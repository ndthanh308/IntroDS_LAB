\documentclass[10pt,conference]{IEEEtran}
%\documentclass[10pt,journal]{IEEEtran}
\IEEEoverridecommandlockouts
\input{packages.tex}
\input{macros.tex}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{\pname
    %\thanks{This study was partially supported by the French ANR project ANR.}
}

\author{\IEEEauthorblockN{DURBET Axel}
\IEEEauthorblockA{\textit{LIMOS, Université Clermont-Auvergne,} \\
\textit{CNRS, Mines Saint-Étienne,}\\
\textit{Aubière, France}\\
axel.durbet@uca.fr}
\and
\IEEEauthorblockN{GROLLEMUND Paul-Marie}
\IEEEauthorblockA{\textit{LMBP, Université Clermont Auvergne,}\\
\textit{CNRS, UMR 6620,}\\
\textit{Aubière, France}\\
paul\_marie.grollemund@uca.fr}
\and
\IEEEauthorblockN{THIRY-ATIGHEHCHI Kevin}
\IEEEauthorblockA{\textit{LIMOS, Université Clermont-Auvergne, 
} \\
\textit{CNRS, Mines Saint-Étienne,}\\
\textit{Aubière, France}\\
kevin.atighehchi@uca.fr}
%\linebreakand
}

\maketitle


\begin{abstract}
    The present paper presents a comprehensive analysis of potential information leakage in distance evaluation, with a specific emphasis on threshold-based obfuscated distance (\textit{i.e.} Fuzzy Matcher).
    It includes detailed descriptions of various situations related to potential information leakage and specific attention is given to their consequences on security.
    %Various scenarios where information leakage may occur are thoroughly described, and their implications for security are examined.
    Generic attacks corresponding to each scenario are outlined, and their complexities are assessed. The main contribution of this work lies in providing an upper bound on the security of a fuzzy matcher in scenarios where there is additional information leakage from the matcher, providing a straightforward understanding of the maximum level of achievable security and its potential implications for data privacy and security.
\end{abstract}

%\tableofcontents
\begin{IEEEkeywords}
Obfuscated Distance, Fuzzy Matcher, Hamming Distance, $L_1$ Distance, Attack Complexity, Information Leakage, Biometrics, Coupon Collector Problem
\end{IEEEkeywords}


\section{Introduction}\label{intro}


% The obfuscated distance function is still little explored in cryptology, and articles mentioning it are recent and rare. An obfuscated distance is a function that allows two or more parties to compute the distance between two inputs such that the only information to learn by each party is the distance. Those functions can be used several times with different modalities. One of the properties of the obfuscated distance is the privacy of the inputs.
In cryptology, the investigation of obfuscated distance functions is still limited, and articles discussing this topic are relatively recent and scarce. An obfuscated distance function facilitates the computation of the distance between two hidden inputs by multiple parties, wherein each party gains knowledge solely of the distance while preserving the privacy of the actual inputs. These functions can be iteratively applied with various features, and one of their fundamental properties is the preservation of input privacy.
% A way to achieve an obfuscated distance function is to use a homomorphic function~\cite{yasuda2017secure,huang2011faster,rane2010privacy} that allows computations to be performed directly on encrypted data without the need for decryption, thereby preserving the privacy of sensitive information; 

A first approach to design an obfuscated distance function involves employing homomorphic cryptography~\cite{yasuda2017secure,huang2011faster,rane2010privacy}, which enables computations to be directly applied on encrypted data without requiring decryption, thereby ensuring the confidentiality of sensitive information;
Garbled circuit~\cite{huang2011faster,bellare2012foundations,yao1986generate} is a cryptographic primitive based on symmetric encryption and oblivious transfer which is used to privately evaluate a function on encrypted inputs without revealing the inputs or the function's logic to the evaluator.
%Functional Encryption~\cite{agrawal2012functional,abdalla2016better} that enables selective access control to specific functions on encrypted data, empowering fine-grained privacy and security in various applications; 
Functional Encryption~\cite{agrawal2012functional,abdalla2016better,Okamoto2012,DATTA201716IPFE,TOMIDA20202019CIP0003IPFE} enables the implementation of specific functions on encrypted data, providing privacy and enhanced security across a wide range of applications such as the distance evaluation;
% Oblivious transfer~\cite{kiraz2015security,bringer2013shade,bringer2014gshade} which allows secure multiparty computation while preserving the privacy; 
Oblivious transfer~\cite{kiraz2015security,bringer2013shade,bringer2014gshade} enables secure multiparty computation while ensuring input privacy by allowing data exchange without revealing the content; 
or others mathematical methods based on computational assumptions~\cite{Galbraith2019PFH,KARABINA2016NTT,fleischhacker2021robust,fleischhacker2022property}. 
The obfuscated distance is also employed for biometric applications, aiming at protecting the client's privacy while maintaining the effectiveness of the biometric identification process.
% The obfuscated distance is used for biometric purposes in order to preserve the privacy of a client. 
% Those primitives can also be used to build a threshold-based obfuscated distance, as in error-correcting code~\cite{huffman2010fundamentals} which detects and corrects errors that may occur during the transmission or storage of digital data, ensuring reliable and accurate data retrieval; 
These cryptographic primitives can also be designed by relying on a threshold-based obfuscated distance, related to error-correcting codes~\cite{huffman2010fundamentals}, which are designed to detect and correct errors that may arise during digital data transmission or storage, thereby ensuring reliable and precise data retrieval;
% secure sketches and fuzzy extractors~\cite{fuller2020computational,dodis2007fuzzy,wen2018robustly,dodis2008fuzzy,cheon2018reusable} that extracts a stable and reusable cryptographic key from noisy or biometric data, enabling secure authentication while accommodating small variations in the input data; 
Secure sketches and fuzzy extractors~\cite{fuller2020computational,dodis2007fuzzy,wen2018robustly,dodis2008fuzzy,cheon2018reusable} are cryptographic schemes able of extracting a consistent and reusable cryptographic key from noisy or biometric data, facilitating secure authentication while accommodating minor variations in the input data;
% or fuzzy vaults~\cite{juels2006fuzzy} securely stores and retrieves secret information by leveraging error-correcting codes and biometric data, providing robust protection against unauthorized access and preserving data integrity.
Fuzzy vaults~\cite{juels2006fuzzy} are cryptographic designs that securely store and retrieve secret information by utilizing error-correcting codes and a noisy input (\textit{e.g.} biometric data), ensuring strong protection against unauthorized access and maintaining data integrity.
% All those constructions are based on or are Fuzzy Matcher, which is a subclass of evasive function~\cite{barak2014obfuscation}. Evasive functions are a class of functions for which it is computationally infeasible for any efficient algorithm to compute their output with high probability on most inputs.
% Most of the authors focus on fuzzy matching for Hamming distance. In this paper, we went a step further and consider our vector in $\mathbb{Z}_q^n$ for the $L_1$ distance however, our result also applies to the Hamming distance. 

All the previous functions and primitives are either founded on or encompass Fuzzy Matcher, which belongs to a subclass of evasive functions. Evasive functions~\cite{Galbraith2019PFH,barak2014obfuscation} are related to a class of functions that represent significant computational challenges for any efficient algorithm attempting to compute their output with high probability on most inputs. 
While many authors focus on fuzzy matching for the Hamming distance, this paper directly tackles the case of vectors in $\mathbb{Z}_q^n$ for the $L_1$ distance. Furthermore, notice that our findings can be extended to the Hamming distance as well.
% The theoretical security of each of these constructions is well known and well described in their respective papers, as is the difficulty an attacker would have in retrieving the initially hidden data. However, with the increasing number of side-channel attacks~\cite{HomoLeak}, implementation errors or construction flaws~\cite{carpovLeak}, the given security bounds are being hazed. One possible scenario is a partial leakage of distance calculation information. So, despite all its properties, an obfuscated distance by construction may leak some information. Information leakage refers to the inadvertent disclosure of sensitive data or details that were not intended to be revealed during the execution of the function. Such inadvertent disclosures can pose significant security and privacy risks, especially in scenarios where the function is utilized in sensitive applications, such as cryptographic protocols or data privacy frameworks (\textit{e.g.} biometric systems). 
% It is crucial to comprehend the implications of information leakage in this context. Hence, in this paper, we emphasize on the impact of leaking extra information on the complexity to retrieve hidden data. 
The theoretical security of each considered function and primitive is extensively investigated and well-documented in their respective papers, including the evaluation of the difficulty for an attacker to deal with the inference of initially hidden input. However, the growing prevalence of side-channel attacks~\cite{HomoLeak,hashemi2023time}, implementation errors, or construction flaws~\cite{carpovLeak} has raised uncertainties about the provided security bounds. One possible concern is the partial leakage of distance calculation information, which could lead to unintended information disclosure during the execution of the function. Such inadvertent disclosures involve significant security and privacy risks, especially in sensitive applications like cryptographic protocols or data privacy frameworks (\textit{e.g.}, biometric systems).

Understanding the implications of information leakage is a milestone in this scientific literature. Hence, this paper focuses on assessing the impact of such information leakage and on the complexity of retrieving hidden data. By investigating this issue, we aim at enhancing knowledge of the impact on the security of obfuscated distance designs and to improve the overall understanding of information leakage risks in cryptographic systems.

Taking the examples of biometric authentication (that requires testing a predicate about a distance) or password authentication (that requires testing a predicate of equality), attacks of interest can be divided into two categories:
\begin{itemize}
\item \textit{Offline exhaustive search attacks} correspond to attacks where a
leaked but protected database is given to the attacker, but the cryptographic obfuscation mechanism used for the verification of a protected fresh vector (biometric template), or the verification of a protected (hashed) password, is not supposed to leak any information beyond its admissibility.
\item \textit{Online exhaustive search attacks} correspond to attacks where an attacker is enforced to interact with the authentication server to deduce information about the target vector.  Such attacks may require malware infection on the server, in order for the attacker to retrieve additional leakage from the matcher, \textit{i.e.} beyond the minimal information leakage (`yes' or `no').
\end{itemize}

\paragraph*{Related Works} 
% Pagnin \textit{et al.}~\cite{pagnin2014leakage} show that in the case of a threshold-based obfuscated distance, it is possible to exploit the result of the matcher to retrieve the hidden vector. This can be related to the zero leakage scenario, where only the output of the matcher is given to the attacker. They show how to perform this attack as well as its complexity. Our work is the same as we consider the same tools, however, we take into account that several extra information may be leaked by the matcher. To the best of our knowledge, this is the only papers that address the subject.
% Pagnin \textit{et al.}~\cite{pagnin2014leakage} show that in the case of a threshold-based obfuscated distance, it is possible to exploit the result of the matcher to retrieve the hidden vector. This can be related to the zero leakage scenario where only the output of the matcher is given to the attacker. They show how to perform this attack as well as its complexity. Our work is the same as we consider the same tools however, we take into account that several extra information may be leaked by the matcher. Ligier \textit{et. al.}~\cite{ligier2017information}. To the best of our knowledge, these are the only papers that address the subject.
Pagnin \textit{et al.}~\cite{pagnin2014leakage} demonstrated that in the context of a Fuzzy Matcher, the result of the matcher can be exploited to retrieve the hidden vector. They work takes place in the minimal leakage, wherein only the matcher's binary output is given to the attacker. They explained the execution of this attack and assessed its complexity. Our work shares a similar focus, as similar tools are also examined. However, we extend the analysis by taking into account the possibility of multiple additional information leaks thanks to the matching operation. 
Similar to the aforementioned work, the proposed attacks aim at recovering the original data, which, in the context of biometrics, corresponds to compromising the privacy of the biometric data. This type of attack is considered the most devastating for such systems, as evidenced by Simoens \textit{et al.}~\cite{Simoens2012AFF}.
To the best of our knowledge, this is the sole paper that comprehensively investigates this subject.


\paragraph*{Contributions}
% In this paper, we delve into a comprehensive analysis of the potential sources of information leakage associated with distance evaluation and more particularly with threshold-based obfuscated distance. These scenarios are described, as well as their implications for security loss. To do so, we highlight generic attacks for each of these scenarios, as well as their complexities.
% In this paper, we delve into a comprehensive analysis of the potential sources of information leakage associated with distance evaluation and, more particularly, with threshold-based obfuscated distance. These scenarios are thoroughly described, along with their implications for security. To achieve this, we systematically outline generic attacks corresponding to each of these scenarios and assess their complexities. Hence, we contribute to the field of information security by offering valuable insights into the complexities of leaking threshold-based obfuscated distance evaluation.
We present a deep analysis of potential information leakage in distance evaluation, with a specific focus on threshold-based obfuscated distance. The paper thoroughly describes various scenarios where information leakage may occur and examines their implications for security. To achieve this, we systematically outline generic attacks corresponding to each scenario and assess their complexities.
Our contribution is to provide insights into the finer points of information leakage in threshold-based obfuscated distance, thus advancing the field of information security. The discussed scenarios give rise to new attacks as well as a range of attacks that complete the work of Pagnin \textit{et al.}:
\begin{enumerate}
\item Accumulation attacks that capture potential attacks from an \textit{honest-but-curious} server when a client authenticates to it. These attacks assume the use of privacy-preserving cryptographic primitives for evaluating the distance between two hidden vectors. Specifically, as an example, we assume the use of a cryptographic obfuscator of the distance function.
\item % A range of attacks that capture data breaches when an obfuscated database is leaked, or when a malicious client launches an \textit{online exhaustive search attack}.
Attacks launched by malicious client exploiting various information leakage from the matcher in the context of a leaked (but obfuscated) database, or by interacting with the server during an \textit{online exhaustive search attack}. 
\end{enumerate}

\paragraph*{Outline}
% The following outline describes the organization of our paper, presenting a clear structure that encompasses the paper framework, different scenarios, the attacks, and some concluding remarks of our obfuscated distance leakage study. Section~\ref{Bg} is dedicated to the definitions used all along the paper on the studied function \texttt{Match}. Then, Section~\ref{Notation} introduces the notations and the oracle used. The main contributions of the paper are in Section~\ref{Leak_type} and Section~\ref{attacks}. The first above-mentioned describes all the leakages scenarios that are studied in this paper. The contents of this section are summarized in Table~\ref{Leak_scenario_table}. The second one relates all the attacks for these scenarios, as well as their complexities. These complexities are then summarized in Table~\ref{Leak_table}. Section~\ref{Conclu} closes the paper by synthesizing all the results of the paper and bringing a new point of view on this work and future perspectives.
%The structure of the paper encompasses the framework, various scenarios, attacks, and concluding remarks of our study on obfuscated distance leakage. 
% Section~\ref{prel} first presents the foundational definitions utilized throughout the paper, specifically focusing on the matcher. 
% Some notations and terminologies are also introduced, and a typology of leakages is provided. This exhaustive description of all the leakage scenarios provides an analysis of the information that may leak.
% The primary contributions of the paper are outlined in Section~\ref{attacks}, 
% where Table~\ref{Leak_scenario_table} provides a concise summary of the scenarios. 
%A concise summary of these scenarios is presented in
%In this section, we also provide a new attack paradigm yielding the accumulation attack as well as the analysis.
Section~\ref{prel} initially presents the fundamental definitions required to read the paper, with a particular emphasis on the matcher. We also introduce certain notations and terminologies, and provide a classification of leakages. This comprehensive description of all leakage scenarios allows for an analysis of potential information leaks. The key contributions of the paper are highlighted in Section~\ref{attacks}, where Table~\ref{Leak_scenario_table} offers a succinct overview of the scenarios.
In the subsection~\ref{AccuAtt:section}, we describe a novel attack paradigm that encompasses the accumulation attack, along with a complete analysis of its complexity.
In contrast, the subsections~\ref{below}, \ref{above}, \ref{both} deepen detailing various attacks corresponding to the identified scenarios, alongside an assessment of their complexities. A succinct summary of these complexities is provided in Table~\ref{Leak_table}.
%Section~\ref{Conclu} concludes the paper, consolidating all the obtained results and presenting novel perspectives on our work, as well as potential directions for future research.


\section{Preliminaries}
\label{prel}
% \begin{definition}[Obfuscated distance scheme]
%     Let $(\Zq,d)$ a metric space equipped with the distance $d:\Zq^n \times \Zq^n \xrightarrow{} \R_{\ge 0}$. Then, $\Delta$ is an obfuscated distance scheme is a pair of algorithm Store and Distance which 
% \end{definition}
%
% In this section, the (Obfuscated) Matcher is defined as a function utilized to verify the proximity of two hidden inputs. The notations to be used throughout the paper are then introduced to facilitate the analysis. In the end, the list of all information leakage scenarios considered is presented.
In this section, the (Obfuscated) Matcher is introduced as a function utilized for verifying the proximity of two hidden inputs. Secondly, the notations used throughout the analysis are presented. Then, a list of all the considered information leakage scenarios is presented.


\subsection{(Obfuscated) Matcher}
\label{Bg}
Let $\Zq^n$ be a metric space equipped with the distance $d$ and $\epsilon\in\mathbb{R}_{\ge 0}$ a threshold. 
%To define a fuzzy matcher, the notion of evasive function must be recalled.
%
% \begin{definition}[Evasive Function]
%     An evasive function family is a collection of functions $F$ such that for every inputs $x$, a random function from $F$ outputs 
% \end{definition}
A private matching scheme $\Xi$ is a pair of an algorithm \texttt{Hide} and a \texttt{Match} which respectively allow hiding a data $x\in \Zq^n$ and check if a newly provided data $y\in \Zq^n$ is such that $d(x,y) \leq \epsilon$. 

\begin{definition}[Hide]
    Let $\Xi$ be a matching scheme, $\Zq^n$ be a metric space equipped with the distance $d$, a space $\mathbb{K}$ and $\epsilon\in\mathbb{R}_{\ge 0}$ a threshold. Given $x\in\Zq^n$,
    \begin{eqnarray*}
        \Xi.\texttt{Hide}: &  \Zq^n & \xrightarrow{} \mathbb{K} \\
        & x & \xrightarrow{} X
    \end{eqnarray*}
    Such that $\Xi.\texttt{Hide}$ can be computed by a polynomial time algorithm (PPT), but any polynomial time randomized algorithm $\mathcal{A}$ that attempts to compute a pseudo-inverse for $\Xi.\texttt{Hide}$ succeeds with negligible probability.
    % act like a one way function
    % the knowledge of $X$ does not gives any informations on $x$.
\end{definition}

Once $x$ has been hidden by the function $\Xi.\texttt{Hide}$, it is possible to check if a vector $y$ is close to $x$ with respect to $\epsilon$. In other words, $\Xi.\texttt{Match}$ indicates if $y\in B_\epsilon(x)$, where $B_\epsilon(x) = \lbrace y \in \Zq^n \,| d(x,y)\leq \epsilon \rbrace$ is the ball of radius $\epsilon$ and centered in $x$. 

\begin{definition}[Match]
    Let $\Xi$ be a matching scheme, $\Zq^n$ be a metric space equipped with the distance $d$, $x\in \Zq^n$, $\mathbb{K}$ be $\Xi.\texttt{Match}(\Zq^n)$ and $\epsilon\in\mathbb{R}_{\ge 0}$ a threshold. Given $Y\in\mathbb{K}$ the output of $\Xi.\texttt{Hide}(y)$ and $X$ the output of $\Xi.\texttt{Hide}(x)$, 
    \begin{eqnarray*}
        \Xi.\texttt{Match}: &  \mathbb{K} \times \mathbb{K} & \xrightarrow{} \lbrace 0, 1 \rbrace \\
        & Y, X  & \xrightarrow{} \begin{cases}
        0 & \text{ if } d(x,y)\leq \epsilon, \\
        1 & \text{ otherwise}, \\ 
        \end{cases}
    \end{eqnarray*}
    such that $\Xi.\texttt{Match}$ is a deterministic polynomial time algorithm that succeeds with probability $1$.
\end{definition}

\begin{rem}
    Both $\Xi.\texttt{Match}$ inputs are hidden by the function $\Xi.\texttt{Hide}$.
\end{rem}

% The $\Xi.\texttt{Match}$ function may leak some information and the possibles leakages scenarios are described later in the paper.
% For the sake of simplicity, in the following, we consider that a vector $y\in\mathbb{Z}_q^n$ can be used directly with $\Xi.\texttt{Match}$ and the pre-transformation $\Xi.\texttt{Hide}(y)$ can be omitted. 
To simplify, we assume that a vector $y \in \mathbb{Z}_q^n$ can be directly used with $\Xi.\texttt{Match}$, \textit{i.e.} pre-transformation $\Xi.\texttt{Hide}(y)$ is omitted when it is not necessary.
The $\Xi.\texttt{Match}$ function has the possibility to disclose certain information, and its possible leakage scenarios are described in the following sections.

\subsection{Notations and Attacker Models}
\label{Notation}

%\subsection{Notations and Attacker Model}
In the following, we consider the metric space $\Zq^n$ (the set of vectors of size $n$ with value in $\llbracket 0, q-1 \rrbracket$) equipped with the distance $d$. 
% $\sigma_{x,\epsilon}$ denote the threshold oracle, which takes as input $y\in\Zq^n$ and return $0$ if the distance between $y$ and $x\in\Zq^n$ a committed vector is below the threshold $\varepsilon$ and $1$ otherwise. For the sake of clarity, the threshold $\epsilon$ is omitted when the context is clear.
%$\mathbb{K}$ denotes $\Xi.\texttt{Match}(\Zq^n)$, \textit{i.e.} the image of $\Zq^n$ by the function $\Xi.\texttt{Match}$. 
Let us define the oracle $\sigma_{x,\epsilon}$ that models the role of $\Xi.\texttt{Match}$, to which the attacker is given access. 
%The oracle $\mathcal{O}_{x,\epsilon}$ return a hided vector $Y\in\mathbb{K}$ such that $\sigma_{x,\epsilon}(Y)$ return $0$. 
For the sake of simplicity, the threshold $\epsilon$ and the hidden vector $x$ are omitted when the context is explicit.

In this framework, the goal of the attacker is to retrieve the hidden data $x\in\Zq^n$ from the transformation $\Xi.\texttt{Hide}(x)$. To do so, she is performing queries to the oracle $\sigma_{x,\epsilon}$ as well as the function $\Xi.\texttt{Hide}$.
Moreover, as regards the accumulation attack scenario, the attacker has access to the oracle  $\mathcal{O}_{x,\epsilon}$ which returns $\Xi.\texttt{Hide}(y)$ with $d(x,y)\leq \varepsilon$. Hence, $\mathcal{O}$ returns a new hidden vector from the genuine client during its authentication in the system.
%Moreover, in the leakage below the threshold scenario, the attacker can have access to the oracle $\mathcal{O}_{x,\epsilon}$ to illustrate an attacker which has access to a genuine client for an authentication scheme.
% The different types of information leakage expose the system to different generic attacks.
% These attacks range from the Exhaustive Search Attack to the Center Search Attack. 
%\todo{Paragraphe introductif de la section}
% A matching scheme $\Xi$ as defined in Section~\ref{Bg} can leak some information. 
% To quantify this leakage, we consider the following scenarios. 
% In the following, we consider that $\Xi.\texttt{Match}$ leaks extra information in addition to its answer $0$ or $1$.  In this section, several scenarios to model these information leaks are defined.
A matching scheme $\Xi$, as defined in Section~\ref{Bg}, can leak some information and we consider that $\Xi.\texttt{Match}$ leaks extra information beyond its binary output ($0$ or $1$). The section comprises two subsections. The first one enumerates the types of information leaks related to a matching scheme and defines the associated scenarios. The second subsection focuses on the various attacks employed to exploit the leaked information. 
%Hence, we present an in-depth analysis of how the leaked information is exploited, and the methodologies utilized (see proofs) to perform these attacks. 
By examining these aspects, we aim at enhancing the understanding of the real security of a matching scheme under different leakage scenarios.


\subsection{Typology of Information Leakage}
\label{Leak_type}
% There are three main scenarios. The first one is a leakage of information below the threshold. The second one is the leakage above the threshold. The last one is when the information leaks below and above the threshold. Among these global scenarios, there are several sub-settings. The first one is the absence of leakage, \textit{i.e.} $\Xi.\texttt{Match}$ returns only $0$ or $1$. 
% Then, the following leak can be declined for above the threshold, below or both. 
% Then, we have the knowledge of the distance $d$, the position of the error only, the distance $d$ and the position of the error, and the distance $d$ and the position of the error as well as the value of each error. Table~\ref{Leak_table} summarizes all those possibilities. 
\noindent
There are three main categories of leakage: 
% The first one involves information leakage below the threshold $\varepsilon$. The second relates to information leakage above $\varepsilon$. The last covers situations where information leaks both below and above the threshold. 
\begin{enumerate}
    \item Information leakage below the threshold. 
    \item Information leakage above the threshold. 
    \item Information leakage both below and above the threshold. 
\end{enumerate}
Among these scenarios, several sub-settings can be identified.
The first sub-setting corresponds to the absence of any leakage, resulting in $\Xi.\texttt{Match}$ yielding only binary outcomes ($0$ or $1$). Then, the following sub-settings are examined: 
\begin{enumerate}
    \item Knowledge of the distance $d$. 
    \item Knowledge of the positions of the errors only.
    \item Knowledge of both the distance $d$ and the positions of the errors.
    \item Knowledge of both the distance and the positions and their corresponding values.
\end{enumerate} 
All these scenarios and sub-settings are summarized in Table~\ref{Leak_table}.

\begin{table}[h]
    \begin{center}
        \begin{tabular}{@{}ll@{}}
            \toprule
            \multicolumn{1}{l}{Threshold}    & \multicolumn{1}{l}{Extra Information} \\ \toprule
            \multirow{5}{*}{Above}           &  No extra leakage                               \\
                                             & Distance    \\
                                             & Position                              \\
                                             & Distance and position                 \\
                                             & Distance, position, and value         \\
                                                                                         \midrule
            \multirow{5}{*}{Below}           & No extra leakage                               \\
                                             & Distance    \\
                                             & Position                              \\
                                             & Distance and, position                \\
                                             & Distance, position, and value         \\
                                                                                         \midrule
            \multirow{5}{*}{Above and Below} & No extra leakage                               \\
                                             & Distance    \\
                                             & Position                              \\
                                             & Distance and position                 \\
                                             & Distance, position, and value         \\
                                                                                         \bottomrule
        \end{tabular}
        \caption{\label{Leak_scenario_table} Summary of distance leakages.}
    \end{center}
\end{table}

\section{Attacks exploiting Leaking Distance}
\label{attacks}

\subsection{Leakage Exploit Attacks}

%Having defined the different types of leakage, we now present the attacks. 
Several attacks are related to the different types of aforementioned leakage scenarios. 
The first attack is the exhaustive search, which tests all possible vectors until the right one is found.

\begin{definition}[Exhaustive Search or Brute-Force Search]
    \label{ExaustiveSearch}
    This attack is a very general problem-solving technique that consists in testing all possibilities until the problem statement is verified. The complexity of this attack is $O(q^n)$ queries to~$\sigma$.
\end{definition}

Then, by considering some extra information, it is possible to perform a hill-climbing attack~\cite{lasry2018methodology}. The aim is to find the solution by iteratively improving a potential solution. 

\begin{definition}[Hill-climbing attack]
    \label{HillClimAtt}
    The hill-climbing attack is based on a mathematical optimization technique. It begins with an arbitrary solution, then it attempts to improve the solution by applying some slight variations. If the modified solution improves the score obtained with the target function, the previous process is repeated with the new solution until the attack succeeds. The complexity of this attack is in $O(nq)$.
\end{definition}

% Using $\sigma$ and obliviously testing someone else vector which can produce a vector close to $x$ under certain circumstances can lead to the total discovery of $x$.
By employing the oracles $\sigma$ and $\mathcal{O}$ under specific conditions, the attacker recovers the complete information of $x$ by accumulating some knowledge about $x$ at each query. However, the accumulation attack only applies to special cases, which are examined in more detail in Section~\ref{AccuAtt:section}.
\begin{definition}[Accumulation Attack]
    \label{AccuAtt}
    The accumulation attack is a passive attack where the attacker recovers a certain amount of information at each interaction.
    By accumulating this information, the entropy of the target is getting smaller until its entropy goes to zero.
    In the end, the attacker has a complete knowledge of the target.
\end{definition}


In~\cite{pagnin2014leakage}, the authors show that from any closed vector $y$ of $x$, \textit{i.e.} $d(x,y)\leq \varepsilon$, it is possible to retrieve the center $x$ of the ball using~$\sigma$. 
\begin{definition}[Center Search Attack~\cite{pagnin2014leakage,Simoens2012AFF}]
    \label{CentSearAtt}
    This attack aims at finding $x$ the center of the acceptance ball $B_\epsilon(x)$. The starting point of the attack is to find a point $b'$ on the edge of the ball, and then converge to its center. The complexity of this attack is $O(nm)$ where $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$.
\end{definition}


% Note that the Center Search Attack is not always possible. In the case where the threshold, \textit{i.e.} the radius of the ball, is too large compared to the space, the attack does not work. %the number of points that can be reached by leaving the ball to get closer is too small. 
% However, with the normal use of a distance-matching system, where $\varepsilon$ is a small fraction of $n$, this should not happen. 
We refer the reader to the work of Pagnin \textit{et al.}~\cite{pagnin2014leakage} for more details.


\subsection{Accumulation Attack}
\label{AccuAtt:section}

The complexity of this attack relies on the coupon collector's problem. This problem is a well-known problem of probability theory, where one seeks to determine the expected number of trials needed to collect a complete set of distinct items from a large pool with replacement. This problem has received considerable attention in the literature, with notable studies conducted by Ferrante \textit{et al.}~\cite{ferrante2012note,CoupnCollector} and Flajolet \textit{et al.}~\cite{flajolet1992birthday}.

In order to support Definition~\ref{AccuAtt}, the subsequent example serves to illustrate the design of an Accumulation Attack.
\begin{ex}
    \label{ExampleAccuAtt}
    
    Assume a setting with a metric space $\mathbb{Z}_2^n$ equipped with the Hamming distance. A client seeks to authenticate to an \textit{honest-but-curious} server that uses a scheme leaking $d_H(x,y)$ and the corresponding errors if $d_H(x,y) \leq \epsilon$.
    As the client is legitimate, \textit{i.e.} $d_H(x,y) \leq \epsilon$, the server recovers the value of at most $\epsilon$ erroneous bits. If the server is lucky, in $n/\epsilon$ steps, the data of the client is compromised. The server needs to collect all the bits of the client, turning this problem into a Coupon Collector problem. According to Ferrante \textit{et al.}~\cite{ferrante2012note,CoupnCollector} and assuming that errors uniformly occur in vector coordinates, the server retrieves the biometric data after an expected number of $N$ authentications with
    \begin{align*}
        \sum\limits_{j=1}^n (-1)^{j-1} \binom{n}{j}\left(1-\frac{n-j}{n}\right)^{-1} & \ge N \\
        \sum\limits_{j=1}^n (-1)^{j-1} \binom{n}{j}\left(1-\frac{\binom{n-j}{\epsilon}}{\binom{n}{\epsilon}}\right)^{-1} & \leq N.
    \end{align*}
    
    For example, let assume $x = (0,0,1,1,0,1,0)$, $\epsilon = 3$. The server set $z = (?,?,?,?,?,?,?)$. Session~1: The client authenticates with $y = (1,1,0,1,0,1,0)$. In this case, $d_H(x,y) = 3 \leq \epsilon$. The server gets the value of the erroneous bits of the client and updates $z = (0,0,1,?,?,?,?)$. Session~2: the client authenticates with $y = (0,0,0,0,1,1,0)$. In this case, $d_H(x,y) = 3 \leq \epsilon$ and the server gets the value of the erroneous bits of the client and updates $z = (0,0,1,1,0,?,?)$. Finally, the server has a vector inside the ball. Hence, she is able to perform an impersonation attack because the entropy of $z$ is smaller than the threshold, or she can perform the Center Search Attack~\ref{CentSearAtt}. Moreover, by trying some extra steps, she will retrieve the very last bits.
\end{ex}
%
% To model this attack, let $\mathcal{O}_{x,\varepsilon}$ be the oracle that returns a $Y=\Xi.\texttt{Hide}(y)$ with $y$ such that $d(x,y)\leq\varepsilon$. 
To model this attack, we consider that $\sigma$ leaks information on the positions and values of errors. Assume that the errors in $y$ given by $\mathcal{O}$ are uniformly distributed. Then, using the same argument as in the example, the vector $x$ is recovered in $O\left(\sum\limits_{j=1}^n (-1)^{j-1} \binom{n}{j}\left(1-\frac{n-j}{n}\right)^{-1}\right)$ queries to both $\mathcal{O}$ and~$\varepsilon$.

\subsection{Attacks complexities for a leakage above the threshold}
\label{above}

% In this section, we consider the first scenario, which is the leakage above the threshold. In other words, given a vector $x$ hided, the submission of $y$ such that $d(x,y)>\varepsilon$ to the $\sigma_{x,\varepsilon}$ oracle may lead to the extra gain of knowledge.
In this section, the first scenario is considered, which involves leakage above the threshold $\varepsilon$. In other words, when a hidden vector $x$ is used, the submission of another vector $y$ such that $d(x,y) > \varepsilon$ to the $\sigma_{x,\varepsilon}$ oracle may lead to the extra gain of knowledge.

\paragraph{The distance is leaked}
%The first case is when the distance is given to the attacker as the extra gain of knowledge. In this case, the attacker can perform a hill-climbing attack till he gets a vector $y$ which is at distance exactly $\varepsilon$ of her target $x$. This part of the attack can be performed in $nq-\varepsilon$ steps. Then, she cannot continue the hill-climbing attack, as she falls below the threshold and does not gain any extra information. However, she can now perform the center search attack in $nm$ steps with $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$.
%Hence, the complexity of the attack to recover $x$ in this case is in $O(n(q+m)-\varepsilon)$.
The first case happens when the distance is provided to the attacker as the extra gain of knowledge. 
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the distance above the threshold, an attacker can retrieve $x$ in $O(n(q+m)-\varepsilon)$ queries to $\sigma_{x,\varepsilon}$, where $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$.       
\end{theorem}
\begin{proof}
In this situation, a hill-climbing attack can be executed by the attacker until a vector $y$ is obtained, precisely at a distance of $\varepsilon$ from their target $x$. This stage of the attack can be completed within $nq-\varepsilon$ steps. Subsequently, the hill-climbing attack cannot be continued since it falls below the threshold, yielding no further extra information. However, the attacker can now proceed with the center search attack, which requires $nm$ steps, where $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$.
%
As a result, the complexity of the attack aimed at recovering $x$, in this case, is in $O(n(q+m)-\varepsilon)$.\\
$\blacksquare$
\end{proof}

\paragraph{The positions are leaked}
% In this case, the extra information given to the attacker is the position of the error, but she ignored the value of each error. Thus, she has to perform an exhaustive search on those erroneous coordinate to get under the threshold. It is reasonable to assume that this part is done in  $q^{n(1-1/q)}$ steps. Indeed, given two random vectors $x,y\in \mathbb{Z}_q^n$, the expectation of the number of coordinate which are different is given by $n(1-1/q)$. Then she can now perform the center search attack in $nm$ steps with $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$.
% Hence, the complexity of the attack to recover $x$ in this case is in $O(q^{n(1-1/q)}+nm)$.
In this case, the error positions are the extra information provided to the attacker, while the value of each error remains secret. 
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the error positions above the threshold, an attacker can retrieve $x$ in average in $O(q^{n(1-1/q)-\varepsilon}+nm)$ (resp. in the worst case in $O(q^{n-\varepsilon}+nm)$) where $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$ queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
\begin{proof}
An exhaustive search on the erroneous coordinates must be performed by the attacker to down below the threshold. It is reasonable to assume that this part can be accomplished in $q^{n(1-1/q)-\varepsilon}$ steps. Given two random vectors $x$ and $y$ from $\mathbb{Z}_q^n$, the expected number of coordinates that differ between them is approximately $n(1-1/q)$. This approximation highlights the difference with the case of an exhaustive search. Indeed, if we simply look at it asymptotically, there is no difference between both.
%
Subsequently, the attacker can perform the center search attack in $nm$ steps, where $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$. Hence, the overall complexity of the attack in this scenario is in $O(q^{n(1-1/q)}+nm)$. The worst case is equivalent to the case above.\\
$\blacksquare$
\end{proof}

\paragraph{The distance and the position are leaked}
%
% In this case, the distance and the position of the errors are given to the attacker when she tried a vector above the threshold. Hence, her hill-climbing attack must be performed in the erroneous coordinates. This part can be done in $nq(1-1/q)-\varepsilon$ steps using the same argument as the above section.
% Then she can now perform the center search attack in $nm$ steps with $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$.
% Hence, the complexity of the attack to recover $x$ in this case is in $O(n(q+m-1)-\varepsilon)$.
%
In this case, when the attacker queries a vector above the threshold, she is provided with both the distance and the error positions. 
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the distance and the positions of the errors above the threshold, an attacker can retrieve $x$ in average in $O(n(q+m-1)-\varepsilon)$ (resp. in the worst case in $O(n(q+m)-\varepsilon)$) where $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$ queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
\begin{proof}
Her hill-climbing attack must be executed on the erroneous coordinates. This stage can be achieved average in $nq(1-1/q)-\varepsilon$ steps (resp. in the worst case in $nq-\varepsilon$), using the same argument as the above section.
In the next stage, the attacker can run the center search attack in $nm$ steps, with $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$. The overall complexity is in average $O(n(q+m-1)-\varepsilon)$ (resp. in the worst case $O(n(q+m)-\varepsilon)$).
\\$\blacksquare$
\end{proof}

\paragraph{The distance, the position, and the value are leaked}
%
%In this last case, the distance, the position of the errors and the value of each error is leaked. In this case, we are facing an error-correcting mechanism that allows the correction above the threshold. It is clear that the attacker recover $x$ in $1$ step. Hence, this attack is in $O(1)$.
%
In this last case, the distance, the error positions and values are leaked.
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the distance, the positions of the errors, and their values above the threshold, an attacker can retrieve $x$ in $O(1)$ queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
\begin{proof}
In this case, the query answer is an error-correcting code, hence yielding a complexity of $O(1)$.
\\
$\blacksquare$
\end{proof}

\subsection{Attack Complexities for Leakage Below the Threshold}
\label{below}
% In this section, we consider the second scenario, which is the leakage below the threshold. In other words, given a vector $x$ hidden, the submission of $y$ such that $d(x,y)\leq\varepsilon$ to the $\sigma_{x,\varepsilon}$ oracle may lead to the extra gain of knowledge.

The second scenario is considered, involving leakage below the threshold. Specifically, assuming the hidden target vector $x$, submitting another vector $y$ such that $d(x,y)\leq\varepsilon$ to the $\sigma_{x,\varepsilon}$ oracle may leak additional information. It is important to note that some systems, such as error-correcting codes, purposely leak information below the threshold and so this is the most likely scenario.

\paragraph{The distance is leaked}
% The first case is when the distance is given to the attacker as the extra gain of knowledge. 
% The first step is to get a vector below the threshold. To do so, the attacker must perform an exhaustive search attack in $q^{n-\varepsilon}$ steps. Then, she can perform a hill-climbing attack in $qn$ steps. Hence, the complexity of the attack to recover $x$, in this case, is in $O(q^{n-\varepsilon}+qn)$.

The first case occurs when the distance is given to the attacker as extra information. 
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and a fuzzy matcher $\Xi$ such that $\Xi.\texttt{Match}$ leaks the distance below the threshold, an attacker can retrieve $x$ in $O(q^{n-\varepsilon}+qn)$ queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
\begin{proof}
The first step involves obtaining a vector below the threshold, which requires performing an exhaustive search attack in $q^{n-\varepsilon}$ steps. Then, a hill-climbing attack can be executed in $qn$ steps. Therefore, the overall complexity is in $O(q^{n-\varepsilon}+qn)$.\\
$\blacksquare$
\end{proof}

\paragraph{The position are leaked}
% In this case, the extra information given to the attacker is the position of the error, but she ignored the value of each error. As in the previous scenario, the first step is to get a vector below the threshold.  To do so, the attacker must perform an exhaustive search attack in $q^{n-\varepsilon}$ steps. Then she must perform an exhaustive search on the erroneous positions in $q^{\varepsilon}$ steps. Hence, the complexity of the attack to recover $x$, in this case, is in $O(q^{n-\varepsilon}+q^{\varepsilon})$.

The position of the errors is the extra information given to the attacker, while their values remain secret. 
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the position of the errors below the threshold, an attacker can retrieve $x$ in $O(q^{n-\varepsilon}+q^{\varepsilon})$ queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
\begin{proof}
The first step is to fall inside the ball, which requires the attacker to perform an exhaustive search attack in $q^{n-\varepsilon}$ steps. Subsequently, an exhaustive search on the erroneous positions must be performed, which takes $q^{\varepsilon}$ steps. Hence, the complexity of the attack to recover $x$, in this case, is in $O(q^{n-\varepsilon}+q^{\varepsilon})$.
\\ $\blacksquare$
\end{proof}


\begin{table*}[]
%\resizebox{\columnwidth}{!}{%
\centering
\begin{tabular}{ccccc}
\toprule
\multicolumn{1}{l}{Threshold related}   & Leakage                      & Complexity type & Worst case complexity in Big-$O$ & Average complexity in Big-$O$              \\
\midrule
\multirow{4}{*}{Above} & Distance                     & Lin.       & $n(q+m)-\varepsilon$  &       $-$       \\
                               & Position                     & Exp        &   $q^{n-\varepsilon} + nm$  & $q^{n(1-1/q)-\varepsilon}+nm$              \\
                               & Distance and position        & Lin.       & $n(q + m) - \varepsilon$   &  $n(q+m-1)-\varepsilon$         \\
                               & Distance, position, and value & Const.     & $1$       &                  $-$        \\
                               \midrule
\multirow{5}{*}{Below} & Distance                     & Exp.       & $q^{n-\varepsilon}+qn$   &          $-$ \\
                               & Position                     & Exp.       & $q^{n-\varepsilon}+q^{\varepsilon}$ & $-$ \\
                               & Distance and positions        & Exp.       & $q^{n-\varepsilon}+q\varepsilon$  & $-$ \\
                               & Positions and values (accumulation) & Lin. & $\infty$  &  $\sum_{j=1}^n (-1)^{j-1} \binom{n}{j}\left(1-\frac{n-j}{n}\right)^{-1}$\\
                               & Distance, positions and values & Exp.       & $q^{n-\varepsilon}$      &  $-$         \\
                               \midrule
\multirow{5}{*}{Both} & Nothing                      & Exp.       & $q^{n-\varepsilon}+nm$  & $-$\\

                               & Distance                     & Lin.       & $nq$     &   $-$                        \\
                               & Positions                     & Exp.       &  $q^n$  &   $q^{n(1-1/q)}$                \\
                               & Distance and positions        & Lin.       &   $nq$  &   $nq(1-1/q)$                  \\
                               & Distance, positions and values & Const.    & $1$         &     $-$                   \\
                               \bottomrule
\end{tabular}
%}
\caption{Summary of all leakage exploits and their complexities, where $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$. The dash in the second column signifies that the worst-case complexity prevails. The accumulation attack assumes uniformly distributed errors across each authentication session.}
\label{Leak_table}
\end{table*}

\paragraph{The distance and the position are leaked}

% In this case, the distance and the position of the errors are given to the attacker when she tries a vector above the threshold. She performed an exhaustive search to get below the threshold in $q^{n-\varepsilon}$ steps. Then, she performs a hill-climbing attack on the faulty coordinates in $q\varepsilon$ steps. Hence, the complexity of the attack to recover $x$ in this case is in $O(q^{n-\varepsilon}+q\varepsilon)$.

In this case, the distance and the positions of the errors are given to the attacker when a vector below the threshold is queried.
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the distance and the positions of the errors below the threshold, an attacker can retrieve $x$ in $O(q^{n-\varepsilon}+q\varepsilon)$ queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
\begin{proof}
An exhaustive search is performed by the attacker to fall below the threshold in $q^{n-\varepsilon}$ steps. Subsequently, a hill-climbing attack is executed on the faulty coordinates, which takes $q\varepsilon$ steps. Therefore, the complexity of the attack to recover $x$ in this case is in $O(q^{n-\varepsilon}+q\varepsilon)$.\\
$\blacksquare$
\end{proof}



\paragraph{The distance, the positions, and the values are leaked}

% In this last case, the distance, the position of the errors and the value of each error is leaked. In this case, we are facing an error-correcting mechanism that allow the correction below the threshold. It is clear that the cost of this attack is equivalent to the exhaustive search to get a vector below the threshold. Hence, the complexity of the attack to recover $x$ in this case is in $O(q^{n-\varepsilon})$.

In this last case, the distance, the position of the errors, and the value of each error are leaked. 
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the distance, the position of the errors, and the value of each error below the threshold, an attacker can retrieve $x$ in $O(q^{n-\varepsilon})$ queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
\begin{proof}
We are confronted with an error-correcting mechanism that allows the correction below the threshold. The cost of this attack is equivalent to the cost of an exhaustive search aiming at a vector below the threshold. As a result, the complexity of the attack to recover $x$, in this case, is in $O(q^{n-\varepsilon})$.
\\
$\blacksquare$
\end{proof}



\subsection{Leakage Below and Above the Threshold}
\label{both}
% In this section, we consider the last scenario, which is the leakage independent of the threshold. In other words, given a vector $x$ hidden, the submission of $y$ to the $\sigma_{x,\varepsilon}$ oracle may lead to the extra gain of knowledge.
The last scenario is considered, which involves a leakage independent of the threshold. In other words, when a hidden vector $x$ is targeted, the queried vector $y$ to the $\sigma_{x,\varepsilon}$ oracle may result in the leak of additional information. Most of the reasoning comes from the previous cases.


\paragraph{Minimal Leakage (single bit of information leakage)}
This case is the same for the three possible scenarios (above, below, and both). 
\begin{theorem}
    Given $\varepsilon$ a threshold, $x$ a vector in $\mathbb{Z}_q^n$ and a fuzzy matcher $\Xi$, an attacker can retrieve $x$ in $O(q^{n-\varepsilon}+nm)$ queries to $\sigma_{x,\epsilon}$, with $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$.       
\end{theorem}
\begin{proof}
The best chance for the attacker is to find a vector in the ball of $x$. Then, she performs the center search attack~\cite{pagnin2014leakage}. Hence, the complexity of the attack to recover $x$ in this case is in $O(q^{n-\varepsilon}+nm)$ with $m=\mathrm{min}(\lfloor 2\epsilon \rfloor,2\ln q)$.
\\
$\blacksquare$
\end{proof}



\paragraph{Leakage of Distance}
When the distance is given to the attacker, she can perform a hill-climbing attack in $O(nq)$. This is the classical setup for a hill-climbing attack~\cite{lasry2018methodology}.
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the distance, an attacker can retrieve $x$ in $O(nq)$ queries to $\sigma_{x,\epsilon}$.       
\end{theorem}


\paragraph{Leakage of Position(s)}
In this case, the extra information given to the attacker is the positions of the errors, but the corresponding values remain secret.
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the positions of the errors, an attacker can retrieve $x$ in an average number of $O(q^{n(1-1/q)})$ (resp. a worst-case number of $O(q^{n})$) queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
\begin{proof}
She has to perform an exhaustive search for the erroneous bits. Hence, the average complexity of the attack to recover $x$, in this case, is $O(q^{n(1-1/q)})$, while the worst case complexity is $O(q^{n})$.
\\
$\blacksquare$
\end{proof}


\paragraph{Leakage of Distance and Position(s)}
In this case, the distance and the positions of the errors are given to the attacker when she guesses a vector.
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks  the distance and the positions of the errors, an attacker can retrieve $x$ in an average number of $O(qn(1-1/q))$ (resp. a worst-case number of $O(qn)$) queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
\begin{proof}
She has to perform a hill-climbing attack on the erroneous values.
Hence, the average complexity of the attack to recover $x$ in this case is $O(qn(1-1/q))$, while the worst-case complexity is $O(qn)$.
\\
$\blacksquare$
\end{proof}


\paragraph{Leakage of Distance, Position(s) and value(s)}
In this last case, the distance, the positions of the errors and corresponding values are leaked. 
\begin{theorem}
    Given a threshold $\varepsilon$, a vector $x\in\mathbb{Z}_q^n$ and $\Xi$ a fuzzy matcher such that $\Xi.\texttt{Match}$ leaks the distance, the positions of the errors and their values, an attacker can retrieve $x$ in $O(1)$ queries to $\sigma_{x,\epsilon}$.       
\end{theorem}
In this case, it is clear that the complexity is in $O(1)$.


Information leakage is related to the properties and the design of the obfuscated distance.
Attacks for each leakage are summarized in Table~\ref{Leak_table}.



\section{Conclusion}
\label{Conclu}
% In this paper, information leakage of a fuzzy matcher was investigated, and the security loss associated with the best generic attack was evaluated. Scenarios of distance leakage, error position leakage, distance and position leakage, and distance, position, and error value leakage were explored for all three possible setups, \textit{i.e.}, above the threshold, below the threshold, and both. It was found that many scenarios significantly impact security. This paper provides insights into this security loss in the event of information leakage and proposes a straightforward attack to exploit it.
Our investigation into the information leakage of a fuzzy matcher has shed light on critical security vulnerabilities that arise under various scenarios. By evaluating the impact of different types of leakage, including distance, error position, and error value, we have gained insights into the potential risks posed to data privacy and security in practical applications. 

Our analysis encompasses all possible setups, both above and below the threshold, allowing us to identify specific conditions under which information leakage can have a substantial effect on the overall security of the system. The simplicity and efficacy of the proposed attack for exploiting information leakage underscore the importance of actively addressing potential vulnerabilities for any fuzzy matcher in particular when the leaked information is above the threshold or both above and below the threshold. 
%Moreover, the presented attacks, which involve exhaustive search, can be theoretically enhanced using techniques such as \textit{set-covering} and \textit{sampling without replacement}, as demonstrated by Pagnin \textit{et al.}~\cite{pagnin2014leakage}. This has not been discussed because the \textit{set-covering} is an NP-Hard problem which makes the attack in question unusable.
Furthermore, the attacks presented in this study, relying on exhaustive search, have the potential for theoretical improvement by using techniques such as \textit{set-covering} and \textit{sampling without replacement}, as shown by Pagnin \textit{et al.}~\cite{pagnin2014leakage}. However, it is essential to note that the feasibility of the mentioned approach is blocked due to the NP-hard nature of the \textit{set-covering} problem, making the attack impractical. It is important to highlight that the leakage below the threshold does not significantly hurt the security of the fuzzy matcher while the leakage above significantly decreases the security.
% Ultimately, our research underscores the significance of investigating information leakage in cryptographic systems and highlights the need for continued exploration and development of cryptographic primitives that can resist side-channel attacks and mitigate potential information leaks effectively.
Ultimately, our research emphasizes the critical importance of exploring information leakage in cryptographic systems, highlighting the ongoing necessity for the development of robust cryptographic primitives capable of withstanding side-channel attacks and effectively mitigating potential information leaks.

% The accumulation attack we examined presumes uniformly distributed errors across each authentication session. To our knowledge, there is no existing literature that offers an analysis of the distribution of these errors. In reality, certain errors could occur more frequently. A skewed distribution of the errors could largely increase the expected number of required authentications from the genuine client. 
The accumulation attack we investigated is based on the assumption of errors uniformly distributed throughout each authentication session. As far as we are aware, no previous studies provide an analysis of how these errors are distributed. In practical scenarios, some errors might manifest more frequently. If the distribution of errors is skewed, this could substantially increase the expected number of authentications required from the legitimate user so that the server to fully recover the hidden vector.


%\newpage
\bibliographystyle{unsrt}
\bibliography{biblio}

\end{document}
