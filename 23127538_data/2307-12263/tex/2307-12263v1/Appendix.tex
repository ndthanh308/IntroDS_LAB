\appendices
\section{The Proof of Proposition \ref{prop2}}
\label{appa}
For the jointly Gaussian random vectors $\bm{x}$ and $\bm{y}$, we have
\begin{equation}
\begin{aligned}
&    \left[\begin{matrix}\bm{x}\\\bm{y}\\\end{matrix}\right] \sim \mathcal{N}\left(\left[\begin{matrix}\bm{\mu}_x\\\bm{\mu}_y\\\end{matrix}\right],\left[\begin{matrix}A&C\\C^T&B\\\end{matrix}\right]\right) \\
& = \mathcal{N}\left(\left[\begin{matrix}\bm{\mu}_x\\\bm{\mu}_y\\\end{matrix}\right],\left[\begin{matrix}\widetilde{A}&\widetilde{C}\\{\widetilde{C}}^T&B\\\end{matrix}\right]^{-1}\right)
\end{aligned}
\end{equation}
then the marginal and conditional distribution of $\bm{x}$ are shown as follows according to \cite{williams2006gaussian}.
\begin{equation}
    \bm{x} \sim \mathcal{N}\left(\bm{\mu}_x,A\right)
\end{equation}
% and
\begin{equation}
\label{app2-1}
    \bm{x}|\bm{y} \sim \mathcal{N}\left(\bm{\mu}_x+CB^{-1}\left(\bm{y}-\bm{\mu}_y\right),A-CB^{-1}C^T\right)
\end{equation}
% or
\begin{equation}
\label{app2-2}
    \bm{x}|\bm{y} \sim \mathcal{N}\left(\bm{\mu}_x-{\widetilde{A}}^{-1}\widetilde{C}\left(\bm{y}-\bm{\mu}_y\right),{\widetilde{A}}^{-1}\right)
\end{equation}

Thus, \textbf{Proposition \ref{prop2}} is proved.










\section{The Proof of Proposition \ref{prop3}}
\label{appb}
The product of two Gaussian distributions is represented as
\begin{equation}
\mathcal{N}\left(\bm{x}\middle|\bm{a},A\right)\mathcal{N}\left(\bm{x}\middle|\bm{b},B\right)=Z^{-1}\mathcal{N}\left(\bm{x}\middle|\bm{c},C\right)
\end{equation}
where
\begin{equation}
\label{app4}
    \bm{c}=C\left(A^{-1}\bm{a}+B^{-1}\bm{b}\right)
\end{equation}
\begin{equation}
\label{app5}
    C=\left(A^{-1}+B^{-1}\right)^{-1}
\end{equation}
\begin{equation}
\label{app6}
    Z^{-1}=\left(2\pi\right)^{-\frac{D}{2}}\left|A+B\right|^{-\frac{1}{2}}\exp{\left(-\frac{\left(\bm{a}-\bm{b}\right)^T\left(\bm{a}-\bm{b}\right)}{2\left(A+B\right)}\right)}
\end{equation}

Thus, through multiplying the cavity distribution by $t_i$ from (\ref{11}), \textbf{Proposition \ref{prop3}} is proved.


\section{The Proof of Proposition \ref{prop4}}
\label{appc}
Consider
\begin{equation}
\label{app7}
Z=\int_{-\infty}^{\infty}{\Phi\left(\frac{x-m}{v}\right)\mathcal{N}(x|\mu,\sigma^2)dx}
\end{equation}
% where
% \begin{equation}
%     \Phi\left(x\right)=\int_{-\infty}^{x}{\mathcal{N}\left(y\right)dy}
% \end{equation}
When $v>0$, by combining$ z=y-x+\mu-m$ and $w=x-\mu$ we can get
\begin{equation}
\begin{aligned}
& Z_{v>0}=\frac{\int_{-\infty}^{\infty}\int_{-\infty}^{x}\exp{\left(-\frac{\left(y-m\right)^2}{2v^2}-\frac{\left(x-\mu\right)^2}{2\sigma^2}\right)}}{2\pi\sigma v}dydx \\
& =\frac{\int_{-\infty}^{\mu-m}\int_{-\infty}^{\infty}\exp{\left(-\frac{\left(z+w\right)^2}{2v^2}-\frac{w^2}{2\sigma^2}\right)}}{2\pi\sigma v}dwdz
\end{aligned}
\end{equation}
% and
\begin{equation}
\begin{aligned}
& Z_{v>0} \\
& =\frac{\int_{-\infty}^{\mu-m}\int_{-\infty}^{\infty}\exp{\left(-\frac{1}{2}\left[\begin{matrix}w\\z\\\end{matrix}\right]^T\left[\begin{matrix}\frac{1}{v^2}+\frac{1}{\sigma^2}&\frac{1}{v^2}\\\frac{1}{v^2}&\frac{1}{v^2}\\\end{matrix}\right]\left[\begin{matrix}w\\z\\\end{matrix}\right]\right)}}{2\pi\sigma v}dwdz \\
& =\int_{-\infty}^{\mu-m}\int_{-\infty}^{\infty}\mathcal{N}\left(\left[\begin{matrix}w\\z\\\end{matrix}\right]|\mathbf{0},\left[\begin{matrix}\sigma^2&-\sigma^2\\-\sigma^2&v^2+\sigma^2\\\end{matrix}\right]\right)dwdz
\end{aligned}
\end{equation}
According to (\ref{app2-1}) and (\ref{app2-2}), we can get
\begin{equation}
\label{app11}
    Z_{v>0}=\frac{\int_{-\infty}^{\mu-m}\exp{\left(-\frac{z^2}{2\left(v^2+\sigma^2\right)}\right)}dz}{\sqrt{2\pi(v^2+\sigma^2)}}=\Phi\left(\frac{\mu-m}{\sqrt{v^2+\sigma^2}}\right)
\end{equation}
When $v<0$, by combining $\Phi\left(-z\right)=1-\Phi\left(z\right)$ and (\ref{app7}),
% we can obtain
\begin{equation}
\label{app12}
Z_{v<0}=1-\Phi\left(\frac{\mu-m}{\sqrt{v^2+\sigma^2}}\right)=\Phi\left(-\frac{\mu-m}{\sqrt{v^2+\sigma^2}}\right)
\end{equation}

By collecting (\ref{app11}) and (\ref{app12}), we can get
\begin{equation}
\label{app13}
Z=\int\Phi\left(\frac{x-m}{v}\right)\mathcal{N}\left(x\middle|\mu,\sigma^2\right)dx=\Phi\left(z\right)
\end{equation}
where $z=\frac{\mu-m}{v\sqrt{1+\sigma^2/v^2}} (v\neq0)$. 
% We aim to get the moments of
% \begin{equation}
% q\left(x\right)=Z^{-1}\Phi\left(\frac{x-m}{v}\right)\mathcal{N}\left(x\middle|\mu,\sigma^2\right)
% \end{equation}
By differentiating with respect to $\mu$ on (\ref{app13}), we can obtain
\begin{equation}
\begin{aligned}
& \frac{\partial Z}{\partial\mu}=\int{\frac{x-\mu}{\sigma^2}\Phi\left(\frac{x-m}{v}\right)}\mathcal{N}\left(x\middle|\mu,\sigma^2\right)dx =\frac{\partial}{\partial\mu}\Phi\left(z\right) \\
& \Longleftrightarrow \frac{1}{\sigma^2}\int x\Phi\left(\frac{x-m}{v}\right)\mathcal{N}\left(x\middle|\mu,\sigma^2\right)dx-\frac{\mu Z}{\sigma^2} \\
& =\frac{\mathcal{N}(z)}{v\sqrt{1+\sigma^2/v^2}}
\end{aligned}
\end{equation}
where $\partial\Phi\left(z\right)/\partial\mu=\mathcal{N}(z)\partial z/\partial\mu$ is utilized. Multiplying through by $\sigma^2/Z$, (\ref{app16}) is obtained.
\begin{equation}
\label{app16}
\mathbb{E}_q\left[x\right]=\mu+\frac{\sigma^2\mathcal{N}\left(z\right)}{\Phi\left(z\right)v\sqrt{1+\frac{\sigma^2}{v^2}}}
\end{equation}
Similarly, we can obtain the second moment as
\begin{equation}
\label{app17}
\begin{aligned}
 & \frac{\partial^2Z}{\partial\mu^2} \\
 & =\int{[\frac{x^2}{\sigma^4}-\frac{2\mu x}{\sigma^4}+\frac{\mu^2}{\sigma^4}-\frac{1}{\sigma^2}] \Phi\left(\frac{x-m}{v}\right)\mathcal{N}\left(x\middle|\mu,\sigma^2\right)} dx  \\
 & =-\frac{z\mathcal{N}(z)}{v^2+\sigma^2} \Longleftrightarrow \\
 & \mathbb{E}_q\left[x^2\right]=2\mu\mathbb{E}_q\left[x\right]-\mu^2+\sigma^2-\frac{\sigma^4z\mathcal{N}\left(z\right)}{\Phi\left(z\right)\left(v^2+\sigma^2\right)}
\end{aligned}
\end{equation}
By combining (\ref{app16}) and (\ref{app17}), we can get
\begin{equation}
\begin{aligned}
& \mathbb{E}_q\left[{(x-\mathbb{E}_q\left[x\right])}^2\right]=\mathbb{E}_q\left[x^2\right]-\mathbb{E}_q[x]^2 \\
& =\sigma^2-\frac{\sigma^4\mathcal{N}\left(z\right)}{\left(v^2+\sigma^2\right)\Phi\left(z\right)}\left(z+\frac{\mathcal{N}\left(z\right)}{\Phi\left(z\right)}\right)
\end{aligned}
\end{equation}

Thus, \textbf{Proposition \ref{prop4}} is proved.

\section{The Proof of Proposition \ref{prop5}}
\label{appd}
We can obtain (\ref{19-1}), (\ref{19-2}), and (\ref{19-3}) according to (\ref{app4}), (\ref{app5}), and (\ref{app6}). Hence, \textbf{Proposition \ref{prop5}} is proved.



\section{The Proof of Proposition \ref{prop6}}
\label{appe}
The approximated mean for $f_\ast$ can be denoted as
\begin{equation}
\begin{aligned}
& \mathbb{E}_q\left[f_\ast|X,\bm{y},\bm{x}_\ast\right]=\bm{k}_\ast^TK^{-1}\bm{\mu} \\
& =\bm{k}_\ast^TK^{-1}\left(K^{-1}+{\widetilde{\Sigma}}^{-1}\right)^{-1}{\widetilde{\Sigma}}^{-1}\widetilde{\bm{\mu}} \\
& =\bm{k}_\ast^T\left(K+\widetilde{\Sigma}\right)^{-1}\widetilde{\bm{\mu}}
\end{aligned}
\end{equation}

The variance of $f_\ast|(X,\bm{y})$ under the Gaussian approximation can be denoted as
\begin{equation}
\begin{aligned}
& \mathbb{V}_q\left[f_\ast\middle| X,\bm{y},\bm{x}_\ast\right] = \mathbb{E}_{p(f_\ast|X,\bm{x}_\ast,\bm{f})} {f_\ast-\mathbb{E}[f_\ast|X,\bm{x}_\ast,\bm{f}]}^2 \\
& =k\left(\bm{x}_\ast,\bm{x}_\ast\right)-\bm{k}_\ast^TK^{-1}\bm{k}_\ast+\bm{k}_\ast^TK^{-1}\left(K^{-1}+\widetilde{\Sigma}\right)^{-1}K^{-1}\bm{k}_\ast \\
& =k\left(\bm{x}_\ast,\bm{x}_\ast\right)-\bm{k}_\ast^T\left(K^{-1}+\widetilde{\Sigma}\right)^{-1}\bm{k}_\ast
\end{aligned}
\end{equation}

Then, we can obtain
\begin{equation}
\begin{aligned}
& q\left(y_\ast\middle| X,\bm{y},\bm{x}_\ast\right)=\mathbb{E}_q\left[\pi_\ast|X,\bm{y},\bm{x}_\ast\right] \\
& =\int\Phi\left(f_\ast\right)q\left(f_\ast\middle| X,\bm{y},\bm{x}_\ast\right)df_\ast
\end{aligned}
\end{equation}

According to (\ref{app11}), we can obtain
\begin{equation}
\label{app22}
\begin{aligned}
& q\left(y_\ast\middle| X,\bm{y},\bm{x}_\ast\right) \\
& =\Phi\left(\frac{\bm{k}_\ast^T\left(K+\widetilde{\Sigma}\right)^{-1}\widetilde{\bm{\mu}}}{\sqrt{1+k\left(\bm{x}_\ast,\bm{x}_\ast\right)-\bm{k}_\ast^T\left(K+\widetilde{\Sigma}\right)^{-1}\bm{k}_\ast}}\right)
\end{aligned}
\end{equation}

By combining (\ref{13}) and (\ref{app22}), \textbf{Proposition \ref{prop6}} is proved.




\section{The Proof of Proposition \ref{prop7}}
\label{appf}
Given $f_s$ and $f_\ast$, $y_s$ and $y_\ast$ are conditionally independent. Hence, $p\left(y_s,y_\ast\middle|\bm{x}_s,\bm{x}_\ast\right)$ can be represented as
\begin{equation}
\begin{aligned}
& p\left(y_s=1,y_\ast=1\middle|\bm{x}_s,\bm{x}_\ast\right) \\
& =\iint{\Phi\left(f_s\right)\Phi\left(f_\ast\right)\phi\left(f_s,f_\ast\middle|\mu_{s\ast},\Sigma_{s\ast}\right)}df_sdf_\ast \\
& =\iint{\Phi\left(f_\ast\right)\phi\left(f_\ast\middle|{\widetilde{\mu}}_\ast\left(f_s\right),{\widetilde{\sigma}}_{\ast\ast}\right)df_\ast\Phi\left(f_s\right)}\phi\left(f_s\middle|\mu_s,\sigma_{ss}\right)df_s \\
& =\int\Phi\left(\frac{{\widetilde{\mu}}_\ast\left(f_s\right)}{\sqrt{{\widetilde{\sigma}}_{\ast\ast}+1}}\right)\Phi\left(f_s\right)\phi\left(f_s\middle|\mu_s,\sigma_{ss}\right)df_s
\end{aligned}
\end{equation}

Hence, \textbf{Proposition \ref{prop7}} is proved.

% \section{The Proof of Lemma \ref{lem}}
% \label{appg}
% \begin{equation}
% \begin{aligned}
% & R_e=\frac{1}{N_a}\sum_{n=1}^{N_a}\mathbb{I}\left(\bm{L}_n \neq \bm{Y}_n\right) \\
% & =\displaystyle\frac{FA+FL}{TL+TA+FL+FA} \\
% & =\displaystyle\frac{1}{\displaystyle\frac{TL+TA+FL+FA}{FA+FL}} \\
% & =\displaystyle\frac{1}{1+\displaystyle\frac{TL+TA}{FA+FL}} \\
% & =\displaystyle\frac{1}{1+\displaystyle\frac{\displaystyle\frac{TL}{TA}+1}{\displaystyle\frac{FA}{TA}+\displaystyle\frac{FL}{TA}}} \\
% & =\frac{1}{1+\displaystyle\frac{\displaystyle\frac{TL}{TA}+1}{\displaystyle\frac{1}{P_{md}-1}+\displaystyle\frac{1}{P_{fa}-1}}}
% \end{aligned}
% \end{equation}

% Hence, \textbf{Lemma \ref{lem}} is proved.