\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@rmstyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{mothukuri2021survey}
V.~Mothukuri, R.~M. Parizi, S.~Pouriyeh, Y.~Huang, A.~Dehghantanha, and
  G.~Srivastava, ``A survey on security and privacy of federated learning,''
  \emph{Future Generation Computer Systems}, vol. 115, pp. 619--640, 2021.

\bibitem{pmlr-v108-bagdasaryan20a}
\BIBentryALTinterwordspacing
E.~Bagdasaryan, A.~Veit, Y.~Hua, D.~Estrin, and V.~Shmatikov, ``How to backdoor
  federated learning,'' in \emph{Proceedings of the Twenty Third International
  Conference on Artificial Intelligence and Statistics}, ser. Proceedings of
  Machine Learning Research, S.~Chiappa and R.~Calandra, Eds., vol. 108.\hskip
  1em plus 0.5em minus 0.4em\relax PMLR, 26--28 Aug 2020, pp. 2938--2948.
  [Online]. Available:
  \url{https://proceedings.mlr.press/v108/bagdasaryan20a.html}
\BIBentrySTDinterwordspacing

\bibitem{8835365}
B.~Wang, Y.~Yao, S.~Shan, H.~Li, B.~Viswanath, H.~Zheng, and B.~Y. Zhao,
  ``Neural cleanse: Identifying and mitigating backdoor attacks in neural
  networks,'' in \emph{2019 IEEE Symposium on Security and Privacy (SP)}, 2019,
  pp. 707--723.

\bibitem{suri2022subject}
A.~Suri, P.~Kanani, V.~J. Marathe, and D.~W. Peterson, ``Subject membership
  inference attacks in federated learning,'' \emph{arXiv preprint
  arXiv:2206.03317}, 2022.

\bibitem{zhang2019poisoning}
J.~Zhang, J.~Chen, D.~Wu, B.~Chen, and S.~Yu, ``Poisoning attack in federated
  learning using generative adversarial nets,'' in \emph{2019 18th IEEE
  international conference on trust, security and privacy in computing and
  communications/13th IEEE international conference on big data science and
  engineering (TrustCom/BigDataSE)}.\hskip 1em plus 0.5em minus 0.4em\relax
  IEEE, 2019, pp. 374--380.

\bibitem{el2022differential}
A.~El~Ouadrhiri and A.~Abdelhadi, ``Differential privacy for deep and federated
  learning: A survey,'' \emph{IEEE access}, vol.~10, pp. 22\,359--22\,380,
  2022.

\bibitem{biggio2012poisoning}
B.~Biggio, B.~Nelson, and P.~Laskov, ``Poisoning attacks against support vector
  machines,'' \emph{arXiv preprint arXiv:1206.6389}, 2012.

\bibitem{fang2020local}
M.~Fang, X.~Cao, J.~Jia, and N.~Gong, ``Local model poisoning attacks to
  $\{$Byzantine-Robust$\}$ federated learning,'' in \emph{29th USENIX security
  symposium (USENIX Security 20)}, 2020, pp. 1605--1622.

\bibitem{sun2019can}
Z.~Sun, P.~Kairouz, A.~T. Suresh, and H.~B. McMahan, ``Can you really backdoor
  federated learning?'' \emph{arXiv preprint arXiv:1911.07963}, 2019.

\bibitem{liu2018fine}
K.~Liu, B.~Dolan-Gavitt, and S.~Garg, ``Fine-pruning: Defending against
  backdooring attacks on deep neural networks,'' in \emph{International
  symposium on research in attacks, intrusions, and defenses}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2018, pp. 273--294.

\bibitem{Xie2020DBA:}
\BIBentryALTinterwordspacing
C.~Xie, K.~Huang, P.-Y. Chen, and B.~Li, ``Dba: Distributed backdoor attacks
  against federated learning,'' in \emph{International Conference on Learning
  Representations}, 2020. [Online]. Available:
  \url{https://openreview.net/forum?id=rkgyS0VFvr}
\BIBentrySTDinterwordspacing

\bibitem{xie2021crfl}
C.~Xie, M.~Chen, P.-Y. Chen, and B.~Li, ``Crfl: Certifiably robust federated
  learning against backdoor attacks,'' in \emph{International Conference on
  Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp.
  11\,372--11\,382.

\bibitem{2018arXiv180709173T}
S.~{Truex}, L.~{Liu}, M.~{Emre Gursoy}, L.~{Yu}, and W.~{Wei}, ``{Towards
  Demystifying Membership Inference Attacks},'' \emph{arXiv e-prints}, p.
  arXiv:1807.09173, June 2018.

\bibitem{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio, ``Generative adversarial nets,'' \emph{Advances
  in neural information processing systems}, vol.~27, 2014.

\bibitem{hitaj2017deep}
B.~Hitaj, G.~Ateniese, and F.~Perez-Cruz, ``Deep models under the gan:
  information leakage from collaborative deep learning,'' in \emph{Proceedings
  of the 2017 ACM SIGSAC conference on computer and communications security},
  2017, pp. 603--618.

\bibitem{shokri2015privacy}
R.~Shokri and V.~Shmatikov, ``Privacy-preserving deep learning,'' in
  \emph{Proceedings of the 22nd ACM SIGSAC conference on computer and
  communications security}, 2015, pp. 1310--1321.

\bibitem{8835269}
L.~Melis, C.~Song, E.~De~Cristofaro, and V.~Shmatikov, ``Exploiting unintended
  feature leakage in collaborative learning,'' in \emph{2019 IEEE Symposium on
  Security and Privacy (SP)}, 2019, pp. 691--706.

\bibitem{xie2018differentially}
L.~Xie, K.~Lin, S.~Wang, F.~Wang, and J.~Zhou, ``Differentially private
  generative adversarial network,'' \emph{arXiv preprint arXiv:1802.06739},
  2018.

\bibitem{augenstein2019generative}
S.~Augenstein, H.~B. McMahan, D.~Ramage, S.~Ramaswamy, P.~Kairouz, M.~Chen,
  R.~Mathews, \emph{et~al.}, ``Generative models for effective ml on private,
  decentralized datasets,'' \emph{arXiv preprint arXiv:1911.06679}, 2019.

\bibitem{zhu2020more}
T.~Zhu, D.~Ye, W.~Wang, W.~Zhou, and S.~Y. Philip, ``More than privacy:
  Applying differential privacy in key areas of artificial intelligence,''
  \emph{IEEE Transactions on Knowledge and Data Engineering}, vol.~34, no.~6,
  pp. 2824--2843, 2020.

\bibitem{truex2019hybrid}
S.~Truex, N.~Baracaldo, A.~Anwar, T.~Steinke, H.~Ludwig, R.~Zhang, and Y.~Zhou,
  ``A hybrid approach to privacy-preserving federated learning,'' in
  \emph{Proceedings of the 12th ACM workshop on artificial intelligence and
  security}, 2019, pp. 1--11.

\bibitem{ghazi2019scalable}
B.~Ghazi, R.~Pagh, and A.~Velingker, ``Scalable and differentially private
  distributed aggregation in the shuffled model,'' \emph{arXiv preprint
  arXiv:1906.08320}, 2019.

\bibitem{osti_10294585}
\BIBentryALTinterwordspacing
S.~Awan, B.~Luo, and F.~Li, ``Contra: Defending against poisoning attacks in
  federated learning,'' \emph{European Symposium on Research in Computer
  Security}. [Online]. Available: \url{https://par.nsf.gov/biblio/10294585}
\BIBentrySTDinterwordspacing

\end{thebibliography}
