# Last Ad-lib 

@article{mothukuri2021survey,
  title={A survey on security and privacy of federated learning},
  author={Mothukuri, Viraaji and Parizi, Reza M and Pouriyeh, Seyedamin and Huang, Yan and Dehghantanha, Ali and Srivastava, Gautam},
  journal={Future Generation Computer Systems},
  volume={115},
  pages={619--640},
  year={2021},
  publisher={Elsevier}
},

@InProceedings{pmlr-v108-bagdasaryan20a,
  title = 	 {How To Backdoor Federated Learning},
  author =       {Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2938--2948},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf},
  url = 	 {https://proceedings.mlr.press/v108/bagdasaryan20a.html},
},
@INPROCEEDINGS{8835365,
  author={Wang, Bolun and Yao, Yuanshun and Shan, Shawn and Li, Huiying and Viswanath, Bimal and Zheng, Haitao and Zhao, Ben Y.},
  booktitle={2019 IEEE Symposium on Security and Privacy (SP)}, 
  title={Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks}, 
  year={2019},
  volume={},
  number={},
  pages={707-723},
  doi={10.1109/SP.2019.00031}},
@article{suri2022subject,
  title={Subject membership inference attacks in federated learning},
  author={Suri, Anshuman and Kanani, Pallika and Marathe, Virendra J and Peterson, Daniel W},
  journal={arXiv preprint arXiv:2206.03317},
  year={2022}
},
@inproceedings{zhang2019poisoning,
  title={Poisoning attack in federated learning using generative adversarial nets},
  author={Zhang, Jiale and Chen, Junjun and Wu, Di and Chen, Bing and Yu, Shui},
  booktitle={2019 18th IEEE international conference on trust, security and privacy in computing and communications/13th IEEE international conference on big data science and engineering (TrustCom/BigDataSE)},
  pages={374--380},
  year={2019},
  organization={IEEE}
},
@article{el2022differential,
  title={Differential privacy for deep and federated learning: A survey},
  author={El Ouadrhiri, Ahmed and Abdelhadi, Ahmed},
  journal={IEEE access},
  volume={10},
  pages={22359--22380},
  year={2022},
  publisher={IEEE}
},
@article{biggio2012poisoning,
  title={Poisoning attacks against support vector machines},
  author={Biggio, Battista and Nelson, Blaine and Laskov, Pavel},
  journal={arXiv preprint arXiv:1206.6389},
  year={2012}
},
@inproceedings{fang2020local,
  title={Local model poisoning attacks to $\{$Byzantine-Robust$\}$ federated learning},
  author={Fang, Minghong and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil},
  booktitle={29th USENIX security symposium (USENIX Security 20)},
  pages={1605--1622},
  year={2020}
},
@article{sun2019can,
  title={Can you really backdoor federated learning?},
  author={Sun, Ziteng and Kairouz, Peter and Suresh, Ananda Theertha and McMahan, H Brendan},
  journal={arXiv preprint arXiv:1911.07963},
  year={2019}
},
@inproceedings{liu2018fine,
  title={Fine-pruning: Defending against backdooring attacks on deep neural networks},
  author={Liu, Kang and Dolan-Gavitt, Brendan and Garg, Siddharth},
  booktitle={International symposium on research in attacks, intrusions, and defenses},
  pages={273--294},
  year={2018},
  organization={Springer}
},
@inproceedings{
Xie2020DBA:,
title={DBA: Distributed Backdoor Attacks against Federated Learning},
author={Chulin Xie and Keli Huang and Pin-Yu Chen and Bo Li},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkgyS0VFvr}
},
@inproceedings{xie2021crfl,
  title={Crfl: Certifiably robust federated learning against backdoor attacks},
  author={Xie, Chulin and Chen, Minghao and Chen, Pin-Yu and Li, Bo},
  booktitle={International Conference on Machine Learning},
  pages={11372--11382},
  year={2021},
  organization={PMLR}
},
@ARTICLE{2018arXiv180709173T,
       author = {{Truex}, Stacey and {Liu}, Ling and {Emre Gursoy}, Mehmet and {Yu}, Lei and {Wei}, Wenqi},
        title = "{Towards Demystifying Membership Inference Attacks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security},
         year = 2018,
        month = jun,
          eid = {arXiv:1807.09173},
        pages = {arXiv:1807.09173},
          doi = {10.48550/arXiv.1807.09173},
archivePrefix = {arXiv}
},
@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
},
@inproceedings{hitaj2017deep,
  title={Deep models under the GAN: information leakage from collaborative deep learning},
  author={Hitaj, Briland and Ateniese, Giuseppe and Perez-Cruz, Fernando},
  booktitle={Proceedings of the 2017 ACM SIGSAC conference on computer and communications security},
  pages={603--618},
  year={2017}
},
@inproceedings{shokri2015privacy,
  title={Privacy-preserving deep learning},
  author={Shokri, Reza and Shmatikov, Vitaly},
  booktitle={Proceedings of the 22nd ACM SIGSAC conference on computer and communications security},
  pages={1310--1321},
  year={2015}
},
@INPROCEEDINGS{8835269,
  author={Melis, Luca and Song, Congzheng and De Cristofaro, Emiliano and Shmatikov, Vitaly},
  booktitle={2019 IEEE Symposium on Security and Privacy (SP)}, 
  title={Exploiting Unintended Feature Leakage in Collaborative Learning}, 
  year={2019},
  volume={},
  number={},
  pages={691-706},
  doi={10.1109/SP.2019.00029}},
@article{xie2018differentially,
  title={Differentially private generative adversarial network},
  author={Xie, Liyang and Lin, Kaixiang and Wang, Shu and Wang, Fei and Zhou, Jiayu},
  journal={arXiv preprint arXiv:1802.06739},
  year={2018}
},
@article{augenstein2019generative,
  title={Generative models for effective ML on private, decentralized datasets},
  author={Augenstein, Sean and McMahan, H Brendan and Ramage, Daniel and Ramaswamy, Swaroop and Kairouz, Peter and Chen, Mingqing and Mathews, Rajiv and others},
  journal={arXiv preprint arXiv:1911.06679},
  year={2019}
},
@article{zhu2020more,
  title={More than privacy: Applying differential privacy in key areas of artificial intelligence},
  author={Zhu, Tianqing and Ye, Dayong and Wang, Wei and Zhou, Wanlei and Philip, S Yu},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={34},
  number={6},
  pages={2824--2843},
  year={2020},
  publisher={IEEE}
},
@inproceedings{truex2019hybrid,
  title={A hybrid approach to privacy-preserving federated learning},
  author={Truex, Stacey and Baracaldo, Nathalie and Anwar, Ali and Steinke, Thomas and Ludwig, Heiko and Zhang, Rui and Zhou, Yi},
  booktitle={Proceedings of the 12th ACM workshop on artificial intelligence and security},
  pages={1--11},
  year={2019}
},
@article{ghazi2019scalable,
  title={Scalable and differentially private distributed aggregation in the shuffled model},
  author={Ghazi, Badih and Pagh, Rasmus and Velingker, Ameya},
  journal={arXiv preprint arXiv:1906.08320},
  year={2019}
},
@article{osti_10294585,
place = {Country unknown/Code not available}, title = {CONTRA: Defending against Poisoning Attacks in Federated Learning}, url = {https://par.nsf.gov/biblio/10294585}, journal = {European Symposium on Research in Computer Security}, author = {Awan, Sana and Luo, Bo and Li, Fengjun}, },


