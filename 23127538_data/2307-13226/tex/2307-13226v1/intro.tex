
%%%%%%%%% BODY TEXT
% Figure environment removed

\section{Introduction}



Representing 3D scenes as radiance fields \cite{mildenhall2020nerf} has enabled photo-realistic rendering quality and emerged as a popular design choice in 3D vision and graphics applications.  
While many methods \cite{park2021nerfies,zhang2020nerf++,barron2021mip} (following NeRF \cite{mildenhall2020nerf}) purely use MLPs to represent neural fields, 
recent works, like TensoRF \cite{chen2022tensorf} and Instant-NGP \cite{muller2022instant}, have demonstrated the advantages of using shared global feature encoding for radiance field modeling, in terms of speed, compactness, and quality.
% recent works, like TensoRF \cite{chen2022tensorf} and Instant-NGP \cite{muller2022instant}, have demonstrated the advantages of using feature grid-based representations for high efficiency and quality.
However, these methods share and assign neural features uniformly in a scene (with tensor factors or hash tables), assuming the scene content is equally complex over the entire space, which can be inefficient (requiring high model capacity) to accurately model intricate local scene details (see Fig.\ref{fig:teaser}).


We aim to accurately and compactly model a 3D scene and reproduce the complex local details.
% We aim to effectively and compactly model the challenging high-frequency geometry and appearance details in a scene, enabling highly accurate and efficient scene reconstruction and rendering.
To this end, we propose \methodname{}, a novel neural scene representation that utilizes \emph{sparsely distributed} and \emph{compactly factorized} local tensor grids to model a volumetric radiance field for high-quality novel view synthesis. 
As shown in Fig.\ref{fig:teaser}, our approach is able to accurately model the complex scene structures that are not recovered well by previous methods. 
More importantly, our superior rendering quality is achieved with much less model capacity. 




In particular, we base our model on TensoRF \cite{chen2022tensorf}, a recent approach that leverages tensor factorization in radiance field modeling. It is fast, compact, and of high rendering quality. 
% TensoRF factorizes an entire scene into vectors with CP decomposition or vectors and matrices with vector-matrix decomposition.
TensoRF applies CP and vector-matrix (VM) decomposition techniques to factorize a field into vectors and matrices and model the entire scene as a global factorized tensor.
% In contrast to TensoRF that factorizes the entire scene as global factors, 
Instead of a single global tensor, we leverage a sparse set of multiple small local tensors distributed around the scene surface for more efficient scene modeling.
Specifically, each of our tensors represents a local radiance field inside its local bounding box and is compactly modeled with factorized triple vectors based on the CP decomposition.
% as factorized triple vectors along the XYZ spatial axes, as done in the classical CP decomposition, unlike the focus of vector-matrix decomposition in TensoRF

% Note that the global CP decomposition has also been adopted in TensoRF in a global factorization, which led to a highly compact model but was unable to achieve close rendering quality to their vector-matrix (VM) decomposition, when using a practically affordable number of tensor components.
Note that the global CP decomposition in TensoRF has led to a highly compact model but cannot achieve comparable rendering quality to their VM decomposition.
This is because a tri-vector CP component is rank-one, while a global feature grid of an entire 3D scene is often complex and of high rank, requiring a large (impractical) number of CP components for high accuracy.
% However, while a full 3D scene corresponds to a high-rank tensor, local regions in the scene are usually smooth and spatially coherent, 
% In essence, our model trades the number for 
TensoRF addresses this by introducing matrix factors in their VM decomposition, essentially increasing the rank of each tensor component.
Our model instead consists of multiple small tensor grids, exploiting local spatial commonalities in a scene. 
Compared to a global tensor, our local tensor is less complex and of much lower rank, thus effectively reducing the required number of CP components (per tensor) and enabling practical high-quality radiance field reconstruction with
 highly compact tri-vector factors.
 Our local tri-vector tensors can lead to superior rendering quality and compactness over TensoRF's VM model (see Fig.~\ref{fig:teaser}). We also observe that our local tensors are generally more robust than a global tensor against the orientation of spatial axes (which can affect the rank of a tensor and thus affects the quality; see Fig.~\ref{tb:rot}).
 


Importantly, adopting local tensors (instead of a global one)
also brings us the flexibility to allocate neural features according to the actual scene distribution, enabling more efficient scene modeling and better usage of model parameters than a global representation. 
%  allows us to avoid unnecessarily modeling the empty space in the scene by directly allocating tensors around the actual scene surface.  
To do so, we pre-acquire coarse scene geometry -- that can be easily achieved via a fast RGB$\sigma$ volume reconstruction (like DVGO \cite{sun2022direct}) or multi-view stereo (like Point-NeRF \cite{xu2022point}) -- to directly distribute local tensors around the actual scene surface, leading to a sparse scene representation that avoids unnecessarily modeling the empty scene space.
% To effectively distribute local tensors, we utilize coarse scene geometry that can be easily pre-acquired via a fast RGBA volume reconstruction as done in DVGO or multi-view stereo as done in previous point- and mesh-based methods.
% The coarse geometry allow us to distribute local tensors around the actual scene surface, leading to a sparse scene representation that avoids unnecessarily modeling the empty scene space. 
Note that while previous methods have also leveraged sparse representations (with voxels \cite{liu2020neural,yu2021plenoxels} or points \cite{xu2022point}) of radiance fields, their local features are modeled and optimized independently.  
Our model instead correlates a group of local features inside a local box and compactly express them with triple vectors, uniquely exploiting the local spatial coherence along axes and imposing local low-rank priors in the feature encoding via tensor factorization.
% uniquely considers the spatial coherence around a local region and imposes local low-rank priors in the feature encoding via tensor factorization. 
Moreover, unlike previous sparse representations that only use a single-scale feature grid or point cloud, we distribute multi-scale local tensors to effectively model the scene geometry and appearance at multiple scales in a hierarchical manner.
In particular, for an arbitrary 3D location, we aggregate the neural features from its neighboring tri-vector components at all scales and decode the volume density and view-dependent color from the aggregated features for radiance field rendering.


Our approach takes the best of previous local and global radiance field representations.
Compared with global representations like TensoRF and Instant-NGP, our model takes advantage of the sparsity of a scene more directly; compared with local representations like Plenoxels and Point-NeRF, our model makes use of the local smoothness and coherence of scene geometry and appearance. 
As shown in our experimental results on both synthetic and real datasets, our model is able to achieve state-of-the-art rendering quality on these datasets, outperforming previous methods, including TensoRF and Instant-NGP, while using significantly fewer model parameters, demonstrating the superior representational power of our model.


