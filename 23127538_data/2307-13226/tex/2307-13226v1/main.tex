\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
% Include other packages here, before hyperref.

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\DeclareMathOperator*{\argmax}{\arg\!\max}
\usepackage[table]{xcolor}
\definecolor{bestcolor}{rgb}{1.0,1.0,1.0} %{1,0.5,0.25}
\definecolor{secondcolor}{rgb}{1.0,1.0,1.0} %{1,0.85,0.3}
\definecolor{thirdcolor}{rgb}{1.0,1.0,1.0} %{1.0,0.9,0.7}
\newcommand{\bone}{\cellcolor{bestcolor}}
\newcommand{\btwo}{\cellcolor{secondcolor}}
\newcommand{\bthird}{\cellcolor{thirdcolor}}
% \definecolor{initcolor}{rgb}{.830,.550,.400} %{1,0.85,0.3}
% \definecolor{optcolor}{rgb}{.400,0.490,.820} %{1.0,0.9,0.7}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).

%\usepackage{subfigure}
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{times}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{subcaption}
% \usepackage[linesnumbered,ruled]{algorithm2e}
% \usepackage{pbox}
% \usepackage[skip=2pt]{caption}
% \usepackage{makecell}
% \usepackage[export]{adjustbox}    
% \usepackage{diagbox}             % added
\usepackage{cuted}
\usepackage{changepage}
% \usepackage{wrapfig}
\usepackage{amsthm}
% \usepackage{geometry}
\usepackage{xcolor}
% \usepackage{setspace}
% \usepackage{mathtools}
% \usepackage{enumitem}
% \usepackage{capt-of}
% \usepackage{booktabs}
% \usepackage{microtype}      % microtypography
\usepackage{enumitem}
\usepackage{tikz}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}
\usepackage{appendix}

\newcommand{\methodname}{Strivec}



\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{3306} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

% Customized command
\newcommand{\boldstart}[1]{\noindent\textbf{#1}}
\newcommand{\boldstartspace}[1]{\vspace{0.05in}\noindent\textbf{#1}}

\newcommand{\zexiang}[1]{{\color{blue}{Zexiang: #1}}}
\newcommand{\qg}[1]{{\color{red}{Qiangeng: #1}}}
\newcommand{\qk}[1]{{\color{orange}{Quankai: #1}}}
\newcommand{\hs}[1]{{\color{magenta}{Hao: #1}}}

\newcommand{\first}{\tikz\draw[yellow,fill=yellow] (0,0) circle (0.7ex);}
\newcommand{\second}{\tikz\draw[lightgray,fill=lightgray] (0,0) circle (0.7ex);}
\newcommand{\third}{\tikz\draw[brown,fill=brown] (0,0) circle (0.7ex);}

\begin{document}

%%%%%%%%% TITLE
\title{Strivec: Sparse Tri-Vector Radiance Fields}

\author{Quankai Gao$^{*1}$ \qquad Qiangeng Xu$^{*1}$ \qquad Hao Su$^{2}$ \qquad Ulrich Neumann$^{1}$ \qquad Zexiang Xu$^{3}$  \\
    \hspace{0mm}$^1$University of Southern California \hspace{18mm} 
    $^2$UC San Diego\hspace{18mm}
    $^3$Adobe Research\\
    % \hspace{0mm}Los Angeles, California \hspace{28mm} San Diego, California\\
    {\tt\small \hspace{0mm}\{quankaig,qiangenx,uneumann\}@usc.edu}\hspace{5mm}
    {\tt\small haosu@ucsd.edu}\hspace{5mm}
    {\tt\small zexu@adobe.com}\qquad
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi
\maketitle
\let\thefootnote\relax\footnotetext{$^*$Equal contribution.\\
Code and results: \href{https://github.com/Zerg-Overmind/Strivec}{https://github.com/Zerg-Overmind/Strivec}}

%%%%%%%%% ABSTRACT
\begin{abstract}
   We propose \methodname{}, a novel neural representation that models a 3D scene as a radiance field with sparsely distributed and compactly factorized local tensor feature grids.
   Our approach leverages tensor decomposition, following the recent work TensoRF~\cite{chen2022tensorf}, to model the tensor grids.  In contrast to TensoRF which uses a global tensor and focuses on their vector-matrix decomposition,  we propose to utilize a cloud of local tensors and apply the classic CANDECOMP/PARAFAC (CP) decomposition \cite{carroll1970analysis} to factorize each tensor into triple vectors that express local feature distributions along spatial axes and compactly encode a local neural field.
   We also apply multi-scale tensor grids to discover the geometry and appearance commonalities and exploit spatial coherence with the tri-vector factorization at multiple local scales.  The final radiance field properties are regressed by aggregating neural features from multiple local tensors across all scales. Our tri-vector tensors are sparsely distributed around the actual scene surface, discovered by a fast coarse reconstruction, leveraging the sparsity of a 3D scene.
   We demonstrate that our model can achieve better rendering quality while using significantly fewer parameters than previous methods, including TensoRF and Instant-NGP~\cite{muller2022instant}.
   
   
\end{abstract}

%\vspace{-25pt}
\input{intro}
\input{related}
\input{method}
\input{implementation}
\input{exp}

\section{Conclusion}
In this work, we have presented a novel approach for high-quality neural scene reconstruction and photo-realistic novel view synthesis.
We propose a novel tensor factorization-based scene representation, which leverages CP decomposition to compactly model a 3D scene as a sparse set of multi-scale tri-vector tensors that express local radiance fields.
Our representation leverages both sparsity and spatial local coherence, and leads to accurate and efficient modeling of complex scene geometry and appearance.
We demonstrate that the sparse tri-vector radiance fields can achieve superior rendering quality than previous state-of-the-art neural representations, including TensoRF and iNGP, while using significantly fewer parameters.

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\newpage
\begin{appendices}
%\title{Appendix}
    \twocolumn[{%
        \renewcommand\twocolumn[1][]{#1}%
        \begin{center}
            \centering
            \LARGE \textbf{\appendixname}
            \vspace{30pt}
        \end{center}%
    }]

%\author{First Author\\
%Institution1\\
%Institution1 address\\
%{\tt\small firstauthor@i1.org}

% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
%\and
%Second Author\\
%Institution2\\
%First line of institution2 address\\
%{\tt\small secondauthor@i2.org}
%}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

% \begin{table}[hbt]
%         \begin{adjustwidth}{0pt}{0pt}  
%         \centering
%         \setlength\tabcolsep{3.0pt}
%             \small{
%                 \begin{tabular}{l|ccc}
%                 %& \multicolumn{5}{c}{\textbf{Average over Scene 101 and Scene 241}} & \\
%                 \hline %\\[-1.05em]
%                  VM-\#Comp & PSNR~$\uparrow$ & SSIM~$\uparrow$  &  \# Param.(M)~$\downarrow$ \\ \hline
%                  Single(0.3)-48  & 33.11 & 0.964 & 86.44   \\
%                  Single(0.3)-24 & 33.16 & 0.964 & 43.33 \\
%                  Single(0.3)-12 & 32.99 & 0.962 & 21.64 \\
%                  \hline
%                 \end{tabular}
%             }
%              \captionsetup{aboveskip=3pt}
%             \captionsetup{belowskip=-5pt}
%             \caption {Ablation of our method with replacing vector bases (CP) into vector-matrix (VM) bases under a different number of components settings on Synthetic-NeRF dataset. We select the number of components 48, 24, and 12 for comparison. Meanwhile, the scale is fixed at 0.3.}
%             % \KS{Add time/iterations for IBRNet. What are the different variants of Point-NeRF discussed here?}}
%             \label{tb:VM_comp_ablation} 
%         \end{adjustwidth}
%     \end{table}


\section{Ablation Studies on Tensor Factorization Strategies}
    \begin{table}[hbt]
        \begin{adjustwidth}{0pt}{0pt}  
        \centering
        \setlength\tabcolsep{3.0pt}
            \small{
                \begin{tabular}{l|c|ccc}
                %& \multicolumn{5}{c}{\textbf{Average over Scene 101 and Scene 241}} & \\
                \hline %\\[-1.05em]
                  & \# Comp & PSNR~$\uparrow$ & SSIM~$\uparrow$  &  \# Param.(M)~$\downarrow$ \\ \hline
                 Multi(0.6, 0.3, 0.15) & 24 & \textbf{33.24} & \textbf{0.963} & \textbf{7.07} \\
                 % Ours(mlt) & 48 & 33.55 & 0.965 & 13.52 \\
                 % Ours(mlt) & 96 & 33.59 & 0.965 & 21.07 \\
                 % TriVec-Cloud (0.3) & 48 & 32.73 & 0.961 & 4.15\\
                 Single(0.3) & 96 & 33.02 & 0.963 & 9.15 \\
                 VM-Cloud (0.3) & 6 & 32.59 & 0.959 & 11.36 \\
                 VM-Cloud (0.3) & 12 & 32.99 & 0.962 & 21.64\\
                 %VM-Single(0.3)$_{24}$ & 33.16 & 0.964 & 43.32 \\
                 %VM-Single(0.3)$_{48}$ & 33.11 & 0.964 & 86.44\\
                 \hline
                \end{tabular}
            }
             \captionsetup{aboveskip=3pt}
            \captionsetup{belowskip=-1pt}
            \caption {(a) Comparisons on our method pairing with different factorization strategies, e.g., CP decomposition and vector-matrix (VM) decomposition (row 2 vs 3,4). The local tensors' edge lengths are all set as 0.3. (b) We also compare a single-scale model with a multi-scale model (row 1 vs 2). We evaluate these settings on the NeRF Synthetic dataset~\cite{mildenhall2020nerf} and evaluate them with both rendering quality and model capacity (\#Param. denotes the number of parameters).}
            % \KS{Add time/iterations for IBRNet. What are the different variants of Point-NeRF discussed here?}}
            \label{tb:doubleAblation} 
        \end{adjustwidth}
    \end{table}
Other than CP decomposition, TensoRF \cite{chen2022tensorf} also proposes vector-matrix (VM) decomposition, which factorizes a 3D tensor as the summation of vector-matrix bases. Each basis is the outer product of a matrix along a plane, e.g., the XY plane, and a vector along an orthogonal direction, e.g., the Z axis. For comparison, we also explore to replace our tri-vector representation with the vector-matrix representation for each local tensor. Tab.~\ref{tb:doubleAblation} shows that the single-scale tri-vector cloud can outperform the vector-matrix cloud representation with less model capacity. 

It is not a surprise that our tri-vector cloud representation achieves more compactness. It applies more compression by factorizing each component of a 3D tensor, with a space complexity of $O(IJK)$, into three vectors, with a space complexity of $O(I+J+K)$. On the other hand, vector-matrix cloud representation factorizes it into three vectors and three matrices, which have a space complexity of $O(IJ+JK+IK)$. Even if we reduce the number of components, the vector-matrix clouds still require more space than our tri-vector representations.

In terms of quality, since our method exploits the spatial sparsity of natural scenes, we only need to factorize each local space independently instead of the entire scene together. The more compact tri-vector representation can benefit from the appearance coherence in local space and result in better performance. In TensoRF \cite{chen2022tensorf}, since the entire space is factorized all at once, the radiance information is, in general, less coherent across locations and the CP decomposition will lead to a shortage of rank. 


\section{Ablation Studies on Multi-scale Models}
In Tab.\ref{tb:doubleAblation}, we also compare our multi-scale tri-vector radiance fields with the single-scale strategy. In our default model, we have three scales, composed of tensors with lengths 0.15, 0.3, and 0.6, respectively. Similar to the findings in iNGP~\cite{muller2022instant}, our multi-scale models provide more smoothness and lead to a better rendering quality than their single-scale counterparts. The multi-scale model with 24 components (row 1) can already outperform the single-scale model (row 2), which has more parameters.

\section{Ablation Studies on the Number of Tensor Components}

We conduct experiments on the NeRF Synthetic dataset~\cite{mildenhall2020nerf} to show the relationship between rendering performance and the number of tensor components. In Tab.\ref{tb:ablation_nerfsynth}, we compare our multi-scale models with 12, 24, 48, and 96 appearance components, respectively. In general, more tensor components will lead to better performance. We also observe that the benefit of adding more components becomes marginal when the number reaches 48. We speculate that it is harder to learn high-frequency details even though the model's capacity can hold high-rank information. Improvement in this aspect can be a promising future direction.

%We also enable using less number of components in the local tensors of smaller scales because the space covered in small local tensors is also small and may not need many components to encode. And model size can be further decreased in this way.  

\begin{table*}%[hbt]
    \begin{adjustwidth}{0pt}{0pt}  
    \centering
    % \setlength\tabcolsep{5pt}
        \small{
            \begin{tabular}{c|ccccc }
            \hline %\\[-1.05em]
             & PSNR$\uparrow$ & SSIM$\uparrow$& LPIPS$_{Vgg}$ $\downarrow$ & LPIPS$_{Alex}$ $\downarrow$ & \# Param.(M)$\downarrow$\\ \hline
            Ours-12 & 32.94 & 0.961 & 0.049 & 0.028 & \textbf{4.87}\\
            %NSVF\cite{liu2020neural} & 4096 & 150k & 0.80-4.00 & - & 31.75 & 0.953 & - & 0.047\\
            Ours-24 & 33.24 & 0.963 & 0.046 & 0.026 & 7.07\\
            % Point-NeRF$_{20k}$\cite{xu2022point} & 4096 & 20k & 27.74 & 33.0m & 30.71 & 0.967 & 0.081& 0.050\\ 
            Ours-48 & 33.55 & 0.965 & 0.044 & 0.025 & 13.52 \\
            Ours-96 & \textbf{33.59} & \textbf{0.965} & \textbf{0.043} & \textbf{0.024} & 21.01  \\ \hline
            \end{tabular}
        }
        \captionsetup{aboveskip=5pt}
        \captionsetup{belowskip=-0pt}
        \caption {Ablation study on the number of tensor components. We use the same setting as our default model but only change the number of components in each variant. These variants are evaluated on the NeRF Synthetic dataset \cite{mildenhall2020nerf}.}
        % \KS{Add time/iterations for IBRNet. What are the different variants of Point-NeRF discussed here?}}
        \label{tb:ablation_nerfsynth} 
    \end{adjustwidth}
\end{table*} 

\section{Ablation Studies on Initial Geometry}
\label{initial_geometry}
We emphasize that our superior quality stems from our novel scene representation rather than the initial geometry.
The initial geometry is simply acquired from a low-res RGBA volume reconstruction, which is coarse and only used to roughly prune empty space.

We show in Fig.~\ref{init_geo} that our approach performs robustly with various choices of these geometry structures and consistently achieves high PSNRs, even with a much worse early-stopped RGBA reconstruction.
This showcases the key to our superior quality is our Strivec model itself.\\
In particular, the self-bootstrap geometry is generated purely from our own model with 8 coarse tri-vectors without existing modules in previous work. 
Moreover, we can also further prune unoccupied tensors during training but we find this leads to similar quality (0.03db difference) and unnecessary extra (+22\%) training time. 
We instead choose to use one single initial geometry to prune empty space in implementation for its simplicity and efficiency.

% Figure environment removed



\section{Speed v.s. Performance}
\label{speed}
Though speed is not our focus, here, if we reduce the number of scales from 3 to 2 and TopK from 4 to 2 (i.e., Multi(0.6, 0.3) with TopK=2), and Strivec becomes faster than CP and close to VM, while still having competitive quality (see Ours-48(fast) in Tab.\ref{tb:speed}). The fewer ranks of our tensor and the less number of TopK to be find for each sample point along a ray lead to less computation, and thus, acceleration. To conclude, Strivec is capable to improve quality, training time and compactness all together with proper hyper-parameters.
\vspace{-6pt}
\begin{table}[hbt]
      \centering
        \setlength\tabcolsep{2pt}
            \small{
                \begin{tabular}{l|cccc}
                \hline %\\[-1.05em]
                 & Train(s)$\downarrow$ & Inference(s/it)$\downarrow$ & \#Params.(M)$\downarrow$ & PSNR$\uparrow$ \\ \hline
                TensoRF-CP & 1914 & 2.01 & 0.98 & 31.56 \\ 
                TensoRF-VM & 915 & 1.60 & 17.95 & 33.14 \\
                %Ours-48(3scales) & 864 & 1.75 & \bf{33.87}\\
                Ours-48(fast) & 959  & 1.67 & 6.20 & 33.09\\
                \hline
                \end{tabular}
            }
            \captionsetup{aboveskip = 2pt}
            \captionsetup{belowskip = -15pt}
            \caption {Comparison on NeRF Synthetic dataset~\cite{mildenhall2020nerf}. We compare the average training time (s), inference time (s/it), the number of parameters (M) and PSNR.  }
            \label{tb:speed} 
    \end{table}




% \section{A. Per-scene Breakdown Results of the
% NeRF Synthetic Dataset}
\section{Per-scene Breakdown Results of the NeRF Synthetic Dataset}
    We show the per-scene detailed quantitative results of the comparisons on the NeRF Synthetic dataset \cite{mildenhall2020nerf} in Tab. \ref{tb:dt_nerfsynth} 
    and qualitative comparisons in our video. With compact model capacity, our method outperforms state-of-the-art methods \cite{mildenhall2020nerf,muller2022instant,xu2022point,chen2022tensorf} and achieves the best PSNRs, and LPIPSs in most of the scenes. %Please note the metric hyper-parameters of SSIM in PointNeRF's original version are different than others, they have updated their SSIM. 
    We report two versions of iNGP~\cite{muller2022instant}. Specifically, iNGP-dark$_{100k}$ is reported in the original paper. According to issue~\href{https://github.com/NVlabs/instant-ngp/discussions/745}{\#745} in iNGP's official repo, the method uses a random color background in training and dark background in testing. The number of iterations, 100k, is referenced to its initial code base release. We also refer to the results reported in \cite{factorfields} as iNGP-white$_{30k}$, since the authors use a white background in both training and testing for 30k iterations, which has the same setting as ours and many other compared methods. Please refer to issue \href{https://github.com/NVlabs/instant-ngp/discussions/745}{\#745} and \href{https://github.com/NVlabs/instant-ngp/issues/1266}{\#1266} in iNGP's official repo for more details.
\begin{table}[]
      \centering
        % \setlength\tabcolsep{5pt}
            \small{
                \begin{tabular}{l|cc|c}
                \hline %\\[-1.05em]
                 & garden & room & Model Size(avg) \\ \hline
                DVGO & 24.32 & 28.35 & 5.1GB \\ 
                Ours-48 & 24.13 & 28.11 & 12.6MB\\
                \hline
                \end{tabular}
            }
            \captionsetup{aboveskip = 2pt}
            \captionsetup{belowskip = -15pt}
            \caption {Results on the Mip-NeRF 360 dataset.}
            % \KS{Add time/iterations for IBRNet. What are the %different variants of Point-NeRF discussed here?}}
            \label{tb:360_tab} 
    \end{table}
    
    \begin{table*}[]
    %   \setlength\tabcolsep{4pt}
      \captionsetup{aboveskip=5pt}
      \centering
      \begin{tabular}{lcccccccc}
            \hline
            \multicolumn{9}{c}{NeRF Synthetic}                                                                                                                 \\
                       & Chair          & Drums          & Lego           & Mic            & Materials      & Ship           & Hotdog         & Ficus          \\ \hline
            \multicolumn{9}{c}{PSNR$\uparrow$}                                                                                                                           \\ \hline

            NeRF~\cite{mildenhall2020nerf}       & 33.00          & 25.01          & 32.54          & 32.91          & 29.62          & 28.65          & 36.18          & 30.13          \\
            NSVF~\cite{liu2020neural}       & 33.19          & 25.18          & 32.54          & 34.27          & \textbf{32.68} & 27.93          & 37.14 & 31.23          \\
            
            Point-NeRF$_{20k}$~\cite{xu2022point}  & 32.50 & 25.03 & 32.40 & 32.31 &  28.11 & 28.13 & 34.53 & 32.67          \\
            Point-NeRF$_{200k}$~\cite{xu2022point} & 35.40 & 26.06 & 35.04 & 35.95 & 29.61 & 30.97 & 37.30 & 36.13 \\ 
            iNGP-dark$_{100k}$~\cite{muller2022instant} & 35.00 & 26.02 & 36.39 & 36.22 & 29.78 & 31.10 & 37.40 & 33.51 \\
            iNGP-white$_{30k}$~\cite{muller2022instant,chen2023factor} & 35.42 & 24.24 & 34.82 & 35.98 & 28.99 & 30.72 & 37.45 & 32.09 \\ 
            TensoRF-CP~\cite{chen2022tensorf}-384$_{30k}$ & 33.60 & 25.17 & 34.05 & 33.77 & 30.10 & 28.84 & 36.24 &  30.72 \\ 
            TensoRF-VM~\cite{chen2022tensorf}-192$_{30k}$ & 35.76 &  26.01 & 36.46 & 34.61 & 30.12 & 30.77 & 37.41 &  33.99 \\ 
            Ours-12$_{30k}$ & 35.21	& 25.96 & 35.60 & 35.29 & 29.54 & 30.64 & 37.03 & 34.21 \\
            Ours-24$_{30k}$ & 35.60 & 26.16 & 36.05 & 35.81 & 29.79 & 30.89 & 37.24 & 34.37 \\
            Ours-48$_{30k}$ & \textbf{35.88} & \textbf{26.20} & \textbf{36.52} & \textbf{36.65} & 29.90 & \textbf{31.13} & \textbf{37.63} & 34.47 \\ \hline
            \multicolumn{9}{c}{SSIM$\uparrow$}                                                                                                                           \\ \hline
            
            NeRF       & 0.967          & 0.925          & 0.961          & 0.980          & 0.949          & 0.856          & 0.974          & 0.964          \\
            NSVF       & 0.968          & 0.931          & 0.960          & 0.987          & \textbf{0.973}          & 0.854          & 0.980          & 0.973          \\
            
            Point-NeRF$_{20k}$  & 0.981 & 0.944 & 0.980 &  0.986 & 0.959 & 0.916 & 0.983 & 0.986          \\
            Point-NeRF$_{200k}$ & \textbf{0.991} & \textbf{0.954} & \textbf{0.988} & \textbf{0.994} & 0.971 & \textbf{0.942} &  \textbf{0.991} & \textbf{0.993} \\
            
            %Point-NeRF$_{200k}$ (calibrated) & 0.984 & 0.935 & 0.978 & 0.990 & 0.948 & 0.892 & 0.982 & \textbf{0.987} \\ 
            iNGP-white$_{30k}$ & 0.985 & 0.924 & 0.979 & 0.990 & 0.945 & 0.892 & 0.982 & 0.977 \\
          
             TensoRF-CP-384$_{30k}$ & 0.973 & 0.921 &  0.971 & 0.983 & 0.950 &  0.857 &  0.975 &  0.965  \\
             TensoRF-VM-192$_{30k}$ & 0.985 & 0.937 & 0.983 & 0.988 & 0.952 & 0.895 & 0.982 & 0.982\\
             Ours-12$_{30k}$ & 0.983 & 0.937 & 0.980 & 0.989 & 0.948 & 0.888 & 0.981 & 0.983  \\
             Ours-24$_{30k}$ & 0.984 & 0.940 & 0.982 & 0.990 & 0.952 & 0.893 & 0.982 & 0.984 \\
             %Ours-48$_{30k}$ & \textbf{0.985} & \textbf{0.940} & \textbf{0.984} & \textbf{0.992} & 0.953 & \textbf{0.899} & \textbf{0.983} & 0.985 \\\hline
             Ours-48$_{30k}$ & 0.985 & 0.940 & 0.984 & 0.992 & 0.953 & 0.899 & 0.983 & 0.985 \\\hline
             
            \multicolumn{9}{c}{LPIPS$_{Vgg}\downarrow$}                                                                                                                       \\ \hline
           
            NeRF       & 0.046          & 0.091          & 0.050          & 0.028          & 0.063          & 0.206          & 0.121          & 0.044          \\
            
            Point-NeRF$_{20k}$  & 0.051 & 0.103 & 0.054 & 0.039 & 0.102 & 0.181 & 0.074 & 0.043         \\
            Point-NeRF$_{200k}$ & 0.023 & 0.078 & 0.024 &  0.014 & 0.072 &\textbf{0.124} & 0.037 & 0.022 \\
            iNGP-white$_{30k}$ &  0.022 & 0.092 & 0.025 & 0.017 & 0.069 & 0.137 & 0.037 & 0.026\\
            
            
            TensoRF-CP-384$_{30k}$ & 0.044 & 0.114 &  0.038 & 0.035 & 0.068 & 0.196 & 0.052 & 0.058 \\
            TensoRF-VM-192$_{30k}$ & 0.022 & 0.073 & 0.018 & 0.015 & 0.058 & 0.138 & 0.032 & 0.022\\
            Ours-12$_{30k}$ & 0.025 & 0.070 & 0.022 & 0.015 & 0.062 & 0.145 & 0.033 & 0.022 \\
            Ours-24$_{30k}$ &  0.022 & 0.067 & 0.020 & 0.013 & 0.058 & 0.141 & 0.031 & 0.021 \\
            Ours-48$_{30k}$ & \textbf{0.021} & \textbf{0.064} & \textbf{0.017} & \textbf{0.011} & \textbf{0.056} & 0.138 & \textbf{0.029} & \textbf{0.018} \\ \hline
            \multicolumn{9}{c}{LPIPS$_{Alex}\downarrow$}                                                                                                                      \\ \hline
            NSVF       & 0.043          & 0.069          & 0.029          & 0.010          & \textbf{0.021} & 0.162          & 0.025          & 0.017          \\
            Point-NeRF$_{20k}$  & 0.027 & 0.057 & 0.022 & 0.024 & 0.076& 0.127 & 0.044 & 0.022         \\
            Point-NeRF$_{200k}$ & 0.010 & 0.055 & 0.011 & 0.007 & 0.041 & \textbf{0.070} & 0.016 & \textbf{0.009} \\ 

            iNGP-white$_{30k}$ & 0.022 & 0.093 & 0.025 & 0.017 & 0.069 & 0.140 & 0.037 & 0.026 \\
            
            TensoRF-CP-384$_{30k}$ & 0.022 & 0.069 & 0.014 & 0.018 & 0.031 & 0.130 &  0.024 & 0.024 \\
            TensoRF-VM-192$_{30k}$ & 0.010 & 0.051 & 0.007 & 0.009 & 0.026 & 0.085 & 0.013 & 0.012 \\
            Ours-12$_{30k}$ & 0.011	& 0.051 & 0.009 & 0.007 & 0.027 & 0.092 & 0.015 & 0.013  \\
            Ours-24$_{30k}$ & 0.010 & 0.049 & 0.008 & 0.006 & 0.024 & 0.087 & 0.014 & 0.012  \\
            Ours-48$_{30k}$ & \textbf{0.009} & \textbf{0.048} & \textbf{0.007} & \textbf{0.005} & 0.023 & 0.086 & \textbf{0.012} & 0.011 \\ \hline
        \end{tabular}      
        \caption{Detailed breakdown of quantitative metrics on individual scenes in the NeRF Synthetic \cite{mildenhall2020nerf} for our method and baselines. All scores are averaged over the testing images. The subscripts are the number of iterations of the models. NeRF only \cite{mildenhall2020nerf} reports the LPIPS$_{Vgg}$~\cite{zhang2018perceptual} while NSVF only reports LPIPS$_{Alex}$. } %PointNeRF has updated their calibrated SSIM in arxiv since the metric hyper-parameters in the original version are different than others.
        \label{tb:dt_nerfsynth}
    \end{table*}
    


% Figure environment removed


\section{The Tanks and Temples Dataset}
We show the qualitative comparison between our Strivec and TensoRF-VM~\cite{chen2022tensorf} on the Tanks and Temples dataset~\cite{Knapitsch2017} in Fig.\ref{fig:tanks_comp}. Similar to the procedures on the NeRF Synthetic dataset, we build the coarse scene geometry within 30 seconds to place our local tensors. The quantitative results are reported in Tab.\ref{tb:tt}. %Note that there are many choices (e.g., meshes or point clouds from multi-view stereo) for the geometry prior and our results are expected to be better when the scene geometry has higher quality.
    
    \begin{table*}[hbt!]
    %   \setlength\tabcolsep{6pt}
      \centering
      \captionsetup{aboveskip=5pt}
        \begin{tabular}{ccccccc}
        \hline
        \multicolumn{7}{c}{Tanks \& Tamples}                                                                                                                \\
        \multicolumn{1}{l}{} & Ignatius             & Truck                & Barn      & Caterpillar                 & Family               & Mean                 \\ \hline
        \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & PSNR~$\uparrow$      & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} \\ \hline
        NV~\cite{lombardi2019neural}                   & 26.54                & 21.71                & 20.82     & 20.71                & 28.72                & 23.70                \\
        NeRF~\cite{mildenhall2020nerf}                 & 25.43                & 25.36                & 24.05     & 23.75                & 30.29                & 25.78                \\
        NSVF~\cite{liu2020neural}                 & 27.91                & 26.92                & 27.16     & 26.44                & 33.58                & 28.40                \\
        TensoRF-CP\cite{chen2022tensorf}    & 27.86                & 26.25                & 26.74     & 24.73                & 32.39                & 27.59 \\
        TensoRF-VM\cite{chen2022tensorf}  & 28.34 & 27.14 & 27.22 & 26.19 & \textbf{33.92} & 28.56 \\
        Ours-48 & \textbf{28.39} &	\textbf{27.32}	& \textbf{28.09} &	\textbf{26.58} &	33.13	& \textbf{28.70}
        \\ \hline
        \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & SSIM~$\uparrow$      & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} &                      \\ \hline
        NV~\cite{lombardi2019neural}                   & 0.992                & 0.793                & 0.721     & 0.819                & 0.916                & 0.848                 \\
        NeRF~\cite{mildenhall2020nerf}                 & 0.920                & 0.860                & 0.750     & 0.860                & 0.932                & 0.864                 \\
        NSVF~\cite{liu2020neural}                 & 0.930                & 0.895                & 0.823     & 0.900                & 0.954                & 0.900                 \\
       TensoRF-CP\cite{chen2022tensorf}    &   0.934 & 0.885 & 0.839 &  0.879 & 0.948 & 0.897 \\
        TensoRF-VM\cite{chen2022tensorf}  &   0.948 & 0.914 &  0.864 & 0.912 & \textbf{0.965} & 0.920\\
        Ours-48 & \textbf{0.948} & \textbf{0.915} & \textbf{0.884} & \textbf{0.917} & 0.957 & \textbf{0.924} \\ \hline
        \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & LPIPS$_{Alex}\downarrow$ & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} &                      \\ \hline
        NV~\cite{lombardi2019neural}                   & 0.117                & 0.312                & 0.479     & 0.280                & 0.111                & 0.260                 \\
        NeRF~\cite{mildenhall2020nerf}                 & 0.111                & 0.192                & 0.395     & 0.196                & 0.098                & 0.198                 \\
        NSVF~\cite{liu2020neural}                 & 0.106                & 0.148                & 0.307     & 0.141                & 0.063                & 0.153                 \\
        TensoRF-CP\cite{chen2022tensorf}  & 0.089 & 0.154 & 0.237 &  0.176 & 0.063 & 0.144\\
        TensoRF-VM\cite{chen2022tensorf}  &  \textbf{0.081} & 0.129 & 0.217 &  0.139 & \textbf{0.057} & 0.125\\
        Ours-48 & 0.083 & \textbf{0.123} & \textbf{0.167} & \textbf{0.125} & 0.065 & \textbf{0.113}\\ \hline
        \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & LPIPS$_{Vgg}\downarrow$  & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} &                      \\ \hline
        TensoRF-CP\cite{chen2022tensorf}  & 0.106 & 0.202 & 0.283 & 0.227 & 0.088 & 0.181\\
        TensoRF-VM\cite{chen2022tensorf}  & \textbf{0.078} & \textbf{0.145} & 0.252 & 0.159 & \textbf{0.064} & 0.140\\
        Ours-48 & 0.083 & 0.150 & \textbf{0.216} & \textbf{0.154} & 0.078 & \textbf{0.136} \\ \hline
        \end{tabular}
        \caption{Quantity comparison on five scenes in the Tanks and Temples dataset \cite{Knapitsch2017} selected in NSVF \cite{liu2020neural}. NV, NeRF, and NSVF have not reported their  LPIPS$_{Vgg}$}
        \label{tb:tt}
    \end{table*}

\section{Mip-NeRF360 Dataset}
We evaluate our method on two scenes (one indoor scene and one outdoor scene) of Mip-NeRF360 dataset~\cite{barron2022mip}. Note that we only use the scene warping scheme the same as DVGO~\cite{sun2022direct} and Mip-NeRF360~\cite{barron2022mip} and keeping other components (i.e., positional encoding, point sampling, etc.) the same as TensoRF~\cite{chen2022tensorf}. The qualitative and quantitative results are shown in Fig.~\ref{fig:360_scene} and Tab.~\ref{tb:360_tab} , respectively. Here, we use only two scales in implementation to show our compactness and scalability.  

% Figure environment removed


% Figure environment removed

    
\end{appendices}






\end{document}