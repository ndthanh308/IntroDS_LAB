\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdar et~al.(2021)Abdar, Pourpanah, Hussain, Rezazadegan, Liu, Ghavamzadeh, Fieguth, Cao, Khosravi, Acharya, et~al.]{abdar2021review}
Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li~Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U~Rajendra Acharya, et~al.
\newblock A review of uncertainty quantification in deep learning: Techniques, applications and challenges.
\newblock \emph{Information Fusion}, 76:\penalty0 243--297, 2021.

\bibitem[Agarwal et~al.(2018)Agarwal, Beygelzimer, Dud{\'\i}k, Langford, and Wallach]{agarwal2018reductions}
Alekh Agarwal, Alina Beygelzimer, Miroslav Dud{\'\i}k, John Langford, and Hanna Wallach.
\newblock A reductions approach to fair classification.
\newblock In \emph{International Conference on Machine Learning}, pp.\  60--69. PMLR, 2018.

\bibitem[Angelopoulos et~al.(2023)Angelopoulos, Bates, et~al.]{angelopoulos2023conformal}
Anastasios~N Angelopoulos, Stephen Bates, et~al.
\newblock Conformal prediction: A gentle introduction.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning}, 16\penalty0 (4):\penalty0 494--591, 2023.

\bibitem[Asuncion \& Newman(2007)Asuncion and Newman]{asuncion2007uci}
Arthur Asuncion and David Newman.
\newblock Uci machine learning repository, 2007.

\bibitem[Awasthi et~al.(2021)Awasthi, Beutel, Kleindessner, Morgenstern, and Wang]{awasthi2021evaluating}
Pranjal Awasthi, Alex Beutel, Matth{\"a}us Kleindessner, Jamie Morgenstern, and Xuezhi Wang.
\newblock Evaluating fairness of machine learning models under uncertain and incomplete information.
\newblock In \emph{Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency}, pp.\  206--214, 2021.

\bibitem[Baldi \& Sadowski(2013)Baldi and Sadowski]{baldi2013understanding}
Pierre Baldi and Peter~J Sadowski.
\newblock Understanding dropout.
\newblock \emph{Advances in neural information processing systems}, 26, 2013.

\bibitem[Bird et~al.(2020)Bird, Dud{\'\i}k, Edgar, Horn, Lutz, Milan, Sameki, Wallach, and Walker]{bird2020fairlearn}
Sarah Bird, Miro Dud{\'\i}k, Richard Edgar, Brandon Horn, Roman Lutz, Vanessa Milan, Mehrnoosh Sameki, Hanna Wallach, and Kathleen Walker.
\newblock Fairlearn: A toolkit for assessing and improving fairness in ai.
\newblock \emph{Microsoft, Tech. Rep. MSR-TR-2020-32}, 2020.

\bibitem[Brown et~al.(2016)Brown, Knapp, Baker, and Kaufmann]{brown2016using}
David~P Brown, Caprice Knapp, Kimberly Baker, and Meggen Kaufmann.
\newblock Using bayesian imputation to assess racial and ethnic disparities in pediatric performance measures.
\newblock \emph{Health services research}, 51\penalty0 (3):\penalty0 1095--1108, 2016.

\bibitem[Chen et~al.(2022{\natexlab{a}})Chen, Liang, Xu, Xie, Hong, and Shu]{chen2022fair}
Canyu Chen, Yueqing Liang, Xiongxiao Xu, Shangyu Xie, Yuan Hong, and Kai Shu.
\newblock On fair classification with mostly private sensitive attributes.
\newblock \emph{arXiv preprint arXiv:2207.08336}, 2022{\natexlab{a}}.

\bibitem[Chen et~al.(2022{\natexlab{b}})Chen, Liang, Xu, Xie, Hong, and Shu]{chen2022fairness}
Canyu Chen, Yueqing Liang, Xiongxiao Xu, Shangyu Xie, Yuan Hong, and Kai Shu.
\newblock When fairness meets privacy: Fair classification with semi-private sensitive attributes.
\newblock In \emph{Workshop on Trustworthy and Socially Responsible Machine Learning, NeurIPS 2022}, 2022{\natexlab{b}}.

\bibitem[Chen et~al.(2019)Chen, Kallus, Mao, Svacha, and Udell]{chen2019fairness}
Jiahao Chen, Nathan Kallus, Xiaojie Mao, Geoffry Svacha, and Madeleine Udell.
\newblock Fairness under unawareness: Assessing disparity when protected class is unobserved.
\newblock In \emph{Proceedings of the conference on fairness, accountability, and transparency}, pp.\  339--348, 2019.

\bibitem[Cordier et~al.(2023)Cordier, Blot, Lacombe, Morzadec, Capitaine, and Brunel]{cordier2023flexible}
Thibault Cordier, Vincent Blot, Louis Lacombe, Thomas Morzadec, Arnaud Capitaine, and Nicolas Brunel.
\newblock Flexible and systematic uncertainty estimation with conformal prediction via the mapie library.
\newblock In \emph{Conformal and Probabilistic Prediction with Applications}, pp.\  549--581. PMLR, 2023.

\bibitem[Coston et~al.(2019)Coston, Ramamurthy, Wei, Varshney, Speakman, Mustahsan, and Chakraborty]{coston2019fair}
Amanda Coston, Karthikeyan~Natesan Ramamurthy, Dennis Wei, Kush~R Varshney, Skyler Speakman, Zairah Mustahsan, and Supriyo Chakraborty.
\newblock Fair transfer learning with missing protected attributes.
\newblock In \emph{Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society}, pp.\  91--98, 2019.

\bibitem[Diana et~al.(2022)Diana, Gill, Kearns, Kenthapadi, Roth, and Sharifi-Malvajerdi]{diana2022multiaccurate}
Emily Diana, Wesley Gill, Michael Kearns, Krishnaram Kenthapadi, Aaron Roth, and Saeed Sharifi-Malvajerdi.
\newblock Multiaccurate proxies for downstream fairness.
\newblock In \emph{2022 ACM Conference on Fairness, Accountability, and Transparency}, pp.\  1207--1239, 2022.

\bibitem[Ding et~al.(2021)Ding, Hardt, Miller, and Schmidt]{ding2021retiring}
Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt.
\newblock Retiring adult: New datasets for fair machine learning.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 6478--6490, 2021.

\bibitem[Dutta et~al.(2020)Dutta, Wei, Yueksel, Chen, Liu, and Varshney]{dutta2020there}
Sanghamitra Dutta, Dennis Wei, Hazar Yueksel, Pin-Yu Chen, Sijia Liu, and Kush Varshney.
\newblock Is there a trade-off between fairness and accuracy? a perspective using mismatched hypothesis testing.
\newblock In \emph{International Conference on Machine Learning}, pp.\  2803--2813. PMLR, 2020.

\bibitem[Dwork et~al.(2012)Dwork, Hardt, Pitassi, Reingold, and Zemel]{dwork2012fairness}
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel.
\newblock Fairness through awareness.
\newblock In \emph{Proceedings of the 3rd innovations in theoretical computer science conference}, pp.\  214--226, 2012.

\bibitem[Ferry et~al.(2023)Ferry, A{\"\i}vodji, Gambs, Huguet, and Siala]{ferry2023exploiting}
Julien Ferry, Ulrich A{\"\i}vodji, S{\'e}bastien Gambs, Marie-Jos{\'e} Huguet, and Mohamed Siala.
\newblock Exploiting fairness to enhance sensitive attributes reconstruction.
\newblock In \emph{2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)}, pp.\  18--41. IEEE, 2023.

\bibitem[Franke(2021)]{franke2021rawls}
Ulrik Franke.
\newblock Rawlsâ€™s original position and algorithmic fairness.
\newblock \emph{Philosophy \& Technology}, 34\penalty0 (4):\penalty0 1803--1817, 2021.

\bibitem[Fremont et~al.(2005)Fremont, Bierman, Wickstrom, Bird, Shah, Escarce, Horstman, and Rector]{fremont2005use}
Allen~M Fremont, Arlene Bierman, Steve~L Wickstrom, Chloe~E Bird, Mona Shah, Jos{\'e}~J Escarce, Thomas Horstman, and Thomas Rector.
\newblock Use of geocoding in managed care settings to identify quality disparities.
\newblock \emph{Health Affairs}, 24\penalty0 (2):\penalty0 516--526, 2005.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{gal2016dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty in deep learning.
\newblock In \emph{international conference on machine learning}, pp.\  1050--1059. PMLR, 2016.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{International conference on machine learning}, pp.\  1321--1330. PMLR, 2017.

\bibitem[Gupta et~al.(2020)Gupta, Podkopaev, and Ramdas]{gupta2020distribution}
Chirag Gupta, Aleksandr Podkopaev, and Aaditya Ramdas.
\newblock Distribution-free binary classification: prediction sets, confidence intervals and calibration.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 3711--3723, 2020.

\bibitem[Gupta et~al.(2018)Gupta, Cotter, Fard, and Wang]{gupta2018proxy}
Maya Gupta, Andrew Cotter, Mahdi~Milani Fard, and Serena Wang.
\newblock Proxy fairness.
\newblock \emph{arXiv preprint arXiv:1806.11212}, 2018.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Srebro]{hardt2016equality}
Moritz Hardt, Eric Price, and Nati Srebro.
\newblock Equality of opportunity in supervised learning.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Hashimoto et~al.(2018)Hashimoto, Srivastava, Namkoong, and Liang]{hashimoto2018fairness}
Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang.
\newblock Fairness without demographics in repeated loss minimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\  1929--1938. PMLR, 2018.

\bibitem[He et~al.(2023)He, Yang, Huang, and Zhao]{he2023large}
Muyang He, Shuo Yang, Tiejun Huang, and Bo~Zhao.
\newblock Large-scale dataset pruning with dynamic uncertainty.
\newblock \emph{arXiv preprint arXiv:2306.05175}, 2023.

\bibitem[Jagielski et~al.(2019)Jagielski, Kearns, Mao, Oprea, Roth, Sharifi-Malvajerdi, and Ullman]{jagielski2019differentially}
Matthew Jagielski, Michael Kearns, Jieming Mao, Alina Oprea, Aaron Roth, Saeed Sharifi-Malvajerdi, and Jonathan Ullman.
\newblock Differentially private fair learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\  3000--3008. PMLR, 2019.

\bibitem[Jeff et~al.(2016)Jeff, Surya, Lauren, and Julia]{compas}
Larson Jeff, Mattu Surya, Kirchner Lauren, and Angwin Julia.
\newblock How we analyzed the compas recidivism algorithm, 2016.

\bibitem[Jung et~al.(2022)Jung, Chun, and Moon]{jung2022learning}
Sangwon Jung, Sanghyuk Chun, and Taesup Moon.
\newblock Learning fair classifiers with partially annotated group labels.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  10348--10357, 2022.

\bibitem[Kamiran \& Calders(2012)Kamiran and Calders]{kamiran2012data}
Faisal Kamiran and Toon Calders.
\newblock Data preprocessing techniques for classification without discrimination.
\newblock \emph{Knowledge and information systems}, 33\penalty0 (1):\penalty0 1--33, 2012.

\bibitem[Kenfack et~al.(2021)Kenfack, Khan, Kazmi, Hussain, Oracevic, and Khattak]{kenfack2021impact}
Patrik~Joslin Kenfack, Adil~Mehmood Khan, SM~Ahsan Kazmi, Rasheed Hussain, Alma Oracevic, and Asad~Masood Khattak.
\newblock Impact of model ensemble on the fairness of classifiers in machine learning.
\newblock In \emph{2021 International conference on applied artificial intelligence (ICAPAI)}, pp.\  1--6. IEEE, 2021.

\bibitem[Kenfack et~al.(2023)Kenfack, Rivera, Khan, and Mazzara]{kenfacklearning}
Patrik~Joslin Kenfack, Ad{\'\i}n~Ram{\'\i}rez Rivera, Adil Khan, and Manuel Mazzara.
\newblock Learning fair representations through uniformly distributed sensitive attributes.
\newblock In \emph{First IEEE Conference on Secure and Trustworthy Machine Learning}, 2023.

\bibitem[Kilbertus et~al.(2018)Kilbertus, Gasc{\'o}n, Kusner, Veale, Gummadi, and Weller]{kilbertus2018blind}
Niki Kilbertus, Adri{\`a} Gasc{\'o}n, Matt Kusner, Michael Veale, Krishna Gummadi, and Adrian Weller.
\newblock Blind justice: Fairness with encrypted sensitive attributes.
\newblock In \emph{International Conference on Machine Learning}, pp.\  2630--2639. PMLR, 2018.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Lahoti et~al.(2020)Lahoti, Beutel, Chen, Lee, Prost, Thain, Wang, and Chi]{lahoti2020fairness}
Preethi Lahoti, Alex Beutel, Jilin Chen, Kang Lee, Flavien Prost, Nithum Thain, Xuezhi Wang, and Ed~Chi.
\newblock Fairness without demographics through adversarially reweighted learning.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 728--740, 2020.

\bibitem[Laine \& Aila(2017)Laine and Aila]{lainetemporal}
Samuli Laine and Timo Aila.
\newblock Temporal ensembling for semi-supervised learning.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Levy et~al.(2020)Levy, Carmon, Duchi, and Sidford]{levy2020large}
Daniel Levy, Yair Carmon, John~C Duchi, and Aaron Sidford.
\newblock Large-scale methods for distributionally robust optimization.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 8847--8860, 2020.

\bibitem[Liang et~al.(2023)Liang, Chen, Tian, and Shu]{liang2023fair}
Yueqing Liang, Canyu Chen, Tian Tian, and Kai Shu.
\newblock Fair classification via domain adaptation: A dual adversarial learning approach.
\newblock \emph{Frontiers in Big Data}, 5:\penalty0 129, 2023.

\bibitem[Liu et~al.(2021)Liu, Haghgoo, Chen, Raghunathan, Koh, Sagawa, Liang, and Finn]{liu2021just}
Evan~Z Liu, Behzad Haghgoo, Annie~S Chen, Aditi Raghunathan, Pang~Wei Koh, Shiori Sagawa, Percy Liang, and Chelsea Finn.
\newblock Just train twice: Improving group robustness without training group information.
\newblock In \emph{International Conference on Machine Learning}, pp.\  6781--6792. PMLR, 2021.

\bibitem[Liu et~al.(2018)Liu, Luo, Wang, and Tang]{liu2018large}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Large-scale celebfaces attributes (celeba) dataset.
\newblock \emph{Retrieved August}, 15\penalty0 (2018):\penalty0 11, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Rawls(2020)]{rawls2020theory}
John Rawls.
\newblock \emph{A theory of justice: Revised edition}.
\newblock Harvard university press, 2020.

\bibitem[Shafer \& Vovk(2008)Shafer and Vovk]{shafer2008tutorial}
Glenn Shafer and Vladimir Vovk.
\newblock A tutorial on conformal prediction.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0 (3), 2008.

\bibitem[Silva et~al.(2019)Silva, Trivedi, and Gutman]{silva2019developing}
Gabriella~C Silva, Amal~N Trivedi, and Roee Gutman.
\newblock Developing and evaluating methods to impute race/ethnicity in an incomplete dataset.
\newblock \emph{Health Services and Outcomes Research Methodology}, 19\penalty0 (2-3):\penalty0 175--195, 2019.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov]{srivastava2014dropout}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{The journal of machine learning research}, 15\penalty0 (1):\penalty0 1929--1958, 2014.

\bibitem[Tarvainen \& Valpola(2017)Tarvainen and Valpola]{tarvainen2017weight}
Antti Tarvainen and Harri Valpola.
\newblock Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Veale \& Binns(2017)Veale and Binns]{veale2017fairer}
Michael Veale and Reuben Binns.
\newblock Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data.
\newblock \emph{Big Data \& Society}, 4\penalty0 (2):\penalty0 2053951717743530, 2017.

\bibitem[Wang et~al.(2020)Wang, Guo, Narasimhan, Cotter, Gupta, and Jordan]{wang2020robust}
Serena Wang, Wenshuo Guo, Harikrishna Narasimhan, Andrew Cotter, Maya Gupta, and Michael Jordan.
\newblock Robust optimization for fairness with noisy protected groups.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 5190--5203, 2020.

\bibitem[Wightman(1998)]{wightman1998lsac}
Linda~F Wightman.
\newblock Lsac national longitudinal bar passage study. lsac research report series.
\newblock 1998.

\bibitem[Yan et~al.(2020)Yan, Kao, and Ferrara]{yan2020fair}
Shen Yan, Hsien-te Kao, and Emilio Ferrara.
\newblock Fair class balancing: Enhancing model fairness without observing sensitive attributes.
\newblock In \emph{Proceedings of the 29th ACM International Conference on Information \& Knowledge Management}, pp.\  1715--1724, 2020.

\bibitem[Yu et~al.(2019)Yu, Wang, Li, Fu, and Heng]{yu2019uncertainty}
Lequan Yu, Shujun Wang, Xiaomeng Li, Chi-Wing Fu, and Pheng-Ann Heng.
\newblock Uncertainty-aware self-ensembling model for semi-supervised 3d left atrium segmentation.
\newblock In \emph{Medical Image Computing and Computer Assisted Intervention--MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13--17, 2019, Proceedings, Part II 22}, pp.\  605--613. Springer, 2019.

\bibitem[Zemel et~al.(2013)Zemel, Wu, Swersky, Pitassi, and Dwork]{zemel2013learning}
Rich Zemel, Yu~Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork.
\newblock Learning fair representations.
\newblock In \emph{International conference on machine learning}, pp.\  325--333. PMLR, 2013.

\bibitem[Zhang et~al.(2018)Zhang, Lemoine, and Mitchell]{zhang2018mitigating}
Brian~Hu Zhang, Blake Lemoine, and Margaret Mitchell.
\newblock Mitigating unwanted biases with adversarial learning.
\newblock In \emph{Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society}, pp.\  335--340, 2018.

\bibitem[Zhang(2018)]{zhang2018assessing}
Yan Zhang.
\newblock Assessing fair lending risks using race/ethnicity proxies.
\newblock \emph{Management Science}, 64\penalty0 (1):\penalty0 178--197, 2018.

\bibitem[Zhao et~al.(2022)Zhao, Dai, Shu, and Wang]{zhao2022towards}
Tianxiang Zhao, Enyan Dai, Kai Shu, and Suhang Wang.
\newblock Towards fair classifiers without sensitive attributes: Exploring biases in related features.
\newblock In \emph{Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining}, pp.\  1433--1442, 2022.

\end{thebibliography}
