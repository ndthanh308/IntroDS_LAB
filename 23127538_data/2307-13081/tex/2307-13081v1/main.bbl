\begin{thebibliography}{}

\bibitem[Abdar et~al., 2021]{abdar2021review}
Abdar, M., Pourpanah, F., Hussain, S., Rezazadegan, D., Liu, L., Ghavamzadeh,
  M., Fieguth, P., Cao, X., Khosravi, A., Acharya, U.~R., et~al. (2021).
\newblock A review of uncertainty quantification in deep learning: Techniques,
  applications and challenges.
\newblock {\em Information Fusion}, 76:243--297.

\bibitem[Agarwal et~al., 2018]{agarwal2018reductions}
Agarwal, A., Beygelzimer, A., Dud{\'\i}k, M., Langford, J., and Wallach, H.
  (2018).
\newblock A reductions approach to fair classification.
\newblock In {\em International Conference on Machine Learning}, pages 60--69.
  PMLR.

\bibitem[Asuncion and Newman, 2007]{asuncion2007uci}
Asuncion, A. and Newman, D. (2007).
\newblock Uci machine learning repository.

\bibitem[Awasthi et~al., 2021]{awasthi2021evaluating}
Awasthi, P., Beutel, A., Kleindessner, M., Morgenstern, J., and Wang, X.
  (2021).
\newblock Evaluating fairness of machine learning models under uncertain and
  incomplete information.
\newblock In {\em Proceedings of the 2021 ACM Conference on Fairness,
  Accountability, and Transparency}, pages 206--214.

\bibitem[Baldi and Sadowski, 2013]{baldi2013understanding}
Baldi, P. and Sadowski, P.~J. (2013).
\newblock Understanding dropout.
\newblock {\em Advances in neural information processing systems}, 26.

\bibitem[Bird et~al., 2020]{bird2020fairlearn}
Bird, S., Dud{\'\i}k, M., Edgar, R., Horn, B., Lutz, R., Milan, V., Sameki, M.,
  Wallach, H., and Walker, K. (2020).
\newblock Fairlearn: A toolkit for assessing and improving fairness in ai.
\newblock {\em Microsoft, Tech. Rep. MSR-TR-2020-32}.

\bibitem[Chen et~al., 2022]{chen2022fair}
Chen, C., Liang, Y., Xu, X., Xie, S., Hong, Y., and Shu, K. (2022).
\newblock On fair classification with mostly private sensitive attributes.
\newblock {\em arXiv preprint arXiv:2207.08336}.

\bibitem[Coston et~al., 2019]{coston2019fair}
Coston, A., Ramamurthy, K.~N., Wei, D., Varshney, K.~R., Speakman, S.,
  Mustahsan, Z., and Chakraborty, S. (2019).
\newblock Fair transfer learning with missing protected attributes.
\newblock In {\em Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics,
  and Society}, pages 91--98.

\bibitem[Diana et~al., 2022]{diana2022multiaccurate}
Diana, E., Gill, W., Kearns, M., Kenthapadi, K., Roth, A., and
  Sharifi-Malvajerdi, S. (2022).
\newblock Multiaccurate proxies for downstream fairness.
\newblock In {\em 2022 ACM Conference on Fairness, Accountability, and
  Transparency}, pages 1207--1239.

\bibitem[Ding et~al., 2021]{ding2021retiring}
Ding, F., Hardt, M., Miller, J., and Schmidt, L. (2021).
\newblock Retiring adult: New datasets for fair machine learning.
\newblock {\em Advances in neural information processing systems},
  34:6478--6490.

\bibitem[Dutta et~al., 2020]{dutta2020there}
Dutta, S., Wei, D., Yueksel, H., Chen, P.-Y., Liu, S., and Varshney, K. (2020).
\newblock Is there a trade-off between fairness and accuracy? a perspective
  using mismatched hypothesis testing.
\newblock In {\em International Conference on Machine Learning}, pages
  2803--2813. PMLR.

\bibitem[Dwork et~al., 2012]{dwork2012fairness}
Dwork, C., Hardt, M., Pitassi, T., Reingold, O., and Zemel, R. (2012).
\newblock Fairness through awareness.
\newblock In {\em Proceedings of the 3rd innovations in theoretical computer
  science conference}, pages 214--226.

\bibitem[Franke, 2021]{franke2021rawls}
Franke, U. (2021).
\newblock Rawlsâ€™s original position and algorithmic fairness.
\newblock {\em Philosophy \& Technology}, 34(4):1803--1817.

\bibitem[Gal and Ghahramani, 2016]{gal2016dropout}
Gal, Y. and Ghahramani, Z. (2016).
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em international conference on machine learning}, pages
  1050--1059. PMLR.

\bibitem[Gupta et~al., 2018]{gupta2018proxy}
Gupta, M., Cotter, A., Fard, M.~M., and Wang, S. (2018).
\newblock Proxy fairness.
\newblock {\em arXiv preprint arXiv:1806.11212}.

\bibitem[Hardt et~al., 2016]{hardt2016equality}
Hardt, M., Price, E., and Srebro, N. (2016).
\newblock Equality of opportunity in supervised learning.
\newblock {\em Advances in neural information processing systems}, 29.

\bibitem[Hashimoto et~al., 2018]{hashimoto2018fairness}
Hashimoto, T., Srivastava, M., Namkoong, H., and Liang, P. (2018).
\newblock Fairness without demographics in repeated loss minimization.
\newblock In {\em International Conference on Machine Learning}, pages
  1929--1938. PMLR.

\bibitem[Jeff et~al., 2016]{compas}
Jeff, L., Surya, M., Lauren, K., and Julia, A. (2016).
\newblock How we analyzed the compas recidivism algorithm.

\bibitem[Kamiran and Calders, 2012]{kamiran2012data}
Kamiran, F. and Calders, T. (2012).
\newblock Data preprocessing techniques for classification without
  discrimination.
\newblock {\em Knowledge and information systems}, 33(1):1--33.

\bibitem[Kenfack et~al., 2021]{kenfack2021adversarial}
Kenfack, P.~J., Khan, A.~M., Hussain, R., and Kazmi, S. (2021).
\newblock Adversarial stacked auto-encoders for fair representation learning.
\newblock {\em arXiv preprint arXiv:2107.12826}.

\bibitem[Kenfack et~al., 2023]{kenfacklearning}
Kenfack, P.~J., Rivera, A.~R., Khan, A., and Mazzara, M. (2023).
\newblock Learning fair representations through uniformly distributed sensitive
  attributes.
\newblock In {\em First IEEE Conference on Secure and Trustworthy Machine
  Learning}.

\bibitem[Lahoti et~al., 2020]{lahoti2020fairness}
Lahoti, P., Beutel, A., Chen, J., Lee, K., Prost, F., Thain, N., Wang, X., and
  Chi, E. (2020).
\newblock Fairness without demographics through adversarially reweighted
  learning.
\newblock {\em Advances in neural information processing systems}, 33:728--740.

\bibitem[Laine and Aila, 2017]{lainetemporal}
Laine, S. and Aila, T. (2017).
\newblock Temporal ensembling for semi-supervised learning.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Liu et~al., 2021]{liu2021just}
Liu, E.~Z., Haghgoo, B., Chen, A.~S., Raghunathan, A., Koh, P.~W., Sagawa, S.,
  Liang, P., and Finn, C. (2021).
\newblock Just train twice: Improving group robustness without training group
  information.
\newblock In {\em International Conference on Machine Learning}, pages
  6781--6792. PMLR.

\bibitem[Paszke et~al., 2019]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al. (2019).
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock {\em Advances in neural information processing systems}, 32.

\bibitem[Rawls, 2020]{rawls2020theory}
Rawls, J. (2020).
\newblock {\em A theory of justice: Revised edition}.
\newblock Harvard university press.

\bibitem[Srivastava et~al., 2014]{srivastava2014dropout}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov,
  R. (2014).
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock {\em The journal of machine learning research}, 15(1):1929--1958.

\bibitem[Wang et~al., 2020]{wang2020robust}
Wang, S., Guo, W., Narasimhan, H., Cotter, A., Gupta, M., and Jordan, M.
  (2020).
\newblock Robust optimization for fairness with noisy protected groups.
\newblock {\em Advances in Neural Information Processing Systems},
  33:5190--5203.

\bibitem[Yu et~al., 2019]{yu2019uncertainty}
Yu, L., Wang, S., Li, X., Fu, C.-W., and Heng, P.-A. (2019).
\newblock Uncertainty-aware self-ensembling model for semi-supervised 3d left
  atrium segmentation.
\newblock In {\em Medical Image Computing and Computer Assisted
  Intervention--MICCAI 2019: 22nd International Conference, Shenzhen, China,
  October 13--17, 2019, Proceedings, Part II 22}, pages 605--613. Springer.

\bibitem[Zemel et~al., 2013]{zemel2013learning}
Zemel, R., Wu, Y., Swersky, K., Pitassi, T., and Dwork, C. (2013).
\newblock Learning fair representations.
\newblock In {\em International conference on machine learning}, pages
  325--333. PMLR.

\bibitem[Zhang et~al., 2018]{zhang2018mitigating}
Zhang, B.~H., Lemoine, B., and Mitchell, M. (2018).
\newblock Mitigating unwanted biases with adversarial learning.
\newblock In {\em Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics,
  and Society}, pages 335--340.

\end{thebibliography}
