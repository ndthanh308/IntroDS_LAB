\section{Time-Uniform Concentration Inequalities} \label{app:con_ineq}
We will make use of the elegant concentration results in \cite{howard2021time}, which analyzes the boundary of sub-Gamma processes.
\begin{definition}[Sub-Gamma process] \label{def:sub_G}
Let $(S_t)_{t=0}^\infty$ and $(V_t)_{t=0}^\infty$ be real-valued processes adapted to $(\mathcal{F}_t)_{t=1}^\infty$ with $S_0 = V_0 = 0$ and $V_t$ non-negative. 
We say that 
 $S_t$ is sub-Gamma if for $\lambda \in [0,1/c)$, there exists a supermartingale $(M_t(\lambda))_{t=0}^\infty$ w.r.t. $\calF_t$, such that $\E\, M_0 = 1$ and for all $t \geq 1$:
\[
\exp\{\lambda S_t - \frac{\lambda^2}{2(1-c\lambda)}V_t \} \leq M_t(\lambda) \qquad a.s.
\]
\end{definition}
The following is a special case of Theorem 1 in \citet{howard2021time}. We have simplified it by making a few straightforward choices for the parameters used originally by \citet{howard2021time}, which will yield an easier-to-use bound in our scenario.
\begin{proposition}[Curved Boundary of Sub-Gamma Processes]
\label{corollary:subgamma:anytime:useful}
   Let $(S_t)_{t\geq0}$ be sub-Gamma with scale parameter $c$ and variance process $(V_t)_{t\geq0}$. Define the boundary 
   \[
   \mathcal{B}_\alpha(v) := \frac{5}{2}\sqrt{\max\{v,1\}\left((\log\log ev)_+ + \log\left(\frac{2}{\alpha}\right)\right)} + 3c\left((\log\log ev)_+ + \log\left(\frac{2}{\alpha}\right)\right),
   \]
   for $v>0$, where $(x)_+ = \max(0,x)$. Then,
   \[
       \mathbb{P}(\exists t : \; S_t \geq \mathcal{B}_{\alpha}(V_t))  \leq \alpha.
   \]
\end{proposition}


\begin{proof}[Proof of \cref{corollary:subgamma:anytime:useful}]
Suppose $\xi(\cdot)$ denotes the Riemann zeta function. Theorem 1 in \citet{howard2021time} states that if $(S_t)_{t\geq 0}$ is a sub-Gamma process with variance process $(V_t)_{t\geq 0}$ then the boundary
   \[
       \mathcal{S}_\alpha(v') = k_1\sqrt{v'\left(\ellofv{v'}\right)} + c k_2\left(\ellofv{v'}\right).
   \]
   satisfies,
   \[
       \mathbb{P}(\exists t: S_t \geq \mathcal{S}_{\alpha}(\max(V_t,1))) \leq \alpha
   \]
   where
   \[
       k_1 := \frac{\eta^{1/4}+\eta^{-1/4} }{\sqrt{2}} \quad\quad \text{and} \quad \quad k_2 := (\sqrt{\eta} + 1)/2
   \]
    and $s, \eta\geq 1$. Choosing $s = 2$ and $\eta = e$, we obtain $\zeta(2) = \pi^2/6 \leq 2$. Furthermore, we have $k_1 \leq \frac{3}{2}$ and $k_2 \leq \frac{3}{2}$. Then if $v' \geq 1$ (which we will enforce by the construction $v'=\max(1,v)$), we compute 
    \begin{align*}
        \ellofv{v'} &\leq 2 (\log\log ev')_+ + \log\left(\frac{2}{\alpha}\right).
    \end{align*}
    Therefore, we can upper bound (using our bounds on $k_1, k_2$)
    \begin{align*}
        \mathcal{S}_\alpha(v') \leq \frac{5}{2}\sqrt{v'\left((\log\log ev')_+ + \log\left(\frac{2}{\alpha}\right)\right)} + 3c\left((\log\log ev')_+ + \log\left(\frac{2}{\alpha}\right)\right).
        \end{align*}
    Now, since the boundary is given by $\mathcal{S}_\alpha(\max(v,1))$ and $v'=\max(v,1) \geq 1$ we deduce that
    \begin{equation*}
        \mathcal{B}_\alpha(v) := \frac{5}{2}\sqrt{\max\{v,1\}\left((\log\log ev)_+ + \log\left(\frac{2}{\alpha}\right)\right)} + 3c\left((\log\log ev)_+ + \log\left(\frac{2}{\alpha}\right)\right).
    \end{equation*}
    is an any-time valid boundary.
\end{proof}


\begin{lemma}[Time-Uniform Two-sided Bernoulli]\label{lem:anytime_bernoulli}
Let $X_1, \dots, X_s, \dots, X_t$ be a martingale sequence of Bernoulli random variables with conditional mean $\gamma_s$. 
Then for all $\delta>0$, 
    \[
    \sP\left(\exists t:\,\, \abs{ \sum_{s=1}^t (X_s-\gamma_s) }\geq \frac{5}{2} \sqrt{ t \left( (\log \log t)_+ + \log(4/\delta)\right)} \right) \leq \delta,
    \]
\end{lemma}
\begin{proof}[Proof of \cref{lem:anytime_bernoulli}]
     By \cref{corollary:subgamma:anytime:useful}, we know that if $S_t$ is sub-Gamma with variance process $V_t$ and scale parameter $c$, then
    \[
    \sP\left(\exists t:\,\, S_t \geq \calB_\delta(V_t)\right) \leq \delta,
    \]
    where
    \[
    \calB_\delta(v) \coloneqq \frac{5}{2} \sqrt{ \max\{1, v\}\left( (\log \log e v)_+ + \log(2/\delta)\right)} + 3c \left( (\log \log e v)_+ + \log(2/\delta)\right).
    \]
By \citet{howard2020time}, we know that if $(X_t)_{t=1}^\infty$ is a Bernoulli sequence, then $S_t = \sum_{s=1}^t (X_s-\gamma_s)$ is sub-Gamma with variance process $V_t = t$ and scale parameter $c=0$ (hence, sub-Gaussian). This implies,
    \[
    \sP\left(\exists t:\,\, \sum_{s=1}^t (X_s-\gamma_s) \geq \frac{5}{2} \sqrt{ t \left( (\log \log t)_+ + \log(2/\delta)\right)} \right) \leq \delta,
    \]
    The above arguments also holds for the sequence $Z_s = -X_s$. Then taking a union bound and adjusting $\delta \leftarrow \delta/2$ concludes the proof.
\end{proof}

\begin{lemma}[Time-Uniform Bernstein]\label{lem:stitched_bound}
Let $(\xi_i)_{i=1}^\infty$ be a sequence of conditionally standard sub-gaussian variables, where each $\xi_i$ is $\calF_{i-1} = \sigma(\xi_1, \dots, \xi_{i})$ measurable. Then, for $v_i \in \sR$ and $\delta \in (0,1]$
    \[
    \sP \left(\exists t:\,\, \sum_{i=1}^t(\xi^2_i-1)v_i \geq 
    \frac{5}{2}\sqrt{ \max\left\{1, 4\norm{\vv_t}^2_2 \right\} \omega_\delta(\norm{\vv_t}_2)} + 12 \omega_\delta(\norm{\vv_t}_2) \max_{i\geq 1}v_i\right) \leq \delta
    \]
    where, $\vv_t = (v_1, \dots, v_t) \in \sR^t$ and $\omega_\delta(v) \coloneqq \left( \log\log (4ev^2)\right)_+ + \log (2/\delta)$.
\end{lemma}
\begin{proof}[Proof of \cref{lem:stitched_bound}]
    From \cref{lem:sub_gamma}, $S_t = \sum_{i=1}^t(\xi^2_i-1)v_i$ is sub-Gamma with variance process $V_t = 4 \sum_{i=1}^tv_i^2$ and $c = 4 \max_{i\geq 1}v_i$.
    By \cref{corollary:subgamma:anytime:useful}, we know that if $S_t$ is sub-Gamma with variance process $V_t$ and scale parameter $c$, then
    \[
    \sP\left(\exists t:\,\, S_t \geq \calB_\delta(V_t)\right) \leq \delta,
    \]
    where
    \[
    \calB_\delta(v) \coloneqq \frac{5}{2} \sqrt{ \max\{1, v\}\left( (\log \log e v)_+ + \log(2/\delta)\right)} + 3c \left( (\log \log e v)_+ + \log(2/\delta)\right).
    \]
\end{proof}

\begin{lemma}[Time-Uniform Azuma-Hoeffding]\label{lem:anytime_azuma}
Let $X_1,\ldots, X_n$ be a martingale difference sequence such that $\abs{X_t} \leq  B$ for all $t>1$ almost surely. Then for all $\delta>0$, 
    \[
    \sP\left(\exists t:\,\, \sum_{s=1}^t X_s \geq \frac{5B}{2} \sqrt{ t\left( (\log \log etB^2)_+ + \log(2/\delta)\right)} \right) \leq \delta,
    \]
\end{lemma}
\begin{proof}[Proof of \cref{lem:anytime_azuma}]
     By \cref{corollary:subgamma:anytime:useful}, we know that if $S_t$ is sub-Gamma with variance process $V_t$ and scale parameter $c$, then
    \[
    \sP\left(\exists t:\,\, S_t \geq \calB_\delta(V_t)\right) \leq \delta,
    \]
    where
    \[
    \calB_\delta(v) \coloneqq \frac{5}{2} \sqrt{ \max\{1, v\}\left( (\log \log e v)_+ + \log(2/\delta)\right)} + 3c \left( (\log \log e v)_+ + \log(2/\delta)\right).
    \]
By \citep{howard2020time}, we know that if $(X_t)_{t=1}^\infty$ is $B$-bounded martingale difference sequence, then $S_t = \sum_{s=1}^t X_s$ is sub-Gamma with variance process $V_t = t B^2$ and scale parameter $c=0$. This implies,
    \[
    \sP\left(\exists t:\,\, S_t \geq \frac{5B}{2} \sqrt{ t\left( (\log \log etB^2)_+ + \log(2/\delta)\right)} \right) \leq \delta,
    \]
    concluding the proof.
\end{proof}


% \subsection{Classic One-time Bounds}
% The concentration inequalities below are only used for the horizon-dependnet analysis, and are not used toward proving guarantees for \alexp.

% \begin{lemma}[Bernoulli Chernoff] \label{lem:chernoff}
%     Let $X_1, \dots, X_n$ be a sequence of independent Bernoulli random variables with mean $\mu_t$. Define $\mu \coloneqq \sum_{t=1}^n\mu_t$.  Then, for any $0 < \delta \leq 1$
%     \begin{align*}
%         \sP \left( \sum_{t=1}^nX_t \geq (1+\delta)\mu \right) \leq \exp\left(\frac{-\mu\delta^2}{3} \right)
%     \end{align*}
%     and 
%         \begin{align*}
%         \sP \left( \sum_{t=1}^nX_t \leq (1-\delta)\mu \right) \leq \exp\left(\frac{-\mu\delta^2}{2} \right)
%     \end{align*}
% \end{lemma}
% \begin{proof}
% This is just an application of the Chernoff bound to Bernoulli variables.
%    Consider the moment generating function for $X = \sum_{t=1}^n X_t$. 
%     \begin{align*}
%         \E\, e^{tX} = \E \prod_{i=1}^n e^{tX_i} = \prod_{i=1}^n \E e^{tX_i} = \left( 1 + \gamma(e^t-1)\right)^n \leq \exp \left(\mu (e^t -1 )\right)
%     \end{align*}
%     Setting $t = \ln(1+ \delta)$, and by the Markov inequality,
%     \begin{align*}
%         \sP \left( X \geq (1+\delta)\mu \right) = \sP \left( e^{tX} \geq e^{(1+\delta)\mu} \right)
%          \leq \frac{ \E\, e^{tX}}{e^{(1+\delta)\mu}} & \leq \frac{\exp \left(\mu (e^t -1 )\right)}{e^{(1+\delta)\mu}}\\
%         & = \left( \frac{e^\delta}{(1+\delta)^{1+\delta}}\right)^{\mu} 
%     \end{align*}
% For $0 < \delta \leq 1$, it holds that
% $
% (1+ \delta/2) \ln (1+\delta) \geq \delta
% $. Therefore,  since $\delta \geq 1$,
% \[
% \left( \frac{e^\delta}{(1+\delta)^{1+\delta}}\right)^{\mu} \leq e^{-\mu\frac{\delta^2}{2+ \delta}} \leq e^{-\mu\frac{\delta^2}{3}}.
% \]
% The lower-bound is proven similarly, by first showing that the probability is less than $\frac{e^{-\delta}}{(1-\delta)^{1-\delta}}$ and then bounding this by $e^{-\mu\delta^2/2}$.
% \end{proof}

% \begin{lemma}[Vanilla Azuma, Lemma A.7 in \citet{cesa2006prediction}] \label{lem:vanilla_azuma}
%   Let $X_1,\ldots, X_n$ be a martingale difference sequence such that $\abs{X_t} \leq  B$ for all $t>1$ almost surely. Then for all $\delta>0$, and $n \geq 1$,
%   \[
%   \sP\left( \sum_{t=1}^nX_t \geq B\sqrt{2n\log 1/\delta}\right) \leq \delta
%   \]
% \end{lemma}

% % \begin{lemma}[Bernstein-Type Inequality \citep{lattimore2020bandit}]\label{lem:bernstein}
% % Let $X_1,\ldots, X_n$ be a sequence of random variables adapted to the filtration $\sF = (\calF_t)_t$, and let $\E_t[\cdot] = \E[\cdot \vert \calF_t]$ and $\mu_t = \E_t[X_t]$. For $\eta >0$, if $\eta X_t \leq 1$ almost surely, then
% % \[
% % \sP\left( \sum_{t=1}^n (X_t - \mu_t) \leq \eta \sum_{t=1}^n \E_{t-1}X_t^2 + \frac{1}{\eta}\log(1/\delta)\right) \geq 1-\delta
% % \]
% % Moreover, if $\eta (X_t-\mu_t) \leq 1$, same inequality holds, with the first term on the right hand side changed to $(X_t-\mu_t)^2$.
% % \end{lemma}


% % \begin{lemma}[Hanson-Wright Inequality (Theorem 6.3.2 of \citet{vershynin2018high})]
% % \label{thm:concentration}
% %     Let $\epsilon_1, \dots, \epsilon_t$ be independent, zero mean, unit variance random variables and assume for all $i \leq t$ that $\epsilon_i$ be $\sigma_i$ sub-Gaussian. Define $\boldsymbol \epsilon_t = (\epsilon_1, \dots, \epsilon_t)$ and $\sigma \coloneqq \max_{i \leq t} \sigma_i$. Let $A \in \sR^{m \times n}$ and $t \geq 0$. Then
% %     \begin{align*}
% %         \mathbb{P}\left( \Big \vert \norm{A\epsilon}_2 - \norm{A}_F \Big \vert \geq t \right) \leq \exp\left( -\frac{t^2}{2\norm{A}^2_2} \right).
% %     \end{align*}
% % \end{lemma}