\section{Proof of Regret Bound} \label{app:regret_bounds}

\begin{theorem}[Anytime Regret, Formal] \label{thm:main_regret_rigorous}
  Let $\delta \in (0, 1]$ and $\pi$ be the maximizer of \eqref{eq:cmin_def}. Assume the oracle agent employs a UCB or a Greedy policy, as laid out in \cref{sec:main_result}.
Suppose $\eta_t = \calO(\cmin t^{-1/2}C(M,\delta,d))$ and $\gamma_t = \calO(t^{-1/4})$ and
$\lambda_t  = \calO(C(M, \delta, d) t^{-1/2})$,
     then exists absolute constants $C_1, \dots, C_6$ for which \algo attains the regret 
\begin{align*}
R(n) & \leq   C_1Bn^{3/4}  + C_2 \sqrt{n} \cmin^{-1} C(M, \delta, d)\log M \\
                         & +C_3 B^2\cmin\sqrt{n} + C_4 B\sqrt{ n\left( (\log \log nB^2)_+ + \log(1/\delta)\right)}\\
                         % & +  \left(1+\cmin^{-1}n^{-3/8}\sqrt{\log(Md/\delta) + (\log\log t)_+} \right) \\
                         & + C_5 \left(1+\cmin^{-1}n^{-3/8}\sqrt{\log(Md/\delta) + (\log\log n)_+} \right)\\
                         & \quad \times \left[ Bn^{1/4} + (n^{3/4} + \frac{\log n}{\cmin})C(M, \delta, d)+ \frac{
                         n^{5/8}}{\sqrt{\cmin}}\sqrt{d\log n + \log(1/\delta) + B^2}\right] 
\end{align*}
with probability greater than $1-\delta$, simultaneously for all $n \geq 1$. Here,
       \[
C(M, \delta, d) = C_6 \sigma \sqrt{ 1 + \sqrt{d \left(\log(M/\delta) + (\log\log d)_+ \right)} + \left( \log(M/\delta) + (\log\log d)_+ \right)}.
\]  
\end{theorem}
Our main regret bound is an immediate corollary of \cref{thm:virtual_regret_rigorous} and \cref{thm:anytime_regret_MS_formal}, considering the regret decomposition of \eqref{eq:reg_decompose}. 

\begin{lemma}[Virtual Regret of the Oracle]\label{thm:virtual_regret_rigorous} Let $\delta \in (0, 1]$ and $\tilde \lambda >0$. Assume the oracle agent employs a UCB or a Greedy policy, as laid out in \cref{sec:main_result}. If $\gamma_t = \calO(t^{1/4})$, there exists an absolute constant $C_1$ for which with probability greater than $1-\delta$, simultaneously for all $n \geq 1$,
\begin{align*}
% \resizebox{.99\hsize}{!}{$
\tilde R_{j^\star}(n) = \tfrac{C_1n^{5/8}}{\sqrt{\cmin}}&\left( 1+ n^{-3/8}\cmin^{-1} \sqrt{\log(Md/\delta) + (\log\log n)_+}\right)\\
& \quad\times \sqrt{\sigma^2d\log\left(\tfrac{n}{\tilde\lambda d}+1\right) + 2\sigma^2\log(1/\delta) + \tilde\lambda B^2}
% $}
\end{align*}
\end{lemma}

\begin{lemma}[Any-Time Model-Selection Regret, Formal]\label{thm:anytime_regret_MS_formal} Let $\delta \in (0, 1]$  and $\pi$ be the maximizer of \eqref{eq:cmin_def}.
Suppose $\eta_t = \calO(\cmin/\sqrt{t}C(M,\delta,d))$ and $\gamma_t = \calO(t^{-1/4})$ and
$\lambda_t  = \calO(C(M, \delta, d)/\sqrt{t})$,
     then exists absolute constants $C_i$ for which \algo attains the model selection regret 
\begin{align*}
R(n,j) & \leq   C_1Bn^{3/4}  + C_2 \sqrt{n} \cmin^{-1} C(M, \delta, d)\log M \\
                         & +C_3 B^2\cmin\sqrt{n} + C_4 B\sqrt{ n\left( (\log \log nB^2)_+ + \log(1/\delta)\right)}\\
                         % & +  \left(1+\cmin^{-1}n^{-3/8}\sqrt{\log(Md/\delta) + (\log\log t)_+} \right) \\
                         & + C_5\left( Bn^{1/4} + (n^{3/4} + \frac{\log n}{\cmin})C(M, \delta, d)  \right) \left(1+\cmin^{-1}n^{-3/8}\sqrt{\log(Md/\delta) + (\log\log n)_+} \right)
\end{align*}
with probability greater than $1-\delta$, simultaneously for all $n \geq 1$. Here,
       \[
C(M, \delta, d) = C_6 \sigma \sqrt{ 1 + \sqrt{d \left(\log(M/\delta) + (\log\log d)_+ \right)} + \left( \log(M/\delta) + (\log\log d)_+ \right)}.
\]
\end{lemma}
%=======================================================================
%=======================================================================
%=======================================================================
%=======================================================================

\subsection{Proof of Model Selection Regret}

Our technique for bounding the model selection regret relies on a classic horizon-independent analysis of the exponential weights algorithm, presented in \cref{lem:exp3_vanilla}.
\begin{lemma} [Anytime Exponential Weights Guarantee]\label{lem:exp3_vanilla}
    Assume $\eta_t \hat r_{t,j} \leq 1$ for all $1\leq j\leq M$ and $t \geq 1$. If the sequence $(\eta_t)_{t\geq 1}$ is non-increasing, then for all $n\geq 1$,
    \[
    \sum_{t=1}^n  \hat r_{t,k} - \sum_{t=1}^n \sum_{j=1}^M  q_{t,j}\hat r_{t,j} \leq \frac{\log M}{\eta_n} +  \sum_{t=1}^n\eta_t\sum_{j=1}^M  q_{t,j} \hat r^2_{t,j}
    \]
    for any arm $k \in [M]$.
\end{lemma}

\begin{proof}[Proof of \cref{lem:exp3_vanilla}] 
Define $\hat R_{t,i} \coloneqq \sum_{s=1}^t \hat r_{s,i}$ to be the expected cumulative reward of agent $i$ after $t$ steps. We rewrite for a fixed $k$
\begin{equation}
    \sum_{t=1}^n  \hat r_{t,k} - \sum_{t=1}^n \sum_{j=1}^M  q_{t,j}\hat r_{t,j} = \sum_{t=1}^n \hat r_{t,k} - \sum_{t=1}^n \E_{j \sim  q_t}[\hat r_{t,j}] \label{eq:vanilla:premise}.
\end{equation}
We focus on a single term in the second sum. For any $t$, we have
\begin{align}
    -\E_{j \sim  q_t}[\hat r_{t,j}] = \log(\exp(-\E_{j \sim  q_t}[\frac{\eta_t}{\eta_t}\hat r_{t,j}])) & = \log(\exp(-\E_{j \sim  q_t}[\eta_t\hat r_{t,j}])^{1/\eta_t}) \nonumber \\
    &= \frac{1}{\eta_t}\log(\exp(-\E_{j \sim  q_t}[\eta_t\hat r_{t,j}])) \nonumber \\
  &= \frac{1}{\eta_t}\log(\E_{i\sim  q_t}\exp(-\E_{j \sim  q_t}[\eta_t\hat r_{t,j}])) \label{eq:transformation:1}
\end{align}
The inner expectation is over $j$, while the outer one is over $i$ and therefore has no effect.  Moreover,
\begin{align}
\frac{1}{\eta_t}\log\E_{i\sim  q_t}\exp(-\eta_t \E_{j \sim  q_t}[\hat r_{t,j}] + \eta_t \hat r_{t,i})
&= \frac{1}{\eta_t}\log \left( \exp(-\eta_t  \E_{j \sim  q_t}[\hat r_{t,j}]) \E_{i\sim  q_t} \exp(\eta_t \hat r_{t,i})\right) \nonumber \\
&= \frac{1}{\eta_t}\log\E_{i\sim  q_t}\exp(-\eta_t  \E_{j \sim  q_t}[\hat r_{t,j}])\nonumber\\
& \quad\quad + \frac{1}{\eta_t}\log\E_{i\sim  q_t}\exp(\eta_t \hat r_{t,i}) \label{eq:transformation:2}
\end{align}
where again, the expectation can be reintroduced to get the last line. Combining \eqref{eq:transformation:1} and \eqref{eq:transformation:2},
\begin{align}
-\E_{j \sim  q_t}[\hat r_{t,j}] = \frac{1}{\eta_t}\log\E_{i\sim  q_t}\exp(-\eta_t \E_{j \sim  q_t}[\hat r_{t,j}] + \eta_t \hat r_{t,i}) - \frac{1}{\eta_t}\log\E_{i\sim  q_t}\exp(\eta_t \hat r_{t,i}) \label{eq:vanilla:twotermstobound}
\end{align}
This transformation is at the core of many exponential weight proofs \citep{bubeck2012regret, lattimore2020bandit}. We first bound the first term in \eqref{eq:vanilla:twotermstobound}:
\newcommand{\Ei}{\E_{i \sim  q_t}}
\newcommand{\Ek}{{\E_{j\sim  q_t}}}
\begin{align}
    \log\Ei\exp(-\eta_t \Ek[\hat r_{t,j}] + \eta_t \hat r_{t,i}) &= \log\Ei\exp(\eta_t \hat r_{t,i}) - \eta_t \Ek \hat r_{t, j} \nonumber \\
    \stackrel{\text{(I)}}{\leq}& \Ei\exp(\eta_t \hat r_{t,i}) - 1 - \eta_t \Ek \hat r_{t, j} \nonumber \\
    &= \Ei\left[ \exp(\eta_t \hat r_{t,i}) - 1 - \eta_t \hat r_{t,i} \right] \nonumber \\
    &\stackrel{\text{(II)}}{\leq} \Ei\left[ \eta_t^2 \hat r_{t,i}^2 \right] \label{eq:vanilla:variancebound}
\end{align}
where in (I) we use the fact that $\log(z) \leq z - 1$ and in (II) we use the fact that for $x\leq 1$, we have $\exp(x) \leq 1 + x + x^2$, and hence $\exp(x) - 1 - x \leq x^2$. For the second term in \eqref{eq:vanilla:twotermstobound}, we will mirror the potential argument in \cite{bubeck2012regret}, but with a slightly different potential function. We expand the definition of $ q_t$:
\begin{align}
    -\frac{1}{\eta_t}\log\E_{i\sim  q_t}\exp(\eta_t \hat r_{t,i})
    &= -\frac{1}{\eta_t} \log \frac{\sum_{i=1}^M \exp(\eta_t \hat R_{t, i})}{\sum_{i=1}^M \exp(\eta_t \hat R_{t-1, i})} \nonumber \\
    &= -\frac{1}{\eta_t}\log \frac{1}{M}\sum_{i=1}^M \exp(\eta_t \hat R_{t, i}) + \frac{1}{\eta_t}\log \frac{1}{M}\sum_{i=1}^M \exp(\eta_t \hat R_{t-1, i})  \nonumber \\
    &= J_{t}(\eta_t) - J_{t-1}(\eta_t), \label{eq:vanilla:potentialsubpart}
\end{align}
where we define $J_t(\eta) = -\frac{1}{\eta}\log\frac{1}{M}\sum_{i=1}^M \exp(\eta \hat R_{t, i})$. We also define $F_t(\eta) = \frac{1}{\eta}\log\frac{1}{M}\sum_{i=1}^M \exp(-\eta \hat R_{t, i})$. We observe the relation $J(\eta) = F(-\eta)$. From this, it follows that for any $\eta$, we have $J'(\eta) = -F'(-\eta) \leq 0$, by the argument in \citet[][ Theorem 3.1]{bubeck2012regret} that shows $F'(\eta) \geq 0$ for any $\eta$.

\textbf{Putting together the pieces} Now, we can bound \eqref{eq:vanilla:twotermstobound} by inputing \eqref{eq:vanilla:variancebound} and \eqref{eq:vanilla:potentialsubpart}:
\begin{equation*}
    -\E_{j \sim  q_t}[\hat r_{t,j}] \leq \Ei\left[ \eta_t \hat r_{t,i}^2 \right] + J_{t}(\eta_t) - J_{t-1}(\eta_t) 
\end{equation*}
With this, we rewrite \eqref{eq:vanilla:premise} as
\begin{equation}
    \sum_{t=1}^n \hat r_{t,k} - \sum_{t=1}^n \E_{j \sim  q_t}[\hat r_{t,j}] = \sum_{t=1}^n \hat r_{t,k} + \sum_{t=1}^n \Ei\left[ \eta_t \hat r_{t,i}^2 \right] + \sum_{t=1}^n J_{t}(\eta_t) - J_{t-1}(\eta_t) \label{eq:vanilla:almostdone}
\end{equation}
\textbf{Potential manipulation} We can do an Abel transformation on the sum of potentials in \eqref{eq:vanilla:almostdone}, namely obtaining
\begin{equation*}
    \sum_{t=1}^n J_{t}(\eta_t) - J_{t-1}(\eta_t) = \sum_{t=1}^{n-1} (J_{t}(\eta_t) - J_{t}(\eta_{t+1})) + J_n(\eta_n),
\end{equation*}
where we used that $J_0(\eta) = 0$.
We know $J'(\eta) \leq 0$ and so $J$ is decreasing and since $\eta_{t+1} \leq \eta_{t}$, we have $J(\eta_{t+1}) \geq J(\eta_{t})$
or $(J_{t}(\eta_t) - J_{t}(\eta_{t+1})) \leq 0$, so that for any fixed $k$ 
\begin{align}
    \sum_{t=1}^n J_{t}(\eta_t) - J_{t-1}(\eta_t) &\leq J_n(\eta_n) \leq \frac{\log(M)}{\eta_n} - \frac{1}{\eta_n}\log\left(\sum_{i=1}^M \exp(\eta_n \hat R_{n,i})\right) \nonumber \\
    &\stackrel{(*)}\leq \frac{\log(M)}{\eta_n} - \frac{1}{\eta_n}\log\left( \exp(\eta_n \hat R_{n, k})\right) \nonumber \\
    &=  \frac{\log(M)}{\eta_n} - \sum_{t=1}^n \hat r_{t,k} \label{eq:vanilla:finalpuzzlepiece}
\end{align}
where $(*)$ follows because $\exp$ is positive and $-\log$ is decreasing (notice that we drop $M-1$ terms from the sum). Plugging \eqref{eq:vanilla:finalpuzzlepiece} into \eqref{eq:vanilla:almostdone}, we obtain
\begin{align*}
    \sum_{t=1}^n \hat r_{t,k} - \sum_{t=1}^n \E_{j \sim  q_t}[\hat r_{t,j}] &\leq \sum_{t=1}^n \hat r_{t,k} + \sum_{t=1}^n \Ei\left[ \eta_t \hat r_{t,i}^2 \right] + \sum_{t=1}^n J_{t}(\eta_t) - J_{t-1}(\eta_t) \\
    &\leq \sum_{t=1}^n \hat r_{t,k} + \sum_{t=1}^n \Ei\left[ \eta_t \hat r_{t,i}^2 \right] + \frac{\log(M)}{\eta_n} - \sum_{t=1}^n \hat r_{t,k} \\
    &\leq \sum_{t=1}^n \Ei\left[ \eta_t \hat r_{t,i}^2 \right] + \frac{\log(M)}{\eta_n} \\
    &= \sum_{t=1}^n \eta_t  \sum_{j=1}^M  q_{t,j} \hat r_{t,j}^2 + \frac{\log(M)}{\eta_n}.
\end{align*}
\end{proof}
%=======================================================================
%=======================================================================
%=======================================================================
%=======================================================================
We expressed in \cref{sec:properties}, that the model selection regret of \alexp, is closely tied to the bias and variance of the reward estimates $\hat r_{t,j}$. The following lemma formalizes this claim.
%=======================================================================
%=======================================================================
\begin{lemma}(Anytime Generic regret bound)\label{lem:anytime_mother_exp4}
    If $\eta_t$ is picked such that $\eta_t \hat r_{t,j} \leq 1$ for all $1\leq j\leq M$ and $1\leq t$ almost surely, then \cref{alg:lassoexp} satisfies with probability greater than $1-2\delta/3$, that simultaneously for all $n\geq 1$
\begin{align*}
R(n,i) \leq  2B\sum_{t=1}^n\gamma_t  &+\frac{\log M}{\eta_n} + \sum_{t=1}^n  \eta_t\sum_{j=1}^M  q_{t,j} \hat r^2_{t,j}  + \sum_{t=1}^n (\omega_{t,i} + \sum_{j=1}^M  q_{t,j} \omega_{t,j}) \\
& + 10B\sqrt{ n\left( (\log \log nB^2)_+ + \log(12/\delta)\right)}
\end{align*}
where $\omega_{t,i} = \abs{r_{t,i} - \hat r_{t,i}}$.
\end{lemma}
\begin{proof}[Proof of \cref{lem:anytime_mother_exp4}]
 Let $\alpha_t$ denote the Bernoulli random variable that is equal to 1 if at step $t$ we select actions according to $\pi$ and 0 otherwise.   
    At each step $t$ with $\alpha_t= 1$ \alexp accumulates a regret of at most $2B$, since $\norm{\vtheta}_\infty \leq B$ and $\norm{\vphi(\cdot)} \leq 1$. We can decompose the regret as,
    \begin{align*}
    R(n,i)& \leq \sum_{t=1}^n  2B \alpha_t + (r_{t,i} - r_t )(1-\alpha_t)  
    \end{align*}
 For the first term, by \cref{lem:anytime_bernoulli}, we have
 \[
 2B \sum_{t=1}^n \alpha_t \leq 2B \left( \sum_{t=1}^n\gamma_t + \frac{5}{2} \sqrt{ n \left( (\log \log n)_+ + \log(4/\delta_1)\right)}\right).
 \]
simultaneously for all $n \geq 1$, with probability $1-\delta_1$.
 Let
$
\hat r_t \coloneqq \sum_{j=1}^M  q_{t,j} \hat r_{t,j}
$. We may re-write the second term of the regret as follows,
\begin{align*}
\sum_{t=1}^n (1-\alpha_t) \Big( r_{t,i} - r_t \Big) & \leq \sum_{t=1}^n (1-\alpha_t) \Big[ (r_{t,i}  - \hat r_{t,i}) + (\hat r_{t,i} - \hat r_t) + (\hat r_t - r_t) \Big]    \\
& \leq \sum_{t=1}^n \omega_{t,i} + (1-\alpha_t) \Big[ (\hat r_{t,i} - \hat r_t) + (\hat r_t - r_t) \Big] 
\end{align*}
We bound the second term on the right hand side, using \cref{lem:exp3_vanilla}
\begin{align*}
  \sum_{t=1}^n (1-\alpha_t) (\hat r_{t,i} - \hat r_t)  & \leq  \sum_{t=1}^n (\hat r_{t,i} - \hat r_t) \leq \frac{\log M}{\eta_n} +  \sum_{t=1}^n \eta_t\sum_{j=1}^M  q_{t,j} \hat r^2_{t,j}.
\end{align*}
As for the third term,
    \begin{align*}
        (1-\alpha_t)(  \sum_{j=1}^M  q_{t,j} \hat r_{t,j} - r_t) & = (1-\alpha_t)\Big[ \sum_{j=1}^M  q_{t,j} (\hat r_{t,j} - r_{t,j} + r_{t,j}) - r_t\Big]\\
        &  \leq \sum_{j=1}^M  q_{t,j}\omega_{t,j} +  (1-\alpha_t) \left(r_t-\sum_{j=1}^M  q_{t,j}r_{t,j}\right).
    \end{align*}
It remains to bound the deviation term. 
For all $t$ that satisfy $\alpha_t=0$, the action/model is selected according to $ q_{t,j}$, therefore the conditional expectation of $r_t$ can be written as
    \[
     \E_{t-1} \, r_t = \sum_{j-1}^M  q_{t,j} r_{t,j}
    \]
The sequence $X_t \coloneqq r_t -  \E_{t-1} \, r_t  $ is a martingale difference sequence adapted to the history $H_{t}$, since for every $t\geq 1$,
\[
\E_{t-1} \, X_t = \E \left[ r_t -  \E_{t-1} \, r_t  \vert H_{t-1}\right] = 0.
\]
Since $r_t \leq B$, then $X_t \leq 2B$ almost surely, which allows for an application of anytime Azuma-Hoeffding (\cref{lem:anytime_azuma}):
  \[
  \sP \left( \exists n:\,\, \sum_{t=1}^n \left( r_t - \sum_{j=1}^M  q_{t,j} r_{t,j}\right)\geq \frac{5B}{2} \sqrt{ n\left( (\log \log nB^2)_+ + \log(2/\delta_2)\right)} \right) \leq \delta_2
  \]
  which, in turn, leads us to
  \begin{align*}
       \sum_{t=1}^n (1-\alpha_t)\left( r_t - \sum_{j=1}^M  q_{t,j} r_{t,j}\right) 
       & \stackrel{\text{a.s.}}{\leq} \sum_{t=1}^n \left( r_t - \sum_{j=1}^M  q_{t,j} r_{t,j}\right) \\
       & \stackrel{\text{w.h.p.}}{\leq} \frac{5B}{2} \sqrt{ n\left( (\log \log nB^2)_+ + \log(2/\delta_2)\right)}
  \end{align*}
  simultaneously for all $n\geq 1$.
    We set $\delta_1 = \delta_2 = \delta/3$, take a union bound and put the terms together obtaining,
    \begin{align*}
R(n,i) \leq  2B\sum_{t=1}^n\gamma_t  &+\frac{\log M}{\eta_n} + \eta \sum_{t=1}^n\sum_{j=1}^M  q_{t,j} \hat r^2_{t,j}  + \sum_{t=1}^n (\omega_{t,i} + \sum_{j=1}^M  q_{t,j} \omega_{t,j}) \\
& + \frac{5B}{2}\sqrt{ n\left( (\log \log nB^2)_+ + \log(6/\delta)\right)} + 5B\sqrt{ n \left( (\log \log n)_+ + \log(12/\delta)\right)}
\end{align*}
We upper bound the sum of last two terms to conclude the proof.
\end{proof}
%=======================================================================
%=======================================================================
The next two lemmas bound the bias and variance terms which appear in \cref{lem:anytime_mother_exp4}.
%=======================================================================
%=======================================================================
\begin{lemma} [Anytime Bound on the Bias Term]\label{lem:anytime_CI_main}
    If the regularization parameter of Lasso is chosen at every step as
    \[
\lambda_t = \frac{2\sigma}{\sqrt{t}}\sqrt{ 1 + \frac{5}{\sqrt{2}}\sqrt{d \left(\log(2M/\delta) + (\log\log d)_+ \right)} + \frac{12}{\sqrt{2}}\left( \log(2M/\delta) + (\log\log d)_+ \right)}
\]
    and $\gamma_t = O(t^{-1/4})$, then with probability greater than $1-\delta$, simultaneously for all $n\geq 1$,
   \[
   \sum_{t=1}^n \abs{\hat r_{t,i} - r_{t,i}} \leq n^{3/4}\cmin^{-1}C(M, \delta, d)
   \left(1+n^{-3/8}\cmin^{-1} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right)
   \]
   where
\[
C(M, \delta, d)\coloneqq C\sigma\sqrt{ 1 + \sqrt{d \left(\log(M/\delta) + (\log\log d)_+ \right)} + \left( \log(M/\delta) + (\log\log d)_+ \right)}
\]
and $C$ is an absolute constant.
\end{lemma}
\begin{proof}[Proof of \cref{lem:anytime_CI_main}] By the definition of the expected reward and its estimate,
    \begin{align*}
        \sum_{t=1}^n \abs{\hat r_{t,i} - r_{t,i}} & =  \sum_{t=1}^n \abs{\int_\calX (r(\vx) - \hat r_t(\vx)) \mathrm{d}p_{t+1,i}(\vx)} \\
        &  \leq \sum_{t=1}^n \int_\calX \abs{ r(\vx) - \hat r_t(\vx)} \mathrm{d}p_{t+1,i}(\vx)\\
         % =& \sum_{t=1}^n \int_\calX \abs{\langle \vtheta - \hat \vtheta_t , \vphi(\vx) \rangle }\mathrm{d}p_{t+1,i}(\vx)\\
        & \stackrel{\text{C.S.}}{\leq} \sum_{t=1}^n \int_\calX \norm{\vtheta - \hat \vtheta_t}_2 \norm{\vphi(\vx)}_2 \mathrm{d}p_{t+1,i}(\vx)\\
        & \stackrel{\text{bdd. }\phi}{\leq}  \sum_{t=1}^n \norm{\vtheta - \hat \vtheta_t}_2 \int_\calX \mathrm{d}p_{t+1,i}(\vx)
        =\sum_{t=1}^n \norm{\vtheta - \hat \vtheta_t}_2.
         \end{align*}
         We highlight that the Cauchy-Schwarz step may be refined. By further assuming that $\vtheta_{j^\star}$ is bounded away from zero (also called the {\em beta-min} condition \citep{buhlmann2011statistics}) one can show that \smash{$\vtheta-\hat\vtheta_t$} is a $2$-sparse vector. This will then allow one to only rely on boundedness of $\norm{\vphi_j}$ rather than $\norm{\vphi}$ to derive the last inequality, and relax our assumption of $\norm{\vphi(\cdot)} \leq 1$ to $\norm{\vphi_j(\cdot)} \leq 1$ for all $j \in [M]$.
From \cref{thm:anytime_lasso}, with probability greater than $1-\delta/2$ simultaneously for all $n\geq 1$,\looseness-1
    \begin{align*}
         \sum_{t=1}^n \abs{\hat r_{t,i} - r_{t,i}}\leq  & \sum_{t=1}^n \frac{4\sqrt{10}\lambda_t}{\kappa^2(\Phi_t, 2)}= \tilde C(M, \delta,d) \sum_{t=1}^n \frac{1}{\kappa^2(\Phi_t, 2)\sqrt{t}}
    \end{align*}
where,
\[
\tilde C(M, \delta, d)\coloneqq 8\sigma\sqrt{ 1 + \frac{5}{\sqrt{2}}\sqrt{d \left(\log(4M/\delta) + (\log\log d)_+ \right)} + \frac{12}{\sqrt{2}}\left( \log(4M/\delta) + (\log\log d)_+ \right)}.
\]
From \cref{lem:kappa_true_emp}, there exist absolute constants $C_1, C_2$ for which,
    \[
        \sP\left(\forall t\geq 1: \,\, \kappa^2(\Phi_t, 2) \geq C_1\cmin  t^{-1/4} - C_2t^{-5/8} \sqrt{\log(Md/\delta) + (\log\log t)_+} \right) \geq 1-\delta.
        \]
        Using Taylor approximation we observe that, $\frac{1}{1-x^{-1}} = 1 + x^{-1} + o(x^{-1}) = \calO(1+x^{-1})$. Therefore, these exists absolute constant $C_3, C_4$, for which with probability greater than $1-\delta$ for all $t\geq 1$ 
        \begin{align*}
            \sum_{t=1}^n \frac{\tilde C(M, \delta, d)}{\kappa^2(\Phi_t, 2)\sqrt{t}} & \leq \sum_{t=1}^n \frac{\tilde C(M, \delta, d)}{\sqrt{t}} \frac{1}{C_1\cmin  t^{-1/4} - C_2t^{-5/8} \sqrt{\log(Md/\delta) + (\log\log t)_+}}\\
            & \leq \sum_{t=1}^n \frac{\tilde C(M, \delta, d)}{\sqrt{t}} \frac{\tilde C_3}{\cmin  t^{-1/4}}\left(1+ \frac{C_2t^{-5/8} \sqrt{\log(Md/\delta) + (\log\log t)_+}}{C_1 \cmin t^{-1/4}}\right)\\
            & \leq  \sum_{t=1}^n \frac{\tilde C_3\tilde C(M, \delta, d)t^{-1/4}}{\cmin}\left(1+\tilde C_4\frac{t^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log t)_+} \right)\\
            & = \frac{C_3\tilde C(M, \delta, d)n^{3/4}}{\cmin}\left(1+C_4\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right).
        \end{align*}
% The above chain of inequalities concludes the proof.
\end{proof}


\begin{lemma}[Anytime Bound on Variance Term] \label{lem:anytime_variance_bound}
    Suppose $\lambda_t$ is chosen according to \cref{lem:anytime_CI_main}, $\gamma_t = \calO(t^{-1/4})$ and $\eta_t = \calO(\cmin t^{-1/2}/C(M,\delta,d))$. Then with probability greater than $1-\delta$, the following holds simultaneously for all $n \geq 1$ and $t \geq 1$
    \begin{align*}
        \hat r_{t,j} & \leq \frac{4\sqrt{10}\lambda_t}{\kappa^2(\Phi_t, 2)} + B,\quad \quad \forall j \in [M]\\
         \sum_{t=1}^n \eta_t \sum_{j=1}^M  q_{t,j} \hat r^2_{t,j} & \leq C_1 B^2\cmin \sqrt{n} 
        + C_2 B n^{1/4}
   \left(1+\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right)\\
   & +  C(M,\delta, d) \frac{\log n}{\cmin}\left(1+\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right) 
    \end{align*}
    where $C_i$ are absolute constants, and $C(M, \delta, d)$ is as defined in \cref{lem:anytime_CI_main}, up to constant factors.
\end{lemma}
\begin{proof}[Proof of \cref{lem:anytime_variance_bound}]
    We start by upper bounding $\hat r_{t,j}$. For all $j$ and $t$ it holds that:
    \begin{align*}
        \hat r_{t,j} & = \int_{\calX} \langle \hat \vtheta_t, \vphi(\vx)\rangle \mathrm{d}p_{t+1,j}(\vx) \leq \norm{\hat \vtheta_t} \int_{\calX} \norm{ \vphi(\vx)} \mathrm{d}p_{t+1,j}(\vx) \leq \norm{\hat \vtheta_t}_2 \leq B + \norm{(\hat \vtheta_t - \vtheta)}_2 
    \end{align*}
    since $\norm{\vtheta}_2\leq B$. To bound the last term, we only need to invoke \cref{thm:anytime_lasso}, which, in turn, will simultaneously bound $\hat r_{t,j}$ for all $j = 1, \dots, M$:
    \[
    \sP\left( \forall t\geq 1,\,  \forall j \in [M]: \,\, \hat r_{t,j} \leq \frac{4\sqrt{10} \lambda_t}{c^2_{\kappa, t}} + B \right) \geq 1-\delta
    \]
  Which implies for all $t \geq 1$,
    \[
    \sum_{j=1}^M  q_{t,j} \hat r^2_{t,j} \leq \left(\frac{4\sqrt{10} \lambda_t}{c^2_{\kappa, t}} + B \right)^2 \sum_{j=1}^M  q_{t,j} = \frac{160 \lambda_t^2}{c^4_{\kappa, t}} + B^2 + \frac{8B\sqrt{10}
\lambda_t}{c_{\kappa, t}^2}.
    \]
    For the last term, similar to the proof of \cref{lem:anytime_CI_main} we have,
    \[
    \sum_{t=1}^n \eta_t\frac{8B\sqrt{10}
\lambda_t}{c_{\kappa, t}^2} \leq C_1 B n^{1/4}
   \left(1+\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right)
    \]
    for some absolute constant $C_1$. We treat the squared term similarly,
            \begin{align*}
            \sum_{t=1}^n \eta_t \frac{160\lambda_t^2}{c^4_{\kappa,t}} 
            % & \leq  C(M,\delta, d)\sum_{t=1}^n \frac{\cmin }{t^{3/2}} \left( \frac{1}{C_1\cmin  t^{-1/4} - C_2t^{-5/8} \sqrt{\log(Md/\delta) + (\log\log t)_+}}\right)^2\\
            % & \leq C(M,\delta, d)\sum_{t=1}^n \frac{1}{t^{3/2}} \frac{\tilde C_3}{\cmin  t^{-1/2}}\left(1+ \frac{2C_2t^{-5/8} \sqrt{\log(Md/\delta) + (\log\log t)_+}}{C_1 \kappa_{\mathrm{min}} t^{-1/4}}\right)\\
            & \leq C(M,\delta, d) \sum_{t=1}^n \frac{\bar C_3}{t \cmin}\left(1+\bar C_4\frac{t^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log t)_+} \right)\\
            % & \leq C(M,\delta, d) \frac{C_3\log n}{\cmin}\left(1+C_4\frac{n^{-1/8}}{\cmin\log n} \sqrt{\log(Md/\delta) + (\log\log t)_+} \right).\\
            & \leq C(M,\delta, d) \frac{C_3\log n}{\cmin}\left(1+C_4\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right).
        \end{align*}
       Note that the last inequality is not tight. This term will not be fastest growing term in the regret, so we have little motivation to bound it tightly. Therefore,
        \begin{align*}
        \sum_{t=1}^n \eta_t\sum_{j=1}^M  q_{t,j} \hat r^2_{t,j} & \leq C_1 B^2\cmin \sqrt{n} 
        + C_2 B n^{1/4}
   \left(1+\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log t)_+} \right)\\
   & +  C(M,\delta, d) \frac{\log n}{\cmin}\left(1+C_4\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right) 
        \end{align*}
        where $C_i$ are absolute constants.
\end{proof}

\begin{proof}[\textbf{Proof of \cref{thm:anytime_regret_MS_formal}}]
We start by conditioning on the event $E$ that $\eta_t$ is picked such that $\eta_t \hat r_{t,j} \leq 1 $ for all $t\geq 1$ and $j = 1, \dots, M$.
Then by application of \cref{lem:anytime_mother_exp4} we get with probability greater than $1-2 \delta/3$,
\begin{align*}
R(n,i) \leq  2B\sum_{t=1}^n\gamma_t  &+\frac{\log M}{\eta_n} + \sum_{t=1}^n\eta_t\sum_{j=1}^M  q_{t,j} \hat r^2_{t,j} 
 + \sum_{t=1}^n (\omega_{t,i} + \sum_{j=1}^M  q_{t,j} \omega_{t,j}) \\
& + 10B\sqrt{ n\left( (\log \log nB^2)_+ + \log(12/ \delta)\right)}
\end{align*}
We invoke \cref{lem:anytime_CI_main} and \cref{lem:anytime_variance_bound} with $\delta \rightarrow \delta/3$ take a union bound, to bound the variance and $\omega_{t,i}$ terms as well. These lemmas require one application of \cref{thm:anytime_lasso} to hold simultaneously and no additional union bound is required between them, since the randomness comes only from the confidence interval over $\hat \vtheta_t$. 
\begin{align*}
R(n,i) \leq  & C_1Bn^{3/4}  +\frac{\log M}{\eta_n} \\
&+C_2 B^2\cmin \sqrt{n} 
        + C_3 B n^{1/4}
   \left(1+\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right)\\
   & +  C(M,\delta, d) \frac{\log n}{\cmin}\left(1+\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right) \\
& + n^{3/4}C(M, \delta, d)
   \left(1+\frac{n^{-3/8}}{\cmin} \sqrt{\log(Md/\delta) + (\log\log n)_+} \right) \\
& + 10B\sqrt{ n\left( (\log \log nB^2)_+ + \log(12/\delta)\right)}
\end{align*}
with probability greater than $1- \delta$, conditioned on event $E$.
Assuming that event $E$ happens with probability $1-2\delta$, let $\calB = \calB(\tilde \delta, M, d, n, B, \sigma, \cmin)$ denote the right-hand-side of the regret inequality above. \newpage
By the chain rule we may write,
\begin{align*}
\sP\big(\mathrm{Reg}&(n,i) \leq \calB \big)   \\
& \geq \sP\left(R(n,i)\leq \calB\Big\vert  \forall t \in [n], j \in [M]:\eta_t \hat r_{t,j} \leq 1\right) \sP\left(\forall t \in [n], j \in [M]:\eta_t \hat r_{t,j} \leq 1\right) \\
& \geq     \sP\left(R(n,i)\leq \calB \,\Big\vert  \,\forall t \in [n], j \in [M]:\,\eta_t \hat r_{t,j} \leq 1\right) (1-2\delta)\\
& \geq (1- \delta)(1-2 \delta)  \geq 1-3\delta.
\end{align*}
It remains to verify that event $E$ is met with probability $1-2\delta$.
Recall that $\eta_t = \calO(\cmin/\sqrt{t}C(M,\delta,d))$, and that from \cref{lem:kappa_true_emp} with probability $1-\delta$,
\[
\frac{\cmin}{4\sqrt{t}C(M, \delta, d)} \leq \frac{C_1\cmin  t^{1/4} - C_2t^{-1/8} \sqrt{\log(Md/\delta) + (\log\log t)_+}}{4\sqrt{10}C(M,\delta,d)} \leq \frac{\kappa^2(\Phi_t,2)}{4\sqrt{10}\lambda_t}
\]
Therefore, from \cref{lem:anytime_variance_bound}, there exists $C_\eta$ such that $\eta_t = C_\eta\cmin/B\sqrt{t}C(M,\delta,d)$ satisfying,
\[
\sP \left( \forall t \geq 1, j \in [M]:\,\eta_t \hat r_{t,j} \leq 1\right) \geq 1-2\delta
\]
% Taking a union bound, we verify that event $E$ happens with probability greater than $1- 2 \delta$.
The proof is then finished by setting $\delta \leftarrow 3\delta$ (and updating the absolute constants).
\end{proof}



