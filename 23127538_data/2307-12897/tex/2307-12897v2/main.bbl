\begin{thebibliography}{64}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P{\'a}l, and
  Szepesv{\'a}ri]{abbasi2011improved}
Yasin Abbasi-Yadkori, D{\'a}vid P{\'a}l, and Csaba Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 2011.

\bibitem[Abbasi-Yadkori et~al.(2012)Abbasi-Yadkori, Pal, and
  Szepesvari]{abbasi2012online}
Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari.
\newblock Online-to-confidence-set conversions and application to sparse
  stochastic bandits.
\newblock In \emph{Artificial Intelligence and Statistics}. PMLR, 2012.

\bibitem[Abernethy and Rakhlin(2009)]{abernethy2009beating}
Jacob Abernethy and Alexander Rakhlin.
\newblock Beating the adaptive bandit with high probability.
\newblock In \emph{2009 Information Theory and Applications Workshop}. IEEE,
  2009.

\bibitem[Abernethy et~al.(2008)Abernethy, Hazan, and
  Rakhlin]{abernethy2008efficient}
Jacob Abernethy, Elad Hazan, and Alexander Rakhlin.
\newblock An efficient algorithm for bandit linear optimization.
\newblock In \emph{Conference on Learning Theory}, 2008.

\bibitem[Agarwal et~al.(2014)Agarwal, Hsu, Kale, Langford, Li, and
  Schapire]{agarwal2014taming}
Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert
  Schapire.
\newblock Taming the monster: A fast and simple algorithm for contextual
  bandits.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2014.

\bibitem[Agarwal et~al.(2017)Agarwal, Luo, Neyshabur, and
  Schapire]{agarwal2017corralling}
Alekh Agarwal, Haipeng Luo, Behnam Neyshabur, and Robert~E Schapire.
\newblock Corralling a band of bandit algorithms.
\newblock In \emph{Conference on Learning Theory}. PMLR, 2017.

\bibitem[Auer et~al.(1995)Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer1995gambling}
Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert~E Schapire.
\newblock Gambling in a rigged casino: The adversarial multi-armed bandit
  problem.
\newblock In \emph{Foundations of Computer Science}. IEEE, 1995.

\bibitem[Auer et~al.(2002{\natexlab{a}})Auer, Cesa-Bianchi, and
  Fischer]{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine learning}, 2002{\natexlab{a}}.

\bibitem[Auer et~al.(2002{\natexlab{b}})Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002nonstochastic}
Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert~E Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM journal on computing}, 2002{\natexlab{b}}.

\bibitem[Banerjee et~al.(2023)Banerjee, Ghosh, Chowdhury, and
  Gopalan]{banerjee2023exploration}
Debangshu Banerjee, Avishek Ghosh, Sayak~Ray Chowdhury, and Aditya Gopalan.
\newblock Exploration in linear bandits with rich action sets and its
  implications for inference.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}. PMLR, 2023.

\bibitem[Bartlett et~al.(2008)Bartlett, Dani, Hayes, Kakade, Rakhlin, and
  Tewari]{bartlett2008high}
Peter~L Bartlett, Varsha Dani, Thomas~P Hayes, Sham~M Kakade, Alexander
  Rakhlin, and Ambuj Tewari.
\newblock High-probability regret bounds for bandit online linear optimization.
\newblock In \emph{Conference on Learning Theory}, 2008.

\bibitem[Bastani and Bayati(2020)]{bastani2020online}
Hamsa Bastani and Mohsen Bayati.
\newblock Online decision making with high-dimensional covariates.
\newblock \emph{Operations Research}, 2020.

\bibitem[Beygelzimer et~al.(2011)Beygelzimer, Langford, Li, Reyzin, and
  Schapire]{beygelzimer2011contextual}
Alina Beygelzimer, John Langford, Lihong Li, Lev Reyzin, and Robert Schapire.
\newblock Contextual bandit algorithms with supervised learning guarantees.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2011.

\bibitem[Bickel et~al.(2009)Bickel, Ritov, and Tsybakov]{bickel2009dantzig}
Peter~J. Bickel, Yaâ€™acov Ritov, and Alexandre~B. Tsybakov.
\newblock {Simultaneous analysis of Lasso and Dantzig selector}.
\newblock \emph{The Annals of Statistics}, 2009.

\bibitem[Bubeck et~al.(2012)Bubeck, Cesa-Bianchi, et~al.]{bubeck2012regret}
S{\'e}bastien Bubeck, Nicolo Cesa-Bianchi, et~al.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  2012.

\bibitem[Bubeck et~al.(2017)Bubeck, Lee, and Eldan]{bubeck2017kernel}
S{\'e}bastien Bubeck, Yin~Tat Lee, and Ronen Eldan.
\newblock Kernel-based methods for bandit convex optimization.
\newblock In \emph{ACM SIGACT Symposium on Theory of Computing}, pages 72--85,
  2017.

\bibitem[B{\"u}hlmann and Van De~Geer(2011)]{buhlmann2011statistics}
Peter B{\"u}hlmann and Sara Van De~Geer.
\newblock \emph{Statistics for high-dimensional data: methods, theory and
  applications}.
\newblock Springer Science \& Business Media, 2011.

\bibitem[Carpentier and Munos(2012)]{carpentier2012bandit}
Alexandra Carpentier and R{\'e}mi Munos.
\newblock Bandit theory meets compressed sensing for high dimensional
  stochastic linear bandit.
\newblock In \emph{Artificial Intelligence and Statistics}. PMLR, 2012.

\bibitem[Cella and Pontil(2021)]{cella2021multi}
Leonardo Cella and Massimiliano Pontil.
\newblock Multi-task and meta-learning with sparse linear bandits.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2021.

\bibitem[Cesa-Bianchi and Lugosi(2006)]{cesa2006prediction}
Nicolo Cesa-Bianchi and G{\'a}bor Lugosi.
\newblock \emph{Prediction, learning, and games}.
\newblock Cambridge university press, 2006.

\bibitem[Foster and Rakhlin(2020)]{foster2020beyond}
Dylan Foster and Alexander Rakhlin.
\newblock Beyond ucb: Optimal and efficient contextual bandits with regression
  oracles.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2020.

\bibitem[Foster et~al.(2017)Foster, Kale, Mohri, and
  Sridharan]{foster2017parameter}
Dylan~J Foster, Satyen Kale, Mehryar Mohri, and Karthik Sridharan.
\newblock Parameter-free online learning via model selection.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Foster et~al.(2019)Foster, Krishnamurthy, and Luo]{foster2019model}
Dylan~J Foster, Akshay Krishnamurthy, and Haipeng Luo.
\newblock Model selection for contextual bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Gerchinovitz(2011)]{gerchinovitz2011sparsity}
S{\'e}bastien Gerchinovitz.
\newblock Sparsity regret bounds for individual sequences in online linear
  regression.
\newblock In \emph{Conference on Learning Theory}, 2011.

\bibitem[Giannopoulos(2003)]{apostolos2003notes}
Apostolos Giannopoulos.
\newblock Notes on isotropic convex bodies, October 2003.

\bibitem[Gonzalez et~al.(2015)Gonzalez, Longworth, James, and
  Lawrence]{gonzalez2015bayesian}
Javier Gonzalez, Joseph Longworth, David~C James, and Neil~D Lawrence.
\newblock Bayesian optimization for synthetic gene design.
\newblock \emph{arXiv preprint}, 2015.

\bibitem[Hao et~al.(2020)Hao, Lattimore, and Wang]{hao2020high}
Botao Hao, Tor Lattimore, and Mengdi Wang.
\newblock High-dimensional sparse linear bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Haussler et~al.(1998)Haussler, Kivinen, and
  Warmuth]{haussler1998sequential}
David Haussler, Jyrki Kivinen, and Manfred~K Warmuth.
\newblock Sequential prediction of individual sequences under general loss
  functions.
\newblock \emph{IEEE Transactions on Information Theory}, 1998.

\bibitem[Howard et~al.(2020)Howard, Ramdas, McAuliffe, and
  Sekhon]{howard2020time}
Steven~R. Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon.
\newblock Time-uniform chernoff bounds via nonnegative supermartingales.
\newblock \emph{Probability Surveys}, 2020.

\bibitem[Howard et~al.(2021)Howard, Ramdas, McAuliffe, and
  Sekhon]{howard2021time}
Steven~R Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon.
\newblock Time-uniform, nonparametric, nonasymptotic confidence sequences.
\newblock \emph{The Annals of Statistics}, 2021.

\bibitem[Imani et~al.(2019)Imani, Ghoreishi, Allaire, and
  Braga-Neto]{imani2019mfbo}
Mahdi Imani, Seyede~Fatemeh Ghoreishi, Douglas Allaire, and Ulisses~M
  Braga-Neto.
\newblock Mfbo-ssm: Multi-fidelity bayesian optimization for fast inference in
  state-space models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2019.

\bibitem[Jang et~al.(2022)Jang, Zhang, and Jun]{jang2022popart}
Kyoungseok Jang, Chicheng Zhang, and Kwang-Sung Jun.
\newblock Popart: Efficient sparse regression and experimental design for
  optimal sparse linear bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Javanmard and Montanari(2014)]{javanmard2014confidence}
Adel Javanmard and Andrea Montanari.
\newblock Confidence intervals and hypothesis testing for high-dimensional
  regression.
\newblock \emph{The Journal of Machine Learning Research}, 2014.

\bibitem[Karimi et~al.(2021)Karimi, G{\"u}rel, Karla{\v{s}}, Rausch, Zhang, and
  Krause]{karimi2021online}
Mohammad~Reza Karimi, Nezihe~Merve G{\"u}rel, Bojan Karla{\v{s}}, Johannes
  Rausch, Ce~Zhang, and Andreas Krause.
\newblock Online active model selection for pre-trained classifiers.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}. PMLR, 2021.

\bibitem[Kassraie et~al.(2022)Kassraie, Rothfuss, and Krause]{kassraie2022meta}
Parnian Kassraie, Jonas Rothfuss, and Andreas Krause.
\newblock Meta-learning hypothesis spaces for sequential decision-making.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2022.

\bibitem[Kaufmann et~al.(2012)Kaufmann, Capp{\'e}, and
  Garivier]{kaufmann2012bayesian}
Emilie Kaufmann, Olivier Capp{\'e}, and Aur{\'e}lien Garivier.
\newblock On bayesian upper confidence bounds for bandit problems.
\newblock In \emph{Artificial intelligence and statistics}. PMLR, 2012.

\bibitem[Kim and Paik(2019)]{kim2019doubly}
Gi-Soo Kim and Myunghee~Cho Paik.
\newblock Doubly-robust lasso bandit.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Koc{\'a}k et~al.(2014)Koc{\'a}k, Neu, Valko, and
  Munos]{kocak2014efficient}
Tom{\'a}{\v{s}} Koc{\'a}k, Gergely Neu, Michal Valko, and R{\'e}mi Munos.
\newblock Efficient learning by implicit exploration in bandit problems with
  side observations.
\newblock \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Lee et~al.(2020)Lee, Luo, Wei, and Zhang]{lee2020bias}
Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, and Mengxiao Zhang.
\newblock Bias no more: high-probability data-dependent regret bounds for
  adversarial bandits and mdps.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Li et~al.(2022)Li, Barik, and Honorio]{li2022simple}
Wenjie Li, Adarsh Barik, and Jean Honorio.
\newblock A simple unified framework for high dimensional bandit problems.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2022.

\bibitem[Liu et~al.(2022)Liu, Xia, Stevens, and Chen]{liu2022cost}
Xuefeng Liu, Fangfang Xia, Rick~L Stevens, and Yuxin Chen.
\newblock Cost-effective online contextual model selection.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Lounici et~al.(2011)Lounici, Pontil, Van De~Geer, and
  Tsybakov]{lounici2011oracle}
Karim Lounici, Massimiliano Pontil, Sara Van De~Geer, and Alexandre~B Tsybakov.
\newblock Oracle inequalities and optimal inference under group sparsity.
\newblock \emph{The annals of statistics}, 2011.

\bibitem[Luo et~al.(2022)Luo, Zhang, Zhao, and Zhou]{luo2022corralling}
Haipeng Luo, Mengxiao Zhang, Peng Zhao, and Zhi-Hua Zhou.
\newblock Corralling a larger band of bandits: A case study on switching regret
  for linear bandits.
\newblock In \emph{Conference on Learning Theory}. PMLR, 2022.

\bibitem[Maillard and Munos(2011)]{odalric2011adaptive}
Odalric-Ambrym Maillard and R{\'e}mi Munos.
\newblock Adaptive bandits: Towards the best history-dependent strategy.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}. JMLR Workshop and Conference Proceedings, 2011.

\bibitem[Massias et~al.(2018)Massias, Gramfort, and Salmon]{celer2018}
Mathurin Massias, Alexandre Gramfort, and Joseph Salmon.
\newblock Celer: a fast solver for the lasso with dual extrapolation.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[McMahan and Streeter(2009)]{mcmahan2009tighter}
H.~Brendan McMahan and Matthew Streeter.
\newblock Tighter bounds for multi-armed bandits with expert advice.
\newblock In \emph{Proceedings of the 22nd Annual Conference on Learning
  Theory}, 2009.

\bibitem[Moradipari et~al.(2022)Moradipari, Turan, Abbasi-Yadkori, Alizadeh,
  and Ghavamzadeh]{moradipari2022feature}
Ahmadreza Moradipari, Berkay Turan, Yasin Abbasi-Yadkori, Mahnoosh Alizadeh,
  and Mohammad Ghavamzadeh.
\newblock Feature and parameter selection in stochastic linear bandits.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2022.

\bibitem[Muthukumar et~al.(2019)Muthukumar, Ray, Sahai, and
  Bartlett]{muthukumar2019best}
Vidya Muthukumar, Mitas Ray, Anant Sahai, and Peter Bartlett.
\newblock Best of many worlds: Robust model selection for online supervised
  learning.
\newblock In \emph{Proceedings of the Twenty-Second International Conference on
  Artificial Intelligence and Statistics}, 2019.

\bibitem[Neu(2015)]{neu2015explore}
Gergely Neu.
\newblock Explore no more: Improved high-probability regret bounds for
  non-stochastic bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Oh et~al.(2021)Oh, Iyengar, and Zeevi]{oh2021sparsity}
Min-hwan Oh, Garud Iyengar, and Assaf Zeevi.
\newblock Sparsity-agnostic lasso bandit.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2021.

\bibitem[Pacchiano et~al.(2020)Pacchiano, Phan, Abbasi~Yadkori, Rao, Zimmert,
  Lattimore, and Szepesvari]{pacchiano2020model}
Aldo Pacchiano, My~Phan, Yasin Abbasi~Yadkori, Anup Rao, Julian Zimmert, Tor
  Lattimore, and Csaba Szepesvari.
\newblock Model selection in contextual stochastic bandit problems.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Pacchiano et~al.(2022)Pacchiano, Wulsin, Barton, and
  Voloch]{pacchiano2022neural}
Aldo Pacchiano, Drausin Wulsin, Robert~A Barton, and Luis Voloch.
\newblock Neural design for genetic perturbation experiments.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem[Rahimi et~al.(2007)Rahimi, Recht, et~al.]{rahimi2007random}
Ali Rahimi, Benjamin Recht, et~al.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2007.

\bibitem[Schur et~al.(2023)Schur, Kassraie, Rothfuss, and
  Krause]{schur2022lifelong}
Felix Schur, Parnian Kassraie, Jonas Rothfuss, and Andreas Krause.
\newblock Lifelong bandit optimization: No prior and no regret.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2023.

\bibitem[Singla et~al.(2018)Singla, Hassani, and Krause]{singla2018learning}
Adish Singla, Hamed Hassani, and Andreas Krause.
\newblock Learning to interact with learning agents.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2018.

\bibitem[Thompson(1933)]{thompson1933likelihood}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock \emph{Biometrika}, 1933.

\bibitem[Tibshirani(1996)]{tibshirani1996regression}
Robert Tibshirani.
\newblock Regression shrinkage and selection via the lasso.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 1996.

\bibitem[Ulmasov et~al.(2016)Ulmasov, Baroukh, Chachuat, Deisenroth, and
  Misener]{ulmasov2016bayesian}
Doniyor Ulmasov, Caroline Baroukh, Benoit Chachuat, Marc~Peter Deisenroth, and
  Ruth Misener.
\newblock Bayesian optimization with dimension scheduling: Application to
  biological systems.
\newblock In \emph{Computer Aided Chemical Engineering}. Elsevier, 2016.

\bibitem[van~de Geer and B{\"u}hlmann(2009)]{sara2009conditions}
Sara~A. van~de Geer and Peter B{\"u}hlmann.
\newblock {On the conditions used to prove oracle results for the Lasso}.
\newblock \emph{Electronic Journal of Statistics}, 2009.

\bibitem[Vershynin(2018)]{vershynin2018high}
Roman Vershynin.
\newblock \emph{High-dimensional probability: An introduction with applications
  in data science}, volume~47.
\newblock Cambridge university press, 2018.

\bibitem[Wainwright(2019)]{wainwright2019high}
Martin~J Wainwright.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint}.
\newblock Cambridge university press, 2019.

\bibitem[Zimmert and Lattimore(2022)]{zimmert2022return}
Julian Zimmert and Tor Lattimore.
\newblock Return of the bias: Almost minimax optimal high probability bounds
  for adversarial linear bandits.
\newblock In \emph{Conference on Learning Theory}. PMLR, 2022.

\end{thebibliography}
