\section{Introduction}

Tree transducers are fundamental devices in theoretical computer science.
%automata theory.
They generalize the finite state transductions from strings to (finite, ranked) trees and
were invented in the 1970s in the context of compiler theory and mathematical linguistics.
The most basic such transducers are the top-down tree
transducer~\cite{DBLP:journals/jcss/Thatcher70,DBLP:journals/mst/Rounds70}
and the bottom-up tree transducer~\cite{th70}, see also~\cite{DBLP:journals/mst/Engelfriet75}.
These transducers traverse their input tree once, but may process subtrees in several copies.
It is well known that these transducers have \emph{linear height increase} (``LHI''),
see e.g.~\cite{DBLP:series/eatcs/FulopV98}.

In this paper we deal with a more powerful kind of tree transducer:
the macro tree transducer~\cite{DBLP:journals/jcss/EngelfrietV85} (``mtt'').
Mtts can be seen as particularly simple functional
programs on trees restricted to primitive recursion via (input) tree pattern matching.
Alternatively, mtts can be seen as context-free tree grammars
(introduced in~\cite{DBLP:journals/mst/Rounds70} as ``context-free dendrogrammars'';
see also~\cite{fis68,DBLP:journals/jcss/EngelfrietS77,DBLP:journals/jcss/EngelfrietS78}
and Section~15 of~\cite{DBLP:reference/hfl/GecsegS97}),
the nonterminals of
which are controlled by a top-down tree storage (in the spirit of~\cite{DBLP:journals/corr/Engelfriet14}).

It is an open problem, if it is decidable for a given mtt whether or not
its translation can be realized by a top-down tree transducer
(with ``origin'' semantics, this problem was shown to be decidable~\cite{DBLP:journals/iandc/FiliotMRT18}).
As mentioned above, it is a necessary condition for the mtt to have
linear height increase (``LHI''). 
This raises the question, can we decide for a given
mtt, whether or not its translation has LHI?
Here we given an affirmative answer to this question.
%
---
It is also an open problem, if it is decidable for a given mtt whether or not
its translation can be realized by an attributed tree 
transducer~\cite{DBLP:journals/mst/Knuth68,DBLP:journals/actaC/Fulop81} (``att'').
It is well-known that atts have \emph{linear size-to-height increase} (``LSHI''), 
see, e.g.,~\cite{DBLP:series/eatcs/FulopV98}. 
This raises the question, can we decide for a given
mtt, whether or not its translation is of LSHI?
Also to this question we give an affirmative answer.
Note that it was conjectured in~\cite{DBLP:journals/siamcomp/EngelfrietM03}
that the methods of that paper
could be adapted to give such an affirmative answer.

Let us now discuss our results in more detail.
To decide both the LHI and LSHI properties, we introduce a new normal form
called ``depth proper''. An mtt is depth proper if each parameter of every 
(reachable) state
appears at infinitely many different depths (for different input trees).
The idea of our construction is to eliminate 
parameters that only appear at bounded depths; we use regular
look-ahead to determine which bounded paths to output at a given moment.
Since in this way we may generate output ``earlier'' than the original transducer,
new ``helper states'' need to be introduced which continue the translation at
the correct input nodes. Both issues, the change of look-ahead and the introduction
of new states may cause the newly constructed transducer \emph{not} to be depth proper.
For this reason our construction has to be iterated before a depth proper mtt
is obtained.

To understand the idea of the construction, let us consider a simple example.
We consider input and output trees over a binary symbol $f$ and the
nullary symbol $a$ and an mtt with the following rules.
\[
\begin{array}{lcl}
q_0(f(x_1,x_2)) &\to& f(q_1(x_2), q_2(x_2, q_{\text{id}}(x_1)))\\
q_1(f(x_1,x_2)) &\to& q_{\text{id}}(x_1)\\
q_2(f(x_1,x_2),y_1) &\to& f(y_1, q_0(x_2))\\
q_2(a,y_1) &\to& f(y_1, a)\\
q_{\text{id}}(f(x_1,x_2)) &\to& f(q_{\text{id}}(x_1), q_{\text{id}}(x_2))\\
q_{\text{id}}(a) &\to& a
\end{array}
\]
The transducer realizes the following translation:
\[
f(t_1, f(t_2, f(t_3, f(t_4, \dots )))) \Rightarrow
f(t_2, f(t_1, f(t_4, f(t_3, \dots ))))
\]
Let us consider the first (top-most) rule: the state $q_1$ produces
the tree $t_2$. The state $q_2$ takes in its parameter argument the
tree $t_1$ (produced by the call $q_{\text{id}}(x_1)$).
At the \emph{next} node of the right-comb of the input tree
the state $q_2$ outputs $f(t_1, t)$ where $t$ is the translation of the transducer 
for the tree $f(t_3, \dots)$. We observe that state $q_2$ is 
\emph{not} depth proper: each tree that it outputs is of the form
$f(y_1, t)$ where $t$ does not contain the parameter $y_1$.
The idea of our construction is to replace each occurrence of state $q_2$ in
the right-hand side of any rule by this tree ``fragment'', where at the 
position of $t$ there will be the new ``helper state'' $[q_2,2]$. 
The path ``2'' indicates that this state should produce the tree at the second
child position of the output tree produced by $q_2$.
We obtain the following rules:
\[
\begin{array}{lcl}
q_0(f(x_1,x_2)) &\to& f(q_1(x_2), f(q_{\text{id}}(x_1), [q_2,2](x_2) )) \\
q_1(f(x_1,x_2)) &\to& q_{\text{id}}(x_1)\\
{[q_2,2]}(f(x_1,x_2)) &\to& q_0(x_2)\\
{[q_2,2]}(a) &\to& a\\
q_{\text{id}}(f(x_1,x_2)) &\to& f(q_{\text{id}}(x_1), q_{\text{id}}(x_2))\\
q_{\text{id}}(a) &\to& a
\end{array}
\]
It should be clear that the new transducer is equivalent to the original one.
Moreover, the new transducer uses no parameters whatsoever, i.e., it is
depth proper.

Given a depth proper mtt, we can decide the LSHI property as follows.
We consider input trees which contain exactly one special marked input leaf
(it will be marked by a state $p$ of the look-ahead automaton, to act as a place-holder for
any input tree for which the look-ahead automaton arrives in state $p$).
For such input trees, the mtt produces output trees which only contain nested state calls
to the special input leaf. The original transducer has LSHI if and only if the
range of this transducer is finite (which is known to be decidable).
In a similar way we can decide LHI: here we consider input trees with multiple
marked input leaves.
To show that if such ranges are not finite, that then the translation does not
have LSHI (or LHI) is done via pumping arguments (which use depth properness);
these pumping arguments are similar to the ones used in~\cite{DBLP:journals/siamcomp/EngelfrietM03}
to show that it is decidable whether or not an mtt has \emph{linear size increase} (LSI).

%In fact, it is known that
If we restrict the translations of mtts to LSI,
then we obtain exactly the MSO definable tree translations~\cite{DBLP:journals/siamcomp/EngelfrietM03}.
Moreover, LSI is decidable for mtts
(it can even be decided for compositions of mtts, and if so,
then the translation is effectively MSO definable~\cite{DBLP:journals/acta/EngelfrietIM21}).
To decide LSI,
the given mtt is first transformed into ``proper'' normal form.
Properness guarantees that 
(1)~each state (except possibly the initial state) produces
infinitely many output trees (this is called ``input proper''),
and that 
(2)~each parameter of a state is instantiated with infinitely many
distinct argument trees (this is called ``parameter proper'').
Note that input properness is a 
generalization of the proper form of~\cite{DBLP:journals/iandc/AhoU71}.
Once in proper normal form, it suffices to check if the transducer
is ``finite copying''. This means that 
(a)~each node of each input tree is processed only a bounded number of times
and that
(b)~each parameter of every state is copied only a bounded number of times. 
Both of these properties can be reduced to the finiteness problem
of ranges of compositions of mtts~\cite{DBLP:journals/iandc/DrewesE98}.
It is also proved (via complicated pumping arguments)
that if a proper mtt is \emph{not} finite copying, then its
translation is \emph{not} of LSI.

Note that the original proof of the proper form of~\cite{DBLP:journals/iandc/AhoU71}
was not correct, because they had not realized that their construction needs to be iterated.
In~\cite{DBLP:journals/siamcomp/EngelfrietM03} it was shown that at most
$|Q|$-many iterations (where $Q$ is the set of states of the original given mtt)
yield an input-proper mtt.
As mentioned before, termination in our depth proper normal form is more complex,
because also new states are introduced. We prove termination by a 
K{\"o}nigs Lemma like argument.
%
%
%
%
\iffalse
We say that the mtt has the ``finite nesting'' property, if
there is a bound on the number of nested state calls that appear on any path of such output trees.

We can decide whether or not an mtt is finite nesting, similar as before: we change the mtt
to nondeterministically output any path of nested states of any such output tree. The 
original mtt is finite nesting if and only if the range
of this transducer is finite (the latter is decidable, as mentioned above).
We can also show that is the mtt is \emph{not} finite nesting, then the given translation
if \emph{not} LSHI.

Technically speaking all our mtts are always equipped with look-ahead. 
Two issues that arise in our construction in general are:
(\emph{i.}) the

In the case of input-properness, only the look-ahead changes in each iteration of the construction.
Our construction of a depth proper mtt also needs to be iterated due to the change of
look-ahead, however, we also add new states in each iteration. This complicates the 
termination proof and we are not able to present a simple bound such as $|Q|$ for our iteration. 

The proof of this normal form is similar to the one of input-properness, but
more complicated.
\fi
