@article{raj2020survey,
  title={A survey on LiDAR scanning mechanisms},
  author={Raj, Thinal and Hanim Hashim, Fazida and Baseri Huddin, Aqilah and Ibrahim, Mohd Faisal and Hussain, Aini},
  journal={Electronics},
  volume={9},
  number={5},
  pages={741},
  year={2020},
  publisher={MDPI}
}

@inproceedings{behley2019semantickitti,
  title={Semantickitti: A dataset for semantic scene understanding of lidar sequences},
  author={Behley, Jens and Garbade, Martin and Milioto, Andres and Quenzel, Jan and Behnke, Sven and Stachniss, Cyrill and Gall, Jurgen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9297--9307},
  year={2019}
}

@inproceedings{wang2021unsupervised,
  title={Unsupervised point cloud pre-training via occlusion completion},
  author={Wang, Hanchen and Liu, Qi and Yue, Xiangyu and Lasenby, Joan and Kusner, Matt J},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9782--9792},
  year={2021}
}

@inproceedings{yu2022point,
  title={Point-bert: Pre-training 3d point cloud transformers with masked point modeling},
  author={Yu, Xumin and Tang, Lulu and Rao, Yongming and Huang, Tiejun and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19313--19322},
  year={2022}
}

@inproceedings{pang2022masked,
  title={Masked autoencoders for point cloud self-supervised learning},
  author={Pang, Yatian and Wang, Wenxiao and Tay, Francis EH and Liu, Wei and Tian, Yonghong and Yuan, Li},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part II},
  pages={604--621},
  year={2022},
  organization={Springer}
}

@inproceedings{dong2023autoencoders,
title={Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image Transformers Help 3D Representation Learning?},
author={Runpei Dong and Zekun Qi and Linfeng Zhang and Junbo Zhang and Jianjian Sun and Zheng Ge and Li Yi and Kaisheng Ma},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=8Oun8ZUVe8N}
}

@inproceedings{afham2022crosspoint,
  title={Crosspoint: Self-supervised cross-modal contrastive learning for 3d point cloud understanding},
  author={Afham, Mohamed and Dissanayake, Isuru and Dissanayake, Dinithi and Dharmasiri, Amaya and Thilakarathna, Kanchana and Rodrigo, Ranga},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9902--9912},
  year={2022}
}

@inproceedings{zhang2021self,
  title={Self-supervised pretraining of 3d features on any point-cloud},
  author={Zhang, Zaiwei and Girdhar, Rohit and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10252--10263},
  year={2021}
}

@article{sun2023vipformer,
  title={ViPFormer: Efficient Vision-and-Pointcloud Transformer for Unsupervised Pointcloud Understanding},
  author={Sun, Hongyu and Wang, Yongcai and Cai, Xudong and Bai, Xuewei and Li, Deying},
  journal={arXiv preprint arXiv:2303.14376},
  year={2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{wang2023image,
  title={Image as a Foreign Language: BEiT Pretraining for Vision and Vision-Language Tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19175--19186},
  year={2023}
}

@inproceedings{girdhar2023imagebind,
  title={ImageBind: One embedding space to bind them all},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15180--15190},
  year={2023}
}

@article{bao2022vlmo,
  title={Vlmo: Unified vision-language pre-training with mixture-of-modality-experts},
  author={Bao, Hangbo and Wang, Wenhui and Dong, Li and Liu, Qiang and Mohammed, Owais Khan and Aggarwal, Kriti and Som, Subhojit and Piao, Songhao and Wei, Furu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32897--32912},
  year={2022}
}

@inproceedings{li2022closer,
  title={A closer look at invariances in self-supervised pre-training for 3d vision},
  author={Li, Lanxiao and Heizmann, Michael},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXX},
  pages={656--673},
  year={2022},
  organization={Springer}
}

@inproceedings{jing2021cross,
  title={Cross-modal center loss for 3D cross-modal retrieval},
  author={Jing, Longlong and Vahdani, Elahe and Tan, Jiaxing and Tian, Yingli},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3142--3151},
  year={2021}
}

@inproceedings{li2022simipu,
  title={Simipu: Simple 2d image and 3d point cloud unsupervised pre-training for spatial-aware visual representations},
  author={Li, Zhenyu and Chen, Zehui and Li, Ang and Fang, Liangji and Jiang, Qinhong and Liu, Xianming and Jiang, Junjun and Zhou, Bolei and Zhao, Hang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={1500--1508},
  year={2022}
}

@article{qian2022pix4point,
  title={Pix4point: Image pretrained transformers for 3d point cloud understanding},
  author={Qian, Guocheng and Zhang, Xingdi and Hamdi, Abdullah and Ghanem, Bernard},
  journal={arXiv preprint arXiv:2208.12259},
  year={2022}
}

@article{huang2022frozen,
  title={Frozen CLIP Model is Efficient Point Cloud Backbone},
  author={Huang, Xiaoshui and Li, Sheng and Qu, Wentao and He, Tong and Zuo, Yifan and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2212.04098},
  year={2022}
}

@inproceedings{gao2023ulip,
  title={ULIP: Learning a Unified Representation of Language, Images, and Point Clouds for 3D Understanding},
  author={Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xue, Le and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1179--1189},
  year={2023}
}

@inproceedings{qi2023recon,
  title={Contrast with Reconstruct: Contrastive 3D Representation Learning Guided by Generative Pretraining},
  author={Qi, Zekun and Dong, Runpei and Fan, Guofan and Ge, Zheng and Zhang, Xiangyu and Ma, Kaisheng and Yi, Li},
  booktitle={International Conference on Machine Learning (ICML) },
  year={2023}
}

@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
} 

@article{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={5232--5270},
  year={2022},
  publisher={JMLRORG}
}


@article{kang4200653learning,
  title={Toward extracting and exploiting generalizable knowledge of deep 2D transformations in computer vision},
  author={Kang, Jiachen and Jia, Wenjing and He, Xiangjian},
  journal={Neurocomputing},
  volume={562},
  pages={126882},
  year={2023},
  publisher={Elsevier}
}

@article{chang2015shapenet,
  title={Shapenet: An information-rich 3d model repository},
  author={Chang, Angel X and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and others},
  journal={arXiv preprint arXiv:1512.03012},
  year={2015}
}

@inproceedings{zhangpoint,
  title={Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training},
  author={Zhang, Renrui and Guo, Ziyu and Gao, Peng and Fang, Rongyao and Zhao, Bin and Wang, Dong and Qiao, Yu and Li, Hongsheng},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022},
}

@article{xu2019disn,
  title={Disn: Deep implicit surface network for high-quality single-view 3d reconstruction},
  author={Xu, Qiangeng and Wang, Weiyue and Ceylan, Duygu and Mech, Radomir and Neumann, Ulrich},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019},
}

@article{ravi2020pytorch3d,
    author = {Nikhila Ravi and Jeremy Reizenstein and David Novotny and Taylor Gordon
                  and Wan-Yen Lo and Justin Johnson and Georgia Gkioxari},
    title = {Accelerating 3D Deep Learning with PyTorch3D},
    journal = {arXiv:2007.08501},
    year = {2020},
}

@inproceedings{wu20153d,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1912--1920},
  year={2015}
}

@inproceedings{uy2019revisiting,
  title={Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data},
  author={Uy, Mikaela Angelina and Pham, Quang-Hieu and Hua, Binh-Son and Nguyen, Thanh and Yeung, Sai-Kit},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1588--1597},
  year={2019}
}

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}

@article{wang2019dynamic,
  title={Dynamic graph cnn for learning on point clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E and Bronstein, Michael M and Solomon, Justin M},
  journal={Acm Transactions On Graphics (tog)},
  volume={38},
  number={5},
  pages={1--12},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{li2018pointcnn,
  title={Pointcnn: Convolution on x-transformed points},
  author={Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{qiu2021geometric,
  title={Geometric back-projection network for point cloud classification},
  author={Qiu, Shi and Anwar, Saeed and Barnes, Nick},
  journal={IEEE Transactions on Multimedia},
  volume={24},
  pages={1943--1955},
  year={2021},
  publisher={IEEE}
}

@inproceedings{marethinking,
  title={Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework},
  author={Ma, Xu and Qin, Can and You, Haoxuan and Ran, Haoxi and Fu, Yun},
  booktitle={International Conference on Learning Representations},
  year={2021},
}

@article{qian2022pointnext,
  title={Pointnext: Revisiting pointnet++ with improved training and scaling strategies},
  author={Qian, Guocheng and Li, Yuchen and Peng, Houwen and Mai, Jinjie and Hammoud, Hasan and Elhoseiny, Mohamed and Ghanem, Bernard},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23192--23204},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{tran2022self,
  title={Self-Supervised Learning with Multi-View Rendering for 3D Point Cloud Analysis},
  author={Tran, Bach and Hua, Binh-Son and Tran, Anh Tuan and Hoai, Minh},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={3086--3103},
  year={2022}
}


@article{liu2021learning,
  title={Learning from 2d: Contrastive pixel-to-point knowledge transfer for 3d pretraining},
  author={Liu, Yueh-Cheng and Huang, Yu-Kai and Chiang, Hung-Yueh and Su, Hung-Ting and Liu, Zhe-Yu and Chen, Chin-Tang and Tseng, Ching-Yu and Hsu, Winston H},
  journal={arXiv preprint arXiv:2104.04687},
  year={2021}
}

@inproceedings{xu2022image2point,
  title={Image2point: 3d point-cloud understanding with 2d image pretrained models},
  author={Xu, Chenfeng and Yang, Shijia and Galanti, Tomer and Wu, Bichen and Yue, Xiangyu and Zhai, Bohan and Zhan, Wei and Vajda, Peter and Keutzer, Kurt and Tomizuka, Masayoshi},
  booktitle={European Conference on Computer Vision},
  pages={638--656},
  year={2022},
  organization={Springer}
}

@article{wang2022p2p,
  title={P2p: Tuning pre-trained image models for point cloud analysis with point-to-pixel prompting},
  author={Wang, Ziyi and Yu, Xumin and Rao, Yongming and Zhou, Jie and Lu, Jiwen},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={14388--14402},
  year={2022}
}

@article{zhou2022pointcmc,
  title={PointCMC: Cross-Modal Multi-Scale Correspondences Learning for Point Cloud Understanding},
  author={Zhou, Honggu and Peng, Xiaogang and Mao, Jiawei and Wu, Zizhao and Zeng, Ming},
  journal={arXiv preprint arXiv:2211.12032},
  year={2022}
}

@inproceedings{zhang2022pointclip,
  title={Pointclip: Point cloud understanding by clip},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8552--8562},
  year={2022}
}

@article{hess2022lidarclip,
  title={Lidarclip or: How i learned to talk to point clouds},
  author={Hess, Georg and Tonderski, Adam and Petersson, Christoffer and Svensson, Lennart and {\AA}str{\"o}m, Kalle},
  journal={arXiv preprint arXiv:2212.06858},
  year={2022}
}

@article{zhang2023clip,
  title={Clip-fo3d: Learning free open-world 3d scene representations from 2d dense clip},
  author={Zhang, Junbo and Dong, Runpei and Ma, Kaisheng},
  journal={arXiv preprint arXiv:2303.04748},
  year={2023}
}

@inproceedings{loshchilov2018decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{wu2023self,
  title={Self-Supervised Intra-Modal and Cross-Modal Contrastive Learning for Point Cloud Understanding},
  author={Wu, Yue and Liu, Jiaming and Gong, Maoguo and Gong, Peiran and Fan, Xiaolong and Qin, AK and Miao, Qiguang and Ma, Wenping},
  journal={IEEE Transactions on Multimedia},
  year={2023},
  publisher={IEEE}
}

@article{rong2023efficient,
  title={Efficient 3D Scene Semantic Segmentation via Active Learning on Rendered 2D Images},
  author={Rong, Mengqi and Cui, Hainan and Shen, Shuhan},
  journal={IEEE Transactions on Image Processing},
  year={2023},
  publisher={IEEE}
}

@article{tang2023point,
  title={Point-LGMask: Local and Global Contexts Embedding for Point Cloud Pre-training with Multi-Ratio Masking},
  author={Tang, Yuan and Li, Xianzhi and Xu, Jinfeng and Yu, Qiao and Hu, Long and Hao, Yixue and Chen, Min},
  journal={IEEE Transactions on Multimedia},
  year={2023},
  publisher={IEEE}
}

@article{xu2022semantic,
  title={Semantic Navigation of PowerPoint-Based Lecture Video for AutoNote Generation},
  author={Xu, Chengpei and Jia, Wenjing and Wang, Ruomei and He, Xiangjian and Zhao, Baoquan and Zhang, Yuanfang},
  journal={IEEE Transactions on Learning Technologies},
  volume={16},
  number={1},
  pages={1--17},
  year={2022},
  publisher={IEEE}
}