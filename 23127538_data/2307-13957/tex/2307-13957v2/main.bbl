\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@rmstyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{wortsman2019learning}
M.~Wortsman, K.~Ehsani, M.~Rastegari, A.~Farhadi, and R.~Mottaghi, ``Learning
  to learn how to learn: Self-adaptive visual navigation using meta-learning,''
  in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2019, pp. 6750--6759.

\bibitem{yang2018visual}
W.~Yang, X.~Wang, A.~Farhadi, A.~Gupta, and R.~Mottaghi, ``Visual semantic
  navigation using scene priors,'' \emph{arXiv preprint arXiv:1810.06543},
  2018.

\bibitem{anderson2018vision}
P.~Anderson, Q.~Wu, D.~Teney, J.~Bruce, M.~Johnson, N.~S{\"u}nderhauf, I.~Reid,
  S.~Gould, and A.~Van Den~Hengel, ``Vision-and-language navigation:
  Interpreting visually-grounded navigation instructions in real
  environments,'' in \emph{Proceedings of the IEEE Conference on Computer
  Vision and Pattern Recognition}, 2018, pp. 3674--3683.

\bibitem{shridhar2020alfred}
M.~Shridhar, J.~Thomason, D.~Gordon, Y.~Bisk, W.~Han, R.~Mottaghi,
  L.~Zettlemoyer, and D.~Fox, ``Alfred: A benchmark for interpreting grounded
  instructions for everyday tasks,'' in \emph{Proceedings of the IEEE/CVF
  conference on computer vision and pattern recognition}, 2020, pp.
  10\,740--10\,749.

\bibitem{RoomR}
L.~Weihs, M.~Deitke, A.~Kembhavi, and R.~Mottaghi, ``Visual room
  rearrangement,'' in \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2021.

\bibitem{omidshafiei2017deep}
S.~Omidshafiei, J.~Pazis, C.~Amato, J.~P. How, and J.~Vian, ``Deep
  decentralized multi-task multi-agent reinforcement learning under partial
  observability,'' in \emph{International Conference on Machine
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 2681--2690.

\bibitem{gupta2017cooperative}
J.~K. Gupta, M.~Egorov, and M.~Kochenderfer, ``Cooperative multi-agent control
  using deep reinforcement learning,'' in \emph{International Conference on
  Autonomous Agents and Multiagent Systems}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2017, pp. 66--83.

\bibitem{iqbal2019actor}
S.~Iqbal and F.~Sha, ``Actor-attention-critic for multi-agent reinforcement
  learning,'' in \emph{International conference on machine learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2019, pp. 2961--2970.

\bibitem{zhou2020learning}
M.~Zhou, Z.~Liu, P.~Sui, Y.~Li, and Y.~Y. Chung, ``Learning implicit credit
  assignment for cooperative multi-agent reinforcement learning,''
  \emph{Advances in Neural Information Processing Systems}, vol.~33, pp.
  11\,853--11\,864, 2020.

\bibitem{jain2019two}
U.~Jain, L.~Weihs, E.~Kolve, M.~Rastegari, S.~Lazebnik, A.~Farhadi, A.~G.
  Schwing, and A.~Kembhavi, ``Two body problem: Collaborative visual task
  completion,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2019, pp. 6689--6699.

\bibitem{jain2020cordial}
U.~Jain, L.~Weihs, E.~Kolve, A.~Farhadi, S.~Lazebnik, A.~Kembhavi, and
  A.~Schwing, ``A cordial sync: Going beyond marginal policies for multi-agent
  embodied tasks,'' in \emph{European Conference on Computer Vision}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer, 2020, pp. 471--490.

\bibitem{yu2022learning}
C.~Yu, X.~Yang, J.~Gao, H.~Yang, Y.~Wang, and Y.~Wu, ``Learning efficient
  multi-agent cooperative visual exploration,'' in \emph{European Conference on
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp.
  497--515.

\bibitem{liu2022multi}
X.~Liu, D.~Guo, H.~Liu, and F.~Sun, ``Multi-agent embodied visual semantic
  navigation with scene prior knowledge,'' \emph{IEEE Robotics and Automation
  Letters}, vol.~7, no.~2, pp. 3154--3161, 2022.

\bibitem{wang2021collaborative}
H.~Wang, W.~Wang, X.~Zhu, J.~Dai, and L.~Wang, ``Collaborative visual
  navigation,'' \emph{arXiv preprint arXiv:2107.01151}, 2021.

\bibitem{tan2020multi}
S.~Tan, W.~Xiang, H.~Liu, D.~Guo, and F.~Sun, ``Multi-agent embodied question
  answering in interactive environments,'' in \emph{Computer Vision--ECCV 2020:
  16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part
  XIII 16}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp.
  663--678.

\bibitem{liuembodied}
X.~Liu, X.~Li, D.~Guo, S.~Tan, H.~Liu, and F.~Sun, ``Embodied multi-agent task
  planning from ambiguous instruction,'' \emph{Robotics: Science and Systems},
  2022.

\bibitem{wakilpoor2020heterogeneous}
C.~Wakilpoor, P.~J. Martin, C.~Rebhuhn, and A.~Vu, ``Heterogeneous multi-agent
  reinforcement learning for unknown environment mapping,'' \emph{arXiv
  preprint arXiv:2010.02663}, 2020.

\bibitem{mondal2022approximation}
W.~U. Mondal, M.~Agarwal, V.~Aggarwal, and S.~V. Ukkusuri, ``On the
  approximation of cooperative heterogeneous multi-agent reinforcement learning
  (marl) using mean field control (mfc),'' \emph{Journal of Machine Learning
  Research}, vol.~23, no. 129, pp. 1--46, 2022.

\bibitem{sharma2022ch}
V.~Sharma, P.~Goyal, K.~Lin, G.~Thattai, Q.~Gao, and G.~S. Sukhatme, ``Ch-marl:
  A multimodal benchmark for cooperative, heterogeneous multi-agent
  reinforcement learning,'' \emph{arXiv preprint arXiv:2208.13626}, 2022.

\bibitem{deng2020mqa}
Y.~Deng, D.~Guo, X.~Guo, N.~Zhang, H.~Liu, and F.~Sun, ``Mqa: Answering the
  question via robotic manipulation,'' \emph{Robotics: Science and Systems},
  2021.

\bibitem{sarch2022tidee}
G.~Sarch, Z.~Fang, A.~W. Harley, P.~Schydlo, M.~J. Tarr, S.~Gupta, and
  K.~Fragkiadaki, ``Tidee: Tidying up novel rooms using visuo-semantic
  commonsense priors,'' in \emph{European Conference on Computer Vision}, 2022.

\bibitem{kant2022housekeep}
Y.~Kant, A.~Ramachandran, S.~Yenamandra, I.~Gilitschenski, D.~Batra, A.~Szot,
  and H.~Agrawal, ``Housekeep: Tidying virtual households using commonsense
  reasoning,'' 2022.

\bibitem{procthor}
M.~Deitke, E.~VanderBilt, A.~Herrasti, L.~Weihs, J.~Salvador, K.~Ehsani,
  W.~Han, E.~Kolve, A.~Farhadi, A.~Kembhavi, and R.~Mottaghi, ``{ProcTHOR:
  Large-Scale Embodied AI Using Procedural Generation},'' 2022.

\bibitem{pal2021learning}
A.~Pal, Y.~Qiu, and H.~Christensen, ``Learning hierarchical relationships for
  object-goal navigation,'' in \emph{Conference on Robot Learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2021, pp. 517--528.

\bibitem{fried2018speaker}
D.~Fried, R.~Hu, V.~Cirik, A.~Rohrbach, J.~Andreas, L.-P. Morency,
  T.~Berg-Kirkpatrick, K.~Saenko, D.~Klein, and T.~Darrell, ``Speaker-follower
  models for vision-and-language navigation,'' \emph{Advances in Neural
  Information Processing Systems}, vol.~31, 2018.

\bibitem{wang2019reinforced}
X.~Wang, Q.~Huang, A.~Celikyilmaz, J.~Gao, D.~Shen, Y.-F. Wang, W.~Y. Wang, and
  L.~Zhang, ``Reinforced cross-modal matching and self-supervised imitation
  learning for vision-language navigation,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019, pp.
  6629--6638.

\bibitem{Wang2021vision}
------, ``Vision-language navigation policy learning and adaptation,''
  \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence},
  vol.~43, no.~12, pp. 4205--4216, 2021.

\bibitem{Lin2022adversarial}
B.~Lin, Y.~Zhu, Y.~Long, X.~Liang, Q.~Ye, and L.~Lin, ``Adversarial reinforced
  instruction attacker for robust vision-language navigation,'' \emph{IEEE
  Transactions on Pattern Analysis and Machine Intelligence}, vol.~44, no.~10,
  pp. 7175--7189, 2022.

\bibitem{Qiao2023hop}
Y.~Qiao, Y.~Qi, Y.~Hong, Z.~Yu, P.~Wang, and Q.~Wu, ``Hop+: History-enhanced
  and order-aware pre-training for vision-and-language navigation,'' \emph{IEEE
  Transactions on Pattern Analysis and Machine Intelligence}, vol.~45, no.~7,
  pp. 8524--8537, 2023.

\bibitem{chaplot2020learning}
D.~S. Chaplot, D.~Gandhi, S.~Gupta, A.~Gupta, and R.~Salakhutdinov, ``Learning
  to explore using active neural slam,'' \emph{arXiv preprint
  arXiv:2004.05155}, 2020.

\bibitem{qi2020reverie}
Y.~Qi, Q.~Wu, P.~Anderson, X.~Wang, W.~Y. Wang, C.~Shen, and A.~v.~d. Hengel,
  ``Reverie: Remote embodied visual referring expression in real indoor
  environments,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2020, pp. 9982--9991.

\bibitem{das2018embodied}
A.~Das, S.~Datta, G.~Gkioxari, S.~Lee, D.~Parikh, and D.~Batra, ``Embodied
  question answering,'' in \emph{Proceedings of the IEEE Conference on Computer
  Vision and Pattern Recognition}, 2018, pp. 1--10.

\bibitem{gordon2018iqa}
D.~Gordon, A.~Kembhavi, M.~Rastegari, J.~Redmon, D.~Fox, and A.~Farhadi, ``Iqa:
  Visual question answering in interactive environments,'' in \emph{Proceedings
  of the IEEE conference on computer vision and pattern recognition}, 2018, pp.
  4089--4098.

\bibitem{wijmans2019embodied}
E.~Wijmans, S.~Datta, O.~Maksymets, A.~Das, G.~Gkioxari, S.~Lee, I.~Essa,
  D.~Parikh, and D.~Batra, ``Embodied question answering in photorealistic
  environments with point cloud perception,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019, pp.
  6659--6668.

\bibitem{Luo2023depth}
H.~Luo, G.~Lin, Y.~Yao, F.~Liu, Z.~Liu, and Z.~Tang, ``Depth and video
  segmentation based visual attention for embodied question answering,''
  \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence},
  vol.~45, no.~6, pp. 6807--6819, 2023.

\bibitem{Tan2023knowledge}
S.~Tan, M.~Ge, D.~Guo, H.~Liu, and F.~Sun, ``Knowledge-based embodied question
  answering,'' \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, pp. 1--13, 2023.

\bibitem{zhang2021hierarchical}
Y.~Zhang and J.~Chai, ``Hierarchical task learning from language instructions
  with unified transformers and self-monitoring,'' \emph{arXiv preprint
  arXiv:2106.03427}, 2021.

\bibitem{gao2022cooperative}
A.~Gao, H.~Liu, Y.~Hu, W.~Liang, and S.~X. Ng, ``Cooperative cache in cognitive
  radio networks: A heterogeneous multi-agent learning approach,'' \emph{IEEE
  Communications Letters}, vol.~26, no.~5, pp. 1032--1036, 2022.

\bibitem{brittain2022scalable}
M.~Brittain and P.~Wei, ``Scalable autonomous separation assurance with
  heterogeneous multi-agent reinforcement learning,'' \emph{IEEE Transactions
  on Automation Science and Engineering}, 2022.

\bibitem{yang2021ihg}
S.~Yang, B.~Yang, Z.~Kang, and L.~Deng, ``Ihg-ma: Inductive heterogeneous graph
  multi-agent reinforcement learning for multi-intersection traffic signal
  control,'' \emph{Neural networks}, vol. 139, pp. 265--277, 2021.

\bibitem{chen2021meta}
J.~Chen, Y.~Gao, J.~Hu, F.~Deng, and T.~L. Lam, ``Meta reinforcement learning
  based sensor scanning in 3d uncertain environments for heterogeneous
  multi-robot systems,'' \emph{arXiv preprint arXiv:2109.13617}, 2021.

\bibitem{patel2021interpretation}
S.~Patel, S.~Wani, U.~Jain, A.~G. Schwing, S.~Lazebnik, M.~Savva, and A.~X.
  Chang, ``Interpretation of emergent communication in heterogeneous
  collaborative embodied agents,'' in \emph{Proceedings of the IEEE/CVF
  International Conference on Computer Vision}, 2021, pp. 15\,953--15\,963.

\bibitem{das2019tarmac}
A.~Das, T.~Gervet, J.~Romoff, D.~Batra, D.~Parikh, M.~Rabbat, and J.~Pineau,
  ``Tarmac: Targeted multi-agent communication,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2019, pp. 1538--1546.

\bibitem{liu2020when2com}
Y.-C. Liu, J.~Tian, N.~Glaser, and Z.~Kira, ``When2com: Multi-agent perception
  via communication graph grouping,'' in \emph{Proceedings of the IEEE/CVF
  Conference on computer vision and pattern recognition}, 2020, pp. 4106--4115.

\bibitem{ai2thor}
E.~Kolve, R.~Mottaghi, W.~Han, E.~VanderBilt, L.~Weihs, A.~Herrasti, D.~Gordon,
  Y.~Zhu, A.~Gupta, and A.~Farhadi, ``{AI2-THOR: An Interactive 3D Environment
  for Visual AI},'' \emph{arXiv}, 2017.

\bibitem{krishna2017visual}
R.~Krishna, Y.~Zhu, O.~Groth, J.~Johnson, K.~Hata, J.~Kravitz, S.~Chen,
  Y.~Kalantidis, L.-J. Li, D.~A. Shamma, \emph{et~al.}, ``Visual genome:
  Connecting language and vision using crowdsourced dense image annotations,''
  \emph{International journal of computer vision}, vol. 123, no.~1, pp. 32--73,
  2017.

\bibitem{pennington2014glove}
J.~Pennington, R.~Socher, and C.~D. Manning, ``Glove: Global vectors for word
  representation,'' in \emph{Proceedings of the 2014 conference on empirical
  methods in natural language processing (EMNLP)}, 2014, pp. 1532--1543.

\bibitem{KipfW2017semi}
T.~N. Kipf and M.~Welling, ``Semi-supervised classification with graph
  convolutional networks,'' in \emph{5th International Conference on Learning
  Representations, {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference
  Track Proceedings}, 2017.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{Proceedings of the IEEE conference on computer vision
  and pattern recognition}, 2016, pp. 770--778.

\bibitem{he2017mask}
K.~He, G.~Gkioxari, P.~Doll{\'a}r, and R.~Girshick, ``Mask r-cnn,'' in
  \emph{Proceedings of the IEEE international conference on computer vision},
  2017, pp. 2961--2969.

\bibitem{hochreiter1997long}
S.~Hochreiter and J.~Schmidhuber, ``Long short-term memory,'' \emph{Neural
  computation}, vol.~9, no.~8, pp. 1735--1780, 1997.

\bibitem{rashid2020monotonic}
T.~Rashid, M.~Samvelyan, C.~S. De~Witt, G.~Farquhar, J.~Foerster, and
  S.~Whiteson, ``Monotonic value function factorisation for deep multi-agent
  reinforcement learning,'' \emph{The Journal of Machine Learning Research},
  vol.~21, no.~1, pp. 7234--7284, 2020.

\bibitem{wang2021tom2c}
Y.~Wang, F.~Zhong, J.~Xu, and Y.~Wang, ``Tom2c: Target-oriented multi-agent
  communication and cooperation with theory of mind,'' \emph{arXiv preprint
  arXiv:2111.09189}, 2021.

\end{thebibliography}
