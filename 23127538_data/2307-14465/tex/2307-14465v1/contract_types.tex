\subsection{Contract Frequency, Root Cause, and Effect of Contract Violations}
\label{subsec:ctvs}

In this subsection, we answer \RQ{1} by presenting the required types of \ML contracts, the root causes of contract violations, and related effects. 

\subsubsection{\textbf{Required ML contracts and associated root causes}}

To explore required ML contracts and the root causes behind contract violations, we use the leaf contract types from our classification (\S{\ref{subsec:con}}) schema. %The statistical result in 
Table~\ref{tab:socontract1} shows the frequency of each type of contract from the classification found in our dataset. Figure~\ref{level3pie} demonstrates the corresponding root causes. Figure~\ref{fig:compare} shows the statistical comparison of ML Contracts for two datasets (all filtered posts and the subset containing posts with scores of 30 or higher).

\finding{Most frequent ML API contracts are: \newline
	\textbullet~constraint check on single arguments of an API. \newline
	\textbullet~order of APIs that become a requirement eventually. 
}

\begin{table}[htbp!]
	\centering
	\caption{Statistics of \ML~Contracts in \SO}
	\label{tab:socontract1}
	\footnotesize
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|rrrr|r|}
\hline
\rowcolor[HTML]{F3F3F3} 
\cellcolor[HTML]{EFEFEF} &
  \multicolumn{4}{c|}{\cellcolor[HTML]{F3F3F3}\textbf{\bfseries ML Library}} &
  \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}} \\ \cline{2-5}
\rowcolor[HTML]{F3F3F3} 
\multirow{-2}{*}{\cellcolor[HTML]{EFEFEF}\textbf{Contract Types}} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{F3F3F3}\tf} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{F3F3F3}\scikit} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{F3F3F3}\keras} &
  \torch &
  \multicolumn{1}{l|}{\multirow{-2}{*}{\cellcolor[HTML]{EFEFEF}\begin{tabular}[c]{@{}l@{}}Overall \end{tabular}}} \\ \hline
Primitive Type (PT) &
  \multicolumn{1}{r|}{0.63\%} &
  \multicolumn{1}{r|}{1.65\%} &
  \multicolumn{1}{r|}{0.97\%} &
  0.00\% &
  0.01\% \\ \hline
\rowcolor[HTML]{EFEFEF} 
Built-in Type (BIT) &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}1.88\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}5.79\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}1.94\%} &
  3.85\% &
  3.18\% \\ \hline
Reference Type (RT) &
  \multicolumn{1}{r|}{0.63\%} &
  \multicolumn{1}{r|}{2.48\%} &
  \multicolumn{1}{r|}{3.88\%} &
  3.85\% &
  2.20\% \\ \hline
\rowcolor[HTML]{EFEFEF} 
ML Type (MT) &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}15.00\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}14.05\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}16.50\%} &
  15.38\% &
  15.16\% \\ \hline
Intra-argument Contract (IC-1) &
  \multicolumn{1}{r|}{20.63\%} &
  \multicolumn{1}{r|}{33.88\%} &
  \multicolumn{1}{r|}{34.95\%} &
  23.08\% &
  28.36\% \\ \hline
\rowcolor[HTML]{EFEFEF} 
Inter-argument Contract (IC-2) &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}3.75\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}1.65\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}0.97\%} &
  3.85\% &
  2.44\% \\ \hline
Always (G) &
  \multicolumn{1}{r|}{11.25\%} &
  \multicolumn{1}{r|}{7.44\%} &
  \multicolumn{1}{r|}{7.77\%} &
  11.54\% &
  9.29\% \\ \hline
\rowcolor[HTML]{EFEFEF} 
Eventually (F) &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}19.38\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}15.70\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}10.68\%} &
  23.08\% &
  16.38\% \\ \hline
SAM (Level 3) $\land$ AMO (Level 2) &
  \multicolumn{1}{r|}{7.50\%} &
  \multicolumn{1}{r|}{8.26\%} &
  \multicolumn{1}{r|}{7.77\%} &
  0.00\% &
  7.33\% \\ \hline
\rowcolor[HTML]{EFEFEF} 
SAM (Level 3) &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}4.38\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}2.48\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}0.97\%} &
  3.85\% &
  2.93\% \\ \hline
AMO (Level 2) &
  \multicolumn{1}{r|}{6.25\%} &
  \multicolumn{1}{r|}{1.65\%} &
  \multicolumn{1}{r|}{5.83\%} &
  3.85\% &
  4.65\% \\ \hline
\rowcolor[HTML]{EFEFEF} 
Comb. of SAM (Level 3) and AMO (Level 2) &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}8.75\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}4.13\%} &
  \multicolumn{1}{r|}{\cellcolor[HTML]{EFEFEF}7.77\%} &
  7.69\% &
  7.09\% \\ \hline
\end{tabular}%
}
\end{table}

% Figure environment removed
\phantomsection
\label{par:IC-1}
{\textbf{Required \ML~Contract.}} We identify that breaking the contract on the \emph{single argument of an API (IC-1)} and \emph{eventually (F) required API method orders} are the most frequent type of contracts violated. 
We observe that the lack of domain knowledge, and incomplete error messages are some of the reasons why \ML API users struggle with the IC-1 category. For example, in \SO~post \ref{fig:post1} the author struggled to grasp the difference between graph level seed and operation level seed when using the \texttt{tf.random\_shuffle} API. 
In addition, some \ML~APIs are involved in \emph{AMO} contracts that require particular method orders. This required method order is often a source of confusion. For the posts with score $\ge$ 30 in \torch library (\ref{fig:compare}), all observed contracts belong to \emph{AMO} category. However, the number of posts with a score of 30 and higher and containing a contract from the \torch library is very low (3 contracts). Thus, we refrain from making any additional observations for this case.
To analyze further why the required contracts mentioned in this finding are commonly violated, we have randomly sampled \ML APIs from our dataset and studied the documentation for these APIs to investigate if the documentation is complete. We have analyzed API documentation from the \keras~and \tf~libraries and observed that 
many of these incorrect usages of APIs are not documented, especially the corner cases.
As an instance, the function \texttt{RELU} is a valid activation function for \ML~layer APIs in \tf.
However, it should not be used if the layer API in question is the output layer of the 
model in a multi-label classification. 

The SE community can employ existing contract mining approaches~\cite{parammine, specmining, ltlmining, lemieux2015mining, deepspecs} 
to mine these contracts and enhance library documentation.

% Figure environment removed

\finding{\ML~APIs require \ML type checking contracts and show inter-dependency between behavioral and temporal contracts.}
%\vspace{0.05cm}
%\noindent
\phantomsection
\label{par:ML}

We have observed ML type checking (MT) is the next major category, 
considering all posts. For instance, in one \SO~post\footnote{https://stackoverflow.com/questions/33762831/}, the \ML API users is trying to use a predefined model through a \tf~API \texttt{seq2seq()}. This API essentially consists of two recurrent neural networks. The encoder part processes the input and the decoder generates the output. To capture this, \texttt{seq2seq()} contains two arguments \texttt{encode\_inputs} and \texttt{decode\_inputs}. The contract requirement for these arguments according to the accepted answer is that if the input has some shape \texttt{[n]}, then both of the arguments are required to have a shape of \texttt{[batch\_size $\times$ n]}.
We also note that, the ML-type checking error is more common (for the posts with 
score $\geq30$) in the \scikit~library compared to other libraries. This is one of the key findings that is different when we compared the original curated dataset and the filtered dataset with posts scored 30 or higher. This observation can be attributed to the fact that the other studied \ML~libraries incorporate some type checking system, unlike~\scikit. As a result, a \tf or a \keras or a \torch program is less likely to contain type errors. For instance,  we have described that in the \SO post~\ref{fig:post2}, the \texttt{matmul()} API from the \tf library requires that both of the arguments assume that the same \texttt{Tensor} types will be provided by the caller of the API. Therefore, supplying anything other than the allowed type will cause a type error and the program to crash. In contrast, \scikit does not require its program to be strongly typed and relies on Python’s default type system. This situation highlights the need for type regulation in the \ML framework. A runtime assertion checking tool could help catch such contract violations; such a tool could be built, for example, by enhancing an off-the-shelf (e.g., PyContracts~\cite{pycontracturl}) tool that can detect violations of the ML-type contracts we propose. We note that some of the type issues may be caused by the dynamically typed nature of the programming language, Python, and are out of the scope for this paper. 

Additionally, we see that one other new category (dependency between behavioral and temporal contracts) in our classification is required for significant number of APIs. 
Contract languages and type checking tools~\cite{pythonstaticchecker, seshia2018formal, jothimurugan2019composable} should add sufficient expressiveness for these additional types of contracts seen in \ML~APIs.

We note that the behavioral contracts reported in this study are largely preconditions. However, we found some postconditions as well. For instance, in SO post\footnote{https://stackoverflow.com/questions/40904979/}, the author is using the \texttt{tensorflow.session()} method to return a \texttt{Session} object. A \texttt{Session} is a class that is used to run \tf operations. Then calling the \texttt{run()} method on this \texttt{Session} object allows evaluation of the \texttt{Tensor}. In the example post cited above, the \texttt{Tensor} is a constant \texttt{String}. It is supplied as the value used for the argument \texttt{Fetches}. We know that any value in a \texttt{Tensor} holds the same data type with a known (or partially known) shape. In this example, the value returned by \texttt{run()} has the same shape as the \texttt{Fetches} argument. Now one can decode this output data as needed.  The contract we see in this~\SO post is a postcondition. The contract for the \texttt{tf.io.decode\_raw()} API is "returns a binary string (python 2), byte string (python 3)" upon exiting the API call. \\

\finding{Unacceptable input value is the most common root cause.}
%\vspace{0.05cm}
\textbf{Primary Root Cause.} We identify that supplying unacceptable input values to APIs is the primary root cause behind contract violation in \ML. The \ML API users fail to recognize acceptable input values often for several reasons, e.g., misunderstanding a hyper-parameter setting. The undesired input values found in our study can be utilized as test cases in \ML~systems and avoid some of these contract breaches. 

\subsubsection{\textbf{Effects of Contract Violations}} To realize the effects of the contract violations, we have used the classification of effects from a prior work \cite{islam19} mentioned in \S{\ref{subsec:class}}. Figure~\ref{fig:effect} illustrates the distribution of contract violation effects across libraries.

\input{effectfigure}

\finding{On average, 56.93\% of the contract violations for the \ML~libraries leads to a crash.}

{\textbf{Crash (C).}} The majority of contract violations for \ML~APIs lead to a crash in the software and we observe the range within 42.31\%-66.02\%. This result varies only for \torch~ with post score $\geq30$. 
\scikit~has the most examples of contract violations that have lead to crashes among the chosen libraries. As an instance, in \SO post~\ref{fig:post2}, violating the inter-argument contract (IC-2), would result in a crash for the program. 
Researchers might build a new automated repair tool inspired by existing repair tools ~\cite{genprog, angelix, 6776507, spr}. In this regard, mined contracts could be utilized that lead to crashes and act as a preemptive measure for the code. 

\finding{Incorrect functionality has a different frequency pattern in \keras.}
\noindent
{\textbf{Incorrect Functionality (IF).}} 
The next frequent (15.33\% on average) effect that we observed in terms of contract violation is causing incorrect functionality in \ML~software. \ML API users apprehend the deviant behavior either from experience or through the logical organization of the \ML~model.

However, the library \keras~shows a lower percentage. This divergence in frequency can be explained by the fact that \keras~is a high-level deep learning library; thereby hiding many complicated implementation details 
which reduces the chance of running into IF. Since the compiler cannot catch incorrect functionality, our dataset can become a benchmark through contract annotation to detect this effect. Expert \ML API users can further rank these particular contract violations (e.g., scary, troubling, concern) to provide a hint of severity for these IFs as many bug detection tools (such as Bugram \cite{bugram}, Salento \cite{salento}) do. 

\finding{Contract violation-effect  distribution is similar across libraries.}
\noindent
{\textbf{Contract violation-effect correlation.}} To determine the effect of breaking a contract, we used the information explicitly available in the \SO~post we labeled. Even so, we hypothesize that by observing the type of contract violation, it is possible to make an informed guess on the corresponding effect. 
For instance, Islam \etal reported that the violation of type or shape usually results in a crash during runtime~\cite{islam19}.
One \SO post~\footnote{https://stackoverflow.com/questions/44429199/} author was not sure how to use the API \texttt{DataLoader()} from the \torch~library. The answer post lists that the API in question requires that the argument type should be a subclass of \texttt{Dataset} class. Even though it was not explicitly described on the post, such a type checking contract violation would result in a crash. \textit{Python} being a loosely typed language, type mismatch may go unnoticed during compilation. it usually crashes for mismatches in the expected type or shapes~\cite{islam19}.
	
To test this hypothesis on learning from other \ML~libraries regarding violation-effect correlation, 
we obtained the conditional probabilities, %\\ 
%\hspace*{3.5 cm}
\begin{equation*}
\Pr(E=\mathrm{effect}_\mathrm{i} \mid V=\mathrm{violation}_\mathrm{j})
\end{equation*}
\\ which describe how likely a certain effect ($\mathrm{effect}_\mathrm{i}$) follow given a contract violation ($\mathrm{violation}_\mathrm{j}$). Then, we utilized the \emph{Jensen–Shannon divergence (JSD)}~\cite{endres2003new} measure to compute the distance between two probability distributions, $E$ and $V$. The divergence ranges from 0 to 1, where 0 indicates perfect similarity, and 1 indicates no similarity. 

In our experiment, we observed that the violation-wise effect distribution is similar across chosen libraries. The result shows that %among the four contract types with 10\% support, 
eventually (F) required method order, \ML type checking (MT), and intra-argument contracts (IC-1) demonstrated a divergence score of 0.08, 0.11, and 0.14, respectively, with 10\% support, indicating a similar effect distribution across libraries. 
This experiment agrees with our hypothesis.   
Therefore, the SE community can learn from contract violations of the same category for \ML~libraries and estimate unexpected behaviors of other \ML~libraries with similar effects in code. Furthermore, this experiment also shows an application of the proposed classification schema.


\finding{Error messages thrown for breaching an \ML~contract are not often adequate at present.}

%\vspace{0.2cm}
%\noindent
\phantomsection
\label{par:Error}
{\textbf{Error message.}} In case of system failure, the crash or error message helps API users debug the code and identify the root cause. 
In the \SO~post \ref{fig:post8}, the author had received the
error message in the listing below when they tried to load weight on a predefined model. It could be an exhausting task 
to understand the problem by only examining the error message. 
The answer to this post registers that the error occurs as the \ML API users missed redefining the model architecture before loading weights.  
We find an error message inadequate if the error message is present in the author's post, and the response demonstrates that the error message presented does not reflect the incorrect usage for the API in question. 
Additionally, since domain experts can explain these challenging ML contracts (see \S{\ref{sec:dcc}}), such extracted contracts can be encoded in a contract-checking tool. Such a tool, as a result, can enable improved debugging mechanisms for ML software developers.\\

{ \quad
	\begin{lrbox}{\mybox}%
		\begin{lstlisting}[language=iPython2]
IndexError    Traceback (most recent call last)
<ipython-input-101-ec968f9e95c5> in <module>()
    1 model2 = Sequential()
--> 2 model2.load_weights("/Users/Desktop/SquareSpace/weights.hdf5") ...
IndexError: list index out of range
\end{lstlisting}
	\end{lrbox}%
\scalebox{0.92}{\usebox{\mybox}}
\captionof{Stack Overflow post}{\href{https://stackoverflow.com/questions/35074549/how-to-load-a-model-from-an-hdf5-file-in-keras}{Example post demonstrating inadequate error message} \label{fig:post8}}}
\hspace*{0.2cm}

In our study, we found only a handful of contract violations that require runtime checks. For example, if overfitting happens during training, \emph{regularization-related} APIs are necessary for the \ML~model stack. Additionally, we have found cases where runtime checks against the state alone are insufficient without more context. For example, in \keras,~it is required to call \texttt{BatchNormalization()} between the \emph{linear} and \emph{non-linear} layer APIs in the model to achieve better performance. Thus, in this case, the presence of temporal history and an assertion check is required. For such kinds of \ML contracts, we can extend the traditional design-by-contract approach~\cite{10.1109/2.161279} to assert those contracts during runtime and utilize the contract violation message accordingly to inform the correct usage of \ML APIs to the users.

In summary, we observed that the majority of the \ML contracts are similar to traditional contracts, and Finding 1 indicates this. The contracts involving \ML type checking and dependency between behavioral and temporal contracts are specific and needed by ML software. Interestingly, we report there are contracts that can be formalized as in traditional contracts, however, the contract violation effect is often different, e.g., bad performance, incorrect functionality, etc.; i.e., issues about performance and accuracy are more common in \ML software.


