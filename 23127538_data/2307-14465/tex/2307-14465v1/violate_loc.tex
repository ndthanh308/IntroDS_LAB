\subsection{Localizing Contract Violations to Pipeline Stages}

This section groups APIs into categories depending on the \ML~pipeline stage (described in  \S{\ref{subsec:vl}}) to explore \RQ{4}. \cite{islam19} report that even for a subclass of \ML contract violations that leads to bugs, bug localization is very challenging. This motivated us to study the stage of the APIs. Our goal was to identify the pipeline stages where contracts are frequently violated. Figure~\ref{fig:location} depicts the distribution of the locations where the \ML~API contract violation occurred.

\finding{A significant chunk of the ML contract violation occurred during data preprocessing and model construction stages.}

%\vspace{0.2cm}
%\noindent
\phantomsection
\label{par:eps}
{\textbf{Model Construction and Data Preprocessing.}} We observe that 30.1\% of contract violations occur during the model construction stage (across all \SO posts for all libraries). As an example, the \SO~post \ref{fig:post9} using \keras failed to use a \texttt{softmax} activation in the \emph{final} layer but chooses the value \texttt{categorical\_crossentropy} as the \emph{loss function} afterward. Here both the APIs involved, \texttt{Dense} and \texttt{Compile}, are from the model construction stage. In this case, the lack of contract checks results in the error propagating to the training and the prediction stages. 

{
\begin{mytbox2}[colback=green!15,fontupper=\scriptsize,flushleft upper,boxrule=0pt,arc=5pt,left=2pt,right=2pt,after=\ignorespacesafterend\par\noindent]{\checkmark Accepted Answer}
{\textbf{Your network will not work because of activation:}} with \texttt{categorical\_crossentropy} you need to have a \texttt{softmax} activation:
\end{mytbox2}
\captionof{Stack Overflow post}{\href{https://stackoverflow.com/questions/46204569/how-to-handle-variable-sized-input-in-cnn-with-keras}{Example post demonstrating contract violation in early \ML~pipeline stage} \label{fig:post9}}
}

%\vspace*{0.15cm}
For \scikit~and~\torch,~ we observe that 22.22\% and 22.73\% of errors occur respectively at the data pre-processing stage. Although it is one of the earliest stages in the \ML~pipeline, this trend is unique for these two libraries.

\input{location}

We observe that APIs from early pipeline stages are more susceptible to contract violations. This observation is crucial because \ML~pipelines often have inherent dependencies between pipeline stages.
Violating contracts for APIs from early pipeline stages can lead to errors propagating to subsequent stages. We speculate from our data that further investigation in this area is needed. For instance, a possible future direction could be designing a verification system (as in prior work~\cite{sankaran2017darviz,dvijotham2019efficient}) with \ML~contract knowledge. Contracts could explain cases where a bug in the \ML~system is caused by an API that has a location early in the pipeline compared to where the error is registered. Catching the errors early in an \ML system can enable better performance and help reduce costs.

\finding{Training and model evaluation related APIs are the succeeding common locations that lead to contract violations across \ML~libraries.}

{\textbf{Train and Model Evaluation.}} Training is one of the stages across all libraries that are prone to contract violation. 15.2\% of the contract violations occur in APIs designed to train models. One of the primary reasons behind this is that current \ML~API documentation is insufficient on the topic of effects of optional parameters on the model's accuracy rate. Contracts can document the appropriate relationship in regard to accuracy for such optional parameters in \ML APIs found in our study. As an instance, one  \SO~post\footnote{https://stackoverflow.com/questions/24617356/} author talks about using the \scikit~API \texttt{linear\_model.SGDClassifier,partial\_fit()} due to dealing with the large size of training data. However, the \ML API user was unaware that the required contract is to shuffle the data provided as the arguments for this API. User's unawareness here can be considered towards insufficient documentation. Additionally, we observe a rate of 15.9\% in terms of model evaluation stage related contract violations. Training and model evaluation stages are significantly important since, together, they can explain the trustworthiness of the model.

\finding{Model initialization as contract violation stage is mostly prevalent in DNN libraries.}

{\textbf{Model Initialization.}} Model initialization is the stage where DNN APIs are susceptible to violating contracts. The contract violations at this stage generally show a correlation towards the crash and bad performance effects. An example of model initialization stage discussed in one \SO~post\footnote{https://stackoverflow.com/questions/47167630/}, the argument for \texttt{keras.backend.set\_session} API should be a \tf~\texttt{session}. We group this example under the model initialization stage since the API in question sets up the environment. Automated tools (e.g., Auto-Net \cite{mendoza2019towards}) that can build DNNs without human interventions can make use of API contracts from this stage to perform better and avoid crashes.