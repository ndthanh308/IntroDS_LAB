@inproceedings{nguyen2014mining,
	author = {Nguyen, Hoan Anh and Dyer, Robert and Nguyen, Tien N. and Rajan, Hridesh},
	title = {Mining Preconditions of {API}s in Large-scale Code Corpus},
	booktitle = {FSE`14: 22nd International Symposium on Foundations of Software Engineering},
	series = {FSE'14},
	month = {November},
	year = {2014},
	location = {Hong Kong},
	entrysubtype = {conference},
	abstract = {
	Modern software relies on existing application programming in- terfaces (APIs)
	from libraries. Formal specifications for the APIs enable many software
	engineering tasks as well as help developers correctly use them. In this work,
	we mine large-scale repositories of existing open-source software to derive
	potential preconditions for API methods. Our key idea is that APIs’
	preconditions would appear frequently in an ultra-large code corpus with a large
	num- ber of API usages, while project-specific conditions will occur less
	frequently. First, we find all client methods invoking APIs. We then compute a
	control dependence relation from each call site and mine the potential
	conditions used to reach those call sites. We use these guard conditions as a
	starting point to automatically infer the preconditions for each API. We
	analyzed almost 120 million lines of code from SourceForge and Apache projects
	to infer preconditions for the standard Java Development Kit (JDK) library.
	The results show that our technique can achieve high accuracy with recall from
	75–80% and precision from 82–84%. We also found 5 preconditions missing from
	human written specifications. They were all confirmed by a specification expert.
	In a user study, par- ticipants found 82% of the mined preconditions as a good
	starting point for writing specifications. Using our mining result, we also
	built a benchmark of more than 4,000 precondition-related bugs.
	}
}

@inproceedings{khairunnesa2017exploiting,
	author = {Samantha Syeda Khairunnesa and Hoan Anh Nguyen and Tien N. Nguyen and Hridesh Rajan},
	title = {Exploiting Implicit Beliefs to Resolve Sparse Usage Problem in Usage-based Specification Mining},
	booktitle = {OOPSLA'17: The ACM SIGPLAN conference on Object-Oriented Programming, Systems, Languages, and Applications},
	series = {OOPSLA'17},
	location = {Vancouver, Canada},
	month = {October},
	year = {2017},
	entrysubtype = {conference},
	abstract = {
	Frameworks and libraries provide application programming interfaces (APIs) that
	serve as building blocks in modern software development. As APIs present the
	opportunity of increased productivity, it also calls for correct use to avoid
	buggy code. The usage-based specification mining technique has shown great
	promise in solving this problem through a data-driven approach. These techniques
	leverage the use of the API in large corpora to understand the recurring usages
	of the APIs and infer behavioral specifications (preconditions and
	postconditions) from such usages. A challenge for such technique is thus
	inference in the presence of insufficient usages, in terms of both frequency and
	richness. We refer to this as a "sparse usage problem." This paper presents the
	first technique to solve the sparse usage problem in usage-based precondition
	mining. Our key insight is to leverage implicit beliefs to overcome sparse
	usage. An implicit belief (IB) is the knowledge implicitly derived from the fact
	about the code. An IB about a program is known implicitly to a programmer via
	the language's constructs and semantics, and thus not explicitly written or
	specified in the code. The technical underpinnings of our new precondition
	mining approach include a technique to analyze the data and control flow in the
	program leading to API calls to infer preconditions that are implicitly present
	in the code corpus, a catalog of 35 code elements in total that can be used to
	derive implicit beliefs from a program, and empirical evaluation of all of these
	ideas. We have analyzed over 350 millions lines of code and 7 libraries that
	suffer from the sparse usage problem. Our approach realizes 6 implicit beliefs
	and we have observed that addition of single-level context sensitivity can
	further improve the result of usage based precondition mining. The result shows
	that we achieve overall 60% in precision and 69% in recall and the accuracy is
	relatively improved by 32% in precision and 78% in recall compared to base
	usage-based mining approach for these libraries.
	}
}

@inproceedings{10.1145/1062455.1062539, author = {H\"{o}st, Martin and Wohlin, Claes and Thelin, Thomas}, title = {Experimental Context Classification: Incentives and Experience of Subjects}, year = {2005}, isbn = {1581139632}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1062455.1062539}, doi = {10.1145/1062455.1062539}, booktitle = {Proceedings of the 27th International Conference on Software Engineering}, pages = {470–478}, numpages = {9}, keywords = {experimentation, subject experience, subject motivation}, location = {St. Louis, MO, USA}, series = {ICSE ’05} }

@inproceedings{10.1145/3180155.3180260, author = {Zhang, Tianyi and Upadhyaya, Ganesha and Reinhardt, Anastasia and Rajan, Hridesh and Kim, Miryung}, title = {Are Code Examples on an Online {Q}\&{A} Forum Reliable? A Study of {API} Misuse on {S}tack {O}verflow}, year = {2018}, isbn = {9781450356381}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3180155.3180260}, doi = {10.1145/3180155.3180260}, booktitle = {Proceedings of the 40th International Conference on Software Engineering}, pages = {886–896}, numpages = {11}, keywords = {online Q\&A forum, API usage pattern, code example assessment}, location = {Gothenburg, Sweden}, series = {ICSE ’18} }

@inproceedings{10.1145/3338906.3341186, author = {Cai, Liang and Wang, Haoye and Xu, Bowen and Huang, Qiao and Xia, Xin and Lo, David and Xing, Zhenchang}, title = {{A}nswer{B}ot: An Answer Summary Generation Tool Based on {S}tack {O}verflow}, year = {2019}, isbn = {9781450355728}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3338906.3341186}, doi = {10.1145/3338906.3341186}, booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering}, pages = {1134–1138}, numpages = {5}, keywords = {Stack Overflow, Relevant Question Retrieval, Summary Generation}, location = {Tallinn, Estonia}, series = {ESEC/FSE 2019} }


@inproceedings{Gonzalez2020TheSO,
	author={Danielle Gonzalez and Thomas Zimmermann and Nachiappan Nagappan},
	title={The State of the {ML}-universe: 10 Years of Artificial Intelligence \& Machine Learning Software Development on {G}it{H}ub},
	publisher = {Mining Software Repositories (MSR)},
	year={2020}
}

@inproceedings{10.1109/ICSECOMPANION.2007.16, author = {Heckman, Sarah Smith}, title = {Adaptive Probabilistic Model for Ranking Code-Based Static Analysis Alerts}, year = {2007}, isbn = {0769528929}, publisher = {IEEE Computer Society}, address = {USA}, url = {https://doi.org/10.1109/ICSECOMPANION.2007.16}, doi = {10.1109/ICSECOMPANION.2007.16}, abstract = {Software engineers tend to repeat mistakes when developing software. Automated static analysis tools can detect some of these mistakes early in the software process. However, these tools tend to generate a significant number of false positive alerts. Due to the need for manual inspection of alerts, the high number of false positives may make an automated static analysis tool too costly to use. In this research, we propose to rank alerts generated from automated static analysis tools via an adaptive model that predicts the probability an alert is a true fault in a system. The model adapts based upon a history of the actions the software engineer has taken to either filter false positive alerts or fix true faults. We hypothesize that by providing this adaptive ranking, software engineers will be more likely to act upon highly ranked alerts until the probability that remaining alerts are true positives falls below a subjective threshold.}, booktitle = {Companion to the Proceedings of the 29th International Conference on Software Engineering}, pages = {89–90}, numpages = {2}, series = {ICSE COMPANION '07} }

@inproceedings{10.1145/2884781.2884800, author = {Treude, Christoph and Robillard, Martin P.}, title = {Augmenting {API} Documentation with Insights from {S}tack {O}verflow}, year = {2016}, isbn = {9781450339001}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2884781.2884800}, doi = {10.1145/2884781.2884800}, abstract = {Software developers need access to different kinds of information which is often dispersed among different documentation sources, such as API documentation or Stack Overflow. We present an approach to automatically augment API documentation with "insight sentences" from Stack Overflow---sentences that are related to a particular API type and that provide insight not contained in the API documentation of that type. Based on a development set of 1,574 sentences, we compare the performance of two state-of-the-art summarization techniques as well as a pattern-based approach for insight sentence extraction. We then present SISE, a novel machine learning based approach that uses as features the sentences themselves, their formatting, their question, their answer, and their authors as well as part-of-speech tags and the similarity of a sentence to the corresponding API documentation. With SISE, we were able to achieve a precision of 0.64 and a coverage of 0.7 on the development set. In a comparative study with eight software developers, we found that SISE resulted in the highest number of sentences that were considered to add useful information not found in the API documentation. These results indicate that taking into account the meta data available on Stack Overflow as well as part-of-speech tags can significantly improve unsupervised extraction approaches when applied to Stack Overflow data.}, booktitle = {Proceedings of the 38th International Conference on Software Engineering}, pages = {392–403}, numpages = {12}, keywords = {API documentation, stack overflow, insight sentences}, location = {Austin, Texas}, series = {ICSE '16} }

@inproceedings{10.1145/3106237.3119875, author = {Ellmann, Mathias}, title = {On the Similarity of Software Development Documentation}, year = {2017}, isbn = {9781450351058}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3106237.3119875}, doi = {10.1145/3106237.3119875}, abstract = { Software developers spent 20% of their time on information seeking on {S}tack {O}verflow, YouTube or an API reference documentation. Software developers can search within Stack Overflow for duplicates or similar posts. They can also take a look on software development documentations that have similar and additional information included as a Stack Overflow post or a development screencast in order to get new inspirations on how to solve their current development problem. The linkage of same and different types of software development documentation might safe time to evolve new software solutions and might increase the productivity of the developer’s work day. In this paper we will discuss our approach to get a broader understanding of different similarity types (exact, similar and maybe) within and between software documentation as well as an understanding of how different software documentations can be extended. }, booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering}, pages = {1030–1033}, numpages = {4}, keywords = {Similarity Types, Software Analytics, Software Development Documentation}, location = {Paderborn, Germany}, series = {ESEC/FSE 2017} }

@inproceedings{Corbin2008BasicsOQ,
	title={Basics of Qualitative Research (3rd ed.): Techniques and Procedures for Developing Grounded Theory},
	author={J. Corbin and A. Strauss},
	year={2008}
}

@article{Aghajani2019SoftwareDI,
	title={Software Documentation Issues Unveiled},
	author={Emad Aghajani and Csaba Nagy and Olga Lucero Vega-M{\'a}rquez and Mario Linares-V{\'a}squez and Laura Moreno and Gabriele Bavota and Michele Lanza},
	journal={2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
	year={2019},
	pages={1199-1210}
}

@article{Beyer2014AMC,
	title={A Manual Categorization of Android App Development Issues on {S}tack {O}verflow},
	author={Stefanie Beyer and Martin Pinzger},
	journal={2014 IEEE International Conference on Software Maintenance and Evolution},
	year={2014},
	pages={531-535}
}

@article{CHATTERJEE2020110454,
	title = "Finding help with programming errors: An exploratory study of novice software engineers’ focus in {S}tack {O}verflow posts",
	journal = "Journal of Systems and Software",
	volume = "159",
	pages = "110454",
	year = "2020",
	issn = "0164-1212",
	doi = "https://doi.org/10.1016/j.jss.2019.110454",
	url = "http://www.sciencedirect.com/science/article/pii/S0164121219302286",
	author = "Preetha Chatterjee and Minji Kong and Lori Pollock",
	keywords = "Empirical study, Stack overflow, Mining software repositories, Software developer behavior",
	abstract = "Monthly, 50 million users visit Stack Overflow, a popular Q&A forum used by software developers, to share and gather knowledge and help with coding problems. Although Q&A forums serve as a good resource for seeking help from developers beyond the local team, the abundance of information can cause developers, especially novice software engineers, to spend considerable time in identifying relevant answers and suitable suggested fixes. This exploratory study aims to understand how novice software engineers direct their efforts and what kinds of information they focus on within a post selected from the results returned in response to a search query on Stack Overflow. The results can be leveraged to improve the Q&A forum interface, guide tools for mining forums, and potentially improve granularity of traceability mappings involving forum posts. We qualitatively analyze the novice software engineers’ perceptions from a survey as well as their annotations of a set of Stack Overflow posts. Our results indicate that novice software engineers pay attention to only 27% of code and 15–21% of text in a Stack Overflow post to understand and determine how to apply the relevant information to their context. Our results also discern the kinds of information prominent in that focus."
}

@article{Barua2012WhatAD,
	title={What are developers talking about? An analysis of topics and trends in {S}tack {O}verflow},
	author={Anton Barua and Stephen W. Thomas and Ahmed E. Hassan},
	journal={Empirical Software Engineering},
	year={2012},
	volume={19},
	pages={619-654}
}

@article{Rosen2015WhatAM,
	title={What are mobile developers asking about? A large scale study using {S}tack {O}verflow},
	author={Christoffer Rosen and Emad Shihab},
	journal={Empirical Software Engineering},
	year={2015},
	volume={21},
	pages={1192-1223}
}

@article{Cummaudo2020InterpretingCC,
	title={Interpreting Cloud Computer Vision Pain-Points: A Mining Study of {S}tack {O}verflow},
	author={Alex Cummaudo and Rajesh Vasa and Scott A. Barnett and John Grundy and Mohamed Abdelrazek},
	journal={ArXiv},
	year={2020},
	volume={abs/2001.10130}
}

@article{endres2003new,
	title={A new metric for probability distributions},
	author={Endres, Dominik Maria and Schindelin, Johannes E},
	journal={IEEE Transactions on Information theory},
	volume={49},
	number={7},
	pages={1858--1860},
	year={2003},
	publisher={IEEE}
}

@article {GroundedTheoryResearchProceduresCanonsandEvaluativeCriteria,
	author = "Juliet Corbin and Anselm Strauss",
	title = "Grounded Theory Research: Procedures, Canons and Evaluative Criteria",
	journal = "Zeitschrift für Soziologie",
	year = "1990",
	publisher = "De Gruyter Oldenbourg",
	address = "Berlin, Boston",
	volume = "19",
	number = "6",
	doi = "https://doi.org/10.1515/zfsoz-1990-0602",
	pages=      "418 - 427",
	url = "https://www.degruyter.com/view/journals/zfsoz/19/6/article-p418.xml"
}

@article{6776507,
  author={Pei, Yu and Furia, Carlo A. and Nordio, Martin and Wei, Yi and Meyer, Bertrand and Zeller, Andreas},
  journal={IEEE Transactions on Software Engineering}, 
  title={Automated Fixing of Programs with Contracts}, 
  year={2014},
  volume={40},
  number={5},
  pages={427-449},
  doi={10.1109/TSE.2014.2312918}}


@inproceedings{10.1145/1858996.1859035, author = {Păsăreanu, Corina S. and Rungta, Neha}, title = {{S}ymbolic {P}ath{F}inder: Symbolic Execution of {J}ava Bytecode}, year = {2010}, isbn = {9781450301169}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1858996.1859035}, doi = {10.1145/1858996.1859035}, booktitle = {Proceedings of the IEEE/ACM International Conference on Automated Software Engineering}, pages = {179–180}, numpages = {2}, keywords = {program analysis, automated test case generation}, location = {Antwerp, Belgium}, series = {ASE ’10} }

@inproceedings{10.1109/ASE.2009.60, author = {Pradel, Michael and Gross, Thomas R.}, title = {Automatic Generation of Object Usage Specifications from Large Method Traces}, year = {2009}, isbn = {9780769538914}, publisher = {IEEE Computer Society}, address = {USA}, url = {https://doi.org/10.1109/ASE.2009.60}, doi = {10.1109/ASE.2009.60}, booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated Software Engineering}, pages = {371–382}, numpages = {12}, keywords = {dynamic analysis, Specification inference, formal specifications, temporal properties}, series = {ASE ’09} }


@inproceedings{islam20repairing,
  author = {Md Johirul Islam and Rangeet Pan and Giang Nguyen and Hridesh Rajan},
  title = {Repairing Deep Neural Networks: Fix Patterns and Challenges},
  booktitle = {ICSE'20: The 42nd International Conference on Software Engineering},
  location = {Seoul, South Korea},
  month = {May 23-May 29, 2020},
  year = {2020},
  entrysubtype = {conference},
  abstract = {
    Significant interest in applying Deep Neural Network (DNN)
    has fueled the need to support engineering of software that
    uses DNNs.
    Repairing software that uses DNNs is one such unmistakable SE
    need where automated tools could be very helpful; however,
    we do not fully understand challenges to repairing and
    patterns that are utilized when manually repairing them.
    What challenges should automated repair tools address?
    What are the repair patterns whose automation could help
    developers? Which repair patterns should be assigned a
    higher priority for automation?
    This work presents a comprehensive study of bug fix patterns
    to address these questions.
    We have studied 415 repairs from Stack Overflow and 555 repairs from
    GitHub for five popular deep learning libraries Caffe, Keras,
    Tensorflow, Theano, and Torch to understand challenges in
    repairs and bug repair patterns.
    Our key findings reveal that
    DNN bug fix patterns are distinctive compared to traditional bug fix patterns;  
    the most common bug fix patterns are fixing data dimension and neural network connectivity;
    DNN bug fixes have the potential to introduce adversarial vulnerabilities;
    DNN bug fixes frequently introduce new bugs; and
    DNN bug localization, reuse of trained model, and coping with frequent releases
    are major challenges faced by developers when fixing bugs.
    We also contribute a benchmark of 667 DNN (bug, repair) instances.

  }
}

@inproceedings{parammine,
	author = {Hao Zhong and Na Meng and Zexuan Li and Li Jia},
	title = {An Empirical Study on {API} Parameter Rules},
	booktitle = {ICSE'20: The 42nd International Conference on Software Engineering},
	location = {Seoul, South Korea},
	month = {May 23-May 29, 2020},
	year = {2020},
	entrysubtype = {conference},
	abstract = {
	Developers build programs based on software libraries to reduce coding effort. If a program inappropriately invokes an API parameter, the program may exhibit unexpected runtime behaviors. To help developers correctly use library APIs, researchers built tools to mine API parameter rules. However, some fundamental questions are still unexplored. For instance, what are the parameter rules overlooked by existing work, and how can we automatically extract such rules? In this paper, we conducted a large-scale empirical study to investigate the above-mentioned questions. Specifically, to study as many parameter rules as possible, we took a hybrid approach that combines automatic localization of constrained parameters with manual inspection. Our automatic approach—PARU—locates parameters that have constraints either documented in Javadoc (i.e., document rules) or implied by source code (i.e., code rules). Our manual inspection (1) identifies and categorizes rules for the located parameters, (2) analyzes how well existing tools detect the rules, and (3) identifies the mapping between document and code rules. By applying PARU to 9 widely used libraries, we located 5,334 parameters with either document or code rules. Interestingly, there are only 108 parameters that have both types of rules, and 79 of these parameters have the rules unmatched. Additionally, PARU extracted 1,688 rule-containing sentences from Javadoc and code. We manually classified these sentences into six categories, and discovered that existing techniques can reveal at most three of the categories. Our research reveals the challenges for automating parameter rule extraction, and provides insights for future tool design.
	}
}

@inproceedings{10.1145/1287624.1287632, author = {Wasylkowski, Andrzej and Zeller, Andreas and Lindig, Christian}, title = {Detecting Object Usage Anomalies}, year = {2007}, isbn = {9781595938114}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1287624.1287632}, doi = {10.1145/1287624.1287632}, booktitle = {Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering}, pages = {35–44}, numpages = {10}, keywords = {automated specification generation, pattern recognition, data mining for software engineering, programming rules, static analysis, automated defect detection, object usage anomalies}, location = {Dubrovnik, Croatia}, series = {ESEC-FSE ’07} }

@inproceedings{10.1145/1831708.1831723, author = {Gruska, Natalie and Wasylkowski, Andrzej and Zeller, Andreas}, title = {Learning from 6,000 Projects: Lightweight Cross-Project Anomaly Detection}, year = {2010}, isbn = {9781605588230}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1831708.1831723}, doi = {10.1145/1831708.1831723}, booktitle = {Proceedings of the 19th International Symposium on Software Testing and Analysis}, pages = {119–130}, numpages = {12}, keywords = {temporal properties, mining specifications, language independent parsing, lightweight parsing, formal concept analysis}, location = {Trento, Italy}, series = {ISSTA ’10} }

@inproceedings{10.1145/1595696.1595767, author = {Nguyen, Tung Thanh and Nguyen, Hoan Anh and Pham, Nam H. and Al-Kofahi, Jafar M. and Nguyen, Tien N.}, title = {Graph-Based Mining of Multiple Object Usage Patterns}, year = {2009}, isbn = {9781605580012}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1595696.1595767}, doi = {10.1145/1595696.1595767}, booktitle = {Proceedings of the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering}, pages = {383–392}, numpages = {10}, keywords = {anomaly, object usage, api usage, pattern, clone, graph mining, groum}, location = {Amsterdam, The Netherlands}, series = {ESEC/FSE ’09} }

@inproceedings{islam19,
	author = {Md Johirul Islam and Giang Nguyen and Rangeet Pan and Hridesh Rajan},
	title = {A Comprehensive Study on Deep Learning Bug Characteristics},
	booktitle = {ESEC/FSE'19: The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE)},
	series = {ESEC/FSE 2019},
	month = {August},
	year = {2019},
	entrysubtype = {conference},
	abstract = {
	Deep learning has gained substantial popularity in recent years.
	Developers mainly rely on libraries and tools to add deep learning
	capabilities to their software. What kinds of bugs are frequently
	found in such software? What are the root causes of such bugs?
	What impacts do such bugs have? Which stages of deep learning
	pipeline are more bug prone? Are there any antipatterns?
	Understanding such characteristics of bugs in deep learning
	software has the potential to foster the development of better
	deep learning platforms, debugging mechanisms, development practices,
	and encourage the development of analysis and verification frameworks.
	Therefore, we study 2716 high-quality posts from Stack Overflow
	and 500 bug fix commits from Github about five popular deep learning
	libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand
	the types of bugs, root causes of bugs, impacts of bugs, bug-prone
	stage of deep learning pipeline as well as whether there are some
	common antipatterns found in this buggy software.
	The key findings of our study include: data bug and logic bug are
	the most severe bug types in deep learning software appearing more
	than 48% of the times, major root causes of these bugs are Incorrect
	Model Parameter (IPS) and Structural Inefficiency (SI) showing up
	more than 43% of the times.
	We have also found that the bugs in the usage of deep learning
	libraries have some common antipatterns that lead to a strong
	correlation of bug types among the libraries.
	}
}

@inproceedings{10.1145/3213846.3213866, author = {Zhang, Yuhao and Chen, Yifan and Cheung, Shing-Chi and Xiong, Yingfei and Zhang, Lu}, title = {An Empirical Study on {T}ensor{F}low Program Bugs}, year = {2018}, isbn = {9781450356992}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3213846.3213866}, doi = {10.1145/3213846.3213866}, booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis}, pages = {129–140}, numpages = {12}, keywords = {Deep Learning, Empirical Study, TensorFlow Program Bug}, location = {Amsterdam, Netherlands}, series = {ISSTA 2018} }

@inproceedings{8305957, 
	author={X. {Sun} and T. {Zhou} and G. {Li} and J. {Hu} and H. {Yang} and B. {Li}}, 
	booktitle={2017 24th Asia-Pacific Software Engineering Conference (APSEC)}, 
	title={An Empirical Study on Real Bugs for Machine Learning Programs}, 
	year={2017}, 
	volume={}, 
	number={}, 
	pages={348-357}, 
	keywords={application program interfaces;learning (artificial intelligence);program debugging;software maintenance;open source machine learning tools;low-quality ML tools;real bugs;machine learning programs;software maintenance;bug category;machine learning bugs;ML algorithms;Computer bugs;Software;Maintenance engineering;Tools;Libraries;Documentation;Software engineering;empirical study;machine learning programs;bug;bug fix}, 
	doi={10.1109/APSEC.2017.41}, 
	ISSN={null}, 
	month={Dec},}

@inproceedings{10.1109/ISSRE.2012.22, author = {Thung, Ferdian and Wang, Shaowei and Lo, David and Jiang, Lingxiao}, title = {An Empirical Study of Bugs in Machine Learning Systems}, year = {2012}, isbn = {9780769548883}, publisher = {IEEE Computer Society}, address = {USA}, url = {https://doi.org/10.1109/ISSRE.2012.22}, doi = {10.1109/ISSRE.2012.22}, booktitle = {Proceedings of the 2012 IEEE 23rd International Symposium on Software Reliability Engineering}, pages = {271–280}, numpages = {10}, series = {ISSRE ’12}}

@inproceedings{DBLP:conf/aaai/Ribeiro0G18,
	author    = {Marco T{\'{u}}lio Ribeiro and
	Sameer Singh and
	Carlos Guestrin},
	editor    = {Sheila A. McIlraith and
	Kilian Q. Weinberger},
	title     = {Anchors: High-Precision Model-Agnostic Explanations},
	booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence,
	(AAAI-18), the 30th innovative Applications of Artificial Intelligence
	(IAAI-18), and the 8th {AAAI} Symposium on Educational Advances in
	Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February
	2-7, 2018},
	pages     = {1527--1535},
	publisher = {{AAAI} Press},
	year      = {2018},
	url       = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16982},
	timestamp = {Tue, 23 Oct 2018 06:42:15 +0200},
	biburl    = {https://dblp.org/rec/conf/aaai/Ribeiro0G18.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1109/ASE.2019.00079, author = {Gopinath, Divya and Converse, Hayes and Pasareanu, Corina S. and Taly, Ankur}, title = {Property Inference for Deep Neural Networks}, year = {2019}, isbn = {9781728125084}, publisher = {IEEE Press}, url = {https://doi.org/10.1109/ASE.2019.00079}, doi = {10.1109/ASE.2019.00079}, booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering}, pages = {797–809}, numpages = {13}, location = {San Diego, California}, series = {ASE ’19} }


@INPROCEEDINGS{926934,  author={S. {Sarker} and F. {Lau} and S. {Sahay}},  booktitle={Proceedings of the 33rd Annual Hawaii International Conference on System Sciences},  title={Building an inductive theory of collaboration in virtual teams: an adapted grounded theory approach},   year={2000},  volume={},  number={},  pages={10 pp. vol.2-},}

@inproceedings{jia2020tfbugs,
	author = {Li Jia and Hao Zhong and Xiaoyin Wang and Linpeng Huang and Xuansheng Lu},
	booktitle = {Proc. DASFAA},
	title = {An Empirical Study on Bugs inside TensorFlows},
	pages={to appear},
	year = {2020}
}

@InProceedings{cousot2013automatic,
	author = {Cousot, Patrick and Cousot, Radhia and Fahndrich, Manuel and Logozzo, Francesco},
	title = {Automatic Inference of Necessary Preconditions},
	booktitle = {in Proceedings of the 14th Conference on Verification, Model Checking and Abstract Interpretation (VMCAI'13)},
	year = {2013},
	month = {January},
	abstract = {We consider the problem of automatic precondition inference. We argue that the common notion of sufficient precondition inference (i.e., under which precondition is the program correct?) imposes too large a burden on callers, and hence it is unfit for automatic program analysis. Therefore, we define the problem of necessary precondition inference (i.e., under which precondition, if violated, will the program always be incorrect?). We designed and implemented several new abstract interpretation-based analyses to infer atomic, disjunctive, universally and existentially quantified necessary preconditions.
	
	We experimentally validated the analyses on large scale industrial code. For unannotated code, the inference algorithms find necessary preconditions for almost 64% of methods which contained warnings. In 27% of these cases the inferred preconditions were also sufficient, meaning all warnings within the method body disappeared. For annotated code, the inference algorithms find necessary preconditions for over 68% of methods with warnings. In almost 50% of these cases the preconditions were also sufficient. Overall, the precision improvement obtained by precondition inference (counted as the additional number of methods with no warnings) ranged between 9% and 21%.},
	publisher = {Springer Verlag},
	url = {https://www.microsoft.com/en-us/research/publication/automatic-inference-of-necessary-preconditions/},
	edition = {in Proceedings of the 14th Conference on Verification, Model Checking and Abstract Interpretation (VMCAI'13)},
}

@article{viera2005understanding,
	title={Understanding interobserver agreement: the kappa statistic},
	author={Viera, Anthony J and Garrett, Joanne M and others},
	journal={Fam med},
	volume={37},
	number={5},
	pages={360--363},
	year={2005}
}

@article{10.1145/502059.502041, author = {Engler, Dawson and Chen, David Yu and Hallem, Seth and Chou, Andy and Chelf, Benjamin}, title = {Bugs as Deviant Behavior: A General Approach to Inferring Errors in Systems Code}, year = {2001}, issue_date = {December 2001}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {35}, number = {5}, issn = {0163-5980}, url = {https://doi.org/10.1145/502059.502041}, doi = {10.1145/502059.502041}, journal = {SIGOPS Oper. Syst. Rev.}, month = oct, pages = {57–72}, numpages = {16} }


@article{10.1109/2.161279, author = {Meyer, Bertrand}, title = {Applying ``Design by Contract"}, year = {1992}, issue_date = {October 1992}, publisher = {IEEE Computer Society Press}, address = {Washington, DC, USA}, volume = {25}, number = {10}, issn = {0018-9162}, url = {https://doi.org/10.1109/2.161279}, doi = {10.1109/2.161279}, journal = {Computer}, month = oct, pages = {40–51}, numpages = {12} }

@article{10.1145/1127878.1127884, author = {Leavens, Gary T. and Baker, Albert L. and Ruby, Clyde}, title = {Preliminary Design of {JML}: A Behavioral Interface Specification Language for {J}ava}, year = {2006}, issue_date = {May 2006}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {31}, number = {3}, issn = {0163-5948}, url = {https://doi.org/10.1145/1127878.1127884}, doi = {10.1145/1127878.1127884}, journal = {SIGSOFT Softw. Eng. Notes}, month = may, pages = {1–38}, numpages = {38} }

@article{10.1093/ptj/85.3.257,
	author = {Sim, Julius and Wright, Chris C},
	title = "{The Kappa Statistic in Reliability Studies: Use, Interpretation, and Sample Size Requirements}",
	journal = {Physical Therapy},
	volume = {85},
	number = {3},
	pages = {257-268},
	year = {2005},
	month = {03},
	abstract = "{Purpose. This article examines and illustrates the use and interpretation of the kappa statistic in musculoskeletal research. Summary of Key Points. The reliability of clinicians' ratings is an important consideration in areas such as diagnosis and the interpretation of examination findings. Often, these ratings lie on a nominal or an ordinal scale. For such data, the kappa coefficient is an appropriate measure of reliability. Kappa is defined, in both weighted and unweighted forms, and its use is illustrated with examples from musculoskeletal research. Factors that can influence the magnitude of kappa (prevalence, bias, and nonindependent ratings) are discussed, and ways of evaluating the magnitude of an obtained kappa are considered. The issue of statistical testing of kappa is considered, including the use of confidence intervals, and appropriate sample sizes for reliability studies using kappa are tabulated. Conclusions. The article concludes with recommendations for the use and interpretation of kappa.}",
	issn = {0031-9023},
	doi = {10.1093/ptj/85.3.257},
	url = {https://doi.org/10.1093/ptj/85.3.257},
	eprint = {https://academic.oup.com/ptj/article-pdf/85/3/257/31670498/ptj0257.pdf},
}

@article{10028142446,
	author="Glaser, B",
	title="Theoretical Sensitivity",
	journal="Advances in the Methodology of Grounded Theory",
	ISSN="",
	publisher="The Sociology Press",
	year="1978",
	month="",
	volume="",
	number="",
	pages="",
	URL="https://ci.nii.ac.jp/naid/10028142446/en/",
	DOI="",
}

@misc{stages,	
	author ={{Guo, Yufeng}},	
	title = {{7 Steps of ML}},	
	year =2017,
	url = "https://towardsdatascience.com/the-7-steps-of-machine-learning-2877d7e5548e",
	note = "Retrieved Aug 2020",	
}

@misc{pythonstaticchecker,	
	author={Lehtosalo, Jukka},
	title = {mypy},
	howpublished = {"http://mypy-lang.org/index.html"},
	url = {"http://mypy-lang.org/index.html"},
	note = {Retrieved Aug 2020},
	year = {2012}	
}

@inproceedings{guo2010characterizing,
	title={Characterizing and predicting which bugs get fixed: an empirical study of Microsoft Windows},
	author={Guo, Philip J and Zimmermann, Thomas and Nagappan, Nachiappan and Murphy, Brendan},
	booktitle={Proceedings of the 32Nd ACM/IEEE International Conference on Software Engineering-Volume 1},
	pages={495--504},
	year={2010}
}

@inproceedings{bugram,
	author = {Wang, Song and Chollak, Devin and Movshovitz-Attias, Dana and Tan, Lin},
	title = {Bugram: Bug Detection with n-{G}ram Language Models},
	year = {2016},
	isbn = {9781450338455},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2970276.2970341},
	doi = {10.1145/2970276.2970341},
	booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
	pages = {708–719},
	numpages = {12},
	keywords = {N-gram Language Model, Static Code Analysis, Bug Detection},
	location = {Singapore, Singapore},
	series = {ASE 2016}
}

@inproceedings{specmining,
	title={A pattern-based approach to parametric specification mining},
	author={Reger, Giles and Barringer, Howard and Rydeheard, David},
	booktitle={2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
	pages={658--663},
	year={2013},
	organization={IEEE}
}
@inproceedings{ltlmining,
	title={General {LTL} specification mining ({T})},
	author={Lemieux, Caroline and Park, Dennis and Beschastnikh, Ivan},
	booktitle={2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
	pages={81--92},
	year={2015},
	organization={IEEE}
}

@inproceedings{lemieux2015mining,
	title={Mining temporal properties of data invariants},
	author={Lemieux, Caroline},
	booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
	volume={2},
	pages={751--753},
	year={2015},
	organization={IEEE}
}

@inproceedings{jothimurugan2019composable,
	title={A Composable Specification Language for Reinforcement Learning Tasks},
	author={Jothimurugan, Kishor and Alur, Rajeev and Bastani, Osbert},
	booktitle={Advances in Neural Information Processing Systems},
	pages={13021--13030},
	year={2019}
}
@inproceedings{seshia2018formal,
	title={Formal specification for deep neural networks},
	author={Seshia, Sanjit A and Desai, Ankush and Dreossi, Tommaso and Fremont, Daniel J and Ghosh, Shromona and Kim, Edward and Shivakumar, Sumukh and Vazquez-Chanlatte, Marcell and Yue, Xiangyu},
	booktitle={International Symposium on Automated Technology for Verification and Analysis},
	pages={20--34},
	year={2018},
	organization={Springer}
}


@inproceedings{salento,
	author = {Murali, Vijayaraghavan and Chaudhuri, Swarat and Jermaine, Chris},
	title = {Bayesian Specification Learning for Finding {API} Usage Errors},
	year = {2017},
	isbn = {9781450351058},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3106237.3106284},
	doi = {10.1145/3106237.3106284},
	booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
	pages = {151–162},
	numpages = {12},
	keywords = {APIs, Anomaly Detection, Bug Finding, Specification Learning},
	location = {Paderborn, Germany},
	series = {ESEC/FSE 2017}
}

@inproceedings{deepspecs,
	author = {Le, Tien-Duy B. and Lo, David},
	title = {Deep Specification Mining},
	year = {2018},
	isbn = {9781450356992},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3213846.3213876},
	doi = {10.1145/3213846.3213876},
	booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
	pages = {106–117},
	numpages = {12},
	keywords = {Deep Learning, Specification Mining},
	location = {Amsterdam, Netherlands},
	series = {ISSTA 2018}
}

@ARTICLE{genprog,
	author={C. {Le Goues} and T. {Nguyen} and S. {Forrest} and W. {Weimer}},
	journal={IEEE Transactions on Software Engineering}, 
	title={{G}en{P}rog: A Generic Method for Automatic Software Repair}, 
	year={2012},
	volume={38},
	number={1},
	pages={54-72},}

@inproceedings{angelix,
	author = {Mechtaev, Sergey and Yi, Jooyong and Roychoudhury, Abhik},
	title = {Angelix: Scalable Multiline Program Patch Synthesis via Symbolic Analysis},
	year = {2016},
	isbn = {9781450339001},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2884781.2884807},
	doi = {10.1145/2884781.2884807},
	booktitle = {Proceedings of the 38th International Conference on Software Engineering},
	pages = {691–701},
	numpages = {11},
	keywords = {scalable semantics-based repair, angelic forest, program repair, multiline patch},
	location = {Austin, Texas},
	series = {ICSE ’16}
}

@inproceedings{spr,
	author = {Long, Fan and Rinard, Martin},
	title = {Staged Program Repair with Condition Synthesis},
	year = {2015},
	isbn = {9781450336758},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2786805.2786811},
	doi = {10.1145/2786805.2786811},
	booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
	pages = {166–178},
	numpages = {13},
	keywords = {Condition synthesis, Staged repair, Program repair},
	location = {Bergamo, Italy},
	series = {ESEC/FSE 2015}
}


@inproceedings{sbpr,
	author = {Tan, Shin Hwei and Yoshida, Hiroaki and Prasad, Mukul R. and Roychoudhury, Abhik},
	title = {Anti-Patterns in Search-Based Program Repair},
	year = {2016},
	isbn = {9781450342186},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2950290.2950295},
	doi = {10.1145/2950290.2950295},
	booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
	pages = {727–738},
	numpages = {12},
	keywords = {and repair, Debugging, fault localization},
	location = {Seattle, WA, USA},
	series = {FSE 2016}
}

@article{robillard2012automated,
	title={Automated {API} property inference techniques},
	author={Robillard, Martin P and Bodden, Eric and Kawrykow, David and Mezini, Mira and Ratchford, Tristan},
	journal={IEEE Transactions on Software Engineering},
	volume={39},
	number={5},
	pages={613--637},
	year={2012},
	publisher={IEEE}
}

@inproceedings{schiller2014case,
	title={Case studies and tools for contract specifications},
	author={Schiller, Todd W and Donohue, Kellen and Coward, Forrest and Ernst, Michael D},
	booktitle={Proceedings of the 36th International Conference on Software Engineering},
	pages={596--607},
	year={2014}
}
@inproceedings{notfind,
	author = {Cole, Brian and Hakim, Daniel and Hovemeyer, David and Lazarus, Reuven and Pugh, William and Stephens, Kristin},
	title = {Improving Your Software Using Static Analysis to Find Bugs},
	year = {2006},
	isbn = {159593491X},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1176617.1176667},
	doi = {10.1145/1176617.1176667},
	booktitle = {Companion to the 21st ACM SIGPLAN Symposium on Object-Oriented Programming Systems, Languages, and Applications},
	pages = {673–674},
	numpages = {2},
	keywords = {Java, FindBugs, static analysis},
	location = {Portland, Oregon, USA},
	series = {OOPSLA ’06}
}

@INPROCEEDINGS{8987482,
	author={T. {Zhang} and C. {Gao} and L. {Ma} and M. {Lyu} and M. {Kim}},
	booktitle={2019 IEEE 30th International Symposium on Software Reliability Engineering (ISSRE)}, 
	title={An Empirical Study of Common Challenges in Developing Deep Learning Applications}, 
	year={2019},
	volume={},
	number={},
	pages={104-115},
	doi={10.1109/ISSRE.2019.00020}}

@INPROCEEDINGS{6405249,
	author={Nasehi, Seyed Mehdi and Sillito, Jonathan and Maurer, Frank and Burns, Chris},
	booktitle={2012 28th IEEE International Conference on Software Maintenance (ICSM)}, 
	title={What makes a good code example?: A study of programming Q amp;A in StackOverflow}, 
	year={2012},
	volume={},
	number={},
	pages={25-34},
	doi={10.1109/ICSM.2012.6405249}}

@misc{pycontracturl,
	author = {Graham, Brett and Furr, William and Kuczmarski, Karol and Biskup, Bernhard and Palay, Adam},
	title = {PyContracts},
	year = 2010,
	howpublished = {https://andreacensi.github.io/contracts//},
	url ={https://andreacensi.github.io/contracts//},
	urldate = {2020-05-05}
}


@inproceedings{sankaran2017darviz,
	title={{DARVIZ}: deep abstract representation, visualization, and verification of deep learning models},
	author={Sankaran, Anush and Aralikatte, Rahul and Mani, Senthil and Khare, Shreya and Panwar, Naveen and Gantayat, Neelamadhav},
	booktitle={2017 IEEE/ACM 39th International Conference on Software Engineering: New Ideas and Emerging Technologies Results Track (ICSE-NIER)},
	pages={47--50},
	year={2017},
	organization={IEEE}
}

@inproceedings{dvijotham2019efficient,
title={Efficient neural network verification with exactness characterization},
author={Dvijotham, Krishnamurthy Dj and Stanforth, Robert and Gowal, Sven and Qin, Chongli and De, Soham and Kohli, Pushmeet},
booktitle={Proc. Uncertainty in Artificial Intelligence, UAI},
pages={164},
year={2019}
}

@inproceedings{nguyen2015graph,
	title={Graph-based statistical language model for code},
	author={Nguyen, Anh Tuan and Nguyen, Tien N},
	booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
	volume={1},
	pages={858--868},
	year={2015},
	organization={IEEE}
}

@inproceedings{dfaults,
	author = {Nargiz Humbatova and Gunel Jahangirova and Gabriele Bavota and Vincenzo Riccio and Andrea Stocco and Paolo Tonella},
	title = {Taxonomy of Real Faults in Deep Learning Systems},
	booktitle = {ICSE'20: The 42nd International Conference on Software Engineering},
	location = {Seoul, South Korea},
	month = {May 23-May 29, 2020},
	year = {2020},
	entrysubtype = {conference},
	abstract = {
	The growing application of deep neural networks in safety-critical domains makes the analysis of faults that occur in such systems of enormous importance. In this paper we introduce a large taxonomy of faults in deep learning (DL) systems. We have manually analysed 1059 artefacts gathered from GitHub commits and issues of projects that use the most popular DL frameworks (TensorFlow, Keras and PyTorch) and from related Stack Overflow posts. Structured interviews with 20 researchers and practitioners describing the problems they have encountered in their experience have enriched our taxonomy with a variety of additional faults that did not emerge from the other two sources. Our final taxonomy was validated with a survey involving an additional set of 21 developers, confirming that almost all fault categories (13/15) were experienced by at least 50% of the survey participants.
	}
}





@incollection{mendoza2019towards,
title={Towards automatically-tuned deep neural networks},
author={Mendoza, Hector and Klein, Aaron and Feurer, Matthias and Springenberg, Jost Tobias and Urban, Matthias and Burkart, Michael and Dippel, Maximilian and Lindauer, Marius and Hutter, Frank},
booktitle={Automated Machine Learning},
pages={135--149},
year={2019},
publisher={Springer}
}

@inproceedings{dlfix,
title={{DLF}ix: Context-based Code Transformation Learning for Automated Program Repair},
author={Li, Yi and Wang, Shaohua and Nguyen, Tien N.},
booktitle={ICSE'20: The 42nd International Conference on Software Engineering},
location = {Seoul, South Korea},
month = {May 23-May 29, 2020},
year = {2020},
entrysubtype = {conference}
}

@article{10.1145/363235.363259, author = {Hoare, C. A. R.}, title = {An Axiomatic Basis for Computer Programming}, year = {1969}, issue_date = {Oct. 1969}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {12}, number = {10}, issn = {0001-0782}, url = {https://doi.org/10.1145/363235.363259}, doi = {10.1145/363235.363259}, journal = {Commun. ACM}, month = oct, pages = {576–580}, numpages = {5}, keywords = {machine-independent programming, programming language design, axiomatic method, formal language definition, theory of programming’ proofs of programs, program documentation} }







@book{murphy2012machine,
	title={Machine learning: a probabilistic perspective},
	author={Murphy, Kevin P},
	year={2012},
	publisher={MIT press}
}

@book{Meyer88,
	Author =	 {Meyer, Bertrand},
	Title =	 {Object-oriented Software Construction},
	Publisher =	 {Prentice Hall},
	Address =	 {NY},
	Year =	 {1988},
	Annote =	 "The programming language Eiffel. 120 References."
}

@book{Manna-Pnueli92,
	Author =	 {Manna, Zohar and Pnueli, Amir},
	Title =	 {The Temporal Logic of Reactive and Concurrent Systems},
	Publisher =	 {SV},
	Year =	 {1992},
	Address = {NY},
	Annote =	 "Many references."
}


@inproceedings{zhang2019empirical,
	title={An empirical study of common challenges in developing deep learning applications},
	author={Zhang, Tianyi and Gao, Cuiyun and Ma, Lei and Lyu, Michael and Kim, Miryung},
	booktitle={2019 IEEE 30th International Symposium on Software Reliability Engineering (ISSRE)},
	pages={104--115},
	year={2019},
	organization={IEEE}
}

@incollection{leavens2022further,
  title={Further lessons from the JML project},
  author={Leavens, Gary T and Cok, David R and Nilizadeh, Amirfarhad},
  booktitle={The Logic of Software. A Tasting Menu of Formal Methods},
  pages={313--349},
  year={2022},
  publisher={Springer}
}

@INPROCEEDINGS{inferICSE,
  author={Pandita, Rahul and Xiao, Xusheng and Zhong, Hao and Xie, Tao and Oney, Stephen and Paradkar, Amit},
  booktitle={2012 34th International Conference on Software Engineering (ICSE)}, 
  title={Inferring method specifications from natural language API descriptions}, 
  year={2012},
  volume={},
  number={},
  pages={815-825},
  doi={10.1109/ICSE.2012.6227137}}
  
  @inproceedings{inferISTAA,
author = {Xie, Danning and Li, Yitong and Kim, Mijung and Pham, Hung Viet and Tan, Lin and Zhang, Xiangyu and Godfrey, Michael W.},
title = {DocTer: Documentation-Guided Fuzzing for Testing Deep Learning API Functions},
year = {2022},
isbn = {9781450393799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533767.3534220},
doi = {10.1145/3533767.3534220},
abstract = {Input constraints are useful for many software development tasks. For example, input constraints of a function enable the generation of valid inputs, i.e., inputs that follow these constraints, to test the function deeper. API functions of deep learning (DL) libraries have DL-specific input constraints, which are described informally in the free-form API documentation. Existing constraint-extraction techniques are ineffective for extracting DL-specific input constraints. To fill this gap, we design and implement a new technique—DocTer—to analyze API documentation to extract DL-specific input constraints for DL API functions. DocTer features a novel algorithm that automatically constructs rules to extract API parameter constraints from syntactic patterns in the form of dependency parse trees of API descriptions. These rules are then applied to a large volume of API documents in popular DL libraries to extract their input parameter constraints. To demonstrate the effectiveness of the extracted constraints, DocTer uses the constraints to enable the automatic generation of valid and invalid inputs to test DL API functions. Our evaluation on three popular DL libraries (TensorFlow, PyTorch, and MXNet) shows that DocTer’s precision in extracting input constraints is 85.4\%. DocTer detects 94 bugs from 174 API functions, including one previously unknown security vulnerability that is now documented in the CVE database, while a baseline technique without input constraints detects only 59 bugs. Most (63) of the 94 bugs are previously unknown, 54 of which have been fixed or confirmed by developers after we report them. In addition, DocTer detects 43 inconsistencies in documents, 39 of which are fixed or confirmed.},
booktitle = {Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {176–188},
numpages = {13},
keywords = {test generation, testing, text analytics, deep learning},
location = {Virtual, South Korea},
series = {ISSTA 2022}
}

@misc{reputationSO,	
	author ={{StackOverflow Reputation}},	
	title = {{StackOverflow Reputation and Moderation}},	
	year =2023,
	url = "https://stackoverflow.com/help/reputation",
	note = "Retrieved Jan 2023",	
}

@misc{SOsurvey,	
	author ={{StackOverflow Survey}},	
	title = {{Survey}},	
	year =2017,
	url = "https://survey.stackoverflow.co/2022/",
	note = "Retrieved Jan 2023",	
}