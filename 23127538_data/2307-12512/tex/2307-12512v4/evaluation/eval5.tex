\section{Evaluation}

% Figure environment removed


\name takes strides in achieving a few cm-scale localization in static and dynamic conditions. 
We rigorously test the system over eight different moving datasets and at multiple static points in various environments, including line-of-sight (LOS at Env-1 and 2) and non-line-of-sight (NLOS at Env-3) conditions as shown in Fig.~\ref{fig:eval-env}. 
To make the NLOS condition in Env-3, a wooden board 2.5 cm thick was placed 30 cm forward from the XRLoc anchor.
Additionally, we re-implement state-of-art AoA-based UWB localization system ULoc~\cite{zhao2021uloc} based on their open-source documentation. We place $3$ anchors in a diverse scenario, as a triangle in this space, and a constrained linear scenario, in a $1$ m straight line. We test ULoc with the same static and dynamic positions.  

% Figure environment removed

% Figure environment removed


\subsection{Static Localization Accuracy}\label{sec:static}

One of the key use cases targeted in \name is to provide accurate locations of real-world objects and place them in the virtual realm. These objects of interest could be tagged with inexpensive and long-lasting UWB tags, which will relay their location to the VR system. 
To simulate this use case, we place multiple tags in the environment with the simple goal of recreating a life-size chess game. 
In this static scenario, from Fig.~\ref{fig:eval-static}(a), we observe a median and $90^\mathrm{th}$ percentile error of $1.5$ cm and $5.5$ cm, respectively. 
We additionally observe \name provides a $9.5 \times$ and $4.0 \times$ improvement at the median over using ULoc in a linear (AoA-L) and diverse (AoA-D) placement scenario which have (median, $90^\mathrm{th}\%$) of (14.6 cm, 28.7 cm) and (6.1 cm, 13.7 cm), respectively. 
The evaluation of different ranges shows median errors of 6.8 cm and 15.2 cm at 4m and 5 m in the LOS condition, respectively, and 35.3 cm and 34.0 cm in the NLOS condition as shown in Fig.~\ref{fig:eval-static}(b).

\subsection{Moving Localization Accuracy}\label{sec:moving}

Continuing with the motivation of playing a life-size chess game, we characterize \name's localization accuracy in dynamic scenarios. Fig.~\ref{fig:eval-moving}(a) and ~\ref{fig:eval-moving}(b) showcase two characteristic movement patterns we tested. We tested $8$ movements, as shown in the demo video$^{\ref{fn:demo}}$, and achieved median and $90^\mathrm{th}$ errors of 2.4 cm and 5.3 cm, respectively, as shown in Fig.~\ref{fig:eval-moving}(c). We observe an $11 \times$ and $3.2 \times$ improvement at median over using ULoc in a linear (AoA-L) and diverse (AoA-D) placement scenario, which have (median, $90^\mathrm{th}\%$) of (26.0, 43.3  cm) and (7.5 cm, 17.4 cm), respectively. 

 In Fig.~\ref{fig:eval-moving}(d), we show the time-series error of localization for the `Fig.~\ref{fig:eval-moving}(b)' movement scenario (Fig.~\ref{fig:eval-moving}(c)). We note that opting to use a particle filter over a brute force approach provides a localization latency of $~1$ ms, compared to exhaustive grid search's latency of $~61.2$ s on a 12 Core CPU as explained in Sec.~\ref{sec:des-opt}. However, because the particle filter performs a sparse sampling over the entire space, \name may initialize the tag's location incorrectly. This is visible in the inset shown in Fig.~\ref{fig:eval-moving}(d). But, throughout $5$ received packets, we can see the location converges to the true location, and \name subsequently provides accurate location predictions. 



 
% Figure environment removed


\subsection{MAC Protocol Efficacy}

In the previous sections, we have shown \name can achieve a few-cm level localization from a single localization module, meeting the first two requirements (\textbf{R1} and \textbf{R2}). To allow multiple tags to be localized with this accuracy, \name leverages a LoRa side-channel to develop a power-efficient MAC protocol as described in Sec.~\ref{sec:des-mac}. To evaluate its efficacy, we set up $10$ tags to transmit at $100$ Hz for a half-hour period. Fig.~\ref{fig:eval-mac}(a) showcases the packet success ratio, and we find over $99.5\%$ of the packets are received by \name's localization module. Alternatively, when we do not have a MAC protocol, we have an average success rate of $~76\%$, ranging between $56\% - 87\%$. Specifically, considering the best and worst tag, we plot the packet arrival rate in Fig.~\ref{fig:eval-mac}(b) over the $30$ min period and observe there are large periods when packets from Tag 09 are not received, likely due to collision from either Tag 02 or any of the other tags in the environment. Alternatively, we see a consistent packet arrival rate using a MAC protocol. Clearly, a MAC protocol is necessary to achieve multi-tag tracking and localization at high rates and fulfill \textbf{R3}.


% Figure environment removed


\subsection{Justifying design choices}\label{sec:mb}

The evaluations from the previous sections prove \name's ability to fulfill the stringent requirements set for Sec.~\ref{sec:introduction}. In the following section, we will answer key questions about the design choices made when developing \name.

\noindent \textbf{TDoA and PDoA are both needed?:}
As we have discussed, a system relying purely on time-based measurements will not meet the stringent requirements of few-cm localization accuracy. We further evaluate this on our datasets in Fig.~\ref{fig:eval-mb}(a). We see a median localization accuracy of 2.4 cm, deviating over an order of magnitude from our few-cm level accuracy requirement. This re-iterates the challenge of achieving single-vantage point localization. 

However, we claimed in Sec.~\ref{sec:des-amb} TDoA measurements play an important role in ruling out ambiguous initialization caused by PDoA-only localization. To confirm this, we see in the same figure when PDoA is solely used for localization, and we have a median accuracy of 49.1 cm. Clearly, ambiguities from phase wrap-around can be detrimental to \name's performance, emphasizing TDoA's role. Through this micro-benchmark, it is apparent TDoA and PDoA work hand-in-hand to provide few-cm location accuracy.   

\noindent \textbf{How does the aperture effect the localization?:}
In Sec.~\ref{sec:des-res}, we discussed the importance of the antenna aperture in bringing resilience to phase measurement error. Consequently, a wider distance between the first and last antenna helps to improve localization accuracy. To ensure easy integration within everyday consumer electronics (like TVs or soundbars), we restrict \name's size to less than $1$ m wide. However, how important is antenna aperture to our localization performance? For this, we reduce the maximum antenna aperture to $80$, $60$, and $40$ cm and report the results in Fig.~\ref{fig:eval-mb}(b). Clearly, a reduction in the aperture size affects the localization accuracy, with median localization accuracy reducing to 9.6, 19.3, and 35.0 cm, respectively. In fact, we see a steep drop-off in accuracy when we have an aperture of $40$ cm. Furthermore, we see that a minimum aperture of $1$ m is required to achieve the required localization accuracy. Under space constraints, smaller apertures may be used at the cost of lower accuracy. 

\noindent \textbf{How many antennas are needed?:}
Clearly, a minimum aperture of $1$ m is needed. However, within this aperture, how many antennas are needed to meet the localization requirements? This is an important question to consider to make \name cost-effective. In the previous localization accuracy analysis, we consider an array with 6 antennas. In Fig.~\ref{fig:eval-mb}(c), we reduce the number of antennas placed within the $1$ m aperture. For 6, 5, and 4 antennas, we see the median location accuracy of 4.7, 6.9, and 28.7 cm, respectively. As few as 4 antennas are enough to meet the required few-cm localization accuracy at the median. Although, we observe a sharp reduction in localization accuracy in the $90^\mathrm{th}$ percentile. More antennas provide a better averaging effect and reduce erroneous TDoA and PDoA measurements, hence improving the localization performance at higher percentiles. From these experiments, we empirically observe choosing at least $6$ antennas meets the required few-cm level accuracy required for XR applications.  

\noindent \textbf{Are there better antenna spacing we can choose?:}
So far, we have considered placing our antennas in a uniform linear array (ULA), separated by $20$ cm. However, many works~\cite{vaidyanathan2010sparse, wang2014rf} showcase antenna patterns that are more optimal than a ULA. To investigate the improvements from these co-prime antenna arrays, we leverage our simulator from Sec.~\ref{sec:back} to carry out extensive simulations and showcase the results in Fig.~\ref{fig:eval-mb}(d). We see slight degradation of error when using co-prime arrays. However, co-prime arrays can be levered to reduce the number of antennas required by \name to achieve similar location accuracy.

% Figure environment removed

\noindent \textbf{Why do we need fine-grained bias compensation?:}
Finally, we evaluate the system-level measurements. In \name, we choose the appropriate clock sources to achieve the required accuracy in both TDoA and PDoA measurements (Sec.~\ref{im:clock}) and additionally calibrate for TDoA and PDoA hardware biases via a 3-point calibration scheme (Sec.~\ref{im:calib}). In Fig.~\ref{fig:eval-hw}(a), we showcase the importance of this bias calibration, observing median localization accuracy degrade by $1.8 \times$ to a median accuracy of 2.4 cm without applying appropriate bias calibration. In Fig.~\ref{fig:eval-hw}(b), we also observe an average TDoA error of $180.7$ ps and PDoA error of $8.2^\circ$.


