\section{Method}\label{sec:method}
%
We first introduce an Invertible scale-Conditional Function~(ICF) to design our self-supervised real-world single image super-resolution framework~(ICF-SRSR); then, we discuss our defined loss functions and the network architecture.
%
For convenience, we denote $X\in\mathbb{R}^{H\times W\times 3}$ as the input LR image with the arbitrary size of $H$ and $W$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Invertible scale-Conditional Function}
%
For a given input $X$, a conditional function $f(X|s)$ returns different outputs for different conditions $s$.
% 
In this paper, we design an Invertible scale-Conditional Function~(ICF) as a specific conditional function, which can act as an operation and the inverse operation for different scale conditions. 
%
Without losing generality, we consider $f$ as an image-to-image mapping and $s$ as an arbitrary scaling factor, respectively.
%
Then, we can resize an arbitrary image $X$ as follows:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
    X_s = f \left( X| s \right),
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
where $X_s \in \mathbb{R}^{sH \times sW \times 3}$ is a resized image.
%
Furthermore, for the same function $f$, we can get the original input $X$ again by the inverse scaling factor $\nicefrac{1}{s}$ as follows:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
    X = f \left( X_s|\nicefrac{1}{s} \right).
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Therefore, $f$ as an ICF can project an image to its arbitrary-scale representation and back-project it to the original input for the scale conditions $s$ and $\nicefrac{1}{s}$, respectively.
\cref{fig:framework_a} illustrates the concept of our ICF.
%
We note that if $s=\nicefrac{1}{s}=1$ the function is identity which implies $f(X|1)=X$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Self-supervised SISR using ICF}
%
One of the challenges in real-world SR is that we cannot acquire the ground-truth HR image for an arbitrary LR image.
%
To overcome this limitation, we develop a novel self-supervised SR framework, ICF-SRSR, based on the concept of ICF.
%
As shown in \cref{fig:framework_b}, our method can simultaneously super-resolve and down-sample the given LR image $X$ with different scale conditions $s$ and $\nicefrac{1}{s}$, without requiring any paired/unpaired LR-HR training samples.
%
Specifically, we first parameterize an ICF $f_\theta$ with CNNs and utilize its property to optimize the model.
%
Then, we repeatedly apply $f_\theta$ to an LR image $X$ with different scale conditions to acquire two outputs $\check{X}, \hat{X} \in \mathbb{R}^{H \times W \times 3}$ as follows:
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{equation}
    \begin{split}
        f_{\theta}(f_{\theta}(X|s)|\nicefrac{1}{s}) &= f_{\theta}(X_s|\nicefrac{1}{s})=\check{X}, \\
        f_{\theta}(f_{\theta}(X|\nicefrac{1}{s})|s) &= f_{\theta}(X_{\nicefrac{1}{s}}|s)=\hat{X},
    \end{split}
    \label{eq:icf}
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
where for $s>1$, $X_{s}\in \mathbb{R}^{sH \times sW \times 3}$ and $X_{\nicefrac{1}{s}} \in \mathbb{R}^{\nicefrac{H}{s} \times \nicefrac{W}{s} \times 3}$ are generated super-resolution~(SR) and low-low-resolution~(LLR) images, respectively.
%
For simplicity, we assume that both $\nicefrac{H}{s}$ and $\nicefrac{W}{s}$ are integers.
%

For an ideal ICF $f_\theta$, both $\check{X}$ and $\hat{X}$ in \cref{eq:icf} should be the same as the original LR image $X$. 
%
Therefore, we train $f_\theta$ in a self-supervised manner by reducing the distance between $X$ and the generated images $\check{X}$ and $\hat{X}$ in two stages simultaneously, as shown in \cref{fig:framework_b}.
%
In the up-down stage, we minimize the distance between $\check{X}$ and $X$.
%
By doing so, the network can learn to down-sample the generated SR image $X_s$ by restoring the output $\check{X}$ as the approximation of the original input $X$.
%
On the other hand, in the down-up stage, we aim to approximate the original input $X$ by reducing the distance between $\hat{X}$ and $X$.
%
Then, the network can learn to up-sample the generated LLR image $X_{\nicefrac{1}{s}}$.
%
Therefore, by leveraging the learned up-sampler and down-sampler applied on the generated images $X_{\nicefrac{1}{s}}$ and $X_s$, respectively, we can generate favorable SR and LLR images $X_s$ and $X_{\nicefrac{1}{s}}$ by employing the learned model $f_\theta$ on the input $X$ with the scale conditions $s$ and $\nicefrac{1}{s}$, respectively.
%

\input{tables/benchmark}
%
We also note that our method is different from CycleGAN~\cite{zhu2017unpaired}, which utilizes unpaired LR-HR images and performs two independent cycles, one on the LR and the other on the HR images.
%
Rather, our model is trained in a self-supervised manner by optimizing the $f_{\theta}$ jointly with two stages on LR images only, without requiring the adversarial loss.
%
In other words, $f_{\theta}$ can perform simultaneous up-sampling and down-sampling without requiring prior information or paired/unpaired data.
%
\input{sections/figures/b100}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Training loss functions}
%
\label{sec:loss}
%
To train the proposed ICF $f_{\theta}$, we design a set of self-supervised loss functions.
%
First, we formulate the consistency loss $\mathcal{L}^{\text{Cons}}$, which preserves information during the simultaneous up-down and down-up stages.
%
The proposed consistency loss $\mathcal{L}^\text{Cons}$ on the approximated LR images $\hat{X}$ and $\check{X}$, and the original input $X$ is defined as follows:
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}\label{eq:loss_cons}
\begin{split}
\mathcal{L}^{\text{Cons}} &=\lVert \hat{X}-X \rVert + \lVert \check{X}-X \rVert.
\end{split}
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
For simplicity, we use $\lVert\cdot\rVert$ to represent the L1 norm.
%
The proposed consistency term $\mathcal{L}^{\text{Cons}}$ guarantees to generate reliable up-sampled and down-sampled images simultaneously.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Furthermore, to stabilize the training and preserve colors between the input and intermediate images $X_s$ and $X_{\nicefrac{1}{s}}$, we utilize the low-frequency loss~\cite{son2021toward}.
%
We implement the low-pass filter with a spatial pooling operator $\mathbf{P} \left( \cdot, w, s \right)$, where $w$ and $s$ are window size and stride, respectively.
%
Our color-preserving loss $\mathcal{L}^\text{Color}$ is defined as follows:
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}\label{eq:loss_pool}
%\begin{aligned}
\begin{split}
\mathcal{L}^{\text{Color}} &= 
\lVert \mathbf{P} \left( X_s, 4s, 4s \right) - \mathbf{P} \left( X, 4, 4 \right) \rVert
\\ &+ \lVert \mathbf{P} \left( X_{\nicefrac{1}{s}}, 4, 4 \right) - \mathbf{P} \left( X, 4s, 4s \right) \rVert,
\end{split}
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
where the window size and stride are adjusted to match dimensions between each of $\left( X_s, X \right)$ and $\left( X_{\nicefrac{1}{s}}, X \right)$.
%
The total training objective $\mathcal{L}^{\text{Total}}$ is the combination of the aforementioned two loss terms, which is defined as follows: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}\label{eq:loss_total}
\mathcal{L}^{\text{Total}} = \mathcal{L}^{\text{Cons}}+\lambda_{\text{Color}}\mathcal{L}^{\text{Color}}.
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
\subsection{Network architecture}\label{sec:net_arch}
%
Our ICF-SRSR architecture leverages a single model to handle different scale conditions.
%
To implement the proposed method, we modify the existing SISR model, \eg, EDSR~\cite{lim2017enhanced} as our baseline backbone architecture.
%
Since the body part is invariant to the scale image (\ie, the input and output have the same resolution), we introduce multiple tail parts for different scale conditions.
%
Employing a single network with the shared body part is more efficient and can improve performance by observing more augmented data, \ie, images with different scales, during the training.
%
In the supplementary material, we provide the details of the network architecture and illustrate that our method is model-agnostic and can leverage different SOTA baseline models. 
%
We will also publish our ICF-SRSR implementation.
