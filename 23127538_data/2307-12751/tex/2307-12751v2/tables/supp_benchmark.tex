\renewcommand{\thetable}{S1}
\begin{table*}[t]
    \small
    \centering
    \begin{tabularx}{\linewidth}{c l >{\centering\arraybackslash}X >{\centering\arraybackslash}X >{\centering\arraybackslash}X >{\centering\arraybackslash}X
    >{\centering\arraybackslash}X 
    }
    \toprule
    \multirow{2}{*}{\textbf{Supervision}} & 
    \multirow{2}{*}{\bf Method} & 
    \textbf{Set5} & 
    \textbf{Set14} &
    \textbf{BSD100} &
    \textbf{Urban100} &
    \textbf{Manga109}\\
    & & $\times2$/$\times4$ & $\times2$/$\times4$ & $\times2$/$\times4$ & $\times2$/$\times4$ & $\times2$/$\times4$   \\
    
    
    \midrule
    & {\footnotesize Bicubic} & {0.929/0.810} & {0.868/0.702} & {0.843/0.667} & {0.840/0.657} & {0.933/0.789}  \\
    \midrule
    \multirow{8}{*}{Supervised}
    & {\footnotesize VDSR~\cite{kim2016accurate}} & {0.959/0.884} & {0.912/0.768} & {0.896/0.725} & {0.914/0.752} & {0.975/0.887}  \\
    & {\footnotesize EDSR~\cite{lim2017enhanced}} & {0.960/0.898} & {0.919/0.787} & {0.901/0.742} & {0.935/0.803} & {0.977/0.915}  \\
    & {\footnotesize CARN~\cite{ahn2018fast}} & {0.959/0.894} & {0.916/0.781} & {0.897/0.735} & {0.925/0.784} & {0.976/0.908}  \\
    & {\footnotesize RCAN~\cite{zhang2018image}} & {0.961/0.900} & {0.921/0.788} & {0.902/0.743} & {0.938/0.806} & {0.978/0.917} \\
    & {\footnotesize RDN~\cite{zhang2018residual}} & {0.961/0.899} & {0.921/0.787} & {0.901/0.741} & {0.935/0.802} & {0.978/0.915}  \\
    & {\footnotesize DRN-S~\cite{guo2020closed}} & {0.960/0.901} & {0.910/0.790} & {0.900/0.744} & {0.920/0.807} & \textbf{0.980}/{0.919}  \\
    & {\footnotesize LIIF~\cite{chen2021learning}} & {0.933/0.898} & {0.882/0.788} & {0.871/0.742} & {0.905/0.805} & {~~~~-~~~~/~~~~-~~~~}  \\
    &{\footnotesize ELAN~\cite{ELAN-light}} & \textbf{0.962}/\textbf{0.902} & \textbf{0.922}/\textbf{0.791} & \textbf{0.903}/\textbf{0.745} & \textbf{0.939}/\textbf{0.816} & {0.979}/\textbf{0.922} \\
    \midrule
    \multirow{3}{*}{Unsupervised} 
    & {\footnotesize SelfExSR~\cite{huang2015single}} & {0.953/0.861} & {0.903/0.751} & {0.885/0.710} & {0.897}/{0.740} & \textbf{0.968}/{0.718} \\
    & {\footnotesize ZSSR~\cite{shocher2018zero}}  & \textbf{0.957}/\textbf{0.879} & \textbf{0.910}/\textbf{0.765} & \textbf{0.892}/\textbf{0.721} & {0.894}/{0.682} & {0.957}/\textbf{0.813} \\
    &  {\footnotesize MZSR~\cite{soh2020meta}} &  {0.956/~~~~-~~~~} & {~~~~-~~~~/~~~~-~~~~} & {\textbf{0.892}/~~~~-~~~~} & {\textbf{0.909}/~~~~-~~~~} & {~~~~-~~~~/~~~~-~~~~}  \\
    \midrule
    \multirow{2}{*}{Self-supervised}
    & {\footnotesize \textbf{ICF-SRSR}~(Ours)} & {0.956/0.874} & {0.908/0.760} & {0.888/0.715} & {0.910/0.740} & {0.970/0.872}  \\
    & {\footnotesize \textbf{EDSR~(LLR,LR)}~(Ours)} & \textbf{0.957}/\textbf{0.876} & \textbf{0.909}/\textbf{0.763} & \textbf{0.889}/\textbf{0.717} & \textbf{0.911}/\textbf{0.745} & \textbf{0.971}/\textbf{0.876} \\ 
    \bottomrule
    \end{tabularx}
    
    \vspace{-2mm}
    \caption{
        \textbf{Quantitative comparisons of different methods on synthetic datasets by SSIM.} 
        %
        We compare our ICF-SRSR with several supervised and unsupervised methods on the five standard benchmark datasets~\cite{bevilacqua2012low, zeyde2010single, martin2001database, huang2015single, Manga109} on scales $\times 2$ and $\times 4$. 
        %
        ICF-SRSR refers to our self-supervised method, while EDSR~(LLR,LR) is the model EDSR trained on our generated pairs (LLR,LR) of the DIV2K dataset.
        %
        We also note that MZSR does not report SSIM for $\times 4$ SR in the original paper.
    }
    \label{tab:supp-benchmark}
    \vspace{-4mm}
\end{table*}

