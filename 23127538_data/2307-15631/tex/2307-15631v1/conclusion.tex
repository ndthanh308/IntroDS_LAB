\vspace{-10pt}

\section{Conclusion}
This paper investigates moral principles and their relation with toxicity in OSS.
Due to the use of domain-specific words and jargon, the majority of toxicity detection tools do not correctly identify toxic language in OSS. Therefore, there is a need to augment the current methods with informative features, and to gain a comprehensive understanding of the triggers of toxicity and its underlying causes.
In this work, we leverage a toxicity-labeled dataset of GitHub to analyze the key concepts of five moral principles and identify exhibited patterns in the dataset. We also mapped the nature of toxicity to the observed types of moral principles in each thread. Our findings revealed that \textit{Sanctity/Degradation} and \textit{Care/Harm} were the most frequently observed moral principles, and were often associated with insulting threads.
%In future work, we plan to develop automated tools to identify moral principles in OSS communications and further investigate the relationship between morality and toxicity.
Overall, our study represents an initial step towards a deeper understanding of the role of moral principles in shaping community dynamics in OSS, and we hope that it will inspire further research in this important area. Consistent with Miller et al.'s ~\cite{Miller2022} data distribution policy, we will share our annotated dataset upon request for research purposes.
% (available to reviewers on HotCRP)
%A recent study~\cite{Miller2022} in OSS found features such as insulting, arrogant, and unprofessional comments mostly prevalent to toxicity in OSS.
%In addition, previous studies showed that people's instant emotions and ideologies can be reflected in their use of language. Moral Foundations Theory captures the reactions of people. 
% We use an extended version of Moral Foundations Dictionary \cite{rezapour2019} to operationalize morality in text.
% SE communications are significantly different than other types of communications seen on other social platforms such as Twitter, Reddit, etc. Therefore, it is necessary for us to see how we can adapt the original definitions of morality to SE communications, especially the language used in \textit{toxic} SE communications.

%\textcolor{red}{ We use the key concepts of each morality principle to see if we can observe any patterns of morality in texts, and in the end, gather the patterns to get clear pictures of each of the principles in the SE domain. In addition, in each thread, we mapped the nature of toxicity to the observed type of moral principles. Based on our results, Sanctity/Degradation and Care/Harm are two of the most observed moral principles in our dataset, which are mainly mapped to insulting threads.}

%With definitions, we do not mean a new, enhanced version of Moral Foundation Theory. But rather, we intend to see how we can interpret moral values in the context of OSS. 
%SE communications are significantly different than other types of communications seen on other social platforms such as Twitter, Reddit, etc. Therefore, it is necessary for us to see how we can adapt the original definitions of morality to SE communications, especially the language used in \textit{toxic} SE communications as we are trying to understand the connection between toxicity and morality. We use the key concepts of each morality type to see if we can observe any patterns in the dataset. Then, we use these patterns to come up with SE-adapted definitions of morality. 
%In this section, we explain these patterns for the 5 moral foundations. It should be noted that detecting morality even in social contexts such as Twitter is a hard task, mostly in the sense of distinguishing types of morality from each other. Because of this very reason, Hoover et. al. \cite{hooverMoral2020} allow for overlapping labels (expressions of moral sentiment that are associated with multiple foundations) during the annotation process for morality detection in the Twitter corpus. We did our best to come up with clear definitions for each type of morality in the domain of SE.


% It should be noted that detecting morality even in social contexts such as Twitter is a hard task, mostly in the sense of distinguishing types of morality from each other~\cite{hooverMoral2020}. We did our best to come up with clear definitions for each type of morality in the domain of SE.

