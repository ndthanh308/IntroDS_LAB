@inproceedings{10.1145/3278721.3278729,
author = {Dixon, Lucas and Li, John and Sorensen, Jeffrey and Thain, Nithum and Vasserman, Lucy},
title = {Measuring and Mitigating Unintended Bias in Text Classification},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278721.3278729},
doi = {10.1145/3278721.3278729},
abstract = {We introduce and illustrate a new approach to measuring and mitigating unintended bias in machine learning models. Our definition of unintended bias is parameterized by a test set and a subset of input features. We illustrate how this can be used to evaluate text classifiers using a synthetic test set and a public corpus of comments annotated for toxicity from Wikipedia Talk pages. We also demonstrate how imbalances in training data can lead to unintended bias in the resulting models, and therefore potentially unfair applications. We use a set of common demographic identity terms as the subset of input features on which we measure bias. This technique permits analysis in the common scenario where demographic information on authors and readers is unavailable, so that bias mitigation must focus on the content of the text itself. The mitigation method we introduce is an unsupervised approach based on balancing the training dataset. We demonstrate that this approach reduces the unintended bias without compromising overall model quality.},
booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {67–73},
numpages = {7},
keywords = {fairness, text classification, machine learning, natural language processing, algorithmic bias},
location = {New Orleans, LA, USA},
series = {AIES '18}
}

@misc{PewResearch,
  author={Maeve Duggan},
  title={\url{https://www.pewresearch.org/internet/2017/07/11/online-harassment-2017/}},
  year={2017}
 }
 
 @misc{DecisionLab,
  author={The Decision Lab},
  title={https://thedecisionlab.com/insights/health/tdl-brief-online-toxicity},
  year={2017}
 }
 https://thedecisionlab.com/insights/health/tdl-brief-online-toxicity
 
  @article{trolling, title={Trolling in asynchronous computer-mediated communication: From user discussions to academic definitions}, volume={6}, ISSN={1613-4877}, url={https://www.degruyter.com/document/doi/10.1515/jplr.2010.011/html}, DOI={10.1515/jplr.2010.011}, abstractNote={Whilst computer-mediated communication (CMC) can benefit users by providing quick and easy communication between those separated by time and space, it can also provide varying degrees of anonymity that may encourage a sense of impunity and freedom from being held accountable for inappropriate online behaviour. As such, CMC is a fertile ground for studying impoliteness, whether it occurs in response to perceived threat (flaming), or as an end in its own right (trolling). Currently, first and second-order definitions of terms such as im/politeness (Brown and Levinson, Politeness: Some universals in language use, Cambridge University Press, 1987; Bousfield, Impoliteness in interaction, John Benjamins, 2008; Culpeper, Reflections on impoliteness, relational work and power, Mouton de Gruyter, 2008; Terkourafi, Towards a unified theory of politeness, impoliteness, and rudeness, Mouton de Gruyter, 2008), in-civility (Lakoff, Civility and its discontents: Or, getting in your face, John Benjamins, 2005), rudeness (Beebe, Polite fictions: Instrumental rudeness as pragmatic competence, Georgetown University Press, 1995, Kienpointner, Functions of Language 4: 251–287, 1997, Kienpointner, Journal of Politeness Research 4: 243–265, 2008), and etiquette (Coulmas, Linguistic etiquette in Japanese society, Mouton de Gruyter, 1992), are subject to much discussion and debate, yet the CMC phenomenon of trolling is not adequately captured by any of these terms. Following Bousfield (in press), Culpeper (Impoliteness: Using language to cause offence, Cambridge University Press, 2010) and others, this paper suggests that a definition of trolling should be informed first and foremost by user discussions. Taking examples from a 172-million-word, asynchronous CMC corpus, four interrelated conditions of aggression, deception, disruption, and success are discussed. Finally, a working definition of trolling is presented.}, number={2}, publisher={De Gruyter Mouton}, author={Hardaker, Claire}, year={2010}, month={Jul}, pages={215–242}, language={en} }

 
 @article{Anderson, title={Toxic Talk: How Online Incivility Can Undermine Perceptions of Media}, volume={30}, ISSN={0954-2892}, url={https://doi.org/10.1093/ijpor/edw022}, DOI={10.1093/ijpor/edw022}, abstractNote={Scholars are increasingly concerned with the potential for uncivil discourse to enhance political polarization in society (Mutz, 2006; Stryker, 2011). Political elites and partisans boost levels of incivility in news media (Muddiman, 2013), and people perceive higher levels of incivility in politics when individuals rather than issues are attacked (Stryker, Conway, &amp; Danielson, 2014). The concerns over incivility extend to the online information environment, where nasty comments can harm healthy back-and-forth dialogue central to democracy that often happens in spaces such as newspapers (Coe, Kenski, &amp; Rains, 2014; Meltzer, 2015). Early research shows that incivility in online comments can be a polarizing factor in how people perceive issues in media, particularly for individuals who hold stronger opinions before seeing the comments (Anderson, Brossard, Scheufele, Xenos, &amp; Ladwig, 2014). In particular, incivility has been found to affect people’s perceptions of the content covered in news articles, a phenomenon dubbed the “nasty effect” (Anderson et al., 2014). It can also increase the perception that individuals in society hold polarized attitudes (Hwang, Kim, &amp; Huh, 2014). Yet, we still do not fully understand how incivility in comments affects perceptions of the news stories themselves or the effect it can have on lines of political polarity in society.}, number={1}, journal={International Journal of Public Opinion Research}, author={Anderson, Ashley A and Yeo, Sara K and Brossard, Dominique and Scheufele, Dietram A and Xenos, Michael A}, year={2016}, month={Aug}, pages={156–168} }


@misc{GooglePerspective,
  author={Google Perspective API},
  title={https://www.perspectiveapi.com/},
  year={accessed Aug, 2022}
 }

@misc{Jigsaw,
  author={Google Jigsaw},
  title={\url{https://jigsaw.google.com/the-current/toxicity/}},
  year={accessed Aug, 2022}
 }

@article{conduct,
author = {Li, Renee and Pandurangan, Pavitthra and Frluckaj, Hana and Dabbish, Laura},
title = {Code of Conduct Conversations in Open Source Software Projects on Github},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
url = {https://doi.org/10.1145/3449093},
doi = {10.1145/3449093},
abstract = {The rapid growth of open source software necessitates a deeper understanding of moderation and governance methods currently used within these projects. The code of conduct, a set of rules articulating standard behavior and responsibilities for participation within a community, is becoming an increasingly common policy document in open source software projects for setting project norms of behavior and discouraging negative or harassing comments and conversation. This study describes the conversations around adopting and crafting a code of conduct as well as those utilizing code of conduct for community governance. We conduct a qualitative analysis of a random sample of GitHub issues that involve the code of conduct. We find that codes of conduct are used both proactively and reactively to govern community behavior in project issues. Oftentimes, the initial addition of a code of conduct does not involve much community participation and input. However, a controversial moderation act is capable of inciting mass community feedback and backlash. Project maintainers balance the tension between disciplining potentially offensive forms of speech and encouraging broad and inclusive participation. These results have implications for the design of inclusive and effective governance practices for open source software communities.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {19},
numpages = {31},
keywords = {open source software, collaboration}
}

@article{heated_discussions,
author = {Ferreira, Isabella and Adams, Bram and Cheng, Jinghui},
title = {How heated is it? Understanding GitHub locked issues},
year = {2022},
booktitle={19th International Conference on Mining Software Repositories}
}

@article{incivility,
author = {Ferreira, Isabella and Cheng, Jinghui and Adams, Bram},
title = {The "Shut the F**k up" Phenomenon: Characterizing Incivility in Open Source Code Review Discussions},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3479497},
doi = {10.1145/3479497},
abstract = {Code review is an important quality assurance activity for software development. Code review discussions among developers and maintainers can be heated and sometimes involve personal attacks and unnecessary disrespectful comments, demonstrating, therefore, incivility. Although incivility in public discussions has received increasing attention from researchers in different domains, the knowledge about the characteristics, causes, and consequences of uncivil communication is still very limited in the context of software development, and more specifically, code review. To address this gap in the literature, we leverage the mature social construct of incivility as a lens to understand confrontational conflicts in open source code review discussions. For that, we conducted a qualitative analysis on 1,545 emails from the Linux Kernel Mailing List (LKML) that were associated with rejected changes. We found that more than half (66.66\%) of the non-technical emails included uncivil features. Particularly, frustration, name calling, and impatience are the most frequent features in uncivil emails. We also found that there are civil alternatives to address arguments, while uncivil comments can potentially be made by any people when discussing any topic. Finally, we identified various causes and consequences of such uncivil communication. Our work serves as the first study about the phenomenon of in(civility) in open source software development, paving the road for a new field of research about collaboration and communication in the context of software engineering activities.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {353},
numpages = {35},
keywords = {online communities, open source, code review, incivility, communication, civility}
}

@misc{so_bot,
  title={https://stackoverflow.blog/2020/04/09/the-unfriendly-robot-automatically-flagging-unwelcoming-comments/},
  author={The Unfriendly Robot Automatically Flagging Unwelcoming Comments},
  note={accessed April, 2022}
 }

@inproceedings{Lees2021CapturingCT,
  title={Capturing Covertly Toxic Speech via Crowdsourcing},
  author={Alyssa Lees and Daniel Borkan and Ian D. Kivlichan and Jorge Nario and Tesh Goyal},
  booktitle={HCINLP},
  year={2021}
}

@INPROCEEDINGS{9793879,  author={Qiu, Huilian Sophie and Vasilescu, Bogdan and Kästner, Christian and Egelman, Carolyn and Jaspan, Ciera and Murphy-Hill, Emerson},  booktitle={2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS)},   title={Detecting Interpersonal Conflict in Issues and Code Review: Cross Pollinating Open- and Closed-Source Approaches},   year={2022},  volume={},  number={},  pages={41-55},  doi={10.1109/ICSE-SEIS55304.2022.9793879}}

@misc{morality_hate_2021,
 title={Morally Homogeneous Networks and Radicalism},
 url={psyarxiv.com/h3udp},
 DOI={10.1177/19485506211059329},
 publisher={PsyArXiv},
 author={Atari, Mohammad and Davani, Aida M and Kogon, Drew and Kennedy, Brendan and Saxena, Nripsuta A and Anderson, Ian A and Dehghani, Morteza},
 year={2021},
 month={Jan}
}

@misc{morality_hate_2018,
 title={The psychology of hate:  Moral concerns differentiate hate from dislike},
 url={psyarxiv.com/x9y2p},
 DOI={10.31234/osf.io/x9y2p},
 publisher={PsyArXiv},
 author={Pretus, Clara and Ray, Jennifer L and Granot, Yael and Cunningham, William A and Van Bavel, Jay J},
 year={2018},
 month={Jun}
}

@inproceedings{offensive,
author = {Xiang, Guang and Fan, Bin and Wang, Ling and Hong, Jason and Rose, Carolyn},
title = {Detecting Offensive Tweets via Topical Feature Discovery over a Large Scale Twitter Corpus},
year = {2012},
isbn = {9781450311564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396761.2398556},
doi = {10.1145/2396761.2398556},
abstract = {In this paper, we propose a novel semi-supervised approach for detecting profanity-related offensive content in Twitter. Our approach exploits linguistic regularities in profane language via statistical topic modeling on a huge Twitter corpus, and detects offensive tweets using automatically these generated features. Our approach performs competitively with a variety of machine learning (ML) algorithms. For instance, our approach achieves a true positive rate (TP) of 75.1% over 4029 testing tweets using Logistic Regression, significantly outperforming the popular keyword matching baseline, which has a TP of 69.7%, while keeping the false positive rate (FP) at the same level as the baseline at about 3.77%. Our approach provides an alternative to large scale hand annotation efforts required by fully supervised learning approaches.},
booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
pages = {1980–1984},
numpages = {5},
keywords = {topic modeling, twitter, machine learning, hadoop},
location = {Maui, Hawaii, USA},
series = {CIKM '12}
}

@book{cyberbullying,
author = {Kowalski, Robin M. and Limber, Susan P. and Agatston, Patricia W.},
title = {Cyberbullying: Bullying in the Digital Age},
year = {2012},
isbn = {1444334816},
publisher = {Wiley Publishing},
edition = {2nd},
abstract = {Psychologists explore the reality of cyberbulliesMillions of children are affected by bullies each year. Advances in social media, email, instant messaging, and cell phones, however, have moved bullying from a schoolyard fear to a constant threat. The second edition of Cyberbullying offers the most current information on this constantly-evolving issue and outlines the unique concerns and challenges it raises for children, parents, and educators. Authored by psychologists who are internationally recognized as experts in this field, the text uses the latest research in this area to provide an updated, reliable text ideal for parents and educators concerned about the cyberbullying phenomenon.}
}

@article{Silva2016AnalyzingTT,
  title={Analyzing the Targets of Hate in Online Social Media},
  author={Leandro Ara{\'u}jo Silva and Mainack Mondal and Denzil Correa and Fabr{\'i}cio Benevenuto and Ingmar Weber},
  journal={ArXiv},
  year={2016},
  volume={abs/1603.07709}
}

@article{Chaudhary2021CounteringOH,
  title={Countering Online Hate Speech: An NLP Perspective},
  author={Mudit Chaudhary and Chandni Saxena and Helen M. Meng},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.02941}
}

@inproceedings{Vigna2017HateMH,
  title={Hate Me, Hate Me Not: Hate Speech Detection on Facebook},
  author={Fabio Del Vigna and Andrea Cimino and Felice Dell’Orletta and Marinella Petrocchi and Maurizio Tesconi},
  booktitle={ITASEC},
  year={2017}
}

 @article{Suler_2004, title={The online disinhibition effect}, volume={7}, ISSN={1094-9313}, DOI={10.1089/1094931041291295}, abstractNote={While online, some people self-disclose or act out more frequently or intensely than they would in person. This article explores six factors that interact with each other in creating this online disinhibition effect: dissociative anonymity, invisibility, asynchronicity, solipsistic introjection, dissociative imagination, and minimization of authority. Personality variables also will influence the extent of this disinhibition. Rather than thinking of disinhibition as the revealing of an underlying “true self,” we can conceptualize it as a shift to a constellation within self-structure, involving clusters of affect and cognition that differ from the in-person constellation.}, number={3}, journal={Cyberpsychology \& Behavior: The Impact of the Internet, Multimedia and Virtual Reality on Behavior and Society}, author={Suler, John}, year={2004}, month={Jun}, pages={321–326}, language={eng} }

@inproceedings{StanfordPoliteness,
  title={A computational approach to politeness with application to social factors},
  author={Cristian Danescu-Niculescu-Mizil and Moritz Sudhof and Daniel Jurafsky and Jure Leskovec and Christopher Potts},
  booktitle={ACL},
  year={2013}
}

@article{Sarker2020ABS,
  title={A Benchmark Study of the Contemporary Toxicity Detectors on Software Engineering Interactions},
  author={Jaydeb Sarker and Asif Kamal Turzo and Amiangshu Bosu},
  journal={2020 27th Asia-Pacific Software Engineering Conference (APSEC)},
  year={2020},
  pages={218-227}
}

@inproceedings{Raman2020,
author = {Raman, Naveen and Cao, Minxuan and Tsvetkov, Yulia and K\"{a}stner, Christian and Vasilescu, Bogdan},
title = {Stress and Burnout in Open Source: Toward Finding, Understanding, and Mitigating Unhealthy Interactions},
year = {2020},
isbn = {9781450371261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377816.3381732},
doi = {10.1145/3377816.3381732},
abstract = {Developers from open-source communities have reported high stress levels from frequent demands for features and bug fixes and from the sometimes aggressive tone of these demands. Toxic conversations may demotivate and burn out developers, creating challenges for sustaining open source. We outline a path toward finding, understanding, and possibly mitigating such unhealthy interactions. We take a first step toward finding them, by developing and demonstrating a measurement instrument (an SVM classifier tailored for software engineering) to detect toxic discussions in GitHub issues. We used our classifier to analyze trends over time and in different GitHub communities, finding that toxicity varies by community and that toxicity decreased between 2012 and 2018.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {57–60},
numpages = {4},
location = {Seoul, South Korea},
series = {ICSE-NIER '20}
}

@INPROCEEDINGS{Miller2022,  author={Miller, Courtney and Cohen, Sophie and Klug, Daniel and Vasilescu, Bogdan and Kästner, Christian},  booktitle={2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)},   title={“Did You Miss My Comment or What?” Understanding Toxicity in Open Source Discussions},   year={2022},  volume={},  number={},  pages={710-722},  doi={10.1145/3510003.3510111}}

@article{Avelino2016ANA,
  title={A novel approach for estimating Truck Factors},
  author={Guilherme Avelino and Leonardo Teixeira Passos and Andr{\'e} C. Hora and Marco T{\'u}lio Valente},
  journal={2016 IEEE 24th International Conference on Program Comprehension (ICPC)},
  year={2016},
  pages={1-10}
}

@article{oss_women,
author = {Dawn Nafus},
title ={‘Patches don’t have gender’: What is not open in open source software},
journal = {New Media \& Society},
volume = {14},
number = {4},
pages = {669-683},
year = {2012},
doi = {10.1177/1461444811422887},

URL = { 
        https://doi.org/10.1177/1461444811422887
    
},
eprint = { 
        https://doi.org/10.1177/1461444811422887
    
}
,
    abstract = { While open source software development promises a fairer, more democratic model of software production often compared to a gift economy, it also is far more male dominated than other forms of software production. The specific ways F/LOSS instantiates notions of openness in everyday practice exacerbates the exclusion of women. ‘Openness’ is a complex construct that affects more than intellectual property arrangements. It weaves together ideas about authorship, agency, and the circumstances under which knowledge and code can and cannot be exchanged. While open source developers believe technology is orthogonal to the social, notions of openness tie the social to the technical by separating persons from one another and relieving them of obligations that might be created in the course of other forms of gift exchange. In doing so, men monopolize code authorship and simultaneously de-legitimize the kinds of social ties necessary to build mechanisms for women’s inclusion. }
}

@ARTICLE{oss_diversity,  author={Albusays, Khaled and Bjorn, Pernille and Dabbish, Laura and Ford, Denae and Murphy-Hill, Emerson and Serebrenik, Alexander and Storey, Margaret-Anne},  journal={IEEE Software},   title={The Diversity Crisis in Software Development},   year={2021},  volume={38},  number={2},  pages={19-25},  doi={10.1109/MS.2020.3045817}}

@article{qiu19,
author = {Qiu, Huilian Sophie and Li, Yucen Lily and Padala, Susmita and Sarma, Anita and Vasilescu, Bogdan},
title = {The Signals That Potential Contributors Look for When Choosing Open-Source Projects},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359224},
doi = {10.1145/3359224},
abstract = {While open-source software has become ubiquitous, its sustainability is in question: without a constant supply of contributor effort, open-source projects are at risk. While prior work has extensively studied the motivations of open-source contributors in general, relatively little is known about how people choose which project to contribute to, beyond personal interest. This question is especially relevant in transparent social coding environments like GitHub, where visible cues on personal profile and repository pages, known as signals, are known to impact impression formation and decision making. In this paper, we report on a mixed-methods empirical study of the signals that influence the contributors' decision to join a GitHub project. We first interviewed 15 GitHub contributors about their project evaluation processes and identified the important signals they used, including the structure of the README and the amount of recent activity. Then, we proceeded quantitatively to test out the impact of each signal based on the data of 9,977 GitHub projects. We reveal that many important pieces of information lack easily observable signals, and that some signals may be both attractive and unattractive. Our findings have direct implications for open-source maintainers and the design of social coding environments, e.g., features to be added to facilitate better project searching experience.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {122},
numpages = {29},
keywords = {signaling theory, open-source software, github}
}

@inproceedings{Igor15,
author = {Steinmacher, Igor and Conte, Tayana and Gerosa, Marco Aur\'{e}lio and Redmiles, David},
title = {Social Barriers Faced by Newcomers Placing Their First Contribution in Open Source Software Projects},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675133.2675215},
doi = {10.1145/2675133.2675215},
abstract = {Newcomers' seamless onboarding is important for online communities that depend upon leveraging the contribution of outsiders. Previous studies investigated aspects of the joining process and motivation in open collaboration communities, but few have focused on identifying and understanding the critical barriers newcomers face when placing their first contribution, a period that frequently leads to dropout. This is important for Open Source Software (OSS) projects, which receive contributions from many one-time contributors. Focusing on OSS, our study qualitatively analyzed social barriers that hindered newcomers' first contributions. We defined a conceptual model composed of 58 barriers including 13 social barriers. The barriers were identified from a qualitative data analysis considering different sources: a systematic literature review; open question responses gathered from OSS projects' contributors; students contributing to OSS projects; and semi-structured interviews with 36 developers from 14 different projects. This paper focuses on social barriers and its contributions include gathering empirical evidence of the barriers faced by newcomers, organizing and better understanding these barriers, surveying the literature from the perspective of the barriers, and identifying new potential research streams.},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
pages = {1379–1392},
numpages = {14},
keywords = {newcomers, open collaboration, qualitative study, joining, online communities, socialization, open source software, new contributor, entry, onboarding, social barriers, barriers},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}

@inproceedings{mcdonald2013performance,
    author = {McDonald, Nora and Goggins, Sean},
    title = {Performance and Participation in Open Source Software on GitHub},
    year = {2013},
    booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
    pages = {139–144},
    numpages = {6},
    keywords = {performance, social computing, open source software},
    location = {Paris, France},
    series = {CHI EA '13}
}

@article{cerpa2010evaluating,
    author = {Cerpa, Narciso and Bardeen, Matthew and Kitchenham, Barbara and Verner, June},
    title = {Evaluating Logistic Regression Models to Estimate Software Project Outcomes},
    year = {2010},
    issue_date = {September, 2010},
    publisher = {Butterworth-Heinemann},
    address = {USA},
    volume = {52},
    number = {9},
    issn = {0950-5849},
    journal = {Information and Software Technology},
    month = sep,
    pages = {934–944},
    numpages = {11}
}

@INPROCEEDINGS{zanetti2013riseandfall,
  author={Zanetti, Marcelo Serrano and Scholtes, Ingo and Tessone, Claudio Juan and Schweitzer, Frank},
  booktitle={2013 6th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE)}, 
  title={The rise and fall of a central contributor: Dynamics of social organization and performance in the GENTOO community}, 
  year={2013},
  volume={},
  number={},
  pages={49-56},
  doi={10.1109/CHASE.2013.6614731}
}

@inproceedings{coelho2017why,
    author = {Coelho, Jailton and Valente, Marco Tulio},
    title = {Why Modern Open Source Projects Fail},
    year = {2017},
    isbn = {9781450351058},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
    pages = {186–196},
    numpages = {11},
    keywords = {GitHub, Open Source Software, Project failure},
    location = {Paderborn, Germany},
    series = {ESEC/FSE 2017}
}

@INPROCEEDINGS{tourani2018code,
  author={Tourani, Parastou and Adams, Bram and Serebrenik, Alexander},
  booktitle={2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Code of conduct in open source projects}, 
  year={2017},
  volume={},
  number={},
  pages={24-33},
  doi={10.1109/SANER.2017.7884606}
}

@misc{yin2021sustainability,
      title={Sustainability Forecasting for Apache Incubator Projects}, 
      author={Likang Yin and Zhunagzhi Chen and Qi Xuan and Vladimir Filkov},
      year={2021},
      eprint={2105.14252},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@INPROCEEDINGS{7476635,
  author={Pinto, Gustavo and Steinmacher, Igor and Gerosa, Marco Aurélio},
  booktitle={2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)}, 
  title={More Common Than You Think: An In-depth Study of Casual Contributors}, 
  year={2016},
  volume={1},
  number={},
  pages={112-123},
  doi={10.1109/SANER.2016.68}}
  
@INPROCEEDINGS{9402044,
  author={Gerosa, Marco and Wiese, Igor and Trinkenreich, Bianca and Link, Georg and Robles, Gregorio and Treude, Christoph and Steinmacher, Igor and Sarma, Anita},
  booktitle={2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)}, 
  title={The Shifting Sands of Motivation: Revisiting What Drives Contributors in Open Source}, 
  year={2021},
  volume={},
  number={},
  pages={1046-1058}}
  
@InProceedings{Hannemann2014,
author="Hannemann, Anna
and Liiva, Kristjan
and Klamma, Ralf",
editor="Corral, Luis
and Sillitti, Alberto
and Succi, Giancarlo
and Vlasenko, Jelena
and Wasserman, Anthony I.",
title="Navigation Support in Evolving Open-Source Communities by a Web-Based Dashboard",
booktitle="Open Source Software: Mobile Open Source Technologies",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="11--20",
abstract="The co-evolution of communities and systems in open-source software (OSS) projects is an established research topic. There are plenty of different studies of OSS community and system evolution available. However, most of the existing OSS project visualization tools provide source code oriented metrics with little support for communities. At the same time, self-reflection helps OSS community members to understand what is happening within their community. Considering missing community-centered OSS visualizations, we investigated the following research question: Are the OSS communities interested in a visualization platform, which reflects community evolution? If so, what aspects should it reflect?",
isbn="978-3-642-55128-4"
}

@INPROCEEDINGS{sean_p_goggins_2021_4627236,
  author={Goggins, Sean and Lumbard, Kevin and Germonprez, Matt},
  booktitle={2021 IEEE/ACM 4th International Workshop on Software Health in Projects, Ecosystems and Communities (SoHeal)}, 
  title={Open Source Community Health: Analytical Metrics and Their Corresponding Narratives}, 
  year={2021},
  volume={},
  number={},
  pages={25-33},
  doi={10.1109/SoHeal52568.2021.00010}}
  
@misc{dotnet_toxic,
    author={Use movups instead of movdqu in block op codegen},
    title={https://github.com/dotnet/runtime/pull/1367},
    note={accessed April, 2022}
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={the Journal of machine Learning research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR. org}
}

@article{reid2022bad,
  title={“Bad Vibrations”: Sensing Toxicity From In-Game Audio Features},
  author={Reid, Elizabeth and Mandryk, Regan and Beres, Nicole A and Klarkowski, Madison and Frommel, Julian},
  journal={IEEE Transactions on Games},
  year={2022},
  publisher={IEEE}
}

@article{shen2020viral,
  title={Viral vitriol: Predictors and contagion of online toxicity in World of Tanks},
  author={Shen, Cuihua and Sun, Qiusi and Kim, Taeyoung and Wolff, Grace and Ratan, Rabindra and Williams, Dmitri},
  journal={Computers in Human Behavior},
  volume={108},
  pages={106343},
  year={2020},
  publisher={Elsevier}
}
@inproceedings{neto2017studying,
  title={Studying toxic behavior influence and player chat in an online video game},
  author={Neto, Joaquim AM and Yokoyama, Kazuki M and Becker, Karin},
  booktitle={Proceedings of the international conference on web intelligence},
  pages={26--33},
  year={2017}
}

@inproceedings{martens2015toxicity,
  title={Toxicity detection in multiplayer online games},
  author={M{\"a}rtens, Marcus and Shen, Siqi and Iosup, Alexandru and Kuipers, Fernando},
  booktitle={2015 International Workshop on Network and Systems Support for Games (NetGames)},
  pages={1--6},
  year={2015},
  organization={IEEE}
}

@inproceedings{kwak2015exploring,
  title={Exploring cyberbullying and other toxic behavior in team competition online games},
  author={Kwak, Haewoon and Blackburn, Jeremy and Han, Seungyeop},
  booktitle={Proceedings of the 33rd annual ACM conference on human factors in computing systems},
  pages={3739--3748},
  year={2015}
}

@inproceedings{weld2021conda,
  title={CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection},
  author={Weld, Henry and Huang, Guanghao and Lee, Jean and Zhang, Tongshu and Wang, Kunze and Guo, Xinghong and Long, Siqu and Poon, Josiah and Han, Caren},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={2406--2416},
  year={2021}
}

@inproceedings{ekiciler2014bullying,
  title={The Bullying Game: Sexism Based Toxic Language Analysis on Online Games Chat Logs by Text Mining},
  author={Ekiciler, Asl{\i} and Ahio{\u{g}}lu, {\.I}mran and Y{\i}ld{\i}r{\i}m, Nihan and Ajas, {\.I} and Kaya, Tolga},
  booktitle={Conference on Gender Studies and Sexuality},
  year={2014}
}

@inproceedings{chong2022understanding,
  title={Understanding Toxicity Triggers on Reddit in the Context of Singapore},
  author={Chong, Yun Yu and Kwak, Haewoon},
  booktitle={Proceedings of the International AAAI Conference on Web and Social Media},
  volume={16},
  pages={1383--1387},
  year={2022}
}

@inproceedings{sap-etal-2022-annotators,
    title = "Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection",
    author = "Sap, Maarten  and
      Swayamdipta, Swabha  and
      Vianna, Laura  and
      Zhou, Xuhui  and
      Choi, Yejin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.431",
    doi = "10.18653/v1/2022.naacl-main.431",
    pages = "5884--5906",
    abstract = "The perceived toxicity of language can vary based on someone{'}s identity and beliefs, but this variation is often ignored when collecting toxic language datasets, resulting in dataset and model biases. We seek to understand the *who*, *why*, and *what* behind biases in toxicity annotations. In two online studies with demographically and politically diverse participants, we investigate the effect of annotator identities (*who*) and beliefs (*why*), drawing from social psychology research about hate speech, free speech, racist beliefs, political leaning, and more. We disentangle *what* is annotated as toxic by considering posts with three characteristics: anti-Black language, African American English (AAE) dialect, and vulgarity. Our results show strong associations between annotator identity and beliefs and their ratings of toxicity. Notably, more conservative annotators and those who scored highly on our scale for racist beliefs were less likely to rate anti-Black language as toxic, but more likely to rate AAE as toxic. We additionally present a case study illustrating how a popular toxicity detection system{'}s ratings inherently reflect only specific beliefs and perspectives. Our findings call for contextualizing toxicity labels in social variables, which raises immense implications for toxic language annotation and detection.",
}

@phdthesis{tellakat2020understanding,
  title={Understanding intergroup vs. intragroup toxicity in online communities},
  author={Tellakat, Mohini},
  year={2020}
}

@inproceedings{isaksen2020using,
  title={Using transfer-based language models to detect hateful and offensive language online},
  author={Isaksen, Vebj{\o}rn and Gamb{\"a}ck, Bj{\"o}rn},
  booktitle={Proceedings of the Fourth Workshop on Online Abuse and Harms},
  pages={16--27},
  year={2020}
}

@inproceedings{davidson2017automated,
  title={Automated hate speech detection and the problem of offensive language},
  author={Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar},
  booktitle={Proceedings of the international AAAI conference on web and social media},
  volume={11},
  number={1},
  pages={512--515},
  year={2017}
}

@inproceedings{founta2018large,
  title={Large scale crowdsourcing and characterization of twitter abusive behavior},
  author={Founta, Antigoni Maria and Djouvas, Constantinos and Chatzakou, Despoina and Leontiadis, Ilias and Blackburn, Jeremy and Stringhini, Gianluca and Vakali, Athena and Sirivianos, Michael and Kourtellis, Nicolas},
  booktitle={Twelfth International AAAI Conference on Web and Social Media},
  year={2018}
}

@inproceedings{sarwar2022unsupervised,
  title={Unsupervised domain adaptation for hate speech detection using a data augmentation approach},
  author={Sarwar, Sheikh Muhammad and Murdock, Vanessa},
  booktitle={Proceedings of the International AAAI Conference on Web and Social Media},
  volume={16},
  pages={852--862},
  year={2022}
}

@inproceedings{agrawal2018deep,
  title={Deep learning for detecting cyberbullying across multiple social media platforms},
  author={Agrawal, Sweta and Awekar, Amit},
  booktitle={European conference on information retrieval},
  pages={141--153},
  year={2018},
  organization={Springer}
}


@inproceedings{waseem2016you,
  title={Are you a racist or am i seeing things? annotator influence on hate speech detection on twitter},
  author={Waseem, Zeerak},
  booktitle={Proceedings of the first workshop on NLP and computational social science},
  pages={138--142},
  year={2016}
}

@inproceedings{waseem2016hateful,
  title={Hateful symbols or hateful people? predictive features for hate speech detection on twitter},
  author={Waseem, Zeerak and Hovy, Dirk},
  booktitle={Proceedings of the NAACL student research workshop},
  pages={88--93},
  year={2016}
}
@inproceedings{arango2019hate,
  title={Hate speech detection is not as easy as you may think: A closer look at model validation},
  author={Arango, Aym{\'e} and P{\'e}rez, Jorge and Poblete, Barbara},
  booktitle={Proceedings of the 42nd international acm sigir conference on research and development in information retrieval},
  pages={45--54},
  year={2019}
}

@article{murthy2019visualizing,
  title={Visualizing YouTube’s comment space: online hostility as a networked phenomena},
  author={Murthy, Dhiraj and Sharma, Sanjay},
  journal={New media \& society},
  volume={21},
  number={1},
  pages={191--213},
  year={2019},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{obadimu2019identifying,
  title={Identifying toxicity within youtube video comment},
  author={Obadimu, Adewale and Mead, Esther and Hussain, Muhammad Nihal and Agarwal, Nitin},
  booktitle={International conference on social computing, Behavioral-cultural modeling and prediction and behavior representation in modeling and simulation},
  pages={214--223},
  year={2019},
  organization={Springer}
}

@inproceedings{zhou2021challenges,
  title={Challenges in Automated Debiasing for Toxic Language Detection},
  author={Zhou, Xuhui and Sap, Maarten and Swayamdipta, Swabha and Choi, Yejin and Smith, Noah A},
  booktitle={Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
  pages={3143--3155},
  year={2021}
}
@inproceedings{hutchinson2020social,
  title={Social Biases in NLP Models as Barriers for Persons with Disabilities},
  author={Hutchinson, Ben and Prabhakaran, Vinodkumar and Denton, Emily and Webster, Kellie and Zhong, Yu and Denuyl, Stephen},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={5491--5501},
  year={2020}
}

%intro
@inproceedings{jahan2020team,
  title={Team oulu at semeval-2020 task 12: Multilingual identification of offensive language, type and target of twitter post using translated datasets},
  author={Jahan, Md Saroar},
  booktitle={Proceedings of the Fourteenth Workshop on Semantic Evaluation},
  pages={1628--1637},
  year={2020}
}

@article{salminen2020developing,
  title={Developing an online hate classifier for multiple social media platforms},
  author={Salminen, Joni and Hopf, Maximilian and Chowdhury, Shammur A and Jung, Soon-gyo and Almerekhi, Hind and Jansen, Bernard J},
  journal={Human-centric Computing and Information Sciences},
  volume={10},
  number={1},
  pages={1--34},
  year={2020},
  publisher={Springer}
}

@article{silva2020data,
  title={Data-Driven and Psycholinguistics-Motivated Approaches to Hate Speech Detection},
  author={Silva, Samuel Caetano da and Ferreira, Thiago Castro and Ramos, Ricelli Moreira Silva and Paraboni, Ivandr{\'e}},
  journal={Computaci{\'o}n y Sistemas},
  volume={24},
  number={3},
  pages={1179--1188},
  year={2020},
  publisher={Centro de Investigaci{\'o}n en Computaci{\'o}n, IPN}
}
@inproceedings{mathur2018did,
  title={Did you offend me? classification of offensive tweets in hinglish language},
  author={Mathur, Puneet and Sawhney, Ramit and Ayyar, Meghna and Shah, Rajiv},
  booktitle={Proceedings of the 2nd workshop on abusive language online (ALW2)},
  pages={138--148},
  year={2018}
}

@inproceedings{an2021predicting,
  title={Predicting Anti-Asian Hateful Users on Twitter during COVID-19},
  author={An, Jisun and Kwak, Haewoon and Lee, Claire Seungeun and Jun, Bogang and Ahn, Yong-Yeol},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages={4655--4666},
  year={2021}
}
@article{boyd2022development,
  title={The development and psychometric properties of LIWC-22},
  author={Boyd, Ryan L and Ashokkumar, Ashwini and Seraj, Sarah and Pennebaker, James W},
  journal={Austin, TX: University of Texas at Austin},
  year={2022}
}

@article{seraj2021language,
  title={Language left behind on social media exposes the emotional and cognitive costs of a romantic breakup},
  author={Seraj, Sarah and Blackburn, Kate G and Pennebaker, James W},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={7},
  pages={e2017154118},
  year={2021},
  publisher={National Acad Sciences}
}

@inproceedings{rezapour2019enhancing,
  title={Enhancing the measurement of social effects by capturing morality},
  author={Rezapour, Rezvaneh and Shah, Saumil H and Diesner, Jana},
  booktitle={Proceedings of the tenth workshop on computational approaches to subjectivity, sentiment and social media analysis},
  year={2019}
}

@article{triandis1989self,
  title={The self and social behavior in differing cultural contexts.},
  author={Triandis, Harry C},
  journal={Psychological review},
  volume={96},
  number={3},
  pages={506},
  year={1989},
  publisher={American Psychological Association}
}

@incollection{graham2013moral,
  title={Moral foundations theory: The pragmatic validity of moral pluralism},
  author={Graham, Jesse and Haidt, Jonathan and Koleva, Sena and Motyl, Matt and Iyer, Ravi and Wojcik, Sean P and Ditto, Peter H},
  booktitle={Advances in experimental social psychology},
  volume={47},
  year={2013},
  publisher={Elsevier}
}

@article{haidt2004intuitive,
  title={Intuitive ethics: How innately prepared intuitions generate culturally variable virtues},
  author={Haidt, Jonathan and Joseph, Craig},
  journal={Daedalus},
  volume={133},
  number={4},
  pages={55--66},
  year={2004},
  publisher={JSTOR}
}

@article{haidt2001emotional,
  title={The emotional dog and its rational tail: a social intuitionist approach to moral judgment.},
  author={Haidt, Jonathan},
  journal={Psychological review},
  volume={108},
  number={4},
  pages={814},
  year={2001},
  publisher={American Psychological Association}
}
@inproceedings{rezapour2021incorporating,
  title={Incorporating the measurement of moral foundations theory into analyzing stances on controversial topics},
  author={Rezapour, Rezvaneh and Dinh, Ly and Diesner, Jana},
  booktitle={Proceedings of the 32nd ACM Conference on Hypertext and Social Media},
  year={2021}
}

@article{graham2009liberals,
  title={Liberals and conservatives rely on different sets of moral foundations.},
  author={Graham, Jesse and Haidt, Jonathan and Nosek, Brian A},
  journal={Journal of personality and social psychology},
  volume={96},
  number={5},
  pages={1029},
  year={2009},
  publisher={American Psychological Association}
}

@article{garten2018dictionaries,
  title={Dictionaries and distributions: Combining expert knowledge and large scale textual data content analysis},
  author={Garten, Justin and Hoover, Joe and Johnson, Kate M and Boghrati, Reihane and Iskiwitch, Carol and Dehghani, Morteza},
  journal={Behavior research methods},
  volume={50},
  number={1},
  pages={344--361},
  year={2018},
  publisher={Springer}
}


@misc{rezapour2019,
doi = {10.13012/B2IDB-3805242\_V1.1},
author = {Rezapour, Rezvaneh and Diesner, Jana},
note = {{\url{https://doi.org/10.13012/B2IDB-3805242_V1.1}}},
publisher = {University of Illinois at Urbana-Champaign},
title = {Expanded Morality Lexicon},
year = {2019}
}


@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@inproceedings{mishne2006leave,
  title={Leave a reply: An analysis of weblog comments},
  author={Mishne, Gilad and Glance, Natalie and others},
  booktitle={Third annual workshop on the Weblogging ecosystem},
  year={2006},
  organization={Edinburgh, Scotland}
}

@inproceedings{pennacchiotti2010detecting,
  title={Detecting controversies in Twitter: a first study},
  author={Pennacchiotti, Marco and Popescu, Ana-Maria},
  booktitle={Proceedings of the NAACL HLT 2010 workshop on computational linguistics in a world of social media},
  pages={31--32},
  year={2010}
}
@inproceedings{addawood2017telling,
  title={Telling apart tweets associated with controversial versus non-controversial topics},
  author={Addawood, Aseel and Rezapour, Rezvaneh and Abdar, Omid and Diesner, Jana},
  booktitle={Proceedings of the Second Workshop on NLP and Computational Social Science},
  pages={32--41},
  year={2017}
}

@article{martinez2022hate,
  title={Hate: Toward understanding its distinctive features across interpersonal and intergroup targets.},
  author={Mart{\'\i}nez, Cristhian A and van Prooijen, Jan-Willem and Van Lange, Paul AM},
  journal={Emotion},
  volume={22},
  number={1},
  pages={46},
  year={2022},
  publisher={American Psychological Association}
}