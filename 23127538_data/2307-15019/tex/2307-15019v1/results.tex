\begin{table}[!t]
\centering
\caption{Performance of the proposed self-supervised graph Transformer deepfake detection model using the in-dataset setting.}
\label{tab:IntraEvaluation}
\begin{tabular}{llcc}
\toprule
\multicolumn{2}{l}{\multirow{1}{*}{\textbf{Dataset}}}            & \textbf{ACC     (\%)}    &\textbf{ AUC    (\%)} \\ \midrule
\multirow{3}{*}{FaceForensics++}  & (Raw)  &      99.38      &  99.96                 \\
                                  & (HQ)   &      98.41      &  99.34               \\
                                  & (LQ)   &      94.59      &  95.16                \\

\multicolumn{2}{l}{Celeb-DF (V2)}         &      99.47      &   99.43            \\
\multicolumn{2}{l}{WildDeepfake}          &      81.37      &  81.24         \\ 

\bottomrule
\end{tabular}
\end{table} 


To fully ascertain the proficiency of the presented deepfake detection framework, an exhaustive set of experiments was conducted, with a multifaceted approach to examine its performance across various perspectives. The scope of investigation encompassed the generalization ability of the framework in detecting deepfakes originating from heterogeneous datasets and manipulation techniques, as well as its resistance against compression and perturbations, and other ablation studies that are critical in appraising the framework's efficacy. To this end, three distinct models were meticulously trained and evaluated in an in-dataset setting using each of the preeminent deepfake forensics datasets, namely FaceForensics++, Celeb-DF (V2), and WildDeepfake, with the corresponding accuracy rate and AUC scores reported in \autoref{tab:IntraEvaluation}.




\begin{table}[t]
\centering
\caption{ Cross-dataset generalization AUC (\%) scores. The model is trained over FaceForensics++ and evaluated over a test set of DeeperForensics (DFo), FaceShifter (FSh), DeepFake Detection Challenge (DFDC), and Celeb-DF (CDF), respectively. }
\label{tab:CrossdatasetEvaluation_video}
\begin{tabular}{l|cccc|c}
\toprule
\textbf{Methods}             	&	 \textbf{DFo} 	&	 \textbf{FSh} 	&	 \textbf{DFDC} 	&	\textbf{ CDF} 	&	 \textbf{Avg.}  \\ \midrule		
Xception~\cite{rossler2019faceforensics++}      	&	84.5	&	72.0	&	70.9	&	73.7	&	 75.3 \\		
CNN-aug~\cite{wang2020cnn}                          &	74.4	&	65.7	&	72.1	&	75.6	&	 72.0 \\		
Patch-based~\cite{chai2020makes}  	                &	81.8	&	57.8	&	65.6	&	69.6	&	 68.7 \\		
Face X-ray~\cite{li2020face}    	                &	86.8	&	92.8	&	65.5	&	79.5	&	 81.2 \\		
CNN-GRU~\cite{sabir2019recurrent}      	            &	74.1	&	80.8	&	68.9	&	69.8	&	 73.4 \\		
Multi-task~\cite{nguyen2019multi}  	                &	77.7	&	66.0	&	68.1	&	75.7	&	 71.9 \\		
DSP-FWA~\cite{li2019exposing}       	            &	50.2	&	65.5	&	67.3	&	69.5	&	 63.1 \\		
LipForensics~\cite{haliassos2021lips} 	            &	97.6	&	97.1	&	73.5	&	82.4	&	 87.7 \\		
FTCN \cite{zheng2021exploring}       	            &	98.8	&	98.8	&	74.0	&	86.9	&	 89.6 \\		
DFDT  \cite{khormali2022dfdt}                	    &	96.9	&	97.8	&	76.1	&	88.3	&	 89.7 \\ 		
RealForensics \cite{haliassos2022leveraging}       	&	99.3	&	99.7	&	75.9	&	86.9	&	 90.5 \\\midrule		
Ours                   	                            &	98.9	&	99.1	&	77.3	&	87.9	&	 90.8 \\ 		\bottomrule
\end{tabular}
\end{table}

\subsection{Cross Dataset Generalization}
The proliferation of fake videos in the real world poses a formidable challenge for the deployment of deepfake detection models, given the diverse forgery techniques, heterogeneous source videos, and extensive post-processing techniques. Therefore, it is crucial to assess the effectiveness of any deployed deepfake detection model from a domain generalization perspective. Although evaluating domain generalization is complicated due to significant disparities between deepfake forensics datasets, this can be addressed through cross-dataset evaluation. This study adopts a similar approach to the existing literature by utilizing the training set of the FaceForensics++ dataset to construct a deepfake detection model and then evaluate its performance on other datasets. More specifically, the model is trained on four distinct types of forgeries that make up the FaceForensics++ dataset. The model's performance is then evaluated on the test sets of four separate benchmark deepfake detection datasets, including DeeperForensics \cite{jiang2020deeperforensics}, FaceShifter \cite{li2019faceshifter}, Deepfake Detection Challenge \cite{dolhansky2019deepfake}, and Celeb-DF (V2) \cite{Celeb_DF_cvpr20}. This evaluation process aims to determine the model's ability to generalize across different forgery techniques and datasets, thus assessing its domain generalization capabilities. It is noteworthy that this evaluation setup is exceedingly arduous since the original and forged videos in DFDC and Celeb-DF (V2) are different from those in FaceForensics++ and were not seen during the training process. 

The results obtained from this cross-dataset evaluation are presented in \autoref{tab:CrossdatasetEvaluation_video}. Based on the results shown in the table, it is evident that the proposed graph Transformer model outperforms all other methods in terms of average AUC scores, achieving an impressive score of 90.8\%. The RealForensics method comes in second place with an average AUC score of 90.5\%, while other methods have lower scores, ranging from 63.1\% to 89.7\%. It is worth noting that some methods, such as Face X-ray and DSP-FWA, perform well on specific datasets but have lower scores on others. This indicates that their performance may be dataset-dependent and may not generalize well across different datasets. On the other hand, the presented method in this study and some other methods, such as FTCN, DFDT, and RealForensics, achieve consistently high scores across all datasets, indicating that they are robust and generalize well across different datasets. In particular, the presented method achieves the highest AUC score on the DeeperForensics, FaceShifter, and Celeb-DF (V2) datasets and the second-highest score on the DFDC dataset. It is pertinent to mention that due to the fact that DeeperForensics and FaceShifter utilize the same source videos as FaceForensics++, they tend to perform better than DFDC and Celeb-DF (V2) in terms of deepfake detection. This is because the models have already been trained on similar data, making it easier for them to generalize to these datasets.



% To do so, training set of the FaceForensics++ dataset with four forgery types, i.e. DF, F2F, FS, NT, is used to train a model, which got tested against test set of DeeperForensics \cite{jiang2020deeperforensics}, FaceShifter \cite{li2019faceshifter}, Deepfake Detection Challenge \cite{dolhansky2019deepfake}, and Celeb-DF (V2) \cite{Celeb_DF_cvpr20}. Note that this setting is extremely challenging since both original and forged videos in DeepFake Detection Challenge and Celeb-DF (V2) are different from the FaceForensics++ and not seen in the training process.  
% The obtained results are listed in \autoref{tab:CrossdatasetEvaluation_video}. It can be observed that the proposed self-supervised framework achieves excellent generalization performances on DFDC, Celeb-DF (V2), and FaceShifter datasets. This indicates the effectiveness of the presented self-supervised framework for deepfake detection. Since Deeperforensics and FaceShiter share the same source videos with FaceForensics++, their performances are better than those on DFDC and Celeb-DF (V2). 



% We compare different methods by using the Area Under Curve (AUC) metric and present the results in Table 1. As seen, our method outperforms other models in most cases and achieves the overall best performance. This
% clearly demonstrates the advantage of the proposed adversarial augmentation and self-supervised tasks. SRM [30] and F3Net [39] both rely on high-frequency components of a image to distinguish forgeries from pristine. Our experiment suggests that they attain worse generalization performance than our approach. This may be because the highfrequency cue identified effective on the FaceForensics++ dataset [41] may not necessarily generalize to other datasets that adopt different post-processing steps. RFM [47] encourages the
% use of multiple facial regions for forgery detection and thus leads to improved generalization performance. However, their method still cannot avoid some data source biases, such as all the whole facial parts in a training sample are from the same source. This limitation may explain why
% their performance is inferior to ours. Face X-ray [24] uses
% the blended artifacts in the forgery for generalization. Compared to our method, Their generalizability will degrade when these artifacts share different patterns in the training and test dataset. As a baseline, Xception [41] does not incorporate any augmentation or feature engineering. Its performance drops drastically in unseen forgeries.



\begin{table}[!t]
\centering
\caption{Cross-manipulation generalization results on FaceForensics++ dataset. The AUC scores (in percentage) are for each forgery class on the FaceForensics++ dataset after training on the other three manipulation types.}
\label{tab:crossmanipulation}
\begin{tabular}{l|cccc|c}
\toprule
\multirow{2}{*}{\textbf{Methods} }        & \multicolumn{4}{c|}{\textbf{Train on remaining sets}} & \multicolumn{1}{l}{\multirow{2}{*}{\textbf{Avg.}}} \\ \cline{2-5}
                               & \textbf{DF}           & \textbf{NT}           & \textbf{F2F } & \textbf{FS}       & \multicolumn{1}{l}{}                      \\ \midrule
Xception~\cite{rossler2019faceforensics++} 	               	&	93.9	&	79.7	&	86.8	&	51.2	&	 77.9                                      \\		
CNN-aug~\cite{wang2020cnn}                       	     	&	87.5	&	67.8	&	80.1	&	56.3	&	 72.9                                      \\		
Patch-based~\cite{chai2020makes}                  		    &	94.0	&	84.8	&	87.3	&	60.5	&	 81.7                                      \\		
Face X-ray~\cite{li2020face}                   		        &	99.5	&	92.5	&	94.5	&	93.2	&	 94.9                                      \\		
CNN-GRU~\cite{sabir2019recurrent}                      		&	97.6	&	86.6	&	85.8	&	47.6	&	 79.4                                      \\		
LipForensics~\cite{haliassos2021lips}                 		&	99.7	&	99.1	&	 {99.7}         	&	90.1	&	 97.1                                      \\ 		
DFDT\cite{khormali2022dfdt}                           		&	99.8	&	99.2	&	99.6	&	93.1	&	   97.9                                 \\		
AV DFD \cite{zhou2021joint}                           		&	100.0 	&	98.3	&	99.8	&	90.5	&	   97.1                                 \\		
FTCN \cite{zheng2021exploring}                        		&	99.9	&	99.2	&	99.7	&	99.9	&	  99.6                                 \\ 		
RealForensics \cite{haliassos2022leveraging}                &	100.0 	&	99.2	&	99.7	&	97.1	&	  99.6                                 \\ \midrule		
Ours                                                   		&	99.9	&	99.2	&	99.8	&	98.3	&	   99.3                                 \\		\bottomrule
\end{tabular}
\end{table}





\subsection{Cross Manipulation Generalization}
In the real world, deepfakes can be generated using various techniques, including different source videos and post-processing methods, resulting in a vast array of manipulated videos. A deepfake detection model that is only trained on a specific dataset may fail to detect deepfakes generated using different techniques, rendering the model ineffective. Therefore, any deployed deepfake detection algorithm must perform well on unseen forgery types \cite{haliassos2021lips, li2020face, nguyen2019multi, zheng2021exploring}. This means that cross-manipulation generalization is critical for deepfake detection as it enables the detection model to perform effectively on unseen and potentially more sophisticated manipulated videos.   
% Therefore, it is essential to evaluate deepfake detection models' cross-manipulation generalization abilities to ensure their effectiveness in real-world scenarios. 
To this end, the cross-manipulation generalization property of the presented approach is investigated using the leave-one-out strategy \cite{haliassos2021lips, khormali2022dfdt, masi2020two, chai2020makes, nguyen2019multi}. Specifically, model performance is evaluated on each forgery type in FaceForensics++ dataset after training with the remaining manipulation techniques. The obtained results on the test sets of Deepfakes (DF),  NeuralTextures (NT), Face2Face (F2F), and FaceSwap (FS) are shown in \autoref{tab:crossmanipulation}. The table shows that the proposed method achieves a high average AUC score of 99.3\%, which is comparable to state-of-the-art methods, such as FTCN and RealForensics. The high average AUC score indicates that the presented method's cross-manipulation extends well to previously unseen manipulation types. It works on par with the SOTA with a self-supervised feature extractor, indicating its effectiveness in capturing more generalizable features for accurate deepfake detection.

\begin{table}[t]
\centering
\caption{Generalization AUC (\%) scores across different compression levels. The model is trained over Neuraltextures (NT) forgery type and tested on Deepfakes (DF) and FaceSwap (FS) forgery types from the FaceForensics++ dataset at two compression levels, \ie LQ and HQ. }
\label{tab:crosscompression}
\begin{tabular}{l|cc|cc}
\toprule
\multirow{2}{*}{\textbf{Method}}  & \multicolumn{2}{c|}{\textbf{HQ}} & \multicolumn{2}{c}{\textbf{LQ}} \\ \cline { 2 - 5}
                        & \textbf{FS}         & \textbf{DF}        & \textbf{FS}         & \textbf{DF}        \\ \midrule
Xception~\cite{rossler2019faceforensics++}               & 71.8      & 77.0     & 51.7      & 58.7     \\
Face X-ray~\cite{li2020face}             & 77.9      & 58.5     & 51.0      & 57.1     \\
F3Net \cite{qian2020thinking}                  & 61.2      & 80.5     & 51.9      & 58.3     \\
RFM  \cite{wang2021representative}                   & 63.9      & 79.8     & 51.6      & 55.8     \\
SRM  \cite{luo2021generalizing}                   & 79.5      & 83.8     & 52.9      & 55.5     \\
SLADD \cite{chen2022self}               & 72.1      & 84.6     & 56.8      & 62.8     \\ \midrule
Ours                    &  72.9     & 84.5     & 57.2      &  61.4    \\ 

\bottomrule
\end{tabular}
\end{table}

% Figure environment removed


\begin{table*}[t]
\centering
\caption{Robustness against common post-processing perturbations. The experiments are performed using five different intensity levels for each perturbation type and reported the average AUC score (\%). Moreover, the average AUC score across all corruptions for each deepfake detection method is presented. }
\label{tab:perturbation}
\begin{tabular}{l|ccccccc|c}
\toprule
\textbf{Method}                & \textbf{Clean} & \textbf{Saturation} & \textbf{Blur} & \textbf{Block} & \textbf{Contrast} & \textbf{Pixel} & \textbf{Noise} & \textbf{Avg}  \\ \midrule
Xception~\cite{rossler2019faceforensics++}    & 99.8  & 99.3       & 60.2 & 99.7  & 98.6     & 74.2  & 53.8  & 78.3 \\
CNN-aug~\cite{wang2020cnn}     & 99.8  & 99.3       & 76.5 & 95.2  & 99.1     & 91.2  & 54.7  & 84.1 \\
Patch-based~\cite{chai2020makes}  & 99.9  & 84.3       & 54.4 & 99.2  & 74.2     & 56.7  & 50.0  & 67.5 \\
Face X-ray~\cite{li2020face}   & 99.8  & 97.6       & 63.8 & 99.1  & 88.5     & 88.6  & 49.8  & 77.5 \\
CNN-GRU~\cite{sabir2019recurrent}      & 99.9  & 99.0       & 71.5 & 97.9  & 98.8     & 86.5  & 47.9  & 82.3 \\
LipForensics~\cite{haliassos2021lips}  & 99.9  & 99.9       & 96.1 & 87.4  & 99.6     & 95.6  & 73.8  & 92.5 \\
FTCN \cite{zheng2021exploring}         & 99.4  & 99.4       & 95.8 & 97.1  & 96.7     & 98.2  & 53.1  & 89.5 \\ 
RealForensics \cite{haliassos2022leveraging} & 99.8  & 99.8       & 95.3 & 98.9  & 99.6     & 98.4  & 79.7  & 95.6 \\\midrule
Ours  & 99.7  & 99.8       & 96.1 & 98.8  & 99.7     & 98.2  & 81.1  & 96.2 \\

\bottomrule
\end{tabular}
\end{table*}






\subsection{Cross Compression Generalization}
In addition to achieving high generalization scores across different types of deepfake manipulations, ensuring the robustness of the deployed detector against varying levels of compression is equally crucial. The proposed method's cross-compression generalization is evaluated through testing on Deepfakes and FaceSwap forgery types with different compression levels, \ie LQ and HQ, while being trained on NeuralTextures from the FaceForensics++ dataset. The results obtained are presented in Table \ref{tab:crosscompression}. It can be observed that while competitive generalization was demonstrated by the proposed graph Transformer model when the compression level was kept constant during training and testing. However, a significant drop in performance was noted once tested against compressed samples, as evidenced in Figure \ref{fig:compression}. This is unsurprising, given that highly compressed images are subject to the loss of textural features and low-level clues. Therefore, FTCN and LipForensics were highly affected by compression levels. However, the proposed self-supervised graph transformer model achieves slightly better performances as it leverages high-level facial representations, which are less susceptible to low-level artifacts.  




\subsection{Resilience to Perturbation}
Given that real-world forgeries are vulnerable to various forms of corruption on social media, such as saturation, contrast, blur, etc., it is essential that the deployed deepfake detector can withstand such post-processing perturbations. The procedure proposed in \cite{haliassos2021lips} is taken into account to investigate the resilience of the model against common post-processing filters, including applying Gaussian noise \& blur, modifying saturation \& contrast, pixelation, and block-wise occlusions \cite{jiang2020deeperforensics}. The model is trained over grayscale clips of the FaceForensics++ dataset, with only horizontal flipping and random cropping augmentations, and evaluated against five different intensity levels of aforementioned perturbations. The resulting average AUC scores are listed in \autoref{tab:perturbation}. The presented graph Transformer model is significantly less vulnerable to aforementioned corruptions compared to other methods that utilize low-level cues such as Patch-based and Face X-ray. Furthermore, the proposed method outperforms FTCN and LipForensics, while exhibiting comparable results to RealForensics, thus showcasing its competitive performance.



\begin{table*}[!h]
\centering
\caption{A quantitative comparison of methods performance on every dataset with existing deepfake detection approaches in frame-level analysis. Reported results are obtained from associated articles. The~same evaluation metric as the literature is used for each dataset to provide a fair comparison and better insight into the model's~performance.} \label{tab:IntraEvaluation_Comparison}
\begin{tabular}{lc|lc|lc}
\toprule
\multirow{2}{*}{\textbf{Methods} } & \textbf{FaceForensics++} & \multirow{2}{*}{\textbf{Methods} } & \multirow{1}{*}{\textbf{Celeb-DF (V2)}} & \multirow{2}{*}{\textbf{Methods} } & \multirow{1}{*}{\textbf{WideDeepfake}}                                      \\ 
                & \textbf{AUC (\%)}        &                         &\textbf{ AUC (\%)}                       &                         & \textbf{(ACC \%)}                                                            \\ \midrule
	Two-stream~\cite{zhou2017two}	                &	70.1	&	Two-stream~\cite{zhou2017two}	                    &	53.8	&	AlexNet~\cite{krizhevsky2017imagenet}	        &	60.3	\\	
	Meso4~\cite{afchar2018mesonet}	                &	84.7	&	Meso4~\cite{afchar2018mesonet}	                    &	54.8	&	VGG16~\cite{simonyan2015very}	                &	60.9	\\	
	HeadPose~\cite{yang2019exposing}	            &	47.3	&	HeadPose~\cite{yang2019exposing}	                &	54.6	&	ResNetV2-50~\cite{he2016identity}	            &	63.9	\\	
	FWA~\cite{li2019exposing}	                    &	80.1	&	FWA~\cite{li2019exposing}	                        &	56.9	&	ResNetV2-101~\cite{he2016identity}	            &	58.7	\\	
	VA-MLP~\cite{matern2019exploiting}	            &	66.4	&	VA-MLP~\cite{matern2019exploiting}	                &	55.0	&	ResNetV2-152~\cite{he2016identity}	            &	59.3	\\	
	Xception~\cite{rossler2019faceforensics++}	    &	99.7	&	Xception~\cite{rossler2019faceforensics++}	        &	65.5	&	Inception-v2~\cite{szegedy2016rethinking}	    &	62.1	\\	
	Multi-task~\cite{nguyen2019multi}	            &	76.3	&	Multi-task~\cite{nguyen2019multi}	                &	54.3	&	MesoNet-1~\cite{afchar2018mesonet}	            &	60.5	\\	
	Capsule~\cite{nguyen2019use}	                &	96.6	&	Capsule~\cite{nguyen2019use}	                    &	57.5	&	MesoNet-4~\cite{afchar2018mesonet}	            &	64.4	\\	
	DSP-FWA~\cite{li2019exposing}	                &	93.0	    &	DSP-FWA~\cite{li2019exposing}	                    &	64.6	&	MesoNet-inception~\cite{afchar2018mesonet}	    &	66.0	\\	
	Two-branch~\cite{masi2020two}	                &	93.2	&	Two-branch~\cite{masi2020two}	                    &	73.4	&	XceptionNet~\cite{chollet2017xception}	        &	69.2	\\	
	SPSL~\cite{liu2021spatial}	                    &	96.9	&	Face X-ray~\cite{li2020face}	                    &	80.5	&	ADDNet-2D~\cite{zi2020wilddeepfake}	            &	76.2	\\	
 	F3-Net~\cite{qian2020thinking}	                &	97.9	&	SPSL~\cite{liu2021spatial}	                        &	76.8	&	ADDNet-3D~\cite{zi2020wilddeepfake}	            &	65.5	\\	
	Video SE~\cite{khan2021video}		            &	99.6   &	F3-Net~\cite{qian2020thinking}	                    &	65.1	&	ADD-Xception~\cite{khormali2021add}	            &	79.2	\\	
	RNN~\cite{guera2018deepfake}                    &	83.1   &	PPA~\cite{charitidis2020investigating}	            &	83.1	&	DFDT~\cite{khormali2022dfdt}                    &	81.3    	\\	
	DFDT~\cite{khormali2022dfdt}                    &	99.7   &	DefakeHop~\cite{chen2021defakehop}	                &	90.5	&			                                        &	    	\\	
		                                            &	    	&	FakeCatcher~\cite{ciftci2020fakecatcher}	        &	91.5	&	                                    	        &	    	\\	
	                                                &		    &	ATS-DE~\cite{tran2021high}	                        &	97.8	&			                                        &	    	\\	
	                                                &		    &	ADD-ResNet~\cite{khormali2021add}	                &	98.3	&			                                        &	    	\\
	                                                &           &   DFDT~\cite{khormali2022dfdt}                        &99.2 &  &   \\  	\midrule
	
	Ours                                           &	{99.9}	    &	Ours              	                &	  {99.4}  	&   Ours			                    &	    {81.3	}\\	
\bottomrule
\end{tabular}
\end{table*}




\subsection{Comparison with SOTA}
A comprehensive evaluation was carried out to assess the superiority of the presented deepfake detection framework over state-of-the-art models. In particular, the model's performance was compared against state-of-the-art deepfake detection models that were trained and tested using same datasets, and the resultant outcomes are presented in \autoref{tab:IntraEvaluation_Comparison}. Remarkably, the model exhibited competitive performance when evaluated on the FaceForensics++ dataset, while outperforming other models when tested on Celeb-DF (V2) and WildDeepfake datasets. The obtained results unequivocally highlight the exceptional potency of the proposed graph Transformer model, underscored by its superlative generalizability attributable to the high-level deepfake representations obtained by a self-supervised framework. Furthermore, the proposed model's ability to leverage the underlying graph structure of the deepfake images enables the identification of both local and global subtle discrepancies and artifacts that may evade detection using traditional methods. This highlights the significance of the proposed model, which offers a compelling alternative to existing deepfake detection methods and has the potential to significantly enhance the reliability and robustness of deepfake detection systems.




\subsection{Ablation Studies and Model Configuration}

The proposed framework was comprehensively evaluated through a series of meticulous ablation studies, aiming to investigate the role of different components of the model and its hyperparameter values. The outcomes of these experiments on Celeb-DF (V2) are summarized in Table \ref{tab:KImpact}. Firstly, the impact of various feature extractors on the overall performance of the classification task was assessed. The combination of visual representations obtained from the proposed constructive learning vision Transformer architecture with the graph Transformer classifier exhibited superior performance compared to utilizing a pre-trained feature extractor, specifically ResNet50, in combination with the same graph Transformer classifier. 

A series of experiments were conducted using both sets of feature extractors to investigate different hyperparameters' impacts. For example, the influence of the number of included neighboring patches, denoted as $K$, on the graph construction process and the overall efficacy of the deepfake detection task is investigated. Table \ref{tab:KImpact} reveals that the best performance was achieved when $K=8$. Smaller values of $K$ yield a reduction in the receptive field of the constructed graph, consequently resulting in lower performance. Lastly, the impact of other critical hyperparameters, such as the number of graph convolutional layers and the number of Transformer blocks, on the overall performance of the deepfake detection pipeline is investigated. The obtained results demonstrated a slight degradation in performance when the number of graph convolution layers decreased from three layers to one layer. This observation can be attributed to the concept of node receptive field, where a greater number of graph convolution layers allows for the incorporation of long-term information during model development. Moreover, it was observed that utilizing three Transformer blocks facilitated more effective pooling of discriminative information, leading to improved performance in deepfake detection tasks.

The conducted ablation studies collectively showcased the superior performance of the proposed self-supervised graph Transformer framework for deepfake detection. These findings contribute to the advancement of the field and emphasize the efficacy of the employed methodology for addressing the challenges associated with deepfake detection.

\begin{table}[]
\centering
\caption{Performance evaluation of the proposed self-supervised graph Transformer deepfake detection model using different ablation studies on Celeb-DF (V2) dataset. Key variables include the feature extractor (FE), neighboring patches count ($K$), graph convolutional layers (GCN), and number of Transformer blocks (TB).}
\label{tab:KImpact}
\begin{tabular}{c|c|c|c|c}
\toprule
\textbf{FE}                     & \textbf{K}  & \textbf{GCN}                & \textbf{TB} & \textbf{AUC (\%)} \\ \midrule
\multirow{8}{*}{ResNet50} & \multirow{4}{*}{4} & \multirow{2}{*}{1} & 3                              &   97.7         \\
                                      &                    &                    & 6                  &   98.1      \\
                                      &                    & \multirow{2}{*}{3} & 3                  &   97.7       \\
                                      &                    &                    & 6                  &   97.8       \\ \cline{2-5}
                                      & \multirow{4}{*}{8} & \multirow{2}{*}{1} & 3                  &   98.4       \\
                                      &                    &                    & 6                  &   98.3       \\
                                      &                    & \multirow{2}{*}{3} & 3                  &   98.5       \\
                                      &                    &                    & 6                  &   98.4       \\ \midrule
\multirow{8}{*}{SSL ViT}              & \multirow{4}{*}{4} & \multirow{2}{*}{1} & 3                  &   98.6       \\
                                      &                    &                    & 6                  &   98.6       \\
                                      &                    & \multirow{2}{*}{3} & 3                  &   99.1       \\
                                      &                    &                    & 6                  &   98.9        \\ \cline{2-5}
                                      & \multirow{4}{*}{8} & \multirow{2}{*}{1} & 3                  &   98.7        \\
                                      &                    &                    & 6                  &   98.6       \\
                                      &                    & \multirow{2}{*}{3} & 3                  &   99.4       \\
                                      &                    &                    & 6                  &   99.1      \\ \bottomrule
\end{tabular}
\end{table}