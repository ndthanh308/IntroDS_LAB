\begin{thebibliography}{41}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Bubeck et~al.(2023)Bubeck, Chandrasekaran, Eldan, Gehrke, Horvitz,
  Kamar, Lee, Lee, Li, Lundberg et~al.}]{bubeck2023sparks}
S{\'e}bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric
  Horvitz, Ece Kamar, Peter Lee, Yin~Tat Lee, Yuanzhi Li, Scott Lundberg,
  et~al. 2023.
\newblock Sparks of artificial general intelligence: Early experiments with
  gpt-4.
\newblock \emph{arXiv preprint arXiv:2303.12712}.

\bibitem[{Chen et~al.(2022)Chen, Zhang, Nguyen, Zan, Lin, Lou, and
  Chen}]{chen2022codet}
Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and
  Weizhu Chen. 2022.
\newblock Codet: Code generation with generated tests.
\newblock \emph{arXiv preprint arXiv:2207.10397}.

\bibitem[{Chen et~al.(2017)Chen, Fisch, Weston, and
  Bordes}]{chen-etal-2017-reading}
Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017.
\newblock \href {https://doi.org/10.18653/v1/P17-1171} {Reading {W}ikipedia to
  answer open-domain questions}.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 1870--1879,
  Vancouver, Canada. Association for Computational Linguistics.

\bibitem[{Chen et~al.(2021)Chen, Tworek, Jun, Yuan, de~Oliveira~Pinto, Kaplan,
  Edwards, Burda, Joseph, Brockman, Ray, Puri, Krueger, Petrov, Khlaaf, Sastry,
  Mishkin, Chan, Gray, Ryder, Pavlov, Power, Kaiser, Bavarian, Winter, Tillet,
  Such, Cummings, Plappert, Chantzis, Barnes, Herbert-Voss, Guss, Nichol,
  Paino, Tezak, Tang, Babuschkin, Balaji, Jain, Saunders, Hesse, Carr, Leike,
  Achiam, Misra, Morikawa, Radford, Knight, Brundage, Murati, Mayer, Welinder,
  McGrew, Amodei, McCandlish, Sutskever, and Zaremba}]{chen2021evaluating}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique~Ponde
  de~Oliveira~Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
  Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy
  Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder,
  Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens
  Winter, Philippe Tillet, Felipe~Petroski Such, Dave Cummings, Matthias
  Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss,
  William~Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor
  Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher
  Hesse, Andrew~N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa,
  Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter
  Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
  Wojciech Zaremba. 2021.
\newblock \href {http://arxiv.org/abs/2107.03374} {Evaluating large language
  models trained on code}.

\bibitem[{Chen et~al.(2023)Chen, Lin, Sch{\"a}rli, and Zhou}]{chen2023teaching}
Xinyun Chen, Maxwell Lin, Nathanael Sch{\"a}rli, and Denny Zhou. 2023.
\newblock Teaching large language models to self-debug.
\newblock \emph{arXiv preprint arXiv:2304.05128}.

\bibitem[{Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser,
  Plappert, Tworek, Hilton, Nakano et~al.}]{cobbe2021training}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz
  Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,
  et~al. 2021.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}.

\bibitem[{Fabbri et~al.(2022)Fabbri, Wu, Liu, and
  Xiong}]{fabbri-etal-2022-qafacteval}
Alexander Fabbri, Chien-Sheng Wu, Wenhao Liu, and Caiming Xiong. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.naacl-main.187}
  {{QAF}act{E}val: Improved {QA}-based factual consistency evaluation for
  summarization}.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 2587--2601, Seattle, United States. Association for
  Computational Linguistics.

\bibitem[{Gao et~al.(2022{\natexlab{a}})Gao, Dai, Pasupat, Chen, Chaganty, Fan,
  Zhao, Lao, Lee, Juan, and Guu}]{gao2022rarr}
Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun~Tejasvi Chaganty,
  Yicheng Fan, Vincent~Y. Zhao, Ni~Lao, Hongrae Lee, Da-Cheng Juan, and Kelvin
  Guu. 2022{\natexlab{a}}.
\newblock \href {http://arxiv.org/abs/2210.08726} {Rarr: Researching and
  revising what language models say, using language models}.

\bibitem[{Gao et~al.(2022{\natexlab{b}})Gao, Madaan, Zhou, Alon, Liu, Yang,
  Callan, and Neubig}]{gao2022pal}
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie
  Callan, and Graham Neubig. 2022{\natexlab{b}}.
\newblock Pal: Program-aided language models.
\newblock \emph{arXiv preprint arXiv:2211.10435}.

\bibitem[{Jha et~al.(2015)Jha, Coke, and Radev}]{jha2015surveyor}
Rahul Jha, Reed Coke, and Dragomir Radev. 2015.
\newblock Surveyor: A system for generating coherent survey articles for
  scientific topics.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~29.

\bibitem[{Ji et~al.(2023)Ji, Lee, Frieske, Yu, Su, Xu, Ishii, Bang, Madotto,
  and Fung}]{ji2023survey}
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,
  Ye~Jin Bang, Andrea Madotto, and Pascale Fung. 2023.
\newblock Survey of hallucination in natural language generation.
\newblock \emph{ACM Computing Surveys}, 55(12):1--38.

\bibitem[{Kamoi et~al.(2023)Kamoi, Goyal, Rodriguez, and
  Durrett}]{kamoi2023wice}
Ryo Kamoi, Tanya Goyal, Juan~Diego Rodriguez, and Greg Durrett. 2023.
\newblock Wice: Real-world entailment for claims in wikipedia.
\newblock \emph{arXiv preprint arXiv:2303.01432}.

\bibitem[{Komeili et~al.(2022)Komeili, Shuster, and
  Weston}]{komeili-etal-2022-internet}
Mojtaba Komeili, Kurt Shuster, and Jason Weston. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.acl-long.579}
  {{I}nternet-augmented dialogue generation}.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 8460--8478,
  Dublin, Ireland. Association for Computational Linguistics.

\bibitem[{Krishna et~al.(2022)Krishna, Riedel, and
  Vlachos}]{krishna-etal-2022-proofver}
Amrith Krishna, Sebastian Riedel, and Andreas Vlachos. 2022.
\newblock \href {https://doi.org/10.1162/tacl_a_00503} {{P}roo{FV}er: Natural
  logic theorem proving for fact verification}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  10:1013--1030.

\bibitem[{Kryscinski et~al.(2020)Kryscinski, McCann, Xiong, and
  Socher}]{kryscinski-etal-2020-evaluating}
Wojciech Kryscinski, Bryan McCann, Caiming Xiong, and Richard Socher. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.750} {Evaluating
  the factual consistency of abstractive text summarization}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 9332--9346, Online. Association
  for Computational Linguistics.

\bibitem[{Lewis et~al.(2020)Lewis, Perez, Piktus, Petroni, Karpukhin, Goyal,
  K{\"u}ttler, Lewis, Yih, Rockt{\"a}schel et~al.}]{lewis2020retrieval}
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
  Karpukhin, Naman Goyal, Heinrich K{\"u}ttler, Mike Lewis, Wen-tau Yih, Tim
  Rockt{\"a}schel, et~al. 2020.
\newblock Retrieval-augmented generation for knowledge-intensive nlp tasks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:9459--9474.

\bibitem[{Lewkowycz et~al.(2022)Lewkowycz, Andreassen, Dohan, Dyer,
  Michalewski, Ramasesh, Slone, Anil, Schlag, Gutman-Solo, Wu, Neyshabur,
  Gur-Ari, and Misra}]{lewkowycz2022solving}
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk
  Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo
  Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra.
  2022.
\newblock \href {http://arxiv.org/abs/2206.14858} {Solving quantitative
  reasoning problems with language models}.

\bibitem[{Liang et~al.(2023)Liang, Wu, Song, Wu, Xia, Liu, Ou, Lu, Ji, Mao,
  Wang, Shou, Gong, and Duan}]{liang2023taskmatrixai}
Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu~Liu, Yang Ou, Shuai
  Lu, Lei Ji, Shaoguang Mao, Yun Wang, Linjun Shou, Ming Gong, and Nan Duan.
  2023.
\newblock \href {http://arxiv.org/abs/2303.16434} {Taskmatrix.ai: Completing
  tasks by connecting foundation models with millions of apis}.

\bibitem[{Lightman et~al.(2023)Lightman, Kosaraju, Burda, Edwards, Baker, Lee,
  Leike, Schulman, Sutskever, and Cobbe}]{lightman2023lets}
Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy
  Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. 2023.
\newblock \href {http://arxiv.org/abs/2305.20050} {Let's verify step by step}.

\bibitem[{Lin(2004)}]{lin-2004-rouge}
Chin-Yew Lin. 2004.
\newblock \href {https://aclanthology.org/W04-1013} {{ROUGE}: A package for
  automatic evaluation of summaries}.
\newblock In \emph{Text Summarization Branches Out}, pages 74--81, Barcelona,
  Spain. Association for Computational Linguistics.

\bibitem[{Lin et~al.(2022)Lin, Hilton, and Evans}]{lin-etal-2022-truthfulqa}
Stephanie Lin, Jacob Hilton, and Owain Evans. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.acl-long.229}
  {{T}ruthful{QA}: Measuring how models mimic human falsehoods}.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 3214--3252,
  Dublin, Ireland. Association for Computational Linguistics.

\bibitem[{Liu et~al.(2021)Liu, Fu, Xiao, Yuan, Chang, Dai, Liu, Ye, and
  Neubig}]{liu-etal-2021-explainaboard}
Pengfei Liu, Jinlan Fu, Yang Xiao, Weizhe Yuan, Shuaichen Chang, Junqi Dai,
  Yixin Liu, Zihuiwen Ye, and Graham Neubig. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.acl-demo.34}
  {{E}xplaina{B}oard: An explainable leaderboard for {NLP}}.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing: System Demonstrations}, pages 280--289, Online.
  Association for Computational Linguistics.

\bibitem[{Liu et~al.(2023)Liu, Yuan, Fu, Jiang, Hayashi, and
  Neubig}]{liu2023pre}
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and
  Graham Neubig. 2023.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting
  methods in natural language processing.
\newblock \emph{ACM Computing Surveys}, 55(9):1--35.

\bibitem[{Liu et~al.(2022)Liu, Fabbri, Liu, Zhao, Nan, Han, Han, Joty, Wu,
  Xiong et~al.}]{liu2022revisiting}
Yixin Liu, Alexander~R Fabbri, Pengfei Liu, Yilun Zhao, Linyong Nan, Ruilin
  Han, Simeng Han, Shafiq Joty, Chien-Sheng Wu, Caiming Xiong, et~al. 2022.
\newblock Revisiting the gold standard: Grounding summarization evaluation with
  robust human evaluation.
\newblock \emph{arXiv preprint arXiv:2212.07981}.

\bibitem[{Madaan et~al.(2023)Madaan, Tandon, Gupta, Hallinan, Gao, Wiegreffe,
  Alon, Dziri, Prabhumoye, Yang, Gupta, Majumder, Hermann, Welleck,
  Yazdanbakhsh, and Clark}]{madaan2023selfrefine}
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah
  Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank
  Gupta, Bodhisattwa~Prasad Majumder, Katherine Hermann, Sean Welleck, Amir
  Yazdanbakhsh, and Peter Clark. 2023.
\newblock \href {http://arxiv.org/abs/2303.17651} {Self-refine: Iterative
  refinement with self-feedback}.

\bibitem[{OpenAI(2023)}]{openai2023gpt4}
OpenAI. 2023.
\newblock \href {http://arxiv.org/abs/2303.08774} {Gpt-4 technical report}.

\bibitem[{Press et~al.(2022)Press, Zhang, Min, Schmidt, Smith, and
  Lewis}]{press2022measuring}
Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah~A. Smith, and Mike
  Lewis. 2022.
\newblock \href {http://arxiv.org/abs/2210.03350} {Measuring and narrowing the
  compositionality gap in language models}.

\bibitem[{Schick et~al.(2023)Schick, Dwivedi-Yu, Dessì, Raileanu, Lomeli,
  Zettlemoyer, Cancedda, and Scialom}]{schick2023toolformer}
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli,
  Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.
\newblock \href {http://arxiv.org/abs/2302.04761} {Toolformer: Language models
  can teach themselves to use tools}.

\bibitem[{Schulman(2023)}]{Schulman2023}
John Schulman. 2023.
\newblock Reinforcement learning from human feedback: Progress and challenges.

\bibitem[{Shen et~al.(2023)Shen, Song, Tan, Li, Lu, and
  Zhuang}]{shen2023hugginggpt}
Yongliang Shen, Kaitao Song, Xu~Tan, Dongsheng Li, Weiming Lu, and Yueting
  Zhuang. 2023.
\newblock \href {http://arxiv.org/abs/2303.17580} {Hugginggpt: Solving ai tasks
  with chatgpt and its friends in huggingface}.

\bibitem[{Shi et~al.(2022)Shi, Fried, Ghazvininejad, Zettlemoyer, and
  Wang}]{shi-etal-2022-natural}
Freda Shi, Daniel Fried, Marjan Ghazvininejad, Luke Zettlemoyer, and Sida~I.
  Wang. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.231} {Natural
  language to code translation with execution}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 3533--3546, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Taylor et~al.(2022)Taylor, Kardas, Cucurull, Scialom, Hartshorn,
  Saravia, Poulton, Kerkez, and Stojnic}]{taylor2022galactica}
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony
  Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic.
  2022.
\newblock \href {http://arxiv.org/abs/2211.09085} {Galactica: A large language
  model for science}.

\bibitem[{Thoppilan et~al.(2022)Thoppilan, De~Freitas, Hall, Shazeer,
  Kulshreshtha, Cheng, Jin, Bos, Baker, Du et~al.}]{thoppilan2022lamda}
Romal Thoppilan, Daniel De~Freitas, Jamie Hall, Noam Shazeer, Apoorv
  Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu~Du,
  et~al. 2022.
\newblock Lamda: Language models for dialog applications.
\newblock \emph{arXiv preprint arXiv:2201.08239}.

\bibitem[{Thorne et~al.(2018{\natexlab{a}})Thorne, Vlachos, Christodoulopoulos,
  and Mittal}]{thorne-etal-2018-fever}
James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal.
  2018{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/N18-1074} {{FEVER}: a large-scale
  dataset for fact extraction and {VER}ification}.
\newblock In \emph{Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pages 809--819, New Orleans,
  Louisiana. Association for Computational Linguistics.

\bibitem[{Thorne et~al.(2018{\natexlab{b}})Thorne, Vlachos, Christodoulopoulos,
  and Mittal}]{Thorne18Fever}
James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal.
  2018{\natexlab{b}}.
\newblock {FEVER}: a large-scale dataset for fact extraction and
  {VERification}.
\newblock In \emph{NAACL-HLT}.

\bibitem[{Wang et~al.(2020)Wang, Cho, and Lewis}]{wang-etal-2020-asking}
Alex Wang, Kyunghyun Cho, and Mike Lewis. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.450} {Asking and
  answering questions to evaluate the factual consistency of summaries}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 5008--5020, Online. Association for
  Computational Linguistics.

\bibitem[{Wang et~al.(2023)Wang, Kordi, Mishra, Liu, Smith, Khashabi, and
  Hajishirzi}]{wang2023selfinstruct}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A. Smith, Daniel
  Khashabi, and Hannaneh Hajishirzi. 2023.
\newblock \href {http://arxiv.org/abs/2212.10560} {Self-instruct: Aligning
  language models with self-generated instructions}.

\bibitem[{Wei et~al.(2023)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le,
  and Zhou}]{wei2023chainofthought}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia,
  Ed~Chi, Quoc Le, and Denny Zhou. 2023.
\newblock \href {http://arxiv.org/abs/2201.11903} {Chain-of-thought prompting
  elicits reasoning in large language models}.

\bibitem[{Yin and Neubig(2017)}]{yin-neubig-2017-syntactic}
Pengcheng Yin and Graham Neubig. 2017.
\newblock \href {https://doi.org/10.18653/v1/P17-1041} {A syntactic neural
  model for general-purpose code generation}.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 440--450,
  Vancouver, Canada. Association for Computational Linguistics.

\bibitem[{Zhong et~al.(2020)Zhong, Xu, Tang, Xu, Duan, Zhou, Wang, and
  Yin}]{zhong-etal-2020-reasoning}
Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai
  Wang, and Jian Yin. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.549} {Reasoning over
  semantic-level graph for fact checking}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 6170--6180, Online. Association for
  Computational Linguistics.

\bibitem[{Zhou et~al.(2023)Zhou, Liu, Xu, Iyer, Sun, Mao, Ma, Efrat, Yu, Yu
  et~al.}]{zhou2023lima}
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe
  Ma, Avia Efrat, Ping Yu, Lili Yu, et~al. 2023.
\newblock Lima: Less is more for alignment.
\newblock \emph{arXiv preprint arXiv:2305.11206}.

\end{thebibliography}
