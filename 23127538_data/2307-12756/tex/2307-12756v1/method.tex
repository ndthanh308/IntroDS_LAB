\section{Unbiased Label Correction For Delayed Feedback Problem}
\subsection{Overall Framework}
% Figure environment removed

We propose an Unbiased delayed feedback Label Correction framework (ULC), which aims to address the delay feedback problem in CVR prediction through label correction. The key idea is that delayed feedback leads to and only leads to incorrect labels. If we are able to identify all the incorrect labels and correct them, we can directly calculate the oracle loss.

Fig.\ref{model_fig} illustrates the overall framework of ULC, which consists of a label correction (LC) model and a CVR prediction model. The LC model is designed to predict the probability that an observed unconverted training sample will finally convert, which is used to calculate our proposed label-corrected loss for CVR model training. We prove in Section 4.2 that if the LC model is accurate enough, the label-corrected loss is an unbiased estimate of the oracle loss. 

The next question is how to learn an accurate LC model. As there is no ready training data for the LC model, we leverage counterfactual labeling to generate training data. It constructs the artificial data by imagining a counterfactual data collection time $T' < T$, the details of which will be introduced in Section 4.3. However, counterfactual labeling suffers from some problems, such as inadequate utilization of the whole training data, which we analyze in Section 4.4. To mitigate this problem, we further apply alternative training to re-train these two models, enhancing the performance by transferring the underlying representation of the CVR model to the LC model.

Next, we elaborate on our framework from unbiased loss, data generation with counterfactual labeling, and alternative training, respectively.

\subsection{Unbiased Loss via Label Correction}
If we have a label correction model $g(\cdot;\psi)$, which can predict the probability $w_i$ of a observed non-conversion sample $i$ to be a final conversion sample, i.e., $P(c_i = 1|x_i,e_i, v_i = 0)$. Then we can directly correct the sample label for the observed negative samples and get the following label-corrected (LC) loss:
\begin{equation}
\begin{aligned}
\mathcal{L}_{LC}(\mathcal{D}) = \frac{1}{|\mathcal{D}|}\sum_{i=1}^{|\mathcal{D}|} [ & v_i \log f(x_i;\theta) + w_i (1 - v_i) \log f(x_i; \theta) \\ &+ (1 - w_i)(1 - v_i) \log (1 - f(x_i; \theta)) ]
\end{aligned}
\end{equation}

The above loss is unbiased to the oracle loss if we have an ideal label correction model, as shown in the following theorem.

\begin{theorem}
    If an ideal label correction model is satisfied, i.e., $w_i = P(c_i = 1|x_i, e_i, v_i = 0)$, then the LC loss is unbiased to the oracle loss.
\end{theorem}

\begin{proof} For simplicity, we denote $\log f(x;\theta)$ as $l_\theta$ and $\log (1 - f(x;\theta))$ as $l_{-\theta}$.
\begin{equation*}
\begin{aligned}
    E[\mathcal{L}_{LC}] &= \iint p(x,e) [p(v = 1|x,e) l_\theta + p(c = 1|v=0,x,e)p(v=0|x,e) l_\theta \\ &+ p(c = 0|v=0,x,e)p(v=0|x,e) l_{-\theta})] dedx \\ 
    &=\iint p(x,e) [p(v = 1,c = 1|x,e) l_\theta + p(c = 1,v=0|x,e) l_\theta \\ 
    &+ p(c = 0,v=0|x,e) l_{-\theta})] dedx \\
   &=\iint p(x,e) [p(c = 1|x,e) l_\theta + p(c = 0|x,e) l_{-\theta})] dedx \\
 &=\int p(x) [p(c=1|x) l_\theta + p(c = 0|x) l_{-\theta}))] dx \\ &= E[\mathcal{L}_{oracle}]
\end{aligned}
\end{equation*}
\end{proof}

The advantage of LC loss over the previous unbiased loss (e.g., FSIW and nnDF) is that it directly complements the information of the correct sample corresponding to the false negative samples, i.e., $w_i(1 - v_i)\log f(x_i;\theta)$. The existing unbiased losses complement the corresponding information in indirect ways, which is strongly influenced by data sparsity and data dynamics. For example, in practice, FSIW complements the correct information by increasing the weights of observed positive samples similar to the false negative sample. However, for some fresh false negative samples, there may not exist similar observed positive samples due to the sparsity and dynamics of CVR data. In this case, these indirect methods cannot effectively supplement the corresponding positive sample information, which is important for the delayed feedback problem as false negative samples are often fresh. In contrast, the LC loss can adequately solve this problem as it directly corrects the label and complements the corresponding correct information.

The remaining problem is how to train an accurate LC model, which we introduce in the next section.

\subsection{Data Generation with Counterfactual Labeling}
For the LC model, there is no ready training data. Note that we need samples with $v_i = 0 \ \& \ c_i = 1$ as positive samples and with $v_i = 0 \ \& \ c_i = 0$ as negative samples. However, there are only samples with $v_i = 1 \ \& \ c_i = 1$ and samples with $v_i = 0$ in the original data. To train the LC model, we need to construct artificial samples.

We leverage a counterfactual method \cite{202006} to generate training data for the LC model. First, we imagine that the training data was collected at a \textit{counterfactual deadline} (CD) before the training data's \textit{actual deadline} (AD), i.e., $T$. The time interval $ \tau$ between the CD and the AD is a hyperparameter. Second, the samples that are clicked but have not converted before the CD are collected as training data, together with $e'$ as the elapsed time of these samples at the CD. Third, we treat the samples with conversion between CD and AD as positive samples, i.e., $w=1$, and others as negative samples, i.e., $w = 0$. Obviously, there exist some samples converting after AD are ignored. Nevertheless, as $\tau$ increases, the proportion of these samples keeps getting smaller. The subsequent experiments demonstrate that even a relatively short $\tau$ can effectively alleviate the delayed feedback problem. 

After data generation, we can train the LC model via the classical binary cross-entropy loss. Then the LC model is frozen and utilized to infer $w$ in the above LC loss. Note that the elapsed time $e$ at the AD is used instead of $e'$ when inferring for LC loss. The detailed data generation procedure is shown in Algorithm \ref{alg2} (lines 2-14).

\subsection{Alternative Training}
Although the training data required for the LC model can be constructed by counterfactual labeling, this method still has some drawbacks. First, data generation only leverages partial training data, i.e., samples that are clicked before CD and converted after CD, which may result in the suboptimal performance of LC model. Second, the LC model also suffers somewhat from delayed feedback. Some potential positive samples that have a long delay and convert after AD may be mistreated as negative samples. Next, we propose an alternative learning based approach to alleviate the first problem. The solution to the second problem we leave to future work.

Note that the CVR prediction model is trained on the whole data, and the conversion rate $P(c = 1|x)$ is similar to the label correction rate $P(c = 1|x,e, v = 0)$. We suppose that the bottom representation (i.e., the embedding layer in Fig.\ref{model_fig}) learned by the CVR model may facilitate the learning of the LC model and alleviate the first problem mentioned above. Therefore, we adopt an alternative learning paradigm. After training the CVR prediction model, the bottom representation of the LC model is initialized using the bottom representation of the CVR prediction model, and then the LC model is retrained. The retrained LC model can be further used for the retraining of the CVR model. The alternative training procedure is shown in Algorithm \ref{alg2}.

\begin{algorithm}
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
	\caption{Alternative training with data generation}
	\label{alg2}
	\begin{algorithmic}[1]
            \REQUIRE training data $\mathcal{D} = \{(x_i, v_i, e_i, cts_i, cvt_i)\}$, $T$ is the timestamp when the data $\mathcal{D}$ are collected, where $x_i$ is the feature vector, $v_i$ is the observed conversion label, $e_i$ is elapsed time since the click timestamp $cts_i$, $cvt_i$ is the conversion timestamp. $\tau$ is a hyperparameter denoting the time interval between CD and AD. $n$ is the rounds of alternative training.
            \ENSURE CVR prediction model $M_{cvr}$
		\STATE Initialize CVR prediction model $M_{cvr}$ and LC model $M_{lc}$
            \STATE // \textit{start to generate data $\mathcal{D}_{lc}$ for LC model training}
		\STATE $\mathcal{D}_{lc} = \emptyset$
            \FOR{$i=1$ to $|\mathcal{D}|$}
                \IF{$cts_i < T - \tau$ and ($v_i == 0$ or $cvt_i > T - \tau$)}
                    \IF{$cvt_i > T - \tau$}
                        \STATE Label the sample $i$ as $w_i = 1$
                    \ELSE
                        \STATE Label the sample $i$ as $w_i = 0$
                    \ENDIF
                    \STATE Insert the sample $(x_i, e_i - \tau, w_i)$ to $\mathcal{D}_{lc}$
                \ENDIF
            \ENDFOR
            \STATE // \textit{finish data generation, start to alternative training}
            \FOR{$i = 1$ to $n + 1$}
                \STATE Initialize $M_{cvr}$
                \STATE Initialize $M_{lc}$ except bottom embeddings
                \STATE Training $M_{lc}$ on $\mathcal{D}_{lc}$ until converge
                \STATE Training $M_{cvr}$ on $\mathcal{D}$ using LC loss until converge
                \STATE Transfer the bottom embeddings from $M_{cvr}$ to $M_{lc}$
            \ENDFOR
            \RETURN CVR prediction model $M_{cvr}$
	\end{algorithmic}  
\end{algorithm}

There are some alternatives compared to alternative training with embedding transfer. For example, joint learning is also a common learning paradigm that enables the LC model to leverage the knowledge of the CVR model. Moreover, in addition to utilizing the learned representation of the CVR model, another easily thought of option is to leverage its prediction. It is possible to mine the mislabeled samples in the training data for the LC model using the CVR prediction model as these potential positive samples might have a high predicted CVR. We also conduct experiments and compare these alternatives in experiment section 5.4.