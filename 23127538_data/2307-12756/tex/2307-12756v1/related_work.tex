\section{Related Work}
\subsection{CVR Prediction}
The CVR prediction task shares many similarities with the widely studied CTR prediction task. They both predict the probability of a user performing a certain behavior on an ad or an item. Besides, their inputs are generally the same. Generally, the model structure designed for the CTR task can also be applied to CVR prediction. Thus, existing research on CVR prediction focuses more on the differences between CVR and CTR.

There are three main challenges for CVR prediction. First, the data for the CVR task are often more sparse than the CTR task. Existing research mitigates this problem through multi-task learning \cite{201902,201903} and pre-training \cite{202001}. Second, CVR prediction suffers from selection bias. The CVR prediction model is trained on click samples but infers for all exposure samples during inference. Differences in exposure distribution and click distribution lead to selection bias, which existing work addresses through entire sample space modeling \cite{202003,201803,202101,ESCM2}, inverse propensity score \cite{202004,202005}, and doubly robust methods \cite{202008,202105}. Third, conversions do not happen as immediately as clicks, with some conversions taking days or even a week. This could result in some positive samples that have not yet converted being incorrectly treated as negative samples. Existing studies address it by delay time modeling \cite{201401, 201801, 202002} or importance sampling \cite{202006,202106}, which we will detail in Session 2.2.
In this work, we focus on the third challenge, the delayed feedback problem, and leave the extension of our method to other problems for future work.

\subsection{Delayed Feedback}
Here we only focus on the delayed feedback problem in the offline setting.

To our knowledge, the delayed feedback problem was first studied by DFM \cite{201401}. DFM models the delay time explicitly. It assumes that the delay time obeys an exponential distribution and then optimizes the maximum likelihood of the currently observed data labels. \cite{201801} extends this approach further by using a non-parametric approach to modeling delay time. A drawback of the above methods is that they try to optimize the observed conversion information instead of directly optimizing the true conversion information.

In contrast to explicitly modeling delay time, recent work \cite{202006, 202204} attempts to address the delay feedback problem by constructing unbiased estimates of the oracle loss that uses true labels. FSIW \cite{202006} leverages importance sampling to construct an unbiased loss.
Intuitively, it increases the weight of observed positive samples and decreases the weight of potentially negative samples as these samples may be mislabeled.
Besides, nnDF \cite{202204} assumes that the labels of samples before a time window are accurate and then uses these samples to correct for the biased loss of the whole training data.
A drawback of the above methods is that, despite their theoretical guarantee of unbias, they might fail to introduce information about the correct positive sample for each specific false negative sample. For FSIW, it only reduces the weight of the mislabeled samples but cannot introduce the information of the corrected sample, i.e., the weight of the corresponding correct sample is still zero. For nnDF, it does not process recent samples, and therefore cannot introduce information about the correct samples among them. This problem is worse when the data distribution has changed recently. As the information about the false negative samples may differ from the past observed positive samples, only using the observed positive samples cannot complement the correct information about the fresh false negative samples.

Unlike the above state-of-art approaches, we propose to correct the label for each observed negative sample so that the information of the correct sample can be introduced directly. Besides, it can also be proved theoretically that the label-corrected loss is an unbiased estimate of the oracle loss.