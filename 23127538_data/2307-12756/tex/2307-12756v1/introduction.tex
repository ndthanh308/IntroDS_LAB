\section{Introduction}
Predicting the probability of users clicking or converting on ads or items is critical to many online applications, such as digital display advertising and recommender systems. Take online advertising as an example. Generally, ad delivery platforms provide advertisers with several optional billing models, such as Cost Per thousand iMpressions (CPM), Cost Per Click (CPC) and Cost Per Acquisition (CPA), in which CPA is preferred as the conversion is closer to advertisers' profits. For the CPA model, predicting the click rate and conversion rate of users to the placed advertisements is the key to achieving more revenue, which are also known as the Click-Through Rate (CTR) and Conversion Rate (CVR) prediction tasks. These two tasks have received increasing attention from industry and academia in recent years \cite{din, deepfm,ctr21}.

Model freshness is important for CTR and CVR prediction models as user interests change dynamically. A common strategy to keep fresh in the industry is to retrain the model daily or weekly on all collected data. This simple strategy can be effective for CTR prediction. However, the delay of conversion behavior makes it challenging to ensure the freshness of CVR models, which is called \textit{Delayed Feedback Problem}. Unlike click behavior happening quickly within minutes of impression, conversions occur much more slowly after days, sometimes taking up to weeks \cite{201401}.
This leads that the ground truth of recently clicked but unconverted samples is unknown as they may convert in the future. 

A vanilla solution is to treat all these unconverted samples as negative feedback, which will cause some positive samples (i.e., real conversions) to be mislabeled, leading to the false negative problem. These mislabeled samples can significantly damage the performance of the CVR prediction model as they are important to the model freshness. Another obvious solution is to wait for a long time until the labels are accurate enough. However, this means that the data is old, which conflicts with the purpose of keeping models fresh. Thus, the delayed feedback problem reflects a trade-off between model freshness and label correctness.
Therefore, handling fresh unconverted data with unknown labels is an important challenge for CVR prediction.

Existing methods for the delayed feedback problem can be classified into two types based on the problem setting: online training \cite{201904,202102,202103,202106,202110,202202, nips22, calibration22} and offline training \cite{201401,201801,202006,202007}. 
In the online setting, when new user behaviors are logged, the model is immediately updated on the new data to keep it fresh.
In the offline setting, the model is retrained daily or weekly on all collected data to ensure freshness.
Industrial systems often choose the appropriate training setting based on their business requirements \cite{202106}. The methods under different settings are quite different, and here we only focus on the offline training.

To our knowledge, DFM \cite{201401} first studied the delayed feedback problem. They propose to explicitly model delay time with delay distribution assumptions. However, the actual delay may not obey the assumptions, which leads to its suboptimal performance. Recent work \cite{202006, 202204} in offline learning attempts to construct unbiased estimates of the oracle loss that uses true labels to alleviate the delayed feedback problem. However, although these methods are theoretically unbiased, we argue that they may fail to introduce the correct information about false negative samples, as they do not construct the correct samples corresponding to these mislabeled samples.

In this paper, we aim to address the delayed feedback problem in CVR prediction through label correction. We theoretically prove that if the label of the observed unconverted samples can be corrected to its probability of being a false negative sample, the label-corrected loss will be an unbiased estimate of the oracle loss that uses true labels. Compared to existing unbiased methods for delayed feedback, the advantage of label correction is that it directly complements the information of the correct samples corresponding to the false negative samples. Further, we attempt to train a label correction (LC) model to correct the labels for the observed unconverted samples. If the LC model is accurate enough, the delayed feedback problem can be well addressed.

However, how to train an accurate LC model is non-trivial. Above all, there exist no ready training data for the LC model. We use a counterfactual labeling method to construct artificial training data by setting a counterfactual deadline. Nevertheless, counterfactual labeling utilizes only partial training data. To enhance the performance of the LC model, we further designed an alternative learning method based on embedding transfer. To demonstrate the effectiveness of our method, we conduct extensive experiments on the public and private datasets. Experimental results show that our method can effectively alleviate the delayed feedback problem.
Our main contributions can be summarized as follows.
\begin{itemize}[leftmargin=*]
    \item To the best of our knowledge, it is the first work in the offline training setting to use an unbiased label correction approach to solve the delayed feedback problem of CVR prediction.
    \item We give a theoretical analysis of unbiased label learning and propose an alternative learning framework for CVR prediction to meet the delayed feedback challenge.
    \item Comparative experimental results on both public and private datasets demonstrate the effectiveness of our proposed framework.
\end{itemize}