% \begin{abstract}
%   % With the development of multi-modal learning, object detection task is not limited to pre-defined categories in a dataset, but any categories described by language, which is called open-vocabulary detection. Recently, there are task that deals with OVD and referring expression comprehension (REC) together, as they both want to locate object based on language description.
%   % Observing the natural limit of detection (detecting only based on short category names, we call \textit{category-guided detection}) and REC (assuming that one and only one object exist in the image that is referred, we call \textit{language-guided grounding}), we propose a new setting that is the mixture of this two task, but more realistic to both: that is, detect the things described by language (\textit{language-guided detection}). For this setting, we propose a dataset, which refers to instance by long description (contrary to OD) and make no assumption on instance existence (contrary to REC).
%   % Besides, we notice previous datasets only locate object with some attribute, but not without some attribute. So we extend the annotation to locate such objects. 
%   % We ablate 5 representative works that achieves SOTA on their original tasks, and designed a new baseline method that outperforms these previous methods on this benchmark.
%   Object understanding is an essential aspect of computer vision tasks, and two representative tasks in this area are object detection (OD) and referring expression comprehension (REC), both require to locate certain objects with references (category names or language descriptions). However, these tasks have limitations, such as the restriction of simple category names for reference in OD or the assumption that there is one and only one instance referred in an image in REC. With the development of multi-modal learning, the gap between these tasks are narrowed. We propose a more flexible and realistic setting called omni-expression detection, which is more realistic and general compared with previous tasks. In this setting, models are required to detect all instances corresponding to free-form language expressions from a dataset. We propose a benchmark with important characteristics like unrestricted language reference, complete annotation, and absence expressions, making it more challenging than existing benchmarks.
%   We evaluate several state-of-the-art methods from previous tasks on the proposed dataset, and propose a new method that outperforms them and can serve as a proposed baseline for future research.
%   Extensive experimental analyses over these methods further dissect the characteristics of the proposed benchmark as well as the difference between previous tasks and methods over this setting.
%   We hope the setting, together with the benchmark, could be useful for general object understanding.
%   Code and data will be released.
% \end{abstract}


\begin{abstract}
    Detecting objects based on language descriptions is a popular task that includes Open-Vocabulary object Detection (OVD) and Referring Expression Comprehension (REC). In this paper, we advance them to a more practical setting called \textit{Described Object Detection} (DOD) by expanding category names to flexible language expressions for OVD and overcoming the limitation of REC to only grounding the pre-existing object. 
    We establish the research foundation for DOD tasks by constructing a \textit{Description Detection Dataset} (\ddd{}), featuring flexible language expressions and annotating all described objects without omission.
    By evaluating previous SOTA methods on \ddd{}, we find some troublemakers that fail current REC, OVD, and bi-functional methods.
    REC methods struggle with confidence scores, rejecting negative instances, and multi-target scenarios, while OVD methods face constraints with long and complex descriptions. Recent bi-functional methods also do not work well on DOD due to their separated training procedures and inference strategies for REC and OVD tasks.
    Building upon the aforementioned findings, we propose a baseline that largely improves REC methods by reconstructing the training data and introducing a binary classification sub-task, outperforming existing methods. 
    % We will publicly release the codes and our dataset.
    Data and code is available at \href{https://github.com/shikras/d-cube}{this URL}.
\end{abstract}
