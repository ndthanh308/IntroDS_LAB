\section{Baselines}
\label{sec:baselines}

\subsection{Existing baselines from different tasks}
\label{subsec:existing_baselines}

We choose multiple advanced methods as the baselines to verify on the proposed \ddd{}, from OVD, REC to bi-functional methods.
% Methods in these tasks are various, and we try to select methods that are more diverse on data, backbone and framework.
% They are summarized in \cref{tab:baselines}.

% \input{tables/baselines}

\noindent \textbf{REC methods.}
We try the state-of-the-art REC method, OFA~\cite{wang2022ofa}, with 2 variants.
OFA is based on an encoder-decoder, Seq-to-seq framework. It is a multi-modal multi-task generalist that deals with different tasks together, and trained on various tasks including language task (mask language modeling), image-to-text (image captioning and VQA) and localization (REC). Notably, though it is trained with detection dataset, it is not evaluated on object detection and achieves poor performance if we do. Currently it holds the SOTA performance on standard REC benchmarks like RefCOCO series.

\noindent \textbf{OVD methods.}
We try OWL-ViT~\cite{minderer2022simpleOWLViT} with two variants and CORA~\cite{wu2023cora}. They are the SOTA methods on OVD tasks, with a simple vision transformer architecture. It is pretrained with image-text contrastive learning and then fine-tuned on detection dataset.

\noindent \textbf{Bi-functional methods utilizing both REC and OVD data.}
Methods falling into this category are few. We try two methods: Grounding-DINO~\cite{liu2023groundingdino} and UNINEXT~\cite{yan2023universal}, each with 2 variants. Both of them are based on DETR~\cite{carion2020end}. They are pretrained on multiple datasets including detection and REC datasets, and then evaluated without single-task fine-tuning.

\subsection{A proposed baseline}
\label{subsec:our_baseline}
The proposed \ddd{} benchmark is challenging and existing works do not perform well, which we will show in \cref{subsec:experimental_comp}. We choose one of them to make adjustment and provide a better baseline.
The chosen work should (1) be capable of understanding text of various length, as the descriptions in \ddd{} are unrestricted; (2) be strong on their original tasks; (3) have a framework with rather simple technical design, so that we can modify its components easily.
We choose OFA, as it (1) is a multi-modal multi-task framework with MLM and image-to-text pretraining; (2) achieve SOTA on REC; (3) has a simple seq2seq framework.

However, OFA faces several problems that makes it still hard for this task, which we will discuss in \cref{sec:experiments}. First, forcing multiple tasks of different modalities into one seq2seq framework, hurts the performance of specific tasks, especially tasks related to localization. Second, training on grounding task results in bad ability for handling multiple instances. We try the model on MSCOCO, and it obtains less than 10 mAP. Thirdly, its REC paradigm also makes it always predict one instance, and unable to reject negative images and irrelevant descriptions.
Therefore, we make some modification on OFA to make it more suitable for this task.

The first is \textbf{granularity decomposition}, to make it more suitable for localization task.
We break the pretraining tasks of OFA into 2 different granularities: global (tasks related to language modeling, like captioning, VQA, MLM, etc.) and local (related to localization, like detection and REC). We add an additional decoder parallel to the original decoder into OFA that carries out the local tasks, while the original decoder only performs the global tasks. This alleviates the conflicts between different tasks, and helps better localization.
% We denote this model as \textbf{OFA-2B}, meaning OFA with two branches.

The second is \textbf{reconstructed data} for pretraining on REC, to improve multi-target localization. We reconstruct the data of REC to make sure that (1) for an image, multiple references are input, and (2) a reference does not necessary correspond to one object, but zero to multiple. This results in a unified data format for OD and REC, though the labels are noisy as they are not initially prepared for DOD.
% We denote this as \textbf{OFA-2B-RD}.
% \Todo{how to avoid misunderstanding of refcoco reconstruction here}.

The third is \textbf{task decomposition}, to empower it with the ability to reject false positives. We reformulate the training on reconstructed data into 2 tasks, which is REC (for locating a region based on a reference) and VQA (for deciding if a region and a reference match each other, essentially a binary classification). The second step is responsible for rejecting possible false positives.
% For inference, we perform REC and VQA sequentially for each reference sequentially.

We denote the model with all 3 modifications as \textbf{OFA-DOD}.
More details on the proposed improvement are in the \supp{}.
Note that this model is far from perfect for the complex \ddd{} benchmark. As we will show in \cref{subsec:experimental_comp}, though it outperforms existing methods, it merely serves as a baseline for future tasks on \ddd{}.
