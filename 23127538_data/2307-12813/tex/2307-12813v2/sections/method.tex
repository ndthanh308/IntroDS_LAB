\section{Baselines}
\label{sec:baselines}

\subsection{Existing baselines from different tasks}
\label{subsec:existing_baselines}

We choose multiple advanced methods to verify on \ddd{} from OVD, REC to bi-functional methods. More details of these methods and their inference process are in our \supp{}.

\noindent \textbf{REC methods.}
We employ the state-of-the-art REC method, OFA~\cite{wang2022ofa}, with two variants.
OFA is based on an encoder-decoder, sequence-to-sequence framework. It is a multi-modal multi-task generalist that deals with different tasks together and is trained on various tasks, including language tasks (masked language modeling), image-to-text tasks (image captioning and Visual Question Answering (VQA)), and localization tasks (REC). Notably, although it is trained with a detection dataset, it is not evaluated on object detection and achieves poor performance if we do. Currently, it holds the SOTA performance on standard REC benchmarks like the RefCOCO series.

\noindent \textbf{OVD methods.}
We evaluate OWL-ViT~\cite{minderer2022simpleOWLViT} with two variants and CORA~\cite{wu2023cora}. They are the SOTA methods on OVD tasks, with a vision transformer as well as a language transformer. They are pretrained with image-text contrastive learning and then fine-tuned on detection dataset.

\noindent \textbf{Bi-functional methods utilizing both REC and OVD data.}
Methods falling into this category are not many but emerging fast recently. We test two methods: Grounding-DINO~\cite{liu2023groundingdino} and UNINEXT~\cite{yan2023universal}, each with two variants. Both of them are based on DETR~\cite{carion2020end}. They are pretrained on multiple datasets, including detection and REC datasets, and then evaluated with different strategies for different tasks.

\subsection{A proposed baseline}
\label{subsec:our_baseline}

\ddd{} is very challenging for existing works, as we will demonstrate in \cref{subsec:experimental_comp}. We have selected one of these works for adjustment to provide a better baseline.
The chosen work should (1) be capable of understanding text of various lengths; (2) excel in their original tasks; (3) have a framework with a rather simple technical design, allowing us to modify its components easily. We have chosen OFA because it (1) is a multi-modal multi-task framework with MLM (Masked Language Modeling) and image-to-text pretraining; (2) achieves SOTA on REC; (3) has a simple seq2seq framework.

However, OFA faces several problems that make it unsatisfactory for this task, as discussed in \cref{sec:experiments}. First, forcing multiple tasks of different modalities into one seq2seq framework adversely affects the performance of specific tasks, especially tasks related to localization. Second, training on the grounding task results in poor ability to handle multiple instances. We evaluated the model on COCO detection, and it achieved less than 10 mAP. Thirdly, its REC paradigm also makes it predict only one instance, making it unable to reject negative images and irrelevant descriptions.

Therefore, we have made some modifications to OFA to make it more suitable for this task.
The first modification is \textbf{granularity decomposition} to make it more suitable for localization. We have divided the pretraining tasks of OFA into two different granularities: global tasks (related to language modeling, such as captioning, VQA, MLM, etc.) and local tasks (related to localization, such as detection and REC). We have added an additional decoder parallel to the original decoder in OFA that handles the local tasks, while the original decoder focuses on the global tasks. This alleviates conflicts between different tasks and enhances localization.

The second modification is \textbf{reconstructed data} for pretraining on REC, aiming to improve multi-target localization. We have reconstructed the data for REC to ensure that (1) multiple references are input for an image, and (2) a reference does not necessarily correspond to one object, but zero or multiple. This results in a unified data format for detection and REC, although the labels may be noisy since they were not initially prepared for DOD.

The third modification is \textbf{task decomposition} to empower the model with the ability to reject false positives. We have reformulated the training on reconstructed data into two tasks: REC (for locating a region based on a reference) and VQA (for determining if a region and a reference match each other, essentially a binary classification). The second step is responsible for rejecting false positives.
% For inference, we perform REC and VQA sequentially for each reference.

We refer to the model with all three modifications as \textbf{OFA-DOD}. More details on the proposed improvements can be found in the \supp{}.
It is important to note that this model is far from perfect for the complex \ddd{} benchmark. As we will show in \cref{subsec:experimental_comp}, although it outperforms existing methods, it serves as a baseline for future tasks on \ddd{}.
