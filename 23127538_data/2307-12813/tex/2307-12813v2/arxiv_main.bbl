\begin{thebibliography}{10}

\bibitem{arbelle2021detector}
A.~Arbelle, S.~Doveh, A.~Alfassy, J.~Shtok, G.~Lev, E.~Schwartz, H.~Kuehne,
  H.~B. Levi, P.~Sattigeri, R.~Panda, et~al.
\newblock Detector-free weakly supervised grounding by separation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1801--1812, 2021.

\bibitem{bai2023qwenvl}
J.~Bai, S.~Bai, S.~Yang, S.~Wang, S.~Tan, P.~Wang, J.~Lin, C.~Zhou, and
  J.~Zhou.
\newblock Qwen-vl: A frontier large vision-language model with versatile
  abilities.
\newblock {\em arXiv preprint arXiv:2308.12966}, 2023.

\bibitem{cai2022bigdetection}
L.~Cai, Z.~Zhang, Y.~Zhu, L.~Zhang, M.~Li, and X.~Xue.
\newblock Bigdetection: A large-scale benchmark for improved object detector
  pre-training.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4777--4787, 2022.

\bibitem{carion2020end}
N.~Carion, F.~Massa, G.~Synnaeve, N.~Usunier, A.~Kirillov, and S.~Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part I 16}, pages 213--229.
  Springer, 2020.

\bibitem{chen2023shikra}
K.~Chen, Z.~Zhang, W.~Zeng, R.~Zhang, F.~Zhu, and R.~Zhao.
\newblock Shikra: Unleashing multimodal llm's referential dialogue magic.
\newblock {\em arXiv preprint arXiv:2306.15195}, 2023.

\bibitem{chen2020uniter}
Y.-C. Chen, L.~Li, L.~Yu, A.~El~Kholy, F.~Ahmed, Z.~Gan, Y.~Cheng, and J.~Liu.
\newblock Uniter: Universal image-text representation learning.
\newblock In {\em Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX}, pages 104--120.
  Springer, 2020.

\bibitem{chen2020copsref}
Z.~Chen, P.~Wang, L.~Ma, K.-Y.~K. Wong, and Q.~Wu.
\newblock Cops-ref: A new dataset and task on compositional referring
  expression comprehension.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10086--10095, 2020.

\bibitem{deng2021transvg}
J.~Deng, Z.~Yang, T.~Chen, W.~Zhou, and H.~Li.
\newblock Transvg: End-to-end visual grounding with transformers.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1769--1779, 2021.

\bibitem{dosovitskiy2021image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit,
  and N.~Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{dou2022fiber}
Z.-Y. Dou, A.~Kamath, Z.~Gan, P.~Zhang, J.~Wang, L.~Li, Z.~Liu, C.~Liu,
  Y.~LeCun, N.~Peng, et~al.
\newblock Coarse-to-fine vision-language pre-training with fusion in the
  backbone.
\newblock {\em Advances in neural information processing systems},
  35:32942--32956, 2022.

\bibitem{Everingham2010}
M.~Everingham, L.~Van~Gool, C.~K. Williams, J.~Winn, and A.~Zisserman.
\newblock The pascal visual object classes (voc) challenge.
\newblock {\em International journal of computer vision}, 2010.

\bibitem{ghiasi2022scaling}
G.~Ghiasi, X.~Gu, Y.~Cui, and T.-Y. Lin.
\newblock Scaling open-vocabulary image segmentation with image-level labels.
\newblock In {\em Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVI}, pages 540--557.
  Springer, 2022.

\bibitem{gu2022openvocabulary}
X.~Gu, T.-Y. Lin, W.~Kuo, and Y.~Cui.
\newblock Open-vocabulary object detection via vision and language knowledge
  distillation.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{gupta2019lvis}
A.~Gupta, P.~Dollar, and R.~Girshick.
\newblock Lvis: A dataset for large vocabulary instance segmentation.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 5356--5364, 2019.

\bibitem{hu2017modeling}
R.~Hu, M.~Rohrbach, J.~Andreas, T.~Darrell, and K.~Saenko.
\newblock Modeling relationships in referential expressions with compositional
  modular networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1115--1124, 2017.

\bibitem{kamath2021mdetr}
A.~Kamath, M.~Singh, Y.~LeCun, G.~Synnaeve, I.~Misra, and N.~Carion.
\newblock Mdetr-modulated detection for end-to-end multi-modal understanding.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1780--1790, 2021.

\bibitem{kazemzadeh2014referitgame}
S.~Kazemzadeh, V.~Ordonez, M.~Matten, and T.~Berg.
\newblock Referitgame: Referring to objects in photographs of natural scenes.
\newblock In {\em EMNLP}, pages 787--798, 2014.

\bibitem{Krasin2017}
I.~Krasin, T.~Lin, T.~Duerig, P.~Kr\"{a}henb\"{u}hl, A.~Gupta, C.~Burgess, and
  V.~Ferrari.
\newblock {OpenImages}: A public dataset for large-scale multi-label and
  multi-class image classification.
\newblock {\em Dataset available from https://github.com/openimages}, 2017.

\bibitem{krishna2017visualgenome}
R.~Krishna, Y.~Zhu, O.~Groth, J.~Johnson, K.~Hata, J.~Kravitz, S.~Chen,
  Y.~Kalantidis, L.-J. Li, D.~A. Shamma, et~al.
\newblock Visual {G}enome: Connecting language and vision using crowdsourced
  dense image annotations.
\newblock {\em IJCV}, 123:32--73, 2017.

\bibitem{kuo2022findit}
W.~Kuo, F.~Bertsch, W.~Li, A.~Piergiovanni, M.~Saffar, and A.~Angelova.
\newblock Findit: Generalized localization with natural language queries.
\newblock In {\em European Conference on Computer Vision}. Springer, 2022.

\bibitem{li2022elevater}
C.~Li, H.~Liu, L.~Li, P.~Zhang, J.~Aneja, J.~Yang, P.~Jin, H.~Hu, Z.~Liu, Y.~J.
  Lee, et~al.
\newblock Elevater: A benchmark and toolkit for evaluating language-augmented
  visual models.
\newblock {\em Advances in Neural Information Processing Systems},
  35:9287--9301, 2022.

\bibitem{li2022grounded}
L.~H. Li, P.~Zhang, H.~Zhang, J.~Yang, C.~Li, Y.~Zhong, L.~Wang, L.~Yuan,
  L.~Zhang, J.-N. Hwang, et~al.
\newblock Grounded language-image pre-training.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10965--10975, 2022.

\bibitem{li2021referring}
M.~Li and L.~Sigal.
\newblock Referring transformer: A one-step approach to multi-task visual
  grounding.
\newblock {\em Advances in neural information processing systems},
  34:19652--19664, 2021.

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan,
  P.~Doll{\'a}r, and C.~L. Zitnick.
\newblock Microsoft {COCO}: Common objects in context.
\newblock In {\em ECCV}, pages 740--755. Springer, 2014.

\bibitem{liu2023polyformer}
J.~Liu, H.~Ding, Z.~Cai, Y.~Zhang, R.~K. Satzoda, V.~Mahadevan, and
  R.~Manmatha.
\newblock Polyformer: Referring image segmentation as sequential polygon
  generation.
\newblock In {\em CVPR}, 2023.

\bibitem{liu2023groundingdino}
S.~Liu, Z.~Zeng, T.~Ren, F.~Li, H.~Zhang, J.~Yang, C.~Li, J.~Yang, H.~Su,
  J.~Zhu, et~al.
\newblock Grounding dino: Marrying dino with grounded pre-training for open-set
  object detection.
\newblock {\em arXiv preprint arXiv:2303.05499}, 2023.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 10012--10022, 2021.

\bibitem{lu2022unified}
J.~Lu, C.~Clark, R.~Zellers, R.~Mottaghi, and A.~Kembhavi.
\newblock Unified-io: A unified model for vision, language, and multi-modal
  tasks.
\newblock {\em arXiv preprint arXiv:2206.08916}, 2022.

\bibitem{luo2020multi}
G.~Luo, Y.~Zhou, X.~Sun, L.~Cao, C.~Wu, C.~Deng, and R.~Ji.
\newblock Multi-task collaborative network for joint referring expression
  comprehension and segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on computer vision and
  pattern recognition}, pages 10034--10043, 2020.

\bibitem{mao2016generation}
J.~Mao, J.~Huang, A.~Toshev, O.~Camburu, A.~L. Yuille, and K.~Murphy.
\newblock Generation and comprehension of unambiguous object descriptions.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 11--20, 2016.

\bibitem{minderer2022simpleOWLViT}
M.~Minderer, A.~Gritsenko, A.~Stone, M.~Neumann, D.~Weissenborn,
  A.~Dosovitskiy, A.~Mahendran, A.~Arnab, M.~Dehghani, Z.~Shen, et~al.
\newblock Simple open-vocabulary object detection.
\newblock In {\em European Conference on Computer Vision}, pages 728--755.
  Springer, 2022.

\bibitem{ordonez2011im2text}
V.~Ordonez, G.~Kulkarni, and T.~Berg.
\newblock Im2text: Describing images using 1 million captioned photographs.
\newblock {\em Advances in neural information processing systems}, 24, 2011.

\bibitem{peng2023kosmos}
Z.~Peng, W.~Wang, L.~Dong, Y.~Hao, S.~Huang, S.~Ma, and F.~Wei.
\newblock Kosmos-2: Grounding multimodal large language models to the world.
\newblock {\em arXiv preprint arXiv:2306.14824}, 2023.

\bibitem{plummer2020phrasedet}
B.~A. Plummer, K.~J. Shih, Y.~Li, K.~Xu, S.~Lazebnik, S.~Sclaroff, and
  K.~Saenko.
\newblock Revisiting image-language networks for open-ended phrase detection.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  44(4):2155--2167, 2020.

\bibitem{plummer2015flickr30k}
B.~A. Plummer, L.~Wang, C.~M. Cervantes, J.~C. Caicedo, J.~Hockenmaier, and
  S.~Lazebnik.
\newblock Flickr30k entities: Collecting region-to-phrase correspondences for
  richer image-to-sentence models.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2641--2649, 2015.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International conference on machine learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{sadhu2019zeroshotgrounding}
A.~Sadhu, K.~Chen, and R.~Nevatia.
\newblock Zero-shot grounding of objects from natural language queries.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4694--4703, 2019.

\bibitem{shao2019objects365}
S.~Shao, Z.~Li, T.~Zhang, C.~Peng, G.~Yu, X.~Zhang, J.~Li, and J.~Sun.
\newblock Objects365: A large-scale, high-quality dataset for object detection.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 8430--8439, 2019.

\bibitem{sharma2018conceptual}
P.~Sharma, N.~Ding, S.~Goodman, and R.~Soricut.
\newblock Conceptual captions: A cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In {\em Proceedings of the 56th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 2556--2565, 2018.

\bibitem{song2021co}
S.~Song, X.~Lin, J.~Liu, Z.~Guo, and S.-F. Chang.
\newblock Co-grounding networks with semantic attention for referring
  expression comprehension in videos.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 1346--1355, 2021.

\bibitem{subramanian2022reclip}
S.~Subramanian, W.~Merrill, T.~Darrell, M.~Gardner, S.~Singh, and A.~Rohrbach.
\newblock Reclip: A strong zero-shot baseline for referring expression
  comprehension.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for
  Computational Linguistics}, Dublin, Ireland, May 2022. Association for
  Computational Linguistics.

\bibitem{thomee2016yfcc100m}
B.~Thomee, D.~A. Shamma, G.~Friedland, B.~Elizalde, K.~Ni, D.~Poland, D.~Borth,
  and L.-J. Li.
\newblock Yfcc100m: The new data in multimedia research.
\newblock {\em Communications of the ACM}, 59(2):64--73, 2016.

\bibitem{wang2023v3det}
J.~Wang, P.~Zhang, T.~Chu, Y.~Cao, Y.~Zhou, T.~Wu, B.~Wang, C.~He, and D.~Lin.
\newblock V3det: Vast vocabulary visual detection dataset.
\newblock In {\em The IEEE International Conference on Computer Vision (ICCV)},
  October 2023.

\bibitem{wang2022ofa}
P.~Wang, A.~Yang, R.~Men, J.~Lin, S.~Bai, Z.~Li, J.~Ma, C.~Zhou, J.~Zhou, and
  H.~Yang.
\newblock Ofa: Unifying architectures, tasks, and modalities through a simple
  sequence-to-sequence learning framework.
\newblock In {\em International Conference on Machine Learning}, pages
  23318--23340. PMLR, 2022.

\bibitem{wu2020phrasecut}
C.~Wu, Z.~Lin, S.~Cohen, T.~Bui, and S.~Maji.
\newblock Phrasecut: Language-based image segmentation in the wild.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10216--10225, 2020.

\bibitem{wu2023cora}
X.~Wu, F.~Zhu, R.~Zhao, and H.~Li.
\newblock Cora: Adapting clip for open-vocabulary detection with region
  prompting and anchor pre-matching.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7031--7040, 2023.

\bibitem{wu2023gres}
Y.~Wu, Z.~Zhang, C.~Xie, F.~Zhu, and R.~Zhao.
\newblock Advancing referring expression segmentation beyond single image.
\newblock In {\em International Conference on Computer Vision (ICCV)}, 2023.

\bibitem{yan2023universal}
B.~Yan, Y.~Jiang, J.~Wu, D.~Wang, P.~Luo, Z.~Yuan, and H.~Lu.
\newblock Universal instance perception as object discovery and retrieval.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15325--15336, 2023.

\bibitem{yao2022detclip}
L.~Yao, J.~Han, Y.~Wen, X.~Liang, D.~Xu, W.~Zhang, Z.~Li, C.~Xu, and H.~Xu.
\newblock Detclip: Dictionary-enriched visual-concept paralleled pre-training
  for open-world detection.
\newblock {\em Advances in Neural Information Processing Systems},
  35:9125--9138, 2022.

\bibitem{yu2016modeling}
L.~Yu, P.~Poirson, S.~Yang, A.~C. Berg, and T.~L. Berg.
\newblock Modeling context in referring expressions.
\newblock In {\em Computer Vision--ECCV 2016: 14th European Conference,
  Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
  pages 69--85. Springer, 2016.

\bibitem{zang2022open}
Y.~Zang, W.~Li, K.~Zhou, C.~Huang, and C.~C. Loy.
\newblock Open-vocabulary detr with conditional matching.
\newblock In {\em Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part IX}, pages 106--122.
  Springer, 2022.

\bibitem{zareian2021open}
A.~Zareian, K.~D. Rosa, D.~H. Hu, and S.-F. Chang.
\newblock Open-vocabulary object detection using captions.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 14393--14402, 2021.

\bibitem{zhang2023dino}
H.~Zhang, F.~Li, S.~Liu, L.~Zhang, H.~Su, J.~Zhu, L.~Ni, and H.-Y. Shum.
\newblock {DINO}: {DETR} with improved denoising anchor boxes for end-to-end
  object detection.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{zhang2022glipv2}
H.~Zhang, P.~Zhang, X.~Hu, Y.-C. Chen, L.~Li, X.~Dai, L.~Wang, L.~Yuan, J.-N.
  Hwang, and J.~Gao.
\newblock Glipv2: Unifying localization and vision-language understanding.
\newblock {\em Advances in Neural Information Processing Systems},
  35:36067--36080, 2022.

\bibitem{zhong2022regionclip}
Y.~Zhong, J.~Yang, P.~Zhang, C.~Li, N.~Codella, L.~H. Li, L.~Zhou, X.~Dai,
  L.~Yuan, Y.~Li, et~al.
\newblock Regionclip: Region-based language-image pretraining.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 16793--16803, 2022.

\bibitem{zhou2022detecting}
X.~Zhou, R.~Girdhar, A.~Joulin, P.~Kr{\"a}henb{\"u}hl, and I.~Misra.
\newblock Detecting twenty-thousand classes using image-level supervision.
\newblock In {\em Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part IX}, pages 350--368.
  Springer, 2022.

\bibitem{zhou2021real}
Y.~Zhou, R.~Ji, G.~Luo, X.~Sun, J.~Su, X.~Ding, C.-W. Lin, and Q.~Tian.
\newblock A real-time global inference network for one-stage referring
  expression comprehension.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  2021.

\bibitem{zhu2022seqtr}
C.~Zhu, Y.~Zhou, Y.~Shen, G.~Luo, X.~Pan, M.~Lin, C.~Chen, L.~Cao, X.~Sun, and
  R.~Ji.
\newblock Seqtr: A simple yet universal network for visual grounding.
\newblock In {\em Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXV}, pages 598--615.
  Springer, 2022.

\end{thebibliography}
