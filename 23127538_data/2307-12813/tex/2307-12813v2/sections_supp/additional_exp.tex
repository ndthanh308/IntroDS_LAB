\section{More experimental results}
\label{sec:additional_exp}

\input{tables/comparison_supp}
\input{tables/bifunctional_thres}
\input{figures/vis_rejection}

\subsection{Additional evaluation results for DOD}

\noindent \textbf{More comparison between baselines.}
In \cref{tab:comparison_supp} we show a more complete comparison of the evaluated baselines on \ddd{} with different metrics. Results on average recalls are added.
In REC datasets like RefCOCO~\cite{yu2016modeling,mao2016generation}, the standard metric is accuracy (which equals to precision and also recall in REC setting). This is not suitable for DOD, which is essentially a detection task. Here we also report the average recall metric in COCO API, but it does not necessarily correspond to the effectiveness of a method for DOD, which requires rejecting negative instances while REC does not.

As shown in \cref{tab:comparison_supp}, REC methods are bad at recall, possibly because it can only predict one instance for one description, no matter how many instances actually exists in GT.
OVD methods are also bad at this metric though they produce a dozen of output (see \cref{fig:vis_absence,fig:vis_rejection}. This may partially explains its low mAP.
The bi-functional methods and the DOD one are all strong on this metric.
Grounding-DINO, though performs not as good as the proposed OFA-DOD in terms of mAPs, obtains the best recall. This indicates that it tends to produce more detection results.

\noindent \textbf{Inference of bi-functional methods.}
As discussed in Section 5.1 of the main paper, bi-functional methods obtain a 100\% No-instance FPPC and fail to reject negative images on \ddd{}. This is due to the inference strategy based on REC. It is possible to apply other inference strategy for them.

We verify the effect of inference strategy on these two bi-functional methods~\cite{yan2023universal,liu2023groundingdino}, with No-instance FPPC and overall \textsl{FULL} mAP, and make comparison with the proposed baseline. As shown in \cref{tab:binfunctional_thres}, we try to apply a threshold to filter out certain low-score predictions, similar to the post-processing steps in OVD~\cite{minderer2022simpleOWLViT}.
With this inference strategy, we observe that the increase of score threshold does lower the No-instance FPPC significantly, but at the cost of overall mAP. Therefore, we apply the REC-based inference strategy for these bi-functional methods by default.

Furthermore, we find that when the score threshold is quite high (0.7 for Grounding-DINO and 0.8 for UNINEXT), they reach a FPPC similar to the proposed baseline but with much less overall mAP (15.7 mAP for UNINEXT and 13.6 mAP for Grounding-DINO, while ours 21.6 mAP). Therefore, it might be fair to say that the proposed baseline achieves a better balance between the ability to reject negative images and the overall detection capability.

% \Todo{mAP (or other overlap metric) to show the difference w/ or wo/ the absence word like "no".}

% \subsection{The proposed baseline on OVD and REC}

% We evaluate OFA-DOD on OVD/REC datasets. The results indicate \textbf{substantial improvements over OFA} for both OVD and REC. This shows the improvements of OFA-DOD over OFA make it better for DOD, OVD and REC, and when a model is improved to be more suitable for DOD, it also exhibit corresponding performance gains on REC and OVD. This implies that the DOD task is compatible with REC and OVD.

% Compared with SOTAs on REC (without fine-tuning), OFA-DOD outperforms the SOTA Grounding-DINO. Compared with SOTAs on OVD (fine-tuning on base classes), OFA-DOD is not good as CORA~\cite{wu2023cora}, but outperforms Detic~\cite{zhou2022detecting} on novel classes, showing good generalization ability. We argue the reason why OFA-DOD does not obtain SOTA on OVD is: the original OFA is not suitable for detection tasks, incapable of rejecting negative instances, lacking compatibility with multi-target outputs and yielding poor results. Although OFA-DOD has augmented its detection ability and improved its performance on OVD by more than 20 mAP, it is still far from perfect for OVD and DOD. This is no surprise as it is only a baseline for future research.

\input{figures/vis_absence}

\subsection{Visual comparisons}

% \noindent \textbf{Images with multiple instances.}

\noindent \textbf{Rejecting negative samples.}
As shown in \cref{fig:vis_rejection}, we visualized two descriptions and two images with no corresponding GT instance. An ideal DOD method should refrain from predicting instances.
OWL-ViT~\cite{minderer2022simpleOWLViT}, the OVD method, predicts multiple instances on these images, some of which overlap with each other. Such redundant predictions are not suitable for this setting.
OFA~\cite{wang2022ofa}, the REC method, always predicts an instance for one reference, making it highly prone to mistakes in such negative images.
Grounding-DINO~\cite{liu2023groundingdino}, the bi-functional method, correctly locates the \texttt{hot air balloon} and \texttt{dog} but fails to capture features related to \texttt{with words} and \texttt{clothed} in the language description.
In the last row, the proposed baseline for DOD successfully rejects one negative image but fails with the other one. This implies that it may perform better on such challenges compared to previous methods, but is still far from being strong.

\noindent \textbf{Absence or presence descriptions.}
In \cref{fig:vis_absence}, we present the detection results for two pairs of descriptions, each with one absence description and its exact counterpart presence description. We visualize the GT (Ground Truth) and also predictions from 4 representative methods.

In the first pair, \texttt{a butterfly that \textcolor{red}{doesn't} stop on flowers}, the GT exists for the absence description, but not for the corresponding presence counterpart. We observe that previous methods are not sensitive to the distinction between presence and absence, leading to similar results for both descriptions. However, the proposed baseline stands as an exception by correctly predicting the bounding box for the absence description and successfully rejecting the presence one. This could be attributed to the language comprehension ability of OFA, as it is trained on multiple text-related tasks.

In the second pair, \texttt{a person in santa claus clothes \textcolor{red}{without} bags}, most methods also yield similar results for both descriptions. Although OFA produces noticeably different bounding boxes for two descriptions, the one corresponding to the absence description is overly large, while the one for the presence description results in a negative prediction. Unfortunately, the proposed baseline incorrectly rejects the predictions for this case.
