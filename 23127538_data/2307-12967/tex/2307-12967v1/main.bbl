\begin{thebibliography}{95}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aubert et~al.(2014)Aubert, Brumm, Ramli, Sutikna, Saptomo, Hakim,
  Morwood, van~den Bergh, Kinsley, and Dosseto]{aubert2014pleistocene}
Aubert, M., Brumm, A., Ramli, M., Sutikna, T., Saptomo, E.~W., Hakim, B.,
  Morwood, M.~J., van~den Bergh, G.~D., Kinsley, L., and Dosseto, A.
\newblock Pleistocene cave art from sulawesi, indonesia.
\newblock \emph{Nature}, 514\penalty0 (7521):\penalty0 223--227, 2014.

\bibitem[Bagus et~al.(2022)Bagus, Marques, Sanghavi, DiCarlo, and
  Schrimpf]{bagus2022primate}
Bagus, A. M. I.~G., Marques, T., Sanghavi, S., DiCarlo, J.~J., and Schrimpf, M.
\newblock Primate inferotemporal cortex neurons generalize better to novel
  image distributions than analogous deep neural networks units.
\newblock In \emph{SVRHM 2022 Workshop@ NeurIPS}, 2022.

\bibitem[Berg et~al.(2005)Berg, Berg, and Malik]{berg2005shape}
Berg, A.~C., Berg, T.~L., and Malik, J.
\newblock Shape matching and object recognition using low distortion
  correspondences.
\newblock In \emph{2005 IEEE computer society conference on computer vision and
  pattern recognition (CVPR'05)}, volume~1, pp.\  26--33. IEEE, 2005.

\bibitem[Bhunia et~al.(2020)Bhunia, Yang, Hospedales, Xiang, and
  Song]{bhunia2020sketch}
Bhunia, A.~K., Yang, Y., Hospedales, T.~M., Xiang, T., and Song, Y.-Z.
\newblock Sketch less for more: On-the-fly fine-grained sketch-based image
  retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  9779--9788, 2020.

\bibitem[Bhunia et~al.(2021)Bhunia, Chowdhury, Yang, Hospedales, Xiang, and
  Song]{bhunia2021vectorization}
Bhunia, A.~K., Chowdhury, P.~N., Yang, Y., Hospedales, T.~M., Xiang, T., and
  Song, Y.-Z.
\newblock Vectorization and rasterization: Self-supervised learning for sketch
  and handwriting.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  5672--5681, 2021.

\bibitem[Cadena et~al.(2019)Cadena, Denfield, Walker, Gatys, Tolias, Bethge,
  and Ecker]{cadena2019deep}
Cadena, S.~A., Denfield, G.~H., Walker, E.~Y., Gatys, L.~A., Tolias, A.~S.,
  Bethge, M., and Ecker, A.~S.
\newblock Deep convolutional models improve predictions of macaque v1 responses
  to natural images.
\newblock \emph{PLoS computational biology}, 15\penalty0 (4):\penalty0
  e1006897, 2019.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pp.\
  1597--1607. PMLR, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{chen2020big}
Chen, T., Kornblith, S., Swersky, K., Norouzi, M., and Hinton, G.~E.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 22243--22255, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2020{\natexlab{c}})Chen, Fan, Girshick, and
  He]{chen2020improved}
Chen, X., Fan, H., Girshick, R., and He, K.
\newblock Improved baselines with momentum contrastive learning.
\newblock \emph{arXiv preprint arXiv:2003.04297}, 2020{\natexlab{c}}.

\bibitem[Chen et~al.(2021)Chen, Xie, and He]{chen2021empirical}
Chen, X., Xie, S., and He, K.
\newblock An empirical study of training self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  9640--9649, 2021.

\bibitem[Cho et~al.(2021)Cho, Hong, Jeon, Lee, Sohn, and Kim]{cho2021cats}
Cho, S., Hong, S., Jeon, S., Lee, Y., Sohn, K., and Kim, S.
\newblock Cats: Cost aggregation transformers for visual correspondence.
\newblock In \emph{Thirty-Fifth Conference on Neural Information Processing
  Systems}, 2021.

\bibitem[Cordts et~al.(2016)Cordts, Omran, Ramos, Rehfeld, Enzweiler, Benenson,
  Franke, Roth, and Schiele]{Cordts2016Cityscapes}
Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
  Franke, U., Roth, S., and Schiele, B.
\newblock The cityscapes dataset for semantic urban scene understanding.
\newblock In \emph{Proc. of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2016.

\bibitem[Dalal \& Triggs(2005)Dalal and Triggs]{dalal2005histograms}
Dalal, N. and Triggs, B.
\newblock Histograms of oriented gradients for human detection.
\newblock In \emph{2005 IEEE computer society conference on computer vision and
  pattern recognition (CVPR'05)}, volume~1, pp.\  886--893. Ieee, 2005.

\bibitem[De~Vries et~al.(2017)De~Vries, Strub, Mary, Larochelle, Pietquin, and
  Courville]{de2017modulating}
De~Vries, H., Strub, F., Mary, J., Larochelle, H., Pietquin, O., and Courville,
  A.~C.
\newblock Modulating early visual processing by language.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Doersch et~al.(2015)Doersch, Gupta, and
  Efros]{doersch2015unsupervised}
Doersch, C., Gupta, A., and Efros, A.~A.
\newblock Unsupervised visual representation learning by context prediction.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  1422--1430, 2015.

\bibitem[Eitz et~al.(2012)Eitz, Richter, Boubekeur, Hildebrand, and
  Alexa]{eitz2012sketch}
Eitz, M., Richter, R., Boubekeur, T., Hildebrand, K., and Alexa, M.
\newblock Sketch-based shape retrieval.
\newblock \emph{ACM Transactions on graphics (TOG)}, 31\penalty0 (4):\penalty0
  1--10, 2012.

\bibitem[Fan et~al.(2018)Fan, Yamins, and Turk-Browne]{fan2018common}
Fan, J.~E., Yamins, D.~L., and Turk-Browne, N.~B.
\newblock Common object representations for visual production and recognition.
\newblock \emph{Cognitive science}, 42\penalty0 (8):\penalty0 2670--2698, 2018.

\bibitem[Fan et~al.(2020)Fan, Hawkins, Wu, and Goodman]{fan2020pragmatic}
Fan, J.~E., Hawkins, R.~D., Wu, M., and Goodman, N.~D.
\newblock Pragmatic inference and visual abstraction enable contextual
  flexibility during visual communication.
\newblock \emph{Computational Brain \& Behavior}, 3\penalty0 (1):\penalty0
  86--101, 2020.

\bibitem[Fodor(2007)]{fodor2007revenge}
Fodor, J.
\newblock The revenge of the given.
\newblock \emph{Contemporary debates in philosophy of mind}, pp.\  105--116,
  2007.

\bibitem[Geirhos et~al.(2018)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{geirhos2018imagenet}
Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.~A., and
  Brendel, W.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock \emph{arXiv preprint arXiv:1811.12231}, 2018.

\bibitem[Geirhos et~al.(2021)Geirhos, Narayanappa, Mitzkus, Thieringer, Bethge,
  Wichmann, and Brendel]{geirhos2021partial}
Geirhos, R., Narayanappa, K., Mitzkus, B., Thieringer, T., Bethge, M.,
  Wichmann, F.~A., and Brendel, W.
\newblock Partial success in closing the gap between human and machine vision.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 23885--23899, 2021.

\bibitem[Gidaris et~al.(2018)Gidaris, Singh, and
  Komodakis]{gidaris2018unsupervised}
Gidaris, S., Singh, P., and Komodakis, N.
\newblock Unsupervised representation learning by predicting image rotations.
\newblock \emph{arXiv preprint arXiv:1803.07728}, 2018.

\bibitem[Goodman(1976)]{goodman1976languages}
Goodman, N.
\newblock \emph{Languages of art: An approach to a theory of symbols}.
\newblock Hackett publishing, 1976.

\bibitem[Greenberg(2021)]{greenberg2021semantics}
Greenberg, G.
\newblock Semantics of pictorial space.
\newblock \emph{Review of Philosophy and Psychology}, 12\penalty0 (4):\penalty0
  847--887, 2021.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar,
  et~al.]{grill2020bootstrap}
Grill, J.-B., Strub, F., Altch{\'e}, F., Tallec, C., Richemond, P.,
  Buchatskaya, E., Doersch, C., Avila~Pires, B., Guo, Z., Gheshlaghi~Azar, M.,
  et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 21271--21284, 2020.

\bibitem[Ham et~al.(2016)Ham, Cho, Schmid, and Ponce]{ham2016proposal}
Ham, B., Cho, M., Schmid, C., and Ponce, J.
\newblock Proposal flow.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3475--3484, 2016.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  9729--9738, 2020.

\bibitem[Hertzmann(2020)]{hertzmann2020line}
Hertzmann, A.
\newblock Why do line drawings work? a realism hypothesis.
\newblock \emph{Perception}, 49\penalty0 (4):\penalty0 439--451, 2020.

\bibitem[Hjelm et~al.(2018)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman,
  Trischler, and Bengio]{hjelm2018learning}
Hjelm, R.~D., Fedorov, A., Lavoie-Marchildon, S., Grewal, K., Bachman, P.,
  Trischler, A., and Bengio, Y.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock \emph{arXiv preprint arXiv:1808.06670}, 2018.

\bibitem[Hochberg \& Brooks(1962)Hochberg and Brooks]{hochberg1962pictorial}
Hochberg, J. and Brooks, V.
\newblock Pictorial recognition as an unlearned ability: A study of one child's
  performance.
\newblock \emph{the american Journal of Psychology}, 75\penalty0 (4):\penalty0
  624--628, 1962.

\bibitem[Hoffmann et~al.(2018)Hoffmann, Standish, García-Diez, Pettitt,
  Milton, Zilhão, Alcolea-González, Cantalejo-Duarte, Collado, de~Balbín,
  Lorblanchet, Ramos-Muñoz, Weniger, and Pike]{hoffman2018dating}
Hoffmann, D.~L., Standish, C.~D., García-Diez, M., Pettitt, P.~B., Milton,
  J.~A., Zilhão, J., Alcolea-González, J.~J., Cantalejo-Duarte, P., Collado,
  H., de~Balbín, R., Lorblanchet, M., Ramos-Muñoz, J., Weniger, G.-C., and
  Pike, A. W.~G.
\newblock U-th dating of carbonate crusts reveals neandertal origin of iberian
  cave art.
\newblock \emph{Science}, 359\penalty0 (6378):\penalty0 912--915, 2018.
\newblock \doi{10.1126/science.aap7778}.
\newblock URL \url{https://www.science.org/doi/abs/10.1126/science.aap7778}.

\bibitem[Huang et~al.(2019)Huang, Wang, Zhang, Yan, and He]{DCCNet}
Huang, S., Wang, Q., Zhang, S., Yan, S., and He, X.
\newblock Dynamic context correspondence network for semantic alignment.
\newblock \emph{2019 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pp.\  2010--2019, 2019.

\bibitem[Huey et~al.(2021)Huey, Lu, Walker, and Fan]{huey2021explanatory}
Huey, H., Lu, X., Walker, C., and Fan, J.
\newblock Explanatory drawings prioritize functional properties at the expense
  of visual fidelity.
\newblock 2021.

\bibitem[Ignatov et~al.(2017)Ignatov, Kobyshev, Timofte, Vanhoey, and
  Van~Gool]{ignatov2017dslr}
Ignatov, A., Kobyshev, N., Timofte, R., Vanhoey, K., and Van~Gool, L.
\newblock Dslr-quality photos on mobile devices with deep convolutional
  networks.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  3277--3285, 2017.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International conference on machine learning}, pp.\
  448--456. PMLR, 2015.

\bibitem[Jabri et~al.(2020)Jabri, Owens, and Efros]{jabri2020space}
Jabri, A., Owens, A., and Efros, A.
\newblock Space-time correspondence as a contrastive random walk.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 19545--19560, 2020.

\bibitem[Jaderberg et~al.(2015)Jaderberg, Simonyan, Zisserman,
  et~al.]{jaderberg2015spatial}
Jaderberg, M., Simonyan, K., Zisserman, A., et~al.
\newblock Spatial transformer networks.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\bibitem[Jeon et~al.(2018)Jeon, Kim, Min, and Sohn]{jeon2018parn}
Jeon, S., Kim, S., Min, D., and Sohn, K.
\newblock Parn: Pyramidal affine regression networks for dense semantic
  correspondence.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  351--366, 2018.

\bibitem[Jeon et~al.(2020)Jeon, Min, Kim, Choe, and Sohn]{jeon2020guided}
Jeon, S., Min, D., Kim, S., Choe, J., and Sohn, K.
\newblock Guided semantic flow.
\newblock In \emph{European Conference on Computer Vision}, pp.\  631--648.
  Springer, 2020.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jia2021scaling}
Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh, Z., Pham, H., Le, Q., Sung,
  Y.-H., Li, Z., and Duerig, T.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4904--4916. PMLR, 2021.

\bibitem[Kennedy \& Ross(1975)Kennedy and Ross]{kennedy1975outline}
Kennedy, J.~M. and Ross, A.~S.
\newblock Outline picture perception by the songe of papua.
\newblock \emph{Perception}, 4\penalty0 (4):\penalty0 391--406, 1975.

\bibitem[Khaligh-Razavi \& Kriegeskorte(2014)Khaligh-Razavi and
  Kriegeskorte]{khaligh2014deep}
Khaligh-Razavi, S.-M. and Kriegeskorte, N.
\newblock Deep supervised, but not unsupervised, models may explain it cortical
  representation.
\newblock \emph{PLoS computational biology}, 10\penalty0 (11):\penalty0
  e1003915, 2014.

\bibitem[Kim et~al.(2013)Kim, Liu, Sha, and Grauman]{kim2013deformable}
Kim, J., Liu, C., Sha, F., and Grauman, K.
\newblock Deformable spatial pyramid matching for fast dense correspondences.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2307--2314, 2013.

\bibitem[Kim et~al.(2018)Kim, Lin, Jeon, Min, and Sohn]{kim2018recurrent}
Kim, S., Lin, S., Jeon, S.~R., Min, D., and Sohn, K.
\newblock Recurrent transformer networks for semantic correspondence.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Kim et~al.(2019)Kim, Min, Jeong, Kim, Jeon, and Sohn]{kim2019semantic}
Kim, S., Min, D., Jeong, S., Kim, S., Jeon, S., and Sohn, K.
\newblock Semantic attribute matching networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  12339--12348, 2019.

\bibitem[Konkle \& Alvarez(2020)Konkle and Alvarez]{konkle2020instance}
Konkle, T. and Alvarez, G.~A.
\newblock Instance-level contrastive learning yields human brain-like
  representation without category-supervision.
\newblock \emph{BioRxiv}, 2020.

\bibitem[Krizhevsky et~al.(2017)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2017imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Communications of the ACM}, 60\penalty0 (6):\penalty0 84--90,
  2017.

\bibitem[Kulvicki(2015)]{kulvicki2015analog}
Kulvicki, J.
\newblock Analog representation and the parts principle.
\newblock \emph{Review of Philosophy and Psychology}, 6\penalty0 (1):\penalty0
  165--180, 2015.

\bibitem[Li et~al.(2020)Li, Han, Li, and Prisacariu]{li2020dual}
Li, X., Han, K., Li, S., and Prisacariu, V.
\newblock Dual-resolution correspondence networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 17346--17357, 2020.

\bibitem[Li et~al.(2021)Li, Fan, Yang, Luo, Cheng, and Liu]{PMD}
Li, X., Fan, D.-P., Yang, F., Luo, A., Cheng, H., and Liu, Z.
\newblock Probabilistic model distillation for semantic correspondence.
\newblock \emph{2021 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  7501--7510, 2021.

\bibitem[Liu et~al.(2010)Liu, Yuen, and Torralba]{liu2010sift}
Liu, C., Yuen, J., and Torralba, A.
\newblock Sift flow: Dense correspondence across scenes and its applications.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 33\penalty0 (5):\penalty0 978--994, 2010.

\bibitem[Loshchilov \& Hutter(2016)Loshchilov and Hutter]{loshchilov2016sgdr}
Loshchilov, I. and Hutter, F.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock \emph{arXiv preprint arXiv:1608.03983}, 2016.

\bibitem[Lowe(1999)]{lowe1999object}
Lowe, D.~G.
\newblock Object recognition from local scale-invariant features.
\newblock In \emph{Proceedings of the seventh IEEE international conference on
  computer vision}, volume~2, pp.\  1150--1157. Ieee, 1999.

\bibitem[Meister et~al.(2018)Meister, Hur, and Roth]{meister2018unflow}
Meister, S., Hur, J., and Roth, S.
\newblock Unflow: Unsupervised learning of optical flow with a bidirectional
  census loss.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~32, 2018.

\bibitem[Melekhov et~al.(2019)Melekhov, Tiulpin, Sattler, Pollefeys, Rahtu, and
  Kannala]{melekhov2019dgc}
Melekhov, I., Tiulpin, A., Sattler, T., Pollefeys, M., Rahtu, E., and Kannala,
  J.
\newblock Dgc-net: Dense geometric correspondence network.
\newblock In \emph{2019 IEEE Winter Conference on Applications of Computer
  Vision (WACV)}, pp.\  1034--1042. IEEE, 2019.

\bibitem[Min \& Cho(2021)Min and Cho]{min2021convolutional}
Min, J. and Cho, M.
\newblock Convolutional hough matching networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2940--2950, 2021.

\bibitem[Min et~al.(2019)Min, Lee, Ponce, and Cho]{min2019hyperpixel}
Min, J., Lee, J., Ponce, J., and Cho, M.
\newblock Hyperpixel flow: Semantic correspondence with multi-layer neural
  features.
\newblock In \emph{ICCV}, 2019.

\bibitem[Mukherjee et~al.(2019)Mukherjee, Hawkins, and
  Fan]{mukherjee2019communicating}
Mukherjee, K., Hawkins, R.~X., and Fan, J.~W.
\newblock Communicating semantic part information in drawings.
\newblock In \emph{CogSci}, pp.\  2413--2419, 2019.

\bibitem[Noroozi \& Favaro(2016)Noroozi and Favaro]{noroozi2016unsupervised}
Noroozi, M. and Favaro, P.
\newblock Unsupervised learning of visual representations by solving jigsaw
  puzzles.
\newblock In \emph{European conference on computer vision}, pp.\  69--84.
  Springer, 2016.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Pang et~al.(2020)Pang, Yang, Hospedales, Xiang, and
  Song]{pang2020solving}
Pang, K., Yang, Y., Hospedales, T.~M., Xiang, T., and Song, Y.-Z.
\newblock Solving mixed-modal jigsaw puzzle for fine-grained sketch-based image
  retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10347--10355, 2020.

\bibitem[Pathak et~al.(2016)Pathak, Krahenbuhl, Donahue, Darrell, and
  Efros]{pathak2016context}
Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., and Efros, A.~A.
\newblock Context encoders: Feature learning by inpainting.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2536--2544, 2016.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
  G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8748--8763. PMLR, 2021.

\bibitem[Rajalingham et~al.(2018)Rajalingham, Issa, Bashivan, Kar, Schmidt, and
  DiCarlo]{rajalingham2018large}
Rajalingham, R., Issa, E.~B., Bashivan, P., Kar, K., Schmidt, K., and DiCarlo,
  J.~J.
\newblock Large-scale, high-resolution comparison of the core visual object
  recognition behavior of humans, monkeys, and state-of-the-art deep artificial
  neural networks.
\newblock \emph{Journal of Neuroscience}, 38\penalty0 (33):\penalty0
  7255--7269, 2018.

\bibitem[Rocco et~al.(2017)Rocco, Arandjelovic, and
  Sivic]{rocco2017convolutional}
Rocco, I., Arandjelovic, R., and Sivic, J.
\newblock Convolutional neural network architecture for geometric matching.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  6148--6157, 2017.

\bibitem[Rocco et~al.(2018{\natexlab{a}})Rocco, Arandjelovi{\'c}, and
  Sivic]{rocco2018a}
Rocco, I., Arandjelovi{\'c}, R., and Sivic, J.
\newblock End-to-end weakly-supervised semantic alignment.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  6917--6925, 2018{\natexlab{a}}.

\bibitem[Rocco et~al.(2018{\natexlab{b}})Rocco, Cimpoi, Arandjelovi{\'c},
  Torii, Pajdla, and Sivic]{rocco2018b}
Rocco, I., Cimpoi, M., Arandjelovi{\'c}, R., Torii, A., Pajdla, T., and Sivic,
  J.
\newblock Neighbourhood consensus networks.
\newblock \emph{Advances in neural information processing systems}, 31,
  2018{\natexlab{b}}.

\bibitem[Rocco et~al.(2020)Rocco, Arandjelovi{\'c}, and
  Sivic]{rocco2020efficient}
Rocco, I., Arandjelovi{\'c}, R., and Sivic, J.
\newblock Efficient neighbourhood consensus networks via submanifold sparse
  convolutions.
\newblock In \emph{European conference on computer vision}, pp.\  605--621.
  Springer, 2020.

\bibitem[Sangkloy et~al.(2016)Sangkloy, Burnell, Ham, and
  Hays]{sangkloy2016sketchy}
Sangkloy, P., Burnell, N., Ham, C., and Hays, J.
\newblock The sketchy database: learning to retrieve badly drawn bunnies.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 35\penalty0 (4):\penalty0
  1--12, 2016.

\bibitem[Seo et~al.(2018)Seo, Lee, Jung, Han, and Cho]{seo2018attentive}
Seo, P.~H., Lee, J., Jung, D., Han, B., and Cho, M.
\newblock Attentive semantic alignment with offset-aware correlation kernels.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  349--364, 2018.

\bibitem[Shen et~al.(2020)Shen, Darmon, Efros, and Aubry]{shen2020ransac}
Shen, X., Darmon, F., Efros, A.~A., and Aubry, M.
\newblock Ransac-flow: generic two-stage image alignment.
\newblock In \emph{European Conference on Computer Vision}, pp.\  618--637.
  Springer, 2020.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Sun et~al.(2018)Sun, Yang, Liu, and Kautz]{sun2018pwc}
Sun, D., Yang, X., Liu, M.-Y., and Kautz, J.
\newblock Pwc-net: Cnns for optical flow using pyramid, warping, and cost
  volume.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  8934--8943, 2018.

\bibitem[Tian et~al.(2020{\natexlab{a}})Tian, Krishnan, and
  Isola]{tian2020contrastive}
Tian, Y., Krishnan, D., and Isola, P.
\newblock Contrastive multiview coding.
\newblock In \emph{European conference on computer vision}, pp.\  776--794.
  Springer, 2020{\natexlab{a}}.

\bibitem[Tian et~al.(2020{\natexlab{b}})Tian, Sun, Poole, Krishnan, Schmid, and
  Isola]{tian2020makes}
Tian, Y., Sun, C., Poole, B., Krishnan, D., Schmid, C., and Isola, P.
\newblock What makes for good views for contrastive learning?
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 6827--6839, 2020{\natexlab{b}}.

\bibitem[Truong et~al.(2020)Truong, Danelljan, and Timofte]{truong2020glu}
Truong, P., Danelljan, M., and Timofte, R.
\newblock Glu-net: Global-local universal network for dense flow and
  correspondences.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  6258--6268, 2020.

\bibitem[Truong et~al.(2021)Truong, Danelljan, Yu, and Van~Gool]{WarpC}
Truong, P., Danelljan, M., Yu, F., and Van~Gool, L.
\newblock Warp consistency for unsupervised learning of dense correspondences.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  10346--10356, 2021.

\bibitem[Truong et~al.(2022)Truong, Danelljan, Yu, and Van~Gool]{pwarpc}
Truong, P., Danelljan, M., Yu, F., and Van~Gool, L.
\newblock Probabilistic warp consistency for weakly-supervised semantic
  correspondences.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  8708--8718, 2022.

\bibitem[Vinker et~al.(2022)Vinker, Pajouheshgar, Bo, Bachmann, Bermano,
  Cohen-Or, Zamir, and Shamir]{vinker2022clipasso}
Vinker, Y., Pajouheshgar, E., Bo, J.~Y., Bachmann, R.~C., Bermano, A.~H.,
  Cohen-Or, D., Zamir, A., and Shamir, A.
\newblock Clipasso: Semantically-aware object sketching.
\newblock \emph{arXiv preprint arXiv:2202.05822}, 2022.

\bibitem[Vondrick et~al.(2018)Vondrick, Shrivastava, Fathi, Guadarrama, and
  Murphy]{vondrick2018tracking}
Vondrick, C., Shrivastava, A., Fathi, A., Guadarrama, S., and Murphy, K.
\newblock Tracking emerges by colorizing videos.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pp.\  391--408, 2018.

\bibitem[Wang \& Gupta(2015)Wang and Gupta]{wang2015unsupervised}
Wang, X. and Gupta, A.
\newblock Unsupervised learning of visual representations using videos.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  2794--2802, 2015.

\bibitem[Wang et~al.(2019)Wang, Jabri, and Efros]{wang2019learning}
Wang, X., Jabri, A., and Efros, A.~A.
\newblock Learning correspondence from the cycle-consistency of time.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2566--2576, 2019.

\bibitem[Wu et~al.(2018)Wu, Xiong, Yu, and Lin]{wu2018unsupervised}
Wu, Z., Xiong, Y., Yu, S.~X., and Lin, D.
\newblock Unsupervised feature learning via non-parametric instance
  discrimination.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  3733--3742, 2018.

\bibitem[Xu \& Wang(2021)Xu and Wang]{xu2021rethinking}
Xu, J. and Wang, X.
\newblock Rethinking self-supervised correspondence learning: A video
  frame-level similarity perspective.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  10075--10085, 2021.

\bibitem[Xu et~al.(2020)Xu, Song, Yin, Song, and Wang]{xu2020deep}
Xu, P., Song, Z., Yin, Q., Song, Y.-Z., and Wang, L.
\newblock Deep self-supervised representation learning for free-hand sketch.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video
  Technology}, 31\penalty0 (4):\penalty0 1503--1513, 2020.

\bibitem[Yamins et~al.(2014)Yamins, Hong, Cadieu, Solomon, Seibert, and
  DiCarlo]{yamins2014performance}
Yamins, D.~L., Hong, H., Cadieu, C.~F., Solomon, E.~A., Seibert, D., and
  DiCarlo, J.~J.
\newblock Performance-optimized hierarchical models predict neural responses in
  higher visual cortex.
\newblock \emph{Proceedings of the national academy of sciences}, 111\penalty0
  (23):\penalty0 8619--8624, 2014.

\bibitem[Yang \& Fan(2021)Yang and Fan]{yang2021visual}
Yang, J. and Fan, J.~E.
\newblock Visual communication of object concepts at different levels of
  abstraction.
\newblock \emph{arXiv preprint arXiv:2106.02775}, 2021.

\bibitem[Yu et~al.(2016)Yu, Liu, Song, Xiang, Hospedales, and
  Loy]{yu2016sketch}
Yu, Q., Liu, F., Song, Y.-Z., Xiang, T., Hospedales, T.~M., and Loy, C.-C.
\newblock Sketch me that shoe.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  799--807, 2016.

\bibitem[Yu et~al.(2017)Yu, Yang, Liu, Song, Xiang, and
  Hospedales]{yu2017sketch}
Yu, Q., Yang, Y., Liu, F., Song, Y.-Z., Xiang, T., and Hospedales, T.~M.
\newblock Sketch-a-net: A deep neural network that beats humans.
\newblock \emph{International journal of computer vision}, 122\penalty0
  (3):\penalty0 411--425, 2017.

\bibitem[Zhang et~al.(2016)Zhang, Isola, and Efros]{zhang2016colorful}
Zhang, R., Isola, P., and Efros, A.~A.
\newblock Colorful image colorization.
\newblock In \emph{European conference on computer vision}, pp.\  649--666.
  Springer, 2016.

\bibitem[Zhou et~al.(2019)Zhou, Zhao, Puig, Xiao, Fidler, Barriuso, and
  Torralba]{zhou2019semantic}
Zhou, B., Zhao, H., Puig, X., Xiao, T., Fidler, S., Barriuso, A., and Torralba,
  A.
\newblock Semantic understanding of scenes through the ade20k dataset.
\newblock \emph{International Journal of Computer Vision}, 127\penalty0
  (3):\penalty0 302--321, 2019.

\bibitem[Zhuang et~al.(2020)Zhuang, She, Andonian, Mark, and
  Yamins]{zhuang2020unsupervised}
Zhuang, C., She, T., Andonian, A., Mark, M.~S., and Yamins, D.
\newblock Unsupervised learning from video with deep neural embeddings.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  9563--9572, 2020.

\bibitem[Zhuang et~al.(2021)Zhuang, Yan, Nayebi, Schrimpf, Frank, DiCarlo, and
  Yamins]{zhuang2021unsupervised}
Zhuang, C., Yan, S., Nayebi, A., Schrimpf, M., Frank, M.~C., DiCarlo, J.~J.,
  and Yamins, D.~L.
\newblock Unsupervised neural network models of the ventral visual stream.
\newblock \emph{Proceedings of the National Academy of Sciences}, 118\penalty0
  (3):\penalty0 e2014196118, 2021.

\end{thebibliography}
