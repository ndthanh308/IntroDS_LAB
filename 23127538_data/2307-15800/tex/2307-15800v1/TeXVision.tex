\documentclass{osa-article}
\usepackage{graphicx}
%% Select the journal you're submitting to
%% oe, boe, ome, osac, osajournal
\journal{oe}
% Key:
% Express journals must have the correct journal selected:
% {oe} Optics Express
% {boe} Biomedical Optics Express
% {ome} Optical Material Express
% {osac} OSAC Continuum
% Other OSA journals may use:
% {osajournal} Applied Optics, Advances in Optics and Photonics, Journal of the Optical Society of America A/B, Optics Letters, Optica, Photonics Research

% Uncomment if submitting to Photonics Research.
% ONLY APPLICABLE FOR \journal{osajournal}
% \setprjcopyright

% Set the article type
% \articletype{Letters}
% Note that article type is not required for Express journals (OE, BOE, OME and OSAC)

% user defined
\newcommand{\eref}[1]{Eq.~(\ref{#1})}
\newcommand{\fref}[1]{Fig.~\ref{#1}}
\newcommand{\tref}[1]{Tab.~\ref{#1}}
\newcommand{\sref}[1]{Sec.~\ref{#1}}
\newcommand{\e}{\ensuremath{\varepsilon}}
\newcommand{\p}{\ensuremath{\partial}}
\newcommand{\im}{\ensuremath{\mathrm{i}}}
\newcommand{\df}{\ensuremath{\mathrm{d}}}
\newcommand{\tr}{\ensuremath{\mathrm{tr}}}
\newcommand{\calA}{\ensuremath{\mathcal{A}}}
\newcommand{\calS}{\ensuremath{\mathcal{S}}}
\newcommand{\calN}{\ensuremath{\mathcal{N}}}
\newcommand{\calM}{\ensuremath{\mathcal{M}}}
\newcommand{\calC}{\ensuremath{\mathcal{C}}}
\newcommand{\calT}{\ensuremath{\mathcal{T}}}
\newcommand{\calP}{\ensuremath{\mathcal{P}}}
\newcommand{\ie}{\emph{i.e.}}
\newcommand{\eg}{\emph{e.g.}}
\newcommand{\etc}{\emph{etc.}}
\newcommand{\cd}{\ensuremath{\mathrm{C}^\circ}}

\begin{document}

\title{Why is thermal imaging textureless}

%\author{Fanglin Bao,\authormark{1,3} Shubhankar Jape,\authormark{1} Andrew Schramka,\authormark{1} Junjie Wang, \authormark{2} Tim E. McGraw, \authormark{2} and Zubin Jacob \authormark{1,4}}
\author{F. Bao,\authormark{1,3} S. Jape,\authormark{1} A. Schramka,\authormark{1} J. Wang, \authormark{2} T. E. McGraw, \authormark{2} and Z. Jacob \authormark{1,4}}

\address{\authormark{1}Birck Nanotechnology Center, School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN 47907, USA\\
\authormark{2}Department of Computer Graphics Technology, Purdue University, West Lafayette, IN 47907, USA\\
\authormark{3}baof@purdue.edu\\
\authormark{4}zjacob@purdue.edu}
%\email{\authormark{*}zjacob@purdue.edu} %% email address is required

% \homepage{http:...} %% author's URL, if desired

%%%%%%%%%%%%%%%%%%% abstract %%%%%%%%%%%%%%%%
%% [use \begin{abstract*}...\end{abstract*} if exempt from copyright]

\begin{abstract*}
Thermal imaging can enable night vision but is usually textureless, well-known as the `ghosting effect'. The mechanism of this ghosting effect has recently been explained [Nature {\bfseries 619}, 743â€“748 (2023)], and TeX vision has been proposed to overcome the ghosting effect. However, it is still unknown for realistic scenarios with non-uniform temperature whether TeX vision can correctly recover geometric textures and how its performance is compared with traditional thermal imaging. Here, we focus on the interplay of geometric textures and non-uniform temperature which is common in realistic thermal imaging, and demonstrate the failure of traditional approaches while TeX vision successfully recovers geometric textures. We also analyze important yet unexplored aspects of the TeX vision theory, and demonstrate a true night vision like broad daylight with the experimentally more feasible Bayer-filter setup.  This deepens the understanding of the ghosting effect and bridges the gap between the TeX vision theory and the consumer thermal-imaging market.
\end{abstract*}

%%%%%%%%%%%%%%%%%%%%%%%%%%  body  %%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
A thermal camera detects the thermal radiation. According to Planck's law, every object of finite temperature $T$, including human body, ground, and buildings, would emit the infrared thermal radiation, depending on object's emissivity $e$. Thermal radiation propagates and scatters, and is omnipresent in both day and night. This gives thermal imaging the ability to see through darkness, which is promising for autonomous navigation and robotics (see, \eg, FLIR thermal dataset for autonomous navigation). Nevertheless, thermal images are known to be of low contrast and lack of details, exhibiting the ghosting effect \cite{Gurton2014,Treible_2017_CVPR}. The loss of information limits thermal imaging only to night vision enhancement of optical RGB images under poor ambient illuminations \cite{Gade2014,9133581,s16060820}.

Why is thermal imaging textureless?

A recent study \cite{Bao2023} revealed the mechanism of the ghosting effect by analogy to a shining bulb that invisiblizes its surface textures. Following the theory of thermal radiation and scattering, the total thermal radiation, or heat signal, $S$, entering a thermal camera reads,
\begin{equation}\label{eq:heatsignal}
    S_{\alpha\nu} = e_{\alpha\nu}B_{\nu}(T_{\alpha}) +[1- e_{\alpha\nu}] X_{\alpha\nu},
\end{equation}
with 
\begin{equation}\label{eq:x}
    X_{\alpha\nu} =  \sum_{\beta\neq\alpha} V_{\alpha\beta}S_{\beta\nu},
\end{equation}
where $B$ is the blackbody radiation given by Planck's law, $V$ is the thermal lighting factor related to object's geometric surface normals, $\alpha$ is the object index, and $\nu$ is the wavenumber. For a shining bulb or for natural objects with near-unity emissivity ($e\approx 1$), blackbody radiation dominates the total heat signal, that is, $S_{\alpha\nu} \approx B_{\nu}(T_{\alpha})$, according to \eref{eq:heatsignal}. It follows that thermal imaging is widely understood as measuring temperature $T$, without any information of object's geometry textures. The insight of \eref{eq:heatsignal} is that geometry information does exist in heat signal as a weak contribution of magnitude order $1-e$, in a low-contrast background of magnitude order $e$. Based on inverse computational algorithms and spectral resolution, Ref.~\cite{Bao2023} shows that artificial intelligence (AI) using TeX vision can recover geometric textures from the heat signal and see through the pitch darkness like broad daylight, making the long-standing dichotomy between day and night for human beings obsolete.

However, the numeric analyses in Ref.~\cite{Bao2023} were mainly restricted in synthetic scenes with uniform temperature for each object. Even though it has been theoretically proven that TeX vision always has more information than thermal vision, the used uniform-temperature scenes still left a loophole and raised the following questions. (1) Can TeX vision correctly recover geometric textures of realistic scenes commonly with non-uniform temperature? And (2) can sophisticated image processing of traditional thermal imaging effectively recover geometric textures close to TeX vision if scenes are not artificially designed to enhance TeX degeneracy?

Among a variety of digital image processing algorithms for contrast enhancement of thermal images \cite{Soundrapandiyan2022}, histogram equalization and its variants \cite{Khare2021,Dhal2021,LI2018164} are widely adopted techniques in state-of-the-art thermal datasets such as the FLIR thermal dataset. Machine-learning-based approaches \cite{Bouhlel2023,Pang2023,KUANG2019119,Lee2017} also present a new research frontier in improving the visual contrast by learning the multi-scale thermal features. Those image processing algorithms aim to recover the scattering signal, $(1-e)X$, by heuristically removing the strong contribution of direct emission. In this paper, we use the Contrast-Limited Adaptive Histogram Equalization (CLAHE) \cite{Khare2021} as the state-of-the-art baseline of image processing. As we will show below, image processing fails to recover geometric textures when the direct emission is spatially non-uniform. We argue that this is the deep reason causing the persistence of the ghosting effect in thermal imaging.

This paper is organized as the following. \sref{sec:tex} shows general examples beyond the shining bulb to explain the loss of geometric textures and the emerging of the ghosting effect. \sref{sec:gttex} briefly introduces the TeX vision for self-consistency of the paper. \sref{sec:sgd} investigates TeX-SGD (semi-global decomposition) on unexplored scenes to illustrate texture recovery close to the ground truth. \sref{sec:tmp} shows the main results of this paper on the interplay of geometric textures and non-uniform temperature to close the loophole, and demonstrate that TeX vision beats existing techniques in overcoming the ghosting effect. \sref{sec:res} and \sref{sec:env} show the influence of spectral resolution and cutoff of environmental radiation in TeX vision.

\section{Loss of geometric textures}\label{sec:tex}
We note that \eref{eq:heatsignal} is a unified theory of optical imaging in daylight under solar illumination and thermal imaging at night. The differences between optical RGB imaging and the long-wave infrared (LWIR) thermal imaging are roughly two folds, within the scope of this paper. Firstly, the spectral response range of the sensor for optical or thermal imaging are in the visible light range and LWIR, respectively. Secondly, the scattering signal of optical imaging is mainly the solar radiance, while the scattering signal of thermal imaging is from room-temperature objects. There is a large temperature contrast between the sun ($T\approx 5,500\,\cd$) and the scene objects on earth ($T\approx 20\,\cd$). According to Planck's law, the blackbody radiation is given by
\begin{equation}
    B_\lambda(T) = \frac{2hc^2}{\lambda^5}\frac{1}{e^{hc/(\lambda k_\mathrm{B}T)}-1},
\end{equation}
where $\lambda=1/\nu$ is the wavelength, $h$ is Planck's constant, $c$ is the speed of light, and $k_\mathrm{B}$ is Boltzmann's constant. Solar radiance peaks in the visible-light range, while room-temperature objects' radiance peaks in the LWIR, as shown in \fref{fig:tex}a.
% Figure environment removed
For optical imaging, scattering of solar illumination is well separated from the direct thermal radiation of scene objects, due to the high temperature contrast. This gives optical imaging vivid geometric textures encoded in the texture term $X$, as can be seen in the left column of \fref{fig:tex}b. Here, optical imaging is set as grayscale for a fair comparison. For thermal imaging, scattering and direct emission are both from scene objects around room temperatures. The fact that a traditional thermal camera collects both weak scattering and strong direct emission leads to textureless thermal images and thus the ghosting effect. See the right column of \fref{fig:tex}b.

We emphasize that visible light and LWIR radiation have different wavelengths, corresponding sensor pixel sizes and noise performance. The resulting different spatial and signal resolutions for two modalities partially account for the different textures that can be captured by optical and thermal cameras. However, the insight from \fref{fig:tex} is that thermal imaging suffers from the ghosting effect and is textureless even if it has the same spatial and signal resolutions as optical imaging. The second insight from \fref{fig:tex} is that the vivid textures of snow, grass, and sand in optical imaging come merely from the geometric surface normals, where their material and temperature have been set to be uniform. These insights imply the possibility of recovering vivid textures through the geometric surface normals by properly removing the direct emission from the total heat signal.

\section{TeX vision obsoletes the dichotomy between day and night}\label{sec:gttex}
Separating the scattering signal from the direct emission in thermal imaging requires spectral resolution. To represent a hyperspectral imaging datacube, or the heat cube, traditional methods commonly use the principal component analysis (PCA) \cite{Du2007}. The PCA approach usually adopts the first 3 principal components to show in the RGB color space, while the rest components are discarded leading to information loss. In contrast, we note that the total information in the heat signal \eref{eq:heatsignal} can be captured in three physics quantities, namely, temperature $T$, emissivity $e$, and texture $X$. TeX vision decomposes these physics quantities from heat signal and shows them in the HSV color space, as illustrated in \fref{fig:gttex}.
% Figure environment removed

For TeX decomposition, we use a semantic library, $ \calM = \{e_{\nu}(m)|m = 1,2,...,M\}$, that approximates all possible spectral emissivity in the scene. For each object, its emissivity can be approximately described by one of the curves in the library, \ie, $e_{\alpha\nu} = e_{\nu}(m_\alpha)$. This semantic library can either be calibrated on site or estimated from the heat cube itself \cite{Bao2023}. The adoption of a semantic library leads to the existence of a unique solution of the inverse TeX decomposition problem defined by \eref{eq:heatsignal}. The parameters to be estimated in the inverse problem are $\{T_\alpha, m_\alpha, V_{\alpha\beta}\}$. The detailed decomposition algorithm will be discussed in \sref{sec:sgd}. Since TeX vision records all the physics quantities, we argue that TeX vision is a full representation of the hyperspectral heat signal without losing information of any spectral bands. Furthermore, we emphasize that the colors in the TeX vision indicate material categories, $m_\alpha$, unlike pseudo coloring in traditional image processing. The accuracy of TeX decomposition depends on the accuracy of how the semantic library depicts the scene. An ideal semantic library becomes a ground-truth material library with exact spectral emissivity profiles. In this paper, we use the exact material library to demonstrate the TeX vision theory.

When the TeX decomposition in \fref{fig:gttex} is ideal, the resulting TeX vision strikingly shows an image of a night scene as if it is seen in daylight, with both recovered textures and semantic information. Artificial intelligence with TeX-based machine vision is thus able to obsolete the long-standing dichotomy between day and night for human beings.

Note that the texture term $X$ in optical imaging usually involves only the sky and the sun as light sources. In thermal imaging, every object in the environment like streets and buildings have their scattering contributions in texture $X$. To mimic daylight optical imaging, scattering contributions of environmental objects other than sky need to be removed. This process is discussed in \sref{sec:sgd}.

\section{TeX-SGD: texture recovery close to the ground truth}\label{sec:sgd}
TeX vision visualizes temperature $T$ as the saturation, material category $e(m)$ as the color hue, and texture $X$ as the brightness. By manually splitting the scattering contribution with the direct emission contribution and by manually controlling temperature and material in Monte Carlo path tracing, we have the knowledge of the ground truth TeX vision of a scene. The ground truth TeX vision in \fref{fig:gttex} shows the recovered textures of night scenes which are as vivid as seen in daylight. Now, we show how to recover the texture and generate the TeX vision close to the ground truth.

To tackle the iterative system of equations (\ref{eq:heatsignal}) and (\ref{eq:x}) with possibly infinite number of environmental objects, we approximate the panoramic environment as $k$ equivalent environmental objects whose spectral emissivity are also among those $M$ curves in the semantic library $\calM$. The following reconstructed heat signal $\Tilde{S}^k_{\alpha\nu}$ with only $k$ environmental objects presents a good approximation of the original heat signal $S_{\alpha\nu}$,
\begin{equation}\label{eq:approxheat}
    \Tilde{S}^k_{\alpha\nu} = e_\nu(m_\alpha)B_{\nu}(T_{\alpha}) +[1- e_\nu(m_\alpha)] \Tilde{X}^k_{\alpha\nu},
\end{equation}
with 
\begin{equation}\label{eq:approxx}
    \Tilde{X}^k_{\alpha\nu} =  V_{\alpha 1}\Tilde{S}_{1\nu}+V_{\alpha 2}\Tilde{S}_{2\nu}+\cdots+V_{\alpha k}\Tilde{S}_{k\nu},
\end{equation}
where environmental radiance $\Tilde{S}_{1,\cdots,k;\nu}$ can be approximated from the captured image, see \sref{sec:env} for more details. The above approximation can be understood in the viewpoint of ray/path tracing. Path tracing of a real-world scene is asymptotically accurate and realistic, when the ray depth and meshing density of the environment increase.

TeX-SGD (semi-global decomposition) aims to extract the scene attributes, \ie, $T_\alpha$, $m_\alpha$, and $V_{\alpha;1,\cdots,k}$, by minimizing the $l_2$-norm residue, $\delta^k_\alpha \equiv ||\Tilde{S}^k_{\alpha\nu} - S_{\alpha\nu}||$,
\begin{equation}\label{eq:sgd}
    \{T^k_\alpha,m^k_\alpha,V^k_{\alpha;1,\cdots,k}\} = \mathrm{argmin}_{TmV}\delta^k_\alpha,
\end{equation}
with additional smoothness constraints. As $k$ increases, $\{T^k_\alpha,m^k_\alpha,\Tilde{X}^k_{\alpha\nu}\}$ are expected to approach $\{T_\alpha,m_\alpha,X_{\alpha\nu}\}$. In practice, small $k$ is used for the ease of computation, and hence $\delta^k_\alpha$ also contains considerable textures as $\delta^k_\alpha \propto \sum_{\beta\neq 1,2,\cdots,k}V_{\alpha\beta}S_{\beta\nu}$. Notably, if those $k$ equivalent environmental objects do not include sky, the whole term of $\Tilde{X}^k_{\alpha\nu}$ need to be removed from $X_{\alpha\nu}$ to mimic daylight optical imaging, as explained in last section. $\delta^k_\alpha \propto ||\Tilde{X}^k_{\alpha\nu} - X_{\alpha\nu} || $ is exactly the right quantity to show textures. When sky is included in the equivalent environmental objects, firstly, we need to inversely solve $\{T^k_\alpha,m^k_\alpha,V^k_{\alpha;1,\cdots,k}\}$ from the heat signal according to \eref{eq:sgd}, and then, we forwardly evaluate the iterative equations (\ref{eq:heatsignal}) and (\ref{eq:x}) with $\{T^k_\alpha,m^k_\alpha\}$ but keeping only the sky thermal lighting factor $V^k_{\alpha;\mathrm{sky}}$, to get a distilled texture $\Bar{X}_\alpha$. At last, the distilled texture $\Bar{X}_\alpha$ is fused with $\delta^k_\alpha$ to get the final texture used in TeX vision.

\fref{fig:sgdflow} illustrates the process to solve $\{T^k_\alpha,m^k_\alpha,V^k_{\alpha;1,\cdots,k}\}$ for a given sample sky pixel, with $k=2$.
% Figure environment removed
The sky pixel is marked in \fref{fig:sgdflow}a as a white cross. \fref{fig:sgdflow}b shows some sample spectral radiance curves for different materials. The subtle difference in the spectral radiance signal is crucial to distinguish the materials. \fref{fig:sgdflow}c shows the ground truth material library we used for the TeX decomposition. In practice, we define $\delta_m = \mathrm{min}_{TV}\delta^k_\alpha$ for each pixel $\alpha$. \eref{eq:sgd} therefore gives $m^k_\alpha = \mathrm{argmin}_{m}\delta_m$. \fref{fig:sgdflow}d shows $\delta_m$ for the sample sky pixel. The minimum residue correctly predicts it as `sky'. Continuous parameters of temperature $T^k_\alpha$ and thermal lighting factors $V^k_{\alpha;1,\cdots,k}$ can be readily solved out by minimizing $\delta_\mathrm{sky}$ using nonlinear least-squares algorithms. The above procedures are repeated for each pixel for a local decomposition. We then impose a smoothness penalty on the resulting $T^k_\alpha$ and $m^k_\alpha$, in addition to $\delta^k_\alpha$, for a global decomposition.

\fref{fig:distill} shows the TeX vision process to reconstruct texture under sky illumination, mimicking daylight optical imaging. Note that the inverse decomposition is either based on TeX-SGD, or a ground truth separation in Monte Carlo path tracing for ground truth TeX vision.
% Figure environment removed

\fref{fig:sgd} shows the TeX vision generated by TeX-SGD, in comparison with the raw thermal vision and the ground truth TeX vision explained in \sref{sec:gttex}.
% Figure environment removed
We emphasize that TeX-SGD has not been previously tested on the synthetic scenes in the HADAR database with ground truth. \fref{fig:sgd} clearly shows the TeX vision generated by TeX-SGD according to \eref{eq:sgd} has recovered the geometric textures as well as semantic information close to the ground truth. Errors also exist, mainly due to the inaccurate approximation of the environmental radiance. See \sref{sec:env} for more analyses.

\section{Interplay of geometric textures and temperature variation}\label{sec:tmp}
For scenes with artificially designed uniform temperature, texture recovery may be possible by traditional image processing, and it is unclear if TeX vision theory can recover textures for common scenes with non-uniform temperature. Here, we study realistic scenes with non-uniform temperature, in addition to the geometric surface normals, and show the advantage of TeX vision with respect to traditional image processing. Differentiating \eref{eq:heatsignal}, we have
\begin{equation}\label{eq:alltex}
    \delta S = \delta T \cdot e\partial_{T}B + \delta e\cdot [B(T) - X] + \delta X\cdot(1-e).
\end{equation}
Here, we have suppressed the subscripts for clarity. The overall signal variation in the image consists of 3 contributions, including the material change $\delta e$, the temperature contrast $\delta T$, and geometric texture $\delta V$ in the term $\delta X = \delta \vec{V}\cdot \vec{S} + \delta \vec{S}\cdot \vec{V}$. \eref{eq:alltex} indicates that recovering the geometric textures requires the separation of 3 variation contributions. We argue this is possible with the spectral resolution, but in principle, impossible for traditional thermal imaging. The inseparability of geometric textures with temperature and material variations in panchromatic thermal imaging is the deep reason underlying the ghosting effect.

\fref{fig:tmp} shows a newly designed scene with both temperature contrast and geometric textures within each object.
% Figure environment removed
The ground truth temperature in \fref{fig:tmp}a and the optical imaging in \fref{fig:tmp}b show the temperature contrast and vivid geometric textures, respectively. However, geometric textures become invisible after being immersed in the temperature contrast in thermal imaging, see \fref{fig:tmp}c. State-of-the-art CLAHE algorithm can improve the visual contrast but fails to separate the geometric textures from temperature contrast, see \fref{fig:tmp}d. Furthermore, state-of-the-art principle component analysis approach also fails to separate the geometric textures from temperature contrast, see \fref{fig:tmp}e. On the contrary, TeX vision recovers the geometric textures, enabling a night vision close to daylight optical imaging. This result closes the loophole and demonstrates the advantage of TeX vision in overcoming the ghosting effect. See \fref{fig:tmp}f for the ground truth TeX vision and \fref{fig:4band} for the TeX vision generated by TeX-SGD.

\section{Influence of spectral resolution}\label{sec:res}
Spectral resolution plays a vital role in solving the inverse problem of \eref{eq:sgd}. In the absence of spectral resolution, thermal camouflage \cite{Bao2023,Li2020,Qu2018June} leads to ambiguous solutions. How many spectral bands are needed for a TeX vision generally depends on the specific scene and how many materials we want to discern. Here, we study the error scaling law of TeX-SGD with respect to the ground truth TeX vision, for various spectral resolution. The analysis is based on the scene shown in \fref{fig:tmp}. The scene was rendered with 100 spectral bands equidistantly distributed within the LWIR (8-14\,$\mu$m). Out of the 100 bands, we choose an equidistant subset to generate TeX vision and derive the error of predicted material and temperature. \fref{fig:res} shows the error scaling law as a function of number of spectral bands. Our results confirm that prediction errors of TeX-SGD decrease with increasing spectral resolution.
% Figure environment removed

LWIR hyperspectral imaging is experimentally very challenging and expensive. Multi-spectral imaging by the Bayer-filter approach \cite{BRINEZDELEON2019195}, with down to 4 filters, can operate in the snapshot mode and hence is promising for real-time applications such as the autonomous navigation. \fref{fig:4band} demonstrates the TeX vision of TeX-SGD based on 4 spectral bands, in comparison with the ground truth TeX vision and the TeX vision based on 54 bands. The fact that 4-band TeX vision can recover geometric textures and even come close to the ground truth TeX vision shows the possibility of implementing TeX vision in the Bayer-filter approach, which is much more feasible in experiments than LWIR hyperspectral imaging.
% Figure environment removed

\section{Cutoff on environmental objects}\label{sec:env}
Here we analyze the dependence of TeX vision on the approximation of environmental radiance. According to Eqs.~(\ref{eq:approxheat}) and (\ref{eq:approxx}), the accuracy of the predicted TeX vision depends on the modelling of the environmental radiation. A panoramic image is ideally needed to correctly characterize the environment. If the field of view is restricted, the captured image (\ie, the spectral data cube) is used to approximate significant environmental objects.

\fref{fig:dn} shows the TeX vision comparison, with average down sampling vs. the K-means down sampling, of two equivalent environmental objects ($k=2$). Here, in average down sampling, we split the spectral data cube into upper and lower halves along the height direction, spatially average each sub data cube, and get two radiation spectra. The upper spectrum approximates the sky radiation, while the lower spectrum approximates the ground radiation. In K-means down sampling, we perform K-means clustering with $k=2$ on all image pixels, and each cluster is spatially averaged to get the spectrum. As can be seen, K-means down sampling for environment approximation shows more accurate TeX vision. This is reasonable, as K-means clustering is better than coarse meshing at extracting objects with irregular shapes.
% Figure environment removed

We used K-means down sampling for all experiments unless otherwise specified. \fref{fig:env} further shows the error in predicted TeX vision for various preset numbers of equivalent environmental objects ($k$). $k$ is used as the input to K-means clustering.
% Figure environment removed
Due to specific orientations, every object has its own environmental objects that dominate its scattering signal. It follows that more environmental objects (\ie, larger $k$) give lower error in solving \eref{eq:sgd}. However, larger $k$ immediately results in more variables of thermal lighting factors $V_k$, which in turn requires higher spectral resolution to solve the problem. This explains, for a given spectral resolution, why errors steadily approach constants in \fref{fig:env}.

\section{Conclusion}
We studied the interplay of geometric textures and non-uniform temperature contrast in thermal imaging. We have shown that traditional thermal imaging lacking spectral resolution cannot resolve geometric textures from temperature variation, and we argue this is the deep reason causing the ghosting effect. This work closes the loophole and also verifies the remaining questions of the TeX vision theory. Furthermore, we have demonstrated TeX vision with the Bayer-filter approach with low spectral resolution. This relieves the experimental challenge of TeX vision, enabling its real-time applications in, for example, autonomous navigation, robotics, wildlife monitoring, smart healthcare, geoscience, and defense.


\begin{backmatter}
\bmsection{Funding}
This work was supported by the Invisible Headlights project from the Defense Advanced Research Projects Agency (DARPA).

\bmsection{Disclosures}
The authors declare no conflicts of interest.

\bmsection{Data Availability Statement}
Data underlying the results presented in this paper are available at \url{https://github.com/FanglinBao/HADAR}.

\end{backmatter}
%%%%%%%%%%%%%%%%%%%%%%% References %%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%% If using BibTeX:
\bibliography{tex}

%%%%%%%%%% If preparing manually:
% \begin{thebibliography}{1}
% \newcommand{\enquote}[1]{``#1''}

% \bibitem{Zhang:14}
% Y.~Zhang, S.~Qiao, L.~Sun, Q.~W. Shi, W.~Huang, L.~Li, and Z.~Yang,
%   \enquote{Photoinduced active terahertz metamaterials with nanostructured
%   vanadium dioxide film deposited by sol-gel method,}
%   {\protect\JournalTitle{Optics Express}} \textbf{22}, 11070--11078 (2014).

% \end{thebibliography}

\end{document}
