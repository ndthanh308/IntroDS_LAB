{
  "2211-14972": {
    "title": "On Separation Between Learning and Control in Partially Observed Markov Decision Processes",
    "authors": [
      "Andreas A. Malikopoulos"
    ],
    "submission_date": "2022-11-28",
    "semantic_scholar_id": "1c75994d9034f6e4bbf22b9383d6c714badee7d7"
  },
  "2207-10821": {
    "title": "Rethinking Sim2Real: Lower Fidelity Simulation Leads to Higher Sim2Real Transfer in Navigation",
    "authors": [
      "Joanne Truong",
      "M. Rudolph",
      "Naoki Yokoyama",
      "S. Chernova",
      "Dhruv Batra",
      "Akshara Rai"
    ],
    "submission_date": "2022-07-21",
    "semantic_scholar_id": "23c9cac7f58297cb2bad7be5804d0fc277199113"
  },
  "2201-08117": {
    "title": "Learning robust perceptive locomotion for quadrupedal robots in the wild",
    "authors": [
      "Takahiro Miki",
      "Joonho Lee",
      "Jemin Hwangbo",
      "Lorenz Wellhausen",
      "V. Koltun",
      "Marco Hutter"
    ],
    "submission_date": "2022-01-19",
    "semantic_scholar_id": "5da5c2167a85ecb5d1ea22656ae36fdf995df0f2"
  },
  "2107-07599": {
    "title": "Partially Observable Markov Decision Processes (POMDPs) and Robotics",
    "authors": [
      "H. Kurniawati"
    ],
    "submission_date": "2021-07-15",
    "semantic_scholar_id": "478f319c24ec220f5ca805e872937d72621cc4f2"
  },
  "2106-14421": {
    "title": "Causal Reinforcement Learning using Observational and Interventional Data",
    "authors": [
      "Maxime Gasse",
      "Damien Grasset",
      "Guillaume Gaudron",
      "Pierre-Yves Oudeyer"
    ],
    "submission_date": "2021-06-28",
    "semantic_scholar_id": "5a67d69618dcc722f3d466f93fd11e31968df71a"
  },
  "2106-13281": {
    "title": "Brax - A Differentiable Physics Engine for Large Scale Rigid Body Simulation",
    "authors": [
      "C. Freeman",
      "Erik Frey",
      "Anton Raichuk",
      "Sertan Girgin",
      "Igor Mordatch",
      "Olivier Bachem"
    ],
    "submission_date": "2021-06-24",
    "semantic_scholar_id": "13263ec6b83e59442aafe1b45b7554bbba57b680"
  },
  "2106-02039": {
    "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem",
    "authors": [
      "Michael Janner",
      "Qiyang Li",
      "S. Levine"
    ],
    "submission_date": "2021-06-03",
    "semantic_scholar_id": "f864d4d2267abba15eb43db54f58286aef78292b"
  },
  "2106-01345": {
    "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling",
    "authors": [
      "Lili Chen",
      "Kevin Lu",
      "A. Rajeswaran",
      "Kimin Lee",
      "Aditya Grover",
      "M. Laskin",
      "P. Abbeel",
      "A. Srinivas",
      "Igor Mordatch"
    ],
    "submission_date": "2021-06-02",
    "semantic_scholar_id": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500"
  },
  "2102-12344": {
    "title": "Memory-based Deep Reinforcement Learning for POMDPs",
    "authors": [
      "Lingheng Meng",
      "R. Gorbet",
      "Dana Kuli'c"
    ],
    "submission_date": "2021-02-24",
    "semantic_scholar_id": "a08fc4802b730f58ff58fe35ff243d652bce03a9"
  },
  "2012-02924": {
    "title": "iGibson 1.0: A Simulation Environment for Interactive Tasks in Large Realistic Scenes",
    "authors": [
      "Bokui Shen",
      "Fei Xia",
      "Chengshu Li",
      "Roberto Mart'in-Mart'in",
      "Linxi (Jim) Fan",
      "Guanzhi Wang",
      "S. Buch",
      "C. D'Arpino",
      "S. Srivastava",
      "Lyne P. Tchapmi",
      "Micael E. Tchapmi",
      "Kent Vainio",
      "Li Fei-Fei",
      "S. Savarese"
    ],
    "submission_date": "2020-12-05",
    "semantic_scholar_id": "cda5d891ae6262c55c8711ef5b18ccc1fe748d7a"
  },
  "2006-04439": {
    "title": "Liquid Time-constant Networks",
    "authors": [
      "Ramin M. Hasani",
      "Mathias Lechner",
      "Alexander Amini",
      "D. Rus",
      "R. Grosu"
    ],
    "submission_date": "2020-06-08",
    "semantic_scholar_id": "1b9a07702cd346673b4c5e798d2256157fab1d3f"
  },
  "1901-04473": {
    "title": "Adaptive Guidance with Reinforcement Meta-Learning",
    "authors": [
      "B. Gaudet",
      "R. Linares"
    ],
    "submission_date": "2019-01-12",
    "semantic_scholar_id": "d437504615af259b676f4a3efc9a943f2a177d1d"
  },
  "1811-03307": {
    "title": "Memory-Based Deep Reinforcement Learning for Obstacle Avoidance in UAV With Limited Environment Knowledge",
    "authors": [
      "Abhik Singla",
      "Sindhu Padakandla",
      "S. Bhatnagar"
    ],
    "submission_date": "2018-11-08",
    "semantic_scholar_id": "c43b12c0571d2d58d513bf9cc9cdfae363aa7d72"
  },
  "1810-05587": {
    "title": "A survey and critique of multiagent deep reinforcement learning",
    "authors": [
      "Pablo Hernandez-Leal",
      "Bilal Kartal",
      "Matthew E. Taylor"
    ],
    "submission_date": "2018-10-12",
    "semantic_scholar_id": "3f43f08611cbcfba62bb9e0c5339c2a8f0cc3e4b"
  },
  "1802-09477": {
    "title": "Addressing Function Approximation Error in Actor-Critic Methods",
    "authors": [
      "Scott Fujimoto",
      "H. V. Hoof",
      "D. Meger"
    ],
    "submission_date": "2018-02-26",
    "semantic_scholar_id": "4debb99c0c63bfaa97dd433bc2828e4dac81c48b"
  },
  "1606-01540": {
    "title": "OpenAI Gym",
    "authors": [
      "Greg Brockman",
      "Vicki Cheung",
      "Ludwig Pettersson",
      "Jonas Schneider",
      "John Schulman",
      "Jie Tang",
      "Wojciech Zaremba"
    ],
    "submission_date": "2016-06-05",
    "semantic_scholar_id": "2b10281297ee001a9f3f4ea1aa9bea6b638c27df"
  },
  "1602-01783": {
    "title": "Asynchronous Methods for Deep Reinforcement Learning",
    "authors": [
      "Volodymyr Mnih",
      "Adrià Puigdomènech Badia",
      "Mehdi Mirza",
      "Alex Graves",
      "T. Lillicrap",
      "Tim Harley",
      "David Silver",
      "K. Kavukcuoglu"
    ],
    "submission_date": "2016-02-04",
    "semantic_scholar_id": "69e76e16740ed69f4dc55361a3d319ac2f1293dd"
  },
  "1512-04455": {
    "title": "Memory-based control with recurrent neural networks",
    "authors": [
      "N. Heess",
      "Jonathan J. Hunt",
      "T. Lillicrap",
      "David Silver"
    ],
    "submission_date": "2015-12-14",
    "semantic_scholar_id": "bcfe915d5983dffbfe95801e9e6757205b3a4723"
  },
  "1509-03044": {
    "title": "Recurrent Reinforcement Learning: A Hybrid Approach",
    "authors": [
      "Xiujun Li",
      "Lihong Li",
      "Jianfeng Gao",
      "Xiaodong He",
      "Jianshu Chen",
      "L. Deng",
      "Ji He"
    ],
    "submission_date": "2015-09-10",
    "semantic_scholar_id": "c9804e5df4ea3f4fcc5379ad44bdd0ff743ab20e"
  },
  "1509-02971": {
    "title": "Continuous control with deep reinforcement learning",
    "authors": [
      "T. Lillicrap",
      "Jonathan J. Hunt",
      "A. Pritzel",
      "N. Heess",
      "Tom Erez",
      "Yuval Tassa",
      "David Silver",
      "D. Wierstra"
    ],
    "submission_date": "2015-09-09",
    "semantic_scholar_id": "024006d4c2a89f7acacc6e4438d156525b60a98f"
  },
  "1507-06527": {
    "title": "Deep Recurrent Q-Learning for Partially Observable MDPs",
    "authors": [
      "Matthew J. Hausknecht",
      "P. Stone"
    ],
    "submission_date": "2015-07-23",
    "semantic_scholar_id": "f5f323e62acb75f785e00b4c90ace16f1690076f"
  },
  "1502-02367": {
    "title": "Gated Feedback Recurrent Neural Networks",
    "authors": [
      "Junyoung Chung",
      "Çaglar Gülçehre",
      "Kyunghyun Cho",
      "Yoshua Bengio"
    ],
    "submission_date": "2015-02-08",
    "semantic_scholar_id": "d14c7e5f5cace4c925abc74c88baa474e9f31a28"
  }
}