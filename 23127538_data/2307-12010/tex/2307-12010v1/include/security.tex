\section{Complexity and Security Analysis}\label{sec:security}
In this section, we first provide a theoretical complexity analysis to show that CryptoMask can support database with millions records.
% which is extremely expensive in most recent literatures. 
Then we analyze that our face recognition protocol is secure against a semi-honest adversary under the assumption supposing the KG is fully trusted.

\subsection{Complexity Analysis}
In CryptoMask, the communication overhead mainly comes from two parts. One is from the CS who sends all the encrypted distances to the verifier which contains $O(Nm/d)$ communication cost. Another one is the result from secure revealing process which requires $O(ml)$ communication. We can obtain the overall communication complexity as $O(Nm/d+ml)$. The computation overhead is more complex. We set the computation for data encryption using HE as $C_{en}$, for homomorphic multiplication as $C_{mul}$, for homomorphic addition as $C_{add}$, for key switching as $C_{sw}$, for secure comparison as $C_{com}$ and for secure~\textit{B2A} as $C_{cov}$. The overall computation overhead for the CS side is $O((Nm/d)(C_{com}+C_{add} + C_{sw}) + m(C_{com}+C_{cov}))$ and for the verifier side is $O(C_{en} + m(C_{com}+C_{cov}))$.

\subsection{Security Analysis}
% We have Theorem~\ref{theorem:security} to capture the security of CryptoMask. 

% \begin{theorem}\label{theorem:security} Algorithm~\ref{alg:distance computation} 
% and Algorithm~\ref{alg:result-revealing} securely compute the functionality $f$ in $f_{com}$-hybrid model against a semi-honest adversary.
% \end{theorem}

\textbf{Privacy of Face Vector Matrix}. 
In CryptoMask, all face vectors are encrypted by HE, and only the KG knows the secret key. Due to the semantic security of HE, neither CS or verifier learns sensitive information about the underlying encrypted face vector, thus the privacy of face vector is always maintained. 

Now we show CryptoMask only reveals a face recognition result to the verifier, and nothing else to either party. 
This is argued as regards to a corrupted CS and a corrupted verifier respectively.

\textbf{Adversarial CS.} We first demonstrate the security against a semi-honest CS. Intuitively, the security against a semi-honest CS comes from the fact that the CS's view of the execution includes only ciphertext, thus reducing the argument to semantic security of HE. We now give the formal argument. 

Let $\mathcal{A}$ be a semi-honest CS in the real protocol. We construct a simulator $\mathcal{S}$ in the ideal world as follows:

\begin{enumerate}
    \item[1.]At the beginning of the protocol execution, $\mathcal{S}$ receives the input $\boldsymbol{\mathsf{A}}$ from the environment $\mathcal{E}$ and also receives the public key $pk$ and the vector length $d$. The simulator sends $\boldsymbol{\mathsf{A}}$ to the trusted party.
    \item[2.]Start running $\mathcal{A}$ on input $\boldsymbol{\mathsf{A}}$. Next, $\mathcal{S}$ computes and sends a ciphertext $ct$ which is the encryption of a $d$ dimensional vector $\boldsymbol{0}$ to the CS under the public key $pk$.
    \item[3.]Output whatever $\mathcal{A}$ outputs.
\end{enumerate}
We argue the above simulated view is indistinguishable from real protocol execution. 
Using the fact that $\mathcal{A}$ is semi-honest, we have that at the end of the scheme in the real world, the verifier obtains $\boldsymbol{\mathsf{A}}(\boldsymbol{\mathsf{b}})$ where $\boldsymbol{\mathsf{b}}$ is the verifier's queried face image. Since $\mathcal{S}$ is semi-honest, this also holds in the ideal world. Since $\boldsymbol{\mathsf{A}}(\boldsymbol{\mathsf{b}})$ is a deterministic function, the joint distribution of the verifier's output and the adversary's output decomposes. Thus, it is suffice to show that the simulated view from $\mathcal{S}$ is computationally indistinguishable from the real view from $\mathcal{A}$.

The view of $\mathcal{A}$ in the real world contains one part: the encrypted face image ${ct}$ from the verifier. When interacting with the simulator $\mathcal{S}$, adversary $\mathcal{A}$ sees an encryption of $\boldsymbol{0}$. Security follows immediately by the semantic security of the BFV scheme.

\textbf{Adversarial Verifier.} We now prove the security against a semi-honest verifier. We construct a simulator $\mathcal{S}$ in the ideal world as follows:

\begin{enumerate}
    \item[1.]At the beginning of the execution, $\mathcal{S}$ receives the input $\boldsymbol{\mathsf{b}}$ from the environment $\mathcal{E}$ and also receives the BFV key pairs $(pk,sk)$ and the matrix size $m,d$. The simulator sends $\boldsymbol{\mathsf{b}}$ to the trusted party.
    \item[2.]Start running $\mathcal{A}$ on input $\boldsymbol{\mathsf{b}}$. Next, $\mathcal{S}$ computes and sends ciphertexts $c_i$ which is the encryption of a $m \times d$ matrix filled by some random values to the verifier under public key $pk_v$.
    \item[3.]Output whatever $\mathcal{A}$ outputs.
\end{enumerate}
In the end of face recognition, the CS has no output. Thus, to show security against a semi-honest verifier, it suffices to show that the output of $\mathcal{S}$ is computationally indistinguishable from the output of the adversary $\mathcal{A}$. Now we show the view of simulator $\mathcal{S}$ in the ideal world is computationally indistinguishable from the view of the adversary $\mathcal{A}$ in the real world.

The view of $\mathcal{A}$ in the real world contains one part: the encrypted face database $\{c_1, \cdots, c_n\}$ from CS. When interacting with the simulator $\mathcal{S}$, adversary $\mathcal{A}$ sees the encryption of random values. Security follows immediately by the semantic security of the BFV scheme.
