\section{Conclusion}
\label{sec:conclusion}

In this work, we propose \emph{The GANfather} to generate data of a class for which no labelled examples are available (malicious activity), while simultaneously training a detection network to classify this class correctly.

We performed experiments in two domains.
In the anti-money laundering setting, the generated attacks are able to move up to 350,000 dollars using just five internal accounts, and without triggering an existing detection system.
Then we show that for a real-world labelled dataset, a model trained with these generated attacks can be used to complement the rules, alerting previously undetected suspicious activity.
In the recommender system setting, we generate attacks that are substantially more successful at recommending the target item than naive baselines.
Then, we train a near-perfect classifier to detect the synthetic malicious activity.
%While no ground truth for the generated attacks are available, we argue that any attack strategy that is possible could in principle be exploited by attackers.
While a real test in a deployment scenario is lacking and should be addressed in future work, we believe our current experiments provide a proof of value of the method.
In these experiments, our method generates a variety of successful attacks, and we therefore believe it can be a valuable method to improve the robustness of defence systems. 

The limitations of our method lie in its assumptions.
Firstly, we assume that the unlabelled data is dominated by legitimate events, and our method would not work in settings where this is not the case.
Secondly, we assume that we can quantify the malicious objective in terms of available features.
In this case, one could argue we can just use the malicious objective as a detection score.
However, the detection system often has a (much) smaller view than the malicious objective.
For example, anti-money laundering systems only view incoming and outgoing transactions for \emph{one} financial institution.
However, our objective can be adapted to generate malicious activity mimicking flows across \emph{multiple} synthetic financial institutions, while keeping the view of the discriminator on an individual institution level.
Thirdly, while our method does not prevent generated data to be very different from real data, we argue that the strength of our method is in generating more subtle attacks that are not immediately distinguishable from real data.
Finally, while we chose the malicious objectives to be as simple as possible in our proof of concept experiments, there is no restriction to make them more complex as long as they are differentiable. 

To conclude, our method fits the adversarial game between criminals and security systems by simulating various meaningful attacks.
If existing defences are in place, our method may learn to avoid them and, eventually, train a complementary model.
Incorporating machine learning models into the detection system typically enhances the detection of illicit activity by triggering more precise alerts, while being easier to fine-tune and maintain.
We believe our work contributes to increase the robustness of detection methods of illicit activity.