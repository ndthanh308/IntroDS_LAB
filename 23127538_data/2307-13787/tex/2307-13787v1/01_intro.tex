% Figure environment removed


\section{Introduction}
\label{sec:introduction}

%Many aspects of our society become increasingly dominated by digital systems, in turn providing new opportunities for illicit actors.
Digital systems' growing dominance in various aspects of our society opens up new opportunities for illicit actors.
For example, digital banking enables clients to open bank accounts more easily but also facilitates complex money laundering schemes. It is estimated that undetected money laundering activities worldwide accumulate to 1.7--4 trillion euros annually \citep{lannoo2021aei}, while operational costs related to anti-money laundering (AML) compliance tasks incurred by financial institutions accumulate to \$37.1 billion~\citep{ray2021celent}. Another example are recommender systems, which are often embedded in digital services to deliver personalised experiences.
However, recommender systems may suffer from injection attacks whenever malicious actors fabricate signals (e.g., clicks, ratings, or reviews) to influence recommendations. These attacks have detrimental effects on the user experience. For example, a one-star decrease in restaurant ratings can lead to a 5 to 9 percent decrease in revenue \citep{luca2011reviews}.

The detection of such malicious attacks is challenging in the following aspects. In many cases, these illicit activities are adversarial in nature, where an attacker and a defence system adapt to each other's behaviour over time. Additionally, labelled datasets are unavailable or incomplete in certain domains due to the absence of natural labels and the cost of manual feedback. For example, besides the large amount of undetected money laundering, the investigation of detected suspicious activity is often far from trivial, resulting in a feedback delay that can last months. 

To address these issues, we propose \textit{The GANfather}, a method to generate examples of illicit activity and train effective detection systems without any labelled examples. Starting from unlabelled data, which we assume to be predominantly legitimate, the proposed method leverages a GAN-like setup~\citep{goodfellow2014generative} to train a generator which learns to create malicious activity, as well as a detection model (the discriminator) learning to distinguish between real data and synthetic malicious data.

To be able to generate samples with malicious properties from legitimate data, we propose to include an additional optimisation objective in the training loss of the generator. This objective is a use-case-specific, user-defined differentiable formulation of the goal of the malicious agents. Furthermore, our method optionally allows to incorporate an existing defence system, as long as a differentiable formulation is possible. In that case, we penalise the generator when triggering existing detection mechanisms. Our method can then actively find liabilities in an existing system while simultaneously training a complementary detection system to protect against such attacks.

\iffalse
% Figure environment removed
\fi

Our method has some desirable properties that make it particularly well-suited for adversarial domains where no labelled data is available:

\begin{itemize}[leftmargin=*]
    \item \textbf{No labelled malicious samples are needed}. Here, we assume that our unlabelled data is predominantly of legitimate nature.
    \item \textbf{Samples with features of malicious activity are generated}. The key to generate such samples from legitimate data is to introduce an extra objective function that nudges the generator to produce samples with the required properties. We implicitly assume that malicious activity shares many properties with legitimate behaviour. We justify this assumption since attackers often mimic legitimate activity to some degree, in order to avoid raising suspicion or triggering existing detection systems.
    \item \textbf{A robust detection system is trained}. By training a discriminator to distinguish between the synthetic malicious samples and real data, we conjecture that the defence against a variety of real malicious attacks can be strengthened.
\end{itemize}

While each of these properties can be found separately in other methods, we believe that the combination of all the properties in a single method is novel and useful in the discussed scenarios. In Figure \ref{fig:cartoon}, we illustrate visually how our method distinguishes itself from some well-known approaches. Finally, while we only perform experiments on two use-cases (anti-money laundering and recommender systems) in the following sections, we believe that the suggested approach is applicable in other domains facing similar constraints, i.e., no labelled data and adversarial attacks, subject to domain-specific adaptations.

