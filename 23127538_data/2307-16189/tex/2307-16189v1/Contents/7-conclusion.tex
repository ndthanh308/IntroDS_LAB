The field of deep learning, while highly advanced, continues to face fundamental challenges such as numerical instability. In this study, we introduced a novel approach to tackle the numerical instability frequently encountered during the backpropagation phase of model training. This involved a sophisticated modification to the Adam optimizer's gradient update equation, leading to a significant reduction in numerical instability, particularly in a 16-bit neural network training scenario.

Our empirical evaluations, conducted on the MNIST dataset using a simple Deep Neural Network (DNN) consisting of a single linear layer, yielded promising results. As shown in Table 1, the modified optimization algorithm consistently demonstrated robust performance, and in most cases, exceeded the traditional Adam optimizer in terms of test accuracy in a 16-bit precision setting. Furthermore, our method ensured numerical stability across a range of epsilon values. Notably, the training time with our modified optimizer in 16-bit precision setting was about 45\% lower than that in a 32-bit precision setting, highlighting the efficiency of our approach. Despite the complexity of the problem, we found that our modified optimizer maintained numerical stability across a range of values. Importantly, we observed a noticeable reduction in the occurrence of numerical underflows and overflows, thus ensuring the robustness of the training process even with 16-bit precision. While the experimental results are encouraging, it is important to acknowledge that this study focused primarily on a simple DNN with a single Linear Layer. This signifies the necessity of further investigations to validate the effectiveness of our proposed method on more complex architectures, such as convolutional neural networks (CNNs) and Vision Transformers (ViTs). By expanding the scope of our approach across various network architectures, we aim to establish a comprehensive and robust method for mitigating numerical instability in a wide range of deep learning models. In conclusion, this work makes a significant contribution to the ongoing endeavors in enhancing deep learning methodologies, specifically focusing on improving the stability and efficiency of model training. We anticipate that our research findings will stimulate further advancements in the field, ultimately leading to the development of more reliable and robust deep learning systems. Our hope is that this innovative approach to preventing numerical instability in 16-bit neural networks will become a cornerstone in the future of efficient and stable model training.