\begin{thebibliography}{00}
\bibitem{kingma2014adam}
D. P. Kingma and J. Ba,
"Adam: A method for stochastic optimization,"
arXiv preprint arXiv:1412.6980, 2014.

\bibitem{tieleman2012lecture}
T. Tieleman and G. Hinton,
"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude,"
COURSERA: Neural Networks for Machine Learning, 2012.

\bibitem{Gupta2015}
S. Gupta, A. Agrawal, K. Gopalakrishnan, and P. Narayanan,
\emph{Deep learning with limited numerical precision},
Proceedings of the 32nd International Conference on Machine Learning (ICML-15),
2015, pp. 1737-1746.

\bibitem{Courbariaux2016}
M. Courbariaux, I. Hubara, D. Soudry, R. El-Yaniv, and Y. Bengio,
\emph{Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1},
arXiv preprint arXiv:1602.02830,

\bibitem{Micikevicius2017}
P. Micikevicius, S. Narang, J. Alben, G. Diamos, E. Elsen, D. Garcia, B. Ginsburg, M. Houston, O. Kuchaiev, G. Venkatesh, and H. Wu,
\emph{Mixed precision training},
arXiv preprint arXiv:1710.03740,

\bibitem{Bengio1994}
Y. Bengio, P. Simard, and P. Frasconi,
\emph{Learning long-term dependencies with gradient descent is difficult},
IEEE Transactions on Neural Networks,
vol. 5, no. 2,
1994, pp. 157-166.

\bibitem{Albericio2016}
J. Albericio, P. Judd, T. Hetherington, T. M. Aamodt, N. E. Jerger, and A. Moshovos,
\emph{Cnvlutin: Ineffectual-neuron-free deep neural network computing},
Proceedings of the 43rd International Symposium on Computer Architecture,
Seoul,
2016, pp. 1-13.

\bibitem{yun2023defense}
J. Yun, B. Kang, F. Rameau, and Z. Fu, "In Defense of Pure 16-bit Floating-Point Neural Networks," arXiv preprint arXiv:2305.10947, 2023.

\bibitem{Han2015}
S. Han, H. Mao, and W. J. Dally,
\emph{Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding},
arXiv preprint arXiv:1510.00149,


\bibitem{Goodfellow2016}
I. Goodfellow, Y. Bengio, and A. Courville, 
\textit{Deep Learning}, 
MIT Press, 2016.

\bibitem{He2015}
K. He, X. Zhang, S. Ren, and J. Sun,
\textit{"Delving deep into rectifiers: Surpassing human-level performance on imagenet classification"}, 
In Proceedings of the IEEE international conference on computer vision, pp. 1026-1034, 2015.

\bibitem{Rumelhart1986}
D. E. Rumelhart, G. E. Hinton, and R. J. Williams, 
\textit{"Learning representations by back-propagating errors"}, 
Nature, 323(6088), pp. 533-536, 1986.

\bibitem{Lecun1998}
Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, 
\textit{"Gradient-based learning applied to document recognition"}, 
Proceedings of the IEEE, 86(11), pp. 2278-2324, 1998.

\bibitem{ruder2017overview}
S. Ruder, 
"An overview of gradient descent optimization algorithms," 
arXiv preprint arXiv:1609.04747, 2017.

\bibitem{lecun1998gradient}
Y. LeCun, L. Bottou, Y. Bengio and P. Haffner,
"Gradient-based learning applied to document recognition,"
Proceedings of the IEEE, vol. 86, no. 11, pp. 2278-2324, Nov. 1998.

\bibitem{dosovitskiy2020image} 
A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby, "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale," \emph{arXiv preprint arXiv:2010.11929}, 2020.

\end{thebibliography}