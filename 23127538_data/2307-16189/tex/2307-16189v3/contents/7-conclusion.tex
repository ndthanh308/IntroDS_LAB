Deep learning, while advanced, faces challenges like numerical instability. We've developed a novel strategy to counter this, primarily seen during backpropagation. Our method modifies the gradient update in the Adam optimizer, reducing instability in 16-bit neural training. Tests on the MNIST dataset using a simple DNN showed our optimizer's effectiveness, often surpassing conventional Adam in a 16-bit setup. Notably, our 16-bit method reduced training time by about 45\% compared to 32-bit and maintained stability across various epsilon values. Trials on the Vision Transformer model for cifar-10 revealed that our 16-bit models processed data 30\% faster than 32-bit, with added stability. However, our focus was on image classification via Linear DNN and VIT. Future research will explore our method's effectiveness in complex architectures and tasks, like NLP. Our goal is to create a comprehensive solution for numerical instability in deep learning, and we believe our work lays a strong foundation for future innovations.