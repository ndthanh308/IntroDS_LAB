@article{Gelenbe1989,
  title = {Random {{Neural Networks}} with {{Negative}} and {{Positive Signals}} and {{Product Form Solution}}},
  author = {Gelenbe, Erol},
  year = {1989},
  month = dec,
  journal = {Neural Comput},
  volume = {1},
  number = {4},
  pages = {502--510},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco.1989.1.4.502}
}


@article{Colabrese.2018, 
year = {2018}, 
title = {{Smart inertial particles}}, 
author = {Colabrese, Simona and Gustavsson, Kristian and Celani, Antonio and Biferale, Luca}, 
journal = {Phys Rev Fluids}, 
doi = {10.1103/physrevfluids.3.084301}, 
eprint = {1711.05853}, 
abstract = {{We performed a numerical study to train smart inertial particles to target specific flow regions with high vorticity through the use of reinforcement learning algorithms. The particles are able to actively change their size to modify their inertia and density. In short, using local measurements of the flow vorticity, the smart particle explores the interplay between its choices of size and its dynamical behavior in the flow environment. This allows it to accumulate experience and learn approximately optimal strategies of how to modulate its size in order to reach the target high-vorticity regions. We consider flows with different complexities: a two-dimensional stationary Taylor-Green-like configuration, a two-dimensional time-dependent flow, and finally a three-dimensional flow given by the stationary Arnold-Beltrami-Childress (ABC) helical flow. We show that smart particles are able to learn how to reach extremely intense vortical structures in all the tackled cases.}}, 
pages = {084301}, 
number = {8}, 
volume = {3}, 
keywords = {}
}


@article{Rafayelyan.2020, 
year = {2020}, 
title = {{Large-Scale Optical Reservoir Computing for Spatiotemporal Chaotic Systems Prediction}}, 
author = {Rafayelyan, Mushegh and Dong, Jonathan and Tan, Yongqi and Krzakala, Florent and Gigan, Sylvain}, 
journal = {Phys Rev X}, 
doi = {10.1103/physrevx.10.041037}, 
eprint = {2001.09131}, 
abstract = {{Reservoir computing is a relatively recent computational paradigm that originates from a recurrent neural network and is known for its wide range of implementations using different physical technologies. Large reservoirs are very hard to obtain in conventional computers, as both the computation complexity and memory usage grow quadratically. We propose an optical scheme performing reservoir computing over very large networks potentially being able to host several millions of fully connected photonic nodes thanks to its intrinsic properties of parallelism and scalability. Our experimental studies confirm that, in contrast to conventional computers, the computation time of our optical scheme is only linearly dependent on the number of photonic nodes of the network, which is due to electronic overheads, while the optical part of computation remains fully parallel and independent of the reservoir size. To demonstrate the scalability of our optical scheme, we perform for the first time predictions on large spatiotemporal chaotic datasets obtained from the Kuramoto-Sivashinsky equation using optical reservoirs with up to 50 000 optical nodes. Our results are extremely challenging for conventional von Neumann machines, and they significantly advance the state of the art of unconventional reservoir computing approaches, in general.}}, 
pages = {041037}, 
number = {4}, 
volume = {10}, 
keywords = {}
}

@article{Marković.2020, 
year = {2020}, 
title = {{Physics for neuromorphic computing}}, 
author = {Marković, Danijela and Mizrahi, Alice and Querlioz, Damien and Grollier, Julie}, 
journal = {Nat Rev Phys}, 
doi = {10.1038/s42254-020-0208-2}, 
abstract = {{Neuromorphic computing takes inspiration from the brain to create energy-efficient hardware for information processing, capable of highly sophisticated tasks. Systems built with standard electronics achieve gains in speed and energy by mimicking the distributed topology of the brain. Scaling-up such systems and improving their energy usage, speed and performance by several orders of magnitude requires a revolution in hardware. We discuss how including more physics in the algorithms and nanoscale materials used for data processing could have a major impact in the field of neuromorphic computing. We review striking results that leverage physics to enhance the computing capabilities of artificial neural networks, using resistive switching materials, photonics, spintronics and other technologies. We discuss the paths that could lead these approaches to maturity, towards low-power, miniaturized chips that could infer and learn in real time. Neuromorphic computing takes inspiration from the brain to create energy-efficient hardware for information processing, capable of highly sophisticated tasks. Including more physics in the algorithms and nanoscale materials used for computing could have a major impact in this field.}}, 
pages = {499--510}, 
number = {9}, 
volume = {2}, 
keywords = {}
}

@book{Cosentino.2019, 
year = {2019}, 
title = {{Feedback Control in Systems Biology}}, 
author = {Cosentino, Carlo and Bates, Declan}, 
isbn = {9781439816912}, 
publisher = {CRC Press}, 
address = {Boca Raton}, 
keywords = {}, 
doi = {10.1201/b11153}
}


@article{Celani.2010, 
year = {2010}, 
title = {{Bacterial strategies for chemotaxis response}}, 
author = {Celani, Antonio and Vergassola, Massimo}, 
journal = {Proc Natl Acad Sci USA}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.0909673107}, 
pmid = {20080704}, 
pmcid = {PMC2824349}, 
abstract = {{Regular environmental conditions allow for the evolution of specifically adapted responses, whereas complex environments usually lead to conflicting requirements upon the organism’s response. A relevant instance of these issues is bacterial chemotaxis, where the evolutionary and functional reasons for the experimentally observed response to chemoattractants remain a riddle. Sensing and motility requirements are in fact optimized by different responses, which strongly depend on the chemoattractant environmental profiles. It is not clear then how those conflicting requirements quantitatively combine and compromise in shaping the chemotaxis response. Here we show that the experimental bacterial response corresponds to the maximin strategy that ensures the highest minimum uptake of chemoattractants for any profile of concentration. We show that the maximin response is the unique one that always outcompetes motile but nonchemotactic bacteria. The maximin strategy is adapted to the variable environments experienced by bacteria, and we explicitly show its emergence in simulations of bacterial populations in a chemostat. Finally, we recast the contrast of evolution in regular vs. complex environments in terms of minimax vs. maximin game-theoretical strategies. Our results are generally relevant to biological optimization principles and provide a systematic possibility to get around the need to know precisely the statistics of environmental fluctuations.}}, 
pages = {1391--1396}, 
number = {4}, 
volume = {107}, 
keywords = {}
}


@article{Gustavsson.2017, 
year = {2017}, 
rating = {0}, 
keywords = {Topical issue: Fluids and Structures: Multi-scale}, 
title = {{Finding efficient swimming strategies in a three-dimensional chaotic flow by reinforcement learning}}, 
author = {Gustavsson, K. and Biferale, L. and Celani, A. and Colabrese, S.}, 
journal = {Eur Phys J E}, 
issn = {1292-8941}, 
doi = {10.1140/epje/i2017-11602-9}, 
pmid = {29234967}, 
eprint = {1711.05826}, 
abstract = {{We apply a reinforcement learning algorithm to show how smart particles can learn approximately optimal strategies to navigate in complex flows. In this paper we consider microswimmers in a paradigmatic three-dimensional case given by a stationary superposition of two Arnold-Beltrami-Childress flows with chaotic advection along streamlines. In such a flow, we study the evolution of point-like particles which can decide in which direction to swim, while keeping the velocity amplitude constant. We show that it is sufficient to endow the swimmers with a very restricted set of actions (six fixed swimming directions in our case) to have enough freedom to find efficient strategies to move upward and escape local fluid traps. The key ingredient is the learning-from-experience structure of the algorithm, which assigns positive or negative rewards depending on whether the taken action is, or is not, profitable for the predetermined goal in the long-term horizon. This is another example supporting the efficiency of the reinforcement learning approach to learn how to accomplish difficult tasks in complex fluid environments. }}, 
pages = {110}, 
number = {12}, 
volume = {40}, 
month = {12}
}
@article{Colabrese.201760u, 
year = {2017}, 
title = {{Flow Navigation by Smart Microswimmers via Reinforcement Learning}}, 
author = {Colabrese, Simona and Gustavsson, Kristian and Celani, Antonio and Biferale, Luca}, 
journal = {Phys Rev Lett}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.118.158004}, 
pmid = {28452499}, 
eprint = {1701.08848}, 
abstract = {{Smart active particles can acquire some limited knowledge of the fluid environment from simple mechanical cues and exert a control on their preferred steering direction. Their goal is to learn the best way to navigate by exploiting the underlying flow whenever possible. As an example, we focus our attention on smart gravitactic swimmers. These are active particles whose task is to reach the highest altitude within some time horizon, given the constraints enforced by fluid mechanics. By means of numerical experiments, we show that swimmers indeed learn nearly optimal strategies just by experience. A reinforcement learning algorithm allows particles to learn effective strategies even in difficult situations when, in the absence of control, they would end up being trapped by flow structures. These strategies are highly nontrivial and cannot be easily guessed in advance. This Letter illustrates the potential of reinforcement learning algorithms to model adaptive behavior in complex flows and paves the way towards the engineering of smart microswimmers that solve difficult navigation problems.}}, 
pages = {158004}, 
number = {15}, 
volume = {118}, 
keywords = {}
}

@article{Muinos-Landin2021,
  title = {Reinforcement Learning with Artificial Microswimmers},
  author = {{Mui{\~n}os-Landin}, S. and Fischer, A. and Holubec, V. and Cichos, F.},
  year = {2021},
  month = mar,
  journal = {Sci Robot},
  volume = {6},
  number = {52},
  pages = {eabd9285},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/scirobotics.abd9285}
}


@article{Schneider.2019, 
year = {2019}, 
title = {{Optimal steering of a smart active particle}}, 
author = {Schneider, E. and Stark, H.}, 
journal = {EPL}, 
issn = {0295-5075}, 
doi = {10.1209/0295-5075/127/64003}, 
eprint = {1909.03243}, 
abstract = {{We formulate the theory for steering an active particle with optimal travel time between two locations and apply it to the Mexican hat potential without brim. For small heights the particle can cross the potential barrier, while for large heights it has to move around it. Thermal fluctuations in the orientation strongly affect the path over the barrier. Then we consider a smart active particle and apply reinforcement learning. We show how the active particle learns in repeating episodes to move optimally. The optimal steering is stored in the optimized action-value function, which is able to rectify thermal fluctuations.}}, 
pages = {64003}, 
number = {6}, 
volume = {127}, 
keywords = {}
}

@article{Liebchen.2019, 
year = {2019}, 
title = {{Optimal navigation strategies for active particles}}, 
author = {Liebchen, Benno and Löwen, Hartmut}, 
journal = {EPL}, 
issn = {0295-5075}, 
doi = {10.1209/0295-5075/127/34003}, 
abstract = {{The quest for the optimal navigation strategy in a complex environment is at the heart of microswimmer applications like cargo carriage or drug targeting to cancer cells. Here, we formulate a variational Fermat's principle for microswimmers determining the optimal path towards a given target regarding travelling time, energy dissipation or fuel consumption. For piecewise constant forces (or flow fields), the principle leads to Snell's law, showing that the optimal path is piecewise linear, as for light rays, but with a generalized refraction law. For complex environments, like general 1D, shear or vortex fields, we obtain exact analytical expressions for the optimal path, showing, for example, that microswimmers sometimes have to temporarily navigate away from their target to reach it fastest. Our results apply to idealized microswimmers which can instantaneously steer, are fast enough so that translational noise is unimportant and might be useful, e.g., to benchmark algorithmic schemes for optimal navigation.}}, 
pages = {34003}, 
number = {3}, 
volume = {127}, 
keywords = {}
}

@article{Gonon2021,
  title = {Fading Memory Echo State Networks Are Universal},
  author = {Gonon, Lukas and Ortega, Juan-Pablo},
  year = {2021},
  month = jun,
  journal = {Neural Netw},
  volume = {138},
  pages = {10--13},
  issn = {08936080}
}

@article{Alata2020,
  title = {Phase {{Noise Robustness}} of a {{Coherent Spatially Parallel Optical Reservoir}}},
  author = {Alata, Romain and Pauwels, Ja{\"e}l and Haelterman, Marc and Massar, Serge},
  year = {2020},
  month = jan,
  journal = {IEEE J Sel Top Quantum Electron},
  volume = {26},
  number = {1},
  pages = {1--10},
  issn = {1558-4542},
  doi = {10.1109/JSTQE.2019.2929181},
  keywords = {Cavity resonators,Neurons,noise mitigation strategies,Numerical models,Optical resonators,phase noise,Phase noise,Photodiodes,photonics,Reservoir computing,Reservoirs}
}

@article{Antonik2017b,
  title = {Brain-{{Inspired Photonic Signal Processor}} for {{Generating Periodic Patterns}} and {{Emulating Chaotic Systems}}},
  shorttitle = {{{光信号RC带feedback含噪音}}},
  author = {Antonik, Piotr and Haelterman, Marc and Massar, Serge},
  year = {2017},
  month = may,
  journal = {Phys Rev Appl},
  volume = {7},
  number = {5},
  pages = {054014},
  issn = {2331-7019},
  doi = {10.1103/PhysRevApplied.7.054014}
}

@article{Antonik2018,
  title = {Random {{Pattern}} and {{Frequency Generation Using}} a {{Photonic Reservoir Computer}} with {{Output Feedback}}},
  shorttitle = {{{光信号RC带feedback}}},
  author = {Antonik, Piotr and Hermans, Michiel and Haelterman, Marc and Massar, Serge},
  year = {2018},
  month = jun,
  journal = {Neural Process Lett},
  volume = {47},
  number = {3},
  pages = {1041--1054},
  issn = {1370-4621, 1573-773X},
  doi = {10.1007/s11063-017-9628-0},
  url = {http://link.springer.com/10.1007/s11063-017-9628-0}
}

@article{Antonik2018a,
  title = {Using a Reservoir Computer to Learn Chaotic Attractors, with Applications to Chaos Synchronization and Cryptography},
  shorttitle = {{{Lorenz}},Liapunov},
  author = {Antonik, Piotr and Gulina, Marvyn and Pauwels, Ja{\"e}l and Massar, Serge},
  year = {2018},
  month = jul,
  journal = {Phys Rev E},
  volume = {98},
  number = {1},
  pages = {012215},
  issn = {2470-0045, 2470-0053},
  doi = {10.1103/PhysRevE.98.012215}
}

@article{Appeltant2011,
  title = {Information Processing Using a Single Dynamical Node as Complex System},
  author = {Appeltant, L. and Soriano, M.C. and {Van der Sande}, G. and Danckaert, J. and Massar, S. and Dambre, J. and Schrauwen, B. and Mirasso, C.R. and Fischer, I.},
  year = {2011},
  month = sep,
  journal = {Nat Commun},
  volume = {2},
  number = {1},
  pages = {468},
  issn = {2041-1723},
  doi = {10.1038/ncomms1476}
}

@article{Appeltant2014,
  title = {Constructing Optimized Binary Masks for Reservoir Computing with Delay Systems},
  author = {Appeltant, Lennert and {Van der Sande}, Guy and Danckaert, Jan and Fischer, Ingo},
  year = {2014},
  month = jan,
  journal = {Sci Rep},
  volume = {4},
  number = {1},
  pages = {3629},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep03629},
  copyright = {2014 The Author(s)},
  keywords = {Applied physics,Computational science}
}

@article{Argyris2018,
  title = {Photonic Machine Learning Implementation for Signal Recovery in Optical Communications},
  author = {Argyris, Apostolos and Bueno, Juli{\'a}n and Fischer, Ingo},
  year = {2018},
  month = may,
  journal = {Sci Rep},
  volume = {8},
  number = {1},
  pages = {8487},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-26927-y},
  copyright = {2018 The Author(s)},
  keywords = {Fibre optics and optical communications,Nonlinear optics,Semiconductor lasers}
}

@inproceedings{Bauduin2015,
  title = {Equalization of the {{Non-Linear Satellite Communication Channel}} with an {{Echo State Network}}},
  booktitle = {2015 {{IEEE}} 81st {{Vehicular Technology Conference}} ({{VTC Spring}})},
  author = {Bauduin, M. and Smerieri, A. and Massar, S. and Horlin, F.},
  year = {2015},
  month = may,
  pages = {1--5},
  issn = {1550-2252},
  doi = {10.1109/VTCSpring.2015.7145827},
  keywords = {Bit error rate,Complexity theory,Equalizers,Neurons,Satellite communication,Satellites,Training}
}

@article{Bengio1994,
  title = {Learning Long-Term Dependencies with Gradient Descent Is Difficult},
  author = {Bengio, Y. and Simard, P. and Frasconi, P.},
  year = {1994},
  month = mar,
  journal = {IEEE Trans Neural Netw},
  volume = {5},
  number = {2},
  pages = {157--166},
  issn = {1941-0093},
  doi = {10.1109/72.279181},
  keywords = {Computer networks,Cost function,Delay effects,Discrete transforms,Displays,Intelligent networks,Neural networks,Neurofeedback,Production,Recurrent neural networks}
}

@article{Bollt2021,
  title = {On Explaining the Surprising Success of Reservoir Computing Forecaster of Chaos? {{The}} Universal Machine Learning Dynamical System with Contrast to {{VAR}} and {{DMD}}},
  author = {Bollt, Erik},
  year = {2021},
  month = jan,
  journal = {Chaos},
  volume = {31},
  number = {1},
  pages = {013108},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/5.0024890}
}

@article{Borghi2021,
  title = {Reservoir Computing Based on a Silicon Microring and Time Multiplexing for Binary and Analog Operations},
  author = {Borghi, Massimo and Biasi, Stefano and Pavesi, Lorenzo},
  year = {2021},
  month = dec,
  journal = {Sci Rep},
  volume = {11},
  number = {1},
  pages = {15642},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-94952-5}
}

@article{Boyd1985,
  title = {Fading Memory and the Problem of Approximating Nonlinear Operators with {{Volterra}} Series},
  author = {Boyd, S. and Chua, L.},
  year = {1985},
  month = nov,
  journal = {IEEE Trans Circuits Syst},
  volume = {32},
  number = {11},
  pages = {1150--1161},
  issn = {1558-1276},
  doi = {10.1109/TCS.1985.1085649},
  keywords = {Control systems,Convolution,Fading,Fasteners,Mathematics,Nonlinear control systems,Nonlinear equations,Nonlinear systems,Operational amplifiers,Polynomials}
}

@article{Canaday2021,
  title = {Model-Free Control of Dynamical Systems with Deep Reservoir Computing},
  author = {Canaday, Daniel and Pomerance, Andrew and Gauthier, Daniel J.},
  year = {2021},
  month = sep,
  journal = {J Phys Complex},
  volume = {2},
  number = {3},
  pages = {035025},
  publisher = {{IOP Publishing}},
  issn = {2632-072X},
  doi = {10.1088/2632-072X/ac24f3}
}

@article{Mijalkov.2016, 
year = {2016}, 
rating = {0}, 
keywords = {interdisciplinary physics,soft matter}, 
title = {{Engineering sensorial delay to control phototaxis and emergent collective behaviors}}, 
author = {Mijalkov, Mite and McDaniel, Austin and Wehr, Jan and Volpe, Giovanni}, 
journal = {Phys Rev X}, 
issn = {21603308}, 
doi = {10.1103/physrevx.6.011008}, 
eprint = {1511.04528}, 
pages = {1---16}, 
number = {1}, 
volume = {6}
}


@article{Chen.2023, 
year = {2023}, 
title = {{Active particles with delayed attractions form quaking crystallites (a)}}, 
author = {Chen, Pin-Chuan and Kroy, Klaus and Cichos, Frank and Wang, Xiangzun and Holubec, Viktor}, 
journal = {EPL}, 
issn = {0295-5075}, 
doi = {10.1209/0295-5075/acd9ea}, 
abstract = {{Perception-reaction delays have experimentally been found to cause a spontaneous circling of microswimmers around a fixed target particle. Here we investigate a many-body version of such an experiment with Brownian-dynamics simulations of active particles in a plane. For short delays, they form a hexagonal crystallite around the target. The bifurcation to a chiral dynamical phase, seen for longer delays, maps onto that for a single active particle. Different angular velocities at different distances from the target induce shear stresses that grow with increasing delay. By exciting shear bands, they shake and intermittently break the rotating crystallite. For long delays, it detaches from the target to circle around it near the preferred single-particle orbit as a compact spinning satellite, trembling from what could be called tidal quakes.}}, 
pages = {67003}, 
number = {6}, 
volume = {142}, 
keywords = {}
}

@article{Cichos2020,
  title = {Machine Learning for Active Matter},
  author = {Cichos, Frank and Gustavsson, Kristian and Mehlig, Bernhard and Volpe, Giovanni},
  year = {2020},
  month = feb,
  journal = {Nat Mach Intel},
  volume = {2},
  number = {2},
  pages = {94--103},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-0146-9}
}

@article{Coulombe2017,
  title = {Computing with Networks of Nonlinear Mechanical Oscillators},
  shorttitle = {模拟,{{弹簧实现RC}}},
  author = {Coulombe, Jean C. and York, Mark C. A. and Sylvestre, Julien},
  editor = {Cymbalyuk, Gennady},
  year = {2017},
  month = jun,
  journal = {PLoS ONE},
  volume = {12},
  number = {6},
  pages = {e0178663},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0178663}
}

@article{Cucchi2022,
  title = {Hands-on Reservoir Computing: A Tutorial for Practical Implementation},
  shorttitle = {综述},
  author = {Cucchi, Matteo and Abreu, Steven and Ciccone, Giuseppe and Brunner, Daniel and Kleemann, Hans},
  year = {2022},
  month = sep,
  journal = {Neuromorph Comput Eng},
  volume = {2},
  number = {3},
  pages = {032002},
  issn = {2634-4386},
  doi = {10.1088/2634-4386/ac7db7}
}

@incollection{Dale2016,
  title = {Evolving {{Carbon Nanotube Reservoir Computers}}},
  booktitle = {Unconventional {{Computation}} and {{Natural Computation}}},
  author = {Dale, Matthew and Miller, Julian F. and Stepney, Susan and Trefzer, Martin A.},
  editor = {Amos, Martyn and Condon, Anne},
  year = {2016},
  volume = {9726},
  pages = {49--61},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-41312-9_5},
  isbn = {978-3-319-41311-2 978-3-319-41312-9}
}

@article{Dambre2012,
  title = {Information {{Processing Capacity}} of {{Dynamical Systems}}},
  shorttitle = {Dynamic系统计算能力},
  author = {Dambre, Joni and Verstraeten, David and Schrauwen, Benjamin and Massar, Serge},
  year = {2012},
  month = jul,
  journal = {Sci Rep},
  volume = {2},
  number = {1},
  pages = {514},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep00514},
  copyright = {2012 The Author(s)},
  keywords = {Evolutionary theory,Information theory and computation,Mathematics and computing,Statistical physics,thermodynamics and nonlinear dynamics}
}

@article{Dion2018,
  title = {Reservoir Computing with a Single Delay-Coupled Non-Linear Mechanical Oscillator},
  author = {Dion, Guillaume and Mejaouri, Salim and Sylvestre, Julien},
  year = {2018},
  month = oct,
  journal = {J Appl Phys},
  volume = {124},
  number = {15},
  pages = {152132},
  issn = {0021-8979, 1089-7550},
  doi = {10.1063/1.5038038}
}

@article{Dong2020,
  title = {Optical {{Reservoir Computing Using Multiple Light Scattering}} for {{Chaotic Systems Prediction}}},
  author = {Dong, Jonathan and Rafayelyan, Mushegh and Krzakala, Florent and Gigan, Sylvain},
  year = {2020},
  month = jan,
  journal = {IEEE J Sel Top Quantum Electron},
  volume = {26},
  number = {1},
  pages = {1--12},
  issn = {1558-4542},
  doi = {10.1109/JSTQE.2019.2936281},
  keywords = {Chaotic time series,Light scattering,Modulation,Network quantization,Optical computing,Optical Computing,Optical imaging,Optical neural networks,Optical scattering,Reservoir Computing,Reservoirs,Speckle}
}

@article{Duport2012,
  title = {All-Optical Reservoir Computing},
  author = {Duport, Fran{\c c}ois and Schneider, Bendix and Smerieri, Anteo and Haelterman, Marc and Massar, Serge},
  year = {2012},
  month = sep,
  journal = {Opt Express},
  volume = {20},
  number = {20},
  pages = {22783},
  issn = {1094-4087},
  doi = {10.1364/OE.20.022783}
}

@article{Estebanez2019,
  title = {Constructive {{Role}} of {{Noise}} for {{High-Quality Replication}} of {{Chaotic Attractor Dynamics Using}} a {{Hardware-Based Reservoir Computer}}},
  author = {Est{\'e}banez, Irene and Fischer, Ingo and Soriano, Miguel C.},
  year = {2019},
  month = sep,
  journal = {Phys Rev Appl},
  volume = {12},
  number = {3},
  pages = {034058},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevApplied.12.034058},
}

@article{Faisal2008,
  title = {Noise in the Nervous System},
  shorttitle = {综述，神经系统内噪音},
  author = {Faisal, A. Aldo and Selen, Luc P. J. and Wolpert, Daniel M.},
  year = {2008},
  month = apr,
  journal = {Nat Rev Neurosci},
  volume = {9},
  number = {4},
  pages = {292--303},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2258}
}

@incollection{Fernando2003,
  title = {Pattern {{Recognition}} in a {{Bucket}}},
  booktitle = {Advances in {{Artificial Life}}},
  author = {Fernando, Chrisantha and Sojakka, Sampsa},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and Banzhaf, Wolfgang and Ziegler, Jens and Christaller, Thomas and Dittrich, Peter and Kim, Jan T.},
  year = {2003},
  volume = {2801},
  pages = {588--597},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-39432-7_63},
  isbn = {978-3-540-20057-4 978-3-540-39432-7}
}

@article{Franzl2021,
  title = {Fully {{Steerable Symmetric Thermoplasmonic Microswimmers}}},
  author = {Fr{\"a}nzl, Martin and {Mui{\~n}os-Landin}, Santiago and Holubec, Viktor and Cichos, Frank},
  year = {2021},
  month = feb,
  journal = {ACS Nano},
  volume = {15},
  number = {2},
  pages = {3434--3440},
  issn = {1936-0851, 1936-086X},
  doi = {10.1021/acsnano.0c10598}
}

@article{Fujii2017,
  title = {Harnessing {{Disordered-Ensemble Quantum Dynamics}} for {{Machine Learning}}},
  author = {Fujii, Keisuke and Nakajima, Kohei},
  year = {2017},
  month = aug,
  journal = {Phys. Rev. Appl.},
  volume = {8},
  number = {2},
  pages = {024030},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevApplied.8.024030}
}

@article{Gal2017,
  title = {Rich Cell-Type-Specific Network Topology in Neocortical Microcircuitry},
  author = {Gal, Eyal and London, Michael and Globerson, Amir and Ramaswamy, Srikanth and Reimann, Michael W and Muller, Eilif and Markram, Henry and Segev, Idan},
  year = {2017},
  month = jul,
  journal = {Nat Neurosci},
  volume = {20},
  number = {7},
  pages = {1004--1013},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4576}
}

@article{Govia2021,
  title = {Quantum Reservoir Computing with a Single Nonlinear Oscillator},
  author = {Govia, L. C. G. and Ribeill, G. J. and Rowlands, G. E. and Krovi, H. K. and Ohki, T. A.},
  year = {2021},
  month = jan,
  journal = {Phys. Rev. Res.},
  volume = {3},
  number = {1},
  pages = {013077},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevResearch.3.013077}
}

@article{Guo2018,
  title = {Functional Importance of Noise in Neuronal Information Processing},
  author = {Guo, Daqing and Perc, Matja{\v z} and Liu, Tiejun and Yao, Dezhong},
  year = {2018},
  month = dec,
  journal = {EPL},
  volume = {124},
  number = {5},
  pages = {50001},
  issn = {1286-4854},
  doi = {10.1209/0295-5075/124/50001}
}

@article{Hartmann,
  title = {Real-{{Time Inverse Dynamics Learning}} for {{Musculoskeletal Robots Based}} on {{Echo State Gaussian Process Regression}}},
  author = {Hartmann, Christoph and Boedecker, Joschka and Obst, Oliver and Ikemoto, Shuhei and Asada, Minoru}
}

@article{Hauser2011,
  title = {Towards a Theoretical Foundation for Morphological Computation with Compliant Bodies},
  author = {Hauser, Helmut and Ijspeert, Auke J. and F{\"u}chslin, Rudolf M. and Pfeifer, Rolf and Maass, Wolfgang},
  year = {2011},
  month = dec,
  journal = {Biol Cybern},
  volume = {105},
  number = {5-6},
  pages = {355--370},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/s00422-012-0471-0}
}

@article{Jaeger2001,
author = {Jaeger, Herbert},
year = {2001},
month = {01},
pages = {},
title = {The "echo state" approach to analysing and training recurrent neural networks-with an erratum note'},
volume = {148},
journal = {Bonn, Germany: German National Research Center for Information Technology\\ GMD Technical Report}
}


@article{Woodhouse.2017, 
year = {2017}, 
rating = {5}, 
title = {{Active matter logic for autonomous microfluidics}}, 
author = {Woodhouse, Francis G. and Dunkel, Jörn}, 
journal = {Nat Comm}, 
doi = {10.1038/ncomms15169}, 
pmid = {28440273}, 
pmcid = {PMC5414041}, 
eprint = {1610.05515}, 
abstract = {{Chemically or optically powered active matter plays an increasingly important role in materials design, but its computational potential has yet to be explored systematically. The competition between energy consumption and dissipation imposes stringent physical constraints on the information transport in active flow networks, facilitating global optimization strategies that are not well understood. Here, we combine insights from recent microbial experiments with concepts from lattice-field theory and non-equilibrium statistical mechanics to introduce a generic theoretical framework for active matter logic. Highlighting conceptual differences with classical and quantum computation, we demonstrate how the inherent non-locality of incompressible active flow networks can be utilized to construct universal logical operations, Fredkin gates and memory storage in set–reset latches through the synchronized self-organization of many individual network components. Our work lays the conceptual foundation for developing autonomous microfluidic transport devices driven by bacterial fluids, active liquid crystals or chemically engineered motile colloids. Active fluids consist of self-driven particles that can drive spontaneous flow without the intervention of external forces. Here Woodhouseet al. show how to design logic circuits using this phenomenon in active fluid networks, which could be further exploited for autonomous microfluidic computing.}}, 
pages = {15169}, 
number = {1}, 
volume = {8}, 
keywords = {}
}

@article{Colen.2021, 
year = {2021}, 
title = {{Machine learning active-nematic hydrodynamics}}, 
author = {Colen, Jonathan and Han, Ming and Zhang, Rui and Redford, Steven A. and Lemma, Linnea M. and Morgan, Link and Ruijgrok, Paul V. and Adkins, Raymond and Bryant, Zev and Dogic, Zvonimir and Gardel, Margaret L. and Pablo, Juan J. de and Vitelli, Vincenzo}, 
journal = {Proc Natl Acad Sci USA}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.2016708118}, 
pmid = {33653956}, 
pmcid = {PMC7958379}, 
eprint = {2006.13203}, 
abstract = {{Hydrodynamic theories effectively describe many-body systems out of equilibrium in terms of a few macroscopic parameters. However, such parameters are difficult to determine from microscopic information. Seldom is this challenge more apparent than in active matter, where the hydrodynamic parameters are in fact fields that encode the distribution of energy-injecting microscopic components. Here, we use active nematics to demonstrate that neural networks can map out the spatiotemporal variation of multiple hydrodynamic parameters and forecast the chaotic dynamics of these systems. We analyze biofilament/molecular-motor experiments with microtubule/kinesin and actin/myosin complexes as computer vision problems. Our algorithms can determine how activity and elastic moduli change as a function of space and time, as well as adenosine triphosphate (ATP) or motor concentration. The only input needed is the orientation of the biofilaments and not the coupled velocity field which is harder to access in experiments. We can also forecast the evolution of these chaotic many-body systems solely from image sequences of their past using a combination of autoencoders and recurrent neural networks with residual architecture. In realistic experimental setups for which the initial conditions are not perfectly known, our physics-inspired machine-learning algorithms can surpass deterministic simulations. Our study paves the way for artificial-intelligence characterization and control of coupled chaotic fields in diverse physical and biological systems, even in the absence of knowledge of the underlying dynamics.}}, 
pages = {e2016708118}, 
number = {10}, 
volume = {118}, 
keywords = {}
}

@article{Knudsen.1987, 
year = {1987}, 
title = {{Computational Maps in the Brain}}, 
author = {Knudsen, E I and Lac, S and Esterly, S D}, 
journal = {Annu Rev Neurosci}, 
issn = {0147-006x}, 
doi = {10.1146/annurev.ne.10.030187.000353}, 
pmid = {3551761}, 
abstract = {{The nervous system performs computations to process information that is biologically important. Some of these computations occur in maps--arrays of neurons in which the tuning of neighboring neurons for a particular parameter value varies systematically. Computational maps transform the representation of information into a place-coded probability distribution that represents the computed values of parameters by sites of maximum relative activity. Numerous computational maps have been discovered, including visual maps of line orientation and direction of motion, auditory maps of amplitude spectrum and time interval, and motor maps of orienting movements. The construction of the auditory map of space is the most thoroughly understood: information about interaural delays and interaural intensity differences is processed in parallel by separate computational maps, and the outputs of these maps feed into a higher order processor that integrates sets of cues corresponding to sound source locations and creates a map of auditory space. Computational maps represent ranges of parameter values that are relevant to the animal, and may differentially magnify the representation of values that are of particular importance. The tuning of individual neurons for values of a mapped parameter is broad relative to the range of the map. Consequently, neurons throughout a large portion of a computational map are activated by any given stimulus, and precise information about the mapped parameter is coded by the locations of peak activity. There are a number of advantages of performing computations in maps. First, information is processed rapidly because the computations are preset and are executed in parallel. Second, maps simplify the schemes of connectivity required for processing and utilizing the information. Third, a common, mapped representation of the results of different kinds of computations allows the nervous system to employ a single strategy for reading the information. Finally, maps enable several classes of neuronal mechanisms to sharpen tuning in a manner not possible for information that is represented in a non-topographic code.}}, 
pages = {41--65}, 
number = {1}, 
volume = {10}, 
keywords = {}
}

@article{Wadhams2004, 
year = {2004}, 
title = {{Making sense of it all: bacterial chemotaxis}}, 
author = {Wadhams, George H. and Armitage, Judith P.}, 
journal = {Nat Rev Mol Cell Biol}, 
issn = {1471-0072}, 
doi = {10.1038/nrm1524}, 
pmid = {15573139}, 
abstract = {{Bacterial chemotaxis is the biasing of movement towards environments that contain higher concentrations of beneficial, or lower concentrations of toxic, chemicals. The signalling pathway that is involved has long been viewed as a paradigm of histidine–aspartate-phosphorelay signalling, and is one of the most well-understood physiological processes in biology.The pathway is composed of chemoreceptors, the histidine protein kinase chemotaxis protein (Che)A and two diffusable response regulators (CheY and CheB). CheY controls flagellar motor switching, whereas CheB controls chemoreceptor adaptation.The chemoreceptors and other proteins of the chemotaxis signalling pathway localize to specific regions of the cell as large higher-order arrays. This is thought to allow sensitivity and gain — cells can respond to a change of just a few molecules over background concentrations that can vary over five orders of magnitude.Biochemical, cellular-concentration and molecular-structure data for the various components of this pathway are available. These data have allowed various mathematical and computational models to be generated and tested.Many bacterial species have several chemosensory pathways, as well as further components that might be expressed under particular environmental conditions to allow bacteria to tune their responses to a specific environment.Chemotaxis is thought to be involved in pathogenicity, symbiosis, biofilm formation and stability, and in maintaining bacteria in their optimal environmental niche. The correct interplay between chemotaxis and other sensing systems is essential for bacterial survival in a changing environment. Bacterial chemotaxis is the biasing of movement towards environments that contain higher concentrations of beneficial, or lower concentrations of toxic, chemicals. The signalling pathway that is involved has long been viewed as a paradigm of histidine–aspartate-phosphorelay signalling, and is one of the most well-understood physiological processes in biology. The pathway is composed of chemoreceptors, the histidine protein kinase chemotaxis protein (Che)A and two diffusable response regulators (CheY and CheB). CheY controls flagellar motor switching, whereas CheB controls chemoreceptor adaptation. The chemoreceptors and other proteins of the chemotaxis signalling pathway localize to specific regions of the cell as large higher-order arrays. This is thought to allow sensitivity and gain — cells can respond to a change of just a few molecules over background concentrations that can vary over five orders of magnitude. Biochemical, cellular-concentration and molecular-structure data for the various components of this pathway are available. These data have allowed various mathematical and computational models to be generated and tested. Many bacterial species have several chemosensory pathways, as well as further components that might be expressed under particular environmental conditions to allow bacteria to tune their responses to a specific environment. Chemotaxis is thought to be involved in pathogenicity, symbiosis, biofilm formation and stability, and in maintaining bacteria in their optimal environmental niche. The correct interplay between chemotaxis and other sensing systems is essential for bacterial survival in a changing environment. Bacteria must be able to respond to a changing environment, and one way to respond is to move. The transduction of sensory signals alters the concentration of small phosphorylated response regulators that bind to the rotary flagellar motor and cause switching. This simple pathway has provided a paradigm for sensory systems in general. However, the increasing number of sequenced bacterial genomes shows that although the central sensory mechanism seems to be common to all bacteria, there is added complexity in a wide range of species.}}, 
pages = {1024--1037}, 
number = {12}, 
volume = {5}, 
keywords = {}
}

@article{Tkacik.2014, 
year = {2014}, 
title = {{Information Processing in Living Systems}}, 
author = {Tkačik, Gašper and Bialek, William}, 
journal = {Annu Rev Condens}, 
issn = {1947-5454}, 
doi = {10.1146/annurev-conmatphys-031214-014803}, 
abstract = {{Life depends as much on the flow of information as on the flow of energy. Here we review the many efforts to make this intuition precise. Starting with the building blocks of information theory, we explore examples where it has been possible to measure, directly, the flow of information in biological networks, or more generally where information-theoretic ideas have been used to guide the analysis of experiments. Systems of interest range from single molecules (the sequence diversity in families of proteins) to groups of organisms (the distribution of velocities in flocks of birds), and all scales in between. Many of these analyses are motivated by the idea that biological systems may have evolved to optimize the gathering and representation of information, and we review the experimental evidence for this optimization, again across a wide range of scales.Expected final online publication date for the Annual Review of Condensed Matter Physics Volume 7 is March 10, 2016. Please see http://www.annualreviews.org/catalog/pubdates.aspx for revised estimates.}}, 
pages = {1--29}, 
number = {1}, 
volume = {7}, 
keywords = {}
}

@article{Abiodun2018, 
year = {2018}, 
title = {{State-of-the-art in artificial neural network applications: A survey}}, 
author = {Abiodun, Oludare Isaac and Jantan, Aman and Omolara, Abiodun Esther and Dada, Kemi Victoria and Mohamed, Nachaat AbdElatif and Arshad, Humaira}, 
journal = {Heliyon}, 
issn = {2405-8440}, 
doi = {10.1016/j.heliyon.2018.e00938}, 
pmid = {30519653}, 
pmcid = {PMC6260436}, 
abstract = {{ This is a survey of neural network applications in the real-world scenario. It provides a taxonomy of artificial neural networks (ANNs) and furnish the reader with knowledge of current and emerging trends in ANN applications research and area of focus for researchers. Additionally, the study presents ANN application challenges, contributions, compare performances and critiques methods. The study covers many applications of ANN techniques in various disciplines which include computing, science, engineering, medicine, environmental, agriculture, mining, technology, climate, business, arts, and nanotechnology, etc. The study assesses ANN contributions, compare performances and critiques methods. The study found that neural-network models such as feedforward and feedback propagation artificial neural networks are performing better in its application to human problems. Therefore, we proposed feedforward and feedback propagation ANN models for research focus based on data analysis factors like accuracy, processing speed, latency, fault tolerance, volume, scalability, convergence, and performance. Moreover, we recommend that instead of applying a single method, future research can focus on combining ANN models into one network-wide application.}}, 
pages = {e00938}, 
number = {11}, 
volume = {4}, 
keywords = {}
}

@article{Verstraeten2007, 
year = {2007}, 
title = {{An experimental unification of reservoir computing methods}}, 
author = {Verstraeten, D. and Schrauwen, B. and D’Haene, M. and Stroobandt, D.}, 
journal = {Neural Netw}, 
issn = {0893-6080}, 
doi = {10.1016/j.neunet.2007.04.003}, 
pmid = {17517492}, 
abstract = {{Three different uses of a recurrent neural network (RNN) as a reservoir that is not trained but instead read out by a simple external classification layer have been described in the literature: Liquid State Machines (LSMs), Echo State Networks (ESNs) and the Backpropagation Decorrelation (BPDC) learning rule. Individual descriptions of these techniques exist, but a overview is still lacking. Here, we present a series of experimental results that compares all three implementations, and draw conclusions about the relation between a broad range of reservoir parameters and network dynamics, memory, node complexity and performance on a variety of benchmark tests with different characteristics. Next, we introduce a new measure for the reservoir dynamics based on Lyapunov exponents. Unlike previous measures in the literature, this measure is dependent on the dynamics of the reservoir in response to the inputs, and in the cases we tried, it indicates an optimal value for the global scaling of the weight matrix, irrespective of the standard measures. We also describe the Reservoir Computing Toolbox that was used for these experiments, which implements all the types of Reservoir Computing and allows the easy simulation of a wide range of reservoir topologies for a number of benchmarks.}}, 
pages = {391--403}, 
number = {3}, 
volume = {20}, 
keywords = {}
}

@article{Jaeger2004,
  title = {Harnessing {{Nonlinearity}}: {{Predicting Chaotic Systems}} and {{Saving Energy}} in {{Wireless Communication}}},
  author = {Jaeger, Herbert and Haas, Harald},
  year = {2004},
  month = apr,
  journal = {Science},
  volume = {304},
  number = {5667},
  pages = {78--80},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1091277}
}

@article{Jalalvand2018,
  title = {On the Application of Reservoir Computing Networks for Noisy Image Recognition},
  author = {Jalalvand, Azarakhsh and Demuynck, Kris and De Neve, Wesley and Martens, Jean-Pierre},
  year = {2018},
  month = feb,
  journal = {Neurocomputing},
  volume = {277},
  pages = {237--248},
  issn = {09252312},
  doi = {10.1016/j.neucom.2016.11.100},
  keywords = {Image classification,Image denoising,Recurrent neural networks,Reservoir computing networks,Text recognition}
}

@inproceedings{Jones2007,
  title = {Is There a {{Liquid State Machine}} in the {{Bacterium Escherichia Coli}}?},
  booktitle = {2007 {{IEEE Symposium}} on {{Artificial Life}}},
  author = {Jones, Ben and Stekel, Dov and Rowe, Jon and Fernando, Chrisantha},
  year = {2007},
  month = apr,
  pages = {187--191},
  publisher = {{IEEE}},
  address = {{Honolulu, HI, USA}},
  doi = {10.1109/ALIFE.2007.367795},
  isbn = {978-1-4244-0701-9}
}

@article{Jungling2018,
  title = {Consistency Properties of Chaotic Systems Driven by Time-Delayed Feedback},
  author = {J{\"u}ngling, T. and Soriano, M. C. and Oliver, N. and Porte, X. and Fischer, I.},
  year = {2018},
  month = apr,
  journal = {Phys Rev E},
  volume = {97},
  number = {4},
  pages = {042202},
  issn = {2470-0045, 2470-0053},
  doi = {10.1103/PhysRevE.97.042202}
}

@article{Jungling2022,
  title = {Consistency {{Hierarchy}} of {{Reservoir Computers}}},
  author = {J{\"u}ngling, Thomas and Lymburn, Thomas and Small, Michael},
  year = {2022},
  month = jun,
  journal = {IEEE Trans Neural Netw Learn},
  volume = {33},
  number = {6},
  pages = {2586--2595},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2021.3119548},
  keywords = {Australia,Complex networks,Computers,Correlation,Matrix decomposition,multivariate time series,Nonlinear dynamical systems,nonlinear dynamics,reservoir computing (RC),Reservoirs,Time series analysis}
}

@article{Keuninckx2017,
  title = {Real-Time {{Audio Processing}} with a {{Cascade}} of {{Discrete-Time Delay Line-Based Reservoir Computers}}},
  author = {Keuninckx, Lars and Danckaert, Jan and {Van der Sande}, Guy},
  year = {2017},
  month = jun,
  journal = {Cogn Comput},
  volume = {9},
  number = {3},
  pages = {315--326},
  issn = {1866-9964},
  doi = {10.1007/s12559-017-9457-5},
  keywords = {Audio,Black-box,Cascade,Real-time,Reservoir computing applications}
}

@article{Khadka2018,
  title = {Active Particles Bound by Information Flows},
  author = {Khadka, Utsab and Holubec, Viktor and Yang, Haw and Cichos, Frank},
  year = {2018},
  month = dec,
  journal = {Nat Commun},
  volume = {9},
  number = {1},
  pages = {3864},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-06445-1}
}

@incollection{Goldenfeld.2018, 
year = {2018}, 
title = {{Lectures on Phase Transitions and the Renormalization Group}}, 
author = {Goldenfeld, Nigel}, 
booktitle = {Anomalous Dimensions}, 
pages = {189--199}, 
keywords = {}, 
doi = {10.1201/9780429493492-7}
}

@article{Holubec.2019, 
year = {2019}, 
title = {{Physically consistent numerical solver for time-dependent Fokker-Planck equations}}, 
author = {Holubec, Viktor and Kroy, Klaus and Steffenoni, Stefano}, 
journal = {Phys Rev E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.99.032117}, 
pmid = {30999402}, 
eprint = {1804.01285}, 
abstract = {{We present a simple thermodynamically consistent method for solving time-dependent Fokker-Planck equations (FPE) for overdamped stochastic processes, also known as Smoluchowski equations. It yields both transition and steady-state behavior and allows for computations of moment-generating and large-deviation functions of observables defined along stochastic trajectories, such as the fluctuating particle current, heat, and work. The key strategy is to approximate the FPE by a master equation with transition rates in configuration space that obey a local detailed balance condition for arbitrary discretization. Its time-dependent solution is obtained by a direct computation of the time-ordered exponential, representing the propagator of the FPE, by summing over all possible paths in the discretized space. The method thus not only preserves positivity and normalization of the solutions but also yields a physically reasonable total entropy production, regardless of the discretization. To demonstrate the validity of the method and to exemplify its potential for applications, we compare it against Brownian-dynamics simulations of a heat engine based on an active Brownian particle trapped in a time-dependent quartic potential.}}, 
pages = {032117}, 
number = {3}, 
volume = {99}
}
@article{Larger2012,
  title = {Photonic Information Processing beyond {{Turing}}: An Optoelectronic Implementation of Reservoir Computing},
  author = {Larger, L. and Soriano, M. C. and Brunner, D. and Appeltant, L. and Gutierrez, J. M. and Pesquera, L. and Mirasso, C. R. and Fischer, I.},
  year = {2012},
  month = jan,
  journal = {Opt Express},
  volume = {20},
  number = {3},
  pages = {3241--3249},
  publisher = {{Optica Publishing Group}},
  issn = {1094-4087},
  doi = {10.1364/OE.20.003241},
  copyright = {\textcopyright{} 2012 OSA},
  keywords = {Computation methods,Diode lasers,Neural networks,Optical networks,Optical neural systems,Optical processing}
}

@article{Larger2017,
  title = {High-{{Speed Photonic Reservoir Computing Using}} a {{Time-Delay-Based Architecture}}: {{Million Words}} per {{Second Classification}}},
  author = {Larger, Laurent and {Bayl{\'o}n-Fuentes}, Antonio and Martinenghi, Romain and Udaltsov, Vladimir S. and Chembo, Yanne K. and Jacquot, Maxime},
  year = {2017},
  month = feb,
  journal = {Phys Rev X},
  volume = {7},
  number = {1},
  pages = {011015},
  issn = {2160-3308},
  doi = {10.1103/PhysRevX.7.011015}
}

@article{Lepri1994,
  title = {High-Dimensional Chaos in Delayed Dynamical Systems},
  author = {Lepri, S. and Giacomelli, G. and Politi, A. and Arecchi, F.T.},
  year = {1994},
  month = jan,
  journal = {Physica D: Nonlinear Phenomena},
  volume = {70},
  number = {3},
  pages = {235--249},
  issn = {01672789},
  doi = {10.1016/0167-2789(94)90016-7}
}

@article{Liao2021,
  title = {Echo State Network Activation Function Based on Bistable Stochastic Resonance},
  author = {Liao, Zhiqiang and Wang, Zeyu and Yamahara, Hiroyasu and Tabata, Hitoshi},
  year = {2021},
  month = dec,
  journal = {Chaos, Solitons \& Fractals},
  volume = {153},
  pages = {111503},
  issn = {0960-0779},
  doi = {10.1016/j.chaos.2021.111503},
  keywords = {Activation function,Echo state network,Noisy adaptability,Reservoir computing,Short-term memory,Stochastic resonance}
}

@article{Lopez-Caraballo2016,
  title = {Mackey-{{Glass}} Noisy Chaotic Time Series Prediction by a Swarm-Optimized Neural Network},
  author = {{L{\'o}pez-Caraballo}, C H and Salfate, I and Lazz{\'u}s, J A and Rojas, P and Rivera, M and {Palma-Chilla}, L},
  year = {2016},
  month = may,
  journal = {J Phys: Conf Ser},
  volume = {720},
  pages = {012002},
  issn = {1742-6588, 1742-6596},
  doi = {10.1088/1742-6596/720/1/012002}
}

@article{Lukosevicius2009,
  title = {Reservoir Computing Approaches to Recurrent Neural Network Training},
  author = {Luko{\v s}evi{\v c}ius, Mantas and Jaeger, Herbert},
  year = {2009},
  month = aug,
  journal = {Comput Sci Rev},
  volume = {3},
  number = {3},
  pages = {127--149},
  issn = {15740137},
  doi = {10.1016/j.cosrev.2009.03.005}
}

@incollection{Lukosevicius2012,
  title = {A {{Practical Guide}} to {{Applying Echo State Networks}}},
  booktitle = {Neural {{Networks}}: {{Tricks}} of the {{Trade}}},
  author = {Luko{\v s}evi{\v c}ius, Mantas},
  editor = {Montavon, Gr{\'e}goire and Orr, Genevi{\`e}ve B. and M{\"u}ller, Klaus-Robert},
  year = {2012},
  volume = {7700},
  pages = {659--686},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-35289-8_36},
  isbn = {978-3-642-35288-1 978-3-642-35289-8}
}

@article{Lymburn2019,
  title = {Consistency in Echo-State Networks},
  author = {Lymburn, Thomas and Khor, Alexander and Stemler, Thomas and Corr{\^e}a, D{\'e}bora C. and Small, Michael and J{\"u}ngling, Thomas},
  year = {2019},
  month = feb,
  journal = {Chaos},
  volume = {29},
  number = {2},
  pages = {023118},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/1.5079686}
}

@incollection{Lymburn2020,
  title = {Quantifying {{Robustness}} and {{Capacity}} of {{Reservoir Computers}} with {{Consistency Profiles}}},
  shorttitle = {Noise, Consistancy},
  booktitle = {Artificial {{Neural Networks}} and {{Machine Learning}} \textendash{} {{ICANN}} 2020},
  author = {Lymburn, Thomas and J{\"u}ngling, Thomas and Small, Michael},
  editor = {Farka{\v s}, Igor and Masulli, Paolo and Wermter, Stefan},
  year = {2020},
  volume = {12397},
  pages = {447--458},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-61616-8_36},
  isbn = {978-3-030-61615-1 978-3-030-61616-8}
}

@article{Lymburn2021,
  title = {Reservoir Computing with Swarms},
  author = {Lymburn, Thomas and Algar, Shannon D. and Small, Michael and J{\"u}ngling, Thomas},
  year = {2021},
  month = mar,
  journal = {Chaos},
  volume = {31},
  number = {3},
  pages = {033121},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/5.0039745}
}

@article{Maass2002,
  title = {Real-{{Time Computing Without Stable States}}: {{A New Framework}} for {{Neural Computation Based}} on {{Perturbations}}},
  author = {Maass, Wolfgang and Natschl{\"a}ger, Thomas and Markram, Henry},
  year = {2002},
  month = nov,
  journal = {Neural Computation},
  volume = {14},
  number = {11},
  pages = {2531--2560},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/089976602760407955}
}

@article{Maass2004,
  title = {Fading Memory and Kernel Properties of Generic Cortical Microcircuit Models},
  author = {Maass, Wolfgang and Natschl{\"a}ger, Thomas and Markram, Henry},
  year = {2004},
  month = jul,
  journal = {J Physiol Paris},
  volume = {98},
  number = {4-6},
  pages = {315--330},
  issn = {09284257},
  doi = {10.1016/j.jphysparis.2005.09.020},
}

@article{Mackey1977,
  title = {Oscillation and Chaos in Physiological Control Systems},
  author = {Mackey, M. C. and Glass, L.},
  year = {1977},
  month = jul,
  journal = {Science},
  volume = {197},
  number = {4300},
  pages = {287--289},
  issn = {0036-8075},
  doi = {10.1126/science.267326},
  pmid = {267326},
  keywords = {Cheyne-Stokes Respiration,Hematopoiesis,Leukemia; Myeloid,Models; Biological,Periodicity,Respiration}
}

@article{Matthews1993,
  title = {Approximating Nonlinear Fading-Memory Operators Using Neural Network Models},
  author = {Matthews, Michael B.},
  year = {1993},
  month = jun,
  journal = {Circuits, Syst Signal Process},
  volume = {12},
  number = {2},
  pages = {279--307},
  issn = {1531-5878},
  doi = {10.1007/BF01189878},
  keywords = {Continuous Function,Internal Representation,Network Model,Neural Network,Neural Network Model}
}

@article{Nakajima2019,
  title = {Boosting {{Computational Power}} through {{Spatial Multiplexing}} in {{Quantum Reservoir Computing}}},
  author = {Nakajima, Kohei and Fujii, Keisuke and Negoro, Makoto and Mitarai, Kosuke and Kitagawa, Masahiro},
  year = {2019},
  month = mar,
  journal = {Phys Rev Appl},
  volume = {11},
  number = {3},
  pages = {034021},
  issn = {2331-7019},
  doi = {10.1103/PhysRevApplied.11.034021}
}

@article{Nakajima2020,
  title = {Physical Reservoir Computing\textemdash an Introductory Perspective},
  shorttitle = {综述},
  author = {Nakajima, Kohei},
  year = {2020},
  month = jun,
  journal = {Jpn J Appl Phys},
  volume = {59},
  number = {6},
  pages = {060501},
  issn = {0021-4922, 1347-4065},
  doi = {10.35848/1347-4065/ab8d4f}
}

@article{Nakajima2021,
  title = {Scalable Reservoir Computing on Coherent Linear Photonic Processor},
  author = {Nakajima, Mitsumasa and Tanaka, Kenji and Hashimoto, Toshikazu},
  year = {2021},
  month = feb,
  journal = {Commun Phys},
  volume = {4},
  number = {1},
  pages = {1--12},
  publisher = {{Nature Publishing Group}},
  issn = {2399-3650},
  doi = {10.1038/s42005-021-00519-1},
  copyright = {2021 The Author(s)},
  keywords = {Information theory and computation,Integrated optics,Optoelectronic devices and components}
}


@article{Paquot.2010, 
year = {2010}, 
title = {{Reservoir computing: a photonic neural network for information processing}}, 
author = {Paquot, Yvan and Dambre, Joni and Schrauwen, Benjamin and Haelterman, Marc and Massar, Serge}, 
journal = {Nonlinear Optics and Applications IV}, 
issn = {0277-786X}, 
doi = {10.1117/12.854050}, 
pages = {77280B--77280B-12}, 
keywords = {}
}

@article{Paquot2012,
  title = {Optoelectronic {{Reservoir Computing}}},
  author = {Paquot, Y. and Duport, F. and Smerieri, A. and Dambre, J. and Schrauwen, B. and Haelterman, M. and Massar, S.},
  year = {2012},
  month = dec,
  journal = {Sci Rep},
  volume = {2},
  number = {1},
  pages = {287},
  issn = {2045-2322},
  doi = {10.1038/srep00287},
  keywords = {Applied physics,Information theory and computation,Nonlinear optics,Optical physics}
}

@article{Pathak2018,
  title = {Model-{{Free Prediction}} of {{Large Spatiotemporally Chaotic Systems}} from {{Data}}: {{A Reservoir Computing Approach}}},
  author = {Pathak, Jaideep and Hunt, Brian and Girvan, Michelle and Lu, Zhixin and Ott, Edward},
  year = {2018},
  month = jan,
  journal = {Phys Rev Lett},
  volume = {120},
  number = {2},
  pages = {024102},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.120.024102}
}

@article{Qian2013,
  title = {Harnessing Thermal Fluctuations for Purposeful Activities: The Manipulation of Single Micro-Swimmers by Adaptive Photon Nudging},
  author = {Qian, Bian and Montiel, Daniel and Bregulla, Andreas and Cichos, Frank and Yang, Haw},
  year = {2013},
  month = mar,
  journal = {Chem Sci},
  volume = {4},
  number = {4},
  pages = {1420--1429},
  publisher = {{The Royal Society of Chemistry}},
  issn = {2041-6539},
  doi = {10.1039/C2SC21263C}
}

@article{Rodan2011,
  title = {Minimum {{Complexity Echo State Network}}},
  author = {Rodan, A and Tino, P},
  year = {2011},
  month = jan,
  journal = {IEEE Trans Neural Netw},
  volume = {22},
  number = {1},
  pages = {131--144},
  issn = {1045-9227, 1941-0093},
  doi = {10.1109/TNN.2010.2089641},
  keywords = {delay line reservoir}
}

@article{Rohm2018,
  title = {Multiplexed Networks: Reservoir Computing with Virtual and Real Nodes},
  author = {R{\"o}hm, Andr{\'e} and L{\"u}dge, Kathy},
  year = {2018},
  month = aug,
  journal = {J Phys Commun},
  volume = {2},
  number = {8},
  pages = {085007},
  issn = {2399-6528},
  doi = {10.1088/2399-6528/aad56d}
}

@article{Savin2005,
  title = {Static and {{Dynamic Errors}} in {{Particle Tracking Microrheology}}},
  author = {Savin, Thierry and Doyle, Patrick S.},
  year = {2005},
  month = jan,
  journal = {Biophys J},
  volume = {88},
  number = {1},
  pages = {623--638},
  issn = {00063495},
  doi = {10.1529/biophysj.104.042457}
}

@incollection{Schumacher2015,
  title = {An {{Introduction}} to {{Delay-Coupled Reservoir Computing}}},
  booktitle = {Artificial {{Neural Networks}}},
  author = {Schumacher, Johannes and Toutounji, Hazem and Pipa, Gordon},
  editor = {{Koprinkova-Hristova}, Petia and Mladenov, Valeri and Kasabov, Nikola K.},
  year = {2015},
  volume = {4},
  pages = {63--90},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-09903-3_4},
  isbn = {978-3-319-09902-6 978-3-319-09903-3}
}

@article{Shougat2021,
  title = {A {{Hopf}} Physical Reservoir Computer},
  author = {Shougat, Md Raf E. Ul and Li, XiaoFu and Mollik, Tushar and Perkins, Edmon},
  year = {2021},
  month = sep,
  journal = {Sci Rep},
  volume = {11},
  number = {1},
  pages = {19465},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-98982-x},
  copyright = {2021 The Author(s)},
  keywords = {Engineering,Mathematics and computing,Mechanical engineering}
}

@article{Soriano2013,
  title = {Optoelectronic Reservoir Computing: Tackling Noise-Induced Performance Degradation},
  author = {Soriano, M. C. and Ort{\'i}n, S. and Brunner, D. and Larger, L. and Mirasso, C. R. and Fischer, I. and Pesquera, L.},
  year = {2013},
  month = jan,
  journal = {Opt Express},
  volume = {21},
  number = {1},
  pages = {12},
  issn = {1094-4087},
  doi = {10.1364/OE.21.000012}
}

@article{Stein2005,
  title = {Neuronal Variability: Noise or Part of the Signal?},
  shorttitle = {Neuronal Variability},
  author = {Stein, Richard B. and Gossen, E. Roderich and Jones, Kelvin E.},
  year = {2005},
  month = may,
  journal = {Nat Rev Neurosci},
  volume = {6},
  number = {5},
  pages = {389--397},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn1668}
}

@article{Sussillo2009,
  title = {Generating {{Coherent Patterns}} of {{Activity}} from {{Chaotic Neural Networks}}},
  author = {Sussillo, David and Abbott, L.F.},
  year = {2009},
  month = aug,
  journal = {Neuron},
  volume = {63},
  number = {4},
  pages = {544--557},
  issn = {08966273},
  doi = {10.1016/j.neuron.2009.07.018}
}

@article{Tanaka2019,
  title = {Recent Advances in Physical Reservoir Computing: {{A}} Review},
  shorttitle = {综述},
  author = {Tanaka, Gouhei and Yamane, Toshiyuki and H{\'e}roux, Jean Benoit and Nakane, Ryosho and Kanazawa, Naoki and Takeda, Seiji and Numata, Hidetoshi and Nakano, Daiju and Hirose, Akira},
  year = {2019},
  month = jul,
  journal = {Neural Netw},
  volume = {115},
  pages = {100--123},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.03.005}
}

@article{Tong2007,
  title = {Learning Grammatical Structure with {{Echo State Networks}}},
  author = {Tong, Matthew H. and Bickett, Adam D. and Christiansen, Eric M. and Cottrell, Garrison W.},
  year = {2007},
  month = apr,
  journal = {Neural Netw},
  volume = {20},
  number = {3},
  pages = {424--432},
  issn = {08936080},
  doi = {10.1016/j.neunet.2007.04.013}
}

@article{Torrejon2017,
  title = {Neuromorphic Computing with Nanoscale Spintronic Oscillators},
  author = {Torrejon, Jacob and Riou, Mathieu and Araujo, Flavio Abreu and Tsunegi, Sumito and Khalsa, Guru and Querlioz, Damien and Bortolotti, Paolo and Cros, Vincent and Yakushiji, Kay and Fukushima, Akio and Kubota, Hitoshi and Yuasa, Shinji and Stiles, Mark D. and Grollier, Julie},
  year = {2017},
  month = jul,
  journal = {Nature},
  volume = {547},
  number = {7664},
  pages = {428--431},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature23011}
}

@article{Tsimring2014,
  title = {Noise in Biology},
  author = {Tsimring, Lev S},
  year = {2014},
  month = feb,
  journal = {Rep Prog Phys},
  volume = {77},
  number = {2},
  pages = {026601},
  issn = {0034-4885, 1361-6633},
  doi = {10.1088/0034-4885/77/2/026601}
}

@article{VanDerSande2017,
  title = {Advances in Photonic Reservoir Computing},
  author = {{Van der Sande}, Guy and Brunner, Daniel and Soriano, Miguel C.},
  year = {2017},
  month = may,
  journal = {Nanophotonics},
  volume = {6},
  number = {3},
  pages = {561--576},
  issn = {2192-8614, 2192-8606},
  doi = {10.1515/nanoph-2016-0132}
}

@article{Wang2023,
  title = {Spontaneous Vortex Formation by Microswimmers with Retarded Attractions},
  author = {Wang, Xiangzun and Chen, Pin-Chuan and Kroy, Klaus and Holubec, Viktor and Cichos, Frank},
  year = {2023},
  month = jan,
  journal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {56},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-35427-7},
  copyright = {2023 The Author(s)},
  keywords = {Colloids,Phase transitions and critical phenomena,Statistical physics}
}

@article{Wu.2021, 
year = {2021}, 
title = {{Improved Reservoir Computing by Carbon Nanotube Network with Polyoxometalate Decoration}}, 
author = {Wu, Shuo and Zhou, Wenli and Wen, Kaiqiang and Li, Chengzhu and Gong, Qingfeng}, 
journal = {2021 IEEE 16th International Conference on Nano/Micro Engineered and Molecular Systems (NEMS)}, 
doi = {10.1109/nems51815.2021.9451290}, 
abstract = {{Physical reservoir computing (RC) is a recently introduced framework for information processing using the complex dynamics of physical systems. In this paper, a physical reservoir based on a molecular network of polyoxometalate (POM) decorated single-walled carbon nanotubes (SWCNT) with PBMA composite is fabricated. By the lab-built hardware platform, we experimentally demonstrate its excellent performance in a time series prediction benchmark with large short-term memory capacity (MC), indicating SWCNT/POM network as a promising substrate for reservoir computing because abundant inner charge and discharge in junctions leading to special electron transport characteristics that make rich dynamic and high-dimensional mapping properties appear in the POM-decorated SWCNT composite structure.}}, 
pages = {994--997}, 
volume = {00}, 
keywords = {}
}


@article{Baeuerle.2020, 
year = {2020}, 
rating = {0}, 
title = {{Formation of stable and responsive collective states in suspensions of active colloids}}, 
author = {B\"auerle, Tobias and L\"offler, Robert C. and Bechinger, Clemens}, 
journal = {Nat Comm}, 
doi = {10.1038/s41467-020-16161-4}, 
pmid = {32439919}, 
pmcid = {PMC7242396}, 
abstract = {{Many animal species organise into disordered swarms, polarised flocks or swirls to protect from predators or optimise foraging. Previous studies suggest that such collective states are related to a critical point, which could explain their balance between robustness to noise and high responsiveness regarding external perturbations. Here we provide experimental evidence for this idea by investigating the stability of swirls formed by light-responsive active colloids which adjust their individual motion to positions and orientations of neighbours. Because their behaviour can be precisely tuned, controlled changes between different collective states can be achieved. During the transition between stable swirls and swarms we observe a maximum of the group’s susceptibility indicating the vicinity of a critical point. Our results support the idea of system-independent organisation principles of collective states and provide useful strategies for the realisation of responsive yet stable ensembles in microrobotic systems. Living organisms, like fish and bacteria, frequently change their pattern as a group to cope with environment. Here, Bäuerle et al. reproduce this phenomenon using a synthetic system of controllably interactive colloids to show their collective motions that indicates being close to a critical point.}}, 
pages = {2547}, 
number = {1}, 
volume = {11}, 
language = {English}, 
keywords = {}, 
month = {05}
}
@article{Lavergne.2019, 
year = {2019}, 
title = {{Group formation and cohesion of active particles with visual perception–dependent motility}}, 
author = {Lavergne, François A. and Wendehenne, Hugo and Bäuerle, Tobias and Bechinger, Clemens}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.aau5347}, 
pmid = {30948548}, 
abstract = {{Group formation in living systems typically results from a delicate balance of repulsive, aligning, and attractive interactions. We found that a mere motility change of the individuals in response to the visual perception of their peers induces group formation and cohesion. We tested this principle in a real system of active particles whose motilities are controlled by an external feedback loop. For narrow fields of view, individuals gathered into cohesive nonpolarized groups without requiring active reorientations. For wider fields of view, cohesion could be achieved by lowering the response threshold. We expect this motility-induced cohesion mechanism to be relevant not only for the self-organization of living systems, but also for the design of robust and scalable autonomous systems.}}, 
pages = {70--74}, 
number = {6435}, 
volume = {364}, 
keywords = {}
}

@article{Bechinger.2016fj9, 
year = {2016}, 
rating = {5}, 
title = {{Active particles in complex and crowded environments}}, 
author = {Bechinger, Clemens and {Di Leonardo}, Roberto  and Löwen, Hartmut and Reichhardt, Charles and Volpe, Giorgio and Volpe, Giovanni}, 
journal = {Rev Mod Phys}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.88.045006}, 
eprint = {1602.00081},
abstract = {{Differently from passive Brownian particles, active particles, also known as self-propelled Brownian particles or microswimmers and nanoswimmers, are capable of taking up energy from their environment and converting it into directed motion. Because of this constant flow of energy, their behavior can be explained and understood only within the framework of nonequilibrium physics. In the biological realm, many cells perform directed motion, for example, as a way to browse for nutrients or to avoid toxins. Inspired by these motile microorganisms, researchers have been developing artificial particles that feature similar swimming behaviors based on different mechanisms. These man-made micromachines and nanomachines hold a great potential as autonomous agents for health care, sustainability, and security applications. With a focus on the basic physical features of the interactions of self-propelled Brownian particles with a crowded and complex environment, this comprehensive review will provide a guided tour through its basic principles, the development of artificial self-propelling microparticles and nanoparticles, and their application to the study of nonequilibrium phenomena, as well as the open challenges that the field is currently facing.}}, 
pages = {045006}, 
number = {4}, 
volume = {88}, 
keywords = {}, 
month = {11}
}

@article{Yildiz2012,
  title = {Re-Visiting the Echo State Property},
  author = {Yildiz, Izzet B. and Jaeger, Herbert and Kiebel, Stefan J.},
  year = {2012},
  month = nov,
  journal = {Neural Netw},
  volume = {35},
  pages = {1--9},
  issn = {08936080},
  doi = {10.1016/j.neunet.2012.07.005}
}
