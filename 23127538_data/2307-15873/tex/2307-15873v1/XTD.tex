%% This is file `elsarticle-template-1-num.tex',
%%
%% Copyright 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%%
%% $Id: elsarticle-template-1-num.tex 149 2009-10-08 05:01:15Z rishi $
%% $URL: http://lenova.river-valley.com/svn/elsbst/trunk/elsarticle-template-1-num.tex $
%%
\documentclass[preprint,3p,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% The graphicx package provides the includegraphics command.
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{calc}
\usepackage{subfigure}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{comment}
\usepackage{ulem}


\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%\usepackage{lineno}


\newcommand{\adding}[1]{{\textcolor{blue}{\textbf{{#1}}}}}
\newcommand{\moving}[1]{{\textcolor{red}{\textbf{\sout{#1}}}}}

\newcommand{\X}{\textbf{X}}
\newcommand{\ud}{\textbf{u}}
\newcommand{\eps}{\boldsymbol{\varepsilon}}
\newcommand{\epse}{\boldsymbol{{\varepsilon}}_{e}}
\newcommand{\epsp}{\boldsymbol{{\varepsilon}}_{p}}
\newcommand{\epst}{\boldsymbol{{\varepsilon}}_{\theta}}
\newcommand{\sig}{\boldsymbol{\sigma}}
\newcommand{\Bm}{\textbf{B}}
\newcommand{\Fm}{\textbf{F}}



%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
%% \biboptions{comma,round}

% \biboptions{}

\journal{Elsevier}
\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % set the Output

\graphicspath{{img/}}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

  \title{Extended tensor decomposition model reduction methods: training, prediction, and design under uncertainty}

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}


%% use optional labels to link authors explicitly to addresses:
  \author[label2]{Ye Lu\corref{cor1}}
  \cortext[cor1]{Corresponding author}
%  \ead{yeluu90@gmail.com}
  \ead{yelu@umbc.edu}
  \author[label3]{Satyajit Mojumder}
  \author[label3]{Jiachen Guo}
  \author[label1]{Yangfan Li}
  \author[label1]{Wing Kam Liu\corref{cor1}}
  \ead{w-liu@northwestern.edu}

 \address[label2]{Department of Mechanical Engineering, University of Maryland Baltimore County, Baltimore, USA}
 \address[label3]{Theoretical and Applied Mechanics Program, Northwestern
University, Evanston, USA}
  \address[label1]{Department of Mechanical Engineering, Northwestern
University, Evanston, USA}


  
  
%\address{California, United States}

  \begin{abstract}
  This paper introduces an extended tensor decomposition (XTD) method for model reduction. The proposed method is based on a sparse non-separated enrichment to the conventional tensor decomposition, which is expected to improve the approximation accuracy and the reducibility (compressibility) in highly nonlinear and singular cases. The proposed XTD method can be a powerful tool for solving nonlinear space-time parametric problems. The method has been successfully applied to parametric elastic-plastic problems and real time additive manufacturing residual stress predictions with uncertainty quantification. Furthermore, a combined XTD-SCA (self-consistent clustering analysis) strategy has been presented for multi-scale material modeling, which enables real time multi-scale multi-parametric simulations. The efficiency of the method is demonstrated with comparison to finite element analysis. The proposed method enables a novel framework for fast manufacturing and material design with uncertainties.  
  
  \end{abstract}

\begin{keyword}
nonlinear model reduction \sep extended tensor decomposition   \sep additive manufacturing \sep multi-scale  modeling \sep  XTD-SCA
%% keywords here, in the form: keyword \sep keyword

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%%
%% Start line numbering here if you want
%%
%\linenumbers

\newcommand{\revision}[2]{\sout{#1} \textcolor{red}{(#2)}}

%% main text
\section{Introduction}
Simulation-based engineering and science, including design and uncertainty quantification, usually necessitate fast responses of numerical models. Despite the significant improvement of the computer hardware over the last decades, real-time simulations of large-scale systems are still intractable with conventional finite element analysis (FEA). The repetitive evaluation of the numerical model using FEA makes the design process computationally prohibitive. Furthermore,  this kind of problem can involve solutions in a large-scale space-time-parameter domain, which challenges the metamodeling or surrogate modeling approaches \cite{wang2007review} that succeeded in relatively small size problems. For example, the design of additive manufacturing processes can involve a large number of parameters related to the process and materials, such as the input heat source power, laser beam size, scan velocity,  material absorptivity, powder size and properties. Optimizing the design parameters demands space-time simulations of the process for different parameter combinations and thus the space-time-parametric solutions. Due to the computational expense of the space-time process simulation, the  metamodeling methods for this design problem require the development of powerful sampling methods for the space-time-parameter domain, which seems still an open question.

Exploring efficient space-time-parametric solution strategies has been one major task in the active area of model order reduction (or model reduction  for short). The model reduction was originated for the purpose of reducing the computational cost of numerical simulations in physical space-time domains, by reducing the degrees of freedom of underlying numerical systems. Self-consistent clustering analysis (SCA) \cite{liu2016self,yu2021multiresolution}, proper orthogonal decomposition (POD) \cite{willcox2002balanced,goury2016automatised,kerfriden2011bridging,lu2018space}, hyper reduction \cite{ryckelynck2009hyper,carlberg2013gnat,zhang2017efficient,lu2020adaptive}, and space-time LATIN proper generalized decomposition (PGD) \cite{ladeveze2010latin,boucinha2014ideal,giacoma2016efficient} are some of the most successful approaches in terms of space-time computation acceleration. For accelerating the computation of parametric solutions, the PGD method has been extended to consider the parameters as extra-coordinates of solutions \cite{ammar2006new,chinesta2011short,chinesta2013pgd} and decompose them like space and time in the approximation. This leads to a new definition of PGD and provides an attractive way to compute space-time-parametric solutions. Specifically, the basic idea is to decompose the multidimensional space-time-parametric solution into several separated 1D functions  and thus reduce the complexity of solving the multi-dimensional problem. However, it seems difficult to apply this method to nonlinear  problems, like plasticity and additive manufacturing. Differently, the so-called LATIN-PGD \cite{relun2013model,heyberger2012multiparametric,ladeveze2018extended} has also been extended for parametric studies, which relies on the LATIN solver \cite{ladeveze2010latin} with a point-wise evaluation of parameters. The method has shown the efficiency for some parametric elastic-plastic problems, thanks to the non-incremental nature of the space-time LATIN solver. In the context of additive manufacturing or other welding-like processes, the nonlinear parametric model reduction becomes even more challenging, especially in terms of problem reducibility. This has motivated the development of the non-intrusive data-driven PGD methods, i.e. high order PGD (HOPGD) \cite{lu2018multi,modesto2015proper} and its sparse counterpart \cite{lu2018adaptive,lu2019datadriven}. The HOPGD can be used for data learning (regression) and compression and has a direct connection to machine learning techniques. 

Machine learning has shown its superior performance in regression, especially for  complex discrete data. The universal approximation theorem \cite{hornik1989multilayer} and the natural scalability of deep learning neural networks have motivated the application to the function approximation for large systems. Many attempts were made to construct  machine learning based surrogate models for fast  space-time-parametric predictions (see e.g. \cite{lu2019data}). However, purely data-driven machine learning needs a huge amount of data that sometimes are not easy to obtain. To alleviate the need of data, the physics-informed type neural networks \cite{raissi2019physics} is proposed by incorporating the physically based governing equations into  the machine learning loss functions. \cite{liu2019deep} proposed to train a deep material network for nonlinear response predictions by using only elastic response data.  More recently, the Hierarchical Deep-learning Neural Network (HiDeNN) method \cite{zhang2021hierarchical,saha2021hierarchical}
 is developed by constraining the weights and biases of DNN to mesh coordinates to build multiple dimensions shape functions for FEA. The method allowed the automatic mesh adaptivity and showed good potential to prevent large numerical systems. Nevertheless, the machine learning-based methods can still suffer from the significant training cost. A solution to reduce the cost is combining the machine learning with model reduction methods. As demonstrated by \cite{zhang2021hidenn}, the coupled HiDeNN-PGD method shows a significant improvement in terms of both efficiency and accuracy by taking advantages of the HiDeNN and PGD methods, compared to conventional FEA. From a general point of view, the synergy of machine learning and model reduction can give rise to a new type of reduced-order machine learning method and opens very interesting opportunities in computational science and engineering. The development of efficient nonlinear parametric model reduction methods is crucial to enable a wider application of such methods.

This work proposes a model reduction method, the so-called extended tensor decomposition (XTD), that provides a new way to solve nonlinear space-time-parametric problems. The XTD stands for a tensor decomposition with a sparse non-separated enrichment. The motivation is that the conventional tensor decomposition may require a strong assumption on the smoothness or the separability of the approximated functions, which can be violated in highly nonlinear or singular cases, thus the enrichment is expected to improve the approximation accuracy and the reducibility. The sparsity of the enrichment is to ensure the localization of the enrichment and minimize the associated computational cost.   Like other model reduction methods, the XTD can be computed from either numerical models or data. If the data is provided, the XTD can be used as a regression (or compression) method. Otherwise, the XTD can perform a reduced-order modeling with the governing equations. In any cases, the overall XTD framework follows a general offline-online strategy, in which the training is performed offline for a large space-time-parameter domain so that the online prediction is real time. The proposed method has been applied to solve nonlinear elastic-plastic problems by performing reduced-order modeling. Different challenging applications, including additive manufacturing type thermal residual stress and multi-scale composite modeling enabled by a coupled XTD-SCA approach, will be presented. It is found that the XTD method shows a good performance in terms of efficiency and accuracy, especially for large scale problems. 

This paper is organized as follows. Section 2 presents the overall offline-online XTD framework. Section 3 presents the formulation of the problem and the XTD solution strategy. Section 4 presents the numerical examples concerning additive manufacturing and XTD-SCA based multi-scale material modeling. Finally, the paper closes with some concluding remarks.

\section{General offline-online XTD learning framework}
\subsection{Extended tensor decomposition}
Let us consider a general  multidimensional space-time-parametric function. 
\begin{equation}
\displaystyle
\label{eq:XTD0} \ud(\X, t,{\mu_1},\dots,\mu_n)
\end{equation}
where $\X$, $t$ are the usual space and time variables. $\mu_i|_{i=1,\dots,n}$ denote general parameters for a given problem. Thus, this function can represent any quantity of interest of engineering problems, which is varying in a space-time-parameter domain. Now, we can consider a discrete representation of the above function using a high order array,
\begin{equation}
\displaystyle
\label{eq:XTDdisc} \boldsymbol{\mathcal{U}}\in \mathbb{R}^{{N_\X}\times{N_t}\times{N_{\mu_1}}\times\cdots\times{N_{\mu_n}}}
\end{equation}
with $N_\X$ denotes the total number degrees of freedom in the discretized physical domain, $N_{t}$ is the number of time steps, 
$N_{\mu_i}$ is the number of discrete points for the parameter $\mu_i$. This array can also be considered as a tensor of order $2+n$ (see e.g. \cite{kolda2009tensor}). Then, we define the following decomposition as the eXtended Tensor Decomposition (XTD).
\begin{equation}
\displaystyle
\label{eq:XTDdef} \boldsymbol{\mathcal{U}}\approx\sum_{m=1}^{M}
\boldsymbol{\mathcal{A}}^{(m)}\otimes \boldsymbol{T}^{(m)}\otimes\boldsymbol{g}_1^{(m)}\otimes\cdots\otimes\boldsymbol{g}_n^{(m)}+\sum_{k=1}^{K}\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}
\end{equation}
where $\boldsymbol{\mathcal{A}}^{(m)}\in\mathbb{R}^{N_\X}$, $\boldsymbol{T}^{(m)}\in\mathbb{R}^{N_t}$, $\boldsymbol{g}_i^{(m)}\in\mathbb{R}^{N_{\mu_i}}$ are vectors, $\otimes$ denotes the vector outer product. $\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}$ is a sparse array which has the same order as the original $\boldsymbol{\mathcal{U}}$. $M$ and $K$ are the numbers of modes. It is known that the first part of equation \eqref{eq:XTDdef} is called canonical tensor decomposition (Generally, it can be any other tensor decomposition format like Tucker  decomposition). The $\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}$ appear as an enrichment, which is expected to remove the singularity or the high non-linearity from the original function (i.e. multidimensional array). We assume that the singularity only appears for a certain part of the original function. Therefore, the enrichment array is sparse. Ideally, the enrichment should improve the reducibility of the first-part tensor decomposition and also the overall approximation accuracy. 

Come back to the continuous representation, the XTD can be written as \begin{equation}
\displaystyle
\label{eq:XTDdefcontinu}
\ud\approx \underbrace{\sum_{m=1}^{M}\boldsymbol{a}^{(m)}(\X)T^{(m)}(t)g_1^{(m)}(\mu_1)\cdots g_n^{(m)}(\mu_n) + \sum_{k=1}^{K}\Tilde{\boldsymbol{a}}^{(k)}(\X,t, {\mu_1},\dots,\mu_n)}_{\ud^{\text{XTD}}}
\end{equation}
where $\boldsymbol{a}^{(m)} (\X),T^{(m)}(t), g_i^{(m)}(\mu_i)$ are separated functions. The enrichment  $\Tilde{\boldsymbol{a}}^{(k)}(\X,{\mu_1},\dots,\mu_n)$ equals zero except for  selected local regions in the space-time-parameter domain.

It should be noticed that equations \eqref{eq:XTDdef} and \eqref{eq:XTDdefcontinu} only define the format of the XTD, in which all the terms are a priori unknown. They should be obtained from a training stage which will be described in the following.

\subsection{Offline training}
The XTD model can be trained either from data or directly from the physical governing equation for a given problem. The general training equation reads then
\begin{equation}
\displaystyle
\label{eq:XTDtraining}
\mathcal{L}(\ud^{\text{XTD}}(\X,t,{\mu_1},\dots,\mu_n))=0
\end{equation}
If the data of $\ud$ is provided, the above equation becomes
\begin{equation}
\displaystyle
\label{eq:XTDdata}
\int_{\Omega}(\delta\ud^{\text{XTD}})^T(\ud-\ud^{\text{XTD}})\ d\X\ dt\ d\mu_1\cdots d\mu_{n}=0
\end{equation}
where $\Omega$ stands for the general space-time-parameter domain.

Otherwise, we can consider $\mathcal{L}$ as a general differential operator, which represents the governing equation of a given problem. 

The solution strategy for solving equation \eqref{eq:XTDdata} is presented in \ref{XTDdata}. It confirms the performance of XTD for dealing with highly nonlinear (or singular) problems. In real applications, a large variation of parameters can involve non-smooth transitions of solutions, thus the XTD is a good choice for solving large space-time-parametric problems. 
We will focus on using the governing equation to train the XTD model in this work. The detailed algorithm will be explained in section \ref{section:XTDformulation}.

It should be noticed that the training should cover a very large space-time-parameter domain so that it can be done once-for-all in the offline stage. The XTD parametric solutions will be stored as a database that can be repetitively used in the online phase. 

\subsection{Online prediction}
Once the training stage is finished, we obtain an XTD model $\ud^{\text{XTD}}(\X,t,{\mu_1},\dots,\mu_n)$ containing the general parametric solutions for the underlying problem. Hence, for any unseen parameter value, we can use the XTD model to predict the solution, like neural networks. This online prediction is very fast, and only as expensive as a simple interpolation. This enables many applications for the online stage, such as real-time system monitoring and control, uncertainty quantification of parameters, inverse identification and design.

As an example, we can formulate a general design problem as follows
\begin{equation}
\displaystyle
\label{eq:design}
\begin{cases}
\begin{aligned}
&\text{Find}\ \mu_1,\dots,\mu_n\\
&\text{Minimize}\ J(\ud^{\text{XTD}}(\X,t,{\mu_1},\dots,\mu_n))\\
&\text{Subject to:}\\
&c_1(\X,t,{\mu_1},\dots,\mu_n)=0\\
&c_2(\X,t,{\mu_1},\dots,\mu_n)\leq0
\end{aligned}
\end{cases}
\end{equation}
where $J$ is the objective function that needs to be evaluated repetitively during the optimization, $c_1,c_2$ are general constraints. Since the XTD model is very cheap to evaluate once the training is finished, we can expect a very fast design in the online stage. This can lead to orders of magnitude speed-ups compared to a conventional design strategy.

In what follows, we will present the XTD method to elastic-plastic problems as applications.
\section{The XTD method for nonlinear parametric elastic-plastic problems}
\label{section:XTDformulation}
\subsection{Problem formulation}
Considering a physical spatial domain $\Omega_\X$ with a prescribed external force $\overline{\textbf{d}}$ and displacement $\overline{\ud}$ respectively on the boundaries $\partial_{\textbf{F}}{\Omega_\X}$ and $\partial_{\textbf{u}}{\Omega_\X}$, and a design parameter vector $\boldsymbol{\mu}\in\Omega_{\boldsymbol{\mu}}$, The quasi-static mechanical analysis consists in seeking the admissible stress, displacement, equivalent plastic strain fields $\sig$, $\ud$ and $\epsp$ satisfying the following balance equations and boundary conditions
\begin{equation}
\displaystyle
\label{eq:MSF}
\begin{cases}
\begin{aligned}
&\nabla\cdot\sig (\X,t;\boldsymbol{\mu})=0\quad \text{in}\ \Omega_\X\\
&\sig(\X,t;\boldsymbol{\mu})\cdot\textbf{n}(\X,t;\boldsymbol{\mu})=\overline{\textbf{d}}(\X,t;\boldsymbol{\mu})\quad   \text{on}\ \partial_{\textbf{F}}{\Omega_\X} \\
&\ud(\X,t;\boldsymbol{\mu})=\overline{\ud}(\X,t;\boldsymbol{\mu})\quad \text{on}\ \partial_{\textbf{u}}{\Omega_\X}
\end{aligned}
\end{cases}
\end{equation}
where {the body forces are neglected}. Under the infinitesimal strain assumption, the stress field $\sig$ reads
\begin{equation}
\displaystyle
\label{eq:stress}
\sig =\textbf{D}:\epse =\textbf{D}:(\eps -\epsp)
\end{equation}
where the total strain $ \eps=\nabla_s \ud(\X,t)$,  $\epse$ and $\epsp$ denote respectively the elastic and the plastic strains,  and $\textbf{D}$ denotes the fourth order elasticity tensor.  The complementary plastic behavior law with an isotropic hardening R reads
\begin{equation}
\displaystyle
\label{eq:MBL}
\begin{cases}
\begin{aligned}
&f(\sig ,\text{p})=\parallel {{\sig }_{d}}\parallel -{\sigma }_{y}-\text{R}(\text{p})\\
&{\dot{\eps }_p}=\mathcal{H}(f)\frac{<{{\sig }_{d}}:{{{\dot{\sig }}}_{d}}>}{\text{R}g}\frac{{{\sig}_{d}}}{\parallel {{\sig }_{d}}\parallel } 
\end{aligned}
\end{cases}
\end{equation}
where ${\sigma }_{y}$ denotes the initial yield stress, $\mathcal{H}(\bullet)$ the Heaviside function, ${\sig }_{d}$  the deviatoric stress tensor, $<A>$ the positive part of A, and p  the equivalent plastic strains and $g=\frac{d\text{R}}{d\text{p}}$.

The weak form of \eqref{eq:MSF} can be written as
\begin{equation}
\displaystyle
\label{eq:weakform}
-\int_{\Omega_\X}{\sig(\ud) :\eps ({{\ud}^{*}})d\X}+\int_{\partial_{\textbf{F}} {{\Omega_\X}}}{\bar{\textbf{d}}\cdot{{\ud}^{*}}ds=0}
\end{equation}
with ${\ud}^{*}$ denoting the test function.

The problem can be discretized by the finite element method and solved by a nonlinear solver (e.g. Newton-Raphson). This consists in solving, at each time step $k$ and for a given parameter vector $\boldsymbol{\mu}$, the following discretized system
\begin{equation}
\displaystyle
\label{eq:FEdiscret}
\begin{aligned}
 \textbf{R}(t_k;\boldsymbol{\mu})={\Fm}_{\text{ext}}(t_k;\boldsymbol{\mu})-{\Fm}_{\text{int}}(t_k;\boldsymbol{\mu})=0
\end{aligned}
\end{equation}
where 
\begin{equation}
\displaystyle
\label{eq:FEforce}
\begin{aligned}
&{\Fm}_{\text{ext}}(t_k;\boldsymbol{\mu}) =\int_{\partial_{\textbf{F}} {{\Omega_\X}}}{\textbf{N}^{T}\bar{\textbf{d}}}\ ds\\
&{\Fm}_{\text{int}}(t_k;\boldsymbol{\mu}) =\int_{\Omega_\X}{\textbf{B}^{T}\sig\ d\X}\\
\end{aligned}
\end{equation}
with the usual shape function and its gradient denoted by $\textbf{N}$ and $\textbf{B}$ respectively. ${\Fm}_{\text{ext}}$ and ${\Fm}_{\text{int}}$ stand for the external and internal nodal forces. Considering the equation \eqref{eq:stress}, the discretized form \eqref{eq:FEdiscret} becomes
\begin{equation}
\displaystyle
\label{eq:FEdiscret2}
\begin{aligned}
 \textbf{R}(t_k;\boldsymbol{\mu})={\Fm}_{\text{ext}}(t_k;\boldsymbol{\mu})-\textbf{K}(\boldsymbol{\mu})\textbf{U}(t_k;\boldsymbol{\mu})+{\Fm}_{\text{pl}}(t_k;\boldsymbol{\mu})=0
\end{aligned}
\end{equation}
where 
\begin{equation}
\displaystyle
\label{eq:Fpl}
\begin{aligned}
&\textbf{K} =\int_{\Omega_\X}{\textbf{B}^{T}\textbf{D}\textbf{B}\ d\X}\\
&{\Fm}_{\text{pl}} =\int_{\Omega_\X}{\textbf{B}^{T}\textbf{D}:\epsp\ d\X}\\
\end{aligned}
\end{equation}
with $\textbf{U}$ as the usual nodal displacement vector.
%\subsection{Challenges with PGD based parametric model reduction}
%The usual way to solve the parametric system \eqref{eq:FEdiscret} can be seen as a point-wise evaluation in the parameter space $\Omega_{\boldsymbol{\mu}}$, which may result in a prohibitive computational cost if an exhaustive exploration of the space is required.
%\subsection{General parametric problems for nonlinear solids}
%In a more general sense, the materials can involve other nonlinear effects, like the viscosity. Denoting by $\eps_{nl}$ the part of strain induced by nonlinear effects, the stress can be then written as
%\begin{equation}
%\displaystyle
%\label{eq:stressgeneral}
%\sig =\textbf{D}:\epse =\textbf{D}:(\eps -\eps_{nl})
%\end{equation}
%and the complementary constitutive law can be written implicitly as
%\begin{equation}
%\displaystyle
%\dot{\eps}_{nl} = f_{ev} (\sig,\eps_{nl}) 
%\end{equation}



\subsection{Extend tensor decomposition for elastic-plastic problems}

For solving the aforementioned parametric space-time problem, 
we chose the increment of the displacement field as the separated variable, which results in
\begin{equation}
\displaystyle
\label{eq:XTDdu}
\Delta\ud(\X,{\mu_1},\dots,\mu_n)= \sum_{m=1}^{M}\boldsymbol{a}^{(m)}(\X)g_1^{(m)}(\mu_1)\cdots g_n^{(m)}(\mu_n) + \sum_{k=1}^{K}\Tilde{\boldsymbol{a}}^{(k)}(\X,{\mu_1},\dots,\mu_n)
\end{equation}
where the $\Delta\ud$ stands for the displacement increment at each time step. The $\mu_i|_{i=1,\dots,n}$ are the components of the design parameter vector $\boldsymbol{\mu}$, and therefore the underlying variable parameters that relate to materials, loading, or geometry. Each parameter $\mu_i$ belongs to a  given range $\Omega_{\mu_i}$, and $\Omega_{\boldsymbol{\mu}}=\Omega_{\mu_1}\times \Omega_{\mu_2}\times\cdots\times\Omega_{\mu_n}$. 

This choice seems appropriate for the reducibility of the decomposition and  the actual FE solution strategy for plasticity. Since the sparsity of $\Tilde{\boldsymbol{a}}^{(k)}$ is essential for the efficiency of the XTD method, we assume that the $\Tilde{\boldsymbol{a}}^{(k)}=0$ holds for the most part of the space-parameter domain $\Omega_\X\times\Omega_{\boldsymbol{\mu}}$ for a displacement increment. In addition, we expect that $\Tilde{\boldsymbol{a}}^{(k)}$ are related to the contribution of the plastic strain. Hence, the plastic region, at least the increment of the plastic region, is assumed to be small compared to the global space-parameter domain $\Omega=\Omega_\X\times\Omega_{\boldsymbol{\mu}}$. 

The overall idea is to compute alternatively the separated terms and the non-separated terms in equation \eqref{eq:XTDdu}. In particular, when computing the separated terms, the problem is considered as a linear problem with plasticity-induced internal forces as external loads. Computing the non-separated terms requires solving the nonlinear plastic problem but only for a small portion of the global domain. The overall solution procedure follows an incremental strategy, which starts from $M=1$ and $K=1$. For a general purpose, let us assume that the $M-1$ separated modes and $K-1$ non-separated extended modes have been computed, the (to be computed) unknown modes  are  denoted by $\boldsymbol{a},g_1,\cdots, g_n$ and $\Tilde{\boldsymbol{a}}$. Then
\begin{equation}
\displaystyle
\Delta\ud(\X,{\mu_1},\dots,\mu_n)= \sum_{m=1}^{M-1}\boldsymbol{a}^{(m)}g_1^{(m)}\cdots g_n^{(m)} + \boldsymbol{a}g_1\cdots g_n + \sum_{k=1}^{K-1}\Tilde{\boldsymbol{a}}^{(k)}+\Tilde{\boldsymbol{a}}
\end{equation}
The week form \eqref{eq:weakform} of the problem for training the XTD model reads then
\begin{equation}
\displaystyle
-\int_{\Omega}{\sig(\ud_0+\Delta\ud) :\eps ({\Delta{\ud}^{*}})\ d\X d\mu_1\cdots d\mu_n}+\int_{\partial_{\textbf{F}} {{\Omega}}}{\bar{\textbf{d}}\cdot{\Delta{\ud}^{*}}\ dsd\mu_1\cdots d\mu_n=0}
\end{equation}
where $\partial_{\textbf{F}} {{\Omega}}=\partial_{\textbf{F}} {{\Omega_\X}}\times\Omega_{\boldsymbol{\mu}}$, $\Delta\ud$ is the displacement increment at the current time step $t_k$, $\ud_0$ is the displacement at the previous step $t_{k-1}$. The test function
$\Delta\ud^*=\boldsymbol{a}^*g_1\cdots g_n+\boldsymbol{a}g_1^*\cdots g_n+\cdots+\boldsymbol{a}g_1\cdots g_n^*+\Tilde{\boldsymbol{a}}^*$.

\subsubsection{Formulation to compute the separated modes \label{formulationsepmode}}
The unknown mode is computed alternatively by considering the others are fixed. For example, we compute $\boldsymbol{a}$ by considering that $g_1,\cdots, g_n$ and  $\Tilde{\boldsymbol{a}}$ are given. Then with the FE discretization, we have
\begin{equation}
\displaystyle
\begin{aligned}
&\int_{\Omega}{g_n^{T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\sum_{m=1}^{M-1}\textbf{B}^T \textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}^{(m)}g_1^{(m)}\cdots g_n^{(m)}\ d\X d\mu_1\cdots d\mu_n}\\
&+\int_{\Omega}{g_n^{T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\textbf{B}^T\textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}g_1\cdots g_n\ d\X d\mu_1\cdots d\mu_n}\\
&+\int_{\Omega}{g_n^{T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\sum_{k=1}^{K-1}\textbf{B}^T \textbf{D}\textbf{B}\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}\ d\X d\mu_1\cdots d\mu_n}\\
&-\int_{\Omega_{\boldsymbol{\mu}}}{g_n^{T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\Delta\textbf{F}_{\text{pl}}\ d\mu_1\cdots d\mu_n}\\
&=\int_{\partial_{\textbf{F}} {{\Omega}}}{g_n^{T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\textbf{N}^T\Delta\bar{\textbf{d}}\ ds d\mu_1\cdots d\mu_n}
\end{aligned}
\end{equation}
where $\boldsymbol{\mathcal{A}}^{(m)}, \boldsymbol{\mathcal{A}}$ are the discrete representation of  $\boldsymbol{a}^{(m)},\boldsymbol{a}$ as introduced in \eqref{eq:XTDdef}. The detailed derivation can be found in \ref{XTDmodel}. Here, we assume that an estimate of $\Delta\textbf{F}_{\text{pl}}$ is also given. Therefore, the only unknown in the above equation is $\boldsymbol{\mathcal{A}}$.

For computing $g_1$, we have 
\begin{equation}
\displaystyle
\begin{aligned}
&\int_{\Omega}{g_n^{T}\cdots g_1^{*T}\boldsymbol{\mathcal{A}}^{T}\sum_{m=1}^{M-1}\textbf{B}^T \textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}^{(m)}g_1^{(m)}\cdots g_n^{(m)}\ d\X d\mu_1\cdots d\mu_n}\\
&+\int_{\Omega}{g_n^{T}\cdots g_1^{*T}\boldsymbol{\mathcal{A}}^{T}\textbf{B}^T\textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}g_1\cdots g_n\ d\X d\mu_1\cdots d\mu_n}\\
&+\int_{\Omega}{g_n^{T}\cdots g_1^{*T}\boldsymbol{\mathcal{A}}^{T}\sum_{k=1}^{K-1}\textbf{B}^T \textbf{D}\textbf{B}\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}\ d\X d\mu_1\cdots d\mu_n}\\
&-\int_{\Omega_{\boldsymbol{\mu}}}{g_n^{T}\cdots g_1^{*T}\boldsymbol{\mathcal{A}}^{T}\Delta\textbf{F}_{\text{pl}}\ d\mu_1\cdots d\mu_n}\\
&=\int_{\partial_{\textbf{F}} {{\Omega}}}{g_n^{T}\cdots g_1^{*T}\boldsymbol{\mathcal{A}}^{T}\textbf{N}^T\Delta\bar{\textbf{d}}\ ds d\mu_1\cdots d\mu_n}
\end{aligned}
\end{equation}
with that the $g_1$ is the only unknown variable.

Analogically, for computing $g_n$, we have 
\begin{equation}
\displaystyle
\begin{aligned}
&\int_{\Omega}{g_n^{*T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{T}\sum_{m=1}^{M-1}\textbf{B}^T \textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}^{(m)}g_1^{(m)}\cdots g_n^{(m)}\ d\X d\mu_1\cdots d\mu_n}\\
&+\int_{\Omega}{g_n^{*T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{T}\textbf{B}^T\textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}g_1\cdots g_n\ d\X d\mu_1\cdots d\mu_n}\\
&+\int_{\Omega}{g_n^{*T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{T}\sum_{k=1}^{K-1}\textbf{B}^T \textbf{D}\textbf{B}\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}\ d\X d\mu_1\cdots d\mu_n}\\
&-\int_{\Omega_{\boldsymbol{\mu}}}{g_n^{*T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{T}\Delta\textbf{F}_{\text{pl}}\ d\mu_1\cdots d\mu_n}\\
&=\int_{\partial_{\textbf{F}} {{\Omega}}}{g_n^{*T}\cdots g_1^{T}\boldsymbol{\mathcal{A}}^{T}\textbf{N}^T\Delta\bar{\textbf{d}}\ ds d\mu_1\cdots d\mu_n}
\end{aligned}
\end{equation}
The above equations can be solved repetitively until $|\boldsymbol{a}g_1\cdots g_n|$ converges. The final converged solution is the solution for one mode. We can incrementally increase the number $M$ to enrich the displacement solution. The converged number can be the one for which the enrichment becomes very small.

\subsubsection{Formulation to compute the non-separated extended modes \label{formulationextmode}}
Once the separated modes are computed, we can enrich the extended modes. This step also consists in correcting the estimated plastic strain and internal forces with the updated displacement increment. 

Taking the current displacement as an initial guess  $\Delta\ud^{(0)}$, we can check the local plastic region in the entire domain with
 \begin{equation}
    \displaystyle
        \Omega_\text{pl}=\{(\X,\boldsymbol{\mu})\in \Omega_\X\times\Omega_{\boldsymbol{\mu}}\ | \ \Delta\epsp(\X,\boldsymbol{\mu})\neq 0\}
    \end{equation}
Then, Newton's method can be applied to solve an updated $\Delta\ud$ satisfying the balance equation 
 \begin{equation}
    \displaystyle
    {{\Fm}_{\text{ext}}-{\Fm}_{\text{int}}=0 \quad \text{in}\quad \Omega_{\text{pl}} \quad \text{with } \quad \Delta\ud|_{\partial \Omega_{\text{pl}} }=\Delta\ud|_{\partial \Omega_{\text{el}} }}
 \end{equation}
 where $\Omega_{\text{el}}=(\Omega_\X\times\Omega_{\boldsymbol{\mu}})\backslash \Omega_{\text{pl}}$. The converged solution gives a new extended mode as
  \begin{equation}
    \displaystyle
     \Tilde{\boldsymbol{a}}=\Delta\ud-\Delta\ud^{(0)}
 \end{equation}
 with the updated $\epsp$, $\Delta\epsp$ and $\Delta\textbf{F}_{\text{pl}}$. They are sparse arrays as the computations are performed locally.  A notable advantage of this formulation is that it enables an  easily implemented parallelization and the possibility to incorporate with an existing FE code.

 
\subsubsection{Overall solution procedure}
The XTD model is trained by solving alternatively the separated and extended modes using the previous formulation. The overall solution procedure is summarized below.
\begin{enumerate}
    \item  For a given time step $t=t_k$, starting from $M=1, K=1$ and assuming
    \begin{equation}
    \displaystyle
        \Tilde{\boldsymbol{a}}=0, \quad \Delta\epsp=0, \quad \forall (\X,\boldsymbol{\mu})\in \Omega_\X\times\Omega_{\boldsymbol{\mu}}
    \end{equation}
    \item Increase $M$ and compute incrementally the separated functions until a predefined convergence as explained in \ref{formulationsepmode} 
    \begin{equation}
    \displaystyle
        {\boldsymbol{a}^{(m)}, g_1^{(m)},\cdots, g_n^{(m)} }
    \end{equation}
    and update the nodal displacement increment $\Delta\ud$.
    \item Update the local plastic region $\Omega_\text{pl}$ with $\Delta\ud$ 
    \item Update the extended mode and the plastic strain increment as explained in \ref{formulationextmode}
    \begin{equation}
    \displaystyle
        \Tilde{\boldsymbol{a}}, \quad \Delta\epsp, \quad \forall (\X,\boldsymbol{\mu})\in \Omega_{\text{pl}}
    \end{equation}
    \item Check the convergence on $\Tilde{\boldsymbol{a}}$
    \begin{equation}
\displaystyle
\frac{\|\Tilde{\boldsymbol{a}}\|_\infty}{\|\Delta\ud\|_\infty}\leq\epsilon_{\text{XTD}}
\end{equation}
    \item If the convergence is achieved, stop computations. Otherwise, $K=K+1$ and go to step 2.
\end{enumerate}

We remark that in the XTD model, the internal variables like $\epsp(\X,\boldsymbol{\mu})$, $\sig(\X,\boldsymbol{\mu})$ are not stored in the separated form. Hence, the storage memory for these variables can be high when dealing with high dimensional space-time-parametric problems. To reduce the storage memory, we can perform a post-treatment using HOPGD \cite{lu2018multi} or the data-driven XTD (see \ref{XTDdata}) for data compression.


\section{Numerical examples}
\subsection{Elastic-plastic test with a variable loading}
The first example consists in testing the proposed XTD method on elastic-plastic materials with cyclic loading. The geometry of the material domain and the loading history are depicted in \figurename~\ref{fig:Ex1doman}. A concentrated displacement load is applied on the top-surface of the domain with the fixed boundary on the bottom surface. The following loading increment is used as a cycle: $\Delta \bar{u}_z=0.03$ m for the first 2 time steps, $\Delta \bar{u}_z=-0.03$ m for the step 3 to step 5, $\Delta \bar{u}_z=0.03$ m for the step 6. The Young's modulus and Poisson's ratio are respectively 210 GPa and 0.3.  Two design parameters are considered: the initial yield stress $\sigma_y\in [\sigma_y^{\min},\ \sigma_y^{\max}]$ and the linear hardening coefficient $H\in [H^{\min},\ H^{\max}]$. Then the XTD model aims at computing the following parametric solutions for each time step.

\begin{equation}
\displaystyle
\label{eq:XTDex1}
\Delta\ud(\X,\sigma_y,H)= \sum_{m=1}^{M}\boldsymbol{a}^{(m)}(\X)g_1^{(m)}(\sigma_y)g_2^{(m)}(H) + \sum_{k=1}^{K}\Tilde{\boldsymbol{a}}^{(k)}(\X,{\sigma_y},H)
\end{equation}

% Figure environment removed

For evaluating the performance of the solution strategy, we used 7 test cases as shown in \tablename~\ref{table:ex1test}. It can be noticed that the parameter space is assumed to be extremely large, although it may not be realistic. Nevertheless, we consider that the offline computations should cover as large as possible the design parameter space so that no more online computations will be required. This is also consistent with the once-for-all concept in the offline-online strategy. From this consideration, we tested the XTD method with large parameter variations.


\begin{table}[htbp]
\caption{Test cases with different meshes and discretizations in the parameter space}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
Case & $l_1\times l_2 \times l_3$ $(m^3)$ &  Mesh &$ [\sigma_y^{\min},\ \sigma_y^{\max}]$ & Grid $\sigma_y$ &$ [H^{\min},\ H^{\max}]$& Grid  $H$ \\ \hline
1 & 6 $\times$ 6 $\times$ 2.5  &  13 $\times$ 13 $\times$ 6 & $[300,\ 900]$ MPa &11  &  $[21,\ 63]$ GPa & 5  \\ \hline
2 & 6 $\times$ 6 $\times$ 2.5  &  13 $\times$ 13 $\times$ 6 & $[300,\ 1800]$ MPa &26  &  $[21,\ 105]$ GPa & 9  \\ \hline
3 & 6 $\times$ 6 $\times$ 2.5  &  13 $\times$ 13 $\times$ 6 & $[300,\ 1800]$ MPa &51  &  $[21,\ 105]$ GPa & 17  \\ \hline
4 & 12$\times$ 12 $\times$ 2.5  &  25 $\times$ 25 $\times$ 6 & $[300,\ 900]$ MPa &11  &  $[21,\ 63]$ GPa & 5  \\ \hline
5 & 12$\times$ 12 $\times$ 2.5  &  25 $\times$ 25 $\times$ 6 & $[300,\ 1800]$ MPa &26  &  $[21,\ 105]$ GPa & 9   \\ \hline
6 & 12$\times$ 12 $\times$ 2.5  &  25 $\times$ 25 $\times$ 6& $[300,\ 1800]$ MPa &51  &  $[21,\ 105]$ GPa & 9  \\ \hline
7 & 12$\times$ 12 $\times$ 10  &  25 $\times$ 25 $\times$ 21& $[300,\ 1800]$ MPa &51  &  $[21,\ 105]$ GPa & 9  \\ \hline
\end{tabular}
\label{table:ex1test}\\
 Note: each design parameter is discretized using a uniform grid
\end{table}


\tablename~\ref{table:ex1cost} reports the offline computational cost for different cases. For better illustrating the computational complexity, we compute the total degrees of freedom (DoFs) using the following equation.
\begin{equation}
\displaystyle
\label{eq:dof}
\text{Total DoFs}=3\times\text{Mesh}\times \text{Time steps} \times \text{Grid }\ \sigma_y\times\text{Grid}\ H
\end{equation}
where 3 is the DoFs of the displacement per node, the number of time steps is 6. For comparison purposes, the finite element analysis (FEA) is run for the 7 test cases in a sequential setting. \figurename~\ref{fig:ex1cost} depicts the computational cost comparison between FEA and XTD in the 7 test cases. It is shown that the XTD has a significant speed-up when dealing with large DoFs. For small size problems (in terms of spatial mesh and discretization in parameter space), the computational cost is almost equivalent between the two methods. This is expected, as the XTD method is designed for computations in a large space-time-parameter domain. This cost analysis is only for the offline training. Once it is done, the online prediction is very fast. For the prediction on arbitrary parameter values, the online cost is less than 0.01 s. This kind of real time prediction is usually intractable with standard FEA.



\begin{table}[htbp]
\caption{Computational cost and prediction error for the test cases}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Case & Total DoFs &  Offline & Online& Err stress& Err plastic strain\\ \hline
1 & 1003860 & 502 s & $<0.01$ s & $<2\%$& $<2\%$\\ \hline
2 & 4270968 & 1355 s & $<0.01$ s & $1.8\%$& $1.5\%$\\ \hline
3 & 15824484 & 4965 s & $<0.01$ s & $1.8\%$& $1.8\%$\\ \hline
4 & 3712500 & 1264 s & $<0.01$ s & $<2\%$& $<2\%$\\ \hline
5 & 15795000 & 4207 s & $<0.01$ s & $1.9\%$& $1.4\%$\\ \hline
6 & 30982500 & 7276 s & $<0.01$ s & $1.9\%$& $1.5\%$\\ \hline
7 & 108438750 & 7276 s & $<0.01$ s & $<2\%$& $<2\%$\\ \hline
\end{tabular}
\label{table:ex1cost}\\
Note: Err stands for the mean error of the equivalent stress and plastic strain to finite element solutions on the test data set. 
\end{table}

% Figure environment removed

For further investigating the online prediction accuracy, a test database containing 10 randomly selected parameters has been constructed using FEA. As reported in \tablename~\ref{table:ex1cost}, 
the XTD prediction seem  at a well acceptable level. The solutions for the stress and plastic strain are well predicted within a mean error of $2\%$. \figurename~\ref{fig:Exmesh1compare} depicts an example of the online solution provided by XTD for the parameter values: $\sigma_y=1747$ MPa, $H=101.6$ GPa. The prediction agrees well with that obtained by FEA.


% Figure environment removed

\figurename~\ref{fig:ExC2t5modesep} illustrates the different modes of $\boldsymbol{a}^{(m)}(\X)$  obtained by XTD for the test case 2 at the time step 5. In particular, the component along the $z$-direction is plotted, which is the most important one in this example. It can be seen that the first mode is related to the boundary conditions and the loading displacement. The following modes are more and more distributed in the spatial domain.  The components of the non-separated extended modes are illustrated in \figurename~\ref{fig:ExC2t5modenonsep}. It confirms that this extended term is sparse in the global domain, as most of the region remains zero. This enables an efficient computation for the non-separated term, as mentioned previously. The other separated modes $g_1^{(m)}(\sigma_y)$ and $\ g_2^{(m)}(H)$ are plotted in \figurename~\ref{fig:ExC2t5modeg1g2}.    They are 1D functions that represent the variation of the solutions in a single parameter direction. It can be seen that the solution variation is not necessarily smooth in the parameter space, which motivated us to develop the XTD method. The total number of modes for each time step is reported in \figurename~\ref{fig:ex1nbmode}. The small number of modes for each time step confirms that the displacement increment is a good choice for the separated variable. For the 6 test cases, we observed similar results. Thus we illustrated test case 2 as an example. 

% Figure environment removed



% Figure environment removed

% Figure environment removed

% Figure environment removed

This first numerical experiment investigated the performance of the proposed XTD method. It confirms its efficiency, in particular, for problems with localized loading. In the next example, we will study the application to problems with a localized moving load, which is relevant to the additive manufacturing process.

\subsection{Application to thermal residual stress prediction}
\subsubsection{Offline training}
Additive manufacturing or welding is controlled by many uncertain parameters related to the materials, heat source, and boundary conditions. The parametric study for such a process fits well the aim of the overall XTD framework. In this example, we will particularly investigate the thermally induced residual stress with respect to the variation of two parameters, again the initial yield stress $\sigma_y$ and the  hardening coefficient $H$. The detailed material properties and the variation range will be described later. Assuming the temperature of each time step is given and the thermal and mechanical problems are weakly coupled, the XTD method  computes the displacement increment as below

\begin{equation}
\displaystyle
\label{eq:XTDex2}
\Delta\ud(\X,\sigma_y,H)= \sum_{m=1}^{M}\boldsymbol{a}^{(m)}(\X)g_1^{(m)}(\sigma_y)g_2^{(m)}(H) + \sum_{k=1}^{K}\Tilde{\boldsymbol{a}}^{(k)}(\X,{\sigma_y},H)
\end{equation}

In our work, we first used the  hyper reduction method \cite{lu2020adaptive} for the thermal fluid analysis to compute the temperature evolution in a predefined domain. The details of the model can be found in \cite{lu2020adaptive}. Some key  parameters for the thermal computations are summarized in \tablename~\ref{table:ex2thermalprocess}. \figurename~\ref{fig:ex2T} illustrates a snapshot of the output temperature profile on the computation domain. We selected 30 output steps as the input for the subsequent mechanical analysis. The resulting stress is considered by the thermal expansion as follows
\begin{equation}
\displaystyle
\label{eq:stressT}
\sig =\textbf{D}:\epse =\textbf{D}:(\eps -\epsp-\eps_{\theta})
\end{equation}
with
\begin{equation}
\displaystyle
\label{eq:expansion}
\eps_{\theta}=\alpha\textbf{I}\theta
\end{equation}
where $\theta$ denotes the temperature and $\textbf{I}$ is the identity matrix. In real implementation, this can be performed by applying an equivalent external force induced by the thermal expansion.

% Figure environment removed

\begin{table}[htbp]
\caption{Parameters used for the thermal  fluid analysis}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Power & Scan speed &  Step size & Total time steps& Output steps& Materials\\ \hline
195 W & 0.8 m/s& $10^{-5}$ s & 145 &30& IN625\\ \hline
\end{tabular}
\label{table:ex2thermalprocess}
\end{table}

In the mechanical analysis, the bottom surface is fixed as the boundary condition. The elastic-plastic materials properties are considered temperature-dependant, as shown in \tablename~\ref{table:ex2mate} and reported in \cite{denlinger2015thermo}. Considering these reported properties as reference values, the variations of the temperature dependant yield stress $\sigma_y (\theta)$ and the  hardening coefficient $H(\theta)$ can be  considered by two amplitude parameters $A_1$ and $A_2$, i.e. $\sigma_y (\theta)\leftarrow A_1 \sigma_y (\theta) $ with $A_1\in [1,\ 2]$ and $H (\theta)\leftarrow A_2 H (\theta) $ with $A_2\in [1,\ 3]$. 

\begin{table}[htbp]
\caption{Temperature-dependant mechanical properties}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Temperature (K) & $\alpha$ ($\times 10^{-6}$ K$^{-1}$) &  $\sigma_y$ (MPa) & $H$ (GPa)& Young's modulus (GPa)\\ \hline
273 & 12.8& 493 & 20.8 &208\\ \hline
293 & 12.8& 493 & 20.8 &208\\ \hline
366 & 12.8& 479 & 20.4 &204\\ \hline
478 & 13.1& 443 & 19.8 &198\\ \hline
588 & 13.3& 430 & 19.2 &192\\ \hline
698 & 13.7& 424 & 18.6 &186\\ \hline
813 & 14.0& 423 & 17.9 &179\\ \hline
923 & 14.8& 422 & 17.0 &170\\ \hline
1033 & 15.3& 415 & 16.1 &161\\ \hline
1143 & 15.8& 386 & 14.8 &148\\ \hline
$>$ 1143 & 15.8& 386 & 14.8 &148\\ \hline
\end{tabular}
\label{table:ex2mate}
\end{table}

Concerning the discretization, a mesh of size $36\times22\times9$ is used for the physical (spatial) domain. The total number of time steps is 30. For the parameter domain, the $A_1$ is discretized by 6 equally distancing points and  $A_2$ is discretized by 5 points. Hence, if the FEA is used for computing the space-time-parametric solutions, we need to run 30 ($6\times 5$) times the nonlinear space-time simulation. Each of this FEA takes around 1100 s. The estimated cost for the 30 runs is then 33000 s.

The XTD model \eqref{eq:XTDex2} is used for computing the parametric solution. The total cost is 10480 s, which is significantly less than that of FEA. This confirms the efficiency of the method.  Again, this is the offline computational cost, the online prediction is very fast ($< 0.01$ s). \figurename~\ref{fig:Ex2FEXTD} compares the online XTD prediction to the FEA reference solution for the parameters $A_1=1.9$, $A_2=2.1$. They show a very good agreement in terms of stress and plastic strain. The  L-2 norm difference is less than $2\%$. 


% Figure environment removed

For visualizing the space-time solution, the evolution of stress and plastic strain fields is depicted in \figurename~\ref{fig:Ex2XTD}. We can see that the overall solution field is evolving significantly over the time range, which challenges the commonly used model reduction methods in the literature. To some extend, the success of the present method in this challenging problem relies on the good choice of the separated variable, i.e. displacement increment. As shown in \figurename~\ref{fig:Ex2XTDmode} and \figurename~\ref{fig:Ex2XTDmodeext}, both the separated and extended modes are concentrated around the region of the heat source. This makes the problem reducible and enables the efficiency of the proposed solution method. The total number of modes at each time step for the XTD model is shown in \figurename~\ref{fig:ex2nbmode}. The overall number is limited within a range of 10. It increases only slightly with time, especially for the extended modes. 

% Figure environment removed

% Figure environment removed

% Figure environment removed

% Figure environment removed

This is the offline training stage for the XTD model. The online stage concerns more about the application (or usage) of these parametric solutions. In the next subsections, we present two applications concerning the online stage.

\subsubsection{Online fast uncertainty quantification}
The first online application concerns the uncertainty quantification (UQ) using the computed XTD solutions. One of the computationally costly problems in UQ is the uncertainty propagation. Given the material parameter uncertainty, the UQ problem consists in propagating the uncertainty to the model output, like residual stresses or distortions. The Monte Carlo (MC) simulation is usually adopted to this end, which is however very expensive as the numerical model (FEA) has to be run many times. In our work, since the parametric solution has been known by offline XTD training, the MC procedure becomes very fast and even in real time.

Let us assume that the material properties $\sigma_y$ and $H$ are two independent random variables and follow two normal distributions, i.e.
\begin{equation}
\displaystyle
\label{eq:distribution}
\sigma_y \sim \mathcal{N}(1.5\sigma^{ref}_y,0.5\sigma^{ref}_y), \quad H \sim \mathcal{N}(2.1 H^{ref},0.5H^{ref})
\end{equation}
where $\sigma^{ref}_y$ and $H^{ref}$ are the reference parameter values shown in \tablename~\ref{table:ex2mate}. We can now study the variability of the residual stress with respect to the material randomness. As an example, the central line A-B (\figurename~\ref{fig:Ex2lineAB}) is chosen to observe the stress variation. Then, 63 random sets of material properties $\sigma_y$ and $H$ are generated according to the distribution \eqref{eq:distribution}. Using the XTD solution, we can easily obtain the propagated uncertainty on the residual stress, as shown in \figurename~\ref{fig:Ex2onlinestd}. Since there is no expensive computations at the online stage, the MC procedure only takes less than 0.2 s. If the parallel computing is used, this can be in real time.  The estimated cost for the MC simulation using FEA  for 65 runs is 69300 s.

% Figure environment removed

% Figure environment removed

\subsubsection{Online fast material design/characterization under uncertainty}
In practice, the stochastic models of material properties are a priori unknown and need to be identified against experiments. Thus, we can consider an inverse  problem as below

\begin{equation}
\displaystyle
\label{eq:inverse}
\begin{cases}
\begin{aligned}
&\text{Find the hyper-parameters of the stochastic models of}\ \sigma_y,H\\
&\text{Minimize}\ J(\sig^{\text{XTD}}(\X,\sigma_y,H),\sig^{\text{target}})
\end{aligned}
\end{cases}
\end{equation}
where the hyper-parameters are the mean and standard deviation of the probabilistic distribution for $\sigma_y$ and $H$. $\sig^{\text{target}}$ can be the experimental measurement of the stress. This inverse problem consists in finding out the best stochastic models of materials that fit the experimental observation in terms of both means and variations. In this case, the objective function reads

\begin{equation}
\displaystyle
\label{eq:inverseJ}
J= w_1\|\text{mean}\ \sig^{\text{XTD}}-\text{mean}\ \sig^{\text{target}}\|+w_2\|\text{std}\ \sig^{\text{XTD}}-\text{std}\ \sig^{\text{target}}\|
\end{equation}
where std stands for the standard deviation. $w_1, w_2$ are the weights. For evaluating the objective function $J$, the statistics (mean and std)  of simulation outputs are needed. Hence, for evaluating $J$ at a given set of hyper-parameters, the MC simulation is required. This makes the optimization extremely expensive as the hyper-parameters need to be modified over and over again. Fortunately, we can use XTD model to do the optimization. It takes only 5 minutes for this optimization problem at the online stage. This is reasonable as the online MC simulation is very cheap (less than 0.2 s), as shown previously. 


% Figure environment removed

An example of the target experimental stress data is illustrated in \figurename~\ref{fig:Ex2exp}. We assume the two random material parameters follow two normal distributions independently. The  identified probabilistic models are given in \eqref{eq:distributionexp}. As shown in \figurename~\ref{fig:Ex2expstd}, the identified model shows a good agreement to the experimental measurement.

\begin{equation}
\displaystyle
\label{eq:distributionexp}
\sigma_y \sim \mathcal{N}(1.61\sigma^{ref}_y,0.38\sigma^{ref}_y), \quad H \sim \mathcal{N}(1.25 H^{ref},0.42H^{ref})
\end{equation}

% Figure environment removed


\subsection{Coupled XTD-SCA strategy for multi-scale multi-parametric modeling of materials}
This example considers a two-scale coupled modeling for composite materials in the proposed XTD framework. In particular, the self-consistent clustering analysis (SCA) \cite{liu2016self} is used for the microscale simulation. Other options like FEA and the FFT (fast Fourier transform) method \cite{moulinec1998numerical} can also be used for the microscale problem. The SCA is adopted because of its efficiency. 

We summarize here the two-scale coupled solution procedure. In the macroscale, the XTD provides first an estimate of strain based on the nodal displacement increment. The macro-strain applies then as boundary conditions to the microscale representative volume element (RVE) associated to each macroscopic integration point. The SCA will provide a fast response of the micro-stress and micro-strain and return the homogenized stress for the marcoscale problem. In other words, the SCA serves as the replacement to constitutive material law in the XTD framework. This allows to directly consider the anisotropic effect of the microstructure without making hypotheses on the constitutive laws. The cost to pay is the microscale simulations. Hence, the two-scale coupled solution is usually very expensive. The present XTD-SCA method offers a way to enable real-time two scale simulations.

In this example, we consider the RVE is the same for all the macroscopic integration points. The geometry of the specimen is shown in \figurename~\ref{fig:Ex3specimen}. The RVE has two material phases, matrix and inclusion. The inclusion is considered purely elastic, whereas the matrix materials are elastoplastic with isotropic hardening.  The yield stress of the RVE matrix is described by the following equation.
\begin{equation}
\displaystyle
\label{eq:XTDex3yield}
\sigma_Y=\sigma_y+Hp^n
\end{equation}
where $\sigma_y$ is the initial yield stress, $H$ and $n$ are the hardening coefficients, $p$ is the equivalent plastic strain. 

The specimen is subject to a cycle load. The increment of displacement loading is given as follows: $\Delta\bar{u}_y=0.00002$ m for the first two steps, then $\Delta\bar{u}_y=0.00001$ m for the following four steps, $\Delta\bar{u}_y=-0.00002$ m for the remaining four steps in a half cycle. The second half cycle follows the same step increments and switches to a compression mode. This complete cycle is repeated twice in this example. There is in total 40 time steps.    


% Figure environment removed

The specimen is discretized by a mesh of 160 cubic elements with 8 integration points. The RVE is discretized by a mesh of $100\times100\times100$. For SCA, the matrix domain is divided by 16 clusters, whereas the inclusion is divided into 4 clusters. The clustering result is depicted in \figurename~\ref{fig:Ex3cluster}.

% Figure environment removed

For the XTD model, we consider two variable parameters, $\sigma_y\in [\sigma_y^{\min},\ \sigma_y^{\max}]$ and $H\in [H^{\min},\ H^{\max}]$. The following parametric solutions are computed for each time step.
\begin{equation}
\displaystyle
\label{eq:XTDex3}
\Delta\ud(\X,\sigma_y,H)= \sum_{m=1}^{M}\boldsymbol{a}^{(m)}(\X)g_1^{(m)}(\sigma_y)g_2^{(m)}(H) + \sum_{k=1}^{K}\Tilde{\boldsymbol{a}}^{(k)}(\X,{\sigma_y},H)
\end{equation}
The material properties for the RVE are illustrated in \tablename~\ref{table:ex3mate}. The initial yield stress $\sigma_y$ is discretized using 11 points. The hardening coefficient $H$ is discretized using 3 points. 

The offline computation of the two-scale coupled XTD-SCA model takes 37633 s. For comparison, the FEA-SCA would take about 105044 s for the 33 runs. If a larger mesh size is used, the speedup is even more significant. Again, once the offline computation is finished, the online XTD prediction for a given parameter set is in real time ($<0.01$ s). \figurename~\ref{fig:Ex3XTD} illustrates the two-scale von Mises stress prediction for the parameters: $\sigma_y=0.013$ (GPa) and $H=0.045$ (GPa). As applications, The XTD-SCA enables real-time monitoring of the two-scale material response and can be used to monitor the effect of microscale defects or the initiation of micro-cracks of materials. It should be noted that this is intractable with conventional FEA as the prediction of FEA-SCA would take more than 3000 s. If the FE$^2$ approach is used, the computational cost will be higher than 30000 s.

\begin{table}[htbp]
\caption{Material properties of RVE}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
Phase & $E$ & $\nu$  & $\sigma_y^{\min}$& $\sigma_y^{\max}$ & $H^{\min}$ &$H^{\max}$&$n$\\ \hline
Inclusion & 66 GPa &  0.19 & - & - &- &- &- \\ \hline
Matrix & 3 GPa & 0.4 & 0.01 GPa & 0.02 GPa &0.03 GPa &0.06  GPa& 0.4 \\ \hline
\end{tabular}\\
$E$: Young's modulus, $v$: Poisson's ratio
\label{table:ex3mate}\\
\end{table}

% Figure environment removed


\section{Conclusion}
This paper presents a novel model reduction method, referred to as XTD model reduction. The basic idea is to introduce an extra sparse term in the tensor decomposition, such as the canonical tensor decomposition. This extra-term is expected to improve the approximation accuracy and reduce the number of modes when encountering highly nonlinear or even singular problems. The overall XTD framework is split into two stages: offline and online. The offline training consists in solving the problem by considering that the solution has the XTD format. The online prediction is real time and can be used for many engineering problems in which parametric solutions are inquired many times, like design and uncertainty quantification.

The proposed method has been applied to nonlinear elastic-plastic problems, including challenging problems like additive manufacturing residual stress prediction and multi-scale composite material modeling. The method has shown significant speedups to conventional FEA, especially when the mesh size is very large. Applications concerning uncertainty quantification and inverse design and calibration have been considered in our work, which show a high potential to enable a wide application of the overall framework. 

Future applications can be considered in terms of multi-scale system monitoring and control for additive manufacturing or other material forming processes. The XTD method can also be combined with other machine learning techniques to further improve efficiency.



\section*{Acknowledgement}
The authors would like to acknowledge the support of the National Science Foundation under Grant No. CMMI-1762035 and CMMI-1934367.


\appendix
{\section{XTD based data learning and regression}\label{XTDdata}}
Without loss of generality, let us consider a scalar-valued multidimensional function $u(\mu_1,\dots,\mu_n)$ and the data of it is known for the general parameters: $(\mu_1,\dots,\mu_n) \in \Omega:=\Omega_{\mu_1}\times\cdots\times\Omega_{\mu_d}$. The training problem \eqref{eq:XTDdata} becomes
\begin{equation}
\displaystyle
\label{eq:XTDdatascalar}
\int_{\Omega}\delta u^{\text{XTD}}(u-u^{\text{XTD}})\  d\mu_1\cdots d\mu_{n}=0
\end{equation}
where the XTD representation of $u$ reads
\begin{equation}
\displaystyle
\label{eq:XTDdefcontinuscalar}
u^{\text{XTD}}({\mu_1},\dots,\mu_n)= {\sum_{m=1}^{M}g_1^{(m)}(\mu_1)\cdots g_n^{(m)}(\mu_n) + \sum_{k=1}^{K}\Tilde{{a}}^{(k)}( {\mu_1},\dots,\mu_n)}
\end{equation}
or in a discrete form
\begin{equation}
\displaystyle
\label{eq:XTDdefdiscretescalar} \boldsymbol{\mathcal{U}}^{\text{XTD}}=\sum_{m=1}^{M}
\boldsymbol{g}_1^{(m)}\otimes\cdots\otimes\boldsymbol{g}_n^{(m)}+\sum_{k=1}^{K}\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}
\end{equation}
with the $g_i^{(m)}$  and $\Tilde{{a}}^{(k)}$  denoting respectively the separated modes and the extended (non-separated) modes. Similar to PGD and HOPGD, the XTD uses an incremental scheme to compute the modes.

\subsection{Compute separated modes with $\Tilde{{a}}^{(1)}=0$}
Starting from $M=1,K=1$, then
\begin{equation}
\displaystyle
\label{eq:XTDonemodeu}
u^{\text{XTD}}=g_1^{(1)}\cdots g_n^{(1)} + \Tilde{{a}}^{(1)}
\end{equation}
\begin{equation}
\displaystyle
\label{eq:XTDdeltau}
\delta u^{\text{XTD}}=\delta g_1^{(1)}\cdots g_n^{(1)}+\cdots+g_1^{(1)}\cdots\delta g_n^{(1)} + \delta \Tilde{{a}}^{(1)}
\end{equation}

We can now compute an estimate of $g^{(1)}_1$ by giving initial values to $g^{(1)}_i,\ \forall i\neq 1$ and with $\Tilde{{a}}^{(1)}=0$. This also leads to $\delta g^{(1)}_i=0,\ \forall i\neq 1$ and $\delta \Tilde{{a}}^{(1)}=0$. Hence, 
\begin{equation}
\displaystyle
\label{eq:uxtdonemode}
 u^{\text{XTD}}= g_1^{(1)}\cdots g_n^{(1)}
\end{equation}
\begin{equation}
\displaystyle
\label{eq:deltaxtdonemode}
\delta u^{\text{XTD}}=\delta g_1^{(1)}\cdots g_n^{(1)}
\end{equation}
Substituting \eqref{eq:uxtdonemode} and \eqref{eq:deltaxtdonemode} into \eqref{eq:XTDdatascalar}, we obtain
\begin{equation}
\displaystyle
\label{eq:XTDdataonemode}
\int_{\Omega}\delta g_1^{(1)}\cdots g_n^{(1)} (u-g_1^{(1)}\cdots g_n^{(1)})\  d\mu_1\cdots d\mu_{n}=0
\end{equation}
By rearrangement,
\begin{equation}
\displaystyle
\label{eq:XTDdataonemode2}
\int_{\Omega}\delta g_1^{(1)}\cdots g_n^{(1)} u\  d\mu_1\cdots d\mu_{n}=\int_{\Omega_{\mu_1}}\delta g_1^{(1)}g_1^{(1)}\ d\mu_1 \cdots \int_{\Omega_{\mu_n}}g_n^{(1)} g_n^{(1)} \ d\mu_{n}
\end{equation}
The discretized form for the right hand side of \eqref{eq:XTDdataonemode2} can be written as
\begin{equation}
\displaystyle
\label{eq:XTDdatarhs}
\int_{\Omega_{\mu_1}}\delta g_1^{(1)}g_1^{(1)}\ d\mu_1 \cdots \int_{\Omega_{\mu_n}}g_n^{(1)} g_n^{(1)} \ d\mu_{n}=(\delta\boldsymbol{g}_1^{(1)})^T\boldsymbol{g}_1^{(1)}\cdots(\boldsymbol{g}_n^{(1)})^T\boldsymbol{g}_n^{(1)}
\end{equation}
The left hand side of \eqref{eq:XTDdataonemode2} requires a full integration but can be performed in a way of vector and matrix multiplications for a reasonable efficiency. We remark that $\boldsymbol{g}_1^{(1)}$ is the only unknown vector in the equation \eqref{eq:XTDdataonemode2}.

For better understanding, we illustrate the complete discrete form of $\eqref{eq:XTDdataonemode2}$ in the two dimensional case, 
\begin{equation}
\displaystyle
(\delta\boldsymbol{g}_1^{(1)})^T\boldsymbol{\mathcal{U}}\boldsymbol{g}_2^{(1)}=(\delta\boldsymbol{g}_1^{(1)})^T\boldsymbol{g}_1^{(1)}(\boldsymbol{g}_2^{(1)})^T\boldsymbol{g}_2^{(1)}
\end{equation}
Thus,
\begin{equation}
\displaystyle
\boldsymbol{g}_1^{(1)}=\boldsymbol{\mathcal{U}}\boldsymbol{g}_2^{(1)}((\boldsymbol{g}_2^{(1)})^T\boldsymbol{g}_2^{(1)})^{-1}
\end{equation}

By solving \eqref{eq:XTDdataonemode2}, the estimate of $g_1^{(1)}$ is obtained. Similarly, we can compute the estimate for $g_2^{(1)}$ by considering  $g^{(1)}_i,\ \forall i\neq 2$ are constant and  $\Tilde{{a}}^{(1)}=0$, $\delta g^{(1)}_i=0,\ \forall i\neq 2$, and $\delta \Tilde{{a}}^{(1)}=0$.  For the remaining functions, the procedure is the same. This is known as the alternating fixed point algorithm. Once all the first estimates for $g_i^{(1)}$ are computed, we can iterate several times until $\|\Delta g_1^{(1)}\cdots g_n^{(1)}\|$ converges. 

Once the first mode converges, we can go to the next mode.  For $M\geq2,K=1$,
\begin{equation}
\displaystyle
u^{\text{XTD}}=\sum_{m=1}^{M-1} g_1^{(m)}\cdots g_n^{(m)}+g_1^{(M)}\cdots g_n^{(M)} + \Tilde{{a}}^{(1)}
\end{equation}
\begin{equation}
\displaystyle
\delta u^{\text{XTD}}=\delta g_1^{(M)}\cdots g_n^{(M)}+\cdots+g_1^{(M)}\cdots\delta g_n^{(M)} + \delta \Tilde{{a}}^{(1)}
\end{equation}

Analogically to the first mode, we can solve for $g_1^{(M)},\dots ,g_n^{(M)}$. As an example, the 2D formulation for $g_1^{(M)}$ reads
\begin{equation}
\displaystyle
\boldsymbol{g}_1^{(M)}=(\boldsymbol{\mathcal{U}}-\sum_{m=1}^{M-1}
\boldsymbol{g}_1^{(m)}\otimes\boldsymbol{g}_2^{(m)})\boldsymbol{g}_2^{(M)}((\boldsymbol{g}_2^{(M)})^T\boldsymbol{g}_2^{(M)})^{-1}
\end{equation}

The number of separated mode $M$ can increase until a predefined criterion is reached, i.e. 
\begin{equation}
\displaystyle
\label{eq:convergsepmode}
\frac{\|u-\sum_{m=1}^{M} g_1^{(m)}\cdots g_n^{(m)}\|_\infty}{\|u\|_\infty}\leq\epsilon_M
\end{equation}

\subsection{Update the extended mode $\Tilde{{a}}^{(1)}$}
In XTD, this criterion $\epsilon_M$ is not the final approximation accuracy but a relatively larger value (e.g. 0.1). Once the stopping criterion is reached, we can update the first extended mode  $\Tilde{{a}}^{(1)}$. The method is very straightforward and can be written as follows
\begin{equation}
\displaystyle
\label{eq:XTDdatanonsep}
\begin{aligned}
&\Tilde{{a}}^{(1)}=u - \sum_{m=1}^{M} g_1^{(m)}\cdots g_n^{(m)},\quad \text{if}\quad ({\mu_1},\dots,\mu_n)\in \mathcal{I}\\
&\Tilde{{a}}^{(1)}=0,\quad \text{otherwise}
\end{aligned}
\end{equation}
where $\mathcal{I}$ is the index of $l$ maximum values of the difference $|u-\sum_{m=1}^{M} g_1^{(m)}\cdots g_n^{(m)}|$. To do so, we might define the following operator
\begin{equation}
\displaystyle
\mathcal{I}=\{({\mu_1},\dots,\mu_n)\in \Omega\ |\ |\mathcal{I}|=l, |u-\sum_{m=1}^{M} g_1^{(m)}\cdots g_n^{(m)}|\geq \sup_{\Omega\backslash\mathcal{I}}|u-\sum_{m=1}^{M} g_1^{(m)}\cdots g_n^{(m)}|\}
\end{equation}
The value of $l$ is at choice, usually much smaller than the vector size of $\boldsymbol{g}_i$. This ensures the sparsity of the extended mode. 
\subsection{Further enrich modes until convergence }
Once it is done, the number of separated modes $M$ can continue increasing until another stopping point. This means computing new separated modes  with the updated extended mode $\Tilde{{a}}^{(1)}$.    A new threshold in \eqref{eq:convergsepmode} can be used for computing a second extended mode. The final convergence criterion is defined as
\begin{equation}
\displaystyle
\label{eq:convergemultimode}
\frac{\|u-\sum_{m=1}^{M} g_1^{(m)}\cdots g_n^{(m)}-\sum_{k=1}^{K}\Tilde{{a}}^{(k)}\|_\infty}{\|u\|_\infty}\leq\epsilon_{XTD}
\end{equation}
where $\epsilon_{XTD}$ stands for the final approximation accuracy.

For summary, the overall solution procedure is described as follows.
\begin{itemize}
    \item Step 1: $  M=1,K=1 $.
    \item Step 2: Initialization for $g_i^{(M)}$ and $\Tilde{{a}}^{(K)}=0$
    \item Step 3: Update alternatively  the $g_i^{(M)}$ for $i=1,n$ using the alternating fixed point algorithm by considering  $\delta g_j^{(M)}=0, \forall j\neq i$ and $\delta\Tilde{{a}}^{(K)}=0$. If $M\geq2$, $g_j^{(m)}$ are constant for $m<M$.
    \item Step 4: If $\|\Delta g_1^{(M)}\cdots g_n^{(M)}\|$ converges, go to Step 5. Otherwise, repeat Step 3.
    \item Step 5: Check the convergence with \eqref{eq:convergsepmode}. If so, update $\Tilde{{a}}^{(K)}$ with \eqref{eq:XTDdatanonsep}. Otherwise,  go to next modes $M\leftarrow M+1$ and return to Step 2.
    \item Step 6: Check the convergence with \eqref{eq:convergemultimode}. If so, stop computations. Otherwise, $M\leftarrow M+1$, $K\leftarrow K+1$, $\epsilon_M\leftarrow \epsilon_M/c$  and return to Step 2.
\end{itemize}
We remark that the factor $c>1$ used in Step 6 is to decrease the convergence threshold.

\subsection{Numerical results}
We will illustrate a numerical example for a two dimensional function. The function for generating the data is written as 
\begin{equation}
\displaystyle
\begin{aligned}
u(\mu_1,\mu_2)=&100e^{\sqrt{(\mu_1-50)^2+(\mu_2-37)^2}/10}+100e^{\sqrt{(\mu_1-35)^2+(\mu_2-50)^2}/10}\\
&+100e^{\sqrt{(\mu_1-25)^2+(\mu_2-30)^2}/10}+100e^{\sqrt{(\mu_1-55)^2+(\mu_2-66)^2}/10}
\end{aligned}
\end{equation}
where the parameters $\mu_1\in [1,\ 100]$, $\mu_2\in [1,\ 100]$. The data  is then generated by evaluating the function $u$ for a uniform mesh of $100\times100$ in the 2D
domain $\Omega=\Omega_{\mu_1}\times\Omega_{\mu_2}$. \figurename~\ref{fig:xtddatafunction}(a) depicts the shape of this highly nonlinear function on the $100\times100$ mesh. We can observe the several sharp points around some predefined locations. This is the singularity that can challenge the reducibility of the function. 

If we use PGD (HOPGD, also equivalent to singular value decomposition in 2D cases) to reproduce this function, it requires 13 separated modes for an error less than $1\%$. However, if the XTD is used, only 7 separated modes and 1 sparse extended mode are needed for the same level of accuracy.  The evolution of error against the total number of modes is illustrated in \figurename~\ref{fig:xtdvspgd}. The first enrichment of the extended mode happens after 5 separated mode for the XTD method. We observe a significant decrease of error with this enrichment. This improvement is also clearly observed in the shape of the function reproduced by XTD (\figurename~\ref{fig:xtddatafunction}). It is shown that the separated modes can reproduce a smooth function, whereas the extended modes can efficiently enrich the local singularity. consequently, the  number of mode is reduced. 

\figurename~\ref{fig:xtddatanonsep} illustrates the location of the non-zero terms in the sparse extended mode. In this example, the initial  $\epsilon_M=10\%$, the number of local enrichment points $l=30$ which is much smaller than the total data size $100\times100$ and the size of one mode (1 pair of separated functions): $100+100$. Storing this sparse matrix is much cheaper than the modes.


% Figure environment removed

% Figure environment removed

% Figure environment removed

This example shows that the singularity can  challenge the reducibility of given functions. This implies that the number of separated modes for a good approximation can be very high. Using the XTD method can significantly improve the approximation in terms of accuracy and separability. 

{\section{Implementation of the XTD  model reduction}\label{XTDmodel}}
For a better illustration, let us consider a problem with two design parameters. The displacement increment at $t_k$ reads
\begin{equation}
\displaystyle
\label{eq:XTDdu2d}
\Delta\ud(\X,{\mu_1},\mu_2)= \sum_{m=1}^{M}\boldsymbol{a}^{(m)}(\X)g_1^{(m)}(\mu_1)g_2^{(m)}(\mu_2) + \sum_{k=1}^{K}\Tilde{\boldsymbol{a}}^{(k)}(\X,{\mu_1},\mu_2)
\end{equation}
Given the  displacement $\ud_0$ at the previous step, the full displacement is then
\begin{equation}
\displaystyle
\ud(\X,{\mu_1},\mu_2)=\ud_0(\X,{\mu_1},\mu_2)+ \Delta\ud(\X,{\mu_1},\mu_2)
\end{equation}
and for the test function 
\begin{equation}
\displaystyle
{{\ud}^{*}}=\Delta\ud^*
\end{equation}
The weak form \eqref{eq:weakform} of the problem  becomes
\begin{equation}
\displaystyle
-\int_{\Omega_\X\times\Omega_{\mu_1}\times\Omega_{\mu_2}}{\sig(\ud_0+\Delta\ud) :\eps ({\Delta{\ud}^{*}})d\X d\mu_1d\mu_2}+\int_{\partial_{\textbf{F}} {{\Omega_\X}}\times\Omega_{\mu_1}\times\Omega_{\mu_2}}{\bar{\textbf{d}}\cdot{\Delta{\ud}^{*}}dsd\mu_1d\mu_2=0}
\end{equation}
Considering that $\bar{\textbf{d}}=\bar{\textbf{d}}_0+\Delta\bar{\textbf{d}}$ with $\bar{\textbf{d}}_0$ denoting the previous loading, we have 
\begin{equation}
\displaystyle
-\int_{\Omega_\X\times\Omega_{\mu_1}\times\Omega_{\mu_2}}{\sig(\ud_0) :\eps ({\Delta{\ud}^{*}})d\X d\mu_1d\mu_2}+\int_{\partial_{\textbf{F}} {{\Omega_\X}}\times\Omega_{\mu_1}\times\Omega_{\mu_2}}{\bar{\textbf{d}}_0\cdot{\Delta{\ud}^{*}}ds d\mu_1d\mu_2=0}
\end{equation}
Therefore, the following equation should be satisfied
\begin{equation}
\displaystyle
-\int_{\Omega_\X\times\Omega_{\mu_1}\times\Omega_{\mu_2}}{\Delta\sig :\eps ({\Delta{\ud}^{*}})d\X d\mu_1d\mu_2}+\int_{\partial_{\textbf{F}} {{\Omega_\X}}\times\Omega_{\mu_1}\times\Omega_{\mu_2}}{\Delta\bar{\textbf{d}}\cdot{\Delta{\ud}^{*}}ds d\mu_1d\mu_2=0}
\end{equation}
With $\Delta\sig=\textbf{D}:(\Delta\eps -\Delta\epsp)$ and $\Omega=\Omega_\X\times\Omega_{\mu_1}\times\Omega_{\mu_2}$ and $\partial_{\textbf{F}}\Omega=\partial_{\textbf{F}} {{\Omega_\X}}\times\Omega_{\mu_1}\times\Omega_{\mu_2}$
\begin{equation}
\displaystyle
\label{eq:weakincrementform}
-\int_{\Omega}{\textbf{D}:(\Delta\eps -\Delta\epsp):\eps ({\Delta{\ud}^{*}})d\X d\mu_1d\mu_2}+\int_{\partial_{\textbf{F}} {{\Omega}}}{\Delta\bar{\textbf{d}}\cdot{\Delta{\ud}^{*}}ds d\mu_1d\mu_2=0}
\end{equation}

\subsection{Compute initial separated modes with $\Tilde{\boldsymbol{a}}^{(k)}=0$ \label{initialsepmode}}
Now, we can start from computing some separated modes of XTD by solving the above problem. Following the incremental strategy explained in \ref{XTDdata}, we start from
$M=1, K=1$. In this case, 
\begin{equation}
\displaystyle
\Delta\ud(\X,{\mu_1},\mu_2)= \boldsymbol{a}^{(1)}(\X)g_1^{(1)}(\mu_1)g_2^{(1)}(\mu_2) + \Tilde{\boldsymbol{a}}^{(1)}
\end{equation}
\begin{equation}
\displaystyle
\Delta\ud^*= \boldsymbol{a}^{(1)*}g_1^{(1)}g_2^{(1)}+\boldsymbol{a}^{(1)}g_1^{(1)*}g_2^{(1)}+\boldsymbol{a}^{(1)}g_1^{(1)}g_2^{(1)*}+ \Tilde{\boldsymbol{a}}^{(1)*}
\end{equation}
Given the initial $\Tilde{\boldsymbol{a}}^{(1)}=0$, then
\begin{equation}
\displaystyle
\Delta\ud(\X,{\mu_1},\mu_2)= \boldsymbol{a}^{(1)}(\X)g_1^{(1)}(\mu_1)g_2^{(1)}(\mu_2) 
\end{equation}
\begin{equation}
\displaystyle
\Delta\ud^*= \boldsymbol{a}^{(1)*}g_1^{(1)}g_2^{(1)}+\boldsymbol{a}^{(1)}g_1^{(1)*}g_2^{(1)}+\boldsymbol{a}^{(1)}g_1^{(1)}g_2^{(1)*}
\end{equation}
For notation simplification, we omit the superscripts
\begin{equation}
\displaystyle
\Delta\ud(\X,{\mu_1},\mu_2)= \boldsymbol{a}(\X)g_1(\mu_1)g_2(\mu_2) 
\end{equation}
\begin{equation}
\displaystyle
\Delta\ud^*= \boldsymbol{a}^{*}g_1 g_2+\boldsymbol{a} g_1^{*}g_2+\boldsymbol{a}g_1g_2^{*}
\end{equation}
Now we solve first $\boldsymbol{a}$ by fixing $g_1, g_2$ as a constant. Hence, $g_1^{*}=0, g_2^{*}=0$.
\begin{equation}
\displaystyle
\Delta\ud^*= \boldsymbol{a}^{*}g_1g_2
\end{equation}
Assuming $\Delta\epsp=0$ and considering the FE discretization for $\boldsymbol{a}(\X)$
\begin{equation}
\displaystyle
\boldsymbol{a}(\X)=\textbf{N}(\X)\boldsymbol{\mathcal{A}} 
\end{equation}
The \eqref{eq:weakincrementform} becomes
\begin{equation}
\displaystyle
-\int_{\Omega}{g_2^{T} g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\textbf{B}^T\textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}g_1g_2\ d\X d\mu_1d\mu_2}+\int_{\partial_{\textbf{F}} {{\Omega}}}{g_2^{T} g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\textbf{N}^T\Delta\bar{\textbf{d}}\ ds d\mu_1d\mu_2=0}
\end{equation}
Here we assume that the stiffness  $\textbf{D}$ is independent of design parameters, and the external load has been separated and can be approximated by one mode, i.e. $\Delta\bar{\textbf{d}}=\textbf{f}_\X(\X) \text{f}_{\mu_1}({\mu_1})\text{f}_{\mu_2}({\mu_2})$. By rearrangement, the above equation reads
\begin{equation}
\displaystyle
\begin{aligned}
\int_{\Omega_\X}{ \boldsymbol{\mathcal{A}}^{*T}\textbf{B}^T\textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}\ d\X \int_{\Omega_{\mu_1}}g_1^{T}g_1\ d\mu_1 \int_{\Omega_{\mu_2}} g_2^{T}g_2\  d\mu_2}\\
=\int_{\partial_{\textbf{F}} {{\Omega_\X}}}{ \boldsymbol{\mathcal{A}}^{*T}\textbf{N}^T\textbf{f}_\X\ ds \int_{\Omega_{\mu_1}} g_1^{T}\text{f}_{\mu_1} \ d\mu_1 \int_{\Omega_{\mu_2}} g_2^{T}\text{f}_{\mu_2}\  d\mu_2}
\end{aligned}
\end{equation}
The final discretized form for solving $\boldsymbol{a}$ is obtained as
\begin{equation}
\displaystyle
\begin{aligned}
\textbf{K}\boldsymbol{\mathcal{A}} \boldsymbol{g}_1^{T}\boldsymbol{g}_1 \boldsymbol{g}_2^{T}\boldsymbol{g}_2
={\textbf{F}_\X }{  \boldsymbol{g}_1^{T}\textbf{F}_{\mu_1}  \boldsymbol{g}_2^{T}\textbf{F}_{\mu_2} }
\end{aligned}
\end{equation}
and
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{\mathcal{A}} 
=\textbf{K}^{-1}{\textbf{F}_\X }{  \boldsymbol{g}_1^{T}\textbf{F}_{\mu_1}  \boldsymbol{g}_2^{T}\textbf{F}_{\mu_2} }(\boldsymbol{g}_1^{T}\boldsymbol{g}_1 \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}
\end{aligned}
\end{equation}
with 
\begin{equation}
\displaystyle
\begin{aligned}
&\textbf{F}_\X =\int_{\partial_{\textbf{F}} {{\Omega_\X}}}{ \textbf{N}^T\textbf{f}_\X\ ds }\\
&\textbf{F}_{\mu_1} = \text{f}_{\mu_1}(\Omega_{\mu_1}^h)  \\ 
&\textbf{F}_{\mu_2}  = \text{f}_{\mu_2}(\Omega_{\mu_2}^h)
\end{aligned}
\end{equation}
where $\Omega_{\mu_1}^h$ and $\Omega_{\mu_2}^h$ denote respectively the supporting mesh in each parameter domain.

After updating $\boldsymbol{a}$, we solve then $g_1$ by fixing $\boldsymbol{a}, g_2$ as a constant. Hence, $\boldsymbol{a}^{*}=0, g_2^{*}=0$.
\begin{equation}
\displaystyle
\Delta\ud^*= \boldsymbol{a}g_1^{*}g_2
\end{equation}
Following the same concept as previously, the final discretized form reads
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}} \boldsymbol{g}_1 \boldsymbol{g}_2^{T}\boldsymbol{g}_2
=\boldsymbol{\mathcal{A}}^T{\textbf{F}_\X }{  \textbf{F}_{\mu_1}  \boldsymbol{g}_2^{T}\textbf{F}_{\mu_2} }
\end{aligned}
\end{equation}
and
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{g}_1
=(\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\boldsymbol{\mathcal{A}}^T{\textbf{F}_\X }{  \textbf{F}_{\mu_1}  \boldsymbol{g}_2^{T}\textbf{F}_{\mu_2} }( \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}
\end{aligned}
\end{equation}

Similarly we solve  $g_2$ by fixing $\boldsymbol{a}, g_1$ as a constant. The final discrete equation is
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{g}_2
=(\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\boldsymbol{\mathcal{A}}^T{\textbf{F}_\X }{  \boldsymbol{g}_1^{T}\textbf{F}_{\mu_1}  \textbf{F}_{\mu_2} }( \boldsymbol{g}_1^{T}\boldsymbol{g}_1)^{-1}
\end{aligned}
\end{equation}
The alternating solution procedure is iteratively performed until $\|\Delta \boldsymbol{\mathcal{A}}\otimes \boldsymbol{g}_1 \otimes \boldsymbol{g}_2\|$ converges. 

When the first mode is obtained, we can continue to solve for more modes. In the case of $M\geq2$, the $M-1$ modes have been known, the current unknown is again denoted by $\boldsymbol{a},g_1,g_2$. We have 
\begin{equation}
\displaystyle
\Delta\ud(\X,{\mu_1},\mu_2)= \sum_{m=1}^{M-1}\boldsymbol{a}^{(m)}(\X)g_1^{(m)}(\mu_1)g_2^{(m)}(\mu_2) + \boldsymbol{a}(\X)g_1(\mu_1)g_2(\mu_2)
\end{equation}
with the test function
\begin{equation}
\displaystyle
\Delta\ud^*= \boldsymbol{a}^{*}g_1 g_2+\boldsymbol{a} g_1^{*}g_2+\boldsymbol{a}g_1g_2^{*}
\end{equation}
The alternating algorithm gives 
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{\mathcal{A}} 
=\ &\textbf{K}^{-1}{\textbf{F}_\X }{  \boldsymbol{g}_1^{T}\textbf{F}_{\mu_1}  \boldsymbol{g}_2^{T}\textbf{F}_{\mu_2} }(\boldsymbol{g}_1^{T}\boldsymbol{g}_1 \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}\\
&-\textbf{K}^{-1}\sum_{m=1}^{M-1}\textbf{K}\boldsymbol{\mathcal{A}}^{(m)} \boldsymbol{g}_1^{T}\boldsymbol{g}_1^{(m)}\boldsymbol{g}_2^{T}\boldsymbol{g}_2^{(m)}(\boldsymbol{g}_1^{T}\boldsymbol{g}_1 \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}
\end{aligned}
\end{equation}
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{g}_1
=(&\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\boldsymbol{\mathcal{A}}^T{\textbf{F}_\X }{  \textbf{F}_{\mu_1}  \boldsymbol{g}_2^{T}\textbf{F}_{\mu_2} }( \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}\\
&-(\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\sum_{m=1}^{M-1}\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}}^{(m)}\boldsymbol{g}_1^{(m)}\boldsymbol{g}_2^{T}\boldsymbol{g}_2^{(m)}(\boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}
\end{aligned}
\end{equation}
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{g}_2
=(&\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\boldsymbol{\mathcal{A}}^T{\textbf{F}_\X }{  \boldsymbol{g}_1^{T}\textbf{F}_{\mu_1}  \textbf{F}_{\mu_2} }( \boldsymbol{g}_1^{T}\boldsymbol{g}_1)^{-1}\\
&-(\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\sum_{m=1}^{M-1}\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}}^{(m)}\boldsymbol{g}_1^{T}\boldsymbol{g}_1^{(m)}\boldsymbol{g}_2^{(m)}(\boldsymbol{g}_1^{T}\boldsymbol{g}_1)^{-1}
\end{aligned}
\end{equation}
The number of modes keeps increasing until the convergence  
\begin{equation}
\displaystyle
\label{eq:XTDROMmodeconverg}
\frac{\|\boldsymbol{\mathcal{A}}\otimes \boldsymbol{g}_1 \otimes \boldsymbol{g}_2\|_\infty}{\|\Delta\ud\|_\infty}\leq\epsilon_M
\end{equation}
\subsection{Compute the extended mode}
Once the first set of separated modes is computed, we can solve the extended mode by updating the plastic strain $\epsp$ and $\Delta\epsp$.

Taking the current displacement increment as an estimate $\Delta \ud^{(0)}$
\begin{equation}
\displaystyle
\Delta\ud^{(0)}(\X,{\mu_1},\mu_2)= \Delta \ud
\end{equation}
we can check the local plastic region $\Omega_{\text{pl}}$ where $\Delta\epsp(\X,{\mu_1},\mu_2)\neq 0$.  This can be done using standard FE implementation for plasticity with a point-wise evaluation in the global domain $\Omega$.

The Newton-Raphson method is then used to update the plastic strain and the displacement in $\Omega_{\text{pl}}$ with the boundary condition imposed by the remaining region. The updated displacement increment $\Delta \ud$ should satisfy that
\begin{equation}
    \displaystyle
    {{\Fm}_{\text{ext}}(\ud_0+\Delta \ud)-{\Fm}_{\text{int}}(\ud_0+\Delta \ud)=0 \quad \text{in}\quad \Omega_{\text{pl}} \quad \text{with } \quad \Delta\ud|_{\partial \Omega_{\text{pl}} }=\Delta\ud|_{\partial \Omega_{\text{el}} }}
\end{equation}
where ${\Fm}_{\text{ext}}$ and ${\Fm}_{\text{int}}$ are computed with \eqref{eq:FEforce}. This solution can be solved easily in a parallel way. 

The sparse extended mode is obtained with
\begin{equation}
\displaystyle
\Tilde{\boldsymbol{a}}^{(K)}(\X,{\mu_1},\mu_2)= \Delta \ud - \Delta\ud^{(0)}(\X,{\mu_1},\mu_2)
\end{equation}
Since $\Delta \ud$ is locally updated, the extended mode is sparse.

An another outcome of this step is the updated plastic strain and the induced internal force, i.e.
\begin{equation}
\displaystyle
\textbf{F}_{\text{pl}}({\mu_1},\mu_2), \quad \Delta\textbf{F}_{\text{pl}}({\mu_1},\mu_2)
\end{equation}
as computed by \eqref{eq:Fpl}, which is also sparse.

\subsection{Enrich separated modes with $\Tilde{\boldsymbol{a}}^{(k)}\neq0$}
With the updated extended mode, we can keep increasing the number of separated modes $M$. Again, the new mode is denoted by $\boldsymbol{a},g_1,g_2$. 
\begin{equation}
\displaystyle
\Delta\ud(\X,{\mu_1},\mu_2)= \sum_{m=1}^{M-1}\boldsymbol{a}^{(m)}g_1^{(m)}g_2^{(m)} + \boldsymbol{a}g_1g_2 +\sum_{k=1}^{K}\Tilde{\boldsymbol{a}}^{(k)}
\end{equation}
with the test function
\begin{equation}
\displaystyle
\Delta\ud^*= \boldsymbol{a}^{*}g_1 g_2+\boldsymbol{a} g_1^{*}g_2+\boldsymbol{a}g_1g_2^{*}
\end{equation}

Now, we solve $\boldsymbol{a}$  by fixing the others. The \eqref{eq:weakincrementform} becomes
\begin{equation}
\displaystyle
\begin{aligned}
&\int_{\Omega}{g_2^{T} g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\sum_{m=1}^{M-1}\textbf{B}^T \textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}^{(m)}g_1^{(m)}g_2^{(m)}\ d\X d\mu_1d\mu_2}\\
&+\int_{\Omega}{g_2^{T} g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\textbf{B}^T\textbf{D}\textbf{B}\boldsymbol{\mathcal{A}}g_1g_2\ d\X d\mu_1d\mu_2}\\
&+\int_{\Omega}{g_2^{T} g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\sum_{k=1}^{K}\textbf{B}^T \textbf{D}\textbf{B}\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}\ d\X d\mu_1d\mu_2}\\
&-\int_{\Omega_{\boldsymbol{\mu}}}{g_2^{T} g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\Delta\textbf{F}_{\text{pl}}\ d\mu_1d\mu_2}\\
&=\int_{\partial_{\textbf{F}} {{\Omega}}}{g_2^{T} g_1^{T}\boldsymbol{\mathcal{A}}^{*T}\textbf{N}^T\Delta\bar{\textbf{d}}\ ds d\mu_1d\mu_2}
\end{aligned}
\end{equation}
where $\Omega_{\boldsymbol{\mu}}$ denotes $\Omega_{{\mu}_1}\times \Omega_{\mu_2}$. As we can see, $\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}$ and $\Delta\textbf{F}_{\text{pl}}$ are not naturally separated,  the third and the forth terms in above equation require the so-called full integration. Nevertheless, since they are sparse and the integration can be done by simple vector and matrix multiplications, the associated cost remains still low from authors' experience. 

Thus the solution is 
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{\mathcal{A}} 
=\ &\textbf{K}^{-1}{\textbf{F}_\X }{  \boldsymbol{g}_1^{T}\textbf{F}_{\mu_1}  \boldsymbol{g}_2^{T}\textbf{F}_{\mu_2} }(\boldsymbol{g}_1^{T}\boldsymbol{g}_1 \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}\\
&-\textbf{K}^{-1}\sum_{m=1}^{M-1}\textbf{K}\boldsymbol{\mathcal{A}}^{(m)} \boldsymbol{g}_1^{T}\boldsymbol{g}_1^{(m)}\boldsymbol{g}_2^{T}\boldsymbol{g}_2^{(m)}(\boldsymbol{g}_1^{T}\boldsymbol{g}_1 \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}\\
&-\textbf{K}^{-1}\textbf{Q}_{\boldsymbol{\Tilde{\boldsymbol{\mathcal{A}}}\mathcal{A}}}(\boldsymbol{g}_1^{T}\boldsymbol{g}_1 \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}+\textbf{K}^{-1}\textbf{Q}_{\boldsymbol{{\text{pl}}\mathcal{A}}}(\boldsymbol{g}_1^{T}\boldsymbol{g}_1 \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}
\end{aligned}
\end{equation}
with
\begin{equation}
\displaystyle
\begin{aligned}
&\textbf{Q}_{\boldsymbol{\Tilde{\boldsymbol{\mathcal{A}}}\mathcal{A}}}=\int_{\Omega}{g_2^{T} g_1^{T}\sum_{k=1}^{K}\textbf{B}^T \textbf{D}\textbf{B}\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}\ d\X d\mu_1d\mu_2}\\
&\textbf{Q}_{\boldsymbol{{\text{pl}}\mathcal{A}}}=\int_{\Omega_{\boldsymbol{\mu}}}{g_2^{T} g_1^{T}\Delta\textbf{F}_{\text{pl}}\ d\mu_1d\mu_2}
\end{aligned}
\end{equation}

Analogically, the alternating algorithm gives 
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{g}_1
=(&\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\boldsymbol{\mathcal{A}}^T{\textbf{F}_\X }{  \textbf{F}_{\mu_1}  \boldsymbol{g}_2^{T}\textbf{F}_{\mu_2} }( \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}\\
&-(\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\sum_{m=1}^{M-1}\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}}^{(m)}\boldsymbol{g}_1^{(m)}\boldsymbol{g}_2^{T}\boldsymbol{g}_2^{(m)}(\boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}\\
&-(\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\textbf{Q}_{\boldsymbol{\Tilde{\boldsymbol{\mathcal{A}}}\boldsymbol{g}_1}}( \boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}+\textbf{K}^{-1}\textbf{Q}_{\boldsymbol{{\text{pl}}\boldsymbol{g}_1}}(\boldsymbol{g}_2^{T}\boldsymbol{g}_2)^{-1}
\end{aligned}
\end{equation}
with
\begin{equation}
\displaystyle
\begin{aligned}
&\textbf{Q}_{\boldsymbol{\Tilde{\boldsymbol{\mathcal{A}}}\boldsymbol{g}_1}}=\int_{\Omega}{g_2^{T} \boldsymbol{\mathcal{A}}^{T}\sum_{k=1}^{K}\textbf{B}^T \textbf{D}\textbf{B}\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}\ d\X d\mu_1d\mu_2}\\
&\textbf{Q}_{\boldsymbol{{\text{pl}}\boldsymbol{g}_1}}=\int_{\Omega_{{\mu}_2}}{g_2^{T} \boldsymbol{\mathcal{A}}^{T}\Delta\textbf{F}_{\text{pl}}\ d\mu_2}
\end{aligned}
\end{equation}

and
\begin{equation}
\displaystyle
\begin{aligned}
\boldsymbol{g}_2
=(&\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\boldsymbol{\mathcal{A}}^T{\textbf{F}_\X }{  \boldsymbol{g}_1^{T}\textbf{F}_{\mu_1}  \textbf{F}_{\mu_2} }( \boldsymbol{g}_1^{T}\boldsymbol{g}_1)^{-1}\\
&-(\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\sum_{m=1}^{M-1}\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}}^{(m)}\boldsymbol{g}_1^{T}\boldsymbol{g}_1^{(m)}\boldsymbol{g}_2^{(m)}(\boldsymbol{g}_1^{T}\boldsymbol{g}_1)^{-1}\\
&-(\boldsymbol{\mathcal{A}}^T\textbf{K}\boldsymbol{\mathcal{A}})^{-1}\textbf{Q}_{\boldsymbol{\Tilde{\boldsymbol{\mathcal{A}}}\boldsymbol{g}_2}}( \boldsymbol{g}_1^{T}\boldsymbol{g}_1)^{-1}+\textbf{K}^{-1}\textbf{Q}_{\boldsymbol{{\text{pl}}\boldsymbol{g}_2}}(\boldsymbol{g}_1^{T}\boldsymbol{g}_1)^{-1}
\end{aligned}
\end{equation}
with
\begin{equation}
\displaystyle
\begin{aligned}
&\textbf{Q}_{\boldsymbol{\Tilde{\boldsymbol{\mathcal{A}}}\boldsymbol{g}_2}}=\int_{\Omega}{g_1^{T} \boldsymbol{\mathcal{A}}^{T}\sum_{k=1}^{K}\textbf{B}^T \textbf{D}\textbf{B}\Tilde{\boldsymbol{\mathcal{A}}}^{(k)}\ d\X d\mu_1d\mu_2}\\
&\textbf{Q}_{\boldsymbol{{\text{pl}}\boldsymbol{g}_2}}=\int_{\Omega_{{\mu}_1}}{g_1^{T} \boldsymbol{\mathcal{A}}^{T}\Delta\textbf{F}_{\text{pl}}\ d\mu_1}
\end{aligned}
\end{equation}

A similar iterative procedure to \ref{initialsepmode} is then applied for this enrichment step.
The converged number of the modes is also determined by \ref{eq:XTDROMmodeconverg}.


\subsection{Overall convergence criterion}
The enrichment can be performed alternatively for the separated modes and extended modes until the following global convergence criterion is satisfied.
\begin{equation}
\displaystyle
\label{eq:XTDROMallconverg}
\frac{\|\Tilde{\boldsymbol{a}}^{(K)}\|_\infty}{\|\Delta\ud\|_\infty}\leq\epsilon_{\text{XTD}}
\end{equation}




%{\section{Formulation of the coupled XTD-SCA method}\label{SCA}}


%% References with bibTeX database:
\bibliographystyle{model1-num-names}
\bibliography{XTD.bib}

 

%% Authors are advised to submit their bibtex database files. They are
%% requested to list a bibtex style file in the manuscript if they do
%% not want to use model1-num-names.bst.

%% References without bibTeX database:

% \begin{thebibliography}{00}

%% \bibitem must have the following form:
%%   \bibitem{key}...
%%

% \bibitem{}

% \end{thebibliography}

\end{document}

%%
%% End of file `elsarticle-template-1-num.tex'.