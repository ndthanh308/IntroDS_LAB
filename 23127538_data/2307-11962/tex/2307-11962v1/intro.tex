\section{INTRODUCTION}

Single-input single-output (SISO) deep neural networks (DNNs) have demonstrated impressive performance in various robotics applications~\cite{deng2020self, meng2019neural, yang2022instinctive, su2022uncertainty}. However, multi-input single-output (MISO) DNNs have emerged as a promising alternative, as they have been shown to surpass SISO DNNs both theoretically and empirically~\cite{DBLP:journals/corr/abs-2208-10442,DBLP:conf/nips/VaswaniSPUJGKP17,DBLP:journals/corr/abs-2205-06175,DBLP:conf/iccv/HuS21}. Developing MISO DNNs is a crucial step towards creating multi-input multi-output (MIMO) DNNs for intelligent embedded systems, especially in the field of robotics.


In order to create truly intelligent robots, they should be capable of processing a person's spoken language and facial expressions in real-time and provide tailored feedback based on factors such as gender and emotion. Interactive companion robots, like the Vector Robot~\cite{bib:vector}, are expected to receive camera and microphone inputs and use this information to predict user preferences and respond appropriately. In on-device learning scenarios with strict hardware constraints and performance requirements, deploying multi-input multi-output (MIMO) deep neural networks (DNNs) can be advantageous. By reducing the need to deploy multiple single-input single-output (MISO) DNN instances on the device, MIMO DNNs can significantly lower resource demands. This paper presents \tool, a novel on-device MIMO DNN framework that achieves both high accuracy and on-device efficiency in terms of critical performance metrics including latency, energy, and memory usage. 
We first constructed a baseline MIMO DNN model and observed that it requires high memory consumption and struggles to meet real-time constraints due to computational demand. To minimize resource demands, \tool builds on an existing DNN model compression technique, VIB~\cite{VIB}, which is effective for single-input single-output (SISO) DNN models. However, extending VIB to MIMO DNN models posed two new challenges. First, VIB exclusively supports the compression of feed-forward networks~\cite{Feed-Forward}, which makes it unsuitable for more advanced networks, such as ResNet~\cite{ResNet}. To address this limitation, \tool extends and develops a modified compression method for ResNet with residual blocks. Second, VIB was not designed to handle MIMO scenarios and did not account for the unique characteristics of MIMO models. VIB focuses on reducing intra-model redundancy but is unable to address common inter-model redundancy in MIMO models. To address this issue, \tool develops a new deep-compression method that reduces both inter- and intra-model redundancy, resulting in deeper lossless compression for MIMO scenarios.

We present a two-fold evaluation of \tool to demonstrate its accuracy and on-device efficiency. In the first set of experiments, we evaluated the accuracy of \tool by comparing it to state-of-the-art SISO and MISO models, as well as a baseline MIMO model, using the RAVDESS multimodal dataset~\cite{RAVDESS}. Our results show that \tool consistently outperforms SISO, MISO, and the baseline MIMO model in terms of accuracy, achieving improvements of 13.1\%, 2.2\%, and 1.0\%, respectively. The superiority of \tool's performance is attributed to its deep-compression method, which reduces both inter- and intra-model redundancy in MIMO settings, resulting in deeper lossless compression.
%
In the second set of experiments, we conducted an extensive evaluation of \tool's on-device efficiency in terms of latency, energy, and memory usage. We deployed \tool on three widely used embedded system platforms: NVIDIA Jetson Nano, NVIDIA Jetson TX2, and NVIDIA AGX Xavier, which are popular platforms for various robotics applications~\cite{deng2020self, meng2019neural, yang2022instinctive,guo2023backdoor} such as Duckiebot~\cite{Duckiebot(DB-J)}, SparkFun Jetbot~\cite{SparkFun_JetBot}, and Waveshare Jetbot~\cite{Waveshare_JetBot}. In addition, we evaluated \tool on a PC machine for a more comprehensive assessment.
In summary, experimental results demonstrate that \tool can achieve:


\begin{itemize}[leftmargin=10px]
\item \textbf{Reduced Memory Usage:} \tool significantly reduces runtime memory usage by 31.0\% compared to the baseline Multiple-Input Multiple-Output (MIMO) model.
\item \textbf{Improved Inference Speed:} \tool exhibits speed-ups of 1.44x, 1.80x, 5.64x, and 3.13x compared to the baseline MIMO model when tested on Nano, AGX, TX2, and PC, respectively.
\item \textbf{Enhanced Energy Efficiency:} The energy savings offered by \tool are 1.69x, 1.90x, and 5.18x compared to the baseline MIMO model when tested on Nano, AGX, and TX2, respectively.
\end{itemize}

In addition to our two-fold evaluation, we conducted a realistic case study using the TurtleBot3 robot to demonstrate the real-world applicability of our proposed approach. Specifically, we evaluated scenarios involving face and audio recognition for interactive emotional robots in a cluttered environment. The results of this case study further validate the superiority of our proposed MIMO model over state-of-the-art SISO and MISO models in terms of accuracy and on-device efficiency. Moreover, we provide visual demonstrations to highlight the effectiveness of our approach in real-world scenarios, demonstrating its practical relevance for interactive robotic systems.

Our contributions can be summarized as follows:

\begin{itemize}[leftmargin=10px]
    \item \textbf{Innovative MIMO Framework for robotics:} To the best of our knowledge, \tool is one of the first frameworks that utilizes a unified neural network to process multiple inputs and produce multiple outputs simultaneously. This framework is designed to address the intricate inference tasks that are crucial in the context of robotics scenarios.
    \item \textbf{New Deep-Compression Method:} \tool introduces a new deep-compression method tailored to enhance the accuracy and on-device efficiency of MIMO framework for robotic applications.
    \item \textbf{Extensive Experimental Results:} Our experiments on three embedded platforms and one PC platform demonstrate that \tool achieves high accuracy while delivering superior on-device efficiency in terms of latency, energy, and memory usage. These features make \tool an appealing choice for many practical on-device learning scenarios, notably for robots that operate under stringent hardware and performance constraints.
\end{itemize}