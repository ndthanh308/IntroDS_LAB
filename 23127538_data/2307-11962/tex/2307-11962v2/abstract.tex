% \zx{robotic experiments on e.g., autonomous driving datasets.}
% \zx{rewrite use robotic community language.}
% \zx{add post-training quantization baseline; add some basic ruled-based pruning baseline.}
% \zx{clarification of methodology and rewrite @xiaoxi}
% \zx{rewrite the setting of experiments.}
% \zx{contain more in related work and discussion of multimodal processing and quantization and pruning work.}
% \zx{consider adding a multimodal dataset( music localization dataset)s}
% \zx{describe why paramater number reduces a lot but end-to-end memory consumption reduce not that much.}
% \zx{proofread on Tue. and Wed.}
Future intelligent robots are expected to process multiple inputs simultaneously (such as image and audio data) and generate multiple outputs accordingly (such as gender and emotion), similar to humans. Recent research has shown that multi-input single-output (MISO) deep neural networks (DNN) outperform traditional single-input single-output (SISO) models, representing a significant step towards this goal. In this paper, we propose \tool, a novel on-device multi-input multi-output (MIMO) DNN framework that achieves high accuracy and on-device efficiency in terms of critical performance metrics such as latency, energy, and memory usage. Leveraging existing SISO model compression techniques, \tool develops a new deep-compression method that is specifically tailored to MIMO models. This new method explores unique yet non-trivial properties of the MIMO model, resulting in boosted accuracy and on-device efficiency. Extensive experiments on three embedded platforms commonly used in robotic systems, as well as a case study using the TurtleBot3 robot, demonstrate that \tool achieves higher accuracy and superior on-device efficiency compared to state-of-the-art SISO and MISO models, as well as a baseline MIMO model we constructed. Our evaluation highlights the real-world applicability of \tool and its potential to significantly enhance the performance of intelligent robotic systems.