

\section{BACKGROUND and RELATED WORK}
\subsection{MIMO Architecture}

% \zx{need to distinguish MIMO and MISO in this paragraph, at least saying MISO is a special case of MIMO}
% \zx{refer to \url{https://pub.tik.ee.ethz.ch/people/thiele/paper/diss_he.pdf}}

% Classical deep neural networks are designed in single-input single-output (SISO) structures~\cite{deng2020self, meng2019neural, yang2022instinctive, su2022uncertainty}, expected to receive one input and generate one output at one time. With the growth of deep learning, some DNNs are extended to be able to deal with multiple inputs from different domains to get better accuracy performance~\cite{he2022towards,DBLP:journals/corr/abs-2208-10442,DBLP:journals/corr/abs-2205-06175,DBLP:conf/iccv/HuS21,DBLP:journals/corr/abs-2208-10442,DBLP:journals/corr/abs-2205-06175,DBLP:conf/iccv/HuS21}, which is also known as multimodal learning~\cite{zhang2016multimodal} and
% multi-view learning~\cite{zhao2017multi}. We name this kind of network a multi-input single-output (MISO) network. Moreover, state-of-the-art models~\cite{hu2022goal,liu2022bevfusion,huang2023fuller} further extend MISO to multi-input-multi-output (MIMO), aiming to generate multiple outputs simultaneously in one inference. \zx{this MIMO is widely used in autonomous driving~\cite{liu2022bevfusion,huang2023fuller} and robotic navigation~\cite{10405986}. However, these methods have significant memory and computation resource requirements, and few work like BEVFusion~\cite{liu2022bevfusion} addresses performance bottlenecks by proposing efficient data processing for sensors. To address these challenges, our work focuses on compressing models to ensure real-world deployability. }

Classical deep neural networks typically follow a single-input single-output (SISO) format, designed to process one input and produce one output at a time. However, as deep learning has evolved, certain networks have been adapted to handle multiple inputs from varied domains, enhancing accuracy. This approach, often referred to as multimodal learning~\cite{zhang2016multimodal} or multi-view learning~\cite{zhao2017multi}, leads to what is termed multi-input single-output (MISO) networks~\cite{DBLP:journals/corr/abs-2208-10442,DBLP:journals/corr/abs-2205-06175,DBLP:conf/iccv/HuS21,he2022towards}.
Building on this, models with advanced accuracies have progressed to multi-input-multi-output (MIMO) configurations~\cite{havasi2020training}, which are capable of generating several outputs in one go. This MIMO technology is particularly beneficial in fields like autonomous driving~\cite{liu2022bevfusion,huang2023fuller} and robotic navigation~\cite{chaplot2019embodied}, although it does come with substantial demands on memory and computational resources. Few concurrent works like BEVFusion~\cite{liu2022bevfusion}, try to alleviate these demands by optimizing data processing from sensors to mitigate performance issues.
Different from these works, our study aims to tackle these challenges by focusing on model compression to facilitate practical deployment in real-world scenarios.

% Current multimodal methods that jointly solve different tasks across domains using a shared model are limited to processing only one task or modality at a time, mostly employing multi-input single-output (MISO)~\cite{DBLP:journals/corr/abs-2208-10442,DBLP:journals/corr/abs-2205-06175,DBLP:conf/iccv/HuS21} or single-input single-output (SISO)~\cite{deng2020self, meng2019neural, yang2022instinctive, su2022uncertainty} architectures that are difficult to compress and may cause memory and energy consumption issues when used in on-device embedded systems. Existing state-of-the-art models such as BEiT-3~\cite{DBLP:journals/corr/abs-2208-10442}, Gato~\cite{DBLP:journals/corr/abs-2205-06175}, and UniT~\cite{DBLP:conf/iccv/HuS21} are examples of such models. On the other hand, concurrent multi-input multi-output (MIMO) works in the field include UniAD~\cite{hu2022goal} and BEVFusion~\cite{liu2022bevfusion}, which propose state-of-the-art solutions for multiple autonomous driving tasks and multi-task multi-sensor fusion, respectively. However, these methods have significant memory and computation resource requirements, and BEVFusion addresses performance bottlenecks by proposing an efficient Bird's Eye View (BEV) pooling strategy for sensors. To address these challenges, our work focuses on compressing models to ensure real-world deployability.

\subsection{Model Compression for On-device Scenarios}

Modern DNNs, like the ViT-Huge~\cite{wu2020visual} and GPT-3~\cite{brown2020language}, although achieving state-of-the-art accuracy strain memory and computation resources for resource-constrained devices during inferences.
A practical solution to mitigate such an issue is model compression, which aims to reduce model parameter count without affecting accuracy. 
They can involve removing redundant parameters \cite{VIB,MTZ,bib:NIPS17:Dong,bib:NIPS93:Hassibi,bib:TMC21:Liu} or minimizing redundant precision \cite{bib:NIPS15:Courbariaux}.
Two subclasses of model compression for multi-branch models consist of single-model pruning and cross-model compression. The former compresses a single network by eliminating unnecessary operations and parameters, while the latter minimizes inter-model redundancy by identifying and removing shared parameters and operations across models \cite{VIB,MTZ,bib:NIPS17:Dong,bib:NIPS93:Hassibi,bib:CVPR19:Molchanov,bib:PIEEE20:Deng,bib:KDD21:He,bib:IJCAI18:Chou}. Notably, the Multi-Task Zipping (MTZ) approach has pioneered cross-model compression by automating the merging of pre-trained DNNs \cite{MTZ}.
However, \tool leverages the Variational Information Bottleneck (VIB) method to reduce intra-model redundancy, extending it for application to ResNet architecture. Furthermore, it adapts modified MTZ to reduce inter-model redundancy, which further
decrease the total parameters in the proposed MIMO model.