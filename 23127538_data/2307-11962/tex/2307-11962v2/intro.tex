\section{INTRODUCTION}

Single-input single-output (SISO) deep neural networks (DNNs) have demonstrated impressive performance in various robotics applications~\cite{deng2020self, meng2019neural, yang2022instinctive, su2022uncertainty}. However, multi-input single-output (MISO) DNNs have emerged as a promising alternative, as they have been shown to surpass SISO DNNs both theoretically and empirically~\cite{DBLP:journals/corr/abs-2208-10442,DBLP:journals/corr/abs-2205-06175,DBLP:conf/iccv/HuS21}. Developing MISO DNNs is a crucial step towards creating multi-input multi-output (MIMO) DNNs for intelligent embedded systems, especially in the field of robotics.

% \textcolor{red}{Since this work seems to be focused on model
% compression, I would suggest re-wording the introduction to
% not imply that the compression leads to speed improvement
% -- it is better to state that a MIMO approach is inherently
% faster as it only requires one forward pass. The bigger
% contribution seems to be memory reduction, focus on that.}

According to Stanford’s ``Artificial Intelligence and Life in 2030'' report~\cite{stone2022artificial}, AI is expected to impact various fields, including home services~\cite{you2003development}, healthcare~\cite{ma2023learning,ma2022learning,lyu2022multimodal,lyu2024badclm}, and transportation~\cite{ma2023eliminating,ma2024data,cottam2024large,zhang2024large}. To build such robots thrive in these areas that inherently require MIMO systems, they must process real-time inputs like spoken language and facial expressions, providing personalized feedback based on factors like gender and emotion. Interactive companion robots, like the Vector Robot~\cite{bib:vector}, are expected to receive camera and microphone inputs and use this information to predict user preferences and respond appropriately. In on-device learning scenarios with strict hardware constraints and performance requirements, deploying multi-input multi-output (MIMO) deep neural networks (DNNs) can be advantageous. By reducing the need to deploy multiple single-input single-output (MISO) DNN instances on the device, MIMO DNNs can significantly lower resource demands. This paper presents \tool, a novel on-device MIMO DNN framework that achieves both high accuracy and on-device efficiency in terms of critical performance metrics including latency, energy, and memory usage. The MIMO approach inherently offers speed improvements by requiring only one forward pass for multiple tasks (instead of multiple passes), reducing computational redundancy.

We first constructed a baseline MIMO DNN model and observed that it requires high memory consumption and struggles to meet real-time constraints due to computational demand. To minimize resource demands, \tool builds on an existing DNN model compression technique, VIB~\cite{VIB}, which is effective for single-input single-output (SISO) DNN models. However, extending VIB to MIMO DNN models posed two new challenges. First, VIB exclusively supports the compression of feed-forward networks~\cite{Feed-Forward}, which makes it unsuitable for more advanced networks, such as ResNet~\cite{ResNet}. To address this limitation, \tool extends and develops a modified compression method for ResNet with residual blocks. Second, VIB was not designed to handle MIMO scenarios and did not account for the unique characteristics of MIMO models. VIB focuses on reducing intra-model redundancy but is unable to address common inter-model redundancy in MIMO models. To address this issue, \tool develops a new deep-compression method that reduces both inter- and intra-model redundancy, resulting in deeper lossless compression for MIMO scenarios.

We conducted a two-fold evaluation of \tool. First, we compared its accuracy against state-of-the-art SISO and MISO models using the RAVDESS dataset~\cite{RAVDESS}, showing that \tool outperforms them in most scenarios. In the second set, we conducted a comprehensive evaluation of \tool's components' impacts on on-device efficiency, including memory, latency, and energy. We deployed \tool on three widely used embedded system platforms: NVIDIA Jetson Nano Orin, NVIDIA AGX Xavier, and NVIDIA AGX Orin, which are most recent used platforms for various robotics applications~\cite{deng2020self, meng2019neural, yang2022instinctive,guo2023backdoor} such as Duckiebot~\cite{Duckiebot(DB-J)}, SparkFun Jetbot~\cite{SparkFun_JetBot}, and Waveshare Jetbot~\cite{Waveshare_JetBot}. In addition, we evaluated \tool on a PC machine for a more comprehensive assessment.
In summary, experimental results demonstrate that \tool can achieve:

% \zx{update number}

\begin{itemize}[leftmargin=10px]
\item \textbf{Reduced Memory Usage:} \tool significantly reduces runtime memory usage by 80.7\% compared to the baseline MISO models.
\item \textbf{Improved Inference Speed:} \tool exhibits speed-ups of 1.98x, 2.29x, and 1.23x compared to the baseline MISO model when tested on Nano, AGX, and Orin, respectively.
\item \textbf{Enhanced Energy Efficiency:} The energy savings offered by \tool are 2.01x, 8.64x, and 2.71x compared to the baseline MISO model when tested on Nano, AGX, and Orin, respectively.
\end{itemize}

% In addition to our evaluation, we conducted a realistic case study using the TurtleBot3 robot to demonstrate the real-world applicability of our proposed approach. Specifically, we evaluated scenarios involving face and audio recognition for interactive emotional robots in a cluttered environment. The results of this case study further validate the superiority of our proposed MIMO model over state-of-the-art SISO and MISO models in terms of accuracy and on-device efficiency. Moreover, we provide visual demonstrations to highlight the effectiveness of our approach in real-world scenarios, demonstrating its practical relevance for interactive robotic systems.

The major contributions of this paper can be summarized as follows:

\begin{itemize}[leftmargin=10px]
    \item \textbf{Innovative MIMO Framework for Robotics:} We introduce \tool, one of the first frameworks to utilize a unified neural network for processing multiple inputs and outputs simultaneously, addressing complex inference tasks in robotics.
    \item \textbf{New Deep-Compression Method:} \tool implements a novel deep-compression method that enhances accuracy and on-device efficiency, specifically tailored for MIMO applications in robotics.
    \item \textbf{Extensive Experimental Results:} Our experiments on three embedded platforms and a PC demonstrate \tool’s high accuracy and superior on-device efficiency in terms of latency, energy, and memory usage, making it suitable for robots under stringent hardware constraints.
    \item \textbf{Real-World Case Study Validation:} We conducted a realistic case study using the TurtleBot3 robot, showing \tool’s practical applicability and superiority over state-of-the-art SISO and MISO models in face and audio recognition within cluttered environments. This further validates its effectiveness for interactive robotic systems.
\end{itemize}