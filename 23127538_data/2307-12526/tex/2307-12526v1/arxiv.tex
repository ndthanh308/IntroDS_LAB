%%%%%%%% ICML 2023 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{enumitem}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2023}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2023}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Rethinking Medical Report Generation}

\begin{document}

\twocolumn[
\icmltitle{Rethinking Medical Report Generation: \\Disease Revealing Enhancement with Knowledge Graph}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2023
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Yixin Wang}{equal,a}
\icmlauthor{Zihao Lin}{equal,b}
\icmlauthor{Haoyu Dong}{equal,c}
%\icmlauthor{Firstname4 Lastname4}{sch}
%\icmlauthor{Firstname5 Lastname5}{yyy}
%\icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
%\icmlauthor{Firstname7 Lastname7}{comp}
%\icmlauthor{}{sch}
%\icmlauthor{Firstname8 Lastname8}{sch}
%\icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\icmlaffiliation{a}{Department of Bioengineering, Stanford University, Stanford, CA, USA}
\icmlaffiliation{b}{Department of Computer Science, Virginia Tech, Blacksburg, VA, USA}
\icmlaffiliation{c}{Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA}
\end{icmlauthorlist}



\icmlcorrespondingauthor{Yixin Wang}{yxinwang@stanford.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Knowledge Graph (KG) plays a crucial role in Medical Report Generation (MRG) because it reveals the relations among diseases and thus can be utilized to guide the generation process. However, constructing a comprehensive KG is labor-intensive and its applications on the MRG process are under-explored.
In this study, we establish a complete KG on chest X-ray imaging that includes 137 types of diseases and abnormalities.
Based on this KG, we find that the current MRG data sets exhibit a long-tailed problem in disease distribution. 
To mitigate this problem, we introduce a novel augmentation strategy that enhances the representation of disease types in the tail-end of the distribution.
We further design a two-stage MRG approach, where a classifier is first trained to detect whether the input images exhibit any abnormalities. The classified images are then independently fed into two transformer-based generators, namely, ``disease-specific generator" and ``disease-free generator" to generate the corresponding reports.
To enhance the clinical evaluation of whether the generated reports correctly describe the diseases appearing in the input image, 
we propose diverse sensitivity (DS), a new metric that checks whether generated diseases match ground truth and measures the diversity of all generated diseases.
Results show that the proposed two-stage generation framework and augmentation strategies improve DS by a considerable margin, indicating a notable reduction in the long-tailed problem associated with under-represented diseases.
\end{abstract}
\section{Introduction}
Chest radiography is one of the most common and effective imaging examinations used in clinical practice for diagnosing diseases and evaluating health risks. The obtained images generally require medical reports with comprehensive interpretation written by qualified physicians or pathologists, which can be time-consuming and requires expertise. With the advancement in deep learning (DL) algorithms, automatic medical report generation (MRG) has been widely explored and achieved significant performance \cite{COATT,report02,report03,report04,report06,R2Gen,liu2021exploring,report09,report10,pmlr-v106-liu19a, wang2022automated,YANG2023102798}. These DL-based systems analyze the chest images and automatically generate a descriptive report outlining the findings. 
% Figure environment removed
However, these methods are primarily designed to optimize the performance of matching generated N-gram to ground truth reports, rather than focusing on aligning generated medical attributes, \textit{i.e.}, abnormalities or diseases with the actual reports, which is more important when assessing the clinical utility of a generation algorithm.
While some researchers \cite{Chexpert,Harzig2019AddressingDB,zhang2020radiology} propose disease labeling tools or build disease knowledge graphs to aid in evaluating the reports, their KG contains limited disease types and they only consider report-level n-gram matching accuracy, which is a coarse reflection of the medical attributes. 
\iffalse
To address these problems, a larger knowledge graph with comprehensive and accurate disease mentions and relations is required to indicate the clinical-relevant information in medical reports.
%Other methods impose KG into MRG to generate clinic-relevant context, but XXX.
%Moreover, the usage of KG is not well-explored.
%Besides using it during the generation phase, we also explore other usages.

Based on the most popular and widely used chest X-ray datasets, i.e., IU-Xray \cite{iuxray} and MIMIC-CXR \cite{johnson2019mimiccxrjpg}, we construct a large knowledge graph (KG) with 137 types of chest diseases (See Section \ref{SectionKG} for details). 
\fi

To address these problems, we construct a large KG with 137 types of chest diseases based on two widely used chest X-ray datasets, IU-Xray \cite{iuxray} and MIMIC-CXR \cite{johnson2019mimiccxrjpg} (See Section \ref{SectionKG} for details).
Utilizing the diseases from this KG, a rule-based criterion is adopted to make a detailed statistical analysis on the appearing diseases and abnormalities in IU-Xray. As depicted in Figure \ref{long_tail}(a), across all reports in the data set, the frequency of sentences indicating normal results (no diseases or abnormalities) is three times greater than those indicating the presence of at least one disease or abnormality. Moreover, the number of sentences with common diseases (occurrences greater than 20) is almost 4 times of those with uncommon diseases (occurrences less than 20). The frequency of occurrence for each disease keyword is further highlighted in Figure \ref{long_tail}(b), which exhibits a long-tailed distribution of the disease classes in the data set. %In this distribution,  several common diseases dominate but rarer ones are under-represented. 
In the original training data (dark blue bars), only three diseases appear more than 100 times and 65.7\% diseases appear less than 10 times in IU-Xray, which shows that several common diseases dominate but rarer ones are under-represented.
%This uneven distribution between the normal and abnormal cases can easily make models biased towards generating ``disease-free'' reports instead of ``disease-specific'' reports. %, i.e., reports that contain specific diseases. 
In response, we design a two-stage generation approach to reduce the bias towards generating ``disease-free'' reports instead of ``disease-specific'' reports, i.e., reports that contain at least one disease or abnormality. 
We further alleviate the long-tailed distribution issue by expanding the distribution of the disease classes through a designed disease augmentation strategy. According to our statistics on the augmented training data (light blue bars in Figure \ref{long_tail}(b)), the overall frequency of uncommon diseases in the original data set increases from 37.6\% to 55.5\%, while the common diseases see a decrease in overall frequency from 62.4\% to 44.5\%. 
\iffalse
In response, we propose a two-stage generation approach to enhance the generation ability of ``disease-specific'' reports. Specifically, a classifier is firstly adopted to distinguish whether the X-ray image exhibits abnormalities, which further determines the generation model; i.e., ``disease-free report generator'' or ``disease-specific report generator'' will be utilized in the second stage to generate the corresponding reports. These two models are separately trained using ``disease-free'' cases and ``disease-specific'' cases. In this way, the ``disease-specific report generator'' will focus more on detecting abnormalities without overfitting problems. In order to further address the imbalance of disease classes, we explore expanding the distribution of these abnormal classes through a designed disease augmentation. 
Specifically, we augment reports containing special disease sentences, and each sentence is replaced by several sentences with the same label and different format. 
Such an augmentation strategy is able to enhance the diversity of the disease-specific information in MRG.
%The replaced sentences pool is constructed in advance based on the knowledge graph.
%\ns{add some augmentation descriptions}. 
%This strategy effectively transfer the disease distribution of head classes to tail classes.
\fi

Moreover, when evaluating generated reports, more emphasis should be placed on clinic-efficacy information. Previous works employ the commonly used N-gram evaluation metrics from image captioning tasks, such as BLEU-N \cite{papineni2002bleu}. However, these metrics do not necessarily reflect the clinical quality of the diagnostic reports, such as the accuracy of the specific diseases. 
In our experiments, as well as in previous studies \cite{Harzig2019AddressingDB}, it has been observed that with an imbalanced data set, models tend to achieve the highest BLEU score when generating repetitive sentences that most frequently appear in the training set.
Li et al. \cite{li2021ffair} argue that the quality of medical reports largely depends on the accurate detection of positive disease keywords. Therefore, they employ several human evaluations as additional measurements. Nevertheless, implementing this evaluation requires significant expert efforts and is prone to subjectivity and variability.
%models with the best BLEU-4 score generate repati the same paragraph for each input image. 
Based on KG, we propose a new evaluation metric, diverse sensitivity (DS), to assess the model's ability to generate reports containing special diseases, which concentrates more on clinical-relevant texts. Our KG and codes will be available at \hyperref[https://github.com/Wangyixinxin/MRG-KG]{https://github.com/Wangyixinxin/MRG-KG}.

Our contributions are as follows:
\begin{itemize}[noitemsep, nolistsep]
\item A complete knowledge graph with 8 disease categories and 137 diseases or abnormalities of chest radiographs is built based on accurate and detailed disease classification. 
\item A novel augmentation strategy is proposed to address the long-tailed problems in chest X-ray data sets.
\item An effective two-stage MRG approach is designed to separately handle normal and abnormal images, generating texts more specific to the identified diseases.
\item A KG-based evaluation metric, DS, is further proposed to assess the quality of generated reports, prioritizing the accuracy of disease-relevant attributes.
\end{itemize}
% Figure environment removed
\section{Knowledge Graph}
\label{SectionKG}
Starting from \cite{zhang2020radiology}, several works have demonstrated the effectiveness of KG on chest report generation \cite{li2019knowledge,liu2021exploring,zhang2020radiology}. The existing KG, which includes the most common diseases or abnormalities \cite{zhang2020radiology}, consists of 7 organs with 18 corresponding diseases, along with ``normal'' and ``other findings''. However, this KG lacks comprehensiveness as it omits many common diseases such as ``calcification'', ``spine degenerative'', and ``lung consolidation''. 
The restriction in disease types places a limitation on the model's capacity to learn about the relationships between diseases, resulting in a lack of clinical depth. 
For example, lung opacity can be divided into categories like ``nodular opacity'', ``lobe opacity'', and ``hilar opacity''. Besides, identical abnormalities can appear in different organs, such as ``lung opacity'', ``diaphragm opacity'' and ``airspace opacity''. 
Lastly, the current KG does not account for several rare diseases or anomalies, leaving them unclassified.
To overcome these limitations, we extend the knowledge graph by adding more diseases based on IU-Xray \cite{iuxray} and MIMIC-CXR \cite{johnson2019mimiccxrjpg}. 
Figure \ref{kg} depicts a partial representation of our proposed knowledge graph.
In our work, we retain the current seven organ categories while supplementing them with additional diseases. 
We also introduce another new category ``other'', which contains abnormalities, such as ``tube'' and ``sternotomy'' that do not belong to any of the seven organs.
%``Description'' includes special adjectives such as ``chronic'' and ``greater than'' and ``other'' contains rare diseases, such as ``lymphadenopathy'' and ``sternotomy'', that do not belong to any of the seven organs.
%We also introduce two new categories``Other'' and ``Description''. 
%For each organ, we obtain more diseases. For example, ``mediastinum'' now contains twelve specific diseases. ``Other'' includes diseases or abnormalities that do not belong to the 7 organs, such as ``lymphadenopathy'' and ``sternotomy''. ``Description'' otherwise contains special some special adjectives such as ``chronic'' and ``greater than''.
%\ns{Other includes XXX.
%Description includes XXX.}
%We also obtain special diseases or abnormalities such as lymphadenopathy which belongs to class ``Other''. In class ``Description'', we add some special keywords such as ``greater than'' and ``chronic'' which also are treated as abnormalities. 
While constructing this KG, we also take into account the synonyms and variations of each specific disease, leading to a comprehensive representation of 137 disease types. These will be leveraged in our training approach (See Section \ref{2stage}) and  evaluation metrics (See Section \ref{metric}).

Based on the knowledge graph, we build a rule-based criterion to classify diagnostic reports. %\ns{elaborate the rule?} 
Firstly, each word will be replaced by its synonyms through a pre-defined synonyms pool. Then, each sentence in the report will be labeled by a concatenation of ``diseases-organs'' pairs if it includes keywords from the KG or ``normal'' class otherwise. For example, the sentence ``there are low lung volumes with broncho-vascular crowding" will be labeled as ``bronchovascular crowding-lung-low volume-lung''.  A report is labeled as ``disease-free'' if all its sentences are labeled as ``normal'', otherwise it's marked as "disease-specific". These report labels will be utilized to train a classifier in our proposed two-stage generation approach.
%\ns{show somewhere that KG is generalizable to otheterr chest datasets, i.e., MIMIC}
% \ns{the rule-based criterion based on KG} 

\section{Two-Stage Generation Approach}
\label{2stage}
%In this section, we first claim that this task is a long-tail problem: (1) the number of normal sentences is much larger than that of sentences describing diseases. (2) Several common diseases demonstrate in the disease pool. 
Figure ~\ref{long_tail} illustrates an imbalance distribution within the IU-Xray dataset between the number of sentences that indicates the presence or absence of diseases, along with a long-tail issue in the disease distributions.
To address these issues, we propose two solutions: firstly, a novel two-stage pipeline including an image classifier and two identical generation networks. These networks are trained with ``disease-free'' and ``disease-specific'' data separately (Section \ref{3.1}). Secondly, a disease-specific augmentation strategy to alleviate the imbalanced distribution of disease data (Section \ref{DataAug}).
% Yixin

%This suggests two ways to better generate reports with the detailed disease information: (1) removing disease-unrelated data when training disease-related data; (2) adding more disease-related data.
%This indicates that separately training `disease-free' and `disease-specific' data using different networks will be better at generating reports with the detailed disease information. 
%On this basis,  We also design 

%It has been discussed in \cite{disease-specific} that a neural network will be more effective to extract disease-related information if more disease-specific characteristics are fed during training. 
% 下面这句有点怪；具体做法可以在后面细说
%On this basis, the built knowledge graph serves as a powerful tool since it enables us to separate training data into ``disease-free'' and ``disease-specific''. 
%To maximize the advantages of these classification knowledge, we then design a two-stage pipeline to improve the accuracy of reports. Our new architecture includes an image classifier and two generation networks with identical structure but trained with `disease-free' and `disease-specific' data respectively.
%\iffalse
%\subsection{Long-tail Problem}
%To analyze the distribution of diseases and abnormalities in original datasets (IU-Xray), we first label each sentence by ``normal'' or a concatenation of ``disease-organ'' pairs in the way described in section \ref{SectionKG}. As illustrated in Fig. \ref{long_tail} part (a), the number of normal sentences is 7,130, the sentences containing common diseases description are 2,026, and the count of sentences containing diseases whose numbers are smaller than or equal to 5 is 556. This unbalanced distribution confirms our motivation to design a two-stage generation approach. On the other hand, the dark blue bars in part (b) illustrate that the diseases statistics fit the long tail distribution in original training data, which makes models hard to learn special diseases.

%\iffalse
%\subsection{Classifier}
%Specifically, in the first stage, we utilize a classifier to make an initial decision on whether this image shows abnormalities. All the images in the training dataset are firstly classified into two categories, i.e., ``disease-free'' and ``disease-specific'', based on the classification of their corresponding reports.  ResNet101 is adopted as a strong classifier, which includes 101-layer residual network architecture and has been pre-trained on ImageNet database \cite{imagenet}. In the training phase, the model takes the whole images as input and optimized by minimizing the Cross-Entropy loss until convergence. During testing, a new image will be labeled by the classifier as ``disease-free'' reports or `disease-specific', and further fed into the corresponding models in the second stage for generating corresponding reports. 
%\fi
\subsection{Training and Inference Stage}
\label{3.1}
To address the dominance of normal findings in the data, we propose a two-stage approach. 
During the training phase, we leverage the available ground-truth reports to segregate the training data into the defined two classes, \textit{i.e.}, ``disease-free'' and ``disease-specific''. Following this strategy, the images corresponding to each report, paired with their respective labels, are leveraged to train an image classifier, ResNet101 \cite{he2016deep}, with standard cross-entropy loss to detect if an input image contains diseases.
In parallel, we employ two generative models for report generation: a ``disease-free generator'' and a ``disease-specific generator'', each trained on data from their respective classes. Both generators utilize the same architectural design based on R2Gen \cite{R2Gen}, one of the most popular approaches for MRG. 
Specifically, given a radiology image as an input, a visual extractor is trained to extract related features. Subsequently, a transformer encoder and a transformer decoder, both consisting of a multi-head self-attention and a multi-head cross-attention module, are further employed to generate long reports.
During the inference stage, a two-stage approach is adopted, where an input image is first fed to the image classifier to distinguish whether it contains any disease or abnormality, and then the corresponding generator is chosen to generate the diagnostic report in the second stage.
\iffalse
, two models are separately trained to generate ``disease-free'' reports and ``disease-specific'' reports.
In order to indicate the effectiveness of our two-stage strategy, one of the most popular approaches, R2Gen\cite{R2Gen}, is utilized as a strong generation backbone of the two models. Given a radiology image as input, a visual extractor is trained to extract related features and then a transformer encoder and a transformer decoder consisting of a multi-head self-attention and a multi-head cross-attention module are further designed to generate long reports. The two models share the same architecture but they are trained with ``disease-free'' data and ``disease-specific'' data, respectively. Note that generating `disease-free' reports is much easier, and our focus is how to improve the capability of the model trained with ``disease-specific'' data, defined as ``Disease-Specific Report Generator'', to effectively capture the specific characteristics of different diseases and generate more accurate disease-specific reports. 
\fi

Although the two-stage strategy can improve the ability of the generator to specifically generate ``disease-specific'' reports, there is still an inherent challenge of data imbalance which biases the model towards producing reports of the most dominant diseases found in the training data. With our disease KG, we further propose a novel data augmentation method to mitigate the disease imbalance issue. % and enhance to model to treat different diseases with equal importance.

% variety
\subsection{Disease-Specific Augmentation} 
\label{DataAug}
The first step of our augmentation strategy is to create a key-value pool of disease sentences, where the keys represent sentence labels (See Section \ref{SectionKG}) which are a concatenation of ``diseases-organs'' pairs such as ``opacity-lung'', and values include all unique-format sentences under this label such as ``The lung is opacity'' and ``This patient has lung opacity''. We define the label count as the number of unique-format sentences for each sentence label. A higher label count indicates more sentence variations that describe that label, which is easier to perform disease augmentation through random substitution. Therefore, we define a count interval [5, 100] by omitting sentence labels with a label count of less than 5 or more than 100. 
Starting from the label with the fewest unique-format sentences in this interval, we first find all diagnostic reports that contain sentences under this sentence label.
For each report, we substitute the sentence under this sentence label with another format from the key-value pool and repeat this operation for all reports.
For example, if 5 distinct sentences belong to a particular label, the proposed augmentation strategy will generate $5 \times (5-1)=20$ additional reports. 
Given that a report might contain multiple disease sentences, this augmentation process could inadvertently boost the frequency of various diseases concurrently. 
To moderate this undesired effect, we update the statistics of disease labels after each round of augmentation and find the next least frequent disease that has not been augmented before. 
%Starting from labels counting 5, we find the corresponding diagnostic report for each sentence in the sentence pool. Then copy the reports and replace the labeled sentence with another sentences with the same label. Thus, if 5 distinct sentences belong to this label, augmentation will result in $5*(5-1)=20$ augmented reports among which the difference is only the labeled sentences. Please note that we also copy other sentences in the report which may contain other diseases, therefore, after each time, we update the statistics of diseases labels and start from the least again but ignore already augmented labels. This process will not stop until all labels in the interval are augmented. If after augmentation the counts of one label extends the upper bound, we will first random sample parts of sentences in the sentence pool, then augment to satisfy the upper bound. 
Figure \ref{long_tail} (b) indicates that the applied augmentation strategy successfully evens out the distribution of diseases, especially in reducing the long-tail problem. It is noted that although the augmentation strategy increases the occurrences of all types of diseases, it prioritizes the occurrence of diseases in the tailed population. % to some extend.
% Figure environment removed
\section{Evaluation Metric}
\label{metric}
Common evaluation metrics, including BLEU \cite{papineni2002bleu}, ROUGE \cite{lin2004rouge}, METEOR \cite{banerjee2005meteor}, etc., fail to consider whether the generated reports describe the diseases appearing in the input image. The accurate description of disease keywords is the main criterion for radiologists to decide whether to use the generated reports.
Therefore, based on our proposed KG, we introduce a new evaluation metric, Diverse Sensitivity (DS), that evaluates whether the diseases identified in the ground-truth report are also accurately depicted in the generated report.
\iffalse
\subsection{Ineffectiveness in NLG}
BLEU-n first splits an input into overlapping grams with length n and counts the number of grams appearing in the reference.
It is known for the ineffectiveness in evaluating diversity \cite{Lavie2004TheSO} and thus a dummy model that constantly generate most frequent sentence can achieve a high score.


Although BLEU is one of the most common criterion in NLP evaluation, it is known for the ineffectiveness in evaluating diversity [cite].
This is also shown in our target dataset. 
Example.

Some works propose to compute BLEU Recall, i.e., finding references on the generated sentences, and BLEU F-score that follows the standard F-score computation.
However, with only a single reference ground truth, reserving the prediction and reference does not result in a significant difference.
Thus, we decide to not use BLEU score as our evaluation criterion.

Firstly, we consider a generated report to be correct \textit{iff} at least one disease appears in the ground truth.

A more strict criterion, i.e., all the diseases described by the generated report should exactly match the ones in the ground truth, is feasible, but we find the SOTA methods achieve close to zero accuracy under this setting.
This suggests that current algorithms are far from generating clinically usable reports and our metric serves as an initial goal towards that objective.

%This criterion serves as an initial step towards the ultimate objective where all detected diseases match the ground truth.
Then, we evaluate the \textit{diversity} of the generated reports, i.e., how many ground-truth diseases are covered by the generated reports.
This is achieved by creating a disease pool that contains all the unique disease types detected during the generation.
A report is counted \textit{iff} it includes at least one disease listed in the disease pool.
Lastly, we follow F-score to weigh the above two components, leading to our proposed new metric, Diverse Sensitivity (DS).
\fi
Firstly, we consider a generated report to be correct \textit{iff} it depicts at least one disease that appears in the ground truth. 
The Sensitivity (Sen.) is defined as $Sen. = \frac{TP}{TP+FN}$, where $TP$ and $FN$ stand for true positive and false negative respectively.
However, due to the long-tail disease distribution, the network is able to achieve a high sensitivity if all the generated reports contain the most common disease.
Thus, we propose a different metric, Diversity (Div.), to account for the variability during generation.
Div. is defined as the ratio between the number of uniquely generated disease types and the number of total disease types.
Lastly, DS is a harmonic mean of Sen. and Div., \textit{i.e.}, $DS = 2\times  \frac{Sen. \times Div.}{Sen. + Div.}$.
Since DS focuses on evaluating ``disease-specific" sentences, we also introduce Diagnostic Odds Ratio (DOR), similar to the concept defined in \cite{glas2003diagnostic}. This complementary metric evaluates the model's ability to generate correct ``disease-free" reports.
\iffalse
We introduce NewName, a metric that evaluates the correctness and diversity of the reports.
A prediction is considered correct iff it contains at least one disease described in the ground truth, which is a privilege of having a knowledge graph.
However, it also fails to consider diversity because a naive generator that only produces sentences with the highest frequent disease performs well.
Thus, we consider diversity by (1) collecting all generated sentences as a disease pool; (2) for each ground-truth (reference) report, checking if it's in the pool.
In this way, a model that generates diverse output will be preferred. 
Formally, we consider the F-score of the two.
\fi
%\subsection{Diagnostic Odds Ratio}
%Since DS only considers the quality of generated reports with diseases, we also include \textit{Diagnostic Odds Ratio} (DOR) as a complementary metric 
%That is, the ability to generate ``disease-free'' reports for normal images and ``disease-specific'' reports for images with diseases.
%This metric, defined as Diagnostic Odds Ratio (DOR), measures the ability to generate ``disease-free'' reports for normal images and ``disease-specific'' reports for images with diseases.
Formally, $DOR = \frac{TP\times TN}{FP\times FN}$, where $TN$ and $FP$ stand for true negative and false positive respectively. 
DS and DOR are considered jointly to evaluate the clinical efficacy of a generation model.

\section{Experiment}
\subsection{Datasets and Implementation}
In the experiments, we adopt IU X-ray \cite{iuxray} which consists of 7,470 chest X-ray images with 3,955 radiology reports. Each report is paired with two associated images - a frontal and a lateral view.  This dataset is split into train/validation/test set by 7:1:2, following R2Gen \cite{R2Gen}. 
Model selection is based on the best DS score on the validation set and we report its performance on the test set.
%Another largest radiology dataset, MIMIC-CXR \cite{johnson2019mimiccxrjpg}, along with IU X-ray, is utilized to build our knowledge graph. 
For a fair comparison, we keep all experimental settings consistent with those used in the R2Gen \cite{R2Gen}.
% \ns{(maybe) mention here or in 5.2 that our KG is able to find disease from reports in MIMIC-CXR} %这样就能说我们的kg能被用在any chest dataset中 

\subsection{Comparison Results}
\subsubsection{Quantitative Results.}
%R2Gen \cite{chen-emnlp-2020-r2gen} is one of the state-of-the-art methods for report generation on IU-Xray.
%It introduces a relational memory that records previous generation processes into current ones and a memory-driven conditional layer normalization into Transformer's decoder.
We evaluate the effectiveness of our proposed method as compared to R2Gen \cite{R2Gen} using DS and DOR. 
We also include Sensitivity (Sen.) and Diversity (Div.) in our comparison for reference.
As shown in Table \ref{tab:main}, our method achieves a DS score of $0.1902$ and a DOR score of $0.5138$, outperforming R2Gen by a large margin.
This improvement in these two clinical-relevant metrics implies greater applicability of our method in real-world clinical settings.
\begin{table}[htbp]
    \centering
     \setlength{\tabcolsep}{0.6mm}{
    \begin{tabular}{ccc|cc}
    \toprule[1.3pt]
    Method & DOR & DS & Sen. & Div.  \\
    \midrule
    R2Gen \cite{R2Gen} & 0.2911 & 0.1523 & 0.0932 & 0.4153  \\
    %TODO & & & & \\
    %\midrule
    %Disease Specific &  \textcolor{red}{0} & 0.1955 & 0.1305 & 0.3898  \\
    %Augmentation & 0.3440 & 0.2178 & 0.1458 & 0.4305  \\
    %\midrule
    %Two-Stage & \textbf{0.4223} & 0.1634 & 0.1034 & 0.3898 \\
    Two-Stage + Aug. (Ours) & \textbf{0.5138} & \textbf{0.1902} & 0.1220 & 0.4305  \\
    \midrule
    Two-Stage & 0.4223 & 0.1634 & 0.1034 & 0.3898 \\
    Disease-Specific Only & 0 & 0.1955 & 0.1305 & 0.3898 \\
    R2Gen$^*$ \cite{R2Gen} & 0.4366 & 0.0324 & 0.0186 & 0.1220 \\
    \bottomrule[1.3pt]
    \end{tabular}}
    \caption{Comparison results. R2Gen$^*$ means the best model under BLEU.}
    \label{tab:main}
\end{table}

We further investigate the effect of augmentation and the two-stage generation process in Table \ref{tab:main}.
The observed decrease in DOR to 0.4223 and DS to 0.1634, when the low-frequency diseases are not augmented, emphasizes the significance of ensuring a balanced disease distribution in the data set.
Given our objective to improve the correct generation of disease sentences, we compare the two-stage generation model to its ``disease-specific generator''.
Although the ``disease-specific generator'' achieves a higher DS, it can only generate reports with diseases, leading to zero TN and thus a zero score on DOR.
Such a model is not clinically useful as it lacks the ability to distinguish between normal and disease images.
Introducing a classifier can alleviate this problem, but it gives rise to another issue of having false negative predictions, which is beyond the scope of this paper.
Lastly, we show the discrepancy between the common metric and the proposed one in the last row by recording a second R2Gen model that is selected based on the best BLEU-4 score.
Although this BLEU-based model gains an impressive performance of $0.1656$ (the leading performance under this metric on IU-Xray, not presented in Table \ref{tab:main} for clarity) in our experiments, it achieves close to zero in both DS and sensitivity. This implies that the majority of the generated reports do not align with the actual diseases, reducing their usefulness in a clinical setting. %$0.0324$ DS and $0.0186$ sensitivity, meaning that there are almost zero matched diseases and thus these generations are hardly usable in a real clinical setting.
\subsubsection{Qualitative Results.}
Figure \ref{compare_fig} provides a qualitative analysis that demonstrates the clinical efficacy of our methods and metrics. The generated reports reveal an important finding: the best R2Gen model, when selected based on the BLEU-4 metric (referring to as R2Gen (BLEU-4)), fails to generate disease-specific sentences, disregarding clinical-relevant information. In contrast, when selecting the models using our proposed DS metric (referring to as R2Gen (DS)), the chosen R2Gen model performs much better, indicating its ability to generate disease-specific sentences and emphasizing the need for a more clinical-relevant evaluation metric. Moreover, our two-stage generation approach, incorporating our augmentation strategy based on the DS metric, denoted as ``Ours (DS)'', effectively tackles the long-tailed issue by successfully capturing rare abnormalities such as ``interstitial opacity'' and ``edema''. The accurate descriptions of diseases generated by our approach, which align with the keywords in our knowledge graph (referred to as ``Disease Keyword''), further validate the utility of our approach.
\section{Conclusion}
In this paper, we present the construction of a comprehensive knowledge graph focusing on chest X-ray images to uncover disease relationships and investigates the significance of disease mentions in medical report generation task. We propose a two-stage generation approach and a KG-based augmentation strategy to mitigate the challenges associated with imbalanced data sets. The KG developed in this study can be extended and utilized by other researchers. Furthermore, a novel evaluation metric is devised, leveraging the information captured in the KG to measure clinical relevance. This work serves as a catalyst for future exploration of the clinical efficacy in medical report generation.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
%\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2023}
%\bibliography{mybib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
%\appendix
\onecolumn
%\section{Appendix}

%You can have as much text here as you want. The main body must be at most $8$ pages long.
%For the final version, one more page can be added.
%If you want, you can use an appendix like this one, even using the one-column format.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
