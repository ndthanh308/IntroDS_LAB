{
  "title": "Contrastive Conditional Latent Diffusion for Audio-visual Segmentation",
  "authors": [
    "Yuxin Mao",
    "Jing Zhang",
    "Mochu Xiang",
    "Yunqiu Lv",
    "Dong Li",
    "Yiran Zhong",
    "Yuchao Dai"
  ],
  "submission_date": "2023-07-31T11:29:50+00:00",
  "revised_dates": [
    "2025-07-01T05:44:57+00:00"
  ],
  "abstract": "We propose a contrastive conditional latent diffusion model for audio-visual segmentation (AVS) to thoroughly investigate the impact of audio, where the correlation between audio and the final segmentation map is modeled to guarantee the strong correlation between them. To achieve semantic-correlated representation learning, our framework incorporates a latent diffusion model. The diffusion model learns the conditional generation process of the ground-truth segmentation map, resulting in ground-truth aware inference during the denoising process at the test stage. As our model is conditional, it is vital to ensure that the conditional variable contributes to the model output. We thus extensively model the contribution of the audio signal by minimizing the density ratio between the conditional probability of the multimodal data, e.g. conditioned on the audio-visual data, and that of the unimodal data, e.g. conditioned on the audio data only. In this way, our latent diffusion model via density ratio optimization explicitly maximizes the contribution of audio for AVS, which can then be achieved with contrastive learning as a constraint, where the diffusion part serves as the main objective to achieve maximum likelihood estimation, and the density ratio optimization part imposes the constraint. By adopting this latent diffusion model via contrastive learning, we effectively enhance the contribution of audio for AVS. The effectiveness of our solution is validated through experimental results on the benchmark dataset. Code and results are online via our project page: https://github.com/OpenNLPLab/DiffusionAVS.",
  "categories": [
    "cs.CV",
    "cs.MM",
    "cs.SD",
    "eess.AS"
  ],
  "primary_category": "cs.CV",
  "doi": "10.1109/TIP.2025.3580269",
  "journal_ref": "IEEE Transactions on Image Processing 2025",
  "arxiv_id": "2307.16579",
  "pdf_url": "https://arxiv.org/pdf/2307.16579v2",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 3923492,
  "size_after_bytes": 504198
}