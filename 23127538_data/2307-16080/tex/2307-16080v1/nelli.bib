@misc{memento:rfc,
	author = {Herbert {Van de Sompel} and
			Michael L. Nelson and
			Robert Sanderson},
	title = {{HTTP Framework for Time-Based Access to Resource States -- Memento, Internet RFC 7089}},
	year = {2013},
	howpublished = {\url{https://tools.ietf.org/html/rfc7089}},
}


@InProceedings{pmlr-v42-glig14,
	title = {Real-time data analysis at the LHC: present and future},
	author = {Gligorov, Vladimir},
	booktitle = {Proceedings of the NIPS 2014 Workshop on High-energy Physics and Machine Learning},
	pages = {1--18},
	year = {2015},
	editor = {Cowan, Glen and Germain, Cecile and Guyon, Isabelle and Kegl, Balazs and Rousseau, David},
	volume = {42},
	series = {Proceedings of Machine Learning Research},
	address = {Montreal, Canada},
	month = {13 Dec},
	publisher = {PMLR},
	pdf = {http://proceedings.mlr.press/v42/glig14.pdf},
	url = {https://proceedings.mlr.press/v42/glig14.html},
	abstract = {The Large Hadron Collider (LHC), which collides protons at an energy of 14 TeV, produces hundreds of exabytes of data per year, making it one of the largest sources of data in the world today. At present it is not possible to even transfer most of this data from the four main particle detectors at the LHC to “offline” data facilities, much less to permanently store it for future processing. For this reason the LHC detectors are equipped with real-time analysis systems, called triggers, which process this volume of data and select the most interesting proton-proton (pp) collisions. The LHC experiment triggers reduce the data produced by the LHC by between 1/1000 and 1/100000, to tens of petabytes per year, allowing its economical storage and further analysis. The bulk of the data-reduction is performed by custom electronics which ignores most of the data in its decision making, and is therefore unable to exploit the most powerful known data analysis strategies. I cover the present status of real-time data analysis at the LHC, before explaining why the future upgrades of the LHC experiments will increase the volume of data which can be sent off the detector and into off-the-shelf data processing facilities (such as CPU or GPU farms) to tens of exabytes per year. This development will simultaneously enable a vast expansion of the physics programme of the LHC’s detectors, and make it mandatory to develop and implement a new generation of real-time multivariate analysis tools in order to fully exploit this new potential of the LHC. I explain what work is ongoing in this direction and motivate why more effort is needed in the coming years.}
}


@article{doi:10.1063/5.0006531,
	author = {Keunecke,Marius and M{\"o}ller,Christina and Schmitt,David and Nolte,Hendrik and Jansen,G. S. Matthijs and Reutzel,Marcel and Gutberlet,Marie and Halasi,Gyula and Steil,Daniel and Steil,Sabine and Mathias,Stefan},
	doi = {10.1063/5.0006531},
	eprint = {https://doi.org/10.1063/5.0006531},
	journal = {Review of Scientific Instruments},
	number = {6},
	pages = {063905},
	title = {Time-resolved momentum microscopy with a 1 MHz high-harmonic extreme ultraviolet beamline},
	url = {https://doi.org/10.1063/5.0006531},
	volume = {91},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1063/5.0006531} }


@article{BORK2021100619,
	abstract = {The Advanced LIGO detectors are sophisticated opto-mechanical devices. At the core of their operation is feedback control. The Advanced LIGO project developed a custom digital control and data acquisition system to handle the unique needs of this new breed of astronomical detector. The advligortsis the software component of this system. This highly modular and extensible system has enabled the unprecedented performance of the LIGO instruments, and has been a vital component in the direct detection of gravitational waves.},
	author = {Rolf Bork and Jonathan Hanks and David Barker and Joseph Betzwieser and Jameson Rollins and Keith Thorne and Erik {von Reis}},
	doi = {https://doi.org/10.1016/j.softx.2020.100619},
	issn = {2352-7110},
	journal = {SoftwareX},
	keywords = {Real-time processing, Feedback control, Hardware control, Data acquisition},
	pages = {100619},
	title = {advligorts: The Advanced LIGO real-time digital control and data acquisition system},
	url = {https://www.sciencedirect.com/science/article/pii/S2352711020303320},
	volume = {13},
	year = {2021},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S2352711020303320},
	bdsk-url-2 = {https://doi.org/10.1016/j.softx.2020.100619} }

@article{Guest:2018yhq,
author = "Guest, Dan and Cranmer, Kyle and Whiteson, Daniel",
title = "Deep Learning and its Application to {LHC} Physics",
eprint = "1806.11484",
archivePrefix = "arXiv",
primaryClass = "hep-ex",
doi = "10.1146/annurev-nucl-101917-021019",
journal = "Ann. Rev. Nucl. Part. Sci.",
volume = "68",
pages = "161--181",
year = "2018"
}

@article{paszke2017automatic,
	title = {Automatic differentiation in {PyTorch}},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	year = {2017}
}

@misc{https://doi.org/10.48550/arxiv.2002.11054,
	doi = {10.48550/ARXIV.2002.11054},

	url = {https://arxiv.org/abs/2002.11054},

	author = {Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},

	keywords = {Programming Languages (cs.PL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},

	title = {MLIR: A Compiler Infrastructure for the End of Moore's Law},

	publisher = {arXiv},

	year = {2020},

	copyright = {Creative Commons Attribution 4.0 International}
}


@misc{torch-mlir,
	author = {Sean Silva and Anush Elangovan},
	title = {{Torch-MLIR}},
	year = {2021},
	howpublished = {\url{https://mlir.llvm.org/OpenMeetings/2021-10-07-The-Torch-MLIR-project.pdf}},
}

@misc{polyhedral-mlir,
	author = {Uday Bondhugula},
	title = {{Polyhedral Compilation Opportunities in MLIR}},
	year = {2020},
	howpublished = {\url{https://acohen.gitlabpages.inria.fr/impact/impact2020/slides/IMPACT_2020_keynote.pdf}},
}


@inbook{Zhang2008,
	abstract = {The rapid increase of complexity in System-on-a-Chip design urges the design community to raise the level of abstraction beyond RTL. Automated behavior-level and system-level synthesis are naturally identified as next steps to replace RTL synthesis and will greatly boost the adoption of electronic system-level (ESL) design. High-level executable specifications, such as C, C++, or SystemC, are also preferred for system-level verification and hardware/software co-design.},
	address = {Dordrecht},
	author = {Zhang, Zhiru and Fan, Yiping and Jiang, Wei and Han, Guoling and Yang, Changqi and Cong, Jason},
	booktitle = {High-Level Synthesis: From Algorithm to Digital Circuit},
	doi = {10.1007/978-1-4020-8588-8_6},
	editor = {Coussy, Philippe and Morawiec, Adam},
	isbn = {978-1-4020-8588-8},
	pages = {99--112},
	publisher = {Springer Netherlands},
	title = {AutoPilot: A Platform-Based ESL Synthesis System},
	url = {https://doi.org/10.1007/978-1-4020-8588-8_6},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1007/978-1-4020-8588-8_6} }

@article{10.1145/2514740,
	author = {Canis, Andrew and Choi, Jongsok and Aldham, Mark and Zhang, Victor and Kammoona, Ahmed and Czajkowski, Tomasz and Brown, Stephen D. and Anderson, Jason H.},
	title = {LegUp: An Open-Source High-Level Synthesis Tool for FPGA-Based Processor/Accelerator Systems},
	year = {2013},
	issue_date = {September 2013},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {13},
	number = {2},
	issn = {1539-9087},
	url = {https://doi.org/10.1145/2514740},
	doi = {10.1145/2514740},
	abstract = {It is generally accepted that a custom hardware implementation of a set of computations will provide superior speed and energy efficiency relative to a software implementation. However, the cost and difficulty of hardware design is often prohibitive, and consequently, a software approach is used for most applications. In this article, we introduce a new high-level synthesis tool called LegUp that allows software techniques to be used for hardware design. LegUp accepts a standard C program as input and automatically compiles the program to a hybrid architecture containing an FPGA-based MIPS soft processor and custom hardware accelerators that communicate through a standard bus interface. In the hybrid processor/accelerator architecture, program segments that are unsuitable for hardware implementation can execute in software on the processor. LegUp can synthesize most of the C language to hardware, including fixed-sized multidimensional arrays, structs, global variables, and pointer arithmetic. Results show that the tool produces hardware solutions of comparable quality to a commercial high-level synthesis tool. We also give results demonstrating the ability of the tool to explore the hardware/software codesign space by varying the amount of a program that runs in software versus hardware. LegUp, along with a set of benchmark C programs, is open source and freely downloadable, providing a powerful platform that can be leveraged for new research on a wide range of high-level synthesis topics.},
	journal = {ACM Trans. Embed. Comput. Syst.},
	month = {sep},
	articleno = {24},
	numpages = {27},
	keywords = {power, performance, field-programmable gate arrays, FPGAs, synthesis, hardware/software codesign, High-level synthesis}
}

@INPROCEEDINGS{ferrandi2021bambu,

	author = {Ferrandi, Fabrizio and Castellana, Vito Giovanni

			and Curzel, Serena and Fezzardi, Pietro and Fiorito, Michele

			and Lattuada, Marco and Minutoli, Marco and Pilato, Christian

			and Tumeo, Antonino},

	booktitle = {2021 58th ACM/IEEE Design Automation Conference (DAC)},

	title = {Invited: Bambu: an Open-Source Research Framework for the

			High-Level Synthesis of Complex Applications},

	year = {2021},

	pages = {1327-1330},

	publisher = {{IEEE}},

}

@phdthesis{tuprints9272,
	title = {Advances in ILP-based Modulo Scheduling for High-Level Synthesis},
	year = {2019},
	language = {en},
	author = {Julian Oppermann},
	school = {Technische Universit{\"a}t},
	address = {Darmstadt},
	url = {http://tuprints.ulb.tu-darmstadt.de/9272/},
	abstract = {In today's heterogenous computing world, field-programmable gate arrays (FPGA) represent the energy-efficient alternative to generic processor cores and graphics accelerators. However, due to their radically different computing model, automatic design methods, such as high-level synthesis (HLS), are needed to harness their full power. HLS raises the abstraction level to behavioural descriptions of algorithms, thus freeing designers from dealing with tedious low-level concerns, and enabling a rapid exploration of different microarchitectures for the same input specification. In an HLS tool, scheduling is the most influential step for the performance of the generated accelerator. Specifically, modulo schedulers enable a pipelined execution, which is a key technique to speed up the computation by extracting more parallelism from the input description. In this thesis, we make a case for the use of integer linear programming (ILP) as a framework for modulo scheduling approaches. First, we argue that ILP-based modulo schedulers are practically usable in the HLS context. Secondly, we show that the ILP framework enables a novel approach for the automatic design of FPGA accelerators. We substantiate the first claim by proposing a new, flexible ILP formulation for the modulo scheduling problem, and evaluate it experimentally with a diverse set of realistic test instances. While solving an ILP may incur an exponential runtime in the worst case, we observe that simple countermeasures, such as setting a time limit, help to contain the practical impact of outlier instances. Furthermore, we present an algorithm to compress problems before the actual scheduling. An HLS-generated microarchitecture is comprised of operators, i.e. single-purpose functional units such as a floating-point multiplier. Usually, the allocation of operators is determined before scheduling, even though both problems are interdependent. To that end, we investigate an extension of the modulo scheduling problem that combines both concerns in a single model. Based on the extension, we present a novel multi-loop scheduling approach capable of finding the fastest microarchitecture that still fits on a given FPGA device - an optimisation problem that current commercial HLS tools cannot solve. This proves our second claim.}
}

@INPROCEEDINGS{1688836,  author = {Cong, J. and Zhiru Zhang},  booktitle = {2006 43rd ACM/IEEE Design Automation Conference},   title = {An efficient and versatile scheduling algorithm based on SDC formulation},   year = {2006},  volume = {},  number = {},  pages = {433-438},  doi = {10.1145/1146909.1147025} }

@INPROCEEDINGS{6546003,  author={Soni, Ritesh Kumar and Steiner, Neil and French, Matthew},  booktitle={2013 IEEE 21st Annual International Symposium on Field-Programmable Custom Computing Machines},   title={Open-Source Bitstream Generation},   year={2013},  volume={},  number={},  pages={105-112},  doi={10.1109/FCCM.2013.45}}

@inproceedings{wolf2013yosys,
  title={Yosys-a free Verilog synthesis suite},
  author={Wolf, Clifford and Glaser, Johann and Kepler, Johannes},
  booktitle={Proceedings of the 21st Austrian Workshop on Microelectronics (Austrochip)},
  year={2013}
}


@article{10.1145/2858788.2688521,
author = {Ashari, Arash and Tatikonda, Shirish and Boehm, Matthias and Reinwald, Berthold and Campbell, Keith and Keenleyside, John and Sadayappan, P.},
title = {On Optimizing Machine Learning Workloads via Kernel Fusion},
year = {2015},
issue_date = {August 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2858788.2688521},
doi = {10.1145/2858788.2688521},
abstract = {},
month = {jan},
pages = {173-182},
numpages = {10},
keywords = {Dense, GPU, Machine Learning, Sparse, Fused Kernel}
}


@article{osti_1574050,
title = {Hierarchical Roofline analysis for GPUs: Accelerating performance optimization for the NERSC-9 Perlmutter system},
author = {Yang, Charlene and Kurth, Thorsten and Williams, Samuel},
abstractNote = {},
doi = {10.1002/cpe.5547},
journal = {Concurrency and Computation. Practice and Experience},
number = 20,
volume = 32,
place = {United Kingdom},
year = {2019},
month = {11}
}


@book{thomas1971catalogue,
  title={A catalogue of optimizing transformations},
  author={Thomas J. Watson IBM Research Center. Research Division and Allen, FE and Cocke, J},
  year={1971}
}


@book{sanders2019sequential,
  title={Sequential and Parallel Algorithms and Data Structures},
  author={Sanders, Peter and Mehlhorn, Kurt and Dietzfelbinger, Martin and Dementiev, Roman},
  year={2019},
  publisher={Springer},
  chapter={9},
  section={9.4},
}

  @misc{ enwiki:1081681080,
    author = "{Wikipedia contributors}",
    title = "Fast inverse square root --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2022",
    howpublished = "\url{https://en.wikipedia.org/wiki/Fast_inverse_square_root}",
    note = "[Online; accessed 3-May-2022]"
  }


@inproceedings{10.1007/978-0-387-72258-0_14,
	address = {Boston, MA},
	author = {Middendorf, Lars and M{\"u}hlbauer, Felix and Umlauf, Georg and Bobda, Christophe},
	booktitle = {Embedded System Design: Topics, Techniques and Trends},
	editor = {Rettberg, Achim and Zanella, Mauro C. and D{\"o}mer, Rainer and Gerstlauer, Andreas and Rammig, Franz J.},
	isbn = {978-0-387-72258-0},
	pages = {155--164},
	publisher = {Springer US},
	title = {Embedded Vertex Shader in FPGA},
	year = {2007}}

@INPROCEEDINGS{8877424,  author={de Dinechin, Florent},  booktitle={2019 IEEE 26th Symposium on Computer Arithmetic (ARITH)},   title={Reflections on 10 Years of FloPoCo},   year={2019},  volume={},  number={},  pages={187-189},  doi={10.1109/ARITH.2019.00042}}


@inproceedings{yehpca2022scalehls,
  title={ScaleHLS: A New Scalable High-Level Synthesis Framework on Multi-Level Intermediate Representation},
  author={Ye, Hanchen and Hao, Cong and Cheng, Jianyi and Jeong, Hyunmin and Huang, Jack and Neuendorffer, Stephen and Chen, Deming},
  booktitle={2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA)},
  year={2022}
}

@INPROCEEDINGS{9516615,  author={Zhang, Jeff Jun and Bohm Agostini, Nicolas and Song, Shihao and Tan, Cheng and Limaye, Ankur and Amatya, Vinay and Manzano, Joseph and Minutoli, Marco and Castellana, Vito Giovanni and Tumeo, Antonino and Wei, Gu-Yeon and Brooks, David},  booktitle={2021 IEEE 32nd International Conference on Application-specific Systems, Architectures and Processors (ASAP)},   title={Towards Automatic and Agile AI/ML Accelerator Design with End-to-End Synthesis},   year={2021},  volume={},  number={},  pages={218-225},  doi={10.1109/ASAP52443.2021.00040}}

@inproceedings{nikhil2004bluespec,
  title={Bluespec System Verilog: efficient, correct RTL from high level specifications},
  author={Nikhil, Rishiyur},
  booktitle={Proceedings. Second ACM and IEEE International Conference on Formal Methods and Models for Co-Design, 2004. MEMOCODE'04.},
  pages={69--70},
  year={2004},
  organization={IEEE}
}


@article{reconfigfpga,
	abstract = {Reconfigurable computing is a potential paradigm which has been effectively performing mostly in the developments of devices likely Field Programmable Gate Arrays (FPGAs). This paper illustrates the reconfigurable architecture of FPGA and its types. Most widely used high-speed computation fabrics utilized in reconfigurable computing are FPGAs. This paper demonstrates the architectures used in reconfigurable computing and shows the various advantages of using reconfigurable computing design over conventional Application-Specific Integrated Circuits for achieving high level of performance for a desired application. The survey deals with the architecture of FPGAs and their types in detail. This paper also explains the highlights and challenges of fine-grained and coarse-grained architectures. FPGAs have supported partial reconfiguration over the few years. This survey also includes the partial reconfiguration techniques and the various applications of reconfigurability.},
	author = {Babu, Praveenkumar and Parthasarathy, Eswaran},
	date = {2021/02/01},
	date-added = {2022-05-03 17:40:19 -0500},
	date-modified = {2022-05-03 17:40:19 -0500},
	doi = {10.1007/s40031-020-00508-y},
	id = {Babu2021},
	isbn = {2250-2114},
	journal = {Journal of The Institution of Engineers (India): Series B},
	number = {1},
	pages = {143--156},
	title = {Reconfigurable FPGA Architectures: A Survey and Applications},
	url = {https://doi.org/10.1007/s40031-020-00508-y},
	volume = {102},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1007/s40031-020-00508-y}}

@inproceedings{10.1145/3211346.3211348,
author = {Roesch, Jared and Lyubomirsky, Steven and Weber, Logan and Pollock, Josh and Kirisame, Marisa and Chen, Tianqi and Tatlock, Zachary},
title = {Relay: A New IR for Machine Learning Frameworks},
year = {2018},
isbn = {9781450358347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3211346.3211348},
doi = {10.1145/3211346.3211348},
abstract = {Machine learning powers diverse services in industry including search, translation, recommendation systems, and security. The scale and importance of these models require that they be efficient, expressive, and portable across an array of heterogeneous hardware devices. These constraints are often at odds; in order to better accommodate them we propose a new high-level intermediate representation (IR) called Relay. Relay is being designed as a purely-functional, statically-typed language with the goal of balancing efficient compilation, expressiveness, and portability. We discuss the goals of Relay and highlight its important design constraints. Our prototype is part of the open source NNVM compiler framework, which powers Amazon's deep learning framework MxNet.},
booktitle = {Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
pages = {58–68},
numpages = {11},
keywords = {intermediate representation, compilers, machine learning, differentiable programming},
location = {Philadelphia, PA, USA},
series = {MAPL 2018}
}

@article{vtr,
author = {Murray, Kevin and Petelin, Oleg and Zhong, Sheng and Wang, Jia and Eldafrawy, Mohamed and Legault, Jean-Philippe and Sha, Eugene and Graham, Aaron and Wu, Jean and Walker, Matthew and Zeng, Hanqing and Patros, Panos and Luu, Jason and Kent, Kenneth and Betz, Vaughn},
year = {2020},
month = {05},
pages = {1-55},
title = {VTR 8: High-performance CAD and Customizable FPGA Architecture Modelling},
volume = {13},
journal = {ACM Transactions on Reconfigurable Technology and Systems},
doi = {10.1145/3388617}
}

@inproceedings{mcmullin2022square,
  title={The Square Kilometre Array project update},
  author={McMullin, J and Diamond, P and Caiazzo, M and Casson, A and Cheetham, T and Dewdney, P and Laing, R and Lewis, B and Schinckel, A and Stringhetti, L and others},
  booktitle={Ground-based and Airborne Telescopes IX},
  volume={12182},
  pages={263--271},
  year={2022},
  organization={SPIE}
}

@article{grainge2017square,
  title={Square Kilometre Array: The radio telescope of the XXI century},
  author={Grainge, Keith and Alachkar, Bassem and Amy, Shaun and Barbosa, Domingos and Bommineni, Murali and Boven, Paul and Braddock, Ralph and Davis, John and Diwakar, Praveen and Francis, Vishal and others},
  journal={Astronomy reports},
  volume={61},
  number={4},
  pages={288--296},
  year={2017},
  publisher={Springer}
}

@article{Hammer_2021,
	doi = {10.1088/1748-0221/16/01/p01025},
  
	url = {https://doi.org/10.1088%2F1748-0221%2F16%2F01%2Fp01025},
  
	year = 2021,
	month = {jan},
  
	publisher = {{IOP} Publishing},
  
	volume = {16},
  
	number = {01},
  
	pages = {P01025--P01025},
  
	author = {M. Hammer and K. Yoshii and A. Miceli},
  
	title = {Strategies for on-chip digital data compression for X-ray pixel detectors},
  
	journal = {Journal of Instrumentation}
}

@article{LHCB-FIGURE-2020-018,
      title         = "{Comparison of particle selection algorithms for the LHCb
                       Upgrade}",
      collaboration = "LHCb Collaboration",
      year          = "2020",
      url           = "https://cds.cern.ch/record/2746789",
}

@article{Gligorov_2013,
	doi = {10.1088/1748-0221/8/02/p02013},
  
	url = {https://doi.org/10.1088%2F1748-0221%2F8%2F02%2Fp02013},
  
	year = 2013,
	month = {feb},
  
	publisher = {{IOP} Publishing},
  
	volume = {8},
  
	number = {02},
  
	pages = {P02013--P02013},
  
	author = {V V Gligorov and M Williams},
  
	title = {Efficient, reliable and fast high-level triggering using a bonsai boosted decision tree},
  
	journal = {Journal of Instrumentation}
}

@article{aaij2020allen,
  title={Allen: A high-level trigger on GPUs for LHCb},
  author={Aaij, Roel and Albrecht, Johannes and Belous, M and Billoir, P and Boettcher, T and Brea Rodr{\'\i}guez, A and Vom Bruch, D and C{\'a}mpora P{\'e}rez, DH and Casais Vidal, A and Craik, DC and others},
  journal={Computing and Software for big Science},
  volume={4},
  number={1},
  pages={1--11},
  year={2020},
  publisher={Springer}
}

@article{alzubaidi2021review,
  title={Review of deep learning: Concepts, CNN architectures, challenges, applications, future directions},
  author={Alzubaidi, Laith and Zhang, Jinglan and Humaidi, Amjad J and Al-Dujaili, Ayad and Duan, Ye and Al-Shamma, Omran and Santamar{\'\i}a, Jos{\'e} and Fadhel, Mohammed A and Al-Amidie, Muthana and Farhan, Laith},
  journal={Journal of big Data},
  volume={8},
  number={1},
  pages={1--74},
  year={2021},
  publisher={Springer}
}

@misc{https://doi.org/10.48550/arxiv.1603.04467,
  doi = {10.48550/ARXIV.1603.04467},
  
  url = {https://arxiv.org/abs/1603.04467},
  
  author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  
  keywords = {Distributed, Parallel, and Cluster Computing (cs.DC), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1512.01274,
  doi = {10.48550/ARXIV.1512.01274},
  
  url = {https://arxiv.org/abs/1512.01274},
  
  author = {Chen, Tianqi and Li, Mu and Li, Yutian and Lin, Min and Wang, Naiyan and Wang, Minjie and Xiao, Tianjun and Xu, Bing and Zhang, Chiyuan and Zhang, Zheng},
  
  keywords = {Distributed, Parallel, and Cluster Computing (cs.DC), Machine Learning (cs.LG), Mathematical Software (cs.MS), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@inproceedings{liu2019deep,
  title={Deep learning accelerated light source experiments},
  author={Liu, Zhengchun and Bicer, Tekin and Kettimuthu, Rajkumar and Foster, Ian},
  booktitle={2019 IEEE/ACM Third Workshop on Deep Learning on Supercomputers (DLS)},
  pages={20--28},
  year={2019},
  organization={IEEE}
}

@article{liu2022exploring,
  title={Exploring physics of ferroelectric domain walls in real time: deep learning enabled scanning probe microscopy},
  author={Liu, Yongtao and Kelley, Kyle P and Funakubo, Hiroshi and Kalinin, Sergei V and Ziatdinov, Maxim},
  journal={Advanced Science},
  pages={2203957},
  year={2022},
  publisher={Wiley Online Library}
}

@inproceedings{patton2018167,
  title={167-pflops deep learning for electron microscopy: from learning physics to atomic manipulation},
  author={Patton, Robert M and Johnston, J Travis and Young, Steven R and Schuman, Catherine D and March, Don D and Potok, Thomas E and Rose, Derek C and Lim, Seung-Hwan and Karnowski, Thomas P and Ziatdinov, Maxim A and others},
  booktitle={SC18: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={638--648},
  year={2018},
  organization={IEEE}
}

@inproceedings{chen2018tvm,
  title={$\{$TVM$\}$: An automated $\{$End-to-End$\}$ optimizing compiler for deep learning},
  author={Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Shen, Haichen and Cowan, Meghan and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and others},
  booktitle={13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)},
  pages={578--594},
  year={2018}
}

@misc{https://doi.org/10.48550/arxiv.1805.00907,
  doi = {10.48550/ARXIV.1805.00907},
  
  url = {https://arxiv.org/abs/1805.00907},
  
  author = {Rotem, Nadav and Fix, Jordan and Abdulrasool, Saleem and Catron, Garret and Deng, Summer and Dzhabarov, Roman and Gibson, Nick and Hegeman, James and Lele, Meghan and Levenstein, Roman and Montgomery, Jack and Maher, Bert and Nadathur, Satish and Olesen, Jakob and Park, Jongsoo and Rakhov, Artem and Smelyanskiy, Misha and Wang, Man},
  
  keywords = {Programming Languages (cs.PL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Glow: Graph Lowering Compiler Techniques for Neural Networks},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{https://doi.org/10.48550/arxiv.1809.02697,
  doi = {10.48550/ARXIV.1809.02697},
  
  url = {https://arxiv.org/abs/1809.02697},
  
  author = {Liu, Yizhi and Wang, Yao and Yu, Ruofei and Li, Mu and Sharma, Vin and Wang, Yida},
  
  keywords = {Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Optimizing CNN Model Inference on CPUs},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@ARTICLE {9664259,
author = {S. Zheng and R. Chen and Y. Jin and A. Wei and B. Wu and X. Li and S. Yan and Y. Liang},
journal = {IEEE Transactions on Parallel and Distributed Systems},
title = {NeoFlow: A Flexible Framework for Enabling Efficient Compilation for High Performance DNN Training},
year = {2022},
volume = {33},
number = {11},
issn = {1558-2183},
pages = {3220-3232},
abstract = {Deep neural networks (DNNs) are increasingly deployed in various image recognition and natural language processing applications. The continuous demand for accuracy and high performance has led to innovations in DNN design and a proliferation of new operators. However, existing DNN training frameworks such as PyTorch and TensorFlow only support a limited range of operators and rely on hand-optimized libraries to provide efficient implementations for these operators. To evaluate novel neural networks with new operators, the programmers have to either replace the holistic new operators with existing operators or provide low-level implementations manually. Therefore, a critical requirement for DNN training frameworks is to provide high-performance implementations for the neural networks containing new operators automatically in the absence of efficient library support. In this article, we introduce NeoFlow, which is a flexible framework for enabling efficient compilation for high-performance DNN training. NeoFlow allows the programmers to directly write customized expressions as new operators to be mapped to graph representation and low-level implementations automatically, providing both high programming productivity and high performance. First, NeoFlow provides expression-based automatic differentiation to support customized model definitions with new operators. Then, NeoFlow proposes an efficient compilation system that partitions the neural network graph into subgraphs, explores optimized schedules, and generates high-performance libraries for subgraphs automatically. Finally, NeoFlow develops an efficient runtime system to combine the compilation and training as a whole by overlapping their execution. In the experiments, we examine the numerical accuracy and performance of NeoFlow. The results show that NeoFlow can achieve similar or even better performance at the operator and whole graph level for DNNs compared to deep learning frameworks. Especially, for novel networks training, the geometric mean speedups of NeoFlow to PyTorch, TensorFlow, and CuDNN are 3.16X, 2.43X, and 1.92X, respectively.},
keywords = {training;libraries;convolution;codes;deep learning;tensors;schedules},
doi = {10.1109/TPDS.2021.3138862},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {nov}
}


@inproceedings{maleki2011evaluation,
  title={An evaluation of vectorizing compilers},
  author={Maleki, Saeed and Gao, Yaoqing and Garzar, Maria J and Wong, Tommy and Padua, David A and others},
  booktitle={2011 International Conference on Parallel Architectures and Compilation Techniques},
  pages={372--382},
  year={2011},
  organization={IEEE}
}

@misc{https://doi.org/10.48550/arxiv.1604.06174,
  doi = {10.48550/ARXIV.1604.06174},
  
  url = {https://arxiv.org/abs/1604.06174},
  
  author = {Chen, Tianqi and Xu, Bing and Zhang, Chiyuan and Guestrin, Carlos},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Training Deep Nets with Sublinear Memory Cost},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Duarte_2018,
	doi = {10.1088/1748-0221/13/07/p07027},
  
	url = {https://doi.org/10.1088%2F1748-0221%2F13%2F07%2Fp07027},
  
	year = 2018,
	month = {jul},
  
	publisher = {{IOP} Publishing},
  
	volume = {13},
  
	number = {07},
  
	pages = {P07027--P07027},
  
	author = {J. Duarte and S. Han and P. Harris and S. Jindariani and E. Kreinar and B. Kreis and J. Ngadiuba and M. Pierini and R. Rivera and N. Tran and Z. Wu},
  
	title = {Fast inference of deep neural networks in {FPGAs} for particle physics},
  
	journal = {Journal of Instrumentation}
}

@ARTICLE{7368920,  author={Nane, Razvan and Sima, Vlad-Mihai and Pilato, Christian and Choi, Jongsok and Fort, Blair and Canis, Andrew and Chen, Yu Ting and Hsiao, Hsuan and Brown, Stephen and Ferrandi, Fabrizio and Anderson, Jason and Bertels, Koen},  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},   title={A Survey and Evaluation of FPGA High-Level Synthesis Tools},   year={2016},  volume={35},  number={10},  pages={1591-1604},  doi={10.1109/TCAD.2015.2513673}}


@misc{https://doi.org/10.48550/arxiv.2203.08402,
  doi = {10.48550/ARXIV.2203.08402},
  
  url = {https://arxiv.org/abs/2203.08402},
  
  author = {Hattori, Momoko and Kobayashi, Naoki and Sato, Ryosuke},
  
  keywords = {Programming Languages (cs.PL), FOS: Computer and information sciences, FOS: Computer and information sciences, D.2.4},
  
  title = {Gradual Tensor Shape Checking},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{rajopadhye2002dependence,
  title={Dependence Analysis and Parallelizing Transformations.},
  author={Rajopadhye, Sanjay V},
  year={2002}
}

@article{10.1145/3296979.3192413,
author = {Moll, Simon and Hack, Sebastian},
title = {Partial Control-Flow Linearization},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/3296979.3192413},
doi = {10.1145/3296979.3192413},
abstract = {If-conversion is a fundamental technique for vectorization. It accounts for the fact that in a SIMD program, several targets of a branch might be executed because of divergence. Especially for irregular data-parallel workloads, it is crucial to avoid if-converting non-divergent branches to increase SIMD utilization. In this paper, we present partial linearization, a simple and efficient if-conversion algorithm that overcomes several limitations of existing if-conversion techniques. In contrast to prior work, it has provable guarantees on which non-divergent branches are retained and will never duplicate code or insert additional branches. We show how our algorithm can be used in a classic loop vectorizer as well as to implement data-parallel languages such as ISPC or OpenCL. Furthermore, we implement prior vectorizer optimizations on top of partial linearization in a more general way. We evaluate the implementation of our algorithm in LLVM on a range of irregular data analytics kernels, a neutronics simulation benchmark and NAB, a molecular dynamics benchmark from SPEC2017 on AVX2, AVX512, and ARM Advanced SIMD machines and report speedups of up to 146 % over ICC, GCC and Clang O3.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {543-556},
numpages = {14},
keywords = {SPMD, Compiler optimizations, SIMD}
}


@inproceedings{10.1145/3192366.3192413,
author = {Moll, Simon and Hack, Sebastian},
title = {Partial Control-Flow Linearization},
year = {2018},
isbn = {9781450356985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3192366.3192413},
doi = {10.1145/3192366.3192413},
abstract = {If-conversion is a fundamental technique for vectorization. It accounts for the fact that in a SIMD program, several targets of a branch might be executed because of divergence. Especially for irregular data-parallel workloads, it is crucial to avoid if-converting non-divergent branches to increase SIMD utilization. In this paper, we present partial linearization, a simple and efficient if-conversion algorithm that overcomes several limitations of existing if-conversion techniques. In contrast to prior work, it has provable guarantees on which non-divergent branches are retained and will never duplicate code or insert additional branches. We show how our algorithm can be used in a classic loop vectorizer as well as to implement data-parallel languages such as ISPC or OpenCL. Furthermore, we implement prior vectorizer optimizations on top of partial linearization in a more general way. We evaluate the implementation of our algorithm in LLVM on a range of irregular data analytics kernels, a neutronics simulation benchmark and NAB, a molecular dynamics benchmark from SPEC2017 on AVX2, AVX512, and ARM Advanced SIMD machines and report speedups of up to 146 % over ICC, GCC and Clang O3.},
booktitle = {Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {543-556},
numpages = {14},
keywords = {SIMD, SPMD, Compiler optimizations},
location = {Philadelphia, PA, USA},
series = {PLDI 2018}
}


@inproceedings{10.1145/3174243.3174268,
author = {Dai, Steve and Liu, Gai and Zhang, Zhiru},
title = {A Scalable Approach to Exact Resource-Constrained Scheduling Based on a Joint SDC and SAT Formulation},
year = {2018},
isbn = {9781450356145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3174243.3174268},
doi = {10.1145/3174243.3174268},
abstract = {Despite increasing adoption of high-level synthesis (HLS) for its design productivity advantage, success in achieving high quality-of-results out-of-the-box is often hindered by the inexactness of the common HLS optimizations. In particular, while scheduling forms the algorithmic core to HLS technology, current scheduling algorithms rely heavily on fundamentally inexact heuristics that make ad hoc local decisions and cannot accurately and globally optimize over a rich set of constraints. To tackle this challenge, we propose a scheduling formulation based on system of integer difference constraints (SDC) and Boolean satisfiability (SAT) to exactly handle a variety of scheduling constraints. We develop a specialized scheduler based on conflict-driven learning and problem-specific knowledge to optimally and efficiently solve the resource-constrained scheduling problem. By leveraging the efficiency of SDC algorithms and scalability of modern SAT solvers, our scheduling technique is able to achieve on average over 100x improvement in runtime over the integer linear programming (ILP) approach while attaining optimal latency. By integrating our scheduling formulation into a state-of-the-art open-source HLS tool, we further demonstrate the applicability of our scheduling technique with a suite of representative benchmarks targeting FPGAs.},
booktitle = {Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {137-146},
numpages = {10},
keywords = {satisfiability modulo theory, optimal solution, ilp, exact algorithm, resource-constrained scheduling, system of difference constraints, integer linear programming, rcs, hls, efficiency, satisfiability, sdc, high-level synthesis, scalability, problem-specific knowledge, conflict-driven learning, sat, scheduling},
location = {Monterey, CALIFORNIA, USA},
series = {FPGA '18}
}

@article{baruch1996scheduling,
  title={Scheduling algorithms for high-level synthesis},
  author={Baruch, Zoltan},
  journal={ACAM Scientific Journal},
  volume={5},
  number={1-2},
  pages={48--57},
  year={1996}
}

@misc{rosser2018cocotb,
  title={Cocotb: a Python-based digital logic verification framework},
  author={Rosser, Benjamin John},
  year={2018},
  publisher={CERN}
}

@article{williamsicarus,
  title={Icarus Verilog, 1998--2020},
  author={Williams, Stephen},
  journal={URL http://iverilog. icarus. com}
}

@article{Liu:fs5198,
	author = {Liu, Zhengchun and Sharma, Hemant and Park, Jun-Sang and Kenesei, Peter and Miceli, Antonino and Almer, Jonathan and Kettimuthu, Rajkumar and Foster, Ian},
	journal = {IUCrJ},
	month = {Jan},
	number = {1},
	pages = {104--113},
	title = {{{\it BraggNN}: fast X-ray Bragg peak analysis using deep learning}},
	volume = {9},
	year = {2022}}


@article{guideultrascale,
  title={UltraScale Architecture DSP Slice},
  author={Guide, Advance Specification User},
  publisher={Citeseer}
}

@article{leibson2013xilinx,
  title={Xilinx ultrascale: The next-generation architecture for your next-generation architecture},
  author={Leibson, Steve and Mehta, Nick},
  journal={Xilinx White Paper WP435},
  volume={143},
  year={2013}
}

@misc{rapidwright,
  title = {Create placed and routed DCP to cross SLR},
  howpublished = {\url{https://www.rapidwright.io/docs/SLR_Crosser_DCP_Creator_Tutorial.html}},
  note = {Accessed: 2022-10-15}
}

@inproceedings{oppermann2022eurollvm,
    author = {Oppermann, Julian and Urbach, Mike and Demme, John}, 
    title = {How to {Make} {Hardware} with {Maths}: {An} {Introduction} to {CIRCT}'s {Scheduling} {Infrastructure}},
    booktitle = {2022 European {LLVM} {Developers}' {Meeting} ({EuroLLVM})},
    year = {2022}
}

@misc{https://doi.org/10.48550/arxiv.1502.03167,
  doi = {10.48550/ARXIV.1502.03167},

  url = {https://arxiv.org/abs/1502.03167},

  author = {Ioffe, Sergey and Szegedy, Christian},

  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},

  publisher = {arXiv},

  year = {2015},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{eldridge2021mlir,
  title={MLIR as hardware compiler infrastructure},
  author={Eldridge, Schuyler and Barua, Prithayan and Chapyzhenka, Aliaksei and Izraelevitz, Adam and Koenig, Jack and Lattner, Chris and Lenharth, Andrew and Leontiev, George and Schuiki, Fabian and Sunder, Ram and others},
  booktitle={Workshop on Open-Source EDA Technology (WOSET)},
  year={2021}
}

@INPROCEEDINGS{9605269,
  author={McCaskey, Alexander and Nguyen, Thien},
  booktitle={2021 IEEE International Conference on Quantum Computing and Engineering (QCE)},
  title={A MLIR Dialect for Quantum Assembly Languages},
  year={2021},
  volume={},
  number={},
  pages={255-264},
  doi={10.1109/QCE52317.2021.00043}
}

@phdthesis{blockhaus2022framework,
  title={A Framework for Adaptive Reprogramming Using a JIT-Compiled Domain Specific Language for Query Execution},
  author={Blockhaus, Paul and Broneske, Ing David},
  year={2022},
  school={Master's thesis. Ottovon-Guericke University Magdeburg}
}

@inproceedings{lattner2004llvm,
  title={LLVM: A compilation framework for lifelong program analysis \& transformation},
  author={Lattner, Chris and Adve, Vikram},
  booktitle={International symposium on code generation and optimization, 2004. CGO 2004.},
  pages={75--86},
  year={2004},
  organization={IEEE}
}

@misc{https://doi.org/10.48550/arxiv.2202.03293,
  doi = {10.48550/ARXIV.2202.03293},

  url = {https://arxiv.org/abs/2202.03293},

  author = {Vasilache, Nicolas and Zinenko, Oleksandr and Bik, Aart J. C. and Ravishankar, Mahesh and Raoux, Thomas and Belyaev, Alexander and Springer, Matthias and Gysi, Tobias and Caballero, Diego and Herhut, Stephan and Laurenzo, Stella and Cohen, Albert},

  keywords = {Programming Languages (cs.PL), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {Composable and Modular Code Generation in MLIR: A Structured and Retargetable Approach to Tensor Compiler Construction},

  publisher = {arXiv},

  year = {2022},

  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{https://doi.org/10.48550/arxiv.2008.08272,
  doi = {10.48550/ARXIV.2008.08272},
  
  url = {https://arxiv.org/abs/2008.08272},
  
  author = {Jin, Tian and Bercea, Gheorghe-Teodor and Le, Tung D. and Chen, Tong and Su, Gong and Imai, Haruki and Negishi, Yasushi and Leu, Anh and O'Brien, Kevin and Kawachiya, Kiyokuni and Eichenberger, Alexandre E.},
  
  keywords = {Programming Languages (cs.PL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Compiling ONNX Neural Network Models Using MLIR},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{10.14778/3551793.3551801,
author = {Jungmair, Michael and Kohn, Andr\'{e} and Giceva, Jana},
title = {Designing an Open Framework for Query Optimization and Compilation},
year = {2022},
issue_date = {July 2022},
publisher = {VLDB Endowment},
volume = {15},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3551793.3551801},
doi = {10.14778/3551793.3551801},
abstract = {Since its invention, data-centric code generation has been adopted for query compilation by various database systems in academia and industry. These database systems are fast but maximize performance at the expense of developer friendliness, flexibility, and extensibility. Recent advances in the field of compiler construction identified similar issues for domain-specific compilers and introduced a solution with MLIR, a generic infrastructure for domain-specific dialects.We propose a layered query compilation stack based on MLIR with open intermediate representations that can be combined at each layer. We further propose moving query optimization into the query compiler to benefit from the existing optimization infrastructure and make cross-domain optimization viable. With LingoDB, we demonstrate that the used approach significantly decreases the implementation effort and is highly flexible and extensible. At the same time, LingoDB achieves high performance and low compilation latencies.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {2389-2401},
numpages = {13}
}

@inproceedings{smith2002introducing,
  title={Introducing reference semantics via refinement},
  author={Smith, Graeme},
  booktitle={Formal Methods and Software Engineering: 4th International Conference on Formal Engineering Methods, ICFEM 2002 Shanghai, China, October 21--25, 2002 Proceedings 4},
  pages={588--599},
  year={2002},
  organization={Springer}
}

@misc{nevergrad,
    author = {J. Rapin and O. Teytaud},
    title = {{Nevergrad - A gradient-free optimization platform}},
    year = {2018},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://GitHub.com/FacebookResearch/Nevergrad}},
}

@inproceedings{ebner2008generalized,
  title={Generalized instruction selection using SSA-graphs},
  author={Ebner, Dietmar and Brandner, Florian and Scholz, Bernhard and Krall, Andreas and Wiedermann, Peter and Kadlec, Albrecht},
  booktitle={Proceedings of the 2008 ACM SIGPLAN-SIGBED conference on Languages, compilers, and tools for embedded systems},
  pages={31--40},
  year={2008}
}
@misc{ladderdialect,
  author = "{Lei Zhang}",
  title = "MLIR CodeGen Dialects for Machine Learning Compilers",
  year = "2022",
  howpublished = "\url{https://www.lei.chat/posts/mlir-codegen-dialects-for-machine-learning-compilers/}",
  note = "[Online; accessed 26-March-2023]"
}
@article{hayakawa1948art,
  title={'The Art of Plain Talk'},
  author={Hayakawa, SI},
  journal={American Speech},
  volume={23},
  number={2},
  pages={138--141},
  year={1948},
  publisher={JSTOR}
}
@inproceedings{10.1145/3178372.3179509,
author = {Zhao, Jie and Kruse, Michael and Cohen, Albert},
title = {A Polyhedral Compilation Framework for Loops with Dynamic Data-Dependent Bounds},
year = {2018},
isbn = {9781450356442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3178372.3179509},
doi = {10.1145/3178372.3179509},
abstract = {},
booktitle = {Proceedings of the 27th International Conference on Compiler Construction},
pages = {14-24},
numpages = {11},
keywords = {polyhedral model, loop nest optimization, dynamic counted loop, parallelizing compiler},
location = {Vienna, Austria},
series = {CC 2018}
}
@article{dickson2011importance,
  title={Importance of explicit vectorization for CPU and GPU software performance},
  author={Dickson, Neil G and Karimi, Kamran and Hamze, Firas},
  journal={Journal of Computational Physics},
  volume={230},
  number={13},
  pages={5383--5398},
  year={2011},
  publisher={Elsevier}
}
@misc{nvidiasass,
  title = "PTX and SASS Assembly Debugging",
  year = "2015",
  howpublished = "\url{https://docs.nvidia.com/gameworks/content/developertools/desktop/ptx_sass_assembly_debugging.htm}",
  note = "[Online; accessed 26-March-2023]"
}
@article{kessenich2018spir,
  title={Spir-v specification},
  author={Kessenich, John and Ouriel, Boaz and Krisch, Raun},
  journal={Khronos Group},
  volume={3},
  pages={17},
  year={2018}
}
@article{behnel2010cython,
  title={Cython: The best of both worlds},
  author={Behnel, Stefan and Bradshaw, Robert and Citro, Craig and Dalcin, Lisandro and Seljebotn, Dag Sverre and Smith, Kurt},
  journal={Computing in Science \& Engineering},
  volume={13},
  number={2},
  pages={31--39},
  year={2010},
  publisher={IEEE}
}
@misc{nuitka,
  author = "{Kay Hayen}",
  title = "Nuitka the Python Compiler",
  year = "2023",
  howpublished = "\url{https://nuitka.net/}",
  note = "[Online; accessed 26-March-2023]"
}
@inproceedings{10.1145/3578360.3580275,
author = {Shajii, Ariya and Ramirez, Gabriel and Smajlovi\'{c}, Haris and Ray, Jessica and Berger, Bonnie and Amarasinghe, Saman and Numanagi\'{c}, Ibrahim},
title = {Codon: A Compiler for High-Performance Pythonic Applications and DSLs},
year = {2023},
isbn = {9798400700880},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578360.3580275},
doi = {10.1145/3578360.3580275},
booktitle = {Proceedings of the 32nd ACM SIGPLAN International Conference on Compiler Construction},
pages = {191-202},
numpages = {12},
keywords = {intermediate representation, domain-specific languages, type checking, Python, optimization},
location = {Montr\'{e}al, QC, Canada},
series = {CC 2023}
}
@inproceedings{lam2015numba,
  title={Numba: A llvm-based python jit compiler},
  author={Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
  booktitle={Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC},
  pages={1--6},
  year={2015}
}
@misc{zimmerman2022langcc,
      title={langcc: A Next-Generation Compiler Compiler}, 
      author={Joe Zimmerman},
      year={2022},
      eprint={2209.08385},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}
@article{parr1995antlr,
  title={ANTLR: A predicated-LL (k) parser generator},
  author={Parr, Terence J. and Quong, Russell W.},
  journal={Software: Practice and Experience},
  volume={25},
  number={7},
  pages={789--810},
  year={1995},
  publisher={Wiley Online Library}
}

@inproceedings{10.1145/1565824.1565827,
author = {Bolz, Carl Friedrich and Cuni, Antonio and Fijalkowski, Maciej and Rigo, Armin},
title = {Tracing the Meta-Level: PyPy's Tracing JIT Compiler},
year = {2009},
isbn = {9781605585413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1565824.1565827},
doi = {10.1145/1565824.1565827},
booktitle = {Proceedings of the 4th Workshop on the Implementation, Compilation, Optimization of Object-Oriented Languages and Programming Systems},
pages = {18-25},
numpages = {8},
location = {Genova, Italy},
series = {ICOOOLPS '09}
}
@inproceedings{barany2014pylibjit,
  title={pylibjit: A JIT Compiler Library for Python.},
  author={Barany, Gerg{\"o}},
  booktitle={Software Engineering (Workshops)},
  pages={213--224},
  year={2014}
}
@misc{pyjion,
  author = "{Anthony Shaw}",
  title = "Nuitka the Python Compiler",
  year = "2023",
  howpublished = "\url{https://pyjion.readthedocs.io/en/latest/}",
  note = "[Online; accessed 26-March-2023]"
}
@misc{pyston,
  title = "Pyston",
  year = "2023",
  howpublished = "\url{https://github.com/pyston/pyston}",
  note = "[Online; accessed 26-March-2023]"
}
@article{troelsen2017philosophy,
  title={The Philosophy of. NET Core},
  author={Troelsen, Andrew and Japikse, Philip and Troelsen, Andrew and Japikse, Philip},
  journal={Pro C\# 7: With. NET and. NET Core},
  pages={1245--1253},
  year={2017},
  publisher={Springer}
}
@article{frostig2018compiling,
  title={Compiling machine learning programs via high-level tracing},
  author={Frostig, Roy and Johnson, Matthew James and Leary, Chris},
  journal={Systems for Machine Learning},
  volume={4},
  number={9},
  year={2018},
  publisher={SysML}
}
@article{kiselyov2012typed,
  title={Typed tagless final interpreters},
  author={Kiselyov, Oleg},
  journal={Generic and indexed programming: International spring school, sSGIP 2010, oxford, uK, march 22-26, 2010, revised lectures},
  pages={130--174},
  year={2012},
  publisher={Springer}
}
@article{10.1145/3158140,
author = {Amin, Nada and Rompf, Tiark},
title = {Collapsing Towers of Interpreters},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {POPL},
url = {https://doi.org/10.1145/3158140},
doi = {10.1145/3158140},
month = {dec},
articleno = {52},
numpages = {33},
keywords = {compiler, reflection, interpreter, staging, Lisp, Scala}
}
@misc{ike2015inside,
  title={Inside the Python Virtual Machine},
  author={Ike-Nwosu, Obi},
  year={2015},
  publisher={Lean Publishing}
}
@inproceedings{li2009note,
  title={A note on auto-tuning GEMM for GPUs},
  author={Li, Yinan and Dongarra, Jack and Tomov, Stanimire},
  booktitle={Computational Science--ICCS 2009: 9th International Conference Baton Rouge, LA, USA, May 25-27, 2009 Proceedings, Part I 9},
  pages={884--892},
  year={2009},
  organization={Springer}
}
@incollection{CARDOSO2017137,
title = {Chapter 5 - Source code transformations and optimizations},
editor = {João M.P. Cardoso and José Gabriel F. Coutinho and Pedro C. Diniz},
booktitle = {Embedded Computing for High Performance},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {137-183},
year = {2017},
isbn = {978-0-12-804189-5},
doi = {https://doi.org/10.1016/B978-0-12-804189-5.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128041895000053},
author = {João M.P. Cardoso and José Gabriel F. Coutinho and Pedro C. Diniz},
keywords = {Code transformations, Code optimizations, Loop transformations, Code refactoring},
abstract = {}
}
@misc{pybind11,
   author = {Wenzel Jakob and Jason Rhinelander and Dean Moldovan},
   year = {2016},
   note = {https://github.com/pybind/pybind11},
   title = {pybind11 - Seamless operability between C++11 and Python}
} 
@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}
@software{stablehlo,
  author = {},
  title = {{StableHLO}: Backward compatible ML compute opset inspired by HLO/MHLO},
  url = {https://github.com/openxla/stablehlo},
  version = {0.4.15},
  year = {2023},
}
@software{torchmlir,
  author = {},
  title = {{Torch-MLIR}: The Torch-MLIR project aims to provide first class support from the PyTorch ecosystem to the MLIR ecosystem},
  url = {https://github.com/llvm/torch-mlir},
  year = {2023},
}
@software{numbamlir,
  author = {Ivan Butygin, Diptorup Deb, Alexander Kalistratov},
  title = {{numba-mlir}: MLIR-based numba backend},
  url = {https://github.com/numba/numba-mlir},
  year = {2023},
}
@inproceedings{10.1145/2833157.2833162,
author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
title = {Numba: A LLVM-Based Python JIT Compiler},
year = {2015},
isbn = {9781450340052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2833157.2833162},
doi = {10.1145/2833157.2833162},
abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is often a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addition, we share our experience in building a JIT compiler using LLVM[1].},
booktitle = {Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC},
articleno = {7},
numpages = {6},
keywords = {Python, compiler, LLVM},
location = {Austin, Texas},
series = {LLVM '15}
}
@article{10.1145/3391902,
author = {Reissmann, Nico and Meyer, Jan Christian and Bahmann, Helge and Sj\"{a}lander, Magnus},
title = {RVSDG: An Intermediate Representation for Optimizing Compilers},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {6},
issn = {1539-9087},
url = {https://doi.org/10.1145/3391902},
doi = {10.1145/3391902},
abstract = {Intermediate Representations (IRs) are central to optimizing compilers as the way the program is represented may enhance or limit analyses and transformations. Suitable IRs focus on exposing the most relevant information and establish invariants that different compiler passes can rely on. While control-flow centric IRs appear to be a natural fit for imperative programming languages, analyses required by compilers have increasingly shifted to understand data dependencies and work at multiple abstraction layers at the same time. This is partially evidenced in recent developments such as the Multi-Level Intermediate Representation (MLIR) proposed by Google. However, rigorous use of data flow centric IRs in general purpose compilers has not been evaluated for feasibility and usability as previous works provide no practical implementations.We present the Regionalized Value State Dependence Graph (RVSDG) IR for optimizing compilers. The RVSDG is a data flow centric IR where nodes represent computations, edges represent computational dependencies, and regions capture the hierarchical structure of programs. It represents programs in demand-dependence form, implicitly supports structured control flow, and models entire programs within a single IR. We provide a complete specification of the RVSDG, construction and destruction methods, as well as exemplify its utility by presenting Dead Node and Common Node Elimination optimizations. We implemented a prototype compiler and evaluate it in terms of performance, code size, compilation time, and representational overhead. Our results indicate that the RVSDG can serve as a competitive IR in optimizing compilers while reducing complexity.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {dec},
articleno = {49},
numpages = {28},
keywords = {Regionalized value state dependence graph (RVSDG), intermediate representation, LLVM}
}
@software{numbamlir,
  author = {Markus Böck},
  title = {{pylir}: An optimizing ahead-of-time Python Compiler},
  url = {https://github.com/zero9178/Pylir},
  year = {2023},
}
@software{,
  author = {{Tal Ben-Nun, Kaushik Kulkarni, Mehdi Amini, Berke Ates}},
  title = {{pyMLIR}: Python Interface for the Multi-Level Intermediate Representation},
  url = {https://github.com/spcl/pymlir},
  year = {2023},
}
@article{brownxdsl,
  title={xDSL: A common compiler ecosystem for domain specific languages},
  author={Brown, Nick and Grosser, Tobias and Fehr, Mathieu and Steuwer, Michel and Kelly, Paul}
}