\section{Problem Formulation}
\label{sec:prob-form}
Our robot is tasked to reach an unseen goal in a partially-mapped environment in minimum expected cost (distance).
The synthetic robot is equipped with a semantically-aware planar laser scanner, which it can use to both localize and update its partial semantic-occupancy-grid map of its local surroundings, limited by range and obstacle occlusion.
As the robot navigates the partially-mapped environment, it updates its belief state $b_t$ to include newly-revealed space and its semantic class.
% At each time step $t$, the action $a_t$ specifies how the robot should move towards the unseen goal while minimizing the expected cost.

Formally, we represent this problem as a Partially Observable Markov Decision Process~\cite{kaelbling1998,littman1997} (POMDP). The expected cost $Q$ under this model can be written via a belief space variant of the Bellman equation~\cite{Pineau-2002-8519}:
\begin{equation}
\label{eq:POMDP}
\begin{split}
    Q(b_t,a_t) = \sum_{b_{t+1}} P(b_{t+1}|b_t,a_t)\Big[R(b_{t+1},b_t,a_t) \\ + \min_{a_{t+1} \in \mathcal{A}(b_t+1)}Q(b_{t+1},a_{t+1})\Big],
\end{split}
\end{equation}
where $R(b_{t+1},b_t,a_t)$ is the cost of reaching belief state $b_{t+1}$ from $b_t$ by taking action $a_t$ and $P(b_{t+1}|b_t, a_t)$ is the transition probability.
%As we cannot solve this equation directly, we will leverage the Learning over Subgoals Planning abstraction~\cite{pmlr-v87-stein18a} to 