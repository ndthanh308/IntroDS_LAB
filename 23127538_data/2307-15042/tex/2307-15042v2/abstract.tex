The gradual nature of a diffusion process that synthesizes samples in small increments constitutes a key ingredient of Denoising Diffusion Probabilistic Models (DDPM), which have presented unprecedented quality in image synthesis and been recently explored in the motion domain.
In this work, we propose to adapt the gradual diffusion concept (operating along a diffusion \textit{time-axis}) into the \textit{temporal-axis} of the motion sequence. Our key idea is to extend the DDPM framework to support \textit{temporally varying} denoising, thereby entangling the two axes. Using our special formulation, we iteratively denoise a \textit{motion buffer} that contains a set of increasingly-noised poses, which auto-regressively produces an arbitrarily long stream of frames. With a \textit{stationary} diffusion time-axis, in each diffusion step we increment only the temporal-axis of the motion such that the framework produces a new, clean frame which is removed from the beginning of the  buffer, followed by a newly drawn noise vector that is appended to it. This new mechanism paves the way towards a new framework for long-term motion synthesis with applications to character animation and other domains. Our code and project are publicly available. \footnote{Project page: \url{https://threedle.github.io/TEDi/}}







