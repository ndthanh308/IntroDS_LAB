\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{Robust5}
Said~Fahri Altindis, Yusuf Dalva, and Aysegul Dundar.
\newblock Benchmarking the robustness of instance segmentation models.
\newblock {\em {CoRR}}, 2021.

\bibitem{nltk}
Steven Bird, Ewan Klein, and Edward Loper.
\newblock {\em Natural Language Processing with Python}.
\newblock O'Reilly, 2009.

\bibitem{DETR}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em {ECCV}}, 2020.

\bibitem{Ref-NMS}
Long Chen, Wenbo Ma, Jun Xiao, and et al.
\newblock Ref-nms: Breaking proposal bottlenecks in two-stage referring
  expression grounding.
\newblock In {\em {AAAI}}, 2021.

\bibitem{SSG}
Xinpeng Chen, Lin Ma, Jingyuan Chen, and et al.
\newblock Real-time referring expression comprehension by single-stage
  grounding network.
\newblock {\em {CoRR}}, 2018.

\bibitem{cheng2021maskformer}
Bowen Cheng, Alexander~G. Schwing, and Alexander Kirillov.
\newblock Per-pixel classification is not all you need for semantic
  segmentation.
\newblock 2021.

\bibitem{TransVG}
Jiajun Deng, Zhengyuan Yang, Tianlang Chen, and et al.
\newblock Transvg: End-to-end visual grounding with transformers.
\newblock In {\em {CVPR}}, 2021.

\bibitem{Bert}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em {NAACL-HLT}}, 2019.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock 2021.

\bibitem{CenterNet}
Kaiwen Duan, Song Bai, Lingxi Xie, Honggang Qi, Qingming Huang, and Qi Tian.
\newblock Centernet: Keypoint triplets for object detection.
\newblock In {\em {ICCV}}, 2019.

\bibitem{robot_navigation}
Zipeng Fu, Ashish Kumar, Ananye Agarwal, and et al.
\newblock Coupling vision and proprioception for navigation of legged robots.
\newblock In {\em {CVPR}}, 2022.

\bibitem{Robust1}
Robert Geirhos, Carlos R.~Medina Temme, Jonas Rauber, and et al.
\newblock Generalisation in humans and deep neural networks.
\newblock In {\em {NeurIPS}}, 2018.

\bibitem{Xavier}
Xavier Glorot and Yoshua Bengio.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In Yee~Whye Teh and D.~Mike Titterington, editors, {\em {AISTATS}},
  2010.

\bibitem{ResNet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em {CVPR}}, 2016.

\bibitem{CMN}
Ronghang Hu, Marcus Rohrbach, Jacob Andreas, and et al.
\newblock Modeling relationships in referential expressions with compositional
  modular networks.
\newblock In {\em {CVPR}}, 2017.

\bibitem{hu2016segmentation}
Ronghang Hu, Marcus Rohrbach, and Trevor Darrell.
\newblock Segmentation from natural language expressions.
\newblock In {\em ECCV}, 2016.

\bibitem{LBYL-Net}
Binbin Huang, Dongze Lian, Weixin Luo, and et al.
\newblock Look before you leap: Learning landmark features for one-stage visual
  grounding.
\newblock In {\em {CVPR}}, 2021.

\bibitem{visual_dialog2}
Xiaoze Jiang, Jing Yu, Yajing Sun, and et al.
\newblock {DAM:} deliberation, abandon and memory networks for generating
  detailed and non-repetitive responses in visual dialogue.
\newblock 2020.

\bibitem{mdetr}
Aishwarya Kamath, Mannat Singh, Yann LeCun, and et al.
\newblock {MDETR} - modulated detection for end-to-end multi-modal
  understanding.
\newblock In {\em {CVPR}}, 2021.

\bibitem{previous2}
Andrej Karpathy and Li Fei{-}Fei.
\newblock Deep visual-semantic alignments for generating image descriptions.
\newblock In {\em {CVPR}}, 2015.

\bibitem{previous1}
Andrej Karpathy, Armand Joulin, and Li Fei{-}Fei.
\newblock Deep fragment embeddings for bidirectional image sentence mapping.
\newblock 2014.

\bibitem{ReferItGame}
Sahar Kazemzadeh, Vicente Ordonez, Mark Matten, and Tamara~L. Berg.
\newblock Referitgame: Referring to objects in photographs of natural scenes.
\newblock In {\em {EMNLP}}, 2014.

\bibitem{kim2022restr}
Namyup Kim, Dongwon Kim, Cuiling Lan, Wenjun Zeng, and Suha Kwak.
\newblock Restr: Convolution-free referring image segmentation using
  transformers.
\newblock 2022.

\bibitem{li2023transformer}
Xiangtai Li, Henghui Ding, Wenwei Zhang, Haobo Yuan, Jiangmiao Pang, Guangliang
  Cheng, Kai Chen, Ziwei Liu, and Chen~Change Loy.
\newblock Transformer-based visual segmentation: A survey.
\newblock {\em arXiv preprint arXiv:2304.09854}, 2023.

\bibitem{li2023panopticpartformer++}
Xiangtai Li, Shilin Xu, Yibo Yang, Haobo Yuan, Guangliang Cheng, Yunhai Tong,
  Zhouchen Lin, Ming-Hsuan Yang, and Dacheng Tao.
\newblock Panopticpartformer++: A unified and decoupled view for panoptic part
  segmentation.
\newblock {\em arXiv preprint arXiv:2301.00954}, 2023.

\bibitem{li2023tube}
Xiangtai Li, Haobo Yuan, Wenwei Zhang, Guangliang Cheng, Jiangmiao Pang, and
  Chen~Change Loy.
\newblock Tube-link: A flexible cross tube baseline for universal video
  segmentation.
\newblock {\em {ICCV}}, 2023.

\bibitem{li2022videoknet}
Xiangtai Li, Wenwei Zhang, Jiangmiao Pang, Kai Chen, Guangliang Cheng, Yunhai
  Tong, and Chen~Change Loy.
\newblock Video k-net: A simple, strong, and unified baseline for video
  segmentation.
\newblock In {\em CVPR}, 2022.

\bibitem{RealTime}
Yue Liao, Si Liu, Guanbin Li, Fei Wang, Yanjie Chen, Chen Qian, and Bo Li.
\newblock A real-time cross-modality correlation filtering method for referring
  expression comprehension.
\newblock In {\em {CVPR}}, 2020.

\bibitem{RetinaNet}
Tsung{-}Yi Lin, Priya Goyal, Ross~B. Girshick, Kaiming He, and Piotr
  Doll{\'{a}}r.
\newblock Focal loss for dense object detection.
\newblock In {\em {ICCV}}, 2017.

\bibitem{NMTree}
Daqing Liu, Hanwang Zhang, Zheng{-}Jun Zha, and et al.
\newblock Learning to assemble neural module tree networks for visual
  grounding.
\newblock In {\em {CVPR}}, 2019.

\bibitem{GDINO}
Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Chunyuan
  Li, Jianwei Yang, Hang Su, Jun Zhu, et~al.
\newblock Grounding dino: Marrying dino with grounded pre-training for open-set
  object detection.
\newblock {\em arXiv preprint arXiv:2303.05499}, 2023.

\bibitem{swin}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em ICCV}, 2021.

\bibitem{RefCOCOg}
Junhua Mao, Jonathan Huang, Alexander Toshev, Oana Camburu, Alan~L. Yuille, and
  Kevin Murphy.
\newblock Generation and comprehension of unambiguous object descriptions.
\newblock In {\em {CVPR}}, 2016.

\bibitem{image_captioning}
Yue Ming, Nannan Hu, Chunxiao Fan, and et al.
\newblock Visuals to text: {A} comprehensive review on automatic image
  captioning.
\newblock {\em IEEE/CAA Journal of Automatica Sinica}, 2022.

\bibitem{Robust2}
Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and et al.
\newblock Exploring generalization in deep learning.
\newblock In {\em {NeurIPS}}, 2017.

\bibitem{previous3}
Ahmad Ostovar, Suna Bensch, and Thomas Hellstr{\"{o}}m.
\newblock Natural language guided object retrieval in images.
\newblock {\em Acta Informatica}, 2021.

\bibitem{Flickr30k}
Bryan~A. Plummer, Liwei Wang, Chris~M. Cervantes, Juan~C. Caicedo, Julia
  Hockenmaier, and Svetlana Lazebnik.
\newblock Flickr30k entities: Collecting region-to-phrase correspondences for
  richer image-to-sentence models.
\newblock {\em {CVPR}}, 2017.

\bibitem{YOLOV3}
Joseph Redmon and Ali Farhadi.
\newblock Yolov3: An incremental improvement.
\newblock {\em CoRR}, 2018.

\bibitem{Faster-RCNN}
Shaoqing Ren, Kaiming He, Ross~B. Girshick, and Jian Sun.
\newblock Faster {R-CNN:} towards real-time object detection with region
  proposal networks.
\newblock {\em {PAMI}}, 2017.

\bibitem{GIOU}
Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian~D. Reid, and
  Silvio Savarese.
\newblock Generalized intersection over union: {A} metric and a loss for
  bounding box regression.
\newblock In {\em {CVPR}}, 2019.

\bibitem{Zero-shot}
Arka Sadhu, Kan Chen, and Ram Nevatia.
\newblock Zero-shot grounding of objects from natural language queries.
\newblock In {\em {ICCV}}, 2019.

\bibitem{Robust4}
Christos Sakaridis, Dengxin Dai, and Luc~Van Gool.
\newblock Semantic foggy scene understanding with synthetic data.
\newblock {\em {IJCV}}, 2018.

\bibitem{Robust3}
Christos Sakaridis, Dengxin Dai, and Luc~Van Gool.
\newblock Guided curriculum model adaptation and uncertainty-aware evaluation
  for semantic nighttime image segmentation.
\newblock In {\em {CVPR}}, 2019.

\bibitem{visual_dialog1}
Kaili Sun, Chi Guo, Huyin Zhang, and et al.
\newblock {HVLM:} exploring human-like visual cognition and language-memory
  network for visual dialog.
\newblock {\em Information Processing \& Management}, 2022.

\bibitem{MHA}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em {NeurIPS}}, 2017.

\bibitem{Two-Branch}
Liwei Wang, Yin Li, Jing Huang, and Svetlana Lazebnik.
\newblock Learning two-branch neural networks for image-text matching tasks.
\newblock {\em {PAMI}}, 2019.

\bibitem{wu2023betrayed}
Jianzong Wu, Xiangtai Li, Henghui Ding, Xia Li, Guangliang Cheng, Yunhai Tong,
  and Chen~Change Loy.
\newblock Betrayed by captions: Joint caption grounding and generation for open
  vocabulary instance segmentation.
\newblock {\em {ICCV}}, 2023.

\bibitem{RRIS}
Jianzong Wu, Xiangtai Li, Xia Li, Henghui Ding, Yunhai Tong, and Dacheng Tao.
\newblock Towards robust referring image segmentation.
\newblock {\em {CoRR}}, 2022.

\bibitem{wu2023open}
Jianzong Wu, Xiangtai Li, Shilin Xu, Haobo Yuan, Henghui Ding, Yibo Yang, Xia
  Li, Jiangning Zhang, Yunhai Tong, Xudong Jiang, Bernard Ghanem, and Dacheng
  Tao.
\newblock Towards open vocabulary learning: A survey.
\newblock {\em arXiv pre-print}, 2023.

\bibitem{xu2022fashionformer}
Shilin Xu, Xiangtai Li, Jingbo Wang, Guangliang Cheng, Yunhai Tong, and Dacheng
  Tao.
\newblock Fashionformer: A simple, effective and unified baseline for human
  fashion segmentation and recognition.
\newblock {\em ECCV}, 2022.

\bibitem{vltvg}
Li Yang, Yan Xu, Chunfeng Yuan, and et al.
\newblock Improving visual grounding with visual-linguistic verification and
  iterative reasoning.
\newblock In {\em {CVPR}}, 2022.

\bibitem{ReSC-Large}
Zhengyuan Yang, Tianlang Chen, Liwei Wang, and et al.
\newblock Improving one-stage visual grounding by recursive sub-query
  construction.
\newblock In {\em {ECCV}}, 2020.

\bibitem{onestage1}
Zhengyuan Yang, Tianlang Chen, Liwei Wang, and et al.
\newblock Improving one-stage visual grounding by recursive sub-query
  construction.
\newblock In {\em {ECCV}}, 2020.

\bibitem{Metric1}
Zhengyuan Yang, Tianlang Chen, Liwei Wang, and Jiebo Luo.
\newblock Improving one-stage visual grounding by recursive sub-query
  construction.
\newblock In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan{-}Michael
  Frahm, editors, {\em {ECCV}}, 2020.

\bibitem{FAOA}
Zhengyuan Yang, Boqing Gong, Liwei Wang, and et al.
\newblock A fast and accurate one-stage approach to visual grounding.
\newblock In {\em {CVPR}}, 2019.

\bibitem{yang2021lavt}
Zhao Yang, Jiaqi Wang, Yansong Tang, Kai Chen, Hengshuang Zhao, and Philip~HS
  Torr.
\newblock Lavt: Language-aware vision transformer for referring image
  segmentation.
\newblock 2022.

\bibitem{MAttNet}
Licheng Yu, Zhe Lin, Xiaohui Shen, Jimei Yang, Xin Lu, Mohit Bansal, and
  Tamara~L. Berg.
\newblock Mattnet: Modular attention network for referring expression
  comprehension.
\newblock In {\em {CVPR}}, 2018.

\bibitem{RefCOCO}
Licheng Yu, Patrick Poirson, Shan Yang, Alexander~C. Berg, and Tamara~L. Berg.
\newblock Modeling context in referring expressions.
\newblock In {\em {ECCV}}, 2016.

\bibitem{VC}
Hanwang Zhang, Yulei Niu, and Shih{-}Fu Chang.
\newblock Grounding referring expressions in images by variational context.
\newblock In {\em {CVPR}}, 2018.

\bibitem{zhang2023rethinking}
Jiangning Zhang, Xiangtai Li, Jian Li, Liang Liu, Zhucun Xue, Boshen Zhang,
  Zhengkai Jiang, Tianxin Huang, Yabiao Wang, and Chengjie Wang.
\newblock Rethinking mobile block for efficient neural models.
\newblock {\em ICCV}, 2023.

\bibitem{zhang2022eatformer}
Jiangning Zhang, Xiangtai Li, Yabiao Wang, Chengjie Wang, Yibo Yang, Yong Liu,
  and Dacheng Tao.
\newblock Eatformer: Improving vision transformer inspired by evolutionary
  algorithm.
\newblock {\em arXiv preprint arXiv:2206.09325}, 2022.

\bibitem{zhou2022transvod}
Qianyu Zhou, Xiangtai Li, Lu He, Yibo Yang, Guangliang Cheng, Yunhai Tong,
  Lizhuang Ma, and Dacheng Tao.
\newblock Transvod: end-to-end video object detection with spatial-temporal
  transformers.
\newblock {\em {PAMI}}, 2023.

\bibitem{zhu2022uni}
Jinguo Zhu, Xizhou Zhu, Wenhai Wang, Xiaohua Wang, Hongsheng Li, Xiaogang Wang,
  and Jifeng Dai.
\newblock Uni-perceiver-moe: Learning sparse generalist models with conditional
  moes.
\newblock {\em arXiv preprint arXiv:2206.04674}, 2022.

\bibitem{zhu2021uni}
Xizhou Zhu, Jinguo Zhu, Hao Li, Xiaoshi Wu, Xiaogang Wang, Hongsheng Li,
  Xiaohua Wang, and Jifeng Dai.
\newblock Uni-perceiver: Pre-training unified architecture for generic
  perception for zero-shot and few-shot tasks.
\newblock {\em arXiv preprint arXiv:2112.01522}, 2021.

\end{thebibliography}
