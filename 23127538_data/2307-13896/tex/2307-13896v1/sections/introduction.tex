\section{Introduction}

The advent of Large Language Models (LLMs) such as GPT-3~\cite{brown2020language} has a profound impact on the research landscape of not only Natural Language Processing (NLP) studies but also the entire AI and Big Data communities. The fine-tuning of Large Language Models (LLMs) has proven highly effective across a multitude of tasks. In the current computing environment, the proliferation of mobile devices and sensors has become instrumental in information acquisition. Leveraging LLMs to process this wealth of information holds the potential to significantly enhance the convenience and expediency of our daily lives. However, the immense scale of parameters in LLMs entails significant computational costs for fine-tuning. Performing fine-tuning directly on these devices is impractical due to the formidable requirement of computation power. Hence, the pursuit of an effective fine-tuning method that achieves desirable outcomes with minimal parameter fine-tuning has become imperative.

Additionally, not all mobile devices can collect a sufficient amount of data. Typically, mobile device users only have processing permissions for the data generated during their own usage, and this data is often unlabeled. For example, mobile device users provide reviews for movies, hotels, or restaurants, and we can obtain a small amount of labeled data based on their positive or negative feedback. However, there is still a significant amount of comment data, such as those on TikTok or Twitter, where we cannot ascertain the sentiment. Fortunately, there is a substantial user base of mobile devices, which means that we have a significant amount of data available, albeit dispersed among various devices. Hence, distributed learning with few-shot labeled data has become an emerging topic. 

Federated learning (FL) enables distributed training of a global model on decentralized data. Hence, we propose leveraging FL to collaboratively train these devices and achieve effective fine-tuning of a global model. Additionally, we explore optimal utilization of labeled and unlabeled samples under the FL scenarios. One approach, PET~\cite{schick2020exploiting}, rephrases input examples using diverse prompts to aid the LLMs' understanding of the task. Fine-tuning is performed on each prompt using a LLM. The resulting models assign soft labels to unlabeled data, expanding the labeled dataset for standard supervised training. However, PET's multi-task setup in a federated environment incurs high computational costs and communication overhead, posing challenges for resource-constrained clients like mobile devices and sensors. 

Our contributions are summarized as follows:
\begin{enumerate}[noitemsep,leftmargin=*]

\item We consider an under-studied task of fine-tuning LLMs with distributed devices with limited communications and local computational powers. 

\item  We fine-tune the LLMs by adding task descriptions to the input examples for text sentiment classification. We start with a small number of labeled samples and then use a semi-supervised method to augment the dataset and enhance the fine-tuning process.

\item We introduce a low-parameter methodology called Low Parameter Federated Learning, abbreviated as LP-FL, for efficiently fine-tuning a small subset of the local model parameters then federate averaging over all clients.

\item We demonstrate that our method achieves comparable or even better performance than Full-Parameter Federated Learning, while greatly reducing computational costs and communication requirements on individual devices.
\end{enumerate}