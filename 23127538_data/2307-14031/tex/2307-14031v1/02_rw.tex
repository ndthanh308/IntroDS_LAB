\begin{table*}[t!]
\centering
\def\arraystretch{0.75}
{\scriptsize 
\resizebox{\textwidth}{!}{
\begin{tabular}{l cccc cccc}
\toprule
\rowcolor{Gray}
\textbf{Dataset (Reference)} & \# Langs    & \# Domains     & \# Train & \# Test & No Translation? & Culturally Adapted? & Coherent? & Multi-P? \\
\cmidrule(lr){2-5} \cmidrule(lr){6-9}
WOZ 2.0~\cite{mrksic-etal-2017-semantic} & {3} & {1} & {600} & {400} & {\xmark} & {\xmark} & {\bluecheck} & {\bluecheck} \\
BiToD~\cite{Lin:2021bitod} & {2} & {5} & {2,894} & {451} & {\bluecheck} & {\bluecheck} & {\bluecheck} & {\xmark} \\
AllWOZ~\cite{Zuo:2021allwoz} & {8} & {5} & {40} & {50} & {\xmark} & {\xmark} & {\bluecheck} & {\bluecheck} \\
GlobalWOZ~\cite{ding-etal-2022-globalwoz} & {21} & {7} & {0 (8,437)}$^{*}$ & {500 (1,000)}$^{*}$ & {\xmark} & {\bluecheck} & {\xmark} & {\xmark} \\
Multi$^2$WOZ~\cite{hung-etal-2022-multi2woz} & {5} & {7} & {0} & {1,000} & {\xmark} & {\xmark} & {\bluecheck} & {\bluecheck} \\
\cmidrule(lr){2-5} \cmidrule(lr){6-9}
\textbf{\dataset} (this work) & {4} & {7} & {7,440} & {860} & {\bluecheck} & {\bluecheck} & {\bluecheck} & {\bluecheck} \\
\bottomrule
\end{tabular}
}
}%
\caption{Summary of multilingual \tod datasets that support multiple languages and \tod tasks (including E2E learning), with more details concerning each dimension of comparison available in \S\ref{s:rw}. For clarity, we do not show (i) monolingual \tod datasets constructed for languages other than English, we refer the reader to the survey of \newcite{Razumovskaia:2022survey} for a comprehensive overview; as well as (ii) the body of multilingual \tod datasets that focus solely on NLU for \tod (see \S\ref{s:rw}). \textbf{\# Langs} refers to the total number of languages in each dataset, including English. \textbf{\# Train} and \textbf{\# Test} refer to the average number of human-created or human-curated dialogs \textit{per each language} in the respective portions of each dataset. \textbf{Multi-P} refers to multi-parallelism of dialogs in the dataset. $(*)$ GlobalWOZ releases training data created automatically by an English-target NMT system, without any human curation nor post-processing, and manually curates only a portion of 500 dialogs from the target language test sets (see \S\ref{s:rw} for more details).}
\label{tab:summary_dataset}
\end{table*}

\section{\dataset versus Limitations of Current Multilingual \tod Datasets}
\label{s:rw}
We now delve deeper into the main benefits of \dataset, characterizing how its key properties make it a unique \tod resource. The summary and statistics of the most relevant prior work are provided in Table~\ref{tab:summary_dataset}. Building upon this table, we discuss those datasets along with other related work in what follows, focusing on the five desirable properties of \dataset and how these counteract the detected main limitations of other datasets.


\vspace{0.5mm}
\noindent \textbf{P1. Supporting Multiple Languages and \tod Tasks.} 
There has been a surge of interest in the creation of multilingual \tod datasets, aiming to mitigate the language resource gap in multilingual NLP \cite{ponti-etal-2019-modeling,joshi-etal-2020-state}. Despite the effort, the gap is still much more pronounced for dialog tasks and data than for some other NLP tasks such as NLI \cite{conneau-etal-2018-xnli,Ebrahimi:2022americasnli} or NER~\cite{adelani-etal-2021-masakhaner}, also due to its increased time demands and cost of annotation.\footnote{For instance, the creation of the validation and test sets of the XCOPA dataset requires a total time ranging from 12 to 20 hours per language \cite{ponti-etal-2020-xcopa}. In contrast, the creation of the validation and testing sets for each individual language in \dataset requires over 300 hours of effort. Even when considering the annotation cost per sentence (utterance), which amounts to approximately \$0.17 per utterance, the cost is notably higher than the per sentence annotation cost for NER (\$0.06 as reported by~\citet{Bontcheva2017}) and NLI (\$0.01015 per instance as reported by~\citet{marelli-etal-2014-sick}).}  Further, the majority of multilingual \tod datasets focused only on two standard NLU tasks (i.e., intent detection and slot labeling), again due to the high cost and specific challenges posed by collecting full dialog data \cite{Budzianowski:2018multiwoz}. The first wave of such NLU datasets were built upon the single-domain English ATIS dataset \cite{hemphill-etal-1990-atis}, extending it to 10 languages via human translation \cite{Upadhyay:2018icassp,xu-etal-2020-end,Dao:2021interspeech}. More recent NLU datasets cover multiple domains and wider linguistic typology and geography \cite{schuster-etal-2019-cross-lingual,FitzGerald:2022arxiv,Moghe:2022multi3nlu,Majewska:2023cod}. However, current NLU datasets (i) still support only the two NLU tasks, and (ii) provide utterances `in isolation' (i.e., out of the context of the full dialog which facilitates their multilingual construction). Further, (iii) some datasets do not provide any training data and are useful only for evaluation of (zero-shot) cross-lingual transfer; (iv) all the datasets except that of \citet{Majewska:2023cod} and the concurrent work of \newcite{presto} were constructed via translation from the source English datasets.



Monolingual `end-to-end' \tod datasets, which support NLU as well as other \tod tasks (i.e., modeling and evaluation of the full \tod pipeline), have been created only for particular high-resource languages. MultiWOZ \cite{Budzianowski:2018multiwoz} and Taskmaster \cite{byrne-etal-2019-taskmaster} are two large-scale multi-domain English datasets spanning 7 and 6 domains, respectively, containing both single-domain and multi-domain dialogs. Inspired by MultiWOZ, monolingual RisaWOZ \cite{quan-etal-2020-risawoz} and CrossWOZ \cite{zhu-etal-2020-crosswoz} datasets have been created for Chinese.
 Crucially, multilingual multi-domain \tod datasets that support full \tod modeling are still scarce, see Table~\ref{tab:summary_dataset}, and they all come with some core limitations, as discussed next.

\vspace{0.5mm}
\noindent \textbf{P2. Avoiding Translation-Based Design.} The majority of datasets have been obtained via \textit{manual or semi-automatic translation} (e.g., via post-editing MT output - PEMT) of an English source dataset \cite{Zuo:2021allwoz,ding-etal-2022-globalwoz,hung-etal-2022-multi2woz}. The translation-based approach is cost-efficient and can natively yield data which is comparable across languages, but results in (i) undesired `translationese' effects \cite{Artetxe:2020emnlp}, (ii) lacks dialog naturalness \cite{ding-etal-2022-globalwoz}, and (iii) typically leads to overinflated and thus misleading performance of \tod systems. For instance, \citet{Majewska:2023cod} empirically validate that cross-lingual transfer performance substantially increases when exactly the same dialogs are obtained via automatic or manual translation rather than via a bottom-up approach relying on native speakers of the target languages. 

Unlike prior work (i.e., all datasets from Table~\ref{tab:summary_dataset} except BiToD), the honed outline-based construction of \dataset (see \S\ref{s:dataset} later) avoids all the negative implications of translation, while maintaining cost efficiency (and thus enabling its large scale), supporting cultural adaptation, and enabling coherence and multi-parallelism.

\vspace{0.5mm}
\noindent \textbf{P3. Dataset Scale and Large-Scale Training.}
\dataset offers a substantially larger number of dialogs for training than any previous multilingual `full \tod' dataset, and it treats the four supported languages in an equitable way: i.e., it provides the same set of manually (bottom-up) constructed dialogs for training, development, and testing in each language. Previous work (Multi$^2$WOZ, AllWOZ, GlobalWOZ) targeted the creation of test data only, for evaluating cross-lingual transfer scenarios. These datasets come (i) without providing any training data at all (Multi$^2$WOZ), or (ii) with a very small set of post edited MT-obtained dialogs (AllWOZ),\footnote{The tiny size of AllWOZ is even more problematic at the level of single domains, e.g., it contains only 13 dialogs for the \textit{Taxi} domain, hindering any generalisable evaluations.} or (iii) with automatically created MT-based training data only (GlobalWOZ). The only exception is BiToD \cite{Lin:2021bitod}, but it spans only two, highest-resourced languages, a smaller number of domains, and has approximately three times fewer training data than \dataset. For instance, \dataset contains almost 124,000 turns \textit{per each represented language} ($\sim$98,000/12,500/12,500), with a total of 494,116 turns; for comparison, the \textit{total} number of turns in BiToD is 115,638, while it is 143,048 in the original English-only MultiWOZ.

\vspace{0.5mm}
\noindent \textbf{P4. (Improved) Cultural Adaptation.} 
A large number of datasets for multilingual NLP ignores the fact that the data should also be adapted to the target cultures and concepts~\cite{ponti-etal-2020-xcopa,Herscovich:2022acl}. Besides (i) propagating the source language bias towards possible \textit{conversational concept}s (e.g., the US-tied concept of \textit{tailgating} or conversations about \textit{baseball}) \cite{ponti-etal-2020-xcopa}, the lack of the so-called \textit{cultural adaptation} also (ii) creates peculiar or more unlikely \textit{conversational contexts} (e.g., a user speaking to a Turkish \tod system about restaurants in Cambridge) \cite{ding-etal-2022-globalwoz}, or (iii) even ignores specificities of a particular culture (e.g., postcodes are not used in Arabic-speaking countries). The only two datasets that try to incorporate the notion of cultural adaptation into their design are BiToD and GlobalWOZ (see Table~\ref{tab:summary_dataset}). However, BiToD's adaptation is based on a very specific bilingual region of the world (Hong Kong), while GlobalWOZ's automatic cultural adaptation approach results in a large number of incoherent dialogs and annotation errors, e.g., see Figure~\ref{fig:globalwozex}. We thus adopt a new and improved cultural adaptation approach that ensures high-quality, coherent and multi-parallel dialogs across languages while respecting the underlying cultural traits, see \S\ref{s:dataset} later.


\vspace{0.5mm}
\noindent \textbf{P5. Dialog Coherence and `Multi-Parallelism'.}
Finally, due to their design properties and oversimplifying assumptions, some datasets break coherence and multi-parallelism of dialogs. GlobalWOZ, while performing a form of cultural adaptation, (i) creates erroneous slot value annotations that are inconsistent with the dialog ontology and database in the particular language, and (ii) even induces inconsistent annotations within an individual dialog. Another problem with GlobalWOZ is that the authors select a subset of 500 test set dialogs for human PEMT work based on a simple heuristic: they opt for dialogs for which the sum of corpus-level
frequencies of their constitutive 4-grams, normalized by dialog length, is the largest. This selection, not motivated in the original paper and performed independently for each language, entails that different portions of the original English MultiWOZ are included into the final language-specific test sets. This design choice, besides (i) artificially decreasing linguistic diversity of dialogs chosen for the test set in 
each language,\footnote{The selection heuristic favors dialogs that contain
the same most frequent 4-grams globally.} also (ii) breaks the desired multi-parallel nature of the test set. As a consequence, GlobalWOZ overestimates downstream \tod performance for target languages, and cannot be used for any direct comparison of \tod task performance across different languages since test sets per language contain different dialogs, as also pointed out by \citet{hung-etal-2022-multi2woz}.

\dataset is the only dataset which performs cultural adaptation and avoids confouding factors such as GlobalWOZ's selection heuristics, while maintaining the desired properties of dialog coherence and multi-parallelism.




% Figure environment removed