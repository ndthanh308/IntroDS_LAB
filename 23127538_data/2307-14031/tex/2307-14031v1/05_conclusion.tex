\section{Conclusion}
\label{s:conclusion}

We have introduced a large-scale, culturally adapted, multilingual, and multi-parallel training and evaluation framework for \tod, which covers $\sim$495,000 dialog turns over 4 languages. The dataset was motivated by the limitations of current \tod datasets in multilingual setups, which we systematically analyzed as one contribution of this work. Owing to its unique set of properties and scale, beyond initial analyses and experiments conducted in this work, we hope that \dataset will inspire a wide array of further developments in modeling, analysis, and interpretability of multilingual and cross-lingual multi-domain \tod.

For instance, future work could replicate the data collection process to expand the dataset to even more languages (including low-resource ones). Further, one could analyze the performance disparities observed in Tables~\ref{tab:nlu-results}-\ref{tab:table_e2e} within each language-specific \tod system, as well as explore methods to mitigate such disparities, e.g., through the utilization of cross-lingual transfer techniques. Future work could also explore evaluation metrics beyond the ones explored in this work, e.g., it would be interesting to explore the correlation between the increase in evaluation scores in multilingual \tod systems and the resulting performance gain in terms of factors such as utility, user experience, and user satisfaction.  Additionally, it would be important to investigate how \tod systems should, ideally, be constructed and evaluated across different languages to ensure their inclusiveness and robustness in diverse linguistic contexts. 

\rparagraph{Code and Data}
We release the dataset and code at \href{https://github.com/cambridgeltl/multi3woz}{\nolinkurl{github.com/cambridgeltl/multi3woz}}.








