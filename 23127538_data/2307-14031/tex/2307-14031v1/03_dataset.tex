% Figure environment removed

\section{\dataset}
\label{s:dataset}





\dataset comprises linguistically and culturally adapted task-oriented dialogs in four languages:  Arabic (\ara; Afro-Asiatic), English (\eng; Indo-European), French (\fra; Indo-European), and Turkish (\tur; Turkic). A total of 27,480 (3$\times$9,160) dialogs is collected for \ara, \fra, \tur, while the dataset also includes a subset of 9,160 normalized and corrected MultiWOZ v2.3 dialogs.\footnote{We select 9,160 out of MultiWOZ's full set of 10,438 dialogs by filtering out erroneous dialogs identified during the normalization and cultural adaptation process; problematic dialogs were also recorded by our annotators during the dialog generation and quality control phases (see later in \S\ref{s:dataset}).}

In what follows, we describe its creation, as depicted in Figure~\ref{fig:fig1}. Our approach involves three key steps:
\begin{enumerate*}[label=(\roman*)]
\item \textit{normalizing annotations} from the original MultiWOZ v2.3 with canonical values.
\item \textit{cultural adaptation} by contextualizing dialogs to entities from the relevant cultures.
\item \textit{collecting linguistically adapted dialogs} from target language native speakers using a bottom-up outlined-based method.
\end{enumerate*}


\rparagraph{Preliminaries and Notation}
In \tod, the domains of a dataset (e.g., MultiWOZ) and the systems built upon it are typically defined by an \textit{ontology}, which provides a structured representation of an underlying \textit{database}. The ontology specifies slots that encompass all entity attributes and their corresponding values~\cite{Budzianowski:2018multiwoz}.
\dataset is designed to be fully compatible with the original English MultiWOZ's ontology and data format, but now with culturally adapted database entries (see Figure~\ref{fig:fig1}). 



\dataset $\mathbbm{D}$ contains four multi-parallel sets of dialogs, namely $\mathbbm{D}^{\ara}$, $\mathbbm{D}^{\eng}$, $\mathbbm{D}^{\fra}$, and $\mathbbm{D}^{\tur}$, along with their corresponding \textit{cultural-specific databases} denoted as $\mathbbm{E}^{\ara}$, $\mathbbm{E}^{\eng}$, $\mathbbm{E}^{\fra}$, and $\mathbbm{E}^{\tur}$.\footnote{In order to simplify our notation, we represent a backend database as a set of data entries, where each entry corresponds to a real-world entity within the target culture.} Each database entry, $\mathcal{E} \in \mathbbm{E}$, contains a set of slot-value pairs, such that $\mathcal{E} = \{({s}_{1}, {v}_{1}), ({s}_{2}, {v}_{2}),\cdots,({s}_{n}, {v}_{n})\}$.\footnote{We denote each attribute of an entity as a slot and consider the domain of an entity as an inherent attribute. 
For example, \textit{\{(domain, police), (name, parkside police station), (address, Parkside, Cambridge), (phone, 01223358966), (postcode, cb11jg)\}} is a database entry in $\mathbbm{E}^{\eng}$.}
Each dialog in the dataset is represented as a list of natural language utterances, with alternating turns between the user and system initiated by the user. Each turn is annotated with its corresponding sentence-level meaning representation.
Namely, for $\mathcal{D} \in \mathbbm{D}$, $\mathcal{D} = [(\mathbf{u}_{1}, \mathbf{a}_1),  \cdots, (\mathbf{u}_{j}, \mathbf{a}_j)]$, where $\mathbf{u}$ is a surface form (user or system) utterance; $\mathbf{a}$ is a dialog act representation; $j$ is the length of the dialog $\mathcal{D}$.


A dialog act $\mathbf{a}$ is then defined as a set of tuples $\mathbf{a} = \{(d_1, i_1, s_1, v_1), \cdots, (d_k, i_k, s_k, v_k)\}$, where each tuple consists of domain $d$, intent $i$, slot $s$, and slot value $v$.




\rparagraph{Slot-Value Normalization}
In the English MultiWOZ dataset, slot values are annotated as text spans within the corresponding utterances. This annotation scheme allows for more flexible and natural language expressions of the canonical value $v_{\text{truth}}$ described in the ontology and database (e.g., \textit{13:00}), resulting in various surface forms ${v^{(1)}, \cdots, v^{(l)}}$ (e.g., \textit{1 pm}, \textit{1:00 pm}, \textit{one}). However, this flexibility can create a discrepancy between the expected canonical value required by the backend API and the predicted value by the model.\footnote{The query sent to the backend API is formulated using a formal language that lacks the flexibility of natural language. This issue can significantly affect the performance of extractive models, such as extractive DST models~\cite{heck-etal-2020-trippy, zhou-etal-2023-xqa}.}

Moreover, the absence of a 1-to-1 mapping between the canonical value in the database and the annotations in MultiWOZ, coupled with erroneous or misspelled entries, hinders the consistent and systematic adaptation of culture-dependent entities to the target language.
To address this, we \textit{manually} created a normalization dictionary and assigned canonical values to all slot values across the English MultiWOZ dataset. For example, we created a normalization dictionary for the \textit{restaurant-name} slot, mapping 544 distinct surface forms to 110 canonical names. These canonical names correspond exactly to the entities in the English \textit{restaurants} domain's database, enabling a one-to-one mapping between the entities described in dialogs and those in the database. Besides facilitating cultural adaptation through the creation of surface form agnostic outlines, we believe that this time-consuming yet crucial normalization process will also enable consistent evaluations of models built on \dataset. Henceforth, any mention of a slot value $v$ assumes that it is in its canonical form.\footnote{The introduction of slot values in canonical forms offers supplementary information to the original MultiWOZ annotation. The original format can be automatically derived, enabling backward compatibility with previous models.}


\rparagraph{Cultural Adaptation}
While English MultiWOZ contains only dialogs describing entities in the Cambridge (UK) area, \dataset expands the scope to three additional languages targeting three cities where the target languages are considered native: Dubai for Arabic, Paris for French, and Ankara for Turkish.\footnote{We fully acknowledge that here we use the term `culture' (imprecisely) as a proxy for the limited set of properties, customs, and entities to be expected or common at the target location. We also acknowledge that language-culture mappings are typically many-to-many, with the possibility of multiple languages being native to the same culture, and one language spreading over more than one culture or subculture \cite{Herscovich:2022acl}. Our (simplified) choice is primarily driven by pragmatic considerations and feasibility requirements.} 
To ensure that our dataset respects and reflects the cultural traits pertaining to each target city and language, we propose a systematic approach for cultural adaptation, which ensures dialog coherence and multi-parallelism across all languages, and includes the following steps: 
\begin{enumerate*}[]
\item \textit{slot-value localization/redistribution} with cultural awareness,
\item \textit{controlled entity replacement} with one-to-one entity mappings,
\item \textit{slot-value randomization} to avoid verbatim memorization.
\end{enumerate*}

We perform \textit{slot-value redistribution} to adjust the original slot and value to align with the target `culture'. These modifications are based on the feedback from native speakers of the target language with expertise in the corresponding cultural context. To better fit the target culture, we remove \eng-specific slots and values that are irrelevant to the culture. For example, we obliterate the \textit{postcode} slot in the Arabic dataset $\mathbbm{D}^{\ara}$ due to its limited relevance in the associated culture.\footnote{We also consider religious factors: e.g., to respect local culture, we replace the `gastropub' \textit{restaurant type} with the value `Arab', or `nightclub' with `waterpark' for the \textit{attractions} slot. Moreover, we address the issue of unbalanced entity distribution in the original MultiWOZ, which is heavily skewed towards Cambridge (UK) and contains a disproportionate number of mentions of `colleges' and `guest houses'.
To mitigate this bias, we swap certain types of entities; e.g., we exchange the very specific term \textit{`college'} with \textit{`architecture'} and \textit{`guest house'} with \textit{`hotel'} to offer a better localization of the entity distribution for the target location.}


The main objective of our proposed cultural adaptation method is to perform \textit{controlled entity replacement} using a 1-to-1 entity mapping.
As a prerequisite, we first construct a localized database (e.g., $\mathbb{E}^{\ara}$ for Arabic) for each target language. This database aims to reflect real-world entities and properties, and has been constructed by human participants in our project, native speakers of the target languages, who referred to a variety of public knowledge sources on the Internet, including the Google Places API and TripAdvisor API.\footnote{However, we note that, for database completeness, a portion of the entity information has been synthetically generated due to missing information on the Web, e.g., when a restaurant does not provide a phone number on its website.}

In order to construct such a 1-to-1 mapping, an English entity $\mathcal{E}^{\eng}$ and a target entity (e.g., $\mathcal{E}^{\ara}$) can be mapped to each other only if all categorical slot values attributed to each entity are identical.\footnote{A categorical slot is defined by the ontology such that the possible values for this slot are a closed set. For example, the slot `price range' can only have the values of `cheap', `moderate', and `expensive'. In contrast, the value for a \textit{hotel name} is an open set and not categorical, as it can be any string.}
Namely, the following condition holds: $\forall ({s}^{\eng}, {v}^{\eng}) \in \mathcal{E}^{\eng}, \exists ({s}^{\ara}, {v}^{\ara}) \in \mathcal{E}^{\ara} : {v}^{\eng} = {v}^{\ara} \; \text{if} \; \texttt{is\_categorical}({s}^{\eng})$.
This strategy guarantees a consistent distribution of entities with respect to each categorical property as MultiWOZ. It further facilitates the coherent and multi-parallel creation of dialogs, particularly when the user requests a certain property of a desired entity along the progress of dialogs (e.g. `an \textit{expensive} restaurant'). This stands in contrast to the random sampling cultural adaptation solution of GlobalWOZ, which results in frequently mismatched entities being returned in response to the user request, and often results in dialog incoherence.




The original MultiWOZ contains a substantial number of randomized slot values, such as \textit{time}, \textit{reference}, and \textit{taxi-phone}. To prevent verbatim memorization and undesired data artefacts, we perform \textit{slot-value randomization} independently in each target dialog subset in \dataset.
For \textit{time}-related slot values in \dataset, we apply the randomization by adding a 1-hour random offset drawn from a uniform distribution [-1, 1] to the original value, as also illustrated in Figure~\ref{fig:fig1}.
We ensure that all \textit{time} relevant slots (e.g. \textit{leaving time} and \textit{arriving time}) in a dialog are equivalently shifted by the same randomized offset. For \textit{reference} numbers, we employ the 1-to-1 randomly generated reference mapping.
Regarding \textit{taxi-phone} values, we first adhere to the target culture's specific phone pattern followed by a 1-to-1 randomly generated phone mapping. 
In general, this procedure mitigates the risk of exploiting annotation artifacts and consequent overfitting when conducting cross-lingual transfer learning experiments.


\rparagraph{Outline-Based Dialog Generation}
By adopting the outline-based dialog generation process we simultaneously enable cultural adaptation while eliminating the impact of syntactic and lexical grounding in the source language (i.e., the so-called ``translation artifacts''), while keeping the annotation protocol feasible \cite{Majewska:2023cod}.
The outline-based method can be decomposed into two steps: \textit{outline creation} (i.e., creating dialog schemata) and \textit{dialog writing} (i.e., creating the actual surface realizations, utterances, from the dialog schemata).

Following \citet{Majewska:2023cod}, \textit{outline creation} involves creating minimal but comprehensive instructions for the so-called \textit{dialog creators} (termed DCs henceforth) to generate dialogs that fully convey specific intents and slots while avoiding the imposition of predefined syntactic structures or linguistic expressions. 
As depicted in Figure~\ref{fig:fig1}, we convert a culturally adapted (termed \textit{CA-ed} henceforth) %
dialog act (e.g., using \ara as an example language, $\mathbf{a}^{\ara}$) into a human-interpretable outline based on a set of manually defined templates, where different sets of templates are used for the user and system utterances. Given a tuple $(d, i, s, v^{\ara}) \in \mathbf{a}^{\ara}$, we transform a domain-intent pair $d$-$i$ into a natural language instruction, e.g., \texttt{Restaurant-Inform} $\Rightarrow$ \textit{``Express your intent to search for a restaurant with the following properties:''}. In addition, the slot $s$ is mapped to a predefined natural language description, and it is presented along with the CA-ed slot value $v^{\ara}$ (e.g., \textit{booking time = 18:45}).
As illustrated in Figure~\ref{fig:fig1}, in cases where there are multiple tuples with the same pair $d$-$i$, we group them together and present within a \textit{``card''}.
We note that a target language utterance (e.g., $\mathbf{u}^{\ara}$) can be constructed based on multiple cards, with each card corresponding to a unique domain-intent pair $d$-$i$.\footnote{\textit{Restaurant-Inform} is the domain-intent pair for the utterance \textit{There will be 5 of us and 19:45 would
be great.}}
Besides, each card may contain multiple slot-value pairs, where each slot value is shown as a CA-ed value (e.g., $v^{\ara}$).
To take full advantage of our outline-based framework, we have developed a Web-based annotation toolkit along with detailed annotation guidelines; the latter is made publicly available.


\textit{Dialog writing} is then carried out by bilingual speakers as DCs. They are (i) native in the target language and (ii) fluent in English: following the results from our pilots, we opted for keeping the English templates as it facilitated the quality control of templates and cards while it did not have any detrimental effect on the quality of finally generated target language dialogs. The DCs were instructed to write natural-sounding exchanges in their native language between a hypothetical user and an assistant, based on the outlines derived from the CA-ed dialog act (e.g. $\mathbf{a}^{\ara}$) and a set of user goals that the hypothetical user wants to achieve (e.g., \textit{You are looking for a place to stay.}). 
For each utterance $\mathbf{u}$ from the source \eng dataset, the tasks of the DCs were then as follows: 
\textbf{1)} writing a native dialog utterance from the card(s) that covers all the slot values from the cards;
\textbf{2)} annotating character-level span indices for each slot value $v^{\ara}$;
\textbf{3)} indicating with a binary flag for each domain-intent pair $d$-$i$ whether this dialog act retains coherence of the full dialog, this way also signaling and capturing errors still present in the English MultiWOZ v2.3 dataset.


% Figure environment removed


\rparagraph{Duration, Cost, Dialog Creators, Quality Control}
The logistically and technically complex data collection process spanned 14 months, starting in January 2022. The full cost of data collection was $\sim$\$64,500, equally distributed across the three target languages.  
The recruited DCs are (i) professional translators and (ii) college students, recruited via the ProZ platform (\url{www.proz.com}) or from universities worldwide. A total of 133 native Arabic speakers, 112 native French speakers, and 75 native Turkish speakers contributed to the dataset. 


We applied a number of quality control mechanisms throughout the data collection process. First, to ensure that the DCs have fully understood the instructions and all (sub)tasks, they were required to complete a qualification round before creating any actually deployed data. Second, our annotation platform features a real-time automatic check for all submissions, providing feedback and highlighting issues for the collected dialogs. Finally, we also ran two rounds of \textit{post-collection dialog editing}: we invited a carefully selected small group of dialog creators, who had consistently produced exceptional high-quality dialogs, to review and, if necessary, edit all the dialogs in the validation and test sets of all three target languages.


\rparagraph{Ethical and Responsible Data Creation and Use}
Following the principles from~\citet{rogers-etal-2021-just-think}, the project has placed a high priority on ethical and responsible data creation and use. It underwent the full Ethics Approval process at University of Cambridge, and we describe other ethics-related aspects here. %


\rrparagraph{Terms of Use}
\dataset is released under the same MIT License as the original MultiWOZ.



\rrparagraph{Privacy}
To comply with the EU General Data Protection Regulation (GDPR), we have acted as a data controller and collected the minimum of personal data required for this project. 
All participants provided informed consent by signing a \textit{Participant Consent Form} before any data collection occurred. %
To adhere to the principle of data minimization, we collected only the participants' email addresses as individually identifiable information for the sole purpose of processing payments.
Our dataset consists solely of hypothetical dialogs in which the domains and content have been restricted and predefined, minimizing the risk of personal data being present in \dataset.

\rrparagraph{Compensation}
The DCs were compensated based on the number of dialogs they contributed to the dataset, with a payment rate of approximately \$12/h. As stated in our consent form, they were able to withdraw from the study at any time. %








\rparagraph{Data Structure and Statistics}
Figure~\ref{fig:examples} presents an example of multi-parallel dialogs from \dataset. All dialogs in \dataset consist of parallel surface form utterances in multiple languages and retain the same annotations as the original MultiWOZ. Precisely, each dialog  $\mathcal{D}$ is annotated with a CA-ed user goal, as well as for each utterance $\mathbf{u}$ in the dialog: a CA-ed dialog act, a CA-ed dialog state. In addition, \dataset offers (i) annotations for character-level textual spans for all the slot values in the dialog act to steer span extraction-based solutions to slot labeling \cite{joshi-etal-2020-spanbert}, and (ii) a binary coherence indicator. The dataset is released in three standard formats: (i) \texttt{json} files following the structure of MultiWOZ \cite{Budzianowski:2018multiwoz}; (ii) a format compatible with the Huggingface repository \cite{wolf-etal-2020-transformers,lhoest-etal-2021-datasets}; (iii) ConvLab-3-compatible format \cite{convlab-3}.


% Figure environment removed


\dataset's language-independent features, e.g. the frequency of dialog acts and average dialog length, closely resemble those of the original MultiWOZ; we thus focus on the statistics pertaining to language and cultural adaptation. %
Figure~\ref{fig:fig2} presents the distribution of the number of tokens per turn, with white spaces as the token delimiter. Note that each language exhibits variance in its morphosyntactic properties (e.g., Turkish is an agglutinative language), which naturally impacts the expected utterance length. Further, we find that 13.3\% of the slot values in the dialog acts are normalized with canonical values, while 38.7\% of the dialog acts' slot values are provided with CA-ed values. The type-to-token ratio (TTR) varies across languages, with English having a lower TTR value (0.010) compared to Arabic (0.032), French (0.023), and Turkish (0.035). In comparison to the GlobalWOZ dataset, which is an MT-based dataset without CA, our dataset (\dataset) achieves an increased TTR for Arabic ($\uparrow$ 0.013), French ($\uparrow$ 0.006), and Turkish ($\uparrow$ 0.014).\footnote{For this comparison, we utilize the ``F\&E'' proportion of the GlobalWOZ dataset. In this dataset, English utterances are translated into the target language using Google Translate, while preserving the slot values associated with English entities. The calculation of the TTR is limited to the dialogs that are included in both the GlobalWOZ dataset and our dataset.} This outcome highlights that \dataset's bottom-up design sparked higher semantic variability and naturalness in the target languages~\cite{Majewska:2023cod}.
We further highlight the higher semantic diversity of utterances in \dataset in comparison to PEMT-based methods such as the one used by Multi$^2$WOZ. We select a subset of 1,586 Arabic dialogs of flows shared between the two datasets and calculate the average pairwise cosine similarity between utterances in each data subset and their corresponding utterances in the English MultiWOZ, relying on LaBSE \cite{labse} as a state-of-the-art multilingual sentence encoder.
The scores of 0.54 (\dataset) and 0.91 (Multi$^2$WOZ) suggest the higher semantic variability created through the outline-based approach with cultural adaptation.















