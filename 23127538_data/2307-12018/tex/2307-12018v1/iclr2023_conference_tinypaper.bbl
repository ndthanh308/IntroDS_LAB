\begin{thebibliography}{20}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bello et~al.(2019)Bello, Zoph, Vaswani, Shlens, and Le]{xu2020aanet}
Irwan Bello, Barret Zoph, Ashish Vaswani, Jonathon Shlens, and Quoc~V. Le.
\newblock Attention augmented convolutional networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, October 2019.

\bibitem[Chen et~al.(2019)Chen, Wang, Pang, Cao, Xiong, Li, Sun, Feng, Liu, Xu,
  et~al.]{chen2019mmdetection}
Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu~Xiong, Xiaoxiao Li,
  Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, et~al.
\newblock Mmdetection: Open mmlab detection toolbox and benchmark.
\newblock \emph{arXiv preprint arXiv:1906.07155}, 2019.

\bibitem[Gao et~al.(2019)Gao, Xie, Wang, and Li]{gao2019globalgsopnet}
Zilin Gao, Jiangtao Xie, Qilong Wang, and Peihua Li.
\newblock Global second-order pooling convolutional networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  3024--3033, 2019.

\bibitem[Goyal et~al.(2017)Goyal, Doll{\'a}r, Girshick, Noordhuis, Wesolowski,
  Kyrola, Tulloch, Jia, and He]{goyal2017accurate}
Priya Goyal, Piotr Doll{\'a}r, Ross Girshick, Pieter Noordhuis, Lukasz
  Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.
\newblock Accurate, large minibatch sgd: Training imagenet in 1 hour.
\newblock \emph{arXiv preprint arXiv:1706.02677}, 2017.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  770--778, 2016.

\bibitem[He et~al.(2017)He, Gkioxari, Doll{\'a}r, and Girshick]{he2017maskrcnn}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pp.\  2961--2969, 2017.

\bibitem[Hu et~al.(2018)Hu, Shen, and Sun]{hu2018squeeze}
Jie Hu, Li~Shen, and Gang Sun.
\newblock Squeeze-and-excitation networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  7132--7141, 2018.

\bibitem[Kolesnikov et~al.(2021)Kolesnikov, Dosovitskiy, Weissenborn, Heigold,
  Uszkoreit, Beyer, Minderer, Dehghani, Houlsby, Gelly, Unterthiner, and
  Zhai]{ViT}
Alexander Kolesnikov, Alexey Dosovitskiy, Dirk Weissenborn, Georg Heigold,
  Jakob Uszkoreit, Lucas Beyer, Matthias Minderer, Mostafa Dehghani, Neil
  Houlsby, Sylvain Gelly, Thomas Unterthiner, and Xiaohua Zhai.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Li et~al.(2022)Li, Xia, Li, Li, Wang, Xiao, Wang, Zheng, and
  Pan]{li2022next-vit}
Jiashi Li, Xin Xia, Wei Li, Huixia Li, Xing Wang, Xuefeng Xiao, Rui Wang, Min
  Zheng, and Xin Pan.
\newblock Next-vit: Next generation vision transformer for efficient deployment
  in realistic industrial scenarios.
\newblock \emph{arXiv preprint arXiv:2207.05501}, 2022.

\bibitem[Lin et~al.(2017)Lin, Goyal, Girshick, He, and
  Doll{\'a}r]{lin2017retinanet}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pp.\  2980--2988, 2017.

\bibitem[Ma et~al.(2018)Ma, Zhang, Zheng, and Sun]{ma2018shufflenet}
Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun.
\newblock Shufflenet v2: Practical guidelines for efficient cnn architecture
  design.
\newblock In \emph{Proceedings of the European Cnference on Computer Vision
  (ECCV)}, pp.\  116--131, 2018.

\bibitem[Maaz et~al.(2022)Maaz, Shaker, Cholakkal, Khan, Zamir, Anwer, and
  Khan]{Maaz2022EdgeNeXt}
Muhammad Maaz, Abdelrahman Shaker, Hisham Cholakkal, Salman Khan, Syed~Waqas
  Zamir, Rao~Muhammad Anwer, and Fahad~Shahbaz Khan.
\newblock Edgenext: Efficiently amalgamated cnn-transformer architecture for
  mobile vision applications.
\newblock In \emph{International Workshop on Computational Aspects of Deep
  Learning at 17th European Conference on Computer Vision (CADL2022)}.
  Springer, 2022.

\bibitem[Qin et~al.(2021)Qin, Zhang, Wu, and Li]{fcanet}
Zequn Qin, Pengyi Zhang, Fei Wu, and Xi~Li.
\newblock Fcanet: Frequency channel attention networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pp.\  783--792, 2021.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{ren2015fasterrcnn}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  volume~28, 2015.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{sandler2018mobilenetv2}
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh
  Chen.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  4510--4520, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{selfattention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  volume~30, 2017.

\bibitem[Wang et~al.(2020)Wang, Wu, Zhu, Li, Zuo, and
  Hu]{shen2021efficientecanet}
Qilong Wang, Banggu Wu, Pengfei Zhu, Peihua Li, Wangmeng Zuo, and Qinghua Hu.
\newblock Eca-net: Efficient channel attention for deep convolutional neural
  networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, 2020.

\bibitem[Wang et~al.(2018)Wang, Girshick, Gupta, and He]{wang2018nonlocal}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  7794--7803, 2018.

\bibitem[Woo et~al.(2018)Woo, Park, Lee, and Kweon]{woo2018cbam}
Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In~So Kweon.
\newblock Cbam: Convolutional block attention module.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  3--19, 2018.

\bibitem[Xie et~al.(2017)Xie, Girshick, Doll{\'a}r, Tu, and He]{xie2017resnext}
Saining Xie, Ross Girshick, Piotr Doll{\'a}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  1492--1500, 2017.

\end{thebibliography}
