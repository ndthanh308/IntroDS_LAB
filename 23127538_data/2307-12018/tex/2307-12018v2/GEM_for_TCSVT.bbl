% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{lin2022exploiting}
J.~Lin, Y.-H. Yeung, and R.~Lau, ``Exploiting semantic relations for glass surface detection,'' \emph{Advances in Neural Information Processing Systems}, vol.~35, pp. 22\,490--22\,504, 2022.

\bibitem{meng2020coupled}
M.~Meng, M.~Lan, J.~Yu, and J.~Wu, ``Coupled knowledge transfer for visual data recognition,'' \emph{IEEE Transactions on Circuits and Systems for Video Technology}, vol.~31, no.~5, pp. 1776--1789, 2020.

\bibitem{mei2020don}
H.~Mei, X.~Yang, Y.~Wang, Y.~Liu, S.~He, Q.~Zhang, X.~Wei, and R.~W. Lau, ``Don't hit me! glass detection in real-world scenes,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020, pp. 3687--3696.

\bibitem{lin2021rich}
J.~Lin, Z.~He, and R.~W. Lau, ``Rich context aggregation with reflection prior for glass surface detection,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021, pp. 13\,415--13\,424.

\bibitem{he2021enhanced}
H.~He, X.~Li, G.~Cheng, J.~Shi, Y.~Tong, G.~Meng, V.~Prinet, and L.~Weng, ``Enhanced boundary learning for glass-like object segmentation,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 15\,859--15\,868.

\bibitem{wang2013glass}
T.~Wang, X.~He, and N.~Barnes, ``Glass object segmentation by label transfer on joint depth and appearance manifolds,'' in \emph{2013 IEEE International Conference on Image Processing}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2013, pp. 2944--2948.

\bibitem{xu2015transcut}
Y.~Xu, H.~Nagahara, A.~Shimada, and R.-i. Taniguchi, ``Transcut: Transparent object segmentation from a light-field image,'' in \emph{Proceedings of the IEEE International Conference on Computer Vision}, 2015, pp. 3442--3450.

\bibitem{kalra2020deep}
A.~Kalra, V.~Taamazyan, S.~K. Rao, K.~Venkataraman, R.~Raskar, and A.~Kadambi, ``Deep polarization cues for transparent object segmentation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020, pp. 8602--8611.

\bibitem{mei2022glass}
H.~Mei, B.~Dong, W.~Dong, J.~Yang, S.-H. Baek, F.~Heide, P.~Peers, X.~Wei, and X.~Yang, ``Glass segmentation using intensity and spectral polarization cues,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 12\,622--12\,631.

\bibitem{huo2023glass}
D.~Huo, J.~Wang, Y.~Qian, and Y.-H. Yang, ``Glass segmentation with rgb-thermal image pairs,'' \emph{IEEE Transactions on Image Processing}, vol.~32, pp. 1911--1926, 2023.

\bibitem{kirillov2023segment}
A.~Kirillov, E.~Mintun, N.~Ravi, H.~Mao, C.~Rolland, L.~Gustafson, T.~Xiao, S.~Whitehead, A.~C. Berg, W.-Y. Lo \emph{et~al.}, ``Segment anything,'' \emph{arXiv preprint arXiv:2304.02643}, 2023.

\bibitem{yang2024depth}
L.~Yang, B.~Kang, Z.~Huang, X.~Xu, J.~Feng, and H.~Zhao, ``Depth anything: Unleashing the power of large-scale unlabeled data,'' \emph{arXiv preprint arXiv:2401.10891}, 2024.

\bibitem{yang2023gpt4v}
Z.~Yang, L.~Li, K.~Lin, J.~Wang, C.-C. Lin, Z.~Liu, and L.~Wang, ``The dawn of lmms: Preliminary explorations with gpt-4v (ision),'' \emph{arXiv preprint arXiv:2309.17421}, vol.~9, no.~1, p.~1, 2023.

\bibitem{rombach2022high}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer, ``High-resolution image synthesis with latent diffusion models,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2022, pp. 10\,684--10\,695.

\bibitem{ding2024vfmm3d}
B.~Ding, J.~Xie, J.~Nie, and J.~Cao, ``Vfmm3d: Releasing the potential of image by vision foundation model for monocular 3d object detection,'' \emph{arXiv preprint arXiv:2404.09431}, 2024.

\bibitem{tang2024foundationgrasp}
C.~Tang, D.~Huang, W.~Dong, R.~Xu, and H.~Zhang, ``Foundationgrasp: Generalizable task-oriented grasping with foundation models,'' \emph{arXiv preprint arXiv:2404.10399}, 2024.

\bibitem{achiam2023gpt4}
J.~Achiam, S.~Adler, S.~Agarwal, L.~Ahmad, I.~Akkaya, F.~L. Aleman, D.~Almeida, J.~Altenschmidt, S.~Altman, S.~Anadkat \emph{et~al.}, ``Gpt-4 technical report,'' \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{radford2021clip}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry, A.~Askell, P.~Mishkin, J.~Clark \emph{et~al.}, ``Learning transferable visual models from natural language supervision,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp. 8748--8763.

\bibitem{zhang2023controlnet}
L.~Zhang, A.~Rao, and M.~Agrawala, ``Adding conditional control to text-to-image diffusion models,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 3836--3847.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly \emph{et~al.}, ``An image is worth 16x16 words: Transformers for image recognition at scale,'' \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{li2022vitdet}
Y.~Li, H.~Mao, R.~Girshick, and K.~He, ``Exploring plain vision transformer backbones for object detection,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 280--296.

\bibitem{zhang2023faster}
C.~Zhang, D.~Han, Y.~Qiao, J.~U. Kim, S.-H. Bae, S.~Lee, and C.~S. Hong, ``Faster segment anything: Towards lightweight sam for mobile applications,'' \emph{arXiv preprint arXiv:2306.14289}, 2023.

\bibitem{mei2021depth}
H.~Mei, B.~Dong, W.~Dong, P.~Peers, X.~Yang, Q.~Zhang, and X.~Wei, ``Depth-aware mirror segmentation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021, pp. 3044--3053.

\bibitem{han2023internal}
D.~Han and S.~Lee, ``Internal-external boundary attention fusion for glass surface segmentation,'' \emph{arXiv preprint arXiv:2307.00212}, 2023.

\bibitem{fan2023rfenet}
K.~Fan, C.~Wang, Y.~Wang, C.~Wang, R.~Yi, and L.~Ma, ``Rfenet: towards reciprocal feature evolution for glass segmentation,'' \emph{arXiv preprint arXiv:2307.06099}, 2023.

\bibitem{li2023scaling}
Y.~Li, H.~Fan, R.~Hu, C.~Feichtenhofer, and K.~He, ``Scaling language-image pre-training via masking,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 23\,390--23\,400.

\bibitem{fang2023eva}
Y.~Fang, W.~Wang, B.~Xie, Q.~Sun, L.~Wu, X.~Wang, T.~Huang, X.~Wang, and Y.~Cao, ``Eva: Exploring the limits of masked visual representation learning at scale,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 19\,358--19\,369.

\bibitem{achiam2023gpt}
J.~Achiam, S.~Adler, S.~Agarwal, L.~Ahmad, I.~Akkaya, F.~L. Aleman, D.~Almeida, J.~Altenschmidt, S.~Altman, S.~Anadkat \emph{et~al.}, ``Gpt-4 technical report,'' \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{zhu2023minigpt}
D.~Zhu, J.~Chen, X.~Shen, X.~Li, and M.~Elhoseiny, ``Minigpt-4: Enhancing vision-language understanding with advanced large language models,'' \emph{arXiv preprint arXiv:2304.10592}, 2023.

\bibitem{wang2023seggpt}
X.~Wang, X.~Zhang, Y.~Cao, W.~Wang, C.~Shen, and T.~Huang, ``Seggpt: Segmenting everything in context,'' \emph{arXiv preprint arXiv:2304.03284}, 2023.

\bibitem{zou2024segment}
X.~Zou, J.~Yang, H.~Zhang, F.~Li, L.~Li, J.~Wang, L.~Wang, J.~Gao, and Y.~J. Lee, ``Segment everything everywhere all at once,'' \emph{Advances in Neural Information Processing Systems}, vol.~36, 2024.

\bibitem{ramesh2021zero}
A.~Ramesh, M.~Pavlov, G.~Goh, S.~Gray, C.~Voss, A.~Radford, M.~Chen, and I.~Sutskever, ``Zero-shot text-to-image generation,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp. 8821--8831.

\bibitem{ramesh2022hierarchical}
A.~Ramesh, P.~Dhariwal, A.~Nichol, C.~Chu, and M.~Chen, ``Hierarchical text-conditional image generation with clip latents,'' \emph{arXiv preprint arXiv:2204.06125}, vol.~1, no.~2, p.~3, 2022.

\bibitem{zhang2023adding}
L.~Zhang, A.~Rao, and M.~Agrawala, ``Adding conditional control to text-to-image diffusion models,'' 2023.

\bibitem{he2023accuracy}
S.~He, R.~Bao, J.~Li, P.~E. Grant, and Y.~Ou, ``Accuracy of segment-anything model (sam) in medical image segmentation tasks,'' \emph{arXiv preprint arXiv:2304.09324}, 2023.

\bibitem{osco2023segment}
L.~P. Osco, Q.~Wu, E.~L. de~Lemos, W.~N. Gon{\c{c}}alves, A.~P.~M. Ramos, J.~Li, and J.~M. Junior, ``The segment anything model (sam) for remote sensing applications: From zero to one shot,'' \emph{International Journal of Applied Earth Observation and Geoinformation}, vol. 124, p. 103540, 2023.

\bibitem{ahmadi2023application}
M.~Ahmadi, A.~G. Lonbar, A.~Sharifi, A.~T. Beris, M.~Nouri, and A.~S. Javidi, ``Application of segment anything model for civil infrastructure defect assessment,'' \emph{arXiv preprint arXiv:2304.12600}, 2023.

\bibitem{han2023segment}
D.~Han, C.~Zhang, Y.~Qiao, M.~Qamar, Y.~Jung, S.~Lee, S.-H. Bae, and C.~S. Hong, ``Segment anything model (sam) meets glass: Mirror and transparent objects cannot be easily detected,'' \emph{arXiv preprint arXiv:2305.00278}, 2023.

\bibitem{he2022synthetic}
R.~He, S.~Sun, X.~Yu, C.~Xue, W.~Zhang, P.~Torr, S.~Bai, and X.~Qi, ``Is synthetic data from generative models ready for image recognition?'' \emph{arXiv preprint arXiv:2210.07574}, 2022.

\bibitem{sariyildiz2023fake}
M.~B. Sariyildiz, K.~Alahari, D.~Larlus, and Y.~Kalantidis, ``Fake it till you make it: Learning transferable representations from synthetic imagenet clones,'' in \emph{CVPR 2023--IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023.

\bibitem{marathe2023wedge}
A.~Marathe, D.~Ramanan, R.~Walambe, and K.~Kotecha, ``Wedge: A multi-weather autonomous driving dataset built from generative vision-language models,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 3317--3326.

\bibitem{feng2022ic9600}
T.~Feng, Y.~Zhai, J.~Yang, J.~Liang, D.-P. Fan, J.~Zhang, L.~Shao, and D.~Tao, ``Ic9600: a benchmark dataset for automatic image complexity assessment,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2022.

\bibitem{li2023mask}
F.~Li, H.~Zhang, H.~Xu, S.~Liu, L.~Zhang, L.~M. Ni, and H.-Y. Shum, ``Mask dino: Towards a unified transformer-based framework for object detection and segmentation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 3041--3050.

\bibitem{zhang2022dino}
H.~Zhang, F.~Li, S.~Liu, L.~Zhang, H.~Su, J.~Zhu, L.~M. Ni, and H.-Y. Shum, ``Dino: Detr with improved denoising anchor boxes for end-to-end object detection,'' \emph{arXiv preprint arXiv:2203.03605}, 2022.

\bibitem{zheng2021rethinking}
S.~Zheng, J.~Lu, H.~Zhao, X.~Zhu, Z.~Luo, Y.~Wang, Y.~Fu, J.~Feng, T.~Xiang, P.~H. Torr \emph{et~al.}, ``Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2021, pp. 6881--6890.

\bibitem{strudel2021segmenter}
R.~Strudel, R.~Garcia, I.~Laptev, and C.~Schmid, ``Segmenter: Transformer for semantic segmentation,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2021, pp. 7262--7272.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin transformer: Hierarchical vision transformer using shifted windows,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2021, pp. 10\,012--10\,022.

\bibitem{xie2021segformer}
E.~Xie, W.~Wang, Z.~Yu, A.~Anandkumar, J.~M. Alvarez, and P.~Luo, ``Segformer: Simple and efficient design for semantic segmentation with transformers,'' \emph{Advances in Neural Information Processing Systems}, vol.~34, pp. 12\,077--12\,090, 2021.

\bibitem{cheng2021mask2former}
B.~Cheng, I.~Misra, A.~G. Schwing, A.~Kirillov, and R.~Girdhar, ``Masked-attention mask transformer for universal image segmentation,'' 2022.

\bibitem{he2023dynamic}
H.~He, J.~Cai, Z.~Pan, J.~Liu, J.~Zhang, D.~Tao, and B.~Zhuang, ``Dynamic focus-aware positional queries for semantic segmentation,'' in \emph{CVPR}, 2023.

\bibitem{siris2021scene}
A.~Siris, J.~Jiao, G.~K. Tam, X.~Xie, and R.~W. Lau, ``Scene context-aware salient object detection,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2021, pp. 4156--4166.

\bibitem{yuan2021tokens}
L.~Yuan, Y.~Chen, T.~Wang, W.~Yu, Y.~Shi, Z.-H. Jiang, F.~E. Tay, J.~Feng, and S.~Yan, ``Tokens-to-token vit: Training vision transformers from scratch on imagenet,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2021, pp. 558--567.

\bibitem{chu2021twins}
X.~Chu, Z.~Tian, Y.~Wang, B.~Zhang, H.~Ren, X.~Wei, H.~Xia, and C.~Shen, ``Twins: Revisiting the design of spatial attention in vision transformers,'' \emph{Advances in Neural Information Processing Systems}, vol.~34, pp. 9355--9366, 2021.

\bibitem{cheng2021maskformer}
B.~Cheng, A.~G. Schwing, and A.~Kirillov, ``Per-pixel classification is not all you need for semantic segmentation,'' 2021.

\bibitem{zhang2023mp}
H.~Zhang, F.~Li, H.~Xu, S.~Huang, S.~Liu, L.~M. Ni, and L.~Zhang, ``Mp-former: Mask-piloted transformer for image segmentation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 18\,074--18\,083.

\bibitem{hassani2023neighborhood}
A.~Hassani, S.~Walton, J.~Li, S.~Li, and H.~Shi, ``Neighborhood attention transformer,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2023, pp. 6185--6194.

\bibitem{hao2023language}
J.~Hao, S.~Chen, X.~Wang, and S.~Han, ``Language-aware multiple datasets detection pretraining for detrs,'' \emph{arXiv preprint arXiv:2304.03580}, 2023.

\end{thebibliography}
