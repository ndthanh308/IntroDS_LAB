{
  "2308-01170": {
    "title": "Revisiting a Design Choice in Gradient Temporal Difference Learning",
    "authors": [
      "Xiaochi Qian",
      "Shangtong Zhang"
    ],
    "submission_date": "2023-08-02",
    "semantic_scholar_id": "c8be4bcdaaeeff9e6d5691c868f938bece5e721e"
  },
  "2301-13757": {
    "title": "Toward Efficient Gradient-Based Value Estimation",
    "authors": [
      "Arsalan Sharifnassab",
      "R. Sutton"
    ],
    "submission_date": "2023-01-31",
    "semantic_scholar_id": "60ab51122b9ccf2beb670120021c8bb9a5c89062"
  },
  "2109-05110": {
    "title": "An Empirical Comparison of Off-policy Prediction Learning Algorithms in the Four Rooms Environment",
    "authors": [
      "Sina Ghiassian",
      "R. Sutton"
    ],
    "submission_date": "2021-09-10",
    "semantic_scholar_id": "eac2883e668063470159539d885fb1488a36a44c"
  },
  "2104-12820": {
    "title": "Universal Off-Policy Evaluation",
    "authors": [
      "Yash Chandak",
      "S. Niekum",
      "Bruno C. da Silva",
      "E. Learned-Miller",
      "E. Brunskill",
      "P. Thomas"
    ],
    "submission_date": "2021-04-26",
    "semantic_scholar_id": "64d80a697ee9c914fc034f1e110b5f7ae91261c6"
  },
  "2101-08862": {
    "title": "Breaking the Deadly Triad with a Target Network",
    "authors": [
      "Shangtong Zhang",
      "Hengshuai Yao",
      "S. Whiteson"
    ],
    "submission_date": "2021-01-21",
    "semantic_scholar_id": "425fd80f1d661c2cf7f04d9c22df2123b2322ff7"
  },
  "2101-02808": {
    "title": "Average-Reward Off-Policy Policy Evaluation with Function Approximation",
    "authors": [
      "Shangtong Zhang",
      "Yi Wan",
      "R. Sutton",
      "S. Whiteson"
    ],
    "submission_date": "2021-01-08",
    "semantic_scholar_id": "2c276e07a4125e34be023c4b72d38db1e540a01f"
  },
  "2011-05053": {
    "title": "Sample Complexity Bounds for Two Timescale Value-based Reinforcement Learning Algorithms",
    "authors": [
      "Tengyu Xu",
      "Yingbin Liang"
    ],
    "submission_date": "2020-11-10",
    "semantic_scholar_id": "f722172a5beca9952d13879d64c94e4cc280bddd"
  },
  "2009-06548": {
    "title": "Variance-Reduced Off-Policy Memory-Efficient Policy Search",
    "authors": [
      "Daoming Lyu",
      "Qi Qi",
      "M. Ghavamzadeh",
      "Hengshuai Yao",
      "Tianbao Yang",
      "Bo Liu"
    ],
    "submission_date": "2020-09-14",
    "semantic_scholar_id": "2c855755a666efe8abfdc8fa38e740499049da58"
  },
  "2007-00611": {
    "title": "Gradient Temporal-Difference Learning with Regularized Corrections",
    "authors": [
      "Sina Ghiassian",
      "Andrew Patterson",
      "Shivam Garg",
      "Dhawal Gupta",
      "Adam White",
      "Martha White"
    ],
    "submission_date": "2020-07-01",
    "semantic_scholar_id": "53f64cdc1da981fd45950eebec8b9e1d1ec4cb30"
  },
  "2002-10542": {
    "title": "Stochastic Polyak Step-size for SGD: An Adaptive Learning Rate for Fast Convergence",
    "authors": [
      "Nicolas Loizou",
      "Sharan Vaswani",
      "I. Laradji",
      "Simon Lacoste-Julien"
    ],
    "submission_date": "2020-02-24",
    "semantic_scholar_id": "bc2fc5f394e709c78226ebac91f6e956781d9ef9"
  },
  "2001-11113": {
    "title": "GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values",
    "authors": [
      "Shangtong Zhang",
      "Bo Liu",
      "S. Whiteson"
    ],
    "submission_date": "2020-01-29",
    "semantic_scholar_id": "568c6c8ca820a161c1097fe3bcc947f436075f57"
  },
  "1912-10583": {
    "title": "Finite-Time Analysis and Restarting Scheme for Linear Two-Time-Scale Stochastic Approximation",
    "authors": [
      "Thinh T. Doan"
    ],
    "submission_date": "2019-12-23",
    "semantic_scholar_id": "84b2db54e36500dd0f23c67ee6bd87b8d37fac4a"
  },
  "1912-04511": {
    "title": "A Finite-Time Analysis of Q-Learning with Neural Network Function Approximation",
    "authors": [
      "Pan Xu",
      "Quanquan Gu"
    ],
    "submission_date": "2019-12-10",
    "semantic_scholar_id": "33b3324a5c81edb56990e9323bb1ca5040adb7ea"
  },
  "1911-09157": {
    "title": "A Tale of Two-Timescale Reinforcement Learning with the Tightest Finite-Time Bound",
    "authors": [
      "Gal Dalal",
      "Balázs Szörényi",
      "Gugan Thoppe"
    ],
    "submission_date": "2019-11-20",
    "semantic_scholar_id": "39a60a3dc1365172aeaf7ff51de5c2d5dd9acc2a"
  },
  "1910-10879": {
    "title": "Convergence rates of subgradient methods for quasi-convex optimization problems",
    "authors": [
      "Yaohua Hu",
      "Jiawen Li",
      "C. Yu"
    ],
    "submission_date": "2019-10-24",
    "semantic_scholar_id": "f4cc623e77dd7027a1244451b50ab083dc2ff848"
  },
  "1910-07479": {
    "title": "Conditional Importance Sampling for Off-Policy Learning",
    "authors": [
      "Mark Rowland",
      "A. Harutyunyan",
      "H. V. Hasselt",
      "Diana Borsa",
      "T. Schaul",
      "R. Munos",
      "Will Dabney"
    ],
    "submission_date": "2019-10-16",
    "semantic_scholar_id": "dd4f02c7b77578bdbda5dfdf2ea92cde88283c7d"
  },
  "1909-11907": {
    "title": "Two Time-scale Off-Policy TD Learning: Non-asymptotic Analysis over Markovian Samples",
    "authors": [
      "Tengyu Xu",
      "Shaofeng Zou",
      "Yingbin Liang"
    ],
    "submission_date": "2019-09-01",
    "semantic_scholar_id": "f70e94ee06a10d9708185e87eb93adb9f4e0fac4"
  },
  "1907-06290": {
    "title": "Finite-Time Performance Bounds and Adaptive Learning Rate Selection for Two Time-Scale Reinforcement Learning",
    "authors": [
      "Harsh Gupta",
      "R. Srikant",
      "Lei Ying"
    ],
    "submission_date": "2019-07-14",
    "semantic_scholar_id": "8cba38e7e2a4b6400c0dbb7a0c2c98918e354d57"
  },
  "1906-03704": {
    "title": "SVRG for Policy Evaluation with Fewer Gradient Evaluations",
    "authors": [
      "Zilun Peng",
      "Ahmed Touati",
      "Pascal Vincent",
      "Doina Precup"
    ],
    "submission_date": "2019-06-09",
    "semantic_scholar_id": "3887a0a8c6be03fd904757068035d0900168c239"
  },
  "1906-03393": {
    "title": "Towards Optimal Off-Policy Evaluation for Reinforcement Learning with Marginalized Importance Sampling",
    "authors": [
      "Tengyang Xie",
      "Yifei Ma",
      "Yu-Xiang Wang"
    ],
    "submission_date": "2019-06-08",
    "semantic_scholar_id": "ecbe3ce8ba487cb98fb71650b2e399a26c726204"
  },
  "1905-10506": {
    "title": "A Kernel Loss for Solving the Bellman Equation",
    "authors": [
      "Yihao Feng",
      "Lihong Li",
      "Qiang Liu"
    ],
    "submission_date": "2019-05-25",
    "semantic_scholar_id": "197cd4b7cd242243b5e8fc48ee08828882c930a1"
  },
  "1905-01072": {
    "title": "Deep Residual Reinforcement Learning",
    "authors": [
      "Shangtong Zhang",
      "Wendelin Böhmer",
      "S. Whiteson"
    ],
    "submission_date": "2019-05-03",
    "semantic_scholar_id": "a76db54e4b5130ee45c224a7518e8a159f0bd843"
  },
  "1901-09455": {
    "title": "Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate Shift",
    "authors": [
      "Carles Gelada",
      "Marc G. Bellemare"
    ],
    "submission_date": "2019-01-27",
    "semantic_scholar_id": "dc4ec37102afb166b96abc268ae3dc15e230d776"
  },
  "1812-01094": {
    "title": "A Single Timescale Stochastic Approximation Method for Nested Stochastic Optimization",
    "authors": [
      "Saeed Ghadimi",
      "A. Ruszczynski",
      "Mengdi Wang"
    ],
    "submission_date": "2018-12-03",
    "semantic_scholar_id": "429985a4abc17744c5999a611198d5302aa697f7"
  },
  "1810-12429": {
    "title": "Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation",
    "authors": [
      "Qiang Liu",
      "Lihong Li",
      "Ziyang Tang",
      "Dengyong Zhou"
    ],
    "submission_date": "2018-10-29",
    "semantic_scholar_id": "e81ea45d8bec329fdb11fd84990852f620895d6f"
  },
  "1802-01561": {
    "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures",
    "authors": [
      "L. Espeholt",
      "Hubert Soyer",
      "R. Munos",
      "K. Simonyan",
      "Volodymyr Mnih",
      "Tom Ward",
      "Yotam Doron",
      "Vlad Firoiu",
      "Tim Harley",
      "Iain Dunning",
      "S. Legg",
      "K. Kavukcuoglu"
    ],
    "submission_date": "2018-02-05",
    "semantic_scholar_id": "80196cdfcd0c6ce2953bf65a7f019971e2026386"
  },
  "1712-09652": {
    "title": "On Convergence of some Gradient-based Temporal-Differences Algorithms for Off-Policy Learning",
    "authors": [
      "Huizhen Yu"
    ],
    "submission_date": "2017-12-27",
    "semantic_scholar_id": "92875931e48d6a1193ddf5e87fec7137004b6b81"
  },
  "1705-04185": {
    "title": "A First Empirical Study of Emphatic Temporal Difference Learning",
    "authors": [
      "Sina Ghiassian",
      "Banafsheh Rafiee",
      "R. Sutton"
    ],
    "submission_date": "2017-05-11",
    "semantic_scholar_id": "8d86bf0554e4086d9fe29a698db3b3287d54b458"
  },
  "1702-07944": {
    "title": "Stochastic Variance Reduction Methods for Policy Evaluation",
    "authors": [
      "S. Du",
      "Jianshu Chen",
      "Lihong Li",
      "Lin Xiao",
      "Dengyong Zhou"
    ],
    "submission_date": "2017-02-25",
    "semantic_scholar_id": "4ce25912f8f0b7bcac53cbc4d8e0ca867f2109bb"
  },
  "1702-07121": {
    "title": "Consistent On-Line Off-Policy Evaluation",
    "authors": [
      "Assaf Hallak",
      "Shie Mannor"
    ],
    "submission_date": "2017-02-23",
    "semantic_scholar_id": "ba847beb3ed679ff56d0414c04748de88ed46af9"
  },
  "1611-09328": {
    "title": "Accelerated Gradient Temporal Difference Learning",
    "authors": [
      "Yangchen Pan",
      "A. White",
      "Martha White"
    ],
    "submission_date": "2016-11-01",
    "semantic_scholar_id": "23fc2c1e8608b25fd2291db9c78d5d10c652273a"
  },
  "1607-07329": {
    "title": "Accelerating Stochastic Composition Optimization",
    "authors": [
      "Mengdi Wang",
      "Ji Liu",
      "Ethan X. Fang"
    ],
    "submission_date": "2016-07-25",
    "semantic_scholar_id": "d53d179dfba4804799278fcefa414c2017f391dc"
  },
  "1602-08771": {
    "title": "Investigating Practical Linear Temporal Difference Learning",
    "authors": [
      "A. White",
      "Martha White"
    ],
    "submission_date": "2016-02-28",
    "semantic_scholar_id": "f8f0e37e0fb56655cb6e348f7dec58a103b97374"
  },
  "1511-05952": {
    "title": "Prioritized Experience Replay",
    "authors": [
      "T. Schaul",
      "John Quan",
      "Ioannis Antonoglou",
      "David Silver"
    ],
    "submission_date": "2015-11-18",
    "semantic_scholar_id": "c6170fa90d3b2efede5a2e1660cb23e1c824f2ca"
  },
  "1509-05172": {
    "title": "Generalized Emphatic Temporal Difference Learning: Bias-Variance Analysis",
    "authors": [
      "Assaf Hallak",
      "Aviv Tamar",
      "R. Munos",
      "Shie Mannor"
    ],
    "submission_date": "2015-09-17",
    "semantic_scholar_id": "83ff34eac4fc50cb92a34b5f2b10925aa22b3c12"
  },
  "2006-14364": {
    "title": "Finite-Sample Analysis of Proximal Gradient TD Algorithms",
    "authors": [
      "Bo Liu",
      "Ji Liu",
      "M. Ghavamzadeh",
      "S. Mahadevan",
      "Marek Petrik"
    ],
    "submission_date": "2015-07-12",
    "semantic_scholar_id": "fc71c22a316ee4d8cbf27fabf5b4c0c9041c43cc"
  },
  "1507-01569": {
    "title": "Emphatic Temporal-Difference Learning",
    "authors": [
      "A. Mahmood",
      "Huizhen Yu",
      "Martha White",
      "R. Sutton"
    ],
    "submission_date": "2015-07-06",
    "semantic_scholar_id": "ef093a089c02ed8fad4b9b476bf038e18634ea4a"
  },
  "1506-02582": {
    "title": "On Convergence of Emphatic Temporal-Difference Learning",
    "authors": [
      "Huizhen Yu"
    ],
    "submission_date": "2015-06-08",
    "semantic_scholar_id": "1baba004465b6721717de67af1b0bf375d24863a"
  },
  "1503-04269": {
    "title": "An Emphatic Approach to the Problem of Off-policy Temporal-Difference Learning",
    "authors": [
      "R. Sutton",
      "A. Mahmood",
      "Martha White"
    ],
    "submission_date": "2015-03-13",
    "semantic_scholar_id": "d6cc19f33b7714de62e45295c8be1bf1b0642557"
  },
  "1406-5143": {
    "title": "The sample complexity of learning linear predictors with the squared loss",
    "authors": [
      "Ohad Shamir"
    ],
    "submission_date": "2014-06-19",
    "semantic_scholar_id": "0bcfb6f6e29b3ae91de8cb06d563e3ac6e34d738"
  },
  "2006-05314": {
    "title": "Regularized Off-Policy TD-Learning",
    "authors": [
      "Bo Liu",
      "S. Mahadevan",
      "Ji Liu"
    ],
    "submission_date": "2012-12-03",
    "semantic_scholar_id": "56b20ad1b7a48bf3b0678c4356fb27c03acd6860"
  },
  "1106-0707": {
    "title": "Efficient Reinforcement Learning Using Recursive Least-Squares Methods",
    "authors": [
      "He He",
      "D. Hu",
      "X. Xu"
    ],
    "submission_date": "2011-06-03",
    "semantic_scholar_id": "5cadafb8e964737c658e5d81f4f68c99c666eb2f"
  },
  "1011-4362": {
    "title": "Should one compute the Temporal Difference fix point or minimize the Bellman Residual? The unified oblique projection view",
    "authors": [
      "B. Scherrer"
    ],
    "submission_date": "2010-06-21",
    "semantic_scholar_id": "1a9bb0a637cbaca8489afd69d6840975a9834a05"
  },
  "0809-0815": {
    "title": "Solving variational inequalities with Stochastic Mirror-Prox algorithm",
    "authors": [
      "A. Juditsky",
      "A. Nemirovskii",
      "Claire Tauvel"
    ],
    "submission_date": "2008-09-04",
    "semantic_scholar_id": "e50c7cba0a612e8045458dd2aa130d9b2a1ff560"
  }
}