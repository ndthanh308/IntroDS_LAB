{
  "title": "Effective Whole-body Pose Estimation with Two-stages Distillation",
  "authors": [
    "Zhendong Yang",
    "Ailing Zeng",
    "Chun Yuan",
    "Yu Li"
  ],
  "submission_date": "2023-07-29T03:49:28+00:00",
  "revised_dates": [
    "2023-08-25T02:46:35+00:00"
  ],
  "abstract": "Whole-body pose estimation localizes the human body, hand, face, and foot keypoints in an image. This task is challenging due to multi-scale body parts, fine-grained localization for low-resolution regions, and data scarcity. Meanwhile, applying a highly efficient and accurate pose estimator to widely human-centric understanding and generation tasks is urgent. In this work, we present a two-stage pose \\textbf{D}istillation for \\textbf{W}hole-body \\textbf{P}ose estimators, named \\textbf{DWPose}, to improve their effectiveness and efficiency. The first-stage distillation designs a weight-decay strategy while utilizing a teacher's intermediate feature and final logits with both visible and invisible keypoints to supervise the student from scratch. The second stage distills the student model itself to further improve performance. Different from the previous self-knowledge distillation, this stage finetunes the student's head with only 20% training time as a plug-and-play training strategy. For data limitations, we explore the UBody dataset that contains diverse facial expressions and hand gestures for real-life applications. Comprehensive experiments show the superiority of our proposed simple yet effective methods. We achieve new state-of-the-art performance on COCO-WholeBody, significantly boosting the whole-body AP of RTMPose-l from 64.8% to 66.5%, even surpassing RTMPose-x teacher with 65.3% AP. We release a series of models with different sizes, from tiny to large, for satisfying various downstream tasks. Our codes and models are available at https://github.com/IDEA-Research/DWPose.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15880",
  "pdf_url": "https://arxiv.org/pdf/2307.15880v2",
  "comment": "Accepted by ICCV 2023, CV4Metaverse Workshop",
  "num_versions": null,
  "size_before_bytes": 21082431,
  "size_after_bytes": 274576
}