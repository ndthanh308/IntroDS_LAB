{
  "title": "BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering",
  "authors": [
    "Khiem Vinh Tran",
    "Kiet Van Nguyen",
    "Ngan Luu Thuy Nguyen"
  ],
  "submission_date": "2023-07-28T06:23:32+00:00",
  "revised_dates": [],
  "abstract": "Visual Question Answering (VQA) is an intricate and demanding task that integrates natural language processing (NLP) and computer vision (CV), capturing the interest of researchers. The English language, renowned for its wealth of resources, has witnessed notable advancements in both datasets and models designed for VQA. However, there is a lack of models that target specific countries such as Vietnam. To address this limitation, we introduce a transformer-based Vietnamese model named BARTPhoBEiT. This model includes pre-trained Sequence-to-Sequence and bidirectional encoder representation from Image Transformers in Vietnamese and evaluates Vietnamese VQA datasets. Experimental results demonstrate that our proposed model outperforms the strong baseline and improves the state-of-the-art in six metrics: Accuracy, Precision, Recall, F1-score, WUPS 0.0, and WUPS 0.9.",
  "categories": [
    "cs.CL",
    "cs.CV"
  ],
  "primary_category": "cs.CL",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15335",
  "pdf_url": "https://arxiv.org/pdf/2307.15335v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 1439596,
  "size_after_bytes": 341789
}