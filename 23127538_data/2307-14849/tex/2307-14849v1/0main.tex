\documentclass[runningheads]{llncs}

\input{macros}

\begin{document}

\title{Counterfactual Explanations for Graph Classification Through the Lenses of Density}

\titlerunning{Counterfactual Explanations for Graph Classification}

\author{Carlo Abrate\inst{1}\orcidID{0009-0003-8604-9699} \and
Giulia Preti\inst{1}\orcidID{0000-0002-2126-326X} \and
Francesco Bonchi\inst{1,2}\orcidID{0000-0001-9464-8315}}

\authorrunning{C. Abrate et al.}

\institute{
    CENTAI Institute, Turin, Italy \and
    EURECAT, Barcelona, Spain\\
    \email{\{carlo.abrate,giulia.preti,bonchi\}@centai.eu}
}

\maketitle \sloppy              % typeset the header of the contribution

\begin{abstract}
Counterfactual examples have emerged as an effective approach to produce simple and understandable post-hoc explanations. In the context of graph classification,
previous work has focused on generating counterfactual explanations by manipulating the most elementary units of a graph, i.e., removing an existing edge, or adding a non-existing one. In this paper, we claim that such language of explanation might be too fine-grained, and turn our attention to some of the main characterizing features of real-world complex networks, such as the tendency to close triangles, the existence of recurring motifs, and the organization into dense modules. We thus define a general
\emph{density-based counterfactual search} framework to generate instance-level counterfactual explanations for graph classifiers, which can be instantiated with different notions of dense substructures. In particular, we show two specific instantiations of this general framework: a method that searches for counterfactual graphs by opening or closing triangles, and a method driven by maximal cliques.
We also discuss how the general method can be instantiated to exploit any other notion of dense substructures, including, for instance, a given taxonomy of nodes.
We evaluate the effectiveness of our approaches in 7 brain network datasets and compare the counterfactual statements generated according to several widely-used metrics. Results confirm that adopting a semantic-relevant unit of change like density is essential to define versatile and interpretable counterfactual explanation methods.

%\keywords{Explainability  \and Counterfactual Explanations \and Graph Classification \and Brain Networks.}
\end{abstract}
%
%
\input{sections/1introduction}
\input{sections/2sota.tex}
\input{sections/3problem.tex}
\input{sections/4algo.tex}
\input{sections/5.1experiments}
%\input{sections/5.2syntetic}
\input{sections/5.3diversity}
\input{sections/5.4methods}
\input{sections/6conclusion.tex}

\clearpage
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
\bibliographystyle{splncs04}
\bibliography{bibfile,biblio}

\end{document}
