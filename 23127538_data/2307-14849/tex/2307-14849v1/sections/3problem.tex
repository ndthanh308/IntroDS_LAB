\section{Preliminaries}\label{sec:problem}
Given a set of nodes $V$ we denote $\mathcal{G}$ the set of all possible graphs defined over $V$. Given one such graphs $G = (V,E) \in \mathcal{G}$, a \emph{subgraph} of $G$ is a graph $H = (V_H, E_H)$ such that $V_H \subseteq V$ and $E_H \subseteq E$.
A subgraph $H$ is a \emph{k-clique} iff $|V_H| = k$ and $E_H = V_H \times V_H$.
The \emph{density}\footnote{Density is usually defined as the number of edges over the number of possible edges. W.l.o.g. we omit the denominator.} $\delta(H)$ of a subgraph $H$ is defined as its number of edges, i.e., $\delta(H) = |E_H|$.

We assume we are given a binary graph classification model $f: \mathcal{G} \rightarrow \{0,1\}$, that assigns a label in $\{0,1\}$ to each graph in $\mathcal{G}$.
We assume that $f$ \textbf{(i)} is a trained machine learning model whose internal structure is not known (black-box model), \textbf{(ii)} can be queried at will, and \textbf{(iii)} does not change from one query to the other one (i.e., it is static).

Given a specific graph $G \in \mathcal{G}$ a \emph{counterfactual graph} is another graph $G' \in \mathcal{G}$ such that  $f(G) = 1 - f(G')$. Depending on the domain at hand, several desired properties might guide the search for counterfactuals, such as, e.g., \emph{similarity} between the original and the counterfactual instance, \emph{sparsity} (the change affects only a few features), \emph{efficiency} (the search should be fast), and the \emph{feasibility} (to generate a feasible instance).
We will discuss some of these measures in Section \ref{sec:results}.
For the moment, we only need to define the \emph{distance} $\textsf{d}(G, G')$ between two graphs $G$ and $G'$ as the symmetric difference between their edge sets:
\begin{equation}\label{eq:xor}
\textsf{d}(G, G') = |E \setminus E'| + |E' \setminus E|\enspace.
\end{equation}


We next introduce a novel framework to generate counterfactual graphs based on the manipulation of dense substructures, which become the fundamental units of the vocabulary of the explanations produced.

 
%Specifically, the framework leverages cliques as the unit of change in the input graph, improving the edge-based method proposed in \cite{countg}.
%We show that dense structures encode more information on the graph, and as such, they are more appropriate for generating human-interpretable explanations for this kind of data.
%Moreover, our framework can provide a set of diverse explanations, which has been demonstrated in previous studies to be advantageous for users~\cite{mothilal2020explaining}.

% To generate better counterfactual, depending on the context there are additional desiderata for $G'$,

% An example of density-based counterfactual explanations generable by our framework for a brain network is the following:
% \begin{displayquote}
%     \emph{A patient $X$ is classified as \texttt{Autism Spectrum Disorder}; however if the Posterior Fossa area had more connections between its neuronal units, $X$ would have been classified as \texttt{Typically Developed}.}
% \end{displayquote} 