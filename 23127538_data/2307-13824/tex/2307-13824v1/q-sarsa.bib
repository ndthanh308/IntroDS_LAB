

@article{brandfonbrener2021offline,
  title={Offline rl without off-policy evaluation},
  author={Brandfonbrener, David and Whitney, Will and Ranganath, Rajesh and Bruna, Joan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={4933--4946},
  year={2021}
}

@article{gulcehre2021regularized,
  title={Regularized behavior value estimation},
  author={Gulcehre, Caglar and Colmenarejo, Sergio G{\'o}mez and Wang, Ziyu and Sygnowski, Jakub and Paine, Thomas and Zolna, Konrad and Chen, Yutian and Hoffman, Matthew and Pascanu, Razvan and de Freitas, Nando},
  journal={arXiv preprint arXiv:2103.09575},
  year={2021}
}

@article{kumar2020conservative,
  title={Conservative {Q}-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7768--7778},
  year={2020}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{rezaeifar2021offline,
  title={Offline Reinforcement Learning as Anti-Exploration},
  author={Rezaeifar, Shideh and Dadashi, Robert and Vieillard, Nino and Hussenot, L{\'e}onard and Bachem, Olivier and Pietquin, Olivier and Geist, Matthieu},
  journal={arXiv preprint arXiv:2106.06431},
  year={2021}
}

@article{kapturowski2022human,
  title={Human-level Atari 200x faster},
  author={Kapturowski, Steven and Campos, V{\'\i}ctor and Jiang, Ray and Raki{\'c}evi{\'c}, Nemanja and van Hasselt, Hado and Blundell, Charles and Badia, Adri{\`a} Puigdom{\`e}nech},
  journal={arXiv preprint arXiv:2209.07550},
  year={2022}
}

@article{pohlen2018observe,
  title={Observe and look further: Achieving consistent performance on atari},
  author={Pohlen, Tobias and Piot, Bilal and Hester, Todd and Azar, Mohammad Gheshlaghi and Horgan, Dan and Budden, David and Barth-Maron, Gabriel and Van Hasselt, Hado and Quan, John and Ve{\v{c}}er{\'\i}k, Mel and others},
  journal={arXiv preprint arXiv:1805.11593},
  year={2018}
}

@inproceedings{lee2021sunrise,
  title={Sunrise: A simple unified framework for ensemble learning in deep reinforcement learning},
  author={Lee, Kimin and Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={6131--6141},
  year={2021},
  organization={PMLR}
}

@article{an2021uncertainty,
  title={Uncertainty-based offline reinforcement learning with diversified {Q}-ensemble},
  author={An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={7436--7447},
  year={2021}
}

@article{janner2021offline,
  title={Offline reinforcement learning as one big sequence modeling problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={1273--1286},
  year={2021}
}

@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{lyu2022mildly,
  title={Mildly conservative {Q}-learning for offline reinforcement learning},
  author={Lyu, Jiafei and Ma, Xiaoteng and Li, Xiu and Lu, Zongqing},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1711--1724},
  year={2022}
}

@article{hoffman2020acme,
  title={Acme: A research framework for distributed reinforcement learning},
  author={Hoffman, Matt and Shahriari, Bobak and Aslanides, John and Barth-Maron, Gabriel and Behbahani, Feryal and Norman, Tamara and Abdolmaleki, Abbas and Cassirer, Albin and Yang, Fan and Baumli, Kate and others},
  journal={arXiv preprint arXiv:2006.00979},
  year={2020}
}

@article{arulkumaran2017brief,
  title={A brief survey of deep reinforcement learning},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={arXiv preprint arXiv:1708.05866},
  year={2017}
}

@article{polydoros2017survey,
  title={Survey of model-based reinforcement learning: Applications on robotics},
  author={Polydoros, Athanasios S and Nalpantidis, Lazaros},
  journal={Journal of Intelligent \& Robotic Systems},
  volume={86},
  number={2},
  pages={153--173},
  year={2017},
  publisher={Springer}
}
@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}
@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}



@article{kumar2019stabilizing,
  title={Stabilizing off-policy {Q}-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{kostrikov2021offline,
  title={Offline reinforcement learning with fisher divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}

@inproceedings{ghasemipour2021emaq,
  title={{EM}a{Q}: Expected-Max {Q}-Learning Operator for Simple Yet Effective Offline and Online RL},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@article{fakoor2021continuous,
  title={Continuous doubly constrained batch reinforcement learning},
  author={Fakoor, Rasool and Mueller, Jonas W and Asadi, Kavosh and Chaudhari, Pratik and Smola, Alexander J},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11260--11273},
  year={2021}
}


@inproceedings{xusparse,
  title={Sparse {Q}-Learning: Offline Reinforcement Learning with Implicit Value Regularization},
  author={Xu, Haoran and Jiang, Li and Li, Jianxiong and Yang, Zhuoran and Wang, Zhaoran and Zhan, Xianyuan},
  booktitle={3rd Offline RL Workshop: Offline RL as a''Launchpad''},
  year={2022}
}

@article{chen2020bail,
  title={BAIL: Best-action imitation learning for batch deep reinforcement learning},
  author={Chen, Xinyue and Zhou, Zijian and Wang, Zheng and Wang, Che and Wu, Yanqiu and Ross, Keith},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18353--18363},
  year={2020}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

@inproceedings{lee2020representation,
  title={Representation balancing offline model-based reinforcement learning},
  author={Lee, Byung-Jun and Lee, Jongmin and Kim, Kee-Eung},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={28954--28967},
  year={2021}
}

@article{wang2022diffusion,
  title={Diffusion policies as an expressive policy class for offline reinforcement learning},
  author={Wang, Zhendong and Hunt, Jonathan J and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2208.06193},
  year={2022}
}

@inproceedings{dadashi2021offline,
  title={Offline reinforcement learning with pseudometric learning},
  author={Dadashi, Robert and Rezaeifar, Shideh and Vieillard, Nino and Hussenot, L{\'e}onard and Pietquin, Olivier and Geist, Matthieu},
  booktitle={International Conference on Machine Learning},
  pages={2307--2318},
  year={2021},
  organization={PMLR}
}

@inproceedings{buckman2020importance,
  title={The Importance of Pessimism in Fixed-Dataset Policy Optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  booktitle={International Conference on Learning Representations},
  year={2020}
}


@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{garg2023extreme,
  title={Extreme {Q}-Learning: MaxEnt RL without Entropy},
  author={Garg, Divyansh and Hejna, Joey and Geist, Matthieu and Ermon, Stefano},
  journal={arXiv preprint arXiv:2301.02328},
  year={2023}
}

@inproceedings{rezaeifar2022offline,
  title={Offline reinforcement learning as anti-exploration},
  author={Rezaeifar, Shideh and Dadashi, Robert and Vieillard, Nino and Hussenot, L{\'e}onard and Bachem, Olivier and Pietquin, Olivier and Geist, Matthieu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={7},
  pages={8106--8114},
  year={2022}
}

@article{kostrikov2021offline2,
  title={Offline reinforcement learning with implicit {Q}-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{yang2022regularized,
  title={A regularized implicit policy for offline reinforcement learning},
  author={Yang, Shentao and Wang, Zhendong and Zheng, Huangjie and Feng, Yihao and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2202.09673},
  year={2022}
}

@inproceedings{zhang2022behavior,
  title={Behavior Estimation from Multi-Source Data for Offline Reinforcement Learning},
  author={Zhang, Guoxi and Kashima, Hisashi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={9},
  pages={11201--11209},
  year={2023}
}

@article{harris2020array,
  title={Array programming with NumPy},
  author={Harris, Charles R and Millman, K Jarrod and Van Der Walt, St{\'e}fan J and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J and others},
  journal={Nature},
  volume={585},
  number={7825},
  pages={357--362},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{bradbury2021jax,
  title={Jax: Autograd and xla},
  author={Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and Wanderman-Milne, Skye and others},
  journal={Astrophysics Source Code Library},
  pages={ascl--2111},
  year={2021}
}