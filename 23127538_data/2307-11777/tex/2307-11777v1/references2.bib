
@misc{olympics_history_2023,
	title = {History of handball},
	url = {https://olympics.com/en/sports/handball/},
	author = {Olympics},
	year = {2023},
	note = {Accessed: 2023-05-13},
}

@article{zebari_predicting_2021,
	title = {Predicting {Football} {Outcomes} by {Using} {Poisson} {Model}: {Applied} to {Spanish} {Primera} {División}},
	volume = {2},
	copyright = {Copyright (c) 2021 mohammed M.Sadeeq, Gheyath  Mustafa Zebari, Subhi  Zeebaree, Rizgar  Zebari},
	issn = {2708-0757},
	shorttitle = {Predicting {Football} {Outcomes} by {Using} {Poisson} {Model}},
	url = {https://jastt.org/index.php/jasttpath/article/view/112},
	doi = {10.38094/jastt204112},
	abstract = {During the past decades, sport, in general, has become one of the most powerful competitions and the most popular in the world. As well as, everyone is waiting for the winner, and who will be the champion in the end in different tournaments. Among these sports, football's popularity is more than all other sports. Football matches results predicting, as well as the champion in various competitions, has been seriously studied in recent years. Moreover, it has become an interesting field for many researchers. In this work, the Poisson model has been presented to predict the winner, draw, and loser from the football matches. The method is applied to the Spanish Primera División (First Division) in 2016-2017; the data has been downloaded from the football-data.co.uk website, which will be used to find the prediction accuracy.},
	language = {en},
	number = {04},
	urldate = {2023-07-19},
	journal = {Journal of Applied Science and Technology Trends},
	author = {Zebari, Gheyath Mustafa and Zeebaree, Subhi and M.Sadeeq, Mohammed and Zebari, Rizgar},
	month = sep,
	year = {2021},
	note = {Number: 04},
	keywords = {Internet of Things},
	pages = {105--112},
}

@article{brier_verification_1950,
	title = {Verification of {Forecasts} {Expressed} in {Terms} of {Probability}},
	volume = {78},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_vofeit_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2},
	abstract = {Abstract No Abstract Available.},
	language = {EN},
	number = {1},
	urldate = {2023-07-18},
	journal = {Monthly Weather Review},
	author = {Brier, Glenn W.},
	month = jan,
	year = {1950},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {1--3},
}

@misc{hamon_robustness_2020,
	title = {Robustness and {Explainability} of {Artificial} {Intelligence}},
	url = {https://publications.jrc.ec.europa.eu/repository/handle/JRC119336},
	abstract = {In the light of the recent advances in artificial intelligence (AI), the serious negative consequences of its use for EU citizens and organisations have led to multiple initiatives from the European Commission to set up the principles of a trustworthy and secure AI. Among the identified requirements, the concepts of robustness and explainability of AI systems have emerged as key elements for a future regulation of this technology. 
This Technical Report by the European Commission Joint Research Centre (JRC) aims to contribute to this movement for the establishment of a sound regulatory framework for AI, by making the connection between the principles embodied in current regulations regarding to the cybersecurity of digital systems and the protection of data, the policy activities concerning AI, and the technical discussions within the scientific community of AI, in particular in the field of machine learning, that is largely at the origin of the recent advancements of this technology.
The individual objectives of this report are to provide a policy-oriented description of the current perspectives of AI and its implications in society, an objective view on the current landscape of AI, focusing of the aspects of robustness and explainability. This also include a technical discussion of the current risks associated with AI in terms of security, safety, and data protection, and a presentation of the scientific solutions that are currently under active development in the AI community to mitigate these risks. 
This report puts forward several policy-related considerations for the attention of policy makers to establish a set of standardisation and certification tools for AI. First, the development of methodologies to evaluate the impacts of AI on society, built on the model of the Data Protection Impact Assessments (DPIA) introduced in the General Data Protection Regulation (GDPR), is discussed. Secondly, a focus is made on the establishment of methodologies to assess the robustness of systems that would be adapted to the context of use. This would come along with the identification of known vulnerabilities of AI systems, and the technical solutions that have been proposed in the scientific community to address them. Finally, the promotion of transparency systems in sensitive systems is discussed, through the implementation of explainability-by-design approaches in AI components that would provide guarantee of the respect of the fundamental rights.},
	language = {en},
	urldate = {2023-07-18},
	journal = {JRC Publications Repository},
	author = {Hamon, Ronan and Junklewitz, Henrik and Sanchez, MARTIN Jose Ignacio},
	month = jan,
	year = {2020},
	doi = {10.2760/57493},
	note = {ISBN: 9789276146605
ISSN: 1831-9424},
}

@misc{felice_ranking_2023,
	title = {Ranking {Handball} {Teams} from {Statistical} {Strength} {Estimation}},
	copyright = {Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (CC-BY-NC-ND)},
	url = {http://arxiv.org/abs/2307.06754},
	abstract = {In this work, we present a methodology to estimate the strength of handball teams using a statistical method. We propose the use of the Conway-Maxwell-Poisson distribution to model the number of goals scored by a team as a flexible discrete distribution which can handle situations of non equi-dispersion. From its parameters, we derive a mathematical formula to determine the strength of a team. We propose a ranking based on the estimated strengths to compare teams across different championships. Applied to female handball club data from European competitions over the season 2022/2023, we show that our new ranking can have an echo in real sports events and the results.},
	urldate = {2023-07-18},
	publisher = {arXiv},
	author = {Felice, Florian},
	month = jul,
	year = {2023},
	note = {arXiv:2307.06754 [stat]},
	keywords = {Statistics - Applications, Statistics - Methodology},
}

@article{wickstrom_uncertainty_2020,
	title = {Uncertainty and interpretability in convolutional neural networks for semantic segmentation of colorectal polyps},
	volume = {60},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841519301574},
	doi = {https://doi.org/10.1016/j.media.2019.101619},
	abstract = {Colorectal polyps are known to be potential precursors to colorectal cancer, which is one of the leading causes of cancer-related deaths on a global scale. Early detection and prevention of colorectal cancer is primarily enabled through manual screenings, where the intestines of a patient is visually examined. Such a procedure can be challenging and exhausting for the person performing the screening. This has resulted in numerous studies on designing automatic systems aimed at supporting physicians during the examination. Recently, such automatic systems have seen a significant improvement as a result of an increasing amount of publicly available colorectal imagery and advances in deep learning research for object image recognition. Specifically, decision support systems based on Convolutional Neural Networks (CNNs) have demonstrated state-of-the-art performance on both detection and segmentation of colorectal polyps. However, CNN-based models need to not only be precise in order to be helpful in a medical context. In addition, interpretability and uncertainty in predictions must be well understood. In this paper, we develop and evaluate recent advances in uncertainty estimation and model interpretability in the context of semantic segmentation of polyps from colonoscopy images. Furthermore, we propose a novel method for estimating the uncertainty associated with important features in the input and demonstrate how interpretability and uncertainty can be modeled in DSSs for semantic segmentation of colorectal polyps. Results indicate that deep models are utilizing the shape and edge information of polyps to make their prediction. Moreover, inaccurate predictions show a higher degree of uncertainty compared to precise predictions.},
	journal = {Medical Image Analysis},
	author = {Wickstrøm, Kristoffer and Kampffmeyer, Michael and Jenssen, Robert},
	year = {2020},
	keywords = {CNN, Decision support systems, Fully convolutional networks, Guided backpropagation, Interpretable ML, Monte carlo dropout, Monte carlo guided backpropagation, PhD - Literature review, Polyp segmentation, Unread},
	pages = {101619},
}

@book{european_commission_robustness_2020,
	address = {LU},
	title = {Robustness and explainability of {Artificial} {Intelligence}: from technical to policy solutions.},
	shorttitle = {Robustness and explainability of {Artificial} {Intelligence}},
	url = {https://data.europa.eu/doi/10.2760/57493},
	language = {eng},
	urldate = {2023-07-01},
	publisher = {Publications Office},
	author = {{European Commission}},
	year = {2020},
}

@inproceedings{ghorbani_data_2019,
	title = {Data {Shapley}: {Equitable} {Valuation} of {Data} for {Machine} {Learning}},
	shorttitle = {Data {Shapley}},
	url = {https://proceedings.mlr.press/v97/ghorbani19c.html},
	abstract = {As data becomes the fuel driving technological and economic growth, a fundamental challenge is how to quantify the value of data in algorithmic predictions and decisions. For example, in healthcare and consumer markets, it has been suggested that individuals should be compensated for the data that they generate, but it is not clear what is an equitable valuation for individual data. In this work, we develop a principled framework to address data valuation in the context of supervised machine learning. Given a learning algorithm trained on nnn data points to produce a predictor, we propose data Shapley as a metric to quantify the value of each training datum to the predictor performance. Data Shapley uniquely satisfies several natural properties of equitable data valuation. We develop Monte Carlo and gradient-based methods to efficiently estimate data Shapley values in practical settings where complex learning algorithms, including neural networks, are trained on large datasets. In addition to being equitable, extensive experiments across biomedical, image and synthetic data demonstrate that data Shapley has several other benefits: 1) it is more powerful than the popular leave-one-out or leverage score in providing insight on what data is more valuable for a given learning task; 2) low Shapley value data effectively capture outliers and corruptions; 3) high Shapley value data inform what type of new data to acquire to improve the predictor.},
	language = {en},
	urldate = {2022-05-31},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Ghorbani, Amirata and Zou, James},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	keywords = {Interpretable ML, Unread},
	pages = {2242--2251},
}

@article{rosenblatt_perceptron_1958,
	title = {The perceptron: {A} probabilistic model for information storage and organization in the brain},
	volume = {65},
	issn = {1939-1471, 0033-295X},
	shorttitle = {The perceptron},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042519},
	doi = {10.1037/h0042519},
	language = {en},
	number = {6},
	urldate = {2023-07-01},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	pages = {386--408},
}

@inproceedings{prokhorenkova_catboost_2018,
	address = {Red Hook, NY, USA},
	series = {{NIPS}'18},
	title = {{CatBoost}: unbiased boosting with categorical features},
	shorttitle = {{CatBoost}},
	doi = {https://doi.org/10.48550/arXiv.1706.09516},
	abstract = {This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.},
	urldate = {2023-07-01},
	booktitle = {Proceedings of the 32nd {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
	year = {2018},
	pages = {6639--6649},
}

@article{groll_hybrid_2019,
	title = {A hybrid random forest to predict soccer matches in international tournaments},
	volume = {15},
	issn = {1559-0410, 2194-6388},
	url = {https://www.degruyter.com/document/doi/10.1515/jqas-2018-0060/html},
	doi = {10.1515/jqas-2018-0060},
	abstract = {Abstract
            
              In this work, we propose a new hybrid modeling approach for the scores of international soccer matches which combines
              random forests
              with
              Poisson ranking methods
              . While the random forest is based on the competing teams’ covariate information, the latter method estimates ability parameters on historical match data that adequately reflect the current strength of the teams. We compare the new
              hybrid random forest
              model to its separate building blocks as well as to conventional Poisson regression models with regard to their predictive performance on all matches from the four FIFA World Cups 2002–2014. It turns out that by combining the random forest with the team ability parameters from the ranking methods as an additional covariate the predictive power can be improved substantially. Finally, the hybrid random forest is used (in advance of the tournament) to predict the FIFA World Cup 2018. To complete our analysis on the previous World Cup data, the corresponding 64 matches serve as an independent validation data set and we are able to confirm the compelling predictive potential of the hybrid random forest which clearly outperforms all other methods including the betting odds.},
	language = {en},
	number = {4},
	journal = {Journal of Quantitative Analysis in Sports},
	author = {Groll, Andreas and Ley, Cristophe and Schauberger, Gunther and Van Eetvelde, Hans},
	month = oct,
	year = {2019},
	pages = {271--287},
}

@article{karlis_analysis_2003,
	title = {Analysis of sports data by using bivariate {Poisson} models},
	volume = {52},
	issn = {1467-9884},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9884.00366},
	doi = {10.1111/1467-9884.00366},
	abstract = {Summary. Models based on the bivariate Poisson distribution are used for modelling sports data. Independent Poisson distributions are usually adopted to model the number of goals of two competing teams. We replace the independence assumption by considering a bivariate Poisson model and its extensions. The models proposed allow for correlation between the two scores, which is a plausible assumption in sports with two opposing teams competing against each other. The effect of introducing even slight correlation is discussed. Using just a bivariate Poisson distribution can improve model fit and prediction of the number of draws in football games. The model is extended by considering an inflation factor for diagonal terms in the bivariate joint distribution. This inflation improves in precision the estimation of draws and, at the same time, allows for overdispersed, relative to the simple Poisson distribution, marginal distributions. The properties of the models proposed as well as interpretation and estimation procedures are provided. An illustration of the models is presented by using data sets from football and water-polo.},
	language = {en},
	number = {3},
	urldate = {2023-07-05},
	journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
	author = {Karlis, Dimitris and Ntzoufras, Ioannis},
	year = {2003},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9884.00366},
	keywords = {Bivariate Poisson regression, Difference of Poisson variates, Inflated distributions, Soccer},
	pages = {381--393},
}

@article{ley_ranking_2019,
	title = {Ranking soccer teams on the basis of their current strength: {A} comparison of maximum likelihood approaches},
	volume = {19},
	issn = {1471-082X},
	shorttitle = {Ranking soccer teams on the basis of their current strength},
	url = {https://doi.org/10.1177/1471082X18817650},
	doi = {10.1177/1471082X18817650},
	abstract = {We present 10 different strength-based statistical models that we use to model soccer match outcomes with the aim of producing a new ranking. The models are of four main types: Thurstone–Mosteller, Bradley–Terry, independent Poisson and bivariate Poisson, and their common aspect is that the parameters are estimated via weighted maximum likelihood, the weights being a match importance factor and a time depreciation factor giving less weight to matches that are played a long time ago. Since our goal is to build a ranking reflecting the teams’ current strengths, we compare the 10 models on the basis of their predictive performance via the Rank Probability Score at the level of both domestic leagues and national teams. We find that the best models are the bivariate and independent Poisson models. We then illustrate the versatility and usefulness of our new rankings by means of three examples where the existing rankings fail to provide enough information or lead to peculiar results.},
	language = {en},
	number = {1},
	urldate = {2023-07-01},
	journal = {Statistical Modelling},
	author = {Ley, Christophe and Van de Wiele, Tom and Van Eetvelde, Hans},
	month = feb,
	year = {2019},
	note = {Publisher: SAGE Publications India},
	pages = {55--73},
}

@article{reep_skill_1971,
	title = {Skill and {Chance} in {Ball} {Games}},
	volume = {134},
	issn = {00359238},
	url = {https://www.jstor.org/stable/2343657},
	doi = {10.2307/2343657},
	number = {4},
	urldate = {2023-07-01},
	journal = {Journal of the Royal Statistical Society. Series A (General)},
	author = {Reep, C. and Pollard, R. and Benjamin, B.},
	year = {1971},
	pages = {623},
}

@article{bradley_rank_1952,
	title = {Rank {Analysis} of {Incomplete} {Block} {Designs}: {I}. {The} {Method} of {Paired} {Comparisons}},
	volume = {39},
	issn = {00063444},
	shorttitle = {Rank {Analysis} of {Incomplete} {Block} {Designs}},
	url = {https://www.jstor.org/stable/2334029?origin=crossref},
	doi = {10.2307/2334029},
	number = {3/4},
	urldate = {2023-07-01},
	journal = {Biometrika},
	author = {Bradley, Ralph Allan and Terry, Milton E.},
	month = dec,
	year = {1952},
	pages = {324},
}

@article{thurstone_psychophysical_1927,
	title = {Psychophysical {Analysis}},
	volume = {38},
	issn = {00029556},
	url = {https://www.jstor.org/stable/1415006?origin=crossref},
	doi = {10.2307/1415006},
	number = {3},
	urldate = {2023-07-01},
	journal = {The American Journal of Psychology},
	author = {Thurstone, L. L.},
	month = jul,
	year = {1927},
	pages = {368},
}

@article{van_bommel_home_2021,
	title = {Home sweet home: {Quantifying} home court advantages for {NCAA} basketball statistics},
	volume = {7},
	issn = {2215020X, 22150218},
	shorttitle = {Home sweet home},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JSA-200450},
	doi = {10.3233/JSA-200450},
	abstract = {Box score statistics are the baseline measures of performance for National Collegiate Athletic Association (NCAA) basketball. Between the 2011-2012 and 2015-2016 seasons, NCAA teams performed better at home compared to on the road in nearly all box score statistics across both genders and all three divisions. Using box score data from over 100,000 games spanning the three divisions for both women and men, we examine the factors underlying this discrepancy. The prevalence of neutral location games in the NCAA provides an additional angle through which to examine the gaps in box score statistic performance, which we believe has been underutilized in existing literature. We also estimate a regression model to quantify the home court advantages for box score statistics after controlling for other factors such as number of possessions, and team strength. Additionally, we examine the biases of scorekeepers and referees. We present evidence that scorekeepers tend to have greater home team biases when observing men compared to women, higher divisions compared to lower divisions, and stronger teams compared to weaker teams. Finally, we present statistically significant results indicating referee decisions are impacted by attendance, with larger crowds resulting in greater bias in favor of the home team.},
	number = {1},
	journal = {Journal of Sports Analytics},
	author = {Van Bommel, Matthew and Bornn, Luke and Chow-White, Peter and Gao, Chuancong},
	month = apr,
	year = {2021},
	pages = {25--36},
}

@article{karlis_bayesian_2008,
	title = {Bayesian modelling of football outcomes: using the {Skellam}'s distribution for the goal difference},
	volume = {20},
	issn = {1471-678X, 1471-6798},
	shorttitle = {Bayesian modelling of football outcomes},
	url = {https://academic.oup.com/imaman/article-lookup/doi/10.1093/imaman/dpn026},
	doi = {10.1093/imaman/dpn026},
	language = {en},
	number = {2},
	journal = {IMA Journal of Management Mathematics},
	author = {Karlis, D. and Ntzoufras, I.},
	month = aug,
	year = {2008},
	pages = {133--145},
}

@misc{felice_statistically_2023,
	title = {Statistically {Enhanced} {Learning}: a feature engineering framework to boost (any) learning algorithms},
	copyright = {All rights reserved},
	shorttitle = {Statistically {Enhanced} {Learning}},
	url = {http://arxiv.org/abs/2306.17006},
	doi = {10.48550/arXiv.2306.17006},
	abstract = {Feature engineering is of critical importance in the field of Data Science. While any data scientist knows the importance of rigorously preparing data to obtain good performing models, only scarce literature formalizes its benefits. In this work, we will present the method of Statistically Enhanced Learning (SEL), a formalization framework of existing feature engineering and extraction tasks in Machine Learning (ML). The difference compared to classical ML consists in the fact that certain predictors are not directly observed but obtained as statistical estimators. Our goal is to study SEL, aiming to establish a formalized framework and illustrate its improved performance by means of simulations as well as applications on real life use cases.},
	publisher = {arXiv},
	author = {Felice, Florian and Ley, Christophe and Groll, Andreas and Bordas, Stéphane},
	month = jun,
	year = {2023},
	note = {arXiv:2306.17006 [stat]},
	keywords = {Statistics - Methodology},
}

@misc{groll_hybrid_2021,
	title = {Hybrid {Machine} {Learning} {Forecasts} for the {UEFA} {EURO} 2020},
	url = {http://arxiv.org/abs/2106.05799},
	abstract = {Three state-of-the-art statistical ranking methods for forecasting football matches are combined with several other predictors in a hybrid machine learning model. Namely an ability estimate for every team based on historic matches; an ability estimate for every team based on bookmaker consensus; average plus-minus player ratings based on their individual performances in their home clubs and national teams; and further team covariates (e.g., market value, team structure) and country-specific socio-economic factors (population, GDP). The proposed combined approach is used for learning the number of goals scored in the matches from the four previous UEFA EUROs 2004-2016 and then applied to current information to forecast the upcoming UEFA EURO 2020. Based on the resulting estimates, the tournament is simulated repeatedly and winning probabilities are obtained for all teams. A random forest model favors the current World Champion France with a winning probability of 14.8\% before England (13.5\%) and Spain (12.3\%). Additionally, we provide survival probabilities for all teams and at all tournament stages.},
	urldate = {2023-07-01},
	publisher = {arXiv},
	author = {Groll, Andreas and Hvattum, Lars Magnus and Ley, Christophe and Popp, Franziska and Schauberger, Gunther and Van Eetvelde, Hans and Zeileis, Achim},
	month = jun,
	year = {2021},
	note = {arXiv:2106.05799 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Applications},
}

@book{zheng_feature_2018,
	title = {Feature engineering for machine learning: principles and techniques for data scientists},
	publisher = {"O'Reilly Media, Inc."},
	author = {Zheng, Alice and Casari, Amanda},
	year = {2018},
}

@article{poisson_probabilite_1837,
	title = {Probabilité des jugements en matière criminelle et en matière civile, précédées des règles générales du calcul des probabilitiés},
	volume = {1},
	number = {1837},
	journal = {Paris, France: Bachelier},
	author = {Poisson, Siméon Denis},
	year = {1837},
	pages = {1837},
}

@article{sovrano_metrics_2022,
	title = {Metrics, {Explainability} and the {European} {AI} {Act} {Proposal}},
	volume = {5},
	issn = {2571-8800},
	url = {https://www.mdpi.com/2571-8800/5/1/10},
	doi = {10.3390/j5010010},
	abstract = {On 21 April 2021, the European Commission proposed the first legal framework on Artificial Intelligence (AI) to address the risks posed by this emerging method of computation. The Commission proposed a Regulation known as the AI Act. The proposed AI Act considers not only machine learning, but expert systems and statistical models long in place. Under the proposed AI Act, new obligations are set to ensure transparency, lawfulness, and fairness. Their goal is to establish mechanisms to ensure quality at launch and throughout the whole life cycle of AI-based systems, thus ensuring legal certainty that encourages innovation and investments on AI systems while preserving fundamental rights and values. A standardisation process is ongoing: several entities (e.g., ISO) and scholars are discussing how to design systems that are compliant with the forthcoming Act, and explainability metrics play a significant role. Specifically, the AI Act sets some new minimum requirements of explicability (transparency and explainability) for a list of AI systems labelled as “high-risk” listed in Annex III. These requirements include a plethora of technical explanations capable of covering the right amount of information, in a meaningful way. This paper aims to investigate how such technical explanations can be deemed to meet the minimum requirements set by the law and expected by society. To answer this question, with this paper we propose an analysis of the AI Act, aiming to understand (1) what specific explicability obligations are set and who shall comply with them and (2) whether any metric for measuring the degree of compliance of such explanatory documentation could be designed. Moreover, by envisaging the legal (or ethical) requirements that such a metric should possess, we discuss how to implement them in a practical way. More precisely, drawing inspiration from recent advancements in the theory of explanations, our analysis proposes that metrics to measure the kind of explainability endorsed by the proposed AI Act shall be risk-focused, model-agnostic, goal-aware, intelligible, and accessible. Therefore, we discuss the extent to which these requirements are met by the metrics currently under discussion.},
	language = {en},
	number = {1},
	urldate = {2023-07-01},
	journal = {J},
	author = {Sovrano, Francesco and Sapienza, Salvatore and Palmirani, Monica and Vitali, Fabio},
	month = feb,
	year = {2022},
	pages = {126--138},
}

@article{lundberg_local_2020,
	title = {From local explanations to global understanding with explainable {AI} for trees},
	volume = {2},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-019-0138-9},
	doi = {10.1038/s42256-019-0138-9},
	abstract = {Tree-based machine learning models such as random forests, decision trees and gradient boosted trees are popular nonlinear predictive models, yet comparatively little attention has been paid to explaining their predictions. Here we improve the interpretability of tree-based models through three main contributions. (1) A polynomial time algorithm to compute optimal explanations based on game theory. (2) A new type of explanation that directly measures local feature interaction effects. (3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to (1) identify high-magnitude but low-frequency nonlinear mortality risk factors in the US population, (2) highlight distinct population subgroups with shared risk characteristics, (3) identify nonlinear interaction effects among risk factors for chronic kidney disease and (4) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model’s performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.},
	language = {en},
	number = {1},
	urldate = {2022-05-31},
	journal = {Nature Machine Intelligence},
	author = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
	month = jan,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computer science, Interpretable ML, Medical research, Software, Unread},
	pages = {56--67},
}

@inproceedings{chen_xgboost_2016,
	address = {New York, NY, USA},
	series = {{KDD} '16},
	title = {{XGBoost}: {A} {Scalable} {Tree} {Boosting} {System}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {{XGBoost}},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
	doi = {10.1145/2939672.2939785},
	abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
	urldate = {2023-07-01},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Tianqi and Guestrin, Carlos},
	year = {2016},
	keywords = {large-scale machine learning},
	pages = {785--794},
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {08856125},
	shorttitle = {Random {Forests}},
	url = {http://link.springer.com/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	number = {1},
	urldate = {2023-07-01},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	year = {2001},
	pages = {5--32},
}

@article{lampis_predictions_2023,
	title = {Predictions of european basketball match results with machine learning algorithms},
	issn = {2215020X, 22150218},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JSA-220639},
	doi = {10.3233/JSA-220639},
	abstract = {The goal of this paper is to build and compare methods for the prediction of the final outcomes of basketball games. In this study, we analyzed data from four different European tournaments: Euroleague, Eurocup, Greek Basket League and Spanish Liga ACB. The data-set consists of information collected from box scores of 5214 games for the period of 2013-2018. The predictions obtained by our implemented methods and models were compared with a “vanilla” model using only the team-name information of each game. In our analysis, we have included new performance indicators constructed by using historical statistics, key performance indicators and measurements from three rating systems (Elo, PageRank, pi-rating). For these three rating systems and every tournament under consideration, we tune the rating system parameters using specific training data-sets. These new game features are improving our predictions efficiently and can be easily obtained in any basketball league. Our predictions were obtained by implementing three different statistics and machine learning algorithms: logistic regression, random forest, and extreme gradient boosting trees. Moreover, we report predictions based on the combination of these algorithms (ensemble learning). We evaluate our predictions using three predictive measures: Brier Score, accuracy and F 1-score. In addition, we evaluate the performance of our algorithms with three different prediction scenarios (full-season, mid-season, and play-offs predictive evaluation). For the mid-season and the play-offs scenarios, we further explore whether incorporating additional results from previous seasons in the learning data-set enhances the predictive performance of the implemented models and algorithms. Concerning the results, there is no clear winner between the machine learning algorithms since they provide identical predictions with small differences. However, models with predictors suggested in this paper out-perform the “vanilla” model by 3-5\% in terms of accuracy. Another conclusion from our results for the play-offs scenarios is that it is not necessary to embed outcomes from previous seasons in our training data-set. Using data from the current season, most of the time, leads to efficient, accurate parameter learning and well-behaved prediction models. Moreover, the Greek league is the least balanced tournament in terms of competitiveness since all our models achieve high predictive accuracy (78\%, on the best-performing model). The second less balanced league is the Spanish one with accuracy reaching 72\% while for the two European tournaments the prediction accuracy is considerably lower (about 69\% ). Finally, we present the most important features by counting the percentage of appearance in every machine learning algorithm for every one of the three analyses. From this analysis, we may conclude that the best predictors are the rating systems (pi-rating, PageRank, and ELO) and the current form performance indicators (e.g., the two most frequent ones are the game score of Hollinger and the floor impact counter).},
	urldate = {2023-07-01},
	journal = {Journal of Sports Analytics},
	author = {Lampis, Tzai and Ioannis, Ntzoufras and Vasilios, Vassalos and Stavrianna, Dimitriou},
	month = mar,
	year = {2023},
	pages = {1--20},
}

@inproceedings{huang_neural_2010,
	address = {Barcelona, Spain},
	title = {A neural network method for prediction of 2006 {World} {Cup} {Football} {Game}},
	isbn = {978-1-4244-6916-1},
	url = {http://ieeexplore.ieee.org/document/5596458/},
	doi = {10.1109/IJCNN.2010.5596458},
	urldate = {2023-07-01},
	booktitle = {The 2010 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Huang, Kou-Yuan and Chang, Wen-Lung},
	month = jul,
	year = {2010},
	pages = {1--8},
}

@article{cai_hybrid_2019,
	title = {A hybrid ensemble learning framework for basketball outcomes prediction},
	volume = {528},
	issn = {03784371},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378437119308507},
	doi = {10.1016/j.physa.2019.121461},
	language = {en},
	urldate = {2023-07-01},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Cai, Weihong and Yu, Ding and Wu, Ziyu and Du, Xin and Zhou, Teng},
	month = aug,
	year = {2019},
	pages = {121461},
}

@article{rodriguez-ruiz_study_2011,
	title = {Study of the {Technical} and {Tactical} {Variables} {Determining} {Set} {Win} or {Loss} in {Top}-{Level} {European} {Men}'s {Volleyball}},
	volume = {7},
	issn = {1559-0410},
	url = {https://www.degruyter.com/document/doi/10.2202/1559-0410.1281/html},
	doi = {10.2202/1559-0410.1281},
	number = {1},
	urldate = {2023-07-01},
	journal = {Journal of Quantitative Analysis in Sports},
	author = {Rodriguez-Ruiz, David and Quiroga, Miriam E. and Miralles, Jose A. and Sarmiento, Samuel and De Saá, Yves and García-Manso, Juan M.},
	month = jan,
	year = {2011},
}

@inproceedings{mccabe_artificial_2008,
	address = {Las Vegas, NV, USA},
	title = {Artificial {Intelligence} in {Sports} {Prediction}},
	isbn = {978-0-7695-3099-4},
	url = {http://ieeexplore.ieee.org/document/4492661/},
	doi = {10.1109/ITNG.2008.203},
	urldate = {2023-07-01},
	booktitle = {Fifth {International} {Conference} on {Information} {Technology}: {New} {Generations} (itng 2008)},
	publisher = {IEEE},
	author = {McCabe, Alan and Trevathan, Jarrod},
	month = apr,
	year = {2008},
	pages = {1194--1197},
}

@inproceedings{miljkovic_use_2010,
	address = {Subotica, Serbia},
	title = {The use of data mining for basketball matches outcomes prediction},
	isbn = {978-1-4244-7394-6},
	url = {http://ieeexplore.ieee.org/document/5647440/},
	doi = {10.1109/SISY.2010.5647440},
	urldate = {2023-07-01},
	booktitle = {{IEEE} 8th {International} {Symposium} on {Intelligent} {Systems} and {Informatics}},
	publisher = {IEEE},
	author = {Miljkovic, Dragan and Gajic, Ljubisa and Kovacevic, Aleksandar and Konjovic, Zora},
	month = sep,
	year = {2010},
	pages = {309--312},
}

@article{pic_performance_2018,
	title = {Performance and {Home} {Advantage} in {Handball}},
	volume = {63},
	issn = {1640-5544},
	doi = {10.2478/hukin-2018-0007},
	abstract = {The main objective of this research was to delve into the concept of playing handball at home from a classical perspective of previous studies. The emergence of regularities or certain patterns of play can be explained by the location of matches. Through an observational methodology and a nomothetic, monitoring and multidimensional design, thirty-nine European elite handball matches were selected (N = 39). A mixed 'ad hoc' registration system was designed. Records were made of the last three minutes of home and visiting games of which images were available. Two observers with observational methodology experience participated in the study. The quality of the records was dealt with in an intraobserver and interobserver way. Two different techniques were applied for the treatment of the data: a) detection of behavioral patterns by Theme (p {\textless} .005) (Magnusson, 2000) and b) Chaid decision trees (p {\textless} .05) using SPSSv.24. The results showed the existence of T-patterns according to the location (different T-patterns: home: 1085; away: 1242) of the matches. The categories most involved in effective launches were unveiled. On the other hand, the Chaid model also showed the effect of location (p {\textless} .001): home-win (node 9) (n = 149, 69\%), away-win (node 10) (n = 15, 16\%) in handball. Crossing analysis offered enriched interpretations to advance in the home advantage concept. From this study, guidelines can be drawn that may help handball coaches to build training tasks as differences in behavioral patterns between home or away play in handball were identified. Thus, designing tasks considering a match location has requires specificity.},
	language = {eng},
	journal = {Journal of Human Kinetics},
	author = {Pic, Miguel},
	month = aug,
	year = {2018},
	pmid = {30279942},
	pmcid = {PMC6162984},
	keywords = {game observational, handball, home advantage, theme},
	pages = {61--71},
}

@article{wagner_individual_2014,
	title = {Individual and team performance in team-handball: a review},
	volume = {13},
	issn = {1303-2968},
	shorttitle = {Individual and team performance in team-handball},
	abstract = {Team handball is a complex sport game that is determined by the individual performance of each player as well as tactical components and interaction of the team. The aim of this review was to specify the elements of team-handball performance based on scientific studies and practical experience, and to convey perspectives for practical implication. Scientific studies were identified via data bases of PubMed, Web of Knowledge, SPORT Discus, Google Scholar, and Hercules. A total of 56 articles met the inclusion criteria. In addition, we supplemented the review with 13 additional articles, proceedings and book sections. It was found that the specific characteristics of team-handball with frequent intensity changes, team-handball techniques, hard body confrontations, mental skills and social factors specify the determinants of coordination, endurance, strength and cognition. Although we found comprehensive studies examining individual performance in team-handball players of different experience level, sex or age, there is a lack of studies, particularly for team-handball specific training, as well as cognition and social factors. Key PointsThe specific characteristics of team-handball with frequent intensity changes, specific skills, hard body confrontations, mental skills and social factors define the determinants of coordination, endurance, strength and cognition.To increase individual and team performance in team-handball specific training based on these determinants have been suggested.Although there are comprehensive studies examining individual performance in team-handball players of different experience level, sex, or age are published, there is a lack of training studies, particularly for team-handball specific techniques and endurance, as well as cognition and social factors.},
	language = {eng},
	number = {4},
	journal = {Journal of Sports Science \& Medicine},
	author = {Wagner, Herbert and Finkenzeller, Thomas and Würth, Sabine and von Duvillard, Serge P.},
	month = dec,
	year = {2014},
	pmid = {25435773},
	pmcid = {PMC4234950},
	keywords = {Coordination, agility, cognition, constitution, endurance, social factors, strength and power},
	pages = {808--816},
}

@article{fonseca_relative_2019,
	title = {Relative {Age} {Effect} is {Modulated} by {Playing} {Position} but is {Not} {Related} to {Competitive} {Success} in {Elite} {Under}-19 {Handball} {Athletes}},
	volume = {7},
	issn = {2075-4663},
	url = {https://www.mdpi.com/2075-4663/7/4/91},
	doi = {10.3390/sports7040091},
	abstract = {This study aimed to verify the occurrence of the relative age effect (RAE) in male elite young handball athletes according to the playing position and its association with team performance in a World Championship. Data from 383 handball athletes from 24 countries who participated in the 7th World Men’s Championship in the under-19 category were analyzed. RAE was investigated from the birth trimester of the athletes, their playing position, and final ranking in the Championship. The results showed an overrepresentation of athletes born in the first two trimesters (Q1 and Q2) (χ2(3) = 32.97; p {\textless} 0.001, ω = 0.29). The analysis of the athlete’s position showed that most wings (χ2(3) = 18.37; p {\textless} 0.001, ω = 0.32) and backs (χ2(3) = 12.51; p = 0.006, ω = 0.34) were born in the first trimesters (Q1 and Q2). The ranking in the Championship presented no significant association with the date of the birth (p {\textgreater} 0.05). The results showed the existence of the RAE in youth handball elite athletes, especially for the back and wing positions. However, the strategy of selecting is questionable once the presence of RAE was not associated with competitive success.},
	language = {en},
	number = {4},
	urldate = {2023-07-01},
	journal = {Sports},
	author = {Fonseca, Fabiano S. and Figueiredo, Lucas S. and Gantois, Petrus and De Lima-Junior, Dalton and Fortes, Leonardo S.},
	month = apr,
	year = {2019},
	pages = {91},
}

@article{madsen_activity_2019,
	title = {Activity {Profile}, {Heart} {Rate}, {Technical} {Involvement}, and {Perceived} {Intensity} and {Fun} in {U13} {Male} and {Female} {Team} {Handball} {Players}: {Effect} of {Game} {Format}},
	volume = {7},
	issn = {2075-4663},
	shorttitle = {Activity {Profile}, {Heart} {Rate}, {Technical} {Involvement}, and {Perceived} {Intensity} and {Fun} in {U13} {Male} and {Female} {Team} {Handball} {Players}},
	url = {https://www.mdpi.com/2075-4663/7/4/90},
	doi = {10.3390/sports7040090},
	abstract = {The aim of the study was to compare the activity pattern, heart rate (HR), technical involvement, and subjective perceptions in U13 boys and girls playing team handball in five game formats. Activity pattern, heart rate (HR), technical involvement, perceived fun, and exertion were recorded from four girls teams (n = 24) and four boys teams (n = 24) played during a 1-day tournament consisting of five different game formats of 15-min duration: Medium court size, 4v4 (M4v4), 5v5 (M5v5), and 6v6 (M6v6), and large court size, 5v5 (L5v5) and 6v6 (L6v6). Girls covered more total distance (TD) and high-speed running (HSR, 13–17.9 km·h−1) on the large court compared to the medium court (p {\textless} 0.05; ES = 2.1–3.1 and 1.2–2.5, respectively). Boys covered more distance as HSR and sprinting on the large court compared to the medium court, but only more TD on the large court compared to the medium court with the same number of players, (p {\textless} 0.05; ES = 1.0–1.8, 1.0–1.8, and 1.1–1.8, respectively). Team handball for U13 boys and girls is a high-intensity activity irrespective of court size. Increasing the court size with a fixed number of players increased the total distance and HSR, whereas manipulating the number of players on a fixed court size appears to influence technical involvement.},
	language = {en},
	number = {4},
	urldate = {2023-07-01},
	journal = {Sports},
	author = {Madsen, Mads and Ermidis, Georgios and Rago, Vincenzo and Surrow, Kristoffer and Vigh-Larsen, Jeppe F. and Randers, Morten B. and Krustrup, Peter and Larsen, Malte N.},
	month = apr,
	year = {2019},
	pages = {90},
}

@article{camacho-cardenosa_anthropometric_2018,
	title = {Anthropometric and {Physical} {Performance} of {Youth} {Handball} {Players}: {The} {Role} of the {Relative} {Age}},
	volume = {6},
	issn = {2075-4663},
	shorttitle = {Anthropometric and {Physical} {Performance} of {Youth} {Handball} {Players}},
	url = {http://www.mdpi.com/2075-4663/6/2/47},
	doi = {10.3390/sports6020047},
	language = {en},
	number = {2},
	urldate = {2023-07-01},
	journal = {Sports},
	author = {Camacho-Cardenosa, Alba and Camacho-Cardenosa, Marta and González-Custodio, Adrián and Martínez-Guardado, Ismael and Timón, Rafael and Olcina, Guillermo and Brazo-Sayavera, Javier},
	month = may,
	year = {2018},
	pages = {47},
}

@article{seil_sports_1998,
	title = {Sports {Injuries} in {Team} {Handball}},
	volume = {26},
	issn = {0363-5465, 1552-3365},
	url = {http://journals.sagepub.com/doi/10.1177/03635465980260051401},
	doi = {10.1177/03635465980260051401},
	abstract = {One hundred eighty-six players of 16 teams in 2 male team handball senior divisions were observed prospectively for 1 season to study the injury incidence in relation to exposure in games and practices. Ninety-one injuries were recorded. Injury incidence was evaluated at 2.5 injuries per 1000 player-hours, with a significantly higher incidence in game injuries (14.3 injuries per 1000 game-hours) compared with practice injuries (0.6 injuries per 1000 practice-hours). Practice injury incidence was higher in the lower performance level group, and game injury incidence was higher in the high-level group. The upper extremity was involved in 37\% of the injuries, and the lower extremity in 54\%. The knee was the most commonly injured joint, followed by the finger, ankle, and shoulder. Knee injuries were the most severe injuries, and they were more frequent in high-level players. There was an increase in the severity of injury with respect to performance level. The injury mechanism revealed a high number of offensive injuries, one-third of them occurring during a counterattack. The injury pattern showed certain variations with respect to player position and performance level. Prophylactic equipment was used by a majority of players at the higher performance level.},
	language = {en},
	number = {5},
	urldate = {2023-07-01},
	journal = {The American Journal of Sports Medicine},
	author = {Seil, Romain and Rupp, Stefan and Tempelhof, Siegbert and Kohn, Dieter},
	month = sep,
	year = {1998},
	pages = {681--687},
}

@article{akyuz_skeletal_2019,
	title = {Skeletal muscle fatigue does not affect shooting accuracy of handball players},
	volume = {27},
	issn = {09593020, 18785913},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/IES-193178},
	doi = {10.3233/IES-193178},
	number = {4},
	urldate = {2023-07-01},
	journal = {Isokinetics and Exercise Science},
	author = {Akyüz, Beyza and Avşar, Pınar Arpınar and Bilge, Murat and Deliceoğlu, Gökhan and Korkusuz, Feza},
	month = nov,
	year = {2019},
	pages = {253--259},
}

@article{grabara_posture_2018,
	title = {The posture of adolescent male handball players: {A} two-year study},
	volume = {31},
	issn = {18786324, 10538127},
	shorttitle = {The posture of adolescent male handball players},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/BMR-170792},
	doi = {10.3233/BMR-170792},
	number = {1},
	urldate = {2023-07-01},
	journal = {Journal of Back and Musculoskeletal Rehabilitation},
	author = {Grabara, Małgorzata},
	month = feb,
	year = {2018},
	pages = {183--189},
}

@article{saavedra_handball_2018,
	title = {Handball {Research}: {State} of the {Art}},
	volume = {63},
	issn = {1899-7562},
	shorttitle = {Handball {Research}},
	url = {https://www.sciendo.com/article/10.2478/hukin-2018-0001},
	doi = {10.2478/hukin-2018-0001},
	language = {en},
	number = {1},
	urldate = {2023-07-01},
	journal = {Journal of Human Kinetics},
	author = {Saavedra, Jose M.},
	month = sep,
	year = {2018},
	pages = {5--8},
}

@book{hahn_fascination_2013,
	title = {Fascination for {Thousands} of {Years} - {Handball} {History} and {Stories}},
	isbn = {19463/2013},
	url = {https://archive.ihf.info/upload/Book/issue0001/offline/download.pdf},
	publisher = {International Handball Federation},
	author = {Hahn, Raymond and Glock, Rudi and Birkefeld, Frank},
	month = jun,
	year = {2013},
}

@article{maher_modelling_1982,
	title = {Modelling association football scores},
	volume = {36},
	issn = {1467-9574},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9574.1982.tb00782.x},
	doi = {10.1111/j.1467-9574.1982.tb00782.x},
	abstract = {Previous authors have rejected the Poisson model for association football scores in favour of the Negative Binomial. This paper, however, investigates the Poisson model further. Parameters representing the teams' inherent attacking and defensive strengths are incorporated and the most appropriate model is found from a hierarchy of models. Observed and expected frequencies of scores are compared and goodness-of-fit tests show that although there are some small systematic differences, an independent Poisson model gives a reasonably accurate description of football scores. Improvements can be achieved by the use of a bivariate Poisson model with a correlation between scores of 0.2.},
	language = {en},
	number = {3},
	urldate = {2023-07-01},
	journal = {Statistica Neerlandica},
	author = {Maher, M. J.},
	year = {1982},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9574.1982.tb00782.x},
	keywords = {Poisson goals distribution, iterative maximum likelihood},
	pages = {109--118},
}

@misc{groll_hybrid_2021-1,
	title = {Hybrid {Machine} {Learning} {Forecasts} for the {UEFA} {EURO} 2020},
	url = {http://arxiv.org/abs/2106.05799},
	doi = {10.48550/arXiv.2106.05799},
	abstract = {Three state-of-the-art statistical ranking methods for forecasting football matches are combined with several other predictors in a hybrid machine learning model. Namely an ability estimate for every team based on historic matches; an ability estimate for every team based on bookmaker consensus; average plus-minus player ratings based on their individual performances in their home clubs and national teams; and further team covariates (e.g., market value, team structure) and country-specific socio-economic factors (population, GDP). The proposed combined approach is used for learning the number of goals scored in the matches from the four previous UEFA EUROs 2004-2016 and then applied to current information to forecast the upcoming UEFA EURO 2020. Based on the resulting estimates, the tournament is simulated repeatedly and winning probabilities are obtained for all teams. A random forest model favors the current World Champion France with a winning probability of 14.8\% before England (13.5\%) and Spain (12.3\%). Additionally, we provide survival probabilities for all teams and at all tournament stages.},
	urldate = {2023-07-01},
	publisher = {arXiv},
	author = {Groll, Andreas and Hvattum, Lars Magnus and Ley, Christophe and Popp, Franziska and Schauberger, Gunther and Van Eetvelde, Hans and Zeileis, Achim},
	month = jun,
	year = {2021},
	note = {arXiv:2106.05799 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Applications},
}

@misc{woodie_data_2020,
	title = {Data {Prep} {Still} {Dominates} {Data} {Scientists}’ {Time}, {Survey} {Finds}},
	url = {https://www.datanami.com/2020/07/06/data-prep-still-dominates-data-scientists-time-survey-finds/},
	abstract = {Data scientists spend about 45\% of their time on data preparation tasks, including loading and cleaning data, according to a survey of data scientists},
	urldate = {2023-06-27},
	journal = {Datanami},
	author = {Woodie, Alex},
	month = jul,
	year = {2020},
}

@article{zhang_data_2003,
	title = {Data preparation for data mining},
	volume = {17},
	issn = {0883-9514, 1087-6545},
	url = {http://www.tandfonline.com/doi/abs/10.1080/713827180},
	doi = {10.1080/713827180},
	language = {en},
	number = {5-6},
	urldate = {2023-06-27},
	journal = {Applied Artificial Intelligence},
	author = {Zhang, Shichao and Zhang, Chengqi and Yang, Qiang},
	month = may,
	year = {2003},
	pages = {375--381},
}

@book{roth_shapley_1988,
	address = {Cambridge},
	title = {The {Shapley} {Value}: {Essays} in {Honor} of {Lloyd} {S}. {Shapley}},
	isbn = {978-0-521-36177-4},
	shorttitle = {The {Shapley} {Value}},
	url = {https://www.cambridge.org/core/books/shapley-value/D3829B63B5C3108EFB62C4009E2B966E},
	abstract = {Composed in honour of the sixty-fifth birthday of Lloyd Shapley, this volume makes accessible the large body of work that has grown out of Shapley's seminal 1953 paper. Each of the twenty essays concerns some aspect of the Shapley value. Three of the chapters are reprints of the 'ancestral' papers: Chapter 2 is Shapley's original 1953 paper defining the value; Chapter 3 is the 1954 paper by Shapley and Shubik applying the value to voting models; and chapter 19 is Shapley's 1969 paper defining a value for games without transferable utility. The other seventeen chapters were contributed especially for this volume. The first chapter introduces the subject and the other essays in the volume, and contains a brief account of a few of Shapley's other major contributions to game theory. The other chapters cover the reformulations, interpretations and generalizations that have been inspired by the Shapley value, and its applications to the study of coalition formulation, to the organization of large markets, to problems of cost allocation, and to the study of games in which utility is not transferable.},
	urldate = {2023-06-27},
	publisher = {Cambridge University Press},
	editor = {Roth, Alvin E.},
	year = {1988},
	doi = {10.1017/CBO9780511528446},
	keywords = {Asymmetric Shapley values},
}

@book{roth_shapley_2005,
	address = {Cambridge},
	edition = {Digitally printed 1. paperback version},
	title = {The {Shapley} value: essays in honor of {Lloyd} {S}. {Shapley}},
	isbn = {978-0-521-36177-4 978-0-521-02133-3},
	shorttitle = {The {Shapley} value},
	language = {en},
	publisher = {Cambridge Univ. Press},
	editor = {Roth, Alvin E. and Shapley, Lloyd S.},
	year = {2005},
}

@misc{frye_asymmetric_2021,
	title = {Asymmetric {Shapley} values: incorporating causal knowledge into model-agnostic explainability},
	shorttitle = {Asymmetric {Shapley} values},
	url = {http://arxiv.org/abs/1910.06358},
	abstract = {Explaining AI systems is fundamental both to the development of high performing models and to the trust placed in them by their users. The Shapley framework for explainability has strength in its general applicability combined with its precise, rigorous foundation: it provides a common, model-agnostic language for AI explainability and uniquely satisfies a set of intuitive mathematical axioms. However, Shapley values are too restrictive in one significant regard: they ignore all causal structure in the data. We introduce a less restrictive framework, Asymmetric Shapley values (ASVs), which are rigorously founded on a set of axioms, applicable to any AI system, and flexible enough to incorporate any causal structure known to be respected by the data. We demonstrate that ASVs can (i) improve model explanations by incorporating causal information, (ii) provide an unambiguous test for unfair discrimination in model predictions, (iii) enable sequentially incremental explanations in time-series models, and (iv) support feature-selection studies without the need for model retraining.},
	urldate = {2023-06-27},
	publisher = {arXiv},
	author = {Frye, Christopher and Rowat, Colin and Feige, Ilya},
	month = dec,
	year = {2021},
	note = {arXiv:1910.06358 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{kokalj_bert_2021,
	address = {Online},
	title = {{BERT} meets {Shapley}: {Extending} {SHAP} {Explanations} to {Transformer}-based {Classifiers}},
	shorttitle = {{BERT} meets {Shapley}},
	url = {https://aclanthology.org/2021.hackashop-1.3},
	abstract = {Transformer-based neural networks offer very good classification performance across a wide range of domains, but do not provide explanations of their predictions. While several explanation methods, including SHAP, address the problem of interpreting deep learning models, they are not adapted to operate on state-of-the-art transformer-based neural networks such as BERT. Another shortcoming of these methods is that their visualization of explanations in the form of lists of most relevant words does not take into account the sequential and structurally dependent nature of text. This paper proposes the TransSHAP method that adapts SHAP to transformer models including BERT-based text classifiers. It advances SHAP visualizations by showing explanations in a sequential manner, assessed by human evaluators as competitive to state-of-the-art solutions.},
	urldate = {2023-06-27},
	booktitle = {Proceedings of the {EACL} {Hackashop} on {News} {Media} {Content} {Analysis} and {Automated} {Report} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Kokalj, Enja and Škrlj, Blaž and Lavrač, Nada and Pollak, Senja and Robnik-Šikonja, Marko},
	month = apr,
	year = {2021},
	pages = {16--21},
}

@article{rahman_deep_2020,
	title = {A deep learning framework for football match prediction},
	volume = {2},
	issn = {2523-3971},
	url = {https://doi.org/10.1007/s42452-019-1821-5},
	doi = {10.1007/s42452-019-1821-5},
	abstract = {An efficient framework is developed by deep neural networks (DNNs) and artificial neural network (ANNs) for predicting the outcomes of football matches. A dataset is used with the rankings, team performances, all previous international football match results and so on. ANN and DNN are used to explore and process the sporting data to generate prediction value. Datasets are divided into sections for training, validating and testing. By using the proposed DNN architecture, corresponding model performed excellently on predicting the FIFA world cup 2018 matches. This model had predicted 63.3\% matches accurately. However, this accuracy can be increased with proper datasets and more accurate information of the teams. The outcome of this hypothesis can be derived that deep learning may be used for successfully predicting the outcomes of football matches or any other sporting events. For more accurate performance of the prediction, prior and more information about each team, player and match is desirable.},
	language = {en},
	number = {2},
	urldate = {2023-06-21},
	journal = {SN Applied Sciences},
	author = {Rahman, Md. Ashiqur},
	month = jan,
	year = {2020},
	keywords = {Artificial neural networks, Deep learning, Deep neural networks, Football match prediction},
	pages = {165},
}

@article{de_oliveira_elementary_1963,
	title = {Some {Elementary} {Tests} for {Mixtures} of {Discrete} {Distribution}},
	url = {https://apps.dtic.mil/sti/citations/AD0405910},
	abstract = {The problems dealt with in this paper arose in the following context. It is known, in some paleontological problems, that the distribution of some countable (meristic) characteristics of neighboring biological species, isolated in well-defined geographical areas, have some fixed (or stable) distribution. In some cases, however, the analysis of the frequency polygon seemed to suggest the existence of a mixture of two populations and the test in 3) was devised for the purpose of deciding about the hypothesis of the mixture. After, some of the results were extended.},
	language = {en},
	urldate = {2023-06-16},
	journal = {Columbia University New York},
	author = {De Oliveira, Tiago},
	year = {1963},
	note = {Section: Technical Reports},
}

@article{bohning_note_1994,
	title = {A note on a test for {Poisson} overdispersion},
	volume = {81},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/81.2.418},
	doi = {10.1093/biomet/81.2.418},
	language = {en},
	number = {2},
	urldate = {2023-06-16},
	journal = {Biometrika},
	author = {Böhning, Dankmar},
	year = {1994},
	pages = {418--419},
}

@article{baksh_extension_2011,
	title = {An extension of an over-dispersion test for count data},
	volume = {55},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947310002161},
	doi = {10.1016/j.csda.2010.05.015},
	abstract = {While over-dispersion in capture–recapture studies is well known to lead to poor estimation of population size, current diagnostic tools to detect the presence of heterogeneity have not been specifically developed for capture–recapture studies. To address this, a simple and efficient method of testing for over-dispersion in zero-truncated count data is developed and evaluated. The proposed method generalizes an over-dispersion test previously suggested for un-truncated count data and may also be used for testing residual over-dispersion in zero-inflation data. Simulations suggest that the asymptotic distribution of the test statistic is standard normal and that this approximation is also reasonable for small sample sizes. The method is also shown to be more efficient than an existing test for over-dispersion adapted for the capture–recapture setting. Studies with zero-truncated and zero-inflated count data are used to illustrate the test procedures.},
	language = {en},
	number = {1},
	urldate = {2023-06-16},
	journal = {Computational Statistics \& Data Analysis},
	author = {Baksh, M. Fazil and Böhning, Dankmar and Lerdsuwansri, Rattana},
	month = jan,
	year = {2011},
	keywords = {Capture–recapture, Over-dispersion, Turing estimator, Zero-inflation, Zero-truncation},
	pages = {466--474},
}

@article{du_techniques_2019,
	title = {Techniques for interpretable machine learning},
	volume = {63},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/3359786},
	doi = {10.1145/3359786},
	abstract = {Uncovering the mysterious ways machine learning models make decisions.},
	number = {1},
	urldate = {2023-06-16},
	journal = {Communications of the ACM},
	author = {Du, Mengnan and Liu, Ninghao and Hu, Xia},
	year = {2019},
	pages = {68--77},
}

@misc{kirchenbauer_watermark_2023,
	title = {A {Watermark} for {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2301.10226},
	abstract = {Potential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient opensource algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of “green” tokens before a word is generated, and then softly promoting use of green tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an informationtheoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security.},
	language = {en},
	urldate = {2023-06-07},
	publisher = {arXiv},
	author = {Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom},
	month = jun,
	year = {2023},
	note = {arXiv:2301.10226 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{yun_are_2020,
	title = {Are {Transformers} universal approximators of sequence-to-sequence functions?},
	url = {http://arxiv.org/abs/1912.10077},
	abstract = {Despite the widespread adoption of Transformer models for NLP tasks, the expressive power of these models is not well-understood. In this paper, we establish that Transformer models are universal approximators of continuous permutation equivariant sequence-to-sequence functions with compact support, which is quite surprising given the amount of shared parameters in these models. Furthermore, using positional encodings, we circumvent the restriction of permutation equivariance, and show that Transformer models can universally approximate arbitrary continuous sequence-to-sequence functions on a compact domain. Interestingly, our proof techniques clearly highlight the different roles of the self-attention and the feed-forward layers in Transformers. In particular, we prove that ﬁxed width self-attention layers can compute contextual mappings of the input sequences, playing a key role in the universal approximation property of Transformers. Based on this insight from our analysis, we consider other simpler alternatives to selfattention layers and empirically evaluate them.},
	language = {en},
	urldate = {2023-06-06},
	publisher = {arXiv},
	author = {Yun, Chulhee and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank J. and Kumar, Sanjiv},
	month = feb,
	year = {2020},
	note = {arXiv:1912.10077 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{sutskever_sequence_2014,
	title = {Sequence to {Sequence} {Learning} with {Neural} {Networks}},
	url = {http://arxiv.org/abs/1409.3215},
	abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difﬁcult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a ﬁxed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT’14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM’s BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difﬁculty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM’s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
	language = {en},
	urldate = {2023-06-06},
	publisher = {arXiv},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	month = dec,
	year = {2014},
	note = {arXiv:1409.3215 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{state_reason_2023,
	title = {Reason to explain: {Interactive} contrastive explanations ({REASONX})},
	shorttitle = {Reason to explain},
	url = {http://arxiv.org/abs/2305.18143},
	abstract = {Many high-performing machine learning models are not interpretable. As they are increasingly used in decision scenarios that can critically affect individuals, it is necessary to develop tools to better understand their outputs. Popular explanation methods include contrastive explanations. However, they suffer several shortcomings, among others an insufficient incorporation of background knowledge, and a lack of interactivity. While (dialogue-like) interactivity is important to better communicate an explanation, background knowledge has the potential to significantly improve their quality, e.g., by adapting the explanation to the needs of the end-user. To close this gap, we present REASONX, an explanation tool based on Constraint Logic Programming (CLP). REASONX provides interactive contrastive explanations that can be augmented by background knowledge, and allows to operate under a setting of under-specified information, leading to increased flexibility in the provided explanations. REASONX computes factual and constrative decision rules, as well as closest constrative examples. It provides explanations for decision trees, which can be the ML models under analysis, or global/local surrogate models of any ML model. While the core part of REASONX is built on CLP, we also provide a program layer that allows to compute the explanations via Python, making the tool accessible to a wider audience. We illustrate the capability of REASONX on a synthetic data set, and on a a well-developed example in the credit domain. In both cases, we can show how REASONX can be flexibly used and tailored to the needs of the user.},
	urldate = {2023-06-04},
	publisher = {arXiv},
	author = {State, Laura and Ruggieri, Salvatore and Turini, Franco},
	month = may,
	year = {2023},
	note = {arXiv:2305.18143 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning, Computer Science - Symbolic Computation},
}

@misc{bubeck_sparks_2023,
	title = {Sparks of {Artificial} {General} {Intelligence}: {Early} experiments with {GPT}-4},
	shorttitle = {Sparks of {Artificial} {General} {Intelligence}},
	url = {http://arxiv.org/abs/2303.12712},
	abstract = {Artiﬁcial intelligence (AI) researchers have been developing and reﬁning large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4 [Ope23], was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT4 is part of a new cohort of LLMs (along with ChatGPT and Google’s PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and diﬃcult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4’s performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4’s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artiﬁcial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reﬂections on societal inﬂuences of the recent technological leap and future research directions.},
	language = {en},
	urldate = {2023-06-02},
	publisher = {arXiv},
	author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
	month = apr,
	year = {2023},
	note = {arXiv:2303.12712 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{sokol_limetree_2023,
	title = {{LIMEtree}: {Consistent} and {Faithful} {Surrogate} {Explanations} of {Multiple} {Classes}},
	shorttitle = {{LIMEtree}},
	url = {http://arxiv.org/abs/2005.01427},
	doi = {10.48550/arXiv.2005.01427},
	abstract = {Explainable machine learning provides tools to better understand predictive models and their decisions, but many such methods are limited to producing insights with respect to a single class. When generating explanations for several classes, reasoning over them to obtain a complete view may be difficult since they can present competing or contradictory evidence. To address this issue we introduce a novel paradigm of multi-class explanations. We outline the theory behind such techniques and propose a local surrogate model based on multi-output regression trees -- called LIMEtree -- which offers faithful and consistent explanations of multiple classes for individual predictions while being post-hoc, model-agnostic and data-universal. In addition to strong fidelity guarantees, our implementation supports (interactive) customisation of the explanatory insights and delivers a range of diverse explanation types, including counterfactual statements favoured in the literature. We evaluate our algorithm with a collection of quantitative experiments, a qualitative analysis based on explainability desiderata and a preliminary user study on an image classification task, comparing it to LIME. Our contributions demonstrate the benefits of multi-class explanations and wide-ranging advantages of our method across a diverse set scenarios.},
	urldate = {2023-05-31},
	publisher = {arXiv},
	author = {Sokol, Kacper and Flach, Peter},
	month = feb,
	year = {2023},
	note = {arXiv:2005.01427 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{montgomery_measuring_2000,
	title = {Measuring {Living} {Standards} with {Proxy} {Variables}},
	volume = {37},
	issn = {0070-3370},
	url = {https://www.jstor.org/stable/2648118},
	doi = {10.2307/2648118},
	abstract = {Very few demographic surveys in developing countries have gathered information on household incomes or consumption expenditures. Researchers interested in living standards therefore have had little alternative but to rely on simple proxy indicators. The properties of these proxies have not been analyzed systematically. We ask what hypotheses can be tested using proxies, and compare these indicators with consumption expenditures per adult, our preferred measure of living standards. We find that the proxies employed in much demographic research are very weak predictors of consumption per adult. Nevertheless, hypothesis tests based on proxies are likely to be powerful enough to warrant consideration.},
	number = {2},
	urldate = {2023-05-29},
	journal = {Demography},
	author = {Montgomery, Mark R. and Gragnolati, Michele and Burke, Kathleen A. and Paredes, Edmundo},
	year = {2000},
	note = {Publisher: Springer},
	pages = {155--174},
}

@book{wooldridge_introductory_2015,
	title = {Introductory {Econometrics}: {A} {Modern} {Approach}},
	isbn = {978-1-305-44638-0},
	shorttitle = {Introductory {Econometrics}},
	abstract = {Discover how empirical researchers today actually think about and apply econometric methods with the practical, professional approach in Wooldridge's INTRODUCTORY ECONOMETRICS: A MODERN APPROACH, 6E. Unlike traditional books, this unique presentation demonstrates how econometrics has moved beyond just a set of abstract tools to become genuinely useful for answering questions in business, policy evaluation, and forecasting environments. INTRODUCTORY ECONOMETRICS is organized around the type of data being analyzed with a systematic approach that only introduces assumptions as they are needed. This makes the material easier to understand and, ultimately, leads to better econometric practices. Packed with timely, relevant applications, the book introduces the latest emerging developments in the field. Gain a full understanding of the impact of econometrics in real practice today with the insights and applications found only in INTRODUCTORY ECONOMETRICS: A MODERN APPROACH, 6E.Important Notice: Media content referenced within the product description or the product text may not be available in the ebook version.},
	language = {en},
	publisher = {Cengage Learning},
	author = {Wooldridge, Jeffrey M.},
	month = sep,
	year = {2015},
	note = {Google-Books-ID: wUF4BwAAQBAJ},
	keywords = {Business \& Economics / Econometrics},
}

@article{wooldridge_estimating_2009,
	title = {On estimating firm-level production functions using proxy variables to control for unobservables},
	volume = {104},
	issn = {0165-1765},
	url = {https://www.sciencedirect.com/science/article/pii/S0165176509001487},
	doi = {10.1016/j.econlet.2009.04.026},
	abstract = {In the common case where polynomial approximations are used for unknown functions, I show how proxy variable approaches to controlling for unobserved productivity, proposed by Olley and Pakes [Olley, S. and Pakes, A., 1996. The dynamics of productivity in the telecommunications equipment industry. Econometrica 64, 1263–1298.] and Levinsohn and Petrin (Levinsohn, J. and Petrin, A., 2003. Estimating production functions using inputs to control for unobservables. Review of Economic Studies 70, 317–341.], can be implemented by specifying different instruments for different equations and applying generalized method of moments. Studying the parameters within a two-equation system clarifies some key identification issues, and joint estimation of the parameters leads to simple inference and more efficient estimators.},
	language = {en},
	number = {3},
	urldate = {2023-05-29},
	journal = {Economics Letters},
	author = {Wooldridge, Jeffrey M.},
	month = sep,
	year = {2009},
	keywords = {Generalized method of moments, Panel data, Production function, Proxy variables},
	pages = {112--114},
}

@misc{mitchell_gputreeshap_2022,
	title = {{GPUTreeShap}: {Massively} {Parallel} {Exact} {Calculation} of {SHAP} {Scores} for {Tree} {Ensembles}},
	shorttitle = {{GPUTreeShap}},
	url = {http://arxiv.org/abs/2010.13972},
	doi = {10.48550/arXiv.2010.13972},
	abstract = {SHAP (SHapley Additive exPlanation) values provide a game theoretic interpretation of the predictions of machine learning models based on Shapley values. While exact calculation of SHAP values is computationally intractable in general, a recursive polynomial-time algorithm called TreeShap is available for decision tree models. However, despite its polynomial time complexity, TreeShap can become a significant bottleneck in practical machine learning pipelines when applied to large decision tree ensembles. Unfortunately, the complicated TreeShap algorithm is difficult to map to hardware accelerators such as GPUs. In this work, we present GPUTreeShap, a reformulated TreeShap algorithm suitable for massively parallel computation on graphics processing units. Our approach first preprocesses each decision tree to isolate variable sized sub-problems from the original recursive algorithm, then solves a bin packing problem, and finally maps sub-problems to single-instruction, multiple-thread (SIMT) tasks for parallel execution with specialised hardware instructions. With a single NVIDIA Tesla V100-32 GPU, we achieve speedups of up to 19x for SHAP values, and speedups of up to 340x for SHAP interaction values, over a state-of-the-art multi-core CPU implementation executed on two 20-core Xeon E5-2698 v4 2.2 GHz CPUs. We also experiment with multi-GPU computing using eight V100 GPUs, demonstrating throughput of 1.2M rows per second -- equivalent CPU-based performance is estimated to require 6850 CPU cores.},
	urldate = {2023-05-24},
	publisher = {arXiv},
	author = {Mitchell, Rory and Frank, Eibe and Holmes, Geoffrey},
	month = feb,
	year = {2022},
	note = {arXiv:2010.13972 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@misc{gyevnar_get_2023,
	title = {Get {Your} {Act} {Together}: {A} {Comparative} {View} on {Transparency} in the {AI} {Act} and {Technology}},
	shorttitle = {Get {Your} {Act} {Together}},
	url = {http://arxiv.org/abs/2302.10766},
	doi = {10.48550/arXiv.2302.10766},
	abstract = {The European Union has proposed the Artificial Intelligence Act which introduces a proportional risk-based approach to AI regulation including detailed requirements for transparency and explainability. Many of these requirements may be addressed in practice by the field of explainable AI (XAI), however, there are fundamental differences between XAI and the Act regarding what transparency and explainability are. These basic definitions should be aligned to assure that regulation continually translates into appropriate technical practices. To facilitate this alignment, we first give an overview of how XAI and European regulation view basic definitions of transparency with a particular focus on the AI Act and the related General Data Protection Regulation (GDPR). We then present a comparison of XAI and regulatory approaches to identify the main points that would improve alignment between the fields: clarification of the scope of transparency, the legal status of XAI, oversight issues in conformity assessments, and dataset-related transparency.},
	urldate = {2023-05-23},
	publisher = {arXiv},
	author = {Gyevnar, Balint and Ferguson, Nick and Schafer, Burkhard},
	month = may,
	year = {2023},
	note = {arXiv:2302.10766 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, I.2.0},
}

@misc{bommer_finding_2023,
	title = {Finding the right {XAI} method -- {A} {Guide} for the {Evaluation} and {Ranking} of {Explainable} {AI} {Methods} in {Climate} {Science}},
	url = {http://arxiv.org/abs/2303.00652},
	doi = {10.48550/arXiv.2303.00652},
	abstract = {Explainable artificial intelligence (XAI) methods shed light on the predictions of deep neural networks (DNNs). Several different approaches exist and have partly already been successfully applied in climate science. However, the often missing ground truth explanations complicate their evaluation and validation, subsequently compounding the choice of the XAI method. Therefore, in this work, we introduce XAI evaluation in the context of climate research and assess different desired explanation properties, namely, robustness, faithfulness, randomization, complexity, and localization. To this end we build upon previous work and train a multi-layer perceptron (MLP) and a convolutional neural network (CNN) to predict the decade based on annual-mean temperature maps. Next, multiple local XAI methods are applied and their performance is quantified for each evaluation property and compared against a baseline test. Independent of the network type, we find that the XAI methods Integrated Gradients, Layer-wise relevance propagation, and InputGradients exhibit considerable robustness, faithfulness, and complexity while sacrificing randomization. The opposite is true for Gradient, SmoothGrad, NoiseGrad, and FusionGrad. Notably, explanations using input perturbations, such as SmoothGrad and Integrated Gradients, do not improve robustness and faithfulness, contrary to previous claims. Overall, our experiments offer a comprehensive overview of different properties of explanation methods in the climate science context and supports users in the selection of a suitable XAI method.},
	urldate = {2023-05-23},
	publisher = {arXiv},
	author = {Bommer, Philine and Kretschmer, Marlene and Hedström, Anna and Bareeva, Dilyara and Höhne, Marina M.-C.},
	month = mar,
	year = {2023},
	note = {arXiv:2303.00652 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{marcinkevics_interpretability_2023,
	title = {Interpretability and {Explainability}: {A} {Machine} {Learning} {Zoo} {Mini}-tour},
	shorttitle = {Interpretability and {Explainability}},
	url = {http://arxiv.org/abs/2012.01805},
	doi = {10.48550/arXiv.2012.01805},
	abstract = {In this review, we examine the problem of designing interpretable and explainable machine learning models. Interpretability and explainability lie at the core of many machine learning and statistical applications in medicine, economics, law, and natural sciences. Although interpretability and explainability have escaped a clear universal definition, many techniques motivated by these properties have been developed over the recent 30 years with the focus currently shifting towards deep learning methods. In this review, we emphasise the divide between interpretability and explainability and illustrate these two different research directions with concrete examples of the state-of-the-art. The review is intended for a general machine learning audience with interest in exploring the problems of interpretation and explanation beyond logistic regression or random forest variable importance. This work is not an exhaustive literature survey, but rather a primer focusing selectively on certain lines of research which the authors found interesting or informative.},
	urldate = {2023-05-23},
	publisher = {arXiv},
	author = {Marcinkevičs, Ričards and Vogt, Julia E.},
	month = mar,
	year = {2023},
	note = {arXiv:2012.01805 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@book{sellers_conway-maxwell-poisson_2022,
	address = {Cambridge, United Kingdom ; New York, NY, USA},
	edition = {First edition},
	series = {Institute of {Mathematical} {Statistics} monographs},
	title = {The {Conway}-{Maxwell}-{Poisson} distribution},
	isbn = {978-1-108-64643-7},
	abstract = {"This is the first comprehensive introduction to the Conway-Maxwell-Poisson distribution and its contributions in statistical theory and computing in R, including its uses in count data modelling. An essential reference for academics in statistics and data science, as well as quantitative researchers and data analysts in applied disciplines"--},
	publisher = {Cambridge University Press},
	author = {Sellers, Kimberly F.},
	year = {2022},
	keywords = {Distribution (Probability theory), R (Computer program language)},
}

@book{mccullagh_generalized_2019,
	address = {New York},
	edition = {2},
	title = {Generalized {Linear} {Models}},
	isbn = {978-0-203-75373-6},
	url = {https://doi.org/10.1201/9780203753736},
	abstract = {The success of the first edition of Generalized Linear Models led to the updated Second Edition, which continues to provide a definitive unified, treatment of methods for the analysis of diverse types of data. Today, it remains popular for its clarity, richness of content and direct relevance to agricultural, biological, health, engineering, and ot},
	publisher = {Routledge},
	author = {McCullagh, P. and Nelder, J. A.},
	month = jan,
	year = {2019},
	doi = {10.1201/9780203753736},
}

@misc{fryer_shapley_2021,
	title = {Shapley values for feature selection: {The} good, the bad, and the axioms},
	shorttitle = {Shapley values for feature selection},
	url = {http://arxiv.org/abs/2102.10936},
	doi = {10.48550/arXiv.2102.10936},
	abstract = {The Shapley value has become popular in the Explainable AI (XAI) literature, thanks, to a large extent, to a solid theoretical foundation, including four "favourable and fair" axioms for attribution in transferable utility games. The Shapley value is provably the only solution concept satisfying these axioms. In this paper, we introduce the Shapley value and draw attention to its recent uses as a feature selection tool. We call into question this use of the Shapley value, using simple, abstract "toy" counterexamples to illustrate that the axioms may work against the goals of feature selection. From this, we develop a number of insights that are then investigated in concrete simulation settings, with a variety of Shapley value formulations, including SHapley Additive exPlanations (SHAP) and Shapley Additive Global importancE (SAGE).},
	urldate = {2023-05-22},
	publisher = {arXiv},
	author = {Fryer, Daniel and Strümke, Inga and Nguyen, Hien},
	month = feb,
	year = {2021},
	note = {arXiv:2102.10936 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{groll_prediction_2020,
	title = {Prediction of the 2019 {IHF} {World} {Men}’s {Handball} {Championship} – {A} sparse {Gaussian} approximation model},
	volume = {6},
	issn = {2215-020X},
	url = {https://content.iospress.com/articles/journal-of-sports-analytics/jsa200384},
	doi = {10.3233/JSA-200384},
	abstract = {In this work, we compare several different modeling approaches for count data applied to the scores of handball matches with regard to their predictive performances based on all matches from the four previous IHF World Men’s Handball Championships 2},
	language = {en},
	number = {3},
	urldate = {2023-05-21},
	journal = {Journal of Sports Analytics},
	author = {Groll, Andreas and Heiner, Jonas and Schauberger, Gunther and Uhrmeister, Jörn},
	month = jan,
	year = {2020},
	note = {Publisher: IOS Press},
	keywords = {handball},
	pages = {187--197},
}

@misc{peng_xai_2022,
	title = {{XAI} {Beyond} {Classification}: {Interpretable} {Neural} {Clustering}},
	shorttitle = {{XAI} {Beyond} {Classification}},
	url = {http://arxiv.org/abs/1808.07292},
	doi = {10.48550/arXiv.1808.07292},
	abstract = {In this paper, we study two challenging problems in explainable AI (XAI) and data clustering. The first is how to directly design a neural network with inherent interpretability, rather than giving post-hoc explanations of a black-box model. The second is implementing discrete \$k\$-means with a differentiable neural network that embraces the advantages of parallel computing, online clustering, and clustering-favorable representation learning. To address these two challenges, we design a novel neural network, which is a differentiable reformulation of the vanilla \$k\$-means, called inTerpretable nEuraL cLustering (TELL). Our contributions are threefold. First, to the best of our knowledge, most existing XAI works focus on supervised learning paradigms. This work is one of the few XAI studies on unsupervised learning, in particular, data clustering. Second, TELL is an interpretable, or the so-called intrinsically explainable and transparent model. In contrast, most existing XAI studies resort to various means for understanding a black-box model with post-hoc explanations. Third, from the view of data clustering, TELL possesses many properties highly desired by \$k\$-means, including but not limited to online clustering, plug-and-play module, parallel computing, and provable convergence. Extensive experiments show that our method achieves superior performance comparing with 14 clustering approaches on three challenging data sets. The source code could be accessed at {\textbackslash}url\{www.pengxi.me\}.},
	urldate = {2023-05-22},
	publisher = {arXiv},
	author = {Peng, Xi and Li, Yunnan and Tsang, Ivor W. and Zhu, Hongyuan and Lv, Jiancheng and Zhou, Joey Tianyi},
	month = apr,
	year = {2022},
	note = {arXiv:1808.07292 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{kwon_weightedshap_2022,
	title = {{WeightedSHAP}: analyzing and improving {Shapley} based feature attributions},
	shorttitle = {{WeightedSHAP}},
	url = {http://arxiv.org/abs/2209.13429},
	doi = {10.48550/arXiv.2209.13429},
	abstract = {Shapley value is a popular approach for measuring the influence of individual features. While Shapley feature attribution is built upon desiderata from game theory, some of its constraints may be less natural in certain machine learning settings, leading to unintuitive model interpretation. In particular, the Shapley value uses the same weight for all marginal contributions -- i.e. it gives the same importance when a large number of other features are given versus when a small number of other features are given. This property can be problematic if larger feature sets are more or less informative than smaller feature sets. Our work performs a rigorous analysis of the potential limitations of Shapley feature attribution. We identify simple settings where the Shapley value is mathematically suboptimal by assigning larger attributions for less influential features. Motivated by this observation, we propose WeightedSHAP, which generalizes the Shapley value and learns which marginal contributions to focus directly from data. On several real-world datasets, we demonstrate that the influential features identified by WeightedSHAP are better able to recapitulate the model's predictions compared to the features identified by the Shapley value.},
	urldate = {2023-05-22},
	publisher = {arXiv},
	author = {Kwon, Yongchan and Zou, James},
	month = sep,
	year = {2022},
	note = {arXiv:2209.13429 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{ouattara_scalable_2021,
	title = {Scalable {Econometrics} on {Big} {Data} -- {The} {Logistic} {Regression} on {Spark}},
	copyright = {All rights reserved},
	url = {http://arxiv.org/abs/2106.10341},
	abstract = {Extra-large datasets are becoming increasingly accessible, and computing tools designed to handle huge amount of data efficiently are democratizing rapidly. However, conventional statistical and econometric tools are still lacking fluency when dealing with such large datasets. This paper dives into econometrics on big datasets, specifically focusing on the logistic regression on Spark. We review the robustness of the functions available in Spark to fit logistic regression and introduce a package that we developed in PySpark which returns the statistical summary of the logistic regression, necessary for statistical inference.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Ouattara, Aurélien and Bulté, Matthieu and Lin, Wan-Ju and Scholl, Philipp and Veit, Benedikt and Ziakas, Christos and Felice, Florian and Virlogeux, Julien and Dikos, George},
	month = jun,
	year = {2021},
	note = {Number: arXiv:2106.10341
arXiv:2106.10341 [econ, stat]},
	keywords = {Economics - Econometrics, Read, Statistics - Computation},
}

@book{wooldridge_econometric_2010,
	address = {Cambridge, MA, USA},
	edition = {2},
	title = {Econometric {Analysis} of {Cross} {Section} and {Panel} {Data}},
	isbn = {978-0-262-23258-6},
	url = {https://mitpress.mit.edu/books/econometric-analysis-cross-section-and-panel-data-second-edition},
	abstract = {The second edition of a comprehensive state-of-the-art graduate level text on microeconometric methods, substantially revised and updated.},
	language = {en},
	publisher = {MIT Press},
	author = {Wooldridge, Jeffrey M.},
	month = oct,
	year = {2010},
}

@incollection{reutlinger_ceteris_2013,
	title = {Ceteris {Paribus} {Laws}},
	url = {https://plato.stanford.edu/entries/ceteris-paribus/},
	booktitle = {Stanford {Encyclopedia} of {Philosophy}},
	publisher = {Center for the Study of Language and Information, Stanford University},
	author = {Reutlinger, Alexander and Schurz, Gerhard and Hüttemann, Andreas and Jaag, Siegfried},
	editor = {Zalta, Edward},
	month = mar,
	year = {2013},
}

@inproceedings{huang_statistical-feature-based_2009,
	title = {A statistical-feature-based approach to internet traffic classification using {Machine} {Learning}},
	doi = {10.1109/ICUMT.2009.5345539},
	abstract = {This Internet traffic classification using Machine Learning is an emerging research field since 1990's, and now it is widely used in numerous network activities. The classification technique focuses on modeling attributes and features of data flows to accomplish the identification of applications. In the paper we design and implement the classification model based on header-derived flow statistical features. Compared with the traditional methods, the model designed here, which is totally insensitive to port numbers and contents of payload on application level, overcomes difficulty in operation caused by unreliable port numbers and complexity of payload interpretation. Rather than relatively complex ML algorithms or even in mixture, supervised k-Nearest Neighbor estimator is adopted for the sake of computational efficiency, along with the effective and easy-to-calculate statistical features selected according to the operational background. Our results indicate that about 90\% accuracy on per-flow classification can be achieved, which is a vast improvement over traditional techniques that achieve 50-70\%.},
	booktitle = {2009 {International} {Conference} on {Ultra} {Modern} {Telecommunications} \& {Workshops}},
	author = {Huang, Shijun and Chen, Kai and Liu, Chao and Liang, Alei and Guan, Haibing},
	month = oct,
	year = {2009},
	note = {ISSN: 2157-023X},
	keywords = {Algorithm design and analysis, Classification algorithms, Computational efficiency, Cryptography, IP networks, Machine Learning, Machine learning, Payloads, Read, StatML, Telecommunication traffic, Testing, Web and internet services, flow features, k-Nearest Neighbor, traffic classification},
	pages = {1--6},
}

@inproceedings{xuan_steganalysis_2005,
	address = {Berlin, Heidelberg},
	title = {Steganalysis {Based} on {Multiple} {Features} {Formed} by {Statistical} {Moments} of {Wavelet} {Characteristic} {Functions}},
	isbn = {978-3-540-31481-3},
	doi = {10.1007/11558859_20},
	abstract = {In this paper, a steganalysis scheme based on multiple features formed by statistical moments of wavelet characteristic functions is proposed. Our theoretical analysis has pointed out that the defined n-th statistical moment of a wavelet characteristic function is related to the n-th derivative of the corresponding wavelet histogram, and hence is sensitive to data embedding. The selection of the first three moments of the characteristic functions of wavelet subbands of the three-level Haar wavelet decomposition as well as the test image has resulted in total 39 features for steganalysis. The effectiveness of the proposed system has been demonstrated by extensive experimental investigation. The detection rate for Cox et al.’s non-blind spread spectrum (SS) data hiding method, Piva et al.’s blind SS method, Huang and Shi’s 8×8 block SS method, a generic LSB method (as embedding capacity being 0.3 bpp), and a generic QIM method (as embedding capacity being 0.1 bpp) are all above 90\% over all of the 1096 images in the CorelDraw image database using the Bayes classifier. Furthermore, when these five typical data hiding methods are jointly considered for steganalysis, i.e., when the proposed steganalysis scheme is first trained sequentially for each of these five methods, and is then tested blindly for stego-images generated by all of these methods, the success classification rate is 86\%, thus pointing out a new promising approach to general blind steganalysis. The detection results of steganalysis on Jsteg, Outguess and F5 have further demonstrated the effectiveness of the proposed steganalysis scheme.},
	language = {en},
	booktitle = {Information {Hiding}},
	publisher = {Springer},
	author = {Xuan, Guorong and Shi, Yun Q. and Gao, Jianjiong and Zou, Dekun and Yang, Chengyun and Zhang, Zhenping and Chai, Peiqi and Chen, Chunhua and Chen, Wen},
	editor = {Barni, Mauro and Herrera-Joancomartí, Jordi and Katzenbeisser, Stefan and Pérez-González, Fernando},
	year = {2005},
	keywords = {Read, StatML},
	pages = {262--277},
}

@article{abu-romoh_automatic_2018,
	title = {Automatic {Modulation} {Classification} {Using} {Moments} and {Likelihood} {Maximization}},
	volume = {22},
	issn = {1558-2558},
	doi = {10.1109/LCOMM.2018.2806489},
	abstract = {Motivated by the fact that moments of the received signal are easy to compute and can provide a simple way to automatically classify the modulation of the transmitted signal, we propose a hybrid method for automatic modulation classification that lies in the intersection between likelihood-based and feature-based classifiers. Specifically, the proposed method relies on statistical moments along with a maximum likelihood engine. We show that the proposed method offers a good trade-off between classification accuracy and complexity relative to the maximum likelihood classifier. Furthermore, our classifier outperforms state-of-the-art machine learning classifiers, such as genetic programming-based K-nearest neighbor classifiers, the linear support vector machine classifier and the fold-based Kolmogorov-Smirnov algorithm.},
	number = {5},
	journal = {IEEE Communications Letters},
	author = {Abu-Romoh, Mohannad and Aboutaleb, Ahmed and Rezki, Zouheir},
	month = may,
	year = {2018},
	note = {Number: 5},
	keywords = {Automatic modulation classification, Feature extraction, Modulation, Probability density function, Read, Receivers, Signal to noise ratio, StatML, Support vector machines, genetic programming, machine learning, moments-based classification, support vector machines},
	pages = {938--941},
}

@article{borith_prediction_2020,
	title = {Prediction of {Machine} {Inactivation} {Status} {Using} {Statistical} {Feature} {Extraction} and {Machine} {Learning}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/10/21/7413},
	doi = {10.3390/app10217413},
	abstract = {In modern manufacturing, the detection and prediction of machine anomalies, i.e., the inactive state of the machine during operation, is an important issue. Accurate inactive state detection models for factory machines can result in increased productivity. Moreover, they can guide engineers in implementing appropriate maintenance actions, which can prevent catastrophic failures and minimize economic losses. In this paper, we present a novel two-step data-driven method for the non-active detection of industry machines. First, we propose a feature extraction approach that aims to better distinguish the pattern of the active state and non-active state of the machine by multiple statistical analyses, such as reliability, time-domain, and frequency-domain analyses. Next, we construct a method to detect the active and non-active status of an industrial machine by applying various machine learning methods. The performance evaluation with a real-world dataset from the automobile part manufacturer demonstrates the proposed method achieves high accuracy.},
	language = {en},
	number = {21},
	urldate = {2022-06-01},
	journal = {Applied Sciences},
	author = {Borith, Taing and Bakhit, Sadirbaev and Nasridinov, Aziz and Yoo, Kwan-Hee},
	month = jan,
	year = {2020},
	note = {Number: 21},
	keywords = {StatML, Unread, machine learning, machine non-active state, statistical feature extraction},
	pages = {7413},
}

@inproceedings{soranamageswari_statistical_2010,
	title = {Statistical {Feature} {Extraction} for {Classification} of {Image} {Spam} {Using} {Artificial} {Neural} {Networks}},
	doi = {10.1109/ICMLC.2010.72},
	abstract = {When the usages of electronic mail continue, unsolicited bulk email also continues to grow. These unsolicited bulk emails occupies server storage space and consumes large amount of network bandwidth. To overcome this serious problem, Anti-spam filters become a common component of internet security. Recently, Image spamming is a new kind of method of email spamming in which the text is embedded in image or picture files. Identifying and preventing spam is one of the top challenges in the internet world. Many approaches for identifying image spam have been established in literature. The artificial neural network is an effective classification method for solving feature extraction problems. In this paper we present an experimental system for the classification of image spam by considering statistical image feature histogram and mean value of an block of image. A comparative study of image classification based on color histogram and mean value is presented in this paper. The experimental result shows the performance of the proposed system and it achieves best results with minimum false positive.},
	booktitle = {2010 {Second} {International} {Conference} on {Machine} {Learning} and {Computing}},
	author = {Soranamageswari, M. and Meena, C.},
	month = feb,
	year = {2010},
	keywords = {Artificial neural networks, Back Propagation Neural Networks, Bandwidth, Electronic mail, Feature Extraction, Feature extraction, Histogram, Histograms, Image Spam, Information filtering, Internet, Machine Learning, Network servers, Read, StatML, Supervised Learning, Unsolicited electronic mail, Web server},
	pages = {101--105},
}

@book{cameron_microeconometrics_2005,
	title = {Microeconometrics: {Methods} and {Applications}},
	isbn = {978-0-521-84805-3},
	shorttitle = {Microeconometrics},
	url = {https://www.cambridge.org/highereducation/books/microeconometrics/982158DE989697607C858068ED05C7B1},
	abstract = {This book provides the most comprehensive treatment to date of microeconometrics, the analysis of individual-level data on the economic behavior of individuals or firms using regression methods for cross section and panel data. The book is oriented to the practitioner. A basic understanding of the linear regression model with matrix algebra is assumed. The text can be used for a microeconometrics course, typically a second-year economics PhD course; for data-oriented applied microeconometrics field courses; and as a reference work for graduate students and applied researchers who wish to fill in gaps in their toolkit. Distinguishing features of the book include emphasis on nonlinear models and robust inference, simulation-based estimation, and problems of complex survey data. The book makes frequent use of numerical examples based on generated data to illustrate the key models and methods. More substantially, it systematically integrates into the text empirical illustrations based on seven large and exceptionally rich data sets.},
	language = {en},
	urldate = {2022-06-01},
	author = {Cameron, A. Colin and Trivedi, Pravin K.},
	month = may,
	year = {2005},
	doi = {10.1017/CBO9780511811241},
}

@misc{janssen_ultra-marginal_2022,
	title = {Ultra-marginal {Feature} {Importance}},
	url = {http://arxiv.org/abs/2204.09938},
	doi = {10.48550/arXiv.2204.09938},
	abstract = {Scientists frequently prioritize learning from data rather than training the best possible model; however, research in machine learning often prioritizes the latter. Marginal feature importance methods, such as marginal contribution feature importance (MCI), attempt to break this trend by providing a useful framework for quantifying the relationships in data in an interpretable fashion. In this work, we generalize the framework of MCI while aiming to improve performance and runtime by introducing ultra-marginal feature importance (UMFI). To do so, we prove that UMFI can be computed directly by applying preprocessing methods from the AI fairness literature to remove dependencies in the feature set. We show on real and simulated data that UMFI performs at least as well as MCI, with significantly better performance in the presence of correlated interactions and unrelated features, while substantially reducing the exponential runtime of MCI to super-linear.},
	urldate = {2022-06-14},
	publisher = {arXiv},
	author = {Janssen, Joseph and Guan, Vincent},
	month = jun,
	year = {2022},
	note = {arXiv:2204.09938 [cs, math, stat]
version: 2},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Interpretable ML, Statistics - Applications, Statistics - Machine Learning},
}

@misc{ribeiro_why_2016,
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	url = {http://arxiv.org/abs/1602.04938},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = aug,
	year = {2016},
	note = {Number: arXiv:1602.04938
arXiv:1602.04938 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Interpretable ML, Statistics - Machine Learning, Unread},
}

@article{cohen_feature_nodate,
	title = {Feature {Selection} {Based} on the {Shapley} {Value}},
	url = {http://www.cs.columbia.edu/~scohen/ijcai05features.pdf},
	abstract = {We present and study the Contribution-Selection algorithm (CSA), a novel algorithm for feature selection. The algorithm is based on the Multiperturbation Shapley Analysis, a framework which relies on game theory to estimate usefulness. The algorithm iteratively estimates the usefulness of features and selects them accordingly, using either forward selection or backward elimination. Empirical comparison with several other existing feature selection methods shows that the backward eliminatination variant of CSA leads to the most accurate classification results on an array of datasets.},
	author = {Cohen, Shay},
	keywords = {Interpretable ML, Shapley, Unread},
}

@misc{cho_learning_2014,
	title = {Learning {Phrase} {Representations} using {RNN} {Encoder}-{Decoder} for {Statistical} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1406.1078},
	abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	month = sep,
	year = {2014},
	note = {Number: arXiv:1406.1078
arXiv:1406.1078 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, Unread},
}

@misc{cho_properties_2014,
	title = {On the {Properties} of {Neural} {Machine} {Translation}: {Encoder}-{Decoder} {Approaches}},
	shorttitle = {On the {Properties} of {Neural} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1409.1259},
	abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
	month = oct,
	year = {2014},
	note = {Number: arXiv:1409.1259
arXiv:1409.1259 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Statistics - Machine Learning, Unread},
}

@inproceedings{guha_robust_2016,
	title = {Robust {Random} {Cut} {Forest} {Based} {Anomaly} {Detection} on {Streams}},
	url = {https://proceedings.mlr.press/v48/guha16.html},
	abstract = {In this paper we focus on the anomaly detection problem for dynamic data streams through the lens of random cut forests. We investigate a robust random cut data structure that can be used as a sketch or synopsis of the input stream. We provide a plausible definition of non-parametric anomalies based on the influence of an unseen point on the remainder of the data, i.e., the externality imposed by that point. We show how the sketch can be efficiently updated in a dynamic data stream. We demonstrate the viability of the algorithm on publicly available real data.},
	language = {en},
	urldate = {2022-05-31},
	booktitle = {Proceedings of {The} 33rd {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Guha, Sudipto and Mishra, Nina and Roy, Gourav and Schrijvers, Okke},
	month = jun,
	year = {2016},
	note = {ISSN: 1938-7228},
	keywords = {Unread},
	pages = {2712--2721},
}

@misc{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {Number: arXiv:1706.03762
arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Unread},
}

@article{han_low_2017,
	title = {Low {Complexity} {Automatic} {Modulation} {Classification} {Based} on {Order}-{Statistics}},
	volume = {16},
	issn = {1558-2248},
	doi = {10.1109/TWC.2016.2623716},
	abstract = {In this paper, we propose three automatic modulation classification classifiers based on order-statistics and reduced order-statistics, where the order-statistics are the random variables sorted by ascending order and the reduced order-statistics represent a subset of the original order-statistics. Specifically, the linear support vector machine classifier applies the linear combination of the order-statistics of the received signals, while the approximate maximum likelihood and the backpropagation neural networks (BPNNs) classifier resort to the reduced order-statistics to decrease the computational complexity. Moreover, BPNN is applicable for modulation classification both in known and unknown channel scenarios. It is shown that in the known channel scenario, the proposed classifiers provide a good tradeoff between performance and computational complexity, while in the unknown channel scenario, the proposed BPNN classifier outperforms the expectation maximization classifier in terms of both classification performance and computational complexity. Simulations results are provided to evaluate the proposed classifiers.},
	number = {1},
	journal = {IEEE Transactions on Wireless Communications},
	author = {Han, Lubing and Gao, Feifei and Li, Zan and Dobre, Octavia A.},
	month = jan,
	year = {2017},
	note = {Number: 1},
	keywords = {Automatic modulation classification, Computational complexity, Neural networks, Phase shift keying, Probability density function, Read, StatML, Wireless communication, backpropagation neural networks, linear support vector machine, machine learning, order-statistics},
	pages = {400--411},
}

@article{aslam_automatic_2012,
	title = {Automatic {Modulation} {Classification} {Using} {Combination} of {Genetic} {Programming} and {KNN}},
	volume = {11},
	issn = {1558-2248},
	doi = {10.1109/TWC.2012.060412.110460},
	abstract = {Automatic Modulation Classification (AMC) is an intermediate step between signal detection and demodulation. It is a very important process for a receiver that has no, or limited, knowledge of received signals. It is important for many areas such as spectrum management, interference identification and for various other civilian and military applications. This paper explores the use of Genetic Programming (GP) in combination with K-nearest neighbor (KNN) for AMC. KNN has been used to evaluate fitness of GP individuals during the training phase. Additionally, in the testing phase, KNN has been used for deducing the classification performance of the best individual produced by GP. Four modulation types are considered here: BPSK, QPSK, QAM16 and QAM64. Cumulants have been used as input features for GP. The classification process has been divided into two-stages for improving the classification accuracy. Simulation results demonstrate that the proposed method provides better classification performance compared to other recent methods.},
	number = {8},
	journal = {IEEE Transactions on Wireless Communications},
	author = {Aslam, Muhammad Waqar and Zhu, Zhechen and Nandi, Asoke Kumar},
	month = aug,
	year = {2012},
	note = {Number: 8},
	keywords = {Automatic modulation classification, Binary phase shift keying, Classification using genetic programming, Feature extraction, Genetic programming, Higher order cumulants, K-nearest neighbor, Read, StatML, Training},
	pages = {2742--2750},
}

@article{mazhar_remaining_2007,
	title = {Remaining life estimation of used components in consumer products: {Life} cycle data analysis by {Weibull} and artificial neural networks},
	volume = {25},
	issn = {1873-1317},
	shorttitle = {Remaining life estimation of used components in consumer products},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1016/j.jom.2007.01.021},
	doi = {10.1016/j.jom.2007.01.021},
	abstract = {Environmental awareness and legislative pressures have made manufacturers responsible for the take-back and end-of-life treatment of their products. To competitively exploit these products, one option is to incorporate used components in “new” or remanufactured products. However, this option is partly limited by a firm's ability to assess the reliability of used components. A comprehensive two-step approach is proposed. The first stage phase statistically analyzes the behavior of components for reuse. A well-known reliability assessment method, the Weibull analysis, is applied to the time-to-failure data to assess the mean life of components. In the second phase, the degradation and condition monitoring data are analyzed by developing an artificial neural network (ANN) model. The advantages of this approach over traditional approaches employing multiple regression analysis are highlighted with empirical data from a consumer product. Finally, the Weibull analysis and the ANN model are then integrated to assess the remaining useful life of components for reuse. This is a critical advance in sustainable management of supply chains since it allows for a better understanding of not only service requirements of product, but the remaining life in a product and hence its suitability for reuse or remanufacture. Future work should assess: (1) reduction in downtime of process equipment through the implementation of this technique as a means to better manage preventative maintenance; (2) reduce field failure of remanufactured product; (3) selling-service strategy through implementation of the proposed methodology.},
	language = {en},
	number = {6},
	urldate = {2022-06-21},
	journal = {Journal of Operations Management},
	author = {Mazhar, M.i. and Kara, S. and Kaebernick, H.},
	year = {2007},
	note = {Number: 6},
	keywords = {Reliability, Remaining life, Reuse, StatML, Unread},
	pages = {1184--1193},
}

@misc{dubey_scalable_2022,
	title = {Scalable {Interpretability} via {Polynomials}},
	url = {http://arxiv.org/abs/2205.14108},
	doi = {10.48550/arXiv.2205.14108},
	abstract = {Generalized Additive Models (GAMs) have quickly become the leading choice for fully-interpretable machine learning. However, unlike uninterpretable methods such as DNNs, they lack expressive power and easy scalability, and are hence not a feasible alternative for real-world tasks. We present a new class of GAMs that use tensor rank decompositions of polynomials to learn powerful, \{{\textbackslash}em fully-interpretable\} models. Our approach, titled Scalable Polynomial Additive Models (SPAM) is effortlessly scalable and models \{{\textbackslash}em all\} higher-order feature interactions without a combinatorial parameter explosion. SPAM outperforms all current interpretable approaches, and matches DNN/XGBoost performance on a series of real-world benchmarks with up to hundreds of thousands of features. We demonstrate by human subject evaluations that SPAMs are demonstrably more interpretable in practice, and are hence an effortless replacement for DNNs for creating interpretable and high-performance systems suitable for large-scale machine learning. Source code is available at https://github.com/facebookresearch/nbm-spam.},
	urldate = {2022-06-17},
	publisher = {arXiv},
	author = {Dubey, Abhimanyu and Radenovic, Filip and Mahajan, Dhruv},
	month = jun,
	year = {2022},
	note = {arXiv:2205.14108 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Interpretable ML, Unread, interpretability},
}

@misc{merrick_explanation_2020,
	title = {The {Explanation} {Game}: {Explaining} {Machine} {Learning} {Models} {Using} {Shapley} {Values}},
	shorttitle = {The {Explanation} {Game}},
	url = {http://arxiv.org/abs/1909.08128},
	abstract = {A number of techniques have been proposed to explain a machine learning model's prediction by attributing it to the corresponding input features. Popular among these are techniques that apply the Shapley value method from cooperative game theory. While existing papers focus on the axiomatic motivation of Shapley values, and efficient techniques for computing them, they offer little justification for the game formulations used, and do not address the uncertainty implicit in their methods' outputs. For instance, the popular SHAP algorithm's formulation may give substantial attributions to features that play no role in the model. In this work, we illustrate how subtle differences in the underlying game formulations of existing methods can cause large differences in the attributions for a prediction. We then present a general game formulation that unifies existing methods, and enables straightforward confidence intervals on their attributions. Furthermore, it allows us to interpret the attributions as contrastive explanations of an input relative to a distribution of reference inputs. We tie this idea to classic research in cognitive psychology on contrastive explanations, and propose a conceptual framework for generating and interpreting explanations for ML models, called formulate, approximate, explain (FAE). We apply this framework to explain black-box models trained on two UCI datasets and a Lending Club dataset.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Merrick, Luke and Taly, Ankur},
	month = jun,
	year = {2020},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Interpretable ML, Statistics - Machine Learning, Unread},
}

@article{atrumbelj_efficient_2010,
	title = {An {Efficient} {Explanation} of {Individual} {Classifications} using {Game} {Theory}},
	volume = {11},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v11/strumbelj10a.html},
	abstract = {We present a general method for explaining individual predictions of classification models. The method is based on fundamental concepts from coalitional game theory and predictions are explained with contributions of individual feature values. We overcome the method's initial exponential time complexity with a sampling-based approximation. In the experimental part of the paper we use the developed method on models generated by several well-known machine learning algorithms on both synthetic and real-world data sets. The results demonstrate that the method is efficient and that the explanations are intuitive and useful.},
	number = {1},
	urldate = {2022-05-31},
	journal = {Journal of Machine Learning Research},
	author = {Å trumbelj, Erik and Kononenko, Igor},
	year = {2010},
	note = {Number: 1},
	keywords = {Interpretable ML, Unread},
	pages = {1--18},
}

@inproceedings{datta_algorithmic_2016,
	title = {Algorithmic {Transparency} via {Quantitative} {Input} {Influence}: {Theory} and {Experiments} with {Learning} {Systems}},
	shorttitle = {Algorithmic {Transparency} via {Quantitative} {Input} {Influence}},
	doi = {10.1109/SP.2016.42},
	abstract = {Algorithmic systems that employ machine learning play an increasing role in making substantive decisions in modern society, ranging from online personalization to insurance and credit decisions to predictive policing. But their decision-making processes are often opaque-it is difficult to explain why a certain decision was made. We develop a formal foundation to improve the transparency of such decision-making systems. Specifically, we introduce a family of Quantitative Input Influence (QII) measures that capture the degree of influence of inputs on outputs of systems. These measures provide a foundation for the design of transparency reports that accompany system decisions (e.g., explaining a specific credit decision) and for testing tools useful for internal and external oversight (e.g., to detect algorithmic discrimination). Distinctively, our causal QII measures carefully account for correlated inputs while measuring influence. They support a general class of transparency queries and can, in particular, explain decisions about individuals (e.g., a loan decision) and groups (e.g., disparate impact based on gender). Finally, since single inputs may not always have high influence, the QII measures also quantify the joint influence of a set of inputs (e.g., age and income) on outcomes (e.g. loan decisions) and the marginal influence of individual inputs within such a set (e.g., income). Since a single input may be part of multiple influential sets, the average marginal influence of the input is computed using principled aggregation measures, such as the Shapley value, previously applied to measure influence in voting. Further, since transparency reports could compromise privacy, we explore the transparency-privacy tradeoff and prove that a number of useful transparency reports can be made differentially private with very little addition of noise. Our empirical validation with standard machine learning algorithms demonstrates that QII measures are a useful transparency mechanism when black box access to the learning system is available. In particular, they provide better explanations than standard associative measures for a host of scenarios that we consider. Further, we show that in the situations we consider, QII is efficiently approximable and can be made differentially private while preserving accuracy.},
	booktitle = {2016 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Datta, Anupam and Sen, Shayak and Zick, Yair},
	month = may,
	year = {2016},
	note = {ISSN: 2375-1207},
	keywords = {Algorithm design and analysis, Atmospheric measurements, Correlation, Decision making, Interpretable ML, Machine learning algorithms, Particle measurements, Privacy, Unread, fairness, machine learning, transparency},
	pages = {598--617},
}

@misc{lundberg_unified_2017,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	url = {http://arxiv.org/abs/1705.07874},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Lundberg, Scott and Lee, Su-In},
	month = nov,
	year = {2017},
	note = {Number: arXiv:1705.07874
arXiv:1705.07874 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Interpretable ML, Statistics - Machine Learning, Unread},
}

@article{salazar_semi-supervised_2018,
	title = {Semi-{Supervised} {Learning} {For} {Imbalanced} {Classification} {Of} {Credit} {Card} {Transaction}},
	issn = {2161-4407},
	url = {https://ieeexplore.ieee.org/document/8489755},
	doi = {10.1109/IJCNN.2018.8489755},
	abstract = {Success in supervised learning is constrained by availability of an adequate labeled data sample for training. The problem of a complete labeling of every data of the training dataset can be alleviated allowing semi-complete labeling in a way so called semi-supervised learning. In this paper, we investigate the performance of semi-supervised learning in imbalanced classification problems. Augmentation of the class of limited data is applied for lowering the variance of the estimate using a data subrogation method. We analyze the effect of this data augmentation in several simulated and experimental scenarios of a challenging application: automatic credit card fraud detection. The relationships among different semi-supervision and sample augmentation ratios in this application are discussed in terms of receiver operating characteristic curves and business key performance indicators.},
	urldate = {2022-05-31},
	journal = {2018 International Joint Conference on Neural Networks (IJCNN)},
	author = {Salazar, Addisson and Safont, Gonzalo and Vergara, Luis},
	month = jul,
	year = {2018},
	keywords = {Unread},
}

@techreport{lin_evaluation_2019,
	title = {An {Evaluation} of {Bitcoin} {Address} {Classification} based on {Transaction} {History} {Summarization}},
	url = {http://arxiv.org/abs/1903.07994},
	abstract = {Bitcoin is a cryptocurrency that features a distributed, decentralized and trustworthy mechanism, which has made Bitcoin a popular global transaction platform. The transaction efficiency among nations and the privacy benefiting from address anonymity of the Bitcoin network have attracted many activities such as payments, investments, gambling, and even money laundering in the past decade. Unfortunately, some criminal behaviors which took advantage of this platform were not identified. This has discouraged many governments to support cryptocurrency. Thus, the capability to identify criminal addresses becomes an important issue in the cryptocurrency network. In this paper, we propose new features in addition to those commonly used in the literature to build a classification model for detecting abnormality of Bitcoin network addresses. These features include various high orders of moments of transaction time (represented by block height) which summarizes the transaction history in an efficient way. The extracted features are trained by supervised machine learning methods on a labeling category data set. The experimental evaluation shows that these features have improved the performance of Bitcoin address classification significantly. We evaluate the results under eight classifiers and achieve the highest Micro-F1/Macro-F1 of 87\%/86\% with LightGBM.},
	number = {arXiv:1903.07994},
	urldate = {2022-05-31},
	institution = {arXiv},
	author = {Lin, Yu-Jing and Wu, Po-Wei and Hsu, Cheng-Han and Tu, I.-Ping and Liao, Shih-wei},
	month = mar,
	year = {2019},
	doi = {10.48550/arXiv.1903.07994},
	note = {Issue: arXiv:1903.07994
arXiv:1903.07994 [cs, stat]
type: article},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Read, StatML, Statistics - Machine Learning},
}

@article{hu_transaction-based_2021,
	title = {Transaction-based classification and detection approach for {Ethereum} smart contract},
	volume = {58},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457320309547},
	doi = {10.1016/j.ipm.2020.102462},
	abstract = {Blockchain technology brings innovation to various industries. Ethereum is currently the second blockchain platform by market capitalization, it’s also the largest smart contract blockchain platform. Smart contracts can simplify and accelerate the development of various applications, but they also bring some problems. For example, smart contracts are used to commit fraud, vulnerability contracts are deliberately developed to undermine fairness, and there are numerous duplicative contracts that waste performance with no actual purpose. In this paper, we propose a transaction-based classification and detection approach for Ethereum smart contract to address these issues. We collected over 10,000 smart contracts from Ethereum and focused on the data behavior generated by smart contracts and users. We identified four behavior patterns from the transactions by manual analysis, which can be used to distinguish the difference between different types of contracts. Then 14 basic features of a smart contract are constructed from these. To construct the experimental dataset, we propose a data slicing algorithm for slicing the collected smart contracts. After that, we use an LSTM network to train and test our datasets. The extensive experimental results show that our approach can distinguish different types of contracts and can be applied to anomaly detection and malicious contract identification with satisfactory precision, recall, and f1-score.},
	language = {en},
	number = {2},
	urldate = {2022-05-31},
	journal = {Information Processing \& Management},
	author = {Hu, Teng and Liu, Xiaolei and Chen, Ting and Zhang, Xiaosong and Huang, Xiaoming and Niu, Weina and Lu, Jiazhong and Zhou, Kun and Liu, Yuan},
	month = mar,
	year = {2021},
	note = {Number: 2},
	keywords = {Blockchain, Classification, Ethereum, Read, Security, Smart contract},
	pages = {102462},
}

@misc{apley_visualizing_2019,
	title = {Visualizing the {Effects} of {Predictor} {Variables} in {Black} {Box} {Supervised} {Learning} {Models}},
	url = {http://arxiv.org/abs/1612.08468},
	abstract = {When fitting black box supervised learning models (e.g., complex trees, neural networks, boosted trees, random forests, nearest neighbors, local kernel-weighted methods, etc.), visualizing the main effects of the individual predictor variables and their low-order interaction effects is often important, and partial dependence (PD) plots are the most popular approach for accomplishing this. However, PD plots involve a serious pitfall if the predictor variables are far from independent, which is quite common with large observational data sets. Namely, PD plots require extrapolation of the response at predictor values that are far outside the multivariate envelope of the training data, which can render the PD plots unreliable. Although marginal plots (M plots) do not require such extrapolation, they produce substantially biased and misleading results when the predictors are dependent, analogous to the omitted variable bias in regression. We present a new visualization approach that we term accumulated local effects (ALE) plots, which inherits the desirable characteristics of PD and M plots, without inheriting their preceding shortcomings. Like M plots, ALE plots do not require extrapolation; and like PD plots, they are not biased by the omitted variable phenomenon. Moreover, ALE plots are far less computationally expensive than PD plots.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Apley, Daniel W. and Zhu, Jingyu},
	month = aug,
	year = {2019},
	note = {Number: arXiv:1612.08468
arXiv:1612.08468 [stat]},
	keywords = {Interpretable ML, Statistics - Methodology, Unread},
}

@article{sandri_analysis_2010,
	title = {Analysis and correction of bias in {Total} {Decrease} in {Node} {Impurity} measures for tree-based algorithms},
	volume = {20},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-009-9132-0},
	doi = {10.1007/s11222-009-9132-0},
	abstract = {Variable selection is one of the main problems faced by data mining and machine learning techniques. These techniques are often, more or less explicitly, based on some measure of variable importance. This paper considers Total Decrease in Node Impurity (TDNI) measures, a popular class of variable importance measures defined in the field of decision trees and tree-based ensemble methods, like Random Forests and Gradient Boosting Machines. In spite of their wide use, some measures of this class are known to be biased and some correction strategies have been proposed. The aim of this paper is twofold. Firstly, to investigate the source and the characteristics of bias in TDNI measures using the notions of informative and uninformative splits. Secondly, a bias-correction algorithm, recently proposed for the Gini measure in the context of classification, is extended to the entire class of TDNI measures and its performance is investigated in the regression framework using simulated and real data.},
	language = {en},
	number = {4},
	urldate = {2022-05-31},
	journal = {Statistics and Computing},
	author = {Sandri, Marco and Zuccolotto, Paola},
	month = oct,
	year = {2010},
	note = {Number: 4},
	keywords = {Ensemble learning, Impurity measures, Interpretable ML, PhD - Literature review, Unread, Variable importance},
	pages = {393--407},
}

@article{sandri_bias_2008,
	title = {A {Bias} {Correction} {Algorithm} for the {Gini} {Variable} {Importance} {Measure} in {Classification} {Trees}},
	volume = {17},
	issn = {1061-8600},
	url = {https://doi.org/10.1198/106186008X344522},
	doi = {10.1198/106186008X344522},
	abstract = {This article considers a measure of variable importance frequently used in variable-selection methods based on decision trees and tree-based ensemble models. These models include CART, random forests, and gradient boosting machine. The measure of variable importance is defined as the total heterogeneity reduction produced by a given covariate on the response variable when the sample space is recursively partitioned. Despite its popularity, some authors have shown that this measure is biased to the extent that, under certain conditions, there may be dangerous effects on variable selection. Here we present a simple and effective method for bias correction, focusing on the easily generalizable case of the Gini index as a measure of heterogeneity.},
	number = {3},
	urldate = {2022-05-31},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Sandri, Marco and Zuccolotto, Paola},
	month = sep,
	year = {2008},
	note = {Number: 3
Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/106186008X344522},
	keywords = {Bias, Interpretable ML, Learning ensemble, PhD - Literature review, Unread, Variable importance, Variable selection},
	pages = {611--628},
}

@misc{ghoshal_estimating_2020,
	title = {Estimating {Uncertainty} and {Interpretability} in {Deep} {Learning} for {Coronavirus} ({COVID}-19) {Detection}},
	url = {http://arxiv.org/abs/2003.10769},
	abstract = {Deep Learning has achieved state of the art performance in medical imaging. However, these methods for disease detection focus exclusively on improving the accuracy of classification or predictions without quantifying uncertainty in a decision. Knowing how much confidence there is in a computer-based medical diagnosis is essential for gaining clinicians trust in the technology and therefore improve treatment. Today, the 2019 Coronavirus (SARS-CoV-2) infections are a major healthcare challenge around the world. Detecting COVID-19 in X-ray images is crucial for diagnosis, assessment and treatment. However, diagnostic uncertainty in the report is a challenging and yet inevitable task for radiologist. In this paper, we investigate how drop-weights based Bayesian Convolutional Neural Networks (BCNN) can estimate uncertainty in Deep Learning solution to improve the diagnostic performance of the human-machine team using publicly available COVID-19 chest X-ray dataset and show that the uncertainty in prediction is highly correlates with accuracy of prediction. We believe that the availability of uncertainty-aware deep learning solution will enable a wider adoption of Artificial Intelligence (AI) in a clinical setting.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Ghoshal, Biraja and Tucker, Allan},
	month = mar,
	year = {2020},
	note = {Number: arXiv:2003.10769
arXiv:2003.10769 [cs, eess, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing, Interpretable ML, PhD - Literature review, Statistics - Machine Learning, Unread},
}

@article{guidotti_survey_2018,
	title = {A {Survey} of {Methods} for {Explaining} {Black} {Box} {Models}},
	volume = {51},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3236009},
	doi = {10.1145/3236009},
	abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
	number = {5},
	urldate = {2022-05-31},
	journal = {ACM Computing Surveys},
	author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
	year = {2018},
	note = {Number: 5},
	keywords = {Interpretable ML, Open the black box, PhD - Literature review, Unread, explanations, interpretability, transparent models},
	pages = {93:1--93:42},
}

@misc{greenwell_pdp_2022,
	title = {pdp: {An} {R} {Package} for {Constructing} {Partial} {Dependence} {Plots}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {pdp},
	url = {https://cran.r-project.org/web/packages/pdp/vignettes/pdp-intro.pdf},
	abstract = {Complex nonparametric models—like neural networks, random forests, and support vector
machines—are more common than ever in predictive analytics, especially when dealing with large
observational databases that don’t adhere to the strict assumptions imposed by traditional statistical
techniques (e.g., multiple linear regression which assumes linearity, homoscedasticity, and normality).
Unfortunately, it can be challenging to understand the results of such models and explain them to
management. Partial dependence plots offer a simple solution. Partial dependence plots are low-
dimensional graphical renderings of the prediction function so that the relationship between the
outcome and predictors of interest can be more easily understood. These plots are especially useful in
explaining the output from black box models. In this paper, we introduce pdp, a general R package
for constructing partial dependence plots.},
	urldate = {2022-05-31},
	author = {Greenwell, Brandon M.},
	month = may,
	year = {2022},
	note = {Programmers: \_:n101},
	keywords = {Interpretable ML, MachineLearning, PhD - Literature review, Unread},
}

@misc{doshi-velez_towards_2017,
	title = {Towards {A} {Rigorous} {Science} of {Interpretable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1702.08608},
	abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Doshi-Velez, Finale and Kim, Been},
	month = mar,
	year = {2017},
	note = {Number: arXiv:1702.08608
arXiv:1702.08608 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Interpretable ML, PhD - Literature review, Statistics - Machine Learning, Unread},
}

@article{friedman_greedy_2001,
	title = {Greedy {Function} {Approximation}: {A} {Gradient} {Boosting} {Machine}},
	volume = {29},
	issn = {0090-5364},
	shorttitle = {Greedy {Function} {Approximation}},
	url = {https://www.jstor.org/stable/2699986},
	abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent "boosting" paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such "TreeBoost" models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
	number = {5},
	urldate = {2022-05-31},
	journal = {The Annals of Statistics},
	author = {Friedman, Jerome H.},
	year = {2001},
	note = {Number: 5
Publisher: Institute of Mathematical Statistics},
	keywords = {Interpretable ML, PhD - Literature review, Unread},
	pages = {1189--1232},
}

@misc{rudin_stop_2019,
	title = {Stop {Explaining} {Black} {Box} {Machine} {Learning} {Models} for {High} {Stakes} {Decisions} and {Use} {Interpretable} {Models} {Instead}},
	url = {http://arxiv.org/abs/1811.10154},
	abstract = {Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains. People have hoped that creating methods for explaining these black box models will alleviate some of these problems, but trying to {\textbackslash}textit\{explain\} black box models, rather than creating models that are {\textbackslash}textit\{interpretable\} in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. There is a way forward -- it is to design models that are inherently interpretable. This manuscript clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare, and computer vision.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Rudin, Cynthia},
	month = sep,
	year = {2019},
	note = {Number: arXiv:1811.10154
arXiv:1811.10154 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Interpretable ML, PhD - Literature review, Statistics - Machine Learning, Unread},
}

@article{carvalho_machine_2019,
	title = {Machine {Learning} {Interpretability}: {A} {Survey} on {Methods} and {Metrics}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	shorttitle = {Machine {Learning} {Interpretability}},
	url = {https://www.mdpi.com/2079-9292/8/8/832},
	doi = {10.3390/electronics8080832},
	abstract = {Machine learning systems are becoming increasingly ubiquitous. These systems’s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.},
	language = {en},
	number = {8},
	urldate = {2022-05-31},
	journal = {Electronics},
	author = {Carvalho, Diogo V. and Pereira, Eduardo M. and Cardoso, Jaime S.},
	month = aug,
	year = {2019},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Interpretable ML, PhD - Literature review, Unread, XAI, explainability, interpretability, machine learning},
	pages = {832},
}

@inproceedings{benard_interpretable_2021,
	title = {Interpretable {Random} {Forests} via {Rule} {Extraction}},
	url = {https://proceedings.mlr.press/v130/benard21a.html},
	abstract = {We introduce SIRUS (Stable and Interpretable RUle Set) for regression, a stable rule learning algorithm, which takes the form of a short and simple list of rules. State-of-the-art learning algorithms are often referred to as “black boxes” because of the high number of operations involved in their prediction process. Despite their powerful predictivity, this lack of interpretability may be highly restrictive for applications with critical decisions at stake. On the other hand, algorithms with a simple structure—typically decision trees, rule algorithms, or sparse linear models—are well known for their instability. This undesirable feature makes the conclusions of the data analysis unreliable and turns out to be a strong operational limitation. This motivates the design of SIRUS, based on random forests, which combines a simple structure, a remarkable stable behavior when data is perturbed, and an accuracy comparable to its competitors. We demonstrate the efficiency of the method both empirically (through experiments) and theoretically (with the proof of its asymptotic stability). A R/C++ software implementation sirus is available from CRAN.},
	language = {en},
	urldate = {2022-05-31},
	booktitle = {Proceedings of {The} 24th {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Bénard, Clément and Biau, Gérard and Veiga, Sébastien da and Scornet, Erwan},
	month = mar,
	year = {2021},
	note = {ISSN: 2640-3498},
	keywords = {Interpretable ML, PhD - Literature review, Unread},
	pages = {937--945},
}

@article{kenett_befitting_2022,
	title = {Befitting {Cross} {Validation} for {Sensible} {Machine} {Learning}: {Embracing} {Data} {Generation} {Structure}},
	abstract = {Modern statistics and machine learning typically involve large amounts of data coupled 
with computationally intensive methods. In a predictive modeling context, one seeks
models that achieve high predictive accuracy on new datasets. This is typically 
implemented by partitioning the data into training and hold-out data sets. The allocation 
is often conducted randomly at the row level of the data matrix. In this work we discuss
an overlooked gap in machine learning and predictive modeling, the role of data structure 
in the partitioning of observational data into training and hold-out datasets. Ignoring such 
structures can lead to deficiencies in model generalizability and operationalization. We 
suggest that explicitly embracing the data generation structure to partition the data for 
validating predictive model is essential to the success of data science project. The 
framework of befitting cross validation, from an Information Quality perspective, is to 
maximize the information quality in the data for sensible machine learning. A case study 
based on a burn in industrial process applied to electro-mechanical devices will illustrate 
the methodological points made in the paper.},
	journal = {Applied Stochastic Models in Business and Industry},
	author = {Kenett, Ron S. and Gotwalt, Chris and Freeman, Laura and Deng, Xinwei},
	year = {2022},
	keywords = {Interpretable ML, PhD - Literature review, Unread},
}

@misc{zhang_why_2019,
	title = {"{Why} {Should} {You} {Trust} {My} {Explanation}?" {Understanding} {Uncertainty} in {LIME} {Explanations}},
	shorttitle = {"{Why} {Should} {You} {Trust} {My} {Explanation}?},
	url = {http://arxiv.org/abs/1904.12991},
	abstract = {Methods for interpreting machine learning black-box models increase the outcomes' transparency and in turn generates insight into the reliability and fairness of the algorithms. However, the interpretations themselves could contain significant uncertainty that undermines the trust in the outcomes and raises concern about the model's reliability. Focusing on the method "Local Interpretable Model-agnostic Explanations" (LIME), we demonstrate the presence of two sources of uncertainty, namely the randomness in its sampling procedure and the variation of interpretation quality across different input data points. Such uncertainty is present even in models with high training and test accuracy. We apply LIME to synthetic data and two public data sets, text classification in 20 Newsgroup and recidivism risk-scoring in COMPAS, to support our argument.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Zhang, Yujia and Song, Kuangyan and Sun, Yiming and Tan, Sarah and Udell, Madeleine},
	month = jun,
	year = {2019},
	note = {Number: arXiv:1904.12991
arXiv:1904.12991 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Interpretable ML, PhD - Literature review, Statistics - Machine Learning, Unread},
}

@misc{benard_sirus_2020,
	title = {{SIRUS}: {Stable} and {Interpretable} {RUle} {Set} for {Classification}},
	shorttitle = {{SIRUS}},
	url = {http://arxiv.org/abs/1908.06852},
	abstract = {State-of-the-art learning algorithms, such as random forests or neural networks, are often qualified as "black-boxes" because of the high number and complexity of operations involved in their prediction mechanism. This lack of interpretability is a strong limitation for applications involving critical decisions, typically the analysis of production processes in the manufacturing industry. In such critical contexts, models have to be interpretable, i.e., simple, stable, and predictive. To address this issue, we design SIRUS (Stable and Interpretable RUle Set), a new classification algorithm based on random forests, which takes the form of a short list of rules. While simple models are usually unstable with respect to data perturbation, SIRUS achieves a remarkable stability improvement over cutting-edge methods. Furthermore, SIRUS inherits a predictive accuracy close to random forests, combined with the simplicity of decision trees. These properties are assessed both from a theoretical and empirical point of view, through extensive numerical experiments based on our R/C++ software implementation sirus available from CRAN.},
	urldate = {2022-05-31},
	publisher = {arXiv},
	author = {Bénard, Clément and Biau, Gérard and da Veiga, Sébastien and Scornet, Erwan},
	month = dec,
	year = {2020},
	note = {Number: arXiv:1908.06852
arXiv:1908.06852 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Interpretable ML, Mathematics - Statistics Theory, PhD - Literature review, Statistics - Machine Learning, Unread},
}

@techreport{gerharz_deducing_2020,
	title = {Deducing neighborhoods of classes from a fitted model},
	url = {http://arxiv.org/abs/2009.05516},
	abstract = {In todays world the request for very complex models for huge data sets is rising steadily. The problem with these models is that by raising the complexity of the models, it gets much harder to interpret them. The growing field of {\textbackslash}emph\{interpretable machine learning\} tries to make up for the lack of interpretability in these complex (or even blackbox-)models by using specific techniques that can help to understand those models better. In this article a new kind of interpretable machine learning method is presented, which can help to understand the partitioning of the feature space into predicted classes in a classification model using quantile shifts. To illustrate in which situations this quantile shift method (QSM) could become beneficial, it is applied to a theoretical medical example and a real data example. Basically, real data points (or specific points of interest) are used and the changes of the prediction after slightly raising or decreasing specific features are observed. By comparing the predictions before and after the manipulations, under certain conditions the observed changes in the predictions can be interpreted as neighborhoods of the classes with regard to the manipulated features. Chordgraphs are used to visualize the observed changes.},
	number = {arXiv:2009.05516},
	urldate = {2022-05-31},
	institution = {arXiv},
	author = {Gerharz, Alexander and Groll, Andreas and Schauberger, Gunther},
	month = sep,
	year = {2020},
	doi = {10.48550/arXiv.2009.05516},
	note = {Issue: arXiv:2009.05516
arXiv:2009.05516 [cs, stat]
type: article},
	keywords = {Computer Science - Machine Learning, Interpretable ML, PhD - Literature review, Statistics - Machine Learning, Statistics - Methodology, Unread},
}
