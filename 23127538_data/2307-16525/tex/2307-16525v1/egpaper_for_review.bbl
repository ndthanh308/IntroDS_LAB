\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{NoCaps}
Harsh Agrawal, Karan Desai, Yufei Wang, Xinlei Chen, Rishabh Jain, Mark
  Johnson, Dhruv Batra, Devi Parikh, Stefan Lee, and Peter Anderson.
\newblock Nocaps: Novel object captioning at scale.
\newblock {\em Proceedings of the IEEE/CVF international conference on computer
  vision}, pages 8948--8957, 2019.

\bibitem{ConstrainedBeamSearch}
Peter Anderson, Basura Fernando, Mark Johnson, and Stephen Gould.
\newblock Guided open vocabulary image captioning with constrained beam search.
\newblock {\em arXiv preprint arXiv:1612.00576}, 2016.

\bibitem{SPICE}
Peter Anderson, Basura Fernando, Mark Johnson, and Stephen Gould.
\newblock Spice: Semantic propositional image caption evaluation.
\newblock {\em Computer Vision--ECCV 2016: 14th European Conference, Amsterdam,
  The Netherlands, October 11-14, 2016, Proceedings, Part V 14}, pages
  382--398, 2016.

\bibitem{BUTD}
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
  Gould, and Lei Zhang.
\newblock Bottom-up and top-down attention for image captioning and visual
  question answering.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 6077--6086, 2018.

\bibitem{GPT3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems},
  33:1877--1901, 2020.

\bibitem{CC12M}
Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to
  recognize long-tail visual concepts.
\newblock {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 3558--3568, 2021.

\bibitem{SCA-CNN}
Long Chen, Hanwang Zhang, Jun Xiao, Liqiang Nie, Jian Shao, Wei Liu, and
  Tat-Seng Chua.
\newblock Sca-cnn: Spatial and channel-wise attention in convolutional networks
  for image captioning.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5659--5667, 2017.

\bibitem{MSCOCO1}
Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr
  Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco captions: Data collection and evaluation server.
\newblock {\em arXiv preprint arXiv:1504.00325}, 2015.

\bibitem{MindEye}
Xinlei Chen and C Lawrence~Zitnick.
\newblock Mind's eye: A recurrent visual representation for image caption
  generation.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2422--2431, 2015.

\bibitem{UniversalCaptioner}
Marcella Cornia, Lorenzo Baraldi, Giuseppe Fiameni, and Rita Cucchiara.
\newblock Universal captioner: Inducing content-style separation in
  vision-and-language model training.
\newblock {\em arXiv preprint arXiv:2111.12727}, 2021.

\bibitem{MMT}
Marcella Cornia, Matteo Stefanini, Lorenzo Baraldi, and Rita Cucchiara.
\newblock Meshed-memory transformer for image captioning.
\newblock {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 10578--10587, 2020.

\bibitem{METEOR}
Michael Denkowski and Alon Lavie.
\newblock Meteor universal: Language specific translation evaluation for any
  target language.
\newblock {\em Proceedings of the ninth workshop on statistical machine
  translation}, pages 376--380, 2014.

\bibitem{ViT}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{feng2019unsupervised}
Yang Feng, Lin Ma, Wei Liu, and Jiebo Luo.
\newblock Unsupervised image captioning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4125--4134, 2019.

\bibitem{StyleNet}
Chuang Gan, Zhe Gan, Xiaodong He, Jianfeng Gao, and Li Deng.
\newblock Stylenet: Generating attractive visual captions with styles.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3137--3146, 2017.

\bibitem{ViLD}
Xiuye Gu, Tsung-Yi Lin, Weicheng Kuo, and Yin Cui.
\newblock Open-vocabulary object detection via vision and language knowledge
  distillation.
\newblock {\em arXiv preprint arXiv:2104.13921}, 2021.

\bibitem{MaskRCNN}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2961--2969, 2017.

\bibitem{ResNet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{DCC}
Lisa~Anne Hendricks, Subhashini Venugopalan, Marcus Rohrbach, Raymond Mooney,
  Kate Saenko, and Trevor Darrell.
\newblock Deep compositional captioning: Describing novel object categories
  without paired training data.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1--10, 2016.

\bibitem{LSTM}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780, 1997.

\bibitem{AoA}
Lun Huang, Wenmin Wang, Jie Chen, and Xiao-Yong Wei.
\newblock Attention on attention for image captioning.
\newblock {\em Proceedings of the IEEE/CVF international conference on computer
  vision}, pages 4634--4643, 2019.

\bibitem{ALIGN}
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le,
  Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock {\em International Conference on Machine Learning}, pages 4904--4916,
  2021.

\bibitem{alignmentcaption}
Andrej Karpathy and Li Fei-Fei.
\newblock Deep visual-semantic alignments for generating image descriptions.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3128--3137, 2015.

\bibitem{AdamW}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{laina2019towards}
Iro Laina, Christian Rupprecht, and Nassir Navab.
\newblock Towards unsupervised image captioning with shared multimodal
  embeddings.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 7414--7424, 2019.

\bibitem{Lseg}
Boyi Li, Kilian~Q Weinberger, Serge Belongie, Vladlen Koltun, and Ren{\'e}
  Ranftl.
\newblock Language-driven semantic segmentation.
\newblock {\em arXiv preprint arXiv:2201.03546}, 2022.

\bibitem{GLIP}
Liunian~Harold Li, Pengchuan Zhang, Haotian Zhang, Jianwei Yang, Chunyuan Li,
  Yiwu Zhong, Lijuan Wang, Lu Yuan, Lei Zhang, Jenq-Neng Hwang, et~al.
\newblock Grounded language-image pre-training.
\newblock {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10965--10975, 2022.

\bibitem{DECAP}
Wei Li, Linchao Zhu, Longyin Wen, and Yi Yang.
\newblock Decap: Decoding clip latents for zero-shot captioning.
\newblock {\em International Conference on Learning Representations}, 2023.

\bibitem{Oscar}
Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan
  Wang, Houdong Hu, Li Dong, Furu Wei, et~al.
\newblock Oscar: Object-semantics aligned pre-training for vision-language
  tasks.
\newblock {\em Computer Vision--ECCV 2020: 16th European Conference, Glasgow,
  UK, August 23--28, 2020, Proceedings, Part XXX 16}, pages 121--137, 2020.

\bibitem{MSCOCO}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich,
  Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pages 740--755,
  2014.

\bibitem{KnowingWhenToLook}
Jiasen Lu, Caiming Xiong, Devi Parikh, and Richard Socher.
\newblock Knowing when to look: Adaptive attention via a visual sentinel for
  image captioning.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 375--383, 2017.

\bibitem{NeuralBabyTalk}
Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh.
\newblock Neural baby talk.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7219--7228, 2018.

\bibitem{ITuning}
Ziyang Luo, Zhipeng Hu, Yadong Xi, Rongsheng Zhang, and Jing Ma.
\newblock I-tuning: Tuning frozen language models with image for lightweight
  image captioning.
\newblock {\em ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 1--5, 2023.

\bibitem{ClipCap}
Ron Mokady, Amir Hertz, and Amit~H Bermano.
\newblock Clipcap: Clip prefix for image captioning.
\newblock {\em arXiv preprint arXiv:2111.09734}, 2021.

\bibitem{CapDec}
David Nukrai, Ron Mokady, and Amir Globerson.
\newblock Text-only training for image captioning using noise-injected clip.
\newblock {\em arXiv preprint arXiv:2211.00575}, 2022.

\bibitem{BLEU}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock {\em Proceedings of the 40th annual meeting of the Association for
  Computational Linguistics}, pages 311--318, 2002.

\bibitem{CLIP}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock {\em International conference on machine learning}, pages 8748--8763,
  2021.

\bibitem{GPT2}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
  Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock {\em OpenAI blog}, 1(8):9, 2019.

\bibitem{OfficeHome}
Mohammad~Mahfujur Rahman, Clinton Fookes, Mahsa Baktashmotlagh, and Sridha
  Sridharan.
\newblock Multi-component image translation for deep domain generalization.
\newblock {\em 2019 IEEE Winter Conference on Applications of Computer Vision
  (WACV)}, pages 579--588, 2019.

\bibitem{SMALLCAP}
Rita Ramos, Bruno Martins, Desmond Elliott, and Yova Kementchedjhieva.
\newblock Smallcap: lightweight image captioning prompted with retrieval
  augmentation.
\newblock {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2840--2849, 2023.

\bibitem{FasterRCNN}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock {\em Advances in neural information processing systems}, 28, 2015.

\bibitem{MAGIC}
Yixuan Su, Tian Lan, Yahui Liu, Fangyu Liu, Dani Yogatama, Yan Wang, Lingpeng
  Kong, and Nigel Collier.
\newblock Language models can see: plugging visual controls in text generation.
\newblock {\em arXiv preprint arXiv:2205.02655}, 2022.

\bibitem{ZeroCap}
Yoad Tewel, Yoav Shalev, Idan Schwartz, and Lior Wolf.
\newblock Zero-shot image-to-text generation for visual-semantic arithmetic.
\newblock {\em arXiv preprint arXiv:2111.14447}, 2021.

\bibitem{Transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{CIDEr}
Ramakrishna Vedantam, C Lawrence~Zitnick, and Devi Parikh.
\newblock Cider: Consensus-based image description evaluation.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4566--4575, 2015.

\bibitem{NOC}
Subhashini Venugopalan, Lisa Anne~Hendricks, Marcus Rohrbach, Raymond Mooney,
  Trevor Darrell, and Kate Saenko.
\newblock Captioning images with diverse objects.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5753--5761, 2017.

\bibitem{SimVLM}
Zirui Wang, Jiahui Yu, Adams~Wei Yu, Zihang Dai, Yulia Tsvetkov, and Yuan Cao.
\newblock Simvlm: Simple visual language model pretraining with weak
  supervision.
\newblock {\em arXiv preprint arXiv:2108.10904}, 2021.

\bibitem{hugface}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, R{\'e}mi Louf, Morgan Funtowicz,
  et~al.
\newblock Transformers: State-of-the-art natural language processing.
\newblock {\em Proceedings of the 2020 conference on empirical methods in
  natural language processing: system demonstrations}, pages 38--45, 2020.

\bibitem{GroupViT}
Jiarui Xu, Shalini De~Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz,
  and Xiaolong Wang.
\newblock Groupvit: Semantic segmentation emerges from text supervision.
\newblock {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 18134--18144, 2022.

\bibitem{ShowAttendTell}
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan
  Salakhudinov, Rich Zemel, and Yoshua Bengio.
\newblock Show, attend and tell: Neural image caption generation with visual
  attention.
\newblock {\em International conference on machine learning}, pages 2048--2057,
  2015.

\bibitem{ICSemanticAttention}
Quanzeng You, Hailin Jin, Zhaowen Wang, Chen Fang, and Jiebo Luo.
\newblock Image captioning with semantic attention.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4651--4659, 2016.

\bibitem{Flickr30k}
Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier.
\newblock From image descriptions to visual denotations: New similarity metrics
  for semantic inference over event descriptions.
\newblock {\em Transactions of the Association for Computational Linguistics},
  2:67--78, 2014.

\bibitem{SMs}
Andy Zeng, Adrian Wong, Stefan Welker, Krzysztof Choromanski, Federico Tombari,
  Aveek Purohit, Michael Ryoo, Vikas Sindhwani, Johnny Lee, Vincent Vanhoucke,
  et~al.
\newblock Socratic models: Composing zero-shot multimodal reasoning with
  language.
\newblock {\em arXiv preprint arXiv:2204.00598}, 2022.

\bibitem{VinVL}
Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang,
  Yejin Choi, and Jianfeng Gao.
\newblock Vinvl: Revisiting visual representations in vision-language models.
\newblock {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 5579--5588, 2021.

\bibitem{OPT}
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
  Chen, Christopher Dewan, Mona Diab, Xian Li, Xi~Victoria Lin, et~al.
\newblock Opt: Open pre-trained transformer language models.
\newblock {\em arXiv preprint arXiv:2205.01068}, 2022.

\bibitem{MemCap}
Wentian Zhao, Xinxiao Wu, and Xiaoxun Zhang.
\newblock Memcap: Memorizing style knowledge for image captioning.
\newblock {\em Proceedings of the AAAI Conference on Artificial Intelligence},
  34(07):12984--12992, 2020.

\end{thebibliography}
