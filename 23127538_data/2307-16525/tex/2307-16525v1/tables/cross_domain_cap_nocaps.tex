
% \begin{table*}
% \small
% \center
% \begin{center}
% \setlength{\tabcolsep}{1.2mm}{
% \begin{tabular}{l|c|c|cc|cc|cc|cc}
% \toprule
% \multicolumn{11}{c}{\textbf{COCO $\Rightarrow$ NoCaps val}} \\
% \midrule
% \multirow{2}{*}{Methods} & \multirow{2}{*}{Published in} & \multirow{2}{*}{Pre-trained Model} & \multicolumn{2}{c|}{in-domain} & \multicolumn{2}{c|}{near-domain} & \multicolumn{2}{c|}{out-of-domain} & \multicolumn{2}{c}{Overall} \\
% ~ & ~ & ~ & CIDEr & SPICE & CIDEr & SPICE & CIDEr & SPICE & CIDEr & SPICE \\
% \midrule
% \multicolumn{11}{l}{\demph{\textbf{Paired image-text training, zero-shot inference}}} \\
% \demph{OSCAR$_{Base}$}~\cite{Oscar} & \demph{ECCV 20} & \demph{Faster R-CNN + BERT$_{Base}$} & \demph{79.6} & \demph{12.3} & \demph{66.1} & \demph{11.5} & \demph{45.3} & \demph{9.7} & \demph{63.8} & \demph{11.2}  \\
% \demph{ClipCap}~\cite{ClipCap} & \demph{ArXiv 21} & \demph{ViT-B/32 + GPT-2$_{Large}$} & \demph{84.9} & \demph{12.1} & \demph{66.8} & \demph{10.9} & \demph{49.1} & \demph{9.6} & \demph{65.8} & \demph{10.9}  \\
% \demph{I-Tuning$_{Base}$}~\cite{ITuning} & \demph{ICASSP 23} & \demph{ViT-B/16 + GPT-2$_{Base}$} & \demph{83.9} & \demph{12.4} & \demph{70.3} & \demph{11.7} & \demph{48.1} & \demph{9.5} & \demph{67.8} & \demph{11.4} \\
% \demph{SmallCap*}~\cite{SMALLCAP} & \demph{CVPR 23} & \demph{ViT-B/32 + GPT-2$_{Base}$ } & \demph{83.3} & \demph{-} & \demph{77.1} & \demph{-} & \demph{65.0} & \demph{-} & \demph{75.8} & \demph{-} \\
% \midrule
% \multicolumn{11}{l}{\textbf{Text-only training, zero-shot inference}} \\
% DeCap* \cite{DECAP} & \demph{ICLR 23} & ViT-B/32 + Transformer & \textbf{65.2} & - & 47.8 & - & 25.8 & - & 45.9 & - \\
% CapDec\dag & \demph{EMNLP 22} & ViT-B/32 + GPT-2$_{\rm Base}$ & 60.1 & 10.2 & 50.2 & 9.3 & 28.7 & 6.0 & 45.9 & 8.3 \\
% \rowcolor{Gray}
% ViECap & - & ViT-B/32 + GPT-2$_{\rm Base}$ & 61.1 & \textbf{10.4} & \textbf{64.3} & \textbf{9.9} & \textbf{65.0} & \textbf{8.6} & \textbf{66.2} & \textbf{9.5} \\
% \bottomrule
% \end{tabular}}
% \end{center}
% \caption{Cross-domain captioning results on the NoCaps validation set. \dag denotes results computed by us. * refers to use an \textbf{extra memory bank}.
% % The model size of CLIP backbone: ViT-B/32 $<$ ViT-B/16.
% Note that SmallCap reports results on the NoCaps test set, while all other methods report results on the NoCaps validation set.}
% \label{tab:nocaps}
% \end{table*}

\begin{table*}
\begin{center}
\small
\setlength{\tabcolsep}{1.5mm}{
\begin{tabular}{l|c|cc|cc|cc|cc}
\toprule
\multicolumn{10}{c}{\textbf{COCO $\Rightarrow$ NoCaps val}} \\
\midrule
\multirow{2}{*}{Methods} & \multirow{2}{*}{Pre-trained Model} & \multicolumn{2}{c|}{in-domain} & \multicolumn{2}{c|}{near-domain} & \multicolumn{2}{c|}{out-of-domain} & \multicolumn{2}{c}{Overall} \\
~  & ~ & CIDEr & SPICE & CIDEr & SPICE & CIDEr & SPICE & CIDEr & SPICE \\
\midrule
\multicolumn{10}{l}{\demph{\textbf{Paired image-text training, zero-shot inference}}} \\
\demph{OSCAR$_{\rm Base}$}~\cite{Oscar} \demph{$_\text{\rm ECCV'20}$} & \demph{\ \ \ Faster R-CNN + BERT$_{\rm Base}$\ \ \ } & \demph{79.6} & \demph{12.3} & \demph{66.1} & \demph{11.5} & \demph{45.3} & \demph{9.7} & \demph{63.8} & \demph{11.2} \\
\demph{ClipCap}~\cite{ClipCap} \demph{$_\text{\rm ArXiv'21}$} & \demph{ViT-B/32 + GPT-2$_{\rm Large}$} & \demph{84.9} & \demph{12.1} & \demph{66.8} & \demph{10.9} & \demph{49.1} & \demph{9.6} & \demph{65.8} & \demph{10.9} \\
\demph{I-Tuning$_{\rm Base}$\ \ \ }~\cite{ITuning} \demph{$_\text{\rm ICASSP'23}$} & \demph{ViT-B/16 + GPT-2$_{\rm Base}$} & \demph{83.9} & \demph{12.4} & \demph{70.3} & \demph{11.7} & \demph{48.1} & \demph{9.5} & \demph{67.8} & \demph{11.4} \\
\demph{SmallCap*}~\cite{SMALLCAP} \demph{$_\text{\rm CVPR'23}$} & \demph{ViT-B/32 + GPT-2$_{\rm Base}$ } & \demph{83.3} & \demph{-} & \demph{77.1} & \demph{-} & \demph{65.0} & \demph{-} & \demph{75.8} & \demph{-} \\
% \midrule
\multicolumn{10}{l}{\textbf{Text-only training, zero-shot inference}} \\
DeCap*~\cite{DECAP} \demph{$_\text{\rm ICLR'22}$} & ViT-B/32 + Transformer & \textbf{65.2} & - & 47.8 & - & 25.8 & - & 45.9 & - \\
CapDec\dag~\cite{CapDec} \demph{$_\text{\rm EMNLP'22}$} & ViT-B/32 + GPT-2$_{\rm Base}$ & 60.1 & 10.2 & 50.2 & 9.3 & 28.7 & 6.0 & 45.9 & 8.3 \\
\rowcolor{Gray}
ViECap \demph{$_\text{\rm ICCV'23}$} & ViT-B/32 + GPT-2$_{\rm Base}$ & 61.1 & \textbf{10.4} & \textbf{64.3} & \textbf{9.9} & \textbf{65.0} & \textbf{8.6} & \textbf{66.2} & \textbf{9.5} \\
\bottomrule
\end{tabular}}
\end{center}
% \setlength{\abovecaptionskip}{0cm}
\caption{Cross-domain captioning results on the NoCaps validation set. \dag represents our re-implemented results. * refers to the use of a \textbf{memory bank}. Note that SmallCap reports results on the NoCaps test set, while other methods report results on the NoCaps validation set.}
\label{tab:nocaps}
\end{table*}