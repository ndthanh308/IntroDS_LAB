
\begin{table}
\small
\begin{center}
\setlength{\tabcolsep}{0.85 mm}{
\begin{tabular}{l|cc|c|cccc}
\toprule
\multirow{2}{*}{Model} & \multirow{2}{*}{pt.} & \multirow{2}{*}{\#para} & \multicolumn{1}{c|}{\textbf{COCO}}&\multicolumn{4}{c}{\textbf{NoCaps val}} \\
 & & & Test & In & Near & Out & Overall \\
\midrule
\multicolumn{5}{l}{\textbf{Tuned language model}} \\
% GPT$_{\rm Base}$ (4-layer) & $\times$ & 67M & 89.8 & 51.8 & 53.4 & 48.1 & 53.1 \\
GPT$_{\rm Base}$ (4-layer) & $\times$ & 67M & 89.8 & 54.5 & 54.2 & 50.2 & 54.6 \\
GPT$_{\rm Base}$ & $\surd$ &124M & 92.9 & {61.1} & {64.3} & {65.0} & 66.2\\
\midrule
\multicolumn{5}{l}{\textbf{Frozen language model}} \\
GPT$_{\rm Base}$ & $\surd$ &124M & 88.0 & 57.7 & 60.2 & 61.4 & 62.0 \\
GPT$_{\rm Large}$ & $\surd$ &774M & 91.7 & 59.4 & 64.4 & 68.4 & 66.9 \\
GPT$_{\rm XL}$ & $\surd$ &1.5B & 94.5 & 63.4 & 66.6 & 68.9 & 68.9 \\
OPT$_{\rm 1.3B}$ & $\surd$ &1.3B & 95.6 & 64.9 & 68.7 & 69.9 & 70.7 \\
OPT$_{\rm 2.7B}$ & $\surd$ &2.7B & 96.9 & 64.7 & 70.2 & 71.9 & 72.1 \\
% OPT-iml & 1.3B & & & & & \\
\bottomrule
\end{tabular}}
\end{center}
\caption{ViECap with different scales of language models. ``pt." represents using pre-trained weights.}
\label{scaleup}
\end{table}