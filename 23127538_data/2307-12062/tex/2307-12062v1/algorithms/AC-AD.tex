\begin{algorithm}[tb]
  \caption{Action Adversary (AC-AD)}
  \label{alg:ac-ad}
  \begin{algorithmic}
  \STATE \textbf{Input:} Initialization of action adversary policy $v$; victim policy $\pi$, initial state $s_0$
  \FOR {$t = 0, 1, 2, \ldots$}
  \STATE adversary $v$ samples an action perturbations $\widehat{a}_{t}\sim\nu(\cdot|s_{t})$, 
  \STATE victim policy $\pi$ outputs action $a_{t}\sim\pi(\cdot|s_{t})$
  \STATE the environment receives $\tilde{a}_{t} = a_{t} + \widehat{a}_{t} $, returns $s_{t+1}$ and $r_t$
  \STATE adversary saves $(s_t, \widehat{a}_t,-r_t,s_{t+1})$ to the adversary buffer
  \STATE adversary updates its policy $v$
  \ENDFOR
  \end{algorithmic}
\end{algorithm}
\vspace{-0.5em}