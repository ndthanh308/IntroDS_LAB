\begin{algorithm}[!hb]
  \caption{Policy Adversarial Actor Director (PA-AD)}
  \label{alg:pa-ad}
  \begin{algorithmic}
  \STATE \textbf{Input:} Initialization of adversary directorâ€™s policy $v$; victim policy $\pi$, the actor function $g$ for the state space $\mathcal{S}$, initial state $s_0$
  \FOR {$t = 0, 1, 2, \ldots$}
  \STATE \textit{Director} $v$ samples a policy perturbing direction and perturbed choice, $\widehat{a}_{t}\sim\nu(\cdot|s_{t})$
  \STATE \textit{Actor} perturbs $s_t$ to $\tilde{s}_{t}=g(\widehat{a}_{t},s_{t})$
  \STATE Victim takes action $a_{t}\sim\pi(\cdot|\tilde{s}_{t})$, proceeds to $s_{t+1}$, receives $r_t$
  \STATE \textit{Director} saves $(s_t, \widehat{a}_t,-r_t,s_{t+1})$ to the adversary buffer
  \STATE \textit{Director} updates its policy $v$ using any RL algorithms
  \ENDFOR
  \end{algorithmic}
\end{algorithm}
\vspace{-0.5em}