\pdfoutput=1
\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
\usepackage[preprint]{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}

\setcitestyle{numbers,square}
\usepackage{xspace}
\usepackage{wrapfig}

\input{supp_macros}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2022}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2022}


% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{neurips_2022}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage{pgfplots}
\DeclareUnicodeCharacter{2212}{âˆ’}
\usepgfplotslibrary{groupplots,dateplot}
\usetikzlibrary{patterns,shapes.arrows}
\pgfplotsset{compat=newest}
\usepackage{colortbl}
\usepackage{multirow}
\usepackage{array}
\usepackage{makecell}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{siunitx}

%%%% Added by JB
% \bibliographystyle{abbrvnat}
%%%% Changed by Yanchao for saving space
\bibliographystyle{plain}


% \usepackage[noline]{algorithm2e}

\RequirePackage{algorithm}
\RequirePackage{algorithmic}
\RequirePackage{forloop}

\usepackage{epstopdf}
\usepackage{graphicx}
% \usepackage{subcaption}

\usepackage{tabulary}
\usepackage{colortbl}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\DeclareMathOperator{\E}{\mathbb{E}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\supp}{supp}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


% \title{Breaking Rectangularity in Robust RL}
\title{
Game-Theoretic
Robust Reinforcement Learning Handles Temporally-Coupled Perturbations}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Yongyuan Liang$^\dag$ \\
  \texttt{cheryllLiang@outlook.com} \\
  \And
  Yanchao Sun$^\dag$ \\
  \texttt{ycs@umd.edu} \\
  \And
  Ruijie Zheng$^\dag$ \\
  \texttt{rzheng12@umd.edu} \\
  \And
  Xiangyu Liu$^\dag$ \\
  \texttt{xyliu999@umd.edu} \\
  \And
  Tuomas Sandholm$^{\triangle \nabla}$\\
  % Carnegie Mellon University\\
  % Strategy Robot, Inc.\\
  % Optimized Markets, Inc.\\
  % Strategic Machine, Inc.\\
  \texttt{sandholm@cs.cmu.edu}\\
  \And
  Furong Huang$^\dag$\\
 %  University of Maryland \\
  \texttt{furongh@umd.edu}\\
  \And
  Stephen McAleer$^{\triangle}$\thanks{Corresponding Author,  $^\dag$ University of Maryland, $^\triangle$ Carnegie Mellon University,    $^\nabla$ Strategy Robot, Inc., Optimized Markets, Inc., Strategic Machine, Inc.}\\
 % \thanks{Corresponding author}\\  Carnegie Mellon University\\
  \texttt{smcaleer@cs.cmu.edu}
}

\begin{document}

\maketitle

\begin{abstract}
% Stephen's draft
Robust reinforcement learning (RL) seeks to train policies that can perform well under environment perturbations or adversarial attacks. Existing approaches typically assume that the space of possible perturbations remains the same across timesteps. However, in many settings, the space of possible perturbations at a given timestep depends on past perturbations.  
We formally introduce temporally-coupled perturbations, presenting a novel challenge for existing robust RL methods. To tackle this challenge, we propose \ours, a novel game-theoretic approach that treats the temporally-coupled robust RL problem as a partially-observable two-player zero-sum game. By finding an approximate equilibrium in this game, \ours ensures the agent's robustness against temporally-coupled perturbations. Empirical experiments on a variety of continuous control tasks demonstrate that our proposed approach exhibits significant robustness advantages compared to baselines against both standard and temporally-coupled attacks, in both state and action spaces.


% Recent years have witnessed the development of robust training to defend against the vulnerability of RL policies. Existing threat models impose static constraints on perturbations at each timestep and overlook the temporal influence of past perturbations on the current ones, despite its crucial consideration in many real-world scenarios. 
% We formally introduce temporally-coupled attacks to account for the temporal coupling between perturbations at consecutive time steps, presenting a novel challenge for existing robust RL methods. To tackle this challenge, we propose \ours, a novel game-theoretic response approach that treats the temporally-coupled robust RL problem as a partially-observable two-player game. By finding an approximate equilibrium in our approach, \ours ensures the agent's robustness against the learned adversary. Empirical experiments on a variety of continuous control tasks demonstrate that our proposed approach exhibits significant robustness advantages compared to baselines against both standard and temporally-coupled attacks, in both the state and action spaces.
\end{abstract}

\input{1_intro}
\input{2_relate}
\input{3_prelim}
\input{4_method}
\input{5_exp}
\input{6_discuss}

\section*{Acknowledgements}
We thank Ben Eysenbach for helpful conversations. This material is based upon work supported by the National Science Foundation under Grant $2127309$ to the Computing Research Association for the CIFellows Project.
Liang, Sun, Zheng, Liu and Huang are supported by National Science Foundation NSF-IIS-FAI program, DOD-ONR-Office of Naval Research, DOD Air Force Office of Scientific Research, DOD-DARPA-Defense Advanced Research Projects Agency Guaranteeing AI Robustness against Deception (GARD), Adobe, Capital One and JP Morgan faculty fellowships. The work of Prof. Sandholm's research group is funded by the National Science Foundation under grants IIS1901403, CCF-1733556, and the ARO under award W911NF2210266.
\bibliography{main}

\newpage
\appendix
\input{app_related}
\input{app_exp}

\end{document}
