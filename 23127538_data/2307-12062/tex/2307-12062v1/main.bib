
@article{double_oracle,
  title={Planning in the presence of cost functions controlled by an adversary},
  author={McMahan, H Brendan and Gordon, Geoffrey J and Blum, Avrim},
  journal={Proceedings of the 20th International Conference on Machine Learning (ICML)},
  year={2003}
}

@article{johanson2012finding,
  title={Finding optimal abstract strategies in extensive-form games},
  author={Johanson, Michael and Bard, Nolan and Burch, Neil and Bowling, Michael},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={26},
  number={1},
  year={2012}
}

@article{smith2021iterative,
  title={Iterative Empirical Game Solving via Single Policy Best Response},
  author={Smith, Max Olan and Anthony, Thomas and Wellman, Michael P},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{balduzzi2019open,
  title={Open-ended learning in symmetric zero-sum games},
  author={Balduzzi, David and Garnelo, Marta and Bachrach, Yoram and Czarnecki, Wojciech and Perolat, Julien and Jaderberg, Max and Graepel, Thore},
  journal={International Conference on Machine Learning (ICML)},
  year={2019}
 }
%   pages={434--443},
%   organization={PMLR}

@article{hansen2004dynamic,
  title={Dynamic programming for partially observable stochastic games},
  author={Hansen, Eric A and Bernstein, Daniel S and Zilberstein, Shlomo},
  journal={Conference on Artificial Intelligence (AAAI)},
  year={2004}
}
%   volume={4},
%   pages={709--715},

@article{dinh2021online,
  title={Online Double Oracle},
  author={Dinh, Le Cong and Yang, Yaodong and Tian, Zheng and Nieves, Nicolas Perez and Slumbers, Oliver and Mguni, David Henry and Ammar, Haitham Bou and Wang, Jun},
  journal={arXiv preprint arXiv:2103.07780},
  year={2021}
}

@article{rashid2018qmix,
  title={QMIX: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1803.11485},
  year={2018}
}
@article{bansal2017emergent,
  title={Emergent complexity via multi-agent competition},
  author={Bansal, Trapit and Pachocki, Jakub and Sidor, Szymon and Sutskever, Ilya and Mordatch, Igor},
  journal={arXiv preprint arXiv:1710.03748},
  year={2017}
}

@article{majumdar2020evolutionary,
  title={Evolutionary Reinforcement Learning for Sample-Efficient Multiagent Coordination},
  author={Majumdar, Somdeb and Khadka, Shauharda and Miret, Santiago and Mcaleer, Stephen and Tumer, Kagan},
  journal={International Conference on Machine Learning},
  pages={6651--6660},
  year={2020},
  organization={PMLR}
}
@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  pages={6379--6390},
  year={2017}
}
@inproceedings{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}


@misc{barrage_bots,
  author = {Sam Moore},
  title = {Stratego AI Evaluator},
  year = {2014},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/braathwaate/strategoevaluator}}
}

@article{fp,
  title={Iterative solution of games by fictitious play},
  author={Brown, George W.},
  journal={Activity analysis of production and allocation},
  pages={374-376},
  year={1951}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{brown2015regret,
  title={Regret-Based Pruning in Extensive-Form Games.},
  author={Brown, Noam and Sandholm, Tuomas},
  booktitle={NIPS},
  pages={1972--1980},
  year={2015}
}

@inproceedings{brown2017dynamic,
  title={Dynamic thresholding and pruning for regret minimization},
  author={Brown, Noam and Kroer, Christian and Sandholm, Tuomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  year={2017}
}

@book{shoham2008multiagent,
  title={Multiagent systems: Algorithmic, game-theoretic, and logical foundations},
  author={Shoham, Yoav and Leyton-Brown, Kevin},
  year={2008},
  publisher={Cambridge University Press}
}

@article{gruslys2020advantage,
  title={The Advantage Regret-Matching Actor-Critic},
  author={Gruslys, Audr{\=u}nas and Lanctot, Marc and Munos, R{\'e}mi and Timbers, Finbarr and Schmid, Martin and Perolat, Julien and Morrill, Dustin and Zambaldi, Vinicius and Lespiau, Jean-Baptiste and Schultz, John and others},
  journal={arXiv preprint arXiv:2008.12234},
  year={2020}
}

@article{bowling2002multiagent,
  title={Multiagent learning using a variable learning rate},
  author={Bowling, Michael and Veloso, Manuela},
  journal={Artificial Intelligence},
  volume={136},
  number={2},
  pages={215--250},
  year={2002},
  publisher={Elsevier}
}

@inproceedings{qpg,
  title={Actor-critic policy optimization in partially observable multiagent environments},
  author={Srinivasan, Sriram and Lanctot, Marc and Zambaldi, Vinicius and P{\'e}rolat, Julien and Tuyls, Karl and Munos, R{\'e}mi and Bowling, Michael},
  booktitle={Advances in neural information processing systems},
  pages={3422--3435},
  year={2018}
}

@article{replicator,
  title={Evolutionary stable strategies and game dynamics},
  author={Taylor, Peter D and Jonker, Leo B},
  journal={Mathematical biosciences},
  volume={40},
  number={1-2},
  pages={145--156},
  year={1978},
  publisher={Citeseer}
}

@book{game_tree_complexity,
  title={Searching for solutions in games and artificial intelligence},
  author={Allis, Louis Victor}
}
@article{silver2017mastering1,
	title={Mastering the game of go without human knowledge},
	author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
	journal={Nature},
	volume={550},
	number={7676},
	pages={354},
	year={2017},
	publisher={Nature Publishing Group}
}

@article{silver2017mastering2,
	title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
	author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
	journal={arXiv preprint arXiv:1712.01815},
	year={2017}
}

@article{dota,
  title={Dota 2 with Large Scale Deep Reinforcement Learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Debiak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@book{agt,
  title={Algorithmic Game Theory},
  author={Nisan, Noam and Roughgarden, Tim and Tardos, Eva and Vazirani, Vijay V},
  year={2007},
  publisher={Cambridge University Press}
}

@inproceedings{xfp,
  title={Fictitious self-play in extensive-form games},
  author={Heinrich, Johannes and Lanctot, Marc and Silver, David},
  booktitle={International Conference on Machine Learning},
  pages={805--813},
  year={2015}
}

@article{neurd,
  title={Neural Replicator Dynamics},
  author={Omidshafiei, Shayegan and Hennes, Daniel and Morrill, Dustin and Munos, Remi and Perolat, Julien and Lanctot, Marc and Gruslys, Audrunas and Lespiau, Jean-Baptiste and Tuyls, Karl},
  journal={arXiv preprint arXiv:1906.00190},
  year={2019}
}

@inproceedings{cfr,
  title={Regret minimization in games with incomplete information},
  author={Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2008}
}

@inproceedings{ray,
  title={Ray: A distributed framework for emerging $\{$AI$\}$ applications},
  author={Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I and others},
  booktitle={13th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 18)},
  pages={561--577},
  year={2018}
}

@inproceedings{rllib,
  title={RLlib: Abstractions for Distributed Reinforcement Learning},
  author={Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph and Jordan, Michael and Stoica, Ion},
  booktitle={International Conference on Machine Learning},
  pages={3053--3062},
  year={2018}
}

@article{discrete_sac,
  title={Soft Actor-Critic for Discrete Action Settings},
  author={Christodoulou, Petros},
  journal={arXiv preprint arXiv:1910.07207},
  year={2019}
}

@article{pbt,
  title={Human-level performance in 3D multiplayer games with population-based reinforcement learning},
  author={Jaderberg, Max and Czarnecki, Wojciech M and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C and Morcos, Ari S and Ruderman, Avraham and others},
  journal={Science},
  volume={364},
  number={6443},
  pages={859--865},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{deep_rl,
  title={Deep reinforcement learning: An overview},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1701.07274},
  year={2017}
}

@inproceedings{stratego_bot,
  title={Quiescence search for stratego},
  author={Schadd, Maarten and Winands, Mark},
  booktitle={Proceedings of the 21st Benelux Conference on Artificial Intelligence. Eindhoven, the Netherlands},
  year={2009}
}

@article{stratego_bots,
  title={The 3rd stratego computer world championship},
  author={Jug, Sven and Schadd, Maarten},
  journal={Icga Journal},
  volume={32},
  number={4},
  pages={233},
  year={2009}
}

@inproceedings{sac,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018}
}

@book{theory_of_learning_in_games,
  title={The theory of learning in games},
  author={Fudenberg, Drew and Drew, Fudenberg and Levine, David K and Levine, David K},
  year={1998},
  publisher={The MIT Press}
}

@inproceedings{rectified_psro,
  title={Open-ended learning in symmetric zero-sum games},
  author={Balduzzi, David and Garnelo, Marta and Bachrach, Yoram and Czarnecki, Wojciech and Perolat, Julien and Jaderberg, Max and Graepel, Thore},
  booktitle={International Conference on Machine Learning},
  pages={434--443},
  year={2019}
}

@inproceedings{lanctot2009monte,
  title={Monte Carlo sampling for regret minimization in extensive games},
  author={Lanctot, Marc and Waugh, Kevin and Zinkevich, Martin and Bowling, Michael},
  booktitle={Advances in neural information processing systems},
  pages={1078--1086},
  year={2009}
}

@book{kuhn1953contributions,
  title={Contributions to the Theory of Games},
  author={Kuhn, Harold William and Tucker, Albert William},
  volume={2},
  year={1953},
  publisher={Princeton University Press}
}

@inproceedings{zinkevich2008regret,
  title={Regret minimization in games with incomplete information},
  author={Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2008}
}

@article{lanctot2019openspiel,
  title={OpenSpiel: A framework for reinforcement learning in games},
  author={Lanctot, Marc and Lockhart, Edward and Lespiau, Jean-Baptiste and Zambaldi, Vinicius and Upadhyay, Satyaki and P{\'e}rolat, Julien and Srinivasan, Sriram and Timbers, Finbarr and Tuyls, Karl and Omidshafiei, Shayegan and others},
  journal={arXiv preprint arXiv:1908.09453},
  year={2019}
}

@article{bosansky2014exact,
  title={An exact double-oracle algorithm for zero-sum extensive-form games with imperfect information},
  author={Bosansky, Branislav and Kiekintveld, Christopher and Lisy, Viliam and Pechoucek, Michal},
  journal={Journal of Artificial Intelligence Research},
  volume={51},
  pages={829--866},
  year={2014}
}
@article{wang2021evaluating,
  title={Evaluating Strategy Exploration in Empirical Game-Theoretic Analysis},
  author={Wang, Yongzhao and Ma, Qiurui and Wellman, Michael P},
  journal={International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  year={2022}
}

@inproceedings{wright2019iterated,
  title={Iterated Deep Reinforcement Learning in Games: History-Aware Training for Improved Stability.},
  author={Wright, Mason and Wang, Yongzhao and Wellman, Michael P},
  booktitle={EC},
  pages={617--636},
  year={2019}
}

@article{silver_2017,
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and Driessche, George van den and Graepel, Thore and Hassabis, Demis},
  year = {2017},
  title = {Mastering the game of Go without human knowledge},
  journal = {Nature},
  publisher = {Nature Publishing Group},
  issn = {0028-0836},
  doi = {10.1038/nature24270},
  volume = {550},
  month = {10},
  pages = {354--359},
  number = {7676},
  url = {http:https://doi.org/10.1038/nature24270},
  abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo.}
}

@inproceedings{brown2019solving,
  title={Solving imperfect-information games via discounted regret minimization},
  author={Brown, Noam and Sandholm, Tuomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={1829--1836},
  year={2019}
}
@inproceedings{farina2019stable,
  title={Stable-predictive optimistic counterfactual regret minimization},
  author={Farina, Gabriele and Kroer, Christian and Brown, Noam and Sandholm, Tuomas},
  booktitle={International conference on machine learning},
  pages={1853--1862},
  year={2019},
  organization={PMLR}
}

@inproceedings{zinkevich07ros,
  title = {A New Algorithm for Generating Equilibria in Massive Zero-Sum Games},
  author = {Martin Zinkevich and Michael Bowling and Neil Burch},
  booktitle = {Twenty-Second Conference on Artificial Intelligence (AAAI)},
  year = 2007
}
@inproceedings{auer1995gambling,
  title={Gambling in a rigged casino: The adversarial multi-armed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  booktitle={Proceedings of IEEE 36th Annual Foundations of Computer Science},
  pages={322--331},
  year={1995},
  organization={IEEE}
}
@article{zhang2021subgame,
  title={Subgame solving without common knowledge},
  author={Zhang, Brian and Sandholm, Tuomas},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23993--24004},
  year={2021}
}
@article{mcaleer2022escher,
  title={ESCHER: Eschewing Importance Sampling in Games by Computing a History Value Function to Estimate Regret},
  author={McAleer, Stephen and Farina, Gabriele and Lanctot, Marc and Sandholm, Tuomas},
  journal={International Conference on Learning Representations},
  year={2023}
}

@inproceedings{hansen2008range,
  title={On Range of Skill.},
  author={Hansen, Thomas Dueholm and Miltersen, Peter Bro and S{\o}rensen, Troels Bjerre},
  booktitle={AAAI},
  pages={277--282},
  year={2008}
}

@article{hansen08onros,
  title = {On Range of Skill},
  author = {Thomas Dueholm Hansen and Peter Bro Miltersen and Troels Bjerre Sørensen},
  journal = {Conference on Artificial Intelligence (AAAI)},
  year = 2008
}


@InProceedings{johanson12cfrbr,
  Title = "Finding Optimal Abstract Strategies in Extensive Form Games",
  Author = "Michael Johanson and Nolan Bard and Neil Burch and Michael Bowling",
  Booktitle = "Conference on Artificial Intelligence (AAAI)",
  Year = "2012",
}

@inproceedings{jordan2010strategy,
  title={Strategy exploration in empirical games},
  author={Jordan, Patrick R and Schvartzman, L Julian and Wellman, Michael P},
  booktitle={9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  year={2010},
  organization={Citeseer}
}

@article{hart2000simple,
  title={A simple adaptive procedure leading to correlated equilibrium},
  author={Hart, Sergiu and Mas-Colell, Andreu},
  journal={Econometrica},
  volume={68},
  number={5},
  pages={1127--1150},
  year={2000},
  publisher={Wiley Online Library}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI conference on artificial intelligence},
  volume={30},
  year={2016}
}

@article{wellman2006methods,
  title={Methods for empirical game-theoretic analysis},
  author={Wellman, Michael P},
   journal={AAAI conference on artificial intelligence},
  year={2006}
}

@book{lattimore_szepesvari_2020, place={Cambridge}, title={Bandit Algorithms}, DOI={10.1017/9781108571401}, publisher={Cambridge University Press}, author={Lattimore, Tor and Szepesvári, Csaba}, year={2020}}

@book{cesa2006prediction,
  title={Prediction, learning, and games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge university press}
}
@article{slumbers2022learning,
  title={Learning Risk-Averse Equilibria in Multi-Agent Systems},
  author={Slumbers, Oliver and Mguni, David Henry and McAleer, Stephen and Wang, Jun and Yang, Yaodong},
  journal={arXiv preprint arXiv:2205.15434},
  year={2022}
}
@article{lanier2022feasible,
  title={Feasible Adversarial Robust Reinforcement Learning for Underspecified Environments},
  author={Lanier, JB and McAleer, Stephen and Baldi, Pierre and Fox, Roy},
  journal={arXiv preprint arXiv:2207.09597},
  year={2022}
}
@article{liu2021towards,
  title={Towards unifying behavioral and response diversity for open-ended learning in zero-sum games},
  author={Liu, Xiangyu and Jia, Hangtian and Wen, Ying and Hu, Yujing and Chen, Yingfeng and Fan, Changjie and Hu, Zhipeng and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={941--952},
  year={2021}
}
@inproceedings{perez2021modelling,
  title={Modelling behavioural diversity for learning in open-ended games},
  author={Perez-Nieves, Nicolas and Yang, Yaodong and Slumbers, Oliver and Mguni, David H and Wen, Ying and Wang, Jun},
  booktitle={International Conference on Machine Learning},
  pages={8514--8524},
  year={2021},
  organization={PMLR}
}

@article{mcaleer2022self,
  title={Self-Play PSRO: Toward Optimal Populations in Two-Player Zero-Sum Games},
  author={McAleer, Stephen and Lanier, JB and Wang, Kevin and Baldi, Pierre and Fox, Roy and Sandholm, Tuomas},
  journal={arXiv preprint arXiv:2207.06541},
  year={2022}
}
@article{sokota2022unified,
  title={A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games},
  author={Sokota, Samuel and D'Orazio, Ryan and Kolter, J Zico and Loizou, Nicolas and Lanctot, Marc and Mitliagkas, Ioannis and Brown, Noam and Kroer, Christian},
  journal={arXiv preprint arXiv:2206.05825},
  year={2022}
}

@inproceedings{brown2019deep,
  title={Deep counterfactual regret minimization},
  author={Brown, Noam and Lerer, Adam and Gross, Sam and Sandholm, Tuomas},
  booktitle={International conference on machine learning},
  pages={793--802},
  year={2019},
  organization={PMLR}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}
@article{freund1999adaptive,
  title={Adaptive game playing using multiplicative weights},
  author={Freund, Yoav and Schapire, Robert E},
  journal={Games and Economic Behavior},
  volume={29},
  number={1-2},
  pages={79--103},
  year={1999},
  publisher={Elsevier}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo},
  journal={arXiv preprint arXiv:1204.5721},
  year={2012}
}


@article{johanson2012finding,
  title={Finding optimal abstract strategies in extensive-form games},
  author={Johanson, Michael and Bard, Nolan and Burch, Neil and Bowling, Michael},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={26},
  number={1},
  year={2012}
}
@article{li2018double,
  title={Double neural counterfactual regret minimization},
  author={Li, Hui and Hu, Kailiang and Ge, Zhibang and Jiang, Tao and Qi, Yuan and Song, Le},
  journal={arXiv preprint arXiv:1812.10607},
  year={2018}
}

@article{kovavrik2022rethinking,
  title={Rethinking formal models of partially observable multiagent decision making},
  author={Kova{\v{r}}{\'\i}k, Vojt{\v{e}}ch and Schmid, Martin and Burch, Neil and Bowling, Michael and Lis{\`y}, Viliam},
  journal={Artificial Intelligence},
  volume={303},
  pages={103645},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{li2019double,
  title={Double Neural Counterfactual Regret Minimization},
  author={Li, Hui and Hu, Kailiang and Zhang, Shaohua and Qi, Yuan and Song, Le},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{burch2012efficient,
  title={Efficient Monte Carlo counterfactual regret minimization in games with many player actions},
  author={Burch, Neil and Lanctot, Marc and Szafron, Duane and Gibson, Richard},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}
@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}
@book{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994},
  publisher={Citeseer}
}
@article{srinivasan2018actor,
  title={Actor-critic policy optimization in partially observable multiagent environments},
  author={Srinivasan, Sriram and Lanctot, Marc and Zambaldi, Vinicius and P{\'e}rolat, Julien and Tuyls, Karl and Munos, R{\'e}mi and Bowling, Michael},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@inproceedings{hennes2020neural,
  title={Neural replicator dynamics: Multiagent learning via hedging policy gradients},
  author={Hennes, Daniel and Morrill, Dustin and Omidshafiei, Shayegan and Munos, R{\'e}mi and Perolat, Julien and Lanctot, Marc and Gruslys, Audrunas and Lespiau, Jean-Baptiste and Parmas, Paavo and Du{\'e}{\~n}ez-Guzm{\'a}n, Edgar and others},
  booktitle={Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={492--501},
  year={2020}
}
@inproceedings{perolat2021poincare,
  title={From {P}oincar{\'e} recurrence to convergence in imperfect information games: Finding equilibrium via regularization},
  author={Perolat, Julien and Munos, Remi and Lespiau, Jean-Baptiste and Omidshafiei, Shayegan and Rowland, Mark and Ortega, Pedro and Burch, Neil and Anthony, Thomas and Balduzzi, David and De Vylder, Bart and others},
  booktitle={International Conference on Machine Learning},
  pages={8525--8535},
  year={2021},
  organization={PMLR}
}

@article{steinberger2019single,
  title={Single deep counterfactual regret minimization},
  author={Steinberger, Eric},
  journal={arXiv preprint arXiv:1901.07621},
  year={2019}
}

@article{mcaleer2021xdo,
  title={{XDO}: A double oracle algorithm for extensive-form games},
  author={McAleer, Stephen and Lanier, John and Baldi, Pierre and Fox, Roy},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}
@article{smith2021iterative,
  title={Iterative Empirical Game Solving via Single Policy Best Response},
  author={Smith, Max Olan and Anthony, Thomas and Wellman, Michael P},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{balduzzi2019open,
  title={Open-ended learning in symmetric zero-sum games},
  author={Balduzzi, David and Garnelo, Marta and Bachrach, Yoram and Czarnecki, Wojciech and Perolat, Julien and Jaderberg, Max and Graepel, Thore},
  journal={International Conference on Machine Learning (ICML)},
  year={2019}
 }
%   pages={434--443},
%   organization={PMLR}

@article{hansen2004dynamic,
  title={Dynamic programming for partially observable stochastic games},
  author={Hansen, Eric A and Bernstein, Daniel S and Zilberstein, Shlomo},
  journal={Conference on Artificial Intelligence (AAAI)},
  year={2004}
}
%   volume={4},
%   pages={709--715},

@article{dinh2021online,
  title={Online Double Oracle},
  author={Dinh, Le Cong and Yang, Yaodong and Tian, Zheng and Nieves, Nicolas Perez and Slumbers, Oliver and Mguni, David Henry and Ammar, Haitham Bou and Wang, Jun},
  journal={arXiv preprint arXiv:2103.07780},
  year={2021}
}

@article{feng2021discovering,
  title={Discovering Multi-Agent Auto-Curricula in Two-Player Zero-Sum Games},
  author={Feng, Xidong and Slumbers, Oliver and Yang, Yaodong and Wan, Ziyu and Liu, Bo and McAleer, Stephen and Wen, Ying and Wang, Jun},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}


@article{rashid2018qmix,
  title={QMIX: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1803.11485},
  year={2018}
}
@article{bansal2017emergent,
  title={Emergent complexity via multi-agent competition},
  author={Bansal, Trapit and Pachocki, Jakub and Sidor, Szymon and Sutskever, Ilya and Mordatch, Igor},
  journal={arXiv preprint arXiv:1710.03748},
  year={2017}
}

@article{majumdar2020evolutionary,
  title={Evolutionary Reinforcement Learning for Sample-Efficient Multiagent Coordination},
  author={Majumdar, Somdeb and Khadka, Shauharda and Miret, Santiago and Mcaleer, Stephen and Tumer, Kagan},
  journal={International Conference on Machine Learning},
  pages={6651--6660},
  year={2020},
  organization={PMLR}
}
@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  pages={6379--6390},
  year={2017}
}
@inproceedings{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}


@misc{barrage_bots,
  author = {Sam Moore},
  title = {Stratego AI Evaluator},
  year = {2014},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/braathwaate/strategoevaluator}}
}

@article{fp,
  title={Iterative solution of games by fictitious play},
  author={Brown, George W.},
  journal={Activity analysis of production and allocation},
  pages={374-376},
  year={1951}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{brown2015regret,
  title={Regret-Based Pruning in Extensive-Form Games.},
  author={Brown, Noam and Sandholm, Tuomas},
  booktitle={NIPS},
  pages={1972--1980},
  year={2015}
}

@inproceedings{brown2017dynamic,
  title={Dynamic thresholding and pruning for regret minimization},
  author={Brown, Noam and Kroer, Christian and Sandholm, Tuomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  year={2017}
}

@inproceedings{rllib,
  title={RLlib: Abstractions for Distributed Reinforcement Learning},
  author={Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph and Jordan, Michael and Stoica, Ion},
  booktitle={International Conference on Machine Learning},
  pages={3053--3062},
  year={2018}
}

@book{shoham2008multiagent,
  title={Multiagent systems: Algorithmic, game-theoretic, and logical foundations},
  author={Shoham, Yoav and Leyton-Brown, Kevin},
  year={2008},
  publisher={Cambridge University Press}
}
@article{bowling2015heads,
  title={Heads-up limit hold’em poker is solved},
  author={Bowling, Michael and Burch, Neil and Johanson, Michael and Tammelin, Oskari},
  journal={Science},
  volume={347},
  number={6218},
  pages={145--149},
  year={2015},
  publisher={American Association for the Advancement of Science}
}
@article{brown2019superhuman,
  title={Superhuman {AI} for multiplayer poker},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={365},
  number={6456},
  pages={885--890},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{liu2022model,
  title={Model-free neural counterfactual regret minimization with bootstrap learning},
  author={Liu, Weiming and Li, Bin and Togelius, Julian},
  journal={IEEE Transactions on Games},
  year={2022},
  publisher={IEEE}
}

@article{steinberger2020dream,
  title={{DREAM}: Deep Regret minimization with Advantage baselines and Model-free learning},
  author={Steinberger, Eric and Lerer, Adam and Brown, Noam},
  journal={arXiv preprint arXiv:2006.10410},
  year={2020}
}

@article{bowling2002multiagent,
  title={Multiagent learning using a variable learning rate},
  author={Bowling, Michael and Veloso, Manuela},
  journal={Artificial Intelligence},
  volume={136},
  number={2},
  pages={215--250},
  year={2002},
  publisher={Elsevier}
}

@inproceedings{qpg,
  title={Actor-critic policy optimization in partially observable multiagent environments},
  author={Srinivasan, Sriram and Lanctot, Marc and Zambaldi, Vinicius and P{\'e}rolat, Julien and Tuyls, Karl and Munos, R{\'e}mi and Bowling, Michael},
  booktitle={Advances in neural information processing systems},
  pages={3422--3435},
  year={2018}
}

@article{replicator,
  title={Evolutionary stable strategies and game dynamics},
  author={Taylor, Peter D and Jonker, Leo B},
  journal={Mathematical biosciences},
  volume={40},
  number={1-2},
  pages={145--156},
  year={1978},
  publisher={Citeseer}
}

@book{game_tree_complexity,
  title={Searching for solutions in games and artificial intelligence},
  author={Allis, Louis Victor}
}

@inproceedings{deep_cfr,
  title={Deep Counterfactual Regret Minimization},
  author={Brown, Noam and Lerer, Adam and Gross, Sam and Sandholm, Tuomas},
  booktitle={International Conference on Machine Learning},
  pages={793--802},
  year={2019}
}

@article{silver2017mastering1,
	title={Mastering the game of go without human knowledge},
	author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
	journal={Nature},
	volume={550},
	number={7676},
	pages={354},
	year={2017},
	publisher={Nature Publishing Group}
}

@article{silver2017mastering2,
	title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
	author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
	journal={arXiv preprint arXiv:1712.01815},
	year={2017}
}

@article{dota,
  title={Dota 2 with Large Scale Deep Reinforcement Learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Debiak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@inproceedings{psro,
  title={A unified game-theoretic approach to multiagent reinforcement learning},
  author={Lanctot, Marc and Zambaldi, Vinicius and Gruslys, Audrunas and Lazaridou, Angeliki and Tuyls, Karl and P{\'e}rolat, Julien and Silver, David and Graepel, Thore},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@book{agt,
  title={Algorithmic Game Theory},
  author={Nisan, Noam and Roughgarden, Tim and Tardos, Eva and Vazirani, Vijay V},
  year={2007},
  publisher={Cambridge University Press}
}

@inproceedings{xfp,
  title={Fictitious self-play in extensive-form games},
  author={Heinrich, Johannes and Lanctot, Marc and Silver, David},
  booktitle={International Conference on Machine Learning},
  pages={805--813},
  year={2015}
}

@article{neurd,
  title={Neural Replicator Dynamics},
  author={Omidshafiei, Shayegan and Hennes, Daniel and Morrill, Dustin and Munos, Remi and Perolat, Julien and Lanctot, Marc and Gruslys, Audrunas and Lespiau, Jean-Baptiste and Tuyls, Karl},
  journal={arXiv preprint arXiv:1906.00190},
  year={2019}
}

@inproceedings{cfr,
  title={Regret minimization in games with incomplete information},
  author={Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2008}
}

@inproceedings{ray,
  title={Ray: A distributed framework for emerging $\{$AI$\}$ applications},
  author={Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I and others},
  booktitle={13th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 18)},
  pages={561--577},
  year={2018}
}
@inproceedings{pinto2017robust,
  title={Robust adversarial reinforcement learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  booktitle={International Conference on Machine Learning},
  pages={2817--2826},
  year={2017},
  organization={PMLR}
}
@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}
@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{brown2018depth,
  title={Depth-limited solving for imperfect-information games},
  author={Brown, Noam and Sandholm, Tuomas and Amos, Brandon},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{moravvcik2017deepstack,
  title={Deepstack: Expert-level artificial intelligence in heads-up no-limit poker},
  author={Morav{\v{c}}{\'\i}k, Matej and Schmid, Martin and Burch, Neil and Lis{\`y}, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
  journal={Science},
  volume={356},
  number={6337},
  pages={508--513},
  year={2017},
  publisher={American Association for the Advancement of Science}
}
@inproceedings{gray2020human,
  title={Human-Level Performance in No-Press Diplomacy via Equilibrium Search},
  author={Gray, Jonathan and Lerer, Adam and Bakhtin, Anton and Brown, Noam},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@article{brown2020combining,
  title={Combining deep reinforcement learning and search for imperfect-information games},
  author={Brown, Noam and Bakhtin, Anton and Lerer, Adam and Gong, Qucheng},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17057--17069},
  year={2020}
}
@article{brown2017safe,
  title={Safe and nested subgame solving for imperfect-information games},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{moravcik2016refining,
  title={Refining subgames in large imperfect information games},
  author={Moravcik, Matej and Schmid, Martin and Ha, Karel and Hladik, Milan and Gaukrodger, Stephen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  year={2016}
}
@inproceedings{burch2014solving,
  title={Solving imperfect information games using decomposition},
  author={Burch, Neil and Johanson, Michael and Bowling, Michael},
  booktitle={Twenty-eighth AAAI conference on artificial intelligence},
  year={2014}
}

@inproceedings{farina2019regret,
   title={Regret Circuits: Composability of Regret Minimizers},
   author={Farina, Gabriele and Kroer, Christian and Sandholm, Tuomas},
   booktitle={International Conference on Machine Learning},
   year={2019}
 }
 
 @inproceedings{farina2019online,
   title={Online Convex Optimization for Sequential Decision Processes and Extensive-Form Games},
   author={Farina, Gabriele and Kroer, Christian and Sandholm, Tuomas},
   booktitle={AAAI Conference on Artificial Intelligence},
   year={2019}
 }
@inproceedings{farina2020stochastic,
   title={Stochastic Regret Minimization in Extensive-Form Games},
   author={Farina, Gabriele and Kroer, Christian and Sandholm, Tuomas},
   booktitle={International Conference on Machine Learning},
   year={2020}
 }

@article{serrino2019finding,
  title={Finding friend and foe in multi-agent games},
  author={Serrino, Jack and Kleiman-Weiner, Max and Parkes, David C and Tenenbaum, Josh},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@article{daskalakis2020independent,
  title={Independent policy gradient methods for competitive reinforcement learning},
  author={Daskalakis, Constantinos and Foster, Dylan J and Golowich, Noah},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={5527--5540},
  year={2020}
}
@article{jin2021v,
  title={V-Learning--A Simple, Efficient, Decentralized Algorithm for Multiagent RL},
  author={Jin, Chi and Liu, Qinghua and Wang, Yuanhao and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2110.14555},
  year={2021}
}
@article{ding2022independent,
  title={Independent policy gradient for large-scale Markov potential games: Sharper rates, function approximation, and game-agnostic convergence},
  author={Ding, Dongsheng and Wei, Chen-Yu and Zhang, Kaiqing and Jovanovi{\'c}, Mihailo R},
  journal={arXiv preprint arXiv:2202.04129},
  year={2022}
}
@article{leonardos2021global,
  title={Global convergence of multi-agent policy gradient in markov potential games},
  author={Leonardos, Stefanos and Overman, Will and Panageas, Ioannis and Piliouras, Georgios},
  journal={arXiv preprint arXiv:2106.01969},
  year={2021}
}
@inproceedings{mguni2021learning,
  title={Learning in nonzero-sum stochastic games with potentials},
  author={Mguni, David H and Wu, Yutong and Du, Yali and Yang, Yaodong and Wang, Ziyi and Li, Minne and Wen, Ying and Jennings, Joel and Wang, Jun},
  booktitle={International Conference on Machine Learning},
  pages={7688--7699},
  year={2021},
  organization={PMLR}
}
@inproceedings{fox2022independent,
  title={Independent natural policy gradient always converges in Markov potential games},
  author={Fox, Roy and Mcaleer, Stephen M and Overman, Will and Panageas, Ioannis},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4414--4425},
  year={2022},
  organization={PMLR}
}

@article{perolat2022mastering,
  title={Mastering the Game of Stratego with Model-Free Multiagent Reinforcement Learning},
  author={Perolat, Julien and de Vylder, Bart and Hennes, Daniel and Tarassov, Eugene and Strub, Florian and de Boer, Vincent and Muller, Paul and Connor, Jerome T and Burch, Neil and Anthony, Thomas and others},
  journal={arXiv preprint arXiv:2206.15378},
  year={2022}
}

@article{zhang2021gradient,
  title={Gradient play in stochastic games: stationary points, convergence, and sample complexity},
  author={Zhang, Runyu and Ren, Zhaolin and Li, Na},
  journal={arXiv preprint arXiv:2106.00198},
  year={2021}
}
@article{wurman2022outracing,
  title={Outracing champion Gran Turismo drivers with deep reinforcement learning},
  author={Wurman, Peter R and Barrett, Samuel and Kawamoto, Kenta and MacGlashan, James and Subramanian, Kaushik and Walsh, Thomas J and Capobianco, Roberto and Devlic, Alisa and Eckert, Franziska and Fuchs, Florian and others},
  journal={Nature},
  volume={602},
  number={7896},
  pages={223--228},
  year={2022},
  publisher={Nature Publishing Group}
}
@inproceedings{perolat2018actor,
  title={Actor-critic fictitious play in simultaneous move multistage games},
  author={Perolat, Julien and Piot, Bilal and Pietquin, Olivier},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={919--928},
  year={2018},
  organization={PMLR}
}
@inproceedings{tuyls2018generalised,
  title={A Generalised Method for Empirical Game Theoretic Analysis},
  author={Tuyls, Karl and Perolat, Julien and Lanctot, Marc and Leibo, Joel Z and Graepel, Thore},
  booktitle={Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={77--85},
  year={2018}
}
@inproceedings{muller2019generalized,
  title={A Generalized Training Approach for Multiagent Learning},
  author={Muller, Paul and Omidshafiei, Shayegan and Rowland, Mark and Tuyls, Karl and Perolat, Julien and Liu, Siqi and Hennes, Daniel and Marris, Luke and Lanctot, Marc and Hughes, Edward and others},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@article{mcaleer2022anytime,
  title={Anytime Optimal PSRO for Two-Player Zero-Sum Games},
  author={McAleer, Stephen and Wang, Kevin and Lanctot, Marc and Lanier, John and Baldi, Pierre and Fox, Roy},
  journal={arXiv preprint arXiv:2201.07700},
  year={2022}
}


@article{morimoto2005robust,
  title={Robust reinforcement learning},
  author={Morimoto, Jun and Doya, Kenji},
  journal={Neural computation},
  volume={17},
  number={2},
  pages={335--359},
  year={2005},
  publisher={MIT Press}
}

@inproceedings{brown2017libratus,
  title={Libratus: The Superhuman {AI} for No-Limit Poker.},
  author={Brown, Noam and Sandholm, Tuomas},
  booktitle={IJCAI},
  pages={5226--5228},
  year={2017}
}

@article{discrete_sac,
  title={Soft Actor-Critic for Discrete Action Settings},
  author={Christodoulou, Petros},
  journal={arXiv preprint arXiv:1910.07207},
  year={2019}
}

@article{pbt,
  title={Human-level performance in 3D multiplayer games with population-based reinforcement learning},
  author={Jaderberg, Max and Czarnecki, Wojciech M and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C and Morcos, Ari S and Ruderman, Avraham and others},
  journal={Science},
  volume={364},
  number={6443},
  pages={859--865},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{deep_rl,
  title={Deep reinforcement learning: An overview},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1701.07274},
  year={2017}
}

@inproceedings{stratego_bot,
  title={Quiescence search for stratego},
  author={Schadd, Maarten and Winands, Mark},
  booktitle={Proceedings of the 21st Benelux Conference on Artificial Intelligence. Eindhoven, the Netherlands},
  year={2009}
}

@article{stratego_bots,
  title={The 3rd stratego computer world championship},
  author={Jug, Sven and Schadd, Maarten},
  journal={Icga Journal},
  volume={32},
  number={4},
  pages={233},
  year={2009}
}
@inproceedings{xie2020learning,
  title={Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={Conference on learning theory},
  pages={3674--3682},
  year={2020},
  organization={PMLR}
}
@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Oct},
  pages={213--231},
  year={2002}
}
@article{wei2017online,
  title={Online reinforcement learning in stochastic games},
  author={Wei, Chen-Yu and Hong, Yi-Te and Lu, Chi-Jen},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{brown2018superhuman,
  title={Superhuman {AI} for heads-up no-limit poker: Libratus beats top professionals},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={359},
  number={6374},
  pages={418--424},
  year={2018},
  publisher={American Association for the Advancement of Science}
}
@article{schmid2021player,
  title={Player of games},
  author={Schmid, Martin and Moravcik, Matej and Burch, Neil and Kadlec, Rudolf and Davidson, Josh and Waugh, Kevin and Bard, Nolan and Timbers, Finbarr and Lanctot, Marc and Holland, Zach and others},
  journal={arXiv preprint arXiv:2112.03178},
  year={2021}
}
@inproceedings{zha2021douzero,
  title={Douzero: Mastering doudizhu with self-play deep reinforcement learning},
  author={Zha, Daochen and Xie, Jingru and Ma, Wenye and Zhang, Sheng and Lian, Xiangru and Hu, Xia and Liu, Ji},
  booktitle={International Conference on Machine Learning},
  pages={12333--12344},
  year={2021},
  organization={PMLR}
}
@article{li2020suphx,
  title={Suphx: Mastering mahjong with deep reinforcement learning},
  author={Li, Junjie and Koyamada, Sotetsu and Ye, Qiwei and Liu, Guoqing and Wang, Chao and Yang, Ruihan and Zhao, Li and Qin, Tao and Liu, Tie-Yan and Hon, Hsiao-Wuen},
  journal={arXiv preprint arXiv:2003.13590},
  year={2020}
}


@inproceedings{sac,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018}
}

@book{theory_of_learning_in_games,
  title={The theory of learning in games},
  author={Fudenberg, Drew and Drew, Fudenberg and Levine, David K and Levine, David K},
  year={1998},
  publisher={The MIT Press}
}

@article{nfsp,
  title={Deep reinforcement learning from self-play in imperfect-information games},
  author={Heinrich, Johannes and Silver, David},
  journal={arXiv preprint arXiv:1603.01121},
  year={2016}
}

@inproceedings{rectified_psro,
  title={Open-ended learning in symmetric zero-sum games},
  author={Balduzzi, David and Garnelo, Marta and Bachrach, Yoram and Czarnecki, Wojciech and Perolat, Julien and Jaderberg, Max and Graepel, Thore},
  booktitle={International Conference on Machine Learning},
  pages={434--443},
  year={2019}
}

@article{alphastar,
  title={Grandmaster level in {StarCraft II} using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{lanctot2009monte,
  title={Monte Carlo sampling for regret minimization in extensive games},
  author={Lanctot, Marc and Waugh, Kevin and Zinkevich, Martin and Bowling, Michael},
  booktitle={Advances in neural information processing systems},
  pages={1078--1086},
  year={2009}
}

@book{kuhn1953contributions,
  title={Contributions to the Theory of Games},
  author={Kuhn, Harold William and Tucker, Albert William},
  volume={2},
  year={1953},
  publisher={Princeton University Press}
}

@inproceedings{zinkevich2008regret,
  title={Regret minimization in games with incomplete information},
  author={Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2008}
}

@inproceedings{mcaleer2020pipeline,
  title={Pipeline {PSRO}: A Scalable Approach for Finding Approximate {Nash} Equilibria in Large Games},
  author={McAleer, Stephen and Lanier, John and Fox, Roy and Baldi, Pierre},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{lanctot2019openspiel,
  title={OpenSpiel: A framework for reinforcement learning in games},
  author={Lanctot, Marc and Lockhart, Edward and Lespiau, Jean-Baptiste and Zambaldi, Vinicius and Upadhyay, Satyaki and P{\'e}rolat, Julien and Srinivasan, Sriram and Timbers, Finbarr and Tuyls, Karl and Omidshafiei, Shayegan and others},
  journal={arXiv preprint arXiv:1908.09453},
  year={2019}
}

@article{bosansky2014exact,
  title={An exact double-oracle algorithm for zero-sum extensive-form games with imperfect information},
  author={Bosansky, Branislav and Kiekintveld, Christopher and Lisy, Viliam and Pechoucek, Michal},
  journal={Journal of Artificial Intelligence Research},
  volume={51},
  pages={829--866},
  year={2014}
}
@article{wang2021evaluating,
  title={Evaluating Strategy Exploration in Empirical Game-Theoretic Analysis},
  author={Wang, Yongzhao and Ma, Qiurui and Wellman, Michael P},
  journal={International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  year={2022}
}

@inproceedings{wright2019iterated,
  title={Iterated Deep Reinforcement Learning in Games: History-Aware Training for Improved Stability.},
  author={Wright, Mason and Wang, Yongzhao and Wellman, Michael P},
  booktitle={EC},
  pages={617--636},
  year={2019}
}

@article{silver_2017,
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and Driessche, George van den and Graepel, Thore and Hassabis, Demis},
  year = {2017},
  title = {Mastering the game of Go without human knowledge},
  journal = {Nature},
  publisher = {Nature Publishing Group},
  issn = {0028-0836},
  doi = {10.1038/nature24270},
  volume = {550},
  month = {10},
  pages = {354--359},
  number = {7676},
  url = {http:https://doi.org/10.1038/nature24270},
  abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo.}
}
@inproceedings{brown2019solving,
  title={Solving imperfect-information games via discounted regret minimization},
  author={Brown, Noam and Sandholm, Tuomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={1829--1836},
  year={2019}
}
@inproceedings{farina2019stable,
  title={Stable-predictive optimistic counterfactual regret minimization},
  author={Farina, Gabriele and Kroer, Christian and Brown, Noam and Sandholm, Tuomas},
  booktitle={International conference on machine learning},
  pages={1853--1862},
  year={2019},
  organization={PMLR}
}
@article{zhang2021subgame,
  title={Subgame solving without common knowledge},
  author={Zhang, Brian and Sandholm, Tuomas},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{zinkevich07ros,
  title = {A New Algorithm for Generating Equilibria in Massive Zero-Sum Games},
  author = {Martin Zinkevich and Michael Bowling and Neil Burch},
  booktitle = {Twenty-Second Conference on Artificial Intelligence (AAAI)},
  year = 2007
}
@inproceedings{auer1995gambling,
  title={Gambling in a rigged casino: The adversarial multi-armed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  booktitle={Proceedings of IEEE 36th Annual Foundations of Computer Science},
  pages={322--331},
  year={1995},
  organization={IEEE}
}

@inproceedings{hansen2008range,
  title={On Range of Skill.},
  author={Hansen, Thomas Dueholm and Miltersen, Peter Bro and S{\o}rensen, Troels Bjerre},
  booktitle={AAAI},
  pages={277--282},
  year={2008}
}

@article{hansen08onros,
  title = {On Range of Skill},
  author = {Thomas Dueholm Hansen and Peter Bro Miltersen and Troels Bjerre Sørensen},
  journal = {Conference on Artificial Intelligence (AAAI)},
  year = 2008
}


@InProceedings{johanson12cfrbr,
  Title = "Finding Optimal Abstract Strategies in Extensive Form Games",
  Author = "Michael Johanson and Nolan Bard and Neil Burch and Michael Bowling",
  Booktitle = "Conference on Artificial Intelligence (AAAI)",
  Year = "2012",
}

@inproceedings{jordan2010strategy,
  title={Strategy exploration in empirical games},
  author={Jordan, Patrick R and Schvartzman, L Julian and Wellman, Michael P},
  booktitle={9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  year={2010},
  organization={Citeseer}
}

@article{hart2000simple,
  title={A simple adaptive procedure leading to correlated equilibrium},
  author={Hart, Sergiu and Mas-Colell, Andreu},
  journal={Econometrica},
  volume={68},
  number={5},
  pages={1127--1150},
  year={2000},
  publisher={Wiley Online Library}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}

@article{wellman2006methods,
  title={Methods for empirical game-theoretic analysis},
  author={Wellman, Michael P},
   journal={AAAI conference on artificial intelligence},
  year={2006}
}

@book{lattimore_szepesvari_2020, place={Cambridge}, title={Bandit Algorithms}, DOI={10.1017/9781108571401}, publisher={Cambridge University Press}, author={Lattimore, Tor and Szepesvári, Csaba}, year={2020}}

@book{cesa2006prediction,
  title={Prediction, learning, and games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge university press}
}

@article{freund1999adaptive,
  title={Adaptive game playing using multiplicative weights},
  author={Freund, Yoav and Schapire, Robert E},
  journal={Games and Economic Behavior},
  volume={29},
  number={1-2},
  pages={79--103},
  year={1999},
  publisher={Elsevier}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo},
  journal={arXiv preprint arXiv:1204.5721},
  year={2012}
}

@book{OsborneRubinstein94,
  title = {A Course in Game Theory},
  author = {Martin J. Osborne and Ariel Rubinstein},
  year = 1994,
  publisher = {MIT Press}
}

@inproceedings{Schmid19VRMCCFR,
  title =       {Variance Reduction in Monte Carlo Counterfactual Regret Minimization ({VR-MCCFR}) for Extensive Form Games using Baselines},
  author =      {Martin Schmid and Neil Burch and Marc Lanctot and Matej Moravcik and Rudolf Kadlec and Michael Bowling},
  booktitle =   {Proceedings of the The Thirty-Third AAAI Conference on Artificial Intelligence},
  year =        {2019},
}

@inproceedings{ach,
  title =       {Actor-Critic Policy Optimization in a Large-Scale Imperfect-Information Game },
  author =      {Haobo Fu and Weiming Liu and Shuang Wu and Yijia Wang and Tao Yang and Kai Li and Junliang Xing and Bin Li and Bo Ma and Qiang Fu and Yang Wei},
  booktitle =   {Proceedings of the Tenth International Conference on Learning Representations (ICLR)},
  year =        {2022},
}

@inproceedings{Gibson12probing,
  title =     {Generalized Sampling and Variance in Counterfactual Regret Minimization},
  author =    {Richard Gibson and Marc Lanctot and Neil Burch and Duane Szafron and Michael Bowling},
  booktitle = {Proceedings of the Twenty-Sixth Conference on Artificial Intelligence (AAAI-12).},
  pages =     {1355--1361},
  year =      {2012},
  AcceptNumbers = {294 of 1129},
  AcceptRate = {26\%}
}

@article{Davis19,
  author    = {Trevor Davis and
               Martin Schmid and
               Michael Bowling},
  title     = {Low-Variance and Zero-Variance Baselines for Extensive-Form Games},
  journal   = {CoRR},
  volume    = {abs/1907.09633},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.09633},
  eprinttype = {arXiv},
  eprint    = {1907.09633},
  timestamp = {Sun, 06 Sep 2020 22:24:20 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-09633.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Farina21:Faster,
   title={Faster Game Solving via Predictive Blackwell Approachability: Connecting Regret Matching and Mirror Descent},
   author={Farina, Gabriele and Kroer, Christian and Sandholm, Tuomas},
   booktitle=AAAI,
   year={2021}
 }

@inproceedings{Gordon07:NoRegret,
   title={No-regret algorithms for online convex programs},
   author={Gordon, Geoffrey},
   booktitle=NIPS,
   year={2007}
 }
@inproceedings{zhang2020robust,
  author = {Zhang, Huan and Chen, Hongge  and Xiao, Chaowei and Li, Bo and Liu, Mingyan and Boning, Duane and Hsieh, Cho-Jui},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {21024--21037},
 publisher = {Curran Associates, Inc.},
 title = {Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations},
 url = {https://proceedings.neurips.cc/paper/2020/file/f0eb6568ea114ba6e293f903c34d7488-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{sun2021strongest,
  author    = {Yanchao Sun and
               Ruijie Zheng and
               Yongyuan Liang and
               Furong Huang},
  title     = {Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion
               Attacks in Deep {RL}},
  booktitle = {International Conference on Learning Representations},
  year      = {2022}
}

@inproceedings{zhang2021robust,
title={Robust Reinforcement Learning on State Observations with Learned Optimal Adversary},
author={Huan Zhang and Hongge Chen and Duane S Boning and Cho-Jui Hsieh},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=sCZbhBvqQaU}
}

@inproceedings{tessler2019action,
  title={Action robust reinforcement learning and applications in continuous control},
  author={Tessler, Chen and Efroni, Yonathan and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={6215--6224},
  year={2019},
  organization={PMLR}
}


@inproceedings{szegedy2013intriguing,
  author    = {Christian Szegedy and
               Wojciech Zaremba and
               Ilya Sutskever and
               Joan Bruna and
               Dumitru Erhan and
               Ian J. Goodfellow and
               Rob Fergus},
  title     = {Intriguing properties of neural networks},
  booktitle = {International Conference on Learning Representations},
  year      = {2014}
}

@inproceedings{behzadan2017vulnerability,
  title={Vulnerability of deep reinforcement learning to policy induction attacks},
  author={Behzadan, Vahid and Munir, Arslan},
  booktitle={International Conference on Machine Learning and Data Mining in Pattern Recognition},
  pages={262--275},
  year={2017},
  organization={Springer}
}

@inproceedings{lin2017tactics,
  author    = {Yen{-}Chen Lin and
               Zhang{-}Wei Hong and
               Yuan{-}Hong Liao and
               Meng{-}Li Shih and
               Ming{-}Yu Liu and
               Min Sun},
  title     = {Tactics of Adversarial Attack on Deep Reinforcement Learning Agents},
  booktitle = {{IJCAI}},
  pages     = {3756--3762},
  publisher = {ijcai.org},
  year      = {2017}
}

@inproceedings{huang2017adversarial,
  author    = {Sandy H. Huang and
               Nicolas Papernot and
               Ian J. Goodfellow and
               Yan Duan and
               Pieter Abbeel},
  title     = {Adversarial Attacks on Neural Network Policies},
  booktitle = {International Conference on Learning Representations(Workshop)},
  year      = {2017}
}


@inproceedings{lutjens2020certified,
  title={Certified adversarial robustness for deep reinforcement learning},
  author={L{\"u}tjens, Bj{\"o}rn and Everett, Michael and How, Jonathan P},
  booktitle={Conference on Robot Learning},
  pages={1328--1337},
  year={2020},
  organization={PMLR}
}

@article{vinitsky2020robust,
  title={Robust reinforcement learning using adversarial populations},
  author={Vinitsky, Eugene and Du, Yuqing and Parvate, Kanaad and Jang, Kathy and Abbeel, Pieter and Bayen, Alexandre},
  journal={arXiv preprint arXiv:2008.01825},
  year={2020}
}

@article{franzmeyer2022illusionary,
  title={Illusory Attacks: Detectability Matters in Adversarial Attacks on Sequential Decision-Makers},
  author={Franzmeyer, Tim and McAleer, Stephen and Henriques, Jo{\~a}o F and Foerster, Jakob N and Torr, Philip HS and Bibi, Adel and de Witt, Christian Schroeder},
  journal={arXiv preprint arXiv:2207.10170v2},
  year={2022}
}

@inproceedings{pattanaik2017robust,
  author    = {Anay Pattanaik and
               Zhenyi Tang and
               Shuijing Liu and
               Gautham Bommannan and
               Girish Chowdhary},
  title     = {Robust Deep Reinforcement Learning with Adversarial Attacks},
  booktitle = {{AAMAS}},
  pages     = {2040--2042},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems
               Richland, SC, {USA} / {ACM}},
  year      = {2018}
}

@article{inkawhich2019snooping,
  title={Snooping attacks on deep reinforcement learning},
  author={Inkawhich, Matthew and Chen, Yiran and Li, Hai},
  journal={arXiv preprint arXiv:1905.11832},
  year={2019}
}

@inproceedings{gowal2019scalable,
  title={Scalable verified training for provably robust image classification},
  author={Gowal, Sven and Dvijotham, Krishnamurthy Dj and Stanforth, Robert and Bunel, Rudy and Qin, Chongli and Uesato, Jonathan and Arandjelovic, Relja and Mann, Timothy and Kohli, Pushmeet},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4842--4851},
  year={2019}
}

@inproceedings{oikarinen2020robust,
title={Robust Deep Reinforcement Learning through Adversarial Loss},
author={Tuomas Oikarinen and Wang Zhang and Alexandre Megretski and Luca Daniel and Tsui-Wei Weng},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=eaAM_bdW0Q}
}

@inproceedings{wu2021crop,
  author    = {Fan Wu and
               Linyi Li and
               Zijian Huang and
               Yevgeniy Vorobeychik and
               Ding Zhao and
               Bo Li},
  title     = {{CROP:} Certifying Robust Policies for Reinforcement Learning through
               Functional Smoothing},
  booktitle = {International Conference on Learning Representations},
  year      = {2022}
}

@inproceedings{shen2020deep,
  title={Deep Reinforcement Learning with Robust and Smooth Policy},
  author={Shen, Qianli and Li, Yan and Jiang, Haoming and Wang, Zhaoran and Zhao, Tuo},
  booktitle={International Conference on Machine Learning},
  pages={8707--8718},
  year={2020},
  organization={PMLR}
}

@inproceedings{kos2017delving,
  author    = {Jernej Kos and
               Dawn Song},
  title     = {Delving into adversarial attacks on deep policies},
  booktitle = {International Conference on Learning Representations(Workshop)},
  year      = {2017}
}

@article{behzadan2017whatever,
  author    = {Vahid Behzadan and
               Arslan Munir},
  title     = {Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger},
  journal   = {CoRR},
  volume    = {abs/1712.09344},
  year      = {2017}
}

@inproceedings{mandlekar2017adversarially,
  title={Adversarially robust policy learning: Active construction of physically-plausible perturbations},
  author={Mandlekar, Ajay and Zhu, Yuke and Garg, Animesh and Fei-Fei, Li and Savarese, Silvio},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3932--3939},
  year={2017},
  organization={IEEE}
}

@article{singh2018fast,
  title={Fast and Effective Robustness Certification.},
  author={Singh, Gagandeep and Gehr, Timon and Mirman, Matthew and P{\"u}schel, Markus and Vechev, Martin T},
  journal={NeurIPS},
  volume={1},
  number={4},
  pages={6},
  year={2018}
}

@article{raghunathan2018certified,
  title={Certified defenses against adversarial examples},
  author={Raghunathan, Aditi and Steinhardt, Jacob and Liang, Percy},
  journal={arXiv preprint arXiv:1801.09344},
  year={2018}
}

@inproceedings{wong2018provable,
  title={Provable defenses against adversarial examples via the convex outer adversarial polytope},
  author={Wong, Eric and Kolter, Zico},
  booktitle={International Conference on Machine Learning},
  pages={5286--5295},
  year={2018},
  organization={PMLR}
}

@article{fischer2019online,
  author    = {Marc Fischer and
               Matthew Mirman and
               Steven Stalder and
               Martin T. Vechev},
  title     = {Online Robustness Training for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1911.00887},
  year      = {2019}
}

@inproceedings{dadashi2019value,
  title={The value function polytope in reinforcement learning},
  author={Dadashi, Robert and Taiga, Adrien Ali and Le Roux, Nicolas and Schuurmans, Dale and Bellemare, Marc G},
  booktitle={International Conference on Machine Learning},
  pages={1486--1495},
  year={2019},
  organization={PMLR}
}

@inproceedings{kumar2021policy,
  author    = {Aounon Kumar and
               Alexander Levine and
               Soheil Feizi},
  title     = {Policy Smoothing for Provably Robust Reinforcement Learning},
  booktitle = {International
Conference on Learning Representations},
  year      = {2022}
}

@inproceedings{littman1994markov,
author = {Littman, Michael L.},
title = {Markov Games as a Framework for Multi-Agent Reinforcement Learning},
year = {1994},
isbn = {1558603352},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Eleventh International Conference on International Conference on Machine Learning},
pages = {157–163},
numpages = {7},
location = {New Brunswick, NJ, USA},
series = {ICML'94}
}

@article{schulman2017proximal,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017}
}

@article{mnih2013playing,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013}
}

@article{tsipras2018robustness,
  title={Robustness may be at odds with accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  journal={arXiv preprint arXiv:1805.12152},
  year={2018}
}

@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
  booktitle={International Conference on Machine Learning},
  pages={7472--7482},
  year={2019},
  organization={PMLR}
}

@article{raghunathan2019adversarial,
  title={Adversarial training can hurt generalization},
  author={Raghunathan, Aditi and Xie, Sang Michael and Yang, Fanny and Duchi, John C and Liang, Percy},
  journal={arXiv preprint arXiv:1906.06032},
  year={2019}
}

@article{raghunathan2020understanding,
  title={Understanding and mitigating the tradeoff between robustness and accuracy},
  author={Raghunathan, Aditi and Xie, Sang Michael and Yang, Fanny and Duchi, John and Liang, Percy},
  journal={arXiv preprint arXiv:2002.10716},
  year={2020}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@inproceedings{Heger1994ConsiderationOR,
  title={Consideration of Risk in Reinforcement Learning},
  author={Matthias Heger},
  booktitle={International Conference on Machine Learning},
  year={1994}
}

@inproceedings{gaskett2003reinforcement,
  title={Reinforcement learning under circumstances beyond its control},
  author={Gaskett, Chris},
  booktitle={ International Conference on Computational Intelligence for Modelling Control and Automation},
  year={2003}
}

@article{tamar2013scaling,
  author    = {Aviv Tamar and
               Huan Xu and
               Shie Mannor},
  title     = {Scaling Up Robust MDPs by Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1306.6189},
  year      = {2013}
}

@article{lim2013reinforcement,
  title={Reinforcement learning in robust markov decision processes},
  author={Lim, Shiau Hong and Xu, Huan and Mannor, Shie},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  pages={701--709},
  year={2013}
}

@inproceedings{Mankowitz2020Robust,
title={Robust Reinforcement Learning for Continuous Control with Model Misspecification},
author={Daniel J. Mankowitz and Nir Levine and Rae Jeong and Abbas Abdolmaleki and Jost Tobias Springenberg and Yuanyuan Shi and Jackie Kay and Todd Hester and Timothy Mann and Martin Riedmiller},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJgC60EtwB}
}



@InProceedings{mirman2018differentiable,
  title = 	 {Differentiable Abstract Interpretation for Provably Robust Neural Networks},
  author =       {Mirman, Matthew and Gehr, Timon and Vechev, Martin},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {3578--3586},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/mirman18b/mirman18b.pdf},
  url = 	 {https://proceedings.mlr.press/v80/mirman18b.html},
  abstract = 	 {We introduce a scalable method for training robust neural networks based on abstract interpretation. We present several abstract transformers which balance efficiency with precision and show these can be used to train large neural networks that are certifiably robust to adversarial perturbations.}
}


@article{gowal2018effectiveness,
  author    = {Sven Gowal and
               Krishnamurthy Dvijotham and
               Robert Stanforth and
               Rudy Bunel and
               Chongli Qin and
               Jonathan Uesato and
               Relja Arandjelovic and
               Timothy A. Mann and
               Pushmeet Kohli},
  title     = {On the Effectiveness of Interval Bound Propagation for Training Verifiably
               Robust Models},
  journal   = {CoRR},
  volume    = {abs/1810.12715},
  year      = {2018}
}

@inproceedings{
madry2018towards,
title={Towards Deep Learning Models Resistant to Adversarial Attacks},
author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=rJzIBfZAb},
}


@inproceedings{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={International Conference on Machine Learning},
  pages={1310--1320},
  year={2019},
  organization={PMLR}
}

@inproceedings{tan2020robustifying,
  title={Robustifying reinforcement learning agents via action space adversarial training},
  author={Tan, Kai Liang and Esfandiari, Yasaman and Lee, Xian Yeow and Sarkar, Soumik and others},
  booktitle={2020 American control conference (ACC)},
  pages={3959--3964},
  year={2020},
  organization={IEEE}
}

@inproceedings{gleave2019adversarial,
title={Adversarial Policies: Attacking Deep Reinforcement Learning},
author={Adam Gleave and Michael Dennis and Cody Wild and Neel Kant and Sergey Levine and Stuart Russell},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{huang2019deceptive,
  title={Deceptive reinforcement learning under adversarial manipulations on cost signals},
  author={Huang, Yunhan and Zhu, Quanyan},
  booktitle={International Conference on Decision and Game Theory for Security},
  pages={217--237},
  year={2019},
  organization={Springer}
}

@inproceedings{sun2020vulnerability,
title={Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics},
author={Yanchao Sun and Da Huo and Furong Huang},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{zhang2020adaptive,
  title={Adaptive Reward-Poisoning Attacks against Reinforcement Learning},
  author={Zhang, Xuezhou and Ma, Yuzhe and Singla, Adish and Zhu, Xiaojin},
  year={2020},
  booktitle={International Conference on Machine Learning}
}

@inproceedings{rakhsha2020policy,
  title={Policy Teaching via Environment Poisoning: Training-time Adversarial Attacks against Reinforcement Learning},
  author={Rakhsha, Amin and Radanovic, Goran and Devidze, Rati and Zhu, Xiaojin and Singla, Adish},
  booktitle={International Conference on Machine Learning},
  pages={7974--7984},
  year={2020}
}

@inproceedings{zeng2020adversarial,
  title={Are adversarial examples created equal? A learnable weighted minimax risk for robustness under non-uniform attacks},
  author={Zeng, Huimin and Zhu, Chen and Goldstein, Tom and Huang, Furong},
  booktitle={Association for the Advancement of Artificial Intelligence},
  year={2020}
}

@inproceedings{zhang2021geometryaware,
title={Geometry-aware Instance-reweighted Adversarial Training},
author={Jingfeng Zhang and Jianing Zhu and Gang Niu and Bo Han and Masashi Sugiyama and Mohan Kankanhalli},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=iAX0l6Cz8ub}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@inproceedings{lillicrap2015continuous,
  author    = {Timothy P. Lillicrap and
               Jonathan J. Hunt and
               Alexander Pritzel and
               Nicolas Heess and
               Tom Erez and
               Yuval Tassa and
               David Silver and
               Daan Wierstra},
  title     = {Continuous control with deep reinforcement learning},
  booktitle = {International Conference on Learning Representations},
  year      = {2016}
}

@article{guez2015deep,
  title={Deep reinforcement learning with double q-learning},
  author={Guez, Arthur and Van Hasselt, H},
  journal={Association for the Advancement of Artificial Intelligence},
  year={2015}
}

@inproceedings{wang2016dueling,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={1995--2003},
  year={2016},
  organization={PMLR}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double Q-Learning},
  author={Hado  Van Hasselt, Arthur  Guez, David  Silver},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{schaul2015prioritized,
  author    = {Tom Schaul and
               John Quan and
               Ioannis Antonoglou and
               David Silver},
  title     = {Prioritized Experience Replay},
  booktitle = {International Conference on Learning Representations},
  year      = {2016}
}

@inproceedings{thomas2021safe,
title={Safe Reinforcement Learning by Imagining the Near Future},
author={Garrett Thomas and Yuping Luo and Tengyu Ma},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=vIDBSGl3vzl}
}

@InProceedings{bechtle2020curious,
  title = 	 {Curious iLQR: Resolving Uncertainty in Model-based RL},
  author =       {Bechtle, Sarah and Lin, Yixin and Rai, Akshara and Righetti, Ludovic and Meier, Franziska},
  booktitle = 	 {Proceedings of the Conference on Robot Learning},
  pages = 	 {162--171},
  year = 	 {2020},
  editor = 	 {Kaelbling, Leslie Pack and Kragic, Danica and Sugiura, Komei},
  volume = 	 {100},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {30 Oct--01 Nov},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v100/bechtle20a/bechtle20a.pdf},
  url = 	 {https://proceedings.mlr.press/v100/bechtle20a.html},
  abstract = 	 {Curiosity as a means to explore during reinforcement learning problems has recently become very popular. However, very little progress has been made in utilizing curiosity for learning control. In this work, we propose a model-based reinforcement learning (MBRL) framework that combines Bayesian modeling of the system dynamics with curious iLQR , an iterative LQR approach that considers model uncertainty. During trajectory optimization the curious iLQR attempts to minimize both the task-dependent cost and the uncertainty in the dynamics model. We demonstrate the approach on reaching tasks with 7-DoF manipulators in simulation and on a real robot. Our experiments show that MBRL with curious iLQR reaches desired end-effector targets more reliably and with less system rollouts when learning a new task from scratch, and that the learned model generalizes better to new reaching tasks.}
}

@article{chakraborty2018adversarial,
  author    = {Anirban Chakraborty and
               Manaar Alam and
               Vishal Dey and
               Anupam Chattopadhyay and
               Debdeep Mukhopadhyay},
  title     = {Adversarial Attacks and Defences: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/1810.00069},
  year      = {2018}
}

@article{roijers2013survey,
  title={A survey of multi-objective sequential decision-making},
  author={Roijers, Diederik M and Vamplew, Peter and Whiteson, Shimon and Dazeley, Richard},
  journal={Journal of Artificial Intelligence Research},
  volume={48},
  pages={67--113},
  year={2013}
}

@article{gelfand1991recursive,
  title={Recursive stochastic algorithms for global optimization in R\^{}d},
  author={Gelfand, Saul B and Mitter, Sanjoy K},
  journal={SIAM Journal on Control and Optimization},
  volume={29},
  number={5},
  pages={999--1018},
  year={1991},
  publisher={SIAM}
}

@inproceedings{zhang2018finding,
author = {Zhang, Huan and Weng, Tsui-Wei and Chen, Pin-Yu and Hsieh, Cho-Jui and Daniel, Luca},
title = {Efficient Neural Network Robustness Certification with General Activation Functions},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Finding minimum distortion of adversarial examples and thus certifying robustness in neural network classifiers for given data points is known to be a challenging problem. Nevertheless, recently it has been shown to be possible to give a non-trivial certified lower bound of minimum adversarial distortion, and some recent progress has been made towards this direction by exploiting the piece-wise linear nature of ReLU activations. However, a generic robustness certification for general activation functions still remains largely unexplored. To address this issue, in this paper we introduce CROWN, a general framework to certify robustness of neural networks with general activation functions for given input data points. The novelty in our algorithm consists of bounding a given activation function with linear and quadratic functions, hence allowing it to tackle general activation functions including but not limited to four popular choices: ReLU, tanh, sigmoid and arctan. In addition, we facilitate the search for a tighter certified lower bound by adaptively selecting appropriate surrogates for each neuron activation. Experimental results show that CROWN on ReLU networks can notably improve the certified lower bounds compared to the current state-of-the-art algorithm Fast-Lin, while having comparable computational efficiency. Furthermore, CROWN also demonstrates its effectiveness and flexibility on networks with general activation functions, including tanh, sigmoid and arctan.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4944–4953},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}



@inproceedings{xu2020automatic,
  title={Automatic perturbation analysis for scalable certified robustness and beyond},
  author={Xu, Kaidi and Shi, Zhouxing and Zhang, Huan and Wang, Yihan and Chang, Kai-Wei and Huang, Minlie and Kailkhura, Bhavya and Lin, Xue and Hsieh, Cho-Jui},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1129--1141},
  year={2020}
}


@inproceedings{
zhang2020towards,
title={Towards Stable and Efficient Training of Verifiably Robust Neural Networks},
author={Huan Zhang and Hongge Chen and Chaowei Xiao and Sven Gowal and Robert Stanforth and Bo Li and Duane Boning and Cho-Jui Hsieh},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Skxuk1rFwB}
}

@inproceedings{wong2018scaling,
  title={Scaling provable adversarial defenses},
  author={Wong, Eric and Schmidt, Frank and Metzen, Jan Hendrik and Kolter, J Zico},
  booktitle={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{wang2018mixtrain,
  title={Mixtrain: Scalable training of verifiably robust neural networks},
  author={Wang, Shiqi and Chen, Yizheng and Abdou, Ahmed and Jana, Suman},
  journal={arXiv preprint arXiv:1811.02625},
  year={2018}
}
@article{mirman2018distilled,
  title={Distilled agent dqn for provable adversarial robustness},
  author={Mirman, Matthew and Fischer, Marc and Vechev, Martin},
  year={2018}
}

@inproceedings{lee2020query,
author = {Lee, Xian Yeow and Esfandiari, Yasaman and Tan, Kai Liang and Sarkar, Soumik},
title = {Query-Based Targeted Action-Space Adversarial Policies on Deep Reinforcement Learning Agents},
year = {2021},
isbn = {9781450383530},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the ACM/IEEE 12th International Conference on Cyber-Physical Systems},
pages = {87–97},
numpages = {11},
keywords = {adversarial policies, adversarial attacks, deep reinforcement learning, adversarial training, black-box attacks},
location = {Nashville, Tennessee},
series = {ICCPS '21}
}

@inproceedings{xiao2019characterizing,
  author    = {Xinlei Pan and
               Chaowei Xiao and
               Warren He and
               Shuang Yang and
               Jian Peng and
               Mingjie Sun and
               Mingyan Liu and
               Bo Li and
               Dawn Song},
  title     = {Characterizing Attacks on Deep Reinforcement Learning},
  booktitle = {{AAMAS}},
  pages     = {1010--1018},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems
               {(IFAAMAS)}},
  year      = {2022}
}


@ARTICLE{akhtar2018threat,  author={Akhtar, Naveed and Mian, Ajmal},  journal={IEEE Access},   title={Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey},   year={2018},  volume={6},  number={},  pages={14410-14430},  doi={10.1109/ACCESS.2018.2807385}}

@inproceedings{korkmaz2021investigating,
  title={Investigating vulnerabilities of deep neural policies},
  author={Korkmaz, Ezgi},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1661--1670},
  year={2021},
  organization={PMLR}
}

@inproceedings{korkmaz2022deep,
  title={Deep reinforcement learning policies learn shared adversarial features across mdps},
  author={Korkmaz, Ezgi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2022},
}

@article{brown2017adversarial,
  author    = {Tom B. Brown and
               Dandelion Man{\'{e}} and
               Aurko Roy and
               Mart{\'{\i}}n Abadi and
               Justin Gilmer},
  title     = {Adversarial Patch},
  journal   = {CoRR},
  volume    = {abs/1712.09665},
  year      = {2017}
}

@inproceedings{
liang2022efficient,
title={Efficient Adversarial Training without Attacking: Worst-Case-Aware Robust Reinforcement Learning},
author={Yongyuan Liang and Yanchao Sun and Ruijie Zheng and Furong Huang},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=y-E1htoQl-n}
}

@inproceedings{
sun2023certifiably,
title={Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication},
author={Yanchao Sun and Ruijie Zheng and Parisa Hassanzadeh and Yongyuan Liang and Soheil Feizi and Sumitra Ganesh and Furong Huang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=dCOL0inGl3e}
}

@inproceedings{li2019robust,
  title={Robust multi-agent reinforcement learning via minimax deep deterministic policy gradient},
  author={Li, Shihui and Wu, Yi and Cui, Xinyue and Dong, Honghua and Fang, Fei and Russell, Stuart},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={4213--4220},
  year={2019}
}

@article{goyal2023robust,
  title={Robust Markov decision processes: Beyond rectangularity},
  author={Goyal, Vineet and Grand-Clement, Julien},
  journal={Mathematics of Operations Research},
  volume={48},
  number={1},
  pages={203--226},
  year={2023},
  publisher={INFORMS}
}

@article{mannor2016robust,
  title={Robust MDPs with k-rectangular uncertainty},
  author={Mannor, Shie and Mebel, Ofir and Xu, Huan},
  journal={Mathematics of Operations Research},
  volume={41},
  number={4},
  pages={1484--1509},
  year={2016},
  publisher={INFORMS}
}

@article{mannor2012lightning,
  title={Lightning does not strike twice: Robust MDPs with coupled uncertainty},
  author={Mannor, Shie and Mebel, Ofir and Xu, Huan},
  journal={arXiv preprint arXiv:1206.4643},
  year={2012}
}