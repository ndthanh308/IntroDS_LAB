{
  "title": "Distillation-guided Representation Learning for Unconstrained Gait Recognition",
  "authors": [
    "Yuxiang Guo",
    "Siyuan Huang",
    "Ram Prabhakar",
    "Chun Pong Lau",
    "Rama Chellappa",
    "Cheng Peng"
  ],
  "submission_date": "2023-07-27T01:53:57+00:00",
  "revised_dates": [
    "2024-10-13T20:01:34+00:00"
  ],
  "abstract": "Gait recognition holds the promise of robustly identifying subjects based on walking patterns instead of appearance information. While previous approaches have performed well for curated indoor data, they tend to underperform in unconstrained situations, e.g. in outdoor, long distance scenes, etc. We propose a framework, termed GAit DEtection and Recognition (GADER), for human authentication in challenging outdoor scenarios. Specifically, GADER leverages a Double Helical Signature to detect segments that contain human movement and builds discriminative features through a novel gait recognition method, where only frames containing gait information are used. To further enhance robustness, GADER encodes viewpoint information in its architecture, and distills representation from an auxiliary RGB recognition model, which enables GADER to learn from silhouette and RGB data at training time. At test time, GADER only infers from the silhouette modality. We evaluate our method on multiple State-of-The-Arts(SoTA) gait baselines and demonstrate consistent improvements on indoor and outdoor datasets, especially with a significant 25.2% improvement on unconstrained, remote gait data.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14578",
  "pdf_url": "https://arxiv.org/pdf/2307.14578v2",
  "comment": "Accepted by IJCB 2024",
  "num_versions": null,
  "size_before_bytes": 15926899,
  "size_after_bytes": 388701
}