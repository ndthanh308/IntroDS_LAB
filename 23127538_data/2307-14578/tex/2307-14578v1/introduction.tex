\section{Introduction}
\label{sec:Introduction}

%Gait recognition is a promising tool for biometric identification using the unique walking pattern. Especially in long distance scenario, where face and fingerprint recognition is not plausible.
% Gait recognition is a promising approach in addressing 
Unconstrained biometric identification, e.g., in outdoor and far-away situations, has been a longstanding challenge~\cite{zhu2021gait,zheng2022gait,sepas2022deep,shen2022comprehensive}. RGB-based face and body recognition systems focus on learning discriminating \emph{spatial} features; however, effects like challenging view angles, low face resolution, changing appearances (e.g., clothes and glasses), and long distance turbulence are observed in the real world and can significantly disrupt spatial information. Consequently, the RGB-based recognition systems tend to perform inconsistently in unconstrained scenarios. 
% for biometric identification based on unique walking patterns. In many unconstrained scenarios, RGB-based face or body recognition does not perform well due to challenging view angles, low image resolution, changing appearance (clothes/glasses), occlusion, and distance/weather effects. 

Gait analysis provides an alternative modality for human recognition by intentionally masking away the color information and focusing on learning discriminating features in the \emph{temporal} domain. As such, it is potentially more robust to challenging, unconstrained situations, and has been broadly applied in many applications such as surveillance~\cite{benedek2016lidar}, health~\cite{del2019gait} and crime analysis~\cite{hadid2012can}, etc.

% Especially in long distance scenario, where face and fingerprint recognition is not plausible. The gait analysis is broadly applied in many applications such as surveillance \cite{benedek2016lidar}, health analysis \cite{del2019gait}, crime analysis \cite{hadid2012can}, etc. The challenges in gait recognition include different view angles, low image resolution, changing appearance (clothes), occlusion, and distance.  

The field of gait recognition has been significantly bloomed~\cite{sarkar2005humanid,han2005individual,chen2009frame,liao2017pose,an2018improving,sepas2022deep} by traditional methods, including template matching methods ~\cite{bobick2001recognition,liu2007gait,zhang2010active} and model-based methods~\cite{benabdelkader2002stride,yoo2008automated,boulgouris2007human,li2008gait}, but limited by dependency on the scale and viewing angle and being sensitive to video quality, respectively. Deep learning (DL)-based approaches~\cite{chao2019gaitset,battistone2019tglstm,lin2021gait} have made significant advances compared to traditional methods. They are able to generate robust identity embeddings by directly processing the complex temporal information present in gait sequences. This enables effective recognition under sources of variability, such as changes in viewpoint and clothing, making DL-based methods widely used in these years.

% Many gait recognition methods have been proposed over the years~\cite{sarkar2005humanid,han2005individual,chen2009frame,liao2017pose,an2018improving,battistone2019tglstm,sepas2022deep}. The traditional methods can be broadly classified into model-free, template matching methods~\cite{bobick2001recognition,liu2007gait,zhang2010active} and model-based methods~\cite{benabdelkader2002stride,yoo2008automated,boulgouris2007human,li2008gait}. Model-free methods are dependent on the scale and viewing angle and model-based approaches are sensitive to video quality. 

% For example, the GaitSet \cite{chao2019gaitset} model extracts a global gait representation using horizontal pyramid mapping. Recently, Liang \textit{et al.}~\cite{liang2022gaitedge} proposed an end-to-end framework utilizing gait synthesis data to block noise for robust recognition.

% Guo \textit{et al.} \cite{guo2022multi} proposed a dual ensemble method utilizing RGB, silhouette and GaitPattern inspired by the Double Helical Gait pattern \cite{ran2010applications} for robust recognition in the wild. %GEINet \cite{shiraga2016geinet} feeds hand crafted feature as input to a Convolutional Neural Network (CNN). Wu \textit{et al.} \cite{wu2016comprehensive} proposed three different CNN architectures with low, middle and global feature fusion. % Some of the traditional model-free gait recognition methods include template matching using Motion Energy Image \cite{bobick2001recognition}, Gait History Image \cite{liu2007gait}, and Active Energy Image \cite{zhang2010active}. Model-based methods aim to model human body using measures like inter body part distances, etc \cite{benabdelkader2002stride,yoo2008automated,boulgouris2007human,li2008gait}. % 
% Gait Energy Image

% Figure environment removed

% challenge of outdoor dataset --gait detector
While DL-based gait recognition performs well for indoor scenes, it often fails to achieve good performance in unconstrained/outdoor scenarios. In this work, we seek to apply gait recognition to unconstrained situations with minimum data curation. 
% For example, state-of-the-art methods on the CASIA-B indoor dataset achieve over 90\% accuracy, but perform poorly in u, e.g. 52\%, on unconstrained outdoor datasets like BRIAR \cite{briar}. 
% Specifically, the outdoor gait
% recently collected BRIAR~\cite{briar} 
% dataset contains \emph{unconstrained outdoor} sequences with variations in human demographics, clothing configurations, atmospheric turbulence, and different platforms (ground, elevated level, or in the air). 
The recently collected BRIAR~\cite{briar} dataset contains standing, structured walking, and random walking sequences, which mimic the real-world constraints of gait recognition.
Existing gait recognition methods assume that the subject is always walking with periodic movement and that there are no standing sequences. 
% However, in practical situations, non-walking sequences and incomplete or occluded bodies are prevalent. 
By making such assumption, these methods
 tend to learn suboptimal representation,
% But including frames from standing or non-walking occurrences can cause a drop in performance of around 10\%. 
% Current SoTA methods are ill-prepared for these situations
e.g. achieving only 31\% on close range recognition. This highlights the need for an approach to filter out non-walking sequences and make the gait recognition inputs more consistent.
% more robust approaches to gait recognition in unconstrained scenarios, which can address the various complexities that arise in real-world settings.


% Additionally, with respect to the enrolled gait pattern, the BRIAR data offer following key challenges 
% Compared to CASIA-B: 
% \begin{enumerate*}[label=(\roman*)]
%     \item while CASIA-B contains only structured walking pattern, BRIAR dataset contains both structured and real-life random walking patterns, 
%     % \item the gait pattern in CASIA-B is periodic in nature, whereas BRIAR contains both periodic motion and non-periodic (standing), 
%     \item Unlike CASIA-B, the BRIAR dataset has standing or non-walking sequences, mimicking real world application of gait recognition.
% \end{enumerate*}

 %General gait model problem ---how to introduce RGB
Current silhouette-based methods employ the practice of \textit{size normalization}, where input silhouettes are resized to the same resolution regardless of the subject's distance from the camera, can lead to information loss. Particularly, the sequence of the ratio between the original body chip and the normalized one can implicitly offer important viewpoint information, which is useful for generating effective embeddings ~\cite{chai2022lagrange}. Unfortunately, this cue is lost in the resizing operation. Besides, RGB modality is often overlooked in gait recognition due to privacy concerns and potential biases introduced by clothing. However, RGB images contain rich information that can be used to build robust features that cannot be captured by silhouettes alone. By solely referring to the feature space of the RGB modality in the training step, we are able to protect the privacy of individuals while still taking advantage of the discrimination provided by RGB images.


%Gait detector
In this paper, we aim to push the frontiers of unconstrained gait analysis through an end-to-end GAit Detection and Recognition system in the wild (GADER). 
% Existing gait recognition methods assume that the subject is always walking with constant periodic movement and that there are no standing sequences in the input. However, in practical situations, non-walking sequences and incomplete or occluded bodies are prevalent. Processing these sequences as though they have a gait pattern can corrupt the learned representation. 
To address the problem of mixing the moving and standing sequences, we introduce a novel gait detection module (Figure~\ref{fig:gaitdetect}) that detects the walking and non-walking parts of a sequence. Instead of using a 3D volume to capture the dynamic movement, our gait detector uses the reliable Double Helical Signature (DHS)~\cite{ran2010applications,niyogi1994analyzing}, a 2D gait pattern with a lightweight classification model to distinguish the walking portion of the input sequence from others. Specifically, we do not input the entire gait pattern into the model. Instead, we split the signature into multiple windows of varying lengths to get predictions, followed by Non-Maximum Suppression (NMS), to localize the movement duration. This provides a pure gait sequence for existing gait recognition models, making it suitable for real-world scenarios.

%Gait recognition
For the gait recognition module (GAR), along with the size normalized silhouettes, we embed the ratio of change in size from the original body size as an attention signal. This \emph{ratio attention} helps preserve the viewpoint information that is beneficial for robust identity representation. We further introduce a \emph{cross-modality feature distillation} step, where we guide intermediate gait features to be more expressive by making them more similar to features generated from RGB frames. This enables the gait features to maintain their robustness against appearance changes, while also benefiting from the discriminative power of RGB features. The augmented gait features can be obtained from silhouettes and do not require the presence of RGB frames during inference.
% Gait verification is pertinent to person re-id, access security systems, etc. 

In summary, GADER introduces three contributions:
\begin{itemize}[noitemsep, nolistsep, leftmargin=*]
    \item We introduce a light-weight gait detector to automatically detect clips with human movements and avoid learning on static information.
    \item We propose a novel gait recognition model, which leverages the color space and size information during training; specifically, knowledge distillation on RGB features is used to enhance feature space capacity. 
    \item We conduct a series of evaluations, i.e. rank retrieval and verification on CASIA-B Gait3D and BRIAR datasets, and show superior performance than the state-of-the-art means.
\end{itemize}