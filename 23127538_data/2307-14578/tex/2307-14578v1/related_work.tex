\section{Related Work}
\label{sec:related_work}
% \subsection{Gait Recognition}

% Figure environment removed

\noindent\textbf{Traditional Gait Representations}: Traditional gait recognition methods can be classified into appearance-based and human model-based. Appearance based gait systems use input data without making any assumptions on human body model \cite{sarkar2005humanid,chen2009frame,zhang2010active}. Bobick and Davis \cite{bobick2001recognition} proposed Motion Energy Image (MEI) and Motion History Image (MHI) to model the input silhouette sequence as a template. Han and Bhanu \cite{han2005individual} introduced Gait Energy Image (GEI) template as an average of aligned and normalized silhouette frames. In \cite{liu2007gait}, Liu and Zheng improved GEI and proposed Gait History Image (GHI). GHI is generated from silhouettes that combines both static and dynamic or temporal characteristics. While appearance-based methods are simple and fast, they are view and scale dependent. %Other popular appearance based gait recognition techniques include Frame Difference Energy Image \cite{chen2009frame} and Active Energy Image \cite{zhang2010active}. MEI at current time step is generated by taking union of previous few silhouette frames. MHI uses current silhouette frame and previous time step MHI to represent the silhouette movement. 

Model-based methods represent whole human body using well-defined models and use them to represent gait. The methods vary by the different techniques used for modeling human body, such as hidden Markov models~\cite{kale2004identification,liu2006improved}, stride length and walking tempo \cite{benabdelkader2002stride}, stick figures \cite{yoo2008automated}, multi-part \cite{boulgouris2007human,li2008gait}, inter body part distances \cite{bobick2001gait,wang2004fusion}, joint angles \cite{tanawongsuwan2001gait}, and Velocity Hough Transform \cite{nash1997dynamic} among many. %Unlike appearance based methods, the model-based methods are view angle and scale independent, however they are dependent on video quality. %  The model-based methods focus on modeling the whole human body. The features extracted from the model is used for representing gait. leg model for walking \cite{yam2004automated,dockstader2003stochastic}

\noindent\textbf{Deep Learning-based Methods}: Early deep learning-based methods learn global gait representation using information like silhouettes \cite{chao2019gaitset}, GEI \cite{shiraga2016geinet,wu2016comprehensive,hossain2013multimodal}, and body pose \cite{liao2017pose,an2018improving,battistone2019tglstm} as input to CNNs. The GaitSet \cite{chao2019gaitset} model applies horizontal pyramid mapping on a set of features extracted from individual silhouette frames to obtain efficient gait representation. Alternatively, local representations extracted using part-based methods have shown success in recent years \cite{lin2021gait,zhang2019cross,liu2004toward}. GaitPart \cite{fan2020gaitpart} uses focal convolution on different body parts and aggregates them using micro-motion capture module. Several methods have been proposed to combine global and local features. One such method by Lin \textit{et al.} \cite{lin2021gait} aggregates local temporal information while retaining spatial information. Subsequently, global and local features extraction followed by temporal pooling is applied to generate robust gait features. Recently, Guo \textit{et al.} \cite{guo2022multi} utilize both RGB and silhouette data to extract robust gait features for challenging indoor and outdoor sequences. In \cite{chai2022lagrange}, Chai \textit{et al.} used Lagrange's equation to demonstrate the importance of second order motion information in gait recognition.  %While global features can provide holistic representations, the local features can encapsulate granular part level representations. 3D representations extracted using depth sensors \cite{hofmann2014tum,nunes2019benchmark,chattopadhyay2015frontal} and human body model from RGB images \cite{liao2020model,liao2017pose,cao2017realtime,kolotouros2021probabilistic,georgakis2020hierarchical} also have shown promising results.

\noindent\textbf{Recognition in the Wild}: Developing an accurate gait representation in the wild is a long term goal and has been broadly researched over the past decade. Towards that aim, Zhu \textit{et al.} curated a large scale gait dataset called GREW \cite{zhu2021gait}. It is a natural videos dataset consisting of 128K sequences of 26K identities captured over 882 cameras. Similarly, Zheng \textit{et al.} \cite{zheng2022gait} collected Gait3D dataset that contains silhouettes, 2D/3D keypoints, and 3D meshes for 3D gait recognition. The authors~\cite{zheng2022gait} observed that state-of-the-art gait recognition methods do not translate similar superior performance in GREW and Gait3D as they do in indoor dataset like CASIA-B. Due to privacy concern, both GREW and Gait3D datasets are silhouette based and do not contain the corresponding RGB sequences. Also, unlike the BRIAR dataset, GREW and Gait3D do not contain sequences captured at long distances (500m). Hence, they do not address challenges due to atmospheric turbulence. Another research direction includes enhancing images captured at long distance and use the restored images for recognition \cite{yasarla2021learning,lau2021atfacegan}. In \cite{lau2021atfacegan}, Lau \textit{et al.} proposed a generative model that deblurs and removes turbulence effects for face recognition at distance. Such methods have not been explored for gait recognition.


%\subsection{Knowledge Distillation}
%In knowledge distillation, a smaller model (student) is trained to imitate a larger model (teacher) without noticeable reduction in accuracy (cite 1, 2, 3, 4). The success of knowledge distillation depend upon favorable data geometry along class margin, gradient-descent optimization bias, and more training samples for monotonicity (5).  Several works have been proposed to improve distillation quality, such as auxiliary loss on intermediate features (6,7,8), bidirectional knowledge distillation (9) and repetitive knowledge distillation (10,11,12). In (13), Tarvainen \textit{et al.} observed that averaging the student models at different epochs resulted in superior models. Feature embedding based distillation methods use the final fully connected layer logits from the teacher model to transfer knowledge to the student (2, 3,21,22). 

%Despite the simplicity and success of embedding based distillation methods, they solely rely upon the logits for distillation and ignore the intermediate features. To address this issue, feature-based distillation methods have shown that intermediate feature maps can also be used for effective distillation (23, 24, 25, 26, 27, 28). Romero \textit{et al.} (18) used intermediate layer hints from a deep teacher model to train a thin and deeper student model. Chen \textit{et al.} (19) propose to use attention mechanism to select multiple semantically close layers from teacher rather than a single layer. Similarly Ji \textit{et al.} (20) proposed a attention guided meta network to identify matching features between teacher and the student. Relation-based knowledge distillation methods utilize relationship between layers or training samples for knowledge transfer (29, 30, 31). In (32), Lee \textit{et al.} propose to distill dataset knowledge from teacher to student using an graph attention network. Passalis \textit{et al.} trained a student model to mimic the information flow between layers of the teacher model (33). The applications of KD include speech recognition (14,15), neural machine translation (16), semi-supervised learning (13), and multi-modal transfer learning (17). In (34), Song \textit{et al.} explored knowledge distillation for gait recognition. 



