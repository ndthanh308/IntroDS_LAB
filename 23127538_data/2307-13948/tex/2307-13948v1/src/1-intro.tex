\section{Introduction}
The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching \cite{Wen_2021_CVPR,ning2021disentangled,zheng2021adversarial}, voice-guided face synthesis \cite{jamaludin2019you, zhou2019talking, guo2021adnerf,cudeiro2019capture}, and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded between voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic correspondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus dominant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice possible?
% yet the face may look very different from the true appearance of the speaker, which implies that the voice-face correlation is rough instead of one-to-one. 
In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases.

% Figure environment removed

There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective \cite{jamaludin2019you, zhou2019talking, guo2021adnerf}, which utilize Generative Adversarial Network (GAN) \cite{mirza2014conditional,goodfellow2020generative} to generate faces with voice as the condition. However, face recovering from voice is ill-posed. \cite{oh2019speech2face} found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumination, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices \cite{blanz1999morphable} which inherently excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths.

Similar to our target, one recent work \cite{wu2022cross} attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. 
% After evaluating their model on our ground-truth voice and 3D face scans, we find no statistically significant correlation between their reconstructed face and the true face.

In our method, we aim to disable all previously used semantics, \eg, gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let us go back and understand how voice is generated by human beings. voice is produced by phonatory structures (\cref{fig:teaser} (a)), \eg, vocal tract and vocal cords. Specifically, when producing vowels, the vocal cords vibrate with no obstruction in the vocal tract. In contrast, for most consonants, the phonation purely depends on the vocal tract resonance with a pulmonic airflow. The vocal tract can be assumed as a filter that makes the phonemes versatile and personalized. With the phonation mechanism of human beings, as shown in \cref{fig:teaser} (b), Markel \textit{et al} introduces linear predictive coding (LPC) \cite{markel1976linear} which models phonation as a unit impulse signal modified by a stack of tubes (vocal tract) and encodes personalized voice by vocal tract coefficients. The LPC yields a good physical model of the vocal tract with only voice inputs in an unsupervised manner. As the mouth and nose serve as the most important parts of the vocal tract, we hypothesize that their geometry should be encoded in the voice. With the tight bind of muscles and skeletons, other parts of face geometry may also be represented by voice.

Though voice and face geometry should have some correlations, we have no idea about which part of the face voice can represent. Constructing uncorrelated relations will lead to random results and raise the model instability. To tackle this problem, we introduce the voice-anthropometric measurement (AM)-face paradigm. Previous studies have shown that anthropometric measurements like the dimensions of nasal cavities \cite{vampola2020influence} or cranium \cite{wyganowska2013anthropometric,wyganowska2017vocal} directly influence the speaker's voices. In our voice-AM-face paradigm, we first summarize a set of AMs from anthropometry literature \cite{ramanathan2006modeling,zhuang2010facial,shan2021anthropometric,farkas2004anthropometric,ghafourzadeh2019part}, then identify predictable AMs and use them to guide the 3D face reconstruction by conducting AM-guided optimization. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. In addition, the analysis of AMs also brings a new view to understanding voice-face correlation in a fine-grained fashion.

Inspired by LPC which learns the shape of the vocal tract by producing voice, we utilize a phonatory module to facilitate voice representation learning for face geometry. Similar to the auto-regressive impulse-by-filter model used in LPC, recently introduced denoising diffusion probabilistic models \cite{ho2020denoising} share a similar structure, which samples a random noise with auto-regressive updating to form the final result. Based on the structure similarity, we choose the diffusion model as our phonatory module. 

With the predicted AMs, we reconstruct the facial shapes by an optimization-based method, which first projects the 3D facial shapes into a low-dimensional linear space \cite{blanz1999morphable}. By adjusting the coefficients in low-dimensional space, we obtain different re-projected 3D facial shapes. Though this paper mainly focuses on understanding the relationship between the 3D facial shape and voice from a scientific angle, this technique has its potential applications. For example, the identity-fidelity facial shape can be used for criminal profiling scenarios, such as hoax calls and voice-based phishing.

In this paper, we try to answer two core questions - (1) Is there a correlation between face geometry and voice?  (2) If so, which part of the face can be represented by the voice? To fulfill our target, we collect a large-scale dataset containing ground-truth 3D face scans and corresponding voice recordings from 1026 speaker identities. A voice-AM-face paradigm equipped with a phonatory module is proposed for analyzing the voice-face correlation. Our contributions can be summarized as follows.
\begin{itemize}
    \item We propose a voice-AM-face paradigm and a corresponding voice-face dataset for tractable 3D face deduction from voice. 
    \item We investigate voice-face correlation in a fine-grained manner by statistically verifying which part of the face can be reflected by the voice. The results can serve as a good reference to support future voice-face research, such as voice-face verification.
    \item We leverage voice production as a proxy task to learn face geometry representation and verify that voice production is highly related to 3D facial shapes.
\end{itemize}

% 从speaker face verification 讲identity fidelity，然后讲explanable/support


