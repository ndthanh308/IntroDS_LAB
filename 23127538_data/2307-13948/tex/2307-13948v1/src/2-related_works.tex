\section{Related Works}

\subsection{Voice-face Matching and Voice-guided Face Synthesis}

The human voice contains rich information that can be used to recognize personality traits, such as speaker identity \cite{bull1983voice, maguinness2018understanding, ravanelli2018speaker}, gender \cite{li2019improving}, age \cite{ptacek1966age, singh2016relationship, grzybowska2016speaker}, and emotion status \cite{wang2017learning, zhang2019attention}. Voices can also be used for monitoring health conditions \cite{ali2017automatic} and other medical applications \cite{han2021exploring}. Most existing works in this area focus on predicting personality traits that are intuitively related to voice. Such personality traits may have essential correlations between the human voice and their faces \cite{NEURIPS2019_eb9fc349}.

Cross-modal voice-face matching \cite{Wen_2021_CVPR,ning2021disentangled,zheng2021adversarial} and cross-modal verification \cite{Nawaz_2021_CVPR, tao2020audio,sari2021multi} are tasks where voices are used as queries to retrieve faces or vice versa, which have received increasing attention in recent years. Voice-guided face synthesis is another related task, which aims to generate coherent and natural lip movements, and includes methods that drive template images \cite{jamaludin2019you, zhou2019talking, guo2021adnerf} or template face meshes \cite{cudeiro2019capture} to talk by speech inputs, or replace lip movements in a video with movements inferred from another video or speech \cite{chen2018lip, wiles2018x2face}. 

Unlike the existing work in related fields that are more focused on semantic correlations between voice and face, our work investigates the voice-face correlation from a geometry view by studying holistic facial structures. There has been recent work that seeks to understand the correlations between voice and facial geometry by first recovering 2D faces from voice and then reconstructing 3D faces from the 2D representations \cite{wu2022cross}. However, during this process, it is still inevitable that the semantic correlations are encoded in the 2D face and affect the 2D-to-3D face reconstruction. Instead, we aim to model our voice-face correlation from a pure geometry view without the influence of any semantics.

% Figure environment removed

\subsection{Phonation and Anthropometry}

The human voice is generated by phonatory structures, and the phonation of different phonemes may be dependent on different physiological structures. For example, the phonation of consonants includes some airflow obstruction in the vocal tract, while vowels do not. By utilizing such properties, it has been proven to be informative and helpful in various tasks, including automatic speech recognition \cite{ghosh2011automatic}, speech enhancement \cite{yang2023paaploss} and emotion recognition \cite{gomez2007relationships}. Beyond those language-related usages, human attributes are also predictable from voice. There is a substantial body of research on inferring human attributes from a person's voice, including speaker identity \cite{Bull1983TheVA, Ravanelli2018SpeakerRF}, age \cite{Bahari2012AgeEF, Ptacek1966AgeRF}, gender \cite{Li2019ImprovingTS}, and emotion status \cite{wang2017learning, Zhang2019AttentionaugmentedEM}. The interaction between these physiological structures may play an important role in the recovery of 3D faces from voice. More specifically, the underlying skeletal and articulatory structure of the face and the tissue covering them may govern the shapes, sizes, and acoustic properties of the vocal tract that produces the voice. Linear predictive coding (LPC) \cite{markel1976linear} which models phonation as a unit impulse signal modified by a stack of tubes (vocal tract) and encodes personalized voice by vocal tract coefficients. The LPC yields a good physical model of the vocal tract with only voice inputs in an unsupervised manner.

To explicitly describe the correspondence between vocal and facial features, anthropometric measurements have been used in a wide range of applications to associate with voice production \cite{singh2016forensic, ramanathan2006modeling,zhuang2010facial,shan2021anthropometric,farkas2004anthropometric,ghafourzadeh2019part}. In a broad sense, AMs may cover various body parameters and characteristics, including skeletal proportions, race, height, body size, etc. These characteristics may influence the phonation of voice by the differences in the placement of the glottis, length of vocal cords, etc.

In this work, we summarize a large set of AMs that is highly associated with voice-face correlation. Meanwhile, we also identify the predictable AMs to guide the 3D facial shape reconstruction. The results can serve as a good reference to support future voice-face research.

