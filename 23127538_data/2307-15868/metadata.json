{
  "title": "Faster Stochastic Algorithms for Minimax Optimization under Polyak--Łojasiewicz Conditions",
  "authors": [
    "Lesi Chen",
    "Boyuan Yao",
    "Luo Luo"
  ],
  "submission_date": "2023-07-29T02:26:31+00:00",
  "revised_dates": [],
  "abstract": "This paper considers stochastic first-order algorithms for minimax optimization under Polyak--Łojasiewicz (PL) conditions. We propose SPIDER-GDA for solving the finite-sum problem of the form $\\min_x \\max_y f(x,y)\\triangleq \\frac{1}{n} \\sum_{i=1}^n f_i(x,y)$, where the objective function $f(x,y)$ is $μ_x$-PL in $x$ and $μ_y$-PL in $y$; and each $f_i(x,y)$ is $L$-smooth. We prove SPIDER-GDA could find an $ε$-optimal solution within ${\\mathcal O}\\left((n + \\sqrt{n}\\,κ_xκ_y^2)\\log (1/ε)\\right)$ stochastic first-order oracle (SFO) complexity, which is better than the state-of-the-art method whose SFO upper bound is ${\\mathcal O}\\big((n + n^{2/3}κ_xκ_y^2)\\log (1/ε)\\big)$, where $κ_x\\triangleq L/μ_x$ and $κ_y\\triangleq L/μ_y$. For the ill-conditioned case, we provide an accelerated algorithm to reduce the computational cost further. It achieves $\\tilde{\\mathcal O}\\big((n+\\sqrt{n}\\,κ_xκ_y)\\log^2 (1/ε)\\big)$ SFO upper bound when $κ_y \\gtrsim \\sqrt{n}$. Our ideas also can be applied to the more general setting that the objective function only satisfies PL condition for one variable. Numerical experiments validate the superiority of proposed methods.",
  "categories": [
    "math.OC",
    "cs.LG"
  ],
  "primary_category": "math.OC",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15868",
  "pdf_url": "https://arxiv.org/pdf/2307.15868v1",
  "comment": "published in NeurIPS 2022; fix a mistake in the proof of Thm. 4.1 and polish the writing",
  "num_versions": null,
  "size_before_bytes": 360252,
  "size_after_bytes": 202803
}