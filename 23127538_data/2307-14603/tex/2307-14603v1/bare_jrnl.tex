%% bare_jrnl.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "% Figure environment removed

\subsection{Segmentation and classification for lymphocyte nuclei}\label{L-seg}
% lymphocyte has very similar performance in  in all the HE images
%We aim to get high-quality segmentation and classification results of lymphocyte nuclei in the H\&E tile images with low labor and time cost. 
The immune response in pancreatic tumors is usually not strong, and the distribution of immune cells is relatively sparse. In contrast, we note that the lymphocyte nuclei' morphological characteristics are independent of the organs in which they are located. The lymphocyte nuclei on pathology images of other organs should be morphologically identical to the pancreatic lymphocyte nuclei, although these images have different backgrounds. Therefore, we considered 
transferring the lymphocyte nuclei from a public dataset with lymphocyte nuclei annotations of other organs to our pancreatic pathological dataset without lymphocyte nuclei annotations.

To this end, we introduce the combination of a pretained baseline model for nuclei segmentation and a domain adversarial network for lymphocyte nuclei classification shown in Figure \ref{HD}. HoVer-Net is a robust baseline model for nuclei segmentation and has demonstrated state-of-the-art performance on various nuclei segmentation tasks \cite{2019HoVer}. There are three branches in the HoVer-Net architecture: the segmentation branch for getting coarse prediction, the structure branch for solving the nuclei overlapping, and the classification branch for nuclei recognition. We use the segmentation and structure branches from the pretrained HoVer-Net in the PanNuke dataset  \cite{gamper2020pannuke} to segment the nuclei for our task. As for the classification, we train a domain adversarial neural network (DANN)  \cite{2015Domain} to get better performance on lymphocyte nuclei recognition. A domain adversarial training strategy is used in the classification network. Figure \ref{dann} demonstrates our training strategy for domain adversarial learning. We crop 239503 lymphocyte nuclei images and 265241 non-lymphocyte nuclei images from the PanNuke dataset with nuclei annotations. Then we obtain 121954 nuclei images with unknown categories (lymphocyte or non-lymphocyte nuclei) based on the segmentation results from the pretrained HoVer-Net. We choose the former as the source domain and the latter as the target domain to train the domain adversarial network for lymphocyte nuclei recognition. ResNet18 \cite{2016Deep} is used as the feature extractor, and two loss terms are calculated as follows.

\begin{equation}\label{losscls}
  L_{cls}=\sum_{i=1}^M y_i\log\frac{1}{G_{y}(G_{f}(x_i))},
\end{equation}

\begin{equation}\label{lossadv}
  L_{adv}=\sum_{i=1}^M d_{i}\log\frac{1}{G_{d}(G_{f}(x_{i}))}+
  (1-d_{i})\log\frac{1}{G_{d}(G_{f}(x_{i}))},
\end{equation}
where $G_f$, $G_y$, and $G_d$ denote the feature extractor, image classifier, and domain discriminator, respectively. $M$ denotes the number of training samples. $x_i$, $y_i$, and $d_i$ denote the image input, nucleus category annotation, and domain label of sample $i$, respectively.
The overall loss of DANN is defined by 
\begin{equation}\label{loss}
  L_{DANN}=L_{cls}+L_{adv}
\end{equation}

% Figure environment removed

% Figure environment removed

\subsection{Cross-scale attention guidance mechanism}
%We observed that TLSs usually occur in regions with high lymphocyte nuclei density. 
TLSs are the particular forms of lymphocyte aggregations, and it is natural to look for TLSs where lymphocytes are relatively aggregated. Therefore, we calculate the lymphocyte density map based on the detected lymphocyte nuclei and convert it to be attention map to guide the detection of TLSs.
%Therefore, we calculated the lymphocyte nuclei density of the H\&E tile images based on the predictions by the previous lymphocyte nuclei segmentation and classification models. 
To obtain the lymphocyte density map on a WSI, we count the number $N_{ij}$ of predicted lymphocyte nuclei in each non-overlapping $d \times d$ patch at location $(i,j)$. Each pixel occupies $25 \times 25$ $\mu m^2$. Then we get a gray-scale lymphocyte density map by the following formulation:

\begin{equation}\label{loss}
  D_{ij}=255 \times \frac{N_{ij}-N_{min}}{N_{max}-N_{min}},
\end{equation}
where $N_{max}$ and $N_{min}$ are the maximum and minimum of the predicted number of lymphocyte nuclei among the patches. Figure \ref{ldm} shows the lymphocyte density map calculated for a WSI from our collected dataset. We split the three channels of the original H\&E images into blue, green, and red channels shown in Figure \ref{fig1}. It can be found that the target TLS regions show low intensity in each color channel. We add a reverse operation to make the predicted lymphocyte density map compatible with the original H\&E image to generate our desired attention map. Each lymphocyte density attention $A_{ij}$ at location $(i,j)$ is calculated as $A_{ij}=255-D_{ij}$. Then a cross-scale attention guidance network is established on the U-shape backbone architecture. There are four channel inputs of the backbone to jointly learn the coarse-scale features from the original H\&E images and the fine-scale features from the calculated lymphocyte density attention.

% Figure environment removed

\subsection{SDF loss for noise-sensitive constraint}
Considering that accurate positioning usually has high priority than finding the boundary of a TLS for clinical issues. Therefore, we train the proposed network with the bounding box annotations from the experts, which is weakly supervised for a segmentation task. Generally, it is difficult for a semantic segmentation network to detect small objects by training with general segmentation loss, such as Dice loss and cross-entropy (CE) loss, because these small regions almost have no impact on the overall loss. However, minor prediction errors can lead to misdiagnosis. To solve this problem, we introduce a noise-sensitive constraint by embedding a signed distance function (SDF) loss into the overall loss function for the training procedure. The signed distance function of a predicted binary mask $Y$ can be calculated as follows:

\begin{equation}\label{dist}
	SDF(x,Y)=
	\left\{
	\begin{array}{lr}
    \underset{y \in \partial Y}{\min}-d(x,y), &x \in Y_{in} \\
	0, &x \in \partial Y \\
    \underset{y \in \partial Y}{\min}d(x,y), &x \in Y_{out},
	\end{array}
	\right.
	\end{equation}
where $d(x,y)$ is the Euclidian distance between $x$ and $y$, and $Y_{in}$, $Y_{out}$ and $\partial Y$ denote the inside, the outside and the boundary of the object, respectively. Then we get the signed distance loss by calculating the mean square error (MSE) between the SDFs of segmentation and ground truth:
\begin{equation}\label{loss}
  L_{SDF}(Y,\hat Y)=\frac{\sum_{i=1}^N(SDF(x_i,Y)-SDF(x_i,\hat Y))^2}{N}.
\end{equation}
where $N$ is the number of pixels in an input image. As shown in Figure \ref{sdf}, small segmentation errors significantly impact the SDF distribution. Besides, the traditional Dice and CE losses are also used in the training procedure. They can be calculated as follows:

\begin{equation}\label{loss}
  L_{Dice}=-\frac{2 \sum_{i=1}^N s_i g_i}{\sum_{i=1}^N s_i^2 + \sum_{i=1}^N g_i^2},
\end{equation}

\begin{equation}\label{loss}
  L_{CE}= -\frac{\sum_{i=1}^N g_i lnp_i}{N},
\end{equation}
where $s_i$ and $g_i$ denote the predicted segmentation and the ground truth of pixel $i$, respectively. $p_i$ denotes the softmax output of $s_i$. Therefore, the overall loss function of our proposed TLSs segmentation network can be formulated as follows:

\begin{equation}\label{loss}
  L=L_{Dice}+L_{CE}+L_{SDF}.
\end{equation}


% Figure environment removed

\section{Experiments}
\subsection{Dataset}
In this work, we evaluate our proposed method on two datasets collected from Nanjing Drum Tower Hospital (NDTH) and Jiangsu Province Hospital of Chinese Medicine (JHCM), respectively. The NDTH  dataset consists of 38 WSIs from 12 surgical pathology-confirmed PDAC patients. The JHCM dataset is composed of 57 WSIs from 41 PDAC patients. To verify the generalization and the performance in few-shot learning of our proposed method, we train and validate our model on the smaller-scale NDTH dataset and test on the larger-scale JHCM dataset. This study was approved by the Ethics Committee of Nanjing Drum Tower Hospital and Jiangsu Province Hospital of Chinese Medicine.

The TLSs on the WSIs are annotated with bounding boxes by two experienced pathologists. The NDTH dataset is divided into four equal folds. One fold containing 9 WSIs is fixed as the validation set, and the other three folds containing 29 WSIs are adopted for training throughout the experiments. The JHCM dataset is only used for testing (i.e., zero-shot evaluation). 

\subsection{Evaluation metrics}
%\textit{Precision} and \textit{Recall} are usually used to evaluate the accuracy of a binary classification model, which are defined as follows:
We employ the precision, recall and  $F_{\beta}$ score to measure the detection accuracy in our experiments, which can be calculated as follows:

\begin{equation}\label{pre}
  Precision=\frac{TP}{TP+FP},
\end{equation}

\begin{equation}\label{rec}
  Recall=\frac{TP}{TP+FN},
\end{equation}

\begin{equation}\label{fscore}
  F_{\beta}=(1+{\beta}^2) \times \frac{Precision\times Recall}{{\beta}^2 \times Precision+Recall},
\end{equation}
where $TP$, $FP$ and $FN$ denote the true positive, false positive and false negative TLS predictions, respectively. Generally, $F_1$ score (i.e., $\beta=1$ in Eq. \ref{fscore}) is used to be the harmonic mean of both the precision and recall. However, because the false negative predictions generally bring greater harm than the false positive predictions in clinical issues, which means the recall metric is more important than the precision metric. Therefore, we also use the $F_2$ score (i.e., $\beta=2$ in Eq. \ref{fscore}) to evaluate the detection performance with greater weight on recall.

Moreover, because of the difference between the TLS annotations by different experts, especially in the regions where it is difficult to distinguish whether there is a single TLS or aggregated TLSs. Fig. \ref{andiff} shows two examples to describe the annotation difference.

% Figure environment removed

Therefore, we propose some new evaluation metrics to coordinate the annotation difference between the experts. Without loss of generality, since the precision describes how many positive cases are true among all the model predictions, we introduce the $TPS$ here instead of $TP$ to represent the TLS number of segmentation results that overlap with ground truths. Similarly, the recall describes how many annotated boxes are truly predicted, we introduce the $TPB$ instead of $TP$ to represent the number of annotated bounding boxes that overlap with the segmentation results. It can be seen that the $TPS$ and $TPB$ are generalizations of the general $TP$ without the one-on-one constraint. Then, we define the corresponding segmentation precision (SP) and box recall (BR) as follows:
%In our case, all ground truths and segmentation results are represented by boxes. Figure \ref{metric} show two schematic diagrams to illustrate the $TP_{seg}$ and $TP_{box}$. Then, the proposed metrics $Precision^{*}$ and $Recall^{*}$ can be defined as follows:
% 在这个数据集的情况下，我们采用的是利用分割框架来进行tls的检测，而对于分割来说，边界重要，对于检测来说，xxx更重要，因此，我们提出了一种新的判别方式（以适用于我们的这种分割代检测的策略）
%Considering that we aim to detect TLSs by a semantic segmentation network with ``weak'' bounding box annotations, we improve the detection metrics to evaluate semantic segmentation models for TLS detection. These metrics can be calculated as follows.


\begin{equation}\label{sp}
  SP=\frac{TPS}{TPS+FP},
\end{equation}

\begin{equation}\label{br}
  BR=\frac{TPB}{TPB+FN}.
\end{equation}
Similarly, the general $F_{\beta}$ score ($GF_{\beta}$) can be calculated as follows:
\begin{equation}\label{fscore}
  GF_{\beta}=(1+{\beta}^2) \times \frac{SP\times BR}{{\beta}^2 \times SP + BR}.
\end{equation}
Fig. \ref{metric} illustrates the insight of the proposed metrics. 

% Figure environment removed

\subsection{Ablation study}
In this section, we present the ablation study to verify the effectiveness of our proposed LDA and SDF in our method. We show the ablation study results in Table \ref{ablations} to investigate the individual impact of the proposed LDA and SDF module.

\subsubsection{Effectiveness of LDA}Without using LDA, the performance significantly drops on our collected datasets, leading to a decrease of 1.60\%-3.56\% in precision, 2.24\%-5.42\% in the recall, 3.16\%-3.42\% in $F_1$ score, and 2.70\%-4.60\% in $F_2$ score. For the introduced metrics, there is a performance decrease of 3.47\%-6.11\% in SP, 2.15\%-7.23\% in BR, 4.08\%-5.32\% in $GF_1$ score, and 3.01\%-6.46\% in $GF_2$ score without the LDA. Figure \ref{LDA_vis} shows the visual comparison of the ablation study for the proposed LDA. It can be found that the false positive predictions with low attention and false negative predictions with high attention can be efficiently captured.

\subsubsection{Effectiveness of SDF}Without using the SDF loss, the performance also drops on our collected  datasets, leading to a decrease of 2.39\%-5.48\% in precision, 1.85\%-3.45\% in $F_1$ score, and 1.27\%-1.48\% in $F_2$ score. For the introduced metrics, there is a performance decrease of 2.41\%-3.88\% in SP, 1.73\%-2.41\% in $GF_1$ score, and 0.51\%-2.41\% in $GF_2$ score without the SDF loss. It should be pointed that the SDF loss leads to a improvement of 1.21\% in recall on the NDTH dataset while it leads to a decrease of 0.84\% in recall on the JHCM dataset, which indicates that the SDF loss improves the overall performance of the detection model by mainly reducing the tiny false positive predictions instead of false negative predictions with relatively large sizes. Figure \ref{SDF_vis} presents the visual comparison of the ablation study for the SDF loss. We can see that tiny segmentation errors can cause huge losses in terms of the signed distance function map, and the SDF loss can significantly reduce the tiny false positive predictions.

\subsubsection{Effectiveness of LDA and SDF}Additionally, it can be observed that without using LDA and SDF losses leads to the worst performance in the recall, $F_1$ score, $F_2$ score BR, $GF_1$ score, $GF_2$ score, indicating that both the proposed LDA and SDF losses are essential for performance improvements. It should be pointed that the baseline model (the proposed method without LDA and SDF loss) achieves the best performance in segmentation precision on NDTH dataset, while the proposed method outperforms the baseline model by 0.29\% in the precision and achieves the best performance in all other metrics.

\begin{table*}[htbp]
\centering
\caption{Ablation study results of the proposed method on two collected datasets. Experimental results on the NDTH validation set and the JHCM dataset are presented. w/o means removing the corresponding module. P, R, F1 and F2 denote the precision, recall, $F_1$ score and $F_2$ score, respectively. SP, BR, GF1 and GF2 represent the introduced segmentation precision, box recall, $GF_1$ score and $GF_2$ score, respectively.}
\setlength{\tabcolsep}{4.2mm}{}{
\begin{tabular}{clcccccccc}
\toprule

Datasets                & Methods              & P      & R       & F1 & F2  &SP &BR &GF1  &GF2      \\ \midrule
\multirow{4}{*}{NDTH}   &Proposed       & \textbf{78.21}           & \textbf{84.34}      & \textbf{81.16}  &\textbf{83.04} &84.80 &\textbf{87.95} &\textbf{86.34} &\textbf{87.30}\\
                        &Proposed w/o $L_{SDF}$      & 75.82           & 83.13      & 79.31 &81.56  &82.39&85.54&83.93&84.89\\
				&Proposed w/o LDA        & 76.61          &78.92      & 77.74  & 78.44 &81.33&80.72&81.02&80.84\\
                &Proposed w/o LDA, $L_{SDF}$      & 77.92           & 72.29      & 75.00 & 73.35 &\textbf{86.21} &74.70&80.04&76.75 \\
                \midrule
\multirow{4}{*}{JHCM} &Proposed       & \textbf{62.25}           & 83.13      & \textbf{71.19}  & \textbf{77.90} & \textbf{76.15}           & 87.70      & \textbf{81.52}  & \textbf{85.12}  \\
                        &Proposed w/o $L_{SDF}$ & 56.77           & \textbf{83.97}     & 67.74  & 76.63  & 72.87           & \textbf{88.16}     & 79.79  & 84.61   \\
				&Proposed w/o LDA         & 58.69          &80.89      & 68.03 & 75.20  & 70.74          &85.55      & 77.44  & 82.11\\
                &Proposed w/o LDA, $L_{SDF}$     & 59.98           & 77.17      & 62.12 & 70.35 & 69.89           & 81.36      & 75.19 & 78.77 \\\bottomrule
\end{tabular}}
\label{ablations}
\end{table*}

% Figure environment removed

 % Figure environment removed

\subsection{Comparison with other state-of-the-art segmentation methods}
In this section, we compare our proposed method with other state-of-the-art (SOTA) methods for TLS detection. The UNet\cite{2015U}, Deeplab v3+\cite{2018Encoder}, and  nnUNet \cite{2018nnU} are included in our experiments for their excellent performance in medical image segmentation. All these methods are trained on the  NDTH training set  and evaluated on the NDTH validation set and the JHCM dataset. Quantitative comparison results are presented on Table \ref{com_sota}.

Experimental results in Table \ref{com_sota} demonstrate that our proposed method significantly outperforms these SOTA methods, and achieves the best performance in recall, $F_1$ score, $F_2$ score, SP, $GF_1$ score and $GF_2$ score. We observe that the generic UNet \cite{2015U} and deeplab v3+ \cite{2018Encoder} always have conservative predictions by minimizing the false positive predictions as much as possible, despite causing many false negative predictions. Therefore, they have a higher precision and SP than ours, but leading to  18.07\%-44.36\%, 6.58\%-21.01\%,  13.68\%-35.25\%, 20.48\%-47.35\%, 9.25\%-29.10\% and 16.28\%-40.68\% decrease in recall, $F_1$ score, $F_2$ score, $GF_1$ score and $GF_2$ score, respectively comparing with ours. Figure \ref{cp_vis} shows the visual comparison of TLS detection results between the above methods and ours.

\begin{table*}[htbp]
\caption{Quantitative comparison results with other SOTA methods for TLSs detection on two collected dataset. Experimental results on the NDTH validation set and the JHCM dataset are presented. P, R, F1 and F2 denote the precision, recall, $F_1$ score and $F_2$ score, respectively. SP, BR, GF1 and GF2 represent the introduced segmentation precision, box recall, $GF_1$ score and $GF_2$ score, respectively.}
\setlength{\tabcolsep}{4.8mm}{}{
\begin{tabular}{clcccccccc}
\toprule
Datasets                & Methods             & P     & R        & F1  &F2     &  SP & BR & GF1  & GF2        \\ \midrule
\multirow{4}{*}{NDTH}   & UNet\cite{2015U}                 & \textbf{85.27} & 66.27          & 74.58  & 69.36     & \textbf{89.92} & 67.47          & 77.09 & 71.02  \\
                        & DeepLab v3+\cite{2018Encoder}           & 84.68          & 63.25          & 72.41 & 66.62   & 85.48          & 63.86          & 73.10 &67.26     \\
                        & nnUNet\cite{2018nnU}                & 77.92          & 72.29          & 75.00  & 73.35  & 86.21          & 74.70          & 80.04 &76.75      \\
                        & Proposed    & 78.21          & \textbf{84.34} & \textbf{81.16} & \textbf{83.04}  & 84.80          & \textbf{87.95} & \textbf{86.34} &\textbf{87.30}\\ \midrule
\multirow{4}{*}{JHCM} & UNet\cite{2015U}                & \textbf{76.57}          & 45.39          & 56.99  & 49.11   & \textbf{82.88}          & 49.02          & 61.60   & 53.38   \\
                        & DeepLab v3+\cite{2018Encoder}          & 71.11          & 38.77          & 50.18 & 42.65  & 74.78          & 40.35          & 52.42      &  44.44   \\
                        & nnUNet\cite{2018nnU}                  &59.98                &77.17                & 62.12     & 70.35  &69.89                &81.36                & 75.19    &  78.77     \\
                        & Proposed               & 62.25               & \textbf{83.13}               & \textbf{71.19}    & \textbf{77.90}   & 76.15               & \textbf{87.70}               & \textbf{81.52}  & \textbf{85.12}    \\ \bottomrule
\end{tabular}}
\label{com_sota}
\end{table*}

% Figure environment removed

\subsection{Application for studying the relationship between TLS density and peripancreatic vascular invasion}

For patients with pancreatic tumors accompanied by peripancreatic vascular invasion, especially venous invasion, whether the peripancreatic vessel is invaded determines the direction of treatment, and also affect the survival time and prognosis of patients \cite{1996Vascular, 2008A, 2016Preoperative}. In this section, we apply our proposed TLS detection method to study the relationship between TLS density and peripancreatic vascular invasion.

We collect the clinical information from 12 patients in NDTH dataset and 40 patients (there is a patient whose clinical information is not available) in JHCM datatset to carry out our statistical experiments. 
%We collect the clinical information from 10 patients in NDTH dataset and 30 patients in JHCM datatset to carry out our statistical experiments, and there are IA, IB, IIB, IIIA and IV tumor stages among the 40 patients with collected clinical information.
 %Six of the 12 samples analyzed are classified, including stages IA and IB in TNM staging. The other six are classified as late, including stages IIB, III, and IV in TNM staging. We calculate the lymphocyte density and TLSs density of these 12 samples, respectively, and use the Wilcoxon rank sum test to observe the correlation between these two factors and tumor stages. The calculated results are shown in Figure \ref{box}, and the density of TLSs on one WSI is more closely related to the pancreatic tumor stage ($p = 0.046$) than the density of lymphocyte nuclei ($p = 0.345$). Thus, as an aggregate of lymphocytes, TLSs may be more significant than lymphocytes in predicting PDAC staging.
% To demonstrate that our work can be used for biological research, i.e. the density of TLSs is more related to tumor staging than the density of lymphocyte nuclei. We study the TLS on 12 WSIs from different patients who were in different stages of pancreatic cancer. We divide the staging of pancreatic cancer into two categories, 0 and 1. Among them, 0 includes stages IA and IB in TNM staging, while 1 includes stages IIB, III, and IV.
%Among the 12 patients, 6 were in stage 0 and 6 were in stage 1. We calculate the density of TLSs and the density of lymphocyte nuclei on the WSI, respectively. Then we use  Wilcoxon rank sum test to observe the correlation between the above two factors and tumor staging.
%Our results are shown in Fig \ref{box}, the density of the TLSs on the WSI is more related to the stage of pancreatic cancer($p = 0.046$), than the density of lymphocyte nuclei($p = 0.345$).
%We remove the sections without pathological information and obtain 40 samples. Out of the 40 samples analyzed, 10 are from Nanjing Drum Tower Hospital, and the other 30 are from Jiangsu Provincial Hospital of Traditional Chinese Medicine. 
%To simplify the problem modeling, we divide the 40 samples into two categories: the IA and IB stage as stage0, and the IIB, IIIA, and IV stage as stage1. 
There are 19 patients without peripancreatic vascular invasion and 33 patients with peripancreatic vascular invasion. Therefore, we divide the 52 samples into two groups: the no-invasion group and the invasion group. Then we apply our proposed method to detect the TLSs on their WSIs, and calculate the TLS density of the patients in the two groups, respectively. The TLS density is calculated as the ratio of the TLS number to the WSI's area.

% The Shapiro-Wilk (S-W) test \cite{1965An} is conducted to check whether the TLS densities of the 52 patients obey the normal distribution. Based on the S-W test results of $p=0.002$ and $p=0.006$ on the stage0 and stage1 category, respectively (i.e., they don't obey the normal distribution), we use the Mann-Whitney U test \cite{1947On} to observe the correlation between the TLS density and the pancreatic tumor staging. We get the result of $p=0.041$ for the Mann-Whitney U test, which indicates that the TLS density  is indeed related to the staging of pancreatic tumors.

The Shapiro-Wilk (S-W) test \cite{1965An} is conducted to check whether the TLS densities of the 52 patients obey the normal distribution. Based on the S-W test results of $p<0.05$ and $p<0.001$ on the invasion and no-invasion group, respectively (i.e., they do not obey the normal distribution), we use the Mann-Whitney U test \cite{1947On} to observe the correlation between the TLS density and the peripancreatic vascular invasion. We get the result of $p=0.03$ for the Mann-Whitney U test, which indicates that the TLS density  is indeed related to the peripancreatic vascular invasion.

% For comparison, we also study on the correlation between the lymphocyte density and the pancreatic tumor staging. The same statistical testing experiments are conducted for the lymphocyte density. We get the S-W test results of $p=0.005$ on the stage1 category (i.e., they don't obey the normal distribution). we use the Mann-Whitney U test to observe the correlation between the TLS density and the pancreatic tumor staging. The we get the result of $p=0.616$ for the Mann-Whitney U test, which indicates that the lymphocyte density has no significant relationship to the staging of pancreatic tumors. Figure \ref{box} presents the distributions of the two stage categories for the TLS density and lymphocyte density, respectively.

For comparison, we also study on the correlation between the lymphocyte density and the peripancreatic vascular invasion. The same statistical testing experiments are conducted for the lymphocyte density. We get the S-W test results of $p<0.01$ on the invasion group (i.e., they do not obey the normal distribution). We use the Mann-Whitney U test to observe the correlation between the TLS density and the peripancreatic vascular invasion. The we get the result of $p=0.1$ for the Mann-Whitney U test, which indicates that the lymphocyte density has no significant relationship to the peripancreatic vascular invasion. Figure \ref{box} presents the distributions of the TLS density and lymphocyte density for the two groups.


% Figure environment removed


\section{Discussions}
In this paper, we develop a novel weakly-supervised segmentation framework for TLS detection. Since TLSs are aggregates of lymphocytes, we utilize the density map of lymphocyte nuclei as an attention guidance in our approach. Although the segmentation of individual lymphocyte nucleus may not affect the TLS detection, the overall accuracy of lymphocyte nuclei segmentation results may still impact the detection results. Therefore, we also show the lymphocyte nuclei segmentation results in this section. As described in Section \ref{L-seg}, we have used a domain-adversarial approach to segment lymphocyte nuclei on pancreatic pathology images.

We show the segmentation and classification results of our designed combination of the baseline model for nuclei segmentation and the domain adversarial network for lymphocyte nuclei recognition in Table \ref{seg_results}. The segmentation accuracy, sensitivity, and specificity for the nucleus achieve 86.20\%, 76.29\%, and 80.94\%, respectively. The classification accuracy, sensitivity, and specificity for lymphocyte and non-lymphocyte nuclei achieve 88.87\%, 94.79\%, and 34.41\%, respectively. Figure \ref{HD_vis} presents two visual results for the segmentation and classification, respectively.

\begin{table}[htbp]
        \centering
		\caption{Segmentation and classification results for lymphocyte nucleus on our test dataset.}
		\vspace{0pt}	
		\renewcommand\arraystretch{2}
		\setlength{\tabcolsep}{4mm}{}{
			\begin{tabular}{lccc}
				\hline
				  Methods                     &Accuracy       & Sensitivity      & Specificity    \\
				\hline
                  HoVerNet                   &86.20                   &76.29               &80.94    \\
				DANN     &88.87                &94.79                     &34.41         \\
				\hline
		\end{tabular}}
		\label{seg_results}
	\end{table}

% Figure environment removed
 
%It should be pointed out that we utilize the simple U-shape segmentation network rather than a complex object detection framework to detect TLSs because detection frameworks usually have more parameters to be trained and require a larger number of annotated data for training than the U-shape segmentation network. Therefore, regarding few-shot learning, the detection framework has no significant superiority over the U-shape network. The designed combination of the baseline model for nuclei segmentation and domain adversarial network for lymphocyte nuclei classification can be further improved regarding the classification results, especially the specificity of lymphocyte nuclei recognition. 

We would like to highlight that we have opted for a simple U-shape segmentation network to detect TLSs rather than a complex object detection framework. This decision is based on the fact that detection frameworks usually require a larger amount of annotated data and parameters to be trained compared to the U-shape segmentation network. Therefore, in the context of few-shot learning, the detection framework does not notably outperform the U-shape network. It is worth noting that the designed combination of the baseline model for nuclei segmentation and domain adversarial network for lymphocyte nuclei classification can still be improved, especially in terms of lymphocyte nuclei recognition specificity.

%As the detection framework depends heavily on the number of annotated data and parameters required for training, we opt for a simple U-shape segmentation network over a complex object detection framework for TLS detection. Since the detection framework has no significant superiority over the U-shape network regarding few-shot learning, we use a combination of the baseline model for nuclei segmentation and domain adversarial network for lymphocyte nuclei classification. We acknowledge that the classification results, particularly the specificity of lymphocyte nuclei recognition, can be further enhanced.

The proposed LDA improves the TLS segmentation performance by multi-channel fusion. However, the proposed LDA can also be embedded in the U-shape network architecture or used as an extra loss function for training, which can be studied in our subsequent work. Additionally, we set the patch size $d$ for coarse-scale pooling and fine-scale density calculation as 32 based on medical experts' experience. 
%More experimental results about this hyper-parameter can be studied.

Our proposed LDA shows an improvement in TLS segmentation performance through multi-channel fusion. However, we intend to investigate further the potential benefits of embedding the proposed LDA in the U-shape network architecture or using it as an additional loss function during training in future work. Furthermore, we have chosen a patch size $d$ of 32 for coarse-scale pooling and fine-scale density calculation based on medical experts' recommendations.

% 对于tls，我们与脉管侵犯进行了关联，发现与单独的淋巴细胞相比，三级淋巴结构更能预示一个好的预后，这是肿瘤的免疫微环境探索的一部分，随着样本量的扩大和免疫细胞的细分，我们将对免疫微环境进行更加细致深入的探索
Regarding the detected TLSs, we have examined the relationship between TLSs and vascular invasion. Through a study of two central patients, we found that TLSs have a stronger association with vascular invasion than individual lymphocytes, highlighting TLSs as an important component of the tumor immune microenvironment. With the expansion of sample size and the subdivision of lymphocyte categories, we will conduct more detailed and in-depth investigations of the immune microenvironment.



\section{Conclusions}
In this paper, we propose a novel weakly supervised segmentation network embedding cross-scale attention guidance and noise-sensitive constraint for TLS detection. We firstly obtain the segmentation and classification results of the lymphocyte nuclei by combining a pretrained baseline model for nuclei segmentation and a domain adversarial network for lymphocyte nuclei recognition. Then, we establish a cross-scale attention guidance network by jointly learning the coarse-scale features from the original H\&E images and fine-scale features from our calculated lymphocyte density attention. A noise-sensitive constraint is introduced by embedding the signed distance function loss in the training procedure to reduce tiny segmentation errors. Experimental results on two collected datasets demonstrate that our proposed algorithm outperforms the state-of-the-art segmentation-based methods for TLS detection. Additionally, we apply our method to validate that the TLS density is significantly related to the peripancreatic vascular invasion based on the clinical data acquired from two independent institutions. Our proposed approach can be applied to the TLS analysis for the tumors in other organs.
 



\section*{Acknowledgment}
This work is supported by China's Ministry of Science and Technology(No. SQ2020YFA0713800), the National Natural Science Foundation of China(No. 11971229, 12001273), and the Fundamental Research Funds for the Central Universities(No.30922010904).




% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

\bibliographystyle{ieeetr}
\bibliography{TLSs-bibliography.bib}%

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{% Figure removed}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}

% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}


% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


