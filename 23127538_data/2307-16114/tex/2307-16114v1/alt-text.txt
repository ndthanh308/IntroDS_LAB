Figure 1:

This figure is made of 8 smaller figures organized in 2 rows and 4 columns. Each sub-figure is labeled from a to h, with section a being the top left and h being the bottom right. Each sub-figure displays a holographic user and a local user, both of whom are wearing Hololens 2 HMDs. Sub figures a and b show the holographic user actuating objects with 1 and 2 Toios, respectively. Sub figures c and d show the holographic user modifying the dimensions of an image, the corners of which are represented by a Toio, and a virtual object with 3 attached Toios which control its scale. Sub figure e shows a Toio representing the remote user as a holographic miniature person moving furniture in the room, with the Toio representing their location in the room and the hologram on top. Sub figure f shows a notification scenario where the remote user notifies the local user by commanding 2 Toios to tap their arm. Sub figure g shows the Toios placed vertically on a whiteboard representing sticky notes, the position of which the remote holographic user can modify by grabbing. Sub figure h shows a holographic remote user and local user facing the same direction, with the local user holding onto a pen attached to the Toio and the remote user "guiding" their hand by moving the Toio, creating the illusion as though the remote user has grabbed the local users hand.


Figure 2:

This figure represents the system setup. It's split into two parts, one visualizing the local environment and the other the remote environment. The local environment depicts an over-the-shoulder angle of the local user looking at the Toio mat with 3 Toios on top, a remote holographic user displayed in front of them using mesh rendering, Bluetooth communication to a nearby PC for communicating with the Toio's and finally a Hololens 2 on both the local and remote users. The remote environment depicts a remote user with a Hololens 2, using Hololens hand-tracking and an Azure Kinect RGBD Camera on a stand opposite them.


Figure 3:

This figure depicts the design space for HoloBots. Split into 3 sections: section one depicts 4 interactions techniques, object actuation (shows a remote user moving virtual objects represented by Toios on the Toio mat), shared tangible UI (depicts a virtual object with the Toios controlling its scale and both the remote and local users able to interact), miniature body interaction (depicts a remote user in miniature in a miniature living room, with the local user waving to them) and haptic communication (depicts local and remote user facing the same direction with the remote user guiding the local user's hand for sketching). Section 2 depicts 2 actuation types, moving an active object (virtual or physical object is represented by or attached to the Toios) and moving a passive object (Toios are used to move a physical object). Section 3 depicts the surface types, horizontal surface (Toio mat on a table) and vertical surface (Toio mat on a wall).


Figure 4:

Depicts a remote user and local user sitting on opposite sides of a table, in the local user's environment with the Toio mat between them. The remote user is actuating an object (a dinosaur) with the Toio representing its position for the local user (the dinosaur is on top of the Toio). The remote user is moving the dinosaur from the right of the Toio mat to the left.


Figure 5:

Depicts a remote user and local user sitting on opposite sides of a table, in the local user's environment with the Toio mat between them. The Toios represent two opposing corners of a 2D image, and both the remote and local users modify the dimensions, position, and scale of the image by grabbing a corner (the local user grabs Toio, the remote user grabs the corner of the image virtually). 


Figure 6:

Depicts a miniature remote user shown standing above the Toio on the Toio mat and a local user sitting behind a table with the Toio mat in front of them. The local user grabs the Toio and moves it to move the remote user within the virtual environment visualized on the Toio mat.


Figure 7:

Depicts a remote user and local user sitting on the same side of a table, in the local user's environment with the Toio mat in front of them. A pen is attached to the Toio, which the local user holds. The remote user then moves the Toio (and by extension the attached pen) while the local user is holding on, creating the illusion that the remote user is physically holding and moving the local user's hand.


Figure 8:

Depicts a remote user and local user sitting on opposite sides of a table, in the local user's environment with the Toio mat between them. Two Toios are tracked to the remote user's index finger and thumb. Using this, the remote user moves a small physical object placed on the Toio mat. The Toios "grab" and move the objects on the remote user's behalf.


Figure 9:

Depicts a remote user and a local user standing opposite one another with a whiteboard on a wall between them. The Toio mat is placed on the wall vertically, with some papers stuck to it and the wall. A sticky note is attached to a Toio, which is on the mat on the wall, which the remote user moves around on the whiteboard.


Figure 10:

Depicts a remote holographic user virtually grabbing a pen, represented by a physical pen attached to a Toio in the local user's environment, and when the remote user draws using the pen the Toio recreates the drawing by following the remote user's hand via hand-tracking. 


Figure 11:

Depicts a remote user and local user sitting on opposite sides of a table, in the local user's environment with the Toio mat between them. There are some physical objects placed on the Toio mat, like trees, rocks, and a dinosaur attached to a Toio. The remote user moves the dinosaur around the mat by actuating the Toio.


Figure 12:

Depicts a remote user and local user sitting on opposite sides of a table, in the local user's environment with the Toio mat between them. There are 3 Toios, one represents a hockey puck and the other two represent paddles while both remote and local user play table hockey. The puck Toio bounces between both users as they collide with the "paddle" Toios. The paddle Toios are held in the hands of both remote and local users, with the remote user virtually grabbing the Toio but the local user physically grabbing the Toio.


Figure 13:

Depicts a miniature remote user holographic user on a Toio mat in the local user's environment. The remote user's location between the miniature furniture is represented by a Toio. There are several pieces of furniture, and the remote user walks up to one and pushes it in another direction; all the while, the Toio represents their position. 


Figure 14:

Depicts a remote user and local user sitting on opposite sides of a table, in the local user's environment with the Toio mat between them. There is a virtual animated 3D model of a chicken between them on the Toio mat. There are 3 Toios, each of which the remote or local users can use to modify the scale of the chicken. The local user widens the chicken model in one frame, while in another frame, the remote user lengthens the chicken.


Figure 15:

Depicts a remote user and local user sitting next to each other on the same side of a table, in the local user's environment, with the Toio mat in front of them. There are two Toios on a Toio mat in front of them, with the local user reading a book with their arm resting on the Toio mat. The remote user selects the Toios, then moves them to touch/push the local user's arm to notify her, which they do as the local user's attention moves from the book to her arm, which is being touched by the Toios.


Figure 16:

Depicts the user study setup. In two frames, one depicts the remote user standing with an equipped Hololens 2, and an Azure Kinect behind a table in front of them, with the Toio mat on the table and a tv with a video call to the local user on a TV behind and above the kinect. The second frame depicts the local user with an iPad (used for the video call to the remote user, with the camera angle pointed to the local user's Toio mat), the local user sitting in front of a table with a Toio mat, Toios, and some objects. Finally, the local user is also wearing a Hololens 2.


Figure 17:

Depicts the statistical results of the Social Presence Questionnaire, as evaluated during our user study.


Figure 18:

Depicts the statistical results of the cognitive workload, system usability, and preference as evaluated during our user study.