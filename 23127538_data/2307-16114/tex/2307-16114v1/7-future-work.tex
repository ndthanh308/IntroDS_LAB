\section{Future Work}

In this paper, our design space exploration is limited to the form factor of \system{}. In this section, we suggest several directions to expand the design space of holographic tangible remote collaboration with different form factors, interaction modality, and user representations.

% Figure environment removed

\subsubsection*{\textbf{Scalability of Interaction Area}}
In our current implementation, the interaction area was limited to one Toio mat, which restricted users to using the limited space of the table or whiteboard.
However, by aligning multiple Toio mats, we can expand the interaction area to cover larger surfaces, such as larger tables or whiteboards.
This expansion would allow for the use of additional mobile robots and the accommodation of more users.
Furthermore, incorporating fiducial markers and tracking cameras, as seen in \textit{ASTEROIDS}~\cite{li2022asteroids}, could further increase the scalability of the interaction area to encompass an entire table or even a whole room.
This approach is not limited to Toio robots, meaning that various robotic platforms could also be incorporated.

\subsubsection*{\textbf{Different Robotic Form Factors}}
In this study, we focused on the combination of a holographic avatar with tabletop mobile robots.
However, future work could expand on this area by incorporating different types of robots.
For example, larger robots, such as robotic vacuum cleaners, could be utilized.
By synchronizing large robots' movements with the remote user, the holographic user could physically impact the local environment on a larger scale.
This could facilitate physical gaming and sports, and/or enable real-scale interior design by moving actual furniture, similarly to \textit{RoomShift}~\cite{suzuki2020roomshift}.

\subsubsection*{\textbf{IoT and Actuated Environments}}
In future work, we could integrate IoT devices, such as lights, fans, and curtains to enable users to affect the local environment in a different way.
% IoT devices, such as lights, fans, and curtains, could be incorporated.
% By synchronizing the avatar's movements with the behavior of these IoT devices, the remote user could affect the local environment by turning lights on/off, opening/closing curtains, and controlling air conditioners.
For example, by synchronizing the remote user's movements with a door's movements, the remote user could interact with the door in the local environment.
Also, by using reeling mechanisms like AeroRigUI~\cite{yu2023aerorigui}, remote users can raise and lower the curtains in the local environment.


\subsubsection*{\textbf{Different User Representation}}
In addition to the current finger and miniature body representations, there are other potential ways to embody remote users using Toio robots. We are interested in exploring the following alternative representations in future work.
\textit{Whole Arm:}
Mobile robots could represent the entire arm of the remote user, enabling them to physically move multiple objects simultaneously or to visualize the joints in the user's arm such as their wrist and elbow.
\textit{Gaze and Eye:} Mobile robots could follow the remote user's gaze or eye movement, allowing the local user to physically understand where the remote user is looking, an insightful metric for gauging a user's intent or thought processes.
\textit{Shadows:} Mobile robots could represent the shadow of the remote user, providing additional information about their body position beyond what an avatar can offer.

\subsubsection*{\textbf{Multi-Modal Interaction}} 
Another potential direction for future work would be to explore multi-modal interaction methods that incorporate different modalities of communication.
One such method could involve the use of a tablet device. By connecting mobile robots to the tablet and sharing the screen between the tablets of both remote and local users, the remote user can manipulate the tablet's position and engage with its contents. This interaction enables functionalities such as scaling and rotating maps shown on the tablet, as well as drawing pictures on the tablet. 


\remove{
\subsubsection*{\textbf{Supporting More Robots}}
In our current application, we utilized up to three Toio robots, but the system could be expanded by incorporating more robots.
Firstly, incorporating more robots would allow users to work with an increased number of active objects and tangible UIs, enabling complex tasks such as storytelling with multiple characters and collaborative modeling that involves numerous variables.
Secondly, an increased number of robots could enhance user representation, such as by allowing the robots to follow all ten fingers of the remote user.
Moreover, additional robots could represent other body parts and joints of the remote user, such as their elbows and wrists, enabling the remote user to more intuitively manipulate objects and engage in more realistic haptic communication with the local user.
}

\subsubsection*{\textbf{Versatile Robot Attachments}}
In future work, the capabilities of \system{} could be enhanced by incorporating versatile physical attachments, inspired by the \textit{HERMITS}~\cite{nakagaki2020hermits} concept. These on-demand attachments could significantly expand the functionality and flexibility of the tabletop robots and enable them to adapt to a wider range of tasks and interaction scenarios for tangible remote collaboration. Here are some possible directions for versatile physical attachments:
\textit{2.5D Shape Display:}
By adopting the technique presented in \textit{HapticBots}~\cite{suzuki2021hapticbots}, we can enhance our mobile robots to enable height adjustments, allowing them to actuate in 2.5 dimensions.
\textit{Attaching Tangible Controllers:}
By attaching complex tangible controllers, such as joysticks, sliders, or knobs, our system could enable remote users to perform intricate manipulations using the shared tangible UI.
\textit{Attaching Grippers:}
Equipping mobile robots with grippers could allow the remote user to manipulate small objects, thereby making it possible for them to actuate a wider range of object types.
\textit{Force Aggregation:}
Combining multiple robots within a single shell could aggerate their force, enabling the remote user to move heavier objects for object actuation or provide stronger haptic feedback for haptic communication.


\remove{
\subsubsection*{\textbf{Actuation in 2.5 Dimensions}}
In this study, the mobile robots were limited to movement within two dimensions (x and y). However, by adopting the technique presented in \textit{HapticBots}~\cite{suzuki2021hapticbots}, we can enhance our mobile robots to enable height adjustments, allowing them to actuate in 2.5 dimensions.
This improvement could lead to more advanced interaction techniques. For instance, enabling vertical movement would enable the remote user to lift objects, allowing them to stack objects or showcase objects to the local user during object actuation. With shared tangible UIs, the enhanced mobile robots could represent more complex interfaces that utilize push-down or pull-up motions.
Moreover, height adjustments could improve miniature body interaction by allowing for a better representation of the miniature body size, enabling the remote user to physically engage with the local environment based on their size. Additionally, this enhancement would enable more realistic haptic feedback of the remote user's arm to the local user by representing the remote user's arm shape in 2.5D, compared to a 2D representation.
}

% \subsubsection*{\textbf{Network Delay}
% As mentioned in the limitations, delays in network connections and communication led to poorer interactions. Decreasing the latency between the Kinect and it's body tracking would likely result in a better overall experience by enabling more seamless synchronization between Kinect body-tracking and Toio actuation. 



% \textbf{Expressive Gestures and Animations:} Incorporate expressive gestures and animations into user avatars to convey emotions, intentions, and nonverbal cues during collaboration. This can lead to more natural and engaging interactions between users, fostering a richer collaborative environment.



% Additionally, another promising direction could be to investigate the use of projection mapping to display remote users' avatars onto physical objects or surfaces in the local environment. This approach could enhance the sense of spatial co-location and potentially enable new interactions such as remotely embodying and controlling objects in the interaction area. Other approaches are also possible, such as representing users as animated avatars of resembling themselves or even other entities/people.



%\todo{Copied from Sketched Reality and auto-genrated based on ChatGPT as an inspiration. Completely rewrite it.}
% In future work, we plan to explore various user representation techniques to enhance the mixed reality experience provided by not only HoloBots but systems that enable tangible remote collaboration. By utilizing different methods for representing users in a shared environment, we can potentially improve the sense of co-presence and the overall collaborative experience. Onr promising direction could be to investigate the use of projection mapping to display remote users' avatars onto physical objects or surfaces in the local environment. This approach can create a more immersive and realistic presence for remote users, enhancing the sense of spatial co-location and potentially enabling new interactions such as by remotely embodying and controlling objects. Other approaches are also possible, such as by representing users as animated avatars as opposed to our implementation using digital recreations similar to what the remote user really looks like. By experimenting with different user representation techniques, we aim to further advance the HoloBots system and create a more immersive and engaging mixed reality telepresence experience for tangible remote collaboration.


%In order to enhance the collaborative multi-user experience in the HoloBots system, we propose investigating the integration of HoloLens and various other technologies. By combining different approaches, we can leverage the benefits of each method while overcoming their individual limitations. Some promising directions for future work include:
%An exciting future direction for the HoloBots system is to explore the combination of multiple approaches, enabling us to leverage the benefits and overcome the limitations of each individual method. Previous research has demonstrated the advantages of using Mobile AR + HMD (e.g., BISHARE, SymbiosisSketch) and HMD + Projector (e.g., ShareVR, AAR) in various applications.
%In future work, we plan to investigate different approaches for AR sketching and assess how each method can enhance user interaction and experiences in the context of the HoloBots system. By combining various techniques, we aim to create a more versatile and adaptive mixed reality telepresence environment that can cater to a wide range of use cases and collaboration scenarios. This exploration will not only contribute to the development of the HoloBots system but also expand our understanding of mixed reality remote collaboration in general.


% Other multi-modal interactions could include mobile users and even desktop user. For example, the webcam on a PC or a front-facing camera on mobile device could be used to generate an avatar of the remote user. Remote desktop users could interact with local users by viewing their shared area in 3D on their PC, while remote mobile users could potentially walk around the local users space using their phone for mobile VR/AR.



%\todo{Copied from Sketched Reality and auto-genrated based on ChatGPT as an inspiration. Completely rewrite it.}
% Another potential direction for future work would be to explore multi-modal interaction methods that combine different user representation techniques with complementary input modalities, such as voice, touch, sketching or gaze. This can lead to more intuitive and efficient user interaction in the mixed reality environment. In particular, future research can explore novel interactions and applications by combining multi-modal user inputs and tangible remote collaboration. Further research can also explore other user modalities, such as a desktop users, VR to AR or even tablet/mobile users.



% A remote user could shut the blinds for a local user or engage
% By synchronizing the avatar's movement and these devices behavior, the avatar can affect the local environment by controlling these devices, such as turning on/off lights or opening/closing curtains.
% Other robotic platforms could be considered as well, such as robotic dogs. Embodying such robotic platforms could provide interesting new interactions with local users, such as by notifying the user of an event by having a robotic dog jump on their leg.

% larger robot (like RoomShift?) 
% IoT devices. (See draft-figures, as an example) 
% drones
% for example, remote sports like soccer? (see draft-figures as an example)
% \todo{Copied from Sketched Reality and auto-genrated based on ChatGPT as an inspiration. Completely rewrite it.}
% Although this paper demonstrated the concept of tangible remote collaboration via mobile tabletop robots, the concept isn't limited to this form factor. Future work can expand this concept further by exploring various other hardware platforms. For instance, larger-sized robots, such as robotic vacuum cleaners or even robot dogs, could potentially be controlled by remote users and serve as a platform to explore further possible interactions. Moreover, such robotic platforms could apply our concept by acting as alternative actuated TUIs or as shape-changing user interfaces. Such robotic platforms could be combined with the aforementioned directions for future work, like multi-modal interactions and different user representations to create more immersive and engaging mixed reality telepresence experience for tangible remote collaboration.

%Such robotic platforms can also be combined with different user representations. For example, it may be possible to create more engaging and immersive tangible remote collaboration systems by enabling remote users to embody different robotic 

%Additionally, we aim to investigate bi-directional interactions between virtual sketches and IoT devices. For example, users could turn off or change the color of a light bulb using sketched AR objects. By integrating IoT devices and different types of robots, we can bring such interactions to everyday environments. We believe that the foundational concept and design space proposed in this paper will inspire and facilitate future explorations in these areas.



%\todo{Copied from Sketched Reality and auto-genrated based on ChatGPT as an inspiration. Completely rewrite it.}
% The scalability of robots, users, and interaction areas is a limitation of our HoloBots prototype that warrants further exploration and development. As mentioned in the limitations section, our application interactions were limited to three Toio tabletop robots as well as the interaction area being limited by the size of the Toio mat. By creating a more scalable interaction area, future work can explore larger spaces, such as entire living spaces, to facilitate full-spatial interactivity. Additionally, such future work can also explore interactions using dynamic and asynchronous interaction areas, where either users interactions dynamically change the interaction area's layout (as mentioned by the interior-design example) or one shared interaction area developed by merging both users individual interaction area. Exploring additional users (i.e. more than the two in our system) and even including multi-modal users (such as mobile, desktop, tablet and HMD users) could also result in new interactions and possibilities.


%By leveraging explorable AR combined with embedded actuation in the real world, it's possible to create an even more immersive and engaging experience for users.

%Moreover, sketching interactions are often employed for multiuser setups, fostering collaborative and cooperative sketching or drawing. Exploring such approaches in a physical space populated by multiple robots and users is a promising direction for future research. Currently, the interaction area for HoloBots is limited to the Toio mat; however, we plan to expand this area to encompass larger spaces, such as entire living spaces, to facilitate full-spatial interactivity. By leveraging explorable AR combined with embedded actuation in the real world, we aim to create an even more immersive and engaging experience for users.


% \subsubsection*{\textbf{Differe}
% integrating virtual interactions, such as sketching? 




% Secondly, with an increased number of robots, the system can make the robots follow all ten fingers of the remote user. 
%\todo{Copied from Sketched Reality and auto-genrated based on ChatGPT as an inspiration. Completely rewrite it.}

% In the future, we plan to extend HoloBots to support a more collaborative environment, involving a greater number of users and robots. This direction has the potential to unlock new interaction possibilities and enhance the shared experience in mixed reality remote collaboration. Some aspects we aim to explore include: 
% \textbf{Simultaneous Multi-user Interaction:} Investigate methods to enable multiple remote users to simultaneously interact with multiple robots in the same environment. This would require the development of efficient coordination mechanisms (i.e. larger than a Toio mat), user-to-user communication and seamless user-to-robot assignment techniques.
% \textbf{Role Assignment and Task Allocation:} Examine how to effectively assign roles and tasks to users and robots in collaborative scenarios. This would involve determining the best way to distribute workload and responsibilities according to user preferences, skills, and the capabilities of the robots according to the 
% \textbf{Dynamic Reconfiguration:} Explore methods for dynamically re-configuring the robot swarm based on changes in the collaborative environment or task requirements. This might involve real-time adjustments to the robot formations or reallocating robots to different tasks as needed.
% %\textbf{Learning from Human-Robot Interaction:} Study how robots can learn from users' interactions and adapt their behavior accordingly. This would involve implementing machine learning algorithms that enable robots to refine their performance based on user feedback and interaction patterns.
% %\textbf{User Experience Evaluation:} Conduct comprehensive user studies to assess the effectiveness of the proposed collaborative environment involving multiple users and robots. This will provide valuable insights into the strengths and weaknesses of the system and help identify areas for improvement.
% By creating a more collaborative environment with multiple users and robots, we hope to further advance the field of mixed reality telepresence and increase the scalability of tangible remote collaboration.



%\todo{Copied from Sketched Reality and auto-genrated based on ChatGPT as an inspiration. Completely rewrite it.}
% In future work, the capabilities of HoloBots could be enhanced by incorporating versatile physical attachments, inspired by the \textit{HERMITS}~\cite{nakagaki2020hermits} concept. These on-demand attachments could significantly expand the functionality and flexibility of the tabletop robots and enable them to adapt to a wider range of tasks and interaction scenarios for tangible remote collaboration. For example, the following are different directions that versatile physical attachments could explore:
% \textbf{Modular Attachment System:} Design a modular attachment system that allows robots to easily connect with and detach from different physical components, based on the requirements of a particular task or interaction. It could also allow a robot to embody the "shell" of different objects, enabling the robot to physically embody a different shape, functionality or aesthetic.
% \textbf{Attachment Inventory:} Develop a diverse set of attachments that can augment the functionality of the robots in various ways, such as grippers or magnets for object manipulation or sensors for gathering environmental/spatial information.
% \textbf{Multi-Robot Collaboration with Attachments:} Explore scenarios where multiple robots with different attachments work together to accomplish complex tasks. For example, one robot could "equip" a shell resembling a dump truck, while another bot "equipped" with a grabbing tool would place grabbed objects onto the dump truck robot. 
% \textbf{Attachment Management:} Examine ways to enable users to seamlessly control the attachment process, either through direct manipulation in the mixed reality environment or through high-level commands issued via the interface. For example, we could use voice input to tell a robot to attach/detach itself from a particular component. Additionally, future work can investigate methods for dynamically managing robotic attachments, allowing robots to autonomously select, connect with, and release attachments based on real-time contextual information.
% By extending HoloBots with versatile physical attachments, future work we could further explore the possibilities for tangible remote collaboration using tabletop robotics.




% As demonstrated by our user study, \system{} can significantly improve co-presence, workload and usability. Additionally, as depicted in our design space and our implemented scenarios, \system can enhance or enable various novel interactions. However, one limitation of our work is it's 2-Dimensional nature. The Sony Toio robots can only move within two dimensions (x and y). However, it's likely that a 3rd dimension would result in further possible interactions. Additionally, the possible interactions as well as the interaction area is limited by the size of the Toio mat, which is required for accurate positional tracking of the Toios.
