\section{Survey Protocol}\label{app:online-survey}
To understand how practitioners perceive security tools, and whether
security is prioritized by individuals and organizations similarly, we
prepared an online survey questionnaire (questionnaire in the
online appendix~\cite{online-appendix}) and drafted a research protocol.
We piloted the initial survey with five participants. Three of the participants were graduate students, and the rest had doctoral degrees. All pilots were from computer science background, with additional experience in software engineering and/or security.
By incorporating their feedback, we improved the survey by modifications and additional descriptions as necessary.
Our final survey protocol received the approval of our Institutional Review Boards (IRBs).
The experimental protocol of both our survey and interviews included a consent form which emphasized that the data of the participants will remain confidential and de-identified.
Furthermore, a participant could optionally submit their email address to have the chance of winning one of two $\$50.00$ gift cards or the equivalent value in local currency vouchers. The winners would be chosen from qualified participants who completed the survey and provided valid responses in the survey.



\subsection{Survey Recruitment}
\label{app:ethical-oss-recruitment}
To diversify our recruitment approach in terms of experience, culture and industry contexts, we leveraged multiple recruitment channels.
We sent invitation emails describing the goal of the survey (\ie in order to learn about their professional experiences and opinions about \sasts) to our professional networks, relying on snowball sampling for recruitment, as well as to OSS developers (as previously described in Section~\ref{sec:survey-protocol-results}).




\myparagraphnew{Ethical Considerations in Recruiting OSS developers}
We collected publicly available email addresses only, and explicitly stated our recruitment procedure in our initial contact, which is common in other recent studies (\eg Endres et al.~\cite{EBW22}).
We considered several \textit{potential trade-offs} that factored into this recruitment strategy, in addition to following the guidance provided by our IRB:
$(a)$~It is \textit{difficult} to recruit practitioners across borders who have the relevant experience, \ie configured and used automated security analysis tools,
$(b)$~we were collecting publicly available information and not amplifying the visibility of the individuals' email address, and
$(c)$~we carefully considered the Menlo Report's ethical guidelines~\cite{KD12,DKB13}.
Specifically based on these guidelines, the only potential \textit{harm} to an invited person would be receiving one unsolicited email, whereas the potential benefit of this research is in helping create more secure software, for everyone, by understanding the needs and challenges of practitioners related to security analysis techniques.


\subsection{Online Survey and Data Analysis}
Our survey (provided in the online appendix~\cite{online-appendix}) consisted of Likert Scale based questions, with optional, open-ended response to clarify their selected choice(s).
Our analysis prioritized the text-based responses since these provided additional context for the selected choice(s) in Likert scale.
One of the authors open-coded the responses for analysis.
The responses of the survey, which we summarize next, guided our interview protocol.
