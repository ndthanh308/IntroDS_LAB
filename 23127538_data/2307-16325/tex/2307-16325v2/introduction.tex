\vspace{-0.5em}
\section{Introduction}\label{sec:introduction}
\vspace{-0.5em}



Software security has gained continued international attention in recent years due to the increase of high-profile cyberattacks and exploits across the public sector. %
For example, incidents such as the SolarWinds Cyberattack
prompted the U.S. Government Accountability Office to elicit responses from both private and public sectors in 2021 to increase the effectiveness of security practices~\cite{solarwinds-response}.
Consequently, corporate and government entities alike are now increasingly emphasizing the security of software and services through a combination of $(1)$ new approaches (\eg Software Bill of Materials (SBOM)~\cite{certify-software-senate-2021}), $(2)$ adoption of security focused certifications of software (\eg Cyber Shield Act~\cite{cyber-shield-act}, IoT Compliance~\cite{ioxt23}), and $(3)$ improvement of existing approaches (\eg identifying and employing recommended types of automated software security testing~\cite{Hou21}). %
As a result, the existing multi-billion dollar industry of automated security analysis tools~\cite{gartner-application-testing-billion-dollars}, particularly Static Application Security Testing (SAST), have continued to proliferate to meet the increased security needs of organizations worldwide.
Further, such tools are now being incorporated into nearly every stage of the software development and maintenance lifecycle, from requirements engineering to fault localization and fixing (\eg the GitHub Code Scan initiative~\cite{github-code-scan}). %


However, SAST tools have been found to suffer from design and implementation flaws~\cite{ACK+22,AKM+21} that prevent them from detecting vulnerabilities that they claim to detect, or which can be expected for certain critical use cases they support (\eg compliance, audits).
Particularly, while SAST tools from industry, the open-source community, and academia have been found to support similar use cases, their design goals often differ dramatically~\cite{ACK+22}.
That is, tools may adopt a \textit{technique-centric} approach, wherein what they can detect is tied to the limitations of a set of chosen static analysis techniques, or, a {\em security-centric} approach, wherein the tool aims to use whichever static analysis techniques necessary to detect vulnerabilities falling under a specific security goal.
These different design ethos carry with them various trade-offs that impact the applicability, efficiency, and effectiveness of the security tools.
These trade-offs and their implications for cybersecurity in practice are currently poorly understood, at best.

In other words, we are increasingly heading towards a future where software developers will be depending more than ever on security focused program-analysis techniques for security assurance, compliance, and audits.
While we know of potential flaws in SASTs (as discussed previously), there exists a {\bf \em key gap} in prior research:
{\em the research community has only a limited understanding of how software developers perceive SASTs, what they expect from SASTs and believe in (particularly in terms of their ability to detect vulnerabilities), and how these perceptions and beliefs impact the adoption and use of SASTs in practice.}
Without addressing this gap through an understanding of the {\em practitioners' perspective}, we may not be able to develop SASTs that are truly effective in practice, \ie possess key properties that practitioners desire in order to improve software security, and moreover, will be unable to uncover gaps in what the practitioners (\ie users of the tools) expect or believe, versus what the tools actually provide, leading to a false sense of security.







\myparagraph{Contributions} This paper describes a qualitative study that investigates the assumptions, expectations, beliefs, and challenges experienced by practitioners who use program-analysis based security-assurance tools, specifically \sasts.
Our study is guided by 3 key research questions ({\bf RQ1} -- {\bf RQ3}), which we explore via in-depth interviews ($n=20$) with software developers, project managers, research engineers and practitioners, who together cover a broad range of security, product, and business contexts:

\newrq{1}{\update{How do practitioners at organizations, with different types of business and security needs, choose and depend on \sasts for ensuring security in their services/products?}}
Various factors may influence an organization's process for selecting a \sast tool, ranging from security or business needs (\eg compliance), brand reputation, or inclusion of safety-critical components. %
Thus, we are interested in exploring what individual practitioners and their organizations care about in terms of security, and how those needs affect the selection of SASTs, as well as their incorporation into their overall vulnerability detection processes.
We also seek to explore {\em how} SASTs are selected, \ie the subjective or objective processes involved in choosing a particular SAST.

\newrq{2}{What do practitioners know and believe about the limitations of \sasts, and what do they expect from them?}
While certain limitations, such as false positives, are relatively well-known, potential issues related to design and/or implementation flaws that result in security-specific false negatives are often unknown and unaccounted for in \sasts.
We are interested to understand the awareness, expectations, and beliefs of practitioners about such limitations, both known and unknown, of \sasts, particularly in terms of false positives and negatives.

\newrq{3}{How do practitioners navigate, address, or work around flaws of \sasts?} A \sast that does not detect vulnerabilities
may lead to vulnerabilities in otherwise security-assured software. %
We are interested in learning about practitioners' experiences regarding the impact of the flaws in \sasts (\eg product-related security incidents).
Furthermore, we are interested to know how practitioners balance the possibility of unsound \sasts that may make their product vulnerable, and the decision to release potentially vulnerable software.
Moreover, if practitioners do happen to find a flaw in a \sast, we seek to uncover their experiences in reporting the issues to the SASTs.
Finally, we seek to investigate the typical pain points that practitioners experience regarding SASTs, in order to understand the key properties they desire more than anything else.





















