\vspace{-0.5em}
\subsection{Interview Protocol}\label{sec:interview-protocol}
\vspace{-0.5em}
We drafted an interview protocol consisting of a semi-structured interview-guide~\cite{Ada15,HA05} structured by "laddering" questions~\cite{CRM+94}, a questioning strategy that is used to understand the relations between concepts in a domain and to explore the concepts in-depth.
The interview guide is designed to help understand the processes used to choose \sasts, how practitioners depend on \sasts for security assurance, their expectations about limitations of \sasts{}, and how they work around such limitations.
An abridged version of the interview guide is in Table~\ref{tbl:interview-questions} in the Appendix.




\vspace{-0.25em}
\subsubsection{Interview Recruitment}\label{sec:interview-recruitment}
We recruited $20$ interview participants through multiple recruitment channels, aiming for diversity in project, cultural background, experience and industry contexts.
Particularly, we recruited $(i)$ \update{$10$} participants from the survey and $(ii)$ $10$ separately through our professional network.
When recruiting from the survey-pool, we only invited participants who submitted reasonably valid responses and expressed interest in interview participation.
To recruit from our professional networks, we relied on snowball sampling~\cite{SnowballSamplinggoodman1961a}, i.e., emailed invitations to software engineers within our network, with details of the study as per protocol, and requested them to forward the invitation to colleagues experienced with \sasts. %

Overall, we recruited $20$ interview participants with diverse cultural background (\eg participants were from Asia, Europe, United Kingdom and North America, working in either local or international projects), industry contexts (\eg safety-critical, business-critical, research \& development, open-source \etc), experience ranging from entry level engineers to project managers, and security-context (\eg working towards compliance).
The anonymized details of participants are shown in Table~\ref{tbl:interview-participants}.  %

\vspace{-0.25em}
\subsubsection{Interview Protocol and Ethics}
\label{sec:ethics}

Similar to the survey, the final version of our interview guide and protocol was approved by our Institutional Review Boards (IRBs). %
Our consent form emphasized that no personally identifiable information would be collected, and responses will be anonymized even in the case of willfully shared private information, such as a participant's (or colleagues) name, associated previous or current organization, and product/client name(s).
Each participant would be interviewed for approximately an hour, and would receive a $\$50.00$ gift card or voucher in local currency.

Furthermore, as our interview-guide contained \textit{sensitive} questions \eg security enhancement vs meeting deadlines, or site-incidents due to flawed \sast,
we followed the Menlo Report Guidelines~\cite{KD12,DKB13} to refine our protocol and interview guide to avoid any potential harm, and reminded participants that they could withdraw/redact at any time, as further detailed in Section~\ref{sec:interview-procedure}.

\vspace{-0.25em}
\subsubsection{Interview Pilot \& Refinement}
We conducted pilot interviews, followed by an in-depth discussion, with three participants within our professional network to improve the interview guide.
Among these, one held a doctoral degree in computer science, with a focus in CyberSecurity, while the other two were pursuing a Ph.D. in Computer Science.

\vspace{-0.25em}
\subsubsection{Interviewing Procedure}
\label{sec:interview-procedure}
We conducted the interviews using either the lead-interviewer or lead-and-backup approaches, while following the semi-structured interview-guide.
The lead-and-backup approach ensured that each interviewer experienced conducting the interview with the guide.
While relevant questions from the guide were raised, it also allowed the lead interviewer to focus on listening and asking laddering/follow-up questions to the interviewee.
All the interviews were conducted virtually via Zoom.
We emailed the Informed Consent Form (and survey response when applicable) with IRB protocol references a day before the interview.
After the participant joined us in the online interview session, we reminded the participant \textit{before starting the interview} that $(a)$ the interview will be recorded, $(b)$ we will anonymize any sensitive information while transcribing, $(c)$ recorded audio will be destroyed after transcribing, $(d)$ they can redact anything they said at any point of the interview and/or can email us about it, and $(e)$ they have the option to stop the interview at any point.
The median, effective duration of the interviews, \ie excluding the intro, briefing and verbal consent, was $1$ hour $52$ seconds.

\vspace{-0.5em}
\subsection{Structure of the Interview Guide}\label{sec:interview-guide}
\vspace{-0.5em}

\input{figs/fig-interview-guide.tex}

We designed the semi-structured interview guide in a way that facilitates understanding how \add{practitioners at} organizations choose and depend on \sasts with the context of their business and security needs~(\rqref{1}), what practitioners with different needs and priorities know and assume about limitations, such as soundness issues, in \sasts~(\rqref{2}), how they address the limitations of \sasts{}~(\rqref{3}).
As shown in Figure~\ref{fig:interview-guide}, the interview guide consists of questions arranged in six segments, ordered by increasing-depth as applicable.

\subsubsection{\interviewSectionParticipants} At the start of the interview, we asked several "\textit{warm-up questions}" to understand the products/services the participants contribute to, their organization, their experience with developer tools for software security and how they define security in terms of their work.
Through these questions we developed the initial context to ask more in-depth follow-up questions.
More specifically, we asked the participants about their domain of work, their target clients, how they learned about software security that's relevant to their work, the security aspects that are important in their work, as well as the relevant threat models they consider. %

\vspace{-0.25em}
\subsubsection{\interviewSectionSecAndOrg} Next, to gain a deeper understanding of the organizational context of security in their practice, we asked the participants about how they address security in their organizations product development life-cycle. For example, we asked whether there are conflicts between feature deadlines and the security of a given feature, what the conflict resolution process is in general, and whether they have experienced any external factors that constrained security.
By raising such questions, we developed a better understanding of the trade-offs an organization makes when it comes to security. %

\vspace{-0.25em}
\subsubsection{\interviewSectionOrgOfSast} %
We then asked questions about how one or more \sasts are being used in organizational and team contexts.
From the survey, we observed that organizations and their developers may have different priorities and perceptions when it comes to security,  which motivated us to distinguish between these two contexts.
To elaborate, we asked the participants about their team structure, whether the team(s) address security requirements collaboratively or separately and how, and what happens when such requirements are not met.
Moreover, to understand the role of \sasts in the organization and team, we asked questions to understand how they decided to use \sasts in the first place, how they selected \sasts, and to explain why and to what degree they rely on \sasts.

\vspace{-0.25em}
\subsubsection{\interviewSectionLimitExpectSast}
We asked questions related to participant's expectations from \sasts and their limitations, using both
 hypothetical scenarios and also leveraging opinions the participant expressed throughout the interview.
For example, we asked about preferences regarding false positives vs. false negatives, explaining the concepts as necessary. Furthermore we asked whether their preference of SASTs is tied to their work, values shared within the community, or something else.

\vspace{-0.25em}
\subsubsection{\interviewSectionImpactUnsoundSast} To understand the impact of a flawed/unsound \sast, we asked the participants about their experiences and organizational processes.
For example, we requested that participants share specific experiences related to security vulnerabilities resulting from a \sast that did not work as intended.
If that participant did not have such experiences, we asked whether a process exists that helps them address such potential flaws.
In addition, we asked how and why the participants generally attempt to address problems encountered while using SASTs.

\subsubsection{\interviewSectionChallengeSolution} Finally, we concluded the interview by raising several "\textit{creative}" questions.
For example, if a participant is given unlimited resources to solve one particular problem of the \sast they use, what problem would they prioritize before anything else, and why would they want to solve it.
By raising such open-ended questions that \textit{remove limitations} tied to organization and product-context, we aimed to understand what participants want or need in the \sasts they use.

\vspace{-0.25em}
\subsection{Transcribing, Coding and Analysis}
\label{subsec:thematic}
\vspace{-0.25em}
One of the authors systematically transcribed the audio records while anonymizing the text.
This required significant amount of time as the median, effective interview duration was one hour, consisting of approximately $9,000$ words, with a total word count of over $187,000$ words across all interviews.
We chose reflexive thematic analysis combined with inductive coding for our analytical approach~\cite{braun2021thematic} as it offered us the flexibility of capturing both latent and semantic meaning based on the complex interactions between the participant's perceptions and contexts, such as assurances offered by automated security analysis techniques, organizational priorities, limitations of security resources, and the nature of products. Furthermore, it considers researcher subjectivity, \ie experiences and skills of researchers in analysis. We chose a single-coder approach, which is considered "good practice for reflexive TA", as it helps interpretation, or \textit{"meaning-making"}, from data~\cite{braun2021thematic}.
While transcribing provides an initial idea about the data and internal patterns, we had to iterate through the steps of thematic analysis (familiarization, coding, identifying potential themes, refining) to finalize the themes.





