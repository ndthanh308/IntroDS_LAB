@inproceedings{JSMB13,
  title      = {Why {{Don}}'t {{Software Developers Use Static Analysis Tools}} to {{Find Bugs}}?},
  booktitle  = {35th {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  author     = {Johnson, Brittany and Song, Yoonki and Murphy-Hill, Emerson and Bowdidge, Robert},
  date       = {2013-05},
  year       = {2013},
  pages      = {672--681},
  publisher  = {{IEEE}},
  location   = {{San Francisco, CA, USA}},
  doi        = {10.1109/ICSE.2013.6606613},
  url        = {http://ieeexplore.ieee.org/document/6606613/},
  urldate    = {2021-05-19},
  abstract   = {Using static analysis tools for automating code inspections can be beneficial for software engineers. Such tools can make finding bugs, or software defects, faster and cheaper than manual inspections. Despite the benefits of using static analysis tools to find bugs, research suggests that these tools are underused. In this paper, we investigate why developers are not widely using static analysis tools and how current tools could potentially be improved. We conducted interviews with 20 developers and found that although all of our participants felt that use is beneficial, false positives and the way in which the warnings are presented, among other things, are barriers to use. We discuss several implications of these results, such as the need for an interactive mechanism to help developers fix defects.},
  eventtitle = {2013 35th {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  isbn       = {978-1-4673-3076-3 978-1-4673-3073-2},
  langid     = {english}
}


@article{SAE+18,
  title      = {{Lessons from Building Static Analysis Tools at Google}},
  author     = {Sadowski, Caitlin and Aftandilian, Edward and Eagle, Alex and Miller-Cushon, Liam and Jaspan, Ciera},
  year       = {2018},
  issue_date = {April 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {61},
  number     = {4},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/3188720},
  doi        = {10.1145/3188720},
  abstract   = {For a static analysis project to succeed, developers must feel they benefit from and enjoy using it.},
  journal    = {Commun. ACM},
  month      = {mar},
  pages      = {58â€“66},
  numpages   = {9}
}

@inproceedings{2015_IccTADetectingIntercomponent_li,
  title = {{{IccTA}}: {{Detecting Inter-component Privacy Leaks}} in {{Android Apps}}},
  shorttitle = {{{IccTA}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Software Engineering}} - {{Volume}} 1},
  author = {Li, Li and Bartel, Alexandre and Bissyand{\'e}, Tegawend{\'e} F. and Klein, Jacques and Le Traon, Yves and Arzt, Steven and Rasthofer, Siegfried and Bodden, Eric and Octeau, Damien and McDaniel, Patrick},
  year = {2015},
  series = {{{ICSE}} '15},
  pages = {280--291},
  publisher = {{IEEE Press}},
  address = {{Piscataway, NJ, USA}},
  urldate = {2019-02-14},
  abstract = {Shake Them All is a popular "Wallpaper" application exceeding millions of downloads on Google Play. At installation, this application is given permission to (1) access the Internet (for updating wallpapers) and (2) use the device microphone (to change background following noise changes). With these permissions, the application could silently record user conversations and upload them remotely. To give more confidence about how Shake Them All actually processes what it records, it is necessary to build a precise analysis tool that tracks the flow of any sensitive data from its source point to any sink, especially if those are in different components. Since Android applications may leak private data carelessly or maliciously, we propose IccTA, a static taint analyzer to detect privacy leaks among components in Android applications. IccTA goes beyond state-of-the-art approaches by supporting inter-component detection. By propagating context information among components, IccTA improves the precision of the analysis. IccTA outperforms existing tools on two benchmarks for ICC-leak detectors: DroidBench and ICC-Bench. Moreover, our approach detects 534 ICC leaks in 108 apps from MalGenome and 2,395 ICC leaks in 337 apps in a set of 15,000 Google Play apps.},
  isbn = {978-1-4799-1934-5},
  keywords = {tools}
}


@inproceedings{APM+07,
  title = {Evaluating Static Analysis Defect Warnings on Production Software},
  booktitle = {Proceedings of the 7th {{ACM SIGPLAN-SIGSOFT}} Workshop on {{Program}} Analysis for Software Tools and Engineering  - {{PASTE}} '07},
  author = {Ayewah, Nathaniel and Pugh, William and Morgenthaler, J. David and Penix, John and Zhou, YuQian},
  year = {2007},
  pages = {1--8},
  publisher = {{ACM Press}},
  address = {{San Diego, California, USA}},
  doi = {10.1145/1251535.1251536},
  urldate = {2020-05-03},
  abstract = {Static analysis tools for software defect detection are becoming widely used in practice. However, there is little public information regarding the experimental evaluation of the accuracy and value of the warnings these tools report. In this paper, we discuss the warnings found by FindBugs, a static analysis tool that finds defects in Java programs. We discuss the kinds of warnings generated and the classification of warnings into false positives, trivial bugs and serious bugs. We also provide some insight into why static analysis tools often detect true but trivial bugs, and some information about defect warnings across the development lifetime of software release. We report data on the defect warnings in Sun's Java 6 JRE, in Sun's Glassfish JEE server, and in portions of Google's Java codebase. Finally, we report on some experiences from incorporating static analysis into the software development process at Google.},
  isbn = {978-1-59593-595-3},
  langid = {english},
  keywords = {findbugs,spotbugs}
}


@inproceedings{IRFW19,
  title      = {Challenges with {{Responding}} to {{Static Analysis Tool Alerts}}},
  booktitle  = {{{IEEE}}/{{ACM}} 16th {{International Conference}} on {{Mining Software Repositories}} ({{MSR}})},
  author     = {Imtiaz, Nasif and Rahman, Akond and Farhana, Effat and Williams, Laurie},
  date       = {2019-05},
  year       = {2019},
  pages      = {245--249},
  issn       = {2574-3864},
  doi        = {10.1109/MSR.2019.00049},
  abstract   = {Static analysis tool alerts can help developers detect potential defects in the code early in the development cycle. However, developers are not always able to respond to the alerts with their preferred action and may turn away from using the tool. In this paper, we qualitatively analyze 280 Stack Overflow (SO) questions regarding static analysis tool alerts to identify the challenges developers face in understanding and responding to these alerts. We find that the most prevalent question on SO is how to ignore and filter alerts, followed by validation of false positives. Our findings confirm prior researchers' findings related to notification communication theory as 44.6\% of the SO questions that we analyzed indicate developers face communication challenges.},
  eventtitle = {2019 {{IEEE}}/{{ACM}} 16th {{International Conference}} on {{Mining Software Repositories}} ({{MSR}})},
  keywords   = {alerts,barrier,challenge,Encoding,Faces,Interviews,Manuals,Software,Stack overflow,Static analysis,Static analysis tool,Tools,warnings}
}

@inproceedings{SVJ+15a,
  title      = {Tricorder: {{Building}} a {{Program Analysis Ecosystem}}},
  shorttitle = {Tricorder},
  booktitle  = {2015 {{IEEE}}/{{ACM}} 37th {{IEEE International Conference}} on {{Software Engineering}}},
  author     = {Sadowski, Caitlin and Van Gogh, Jeffrey and Jaspan, Ciera and Soderberg, Emma and Winter, Collin},
  date       = {2015-05},
  pages      = {598--608},
  publisher  = {{IEEE}},
  year = {2015},
  location   = {{Florence}},
  doi        = {10.1109/ICSE.2015.76},
  url        = {https://ieeexplore.ieee.org/document/7194609/},
  urldate    = {2023-02-04},
  abstract   = {Static analysis tools help developers find bugs, improve code readability, and ensure consistent style across a project. However, these tools can be difficult to smoothly integrate with each other and into the developer workflow, particularly when scaling to large codebases. We present TRICORDER, a program analysis platform aimed at building a data-driven ecosystem around program analysis. We present a set of guiding principles for our program analysis tools and a scalable architecture for an analysis platform implementing these principles. We include an empirical, in-situ evaluation of the tool as it is used by developers across Google that shows the usefulness and impact of the platform.},
  eventtitle = {2015 {{IEEE}}/{{ACM}} 37th {{IEEE International Conference}} on {{Software Engineering}} ({{ICSE}})},
  isbn       = {978-1-4799-1934-5},
  langid     = {english}
}

@inproceedings{WBS+22,
  title = {To {{Fix}} or {{Not}} to {{Fix}}: {{A Critical Study}} of {{Crypto-misuses}} in the {{Wild}}},
  shorttitle = {To {{Fix}} or {{Not}} to {{Fix}}},
  booktitle = {The 21th {{IEEE International Conference}} on {{Trust}}, {{Security}} and {{Privacy}} in {{Computing}} and {{Communications}} ({{TrustCom}})},
  author = {Wickert, Anna-Katharina and Baumg{\"a}rtner, Lars and Schlichtig, Michael and Narasimhan, Krishna and Mezini, Mira},
  year = {2022},
  eprint = {2209.11103},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{IEEE}},
  abstract = {Recent studies have revealed that 87 \% to 96 \% of the Android apps using cryptographic APIs have a misuse which may cause security vulnerabilities. As previous studies did not conduct a qualitative examination of the validity and severity of the findings, our objective was to understand the findings in more depth. We analyzed a set of 936 open-source Java applications for cryptographic misuses. Our study reveals that 88.10 \% of the analyzed applications fail to use cryptographic APIs securely. Through our manual analysis of a random sample, we gained new insights into effective false positives. For example, every fourth misuse of the frequently misused JCA class MessageDigest is an effective false positive due to its occurrence in a non-security context. As we wanted to gain deeper insights into the security implications of these misuses, we created an extensive vulnerability model for cryptographic API misuses. Our model includes previously undiscussed attacks in the context of cryptographic APIs such as DoS attacks. This model reveals that nearly half of the misuses are of high severity, e.g., hard-coded credentials and potential Man-in-the-Middle attacks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Software Engineering}
}


@inproceedings{ACK+22,
  title = {Why {{Crypto-detectors Fail}}: {{A Systematic Evaluation}} of {{Cryptographic Misuse Detection Techniques}}},
  booktitle = {2022 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{S}}\&{{P}})},
  author = {Ami, Amit Seal and Cooper, Nathan and Kafle, Kaushal and Moran, Kevin and Poshyvanyk, Denys and Nadkarni, Adwait},
  year = {2022},
  month = may,
  pages = {397--414},
  publisher = {{IEEE Computer Society}},
  address = {{San Francisco, CA, USA}},
  issn = {2375-1207},
  pdf = {https://arxiv.org/pdf/2107.07065.pdf},
  sourcecode = {https://github.com/Secure-Platforms-Lab-W-M/masc-artifact}
}

@article{AKM+21,
  title = {Systematic {{Mutation-Based Evaluation}} of the {{Soundness}} of {{Security-Focused Android Static Analysis Techniques}}},
  author = {Ami, Amit Seal and Kafle, Kaushal and Moran, Kevin and Nadkarni, Adwait and Poshyvanyk, Denys},
  year = {2021},
  month = feb,
  journal = {ACM Transactions on Privacy and Security},
  volume = {24},
  number = {3},
  pages = {15:1--15:37},
  issn = {2471-2566},
  doi = {10.1145/3439802},
  keywords = {CryptoPAn,Network trace anonymization,semantic attacks}
}

@INPROCEEDINGS{akm+21-demo,
  author={Amit Seal Ami and Kaushal Kafle and Kevin Moran and Adwait Nadkarni and Denys Poshyvanyk},
  title={{Demo: Mutation-based Evaluation of Security-focused Static Analysis Tools for Android.}},
  booktitle={Proceedings of the 43rd IEEE/ACM International Conference on Software Engineering (ICSE'21), Formal Tool Demonstration Track},
  year={2021},
  month= May,
  },
}

@INPROCEEDINGS{AAR+23-demo,
  author={Amit Seal Ami and Syed Yusuf Ahmed and Radowan Mahmud Redoy and Nathan Cooper and Kaushal Kafle and Kevin Moran and Adwait Nadkarni and Denys Poshyvanyk},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  title={{MASC: A Tool for Mutation-based Evaluation of Static Crypto-API Misuse Detectors}},
  booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  year={2023},
  month= Dec,
  location = {California, United States},
  series = {ESEC/FSE 2023}
}



@article{NWA20,
  title = {Why {{Do Software Developers Use Static Analysis Tools}}? {{A User-Centered Study}} of {{Developer Needs}} and {{Motivations}}},
  shorttitle = {Why {{Do Software Developers Use Static Analysis Tools}}?},
  author = {Nguyen Quang Do, Lisa and Wright, James and Ali, Karim},
  year = {2020},
  journal = {IEEE Transactions on Software Engineering},
  pages={835-847},
   issn = {1939-3520},
  doi = {10.1109/TSE.2020.3004525},
  volume={48},
  number={3},
  keywords = {Computer bugs,Development tools,Graphical environments,Industries,Integrated environments,Program analysis,Security,Static analysis,Tools,Usability}
}

@inproceedings{SDM20,
  title = {Why {{Can}}'t {{Johnny Fix Vulnerabilities}}: {{A Usability Evaluation}} of {{Static Analysis Tools}} for {{Security}}},
  booktitle = {Sixteenth Symposium on Usable Privacy and Security ({{SOUPS}} 2020)},
  author = {Smith, Justin and Do, Lisa Nguyen Quang and {Murphy-Hill}, Emerson},
  year = {2020},
  month = aug,
  pages = {221--238},
  publisher = {{USENIX Association}},
  isbn = {978-1-939133-16-8}
}
@article{VPP+20a,
  title = {How Developers Engage with Static Analysis Tools in Different Contexts},
  author = {Vassallo, Carmine and Panichella, Sebastiano and Palomba, Fabio and Proksch, Sebastian and Gall, Harald C. and Zaidman, Andy},
  year = {2020},
  month = mar,
  journal = {Empirical Software Engineering},
  volume = {25},
  number = {2},
  pages = {1419--1457},
  issn = {1573-7616},
  doi = {10.1007/s10664-019-09750-5},
  langid = {english}
}

@article{lss+15,
  title = {In Defense of Soundiness: A Manifesto},
  shorttitle = {In Defense of Soundiness},
  author = {Livshits, Benjamin and Vardoulakis, Dimitrios and Sridharan, Manu and Smaragdakis, Yannis and Lhot{\'a}k, Ond{\v r}ej and Amaral, J. Nelson and Chang, Bor-Yuh Evan and Guyer, Samuel Z. and Khedker, Uday P. and M\o ller, Anders},
  year = {2015},
  month = jan,
  volume = {58},
  pages = {44--46},
  issn = {00010782},
  doi = {10.1145/2644805},
  journal = {Communications of the ACM},
  language = {en},
  number = {2}
}


@InProceedings{nong23icse,
	title={{VulGen}: Realistic Vulnerable Sample Generation via Pattern Mining and Deep Learning},
	author={Yu Nong and Yuzhe Ou and Michael Pradel and Feng Chen and Haipeng Cai},
	booktitle={IEEE/ACM International Conference on Software Engineering (ICSE)},
	Keywords = {program generation, vulnerability analysis, software security},
	url_pdf = {http://chapering.github.io/pubs/icse23yu.pdf},
	url_project = {https://figshare.com/s/faf2c8a24410b34b7e70},
	year={2023}
}

@inproceedings{NSB22,
  title = {A Large-Scale Study of Usability Criteria Addressed by Static Analysis Tools},
  booktitle = {Proceedings of the 31st {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}}},
  author = {Nachtigall, Marcus and Schlichtig, Michael and Bodden, Eric},
  year = {2022},
  month = jul,
  pages = {532--543},
  publisher = {{ACM}},
  address = {{Virtual South Korea}},
  doi = {10.1145/3533767.3534374},
  abstract = {Static analysis tools support developers in detecting potential coding issues, such as bugs or vulnerabilities. Research on static analysis emphasizes its technical challenges but also mentions severe usability shortcomings. These shortcomings hinder the adoption of static analysis tools, and in some cases, user dissatisfaction even leads to tool abandonment.},
  isbn = {978-1-4503-9379-9},
  langid = {english}
}

@misc{cognicrypteclipse,
    key   = {cognicrypt},
    title = {{{CogniCrypt}} - {{Secure Integration}} of {{Cryptographic Software}} | {{CogniCrypt}}},
    note  = {\url{https://www.eclipse.org/cognicrypt/}},
    year  = {2020},
    month = jun
}

@misc{npm,
  key={npm},
  title = {Auditing Package Dependencies for Security Vulnerabilities | Npm {{Docs}}},
  abstract = {Documentation for the npm registry, website, and command-line interface},
  howpublished = {https://docs.npmjs.com/auditing-package-dependencies-for-security-vulnerabilities/},
  langid = {english}
}

@misc{github_code_scanning_suite,
    key   = {Github},
    title = {About code scanning - GitHub Docs},
    note  = {\url{https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/about-code-scanning
}},
    year  = {2020},
    month = {nov}
}

@article{EN08,
  title = {A {{Comparative Study}} of {{Industrial Static Analysis Tools}}},
  author = {Emanuelsson, P{\"a}r and Nilsson, Ulf},
  year = {2008},
  month = jul,
  journal = {Electronic Notes in Theoretical Computer Science},
  volume = {217},
  pages = {5--21},
  issn = {15710661},
  doi = {10.1016/j.entcs.2008.06.039},
  langid = {english}
}

@book{And20,
  title = {Security {{Engineering}}: {{A Guide}} to {{Building Dependable Distributed Systems}}},
  author = {Anderson, Ross},
  year = {2020},
  edition = {3rd},
  publisher = {{Wiley}},
  address = {{New York}},
  isbn = {978-1-119-64278-7},
  langid = {english}
}

@article{2018_AmandroidPreciseGeneral_wei,
  title = {Amandroid: {{A Precise}} and {{General Inter-component Data Flow Analysis Framework}} for {{Security Vetting}} of {{Android Apps}}},
  shorttitle = {Amandroid},
  author = {Wei, Fengguo and Roy, Sankardas and Ou, Xinming and {Robby}},
  year = {2018},
  month = apr,
  journal = {ACM Transactions on Privacy and Security},
  volume = {21},
  number = {3},
  pages = {1--32},
  issn = {24712566},
  doi = {10.1145/3183575},
  urldate = {2019-07-19},
  langid = {english}
}

@inproceedings{2015_ScalablePreciseTaint_huang,
  title = {Scalable and Precise Taint Analysis for {{Android}}},
  booktitle = {Proceedings of the 2015 {{International Symposium}} on {{Software Testing}} and {{Analysis}} - {{ISSTA}} 2015},
  author = {Huang, Wei and Dong, Yao and Milanova, Ana and Dolby, Julian},
  year = {2015},
  pages = {106--117},
  publisher = {{ACM Press}},
  address = {{Baltimore, MD, USA}},
  doi = {10.1145/2771783.2771803},
  urldate = {2019-02-14},
  isbn = {978-1-4503-3620-8},
  langid = {english},
  keywords = {Android,CFL-reachability,information flow,Taint analysis,tools}
}

@inproceedings{2013_FlowDroidPreciseContext_arzt,
  title = {{{FlowDroid}}: Precise Context, Flow, Field, Object-Sensitive and Lifecycle-Aware Taint Analysis for {{Android}} Apps},
  shorttitle = {{{FlowDroid}}},
  booktitle = {Proceedings of the 35th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}} - {{PLDI}} '14},
  author = {Arzt, Steven and Rasthofer, Siegfried and Fritz, Christian and Bodden, Eric and Bartel, Alexandre and Klein, Jacques and Le Traon, Yves and Octeau, Damien and McDaniel, Patrick},
  year = {2013},
  pages = {259--269},
  publisher = {{ACM Press}},
  address = {{Edinburgh, United Kingdom}},
  doi = {10.1145/2594291.2594299},
  urldate = {2019-01-11},
  isbn = {978-1-4503-2784-8},
  langid = {english}
}

@inproceedings{RXA+19,
  title = {{{CryptoGuard}}: {{High Precision Detection}} of {{Cryptographic Vulnerabilities}} in {{Massive-sized Java Projects}}},
  shorttitle = {{{CryptoGuard}}},
  booktitle = {Proceedings of the 2019 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}  - {{CCS}} '19},
  author = {Rahaman, Sazzadur and Xiao, Ya and Afrose, Sharmin and Shaon, Fahad and Tian, Ke and Frantz, Miles and Kantarcioglu, Murat and Yao, Danfeng (Daphne)},
  year = {2019},
  pages = {2455--2472},
  publisher = {{ACM Press}},
  address = {{London, United Kingdom}},
  doi = {10.1145/3319535.3345659},
  urldate = {2019-11-30},
  isbn = {978-1-4503-6747-9},
  langid = {english}
}

@inproceedings{CB16,
  title = {What Developers Want and Need from Program Analysis: An Empirical Study},
  shorttitle = {What Developers Want and Need from Program Analysis},
  booktitle = {Proceedings of the 31st {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}}},
  author = {Christakis, Maria and Bird, Christian},
  year = {2016},
  month = aug,
  pages = {332--343},
  publisher = {{ACM}},
  address = {{Singapore Singapore}},
  doi = {10.1145/2970276.2970347},
  urldate = {2023-02-11},
  isbn = {978-1-4503-3845-5},
  langid = {english}
}

@article{BBC+10,
  title = {A {{Few Billion Lines}} of {{Code Later}}: {{Using Static Analysis}} to {{Find Bugs}} in the {{Real World}}},
  author = {Bessey, Al and Block, Ken and Chelf, Ben and Chou, Andy and Fulton, Bryan and Hallem, Seth and {Henri-Gros}, Charles and Kamsky, Asya and McPeak, Scott and Engler, Dawson},
  year = {2010},
  month = feb,
  journal = {Communications of the ACM},
  volume = {53},
  number = {2},
  pages = {66--75},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  issn = {0001-0782},
  doi = {10.1145/1646353.1646374},
  abstract = {How Coverity built a bug-finding tool, and a business, around the unlimited supply of bugs in software systems.},
  issue_date = {February 2010}
}

@inproceedings{SFZ11,
  title = {{{EFindBugs}}: {{Effective Error Ranking}} for {{FindBugs}}},
  shorttitle = {{{EFindBugs}}},
  booktitle = {Verification and {{Validation}} 2011 {{Fourth IEEE International Conference}} on {{Software Testing}}},
  author = {Shen, Haihao and Fang, Jianhong and Zhao, Jianjun},
  year = {2011},
  month = mar,
  pages = {299--308},
  issn = {2159-4848},
  doi = {10.1109/ICST.2011.51},
  keywords = {Computer bugs,Correlation,Detectors,Error Ranking,FindBugs,Java,Optimization,Software,Sorting,Static Analysis Tool}
}

@incollection{CMW15,
  title = {An {{Experimental Evaluation}} of {{Deliberate Unsoundness}} in a {{Static Program Analyzer}}},
  booktitle = {Verification, {{Model Checking}}, and {{Abstract Interpretation}}},
  author = {Christakis, Maria and M{\"u}ller, Peter and W{\"u}stholz, Valentin},
  editor = {D'Souza, Deepak and Lal, Akash and Larsen, Kim Guldstrand},
  year = {2015},
  volume = {8931},
  pages = {336--354},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-46081-8_19},
  urldate = {2023-03-08},
  abstract = {Many practical static analyzers are not completely sound by design. Their designers trade soundness in order to increase automation, improve performance, and reduce the number of false positives or the annotation overhead. However, the impact of such design decisions on the effectiveness of an analyzer is not well understood. In this paper, we report on the first systematic effort to document and evaluate the sources of unsoundness in a static analyzer. We present a code instrumentation that reflects the sources of deliberate unsoundness in the .NET static analyzer Clousot. We have instrumented code from several open source projects to evaluate how often concrete executions violate Clousot's unsound assumptions. In our experiments, this was the case in 8\textendash 29\% of all analyzed methods. Our approach and findings can guide users of static analyzers in using them fruitfully, and designers in finding good trade-offs.},
  isbn = {978-3-662-46080-1 978-3-662-46081-8},
  langid = {english}
}

@inproceedings{AP08,
  title = {A {{Report}} on a {{Survey}} and {{Study}} of {{Static Analysis Users}}},
  booktitle = {Proceedings of the 2008 Workshop on {{Defects}} in Large Software Systems - {{DEFECTS}} '08},
  author = {Ayewah, Nathaniel and Pugh, William},
  year = {2008},
  pages = {1},
  publisher = {{ACM Press}},
  address = {{Seattle, Washington}},
  doi = {10.1145/1390817.1390819},
  urldate = {2021-05-30},
  abstract = {As static analysis tools mature and attract more users, vendors and researchers have an increased interest in understanding how users interact with them, and how they impact the software development process. The FindBugs project has conducted a number of studies including online surveys, interviews and a preliminary controlled user study to better understand the practices, experiences and needs of its users. Through these studies we have learned that many users are interested in even low priority warnings, and some organizations are building custom solutions to more seamlessly and automatically integrate FindBugs into their software processes. We've also observed that developers can make decisions about the accuracy and severity of warnings fairly quickly and independent reviewers will generally reach the same conclusions about warnings.},
  isbn = {978-1-60558-051-7},
  langid = {english}
}

@article{APH+08,
  title = {Using {{Static Analysis}} to {{Find Bugs}}},
  author = {Ayewah, Nathaniel and Pugh, William and Hovemeyer, David and Morgenthaler, J. David and Penix, John},
  year = {2008},
  month = sep,
  journal = {IEEE Software},
  volume = {25},
  number = {5},
  pages = {22--29},
  issn = {1937-4194},
  doi = {10.1109/MS.2008.130},
  abstract = {Static analysis examines code in the absence of input data and without running the code. It can detect potential security violations (SQL injection), runtime errors (dereferencing a null pointer) and logical inconsistencies (a conditional test that can't possibly be true). Although a rich body of literature exists on algorithms and analytical frameworks used by such tools, reports describing experiences in industry are much harder to come by. The authors describe FindBugs, an open source static-analysis tool for Java, and experiences using it in production settings. FindBugs evaluates what kinds of defects can be effectively detected with relatively simple techniques and helps developers understand how to incorporate such tools into software development.},
  keywords = {bug patterns,code quality,Computer bugs,Educational institutions,FindBugs,Java,Open source software,Production,Programming,Security,software defects,software quality,Software quality,Software tools,static analysis,Testing}
}

@article{OMJ+,
  title = {Effective {{Inter-Component Communication Mapping}} in {{Android}} with {{Epicc}}: {{An Essential Step Towards Holistic Security Analysis}}},
  author = {Octeau, Damien and McDaniel, Patrick and Jha, Somesh and Bartel, Alexandre and Bodden, Eric and Traon, Yves Le},
  abstract = {Many threats present in smartphones are the result of interactions between application components, not just artifacts of single components. However, current techniques for identifying inter-application communication are ad hoc and do not scale to large numbers of applications. In this paper, we reduce the discovery of inter-component communication (ICC) in smartphones to an instance of the Interprocedural Distributive Environment (IDE) problem, and develop a sound static analysis technique targeted to the Android platform. We apply this analysis to 1,200 applications selected from the Play store and characterize the locations and substance of their ICC. Experiments show that full specifications for ICC can be identified for over 93\% of ICC locations for the applications studied. Further the analysis scales well; analysis of each application took on average 113 seconds to complete. Epicc, the resulting tool, finds ICC vulnerabilities with far fewer false positives than the next best tool. In this way, we develop a scalable vehicle to extend current security analysis to entire collections of applications as well as the interfaces they export.},
  langid = {english}
}

@inproceedings{OMJ+13,
  title = {Effective {{Inter-Component}} Communication Mapping in Android: {{An}} Essential Step towards Holistic Security Analysis},
  booktitle = {22nd {{USENIX}} Security Symposium ({{USENIX}} Security 13)},
  author = {Octeau, Damien and McDaniel, Patrick and Jha, Somesh and Bartel, Alexandre and Bodden, Eric and Klein, Jacques and Traon, Yves Le},
  year = {2013},
  month = aug,
  pages = {543--558},
  publisher = {{USENIX Association}},
  address = {{Washington, D.C.}},
  isbn = {978-1-931971-03-4}
}
@inproceedings{KSA+18,
  title = {{{CrySL}}: {{An Extensible Approach}} to {{Validating}} the {{Correct Usage}} of {{Cryptographic APIs}}},
  booktitle = {32nd {{European Conference}} on {{Object-Oriented Programming}} ({{ECOOP}} 2018)},
  author = {Kr{\"u}ger, Stefan and Sp{\"a}th, Johannes and Ali, Karim and Bodden, Eric and Mezini, Mira},
  editor = {Millstein, Todd},
  year = {2018},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {109},
  pages = {10:1-10:27},
  publisher = {{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik}},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.ECOOP.2018.10},
  isbn = {978-3-95977-079-8},
  urn = {urn:nbn:de:0030-drops-92151}
}

@inproceedings{KNR+17,
  title = {{{CogniCrypt}}: {{Supporting Developers}} in {{Using Cryptography}}},
  shorttitle = {{{CogniCrypt}}},
  booktitle = {Proceedings of the {{32Nd IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}}},
  author = {Kr{\"u}ger, Stefan and Nadi, Sarah and Reif, Michael and Ali, Karim and Mezini, Mira and Bodden, Eric and G{\"o}pfert, Florian and G{\"u}nther, Felix and Weinert, Christian and Demmler, Daniel and Kamath, Ram},
  year = {2017},
  series = {{{ASE}} 2017},
  pages = {931--936},
  publisher = {{IEEE Press}},
  address = {{Piscataway, NJ, USA}},
  urldate = {2019-02-05},
  abstract = {Previous research suggests that developers often struggle using low-level cryptographic APIs and, as a result, produce insecure code. When asked, developers desire, among other things, more tool support to help them use such APIs. In this paper, we present CogniCrypt, a tool that supports developers with the use of cryptographic APIs. CogniCrypt assists the developer in two ways. First, for a number of common cryptographic tasks, CogniCrypt generates code that implements the respective task in a secure manner. Currently, CogniCrypt supports tasks such as data encryption, communication over secure channels, and long-term archiving. Second, CogniCrypt continuously runs static analyses in the background to ensure a secure integration of the generated code into the developer's workspace. This video demo showcases the main features of CogniCrypt: youtube.com/watch?v=JUq5mRHfAWY.},
  isbn = {978-1-5386-2684-9},
  keywords = {Code Analysis,Code Generation,cognicrypt,Cryptography,Variability Modeling}
}


@inproceedings{FHM+12,
  title = {Why {{Eve}} and {{Mallory Love Android}}: {{An Analysis}} of {{Android SSL}} (in){{Security}}},
  booktitle = {Proceedings of the 2012 {{ACM Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Fahl, Sascha and Harbach, Marian and Muders, Thomas and Baumg{\"a}rtner, Lars and Freisleben, Bernd and Smith, Matthew},
  year = {2012},
  series = {{{CCS}} '12},
  pages = {50--61},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2382196.2382205},
  abstract = {Many Android apps have a legitimate need to communicate over the Internet and are then responsible for protecting potentially sensitive data during transit. This paper seeks to better understand the potential security threats posed by benign Android apps that use the SSL/TLS protocols to protect data they transmit. Since the lack of visual security indicators for SSL/TLS usage and the inadequate use of SSL/TLS can be exploited to launch Man-in-the-Middle (MITM) attacks, an analysis of 13,500 popular free apps downloaded from Google's Play Market is presented. We introduce MalloDroid, a tool to detect potential vulnerability against MITM attacks. Our analysis revealed that 1,074 (8.0\%) of the apps examined contain SSL/TLS code that is potentially vulnerable to MITM attacks. Various forms of SSL/TLS misuse were discovered during a further manual audit of 100 selected apps that allowed us to successfully launch MITM attacks against 41 apps and gather a large variety of sensitive data. Furthermore, an online survey was conducted to evaluate users' perceptions of certificate warnings and HTTPS visual security indicators in Android's browser, showing that half of the 754 participating users were not able to correctly judge whether their browser session was protected by SSL/TLS or not. We conclude by considering the implications of these findings and discuss several countermeasures with which these problems could be alleviated.},
  isbn = {978-1-4503-1651-4},
  keywords = {android,apps,mitma,security,ssl}
}

@inproceedings{EBFK13,
  title = {An Empirical Study of Cryptographic Misuse in Android Applications},
  booktitle = {Proceedings of the 2013 {{ACM SIGSAC}} Conference on {{Computer}} \& Communications Security - {{CCS}} '13},
  author = {Egele, Manuel and Brumley, David and Fratantonio, Yanick and Kruegel, Christopher},
  year = {2013},
  pages = {73--84},
  publisher = {{ACM Press}},
  address = {{Berlin, Germany}},
  doi = {10.1145/2508859.2516693},
  urldate = {2019-01-23},
  abstract = {Developers use cryptographic APIs in Android with the intent of securing data such as passwords and personal information on mobile devices. In this paper, we ask whether developers use the cryptographic APIs in a fashion that provides typical cryptographic notions of security, e.g., IND-CPA security. We develop program analysis techniques to automatically check programs on the Google Play marketplace, and find that 10,327 out of 11,748 applications that use cryptographic APIs \textendash{} 88\% overall \textendash{} make at least one mistake. These numbers show that applications do not use cryptographic APIs in a fashion that maximizes overall security. We then suggest specific remediations based on our analysis towards improving overall cryptographic security in Android applications.},
  isbn = {978-1-4503-2477-9},
  langid = {english},
  keywords = {symmetric}
}

@inproceedings{CGM16,
  title = {{{HornDroid}}: {{Practical}} and {{Sound Static Analysis}} of {{Android Applications}} by {{SMT Solving}}},
  shorttitle = {{{HornDroid}}},
  booktitle = {2016 {{IEEE European Symposium}} on {{Security}} and {{Privacy}} ({{EuroS P}})},
  author = {Calzavara, S. and Grishchenko, I. and Maffei, M.},
  year = {2016},
  month = mar,
  pages = {47--62},
  doi = {10.1109/EuroSP.2016.16},
  abstract = {We present HornDroid, a new tool for the static analysis of information flow properties in Android applications. The core idea underlying HornDroid is to use Horn clauses for soundly abstracting the semantics of Android applications and to express security properties as a set of proof obligations that are automatically discharged by an off-the-shelf SMT solver. This approach makes it possible to fine-tune the analysis in order to achieve a high degree of precision while still using off-the-shelf verification tools, thereby leveraging the recent advances in this field. As a matter of fact, HornDroid outperforms state-of-the-art Android static analysis tools on benchmarks proposed by the community. Moreover, HornDroid is the first static analysis tool for Android to come with a formal proof of soundness, which covers the core of the analysis technique: besides yielding correctness assurances, this proof allowed us to identify some critical corner-cases that affect the soundness guarantees provided by some of the previous static analysis tools for Android.},
  keywords = {Analytical models,Android (operating system),Android applications,Androids,HornDroid,Humanoid robots,information flow properties,Java,off-the-shelf SMT solver,program diagnostics,Security,security of data,security properties,Semantics,Smart phones,sound static analysis}
}

@inproceedings{ARLB14,
  title = {{{DroidForce}}: {{Enforcing}} Complex, Data-Centric, System-Wide Policies in Android},
  booktitle = {International Conference on Availability, Reliability and Security ({{ARES}} 2014)},
  author = {Arzt, Steven and Rasthofer, Siegfried and Lovat, Enrico and Bodden, Eric},
  year = {2014},
  month = sep,
  pages = {40--49},
  publisher = {{IEEE}}
}


@inproceedings{AB16,
  title = {{{StubDroid}}: {{Automatic}} Inference of Precise Data-Flow Summaries for the Android Framework},
  booktitle = {International Conference for Software Engineering ({{ICSE}})},
  author = {Arzt, Steven and Bodden, Eric},
  year = {2016},
  month = may,
  keywords = {ITSECWEBSITE}
}

@article{SAB19a,
  title = {Context-, Flow-, and Field-Sensitive Data-Flow Analysis Using Synchronized {{Pushdown}} Systems},
  author = {Sp{\"a}th, Johannes and Ali, Karim and Bodden, Eric},
  year = {2019},
  month = jan,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {3},
  number = {POPL},
  pages = {1--29},
  issn = {2475-1421},
  doi = {10.1145/3290361},
  urldate = {2023-04-13},

  langid = {english}
}


@inproceedings{KFSZ18,
  title = {Practical {{Precise Taint-flow Static Analysis}} for {{Android App Sets}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Klieber, William and Flynn, Lori and Snavely, Will and Zheng, Michael},
  year = {2018},
  month = aug,
  pages = {1--7},
  publisher = {{ACM}},
  address = {{Hamburg Germany}},
  doi = {10.1145/3230833.3232825},
  urldate = {2023-04-13},
  isbn = {978-1-4503-6448-5},
  langid = {english}
}

@inproceedings{BD16,
  title = {Mining {{Cryptography Misuse}} in {{Online Forums}}},
  booktitle = {2016 {{IEEE International Conference}} on {{Software Quality}}, {{Reliability}} and {{Security Companion}} ({{QRS-C}})},
  author = {Braga, A. and Dahab, R.},
  year = {2016},
  month = aug,
  pages = {143--150},
  doi = {10.1109/QRS-C.2016.23},
  abstract = {This work analyzes cryptography misuse by software developers, from their contributions to online forums on cryptography-based security and cryptographic programming. We studied three popular forums: Oracle Java Cryptography, Google Android Developers, and Google Android Security Discussions. We applied a data mining technique, namely Apriori, to elicit association rules among cryptographic bad practices, platform-specific issues, cryptographic programming tasks, and cryptography-related use cases. We found that, with surprisingly high probabilities (90\% for Java and 71\% for Android), several types of cryptography misuse can be found in the posts, but unfortunately masked by technology-specific issues and programming concerns. We also found that cryptographic bad practices frequently occur in pairs or triples. We related triple associations to use cases and tasks, characterizing worst case scenarios of cryptography misuse. Finally, we observed that hard-to-use architectures confuse developers and contribute to perpetuate recurring errors in cryptographic programming.},
  keywords = {Android (operating system),Apriori,Apriori algorithm,association rules,Computer architecture,cryptographic programming,cryptography,cryptography misuse,cryptography misuse mining,cryptography-based security,data mining,Encryption,Google Android developers,Google Android security discussions,Java,Java cryptographic architecture,online forums,oracle Java cryptography,probabilities,probability,Programming,secure coding,Software}
}

@inproceedings{NWA+17,
  title = {A {{Stitch}} in {{Time}}: {{Supporting Android Developers}} in {{WritingSecure Code}}},
  shorttitle = {A {{Stitch}} in {{Time}}},
  booktitle = {Proceedings of the 2017 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Nguyen, Duc Cuong and Wermke, Dominik and Acar, Yasemin and Backes, Michael and Weir, Charles and Fahl, Sascha},
  year = {2017},
  month = oct,
  series = {{{CCS}} '17},
  pages = {1065--1077},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3133956.3133977},
  urldate = {2023-04-13},
  abstract = {Despite security advice in the official documentation and an extensive body of security research about vulnerabilities and exploits, many developers still fail to write secure Android applications. Frequently, Android developers fail to adhere to security best practices, leaving applications vulnerable to a multitude of attacks. We point out the advantage of a low-time-cost tool both to teach better secure coding and to improve app security. Using the FixDroid IDE plug-in, we show that professional and hobby app developers can work with and learn from an in-environment tool without it impacting their normal work; and by performing studies with both students and professional developers, we identify key UI requirements and demonstrate that code delivered with such a tool by developers previously inexperienced in security contains significantly less security problems. Perfecting and adding such tools to the Android development environment is an essential step in getting both security and privacy for the next generation of apps.},
  isbn = {978-1-4503-4946-8},
  keywords = {android security,cryptographic api,support developers,usable security}
}


@article{BDA+19,
  title = {Understanding {{How}} to {{Use Static Analysis Tools}} for {{Detecting Cryptography Misuse}} in {{Software}}},
  author = {Braga, Alexandre and Dahab, Ricardo and Antunes, Nuno and Laranjeiro, Nuno and Vieira, Marco},
  year = {2019},
  month = dec,
  journal = {IEEE Transactions on Reliability},
  volume = {68},
  number = {4},
  pages = {1384--1403},
  issn = {0018-9529, 1558-1721},
  doi = {10.1109/TR.2019.2937214},
  urldate = {2019-12-03},
  abstract = {The use of cryptography is nowadays common in software systems, with cryptographic libraries widely available to software developers. As such, the likely weakest link in sensitive software has moved from cryptographic function implementations to the application code surrounding such functions. Ordinary developers usually lack knowledge in practical cryptography, and support from specialists is rare. Frequently, these difficulties are addressed by running static analysis tools to automatically detect cryptography misuse during coding and reviews. However, the effectiveness of such tools is not yet well understood. This article studies how well programmatic misuse of cryptography is detected by free static code analysis tools. The performance of such tools in detecting misuse is correlated to coding tasks and use cases commonly found in development efforts; also, cryptography misuse is classified in comprehensive categories, easily recognizable by software security practitioners. Our research shows that the coverage of public-key cryptography by static code analysis tools is full of blind spots, because tools prioritize only those misuses related to the most frequent coding tasks and use cases, while neglecting infrequent use cases. We found that, in addition to a relatively low recall in our tests, evaluated tools also have a small overlap regarding the misuses detected by all the evaluated tools, as well as an intersection of false alarms, suggesting lack of discrimination between specific misuses and corresponding good uses of cryptography. In spite of that, well-selected tools can be useful when developing cryptographic software, but support of experts is still required for solving complex cases.},
  langid = {english}
}


@inproceedings{BBD+16,
  title = {R-{{Droid}}: {{Leveraging Android App Analysis}} with {{Static Slice Optimization}}},
  shorttitle = {R-{{Droid}}},
  booktitle = {Proceedings of the 11th {{ACM}} on {{Asia Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Backes, Michael and Bugiel, Sven and Derr, Erik and Gerling, Sebastian and Hammer, Christian},
  year = {2016},
  series = {{{ASIA CCS}} '16},
  pages = {129--140},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2897845.2897927},
  urldate = {2019-02-14},
  abstract = {Today's feature-rich smartphone apps intensively rely on access to highly sensitive (personal) data. This puts the user's privacy at risk of being violated by overly curious apps or libraries (like advertisements). Central app markets conceptually represent a first line of defense against such invasions of the user's privacy, but unfortunately we are still lacking full support for automatic analysis of apps' internal data flows and supporting analysts in statically assessing apps' behavior. In this paper we present a novel slice-optimization approach to leverage static analysis of Android applications. Building on top of precise application lifecycle models, we employ a slicing-based analysis to generate data-dependent statements for arbitrary points of interest in an application. As a result of our optimization, the produced slices are, on average, 49\% smaller than standard slices, thus facilitating code understanding and result validation by security analysts. Moreover, by re-targeting strings, our approach enables automatic assessments for a larger number of use-cases than prior work. We consolidate our improvements on statically analyzing Android apps into a tool called R-Droid and conducted a large-scale data-leak analysis on a set of 22,700 Android apps from Google Play. R-Droid managed to identify a significantly larger set of potential privacy-violating information flows than previous work, including 2,157 sensitive flows of password-flagged UI widgets in 256 distinct apps.},
  isbn = {978-1-4503-4233-9},
  keywords = {android,app analysis,constant propagation,mobile security,slice optimization,string analysis,technique}
}

@article{CM04,
  title = {Static Analysis for Security},
  author = {Chess, B. and McGraw, G.},
  year = {2004},
  month = nov,
  journal = {IEEE Security Privacy},
  volume = {2},
  number = {6},
  pages = {76--79},
  issn = {1558-4046},
  doi = {10.1109/MSP.2004.111},
  abstract = {All software projects are guaranteed to have one artifact in common \$source code. Together with architectural risk analysis, code review for security ranks very high on the list of software security best practices. We look at how to automate source-code security analysis with static analysis tools.},
  keywords = {Application software,Best practices,Buildings,Computer bugs,Computer languages,Computer security,Costs,Privacy,quotable,Rats,Risk analysis,software development life cycle,source code,static analysis}
}


@inproceedings{QWR18,
  title = {Analyzing the Analyzers: {{FlowDroid}}/{{IccTA}}, {{AmanDroid}}, and {{DroidSafe}}},
  shorttitle = {Analyzing the Analyzers},
  booktitle = {Proceedings of the 27th {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}} - {{ISSTA}} 2018},
  author = {Qiu, Lina and Wang, Yingying and Rubin, Julia},
  year = {2018},
  pages = {176--186},
  publisher = {{ACM Press}},
  address = {{Amsterdam, Netherlands}},
  doi = {10.1145/3213846.3213873},
  urldate = {2020-06-14},
  abstract = {Numerous static analysis techniques have recently been proposed for identifying information flows in mobile applications. These techniques are compared to each other, usually on a set of syntactic benchmarks. Yet, configurations used for such comparisons are rarely described. Our experience shows that tools are often compared under different setup, rendering the comparisons irreproducible and largely inaccurate. In this paper, we provide a large, controlled, and independent comparison of the three most prominent static analysis tools: FlowDroid combined with IccTA, Amandroid, and DroidSafe. We evaluate all tools using common configuration setup and on the same set of benchmark applications. We compare the results of our analysis to the results reported in previous studies, identify main reasons for inaccuracy in existing tools, and provide suggestions for future research.},
  isbn = {978-1-4503-5699-2},
  langid = {english}
}

@inproceedings{ANN+16,
  title = {{{MUBench}}: {{A Benchmark}} for {{API-Misuse Detectors}}},
  shorttitle = {{{MUBench}}},
  booktitle = {2016 {{IEEE}}/{{ACM}} 13th {{Working Conference}} on {{Mining Software Repositories}} ({{MSR}})},
  author = {Amann, S. and Nadi, S. and Nguyen, H. A. and Nguyen, T. N. and Mezini, M.},
  year = {2016},
  month = may,
  pages = {464--467},
  doi = {10.1109/MSR.2016.055},
  abstract = {Over the last few years, researchers proposed a multitude of automated bug-detection approaches that mine a class of bugs that we call API misuses. Evaluations on a variety of software products show both the omnipresence of such misuses and the ability of the approaches to detect them. This work presents MuBench, a dataset of 89 API misuses that we collected from 33 real-world projects and a survey. With the dataset we empirically analyze the prevalence of API misuses compared to other types of bugs, finding that they are rare, but almost always cause crashes. Furthermore, we discuss how to use it to benchmark and compare API-misuse detectors.},
  keywords = {API-Misuse Detection,API-misuse detectors,application program interfaces,automated bug-detection,Benchmark,Benchmark testing,Bug Detection,Computer bugs,Detectors,Java,Metadata,MUBench,program debugging,Software,software engineering,software product variety}
}

@article{ANN+19,
  title = {A {{Systematic Evaluation}} of {{Static API-Misuse Detectors}}},
  author = {Amann, Sven and Nguyen, Hoan Anh and Nadi, Sarah and Nguyen, Tien N. and Mezini, Mira},
  year = {2019},
  month = dec,
  journal = {IEEE Transactions on Software Engineering},
  volume = {45},
  number = {12},
  pages = {1170--1188},
  issn = {1939-3520},
  doi = {10.1109/TSE.2018.2827384},
  abstract = {Application Programming Interfaces (APIs) often have usage constraints, such as restrictions on call order or call conditions. API misuses, i.e., violations of these constraints, may lead to software crashes, bugs, and vulnerabilities. Though researchers developed many API-misuse detectors over the last two decades, recent studies show that API misuses are still prevalent. Therefore, we need to understand the capabilities and limitations of existing detectors in order to advance the state of the art. In this paper, we present the first-ever qualitative and quantitative evaluation that compares static API-misuse detectors along the same dimensions, and with original author validation. To accomplish this, we develop MUC, a classification of API misuses, and MUBENCHPIPE, an automated benchmark for detector comparison, on top of our misuse dataset, MUBENCH. Our results show that the capabilities of existing detectors vary greatly and that existing detectors, though capable of detecting misuses, suffer from extremely low precision and recall. A systematic root-cause analysis reveals that, most importantly, detectors need to go beyond the naive assumption that a deviation from the most-frequent usage corresponds to a misuse and need to obtain additional usage examples to train their models. We present possible directions towards more-powerful API-misuse detectors.},
  keywords = {API-misuse detection,application program interfaces,benchmark,Benchmark testing,Classification,Computer bugs,Detectors,failure analysis,misuse classification,misuse dataset,MUBench,MUBENCH dataset,MUBENCHPIPE benchmark,program diagnostics,security of data,static API-misuse detectors,survey,systematic root-cause analysis,Systematics}
}

@misc{SWK+22,
  title = {{{CamBench}} -- {{Cryptographic API Misuse Detection Tool Benchmark Suite}}},
  author = {Schlichtig, Michael and Wickert, Anna-Katharina and Kr{\"u}ger, Stefan and Bodden, Eric and Mezini, Mira},
  year = {2022},
  month = apr,
  number = {arXiv:2204.06447},
  eprint = {arXiv:2204.06447},
  publisher = {{arXiv}},
  urldate = {2023-02-11},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Software Engineering}
}

@techreport{FAR+13,
  title = {Highly Precise Taint Analysis for Android Applications},
  author = {Fritz, Christian and Arzt, Steven and Rasthofer, Siegfried and Bodden, Eric and Bartel, Alexandre and Klein, Jacques and le Traon, Yves and Octeau, Damien and McDaniel, Patrick},
  year = {2013},
  month = may,
  number = {TUD-CS-2013-0113},
  institution = {{EC SPRIDE}}
}

@inproceedings{ARY19,
  title = {{{CryptoAPI-Bench}}: {{A}} Comprehensive Benchmark on Java Cryptographic {{API}} Misuses},
  booktitle = {2019 {{IEEE}} Cybersecurity Development ({{SecDev}})},
  author = {Afrose, S. and Rahaman, S. and Yao, D.},
  year = {2019},
  month = sep,
  pages = {49--61},
  doi = {10.1109/SecDev.2019.00017},
  keywords = {accuracy,benchmark,cryptographic API misuses}
}



@article{AXR+22,
  title = {Evaluation of {{Static Vulnerability Detection Tools}} with {{Java Cryptographic API Benchmarks}}},
  author = {Afrose, Sharmin and Xiao, Ya and Rahaman, Sazzadur and Miller, Barton and Yao, Danfeng Daphne},
  year = {2022},
  journal = {IEEE Transactions on Software Engineering},
  doi = {10.1109/TSE.2022.3154717},
  urldate = {2022-04-02},
  langid = {english}
}

@article{NMF+18,
  title = {Benchmarking {{Static Analysis Tools}} for {{Web Security}}},
  author = {Nunes, Paulo and Medeiros, Ib{\'e}ria and Fonseca, Jos{\'e} C. and Neves, Nuno and Correia, Miguel and Vieira, Marco},
  year = {2018},
  month = sep,
  journal = {IEEE Transactions on Reliability},
  volume = {67},
  number = {3},
  pages = {1159--1175},
  issn = {1558-1721},
  doi = {10.1109/TR.2018.2839339},
  abstract = {Static analysis tools are recurrently used by developers to search for vulnerabilities in the source code of web applications. However, distinct tools provide different results depending on factors such as the complexity of the code under analysis and the application scenario; thus, missing some of the vulnerabilities while reporting false problems. Benchmarks can be used to assess and compare different systems or components, however, existing benchmarks have strong representativeness limitations, disregarding the specificities of the environment, where the tools under benchmarking will be used. In this paper, we propose a benchmark for assessing and comparing static analysis tools in terms of their capability to detect security vulnerabilities. The benchmark considers four real-world development scenarios, including workloads composed of real web applications with different goals and constraints, ranging from low budget to high-end applications. Our benchmark was implemented and assessed experimentally using a set of 134 WordPress plugins, which served as the basis for the evaluation of five free PHP static analysis tools. Results clearly show that the best solution depends on the deployment scenario and class of vulnerability being detected; therefore, highlighting the importance of these aspects in the design of the benchmark and of future static analysis tools.},
  keywords = {Benchmark testing,Benchmarking,Complexity theory,security metrics,Software tools,Static analysis,static analysis tools (SATs),vulnerability detection}
}

@inproceedings{ZCD+19,
  title = {{{CryptoREX}}: Large-Scale Analysis of Cryptographic Misuse in {{IoT}} Devices},
  booktitle = {22nd International Symposium on Research in Attacks, Intrusions and Defenses ({{RAID}} 2019)},
  author = {Zhang, Li and Chen, Jiongyi and Diao, Wenrui and Guo, Shanqing and Weng, Jian and Zhang, Kehuan},
  year = {2019},
  month = sep,
  pages = {151--164},
  publisher = {{USENIX Association}},
  address = {{Chaoyang District, Beijing}},
  isbn = {978-1-939133-07-6}
}


@inproceedings{WRE+19,
  title = {A {{Dataset}} of {{Parametric Cryptographic Misuses}}},
  booktitle = {2019 {{IEEE}}/{{ACM}} 16th {{International Conference}} on {{Mining Software Repositories}} ({{MSR}})},
  author = {Wickert, Anna-Katharina and Reif, Michael and Eichberg, Michael and Dodhy, Anam and Mezini, Mira},
  year = {2019},
  month = may,
  pages = {96--100},
  issn = {2574-3864},
  doi = {10.1109/MSR.2019.00023},
  abstract = {Cryptographic APIs (Crypto APIs) provide the foundations for the development of secure applications. Unfortunately, most applications do not use Crypto APIs securely and end up being insecure, e.g., by the usage of an outdated algorithm, a constant initialization vector, or an inappropriate hashing algorithm. Two different studies [1], [2] have recently shown that 88\% to 95\% of those applications using Crypto APIs are insecure due to misuses. To facilitate further research on these kinds of misuses, we created a collection of 201 misuses found in real-world applications along with a classification of those misuses. In the provided dataset, each misuse consists of the corresponding open-source project, the project's build information, a description of the misuse, and the misuse's location. Further, we integrated our dataset into MUBench [3], a benchmark for API misuse detection. Our dataset provides a foundation for research on Crypto API misuses. For example, it can be used to evaluate the precision and recall of detection tools, as a foundation for studies related to Crypto API misuses, or as a training set.},
  keywords = {API-misuse,benchmark,Benchmark testing,Computer bugs,Cryptographic misuse,Cryptography,dataset,Java,Static analysis,Tools}
}

@inproceedings{MR17,
  title = {Ghera: {{A Repository}} of {{Android App Vulnerability Benchmarks}}},
  shorttitle = {Ghera},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Predictive Models}} and {{Data Analytics}} in {{Software Engineering}}},
  author = {Mitra, Joydeep and Ranganath, Venkatesh-Prasad},
  year = {2017},
  month = nov,
  pages = {43--52},
  publisher = {{ACM}},
  address = {{Toronto Canada}},
  doi = {10.1145/3127005.3127010},
  urldate = {2023-04-13},
  isbn = {978-1-4503-5305-2},
  langid = {english}
}

@inproceedings{PBW18,
  title = {Do {{Android Taint Analysis Tools Keep Their Promises}}?},
  booktitle = {Proceedings of the 2018 26th {{ACM Joint Meeting}} on {{European Software Engineering Conference}} and {{Symposium}} on the {{Foundations}} of {{Software Engineering}}},
  author = {Pauck, Felix and Bodden, Eric and Wehrheim, Heike},
  year = {2018},
  series = {{{ESEC}}/{{FSE}} 2018},
  pages = {331--341},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3236024.3236029},
  urldate = {2019-02-14},
  abstract = {In recent years, researchers have developed a number of tools to conduct taint analysis of Android applications. While all the respective papers aim at providing a thorough empirical evaluation, comparability is hindered by varying or unclear evaluation targets. Sometimes, the apps used for evaluation are not precisely described. In other cases, authors use an established benchmark but cover it only partially. In yet other cases, the evaluations differ in terms of the data leaks searched for, or lack a ground truth to compare against. All those limitations make it impossible to truly compare the tools based on those published evaluations.   We thus present ReproDroid, a framework allowing the accurate comparison of Android taint analysis tools. ReproDroid supports researchers in inferring the ground truth for data leaks in apps, in automatically applying tools to benchmarks, and in evaluating the obtained results. We use ReproDroid to comparatively evaluate on equal grounds the six prominent taint analysis tools Amandroid, DIALDroid, DidFail, DroidSafe, FlowDroid and IccTA. The results are largely positive although four tools violate some promises concerning features and accuracy. Finally, we contribute to the area of unbiased benchmarking with a new and improved version of the open test suite DroidBench.},
  isbn = {978-1-4503-5573-5},
  keywords = {Android Taint Analysis,Benchmarks,Empirical Studies,reprodroid,Reproducibility,review,Tools}
}
@article{LPP+22,
  title = {{{TaintBench}}: {{Automatic}} Real-World Malware Benchmarking of {{Android}} Taint Analyses},
  shorttitle = {{{TaintBench}}},
  author = {Luo, Linghui and Pauck, Felix and Piskachev, Goran and Benz, Manuel and Pashchenko, Ivan and Mory, Martin and Bodden, Eric and Hermann, Ben and Massacci, Fabio},
  year = {2022},
  month = jan,
  journal = {Empirical Software Engineering},
  volume = {27},
  number = {1},
  pages = {16},
  issn = {1382-3256, 1573-7616},
  doi = {10.1007/s10664-021-10013-5},
  urldate = {2022-07-11},
  abstract = {Due to the lack of established real-world benchmark suites for static taint analyses of Android applications, evaluations of these analyses are often restricted and hard to compare. Even in evaluations that do use real-world apps, details about the ground truth in those apps are rarely documented, which makes it difficult to compare and reproduce the results. To push Android taint analysis research forward, this paper thus recommends criteria for constructing real-world benchmark suites for this specific domain, and presents TAINTBENCH, the first real-world malware benchmark suite with documented taint flows. TAINTBENCH benchmark apps include taint flows with complex structures, and addresses static challenges that are commonly agreed on by the community. Together with the TAINTBENCH suite, we introduce the TAINTBENCH framework, whose goal is to simplify real-world benchmarking of Android taint analyses. First, a usability test shows that the framework improves experts' performance and perceived usability when documenting and inspecting taint flows. Second, experiments using TAINTBENCH reveal new insights for the taint analysis tools AMANDROID and FLOWDROID: (i) They are less effective on real-world malware apps than on synthetic benchmark apps. (ii) Predefined lists of sources and sinks heavily impact the tools' accuracy. (iii) Surprisingly, up-to-date versions of both tools are less accurate than their predecessors.},
  langid = {english}
}


@inproceedings{GAF+21,
  title = {Evaluating and {{Improving Static Analysis Tools Via Differential Mutation Analysis}}},
  booktitle = {2021 {{IEEE}} 21st {{International Conference}} on {{Software Quality}}, {{Reliability}} and {{Security}} ({{QRS}})},
  author = {Groce, Alex and Ahmed, Iftekhar and Feist, Josselin and Grieco, Gustavo and Gesi, Jiri and Meidani, Mehran and Chen, Qihong},
  year = {2021},
  month = dec,
  pages = {207--218},
  publisher = {{IEEE}},
  address = {{Hainan, China}},
  doi = {10.1109/QRS54544.2021.00032},
  urldate = {2022-07-19},
  abstract = {Static analysis tools attempt to detect faults in code without executing it. Understanding the strengths and weaknesses of such tools, and performing direct comparisons of their effectiveness, is difficult, involving either manual examination of differing warnings on real code, or the bias-prone construction of artificial test cases. This paper proposes a novel automated approach to comparing static analysis tools, based on producing mutants of real code, and comparing detection rates over these mutants. In addition to making tool differences quantitatively observable without extensive manual effort, this approach offers a new way to detect and fix omissions in a static analysis tool's set of detectors. We present an extensive comparison of three smart contract static analysis tools, and show how our approach allowed us to add three effective new detectors to the best of these. We also evaluate popular Java and Python static analysis tools and discuss their strengths and weaknesses.},
  isbn = {978-1-66545-813-9},
  langid = {english}
}

@inproceedings{BKM+18,
  title = {Discovering {{Flaws}} in {{Security-Focused Static Analysis Tools}} for {{Android}} Using {{Systematic Mutation}}},
  booktitle = {27th {{USENIX Security Symposium}} ({{USENIX Security}} 18)},
  author = {Bonett, Richard and Kafle, Kaushal and Moran, Kevin and Nadkarni, Adwait and Poshyvanyk, Denys},
  year = {2018},
  month = aug,
  pages = {1263--1280},
  publisher = {{USENIX Association}},
  address = {{Baltimore, MD}},
  isbn = {978-1-939133-04-5}
}

@article{DFLO19,
  title = {Scaling Static Analyses at {{Facebook}}},
  author = {Distefano, Dino and F{\"a}hndrich, Manuel and Logozzo, Francesco and O'Hearn, Peter W.},
  year = {2019},
  month = jul,
  journal = {Communications of the ACM},
  volume = {62},
  number = {8},
  pages = {62--70},
  issn = {0001-0782},
  doi = {10.1145/3338112},
  urldate = {2021-05-30},
  abstract = {Key lessons for designing static analyses tools deployed to find bugs in hundreds of millions of lines of code.}
}
