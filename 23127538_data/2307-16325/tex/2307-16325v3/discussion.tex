\vspace{-0.5em}
\section{Discussion}\label{sec:discussion}
\vspace{-0.5em}

The findings from our study reveal salient aspects of how developers use SASTs, what they expect from them, and how they react when SASTs do not fulfill those expectations.
We now distill the findings into four themes related to the problems inherent in the use and perceptions of SASTs as well as a path forward for researchers and practitioners.

\vspace{-0.5em}
\subsection{Mind the Gap: The Dichotomy of Perceived Developer Needs and SAST Selection/Evaluation}
\vspace{-0.5em}


A common sentiment observed throughout this study is that practitioners do care about and prioritize security.
To elaborate, practitioners stated that they would generally fix vulnerabilities regardless of release deadlines (\fnumber{1}), except in certain mitigating circumstances (\fnumber{2}, \fnumber{3}), and use SASTs to cover the blind spots and subjectivity pertinent to manual code analysis (\fnumber{6}).
Moreover, nearly all practitioners favored lower false negatives (\ie not "letting security things slide through") (\fnumber{10}), expressing a surprising tolerance for false positives as long as SASTs found vulnerabilities ~(\fnumber{11}).

However, we found that this strong preference for security, and particularly SASTs that find real vulnerabilities, is not reflected in how practitioners select SASTs.
To elaborate, practitioners select SASTs based on cost, corporate pressure, ease of integration/use, and particularly, recommendations from peers and general reputation of the tool (\fnumber{5}).
This generally ad-hoc and subjective criteria does not provide objective evidence of a SAST's performance in detecting vulnerabilities.
Hence, there is a clear {\em gap} between the criteria that practitioners use for selecting SASTs, and what they want most from SASTs (evidence of real vulnerability detection abilities).





\subsection{The Power of Reputation and the Lack of Reliable Objective Criteria}


The key question is, {\em why does  this gap exist? That is, why don't practitioners evaluate the security properties of SASTs?}
Our findings point to two key reasons:

First, we find that practitioners may not have any motivation to evaluate SASTs.
That is, practitioners seem to be unreasonably optimistic about the SASTs' abilities, assuming that SASTs must detect everything they claim to (\ie define as within scope) (\fnumber{8}), and assume that SASTs "just work" (\fnumber{14}).
This optimism, coupled with their reliance on reputation as a valid metric for selecting SASTs (\fnumber{4}), may be sufficient to dissuade practitioners from any additional effort required to evaluate SASTs.
Thus, the observed lack of motivation to evaluate SASTs is concerning, particularly as the blind belief practitioners express in SASTs and their reputation does not hold up to scrutiny: \eg a recent evaluation of reputed crypto-API vulnerability detectors showed serious, previously unknown flaws, which prevent the detectors from finding vulnerabilities they consider ``in scope''~\cite{ACK+22}.

Second, even when practitioners want to evaluate SASTs, the existing means to do so, \ie benchmarks, are perceived as insufficient.
As we found, while some practitioners may be unaware of benchmarks for evaluating SASTs, most are not.
In fact, most practitioners {\em do not trust existing benchmarks}, viewing them as either too basic (and not representative of real, complex, vulnerabilities), or biased (\fnumber{5}).
These findings indicate a significant gap in the research on evaluating SASTs, and motivate the development of high-quality, comprehensive, real-world benchmarks vetted by both researchers and practitioners, if we intend to help practitioners objectively evaluate SASTs for what they most desire: the ability to detect vulnerabilities.











\vspace{-0.5em}
\subsection{Giving Developers What They Want}
\vspace{-0.5em}
We observe that practitioners repeatedly expressed that they want two things from \sasts: ease of configuration (\fnumber{4}, \fnumber{17}), and for tools to detect real vulnerabilities (\fnumber{8}).

Fortunately, the ease of configuration is being addressed by the recent, additional support for \sasts through integration into CI/CD pipelines of open source projects, such as via Github Actions~\cite{github-actions, github-code-scan}, as well as standardized output formats, such as SARIF~\cite{SARIF}.
However, the latter is harder to achieve at present.
That is, while our practitioners repeatedly expressed that they want SASTs to be first and foremost able to find critical vulnerabilities (and all those considered within scope, \fnumber{8}), even at the cost of higher number of false positives (\fnumber{10}, \fnumber{11}), the research community continues to show preference towards improving precision instead, \ie decreasing false positives, for SAST tools throughout the last decade~\cite{2018_AmandroidPreciseGeneral_wei,2013_FlowDroidPreciseContext_arzt,2015_ScalablePreciseTaint_huang,RXA+19, BBC+10, SFZ11,SAE+18}. %
Thus, for SASTs to actually be useful, the research and industry communities  need to refocus their efforts towards finding critical vulnerabilities (and all that is deemed within scope), with improved precision being an additional, desired, property.










\vspace{-0.5em}
\subsection{Industry is not prepared for the flaws of \sasts{}}
\vspace{-0.5em}

Our findings expose a {\bf \em critical paradox} in the assumptions industry practitioners make about their approach towards SASTs:
While practitioners do expect SASTs to detect all vulnerabilities within scope (\fnumber{8}), they are not overly concerned with SASTs missing such vulnerabilities due to undocumented flaws, because their subsequent manual analysis to find what the SASTs missed (\fnumber{13}).
However, practitioners also emphasized that their key reason for using SASTs is to account for knowledge gaps, blind spots, and subjectivity inherent in manual analysis (\fnumber{6}, \fnumber{12}).
To summarize the paradox, practitioners use SASTs to account for gaps in manual analysis, but then, in turn, are confident that manual analysis will account for (unknown) \sast flaws.

This paradox suggests several undesirable aspects of the status quo. First, that developers may be overly confident in guarantees offered by their process of combining SASTs (or other tools) and manual analysis, or may simply take the reports of SASTs at face value (\fnumber{14}), which may result in undetected vulnerabilities in code that are missed by both SASTs and manual analysis; \eg previous work has shown that the same undocumented flaws can manifest in any number of \sasts, and lead to vulnerabilities in programs analyzed by the SASTs~\cite{ACK+22,AKM+21}.
Second, given that practitioners generally hesitate to report flaws in SASTs (\fnumber{15}), the flaws in a SAST would persist and harm most software using the SAST, even if a few practitioners do uncover false negatives/flaws during manual analysis.
That is, if the status quo observed in this study continues, SASTs will likely never improve in their ability to detect vulnerabilities, but instead, will continue to be used in a manner that inspires a false sense of security among practitioners.

To summarize, we conclude that the industry is ill-equipped to find or address any flaws in \sasts, particularly given the state of current reporting processes that are mired in confidentiality issues, an evasive attitude, and lack of response from \sasts (\fnumber{15}).
Thus, practitioners are stuck with repurposing common issue submission processes that does not cater to their confidentiality needs, does not elicit a response, and does not facilitate discussion.

\vspace{-0.25em}
\subsection{Moving Forward: New Directions and Ideas}
\vspace{-0.25em}

To improve this status quo, researchers and practitioners need to establish a dedicated process for reporting false negatives, as well as expectations from SASTs upon receiving such reports, in a manner similar to bug reporting expectations for typical software products. This might involve the development of automated methods for creating minimal examples of vulnerabilities missed by SASTs or even ``self-healing'' SASTs that leverage advancements in automated program repair to address missed vulnerabilities.
Moreover, future work may also explore streamlining the automated evaluation of SASTs (\eg developing web-based services that allow practitioners to "test" SASTs with realistic vulnerabilities), so that developers may be able to evaluate SASTs before using them, instead of leveraging subjective criteria for the same.
Beyond evaluation techniques, researchers should also consider orienting future work on SAST development toward the high preference of practitioners in finding important/critical vulnerabilities, even at the expense of a high number of false positives. 

To summarize, only by raising awareness about the flaws in \sasts, aligning their goals with the goals of developers, designing protocols for evaluating them, and streamlining bug reporting, particularly for false negatives, can we move towards a more desired state where practitioners are able to leverage SASTs to their true potential, resulting in a holistic reduction in hard-to-find vulnerabilities.
















