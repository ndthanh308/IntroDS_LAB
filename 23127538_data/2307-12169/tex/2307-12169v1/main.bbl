\begin{thebibliography}{10}

\bibitem{aibusinessgptuser}
Ubs: Chatgpt may be the fastest growing app of all time, 2023.
\newblock URL
  \url{https://aibusiness.com/nlp/ubs-chatgpt-is-the-fastest-growing-app-of-all-time}.

\bibitem{bard}
What’s ahead for bard: More global, more visual, more integrated, 2023.
\newblock URL
  \url{https://blog.google/technology/ai/google-bard-updates-io-2023}.

\bibitem{githubcop}
Your ai pair programmer: Github copilot uses the openai codex to suggest code
  and entire functions in real-time, right from your editor., 2023.
\newblock URL \url{https://github.com/features/copilot}.

\bibitem{bing}
Confirmed: the new bing runs on openai’s gpt-4, 2023.
\newblock URL
  \url{https://blogs.bing.com/search/march_2023/Confirmed-the-new-Bing-runs-on-OpenAI%E2%80%99s-GPT-4}.

\bibitem{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem{gpt4params}
Gpt-4 has a trillion parameters - report, 2023.
\newblock URL \url{https://the-decoder.com/gpt-4-has-a-trillion-parameters/}.

\bibitem{flex_flow}
Z.~Jia, M.~Zaharia, and A.~Aiken.
\newblock Beyond data and model parallelism for deep neural networks.
\newblock {\em SysML}, 2019.

\bibitem{alpa}
L.~Zheng, Z.~Li, H.~Zhang, Y.~Zhuang, Z.~Chen, Y.~Huang, Y.~Wang, Y.~Xu,
  D.~Zhuo, E.~P. Xing, J.~E. Gonzalez, and I.~Stoica.
\newblock Alpa: Automating inter- and {Intra-Operator} parallelism for
  distributed deep learning.
\newblock In {\em 16th USENIX Symposium on Operating Systems Design and
  Implementation (OSDI 22)}, pages 559--578, Carlsbad, CA, July 2022. USENIX
  Association.

\bibitem{unity}
C.~Unger, Z.~Jia, W.~Wu, S.~Lin, M.~Baines, C.~E.~Q. Narvaez,
  V.~Ramakrishnaiah, N.~Prajapati, P.~McCormick, J.~Mohd-Yusof, X.~Luo,
  D.~Mudigere, J.~Park, M.~Smelyanskiy, and A.~Aiken.
\newblock Unity: Accelerating {DNN} training through joint optimization of
  algebraic transformations and parallelization.
\newblock In {\em 16th USENIX Symposium on Operating Systems Design and
  Implementation (OSDI 22)}, pages 267--284, Carlsbad, CA, July 2022. USENIX
  Association.

\bibitem{tofu}
M.~Wang, C.-c. Huang, and J.~Li.
\newblock Supporting very large models using automatic dataflow graph
  partitioning.
\newblock In {\em Proceedings of the Fourteenth EuroSys Conference 2019},
  EuroSys '19, New York, NY, USA, 2019. Association for Computing Machinery.

\bibitem{muri}
Y.~Zhao, Y.~Liu, Y.~Peng, Y.~Zhu, X.~Liu, and X.~Jin.
\newblock Multi-resource interleaving for deep learning training.
\newblock In {\em Proceedings of the ACM SIGCOMM 2022 Conference}, SIGCOMM '22,
  page 428–440, New York, NY, USA, 2022. Association for Computing Machinery.

\bibitem{gandiva}
W.~Xiao, R.~Bhardwaj, R.~Ramjee, M.~Sivathanu, N.~Kwatra, Z.~Han, P.~Patel,
  X.~Peng, H.~Zhao, Q.~Zhang, F.~Yang, and L.~Zhou.
\newblock Gandiva: Introspective cluster scheduling for deep learning.
\newblock In {\em 13th USENIX Symposium on Operating Systems Design and
  Implementation (OSDI 18)}, pages 595--610, Carlsbad, CA, Oct. 2018. USENIX
  Association.

\bibitem{tiresias}
J.~Gu, M.~Chowdhury, K.~G. Shin, Y.~Zhu, M.~Jeon, J.~Qian, H.~Liu, and C.~Guo.
\newblock Tiresias: A {GPU} cluster manager for distributed deep learning.
\newblock In {\em 16th USENIX Symposium on Networked Systems Design and
  Implementation (NSDI 19)}, pages 485--500, Boston, MA, Feb. 2019. USENIX
  Association.

\bibitem{grad_comp}
Y.~Bai, C.~Li, Q.~Zhou, J.~Yi, P.~Gong, F.~Yan, R.~Chen, and Y.~Xu.
\newblock Gradient compression supercharged high-performance data parallel dnn
  training.
\newblock In {\em Proceedings of the ACM SIGOPS 28th Symposium on Operating
  Systems Principles}, SOSP '21, page 359–375, New York, NY, USA, 2021.
  Association for Computing Machinery.

\bibitem{sipml}
M.~Khani, M.~Ghobadi, M.~Alizadeh, Z.~Zhu, M.~Glick, K.~Bergman, A.~Vahdat,
  B.~Klenk, and E.~Ebrahimi.
\newblock Sip-ml: High-bandwidth optical network interconnects for machine
  learning training.
\newblock In {\em Proceedings of the 2021 ACM SIGCOMM 2021 Conference}, SIGCOMM
  '21, page 657–675, New York, NY, USA, 2021. Association for Computing
  Machinery.

\bibitem{topoopt}
W.~Wang, M.~Khazraee, Z.~Zhong, M.~Ghobadi, Z.~Jia, D.~Mudigere, Y.~Zhang, and
  A.~Kewitsch.
\newblock {TopoOpt}: Co-optimizing network topology and parallelization
  strategy for distributed training jobs.
\newblock In {\em 20th USENIX Symposium on Networked Systems Design and
  Implementation (NSDI 23)}, pages 739--767, Boston, MA, Apr. 2023. USENIX
  Association.

\bibitem{zhao2022optimal}
L.~Zhao, S.~Pal, T.~Chugh, W.~Wang, P.~Basu, J.~Khoury, and A.~Krishnamurthy.
\newblock Optimal direct-connect topologies for collective communications,
  2022.

\bibitem{gpt3}
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~Kaplan, P.~Dhariwal,
  A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal, A.~Herbert-Voss,
  G.~Krueger, T.~Henighan, R.~Child, A.~Ramesh, D.~M. Ziegler, J.~Wu,
  C.~Winter, C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray, B.~Chess,
  J.~Clark, C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and D.~Amodei.
\newblock Language models are few-shot learners, 2020.

\bibitem{gpt3time}
Openai's gpt-3 language model: A technical overview, 2020.
\newblock URL \url{https://lambdalabs.com/blog/demystifying-gpt-3}.

\bibitem{dgxh100archdoc}
Nvidia dgx superpod: Next generation scalable infrastructure for ai leadership,
  reference architecture, 2023.
\newblock URL
  \url{https://docs.nvidia.com/dgx-superpod-reference-architecture-with-dgx-h100-systems.pdf}.

\bibitem{nvlnvs}
Nvlink and nvswitch: The building blocks of advanced multi-gpu
  communication—within and between servers., 2023.
\newblock URL \url{https://www.nvidia.com/en-us/data-center/nvlink/}.

\bibitem{mlnxrdmagpu}
G.~Shainer, P.~Lui, and T.~Liu.
\newblock The development of mellanox/nvidia gpudirect over infiniband: A new
  model for gpu to gpu communications.
\newblock In {\em Proceedings of the 2011 TeraGrid Conference: Extreme Digital
  Discovery}, TG '11, New York, NY, USA, 2011. Association for Computing
  Machinery.

\bibitem{gpudirect}
Nvidia gpudirect: Enhancing data movement and access for gpus, 2023.
\newblock URL \url{https://developer.nvidia.com/gpudirect}.

\bibitem{pfc_storm}
C.~Guo, H.~Wu, Z.~Deng, G.~Soni, J.~Ye, J.~Padhye, and M.~Lipshteyn.
\newblock Rdma over commodity ethernet at scale.
\newblock In {\em Proceedings of the 2016 ACM SIGCOMM Conference}, SIGCOMM '16,
  page 202–215, New York, NY, USA, 2016. Association for Computing Machinery.

\bibitem{rdma_azure}
W.~Bai, S.~S. Abdeen, A.~Agrawal, K.~K. Attre, P.~Bahl, A.~Bhagat, G.~Bhaskara,
  T.~Brokhman, L.~Cao, A.~Cheema, R.~Chow, J.~Cohen, M.~Elhaddad, V.~Ette,
  I.~Figlin, D.~Firestone, M.~George, I.~German, L.~Ghai, E.~Green,
  A.~Greenberg, M.~Gupta, R.~Haagens, M.~Hendel, R.~Howlader, N.~John,
  J.~Johnstone, T.~Jolly, G.~Kramer, D.~Kruse, A.~Kumar, E.~Lan, I.~Lee,
  A.~Levy, M.~Lipshteyn, X.~Liu, C.~Liu, G.~Lu, Y.~Lu, X.~Lu, V.~Makhervaks,
  U.~Malashanka, D.~A. Maltz, I.~Marinos, R.~Mehta, S.~Murthi, A.~Namdhari,
  A.~Ogus, J.~Padhye, M.~Pandya, D.~Phillips, A.~Power, S.~Puri, S.~Raindel,
  J.~Rhee, A.~Russo, M.~Sah, A.~Sheriff, C.~Sparacino, A.~Srivastava, W.~Sun,
  N.~Swanson, F.~Tian, L.~Tomczyk, V.~Vadlamuri, A.~Wolman, Y.~Xie, J.~Yom,
  L.~Yuan, Y.~Zhang, and B.~Zill.
\newblock Empowering azure storage with {RDMA}.
\newblock In {\em 20th USENIX Symposium on Networked Systems Design and
  Implementation (NSDI 23)}, pages 49--67, Boston, MA, Apr. 2023. USENIX
  Association.

\bibitem{ib_deadlock}
T.~Schneider, O.~Bibartiu, and T.~Hoefler.
\newblock Ensuring deadlock-freedom in low-diameter infiniband networks.
\newblock In {\em 2016 IEEE 24th Annual Symposium on High-Performance
  Interconnects (HOTI)}, pages 1--8, 2016.

\bibitem{bfc}
P.~Goyal, P.~Shah, K.~Zhao, G.~Nikolaidis, M.~Alizadeh, and T.~E. Anderson.
\newblock Backpressure flow control.
\newblock In {\em 19th USENIX Symposium on Networked Systems Design and
  Implementation (NSDI 22)}, pages 779--805, Renton, WA, Apr. 2022. USENIX
  Association.

\bibitem{ddlindc}
S.~Hu, Y.~Zhu, P.~Cheng, C.~Guo, K.~Tan, J.~Padhye, and K.~Chen.
\newblock Deadlocks in datacenter networks: Why do they form, and how to avoid
  them.
\newblock In {\em Proceedings of the 15th ACM Workshop on Hot Topics in
  Networks}, HotNets '16, page 92–98, New York, NY, USA, 2016. Association
  for Computing Machinery.

\bibitem{rdma_cc}
Y.~Zhu, H.~Eran, D.~Firestone, C.~Guo, M.~Lipshteyn, Y.~Liron, J.~Padhye,
  S.~Raindel, M.~H. Yahia, and M.~Zhang.
\newblock Congestion control for large-scale rdma deployments.
\newblock In {\em Proceedings of the 2015 ACM Conference on Special Interest
  Group on Data Communication}, SIGCOMM '15, page 523–536, New York, NY, USA,
  2015. Association for Computing Machinery.

\bibitem{srnic}
Z.~Wang, L.~Luo, Q.~Ning, C.~Zeng, W.~Li, X.~Wan, P.~Xie, T.~Feng, K.~Cheng,
  X.~Geng, T.~Wang, W.~Ling, K.~Huo, P.~An, K.~Ji, S.~Zhang, B.~Xu, R.~Feng,
  T.~Ding, K.~Chen, and C.~Guo.
\newblock {SRNIC}: A scalable architecture for {RDMA} {NICs}.
\newblock In {\em 20th USENIX Symposium on Networked Systems Design and
  Implementation (NSDI 23)}, pages 1--14, Boston, MA, Apr. 2023. USENIX
  Association.

\bibitem{revisitrdmanet}
R.~Mittal, A.~Shpiner, A.~Panda, E.~Zahavi, A.~Krishnamurthy, S.~Ratnasamy, and
  S.~Shenker.
\newblock Revisiting network support for rdma.
\newblock In {\em Proceedings of the 2018 Conference of the ACM Special
  Interest Group on Data Communication}, SIGCOMM '18, page 313–326, New York,
  NY, USA, 2018. Association for Computing Machinery.

\bibitem{fattree}
M.~Al-Fares, A.~Loukissas, and A.~Vahdat.
\newblock A scalable, commodity data center network architecture.
\newblock In {\em Proceedings of the ACM SIGCOMM 2008 Conference on Data
  Communication}, SIGCOMM '08, page 63–74, New York, NY, USA, 2008.
  Association for Computing Machinery.

\bibitem{fbdcarch}
Introducing data center fabric, the next-generation facebook data center
  network, 2014.
\newblock URL
  \url{https://engineering.fb.com/2014/11/14/production-engineering/introducing-data-center-fabric-the-next-generation-facebook-data-center-network/}.

\bibitem{swhwcodesign}
D.~Mudigere, Y.~Hao, J.~Huang, Z.~Jia, A.~Tulloch, S.~Sridharan, X.~Liu,
  M.~Ozdal, J.~Nie, J.~Park, L.~Luo, J.~A. Yang, L.~Gao, D.~Ivchenko,
  A.~Basant, Y.~Hu, J.~Yang, E.~K. Ardestani, X.~Wang, R.~Komuravelli, C.-H.
  Chu, S.~Yilmaz, H.~Li, J.~Qian, Z.~Feng, Y.~Ma, J.~Yang, E.~Wen, H.~Li,
  L.~Yang, C.~Sun, W.~Zhao, D.~Melts, K.~Dhulipala, K.~Kishore, T.~Graf,
  A.~Eisenman, K.~K. Matam, A.~Gangidi, G.~J. Chen, M.~Krishnan, A.~Nayak,
  K.~Nair, B.~Muthiah, M.~khorashadi, P.~Bhattacharya, P.~Lapukhov, M.~Naumov,
  A.~Mathews, L.~Qiao, M.~Smelyanskiy, B.~Jia, and V.~Rao.
\newblock Software-hardware co-design for fast and scalable training of deep
  learning recommendation models.
\newblock In {\em Proceedings of the 49th Annual International Symposium on
  Computer Architecture}, ISCA '22, page 993–1011, New York, NY, USA, 2022.
  Association for Computing Machinery.

\bibitem{gh200}
Nvidia dgx gh200, 2023.
\newblock URL \url{https://www.nvidia.com/en-us/data-center/dgx-gh200/}.

\bibitem{zhang2022opt}
S.~Zhang, S.~Roller, N.~Goyal, M.~Artetxe, M.~Chen, S.~Chen, C.~Dewan, M.~Diab,
  X.~Li, X.~V. Lin, T.~Mihaylov, M.~Ott, S.~Shleifer, K.~Shuster, D.~Simig,
  P.~S. Koura, A.~Sridhar, T.~Wang, and L.~Zettlemoyer.
\newblock Opt: Open pre-trained transformer language models, 2022.

\bibitem{chowdhery2022palm}
A.~Chowdhery, S.~Narang, J.~Devlin, M.~Bosma, G.~Mishra, A.~Roberts, P.~Barham,
  H.~W. Chung, C.~Sutton, S.~Gehrmann, P.~Schuh, K.~Shi, S.~Tsvyashchenko,
  J.~Maynez, A.~Rao, P.~Barnes, Y.~Tay, N.~Shazeer, V.~Prabhakaran, E.~Reif,
  N.~Du, B.~Hutchinson, R.~Pope, J.~Bradbury, J.~Austin, M.~Isard, G.~Gur-Ari,
  P.~Yin, T.~Duke, A.~Levskaya, S.~Ghemawat, S.~Dev, H.~Michalewski, X.~Garcia,
  V.~Misra, K.~Robinson, L.~Fedus, D.~Zhou, D.~Ippolito, D.~Luan, H.~Lim,
  B.~Zoph, A.~Spiridonov, R.~Sepassi, D.~Dohan, S.~Agrawal, M.~Omernick, A.~M.
  Dai, T.~S. Pillai, M.~Pellat, A.~Lewkowycz, E.~Moreira, R.~Child, O.~Polozov,
  K.~Lee, Z.~Zhou, X.~Wang, B.~Saeta, M.~Diaz, O.~Firat, M.~Catasta, J.~Wei,
  K.~Meier-Hellstern, D.~Eck, J.~Dean, S.~Petrov, and N.~Fiedel.
\newblock Palm: Scaling language modeling with pathways, 2022.

\bibitem{shoeybi2020megatronlm}
M.~Shoeybi, M.~Patwary, R.~Puri, P.~LeGresley, J.~Casper, and B.~Catanzaro.
\newblock Megatron-lm: Training multi-billion parameter language models using
  model parallelism, 2020.

\bibitem{korthikanti2022reducing}
V.~Korthikanti, J.~Casper, S.~Lym, L.~McAfee, M.~Andersch, M.~Shoeybi, and
  B.~Catanzaro.
\newblock Reducing activation recomputation in large transformer models, 2022.

\bibitem{kaplan2020scaling}
J.~Kaplan, S.~McCandlish, T.~Henighan, T.~B. Brown, B.~Chess, R.~Child,
  S.~Gray, A.~Radford, J.~Wu, and D.~Amodei.
\newblock Scaling laws for neural language models, 2020.

\bibitem{jupiterevolving}
L.~Poutievski, O.~Mashayekhi, J.~Ong, A.~Singh, M.~Tariq, R.~Wang, J.~Zhang,
  V.~Beauregard, P.~Conner, S.~Gribble, R.~Kapoor, S.~Kratzer, N.~Li, H.~Liu,
  K.~Nagaraj, J.~Ornstein, S.~Sawhney, R.~Urata, L.~Vicisano, K.~Yasumura,
  S.~Zhang, J.~Zhou, and A.~Vahdat.
\newblock Jupiter evolving: Transforming google's datacenter network via
  optical circuit switches and software-defined networking.
\newblock In {\em Proceedings of the ACM SIGCOMM 2022 Conference}, SIGCOMM '22,
  page 66–85, New York, NY, USA, 2022. Association for Computing Machinery.

\bibitem{sirius}
H.~Ballani, P.~Costa, R.~Behrendt, D.~Cletheroe, I.~Haller, K.~Jozwik,
  F.~Karinou, S.~Lange, K.~Shi, B.~Thomsen, and H.~Williams.
\newblock Sirius: A flat datacenter network with nanosecond optical switching.
\newblock In {\em Proceedings of the Annual Conference of the ACM Special
  Interest Group on Data Communication on the Applications, Technologies,
  Architectures, and Protocols for Computer Communication}, SIGCOMM '20, page
  782–797, New York, NY, USA, 2020. Association for Computing Machinery.

\bibitem{dnnmodelgrowth}
Openai: Ai and compute, 2023.
\newblock URL \url{https://openai.com/research/ai-and-compute}.

\bibitem{dolly}
Hello dolly: Democratizing the magic of chatgpt with open models, 2023.
\newblock URL
  \url{https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html}.

\bibitem{alpaserve}
Z.~Li, L.~Zheng, Y.~Zhong, V.~Liu, Y.~Sheng, X.~Jin, Y.~Huang, Z.~Chen,
  H.~Zhang, J.~E. Gonzalez, and I.~Stoica.
\newblock {AlpaServe}: Statistical multiplexing with model parallelism for deep
  learning serving.
\newblock In {\em 17th USENIX Symposium on Operating Systems Design and
  Implementation (OSDI 23)}, Boston, MA, July 2023. USENIX Association.

\bibitem{zhao2023bandwidth}
L.~Zhao and A.~Krishnamurthy.
\newblock Bandwidth optimal pipeline schedule for collective communication,
  2023.

\bibitem{dlrm}
M.~Naumov, D.~Mudigere, H.-J.~M. Shi, J.~Huang, N.~Sundaraman, J.~Park,
  X.~Wang, U.~Gupta, C.-J. Wu, A.~G. Azzolini, D.~Dzhulgakov, A.~Mallevich,
  I.~Cherniavskii, Y.~Lu, R.~Krishnamoorthi, A.~Yu, V.~Kondratenko, S.~Pereira,
  X.~Chen, W.~Chen, V.~Rao, B.~Jia, L.~Xiong, and M.~Smelyanskiy.
\newblock Deep learning recommendation model for personalization and
  recommendation systems, 2019.

\end{thebibliography}
