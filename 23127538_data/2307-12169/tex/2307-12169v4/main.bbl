% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{gpt3}
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~Kaplan, P.~Dhariwal, A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal, A.~Herbert-Voss, G.~Krueger, T.~Henighan, R.~Child, A.~Ramesh, D.~M. Ziegler, J.~Wu, C.~Winter, C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray, B.~Chess, J.~Clark, C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and D.~Amodei, ``Language models are few-shot learners,'' 2020.

\bibitem{gpt3time}
\BIBentryALTinterwordspacing
L.~Labs, ``Openai's gpt-3 language model: A technical overview,'' 2020. [Online]. Available: \url{https://lambdalabs.com/blog/demystifying-gpt-3}
\BIBentrySTDinterwordspacing

\bibitem{openai2023gpt4}
OpenAI, ``Gpt-4 technical report,'' 2023.

\bibitem{gpt4params}
\BIBentryALTinterwordspacing
The-Decoder, ``Gpt-4 has a trillion parameters - report,'' 2023. [Online]. Available: \url{https://the-decoder.com/gpt-4-has-a-trillion-parameters/}
\BIBentrySTDinterwordspacing

\bibitem{nvlnvs}
\BIBentryALTinterwordspacing
Nvidia, ``Nvlink and nvswitch: The building blocks of advanced multi-gpu communication—within and between servers.'' 2023. [Online]. Available: \url{https://www.nvidia.com/en-us/data-center/nvlink/}
\BIBentrySTDinterwordspacing

\bibitem{mi300x}
\BIBentryALTinterwordspacing
AMD, ``Amd instinct mi300x platform,'' 2023. [Online]. Available: \url{https://www.amd.com/en/products/accelerators/instinct/mi300/platform.html}
\BIBentrySTDinterwordspacing

\bibitem{fattree}
\BIBentryALTinterwordspacing
M.~Al-Fares, A.~Loukissas, and A.~Vahdat, ``A scalable, commodity data center network architecture,'' in \emph{Proceedings of the ACM SIGCOMM 2008 Conference on Data Communication}, ser. SIGCOMM '08.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2008, p. 63–74. [Online]. Available: \url{https://doi.org/10.1145/1402958.1402967}
\BIBentrySTDinterwordspacing

\bibitem{pfc_storm}
\BIBentryALTinterwordspacing
C.~Guo, H.~Wu, Z.~Deng, G.~Soni, J.~Ye, J.~Padhye, and M.~Lipshteyn, ``Rdma over commodity ethernet at scale,'' in \emph{Proceedings of the 2016 ACM SIGCOMM Conference}, ser. SIGCOMM '16.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2016, p. 202–215. [Online]. Available: \url{https://doi.org/10.1145/2934872.2934908}
\BIBentrySTDinterwordspacing

\bibitem{rdma_azure}
\BIBentryALTinterwordspacing
W.~Bai, S.~S. Abdeen, A.~Agrawal, K.~K. Attre, P.~Bahl, A.~Bhagat, G.~Bhaskara, T.~Brokhman, L.~Cao, A.~Cheema, R.~Chow, J.~Cohen, M.~Elhaddad, V.~Ette, I.~Figlin, D.~Firestone, M.~George, I.~German, L.~Ghai, E.~Green, A.~Greenberg, M.~Gupta, R.~Haagens, M.~Hendel, R.~Howlader, N.~John, J.~Johnstone, T.~Jolly, G.~Kramer, D.~Kruse, A.~Kumar, E.~Lan, I.~Lee, A.~Levy, M.~Lipshteyn, X.~Liu, C.~Liu, G.~Lu, Y.~Lu, X.~Lu, V.~Makhervaks, U.~Malashanka, D.~A. Maltz, I.~Marinos, R.~Mehta, S.~Murthi, A.~Namdhari, A.~Ogus, J.~Padhye, M.~Pandya, D.~Phillips, A.~Power, S.~Puri, S.~Raindel, J.~Rhee, A.~Russo, M.~Sah, A.~Sheriff, C.~Sparacino, A.~Srivastava, W.~Sun, N.~Swanson, F.~Tian, L.~Tomczyk, V.~Vadlamuri, A.~Wolman, Y.~Xie, J.~Yom, L.~Yuan, Y.~Zhang, and B.~Zill, ``Empowering azure storage with {RDMA},'' in \emph{20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)}.\hskip 1em plus 0.5em minus 0.4em\relax Boston, MA: USENIX Association, Apr. 2023, pp. 49--67. [Online]. Available:
  \url{https://www.usenix.org/conference/nsdi23/presentation/bai}
\BIBentrySTDinterwordspacing

\bibitem{ib_deadlock}
T.~Schneider, O.~Bibartiu, and T.~Hoefler, ``Ensuring deadlock-freedom in low-diameter infiniband networks,'' in \emph{2016 IEEE 24th Annual Symposium on High-Performance Interconnects (HOTI)}, 2016, pp. 1--8.

\bibitem{bfc}
\BIBentryALTinterwordspacing
P.~Goyal, P.~Shah, K.~Zhao, G.~Nikolaidis, M.~Alizadeh, and T.~E. Anderson, ``Backpressure flow control,'' in \emph{19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22)}.\hskip 1em plus 0.5em minus 0.4em\relax Renton, WA: USENIX Association, Apr. 2022, pp. 779--805. [Online]. Available: \url{https://www.usenix.org/conference/nsdi22/presentation/goyal}
\BIBentrySTDinterwordspacing

\bibitem{ddlindc}
\BIBentryALTinterwordspacing
S.~Hu, Y.~Zhu, P.~Cheng, C.~Guo, K.~Tan, J.~Padhye, and K.~Chen, ``Deadlocks in datacenter networks: Why do they form, and how to avoid them,'' in \emph{Proceedings of the 15th ACM Workshop on Hot Topics in Networks}, ser. HotNets '16.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2016, p. 92–98. [Online]. Available: \url{https://doi.org/10.1145/3005745.3005760}
\BIBentrySTDinterwordspacing

\bibitem{topoopt}
\BIBentryALTinterwordspacing
W.~Wang, M.~Khazraee, Z.~Zhong, M.~Ghobadi, Z.~Jia, D.~Mudigere, Y.~Zhang, and A.~Kewitsch, ``{TopoOpt}: Co-optimizing network topology and parallelization strategy for distributed training jobs,'' in \emph{20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)}.\hskip 1em plus 0.5em minus 0.4em\relax Boston, MA: USENIX Association, Apr. 2023, pp. 739--767. [Online]. Available: \url{https://www.usenix.org/conference/nsdi23/presentation/wang-weiyang}
\BIBentrySTDinterwordspacing

\bibitem{dgxh100}
\BIBentryALTinterwordspacing
NVIDIA, ``Dgx h100 computer,'' 2023. [Online]. Available: \url{https://www.nvidia.com/en-us/data-center/dgx-h100/}
\BIBentrySTDinterwordspacing

\bibitem{gb200nvl72}
\BIBentryALTinterwordspacing
------, ``Gb200 nvl72 computer,'' 2024. [Online]. Available: \url{https://www.nvidia.com/en-us/data-center/gb200-nvl72/}
\BIBentrySTDinterwordspacing

\bibitem{gh200}
\BIBentryALTinterwordspacing
Nvidia, ``Nvidia dgx gh200,'' 2023. [Online]. Available: \url{https://www.nvidia.com/en-us/data-center/dgx-gh200/}
\BIBentrySTDinterwordspacing

\bibitem{nccl212}
\BIBentryALTinterwordspacing
------, ``Doubling all2all performance with nvidia collective communication library 2.12,'' 2022. [Online]. Available: \url{https://developer.nvidia.com/blog/doubling-all2all-performance-with-nvidia-collective-communication-library-2-12/}
\BIBentrySTDinterwordspacing

\bibitem{fbdcarch}
\BIBentryALTinterwordspacing
Meta, ``Introducing data center fabric, the next-generation facebook data center network,'' 2014. [Online]. Available: \url{https://engineering.fb.com/2014/11/14/production-engineering/introducing-data-center-fabric-the-next-generation-facebook-data-center-network/}
\BIBentrySTDinterwordspacing

\bibitem{dgxh100archdoc}
\BIBentryALTinterwordspacing
Nvidia, ``Nvidia dgx superpod: Next generation scalable infrastructure for ai leadership, reference architecture,'' 2023. [Online]. Available: \url{https://docs.nvidia.com/dgx-superpod-reference-architecture-with-dgx-h100-systems.pdf}
\BIBentrySTDinterwordspacing

\bibitem{multirail}
S.~Coll, E.~Frachtenberg, F.~Petrini, A.~Hoisie, and L.~Gurvits, ``Using multirail networks in high-performance clusters,'' in \emph{Proceedings 2001 IEEE International Conference on Cluster Computing}, 2001, pp. 15--24.

\bibitem{narayanan2021efficient}
D.~Narayanan, M.~Shoeybi, J.~Casper, P.~LeGresley, M.~Patwary, V.~A. Korthikanti, D.~Vainbrand, P.~Kashinkunti, J.~Bernauer, B.~Catanzaro, A.~Phanishayee, and M.~Zaharia, ``Efficient large-scale language model training on gpu clusters using megatron-lm,'' 2021.

\bibitem{rajbhandari2022deepspeedmoe}
S.~Rajbhandari, C.~Li, Z.~Yao, M.~Zhang, R.~Y. Aminabadi, A.~A. Awan, J.~Rasley, and Y.~He, ``Deepspeed-moe: Advancing mixture-of-experts inference and training to power next-generation ai scale,'' 2022.

\bibitem{rotornet}
\BIBentryALTinterwordspacing
W.~M. Mellette, R.~McGuinness, A.~Roy, A.~Forencich, G.~Papen, A.~C. Snoeren, and G.~Porter, ``Rotornet: A scalable, low-complexity, optical datacenter network,'' in \emph{Proceedings of the Conference of the ACM Special Interest Group on Data Communication}, ser. SIGCOMM '17.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2017, p. 267–280. [Online]. Available: \url{https://doi.org/10.1145/3098822.3098838}
\BIBentrySTDinterwordspacing

\bibitem{opera}
\BIBentryALTinterwordspacing
W.~M. Mellette, R.~Das, Y.~Guo, R.~McGuinness, A.~C. Snoeren, and G.~Porter, ``Expanding across time to deliver bandwidth efficiency and low latency,'' in \emph{17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20)}.\hskip 1em plus 0.5em minus 0.4em\relax Santa Clara, CA: USENIX Association, Feb. 2020, pp. 1--18. [Online]. Available: \url{https://www.usenix.org/conference/nsdi20/presentation/mellette}
\BIBentrySTDinterwordspacing

\bibitem{jouppi2023tpu}
N.~P. Jouppi, G.~Kurian, S.~Li, P.~Ma, R.~Nagarajan, L.~Nai, N.~Patil, S.~Subramanian, A.~Swing, B.~Towles, C.~Young, X.~Zhou, Z.~Zhou, and D.~Patterson, ``Tpu v4: An optically reconfigurable supercomputer for machine learning with hardware support for embeddings,'' 2023.

\bibitem{jupiterevolving}
\BIBentryALTinterwordspacing
L.~Poutievski, O.~Mashayekhi, J.~Ong, A.~Singh, M.~Tariq, R.~Wang, J.~Zhang, V.~Beauregard, P.~Conner, S.~Gribble, R.~Kapoor, S.~Kratzer, N.~Li, H.~Liu, K.~Nagaraj, J.~Ornstein, S.~Sawhney, R.~Urata, L.~Vicisano, K.~Yasumura, S.~Zhang, J.~Zhou, and A.~Vahdat, ``Jupiter evolving: Transforming google's datacenter network via optical circuit switches and software-defined networking,'' in \emph{Proceedings of the ACM SIGCOMM 2022 Conference}, ser. SIGCOMM '22.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2022, p. 66–85. [Online]. Available: \url{https://doi.org/10.1145/3544216.3544265}
\BIBentrySTDinterwordspacing

\bibitem{calculon}
\BIBentryALTinterwordspacing
M.~Isaev, N.~Mcdonald, L.~Dennison, and R.~Vuduc, ``Calculon: a methodology and tool for high-level co-design of systems and large language models,'' in \emph{Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, ser. SC '23.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2023. [Online]. Available: \url{https://doi.org/10.1145/3581784.3607102}
\BIBentrySTDinterwordspacing

\bibitem{korthikanti2022reducing}
V.~Korthikanti, J.~Casper, S.~Lym, L.~McAfee, M.~Andersch, M.~Shoeybi, and B.~Catanzaro, ``Reducing activation recomputation in large transformer models,'' 2022.

\bibitem{kaplan2020scaling}
J.~Kaplan, S.~McCandlish, T.~Henighan, T.~B. Brown, B.~Chess, R.~Child, S.~Gray, A.~Radford, J.~Wu, and D.~Amodei, ``Scaling laws for neural language models,'' 2020.

\bibitem{nvidia400gpower}
\BIBentryALTinterwordspacing
Nvidia, ``Nvidia docs hub: Mma4z00-ns400 400gb/s single-port osfp 400gb/s multimode sr4 50m connectivity scenarios,'' 2023. [Online]. Available: \url{https://docs.nvidia.com/networking/display/mma4z00ns400/connectivity+scenarios#:~:text=The%20400Gb%2Fs%20transceiver%20has,maximum%20or%208%20Watts%20typical.}
\BIBentrySTDinterwordspacing

\bibitem{qm7900spec}
\BIBentryALTinterwordspacing
------, ``Nvidia docs hub: Qm9700/qm9790 1u ndr 400gb/s infiniband switch systems user manual specifications,'' 2023. [Online]. Available: \url{https://docs.nvidia.com/networking/display/qm97x0pub/specifications}
\BIBentrySTDinterwordspacing

\bibitem{sirius}
\BIBentryALTinterwordspacing
H.~Ballani, P.~Costa, R.~Behrendt, D.~Cletheroe, I.~Haller, K.~Jozwik, F.~Karinou, S.~Lange, K.~Shi, B.~Thomsen, and H.~Williams, ``Sirius: A flat datacenter network with nanosecond optical switching,'' in \emph{Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication}, ser. SIGCOMM '20.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2020, p. 782–797. [Online]. Available: \url{https://doi.org/10.1145/3387514.3406221}
\BIBentrySTDinterwordspacing

\bibitem{dnnmodelgrowth}
\BIBentryALTinterwordspacing
OpenAI, ``Openai: Ai and compute,'' 2023. [Online]. Available: \url{https://openai.com/research/ai-and-compute}
\BIBentrySTDinterwordspacing

\bibitem{shoeybi2020megatronlm}
M.~Shoeybi, M.~Patwary, R.~Puri, P.~LeGresley, J.~Casper, and B.~Catanzaro, ``Megatron-lm: Training multi-billion parameter language models using model parallelism,'' 2020.

\bibitem{dolly}
\BIBentryALTinterwordspacing
Databricks, ``Hello dolly: Democratizing the magic of chatgpt with open models,'' 2023. [Online]. Available: \url{https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html}
\BIBentrySTDinterwordspacing

\bibitem{deepspeedzeropp}
\BIBentryALTinterwordspacing
Microsoft, ``Deepspeed zero++: A leap in speed for llm and chat model training with 4x less communication,'' 2023. [Online]. Available: \url{https://www.microsoft.com/en-us/research/blog/deepspeed-zero-a-leap-in-speed-for-llm-and-chat-model-training-with-4x-less-communication/}
\BIBentrySTDinterwordspacing

\bibitem{alpaserve}
\BIBentryALTinterwordspacing
Z.~Li, L.~Zheng, Y.~Zhong, V.~Liu, Y.~Sheng, X.~Jin, Y.~Huang, Z.~Chen, H.~Zhang, J.~E. Gonzalez, and I.~Stoica, ``{AlpaServe}: Statistical multiplexing with model parallelism for deep learning serving,'' in \emph{17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23)}.\hskip 1em plus 0.5em minus 0.4em\relax Boston, MA: USENIX Association, Jul. 2023. [Online]. Available: \url{https://www.usenix.org/conference/osdi23/presentation/li-zhouhan}
\BIBentrySTDinterwordspacing

\bibitem{pope2022efficiently}
R.~Pope, S.~Douglas, A.~Chowdhery, J.~Devlin, J.~Bradbury, A.~Levskaya, J.~Heek, K.~Xiao, S.~Agrawal, and J.~Dean, ``Efficiently scaling transformer inference,'' 2022.

\bibitem{gandiva}
\BIBentryALTinterwordspacing
W.~Xiao, R.~Bhardwaj, R.~Ramjee, M.~Sivathanu, N.~Kwatra, Z.~Han, P.~Patel, X.~Peng, H.~Zhao, Q.~Zhang, F.~Yang, and L.~Zhou, ``Gandiva: Introspective cluster scheduling for deep learning,'' in \emph{13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)}.\hskip 1em plus 0.5em minus 0.4em\relax Carlsbad, CA: USENIX Association, Oct. 2018, pp. 595--610. [Online]. Available: \url{https://www.usenix.org/conference/osdi18/presentation/xiao}
\BIBentrySTDinterwordspacing

\bibitem{tiresias}
\BIBentryALTinterwordspacing
J.~Gu, M.~Chowdhury, K.~G. Shin, Y.~Zhu, M.~Jeon, J.~Qian, H.~Liu, and C.~Guo, ``Tiresias: A {GPU} cluster manager for distributed deep learning,'' in \emph{16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19)}.\hskip 1em plus 0.5em minus 0.4em\relax Boston, MA: USENIX Association, Feb. 2019, pp. 485--500. [Online]. Available: \url{https://www.usenix.org/conference/nsdi19/presentation/gu}
\BIBentrySTDinterwordspacing

\bibitem{muri}
\BIBentryALTinterwordspacing
Y.~Zhao, Y.~Liu, Y.~Peng, Y.~Zhu, X.~Liu, and X.~Jin, ``Multi-resource interleaving for deep learning training,'' in \emph{Proceedings of the ACM SIGCOMM 2022 Conference}, ser. SIGCOMM '22.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2022, p. 428–440. [Online]. Available: \url{https://doi.org/10.1145/3544216.3544224}
\BIBentrySTDinterwordspacing

\bibitem{rajasekaran2023cassini}
S.~Rajasekaran, M.~Ghobadi, and A.~Akella, ``Cassini: Network-aware job scheduling in machine learning clusters,'' 2023.

\bibitem{mudigere2023softwarehardware}
D.~Mudigere, Y.~Hao, J.~Huang, Z.~Jia, A.~Tulloch, S.~Sridharan, X.~Liu, M.~Ozdal, J.~Nie, J.~Park, L.~Luo, J.~A. Yang, L.~Gao, D.~Ivchenko, A.~Basant, Y.~Hu, J.~Yang, E.~K. Ardestani, X.~Wang, R.~Komuravelli, C.-H. Chu, S.~Yilmaz, H.~Li, J.~Qian, Z.~Feng, Y.~Ma, J.~Yang, E.~Wen, H.~Li, L.~Yang, C.~Sun, W.~Zhao, D.~Melts, K.~Dhulipala, K.~Kishore, T.~Graf, A.~Eisenman, K.~K. Matam, A.~Gangidi, G.~J. Chen, M.~Krishnan, A.~Nayak, K.~Nair, B.~Muthiah, M.~khorashadi, P.~Bhattacharya, P.~Lapukhov, M.~Naumov, A.~Mathews, L.~Qiao, M.~Smelyanskiy, B.~Jia, and V.~Rao, ``Software-hardware co-design for fast and scalable training of deep learning recommendation models,'' 2023.

\bibitem{alpa}
\BIBentryALTinterwordspacing
L.~Zheng, Z.~Li, H.~Zhang, Y.~Zhuang, Z.~Chen, Y.~Huang, Y.~Wang, Y.~Xu, D.~Zhuo, E.~P. Xing, J.~E. Gonzalez, and I.~Stoica, ``Alpa: Automating inter- and {Intra-Operator} parallelism for distributed deep learning,'' in \emph{16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)}.\hskip 1em plus 0.5em minus 0.4em\relax Carlsbad, CA: USENIX Association, Jul. 2022, pp. 559--578. [Online]. Available: \url{https://www.usenix.org/conference/osdi22/presentation/zheng-lianmin}
\BIBentrySTDinterwordspacing

\bibitem{unity}
\BIBentryALTinterwordspacing
C.~Unger, Z.~Jia, W.~Wu, S.~Lin, M.~Baines, C.~E.~Q. Narvaez, V.~Ramakrishnaiah, N.~Prajapati, P.~McCormick, J.~Mohd-Yusof, X.~Luo, D.~Mudigere, J.~Park, M.~Smelyanskiy, and A.~Aiken, ``Unity: Accelerating {DNN} training through joint optimization of algebraic transformations and parallelization,'' in \emph{16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)}.\hskip 1em plus 0.5em minus 0.4em\relax Carlsbad, CA: USENIX Association, Jul. 2022, pp. 267--284. [Online]. Available: \url{https://www.usenix.org/conference/osdi22/presentation/unger}
\BIBentrySTDinterwordspacing

\bibitem{zhao2023bandwidth}
L.~Zhao and A.~Krishnamurthy, ``Bandwidth optimal pipeline schedule for collective communication,'' 2023.

\end{thebibliography}
