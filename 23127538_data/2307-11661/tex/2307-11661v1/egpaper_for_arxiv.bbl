\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{Caltech-UCSD200}
{Caltech-UCSD Birds 200}.

\bibitem{7293699}
Zeynep Akata, Florent Perronnin, Zaid Harchaoui, and Cordelia Schmid.
\newblock Label-embedding for image classification.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  38(7):1425--1438, 2016.

\bibitem{bossard2014food}
Lukas Bossard, Matthieu Guillaumin, and Luc Van~Gool.
\newblock Food-101--mining discriminative components with random forests.
\newblock In {\em ECCV}, 2014.

\bibitem{brown2020language}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
  Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
  Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
  Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter,
  Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
  Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
  Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners, 2020.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em ICML}, 2020.

\bibitem{chowdhery2022palm}
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
  Adam Roberts, Paul Barham, Hyung~Won Chung, Charles Sutton, Sebastian
  Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
  Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran,
  Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob
  Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm
  Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia,
  Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David
  Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David
  Dohan, Shivani Agrawal, Mark Omernick, Andrew~M. Dai,
  Thanumalayan~Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
  Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi
  Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,
  Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
\newblock Palm: Scaling language modeling with pathways, 2022.

\bibitem{cimpoi2014describing}
Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea
  Vedaldi.
\newblock Describing textures in the wild.
\newblock In {\em CVPR}, 2014.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{desai2021virtex}
Karan Desai and Justin Johnson.
\newblock Virtex: Learning visual representations from textual annotations.
\newblock In {\em CVPR}, 2021.

\bibitem{elhoseiny2013write}
Mohamed Elhoseiny, Babak Saleh, and Ahmed Elgammal.
\newblock Write a classifier: Zero-shot learning using purely textual
  descriptions.
\newblock In {\em ICCV}, 2013.

\bibitem{fei2004learning}
Li Fei-Fei, Rob Fergus, and Pietro Perona.
\newblock Learning generative visual models from few training examples: An
  incremental bayesian approach tested on 101 object categories.
\newblock In {\em CVPR-W}, 2004.

\bibitem{FerjadNaeemI2MVFormer:Classification}
Muhammad Ferjad~Naeem, Muhammad Gul Zain Ali~Khan, Yongqin Xian, Muhammad
  Zeshan~Afzal, Didier Stricker, Luc Van~Gool, Federico Tombari, and Eth
  Z{\"{u}}rich.
\newblock {I2MVFormer: Large Language Model Generated Multi-View Document
  Supervision for Zero-Shot Image Classification}.

\bibitem{frome2013devise}
Andrea Frome, Greg~S Corrado, Jon Shlens, Samy Bengio, Jeff Dean, Marc'Aurelio
  Ranzato, and Tomas Mikolov.
\newblock Devise: A deep visual-semantic embedding model.
\newblock {\em NeurIPS}, 2013.

\bibitem{furst2021cloob}
Andreas F{\"u}rst, Elisabeth Rumetshofer, Viet Tran, Hubert Ramsauer, Fei Tang,
  Johannes Lehner, David Kreil, Michael Kopp, G{\"u}nter Klambauer, Angela
  Bitto-Nemling, et~al.
\newblock Cloob: Modern hopfield networks with infoloob outperform clip.
\newblock {\em arXiv preprint arXiv:2110.11316}, 2021.

\bibitem{GaoCLIP-Adapter:Adapters}
Peng Gao, Shijie Geng, Renrui Zhang, Teli Ma, Rongyao Fang, Yongfeng Zhang,
  Hongsheng Li, and Yu Qiao.
\newblock {CLIP-Adapter: Better Vision-Language Models with Feature Adapters}.

\bibitem{gao2021clip}
Peng Gao, Shijie Geng, Renrui Zhang, Teli Ma, Rongyao Fang, Yongfeng Zhang,
  Hongsheng Li, and Yu Qiao.
\newblock Clip-adapter: Better vision-language models with feature adapters.
\newblock {\em arXiv preprint arXiv:2110.04544}, 2021.

\bibitem{he2020momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em CVPR}, 2020.

\bibitem{helber2019eurosat}
Patrick Helber, Benjamin Bischke, Andreas Dengel, and Damian Borth.
\newblock Eurosat: A novel dataset and deep learning benchmark for land use and
  land cover classification.
\newblock {\em IEEE Journal of Selected Topics in Applied Earth Observations
  and Remote Sensing}, 2019.

\bibitem{Jia2021ScalingSupervision}
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc~V
  Le, Yunhsuan Sung, Zhen Li, and Tom Duerig.
\newblock {Scaling Up Visual and Vision-Language Representation Learning With
  Noisy Text Supervision}.
\newblock page 139, 2021.

\bibitem{jia2021scaling}
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc~V
  Le, Yunhsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In {\em ICML}, 2021.

\bibitem{jiang2020can}
Zhengbao Jiang, Frank~F Xu, Jun Araki, and Graham Neubig.
\newblock How can we know what language models know?
\newblock {\em ACL}, 2020.

\bibitem{joulin2016learning}
Armand Joulin, Laurens Van Der~Maaten, Allan Jabri, and Nicolas Vasilache.
\newblock Learning visual features from large weakly supervised data.
\newblock In {\em ECCV}, 2016.

\bibitem{krause20133d}
Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In {\em ICCV-W}, 2013.

\bibitem{lei2015predicting}
Jimmy Lei~Ba, Kevin Swersky, Sanja Fidler, et~al.
\newblock Predicting deep zero-shot convolutional neural networks using textual
  descriptions.
\newblock In {\em ICCV}, 2015.

\bibitem{lester2021power}
Brian Lester, Rami Al-Rfou, and Noah Constant.
\newblock The power of scale for parameter-efficient prompt tuning.
\newblock {\em arXiv preprint arXiv:2104.08691}, 2021.

\bibitem{li2017learning}
Ang Li, Allan Jabri, Armand Joulin, and Laurens van~der Maaten.
\newblock Learning visual n-grams from web data.
\newblock In {\em ICCV}, 2017.

\bibitem{li2021prefix}
Xiang~Lisa Li and Percy Liang.
\newblock Prefix-tuning: Optimizing continuous prompts for generation.
\newblock {\em arXiv preprint arXiv:2101.00190}, 2021.

\bibitem{liu2021pre}
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and
  Graham Neubig.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting
  methods in natural language processing.
\newblock {\em arXiv preprint arXiv:2107.13586}, 2021.

\bibitem{maji2013fine}
Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Andrea Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock {\em arXiv preprint arXiv:1306.5151}, 2013.

\bibitem{Maniparambil2022BaseTransformers:Learning}
Mayug Maniparambil, Kevin Mcguinness, and Noel~E O'connor.
\newblock {BaseTransformers: Attention over base data-points for One Shot
  Learning}.
\newblock 2022.

\bibitem{nilsback2008automated}
Maria-Elena Nilsback and Andrew Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In {\em ICVGIP}, 2008.

\bibitem{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem{parkhi2012cats}
Omkar~M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV Jawahar.
\newblock Cats and dogs.
\newblock In {\em CVPR}, 2012.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em ICML}, 2021.

\bibitem{RadfordLearningSupervision}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock {Learning Transferable Visual Models From Natural Language
  Supervision}.

\bibitem{SchonfeldGeneralizedAutoencoders}
Edgar Sch{\"{o}}nfeld, Sayna Ebrahimi, Samarth Sinha, Trevor Darrell, and
  Zeynep Akata.
\newblock {Generalized Zero-and Few-Shot Learning via Aligned Variational
  Autoencoders}.

\bibitem{shin2020autoprompt}
Taylor Shin, Yasaman Razeghi, Robert~L Logan~IV, Eric Wallace, and Sameer
  Singh.
\newblock Autoprompt: Eliciting knowledge from language models with
  automatically generated prompts.
\newblock In {\em EMNLP}, 2020.

\bibitem{socher2013zero}
Richard Socher, Milind Ganjoo, Hamsa Sridhar, Osbert Bastani, Christopher~D
  Manning, and Andrew~Y Ng.
\newblock Zero-shot learning through cross-modal transfer.
\newblock In {\em NeurIPS}, 2013.

\bibitem{soomro2012ucf101}
Khurram Soomro, Amir~Roshan Zamir, and Mubarak Shah.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the
  wild.
\newblock {\em arXiv preprint arXiv:1212.0402}, 2012.

\bibitem{VaswaniAttentionNeed}
Ashish Vaswani, Google Brain, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
  Jones, Aidan~N Gomez, Łukasz Kaiser, and Illia Polosukhin.
\newblock {Attention Is All You Need}.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{XianZero-ShotUglyc}
Yongqin Xian, Christoph~H Lampert, Bernt Schiele, and Zeynep Akata.
\newblock {Zero-Shot Learning-A Comprehensive Evaluation of the Good, the Bad
  and the Ugly}.

\bibitem{xian2017zero}
Yongqin Xian, Bernt Schiele, and Zeynep Akata.
\newblock Zero-shot learning-the good, the bad and the ugly.
\newblock In {\em CVPR}, 2017.

\bibitem{xiao2010sun}
Jianxiong Xiao, James Hays, Krista~A Ehinger, Aude Oliva, and Antonio Torralba.
\newblock Sun database: Large-scale scene recognition from abbey to zoo.
\newblock In {\em CVPR}, 2010.

\bibitem{YuKoLA:Models}
Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao, Daniel Zhang-Li, Xin Lv, Hao
  Peng, Zijun Yao, Xiaohan Zhang, Hanming Li, Chunyang Li, Zheyuan Zhang, Yushi
  Bai, Yantao Liu, Amy Xin, Nianyi Lin, Kaifeng Yun, Linlu Gong, Jianhui Chen,
  Zhili Wu, Yunjia Qi, Weikai Li, Yong Guan, Kaisheng Zeng, Ji Qi, Hailong Jin,
  Jinxin Liu, Yu Gu, Yuan Yao, Ning Ding, Lei Hou, Zhiyuan Liu, Bin Xu, Jie
  Tang, and Juanzi Li.
\newblock {KoLA: Carefully Benchmarking World Knowledge of Large Language
  Models}.

\bibitem{ZhangTip-Adapter:Classification}
Renrui Zhang, Wei Zhang, Rongyao Fang, Peng Gao, Kunchang Li, Jifeng Dai, Yu
  Qiao, and Hongsheng Li.
\newblock {Tip-Adapter: Training-free Adaption of CLIP for Few-shot
  Classification}.

\bibitem{zhong2021factual}
Zexuan Zhong, Dan Friedman, and Danqi Chen.
\newblock Factual probing is [mask]: Learning vs. learning to recall.
\newblock In {\em NAACL}, 2021.

\bibitem{ZhouLearningModelsb}
Kaiyang Zhou, · Jingkang, Yang~· Chen, Change Loy, Ziwei Liu, Jingkang Yang,
  and Chen~Change Loy.
\newblock {Learning to Prompt for Vision-Language Models}.

\bibitem{ZhouConditionalModels}
Kaiyang Zhou, Jingkang Yang, Chen~Change Loy, and Ziwei Liu.
\newblock {Conditional Prompt Learning for Vision-Language Models}.

\bibitem{zhou2021coop}
Kaiyang Zhou, Jingkang Yang, Chen~Change Loy, and Ziwei Liu.
\newblock Learning to prompt for vision-language models.
\newblock {\em arXiv preprint arXiv:2109.01134}, 2021.

\end{thebibliography}
