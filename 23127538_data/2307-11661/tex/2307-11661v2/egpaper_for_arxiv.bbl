\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{Caltech-UCSD200}
{Caltech-UCSD Birds 200}.

\bibitem{bossard2014food}
Lukas Bossard, Matthieu Guillaumin, and Luc Van~Gool.
\newblock Food-101--mining discriminative components with random forests.
\newblock In {\em ECCV}, 2014.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 1877--1901. Curran Associates, Inc., 2020.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em ICML}, 2020.

\bibitem{chowdhery2022palm}
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
  Adam Roberts, Paul Barham, Hyung~Won Chung, Charles Sutton, Sebastian
  Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
  Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran,
  Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob
  Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm
  Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia,
  Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David
  Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David
  Dohan, Shivani Agrawal, Mark Omernick, Andrew~M. Dai,
  Thanumalayan~Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
  Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi
  Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,
  Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
\newblock Palm: Scaling language modeling with pathways, 2022.

\bibitem{cimpoi2014describing}
Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea
  Vedaldi.
\newblock Describing textures in the wild.
\newblock In {\em CVPR}, 2014.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{fei2004learning}
Li Fei-Fei, Rob Fergus, and Pietro Perona.
\newblock Learning generative visual models from few training examples: An
  incremental bayesian approach tested on 101 object categories.
\newblock In {\em CVPR-W}, 2004.

\bibitem{furst2022cloob}
Andreas F{\"u}rst, Elisabeth Rumetshofer, Johannes Lehner, Viet~T Tran, Fei
  Tang, Hubert Ramsauer, David Kreil, Michael Kopp, G{\"u}nter Klambauer,
  Angela Bitto, et~al.
\newblock Cloob: Modern hopfield networks with infoloob outperform clip.
\newblock {\em Advances in neural information processing systems},
  35:20450--20468, 2022.

\bibitem{gao2021clip}
Peng Gao, Shijie Geng, Renrui Zhang, Teli Ma, Rongyao Fang, Yongfeng Zhang,
  Hongsheng Li, and Yu Qiao.
\newblock Clip-adapter: Better vision-language models with feature adapters.
\newblock {\em arXiv preprint arXiv:2110.04544}, 2021.

\bibitem{he2020momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em CVPR}, 2020.

\bibitem{helber2019eurosat}
Patrick Helber, Benjamin Bischke, Andreas Dengel, and Damian Borth.
\newblock Eurosat: A novel dataset and deep learning benchmark for land use and
  land cover classification.
\newblock {\em IEEE Journal of Selected Topics in Applied Earth Observations
  and Remote Sensing}, 2019.

\bibitem{Jia2021ScalingSupervision}
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc~V
  Le, Yunhsuan Sung, Zhen Li, and Tom Duerig.
\newblock {Scaling Up Visual and Vision-Language Representation Learning With
  Noisy Text Supervision}.
\newblock page 139, 2021.

\bibitem{jia2021scaling}
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc~V
  Le, Yunhsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In {\em ICML}, 2021.

\bibitem{kopf2023openassistant}
Andreas K{\"o}pf, Yannic Kilcher, Dimitri von R{\"u}tte, Sotiris Anagnostidis,
  Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen~Minh Duc, Oliver
  Stanley, Rich{\'a}rd Nagyfi, et~al.
\newblock Openassistant conversations--democratizing large language model
  alignment.
\newblock {\em arXiv preprint arXiv:2304.07327}, 2023.

\bibitem{krause20133d}
Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In {\em ICCV-W}, 2013.

\bibitem{maji2013fine}
Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Andrea Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock {\em arXiv preprint arXiv:1306.5151}, 2013.

\bibitem{maniparambil2022}
Mayug Maniparambil, Kevin Mcguinness, and Noel O'connor.
\newblock {BaseTransformers: Attention over base data-points for One Shot
  Learning}.
\newblock In {\em British Machine Vision Conference 2022, BMVC 2022}, 2022.

\bibitem{menon2022visual}
Sachit Menon and Carl Vondrick.
\newblock Visual classification via description from large language models.
\newblock {\em ICLR}, 2023.

\bibitem{naeem2023i2mvformer}
Muhammad~Ferjad Naeem, Muhammad Gul Zain~Ali Khan, Yongqin Xian,
  Muhammad~Zeshan Afzal, Didier Stricker, Luc Van~Gool, and Federico Tombari.
\newblock I2mvformer: Large language model generated multi-view document
  supervision for zero-shot image classification.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15169--15179, 2023.

\bibitem{nilsback2008automated}
Maria-Elena Nilsback and Andrew Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In {\em ICVGIP}, 2008.

\bibitem{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem{parkhi2012cats}
Omkar~M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV Jawahar.
\newblock Cats and dogs.
\newblock In {\em CVPR}, 2012.

\bibitem{PrattWhatClassification}
Sarah Pratt, Rosanne Liu, and Ali Farhadi.
\newblock {What does a platypus look like? Generating customized prompts for
  zero-shot image classification}.
\newblock 2023.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International conference on machine learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{soomro2012ucf101}
Khurram Soomro, Amir~Roshan Zamir, and Mubarak Shah.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the
  wild.
\newblock {\em arXiv preprint arXiv:1212.0402}, 2012.

\bibitem{UdandaraoSuS-X:Models}
Vishaal Udandarao, Ankush Gupta~DeepMind, and Samuel Albanie.
\newblock {SuS-X: Training-Free Name-Only Transfer of Vision-Language Models}.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{wei2022chain}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc~V
  Le, Denny Zhou, et~al.
\newblock Chain-of-thought prompting elicits reasoning in large language
  models.
\newblock {\em Advances in Neural Information Processing Systems},
  35:24824--24837, 2022.

\bibitem{xian2018zero}
Yongqin Xian, Christoph~H Lampert, Bernt Schiele, and Zeynep Akata.
\newblock Zero-shot learningâ€”a comprehensive evaluation of the good, the bad
  and the ugly.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  41(9):2251--2265, 2018.

\bibitem{xiao2010sun}
Jianxiong Xiao, James Hays, Krista~A Ehinger, Aude Oliva, and Antonio Torralba.
\newblock Sun database: Large-scale scene recognition from abbey to zoo.
\newblock In {\em CVPR}, 2010.

\bibitem{YuKoLA:Models}
Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao, Daniel Zhang-Li, Xin Lv, Hao
  Peng, Zijun Yao, Xiaohan Zhang, Hanming Li, Chunyang Li, Zheyuan Zhang, Yushi
  Bai, Yantao Liu, Amy Xin, Nianyi Lin, Kaifeng Yun, Linlu Gong, Jianhui Chen,
  Zhili Wu, Yunjia Qi, Weikai Li, Yong Guan, Kaisheng Zeng, Ji Qi, Hailong Jin,
  Jinxin Liu, Yu Gu, Yuan Yao, Ning Ding, Lei Hou, Zhiyuan Liu, Bin Xu, Jie
  Tang, and Juanzi Li.
\newblock {KoLA: Carefully Benchmarking World Knowledge of Large Language
  Models}.

\bibitem{zhang2022tip}
Renrui Zhang, Wei Zhang, Rongyao Fang, Peng Gao, Kunchang Li, Jifeng Dai, Yu
  Qiao, and Hongsheng Li.
\newblock Tip-adapter: Training-free adaption of clip for few-shot
  classification.
\newblock In {\em European Conference on Computer Vision}, pages 493--510.
  Springer, 2022.

\bibitem{zhou2022conditional}
Kaiyang Zhou, Jingkang Yang, Chen~Change Loy, and Ziwei Liu.
\newblock Conditional prompt learning for vision-language models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 16816--16825, 2022.

\bibitem{zhou2022learning}
Kaiyang Zhou, Jingkang Yang, Chen~Change Loy, and Ziwei Liu.
\newblock Learning to prompt for vision-language models.
\newblock {\em International Journal of Computer Vision}, 130(9):2337--2348,
  2022.

\end{thebibliography}
