% Version 1.2 of SN LaTeX, November 2022
%
% See section 11 of the User Manual for version history 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove Numbered in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst, sn-mathphys.bst. %  
 
%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[sn-mathphys,Numbered]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{float}%
\usepackage{subcaption}%
\usepackage{bm}
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Article Title]{Understanding the Forward Process of Convolutional Neural Networks.}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Peixin} \sur{Tian}}\email{tcxtpx@mail.ustc.edu.cn}

\author[2]{\fnm{Dong} \sur{Zhang}}\email{topk@mail.ustc.edu.cn}
%\equalcont{These authors contributed equally to this work.}

\author[1]{\fnm{Qibin} \sur{Sun}}\email{qibinsun@mail.ustc.edu.cn}
%\equalcont{These authors contributed equally to this work.}

\affil*[1]{\orgdiv{Institute of Advanced Technology}, \orgname{University of Science and Technology of China}, \orgaddress{\city{Hefei}, \postcode{230026}, \state{Anhui}, \country{China}}}

\affil[2]{\orgdiv{Institute of Dataspace}, \orgname{National Science Center}, \orgaddress{\city{Hefei}, \postcode{231299}, \state{Anhui}, \country{China}}}


%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{Despite widespread adoption and application in various domains, the interpretability remains a major challenge since the inception of this field. Understanding the decision-making process of these models, the dynamic changes occurring within the model as data is processed, and the appropriate adjustments of model parameters to cater to specific requirements can be quite challenging. Consequently, the lack of confidence in deep learning models engenders a diminished level of trust, impeding both their advancement in research and practical implementation. This research paper delves into a comprehensive analysis of the rotational transformations observed in the forward process of convolutional neural networks (CNN). It elucidates the activation function as a discerning mechanism that unifies and quantizes the rotational aspects of the input data. Experiments show how this defined methodology reflects the progress network distinguish inputs based on statistical indicators, which can be comprehended or analyzed by applying structured mathematical tools. Our findings also unveil the consistency between artificial neural networks and the human brain in their data processing pattern. Since the emergence of ChatGPT, its ability to exhibit some autonomous thinking and anti-human tendencies has increased people’s concerns about the use of this technology. These discoveries empower us to quantify and intervene in the decision-making process of neural networks through the utilization of mathematical tools, thus bolstering the dependability and trustworthiness of artificial intelligence in applications.}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{Explainable artificial intelligence , Convolutional neural network}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}\label{sec1}

Artificial intelligence has made remarkable strides in domains such as computer vision, natural language processing and autonomous systems. Yet the inner workings of most AI models remain obscure and incomprehensible to humans, hindering our ability to scrutinize and evaluate their reasoning and decisions. This raises concerns about the trustworthiness, accountability, and ethics of AI systems, particularly when they are deployed in critical domains that affect human lives, property, and security. Explainable artificial intelligence (XAI) is a research field that aims to ensure that AI systems can justify their decisions \cite{gunning2021darpa, jalil2019machines}. However, the current explanations of models are inadequate, and understanding and influencing the network decision processes remain major hurdle.

XAI methods can be classified into local and global approaches. Local approaches examine how different attributes affect the model decision for a given input, while global approaches measure the importance of high-level concepts for the model prediction. Local Interpretable Model-Agnostic Explanations \cite{Lime} (LIME) is a local approach that generates a new dataset by perturbing the prediction of a complex model for a specific input and fits a simple model to the new dataset to explain the complex model locally. \citet{shap} introduced a novel approach called Shapley Additive Explanations (SHAP) for interpreting model predictions. This method determines the significance of each feature in making a specific prediction. The framework encompasses a unique set of additive feature importance measures and provides theoretical substantiation for the existence of a singular solution within this category, which encompasses a multitude of advantageous characteristics.Testing with Concept Activation Vectors \cite{TCAV} (TCAV) is a global method that defines high-level concepts (such as texture, color, shape), and calculates their activation vectors at different levels in convolutional neural networks. Thus, obtaining a concept sensitivity score, which indicates the degree of dependence of the model on these concepts \cite{gunning2021darpa, arrieta2020explainable, adadi2018peeking, dwivedi2023explainable, molnar2020interpretable}. Besides above methods, XAI has witnessed numerous inspiring endeavors such as Grad-CAM \cite{gradcam}, DeepLIFT \cite{deeplift} and Integrated Gradients \cite{ing}. Various strategies have been developed to address the issue of neural networks' lack of interpretability from a systematic standpoint \cite{exp, debug, viscnn, qi2019visualizing}, yielding encouraging outcomes. In contrast to current XAI methods, this paper aims to understand and describe the data transformations in the network, rather than just understanding the influence of a certain attribute on the model prediction.

A powerful and versatile category of neural networks, known as convolutional neural networks, has been applied to a range of domains with great success. CNNs are composed of several fundamental elements: convolutional layers, pooling layers, activation layers, normalization layers, and fully connected layers. By integrating residual structures into CNNs \cite{resnet}, they have managed to surpass the inherent depth limitations of conventional networks, leading to improved performance. CNNs continue to be widely utilized due to their exceptional ability to generalize effectively and their remarkable computational efficiency, along with other advantages \cite{cnn1, cnn2}.

Our goal was to elucidate the mechanisms of data transformation and prediction generation in a trained convolutional neural network across its various structures and levels. To accomplish this, we devise novel interpretations of some operations that under preserved the input-output relationship. We designed experiments to demonstrate their validity. On this basis, we developed methods to assess and manipulate the model output using these interpretations. 

\citet{libby2021rotational} have revealed that the brain avoids interference in memory processing by selectively rotates sensory representations. This paper investigates how artificial neural networks process data by analyzing activation functions in terms of rotation. The representation reveals the data processing within the network and shows its similarity to information processing in the brain.

We acknowledge the limitations of our method in this paper. Our analysis is restricted to two-dimensional discrete convolution and the rectified linear unit \cite{relu0, relu, relu1} (ReLU) activation function, which are widely used in CNNs, but not universal. Therefore, our conclusion may not generalize to other types of CNNs.

\section{Methods}\label{sec12}
Here we introduce a selection of methods and concepts that are employed in subsequent experiments, accompanied by comprehensive explanations.

\subsection{Two-dimensional discrete convolution}
Two-dimensional discrete convolution is the most common convolution operation in convolutional neural networks when processing images. It can be expressed as below \cite{onedcnn}: 

\begin{equation}
	H(i, j)=\sum_{m} \sum_{n} F(m, n) G(i-m, j-n)
\end{equation}

After training, the model parameters are fixed, thus each convolution operation can be seen as a linear equation, and multiple-channel convolution filters form a system of linear equations. For instance, consider a 2 $\times$ 2 convolution filter with 4 channels, $G’$, and input feature $F'$: 

\begin{equation}
\begin{array}{c}
	G^{\prime 1}=\left[\begin{array}{ll}
		k_{1}^{1} & k_{2}^{1} \\
		k_{3}^{1} & k_{4}^{1}
	\end{array}\right], \quad G^{\prime 2}=\left[\begin{array}{cc}
		k_{1}^{2} & k_{2}^{2} \\
		k_{1}^{2} & k_{1}^{2}
	\end{array}\right], \quad G^{\prime 3}=\left[\begin{array}{cc}
		k_{1}^{3} & k_{2}^{3} \\
		k_{3}^{3} & k_{4}^{3}
	\end{array}\right], \quad G^{\prime 4}=\left[\begin{array}{cc}
		k_{1}^{4} & k_{2}^{4} \\
		k_{1}^{4} & k_{1}^{4}
	\end{array}\right] \\
	F^{\prime}=\left[\begin{array}{ll}
		x_{1} & x_{2} \\
		x_{3} & x_{4}
	\end{array}\right]
\end{array}
\end{equation}
The corresponding linear equation system can be described as (ignore bias):
\begin{equation}
	\left\{\begin{matrix}
		F'*{G'}^1 =k_4^1\cdot x_1+k_3^1\cdot x_2+k_2^1\cdot x_3 + k_1^1 \cdot x_4=y^1
		\\F'*{G'}^2 =k_4^2\cdot x_1+k_3^2\cdot x_2+k_2^2\cdot x_3 + k_1^2 \cdot x_4=y^2
		\\F'*{G'}^2 =k_4^3\cdot x_1+k_3^3\cdot x_2+k_2^3\cdot x_3 + k_1^3 \cdot x_4=y^3
		\\F'*{G'}^2 =k_4^4\cdot x_1+k_3^4\cdot x_2+k_2^4\cdot x_3 + k_1^4 \cdot x_4=y^4
		
	\end{matrix}\right.
\end{equation}

Using matrix operations to express this process:

\begin{equation}
\left[\begin{array}{cccc}
	k_{4}^{1} & k_{3}^{1} & k_{2}^{1} & k_{1}^{1} \\
	k_{4}^{2} & k_{3}^{2} & k_{2}^{2} & k_{1}^{2} \\
	k_{4}^{3} & k_{3}^{3} & k_{2}^{3} & k_{1}^{3} \\
	k_{4}^{4} & k_{3}^{4} & k_{2}^{4} & k_{1}^{4}
\end{array}\right]\left[\begin{array}{l}
	x_{1} \\
	x_{2} \\
	x_{3} \\
	x_{4}
\end{array}\right]=\left[\begin{array}{c}
	y^{1} \\
	y^{2} \\
	y^{3} \\
	y^{4}
\end{array}\right]
\label{lineq}
\end{equation}
Matrix theory enables analyzing two-dimensional discrete convolution operations in the representation. In CNNs, channels commonly outnumber variables, and linear equations constrain the output differently. We measure the influence of each equation in output, select, and solve the most relevant ones, to describe data variation in the network.

\subsection{ReLU}
ReLU \cite{relu0, relu, relu1} activation function dominates the current landscape of deep convolutional neural networks. Its appeal lies in its ability to accelerate convergence and promote sparsity in deep learning models. Its calculation is simple: 

\begin{equation}
	f(x) = max(0, x)
	\label{relu}
\end{equation}

As in equation \eqref{relu}, the calculation of ReLU is simple. The activation function is mainly regarded as a kind of trigger mechanism. This discrete representation hampers analysis. Hence, this paper offers an alternative angle for analyzing ReLU. Here we show that ReLU performs a rotation of vectors in high-dimensional space. This selective rotation operation eludes a mathematical equation, but its effects on specific inputs can be assessed.

\begin{equation}
	\mathbf{R}(\left[\begin{array}{ll}
		x_1\\x_2\\\dots \\x_n\\
	\end{array}\right]) = \left[\begin{array}{ll}
		max(0, x_1)\\max(0, x_2)\\\dots \\max(0,x_n)\\
	\end{array}\right]
	\label{rotate}
\end{equation}

\begin{equation}
	\theta=\arccos{ \frac{\mathbf{v} \cdot \mathbf{v'}}{\|\mathbf{v}\|\|\mathbf{v'}\|}}
	\label{angle}
\end{equation}

As in equation \eqref{rotate}, We define this selective rotation as $\mathbf{R}(\mathbf{v})$, which shares the input and output with ReLU. $\mathbf{R}(\mathbf{v})$ rotates a spatial vector by a minimum angle to align or orthogonalized it with the positive quadrant of the coordinate system defined by the basis vectors. Its scaling factor is $\frac{k'}{k}$, where $k$ and $k’$ are the magnitudes of the original vector and the projection onto all positive subspaces, respectively. In this way, we can calculate the angle, $\theta$, between high-dimensional space vectors and analyzing its mathematical properties before and after applying activation function as equation \eqref{angle}. We will demonstrate how defining such a rotation operation can reveal important insights in the following sections.




\subsection{Fully connected (FC) layer}

We focus on the FC layers that are closest to the output here. Those that are inserted in the middle of the network for other purposes are beyond the scope of this paper.

The fully connected layer linearly transforms the data from the deep neural network and outputs the final distribution for classification tasks \cite{fc}. The layer parameters fit the network’s data set distribution globally. The network assigns each data point to the most likely category channel and the confidence score reflects the similarity of this assignment.

Consider a network that classifies its inputs into $n$ categories based on the output of its final hidden layer, which has c units. The FC layer with a $c\times n$ weight matrix that maps the hidden output to the output distribution. To do this, the network first flattens the hidden output into a $1\times c$ vector and then multiplies it by the weight matrix. The network then compares the resulting vector with each of the $n$ category-specific vectors in the FC layer, which are fixed after training, and chooses the category with the highest similarity score as the output.

Projecting the data onto a low-dimensional subspace with maximum variance in the original space by Principal Component Analysis \cite{pca} (PCA) partly retains the global spatial information of the high-dimensional distribution that shows the structure of categories instead of their similarities or differences.

%We applied principal component analysis (PCA), a linear method, to reduce the dimensionality of the FC layer parameters for different channels in models. PCA was employed for it preserves the global spatial information of high-dimensional distributions to some extent by projecting data onto a lower-dimensional subspace that maximizes variance in the original space.


\section{Results}\label{sec2}

To reveal the hidden shape of data, we first reduced its dimensions and assumed it formed a cone. Then we projected it onto different planes and looked for the sparsest clusters of points which marked the vertex of the cone. The principal axis was automatically calculated based on the vertex coordinates and the mean of the data. For clear visualization, we transform the data to a new coordinate system that has the cone’s vertex as the origin and the principal axis as the z-axis.

We conducted dimensionality reduction to the parameters of fully connected (FC) layer in models trained on the ImageNet dataset \cite{imagenet}. As illustrated in figure \ref{fig:fig1}, the parameters of the FC layers in these models do not follow a uniform distribution within the three-dimensional subspace. Instead, they exhibit a distinctive conical pattern. Interestingly, this pattern can be observed in previous studies exploring restricted Boltzmann machines \cite{hinton2006reducing}, suggesting that it is not a result of the convolutional operations.

We utilized Python 3.8.2 for data analysis and visualization, and employed the libraries sklearn \cite{scikit} (v.1.2.2), NumPy \cite{numpy} (v.1.22.3) and Matplotlib \cite{plt} (v.3.5.2). The neural network was implemented in PyTorch (v.1.11.0) framework.

% [fig cone]

%% Figure environment removed

% Figure environment removed




\textbf{Cone-shape distribution. }Figure \ref{fig:fig1} provides a comparative analysis between the distribution of FC layer parameters, which have been reduced to a three-dimensional subspace, and the standard conical surface. We utilized the ResNet \cite{resnet} series networks, renowned for their widespread usage and excellent performance. ResNet exhibits a relatively straightforward architecture, comprising fundamental components necessary for the efficacy of deep neural networks, including convolutional layers, pooling layers, normalization layers, fully connected layers, and residual connections. We employed pre-trained ResNet models obtained from two prominent providers, PyTorch \cite{pytorch_resnet} and Microsoft \cite{huggingface_microsoft}. Networks with matching depths from both providers exhibited comparable performance on the ImageNet dataset. 

Beside ResNet, we present dimensionality reduction results for VGG19 \cite{vgg} and Vision Transformer \cite{transformer, vit}, thereby showcasing the ubiquity of this phenomenon across diverse neural network architectures. The subsequent analysis will attempt to explain the emergence mechanism of the conical distribution.

To better evaluate the parameters after dimensionality reduction, we divided them into $n$ equal parts along the z-axis direction. We calculate the area of the circumscribed circle of the convex polygon formed by the projection of the points in each part on the xy-plane. The area of circumscribed circle varies with the cross-section of distribution. How the area change curve approaches the standard quadratic curve reflects the similarity between the points and conical distribution. A sufficient number of points are needed to calibrate the cross-section of data distribution. Some slices, however, were too sparse to provide reliable information.

% k=50; [4, 36]
%%%%%[fig]

% Figure environment removed



We performed experiments using models of different depths provided by Pytorch. According to the official documentation, Pytorch trained these models with relatively consistent parameters, thus minimizing the influence of specific training process. As shown in figure \ref{fig2}, the distribution after dimensionality reduction generally approached a conical with depth increasing. The aforementioned experiments do not serve as proof, but approximating the distribution as a cone can facilitate the analysis of rotations.

\textbf{Rotating cone. }When studying the cone-shaped distribution, a natural approach is to examine the distribution along the directions parallel and perpendicular to the principal axis. Through PCA, we projected the FC layers parameters onto the xz and xy planes \cite{recon}, resulting in two-dimensional projected data distributions denoted as $P_{xz}$ and $P_{xy}$, respectively.

$P_{xz}$ and $P_{xy}$ are utilized to ascertain the relative positions of points corresponding to a specific category within the overall distribution and the cross-sectional projection plane. We examine the vertical and polar coordinate of the same point under two scenarios: varying model providers with identical model architecture, and the same model provider with different model architectures. Subsequently, we perform statistical analysis to determine the relative positions of these points within the model distribution. In the case of $P_{xz}$, the cone-shaped distribution exhibits non-uniformity along its principal axis. Consequently, our analysis focuses on the relative positions of points within the complete dataset, rather than their positions within uniformly distributed intervals. As for $P_{xy}$, we transform the Cartesian coordinates into polar coordinates and rotate the coordinate system to align the first category precisely with the polar axis.
%
% [fig] pxz, pxy
% Figure environment removed

As shown in figure \ref{fig3} We partition the data within the entire dataset into two segments. The data from the same category tend to cluster together on the projection plane aligned with the principal axis, across models from various providers. On the other hand, the clustering probability decreases significantly on the projection plane perpendicular to the principal axis, indicating a more random distribution. Remarkably, models trained by PyTorch with its consistent training methodology show high consistency in both axial directions. These results suggest that neural networks perform a selective rotation operation that is related to the training process. This operation rotates data from different categories by varying angles in high-dimensional space, increasing the randomness in the projection planes orthogonal to the rotation axis.

Here we show that neural networks perform a selective rotation operation that is directly linked to the training process. This operation rotates data from different categories by varying angles in high-dimensional space, resulting in a higher degree of randomness in the projection planes perpendicular to the rotation axis. We illustrate this phenomenon using two scenarios of projecting high-dimensional data onto two-dimensional planes. In the first scenario, the distributions of $p_{xz}$ and $p_{xz}'$ are more consistent, while the similarity between $P_{xy}$ and $P_{xy}'$ is close to random. In contrast, in the second scenario, both directions show high consistency. Our findings reveal a novel aspect of neural network learning and suggest a possible way to improve their performance.

We define ReLU as a selective rotation operation as the equation \eqref{rotate}. This operation poses certain challenges to capture with a unified mathematical equation, but we can quantify each ReLU operation based on specific inputs.

\textbf{Data rotation throughout the network.} In this paper, we analysis hidden layer features from two perspectives: feature maps and channels. Since the networks’ output relies on the cross-channel information, inter-channel relationships can reflect the decision-making process better than feature maps. Different channels store distinct features extracted from the input, and that ReLU selectively rotates the hidden layer data. This rotation causes data from different channels to exhibit diverse characteristics. As a result, the cone-shaped distribution resulting from the rotation is observed among the data across channels.

% [fig] PCA
% Figure environment removed

We investigate the inter-channel parameters of the network’s hidden layers using PCA. To achieve this, we flatten the feature maps within each channel into one-dimensional vectors and apply PCA to reduce the data dimensionality across all channels. We observe a cone-shaped distribution that emerges gradually with increasing layer depth (Figure \ref{fig4}). The data exhibit a uniform distribution before passing through the activation layer, indicating that this activation function causes the cone-shaped distribution.
%

We define ReLU as a rotation operation and show how this explains the network’s data processing. The network transforms the input by channel-wise \cite{bn, bn1} operations and feature-wise \cite{layernorm} down-sampling. According to equation \eqref{lineq}, When the number of channels increases, convolution introduces conflicting information, thus reducing the number of channels can be advantageous to some extent. We analysis the high-dimensional vector angles among the dominant channels in the output of the nearest ReLU layer.

%[fig], rotate angle
% Figure environment removed

%rewrite
%[*]Figure \ref{fig5} shows the vector angles of the data points for each category along the principal axis of the cone-shaped distribution, sorted from bottom to top. ReLU processing causes a 2.**° rotation between the data points closest and furthest from the apex. This small angle reflects the variation in data rotation in the final network layer, which accumulates throughout the network. However, tracking the data rotation in the network is difficult due to variations in channel numbers and correspondences between layers. %We adopt a different approach to overcome this challenge.

\textbf{Quantize rotation.} Figure \ref{fig5} \textbf{a} shows the rotated angle of data points for each category along the principal axis of the cone-shaped distribution, sorted from bottom to top. We show that ReLU processing leads to a substantial variation in the rotational probability of class-specific data points at different locations within the cone. This variation reflects the “density” of data points across the entire distribution, which is a key factor for identifying their positions. Because rotation introduces more uncertainty perpendicular to the principal axis, assessing data points based on their distribution-wide positions is more reasonable. Our experiment reveals a way to distinguish different classes along the principal axis.

Confidence levels also influence the rotation angles. We arrange the input in ascending order based on their confidence levels and measure the rotation angles by the dominant channels in the final layer.Figure \ref{fig5}\textbf{b} shows that the vector angles after ReLU processing the rotation angle grows, so does the corresponding increase in the level of confidence. This observation implies that the model assigns more confident classifications to inputs that undergo more substantial rotations.

Data rotation reveals intrinsic characteristics of data categories. We investigated how the angle of data rotation affects its position in the distribution and the network’s confidence in its assessment. These findings suggest that data rotation can be used as a mathematical method to represent and manipulate the intrinsic characteristics of data categories.

It is challenging to track data rotation within the network due to the fluctuations in channel numbers and interlayer correspondence. The significant disparity in the count of unrotated classes highlights the network’s varied input processing at different positions within the distribution. However, the experiment solely captures the data rotation dynamics in the later stage of the model. 


%However, monitoring the data rotation in the network is challenging due to variations in channel numbers and random correspondences between layers. We use a different approach to address this challenge in the following analyses.



\textbf{Role of rotation. }We also approach the analysis of feature maps from an alternative perspective. We consider each row of a feature map as an individual point in high-dimensional space, and collectively, the feature map represents a cluster of points. This thought is commonly used in video analysis, where each frame can be regarded as a fundamental unit. We extend this method to image analysis as well. By recognizing the correlation between adjacent rows in an image, this angle enables us to effectively locate distinct parts within the image.

%[fig], feature map, data flow
% Figure environment removed

We employed the t-Distributed Stochastic Neighbor Embedding \cite{tsne} (t-SNE) technique for dimensionality reduction, aiming to preserve the intrinsic distance relationships among points in high-dimensional space. Figure \ref{fig6} presents the t-SNE visualization results for the same input data across different layers of the model. Initially, the data points exhibit distinct clusters, which gradually merge and become indistinguishable as we move towards the final layers, reflecting the process of information integration within a single feature map. This process also reveals the occurrence of rotational phenomena. Unlike a simple linear one, this selective rotation operation varies depending on the input. It involves the gradual mixing and alignment of feature maps within a channel during the rotation and transformation process.

When classifying, the model needs to distinguish the main object from the background noise. We divide the data into two parts: the object and the noise. As the model rotates and transports features, the information within a single feature map converges and becomes indistinguishable. Figure \ref{fig6} shows the dimensionality reduction results of the same input data in different layers of the model. The data points form clear clusters at first and blur at the end. We can exploit this characteristic to intervene in the model’s decision-making in the early stages.

% [table/fig] , intervene results
% Figure environment removed


\textbf{Intervene making decision.} We utilized the K-means \cite{kmeans} clustering algorithm for binary classification of the dimensionally reduced data. We then set the two classes to zero in their respective corresponding channels or feature map rows and calculated the prediction. Figure \ref{fig7}\textbf{b} shows the decision intervention results of the same input at different depths of the hidden layers in the ResNet34 model. The feature-wise method outperformed the channel-wise method. Interestingly, the success rates of both methods displayed an inverted U-shaped trend with increasing network depth. This phenomenon reflects the data's mixing and separation dynamics during the selective rotation process in the network. As the rotation progresses, the data tends to become more homogeneous within the network initially, followed by a re-clustering phenomenon that often facilitates improved classification. By integrating suitable detection and decision algorithms, effective manipulation of data decisions within the network can yield favorable outcomes.

%% [fig] , involve decision
%% Figure environment removed


Figure \ref{fig7}\textbf{a} showcases the successful rectification of the model's inaccurate predictions through channel intervention preceding the initial residual layer. Despite not aligning with the ground truth labels, the succeeding layers’ rectified outcomes generally correspond to the objects present in the images. Conversely, the feature map intervention method did not effectively address the mispredictions in this specific instances. As anticipated, our decision intervention approach based on clustering demonstrated superior performance during the initial stages of information fusion and rotation within the model.

% not segmented but are are needed to highlight.



\section{Discussion}\label{sec13}

This study aims to elucidate the image data classification process carried out by mature networks and provides a mathematical reinterpretation of this process. We employed fundamental mathematical tools yet uncovered some valuable phenomena. Specifically, the rotational distribution and the understanding of the ReLU activation function exhibit remarkable similarities, offering a potential framework for a structured restatement approach. This discovery implies a significant correspondence between artificial neural networks and the human brain in terms of information processing, which is truly remarkable. Moreover, interpreting ReLU as a form of selective rotation opens new avenues for quantifying and influencing network decision-making processes. This paper offers preliminary insights into these possibilities and anticipates further advancements in future research to make practical strides in this field.

Due to constraints in space and capabilities, the vast potential of this theory remains unexplored. This paper focuses solely the ReLU activation function and does not offer a comprehensive explanation or proof for the generation process of the observed rotational distribution. Remarkably, the observed rotational distribution is not limited to networks utilizing the ReLU activation function. This suggests that the interpretive methodology employed in this study may have broader applicability to other activation functions, albeit with increased intricacy. Furthermore, this study does not track the rotational phenomenon of data throughout the network, fails to elucidate the precise meaning of the term "density" in categories, and does not provide practical quantification and intervention approaches. We eagerly anticipate subsequent research that can make more significant contributions, freeing artificial intelligence researchers and engineers from the black-box nature of artificial neural networks. Such work would unveil the relationship between artificial and human intelligence, propelling the field forward.

\backmatter

%\bmhead{Supplementary information}
%
%If your article has accompanying supplementary file/s please state so here. 
%
%Authors reporting data from electrophoretic gels and blots should supply the full unprocessed scans for key as part of their Supplementary information. This may be requested by the editorial team/s if it is missing.
%
%Please refer to Journal-level guidance for any specific requirements.
%
%\bmhead{Acknowledgments}
%
%Acknowledgments are not compulsory. Where included they should be brief. Grant or contribution numbers may be acknowledged.
%
%Please refer to Journal-level guidance for any specific requirements.



%\begin{flushleft}%
%Editorial Policies for:
%
%\bigskip\noindent
%Springer journals and proceedings: \url{https://www.springer.com/gp/editorial-policies}
%
%\bigskip\noindent
%Nature Portfolio journals: \url{https://www.nature.com/nature-research/editorial-policies}
%
%\bigskip\noindent
%\textit{Scientific Reports}: \url{https://www.nature.com/srep/journal-policies/editorial-policies}
%
%\bigskip\noindent
%BMC journals: \url{https://www.biomedcentral.com/getpublished/editorial-policies}
%\end{flushleft}



%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\bibliography{sn-bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
