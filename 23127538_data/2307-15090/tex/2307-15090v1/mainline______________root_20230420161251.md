### abstract

自从深度学习诞生以来，其黑箱属性就一直困扰着相关的研究者们。这种属性为深度学习的研究和发展带来了非常多的困难，也为深度学习在日常生活中的应用带来了许多阻碍。因为深度神经网络的不可解释性，人们无法理解模型是如何根据输入做出决策，无法感受数据在模型内部发生了什么样的变化，同样也无法根据自己的需求对模型的参数进行调整。这很大程度上导致了对于深度学习模型的不信任，从而阻碍了深度学习的研究和应用。本论文考虑深度深度神经网络中的一类重要的网络，卷积神经网络，将卷积神经网络划分成不同的部分，并分析前向计算中数据在成熟模型内部的处理过程。在此基础上理解模型做出决策的过程，并探索可能的干涉模型决策的方法。（分析结果：本论文提出的逆预训练方法在多种模型和数据集上展现了良好的结果，揭示了神经网络的数据处理是一个对高维空间进行旋转从而分离异类数据的过程，并在此基础上提出了一种干涉神经网络决策的方法。）本文展示了一种对神经网络决策进行描述的视角，以及基于这种视角对于深度神经网络的一些常见问题的解释和预测。本文利用了简单的数学方法对深度神经网络的前向过程进行分析，从而描述深度神经网络的前向过程。这项工作的研究前景是令人激动的，ChatGPT问世以来，它表现出的一些自主思考的能力和反人类的倾向结合增加了人们对于这项技术应用的担忧。未来人们能够根据自己的目的像修改程序代码一样修改模型的参数，那么人工智能能够更好地为人们服务。

### introduction

人工智能(AI)在计算机视觉、自然语言处理和自主系统等各个领域都取得了显著的成功。然而，许多最先进的人工智能模型都非常复杂和不透明，这使得人类很难理解它们的推理和决策过程。这对人工智能系统的可信度、问责制和伦理性提出了挑战，特别是当它们应用于涉及人类生命、财产和安全的关键领域时。可解释人工智能(XAI)是一个研究领域，旨在确保人工智能系统能够向人类用户解释其基本原理和行为。

- LIME（局部可解释的模型-敏感性分析）：一种局部方法，通过在输入附近采样一些点，并用一个简单的线性模型来拟合原始模型在这些点上的输出，从而得到输入特征对预测的贡献度。

- SHAP（SHapley Additive exPlanations）：一种局部方法，通过利用博弈论中的Shapley值概念，将预测值分解为每个输入特征的贡献度，从而得到一个一致和公平的解释。
- Grad-CAM（梯度加权类激活图）：一种局部方法，通过计算输入图像中每个像素对卷积神经网络最后一层特征图上某个类别激活值的梯度，从而得到一个热力图，显示出图像中对预测最重要的区域。
- TCAV（Testing with Concept Activation Vectors）：一种全局方法，通过定义一些高层次的概念（如纹理、颜色、形状等），并计算它们在卷积神经网络中不同层次上的激活向量，从而得到一个概念敏感度分数，表示模型对这些概念的依赖程度。

但是现有的XAI方法仍然从表象出发，因此这些方法虽然尝试解释深度神经网络的决策，但实际上仍然没有办法解释决策的过程。本论文将一个深度神经网络切分成卷积层、激活函数、线性层三个主要部分，并分析数据在网络层次中流动的过程中分布的变化。本文从新颖的视角考察数据在高维空间中的分布及在此过程中激活函数起到的作用，提出了深度卷积神经网络是在对高维空间进行持续的旋转以分离不同的数据分布。在此基础上，本论文提出了一种对深度卷积神经网络决策过程进行干涉的方法。本论文提出的方法极大地扩展了深度神经网络的数学可解释性，并为人工干涉和修改神经网络的决策过程提供了参考。

### method

#### 卷积层

* 在深度卷积神经网络的计算中，最常见的卷积操作是二维离散卷积，它可以表示为公式【】。

$$
H(i, j)=\sum_{m} \sum_{n} F(m, n) G(i-m, j-n)
$$

当一个模型的训练过程结束后而参数固定下来之后，每个卷积过程就可以看做是一个多元方程，而多个通道的卷积核则构成了一个多元方程组。研究这个卷积方程组的解空间在时空维度中的变化可以指示数据在模型运算中发生的变化。以一个4通道，2$\times$2的卷积核G’为例，给定原始特征和4个通道的卷积核：
$$
{G'}^1 = \begin {bmatrix} k_1^1 & k_2^1 \\ k_3^1 & k_4^1 \\ \end {bmatrix}, \quad {G'}^2 = \begin {bmatrix} k_1^2 & k_2^2 \\ k_1^2 & k_1^2 \\ \end {bmatrix}, \quad {G'}^3 = \begin {bmatrix} k_1^3 & k_2^3 \\ k_3^3 & k_4^3 \\ \end {bmatrix}, \quad {G'}^4 = \begin {bmatrix} k_1^4 & k_2^4 \\ k_1^4 & k_1^4 \\ \end {bmatrix};\\
F' = \begin {bmatrix} x_1 & x_2 \\ x_3 & x_4 \\ \end {bmatrix}\\
$$
在忽略偏置值的情况下一次卷积运算过程对应的线性方程组可以表示为：
$$
\left\{\begin{matrix}
 F'*{G'}^1 =k_4^1\cdot x_1+k_3^1\cdot x_2+k_2^1\cdot x_3 + k_1^1 \cdot x_4=y^1
 \\F'*{G'}^2 =k_4^2\cdot x_1+k_3^2\cdot x_2+k_2^2\cdot x_3 + k_1^2 \cdot x_4=y^2
 \\F'*{G'}^2 =k_4^3\cdot x_1+k_3^3\cdot x_2+k_2^3\cdot x_3 + k_1^3 \cdot x_4=y^3
\\F'*{G'}^2 =k_4^4\cdot x_1+k_3^4\cdot x_2+k_2^4\cdot x_3 + k_1^4 \cdot x_4=y^4

\end{matrix}\right.
$$


用矩阵运算表示即为：
$$
\left[\begin{array}{ll}
k_{4}^{1} & k_{3}^{1} & k_2^1 & k^1_1\\
k_{4}^{2} & k_{3}^{2} & k_2^2 & k_1^2\\
k_{4}^{3} & k_{3}^{3} & k_2^3 & k_1^3\\
k_{4}^{4} & k_{3}^{4} & k_2^4 & k_1^4\\
\end{array}\right]
\left[\begin{array}{ll}
x_1\\x_2\\x_3\\x_4\\
\end{array}\right] = \left[\begin{array}{ll}
y^1\\y^2\\y^3\\y^4\\
\end{array}\right]
$$
通过这种表示方法，二维离散卷积操作可以利用矩阵理论进行分析。因为在通常的情况下，通道数远多于变量的个数，因此本论文简单地采用最小二乘法求解给定参数对于数据映射的能力，在本论文中称为解空间。除了解空间之外，相近的原始输入在经过卷积操作之后应该被映射到相近的位置，这种类间的映射能力在本论文中称为类空间。一个优秀的初始化参数要尽可能保证解空间与类空间的分布接近于真实分布。

* 激活函数

ReLU【】激活函数是现在深度卷积神经网络中最常用的激活函数，它因为快速收敛和诱导稀疏性等有点而在深度学习领域被广泛应用。本论文只考察ReLU激活函数在网络中的作用，因此其结论可能并不适应于使用其他激活函数的神经网络。
$$
f(x) = max(0, x)
$$
如公式【】，ReLU通过一个简单的触发装置计算。这种离散的表示方法会对分析造成困难，因此本论文通过重新定义ReLU提供了另一个分析的角度。在这篇论文中，我们定义ReLU是一种旋转空间向量的函数，其作用是将一个空间向量旋转一个最小的角度，使得旋转后的向量与所有的空间基向量标定的正方向的夹角小于或等于pi/2。经过这样重新定义之后，ReLU的计算方法与原始无异，但是我们可以计算原始向量相对于激活向量向各基向量正方向旋转的角度分量。而这样原始向量相对于激活向量的旋转就可以看做是经过多次旋转的最终结果。

* 全连接层

在一些神经网络中，其中间层架构中也会包含全连接层，但是本论文中提到的全连接层特指的是输出最终分布的全连接层。全连接层的工作是拟合深度网络处理后的数据分布，而当一个新的数据通过网络时，线性层会计算它与已知数据点的相似程度。置信度是衡量这种程度的重要指标，当经过全连接层处理之后的数据分布较为均匀时，证明当前输出没有与已有分布的一点产生较高的相似性。在这种情况下，网络没有见过当前输入数据所在类别或者对输入数据进行错判的可能性较大。

本论文利用主成分分析PCA对线性层不同通道的参数进行降维，以观察经过网络处理后的类别空间分布。考虑到模型选择的特殊性，本论文选择了多个在不同数据集上，由不同提供方训练的模型全连接层进行降维。结果显示，深度神经网络的全连接层降维到三维空间后可以近似地看做圆锥形。

