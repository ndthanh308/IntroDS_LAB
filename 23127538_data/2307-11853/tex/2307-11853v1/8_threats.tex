\vspace{-0.03in}
\section{Threats to Validity}
\label{sec:threats}

%真的彻底解决这个问题了吗，有没有引入新的问题，我们不予考虑


\noindent{\bf Threats to internal validity.} 
Internal bias and errors pose a significant risk in the dataset construction phase. %which may lead to several threats. 
The most essential threat is the exclusion of critical keywords or tokens that are important for identifying security-related commits. 
To address this issue, we propose an automated approach for learning security-related keywords. 
However, the current approach of topic models prioritizes the occurrence probabilities of words, which may lead to ignoring infrequent but essential words or tokens. Additionally, commits lacking proper documentation or commit messages are often overlooked, leading to further bias in the dataset. 


%There are \textcolor{red}{xxx} threats related to internal bias and errors. One threat is from the dataset construction phase. We propose to learn the security-related keywords automatically. Since the topic models prioritize the probabilities of occurrence, the word with less occurrence will be excluded, even if the word/token is important, which will lead to the ignorance of the commit that shares that keyword/token. Meanwhile, we neglect the commits without a commit message or have not been well-documented. To reduce this bias, we randomly selected 10\% commits from the non-security set to make sure we will not assign such commits as non-security. 

%Besides, we assume that all information from MITRE CVE is correct, which implies that the commit from the URLs provided by the MITRE CVE is its corresponding vulnerability fixes.

%Another threat may introduce bias caused by manually verifying security commits candidates. To mitigate such bias, we hire three experts and only take the commits that have a unanimous opinion.

\noindent{\bf Threats to external validity.} 
Our experiment and dataset are focused on Python commits, which may limit the generalizability of the \gnn{} to other programming languages. Also, since our dataset derives from open-source software, the data may not be applicable for identifying security-related commits in closed-source systems. However, we aim to expand the scope of our research in the future by incorporating more programming languages and diversifying our dataset to enhance the applicability of the \gnn{}.

%We build the dataset and conduct our experiment on Python commits, thus we may not generalize \gnn{} to other programming languages. In addition, our dataset is from open-source software. It might be not extensible to identify security commits from the close source system. In the future, we plan to include more programming languages and diversify our dataset.

\noindent{\bf Threats to construct validity.} 
\gnn{} is built on top of Joern~\cite{joern} to construct the code property graphs for the programs of previous and current versions; thus, \gnn{} inherits the limitations of Joern. Since Joern disregards the calling relations among multiple functions, \gnn{} cannot handle the commits that only change the function calls. Besides, Joern cannot identify the import and use operations of Python packages; thus, \gnn{} discards these edges in \cpg{} when the commits only operate packages.

%We rely on Joern~\cite{joern} to construct the code property graph of the previous commit and current commit, which imply that \gnn{} inherit the limitations from Joern. 
%One threat is that the calling relations among multiple functions are disregarded, so we cannot handle the commits only by changing the function calls. 
%Furthermore, we do not consider the relationships between the package import and the package usage. Thus, there will be no edge when commits only change the package usage, which will be discarded.

% \noindent{\bf Threats to conclusion validity.} 

% data not in the training set may lead to bias in the conclusion.