
\subsection{Neural-symbolic AI in semantic image interpretation}
In recent years, there has been significant research focus on NeSy architectures for addressing semantic image interpretation tasks \cite{Yu2021RecentAI,LTN,manigrasso2021faster,donadello2019compensating,Martone2022PROTOtypicalLT,li2021calibrating}. 
The present studies falls within the class of NeSy
techniques that seeks to incorporate symbolic information as a prior \cite{van2021modular}. Specifically, we rely on LTNs, which are modular architectures capable of incorporating FOL constraints \cite{LTN,Martone2022PROTOtypicalLT} and can be jointly trained with  neural module in an end-to-end manner \cite{manigrasso2021faster}.


In the LTN framework, the concept of  \textit{grounding} plays a crucial role in interpreting FOL within a specific subset of the domain, denoted as $\mathbb{R}^{n}$. In this approach, logical predicates and axioms are represented as vectors, which are then grounded (interpreted) as real numbers in the range [0, 1] using a technique called  \textit{Real Logic}. By employing this grounding mechanism, the LTN framework maps each term, denoted as $x$, to a vector representation in $\mathcal{G}(x) = \mathbb{R}^{n}$, while each predicate symbol, represented by $p \in \mathcal{P}$, is mapped to $\mathcal{G}\left(D(p)\right) \rightarrow [0,1]$. The concept can be illustrated by considering the frequently encountered \texttt{isOfClass} predicate in neuro-symbolic architectures, which quantifies the probability of a given term belonging to a specific class $c$ \cite{manigrasso2021faster,Martone2022PROTOtypicalLT}. The training objective is formulated by constructing a knowledge base $\mathcal{K}$ of FOL axioms, and finding the \textit{best satisfiability} (sat). %Given the aggregate truth value of the knowledge base, the loss function corresponds to $Loss = 1 - \text{sat}$ \cite{LTN}.



\subsection{Zero-shot learning}
ZSL tasks entail recognizing objects from previously unseen classes by exploiting some form of auxiliary knowledge, usually attribute-based, learned from seen classes. GZSL extends ZSL by assuming both seen and unseen classes are present at test time. Different strategies have been proposed to tackle ZSL, including embedding-based, attention mechanism-based, and generative strategies.

\textbf{Embedding-based} techniques compare semantic attributes and visual information by mapping them onto a suitable embedding space. Some methods embed images into the attribute space using an embedding function and consider semantic attributes as the common space~\cite{APN,CC-ZSL}. Other techniques have proposed to adopt the image embedding space as common space~\cite{Martone2022PROTOtypicalLT,dem,vse} to mitigate the hubness problem~\cite{Zhang2016LearningAD}. %adopting  images as a common space~\cite{dem,Martone2022PROTOtypicalLT,vse}.  
A third class of approaches~\cite{SP-AEN,EDEZSL,TCN} utilizes a shared space distinct from both image and attribute domains. To prevent overfitting to seen classes, these approaches require the use of pseudo-labeling techniques or a transductive setting~\cite{EDEZSL}, assuming that unlabeled images from unseen classes are provided during training. \textbf{Attention mechanisms} have been proposed to find the image regions that contribute the most to the categorization of a certain class and improve the embedding space~\cite{APN,CC-ZSL,Li2021AttributeModulatedGM,AREN}.



A critical aspect of embedding-based method is preventing overfitting to seen classes using, e.g., regularization \cite{APN,EDEZSL} or contrastive techniques \cite{CC-ZSL}. 
FLVN accomplishes this objective by incorporating a symbolic prior to aggregate visually and semantically similar features, while also explicitly establishing relationships between classes within the same macro class (a characteristic often implicitly addressed in alternative methodologies).

Previous approaches have used semantic class descriptions for the classification, but attributes linked to a specific class may not be consistently expressed or detectable in individual images. FLVN addresses this limitation by incorporating axioms that encode the existence of ``exceptions to the rule'' within the dataset. This aspect, which has received limited consideration in previous studies, has been experimentally shown to improve classification accuracy.


\textbf{Generative techniques}, on othe other hand, exploit auxiliary models, such as Generative Adversarial Networks (GANs), to generate artificial examples representing unseen classes by learning a conditional probability for each class~\cite{E-PGN,TGMZ,LisGAN,cycle-CLSWGAN}. Recently, feature generation models were integrated with embedding-based models in a contrastive setting~\cite{CEGZSL}. Generative methods require prior knowledge regarding unseen classes when generating training data. In contrast, the training process of FLVN relies on a subset of distinct seen classes and solely assumes knowledge of the class hierarchy at training time, so that the training can be easily extended to new unseen classes. Nonetheless, our approach is complementary to generative techniques, and could be in principle combined. 




