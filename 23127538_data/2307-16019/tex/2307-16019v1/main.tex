% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\pdfoutput=1 
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
%\usepackage[finalizecache,cachedir=minted-cache]{minted} 
\usepackage{amsmath}
\usepackage{eucal}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{bibnames}
\usepackage{breqn}
\usepackage{csquotes}
\usepackage{siunitx}
\usepackage{url}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please un the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}
%
\begin{document}
%\newcommand{\FM}[1]{\textcolor{blue}{\textsf{\textbf{FM:}~#1}}}
%
%\newcommand{\LM}[1]{\textcolor{red}{\textsf{\textbf{LM:}~#1}}}
%
\title{Fuzzy Logic Visual Network (FLVN): A neuro-symbolic approach for visual features matching }
%
\titlerunning{FLVN:  A neuro-symbolic approach for visual features matching}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%




\author{Francesco Manigrasso\inst{1}\orcidID{0000-0002-4151-8880} \and
Lia Morra\inst{1}\orcidID{0000-0003-2122-7178} \and
Fabrizio Lamberti\inst{1}\orcidID{0000-0001-7703-1372}}
%
\authorrunning{F. Manigrasso et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Politecnico di Torino, Dipartimento di Automatica e Informatica, Torino, Italy\\
\email\{francesco.manigrasso, lia.morra, fabrizio.lamberti\}@polito.it}

%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Neuro-symbolic integration aims at harnessing the power of symbolic knowledge representation combined with the learning capabilities of deep neural networks. In particular, Logic Tensor Networks (LTNs) allow to incorporate background knowledge in the form of logical axioms by grounding a first order logic language as differentiable operations between real tensors. Yet, few studies have investigated the potential benefits of this approach to improve zero-shot learning (ZSL) classification. In this study, we present the Fuzzy Logic Visual Network (FLVN) that formulates the task of learning a visual-semantic embedding space within a neuro-symbolic LTN framework. FLVN incorporates prior knowledge in the form of class hierarchies (classes and macro-classes) along with robust high-level inductive biases. The latter allow, for instance, to handle exceptions in class-level attributes, and to enforce similarity between images of the same class, preventing premature overfitting to seen classes and improving overall performance.  FLVN reaches state of the art performance on the Generalized ZSL (GZSL) benchmarks AWA2 and CUB, improving by 1.3\% and 3\%, respectively. Overall, it achieves competitive performance to recent ZSL methods with less computational overhead.
FLVN is available at
\url{https://gitlab.com/grains2/flvn}.

\keywords{Zero shot learning  \and NeuroSymbolic AI  \and Logic Tensor Networks}
\end{abstract}
%
%

\input{Chapters/new_commands}
\section{Introduction}
\input{Chapters/Introduction}

\section{Related work}
\label{sec:related}
\input{Chapters/ReleatedWork}

\section{Fuzzy Logic Visual Network}
\label{sec:flvn}
\input{Chapters/ProblemDefinition}

\section{Experimental settings}
\label{sec:Experiments}
\input{Chapters/Experiments}

\section{Results}
\label{sec:Results}
\input{Chapters/Results}

\section{Conclusions and future work}
\label{sec:Conclusion}
\input{Chapters/Conclusion}

\section*{Acknowledgements}
This study was carried out within the FAIR - Future Artificial Intelligence Research and received funding from the European Union Next-GenerationEU (PIANO NAZIONALE DI RIPRESA E RESILIENZA (PNRR) – MISSIONE 4 COMPONENTE 2, INVESTIMENTO 1.3 – D.D. 1555 11/10/2022, PE00000013). This manuscript reflects only the authors’ views and opinions, neither the European Union nor the European Commission can be considered responsible for them.

\bibliographystyle{splncs05}
\bibliography{main.bib}

\end{document}
