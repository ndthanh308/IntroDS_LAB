
@article{Yu2021RecentAI,
  title={Recent Advances in Neural-symbolic Systems: A Survey},
  author={Yu, Dongran and Yang, Bo and Liu, Dayou and Wang, Hui and Pan, Shirui},
  journal={arXiv preprint arXiv:2111.08164},
  year={2021}
}




@article{IEEEexample:article_typical,
  author        = "S. Zhang and C. Zhu and J. K. O. Sin and P. K. T. Mok",
  title         = "A Novel Ultrathin Elevated Channel Low-temperature
                  Poly-{Si} {TFT}",
  month         = nov,
  year          = "1999"
};




@incollection{LTN2,
  title={Logic Tensor Networks: Theory and Applications},
  author={Serafini, Luciano and d’Avila Garcez, Artur and Badreddine, Samy and Donadello, Ivan and Spranger, Michael and Bianchi, Federico},
  booktitle={Neuro-Symbolic Artificial Intelligence: The State of the Art},
  year={2021},
  publisher={IOS Press}
}

@article{LTN,
  title={Logic tensor networks},
  author={Badreddine, Samy and Garcez, Artur d'Avila and Serafini, Luciano and Spranger, Michael},
  journal={Artificial Intelligence},
  volume={303},
  pages={103649},
  year={2022},
  publisher={Elsevier}
}

@inbook{subsymbolic,
author = {Bianchi, Federico and Palmonari, Matteo and Hitzler, Pascal and Serafini, Luciano},
year = {2019},
month = {09},
pages = {161-170},
title = {Complementing Logical Reasoning with Sub-symbolic Commonsense},
isbn = {978-3-030-31094-3}
}





@inproceedings{LTN_first,
author = {Serafini, Luciano and Garcez, Artur},
year = {2016},
month = {11},
pages = {334-348},
title = {Learning and Reasoning with Logic Tensor Networks},
isbn = {978-3-319-49129-5}
};

@misc{fuzzylogic,
      title={Analyzing Differentiable Fuzzy Logic Operators}, 
      author={Emile van Krieken and Erman Acar and Frank van Harmelen},
      year={2020},
      eprint={2002.06100},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@INPROCEEDINGS{few1,
  author={E. G. {Miller} and N. E. {Matsakis} and P. A. {Viola}},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Learning from one example through shared densities on transforms}, 
  year={2000},
  number={}
  }
  
@article{few2,
  title={One shot learning of simple visual concepts},
  author={B. Lake and R. Salakhutdinov and J. Gross and J. Tenenbaum},
  journal={Cognitive Science},
  year={2011}
}

@inproceedings{few3,
  title={Siamese neural networks for one-shot image recognition},
  author={Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan and others},
  booktitle={ICML deep learning workshop},
  year={2015},
  organization={Lille}
}


@inproceedings{prototypical,
author = {Snell, Jake and Swersky, Kevin and Zemel, Richard},
title = {Prototypical Networks for Few-Shot Learning},
year = {2017},
isbn = {9781510860964},
booktitle = {31st International Conference on Neural Information Processing Systems},
pages = {4080--4090},
}


@inproceedings{matching,
author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
title = {Matching Networks for One Shot Learning},
year = {2016},
booktitle = {30th International Conference on Neural Information Processing Systems},
pages = {3637–3645},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}

@INPROCEEDINGS{relation,  author={F. {Sung} and Y. {Yang} and L. {Zhang} and T. {Xiang} and P. H. S. {Torr} and T. M. {Hospedales}},  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},   title={Learning to Compare: {R}elation Network for Few-Shot Learning},   year={2018},  

}

@article{Kahneman1973OnTP,
  title={On the psychology of prediction},
  author={D. Kahneman and A. Tversky},
  journal={Psychological Review},
  year={1973}

}

@book{kahneman2011thinking,
  abstract = {In this work the author, a recipient of the Nobel Prize in Economic Sciences for his seminal work in psychology that challenged the rational model of judgment and decision making, has brought together his many years of research and thinking in one book. He explains the two systems that drive the way we think. System 1 is fast, intuitive, and emotional; System 2 is slower, more deliberative, and more logical. He exposes the extraordinary capabilities, and also the faults and biases, of fast thinking, and reveals the pervasive influence of intuitive impressions on our thoughts and behavior. He reveals where we can and cannot trust our intuitions and how we can tap into the benefits of slow thinking. He offers practical and enlightening insights into how choices are made in both our business and our personal lives, and how we can use different techniques to guard against the mental glitches that often get us into trouble. This author's work has transformed cognitive psychology and launched the new fields of behavioral economics and happiness studies. In this book, he takes us on a tour of the mind and explains the two systems that drive the way we think and the way we make choices.},
  added-at = {2013-01-10T15:41:11.000+0100},
  address = {New York},
  author = {Kahneman, Daniel},
  biburl = {https://www.bibsonomy.org/bibtex/2f322864169411fd5914f3fa5488e288c/schmidt2},
  description = {Thinking, Fast and Slow: Amazon.de: Daniel Kahneman: Englische Bücher},
  interhash = {a1400a299a00de009ec8eda73e6289af},
  intrahash = {f322864169411fd5914f3fa5488e288c},
  isbn = {9780374275631 0374275637},
  keywords = {bib books psychology thinking toread},
  publisher = {Farrar, Straus and Giroux},
  refid = {706020998},
  timestamp = {2013-01-10T15:41:11.000+0100},
  title = {Thinking, fast and slow},
  url = {https://www.amazon.de/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/ref=wl_it_dp_o_pdT1_nS_nC?ie=UTF8&colid=151193SNGKJT9&coliid=I3OCESLZCVDFL7},
  year = 2011
}

@ARTICLE{awa2,
  author={Xian, Yongqin and Lampert, Christoph H. and Schiele, Bernt and Akata, Zeynep},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Zero-Shot Learning — {A} Comprehensive Evaluation of the Good, the Bad and the Ugly}, 
  year={2019},
  number={9}}
  
@article{mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  year={2010}
}

@article{fashion-mnist,
  author    = {Han Xiao and
               Kashif Rasul and
               Roland Vollgraf},
  title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning
               Algorithms},
  journal   = {CoRR},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.07747},
  archivePrefix = {arXiv},
  eprint    = {1708.07747},
  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{dem,
  author={Zhang, Li and Xiang, Tao and Gong, Shaogang},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Learning a Deep Embedding Model for Zero-Shot Learning}, 
  year={2017},
  number={}}
  
@article{hubness,
author = {Radovanovi\'{c}, Milo\v{s} and Nanopoulos, Alexandros and Ivanovi\'{c}, Mirjana},
title = {Hubs in Space: Popular Nearest Neighbors in High-Dimensional Data},
year = {2010},
issue_date = {3/1/2010},
publisher = {JMLR.org},
issn = {1532-4435},
abstract = {Different aspects of the curse of dimensionality are known to present serious challenges to various machine-learning methods and tasks. This paper explores a new aspect of the dimensionality curse, referred to as hubness, that affects the distribution of k-occurrences: the number of times a point appears among the k nearest neighbors of other points in a data set. Through theoretical and empirical analysis involving synthetic and real data sets we show that under commonly used assumptions this distribution becomes considerably skewed as dimensionality increases, causing the emergence of hubs, that is, points with very high k-occurrences which effectively represent "popular" nearest neighbors. We examine the origins of this phenomenon, showing that it is an inherent property of data distributions in high-dimensional vector space, discuss its interaction with dimensionality reduction, and explore its influence on a wide range of machine-learning tasks directly or indirectly based on measuring distances, belonging to supervised, semi-supervised, and unsupervised learning families.},
journal = {J. Mach. Learn. Res.},
month = dec,
pages = {2487–2531},
numpages = {45}
}

@article{mazzia21,
    author  = {V. Mazzia and F. Salvetti and M. Chiaberge},
    title   = {Efficient-CapsNet: Capsule Network with Self-Attention Routing},
    year    = {2021},
    journal = {arXiv:2101.12491},
    eprint  = {arXiv:2101.12491}
}

@inproceedings{Zhong2020RandomED,
  title={Random Erasing Data Augmentation},
  author={Zhun Zhong and L. Zheng and Guoliang Kang and Shaozi Li and Y. Yang},
  booktitle={AAAI},
  year={2020}
}

@INPROCEEDINGS{resnet101,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  number={}}
  
@INPROCEEDINGS{imagenet,
author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
title={ImageNet: A large-scale hierarchical image database}, 
year={2009},
number={},
pages={248-255}}
  
@article{t-sne,
  author  = {Laurens van der Maaten and Geoffrey Hinton},
  title   = {Visualizing Data using {t-SNE}},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  number  = {86},
  url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}



@inproceedings{devise,
author = {Frome, Andrea and Corrado, Greg S. and Shlens, Jonathon and Bengio, Samy and Dean, Jeffrey and Ranzato, Marc'Aurelio and Mikolov, Tomas},
title = {De{V}i{SE}: A Deep Visual-Semantic Embedding Model},
year = {2013},
abstract = {Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18\% across thousands of novel labels never seen by the visual model.},
booktitle = {26th International Conference on Neural Information Processing Systems},
pages = {2121–2129},
}

@ARTICLE{ale,
author={Akata, Zeynep and Perronnin, Florent and Harchaoui, Zaid and Schmid, Cordelia},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Label-Embedding for Image Classification}, 
year={2016},
number={7},
pages={1425-1438}}

@INPROCEEDINGS{sync,
author={Changpinyo, Soravit and Chao, Wei-Lun and Gong, Boqing and Sha, Fei},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition}, 
title={Synthesized Classifiers for Zero-Shot Learning}, 
year={2016},
number={},
pages={5327-5336}}

@INPROCEEDINGS{robustbidirectional,  author={Xing, Yun and Huang, Sheng and Huangfu, Luwen and Chen, Feiyu and Ge, Yongxin},  booktitle={IEEE International Conference on Multimedia and Expo},   title={Robust Bidirectional Generative Network For Generalized Zero-Shot Learning},   year={2020},  
number={}}

@InProceedings{gdan,
author = {Huang, He and Wang, Changhu and Yu, Philip S. and Wang, Chang-Dong},
title = {Generative Dual Adversarial Network for Generalized Zero-Shot Learning},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition},
year = {2019}
}

@InProceedings{Verma_2018_CVPR,
author = {Verma, Vinay Kumar and Arora, Gundeep and Mishra, Ashish and Rai, Piyush},
title = {Generalized Zero-Shot Learning via Synthesized Examples},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
year = {2018}
}

@InProceedings{pren,
author = {Ye, Meng and Guo, Yuhong},
title = {Progressive Ensemble Networks for Zero-Shot Recognition},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition},
year = {2019}
}

@InProceedings{vse,
author = {Zhu, Pengkai and Wang, Hanxiao and Saligrama, Venkatesh},
title = {Generalized Zero-Shot Recognition Based on Visually Semantic Embedding},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition},
year = {2019}
}

@article{nesy1,
          number = {4},
           title = {Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning},
          author = {A. Garcez and M. Gori and L. C. Lamb and L. Serafini and M. Spranger and S. N. Tran},
            year = {2019},
         journal = {Journal of Applied Logics},
             url = {https://openaccess.city.ac.uk/id/eprint/22984/},
        abstract = {Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.}
}

@inproceedings{nesy2,
  title     = {Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective},
  author    = {Lamb, Luís C. and Garcez, Artur d’Avila and Gori, Marco and Prates, Marcelo O.R. and Avelar, Pedro H.C. and Vardi, Moshe Y.},
  booktitle = {29th International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  year      = {2020},
  month     = {7},
  note      = {Survey track}
}

@inproceedings{rudin1,
  title={Deep Learning for Case-based Reasoning through Prototypes: A Neural Network that Explains its Predictions},
  author={O. Li and H. Liu and C. Chen and C. Rudin},
  booktitle={AAAI},
  year={2018}
}

@article{rudin2,
  title={This Looks Like That: Deep Learning for Interpretable Image Recognition},
  author={Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{CUB,
  title={Multiclass recognition and part localization with humans in the loop},
  author={Catherine Wah and Steve Branson and Pietro Perona and others},
  journal={International Conference on Computer Vision},
  year={2011}
}


@article{Akata2015EvaluationOO,
  title={Evaluation of output embeddings for fine-grained image classification},
  author={Zeynep Akata and Scott E. Reed and Daniel Walter and Honglak Lee and Bernt Schiele},
  journal={2015 IEEE Conference on Computer Vision and Pattern Recognition},
  year={2015}
}

@INPROCEEDINGS{aPY,  author={Farhadi, Ali and Endres, Ian and Hoiem, Derek and Forsyth, David},  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},   title={Describing objects by their attributes},   year={2009}, 
number={}}

@INPROCEEDINGS{SUN,  author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A. and Oliva, Aude and Torralba, Antonio},  booktitle={ IEEE Conference on Computer Vision and Pattern Recognition},   title={{SUN} database: Large-scale scene recognition from abbey to zoo},   year={2010}, 
number={}}


@article{goyal2020inductive,
  title={Inductive biases for deep learning of higher-level cognition},
  author={Goyal, Anirudh and Bengio, Yoshua},
  journal={arXiv preprint arXiv:2011.15091},
  year={2020}
}


@inproceedings{manigrasso2021faster,
  title={{Faster-LTN}: a neuro-symbolic, end-to-end object detection architecture},
  author={Manigrasso, Francesco and Miro, Filomeno Davide and Morra, Lia and Lamberti, Fabrizio},
  booktitle={International Conference on Artificial Neural Networks},
  year={2021},
  organization={Springer}
}



@article{marra2021statistical,
  title={From Statistical Relational to Neural Symbolic Artificial Intelligence: a Survey},
  author={Marra, Giuseppe and Duman{\v{c}}i{\'c}, Sebastijan and Manhaeve, Robin and De Raedt, Luc},
  journal={arXiv preprint arXiv:2108.11451},
  year={2021}
}

@inproceedings{de2021statistical,
  title={From Statistical Relational to Neuro-Symbolic Artificial Intelligence},
  author={De Raedt, Luc and Dumancic, Sebastijan and Manhaeve, Robin and Marra, Giuseppe},
  booktitle={29th International Joint Conference on Artificial Intelligence},

  year={2021}
}

@article{besold2017neural,
  title={Neural-symbolic learning and reasoning: A survey and interpretation},
  author={Besold, Tarek R and Garcez, Artur d'Avila and Bader, Sebastian and Bowman, Howard and Domingos, Pedro and Hitzler, Pascal and K{\"u}hnberger, Kai-Uwe and Lamb, Luis C and Lowd, Daniel and Lima, Priscila Machado Vieira and others},
  journal={arXiv preprint arXiv:1711.03902},
  year={2017}
}

@InProceedings{10.1007/978-3-642-12842-4_10,
author="Dasiopoulou, Stamatia
and Kompatsiaris, Ioannis",
editor="Konstantopoulos, Stasinos
and Perantonis, Stavros
and Karkaletsis, Vangelis
and Spyropoulos, Constantine D.
and Vouros, George",
title="Trends and Issues in Description Logics Frameworks for Image Interpretation",
booktitle="Artificial Intelligence: Theories, Models and Applications",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="61--70",
abstract="Description Logics have recently attracted significant interest as the underlying formalism for conceptual modelling in the context of high-level image interpretation. Differences in the formulation of image interpretation semantics have resulted in varying configurations with respect to the adopted modelling paradigm, the utilised form of reasoning, and the way imprecision is managed. In this paper, we examine the relevant literature, outlining the corresponding strengths and weaknesses, and argue that although coming up with a complete solution is hard to envisage any time soon, there are a number of key considerations that may serve as guidelines towards this direction.",
isbn="978-3-642-12842-4"
}


@inproceedings{donadello_semantic_image_interpretation,
author = {Donadello, Ivan and Serafini, Luciano and Garcez, Artur D'Avila},
title = {Logic Tensor Networks for Semantic Image Interpretation},
year = {2017},
isbn = {9780999241103},
abstract = {Semantic Image Interpretation (SII) is the task of extracting structured semantic descriptions from images. It is widely agreed that the combined use of visual data and background knowledge is of great importance for SII. Recently, Statistical Relational Learning (SRL) approaches have been developed for reasoning under uncertainty and learning in the presence of data and rich knowledge. Logic Tensor Networks (LTNs) are a SRL framework which integrates neural networks with first-order fuzzy logic to allow (i) efficient learning from noisy data in the presence of logical constraints, and (ii) reasoning with logical formulas describing general properties of the data. In this paper, we develop and apply LTNs to two of the main tasks of SII, namely, the classification of an image's bounding boxes and the detection of the relevant  part-of  relations between objects. To the best of our knowledge, this is the first successful application of SRL to such SII tasks. The proposed approach is evaluated on a standard image processing benchmark. Experiments show that background knowledge in the form of logical constraints can improve the performance of purely data-driven approaches, including the state-of-the-art Fast Region-based Convolutional Neural Networks (Fast R-CNN). Moreover, we show that the use of logical background knowledge adds robustness to the learning system when errors are present in the labels of the training data.},
booktitle = {26th International Joint Conference on Artificial Intelligence},
pages = {1596--1602}
}


@InProceedings{Al-Halah_2016_CVPR,
author = {Al-Halah, Ziad and Tapaswi, Makarand and Stiefelhagen, Rainer},
title = {Recovering the Missing Link: Predicting Class-Attribute Associations for Unsupervised Zero-Shot Learning},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
year = {2016}
}

@misc{jayaraman2016zero,
      title={Zero Shot Recognition with Unreliable Attributes}, 
      author={Dinesh Jayaraman and Kristen Grauman},
      year={2016},
      eprint={1409.4327},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{6248112,  author={Kankuekul, Pichai and Kawewong, Aram and Tangruamsub, Sirinart and Hasegawa, Osamu},  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},   title={Online incremental attribute-based zero-shot learning},   year={2012},    number={}}



@INPROCEEDINGS{donadello2019compensating,  author={Donadello, Ivan and Serafini, Luciano},  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)},   title={Compensating Supervision Incompleteness with Prior Knowledge in Semantic Image Interpretation},   year={2019}, 

number={}
}

@article{van2008visualizing,
  title={{Visualizing data} using t-SNE.},
  author={{Van der Maaten}, Laurens and Hinton, Geoffrey},
  journal={Journal of Machine Learning Research},
 
  number={11},
  year={2008}
}



@article{van2021modular,
  title={Modular design patterns for hybrid learning and reasoning systems: a taxonomy, patterns and use cases},
  author={van Bekkum, Michael and de Boer, Maaike and van Harmelen, Frank and Meyer-Vitali, Andr{\'e} and Teije, Annette ten},
  journal={Applied Intelligence},
  volume={51},
  number={9},
  pages={6528--6546},
  year={2021},
  publisher={Springer}
}

@inproceedings{yi2018neural,
  title={Neural-symbolic {VQA}: disentangling reasoning from vision and language understanding},
  author={Yi, Kexin and Wu, Jiajun and Gan, Chuang and Torralba, Antonio and Kohli, Pushmeet and Tenenbaum, Joshua B},
  booktitle={32nd International Conference on Neural Information Processing Systems},

  year={2018}
}

@inproceedings{vedantam2019probabilistic,
  title={Probabilistic neural symbolic models for interpretable visual question answering},
  author={Vedantam, Ramakrishna and Desai, Karan and Lee, Stefan and Rohrbach, Marcus and Batra, Dhruv and Parikh, Devi},
  booktitle={International Conference on Machine Learning},
 
  year={2019},
}

@inproceedings{li2021calibrating,
  title={Calibrating Concepts and Operations: Towards Symbolic Reasoning on Real Images},
  author={Li, Zhuowan and Stengel-Eskin, Elias and Zhang, Yixiao and Xie, Cihang and Tran, Quan Hung and Van Durme, Benjamin and Yuille, Alan},
  booktitle={IEEE/CVF International Conference on Computer Vision},

  year={2021}
}

@article{yu2021survey,
  title={A Survey on Neural-symbolic Systems},
  author={Yu, Dongran and Yang, Bo and Liu, Dayou and Wang, Hui},
  journal={arXiv preprint arXiv:2111.08164},
  year={2021}
}
@inproceedings{luo2020context,
  title={Context-aware zero-shot recognition},
  author={Luo, Ruotian and Zhang, Ning and Han, Bohyung and Yang, Linjie},
  booktitle={AAAI Conference on Artificial Intelligence},

  number={07},
 
  year={2020}
}

@article{wan2019transductive,
  title={Transductive zero-shot learning with visual structure constraint},
  author={Wan, Ziyu and Chen, Dongdong and Li, Yan and Yan, Xingguang and Zhang, Junge and others},
  journal={Advances in Neural Information Processing Systems},


  year={2019}
}





@article{Martone2022PROTOtypicalLT,
  title={{PROTOtypical} Logic Tensor Networks ({PROTO-LTN}) for Zero Shot Learning},
  author={Simone Martone and Francesco Manigrasso and Fabrizio Lamberti and Lia Morra},
  journal={2022 26th International Conference on Pattern Recognition (ICPR)},
  year={2022}

}

@article{Wagner2021NeuralSymbolicIF,
  title={Neural-Symbolic Integration for Interactive Learning and Conceptual Grounding},
  author={Benedikt Wagner and Artur S. d'Avila Garcez},
  journal={ArXiv},
  year={2021}
 
}

@inproceedings{Wagner2021NeuralSymbolicIF2,
  title={Neural-Symbolic Integration for Fairness in {AI}},
  author={Benedikt Wagner and Artur S. d'Avila Garcez},
  booktitle={AAAI Spring Symposium Combining Machine Learning with Knowledge Engineering},
  year={2021}
}

@article{Futia2020OnTI,
  title={On the Integration of Knowledge Graphs into Deep Learning Models for a More Comprehensible AI - Three Challenges for Future Research},
  author={Giuseppe Futia and Antonio Vetr{\`o}},
  journal={Inf.},
  year={2020}


}

@inproceedings{DualProgressivePrototypeNetworkg2021DualPP,
  title={Dual Progressive Prototype Network for Generalized Zero-Shot Learning},
  author={Chaoqun Wang and Shaobo Min and Xuejin Chen and Xiaoyan Sun and Houqiang Li},
  booktitle={Neural Information Processing Systems},
  year={2021}
}

@article{Lee2023AdaptiveMC,
  title={Adaptive Margin-based Contrastive Network for Generalized Zero-Shot Learning},
  author={Jeong-Cheol Lee and Athul Shibu and Dong-Gyu Lee},
  journal={2023 IEEE International Conference on Consumer Electronics (ICCE)},
  year={2023}
}

@article{Liu2021GoalOrientedGE,
  title={Goal-Oriented Gaze Estimation for Zero-Shot Learning},
  author={Yang Liu and Lei Zhou and Xiao Bai and Yifei Huang and Lin Gu and Jun Zhou and Tatsuya Harada},
  journal={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@article{APN,
  title={Attribute Prototype Network for Zero-Shot Learning},
  author={Wenjia Xu and Yongqin Xian and Jiuniu Wang and Bernt Schiele and Zeynep Akata},
  journal={ArXiv},
  year={2020}
}

@article{Yun2022AttributesLN,
  title={Attributes learning network for generalized zero-shot learning},
  author={Yu Yun and Sen Wang and Mingzheng Hou and Quanxue Gao},
  journal={Neural networks : the official journal of the International Neural Network Society},
  year={2022}}

@InProceedings{Akata_2013_CVPR,
author = {Akata, Zeynep and Perronnin, Florent and Harchaoui, Zaid and Schmid, Cordelia},
title = {Label-Embedding for Attribute-Based Classification},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2013}
}

@article{SJE,
  title={Evaluation of output embeddings for fine-grained image classification},
  author={Zeynep Akata and Scott E. Reed and Daniel Walter and Honglak Lee and Bernt Schiele},
  journal={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2014}
}

@article{LATEM,
  title={Latent Embeddings for Zero-Shot Classification},
  author={Yongqin Xian and Zeynep Akata and Gaurav Sharma and Quynh N. Nguyen and Matthias Hein and Bernt Schiele},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016}
}

@article{PSR,
  title={Preserving Semantic Relations for Zero-Shot Learning},
  author={Yashas Annadani and Soma Biswas},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2018}
}

@article{SP-AEN,
  title={Zero-Shot Visual Recognition Using Semantics-Preserving Adversarial Embedding Networks},
  author={Long Chen and Hanwang Zhang and Jun Xiao and W. Liu and Shih-Fu Chang},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2018}
}

@article{TCN,
  title={Transferable Contrastive Network for Generalized Zero-Shot Learning},
  author={Huajie Jiang and Ruiping Wang and S. Shan and Xilin Chen},
  journal={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019}
}

@article{DAZLE,
  title={Fine-Grained Generalized Zero-Shot Learning via Dense Attribute-Based Attention},
  author={Dat T. Huynh and Ehsan Elhamifar},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020}
}

@article{f-CLSWGAN,
  title={Feature Generating Networks for Zero-Shot Learning},
  author={Yongqin Xian and Tobias Lorenz and Bernt Schiele and Zeynep Akata},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2017}
}
@inproceedings{cycle-CLSWGAN,
  title={Multi-modal cycle-consistent generalized zero-shot learning},
  author={Felix, Rafael and Reid, Ian and Carneiro, Gustavo and others},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={21--37},
  year={2018}
}

@article{LisGAN,
  title={Leveraging the Invariant Side of Generative Zero-Shot Learning},
  author={Jingjing Li and Mengmeng Jing and Ke Lu and Zhengming Ding and Lei Zhu and Zi Huang},
  journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@article{E-PGN,
  title={Episode-Based Prototype Generating Network for Zero-Shot Learning},
  author={Yunlong Yu and Zhong Ji and Jungong Han and Zhongfei Zhang},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@inproceedings{TGMZ,
  title={Task Aligned Generative Meta-learning for Zero-shot Learning},
  author={Zhe Liu and Yun Li and Lina Yao and Xianzhi Wang and Guodong Long},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2021}
}

@article{CEGZSL,
  title={Contrastive Embedding for Generalized Zero-Shot Learning},
  author={Zongyan Han and Zhenyong Fu and Shuo Chen and Jian Yang},
  journal={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@article{Song2018TransductiveUE,
  title={Transductive Unbiased Embedding for Zero-Shot Learning},
  author={Jie Song and Chengchao Shen and Yezhou Yang and Yang Liu and Mingli Song},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2018}
}

@article{AREN,
  title={Attentive Region Embedding Network for Zero-Shot Learning},
  author={Guosen Xie and Li Liu and Xiaobo Jin and Fan Zhu and Zheng Zhang and Jie Qin and Yazhou Yao and Ling Shao},
  journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@article{AMGML,
  title={Attribute-modulated generative meta learning for zero-shot learning},
  author={Li, Yun and Liu, Zhe and Yao, Lina and Chang, Xiaojun},
  journal={IEEE Transactions on Multimedia},
  year={2021},
  publisher={IEEE}
}


@article{CC-ZSL,
  title={Discriminative and Robust Attribute Alignment for Zero-Shot Learning},
  author={De Cheng and Gerong Wang and Nannan Wang and Dingwen Zhang and Qiang Zhang and Xinbo Gao},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2023}
}

EDEZSL

@article{EDEZSL,
  title={Towards Effective Deep Embedding for Zero-Shot Learning},
  author={Lei Zhang and Peng Wang and Lingqiao Liu and Chunhua Shen and Wei Wei and Yanning Zhang and Anton van den Hengel},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2018}
}

@article{Zhang2016LearningAD,
  title={Learning a Deep Embedding Model for Zero-Shot Learning},
  author={Li Zhang and Tao Xiang and Shaogang Gong},
  journal={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2017}
  
}

@article{QSFL,
  title={Transductive Unbiased Embedding for Zero-Shot Learning},
  author={Jie Song and Chengchao Shen and Yezhou Yang and Yang Liu and Mingli Song},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2018}
}

@article{Zhang2018TowardsED,
  title={Towards Effective Deep Embedding for Zero-Shot Learning},
  author={Lei Zhang and Peng Wang and Lingqiao Liu and Chunhua Shen and Wei Wei and Yanning Zhang and Anton van den Hengel},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2018}
}

@article{Sikka2020ZeroShotLW,
  title={Zero-Shot Learning with Knowledge Enhanced Visual Semantic Embeddings},
  author={Karan Sikka and Jihua Huang and Andrew Silberfarb and Prateeth Nayak and Luke Rohrer and Pritish Sahu and others},
  journal={ArXiv},
  year={2020}
 
}

@article{Chen2022MSDNMS,
  title={{MSDN}: Mutually Semantic Distillation Network for Zero-Shot Learning},
  author={Shiming Chen and Ziming Hong and Guosen Xie and Wenhan Wang and Qinmu Peng and Kai Wang and others},
  journal={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{Wang2023GeneralizedZA,
  title={Generalized Zero-Shot Activity Recognition with Embedding-Based Method},
  author={Wei Wang and Qingzhong Li},
  journal={ACM Transactions on Sensor Networks},
  year={2023}
}

@article{Li2021AttributeModulatedGM,
  title={Attribute-Modulated Generative Meta Learning for Zero-Shot Classification},
  author={Yun Li and Zhe Liu and Lina Yao and Xianzhi Wang and Can Wang},
  journal={ArXiv},
  year={2021}
 
}


@article{Gao2022VisualSemanticAB,
  title={Visual-Semantic Aligned Bidirectional Network for Zero-Shot Learning},
  author={Rui Gao and Xingsong Hou and Jie Qin and Yuming Shen and Yang Long and Li Liu and Zhao Zhang and Ling Shao},
  journal={IEEE Transactions on Multimedia},
  year={2022}
}


@article{Xu2022VGSEVS,
  title={VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning},
  author={Wenjia Xu and Yongqin Xian and Jiuniu Wang and Bernt Schiele and Zeynep Akata},
  journal={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}


@article{Chen2021TransZeroAT,
  title={TransZero: Attribute-guided Transformer for Zero-Shot Learning},
  author={Shiming Chen and Ziming Hong and Yang Liu and Guosen Xie and Baigui Sun and Hao Li and Qinmu Peng and Kelvin Lu and Xinge You},
  journal={ArXiv},
  year={2021}

}

@article{Fang2021LearningAC,
  title={Learning Aligned Cross-Modal Representation for Generalized Zero-Shot Classification},
  author={Zhiyu Fang and Xiaobin Zhu and Chun Yang and Zheng Han and Jingyan Qin and Xu-Cheng Yin},
  journal={ArXiv},
  year={2021}
 
}

@article{Li2023CoGZSLFC,
  title={Co-GZSL: Feature Contrastive Optimization for Generalized Zero-Shot Learning},
  author={Qun Li and Zhuxi Zhan and Yaying Shen and Bir Bhanu},
  journal={SSRN Electronic Journal},
  year={2023}
}

@article{Su2023DualalignedFC,
  title={Dual-aligned Feature Confusion Alleviation for Generalized Zero-shot Learning},
  author={Hongzu Su and Jingjing Li and Ke Lu and Lei Zhu and Heng Tao Shen},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2023}
}

@article{Mao2018RobustDO,
  title={Robust Detection of Android UI Similarity},
  author={Jian Mao and Jingdong Bian and Hanjun Ma and Yaoqi Jia and Zhenkai Liang and Xuxian Jiang},
  journal={2018 IEEE International Conference on Communications (ICC)},
  year={2018}
}

@article{Arakelyan2020ComplexQA,
  title={Complex Query Answering with Neural Link Predictors},
  author={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},
  journal={ArXiv},
  year={2020}
 
}

@article{Tran2021LogicalBM,
  title={Logical Boltzmann Machines},
  author={S. Tran and Artur S. d'Avila Garcez},
  journal={ArXiv},
  year={2021}
}

@article{Oram2001WordNetAE,
  title={WordNet: An electronic lexical database},
  author={Peter Oram},
  journal={Applied Psycholinguistics},
  year={2001},
  volume={22},
  pages={131 - 134}
}

@misc{LTNtorch,
  author = {Tommaso Carraro},
  title = {{LTNtorch: PyTorch implementation of Logic Tensor Networks}},
  url={ https://doi.org/10.5281/zenodo.6394282},
  month = {mar},
  year = {2022},
  publisher = {Zenodo},
  version = {1.0.0}
}
