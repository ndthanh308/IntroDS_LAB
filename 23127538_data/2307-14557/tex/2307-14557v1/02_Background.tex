
\section{Background}
\label{sec:background}
In this section, we discuss the role of PMM in cryptography, describe various PMM methods, review existing strategies for accelerating PMM, and review the concept of XBA.
\subsection{PMM in Cryptography}

The RLWE problem~\cite{RLWE}, foundational to lattice-based cryptography~\cite{lattice_theory}, and specifically to HE schemes~\cite{HEStandard}, leverages polynomials over a specific ring for its operations. HE, which enables arbitrary computations on encrypted data without prior decryption, ensures secure computation in untrusted environments while preserving data privacy. The primary computational bottleneck in HE arises from the need to perform polynomial arithmetic, particularly PMM~\cite{B/FV,BGV,CKKS}. Consequently, enhancing PMM's performance with respect to latency and energy consumption becomes critical in cryptography.


\subsection{PMM}\label{sec:pmm}

\edit{Polynomial modular multiplication (PMM) is a fundamental operation in various applications, including cryptography, error correction codes, and polynomial arithmetic. It involves multiplying two polynomials and reducing the result modulo a given polynomial, resulting in a polynomial of a lower degree. By performing PMM, it becomes possible to efficiently compute large polynomial expressions while maintaining the desired modulus properties.
}

\edit{PMM can be accomplished using various methods, including the Conv1D approach and more optimized solutions like NTT as shown in Fig.~\ref{fig:pmm}(a). The Conv1D approach for PMM follows a straightforward procedure (Fig.~\ref{fig:pmm}(a)(1)). Two polynomials $A(x)$ and $B(x)$, with polynomial degree $n$ and modulo $q$,  are multiplied by summing the corresponding terms, akin to Conv1D computation with time complexity of $O(n^2)$. Then, the product undergoes modular reduction by dividing it with a modulus polynomial. The remainder is extracted polynomial long division to get the final result $P(x)$.}

\edit{NTT, alternatively, is proposed to reduce the computational complexity of PMM, particularly when the modulus polynomial satisfies specific properties, such as being irreducible and having a specific degree~\cite{NTT}. As depicted in Fig.~\ref{fig:pmm}(a)(2), the NTT approach involves transforming the polynomials into a different domain through NTT. During the NTT transformation, butterfly computations are performed by combining pairs of coefficients and multiplying them with twiddle factors, which are complex values associated with the modulus polynomial, resulting in the frequency-domain representation of the polynomial~\cite{NTT}. The process has a time complexity of $O(n\log{n})$. Then in this transformed domain, element-wise multiplication is performed, followed by the inverse NTT (INTT) to convert the result back to the original domain to obtain the final polynomial $P(x)$. Modular reduction is applied after each domain transformation.}

\edit{The computational complexity of PMM in hardware is primarily influenced by two key factors: the polynomial degree $n$, which represents the number of coefficients in a polynomial, and the bitwidth $k$ of modulo $q$, which signifies the size of these coefficients. In real-world applications, such as HE in privacy-preserving machine learning inference, these parameters can be quite substantial. For instance, the polynomial degree $n$ in these applications can range from 256 to 8192, while the bitwidth $k$  can vary from 16 bits to 64 bits \cite{GAZELLE,cheetah}. The magnitude of these degrees and bitwidths significantly intensifies the computational complexity of a single PMM, presenting a considerable challenge in the field.}

% Figure environment removed

\subsection{Related Work}

In this section, we briefly review existing efforts to accelerate PMM. As existing work primarily employs NTT-based solutions, we focus our review accordingly, discussing both traditional ASIC and FPGA solutions, as well as CIM-based accelerators.

\subsubsection{ASIC and FPGA solutions}

 Nejatollahi, H., et al.~\cite{fpga_ntt} proposed an innovative FPGA solution by designing two high-throughput systolic array polynomial multipliers, one based on NTT and the other on convolution. Their sequential NTT-based multiplier yielded a 3$\times$ speedup over the SOTA FPGA implementation of the polynomial multiplier in the NewHope-Simple key exchange mechanism on an Artix7 FPGA \cite{newhope}. 

ASIC implementations of lattice-based cryptographic protocols have also been actively studied. LEIA~\cite{leia}, a high-performance lattice encryption instruction accelerator, and Sapphire~\cite{sapphire}, a configurable processor for low-power embedded devices, both demonstrate substantial performance improvements and energy efficiency compared to prior ASIC designs.

There are also a number of works that directly accelerate HE, inherently accelerating PMM~\cite{HE_F1,craterlake,BTS,cheetah,CIM_HE_SAC}. These works, which also typically use NTT, aim to create large-scale accelerators for privacy-preserving computations. Since this paper focuses on PMM, we will not compare it to these works. It suffices to say that an efficient PMM accelerator will directly help HE implementations. 



\subsubsection{Compute-in-Memory solutions}
\edit{Previous research has introduced a variety of CIM kernels, including crossbars and general-purpose CIM. Ranjan et al.~\cite{ranjan2019x} have demonstrated that XBAs excel at performing VMM. Reis et al.~\cite{reis2018computing} have discussed the general-purpose CIM enabling Boolean logic and arithmetic operations to be executed directly within the memory.  Additionally, ongoing researches focus on exploring different underlying technologies for implementing these CIM kernels, including CMOS, ReRAM, and Ferroelectric FET (FeFET)~\cite{ni2019ferroelectric}. These technologies are actively studied due to their potential to provide higher density and lower latency/energy overhead in CIM architecture.}
Several research efforts have explored the use of CIM architectures for the acceleration of the NTT, including CryptoPIM~\cite{CryptoPIM}, MENTT~\cite{MENTT}, RMNTT~\cite{rmntt} and BPNTT~\cite{bpntt}. We compare \name against these established researches, so we concisely introduce these approaches in the following discussion.

CryptoPIM, MENTT, and BPNTT proposed efficient NTT accelerators based on general-purpose CIM kernels. CryptoPIM \cite{CryptoPIM} and MENTT \cite{MENTT}, built on ReRAM and SRAM respectively, both introduced unique mapping strategies to streamline the data flow between NTT stages, leading to significant reductions in latency, energy, and area overheads. BPNTT presented an in-SRAM architecture using bit-parallel modular multiplication, significantly improving throughput-per-watt. 

RMNTT~\cite{rmntt} proposed an NTT accelerator using ReRAM-based XBAs. RMNTT stores the modified twiddle factor matrix in the XBAs and employs a modified Montgomery reduction algorithm to perform modular reduction on the VMM results. The evaluation results in~\cite{rmntt} show that RMNTT outperforms other NTT accelerators in terms of throughput but incurs a large area overhead.



\subsection{Crossbars} \label{sec:Crossbar}
Given the competitiveness of XBA-based NTT accelerators, we consider leveraging XBAs to accelerate PMM. We briefly review the XBA basics below. 

XBA~\cite{SWIPE} is one representative CIM kernel in which every input signal is connected to every output signal through their cross-points consisting of memory elements and selectors. XBAs can efficiently implement VMM and have been widely studied for CNNs. In particular, XBA implemented with nonvolatile memory (NVM) devices such as ReRAM~\cite{wu2018methodology} have gained popularity due to their high storage density, nonvolatility, and low energy consumption. \edit{However, XBAs face challenges stemming from the underlying memory devices and circuits. In-situ memory device nonidealities, e.g., non-linearity, thermal noise, and variations, impact computed accuracy.}

Fig.~\ref{fig:crossbar}(a) illustrates a general XBA structure. For each column, we adopt the current summing model as shown in Fig.~\ref{fig:crossbar}(b). In this work, both input voltage ($V_{j}$) and memory cell states ($G_{i,j}$) assume binary values, i.e., $I_{i} = \sum_{0}^{R-1}G_{ij}V_{j}$, where $V_{j}$ and $G_{ij}$ are either 0 or 1. Binary XBAs exhibit greater robustness to device and circuit nonidealities, and offer improved scalability.

% Figure environment removed