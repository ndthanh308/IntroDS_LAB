%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{NTT vs. Conv1D} \label{sec:discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The choice of PMM algorithm is critical to achieving high performance in terms of speed, noise, and area in the context of the CIM computing paradigm as discussed in Sec.~\ref{sec:pmm}. Two commonly used methods for performing PMM are Conv1D and  NTT. Recent efforts utilizing XBAs for PMM have primarily focused on accelerating NTT-based methods~\cite{rmntt}~\cite{iedm_ntt}. However, there is no systematic comparative study of which method, Conv1D or NTT, is a better fit for leveraging XBAs to accelerate PMM. We fill this gap with an in-depth investigation below. Our study reveals three key insights which favor the Conv1D over the NTT-based approach. First,  data mapping complexity is higher when using NTT. Second, the Conv1D method potentially offers a better performance trade-off in terms of area and throughput, providing more opportunities for design scalability. Third, the noise growth is generally higher in the NTT approach than Conv1D, which can negatively impact the performance and accuracy of the system. Below, we elaborate on these insights.

\subsection{The Impact of Data Mapping to XBAs}

% Data mapping is a crucial aspect of computational-in-memory (CIM) as it significantly affects the efficiency and accuracy of the system. In previous NTT-type PMM implementations, a vector-matrix-multiplication (VMM) style mapping was required, as shown in \notes{Figure X}. This means that despite the use of NTT, the data mapping on XBA arrays still follows a VMM style, which is similar to the conventional Conv1D implementation.

To use XBAs for PMM, both NTT-based and Conv1D-based PMM approaches require converting their respective operands into matrices and performing VMM on XBAs\cite{rmntt}. In the NTT-based approach, the twiddle factor of NTT must be converted into a matrix. In the Conv1D approach, one of the polynomials is transformed into a matrix, while the other remains a vector, facilitating the execution of VMM. Data mapping to XBAs in NTT and Conv1D can be better visualized in Fig.\ref{fig:pmm}(b) and (c). The figures show that the same number of memory cells are needed for both methods; thus, NTT does not provide benefits over Conv1D in terms of the XBA area. Also, due to the butterfly computation involved in NTT, converting the twiddle factors into a matrix is significantly more complex than converting a polynomial into a matrix for Conv1D~\cite{rmntt}. 

The end-to-end computational complexity of NTT-based PMM on XBAs is actively higher than directly mapping Conv1D into XBAs. As depicted in Fig.~\ref{fig:pmm}(a), NTT-based PMM involves three main steps: NTT computation ($O(n\log n)$ complexity), element-wise multiplication ($O(n)$ complexity), and INTT computation ($O(n\log n)$ complexity). In contrast, Conv1D-based PMM has a complexity of $O(n^{2})$. However, when utilizing XBA acceleration, the complexity of Conv1D-based PMM can be reduced from $O(n^{2})$ to $O(1)$. By employing similar data mappings, NTT and Conv1D exhibit the same time complexity on XBA. Therefore, Conv1D-based PMM on XBA demonstrates a lower end-to-end complexity compared to NTT-based PMM, as it requires fewer operationsâ€”Conv1D only necessitates $O(1)$ operations, while NTT involves $O(1)$ + $O(n)$ + $O(1)$ operations.

\subsection{Performance Analysis}\label{sec:Performance_analysis}
% \notes{Table X} summarizes the area and operation requirements of Conv1D and NTT-type PolyM in XBA-type CIM applications. While NTT-type PolyM reduces the time complexity from $O(N^2)$ to $O(NlogN)$ on conventional computing platforms such as CPUs and GPUs, it does not offer significant speed or area benefits compared to the conventional Conv1D approach in XBA-type CIM implementations due to the similar data mapping resulting in similar operation requirements. Therefore, the choice between the two implementations depends on the specific requirements of the application, including the desired trade-offs between accuracy, efficiency, and complexity.

NTT-based PMM requires that the twiddle factors be stored for NTT and INTT in the XBAs~(See Fig~\ref{fig:pmm}(c)). The stored twiddle factors approach  necessitates either frequent updates to the twiddle factors stored in the XBAs or the use of additional XBAs to store all twiddle factors needed for NTT. As a result, this leads to either higher latency and energy consumption or increased area. Alternatively, Conv1D-based PMM has numerous identical values that, when stored in XBAs, can be reused repeatedly. This provides the opportunity to devise intelligent data reuse schemes (see Sec. \ref{sec:poly_mapping}), ultimately leading to more efficient and optimized solutions in terms of area and energy consumption. Therefore, Conv1D-based PMM can be a more promising method for accelerating PMM with XBAs.


\subsection{Noise}
% Noise is a significant challenge in CIM computing, especially for those built on non-volatile devices, as the device's non-idealities can cause noise in the computing output. Additionally, the noise can increase with more operations.

As discussed in Sec~\ref{sec:Crossbar}, XBAs are susceptible to accuracy degradation stemming from the intrinsic nonidealities of the memory cells, and the limitation of ADC precision. As a result, using XBAs inevitably introduces a certain amount of noise (i.e., error) in VMM results. When implemented on XBAs, Conv1D-based PMM incurs less noise than NTT-based PMM. The primary reason is that in Conv1D-based PMM, the entire computation can be completed in one step in XBAs, which helps control the magnitude of the noise. However, in NTT-based PMM, the NTT, element-wise multiplication, and INTT must be performed, which increases the noise introduced by XBAs multiplicatively (See Fig~\ref{fig:pmm}(a)). In applications such as HE, higher noise levels are not tolerable, making NTT-based XBA PMM unsuitable for such applications.

Based on the observations in this section, we believe that Conv1D-based PMM is a better approach for accelerating PMM with XBAs. We thus focus on the design and optimization of the XBA fabric to accelerate Conv1D-based PMM. 

