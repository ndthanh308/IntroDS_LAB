
\section{\name}\label{sec:design}
\eat{
% Figure environment removed}


% Figure environment removed

\edit{Design and optimization of Conv1D-based PMM on XBAs  for long polynomials must solve several key problems. These include mapping data to XBAs to efficiently  use the resources, enhancing memory utilization at the Processing Element (PE) level, and effectively implementing modular reduction strategies. We present \name for accelerating the Conv1D-based PMM and provide tailored solutions to address the aforementioned challenges.}

% \edit{In this section, we provide an overview of \name (Sec.~\ref{sec:overview}), the data mapping techniques (Sec.\ref{sec:mapping}), and details of our polynomial mapping strategies that aim to improve memory utilization  (Sec.\ref{sec:poly_mapping}). Lastly, we outline our proposed modular reduction strategies (Sec.\ref{sec:modular}) and conclude with a comprehensive breakdown of the entire computation flow of our XBA-based PMM accelerator design (Sec.~\ref{sec:flow}).}

% \name builds on the Conv1D implementation design and optimizes it for long polynomials. We first present an overview of our design approach in Sec.~\ref{sec:overview} and a detailed discussion of our novel data mapping techniques in Sec.~\ref{sec:mapping}. We then describe our PE-level optimization strategies to improve memory utilization in Sec.~\ref{sec:optim}. Lastly, we discuss our proposed modular reduction study in Sec.~\ref{sec:modular} and present the entire computation flow of our new XBA-based PMM accelerator design in Sec.~\ref{sec:flow}.


\subsection{Overview}\label{sec:overview}

The high-bitwidth long polynomials employed in cryptographic algorithms like HE propose challenges for the design of XBA-based architecture. One specific issue relates to the limited size of the XBA. For instance, an array with 128 rows and 128 columns falls short in accommodating high-bitwidth polynomials with a degree exceeding 256.

To address the challenge, \name utilizes a hierarchical approach to address computational complexity. Fig.~\ref{fig:overall} illustrates the overall structure and data mapping of \name, consisting of the tile, PEs, and XBAs. The tile (Fig.~\ref{fig:overall}(1)) contains multiple PEs, an accumulator, and a specifically designed reduction unit for modular reduction. Each PE holds one-bit weights and shares the same input. Thus, $k$ PEs can store $k$-bit polynomials from the most significant bit (MSB) to the least significant bit (LSB), working in parallel. 


The PE (Fig.~\ref{fig:overall}(2)) is composed of multiple XBAs working on different parts of the polynomials simultaneously, as well as an adder tree and a shifter. The XBAs (Fig.~\ref{fig:overall}(3)) are used for coefficient multiplication, while the adder tree and shifter within each PE accumulate partial results from each XBA and perform shift-add operations. 


\subsection{Bit Mapping}\label{sec:mapping}
% Description of the new XBA data mapping for high-bitwidth data
% Reduction of fine-grained shift-add operations

The high bitwidth and large polynomial degree required for cryptographic applications need a large number of shift-add operations, which may not be efficiently supported in a CIM architecture. Due to the limited precision of a memory cell in an XBA, we need to map the bits of weight into multiple memory cells. Fig.~\ref{fig:mapping}(a) illustrates the conventional approach for mapping the high bitwidth weight to multiple XBAs. All bits of weight are stored in multiple columns of the XBA. When input arrives at the XBA, each column conducts a multiplication operation. Immediately following this, shift-adders carry out the shift-add operations after the XBA computation. This XBA-level shift-add operation requires lots of shift-adders and is expensive in terms of both time and energy. 

As such, in this work, we propose a new bit mapping (BM) technique that groups the same bit of all weights together, as shown in Fig.~\ref{fig:mapping}(b). For example, in the case of 4x4 2-bit weights distributed among 2 PEs (4 XBAs per PE), each PE process one bit of each weight. After all PEs process one input bit, the shift operation is performed at the PE level, thereby avoiding a costly array-level shift-add operation. Comparing the conventional mapping (Fig.~\ref{fig:mapping}(a)) and the bit mapping (Fig.~\ref{fig:mapping}(b)) in the example, the number of shift-adders is reduced from 8 to 2. 


% Figure environment removed



As will be seen, this bit mapping strategy can significantly improve both the area and speed for processing high-bitwidth polynomial-based workloads in XBAs. In addition to its benefits for shift operations, the BM technique also simplifies the design of the PE. Since each PE handles a bit of each polynomial, the data patterns are captured at the polynomial coefficient level. We can simultaneously perform mapping optimization for all PEs. Thus, this technique can be easily extended to accommodate polynomials with different degrees or bitwidths, making it a flexible solution for performing polynomial operations in XBAs.


\eat{
% Figure environment removed
}



\subsection{Polynomial Mapping}\label{sec:poly_mapping}


In our PMM approach (utilizing VMM in XBAs), we first map polynomials into matrices to facilitate computation. Each polynomial is converted into a matrix by horizontally shifting the coefficients of the polynomial across each row, with any remaining gaps filled with zeros. This procedure results in a matrix structure that supports the critical shift-add operations intrinsic to PMM. 

Mapping the matrices into XBAs in our PMM approach using VMM is straightforward. However, in an effort to further optimize this mapping scheme, we noted that for any given polynomial degree $n$ and XBA row length $x$, there is a consistent pattern of repeated XBAs. Specifically, in every instance, we require $n/x$ identical XBAs to represent the polynomial matrix.

This aspect of our design stands in contrast with NTT-based XBA designs~\cite{rmntt}, which often find themselves confined to specific polynomial parameter settings. As such, \name offers a significant increase in flexibility. For example, consider two application scenarios for privacy-preserving machine learning (PPML) inference as shown in~\cite{GAZELLE}. On server-side inference, where performance is prioritized, and energy or area constraints are less critical, \name can leverage a larger count of XBAs for high-throughput PMM in HE of PPML. For edge-device inference, where area and energy efficiency are paramount, \name can efficiently handle a variety of large polynomial degrees and bitwidths with a smaller number of XBAs. A detailed study of the scalability of our design, referred to as \name, is provided in Sec. \ref{sec:memory_utilized}.




\subsection{Modular Reduction}\label{sec:modular}
Modular reduction is a crucial step in PMM, which ensures that the resulting polynomial remains within a specified degree and coefficient bounds. The essential steps in the reduction process include selecting an appropriate modulus for the ring and performing the modulo operation on the degree and coefficients of the resulting polynomial.

In \name, we utilize a variant of the Barrett reduction~\cite{Barrett} technique for efficient modular reduction. This method is known for its effectiveness in cryptographic applications and modular arithmetic, as it can compute the remainder of a division operation without performing the division itself. Notably, to minimize computation overhead in reduction, we strategically pre-compute specific parameters. This strategy transforms the complex, time-consuming multiplication and division operations into  shift operations, effectively reducing computation time and optimizing the overall reduction process.





\subsection{Computation Flow}\label{sec:flow}

Assuming polynomial $A$ is mapped onto XBAs in \name, PMM can be accomplished as follows. (1) \textbf{Input processing}: We begin by bit-slicing each element in the new polynomial B, separating it into its individual bits. (2) \textbf{PE computation:} Within each PE, different arrays handle distinct sections of the polynomial and perform multiplications with corresponding sections of the input. The results are then summed and shifted at the PE level. This bit-by-bit input process continues until all input bits have been addressed. (3) \textbf{Tile accumulation:} Afterward, the results from all PEs are accumulated at the tile level, and the partial results obtained from each PE are combined. (4) \textbf{Tile reduction:} Finally, a tile-level reduction operation is applied for efficient modular reduction. 

We also prioritize maximizing throughput in our design by incorporating a three-stage pipeline into the \name workflow to enhance the PMM process. This pipeline, which encompasses the PE computation, tile accumulation, and tile reduction stages, enables efficient synchronization and overlapping operations. 