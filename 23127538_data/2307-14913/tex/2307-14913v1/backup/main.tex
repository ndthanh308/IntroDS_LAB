\documentclass{cup-pan}
\usepackage{blindtext}

\title{PAN23 Multi Author Writing Style Analysis}

\author[1]{Author One}
\author[2]{Author Two}
\author[3]{Author Three}
\author[2]{Author Four}

\affil[1]{Department One, Institution One, Address One. Email: \url{abc@example.edu}}
\affil[2]{Department Two, Institution Two, Address Two.}
\affil[3]{Department Three, Institution Three, Address Three.}

%% Corresponding author
\corrauthor{Author One}

%% Abbreviated author list for the running footer
\runningauthor{One et al.}

\addbibresource{refs.bib}

\begin{document}

\maketitle

\begin{abstract}
To Do

\keywords{To, Do.}
\end{abstract}
\section{Task}
% Figure environment removed


\begin{table}[h]
\caption{Number of pairs documents in sets.}
\label{tab:dataset-v2}
\centering
\begin{tabular}{l c c}
\headrow \thead{Difficulty} & \thead{TRAIN} & \thead{VALIDATION}\\
Easy &   4200 & 900\\
Medium & 4200 & 900\\
Hard & 4200 & 900\\

\end{tabular}
\end{table}

\begin{table}[h]
\caption{Number of pairs for each label. Left one is the number of the 0s and the right one is the number of the 1s.}
\label{tab:dataset-v2}
\centering
\begin{tabular}{l c c}
\headrow \thead{Difficulty} & \thead{TRAIN} & \thead{VALIDATION}\\
Easy &   1557 - 11347 & 377- 2451\\
Medium & 15001 - 13215 & 4013 - 3029\\
Hard & 10092 - 9021 & 2159 - 1953\\

\end{tabular}

\end{table}

\begin{table}[h]
\caption{Number of pairs for each label. Left one is the number of the 0s and the right one is the number of the 1s.}
\label{tab:dataset-analysis}
\centering
\begin{tabular}{l c c c c c c}
\headrow &\thead{1 Auth} & \thead{2 Auth} & \thead{3 Auth} & \thead{4 Auth} & \thead{5 Auth} & \thead{6+ Auth} \\
0 - 9 par.&0&950&1091&1105&655&374\\
10 - 19 par.&0&0&0&0&0&24\\
20 - 29 par.&0&0&0&1&0&0\\
30 - 39 par.&0&0&0&0&0&0\\
40 - 49 par.&0&0&0&0&0&0\\

\end{tabular}

\end{table}


Participants are asked to solve the the intrinsic style change detection task. For a given text, we find all positions of writing style change on the paragraph-level. There are three difficulty levels:
\subsection{Easy}
The paragraphs of a document consist of various number of topics.
\subsection{Medium}
The topical variety is small. Need of the style detection instead of topic detection increases. 
\subsection{Hard}
All paragraphs in a documents are on the same topic. 

\section{To Do.}


\begin{table}[h]
\caption{Weighted F1 Scores, with different seeds}
\label{tab:example}
\centering
\begin{tabular}{l l l l}
\headrow \thead{model - seed} & \thead{Easy} & \thead{Medium} & \thead{Hard} \\
bert-base-cased - 1000 &  0.977 &  0.795 &  0.362 \\
bert-base-cased - 2000 &  0.992 &  0.810 &  0.362 \\
bert-base-cased - 3000 &  0.983 &  0.791 &  0.717 \\
bert-base-cased - 4000 &  0.974 &  0.785 &  0.742 \\
bert-base-cased - 5000 &  0.991 &  \textbf{0.811} &  0.751 \\

roberta-base - 1000 &  0.990 &  0.657 &  0.362 \\
roberta-base - 2000 &  0.805 &  0.660 &  0.362 \\
roberta-base - 3000 &  0.978 &  0.413 &  0.362 \\
roberta-base - 4000 &  0.791 &  0.413 &  0.362 \\
roberta-base - 5000 &  0.906 &  0.413 &  0.362 \\
deberta-base - 1000 &  0.805 &  0.671 &  0.362 \\
deberta-base - 2000 &  0.805 &  0.761 &  0.508 \\
deberta-base - 3000 &  0.986 &  0.681 &  0.362\\
deberta-base - 4000 &  0.988 &  0.414 &  0.525\\
deberta-base - 5000 &  0.985 &  0.579 &  0.362\\
albert-base-v2 - 1000 &  0.989 & 0.413  & 0.362 \\
albert-base-v2 - 2000 &  0.986 & 0.413  & 0.362 \\
albert-base-v2 - 3000 &  0.992 & 0.760  & 0.362 \\
albert-base-v2 - 4000 &  0.986 & 0.683  & 0.362 \\
albert-base-v2 - 5000 &  0.990 & 0.413  & 0.362 \\
longformer-base-4096 - 5000 & 0.987  & 0.413 & 0.362\\
bigbert-roberta-base - 5000 & \textbf{0.993}  & 0.446 & 0.362\\
bigbert-roberta-base-warmup - 5000 & 0.988  & 0.808 & 0.761\\
bigbert-roberta-base-warmup-trunc - 5000 & 0.988  & 0.808 & \textbf{0.773}\\
roberta-base-warmup & 0.876 & 0.808 & 0.362\\
deberta-base-warmup-1024 - 5000 & ? & 0.789 & 0.614\\
mpnet-warmup - 5000 & ? & 0.414 & 0.362\\
bert-base-cased-trunc - 5000 &  0.982 &  0.739 & 0.362 \\
roberta-base-trunc - 5000 &  0.992 &  0.697 &  0.362 \\
deberta-base-trunc - 5000 &  0.805 &  0.784 &  0.362\\
albert-base-v2-trunc - 5000 &  0.970 & 0.690 & 0.362 \\
electra-base-trunc - 5000 &  0.989 & 0.788 & 0.362 \\
best-bert-3-ensemble-majority & 0.986 & 0.730 & 0.740 \\
best-bert-3-ensemble-softmaxmean & 0.986 & 0.728 & 0.747 \\
\hline
random & 0.589 & 0.501 & 0.498\\
tfidf+svc & 0.825 & 0.621 & 0.531\\

\end{tabular}

\end{table}



\begin{table}[h]
\caption{Official Macro F1 Scores, with different seeds}
\label{tab:example-2}
\centering
\begin{tabular}{l l l l}
\headrow \thead{model} & \thead{Easy} & \thead{Medium} & \thead{Hard} \\
random & 0.401 & 0.504 & 0.505 \\
tfidf & 0.551 & 0.615 & 0.531\\
\hline
bert-base & 0.980 & \textbf{0.807} & 0.753 \\
roberta-base & 0.790 & 0.363 & 0.344 \\
deberta-v3 & 0.966 & 0.591 & 0.344 \\
bigbird-roberta-base & 0.965 & 0.400 & 0.344 \\
\hline
bert-base-warmup & 0.982 & 0.786 & 0.755\\
roberta-base-warmup & 0.662 & 0.766 & 0.643\\
deberta-v3-warmup & ? & 0.753 & 0.560\\
bigbird-roberta-base-warmup & 0.971 & 0.805 & 0.700\\
\hline
bert-base-transition & 0.918 & 0.766 & 0.344 \\
roberta-base-transition & 0.976 & 0.363 & 0.344 \\
deberta-v3-transition & 0.464 & 0.778 & 0.344 \\
bigbird-roberta-base-transition & 0.969 & 0.796 & 0.724\\
\hline
bert-base-warmup-transition & 0.958 & 0.772 & 0.660\\
roberta-base-warmup-transition & \textbf{0.981} & 0.804 & 0.344 \\
deberta-v3-warmup-transition & ? & ? & ? \\
bigbird-roberta-base-warmup-transition & 0.958 & 0.804 & \textbf{0.759}\\

\end{tabular}

\end{table}

In Table \ref{tab:example}, task becomes \begin{equation}
    [CLS] text1 [SEP] text2 [SEP]
\end{equation}
    
 classification. 1 for style change from text1 to text2. 0 otherwise. Models are trained with 5 random initialization using 5 different seeds. Total sequence length 512. Truncate longest. Pad to maxlength.

 In -trunc models, First paragraph's last 256 tokens are concatenated to the second paragraph's first 256 tokens with the same format.


In Tf-idf + svc model, features are extracted using tfidf vectorizer and number of words, punctuation etc. are added to the feature map. The feature vectors of the two texts are concatenated and fitted to the SVC.



In Table \ref{tab:example-2}, the f1 scores of the 5 models which will be used in ensemble method can be seen. Stratified 5-fold ensemble method is used.
%\blinddocument

%\bigskip



\printbibliography
\end{document}