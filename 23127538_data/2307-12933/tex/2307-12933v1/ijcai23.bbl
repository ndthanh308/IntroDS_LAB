\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Botev \bgroup \em et al.\egroup }{2013}]{cem}
Zdravko~I Botev, Dirk~P Kroese, Reuven~Y Rubinstein, and Pierre Lâ€™Ecuyer.
\newblock The cross-entropy method for optimization.
\newblock In {\em Handbook of statistics}, volume~31, pages 35--59. Elsevier,
  2013.

\bibitem[\protect\citeauthoryear{Buckman \bgroup \em et al.\egroup
  }{2018}]{steve}
Jacob Buckman, Danijar Hafner, George Tucker, Eugene Brevdo, and Honglak Lee.
\newblock Sample-efficient reinforcement learning with stochastic ensemble
  value expansion.
\newblock In {\em Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pages 8234--8244, 2018.

\bibitem[\protect\citeauthoryear{Chua \bgroup \em et al.\egroup }{2018}]{pets}
Kurtland Chua, Roberto Calandra, Rowan McAllister, and Sergey Levine.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[\protect\citeauthoryear{Clavera \bgroup \em et al.\egroup
  }{2020}]{maac}
Ignasi Clavera, Yao Fu, and Pieter Abbeel.
\newblock Model-augmented actor-critic: Backpropagating through paths.
\newblock In {\em 8th International Conference on Learning Representations},
  2020.

\bibitem[\protect\citeauthoryear{Ebert \bgroup \em et al.\egroup
  }{2018}]{VisualForesight}
Frederik Ebert, Chelsea Finn, Sudeep Dasari, Annie Xie, Alex~X. Lee, and Sergey
  Levine.
\newblock Visual foresight: Model-based deep reinforcement learning for
  vision-based robotic control.
\newblock {\em CoRR}, abs/1812.00568, 2018.

\bibitem[\protect\citeauthoryear{Feinberg \bgroup \em et al.\egroup
  }{2018}]{mve}
Vladimir Feinberg, Alvin Wan, Ion Stoica, Michael~I. Jordan, Joseph~E.
  Gonzalez, and Sergey Levine.
\newblock Model-based value estimation for efficient model-free reinforcement
  learning.
\newblock {\em CoRR}, abs/1803.00101, 2018.

\bibitem[\protect\citeauthoryear{Fujimoto \bgroup \em et al.\egroup
  }{2018}]{td3}
Scott Fujimoto, Herke Hoof, and David Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In {\em International Conference on Machine Learning}, pages
  1587--1596. PMLR, 2018.

\bibitem[\protect\citeauthoryear{Haarnoja \bgroup \em et al.\egroup
  }{2018}]{sac}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In {\em International conference on machine learning}, pages
  1861--1870. PMLR, 2018.

\bibitem[\protect\citeauthoryear{Heess \bgroup \em et al.\egroup }{2015}]{svg}
Nicolas Heess, Gregory Wayne, David Silver, Timothy Lillicrap, Tom Erez, and
  Yuval Tassa.
\newblock Learning continuous control policies by stochastic value gradients.
\newblock {\em Advances in Neural Information Processing Systems},
  28:2944--2952, 2015.

\bibitem[\protect\citeauthoryear{Hu \bgroup \em et al.\egroup }{2021}]{gem}
Hao Hu, Jianing Ye, Guangxiang Zhu, Zhizhou Ren, and Chongjie Zhang.
\newblock Generalizable episodic memory for deep reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  4380--4390. PMLR, 2021.

\bibitem[\protect\citeauthoryear{Janner \bgroup \em et al.\egroup
  }{2019}]{mbpo}
Michael Janner, Justin Fu, Marvin Zhang, and Sergey Levine.
\newblock When to trust your model: Model-based policy optimization.
\newblock {\em Advances in Neural Information Processing Systems},
  32:12519--12530, 2019.

\bibitem[\protect\citeauthoryear{Jia \bgroup \em et al.\egroup }{2021}]{emc-ac}
Ruonan Jia, Qingming Li, Wenzhen Huang, Junge Zhang, and Xiu Li.
\newblock Consistency regularization for ensemble model based reinforcement
  learning.
\newblock In {\em Trends in Artificial Intelligence: 18th Pacific Rim
  International Conference on Artificial Intelligence, Proceedings, Part III
  18}, pages 3--16. Springer, 2021.

\bibitem[\protect\citeauthoryear{Kurutach \bgroup \em et al.\egroup
  }{2018}]{me-trpo}
Thanard Kurutach, Ignasi Clavera, Yan Duan, Aviv Tamar, and Pieter Abbeel.
\newblock Model-ensemble trust-region policy optimization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem[\protect\citeauthoryear{Levine and Abbeel}{2014}]{gps}
Sergey Levine and Pieter Abbeel.
\newblock Learning neural network policies with guided policy search under
  unknown dynamics.
\newblock In {\em NIPS}, volume~27, pages 1071--1079. Citeseer, 2014.

\bibitem[\protect\citeauthoryear{Levine and Koltun}{2013}]{gps2}
Sergey Levine and Vladlen Koltun.
\newblock Guided policy search.
\newblock In {\em International conference on machine learning}, pages 1--9.
  PMLR, 2013.

\bibitem[\protect\citeauthoryear{Lillicrap \bgroup \em et al.\egroup
  }{2016}]{ddpg}
Timothy~P Lillicrap, Jonathan~J Hunt, Alexander Pritzel, Nicolas Heess, Tom
  Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock In {\em ICLR (Poster)}, 2016.

\bibitem[\protect\citeauthoryear{Luo \bgroup \em et al.\egroup }{2019}]{slbo}
Yuping Luo, Huazhe Xu, Yuanzhi Li, Yuandong Tian, Trevor Darrell, and Tengyu
  Ma.
\newblock Algorithmic framework for model-based deep reinforcement learning
  with theoretical guarantees.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem[\protect\citeauthoryear{Mnih \bgroup \em et al.\egroup }{2013}]{dqn}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[\protect\citeauthoryear{Pan \bgroup \em et al.\egroup }{2020}]{m2ac}
Feiyang Pan, Jia He, Dandan Tu, and Qing He.
\newblock Trust the model when it is confident: Masked model-based
  actor-critic.
\newblock {\em Advances in neural information processing systems},
  33:10537--10546, 2020.

\bibitem[\protect\citeauthoryear{Rybkin \bgroup \em et al.\egroup
  }{2021}]{latco}
Oleh Rybkin, Chuning Zhu, Anusha Nagabandi, Kostas Daniilidis, Igor Mordatch,
  and Sergey Levine.
\newblock Model-based reinforcement learning via latent-space collocation.
\newblock In {\em International Conference on Machine Learning}, pages
  9190--9201. PMLR, 2021.

\bibitem[\protect\citeauthoryear{Schulman \bgroup \em et al.\egroup
  }{2017}]{ppo}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[\protect\citeauthoryear{Tassa \bgroup \em et al.\egroup }{2012}]{mpc}
Yuval Tassa, Tom Erez, and Emanuel Todorov.
\newblock Synthesis and stabilization of complex behaviors through online
  trajectory optimization.
\newblock In {\em 2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pages 4906--4913. IEEE, 2012.

\bibitem[\protect\citeauthoryear{Todorov \bgroup \em et al.\egroup
  }{2012}]{mujoco}
Emanuel Todorov, Tom Erez, and Yuval Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In {\em 2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pages 5026--5033. IEEE, 2012.

\bibitem[\protect\citeauthoryear{Voelcker \bgroup \em et al.\egroup
  }{2022}]{vagram}
Claas~A Voelcker, Victor Liao, Animesh Garg, and Amir-massoud Farahmand.
\newblock Value gradient weighted model-based reinforcement learning.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem[\protect\citeauthoryear{Wang and Ba}{2019}]{poplin}
Tingwu Wang and Jimmy Ba.
\newblock Exploring model-based planning with policy networks.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem[\protect\citeauthoryear{Wang \bgroup \em et al.\egroup }{2023}]{pdml}
Xiyao Wang, Wichayaporn Wongkamjan, Ruonan Jia, and Furong Huang.
\newblock Live in the moment: Learning dynamics model adapted to evolving
  policy.
\newblock In {\em Proceedings of the 40th International Conference on Machine
  Learning}, volume 202 of {\em Proceedings of Machine Learning Research},
  pages 36470--36493. PMLR, 23--29 Jul 2023.

\bibitem[\protect\citeauthoryear{Zhang \bgroup \em et al.\egroup
  }{2022}]{gobigger}
Ming Zhang, Shenghan Zhang, Zhenjie Yang, Lekai Chen, Jinliang Zheng, Chao
  Yang, Chuming Li, Hang Zhou, Yazhe Niu, and Yu~Liu.
\newblock Gobigger: A scalable platform for cooperative-competitive multi-agent
  interactive simulation.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2022.

\bibitem[\protect\citeauthoryear{Zhou \bgroup \em et al.\egroup }{2022}]{taec}
Tong Zhou, Letian Wang, Ruobing Chen, Wenshuo Wang, and Yu~Liu.
\newblock Accelerating reinforcement learning for autonomous driving using
  task-agnostic and ego-centric motion skills.
\newblock {\em arXiv preprint arXiv:2209.12072}, 2022.

\end{thebibliography}
