To evaluate the applicability of QLSTMs and DisCoCat to sentiment analysis in finance, we employ both approaches as specified in Sec.~\ref{sec:methodology} on the generated datasets using an 80/10/10 train/validation/test split and employing the binary cross entropy loss. As displayed in Fig.~\ref{fig:eval:qlstm-training}, the classical and the QLSTM are capable of learning the data in merely 20 epochs with validation accuracies over 80\%, hence showing very promising performance. For the moderate complexity dataset, much longer training times appear to be necessary, especially for the QLSTM, where it takes about 100 epochs before training progress starts to manifest, indicating possible barren plateaus. A more extensive hyperparameter search might circumvent this issue, but as the simulation already took 10 hours with a small sized cloud compute approach, classical circuit simulation appears to become a substantial bottleneck. In course of the conducted hyperparameter optimization, this effect appears to be strongly correlated with the number of ansatz layers employed, which is sensible, as an increased number of layers leads to a bigger number of parameters -- which is a natural cause of barren plateaus~\cite{skolik2021layerwise}. This correspondence indicates a time/quality trade-off which should be investigated more closely in future work.

For the DisCoCat approach, only the low complexity data was used, as the hardware requirements were substantially higher with 100 epochs taking roughly 82 hours of wallclock time with the same setup used for the QLSTM evaluation. Examining the results of DisCoCat displayed in Fig.~\ref{fig:eval:discocat-training}, we can observe that while a slight trend of improvement in the loss and accuracy is visible over the course of all 100 epochs, it is barely better than random guessing, which would achieve a 50\% accuracy. This indicates that QLSTMs are a lot faster to train than DisCoCat based approaches for realistic data sizes and complexities when using the employed CPU based circuit simulator. However, we argue against generalizing these results towards ''QLSTMs outperform DisCoCat``, as a clear learning progress of DisCoCat is observable. Extrapolating from similar studies~\cite{10.1613/jair.1.14329}, we expect reasonably accurate results for DisCoCat given a more efficient software implementation.


% Figure environment removed

% Figure environment removed