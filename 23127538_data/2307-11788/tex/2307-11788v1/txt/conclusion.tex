In sight of current QC hard- and software limitations, QLSTMs seem to be better suited when solving QNLP tasks like sentiment analysis on the employed datasets, which appear to be a lot more realistic than those used in existing proofs of concept for both approaches. Notably, the employed ChatGPT-based data generation approach enabled producing realistic data, while preserving necessary grammatical correctness, which facilitates more practical testing. A future possibility to overcome the experienced circuit simulation bottleneck might be the support of GPU based circuit simulation for the employed implementation using pennylane and Lambeq.