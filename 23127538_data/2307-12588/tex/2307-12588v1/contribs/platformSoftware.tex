


%% Figure environment removed



\subsection{In-Field Intervention Pipeline}
\label{subsec:interventionPipeline}
All sensors on \bbot\ are directly connected to a high performance fanless embedded computer (DS-1202) powered by 7th Generation Intel® Core™ processor running the robot operating system (ROS). 
This computer is equipped with an Nvidia® Quadro P2200 featuring a Pascal GPU with 1280 CUDA cores, 5 GB GDDR5X on-board memory which is used for parallel processing and inference of DNNs.
Additionally, a dedicated Intel® NUC PC runs the controller for the platforms motion providing wheel odometry data and the status of batteries and electronic infrastructure on the platform. % Thorvald. 

% \bbot\ incorporates a vision-based monitoring approach to perceive field as it moves in rows of crop. 
The software architecture of \bbot\ contains four different nodes enable selective in-motion intervention.
\RNum{1} Field Monitoring: runs Mask-RCNN for instance-based semantic segmentation and intra-camera tracking which estimates necessary phenotypic information about the plants, more details are in~\secref{subsec:fieldMonitoring}.
% This node provides track-lets of crops and weeds along with their estimated phenotypic information.
% To enhance accuracy of track-lets (crop/weeds which are detected) tacking, directly effecting interventions performances. 
\RNum{2} In-field localization: improves the localization accuracy of the robot using an EKF to fuse GPS and wheel odometry data~\cite{wei2011intelligent}.
%\RNum{3} Intervention Controller: Is responsible for managing the targets within work-space of weeding tools. This includes planning paths for the intervention heads (sprays) using our path planning scheme elaborated on in~\secref{subsec:selectivePreciseIntervenstion}.
\RNum{3} Intervention Controller: manages the targets within the work-space of the weeding tools and includes planning paths for the intervention heads (sprays) described in~\secref{subsec:selectivePreciseIntervenstion}.
\RNum{4} Weeding Implement: provides low-level control of the weeding tool (e.g. actuation) by taking commands from the intervention controller.
%\RNum{4} Weeding Implement: the low-level controller of the weeding tool which acts on the targets by taking commands from the intervention controller.
% 
\subsection{Weeding Simulation Framework}
\label{subsec:simulation}
% 
% Figure environment removed

Conducting experiments in real fields is potentially time consuming and costly.
An accurate and reliable simulation environment that mimics real world situations is an invaluable tool which avoids this issue.
%To resolve this issue an accurate and reliable simulation environment that mimics real world situations is an invaluable tool.
% Hence, a proper and reliable simulation environment which can mimic the real world situations is priceless. 
We use two different types of simulation environments for development and evaluation of our methods on \bbot\, a ROS based one-to-one scale simulation and a native python simulator especially developed for weeding application and intervention motoring purposes. 
A demonstration of the ROS-based simulation model is shown in~\figref{fig:simulationModel}-(left), where all sensors and actuators are active. 
% and supporting field generator plugin which generate fields with row-crop field with different plant sizes and crops row shapes.
Then a field generator allows us to create row-crop fields with different plant sizes and crop-row shapes, simulating a real field.
To evaluate the weeding algorithms, we developed a native Python based framework capable which simulates the robot kinematics and generates synthetic crop-rows with varying weed distributions.
%To properly evaluate the weeding algorithms we developed a native Python based framework capable of simulating robot kinematics and generating synthetic crop/weed distribution of crop-rows with different weed densities.
This framework uses Open3D and Pyglet python libraries for rendering graphics, an simplified example view of the planning scenario is shown in~\figref{fig:simulationModel}-(right).
We used this environment to implement and evaluate different weeding strategies which we elaborate on in~\secref{subsec:selectivePreciseIntervenstion}.

 