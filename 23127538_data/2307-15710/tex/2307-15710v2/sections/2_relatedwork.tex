\section{Related Work}
\label{sec:related}

\begin{table}[t]
\small
\centering
\caption{Comparison of our method with related settings}
\begin{tabular}{cccc}
\toprule
Setting & Detect Novel OOD Data & Semi-Supervised & Learns from Novel OOD Data \\
\midrule
SSOD & \xmark & \cmark & \xmark \\ 
Open-World OD & \cmark & \xmark & \cmark \\
Open-Set SSOD & \cmark & \cmark & \xmark \\ \midrule
\textbf{Our Method} & \cmark & \cmark & \cmark \\
\bottomrule
\end{tabular}
\label{tab:comparison}
\end{table}

\paragraph{Semi-Supervised Object Detection.} Semi-supervised object detection (SSOD) approaches have become popular to reduce the need for labeling \cite{sohn2020detection, berthelot2019mixmatch, jeong2019consistency}. Pseudo-labeling based methods such as FlexMatch \cite{zhang2021flexmatch}, TSSDL \cite{shi2018transductive}, and others \cite{iscen2019label, luo2018smooth, yan2019semi, liu2021unbiased, xu2021end}, first train a teacher model using only labeled data and then use that model to create pseudo-labels for unlabeled images. The pseudo-labels are then used along with the original labeled data to train a student model. On the other hand, consistency regularization approaches such as \cite{sajjadi2016regularization, laine2017temporal, tarvainen2017mean, liu2021certainty, luo2018smooth, jeong2019consistency, iscen2019label, liu2021unbiased, xu2021end}, aim to minimize a consistency loss between differently augmented versions of an image. All of these semi-supervised learning approaches assume a ``closed-world'' setting with a fixed set of classes in both training and testing, which is not a valid assumption in real-world applications.

\paragraph{Open-World Object Detection.} Open-world object detection enables the detection of novel objects by incrementally adding novel object classes to the set of known classes. Previous work \cite{kim2022learning, kuo2015deepbox, o2015learning, wang2020leads, Maaz2022Multimodal} has studied different methods of object proposals for novel objects by attempting to remove the notion of class (all objects are regarded the same). ORE \cite{joseph2021towards} is the first to propose an open-world object detector that identifies novel classes as ‘unknown’ and proceeds to learn the unknown classes once the labels become available. \cite{han2022expanding} aims to identify unknown objects by separating high/low-density regions in the latent space. Both these approaches work in a fully-supervised setting. Our setup goes a step further and situates the open-world problem in the context of semi-supervised learning, with limited amounts of labeled ID data \textit{only}, that more closely resembles the real-world settings. 

\paragraph{Unsupervised Object Localization.} Recently proposed methods such as CutLER \cite{wang2023cut}, FreeSolo \cite{wang2022freesolo}, LOST \cite{LOST}, and MOST \cite{rambhatla2023most} propose to localize objects in an unsupervised manner, either by segmentation masks or bounding boxes. Some of these \cite{wang2023cut, LOST, rambhatla2023most} use features from self-supervised trained transformers to localize objects in the scene. In our work, we evaluate the capabilities of such methods for localizing OOD objects, as they present open-world capabilities. Based on our evaluation (\ref{sec:expts:ablation}), we use CutLER as part of the OOD Explorer to localize OOD classes. Section \ref{sec:expts} provides the details of our evaluation. 

\paragraph{Open-Set/Open-world Semi-Supervised Object Detection.}
The open-set semi-supervised object detection problem \cite{liuopen} addressed some of the limitation of the above mentioned work. Furthermore, they address like the performance of ID classes in the presence of OOD data, but they do not learn from it or improve OOD performance. They propose an offline OOD detector to filter out OOD data, thus limiting the risk of ID performance in the presence of OOD data. In contrast, our approach \textit{both} improves performance for ID classes \textit{as well as} OOD classes, i.e., our proposed framework solves a strictly stronger problem. Specifically speaking, \cite{liuopen} solves for identifying novel classes and filters it out, but does not re-introduce the classes back into the training pipeline in order to be able to learn its features. \cite{mullappilly2024semi} addresses some of the limitations of the previous mentioned methods by extending the problem to a semi-supervised setting. However, their problem setting is similar to an incremental learning setting, access to unknown class labels is provided in subsequent tasks. Our generalized setting, on the other hand, does not require access to any unknown class labels. 
