% Rewritten by Jin Chen
With the development of large language models, there is an observation that LLMs exhibit reasoning abilities~\cite{huang2022towards,wei2022emergent} when they are sufficiently large, which is fundamental for human intelligence for decision-making and problem-solving. By providing the models with the `chain of thoughts'~\cite{wei2022chain}, such as prompting with \textit{'let us think about it step by step'}, the large language models exhibit emergent abilities for reasoning and can arrive at conclusions or judgments according to the evidence or logics. Accordingly, for recommender systems, large language models are capable of reasoning to help user interest mining, thus improving performance. 
 
\subsection{Making Direct Recommendations}

\begin{table*}[]
% 表格换行使用
\newcommand{\tabincell}[2]{
\begin{tabular}{@{}#1@{}}#2\end{tabular}
}

    \caption{Zero/few-shot learners of LLMs for RS}
    \label{tab:zero_show_recs}
    \resizebox{1.\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c}
\toprule
Approach                                                                & LLM backbone                                                                & Task                           & Metric                    & Datasets    & ICL & COT                                                      \\ \midrule
\cite{liu2023chatgpt}    & gpt-3.5-turbo                                   & \tabincell{c}{rating prediction \\ sequential recommendation \\  direct recommendation \\   explanation generation \\ review summarization }         & \tabincell{c}{RMSE,MAE \\HR,NDCG \\ HR,NDCG \\     BLUE4,ROUGE,Human Eval\\BLUE4,ROUGE,Human Eval }             & Amazon Beauty   & $\checkmark$ &                                  \\ \midrule
\cite{dai2023uncovering} & \tabincell{c}{text-davinci-002\\text-davinci-003\\gpt-3.5-turbo}  & \tabincell{c}{point-wise\\pair-wise\\list-wise}                     & NDCG,MRR & \tabincell{c}{MovieLens-1M\\Amazon-Book\\Amazon-Music\\MIND-small} & $\checkmark$ & \\  \midrule
\cite{kang2023llms}            & \tabincell{c}{Flan-U-PALM\\gpt-3.5-turbo \\text-davinci-003} & \tabincell{c}{rating prediction\\ranking prediction}              & \tabincell{c}{RMSE,MAE \\ROC-AUC}                  & \tabincell{c}{MovieLens-1M\\Amazon-Books}                 & $\checkmark$ & \\ \midrule
\cite{wang2023zero}                              & text-davinci-003                                                     & reranking& NDCG,HR                   & MovieLens 100K  & $\checkmark$&$\checkmark$                                                  \\ \midrule
\cite{hou2023large}                              & gpt-3.5-turbo                                                               & reranking& NDCG                      & \tabincell{c}{MovieLens-1M\\Amazon-Games}   & $\checkmark$ &   \\ \midrule
~\cite{li2023preliminary} & gpt-3.5-turbo & reranking & Precision & MIND & $\checkmark$ & \\ \bottomrule                                   
\end{tabular}
}
\end{table*}



In-context learning~\cite{dong2022survey,dai2022can,min2022rethinking,levy2022diverse,xieexplanation,olsson2022context,akyurek2022learning} is one of the emergent abilities of LLMs that differentiate LLMs from previous pre-trained language models, where, given a natural language instruction and task demonstrations, LLMs would generate the output by completing the word sequence without training or tuning~\cite{brown2020language}. As for in-context learning, the prompt follows by the task instruction and/or the several input-output pairs to demonstrate the task and a test input is added to require the LLM to make predictions. The input-output pair is called a \textit{shot}. This emergent ability enables prediction on new cases without tuning unlike previous machine learning. 


% Figure environment removed

In the realm of recommender systems, numerous studies have explored the performance of zero-shot/few-shot learning using large language models, covering the common recommendation tasks such as rating prediction, and ranking prediction. These studies evaluate the ability of language models to provide recommendations without explicit tuning, as summarized in Table~\ref{tab:zero_show_recs}, where all methods adopt in-context learning for direct recommenders. The general process can be attached in Figure~\ref{fig:zero_few_shot}. Accordingly, we have the following findings:
\begin{itemize}
    \item The aforementioned studies primarily focused on evaluating zero-shot/few-shot recommenders using open-domain datasets, predominantly in domains such as movies and books. Large language models are trained on extensive open-domain datasets, enabling them to possess a significant amount of common-sense knowledge, including information about well-known movies. However, when it comes to private domain data, such as e-commerce products or specific locations, the ability of zero-shot recommenders lacks of validation, which is expected to be challenging.
    \item Current testing methods necessitate the integration of additional modules to validate the performance of zero-shot recommenders for specific tasks. In particular, for ranking tasks that involve providing a list of items in order of preference, a candidate generation module is employed to narrow down the pool of items~\cite{wang2023zero} and \cite{hou2023large}. Generative-based models like gpt-3.5-turbo generate results in a generative manner rather than relying on recall from existing memories, thus requiring additional modules to implement ID-based item recommendations.
    \item From the perspective of recommendation performance, zero-shot recommenders exhibit some capabilities and few-shot learners perform better than zero-shot recommenders. However, there still exists a substantial gap when compared to traditional recommendation models, particularly fine-tuned large language models designed specifically for recommenders, such as P5\cite{geng2022recommendation} and M6-Rec~\cite{cui2022m6}. This highlights that large language models do not possess a significant advantage in personalized modeling.
\end{itemize}

Another important emergent ability is the \textit{`step by step'} reasoning, where LLMs can solve complex tasks by utilizing prompts including previous intermediate reasoning steps, called the `chain of thoughts' strategy~\cite{wei2022chain}. Wang and Lim~\cite{wang2023zero} design a three-step prompt, namely NIR, to capture user preferences, extract the most representative movies and rerank the items after item filtering. Such a multi-step reasoning strategy significantly improves recommendation performance. 


\subsection{Reasoning for Automated Selection}
\input{contents/llm_nas}