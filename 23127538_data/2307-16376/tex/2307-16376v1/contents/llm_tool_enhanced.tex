% modified by Yuanhao (2023/06/18)(2023/06/23)
\subsection{LLM-based Tool Learning}
Tool learning is an emerging research field that aims to enhance task-solving capabilities by combining specialized tools with foundational models, which has been understood by~\cite{qin2023tool} as two perspectives: 
\begin{enumerate}
    \item \textbf{Tool-augmented learning} treats specialized tools as assistants in order for improving the quality and accuracy of tasks, or \textbf{Tool for AI};
    \item \textbf{Tool-oriented learning} focuses more on training models to effectively use tools, controlling and optimizing tool-applying processes, or \textbf{AI for Tool}.
\end{enumerate}


Tool learning has found applications in various fields, and this section primarily focuses on tool learning paradigms based on large language models (LLMs). While recent works often involve a combination of these two perspectives, we do not specifically categorize each work into one type. LLMs, such as GPT, are well-suited for tool learning applications~\cite{mialon2023augmented}. With their powerful natural language processing capabilities, LLMs can break down complex tasks into smaller sub-tasks and convert them into executable instructions. Specialized tools allow LLMs to access knowledge that is beyond their own understanding. By integrating specialized tools, LLMs can better understand and address complex problems, offering more accurate and efficient solutions.



\begin{table*}[]
% 表格换行使用
\newcommand{\tabincell}[2]{
\begin{tabular}{@{}#1@{}}#2\end{tabular}
}

    \caption{LLM-based tool learning approaches}
    \label{tab:toollearning}
    \centering
    \resizebox{1.0\textwidth}{!}{
\begin{tabular}{c|c|c|c}
\toprule
Approach & Tool usage & LLM backbone & Task \\ \midrule
Re3\cite{yang2022re3} & LLM & \tabincell{c}{gpt3-instruct-175B\\ gpt3-instruct-13B} & Long Stories Generation\\ \midrule
PEER\cite{schick2022peer} & LLM & LM-Adapted T5 & Editions, Citations, Quotes\\ \midrule
METALM\cite{hao2022language} & \tabincell{c}{Pretrained Encoders \\ with diverse modalities} & \tabincell{c}{Transformer \\ (pretrained from scratch)} & \tabincell{c}{language-only tasks\\ vision-language tasks}\\ \midrule
Atlas\cite{izacard2022few} & Dense retriever & T5 & \tabincell{c}{Knowledge-Intensive Language Tasks\\ Massively-Multitask Language Understanding\\ Question Answering\\ Fact Checking}\\ \midrule
LaMDA\cite{thoppilan2022lamda} & \tabincell{c}{Retriever\\ Translator\\ Calculator} & Decoder-only Transformer & Dialog\\ \midrule
WebGPT\cite{nakano2021webgpt} & Web Browser & gpt-3 & Question answering\\ \midrule
Mind's Eye\cite{liu2022mind} & \tabincell{c}{Physics Engine\\ Text-to-code LM} & \tabincell{c}{gpt-3\\ PaLM} & Reasoning\\ \midrule
PAL\cite{gao2022pal} & Python Interpreter & CODEX(code-davinci-002) & \tabincell{c}{Mathematical\\ Symbolic\\ Algorithmic Reasoning}\\ \midrule
SayCan\cite{ahn2022can} & Robots & PaLM & Real-world robotic tasks\\ \midrule
HuggingGPT\cite{shen2023hugginggpt} & \tabincell{c}{AI models\\ in Hugging Face Community} & \tabincell{c}{gpt-3.5-turbo\\ text-davinci-003 \\ gpt-4} & \tabincell{c}{Image Classification\\ Image Captioning\\ Object Detection\\ etc.}\\ \midrule
Auto-GPT & \tabincell{c}{Web Browser} & \tabincell{c}{gpt-3.5-turbo\\text-davinci-003\\ gpt-4} & User-specified Tasks\\ \midrule
\tabincell{c}{Visual ChatGPT\cite{wu2023visual} \\ Taskmatrix.AI\cite{liang2023taskmatrix}} & \tabincell{c}{Visual Foundation models\\ Customized models with unified API form} & text-davinci-003 & Visual Customized Tasks\\\midrule
ReAct\cite{yao2022react} & Wikipedia API & PaLM-540B & \tabincell{c}{Question Answering\\ Face Verificaiton}\\ \midrule
Toolformer\cite{schick2023toolformer} & \tabincell{c}{Calculator\\ Q\&A system\\ Search Engine \\ Translation System\\ Calendar} & GPT-J & Downstream Tasks\\
 \bottomrule                                   
\end{tabular}
}
\end{table*}

LLMs are commonly applied as controllers to select and manage various existing AI models to solve complex tasks, which rely on user input and language interfaces on making summarizations. They act as the central component, responsible for comprehending problem statements and making decisions regarding which actions to execute. Additionally, they aggregate the outcomes based on the results of the executed actions. In that case, HuggingGPT~\cite{shen2023hugginggpt} leverages existing models from the Hugging Face community\footnote{https://huggingface.co} to assist in task-solving. Visual ChatGPT\cite{wu2023visual} combines visual foundation models like BLIP~\cite{li2022blip}, Stable Diffusion~\cite{rombach2022high}, etc. with LangChain\footnote{https://docs.langchain.com} to handle complex visual tasks, while the following TaskMatrix.AI~\cite{liang2023taskmatrix} maintains a unified API Platform extending the capabilities of Visual ChatGPT, extends the capabilities of Visual ChatGPT by maintaining a unified API Platform, enabling input from multiple modalities and generating more complex task solutions. On the contrary, Auto-GPT\footnote{https://github.com/Significant-Gravitas/Auto-GPT} operates as an agent that autonomously understands specific targets through natural language and performs all processes in an automated loop, without requiring mandatory human input.
% by Yuxuan
WebGPT~\cite{nakano2021webgpt} introduces a text-based web browsing interactive environment, where LLMs learn to emulate the complete process of human interaction with a web browser using behavior cloning and rejection sampling techniques. In ReAct~\cite{yao2022react}, by leveraging an intuitive prompt, LLMs learn to generate both reasoning paths and task-specific actions alternately when solving a specific task. The execution of specific actions is delegated to corresponding tools, and external feedback obtained from these tools is utilized to validate and guide the reasoning process further. The motivation behind Toolformer~\cite{schick2023toolformer} aligns closely with ReAct; however, it goes a step further by combining diverse tools within a single model. This integration provides the model with flexible decision-making abilities and improved generalization capabilities, achieved through a simple yet effective self-supervised method. In contrast to prior works, LATM~\cite{cai2023large} takes a novel approach by empowering LLMs to directly generate tools. It achieves a division of labor within the task-solving process by employing LLMs at different scales: the tool maker, tool user, and dispatcher. LATM is entirely composed of LLMs, enabling the self-generation and self-utilization of tools.

\subsection{Applications in Personalization Scenarios}
Recently, LLMs have demonstrated impressive abilities in leveraging internal world knowledge and common sense reasoning to accurately understand user intent from dialogues. Moreover, LLMs can communicate with users fluently in natural language, offering a seamless and delightful user experience. These advantages make LLMs an appealing choice as recommendation agents to enhance the personalized experience.


However, despite the impressive memory capacity of LLMs, they face challenges in memorizing specific knowledge in private and specialized domains without sufficient training. For instance, storing the item corpus and all user profiles in a recommender system can be challenging for LLMs. This limitation can result in LLMs generating inaccurate or incorrect responses and makes it difficult to control their behavior within a specific domain. Furthermore, LLMs face the challenge of the \emph{temporal generalization problem} as external knowledge continues to evolve and change over time. To address these issues, various tools can be utilized to augment LLMs and enhance their effectiveness as recommendation agents.





\textbf{Search engine.} Search engines are widely employed to provide external knowledge to LLMs, reducing LLMs’ memory burden and alleviating the occurrence of hallucinations in LLMs’ responses. BlenderBot 3~\cite{shuster2022blenderbot} uses specific datasets to fine-tune a series of modules, enabling LLMs to learn to invoke the search engine at the appropriate time and extract useful knowledge from the retrieval results. LaMDA~\cite{thoppilan2022lamda} learns to use a toolset that includes an IR system, a translator, and a calculator through fine-tuning to generate more factual responses. RETA-LLM~\cite{liu2023reta} is a toolkit for retrieval-augmented LLMs. It disentangles IR systems and LLMs entirely, facilitating the development of in-domain LLM-based systems.~\cite{thoppilan2022lamda} shows a case of applying LaMDA to content recommendation. Preconditioned on a few role-specific dialogues, LaMDA can play the role of a music recommendation agent.

\textbf{Recommendation engine.} Some works have attempted to alleviate the memory burden of LLMs by equipping them with a recommendation engine as a tool, enabling LLMs to offer recommendations grounded on the item corpus. The recommendation engine in Chat-REC\cite{gao2023chat} is further divided into two stages: retrieve and reranking, which aligns with typical recommendation system strategies. In the retrieval stage, LLMs utilize traditional recommendation systems as tools to retrieve 20 items from the item corpus as a candidate item set. Subsequently, LLMs employ themselves as tools to rerank the candidate item set. LLMs' commonsense reasoning ability, coupled with the internal world knowledge within them, allow them to provide explanations for the sorting results. The recommendation engine tool used in RecLLM\cite{friedman2023leveraging} is highly similar to it in Chat-REC,  and it is also divided into retrieval and reranking stages. RecLLM provides several practical solutions for large-scale retrievals, such as Generalized Dual Encoder Model and Concept Based Search, and so on.

\textbf{Database.} Databases are also utilized as tools to supplement additional information for LLMs. In order to better cope with the cold-start problem for new items and alleviate the temporal generalization problem of LLMs, a vector database is utilized to provide information for new items that the LLMs are unaware of in Chat-REC~\cite{gao2023chat}. When encountering new items, LLMs can utilize this database to access information about them based on the similarity between the user’s request embedding and item embeddings in the database. User profiles can also help LLMs better understand the user's intent. RecLLM\cite{friedman2023leveraging} employs a user profile module as a tool to deposit meaningful and enduring facts about users exposed during historical conversations in user memory and retrieve a single fact related to the current dialogue when necessary.

% challenges of tool learning for recommendation system
Although some works have applied the concept of tool learning to personalization systems, there are still interesting and promising research topics that deserve exploration. 
1) \textbf{Fine-tuning models for better tool use.} In-context learning has shown promise in teaching LLMs how to effectively use tools with a small number of demonstrations, as shown in Chat-REC and RecLLM. However, LLMs often struggled to learn strategies for handling complex contexts with limited demonstrations. Fine-tuning is a viable option for improving tool use, but it requires sufficient training data and effective techniques. RecLLM further fine-tunes some modules of it using synthetic data generated by a user simulator through RLHF\cite{ouyang2022training} technique. Investigating methods to obtain sufficient training data and developing tailored fine-tuning techniques for recommendation systems is a worthwhile research direction. 
2) \textbf{Developing a more powerful recommendation engine.} Traditional recommendation systems often rely on collaborative filtering signals and item-to-item transition relationships for recommendations. However, with the use of LLMs as the foundation models, user preferences can be reflected through natural language and even images. Therefore, developing a recommendation engine that supports multimodal data is a crucial research direction. Additionally, the recommendation engine should also be capable of adjusting the candidate set based on user preferences or feedback (such as querying movies of a specific genre or disliking an item in the recommendation set).  
3) \textbf{Building more tools.} To provide LLMs with more authentic and personalized information, the development of additional tools is crucial. For example, APIs for querying knowledge graphs~\cite{pan2023unifying} or accessing users' social relationships can enhance the knowledge available to LLMs, enabling more accurate and tailored recommendations.


