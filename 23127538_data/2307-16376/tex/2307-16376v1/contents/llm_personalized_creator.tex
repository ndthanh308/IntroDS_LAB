% Rewritten by Jin Chen

Traditional recommender systems focus on suggesting existing items based on user preferences and historical data, where displayed content is already generated for retrieval. However, with the advancements in techniques and platforms for content creators, personalized content creator has attracted more and more attention, where more appealing content is customized generated to match the user's interests and preferences, especially in the realm of online advertising~\cite{vempati2020enabling}. The common contents contain the visual and semantic contents~\cite{thomaidou2013automated,zhang2022automatic,lei2022plato}, such as title, abstract, description, copywritings, ad banners, thumbnail, and videos. One more widely discussed topic is text ad generation, where the ad title and ad description are generated with personalized information. Earlier works adopt the pre-defined templates~\cite{bartz2008natural,fujita2010automatic,thomaidou2013automated} to reduce the extensive human effort, which, however, often fail to fully meet the user's interests and preferences. More recent data-driven methods have emerged, which incorporate user feedback as rewards in the reinforcement learning framework to guide the generation process~\cite{hughes2019generating,wang2021reinforcing,chen2022personalized,zhang2021chase}. Furthermore, the incorporation of pre-trained language models has played a significant role in improving the generation process for multiple content items~\cite{kanungo2021ad,wei2022creater,kanungo2022cobart,chen2019towards}. This integration helps refine the content generation models and improve their ability to meet user preferences effectively.



As recommender systems and large language models continue to evolve, a promising technique that would bring new opportunities is the integration of AI Generated Content (AIGC). AIGC~\cite{cao2023comprehensive} involves the creation of digital content, such as images, music and natural language through AI models, with the aim of making the content creation process more efficient and accessible.  Earlier efforts in this field focused on deep-learning-based generative models, including Generative Adversarial Networks (GANs)~\cite{goodfellow2014generative}, Variational AutoEncoders (VAEs)~\cite{kingma2013auto}, Normalizing Flows~\cite{dinh2014nice}, and diffusion-based models~\cite{ho2020denoising} for high-quality image generation. As the generative model evolves, it eventually emerges as the transformer architecture~\cite{vaswani2017attention}, acting as the foundational blocks for BERT~\cite{kenton2019bert} and GPT~\cite{radford2018improving} in the field of NLP, and for Vision Transformer (ViT)~\cite{dosovitskiyimage} and Swin Transformer~\cite{liu2021swin} in the field of CV. Moreover,  the scope of generation tasks expanded from uni-modal to multi-modal tasks, including the representative model CLIP~\cite{radford2021learning}, which can be used as image encoders with multi-modal prompting for generation. The multi-modal generation has become an essential aspect of AIGC, which learns the multimodal connection and interaction, typically including vision language generation~\cite{radford2021learning}, text audio generation~\cite{chenadaspeech}, text graph generation~\cite{li2016commonsense}, text Code Generation~\cite{feng2020codebert}. With the emergence of large language models, nowadays AIGC is achieved by extracting the human intention from instructions and generating the content according to its knowledge and intention. Representative products, including ChatGPT~\cite{chatgpt}, DALL-E-2~\cite{ramesh2021zero}, Codex~\cite{chen2021evaluating} and Midjourney~\cite{midjourney}, have attaining significant attention from society. With the growth of data and model size, the model can learn more comprehensive information and thus leading to more realistic and high-quality content creators.


Recall to the personalized content creator, the large language models would bring opportunities from the following points. Large language models would further extend the capabilities of the pre-trained model, allowing for better reasoning of user personalized intent and interest. Previous methods~\cite{wei2022creater,kanungo2022cobart} depending on tailored pre-training models may be enhanced to better improve the reasoning abilities and few-shot prompting. Secondly, \textit{Reinforcement Learning from Human Feedback} (RLHF) strategy can be applied to fine-tune models to better capture the user intent information, similar to existing RL-based framework~\cite{wang2021reinforcing} for text ad generation. Last but not least, the powerful generative abilities of large language models empower realistic creation thanks to the availability of sufficient cross-modal knowledge bases. The work~\cite{wang2023generative} more specifically proposes a recommendation paradigm based on ChatGPT, where the generation process receives feedback and multiple rounds of conversions to better capture the user explicit preferences. Compared to previous training paradigms, more explicit expressions of user interest can be understood by the large language models and converted into corresponding instructions to guide the generation of content, significantly alleviating the problem of extremely sparse feedback.


However, there are two major security and privacy risks for personalized content creators. One of the concerns is the reliability of models like ChatGPT in terms of factuality, as indicated in the work ~\cite{borji2023categorical}. While these models generate content that appears reasonable, there is a risk of distributing misleading or inaccurate information, which can weaken the truthfulness of internet content. This concern becomes particularly crucial in personalized recommendations, where the model may inadvertently promote misleading information tailored to the user's interests.
The second concern revolves around data privacy, encompassing both user profiles and long-term human interaction histories. In the case of large language models, these interaction histories are collected or shared, potentially leading to the large models memorizing sensitive user data. Previous work~\cite{carlini2021extracting} has demonstrated that large language models, especially GPT-2~\cite{radford2019language}, memorize and leak individual training examples. This emphasizes the need for strict user approval and careful handling of annotator data to mitigate privacy risks. It is crucial to develop new techniques that prioritize privacy preservation during the training process.
