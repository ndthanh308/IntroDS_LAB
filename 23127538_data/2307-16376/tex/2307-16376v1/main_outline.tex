\documentclass[10pt,journal,compsoc]{IEEEtran}





\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{color}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{pifont}





\begin{document}

\hyphenation{op-tical net-works semi-conduc-tor}

\title{When Large Language Models Meet Personalization: Perspectives of Challenges and Opportunities} 

\author{\IEEEauthorblockN{Jin~Chen\IEEEauthorrefmark{1},
Zheng~Liu\IEEEauthorrefmark{1},
Xu~Huang, 
Chenwang~Wu, Qi~Liu, Gangwei~Jiang, Yuanhao~Pu, Yuxuan~Lei, Xiaolong~Chen, Xingmei~Wang, Defu~Lian and Enhong~Chen}
\IEEEcompsocitemizethanks{
\IEEEcompsocthanksitem \IEEEauthorrefmark{1}Equal Contribution 
\IEEEcompsocthanksitem X. Huang, C. Wu, Q. Liu, G. Jiang, Y. Pu, Y. Lei, X. Chen, X. Wang, D. Lian and E. Chen are with the University of Science and Technology of China. Email: \{xuhuangcs, wcw1996, qiliu67, gwjiang, puyuanhao, lyx180812, chenxiaolong, xingmeiwang\}@mail.ustc.edu.cn and \{liandefu, cheneh\}@ustc.edu.cn.\protect
\IEEEcompsocthanksitem Z. Liu is with Huawei Technologies Ltd. Co. E-mail: zhengliu1026@gmail.com. \protect
\IEEEcompsocthanksitem J. Chen is with the University of Electronic Science and Technology of China. E-mail: chenjin@std.uestc.edu.cn.\protect
}
\thanks{
Corresponding author: Defu Lian (E-mail: liandefu@ustc.edu.cn)}}



\IEEEtitleabstractindextext{%
\begin{abstract}
The advent of large language models marks a revolutionary breakthrough in artificial intelligence. With the unprecedented scale of training and model parameters, the capability of large language models has been dramatically improved, leading to human-like performances in understanding, language synthesizing, and common-sense reasoning, etc. Such a major leap-forward in general AI capacity will fundamentally change the pattern of how personalization is conducted. For one thing, it will reform the way of interaction between humans and personalization systems. Instead of being a passive medium of information filtering, like conventional recommender systems and search engines, large language models present the foundation for active user engagement. On top of such a new foundation, user's requests can be proactively explored, and user's required information can be delivered in a natural, interactable, and explainable way. For another thing, it will also considerably expand the scope of personalization, making it grow from the sole function of collecting personalized information to the compound function of providing personalized services. By leveraging large language models as a general-purpose interface, the personalization systems may compile user's requests into plans, calls the functions of external tools (e.g., search engines, calculators, service APIs, etc.) to execute the plans, and integrate the tools' outputs to complete the end-to-end personalization tasks. Today, large language models are still being rapidly developed, whereas the application in personalization is largely unexplored. Therefore, we consider it to be right the time to review the challenges in personalization and the opportunities to address them with large language models. In particular, we dedicate this perspective paper to the discussion of the following aspects: the development and challenges for the existing personalization system, the newly emerged capabilities of large language models, and the potential ways of making use of large language models for personalization. 
\end{abstract}

\begin{IEEEkeywords}
Large Language Models, Personalization Systems, Recommender Systems, Tool-learning, AIGC
\end{IEEEkeywords}}

\maketitle


\IEEEdisplaynontitleabstractindextext

\IEEEpeerreviewmaketitle


\section{Introduction}
\input{contents/intro}


\section{Background Overview}
\subsection{Personalization Techniques} \label{sec:personalization_sec}
\input{contents/overview_personalization}


\subsection{Large Language Models}\label{sec:llms}
Language models perform the probabilistic modeling for the generation of natural language, i.e., presented with one specific context, the language models make predictions for the words which are to be generated for the future steps. Nowadays, the language models are mostly built upon deep neural networks, where two features need to be emphasized. First of all, the majority of language models are based on transformers or its close variations \cite{vaswani2017attention}. Such types of neural networks are proficient at modeling context dependency within natural languages, and exhibit superior and consistently improved performances when being scaled up. Secondly, the language models are pre-trained at scale with a massive amount of unlabeled corpus. The pre-trained models are further fine-tuned with task-oriented data so as to adapt to different downstream applications. 

There have been tremendous progresses about language models in recent years, where the emergent of large language models, represented by GPT-3, marks an important milestone for the entire AI community. The large language models (LLMs), as the name suggests, are massively scaled-up derivatives of conventional language models. Particularly, the backbone networks and the training data have been largely magnified. For one thing, although there is no specific criteria for the minimum number, a typical LLM usually consists of no less than several billions and up-to trillions of model parameters, which are orders of larger than before. For another thing, the pre-training is conducted based on much more unsupervised corpora, with hundreds of billions or trillions of tokens carefully filtered from sources like Common Crawl, GitHub, Wikipedia, Books, ArXiv, etc. The impact of scaling is  illustrated by the scaling laws \cite{kaplan2020scaling,hoffmann2022training}, which numerically uncover the power-law relationship between model size, data volume, training scale and the growth of model's performance.  


The scaling up of network and training data lead to the leap-forward of large language models' capability. They not only become more proficient at conventional skills, like understanding people's intent and synthesising human-like languages, but also process capabilities which are rarely exhibited by those smaller models. Such a phenomenon is referred as the emergent abilities of LLMs, where three representatives capabilities are frequently discussed. One is the in-context learning capability, where LLMs may quickly learn from the few-shot examples provided in the prompt. Another one is the instruct following capability. After fine-tuned with diversified tasks in the form of instruction tuning, the LLMs are made proficient to follow the human's instructions. Thus, they may handle different tasks presented in an ad-hoc manner. Last but not least, LLMs are found to be able to conduct step-by-step reasoning. With certain types of prompting strategies, like Chain-of-Thought (CoT), LLMs may iteratively approach the final answer of some complex tasks, like mathematical word problems, by breaking down the tasks into sub-problems and figuring out the plausible intermediate answers for each of the sub-problems. 

Thanks to the superior capabilities on understanding, reasoning, and generating, large language models, especially the chat models produced by instruction tuning, are presented as foundamental building blocks for many personalization services. One direct scenario is the conversational search and recommendation. Once built upon large language models, the search and recommendation systems will be able to engage with user via interactions, present outputs in a verbalized and explainable way, receive feedback from the user and make adjustment on top of the feedback, etc. The above changes will bring about a paradigm shift for the personalization services, from passively making search and recommendation, to proactively figuring out user's need and seeking for user's preferred items. In broader scopes, the LLMs may go beyond simply making personalized search and recommendation, but play as personalized assistants to help users with their task completions. The LLMs may take notes of users' important information within their memory, make personalized plans based on memorized information when new demands are raised, and execute plans by leveraging tools like search engines and recommendation systems. 

Yet, we have to confront the reality that applying LLMs for personalization is not a trivial problem. To name a quite few of the open challenges. Firstly, personalization calls for the understanding of user preference, which is more of domain-specific knowledge rather than the common-sense knowledge learned by LLMs. The effectively and efficiently adaptation of LLMs for personalized services remains to be resolved. Besides, the LLMs could memorize user's confidential information while providing personalized services. Thus, it raises the concerns for privacy protection. The LLMs are learned from Internet data; due to the exposure bias, it is almost inevitable to make unfair  predictions for the minorities. To address the above challenges, benchmarks and evaluation datasets are needed by the research communities. However, such resources are far from complete at present. To fully support personalization with LLMs, methodological and experimental frameworks need to be systematically established for all these perspectives. 

\section{LLMs for Personalization}
In the following sections, we delve into the potential of large language models for personalization, examining their evolution from simple use cases, like utilizing word knowledge as features, to more intricate integration with other tool modules to act as agents. Specifically, we focus on the progression of emergent capabilities, starting from basic world knowledge and understanding user intent, and advancing to high-level reasoning abilities. We explore how large language models can contribute to constructing a knowledge base that enriches common-sense knowledge about various items. Additionally, we discuss how the understanding capability of large language models can empower content interpreters and explainers for in-depth analysis of interactions.
Furthermore, we observe attempts to leverage the reasoning ability of large language models for system reasoners to provide recommendation results. 
These increasingly sophisticated capabilities enable complex utilization of large language models with other tool modules, enabling them to better comprehend user intentions and fulfill user instructions. Consequently, we also explore the integration of large language models with other tools for personalization, including tool learning, conversational agents and personalized content creators. The overview of this chapter is depicted in Figure~\ref{fig:overall}. Our comprehensive survey aims to provide a deeper understanding of the current landscape, shedding light on the opportunities and challenges associated with incorporating large language models into personalization.

% Figure environment removed

\section{LLMs as Knowledge Base}\label{sec:llm_knowledge_base} 
\input{contents/llms_knowledge_base}

\section{LLMs as Content Interpreter}
\input{contents/llm_content_interpreter}


\section{LLMs as Explainer}
\input{contents/llms_explainer}

\section{LLMs as Common System Reasoner}
\input{contents/llms_common_reasoner}



\section{LLMs as Conversational Agent}
\input{contents/llm_conversational_agent}


\section{Tool-Learning and its Applications in Recommendation} \label{tool_learning}

\input{contents/llm_tool_enhanced}

\section{LLMs as Personalized Content Creator}\label{sec:llm_personalized_content_creator}
\input{contents/llm_personalized_creator}


\section{Open Challenges}\label{sec:challenges}
\input{contents/challenges}


\bibliographystyle{IEEEtran}
\bibliography{ref}

\end{document}
\endinput
%%
%% End of file `sample-manuscript.tex'.
