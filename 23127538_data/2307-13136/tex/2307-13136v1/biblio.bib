
################# Expanding use of AI ############################# 
@book{police_facial_rec,
  title={The perpetual line-up: Unregulated police face recognition in America},
  author={Garvie, Clare},
  year={2016},
  publisher={Georgetown Law, Center on Privacy \& Technology}
}

@article{predictive_policing,
  title={Predictive policing: Review of benefits and drawbacks},
  author={Meijer, Albert and Wessels, Martijn},
  journal={International Journal of Public Administration},
  volume={42},
  number={12},
  pages={1031--1039},
  year={2019},
  publisher={Taylor \& Francis}
}

@inproceedings{healthcare1,
  title={" The human body is a black box" supporting clinical decision-making with deep learning},
  author={Sendak, Mark and Elish, Madeleine Clare and Gao, Michael and Futoma, Joseph and Ratliff, William and Nichols, Marshall and Bedoya, Armando and Balu, Suresh and O'Brien, Cara},
  booktitle={Proceedings of the 2020 conference on fairness, accountability, and transparency},
  pages={99--109},
  year={2020}
}
@article{healthcare2,
  author       = {Pranav Rajpurkar and
                  Jeremy Irvin and
                  Kaylie Zhu and
                  Brandon Yang and
                  Hershel Mehta and
                  Tony Duan and
                  Daisy Yi Ding and
                  Aarti Bagul and
                  Curtis P. Langlotz and
                  Katie S. Shpanskaya and
                  Matthew P. Lungren and
                  Andrew Y. Ng},
  title        = {CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with
                  Deep Learning},
  journal      = {CoRR},
  volume       = {abs/1711.05225},
  year         = {2017},
  url          = {http://arxiv.org/abs/1711.05225},
  eprinttype    = {arXiv},
  eprint       = {1711.05225},
  timestamp    = {Fri, 26 Nov 2021 17:17:06 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1711-05225.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{healthcare3,
  title={Making the most of text semantics to improve biomedical vision--language processing},
  author={Boecking, Benedikt and Usuyama, Naoto and Bannur, Shruthi and Castro, Daniel C and Schwaighofer, Anton and Hyland, Stephanie and Wetscherek, Maria and Naumann, Tristan and Nori, Aditya and Alvarez-Valle, Javier and others},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVI},
  pages={1--21},
  year={2022},
  organization={Springer}
}

################# Generalization is Important ##########################
@article{dataset_shift1,
  title={Dataset shift in machine learning},
  author={Candela, J Quinonero and Sugiyama, Masashi and Schwaighofer, Anton and Lawrence, Neil D},
  journal={The MIT Press},
  volume={1},
  pages={5},
  year={2009}
}

@inproceedings{dataset_shift2,
  title={Unbiased look at dataset bias},
  author={Torralba, Antonio and Efros, Alexei A},
  booktitle={CVPR 2011},
  pages={1521--1528},
  year={2011},
  organization={IEEE}
}

@article{covid_sepsis_alerts,
  title={Quantification of sepsis model alerts in 24 US hospitals before and during the COVID-19 pandemic},
  author={Wong, Andrew and Cao, Jie and Lyons, Patrick G and Dutta, Sayon and Major, Vincent J and {\"O}tle{\c{s}}, Erkin and Singh, Karandeep},
  journal={JAMA Network Open},
  volume={4},
  number={11},
  pages={e2135286--e2135286},
  year={2021},
  publisher={American Medical Association}
}

################### SOTA Saturating Benchmarks #######################

@InProceedings{clip_data_robustness,
  title = 	 {Data Determines Distributional Robustness in Contrastive Language Image Pre-training ({CLIP})},
  author =       {Fang, Alex and Ilharco, Gabriel and Wortsman, Mitchell and Wan, Yuhao and Shankar, Vaishaal and Dave, Achal and Schmidt, Ludwig},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {6216--6234},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/fang22a/fang22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/fang22a.html},
  abstract = 	 {Contrastively trained language-image models such as CLIP, ALIGN, and BASIC have demonstrated unprecedented robustness to multiple challenging natural distribution shifts. Since these language-image models differ from previous training approaches in several ways, an important question is what causes the large robustness gains. We answer this question via a systematic experimental investigation. Concretely, we study five different possible causes for the robustness gains: (i) the training set size, (ii) the training distribution, (iii) language supervision at training time, (iv) language supervision at test time, and (v) the contrastive loss function. Our experiments show that the more diverse training distribution is the main cause for the robustness gains, with the other factors contributing little to no robustness. Beyond our experimental results, we also introduce ImageNet-Captions, a version of ImageNet with original text annotations from Flickr, to enable further controlled experiments of language-image training.}
}


@article{human_machine_gap,
  title={Partial success in closing the gap between human and machine vision},
  author={Geirhos, Robert and Narayanappa, Kantharaju and Mitzkus, Benjamin and Thieringer, Tizian and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23885--23899},
  year={2021}
}

#################### SOTA Failures #########################

# CLIP is brittle, adversarial setting 
@article{clipbrittle3Dlighting,
  title={Small in-distribution changes in 3D perspective and lighting fool both CNNs and Transformers},
  author={Madan, Spandan and Sasaki, Tomotake and Li, Tzu-Mao and Boix, Xavier and Pfister, Hanspeter},
  journal={arXiv preprint arXiv:2106.16198},
  year={2021}
}

# CLIP has performance drop with unusual poses
@article{clipbrittlepose,
  title={Progress and limitations of deep networks to recognize objects in unusual poses},
  author={Abbas, Amro and Deny, St{\'e}phane},
  journal={arXiv preprint arXiv:2207.08034},
  year={2022}
}

# CLIP lacks compositional reasoning
@InProceedings{clipcomp1,
    author    = {Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
    title     = {Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {5238-5248}
}

# CLIP lacks compositional reasoning 
@article{clipcomp2,
  title={When and why vision-language models behave like bags-of-words, and what to do about it?},
  author={Yuksekgonul, Mert and Bianchi, Federico and Kalluri, Pratyusha and Jurafsky, Dan and Zou, James},
  journal={arXiv e-prints},
  pages={arXiv--2210},
  year={2022}
}

@misc{imagenete,
      title={ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing}, 
      author={Xiaodan Li and Yuefeng Chen and Yao Zhu and Shuhui Wang and Rong Zhang and Hui Xue},
      year={2023},
      eprint={2303.17096},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

- REFERENCES NEEDED - real world examples of harm from poor generalization
- REFERENCES NEEDED - generalization "in-the-wild" is complicated and multifaceted.


## ImageNet Analysis (Saturation, Western Bias, Inappropriate Adult Content, and Imbalanced Demographic Representation) ## 
###############################################################################################################
@misc{imagenet_saturated,
      title={When does dough become a bagel? Analyzing the remaining mistakes on ImageNet}, 
      author={Vijay Vasudevan and Benjamin Caine and Raphael Gontijo-Lopes and Sara Fridovich-Keil and Rebecca Roelofs},
      year={2022},
      eprint={2205.04596},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{imagenet_western,
      title={No Classification without Representation: Assessing Geodiversity Issues in Open Data Sets for the Developing World}, 
      author={Shreya Shankar and Yoni Halpern and Eric Breck and James Atwood and Jimbo Wilson and D. Sculley},
      year={2017},
      eprint={1711.08536},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{imagenet_demographics,
      title={Auditing ImageNet: Towards a Model-driven Framework for Annotating Demographic Attributes of Large-Scale Image Datasets}, 
      author={Chris Dulhanty and Alexander Wong},
      year={2019},
      eprint={1905.01347},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{imagenet_content,
  author={Birhane, Abeba and Prabhu, Vinay Uday},
  booktitle={2021 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Large image datasets: A pyrrhic win for computer vision?}, 
  year={2021},
  volume={},
  number={},
  pages={1536-1546},
  doi={10.1109/WACV48630.2021.00158}}

### OOD Datasets ### 
###################################################################################################################

@article{imagenetc,
  author       = {Dan Hendrycks and
                  Thomas G. Dietterich},
  title        = {Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  journal      = {CoRR},
  volume       = {abs/1903.12261},
  year         = {2019},
  url          = {http://arxiv.org/abs/1903.12261},
  eprinttype    = {arXiv},
  eprint       = {1903.12261},
  timestamp    = {Tue, 02 Apr 2019 12:29:45 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1903-12261.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{imageneta,
      title={Natural Adversarial Examples}, 
      author={Dan Hendrycks and Kevin Zhao and Steven Basart and Jacob Steinhardt and Dawn Song},
      year={2021},
      eprint={1907.07174},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{objectnet,
  title={Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models},
  author={Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{imagenetv2,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={International conference on machine learning},
  pages={5389--5400},
  year={2019},
  organization={PMLR}
}

@article{imagenetsketch,
  title={Learning robust global representations by penalizing local predictive power},
  author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@misc{imagenetr,
      title={The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization}, 
      author={Dan Hendrycks and Steven Basart and Norman Mu and Saurav Kadavath and Frank Wang and Evan Dorundo and Rahul Desai and Tyler Zhu and Samyak Parajuli and Mike Guo and Dawn Song and Jacob Steinhardt and Justin Gilmer},
      year={2021},
      eprint={2006.16241},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{imagenet9,
      title={Noise or Signal: The Role of Image Backgrounds in Object Recognition}, 
      author={Kai Xiao and Logan Engstrom and Andrew Ilyas and Aleksander Madry},
      year={2020},
      eprint={2006.09994},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{geirhos2018imagenet,
  title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  journal={arXiv preprint arXiv:1811.12231},
  year={2018}
}

@article{biasedcars,
  title={When and how do cnns generalize to out-of-distribution category-viewpoint combinations?},
  author={Madan, Spandan and Henry, Timothy and Dozier, Jamell and Ho, Helen and Bhandari, Nishchal and Sasaki, Tomotake and Durand, Fr{\'e}do and Pfister, Hanspeter and Boix, Xavier},
  journal={arXiv preprint arXiv:2007.08032},
  year={2020}
}

## Limitations of current OOD benchmarking for Vision ## 
###################################################################################################################

- REFERENCES NEEDED - limitations of current benchmarks, especially in light of foundation models trained on much larger datasets 

@misc{bommasani2022opportunities,
      title={On the Opportunities and Risks of Foundation Models}, 
      author={Rishi Bommasani and Drew A. Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tramèr and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},
      year={2022},
      eprint={2108.07258},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
 


### Robustness Improvements in CLIP / Other more recent interventions ### 
###################################################################################################################

- REFERENCES NEEDED 

@misc{clip,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lastlayerretraining,
      title={Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations}, 
      author={Polina Kirichenko and Pavel Izmailov and Andrew Gordon Wilson},
      year={2022},
      eprint={2204.02937},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6023--6032},
  year={2019}
}

@article{augmix,
  title={Augmix: A simple data processing method to improve robustness and uncertainty},
  author={Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02781},
  year={2019}
}

@article{texture_biased,
  title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  journal={arXiv preprint arXiv:1811.12231},
  year={2018}
}


## Analyzing OOD ## 
###################################################################################################################

@inproceedings{accuracyontheline,
  title={Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization},
  author={Miller, John P and Taori, Rohan and Raghunathan, Aditi and Sagawa, Shiori and Koh, Pang Wei and Shankar, Vaishaal and Liang, Percy and Carmon, Yair and Schmidt, Ludwig},
  booktitle={International Conference on Machine Learning},
  pages={7721--7735},
  year={2021},
  organization={PMLR}
}

@misc{agreementontheline,
      title={Agreement-on-the-Line: Predicting the Performance of Neural Networks under Distribution Shift}, 
      author={Christina Baek and Yiding Jiang and Aditi Raghunathan and Zico Kolter},
      year={2022},
      eprint={2206.13089},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{robustness_synth_nat,
      title={Measuring Robustness to Natural Distribution Shifts in Image Classification}, 
      author={Rohan Taori and Achal Dave and Vaishaal Shankar and Nicholas Carlini and Benjamin Recht and Ludwig Schmidt},
      year={2020},
      eprint={2007.00644},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{robustness_spat_adv_tradeoff,
  title={Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks},
  author={Kamath, Sandesh and Deshpande, Amit and Kambhampati Venkata, Subrahmanyam and N Balasubramanian, Vineeth},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27462--27474},
  year={2021}
}

@misc{imagenet_doesnt_transfer,
      title={Does progress on ImageNet transfer to real-world datasets?}, 
      author={Alex Fang and Simon Kornblith and Ludwig Schmidt},
      year={2023},
      eprint={2301.04644},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{effective_robustness,
      title={Effective Robustness against Natural Distribution Shifts for Models with Different Training Data}, 
      author={Zhouxing Shi and Nicholas Carlini and Ananth Balashankar and Ludwig Schmidt and Cho-Jui Hsieh and Alex Beutel and Yao Qin},
      year={2023},
      eprint={2302.01381},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{difficultysamples,
      title={Understanding out-of-distribution accuracies through quantifying difficulty of test samples}, 
      author={Berfin Simsek and Melissa Hall and Levent Sagun},
      year={2022},
      eprint={2203.15100},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{simplicitybias,
      title={Simplicity Bias Leads to Amplified Performance Disparities}, 
      author={Samuel J. Bell and Levent Sagun},
      year={2022},
      eprint={2212.06641},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

## Generalization Theory ## 
###################################################################################################################

@article{generalization_scaling,
	doi = {10.1088/1742-5468/ab633c},
	url = {https://doi.org/10.1088\%2F1742-5468\%2Fab633c},
	year = 2020,
	month = {feb},
	publisher = {{IOP} Publishing},
	volume = {2020},
	number = {2},
	pages = {023401},
	author = {Mario Geiger and Arthur Jacot and Stefano Spigler and Franck Gabriel and Levent Sagun and St{\'{e}
}phane d'Ascoli and Giulio Biroli and Cl{\'{e}}ment Hongler and Matthieu Wyart},
	title = {Scaling description of generalization with number of parameters in deep learning},
	journal = {Journal of Statistical Mechanics: Theory and Experiment}
}

@article{predicting_generealization_competition,
  author       = {Yiding Jiang and
                  Pierre Foret and
                  Scott Yak and
                  Daniel M. Roy and
                  Hossein Mobahi and
                  Gintare Karolina Dziugaite and
                  Samy Bengio and
                  Suriya Gunasekar and
                  Isabelle Guyon and
                  Behnam Neyshabur},
  title        = {NeurIPS 2020 Competition: Predicting Generalization in Deep Learning},
  journal      = {CoRR},
  volume       = {abs/2012.07976},
  year         = {2020},
  url          = {https://arxiv.org/abs/2012.07976},
  eprinttype    = {arXiv},
  eprint       = {2012.07976},
  timestamp    = {Sat, 02 Jan 2021 15:43:30 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2012-07976.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

### Geographical Bias in Image Classification ### 
###################################################################################################################

@misc{gustafson2023pinpointing,
      title={Pinpointing Why Object Recognition Performance Degrades Across Income Levels and Geographies}, 
      author={Laura Gustafson and Megan Richards and Melissa Hall and Caner Hazirbas and Diane Bouchacourt and Mark Ibrahim},
      year={2023},
      eprint={2304.05391},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{goyal2021self,
  title={Self-supervised pretraining of visual features in the wild},
  author={Goyal, Priya and Caron, Mathilde and Lefaudeux, Benjamin and Xu, Min and Wang, Pengchao and Pai, Vivek and Singh, Mannat and Liptchinsky, Vitaliy and Misra, Ishan and Joulin, Armand and others},
  journal={arXiv preprint arXiv:2103.01988},
  year={2021}
}

@misc{goyal2022vision,
      title={Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision}, 
      author={Priya Goyal and Quentin Duval and Isaac Seessel and Mathilde Caron and Ishan Misra and Levent Sagun and Armand Joulin and Piotr Bojanowski},
      year={2022},
      eprint={2202.08360},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{rojasdollar,
  title={The Dollar Street Dataset: Images Representing the Geographic and Socioeconomic Diversity of the World},
  author={Rojas, William A Gaviria and Diamos, Sudnya and Kini, Keertan Ranjan and Kanter, David and Reddi, Vijay Janapa and Coleman, Cody},
  booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track}
}

@article{seer,
  author       = {Mannat Singh and
                  Laura Gustafson and
                  Aaron Adcock and
                  Vinicius de Freitas Reis and
                  Bugra Gedik and
                  Raj Prateek Kosaraju and
                  Dhruv Mahajan and
                  Ross B. Girshick and
                  Piotr Doll{\'{a}}r and
                  Laurens van der Maaten},
  title        = {Revisiting Weakly Supervised Pre-Training of Visual Perception Models},
  journal      = {CoRR},
  volume       = {abs/2201.08371},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.08371},
  eprinttype    = {arXiv},
  eprint       = {2201.08371},
  timestamp    = {Tue, 01 Feb 2022 14:59:01 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2201-08371.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ramaswamy2023beyond,
  title={Beyond web-scraping: Crowd-sourcing a geographically diverse image dataset},
  author={Ramaswamy, Vikram V and Lin, Sing Yu and Zhao, Dora and Adcock, Aaron B and van der Maaten, Laurens and Ghadiyaram, Deepti and Russakovsky, Olga},
  journal={arXiv preprint arXiv:2301.02560},
  year={2023}
}

@misc{devries2019does,
      title={Does Object Recognition Work for Everyone?}, 
      author={Terrance DeVries and Ishan Misra and Changhan Wang and Laurens van der Maaten},
      year={2019},
      eprint={1906.02659},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

### Measuring Geographical Bias in Datasets ### 
###################################################################################################################


@misc{shankar2017classification,
      title={No Classification without Representation: Assessing Geodiversity Issues in Open Data Sets for the Developing World}, 
      author={Shreya Shankar and Yoni Halpern and Eric Breck and James Atwood and Jimbo Wilson and D. Sculley},
      year={2017},
      eprint={1711.08536},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

### Geographical Bias in Domain Adaptation ### 
###################################################################################################################

@article{DBLP:journals/corr/abs-2103-15796,
  author       = {Abhimanyu Dubey and
                  Vignesh Ramanathan and
                  Alex Pentland and
                  Dhruv Mahajan},
  title        = {Adaptive Methods for Real-World Domain Generalization},
  journal      = {CoRR},
  volume       = {abs/2103.15796},
  year         = {2021},
  url          = {https://arxiv.org/abs/2103.15796},
  eprinttype    = {arXiv},
  eprint       = {2103.15796},
  timestamp    = {Wed, 07 Apr 2021 15:31:46 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2103-15796.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{kalluri2023geonet,
      title={GeoNet: Benchmarking Unsupervised Adaptation across Geographies}, 
      author={Tarun Kalluri and Wangdong Xu and Manmohan Chandraker},
      year={2023},
      eprint={2303.15443},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


################################################ OTHERS


@InProceedings{pmlr-v177-idrissi22a,
  title = 	 {Simple data balancing achieves competitive worst-group-accuracy},
  author =       {Idrissi, Badr Youbi and Arjovsky, Martin and Pezeshki, Mohammad and Lopez-Paz, David},
  booktitle = 	 {Proceedings of the First Conference on Causal Learning and Reasoning},
  pages = 	 {336--351},
  year = 	 {2022},
  editor = 	 {Schölkopf, Bernhard and Uhler, Caroline and Zhang, Kun},
  volume = 	 {177},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {11--13 Apr},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v177/idrissi22a/idrissi22a.pdf},
  url = 	 {https://proceedings.mlr.press/v177/idrissi22a.html},
  abstract = 	 {We study the problem of learning classifiers that perform well across (known or unknown) groups of data. After observing that common worst-group-accuracy datasets suffer from substantial imbalances, we set out to compare state-of-the-art methods to simple balancing of classes and groups by either subsampling or reweighting data. Our results show that these data balancing baselines achieve state-of-the-art-accuracy, while being faster to train and requiring no additional hyper-parameters. Finally, we highlight that access to group information is most critical for model selection purposes, and not so much during training. All in all, our findings beg closer examination of both benchmarks and methods for future research in worst-group-accuracy optimization.}
}


@misc{pan2022contrastive,
      title={Contrastive Language-Image Pre-Training with Knowledge Graphs}, 
      author={Xuran Pan and Tianzhu Ye and Dongchen Han and Shiji Song and Gao Huang},
      year={2022},
      eprint={2210.08901},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{degrave2021ai,
  title={AI for radiographic COVID-19 detection selects shortcuts over signal},
  author={DeGrave, Alex J and Janizek, Joseph D and Lee, Su-In},
  journal={Nature Machine Intelligence},
  volume={3},
  number={7},
  pages={610--619},
  year={2021},
  publisher={Nature Publishing Group UK London}
}
@misc{li2023whacamole,
      title={A Whac-A-Mole Dilemma: Shortcuts Come in Multiples Where Mitigating One Amplifies Others}, 
      author={Zhiheng Li and Ivan Evtimov and Albert Gordo and Caner Hazirbas and Tal Hassner and Cristian Canton Ferrer and Chenliang Xu and Mark Ibrahim},
      year={2023},
      eprint={2212.04825},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ryali2021characterizing,
      title={Characterizing and Improving the Robustness of Self-Supervised Learning through Background Augmentations}, 
      author={Chaitanya K. Ryali and David J. Schwab and Ari S. Morcos},
      year={2021},
      eprint={2103.12719},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{geirhos2020generalisation,
      title={Generalisation in humans and deep neural networks}, 
      author={Robert Geirhos and Carlos R. Medina Temme and Jonas Rauber and Heiko H. Schütt and Matthias Bethge and Felix A. Wichmann},
      year={2020},
      eprint={1808.08750},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{shi2022robust,
      title={How Robust is Unsupervised Representation Learning to Distribution Shift?}, 
      author={Yuge Shi and Imant Daunhawer and Julia E. Vogt and Philip H. S. Torr and Amartya Sanyal},
      year={2022},
      eprint={2206.08871},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{mao2023understanding,
      title={Understanding Zero-Shot Adversarial Robustness for Large-Scale Models}, 
      author={Chengzhi Mao and Scott Geng and Junfeng Yang and Xin Wang and Carl Vondrick},
      year={2023},
      eprint={2212.07016},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ibrahim2022robustness,
      title={The Robustness Limits of SoTA Vision Models to Natural Variation}, 
      author={Mark Ibrahim and Quentin Garrido and Ari Morcos and Diane Bouchacourt},
      year={2022},
      eprint={2210.13604},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{madan2023adversarial,
      title={Adversarial examples within the training distribution: A widespread challenge}, 
      author={Spandan Madan and Tomotake Sasaki and Hanspeter Pfister and Tzu-Mao Li and Xavier Boix},
      year={2023},
      eprint={2106.16198},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{abbas2022progress,
      title={Progress and limitations of deep networks to recognize objects in unusual poses}, 
      author={Amro Abbas and Stéphane Deny},
      year={2022},
      eprint={2207.08034},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chan2022data,
      title={Data Distributional Properties Drive Emergent In-Context Learning in Transformers}, 
      author={Stephanie C. Y. Chan and Adam Santoro and Andrew K. Lampinen and Jane X. Wang and Aaditya Singh and Pierre H. Richemond and Jay McClelland and Felix Hill},
      year={2022},
      eprint={2205.05055},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{fang2022data,
      title={Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP)}, 
      author={Alex Fang and Gabriel Ilharco and Mitchell Wortsman and Yuhao Wan and Vaishaal Shankar and Achal Dave and Ludwig Schmidt},
      year={2022},
      eprint={2205.01397},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nguyen2023quality,
      title={Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP}, 
      author={Thao Nguyen and Gabriel Ilharco and Mitchell Wortsman and Sewoong Oh and Ludwig Schmidt},
      year={2023},
      eprint={2208.05516},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{k2021robustness,
      title={Robustness to Augmentations as a Generalization metric}, 
      author={Sumukh Aithal K and Dhruva Kashyap and Natarajan Subramanyam},
      year={2021},
      eprint={2101.06459},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{abnar2021exploring,
      title={Exploring the Limits of Large Scale Pre-training}, 
      author={Samira Abnar and Mostafa Dehghani and Behnam Neyshabur and Hanie Sedghi},
      year={2021},
      eprint={2110.02095},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{pinto2023regmixup,
      title={RegMixup: Mixup as a Regularizer Can Surprisingly Improve Accuracy and Out Distribution Robustness}, 
      author={Francesco Pinto and Harry Yang and Ser-Nam Lim and Philip H. S. Torr and Puneet K. Dokania},
      year={2023},
      eprint={2206.14502},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}
@software{Ilharco_OpenCLIP_2021,
author = {Ilharco, Gabriel and Wortsman, Mitchell and Wightman, Ross and Gordon, Cade and Carlini, Nicholas and Taori, Rohan and Dave, Achal and Shankar, Vaishaal and Namkoong, Hongseok and Miller, John and Hajishirzi, Hannaneh and Farhadi, Ali and Schmidt, Ludwig},
doi = {10.5281/zenodo.5143773},
month = jul,
title = {{OpenCLIP}},
version = {v0.1},
year = {2021}
}

@article{beyondneuralscalinglaws,
  title={Beyond neural scaling laws: beating power law scaling via data pruning},
  author={Sorscher, Ben and Geirhos, Robert and Shekhar, Shashank and Ganguli, Surya and Morcos, Ari},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={19523--19536},
  year={2022}
}

@inproceedings{huggingface,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article{spacey_package,
author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
doi = {10.5281/zenodo.1212303},
title = {{spaCy: Industrial-strength Natural Language Processing in Python}},
year = {2020}
}


@article{moayeri2022explicit,
  title={Explicit Tradeoffs between Adversarial and Natural Distributional Robustness},
  author={Moayeri, Mazda and Banihashem, Kiarash and Feizi, Soheil},
  journal={arXiv preprint arXiv:2209.07592},
  year={2022}
}


@article{teney2022id,
  title={Id and ood performance are sometimes inversely correlated on real-world datasets},
  author={Teney, Damien and Lin, Yong and Oh, Seong Joon and Abbasnejad, Ehsan},
  journal={arXiv preprint arXiv:2209.00613},
  year={2022}
}


@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@misc{russakovsky2015imagenet,
      title={ImageNet Large Scale Visual Recognition Challenge}, 
      author={Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
      year={2015},
      eprint={1409.0575},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{kirichenko2022layer,
      title={Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations}, 
      author={Polina Kirichenko and Pavel Izmailov and Andrew Gordon Wilson},
      year={2022},
      eprint={2204.02937},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}