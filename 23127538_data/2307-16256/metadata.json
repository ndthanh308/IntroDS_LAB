{
  "title": "3D Medical Image Segmentation with Sparse Annotation via Cross-Teaching between 3D and 2D Networks",
  "authors": [
    "Heng Cai",
    "Lei Qi",
    "Qian Yu",
    "Yinghuan Shi",
    "Yang Gao"
  ],
  "submission_date": "2023-07-30T15:26:17+00:00",
  "revised_dates": [],
  "abstract": "Medical image segmentation typically necessitates a large and precisely annotated dataset. However, obtaining pixel-wise annotation is a labor-intensive task that requires significant effort from domain experts, making it challenging to obtain in practical clinical scenarios. In such situations, reducing the amount of annotation required is a more practical approach. One feasible direction is sparse annotation, which involves annotating only a few slices, and has several advantages over traditional weak annotation methods such as bounding boxes and scribbles, as it preserves exact boundaries. However, learning from sparse annotation is challenging due to the scarcity of supervision signals. To address this issue, we propose a framework that can robustly learn from sparse annotation using the cross-teaching of both 3D and 2D networks. Considering the characteristic of these networks, we develop two pseudo label selection strategies, which are hard-soft confidence threshold and consistent label fusion. Our experimental results on the MMWHS dataset demonstrate that our method outperforms the state-of-the-art (SOTA) semi-supervised segmentation methods. Moreover, our approach achieves results that are comparable to the fully-supervised upper bound result.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16256",
  "pdf_url": "https://arxiv.org/pdf/2307.16256v1",
  "comment": "MICCAI 2023 Early Accept",
  "num_versions": null,
  "size_before_bytes": 5316908,
  "size_after_bytes": 129152
}