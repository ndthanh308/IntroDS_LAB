\section{Introduction}
% Digital content editing is a dynamic and fast-growing research area with significant potential to shape the future of digital media.
3D content editing is a fast-growing research area 
with significant potential to shape the future of digital media.
%最近NeRF兴起，让重建静态和动态3D场景变得非常容易。
%NeRF and its extended methods have made it easy to reconstruct static and dynamic 3D scenes.
Recently, NeRF~\cite{mildenhall2020nerf} and its extended methods~\cite{barron2021mip, barron2022mip3,li2020neural, park2021nerfies, peng2021neural} have made it easy to reconstruct static and even dynamic 3D scenes.
%因此research on static 3D scene editing based on NeRFs has also emerged.
Therefore, research on 3D scene editing based on NeRFs has also emerged. 
%现在有很多研究 3D静态 scene编辑的方法，为非专业的用户提供友好的编辑工具。
Many methods~\cite{liu2021editing,yang2022neumesh,huang2022stylizednerf} were proposed for editing static 3D scenes, which provide friendly editing tools for non-professional users. 
% there is a noticeable lack of research related to editing the appearance of dynamic 3D scenes. editing the appearance of dynamic 3D scenes是一个重要的topic，因为用户有很大的需求在动态场景上面加上自己想要的图案。
However, there is a noticeable lack of research related to editing the appearance of dynamic 3D scenes, despite a great demand for users to add their desired content  to volumetric videos.
% Motivated by the increasing 对动态场景编辑的需求， this paper focuses on the specific setting of fine-grained 编辑dynamic scene的局部appearance. 
% Motivated by the demand for dynamic 3D scene editing, 
% this paper focuses on the specific setting of locally fine-grained appearance editing based on single image for dynamic scenes.

This paper specifically focuses on fine-grained local appearance editing for 3D dynamic scenes.
% 给定一个动态NeRF和video视频，我们可以edit the appearance of the dynamic NeRF by locally modifying a single 2D image in the training video. 
Given a dynamic NeRF (probably in various representations) and its original training videos,
we aim to edit the appearance of the dynamic NeRF by modifying a single 2D frame in the training videos,
as illustrated in~\figref{teaser}.
% 由于现在对于不同的动态场景往往会采用不同的方法建模，
% so that our method can be applied to most dynamic scenes.
% 通过我们的方法，非拥有专业知识的用户可以在一个运动的3D物体的外观加上自己想要的图案，并且可以自由地多视角查看被修改后的运动物体。
% By using our method, users without professional knowledge can add their desired textures to the appearance of a moving 3D object,
% and can freely view the modified moving object from multiple viewpoints.
This problem is challenging for three reasons.
% 1. 如何通过修改单张图片修改3D场景是一件不trival的事情
First, it is non-trivial to propagate the edited 2D pixels to the implicit neural scene representation, especially for dynamic scenes.
Moreover, how to propagate the single-frame edited content to other frames in a temporally consistent manner is not well explored.
Finally, designing a generally applicable editing tool that can be plugged into different variants of dynamic NeRF representations ~\cite{peng2021neural,li2020neural,park2021nerfies,Gao2021DynNeRF, li2022neural} presents a significant challenge.
%  现在没有一个方法可以重建大多数的动态场景，更别提设计一个方法可以编辑大多数的动态场景。
% There currently exists no method that can reconstruct most dynamic scenes, 
% let alone design a method that can edit most dynamic scenes.
% 一个navie baseline是直接在这张图上finetune dynamic NeRF.
A naive baseline is to directly fine-tune a dynamic NeRF on the edited image.
% 然而，直接让dynamic NeRF去拟合单个图片的话，会导致dynamic NeRF overfit某个视角，造成在其他视角的渲染效果degrade，无法 to 传播到其他帧
However, training the dynamic NeRF directly using a single image tends to cause the network to overfit to a single view, leading to the degradation of the rendering quality on other views and the failure of propagating the edited result to other frames, despite the tedious computation.




%我们aim to design a 方法可以编辑大多数的动态NeRF。
% our goal is to design a method that can edit most dynamic NeRFs.
% The similar problem also is discussed in NeuMesh~\cite{yang2022neumesh}.
% NeuMesh~\cite{yang2022neumesh} propose a mesh-based representation extracted from SDF fields~\cite{wang2021neus,yariv2021volume}
% to solve this problem.
% %然而， reconstructing SDF fields for dynamic scenes is still a not well-solved problem.
% Nevertheless, reconstructing SDF fields for dynamic scenes is still a not well-solved problem. 
% to guarantee that patterns modified on a single image can be accurately rendered on other views, 
% the edited objects need to have well-defined surfaces. 
% Otherwise, the results rendered on other views will be distorted and blurred.
% 现在重建动态场景的方法大多使用NeRF，没有well-defined surface，无法保证编辑区域的高质量渲染. 如何在动态场景上面重建好的surface仍然是一个not well-solved问题，由于动态场景的复杂性。
% Currently, most methods for reconstructing dynamic scenes employ NeRFs,
% but NeRFs lack well-defined surfaces. 
% Therefore, reconstructing well-defined surfaces for dynamic scenes is still a not well-solved problem.
% 有一些工作尝试使用SDF重建动态场景，但是只能在有RGBD训练数据或者简单场景下面有效
% Some works~\cite{Cai2022NDR,qiao2022neuphysics,johnson2023ub4d} attempt to use SDF fields to reconstruct dynamic scenes, 
% but they are only effective for simple scenes or in the presence of RGBD training data.~\todo{add the fig of failure case of SDF}
% (2) 为了满足渲染的视频时序consistent，不同帧表面上的point-wise的对应关系必须准确。如果找不准帧与帧之间的位置关系，那么编辑后的视频则会产生漂移的artifact。 
% 如何找准空间中的点的对应关系并没有被探索

%为了满足传播是temporally consistent
% To ensure that the propagation is temporally consistent,
% the point-wise correspondence between different frames must be accurate across video frames.
% If the correspondence between frames is not accurate, 
% the edited video will have drifting artifacts.
%然而现在的方法忽视这个问题
% However,  existing methods~\cite{li2020neural, park2021nerfies, park2021hypernerf} ignore this challenge, as shown in Gao~\etal~\cite{gao2022dynamic}. 
% how to accurately find the point-wise correspondence between different frames is 

% To tackle these problem, 我们提出了DynEdit， enable users to edit the appearance of dynamic NeRFs by modifying a single image.
To tackle these challenges, we propose a novel framework called Dyn-E, 
which enables users to locally edit the appearance of dynamic NeRFs by modifying a single image.
% Our key idea is as follows. 由于完全解决以上三个挑战过于困难，我们不设计一个全局的动态场景表示，而是选择只建模局部的表面和运动去编辑给定的dynamic NeRF。
% Since it is too difficult to solve the above two challenges completely,
% The task of fine-grained editing NeRF from a single image has local property,
% i.e., users usually only need to edit a part of the image, rather than the entire image, as shown in~\cite{yang2022neumesh,xiang2021neutex,das2022learning}.
% 我们的pipeline is that 我们将用户编辑的local区域, lift to 3D space形成一个local surface, 并且使用一个可逆网络建模local surface的motion representation propagate it to other video frames.
% Our pipeline is that we lift the edited local region to 3D space to form a local surface,
% then use an invertible network to model the motion of the local surface, and propagate it to other video frames.
Our approach first lifts the edited local region to 3D space to form a local surface and then uses an invertible network to represent the motion of the local surface, allowing us to propagate the edited results across video frames.
% 这个local surface可以被interpret成为一个独立的layer，which可以插入most dynamic NeRFs。
% Based on this observation, we choose to only model the local surface and motion to edit the given dynamic NeRF.
% 这也符合了 the task of fine-grained  editing NeRF from a single image has local property, i.e., users usually only need to edit a part of the image, rather than the entire image, as shown in ~\cite{neutex,neumesh,other}
% 这样做可以让整个任务的难度大大降低。我们不需要关心全部的区域的surface重建情况，也不需要精确建模全局的运动信息。
% This can greatly reduce the difficulty of our task.
% because we do not need to be concerned with the reconstruction of surfaces for all areas, 
% nor do we need to accurately model global motion information.
% Based on this key idea, 我们提出了一个trackable local surface。我们设计了一个local surface的表示，这个local surface可以和要被编辑的dynamic NeRF一起渲染，保障了编辑区域高质量的渲染结果。同时由于我们设计的local surface只会修改给定的动态NeRF的局部区域，因此自然满足了不改变给定动态NeRF的不编辑区域的性质。同时我们的local surface是agnostic to给定的动态NeRF的。
% 从dynamic NeRFs render depth，从edited region构建textured mesh
Specifically, our local surface is a textured mesh lifted from the edited region of the single image through the rendered depth map of the given dynamic NeRF. We convert the textured mesh into a local density and color field, which can be rendered together with the given dynamic NeRF.
%we design a local surface representation, which is based on local mesh.
% We combine our proposed local surface with the given dynamic NeRF by a mask field and 
% render them together using volume rendering equation to handle occulusion relationship.
% which can be rendered together with the dynamic NeRF.
% 避免了overfitting在单个视角上面的问题。
% Our local surface can avoid the overfitting problem on a single view.
% Additionally, since our local surface representation 有well-defined surface, 他可以在其他视角下面高质量的渲染，没有distortion和blurring的artifact like edited NeRF.
% Additionally, since our local surface representation has a well-defined surface,
% it can be rendered in other views with high quality, without distortion and blurring artifacts.
%具有很强的通用性
% Moreover, our local surface can be combined with most existing dynamic NeRFs, which has strong versatility.
% 其次我们使用dual-motion representation作为我们的motion表示，可以建模一个时刻下surface上的点到其他时刻下的点的位置对应关系，保证了时序一致性。
% To propagate the local surface to other frames, we adopt an invertible motion representation, which can warp the local surface to arbitrary other frames.
% To propagate the edits to other frames, an invertible motion representation is learned from the input videos to efficiently warp the local surface to different time steps.
To propagate the edits to other frames, an invertible motion representation is learned from the input videos, enabling efficient warping of the local surface to different time steps.
% Second, 
% we adopt an invertible motion representation, 
% which can model the point-wise correspondence between arbitrary two frames.
% Based on our motion representation, we can easily propagate the editing results to other frames.
% 通过我们上面提出的方法，我们可以轻松恢复出trackable local surface。因此一些regularization可以轻易的直接在surface上面。这些regularization可以让我们的local surface的空间位置更加准确。
% By combining the proposed local surface and motion representation, 
% we can easily recover the trackable local surface across frames.
% Our method can be interpreted as an independent local layer, and it can be inserted into most dynamic NeRFs, which has strong versatility. 

Our proposed local surface representation is an independent layer that does not make assumptions about the underlying scene structure, thus it is versatile and can be inserted into most existing dynamic NeRF representations.
% 我们的方法可以保持动态NeRFs编辑区域外渲染的performance，同时在渲染区域内可以高质量的渲染。
% 多亏了local surface,
% 我们可以保持动态NeRFs编辑区域外渲染的performance，同时在渲染区域内可以高质量的渲染。
%高质量fine-grained地编辑dynamic NeRFs
Thanks to the local surface representation, we are able to maintain the rendering performance of the dynamic NeRFs outside the edited region.
The surface-based representation also allows us to leverage smoothness and  photometric    
constraints on the surface deformation to regularize the learning of the invertible motion network, which makes the spatial positions of the local surface in all frames more accurate.
% 我们在三个常用的动态场景数据集上进行了广泛的实验以验证我们算法的有效性。并且通过对hypernerf，dynamicnerf， neuralbody的编辑，证明了我们的方法是对大部分dynamic nerf合适的representation
We conduct extensive experiments on three commonly used dynamic scene datasets to verify the effectiveness of our algorithm.
Additionally, we demonstrate that our method is suitable for most dynamic NeRFs by editing HyperNeRF~\cite{park2021hypernerf}, DynamicNeRF~\cite{Gao2021DynNeRF}, and Neural Body~\cite{peng2021neural}.

% 我们的主要贡献如下：
Our main contributions are summarized as follows:
%我们提出了一个framework首次解决了dynamic scene appearance editing这个task
(1) We propose a novel approach to the task of image-based local appearance editing for dynamic NeRFs.
% 2. 我们设计了trackable local surface和直接加在surface上的regularization facilitates easy and consistent dynamic scene appearance editing
(2) We design a trackable local surface representation that facilitates spatio-temporally consistent dynamic scene appearance editing. 
% 3.我们在多个复杂数据集上广泛验证了我们算法的有效性。
(3) We extensively verify the effectiveness and versatility of our approach with various dynamic NeRF representations and multiple complex datasets.
% 1. novel setting novel framework
% 2. trackable local surface + regularization
