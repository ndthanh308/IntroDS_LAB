\section{Related Works}
\paragraph{Dynamic NeRFs.}
% 1. NeRF
% 2. NSFF
% 3. Nerfies/hypernerf
% 4. dnerf/ngnerf
% cannot be edited
%  最近，NeRFs在novel view synthesis表现非常出色
Recently, Neural Radiance Fields (NeRFs)
~\cite{mildenhall2020nerf} demonstrate remarkable performance in the domain of novel view synthesis.
%  给定一系列静态场景的多视角图片，NeRFs可以恢复出场景，并且进行自由视点渲染。
Given a set of multi-view images of static scenes, NeRF has the ability to reconstruct scenes and generate free-viewpoint videos.
% 一些工作将NeRFs扩展到动态场景上，展现了非常promising的结果。
Some studies~\cite{pumarola2020d, tretschk2021nonrigid,park2021nerfies,park2021hypernerf, peng2023representing, lin2022efficient} extend NeRFs to dynamic scenes, showcasing promising results.
% D-NeRF和Nerfies通过建模canonical NeRFs和一系列的形变场建模动态场景。 
D-NeRF~\cite{pumarola2020d} and Nerfies~\cite{park2021nerfies} employ canonical NeRFs and a series of deformation fields to capture dynamic scenes.
% NSFF利用MLPs建模了scene flow保证时序上的一致性
NSFF~\cite{li2020neural} uses MLPs to model the scene flow fields, ensuring temporal consistency.
% Neural 3D video 直接利用time-conditioned neural radiance fields表示了动态场景。
DyNeRF~\cite{li2022neural} directly utilizes time-conditioned neural radiance fields for representing dynamic scenes.
% Neuralbody and Animatable-NeRF利用人体先验，可以处理动作幅度比较大的动态人体。 
Several works~\cite{peng2021animatable, peng2021neural, zheng2022structured, liu2021neural} utilize prior knowledge of the human body to handle dynamic human bodies with a wide range of motion.
%虽然这些工作取得了非常好的渲染效果，然而都不能允许用户自由编辑appearance。
Despite achieving high-quality rendering results, these works do not allow users to freely edit their appearance.






\paragraph{Neural scene editing.}
% 1. 有很多工作专注于对场景进行编辑。
Scene editing based on neural fields is gaining increasing attention.
% 2  一些工作可以编辑场景的几何。取得了令人惊艳的效果，而另一些工作与我们的工作一样专注于编辑场景的外观。
Some works~\cite{xu2022deforming, yuan2022nerf, liu2021editing, bao2023sine} are able to modify the geometry of scenes, producing impressive results, while others focus on editing the appearance of scenes, similar to our work.
% 3. 一系列工作通过2D pretrained网络改变了神经场外观的风格
A series of works~\cite{zhang2022arf, huang2022stylizednerf, nguyen2022snerf} utilize pretrained 2D neural networks to modify the style of neural radiance fields.
% 4. 一些工作通过恢复物体的材质和环境的光照，可以对NeRF进行physics-based relighting and material editing.
Some works~\cite{zhang2021nerfactor, zhang2022modeling, zhang2021physg} enable physics-based relighting and material editing on NeRFs by recovering the material properties of objects and the environmental lighting conditions.
% 5. 还有一些工作专注于对NeRF进行精细的外观编辑。
Another line of work~\cite{yang2022neumesh, xiang2021neutex, das2022learning} focuses on fine-grained appearance editing of NeRFs.
% 6. NeuMesh通过编辑一个视角的2D图片，就可以改变整个物体的外观，并且在其他视角能够稳定地渲染。
NeuMesh~\cite{yang2022neumesh} empowers users to modify the appearance of objects by editing a 2D image captured from a specific viewpoint and achieves consistent rendering of the edited appearance from multiple viewpoints.
% 7. 但是这些工作只能对静态场景经行编辑，没有探索动态场景的编辑。
However, these methods only enable editing the appearance of static scenes and do not explore editing dynamic scenes.
% 8. 最近有一些工作尝试编辑动态人体，但是需要利用使用人体先验,我们不需要人体先验。
Recently, some works~\cite{ho2023custom, jafarian2023normal, chen2022uv} attempt to edit dynamic human bodies, 
but they need to utilize prior knowledge of the human body which is not required in our work.

\paragraph{Video editing.}
% 1. propagation-based methods
% 2. optical flow
% 3. atlas based
% cannot perform novel view  high-qualitysynthesis
Achieving consistent video editing~\cite{yu2023videodoodles, molad2023dreamix, qi2023fatezero, liu2023video} has always been a long-standing challenge in the field of video editing.
% 最近，一些工作利用optical flow传播或者作为约束，达到时序一致性。
To achieve temporal consistency, some studies~\cite{ruder2016artistic, xu2022temporally} utilize optical flow as a constraint.
% 另一些工作基于keyframes传播的方法，将keyframes修改后传播到其他帧上。
Other studies~\cite{jamrivska2019stylizing, texler2020interactive} utilize keyframe propagation methods to propagate modifications made in keyframes to other frames.
% 还有将video建模为2D atlases的方法，通过修改atlases修改视频appearance。
Additionally, there are approaches~\cite{kasten2021layered, bar2022text2live, ye2022deformable} that represent videos as 2D atlases, enabling appearance editing of the videos by modifying the atlases.
% 然而这些方法都不是3D-aware的，因此让他们做novel view synthesis不是trival extension
However, these methods lack 3D awareness, making it non-trivial to extend them for performing novel view synthesis.
% However, these methods are not 3D-aware, so extending them to perform novel view synthesis is not trivial.
% 在一些传统方法尝试基于通过重建动态物体的3D显示表示~\cite{deng2022survey}来实现的动态视频的外观编辑
Some traditional methods~\cite{deng2022survey, xu2014nonrigid, habermann2019nrst} attempt to edit the appearance of dynamic videos by reconstructing the explicit 3D representation of dynamic objects.
However, they only show the editing results
for simple scenes or in the presence of RGBD training data.








