\chapter{Related Work}
\label{chap:related}

% Figure environment removed

Flapping Wing Micro-Aerial Vehicle (FWMAV) platforms in the literature may be broadly divided into two categories based on the size of the robot. Insect-scale platforms such as Harvard's Robobee \cite{ma_controlled_2013} and University of Washington's RoboFly \cite{chukewad_robofly_2021} range in weight from a few milligrams to a few grams ($<$10g). These typically implement offboard processing with little to no payload budget for onboard sensors. Other examples of platforms in this category are Robo Moth \cite{rosen_development_2016}, Delfly Micro \cite{de_croon_design_2009}, Jellyfish Flier \cite{ristroph_stable_2014} and Insectothopter \cite{noauthor_insectothopter_nodate}.

Larger-scale platforms such as TU Delft's DelFly \cite{de_wagter_autonomous_2014} and Purdue's Hummingbird \cite{zhang_design_2017} weigh in the order of tens of grams and are capable of carrying sensors and sufficient processing onboard for basic perception. Other platforms in this category are UC Berkeley's DASH and BOLT \cite{peterson_experimental_2011} and KUBeetle-S \cite{phan_kubeetle-s_2019}. 

On the extreme end of this scale are large ornithopters such as the University of Seville's GRIFFIN \cite{zufferey_design_2021}, RoboRaven \cite{gerdes_robo_2014}, FESTO Smart Bird, Pidgeonbot \cite{chang_soft_2020}, MIT Phoenix \cite{tedrake_learning_nodate} and EPFL's morphing wing robot \cite{di_luca_bioinspired_2017} which all weigh in the order of a few hundred grams, comparable in weight and payload capacity to multi-rotors. All these platforms are compared in Figure \ref{fig:literature_search}by plotting them on a logarithmic scale of mass and wingspan.

Northeastern University's Aerobat sits uniquely in the middle of the range of FWMAV sizes. With a wing span of 30 cm and weighing 40g (when carrying a battery and a basic microcontroller), it is small enough that it can be agile, but also is capable of carrying an additional 40g of payload which can be used for sensors and processing to develop autonomy, which is significantly larger than other comparably sized platforms. In contrast, the comparably sized DelFly Explorer has a wingspan of 28cm and weighs 20g including autonomy electronics and the Purdue Hummingbird, which has a wingspan of 17cm weighs 12g.

The larger payload budget on Aerobat opens up the possibility of pushing the envelope for onboard perception and state estimation in flapping wing systems. Perception and state estimation in flapping wing robots is severely limited by the amount of computation possible onboard, and there are a limited number of works that have successfully demonstrated any level of onboard autonomy. \cite{garcia_bermudez_optical_2009}, \cite{mcguire_efficient_2017} and \cite{duhamel_altitude_2012} use optical flow for low-level control. Of these, only \cite{mcguire_efficient_2017} and \cite{garcia_bermudez_optical_2009} perform the computations onboard. \cite{de_wagter_autonomous_2014} uses a stereo rig to perform obstacle avoidance using onboard computation of disparity maps. The authors demonstrate autonomous avoidance of pillars during flight, but this method would struggle in more unstructured environments where depth information about obstacles needs to be more precise. \cite{tu_acting_2019} exploits its soft deformable wings by using them as sensors to detect wall collisions to navigate through a confined space. All of these works carry out onboard computation on small micro-controllers that can only handle basic autonomy. However, Aerobat's larger payload can support better processing, giving the opportunity to attempt more state of the art approaches. 

The state of the art in aerial robot perception has been established largely using multi-rotor platforms or offboard computation. Specifically, visual inertial approaches have gained much popularity due to cameras being cheap, lightweight and easily available, and complementing the noisy but high rate inertial data provided by an IMU. These have been implemented with variations in the type of visual data used (feature based \cite{campos_orb-slam3_2021, qin_vins-mono_2018} or direct \cite{engel_lsd-slam_2014, bloesch_iterated_2017}), the number of data points considered (full history, sliding window, latest only), methods for matching and estimation, back-end optimization \cite{kaess_isam2_2012}, loop closures, etc. and have been tested in various multi-rotor applications \cite{rhodes_autonomous_2022, weinstein_visual_2018}.

Considering the popularity and versatility of visual inertial odometry, this is chosen as the approach of choice for Aerobat. However, these algorithms typically require heavy processors to run in real time. Chapter \ref{chap:perception} Section \ref{subsec:processor} provides more details about the selection of processor on Aerobat and a comparison with processors typically used in these applications, however, here it is sufficient to say that care must be taken in selecting the visual inertial algorithm to be implemented on Aerobat. 

% Figure environment removed

\cite{delmerico_benchmark_2018} compares the performance of visual inertial odometry algorithms on various processors, noting the amount of CPU and RAM usage, processing time and accuracy. Figure \ref{fig:benchmark}, from \cite{delmerico_benchmark_2018} shows the graph of performance of different Visual Inertial Odometry (VIO) algorithms. Of the processors compared in this work, Odroid XU4 and Intel Up Board relevant for comparison with Aerobat. With 2GB and 4GB of available RAM respectfully, they are on the lower end of typically used processors in these applications. More details about the two and a comparison is presented in Section \ref{subsec:processor}, but the results of this paper indicate that although there is a drop off in accuracy, lighter algorithms such as Multi-State Constrained Kalman Filter (MSCKF) and Semi-direct Visual-inertial Odometry + Multi-Sensor Fusion (SVOMSF) can run on limited hardware. Heavier algorithms such as SVO+GTSAM, OKVIS and ROVIO have larger processing times and consume more memory, but are also more accurate, and may potentially be implemented if the processing capacity of Aerobat is improved.

This provides hope that with further optimization and tailoring of these and newer algorithms to Aerobat's specific application, it is possible to run these state of the art algorithms close to real time on limited hardware.