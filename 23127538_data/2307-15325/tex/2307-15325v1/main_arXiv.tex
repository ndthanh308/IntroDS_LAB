%File: anonymous-submission-latex-2024.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai24_arXiv} %[submission]{aaai24}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{enumitem}
\usepackage{pdfpages}



\usepackage{todonotes}
\usepackage{amsmath,amsthm,amssymb}
\newcommand{\todohans}[1]{\todo[author=Hans, inline]{#1}}

\newcommand{\FP}[1]{{\color{magenta}#1}}
\newcommand{\FN}[1]{{\color{blue}#1}}

\newcommand{\Khat}{\hat{K}}
\newcommand{\Ktilde}{\tilde{K}}
\newcommand{\Z}{\mathbb Z}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\renewcommand{\H}{\mathcal{H}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\Acal}{\mathcal{A}}
\newcommand{\Ical}{\mathcal{I}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\Gcal}{\mathcal{G}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Kcal}{\mathcal{K}}
\newcommand{\Kcalhat}{\hat{\Kcal}}
\newcommand{\Kcaltilde}{\tilde{\Kcal}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Ucal}{\mathcal{U}}
\newcommand{\Xcal}{\mathcal{X}}
\newcommand{\Ycal}{\mathcal{Y}}
\newcommand{\Zcal}{\mathcal{Z}}
\renewcommand{\S}{\mathcal{S}}
\newcommand{\expnumber}[2]{{#1}\mathrm{e}{#2}}
\newcommand{\identity}{\operatorname{id}}

\newcommand{\groupaction}[2]{{#1}\left[{#2}\right]}
\newcommand{\invgroupaction}[2]{{#1}^{-1}\left[{#2}\right]}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\pder}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pderhigher}[3]{\frac{\partial^{#3} #1}{\partial #2^{#3}}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\conv}{conv}
\DeclareMathOperator*{\proj}{proj}
\DeclareMathOperator{\co}{co}
\DeclareMathOperator{\st}{s.t.}

\newcommand{\dint}[1]{\,\mathrm{d}#1}
\newcommand{\parder}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\parderHigher}[3]{\frac{\partial^{#3} #1}{\partial #2^{#3}}}
\newcommand{\dt}{\dint{t}}


\newtheorem{theorem}{Theorem}%[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}[theorem]{Assumption}








%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2024.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai22.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash

%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{Partial observations, coarse graining and equivariance in Koopman operator theory for large-scale dynamical systems}%partial differential equations}
\author {
    % Authors
    Sebastian Peitz,\textsuperscript{\rm 1}
    Hans Harder,\textsuperscript{\rm 1}
    Feliks Nüske,\textsuperscript{\rm 2}
    \\
    Friedrich Philipp,\textsuperscript{\rm 3}
    Manuel Schaller,\textsuperscript{\rm 3}
    Karl Worthmann\textsuperscript{\rm 3}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1} Department of Computer Science, Paderborn University, Paderborn, Germany\\
    \textsuperscript{\rm 2} Max Planck Institute for Dynamics of Complex Technical Systems, Magdeburg, Germany\\
    \textsuperscript{\rm 3} Optimization-based Control Group, TU Ilmenau, Ilmenau, Germany\\
    \{sebastian.peitz, hans.harder\}@upb.de, 
    %sebastian.peitz@upb.de, 
    %hans.harder@upb.de, 
    nueske@mpi-magdeburg.mpg.de,\\
    \{friedrich.philipp, manuel.schaller, karl.worthmann\}@tu-ilmenau.de
    %friedrich.philipp@tu-ilmenau.de,
    %manuel.schaller@tu-ilmenau.de,
    %karl.worthmann@tu-ilmenau.de
}

\begin{document}

\maketitle

\begin{abstract}
The Koopman operator has become an essential tool for data-driven analysis, prediction and control of complex systems, the main reason being the enormous potential of identifying linear function space representations of nonlinear dynamics from measurements. 
%Until now, a large part of the literature treats systems as (semi-discretized) ordinary differential equations, even if the underlying dynamics are described by partial differential equations (PDEs). Moreover, the focus usually lies on full state observations, even though this is an unrealistic assumption in most applications. 
Until now, the situation where for large-scale systems, we (i) only have access to partial observations (i.e., measurements, as is very common for experimental data) or (ii) deliberately perform coarse graining (for efficiency reasons) %and at the same time do not precisely know the state space of the system 
has not been treated to its full extent.
In this paper, we address the pitfall associated with this situation, that the classical EDMD algorithm does not automatically provide a Koopman operator approximation for the underlying system if we do not carefully select the number of observables.
%when using partial observations only  and study its implications in detail. 
Moreover, we show that symmetries in the system dynamics can be carried over to the Koopman operator, which allows us to massively increase the model efficiency. We also briefly draw a connection to domain decomposition techniques for partial differential equations and present numerical evidence using the Kuramoto--Sivashinsky equation.
\end{abstract}

\section{Introduction}
Many phenomena in nature can be described by \emph{partial differential equations (PDEs)}, where the system state depends both on space and time. Popular examples are fluid dynamics or electromagnetics. Studying such systems poses many challenges, including sophisticated numerical discretization schemes (using, e.g., finite elements), a very high dimension of the resulting discretized nonlinear systems, and the challenge that in real experiments, the entire system state is accessible in few cases only. Finally, we only have very crude models (if at all) for some systems, e.g., from biology.

Due to these reasons, there has been an increasing interest in the scientific community to develop and improve methods to infer and predict dynamical systems from data. Popular examples are the \emph{Sparse Identification of Nonlinear Dynamics} \cite{BPK16}, statistical approaches such as the \emph{Mori-Zwanzig} framework \cite{CHK00}, or techniques based on deep learning \cite{VBW+18}, also using physical knowledge \cite{RPK19}. Another approach that has been particularly successful in the past decade is the \emph{Koopman operator} framework \cite{Koo31,RMB+09,Mez13}. The driving force behind this renaissance is twofold: (1) The Koopman operator yields a linear representation of nonlinear dynamical systems, thus giving us access to powerful techniques from linear systems theory, and (2) the advances in numerical approximation (here in the form of the \emph{Extended Dynamic Mode Decomposition (EDMD)} \cite{WKR15,KKS16,KNP+20}) now allow us to identify the Koopman operator from measurements using simple linear regression.
As a consequence, the Koopman operator has been studied extensively for data-driven analysis \cite{BBKK22}, coarse graining \cite{BNC18,KNP+20,NKS21,NKBC21} and control \cite{PBK15,KM18,PK19,POR20,SWP+23} of a very large number of applications from neuroscience over social systems and robotics to fluid dynamics. Besides, a formal treatment of Koopman operator methods for PDEs was addressed in \citet{NM20,Mau21}, and recent results on finite-data error bounds can be found in \citet{ZZ22,NPP+23,PSW+23,BML+23}.

\paragraph{Contributions:}~\\
%\begin{itemize}[leftmargin=*]
    %\item
    \noindent
    $\bullet$ Even though the Koopman operator allows for arbitrary observations, 
    there are severe pitfalls when we do not know or cannot efficiently discretize the system's state space.
    Many articles simply use the \emph{full state observable}, which greatly simplifies the situation. 
    %Ignorance of the state space of the dynamics as well as partial observations have been treated only to a small extent until now. 
    Here, we address this issue in detail and derive rigorous conditions on partial observations that rely on fundamental embedding theorems.
    
    %\item 
    \noindent
    $\bullet$ There is only little literature on Koopman operators for systems with symmetries; see, e.g., \citet{SER+19} for ordinary differential equations, or \citet{WSGK22}, where the matrix approximation of the Koopman operator was used to heuristically identify symmetries in Markov Decision Processes. Here, we provide a systematic treatment of symmetries in PDEs, which will allow us to significantly increase the numerical performance of the Koopman operator approximation. Furthermore, our approach allows us to transfer a learned Koopman approximation from one domain to another without retraining.
    
    %\item 
    \noindent
    $\bullet$ We draw a connection between our equivariant Koopman formulation to well-established domain decomposition methods for PDEs.
%\end{itemize}

%Symmetries: \cite{SER+19,WSGK22}

\section{Koopman operator for PDEs}
We start by introducing the Koopman operator for partial differential equations, although everything that follows applies equally to ordinary differential equations (ODEs). Consider the general dynamical system
\begin{equation}\label{eq:PDE}
    \parder{y}{t} = \Ncal(y), \quad y(\cdot,0) = y_0.
\end{equation}
Here, $y(x,t)$ is the space- and time-dependent system state, $t \in \R_{\geq 0}$ is the time and $x\in\Omega$ the spatial coordinate (for now one-dimensional). Moreover, $y(\cdot, t)\in L^2(\Omega)$ and $\Ncal: D(\Ncal) \rightarrow L^2(\Omega)$ (with $D(\Ncal)\subset L^2(\Omega)$ being the domain of $\Ncal$) is a nonlinear partial differential operator describing the dynamics of the system. We assume periodic boundary conditions (BCs). The system's flow map $\Phi^\tau : L^2(\Omega)\to L^2(\Omega)$ is defined by
\[
    y(\cdot,t+\tau) = \Phi^\tau(y(\cdot,t)).
\]
Furthermore, we assume that the system possesses an invariant compact set $\Acal\subset D(\mathcal N)$, i.e., $\Phi^\tau(\Acal) = \Acal$, which has dimension~$\dim(\Acal)=d$ (often, the \emph{box counting dimension} is used in this context \cite{ZDG19}). 
%\FP{What is the dimension of a compact set?}. 
Usually, $\Acal$ is the system's \emph{attractor} or an \emph{invariant manifold}, and it is well known that many PDEs possess an attractor with $d<\infty$.
\begin{example}
    The well-known \emph{Kuramoto--Sivashinsky} equation that we will study in this paper is, in dimensionless form,
\begin{equation}\label{eq:KS}
    % y_t + 4y_{xxxx} + \mu \left[ y_{xx} + 0.5 (y_x)^2 \right] = 0
    \parder{y}{t} + 4\parderHigher{y}{x}{4} + \mu \left[ \parderHigher{y}{x}{2} + y \parder{y}{x} \right] = 0
\end{equation}
    on the domain $\Omega=[0,L]=[0,2\pi]$ with $\mu \in (0,\infty)$. Depending on $\mu$, the system exhibits rich dynamics, from bimodal fixed points to traveling waves to fully chaotic behavior \cite{HNZ86}. Moreover, one can bound the dimension of the attractor $\Acal$ in terms of the domain size $L$ via $d\leq L^{2.46}$ when not considering the non-dimensionalized version as we do in \eqref{eq:KS}, see \citet{ZDG19} for more details.
    %We here have used the shorter index notation for partial derivatives with respect to time and space.
\end{example}

The \emph{semigroup of Koopman operators} associated with \eqref{eq:PDE} is defined on a space of observable functionals, see~\cite{Mau21}.

\begin{definition}[Koopman semigroup and generator]\label{def:Koopman}
Consider the space $C(\Acal)$ of continuous real-valued functionals $f: \Acal \to \R$, endowed with the supremum norm $\norm{f} = \sup_{y\in\Acal}\abs{f(y)}$.
%To do so, we need to assume that we consider the dynamics of $\Phi^\tau$ on an 
%where the definition domain $\Acal \subset D(\Ncal)$ is invariant under $\Phi^\tau$. 
The \emph{semigroup of Koopman  operators} $(\Kcal^\tau)_{\tau\geq 0}$ associated with the semiflow $(\Phi^\tau)_{\tau\geq 0}$ is defined by
\begin{equation}\label{eq:Koopman}
\Kcal^\tau f = f \circ \Phi^\tau, \qquad f\in C(\Acal).
\end{equation}
The Lie generator of the semigroup is the linear operator $\Kcal: D(\Kcal) \rightarrow C(\Acal)$ that satisfies
\begin{align}\label{eq:Koopman_generator}
\Kcal f = \lim_{\tau\to 0} \frac{\Kcal^\tau f - f}{\tau}.
\end{align}
\end{definition}

\begin{remark}\label{rem:vector}
An extension to vector-valued observable functions $f: \Acal \rightarrow \R^q$ in $C(\Acal)^q$ can be realized in a straightforward manner, see, e.g., \cite{BMM12}.
\end{remark}

In the case of a Koopman semigroup associated with a semiflow generated by the PDE \eqref{eq:PDE}, it follows from the chain rule that the generator is given by
\begin{equation}\label{eq:Koopman_DE}
    (\Kcal f)(y) = D_{\Ncal(y)}f(y),
\end{equation}
which can be interpreted as the Lie derivative associated with the infinite-dimensional vector field $\Ncal$, where $D_{\Ncal(y)}f(y)$ denotes the (linear) Gâteaux derivative of $f$ at $y$ in the direction $\Ncal(y)$. %\cite{NM20,Mau21}. 
Note that this is closely related to the generator PDE that we find for ODEs \cite{KNP+20}. An alternative derivation using the functional derivative can be found in \citet{NM20}.

Even though the Koopman operator formalism has been known for a very long time, it has received a massive increase in attention in the past decade, mostly due to the advances in its numerical approximation via EDMD. Based on the observation that Eqs.\ \eqref{eq:Koopman} and \eqref{eq:Koopman_generator} are linear, we can try to compute finite-dimensional approximations $K^\tau\in\R^{\ell \times \ell}$ and $K\in\R^{\ell \times \ell}$ to $\Kcal^\tau$ and $\Kcal$, respectively. We achieve this via Galerkin projection by introducing a finite dictionary $\{\psi_j\}_{j=1}^{\ell}$ of functions $\psi_j\in C(\Acal)^q$, and coefficients $a\in\R^\ell$: 
\begin{equation}\label{eq:Galerkin}
f(y(\cdot,t)) \approx \sum_{j=1}^\ell a_j \psi_j(y(\cdot,t)) = a^\top \Psi(y(\cdot,t)).
\end{equation}
Using observed time series data $[\Psi(y_0),\Psi(y_1),\ldots,\Psi(y_m)]$, where $y_i=y(\cdot,i\tau)$ and $\Psi = [\psi_1^\top,\cdots,\psi_\ell^\top]^\top : \Acal\to \R^{\ell q}$, we can now simply use linear regression to find the best fit matrix $K^\tau$:
\begin{equation}\label{eq:Koopman_regression}
\min_{K^\tau\in\R^{\ell q \times \ell q}} \sum_{i=0}^{m-1} \norm{\Psi(y_{i+1}) - K^\tau \Psi(y_i)}_2^2.
\end{equation}
A very similar regression problem can be formulated to approximate the generator $\Kcal$ via $K$ \cite{KNP+20}.
In both cases, it can be shown that this matrix converges to the Galerkin projection of $\Kcal^\tau$ in the infinite data limit $m\rightarrow\infty$ \cite{WKR15,KKS16}, and to the true Koopman operator when additionally $\ell\rightarrow \infty$ \cite{KM18b}. Moreover, finite-data error bounds can be found in \citet{ZZ22,NPP+23,PSW+23,BML+23}, using either i.i.d.\ or ergodic sampling.
%\textcolor{orange}{Shouldn't we mention something like ergodicity?}



\section{Partial measurements, coarse graining \& unknown state spaces}

A large part of the existing literature focuses on small-scale systems or the situation where $f$ is the identity mapping, i.e., the \emph{full state observable}. Alternatively, it is at least assumed that the state space (here: $L^2(\Omega)$) is known and that the observable $f$ can be numerically approximated in an efficient manner. (An exception is \citet{OPR22}, where a Kalman filter was used to infer the state of an unknown system from measurements.)
%
However, this viewpoint has severe limitations. If, for instance, we consider PDEs, the state space may be challenging to approximate numerically. Moreover, if the data stems from real experiments, the domain may be unknown altogether. The same challenges occur in large-scale systems of ODEs such as molecular dynamics, agent-based systems or dynamics on graphs (e.g., electric grids, where the entire graph is not necessarily known). In this situation, a coarse graining to meaningful macro observables \cite{ZHS16,BNC18,NKS21,NKBC21} is highly desirable, at the cost of loosing knowledge of the underlying dynamical equations.
% In the following, we will consider exactly this situation, where we do not necessarily know $f$ or $\Ycal$. %For instance, this can be the case when we use experimental data from a PDE system, but we do not know the  exact geometry of the spatial domain. Another example might be a dynamical system on a large graph , where we collect measurements at a subset of the nodes, but we do not even know the overall graph structure.

\subsection{A common pitfall of partial measurements}
In the following, we will precisely consider the above-described situation where we do not necessarily know $f$ or the state space, not to mention the attractor $\Acal$. Formally, there still exists an observable $f:\Acal \rightarrow \R^q$, according to which we collect our measurements $z_i = f(y_i)$. However, as we are ignorant of $f$ or the domain $\Acal$, we appear to be at an impasse: we cannot define a dictionary $\{\psi_j\}_{j=1}^{\ell}$ in $C(\Acal)^q$, which is the key step in EDMD, cf.\ Eqs.\ \eqref{eq:Galerkin}--\eqref{eq:Koopman_regression}.

A practical means to overcome this impasse is to collect measurements $z=[z_0,z_1,\ldots,z_m]\in\R^{q \times (m+1)}$, where $z_i = f(y_i)$, and try to approximate the Koopman operator directly from the data. 
If the measurement is low-dimensional (i.e., $q$ is small) people often simply \emph{lift} the data $z$ using a dictionary such as delay coordinates or polynomials with maximal degree $s$, i.e.,
\begin{equation}\label{eq:EDMD_CDS}
    \Psi(z) = \begin{bmatrix} 1 & z_1 & \ldots & z_q & z_1^2 & z_1 z_2 & \ldots & z_q^{s}\end{bmatrix}^\top_{~\cdot}
\end{equation}
Examples of this approach are, e.g., lift and drag measurements of a fluid flow \cite{PK19}, coarse-grained coordinates of large molecules \cite{NKBC21} or delay coordinates of highway traffic data \cite{AM20}.
%Examples of this can be found in, e.g., \citet{PK19}, \citet{NKBC21} or \citet{AM20}. 
%In the first case, $K^\tau$ was approximated from lift and drag measurements of a fluid flow alone, without explicit knowledge of the state space $\Ycal$ or the observable $f$. In the second case, the dynamics of lower-dimensional, coarse grained data was learned. Finally, in the last case, the Koopman operator for highway traffic data was derived using delay observables.
%
However, this approach provides a major pitfall when it comes to learning anything about the dynamics of the original system. 
Conceptually, we treat our measurements in such a way that we now use the full state observable on a different, implicitly defined dynamical system $\varphi^\tau: \R^q \rightarrow \R^q$ that describes the dynamics of the observed quantity $z$ on the artificial \emph{state space} $\R^q$:
\begin{equation}\label{eq:CDS}
    z_{i+1} = \varphi^\tau(z_i).
\end{equation}
Following \citet{DHZ16,ZDG19}, we will call \eqref{eq:CDS} the \emph{Core Dynamical System (CDS)}.

Assuming that the CDS exists and is uniquely defined, we can now define a new observable $h\in \Hcal= C(f(\Acal))^q$, $h: \R^q \rightarrow \R^q$ 
%\FP{Sicher, dass die nach $\R^q$ mappen soll?} 
whose domain is now the state space of the CDS. 
%\FP{Der sollte doch hoeher dimensional sein, wenn ich mir (8) angucke.} 
In this setting, we can simply apply EDMD in its standard form (Eqs.\ \eqref{eq:Galerkin}--\eqref{eq:Koopman_regression} in combination with a dictionary as in \eqref{eq:EDMD_CDS}), to identify the Koopman operator associated with the CDS and the observable function $h$.\footnote{For convenience, we will use the full state observable $h=\identity$ here, but our equivalence result in Theorem \ref{thm:Koopman_CDS} also covers the more general setting for arbitrary $h$.} This concept is illustrated in Fig.\ \ref{fig:Koopman_CDS}, where $z=h(z) = h(f(y))$, and $\{\psi_j\}_{j=1}^{\ell}$ spans a subspace of $\Hcal$ instead of $C(\Acal)$.

%However, can we really say that this system possesses the same dynamics as the original one?
% We need embedding results (Takens, Whitney, Robinson, ...)
%Core Dynamical System (CDS) \cite{DHZ16,ZDG19} ensures a one-to-one relation, cf.\ Fig.\ \ref{fig:Koopman_CDS}.

% Figure environment removed




\subsection{Relation between the Core Dynamical System and the underlying PDE}
What remains to be shown is the correspondence between the original dynamical system $\Phi^\tau$ and the corresponding CDS $\varphi^\tau$. To this end, we closely follow the approach in \citet{ZDG19} and make use of well-known embedding theorems such as \citet{Whi36}, \citet{Tak81}, or \citet{Rob05}. 
%To do so, we need to assume that we consider the dynamics of $\Phi^\tau$ on an invariant compact set $\Acal$, i.e., $\Phi^\tau(\Acal) = \Acal$, which is of finite dimension $d$. Usually, $\Acal$ is the system's \emph{attractor} or an \emph{invariant manifold}, and it is well known that many PDEs possess an attractor with $d<\infty$.
%\begin{remark}
For a detailed discussion on the more intricate implications of the following theorem --- as well as the definitions of the terms \emph{box counting dimension}, \emph{thickness exponent} (which is usually $\sigma=0$) and \emph{prevalence} --- we refer the reader to \citet{ZDG19}.
%\end{remark}

\begin{theorem}[\citet{Rob05,ZDG19}]\label{thm:embedding} 
Let $\Acal \subset \Ycal$ be a compact, invariant set, with upper \emph{box counting dimension} $\dim(\Acal)=d$, and \emph{thickness exponent} $\sigma$. Choose an integer $q > 2(1 +\sigma )d$, and suppose further that the set $\Acal_p$ of $p$-periodic points of $\Phi^\tau$ satisfies $\dim(\Acal_p) < p/(2 + 2\sigma )$ for $p= 1,...,q$. 
%\FP{Verstehe ich nicht. Soll das $Y$ ein $\Ycal$ sein? Dann haette ich gedacht, dass $\Acal_p\subset\Ycal$ ist. Dann ist aber die Distanz oben immer Null.} 
Then for almost every (in the sense of \emph{prevalence}) Lipschitz map $g:\Ycal\rightarrow \R$ the \emph{delay observation map} $f:=D_q[g,\Phi^\tau]: \Ycal \rightarrow \R^q$ defined by 
\begin{equation*}
    %\small
    %f:=D_q[g,\Phi^\tau](y) = {
		y\mapsto\begin{bmatrix}
        g(y) & g(\Phi^\tau(y)) & \ldots & g(\Phi^{(q - 1)\tau}(y)
    \end{bmatrix}^\top
\end{equation*}
is one-to-one on $\Acal$. The same holds for a set of $q$ distinct observables $g_1,\ldots,g_q : \Ycal\to\R$, i.e.,
\begin{equation*}%\label{eq:embedding2}
    f = \begin{bmatrix}g_1(y) & \ldots & g_q(y)\end{bmatrix}^\top.
\end{equation*}
%\FP{Also, ich finde, hier geht einiges durcheinander. Jetzt ist der state space $\Ycal$ ein allgemeiner Banachraum. Dann fragt sich, was periodische Randbedingungen sein sollen. Also, ich wuerde sagen: entweder wir passen Thm 4 an die spezielle Situation mit $\Ycal = L^2(0,L)$ an oder machen alles allgemein auf einem Banachraum von Funktionen $\Ycal$ auf $[0,L]$ (vorher wurde $\Ycal$ eingefuehrt als beliebiger separabler Hilbertraum). Mir ist das gleich. Es sollte nur einheitlich sein.}
\end{theorem}

\begin{remark}
The \emph{\textbf{central message}} of the above theorem is that we can draw a close connection between the observable $f$ 
%\FP{Was genau ist hier mit "Definition" gemeint?} 
in the Koopman setting (Definition \ref{def:Koopman} and Remark \ref{rem:vector}) and the observation map $g$ in the embedding framework. The key statement for our purposes is that if the system dynamics of $\Phi^\tau$ is restricted to a compact set $\Acal$ with a finite dimension $d$, then we need to have at least $q>2d$ distinct measurements $g$ -- which jointly form the Koopman observable $f$ -- to obtain a one-to-one correspondence between $\Phi^\tau$ and $\varphi^\tau$:
\begin{equation*}%\label{eq:CDS_PDE}
\Phi^\tau = E \circ \varphi^\tau \circ D_q[g,\Phi^\tau] = E \circ \varphi^\tau \circ f,
\end{equation*}
where $E$ is the inverse of $f$. This way, the CDS becomes:
\begin{equation}\label{eq:CDS_PDE}
    \varphi^\tau = f\circ\Phi^\tau\circ f^{-1}.
\end{equation}
%\FP{\rm "can be interpreted" ist mir zu schwammig. Ich denke, $E$ {\em ist} die Inverse von $f$, definiert auf $f(\Acal)$. Oder? Das passt auf jeden Fall, wenn man das dynamische System $\varphi^\tau$ auf $f(\Acal)$ definiert als $\varphi^\tau = f\circ\Phi^\tau\circ f^{-1}$. Dann können wir auch $\Hcal$ definieren als $C(f(\Acal))^p$.}
\end{remark}

As a consequence, we can relate the Koopman operator for $\varphi^\tau$ to the Koopman operator for $\Phi^\tau$.

\begin{theorem}\label{thm:Koopman_CDS}
Let the assumptions of Theorem \ref{thm:embedding} hold and define the Koopman operator $\Kcal^\tau$ for the PDE \eqref{eq:PDE} in its standard form as in \eqref{eq:Koopman}. Furthermore, define the Koopman operator for the CDS $\varphi^\tau$ with observable $h:\R^q \rightarrow \R^p$ as follows:
\[
    \Kcalhat^\tau h = h \circ \varphi^\tau, \qquad h\in\Hcal.
\]
%\FP{Wie gesagt: $\Hcal$ muss definiert sein.} 
Then $h\circ \Kcal^\tau f = \Kcalhat^\tau h \circ f$. 
Moreover, we find that $\Kcal^\tau$ and $\Kcalhat^\tau$ share the same spectrum, and the eigenfunctions are related via $f$. 
\end{theorem}
\begin{proof}
The proof immediately follows from the one-to-one correspondence established in Theorem \ref{thm:embedding}, which means that for every $z\in f(\Acal)$ we find exactly one $y\in\Acal$ such that $f(y)=z$. Choose an arbitrary $y_0\in\Acal$ with $y_1=\Phi^\tau(y_0)\in \Acal$ (we have $y_1\in\Acal$ due to the invariance of $\Acal$). Then
\begin{equation*}
    \begin{aligned}
        % (\Kcal^\tau f)(y_0) &= f(\Phi^\tau(y_0)) = f(y_1)=z_1 = h(z_1) \\
        % &= h(\varphi^\tau(z_0)) = (\Kcalhat^\tau h)(z_0) = (\Kcalhat^\tau h)(f(y_0)) \\
        % &= (\Kcalhat^\tau h \circ f)(y_0)
        h((\Kcal^\tau f)(y_0)) &= h(f(\Phi^\tau(y_0))) = h(f(y_1)) = h(z_1) \\
        &= h(\varphi^\tau(z_0)) = (\Kcalhat^\tau h)(z_0) = (\Kcalhat^\tau h)(f(y_0)) \\
        &= (\Kcalhat^\tau h \circ f)(y_0).
    \end{aligned}
\end{equation*}
%Setting $h=\identity$ immediately yields the desired special case. 
%\FP{Ich wuerde $\operatorname{id}$ statt $Id$ benutzen, da Letzteres meistens fuer die Einheitsmatrix steht.}
For the spectrum, consider an eigenfunction $\hat\xi$ with associated eigenvalue $\hat\lambda$ such that
\begin{align*}
    \Kcalhat^\tau \hat\xi = \hat\lambda \hat\xi.
\end{align*}
Then, using Eq.\ \eqref{eq:CDS_PDE} and introducing $\xi = \hat\xi\circ f$, we find
\begin{align*}
    \hat\xi \circ \varphi^\tau = \hat\xi \circ f\circ\Phi^\tau\circ f^{-1}&= \hat\lambda \hat\xi \\
    \Leftrightarrow \qquad \hat\xi \circ f\circ\Phi^\tau &= \hat\lambda \hat\xi \circ f \\
    \Leftrightarrow \qquad \quad~~\xi\circ\Phi^\tau &= \hat\lambda \xi.
\end{align*}
\end{proof}
\begin{remark}
    For $h=\identity$, we find $\Kcal^\tau f = \Kcalhat^\tau h \circ f$.
\end{remark}





\section{Equivariant Koopman operators for equivariant PDEs and convolution observables}
We now want to make use of the above-mentioned partial observations in order to approximate local, spatially confined Koopman operators for partial differential equations (PDEs) that possess symmetries.
That means, instead of measuring the entire state, we will only utilize point measurements from a small subregion of the spatial domain.
We are going to realize this by means of a convolution observable, which as a special case yields point measurements, but covers many other settings as well.

In order to discuss the basic symmetry concepts, let us forget about the time dependence of $y$ for a moment and instead denote the state at a fixed time $t$ by $y_t(x)=y(x,t)$ for $x\in\Omega$ 
%\FP{Was ist $\Omega$? Besser $[0,L]$? Oder wollen wir von Beginn an $\Omega\subset\R^n$ als spatial domain waehlen? Dann ist $\Omega = [0,L]$ nur ein Spezialfall.}. 
For a more detailed introduction, see \cite{BBCV21}. A \emph{group} is a set $G$ along with an associative composition operation $\circ : G \times G \rightarrow G$ that contains an identity and inverses. 
%\FP{Muss man sowas Grundlegendes wirklich definieren?} 
A \emph{group action} of $G$ on a set $\Omega$ is then defined as a mapping $(g,x) \rightarrow \groupaction{g}{x}$ associating a group element $g\in G$ and a point $x\in\Omega$ with some other point in $\Omega$ in a way that is compatible with the group operations, i.e., $\groupaction{g}{(\groupaction{h}{x})}=\groupaction{(gh)}{x}$ for all $g, h \in G$ and $x \in \Omega$.
%
\begin{example}
The Euclidean group $E(2)$ in the plane is the group of transformations of $\R^2$ that preserves Euclidean distances, consists of translations, rotations, and reflections. The same group can also act on the space of functions on the plane, that is, if we have a group $G$ acting on $\Omega$, we automatically obtain an action of $G$ on the space $\Ycal(\Omega)$: $\groupaction{g}{y_t}(x) = y_t(\invgroupaction{g}{x})$.
% \begin{equation}\label{eq:group_action}
%     (\groupaction{g}{z})(x) = z(\invgroupaction{g}{x}).
% \end{equation}
Due to the inverse on $g$, this is indeed a valid group action, in that we have 
$(\groupaction{g}{(\groupaction{h}{y_t})})(x)=(\groupaction{(gh)}{y_t})(x)$.
\end{example}
%
For the subset of linear group actions, we can define group representations $T_g : \Omega \rightarrow \Omega$. 
%\FP{Soll $g\mapsto T_g$ besondere Eigenschaften haben? Was ist eine Group Representation? Und was ist eine linear group action?}
%\textcolor{orange}{$T^g$ vs.\ $T_g$. Similar: group representation and transformation operator}
If $T_g$ satisfies $y_t(x) = y_t(T_g x )$ for all $g \in G$ and $x \in \Omega$, then we say that $y_t$ is \emph{invariant} or symmetric to $T_g$ and that $\{T_g\}_{g\in G}$ is a set of symmetries of $y_t$. 
A related notion is \emph{equivariance}. Given a transformation map $T_g : \Omega \rightarrow \Omega$ and some $y_t\in\Ycal$, we say that $y_t$ is equivariant to the transformation
if there exists a second transformation operator $T'_g : \Ycal \rightarrow \Ycal$ in the output space of $y_t$ such that $T'_g y_t(x) = y_t(T_g x)$ for all $g \in G$, $y_t \in \Ycal$. 
%\FP{Eben war $y_t$ noch fest. Deshalb verstehe ich die Definition auch nicht. Ich setze einfach $T_g'y = y\circ T_g$ und bin fertig. Oder was ist hier die Krux?} 
The operators $T_g$ and $T'_g$ can be seen as describing the same transformation, but in different spaces. Invariance is a special case of equivariance, if we set $T'_g$ to the identity for all~$g$.

Let us now define a particular observable, namely the \emph{Convolution operator}. 
%For simplicity, we will consider the 1D case here. 
Generally, a convolution is the composition of two functions which produces another function in a new coordinate. Usually, a function of interest (e.g., our system state $y$) is composed with a kernel $\theta$:
\begin{equation*}%\label{eq:convolution}
    %(y \star \theta)(s,t)= \int_{\Omega} y(x,t) \theta(s-x) \dint{x}.
    (y_t \star \theta)(s)= \int_{\Omega} y_t(x) \theta(s-x) \dint{x}.
\end{equation*}
In many situations, $\theta$ is a Gaussian kernel that somewhat ``localizes'' $y_t$ around the center $s$ (even though not in a strict sense, of course).
%
Now, fixing $s$, we can define the observable function
\begin{equation}\label{eq:observable}
    % f_s(y(\cdot,t)) = z(s,t) = (y \star \theta)(s,t).
    f_s(y_t) = z_t(s) = (y_t \star \theta)(s).
\end{equation}

%\FP{Muessen wir in dieser Sektion bis hierhin wirklich immer das $t$ im Index mitschleppen? Es reicht doch, einfach überall nur $y$ statt $y_t$ zu schreiben, oder nicht?}

\begin{remark}\label{rem:conv}
    Eq.\ \eqref{eq:observable} is very general, as it includes point observables (using a Dirac-Delta kernel) as well as integrals over parts of the domain. An extension to more complex expressions (i.e., nonlinear functions of the full state $y$) can be realized in a straightforward manner by applying the convolution to a nonlinear transformation of the state.
\end{remark}

Let us now assume that our group action is a shift operation (e.g., $T_{g}x = x-a ~ \mathsf{mod}~L$). 
Furthermore, we assume that the partial differential operator $\Ncal$ defined by Eq.\ \eqref{eq:PDE} does not explicitly depend on space $x$ or time $t$.
We thus obtain shift equivariance of the right-hand side of the PDE and thus, the group action on the position commutes with the flow $\Phi^t$ \cite[Remark 1]{OP21}:
\begin{equation*}%\label{eq:eqiv_flow}
    \begin{aligned}
    y(\invgroupaction{g}{x}, t) &= \groupaction{g}{y}(x,t) = \Phi^t(\groupaction{g}{y}(x,0)) \\&= \Phi^t(y(\invgroupaction{g}{x}, 0)).
\end{aligned}
\end{equation*}
Note that the group action $g$ formally transforms the function $y$ which depends on $x$ and $t$, but acts as the identity on~$t$. Using the convolution observable and the equivariance of the PDE, we find that the corresponding Koopman operator inherits the equivariance property.
\begin{theorem}
    Consider a PDE of the general form \eqref{eq:PDE} with periodic boundary conditions, where $\Ncal$ does not explicitly depend on space $x$ or time $t$ and is thus equivariant under translations in $x$ (and $t$) in view of the periodic boundary conditions. 
    Then, the Koopman operator associated with \eqref{eq:PDE} and the observable $f_s$ as defined in \eqref{eq:observable} is also equivariant under the same group action.
\end{theorem}
\begin{proof}
Introducing $\tilde{x} = x-a$, we get (under periodic BCs)
\begin{equation*}
\begin{aligned}
    f_{\invgroupaction{g}{s}}(y_t) &= z_t(\invgroupaction{g}{s}) = \int_{\Omega} y_t(x) \theta(s+a-x) \dint{x} \\
    &= \int_{\Omega} y_t(\tilde{x}+a) \theta(s-\tilde{x}) \dint{\tilde x}  \\
    &= \int_{\Omega} y_t(\invgroupaction{g}{\tilde{x}}) \theta(s-\tilde{x}) \dint{\tilde x} \\
    &= (\groupaction{g}{y_t} \star \theta)(s)= \groupaction{g}{(y_t \star \theta)}(s) \\
    &= \groupaction{g}{z_t}(s)= \groupaction{g}{f_{(\cdot)}(y_t)}(s),
\end{aligned}
\end{equation*}
where we have exploited the linearity of both the convolution operation and the group action in line four in order to exchange the operations.
As a consequence, we also obtain equivariance of the action of the Koopman operator. For any $y_0\in\Acal$ with $y_1=\Phi^\tau\in\Acal$, we find
\begin{equation*}
    \begin{aligned}
    \left(\Kcal^t f_{\invgroupaction{g}{s}}\right)(y_0) &= f_{\invgroupaction{g}{s}} \left(\Phi^t(y_0)\right) \\
    &= \groupaction{g}{f_{(\cdot)}\left(\Phi^t(y_0)\right)}(s) \\
    &= \groupaction{g}{\left(\Kcal^t f_{(\cdot)}\right)(y_0)}(s).
    \end{aligned}
\end{equation*}
\end{proof}
What follows is that the same Koopman operator can be applied to different observables $f_{s_1}$ and $f_{s_2}$, where $s_2-s_1 = a \in \R$. We can thus compute a Koopman operator for some $f_{s}$, and apply the same operator of a shifted version of $f_{s}$, which opens up the possibility to pursue \emph{domain decomposition} strategies as they are very common in finite element techniques or numerical solution approaches for PDEs in general. Moreover, we obtain the possibility to decouple the Koopman operator from a specific spatial domain $\Omega$. As long as we remain within domains with periodic boundary conditions, a transfer is possible in a simple and straightforward manner. Moreover, the equivariance can easily be extended to vector-valued convolution observables, cf.\ Remark \ref{rem:vector}.

\begin{remark}
    Related approaches for the exploitation of translational equivariance have been studied for reservoir computing \cite{PHG+18} and in the context of reinforcement learning \cite{PSC+23,VRV+23}.
\end{remark}

\section{Practical considerations and numerical examples}
In this section, we will compare local Koopman models $\Kcalhat^\tau$ -- obtained from $q$ point measurements located in a compact subset of $[0,L]$ (e.g., neighboring grid points in the discretization) -- to a global Koopman model $\Kcal^\tau$ which is obtained using the classical full state observable (i.e., we observe the entire numerical grid at once). As briefly mentioned above, these point measurements can be interpreted in terms of Eq.\ \eqref{eq:observable} by considering a Dirac delta function as the kernel. This way, we obtain 
\[ \begin{bmatrix} z_{t,1} = f_{x_1}(y_t)=y_t(x_1) & \ldots & z_{t,N} = y_t(x_N) \end{bmatrix}. \]

% Figure environment removed

We will compare these two models both regarding the Koopman spectrum and the prediction accuracy. In the latter case, Fig.\ \ref{fig:Koopman_Conv} (a) illustrates how the local models $\Kcal^\tau$ can be combined to a global model of repeating entries. Conceptually, we simply obtain a number of entirely independent predictors for subsections of $\Ycal$. As we always have to deal with approximations of $\Kcalhat^\tau$, it is clear that the approximate solution can quickly lead to inconsistencies with respect to the PDE state, for instance by developing artificial discontinuities. The question is therefore whether we can establish a link between the different local models. A first intuitive approach would be to simply consider overlapping domains. For instance -- considering the example of a local model of size three -- we can apply the same $\Kcalhat^\tau$ to $\Psi((z_1,z_2,z_3))$ and to $\Psi((z_2,z_3,z_4))$.
However, this means that we effectively obtain multiple predictors for the same quantity (in the previous example, $z_2$ and $z_3$ are contained in both models). While it is certainly possible to project each of the local systems back onto the coordinates $z$ and then use the average as the predictor, we would still not achieve a coupling between different model instances.
\begin{remark}
    In fact, if we were able to obtain an exact finite-dimensional approximation of $\Kcalhat^\tau$, then we would quickly run into inconsistencies, as the same matrix would be a predictor for $(z_1,z_2,z_3)$ and for $(z_2,z_3,z_4)$. A quick calculation then shows that the prediction of any $z_i$ can not depend on any other $z_j$, which would mean that $K^\tau$ is just a diagonal matrix. Our interpretation of this dilemma is that inconsistencies cannot be avoided, as in the generic situation, any finite-dimensional approximation is inexact, meaning that the local Koopman models have to be globally inconsistent or yield trivial dynamics.
\end{remark}
Instead, a coupling can be achieved in two different ways. The first option is to treat the connection between two neighboring models as it is done in the Dynamic Mode Decomposition with control (DMDc, \citet{PBK15}), meaning that using a slightly modified regression problem, we obtain a model of the form
\begin{equation}\label{eq:DMDc}
    \begin{aligned}
    \Psi((z_{t+\tau,2},z_{t+\tau,3},z_{t+\tau,4})^\top) &\approx \\ 
    \Khat^\tau \Psi((z_{t,2},z_{t,3},z_{t,4})^\top) &+ B_l z_{t,1} + B_r z_{t,5},
    \end{aligned}
\end{equation}
where the two terms $B_r, B_l\in\R^{q\times 1}$ are used to treat the left and right neighbors as control inputs to the dynamics.

As the above approach only works for control inputs that enter the original system in a purely linear fashion \cite{NPP+23}, an alternative approach is to accept that a purely linear approach may be too much to ask for. Instead, a coupling can be achieved by predicting the next state, project from $\Psi(z)$ onto the coordinates $z$, and then lift again for each system. Due to the project-then-lift step, we ``synchronize'' the local systems, at the cost of obtaining nonlinear dynamics. Note that if we use kernel EDMD, then this approach is very closely related to Gaussian Process models.

%However, as this may be numerically unstable and inconsistent if we only consider approximations of the Koopman operator, the second option is to use overlapping domains which -- in the extreme case -- only differ by a stride of one. This way, we can effectively reduce the regression problem to learning a single row of $\Kcalhat^\tau$ which we then 

\subsection{Numerical setup}
In the following, we will study the proposed approaches using the Kuramoto-Sivashinsky equation for two different parameter values $\mu>0$.
For the data generation process, we numerically solve \eqref{eq:KS} using the spectral Galerkin method implemented in the open source package \emph{shenfun} \cite{Mor18}. As a spatial discretization of $\Omega$, we use $N=32$ Fourier modes, which is equivalent to $N=32$ equidistant grid points, i.e., we have $\Delta x = \frac{L}{N} = \frac{\pi}{16}$. The time step for the PDE solver is $\Delta t=0.01$, and we set $\tau = 20\Delta t = 0.2$ for the traveling wave and $\tau = 5 \Delta t = 0.05$ for the bimodal fixed-point setting. We collect $M=1000$ samples from the attractor $\Acal$, which yields a sufficient coverage for the considered $\mu$ values.

In our experiments, we first compare the PDE solution to the approximation $K$ of the global Koopman operator $\Kcal$, where $f(y)=y$. We then compare this to local Koopman models $\Khat$ both in terms of the Koopman spectrum as well as regarding the prediction accuracy. 
For the latter, we construct a global model $\Ktilde$ from the local $\Khat$. We do so following both the classical approach (Fig.\ \ref{fig:Koopman_Conv} (a)) and the DMDc approach (Fig.\ \ref{fig:Koopman_Conv} (b)).
Following Theorem \ref{thm:embedding}, we study different embedding dimensions, where $q_w$ is the \emph{window width} (i.e., the number of neighboring points of the discretized PDE), $q_d$ is the number of delays, and the total dimension is $q=q_w\cdot q_d$. The global Koopman model $K$ is thus a special case of $\Khat$ where $q_w=N$. We will use standard DMD (i.e., $\Psi=\identity$) in all experiments.

\subsection{Traveling wave ($\mu=15$)}
At $\mu=15$, the system exhibits a traveling wave solution, as shown in Fig.\ \ref{fig:KS_mu15_PDE_vs_K}. As this is a very simple behavior, we do not study delay coordinates and set $q_d=1$, i.e., $q=q_w$. We see in Fig.\ \ref{fig:KS_mu15_PDE_vs_K} (bottom) that the DMD approximation (i.e., $\Psi=\identity$) is sufficient to yield accurate long-term predictions, even though a slow decay is visible after a while.
% Figure environment removed 
% Figure environment removed

We next compare $K$ and the local Koopman model $\Khat$ for different values of $q_w=q$, varying between $q=1$ and $q=16$, which is half of the domain. The corresponding spectra are compared in Fig.\ \ref{fig:KS_mu15_spectra}, and we observe a very good agreement for the leading eigenvalues (the lowest frequency corresponds to the frequency of the traveling wave).

The prediction of the state $y$ using the reconstructed Koopman operator $\Ktilde$ (according to Fig.\ \ref{fig:Koopman_Conv} (a)) is depicted in Fig.\ \ref{fig:KS_mu15_predictions}. As discussed before, the complete decoupling of the local models $\Khat$ yields globally inconsistent dynamics caused by small prediction errors. This is most evident for $q=4$ and $q=8$. At $q=16$, the approximation is sufficiently accurate that we do no longer observe this phenomenon. Interestingly, this decoherence is quite severe even though the one-step prediction error reaches a very small value already at $q=4$, cf.\ Fig.\ \ref{fig:KS_mu15_errors}.

% Figure environment removed

% Figure environment removed

% Figure environment removed

Unsurprisingly, the prediction accuracy improves massively when we build in a coupling term according to Fig.\ \ref{fig:Koopman_Conv} (b) and Eq.\ \eqref{eq:DMDc}. Using a single input from left and right, we obtain high-quality predictions using a very small linear system ($q=1$ and two inputs), see Fig.\ \ref{fig:KS_mu15_DMDc}.

\subsection{Bimodal fixed point ($\mu=18$)}
As a second system, we study the parameter $\mu=18$ which results in a ``checkerboard'' pattern. As the dynamics are now much more complex (due to the equivariance w.r.t.\ translations in space, the attractor consists of infinitely many checkerboard patterns), we here additionally consider $q_d=50$ delay observations. Using this higher-dimensional observable, many results from the previous case hold in a very similar fashion. Fig.\ \ref{fig:KS_mu18} shows a comparison of different approximations, more figures can be found in the appendix.
% Figure environment removed

\section{Conclusion}
We have presented two extensions to the current Koopman theory that deal with (i) the issue of not knowing the system's state space (i.e., using partial measurements, for instance from sensors) and (ii) the exploitation of symmetries when setting up Koopman-based surrogate models.
Regarding part (i), we have shown that there exists a close connection between the Koopman observable function $f$ and observation maps as they are defined in the embedding literature (Takens, Whitney, ...). If we observe sufficiently many points (more than two times the attractor dimension), then we can simply treat our measurements as if they have been generated by another dynamical system with state space $\R^q$, on which we can then use standard EDMD techniques. This yields rigorous criteria for the situation when building Koopman models exclusively from partial measurements.
For part (ii), we have then exploited this in order to simply use $q$ local measurements to build a local Koopman operator approximation.
Our numerical results show that including coupling terms (in the spirit of DMD with control) significantly increases the accuracy, even for very small model sizes.

\section{Acknowledgments}

S.P.\ and H.H.\ acknowledge financial support by the project ``SAIL: SustAInable Life-cycle of Intelligent Socio-Technical Systems'' (Grant ID NW21-059D), which is funded by the program ``Netzwerke 2021'' of the Ministry of Culture and Science of the State of Northrhine Westphalia, Germany. K.W.\ gratefully acknowledges funding by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -- Project-ID 507037103.

% Use \bibliography{yourbibfile} instead or the References section will not appear in your paper
\bibliography{references}


\appendix
\section{Appendix}
\subsection{Additional plots for $\mu=18$}
We here show the same figures as for the traveling wave solution at $\mu=15$. The key difference in the numerical approximation is that we now consider delay observables, i.e., $f$ consists of $q_d=50$ delays and varying numbers $q_w$ of observed grid nodes.
% Figure environment removed 
% Figure environment removed
% Figure environment removed
% Figure environment removed
% Figure environment removed

\end{document}