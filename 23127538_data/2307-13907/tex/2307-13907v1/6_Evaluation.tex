\section{Experimental Results and Evaluation}
\label{sec: Evaluation} The actual experimental results shown in this paper are conducted in a Windows-10 computer with the 64-bit operating system, Intel(R) Core(TM) i7-8850H processor, and 16 GB RAM.

For all four noise scenarios [Sec.~\ref{Noise Types}], local and global (for 100 consecutive time steps) robustness properties are considered for both datasets. The local monotonicity property is only considered for the turbine RUL estimation example.

\paragraph{\textbf{Battery State-of-Charge Dataset (BSOC)}:}
In this dataset, the output value (SOC) is supposed to be any value between 0 and 1 (or 0 and 100$\%$). But, for the instances where the lower bound is negative, we instead treat it as 0 because a negative SOC does not provide any meaningful implications. 

For SFSI, for a random (here feature 3) input feature-signal, the noise is added only at the last time step ($t_{30}$) of the 3rd feature, whereas for SFAI, noise is added throughout all the time instances of the input signal. The effect of four different noise values, 1$\%$, 2.5$\%$, 5$\%$ and 10$\%$ of the mean($\mu$), are then evaluated using over-approximate star reachability analysis [Sec.~\ref{Sec:Reachability}] on 100 consecutive input signal, each with 30 time instances. We considered $\pm 5\%$ around the actual SOC value as the allowable bounds. For all the noises, 2 different robustness values, PR [Def.~\ref{def:PSR}] and POR [(Def.~\ref{def:POR}] are then calculated, and comparative tables are shown below in Table~\ref{tab:Table2}. 
% \vspace*{-\baselineskip}
% Figure environment removed
\begin{table}[h!]
    \caption{Global Robustness: Percentage Robustness(PR) for noises for 100 consecutive time steps}
    \label{tab:Table2}
    \centering 
    \begin{tabular}{ccccccc}
    \toprule
    \centering
    $noise$ & $PR_{SFSI}$ & $POR_{SFSI}$ & $avgRT_{SFSI}(s)$ & $PR_{SFAI}$ & $POR_{SFAI}$ & $avgRT_{SFAI}(s)$\\ 
    \hline 
    1 & 100 & 100 & 0.7080 & 100 & 100 & 20.9268\\ 
    2.5 & 100 & 100 & 0.7080 & 100 & 100 & 20.9991\\
    5 & 100 & 100 & 0.7116 & 100 & 100 & 21.0729\\
    10 & 100 & 100 & 0.7027 & 100 & 100 & 21.0780\\
    \hline 
    \end{tabular}
    \begin{tabular}{ccccccc}
    \toprule
    \centering
    $noise$ & $PR_{MFSI}$ & $POR_{MFSI}$ & $avgRT_{MFSI}(s)$ & $PR_{MFAI}$ & $POR_{MFAI}$ & $avgRT_{MFAI}(s)$\\ 
    \hline 
    1 & 100 & 100 & 0.7653 & 100 & 100 & 36.1723\\ 
    2.5 & 0  & 73.87 & 0.8251 & 0  & 73.87 & 59.0588\\
    5 & 0 & 35.95 & 0.9026 & 0 & 35.95 & 91.6481\\
    10 & 0 & 17.89 & 1.1051 & 0 & 17.89 & 163.7568\\
    \hline 
    \end{tabular}
    % \vspace*{-\baselineskip}
\end{table}
% Figure environment removed
\vspace*{-\baselineskip}
\subsubsection{Observation and Analysis:}
Fig.~\ref{fig:BSOCBounds} shows a sample plot for gradually increasing estimation bounds with increasing MFSI noise. We can see from the figure that for each time instance, the system becomes locally non-robust as the noise value increases.

Table.~\ref{tab:Table2} presents the network's overall performance, i.e., \newblue{the percentage robustness measures, PR [Def.~\ref{def:PSR}], POR [Def.~\ref{def:POR}] and average verification runtime (avgRT)}, with respect to each noise. The percentage robustness values start decreasing and the average (as well as total) runtime starts increasing as the measure of noise increases for MFAI and MFSI, but for SFSI and SFAI it remains the same for these noise perturbations considered. This is because in the first case, the noise is added to all the features, resulting in increasing the cumulative effect of disturbance on the output estimation. However, in the other case, the noise is attached only to a single feature, assuming that not all features will get polluted by noise simultaneously; and that the reachable bounds are in the acceptable range. A plot of robustness values and the total runtime is shown in Fig~\ref{fig:SOCRobustnessplot}.

We can also see that the decrease in POR values for MFSI and MFAI are less compared to the PR values with increasing noise because, for PR calculation, only those time steps are considered where the estimated range falls entirely within the allowed range, whereas for POR calculation even if some part of the estimated range goes outside the allowable range, their fractional contribution is still considered.

Another interesting observation here is the robustness matrices for both SFSI and SFAI are the same; however, the computations for SFAI take almost three times longer than the computations for SFSI. The same analogy is observed for MFSI and MFAI datasets but with an even higher time taken for MFAI. The possible reason for this observation could be that, while the data is subjected to perturbations across all time instances, the noise added to the final time step has the most significant impact on the output.

\paragraph{ \textbf{Turbofan Engine Degradation Simulation Data Set (TEDS)}:}
 In this dataset, the acceptable RUL bounds are considered to be $\pm 10$ of the actual RUL. For instances where the lower bound is negative, we assume those values to be 0 as well. We then calculate the percentage robustness measures, PR [Def.\ref{def:PSR}], POR [Def.\ref{def:POR}], and \newblue{average verification runtime (avgRT)}, for an input set with all 100 consecutive data points, each having 30 time instances. The results for three different noise values, $0.1\%$, $0.5\%$, and $1\%$ of the mean ($\mu$), are presented in Table~\ref{tab:Table4}. For SFSI and SFAI noises, we randomly choose a feature (feature 7, representing sensor 2) for noise addition. The noise is added to the last time step ($t_{30}$) of each data sample for SFSI and SFAI noises. The results of the MFAI noise have been omitted due to scalability issues, as it is computationally heavy and time-consuming \footnote{\newblue{The MFAI noise, i.e., adding the $L_\infty$ norm to all feature values across all time instances, significantly increases the input-set size compared to other noise types. This leads to computationally expensive calculations for layer-wise reachability, resulting in longer run times. Moreover, noise in an industrial setting affecting all features over an extended period is unlikely. Considering these factors, we decided to exclude the results of the MFAI noise for the TEDS dataset from our analysis.}}.
 
For verifying the local monotonicity of the estimated output RUL bounds at a particular time instance, we have fitted the previous RUL bounds along with the estimated one in a linear equation as shown in Fig. \ref{fig:localmonotonicity}. This guarantees the monotonically decreasing nature of the estimated RUL at any time-instance.
\vspace*{-\baselineskip}
% Figure environment removed
\vspace*{-\baselineskip}
\begin{table}[h!]
    \caption{Global Robustness: Percentage Robustness(PR) for noises for 100 consecutive time steps}
    \label{tab:Table4}
    \centering 
    \begin{tabular}{ccccccc}
    \toprule
    \centering
    $noise$ & $PR_{SFSI}$ & $POR_{SFSI}$ & $avgRT_{SFSI}(s)$ & $PR_{SFAI}$ & $POR_{SFAI}$ & $avgRT_{SFAI}(s)$\\ 
    \hline 
    1 & 13 & 13 & 1.0796 & 13 & 13.31 & 32.8670\\ 
    2.5 & 13 & 13 & 1.1755 & 12 & 13.13 & 62.1483\\
    5 & 13 & 13 & 1.2908 & 8 & 12.64 & 108.0736\\
    % 10 & 100 & 100 & 0.7027 & 100 & 100 & 21.0780\\
    \hline 
    \end{tabular}
    \begin{tabular}{ccccccc}
    \toprule
    \centering
    $noise$ & $PR_{MFSI}$ & $POR_{MFSI}$ & $avgRT_{MFSI}(s)$ \\%& $PR_{MFAI}$ & $POR_{MFAI}$ & $avgRT_{MFAI}(s)$\\ 
    \hline 
    1 & 13 & 13 & 9.6567 \\%& 100 & 100 & 36.1723 
    2.5 & 13  & 13 & 10.2540 \\%& 0  & 73.87 & 59.0588
    5 & 13 & 13 & 11.2100 \\%& 0 & 35.95 & 91.6481
    % 10 & 0 & 17.89 & 1.1051 & 0 & 17.89 & 163.7568\\
    \hline 
    \end{tabular}
    \vspace*{-\baselineskip}
    \vspace*{-\baselineskip}
\end{table}
\vspace*{-\baselineskip}
% \vspace*{-\baselineskip}
% Figure environment removed
\vspace*{-\baselineskip}
\subsubsection{Observation and Analysis:}Fig.~\ref{fig:RULBounds} shows a sample plot for gradually increasing estimation bounds with increasing SFAI noise. Here we need to notice that the network's performance in terms of following the actual RUL value is not well. However, Table.~\ref{tab:Table4} presents the network's overall performance with respect to each noise. Contrary to the other dataset, we see that the percentage robustness measures corresponding to SFAI and SFSI noises differ. Interestingly, while the noise value increases, the PR, and POR for SFSI remain the same, whereas the robustness measures for SFAI decrease. However, the performance matrices for MFSI are the same as the SFSI except for the time. This might be because, for both SFSI and MFSI, the noise is added only at a single time instance, whereas for SFAI, the noise is added to the entire time instances, resulting in an increased cumulative effect of disturbance on the output. 

\newblue{Our results consistently show higher POR values than PR values in Table. [\ref{tab:Table2}-\ref{tab:Table4}]. Since we assess output reachable bounds using $L_\infty$ perturbations in the input, we acknowledge the significance of cases where reachable sets overlap with permissible bounds but do not entirely fall within them. In summary, PR measures adopt a more conservative approach, while POR captures the relationship between output reachable bounds and permissible bounds more accurately.}