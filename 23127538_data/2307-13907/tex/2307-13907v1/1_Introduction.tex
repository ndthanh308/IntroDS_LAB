\section{Introduction}
\label{sec: Introduction}

% \todo{\diego{FORMATS has a limit of 15 pages (not including references), keep that in mind}}

Over time, Deep Neural Networks (DNNs) have shown tremendous potential in solving complex tasks, such as image  classification, face detection, object detection, speech recognition, natural language processing, document analysis, etc., sometimes even outperforming humans\cite{lawrence1997face,krizhevsky2012imagenet,lecun1998gradient}. This has motivated a spurt in investigating the applicability of DNNs in numerous real-world  applications, such as biometrics authentication, face authentication for mobile locking systems, malware detection, different bioinformatics applications, etc. In dealing with such susceptible information in these critical areas, safety, security, and verification thereof have become essential design considerations.

Unfortunately, it has been demonstrated that state-of-the-art well-trained networks can be easily deceived by minimal perturbations in the input leading to erroneous predictions \cite{moosavi2016deepfool,LBFGS,goodfellow2014explaining}. The most researched domain for verification of such networks involves image inputs, particularly safety and robustness checking of various classification neural networks \cite{tran2021robustness,anderson2019optimization,botoeva2020efficient,katz2019marabou,mohapatra2020towards,tran2020verification}. Previous research has analyzed feed-forward neural networks (FFNN\cite{tran2019star}), convolutional neural networks (CNN\cite{tran2020verification}), and semantic segmentation networks (SSN\cite{tran2021robustness}) using different set-based reachability tools, such as Neural Network Verification (NNV\cite{tran2020nnv, lopez2023nnv}) and JuliaReach \cite{bogomolov2019juliareach}, among others. 

Input perturbations are not only confined to image-based networks but also have been extended to other input types, including time series data or input signals with different noises in predictive maintenance applications \cite{delillo1999white,truax1999handbook}. One such use case is in the manufacturing industry, where data from process systems, such as IoT sensors and industrial machines, are stored for future analysis \cite{semenick2000time,ferguson1965time}. Data analytics in this context provide insights and statistical information and can be used to diagnose past behavior \cite{zhang2021fault,lv2017weighted}, and predicts future behavior \cite{susto2016dealing,borgi2017data,lin2019time}, maximizing industry production. This application is not only limited to manufacturing, but is also relevant in fields like healthcare digitalization \cite{zeger2006time,touloumi2004analysis} and smart cities \cite{stubinger2020understanding,soomro2019smart}. Noisy input data, here, refers to data containing errors, uncertainties, or disturbances, caused by factors like sensor measurement errors, environmental variations, or other noise sources.
% A time series is a collection of observations of a specific process over time, where the time steps are generally equally spaced (time unit being: minutes, hours, days, weeks, months, etc. and in some cases small deviations in time intervals are acceptable).

While NN applications with image data have received significant attention, little work has been done in the domain of regression-type model verification, particularly with time series data in predictive maintenance applications. Regression-based models with noisy data are crucial for learning data representations and predicting future values, enabling fault prediction and anomaly detection in high-confidence, safety-critical systems \cite{de2022anomaly, kauffman2021palisade}. This motivated us to use verification techniques to validate the output of regression networks and ensure that the output(s) fall within a specific safe and acceptable range.
 


\paragraph*{Contributions.}
\begin{enumerate}
    \item \newblue{In this paper, we primarily focus on exploring a new case study, specifically examining time-series-based neural networks in two distinct industrial predictive maintenance application domains. We utilize the established concept of star-set-based reachability methods to analyze whether the upper and lower bounds of the output set adhere to industrial guidelines' permissible bounds.} We develop our work\footnote{The code is available at: \url{https://github.com/Neelanjana314/nnv/tree/master/code/nnv/examples/Submission/FMCIS2023}} as an extension of the NNV tool to formally analyze and explore regression-based NN verification for time series data using sound and deterministic reachability methods and experiment on different discrete time signals to check if the output lies within pre-defined safe bounds.
    \item \newblue{Another significant contribution of our work is the flexibility of variable-length inputs in neural networks. This approach simplifies input manipulation and enhances the generalizability of network architectures. Unlike published literature that relied on fixed-sized windows \cite{ForMuLA, muller2022third}, which necessitated preprocessing and experimenting with window sizes, our method allows for flexibility in utilizing any sequence length. This flexibility improves the generalizability of reachability analysis.}
    \item We run an extensive evaluation on two different network architectures in two different predictive maintenance use cases. \newblue{In terms of evaluation, we have introduced a novel robustness measure called Percentage Overlap Robustness (POR). Unlike the existing Percentage Sample Robustness (PR/PSR) \cite{tran2021robustness}, which considers only instances where reachable bounds remain entirely within permissible bounds, the proposed POR accounts for all instances with overlap.}
    \item Finally, we develop insights on evaluating the reachability analysis on those networks and possible future direction.
\end{enumerate}

\paragraph*{Outline.} 
The paper is organized as follows:
Section \ref{sec: Preliminaries} provides the necessary context for the background; Section \ref{Sec: Advnoise} details the adversarial noises; Section \ref{Sec: VerProp} defines the verification properties; Section \ref{Sec:ReachabilityLayers} explains the reachability calculations for layers to accommodate variable-length input; Section \ref{sec: problem} defines the research problem, and Section \ref{sec: Experimental Setup} describes the methodology, including dataset, network models, and input attacks. Section \ref{sec: Evaluation} presents the experimental results, evaluation metrics, and their implications. Finally, Section \ref{sec: Conclusion and Future Work} summarizes the main findings and suggests future research directions.