\textbf{Data preprocessing.} The Romanian Academic Word List, with words from the ROMBAC corpus, provides the lowercase lemma for each word in the corpus and its frequency. Therefore, no preprocessing step was done on this data. Even if we use the word frequencies from the Romanian Academic Word List, we will refer to this data as the ROMBAC corpus, given that the list contains all the words from ROMBAC.

The EXPRES corpus is organised in multiple .txt files, one for each article from the four domains LG, IT, PS, and EC. For each document, we removed specific tags used for article anonymisation, such as {JOURNAL\_TITLE}, {AUTHOR\_NAME}, etc., and the specific XML tags used to mark the beginning or end of the title ($<$TITLE$>$, $<$/TITLE$>$), abstract ($<$ABS\_INT$>$, $<$/ABS\_INT$>$), or different sections of the article ($<$INTROD$>$, $<$/INTROD$>$), etc. The EXPRES corpus statistics regarding the words and word types in the corpora are shown in Table \ref{tab:expres}. For preprocessing the text, we used Stanza \cite{qi2020stanza} for lemmatising and extracting part-of-speech tags. All the lemmas from the texts are transformed into lowercase. The Stanza toolkit was chosen for its good performance for the Romanian language, compared to other NLP tools \cite{pais2021depth}. However, we performed a manual analysis of the extracted lemmas and observed that some of them are incorrect: “sociales” instead of “social” ( En: “social”), “europes” instead of “european” (En: “European”), and others. Even if previous works have shown a good performance of the Stanza toolkit for lemmatisation in the Romanian language \cite{pais2021depth}, we chose to use the lemmas from the ROMBAC corpora for the words that appear in ROMBAC. We used Stanza only for extracting the lemma of words that were not part of ROMBAC. This way, the noise of lemmatisation was diminished, as the lemmas provided in the ROMBAC corpus were accurate and have been previously validated \cite{ion2012rombac}. 

\textbf{Building the academic word list.} For constructing the academic word list, we follow the methodology for building the Academic Vocabulary List for the English language \cite{gardner2014new}, comprising different frequency measures for lemmas. We chose to use the methodology from \citet{gardner2014new} instead of the procedure from \citet{coxhead2000new} because the former method provides an academic list with almost twice the latter's coverage. The approach from \citet{coxhead2000new} is based on word families, while the method from \citet{gardner2014new} relies on lemmas. A word family is represented by the base word from which other words are derived with suffixes and prefixes. This can be problematic in the case of academic words, as the base of a word family can be an academic word, but their derivations might not be academic \cite{gardner2014new}.

The methodology is based on four measures: ratio, range, dispersion and discipline measure. The ratio is used to exclude general high-frequency words from the corpus, while the other three metrics exclude technical or discipline-specific terms. We further expand on each metric below.

\textbf{Ratio.} Similar to \citet{gardner2014new}, general high-frequency words (in our case, lemmas) are removed from the academic word list. The ratio is computed to keep in the list words with a higher frequency in the academic corpus than in the general non-academic corpus. We computed the normalised frequency per million words of each word in the two corpora, EXPRES and ROMBAC. The ratio is calculated by dividing the academic corpus's normalised frequency by the general corpus's normalised frequency for each word. \citet{gardner2014new} use the frequency ratio of 1.5 in their method, but mention that the measure is not a gold standard. We experimented with values between 1.2 and 2.0 for ratio, and, in our case, the 1.2 ratio was a suitable value, to not have important academic words excluded from our list, such as “metodologic" (En: “methodological"), “clasificare" (En: “classification"), “activitate" (En: “activity"), “distinge" (En: “distinguish"), “sugera" (En: “suggest"), which are found in the original AVL for the English language.

\textbf{Range.} The range measure allows for selecting words that only occur in multiple disciplines, and filtering out discipline-specific words. \citet{gardner2014new} proposed that a word should have at least 20\% of the expected frequency in 78\% of the sub-corpora (i.e. 7 out of 9 domains). For computing the expected frequency, we first calculated each word’s frequency in relation to the corpus by dividing the word count by the total number of words in EXPRES. Afterwards, the frequency in relation to the corpus is multiplied by the number of words in a given sub-corpora to get the expected frequency in each sub-corpora.
In our case, EXPRES has only four domains, and we chose words that had at least 20\% of the expected frequency in at least three out of four fields, corresponding to 75\% of sub-corpora.

\textbf{Dispersion.} The measure used for dispersion is Julliand's D \cite{juilland2021frequency}, which shows how evenly a word appears in a corpus. The formula is as follows:

\vspace{3mm}
$Juilland's D = 1 - \frac{\sigma }{\bar{x}}\times \frac{1}{\sqrt{n-1}}$
\vspace{3mm}

where $\sigma$ represents the standard deviation and $\bar{x}$ represents the mean frequency of a word. $n$ is the number of sub-corpora.

The values of dispersion range from 0.01 (corresponding to words that appear in a small part of the corpus) to 1.00 (meaning that a word is spread evenly in the corpus). Unlike the range measure, which estimates if a word has the expected frequency in the four domains, the dispersion measure ensures that a given word is distributed uniformly in the four sub-corpora. \citet{gardner2014new} chose 0.80 dispersion, while, in other works, the dispersion measure varies between 0.30 to 0.60 \cite{oakes2006use,johannessen2016constructing,lei2016new}. We decided to use a dispersion value of 0.50 in our work.

\textbf{Discipline measure.} This measure is used for filtering out words with a very high frequency in a given domain, which may be technical discipline-specific words. \citet{gardner2014new} proposed that a word cannot have more than three times the expected frequency in any domain. Following a similar approach, we remove words with more than three times the expected frequency in any of the four domains.

As an additional measure, we excluded words with low frequency in the academic corpus, because the metrics mentioned above do not filter them out. Inspired by \citet{coxhead2000new} and \citet{lei2016new}, we remove from the final academic list the words that have a minimum frequency of 28.57 per million words, corresponding to the minimum frequency originally proposed by \citet{coxhead2000new} of 100 times in the 3.5 million words corpus they used in their work. We also performed a manual analysis of the academic word list and removed the noise, such as proper nouns (e.g., “București”, En: “Bucharest”), some numerals, and some words that were not academic and that were not filtered out by the measures mentioned above.





