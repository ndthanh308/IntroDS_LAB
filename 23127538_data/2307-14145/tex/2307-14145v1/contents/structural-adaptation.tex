
\section{Model Structure Adaptation}\label{sec:structural-adaptation}

In section~\ref{sec:one-solutiona-approach}, we touched upon the notion that FE minimization should ideally drive the generative model $p$ to evolve to structurally segregated but communicating sub-models that reflect the causal structure of the environment. Technically, this is due to the drive for a lower surprise ($-\log p(x)$).

There is another reason why online structural adaptation is important. Free energy minimization over the structure of $p$ should also lead to a model structure for which inference costs $D_{\text{KL}}[q(z)|| p(z|x)]$ are lower by moving $p(z|x)$ closer to $q(z)$. Consider again the procedural and reactive inference code in Fig.~\ref{fig:AIF-algorithms}. The control flow in the procedural code aims to cleverly steer the inference process toward maximal inference accuracy for minimal computational costs. In contrast, the reactive code just declares that the system should react (by message passing) to any FE minimization opportunity. In the reactive framework, \emph{clever} inference is learned over time by continual minimization over all movable parts of the CBFE, i.e., by FEM over states, parameters, structure (adaptation of $p$), and constraints (adaptation of the structure of $q$). To learn the most effective paths for inference, the toolbox should support structural adaptation over both $p$ and $q$. 

%In short, there are multiple reasons why we should demand that our AIF toolbox supports slow, continual structural adaptation of the generative model. 

Unfortunately, online structural adaptation during the deployment of the robot is still an ongoing research issue, e.g., \cite{friston_bayesian_2018, loeliger_sparsity_2016, beckers_principled_2022}. One technical difficulty is that an efficient inference control flow (which states are updated at what time, etc.) may change if the structure of the generative model changes. In a procedural programming style, we would need to reset the system and reprogram the inference code in Algorithm-1 (in Fig.~\ref{fig:AIF-algorithms}). This is incompatible with the demand that the agent adapts during deployment. As discussed above, a reactive programming style solves this issue since the application inference code (Algorithm-2 in Fig.~\ref{fig:AIF-algorithms}) is independent of the model structure.   


%Hence, we demand that our toolbox supports simultaneous and continual inference over multiple temporal abstraction levels, including fhttps://www.overleaf.com/project/646486ae97ed6e28fbb7798bast updating for states (measured in milliseconds to seconds), slower updating for parameters (seconds to days), and even slower model structure adaptation (days to weeks). %In principle, yet even slower updating of prior preferences can be considered. 


%In principle, we distinguish at least four levels of  in an AIF agent. Inference for internal and active states relates to executing the perceptual and control tasks, respectively. If the model's predictions for sensory inputs are inaccurate, then state inference will also be inaccurate and the intended (perceptual or control) task will not be executed well. An active inference agent corrects this problem automatically by extending FE minimization to the states of the next higher abstraction layer in a hierarchical model structure. This process of extending FE minimization to the states in the next higher layer if prediction errors continue to be present, continues until all layers are actively updating their states. At the lowest layer, state adaptation would likely proceed over a time span of milliseconds, whereas in the highest layer, the adaptation rate would be measured in hours to days. Technically, we often call the states of higher layers the ``parameters'' of the model. If these parameter update processes in the higher layers would still not lead to sufficient model prediction accuracy, then an active inference agent (ought to) improve automatically by extending FE minimization to its generative model structure $p$, for instance by extending the number of layers and columns in the model. In this way, an active inference agent systematically and incrementally improves the performance of its intended task to the desired accuracy levels as time passes. 

%The prior for desired behavior should be less adaptable than the generative model. 
 


