\section{Introduction}

Designing efficient algorithms to multiply two matrices is an ongoing research topic, due to its wide applications. The research originates from Strassen~\cite{Strassen69} in 1969, and the known fastest algorithm was proposed by Duan, Wu, and Zhou~\cite{DuanWZ23} in 2023, with time complexity $O(n^{2.37188})$, where $n$ is the row- and column-dimensions of the matrices. Although the best known algorithm for matrix multiplication is still super-quadratic, verifying  whether the product of two matrices is equal to a given matrix can be done more efficiently. Freivalds~\cite{Freivalds77} proposed a randomized algorithm that verifies with high probability whether $AB=C$, for given matrices $A$, $B$, and $C$. In Freivalds' algorithm, a vector $\vectorbold{v}$ is chosen at random, and the result of whether $A(B\vectorbold{v})=C\vectorbold{v}$ is reported. Clearly, Freivalds' algorithm has one-sided error; namely the answer may be false-positive. Nevertheless, there are only $O(n^2)$ operations needed. 
% Since then, the study of ``certifying algorithms'' for matrix multiplication was initiated. 

\medskip
It is still unknown whether Freivalds' algorithm can be efficiently derandomized~\cite{GkasieniecLLPT17}. An immediate attempt for derandomizing Freivalds' algorithm is to choose a vector $\vectorbold{x}$ of the form $(1, x, x^2, \dots, x^n)$. Then $AB\vectorbold{x}-C\vectorbold{x}$ consists of $n$ polynomials in $x$. The problem reduces to determining whether the nonzero polynomials are all zero at ${x}$. If $x$ is chosen as a non-root to all nonzero polynomials, then the modified algorithm verifies whether $AB=C$ deterministically. However, even though such an $x$ can be found, for example, by applying Cauchy's bound, one needs to manipulate numbers which are exponentially large. This makes the algorithm impractical. Related discussion can be found in~\cite{GkasieniecLLPT17,IvJi14}. 

\medskip
Recently, G{\k{a}}sieniec et al.~\cite{GkasieniecLLPT17} showed that, if the matrix $C$ has at most $k$ erroneous entries, then these entries can be identified and also corrected in deterministic  $\tilde{O}(kn^2)$ time, where $\tilde{O}(\cdot)$ suppresses polylogarithmic terms in $n$ and $k$. Their approach resembles methods from combinatorial group testing~\cite{DuHwang99}. Based on the same concept, randomized algorithms were also developed for $k$ equal to the number of erroneous entries. When the number of erroneous entries is not known, they applied the technique of compressed matrix multiplication~\cite{Pagh13}, and developed a randomized algorithm which runs in $\tilde{O}(n^2+kn)$ time. Note that the algorithms of G{\k{a}}sieniec et al. applies for matrix multiplications over any ring. For matrix multiplications over the ring of integers, Kutzkov~\cite{kutzkov} developed a deterministic algorithm running in $O(n^2 +k^2 n \log^5 n)$ time; K\"{u}nnemann~\cite{Kunnemann18} proposed an ${O}(\sqrt{k}n^2\log^{2+o(1)} n+k^2\log^{3+o(1)}n)$-time deterministic algorithm, given that the absolute values of the input integers are upper bounded by $n^c$ for some constant $c$.   


\medskip
In this paper, we are also concerned with the problem of correcting $C$ to be the product of $A$ and $B$, where $A$, $B$, and $C$ are three $n\times n$ matrices with $C$ different from $AB$ by at most $k$ entries. The matrix multiplication is restricted to be over the ring of integers. We develop a deterministic algorithm, which runs in $O(\sqrt{k}n^2+k^2n)$ time. 
Our algorithm is purely combinatorial; i.e. it does not rely on fast matrix multiplications or other well-developed subroutines. The idea is inherited from  G{\k{a}}sieniec et al.~\cite{GkasieniecLLPT17}, based on combinatorial group testing. This can also be viewed as an extension of Freivalds' algorithm; a number of vectors $\vectorbold{x}_1, \vectorbold{x}_2, \dots, \vectorbold{x}_m$ are chosen, and the erroneous entries are identified and corrected based on the result of $(AB-C)(\vectorbold{x}_1\mid  \vectorbold{x}_2\mid  \dots\mid \vectorbold{x}_m)$. 

\medskip
We note here that the values manipulated by the algorithm are of $O(\alpha^2n^3)$, where $\alpha$ is the largest absolute value of an entry in the input matrices. All values to manipulate are in a reasonable range, namely polynomial in both $n$ and the input values. In the remainder of this paper, 
we summarize necessary tools in Section~\ref{sec:pre}, and then give the algorithm in Section~\ref{sec:main}.

% To verify: What is the largest number used by K\"{u}nnemann during his computation? (at least $2^dn^2$, the time complexity is also at least $O(2^dn^2(\log d+\log n))$, where $d$ is the exponent for which the largest number in $A$, $B$, and $C$ is at most $n^{d-1}$. 


% Since then, Freivalds' algorithm has become one of the main building blocks that verifies the correctness of large-scale matrix multiplications and several computational linear algebra problems, whose error sources may include software bugs, hardware logical errors, faulty communication, etc. See~\cite{DumasHPR19,GkasieniecLLPT17,KaltofenNS11,Roche18} for example.

 

% It is still unknown whether Freivalds' algorithm can be efficiently derandomized~\cite{GkasieniecLLPT17}, though the number of random bits required can be reduced from linear to logarithmic~\cite{ChenK97,KimbrelS93,NaorN93} and the failure probability can be greatly reduced at no cost of running time~\cite{JiMascagniLi20}. However,  


 % The efficiencies of known results are guaranteed either by assuming $\alpha\in O(n^c)$ for some constant $c$, or by assuming the capability of manipulating integers whose values are exponentially large in $\alpha$. We make no assumption on the input integers, and