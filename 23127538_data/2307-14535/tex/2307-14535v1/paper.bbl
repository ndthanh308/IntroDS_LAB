\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Song et~al.(2020)Song, Zeng, Lee, and Funkhouser]{song2020grasping}
S.~Song, A.~Zeng, J.~Lee, and T.~Funkhouser.
\newblock Grasping in the wild: Learning 6dof closed-loop grasping from
  low-cost demonstrations.
\newblock \emph{IEEE Robotics and Automation Letters}, 5\penalty0 (3):\penalty0
  4978--4985, 2020.

\bibitem[Zhao et~al.(2023)Zhao, Kumar, Levine, and Finn]{zhao2023learning}
T.~Z. Zhao, V.~Kumar, S.~Levine, and C.~Finn.
\newblock Learning fine-grained bimanual manipulation with low-cost hardware.
\newblock \emph{arXiv preprint arXiv:2304.13705}, 2023.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012mujoco}
E.~Todorov, T.~Erez, and Y.~Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pages 5026--5033. IEEE, 2012.
\newblock \doi{10.1109/IROS.2012.6386109}.

\bibitem[Zhu et~al.(2020)Zhu, Wong, Mandlekar, and
  Mart{\'\i}n-Mart{\'\i}n]{zhu2020robosuite}
Y.~Zhu, J.~Wong, A.~Mandlekar, and R.~Mart{\'\i}n-Mart{\'\i}n.
\newblock robosuite: A modular simulation framework and benchmark for robot
  learning.
\newblock \emph{arXiv preprint arXiv:2009.12293}, 2020.

\bibitem[Nair et~al.(2022)Nair, Rajeswaran, Kumar, Finn, and
  Gupta]{nair2022r3m}
S.~Nair, A.~Rajeswaran, V.~Kumar, C.~Finn, and A.~Gupta.
\newblock R3m: A universal visual representation for robot manipulation.
\newblock \emph{arXiv preprint arXiv:2203.12601}, 2022.

\bibitem[Grauman et~al.(2022)Grauman, Westbury, Byrne, Chavis, Furnari,
  Girdhar, Hamburger, Jiang, Liu, Liu, et~al.]{grauman2022ego4d}
K.~Grauman, A.~Westbury, E.~Byrne, Z.~Chavis, A.~Furnari, R.~Girdhar,
  J.~Hamburger, H.~Jiang, M.~Liu, X.~Liu, et~al.
\newblock Ego4d: Around the world in 3,000 hours of egocentric video.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 18995--19012, 2022.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{fu2020d4rl}
J.~Fu, A.~Kumar, O.~Nachum, G.~Tucker, and S.~Levine.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2004.07219}, 2020.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{levine2020offline}
S.~Levine, A.~Kumar, G.~Tucker, and J.~Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on
  open problems.
\newblock \emph{arXiv preprint arXiv:2005.01643}, 2020.

\bibitem[Florence et~al.(2021)Florence, Lynch, Zeng, Ramirez, Wahid, Downs,
  Wong, Lee, Mordatch, and Tompson]{florence2021implicit}
P.~Florence, C.~Lynch, A.~Zeng, O.~Ramirez, A.~Wahid, L.~Downs, A.~Wong,
  J.~Lee, I.~Mordatch, and J.~Tompson.
\newblock Implicit behavioral cloning.
\newblock \emph{Conference on Robot Learning (CoRL)}, November 2021.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel,
  Srinivas, and Mordatch]{chen2021decision}
L.~Chen, K.~Lu, A.~Rajeswaran, K.~Lee, A.~Grover, M.~Laskin, P.~Abbeel,
  A.~Srinivas, and I.~Mordatch.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 15084--15097, 2021.

\bibitem[Zhu et~al.(2022)Zhu, Joshi, Stone, and Zhu]{zhu2022viola}
Y.~Zhu, A.~Joshi, P.~Stone, and Y.~Zhu.
\newblock Viola: Imitation learning for vision-based manipulation with object
  proposal priors.
\newblock \emph{6th Annual Conference on Robot Learning (CoRL)}, 2022.

\bibitem[Wu et~al.(2020)Wu, Sun, Zeng, Song, Lee, Rusinkiewicz, and
  Funkhouser]{wu2020spatial}
J.~Wu, X.~Sun, A.~Zeng, S.~Song, J.~Lee, S.~Rusinkiewicz, and T.~Funkhouser.
\newblock Spatial action maps for mobile manipulation.
\newblock \emph{arXiv preprint arXiv:2004.09141}, 2020.

\bibitem[Shridhar et~al.(2022)Shridhar, Manuelli, and Fox]{shridhar2022peract}
M.~Shridhar, L.~Manuelli, and D.~Fox.
\newblock Perceiver-actor: A multi-task transformer for robotic manipulation.
\newblock In \emph{Proceedings of the 6th Conference on Robot Learning (CoRL)},
  2022.

\bibitem[Shridhar et~al.(2021)Shridhar, Manuelli, and Fox]{shridhar2021cliport}
M.~Shridhar, L.~Manuelli, and D.~Fox.
\newblock Cliport: What and where pathways for robotic manipulation.
\newblock In \emph{Proceedings of the 5th Conference on Robot Learning (CoRL)},
  2021.

\bibitem[Zeng et~al.(2021)Zeng, Florence, Tompson, Welker, Chien, Attarian,
  Armstrong, Krasin, Duong, Sindhwani, et~al.]{zeng2021transporter}
A.~Zeng, P.~Florence, J.~Tompson, S.~Welker, J.~Chien, M.~Attarian,
  T.~Armstrong, I.~Krasin, D.~Duong, V.~Sindhwani, et~al.
\newblock Transporter networks: Rearranging the visual world for robotic
  manipulation.
\newblock In \emph{Conference on Robot Learning}, pages 726--747. PMLR, 2021.

\bibitem[Chi et~al.(2023)Chi, Feng, Du, Xu, Cousineau, Burchfiel, and
  Song]{chi2023diffusionpolicy}
C.~Chi, S.~Feng, Y.~Du, Z.~Xu, E.~Cousineau, B.~Burchfiel, and S.~Song.
\newblock Diffusion policy: Visuomotor policy learning via action diffusion.
\newblock In \emph{Proceedings of Robotics: Science and Systems (RSS)}, 2023.

\bibitem[Lynch and Sermanet(2020)]{lynch2020language}
C.~Lynch and P.~Sermanet.
\newblock Language conditioned imitation learning over unstructured data.
\newblock \emph{arXiv preprint arXiv:2005.07648}, 2020.

\bibitem[Stepputtis et~al.(2020)Stepputtis, Campbell, Phielipp, Lee, Baral, and
  Ben~Amor]{stepputtis2020language}
S.~Stepputtis, J.~Campbell, M.~Phielipp, S.~Lee, C.~Baral, and H.~Ben~Amor.
\newblock Language-conditioned imitation learning for robot manipulation tasks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 13139--13150, 2020.

\bibitem[Jang et~al.(2022)Jang, Irpan, Khansari, Kappler, Ebert, Lynch, Levine,
  and Finn]{jang22a}
E.~Jang, A.~Irpan, M.~Khansari, D.~Kappler, F.~Ebert, C.~Lynch, S.~Levine, and
  C.~Finn.
\newblock Bc-z: Zero-shot task generalization with robotic imitation learning.
\newblock In A.~Faust, D.~Hsu, and G.~Neumann, editors, \emph{Proceedings of
  the 5th Conference on Robot Learning}, volume 164 of \emph{Proceedings of
  Machine Learning Research}, pages 991--1002. PMLR, 08--11 Nov 2022.
\newblock URL \url{https://proceedings.mlr.press/v164/jang22a.html}.

\bibitem[Lynch et~al.(2022)Lynch, Wahid, Tompson, Ding, Betker, Baruch,
  Armstrong, and Florence]{lynch2022interactive}
C.~Lynch, A.~Wahid, J.~Tompson, T.~Ding, J.~Betker, R.~Baruch, T.~Armstrong,
  and P.~Florence.
\newblock Interactive language: Talking to robots in real time.
\newblock \emph{arXiv preprint arXiv:2210.06407}, 2022.

\bibitem[Mees et~al.(2022)Mees, Hermann, and Burgard]{mees2022matters}
O.~Mees, L.~Hermann, and W.~Burgard.
\newblock What matters in language conditioned robotic imitation learning over
  unstructured data.
\newblock \emph{IEEE Robotics and Automation Letters}, 7\penalty0 (4):\penalty0
  11205--11212, 2022.

\bibitem[Brohan et~al.(2022)Brohan, Brown, Carbajal, Chebotar, Dabis, Finn,
  Gopalakrishnan, Hausman, Herzog, Hsu, et~al.]{brohan2022rt}
A.~Brohan, N.~Brown, J.~Carbajal, Y.~Chebotar, J.~Dabis, C.~Finn,
  K.~Gopalakrishnan, K.~Hausman, A.~Herzog, J.~Hsu, et~al.
\newblock Rt-1: Robotics transformer for real-world control at scale.
\newblock \emph{arXiv preprint arXiv:2212.06817}, 2022.

\bibitem[Mees et~al.(2022)Mees, Hermann, Rosete-Beas, and
  Burgard]{mees2022calvin}
O.~Mees, L.~Hermann, E.~Rosete-Beas, and W.~Burgard.
\newblock Calvin: A benchmark for language-conditioned policy learning for
  long-horizon robot manipulation tasks.
\newblock \emph{IEEE Robotics and Automation Letters}, 7\penalty0 (3):\penalty0
  7327--7334, 2022.

\bibitem[Xiao et~al.(2022)Xiao, Chan, Sermanet, Wahid, Brohan, Hausman, Levine,
  and Tompson]{xiao2022robotic}
T.~Xiao, H.~Chan, P.~Sermanet, A.~Wahid, A.~Brohan, K.~Hausman, S.~Levine, and
  J.~Tompson.
\newblock Robotic skill acquisition via instruction augmentation with
  vision-language models.
\newblock \emph{arXiv preprint arXiv:2211.11736}, 2022.

\bibitem[Nair et~al.(2022)Nair, Mitchell, Chen, Savarese, Finn,
  et~al.]{nair2022learning}
S.~Nair, E.~Mitchell, K.~Chen, S.~Savarese, C.~Finn, et~al.
\newblock Learning language-conditioned robot behavior from offline data and
  crowd-sourced annotation.
\newblock In \emph{Conference on Robot Learning}, pages 1303--1315. PMLR, 2022.

\bibitem[Goyal et~al.(2017)Goyal, Ebrahimi~Kahou, Michalski, Materzynska,
  Westphal, Kim, Haenel, Fruend, Yianilos, Mueller-Freitag,
  et~al.]{goyal2017something}
R.~Goyal, S.~Ebrahimi~Kahou, V.~Michalski, J.~Materzynska, S.~Westphal, H.~Kim,
  V.~Haenel, I.~Fruend, P.~Yianilos, M.~Mueller-Freitag, et~al.
\newblock The" something something" video database for learning and evaluating
  visual common sense.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 5842--5850, 2017.

\bibitem[Damen et~al.(2018)Damen, Doughty, Farinella, Fidler, Furnari, Kazakos,
  Moltisanti, Munro, Perrett, Price, et~al.]{damen2018scaling}
D.~Damen, H.~Doughty, G.~M. Farinella, S.~Fidler, A.~Furnari, E.~Kazakos,
  D.~Moltisanti, J.~Munro, T.~Perrett, W.~Price, et~al.
\newblock Scaling egocentric vision: The epic-kitchens dataset.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 720--736, 2018.

\bibitem[Chen et~al.(2021)Chen, Nair, and Finn]{chen2021learning}
A.~S. Chen, S.~Nair, and C.~Finn.
\newblock Learning generalizable robotic reward functions from" in-the-wild"
  human videos.
\newblock \emph{arXiv preprint arXiv:2103.16817}, 2021.

\bibitem[Garrett et~al.(2021)Garrett, Chitnis, Holladay, Kim, Silver,
  Kaelbling, and Lozano-P{\'e}rez]{garrett2021integrated}
C.~R. Garrett, R.~Chitnis, R.~Holladay, B.~Kim, T.~Silver, L.~P. Kaelbling, and
  T.~Lozano-P{\'e}rez.
\newblock Integrated task and motion planning.
\newblock \emph{Annual review of control, robotics, and autonomous systems},
  4:\penalty0 265--293, 2021.

\bibitem[Huang et~al.(2022)Huang, Abbeel, Pathak, and
  Mordatch]{huang2022language}
W.~Huang, P.~Abbeel, D.~Pathak, and I.~Mordatch.
\newblock Language models as zero-shot planners: Extracting actionable
  knowledge for embodied agents.
\newblock In \emph{International Conference on Machine Learning}, pages
  9118--9147. PMLR, 2022.

\bibitem[Ahn et~al.(2022)Ahn, Brohan, Brown, Chebotar, Cortes, David, Finn,
  Gopalakrishnan, Hausman, Herzog, et~al.]{ahn2022can}
M.~Ahn, A.~Brohan, N.~Brown, Y.~Chebotar, O.~Cortes, B.~David, C.~Finn,
  K.~Gopalakrishnan, K.~Hausman, A.~Herzog, et~al.
\newblock Do as i can, not as i say: Grounding language in robotic affordances.
\newblock \emph{arXiv preprint arXiv:2204.01691}, 2022.

\bibitem[Huang et~al.()Huang, Xia, Xiao, Chan, Liang, Florence, Zeng, Tompson,
  Mordatch, Chebotar, et~al.]{huanginner}
W.~Huang, F.~Xia, T.~Xiao, H.~Chan, J.~Liang, P.~Florence, A.~Zeng, J.~Tompson,
  I.~Mordatch, Y.~Chebotar, et~al.
\newblock Inner monologue: Embodied reasoning through planning with language
  models.
\newblock In \emph{6th Annual Conference on Robot Learning}.

\bibitem[Liang et~al.(2022)Liang, Huang, Xia, Xu, Hausman, Ichter, Florence,
  and Zeng]{codeaspolicies2022}
J.~Liang, W.~Huang, F.~Xia, P.~Xu, K.~Hausman, B.~Ichter, P.~Florence, and
  A.~Zeng.
\newblock Code as policies: Language model programs for embodied control.
\newblock In \emph{arXiv preprint arXiv:2209.07753}, 2022.

\bibitem[Driess et~al.(2023)Driess, Xia, Sajjadi, Lynch, Chowdhery, Ichter,
  Wahid, Tompson, Vuong, Yu, et~al.]{driess2023palm}
D.~Driess, F.~Xia, M.~S. Sajjadi, C.~Lynch, A.~Chowdhery, B.~Ichter, A.~Wahid,
  J.~Tompson, Q.~Vuong, T.~Yu, et~al.
\newblock Palm-e: An embodied multimodal language model.
\newblock \emph{ICML}, 2023.

\bibitem[Lin et~al.(2023)Lin, Agia, Migimatsu, Pavone, and
  Bohg]{lin2023text2motion}
K.~Lin, C.~Agia, T.~Migimatsu, M.~Pavone, and J.~Bohg.
\newblock Text2motion: From natural language instructions to feasible plans.
\newblock \emph{arXiv preprint arXiv:2303.12153}, 2023.

\bibitem[Agarwal et~al.(2022)Agarwal, Kumar, Malik, and
  Pathak]{agarwal2022legged}
A.~Agarwal, A.~Kumar, J.~Malik, and D.~Pathak.
\newblock Legged locomotion in challenging terrains using egocentric vision,
  2022.

\bibitem[Seita et~al.(2019)Seita, Ganapathi, Hoque, Hwang, Cen, Tanwani,
  Balakrishna, Thananjeyan, Ichnowski, Jamali, Yamane, Iba, Canny, and
  Goldberg]{seita2019deep}
D.~Seita, A.~Ganapathi, R.~Hoque, M.~Hwang, E.~Cen, A.~K. Tanwani,
  A.~Balakrishna, B.~Thananjeyan, J.~Ichnowski, N.~Jamali, K.~Yamane, S.~Iba,
  J.~F. Canny, and K.~Goldberg.
\newblock Deep imitation learning of sequential fabric smoothing policies.
\newblock \emph{CoRR}, abs/1910.04854, 2019.
\newblock URL \url{http://arxiv.org/abs/1910.04854}.

\bibitem[Miki et~al.(2022)Miki, Lee, Hwangbo, Wellhausen, Koltun, and
  Hutter]{miki2022learning}
T.~Miki, J.~Lee, J.~Hwangbo, L.~Wellhausen, V.~Koltun, and M.~Hutter.
\newblock Learning robust perceptive locomotion for quadrupedal robots in the
  wild.
\newblock \emph{Science Robotics}, 7\penalty0 (62):\penalty0 eabk2822, 2022.

\bibitem[Levine et~al.(2016)Levine, Finn, Darrell, and Abbeel]{levine2016end}
S.~Levine, C.~Finn, T.~Darrell, and P.~Abbeel.
\newblock End-to-end training of deep visuomotor policies.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 1334--1373, 2016.

\bibitem[Hausman et~al.(2017)Hausman, Chebotar, Schaal, Sukhatme, and
  Lim]{hausman2017multi}
K.~Hausman, Y.~Chebotar, S.~Schaal, G.~Sukhatme, and J.~J. Lim.
\newblock Multi-modal imitation learning from unstructured demonstrations using
  generative adversarial nets.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Shafiullah et~al.(2022)Shafiullah, Cui, Altanzaya, and
  Pinto]{shafiullah2022behavior}
N.~M.~M. Shafiullah, Z.~J. Cui, A.~Altanzaya, and L.~Pinto.
\newblock Behavior transformers: Cloning $k$ modes with one stone, 2022.

\bibitem[Yu et~al.(2020)Yu, Quillen, He, Julian, Hausman, Finn, and
  Levine]{yu2020meta}
T.~Yu, D.~Quillen, Z.~He, R.~Julian, K.~Hausman, C.~Finn, and S.~Levine.
\newblock Meta-world: A benchmark and evaluation for multi-task and meta
  reinforcement learning.
\newblock In \emph{Conference on robot learning}, pages 1094--1100. PMLR, 2020.

\bibitem[Kalashnikov et~al.(2021)Kalashnikov, Varley, Chebotar, Swanson,
  Jonschkowski, Finn, Levine, and Hausman]{kalashnikov2021mt}
D.~Kalashnikov, J.~Varley, Y.~Chebotar, B.~Swanson, R.~Jonschkowski, C.~Finn,
  S.~Levine, and K.~Hausman.
\newblock Mt-opt: Continuous multi-task robotic reinforcement learning at
  scale.
\newblock \emph{arXiv preprint arXiv:2104.08212}, 2021.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl2015deep}
J.~Sohl-Dickstein, E.~Weiss, N.~Maheswaranathan, and S.~Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International Conference on Machine Learning}, pages
  2256--2265. PMLR, 2015.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
J.~Ho, A.~Jain, and P.~Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 6840--6851, 2020.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton,
  Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans,
  et~al.]{saharia2022photorealistic}
C.~Saharia, W.~Chan, S.~Saxena, L.~Li, J.~Whang, E.~L. Denton, K.~Ghasemipour,
  R.~Gontijo~Lopes, B.~Karagol~Ayan, T.~Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 36479--36494, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2022high}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10684--10695, 2022.

\bibitem[LaValle et~al.()]{lavalle1998rapidly}
S.~M. LaValle et~al.
\newblock Rapidly-exploring random trees: A new tool for path planning.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem[Mandlekar et~al.(2021)Mandlekar, Xu, Wong, Nasiriany, Wang, Kulkarni,
  Fei-Fei, Savarese, Zhu, and Mart{\'\i}n-Mart{\'\i}n]{robomimic2021}
A.~Mandlekar, D.~Xu, J.~Wong, S.~Nasiriany, C.~Wang, R.~Kulkarni, L.~Fei-Fei,
  S.~Savarese, Y.~Zhu, and R.~Mart{\'\i}n-Mart{\'\i}n.
\newblock What matters in learning from offline human demonstrations for robot
  manipulation.
\newblock In \emph{5th Annual Conference on Robot Learning}, 2021.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Song et~al.()Song, Meng, and Ermon]{songdenoising}
J.~Song, C.~Meng, and S.~Ermon.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[Downs et~al.(2022)Downs, Francis, Koenig, Kinman, Hickman, Reymann,
  McHugh, and Vanhoucke]{downs2022scannedobjects}
L.~Downs, A.~Francis, N.~Koenig, B.~Kinman, R.~Hickman, K.~Reymann, T.~B.
  McHugh, and V.~Vanhoucke.
\newblock Google scanned objects: A high-quality dataset of 3d scanned
  household items, 2022.
\newblock URL \url{https://arxiv.org/abs/2204.11918}.

\bibitem[Zakka(2022)]{zakka2022scannedobjectsmujoco}
K.~Zakka.
\newblock {Scanned Objects MuJoCo Models}, 7 2022.
\newblock URL \url{https://github.com/kevinzakka/mujoco_scanned_objects}.

\end{thebibliography}
