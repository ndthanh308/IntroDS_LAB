\documentclass{article}
\usepackage[preprint]{style} %
\input{preamble}

\title{Scaling Up and Distilling Down: \\ { Language-Guided Robot Skill Acquisition}
}

\author[1]{Huy Ha}
\author[2]{Pete Florence}
\author[1]{Shuran Song}
\affil[1]{Columbia University}
\affil[2]{Google Research}

\pdfinfo{
   /Author (Huy Ha, Pete Florence, Shuran Song)
   /Title  (Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition)
   /CreationDate (D:20230404120000)
   /Subject ()
   /Keywords ()
}

\begin{document}

\maketitle

\vspace{-10mm}
\begin{abstract}
   We present a framework for robot skill acquisition, which 1) efficiently scale up data generation of language-labelled robot data and 2) effectively distills this data down into a robust multi-task language-conditioned visuo-motor policy.
   For (1), we use a large language model (LLM) to guide high-level planning, and sampling-based robot planners (\eg motion or grasp samplers) for generating diverse and rich manipulation trajectories.
   To robustify this data-collection process, the LLM also infers a code-snippet for the success condition of each task, simultaneously enabling the data-collection process to detect failure and retry as well as the automatic labeling of trajectories with success/failure.
   For (2), we extend the diffusion policy single-task behavior-cloning approach to  multi-task settings with language conditioning.
   Finally, we propose a new multi-task benchmark with 18 tasks across five domains to test long-horizon behavior, common-sense reasoning, tool-use, and intuitive physics.
   We find that our distilled policy successfully learned the robust retrying behavior in its data collection policy, while improving absolute success rates by $34.8\%$ on average across five domains.
   The benchmark, code, and qualitative results are on \href{https://www.cs.columbia.edu/~huy/scalingup/}{project website}.
\end{abstract}

\input{text_v2/Intro_shuran}
\input{text_v2/relatedwoks_pete}
\input{text_v2/method_huy}
\input{text_v2/experiment_huy.tex}
\input{text_v2/discussion.tex}

\acknowledgments{
   We would like to thank Cheng Chi, Zeyi Liu, Samir Yitzhak Gadre, Mengda Xu, Zhenjia Xu, Mandi Zhao and Dominik Bauer for their helpful feedback and fruitful discussions.
   This work was supported in part by Google Research Award, NSF Award \#2143601, and \#2132519. We would like to thank Google for the UR5 robot hardware.  The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the sponsors.}
\bibliography{references}


\newpage
\begin{appendix}
   \input{text_v2/supp_content.tex}
\end{appendix}

\end{document}