{
  "title": "Uncertainty in Natural Language Generation: From Theory to Applications",
  "authors": [
    "Joris Baan",
    "Nico Daheim",
    "Evgenia Ilia",
    "Dennis Ulmer",
    "Haau-Sing Li",
    "Raquel Fern√°ndez",
    "Barbara Plank",
    "Rico Sennrich",
    "Chrysoula Zerva",
    "Wilker Aziz"
  ],
  "submission_date": "2023-07-28T17:51:21+00:00",
  "revised_dates": [],
  "abstract": "Recent advances of powerful Language Models have allowed Natural Language Generation (NLG) to emerge as an important technology that can not only perform traditional tasks like summarisation or translation, but also serve as a natural language interface to a variety of applications. As such, it is crucial that NLG systems are trustworthy and reliable, for example by indicating when they are likely to be wrong; and supporting multiple views, backgrounds and writing styles -- reflecting diverse human sub-populations. In this paper, we argue that a principled treatment of uncertainty can assist in creating systems and evaluation protocols better aligned with these goals. We first present the fundamental theory, frameworks and vocabulary required to represent uncertainty. We then characterise the main sources of uncertainty in NLG from a linguistic perspective, and propose a two-dimensional taxonomy that is more informative and faithful than the popular aleatoric/epistemic dichotomy. Finally, we move from theory to applications and highlight exciting research directions that exploit uncertainty to power decoding, controllable generation, self-assessment, selective answering, active learning and more.",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.LG"
  ],
  "primary_category": "cs.CL",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15703",
  "pdf_url": "https://arxiv.org/pdf/2307.15703v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 351473,
  "size_after_bytes": 197297
}