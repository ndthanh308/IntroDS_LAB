\section{Conclusion}
In this paper, we have argued for the importance of a principled and fundamental understanding of representing, learning and reasoning about uncertainty in NLG. We identified and organised the main sources of uncertainty, and highlighted the many important applications this perspective can power.

To do so, we laid down central concepts, their formal mathematical frameworks and the necessary vocabulary. We specifically drew attention to the possible worlds framework; probability as a way to express preference over these possible worlds; its two main interpretations; statistical tools to acquire and revise knowledge; and how these are commonly used in NLG. 

Then, building on the triangle of reference, we identified and organised the main sources of uncertainty in language production: input \textit{ambiguity}, \textit{errors}, and \textit{complexity}; the \textit{open-endedness of the communicative task}, the \textit{agent's personal perspective}, and the final \textit{linguistic realisation}--- and modelling: \textit{model specification}, \textit{parameter estimation}, and \textit{distribution shift}. We proposed a two-dimensional taxonomy to organise sources as a richer alternative to the aleatoric/epistemic distinction.

Finally, we highlighted exciting applications of disentangled representations of uncertainty in NLG. These span from applications related data uncertainty (decoding, controllable generation, explicit modelling of sub-populations), to model uncertainty (self-assessment, selective answering, OOD detection, active learning).

We hope to spark a shared understanding of uncertainty and inspire more principled and focused research in NLG. Crucially, we believe this perspective allows for systems that are more flexible, representative of the diversity of human language and its speakers, and reliable and trustworthy.
