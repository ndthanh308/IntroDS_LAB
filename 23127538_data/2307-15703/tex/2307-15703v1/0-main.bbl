\begin{thebibliography}{197}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Abdar et~al.(2020)Abdar, Pourpanah, Hussain, Rezazadegan, Liu,
  Ghavamzadeh, Fieguth, Cao, Khosravi, Acharya, Makarenkov, and
  Nahavandi}]{abdar-review-2020}
Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li~Liu,
  Mohammad Ghavamzadeh, Paul~W. Fieguth, Xiaochun Cao, Abbas Khosravi,
  U.~Rajendra Acharya, Vladimir Makarenkov, and Saeid Nahavandi. 2020.
\newblock \href {http://arxiv.org/abs/2011.06225} {A review of uncertainty
  quantification in deep learning: Techniques, applications and challenges}.
\newblock \emph{CoRR}, abs/2011.06225.

\bibitem[{Ahmed et~al.(2019)Ahmed, Samee, and Mercer}]{ahmed2019improving}
Mahtab Ahmed, Muhammad~Rifayat Samee, and Robert~E Mercer. 2019.
\newblock \href {https://ieeexplore.ieee.org/abstract/document/8665673}
  {Improving tree-lstm with tree attention}.
\newblock In \emph{2019 IEEE 13th international conference on semantic
  computing (ICSC)}, pages 247--254. IEEE.

\bibitem[{Ambati(2012)}]{ambati2012active}
Vamshi Ambati. 2012.
\newblock \href {https://dl.acm.org/doi/10.5555/2519491} {\emph{Active learning
  and crowdsourcing for machine translation in low resource scenarios}}.
\newblock Ph.D. thesis, Carnegie Mellon University.

\bibitem[{Amrhein and Sennrich(2022)}]{amrhein-sennrich-2022-identifying}
Chantal Amrhein and Rico Sennrich. 2022.
\newblock \href {https://aclanthology.org/2022.aacl-main.83} {Identifying
  weaknesses in machine translation metrics through minimum {B}ayes risk
  decoding: A case study for {COMET}}.
\newblock In \emph{Proceedings of the 2nd Conference of the Asia-Pacific
  Chapter of the Association for Computational Linguistics and the 12th
  International Joint Conference on Natural Language Processing (Volume 1: Long
  Papers)}, pages 1125--1141, Online only. Association for Computational
  Linguistics.

\bibitem[{Angelopoulos and Bates(2021)}]{angelopoulos2021gentle}
Anastasios~N Angelopoulos and Stephen Bates. 2021.
\newblock \href {https://arxiv.org/abs/2107.07511} {A gentle introduction to
  conformal prediction and distribution-free uncertainty quantification}.
\newblock \emph{arXiv preprint arXiv:2107.07511}.

\bibitem[{Aroyo and Welty(2015)}]{Aroyo_Welty_2015}
Lora Aroyo and Chris Welty. 2015.
\newblock \href {https://doi.org/10.1609/aimag.v36i1.2564} {Truth is a lie:
  Crowd truth and the seven myths of human annotation}.
\newblock \emph{AI Magazine}, 36(1):15--24.

\bibitem[{Ataman et~al.(2020)Ataman, Aziz, and Birch}]{Ataman2020A}
Duygu Ataman, Wilker Aziz, and Alexandra Birch. 2020.
\newblock \href {https://openreview.net/forum?id=BJxSI1SKDH} {A latent
  morphology model for open-vocabulary neural machine translation}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Baan et~al.(2022)Baan, Aziz, Plank, and Fernandez}]{baan2022stop}
Joris Baan, Wilker Aziz, Barbara Plank, and Raquel Fernandez. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.124} {Stop measuring
  calibration when humans disagree}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 1892--1915, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Banerjee and Lavie(2005)}]{banerjee-lavie-2005-meteor}
Satanjeev Banerjee and Alon Lavie. 2005.
\newblock \href {https://aclanthology.org/W05-0909} {{METEOR}: An automatic
  metric for {MT} evaluation with improved correlation with human judgments}.
\newblock In \emph{Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic
  Evaluation Measures for Machine Translation and/or Summarization}, pages
  65--72, Ann Arbor, Michigan. Association for Computational Linguistics.

\bibitem[{Barkhof and Aziz(2022)}]{barkhof2022statistical}
Claartje Barkhof and Wilker Aziz. 2022.
\newblock \href {https://arxiv.org/abs/2204.03030} {Statistical model criticism
  of variational auto-encoders}.
\newblock \emph{arXiv preprint arXiv:2204.03030}.

\bibitem[{Basile et~al.(2021)Basile, Fell, Fornaciari, Hovy, Paun, Plank,
  Poesio, and Uma}]{basile-etal-2021-need}
Valerio Basile, Michael Fell, Tommaso Fornaciari, Dirk Hovy, Silviu Paun,
  Barbara Plank, Massimo Poesio, and Alexandra Uma. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.bppf-1.3} {We need to
  consider disagreement in evaluation}.
\newblock In \emph{Proceedings of the 1st Workshop on Benchmarking: Past,
  Present and Future}, pages 15--21, Online. Association for Computational
  Linguistics.

\bibitem[{Bernardo and Smith(1994)}]{bernardo1994bayesian}
Jos{\'e}~M Bernardo and Adrian~FM Smith. 1994.
\newblock \emph{Bayesian theory}, volume 405.
\newblock John Wiley \& Sons.

\bibitem[{Bhatt et~al.(2021)Bhatt, Antor\'{a}n, Zhang, Liao, Sattigeri,
  Fogliato, Melan\c{c}on, Krishnan, Stanley, Tickoo, Nachman, Chunara,
  Srikumar, Weller, and Xiang}]{bhatt-uncertainty-2021}
Umang Bhatt, Javier Antor\'{a}n, Yunfeng Zhang, Q.~Vera Liao, Prasanna
  Sattigeri, Riccardo Fogliato, Gabrielle Melan\c{c}on, Ranganath Krishnan,
  Jason Stanley, Omesh Tickoo, Lama Nachman, Rumi Chunara, Madhulika Srikumar,
  Adrian Weller, and Alice Xiang. 2021.
\newblock \href {https://doi.org/10.1145/3461702.3462571} {Uncertainty as a
  form of transparency: Measuring, communicating, and using uncertainty}.
\newblock In \emph{Association for Computing Machinery}, AIES '21, page
  401–413, New York, NY, USA.

\bibitem[{Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra}]{blundell2015weight}
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. 2015.
\newblock \href {https://proceedings.mlr.press/v37/blundell15.html} {Weight
  uncertainty in neural network}.
\newblock In \emph{International conference on machine learning}, pages
  1613--1622. PMLR.

\bibitem[{Bowman et~al.(2016)Bowman, Vilnis, Vinyals, Dai, Jozefowicz, and
  Bengio}]{bowman-etal-2016-generating}
Samuel~R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and
  Samy Bengio. 2016.
\newblock \href {https://doi.org/10.18653/v1/K16-1002} {Generating sentences
  from a continuous space}.
\newblock In \emph{Proceedings of the 20th {SIGNLL} Conference on Computational
  Natural Language Learning}, pages 10--21, Berlin, Germany. Association for
  Computational Linguistics.

\bibitem[{Bradbury and Socher(2017)}]{bradbury2017towards}
James Bradbury and Richard Socher. 2017.
\newblock \href {https://aclanthology.org/W17-4303} {Towards neural machine
  translation with latent tree attention}.
\newblock In \emph{Proceedings of the 2nd Workshop on Structured Prediction for
  Natural Language Processing, SPNLP@EMNLP, Copenhagen, Denmark, September
  2017}, pages 12--16. Association for Computational Linguistics.

\bibitem[{Bra{\v{z}}inskas et~al.(2020)Bra{\v{z}}inskas, Lapata, and
  Titov}]{brazinskas-etal-2020-unsupervised}
Arthur Bra{\v{z}}inskas, Mirella Lapata, and Ivan Titov. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.461} {Unsupervised
  opinion summarization as copycat-review generation}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 5151--5169, Online. Association for
  Computational Linguistics.

\bibitem[{Bubeck et~al.(2023)Bubeck, Chandrasekaran, Eldan, Gehrke, Horvitz,
  Kamar, Lee, Lee, Li, Lundberg et~al.}]{bubeck2023sparks}
S{\'e}bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric
  Horvitz, Ece Kamar, Peter Lee, Yin~Tat Lee, Yuanzhi Li, Scott Lundberg,
  et~al. 2023.
\newblock \href {https://arxiv.org/abs/2303.12712} {Sparks of artificial
  general intelligence: Early experiments with gpt-4}.
\newblock \emph{arXiv preprint arXiv:2303.12712}.

\bibitem[{Bulian et~al.(2022)Bulian, Buck, Gajewski, Boerschinger, and
  Schuster}]{bulian2022tomayto}
Jannis Bulian, Christian Buck, Wojciech Gajewski, Benjamin Boerschinger, and
  Tal Schuster. 2022.
\newblock \href {http://arxiv.org/abs/2202.07654} {Tomayto, tomahto. beyond
  token-level answer equivalence for question answering evaluation}.

\bibitem[{Calixto et~al.(2019)Calixto, Rios, and
  Aziz}]{calixto-etal-2019-latent}
Iacer Calixto, Miguel Rios, and Wilker Aziz. 2019.
\newblock \href {https://doi.org/10.18653/v1/P19-1642} {Latent variable model
  for multi-modal translation}.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 6392--6405, Florence, Italy.
  Association for Computational Linguistics.

\bibitem[{Cao and Rimell(2021)}]{cao-rimell-2021-evaluate}
Kris Cao and Laura Rimell. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.emnlp-main.161} {You should
  evaluate your language model on marginal likelihood over tokenisations}.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 2104--2114, Online and Punta Cana,
  Dominican Republic. Association for Computational Linguistics.

\bibitem[{Celikyilmaz et~al.(2020)Celikyilmaz, Clark, and
  Gao}]{celikyilmaz-evaluation-2020}
Asli Celikyilmaz, Elizabeth Clark, and Jianfeng Gao. 2020.
\newblock \href {http://arxiv.org/abs/2006.14799} {Evaluation of text
  generation: {A} survey}.
\newblock \emph{CoRR}, abs/2006.14799.

\bibitem[{Chen et~al.(2023)Chen, Yuan, Cui, Liu, and Ji}]{chen2022close}
Yangyi Chen, Lifan Yuan, Ganqu Cui, Zhiyuan Liu, and Heng Ji. 2023.
\newblock \href {https://aclanthology.org/2023.acl-long.75} {A close look into
  the calibration of pre-trained language models}.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto,
  Canada, July 9-14, 2023}, pages 1343--1367. Association for Computational
  Linguistics.

\bibitem[{Chirkova et~al.(2023)Chirkova, Kruszewski, Rozen, and
  Dymetman}]{chirkova-etal-2023-marginalize}
Nadezhda Chirkova, Germ{\'a}n Kruszewski, Jos Rozen, and Marc Dymetman. 2023.
\newblock \href {https://aclanthology.org/2023.acl-short.1} {Should you
  marginalize over possible tokenizations?}
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, pages 1--12,
  Toronto, Canada. Association for Computational Linguistics.

\bibitem[{Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and
  Amodei}]{christiano2017deep}
Paul~F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario
  Amodei. 2017.
\newblock \href
  {https://proceedings.neurips.cc/paper_files/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf}
  {Deep reinforcement learning from human preferences}.
\newblock \emph{Advances in neural information processing systems}, 30.

\bibitem[{Cole et~al.(2023)Cole, Zhang, Gillick, Eisenschlos, Dhingra, and
  Eisenstein}]{cole2023selectively}
Jeremy~R Cole, Michael~JQ Zhang, Daniel Gillick, Julian~Martin Eisenschlos,
  Bhuwan Dhingra, and Jacob Eisenstein. 2023.
\newblock \href {https://arxiv.org/abs/2305.14613} {Selectively answering
  ambiguous questions}.
\newblock \emph{arXiv preprint arXiv:2305.14613}.

\bibitem[{De~Finetti(1974)}]{definetti2017theory}
Bruno De~Finetti. 1974.
\newblock \emph{Theory of probability: A critical introductory treatment},
  volume~6.
\newblock John Wiley \& Sons.

\bibitem[{Deng et~al.(2018)Deng, Kim, Chiu, Guo, and Rush}]{DengEtAl2018}
Yuntian Deng, Yoon Kim, Justin Chiu, Demi Guo, and Alexander Rush. 2018.
\newblock \href
  {https://proceedings.neurips.cc/paper_files/paper/2018/file/b691334ccf10d4ab144d672f7783c8a3-Paper.pdf}
  {Latent alignment and variational attention}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31. Curran Associates, Inc.

\bibitem[{Deng et~al.(2022)Deng, Kuleshov, and Rush}]{deng-etal-2022-model}
Yuntian Deng, Volodymyr Kuleshov, and Alexander Rush. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.815} {Model criticism
  for long-form text generation}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 11887--11912, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Der~Kiureghian and Ditlevsen(2009)}]{der2009aleatory}
Armen Der~Kiureghian and Ove Ditlevsen. 2009.
\newblock \href
  {https://www.sciencedirect.com/science/article/abs/pii/S0167473008000556}
  {Aleatory or epistemic? does it matter?}
\newblock \emph{Structural safety}, 31(2):105--112.

\bibitem[{Dhuliawala et~al.(2022)Dhuliawala, Adolphs, Das, and
  Sachan}]{dhuliawala-etal-2022-calibration}
Shehzaad Dhuliawala, Leonard Adolphs, Rajarshi Das, and Mrinmaya Sachan. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.findings-acl.133}
  {Calibration of machine reading systems at scale}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2022}, pages 1682--1693, Dublin, Ireland. Association for Computational
  Linguistics.

\bibitem[{Dinan et~al.(2019)Dinan, Roller, Shuster, Fan, Auli, and
  Weston}]{dinan2018wizard}
Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason
  Weston. 2019.
\newblock \href {https://openreview.net/forum?id=r1l73iRqKm} {Wizard of
  wikipedia: Knowledge-powered conversational agents}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Dong et~al.(2022)Dong, Li, Gong, Chen, Li, Shen, and
  Yang}]{dong-survey-2022}
Chenhe Dong, Yinghui Li, Haifan Gong, Miaoxin Chen, Junxin Li, Ying Shen, and
  Min Yang. 2022.
\newblock \href {https://doi.org/10.1145/3554727} {A survey of natural language
  generation}.
\newblock \emph{ACM Comput. Surv.}, 55(8).

\bibitem[{Dubois and Prade(1990)}]{duboisprade90}
D.~Dubois and H.~Prade. 1990.
\newblock \emph{An Introduction to Possibilistic and Fuzzy Logics}.
\newblock Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.

\bibitem[{Dubois and Prade(2009)}]{dubois2009formal}
Didier Dubois and Henri Prade. 2009.
\newblock Formal representations of uncertainty.
\newblock In \emph{Concepts \& Methods of Decision-Making}, chapter~3. John
  Wiley \& Sons Inc.

\bibitem[{Eikema and Aziz(2019)}]{eikema2019auto}
Bryan Eikema and Wilker Aziz. 2019.
\newblock \href {https://aclanthology.org/W19-4315} {Auto-encoding variational
  neural machine translation}.
\newblock In \emph{Proceedings of the 4th Workshop on Representation Learning
  for NLP, RepL4NLP@ACL 2019, Florence, Italy, August 2, 2019}, pages 124--141.
  Association for Computational Linguistics.

\bibitem[{Eikema and Aziz(2020)}]{eikema-aziz-2020-map}
Bryan Eikema and Wilker Aziz. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.coling-main.398} {Is {MAP}
  decoding all you need? the inadequacy of the mode in neural machine
  translation}.
\newblock In \emph{Proceedings of the 28th International Conference on
  Computational Linguistics}, pages 4506--4520, Barcelona, Spain (Online).
  International Committee on Computational Linguistics.

\bibitem[{Eisape et~al.(2020)Eisape, Zaslavsky, and Levy}]{eisape2020cloze}
Tiwalayo Eisape, Noga Zaslavsky, and Roger Levy. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.conll-1.49} {Cloze
  distillation: Improving neural language models with human next-word
  prediction}.
\newblock In \emph{Proceedings of the 24th Conference on Computational Natural
  Language Learning}, pages 609--619, Online. Association for Computational
  Linguistics.

\bibitem[{El-Yaniv et~al.(2010)}]{el2010foundations}
Ran El-Yaniv et~al. 2010.
\newblock \href {https://www.jmlr.org/papers/v11/el-yaniv10a.html} {On the
  foundations of noise-free selective classification.}
\newblock \emph{Journal of Machine Learning Research}, 11(5).

\bibitem[{Erdem et~al.(2022)Erdem, Kuyu, Yagcioglu, Frank, Parcalabescu, Plank,
  Babii, Turuta, Erdem, Calixto, Lloret, Apostol, Truic\u{a}, \v{S}andrih,
  Martin\v{c}i\'{c}-Ip\v{s}i\'{c}, Berend, Gatt, and
  Korvel}]{erdem-neural-2022}
Erkut Erdem, Menekse Kuyu, Semih Yagcioglu, Anette Frank, Letitia Parcalabescu,
  Barbara Plank, Andrii Babii, Oleksii Turuta, Aykut Erdem, Iacer Calixto,
  Elena Lloret, Elena-Simona Apostol, Ciprian-Octavian Truic\u{a}, Branislava
  \v{S}andrih, Sanda Martin\v{c}i\'{c}-Ip\v{s}i\'{c}, G\'{a}bor Berend, Albert
  Gatt, and Gr\u{a}zina Korvel. 2022.
\newblock \href {https://doi.org/10.1613/jair.1.12918} {Neural natural language
  generation: A survey on multilinguality, multimodality, controllability and
  learning}.
\newblock \emph{J. Artif. Int. Res.}, 73.

\bibitem[{Fan et~al.(2018)Fan, Lewis, and Dauphin}]{fan-etal-2018-hierarchical}
Angela Fan, Mike Lewis, and Yann Dauphin. 2018.
\newblock \href {https://doi.org/10.18653/v1/P18-1082} {Hierarchical neural
  story generation}.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 889--898,
  Melbourne, Australia. Association for Computational Linguistics.

\bibitem[{Fernandes et~al.(2022)Fernandes, Farinhas, Rei, C.~de Souza, Ogayo,
  Neubig, and Martins}]{fernandes-etal-2022-quality}
Patrick Fernandes, Ant{\'o}nio Farinhas, Ricardo Rei, Jos{\'e}~G. C.~de Souza,
  Perez Ogayo, Graham Neubig, and Andre Martins. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.naacl-main.100}
  {Quality-aware decoding for neural machine translation}.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 1396--1412, Seattle, United States. Association for
  Computational Linguistics.

\bibitem[{Ferreira and Dell(2000)}]{ferreira2000effect}
Victor~S Ferreira and Gary~S Dell. 2000.
\newblock \href
  {https://www.sciencedirect.com/science/article/pii/S0010028599907302} {Effect
  of ambiguity and lexical availability on syntactic and lexical production}.
\newblock \emph{Cognitive psychology}, 40(4):296--340.

\bibitem[{Fomicheva et~al.(2020)Fomicheva, Sun, Yankovskaya, Blain, Guzmán,
  Fishel, Aletras, Chaudhary, and Specia}]{fomicheva2020unsupervised}
Marina Fomicheva, Shuo Sun, Lisa Yankovskaya, Frédéric Blain, Francisco
  Guzmán, Mark Fishel, Nikolaos Aletras, Vishrav Chaudhary, and Lucia Specia.
  2020.
\newblock \href {https://doi.org/10.1162/tacl_a_00330} {{Unsupervised Quality
  Estimation for Neural Machine Translation}}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  8:539--555.

\bibitem[{Fortunato et~al.(2017)Fortunato, Blundell, and
  Vinyals}]{fortunato2017bayesian}
Meire Fortunato, Charles Blundell, and Oriol Vinyals. 2017.
\newblock \href {https://arxiv.org/abs/1704.02798} {Bayesian recurrent neural
  networks}.
\newblock \emph{arXiv preprint arXiv:1704.02798}.

\bibitem[{Freitag et~al.(2023)Freitag, Ghorbani, and
  Fernandes}]{freitag2023epsilon}
Markus Freitag, Behrooz Ghorbani, and Patrick Fernandes. 2023.
\newblock \href {https://arxiv.org/abs/2305.09860} {Epsilon sampling rocks:
  Investigating sampling strategies for minimum bayes risk decoding for machine
  translation}.
\newblock \emph{arXiv preprint arXiv:2305.09860}.

\bibitem[{Freitag et~al.(2020)Freitag, Grangier, and
  Caswell}]{freitag-etal-2020-bleu}
Markus Freitag, David Grangier, and Isaac Caswell. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.5} {{BLEU} might
  be guilty but references are not innocent}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 61--71, Online. Association for
  Computational Linguistics.

\bibitem[{Friedman and Halpern(1996)}]{friedman96}
Nir Friedman and Joseph~Y. Halpern. 1996.
\newblock \href
  {https://aaai.org/papers/192-plausibility-measures-and-default-reasoning/}
  {Plausibility measures and default reasoning}.
\newblock In \emph{Proceedings of the Thirteenth National Conference on
  Artificial Intelligence - Volume 2}, AAAI'96, page 1297–1304. AAAI Press.

\bibitem[{Gal and Ghahramani(2016)}]{gal2016theoretically}
Yarin Gal and Zoubin Ghahramani. 2016.
\newblock \href
  {https://proceedings.neurips.cc/paper/2016/hash/076a0c97d09cf1a0ec3e19c7f2529f2b-Abstract.html}
  {A theoretically grounded application of dropout in recurrent neural
  networks}.
\newblock In \emph{Advances in Neural Information Processing Systems 29: Annual
  Conference on Neural Information Processing Systems 2016, December 5-10,
  2016, Barcelona, Spain}, pages 1019--1027.

\bibitem[{Gan et~al.(2017)Gan, Li, Chen, Pu, Su, and Carin}]{gan2017scalable}
Zhe Gan, Chunyuan Li, Changyou Chen, Yunchen Pu, Qinliang Su, and Lawrence
  Carin. 2017.
\newblock \href {https://doi.org/10.18653/v1/P17-1030} {Scalable {B}ayesian
  learning of recurrent neural networks for language modeling}.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 321--331,
  Vancouver, Canada. Association for Computational Linguistics.

\bibitem[{Gao et~al.(2023)Gao, Madaan, Zhou, Alon, Liu, Yang, Callan, and
  Neubig}]{gao2022pal}
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie
  Callan, and Graham Neubig. 2023.
\newblock Pal: Program-aided language models.
\newblock In \emph{International Conference on Machine Learning}, pages
  10764--10799. PMLR.

\bibitem[{Gatt and Krahmer(2018)}]{gatt-survey-2018}
Albert Gatt and Emiel Krahmer. 2018.
\newblock \href {https://dl.acm.org/doi/10.5555/3241691.3241693} {Survey of the
  state of the art in natural language generation: Core tasks, applications and
  evaluation}.
\newblock \emph{J. Artif. Int. Res.}, 61(1):65–170.

\bibitem[{Gawlikowski et~al.(2021)Gawlikowski, Tassi, Ali, Lee, Humt, Feng,
  Kruspe, Triebel, Jung, Roscher, Shahzad, Yang, Bamler, and
  Zhu}]{gawlikowski-survey-2021}
Jakob Gawlikowski, Cedrique Rovile~Njieutcheu Tassi, Mohsin Ali, Jongseok Lee,
  Matthias Humt, Jianxiang Feng, Anna~M. Kruspe, Rudolph Triebel, Peter Jung,
  Ribana Roscher, Muhammad Shahzad, Wen Yang, Richard Bamler, and Xiao~Xiang
  Zhu. 2021.
\newblock \href {http://arxiv.org/abs/2107.03342} {A survey of uncertainty in
  deep neural networks}.
\newblock \emph{CoRR}, abs/2107.03342.

\bibitem[{Gehrmann et~al.(2023)Gehrmann, Clark, and
  Sellam}]{gehrmann2022repairing}
Sebastian Gehrmann, Elizabeth Clark, and Thibault Sellam. 2023.
\newblock \href {https://doi.org/10.1613/jair.1.13715} {Repairing the cracked
  foundation: A survey of obstacles in evaluation practices for generated
  text}.
\newblock \emph{J. Artif. Int. Res.}, 77.

\bibitem[{Gelman et~al.(2004)Gelman, Carlin, Stern, and Rubin}]{gelmanbda04}
Andrew Gelman, John~B. Carlin, Hal~S. Stern, and Donald~B. Rubin. 2004.
\newblock \emph{Bayesian Data Analysis}, 2nd ed. edition.
\newblock Chapman and Hall/CRC.

\bibitem[{Geva et~al.(2019)Geva, Goldberg, and
  Berant}]{geva-etal-2019-modeling}
Mor Geva, Yoav Goldberg, and Jonathan Berant. 2019.
\newblock \href {https://doi.org/10.18653/v1/D19-1107} {Are we modeling the
  task or the annotator? an investigation of annotator bias in natural language
  understanding datasets}.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 1161--1166, Hong Kong,
  China. Association for Computational Linguistics.

\bibitem[{Gidiotis and Tsoumakas(2022)}]{gidiotis-tsoumakas-2022-trust}
Alexios Gidiotis and Grigorios Tsoumakas. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.findings-acl.325} {Should we
  trust this summary? {B}ayesian abstractive summarization to the rescue}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2022}, pages 4119--4131, Dublin, Ireland. Association for Computational
  Linguistics.

\bibitem[{Giovannotti(2023)}]{giovannotti2023evaluating}
Patrizio Giovannotti. 2023.
\newblock \href {https://arxiv.org/abs/2306.01549} {Evaluating machine
  translation quality with conformal predictive distributions}.
\newblock \emph{arXiv preprint arXiv:2306.01549}.

\bibitem[{Giulianelli et~al.(2023)Giulianelli, Baan, Aziz, Fern{\'a}ndez, and
  Plank}]{giulianelli2023comes}
Mario Giulianelli, Joris Baan, Wilker Aziz, Raquel Fern{\'a}ndez, and Barbara
  Plank. 2023.
\newblock \href {https://arxiv.org/abs/2305.11707} {What comes next? evaluating
  uncertainty in neural text generators against human production variability}.
\newblock \emph{arXiv preprint arXiv:2305.11707}.

\bibitem[{Glushkova et~al.(2021)Glushkova, Zerva, Rei, and
  Martins}]{glushkova-etal-2021-uncertainty-aware}
Taisiya Glushkova, Chrysoula Zerva, Ricardo Rei, and Andr{\'e} F.~T. Martins.
  2021.
\newblock \href {https://doi.org/10.18653/v1/2021.findings-emnlp.330}
  {Uncertainty-aware machine translation evaluation}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2021}, pages 3920--3938, Punta Cana, Dominican Republic. Association
  for Computational Linguistics.

\bibitem[{Goldberg and Ferreira(2022)}]{goldberg2022good}
Adele~E Goldberg and Fernanda Ferreira. 2022.
\newblock \href {https://doi.org/10.1016/j.tics.2022.01.005} {Good-enough
  language production}.
\newblock \emph{Trends in Cognitive Sciences}.

\bibitem[{Goldszmidt and Pearl(1992)}]{GoldszmidtPearl92}
Mois\'{e}s Goldszmidt and Judea Pearl. 1992.
\newblock \href {https://dl.acm.org/doi/10.5555/3087223.3087290} {Rank-based
  systems: A simple approach to belief revision, belief update, and reasoning
  about evidence and actions}.
\newblock In \emph{Proceedings of the Third International Conference on
  Principles of Knowledge Representation and Reasoning}, KR'92, page 661–672,
  San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.

\bibitem[{Google(2023)}]{google_bard}
Google. 2023.
\newblock \href
  {https://blog.google/technology/ai/bard-google-ai-search-updates/} {An
  important next step on our ai journey}.

\bibitem[{Gruber et~al.(2023)Gruber, Schenk, Schierholz, Kreuter, and
  Kauermann}]{gruber2023sources}
Cornelia Gruber, Patrick~Oliver Schenk, Malte Schierholz, Frauke Kreuter, and
  G{\"o}ran Kauermann. 2023.
\newblock \href {https://arxiv.org/abs/2305.16703} {Sources of uncertainty in
  machine learning--a statisticians' view}.
\newblock \emph{arXiv preprint arXiv:2305.16703}.

\bibitem[{Guerreiro et~al.(2023)Guerreiro, Voita, and
  Martins}]{guerreiro2022looking}
Nuno~M. Guerreiro, Elena Voita, and Andr{\'e} Martins. 2023.
\newblock \href {https://aclanthology.org/2023.eacl-main.75} {Looking for a
  needle in a haystack: A comprehensive study of hallucinations in neural
  machine translation}.
\newblock In \emph{Proceedings of the 17th Conference of the European Chapter
  of the Association for Computational Linguistics}, pages 1059--1075,
  Dubrovnik, Croatia. Association for Computational Linguistics.

\bibitem[{Guo et~al.(2017)Guo, Pleiss, Sun, and
  Weinberger}]{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger. 2017.
\newblock \href {https://proceedings.mlr.press/v70/guo17a.html} {On calibration
  of modern neural networks}.
\newblock In \emph{International Conference on Machine Learning}, pages
  1321--1330. PMLR.

\bibitem[{Hacking(1975)}]{hacking1975emergence}
Ian Hacking. 1975.
\newblock \emph{The emergence of probability: A philosophical study of early
  ideas about probability, induction and statistical inference}.
\newblock Cambridge University Press.

\bibitem[{Hahn and Goyal(2023)}]{hahn2023theory}
Michael Hahn and Navin Goyal. 2023.
\newblock \href {https://arxiv.org/abs/2303.07971} {A theory of emergent
  in-context learning as implicit structure induction}.
\newblock \emph{arXiv preprint arXiv:2303.07971}.

\bibitem[{Halpern(2017)}]{halpern2017reasoning}
Joseph~Y Halpern. 2017.
\newblock \emph{Reasoning about uncertainty}.
\newblock MIT press.

\bibitem[{He et~al.(2023)He, Zhang, Wang, Kumar, Cho, Glass, and
  Tsvetkov}]{he2023blind}
Tianxing He, Jingyu Zhang, Tianle Wang, Sachin Kumar, Kyunghyun Cho, James
  Glass, and Yulia Tsvetkov. 2023.
\newblock On the blind spots of model-based evaluation metrics for text
  generation.
\newblock \emph{arXiv preprint arXiv:2212.10020}.

\bibitem[{Hewitt et~al.(2022)Hewitt, Manning, and
  Liang}]{hewitt-etal-2022-truncation}
John Hewitt, Christopher Manning, and Percy Liang. 2022.
\newblock \href {https://aclanthology.org/2022.findings-emnlp.249} {Truncation
  sampling as language model desmoothing}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2022}, pages 3414--3427, Abu Dhabi, United Arab Emirates. Association
  for Computational Linguistics.

\bibitem[{High(2012)}]{high2012era}
Rob High. 2012.
\newblock The era of cognitive systems: An inside look at ibm watson and how it
  works.
\newblock \emph{IBM Corporation, Redbooks}, 1:16.

\bibitem[{Hintikka(1957)}]{hintikka1957modality}
Jaakko Hintikka. 1957.
\newblock \emph{Modality as referential multiplicity}.
\newblock Filosofisen Yhdistyksen vuosikirja.

\bibitem[{Hintikka(1961)}]{hintikka1961modality}
Jaakko Hintikka. 1961.
\newblock Modality and quantification.
\newblock \emph{Theoria}, 27(3):119--128.

\bibitem[{Holtzman et~al.(2020)Holtzman, Buys, Du, Forbes, and
  Choi}]{Holtzman2020The}
Ari Holtzman, Jan Buys, Li~Du, Maxwell Forbes, and Yejin Choi. 2020.
\newblock \href {https://openreview.net/forum?id=rygGQyrFvH} {The curious case
  of neural text degeneration}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Holtzman et~al.(2021)Holtzman, West, Shwartz, Choi, and
  Zettlemoyer}]{holtzman-etal-2021-surface}
Ari Holtzman, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer.
  2021.
\newblock \href {https://doi.org/10.18653/v1/2021.emnlp-main.564} {Surface form
  competition: Why the highest probability answer isn{'}t always right}.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 7038--7051, Online and Punta Cana,
  Dominican Republic. Association for Computational Linguistics.

\bibitem[{Houlsby et~al.(2011)Houlsby, Husz{\'a}r, Ghahramani, and
  Lengyel}]{houlsby2011bayesian}
Neil Houlsby, Ferenc Husz{\'a}r, Zoubin Ghahramani, and M{\'a}t{\'e} Lengyel.
  2011.
\newblock \href {https://arxiv.org/abs/1112.5745} {Bayesian active learning for
  classification and preference learning}.
\newblock \emph{arXiv preprint arXiv:1112.5745}.

\bibitem[{Hu et~al.(2023)Hu, Zhang, Zhao, Huang, and Wu}]{hu2023uncertainty}
Mengting Hu, Zhen Zhang, Shiwan Zhao, Minlie Huang, and Bingzhe Wu. 2023.
\newblock \href {https://arxiv.org/abs/2306.04459} {Uncertainty in natural
  language processing: Sources, quantification, and applications}.
\newblock \emph{arXiv preprint arXiv:2306.04459}.

\bibitem[{H{\"u}llermeier and Waegeman(2021)}]{hullermeier2021aleatoric}
Eyke H{\"u}llermeier and Willem Waegeman. 2021.
\newblock \href {https://doi.org/10.1007/s10994-021-05946-3} {Aleatoric and
  epistemic uncertainty in machine learning: An introduction to concepts and
  methods}.
\newblock \emph{Machine Learning}, 110:457--506.

\bibitem[{Hupkes et~al.(2022)Hupkes, Giulianelli, Dankers, Artetxe, Elazar,
  Pimentel, Christodoulopoulos, Lasri, Saphra, Sinclair
  et~al.}]{hupkes2022state}
Dieuwke Hupkes, Mario Giulianelli, Verna Dankers, Mikel Artetxe, Yanai Elazar,
  Tiago Pimentel, Christos Christodoulopoulos, Karim Lasri, Naomi Saphra,
  Arabella Sinclair, et~al. 2022.
\newblock \href {https://arxiv.org/abs/2210.03050} {State-of-the-art
  generalisation research in nlp: a taxonomy and review}.
\newblock \emph{arXiv preprint arXiv:2210.03050}.

\bibitem[{Jacovi et~al.(2021)Jacovi, Marasovi{\'c}, Miller, and
  Goldberg}]{jacovi2021formalizing}
Alon Jacovi, Ana Marasovi{\'c}, Tim Miller, and Yoav Goldberg. 2021.
\newblock \href {https://doi.org/10.1145/3442188.3445923} {Formalizing trust in
  artificial intelligence: Prerequisites, causes and goals of human trust in
  ai}.
\newblock In \emph{Proceedings of the 2021 ACM conference on fairness,
  accountability, and transparency}, pages 624--635.

\bibitem[{Ji et~al.(2022)Ji, Lee, Frieske, Yu, Su, Xu, Ishii, Bang, Madotto,
  and Fung}]{hi-survey-2022}
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,
  Yejin Bang, Andrea Madotto, and Pascale Fung. 2022.
\newblock \href {https://doi.org/10.1145/3571730} {Survey of hallucination in
  natural language generation}.
\newblock \emph{ACM Comput. Surv.}
\newblock Just Accepted.

\bibitem[{Jiang and Marneffe(2022)}]{jiang-tacl_a_00523}
Nan-Jiang Jiang and Marie-Catherine~de Marneffe. 2022.
\newblock \href {https://doi.org/10.1162/tacl_a_00523} {{Investigating Reasons
  for Disagreement in Natural Language Inference}}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  10:1357--1374.

\bibitem[{Jiang et~al.(2021)Jiang, Araki, Ding, and Neubig}]{jiang2021can}
Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. 2021.
\newblock \href {https://aclanthology.org/2020.tacl-1.28} {How can we know when
  language models know? on the calibration of language models for question
  answering}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  9:962--977.

\bibitem[{Johnson et~al.(2023)Johnson, Tarlow, and Walder}]{johnson2023ru}
Daniel~D Johnson, Daniel Tarlow, and Christian Walder. 2023.
\newblock \href {https://arxiv.org/abs/2303.00732} {Ru-sure? uncertainty-aware
  code suggestions by maximizing utility across random user intents}.
\newblock \emph{arXiv preprint arXiv:2303.00732}.

\bibitem[{Jordan et~al.(1999)Jordan, Ghahramani, Jaakkola, and
  Saul}]{jordan1999introduction}
Michael~I Jordan, Zoubin Ghahramani, Tommi~S Jaakkola, and Lawrence~K Saul.
  1999.
\newblock \href {https://doi.org/10.1023/A:1007665907178} {An introduction to
  variational methods for graphical models}.
\newblock \emph{Machine learning}, 37:183--233.

\bibitem[{Kadavath et~al.(2022)Kadavath, Conerly, Askell, Henighan, Drain,
  Perez, Schiefer, Dodds, DasSarma, Tran-Johnson et~al.}]{kadavath2022language}
Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan
  Perez, Nicholas Schiefer, Zac~Hatfield Dodds, Nova DasSarma, Eli
  Tran-Johnson, et~al. 2022.
\newblock \href {https://arxiv.org/abs/2207.05221} {Language models (mostly)
  know what they know}.
\newblock \emph{arXiv preprint arXiv:2207.05221}.

\bibitem[{Kamath et~al.(2020)Kamath, Jia, and Liang}]{kamath2020selective}
Amita Kamath, Robin Jia, and Percy Liang. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.503} {Selective
  question answering under domain shift}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 5684--5696, Online. Association for
  Computational Linguistics.

\bibitem[{Kim et~al.(2019{\natexlab{a}})Kim, Dyer, and
  Rush}]{kim-etal-2019-compound}
Yoon Kim, Chris Dyer, and Alexander Rush. 2019{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/P19-1228} {Compound probabilistic
  context-free grammars for grammar induction}.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 2369--2385, Florence, Italy.
  Association for Computational Linguistics.

\bibitem[{Kim et~al.(2019{\natexlab{b}})Kim, Rush, Yu, Kuncoro, Dyer, and
  Melis}]{kim-etal-2019-unsupervised}
Yoon Kim, Alexander Rush, Lei Yu, Adhiguna Kuncoro, Chris Dyer, and G{\'a}bor
  Melis. 2019{\natexlab{b}}.
\newblock \href {https://doi.org/10.18653/v1/N19-1114} {Unsupervised recurrent
  neural network grammars}.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 1105--1117,
  Minneapolis, Minnesota. Association for Computational Linguistics.

\bibitem[{Knight(1921)}]{knight1921risk}
Frank~Hyneman Knight. 1921.
\newblock \emph{Risk, uncertainty and profit}, volume~31.
\newblock Houghton Mifflin.

\bibitem[{Kolmogorov(1960)}]{kolmogorov1960foundations}
Andrey~N. Kolmogorov. 1960.
\newblock \emph{Foundations of the Theory of Probability}, 2 edition.
\newblock Chelsea Pub Co.

\bibitem[{Kompa et~al.(2021)Kompa, Snoek, and Beam}]{kompa2021empirical}
Benjamin Kompa, Jasper Snoek, and Andrew~L Beam. 2021.
\newblock \href {https://doi.org/10.3390/e23121608} {Empirical frequentist
  coverage of deep learning uncertainty quantification procedures}.
\newblock \emph{Entropy}, 23(12):1608.

\bibitem[{Kuhn et~al.(2023)Kuhn, Gal, and Farquhar}]{kuhn2023semantic}
Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023.
\newblock \href {https://openreview.net/forum?id=VD-AYtP0dve} {Semantic
  uncertainty: Linguistic invariances for uncertainty estimation in natural
  language generation}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}.

\bibitem[{Kumar and Sarawagi(2019)}]{kumar2019calibration}
Aviral Kumar and Sunita Sarawagi. 2019.
\newblock \href {https://arxiv.org/abs/1903.00802} {Calibration of encoder
  decoder models for neural machine translation}.
\newblock \emph{arXiv preprint arXiv:1903.00802}.

\bibitem[{Lahlou et~al.(2021)Lahlou, Jain, Nekoei, Butoi, Bertin,
  Rector-Brooks, Korablyov, and Bengio}]{lahlou2021deup}
Salem Lahlou, Moksh Jain, Hadi Nekoei, Victor~Ion Butoi, Paul Bertin, Jarrid
  Rector-Brooks, Maksym Korablyov, and Yoshua Bengio. 2021.
\newblock \href {https://arxiv.org/abs/2102.08501} {Deup: Direct epistemic
  uncertainty prediction}.
\newblock \emph{arXiv preprint arXiv:2102.08501}.

\bibitem[{Lee et~al.(2022)Lee, Cheung, and Zhang}]{lee-etal-2022-adaptive}
Dongkyu Lee, Ka~Chun Cheung, and Nevin Zhang. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.664} {Adaptive label
  smoothing with self-knowledge in natural language generation}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 9781--9792, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Lehmann and Romano(2005)}]{lehmann2005testing}
E.~L. Lehmann and Joseph~P. Romano. 2005.
\newblock \emph{Testing statistical hypotheses}, third edition.
\newblock Springer Texts in Statistics. Springer, New York.

\bibitem[{Lehmann(1993)}]{lehmann1993fisher}
Erich~L Lehmann. 1993.
\newblock \href
  {https://www.tandfonline.com/doi/abs/10.1080/01621459.1993.10476404} {The
  fisher, neyman-pearson theories of testing hypotheses: one theory or two?}
\newblock \emph{Journal of the American statistical Association},
  88(424):1242--1249.

\bibitem[{Lehmann and Casella(1998)}]{LehmCase98}
Erich~L. Lehmann and George Casella. 1998.
\newblock \emph{Theory of Point Estimation}, second edition.
\newblock Springer-Verlag, New York, NY, USA.

\bibitem[{Levelt(1993)}]{levelt1993speaking}
Willem~JM Levelt. 1993.
\newblock \emph{Speaking: {F}rom intention to articulation}.
\newblock MIT press.

\bibitem[{Lewis(1995)}]{lewis1995sequential}
David~D Lewis. 1995.
\newblock \href {https://doi.org/10.1007/978-1-4471-2099-5_1} {A sequential
  algorithm for training text classifiers: Corrigendum and additional data}.
\newblock In \emph{Acm Sigir Forum}, volume~29, pages 13--19. ACM New York, NY,
  USA.

\bibitem[{Lewis et~al.(2020)Lewis, Perez, Piktus, Petroni, Karpukhin, Goyal,
  K\"{u}ttler, Lewis, Yih, Rockt\"{a}schel, Riedel, and Kiela}]{lewis2020rag}
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
  Karpukhin, Naman Goyal, Heinrich K\"{u}ttler, Mike Lewis, Wen-tau Yih, Tim
  Rockt\"{a}schel, Sebastian Riedel, and Douwe Kiela. 2020.
\newblock \href
  {https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html}
  {Retrieval-augmented generation for knowledge-intensive nlp tasks}.
\newblock In \emph{Proceedings of the 34th International Conference on Neural
  Information Processing Systems}, NIPS'20, Red Hook, NY, USA. Curran
  Associates Inc.

\bibitem[{Li et~al.(2016)Li, Galley, Brockett, Gao, and
  Dolan}]{li-etal-2016-diversity}
Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016.
\newblock \href {https://doi.org/10.18653/v1/N16-1014} {A diversity-promoting
  objective function for neural conversation models}.
\newblock In \emph{Proceedings of the 2016 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 110--119, San Diego, California. Association for
  Computational Linguistics.

\bibitem[{Liao and Vaughan(2023)}]{liao2023ai}
Q~Vera Liao and Jennifer~Wortman Vaughan. 2023.
\newblock \href {https://arxiv.org/abs/2306.01941} {Ai transparency in the age
  of llms: A human-centered research roadmap}.
\newblock \emph{arXiv preprint arXiv:2306.01941}.

\bibitem[{Lin(2004)}]{lin-2004-rouge}
Chin-Yew Lin. 2004.
\newblock \href {https://aclanthology.org/W04-1013} {{ROUGE}: A package for
  automatic evaluation of summaries}.
\newblock In \emph{Text Summarization Branches Out}, pages 74--81, Barcelona,
  Spain. Association for Computational Linguistics.

\bibitem[{Lin et~al.(2022)Lin, Hilton, and Evans}]{lin2022teaching}
Stephanie Lin, Jacob Hilton, and Owain Evans. 2022.
\newblock \href {https://openreview.net/forum?id=8s8K2UZGTZ} {Teaching models
  to express their uncertainty in words}.
\newblock \emph{Transactions on Machine Learning Research}.

\bibitem[{Lin et~al.(2023)Lin, Trivedi, and Sun}]{lin2023generating}
Zhen Lin, Shubhendu Trivedi, and Jimeng Sun. 2023.
\newblock \href {https://arxiv.org/abs/2305.19187} {Generating with confidence:
  Uncertainty quantification for black-box large language models}.
\newblock \emph{arXiv preprint arXiv:2305.19187}.

\bibitem[{Lindley(2013)}]{lindley2013understanding}
Dennis~V Lindley. 2013.
\newblock \emph{Understanding uncertainty}.
\newblock John Wiley \& Sons.

\bibitem[{Liu et~al.(2020)Liu, Lin, Padhy, Tran, Bedrax~Weiss, and
  Lakshminarayanan}]{liu2020sngp}
Jeremiah Liu, Zi~Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax~Weiss, and
  Balaji Lakshminarayanan. 2020.
\newblock \href
  {https://proceedings.neurips.cc/paper_files/paper/2020/file/543e83748234f7cbab21aa0ade66565f-Paper.pdf}
  {Simple and principled uncertainty estimation with deterministic deep
  learning via distance awareness}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 7498--7512. Curran Associates, Inc.

\bibitem[{Lyu et~al.(2020)Lyu, Duolikun, Dai, Yao, Minervini, Xiao, and
  Gal}]{lyu2020you}
Zhihao Lyu, Danier Duolikun, Bowei Dai, Yuan Yao, Pasquale Minervini, Tim~Z
  Xiao, and Yarin Gal. 2020.
\newblock You need only uncertain answers: Data efficient multilingual question
  answering.
\newblock \emph{Workshop on Uncertainty and Robustness in Deep Learning}.

\bibitem[{Malinin and Gales(2021)}]{malinin2020uncertainty}
Andrey Malinin and Mark J.~F. Gales. 2021.
\newblock \href {https://openreview.net/forum?id=jN5y-zb5Q7m} {Uncertainty
  estimation in autoregressive structured prediction}.
\newblock In \emph{9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net.

\bibitem[{Meister and Cotterell(2021)}]{meister-cotterell-2021-language}
Clara Meister and Ryan Cotterell. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.acl-long.414} {Language model
  evaluation beyond perplexity}.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pages 5328--5339,
  Online. Association for Computational Linguistics.

\bibitem[{Meister et~al.(2020)Meister, Cotterell, and
  Vieira}]{meister-etal-2020-beam}
Clara Meister, Ryan Cotterell, and Tim Vieira. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.170} {If beam
  search is the answer, what was the question?}
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 2173--2185, Online. Association
  for Computational Linguistics.

\bibitem[{Mena et~al.(2021)Mena, Pujol, and Vitri\`{a}}]{mena-survey-2022}
Jos\'{e} Mena, Oriol Pujol, and Jordi Vitri\`{a}. 2021.
\newblock \href {https://doi.org/10.1145/3477140} {A survey on uncertainty
  estimation in deep learning classification systems from a bayesian
  perspective}.
\newblock \emph{ACM Comput. Surv.}, 54(9).

\bibitem[{Menzel(2023)}]{sep-possible-worlds}
Christopher Menzel. 2023.
\newblock {Possible Worlds}.
\newblock In Edward~N. Zalta and Uri Nodelman, editors, \emph{The {Stanford}
  Encyclopedia of Philosophy}, {S}ummer 2023 edition. Metaphysics Research Lab,
  Stanford University.

\bibitem[{Mielke et~al.(2022)Mielke, Szlam, Dinan, and
  Boureau}]{mielke2022reducing}
Sabrina~J Mielke, Arthur Szlam, Emily Dinan, and Y-Lan Boureau. 2022.
\newblock \href {https://aclanthology.org/2022.tacl-1.50} {Reducing
  conversational agents’ overconfidence through linguistic calibration}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  10:857--872.

\bibitem[{Mishra et~al.(2022)Mishra, Khashabi, Baral, and
  Hajishirzi}]{mishra-etal-2022-cross}
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.acl-long.244} {Cross-task
  generalization via natural language crowdsourcing instructions}.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 3470--3487,
  Dublin, Ireland. Association for Computational Linguistics.

\bibitem[{Moon et~al.(2019)Moon, Shah, Kumar, and
  Subba}]{moon-etal-2019-opendialkg}
Seungwhan Moon, Pararth Shah, Anuj Kumar, and Rajen Subba. 2019.
\newblock \href {https://doi.org/10.18653/v1/P19-1081} {{O}pen{D}ial{KG}:
  Explainable conversational reasoning with attention-based walks over
  knowledge graphs}.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 845--854, Florence, Italy. Association
  for Computational Linguistics.

\bibitem[{Moreno-Torres et~al.(2012)Moreno-Torres, Raeder,
  Alaiz-Rodr{\'\i}guez, Chawla, and Herrera}]{moreno2012unifying}
Jose~G Moreno-Torres, Troy Raeder, Roc{\'\i}o Alaiz-Rodr{\'\i}guez, Nitesh~V
  Chawla, and Francisco Herrera. 2012.
\newblock \href {https://doi.org/10.1016/j.patcog.2011.06.019} {A unifying view
  on dataset shift in classification}.
\newblock \emph{Pattern recognition}, 45(1):521--530.

\bibitem[{Morgan and Henrion(1990)}]{morgan_henrion_1990}
Millett~Granger Morgan and Max Henrion. 1990.
\newblock \href {https://doi.org/10.1017/CBO9780511840609} {\emph{Uncertainty:
  A Guide to Dealing with Uncertainty in Quantitative Risk and Policy
  Analysis}}.
\newblock Cambridge University Press.

\bibitem[{Naeini et~al.(2015)Naeini, Cooper, and
  Hauskrecht}]{naeini2015obtaining}
Mahdi~Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht. 2015.
\newblock \href {https://doi.org/10.1609/aaai.v29i1.9602} {Obtaining well
  calibrated probabilities using bayesian binning}.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~29.

\bibitem[{Nguyen et~al.(2020)Nguyen, Joty, Hoi, and Socher}]{nguyen2020tree}
Xuan{-}Phi Nguyen, Shafiq~R. Joty, Steven C.~H. Hoi, and Richard Socher. 2020.
\newblock \href {https://openreview.net/forum?id=HJxK5pEYvr} {Tree-structured
  attention with hierarchical accumulation}.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net.

\bibitem[{Ogden and Richards(1923)}]{ogden-richards-1923meaning}
Charles~Kay Ogden and Ivor~Armstrong Richards. 1923.
\newblock \emph{The meaning of meaning: A study of the influence of thought and
  of the science of symbolism}.
\newblock Harcourt, Brace \& World, Inc.

\bibitem[{OpenAI(2022)}]{openai_chatgpt}
OpenAI. 2022.
\newblock \href {https://openai.com/blog/chatgpt} {Introducing chatgpt}.

\bibitem[{Osband et~al.(2022)Osband, Asghari, Van~Roy, McAleese, Aslanides, and
  Irving}]{osband2023finetuning}
Ian Osband, Seyed~Mohammad Asghari, Benjamin Van~Roy, Nat McAleese, John
  Aslanides, and Geoffrey Irving. 2022.
\newblock \href {https://arxiv.org/abs/2211.01568} {Fine-tuning language models
  via epistemic neural networks}.
\newblock \emph{arXiv preprint arXiv:2211.01568}.

\bibitem[{Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Gray, Schulman, Hilton, Kelton, Miller, Simens,
  Askell, Welinder, Christiano, Leike, and Lowe}]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John
  Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
  Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
\newblock \href {https://openreview.net/forum?id=TG8KACxEON} {Training language
  models to follow instructions with human feedback}.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Papadopoulos et~al.(2002)Papadopoulos, Proedrou, Vovk, and
  Gammerman}]{papadopoulos2002inductive}
Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alex Gammerman. 2002.
\newblock \href {https://doi.org/10.1007/3-540-36755-1_29} {Inductive
  confidence machines for regression}.
\newblock In \emph{Machine Learning: ECML 2002: 13th European Conference on
  Machine Learning Helsinki, Finland, August 19--23, 2002 Proceedings 13},
  pages 345--356. Springer.

\bibitem[{Papineni et~al.(2002)Papineni, Roukos, Ward, and
  Zhu}]{papineni-etal-2002-bleu}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.
\newblock \href {https://doi.org/10.3115/1073083.1073135} {{B}leu: a method for
  automatic evaluation of machine translation}.
\newblock In \emph{Proceedings of the 40th Annual Meeting of the Association
  for Computational Linguistics}, pages 311--318, Philadelphia, Pennsylvania,
  USA. Association for Computational Linguistics.

\bibitem[{Parmar et~al.(2023)Parmar, Mishra, Geva, and
  Baral}]{parmar-etal-2023-dont}
Mihir Parmar, Swaroop Mishra, Mor Geva, and Chitta Baral. 2023.
\newblock \href {https://aclanthology.org/2023.eacl-main.130} {Don{'}t blame
  the annotator: Bias already starts in the annotation instructions}.
\newblock In \emph{Proceedings of the 17th Conference of the European Chapter
  of the Association for Computational Linguistics}, pages 1779--1789,
  Dubrovnik, Croatia. Association for Computational Linguistics.

\bibitem[{Paulus et~al.(2018)Paulus, Xiong, and Socher}]{paulus2018a}
Romain Paulus, Caiming Xiong, and Richard Socher. 2018.
\newblock \href {https://openreview.net/forum?id=HkAClQgA-} {A deep reinforced
  model for abstractive summarization}.
\newblock In \emph{6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
  Proceedings}. OpenReview.net.

\bibitem[{Pillutla et~al.(2021)Pillutla, Swayamdipta, Zellers, Thickstun,
  Welleck, Choi, and Harchaoui}]{pillutla2021mauve}
Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean
  Welleck, Yejin Choi, and Zaid Harchaoui. 2021.
\newblock \href {https://openreview.net/forum?id=Tqx7nJp7PR} {Mauve: Measuring
  the gap between neural text and human text using divergence frontiers}.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:4816--4828.

\bibitem[{Pimentel et~al.(2023)Pimentel, Meister, and
  Cotterell}]{pimentel2023on}
Tiago Pimentel, Clara Meister, and Ryan Cotterell. 2023.
\newblock \href {https://openreview.net/pdf?id=bvpkw7UIRdU} {On the usefulness
  of embeddings, clusters and strings for text generation evaluation}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net.

\bibitem[{Plank(2022)}]{plank-2022-problem}
Barbara Plank. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.731} {The
  {``}problem{''} of human label variation: On ground truth in data, modeling
  and evaluation}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 10671--10682, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{van~der Poel et~al.(2022)van~der Poel, Cotterell, and
  Meister}]{van2022mutual}
Liam van~der Poel, Ryan Cotterell, and Clara Meister. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.399} {Mutual
  information alleviates hallucinations in abstractive summarization}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 5956--5965, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Poesio et~al.(2019)Poesio, Chamberlain, Paun, Yu, Uma, and
  Kruschwitz}]{poesio-etal-2019-crowdsourced}
Massimo Poesio, Jon Chamberlain, Silviu Paun, Juntao Yu, Alexandra Uma, and Udo
  Kruschwitz. 2019.
\newblock \href {https://doi.org/10.18653/v1/N19-1176} {A crowdsourced corpus
  of multiple judgments and disagreement on anaphoric interpretation}.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 1778--1789,
  Minneapolis, Minnesota. Association for Computational Linguistics.

\bibitem[{Quach et~al.(2023)Quach, Fisch, Schuster, Yala, Sohn, Jaakkola, and
  Barzilay}]{quach2023conformal}
Victor Quach, Adam Fisch, Tal Schuster, Adam Yala, Jae~Ho Sohn, Tommi~S
  Jaakkola, and Regina Barzilay. 2023.
\newblock \href {https://arxiv.org/abs/2306.10193} {Conformal language
  modeling}.
\newblock \emph{arXiv preprint arXiv:2306.10193}.

\bibitem[{Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever
  et~al.}]{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
  Sutskever, et~al. 2019.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1(8):9.

\bibitem[{Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu}]{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J Liu. 2020.
\newblock \href {https://jmlr.org/papers/v21/20-074.html} {Exploring the limits
  of transfer learning with a unified text-to-text transformer}.
\newblock \emph{The Journal of Machine Learning Research}, 21(1):5485--5551.

\bibitem[{Ramsey(1931)}]{ramsey1931foundations}
Frank~Plumpton Ramsey. 1931.
\newblock \emph{The foundations of mathematics and other logical essays}.
\newblock K. Paul, Trench, Trubner \& Company, Limited.

\bibitem[{Rasmussen et~al.(2006)Rasmussen, Williams
  et~al.}]{rasmussen2006gaussian}
Carl~Edward Rasmussen, Christopher~KI Williams, et~al. 2006.
\newblock \href {https://doi.org/10.7551/mitpress/3206.001.0001}
  {\emph{Gaussian processes for machine learning}}, volume~1.
\newblock Springer.

\bibitem[{Ravfogel et~al.(2023)Ravfogel, Goldberg, and
  Goldberger}]{ravfogel2023conformal}
Shauli Ravfogel, Yoav Goldberg, and Jacob Goldberger. 2023.
\newblock \href {https://aclanthology.org/2023.findings-acl.3} {Conformal
  nucleus sampling}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  {ACL} 2023, Toronto, Canada, July 9-14, 2023}, pages 27--34. Association for
  Computational Linguistics.

\bibitem[{Rei et~al.(2020)Rei, Stewart, Farinha, and
  Lavie}]{rei-etal-2020-comet}
Ricardo Rei, Craig Stewart, Ana~C Farinha, and Alon Lavie. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.213} {{COMET}: A
  neural framework for {MT} evaluation}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 2685--2702, Online. Association
  for Computational Linguistics.

\bibitem[{Reiter and Dale(2000)}]{reiter_dale_2000}
Ehud Reiter and Robert Dale. 2000.
\newblock \href {https://doi.org/10.1017/CBO9780511519857} {\emph{Building
  Natural Language Generation Systems}}.
\newblock Studies in Natural Language Processing. Cambridge University Press.

\bibitem[{Ren et~al.(2023{\natexlab{a}})Ren, Dixit, Bodrova, Singh, Tu, Brown,
  Xu, Takayama, Xia, Varley et~al.}]{ren2023robots}
Allen~Z Ren, Anushri Dixit, Alexandra Bodrova, Sumeet Singh, Stephen Tu, Noah
  Brown, Peng Xu, Leila Takayama, Fei Xia, Jake Varley, et~al.
  2023{\natexlab{a}}.
\newblock \href {https://arxiv.org/abs/2307.01928} {Robots that ask for help:
  Uncertainty alignment for large language model planners}.
\newblock \emph{arXiv preprint arXiv:2307.01928}.

\bibitem[{Ren et~al.(2023{\natexlab{b}})Ren, Luo, Zhao, Krishna, Saleh,
  Lakshminarayanan, and Liu}]{ren2023outofdistribution}
Jie Ren, Jiaming Luo, Yao Zhao, Kundan Krishna, Mohammad Saleh, Balaji
  Lakshminarayanan, and Peter~J Liu. 2023{\natexlab{b}}.
\newblock \href {https://openreview.net/forum?id=kJUS5nD0vPB}
  {Out-of-distribution detection and selective generation for conditional
  language models}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}.

\bibitem[{Robert et~al.(1999)Robert, Casella, and Casella}]{robert1999monte}
Christian~P Robert, George Casella, and George Casella. 1999.
\newblock \emph{Monte Carlo statistical methods}, volume~2.
\newblock Springer.

\bibitem[{Sandri et~al.(2023)Sandri, Leonardelli, Tonelli, and
  Jezek}]{sandri-etal-2023-dont}
Marta Sandri, Elisa Leonardelli, Sara Tonelli, and Elisabetta Jezek. 2023.
\newblock \href {https://aclanthology.org/2023.eacl-main.178} {Why don{'}t you
  do it right? analysing annotators{'} disagreement in subjective tasks}.
\newblock In \emph{Proceedings of the 17th Conference of the European Chapter
  of the Association for Computational Linguistics}, pages 2428--2441,
  Dubrovnik, Croatia. Association for Computational Linguistics.

\bibitem[{Sankararaman et~al.(2022)Sankararaman, Wang, and
  Fang}]{sankararaman2022bayesformer}
Karthik~Abinav Sankararaman, Sinong Wang, and Han Fang. 2022.
\newblock \href {https://arxiv.org/abs/2206.00826} {Bayesformer: Transformer
  with uncertainty estimation}.
\newblock \emph{arXiv preprint arXiv:2206.00826}.

\bibitem[{Savage(1972)}]{savage1972foundations}
Leonard~J Savage. 1972.
\newblock \emph{The foundations of statistics}.
\newblock Courier Corporation.

\bibitem[{Schick et~al.(2023)Schick, Dwivedi-Yu, Dessì, Raileanu, Lomeli,
  Zettlemoyer, Cancedda, and Scialom}]{schick2023toolformer}
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli,
  Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.
\newblock \href {https://arxiv.org/abs/2302.04761} {Toolformer: Language models
  can teach themselves to use tools}.
\newblock \emph{arXiv preprint arXiv:2302.04761}.

\bibitem[{Scovel(1998)}]{scovel1998psycholinguistics}
Thomas Scovel. 1998.
\newblock \emph{Psycholinguistics}.
\newblock Oxford University Press.

\bibitem[{Sellam et~al.(2020)Sellam, Das, and Parikh}]{sellam-etal-2020-bleurt}
Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.704} {{BLEURT}:
  Learning robust metrics for text generation}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 7881--7892, Online. Association for
  Computational Linguistics.

\bibitem[{Sennrich et~al.(2016{\natexlab{a}})Sennrich, Haddow, and
  Birch}]{sennrich-etal-2016-controlling}
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/N16-1005} {Controlling politeness
  in neural machine translation via side constraints}.
\newblock In \emph{Proceedings of the 2016 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 35--40, San Diego, California. Association for
  Computational Linguistics.

\bibitem[{Sennrich et~al.(2016{\natexlab{b}})Sennrich, Haddow, and
  Birch}]{sennrich-etal-2016-neural}
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016{\natexlab{b}}.
\newblock \href {https://doi.org/10.18653/v1/P16-1162} {Neural machine
  translation of rare words with subword units}.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 1715--1725,
  Berlin, Germany. Association for Computational Linguistics.

\bibitem[{Shafer(1976)}]{shafer76}
Glenn Shafer. 1976.
\newblock \href {http://www.jstor.org/stable/j.ctv10vm1qb} {\emph{A
  Mathematical Theory of Evidence}}.
\newblock Princeton University Press.

\bibitem[{Shen et~al.(2016)Shen, Cheng, He, He, Wu, Sun, and
  Liu}]{shen-etal-2016-minimum}
Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua Wu, Maosong Sun, and Yang Liu.
  2016.
\newblock \href {https://doi.org/10.18653/v1/P16-1159} {Minimum risk training
  for neural machine translation}.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 1683--1692,
  Berlin, Germany. Association for Computational Linguistics.

\bibitem[{Si et~al.(2023)Si, Gan, Yang, Wang, Wang, Boyd-Graber, and
  Wang}]{si2023prompting}
Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan~Lee
  Boyd-Graber, and Lijuan Wang. 2023.
\newblock \href {https://openreview.net/forum?id=98p5x51L5af} {Prompting
  {GPT}-3 to be reliable}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}.

\bibitem[{Siddhant and Lipton(2018)}]{siddhant-lipton-2018-deep}
Aditya Siddhant and Zachary~C. Lipton. 2018.
\newblock \href {https://doi.org/10.18653/v1/D18-1318} {Deep {B}ayesian active
  learning for natural language processing: Results of a large-scale empirical
  study}.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 2904--2909, Brussels, Belgium.
  Association for Computational Linguistics.

\bibitem[{Stahlberg and Byrne(2019)}]{stahlberg-byrne-2019-nmt}
Felix Stahlberg and Bill Byrne. 2019.
\newblock \href {https://doi.org/10.18653/v1/D19-1331} {On {NMT} search errors
  and model errors: Cat got your tongue?}
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 3356--3362, Hong Kong,
  China. Association for Computational Linguistics.

\bibitem[{Stahlberg and Kumar(2022)}]{stahlberg2022scones}
Felix Stahlberg and Shankar Kumar. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.naacl-main.365} {Jam or cream
  first? modeling ambiguity in neural machine translation with {SCONES}}.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 4950--4961, Seattle, United States. Association for
  Computational Linguistics.

\bibitem[{Stengel-Eskin et~al.(2023)Stengel-Eskin, Rawlins, and
  Van~Durme}]{stengel2023zero}
Elias Stengel-Eskin, Kyle Rawlins, and Benjamin Van~Durme. 2023.
\newblock \href {https://arxiv.org/abs/2306.00824} {Zero and few-shot semantic
  parsing with ambiguous inputs}.
\newblock \emph{arXiv preprint arXiv:2306.00824}.

\bibitem[{Stiennon et~al.(2020)Stiennon, Ouyang, Wu, Ziegler, Lowe, Voss,
  Radford, Amodei, and Christiano}]{stiennon2020learning}
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea
  Voss, Alec Radford, Dario Amodei, and Paul~F Christiano. 2020.
\newblock \href
  {https://proceedings.neurips.cc/paper/2020/hash/1f89885d556929e98d3ef9b86448f951-Abstract.html}
  {Learning to summarize with human feedback}.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:3008--3021.

\bibitem[{Sun et~al.(2022)Sun, Wang, Zhou, Zhao, Huang, Chen, and
  Li}]{sun-etal-2022-rethinking}
Zewei Sun, Mingxuan Wang, Hao Zhou, Chengqi Zhao, Shujian Huang, Jiajun Chen,
  and Lei Li. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.findings-acl.279} {Rethinking
  document-level neural machine translation}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2022}, pages 3537--3548, Dublin, Ireland. Association for Computational
  Linguistics.

\bibitem[{Taori and Hashimoto(2023)}]{taori2022data}
Rohan Taori and Tatsunori Hashimoto. 2023.
\newblock Data feedback loops: Model-driven amplification of dataset biases.
\newblock In \emph{International Conference on Machine Learning}, pages
  33883--33920. PMLR.

\bibitem[{Tifrea et~al.(2022)Tifrea, Clarysse, and Yang}]{tifrea2022uniform}
Alexandru Tifrea, Jacob Clarysse, and Fanny Yang. 2022.
\newblock Uniform versus uncertainty sampling: When being active is less
  efficient than staying passive.
\newblock \emph{arXiv preprint arXiv:2212.00772}.

\bibitem[{Touvron et~al.(2023{\natexlab{a}})Touvron, Lavril, Izacard, Martinet,
  Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar
  et~al.}]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al. 2023{\natexlab{a}}.
\newblock \href {https://arxiv.org/abs/2302.13971} {Llama: Open and efficient
  foundation language models}.
\newblock \emph{arXiv preprint arXiv:2302.13971}.

\bibitem[{Touvron et~al.(2023{\natexlab{b}})Touvron, Martin, Stone, Albert,
  Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale
  et~al.}]{touvron2023llama2}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
  Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
  et~al. 2023{\natexlab{b}}.
\newblock \href {https://arxiv.org/abs/2307.09288} {Llama 2: Open foundation
  and fine-tuned chat models}.
\newblock \emph{arXiv preprint arXiv:2307.09288}.

\bibitem[{Turing(1950)}]{turing1950computing}
Alan Turing. 1950.
\newblock \href {https://doi.org/10.1093/mind/LIX.236.433} {{Computing
  Machinery and Intelligence}}.
\newblock \emph{Mind}, LIX(236):433--460.

\bibitem[{Ulmer et~al.(2022)Ulmer, Frellsen, and
  Hardmeier}]{ulmer2022exploring}
Dennis Ulmer, Jes Frellsen, and Christian Hardmeier. 2022.
\newblock \href {https://aclanthology.org/2022.findings-emnlp.198} {Exploring
  predictive uncertainty and calibration in {NLP}: A study on the impact of
  method {\&} data scarcity}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2022}, pages 2707--2735, Abu Dhabi, United Arab Emirates. Association
  for Computational Linguistics.

\bibitem[{Van~Landeghem et~al.(2022)Van~Landeghem, Blaschko, Anckaert, and
  Moens}]{van2022benchmarking}
Jordy Van~Landeghem, Matthew Blaschko, Bertrand Anckaert, and Marie-Francine
  Moens. 2022.
\newblock \href {https://doi.org/10.1109/ACCESS.2022.3168734} {Benchmarking
  scalable predictive uncertainty in text classification}.
\newblock \emph{IEEE Access}.

\bibitem[{Veselovsky et~al.(2023)Veselovsky, Ribeiro, and
  West}]{veselovsky2023artificial}
Veniamin Veselovsky, Manoel~Horta Ribeiro, and Robert West. 2023.
\newblock \href {https://arxiv.org/abs/2306.07899} {Artificial artificial
  artificial intelligence: Crowd workers widely use large language models for
  text production tasks}.
\newblock \emph{arXiv preprint arXiv:2306.07899}.

\bibitem[{Von~Neumann and Morgenstern(1947)}]{von1947theory}
John Von~Neumann and Oskar Morgenstern. 1947.
\newblock \emph{Theory of games and economic behavior, 2nd rev}.
\newblock Princeton university press.

\bibitem[{Vovk et~al.(2005)Vovk, Gammerman, and Shafer}]{vovk2005algorithmic}
Vladimir Vovk, Alexander Gammerman, and Glenn Shafer. 2005.
\newblock \emph{Algorithmic learning in a random world}, volume~29.
\newblock Springer.

\bibitem[{Wald(1951)}]{Wald1951StatisticalDF}
Abraham Wald. 1951.
\newblock Statistical decision functions.
\newblock \emph{Nature}, 167:1044--1044.

\bibitem[{Wang et~al.(2017)Wang, Tu, Way, and
  Liu}]{wang-etal-2017-exploiting-cross}
Longyue Wang, Zhaopeng Tu, Andy Way, and Qun Liu. 2017.
\newblock \href {https://doi.org/10.18653/v1/D17-1301} {Exploiting
  cross-sentence context for neural machine translation}.
\newblock In \emph{Proceedings of the 2017 Conference on Empirical Methods in
  Natural Language Processing}, pages 2826--2831, Copenhagen, Denmark.
  Association for Computational Linguistics.

\bibitem[{Wang et~al.(2019)Wang, Lee, and Chen}]{wang2019tree}
Yau{-}Shian Wang, Hung{-}yi Lee, and Yun{-}Nung Chen. 2019.
\newblock \href {https://aclanthology.org/D19-1098} {Tree transformer:
  Integrating tree structures into self-attention}.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing, {EMNLP-IJCNLP} 2019, Hong Kong, China, November
  3-7, 2019}, pages 1061--1070. Association for Computational Linguistics.

\bibitem[{Wei et~al.(2022)Wei, Bosma, Zhao, Guu, Yu, Lester, Du, Dai, and
  Le}]{wei2022finetuned}
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams~Wei Yu, Brian Lester,
  Nan Du, Andrew~M. Dai, and Quoc~V Le. 2022.
\newblock \href {https://openreview.net/forum?id=gEZrGCozdqR} {Finetuned
  language models are zero-shot learners}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Weizenbaum(1966)}]{weizenbaum1966eliza}
Joseph Weizenbaum. 1966.
\newblock Eliza—a computer program for the study of natural language
  communication between man and machine.
\newblock \emph{Communications of the ACM}, 9(1):36--45.

\bibitem[{Xiang et~al.(2021)Xiang, Liu, Cai, Li, Lian, and
  Liu}]{xiang-etal-2021-assessing}
Jiannan Xiang, Yahui Liu, Deng Cai, Huayang Li, Defu Lian, and Lemao Liu. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.findings-acl.193} {Assessing
  dialogue systems with distribution distances}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL-IJCNLP 2021}, pages 2192--2198, Online. Association for Computational
  Linguistics.

\bibitem[{Xiao et~al.(2020)Xiao, Gomez, and Gal}]{xiao2020wat}
Tim~Z Xiao, Aidan~N Gomez, and Yarin Gal. 2020.
\newblock \href {https://arxiv.org/abs/2006.08344} {Wat zei je? detecting
  out-of-distribution translations with variational transformers}.
\newblock \emph{arXiv preprint arXiv:2006.08344}.

\bibitem[{Xiao and Wang(2021)}]{xiao2021hallucination}
Yijun Xiao and William~Yang Wang. 2021.
\newblock \href {https://aclanthology.org/2021.eacl-main.236} {On hallucination
  and predictive uncertainty in conditional language generation}.
\newblock In \emph{Proceedings of the 16th Conference of the European Chapter
  of the Association for Computational Linguistics: Main Volume, {EACL} 2021,
  Online, April 19 - 23, 2021}, pages 2734--2744. Association for Computational
  Linguistics.

\bibitem[{Xie et~al.(2022)Xie, Raghunathan, Liang, and Ma}]{xie2022explanation}
Sang~Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. 2022.
\newblock An explanation of in-context learning as implicit bayesian inference.
\newblock In \emph{The Tenth International Conference on Learning
  Representations, {ICLR} 2022, Virtual Event, April 25-29, 2022}.
  OpenReview.net.

\bibitem[{Yao et~al.(2019)Yao, Pan, Ghosh, and Doshi-Velez}]{yao2019quality}
Jiayu Yao, Weiwei Pan, Soumya Ghosh, and Finale Doshi-Velez. 2019.
\newblock Quality of uncertainty quantification for bayesian neural network
  inference.
\newblock \emph{arXiv preprint arXiv:1906.09686}.

\bibitem[{Yao et~al.(2023)Yao, Zhao, Yu, Du, Shafran, Narasimhan, and
  Cao}]{yao2022react}
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik~R.
  Narasimhan, and Yuan Cao. 2023.
\newblock \href {https://openreview.net/pdf?id=WE\_vluYUL-X} {React:
  Synergizing reasoning and acting in language models}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}.

\bibitem[{Yoshikawa and Okazaki(2023)}]{yoshikawa2023selective}
Hiyori Yoshikawa and Naoaki Okazaki. 2023.
\newblock Selective-lama: Selective prediction for confidence-aware evaluation
  of language models.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EACL 2023}, pages 1972--1983.

\bibitem[{Zablotskaia et~al.(2023)Zablotskaia, Phan, Maynez, Narayan, Ren, and
  Liu}]{zablotskaia2023uncertainty}
Polina Zablotskaia, Du~Phan, Joshua Maynez, Shashi Narayan, Jie Ren, and
  Jeremiah Liu. 2023.
\newblock \href {https://arxiv.org/abs/2304.08653} {On uncertainty calibration
  and selective generation in probabilistic neural summarization: A benchmark
  study}.
\newblock \emph{arXiv preprint arXiv:2304.08653}.

\bibitem[{Zerva et~al.(2022)Zerva, Glushkova, Rei, and
  Martins}]{zerva-etal-2022-disentangling}
Chrysoula Zerva, Taisiya Glushkova, Ricardo Rei, and Andr{\'e} F.~T. Martins.
  2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.591} {Disentangling
  uncertainty in machine translation evaluation}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 8622--8641, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Zerva and Martins(2023)}]{zerva2023conformalizing}
Chrysoula Zerva and Andr{\'e}~FT Martins. 2023.
\newblock \href {https://arxiv.org/abs/2306.06221} {Conformalizing machine
  translation evaluation}.
\newblock \emph{arXiv preprint arXiv:2306.06221}.

\bibitem[{Zhang et~al.(2016)Zhang, Xiong, Su, Duan, and
  Zhang}]{zhang-etal-2016-variational-neural}
Biao Zhang, Deyi Xiong, Jinsong Su, Hong Duan, and Min Zhang. 2016.
\newblock \href {https://doi.org/10.18653/v1/D16-1050} {Variational neural
  machine translation}.
\newblock In \emph{Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, pages 521--530, Austin, Texas. Association for
  Computational Linguistics.

\bibitem[{Zhang et~al.(2018{\natexlab{a}})Zhang, Luan, Sun, Zhai, Xu, Zhang,
  and Liu}]{zhang-etal-2018-improving}
Jiacheng Zhang, Huanbo Luan, Maosong Sun, Feifei Zhai, Jingfang Xu, Min Zhang,
  and Yang Liu. 2018{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/D18-1049} {Improving the
  transformer translation model with document-level context}.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 533--542, Brussels, Belgium. Association
  for Computational Linguistics.

\bibitem[{Zhang et~al.(2018{\natexlab{b}})Zhang, Dinan, Urbanek, Szlam, Kiela,
  and Weston}]{zhang-etal-2018-personalizing}
Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason
  Weston. 2018{\natexlab{b}}.
\newblock \href {https://doi.org/10.18653/v1/P18-1205} {Personalizing dialogue
  agents: {I} have a dog, do you have pets too?}
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 2204--2213,
  Melbourne, Australia. Association for Computational Linguistics.

\bibitem[{Zhang et~al.(2020)Zhang, Kishore, Wu, Weinberger, and
  Artzi}]{Zhang2020BERTScore}
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian~Q. Weinberger, and Yoav Artzi.
  2020.
\newblock \href {https://openreview.net/forum?id=SkeHuCVFDr} {Bertscore:
  Evaluating text generation with {BERT}}.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}.

\bibitem[{Zhang et~al.(2018{\natexlab{c}})Zhang, Galley, Gao, Gan, Li,
  Brockett, and Dolan}]{zhang2018generating}
Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris Brockett,
  and Bill Dolan. 2018{\natexlab{c}}.
\newblock \href
  {https://proceedings.neurips.cc/paper/2018/hash/23ce1851341ec1fa9e0c259de10bf87c-Abstract.html}
  {Generating informative and diverse conversational responses via adversarial
  information maximization}.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
  December 3-8, 2018, Montr{\'{e}}al, Canada}, pages 1815--1825.

\bibitem[{Zhao et~al.(2023)Zhao, Khalman, Joshi, Narayan, Saleh, and
  Liu}]{zhao2022calibrating}
Yao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and
  Peter~J. Liu. 2023.
\newblock \href {https://openreview.net/pdf?id=0qSOodKmJaN} {Calibrating
  sequence likelihood improves conditional language generation}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}.

\bibitem[{Zhou et~al.(2023{\natexlab{a}})Zhou, Jurafsky, and
  Hashimoto}]{zhou2023navigating}
Kaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023{\natexlab{a}}.
\newblock \href {https://arxiv.org/abs/2302.13439} {Navigating the grey area:
  Expressions of overconfidence and uncertainty in language models}.
\newblock \emph{arXiv preprint arXiv:2302.13439}.

\bibitem[{Zhou et~al.(2023{\natexlab{b}})Zhou, Jiang, Wilcox, Cotterell, and
  Sachan}]{zhou2023controlled}
Wangchunshu Zhou, Yuchen~Eleanor Jiang, Ethan Wilcox, Ryan Cotterell, and
  Mrinmaya Sachan. 2023{\natexlab{b}}.
\newblock Controlled text generation with natural language instructions.
\newblock \emph{arXiv preprint arXiv:2304.14293}.

\end{thebibliography}
