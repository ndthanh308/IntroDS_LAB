\pdfoutput=1

\documentclass[11pt]{article}

\usepackage[]{acl}

\usepackage{times}
\usepackage{latexsym}
\usepackage{mathtools}
\usepackage[T1]{fontenc}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{microtype}
\usepackage{bbm}
\usepackage{url}
\usepackage{changes}    
\usepackage{booktabs}
\usepackage{physics}
\usepackage{xcolor}
\newcommand\nico[1]{\textcolor{violet}{[Nico\@: #1]}}
\newcommand\dennis[1]{\textcolor{green!60!black}{[Dennis\@: #1]}}
\newcommand\chryssa[1]{\textcolor{cyan!60!black}{[CZ\@: #1]}}
\newcommand\rico[1]{\textcolor{orange!60!black}{[Rico\@: #1]}}
\newcommand\jb[1]{\textcolor{blue!60!black}{[JB\@: #1]}}
\newcommand\wa[1]{\textcolor{yellow!60!black}{[wa\@: #1]}}
\newcommand\raq[1]{\textcolor{red!60!black}{[Raq\@: #1]}}
\newcommand\ei[1]{\textcolor{magenta}{[ei\@: #1]}}
\newcommand\bp[1]{\textcolor{magenta!60!black}{[BP\@: #1]}}
\newcommand\haausing[1]{\textcolor{white!60!black}{[HS\@: #1]}}
\newcommand{\blockcomment}[1]{}

\usepackage{nicefrac}

\usepackage{mathtools, bm}
\newcommand{\btheta}{\bm{\theta}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\Expect}{\mathbb{E}}
\newcommand{\Pl}{\ensuremath{\operatorname{Pl}}}

\usepackage{xspace}
\newcommand{\ie}{\emph{i.e.}\xspace}
\newcommand{\eg}{\emph{e.g.}\xspace}
\newcommand{\etc}{\emph{etc}\xspace}
\newcommand{\ia}{\emph{inter alia}\xspace}
\newcommand{\example}[1]{\textcolor{gray}{#1}}


\usepackage[noabbrev,capitalize,nameinlink]{cleveref}

\usepackage{alphabeta}

\usepackage{twemojis}

\title{Uncertainty in Natural Language Generation: \\From Theory to Applications}


\newcommand{\amsterdam}[0]{$^{1}$}
\newcommand{\darmstadt}[0]{$^{2}$}
\newcommand{\itu}[0]{$^{3}$}
\newcommand{\aipc}[0]{$^4$}
\newcommand{\lisbon}[0]{$^5$}
\newcommand{\lisbonist}[0]{$^6$}
\newcommand{\lmu}[0]{$^{9}$}
\newcommand{\zurich}[0]{$^7$}
\newcommand{\edinburgh}[0]{$^8$}


\author{
Joris Baan\amsterdam \thanks{\;\;Equal contributions. Corresp. to \url{j.s.baan@uva.nl}} \ 
Nico Daheim\darmstadt \footnotemark[1] \  
Evgenia Ilia\amsterdam \footnotemark[1] \ 
Dennis Ulmer\itu$^,$\aipc \footnotemark[1] \  
{\bf Haau-Sing Li}\darmstadt \\
{\bf Raquel Fern\'{a}ndez}\amsterdam 
{\bf Barbara Plank}\lmu$^,$\itu%
{\bf Rico Sennrich}\zurich$^,$\edinburgh 
{\bf Chrysoula Zerva}\lisbon$^,$\lisbonist \ 
{\bf Wilker Aziz}\amsterdam
\\
\amsterdam University of Amsterdam
\darmstadt TU Darmstadt \& hessian.AI
\itu IT University of Copenhagen \\
\aipc Pioneer Centre for Artificial Intelligence
\lisbon Instituto de Telecomunica\c{c}\~{o}es\\ 
\lisbonist Instituto Superior TÃ©cnico \& LUMLIS (Lisbon ELLIS Unit)
\zurich University of Zurich\\
\edinburgh University of Edinburgh
\lmu LMU Munich \& Munich Center for Machine Learning
}
\begin{document}

\maketitle

\begin{abstract}

Recent advances of powerful Language Models have allowed Natural Language Generation (NLG) to emerge as an important technology that can not only perform traditional tasks like summarisation or translation, but also serve as a natural language interface to a variety of applications. As such, it is crucial that NLG systems are trustworthy and reliable, for example by indicating when they are likely to be wrong; and supporting multiple views, backgrounds and writing styles---reflecting diverse human sub-populations.
In this paper, we argue that a principled treatment of \textit{uncertainty} can assist in creating systems and evaluation protocols better aligned with these goals.
We first present the fundamental theory, frameworks and vocabulary required to represent uncertainty. We then characterise the main sources of uncertainty in NLG from a linguistic perspective, and propose a two-dimensional taxonomy that is more informative and faithful than the popular aleatoric/epistemic dichotomy. Finally, we move from theory to applications and highlight exciting research directions that exploit uncertainty to power decoding, controllable generation, self-assessment, selective answering, active learning and more.


\end{abstract}

\input{1-introduction}
\input{2-background}
\input{3-sources}
\input{4-modeling}
\input{8-conclusion}

\section*{Acknowledgements}

This work was initiated at and benefited substantially from the Dagstuhl Research Meeting 22474: European Laboratory's for Learning and Intelligent Systems Third ELLIS NLP Workshop.

EI, CZ and WA are supported by the EU's Horizon Europe research and innovation programme (grant agreement No.\ 101070631, UTTER). CZ is also supported by
the Portuguese Recovery and Resilience Plan
through project C645008882-00000055 (NextGenAI, Center for Responsible AI).
ND has received funding by the German Federal Ministry of Education and Research and the Hessian Ministry of Higher Education, Research, Science and the Arts within their joint support of the National Research Center for Applied Cybersecurity ATHENE.
RF is supported by the European Research Council (ERC) Consolidator grant DREAM (No.\ 819455). BP is supported by ERC
Consolidator Grant DIALECT No.\ 101043235.
RS is supported by the Swiss National Science Foundation (project no.~176727).
JB is supported by the ELLIS Amsterdam Unit.


\bibliography{custom, anthology}
\bibliographystyle{acl_natbib}


\end{document}
