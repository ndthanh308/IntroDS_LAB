\section{User Study} \label{sec:user_study}

Having identified the relevant \captcha types, we conducted a $1,000$ participant online user study to evaluate real users' solving times and preferences for these types of \captchas.
Our study was run using using Amazon MTurk and can be summarized into the following four phases:


\taggedpara{1. Introduction:} Participants were first given an overview of the study and details of the tasks to complete.

\taggedpara{2. Pre-study questions:} All participants were then asked to provide demographic information by answering the pre-study questions shown in Table~\ref{tab:questions} in Appendix~\ref{sec:appendix-questions}.

\taggedpara{3. Tasks:} Participants were asked to complete tasks, which included solving exactly ten \captchas, presented in random order.
Unless otherwise stated, each \captcha was \emph{unique} (i.e., freshly generated per participant).
Participants had to solve each \captcha in order to progress to the next step, thus preventing them from speeding through the study.

\taggedpara{4. Post-study question} Finally, participants were asked questions about the \captchas they had just solved.
The exact questions and possible answers are shown in Table~\ref{tab:questions} in Appendix~\ref{sec:appendix-questions}.


% Figure environment removed


% Figure environment removed

\subsection{Choice of \Captchas}
\label{sec:choice_of_captchas}
Based on our website inspection (Section~\ref{sec:inspection}), we selected the following ten types of \captchas:
\begin{itemize}[itemsep=.2mm]	
	\item Two reCAPTCHA v2 \captchas: one with the setting \emph{easiest for users} and the other with \emph{most secure}. Note that we do not have control over whether the user is shown an image-based (Figure~\ref{fig:recaptcha_image}) challenge in addition to the click-based (Figure~\ref{fig:recaptcha_check}) task.
	\item Two game-based \captchas from Arkose Labs~\cite{arkose}: one required using arrows to rotate an object (Figure~\ref{fig:arkose_rotate}) and the other required selecting the upright object (Figure~\ref{fig:arkose_orientation}).
	\item Two hCAPTCHAs~\cite{hCaptcha}: one with easy and one with difficult settings (Figure~\ref{fig:hcaptcha}). 
	\item One slider-based \captcha from Geetest~\cite{geetest}: we selected Geetest because it was used on several of the inspected websites and offers a convenient API (Figure~\ref{fig:geetest}).
	\item Three types of distorted text \captchas (Figure~\ref{fig:distorted_text_captcha}): (a) the \emph{simple} version had four unobscured characters, (b) the \emph{masked} version had five characters and included some masking effects, and (c) the \emph{moving} version contained moving characters.
\end{itemize}
These form a representative sample of \captchas we encountered in our website inspection.
Although hCAPTCHA only appeared once, we included it since it is an emerging image-based approach, which claims to be the largest independent \captcha service~\cite{hCaptcha_largest}.



\subsection{Direct vs. contextualized settings}
\label{sec:B_vs_UB_SD}
We initially hypothesized that we would observe a difference in behavior depending on experimental context.
In order to evaluate this, we designed two settings of the study: 500 participants completed the \emph{direct setting}, whilst the other 
500 completed the \emph{contextualized setting}.
In both settings, each participant solved exactly ten \captchas in random order. %

\taggedpara{Direct setting:} This setting was designed to match previous \captcha user studies, in which participants are directly asked to solve \captchas.
The MTurk study title was ``CAPTCHA User Study'' and the instructions in the first phase informed users that their task was to solve \captchas.
In the second phase, in addition to the basic demographic information, participants were asked about their experience with and perception of \captchas; see Table~\ref{tab:questions} in Appendix~\ref{sec:appendix-questions}.
In the third phase, participants were shown ten \captchas in random order. %
The fourth phase was the same for both settings.

\taggedpara{Contextualized setting:} This setting was designed to measure \captcha solving behavior \emph{in the context} of a typical web activity.
We selected the task of user account creation, as this often includes solving a \captcha. 
The MTurk study title was ``Account Creation User Study'' and the first and second phases did not mention \captchas.
In the third phase, participants were asked to complete ten typical user account creation forms, each displaying a \captcha \emph{after} the participant clicked submit, as is often the case on real websites.
This sequencing allowed us to precisely measure the \captcha solving time in isolation from the rest of the account creation task. 
The account creation task was a basic web form asking for a randomized subset of: name, email address, phone number, password, and address.
To avoid collecting personally identifiable information, participants were provided with synthetic information at each step.
Each page also included a large banner clearly stating not to enter any personal information.
The fact that we were specifically measuring \captcha solving time was only revealed to participants after they completed the first three phases.


\begin{table*}[tb]
\footnotesize
\caption{Summary of demographic data for the $1,400$ participants of the main user study.}
\label{tab:demographics}
	\begin{tabularx}{\textwidth}[t]{X|X|X|X|X|X|X}
	\toprule
		\textbf{Age} & \textbf{Residence} & \textbf{Education} & \textbf{Gender} & \textbf{Device Type} & \textbf{Input Method} & \textbf{Internet Use} \\
		\cmidrule(r){1-1} \cmidrule(lr){2-2} \cmidrule(lr){3-3} \cmidrule(lr){4-4} \cmidrule(lr){5-5} \cmidrule(lr){6-6} \cmidrule(l){7-7}
		30 - 39 (531) & USA (985) & Bachelors (822) & Male (832) & Computer (1301) & Keyboard (1261) & Work (860)\\
		20 - 29 (403) & India (240) & Masters (243) & Female (557) & Phone (74) & Touch (125) & Web surf (397)\\
		40 - 49 (271) & Brazil (50) & High school (210) & Non-Binary (11) & Tablet (25) & Other (14) & Education (87)\\
		50 - 59 (106)  & Italy (27) & Associate (98) & \multirow{3}{*}{} & \multirow{3}{*}{} & \multirow{3}{*}{} & Gaming (30) \\
		\;\;\;$\geq 60$ (58)     & UK (24) & PhD (24) & & & & Other (26)\\
		18 - 19 (31)  & Other (74) & No degree (3) & & & & \\
	\bottomrule
	\end{tabularx}
\end{table*}

\subsection{Timeline and compensation}
\label{sec:time_and_comp}
The primary study ran for two months with a total of $1,000$ distinct participants.\footnote{To the best of our knowledge, all participants were distinct. We configured Amazon MTurk to only allow unique accounts to participate.}
Participants were initially paid \$0.30 for completing the direct version and \$0.75 for the contextualized version, as the latter involved a larger workload. 
After completing the study, we realized we may have unintentionally under-compensated participants,\footnote{In terms of US federal minimum wage.} since the median HIT completion time was $4.4$ and $11.5$ minutes for direct and contextualized versions.
We therefore retroactively doubled all participants' compensation to $\$0.60$ and $\$1.50$, which equates to approximately $\$7.80$ -- $\$8.20$ per hour.

\subsection{Ethical considerations}
\label{sec:ethical}
This user study was duly approved by the Institutional Review Board (IRB) of the primary authors' organization.
No sensitive or personally identifiable information was collected from participants. 
We used the pseudonymous MTurk worker IDs only to check that participants were unique.

Since the contextualized setting did not inform participants of the actual aim of the study beforehand, two additional documents were filed and approved by the IRB: 
(1) \emph{``Use of deception/incomplete disclosure''} and (2) \emph{``Waiver or Alteration of the Consent''}.
After each participant completed the contextualized setting, we disclosed the study's actual goal and asked whether they gave us permission to use their data.
No data were collected from participants who declined.




\subsection{User study implementation}
\label{sec:user_study_impl}
The realization of the user study included a front-end webpage and a back-end server.
The front-end was a single HTML page that implemented the four phases described above.
To prevent any inconsistencies, participants were prevented from going back to a previous phase or retrying a task once they had progressed.
Timing events were captured with millisecond precision using the native JavaScript \texttt{Date} library.
Timing events were recorded at several points for each \captcha: request, serve, load, display, submit, and server response.
We measured \emph{solving time} as the time between a \captcha being displayed and the participant submitting a solution, as is done in prior \captcha user studies~\cite{Bursztein,Bigham,fidas2011,yan2008,belk,Ho,Krol,Ross,Uzun,Gao,mohitAutomatic2019,manarDynamic2014,gaoEmerging2019}.
Depending on the type of \captcha, this might include multiple rounds or attempts.

We used Amazon MTurk to recruit participants, host the front-end, and collect data.
While most types of \captchas shown by the front-end were served from their respective providers, distorted text \captchas were not available from a third-party provider, as these are usually hosted by the websites themselves.
We therefore set up our own back-end server to serve distorted text \captchas. 
Specifically, we downloaded a total of 1,000 unique distorted text \captchas of three different types, and stored these in a local \texttt{MongoDB}~\cite{mongodb} database.
We used a \texttt{Node.js}~\cite{nodejs} server to retrieve and serve \captchas from the database.
Every participant was served one text \captcha of each type, and each unique text \captcha was served to three different participants.


Table~\ref{tab:demographics} shows the demographic information of the participants who completed the study.
The demographics of the two subgroups who completed direct and contextualized studies are very similar to each other.






\subsection{Potential limitations}
\label{sec:study_limitations}
\taggedpara{Use of MTurk:}
Webb et al.~\cite{webb2022too} reported several potential concerns regarding the quality of data collected from MTurk.
Of their six criteria, our study did not implement two: consent quiz (1) and examination of qualitative responses (2), which we acknowledge as a limitation.
The remaining four criteria can be either evaluated through collected data or are not an issue for our study.
Eligibility (3) and attention check (4) can be verified via the accuracy of text-based \captcha responses, which confirm that nearly all of our participants were focused and provided correct data.
Response time (5) was within our expected range.
Study completion (6) was not an issue, since each participant had to complete every \captcha to proceed.


\taggedpara{Bots and farms:}
Similarly, Chmielewski et al.~\cite{chmielewski2020mturk} reported a decrease in data quality, citing bot and farm activity.
However, Moss and Litman~\cite{moss_2020} subsequently used several bot-detection measures to evaluate whether bots could be contaminating MTurk data, and found no evidence of bot activity.
Every participant who completed our study solved ten modern \captchas, which although possible, would be more difficult for bots.
Since we configured MTurk to only allow one completion per MTurk account, farm activity was also limited.
Therefore, we are reasonably confident that our results are not influenced by bots or farms.


\taggedpara{Choice of \captchas:}
One consequence of using the \captcha types we identified in Section~\ref{sec:inspection} is that our user study results are not directly comparable with those from prior \captcha user studies.
In general, it is difficult to directly compare such studies, as even if the same \emph{types} of \captchas are studied, different implementations may be used e.g., reCAPTCHA and hCAPTCHA are both image-based \captchas, but could give different results. 


\taggedpara{Unmodified \captchas:}
In order to maximize the level of realism in our study, we used existing unmodified \captchas. 
We therefore did not have fine-grained control over the precise behavior of these \captchas, nor the ability to obtain more fine-grained measurements of participants' accuracy or performance beyond overall solving time.
However, like previous studies, we consider overall solving time to be the most important measurable quantity.




\taggedpara{Invalid inputs:}
Unfortunately, the input field for the \captcha preference question in our post-study questionnaire was a free text field rather than a pull-down menu.
This allowed some participants to provide preference scores outside the requested 1-5 range.
We therefore excluded invalid preference scores from 163 participants.\footnote{However, we have high confidence that these participants did not provide incorrect or rushed responses during the rest of the study because their average accuracy in text-based \captchas was similar to the study-wide average.
We therefore retained their measurements in other sections.}


\taggedpara{Abandonment:}
Since we did not record how many participants began our main study, we cannot precisely quantify the rate of abandonment.
To investigate this further, we performed an additional abandonment-focused study (Section~\ref{sec:eval_abandonment}), where we observed a $30\%$ abandonment rate.
We can therefore assume a similar abandonment rate for our main study.
Whilst the impact of this level of abandonment is unclear, it could potentially affect the ecological validity of our results, as the participants who were willing to complete the study may not be representative of all users.

\taggedpara{Confounding factors:}
There were several differences between our direct and contextualized settings, some of which may be confounding factors when comparing these two groups.
For example, participants in the contextualized setting had to do more work, so their attention or focus might have been reduced during \captcha solving.
Differences in compensation or participants' perceived benefit of completing the task (i.e., creating an account vs.\ solving a \captcha) may have affected motivation or likeliness to abandon the task.







