\section{Research Questions \& Main Findings}
\label{sec:findings}


We now present our research questions and summarize our main findings.
Table~\ref{tab:findings} shows how our findings relate to prior work at a high level, with detailed comparisons in Section~\ref{sec:related}.


\textbf{RQ1: How long do human users take to solve different types of \captchas?} 
Specifically, we aimed to measure solving times for \captchas that users are likely to encounter (e.g., those used on popular websites).
Our results align with previous findings~\cite{Bursztein, senCAP, Bigham} in showing that there are significant differences in mean solving times between \captcha types.
For comparison, we also identified the current fastest attacks on each type of \captcha (Table~\ref{tab:bots_vs_humans}).

\textbf{RQ2: What \Captcha types do users prefer?}
In order to understand users' relative preference for various types of \captchas, we asked participants to rate all \captcha types on a Likert scale of $1-5$, from least to most enjoyable. 
Our results show that there are marked differences in participants' preferences, with average preference scores ranging from $2.76$ to $3.94$.
Our results also show that average solving time is \emph{not fully correlated} with participants' preferences, which means that other factors, beyond the amount of time required to solve a \captcha, influence participants' preferences.
Our analysis of data from prior studies~\cite{Krol, senCAP, tanth19} shows that their data supports this finding (even if they do not discuss it explicitly).





\textbf{RQ3: Does experimental context affect solving time?}
Specifically, we aimed to quantify the difference in solving times between the setting where participants are directly tasked with solving \captchas versus the setting in which participants solve \captchas as part of a typical web activity, such as user account creation.
We therefore ran two separate versions of our main user study: \emph{direct} and \emph{contextualized}, which we describe in detail in Section~\ref{sec:B_vs_UB_SD}.
Whilst there were several potential confounding factors in our study, our results show that experimental context could have an impact on \captcha user studies, with the difference in mean solving times as high as 57.5\% in our study.

\textbf{RQ4: Do demographics affect solving time?}
We analyzed different self-reported metrics including age, gender, country of residence, education, Internet usage, device type and input method.
In line with prior results~\cite{Bursztein}, we found that all types of \captchas take longer for older participants.
Specifically, \cite{Bursztein} reported an increase in solving time for text-based \captchas of $0.03$ seconds per year of participant age.
Our results show an even stronger dependence with an average increase across all \captcha types of $0.09$ seconds per year.
Additionally, \cite{Bursztein} showed that participants with a PhD solved \captchas faster than all other educational groups.
In contrast, our results show that our participants' self-reported level of education does not correlate with their solving times.

\textbf{RQ5: Does experimental context influence abandonment?}
Specifically, we aimed to quantify the extent to which abandonment within a \captcha user study is influenced by i) experimental context, and ii) the amount of compensation offered.
For different combinations of the above variables, we found that between 18\% and 45\% of participants abandoned the study after the presentation of the first \captcha.
Only one prior \captcha user study~\cite{Bursztein} disclosed their observed rate of abandonment, which is similar to that observed in our study.
Overall, participants in the contextualized setting were 120\% more likely to abandon than their peers in the direct setting.
This connection between experimental context and user abandonment is a new finding.











\begin{table*}[ht]
\footnotesize
\caption{Summary of research questions and main findings.}
\label{tab:findings}
\begin{tabularx}{\textwidth}{X X X X}
\toprule
& \textbf{Findings supporting prior work} 
& \textbf{Findings contradicting prior work} 
& \textbf{New findings on \Captchas} 
\\\toprule
\textbf{RQ1: How long does it take humans to solve different types of \captchas?} 
&  Solving time across \captcha types has a large degree of variance. \cite{Bursztein, senCAP, Bigham}
&                                              
&  
\\ \midrule
\textbf{RQ2: What \Captcha types do users prefer?}                         
&   Solving time is not correlated with user preference. \cite{Krol, senCAP, tanth19}                
&                                  
&  
\\ \midrule
\textbf{RQ3: Does experimental context affect solving time?}                         
&                                            
&                                               
&  Solving time is heavily influenced by experimental context, with differences in means up to 57.5\%.
\\ \midrule
\textbf{RQ4: Do demographics affect solving time?}                                      
&  Age has an effect on solving time. \cite{Bursztein}
&  Self-reported education does not correlate with solving time. \cite{Bursztein}
&  %
\\ \midrule
\textbf{RQ5: Does experimental context influence abandonment?}                        
&   High abandonment rates observed in \captcha user studies. \cite{Bursztein}
&                                               
&   Experimental context directly affects the rate of abandonment. 
\\ \bottomrule                             
\end{tabularx}
\end{table*}





