\section{Related Work}
\label{sec:related}


\Captchas are a well-studied topic, with several prior studies investigating both existing and novel \captcha schemes.

\subsection{Comparison of methodologies}
Table~\ref{tab:methodology} summarizes the key methodological aspects of prior \captcha user studies, from which the following observations can be made:

\begin{table*}[ht]
\footnotesize
\caption{Methodology and details of previous \captcha-related user studies.}
\label{tab:methodology}
\begin{tabularx}{\textwidth}{l p{24mm} p{13mm} p{22mm} X p{20mm} p{25mm}}
\toprule
                          & \textbf{\Captcha types}         & \textbf{Delivery medium} & \textbf{Measurements}                           & \textbf{Survey methods}           & \textbf{\Captcha source}      & \textbf{Compensation} (USD per \# \captchas) \\ \midrule
Ours                      & Text, Image, Game, Slider, Behavior   & MTurk              & Time, Agreement, Accuracy, Abandonment, Context & Demographics, Preference          & Alexa                             & \$0.30-\$1.50 per 10                     \\ \midrule
\cite{Bursztein}          & Text, Audio                           & MTurk, Website     & Time, Agreement                                 & Demographics                      & Alexa                             & \$0.02-\$0.50 per 24-39                  \\ \midrule
\cite{manarDynamic2014}   & DCG Captcha                           & MTurk              & Time, Accuracy                                  & Demographics, SUS                 & Newly proposed                    & \$0.50 per 4                             \\ \midrule
\cite{mohitAutomatic2019} & reCAPGen Audio                        & MTurk              & Time, Accuracy                                  & Demographics, Rating/Preference   & Newly proposed                    & \$4.00 per 60                            \\ \midrule
\cite{gaoEmerging2019}    &  3D/2D Text                           & MTurk              & Time, Accuracy                                  & Demographics, SUS                 & \cite{EICAP1,EICAP2,EICAP3}       & \$1.00 per 30                            \\ \midrule
\cite{Ho}                 & Text                                  & MTurk, DevilTyper  & Time, Accuracy, Abandonment                     & None                              & Major websites                    & \$0.03 per 15 (MTurk), 30.00 per 1.4 mil \\ \midrule
\cite{Bigham}             & Text, Audio, Interface                & Website            & Time, Accuracy                                  & Demographics, Preference          & Alexa                             & None                                     \\ \midrule
\cite{fidas2011}          & Text                                  & Website            & None                                            & Demographics, Rating/Preference   & Newly proposed                    & None                                     \\ \midrule
\cite{Gao}                & Jigsaw puzzle                         & Website            & Time, Accuracy                                  & Demographics, Preference          & Newly proposed                    & None                                     \\ \midrule
\cite{Krol}               & Text, Game, NoBot                     & Website            & Time                                            & Workload, Perceptions, Preference & None                              & None                                     \\ \midrule
\cite{senCAP}             & SenCAPTCHA, Text, Image, Audio, Video & MTurk              & Time                                            & Demographics, Preference, SUS     & Newly proposed, \cite{securimage} & \$1.25 per 9-15                          \\ \midrule
\cite{tanth19}            & Text, Behavior, Invisible, Game, Math & Unknown            & Time                                            & Demographics, Preference          & None                              & None                                     \\ \midrule
\cite{Ross}               & Sketcha                               & MTurk              & Time, Accuracy                                  & Demographics                      & Newly proposed                    & \$0.05-\$0.30 per 10-12                  \\ \bottomrule
\end{tabularx}
\end{table*}



\begin{itemize}[itemsep=.2mm] 
\item Most prior research has focussed on distorted text and newly-proposed \captcha schemes.

\item MTurk and proprietary websites have been the norm across \captcha user studies (except DevilTyper~\cite{Ho}).

\item Whilst almost all studies measured solving time, there is a bifurcation in terms of accuracy measurements: studies evaluating their own \captcha schemes or reimplementing existing schemes typically have direct access to accuracy results, whereas those evaluating unmodified deployed \captchas can only measure quantities such as agreement.

\item Most studies measured demographics and ratings or preferences.
Some studies also measured workload, open response (perceptions), and perceived usability.



\end{itemize}










\subsection{Detailed comparisons}
\label{sec:detailed_comparison}
We present detailed comparisons of our methodology and results with three representative prior \captcha studies.

\taggedpara{Bursztein et al.}~\cite{Bursztein} presented the first large-scale study on human \captcha solving performance.
Focussing on distorted text and audio \captchas, they used both MTurk and an underground \captcha-solving service to measure solving time and accuracy.
In terms of solving times, they found that it took on average $9.8$ and $28.4$ seconds to solve distorted text and audio \captchas respectively.
Although we did not evaluate audio \captchas (as we did not observe these in our website inspection), our results for distorted text \captchas broadly agree at $12.5$ on average.
Similarly to our study, they used \emph{agreement} between participants as a proxy for accuracy.
For distorted text, they observed $71\%$ agreement, which is in line with our observation of $75\%$ when averaging case sensitive and insensitive versions (see Table~\ref{tab:accuracy}).

\taggedpara{Feng et al.}~\cite{senCAP} presented senCAPTCHA, a new \captcha type using orientation sensors designed specifically for mobile devices with small screens.
They evaluated its security against brute-force and ML-based attacks, and its usability through two usability studies totalling 472 participants.
The second user study compared senCAPTCHA against text-, audio-, image-, and video-based \captchas, some of which were reimplemented for the study.
senCAPTCHA had the lowest median solving time ($5.02$ seconds), followed by image ($9.6$), video ($10.08$), text ($11.93$), and audio ($47.07$).
With the exception of click-based reCAPTCHA, it can be extrapolated that senCAPTCHA would have a lower solving time than the other \captcha types in our study.
In terms of preferences, most participants in their study preferred senCAPTCHA.
Out of the \captcha types in our study, senCAPTCHA most closely resembles the game-based \captchas, which supports our finding that game-based \captchas are generally preferred over text and image-based \captchas (see Figure~\ref{fig:pref_res}).

\taggedpara{Tanthavech and Nimkoompai}~\cite{tanth19} performed a 40-participant user study, measuring solving time for five \captcha types: click-based reCAPTCHA, text-, game-, math-based, and a newly-proposed invisible \captcha, which is essentially a honeypot for bots.
In terms of solving times, their distorted text measurement ($12$ seconds) is in the middle of our observed range ($9$-$15$ seconds), which is expected since it closely resembles our \emph{masked} type of distorted text.
Similarly, their click-based reCAPTCHA measurement ($3.1$ seconds) is on the boundary of our range ($3.1$-$4.9$), which suggests they may have configured the ``easier for users'' setting.
Their game-based \captcha appears to have a lower solving time than ours, but this is likely due to the type of game.
We did not observe or evaluate any math-based \captchas.
They also asked participants several post-study questions about the five \captcha types.
Interestingly, their participants ``enjoyed'' the game-based \captcha more than reCAPTCHA (click), which is the inverse of our findings (see Figure~\ref{fig:pref_res}), but may again be due to the different types of game.

\taggedpara{Overall}, where our study measured similar quantities to prior work, our findings broadly agree.
However, there is still a high degree of diversity in the sets of quantities measured in each study (e.g., types of \captchas, effect of experimental context), suggesting that a plurality of studies are needed to understand the full \captcha landscape.



\begin{table*}[!ht]
\footnotesize
\caption{Comparison of results from prior user studies evaluating \captchas: audio (A), behavior (B), distorted text (DT), game (G), honeypot (HP), image (I), math (M), service (S), slider (SL), video (V) and newly-proposed (New). Some studies used non-unique (NU) participants or MTurk (MT). * denotes reimplemented \captcha types.}
\label{tab:related_results}
\begin{tabularx}{\textwidth}{l X X l l}
\toprule
  & \textbf{Unique users} & \textbf{\Captchas solved} & \textbf{Average solving time (seconds)} & \textbf{Average accuracy} \\ \midrule
Ours                & 1,400 (MT)           & 14,000          & 9-15 (DT), 15-32 (I), 18-42 (G), 29 (SL), 3.1-4.9 (B) & 50-84\% (DT), 71-81\% (I), 71-85\% (B) \\ \midrule
\cite{Bursztein}          & 1,100-11,800 (MT)   & 318,000        & 9.8 (DT), 28.4 (A), 22.4 (S) & 71\% (DT), 31\% (A), 93\% (ebay DT) \\ \midrule
\cite{manarDynamic2014}   & 120                 & 480            & 8.5-16 (New), 17-47 (Attacks) & 16-100\% (New) \\ \midrule
\cite{mohitAutomatic2019} & 79                  & 4,740          & 9.6 (New) & 78.2\% (New) \\ \midrule
\cite{gaoEmerging2019}    & 120                 & 3,600          & 10 (3D-DT), 6.2-6.7 (DT) & 84\% (3D-DT), 92-96\% (DT) \\ \midrule
\cite{Ho}                 & 5,000 (NU), 44 (MT) & 1.4 mil, 7,500 & 8.5-12 (DT) & 79\%-89\%  (DT) \\ \midrule
\cite{Bigham}             & 162, 14 (Interface) & 2,350          & 9.9 (DT), 50.9 (Blind DT), 22.8 (A) & 80\% (DT), 39-43\% (A) \\ \midrule
\cite{fidas2011}          & 210                 & 210            & None & None \\ \midrule
\cite{Gao}                & 100                 & 300            & 4.9-6.4 (New) & 78\%-87.5\% (New) \\ \midrule
\cite{Krol}               & 87                  & 261            & 20 (DT), 29 (G), 70 (NoBot) & None \\ \midrule
\cite{senCAP}             & 436                 & 4,920          & 12 (DT), 47 (A), 9.6 (I*), 5 (New), 12 (V*) & None\\ \midrule
\cite{tanth19}            & 40                  & 200            & 12 (DT), 0 (HP), 3.1 (B), 8.2 (G \cite{yu2015automatic}), 4.1 (M \cite{HERNANDEZCASTRO2010141}) & None \\ \midrule
\cite{Ross}               & 558 (NU)            & 14,302         & 35 (New) & 42\%-88\% (New) \\ \bottomrule
\end{tabularx}
\end{table*}



\subsection{Summarized comparisons}
\label{sec:comparison_of_results}
In addition, Table~\ref{tab:related_results} presents a summarized comparison of our results with those of other prior studies.



\taggedpara{Solving Time:}
Overall, the average solving time in our study ranged from $3.6$ to $42.7$~seconds per \captcha, which is a larger range than that observed by Bursztein et al.~\cite{Bursztein} in 2010 ($9.8$ -- $28.4$~seconds) but is similar to the 2019 study by Feng et al.~\cite{senCAP} (medians ranging from $5.0$ to $47.1$~seconds).
Although direct comparison of solving times is not always meaningful, even for the same \captcha type (e.g., due to differing implementations or difficulty settings), we can identify a few trends.
Firstly, our measured solving times for the three types of distorted text \captchas ($9$-$15$ seconds\footnote{Unless otherwise stated, measurements refer to average solving time.}) are within the range of observations from prior studies ($6$-$20$ seconds).
We can therefore use this as a reference point for comparisons.
Secondly, with the exception of behavior-based \captchas, we observed that all other \captcha types took longer than distorted text.
Without considering newly-proposed \captcha types, this trend is consistent across most prior studies (with the exception of \cite{senCAP} and \cite{tanth19}).
Thirdly, although we do not evaluate any newly-proposed \captcha types, the times reported for these by other studies are typically faster than most of the \captcha types in our study, suggesting that there is scope for developing new \captcha types with lower solving times.
Finally, even in comparison to newly-proposed schemes, the behavior-based \captchas (e.g. reCAPTCHA click) appear to have the lowest solving times overall. 


\taggedpara{Accuracy:}
For the case-sensitive setting, we observed a relatively broad range of accuracy (i.e., agreement) measurements for distorted text ($50$-$84\%$).
However, in the case-insensitive setting, our accuracy range narrows to $73$-$93$\%, which more closely aligns with prior studies, which have reported distorted text accuracies in the range $71$-$96$\%.
This suggests that both participants and prior studies have focussed on the case-insensitive setting.
In terms of deployed \captchas, \cite{Bursztein} reported an accuracy of $93\%$ for distorted text \captchas used by EBay in 2010.
This is higher than for the image-based \captchas we measured ($71$-$81\%$), suggesting that the latter may have increased in difficulty.


\taggedpara{Security:}
Table \ref{tab:bots_vs_humans} shows a comparison of our results to prior security analyses. %
Automated attacks on various \captcha schemes have been quite successful~\cite{Zi20,chen17,tang18,Gao16,li20,Goodfellow,unCaptcha,deepCRACK,Sano2013,Bursztein2011,Shekhar2021,Saumya2017,Darnstadt2014,Hossen2020,Hossen2021,Alqahtani2020,Haiqin2019,Lorenzi2012,Sivakorn2016}.
The bots' accuracy ranges from 85-100\%, with the majority above 96\%.
This substantially exceeds the human accuracy range we observed ($50$-$85\%$). %
Furthermore the bots' solving times are significantly lower in all cases, except reCAPTCHA (image), where human solving time ($18$ seconds) is similar to the bots' ($17.5$ seconds).
However, in the contextualized setting, human solving time rises to $22$ seconds, indicating that in this more natural setting, humans are slightly slower than bots.
