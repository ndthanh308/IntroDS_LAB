
@article{raissi_physics-informed_2019,
	title = {Physics-informed neural networks: {A} deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
	volume = {378},
	issn = {00219991},
	shorttitle = {Physics-informed neural networks},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999118307125},
	doi = {10.1016/j.jcp.2018.10.045},
	language = {en},
	urldate = {2022-04-18},
	journal = {Journal of Computational Physics},
	author = {Raissi, M. and Perdikaris, P. and Karniadakis, G.E.},
	month = feb,
	year = {2019},
	pages = {686--707},
	file = {1-s2.0-S0021999118307125-main.pdf:G\:\\Mi unidad\\ACIP\\PINNs\\1-s2.0-S0021999118307125-main.pdf:application/pdf},
}

@inproceedings{zang_intratomo_2021,
	address = {Montreal, QC, Canada},
	title = {{IntraTomo}: {Self}-supervised {Learning}-based {Tomography} via {Sinogram} {Synthesis} and {Prediction}},
	isbn = {978-1-66542-812-5},
	shorttitle = {{IntraTomo}},
	url = {https://ieeexplore.ieee.org/document/9710599/},
	doi = {10.1109/ICCV48922.2021.00197},
	abstract = {We propose IntraTomo, a powerful framework that combines the benefits of learning-based and model-based approaches for solving highly ill-posed inverse problems in the Computed Tomography (CT) context. IntraTomo is composed of two core modules: a novel sinogram prediction module, and a geometry refinement module, which are applied iteratively. In the first module, the unknown density field is represented as a continuous and differentiable function, parameterized by a deep neural network. This network is learned, in a self-supervised fashion, from the incomplete or/and degraded input sinogram. After getting estimated through the sinogram prediction module, the density field is consistently refined in the second module using local and non-local geometrical priors. With these two core modules, we show that IntraTomo significantly outperforms existing approaches on several ill-posed inverse problems, such as limited angle tomography with a range of 45 degrees, sparse view tomographic reconstruction with as few as eight views, or super-resolution tomography with eight times increased resolution. The experiments on simulated and real data show that our approach can achieve results of unprecedented quality.},
	language = {en},
	urldate = {2022-11-03},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Zang, Guangming and Idoughi, Ramzi and Li, Rui and Wonka, Peter and Heidrich, Wolfgang},
	month = oct,
	year = {2021},
	pages = {1940--1950},
	file = {intratomo.pdf:C\:\\Users\\Tabita\\Documents\\ACIP\\Abstract\\intratomo.pdf:application/pdf},
}

@article{shen_nerp_2022,
	title = {{NeRP}: {Implicit} {Neural} {Representation} {Learning} {With} {Prior} {Embedding} for {Sparsely} {Sampled} {Image} {Reconstruction}},
	issn = {2162-237X, 2162-2388},
	shorttitle = {{NeRP}},
	url = {https://ieeexplore.ieee.org/document/9788018/},
	doi = {10.1109/TNNLS.2022.3177134},
	abstract = {Image reconstruction is an inverse problem that solves for a computational image based on sampled sensor measurement. Sparsely sampled image reconstruction poses addition challenges due to limited measurements. In this work, we propose an implicit Neural Representation learning methodology with Prior embedding (NeRP) to reconstruct a computational image from sparsely sampled measurements. The method differs fundamentally from previous deep learning-based image reconstruction approaches in that NeRP exploits the internal information in an image prior, and the physics of the sparsely sampled measurements to produce a representation of the unknown subject. No large-scale data is required to train the NeRP except for a prior image and sparsely sampled measurements. In addition, we demonstrate that NeRP is a general methodology that generalizes to different imaging modalities such as CT and MRI. We also show that NeRP can robustly capture the subtle yet significant image changes required for assessing tumor progression.},
	language = {en},
	urldate = {2022-11-03},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Shen, Liyue and Pauly, John and Xing, Lei},
	year = {2022},
	keywords = {notion},
	pages = {1--13},
	file = {nerp.pdf:C\:\\Users\\Tabita\\Documents\\ACIP\\Abstract\\nerp.pdf:application/pdf},
}

@inproceedings{lindell_bacon_2022,
	address = {New Orleans, LA, USA},
	title = {Bacon: {Band}-limited {Coordinate} {Networks} for {Multiscale} {Scene} {Representation}},
	isbn = {978-1-66546-946-3},
	shorttitle = {Bacon},
	url = {https://ieeexplore.ieee.org/document/9880123/},
	doi = {10.1109/CVPR52688.2022.01577},
	abstract = {Coordinate-based networks have emerged as a powerful tool for 3D representation and scene reconstruction. These networks are trained to map continuous input coordinates to the value of a signal at each point. Still, current architectures are black boxes: their spectral characteristics cannot be easily analyzed, and their behavior at unsupervised points is difficult to predict. Moreover, these networks are typically trained to represent a signal at a single scale, so naive downsampling or upsampling results in artifacts. We introduce band-limited coordinate networks (BACON), a network architecture with an analytical Fourier spectrum. BACON has constrained behavior at unsupervised points, can be designed based on the spectral characteristics of the represented signal, and can represent signals at multiple scales without per-scale supervision. We demonstrate BACON for multiscale neural representation of images, radiance fields, and 3D scenes using signed distance functions and show that it outperforms conventional single-scale coordinate networks in terms of interpretability and quality.},
	language = {en},
	urldate = {2022-11-03},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Lindell, David B. and Van Veen, Dave and Park, Jeong Joon and Wetzstein, Gordon},
	month = jun,
	year = {2022},
	pages = {16231--16241},
	file = {bacon.pdf:C\:\\Users\\Tabita\\Documents\\ACIP\\Abstract\\bacon.pdf:application/pdf},
}

@misc{sitzmann_implicit_2020,
	title = {Implicit {Neural} {Representations} with {Periodic} {Activation} {Functions}},
	url = {http://arxiv.org/abs/2006.09661},
	abstract = {Implicitly deﬁned, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible beneﬁts over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with ﬁne detail, and fail to represent a signal’s spatial and temporal derivatives, despite the fact that these are essential to many physical signals deﬁned implicitly as the solution to partial differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or SIRENs, are ideally suited for representing complex natural signals and their derivatives. We analyze SIREN activation statistics to propose a principled initialization scheme and demonstrate the representation of images, waveﬁelds, video, sound, and their derivatives. Further, we show how SIRENs can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine SIRENs with hypernetworks to learn priors over the space of SIREN functions. Please see the project website for a video overview of the proposed method and all applications.},
	language = {en},
	urldate = {2022-11-03},
	publisher = {arXiv},
	author = {Sitzmann, Vincent and Martel, Julien N. P. and Bergman, Alexander W. and Lindell, David B. and Wetzstein, Gordon},
	month = jun,
	year = {2020},
	note = {arXiv:2006.09661 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Machine Learning},
	file = {siren.pdf:C\:\\Users\\Tabita\\Documents\\ACIP\\Abstract\\siren.pdf:application/pdf},
}

@article{menchon-lara_reconstruction_2019,
	title = {Reconstruction techniques for cardiac cine {MRI}},
	volume = {10},
	issn = {1869-4101},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6757088/},
	doi = {10.1186/s13244-019-0754-2},
	abstract = {The present survey describes the state-of-the-art techniques for dynamic cardiac magnetic resonance image reconstruction. Additionally, clinical relevance, main challenges, and future trends of this image modality are outlined. Thus, this paper aims to provide a general vision about cine MRI as the standard procedure in functional evaluation of the heart, focusing on technical methodologies.},
	urldate = {2022-11-03},
	journal = {Insights into Imaging},
	author = {Menchón-Lara, Rosa-María and Simmross-Wattenberg, Federico and Casaseca-de-la-Higuera, Pablo and Martín-Fernández, Marcos and Alberola-López, Carlos},
	month = sep,
	year = {2019},
	pmid = {31549235},
	pmcid = {PMC6757088},
	keywords = {notion},
	pages = {100},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\GE9VESXC\\Menchón-Lara et al. - 2019 - Reconstruction techniques for cardiac cine MRI.pdf:application/pdf},
}

@article{kleineisel_real-time_2022,
	title = {Real-time cardiac {MRI} using an undersampled spiral k-space trajectory and a reconstruction based on a variational network},
	volume = {88},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.29357},
	doi = {10.1002/mrm.29357},
	abstract = {Purpose Cardiac MRI represents the gold standard to determine myocardial function. However, the current clinical standard protocol, a segmented Cartesian acquisition, is time-consuming and can lead to compromised image quality in the case of arrhythmia or dyspnea. In this article, a machine learning–based reconstruction of undersampled spiral k-space data is presented to enable free breathing real-time cardiac MRI with good image quality and short reconstruction times. Methods Data were acquired in free breathing with a 2D spiral trajectory corrected by the gradient system transfer function. Undersampled data were reconstructed by a variational network (VN), which was specifically adapted to the non-Cartesian sampling pattern. The network was trained with data from 11 subjects. Subsequently, the imaging technique was validated in 14 subjects by quantifying the difference to a segmented reference acquisition, an expert reader study, and by comparing derived volumes and functional parameters with values obtained using the current clinical gold standard. Results The scan time for the entire heart was below 1 min. The VN reconstructed data in about 0.9 s per image, which is considerably shorter than conventional model-based approaches. The VN furthermore performed better than a U-Net and not inferior to a low-rank plus sparse model in terms of achieved image quality. Functional parameters agreed, on average, with reference data. Conclusions The proposed VN method enables real-time cardiac imaging with both high spatial and temporal resolution in free breathing and with short reconstruction time.},
	language = {en},
	number = {5},
	urldate = {2022-11-03},
	journal = {Magnetic Resonance in Medicine},
	author = {Kleineisel, Jonas and Heidenreich, Julius F. and Eirich, Philipp and Petri, Nils and Köstler, Herbert and Petritsch, Bernhard and Bley, Thorsten A. and Wech, Tobias},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.29357},
	keywords = {cardiac imaging, convolutional neural network, heart, machine learning, magnetic resonance imaging, variational network, notion},
	pages = {2167--2178},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\9TD4JXPC\\Kleineisel et al. - 2022 - Real-time cardiac MRI using an undersampled spiral.pdf:application/pdf;Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\MLXGMTHI\\mrm.html:text/html},
}

@article{kofler_end--end-trainable_2021,
	title = {An end-to-end-trainable iterative network architecture for accelerated radial multi-coil {2D} cine {MR} image reconstruction},
	volume = {48},
	issn = {2473-4209},
	doi = {10.1002/mp.14809},
	abstract = {PURPOSE: Iterative convolutional neural networks (CNNs) which resemble unrolled learned iterative schemes have shown to consistently deliver state-of-the-art results for image reconstruction problems across different imaging modalities. However, because these methods include the forward model in the architecture, their applicability is often restricted to either relatively small reconstruction problems or to problems with operators which are computationally cheap to compute. As a consequence, they have not been applied to dynamic non-Cartesian multi-coil reconstruction problems so far.
METHODS: In this work, we propose a CNN architecture for image reconstruction of accelerated 2D radial cine MRI with multiple receiver coils. The network is based on a computationally light CNN component and a subsequent conjugate gradient (CG) method which can be jointly trained end-to-end using an efficient training strategy. We investigate the proposed training strategy and compare our method with other well-known reconstruction techniques with learned and non-learned regularization methods.
RESULTS: Our proposed method outperforms all other methods based on non-learned regularization. Further, it performs similar or better than a CNN-based method employing a 3D U-Net and a method using adaptive dictionary learning. In addition, we empirically demonstrate that even by training the network with only iteration, it is possible to increase the length of the network at test time and further improve the results.
CONCLUSIONS: End-to-end training allows to highly reduce the number of trainable parameters of and stabilize the reconstruction network. Further, because it is possible to change the length of the network at the test time, the need to find a compromise between the complexity of the CNN-block and the number of iterations in each CG-block becomes irrelevant.},
	language = {eng},
	number = {5},
	journal = {Medical Physics},
	author = {Kofler, Andreas and Haltmeier, Markus and Schaeffter, Tobias and Kolbitsch, Christoph},
	month = may,
	year = {2021},
	pmid = {33651398},
	keywords = {Magnetic Resonance Imaging, Image Processing, Computer-Assisted, Magnetic Resonance Imaging, Cine, Neural Networks, Computer, magnetic resonance imaging, deep learning, inverse problems, neural networks},
	pages = {2412--2425},
	file = {Texto completo:C\:\\Users\\Tabita\\Zotero\\storage\\FE6ZTT44\\Kofler et al. - 2021 - An end-to-end-trainable iterative network architec.pdf:application/pdf},
}

@article{qin_convolutional_2019,
	title = {Convolutional {Recurrent} {Neural} {Networks} for {Dynamic} {MR} {Image} {Reconstruction}},
	volume = {38},
	issn = {1558-254X},
	doi = {10.1109/TMI.2018.2863670},
	abstract = {Accelerating the data acquisition of dynamic magnetic resonance imaging leads to a challenging ill-posed inverse problem, which has received great interest from both the signal processing and machine learning communities over the last decades. The key ingredient to the problem is how to exploit the temporal correlations of the MR sequence to resolve aliasing artifacts. Traditionally, such observation led to a formulation of an optimization problem, which was solved using iterative algorithms. Recently, however, deep learning-based approaches have gained significant popularity due to their ability to solve general inverse problems. In this paper, we propose a unique, novel convolutional recurrent neural network architecture which reconstructs high quality cardiac MR images from highly undersampled k-space data by jointly exploiting the dependencies of the temporal sequences as well as the iterative nature of the traditional optimization algorithms. In particular, the proposed architecture embeds the structure of the traditional iterative algorithms, efficiently modeling the recurrence of the iterative reconstruction stages by using recurrent hidden connections over such iterations. In addition, spatio–temporal dependencies are simultaneously learnt by exploiting bidirectional recurrent hidden connections across time sequences. The proposed method is able to learn both the temporal dependence and the iterative reconstruction process effectively with only a very small number of parameters, while outperforming current MR reconstruction methods in terms of reconstruction accuracy and speed.},
	number = {1},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Qin, Chen and Schlemper, Jo and Caballero, Jose and Price, Anthony N. and Hajnal, Joseph V. and Rueckert, Daniel},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {convolutional neural network, cardiac image reconstruction, dynamic magnetic resonance imaging, Image reconstruction, Iterative methods, Machine learning, Magnetic resonance imaging, Optimization, Recurrent neural network, Recurrent neural networks},
	pages = {280--290},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\V89EPI94\\Qin et al. - 2019 - Convolutional Recurrent Neural Networks for Dynami.pdf:application/pdf},
}

@article{lim_tile-net_2021,
	title = {Tile-net for undersampled cardiovascular {CINE} magnetic resonance imaging},
	volume = {84},
	issn = {0730-725X},
	url = {https://www.sciencedirect.com/science/article/pii/S0730725X21001429},
	doi = {10.1016/j.mri.2021.09.001},
	abstract = {We propose the “Tile-net” method based on dividing an image into smaller tiles. Using the tile as the input to the neural network, the network is simplified substantially. The Tile-net learns at a much faster rate than the networks without tiling. The training and reconstruction times for the Tile-net are reduced by 40\% and 33\%, respectively compared to the networks without tiling. The Tile-net performance is evaluated through the normalized mean square error (NMSE), peak signal to noise ratio (PSNR), structure similarity index measure (SSIM) and the quality of the reconstructed image for test datasets. The Tile-net does not degrade performance; however, it reduces the NMSE by 0.3\% compared to the networks without tiling.},
	language = {en},
	urldate = {2022-11-03},
	journal = {Magnetic Resonance Imaging},
	author = {Lim, Chae Guk and Park, Seong Jae and Ahn, Chang-Beom},
	month = dec,
	year = {2021},
	keywords = {Cardiovascular CINE magnetic resonance imaging, Complexity, Neural network, Tile-net, U-net, notion},
	pages = {27--34},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\Q58PM3CE\\Lim et al. - 2021 - Tile-net for undersampled cardiovascular CINE magn.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\5ASNAAPD\\S0730725X21001429.html:text/html},
}

@article{feng_golden-angle_2014,
	title = {Golden-angle radial sparse parallel {MRI}: combination of compressed sensing, parallel imaging, and golden-angle radial sampling for fast and flexible dynamic volumetric {MRI}},
	volume = {72},
	issn = {1522-2594},
	shorttitle = {Golden-angle radial sparse parallel {MRI}},
	doi = {10.1002/mrm.24980},
	abstract = {PURPOSE: To develop a fast and flexible free-breathing dynamic volumetric MRI technique, iterative Golden-angle RAdial Sparse Parallel MRI (iGRASP), that combines compressed sensing, parallel imaging, and golden-angle radial sampling.
METHODS: Radial k-space data are acquired continuously using the golden-angle scheme and sorted into time series by grouping an arbitrary number of consecutive spokes into temporal frames. An iterative reconstruction procedure is then performed on the undersampled time series where joint multicoil sparsity is enforced by applying a total-variation constraint along the temporal dimension. Required coil-sensitivity profiles are obtained from the time-averaged data.
RESULTS: iGRASP achieved higher acceleration capability than either parallel imaging or coil-by-coil compressed sensing alone. It enabled dynamic volumetric imaging with high spatial and temporal resolution for various clinical applications, including free-breathing dynamic contrast-enhanced imaging in the abdomen of both adult and pediatric patients, and in the breast and neck of adult patients.
CONCLUSION: The high performance and flexibility provided by iGRASP can improve clinical studies that require robustness to motion and simultaneous high spatial and temporal resolution. Magn Reson Med 72:707-717, 2014. © 2013 Wiley Periodicals, Inc.},
	language = {eng},
	number = {3},
	journal = {Magnetic Resonance in Medicine},
	author = {Feng, Li and Grimm, Robert and Block, Kai Tobias and Chandarana, Hersh and Kim, Sungheon and Xu, Jian and Axel, Leon and Sodickson, Daniel K. and Otazo, Ricardo},
	month = sep,
	year = {2014},
	pmid = {24142845},
	pmcid = {PMC3991777},
	keywords = {compressed sensing, Magnetic Resonance Imaging, parallel imaging, Humans, Abdomen, Adult, Breast Diseases, Child, Preschool, Contrast Media, Data Compression, dynamic imaging, Female, Gadolinium DTPA, golden-angle, Head and Neck Neoplasms, Image Enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, joint sparsity, Liver Diseases, Male, Middle Aged, radial sampling, Tuberous Sclerosis},
	pages = {707--717},
	file = {Texto completo:C\:\\Users\\Tabita\\Zotero\\storage\\X2KT38D7\\Feng et al. - 2014 - Golden-angle radial sparse parallel MRI combinati.pdf:application/pdf},
}

@misc{blumenthal_mrireconbart_2022,
	title = {mrirecon/bart: version 0.8.00},
	copyright = {BSD 3-Clause "New" or "Revised" License, Open Access},
	shorttitle = {mrirecon/bart},
	url = {https://zenodo.org/record/7110562},
	abstract = {Changes: new tools: epg ictv sim reconet onehotenc measure mnist multicfl morphop fovshift epg: EPG simulations ictv: infimal convolution TV (experimental) sim: Bloch simulations reconet: deep learning reconstruction (MoDL, VarNET) onehotenc: transform onehotencoded data to integer encoded measure: compute MSE, SSIM, PSNR mnist: simple mnist network for demonstration multicfl: combine/split cfl files morphop: morphological operations fovshift: retrospectively shift the FOV pics: tensorflow loss pics: select wavelet type pics: TGV/ICTV regularization (experimental) moba: scaling parameters via command-line parameters moba: various numerical fixes moba: time timensions moba: support for ADMM moba: Bloch model recon with tests moba: multi-gpu option moba: scaling of TV derivatives phantom: NIST phantom and others phantom: rotation for TUBE and NIST phantom geometries phantom: rectangle geometry traj: flag for oversampled trajectory traj: 3D uniform (half-sphere) trajectory sim: output partial derivatives twixread: updates for VD/VE versions ismrmd: support for reading XML metadata estdelay: more generic regarding un-/centered trajectories tgv: for rof / tgv denoising rmfreq: support for contrast changes and coilwise contrast mobafit: T2 and diffusion fit ecalib: make number of iterations for orthiter configurable nufft: warn about incorrectly scaled trajectories nlinv: fix noncart ENLIVE pics: fix basis pursuit pics when using a sampling pattern (\#285) fakeksp: fix output argument python interface: allow multiple files with the correct option string python interface: faster write\_cfl library: New md functions: zacos, zsinh, zcosh, pdf\_gauss, zmaxnorm, zcorr, tenmul library: framework for neural networks library: optimization algorithms: SGD, Adam, Adadelta, iPALM library: linear operators: scale, zconj, zreal, permute, padding, repmat, scaled\_sum library: many new non-linear operators library: support for using different wavelet type library: nlop\_attach, for attaching a random data pointer library: nlop reshape function library: allow forward nufft with toeplitz library: tgv/ictv + multiple penalties + 3D generic: radial DCF examples generic: Add support for multi cfl generic: POSIX shared memory files generic: improve determinism generic: improved parallelization and multi-gpu support generic: add better support for use as shared libray generic: bart for centos 7 generic: Fix Fedora Packages generic: Windows support by MSYS2 generic: support for linking with cudann generic: support for linking with tensorlfow generic: add pythontest to github action generic: LTO test builts many other bug fixes and improvements},
	urldate = {2022-11-03},
	publisher = {Zenodo},
	author = {Blumenthal, Moritz and Holme, Christian and Roeloffs, Volkert and Rosenzweig, Sebastian and Schaten, Philip and Scholand, Nick and Tamir, Jon and Xiaoqing Wang and Uecker, Martin},
	month = sep,
	year = {2022},
	doi = {10.5281/ZENODO.7110562},
	keywords = {compressed sensing, parallel imaging, magnetic resonance imaging, deep learning, computational imaging, model-based reconstruction},
}

@misc{mildenhall_nerf_2020,
	title = {{NeRF}: {Representing} {Scenes} as {Neural} {Radiance} {Fields} for {View} {Synthesis}},
	shorttitle = {{NeRF}},
	url = {http://arxiv.org/abs/2003.08934},
	doi = {10.48550/arXiv.2003.08934},
	abstract = {We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location \$(x,y,z)\$ and viewing direction \$({\textbackslash}theta, {\textbackslash}phi)\$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons.},
	urldate = {2022-11-03},
	publisher = {arXiv},
	author = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
	month = aug,
	year = {2020},
	note = {arXiv:2003.08934 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, notion},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\Y8Y876M7\\Mildenhall et al. - 2020 - NeRF Representing Scenes as Neural Radiance Field.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\5AHEEZZD\\2003.html:text/html},
}

@article{kustner_cinenet_2020,
	title = {{CINENet}: deep learning-based {3D} cardiac {CINE} {MRI} reconstruction with multi-coil complex-valued {4D} spatio-temporal convolutions},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	shorttitle = {{CINENet}},
	url = {https://www.nature.com/articles/s41598-020-70551-8},
	doi = {10.1038/s41598-020-70551-8},
	abstract = {Cardiac CINE magnetic resonance imaging is the gold-standard for the assessment of cardiac function. Imaging accelerations have shown to enable 3D CINE with left ventricular (LV) coverage in a single breath-hold. However, 3D imaging remains limited to anisotropic resolution and long reconstruction times. Recently deep learning has shown promising results for computationally efficient reconstructions of highly accelerated 2D CINE imaging. In this work, we propose a novel 4D (3D + time) deep learning-based reconstruction network, termed 4D CINENet, for prospectively undersampled 3D Cartesian CINE imaging. CINENet is based on (3 + 1)D complex-valued spatio-temporal convolutions and multi-coil data processing. We trained and evaluated the proposed CINENet on in-house acquired 3D CINE data of 20 healthy subjects and 15 patients with suspected cardiovascular disease. The proposed CINENet network outperforms iterative reconstructions in visual image quality and contrast (+ 67\% improvement). We found good agreement in LV function (bias ± 95\% confidence) in terms of end-systolic volume (0 ± 3.3 ml), end-diastolic volume (− 0.4 ± 2.0 ml) and ejection fraction (0.1 ± 3.2\%) compared to clinical gold-standard 2D CINE, enabling single breath-hold isotropic 3D CINE in less than 10 s scan and {\textasciitilde} 5 s reconstruction time.},
	language = {en},
	number = {1},
	urldate = {2022-11-03},
	journal = {Scientific Reports},
	author = {Küstner, Thomas and Fuin, Niccolo and Hammernik, Kerstin and Bustin, Aurelien and Qi, Haikun and Hajhosseiny, Reza and Masci, Pier Giorgio and Neji, Radhouene and Rueckert, Daniel and Botnar, René M. and Prieto, Claudia},
	month = aug,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Machine learning, Magnetic resonance imaging, Biomedical engineering, Cardiology, Computational models, Computational science, Data acquisition, Image processing, Three-dimensional imaging},
	pages = {13710},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\GI8GFZTH\\Küstner et al. - 2020 - CINENet deep learning-based 3D cardiac CINE MRI r.pdf:application/pdf;Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\X4GCC7HV\\s41598-020-70551-8.html:text/html},
}

@inproceedings{bergman_fast_2021,
	title = {Fast {Training} of {Neural} {Lumigraph} {Representations} using {Meta} {Learning}},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/01931a6925d3de09e5f87419d9d55055-Abstract.html},
	abstract = {Novel view synthesis is a long-standing problem in machine learning and computer vision. Significant progress has recently been made in developing neural scene representations and rendering techniques that synthesize photorealistic images from arbitrary views. These representations, however, are extremely slow to train and often also slow to render. Inspired by neural variants of image-based rendering, we develop a new neural rendering approach with the goal of quickly learning a high-quality representation which can also be rendered in real-time. Our approach, MetaNLR++, accomplishes this by using a unique combination of a neural shape representation and 2D CNN-based image feature extraction, aggregation, and re-projection. To push representation convergence times down to minutes, we leverage meta learning to learn neural shape and image feature priors which accelerate training. The optimized shape and image features can then be extracted using traditional graphics techniques and rendered in real time. We show that MetaNLR++ achieves similar or better novel view synthesis results in a fraction of the time that competing methods require.},
	urldate = {2022-11-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Bergman, Alexander and Kellnhofer, Petr and Wetzstein, Gordon},
	year = {2021},
	pages = {172--186},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\35TKJZVW\\Bergman et al. - 2021 - Fast Training of Neural Lumigraph Representations .pdf:application/pdf},
}

@misc{tancik_learned_2021,
	title = {Learned {Initializations} for {Optimizing} {Coordinate}-{Based} {Neural} {Representations}},
	url = {http://arxiv.org/abs/2012.02189},
	doi = {10.48550/arXiv.2012.02189},
	abstract = {Coordinate-based neural representations have shown significant promise as an alternative to discrete, array-based representations for complex low dimensional signals. However, optimizing a coordinate-based network from randomly initialized weights for each new signal is inefficient. We propose applying standard meta-learning algorithms to learn the initial weight parameters for these fully-connected networks based on the underlying class of signals being represented (e.g., images of faces or 3D models of chairs). Despite requiring only a minor change in implementation, using these learned initial weights enables faster convergence during optimization and can serve as a strong prior over the signal class being modeled, resulting in better generalization when only partial observations of a given signal are available. We explore these benefits across a variety of tasks, including representing 2D images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D image observations.},
	urldate = {2022-11-03},
	publisher = {arXiv},
	author = {Tancik, Matthew and Mildenhall, Ben and Wang, Terrance and Schmidt, Divi and Srinivasan, Pratul P. and Barron, Jonathan T. and Ng, Ren},
	month = mar,
	year = {2021},
	note = {arXiv:2012.02189 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\M5IJ6PTY\\Tancik et al. - 2021 - Learned Initializations for Optimizing Coordinate-.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\3HYW84DT\\2012.html:text/html},
}

@misc{yoo_time-dependent_2021,
	title = {Time-{Dependent} {Deep} {Image} {Prior} for {Dynamic} {MRI}},
	url = {http://arxiv.org/abs/1910.01684},
	abstract = {We propose a novel unsupervised deep-learning-based algorithm for dynamic magnetic resonance imaging (MRI) reconstruction. Dynamic MRI requires rapid data acquisition for the study of moving organs such as the heart. Existing reconstruction methods suffer from restrictions either in the model design or in the absence of ground-truth data, resulting in low image quality. We introduce a generalized version of the deep-image-prior approach, which optimizes the network weights to fit a sequence of sparsely acquired dynamic MRI measurements. Our method needs neither prior training nor additional data. In particular, for cardiac images, it does not require the marking of heartbeats or the reordering of spokes. The key ingredients of our method are threefold: 1) a fixed low-dimensional manifold that encodes the temporal variations of images; 2) a network that maps the manifold into a more expressive latent space; and 3) a convolutional neural network that generates a dynamic series of MRI images from the latent variables and that favors their consistency with the measurements in k-space. Our method outperforms the state-of-the-art methods quantitatively and qualitatively in both retrospective and real fetal cardiac datasets. To the best of our knowledge, this is the first unsupervised deep-learning-based method that can reconstruct the continuous variation of dynamic MRI sequences with high spatial resolution.},
	urldate = {2022-11-08},
	publisher = {arXiv},
	author = {Yoo, Jaejun and Jin, Kyong Hwan and Gupta, Harshit and Yerly, Jerome and Stuber, Matthias and Unser, Michael},
	month = jan,
	year = {2021},
	note = {arXiv:1910.01684 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Machine Learning, notion},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\PI7DTMNT\\Yoo et al. - 2021 - Time-Dependent Deep Image Prior for Dynamic MRI.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\BIB5A2KD\\1910.html:text/html},
}

@inproceedings{yazdanpanah_non-learning_2019,
	title = {Non-{Learning} based {Deep} {Parallel} {MRI} {Reconstruction} ({NLDpMRI})},
	url = {http://arxiv.org/abs/1808.02122},
	doi = {10.1117/12.2511653},
	abstract = {Fast data acquisition in Magnetic Resonance Imaging (MRI) is vastly in demand and scan time directly depends on the number of acquired k-space samples. Recently, the deep learning-based MRI reconstruction techniques were suggested to accelerate MR image acquisition. The most common issues in any deep learning-based MRI reconstruction approaches are generalizability and transferability. For different MRI scanner configurations using these approaches, the network must be trained from scratch every time with new training dataset, acquired under new configurations, to be able to provide good reconstruction performance. Here, we propose a new generalized parallel imaging method based on deep neural networks called NLDpMRI to reduce any structured aliasing ambiguities related to the different k-space undersampling patterns for accelerated data acquisition. Two loss functions including non-regularized and regularized are proposed for parallel MRI reconstruction using deep network optimization and we reconstruct MR images by optimizing the proposed loss functions over the network parameters. Unlike any deep learning-based MRI reconstruction approaches, our method doesn't include any training step that the network learns from a large number of training samples and it only needs the single undersampled multi-coil k-space data for reconstruction. Also, the proposed method can handle k-space data with different undersampling patterns, and the different number of coils. Experimental results show that the proposed method outperforms the current state-of-the-art GRAPPA method and the deep learning-based variational network method.},
	urldate = {2022-11-08},
	booktitle = {Medical {Imaging} 2019: {Image} {Processing}},
	author = {Yazdanpanah, Ali Pour and Afacan, Onur and Warfield, Simon K.},
	month = mar,
	year = {2019},
	note = {arXiv:1808.02122 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, notion},
	pages = {3},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\L869CEN7\\Yazdanpanah et al. - 2019 - Non-Learning based Deep Parallel MRI Reconstructio.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\DP8W2HNI\\1808.html:text/html},
}

@inproceedings{narnhofer_inverse_2019,
	title = {Inverse {GANs} for accelerated {MRI} reconstruction},
	volume = {11138},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11138/111381A/Inverse-GANs-for-accelerated-MRI-reconstruction/10.1117/12.2527753.full},
	doi = {10.1117/12.2527753},
	abstract = {State-of-the-art algorithms for accelerated magnetic resonance image (MRI) reconstruction are nowadays dominated by deep learning-based techniques. However, the majority of these methods require the respective sampling patterns in training, which limits their application to a specific problem class. We propose an iterative reconstruction approach that incorporates the implicit prior provided by a generative adversarial network (GAN), which learns the probability distribution of uncorrupted MRI data in an off-line step. Since the unsupervised training of the GAN is completely independent of the measurement process, our method is in principle able to address multiple sampling modalities using a single pre-trained model. However, it turns out that the desired target images potentially lie outside the range space of the learned GAN, leading to reconstructions that resemble the target images only at a coarse level of detail. To overcome this issue, we propose a refinement scheme termed GAN prior adaption, that allows for additional adaption of the generating network with respect to the measured data. The proposed method is evaluated on multi-coil knee MRI data for different acceleration factors and compared to a classical as well as a deep learning-based approach showing promising quantitative and qualitative results.},
	urldate = {2022-11-08},
	booktitle = {Wavelets and {Sparsity} {XVIII}},
	publisher = {SPIE},
	author = {Narnhofer, Dominik and Hammernik, Kerstin and Knoll, Florian and Pock, Thomas},
	month = sep,
	year = {2019},
	pages = {381--392},
	file = {Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\7PWSZB4F\\12.2527753.html:text/html},
}

@article{tezcan_mr_2019,
	title = {{MR} image reconstruction using deep density priors},
	volume = {38},
	issn = {0278-0062, 1558-254X},
	url = {http://arxiv.org/abs/1711.11386},
	doi = {10.1109/TMI.2018.2887072},
	abstract = {Algorithms for Magnetic Resonance (MR) image reconstruction from undersampled measurements exploit prior information to compensate for missing k-space data. Deep learning (DL) provides a powerful framework for extracting such information from existing image datasets, through learning, and then using it for reconstruction. Leveraging this, recent methods employed DL to learn mappings from undersampled to fully sampled images using paired datasets, including undersampled and corresponding fully sampled images, integrating prior knowledge implicitly. In this article, we propose an alternative approach that learns the probability distribution of fully sampled MR images using unsupervised DL, specifically Variational Autoencoders (VAE), and use this as an explicit prior term in reconstruction, completely decoupling the encoding operation from the prior. The resulting reconstruction algorithm enjoys a powerful image prior to compensate for missing k-space data without requiring paired datasets for training nor being prone to associated sensitivities, such as deviations in undersampling patterns used in training and test time or coil settings. We evaluated the proposed method with T1 weighted images from a publicly available dataset, multi-coil complex images acquired from healthy volunteers (N=8) and images with white matter lesions. The proposed algorithm, using the VAE prior, produced visually high quality reconstructions and achieved low RMSE values, outperforming most of the alternative methods on the same dataset. On multi-coil complex data, the algorithm yielded accurate magnitude and phase reconstruction results. In the experiments on images with white matter lesions, the method faithfully reconstructed the lesions. Keywords: Reconstruction, MRI, prior probability, machine learning, deep learning, unsupervised learning, density estimation},
	number = {7},
	urldate = {2022-11-08},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Tezcan, Kerem C. and Baumgartner, Christian F. and Luechinger, Roger and Pruessmann, Klaas P. and Konukoglu, Ender},
	month = jul,
	year = {2019},
	note = {arXiv:1711.11386 [cs, eess, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Statistics - Machine Learning},
	pages = {1633--1642},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\84M28JM7\\Tezcan et al. - 2019 - MR image reconstruction using deep density priors.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\62WU4MLJ\\1711.html:text/html},
}

@article{pruessmann_sense_1999,
	title = {{SENSE}: sensitivity encoding for fast {MRI}},
	volume = {42},
	issn = {0740-3194},
	shorttitle = {{SENSE}},
	url = {https://pubmed.ncbi.nlm.nih.gov/10542355/},
	abstract = {New theoretical and practical concepts are presented for considerably enhancing the performance of magnetic resonance imaging (MRI) by means of arrays of multiple receiver coils. Sensitivity encoding (SENSE) is based on the fact that receiver sensitivity generally has an encoding effect complementary to Fourier preparation by linear field gradients. Thus, by using multiple receiver coils in parallel scan time in Fourier imaging can be considerably reduced. The problem of image reconstruction from sensitivity encoded data is formulated in a general fashion and solved for arbitrary coil configurations and k-space sampling patterns. Special attention is given to the currently most practical case, namely, sampling a common Cartesian grid with reduced density. For this case the feasibility of the proposed methods was verified both in vitro and in vivo. Scan time was reduced to one-half using a two-coil array in brain imaging. With an array of five coils double-oblique heart images were obtained in one-third of conventional scan time. Magn Reson Med 42:952-962, 1999.},
	language = {eng},
	number = {5},
	journal = {Magnetic Resonance in Medicine},
	author = {Pruessmann, K. P. and Weiger, M. and Scheidegger, M. B. and Boesiger, P.},
	month = nov,
	year = {1999},
	pmid = {10542355},
	keywords = {Magnetic Resonance Imaging, Heart, Humans, Image Enhancement, Brain, Fourier Analysis, Models, Theoretical, Phantoms, Imaging, Sensitivity and Specificity, notion},
	pages = {952--962},
}

@article{lustig_compressed_2008,
	title = {Compressed {Sensing} {MRI}},
	volume = {25},
	issn = {1558-0792},
	doi = {10.1109/MSP.2007.914728},
	abstract = {This article reviews the requirements for successful compressed sensing (CS), describes their natural fit to MRI, and gives examples of four interesting applications of CS in MRI. The authors emphasize on an intuitive understanding of CS by describing the CS reconstruction as a process of interference cancellation. There is also an emphasis on the understanding of the driving factors in applications, including limitations imposed by MRI hardware, by the characteristics of different types of images, and by clinical concerns.},
	number = {2},
	journal = {IEEE Signal Processing Magazine},
	author = {Lustig, Michael and Donoho, David L. and Santos, Juan M. and Pauly, John M.},
	month = mar,
	year = {2008},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Image reconstruction, Magnetic resonance imaging, Biomedical imaging, Compressed sensing, Encoding, Image coding, Magnetization, Protons, Radio frequency, Wavelet transforms},
	pages = {72--82},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\TI7DJTRK\\4472246.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\PGWG8X4D\\Lustig et al. - 2008 - Compressed Sensing MRI.pdf:application/pdf},
}

@article{ulyanov_deep_2020,
	title = {Deep {Image} {Prior}},
	volume = {128},
	issn = {0920-5691, 1573-1405},
	url = {http://arxiv.org/abs/1711.10925},
	doi = {10.1007/s11263-020-01303-4},
	abstract = {Deep convolutional networks have become a popular tool for image generation and restoration. Generally, their excellent performance is imputed to their ability to learn realistic image priors from a large number of example images. In this paper, we show that, on the contrary, the structure of a generator network is sufficient to capture a great deal of low-level image statistics prior to any learning. In order to do so, we show that a randomly-initialized neural network can be used as a handcrafted prior with excellent results in standard inverse problems such as denoising, super-resolution, and inpainting. Furthermore, the same prior can be used to invert deep neural representations to diagnose them, and to restore images based on flash-no flash input pairs. Apart from its diverse applications, our approach highlights the inductive bias captured by standard generator network architectures. It also bridges the gap between two very popular families of image restoration methods: learning-based methods using deep convolutional networks and learning-free methods based on handcrafted image priors such as self-similarity. Code and supplementary material are available at https://dmitryulyanov.github.io/deep\_image\_prior .},
	number = {7},
	urldate = {2022-11-08},
	journal = {International Journal of Computer Vision},
	author = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
	month = jul,
	year = {2020},
	note = {arXiv:1711.10925 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	pages = {1867--1888},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\ATY3YZBC\\Ulyanov et al. - 2020 - Deep Image Prior.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\SKM3IJ7T\\1711.html:text/html},
}

@inproceedings{tancik_fourier_2020,
	title = {Fourier {Features} {Let} {Networks} {Learn} {High} {Frequency} {Functions} in {Low} {Dimensional} {Domains}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/55053683268957697aa39fba6f231c68-Abstract.html},
	abstract = {We show that passing input points through a simple Fourier feature mapping enables a multilayer perceptron (MLP) to learn high-frequency functions in low-dimensional problem domains. These results shed light on recent advances in computer vision and graphics that achieve state-of-the-art results by using MLPs to represent complex 3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature, we show that a standard MLP has impractically slow convergence to high frequency signal components. To overcome this spectral bias, we use a Fourier feature mapping to transform the effective NTK into a stationary kernel with a tunable bandwidth. We suggest an approach for selecting problem-specific Fourier features that greatly improves the performance of MLPs for low-dimensional regression tasks relevant to the computer vision and graphics communities.},
	urldate = {2022-11-09},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
	year = {2020},
	pages = {7537--7547},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\CTZ5YMIK\\Tancik et al. - 2020 - Fourier Features Let Networks Learn High Frequency.pdf:application/pdf},
}

@article{xie_neural_2022,
	title = {Neural {Fields} in {Visual} {Computing} and {Beyond}},
	volume = {41},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14505},
	doi = {10.1111/cgf.14505},
	abstract = {Recent advances in machine learning have led to increased interest in solving visual computing problems using methods that employ coordinate-based neural networks. These methods, which we call neural fields, parameterize physical properties of scenes or objects across space and time. They have seen widespread success in problems such as 3D shape and image synthesis, animation of human bodies, 3D reconstruction, and pose estimation. Rapid progress has led to numerous papers, but a consolidation of the discovered knowledge has not yet emerged. We provide context, mathematical grounding, and a review of over 250 papers in the literature on neural fields. In Part I, we focus on neural field techniques by identifying common components of neural field methods, including different conditioning, representation, forward map, architecture, and manipulation methods. In Part II, we focus on applications of neural fields to different problems in visual computing, and beyond (e.g., robotics, audio). Our review shows the breadth of topics already covered in visual computing, both historically and in current incarnations, and highlights the improved quality, flexibility, and capability brought by neural field methods. Finally, we present a companion website that acts as a living database that can be continually updated by the community.},
	language = {en},
	number = {2},
	urldate = {2022-11-09},
	journal = {Computer Graphics Forum},
	author = {Xie, Yiheng and Takikawa, Towaki and Saito, Shunsuke and Litany, Or and Yan, Shiqin and Khan, Numair and Tombari, Federico and Tompkin, James and Sitzmann, Vincent and Sridhar, Srinath},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14505},
	keywords = {• Computing methodologies → Machine Learning, Artificial Intelligence, CCS Concepts, notion},
	pages = {641--676},
	file = {Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\UF3YAT23\\cgf.html:text/html;Versión enviada:C\:\\Users\\Tabita\\Zotero\\storage\\XBTPFYAM\\Xie et al. - 2022 - Neural Fields in Visual Computing and Beyond.pdf:application/pdf},
}

@inproceedings{rahaman_spectral_2019,
	title = {On the {Spectral} {Bias} of {Neural} {Networks}},
	url = {https://proceedings.mlr.press/v97/rahaman19a.html},
	abstract = {Neural networks are known to be a class of highly expressive functions able to fit even random input-output mappings with 100\% accuracy. In this work we present properties of neural networks that complement this aspect of expressivity. By using tools from Fourier analysis, we highlight a learning bias of deep networks towards low frequency functions – i.e. functions that vary globally without local fluctuations – which manifests itself as a frequency-dependent learning speed. Intuitively, this property is in line with the observation that over-parameterized networks prioritize learning simple patterns that generalize across data samples. We also investigate the role of the shape of the data manifold by presenting empirical and theoretical evidence that, somewhat counter-intuitively, learning higher frequencies gets easier with increasing manifold complexity.},
	language = {en},
	urldate = {2022-11-09},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred and Bengio, Yoshua and Courville, Aaron},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	keywords = {notion},
	pages = {5301--5310},
	file = {Supplementary PDF:C\:\\Users\\Tabita\\Zotero\\storage\\9USC4FXW\\Rahaman et al. - 2019 - On the Spectral Bias of Neural Networks.pdf:application/pdf},
}

@article{el-rewaidy_multi-domain_2021,
	title = {Multi-domain convolutional neural network ({MD}-{CNN}) for radial reconstruction of dynamic cardiac {MRI}},
	volume = {85},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.28485},
	doi = {10.1002/mrm.28485},
	abstract = {Purpose Cardiac MR cine imaging allows accurate and reproducible assessment of cardiac function. However, its long scan time not only limits the spatial and temporal resolutions but is challenging in patients with breath-holding difficulty or non-sinus rhythms. To reduce scan time, we propose a multi-domain convolutional neural network (MD-CNN) for fast reconstruction of highly undersampled radial cine images. Methods MD-CNN is a complex-valued network that processes MR data in k-space and image domains via k-space interpolation and image-domain subnetworks for residual artifact suppression. MD-CNN exploits spatio-temporal correlations across timeframes and multi-coil redundancies to enable high acceleration. Radial cine data were prospectively collected in 108 subjects (50 ± 17 y, 72 males) using retrospective-gated acquisition with 80\%:20\% split for training/testing. Images were reconstructed by MD-CNN and k-t Radial Sparse-Sense(kt-RASPS) using an undersampled dataset (14 of 196 acquired views; relative acceleration rate = 14). MD-CNN images were evaluated quantitatively using mean-squared-error (MSE) and structural similarity index (SSIM) relative to reference images, and qualitatively by three independent readers for left ventricular (LV) border sharpness and temporal fidelity using 5-point Likert-scale (1-non-diagnostic, 2-poor, 3-fair, 4-good, and 5-excellent). Results MD-CNN showed improved MSE and SSIM compared to kt-RASPS (0.11 ± 0.10 vs. 0.61 ± 0.51, and 0.87 ± 0.07 vs. 0.72 ± 0.07, respectively; P {\textless} .01). Qualitatively, MD-CCN significantly outperformed kt-RASPS in LV border sharpness (3.87 ± 0.66 vs. 2.71 ± 0.58 at end-diastole, and 3.57 ± 0.6 vs. 2.56 ± 0.6 at end-systole, respectively; P {\textless} .01) and temporal fidelity (3.27 ± 0.65 vs. 2.59 ± 0.59; P {\textless} .01). Conclusion MD-CNN reduces the scan time of cine imaging by a factor of 23.3 and provides superior image quality compared to kt-RASPS.},
	language = {en},
	number = {3},
	urldate = {2022-11-28},
	journal = {Magnetic Resonance in Medicine},
	author = {El-Rewaidy, Hossam and Fahmy, Ahmed S. and Pashakhanloo, Farhad and Cai, Xiaoying and Kucukseymen, Selcuk and Csecs, Ibolya and Neisius, Ulf and Haji-Valizadeh, Hassan and Menze, Bjoern and Nezafat, Reza},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.28485},
	keywords = {image reconstruction, deep learning, Cardiac MRI, non-cartesian acquisition, radial acquisition, real-time imaging, notion},
	pages = {1195--1208},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\NVM6HW9C\\El-Rewaidy et al. - 2021 - Multi-domain convolutional neural network (MD-CNN).pdf:application/pdf;Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\VHYYAGBL\\mrm.html:text/html},
}

@misc{kim_generalizable_2022,
	title = {Generalizable {Implicit} {Neural} {Representations} via {Instance} {Pattern} {Composers}},
	url = {http://arxiv.org/abs/2211.13223},
	abstract = {Despite recent advances in implicit neural representations (INRs), it remains challenging for a coordinate-based multi-layer perceptron (MLP) of INRs to learn a common representation across data instances and generalize it for unseen instances. In this work, we introduce a simple yet effective framework for generalizable INRs that enables a coordinate-based MLP to represent complex data instances by modulating only a small set of weights in an early MLP layer as an instance pattern composer; the remaining MLP weights learn pattern composition rules for common representations across instances. Our generalizable INR framework is fully compatible with existing meta-learning and hypernetworks in learning to predict the modulated weight for unseen instances. Extensive experiments demonstrate that our method achieves high performance on a wide range of domains such as an audio, image, and 3D object, while the ablation study validates our weight modulation.},
	urldate = {2022-11-28},
	publisher = {arXiv},
	author = {Kim, Chiheon and Lee, Doyup and Kim, Saehoon and Cho, Minsu and Han, Wook-Shin},
	month = nov,
	year = {2022},
	note = {arXiv:2211.13223 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\2D5RNXX8\\Kim et al. - 2022 - Generalizable Implicit Neural Representations via .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\SWAW63TS\\2211.html:text/html},
}

@article{schlemper_deep_2018,
	title = {A {Deep} {Cascade} of {Convolutional} {Neural} {Networks} for {Dynamic} {MR} {Image} {Reconstruction}},
	volume = {37},
	issn = {1558-254X},
	doi = {10.1109/TMI.2017.2760978},
	abstract = {Inspired by recent advances in deep learning, we propose a framework for reconstructing dynamic sequences of 2-D cardiac magnetic resonance (MR) images from undersampled data using a deep cascade of convolutional neural networks (CNNs) to accelerate the data acquisition process. In particular, we address the case where data are acquired using aggressive Cartesian undersampling. First, we show that when each 2-D image frame is reconstructed independently, the proposed method outperforms state-of-the-art 2-D compressed sensing approaches, such as dictionary learning-based MR image reconstruction, in terms of reconstruction error and reconstruction speed. Second, when reconstructing the frames of the sequences jointly, we demonstrate that CNNs can learn spatio-temporal correlations efficiently by combining convolution and data sharing approaches. We show that the proposed method consistently outperforms state-of-the-art methods and is capable of preserving anatomical structure more faithfully up to 11-fold undersampling. Moreover, reconstruction is very fast: each complete dynamic sequence can be reconstructed in less than 10 s and, for the 2-D case, each image frame can be reconstructed in 23 ms, enabling real-time applications.},
	language = {eng},
	number = {2},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Schlemper, Jo and Caballero, Jose and Hajnal, Joseph V. and Price, Anthony N. and Rueckert, Daniel},
	month = feb,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {compressed sensing, image reconstruction, Algorithms, Databases, Factual, Heart, Humans, Image Processing, Computer-Assisted, Magnetic Resonance Imaging, Cine, Neural Networks, Computer, convolutional neural network, dynamic magnetic resonance imaging, Image reconstruction, Machine learning, Compressed sensing, Deep learning, Imaging, Neural networks, Redundancy, Two dimensional displays},
	pages = {491--503},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\CIZRZEDY\\8067520.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\4923M3VC\\Schlemper et al. - 2018 - A Deep Cascade of Convolutional Neural Networks fo.pdf:application/pdf;Versión enviada:C\:\\Users\\Tabita\\Zotero\\storage\\V65NVDM4\\Schlemper et al. - 2018 - A Deep Cascade of Convolutional Neural Networks fo.pdf:application/pdf},
}

@article{oh_end--end_2022,
	title = {An {End}-to-{End} {Recurrent} {Neural} {Network} for {Radial} {MR} {Image} {Reconstruction}},
	volume = {22},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/19/7277},
	doi = {10.3390/s22197277},
	abstract = {Recent advances in deep learning have contributed greatly to the field of parallel MR imaging, where a reduced amount of k-space data are acquired to accelerate imaging time. In our previous work, we have proposed a deep learning method to reconstruct MR images directly from k-space data acquired with Cartesian trajectories. However, MRI utilizes various non-Cartesian trajectories, such as radial trajectories, with various numbers of multi-channel RF coils according to the purpose of an MRI scan. Thus, it is important for a reconstruction network to efficiently unfold aliasing artifacts due to undersampling and to combine multi-channel k-space data into single-channel data. In this work, a neural network named ‘ETER-net’ is utilized to reconstruct an MR image directly from k-space data acquired with Cartesian and non-Cartesian trajectories and multi-channel RF coils. In the proposed image reconstruction network, the domain transform network converts k-space data into a rough image, which is then refined in the following network to reconstruct a final image. We also analyze loss functions including adversarial and perceptual losses to improve the network performance. For experiments, we acquired k-space data at a 3T MRI scanner with Cartesian and radial trajectories to show the learning mechanism of the direct mapping relationship between the k-space and the corresponding image by the proposed network and to demonstrate the practical applications. According to our experiments, the proposed method showed satisfactory performance in reconstructing images from undersampled single- or multi-channel k-space data with reduced image artifacts. In conclusion, the proposed method is a deep-learning-based MR reconstruction network, which can be used as a unified solution for parallel MRI, where k-space data are acquired with various scanning trajectories.},
	language = {en},
	number = {19},
	urldate = {2022-12-14},
	journal = {Sensors},
	author = {Oh, Changheun and Chung, Jun-Young and Han, Yeji},
	month = jan,
	year = {2022},
	note = {Number: 19
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {image reconstruction, end to end, MRI, RNN},
	pages = {7277},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\WRB9J2FA\\Oh et al. - 2022 - An End-to-End Recurrent Neural Network for Radial .pdf:application/pdf},
}

@incollection{mojibian_chapter_2018,
	title = {Chapter 8 - {Cardiac} {Magnetic} {Resonance} {Imaging}},
	isbn = {978-0-323-51149-0},
	url = {https://www.sciencedirect.com/science/article/pii/B9780323511490000080},
	abstract = {Cardiac MRI is one of the newest tools in the evaluation of patients with cardiovascular disease. This chapter provides a very basic introduction to MRI technology and also clinical indications of cardiac MRI in practice of modern cardiology.},
	language = {en},
	urldate = {2022-12-15},
	booktitle = {Practical {Cardiology}},
	publisher = {Elsevier},
	author = {Mojibian, Hamid and Pouraliakbar, Hamidreza},
	editor = {Maleki, Majid and Alizadehasl, Azin and Haghjoo, Majid},
	month = jan,
	year = {2018},
	doi = {10.1016/B978-0-323-51149-0.00008-0},
	pages = {159--166},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\YXXBIKJ9\\Mojibian y Pouraliakbar - 2018 - Chapter 8 - Cardiac Magnetic Resonance Imaging.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\VWT5KMZZ\\B9780323511490000080.html:text/html},
}

@article{tsao_k-t_2003,
	title = {k-t {BLAST} and k-t {SENSE}: {Dynamic} {MRI} with high frame rate exploiting spatiotemporal correlations},
	volume = {50},
	issn = {1522-2594},
	shorttitle = {k-t {BLAST} and k-t {SENSE}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.10611},
	doi = {10.1002/mrm.10611},
	abstract = {Dynamic images of natural objects exhibit significant correlations in k-space and time. Thus, it is feasible to acquire only a reduced amount of data and recover the missing portion afterwards. This leads to an improved temporal resolution, or an improved spatial resolution for a given amount of acquisition. Based on this approach, two methods were developed to significantly improve the performance of dynamic imaging, named k-t BLAST (Broad-use Linear Acquisition Speed-up Technique) and k-t SENSE (SENSitivity Encoding) for use with a single or multiple receiver coils, respectively. Signal correlations were learned from a small set of training data and the missing data were recovered using all available information in a consistent and integral manner. The general theory of k-t BLAST and k-t SENSE is applicable to arbitrary k-space trajectories, time-varying coil sensitivities, and under- and overdetermined reconstruction problems. Examples from ungated cardiac imaging demonstrate a 4-fold acceleration (voxel size 2.42 × 2.52 mm2, 38.4 fps) with either one or six receiver coils. k-t BLAST and k-t SENSE are applicable to many areas, especially those exhibiting quasiperiodic motion, such as imaging of the heart, the lungs, the abdomen, and the brain under periodic stimulation. Magn Reson Med 50:1031–1042, 2003. © 2003 Wiley-Liss, Inc.},
	language = {en},
	number = {5},
	urldate = {2022-12-16},
	journal = {Magnetic Resonance in Medicine},
	author = {Tsao, Jeffrey and Boesiger, Peter and Pruessmann, Klaas P.},
	year = {2003},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.10611},
	keywords = {MRI, fast dynamic imaging, k-t BLAST, k-t SENSE, prior-information-driven parallel imaging},
	pages = {1031--1042},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\BVAM8NWC\\Tsao et al. - 2003 - k-t BLAST and k-t SENSE Dynamic MRI with high fra.pdf:application/pdf;Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\IP3P2JWM\\mrm.html:text/html},
}

@article{feng_golden-angle_2022,
	title = {Golden-{Angle} {Radial} {MRI}: {Basics}, {Advances}, and {Applications}},
	volume = {56},
	issn = {1522-2586},
	shorttitle = {Golden-{Angle} {Radial} {MRI}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.28187},
	doi = {10.1002/jmri.28187},
	abstract = {In recent years, golden-angle radial sampling has received substantial attention and interest in the magnetic resonance imaging (MRI) community, and it has become a popular sampling trajectory for both research and clinical use. However, although the number of relevant techniques and publications has grown rapidly, there is still a lack of a review paper that provides a comprehensive overview and summary of the basics of golden-angle rotation, the advantages and challenges/limitations of golden-angle radial sampling, and recommendations in using different types of golden-angle radial trajectories for MRI applications. Such a review paper is expected to be helpful both for clinicians who are interested in learning the potential benefits of golden-angle radial sampling and for MRI physicists who are interested in exploring this research direction. The main purpose of this review paper is thus to present an overview and summary about golden-angle radial MRI sampling. The review consists of three sections. The first section aims to answer basic questions such as: what is a golden angle; how is the golden angle calculated; why is golden-angle radial sampling useful, and what are its limitations. The second section aims to review more advanced trajectories of golden-angle radial sampling, including tiny golden-angle rotation, stack-of-stars golden-angle radial sampling, and three-dimensional (3D) kooshball golden-angle radial sampling. Their respective advantages and limitations and potential solutions to address these limitations are also discussed. Finally, the third section reviews MRI applications that can benefit from golden-angle radial sampling and provides recommendations to readers who are interested in implementing golden-angle radial trajectories in their MRI studies. Evidence Level 5 Technical Efficacy Stage 1},
	language = {en},
	number = {1},
	urldate = {2022-12-16},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Feng, Li},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.28187},
	keywords = {golden-angle, radial sampling, continuous acquisition, motion robustness, self-navigation, stack-of-stars},
	pages = {45--62},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\JM9ZI6RG\\Feng - 2022 - Golden-Angle Radial MRI Basics, Advances, and App.pdf:application/pdf;Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\6M6PBTJL\\jmri.html:text/html},
}

@article{fessler_nonuniform_2003,
	title = {Nonuniform fast {Fourier} transforms using min-max interpolation},
	volume = {51},
	issn = {1941-0476},
	doi = {10.1109/TSP.2002.807005},
	abstract = {The fast Fourier transform (FFT) is used widely in signal processing for efficient computation of the FT of finite-length signals over a set of uniformly spaced frequency locations. However, in many applications, one requires nonuniform sampling in the frequency domain, i.e., a nonuniform FT. Several papers have described fast approximations for the nonuniform FT based on interpolating an oversampled FFT. This paper presents an interpolation method for the nonuniform FT that is optimal in the min-max sense of minimizing the worst-case approximation error over all signals of unit norm. The proposed method easily generalizes to multidimensional signals. Numerical results show that the min-max approach provides substantially lower approximation errors than conventional interpolation methods. The min-max criterion is also useful for optimizing the parameters of interpolation kernels such as the Kaiser-Bessel function.},
	number = {2},
	journal = {IEEE Transactions on Signal Processing},
	author = {Fessler, J.A. and Sutton, B.P.},
	month = feb,
	year = {2003},
	note = {Conference Name: IEEE Transactions on Signal Processing},
	keywords = {Image reconstruction, Iterative methods, Magnetic resonance imaging, Approximation error, Fast Fourier transforms, Frequency domain analysis, Interpolation, Multidimensional signal processing, Multidimensional systems, Nonuniform sampling},
	pages = {560--574},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\SSIHDVKQ\\1166689.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\GYKVHJUM\\Fessler y Sutton - 2003 - Nonuniform fast Fourier transforms using min-max i.pdf:application/pdf},
}

@article{kustner_lapnet_2021,
	title = {{LAPNet}: {Non}-{Rigid} {Registration} {Derived} in k-{Space} for {Magnetic} {Resonance} {Imaging}},
	volume = {40},
	issn = {0278-0062, 1558-254X},
	shorttitle = {{LAPNet}},
	url = {https://ieeexplore.ieee.org/document/9478906/},
	doi = {10.1109/TMI.2021.3096131},
	abstract = {Physiological motion, such as cardiac and respiratory motion, during Magnetic Resonance (MR) image acquisition can cause image artifacts. Motion correction techniques have been proposed to compensate for these types of motion during thoracic scans, relying on accurate motion estimation from undersampled motion-resolved reconstruction. A particular interest and challenge lie in the derivation of reliable non-rigid motion ﬁelds from the undersampled motion-resolved data. Motion estimation is usually formulated in image space via diffusion, parametric-spline, or optical flow methods. However, image-based registration can be impaired by remaining aliasing artifacts due to the undersampled motion-resolved reconstruction. In this work, we describe a formalism to perform non-rigid registration directly in the sampled Fourier space, i.e. k-space. We propose a deep-learning based approach to perform fast and accurate non-rigid registration from the undersampled k-space data. The basic working principle originates from the Local AllPass (LAP) technique, a recently introduced optical flow-based registration. The proposed LAPNet is compared against traditional and deep learning image-based registrations and tested on fully-sampled and highly-accelerated (with two undersampling strategies) 3D respiratory motion-resolved MR images in a cohort of 40 patients with suspected liver or lung metastases and 25 healthy subjects. The proposed LAPNet provided consistent and superior performance to image-based approaches throughout different sampling trajectories and acceleration factors.},
	language = {en},
	number = {12},
	urldate = {2022-12-26},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Kustner, Thomas and Pan, Jiazhen and Qi, Haikun and Cruz, Gastao and Gilliam, Christopher and Blu, Thierry and Yang, Bin and Gatidis, Sergios and Botnar, Rene and Prieto, Claudia},
	month = dec,
	year = {2021},
	pages = {3686--3697},
	file = {Kustner et al. - 2021 - LAPNet Non-Rigid Registration Derived in k-Space .pdf:C\:\\Users\\Tabita\\Zotero\\storage\\NR2GMSX5\\Kustner et al. - 2021 - LAPNet Non-Rigid Registration Derived in k-Space .pdf:application/pdf},
}

@misc{hoffman_probnerf_2022,
	title = {{ProbNeRF}: {Uncertainty}-{Aware} {Inference} of {3D} {Shapes} from {2D} {Images}},
	shorttitle = {{ProbNeRF}},
	url = {http://arxiv.org/abs/2210.17415},
	doi = {10.48550/arXiv.2210.17415},
	abstract = {The problem of inferring object shape from a single 2D image is underconstrained. Prior knowledge about what objects are plausible can help, but even given such prior knowledge there may still be uncertainty about the shapes of occluded parts of objects. Recently, conditional neural radiance field (NeRF) models have been developed that can learn to infer good point estimates of 3D models from single 2D images. The problem of inferring uncertainty estimates for these models has received less attention. In this work, we propose probabilistic NeRF (ProbNeRF), a model and inference strategy for learning probabilistic generative models of 3D objects' shapes and appearances, and for doing posterior inference to recover those properties from 2D images. ProbNeRF is trained as a variational autoencoder, but at test time we use Hamiltonian Monte Carlo (HMC) for inference. Given one or a few 2D images of an object (which may be partially occluded), ProbNeRF is able not only to accurately model the parts it sees, but also to propose realistic and diverse hypotheses about the parts it does not see. We show that key to the success of ProbNeRF are (i) a deterministic rendering scheme, (ii) an annealed-HMC strategy, (iii) a hypernetwork-based decoder architecture, and (iv) doing inference over a full set of NeRF weights, rather than just a low-dimensional code.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Hoffman, Matthew D. and Le, Tuan Anh and Sountsov, Pavel and Suter, Christopher and Lee, Ben and Mansinghka, Vikash K. and Saurous, Rif A.},
	month = oct,
	year = {2022},
	note = {arXiv:2210.17415 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, 62F15 (Primary) 68T45 (Secondary), G.3, I.4.10, I.5.1},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\TVPC4R4Y\\Hoffman et al. - 2022 - ProbNeRF Uncertainty-Aware Inference of 3D Shapes.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\KSLTT4EK\\2210.html:text/html},
}

@article{muller_instant_2022,
	title = {Instant neural graphics primitives with a multiresolution hash encoding},
	volume = {41},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3528223.3530127},
	doi = {10.1145/3528223.3530127},
	abstract = {Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920×1080.},
	language = {en},
	number = {4},
	urldate = {2023-03-02},
	journal = {ACM Transactions on Graphics},
	author = {Müller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
	month = jul,
	year = {2022},
	pages = {1--15},
	file = {3528223.pdf:C\:\\Users\\Tabita\\Zotero\\storage\\26SMQ98G\\3528223.pdf:application/pdf},
}

@inproceedings{feng_viinter_2022,
	address = {New York, NY, USA},
	series = {{SA} '22},
	title = {{VIINTER}: {View} {Interpolation} with {Implicit} {Neural} {Representations} of {Images}},
	isbn = {978-1-4503-9470-3},
	shorttitle = {{VIINTER}},
	url = {https://doi.org/10.1145/3550469.3555417},
	doi = {10.1145/3550469.3555417},
	abstract = {We present VIINTER, a method for view interpolation by interpolating the implicit neural representation (INR) of the captured images. We leverage the learned code vector associated with each image and interpolate between these codes to achieve viewpoint transitions. We propose several techniques that significantly enhance the interpolation quality. VIINTER signifies a new way to achieve view interpolation without constructing 3D structure, estimating camera poses, or computing pixel correspondence. We validate the effectiveness of VIINTER on several multi-view scenes with different types of camera layout and scene composition. As the development of INR of images (as opposed to surface or volume) has centered around tasks like image fitting and super-resolution, with VIINTER, we show its capability for view interpolation and offer a promising outlook on using INR for image manipulation tasks.},
	urldate = {2023-03-02},
	booktitle = {{SIGGRAPH} {Asia} 2022 {Conference} {Papers}},
	publisher = {Association for Computing Machinery},
	author = {Feng, Brandon Yushan and Jabbireddy, Susmija and Varshney, Amitabh},
	month = nov,
	year = {2022},
	keywords = {coordinate network, implicit neural representation, view synthesis},
	pages = {1--9},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\CJDRSP9P\\Feng et al. - 2022 - VIINTER View Interpolation with Implicit Neural R.pdf:application/pdf},
}

@article{sen_inr-v_2022,
	title = {{INR}-{V}: {A} {Continuous} {Representation} {Space} for {Video}-based {Generative} {Tasks}},
	issn = {2835-8856},
	shorttitle = {{INR}-{V}},
	url = {https://openreview.net/forum?id=aIoEkwc2oB},
	abstract = {Generating videos is a complex task that is accomplished by generating a set of temporally coherent images frame-by-frame. This limits the expressivity of videos to only image-based operations on the individual video frames needing network designs to obtain temporally coherent trajectories in the underlying image space. We propose INR-V, a video representation network that learns a continuous space for video-based generative tasks. INR-V parameterizes videos using implicit neural representations (INRs), a multi-layered perceptron that predicts an RGB value for each input pixel location of the video. The INR is predicted using a meta-network which is a hypernetwork trained on neural representations of multiple video instances. Later, the meta-network can be sampled to generate diverse novel videos enabling many downstream video-based generative tasks. Interestingly, we find that conditional regularization and progressive weight initialization play a crucial role in obtaining INR-V. The representation space learned by INR-V is more expressive than an image space showcasing many interesting properties not possible with the existing works. For instance, INR-V can smoothly interpolate intermediate videos between known video instances (such as intermediate identities, expressions, and poses in face videos). It can also in-paint missing portions in videos to recover temporally coherent full videos. In this work, we evaluate the space learned by INR-V on diverse generative tasks such as video interpolation, novel video generation, video inversion, and video inpainting against the existing baselines. INR-V significantly outperforms the baselines on several of these demonstrated tasks, clearly showing the potential of the proposed representation space.},
	language = {en},
	urldate = {2023-03-02},
	journal = {Transactions on Machine Learning Research},
	author = {Sen, Bipasha and Agarwal, Aditya and Namboodiri, Vinay P. and Jawahar, C. V.},
	month = oct,
	year = {2022},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\4YT9DX7D\\Sen et al. - 2022 - INR-V A Continuous Representation Space for Video.pdf:application/pdf},
}

@misc{li_3d-aware_2022,
	title = {{3D}-{Aware} {Encoding} for {Style}-based {Neural} {Radiance} {Fields}},
	url = {http://arxiv.org/abs/2211.06583},
	doi = {10.48550/arXiv.2211.06583},
	abstract = {We tackle the task of NeRF inversion for style-based neural radiance fields, (e.g., StyleNeRF). In the task, we aim to learn an inversion function to project an input image to the latent space of a NeRF generator and then synthesize novel views of the original image based on the latent code. Compared with GAN inversion for 2D generative models, NeRF inversion not only needs to 1) preserve the identity of the input image, but also 2) ensure 3D consistency in generated novel views. This requires the latent code obtained from the single-view image to be invariant across multiple views. To address this new challenge, we propose a two-stage encoder for style-based NeRF inversion. In the first stage, we introduce a base encoder that converts the input image to a latent code. To ensure the latent code is view-invariant and is able to synthesize 3D consistent novel view images, we utilize identity contrastive learning to train the base encoder. Second, to better preserve the identity of the input image, we introduce a refining encoder to refine the latent code and add finer details to the output image. Importantly note that the novelty of this model lies in the design of its first-stage encoder which produces the closest latent code lying on the latent manifold and thus the refinement in the second stage would be close to the NeRF manifold. Through extensive experiments, we demonstrate that our proposed two-stage encoder qualitatively and quantitatively exhibits superiority over the existing encoders for inversion in both image reconstruction and novel-view rendering.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Li, Yu-Jhe and Xu, Tao and Wu, Bichen and Zheng, Ningyuan and Dai, Xiaoliang and Pumarola, Albert and Zhang, Peizhao and Vajda, Peter and Kitani, Kris},
	month = nov,
	year = {2022},
	note = {arXiv:2211.06583 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\U285HFUJ\\Li et al. - 2022 - 3D-Aware Encoding for Style-based Neural Radiance .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\MTNF8MUM\\2211.html:text/html},
}

@misc{yang_tinc_2022,
	title = {{TINC}: {Tree}-structured {Implicit} {Neural} {Compression}},
	shorttitle = {{TINC}},
	url = {http://arxiv.org/abs/2211.06689},
	doi = {10.48550/arXiv.2211.06689},
	abstract = {Implicit neural representation (INR) can describe the target scenes with high fidelity using a small number of parameters, and is emerging as a promising data compression technique. However, INR in intrinsically of limited spectrum coverage, and it is non-trivial to remove redundancy in diverse complex data effectively. Preliminary studies can only exploit either global or local correlation in the target data and thus of limited performance. In this paper, we propose a Tree-structured Implicit Neural Compression (TINC) to conduct compact representation for local regions and extract the shared features of these local representations in a hierarchical manner. Specifically, we use MLPs to fit the partitioned local regions, and these MLPs are organized in tree structure to share parameters according to the spatial distance. The parameter sharing scheme not only ensures the continuity between adjacent regions, but also jointly removes the local and non-local redundancy. Extensive experiments show that TINC improves the compression fidelity of INR, and has shown impressive compression capabilities over commercial tools and other deep learning based methods. Besides, the approach is of high flexibility and can be tailored for different data and parameter settings. All the reproducible codes are going to be released on github.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Yang, Runzhao and Xiao, Tingxiong and Cheng, Yuxiao and Suo, Jinli and Dai, Qionghai},
	month = nov,
	year = {2022},
	note = {arXiv:2211.06689 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\XVK87A5N\\Yang et al. - 2022 - TINC Tree-structured Implicit Neural Compression.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\9JLGESMV\\2211.html:text/html},
}

@misc{kreis_latent_2022,
	title = {Latent {Space} {Diffusion} {Models} of {Cryo}-{EM} {Structures}},
	url = {http://arxiv.org/abs/2211.14169},
	doi = {10.48550/arXiv.2211.14169},
	abstract = {Cryo-electron microscopy (cryo-EM) is unique among tools in structural biology in its ability to image large, dynamic protein complexes. Key to this ability is image processing algorithms for heterogeneous cryo-EM reconstruction, including recent deep learning-based approaches. The state-of-the-art method cryoDRGN uses a Variational Autoencoder (VAE) framework to learn a continuous distribution of protein structures from single particle cryo-EM imaging data. While cryoDRGN can model complex structural motions, the Gaussian prior distribution of the VAE fails to match the aggregate approximate posterior, which prevents generative sampling of structures especially for multi-modal distributions (e.g. compositional heterogeneity). Here, we train a diffusion model as an expressive, learnable prior in the cryoDRGN framework. Our approach learns a high-quality generative model over molecular conformations directly from cryo-EM imaging data. We show the ability to sample from the model on two synthetic and two real datasets, where samples accurately follow the data distribution unlike samples from the VAE prior distribution. We also demonstrate how the diffusion model prior can be leveraged for fast latent space traversal and interpolation between states of interest. By learning an accurate model of the data distribution, our method unlocks tools in generative modeling, sampling, and distribution analysis for heterogeneous cryo-EM ensembles.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Kreis, Karsten and Dockhorn, Tim and Li, Zihao and Zhong, Ellen},
	month = nov,
	year = {2022},
	note = {arXiv:2211.14169 [q-bio, stat]},
	keywords = {Quantitative Biology - Quantitative Methods, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\WJFU7TS8\\Kreis et al. - 2022 - Latent Space Diffusion Models of Cryo-EM Structure.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\6SX6YBMB\\2211.html:text/html},
}

@misc{arratia_warppinn_2022,
	title = {{WarpPINN}: {Cine}-{MR} image registration with physics-informed neural networks},
	shorttitle = {{WarpPINN}},
	url = {http://arxiv.org/abs/2211.12549},
	doi = {10.48550/arXiv.2211.12549},
	abstract = {Heart failure is typically diagnosed with a global function assessment, such as ejection fraction. However, these metrics have low discriminate power, failing to distinguish different types of this disease. Quantifying local deformations in the form of cardiac strain can provide helpful information, but it remains a challenge. In this work, we introduce WarpPINN, a physics-informed neural network to perform image registration to obtain local metrics of the heart deformation. We apply this method to cine magnetic resonance images to estimate the motion during the cardiac cycle. We inform our neural network of near-incompressibility of cardiac tissue by penalizing the jacobian of the deformation field. The loss function has two components: an intensity-based similarity term between the reference and the warped template images, and a regularizer that represents the hyperelastic behavior of the tissue. The architecture of the neural network allows us to easily compute the strain via automatic differentiation to assess cardiac activity. We use Fourier feature mappings to overcome the spectral bias of neural networks, allowing us to capture discontinuities in the strain field. We test our algorithm on a synthetic example and on a cine-MRI benchmark of 15 healthy volunteers. We outperform current methodologies both landmark tracking and strain estimation. We expect that WarpPINN will enable more precise diagnostics of heart failure based on local deformation information. Source code is available at https://github.com/fsahli/WarpPINN.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Arratia, Pablo and Mella, Hernán and Uribe, Sergio and Hurtado, Daniel E. and Costabal, Francisco Sahli},
	month = nov,
	year = {2022},
	note = {arXiv:2211.12549 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\K98Y6I6M\\López et al. - 2022 - WarpPINN Cine-MR image registration with physics-.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\K2VUX76F\\2211.html:text/html},
}

@misc{wu_neural_2022,
	title = {Neural {Fourier} {Filter} {Bank}},
	url = {http://arxiv.org/abs/2212.01735},
	doi = {10.48550/arXiv.2212.01735},
	abstract = {We present a novel method to provide efficient and highly detailed reconstructions. Inspired by wavelets, our main idea is to learn a neural field that decompose the signal both spatially and frequency-wise. We follow the recent grid-based paradigm for spatial decomposition, but unlike existing work, encourage specific frequencies to be stored in each grid via Fourier features encodings. We then apply a multi-layer perceptron with sine activations, taking these Fourier encoded features in at appropriate layers so that higher-frequency components are accumulated on top of lower-frequency components sequentially, which we sum up to form the final output. We demonstrate that our method outperforms the state of the art regarding model compactness and efficiency on multiple tasks: 2D image fitting, 3D shape reconstruction, and neural radiance fields.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Wu, Zhijie and Jin, Yuhe and Yi, Kwang Moo},
	month = dec,
	year = {2022},
	note = {arXiv:2212.01735 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\JM2XAX5Y\\Wu et al. - 2022 - Neural Fourier Filter Bank.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\PD729J3X\\2212.html:text/html},
}

@misc{rho_masked_2022,
	title = {Masked {Wavelet} {Representation} for {Compact} {Neural} {Radiance} {Fields}},
	url = {http://arxiv.org/abs/2212.09069},
	doi = {10.48550/arXiv.2212.09069},
	abstract = {Neural radiance fields (NeRF) have demonstrated the potential of coordinate-based neural representation (neural fields or implicit neural representation) in neural rendering. However, using a multi-layer perceptron (MLP) to represent a 3D scene or object requires enormous computational resources and time. There have been recent studies on how to reduce these computational inefficiencies by using additional data structures, such as grids or trees. Despite the promising performance, the explicit data structure necessitates a substantial amount of memory. In this work, we present a method to reduce the size without compromising the advantages of having additional data structures. In detail, we propose using the wavelet transform on grid-based neural fields. Grid-based neural fields are for fast convergence, and the wavelet transform, whose efficiency has been demonstrated in high-performance standard codecs, is to improve the parameter efficiency of grids. Furthermore, in order to achieve a higher sparsity of grid coefficients while maintaining reconstruction quality, we present a novel trainable masking approach. Experimental results demonstrate that non-spatial grid coefficients, such as wavelet coefficients, are capable of attaining a higher level of sparsity than spatial grid coefficients, resulting in a more compact representation. With our proposed mask and compression pipeline, we achieved state-of-the-art performance within a memory budget of 2 MB. Our code is available at https://github.com/daniel03c1/masked\_wavelet\_nerf.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Rho, Daniel and Lee, Byeonghyeon and Nam, Seungtae and Lee, Joo Chan and Ko, Jong Hwan and Park, Eunbyung},
	month = dec,
	year = {2022},
	note = {arXiv:2212.09069 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\ZPHWAF7W\\Rho et al. - 2022 - Masked Wavelet Representation for Compact Neural R.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\DSMYMGLB\\2212.html:text/html},
}

@misc{siarohin_unsupervised_2023,
	title = {Unsupervised {Volumetric} {Animation}},
	url = {http://arxiv.org/abs/2301.11326},
	doi = {10.48550/arXiv.2301.11326},
	abstract = {We propose a novel approach for unsupervised 3D animation of non-rigid deformable objects. Our method learns the 3D structure and dynamics of objects solely from single-view RGB videos, and can decompose them into semantically meaningful parts that can be tracked and animated. Using a 3D autodecoder framework, paired with a keypoint estimator via a differentiable PnP algorithm, our model learns the underlying object geometry and parts decomposition in an entirely unsupervised manner. This allows it to perform 3D segmentation, 3D keypoint estimation, novel view synthesis, and animation. We primarily evaluate the framework on two video datasets: VoxCeleb \$256{\textasciicircum}2\$ and TEDXPeople \$256{\textasciicircum}2\$. In addition, on the Cats \$256{\textasciicircum}2\$ image dataset, we show it even learns compelling 3D geometry from still images. Finally, we show our model can obtain animatable 3D objects from a single or few images. Code and visual results available on our project website, see https://snap-research.github.io/unsupervised-volumetric-animation .},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Siarohin, Aliaksandr and Menapace, Willi and Skorokhodov, Ivan and Olszewski, Kyle and Ren, Jian and Lee, Hsin-Ying and Chai, Menglei and Tulyakov, Sergey},
	month = jan,
	year = {2023},
	note = {arXiv:2301.11326 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\T4QZGQ2N\\Siarohin et al. - 2023 - Unsupervised Volumetric Animation.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\W9BT79BR\\2301.html:text/html},
}

@misc{navon_equivariant_2023,
	title = {Equivariant {Architectures} for {Learning} in {Deep} {Weight} {Spaces}},
	url = {http://arxiv.org/abs/2301.12780},
	doi = {10.48550/arXiv.2301.12780},
	abstract = {Designing machine learning architectures for processing neural networks in their raw weight matrix form is a newly introduced research direction. Unfortunately, the unique symmetry structure of deep weight spaces makes this design very challenging. If successful, such architectures would be capable of performing a wide range of intriguing tasks, from adapting a pre-trained network to a new domain to editing objects represented as functions (INRs or NeRFs). As a first step towards this goal, we present here a novel network architecture for learning in deep weight spaces. It takes as input a concatenation of weights and biases of a pre-trained MLP and processes it using a composition of layers that are equivariant to the natural permutation symmetry of the MLP's weights: Changing the order of neurons in intermediate layers of the MLP does not affect the function it represents. We provide a full characterization of all affine equivariant and invariant layers for these symmetries and show how these layers can be implemented using three basic operations: pooling, broadcasting, and fully connected layers applied to the input in an appropriate manner. We demonstrate the effectiveness of our architecture and its advantages over natural baselines in a variety of learning tasks.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Navon, Aviv and Shamsian, Aviv and Achituve, Idan and Fetaya, Ethan and Chechik, Gal and Maron, Haggai},
	month = jan,
	year = {2023},
	note = {arXiv:2301.12780 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\FM887D8B\\Navon et al. - 2023 - Equivariant Architectures for Learning in Deep Wei.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\XA69W2U5\\2301.html:text/html},
}

@misc{liu_devrf_2022,
	title = {{DeVRF}: {Fast} {Deformable} {Voxel} {Radiance} {Fields} for {Dynamic} {Scenes}},
	shorttitle = {{DeVRF}},
	url = {http://arxiv.org/abs/2205.15723},
	abstract = {Modeling dynamic scenes is important for many applications such as virtual reality and telepresence. Despite achieving unprecedented fidelity for novel view synthesis in dynamic scenes, existing methods based on Neural Radiance Fields (NeRF) suffer from slow convergence (i.e., model training time measured in days). In this paper, we present DeVRF, a novel representation to accelerate learning dynamic radiance fields. The core of DeVRF is to model both the 3D canonical space and 4D deformation field of a dynamic, non-rigid scene with explicit and discrete voxel-based representations. However, it is quite challenging to train such a representation which has a large number of model parameters, often resulting in overfitting issues. To overcome this challenge, we devise a novel static-to-dynamic learning paradigm together with a new data capture setup that is convenient to deploy in practice. This paradigm unlocks efficient learning of deformable radiance fields via utilizing the 3D volumetric canonical space learnt from multi-view static images to ease the learning of 4D voxel deformation field with only few-view dynamic sequences. To further improve the efficiency of our DeVRF and its synthesized novel view's quality, we conduct thorough explorations and identify a set of strategies. We evaluate DeVRF on both synthetic and real-world dynamic scenes with different types of deformation. Experiments demonstrate that DeVRF achieves two orders of magnitude speedup (100x faster) with on-par high-fidelity results compared to the previous state-of-the-art approaches. The code and dataset will be released in https://github.com/showlab/DeVRF.},
	urldate = {2023-03-29},
	publisher = {arXiv},
	author = {Liu, Jia-Wei and Cao, Yan-Pei and Mao, Weijia and Zhang, Wenqiao and Zhang, David Junhao and Keppo, Jussi and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
	month = jun,
	year = {2022},
	note = {arXiv:2205.15723 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\FH3VI7Q2\\Liu et al. - 2022 - DeVRF Fast Deformable Voxel Radiance Fields for D.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\L7YHBMVS\\2205.html:text/html},
}

@inproceedings{chen_videoinr_2022,
	address = {New Orleans, LA, USA},
	title = {{VideoINR}: {Learning} {Video} {Implicit} {Neural} {Representation} for {Continuous} {Space}-{Time} {Super}-{Resolution}},
	isbn = {978-1-66546-946-3},
	shorttitle = {{VideoINR}},
	url = {https://ieeexplore.ieee.org/document/9878371/},
	doi = {10.1109/CVPR52688.2022.00209},
	abstract = {Videos typically record the streaming and continuous visual data as discrete consecutive frames. Since the storage cost is expensive for videos of high ﬁdelity, most of them are stored in a relatively low resolution and frame rate. Recent works of Space-Time Video Super-Resolution (STVSR) are developed to incorporate temporal interpolation and spatial super-resolution in a uniﬁed framework. However, most of them only support a ﬁxed upsampling scale, which limits their ﬂexibility and applications. In this work, instead of following the discrete representations, we propose Video Implicit Neural Representation (VideoINR), and we show its applications for STVSR. The learned implicit neural representation can be decoded to videos of arbitrary spatial resolution and frame rate. We show that VideoINR achieves competitive performances with state-of-the-art STVSR methods on common up-sampling scales and signiﬁcantly outperforms prior works on continuous and out-of-training-distribution scales. Our project page is at here and code is available at https://github.com/Picsart-AI-Research/VideoINRContinuous-Space-Time-Super-Resolution.},
	language = {en},
	urldate = {2023-03-29},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Chen, Zeyuan and Chen, Yinbo and Liu, Jingwen and Xu, Xingqian and Goel, Vidit and Wang, Zhangyang and Shi, Humphrey and Wang, Xiaolong},
	month = jun,
	year = {2022},
	pages = {2037--2047},
	file = {Chen et al. - 2022 - VideoINR Learning Video Implicit Neural Represent.pdf:C\:\\Users\\Tabita\\Zotero\\storage\\2YC8HGHP\\Chen et al. - 2022 - VideoINR Learning Video Implicit Neural Represent.pdf:application/pdf},
}

@article{zhang_dynamic_2023,
	title = {Dynamic cone-beam {CT} reconstruction using spatial and temporal implicit neural representation learning ({STINR})},
	volume = {68},
	issn = {0031-9155},
	url = {https://dx.doi.org/10.1088/1361-6560/acb30d},
	doi = {10.1088/1361-6560/acb30d},
	abstract = {Objective. Dynamic cone-beam CT (CBCT) imaging is highly desired in image-guided radiation therapy to provide volumetric images with high spatial and temporal resolutions to enable applications including tumor motion tracking/prediction and intra-delivery dose calculation/accumulation. However, dynamic CBCT reconstruction is a substantially challenging spatiotemporal inverse problem, due to the extremely limited projection sample available for each CBCT reconstruction (one projection for one CBCT volume). Approach. We developed a simultaneous spatial and temporal implicit neural representation (STINR) method for dynamic CBCT reconstruction. STINR mapped the unknown image and the evolution of its motion into spatial and temporal multi-layer perceptrons (MLPs), and iteratively optimized the neuron weightings of the MLPs via acquired projections to represent the dynamic CBCT series. In addition to the MLPs, we also introduced prior knowledge, in the form of principal component analysis (PCA)-based patient-specific motion models, to reduce the complexity of the temporal mapping to address the ill-conditioned dynamic CBCT reconstruction problem. We used the extended-cardiac-torso (XCAT) phantom and a patient 4D-CBCT dataset to simulate different lung motion scenarios to evaluate STINR. The scenarios contain motion variations including motion baseline shifts, motion amplitude/frequency variations, and motion non-periodicity. The XCAT scenarios also contain inter-scan anatomical variations including tumor shrinkage and tumor position change. Main results. STINR shows consistently higher image reconstruction and motion tracking accuracy than a traditional PCA-based method and a polynomial-fitting-based neural representation method. STINR tracks the lung target to an average center-of-mass error of 1–2 mm, with corresponding relative errors of reconstructed dynamic CBCTs around 10\%. Significance. STINR offers a general framework allowing accurate dynamic CBCT reconstruction for image-guided radiotherapy. It is a one-shot learning method that does not rely on pre-training and is not susceptible to generalizability issues. It also allows natural super-resolution. It can be readily applied to other imaging modalities as well.},
	language = {en},
	number = {4},
	urldate = {2023-03-29},
	journal = {Physics in Medicine \& Biology},
	author = {Zhang, You and Shao, Hua-Chieh and Pan, Tinsu and Mengke, Tielige},
	month = feb,
	year = {2023},
	note = {Publisher: IOP Publishing},
	pages = {045005},
	file = {Versión enviada:C\:\\Users\\Tabita\\Zotero\\storage\\UTMNT6J3\\Zhang et al. - 2023 - Dynamic cone-beam CT reconstruction using spatial .pdf:application/pdf},
}

@misc{jeong_time-series_2022,
	title = {Time-{Series} {Anomaly} {Detection} with {Implicit} {Neural} {Representation}},
	url = {http://arxiv.org/abs/2201.11950},
	abstract = {Detecting anomalies in multivariate time-series data is essential in many real-world applications. Recently, various deep learning-based approaches have shown considerable improvements in time-series anomaly detection. However, existing methods still have several limitations, such as long training time due to their complex model designs or costly tuning procedures to find optimal hyperparameters (e.g., sliding window length) for a given dataset. In our paper, we propose a novel method called Implicit Neural Representation-based Anomaly Detection (INRAD). Specifically, we train a simple multi-layer perceptron that takes time as input and outputs corresponding values at that time. Then we utilize the representation error as an anomaly score for detecting anomalies. Experiments on five real-world datasets demonstrate that our proposed method outperforms other state-of-the-art methods in performance, training speed, and robustness.},
	urldate = {2023-03-29},
	publisher = {arXiv},
	author = {Jeong, Kyeong-Joong and Shin, Yong-Min},
	month = jan,
	year = {2022},
	note = {arXiv:2201.11950 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\34FP2YW3\\Jeong y Shin - 2022 - Time-Series Anomaly Detection with Implicit Neural.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\3FJULAA9\\2201.html:text/html},
}

@inproceedings{mai_motion-adjustable_2022,
	title = {Motion-{Adjustable} {Neural} {Implicit} {Video} {Representation}},
	url = {https://openaccess.thecvf.com/content/CVPR2022/html/Mai_Motion-Adjustable_Neural_Implicit_Video_Representation_CVPR_2022_paper.html},
	language = {en},
	urldate = {2023-03-29},
	author = {Mai, Long and Liu, Feng},
	year = {2022},
	pages = {10738--10747},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\RINYCM76\\Mai y Liu - 2022 - Motion-Adjustable Neural Implicit Video Representa.pdf:application/pdf},
}

@misc{feng_spatiotemporal_2023,
	title = {Spatiotemporal implicit neural representation for unsupervised dynamic {MRI} reconstruction},
	url = {http://arxiv.org/abs/2301.00127},
	doi = {10.48550/arXiv.2301.00127},
	abstract = {Supervised Deep-Learning (DL)-based reconstruction algorithms have shown state-of-the-art results for highly-undersampled dynamic Magnetic Resonance Imaging (MRI) reconstruction. However, the requirement of excessive high-quality ground-truth data hinders their applications due to the generalization problem. Recently, Implicit Neural Representation (INR) has appeared as a powerful DL-based tool for solving the inverse problem by characterizing the attributes of a signal as a continuous function of corresponding coordinates in an unsupervised manner. In this work, we proposed an INR-based method to improve dynamic MRI reconstruction from highly undersampled k-space data, which only takes spatiotemporal coordinates as inputs. Specifically, the proposed INR represents the dynamic MRI images as an implicit function and encodes them into neural networks. The weights of the network are learned from sparsely-acquired (k, t)-space data itself only, without external training datasets or prior images. Benefiting from the strong implicit continuity regularization of INR together with explicit regularization for low-rankness and sparsity, our proposed method outperforms the compared scan-specific methods at various acceleration factors. E.g., experiments on retrospective cardiac cine datasets show an improvement of 5.5 {\textasciitilde} 7.1 dB in PSNR for extremely high accelerations (up to 41.6-fold). The high-quality and inner continuity of the images provided by INR has great potential to further improve the spatiotemporal resolution of dynamic MRI, without the need of any training data.},
	urldate = {2023-03-29},
	publisher = {arXiv},
	author = {Feng, Jie and Feng, Ruimin and Wu, Qing and Zhang, Zhiyong and Zhang, Yuyao and Wei, Hongjiang},
	month = jan,
	year = {2023},
	note = {arXiv:2301.00127 [physics]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Physics - Medical Physics},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\6DCLUVJK\\Feng et al. - 2023 - Spatiotemporal implicit neural representation for .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\DWZCB482\\2301.html:text/html},
}

@inproceedings{li_e-nerv_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {E-{NeRV}: {Expedite} {Neural} {Video} {Representation} with {Disentangled} {Spatial}-{Temporal} {Context}},
	isbn = {978-3-031-19833-5},
	shorttitle = {E-{NeRV}},
	doi = {10.1007/978-3-031-19833-5_16},
	abstract = {Recently, the image-wise implicit neural representation of videos, NeRV, has gained popularity for its promising results and swift speed compared to regular pixel-wise implicit representations. However, the redundant parameters within the network structure can cause a large model size when scaling up for desirable performance. The key reason of this phenomenon is the coupled formulation of NeRV, which outputs the spatial and temporal information of video frames directly from the frame index input. In this paper, we propose E-NeRV, which dramatically expedites NeRV by decomposing the image-wise implicit neural representation into separate spatial and temporal context. Under the guidance of this new formulation, our model greatly reduces the redundant model parameters, while retaining the representation ability. We experimentally find that our method can improve the performance to a large extent with fewer parameters, resulting in a more than \$\$8{\textbackslash}times \$\$8×faster speed on convergence. Code is available at https://github.com/kyleleey/E-NeRV.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2022},
	publisher = {Springer Nature Switzerland},
	author = {Li, Zizhang and Wang, Mengmeng and Pi, Huaijin and Xu, Kechun and Mei, Jianbiao and Liu, Yong},
	editor = {Avidan, Shai and Brostow, Gabriel and Cissé, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
	year = {2022},
	keywords = {Implicit representation, Neural video representation, Spatial-temporal disentanglement},
	pages = {267--284},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\LF4NNV3R\\Li et al. - 2022 - E-NeRV Expedite Neural Video Representation with .pdf:application/pdf},
}

@misc{fons_hypertime_2022,
	title = {{HyperTime}: {Implicit} {Neural} {Representation} for {Time} {Series}},
	shorttitle = {{HyperTime}},
	url = {http://arxiv.org/abs/2208.05836},
	doi = {10.48550/arXiv.2208.05836},
	abstract = {Implicit neural representations (INRs) have recently emerged as a powerful tool that provides an accurate and resolution-independent encoding of data. Their robustness as general approximators has been shown in a wide variety of data sources, with applications on image, sound, and 3D scene representation. However, little attention has been given to leveraging these architectures for the representation and analysis of time series data. In this paper, we analyze the representation of time series using INRs, comparing different activation functions in terms of reconstruction accuracy and training convergence speed. We show how these networks can be leveraged for the imputation of time series, with applications on both univariate and multivariate data. Finally, we propose a hypernetwork architecture that leverages INRs to learn a compressed latent representation of an entire time series dataset. We introduce an FFT-based loss to guide training so that all frequencies are preserved in the time series. We show that this network can be used to encode time series as INRs, and their embeddings can be interpolated to generate new time series from existing ones. We evaluate our generative method by using it for data augmentation, and show that it is competitive against current state-of-the-art approaches for augmentation of time series.},
	urldate = {2023-03-29},
	publisher = {arXiv},
	author = {Fons, Elizabeth and Sztrajman, Alejandro and El-laham, Yousef and Iosifidis, Alexandros and Vyetrenko, Svitlana},
	month = aug,
	year = {2022},
	note = {arXiv:2208.05836 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\9PVGVZCX\\Fons et al. - 2022 - HyperTime Implicit Neural Representation for Time.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\CCKIAXIS\\2208.html:text/html},
}

@inproceedings{chen_nerv_2021,
	title = {{NeRV}: {Neural} {Representations} for {Videos}},
	volume = {34},
	shorttitle = {{NeRV}},
	url = {https://proceedings.neurips.cc/paper/2021/hash/b44182379bf9fae976e6ae5996e13cd8-Abstract.html},
	urldate = {2023-03-29},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Chen, Hao and He, Bo and Wang, Hanyu and Ren, Yixuan and Lim, Ser Nam and Shrivastava, Abhinav},
	year = {2021},
	pages = {21557--21568},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\W58X4LRN\\Chen et al. - 2021 - NeRV Neural Representations for Videos.pdf:application/pdf},
}

@misc{lindell_bacon_2022-1,
	title = {{BACON}: {Band}-limited {Coordinate} {Networks} for {Multiscale} {Scene} {Representation}},
	shorttitle = {{BACON}},
	url = {http://arxiv.org/abs/2112.04645},
	abstract = {Coordinate-based networks have emerged as a powerful tool for 3D representation and scene reconstruction. These networks are trained to map continuous input coordinates to the value of a signal at each point. Still, current architectures are black boxes: their spectral characteristics cannot be easily analyzed, and their behavior at unsupervised points is difficult to predict. Moreover, these networks are typically trained to represent a signal at a single scale, so naive downsampling or upsampling results in artifacts. We introduce band-limited coordinate networks (BACON), a network architecture with an analytical Fourier spectrum. BACON has constrained behavior at unsupervised points, can be designed based on the spectral characteristics of the represented signal, and can represent signals at multiple scales without per-scale supervision. We demonstrate BACON for multiscale neural representation of images, radiance fields, and 3D scenes using signed distance functions and show that it outperforms conventional single-scale coordinate networks in terms of interpretability and quality.},
	urldate = {2023-04-18},
	publisher = {arXiv},
	author = {Lindell, David B. and Van Veen, Dave and Park, Jeong Joon and Wetzstein, Gordon},
	month = mar,
	year = {2022},
	note = {arXiv:2112.04645 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Graphics},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\LSCADD22\\Lindell et al. - 2022 - BACON Band-limited Coordinate Networks for Multis.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\WAQSY8YK\\2112.html:text/html},
}

@misc{yoo_time-dependent_2021-1,
	title = {Time-{Dependent} {Deep} {Image} {Prior} for {Dynamic} {MRI}},
	url = {http://arxiv.org/abs/1910.01684},
	abstract = {We propose a novel unsupervised deep-learning-based algorithm for dynamic magnetic resonance imaging (MRI) reconstruction. Dynamic MRI requires rapid data acquisition for the study of moving organs such as the heart. Existing reconstruction methods suffer from restrictions either in the model design or in the absence of ground-truth data, resulting in low image quality. We introduce a generalized version of the deep-image-prior approach, which optimizes the network weights to fit a sequence of sparsely acquired dynamic MRI measurements. Our method needs neither prior training nor additional data. In particular, for cardiac images, it does not require the marking of heartbeats or the reordering of spokes. The key ingredients of our method are threefold: 1) a fixed low-dimensional manifold that encodes the temporal variations of images; 2) a network that maps the manifold into a more expressive latent space; and 3) a convolutional neural network that generates a dynamic series of MRI images from the latent variables and that favors their consistency with the measurements in k-space. Our method outperforms the state-of-the-art methods quantitatively and qualitatively in both retrospective and real fetal cardiac datasets. To the best of our knowledge, this is the first unsupervised deep-learning-based method that can reconstruct the continuous variation of dynamic MRI sequences with high spatial resolution.},
	urldate = {2023-04-18},
	publisher = {arXiv},
	author = {Yoo, Jaejun and Jin, Kyong Hwan and Gupta, Harshit and Yerly, Jerome and Stuber, Matthias and Unser, Michael},
	month = jan,
	year = {2021},
	note = {arXiv:1910.01684 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\C5IV2Q2X\\Yoo et al. - 2021 - Time-Dependent Deep Image Prior for Dynamic MRI.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\RGYYJZY2\\1910.html:text/html},
}

@article{hammernik_physics-driven_2023,
	title = {Physics-{Driven} {Deep} {Learning} for {Computational} {Magnetic} {Resonance} {Imaging}: {Combining} physics and machine learning for improved medical imaging},
	volume = {40},
	issn = {1558-0792},
	shorttitle = {Physics-{Driven} {Deep} {Learning} for {Computational} {Magnetic} {Resonance} {Imaging}},
	url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10004819},
	doi = {10.1109/MSP.2022.3215288},
	abstract = {Physics-driven deep learning methods have emerged as a powerful tool for computational magnetic resonance imaging (MRI) problems, pushing reconstruction performance to new limits. This article provides an overview of the recent developments in incorporating physics information into learning-based MRI reconstruction. We consider inverse problems with both linear and nonlinear forward models for computational MRI and review the classical approaches for solving these. We then focus on physics-driven deep learning approaches, covering physics-driven loss functions, plug-and-play (PnP) methods, generative models, and unrolled networks. We highlight domain-specific challenges, such as real- and complex-valued building blocks of neural networks, and translational applications in MRI with linear and nonlinear forward models. Finally, we discuss common issues and open challenges, and we draw connections to the importance of physics-driven learning when combined with other downstream tasks in the medical imaging pipeline.},
	number = {1},
	journal = {IEEE Signal Processing Magazine},
	author = {Hammernik, Kerstin and Küstner, Thomas and Yaman, Burhaneddin and Huang, Zhengnan and Rueckert, Daniel and Knoll, Florian and Akçakaya, Mehmet},
	month = jan,
	year = {2023},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Signal processing, Magnetic resonance imaging, Deep learning, Computational modeling, Inverse problems, Pipelines, Task analysis},
	pages = {98--114},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\ZMRYYBQ7\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\FPKTWZ69\\Hammernik et al. - 2023 - Physics-Driven Deep Learning for Computational Mag.pdf:application/pdf},
}

@misc{catalan_highly_2022,
	title = {Highly accelerated {Cardiac} {CINE} {MRI} using {Neural} {Fields}},
	abstract = {Neural fields cardiac MRI (NF-cMRI), a method for highly accelerated CINE reconstruction using deep learning, is proposed. NF-cMRI relies on an intensity network, based on neural fields with Fourier features to encode a continuous reconstruction. The network is trained with one undersampled radial k-space data set without the need of a fully-sampled reference image. Good image quality of the heart is achieved with 8 radial spokes/cardiac frame. Results are compared against GRASP. Future work will focus on reducing reconstruction time and evaluating the proposed approach in prospectively undersampled k-space data.},
	author = {Catalán, Tabita and Courdurier, Matías and Osses, Axel and Botnar, René and Sahli Costábal, Francisco and Prieto, Claudia},
	month = nov,
	year = {2022},
}

@inproceedings{lee_systematic_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Systematic} {Study} of {Race} and {Sex} {Bias} in {CNN}-{Based} {Cardiac} {MR} {Segmentation}},
	isbn = {978-3-031-23443-9},
	doi = {10.1007/978-3-031-23443-9_22},
	abstract = {In computer vision there has been significant research interest in assessing potential demographic bias in deep learning models. One of the main causes of such bias is imbalance in the training data. In medical imaging, where the potential impact of bias is arguably much greater, there has been less interest. In medical imaging pipelines, segmentation of structures of interest plays an important role in estimating clinical biomarkers that are subsequently used to inform patient management. Convolutional neural networks (CNNs) are starting to be used to automate this process. We present the first systematic study of the impact of training set imbalance on race and sex bias in CNN-based segmentation. We focus on segmentation of the structures of the heart from short axis cine cardiac magnetic resonance images, and train multiple CNN segmentation models with different levels of race/sex imbalance. We find no significant bias in the sex experiment but significant bias in two separate race experiments, highlighting the need to consider adequate representation of different demographic groups in health datasets.},
	language = {en},
	booktitle = {Statistical {Atlases} and {Computational} {Models} of the {Heart}. {Regular} and {CMRxMotion} {Challenge} {Papers}},
	publisher = {Springer Nature Switzerland},
	author = {Lee, Tiarna and Puyol-Antón, Esther and Ruijsink, Bram and Shi, Miaojing and King, Andrew P.},
	editor = {Camara, Oscar and Puyol-Antón, Esther and Qin, Chen and Sermesant, Maxime and Suinesiaputra, Avan and Wang, Shuo and Young, Alistair},
	year = {2022},
	keywords = {Cardiac MRI, CNN, Fairness, Segmentation},
	pages = {233--244},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\SXIFSZMG\\Lee et al. - 2022 - A Systematic Study of Race and Sex Bias in CNN-Bas.pdf:application/pdf},
}

@article{korkmaz_unsupervised_2022,
	title = {Unsupervised {MRI} {Reconstruction} via {Zero}-{Shot} {Learned} {Adversarial} {Transformers}},
	volume = {41},
	issn = {1558-254X},
	doi = {10.1109/TMI.2022.3147426},
	abstract = {Supervised reconstruction models are characteristically trained on matched pairs of undersampled and fully-sampled data to capture an MRI prior, along with supervision regarding the imaging operator to enforce data consistency. To reduce supervision requirements, the recent deep image prior framework instead conjoins untrained MRI priors with the imaging operator during inference. Yet, canonical convolutional architectures are suboptimal in capturing long-range relationships, and priors based on randomly initialized networks may yield suboptimal performance. To address these limitations, here we introduce a novel unsupervised MRI reconstruction method based on zero-Shot Learned Adversarial TransformERs (SLATER). SLATER embodies a deep adversarial network with cross-attention transformers to map noise and latent variables onto coil-combined MR images. During pre-training, this unconditional network learns a high-quality MRI prior in an unsupervised generative modeling task. During inference, a zero-shot reconstruction is then performed by incorporating the imaging operator and optimizing the prior to maximize consistency to undersampled data. Comprehensive experiments on brain MRI datasets clearly demonstrate the superior performance of SLATER against state-of-the-art unsupervised methods.},
	number = {7},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Korkmaz, Yilmaz and Dar, Salman U. H. and Yurt, Mahmut and Özbey, Muzaffer and Çukur, Tolga},
	month = jul,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Image reconstruction, Magnetic resonance imaging, Training, Data models, MRI, Task analysis, Adaptation models, Adversarial, generative, reconstruction, transformers, Transformers, unsupervised, zero shot},
	pages = {1747--1763},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\UCKP79AP\\Korkmaz et al. - 2022 - Unsupervised MRI Reconstruction via Zero-Shot Lear.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\GCIBN6WW\\getPDF.html:text/html},
}

@article{ke_unsupervised_2020,
	title = {An unsupervised deep learning method for multi-coil cine {MRI}},
	volume = {65},
	issn = {0031-9155},
	url = {https://dx.doi.org/10.1088/1361-6560/abaffa},
	doi = {10.1088/1361-6560/abaffa},
	abstract = {Deep learning has achieved good success in cardiac magnetic resonance imaging (MRI) reconstruction, in which convolutional neural networks (CNNs) learn a mapping from the undersampled k-space to the fully sampled images. Although these deep learning methods can improve the reconstruction quality compared with iterative methods without requiring complex parameter selection or lengthy reconstruction time, the following issues still need to be addressed: 1) all these methods are based on big data and require a large amount of fully sampled MRI data, which is always difficult to obtain for cardiac MRI; 2) the effect of coil correlation on reconstruction in deep learning methods for dynamic MR imaging has never been studied. In this paper, we propose an unsupervised deep learning method for multi-coil cine MRI via a time-interleaved sampling strategy. Specifically, a time-interleaved acquisition scheme is utilized to build a set of fully encoded reference data by directly merging the k-space data of adjacent time frames. Then these fully encoded data can be used to train a parallel network for reconstructing images of each coil separately. Finally, the images from each coil are combined via a CNN to implicitly explore the correlations between coils. The comparisons with classic k-t FOCUSS, k-t SLR, L+S and KLR methods on in vivo datasets show that our method can achieve improved reconstruction results in an extremely short amount of time.},
	language = {en},
	number = {23},
	urldate = {2023-04-24},
	journal = {Physics in Medicine \& Biology},
	author = {Ke, Ziwen and Cheng, Jing and Ying, Leslie and Zheng, Hairong and Zhu, Yanjie and Liang, Dong},
	month = nov,
	year = {2020},
	note = {Publisher: IOP Publishing},
	pages = {235041},
	file = {IOP Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\4QQUHIXP\\Ke et al. - 2020 - An unsupervised deep learning method for multi-coi.pdf:application/pdf},
}

@article{akcakaya_scan-specific_2019,
	title = {Scan-specific robust artificial-neural-networks for k-space interpolation ({RAKI}) reconstruction: {Database}-free deep learning for fast imaging},
	volume = {81},
	issn = {1522-2594},
	shorttitle = {Scan-specific robust artificial-neural-networks for k-space interpolation ({RAKI}) reconstruction},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.27420},
	doi = {10.1002/mrm.27420},
	abstract = {Purpose To develop an improved k-space reconstruction method using scan-specific deep learning that is trained on autocalibration signal (ACS) data. Theory Robust artificial-neural-networks for k-space interpolation (RAKI) reconstruction trains convolutional neural networks on ACS data. This enables nonlinear estimation of missing k-space lines from acquired k-space data with improved noise resilience, as opposed to conventional linear k-space interpolation-based methods, such as GRAPPA, which are based on linear convolutional kernels. Methods The training algorithm is implemented using a mean square error loss function over the target points in the ACS region, using a gradient descent algorithm. The neural network contains 3 layers of convolutional operators, with 2 of these including nonlinear activation functions. The noise performance and reconstruction quality of the RAKI method was compared with GRAPPA in phantom, as well as in neurological and cardiac in vivo data sets. Results Phantom imaging shows that the proposed RAKI method outperforms GRAPPA at high (≥4) acceleration rates, both visually and quantitatively. Quantitative cardiac imaging shows improved noise resilience at high acceleration rates (rate 4:23\% and rate 5:48\%) over GRAPPA. The same trend of improved noise resilience is also observed in high-resolution brain imaging at high acceleration rates. Conclusion The RAKI method offers a training database-free deep learning approach for MRI reconstruction, with the potential to improve many existing reconstruction approaches, and is compatible with conventional data acquisition protocols.},
	language = {en},
	number = {1},
	urldate = {2023-04-25},
	journal = {Magnetic Resonance in Medicine},
	author = {Akçakaya, Mehmet and Moeller, Steen and Weingärtner, Sebastian and Uğurbil, Kâmil},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.27420},
	keywords = {image reconstruction, parallel imaging, deep learning, accelerated imaging, convolutional neural networks, k-space interpolation, nonlinear estimation},
	pages = {439--453},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\HZS6PX4W\\Akçakaya et al. - 2019 - Scan-specific robust artificial-neural-networks fo.pdf:application/pdf;Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\U5EW6URV\\mrm.html:text/html},
}

@article{hammernik_systematic_2021,
	title = {Systematic evaluation of iterative deep neural networks for fast parallel {MRI} reconstruction with sensitivity-weighted coil combination},
	volume = {86},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.28827},
	doi = {10.1002/mrm.28827},
	abstract = {Purpose To systematically investigate the influence of various data consistency layers and regularization networks with respect to variations in the training and test data domain, for sensitivity-encoded accelerated parallel MR image reconstruction. Theory and Methods Magnetic resonance (MR) image reconstruction is formulated as a learned unrolled optimization scheme with a down-up network as regularization and varying data consistency layers. The proposed networks are compared to other state-of-the-art approaches on the publicly available fastMRI knee and neuro dataset and tested for stability across different training configurations regarding anatomy and number of training samples. Results Data consistency layers and expressive regularization networks, such as the proposed down-up networks, form the cornerstone for robust MR image reconstruction. Physics-based reconstruction networks outperform post-processing methods substantially for R = 4 in all cases and for R = 8 when the training and test data are aligned. At R = 8, aligning training and test data is more important than architectural choices. Conclusion In this work, we study how dataset sizes affect single-anatomy and cross-anatomy training of neural networks for MRI reconstruction. The study provides insights into the robustness, properties, and acceleration limits of state-of-the-art networks, and our proposed down-up networks. These key insights provide essential aspects to successfully translate learning-based MRI reconstruction to clinical practice, where we are confronted with limited datasets and various imaged anatomies.},
	language = {en},
	number = {4},
	urldate = {2023-04-25},
	journal = {Magnetic Resonance in Medicine},
	author = {Hammernik, Kerstin and Schlemper, Jo and Qin, Chen and Duan, Jinming and Summers, Ronald M. and Rueckert, Daniel},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.28827},
	keywords = {parallel imaging, deep learning, data consistency, domain shift, down-up networks, fastMRI, iterative image reconstruction},
	pages = {1859--1872},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\344ESNVH\\Hammernik et al. - 2021 - Systematic evaluation of iterative deep neural net.pdf:application/pdf;Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\A6Z9WF5H\\mrm.html:text/html},
}

@article{ahmed_dynamic_2022,
	title = {Dynamic {Imaging} {Using} {Deep} {Bi}-{Linear} {Unsupervised} {Representation} ({DEBLUR})},
	volume = {41},
	issn = {1558-254X},
	doi = {10.1109/TMI.2022.3168559},
	abstract = {Bilinear models such as low-rank and dictionary methods, which decompose dynamic data to spatial and temporal factor matrices are powerful and memory-efficient tools for the recovery of dynamic MRI data. Current bilinear methods rely on sparsity and energy compaction priors on the factor matrices to regularize the recovery. Motivated by deep image prior, we introduce a novel bilinear model, whose factor matrices are generated using convolutional neural networks (CNNs). The CNN parameters, and equivalently the factors, are learned from the undersampled data of the specific subject. Unlike current unrolled deep learning methods that require the storage of all the time frames in the dataset, the proposed approach only requires the storage of the factors or compressed representation; this approach allows the direct use of this scheme to large-scale dynamic applications, including free breathing cardiac MRI considered in this work. To reduce the run time and to improve performance, we initialize the CNN parameters using existing factor methods. We use sparsity regularization of the network parameters to minimize the overfitting of the network to measurement noise. Our experiments on free-breathing and ungated cardiac cine data acquired using a navigated golden-angle gradient-echo radial sequence show the ability of our method to provide reduced spatial blurring as compared to classical bilinear methods as well as a recent unsupervised deep-learning approach.},
	number = {10},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Ahmed, Abdul Haseeb and Zou, Qing and Nagpal, Prashant and Jacob, Mathews},
	month = oct,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {image reconstruction, Image reconstruction, Magnetic resonance imaging, Optimization, dynamic imaging, cardiac MRI, Bilinear model, Convolutional neural networks, Generators, Noise measurement, unsupervised learning, Urban areas},
	pages = {2693--2703},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\NUT9L5RL\\9759446.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\MCZHYA6D\\Ahmed et al. - 2022 - Dynamic Imaging Using Deep Bi-Linear Unsupervised .pdf:application/pdf},
}

@misc{cole_unsupervised_2020,
	title = {Unsupervised {MRI} {Reconstruction} with {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/2008.13065},
	doi = {10.48550/arXiv.2008.13065},
	abstract = {Deep learning-based image reconstruction methods have achieved promising results across multiple MRI applications. However, most approaches require large-scale fully-sampled ground truth data for supervised training. Acquiring fully-sampled data is often either difficult or impossible, particularly for dynamic contrast enhancement (DCE), 3D cardiac cine, and 4D flow. We present a deep learning framework for MRI reconstruction without any fully-sampled data using generative adversarial networks. We test the proposed method in two scenarios: retrospectively undersampled fast spin echo knee exams and prospectively undersampled abdominal DCE. The method recovers more anatomical structure compared to conventional methods.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Cole, Elizabeth K. and Pauly, John M. and Vasanawala, Shreyas S. and Ong, Frank},
	month = aug,
	year = {2020},
	note = {arXiv:2008.13065 [cs, eess, stat]},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\DGFELJD5\\Cole et al. - 2020 - Unsupervised MRI Reconstruction with Generative Ad.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\AFMSAPER\\2008.html:text/html},
}

@article{korkmaz_unsupervised_2022-1,
	title = {Unsupervised {MRI} {Reconstruction} via {Zero}-{Shot} {Learned} {Adversarial} {Transformers}},
	volume = {41},
	issn = {1558-254X},
	doi = {10.1109/TMI.2022.3147426},
	abstract = {Supervised reconstruction models are characteristically trained on matched pairs of undersampled and fully-sampled data to capture an MRI prior, along with supervision regarding the imaging operator to enforce data consistency. To reduce supervision requirements, the recent deep image prior framework instead conjoins untrained MRI priors with the imaging operator during inference. Yet, canonical convolutional architectures are suboptimal in capturing long-range relationships, and priors based on randomly initialized networks may yield suboptimal performance. To address these limitations, here we introduce a novel unsupervised MRI reconstruction method based on zero-Shot Learned Adversarial TransformERs (SLATER). SLATER embodies a deep adversarial network with cross-attention transformers to map noise and latent variables onto coil-combined MR images. During pre-training, this unconditional network learns a high-quality MRI prior in an unsupervised generative modeling task. During inference, a zero-shot reconstruction is then performed by incorporating the imaging operator and optimizing the prior to maximize consistency to undersampled data. Comprehensive experiments on brain MRI datasets clearly demonstrate the superior performance of SLATER against state-of-the-art unsupervised methods.},
	number = {7},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Korkmaz, Yilmaz and Dar, Salman U. H. and Yurt, Mahmut and Özbey, Muzaffer and Çukur, Tolga},
	month = jul,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Image reconstruction, Magnetic resonance imaging, Training, Data models, MRI, Task analysis, Adaptation models, Adversarial, generative, reconstruction, transformers, Transformers, unsupervised, zero shot},
	pages = {1747--1763},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\XWPWGU97\\9695412.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\KLWAPLDQ\\Korkmaz et al. - 2022 - Unsupervised MRI Reconstruction via Zero-Shot Lear.pdf:application/pdf},
}

@inproceedings{cole_fast_2021,
	title = {Fast {Unsupervised} {MRI} {Reconstruction} {Without} {Fully}-{Sampled} {Ground} {Truth} {Data} {Using} {Generative} {Adversarial} {Networks}},
	url = {https://openaccess.thecvf.com/content/ICCV2021W/LCI/html/Cole_Fast_Unsupervised_MRI_Reconstruction_Without_Fully-Sampled_Ground_Truth_Data_Using_ICCVW_2021_paper.html},
	language = {en},
	urldate = {2023-04-26},
	author = {Cole, Elizabeth K. and Ong, Frank and Vasanawala, Shreyas S. and Pauly, John M.},
	year = {2021},
	pages = {3988--3997},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\JAKWVKYQ\\Cole et al. - 2021 - Fast Unsupervised MRI Reconstruction Without Fully.pdf:application/pdf},
}

@misc{tamir_unsupervised_2020,
	title = {Unsupervised {Deep} {Basis} {Pursuit}: {Learning} inverse problems without ground-truth data},
	shorttitle = {Unsupervised {Deep} {Basis} {Pursuit}},
	url = {http://arxiv.org/abs/1910.13110},
	doi = {10.48550/arXiv.1910.13110},
	abstract = {Basis pursuit is a compressed sensing optimization in which the l1-norm is minimized subject to model error constraints. Here we use a deep neural network prior instead of l1-regularization. Using known noise statistics, we jointly learn the prior and reconstruct images without access to ground-truth data. During training, we use alternating minimization across an unrolled iterative network and jointly solve for the neural network weights and training set image reconstructions. At inference, we fix the weights and pass the measurements through the network. We compare reconstruction performance between unsupervised and supervised (i.e. with ground-truth) methods. We hypothesize this technique could be used to learn reconstruction when ground-truth data are unavailable, such as in high-resolution dynamic MRI.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Tamir, Jonathan I. and Yu, Stella X. and Lustig, Michael},
	month = feb,
	year = {2020},
	note = {arXiv:1910.13110 [eess]},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Signal Processing},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\YSM7QJ96\\Tamir et al. - 2020 - Unsupervised Deep Basis Pursuit Learning inverse .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\G36KQGQT\\1910.html:text/html},
}

@article{ke_unsupervised_2020-1,
	title = {An unsupervised deep learning method for multi-coil cine {MRI}},
	volume = {65},
	issn = {0031-9155},
	url = {https://dx.doi.org/10.1088/1361-6560/abaffa},
	doi = {10.1088/1361-6560/abaffa},
	abstract = {Deep learning has achieved good success in cardiac magnetic resonance imaging (MRI) reconstruction, in which convolutional neural networks (CNNs) learn a mapping from the undersampled k-space to the fully sampled images. Although these deep learning methods can improve the reconstruction quality compared with iterative methods without requiring complex parameter selection or lengthy reconstruction time, the following issues still need to be addressed: 1) all these methods are based on big data and require a large amount of fully sampled MRI data, which is always difficult to obtain for cardiac MRI; 2) the effect of coil correlation on reconstruction in deep learning methods for dynamic MR imaging has never been studied. In this paper, we propose an unsupervised deep learning method for multi-coil cine MRI via a time-interleaved sampling strategy. Specifically, a time-interleaved acquisition scheme is utilized to build a set of fully encoded reference data by directly merging the k-space data of adjacent time frames. Then these fully encoded data can be used to train a parallel network for reconstructing images of each coil separately. Finally, the images from each coil are combined via a CNN to implicitly explore the correlations between coils. The comparisons with classic k-t FOCUSS, k-t SLR, L+S and KLR methods on in vivo datasets show that our method can achieve improved reconstruction results in an extremely short amount of time.},
	language = {en},
	number = {23},
	urldate = {2023-04-26},
	journal = {Physics in Medicine \& Biology},
	author = {Ke, Ziwen and Cheng, Jing and Ying, Leslie and Zheng, Hairong and Zhu, Yanjie and Liang, Dong},
	month = nov,
	year = {2020},
	note = {Publisher: IOP Publishing},
	pages = {235041},
	file = {IOP Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\IL7BMUC2\\Ke et al. - 2020 - An unsupervised deep learning method for multi-coi.pdf:application/pdf},
}

@inproceedings{korkmaz_deep_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Deep {MRI} {Reconstruction} with {Generative} {Vision} {Transformers}},
	isbn = {978-3-030-88552-6},
	doi = {10.1007/978-3-030-88552-6_6},
	abstract = {Supervised training of deep network models for MRI reconstruction requires access to large databases of fully-sampled MRI acquisitions. To alleviate dependency on costly databases, unsupervised learning strategies have received interest. A powerful framework that eliminates the need for training data altogether is the deep image prior (DIP). To do this, DIP inverts randomly-initialized models to infer network parameters most consistent with the undersampled test data. However, existing DIP methods leverage convolutional backbones, suffering from limited sensitivity to long-range spatial dependencies and thereby poor model invertibility. To address these limitations, here we propose an unsupervised MRI reconstruction based on a novel generative vision transformer (GVTrans). GVTrans progressively maps low-dimensional noise and latent variables onto MR images via cascaded blocks of cross-attention vision transformers. Cross-attention mechanism between latents and image features serve to enhance representational learning of local and global context. Meanwhile, latent and noise injections at each network layer permit fine control of generated image features, improving model invertibility. Demonstrations are performed for scan-specific reconstruction of brain MRI data at multiple contrasts and acceleration factors. GVTrans yields superior performance to state-of-the-art generative models based on convolutional neural networks (CNNs).},
	language = {en},
	booktitle = {Machine {Learning} for {Medical} {Image} {Reconstruction}},
	publisher = {Springer International Publishing},
	author = {Korkmaz, Yilmaz and Yurt, Mahmut and Dar, Salman Ul Hassan and Özbey, Muzaffer and Cukur, Tolga},
	editor = {Haq, Nandinee and Johnson, Patricia and Maier, Andreas and Würfl, Tobias and Yoo, Jaejun},
	year = {2021},
	keywords = {Attention, Generative, MRI reconstruction, Transformer, Unsupervised},
	pages = {54--64},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\YFPRMBQ2\\Korkmaz et al. - 2021 - Deep MRI Reconstruction with Generative Vision Tra.pdf:application/pdf},
}

@misc{feng_spatiotemporal_2023-1,
	title = {Spatiotemporal implicit neural representation for unsupervised dynamic {MRI} reconstruction},
	url = {http://arxiv.org/abs/2301.00127},
	doi = {10.48550/arXiv.2301.00127},
	abstract = {Supervised Deep-Learning (DL)-based reconstruction algorithms have shown state-of-the-art results for highly-undersampled dynamic Magnetic Resonance Imaging (MRI) reconstruction. However, the requirement of excessive high-quality ground-truth data hinders their applications due to the generalization problem. Recently, Implicit Neural Representation (INR) has appeared as a powerful DL-based tool for solving the inverse problem by characterizing the attributes of a signal as a continuous function of corresponding coordinates in an unsupervised manner. In this work, we proposed an INR-based method to improve dynamic MRI reconstruction from highly undersampled k-space data, which only takes spatiotemporal coordinates as inputs. Specifically, the proposed INR represents the dynamic MRI images as an implicit function and encodes them into neural networks. The weights of the network are learned from sparsely-acquired (k, t)-space data itself only, without external training datasets or prior images. Benefiting from the strong implicit continuity regularization of INR together with explicit regularization for low-rankness and sparsity, our proposed method outperforms the compared scan-specific methods at various acceleration factors. E.g., experiments on retrospective cardiac cine datasets show an improvement of 5.5 {\textasciitilde} 7.1 dB in PSNR for extremely high accelerations (up to 41.6-fold). The high-quality and inner continuity of the images provided by INR has great potential to further improve the spatiotemporal resolution of dynamic MRI, without the need of any training data.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Feng, Jie and Feng, Ruimin and Wu, Qing and Zhang, Zhiyong and Zhang, Yuyao and Wei, Hongjiang},
	month = jan,
	year = {2023},
	note = {arXiv:2301.00127 [physics]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Physics - Medical Physics},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\8BXJFIDX\\Feng et al. - 2023 - Spatiotemporal implicit neural representation for .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\PLKBIZNV\\2301.html:text/html},
}

@misc{huang_unsupervised_2022,
	title = {Unsupervised {Deep} {Unrolled} {Reconstruction} {Using} {Regularization} by {Denoising}},
	url = {http://arxiv.org/abs/2205.03519},
	doi = {10.48550/arXiv.2205.03519},
	abstract = {Deep learning methods have been successfully used in various computer vision tasks. Inspired by that success, deep learning has been explored in magnetic resonance imaging (MRI) reconstruction. In particular, integrating deep learning and model-based optimization methods has shown considerable advantages. However, a large amount of labeled training data is typically needed for high reconstruction quality, which is challenging for some MRI applications. In this paper, we propose a novel reconstruction method, named DURED-Net, that enables interpretable unsupervised learning for MR image reconstruction by combining an unsupervised denoising network and a plug-and-play method. We aim to boost the reconstruction performance of unsupervised learning by adding an explicit prior that utilizes imaging physics. Specifically, the leverage of a denoising network for MRI reconstruction is achieved using Regularization by Denoising (RED). Experiment results demonstrate that the proposed method requires a reduced amount of training data to achieve high reconstruction quality.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Huang, Peizhou and Zhang, Chaoyi and Zhang, Xiaoliang and Li, Xiaojuan and Dong, Liang and Ying, Leslie},
	month = sep,
	year = {2022},
	note = {arXiv:2205.03519 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\E59S4XXR\\Huang et al. - 2022 - Unsupervised Deep Unrolled Reconstruction Using Re.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\AYY4X6YF\\2205.html:text/html},
}

@article{wei_real-time_nodate,
	title = {Real-time {3D} {MRI} reconstruction from cine-{MRI} using unsupervised network in {MRI}-guided radiotherapy for liver cancer},
	volume = {n/a},
	issn = {2473-4209},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.16141},
	doi = {10.1002/mp.16141},
	abstract = {Purpose Respiration has a major impact on the accuracy of radiation treatment for thorax and abdominal tumours. Instantaneous volumetric imaging could provide precise knowledge of tumour and normal organs’ three-dimensional (3D) movement, which is the key to reducing the negative effect of breathing motion. Therefore, this study proposed a real-time 3D MRI reconstruction method from cine-MRI using an unsupervised network. Methods and materials Cine-MRI and setup 3D-MRI from eight patients with liver cancer were utilized to establish and validate the deep learning network for 3D-MRI reconstruction. Unlike previous methods that required 4D-MRI for network training, the proposed method utilized a reference 3D-MRI and cine-MRI to generate the training data. Then, a network was trained in an unsupervised manner to estimate the relationship between the cine-MRI acquired on coronal plane and deformation vector field (DVF) that describes the patient's breathing motion. After the training process, the coronal cine-MRI were inputted into the network, and the corresponding DVF was obtained. By wrapping the reference 3D-MRI with the generated DVF, the 3D-MRI could be reconstructed. Results The reconstructed 3D-MRI slices were compared with the corresponding phase-sorted cine-MRI using dice similarity coefficients (DSCs) of liver contours and blood vessel localization error. In all patients, the liver DSC had mean value {\textgreater}96.1\% and standard deviation {\textless} 1.3\%; the blood vessel localization error had mean value {\textless}2.6 mm, and standard deviation was {\textless}2.0 mm. Moreover, the time for 3D-MRI reconstruction was approximately 100 ms. These results indicated that the proposed method could accurately reconstruct the 3D-MRI in real time. Conclusions The proposed method could accurately reconstruct the 3D-MRI from cine-MRI in real time. This method has great potential in improving the accuracy of radiotherapy for moving tumours.},
	language = {en},
	number = {n/a},
	urldate = {2023-04-26},
	journal = {Medical Physics},
	author = {Wei, Ran and Chen, Jiayun and Liang, Bin and Chen, Xinyuan and Men, Kuo and Dai, Jianrong},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mp.16141},
	keywords = {unsupervised learning, 3D-MRI reconstruction, cine-MRI},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\M4W3D4KH\\Wei et al. - Real-time 3D MRI reconstruction from cine-MRI usin.pdf:application/pdf;Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\WT768LIQ\\mp.html:text/html},
}

@article{moreno_lopez_evaluation_2021,
	title = {Evaluation of {MRI} {Denoising} {Methods} {Using} {Unsupervised} {Learning}},
	volume = {4},
	issn = {2624-8212},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2021.642731},
	abstract = {In this paper we evaluate two unsupervised approaches to denoise Magnetic Resonance Images (MRI) in the complex image space using the raw information that k-space holds. The first method is based on Stein’s Unbiased Risk Estimator, while the second approach is based on a blindspot network, which limits the network’s receptive field. Both methods are tested on two different datasets, one containing real knee MRI and the other consists of synthetic brain MRI. These datasets contain information about the complex image space which will be used for denoising purposes. Both networks are compared against a state-of-the-art algorithm, Non-Local Means (NLM) using quantitative and qualitative measures. For most given metrics and qualitative measures, both networks outperformed NLM, and they prove to be reliable denoising methods.},
	urldate = {2023-04-26},
	journal = {Frontiers in Artificial Intelligence},
	author = {Moreno López, Marc and Frederick, Joshua M. and Ventura, Jonathan},
	year = {2021},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\AA67PT7M\\Moreno López et al. - 2021 - Evaluation of MRI Denoising Methods Using Unsuperv.pdf:application/pdf},
}

@misc{feng_scan-specific_2022,
	title = {A scan-specific unsupervised method for parallel {MRI} reconstruction via implicit neural representation},
	url = {http://arxiv.org/abs/2210.10439},
	doi = {10.48550/arXiv.2210.10439},
	abstract = {Parallel imaging is a widely-used technique to accelerate magnetic resonance imaging (MRI). However, current methods still perform poorly in reconstructing artifact-free MRI images from highly undersampled k-space data. Recently, implicit neural representation (INR) has emerged as a new deep learning paradigm for learning the internal continuity of an object. In this study, we adopted INR to parallel MRI reconstruction. The MRI image was modeled as a continuous function of spatial coordinates. This function was parameterized by a neural network and learned directly from the measured k-space itself without additional fully sampled high-quality training data. Benefitting from the powerful continuous representations provided by INR, the proposed method outperforms existing methods by suppressing the aliasing artifacts and noise, especially at higher acceleration rates and smaller sizes of the auto-calibration signals. The high-quality results and scanning specificity make the proposed method hold the potential for further accelerating the data acquisition of parallel MRI.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Feng, Ruimin and Wu, Qing and Zhang, Yuyao and Wei, Hongjiang},
	month = oct,
	year = {2022},
	note = {arXiv:2210.10439 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tabita\\Zotero\\storage\\FUAAMM6V\\Feng et al. - 2022 - A scan-specific unsupervised method for parallel M.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\HT7ENULJ\\2210.html:text/html},
}

@article{schlemper_deep_2018-1,
	title = {A {Deep} {Cascade} of {Convolutional} {Neural} {Networks} for {Dynamic} {MR} {Image} {Reconstruction}},
	volume = {37},
	issn = {1558-254X},
	doi = {10.1109/TMI.2017.2760978},
	abstract = {Inspired by recent advances in deep learning, we propose a framework for reconstructing dynamic sequences of 2-D cardiac magnetic resonance (MR) images from undersampled data using a deep cascade of convolutional neural networks (CNNs) to accelerate the data acquisition process. In particular, we address the case where data are acquired using aggressive Cartesian undersampling. First, we show that when each 2-D image frame is reconstructed independently, the proposed method outperforms state-of-the-art 2-D compressed sensing approaches, such as dictionary learning-based MR image reconstruction, in terms of reconstruction error and reconstruction speed. Second, when reconstructing the frames of the sequences jointly, we demonstrate that CNNs can learn spatio-temporal correlations efficiently by combining convolution and data sharing approaches. We show that the proposed method consistently outperforms state-of-the-art methods and is capable of preserving anatomical structure more faithfully up to 11-fold undersampling. Moreover, reconstruction is very fast: each complete dynamic sequence can be reconstructed in less than 10 s and, for the 2-D case, each image frame can be reconstructed in 23 ms, enabling real-time applications.},
	number = {2},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Schlemper, Jo and Caballero, Jose and Hajnal, Joseph V. and Price, Anthony N. and Rueckert, Daniel},
	month = feb,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {compressed sensing, image reconstruction, convolutional neural network, dynamic magnetic resonance imaging, Image reconstruction, Machine learning, Compressed sensing, Deep learning, Imaging, Neural networks, Redundancy, Two dimensional displays},
	pages = {491--503},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\MYD997P2\\Schlemper et al. - 2018 - A Deep Cascade of Convolutional Neural Networks fo.pdf:application/pdf},
}

@article{djebra_manifold_2023,
	title = {Manifold {Learning} via {Linear} {Tangent} {Space} {Alignment} ({LTSA}) for {Accelerated} {Dynamic} {MRI} {With} {Sparse} {Sampling}},
	volume = {42},
	issn = {1558-254X},
	doi = {10.1109/TMI.2022.3207774},
	abstract = {The spatial resolution and temporal frame-rate of dynamic magnetic resonance imaging (MRI) can be improved by reconstructing images from sparsely sampled k -space data with mathematical modeling of the underlying spatiotemporal signals. These models include sparsity models, linear subspace models, and non-linear manifold models. This work presents a novel linear tangent space alignment (LTSA) model-based framework that exploits the intrinsic low-dimensional manifold structure of dynamic images for accelerated dynamic MRI. The performance of the proposed method was evaluated and compared to state-of-the-art methods using numerical simulation studies as well as 2D and 3D in vivo cardiac imaging experiments. The proposed method achieved the best performance in image reconstruction among all the compared methods. The proposed method could prove useful for accelerating many MRI applications, including dynamic MRI, multi-parametric MRI, and MR spectroscopic imaging.},
	number = {1},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Djebra, Yanis and Marin, Thibault and Han, Paul K. and Bloch, Isabelle and Fakhri, Georges El and Ma, Chao},
	month = jan,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {dynamic magnetic resonance imaging, Image reconstruction, Magnetic resonance imaging, Biomedical imaging, Data models, Mathematical models, Constrained image reconstruction, linear tangent space alignment (LTSA), manifold learning, Manifolds, Transforms},
	pages = {158--169},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\HS83PKZ6\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\BD952MX4\\Djebra et al. - 2023 - Manifold Learning via Linear Tangent Space Alignme.pdf:application/pdf},
}

@article{gao_hierarchical_2023,
	title = {Hierarchical {Perception} {Adversarial} {Learning} {Framework} for {Compressed} {Sensing} {MRI}},
	issn = {1558-254X},
	doi = {10.1109/TMI.2023.3240862},
	abstract = {The long acquisition time has limited the accessibility of magnetic resonance imaging (MRI) because it leads to patient discomfort and motion artifacts. Although several MRI techniques have been proposed to reduce the acquisition time, compressed sensing in magnetic resonance imaging (CS-MRI) enables fast acquisition without compromising SNR and resolution. However, existing CS-MRI methods suffer from the challenge of aliasing artifacts. This challenge results in the noise-like textures and missing the fine details, thus leading to unsatisfactory reconstruction performance. To tackle this challenge, we propose a hierarchical perception adversarial learning framework (HP-ALF). HP-ALF can perceive the image information in the hierarchical mechanism: image-level perception and patch-level perception. The former can reduce the visual perception difference in the entire image, and thus achieve aliasing artifact removal. The latter can reduce this difference in the regions of the image, and thus recover fine details. Specifically, HP-ALF achieves the hierarchical mechanism by utilizing multilevel perspective discrimination. This discrimination can provide the information from two perspectives (overall and regional) for adversarial learning. It also utilizes a global and local coherent discriminator to provide structure information to the generator during training. In addition, HP-ALF contains a context-aware learning block to effectively exploit the slice information between individual images for better reconstruction performance. The experiments validated on three datasets demonstrate the effectiveness of HP-ALF and its superiority to the comparative methods.},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Gao, Zhifan and Guo, Yifeng and Zhang, Jiajing and Zeng, Tieyong and Yang, Guang},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Magnetic Resonance Imaging, Image reconstruction, Magnetic resonance imaging, Compressed Sensing, Data mining, Feature extraction, Generative Adversarial Networks, Image restoration, MRI Reconstruction, Visual perception, Visualization},
	pages = {1--1},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\UAZEWLZZ\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\83LU2KZD\\Gao et al. - 2023 - Hierarchical Perception Adversarial Learning Frame.pdf:application/pdf},
}

@article{antun_instabilities_2020,
	title = {On instabilities of deep learning in image reconstruction and the potential costs of {AI}},
	volume = {117},
	url = {https://www.pnas.org/doi/10.1073/pnas.1907377117},
	doi = {10.1073/pnas.1907377117},
	abstract = {Deep learning, due to its unprecedented success in tasks such as image classification, has emerged as a new tool in image reconstruction with potential to change the field. In this paper, we demonstrate a crucial phenomenon: Deep learning typically yields unstable methods for image reconstruction. The instabilities usually occur in several forms: 1) Certain tiny, almost undetectable perturbations, both in the image and sampling domain, may result in severe artefacts in the reconstruction; 2) a small structural change, for example, a tumor, may not be captured in the reconstructed image; and 3) (a counterintuitive type of instability) more samples may yield poorer performance. Our stability test with algorithms and easy-to-use software detects the instability phenomena. The test is aimed at researchers, to test their networks for instabilities, and for government agencies, such as the Food and Drug Administration (FDA), to secure safe use of deep learning methods.},
	number = {48},
	urldate = {2023-05-05},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Antun, Vegard and Renna, Francesco and Poon, Clarice and Adcock, Ben and Hansen, Anders C.},
	month = dec,
	year = {2020},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {30088--30095},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\IUFWYRXY\\Antun et al. - 2020 - On instabilities of deep learning in image reconst.pdf:application/pdf},
}

@article{xu_nesvor_2023,
	title = {{NeSVoR}: {Implicit} {Neural} {Representation} for {Slice}-to-{Volume} {Reconstruction} in {MRI}},
	issn = {1558-254X},
	shorttitle = {{NeSVoR}},
	doi = {10.1109/TMI.2023.3236216},
	abstract = {Reconstructing 3D MR volumes from multiple motion-corrupted stacks of 2D slices has shown promise in imaging of moving subjects, e.g., fetal MRI. However, existing slice-to-volume reconstruction methods are time-consuming, especially when a high-resolution volume is desired. Moreover, they are still vulnerable to severe subject motion and when image artifacts are present in acquired slices. In this work, we present NeSVoR, a resolution-agnostic slice-to-volume reconstruction method, which models the underlying volume as a continuous function of spatial coordinates with implicit neural representation. To improve robustness to subject motion and other image artifacts, we adopt a continuous and comprehensive slice acquisition model that takes into account rigid inter-slice motion, point spread function, and bias fields. NeSVoR also estimates pixel-wise and slice-wise variances of image noise and enables removal of outliers during reconstruction and visualization of uncertainty. Extensive experiments are performed on both simulated and in vivo data to evaluate the proposed method. Results show that NeSVoR achieves state-of-the-art reconstruction quality while providing two to ten-fold acceleration in reconstruction times over the state-of-the-art algorithms.},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Xu, Junshen and Moyer, Daniel and Gagoski, Borjan and Iglesias, Juan Eugenio and Ellen Grant, P. and Golland, Polina and Adalsteinsson, Elfar},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Image reconstruction, Magnetic resonance imaging, Biomedical imaging, Encoding, Training, Solid modeling, MRI, implicit neural representation, 3D reconstruction, fetal brain MRI, motion correction, slice-to-volume reconstruction, super-resolution, Three-dimensional displays},
	pages = {1--1},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\29GPSKRC\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\VBY67VZG\\Xu et al. - 2023 - NeSVoR Implicit Neural Representation for Slice-t.pdf:application/pdf;NeSVoR_Implicit_Neural_Representation_for_Slice-to-Volume_Reconstruction_in_MRI.pdf:C\:\\Users\\Tabita\\Zotero\\storage\\RS7EGA5H\\NeSVoR_Implicit_Neural_Representation_for_Slice-to-Volume_Reconstruction_in_MRI.pdf:application/pdf},
}

@article{doneva_mathematical_2020,
	title = {Mathematical {Models} for {Magnetic} {Resonance} {Imaging} {Reconstruction}: {An} {Overview} of the {Approaches}, {Problems}, and {Future} {Research} {Areas}},
	volume = {37},
	issn = {1558-0792},
	shorttitle = {Mathematical {Models} for {Magnetic} {Resonance} {Imaging} {Reconstruction}},
	doi = {10.1109/MSP.2019.2936964},
	abstract = {Since its inception in the early 1970s [1], magnetic resonance imaging (MRI) has revolutionized radiology and medicine. Apart from high-quality data acquisition, image reconstruction is an important step to guarantee high image quality in MRI. Although the very first MR images were obtained from data resembling radial projections of the imaged object by applying an iterative reconstruction algorithm [1], non-Cartesian acquisition and iterative reconstruction techniques were not adopted in clinical MRI for many years, and, even today, their use is very limited. The reason for this is twofold. First, the underlying assumption that the measured data are radial projections of the imaged object fails in the presence of B0 field inhomogeneity and/or gradient waveform imperfections. Second, the long reconstruction times associated with iterative reconstruction algorithms limit their practical application.},
	number = {1},
	journal = {IEEE Signal Processing Magazine},
	author = {Doneva, Mariya},
	month = jan,
	year = {2020},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Image reconstruction, Magnetic resonance imaging, Compressed sensing, Encoding, Radio frequency, Magnetic field measurement, Magnetic fields},
	pages = {24--32},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tabita\\Zotero\\storage\\USCEWHWS\\8962368.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\2LXZVNJM\\Doneva - 2020 - Mathematical Models for Magnetic Resonance Imaging.pdf:application/pdf},
}

@misc{noauthor_cardiac_nodate,
	title = {Cardiac {MRI} - {ClinicalKey}},
	url = {https://www.clinicalkey.com/#!/content/playContent/1-s2.0-S0025712515000449?returnurl=https:%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0025712515000449%3Fshowall%3Dtrue&referrer=},
	urldate = {2023-05-03},
	file = {Cardiac MRI - ClinicalKey:C\:\\Users\\Tabita\\Zotero\\storage\\VANXR24C\\www.clinicalkey.com.html:text/html},
}

@article{sharafutdinov_radon_2021,
	title = {Radon {Transform} on {Sobolev} {Spaces}},
	volume = {62},
	issn = {1573-9260},
	url = {https://doi.org/10.1134/S0037446621030198},
	doi = {10.1134/S0037446621030198},
	abstract = {The Radon transform \$ R \$maps a function \$ f \$on \$ \{𝕉\}{\textasciicircum}\{n\} \$to the family of the integrals of \$ f \$over all hyperplanes. The classicalReshetnyak formula (also called the Plancherel formula for the Radon transform) states that\$ {\textbackslash}{\textbar}f{\textbackslash}{\textbar}\_\{L{\textasciicircum}\{2\}(\{𝕉\}{\textasciicircum}\{n\})\}={\textbackslash}{\textbar}Rf{\textbackslash}{\textbar}\_\{H{\textasciicircum}\{(n-1)/2\}\_\{(n-1)/2\}(\{𝕊\}{\textasciicircum}\{n-1\}{\textbackslash}times\{𝕉\})\} \$,where\$ {\textbackslash}{\textbar}{\textbackslash}cdot{\textbackslash}{\textbar}\_\{H{\textasciicircum}\{(n-1)/2\}\_\{(n-1)/2\}(\{𝕊\}{\textasciicircum}\{n-1\}{\textbackslash}times\{𝕉\})\} \$is some special norm. The formula extends the Radon transform to the bijective Hilbert space isometry\$ R:L{\textasciicircum}\{2\}(\{𝕉\}{\textasciicircum}\{n\}){\textbackslash}rightarrow H{\textasciicircum}\{(n-1)/2\}\_\{(n-1)/2,e\}(\{𝕊\}{\textasciicircum}\{n-1\}{\textbackslash}times\{𝕉\}) \$.Given reals \$ r \$, \$ s \$, and \$ t{\textgreater}-n/2 \$, we introduce the Sobolev type spaces\$ H{\textasciicircum}\{(r,s)\}\_\{t\}(\{𝕉\}{\textasciicircum}\{n\}) \$and \$ H{\textasciicircum}\{(r,s)\}\_\{t,e\}(\{𝕊\}{\textasciicircum}\{n-1\}{\textbackslash}times\{𝕉\}) \$and prove the version of the Reshetnyak formula:\$ {\textbackslash}{\textbar}f{\textbackslash}{\textbar}\_\{H{\textasciicircum}\{(r,s)\}\_\{t\}(\{𝕉\}{\textasciicircum}\{n\})\}={\textbackslash}{\textbar}Rf{\textbackslash}{\textbar}\_\{H{\textasciicircum}\{(r,(s+n-1)/2)\}\_\{t+(n-1)/2\}(\{𝕊\}{\textasciicircum}\{n-1\}{\textbackslash}times\{𝕉\})\} \$.The formula extends the Radon transform to the bijective Hilbert space isometry\$ R:H{\textasciicircum}\{(r,s)\}\_\{t\}(\{𝕉\}{\textasciicircum}\{n\}){\textbackslash}rightarrow H{\textasciicircum}\{(r,s+(n-1)/2)\}\_\{t+(n-1)/2,e\}(\{𝕊\}{\textasciicircum}\{n-1\}{\textbackslash}times\{𝕉\}) \$.If \$ r{\textbackslash}geq 0 \$and \$ s{\textbackslash}geq 0 \$are integers then \$ H{\textasciicircum}\{(r,s)\}\_\{0,e\}(\{𝕊\}{\textasciicircum}\{n-1\}{\textbackslash}times\{𝕉\}) \$consists of the even functions \$ {\textbackslash}varphi({\textbackslash}xi,p) \$with square integrable derivatives of order \$ {\textbackslash}leq r \$with respect to \$ {\textbackslash}xi \$and order \$ {\textbackslash}leq s \$with respect to \$ p \$.},
	language = {en},
	number = {3},
	urldate = {2023-05-02},
	journal = {Siberian Mathematical Journal},
	author = {Sharafutdinov, V. A.},
	month = may,
	year = {2021},
	keywords = {517.9, Radon transform, Reshetnyak formula, Sobolev spaces},
	pages = {560--580},
}

@article{sharafutdinov_reshetnyak_2016,
	title = {The {Reshetnyak} formula and {Natterer} stability estimates in tensor tomography},
	volume = {33},
	issn = {0266-5611},
	url = {https://dx.doi.org/10.1088/1361-6420/33/2/025002},
	doi = {10.1088/1361-6420/33/2/025002},
	abstract = {The Reshetnyak formula (also known as the Plancherel formula for the Radon transform) states that the Radon transform R is an isometry between and , the latter being the Hilbert space of even functions on furnished by some special norm. We generalize this statement to Sobolev spaces: R is an isometry between and for every real s. Moreover, with the help of Riesz potentials, we define some new Hilbert spaces and prove that R is an isometry between and . The generalized Reshetnyak formula closely relates to the Natterer stability estimates: for functions f supported in a fixed ball. Then we obtain analogs of these statements for the x-ray transform of symmetric tensor fields.},
	language = {en},
	number = {2},
	urldate = {2023-05-02},
	journal = {Inverse Problems},
	author = {Sharafutdinov, Vladimir A.},
	month = dec,
	year = {2016},
	note = {Publisher: IOP Publishing},
	pages = {025002},
	file = {IOP Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\2EZE2WKI\\Sharafutdinov - 2016 - The Reshetnyak formula and Natterer stability esti.pdf:application/pdf},
}

@article{karniadakis_physics-informed_2021,
	title = {Physics-informed machine learning},
	volume = {3},
	issn = {2522-5820},
	url = {https://www.nature.com/articles/s42254-021-00314-5},
	doi = {10.1038/s42254-021-00314-5},
	abstract = {Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-d imensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-t ime domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-b ased regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-d imensional problems.},
	language = {en},
	number = {6},
	urldate = {2023-05-10},
	journal = {Nature Reviews Physics},
	author = {Karniadakis, George Em and Kevrekidis, Ioannis G. and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
	month = may,
	year = {2021},
	pages = {422--440},
	file = {Karniadakis et al. - 2021 - Physics-informed machine learning.pdf:C\:\\Users\\Tabita\\Zotero\\storage\\B56N4LPX\\Karniadakis et al. - 2021 - Physics-informed machine learning.pdf:application/pdf;Nature-REviews_GK.pdf:G\:\\.shortcut-targets-by-id\\1bswZvnBiuixrTBsf70wYo9mQEB_gF29T\\Tabitas_Project\\Nature-REviews_GK.pdf:application/pdf},
}

@misc{kunz_implicit_2023,
	title = {Implicit {Neural} {Networks} with {Fourier}-{Feature} {Inputs} for {Free}-breathing {Cardiac} {MRI} {Reconstruction}},
	url = {http://arxiv.org/abs/2305.06822},
	abstract = {In this paper, we propose an approach for cardiac magnetic resonance imaging (MRI), which aims to reconstruct a real-time video of a beating heart from continuous highly under-sampled measurements. This task is challenging since the object to be reconstructed (the heart) is continuously changing during signal acquisition. To address this challenge, we represent the beating heart with an implicit neural network and fit the network so that the representation of the heart is consistent with the measurements. The network in the form of a multi-layer perceptron with Fourier-feature inputs acts as an effective signal prior and enables adjusting the regularization strength in both the spatial and temporal dimensions of the signal. We examine the proposed approach for 2D free-breathing cardiac real-time MRI in different operating regimes, i.e., for different image resolutions, slice thicknesses, and acquisition lengths. Our method achieves reconstruction quality on par with or slightly better than state-of-the-art untrained convolutional neural networks and superior image quality compared to a recent method that fits an implicit representation directly to Fourier-domain measurements. However, this comes at a higher computational cost. Our approach does not require any additional patient data or biosensors including electrocardiography, making it potentially applicable in a wide range of clinical scenarios.},
	urldate = {2023-05-22},
	publisher = {arXiv},
	author = {Kunz, Johannes F. and Ruschke, Stefan and Heckel, Reinhard},
	month = may,
	year = {2023},
	note = {arXiv:2305.06822 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\FGVN4CS5\\2305.html:text/html;Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\FIFUJJ7U\\Kunz et al. - 2023 - Implicit Neural Networks with Fourier-Feature Inpu.pdf:application/pdf},
}

@misc{alblas_implicit_2023,
	title = {Implicit {Neural} {Representations} for {Modeling} of {Abdominal} {Aortic} {Aneurysm} {Progression}},
	url = {http://arxiv.org/abs/2303.01069},
	abstract = {Abdominal aortic aneurysms (AAAs) are progressive dilatations of the abdominal aorta that, if left untreated, can rupture with lethal consequences. Imaging-based patient monitoring is required to select patients eligible for surgical repair. In this work, we present a model based on implicit neural representations (INRs) to model AAA progression. We represent the AAA wall over time as the zero-level set of a signed distance function (SDF), estimated by a multilayer perception that operates on space and time. We optimize this INR using automatically extracted segmentation masks in longitudinal CT data. This network is conditioned on spatiotemporal coordinates and represents the AAA surface at any desired resolution at any moment in time. Using regularization on spatial and temporal gradients of the SDF, we ensure proper interpolation of the AAA shape. We demonstrate the network's ability to produce AAA interpolations with average surface distances ranging between 0.72 and 2.52 mm from images acquired at highly irregular intervals. The results indicate that our model can accurately interpolate AAA shapes over time, with potential clinical value for a more personalised assessment of AAA progression.},
	urldate = {2023-05-22},
	publisher = {arXiv},
	author = {Alblas, Dieuwertje and Hofman, Marieke and Brune, Christoph and Yeung, Kak Khee and Wolterink, Jelmer M.},
	month = mar,
	year = {2023},
	note = {arXiv:2303.01069 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\5FW6VHRI\\2303.html:text/html;Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\MBTN2PA2\\Alblas et al. - 2023 - Implicit Neural Representations for Modeling of Ab.pdf:application/pdf},
}

@inproceedings{wolterink_implicit_2022,
	title = {Implicit {Neural} {Representations} for {Deformable} {Image} {Registration}},
	url = {https://proceedings.mlr.press/v172/wolterink22a.html},
	abstract = {Deformable medical image registration has in past years been revolutionized by the use of convolutional neural networks. These methods surpass conventional image registration techniques in speed but not in accuracy. Here, we present an alternative approach to leveraging neural networks for image registration. Instead of using a convolutional neural network to predict the transformation between images, we optimize a multi-layer perceptron to represent this transformation function. Using recent insights from differentiable rendering, we show how such an implicit deformable image registration (IDIR) model can be naturally combined with regularization terms based on standard automatic differentiation techniques. We demonstrate the effectiveness of this model on 4D chest CT registration in the DIR-LAB data set and find that a three-layer multi-layer perceptron with periodic activation functions outperforms all published deep learning-based results on this problem, without any folding and without the need for training data. The model is implemented using standard deep learning libraries and flexible enough to be extended to include different losses, regularizers, and optimization schemes.},
	language = {en},
	urldate = {2023-05-22},
	booktitle = {Proceedings of {The} 5th {International} {Conference} on {Medical} {Imaging} with {Deep} {Learning}},
	publisher = {PMLR},
	author = {Wolterink, Jelmer M. and Zwienenberg, Jesse C. and Brune, Christoph},
	month = dec,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {1349--1359},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\EMIMPM27\\Wolterink et al. - 2022 - Implicit Neural Representations for Deformable Ima.pdf:application/pdf},
}

@inproceedings{alblas_going_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Going {Off}-{Grid}: {Continuous} {Implicit} {Neural} {Representations} for {3D} {Vascular} {Modeling}},
	isbn = {978-3-031-23443-9},
	shorttitle = {Going {Off}-{Grid}},
	doi = {10.1007/978-3-031-23443-9_8},
	abstract = {Personalised 3D vascular models are valuable for diagnosis, prognosis and treatment planning in patients with cardiovascular disease. Traditionally, such models have been constructed with explicit representations such as meshes and voxel masks, or implicit representations such as radial basis functions or atomic (cylindrical) shapes. Here, we propose to represent surfaces by the zero level set of their signed distance function (SDF) in a differentiable implicit neural representation (INR). This allows us to model complex vascular structures with a representation that is implicit, continuous, light-weight, and easy to integrate with deep learning algorithms. We here demonstrate the potential of this approach with three practical examples. First, we obtain an accurate and watertight surface for an abdominal aortic aneurysm (AAA) from CT images and show robust fitting from as few as 200 points on the surface. Second, we simultaneously fit nested vessel walls in a single INR without intersections. Third, we show how 3D models of individual arteries can be smoothly blended into a single watertight surface. Our results show that INRs are a flexible representation with potential for minimally interactive annotation and manipulation of complex vascular structures.},
	language = {en},
	booktitle = {Statistical {Atlases} and {Computational} {Models} of the {Heart}. {Regular} and {CMRxMotion} {Challenge} {Papers}},
	publisher = {Springer Nature Switzerland},
	author = {Alblas, Dieuwertje and Brune, Christoph and Yeung, Kak Khee and Wolterink, Jelmer M.},
	editor = {Camara, Oscar and Puyol-Antón, Esther and Qin, Chen and Sermesant, Maxime and Suinesiaputra, Avan and Wang, Shuo and Young, Alistair},
	year = {2022},
	keywords = {Abdominal aortic aneurysm, Implicit neural representation, Level set, Signed distance function, Vascular model},
	pages = {79--90},
	file = {Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\U29THQG9\\Alblas et al. - 2022 - Going Off-Grid Continuous Implicit Neural Represe.pdf:application/pdf},
}

@article{larkman_parallel_2007,
	title = {Parallel magnetic resonance imaging},
	volume = {52},
	issn = {0031-9155},
	url = {https://dx.doi.org/10.1088/0031-9155/52/7/R01},
	doi = {10.1088/0031-9155/52/7/R01},
	abstract = {Parallel imaging has been the single biggest innovation in magnetic resonance imaging in the last decade. The use of multiple receiver coils to augment the time consuming Fourier encoding has reduced acquisition times significantly. This increase in speed comes at a time when other approaches to acquisition time reduction were reaching engineering and human limits. A brief summary of spatial encoding in MRI is followed by an introduction to the problem parallel imaging is designed to solve. There are a large number of parallel reconstruction algorithms; this article reviews a cross-section, SENSE, SMASH, g-SMASH and GRAPPA, selected to demonstrate the different approaches. Theoretical (the g-factor) and practical (coil design) limits to acquisition speed are reviewed. The practical implementation of parallel imaging is also discussed, in particular coil calibration. How to recognize potential failure modes and their associated artefacts are shown. Well-established applications including angiography, cardiac imaging and applications using echo planar imaging are reviewed and we discuss what makes a good application for parallel imaging. Finally, active research areas where parallel imaging is being used to improve data quality by repairing artefacted images are also reviewed.},
	language = {en},
	number = {7},
	urldate = {2023-05-23},
	journal = {Physics in Medicine \& Biology},
	author = {Larkman, David J. and Nunes, Rita G.},
	month = mar,
	year = {2007},
	pages = {R15},
	file = {IOP Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\V5E8WGQT\\Larkman y Nunes - 2007 - Parallel magnetic resonance imaging.pdf:application/pdf},
}

@misc{noauthor_cardiac_nodate-1,
	title = {Cardiac {MRI} - {ClinicalKey}},
	url = {https://www.clinicalkey.com/#!/content/playContent/1-s2.0-S0025712515000449?returnurl=https:%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0025712515000449%3Fshowall%3Dtrue&referrer=},
	urldate = {2023-05-23},
	file = {Cardiac MRI - ClinicalKey:C\:\\Users\\Tabita\\Zotero\\storage\\JPHNSXU7\\www.clinicalkey.com.html:text/html},
}

@article{pfeiffer_cardiac_2015,
	title = {Cardiac {MRI}},
	volume = {99},
	issn = {00257125},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0025712515000449},
	doi = {10.1016/j.mcna.2015.02.011},
	language = {en},
	number = {4},
	urldate = {2023-05-23},
	journal = {Medical Clinics of North America},
	author = {Pfeiffer, Michael P. and Biederman, Robert W.W.},
	month = jul,
	year = {2015},
	pages = {849--861},
	file = {Pfeiffer y Biederman - 2015 - Cardiac MRI.pdf:C\:\\Users\\Tabita\\Zotero\\storage\\LRPNJ7AE\\Pfeiffer y Biederman - 2015 - Cardiac MRI.pdf:application/pdf},
}

@article{lundervold_overview_2019,
	series = {Special {Issue}: {Deep} {Learning} in {Medical} {Physics}},
	title = {An overview of deep learning in medical imaging focusing on {MRI}},
	volume = {29},
	issn = {0939-3889},
	url = {https://www.sciencedirect.com/science/article/pii/S0939388918301181},
	doi = {10.1016/j.zemedi.2018.11.002},
	abstract = {What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artificial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding field we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI. Our aim is threefold: (i) give a brief introduction to deep learning with pointers to core references; (ii) indicate how deep learning has been applied to the entire MRI processing chain, from acquisition to image retrieval, from segmentation to disease prediction; (iii) provide a starting point for people interested in experimenting and perhaps contributing to the field of deep learning for medical imaging by pointing out good educational resources, state-of-the-art open-source code, and interesting sources of data and problems related medical imaging.},
	language = {en},
	number = {2},
	urldate = {2023-05-23},
	journal = {Zeitschrift für Medizinische Physik},
	author = {Lundervold, Alexander Selvikvåg and Lundervold, Arvid},
	month = may,
	year = {2019},
	keywords = {Deep learning, Machine learning, Medical imaging, MRI},
	pages = {102--127},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\7TT98JPG\\Lundervold y Lundervold - 2019 - An overview of deep learning in medical imaging fo.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Tabita\\Zotero\\storage\\RRID5XHT\\S0939388918301181.html:text/html},
}

@article{muckley_results_2021,
	title = {Results of the 2020 {fastMRI} {Challenge} for {Machine} {Learning} {MR} {Image} {Reconstruction}},
	volume = {40},
	issn = {0278-0062},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8428775/},
	doi = {10.1109/TMI.2021.3075856},
	abstract = {Accelerating MRI scans is one of the principal outstanding problems in the MRI research community. Towards this goal, we hosted the second fastMRI competition targeted towards reconstructing MR images with subsampled k-space data. We provided participants with data from 7,299 clinical brain scans (de-identified via a HIPAA-compliant procedure by NYU Langone Health), holding back the fully-sampled data from 894 of these scans for challenge evaluation purposes. In contrast to the 2019 challenge, we focused our radiologist evaluations on pathological assessment in brain images. We also debuted a new Transfer track that required participants to submit models evaluated on MRI scanners from outside the training set. We received 19 submissions from eight different groups. Results showed one team scoring best in both SSIM scores and qualitative radiologist evaluations. We also performed analysis on alternative metrics to mitigate the effects of background noise and collected feedback from the participants to inform future challenges. Lastly, we identify common failure modes across the submissions, highlighting areas of need for future research in the MRI reconstruction community.},
	number = {9},
	urldate = {2023-05-23},
	journal = {IEEE transactions on medical imaging},
	author = {Muckley, Matthew J. and Riemenschneider, Bruno and Radmanesh, Alireza and Kim, Sunwoo and Jeong, Geunu and Ko, Jingyu and Jun, Yohan and Shin, Hyungseob and Hwang, Dosik and Mostapha, Mahmoud and Arberet, Simon and Nickel, Dominik and Ramzi, Zaccharie and Ciuciu, Philippe and Starck, Jean-Luc and Teuwen, Jonas and Karkalousos, Dimitrios and Zhang, Chaoping and Sriram, Anuroop and Huang, Zhengnan and Yakubova, Nafissa and Lui, Yvonne W. and Knoll, Florian},
	month = sep,
	year = {2021},
	pmid = {33929957},
	pmcid = {PMC8428775},
	pages = {2306--2317},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Tabita\\Zotero\\storage\\GRX293SM\\Muckley et al. - 2021 - Results of the 2020 fastMRI Challenge for Machine .pdf:application/pdf},
}
