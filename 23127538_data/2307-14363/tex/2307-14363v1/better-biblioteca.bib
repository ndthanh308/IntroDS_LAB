@article{aggarwalENSUREGeneralApproach2023,
  title = {{{ENSURE}}: {{A General Approach}} for {{Unsupervised Training}} of {{Deep Image Reconstruction Algorithms}}},
  shorttitle = {{{ENSURE}}},
  author = {Aggarwal, Hemant Kumar and Pramanik, Aniket and John, Maneesh and Jacob, Mathews},
  year = {2023},
  month = apr,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {42},
  number = {4},
  pages = {1133--1144},
  issn = {1558-254X},
  doi = {10.1109/TMI.2022.3224359},
  abstract = {Image reconstruction using deep learning algorithms offers improved reconstruction quality and lower reconstruction time than classical compressed sensing and model-based algorithms. Unfortunately, clean and fully sampled ground-truth data to train the deep networks is often unavailable in several applications, restricting the applicability of the above methods. We introduce a novel metric termed the ENsemble Stein's Unbiased Risk Estimate (ENSURE) framework, which can be used to train deep image reconstruction algorithms without fully sampled and noise-free images. The proposed framework is the generalization of the classical SURE and GSURE formulation to the setting where the images are sampled by different measurement operators, chosen randomly from a set. We evaluate the expectation of the GSURE loss functions over the sampling patterns to obtain the ENSURE loss function. We show that this loss is an unbiased estimate for the true mean-square error, which offers a better alternative to GSURE, which only offers an unbiased estimate for the projected error. Our experiments show that the networks trained with this loss function can offer reconstructions comparable to the supervised setting. While we demonstrate this framework in the context of MR image recovery, the ENSURE framework is generally applicable to arbitrary inverse problems.},
  keywords = {deep learning,Image reconstruction,inverse problems,Loss measurement,Magnetic resonance imaging,Measurement,MRI,Noise measurement,SURE,Training,Unsupervised learning,Weight measurement},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/C65MCBBN/Aggarwal et al. - 2023 - ENSURE A General Approach for Unsupervised Traini.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/5XFE5PFL/references.html}
}

@article{ahmedDynamicImagingUsing2022,
  title = {Dynamic {{Imaging Using Deep Bi-Linear Unsupervised Representation}} ({{DEBLUR}})},
  author = {Ahmed, Abdul Haseeb and Zou, Qing and Nagpal, Prashant and Jacob, Mathews},
  year = {2022},
  month = oct,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {41},
  number = {10},
  pages = {2693--2703},
  issn = {1558-254X},
  doi = {10.1109/TMI.2022.3168559},
  abstract = {Bilinear models such as low-rank and dictionary methods, which decompose dynamic data to spatial and temporal factor matrices are powerful and memory-efficient tools for the recovery of dynamic MRI data. Current bilinear methods rely on sparsity and energy compaction priors on the factor matrices to regularize the recovery. Motivated by deep image prior, we introduce a novel bilinear model, whose factor matrices are generated using convolutional neural networks (CNNs). The CNN parameters, and equivalently the factors, are learned from the undersampled data of the specific subject. Unlike current unrolled deep learning methods that require the storage of all the time frames in the dataset, the proposed approach only requires the storage of the factors or compressed representation; this approach allows the direct use of this scheme to large-scale dynamic applications, including free breathing cardiac MRI considered in this work. To reduce the run time and to improve performance, we initialize the CNN parameters using existing factor methods. We use sparsity regularization of the network parameters to minimize the overfitting of the network to measurement noise. Our experiments on free-breathing and ungated cardiac cine data acquired using a navigated golden-angle gradient-echo radial sequence show the ability of our method to provide reduced spatial blurring as compared to classical bilinear methods as well as a recent unsupervised deep-learning approach.},
  keywords = {Bilinear model,cardiac MRI,Convolutional neural networks,dynamic imaging,Generators,image reconstruction,Image reconstruction,Magnetic resonance imaging,Noise measurement,Optimization,unsupervised learning,Urban areas},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/MCZHYA6D/Ahmed et al. - 2022 - Dynamic Imaging Using Deep Bi-Linear Unsupervised .pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/NUT9L5RL/9759446.html}
}

@article{akcakayaScanspecificRobustArtificialneuralnetworks2019,
  title = {Scan-Specific Robust Artificial-Neural-Networks for k-Space Interpolation ({{RAKI}}) Reconstruction: {{Database-free}} Deep Learning for Fast Imaging},
  shorttitle = {Scan-Specific Robust Artificial-Neural-Networks for k-Space Interpolation ({{RAKI}}) Reconstruction},
  author = {Ak{\c c}akaya, Mehmet and Moeller, Steen and Weing{\"a}rtner, Sebastian and U{\u g}urbil, K{\^a}mil},
  year = {2019},
  journal = {Magnetic Resonance in Medicine},
  volume = {81},
  number = {1},
  pages = {439--453},
  issn = {1522-2594},
  doi = {10.1002/mrm.27420},
  urldate = {2023-04-25},
  abstract = {Purpose To develop an improved k-space reconstruction method using scan-specific deep learning that is trained on autocalibration signal (ACS) data. Theory Robust artificial-neural-networks for k-space interpolation (RAKI) reconstruction trains convolutional neural networks on ACS data. This enables nonlinear estimation of missing k-space lines from acquired k-space data with improved noise resilience, as opposed to conventional linear k-space interpolation-based methods, such as GRAPPA, which are based on linear convolutional kernels. Methods The training algorithm is implemented using a mean square error loss function over the target points in the ACS region, using a gradient descent algorithm. The neural network contains 3 layers of convolutional operators, with 2 of these including nonlinear activation functions. The noise performance and reconstruction quality of the RAKI method was compared with GRAPPA in phantom, as well as in neurological and cardiac in vivo data sets. Results Phantom imaging shows that the proposed RAKI method outperforms GRAPPA at high ({$\geq$}4) acceleration rates, both visually and quantitatively. Quantitative cardiac imaging shows improved noise resilience at high acceleration rates (rate 4:23\% and rate 5:48\%) over GRAPPA. The same trend of improved noise resilience is also observed in high-resolution brain imaging at high acceleration rates. Conclusion The RAKI method offers a training database-free deep learning approach for MRI reconstruction, with the potential to improve many existing reconstruction approaches, and is compatible with conventional data acquisition protocols.},
  langid = {english},
  keywords = {accelerated imaging,Adult,Algorithms,Brain,Brain Mapping,convolutional neural networks,{Databases, Factual},deep learning,Deep Learning,Female,Heart,Humans,Image Enhancement,{Image Interpretation, Computer-Assisted},{Image Processing, Computer-Assisted},image reconstruction,k-space interpolation,Magnetic Resonance Imaging,Male,Middle Aged,{Neural Networks, Computer},nonlinear estimation,parallel imaging,{Phantoms, Imaging},Radionuclide Imaging,Young Adult},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/HZS6PX4W/Akçakaya et al. - 2019 - Scan-specific robust artificial-neural-networks fo.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/U5EW6URV/mrm.html}
}

@inproceedings{alblasGoingOffGridContinuous2022,
  title = {Going {{Off-Grid}}: {{Continuous Implicit Neural Representations}} for~{{3D Vascular Modeling}}},
  shorttitle = {Going {{Off-Grid}}},
  booktitle = {Statistical {{Atlases}} and {{Computational Models}} of the {{Heart}}. {{Regular}} and {{CMRxMotion Challenge Papers}}},
  author = {Alblas, Dieuwertje and Brune, Christoph and Yeung, Kak Khee and Wolterink, Jelmer M.},
  editor = {Camara, Oscar and {Puyol-Ant{\'o}n}, Esther and Qin, Chen and Sermesant, Maxime and Suinesiaputra, Avan and Wang, Shuo and Young, Alistair},
  year = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {79--90},
  publisher = {{Springer Nature Switzerland}},
  address = {{Cham}},
  doi = {10.1007/978-3-031-23443-9\_8},
  abstract = {Personalised 3D vascular models are valuable for diagnosis, prognosis and treatment planning in patients with cardiovascular disease. Traditionally, such models have been constructed with explicit representations such as meshes and voxel masks, or implicit representations such as radial basis functions or atomic (cylindrical) shapes. Here, we propose to represent surfaces by the zero level set of their signed distance function (SDF) in a differentiable implicit neural representation (INR). This allows us to model complex vascular structures with a representation that is implicit, continuous, light-weight, and easy to integrate with deep learning algorithms. We here demonstrate the potential of this approach with three practical examples. First, we obtain an accurate and watertight surface for an abdominal aortic aneurysm (AAA) from CT images and show robust fitting from as few as 200 points on the surface. Second, we simultaneously fit nested vessel walls in a single INR without intersections. Third, we show how 3D models of individual arteries can be smoothly blended into a single watertight surface. Our results show that INRs are a flexible representation with potential for minimally interactive annotation and manipulation of complex vascular structures.},
  isbn = {978-3-031-23443-9},
  langid = {english},
  keywords = {Abdominal aortic aneurysm,Implicit neural representation,Level set,Signed distance function,Vascular model},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/U29THQG9/Alblas et al. - 2022 - Going Off-Grid Continuous Implicit Neural Represe.pdf}
}

@misc{alblasImplicitNeuralRepresentations2023,
  title = {Implicit {{Neural Representations}} for {{Modeling}} of {{Abdominal Aortic Aneurysm Progression}}},
  author = {Alblas, Dieuwertje and Hofman, Marieke and Brune, Christoph and Yeung, Kak Khee and Wolterink, Jelmer M.},
  year = {2023},
  month = mar,
  number = {arXiv:2303.01069},
  eprint = {2303.01069},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  urldate = {2023-05-22},
  abstract = {Abdominal aortic aneurysms (AAAs) are progressive dilatations of the abdominal aorta that, if left untreated, can rupture with lethal consequences. Imaging-based patient monitoring is required to select patients eligible for surgical repair. In this work, we present a model based on implicit neural representations (INRs) to model AAA progression. We represent the AAA wall over time as the zero-level set of a signed distance function (SDF), estimated by a multilayer perception that operates on space and time. We optimize this INR using automatically extracted segmentation masks in longitudinal CT data. This network is conditioned on spatiotemporal coordinates and represents the AAA surface at any desired resolution at any moment in time. Using regularization on spatial and temporal gradients of the SDF, we ensure proper interpolation of the AAA shape. We demonstrate the network's ability to produce AAA interpolations with average surface distances ranging between 0.72 and 2.52 mm from images acquired at highly irregular intervals. The results indicate that our model can accurately interpolate AAA shapes over time, with potential clinical value for a more personalised assessment of AAA progression.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/MBTN2PA2/Alblas et al. - 2023 - Implicit Neural Representations for Modeling of Ab.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/5FW6VHRI/2303.html}
}

@article{antunInstabilitiesDeepLearning2020,
  title = {On Instabilities of Deep Learning in Image Reconstruction and the Potential Costs of {{AI}}},
  author = {Antun, Vegard and Renna, Francesco and Poon, Clarice and Adcock, Ben and Hansen, Anders C.},
  year = {2020},
  month = dec,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {117},
  number = {48},
  pages = {30088--30095},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1907377117},
  urldate = {2023-05-05},
  abstract = {Deep learning, due to its unprecedented success in tasks such as image classification, has emerged as a new tool in image reconstruction with potential to change the field. In this paper, we demonstrate a crucial phenomenon: Deep learning typically yields unstable methods for image reconstruction. The instabilities usually occur in several forms: 1) Certain tiny, almost undetectable perturbations, both in the image and sampling domain, may result in severe artefacts in the reconstruction; 2) a small structural change, for example, a tumor, may not be captured in the reconstructed image; and 3) (a counterintuitive type of instability) more samples may yield poorer performance. Our stability test with algorithms and easy-to-use software detects the instability phenomena. The test is aimed at researchers, to test their networks for instabilities, and for government agencies, such as the Food and Drug Administration (FDA), to secure safe use of deep learning methods.},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/IUFWYRXY/Antun et al. - 2020 - On instabilities of deep learning in image reconst.pdf}
}

@misc{arratiaWarpPINNCineMRImage2022,
  title = {{{WarpPINN}}: {{Cine-MR}} Image Registration with Physics-Informed Neural Networks},
  shorttitle = {{{WarpPINN}}},
  author = {Arratia, Pablo and Mella, Hern{\'a}n and Uribe, Sergio and Hurtado, Daniel E. and Costabal, Francisco Sahli},
  year = {2022},
  month = nov,
  number = {arXiv:2211.12549},
  eprint = {2211.12549},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2211.12549},
  urldate = {2023-03-02},
  abstract = {Heart failure is typically diagnosed with a global function assessment, such as ejection fraction. However, these metrics have low discriminate power, failing to distinguish different types of this disease. Quantifying local deformations in the form of cardiac strain can provide helpful information, but it remains a challenge. In this work, we introduce WarpPINN, a physics-informed neural network to perform image registration to obtain local metrics of the heart deformation. We apply this method to cine magnetic resonance images to estimate the motion during the cardiac cycle. We inform our neural network of near-incompressibility of cardiac tissue by penalizing the jacobian of the deformation field. The loss function has two components: an intensity-based similarity term between the reference and the warped template images, and a regularizer that represents the hyperelastic behavior of the tissue. The architecture of the neural network allows us to easily compute the strain via automatic differentiation to assess cardiac activity. We use Fourier feature mappings to overcome the spectral bias of neural networks, allowing us to capture discontinuities in the strain field. We test our algorithm on a synthetic example and on a cine-MRI benchmark of 15 healthy volunteers. We outperform current methodologies both landmark tracking and strain estimation. We expect that WarpPINN will enable more precise diagnostics of heart failure based on local deformation information. Source code is available at https://github.com/fsahli/WarpPINN.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/K98Y6I6M/López et al. - 2022 - WarpPINN Cine-MR image registration with physics-.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/K2VUX76F/2211.html}
}

@inproceedings{basriConvergenceRateNeural2019,
  title = {The {{Convergence Rate}} of {{Neural Networks}} for {{Learned Functions}} of {{Different Frequencies}}},
  booktitle = {Neural {{Information Processing Systems}}},
  author = {Basri, R. and Jacobs, D. and Kasten, Y. and Kritchman, S.},
  year = {2019},
  month = jun,
  urldate = {2023-07-14},
  abstract = {We study the relationship between the frequency of a function and the speed at which a neural network learns it. We build on recent results that show that the dynamics of overparameterized neural networks trained with gradient descent can be well approximated by a linear system. When normalized training data is uniformly distributed on a hypersphere, the eigenfunctions of this linear system are spherical harmonic functions. We derive the corresponding eigenvalues for each frequency after introducing a bias term in the model. This bias term had been omitted from the linear network model without significantly affecting previous theoretical results. However, we show theoretically and experimentally that a shallow neural network without bias cannot represent or learn simple, low frequency functions with odd frequencies. Our results lead to specific predictions of the time it will take a network to learn functions of varying frequency. These predictions match the empirical behavior of both shallow and deep networks.},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/IZSXV7U9/Basri et al. - 2019 - The Convergence Rate of Neural Networks for Learne.pdf}
}

@inproceedings{bergmanFastTrainingNeural2021,
  title = {Fast {{Training}} of {{Neural Lumigraph Representations}} Using {{Meta Learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bergman, Alexander and Kellnhofer, Petr and Wetzstein, Gordon},
  year = {2021},
  volume = {34},
  pages = {172--186},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-11-03},
  abstract = {Novel view synthesis is a long-standing problem in machine learning and computer vision. Significant progress has recently been made in developing neural scene representations and rendering techniques that synthesize photorealistic images from arbitrary views. These representations, however, are extremely slow to train and often also slow to render. Inspired by neural variants of image-based rendering, we develop a new neural rendering approach with the goal of quickly learning a high-quality representation which can also be rendered in real-time. Our approach, MetaNLR++, accomplishes this by using a unique combination of a neural shape representation and 2D CNN-based image feature extraction, aggregation, and re-projection. To push representation convergence times down to minutes, we leverage meta learning to learn neural shape and image feature priors which accelerate training. The optimized shape and image features can then be extracted using traditional graphics techniques and rendered in real time. We show that MetaNLR++ achieves similar or better novel view synthesis results in a fraction of the time that competing methods require.},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/35TKJZVW/Bergman et al. - 2021 - Fast Training of Neural Lumigraph Representations .pdf}
}

@misc{blumenthalMrireconBartVersion2022,
  title = {Mrirecon/Bart: Version 0.8.00},
  shorttitle = {Mrirecon/Bart},
  author = {Blumenthal, Moritz and Holme, Christian and Roeloffs, Volkert and Rosenzweig, Sebastian and Schaten, Philip and Scholand, Nick and Tamir, Jon and Xiaoqing Wang and Uecker, Martin},
  year = {2022},
  month = sep,
  doi = {10.5281/ZENODO.7110562},
  urldate = {2022-11-03},
  abstract = {Changes: new tools: epg ictv sim reconet onehotenc measure mnist multicfl morphop fovshift epg: EPG simulations ictv: infimal convolution TV (experimental) sim: Bloch simulations reconet: deep learning reconstruction (MoDL, VarNET) onehotenc: transform onehotencoded data to integer encoded measure: compute MSE, SSIM, PSNR mnist: simple mnist network for demonstration multicfl: combine/split cfl files morphop: morphological operations fovshift: retrospectively shift the FOV pics: tensorflow loss pics: select wavelet type pics: TGV/ICTV regularization (experimental) moba: scaling parameters via command-line parameters moba: various numerical fixes moba: time timensions moba: support for ADMM moba: Bloch model recon with tests moba: multi-gpu option moba: scaling of TV derivatives phantom: NIST phantom and others phantom: rotation for TUBE and NIST phantom geometries phantom: rectangle geometry traj: flag for oversampled trajectory traj: 3D uniform (half-sphere) trajectory sim: output partial derivatives twixread: updates for VD/VE versions ismrmd: support for reading XML metadata estdelay: more generic regarding un-/centered trajectories tgv: for rof / tgv denoising rmfreq: support for contrast changes and coilwise contrast mobafit: T2 and diffusion fit ecalib: make number of iterations for orthiter configurable nufft: warn about incorrectly scaled trajectories nlinv: fix noncart ENLIVE pics: fix basis pursuit pics when using a sampling pattern (\#285) fakeksp: fix output argument python interface: allow multiple files with the correct option string python interface: faster write\_cfl library: New md functions: zacos, zsinh, zcosh, pdf\_gauss, zmaxnorm, zcorr, tenmul library: framework for neural networks library: optimization algorithms: SGD, Adam, Adadelta, iPALM library: linear operators: scale, zconj, zreal, permute, padding, repmat, scaled\_sum library: many new non-linear operators library: support for using different wavelet type library: nlop\_attach, for attaching a random data pointer library: nlop reshape function library: allow forward nufft with toeplitz library: tgv/ictv + multiple penalties + 3D generic: radial DCF examples generic: Add support for multi cfl generic: POSIX shared memory files generic: improve determinism generic: improved parallelization and multi-gpu support generic: add better support for use as shared libray generic: bart for centos 7 generic: Fix Fedora Packages generic: Windows support by MSYS2 generic: support for linking with cudann generic: support for linking with tensorlfow generic: add pythontest to github action generic: LTO test builts many other bug fixes and improvements},
  copyright = {BSD 3-Clause "New" or "Revised" License, Open Access},
  howpublished = {Zenodo},
  keywords = {compressed sensing,computational imaging,deep learning,magnetic resonance imaging,model-based reconstruction,parallel imaging}
}

@misc{bradburyJAXComposableTransformations2018,
  title = {{{JAX}}: Composable Transformations of {{Python}}+{{NumPy}} Programs},
  shorttitle = {Jax},
  author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and James Johnson, Matthew and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and {Wanderman-Milne}, Skye and Zhang, Qiao},
  year = {2018}
}

@misc{CardiacMRIClinicalKey,
  title = {Cardiac {{MRI}} - {{ClinicalKey}}},
  urldate = {2023-05-03},
  howpublished = {https://www.clinicalkey.com/\#!/content/playContent/1-s2.0-S0025712515000449?returnurl=https:\%2F\%2Flinkinghub.elsevier.com\%2Fretrieve\%2Fpii\%2FS0025712515000449\%3Fshowall\%3Dtrue\&referrer=},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/VANXR24C/www.clinicalkey.com.html}
}

@misc{catalanHighlyAcceleratedCardiac2022,
  title = {Highly Accelerated {{Cardiac CINE MRI}} Using {{Neural Fields}}},
  author = {Catal{\'a}n, Tabita and Courdurier, Mat{\'i}as and Osses, Axel and Botnar, Ren{\'e} and Sahli Cost{\'a}bal, Francisco and Prieto, Claudia},
  year = {2022},
  month = nov,
  abstract = {Neural fields cardiac MRI (NF-cMRI), a method for highly accelerated CINE reconstruction using deep learning, is proposed. NF-cMRI relies on an intensity network, based on neural fields with Fourier features to encode a continuous reconstruction. The network is trained with one undersampled radial k-space data set without the need of a fully-sampled reference image. Good image quality of the heart is achieved with 8 radial spokes/cardiac frame. Results are compared against GRASP. Future work will focus on reducing reconstruction time and evaluating the proposed approach in prospectively undersampled k-space data.}
}

@inproceedings{chenNeRVNeuralRepresentations2021,
  title = {{{NeRV}}: {{Neural Representations}} for {{Videos}}},
  shorttitle = {{{NeRV}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Chen, Hao and He, Bo and Wang, Hanyu and Ren, Yixuan and Lim, Ser Nam and Shrivastava, Abhinav},
  year = {2021},
  volume = {34},
  pages = {21557--21568},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-29},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/W58X4LRN/Chen et al. - 2021 - NeRV Neural Representations for Videos.pdf}
}

@inproceedings{chenVideoINRLearningVideo2022,
  title = {{{VideoINR}}: {{Learning Video Implicit Neural Representation}} for {{Continuous Space-Time Super-Resolution}}},
  shorttitle = {{{VideoINR}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Chen, Zeyuan and Chen, Yinbo and Liu, Jingwen and Xu, Xingqian and Goel, Vidit and Wang, Zhangyang and Shi, Humphrey and Wang, Xiaolong},
  year = {2022},
  month = jun,
  pages = {2037--2047},
  publisher = {{IEEE}},
  address = {{New Orleans, LA, USA}},
  doi = {10.1109/CVPR52688.2022.00209},
  urldate = {2023-03-29},
  abstract = {Videos typically record the streaming and continuous visual data as discrete consecutive frames. Since the storage cost is expensive for videos of high fidelity, most of them are stored in a relatively low resolution and frame rate. Recent works of Space-Time Video Super-Resolution (STVSR) are developed to incorporate temporal interpolation and spatial super-resolution in a unified framework. However, most of them only support a fixed upsampling scale, which limits their flexibility and applications. In this work, instead of following the discrete representations, we propose Video Implicit Neural Representation (VideoINR), and we show its applications for STVSR. The learned implicit neural representation can be decoded to videos of arbitrary spatial resolution and frame rate. We show that VideoINR achieves competitive performances with state-of-the-art STVSR methods on common up-sampling scales and significantly outperforms prior works on continuous and out-of-training-distribution scales. Our project page is at here and code is available at https://github.com/Picsart-AI-Research/VideoINRContinuous-Space-Time-Super-Resolution.},
  isbn = {978-1-66546-946-3},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/2YC8HGHP/Chen et al. - 2022 - VideoINR Learning Video Implicit Neural Represent.pdf}
}

@article{christodoulouAcceleratedDynamicMagnetic2020,
  title = {Accelerated {{Dynamic Magnetic Resonance Imaging Using Learned Representations}}: {{A New Frontier}} in {{Biomedical Imaging}}},
  shorttitle = {Accelerated {{Dynamic Magnetic Resonance Imaging Using Learned Representations}}},
  author = {Christodoulou, Anthony G. and Lingala, Sajan Goud},
  year = {2020},
  month = jan,
  journal = {IEEE Signal Processing Magazine},
  volume = {37},
  number = {1},
  pages = {83--93},
  issn = {1558-0792},
  doi = {10.1109/MSP.2019.2942180},
  abstract = {Dynamic magnetic resonance imaging (MRI) can be used to scan a wide range of dynamic processes within the body, including the motion of internal organs, tissue-level nuclear magnetic resonance (NMR) relaxation, and dynamic contrast enhancement (DCE) of dye agents. The ability of MRI to safely provide unique soft-tissue contrast and comprehensive functional information has made dynamic MRI central to a number of imaging exams for cardiac, interventional, vocal tract, cancer, and gastrointestinal applications, among others. Unfortunately, MRI is a notoriously slow imaging modality due to fundamental physical and physiological limitations. These limitations result in tradeoffs between spatial and temporal resolutions, spatial coverage, and the signal-to-noise ratio and have made dynamic MRI a challenging technical goal.},
  keywords = {Adaptation models,Compressed sensing,Data models,Magnetic resonance imaging,Matrix decomposition},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/I6PMYUXX/Christodoulou and Lingala - 2020 - Accelerated Dynamic Magnetic Resonance Imaging Usi.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/RGYJ5DDV/8962380.html}
}

@inproceedings{coleFastUnsupervisedMRI2021,
  title = {Fast {{Unsupervised MRI Reconstruction Without Fully-Sampled Ground Truth Data Using Generative Adversarial Networks}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Cole, Elizabeth K. and Ong, Frank and Vasanawala, Shreyas S. and Pauly, John M.},
  year = {2021},
  pages = {3988--3997},
  urldate = {2023-04-26},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/JAKWVKYQ/Cole et al. - 2021 - Fast Unsupervised MRI Reconstruction Without Fully.pdf}
}

@misc{coleUnsupervisedMRIReconstruction2020,
  title = {Unsupervised {{MRI Reconstruction}} with {{Generative Adversarial Networks}}},
  author = {Cole, Elizabeth K. and Pauly, John M. and Vasanawala, Shreyas S. and Ong, Frank},
  year = {2020},
  month = aug,
  number = {arXiv:2008.13065},
  eprint = {2008.13065},
  primaryclass = {cs, eess, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2008.13065},
  urldate = {2023-04-26},
  abstract = {Deep learning-based image reconstruction methods have achieved promising results across multiple MRI applications. However, most approaches require large-scale fully-sampled ground truth data for supervised training. Acquiring fully-sampled data is often either difficult or impossible, particularly for dynamic contrast enhancement (DCE), 3D cardiac cine, and 4D flow. We present a deep learning framework for MRI reconstruction without any fully-sampled data using generative adversarial networks. We test the proposed method in two scenarios: retrospectively undersampled fast spin echo knee exams and prospectively undersampled abdominal DCE. The method recovers more anatomical structure compared to conventional methods.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing,Statistics - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/DGFELJD5/Cole et al. - 2020 - Unsupervised MRI Reconstruction with Generative Ad.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/AFMSAPER/2008.html}
}

@misc{ConnectedPapersFind,
  title = {Connected {{Papers}} | {{Find}} and Explore Academic Papers},
  urldate = {2023-06-22},
  abstract = {A unique, visual tool to help researchers and applied scientists find and explore papers relevant to their field of work.},
  howpublished = {https://www.connectedpapers.com/main/3d9f237fe6ed8590f0e604d7e671d8fa3f99f494/Time\%20Dependent-Deep-Image-Prior-for-Dynamic-MRI/graph},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/8NXBR4Z7/graph.html}
}

@misc{darestaniAcceleratedMRIUntrained2021,
  title = {Accelerated {{MRI}} with {{Un-trained Neural Networks}}},
  author = {Darestani, Mohammad Zalbagi and Heckel, Reinhard},
  year = {2021},
  month = apr,
  number = {arXiv:2007.02471},
  eprint = {2007.02471},
  primaryclass = {cs, eess, stat},
  publisher = {{arXiv}},
  urldate = {2023-07-11},
  abstract = {Convolutional Neural Networks (CNNs) are highly effective for image reconstruction problems. Typically, CNNs are trained on large amounts of training images. Recently, however, un-trained CNNs such as the Deep Image Prior and Deep Decoder have achieved excellent performance for image reconstruction problems such as denoising and inpainting, \textbackslash emph\{without using any training data\}. Motivated by this development, we address the reconstruction problem arising in accelerated MRI with un-trained neural networks. We propose a highly optimized un-trained recovery approach based on a variation of the Deep Decoder and show that it significantly outperforms other un-trained methods, in particular sparsity-based classical compressed sensing methods and naive applications of un-trained neural networks. We also compare performance (both in terms of reconstruction accuracy and computational cost) in an ideal setup for trained methods, specifically on the fastMRI dataset, where the training and test data come from the same distribution. We find that our un-trained algorithm achieves similar performance to a baseline trained neural network, but a state-of-the-art trained network outperforms the un-trained one. Finally, we perform a comparison on a non-ideal setup where the train and test distributions are slightly different, and find that our un-trained method achieves similar performance to a state-of-the-art accelerated MRI reconstruction method.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing,Statistics - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/S6HJQ353/Darestani y Heckel - 2021 - Accelerated MRI with Un-trained Neural Networks.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/NH6654PY/2007.html}
}

@inproceedings{darestaniMeasuringRobustnessDeep2021,
  title = {Measuring {{Robustness}} in {{Deep Learning Based Compressive Sensing}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Darestani, Mohammad Zalbagi and Chaudhari, Akshay S. and Heckel, Reinhard},
  year = {2021},
  month = jul,
  pages = {2433--2444},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-07-18},
  abstract = {Deep neural networks give state-of-the-art accuracy for reconstructing images from few and noisy measurements, a problem arising for example in accelerated magnetic resonance imaging (MRI). However, recent works have raised concerns that deep-learning-based image reconstruction methods are sensitive to perturbations and are less robust than traditional methods: Neural networks (i) may be sensitive to small, yet adversarially-selected perturbations, (ii) may perform poorly under distribution shifts, and (iii) may fail to recover small but important features in an image. In order to understand the sensitivity to such perturbations, in this work, we measure the robustness of different approaches for image reconstruction including trained and un-trained neural networks as well as traditional sparsity-based methods. We find, contrary to prior works, that both trained and un-trained methods are vulnerable to adversarial perturbations. Moreover, both trained and un-trained methods tuned for a particular dataset suffer very similarly from distribution shifts. Finally, we demonstrate that an image reconstruction method that achieves higher reconstruction quality, also performs better in terms of accurately recovering fine details. Our results indicate that the state-of-the-art deep-learning-based image reconstruction methods provide improved performance than traditional methods without compromising robustness.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/EXQSTG3G/Darestani et al. - 2021 - Measuring Robustness in Deep Learning Based Compre.pdf}
}

@article{djebraManifoldLearningLinear2023,
  title = {Manifold {{Learning}} via {{Linear Tangent Space Alignment}} ({{LTSA}}) for {{Accelerated Dynamic MRI With Sparse Sampling}}},
  author = {Djebra, Yanis and Marin, Thibault and Han, Paul K. and Bloch, Isabelle and Fakhri, Georges El and Ma, Chao},
  year = {2023},
  month = jan,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {42},
  number = {1},
  pages = {158--169},
  issn = {1558-254X},
  doi = {10.1109/TMI.2022.3207774},
  abstract = {The spatial resolution and temporal frame-rate of dynamic magnetic resonance imaging (MRI) can be improved by reconstructing images from sparsely sampled k -space data with mathematical modeling of the underlying spatiotemporal signals. These models include sparsity models, linear subspace models, and non-linear manifold models. This work presents a novel linear tangent space alignment (LTSA) model-based framework that exploits the intrinsic low-dimensional manifold structure of dynamic images for accelerated dynamic MRI. The performance of the proposed method was evaluated and compared to state-of-the-art methods using numerical simulation studies as well as 2D and 3D in vivo cardiac imaging experiments. The proposed method achieved the best performance in image reconstruction among all the compared methods. The proposed method could prove useful for accelerating many MRI applications, including dynamic MRI, multi-parametric MRI, and MR spectroscopic imaging.},
  keywords = {Biomedical imaging,Constrained image reconstruction,Data models,dynamic magnetic resonance imaging,Image reconstruction,linear tangent space alignment (LTSA),Magnetic resonance imaging,manifold learning,Manifolds,Mathematical models,Transforms},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/4HQ74F94/Manifold_Learning_via_Linear_Tangent_Space_Alignment_LTSA_for_Accelerated_Dynamic_MRI_With_Sparse_Sampling.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/BD952MX4/Djebra et al. - 2023 - Manifold Learning via Linear Tangent Space Alignme.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/HS83PKZ6/stamp.html}
}

@article{donevaMathematicalModelsMagnetic2020,
  title = {Mathematical {{Models}} for {{Magnetic Resonance Imaging Reconstruction}}: {{An Overview}} of the {{Approaches}}, {{Problems}}, and {{Future Research Areas}}},
  shorttitle = {Mathematical {{Models}} for {{Magnetic Resonance Imaging Reconstruction}}},
  author = {Doneva, Mariya},
  year = {2020},
  month = jan,
  journal = {IEEE Signal Processing Magazine},
  volume = {37},
  number = {1},
  pages = {24--32},
  issn = {1558-0792},
  doi = {10.1109/MSP.2019.2936964},
  abstract = {Since its inception in the early 1970s [1], magnetic resonance imaging (MRI) has revolutionized radiology and medicine. Apart from high-quality data acquisition, image reconstruction is an important step to guarantee high image quality in MRI. Although the very first MR images were obtained from data resembling radial projections of the imaged object by applying an iterative reconstruction algorithm [1], non-Cartesian acquisition and iterative reconstruction techniques were not adopted in clinical MRI for many years, and, even today, their use is very limited. The reason for this is twofold. First, the underlying assumption that the measured data are radial projections of the imaged object fails in the presence of B0 field inhomogeneity and/or gradient waveform imperfections. Second, the long reconstruction times associated with iterative reconstruction algorithms limit their practical application.},
  keywords = {Compressed sensing,Encoding,Image reconstruction,Magnetic field measurement,Magnetic fields,Magnetic resonance imaging,Radio frequency},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/2LXZVNJM/Doneva - 2020 - Mathematical Models for Magnetic Resonance Imaging.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/3NA8CW38/Doneva - 2020 - Mathematical Models for Magnetic Resonance Imaging.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/USCEWHWS/8962368.html}
}

@article{el-rewaidyMultidomainConvolutionalNeural2021,
  title = {Multi-Domain Convolutional Neural Network ({{MD-CNN}}) for Radial Reconstruction of Dynamic Cardiac {{MRI}}},
  author = {{El-Rewaidy}, Hossam and Fahmy, Ahmed S. and Pashakhanloo, Farhad and Cai, Xiaoying and Kucukseymen, Selcuk and Csecs, Ibolya and Neisius, Ulf and {Haji-Valizadeh}, Hassan and Menze, Bjoern and Nezafat, Reza},
  year = {2021},
  journal = {Magnetic Resonance in Medicine},
  volume = {85},
  number = {3},
  pages = {1195--1208},
  issn = {1522-2594},
  doi = {10.1002/mrm.28485},
  urldate = {2022-11-28},
  abstract = {Purpose Cardiac MR cine imaging allows accurate and reproducible assessment of cardiac function. However, its long scan time not only limits the spatial and temporal resolutions but is challenging in patients with breath-holding difficulty or non-sinus rhythms. To reduce scan time, we propose a multi-domain convolutional neural network (MD-CNN) for fast reconstruction of highly undersampled radial cine images. Methods MD-CNN is a complex-valued network that processes MR data in k-space and image domains via k-space interpolation and image-domain subnetworks for residual artifact suppression. MD-CNN exploits spatio-temporal correlations across timeframes and multi-coil redundancies to enable high acceleration. Radial cine data were prospectively collected in 108 subjects (50 {$\pm$} 17 y, 72 males) using retrospective-gated acquisition with 80\%:20\% split for training/testing. Images were reconstructed by MD-CNN and k-t Radial Sparse-Sense(kt-RASPS) using an undersampled dataset (14 of 196 acquired views; relative acceleration rate = 14). MD-CNN images were evaluated quantitatively using mean-squared-error (MSE) and structural similarity index (SSIM) relative to reference images, and qualitatively by three independent readers for left ventricular (LV) border sharpness and temporal fidelity using 5-point Likert-scale (1-non-diagnostic, 2-poor, 3-fair, 4-good, and 5-excellent). Results MD-CNN showed improved MSE and SSIM compared to kt-RASPS (0.11 {$\pm$} 0.10 vs. 0.61 {$\pm$} 0.51, and 0.87 {$\pm$} 0.07 vs. 0.72 {$\pm$} 0.07, respectively; P {$<$} .01). Qualitatively, MD-CCN significantly outperformed kt-RASPS in LV border sharpness (3.87 {$\pm$} 0.66 vs. 2.71 {$\pm$} 0.58 at end-diastole, and 3.57 {$\pm$} 0.6 vs. 2.56 {$\pm$} 0.6 at end-systole, respectively; P {$<$} .01) and temporal fidelity (3.27 {$\pm$} 0.65 vs. 2.59 {$\pm$} 0.59; P {$<$} .01). Conclusion MD-CNN reduces the scan time of cine imaging by a factor of 23.3 and provides superior image quality compared to kt-RASPS.},
  langid = {english},
  keywords = {Cardiac MRI,deep learning,image reconstruction,non-cartesian acquisition,notion,radial acquisition,real-time imaging},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/NVM6HW9C/El-Rewaidy et al. - 2021 - Multi-domain convolutional neural network (MD-CNN).pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/VHYYAGBL/mrm.html}
}

@misc{el-rewaidyReplicationDataMultiDomain2020,
  title = {Replication {{Data}} for: {{Multi-Domain Convolutional Neural Network}} ({{MD-CNN}}) {{For Radial Reconstruction}} of {{Dynamic Cardiac MRI}}},
  shorttitle = {Replication {{Data}} For},
  author = {{El-Rewaidy}, Hossam},
  year = {2020},
  publisher = {{Harvard Dataverse}},
  doi = {10.7910/DVN/CI3WB6},
  urldate = {2023-07-14},
  abstract = {Datasets of radial cine cardiac MRI data collected from 108 subjects (101 patients and 7 healthy subjects). Codes for the Multi-domain network and data reading are also included. - Each .mat file contains a radial data with the following dimensions: (\#slices, \#phases, \#samples\_zero-padded\_over-sampled\_by2, \#radial\_views, \#coils, real\_and\_imaginary\_components). For example a dataset of size (1, 25, 832, 196, 16, 2) contains radial data from: 1 slice 25 cardiac phase 832 samples (including oversampling and zero-padding) 196 radial view per frame 16 coils 2 for real\&amp;imaginary components},
  collaborator = {{El-Rewaidy}, Hossam}
}

@article{fengGoldenAngleRadialMRI2022,
  title = {Golden-{{Angle Radial MRI}}: {{Basics}}, {{Advances}}, and {{Applications}}},
  shorttitle = {Golden-{{Angle Radial MRI}}},
  author = {Feng, Li},
  year = {2022},
  journal = {Journal of Magnetic Resonance Imaging},
  volume = {56},
  number = {1},
  pages = {45--62},
  issn = {1522-2586},
  doi = {10.1002/jmri.28187},
  urldate = {2022-12-16},
  abstract = {In recent years, golden-angle radial sampling has received substantial attention and interest in the magnetic resonance imaging (MRI) community, and it has become a popular sampling trajectory for both research and clinical use. However, although the number of relevant techniques and publications has grown rapidly, there is still a lack of a review paper that provides a comprehensive overview and summary of the basics of golden-angle rotation, the advantages and challenges/limitations of golden-angle radial sampling, and recommendations in using different types of golden-angle radial trajectories for MRI applications. Such a review paper is expected to be helpful both for clinicians who are interested in learning the potential benefits of golden-angle radial sampling and for MRI physicists who are interested in exploring this research direction. The main purpose of this review paper is thus to present an overview and summary about golden-angle radial MRI sampling. The review consists of three sections. The first section aims to answer basic questions such as: what is a golden angle; how is the golden angle calculated; why is golden-angle radial sampling useful, and what are its limitations. The second section aims to review more advanced trajectories of golden-angle radial sampling, including tiny golden-angle rotation, stack-of-stars golden-angle radial sampling, and three-dimensional (3D) kooshball golden-angle radial sampling. Their respective advantages and limitations and potential solutions to address these limitations are also discussed. Finally, the third section reviews MRI applications that can benefit from golden-angle radial sampling and provides recommendations to readers who are interested in implementing golden-angle radial trajectories in their MRI studies. Evidence Level 5 Technical Efficacy Stage 1},
  langid = {english},
  keywords = {continuous acquisition,golden-angle,motion robustness,radial sampling,self-navigation,stack-of-stars},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/JM9ZI6RG/Feng - 2022 - Golden-Angle Radial MRI Basics, Advances, and App.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/6M6PBTJL/jmri.html}
}

@article{fengGoldenangleRadialSparse2014,
  title = {Golden-Angle Radial Sparse Parallel {{MRI}}: Combination of Compressed Sensing, Parallel Imaging, and Golden-Angle Radial Sampling for Fast and Flexible Dynamic Volumetric {{MRI}}},
  shorttitle = {Golden-Angle Radial Sparse Parallel {{MRI}}},
  author = {Feng, Li and Grimm, Robert and Block, Kai Tobias and Chandarana, Hersh and Kim, Sungheon and Xu, Jian and Axel, Leon and Sodickson, Daniel K. and Otazo, Ricardo},
  year = {2014},
  month = sep,
  journal = {Magnetic Resonance in Medicine},
  volume = {72},
  number = {3},
  pages = {707--717},
  issn = {1522-2594},
  doi = {10.1002/mrm.24980},
  abstract = {PURPOSE: To develop a fast and flexible free-breathing dynamic volumetric MRI technique, iterative Golden-angle RAdial Sparse Parallel MRI (iGRASP), that combines compressed sensing, parallel imaging, and golden-angle radial sampling. METHODS: Radial k-space data are acquired continuously using the golden-angle scheme and sorted into time series by grouping an arbitrary number of consecutive spokes into temporal frames. An iterative reconstruction procedure is then performed on the undersampled time series where joint multicoil sparsity is enforced by applying a total-variation constraint along the temporal dimension. Required coil-sensitivity profiles are obtained from the time-averaged data. RESULTS: iGRASP achieved higher acceleration capability than either parallel imaging or coil-by-coil compressed sensing alone. It enabled dynamic volumetric imaging with high spatial and temporal resolution for various clinical applications, including free-breathing dynamic contrast-enhanced imaging in the abdomen of both adult and pediatric patients, and in the breast and neck of adult patients. CONCLUSION: The high performance and flexibility provided by iGRASP can improve clinical studies that require robustness to motion and simultaneous high spatial and temporal resolution. Magn Reson Med 72:707-717, 2014. \textcopyright{} 2013 Wiley Periodicals, Inc.},
  langid = {english},
  pmcid = {PMC3991777},
  pmid = {24142845},
  keywords = {Abdomen,Adult,Breast Diseases,{Child, Preschool},compressed sensing,Contrast Media,Data Compression,dynamic imaging,Female,Gadolinium DTPA,golden-angle,Head and Neck Neoplasms,Humans,Image Enhancement,{Image Interpretation, Computer-Assisted},{Imaging, Three-Dimensional},joint sparsity,Liver Diseases,Magnetic Resonance Imaging,Male,Middle Aged,parallel imaging,radial sampling,Tuberous Sclerosis},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/X2KT38D7/Feng et al. - 2014 - Golden-angle radial sparse parallel MRI combinati.pdf}
}

@misc{fengScanspecificUnsupervisedMethod2022,
  title = {A Scan-Specific Unsupervised Method for Parallel {{MRI}} Reconstruction via Implicit Neural Representation},
  author = {Feng, Ruimin and Wu, Qing and Zhang, Yuyao and Wei, Hongjiang},
  year = {2022},
  month = oct,
  number = {arXiv:2210.10439},
  eprint = {2210.10439},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2210.10439},
  urldate = {2023-04-26},
  abstract = {Parallel imaging is a widely-used technique to accelerate magnetic resonance imaging (MRI). However, current methods still perform poorly in reconstructing artifact-free MRI images from highly undersampled k-space data. Recently, implicit neural representation (INR) has emerged as a new deep learning paradigm for learning the internal continuity of an object. In this study, we adopted INR to parallel MRI reconstruction. The MRI image was modeled as a continuous function of spatial coordinates. This function was parameterized by a neural network and learned directly from the measured k-space itself without additional fully sampled high-quality training data. Benefitting from the powerful continuous representations provided by INR, the proposed method outperforms existing methods by suppressing the aliasing artifacts and noise, especially at higher acceleration rates and smaller sizes of the auto-calibration signals. The high-quality results and scanning specificity make the proposed method hold the potential for further accelerating the data acquisition of parallel MRI.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/FUAAMM6V/Feng et al. - 2022 - A scan-specific unsupervised method for parallel M.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/HT7ENULJ/2210.html}
}

@misc{fengSpatiotemporalImplicitNeural2023,
  title = {Spatiotemporal Implicit Neural Representation for Unsupervised Dynamic {{MRI}} Reconstruction},
  author = {Feng, Jie and Feng, Ruimin and Wu, Qing and Zhang, Zhiyong and Zhang, Yuyao and Wei, Hongjiang},
  year = {2023},
  month = jan,
  number = {arXiv:2301.00127},
  eprint = {2301.00127},
  primaryclass = {physics},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2301.00127},
  urldate = {2023-04-26},
  abstract = {Supervised Deep-Learning (DL)-based reconstruction algorithms have shown state-of-the-art results for highly-undersampled dynamic Magnetic Resonance Imaging (MRI) reconstruction. However, the requirement of excessive high-quality ground-truth data hinders their applications due to the generalization problem. Recently, Implicit Neural Representation (INR) has appeared as a powerful DL-based tool for solving the inverse problem by characterizing the attributes of a signal as a continuous function of corresponding coordinates in an unsupervised manner. In this work, we proposed an INR-based method to improve dynamic MRI reconstruction from highly undersampled k-space data, which only takes spatiotemporal coordinates as inputs. Specifically, the proposed INR represents the dynamic MRI images as an implicit function and encodes them into neural networks. The weights of the network are learned from sparsely-acquired (k, t)-space data itself only, without external training datasets or prior images. Benefiting from the strong implicit continuity regularization of INR together with explicit regularization for low-rankness and sparsity, our proposed method outperforms the compared scan-specific methods at various acceleration factors. E.g., experiments on retrospective cardiac cine datasets show an improvement of 5.5 \textasciitilde{} 7.1 dB in PSNR for extremely high accelerations (up to 41.6-fold). The high-quality and inner continuity of the images provided by INR has great potential to further improve the spatiotemporal resolution of dynamic MRI, without the need of any training data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing,Physics - Medical Physics},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/6DCLUVJK/Feng et al. - 2023 - Spatiotemporal implicit neural representation for .pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/8BXJFIDX/Feng et al. - 2023 - Spatiotemporal implicit neural representation for .pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/PLKBIZNV/2301.html}
}

@inproceedings{fengVIINTERViewInterpolation2022,
  title = {{{VIINTER}}: {{View Interpolation}} with {{Implicit Neural Representations}} of {{Images}}},
  shorttitle = {{{VIINTER}}},
  booktitle = {{{SIGGRAPH Asia}} 2022 {{Conference Papers}}},
  author = {Feng, Brandon Yushan and Jabbireddy, Susmija and Varshney, Amitabh},
  year = {2022},
  month = nov,
  series = {{{SA}} '22},
  pages = {1--9},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3550469.3555417},
  urldate = {2023-03-02},
  abstract = {We present VIINTER, a method for view interpolation by interpolating the implicit neural representation (INR) of the captured images. We leverage the learned code vector associated with each image and interpolate between these codes to achieve viewpoint transitions. We propose several techniques that significantly enhance the interpolation quality. VIINTER signifies a new way to achieve view interpolation without constructing 3D structure, estimating camera poses, or computing pixel correspondence. We validate the effectiveness of VIINTER on several multi-view scenes with different types of camera layout and scene composition. As the development of INR of images (as opposed to surface or volume) has centered around tasks like image fitting and super-resolution, with VIINTER, we show its capability for view interpolation and offer a promising outlook on using INR for image manipulation tasks.},
  isbn = {978-1-4503-9470-3},
  keywords = {coordinate network,implicit neural representation,view synthesis},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/CJDRSP9P/Feng et al. - 2022 - VIINTER View Interpolation with Implicit Neural R.pdf}
}

@article{fesslerNonuniformFastFourier2003,
  title = {Nonuniform Fast {{Fourier}} Transforms Using Min-Max Interpolation},
  author = {Fessler, J.A. and Sutton, B.P.},
  year = {2003},
  month = feb,
  journal = {IEEE Transactions on Signal Processing},
  volume = {51},
  number = {2},
  pages = {560--574},
  issn = {1941-0476},
  doi = {10.1109/TSP.2002.807005},
  abstract = {The fast Fourier transform (FFT) is used widely in signal processing for efficient computation of the FT of finite-length signals over a set of uniformly spaced frequency locations. However, in many applications, one requires nonuniform sampling in the frequency domain, i.e., a nonuniform FT. Several papers have described fast approximations for the nonuniform FT based on interpolating an oversampled FFT. This paper presents an interpolation method for the nonuniform FT that is optimal in the min-max sense of minimizing the worst-case approximation error over all signals of unit norm. The proposed method easily generalizes to multidimensional signals. Numerical results show that the min-max approach provides substantially lower approximation errors than conventional interpolation methods. The min-max criterion is also useful for optimizing the parameters of interpolation kernels such as the Kaiser-Bessel function.},
  keywords = {Approximation error,Fast Fourier transforms,Frequency domain analysis,Image reconstruction,Interpolation,Iterative methods,Magnetic resonance imaging,Multidimensional signal processing,Multidimensional systems,Nonuniform sampling},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/GYKVHJUM/Fessler y Sutton - 2003 - Nonuniform fast Fourier transforms using min-max i.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/SSIHDVKQ/1166689.html}
}

@article{fesslerOptimizationMethodsMagnetic2020,
  title = {Optimization {{Methods}} for {{Magnetic Resonance Image Reconstruction}}: {{Key Models}} and {{Optimization Algorithms}}},
  shorttitle = {Optimization {{Methods}} for {{Magnetic Resonance Image Reconstruction}}},
  author = {Fessler, Jeffrey A.},
  year = {2020},
  month = jan,
  journal = {IEEE Signal Processing Magazine},
  volume = {37},
  number = {1},
  pages = {33--40},
  issn = {1558-0792},
  doi = {10.1109/MSP.2019.2943645},
  abstract = {The development of compressed-sensing (CS) methods for magnetic resonance (MR) image reconstruction led to an explosion of research on models and optimization algorithms for MR imaging (MRI). Roughly 10 years after such methods first appeared in the MRI literature, the U.S. Food and Drug Administration (FDA) approved certain CS methods for commercial use, making CS a clinical success story for MRI. This article reports on several key models and optimization algorithms for MR image reconstruction. Included are both methods that the FDA has approved for clinical use and more recent methods being considered in the research community that use data-adaptive regularizers. It presents in a single survey the many algorithms devised to exploit the structure of the system model and regularizers used in MRI.},
  keywords = {Compressed sensing,Computational modeling,Cost function,Image reconstruction,Magnetic resonance imaging,Signal processing algorithms},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/NA6TU79K/Fessler - 2020 - Optimization Methods for Magnetic Resonance Image .pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/U9RFMLRJ/8962384.html}
}

@misc{fonsHyperTimeImplicitNeural2022,
  title = {{{HyperTime}}: {{Implicit Neural Representation}} for {{Time Series}}},
  shorttitle = {{{HyperTime}}},
  author = {Fons, Elizabeth and Sztrajman, Alejandro and {El-laham}, Yousef and Iosifidis, Alexandros and Vyetrenko, Svitlana},
  year = {2022},
  month = aug,
  number = {arXiv:2208.05836},
  eprint = {2208.05836},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2208.05836},
  urldate = {2023-03-29},
  abstract = {Implicit neural representations (INRs) have recently emerged as a powerful tool that provides an accurate and resolution-independent encoding of data. Their robustness as general approximators has been shown in a wide variety of data sources, with applications on image, sound, and 3D scene representation. However, little attention has been given to leveraging these architectures for the representation and analysis of time series data. In this paper, we analyze the representation of time series using INRs, comparing different activation functions in terms of reconstruction accuracy and training convergence speed. We show how these networks can be leveraged for the imputation of time series, with applications on both univariate and multivariate data. Finally, we propose a hypernetwork architecture that leverages INRs to learn a compressed latent representation of an entire time series dataset. We introduce an FFT-based loss to guide training so that all frequencies are preserved in the time series. We show that this network can be used to encode time series as INRs, and their embeddings can be interpolated to generate new time series from existing ones. We evaluate our generative method by using it for data augmentation, and show that it is competitive against current state-of-the-art approaches for augmentation of time series.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/9PVGVZCX/Fons et al. - 2022 - HyperTime Implicit Neural Representation for Time.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/CCKIAXIS/2208.html}
}

@article{gaoHierarchicalPerceptionAdversarial2023,
  title = {Hierarchical {{Perception Adversarial Learning Framework}} for {{Compressed Sensing MRI}}},
  author = {Gao, Zhifan and Guo, Yifeng and Zhang, Jiajing and Zeng, Tieyong and Yang, Guang},
  year = {2023},
  journal = {IEEE Transactions on Medical Imaging},
  pages = {1--1},
  issn = {1558-254X},
  doi = {10.1109/TMI.2023.3240862},
  abstract = {The long acquisition time has limited the accessibility of magnetic resonance imaging (MRI) because it leads to patient discomfort and motion artifacts. Although several MRI techniques have been proposed to reduce the acquisition time, compressed sensing in magnetic resonance imaging (CS-MRI) enables fast acquisition without compromising SNR and resolution. However, existing CS-MRI methods suffer from the challenge of aliasing artifacts. This challenge results in the noise-like textures and missing the fine details, thus leading to unsatisfactory reconstruction performance. To tackle this challenge, we propose a hierarchical perception adversarial learning framework (HP-ALF). HP-ALF can perceive the image information in the hierarchical mechanism: image-level perception and patch-level perception. The former can reduce the visual perception difference in the entire image, and thus achieve aliasing artifact removal. The latter can reduce this difference in the regions of the image, and thus recover fine details. Specifically, HP-ALF achieves the hierarchical mechanism by utilizing multilevel perspective discrimination. This discrimination can provide the information from two perspectives (overall and regional) for adversarial learning. It also utilizes a global and local coherent discriminator to provide structure information to the generator during training. In addition, HP-ALF contains a context-aware learning block to effectively exploit the slice information between individual images for better reconstruction performance. The experiments validated on three datasets demonstrate the effectiveness of HP-ALF and its superiority to the comparative methods.},
  keywords = {Compressed Sensing,Data mining,Feature extraction,Generative Adversarial Networks,Image reconstruction,Image restoration,Magnetic resonance imaging,Magnetic Resonance Imaging,MRI Reconstruction,Visual perception,Visualization},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/83LU2KZD/Gao et al. - 2023 - Hierarchical Perception Adversarial Learning Frame.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/BZQPJMYS/Hierarchical_Perception_Adversarial_Learning_Framework_for_Compressed_Sensing_MRI.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/UAZEWLZZ/stamp.html}
}

@article{griswoldGeneralizedAutocalibratingPartially2002,
  title = {Generalized Autocalibrating Partially Parallel Acquisitions ({{GRAPPA}})},
  author = {Griswold, Mark A. and Jakob, Peter M. and Heidemann, Robin M. and Nittka, Mathias and Jellus, Vladimir and Wang, Jianmin and Kiefer, Berthold and Haase, Axel},
  year = {2002},
  month = jun,
  journal = {Magnetic Resonance in Medicine},
  volume = {47},
  number = {6},
  pages = {1202--1210},
  issn = {0740-3194},
  doi = {10.1002/mrm.10171},
  abstract = {In this study, a novel partially parallel acquisition (PPA) method is presented which can be used to accelerate image acquisition using an RF coil array for spatial encoding. This technique, GeneRalized Autocalibrating Partially Parallel Acquisitions (GRAPPA) is an extension of both the PILS and VD-AUTO-SMASH reconstruction techniques. As in those previous methods, a detailed, highly accurate RF field map is not needed prior to reconstruction in GRAPPA. This information is obtained from several k-space lines which are acquired in addition to the normal image acquisition. As in PILS, the GRAPPA reconstruction algorithm provides unaliased images from each component coil prior to image combination. This results in even higher SNR and better image quality since the steps of image reconstruction and image combination are performed in separate steps. After introducing the GRAPPA technique, primary focus is given to issues related to the practical implementation of GRAPPA, including the reconstruction algorithm as well as analysis of SNR in the resulting images. Finally, in vivo GRAPPA images are shown which demonstrate the utility of the technique.},
  langid = {english},
  pmid = {12111967},
  keywords = {Algorithms,Calibration,Computer Simulation,Humans,{Image Processing, Computer-Assisted},Magnetic Resonance Imaging,{Models, Theoretical}},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/K2NPG3NG/Griswold et al. - 2002 - Generalized autocalibrating partially parallel acq.pdf}
}

@article{hammernikPhysicsDrivenDeepLearning2023,
  title = {Physics-{{Driven Deep Learning}} for {{Computational Magnetic Resonance Imaging}}: {{Combining}} Physics and Machine Learning for Improved Medical Imaging},
  shorttitle = {Physics-{{Driven Deep Learning}} for {{Computational Magnetic Resonance Imaging}}},
  author = {Hammernik, Kerstin and K{\"u}stner, Thomas and Yaman, Burhaneddin and Huang, Zhengnan and Rueckert, Daniel and Knoll, Florian and Ak{\c c}akaya, Mehmet},
  year = {2023},
  month = jan,
  journal = {IEEE Signal Processing Magazine},
  volume = {40},
  number = {1},
  pages = {98--114},
  issn = {1558-0792},
  doi = {10.1109/MSP.2022.3215288},
  abstract = {Physics-driven deep learning methods have emerged as a powerful tool for computational magnetic resonance imaging (MRI) problems, pushing reconstruction performance to new limits. This article provides an overview of the recent developments in incorporating physics information into learning-based MRI reconstruction. We consider inverse problems with both linear and nonlinear forward models for computational MRI and review the classical approaches for solving these. We then focus on physics-driven deep learning approaches, covering physics-driven loss functions, plug-and-play (PnP) methods, generative models, and unrolled networks. We highlight domain-specific challenges, such as real- and complex-valued building blocks of neural networks, and translational applications in MRI with linear and nonlinear forward models. Finally, we discuss common issues and open challenges, and we draw connections to the importance of physics-driven learning when combined with other downstream tasks in the medical imaging pipeline.},
  keywords = {Computational modeling,Deep learning,Inverse problems,Magnetic resonance imaging,Pipelines,Signal processing,Task analysis},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/FPKTWZ69/Hammernik et al. - 2023 - Physics-Driven Deep Learning for Computational Mag.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/ZMRYYBQ7/stamp.html}
}

@article{hammernikSystematicEvaluationIterative2021,
  title = {Systematic Evaluation of Iterative Deep Neural Networks for Fast Parallel {{MRI}} Reconstruction with Sensitivity-Weighted Coil Combination},
  author = {Hammernik, Kerstin and Schlemper, Jo and Qin, Chen and Duan, Jinming and Summers, Ronald M. and Rueckert, Daniel},
  year = {2021},
  journal = {Magnetic Resonance in Medicine},
  volume = {86},
  number = {4},
  pages = {1859--1872},
  issn = {1522-2594},
  doi = {10.1002/mrm.28827},
  urldate = {2023-04-25},
  abstract = {Purpose To systematically investigate the influence of various data consistency layers and regularization networks with respect to variations in the training and test data domain, for sensitivity-encoded accelerated parallel MR image reconstruction. Theory and Methods Magnetic resonance (MR) image reconstruction is formulated as a learned unrolled optimization scheme with a down-up network as regularization and varying data consistency layers. The proposed networks are compared to other state-of-the-art approaches on the publicly available fastMRI knee and neuro dataset and tested for stability across different training configurations regarding anatomy and number of training samples. Results Data consistency layers and expressive regularization networks, such as the proposed down-up networks, form the cornerstone for robust MR image reconstruction. Physics-based reconstruction networks outperform post-processing methods substantially for R = 4 in all cases and for R = 8 when the training and test data are aligned. At R = 8, aligning training and test data is more important than architectural choices. Conclusion In this work, we study how dataset sizes affect single-anatomy and cross-anatomy training of neural networks for MRI reconstruction. The study provides insights into the robustness, properties, and acceleration limits of state-of-the-art networks, and our proposed down-up networks. These key insights provide essential aspects to successfully translate learning-based MRI reconstruction to clinical practice, where we are confronted with limited datasets and various imaged anatomies.},
  langid = {english},
  keywords = {data consistency,deep learning,domain shift,down-up networks,fastMRI,iterative image reconstruction,parallel imaging},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/344ESNVH/Hammernik et al. - 2021 - Systematic evaluation of iterative deep neural net.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/A6Z9WF5H/mrm.html}
}

@misc{heckelDeepDecoderConcise2019,
  title = {Deep {{Decoder}}: {{Concise Image Representations}} from {{Untrained Non-convolutional Networks}}},
  shorttitle = {Deep {{Decoder}}},
  author = {Heckel, Reinhard and Hand, Paul},
  year = {2019},
  month = feb,
  number = {arXiv:1810.03982},
  eprint = {1810.03982},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-07-11},
  abstract = {Deep neural networks, in particular convolutional neural networks, have become highly effective tools for compressing images and solving inverse problems including denoising, inpainting, and reconstruction from few and noisy measurements. This success can be attributed in part to their ability to represent and generate natural images well. Contrary to classical tools such as wavelets, image-generating deep neural networks have a large number of parameters---typically a multiple of their output dimension---and need to be trained on large datasets. In this paper, we propose an untrained simple image model, called the deep decoder, which is a deep neural network that can generate natural images from very few weight parameters. The deep decoder has a simple architecture with no convolutions and fewer weight parameters than the output dimensionality. This underparameterization enables the deep decoder to compress images into a concise set of network weights, which we show is on par with wavelet-based thresholding. Further, underparameterization provides a barrier to overfitting, allowing the deep decoder to have state-of-the-art performance for denoising. The deep decoder is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel-wise linear combination of channels, ReLU activation, and channelwise normalization. This simplicity makes the network amenable to theoretical analysis, and it sheds light on the aspects of neural networks that enable them to form effective signal representations.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/Z46SP46W/Heckel y Hand - 2019 - Deep Decoder Concise Image Representations from U.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/8Q8A8MAF/1810.html}
}

@misc{hoffmanProbNeRFUncertaintyAwareInference2022,
  title = {{{ProbNeRF}}: {{Uncertainty-Aware Inference}} of {{3D Shapes}} from {{2D Images}}},
  shorttitle = {{{ProbNeRF}}},
  author = {Hoffman, Matthew D. and Le, Tuan Anh and Sountsov, Pavel and Suter, Christopher and Lee, Ben and Mansinghka, Vikash K. and Saurous, Rif A.},
  year = {2022},
  month = oct,
  number = {arXiv:2210.17415},
  eprint = {2210.17415},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2210.17415},
  urldate = {2023-03-02},
  abstract = {The problem of inferring object shape from a single 2D image is underconstrained. Prior knowledge about what objects are plausible can help, but even given such prior knowledge there may still be uncertainty about the shapes of occluded parts of objects. Recently, conditional neural radiance field (NeRF) models have been developed that can learn to infer good point estimates of 3D models from single 2D images. The problem of inferring uncertainty estimates for these models has received less attention. In this work, we propose probabilistic NeRF (ProbNeRF), a model and inference strategy for learning probabilistic generative models of 3D objects' shapes and appearances, and for doing posterior inference to recover those properties from 2D images. ProbNeRF is trained as a variational autoencoder, but at test time we use Hamiltonian Monte Carlo (HMC) for inference. Given one or a few 2D images of an object (which may be partially occluded), ProbNeRF is able not only to accurately model the parts it sees, but also to propose realistic and diverse hypotheses about the parts it does not see. We show that key to the success of ProbNeRF are (i) a deterministic rendering scheme, (ii) an annealed-HMC strategy, (iii) a hypernetwork-based decoder architecture, and (iv) doing inference over a full set of NeRF weights, rather than just a low-dimensional code.},
  archiveprefix = {arxiv},
  keywords = {62F15 (Primary) 68T45 (Secondary),Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,G.3,I.4.10,I.5.1},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/TVPC4R4Y/Hoffman et al. - 2022 - ProbNeRF Uncertainty-Aware Inference of 3D Shapes.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/KSLTT4EK/2210.html}
}

@misc{huangUnsupervisedDeepUnrolled2022,
  title = {Unsupervised {{Deep Unrolled Reconstruction Using Regularization}} by {{Denoising}}},
  author = {Huang, Peizhou and Zhang, Chaoyi and Zhang, Xiaoliang and Li, Xiaojuan and Dong, Liang and Ying, Leslie},
  year = {2022},
  month = sep,
  number = {arXiv:2205.03519},
  eprint = {2205.03519},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2205.03519},
  urldate = {2023-04-26},
  abstract = {Deep learning methods have been successfully used in various computer vision tasks. Inspired by that success, deep learning has been explored in magnetic resonance imaging (MRI) reconstruction. In particular, integrating deep learning and model-based optimization methods has shown considerable advantages. However, a large amount of labeled training data is typically needed for high reconstruction quality, which is challenging for some MRI applications. In this paper, we propose a novel reconstruction method, named DURED-Net, that enables interpretable unsupervised learning for MR image reconstruction by combining an unsupervised denoising network and a plug-and-play method. We aim to boost the reconstruction performance of unsupervised learning by adding an explicit prior that utilizes imaging physics. Specifically, the leverage of a denoising network for MRI reconstruction is achieved using Regularization by Denoising (RED). Experiment results demonstrate that the proposed method requires a reduced amount of training data to achieve high reconstruction quality.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/E59S4XXR/Huang et al. - 2022 - Unsupervised Deep Unrolled Reconstruction Using Re.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/AYY4X6YF/2205.html}
}

@article{hyunDeepLearningUndersampled2018,
  title = {Deep Learning for Undersampled {{MRI}} Reconstruction},
  author = {Hyun, Chang Min and Kim, Hwa Pyung and Lee, Sung Min and Lee, Sungchul and Seo, Jin Keun},
  year = {2018},
  month = jun,
  journal = {Physics in Medicine \& Biology},
  volume = {63},
  number = {13},
  pages = {135007},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aac71a},
  urldate = {2023-07-07},
  abstract = {This paper presents a deep learning method for faster magnetic resonance imaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and provides a rationale for why the proposed approach works well. Uniform subsampling is used in the time-consuming phase-encoding direction to capture high-resolution image information, while permitting the image-folding problem dictated by the Poisson summation formula. To deal with the localization uncertainty due to image folding, a small number of low-frequency k-space data are added. Training the deep learning net involves input and output images that are pairs of the Fourier transforms of the subsampled and fully sampled k-space data. Our experiments show the remarkable performance of the proposed method; only 29 of the k-space data can generate images of high quality as effectively as standard MRI reconstruction with the fully sampled data.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/AP8DCHN4/Hyun et al. - 2018 - Deep learning for undersampled MRI reconstruction.pdf}
}

@misc{jeongTimeSeriesAnomalyDetection2022,
  title = {Time-{{Series Anomaly Detection}} with {{Implicit Neural Representation}}},
  author = {Jeong, Kyeong-Joong and Shin, Yong-Min},
  year = {2022},
  month = jan,
  number = {arXiv:2201.11950},
  eprint = {2201.11950},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-03-29},
  abstract = {Detecting anomalies in multivariate time-series data is essential in many real-world applications. Recently, various deep learning-based approaches have shown considerable improvements in time-series anomaly detection. However, existing methods still have several limitations, such as long training time due to their complex model designs or costly tuning procedures to find optimal hyperparameters (e.g., sliding window length) for a given dataset. In our paper, we propose a novel method called Implicit Neural Representation-based Anomaly Detection (INRAD). Specifically, we train a simple multi-layer perceptron that takes time as input and outputs corresponding values at that time. Then we utilize the representation error as an anomaly score for detecting anomalies. Experiments on five real-world datasets demonstrate that our proposed method outperforms other state-of-the-art methods in performance, training speed, and robustness.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/34FP2YW3/Jeong y Shin - 2022 - Time-Series Anomaly Detection with Implicit Neural.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/3FJULAA9/2201.html}
}

@article{karniadakisPhysicsinformedMachineLearning2021,
  title = {Physics-Informed Machine Learning},
  author = {Karniadakis, George Em and Kevrekidis, Ioannis G. and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
  year = {2021},
  month = may,
  journal = {Nature Reviews Physics},
  volume = {3},
  number = {6},
  pages = {422--440},
  issn = {2522-5820},
  doi = {10.1038/s42254-021-00314-5},
  urldate = {2023-05-10},
  abstract = {Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-d imensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-t ime domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-b ased regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-d imensional problems.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/B56N4LPX/Karniadakis et al. - 2021 - Physics-informed machine learning.pdf;G\:\\.shortcut-targets-by-id\\1bswZvnBiuixrTBsf70wYo9mQEB_gF29T\\Tabitas_Project\\Nature-REviews_GK.pdf}
}

@article{keDeepManifoldLearning2021,
  title = {Deep {{Manifold Learning}} for {{Dynamic MR Imaging}}},
  author = {Ke, Ziwen and Cui, Zhuo-Xu and Huang, Wenqi and Cheng, Jing and Jia, Sen and Ying, Leslie and Zhu, Yanjie and Liang, Dong},
  year = {2021},
  journal = {IEEE Transactions on Computational Imaging},
  volume = {7},
  pages = {1314--1327},
  issn = {2333-9403},
  doi = {10.1109/TCI.2021.3131564},
  abstract = {Recently, low-dimensional manifold regularization has been recognized as a competitive method for accelerated cardiac MRI, due to its ability to capture temporal correlations. However, existing methods have not been performed with the nonlinear structure of an underlying manifold. In this paper, we propose a deep learning method in an unrolling manner for accelerated cardiac MRI on a low-dimensional manifold. Specifically, a fixed low-rank tensor (Riemannian) manifold is chosen to capture the strong temporal correlations of dynamic signals; the reconstruction problem is modeled as a CS-based optimization problem on this manifold. Following the manifold structure, a Riemannian gradient descent (RGD) method is adopted to solve this problem. Finally, the RGD algorithm is unrolled into a neural network, called Manifold-Net, on the manifold to avoid the long computation time and the challenging parameter selection. The experimental results at high accelerations demonstrate that the proposed method can obtain improved reconstruction compared with three conventional methods (k-t SLR, SToRM and k-t MLSD) and three state-of-the-art deep learning-based methods (DC-CNN, CRNN, and SLR-Net). To our knowledge, this work represents the first study to unroll the iterative optimization procedure into neural networks on manifolds. Moreover, the designed Manifold-Net provides a new mechanism for low-rank priors in dynamic MRI and should also prove useful for fast reconstruction in other dynamic imaging problems.},
  keywords = {Correlation,deep learning,Dynamic MR imaging,Image reconstruction,Imaging,low-rank,Magnetic resonance imaging,manifold learning,Manifolds,Optimization,Riemannian optimization,Tensors},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/RVM6YW8I/Ke et al. - 2021 - Deep Manifold Learning for Dynamic MR Imaging.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/2QE5TCRN/9632354.html}
}

@article{keUnsupervisedDeepLearning2020a,
  title = {An Unsupervised Deep Learning Method for Multi-Coil Cine {{MRI}}},
  author = {Ke, Ziwen and Cheng, Jing and Ying, Leslie and Zheng, Hairong and Zhu, Yanjie and Liang, Dong},
  year = {2020},
  month = nov,
  journal = {Physics in Medicine \& Biology},
  volume = {65},
  number = {23},
  pages = {235041},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/abaffa},
  urldate = {2023-04-24},
  abstract = {Deep learning has achieved good success in cardiac magnetic resonance imaging (MRI) reconstruction, in which convolutional neural networks (CNNs) learn a mapping from the undersampled k-space to the fully sampled images. Although these deep learning methods can improve the reconstruction quality compared with iterative methods without requiring complex parameter selection or lengthy reconstruction time, the following issues still need to be addressed: 1) all these methods are based on big data and require a large amount of fully sampled MRI data, which is always difficult to obtain for cardiac MRI; 2) the effect of coil correlation on reconstruction in deep learning methods for dynamic MR imaging has never been studied. In this paper, we propose an unsupervised deep learning method for multi-coil cine MRI via a time-interleaved sampling strategy. Specifically, a time-interleaved acquisition scheme is utilized to build a set of fully encoded reference data by directly merging the k-space data of adjacent time frames. Then these fully encoded data can be used to train a parallel network for reconstructing images of each coil separately. Finally, the images from each coil are combined via a CNN to implicitly explore the correlations between coils. The comparisons with classic k-t FOCUSS, k-t SLR, L+S and KLR methods on in vivo datasets show that our method can achieve improved reconstruction results in an extremely short amount of time.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/4QQUHIXP/Ke et al. - 2020 - An unsupervised deep learning method for multi-coi.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/IL7BMUC2/Ke et al. - 2020 - An unsupervised deep learning method for multi-coi.pdf}
}

@misc{kimGeneralizableImplicitNeural2022,
  title = {Generalizable {{Implicit Neural Representations}} via {{Instance Pattern Composers}}},
  author = {Kim, Chiheon and Lee, Doyup and Kim, Saehoon and Cho, Minsu and Han, Wook-Shin},
  year = {2022},
  month = nov,
  number = {arXiv:2211.13223},
  eprint = {2211.13223},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-11-28},
  abstract = {Despite recent advances in implicit neural representations (INRs), it remains challenging for a coordinate-based multi-layer perceptron (MLP) of INRs to learn a common representation across data instances and generalize it for unseen instances. In this work, we introduce a simple yet effective framework for generalizable INRs that enables a coordinate-based MLP to represent complex data instances by modulating only a small set of weights in an early MLP layer as an instance pattern composer; the remaining MLP weights learn pattern composition rules for common representations across instances. Our generalizable INR framework is fully compatible with existing meta-learning and hypernetworks in learning to predict the modulated weight for unseen instances. Extensive experiments demonstrate that our method achieves high performance on a wide range of domains such as an audio, image, and 3D object, while the ablation study validates our weight modulation.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/2D5RNXX8/Kim et al. - 2022 - Generalizable Implicit Neural Representations via .pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/SWAW63TS/2211.html}
}

@article{kingmaAdamMethodStochastic2014,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2014},
  month = dec,
  journal = {CoRR},
  urldate = {2023-06-29},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/24H5ERW9/Kingma and Ba - 2014 - Adam A Method for Stochastic Optimization.pdf}
}

@article{kleineiselRealtimeCardiacMRI2022,
  title = {Real-Time Cardiac {{MRI}} Using an Undersampled Spiral k-Space Trajectory and a Reconstruction Based on a Variational Network},
  author = {Kleineisel, Jonas and Heidenreich, Julius F. and Eirich, Philipp and Petri, Nils and K{\"o}stler, Herbert and Petritsch, Bernhard and Bley, Thorsten A. and Wech, Tobias},
  year = {2022},
  journal = {Magnetic Resonance in Medicine},
  volume = {88},
  number = {5},
  pages = {2167--2178},
  issn = {1522-2594},
  doi = {10.1002/mrm.29357},
  urldate = {2022-11-03},
  abstract = {Purpose Cardiac MRI represents the gold standard to determine myocardial function. However, the current clinical standard protocol, a segmented Cartesian acquisition, is time-consuming and can lead to compromised image quality in the case of arrhythmia or dyspnea. In this article, a machine learning\textendash based reconstruction of undersampled spiral k-space data is presented to enable free breathing real-time cardiac MRI with good image quality and short reconstruction times. Methods Data were acquired in free breathing with a 2D spiral trajectory corrected by the gradient system transfer function. Undersampled data were reconstructed by a variational network (VN), which was specifically adapted to the non-Cartesian sampling pattern. The network was trained with data from 11 subjects. Subsequently, the imaging technique was validated in 14 subjects by quantifying the difference to a segmented reference acquisition, an expert reader study, and by comparing derived volumes and functional parameters with values obtained using the current clinical gold standard. Results The scan time for the entire heart was below 1 min. The VN reconstructed data in about 0.9 s per image, which is considerably shorter than conventional model-based approaches. The VN furthermore performed better than a U-Net and not inferior to a low-rank plus sparse model in terms of achieved image quality. Functional parameters agreed, on average, with reference data. Conclusions The proposed VN method enables real-time cardiac imaging with both high spatial and temporal resolution in free breathing and with short reconstruction time.},
  langid = {english},
  keywords = {cardiac imaging,convolutional neural network,heart,machine learning,magnetic resonance imaging,notion,variational network},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/9TD4JXPC/Kleineisel et al. - 2022 - Real-time cardiac MRI using an undersampled spiral.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/MLXGMTHI/mrm.html}
}

@article{knollDeepLearningMethodsParallel2020,
  title = {Deep-{{Learning Methods}} for {{Parallel Magnetic Resonance Imaging Reconstruction}}: {{A Survey}} of the {{Current Approaches}}, {{Trends}}, and {{Issues}}},
  shorttitle = {Deep-{{Learning Methods}} for {{Parallel Magnetic Resonance Imaging Reconstruction}}},
  author = {Knoll, Florian and Hammernik, Kerstin and Zhang, Chi and Moeller, Steen and Pock, Thomas and Sodickson, Daniel K. and Akcakaya, Mehmet},
  year = {2020},
  month = jan,
  journal = {IEEE Signal Processing Magazine},
  volume = {37},
  number = {1},
  pages = {128--140},
  issn = {1558-0792},
  doi = {10.1109/MSP.2019.2950640},
  abstract = {Following the success of deep learning in a wide range of applications, neural network-based machine-learning techniques have received interest as a means of accelerating magnetic resonance imaging (MRI). A number of ideas inspired by deep-learning techniques for computer vision and image processing have been successfully applied to nonlinear image reconstruction in the spirit of compressed sensing for both low-dose computed tomography and accelerated MRI. The additional integration of multicoil information to recover missing k-space lines in the MRI reconstruction process is studied less frequently, even though it is the de facto standard for the currently used accelerated MR acquisitions. This article provides an overview of the recent machine-learning approaches that have been proposed specifically for improving parallel imaging. A general background introduction to parallel MRI is given and structured around the classical view of image- and k-space-based methods. Linear and nonlinear methods are covered, followed by a discussion of the recent efforts to further improve parallel imaging using machine learning and, specifically, artificial neural networks. Image domain-based techniques that introduce improved regularizers are covered as well as k-space-based methods, where the focus is on better interpolation strategies using neural networks. Issues and open problems are discussed and recent efforts for producing open data sets and benchmarks for the community are examined.},
  keywords = {Compressed sensing,Image reconstruction,Machine learning,Magnetic resonance imaging},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/ZXCEX3IS/Knoll et al. - 2020 - Deep-Learning Methods for Parallel Magnetic Resona.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/7QG9QWYS/getPDF.html}
}

@article{koflerEndtoendtrainableIterativeNetwork2021,
  title = {An End-to-End-Trainable Iterative Network Architecture for Accelerated Radial Multi-Coil {{2D}} Cine {{MR}} Image Reconstruction},
  author = {Kofler, Andreas and Haltmeier, Markus and Schaeffter, Tobias and Kolbitsch, Christoph},
  year = {2021},
  month = may,
  journal = {Medical Physics},
  volume = {48},
  number = {5},
  pages = {2412--2425},
  issn = {2473-4209},
  doi = {10.1002/mp.14809},
  abstract = {PURPOSE: Iterative convolutional neural networks (CNNs) which resemble unrolled learned iterative schemes have shown to consistently deliver state-of-the-art results for image reconstruction problems across different imaging modalities. However, because these methods include the forward model in the architecture, their applicability is often restricted to either relatively small reconstruction problems or to problems with operators which are computationally cheap to compute. As a consequence, they have not been applied to dynamic non-Cartesian multi-coil reconstruction problems so far. METHODS: In this work, we propose a CNN architecture for image reconstruction of accelerated 2D radial cine MRI with multiple receiver coils. The network is based on a computationally light CNN component and a subsequent conjugate gradient (CG) method which can be jointly trained end-to-end using an efficient training strategy. We investigate the proposed training strategy and compare our method with other well-known reconstruction techniques with learned and non-learned regularization methods. RESULTS: Our proposed method outperforms all other methods based on non-learned regularization. Further, it performs similar or better than a CNN-based method employing a 3D U-Net and a method using adaptive dictionary learning. In addition, we empirically demonstrate that even by training the network with only iteration, it is possible to increase the length of the network at test time and further improve the results. CONCLUSIONS: End-to-end training allows to highly reduce the number of trainable parameters of and stabilize the reconstruction network. Further, because it is possible to change the length of the network at the test time, the need to find a compromise between the complexity of the CNN-block and the number of iterations in each CG-block becomes irrelevant.},
  langid = {english},
  pmid = {33651398},
  keywords = {deep learning,{Image Processing, Computer-Assisted},inverse problems,magnetic resonance imaging,Magnetic Resonance Imaging,{Magnetic Resonance Imaging, Cine},neural networks,{Neural Networks, Computer}},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/FE6ZTT44/Kofler et al. - 2021 - An end-to-end-trainable iterative network architec.pdf}
}

@article{koflerSpatioTemporalDeepLearningBased2020a,
  title = {Spatio-{{Temporal Deep Learning-Based Undersampling Artefact Reduction}} for {{2D Radial Cine MRI With Limited Training Data}}},
  author = {Kofler, Andreas and Dewey, Marc and Schaeffter, Tobias and Wald, Christian and Kolbitsch, Christoph},
  year = {2020},
  month = mar,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {39},
  number = {3},
  pages = {703--717},
  issn = {1558-254X},
  doi = {10.1109/TMI.2019.2930318},
  abstract = {In this work we reduce undersampling artefacts in two-dimensional (2D) golden-angle radial cine cardiac MRI by applying a modified version of the U-net. The network is trained on 2D spatio-temporal slices which are previously extracted from the image sequences. We compare our approach to two 2D and a 3D deep learning-based post processing methods, three iterative reconstruction methods and two recently proposed methods for dynamic cardiac MRI based on 2D and 3D cascaded networks. Our method outperforms the 2D spatially trained U-net and the 2D spatio-temporal U-net. Compared to the 3D spatio-temporal U-net, our method delivers comparable results, but requiring shorter training times and less training data. Compared to the compressed sensing-based methods kt-FOCUSS and a total variation regularized reconstruction approach, our method improves image quality with respect to all reported metrics. Further, it achieves competitive results when compared to the iterative reconstruction method based on adaptive regularization with dictionary learning and total variation and when compared to the methods based on cascaded networks, while only requiring a small fraction of the computational and training time. A persistent homology analysis demonstrates that the data manifold of the spatio-temporal domain has a lower complexity than the one of the spatial domain and therefore, the learning of a projection-like mapping is facilitated. Even when trained on only one single subject without data-augmentation, our approach yields results which are similar to the ones obtained on a large training dataset. This makes the method particularly suitable for training a network on limited training data. Finally, in contrast to the spatial 2D U-net, our proposed method is shown to be naturally robust with respect to image rotation in image space and almost achieves rotation-equivariance where neither data-augmentation nor a particular network design are required.},
  keywords = {Biomedical imaging,compressed sensing,Deep learning,dynamic MRI,image processing,Image reconstruction,Image sequences,Magnetic resonance imaging,neural networks,persistent homology analysis,Three-dimensional displays,Training,Two dimensional displays},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/JKURVQ2C/Kofler et al. - 2020 - Spatio-Temporal Deep Learning-Based Undersampling .pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/ZCS9AMCA/8793147.html}
}

@inproceedings{korkmazDeepMRIReconstruction2021,
  title = {Deep {{MRI Reconstruction}} with {{Generative Vision Transformers}}},
  booktitle = {Machine {{Learning}} for {{Medical Image Reconstruction}}},
  author = {Korkmaz, Yilmaz and Yurt, Mahmut and Dar, Salman Ul Hassan and {\"O}zbey, Muzaffer and Cukur, Tolga},
  editor = {Haq, Nandinee and Johnson, Patricia and Maier, Andreas and W{\"u}rfl, Tobias and Yoo, Jaejun},
  year = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {54--64},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-88552-6\_6},
  abstract = {Supervised training of deep network models for MRI reconstruction requires access to large databases of fully-sampled MRI acquisitions. To alleviate dependency on costly databases, unsupervised learning strategies have received interest. A powerful framework that eliminates the need for training data altogether is the deep image prior (DIP). To do this, DIP inverts randomly-initialized models to infer network parameters most consistent with the undersampled test data. However, existing DIP methods leverage convolutional backbones, suffering from limited sensitivity to long-range spatial dependencies and thereby poor model invertibility. To address these limitations, here we propose an unsupervised MRI reconstruction based on a novel generative vision transformer (GVTrans). GVTrans progressively maps low-dimensional noise and latent variables onto MR images via cascaded blocks of cross-attention vision transformers. Cross-attention mechanism between latents and image features serve to enhance representational learning of local and global context. Meanwhile, latent and noise injections at each network layer permit fine control of generated image features, improving model invertibility. Demonstrations are performed for scan-specific reconstruction of brain MRI data at multiple contrasts and acceleration factors. GVTrans yields superior performance to state-of-the-art generative models based on convolutional neural networks (CNNs).},
  isbn = {978-3-030-88552-6},
  langid = {english},
  keywords = {Attention,Generative,MRI reconstruction,Transformer,Unsupervised},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/YFPRMBQ2/Korkmaz et al. - 2021 - Deep MRI Reconstruction with Generative Vision Tra.pdf}
}

@article{korkmazUnsupervisedMRIReconstruction2022,
  title = {Unsupervised {{MRI Reconstruction}} via {{Zero-Shot Learned Adversarial Transformers}}},
  author = {Korkmaz, Yilmaz and Dar, Salman U. H. and Yurt, Mahmut and {\"O}zbey, Muzaffer and {\c C}ukur, Tolga},
  year = {2022},
  month = jul,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {41},
  number = {7},
  pages = {1747--1763},
  issn = {1558-254X},
  doi = {10.1109/TMI.2022.3147426},
  abstract = {Supervised reconstruction models are characteristically trained on matched pairs of undersampled and fully-sampled data to capture an MRI prior, along with supervision regarding the imaging operator to enforce data consistency. To reduce supervision requirements, the recent deep image prior framework instead conjoins untrained MRI priors with the imaging operator during inference. Yet, canonical convolutional architectures are suboptimal in capturing long-range relationships, and priors based on randomly initialized networks may yield suboptimal performance. To address these limitations, here we introduce a novel unsupervised MRI reconstruction method based on zero-Shot Learned Adversarial TransformERs (SLATER). SLATER embodies a deep adversarial network with cross-attention transformers to map noise and latent variables onto coil-combined MR images. During pre-training, this unconditional network learns a high-quality MRI prior in an unsupervised generative modeling task. During inference, a zero-shot reconstruction is then performed by incorporating the imaging operator and optimizing the prior to maximize consistency to undersampled data. Comprehensive experiments on brain MRI datasets clearly demonstrate the superior performance of SLATER against state-of-the-art unsupervised methods.},
  keywords = {Adaptation models,Adversarial,Data models,generative,Image reconstruction,Magnetic resonance imaging,MRI,reconstruction,Task analysis,Training,transformers,Transformers,unsupervised,zero shot},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/KLWAPLDQ/Korkmaz et al. - 2022 - Unsupervised MRI Reconstruction via Zero-Shot Lear.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/UCKP79AP/Korkmaz et al. - 2022 - Unsupervised MRI Reconstruction via Zero-Shot Lear.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/GCIBN6WW/getPDF.html}
}

@misc{kreisLatentSpaceDiffusion2022,
  title = {Latent {{Space Diffusion Models}} of {{Cryo-EM Structures}}},
  author = {Kreis, Karsten and Dockhorn, Tim and Li, Zihao and Zhong, Ellen},
  year = {2022},
  month = nov,
  number = {arXiv:2211.14169},
  eprint = {2211.14169},
  primaryclass = {q-bio, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2211.14169},
  urldate = {2023-03-02},
  abstract = {Cryo-electron microscopy (cryo-EM) is unique among tools in structural biology in its ability to image large, dynamic protein complexes. Key to this ability is image processing algorithms for heterogeneous cryo-EM reconstruction, including recent deep learning-based approaches. The state-of-the-art method cryoDRGN uses a Variational Autoencoder (VAE) framework to learn a continuous distribution of protein structures from single particle cryo-EM imaging data. While cryoDRGN can model complex structural motions, the Gaussian prior distribution of the VAE fails to match the aggregate approximate posterior, which prevents generative sampling of structures especially for multi-modal distributions (e.g. compositional heterogeneity). Here, we train a diffusion model as an expressive, learnable prior in the cryoDRGN framework. Our approach learns a high-quality generative model over molecular conformations directly from cryo-EM imaging data. We show the ability to sample from the model on two synthetic and two real datasets, where samples accurately follow the data distribution unlike samples from the VAE prior distribution. We also demonstrate how the diffusion model prior can be leveraged for fast latent space traversal and interpolation between states of interest. By learning an accurate model of the data distribution, our method unlocks tools in generative modeling, sampling, and distribution analysis for heterogeneous cryo-EM ensembles.},
  archiveprefix = {arxiv},
  keywords = {Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/WJFU7TS8/Kreis et al. - 2022 - Latent Space Diffusion Models of Cryo-EM Structure.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/6SX6YBMB/2211.html}
}

@misc{kunzImplicitNeuralNetworks2023,
  title = {Implicit {{Neural Networks}} with {{Fourier-Feature Inputs}} for {{Free-breathing Cardiac MRI Reconstruction}}},
  author = {Kunz, Johannes F. and Ruschke, Stefan and Heckel, Reinhard},
  year = {2023},
  month = may,
  number = {arXiv:2305.06822},
  eprint = {2305.06822},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  urldate = {2023-05-22},
  abstract = {In this paper, we propose an approach for cardiac magnetic resonance imaging (MRI), which aims to reconstruct a real-time video of a beating heart from continuous highly under-sampled measurements. This task is challenging since the object to be reconstructed (the heart) is continuously changing during signal acquisition. To address this challenge, we represent the beating heart with an implicit neural network and fit the network so that the representation of the heart is consistent with the measurements. The network in the form of a multi-layer perceptron with Fourier-feature inputs acts as an effective signal prior and enables adjusting the regularization strength in both the spatial and temporal dimensions of the signal. We examine the proposed approach for 2D free-breathing cardiac real-time MRI in different operating regimes, i.e., for different image resolutions, slice thicknesses, and acquisition lengths. Our method achieves reconstruction quality on par with or slightly better than state-of-the-art untrained convolutional neural networks and superior image quality compared to a recent method that fits an implicit representation directly to Fourier-domain measurements. However, this comes at a higher computational cost. Our approach does not require any additional patient data or biosensors including electrocardiography, making it potentially applicable in a wide range of clinical scenarios.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/FIFUJJ7U/Kunz et al. - 2023 - Implicit Neural Networks with Fourier-Feature Inpu.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/FGVN4CS5/2305.html}
}

@article{kustnerCINENetDeepLearningbased2020,
  title = {{{CINENet}}: Deep Learning-Based {{3D}} Cardiac {{CINE MRI}} Reconstruction with Multi-Coil Complex-Valued {{4D}} Spatio-Temporal Convolutions},
  shorttitle = {{{CINENet}}},
  author = {K{\"u}stner, Thomas and Fuin, Niccolo and Hammernik, Kerstin and Bustin, Aurelien and Qi, Haikun and Hajhosseiny, Reza and Masci, Pier Giorgio and Neji, Radhouene and Rueckert, Daniel and Botnar, Ren{\'e} M. and Prieto, Claudia},
  year = {2020},
  month = aug,
  journal = {Scientific Reports},
  volume = {10},
  number = {1},
  pages = {13710},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-70551-8},
  urldate = {2022-11-03},
  abstract = {Cardiac CINE magnetic resonance imaging is the gold-standard for the assessment of cardiac function. Imaging accelerations have shown to enable 3D CINE with left ventricular (LV) coverage in a single breath-hold. However, 3D imaging remains limited to anisotropic resolution and long reconstruction times. Recently deep learning has shown promising results for computationally efficient reconstructions of highly accelerated 2D CINE imaging. In this work, we propose a novel 4D (3D\,+\,time) deep learning-based reconstruction network, termed 4D CINENet, for prospectively undersampled 3D Cartesian CINE imaging. CINENet is based on (3\,+\,1)D complex-valued spatio-temporal convolutions and multi-coil data processing. We trained and evaluated the proposed CINENet on in-house acquired 3D CINE data of 20 healthy subjects and 15 patients with suspected cardiovascular disease. The proposed CINENet network outperforms iterative reconstructions in visual image quality and contrast (+\,67\% improvement). We found good agreement in LV function (bias\,{$\pm$}\,95\% confidence) in terms of end-systolic volume (0\,{$\pm$}\,3.3~ml), end-diastolic volume (-\,0.4\,{$\pm$}\,2.0~ml) and ejection fraction (0.1\,{$\pm$}\,3.2\%) compared to clinical gold-standard 2D CINE, enabling single breath-hold isotropic 3D CINE in less than 10~s scan and\,\textasciitilde\,5~s reconstruction time.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Biomedical engineering,Cardiology,Computational models,Computational science,Data acquisition,Image processing,Machine learning,Magnetic resonance imaging,Three-dimensional imaging},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/GI8GFZTH/Küstner et al. - 2020 - CINENet deep learning-based 3D cardiac CINE MRI r.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/X4GCC7HV/s41598-020-70551-8.html}
}

@article{kustnerLAPNetNonRigidRegistration2021,
  title = {{{LAPNet}}: {{Non-Rigid Registration Derived}} in k-{{Space}} for {{Magnetic Resonance Imaging}}},
  shorttitle = {{{LAPNet}}},
  author = {Kustner, Thomas and Pan, Jiazhen and Qi, Haikun and Cruz, Gastao and Gilliam, Christopher and Blu, Thierry and Yang, Bin and Gatidis, Sergios and Botnar, Rene and Prieto, Claudia},
  year = {2021},
  month = dec,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {40},
  number = {12},
  pages = {3686--3697},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2021.3096131},
  urldate = {2022-12-26},
  abstract = {Physiological motion, such as cardiac and respiratory motion, during Magnetic Resonance (MR) image acquisition can cause image artifacts. Motion correction techniques have been proposed to compensate for these types of motion during thoracic scans, relying on accurate motion estimation from undersampled motion-resolved reconstruction. A particular interest and challenge lie in the derivation of reliable non-rigid motion fields from the undersampled motion-resolved data. Motion estimation is usually formulated in image space via diffusion, parametric-spline, or optical flow methods. However, image-based registration can be impaired by remaining aliasing artifacts due to the undersampled motion-resolved reconstruction. In this work, we describe a formalism to perform non-rigid registration directly in the sampled Fourier space, i.e. k-space. We propose a deep-learning based approach to perform fast and accurate non-rigid registration from the undersampled k-space data. The basic working principle originates from the Local AllPass (LAP) technique, a recently introduced optical flow-based registration. The proposed LAPNet is compared against traditional and deep learning image-based registrations and tested on fully-sampled and highly-accelerated (with two undersampling strategies) 3D respiratory motion-resolved MR images in a cohort of 40 patients with suspected liver or lung metastases and 25 healthy subjects. The proposed LAPNet provided consistent and superior performance to image-based approaches throughout different sampling trajectories and acceleration factors.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/NR2GMSX5/Kustner et al. - 2021 - LAPNet Non-Rigid Registration Derived in k-Space .pdf}
}

@article{larkmanParallelMagneticResonance2007,
  title = {Parallel Magnetic Resonance Imaging},
  author = {Larkman, David J. and Nunes, Rita G.},
  year = {2007},
  month = mar,
  journal = {Physics in Medicine \& Biology},
  volume = {52},
  number = {7},
  pages = {R15},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/52/7/R01},
  urldate = {2023-05-23},
  abstract = {Parallel imaging has been the single biggest innovation in magnetic resonance imaging in the last decade. The use of multiple receiver coils to augment the time consuming Fourier encoding has reduced acquisition times significantly. This increase in speed comes at a time when other approaches to acquisition time reduction were reaching engineering and human limits. A brief summary of spatial encoding in MRI is followed by an introduction to the problem parallel imaging is designed to solve. There are a large number of parallel reconstruction algorithms; this article reviews a cross-section, SENSE, SMASH, g-SMASH and GRAPPA, selected to demonstrate the different approaches. Theoretical (the g-factor) and practical (coil design) limits to acquisition speed are reviewed. The practical implementation of parallel imaging is also discussed, in particular coil calibration. How to recognize potential failure modes and their associated artefacts are shown. Well-established applications including angiography, cardiac imaging and applications using echo planar imaging are reviewed and we discuss what makes a good application for parallel imaging. Finally, active research areas where parallel imaging is being used to improve data quality by repairing artefacted images are also reviewed.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/V5E8WGQT/Larkman y Nunes - 2007 - Parallel magnetic resonance imaging.pdf}
}

@inproceedings{leeSystematicStudyRace2022,
  title = {A {{Systematic Study}} of {{Race}} and {{Sex Bias}} in {{CNN-Based Cardiac MR Segmentation}}},
  booktitle = {Statistical {{Atlases}} and {{Computational Models}} of the {{Heart}}. {{Regular}} and {{CMRxMotion Challenge Papers}}},
  author = {Lee, Tiarna and {Puyol-Ant{\'o}n}, Esther and Ruijsink, Bram and Shi, Miaojing and King, Andrew P.},
  editor = {Camara, Oscar and {Puyol-Ant{\'o}n}, Esther and Qin, Chen and Sermesant, Maxime and Suinesiaputra, Avan and Wang, Shuo and Young, Alistair},
  year = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {233--244},
  publisher = {{Springer Nature Switzerland}},
  address = {{Cham}},
  doi = {10.1007/978-3-031-23443-9\_22},
  abstract = {In computer vision there has been significant research interest in assessing potential demographic bias in deep learning models. One of the main causes of such bias is imbalance in the training data. In medical imaging, where the potential impact of bias is arguably much greater, there has been less interest. In medical imaging pipelines, segmentation of structures of interest plays an important role in estimating clinical biomarkers that are subsequently used to inform patient management. Convolutional neural networks (CNNs) are starting to be used to automate this process. We present the first systematic study of the impact of training set imbalance on race and sex bias in CNN-based segmentation. We focus on segmentation of the structures of the heart from short axis cine cardiac magnetic resonance images, and train multiple CNN segmentation models with different levels of race/sex imbalance. We find no significant bias in the sex experiment but significant bias in two separate race experiments, highlighting the need to consider adequate representation of different demographic groups in health datasets.},
  isbn = {978-3-031-23443-9},
  langid = {english},
  keywords = {Cardiac MRI,CNN,Fairness,Segmentation},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/SXIFSZMG/Lee et al. - 2022 - A Systematic Study of Race and Sex Bias in CNN-Bas.pdf}
}

@misc{li3DAwareEncodingStylebased2022,
  title = {{{3D-Aware Encoding}} for {{Style-based Neural Radiance Fields}}},
  author = {Li, Yu-Jhe and Xu, Tao and Wu, Bichen and Zheng, Ningyuan and Dai, Xiaoliang and Pumarola, Albert and Zhang, Peizhao and Vajda, Peter and Kitani, Kris},
  year = {2022},
  month = nov,
  number = {arXiv:2211.06583},
  eprint = {2211.06583},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2211.06583},
  urldate = {2023-03-02},
  abstract = {We tackle the task of NeRF inversion for style-based neural radiance fields, (e.g., StyleNeRF). In the task, we aim to learn an inversion function to project an input image to the latent space of a NeRF generator and then synthesize novel views of the original image based on the latent code. Compared with GAN inversion for 2D generative models, NeRF inversion not only needs to 1) preserve the identity of the input image, but also 2) ensure 3D consistency in generated novel views. This requires the latent code obtained from the single-view image to be invariant across multiple views. To address this new challenge, we propose a two-stage encoder for style-based NeRF inversion. In the first stage, we introduce a base encoder that converts the input image to a latent code. To ensure the latent code is view-invariant and is able to synthesize 3D consistent novel view images, we utilize identity contrastive learning to train the base encoder. Second, to better preserve the identity of the input image, we introduce a refining encoder to refine the latent code and add finer details to the output image. Importantly note that the novelty of this model lies in the design of its first-stage encoder which produces the closest latent code lying on the latent manifold and thus the refinement in the second stage would be close to the NeRF manifold. Through extensive experiments, we demonstrate that our proposed two-stage encoder qualitatively and quantitatively exhibits superiority over the existing encoders for inversion in both image reconstruction and novel-view rendering.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/U285HFUJ/Li et al. - 2022 - 3D-Aware Encoding for Style-based Neural Radiance .pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/MTNF8MUM/2211.html}
}

@inproceedings{liENeRVExpediteNeural2022,
  title = {E-{{NeRV}}: {{Expedite Neural Video Representation}} with~{{Disentangled Spatial-Temporal Context}}},
  shorttitle = {E-{{NeRV}}},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2022},
  author = {Li, Zizhang and Wang, Mengmeng and Pi, Huaijin and Xu, Kechun and Mei, Jianbiao and Liu, Yong},
  editor = {Avidan, Shai and Brostow, Gabriel and Ciss{\'e}, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
  year = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {267--284},
  publisher = {{Springer Nature Switzerland}},
  address = {{Cham}},
  doi = {10.1007/978-3-031-19833-5\_16},
  abstract = {Recently, the image-wise implicit neural representation of videos, NeRV, has gained popularity for its promising results and swift speed compared to regular pixel-wise implicit representations. However, the redundant parameters within the network structure can cause a large model size when scaling up for desirable performance. The key reason of this phenomenon is the coupled formulation of NeRV, which outputs the spatial and temporal information of video frames directly from the frame index input. In this paper, we propose E-NeRV, which dramatically expedites NeRV by decomposing the image-wise implicit neural representation into separate spatial and temporal context. Under the guidance of this new formulation, our model greatly reduces the redundant model parameters, while retaining the representation ability. We experimentally find that our method can improve the performance to a large extent with fewer parameters, resulting in a more than \$\$8\textbackslash times \$\$8\texttimes faster speed on convergence. Code is available at https://github.com/kyleleey/E-NeRV.},
  isbn = {978-3-031-19833-5},
  langid = {english},
  keywords = {Implicit representation,Neural video representation,Spatial-temporal disentanglement},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/LF4NNV3R/Li et al. - 2022 - E-NeRV Expedite Neural Video Representation with .pdf}
}

@article{limTilenetUndersampledCardiovascular2021,
  title = {Tile-Net for Undersampled Cardiovascular {{CINE}} Magnetic Resonance Imaging},
  author = {Lim, Chae Guk and Park, Seong Jae and Ahn, Chang-Beom},
  year = {2021},
  month = dec,
  journal = {Magnetic Resonance Imaging},
  volume = {84},
  pages = {27--34},
  issn = {0730-725X},
  doi = {10.1016/j.mri.2021.09.001},
  urldate = {2022-11-03},
  abstract = {We propose the ``Tile-net'' method based on dividing an image into smaller tiles. Using the tile as the input to the neural network, the network is simplified substantially. The Tile-net learns at a much faster rate than the networks without tiling. The training and reconstruction times for the Tile-net are reduced by 40\% and 33\%, respectively compared to the networks without tiling. The Tile-net performance is evaluated through the normalized mean square error (NMSE), peak signal to noise ratio (PSNR), structure similarity index measure (SSIM) and the quality of the reconstructed image for test datasets. The Tile-net does not degrade performance; however, it reduces the NMSE by 0.3\% compared to the networks without tiling.},
  langid = {english},
  keywords = {Cardiovascular CINE magnetic resonance imaging,Complexity,Neural network,notion,Tile-net,U-net},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/Q58PM3CE/Lim et al. - 2021 - Tile-net for undersampled cardiovascular CINE magn.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/5ASNAAPD/S0730725X21001429.html}
}

@inproceedings{lindellBaconBandlimitedCoordinate2022,
  title = {Bacon: {{Band-limited Coordinate Networks}} for {{Multiscale Scene Representation}}},
  shorttitle = {Bacon},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Lindell, David B. and Van Veen, Dave and Park, Jeong Joon and Wetzstein, Gordon},
  year = {2022},
  month = jun,
  pages = {16231--16241},
  publisher = {{IEEE}},
  address = {{New Orleans, LA, USA}},
  doi = {10.1109/CVPR52688.2022.01577},
  urldate = {2022-11-03},
  abstract = {Coordinate-based networks have emerged as a powerful tool for 3D representation and scene reconstruction. These networks are trained to map continuous input coordinates to the value of a signal at each point. Still, current architectures are black boxes: their spectral characteristics cannot be easily analyzed, and their behavior at unsupervised points is difficult to predict. Moreover, these networks are typically trained to represent a signal at a single scale, so naive downsampling or upsampling results in artifacts. We introduce band-limited coordinate networks (BACON), a network architecture with an analytical Fourier spectrum. BACON has constrained behavior at unsupervised points, can be designed based on the spectral characteristics of the represented signal, and can represent signals at multiple scales without per-scale supervision. We demonstrate BACON for multiscale neural representation of images, radiance fields, and 3D scenes using signed distance functions and show that it outperforms conventional single-scale coordinate networks in terms of interpretability and quality.},
  isbn = {978-1-66546-946-3},
  langid = {english},
  file = {C\:\\Users\\Tabita\\Documents\\ACIP\\Abstract\\bacon.pdf}
}

@misc{liuDeVRFFastDeformable2022,
  title = {{{DeVRF}}: {{Fast Deformable Voxel Radiance Fields}} for {{Dynamic Scenes}}},
  shorttitle = {{{DeVRF}}},
  author = {Liu, Jia-Wei and Cao, Yan-Pei and Mao, Weijia and Zhang, Wenqiao and Zhang, David Junhao and Keppo, Jussi and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  year = {2022},
  month = jun,
  number = {arXiv:2205.15723},
  eprint = {2205.15723},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-03-29},
  abstract = {Modeling dynamic scenes is important for many applications such as virtual reality and telepresence. Despite achieving unprecedented fidelity for novel view synthesis in dynamic scenes, existing methods based on Neural Radiance Fields (NeRF) suffer from slow convergence (i.e., model training time measured in days). In this paper, we present DeVRF, a novel representation to accelerate learning dynamic radiance fields. The core of DeVRF is to model both the 3D canonical space and 4D deformation field of a dynamic, non-rigid scene with explicit and discrete voxel-based representations. However, it is quite challenging to train such a representation which has a large number of model parameters, often resulting in overfitting issues. To overcome this challenge, we devise a novel static-to-dynamic learning paradigm together with a new data capture setup that is convenient to deploy in practice. This paradigm unlocks efficient learning of deformable radiance fields via utilizing the 3D volumetric canonical space learnt from multi-view static images to ease the learning of 4D voxel deformation field with only few-view dynamic sequences. To further improve the efficiency of our DeVRF and its synthesized novel view's quality, we conduct thorough explorations and identify a set of strategies. We evaluate DeVRF on both synthetic and real-world dynamic scenes with different types of deformation. Experiments demonstrate that DeVRF achieves two orders of magnitude speedup (100x faster) with on-par high-fidelity results compared to the previous state-of-the-art approaches. The code and dataset will be released in https://github.com/showlab/DeVRF.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/FH3VI7Q2/Liu et al. - 2022 - DeVRF Fast Deformable Voxel Radiance Fields for D.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/L7YHBMVS/2205.html}
}

@article{lundervoldOverviewDeepLearning2019,
  title = {An Overview of Deep Learning in Medical Imaging Focusing on {{MRI}}},
  author = {Lundervold, Alexander Selvikv{\aa}g and Lundervold, Arvid},
  year = {2019},
  month = may,
  journal = {Zeitschrift f\"ur Medizinische Physik},
  series = {Special {{Issue}}: {{Deep Learning}} in {{Medical Physics}}},
  volume = {29},
  number = {2},
  pages = {102--127},
  issn = {0939-3889},
  doi = {10.1016/j.zemedi.2018.11.002},
  urldate = {2023-05-23},
  abstract = {What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artificial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding field we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI. Our aim is threefold: (i) give a brief introduction to deep learning with pointers to core references; (ii) indicate how deep learning has been applied to the entire MRI processing chain, from acquisition to image retrieval, from segmentation to disease prediction; (iii) provide a starting point for people interested in experimenting and perhaps contributing to the field of deep learning for medical imaging by pointing out good educational resources, state-of-the-art open-source code, and interesting sources of data and problems related medical imaging.},
  langid = {english},
  keywords = {Deep learning,Machine learning,Medical imaging,MRI},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/7TT98JPG/Lundervold y Lundervold - 2019 - An overview of deep learning in medical imaging fo.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/RRID5XHT/S0939388918301181.html}
}

@article{lustigCompressedSensingMRI2008,
  title = {Compressed {{Sensing MRI}}},
  author = {Lustig, Michael and Donoho, David L. and Santos, Juan M. and Pauly, John M.},
  year = {2008},
  month = mar,
  journal = {IEEE Signal Processing Magazine},
  volume = {25},
  number = {2},
  pages = {72--82},
  issn = {1558-0792},
  doi = {10.1109/MSP.2007.914728},
  abstract = {This article reviews the requirements for successful compressed sensing (CS), describes their natural fit to MRI, and gives examples of four interesting applications of CS in MRI. The authors emphasize on an intuitive understanding of CS by describing the CS reconstruction as a process of interference cancellation. There is also an emphasis on the understanding of the driving factors in applications, including limitations imposed by MRI hardware, by the characteristics of different types of images, and by clinical concerns.},
  keywords = {Biomedical imaging,Compressed sensing,Encoding,Image coding,Image reconstruction,Magnetic resonance imaging,Magnetization,Protons,Radio frequency,Wavelet transforms},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/PGWG8X4D/Lustig et al. - 2008 - Compressed Sensing MRI.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/TI7DJTRK/4472246.html}
}

@inproceedings{maiMotionAdjustableNeuralImplicit2022,
  title = {Motion-{{Adjustable Neural Implicit Video Representation}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Mai, Long and Liu, Feng},
  year = {2022},
  pages = {10738--10747},
  urldate = {2023-03-29},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/RINYCM76/Mai y Liu - 2022 - Motion-Adjustable Neural Implicit Video Representa.pdf}
}

@article{menchon-laraReconstructionTechniquesCardiac2019,
  title = {Reconstruction Techniques for Cardiac Cine {{MRI}}},
  author = {{Mench{\'o}n-Lara}, Rosa-Mar{\'i}a and {Simmross-Wattenberg}, Federico and {Casaseca-de-la-Higuera}, Pablo and {Mart{\'i}n-Fern{\'a}ndez}, Marcos and {Alberola-L{\'o}pez}, Carlos},
  year = {2019},
  month = sep,
  journal = {Insights into Imaging},
  volume = {10},
  pages = {100},
  issn = {1869-4101},
  doi = {10.1186/s13244-019-0754-2},
  urldate = {2022-11-03},
  abstract = {The present survey describes the state-of-the-art techniques for dynamic cardiac magnetic resonance image reconstruction. Additionally, clinical relevance, main challenges, and future trends of this image modality are outlined. Thus, this paper aims to provide a general vision about cine MRI as the standard procedure in functional evaluation of the heart, focusing on technical methodologies.},
  pmcid = {PMC6757088},
  pmid = {31549235},
  keywords = {notion},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/GE9VESXC/Menchón-Lara et al. - 2019 - Reconstruction techniques for cardiac cine MRI.pdf}
}

@misc{mildenhallNeRFRepresentingScenes2020,
  title = {{{NeRF}}: {{Representing Scenes}} as {{Neural Radiance Fields}} for {{View Synthesis}}},
  shorttitle = {{{NeRF}}},
  author = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
  year = {2020},
  month = aug,
  number = {arXiv:2003.08934},
  eprint = {2003.08934},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2003.08934},
  urldate = {2022-11-03},
  abstract = {We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location \$(x,y,z)\$ and viewing direction \$(\textbackslash theta, \textbackslash phi)\$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,notion},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/Y8Y876M7/Mildenhall et al. - 2020 - NeRF Representing Scenes as Neural Radiance Field.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/5AHEEZZD/2003.html}
}

@incollection{mojibianChapterCardiacMagnetic2018,
  title = {Chapter 8 - {{Cardiac Magnetic Resonance Imaging}}},
  booktitle = {Practical {{Cardiology}}},
  author = {Mojibian, Hamid and Pouraliakbar, Hamidreza},
  editor = {Maleki, Majid and Alizadehasl, Azin and Haghjoo, Majid},
  year = {2018},
  month = jan,
  pages = {159--166},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-323-51149-0.00008-0},
  urldate = {2022-12-15},
  abstract = {Cardiac MRI is one of the newest tools in the evaluation of patients with cardiovascular disease. This chapter provides a very basic introduction to MRI technology and also clinical indications of cardiac MRI in practice of modern cardiology.},
  isbn = {978-0-323-51149-0},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/YXXBIKJ9/Mojibian y Pouraliakbar - 2018 - Chapter 8 - Cardiac Magnetic Resonance Imaging.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/VWT5KMZZ/B9780323511490000080.html}
}

@article{morenolopezEvaluationMRIDenoising2021,
  title = {Evaluation of {{MRI Denoising Methods Using Unsupervised Learning}}},
  author = {Moreno L{\'o}pez, Marc and Frederick, Joshua M. and Ventura, Jonathan},
  year = {2021},
  journal = {Frontiers in Artificial Intelligence},
  volume = {4},
  issn = {2624-8212},
  urldate = {2023-04-26},
  abstract = {In this paper we evaluate two unsupervised approaches to denoise Magnetic Resonance Images (MRI) in the complex image space using the raw information that k-space holds. The first method is based on Stein's Unbiased Risk Estimator, while the second approach is based on a blindspot network, which limits the network's receptive field. Both methods are tested on two different datasets, one containing real knee MRI and the other consists of synthetic brain MRI. These datasets contain information about the complex image space which will be used for denoising purposes. Both networks are compared against a state-of-the-art algorithm, Non-Local Means (NLM) using quantitative and qualitative measures. For most given metrics and qualitative measures, both networks outperformed NLM, and they prove to be reliable denoising methods.},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/AA67PT7M/Moreno López et al. - 2021 - Evaluation of MRI Denoising Methods Using Unsuperv.pdf}
}

@article{muckleyResults2020FastMRI2021,
  title = {Results of the 2020 {{fastMRI Challenge}} for {{Machine Learning MR Image Reconstruction}}},
  author = {Muckley, Matthew J. and Riemenschneider, Bruno and Radmanesh, Alireza and Kim, Sunwoo and Jeong, Geunu and Ko, Jingyu and Jun, Yohan and Shin, Hyungseob and Hwang, Dosik and Mostapha, Mahmoud and Arberet, Simon and Nickel, Dominik and Ramzi, Zaccharie and Ciuciu, Philippe and Starck, Jean-Luc and Teuwen, Jonas and Karkalousos, Dimitrios and Zhang, Chaoping and Sriram, Anuroop and Huang, Zhengnan and Yakubova, Nafissa and Lui, Yvonne W. and Knoll, Florian},
  year = {2021},
  month = sep,
  journal = {IEEE transactions on medical imaging},
  volume = {40},
  number = {9},
  pages = {2306--2317},
  issn = {0278-0062},
  doi = {10.1109/TMI.2021.3075856},
  urldate = {2023-05-23},
  abstract = {Accelerating MRI scans is one of the principal outstanding problems in the MRI research community. Towards this goal, we hosted the second fastMRI competition targeted towards reconstructing MR images with subsampled k-space data. We provided participants with data from 7,299 clinical brain scans (de-identified via a HIPAA-compliant procedure by NYU Langone Health), holding back the fully-sampled data from 894 of these scans for challenge evaluation purposes. In contrast to the 2019 challenge, we focused our radiologist evaluations on pathological assessment in brain images. We also debuted a new Transfer track that required participants to submit models evaluated on MRI scanners from outside the training set. We received 19 submissions from eight different groups. Results showed one team scoring best in both SSIM scores and qualitative radiologist evaluations. We also performed analysis on alternative metrics to mitigate the effects of background noise and collected feedback from the participants to inform future challenges. Lastly, we identify common failure modes across the submissions, highlighting areas of need for future research in the MRI reconstruction community.},
  pmcid = {PMC8428775},
  pmid = {33929957},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/GRX293SM/Muckley et al. - 2021 - Results of the 2020 fastMRI Challenge for Machine .pdf}
}

@article{mullerInstantNeuralGraphics2022,
  title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
  author = {M{\"u}ller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  year = {2022},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {41},
  number = {4},
  pages = {1--15},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3528223.3530127},
  urldate = {2023-03-02},
  abstract = {Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920\texttimes 1080.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/26SMQ98G/3528223.pdf}
}

@inproceedings{narnhoferInverseGANsAccelerated2019,
  title = {Inverse {{GANs}} for Accelerated {{MRI}} Reconstruction},
  booktitle = {Wavelets and {{Sparsity XVIII}}},
  author = {Narnhofer, Dominik and Hammernik, Kerstin and Knoll, Florian and Pock, Thomas},
  year = {2019},
  month = sep,
  volume = {11138},
  pages = {381--392},
  publisher = {{SPIE}},
  doi = {10.1117/12.2527753},
  urldate = {2022-11-08},
  abstract = {State-of-the-art algorithms for accelerated magnetic resonance image (MRI) reconstruction are nowadays dominated by deep learning-based techniques. However, the majority of these methods require the respective sampling patterns in training, which limits their application to a specific problem class. We propose an iterative reconstruction approach that incorporates the implicit prior provided by a generative adversarial network (GAN), which learns the probability distribution of uncorrupted MRI data in an off-line step. Since the unsupervised training of the GAN is completely independent of the measurement process, our method is in principle able to address multiple sampling modalities using a single pre-trained model. However, it turns out that the desired target images potentially lie outside the range space of the learned GAN, leading to reconstructions that resemble the target images only at a coarse level of detail. To overcome this issue, we propose a refinement scheme termed GAN prior adaption, that allows for additional adaption of the generating network with respect to the measured data. The proposed method is evaluated on multi-coil knee MRI data for different acceleration factors and compared to a classical as well as a deep learning-based approach showing promising quantitative and qualitative results.},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/7PWSZB4F/12.2527753.html}
}

@book{nattererMathematicsComputerizedTomography2001,
  title = {The Mathematics of Computerized Tomography},
  author = {Natterer, F.},
  year = {2001},
  series = {Classics in Applied Mathematics},
  number = {32},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  isbn = {978-0-89871-493-7},
  lccn = {RC78.7.T6 N37 2001},
  keywords = {Geometric tomography}
}

@misc{navonEquivariantArchitecturesLearning2023,
  title = {Equivariant {{Architectures}} for {{Learning}} in {{Deep Weight Spaces}}},
  author = {Navon, Aviv and Shamsian, Aviv and Achituve, Idan and Fetaya, Ethan and Chechik, Gal and Maron, Haggai},
  year = {2023},
  month = jan,
  number = {arXiv:2301.12780},
  eprint = {2301.12780},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2301.12780},
  urldate = {2023-03-02},
  abstract = {Designing machine learning architectures for processing neural networks in their raw weight matrix form is a newly introduced research direction. Unfortunately, the unique symmetry structure of deep weight spaces makes this design very challenging. If successful, such architectures would be capable of performing a wide range of intriguing tasks, from adapting a pre-trained network to a new domain to editing objects represented as functions (INRs or NeRFs). As a first step towards this goal, we present here a novel network architecture for learning in deep weight spaces. It takes as input a concatenation of weights and biases of a pre-trained MLP and processes it using a composition of layers that are equivariant to the natural permutation symmetry of the MLP's weights: Changing the order of neurons in intermediate layers of the MLP does not affect the function it represents. We provide a full characterization of all affine equivariant and invariant layers for these symmetries and show how these layers can be implemented using three basic operations: pooling, broadcasting, and fully connected layers applied to the input in an appropriate manner. We demonstrate the effectiveness of our architecture and its advantages over natural baselines in a variety of learning tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/FM887D8B/Navon et al. - 2023 - Equivariant Architectures for Learning in Deep Wei.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/XA69W2U5/2301.html}
}

@article{ohEndtoEndRecurrentNeural2022,
  title = {An {{End-to-End Recurrent Neural Network}} for {{Radial MR Image Reconstruction}}},
  author = {Oh, Changheun and Chung, Jun-Young and Han, Yeji},
  year = {2022},
  month = jan,
  journal = {Sensors},
  volume = {22},
  number = {19},
  pages = {7277},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1424-8220},
  doi = {10.3390/s22197277},
  urldate = {2022-12-14},
  abstract = {Recent advances in deep learning have contributed greatly to the field of parallel MR imaging, where a reduced amount of k-space data are acquired to accelerate imaging time. In our previous work, we have proposed a deep learning method to reconstruct MR images directly from k-space data acquired with Cartesian trajectories. However, MRI utilizes various non-Cartesian trajectories, such as radial trajectories, with various numbers of multi-channel RF coils according to the purpose of an MRI scan. Thus, it is important for a reconstruction network to efficiently unfold aliasing artifacts due to undersampling and to combine multi-channel k-space data into single-channel data. In this work, a neural network named `ETER-net' is utilized to reconstruct an MR image directly from k-space data acquired with Cartesian and non-Cartesian trajectories and multi-channel RF coils. In the proposed image reconstruction network, the domain transform network converts k-space data into a rough image, which is then refined in the following network to reconstruct a final image. We also analyze loss functions including adversarial and perceptual losses to improve the network performance. For experiments, we acquired k-space data at a 3T MRI scanner with Cartesian and radial trajectories to show the learning mechanism of the direct mapping relationship between the k-space and the corresponding image by the proposed network and to demonstrate the practical applications. According to our experiments, the proposed method showed satisfactory performance in reconstructing images from undersampled single- or multi-channel k-space data with reduced image artifacts. In conclusion, the proposed method is a deep-learning-based MR reconstruction network, which can be used as a unified solution for parallel MRI, where k-space data are acquired with various scanning trajectories.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {end to end,image reconstruction,MRI,RNN},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/WRB9J2FA/Oh et al. - 2022 - An End-to-End Recurrent Neural Network for Radial .pdf}
}

@article{oscanoaDeepLearningBasedReconstruction2023,
  title = {Deep {{Learning-Based Reconstruction}} for {{Cardiac MRI}}: {{A Review}}},
  shorttitle = {Deep {{Learning-Based Reconstruction}} for {{Cardiac MRI}}},
  author = {Oscanoa, Julio A. and Middione, Matthew J. and Alkan, Cagan and Yurt, Mahmut and Loecher, Michael and Vasanawala, Shreyas S. and Ennis, Daniel B.},
  year = {2023},
  month = mar,
  journal = {Bioengineering},
  volume = {10},
  number = {3},
  pages = {334},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2306-5354},
  doi = {10.3390/bioengineering10030334},
  urldate = {2023-07-18},
  abstract = {Cardiac magnetic resonance (CMR) is an essential clinical tool for the assessment of cardiovascular disease. Deep learning (DL) has recently revolutionized the field through image reconstruction techniques that allow unprecedented data undersampling rates. These fast acquisitions have the potential to considerably impact the diagnosis and treatment of cardiovascular disease. Herein, we provide a comprehensive review of DL-based reconstruction methods for CMR. We place special emphasis on state-of-the-art unrolled networks, which are heavily based on a conventional image reconstruction framework. We review the main DL-based methods and connect them to the relevant conventional reconstruction theory. Next, we review several methods developed to tackle specific challenges that arise from the characteristics of CMR data. Then, we focus on DL-based methods developed for specific CMR applications, including flow imaging, late gadolinium enhancement, and quantitative tissue characterization. Finally, we discuss the pitfalls and future outlook of DL-based reconstructions in CMR, focusing on the robustness, interpretability, clinical deployment, and potential for new methods.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {cardiac magnetic resonance imaging,deep learning,image reconstruction,machine learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/R7RMWH9C/Oscanoa et al. - 2023 - Deep Learning-Based Reconstruction for Cardiac MRI.pdf}
}

@article{pfeifferCardiacMRI2015,
  title = {Cardiac {{MRI}}},
  author = {Pfeiffer, Michael P. and Biederman, Robert W.W.},
  year = {2015},
  month = jul,
  journal = {Medical Clinics of North America},
  volume = {99},
  number = {4},
  pages = {849--861},
  issn = {00257125},
  doi = {10.1016/j.mcna.2015.02.011},
  urldate = {2023-05-23},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/LRPNJ7AE/Pfeiffer y Biederman - 2015 - Cardiac MRI.pdf}
}

@article{pruessmannSENSESensitivityEncoding1999,
  title = {{{SENSE}}: Sensitivity Encoding for Fast {{MRI}}},
  shorttitle = {{{SENSE}}},
  author = {Pruessmann, K. P. and Weiger, M. and Scheidegger, M. B. and Boesiger, P.},
  year = {1999},
  month = nov,
  journal = {Magnetic Resonance in Medicine},
  volume = {42},
  number = {5},
  pages = {952--962},
  issn = {0740-3194},
  abstract = {New theoretical and practical concepts are presented for considerably enhancing the performance of magnetic resonance imaging (MRI) by means of arrays of multiple receiver coils. Sensitivity encoding (SENSE) is based on the fact that receiver sensitivity generally has an encoding effect complementary to Fourier preparation by linear field gradients. Thus, by using multiple receiver coils in parallel scan time in Fourier imaging can be considerably reduced. The problem of image reconstruction from sensitivity encoded data is formulated in a general fashion and solved for arbitrary coil configurations and k-space sampling patterns. Special attention is given to the currently most practical case, namely, sampling a common Cartesian grid with reduced density. For this case the feasibility of the proposed methods was verified both in vitro and in vivo. Scan time was reduced to one-half using a two-coil array in brain imaging. With an array of five coils double-oblique heart images were obtained in one-third of conventional scan time. Magn Reson Med 42:952-962, 1999.},
  langid = {english},
  pmid = {10542355},
  keywords = {Brain,Fourier Analysis,Heart,Humans,Image Enhancement,Magnetic Resonance Imaging,{Models, Theoretical},notion,{Phantoms, Imaging},Sensitivity and Specificity}
}

@article{qayyumUntrainedNeuralNetwork2023,
  title = {Untrained {{Neural Network Priors}} for {{Inverse Imaging Problems}}: {{A Survey}}},
  shorttitle = {Untrained {{Neural Network Priors}} for {{Inverse Imaging Problems}}},
  author = {Qayyum, Adnan and Ilahi, Inaam and Shamshad, Fahad and Boussaid, Farid and Bennamoun, Mohammed and Qadir, Junaid},
  year = {2023},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {45},
  number = {5},
  pages = {6511--6536},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2022.3204527},
  abstract = {In recent years, advancements in machine learning (ML) techniques, in particular, deep learning (DL) methods have gained a lot of momentum in solving inverse imaging problems, often surpassing the performance provided by hand-crafted approaches. Traditionally, analytical methods have been used to solve inverse imaging problems such as image restoration, inpainting, and superresolution. Unlike analytical methods for which the problem is explicitly defined and the domain knowledge is carefully engineered into the solution, DL models do not benefit from such prior knowledge and instead make use of large datasets to predict an unknown solution to the inverse problem. Recently, a new paradigm of training deep models using a single image, named untrained neural network prior (UNNP) has been proposed to solve a variety of inverse tasks, e.g., restoration and inpainting. Since then, many researchers have proposed various applications and variants of UNNP. In this paper, we present a comprehensive review of such studies and various UNNP applications for different tasks and highlight various open research problems which require further research.},
  keywords = {deep learning,Deep learning,Image reconstruction,Imaging,Inverse imaging problems,Inverse problems,Neural networks,Noise measurement,Task analysis,untrained neural networks priors},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/9W4RLILI/Qayyum et al. - 2023 - Untrained Neural Network Priors for Inverse Imagin.pdf}
}

@article{qinConvolutionalRecurrentNeural2019,
  title = {Convolutional {{Recurrent Neural Networks}} for {{Dynamic MR Image Reconstruction}}},
  author = {Qin, Chen and Schlemper, Jo and Caballero, Jose and Price, Anthony N. and Hajnal, Joseph V. and Rueckert, Daniel},
  year = {2019},
  month = jan,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {38},
  number = {1},
  pages = {280--290},
  issn = {1558-254X},
  doi = {10.1109/TMI.2018.2863670},
  abstract = {Accelerating the data acquisition of dynamic magnetic resonance imaging leads to a challenging ill-posed inverse problem, which has received great interest from both the signal processing and machine learning communities over the last decades. The key ingredient to the problem is how to exploit the temporal correlations of the MR sequence to resolve aliasing artifacts. Traditionally, such observation led to a formulation of an optimization problem, which was solved using iterative algorithms. Recently, however, deep learning-based approaches have gained significant popularity due to their ability to solve general inverse problems. In this paper, we propose a unique, novel convolutional recurrent neural network architecture which reconstructs high quality cardiac MR images from highly undersampled k-space data by jointly exploiting the dependencies of the temporal sequences as well as the iterative nature of the traditional optimization algorithms. In particular, the proposed architecture embeds the structure of the traditional iterative algorithms, efficiently modeling the recurrence of the iterative reconstruction stages by using recurrent hidden connections over such iterations. In addition, spatio\textendash temporal dependencies are simultaneously learnt by exploiting bidirectional recurrent hidden connections across time sequences. The proposed method is able to learn both the temporal dependence and the iterative reconstruction process effectively with only a very small number of parameters, while outperforming current MR reconstruction methods in terms of reconstruction accuracy and speed.},
  keywords = {cardiac image reconstruction,convolutional neural network,dynamic magnetic resonance imaging,Image reconstruction,Iterative methods,Machine learning,Magnetic resonance imaging,Optimization,Recurrent neural network,Recurrent neural networks},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/V89EPI94/Qin et al. - 2019 - Convolutional Recurrent Neural Networks for Dynami.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/QK6528P9/8425639.html}
}

@inproceedings{rahamanSpectralBiasNeural2019,
  title = {On the {{Spectral Bias}} of {{Neural Networks}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred and Bengio, Yoshua and Courville, Aaron},
  year = {2019},
  month = may,
  pages = {5301--5310},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-11-09},
  abstract = {Neural networks are known to be a class of highly expressive functions able to fit even random input-output mappings with 100\% accuracy. In this work we present properties of neural networks that complement this aspect of expressivity. By using tools from Fourier analysis, we highlight a learning bias of deep networks towards low frequency functions \textendash{} i.e. functions that vary globally without local fluctuations \textendash{} which manifests itself as a frequency-dependent learning speed. Intuitively, this property is in line with the observation that over-parameterized networks prioritize learning simple patterns that generalize across data samples. We also investigate the role of the shape of the data manifold by presenting empirical and theoretical evidence that, somewhat counter-intuitively, learning higher frequencies gets easier with increasing manifold complexity.},
  langid = {english},
  keywords = {notion},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/9USC4FXW/Rahaman et al. - 2019 - On the Spectral Bias of Neural Networks.pdf}
}

@article{raissiPhysicsinformedNeuralNetworks2019,
  title = {Physics-Informed Neural Networks: {{A}} Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations},
  shorttitle = {Physics-Informed Neural Networks},
  author = {Raissi, M. and Perdikaris, P. and Karniadakis, G.E.},
  year = {2019},
  month = feb,
  journal = {Journal of Computational Physics},
  volume = {378},
  pages = {686--707},
  issn = {00219991},
  doi = {10.1016/j.jcp.2018.10.045},
  urldate = {2022-04-18},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/IZT76CAH/1-s2.0-S0021999118307125-main.pdf}
}

@misc{rhoMaskedWaveletRepresentation2022,
  title = {Masked {{Wavelet Representation}} for {{Compact Neural Radiance Fields}}},
  author = {Rho, Daniel and Lee, Byeonghyeon and Nam, Seungtae and Lee, Joo Chan and Ko, Jong Hwan and Park, Eunbyung},
  year = {2022},
  month = dec,
  number = {arXiv:2212.09069},
  eprint = {2212.09069},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2212.09069},
  urldate = {2023-03-02},
  abstract = {Neural radiance fields (NeRF) have demonstrated the potential of coordinate-based neural representation (neural fields or implicit neural representation) in neural rendering. However, using a multi-layer perceptron (MLP) to represent a 3D scene or object requires enormous computational resources and time. There have been recent studies on how to reduce these computational inefficiencies by using additional data structures, such as grids or trees. Despite the promising performance, the explicit data structure necessitates a substantial amount of memory. In this work, we present a method to reduce the size without compromising the advantages of having additional data structures. In detail, we propose using the wavelet transform on grid-based neural fields. Grid-based neural fields are for fast convergence, and the wavelet transform, whose efficiency has been demonstrated in high-performance standard codecs, is to improve the parameter efficiency of grids. Furthermore, in order to achieve a higher sparsity of grid coefficients while maintaining reconstruction quality, we present a novel trainable masking approach. Experimental results demonstrate that non-spatial grid coefficients, such as wavelet coefficients, are capable of attaining a higher level of sparsity than spatial grid coefficients, resulting in a more compact representation. With our proposed mask and compression pipeline, we achieved state-of-the-art performance within a memory budget of 2 MB. Our code is available at https://github.com/daniel03c1/masked\_wavelet\_nerf.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/ZPHWAF7W/Rho et al. - 2022 - Masked Wavelet Representation for Compact Neural R.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/DSMYMGLB/2212.html}
}

@inproceedings{saragadamWIREWaveletImplicit2023,
  title = {{{WIRE}}: {{Wavelet Implicit Neural Representations}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Saragadam, Vishwanath and LeJeune, Daniel and Tan, Jasper and Balakrishnan, Guha and Veeraraghavan, Ashok and Baraniuk, Richard G},
  year = {2023},
  pages = {18507--18516},
  abstract = {Implicit neural representations (INRs) have recently advanced numerous vision-related areas. INR performance depends strongly on the choice of activation function employed in its MLP network. A wide range of nonlinearities have been explored, but, unfortunately, current INRs designed to have high accuracy also suffer from poor robustness (to signal noise, parameter variation, etc.). Inspired by harmonic analysis, we develop a new, highly accurate and robust INR that does not exhibit this tradeoff. Our Wavelet Implicit neural REpresentation (WIRE) uses as its activation function the complex Gabor wavelet that is wellknown to be optimally concentrated in space\textendash frequency and to have excellent biases for representing images. A wide range of experiments (image denoising, image inpainting, super-resolution, computed tomography reconstruction, image overfitting, and novel view synthesis with neural radiance fields) demonstrate that WIRE defines the new state of the art in INR accuracy, training time, and robustness.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/4PWZPMDZ/Saragadam et al. - WIRE Wavelet Implicit Neural Representations.pdf}
}

@article{schlemperDeepCascadeConvolutional2018,
  title = {A {{Deep Cascade}} of {{Convolutional Neural Networks}} for {{Dynamic MR Image Reconstruction}}},
  author = {Schlemper, Jo and Caballero, Jose and Hajnal, Joseph V. and Price, Anthony N. and Rueckert, Daniel},
  year = {2018},
  month = feb,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {37},
  number = {2},
  pages = {491--503},
  issn = {1558-254X},
  doi = {10.1109/TMI.2017.2760978},
  abstract = {Inspired by recent advances in deep learning, we propose a framework for reconstructing dynamic sequences of 2-D cardiac magnetic resonance (MR) images from undersampled data using a deep cascade of convolutional neural networks (CNNs) to accelerate the data acquisition process. In particular, we address the case where data are acquired using aggressive Cartesian undersampling. First, we show that when each 2-D image frame is reconstructed independently, the proposed method outperforms state-of-the-art 2-D compressed sensing approaches, such as dictionary learning-based MR image reconstruction, in terms of reconstruction error and reconstruction speed. Second, when reconstructing the frames of the sequences jointly, we demonstrate that CNNs can learn spatio-temporal correlations efficiently by combining convolution and data sharing approaches. We show that the proposed method consistently outperforms state-of-the-art methods and is capable of preserving anatomical structure more faithfully up to 11-fold undersampling. Moreover, reconstruction is very fast: each complete dynamic sequence can be reconstructed in less than 10 s and, for the 2-D case, each image frame can be reconstructed in 23 ms, enabling real-time applications.},
  langid = {english},
  keywords = {Algorithms,compressed sensing,Compressed sensing,convolutional neural network,{Databases, Factual},Deep learning,dynamic magnetic resonance imaging,Heart,Humans,{Image Processing, Computer-Assisted},image reconstruction,Image reconstruction,Imaging,Machine learning,{Magnetic Resonance Imaging, Cine},Neural networks,{Neural Networks, Computer},Redundancy,Two dimensional displays},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/4923M3VC/Schlemper et al. - 2018 - A Deep Cascade of Convolutional Neural Networks fo.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/V65NVDM4/Schlemper et al. - 2018 - A Deep Cascade of Convolutional Neural Networks fo.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/WNRJU9KJ/A_Deep_Cascade_of_Convolutional_Neural_Networks_for_Dynamic_MR_Image_Reconstruction.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/CIZRZEDY/8067520.html}
}

@article{senINRVContinuousRepresentation2022,
  title = {{{INR-V}}: {{A Continuous Representation Space}} for {{Video-based Generative Tasks}}},
  shorttitle = {{{INR-V}}},
  author = {Sen, Bipasha and Agarwal, Aditya and Namboodiri, Vinay P. and Jawahar, C. V.},
  year = {2022},
  month = oct,
  journal = {Transactions on Machine Learning Research},
  issn = {2835-8856},
  urldate = {2023-03-02},
  abstract = {Generating videos is a complex task that is accomplished by generating a set of temporally coherent images frame-by-frame. This limits the expressivity of videos to only image-based operations on the individual video frames needing network designs to obtain temporally coherent trajectories in the underlying image space. We propose INR-V, a video representation network that learns a continuous space for video-based generative tasks. INR-V parameterizes videos using implicit neural representations (INRs), a multi-layered perceptron that predicts an RGB value for each input pixel location of the video. The INR is predicted using a meta-network which is a hypernetwork trained on neural representations of multiple video instances. Later, the meta-network can be sampled to generate diverse novel videos enabling many downstream video-based generative tasks. Interestingly, we find that conditional regularization and progressive weight initialization play a crucial role in obtaining INR-V. The representation space learned by INR-V is more expressive than an image space showcasing many interesting properties not possible with the existing works. For instance, INR-V can smoothly interpolate intermediate videos between known video instances (such as intermediate identities, expressions, and poses in face videos). It can also in-paint missing portions in videos to recover temporally coherent full videos. In this work, we evaluate the space learned by INR-V on diverse generative tasks such as video interpolation, novel video generation, video inversion, and video inpainting against the existing baselines. INR-V significantly outperforms the baselines on several of these demonstrated tasks, clearly showing the potential of the proposed representation space.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/4YT9DX7D/Sen et al. - 2022 - INR-V A Continuous Representation Space for Video.pdf}
}

@article{sharafutdinovRadonTransformSobolev2021,
  title = {Radon {{Transform}} on {{Sobolev Spaces}}},
  author = {Sharafutdinov, V. A.},
  year = {2021},
  month = may,
  journal = {Siberian Mathematical Journal},
  volume = {62},
  number = {3},
  pages = {560--580},
  issn = {1573-9260},
  doi = {10.1134/S0037446621030198},
  urldate = {2023-05-02},
  abstract = {The Radon transform~\$ R \$maps a function~\$ f \$on~\$ \{𝕉\}\^\{n\} \$to the family of the integrals of~\$ f \$over all hyperplanes. The classicalReshetnyak formula (also called the Plancherel formula for the Radon transform) states that\$ \textbackslash |f\textbackslash |\_\{L\^\{2\}(\{𝕉\}\^\{n\})\}=\textbackslash |Rf\textbackslash |\_\{H\^\{(n-1)/2\}\_\{(n-1)/2\}(\{{$\mathbb{S}\rbrace\sphat\lbrace$}n-1\}\textbackslash times\{𝕉\})\} \$,where\$ \textbackslash |\textbackslash cdot\textbackslash |\_\{H\^\{(n-1)/2\}\_\{(n-1)/2\}(\{{$\mathbb{S}\rbrace\sphat\lbrace$}n-1\}\textbackslash times\{𝕉\})\} \$is some special norm. The formula extends the Radon transform to the bijective Hilbert space isometry\$ R:L\^\{2\}(\{𝕉\}\^\{n\})\textbackslash rightarrow H\^\{(n-1)/2\}\_\{(n-1)/2,e\}(\{{$\mathbb{S}\rbrace\sphat\lbrace$}n-1\}\textbackslash times\{𝕉\}) \$.Given reals~\$ r \$, \$ s \$, and \$ t{$>$}-n/2 \$, we introduce the Sobolev type spaces\$ H\^\{(r,s)\}\_\{t\}(\{𝕉\}\^\{n\}) \$and \$ H\^\{(r,s)\}\_\{t,e\}(\{{$\mathbb{S}\rbrace\sphat\lbrace$}n-1\}\textbackslash times\{𝕉\}) \$and prove the version of the Reshetnyak formula:\$ \textbackslash |f\textbackslash |\_\{H\^\{(r,s)\}\_\{t\}(\{𝕉\}\^\{n\})\}=\textbackslash |Rf\textbackslash |\_\{H\^\{(r,(s+n-1)/2)\}\_\{t+(n-1)/2\}(\{{$\mathbb{S}\rbrace\sphat\lbrace$}n-1\}\textbackslash times\{𝕉\})\} \$.The formula extends the Radon transform to the bijective Hilbert space isometry\$ R:H\^\{(r,s)\}\_\{t\}(\{𝕉\}\^\{n\})\textbackslash rightarrow H\^\{(r,s+(n-1)/2)\}\_\{t+(n-1)/2,e\}(\{{$\mathbb{S}\rbrace\sphat\lbrace$}n-1\}\textbackslash times\{𝕉\}) \$.If \$ r\textbackslash geq 0 \$and \$ s\textbackslash geq 0 \$are integers then \$ H\^\{(r,s)\}\_\{0,e\}(\{{$\mathbb{S}\rbrace\sphat\lbrace$}n-1\}\textbackslash times\{𝕉\}) \$consists of the even functions \$ \textbackslash varphi(\textbackslash xi,p) \$with square integrable derivatives of order~\$ \textbackslash leq r \$with respect to~\$ \textbackslash xi \$and order~\$ \textbackslash leq s \$with respect to~\$ p \$.},
  langid = {english},
  keywords = {517.9,Radon transform,Reshetnyak formula,Sobolev spaces}
}

@article{sharafutdinovReshetnyakFormulaNatterer2016,
  title = {The {{Reshetnyak}} Formula and {{Natterer}} Stability Estimates in Tensor Tomography},
  author = {Sharafutdinov, Vladimir A.},
  year = {2016},
  month = dec,
  journal = {Inverse Problems},
  volume = {33},
  number = {2},
  pages = {025002},
  publisher = {{IOP Publishing}},
  issn = {0266-5611},
  doi = {10.1088/1361-6420/33/2/025002},
  urldate = {2023-05-02},
  abstract = {The Reshetnyak formula (also known as the Plancherel formula for the Radon transform) states that the Radon transform R is an isometry between and , the latter being the Hilbert space of even functions on furnished by some special norm. We generalize this statement to Sobolev spaces: R is an isometry between and for every real s. Moreover, with the help of Riesz potentials, we define some new Hilbert spaces and prove that R is an isometry between and . The generalized Reshetnyak formula closely relates to the Natterer stability estimates: for functions f supported in a fixed ball. Then we obtain analogs of these statements for the x-ray transform of symmetric tensor fields.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/2EZE2WKI/Sharafutdinov - 2016 - The Reshetnyak formula and Natterer stability esti.pdf}
}

@article{shenNeRPImplicitNeural2022,
  title = {{{NeRP}}: {{Implicit Neural Representation Learning With Prior Embedding}} for {{Sparsely Sampled Image Reconstruction}}},
  shorttitle = {{{NeRP}}},
  author = {Shen, Liyue and Pauly, John and Xing, Lei},
  year = {2022},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  pages = {1--13},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2022.3177134},
  urldate = {2022-11-03},
  abstract = {Image reconstruction is an inverse problem that solves for a computational image based on sampled sensor measurement. Sparsely sampled image reconstruction poses addition challenges due to limited measurements. In this work, we propose an implicit Neural Representation learning methodology with Prior embedding (NeRP) to reconstruct a computational image from sparsely sampled measurements. The method differs fundamentally from previous deep learning-based image reconstruction approaches in that NeRP exploits the internal information in an image prior, and the physics of the sparsely sampled measurements to produce a representation of the unknown subject. No large-scale data is required to train the NeRP except for a prior image and sparsely sampled measurements. In addition, we demonstrate that NeRP is a general methodology that generalizes to different imaging modalities such as CT and MRI. We also show that NeRP can robustly capture the subtle yet significant image changes required for assessing tumor progression.},
  langid = {english},
  keywords = {notion},
  file = {C\:\\Users\\Tabita\\Documents\\ACIP\\Abstract\\nerp.pdf}
}

@misc{siarohinUnsupervisedVolumetricAnimation2023,
  title = {Unsupervised {{Volumetric Animation}}},
  author = {Siarohin, Aliaksandr and Menapace, Willi and Skorokhodov, Ivan and Olszewski, Kyle and Ren, Jian and Lee, Hsin-Ying and Chai, Menglei and Tulyakov, Sergey},
  year = {2023},
  month = jan,
  number = {arXiv:2301.11326},
  eprint = {2301.11326},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2301.11326},
  urldate = {2023-03-02},
  abstract = {We propose a novel approach for unsupervised 3D animation of non-rigid deformable objects. Our method learns the 3D structure and dynamics of objects solely from single-view RGB videos, and can decompose them into semantically meaningful parts that can be tracked and animated. Using a 3D autodecoder framework, paired with a keypoint estimator via a differentiable PnP algorithm, our model learns the underlying object geometry and parts decomposition in an entirely unsupervised manner. This allows it to perform 3D segmentation, 3D keypoint estimation, novel view synthesis, and animation. We primarily evaluate the framework on two video datasets: VoxCeleb \$256\^2\$ and TEDXPeople \$256\^2\$. In addition, on the Cats \$256\^2\$ image dataset, we show it even learns compelling 3D geometry from still images. Finally, we show our model can obtain animatable 3D objects from a single or few images. Code and visual results available on our project website, see https://snap-research.github.io/unsupervised-volumetric-animation .},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/T4QZGQ2N/Siarohin et al. - 2023 - Unsupervised Volumetric Animation.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/W9BT79BR/2301.html}
}

@misc{sitzmannImplicitNeuralRepresentations2020,
  title = {Implicit {{Neural Representations}} with {{Periodic Activation Functions}}},
  author = {Sitzmann, Vincent and Martel, Julien N. P. and Bergman, Alexander W. and Lindell, David B. and Wetzstein, Gordon},
  year = {2020},
  month = jun,
  number = {arXiv:2006.09661},
  eprint = {2006.09661},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  urldate = {2022-11-03},
  abstract = {Implicitly defined, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible benefits over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with fine detail, and fail to represent a signal's spatial and temporal derivatives, despite the fact that these are essential to many physical signals defined implicitly as the solution to partial differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or SIRENs, are ideally suited for representing complex natural signals and their derivatives. We analyze SIREN activation statistics to propose a principled initialization scheme and demonstrate the representation of images, wavefields, video, sound, and their derivatives. Further, we show how SIRENs can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine SIRENs with hypernetworks to learn priors over the space of SIREN functions. Please see the project website for a video overview of the proposed method and all applications.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C\:\\Users\\Tabita\\Documents\\ACIP\\Abstract\\siren.pdf}
}

@misc{tamirUnsupervisedDeepBasis2020,
  title = {Unsupervised {{Deep Basis Pursuit}}: {{Learning}} Inverse Problems without Ground-Truth Data},
  shorttitle = {Unsupervised {{Deep Basis Pursuit}}},
  author = {Tamir, Jonathan I. and Yu, Stella X. and Lustig, Michael},
  year = {2020},
  month = feb,
  number = {arXiv:1910.13110},
  eprint = {1910.13110},
  primaryclass = {eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1910.13110},
  urldate = {2023-04-26},
  abstract = {Basis pursuit is a compressed sensing optimization in which the l1-norm is minimized subject to model error constraints. Here we use a deep neural network prior instead of l1-regularization. Using known noise statistics, we jointly learn the prior and reconstruct images without access to ground-truth data. During training, we use alternating minimization across an unrolled iterative network and jointly solve for the neural network weights and training set image reconstructions. At inference, we fix the weights and pass the measurements through the network. We compare reconstruction performance between unsupervised and supervised (i.e. with ground-truth) methods. We hypothesize this technique could be used to learn reconstruction when ground-truth data are unavailable, such as in high-resolution dynamic MRI.},
  archiveprefix = {arxiv},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing,Electrical Engineering and Systems Science - Signal Processing},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/YSM7QJ96/Tamir et al. - 2020 - Unsupervised Deep Basis Pursuit Learning inverse .pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/G36KQGQT/1910.html}
}

@inproceedings{tancikFourierFeaturesLet2020a,
  title = {Fourier {{Features Let Networks Learn High Frequency Functions}} in {{Low Dimensional Domains}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and {Fridovich-Keil}, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
  year = {2020},
  volume = {33},
  pages = {7537--7547},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-11-09},
  abstract = {We show that passing input points through a simple Fourier feature mapping enables a multilayer perceptron (MLP) to learn high-frequency functions in low-dimensional problem domains. These results shed light on recent advances in computer vision and graphics that achieve state-of-the-art results by using MLPs to represent complex 3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature, we show that a standard MLP has impractically slow convergence to high frequency signal components. To overcome this spectral bias, we use a Fourier feature mapping to transform the effective NTK into a stationary kernel with a tunable bandwidth. We suggest an approach for selecting problem-specific Fourier features that greatly improves the performance of MLPs for low-dimensional regression tasks relevant to the computer vision and graphics communities.},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/CTZ5YMIK/Tancik et al. - 2020 - Fourier Features Let Networks Learn High Frequency.pdf}
}

@inproceedings{tancikLearnedInitializationsOptimizing2021a,
  title = {Learned {{Initializations}} for {{Optimizing Coordinate-Based Neural Representations}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Tancik, Matthew and Mildenhall, Ben and Wang, Terrance and Schmidt, Divi and Srinivasan, Pratul P. and Barron, Jonathan T. and Ng, Ren},
  year = {2021},
  month = jun,
  pages = {2845--2854},
  publisher = {{IEEE}},
  address = {{Nashville, TN, USA}},
  doi = {10.1109/CVPR46437.2021.00287},
  urldate = {2023-07-13},
  abstract = {Coordinate-based neural representations have shown significant promise as an alternative to discrete, arraybased representations for complex low dimensional signals. However, optimizing a coordinate-based network from randomly initialized weights for each new signal is inefficient. We propose applying standard meta-learning algorithms to learn the initial weight parameters for these fully-connected networks based on the underlying class of signals being represented (e.g., images of faces or 3D models of chairs). Despite requiring only a minor change in implementation, using these learned initial weights enables faster convergence during optimization and can serve as a strong prior over the signal class being modeled, resulting in better generalization when only partial observations of a given signal are available. We explore these benefits across a variety of tasks, including representing 2D images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D image observations.},
  isbn = {978-1-66544-509-2},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/5KJAKFRX/Tancik et al. - 2021 - Learned Initializations for Optimizing Coordinate-.pdf}
}

@article{tezcanMRImageReconstruction2019,
  title = {{{MR}} Image Reconstruction Using Deep Density Priors},
  author = {Tezcan, Kerem C. and Baumgartner, Christian F. and Luechinger, Roger and Pruessmann, Klaas P. and Konukoglu, Ender},
  year = {2019},
  month = jul,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {38},
  number = {7},
  eprint = {1711.11386},
  primaryclass = {cs, eess, stat},
  pages = {1633--1642},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2018.2887072},
  urldate = {2022-11-08},
  abstract = {Algorithms for Magnetic Resonance (MR) image reconstruction from undersampled measurements exploit prior information to compensate for missing k-space data. Deep learning (DL) provides a powerful framework for extracting such information from existing image datasets, through learning, and then using it for reconstruction. Leveraging this, recent methods employed DL to learn mappings from undersampled to fully sampled images using paired datasets, including undersampled and corresponding fully sampled images, integrating prior knowledge implicitly. In this article, we propose an alternative approach that learns the probability distribution of fully sampled MR images using unsupervised DL, specifically Variational Autoencoders (VAE), and use this as an explicit prior term in reconstruction, completely decoupling the encoding operation from the prior. The resulting reconstruction algorithm enjoys a powerful image prior to compensate for missing k-space data without requiring paired datasets for training nor being prone to associated sensitivities, such as deviations in undersampling patterns used in training and test time or coil settings. We evaluated the proposed method with T1 weighted images from a publicly available dataset, multi-coil complex images acquired from healthy volunteers (N=8) and images with white matter lesions. The proposed algorithm, using the VAE prior, produced visually high quality reconstructions and achieved low RMSE values, outperforming most of the alternative methods on the same dataset. On multi-coil complex data, the algorithm yielded accurate magnitude and phase reconstruction results. In the experiments on images with white matter lesions, the method faithfully reconstructed the lesions. Keywords: Reconstruction, MRI, prior probability, machine learning, deep learning, unsupervised learning, density estimation},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing,Statistics - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/84M28JM7/Tezcan et al. - 2019 - MR image reconstruction using deep density priors.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/62WU4MLJ/1711.html}
}

@article{tsaoKtBLASTKt2003,
  title = {K-t {{BLAST}} and k-t {{SENSE}}: {{Dynamic MRI}} with High Frame Rate Exploiting Spatiotemporal Correlations},
  shorttitle = {K-t {{BLAST}} and k-t {{SENSE}}},
  author = {Tsao, Jeffrey and Boesiger, Peter and Pruessmann, Klaas P.},
  year = {2003},
  journal = {Magnetic Resonance in Medicine},
  volume = {50},
  number = {5},
  pages = {1031--1042},
  issn = {1522-2594},
  doi = {10.1002/mrm.10611},
  urldate = {2022-12-16},
  abstract = {Dynamic images of natural objects exhibit significant correlations in k-space and time. Thus, it is feasible to acquire only a reduced amount of data and recover the missing portion afterwards. This leads to an improved temporal resolution, or an improved spatial resolution for a given amount of acquisition. Based on this approach, two methods were developed to significantly improve the performance of dynamic imaging, named k-t BLAST (Broad-use Linear Acquisition Speed-up Technique) and k-t SENSE (SENSitivity Encoding) for use with a single or multiple receiver coils, respectively. Signal correlations were learned from a small set of training data and the missing data were recovered using all available information in a consistent and integral manner. The general theory of k-t BLAST and k-t SENSE is applicable to arbitrary k-space trajectories, time-varying coil sensitivities, and under- and overdetermined reconstruction problems. Examples from ungated cardiac imaging demonstrate a 4-fold acceleration (voxel size 2.42 \texttimes{} 2.52 mm2, 38.4 fps) with either one or six receiver coils. k-t BLAST and k-t SENSE are applicable to many areas, especially those exhibiting quasiperiodic motion, such as imaging of the heart, the lungs, the abdomen, and the brain under periodic stimulation. Magn Reson Med 50:1031\textendash 1042, 2003. \textcopyright{} 2003 Wiley-Liss, Inc.},
  langid = {english},
  keywords = {fast dynamic imaging,k-t BLAST,k-t SENSE,MRI,prior-information-driven parallel imaging},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/BVAM8NWC/Tsao et al. - 2003 - k-t BLAST and k-t SENSE Dynamic MRI with high fra.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/IP3P2JWM/mrm.html}
}

@article{ueckerESPIRiTEigenvalueApproach2014,
  title = {{{ESPIRiT}}\textemdash an Eigenvalue Approach to Autocalibrating Parallel {{MRI}}: {{Where SENSE}} Meets {{GRAPPA}}},
  shorttitle = {{{ESPIRiT}}\textemdash an Eigenvalue Approach to Autocalibrating Parallel {{MRI}}},
  author = {Uecker, Martin and Lai, Peng and Murphy, Mark J. and Virtue, Patrick and Elad, Michael and Pauly, John M. and Vasanawala, Shreyas S. and Lustig, Michael},
  year = {2014},
  journal = {Magnetic Resonance in Medicine},
  volume = {71},
  number = {3},
  pages = {990--1001},
  issn = {1522-2594},
  doi = {10.1002/mrm.24751},
  urldate = {2023-06-27},
  abstract = {Purpose Parallel imaging allows the reconstruction of images from undersampled multicoil data. The two main approaches are: SENSE, which explicitly uses coil sensitivities, and GRAPPA, which makes use of learned correlations in k-space. The purpose of this work is to clarify their relationship and to develop and evaluate an improved algorithm. Theory and Methods A theoretical analysis shows: (1) The correlations in k-space are encoded in the null space of a calibration matrix. (2) Both approaches restrict the solution to a subspace spanned by the sensitivities. (3) The sensitivities appear as the main eigenvector of a reconstruction operator computed from the null space. The basic assumptions and the quality of the sensitivity maps are evaluated in experimental examples. The appearance of additional eigenvectors motivates an extended SENSE reconstruction with multiple maps, which is compared to existing methods. Results The existence of a null space and the high quality of the extracted sensitivities are confirmed. The extended reconstruction combines all advantages of SENSE with robustness to certain errors similar to GRAPPA. Conclusion In this article the gap between both approaches is finally bridged. A new autocalibration technique combines the benefits of both. Magn Reson Med 71:990\textendash 1001, 2014. \textcopyright{} 2013 Wiley Periodicals, Inc.},
  copyright = {Copyright \textcopyright{} 2013 Wiley Periodicals, Inc.},
  langid = {english},
  keywords = {autocalibration,compressed sensing,GRAPPA,parallel imaging,SENSE},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/VLHPH97E/Uecker et al. - 2014 - ESPIRiT—an eigenvalue approach to autocalibrating .pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/2DIBQJNP/mrm.html}
}

@article{ulyanovDeepImagePrior2020,
  title = {Deep {{Image Prior}}},
  author = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  year = {2020},
  month = jul,
  journal = {International Journal of Computer Vision},
  volume = {128},
  number = {7},
  eprint = {1711.10925},
  primaryclass = {cs, stat},
  pages = {1867--1888},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-020-01303-4},
  urldate = {2022-11-08},
  abstract = {Deep convolutional networks have become a popular tool for image generation and restoration. Generally, their excellent performance is imputed to their ability to learn realistic image priors from a large number of example images. In this paper, we show that, on the contrary, the structure of a generator network is sufficient to capture a great deal of low-level image statistics prior to any learning. In order to do so, we show that a randomly-initialized neural network can be used as a handcrafted prior with excellent results in standard inverse problems such as denoising, super-resolution, and inpainting. Furthermore, the same prior can be used to invert deep neural representations to diagnose them, and to restore images based on flash-no flash input pairs. Apart from its diverse applications, our approach highlights the inductive bias captured by standard generator network architectures. It also bridges the gap between two very popular families of image restoration methods: learning-based methods using deep convolutional networks and learning-free methods based on handcrafted image priors such as self-similarity. Code and supplementary material are available at https://dmitryulyanov.github.io/deep\_image\_prior .},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Statistics - Machine Learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/ATY3YZBC/Ulyanov et al. - 2020 - Deep Image Prior.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/SKM3IJ7T/1711.html}
}

@article{waltScikitimageImageProcessing2014,
  title = {Scikit-Image: Image Processing in {{Python}}},
  shorttitle = {Scikit-Image},
  author = {van der Walt, St{\'e}fan and Sch{\"o}nberger, Johannes L. and {Nunez-Iglesias}, Juan and Boulogne, Fran{\c c}ois and Warner, Joshua D. and Yager, Neil and Gouillart, Emmanuelle and Yu, Tony},
  year = {2014},
  month = jun,
  journal = {PeerJ},
  volume = {2},
  pages = {e453},
  publisher = {{PeerJ Inc.}},
  issn = {2167-8359},
  doi = {10.7717/peerj.453},
  urldate = {2023-06-29},
  abstract = {scikit-image is an image processing library that implements algorithms and utilities for use in research, education and industry applications. It is released under the liberal Modified BSD open source license, provides a well-documented API in the Python programming language, and is developed by an active, international team of collaborators. In this paper we highlight the advantages of open source to achieve the goals of the scikit-image library, and we showcase several real-world image processing applications that use scikit-image. More information can be found on the project homepage, http://scikit-image.org.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/GHTPTLUC/Walt et al. - 2014 - scikit-image image processing in Python.pdf}
}

@article{wangImageQualityAssessment2004,
  title = {Image Quality Assessment: From Error Visibility to Structural Similarity},
  shorttitle = {Image Quality Assessment},
  author = {Wang, Zhou and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  year = {2004},
  month = apr,
  journal = {IEEE Transactions on Image Processing},
  volume = {13},
  number = {4},
  pages = {600--612},
  issn = {1941-0042},
  doi = {10.1109/TIP.2003.819861},
  abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.},
  keywords = {Data mining,Degradation,Humans,Image quality,Indexes,Layout,Quality assessment,Transform coding,Visual perception,Visual system},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/C8UVVMJU/Wang et al. - 2004 - Image quality assessment from error visibility to.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/7GJAJQA6/1284395.html}
}

@article{weiRealtime3DMRI,
  title = {Real-Time {{3D MRI}} Reconstruction from Cine-{{MRI}} Using Unsupervised Network in {{MRI-guided}} Radiotherapy for Liver Cancer},
  author = {Wei, Ran and Chen, Jiayun and Liang, Bin and Chen, Xinyuan and Men, Kuo and Dai, Jianrong},
  journal = {Medical Physics},
  volume = {n/a},
  number = {n/a},
  issn = {2473-4209},
  doi = {10.1002/mp.16141},
  urldate = {2023-04-26},
  abstract = {Purpose Respiration has a major impact on the accuracy of radiation treatment for thorax and abdominal tumours. Instantaneous volumetric imaging could provide precise knowledge of tumour and normal organs' three-dimensional (3D) movement, which is the key to reducing the negative effect of breathing motion. Therefore, this study proposed a real-time 3D MRI reconstruction method from cine-MRI using an unsupervised network. Methods and materials Cine-MRI and setup 3D-MRI from eight patients with liver cancer were utilized to establish and validate the deep learning network for 3D-MRI reconstruction. Unlike previous methods that required 4D-MRI for network training, the proposed method utilized a reference 3D-MRI and cine-MRI to generate the training data. Then, a network was trained in an unsupervised manner to estimate the relationship between the cine-MRI acquired on coronal plane and deformation vector field (DVF) that describes the patient's breathing motion. After the training process, the coronal cine-MRI were inputted into the network, and the corresponding DVF was obtained. By wrapping the reference 3D-MRI with the generated DVF, the 3D-MRI could be reconstructed. Results The reconstructed 3D-MRI slices were compared with the corresponding phase-sorted cine-MRI using dice similarity coefficients (DSCs) of liver contours and blood vessel localization error. In all patients, the liver DSC had mean value {$>$}96.1\% and standard deviation {$<$} 1.3\%; the blood vessel localization error had mean value {$<$}2.6 mm, and standard deviation was {$<$}2.0 mm. Moreover, the time for 3D-MRI reconstruction was approximately 100 ms. These results indicated that the proposed method could accurately reconstruct the 3D-MRI in real time. Conclusions The proposed method could accurately reconstruct the 3D-MRI from cine-MRI in real time. This method has great potential in improving the accuracy of radiotherapy for moving tumours.},
  langid = {english},
  keywords = {3D-MRI reconstruction,cine-MRI,unsupervised learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/M4W3D4KH/Wei et al. - Real-time 3D MRI reconstruction from cine-MRI usin.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/WT768LIQ/mp.html}
}

@inproceedings{wolterinkImplicitNeuralRepresentations2022,
  title = {Implicit {{Neural Representations}} for {{Deformable Image Registration}}},
  booktitle = {Proceedings of {{The}} 5th {{International Conference}} on {{Medical Imaging}} with {{Deep Learning}}},
  author = {Wolterink, Jelmer M. and Zwienenberg, Jesse C. and Brune, Christoph},
  year = {2022},
  month = dec,
  pages = {1349--1359},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-05-22},
  abstract = {Deformable medical image registration has in past years been revolutionized by the use of convolutional neural networks. These methods surpass conventional image registration techniques in speed but not in accuracy. Here, we present an alternative approach to leveraging neural networks for image registration. Instead of using a convolutional neural network to predict the transformation between images, we optimize a multi-layer perceptron to represent this transformation function. Using recent insights from differentiable rendering, we show how such an implicit deformable image registration (IDIR) model can be naturally combined with regularization terms based on standard automatic differentiation techniques. We demonstrate the effectiveness of this model on 4D chest CT registration in the DIR-LAB data set and find that a three-layer multi-layer perceptron with periodic activation functions outperforms all published deep learning-based results on this problem, without any folding and without the need for training data. The model is implemented using standard deep learning libraries and flexible enough to be extended to include different losses, regularizers, and optimization schemes.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/EMIMPM27/Wolterink et al. - 2022 - Implicit Neural Representations for Deformable Ima.pdf}
}

@misc{wuNeuralFourierFilter2022,
  title = {Neural {{Fourier Filter Bank}}},
  author = {Wu, Zhijie and Jin, Yuhe and Yi, Kwang Moo},
  year = {2022},
  month = dec,
  number = {arXiv:2212.01735},
  eprint = {2212.01735},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2212.01735},
  urldate = {2023-03-02},
  abstract = {We present a novel method to provide efficient and highly detailed reconstructions. Inspired by wavelets, our main idea is to learn a neural field that decompose the signal both spatially and frequency-wise. We follow the recent grid-based paradigm for spatial decomposition, but unlike existing work, encourage specific frequencies to be stored in each grid via Fourier features encodings. We then apply a multi-layer perceptron with sine activations, taking these Fourier encoded features in at appropriate layers so that higher-frequency components are accumulated on top of lower-frequency components sequentially, which we sum up to form the final output. We demonstrate that our method outperforms the state of the art regarding model compactness and efficiency on multiple tasks: 2D image fitting, 3D shape reconstruction, and neural radiance fields.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/JM2XAX5Y/Wu et al. - 2022 - Neural Fourier Filter Bank.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/PD729J3X/2212.html}
}

@article{xieNeuralFieldsVisual2022,
  title = {Neural {{Fields}} in {{Visual Computing}} and {{Beyond}}},
  author = {Xie, Yiheng and Takikawa, Towaki and Saito, Shunsuke and Litany, Or and Yan, Shiqin and Khan, Numair and Tombari, Federico and Tompkin, James and Sitzmann, Vincent and Sridhar, Srinath},
  year = {2022},
  journal = {Computer Graphics Forum},
  volume = {41},
  number = {2},
  pages = {641--676},
  issn = {1467-8659},
  doi = {10.1111/cgf.14505},
  urldate = {2022-11-09},
  abstract = {Recent advances in machine learning have led to increased interest in solving visual computing problems using methods that employ coordinate-based neural networks. These methods, which we call neural fields, parameterize physical properties of scenes or objects across space and time. They have seen widespread success in problems such as 3D shape and image synthesis, animation of human bodies, 3D reconstruction, and pose estimation. Rapid progress has led to numerous papers, but a consolidation of the discovered knowledge has not yet emerged. We provide context, mathematical grounding, and a review of over 250 papers in the literature on neural fields. In Part I, we focus on neural field techniques by identifying common components of neural field methods, including different conditioning, representation, forward map, architecture, and manipulation methods. In Part II, we focus on applications of neural fields to different problems in visual computing, and beyond (e.g., robotics, audio). Our review shows the breadth of topics already covered in visual computing, both historically and in current incarnations, and highlights the improved quality, flexibility, and capability brought by neural field methods. Finally, we present a companion website that acts as a living database that can be continually updated by the community.},
  langid = {english},
  keywords = {\textbullet{} Computing methodologies \textrightarrow{} Machine Learning,Artificial Intelligence,CCS Concepts,notion},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/XBTPFYAM/Xie et al. - 2022 - Neural Fields in Visual Computing and Beyond.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/UF3YAT23/cgf.html}
}

@article{xuNeSVoRImplicitNeural2023,
  title = {{{NeSVoR}}: {{Implicit Neural Representation}} for {{Slice-to-Volume Reconstruction}} in {{MRI}}},
  shorttitle = {{{NeSVoR}}},
  author = {Xu, Junshen and Moyer, Daniel and Gagoski, Borjan and Iglesias, Juan Eugenio and Ellen Grant, P. and Golland, Polina and Adalsteinsson, Elfar},
  year = {2023},
  journal = {IEEE Transactions on Medical Imaging},
  pages = {1--1},
  issn = {1558-254X},
  doi = {10.1109/TMI.2023.3236216},
  abstract = {Reconstructing 3D MR volumes from multiple motion-corrupted stacks of 2D slices has shown promise in imaging of moving subjects, e.g., fetal MRI. However, existing slice-to-volume reconstruction methods are time-consuming, especially when a high-resolution volume is desired. Moreover, they are still vulnerable to severe subject motion and when image artifacts are present in acquired slices. In this work, we present NeSVoR, a resolution-agnostic slice-to-volume reconstruction method, which models the underlying volume as a continuous function of spatial coordinates with implicit neural representation. To improve robustness to subject motion and other image artifacts, we adopt a continuous and comprehensive slice acquisition model that takes into account rigid inter-slice motion, point spread function, and bias fields. NeSVoR also estimates pixel-wise and slice-wise variances of image noise and enables removal of outliers during reconstruction and visualization of uncertainty. Extensive experiments are performed on both simulated and in vivo data to evaluate the proposed method. Results show that NeSVoR achieves state-of-the-art reconstruction quality while providing two to ten-fold acceleration in reconstruction times over the state-of-the-art algorithms.},
  keywords = {3D reconstruction,Biomedical imaging,Encoding,fetal brain MRI,Image reconstruction,implicit neural representation,Magnetic resonance imaging,motion correction,MRI,slice-to-volume reconstruction,Solid modeling,super-resolution,Three-dimensional displays,Training},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/RS7EGA5H/NeSVoR_Implicit_Neural_Representation_for_Slice-to-Volume_Reconstruction_in_MRI.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/VBY67VZG/Xu et al. - 2023 - NeSVoR Implicit Neural Representation for Slice-t.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/29GPSKRC/stamp.html}
}

@article{yamanSelfsupervisedLearningPhysicsguided2020,
  title = {Self-Supervised Learning of Physics-Guided Reconstruction Neural Networks without Fully Sampled Reference Data},
  author = {Yaman, Burhaneddin and Hosseini, Seyed Amir Hossein and Moeller, Steen and Ellermann, Jutta and U{\u g}urbil, K{\^a}mil and Ak{\c c}akaya, Mehmet},
  year = {2020},
  journal = {Magnetic Resonance in Medicine},
  volume = {84},
  number = {6},
  pages = {3172--3191},
  issn = {1522-2594},
  doi = {10.1002/mrm.28378},
  urldate = {2023-06-22},
  abstract = {Purpose To develop a strategy for training a physics-guided MRI reconstruction neural network without a database of fully sampled data sets. Methods Self-supervised learning via data undersampling (SSDU) for physics-guided deep learning reconstruction partitions available measurements into two disjoint sets, one of which is used in the data consistency (DC) units in the unrolled network and the other is used to define the loss for training. The proposed training without fully sampled data is compared with fully supervised training with ground-truth data, as well as conventional compressed-sensing and parallel imaging methods using the publicly available fastMRI knee database. The same physics-guided neural network is used for both proposed SSDU and supervised training. The SSDU training is also applied to prospectively two-fold accelerated high-resolution brain data sets at different acceleration rates, and compared with parallel imaging. Results Results on five different knee sequences at an acceleration rate of 4 shows that the proposed self-supervised approach performs closely with supervised learning, while significantly outperforming conventional compressed-sensing and parallel imaging, as characterized by quantitative metrics and a clinical reader study. The results on prospectively subsampled brain data sets, in which supervised learning cannot be used due to lack of ground-truth reference, show that the proposed self-supervised approach successfully performs reconstruction at high acceleration rates (4, 6, and 8). Image readings indicate improved visual reconstruction quality with the proposed approach compared with parallel imaging at acquisition acceleration. Conclusion The proposed SSDU approach allows training of physics-guided deep learning MRI reconstruction without fully sampled data, while achieving comparable results with supervised deep learning MRI trained on fully sampled data.},
  copyright = {\textcopyright{} 2020 International Society for Magnetic Resonance in Medicine},
  langid = {english},
  keywords = {accelerated imaging,convolutional neural networks,deep learning,image reconstruction,parallel imaging,self-supervised learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/SWI9EML3/Yaman et al. - 2020 - Self-supervised learning of physics-guided reconst.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/UUMHRI63/mrm.html}
}

@article{yangDAGANDeepDeAliasing2018,
  title = {{{DAGAN}}: {{Deep De-Aliasing Generative Adversarial Networks}} for {{Fast Compressed Sensing MRI Reconstruction}}},
  shorttitle = {{{DAGAN}}},
  author = {Yang, Guang and Yu, Simiao and Dong, Hao and Slabaugh, Greg and Dragotti, Pier Luigi and Ye, Xujiong and Liu, Fangde and Arridge, Simon and Keegan, Jennifer and Guo, Yike and Firmin, David},
  year = {2018},
  month = jun,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {37},
  number = {6},
  pages = {1310--1321},
  issn = {1558-254X},
  doi = {10.1109/TMI.2017.2785879},
  abstract = {Compressed sensing magnetic resonance imaging (CS-MRI) enables fast acquisition, which is highly desirable for numerous clinical applications. This can not only reduce the scanning cost and ease patient burden, but also potentially reduce motion artefacts and the effect of contrast washout, thus yielding better image quality. Different from parallel imaging-based fast MRI, which utilizes multiple coils to simultaneously receive MR signals, CS-MRI breaks the Nyquist-Shannon sampling barrier to reconstruct MRI images with much less required raw data. This paper provides a deep learning-based strategy for reconstruction of CS-MRI, and bridges a substantial gap between conventional non-learning methods working only on data from a single image, and prior knowledge from large training data sets. In particular, a novel conditional Generative Adversarial Networks-based model (DAGAN)-based model is proposed to reconstruct CS-MRI. In our DAGAN architecture, we have designed a refinement learning method to stabilize our U-Net based generator, which provides an end-to-end network to reduce aliasing artefacts. To better preserve texture and edges in the reconstruction, we have coupled the adversarial loss with an innovative content loss. In addition, we incorporate frequency-domain information to enforce similarity in both the image and frequency domains. We have performed comprehensive comparison studies with both conventional CS-MRI reconstruction methods and newly investigated deep learning approaches. Compared with these methods, our DAGAN method provides superior reconstruction with preserved perceptual image details. Furthermore, each image is reconstructed in about 5 ms, which is suitable for real-time processing.},
  keywords = {Acceleration,Compressed sensing,de-aliasing,deep learning,Encoding,fast MRI,generative adversarial networks (GAN),Image reconstruction,inverse problems,Machine learning,magnetic resonance imaging (MRI),Transforms},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/7E99MD3R/Yang et al. - 2018 - DAGAN Deep De-Aliasing Generative Adversarial Net.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/99999P97/8233175.html}
}

@misc{yangTINCTreestructuredImplicit2022,
  title = {{{TINC}}: {{Tree-structured Implicit Neural Compression}}},
  shorttitle = {{{TINC}}},
  author = {Yang, Runzhao and Xiao, Tingxiong and Cheng, Yuxiao and Suo, Jinli and Dai, Qionghai},
  year = {2022},
  month = nov,
  number = {arXiv:2211.06689},
  eprint = {2211.06689},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2211.06689},
  urldate = {2023-03-02},
  abstract = {Implicit neural representation (INR) can describe the target scenes with high fidelity using a small number of parameters, and is emerging as a promising data compression technique. However, INR in intrinsically of limited spectrum coverage, and it is non-trivial to remove redundancy in diverse complex data effectively. Preliminary studies can only exploit either global or local correlation in the target data and thus of limited performance. In this paper, we propose a Tree-structured Implicit Neural Compression (TINC) to conduct compact representation for local regions and extract the shared features of these local representations in a hierarchical manner. Specifically, we use MLPs to fit the partitioned local regions, and these MLPs are organized in tree structure to share parameters according to the spatial distance. The parameter sharing scheme not only ensures the continuity between adjacent regions, but also jointly removes the local and non-local redundancy. Extensive experiments show that TINC improves the compression fidelity of INR, and has shown impressive compression capabilities over commercial tools and other deep learning based methods. Besides, the approach is of high flexibility and can be tailored for different data and parameter settings. All the reproducible codes are going to be released on github.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/XVK87A5N/Yang et al. - 2022 - TINC Tree-structured Implicit Neural Compression.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/9JLGESMV/2211.html}
}

@inproceedings{yazdanpanahNonLearningBasedDeep2019,
  title = {Non-{{Learning}} Based {{Deep Parallel MRI Reconstruction}} ({{NLDpMRI}})},
  booktitle = {Medical {{Imaging}} 2019: {{Image Processing}}},
  author = {Yazdanpanah, Ali Pour and Afacan, Onur and Warfield, Simon K.},
  year = {2019},
  month = mar,
  eprint = {1808.02122},
  primaryclass = {cs},
  pages = {3},
  doi = {10.1117/12.2511653},
  urldate = {2022-11-08},
  abstract = {Fast data acquisition in Magnetic Resonance Imaging (MRI) is vastly in demand and scan time directly depends on the number of acquired k-space samples. Recently, the deep learning-based MRI reconstruction techniques were suggested to accelerate MR image acquisition. The most common issues in any deep learning-based MRI reconstruction approaches are generalizability and transferability. For different MRI scanner configurations using these approaches, the network must be trained from scratch every time with new training dataset, acquired under new configurations, to be able to provide good reconstruction performance. Here, we propose a new generalized parallel imaging method based on deep neural networks called NLDpMRI to reduce any structured aliasing ambiguities related to the different k-space undersampling patterns for accelerated data acquisition. Two loss functions including non-regularized and regularized are proposed for parallel MRI reconstruction using deep network optimization and we reconstruct MR images by optimizing the proposed loss functions over the network parameters. Unlike any deep learning-based MRI reconstruction approaches, our method doesn't include any training step that the network learns from a large number of training samples and it only needs the single undersampled multi-coil k-space data for reconstruction. Also, the proposed method can handle k-space data with different undersampling patterns, and the different number of coils. Experimental results show that the proposed method outperforms the current state-of-the-art GRAPPA method and the deep learning-based variational network method.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,notion},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/L869CEN7/Yazdanpanah et al. - 2019 - Non-Learning based Deep Parallel MRI Reconstructio.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/DP8W2HNI/1808.html}
}

@misc{yooTimeDependentDeepImage2021,
  title = {Time-{{Dependent Deep Image Prior}} for {{Dynamic MRI}}},
  author = {Yoo, Jaejun and Jin, Kyong Hwan and Gupta, Harshit and Yerly, Jerome and Stuber, Matthias and Unser, Michael},
  year = {2021},
  month = jan,
  number = {arXiv:1910.01684},
  eprint = {1910.01684},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  urldate = {2022-11-08},
  abstract = {We propose a novel unsupervised deep-learning-based algorithm for dynamic magnetic resonance imaging (MRI) reconstruction. Dynamic MRI requires rapid data acquisition for the study of moving organs such as the heart. Existing reconstruction methods suffer from restrictions either in the model design or in the absence of ground-truth data, resulting in low image quality. We introduce a generalized version of the deep-image-prior approach, which optimizes the network weights to fit a sequence of sparsely acquired dynamic MRI measurements. Our method needs neither prior training nor additional data. In particular, for cardiac images, it does not require the marking of heartbeats or the reordering of spokes. The key ingredients of our method are threefold: 1) a fixed low-dimensional manifold that encodes the temporal variations of images; 2) a network that maps the manifold into a more expressive latent space; and 3) a convolutional neural network that generates a dynamic series of MRI images from the latent variables and that favors their consistency with the measurements in k-space. Our method outperforms the state-of-the-art methods quantitatively and qualitatively in both retrospective and real fetal cardiac datasets. To the best of our knowledge, this is the first unsupervised deep-learning-based method that can reconstruct the continuous variation of dynamic MRI sequences with high spatial resolution.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing,notion},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/PI7DTMNT/Yoo et al. - 2021 - Time-Dependent Deep Image Prior for Dynamic MRI.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/BIB5A2KD/1910.html}
}

@inproceedings{zangIntraTomoSelfsupervisedLearningbased2021,
  title = {{{IntraTomo}}: {{Self-supervised Learning-based Tomography}} via {{Sinogram Synthesis}} and {{Prediction}}},
  shorttitle = {{{IntraTomo}}},
  booktitle = {2021 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Zang, Guangming and Idoughi, Ramzi and Li, Rui and Wonka, Peter and Heidrich, Wolfgang},
  year = {2021},
  month = oct,
  pages = {1940--1950},
  publisher = {{IEEE}},
  address = {{Montreal, QC, Canada}},
  doi = {10.1109/ICCV48922.2021.00197},
  urldate = {2022-11-03},
  abstract = {We propose IntraTomo, a powerful framework that combines the benefits of learning-based and model-based approaches for solving highly ill-posed inverse problems in the Computed Tomography (CT) context. IntraTomo is composed of two core modules: a novel sinogram prediction module, and a geometry refinement module, which are applied iteratively. In the first module, the unknown density field is represented as a continuous and differentiable function, parameterized by a deep neural network. This network is learned, in a self-supervised fashion, from the incomplete or/and degraded input sinogram. After getting estimated through the sinogram prediction module, the density field is consistently refined in the second module using local and non-local geometrical priors. With these two core modules, we show that IntraTomo significantly outperforms existing approaches on several ill-posed inverse problems, such as limited angle tomography with a range of 45 degrees, sparse view tomographic reconstruction with as few as eight views, or super-resolution tomography with eight times increased resolution. The experiments on simulated and real data show that our approach can achieve results of unprecedented quality.},
  isbn = {978-1-66542-812-5},
  langid = {english},
  file = {C\:\\Users\\Tabita\\Documents\\ACIP\\Abstract\\intratomo.pdf}
}

@article{zhangDynamicConebeamCT2023,
  title = {Dynamic Cone-Beam {{CT}} Reconstruction Using Spatial and Temporal Implicit Neural Representation Learning ({{STINR}})},
  author = {Zhang, You and Shao, Hua-Chieh and Pan, Tinsu and Mengke, Tielige},
  year = {2023},
  month = feb,
  journal = {Physics in Medicine \& Biology},
  volume = {68},
  number = {4},
  pages = {045005},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/acb30d},
  urldate = {2023-03-29},
  abstract = {Objective. Dynamic cone-beam CT (CBCT) imaging is highly desired in image-guided radiation therapy to provide volumetric images with high spatial and temporal resolutions to enable applications including tumor motion tracking/prediction and intra-delivery dose calculation/accumulation. However, dynamic CBCT reconstruction is a substantially challenging spatiotemporal inverse problem, due to the extremely limited projection sample available for each CBCT reconstruction (one projection for one CBCT volume). Approach. We developed a simultaneous spatial and temporal implicit neural representation (STINR) method for dynamic CBCT reconstruction. STINR mapped the unknown image and the evolution of its motion into spatial and temporal multi-layer perceptrons (MLPs), and iteratively optimized the neuron weightings of the MLPs via acquired projections to represent the dynamic CBCT series. In addition to the MLPs, we also introduced prior knowledge, in the form of principal component analysis (PCA)-based patient-specific motion models, to reduce the complexity of the temporal mapping to address the ill-conditioned dynamic CBCT reconstruction problem. We used the extended-cardiac-torso (XCAT) phantom and a patient 4D-CBCT dataset to simulate different lung motion scenarios to evaluate STINR. The scenarios contain motion variations including motion baseline shifts, motion amplitude/frequency variations, and motion non-periodicity. The XCAT scenarios also contain inter-scan anatomical variations including tumor shrinkage and tumor position change. Main results. STINR shows consistently higher image reconstruction and motion tracking accuracy than a traditional PCA-based method and a polynomial-fitting-based neural representation method. STINR tracks the lung target to an average center-of-mass error of 1\textendash 2 mm, with corresponding relative errors of reconstructed dynamic CBCTs around 10\%. Significance. STINR offers a general framework allowing accurate dynamic CBCT reconstruction for image-guided radiotherapy. It is a one-shot learning method that does not rely on pre-training and is not susceptible to generalizability issues. It also allows natural super-resolution. It can be readily applied to other imaging modalities as well.},
  langid = {english},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/UTMNT6J3/Zhang et al. - 2023 - Dynamic cone-beam CT reconstruction using spatial .pdf}
}

@article{zhangImageRestorationSparse2017,
  title = {Image {{Restoration}}: {{From Sparse}} and {{Low-Rank Priors}} to {{Deep Priors}} [{{Lecture Notes}}]},
  shorttitle = {Image {{Restoration}}},
  author = {Zhang, Lei and Zuo, Wangmeng},
  year = {2017},
  month = sep,
  journal = {IEEE Signal Processing Magazine},
  volume = {34},
  number = {5},
  pages = {172--179},
  issn = {1558-0792},
  doi = {10.1109/MSP.2017.2717489},
  abstract = {The use of digital imaging devices, ranging from professional digital cinema cameras to consumer grade smartphone cameras, has become ubiquitous. The acquired image is a degraded observation of the unknown latent image, while the degradation comes from various factors such as noise corruption, camera shake, object motion, resolution limit, hazing, rain streaks, or a combination of them. Image restoration (IR), as a fundamental problem in image processing and low-level vision, aims to reconstruct the latent high-quality image from its degraded observation. Image degradation is, in general, irreversible, and IR is a typical ill-posed inverse problem. Due to the large space of natural image contents, prior information on image structures is crucial to regularize the solution space and produce a good estimation of the latent image. Image prior modeling and learning then are key issues in IR research. This lecture note describes the development of image prior modeling and learning techniques, including sparse representation models, low-rank models, and deep learning models.},
  keywords = {Cameras,Digital cameras,Digital imaging,Dynamic range,Encoding,Machine learning,Transform coding},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/EJANMECC/Zhang and Zuo - 2017 - Image Restoration From Sparse and Low-Rank Priors.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/4V68TJ5C/8026108.html}
}

@article{zhaoReferenceDrivenCompressedSensing2020,
  title = {Reference-{{Driven Compressed Sensing MR Image Reconstruction Using Deep Convolutional Neural Networks}} without {{Pre-Training}}},
  author = {Zhao, Di and Zhao, Feng and Gan, Yongjin},
  year = {2020},
  month = jan,
  journal = {Sensors},
  volume = {20},
  number = {1},
  pages = {308},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1424-8220},
  doi = {10.3390/s20010308},
  urldate = {2023-07-11},
  abstract = {Deep learning has proven itself to be able to reduce the scanning time of Magnetic Resonance Imaging (MRI) and to improve the image reconstruction quality since it was introduced into Compressed Sensing MRI (CS-MRI). However, the requirement of using large, high-quality, and patient-based datasets for network training procedures is always a challenge in clinical applications. In this paper, we propose a novel deep learning based compressed sensing MR image reconstruction method that does not require any pre-training procedure or training dataset, thereby largely reducing clinician dependence on patient-based datasets. The proposed method is based on the Deep Image Prior (DIP) framework and uses a high-resolution reference MR image as the input of the convolutional neural network in order to induce the structural prior in the learning procedure. This reference-driven strategy improves the efficiency and effect of network learning. We then add the k-space data correction step to enforce the consistency of the k-space data with the measurements, which further improve the image reconstruction accuracy. Experiments on in vivo MR datasets showed that the proposed method can achieve more accurate reconstruction results from undersampled k-space data.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {compressed sensing,deep image prior,deep learning,magnetic resonance imaging,reference-driven},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/SXN6QZ8Q/Zhao et al. - 2020 - Reference-Driven Compressed Sensing MR Image Recon.pdf}
}

@article{zhuImageReconstructionDomaintransform2018,
  title = {Image Reconstruction by Domain-Transform Manifold Learning},
  author = {Zhu, Bo and Liu, Jeremiah Z. and Cauley, Stephen F. and Rosen, Bruce R. and Rosen, Matthew S.},
  year = {2018},
  month = mar,
  journal = {Nature},
  volume = {555},
  number = {7697},
  pages = {487--492},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature25988},
  urldate = {2023-07-11},
  abstract = {Image reconstruction is reformulated using a data-driven, supervised machine learning framework that allows a mapping between sensor and image domains to emerge from even noisy and undersampled data, improving accuracy and reducing image artefacts.},
  copyright = {2018 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
  langid = {english},
  keywords = {Computational science,Information theory and computation},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/BDVPHLLT/Zhu et al. - 2018 - Image reconstruction by domain-transform manifold .pdf}
}

@article{zouDynamicImagingUsing2021a,
  title = {Dynamic {{Imaging Using}} a {{Deep Generative SToRM}} ({{Gen-SToRM}}) {{Model}}},
  author = {Zou, Qing and Ahmed, Abdul Haseeb and Nagpal, Prashant and Kruger, Stanley and Jacob, Mathews},
  year = {2021},
  month = nov,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {40},
  number = {11},
  pages = {3102--3112},
  issn = {1558-254X},
  doi = {10.1109/TMI.2021.3065948},
  abstract = {We introduce a generative smoothness regularization on manifolds (SToRM) model for the recovery of dynamic image data from highly undersampled measurements. The model assumes that the images in the dataset are non-linear mappings of low-dimensional latent vectors. We use the deep convolutional neural network (CNN) to represent the non-linear transformation. The parameters of the generator as well as the low-dimensional latent vectors are jointly estimated only from the undersampled measurements. This approach is different from traditional CNN approaches that require extensive fully sampled training data. We penalize the norm of the gradients of the non-linear mapping to constrain the manifold to be smooth, while temporal gradients of the latent vectors are penalized to obtain a smoothly varying time-series. The proposed scheme brings in the spatial regularization provided by the convolutional network. The main benefit of the proposed scheme is the improvement in image quality and the orders-of-magnitude reduction in memory demand compared to traditional manifold models. To minimize the computational complexity of the algorithm, we introduce an efficient progressive training-in-time approach and an approximate cost function. These approaches speed up the image reconstructions and offers better reconstruction performance.},
  keywords = {CNN,deep image prior,Electronics packaging,Generative model,Generators,Imaging,Magnetic resonance imaging,manifold approach,Manifolds,Storms,Time series analysis,unsupervised learning},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/36AGYJ2R/Zou et al. - 2021 - Dynamic Imaging Using a Deep Generative SToRM (Gen.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/W5CIKUNI/stamp.html}
}

@article{zouRecoverySurfacesFunctions2021,
  title = {Recovery of {{Surfaces}} and {{Functions}} in {{High Dimensions}}: {{Sampling Theory}} and {{Links}} to {{Neural Networks}}},
  shorttitle = {Recovery of {{Surfaces}} and {{Functions}} in {{High Dimensions}}},
  author = {Zou, Qing and Jacob, Mathews},
  year = {2021},
  month = jan,
  journal = {SIAM Journal on Imaging Sciences},
  volume = {14},
  number = {2},
  pages = {580--619},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/20M1340654},
  urldate = {2023-06-29},
  abstract = {We introduce a method to recover a continuous domain representation of a piecewise constant two-dimensional image from few low-pass Fourier samples. Assuming the edge set of the image is localized to the zero set of a trigonometric polynomial, we show that the Fourier coefficients of the partial derivatives of the image satisfy a linear annihilation relation. We present necessary and sufficient conditions for unique recovery of the image from finite low-pass Fourier samples using the annihilation relation. We also propose a practical two-stage recovery algorithm that is robust to model-mismatch and noise. In the first stage we estimate a continuous domain representation of the edge set of the image. In the second stage we perform an extrapolation in Fourier domain by a least squares two-dimensional linear prediction, which recovers the exact Fourier coefficients of the underlying image.  We demonstrate our algorithm on the superresolution recovery of MRI phantoms and real MRI data from low-pass Fourier samples, which shows benefits over standard approaches for single-image superresolution MRI.},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/JKLMC6EV/Zou and Jacob - 2021 - Recovery of Surfaces and Functions in High Dimensi.pdf}
}

@article{zouVariationalManifoldLearning2022,
  title = {Variational {{Manifold Learning From Incomplete Data}}: {{Application}} to {{Multislice Dynamic MRI}}},
  shorttitle = {Variational {{Manifold Learning From Incomplete Data}}},
  author = {Zou, Qing and Ahmed, Abdul Haseeb and Nagpal, Prashant and Priya, Sarv and Schulte, Rolf F. and Jacob, Mathews},
  year = {2022},
  month = dec,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {41},
  number = {12},
  pages = {3552--3561},
  issn = {1558-254X},
  doi = {10.1109/TMI.2022.3189905},
  abstract = {Current deep learning-based manifold learning algorithms such as the variational autoencoder (VAE) require fully sampled data to learn the probability density of real-world datasets. However, fully sampled data is often unavailable in a variety of problems, including the recovery of dynamic and high-resolution magnetic resonance imaging (MRI). We introduce a novel variational approach to learn a manifold from undersampled data. The VAE uses a decoder fed by latent vectors, drawn from a conditional density estimated from the fully sampled images using an encoder. Since fully sampled images are not available in our setting, we approximate the conditional density of the latent vectors by a parametric model whose parameters are estimated from the undersampled measurements using back-propagation. We use the framework for the joint alignment and recovery of multi-slice free breathing and ungated cardiac MRI data from highly undersampled measurements. Experimental results demonstrate the utility of the proposed scheme in dynamic imaging alignment and reconstructions.},
  keywords = {CNN,Convolutional neural networks,Data models,free-breathing cardiac magnetic resonance imaging (MRI),generative model,image reconstruction,Magnetic resonance imaging,manifold approach,Manifolds,Three-dimensional displays,Time series analysis,unsupervised learning,Variational autoencoder,Volume measurement},
  file = {/home/tabita/snap/zotero-snap/common/Zotero/storage/UUWZ4DWR/Zou et al. - 2022 - Variational Manifold Learning From Incomplete Data.pdf;/home/tabita/snap/zotero-snap/common/Zotero/storage/KKYZKN7K/stamp.html}
}
