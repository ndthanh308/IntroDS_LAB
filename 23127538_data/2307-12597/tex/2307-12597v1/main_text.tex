\documentclass{article}
\usepackage[a4paper,width=150mm,top=25mm,bottom=25mm,bindingoffset=6mm]{geometry}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[sorting=none]{biblatex}
\addbibresource{refs.bib}
\usepackage{mdframed}
\usepackage{framed}
\usepackage{amsfonts,amsmath,amsthm,amssymb,bbm,dsfont,enumerate}
\usepackage{tcolorbox}
\usepackage[pdfborder={0 0 0},pdfpagemode=UseOutlines,bookmarks=false,breaklinks=true,colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}

\renewcommand{\baselinestretch}{1.2}

\newcommand{\ja}[1]{\textbf{\textcolor{red}{[JA: #1]}}}
\newcommand{\ric}[1]{\textbf{\textcolor{blue}{[RIC: #1]}}}

\numberwithin{equation}{section}

\theoremstyle{plain} \newtheorem{theorem}{Theorem}[section]
\theoremstyle{plain} \newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{plain} \newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{plain} \newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition} \newtheorem{definition}[theorem]{Definition}
\theoremstyle{definition} \newtheorem{notation}[theorem]{Notation}
\theoremstyle{remark} \newtheorem{remark}[theorem]{Remark}
\theoremstyle{remark} \newtheorem{algorithm}[theorem]{Algorithm}
\theoremstyle{remark} \newtheorem{example}[theorem]{Example}

% Abbreviations
\def\R{\mathbb{R}}
\def\Q{\mathbb{Q}}
\def\S{\mathbb{S}}
\def\N{\mathbb{N}}
\def\Z{\mathbb{Z}}
\def\C{\mathbb{C}}
\def\E{{\sf E}}
\def\P{{\sf P}}
\def\I{{\sf I}}
\def\i{{\rm i}}
\def\e{{\rm e}}
\def\d{{\rm d}}
\def\var{{\rm var}}
\def\cov{{\rm cov}}
\def\eps{\varepsilon}
\def\distr{\stackrel{\rm d}{\longrightarrow}}
\def\prob{\stackrel{{\P}}{\longrightarrow}}
\def\as{\stackrel{\rm as}{\longrightarrow}}
\def\nto{\stackrel{n \to \infty}{\longrightarrow}}
\def\xto{\stackrel{x \to \infty}{\longrightarrow}}
\def\Borel{{\cal B}}

\begin{document}

\centerline{\sc \Large
A Unified Perspective on Sampling Algorithms} 
\vspace{1mm}
\centerline{\sc \Large
for Rare Trajectories of 
Discrete Markov Processes}

\vspace{5mm}

\centerline{{\bf Javier Aguilar} (1) and {\bf Riccardo Gatto} (2)} 

\vspace{2mm}

\centerline{\today}

\vspace{4mm}

\centerline{\bf Abstract}
\noindent
This article analyzes and compares two general techniques of rare event simulation for generating paths of Markov processes over fixed time horizons: 
backtracking and exponential tilting. 
These two methods allow to
compute the probability that the process ends within a rare region, 
which is unlikely to be attained. 
Backtracking consists in reversing the time of the process:
the path is obtained backwards, from the terminal point until
the initial one. The terminal point is generated from 
an appropriately chosen distribution that covers well the arrival 
region. Exponential tilting is a general technique
for obtaining  an alternative sampling probability measure,
under which the process is likely 
to hit the rare region at terminal time. 
We show that both methods belong to the same class of importance sampling procedures, by providing the common mathematical framework 
of these two conceptually different
methods of sampling rare trajectories.
Besides this analytical comparison, we 
compare the two methods numerically, 
by means of a simple random walk and a process with meta-stable states.
The numerical analysis shows that both methods possess distinct areas of application where they exhibit greater efficiency.
Detailed algorithms of
the proposed simulation methods are provided.
\vspace{2mm}

\centerline{\bf Key words and phrases}
\noindent
Backtracking -
Exponential tilting -
Importance sampling -
Likelihood ratio process - 
Meta-stable state -
Monte Carlo simulation -
Radon-Nikodym derivative - 
Rare event probability -
Relative error -
Stochastic bridge.

\vspace{2mm}

{\small
\centerline{\bf Addresses} 
\noindent
1. {\it Corresponding author}. Instituto de F\'isica Interdisciplinar y Sistemas Complejos IFISC (CSIC-UIB), Campus UIB, 07122 Palma de Mallorca, Spain -
{\tt javieraguilar@ifisc.uib-csic.es}
\\
2. Institute of Mathematical Statistics and Actuarial Science, University of Bern \\
Alpeneggstrasse 22, 3012 Bern, Switzerland -
{\tt riccardo.gatto@unibe.ch}
\\\\
\centerline{\bf Acknowledgement}
The authors thank Raúl Toral, Pablo I. Hurtado, Carlos Pérez-Espigares, Raphael Chetrite and David Ginsbourger for useful discussions. \\ Research partially supported by the 
University of Bern,
UniBE ID Grant 2021, and the Conselleria d'Educaci\'o, Universitat i Recerca of the Balearic Islands (Grant FPI FPI\_006\_2020). Also financial support has been received from the Agencia Estatal de
Investigación (AEI, MCI, Spain) MCIN/AEI/10.13039/ 501100011033 and Fondo
Europeo de Desarrollo Regional (FEDER, UE) under Project APASOS
(PID2021$\textbf{-}$ 122256NB$\textbf{-}$C21$/$C22) and the María de Maeztu Program for units of
Excellence in $\text{R\&D}$, grant CEX2021$\text{-}$ 001164$\text{-}$M.
}

\newpage

\tableofcontents

\newpage

\section{Introduction}

\noindent Rare trajectories account for realizations of stochastic processes that are extremely unlikely to happen, in the sense that conventional methods to sample stochastic trajectories, like the Euler-Maruyama methods in the context of stochastic differential equations~\cite{asmussen2007stochastic,toral2014stochastic} or the Gillespie algorithm for jumping processes~\cite{masuda2022gillespie,JAsampling_trajectories}, might fail to give their proper statistical characterization within affordable times. Even if these paths are uncommon, they can have a decisive role in nature. Indeed, catastrophic events such as extinction of species~\cite{mobilia2010fixation,kessler2007extinction}, heavy rains~\cite{frei2001detection}, or earthquakes~\cite{gabrielov2000colliding} manifest through rare fluctuations. Also, rare paths usually occur in precise shapes and unveil spatiotemporal patterns~\cite{hurtado2020building,ciccarese2022rare}. Moreover, rare events can have practical significance in many areas of science: the probability that 
the therapy efficacy falls below a low threshold~\cite{ramoso_stochastic_2020},
the probability that 
the level of a dam exceeds a certain extreme (small or large) 
level~\cite{harrison1976stationary},
the probability of ruin of an insurance company, namely the probability that the capital ever goes below the null
line~\cite{gerber1979introduction} 
or, as last example, the probability that
memory cells on silicon used in microchips get hit by 
high-energy particles
from outer space and corrupt stored data~\cite{1156060}.
Therefore, the challenge of generating unlikely paths by using conventional methods, coupled with their significance in numerous phenomena, justifies the need of advanced algorithms for sampling rare paths.

The literature contains numerous Monte Carlo algorithms that thwart the rarity of the event to simulate, making it possible to control the simulation error. Some of these methods rely on the generation of the bridge process, which condition paths to the endpoints and associate rare trajectories to the occurrence or rare pairs of endpoints~\cite{aguilar2022sampling,majumdar2015effective}. Other algorithms, like the cloning method~\cite{lecomte2007numerical,perez2019sampling,brewer2018efficient,grassberger2002go} or Metropolis schemes~\cite{claussen2015convex,hartmann2020convex}, link rare trajectories to the occurrence of rare sample averages of integrated quantities. Actually, the high variety of methods makes it difficult to assess which is the best strategy to tackle the generation of rare paths in specific problems. Moreover, it is difficult to convey to what extent these methods are fundamentally different or are simply different expressions of the same mathematical framework. One of the objectives of this article is to show that most of the mentioned methods
consist in changing the underlying probability measure of paths
and they are referred to as importance sampling. 

In this work, we focus on two practical importance sampling 
algorithms: backtracking
and exponential tilting. The reason to choose these two classes is that they enclose most of the strategies used to sample rare paths in out-of-equilibrium processes.  In addition to illustrating how these two perspectives arise from the technique of change-of-measure, we will offer readily applicable algorithms that streamline the implementation of these concepts into programs. Therefore, this work can serve as a tutorial for applied scientists who are specifically interested in practical applications, bypassing the need to delve into the underlying theory. The last aim of this work is to compare the performance of the two techniques in different settings.  We will show numerical evidence that the relative errors within the methods are bounded and that there is usually an optimal parameter minimizing the error. Ultimately, we find that the exponential-tilt proves to be more favorable for addressing problems with multiple dimensions, while the backtracking method demonstrates superior suitability for tackling challenges associated with rare transitions between meta-stable states.


The structure of this article is as follows. 
We start by reviewing the theory of change-of-measure
with stochastic processes, in
Section~\ref{s2}. In Sections~\ref{s3} and~\ref{sec:backtracking} we apply this perspective to introduce the exponential tilt and backtracking methods respectively. Finally, numerical comparisons 
of both methods are provided in Section~\ref{s4}
and concluding remarks are presented in Section \ref{s5}. Then Appendix \ref{ap:conditioned_moments_binomial} provides 
some algebraic derivations regarding the model investigated in
Section \ref{s4}.

\section{Change-of-measure and likelihood ratio process}    \label{s2}
This section provides a succinct introduction to the theory of 
change-of-measure.
Some basic concepts of probability theory are briefly reminded.
For a complete introduction, we refer to the monographs
\cite{asmussen2007stochastic},
\cite{bucklew2004introduction} and 
\cite{asmussen2003applied}. For a survey one can refer e.g. to 
\cite{doi:https://doi.org/10.1002/9781118445112.stat07823}.
We start with the case of the single random variable
and we then generalize this to  
stochastic process.

\subsection{Random variable}\label{sec:RV}

The central idea of rare event simulation is the change of sampling measure. The basic result is the following. Let $(\Omega, {\cal F},\tilde{\P})$ 
be a probability space.
Assume that the random variable $L$ over this space
is $\tilde{\P}$-a.s. nonnegative and satisfies 
$\E_{\tilde{\P}}[L] = 1$. Then, one shows that
\begin{equation}                               \label{e391}
{\P}[A] = \E_{\P} [ I_A ]= \E_{\tilde{\P}} [ I_A L ] = \int_A L d \tilde{\P}, \; \forall A \in {\cal F},
\end{equation}
defines an unique probability measure ${\P}$ on $(\Omega, {\cal F})$. 
In Eq.~\eqref{e391} we denote the indicator as $$I_A(\omega)=I\{\omega\in A\}=\begin{cases}
    1, \quad \text{if  }\omega\in A, \\
    0, \quad \text{otherwise.}
\end{cases}$$
Therefore, computing the probability $\P[A]$, which is the expectation of $I_A$ under the measure $\P$, is equivalent to computing the expectation, this time under $\Tilde{P}$, of the indicator weighted by $L$, i.e,  $I_A L$. The above result is a general one, since the only restriction on the new measure $\Tilde{\P}$ is absolute continuity with respect to
(w.r.t.) ${\P}$, noted $\P \ll \tilde{\P}$ on ${\cal F}$.\footnote{This means $\tilde{\P}[A] = 0 \Rightarrow 
{\P}[A]=0$, $\forall A \in \cal{F}$. With words, any set $A$ allowed by ${\P}$ must be allowed
by $\tilde{\P}$ as well.}
The random variable $L$, often called likelihood ratio, is the 
Radon-Nikodym derivative of ${\P}$ w.r.t. $\tilde{\P}$, denoted
$d {\P} / d \tilde{\P}$. 

Eq. (\ref{e391}) gives the following 
change-of-measure result.
Let $X$ be a random variable on $(\Omega, {\cal F})$, then
\begin{align}                                   \label{e392}
z=\E_{{\P}}[X] = \E_{\tilde{\P}}[ X L].
\end{align}
Eq. (\ref{e392}) requires
${\P} \ll \tilde{\P}$ only 
on the restriction of ${\cal F}$ to the $\sigma$-algebra generated by $X$,
viz. $\sigma(X)=\{X^{-1}(B)| B \in {\cal B}(\R)\}$,
and obviously on the additional restriction 
to $\{X \neq 0\}$. Thus absolute continuity is required on
on $\sigma(X) \cap \{X \neq 0\}$. With $X=I_A$, $A \in {\cal F}$,
the requirement $\P \ll \tilde{\P}$ is thus restricted to $A$.

A simple illustration is the following. Let $X$ be 
Gaussian with mean 0 and variance 1, under $\P$, let 
$\mu \in \R$ and
\begin{align}                           \label{e2000}
L=\exp\left\{-\mu (X-\mu) - \frac{\mu^2}{2} \right\}. 
\end{align}
From Eq. (\ref{e392}),
$$\E_{\P}[\e^{v X}] = 
\E_{\tilde{\P}}[\e^{v X}L]=
\e^\frac{v^2}{2}, \; \forall v \in \R,$$
iff $X$ is Gaussian with mean $\mu$ and variance one under
$\tilde{\P}$. So, this change-of-measure allows for arbitrary 
recentering, yet without changing the variance. 

Let $f$ and $\tilde{f}$ be the densities of the random variable $X$ 
under $\P$ and $\tilde{\P}$, respectively.
On the restriction of ${\cal F}$ to $\sigma(X)$,
we have that
\begin{equation*}                                                              
L = \frac{f(X)}{\tilde{f}(X)}
\end{equation*}
is a valid likelihood ratio and we obtain
$$
z = \E_\P[X]=
\E_{\tilde{\P}} [X L] = \int_\R x \frac{f(x)}{\tilde{f}(x)} \tilde{\P} 
[ X \in ( x , x + d x) ] .$$
Note that 
$ \P \ll \tilde{\P}$ simply means that the support of $f$ is included into the support of $\tilde{f}$.
We see directly that the likelihood ratio in Eq. (\ref{e2000}) 
is indeed the ratio of the two given Gaussian densities, evaluated
at $X$.

The importance sampling algorithm amounts to select $m$ large, to
generate $X_1 , \ldots, X_m $ independently from $\tilde{f}$ and to
estimate $z$ by
$$\hat{z}_m = \frac{1}{m} \sum_{j=1}^m X_j 
\frac{f(X_j)}{\tilde{f}(X_j)}. $$

\subsection{Stochastic process}

In this section, we show the extension of Section~\ref{sec:RV} to the case of stochastic processes. Let $(\Omega, {\cal F},  \{ {\cal F}_t\}_{t \ge 0},\tilde{\P})$ be a
filtered probability 
space.\footnote{The sequence of $\sigma$-algebras
 $\{ {\cal F}_t\}_{t \ge 0}$ is a filtration in the
 sense that ${\cal F}_s \subset {\cal F}_t \subset {\cal F}$,
 $\forall \ 0 \le s \le t < \infty$ (with inclusion meant weakly.}, where  time is either discrete, $t \in \N$, $\N=
 \{0,1,\ldots\}$, or continuous $t \in [0,\infty)$.
Assume that the stochastic process $\{ L_t \}_{t \ge 0}$ 
over this space
is a
$\tilde{\P}$-a.s. nonnegative martingale
w.r.t. the filtration $\{{\cal F}_t \}_{t \ge 0}$\footnote{This means
that $\E_{\tilde{\P}}[ L_t | {\cal F}_s] = L_s$, $\forall \ 0 \le s \le t < \infty$.} 
such that $\E_{\tilde{\P}}[L_t] = 1$, $\forall t \ge 0$.
Then there exists a unique probability measure $\P$ on  $(\Omega, {\cal F})$ such that,
\begin{equation}                                                                        \label{e101}
\forall t \ge 0, \; {\P}[A_t] = 
\E_{\tilde{\P}}[ I_{A_t} L_t] = 
\int_{A_t} L_t d \tilde{\P}, \; \forall A_t \in {\cal F}_t .
\end{equation}
Thus $\P \ll \tilde{\P}$ on the restriction 
${\cal F}_t$, $\forall t \ge 0$.\footnote{Thus 
$\P \ll \tilde{\P}$ may not hold on ${\cal F}$.}
The martingale $\{L_t\}_{t \ge 0}$ is called Radon-Nikodym or likelihood ratio process. At any $t\ge0$,
$L_t$ is the density or Radon-Nikodym derivative
of ${\P}$ w.r.t. $\tilde{\P}$ on ${\cal F}_t$ and an alternative
notation
is $L_t = d {\P} / d \tilde{\P} \! \mid_t$. 
Proof of Eq. (\ref{e101}) can be found e.g. in \cite{asmussen2003applied}. Thus
Eq. (\ref{e101}) generalizes Eq. (\ref{e391}). We 
have the following change-of-measure result for stochastic 
processes:
for any integrable and $\{ {\cal F}_t\}_{t \ge 0}$-adapted process
$\{ X_t \}_{t \ge 0}$, it holds that
\begin{align}                               \label{e394}
\E_{\P}[X_s] =
\E_{\tilde{\P}}[X_s L_s] =
\E_{\tilde{\P}}[X_s L_t],
\end{align}
provided 
$\P \ll \tilde{\P}$ on ${\cal F}_s \cap \{ X_s \neq 0 \}$, 
$\forall 0 \le s \le t$.

\subsection{Discrete Markov process}\label{sec:Backtracking_dt_ds}

Through the rest of the text, we will consider the Markov process with discrete time domain 
$\N$ and discrete state space $\Z=\{\ldots,-1,0,1,\ldots\}$. We note that most applied problems can be indeed formulated in this setting through time and space discretization, so this choice should not entail practical restrictions.
We obtain the likelihood ratio process of change-of-measure
from the induced probability of the Markov process. 
The likelihood ratio takes a simple form, depending only on the 
transition kernels of the Markov process. In this section
we consider the time $t \ge 1$ and the states
$n,n' \in \Z$.

Our Markov process $\{ X_t \}_{t \in \N}$ is defined on
the filtered probability space
 $(\Omega,{\cal F}, \{{\cal F}_t \}_{t \ge 0} ,\P)$.
Let us define the transition probabilities
\begin{align*}
p_{t,n}(j) & = \P [X_t = n + j \mid X_{t-1} = n], \;\;
\forall j\in \Z,
\end{align*}
together with the probabilities of the initial state
\begin{align*}
p_0(n) & =
\P [X_0 = n ].
\end{align*}

Let $\tilde{\P}$ denote a second probability measure on
$(\Omega,{\cal F}, \{{\cal F}_t \}_{t \ge 0})$, which is
unambiguously determined 
through the change-of-measure kernels 
$q_0:\Z \to [0,\infty)$ and
$q_t:\Z\times\Z \to [0,\infty)$ as follows:
\begin{align}                                   \label{e130} 
p_0(n) & = 
q_0(n) \tilde{\P} [X_0 = n]
\end{align}
and
\begin{align}                                   \label{e31}
{\P} [X_t = n' & \mid X_{t-1} = n, X_{t-2} = n_{t-2},\ldots, X_1 = n_1] = 
\nonumber \\
&  q_t(n,n') \tilde{\P} [X_t = n' \mid X_{t-1} = n, X_{t-2} = n_{t-2},
\ldots, X_1 = n_1],
\end{align}
for $n_{t-2}, \ldots,n_1 \in \Z$.
Because $\{ X_t \}_{t \in \N}$ is a Markov process under $\P$,
the values of $n_{t-2}, \ldots,n_1$ on the
left side of Eq. (\ref{e31}) are irrelevant. They remain
irrelevant on the right side and thus
$\{ X_t \}_{t \in \N}$
remains a Markov process
under the new probability measure $\tilde{\P}$. So 
we can simplify Eq. (\ref{e31}) to
\begin{align}                               \label{e110}
p_{t,n}(n'-n) & = 
q_t(n,n') \tilde{\P} [X_t = n' \mid X_{t-1} = n].
\end{align}
We can define the transition probabilities under $\tilde{\P}$ by
\begin{align*}
\tilde{p}_{t,n}(j) & =
\tilde{\P} [X_t = n + j \mid X_{t-1} = n], \; 
\forall j\in \Z,
\end{align*}
and the initial probability under $\tilde{\P}$ by
\begin{align*}
\tilde{p}_0(n) & =
\tilde{\P} [X_0 = n ].
\end{align*}
We then have,
for $n_{0}, \ldots,n_m \in \Z$,
\begin{align*}
\frac{{p}_0 (n_0)}
{\tilde{p}_0(n_0)}
\prod_{t=1}^{m}
\frac{{p}_{t,n_{t-1}}(n_t-n_{t-1})}
{\tilde{p}_{t,n_{t-1}}(n_t-n_{t-1})} =
q_0(n_0) \prod_{t=1}^{m} q_t (n_{t-1},n_t), \; \text{ for }
m=1,2,\ldots.
\end{align*}
This last expression gives us the following general form of the likelihood ratio process,
\begin{align*}                                       
L_0 & = q_0 (X_0) \; \text{ and } \;
L_{m}  =
q_0(X_0) \prod_{t=1}^{m} q_t (X_{t-1},X_t), \; 
\text{ for }
m=1,2,\ldots.
\end{align*}
Thus $L_m$ is a function of $X_0,\ldots,X_m$, 
for $m=0,1,\ldots$. In other terms, the 
likelihood ratio process is adapted to the 
filtration generated by the Markov process.

When the Markov process is homogeneous under $\P$ and
the change-of-measure kernel $q_t$ does not depend on $t \ge 1$, then
the Markov process $\{ X_t \}_{t \in \N}$
remains homogeneous under
$\tilde{\P}$. In this case, 
by redenoting the change-of-measure kernels at times $t\neq 0$
in Eq. (\ref{e31})
simply by $q_\bullet$, we
obtain the likelihood ratio process 
\begin{align}                                   \label{e27}
L_0 & = q_0 (X_0) \; \text{ and } 
L_{m}   =
q_0(X_0) \prod_{t=1}^{m} q_\bullet (X_{t-1},X_t), \text{ for }
m=1,2,\ldots.
\end{align}

Thus the following change-of-measure formula holds for all 
events depending on the Markov process over the 
finite time horizon $\{0,\ldots,t^{\dag}\}$, for some $t^{\dag} \ge 1$. 
For some given function
$g:\Z^{t^{\dag}+1} \to \R$,
define the importance sampling estimator
$Z_{t^\dag}=g(X_0,\ldots,X_{t^{\dag}}) 
L_{t^{\dag}}$. We then have
\begin{align}                                   \label{e49}
z_{t^\dag}=&\E_{{\P}} [ g(X_0,\ldots,X_{t^{\dag}}) ]  =
\E_{\tilde{\P}} \left[ g(X_0,\ldots,X_{t^{\dag}}) 
\frac{\d {\P}}{\d \tilde{\P}} \Big|_{t^\dag} \right] =
\E_{\tilde{\P}} \left[ g(X_0,\ldots,X_{t^{\dag}}) 
L_{t^{\dag}}  \right] 
= \E_{\tilde{\P}} \left[ Z_{t^\dag} \right],
\end{align}
whenever $\P \ll \tilde{\P}$ on ${\cal F}_{t^\dag}$.

%A particular problem concerns the first passage through the subset $[t_1,t_2]\times [c-a,c+a]$, for given $1 \le t_1 \le t_2 \le t^{\dag}$, $c\in \Z$ and $a \ge 0$. We are interested in the probability of this passage under the initial measure $\P$ and this probability is assumed small. We can obtain this first passage probability trough Eq. (\ref{e49}) with 
%\begin{align}                           \label{eqset}
%z_{t_1,t_2}([c-a,c+a]) & = 
%\P \left[ \exists  t \in [t_1,t_2] :  
%        X_t \in [c-a,c+a]  \right] = 
%\P \left[ \bigcup_{ t = t_1}^{t_2}  
%        \{ X_t \in [c-a,c+a] \} \right].
%\end{align}
%We can obtain this first passage probability by importance sampling, with the help of Eq. (\ref{e49}).
%This problem is investigated in Section \ref{NCII}.

\subsection{Absolute continuity and simulation}  \label{sec:absolute_continuity}
%From a numerical perspective, the target expected value [$z$ in Eq.~\eqref{e49}] is approximated by the sample mean computed from an ensemble of $M$ paths:
%\begin{equation}\label{eq:sample_mean}
 %   z_M:=\frac{1}{M}\sum_{i=1}^M g(X_0^{(i)},\dots,X_{t^\dag}^{(i)}).
%\end{equation}
%The quality of the approximation is given by the relative error, also referred to as precision, which depends on the standard deviation and the number of realizations:
%\begin{equation}
 %   \text{err}_{\P,M}(Z):=\frac{\sigma(Z)}{\sqrt{M}}.
%\end{equation}

%The theory of change of measure explained so far does not inform a priory of how to choose the new measure to solve a particular problem. However,  given two possible new measures $\tilde{\P}_1$ and $\tilde{\P}_2$  we can discern which one is more practical with respect to the numerical estimation of $z$  [Eq.~\eqref{e49}].

In the context of simulation, ${\P}$ represents the original measure 
and replications of $XL$, see Eq. (\ref{e392}), or of $XL_s$,
see Eq. (\ref{e394}),
are drawn under the importance sampling measure $\tilde{\P}$.
It may appear weird to state the existence of the original measure
$\P$ (which we already have) through 
Eq. (\ref{e391}) and Eq. (\ref{e101}), but the important
aspect here is the unambiguous
relationship between $\P$ and $\tilde{\P}$:
if either
Eq. (\ref{e391}) or Eq. (\ref{e101}) can be established, then the
importance sampling algorithm with $\tilde{\P}$ is valid.

From the theoretical perspective,
the only restriction for choosing the importance sampling measure 
($\tilde{\P}$)
is absolute continuity ($\P\ll\tilde{\P}$), which $\tilde{\P}$-a.s. 
guarantees the existence of the likelihood process ($\{L_t\}_{t \ge 0}$). 
A sample path with probability zero under the original measure 
($\P$) may thus receive positive probability under the importance
sampling measure ($\tilde{\P}$). However, since paths can be important observables themselves, one can be interested in a new measure 
($\tilde{\P}$)
that sample only the paths that have positive
probability under the original probability ($\P$).  
For example, in the context of stochastic thermodynamics, random paths have a prominent role in the characterization of entropy production~\cite{van2013stochastic,seifert2012stochastic}. As another example, rare paths can be measurable objects with important biological implications~\cite{wang2011quantifying,ciccarese2022rare}. Thus, it can also be useful to have the additional constraint of equivalence of measures, namely
$\P[A_t]=0\Leftrightarrow\tilde{\P}[A_t]=0$, $\forall A_t \in {\cal F}_t$,
at any time $t \ge 0$.
In Sections \ref{s3} we will see that the exponential tilting always satisfies this condition. Whereas in the backtracking process, the equivalence of measures depends on the choice of the terminal distribution (see \ref{sec:backtracking}).

Lastly, we note that when only absolute continuity of the new measure w.r.t. the original one ($\tilde{\P}\ll\P$) holds, 
an importance sampling algorithm may still be used but
introduce systematic errors in the estimation of the quantity of interest $z$, given in Eq.~\eqref{e49}. 
Such systematic errors can be very small, relative to the Monte
Carlo variability, if the forbidden region by $\tilde{\P}$ is irrelevant for the estimation of $Z$.
We will elaborate more on this point  through a numerical example in Section~\ref{sec:homogeneous_binomial_process}.

\section{Exponential tilting
for Markov processes}   \label{s3}

This section provides the analytical
formulation of importance sampling by exponential tilting.
The technique is first introduced for a single random variable,
then for the simple process of partial sums of i.i.d. random variables
and finally for discrete Markov processes. 

Exponential tilting is a fairly general change-of-measure
procedure that can be applied whenever the underlying distribution decays sufficiently fast at extremities;
namely when the distribution is ``light-tailed''.
Exponential tilting provides a 
new probability measure that renders likely 
trajectories that would have been otherwise 
rare under the original probability. This technique is sometimes called Esscher transformation.
It was indeed suggested by
\cite{escher1932probability,esscher1963approximate}
for local applications of the central limit theorem,
in order to obtain accurate approximations
to the distribution of the sum. 
It was then shown by \cite{daniels1954saddlepoint} that
these approximations can be reformulated in terms the saddlepoint
approximation of asymptotic analysis~\cite{copson2004asymptotic}.
Theoretically, both saddlepoint approximation and
importance sampling by exponential tilting belong to the class of
large deviations
approximations~\cite{gatto2014saddlepoint}.
These approximations are adequate
for obtaining the small probabilities of rare events;
see e.g. Chapter 3 of~\cite{bucklew2004introduction} and~\cite{chetrite2015nonequilibrium}. Note also that
exponential tilt Monte Carlo encloses 
recent algorithms for sampling rare paths, like cloning algorithms~\cite{lecomte2007numerical,perez2019sampling,brewer2018efficient,grassberger2002go} and Metropolis schemes~\cite{claussen2015convex,hartmann2020convex}.

Exponential tilting is introduced in
Section \ref{s32} for a single random variable. It is
then given for the sum of i.i.d. random variables,
in Section \ref{s33}.
The likelihood ratio process of
exponential tilt for Markov processes is provided in 
Section \ref{s34}. 
Section \ref{s35} concerns the choice of the tilting
parameter.

\subsection{Exponential tilting for random variable}           \label{s32}

Consider now the random variable $X$ with 
cumulant generating function (c.g.f.)
$$K(v) = \log \E_\P [ \e^{vX} ], \quad \text{for } v \in \R,$$
$\P$ representing the actual probability measure.
Consider any point $v=\theta$  at which $K(\theta)$ is finite.
The exponentially tilted measure $\P_{\theta}$ 
is the measure $\tilde{\P}$ of Eq. (\ref{e101}) obtained by
Radon-Nikodym derivative or
likelihood ratio 
\begin{equation*}                                    
L_\theta = 
\frac{d \P}{d \P_{\theta}} = \exp \{ - \theta X + K(\theta)\},
\end{equation*} 
over
$\sigma(X)$. 
Thus $\P_\theta$
is equivalent to $\P$, 
in the sense that $\P_\theta \ll \P$ and $\P \ll \P_\theta$,
on $\sigma(X)$. The new measure
$\P_\theta$, called exponential tilt of $\P$, is a
practical importance sampling measure. We note that
if $F$ is the distribution function (d.f.) of $X$
under $\P$, then
\begin{align}                                   \label{e88}
 d F_{\theta} (y) = \exp\{ \theta y - K(\theta) \}
d F(y)
\end{align}
provides the d.f. under $\P_\theta$.

\subsection{Exponential tilting for random walk}                                        \label{s33}

Let us introduce the exponential tilt likelihood ratio
process for the simple random walk, which is the process of partial sums of the 
i.i.d. random
variables $Y_1, Y_2, \ldots$, with common d.f. $F$ and c.g.f. $K$, 
under probability measure $\P$. Consider thus
$$X_t = \sum_{j=1}^t Y_j, \text{ for } t=1,2,\ldots.$$ 
We can define $X_0=0$ and thus assume that the fixed initial 
state $0$.
The exponentially tilted measure $\P_{\theta}$ over
$\sigma(X_1,\ldots,X_t)$ is
obtained from the likelihood ratio process
\begin{align}\label{e244}
L_{t}(\theta) = \exp \{ - \theta X_t  + t K(\theta) \},
\;\; \mbox{for} \; t=1,2\ldots .
\end{align}
We have $\P \ll \P_\theta$ and $\P_\theta \ll \P$ 
on $\sigma(X_1,\ldots,X_t)$, for $t=1,2,\ldots$.

For a given time horizon $t^\dag \ge 1$ and for a given 
function
$g:\Z^{t^{\dag}} \to \R$, we are generally interested
in computing
\begin{align*}                                  
z_{t^\dag}=&\E_{{\P}} [ g(X_1,\ldots,X_{t^{\dag}}) ].
\end{align*}
The importance sampling estimator
of exponential tilting is
\begin{align*}                                  
Z_{t^\dag}(\theta)=g(X_1,\ldots,X_{t^{\dag}}) 
L_{t^{\dag}}(\theta)
\end{align*}
and we have
\begin{align*}                                  
z_{t^\dag}=&\E_{{\P}} [ g(X_1,\ldots,X_{t^{\dag}}) ]  =
\E_{\P_{\theta}} \left[ g(X_1,\ldots,X_{t^{\dag}}) 
L_{t^{\dag}}(\theta) \right] 
= \E_{\P_{\theta}} \left[ Z_{t^\dag}(\theta) \right].
\end{align*}

Note that sampling under $\P_{\theta}$ amounts to
generate i.i.d. summands 
from the exponentially tilted d.f. in Eq. (\ref{e88}).
So we obtain Algorithm \ref{al020} for importance sampling
by exponential tilt with the random walk.
\begin{tcolorbox}
\begin{algorithm}[Exponential tilting for partial sums of i.i.d. random variables]\label{al020} \hspace{1mm}

Select a large number $m$ of iterations.
\begin{enumerate}
\item Repeat for $j=1,\ldots,m$,
\begin{itemize}
\item
generate $Y_1^{(j)},\ldots,Y_{t^\dag}^{(j)}$ independently from the d.f. $F_\theta$, given in Eq.
(\ref{e88}), and compute $X_{t^\dag}^{(j)}=\sum_{t=1}^{t^\dag} Y_i^{(j)}$
\item
obtain the likelihood ratio $L_{t^\dag}^{(j)}(\theta)$, as
in Eq. (\ref{e244}).
\end{itemize}
\item Compute the importance sampling 
estimator of $z_{t^\dag}=\E_{{\P}} [ X_{t^{\dag}} ]$ given by
$$\hat{z}_{t^\dag,m} = m^{-1} \sum_{j=1}^m X_{t^\dag}^{(j)}
L_{t^\dag}^{(j)}(\theta).$$
\end{enumerate}
\end{algorithm}
\end{tcolorbox}

For some large 
$x > \E_\P[ Y_1 ]$, let
$\I_x= (t^\dag x , \infty)$, for some time horizon $t^\dag \ge 1$.
We are now interested in the particular case 
$z_{t^\dag}(\I_x) = \P [ X_{t^\dag}\in \I_x ]$. 
The importance sampling estimator is thus given by
\begin{align}                               \label{e19}
Z_{t^\dag}(\theta,\I_x) = I\{ X_{t^\dag} \in \I_x \} L_{t^\dag}(\theta)= I\{ X_{t^\dag} > t^\dag x\} L_{t^\dag}(\theta)
\end{align}
and we have
$z_{t^\dag}(\I_x) = \E_{\P_\theta}[Z_{t^\dag}(\theta,\I_x)]$.

But not every choice of tilting parameter $\theta$ reduces the
variability and inadequate choices may also increase it, substantially.
Let $\theta(x)$ the solution w.r.t. $v$ 
of 
\begin{align}                                       \label{e47}
K'(v) = \frac{d}{d v} K(v) = x
\; \text{ i.e. } \;
\E_{\P_{\theta(x)}}[Y_1]=x
\; \text{ i.e. } \;
\E_{\P_{\theta(x)}}[X_{t^\dag}]=t^\dag x.
\end{align}
It is shown that $\theta(x)$ exists and it is unique, for any
$x$ within the interior of the range of $K'$; see e.g.
\cite{daniels1954saddlepoint}.
Moreover, \cite{daniels1954saddlepoint} shows also
that $\theta(x)$ appears as a saddlepoint
on the surface of the real part of the complex exponent
of the Fourier transform of the density. 
It is shown 
at p. 168-169 of \cite{asmussen2007stochastic} that
the importance sampling estimator given in Eq. (\ref{e19}) with
$\theta = \theta(x)$
%$$Z_{\theta(x),t}(x) = 
%I\{ S_t > t x\} L_{\theta(x),t}, \; \text{ for } t 
%=1,2,\ldots,
%$$
is optimal, in the sense of logarithmic efficiency,
under $\P_{\theta(x)}$ and that it is the unique optimal
importance sampling estimator. 
A less rigourous but simple justification
of the optimality of this choice of titling parameter
is given at Section \ref{s35}.

Logarithmic efficiency is a marginally weaker criterion 
than bounded relative error. 
These two usual optimality criteria of rare event simulation
are asymptotic for vanishing probabilities like $z_{t^\dag}(\I_x)$,
as $x\to \infty$.
For many important accurate estimators of small probabilities, 
only logarithmic efficiency can be established~\cite{asmussen2007stochastic}. 
But these two criteria can hardly be
distinguished in practical work. For the precise definitions of 
logarithmic efficiency and bounded relative error,
we refer to p. 158-160 of \cite{asmussen2007stochastic}. 

Note finally the following property: the exponentially tilted 
distribution $\P_{\theta(x)}$ is the closest one to
the original distribution $\P$, under all
distributions that are centered according to (\ref{e47}), where
closeness is
in terms of Kullback-Leibler divergence; cf. e.g. \cite{gatto2014saddlepoint}.

\subsection{Exponential tilting for homogeneous Markov processes}           \label{s34}

The discrete time Markov process, its change-of-measure
kernels and and its likelihood ratio process are all introduced 
in Section \ref{sec:Backtracking_dt_ds}. 
We showed that the change-of-measure kernels allow us to
obtain an alternative probability measure $\tilde{\P}$.
The objective is to choose $\tilde{\P}$ so to
reorient sample paths towards a specific region of interest, which 
is rarely reached under
the original measure $\P$. We show here how to $\tilde{\P}$
is obtained through exponential tilt, for 
the homogeneous Markov process. 
We only need to obtain the change-of-measure kernels
of Eq. (\ref{e130}) and Eq. (\ref{e31}) of exponential tilting.
In this section
we consider the time $t \ge 1$ and the states
$n,n' \in \Z$.

Let 
\begin{align*}
z(n,\theta) & = 
\exp \{ \theta n - K_{0}(\theta)\}
\end{align*}
and
\begin{align*}                           
z(n,n',\theta) & = 
\exp \{ \theta (n'-n) - K_{\bullet n}(\theta)\}, 
\end{align*}
where 
\begin{align}                                   \label{e158}
K_{0}(\theta) = \log \sum_{j \in \Z} \exp\{\theta j\} 
p_{0}(j) 
\end{align}
and
\begin{align}                                   \label{e159}
K_{\bullet n}(\theta) = \log \sum_{j \in \Z} \exp\{\theta j\} 
p_{\bullet n}(j),
\end{align}
at any $\theta \in \R$ where the two sums above converge,
are the c.g.f.  
of the probability of the initial state, denoted $p_0$, and
the c.g.f.
of the homogeneous
transition probabilities, denoted $p_{\bullet n} = p_{t, n}$ and
independent of the time index $t\ge 1$.
Note that in many problems
of physics the state space is a finite set and so all
c.g.f. above do always exist (without restrictions on
the value of the tilting parameter $\theta$).
The exponentially tilted probability measure,
$\tilde{\P} = \P_\theta$, is characterized by
\begin{align}                                           \label{e38}
 p_{0}(n,\theta) & =  \P_\theta [X_0 = n ] 
  = \exp \{ \theta n - K_{0}(\theta)\} 
     \P [X_0 = n] 
= z(n,\theta) p_{0}(n)
\end{align}
and
\begin{align}                                           \label{e40}
 p_{\bullet n}(j,\theta) & =  \P_\theta [X_t = n + j \mid X_{t-1} = n]  = \exp \{ \theta j - K_{\bullet n}(\theta)\} 
     \P [X_t = n + j \mid X_{t-1} = n] \nonumber \\
& = z(n,n+j,\theta) p_{\bullet n}(j), \; 
\forall j\in \Z.
\end{align}

Thus exponential tilt corresponds to
the particular choice of the general change-of-measure kernels
Eq. (\ref{e130}) and Eq. (\ref{e31}), respectively given by
$$
q_0(n) = \frac{1}{z(n,\theta)}
\; \text{ and } \;
q_\bullet(n,n') = \frac{1}{z(n,n',\theta)}.$$ 

Thus, the likelihood ratio process of Eq. (\ref{e27})
for the case of exponential tilt
becomes
\begin{align}                                   \label{e29}
L_0(\theta) & = q_0 (X_0) =[z(X_0,\theta)]^{-1}\; \text{ and } \nonumber \\
L_{t}(\theta) & = 
\left[ z(X_0,\theta) \prod_{k=1}^{t} z(X_{k-1},X_k,
\theta) \right]^{-1} 
\nonumber \\
& = \left[ \exp \left\{ \theta X_0 - K_0(\theta)  +
\sum_{k=1}^{t} \theta (X_k - X_{k-1}) - K_{\bullet X_{k-1}} 
(\theta)\right\} \right]^{-1} \nonumber \\
& = \exp \left\{ - \theta X_t + \left[ K_0(\theta)  +
\sum_{k=1}^{t} K_{\bullet X_{k-1}} 
(\theta)\right] \right\} \nonumber \\
& = \e^{-\theta X_t} M_0(\theta)
\prod_{k=1}^{t} M_{\bullet X_{k-1}} (\theta), 
\end{align}
where the argument $\theta$ has been added to the likelihood ratio 
for convenience and where $M_{0} = \e^{K_{0}}$ and
$M_{\bullet n} = \e^{K_{\bullet n}}$ are
the moment generating functions (m.g.f.) of 
$p_0$ and $p_{\bullet n}$, 
respectively.

Let us now give a couple of remarks.
The required absolute continuity is clearly satisfied,
because of the positivity of the change-of-measure kernels of exponential tilt.
In fact, both ${\P} \ll {\P}_\theta$ and
${\P}_\theta \ll {\P}$ hold, viz. 
${\P}$ and ${\P}_\theta$ are equivalent.
In contrast with the likelihood ratio of backtracking, discussed inSection~\ref{sec:backtracking}, the likelihood ratio of Eq. (\ref{e29}) 
is not restricted to problems with finite time horizon.


Consider the time horizon $t^\dag \ge 1$ and the  
function
$g:\Z^{t^{\dag}+1} \to \R$. We want to evaluate
\begin{align}                         \label{e210}                   
z_{t^\dag}=&\E_{{\P}} [ g(X_0,\ldots,X_{t^{\dag}}) ].
\end{align}
The importance sampling estimator
of exponential tilting is
\begin{align}                                   \label{e344}
Z_{t^\dag}(\theta)=g(X_0,\ldots,X_{t^{\dag}}) 
L_{t^{\dag}}(\theta),
\end{align}
for $L_{t^{\dag}}(\theta)$ given in Eq. (\ref{e29}),
and we have
\begin{align}                                           \label{e129}             
z_{t^\dag}=&\E_{{\P}} [ g(X_0,\ldots,X_{t^{\dag}}) ]  =
\E_{\P_{\theta}} \left[ g(X_0,\ldots,X_{t^{\dag}}) 
L_{t^{\dag}}(\theta)  \right] 
= \E_{\P_{\theta}} \left[ Z_{t^\dag} (\theta)\right].
\end{align}

From the above derivations, we can compute the desired expectation
in Eq. (\ref{e210})
with Algorithm \ref{al:tilting} below of 
importance sampling by exponential tilting. We consider 
the practical case with fixed initial initial state.
\begin{tcolorbox}
\begin{algorithm}[Exponential tilting for Markov process]\label{al:tilting}
$ $\\
\hspace*{3truemm} Select a large number $m$ of iterations and fix the
initial state $X_0=n_0$.
\begin{enumerate}
    \item Repeat for $j=1,\ldots,m$, 
    \begin{itemize}    
    \item generate $X_1^{(j)},\ldots, X_{t^\dag}^{(j)}$,
 the $j$-th sample path of the Markov process, recursively
    from the exponentially tilted transition probabilities given by Eq.~\eqref{e38} and Eq.~\eqref{e40};
    \item
    obtain $Z_{t^\dag,j}(\theta)$,
    the $j$-th replication of the estimator given by Eq. (\ref{e344}).
    \end{itemize}
    \item Compute the estimator of $z_{t^\dag}$, given by Eq.~\eqref{e129}, by
    \begin{align*}
        \hat{z}_{t^\dag,m} 
        & =\frac{1}{m}\sum_{j=1}^m Z_{t^\dag,j}(\theta). 
    \end{align*}
\end{enumerate}
\end{algorithm}
\end{tcolorbox}

%We are now interested in the probability of reaching, at some final time $t^\dag$, the interval  of state(s)
%$$\I_{c}(a)=[c-a,c+a] \cap \Z, \; \text{ for some integers } \; 
%a \ge 0 \text{ and } c.$$ 
%Consider fixed initial state fixed $X_0=n_0$, for some $n_0 \in \Z$ much smaller than $c-a$. The quantity of interest is thus
%\begin{align}                                       \label{e21}
%z_{t^\dag}(\I_{c}(a))= \P[X_{t^\dag} \in \I_{c}(a)].
%\end{align}
%An optimal choice of the tilting parameter seems difficult to establish. In the considered situation where the target interval $\I_c(a)$ is well above the starting point $n_0$, any value $\theta>0$ that re-drifts the process  sufficiently upwards is expected to reduce the Monte Carlo variability. We investigate this problem numerically with the binomial process, in Section \ref{s52}. The optimal choice is simpler with the time and space  homogeneous Markov process and it is explained in Section \ref{s35}.

\subsection{Optimal tilting parameter under time and space homogeneity}            \label{s35}

The theory explained so far does not address the question of how to select the tilting parameter associated with specific rare events. In fact, through the numerical examples in Section~\ref{s4}, we will show evidence that there is usually an optimal tilting parameter minimizing the sampling error of the numerical estimations. We next show the computation of the optimal tilting parameter for a particular problem as an illustration. In particular, we are now interested in the probability 
of reaching, at some final time $t^\dag$, the interval 
of states
$$\I_{c}(a)=[c-a,c+a] \cap \Z, \; \text{ for some integers } \; 
a \ge 0
\text{ and } c.$$
Consider also that the initial state is fixed $X_0=n_0$, for some
$n_0 \in \Z$ much smaller than $c-a$.
The quantity
of interest is thus
\begin{align}                                       \label{e21}
z_{t^\dag}(\I_{c}(a))= \P[X_{t^\dag} \in \I_{c}(a)].
\end{align}


%We end this section a simple justification of the optimal tilting parameter. In this section we consider the times $t<t^\dag$, both in $\N$,  and the state $n\in \Z$. We further consider  $\I_c(a)$ as the target interval at terminal time $t^{\dag}$,  for integers $c \in \Z$ and $a \ge 0$ such that $c-a$ is much larger than $n_0 \in \Z$, representing the initial state of the process. We are interested in the probability of ending, at time $t^\dag$, within $\I_c(a)$, viz. in $z_{t^\dag}(\I_c(a))= \P[X_{t^\dag} \in \I_c(a)]$.

We further assume that the process is homogeneous in the state space:
the transition probability $p_{\bullet n}$ 
does not depend on $n$ and we denote $p_{\bullet \bullet}=p_{\bullet n}$. This is the random walk
of Section \ref{s33}.
Denote by $K_{\bullet \bullet}$ the c.g.f. of
$p_{\bullet \bullet}$.
We want to determine the exponential tilting
parameter $\theta$ for which $\var_{\P_\theta}
(Z_{t^\dag}(\theta,\I_c(a)))$ is small,
i.e. such that $\E_{\P_\theta}[Z^2_{t^\dag}(\theta,\I_c(a))]$ is small. 
Then Eq. (\ref{e29}) leads to
$$
L_{t^{\dag}}(\theta) = 
\exp\{-\theta (X_{t^{\dag}}-n_0)+ t^{\dag} K_{\bullet \bullet}
    (\theta)\}.
$$
We thus have
\begin{align*}
\E_{\P_\theta}\left[\left(Z_{t^\dag}(\theta,\I_c(a))\right)^2\right] & = \E_{\P_\theta}[(I\{ 
    c-a \le X_{t^{\dag}} \le c-a \}
                L_{t^{\dag}}(\theta) )^2] \\
    & \le \E_{\P_\theta}[I\{X_{t^{\dag}} \ge c - a \}
    (\exp\{-\theta (X_{t^{\dag}}-n_0)+ t^{\dag} K_{\bullet \bullet}
    (\theta)\})^2] \\
    & \le (\exp\{-\theta (c-a-n_0) + t^{\dag} K_{\bullet \bullet}
    (\theta)\})^2 \E_{\P_\theta}[I\{X_{t^{\dag}} \ge c-a \} ] \\
    & \le \exp\{-2[\theta (c-a-n_0) - t^{\dag} K_{\bullet \bullet}
    (\theta)]\},
\end{align*}
given that $\theta > 0$ whenever $a>0$.
Strict convexity of $K_{\bullet \bullet}$ implies that
the
above exponent is minimized for
$$t^{\dag} K_{\bullet \bullet}'(\theta)=c- a - n_0 > 0,$$
namely for
\begin{equation}                                \label{e150}  
\E_{\P_\theta}[X_{t^{\dag}} - X_0 \mid X_0 = n_0 ] = c-a- n_0,
\end{equation}
which thus recenters the average of $X_{t^{\dag}}$ towards 
the lower bound of the target interval $\I_c(a)$.

%In the example given later regarding the binomial process or random walk,  Eq. (\ref{eq:eq_for_theta_BRW}) corresponds to Eq. (\ref{e150}) with mean final state of the process  $n_{t^{\dag}}$ instead of $c-a$. That example provides numerical evidence regarding the optimality of the above argument,  of centering around the lower bound of the interval. Indeed, Fig. \ref{fig:example1_exponential_tilt}(b) shows that the relative error of the exponential tilting estimator in Eq. (\ref{e21}) is minimized around the  value $n_{t^{\dag}}=-10$, which is equal to $c-a-n_0$ with the values of the example $c=0$, $a=10$ and $n_0=0$.

The problem of finding the optimal parameter for arbitrary expectations is not yet solved (e.g. for the case of computing the same estimator  in Eq.~\eqref{e21} but for a process with state-dependent transition probabilities). Nevertheless, expressions like  Eq.~\eqref{e150} can be used in an intuitive way to reduce the sampling errors.  For example, in the considered situation
where the target interval $\I_c(a)$ is well above the starting point
$n_0$, any value $\theta>0$ that re-drifts the process 
sufficiently upwards is expected to reduce the Monte Carlo variability. We will elaborate more on this point in Section~\ref{sec:homogeneous_binomial_process}

\section{Backtracking for Markov processes}\label{sec:backtracking}

% Paragrah theme: define the Markov Chain
Backtracking provides a practical alternative technique to
exponential tilting. It also constructs a new sampling probability measure $\Tilde{\P}$ that makes frequent a given event of 
interest, which is rare under $\P$.
The main idea is to generate a bridge process with fixed 
boundary points or endpoints.
The bridge process is then used for sampling the rare paths that 
possess unlikely pairs of endpoints, under the original probability.
There are various recent applications of this methodology
for sampling rare events~\cite{aguilar2022sampling,majumdar2015effective,delorme2016extreme}.
%This strategy 
%encapsulates different recent applications for sampling rare %events~\cite{aguilar2022sampling,majumdar2015effective,delorme2016extre%me}.
The generator of the bridge process is obtained conditioning the transition probabilities~\cite{chetrite2015nonequilibrium,aguilar2022sampling}, which is explained in the following section. As before, we consider processes with discrete state and time spaces. 
With the methods of this section, we always need a fixed
time horizon $t^\dag \ge 1$. We
consider the time $t< t^\dag$, in $\N$,
and states $n_0,n_{t^\dag},n,n' \in \Z$.

\subsection{Conditioned Markov process}\label{sec:Conditioned_MP}

The bridge process is obtained upon conditioning the original Markov process on passing through particular states at given times. It is possible to sample the stochastic bridges both backward or forward in time, giving rise to two possible generators that we describe below.

\subsubsection{Forward generator}

We can derive transition probabilities that are conditional 
on some fixed final state $X_{t^\dag}=n_{t^\dag}$
through the relation
\begin{align}\label{eq:proof_forward_conditioning_rate}
    \P[X_{t+1}=n'|X_{t}&=n,X_{t^\dag}=n_{t^\dag}] =\frac{\P[X_{t+1}=n',X_{t}=n,X_{t^\dag}=n_{t^\dag}]}{\P[X_{t}=n,X_{t^\dag}=n_{t^\dag}]}  \nonumber \\
    &= \P[X_{t+1}=n'|X_t=n]\frac{\P[X_{t^\dag}=n_{t^\dag}|X_{t+1}=n',X_t=n]}{\P[X_{t^\dag}=n_{t^\dag}|X_{t}=n]} \nonumber \\
    &= \P[X_{t+1}=n'|X_t=n]\frac{\P[X_{t^\dag}=n_{t^\dag}|X_{t+1}=n']}{\P[X_{t^\dag}=n_{t^\dag}|X_{t}=n]}.
\end{align}
We can re-express Eq. (\ref{eq:proof_forward_conditioning_rate}) with
specific notation for transition probabilities 
and change-of-measure kernels
as
\begin{align} \label{eq:proof_forward_conditioning_rate_bis}
    \tilde{p}_{t+1,n}(n'-n;t^\dag,n_{t_\dag}) =
    u_{t+1}(n,n';t^\dag,n_{t^\dag}) 
    p_{t+1,n}(n'-n),
\end{align}
where
\begin{align}                                           \label{e238}
u_{t+1}(n,n';t^\dag,n_{t^\dag}) =
\frac{\P[X_{t^\dag}=n_{t^\dag}|X_{t+1}=n']}{\P[X_{t^\dag}=n_{t^\dag}|X_{t}=n]}
\end{align}
and
\begin{align*}
 \tilde{p}_{t+1,n}(n'-n;t^\dag,n_{t_\dag}) = 
 \P[X_{t+1}=n'|X_{t}&=n,X_{t^\dag}=n_{t^\dag}].
\end{align*}
Thus, Eq. (\ref{eq:proof_forward_conditioning_rate_bis})
is a special case of Eq. (\ref{e110}).
We consider the initial state of the process as fixed, 
viz. $X_0=n_0$, so that the change-of-measure equation at initial
time (\ref{e130}) is not required here.

As conclusion for this section,
by using the transition probabilities on the left side of Eq.~\eqref{eq:proof_forward_conditioning_rate_bis} 
and by considering
fixed initial state,
we obtain paths that necessarily cross the boundary points $X_0=n_0$ and $X_{t^\dag}=n_{t^\dag}$. We have thus generated a bridge process.
Since the transition probabilities in Eq.~\eqref{eq:proof_forward_conditioning_rate_bis} operate forward in time, we call this procedure the forward generator of the bridge. The alternative generator that operates
backward in time is given in the next section.

\subsubsection{Backtracking: backward generator}

Alternatively, we can define conditional probabilities
backward in time. As with the forward generator, we consider fixed initial state $X_0=n_0$. We now derive a
sequential procedure of obtaining the conditional
probabilities, which we call backward generator or simply
backtracking.

A formula for the backward transition probabilities, obtained through manipulations similar 
to those given in Eq. (\ref{eq:proof_forward_conditioning_rate}),
is given by
\begin{align*}
    \P[X_t=n'|X_{t+1}&=n,X_0=n_0] =
     \P[X_{t+1}=n|X_t=n'] \frac{\P[X_{t}=n'|X_{0}=n_0]}{\P[X_{t+1}=n|X_{0}=n_0]},
\end{align*}
namely
\begin{align}\label{eq:proof_backtracking_rate}
    \P[X_t=n'|X_{t+1} =n,X_0=n_0] & = w_{t}(n',n;n_0)
     \P[X_{t+1}=n|X_t=n'] \nonumber \\
     & = w_{t}(n',n;n_0) p_{t+1,n'}(n-n'),
\end{align}
where
\begin{equation}\label{eq:transition_kernel_backtracking}
w_{t}(n',n;n_0)=\frac{\P[X_t=n'|X_0=n_0]}{\P[X_{t+1}=n|X_0=n_0]}
\end{equation}
is the backward change-of-measure kernel.

Both forward Eq.
(\ref{eq:proof_forward_conditioning_rate})
and backward Eq.
(\ref{eq:proof_backtracking_rate})
generators are obtained upon multiplying the original transition probabilities by the change-of-measure kernels $u_{t+1}$ and $w_t$.
These kernels take the form of Doob's $h$-transform, cf. p.
190-195 of ~\cite{asmussen2003applied}. Nevertheless, the probabilities in numerator and denominator of $u_{t+1}$ of
%$\P[X_{t^\dag}=n_{t^\dag}|X_{t}=n]$ in 
Eq.~\eqref{e238} are efficiently computed through a backward Kolmogorov equation, whereas 
the probabilities 
%$\P[X_t=n|X_{0}=n_0]$ 
in numerator and denominator of $w_{t}$
of Eq.~\eqref{eq:transition_kernel_backtracking} are usually computed with a forward Kolmogorov equation. 

Applications that involve sampling bridges with a common initial state (at $t=0$) but multiple final destinations
(at $t=t^\dag$), such as when $\P[X_0=n]=\delta_{n,n_0}$, are better addressed by the backward generator, as described in \cite{aguilar2022sampling}. The reason is that with the backward generator we need to iterate the forward Kolmogorov equation only once, in order to compute the quantities $\P[X_t=n|X_0=n_0]$, for all relevant values of $n$ and $t$, that are necessary for obtaining
the backward change-of-measure kernel 
Eq. \eqref{eq:transition_kernel_backtracking} and thus for
sampling the bridges. On the other hand, sampling bridges with fixed initial state and multiple final destinations using the forward generator with its change-of-measure kernel in Eq.~\eqref{e238} would require iterating the backward Kolmogorov equation once for each final point of the bridge.

For the same reason, the forward generator is more practical than the backward generator when investigating ensembles of bridges with a fixed final position but varying initial conditions. Since this article focuses on applications with fixed initial conditions, we will employ the backward generator to construct the change-of-measure.

\subsection{Backtracking  change-of-measure and likelihood ratio}

From the theoretical perspective, the backward generator Eq. (\ref{eq:proof_backtracking_rate}) provides 
a new probability measure that we denote $\tilde{\P}=\P_{n_0}$.
The paths have fixed initial condition $X_0=n_0$ and the 
generation of the
Markov process under $\P_{n_0}$ proceeds backward in time, 
from the last considered time $(t=t^{\dag})$ to the first one  $(t=0)$. Thus the kernels in
Eq. \eqref{eq:transition_kernel_backtracking}
partially determine the new probability measure $\P_{n_0}$.
Clealry, the kernels of Eq. \eqref{eq:transition_kernel_backtracking} have different functionality than the change-of-measure 
kernel of Eq. (\ref{e110}). This distinction arises from the backward nature of the generator for the bridge process. 

The second requirement on the new or
the backtracking measure $\P_{n_0}$ is provided by the distribution of the final state, namely the distribution 
$X_{t^\dag}$. We are essentially free in the choice of this distribution,
up to simple constraints of admissibility (see Section~\ref{subsec:choice_of_final_distribution} for a detailed discussion of this aspect). We define the probability function of the final state by
\begin{equation}\label{eq:distribution_last_state_backtrack}
    w_{t^{\dag}}(n;n_0)=\P_{n_0}[X_{t^{\dag}}=n].
\end{equation}

We have thus obtained an alternative version 
of the generic change-of-measure formulae in
Eq. (\ref{e130}) and Eq. (\ref{e31}),
that determine the new measure $\tilde{\P}$, which is here $\P_{n_0}$.
Here the change-of-measure is precisely
given by Eq. (\ref{eq:distribution_last_state_backtrack}) and by
\begin{equation}\label{eq:transition_probabilities_backtracking}
    {\P}_{n_0}[X_t=n'|X_{t+1}=n]=w_{t}(n',n;n_0)\P[X_{t+1}=n'|X_t=n].
\end{equation}

The corresponding likelihood ratio is obtained by multiplication of these
backward
change-of-measure kernels and it is thus given by
\begin{align}\label{eq:likelihood_ratio_backtrack_V0}
    L_{t^{\dag}}(n_0)=\left[w_0(n_0,X_1;n_0)\dots w_{t^\dag-1}(X_{t^\dag-1},X_{t^\dag};n_0)w_{t^\dag}(X_t^\dag;n_0)\right]^{-1}.
\end{align}
Interestingly, all terms in Eq.~\eqref{eq:likelihood_ratio_backtrack_V0} cancel out excepting those that depend on the final state at time $t^\dag$. 
Therefore, the
expression of the likelihood ratio reduces to
\begin{align}\label{eq:likelihood_ratio_backtrack}
    L_{t^{\dag}}(n_0)=\frac{h(X_{t^{\dag}};n_0)}{w_{t^{\dag}}(X_{t^{\dag}};n_0)},
\end{align}
where
\begin{equation*}
    h(n;n_0) = \P[X_{t^{\dag}}=n|X_0=n_0].
\end{equation*}
Thus,
for some given function
$g:\Z^{t^{\dag}+1} \to \R$,
the importance sampling estimator
of backtracking is given by
$$Z_{n_0,t^\dag}=g(n_0,X_1,\ldots,X_{t^{\dag}}) 
L_{t^{\dag}}(n_0)$$ and we have
\begin{align*}                                  
z_{t^\dag}=&\E_{{\P}} [ g(n_0,X_1,\ldots,X_{t^{\dag}}) ]  =
\E_{\P_{n_0}} \left[ g(n_0,X_1,\ldots,X_{t^{\dag}}) 
L_{t^{\dag}}  \right] 
= \E_{\P_{n_0}} \left[ Z_{n_0,t^\dag} \right].
\end{align*}
We note that with backtracking it is necessary to
fix the time horizon $t^\dag$ in advance and there
will be only a single likelihood ratio random variable,
to be used at all intermediate times $t\in [0,t^\dag]$, 
instead of a complete likelihood ratio process over the time horizon $[0,t^\dag]$.

With the above results, we can provide 
Algorithm \ref{al:backtracking} of 
importance sampling by backtracking,
for the computation of $z_{t^{\dag}}$.
\begin{tcolorbox}
\begin{algorithm}[Backtracking for Markov process]\label{al:backtracking}
$ $\\
\hspace*{3truemm} Select a large number $m$ of iterations and fix the
initial state $n_0$.
\begin{enumerate} 
\item Repeat for $j=1,\ldots,m$, 
\begin{itemize}
\item
generate $X^{(j)}_{t^{\dag}}$ from $w_{t^{\dag}}(\cdot,n_0)$, given in Eq. (\ref{eq:distribution_last_state_backtrack});
\item generate $X^{(j)}_{t^{\dag}-1},\dots,X^{(j)}_0$ from the backward bridge generator, given in Eq.~\eqref{eq:proof_backtracking_rate}, with backward departure 
point $X^{(j)}_{t^{\dag}}$;
\item
compute 
the likelihood ratio $L^{(j)}_{t^{\dag}}(n_0)$ from Eq. (\ref{eq:likelihood_ratio_backtrack})
and
$$Z^{(j)}_{n_0,t^{\dag}}=L^{(j)}_{t^{\dag}}g(n_0, X^{(j)}_1,\ldots X^{(j)}_{t^{\dag}}).$$
\end{itemize}
\item Compute the backtracking 
estimator of $z_{t^{\dag}}$ by
$$\hat{z}_{t^{\dag},n_0,m} = m^{-1} \sum_{j=1}^m Z^{(j)}_{n_0,t^{\dag}}.$$
\end{enumerate}
\end{algorithm}
\end{tcolorbox}

\subsection{Choice of terminal distribution}\label{subsec:choice_of_final_distribution}

The efficiency of the backtracking method depends on the choice of the final distribution for the new process ($w_{t^{\dag}}$), thus having a similar role to the tilting parameter ($\theta$) in the case of the exponential tilt measure. 
Let $n,n_0 \in \Z$.
For example, if we choose $w_{t^{\dag}}$ to be equal to the distribution of states at time $t^{\dag}$ with the original process ($w_{t^{\dag}}(n;n_0)=\P[X_{t^{\dag}}=n|X_0=n_0]$), then the new and original measures assign the same weights to paths ($L_{t^{\dag}}=1$), and therefore the change-of-measure will not result in improved efficiency for sampling rare events.

The only mathematical restriction on the choice of the final probability
 $w_{t^{\dag}}$ is the absolutely continuity of measures on
 the $\sigma$-algebra at terminal time restricted on the
 initial condition, viz.
 $\P\ll \P_{n_0}$
 on ${\cal F}_{t^\dag} \cap \{X_0=n_0\}$. 
 This condition is fulfilled if 
 \begin{equation}\label{eq:backtracking_absolute_continuity}
      w_{t^{\dag}}(n;n_0)=0\Longrightarrow \P[X_{t^\dag}=n|X_{0}=n_0]=0.
 \end{equation}

As discussed in Section \ref{sec:absolute_continuity}, many applications require that all paths sampled with the new probability measure are also accessible with the original measure (e.g. the equivalence between measures). This stronger constraint is fulfilled when
\begin{equation}\label{eq:backtracking_equivalent}
   w_{t^{\dag}}(n;n_0)=0\Longleftrightarrow \P[X_{t^{\dag}}=n|X_{0}=n_0]=0.
\end{equation}

Choices of $w_{t^{\dag}}$ fulfilling Eq.~\eqref{eq:backtracking_equivalent} and Eq.~\eqref{eq:backtracking_absolute_continuity} generate exact changes-of-measure, in the sense that the computed expected values are not affected by systematic errors. Contrary, if there are forbidden states under the new measure that were accessible with the original process, then we would expect errors for the numerical estimators that do not tend to zero as the number of measures increase. Nevertheless, these biased errors could be smaller than the sampling errors in cases for which the forbidden areas under the new measure are irrelevant for the estimator. This applies to problems that involve transition paths between meta-stable states, where choices such as delta distributions ($w_{t^{\dag}}(n;n_0)=\delta_{n,n_{t^{\dag}}}$), that violate absolute continuity, can be used in order to compute estimators with sufficiently small errors, as described in~\cite{aguilar2022sampling}.

\section{Examples and numerical study}\label{s4}

In this section,
numerical comparison between backtracking and exponential tilting are presented through the
following examples: the  binomial process, in Section
\ref{sec:homogeneous_binomial_process}, and a process with state-dependent transition probabilities exhibiting meta-stable states, in Section
\ref{s52}.
We define times $s<t< t^\dag$, in $\N$,
and states $n_0,n_{t^\dag},n,n' \in \Z$.

\subsection{The binomial  Markov process}\label{sec:homogeneous_binomial_process}

In this section we study the
binomial process or biased random walk. Random walks are prototypical toy-models to test methods in non-equilibrium statistical physics. Furthermore,  the extreme statistics of random walks have recently become a subject of intense research due to their wide-ranging applications in finance; see e.g.~\cite{mori2019time,benichou2016joint}. Our work utilizes this random walk example as a basis for applying the derivations discussed in previous sections. By using a simple and analytically calculable example, we can better understand the two 
proposed Monte Carlo methods.

The process is defined by the
transition probabilities $p_{\bullet \bullet} = p_{\bullet n}$,
thus not depending on $n \in \Z$,
the value of the penultimate state, that are given by 
\begin{align}        \label{e68}
 p_{\bullet \bullet}(j) & = \begin{cases} 1-r, & \text{if } j =-1, \\
                            r,   & \text{if } j = 1,
 \end{cases}
\end{align}
for some $r\in (0,1)$. Since the jump probabilities depend neither on the state nor on time, the position of the walker follows a binomial distribution (see e.g.~\cite{van2013stochastic}),
\begin{equation*}
    \P[X_t=n|X_s=n']=B\left(\frac{n-n'+t-s}{2},r,t-s\right),
\end{equation*}
where $\forall p \in (0,1)$, $k\in \{1,2,\ldots\}$,
\begin{equation}                                \label{e184}
    B(j,p,k)= \begin{cases} \left( 
    \begin{array}{c} k \\ j 
    \end{array}
    \right)
    p^{j}(1-p)^{k-j}, & \text{if } j=0,1,\ldots,k, \\
                            0,   & \text{otherwise},
 \end{cases}
\end{equation}
are binomial probabilities. Fig.~\ref{fig:trajectories_UBRW}(a) shows instances of trajectories generated with these transition probabilities, with $r=0.6$ and over the time interval $[0,1000]$ together with the first and second cumulants of the binomial process.
%\ja{Riccardo, I am sure that the two  equations above are %correct, but could you check if you like the notation for %Eq.~\eqref{e184}?} -> Ok

In the following examples, we will consider the problem of estimating the probability of a process departing from the fixed state $n_0\in\Z$ at time $0$ and its subsequent passage through specific 
domains in the time-space space,
within the time interval $[0,1000]$. 
Thus, the probability for the first state is given by
$\P[X_0=n] = \delta_{n,n_0}$.

Before showing numerical comparisons in Sections 
\ref{s512}, \ref{subsec:exampleI} and \ref{NCII}, let us summarize 
in Section \ref{s511}
how the two change-of-measure procedures apply to this particular scenario.

\subsubsection{Likelihood ratio of exponential tilting} \label{s511}

Exponential tilting simplifies substantially when considering
the binomial process.
We find directly the c.g.f.
$$K_{\bullet \bullet} (\theta) = 
-\theta + \log \left\{ 1 - r (1 - \e^{-2 \theta}) \right\}$$ and thus
the exponential tilting  transition probabilities of Eq.~(\ref{e40}) become
\begin{equation}\label{eq:transition_prob_exp_tilt_BRW}
 p_{\bullet \bullet}(j,\theta)  = z(n, n+j,\theta) p_{\bullet \bullet}(j) \\
   = \begin{cases} \frac{1-r}{1-r+r \e^{2 \theta}}, & \text{if } j =-1,\\
        \frac{r}{r + (1-r)\e^{-2 \theta}} ,   & \text{if } j = 1.
 \end{cases}
\end{equation}
Thus, under the tilted measure $\P_\theta$, the process remains
binomial. In consistency with the rest of the text, we consider the fixed initial state $n_0 \in \Z$.
Similar to what done in Eq.
(\ref{e150}), we obtain the tilting parameter by
 setting the
 conditional expectation of the total run through distance 
 equal to $n_{t^{\dag}}-n_0$, viz. by solving
\begin{equation}                    \label{eq:eq_for_theta_BRW}    
\E_{\P_\theta}[X_{t^{\dag}}- X_0 \mid X_0 = n_0 ] =t^{\dag} \left(
2\frac{r}{r + (1-r)\e^{-2 \theta}}-1\right)=n_{t^{\dag}}-n_0.
\end{equation}
Where the above expectation 
is the one of the binomial distribution.
By defining 
\begin{equation}\label{eq:def_rho}
    \rho=\frac{n_{t^{\dag}}-n_0}{t^{\dag}}
\end{equation} 
and by inverting Eq. (\ref{eq:eq_for_theta_BRW}), we obtain 
\begin{equation}\label{eq:theta_BRW}
    \theta =-\frac{1}{2}\log \left(\frac{r}{1-r}\frac{1-\rho}{1+\rho}\right),
\end{equation}
which is well-defined when $|n_{t^{\dag}}-n_0|<t^{\dag}$
(thus with exclusion of the two monotone sample paths). 

Eq.~\eqref{eq:theta_BRW} implies that it is equivalent to fix the tilting parameter ($\theta$), the average current ($\rho$), or the average final destination ($n_{t^{\dag}}$) of the walker. This map between the tilting parameter and the average current $\rho$ makes it easier to find intuitively values of $\theta$ that will bias paths towards desired regions of the space. Furthermore, this expression makes it explicit the analogy with the canonical ensemble, in which the temperature parameter fixes the energy of the system on average; thus explaining why exponential tilt  methods are also referred to as canonical methods~\cite{chetrite2015nonequilibrium}. Still, the choice of the optimal tilting parameter (or average current) that minimizes the relative error will depend to the specific problem to solve (see e.g. Section~\ref{subsec:exampleI}).

Upon inserting Eq. \eqref{eq:theta_BRW} into Eq. \eqref{eq:transition_prob_exp_tilt_BRW}, we obtain
the exponentially tilted transition probabilities
\begin{equation*}
    p_{\bullet \bullet}(j,\theta)=\begin{cases} \frac{1-\rho}{2}, & \text{if } j =-1,\\
        \frac{1+\rho}{2} ,   & \text{if } j = 1.
 \end{cases}  
\end{equation*}
We note that
these tilted probabilities do not depend on 
$r$. In Fig.~\ref{fig:trajectories_UBRW}(b), we show instances of trajectories generated with these transition probabilities using $\rho=0$. The homogeneity of the process simplifies the expression of the likelihood 
ratio Eq. (\ref{e29}) to
\begin{align}\label{eq:likelihood_ratio_exponential_tilt_UBRW}
    L_t(\theta) & = \e^{-\theta (X_t-n_0)}
        \prod_{k=1}^t M_{\bullet \bullet} (\theta) 
    =\e^{-\theta (X_t-n_0)}\left\{r \e^{\theta}+(1-r)\e^{-\theta}\right\}^t, \; \text{ for } t=1,\ldots, t^{\dag},
\end{align}
where $M_{\bullet \bullet}$ is the m.g.f. of
$p_{\bullet \bullet}$.
We can simplify further Eq.
(\ref{eq:likelihood_ratio_exponential_tilt_UBRW})
by introducing the 
tilting parameter as given in Eq. \eqref{eq:theta_BRW} together with the change-of-variables $q=(1+\rho)/2$ and $N_t=(X_t-n_0+t)/2$, yielding
\begin{equation}\label{eq:likelihood_ratio_exponential_tilt_UBRW_V2}
L_t(\theta(q))=\left(\frac{r}{q}\right)^{N_t}\left(\frac{1-r}{1-q}\right)^{t-N_t}, \; \text{ for } t=1,\ldots, t^{\dag},
\end{equation}
where the selected tilting parameter $\theta$ is 
redenoted $\theta(q)$.

\subsubsection{Likelihood ratio of backtracking} \label{s512}

The binomial distribution of the process simplifies the application of backtracking as well, since the probabilities 
of the backward change-of-measure kernels given in
Eq.~\eqref{eq:transition_kernel_backtracking} are
obtained directly from
\begin{equation}\label{eq:binomial_UBRW}
\P[X_t=n|X_0=n_0]= B\left(\frac{t+n-n_0}{2},r,t\right).
\end{equation}

Therefore, by inserting Eq.~\eqref{eq:binomial_UBRW} into Eq.~\eqref{eq:transition_kernel_backtracking}, we obtain the transition probabilities under the backtracking measure $\P_{n_0}$ 
through Eq. (\ref{eq:proof_backtracking_rate})
as
\begin{equation}\label{eq:transition_probabilities_backtrack_UBRW}
    %p_{n_0,k}(j)
    % the above function was never defined, in this paper at least,
    % so I replace it by its full expression
    \P[X_t = n \mid X_{t+1}=n+j, X_0=n_0]
    =\begin{cases} \frac{1}{2}(1-\frac{n_0-n}{t}), & \text{if } j =-1, \\
    \frac{1}{2}(1+\frac{n_0-n}{t})                        ,   & \text{if } j = 1.
 \end{cases}
\end{equation}
We can freely choose the probability distribution of the states at final time $t^{\dag}$,
i.e. $w_{t^{\dag}}$ defined at Eq.~\eqref{eq:distribution_last_state_backtrack}. When the final distribution is a Kronecker delta, $w_{t^{\dag}}(n;n_0)=\delta_{n,n_{t^{\dag}}}$, the process evolving through Eq.~\eqref{eq:transition_probabilities_backtrack_UBRW} has fixed initial ($n_0$) and final ($n_{t^{\dag}}$) positions. Therefore, since the backtracking can fix the current $\rho$ exactly, cf. Eq.~\eqref{eq:def_rho}, and not in average as the exponential tilting method, it is also referred to as a microcanonical method~\cite{chetrite2015nonequilibrium} (in analogy with the microcanonical ensemble in which the energy is fixed exactly).  In Fig.~\ref{fig:trajectories_UBRW}(c), we show instances of trajectories generated with these transition probabilities using $w_{t^{\dag}}(n;n_0)=\delta_{n,n_0}$. 
Further, the likelihood ratio of Eq.~\eqref{eq:likelihood_ratio_backtrack} in this case reads
\begin{equation}\label{eq:likelihood_ratio_backtrack_UBRW}
    L_{t^{\dag}}(n_0)=\frac{B\left(\frac{t^{\dag}+X_{t^{\dag}}-n_0}{2},r,t^{\dag}\right)}{w_{t^{\dag}}(X_{t^{\dag}};n_0)}.
\end{equation}

\subsubsection{Numerical comparisons I: local time target}\label{subsec:exampleI}

Our first numerical experiment compares
exponential tilting and backtracking for obtaining
the probability that the process departing from state 
$n_0=0$ hits the target interval $\I_0(10)=[-10,10]$ at terminal time $t^\dag=1000$
with a positive drift or bias obtained by setting $r=0.6$. 
This is a simple example that can be solved analytically and we indeed obtain
\begin{equation}\label{eq:first_moment}
    z_{t^{\dag}}(\I_0(10))=\P[X_{t^{\dag}}\in \I_0(10)]=\sum_{n=-10}^{10} \P[X_{t^{\dag}}=n|X_0=0]=7.543\cdot10^{-10}.
\end{equation}
The objective is thus to benchmark the two Monte Carlo methods when the quantity of interest is available. Moreover, this example enables us to assess the importance of appropriate selections of tilting parameter and of terminal distribution,
respectively for the exponential tilting and backtracking.
Careful selections are crucial for the efficiency of 
these methods.
%This is reflected in the fact that the likelihood process in both the %likelihood and backtrack measures only depends on the last state of %the process; see %Eq.~\eqref{eq:likelihood_ratio_exponential_tilt_UBRW} and %Eq.~\eqref{eq:likelihood_ratio_backtrack_UBRW}.

The homogeneity of the process and the simplicity of the target makes that we can actually avoid the generation of the full
trajectory and only generate, by importance sampling, the last state of the process ($X_{t^{\dag}}$). We can then define the importance sampling estimators of exponential 
tilting and backtracking respectively as
\begin{align}                                       \label{e55}
Z_{\theta, t^\dag} (\I_0(10)) & = I_{\I_0(10)}(X_{t^{\dag}} ) L_{t^{\dag}}(\theta)\;\text{ and } \quad  Z_{n_0, t^\dag} (\I_0(10))  = I_{\I_0(10)}(X_{t^{\dag}} ) L_{t^{\dag}}(n_0).
\end{align}
Then, the probability of ending in $\I_0(10)$ is
the expectation of these two Monte Carlo
estimators w.r.t. their importance sampling distributions, precisely 
\begin{align}                                   \label{e89}
z_{t^\dag}(\I_0(10))  =\E_{\P_{\theta}}[Z_{\theta, t^\dag} (\I_0(10))]= \E_{\P_{n_0}}[Z_{n_0, t^\dag} (\I_0(10))].
\end{align}

{\bf For exponential tilting}, we generate random arrival states from the binomial distribution and then compute their mean weighted by the likelihood ratios in Eq.~\eqref{eq:likelihood_ratio_exponential_tilt_UBRW_V2}. 
Algorithm \ref{al40}, generally given for
$\I_c(a)$, $a \ge 0$ and $c$ integers,
follows directly from Eq.
(\ref{e55}) and Eq. (\ref{e89}).
\begin{tcolorbox}
\begin{algorithm}[Exponential tilting for binomial process]                         \label{al40}
$ $ \\
Select a large number $m$ of iterations.
\begin{enumerate}
\item Repeat for $j=1,\ldots,m$, 
\begin{itemize}
    \item generate $N_{t^{\dag}}^{(j)}$ from the 
    binomial distribution
    $B(\cdot,q,t^{\dag})$ with $q=(1+\rho)/2$ and
    $\rho$ obtained from Eq.~\eqref{eq:def_rho},
    representing the number of positive jumps of the process in the time interval $[0,t^{\dag}]$, under the exponentially 
    tilted measure;
    \item transform the generated number of positive jumps into the value of the final state, according to 
    \begin{equation*}
        X^{(j)}_{t^{\dag}}=2N_{t^{\dag}}^{(j)}-t^{\dag}+n_0;
    \end{equation*}
    \item obtain the likelihood ratio
    $L_{t^{\dag}}^{(j)}(\theta)$ from Eq.
    (\ref{eq:likelihood_ratio_exponential_tilt_UBRW_V2}) with $N_{t^{\dag}}^{(j)}$.
\end{itemize}
    \item Compute the estimator of $z_{t^\dag}(\I_c(a))=\P[X_{t^{\dag}}\in \I_c(a)]$ given by
    \begin{align}\label{eq:estimator_exponential_tilted_example1}
        \hat{z}_{t^\dag,m}(\I_c(a)) & =\frac{1}{m}\sum_{j=1}^m I_{\I_c(a)}(X^{(j)}_{t^{\dag}})L_{t^{\dag}}^{(j)}(\theta)
        =\frac{1}{m}\sum_{j=1}^m I_{\I_c(a)}(X^{(j)}_{t^{\dag}})\left(\frac{r}{q}\right)^{N^{(j)}_{t^{\dag}}}\left(\frac{1-r}{1-q}\right)^{t^{\dag}-N^{(j)}_{t^{\dag}}}.
    \end{align}
\end{enumerate}
\end{algorithm}
\end{tcolorbox}
In Fig. \ref{fig:example1_exponential_tilt}(a) we show that, 
for various values of the tilting parameter,
the importance sampling estimator with the exponential tilted measure is in close agreement with the true analytical value. 

The simplicity of this example allows us to compute the theoretical value of the relative error 
of importance sampling. Denote the second moment of the exponential tilt estimator by
\begin{equation}                                \label{e117}
    z_2=\E_{\P_\theta}\left[I_{\I_0(10)}(X_{t^{\dag}})\{L_{t^{\dag}}(\theta)\}^2\right]=\sum_{n=n_0-t^{\dag}}^{n_0+t^{\dag}} I_{\I_0(10)}(n)\{L_{t^{\dag}}(\theta)\}^2 B\left(\frac{t^{\dag}+n-n_0}{2},r,t^{\dag}\right).
\end{equation}
For simplicity, denote $z=z_{t^\dag}(\I_0(10))$.
Eq. (\ref{e117}) together with Eq.~\eqref{eq:first_moment} allow
us to compute the relative error $\sigma_Z/z$, where
$\sigma_Z=\sqrt{z_2-z^2}$.
This relative error is proportional to the square of the number of Monte Carlo replications required for target precision in the calculations, cf. p. 158-159~\cite{asmussen2007stochastic}. Minimizing the relative error enhances efficiency, in the sense as fewer realizations are necessary 
in order to reach a desired level of precision. It is shown in Fig. \ref{fig:example1_exponential_tilt}(b) that empirical and theoretical values for the relative error are in agreement. Furthermore, Fig. \ref{fig:example1_exponential_tilt}(b) shows that the minimal relative error is obtained by the tilting parameter that places the average final position at the lower bound of the target interval ($n_{t^\dag}=10$), this in agreement with the derivations of Section~\ref{s35}.

{\bf For backtracking}, we need to choose the distribution of the last states ($w_{t^{\dag}}$). As in the case of the exponential tilt discussed above, it is easier to work with the distribution of the number of positive jumps by the final time ($N_{t^\dag}$) that we call $f_{t^{\dag}}$, 
\begin{equation*}
    f_{t^{\dag}}(n)=\P[N_{t^\dag}=n].
\end{equation*}
We observe that the distribution of positive jumps is related to the terminal distribution of the states through
\begin{equation*}
    f_{t^{\dag}}(n)=w_{t^{\dag}}(2n+n_0-t^{\dag};n_0).
\end{equation*}
For the number of positive jumps, we opt for the uniform 
distribution given by
\begin{equation}\label{eq:distribution_final_positions_backtracking}
    f_{t^{\dag}}(n)=\begin{cases} \frac{1}{D+1}, & \text{if } n \in[\frac{t^{\dag}}{2}-D,\frac{t^{\dag}}{2}+D],\\
    0, & \text{otherwise}.
 \end{cases}
\end{equation}
This choice is motivated by the simplicity of the distribution together with the efficiency of generating uniform random numbers. Additionally, 
Eq. \eqref{eq:distribution_final_positions_backtracking} offers the flexibility to adjust the distribution's width, represented by the parameter $D$, allowing us to examine scenarios where the new measure does not adhere to absolute continuity. Notably, selecting $D<t^{\dag}$ violates the requirement $\P\ll\P_{n_0}$, leading to the inclusion of biased errors (see Sections \ref{sec:absolute_continuity} and ~\ref{subsec:choice_of_final_distribution}). 

Algorithm \ref{al50} provides the details of the implementation of backtracking, generally for
$\I_c(a)$, $a \ge 0$ and $c$ integers.
\begin{tcolorbox}
\begin{algorithm}[Backtracking for 
binomial process]   \label{al50}
$ $ \\
Select a large number $m$ of iterations.
\begin{enumerate}
\item Repeat for $j=1,\ldots,m$, 
\begin{itemize}
    \item 
    generate $N_{t^{\dag}}^{(j)}$ from $f_{t^{\dag}}$,
    representing the number of positive jumps of the process in the time interval $[0,t^{\dag}]$, under the backtracking measure;
    \item transform this number of positive jumps into 
    the value of the final state, according to 
    \begin{equation*}
        X^{(j)}_{t^{\dag}}=2N_{t^{\dag}}^{(j)}-t^{\dag}+n_0;
    \end{equation*}
    \item obtain the likelihood ratio $L_{t^{\dag}}^{(j)}(n_0)$ from (\ref{eq:likelihood_ratio_backtrack_UBRW}) with
    $X^{(j)}_{t^{\dag}}$ or with $N^{(j)}_{t^{\dag}}$.
    \end{itemize}
\item Compute the estimator of ${z}_{t^\dag}(\I_c(a))=\P[X_{t^{\dag}}\in \I_c(a)]$ given by
    \begin{equation*} \!\!\!\!
        \hat{z}_{t^\dag,m}(\I_c(a)) =\frac{1}{m}\sum_{j=1}^m I_{\I_c(a)}(X^{(j)}_{t^{\dag}})L_{t^{\dag}}^{(j)}(n_0) =\frac{2D}{m}\sum_{j=1}^m I_{\I_c(a)}(X^{(j)}_{t^{\dag}})B(N_{t^{\dag}}^{(j)},r,t^{\dag}),
    \end{equation*}
    where $B$ is the binomial probability function in Eq. (\ref{e184}).
\end{enumerate}
\end{algorithm}
\end{tcolorbox}
Fig. \ref{fig:example1_backtracking}(a) shows that importance sampling 
with the backtracking is in agreement with the analytical value, 
for final distributions that include the target region, viz. for $D>10$. Therefore, for $D<10$ the backtracking measure forbids states that are important for the estimation of $z$. Thus, these values of $D$ are linked with biased errors. In contrast with this, 
for values $D\ge10$, forbidden areas do not affect the backtracking estimator, even if absolute continuity is still not satisfied.

Fig. \ref{fig:example1_backtracking}(b) shows how the width of the terminal distribution ($D$) affects the relative error. In this figure, we also compare the numerical results with the theoretical value for the relative error,
\begin{align*}
    z_2& =\E_{\P_{n_0}}\left[I_{\I_0(10)}(X_{t^{\dag}})\{L_{t^{\dag},n_0}(X_{t^{\dag}})\}^2\right]  
    = 2D \sum_{n=n_0-t^{\dag}}^{n_0+t^{\dag}} I_{\I_0(10)}(n) \left\{B\left(\frac{t^{\dag}+n-n_0}{2},r,t^{\dag}\right)\right\}^2.
\end{align*}

Even if we find that sampling errors grow monotonically with $D$, this result is not significant for $D<10$, where biased errors can have important effects [as shown in Fig. \ref{fig:example1_backtracking}(a)].
% Figure environment removed

% Figure environment removed

% Figure environment removed

\subsubsection{Numerical comparisons II: extended time target}  \label{NCII}

For the second numerical example, we evaluate the probability that the binomial process hits a target extended in time: 
\begin{equation}\label{eq:extended_time_target}
    z_{t_1,t_2}(\I_0(10))=\P[\exists s\in[t_1,t_2]: X_s\in \I_0(10)],
\end{equation}
where $0 \le t_1 < t_2 \le t^\dag$.
As in the previous example, the process is biased towards the positive direction with $r=0.6$. In this case, the hitting probability is not trivial to obtain analytically. Thus,  numerical techniques are the preferred option to tackle the problem. Moreover, since the target can be hit at different times, we need to simulate the process at intermediate times.

{\bf For exponential tilting}, we follow Algorithm~\ref{al:tilting}, where we choose the tilting parameter according Eq.~\eqref{eq:def_rho} and
    Eq. \eqref{eq:theta_BRW} such that the tilting parameter sets the mean final state of trajectories equal to the center of the interval $\I_c(a)$, namely $c$. Also, we can compute the estimator as 
    \begin{align}\label{eq:estimator_exponential_tilted_example2}
        \hat{z}_{t_1,t_2,m}(\I_c(a)) 
        & =\frac{1}{m}\sum_{i=1}^m I\left\{\sum _{s=t_1}^{t_2}I_{\I_c(a)}(X^{(i)}_{s})>0\right\}L_{t^{\dag}}(X_{t^{\dag}},
        \theta) \nonumber \\ 
        & =\frac{1}{m}\sum_{i=1}^m I\left\{\sum _{s=t_1}^{t_2}I_{\I_c(a)}(X^{(i)}_{s})>0\right\}\left(\frac{r}{q}\right)^{N^{(i)}_{t^{\dag}}}\left(\frac{1-r}{1-q}\right)^{t^{\dag}-N^{(i)}_{t^{\dag}}},
    \end{align}
where 
    \begin{equation*}
        N_{t^{\dag}}^{(j)}=\frac{t^{\dag}+X^{(j)}_{t^{\dag}}}{2}.
    \end{equation*}
    
%Algorithm \ref{al5} and Algorithm \ref{al6}
%below provide the details of the implementation of
%exponential tilting and
%backtracking, respectively. In our numerical illustrtions, we
%apply these two algorithms, 
%with $n_0=0$, $t^\dag=1000$, $a=10$, \ric{$c=?$ and $m=?$. (I cannot find this in the paper, thank you!)}
%\begin{tcolorbox}
%\begin{algorithm}[Exponential tilting for homogeneous Markov process] \label{al5}
%$ $ \\
%Select a large number $m$ of iterations.
%\begin{enumerate}
 %   \item Choose the tilting parameter according Eq.~\eqref{eq:def_rho} and
%    Eq. \eqref{eq:theta_BRW}. 
%    \item Repeat for $j=1,\ldots,m$, 
%    \begin{itemize}    
%    \item generate $\{X_t^{(j)}\}_{t \in [0,t^{\dag}]}$, the $j$-th sample path of the process, 
 %   from the exponentially tilted transition probabilities of Eq.~\eqref{eq:transition_prob_exp_tilt_BRW}, 
 %   departing 
 %   at time $t=0$
  %  from state $n_0$ and stopping at time %$t=t^{\dag}$;
  %  \item transform the last generated state $X^{(j)}_{t^{\dag}}$ into the number of positive jumps of the trajectory
 %   \begin{equation*}
 %       N_{t^{\dag}}^{(j)}=\frac{t^{\dag}+X^{(j)}_{t^{\dag}}}{2}.
 %   \end{equation*}
%    \end{itemize}
 %   \item Compute the estimator of $z_{t_1,t_2}(\I_c(a))$, given in Eq.~\eqref{eq:extended_time_target}, by
%    \begin{align}\label{eq:estimator_exponential_tilted_example2}
  %      \hat{z}_{t_1,t_2,m}(\I_c(a)) 
  %      & =\frac{1}{m}\sum_{i=1}^m I\left\{\sum %_{s=t_1}^{t_2}I_{\I_c(a)}(X^{(i)}_{s})>0\right\}L_{t^{\dag}}(X_{t^{\dag}},
  %      \theta) \nonumber \\ 
 %       & =\frac{1}{m}\sum_{i=1}^m I\left\{\sum %_{s=t_1}^{t_2}I_{\I_c(a)}(X^{(i)}_{s})>0\right\}\left(\frac{r}{q}\right)^{N^{(i)}_{t^{\dag}}}\left(\frac{1-r}{1-q}\right)^{t^{\dag}-N^{(i)}_{t^{\dag}}}.
 %   \end{align}
%\end{enumerate}
%\end{algorithm}
%\end{tcolorbox}

{\bf For backtracking}, we use Algorithm~\ref{al:backtracking} with an uniform terminal distribution,
\begin{equation*}
    w_{t^\dag}(n;n_0)=\begin{cases} \frac{1}{D}, & \text{if } n \in \I_c(a),\\
    0, & \text{otherwise}.
    \end{cases}
\end{equation*}
Also, we can compute the estimator of 
    of $z_{t_1,t_2}(\I_c(a))$, given in Eq.~\eqref{eq:extended_time_target}, by
    \begin{align*}
        \hat{z}_{t_1,t_2,m}(\I_c(a)) &=\frac{1}{m}\sum_{i=1}^m  I\left\{\sum _{s=t_1}^{t_2}I_{\I_c(a)}(X^{(i)}_{s})>0\right\} L_{t^{\dag},n_0}(X^{(i)}_{t^{\dag}}) \nonumber \\ &=\frac{2D}{m}\sum_{i=1}^m  I\left\{\sum _{s=t_1}^{t_2}I_{\I_c(a)}(X^{(i)}_{s})>0\right\}B(N_{t^{\dag}}^{(i)},r,t^{\dag}),
        \end{align*}
        where $B$ is the binomial probability function (\ref{e184}).
%\begin{samepage}
%\begin{tcolorbox}
%\begin{algorithm}[Backtracking for homogeneous Markov process]
%\label{al6}
%$ $ \\
%Select a large number $m$ of iterations.
%\begin{enumerate}
%    \item  From the uniform distribution over $A_c=[c-a,c+a]$, 
%    \begin{equation*}
%    w_{t^\dag}(n;n_0)=\begin{cases} \frac{1}{D}, & \text{if } n \in A_c,\\
 %   0, & \text{otherwise},
%    \end{cases}
%    \end{equation*}
%    with $D=1+2c$, generate the final position $X_{t^{\dag}}^{(j)}$ of the process.
%    \item Repeat for $j=1,\ldots,m$, 
%    \begin{itemize}    
%    \item generate $\{X_t^{(j)}\}_{t \in [0,t^{\dag}]}$, 
%    the $j^{\text{th}}$ sample path of the process,
%    from backtracking with the transition probabilities of Eq.~\eqref{eq:transition_probabilities_backtrack_UBRW},
 %   backwards in time, departing at time $t={t^{\dag}}$ from the 
   % state 
 %   $X_{t^{\dag}}^{(j)}$,
 %   generated under 1,
 %   and stopping at time $t=0$;
 %   \item 
 %   transform the last generated state $X^{(j)}_{t^{\dag}}$ into the number of positive jumps of the trajectory
 %   \begin{equation*}
  %      N_{t^{\dag}}^{(j)}=\frac{t^{\dag}+X^{(j)}_{t^{\dag}}}{2}.
   % \end{equation*}
    %transform the number samples of positive jumps 
    %into final states according to 
    %\begin{equation*}
    %X^{(j)}_{t^{\dag}}=2N_{t^{\dag}}^{(j)}-t^{\dag}+n_0.
    %\end{equation*}
    %\end{itemize}
  %  \item Compute the estimator of 
  %  of $z_{t_1,t_2}(A_c)$, given in Eq.~\eqref{eq:extended_time_target}, by
  %  \begin{align*}
   %     \hat{z}_{t_1,t_2,m}(A_c) &=\frac{1}{m}\sum_{i=1}^m  I\left\{\sum _{s=t_1}^{t_2}I_{A_c}(X^{(i)}_{s})>0\right\} L_{t^{\dag},n_0}(X^{(i)}_{t^{\dag}}) \nonumber \\ &=\frac{2D}{m}\sum_{i=1}^m  I\left\{\sum _{s=t_1}^{t_2}I_{A_c}(X^{(i)}_{s})>0\right\}B(N_{t^{\dag}}^{(i)},r,t^{\dag}),
    %    \end{align*}
     %   where $B$ is the binomial probability function (\ref{e184}).
%\end{enumerate}
%\end{algorithm}
%\end{tcolorbox}
%\end{samepage}

% Figure environment removed

In Fig.~\ref{fig:target_extended_in_time}-(a) we show that the sample average for different values of the center $c$ computed with the two methods agree within errors. In Fig.~\ref{fig:target_extended_in_time}-(b) we also show that the relative errors in both methods have the same order of magnitude. However, the relative error for the exponential tilt increases as the event becomes rarer whereas the errors in the backtracking method are more constant. This result is surprising provided that the backtracking process is biased (because our particular choice of $w_{t^\dag}$ in Eq.~\eqref{eq:likelihood_ratio_backtrack} does not fulfill absolute continuity) whereas the exponential tilted method is unbiased.

\subsection{Process with meta-stable states}     \label{s52}

In this section, we study a more sophisticated Markovian model where transition probabilities in Eq.
(\ref{e68}) depend on the value of the state $n$.
%and we thus redenote the probability $r$ by $r_n$
Precisely, they are given by
\begin{align}\label{eq:PT_metastable}
 p_{\bullet n}(j) & = \begin{cases} \left[1+\e^{j\nu{n(n-\ell)(n+\ell)}}\right]^{-1} , & \text{if } j =-1,1, \\
                            0,   & \text{otherwise},
 \end{cases}
 \end{align}
where $n$ and $\ell>0$ are integers and $\nu>0$. 
We note that the probability transitions in Eq.~\eqref{eq:PT_metastable} define a one-step process since $p_{\bullet n}(1) + p_{\bullet n}(-1) = 1$. Additionally, this process exhibits two meta-stable states at positions $n=\pm \ell$. This means that trajectories tend to oscillate around these states, and it is exceptionally rare to observe a transition from one of these states to the other. The parameter $\nu$ tunes the robustness of the meta-stable states. If $\nu=0$, then the process is an unbiased random walk without meta-stable states. At the opposite, in the limit $\nu\to\infty$, trajectories evolve forming a straight line (deterministically) towards either $\ell$ or $-\ell$. In Fig.~\ref{fig:trajectories_metastable}-(a) we show typical trajectories for this process. Furthermore, the roles of $\ell$ and $\nu$ can be understood intuitively from a physical perspective. The transition probabilities in Eq.~\eqref{eq:PT_metastable} can be seen as a discretization of a model where a particle is subjected to the force $f(n)=-\tanh(\frac{\nu{n(n-\ell)(n+\ell)}}{2})$ in the overdamped limit, i.e.  in a high viscosity regime where inertia can be neglected.
% Figure environment removed

In order to statistically characterize these transitions, we make use of the change-of-measure strategies defined so far.

{\bf For exponential tilting}, by using Eq.~\eqref{e38} we can compute the transition probabilities for a fixed value of $\theta$,
\begin{align}\label{eq:PT_exp_tilt}
 p_{\bullet n}(j,\theta) & = \begin{cases} \left\{1+\e^{j\left[\nu{n(n-\ell)(n+\ell)}-2\theta\right]}\right\}^{-1} , & \text{if } j =-1,1, \\
                            0,   & \text{otherwise}.
 \end{cases}
 \end{align}
Thus, the parameter $\theta$ breaks the symmetry of the transition rates around $n=0$ and effectively biases paths either towards the meta-stable state in the positive position (for $\theta>0$) or in the negative position (for $\theta<0$). We note that the position of the meta-stable states is not preserved and depends on the value of $\theta$ [see Fig.~\ref{fig:trajectories_metastable}-(b)].

In this case, the likelihood process for the tilted process depends on the whole realization and is obtained through the evaluation of Eq.~\eqref{e29}.

{\bf For backtracking}, we cannot use an analytical form for the transition probabilities, and we have to evaluate Eq.~\eqref{eq:transition_kernel_backtracking} numerically. This evaluation would, in principle, require the computation of $\P[X_t=n|X_0=n_0], \; \forall n,t\in[1,t^{\dag}]$, through the iteration of the forward Kolmogorov equation: 
\begin{equation}\label{eq:forward_KE}
    \P[X_{t+1}=n|X_0=n_0]= p_{\bullet n+1}(-1) \P[X_t=n+1|X_0=n_0]+p_{\bullet n-1}(1) \P[X_t=n-1|X_0=n_0].
\end{equation}
To ensure numerical tractability of Eq. \eqref{eq:forward_KE}, boundary conditions are introduced to the system by setting $\ell_\text{max}$ and $-\ell_\text{max}$ as boundaries, such that $p_{\bullet -\ell_\text{max}}(-1)=p_{\bullet \ell_\text{max}}(1)=0$ and $p_{\bullet -\ell_\text{max}}(0)=p_{\bullet \ell_\text{max}}(0)=\left[1+\e^{-\nu{n(n-\ell_\text{max})(n+\ell_\text{max})}}\right]^{-1}$. These conditions imply that particles are unable to cross the boundaries, but they can avoid jumping precisely at the boundaries. This approximation does not introduce significant systematic errors in the solution as long as the probability for the process to reach the boundaries is low ($\P[X_t=\pm\ell_\text{max}]\approx 0, \; \forall t\ge 0$). Although it is possible to introduce alternative approximations that avoid the use of Eq. \eqref{eq:forward_KE}, this approach is not employed in this work. For more details on these alternative approaches, we refer the interested reader to ~\cite{aguilar2022sampling}. In Fig.~\ref{fig:trajectories_metastable}-(c) it is shown that the backtracking process can be used to sample paths connecting meta-stable states.

\subsubsection{Numerical comparisons III: local time target}\label{subsec:exampleIII}
Similar to what we did in Section~\ref{subsec:exampleI}, we analyze a simple example for which we can estimate the solution. Particularly, we compute the probability that a path starting from one of the meta-stable states ($X_0=-\ell$) hits an interval that includes the other meta-stable state by terminal time $t^{\dag}$,
$$z=\P[X_{t^{\dag}}\in A|X_0=-\ell].$$

Where the set $A$ is such that $-\ell\notin A$ and $\ell \in A$. This problem can be solved numerically computing $\P[X_t^{\dag}=j|X_0=-\ell]$, $\forall j\in A$, with Eq.~\eqref{eq:forward_KE}, then
\begin{equation}\label{eq:computation_of_z}
    z=\sum_{j\in A} \P[X_t^{\dag}=j|X_0=-\ell].
\end{equation}
We first estimate $z$ using an ensemble of paths generated with the backtracking change-of-measure as described in Algorithm~\ref{al:backtracking}. For the terminal distribution, we chose a uniform distribution ,
\begin{equation*}
    w_{t}(n;-\ell)=\begin{cases} \frac{1}{2D+1}, & \text{if } n \in[\ell-D,\ell+D],\\
    0, & \text{otherwise},
    \end{cases}
 \end{equation*}
However, in this case, we vary the terminal time of the paths generated in the backtracking measure. This is, we will generate backtracking paths for $t=0,\dots,t^*$ for $t^*\ge t^\dag$. In this way, we will be able to check if the terminal time has an effect on the estimation of $z$. 
In Fig.~\ref{fig:exp_3}-(a), we show that the estimation of $z$ agrees with the expected value computed from Eq.~\eqref{eq:computation_of_z} within errors. The statistical errors of the backtracking method increase as the time of the terminal distribution differ from $t^{\dag}$.

In Fig.~\ref{fig:exp_3}-(b) we show the computation of $z$ over an ensemble of paths generated with the exponential tilt change-of-measure as described in Algorithm \ref{al:tilting} for different values of the tilting parameter $\theta$. 
In contrast with backtracking change-of-measure, the exponential tilting estimator does not seem to converge to the expected value of $z$. Furthermore, certain realizations display tremendous fluctuations, clearly visible in Fig.~\ref{fig:exp_3}-(b) as the error bars steadily increase. We note that  the distribution of $z$ under the exponential tilt measure exhibits heavy tails. Consequently, achieving a reliable numerical estimator for the first moment necessitates a significant number of realizations. As the number of samples increases, we observe a notable improvement in the quality of numerical estimators obtained with the exponential tilt method (see Fig.~\ref{fig:exp_3_more_realiz}, where we use the exponential tilt method increasing the number of realizations with respect to Fig.~\ref{fig:exp_3}-(b)). In particular, we observe through Fig.~\ref{fig:exp_3_more_realiz} that the optimal tilting parameter is located around $\theta\approx 0.3$. Still, wild oscillations are observed for values close to one, pointing out the necessity of estimating the optimal tilting parameter in this kind of application.
% Figure environment removed

The example presented in this section offers valuable insights into the suitability of the backtracking change-of-measure approach for addressing problems involving transition paths between meta-stable states. Remarkably, despite the fact that the exponential tilt method is unbiased, the backtracking method proves to be more effective in such scenarios, despite the presence of biases resulting from the violation of absolute continuity.
% Figure environment removed
\section{Final remarks}               \label{s5}

 Problems that require sampling rare trajectories in a feasible amount of time appear in various scientific disciplines (such as physics, mathematical biology and finance). In this article, we analyze two paradigms of methods for sampling rare trajectories
 of Markov processes: exponential tilting and backtracking. Our main contribution is to show that these two methods can be re-expressed within the general theory of change-of-measure and importance sampling.
 %Thus, we contribute to a general theory for sampling rare events.
 Through numerical examples,
 we illustrate the applicability of both Monte Carlo methods to the computation of
 probabilities of rare trajectories.
Moreover, we provide the related Monte Carlo algorithms, so to make them directly 
accessible to applied scientists mainly 
interested in their applications.

For the case of the binomial process, we provided numerical 
 evidence that the relative errors of these two sampling 
 strategies are of comparable and small order. In problems involving transition paths between meta-stable states, the backtracking change-of-measure appears to assign consistent values to the estimators for different choices of the terminal distribution. In contrast, when utilizing the exponential tilting change-of-measure, the distribution of the estimator appears heavy-tailed. Consequently, obtaining an accurate estimation of the first moment often necessitates a large number of Monte Carlo samples. We nevertheless expect that 
 the
 exponential tilting change-of-measure could be particularly valuable when dealing with multi-dimensional processes, where the application of the backtracking change-of-measure becomes challenging.
 One should also note that exponential tilting requires
 the existence of the c.g.f. of the transition probabilities,
 see Eq. (\ref{e158}) and Eq. (\ref{e159}), which is a light-tail
 requirement on the transition distributions. 
 There is no such restriction with backtracking.
 
There is a manifest need for future research in this topic. 
In our numerical examples, we showed that there are optimal choices of the tilting parameter and of the terminal distribution, that minimize the errors of exponential tilting and backtracking, respectively. Analytical optimality results and practical formulae for the tilting parameter and for the terminal distribution 
are important unsolved questions to be addressed in the future. 
Another subject of investigation could be
be the extension of the exponential tilting 
likelihood ratio in Eq. (\ref{e29})
from one to many tilting parameters: at each transition
of the process, a specific tilting parameter could 
be used, thus depending on the current states.
Finally, we could consider other practical settings
for comparing backtracking and exponential 
tilting, such as the one
of the insurer ruin with recuperation. This is 
the passage of a process through a lower barrier followed by
the passage through an upper barrier (cf.
\cite{gatto2015} in relation with spectrally negative L\'evy processes).
 
\printbibliography

\clearpage
\newpage
\clearpage

 \setcounter{page}{1}
 \begin{center}
 \Large{\bf Appendix}
 \end{center}
 \appendix
 
%\setcounter{figure}{0}
%\setcounter{equation}{0}
%\setcounter{section}{0}
\renewcommand{\thesection}{A\arabic{section}} 
\renewcommand{\theequation}{A\arabic{equation}}
\renewcommand{\thefigure}{A\arabic{figure}}
\setcounter{equation}{0}

\section{Conditioned moments of binomial process}\label{ap:conditioned_moments_binomial}

This section provides the details of the calculation of the first two moments of the binomial bridge, i.e. the binomial process $\{X_t\}_{t \in [0,t^\dag]}$ conditioned to both endpoints
$X_0=a \in \Z$ and $X_{t^\dag}=b \in \Z$. These moments
are used  in Section~\ref{sec:Conditioned_MP}.
We consider $0\le s \le t \le {t^{\dag}}$.
For any Markov process $\{X_t\}_{t \in [0,t^\dag]}$
and for any random variable $Z_t=f(X_t)$, for some
$f: \Z \to \Z$, the following relation  for the conditional
expectation holds,
\begin{align}\label{eq:conditioned_average}
    \E\left[Z_{t}|X_{t^{\dag}}=b,X_0=a\right] &=\sum_{j=-\infty}^\infty j \P[Z_t = j |X_{t^{\dag}}=b,X_0=a]
    = \sum_{j=-\infty}^\infty j \frac{\P[Z_t=j,X_{t^{\dag}}=b,X_0=a]}{\P[X_{t^{\dag}}=b,X_0=a]}\nonumber \\
    &= \sum_{j=-\infty}^\infty j\frac{\P[X_{t^{\dag}}=b|Z_t=j,X_0=a]\P[Z_t=j|X_0=a]}{\P[X_{t^{\dag}}=b|X_0=a]}\nonumber \\
    &= \sum_{j=-\infty}^\infty j \frac{\P[X_{t^{\dag}}=b|Z_t=j]\P[Z_t=j|X_0=a]}{\P[X_{t^{\dag}}=b|X_0=a]}, 
\end{align}
by using the Markov property. 

For the case where $\{X_t\}_{t \in [0,t^\dag]}$ is a binomial process (cf. Section~\ref{sec:homogeneous_binomial_process}) and
for $n,n' \in \Z$,
the conditional probabilities read 
\begin{equation}\label{eq:binomial_jump}
\P[X_t=n'|X_s=n]=
\binom{t-s}{\frac{n'-n+t-s}{2}}
r^{\frac{n'-n+t-s}{2}}(1-r)^{\frac{n'-n-t+s}{2}}.
\end{equation}
By inserting Eq.~\eqref{eq:binomial_jump} into Eq.~\eqref{eq:conditioned_average}, one obtains
\begin{align*}
    \E\left[Z_{t}|X_{t^{\dag}},X_0\right] =\binom{{t^{\dag}}}{\frac{X_{t^{\dag}}+t}{2}}^{-1} \sum_{n=0}^t f(n)\binom{{t^{\dag}}-t}{\frac{X_{t^{\dag}}-n+t}{2}}\binom{t}{\frac{n+t}{2}}.
\end{align*}
We can use the above formula for the case $Z_t=X_t$ and $Z_t=X_t^2$, thus yielding the first two moments
\begin{align*}
    \E\left[X_{t}|X_{t^{\dag}},X_0=0\right] =\frac{t}{{t^{\dag}}}X_{t^{\dag}}
\end{align*}
and
\begin{align*}
    \E\left[X_{t}^2|X_{t^{\dag}},X_0=0\right] = & (X_{t^{\dag}}+{t^{\dag}})t\frac{(X_{t^{\dag}}+{t^{\dag}})(t-1)-2t+2{t^{\dag}}}{{t^{\dag}}({t^{\dag}}-1)}
    +2t^2-\frac{t^2(X_{t^{\dag}}+{t^{\dag}})}{{t^{\dag}}}.
\end{align*}
\end{document}

