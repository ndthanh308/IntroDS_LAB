% Muestra como se hace el control de temperatura en una cpu comercial. Dentro se referencian los métodos para control activo y pasivo.
@Article{electronics8121423,
AUTHOR = {Peluso, Valentino and Rizzo, Roberto Giorgio and Calimera, Andrea},
TITLE = {Performance Profiling of Embedded ConvNets under Thermal-Aware DVFS},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {1423},
URL = {https://www.mdpi.com/2079-9292/8/12/1423},
ISSN = {2079-9292},
ABSTRACT = {Convolutional Neural Networks (ConvNets) can be shrunk to fit embedded CPUs adopted on mobile end-nodes, like smartphones or drones. The deployment onto such devices encompasses several algorithmic level optimizations, e.g., topology restructuring, pruning, and quantization, that reduce the complexity of the network, ensuring less resource usage and hence higher speed. Several studies revealed remarkable performance, paving the way towards real-time inference on low power cores. However, continuous execution at maximum speed is quite unrealistic due to a fast increase of the on-chip temperature. Indeed, proper thermal management is paramount to guarantee silicon reliability and a safe user experience. Power management schemes, like voltage lowering and frequency scaling, are common knobs to control the thermal stability. Obviously, this implies a performance degradation, often not considered during the training and optimization stages. The objective of this work is to present the performance assessment of embedded ConvNets under thermal management. Our study covers the behavior of two control policies, namely reactive and proactive, implemented through the Dynamic Voltage-Frequency Scaling (DVFS) mechanism available on commercial embedded CPUs. As benchmarks, we used four state-of-the-art ConvNets for computer vision flashed into the ARM Cortex-A15 CPU. With the collected results, we aim to show the existing temperature-performance trade-off and give a more realistic analysis of the maximum performance achievable. Moreover, we empirically demonstrate the strict relationship between the on-chip thermal behavior and the hyper-parameters of the ConvNet, revealing optimization margins for a thermal-aware design of neural network layers.},
DOI = {10.3390/electronics8121423}
}

%RL para control termico pero fuera del ambito espacial
@article{gao2019energy,
  title={Energy-efficient thermal comfort control in smart buildings via deep reinforcement learning},
  author={Gao, Guanyu and Li, Jie and Wen, Yonggang},
  journal={arXiv preprint arXiv:1901.04693},
  year={2019}
}


% Utiliza RL para ajustar de manera adaptativa los parámetros de un control térmico PID (proportional–integral–derivative)
@article{xiong2020intelligent,
  title={Intelligent thermal control strategy based on reinforcement learning for space telescope},
  author={Xiong, Yan and Guo, Liang and Huang, Yong and Chen, Liheng},
  journal={Journal of Thermophysics and Heat Transfer},
  volume={34},
  number={1},
  pages={37--44},
  year={2020},
  publisher={American Institute of Aeronautics and Astronautics},
  abstract={In this study, a thermal model of a space telescope is established in Simulink. An intelligent autonomous thermal control strategy based on actor-critic reinforcement learning (RL) for proportional–integral–derivative (PID) parameter adaptive self-tuning, called RL PID, is proposed. This control strategy enables the PID thermal controller to adaptively tune the PID parameters to achieve stable and precise temperature control. A single radial basis function (RBF) neural network is applied to simultaneously approximate the strategy function of the actor and the value function of the critic. The actor maps the system state to PID parameters, and the critic evaluates the output of the actor and generates a temporal difference (TD) error. Based on the architecture of the actor-critic RL algorithm and the TD error performance index, a design flow chart of RL PID is made. Both theoretical and experimental results show that RL PID can achieve a temperature control precision of 0.01°C, and that the steady-state error is reduced by 50 and 75\% in the simulation and 50 and 67\% in the experiment compared with those of the traditional PID controller and the traditional switch controller, respectively. RL PID has better reliability, more robustness, and a faster response.}
}

%PPO
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

%SAC
@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}
%Optimizaciones a PPO
@article{booth2019ppo,
  title={PPO dash: Improving generalization in deep reinforcement learning},
  author={Booth, Joe},
  journal={arXiv preprint arXiv:1907.06704},
  year={2019}
}

% Artículo ESA sobre control termico
@article{parolis1996current,
  title={Current and future techniques for spacecraft thermal control},
  author={Parolis, DM and Pinter-Krainer, W},
  journal={ESA Bulletin},
  number={87},
  year={1996}
}

% Articulo de la nasa sobre control termico en smallsats
@article{nasa,
  title={State-of-the-art small spacecraft technology},
  author={Yost, Bruce and Weston, Sasha and Benavides, Gabriel and Krage, Frederic and Hines, John and Mauro, Stephanie and Etchey, Selasi and O’Neill, Kiara and Braun, Barbra},
  year={2021}
}

%--------------------------------------Fuzzy control systems--------------------------------------------

% Fuzzy system for controlling Thermoelectric modules on spacecrafts
@inproceedings{wang2021research,
  title={Research on Intelligent Temperature Control Technology for Spacecraft with Instantaneous High Power Load},
  author={Wang, Jin and Gong, Mengmeng and Zhu, Shanglong and Zhang, Qun and Chen, Yi and Li, Defu and Deng, Wan and Qi, Feng},
  booktitle={Journal of Physics: Conference Series},
  volume={1871},
  number={1},
  pages={012052},
  year={2021},
  organization={IOP Publishing}
}

%  Fuzzy control system for controlling a loop heat pipe and a variable emittance radiator in spacecrafts
@article{dong2012fuzzy,
  title={Fuzzy incremental control algorithm of loop heat pipe cooling system for spacecraft applications},
  author={Dong, Su-Jun and Li, Yun-Ze and Wang, Jin and Wang, Jun},
  journal={Computers \& Mathematics with Applications},
  volume={64},
  number={5},
  pages={877--886},
  year={2012},
  publisher={Elsevier}
}

% Fuzzy control system for controlling a MEMS (Micro Electro Mechanical Systems)-based thermal system
@INPROCEEDINGS{5365072,
  author={Jia, Liu and Yunze, Li and Yuying, Wang and Jun, Wang},
  booktitle={2009 Ninth International Conference on Intelligent Systems Design and Applications}, 
  title={Agent-Oriented Intelligent Control Strategies for the Nano-satellite Autonomous Thermal System}, 
  year={2009},
  volume={},
  number={},
  pages={708-713},
  doi={10.1109/ISDA.2009.139}}

%--------------------------------------------------------------------------------------------------------


%--------------------------------------------------------------------------------------------------------------------------------------------
% NO USADOS...

% Articulo ESA sobre inteligencia en las cargas útiles. Se utiliza para otras cosas pero sirve para decir que no hay suficiente inteligencia abordo.
@article{mateo2022orbit,
  title={In-orbit demonstration of a re-trainable Machine Learning Payload for processing optical imagery},
  author={Mateo-Garc{\'\i}a, Gonzalo and Veitch-Michaelis, Josh and Purcell, Cormac and Longepe, Nicolas and Mathieu, Pierre Philippe and Reid, Simon and Anlind, Alice and Bruhn, Fredrik and Parr, James},
  year={2022}
}

% Utiliza RL para ajustar de manera adaptativa los parámetros de un control térmico PID (proportional–integral–derivative)
@article{lawrence2022deep,
  title={Deep reinforcement learning with shallow controllers: An experimental application to PID tuning},
  author={Lawrence, Nathan P and Forbes, Michael G and Loewen, Philip D and McClement, Daniel G and Backstr{\"o}m, Johan U and Gopaluni, R Bhushan},
  journal={Control Engineering Practice},
  volume={121},
  pages={105046},
  year={2022},
  publisher={Elsevier}
}

% Utiliza RL para ajustar de manera adaptativa los parámetros de un control térmico PID (proportional–integral–derivative). Del mismo autor e igual a xiong2020intelligent
@article{xiong,
author = {Xiong, Yan and Guo, Liang and Wang, Hongliang and Huang, Yong and Liu, Chunlong},
year = {2020},
month = {03},
pages = {},
title = {Intelligent Thermal Control Algorithm Based on Deep Deterministic Policy Gradient for Spacecraft},
journal = {Journal of Thermophysics and Heat Transfer},
doi = {10.2514/1.T5951},
abstract={In practical applications, the control parameters of a proportional integral derivative (PID) thermal controller are difficult to self-tuning online. As the control object or environment changes, the control parameters are required to change accordingly. An intelligent thermal controller based on the deep deterministic policy gradient, called DRLTC, is proposed. Two types of reinforcement learning agents were designed in DRLTC, which can automatically adjust the control parameters of the thermal controllers and self-optimize online after training. Both theoretical and experimental results revealed that, when the control object was the main mirror support, the DRLTC achieved a control precision of 0.01 °C. Additionally, the steady-state error was reduced by 40.2\%, 62.5\%, and 33.3\% in the simulation, and by 5.6\%, 80.6\%, and 85.7\% in the experiment, compared with the reinforcement learning PID, neural network PID, and Fuzzy PID, respectively. When the control object was changed to the main mirror installation, the DRLTC achieved a control precision of 0.02 °C, and the steady-state error was reduced by 87.5\%, 91.7\%, and 90.9\% in the simulation, and by 80.2\%, 90.6\%, and 85.7\% in the experiment, compared with the above-mentioned thermal control strategies, respectively. Therefore, the DRLTC has better universality, stronger robustness, and achieve more energy saving.}
}

%% Software
@misc{rl-zoo3,
  author = {Raffin, Antonin},
  title = {RL Baselines3 Zoo},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/rl-baselines3-zoo}},
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}
@inproceedings{optuna2019,
    title={Optuna: A Next-generation Hyperparameter Optimization Framework},
    author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
    booktitle={Proceedings of the 25th {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
    year={2019}
}
@ARTICLE{noauthor_2019-lb,
  title     = "Pid controller for thermal control in satellites",
  abstract  = "The paper gives the application of PID controller in satellite
               launching; it gives out the different technique which involves
               PID controller. It involves the temperature control (thermistor)
               in heater which is situated in the satellite. PID controller is
               implemented with the use of programmable logic controller. Using
               Ordinary control techniques, it is very difficult for
               controlling temperature; hence the purpose of proposed research
               is implementing PID controller design using programmable logic
               controller (PLC) in order to control the temperature and
               maintain the output in such a way that there is zero error
               between process variable and set point/desired output by closed
               loop operations in the satellite by avoiding the manual
               monitoring system. A thorough analysis using various PID
               parameters is presented in terms of system response. Performance
               of the controller is examined in terms of duty cycle, average
               current and power dissipation. Finally, a comparative analysis
               of PID controller for thermal control in satellite is presented",
  journal   = "ijrte",
  publisher = "Blue Eyes Intelligence Engineering and Sciences Engineering and
               Sciences Publication - BEIESP",
  volume    =  8,
  number    = "2S3",
  pages     = "1068--1071",
  month     =  aug,
  year      =  2019,
  author    = {Rama, Murthy and Sudharshan, Banakar and Pragnyatatti and  Mushahira and Gousiya, Banu},
  language  = "en"
}

@misc{gymnasium,
        title = {Gymnasium},
        url = {https://zenodo.org/record/8127025},
        abstract = {An API standard for single-agent reinforcement learning environments, with popular reference environments and related utilities (formerly Gym)},
        urldate = {2023-07-08},
        publisher = {Zenodo},
        author = {Towers, Mark and Terry, Jordan K. and Kwiatkowski, Ariel and Balis, John U. and Cola, Gianluca de and Deleu, Tristan and Goulão, Manuel and Kallinteris, Andreas and KG, Arjun and Krimmel, Markus and Perez-Vicente, Rodrigo and Pierré, Andrea and Schulhoff, Sander and Tai, Jun Jet and Shen, Andrew Tan Jin and Younis, Omar G.},
        month = mar,
        year = {2023},
        doi = {10.5281/zenodo.8127026},
}