\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\usepackage{array}
    \newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\usepackage{tabularray}
% updated with editorial comments 8/9/2021

\begin{document}

\title{EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction}

\author{Mohammadali Sefidi Esfahani, and Mohammad Akbari 

\thanks{M. Sefidi Esfahani and M. Akbari are with the Department of Mathematics and Computer Science, Amirkabir University of Technology, Tehran, Iran.
E-mail: mohammadali.esfahani@aut.ac.ir, akbari.ma@aut.ac.ir}}


\markboth{Iranian Journal of Science, VOL. X, NO. Y, DECEMBER 2024}%
{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}




\maketitle

\begin{abstract}
Social platforms have emerged as crucial platforms for disseminating information and discussing real-life social events, offering researchers an excellent opportunity to design and implement novel event detection frameworks. However, most existing approaches only exploit keyword burstiness or network structures to detect unspecified events. Thus, they often need help identifying unknown events regarding the challenging nature of events and social data. Social data, e.g., tweets, is characterized by misspellings, incompleteness, word sense ambiguation, irregular language, and variation in aspects of opinions. Moreover, extracting discriminative features and patterns for evolving events by exploiting the limited structural knowledge is almost infeasible. To address these challenges, in this paper, we propose a novel framework, namely EnrichEvent, that leverages the linguistic and contextual representations of streaming social data. In particular, we leverage contextual and linguistic knowledge to detect semantically related tweets and enhance the effectiveness of the event detection approaches. Eventually, our proposed framework produces cluster chains for each event to show the evolving variation of the event through time. We conducted extensive experiments to evaluate our framework, validating its high performance and effectiveness in detecting and distinguishing unspecified social events.
\end{abstract}

\begin{IEEEkeywords}
Unspecified Event Detection, Dynamic Event Detection, Computational Social Science, Social Networks, Twitter
\end{IEEEkeywords}

\section{Introduction}
\IEEEPARstart{S}{ocial} media platforms have become integral to our daily routines for communicating with friends, sharing information, exchanging ideas, and acquiring knowledge~\cite{Chen2013EmergingTD}. There is massive participation from people worldwide in social media. Social network statisticians expect the number of active social media users worldwide to increase from 2.86 billion in 2017 to 4.41 billion in 2025~\cite {SocialMedia_Statistics}. As a result, social media has emerged as a crucial platform for discussing and disseminating information about significant events. When a social incident occurs, experts and ordinary users engage in discussions on social media platforms (e.g., Twitter discussions on the Notre Dame Cathedral fire) from various perspectives~\cite{Aldhaheri_2017, Sun_Xiang_Wu_2015}. The active presence of users on social media has transformed it into a primary source for identifying, analyzing, and investigating events, providing real-time updates on critical incidents. The abundance of live data on social platforms offers an excellent opportunity for early detection of newsworthy events before conventional broadcast media channels cover them. Therefore, academia and industry have demonstrated significant interest in developing platforms that can discover social events and understand real-time discussions happening on social media.

Traditionally, an \emph{event} is defined as an important happening in a specific time and place~\cite{allan1998topic}. With the emergence of social media, this definition expands to a happening in society that attracts a sudden burst of attention in social media, and similar to the previous explanation, it occurs in a specific time and place~\cite{boettcher2012eventradar}. Intuitively, when an event occurs, quick and accurate event identification is one of the most crucial concerns for the government, aid agencies, related organizations, and even for journalists and experts~\cite{Governments, huang2021similarity}. For instance, when a natural disaster occurs, relief organizations consider event detection as one of the ways to capture different types of information, such as the severity of the incident, the number of victims, and how to provide aid for them during natural disasters. These related organizations are keen on being informed of an event as soon as possible to take appropriate actions regarding the event~\cite{nugent2017comparison,pekar2020early,sreenivasulu2020comparative}. Besides, awareness of event occurrence is vital for other purposes such as marketing, commercial, and even financial markets~\cite{Mohan, Shah}. For instance, leading retail brands always want to discover what is happening all over the market, and this awareness, accompanying the right decisions, puts them on the path to being ahead of their rivals.

Despite its value and significance, quick and accurate identification of unspecified social events has yet to be fully investigated due to the following challenges. 1)~\textbf{Streaming and Evolutionary}. Social media services provide a streaming source of information in which people freely create content around real-world events. While working on streaming sources, processing the incoming data in a single stage is a challenging and opening problem. In addition, turning a simple happening into a hot event, which everyone will be talking about, is a complex and evolutionary phenomenon comprised of three major steps. \textbf{a)} An event happens in the real world. \textbf{b)} Observers, journalists, and ordinary people start a discussion about the occurred event on social platforms. \textbf{c)} The event turns into a hot event for a while or fades out at the beginning~\cite{Chen2013EmergingTD}. How to model the evolving characteristics of an event is an arduous task. 2) \textbf{Variation in Language Expressions and Aspects of Opinions}. Twitter users produce and consume information in a very informal and irregular way, and the published tweets usually include idioms, abbreviations, misspellings, irregular language, and emojis. Due to the huge and diverse user base, Twitter usually contains different words and word sequences describing the same idea. Also, in most languages, many words have various meanings in different contexts. For example, the word "fair" in a different context has multiple meanings, such as "carnival," "treating someone right," and "having light skin/hair." This issue makes it hard for machine learning models to understand users' purpose. Besides, while talking about an event, users may have different opinions and express them differently. Detecting and aggregating various opinions and aspects of events is another challenge.

Retrospective studies in social media and event detection have proposed practical approaches for identifying events from social data by leveraging content and network structure. For instance, frequent keyword extraction has been used to detect bursty keywords corresponding to an event, and hashtags have been leveraged to capture semantics from tweets to address the short context problem~\cite{Keyword_Volume_Approach, Yang2018AnED}. Similarly, clustering methods have been employed for mitigating short and sparse contexts in social posts~\cite{akbari2017leveraging}. Further, modular decomposition and community detection have been exploited to utilize links and network structures. While much work has been devoted to event detection, more research has yet to tackle the problem of unspecified event detection and its evolution. In this paper, we design an end-to-end framework, namely \textbf{EnrichEvent}, to address the challenges mentioned in the previous paragraph. We define an event as a single chain of clusters where each cluster contains closely related entities both in time and semantic dimensions. In addition, we leverage contextual knowledge and structural aspects of the tweets to enrich their representation and achieve better results. Exploiting contextual knowledge assists the model in comprehending the existing relation among tweets and generating a higher-quality representation. We conducted several experiments to evaluate all the components of our proposed framework. The empirical results validate that EnrichEvent achieves better than various baselines based on the evaluation metrics. In summary, our main contributions are as follows:
\begin{itemize}
    \item We design a novel framework, EnrichEvent, that is robust to variation in language expressions and aspects of opinions and considers the temporal variation of context around a given event to model the evolutionary process of events occurring sufficiently.
    \item We propose a generative approach for event summarization, an innovation since most recent research utilized extractive approaches.
    \item  We provide two real-world datasets for training the trend detection model and performing experiments to evaluate our proposed event detection framework. The result empirically demonstrates the effectiveness of EnrichEvent. Moreover, researchers can exploit these datasets in topic modeling, sentiment analysis, etc.
\end{itemize}

% Figure environment removed

\section{Related Works}
Event detection from Twitter has received noticeable attention in recent years, as it introduced TwitterAPI, and researchers can easily collect real-time data~\cite{Survey_2016, ED_SWE}. We can divide the problem of social event detection into three sub-categories. Identification of \textbf{unspecified events}, \textbf{predetermined events}, and \textbf{sub-events}~\cite{atefeh2015survey}. Our work belongs to the first category, and in this section, we investigate these three sub-categories and explain some related works that have motivated us to work in this field.

\subsection{Identification of unspecified events}
While working on this category, there needs to be an antecedent description of the events, and researchers aim to detect general events. Researchers typically investigate different aspects of the tweets in this category to discover their existing relations. As mentioned in the previous section, processing streaming data is a challenging task, and \textbf{Comito et al.}~\cite{Bursty_Event_Detection} tried to design an event detection framework that is robust to processing issues. Moreover, they exploited the existing semantics in the tweets by working on the 2-grams of words, hashtags, and mentioned users. Eventually, they identified the events by grouping the related tweets using the incremental clustering approach. The main idea of~\textbf{Yang et al.}~\cite{Yang2018AnED} is to cluster similar hashtags together, and clusters of hashtags represent occurring events. They focused on the occurrence of hashtags in tweets and considered hashtags as a bag of words and hashtags. Eventually, they used the concatenation of hashtag-hashtag and hashtag-words co-occurrence vectors as a final feature vector for clustering. The main challenge of this work is that users may not necessarily use hashtags in all tweets. Besides, hashtags used in tweets are not necessarily relevant to their content. ~\textbf{Fedoryszak et al.}~\cite{RealTime_EventDetection_Twitter} considers happening events as chains of clusters. They built a real-time system to identify groups of event-related entities. Then, they linked these clusters together and generated cluster chains that represent the events. Note that this paper only focused on the lexical representation of named entities and used occurrence vectors to cluster them.

\subsection{Identification of predetermined events}
In the second category, researchers usually leverage datasets such as Event2012~\cite{Event2012} and Event2018~\cite{Event2018}, which contain predefined events in different event classes. Two critical challenges exist in this category, providing researchers with opportunities to design novel frameworks. \textbf{1) Scalability}, most of the recent papers converted the message blocks to message graphs in their ways to model the dependencies between the tweets. Moreover, they leveraged the GNN models to generate the embedding of the tweets~\cite{Knowledge_Preserving, peng2021streaming, peng2022reinforced}. Although utilizing message graphs and GNN models enhances the messages' embedding, they reduce the scalability of the frameworks. \textbf{2) Usability}, the proposed frameworks should be trained on labeled datasets, which makes their use in real-world problems challenging.~\textbf{Ren et al.}~\cite{Qsgnn} investigated this challenge and designed a framework, namely QS-GNN. While training the proposed model, it only required the labeled messages in the first time frame. Although they have minimized the model's dependence on labeled data, leveraging these frameworks for real-world problems is still challenging.

\subsection{Identification of sub-events}
In this category, researchers consider a specific event, e.g., a football match, and aim to identify the relevant sub-events. Designing a decent approach to find the correlations between the tweets and a given event is the main challenge of this category. ~\textbf{Bekoulis et al.}~\cite{bekoulis-sub} investigated the temporal aspects of the tweets and proposed a two-stage framework that detects the sub-events by analyzing their evolution over time. Moreover, ~\textbf{Lu et al.}~\cite{lu2021hashtag} focused on semantics to generate a better representation of tweets. In addition, they used hashtags and their n-grams to capture the correlations suitably. Though much research has been done in this category, researchers can enhance the existing frameworks differently.

\section{Problem Statement}
In this section, we present the notation and then formally define the problem of emergent event detection from social media data.

\noindent \textbf{Definition 2.1.} Social stream $\mathcal{S}=\{\mathcal{M}_1, \ldots, \mathcal{M}_{i-1}, \mathcal{M}_i, \ldots\}$ defined as a consecutive sequence of message blocks. We denote message block $\mathcal{M}_i$ as $\mathcal{M}_i=\{m_j | 1 \le j \le |\mathcal{M}_i| \}$, where $|\mathcal{M}_i|$ is total numbers of the tweets in time period $[t_i, t_{i_1})$ and $m_j$ denotes a single tweet.

\noindent\textbf{Definition 2.2.} We can group all the tweets in message block $\mathcal{M}_i$ to finite set of clusters $\mathcal{C}_i=\{c_j | 1 \le j \le |\mathcal{C}_i| \}$, where messages in each cluster are contextually related.

\noindent\textbf{Definition 2.3.} $e=\{c_{ij} | 1 \le i \le |\mathcal{M}_i| , 1 \le j \le |\mathcal{C}_i| \}$ is a social \emph{event} and formally defined as a continuous sequence of contextually related clusters where all the clusters refer to a single event. Note that we assume each social message belongs to, at most, one event.

\noindent\textbf{Objective:} Given a social stream of message blocks $\mathcal{S}$, we aim to design and implement a framework $F$ as follows where each $E$ is a set of unknown social events.

\begin{equation}
    \centering
    F: \mathcal{S} \rightarrow E=\{e_1, e_2, \ldots\}
\end{equation}

\section{Methodology}
In this section, we present various components of our proposed framework. The main advantage of the proposed framework is the capability to process streaming social data and extract candidate social events in a near online setting. In addition, our framework is language-independent and can be easily adjusted to different languages. In summary, EnrichEvent gets the message blocks as inputs and finally stores the detected events with their attributes in the database. Here, we first go through the different components of the EnrichEvent. Afterward, we define their roles and functionality and then delve into the details of each unit. Figure 1 provides an overview of the architecture of EnrichEvent.

\subsection{Framework}
Since events start at a specific time point and can extend over multiple time windows, in this paper, we focus on the need for an end-to-end pipeline that can handle the streaming nature of social media data by processing incoming data and detecting unspecified events. Our proposed framework, i.e., \textbf{EnrichEvent}, comprises seven components: \textbf{Trending Data Extraction}, \textbf{Contextual Knowledge Enhancement}, \textbf{Event Clustering}, \textbf{Event Chain Formation}, \textbf{Event Summarization}, \textbf{Storage}, and \textbf{Evaluation}. First, Trending Data Extraction identifies newsworthy tweets that potentially refer to an occurring event. The message block is then sent to Contextual Knowledge Enhancement to extract and enrich contextual knowledge, which assists the clustering model in comprehending the existing patterns among the tweets. Inspired by previous studies ~\cite{RealTime_EventDetection_Twitter, Bursty_Event_Detection}, Event Clustering groups the semantically related entities into groups. Then, Event Chain Formation links the clusters in consecutive time steps and generates evolving chains of clusters that present the occurring events. In the following stage, all the identified events are summarized using a generative approach. Eventually, the framework generates a JSON file as the output and stores it in the database. In addition, it evaluates the results at the final stage.

\subsection{Trending Data Extraction}
Social media data is often known as a noisy and sparse information source, and $40\%$ of tweets refer to \emph{pointless babble}. Thus, it is crucial to filter out irrelevant data and extract tweets corresponding to the events~\cite{SEDTW}. In other words, we had to appropriately filter out noisy data and gather valuable and informative ones. To do so, we proposed filtering general tweets and accumulating those with a high probability of referring to an event. Here, we leverage a supervised learning model to mark tweets potentially referring to the events. Intuitively, our model examines the tweets to determine whether they refer to an important event. We achieved this through a two-segment architecture. In the first segment, a combination of embedding, convolution, and max pooling layers extract efficient features from the input tweet. In the second segment, we exploited fully connected layers to classify whether the incoming tweet refers to an important event. In summary, the proposed model gets a tweet as input and returns the probability of referring to an event, which helps us to filter the tweets based on the minimum threshold $\lambda$.

\textbf{Trend detection dataset}: To train the trend detection model, we started preparing an offline trend detection dataset using TwitterAPI. We have collected 1.6 million Persian tweets in different categories and tried to label them manually based on key phrases. The generated dataset has informative columns such as \textit{timestamp}, \textit{tweet id}, \textit{text}, \textit{username}, \textit{reply count}, \textit{like count}, and \textit{retweet count}. Eventually, we utilized it to train the trend detection model. We have provided more details about the trend detection dataset in Appendix A.

Inspired by retrospective studies~\cite{Chen2013EmergingTD}, we adopt a supervised learning approach and train a model $\mathcal{T}$ that identifies tweets with a high probability of referring to an event. Given a message block, we converted the existing tweets to sequences of numbers and considered them as the inputs of trend detection models. Additionally, We should extract a prominent and discriminative representation from the tweets to train an effective model using the pre-trained language models. Therefore, we used Parsbert's pre-trained model~\cite{ParsBERT} to obtain the tweets' representation. While training the model, we use this representation in the embedding layer to understand the context better. Note that we did not fine-tune the Bert model, and the parameters of the embedding layer were not trainable. This model gains extracted features from tweets as input vectors, i.e., $X$, and computes the probability of containing general information or a simple status update, i.e., negative class, or referring to a potential event, i.e., positive class. Formally, the prediction of model $\mathcal{T}$ is performed by solving the following optimization problem:

\begin{equation}
    \centering
    \arg \min_\mathbf{W} \mathcal{L}(\mathbf{X}, \mathbf{W}, \mathbf{Y}),
\end{equation}

Where $\mathcal{L}(.)$ is the loss function and often is defined as binary cross entropy. $\mathbf{W}$ denotes all parameters that the model learns from the training set, and $\mathbf{Y}$ indicates the label of the tweets where one is used for tweets referring to an event, otherwise zero. 

\subsection{Contextual Knowledge Enhancement}

Working on lexical and structural aspects of tweets is a conventional way to design event detection models. However, training a well-performing model is arduous because of the tweets' challenging characteristics, i.e., variation in language expressions and aspects of opinions. When users debate about an occurring event on social platforms, they discuss different aspects and have diverse opinions. Therefore, we have to consider various contexts where users post tweets and aim to generate a high-quality representation for them.

In this work, we considered entities within a tweet as its representative and concentrated on two main types of entities: \textbf{Named Entities} and \textbf{Hashtags}. Named entities are critical indicators for detecting events since an event happens at a specific time and location and includes various actors. As such, named entities demonstrate one of these attributes about an event. Hashtags, on the other hand, were intrinsically incorporated into social posts to reveal the correlation of the tweets to an event or a topic, making them invaluable indicators of tweets related to an event. For instance, the following text from our dataset contains both named entities and hashtags. The named entities indicate that the attributes of the event are \textbf{Silicon Valley}, \textbf{USA}, and \textbf{2008}. In addition, \textbf{\#bankruptcy} demonstrates that the event corresponds to bankruptcy.

\begin{itemize}
    \item \textbf{Silicon Valley} Bank of the \textbf{United States} collapsed! The largest bank \textbf{\#bankruptcy} in the \textbf{USA} since the crisis of \textbf{2008} !!!
\end{itemize}

In this stage, We use Bert's pre-trained NER model to extract all the existing named entities from all the tweets in the message blocks, i.e., $\mathcal{M}_i$. Afterward, we add all the posted hashtags to the extracted named entities. Assume that message block $\mathcal{M}_i$ contains $|\mathcal{M}_i|$ tweets, and there exist $k$ unique entities within them. Then, For all the extracted entities in message block $\mathcal{M}_i$, we follow a three-step procedure: 

\noindent\textbf{(1)} To cover lexical aspects of the tweets, we consider entity $k$ as a bag of tweets, which is an aggregation of all the tweets containing entity $k$. Then, we construct the occurrence matrix in which the element $e_{ij}$ shows the frequency of entity $k_i$ in tweet $t_j$. Therefore, the dimension of the obtained occurrence matrix is $k \times |\mathcal{M}_i|$. 

\noindent\textbf{(2)} Sentence embedding is a type of sentence representation that allows sentences with similar meanings to have a close representation. This idea helps us to consider the context in which the extracted entities appeared. To calculate the embedding vector for a given entity, e.g., entity \(k_i\), we choose a combination of top retweeted and random tweets in which entity \(k_i\) appears. We defined a hyper-parameter $\beta$ to control the number of selections. Furthermore, we select $\frac{\beta}{2}$ of tweets from the top retweeted tweets and the rest randomly from the other tweets in which name entity \(k_i\) appears. Then, we concatenate the selected tweets and exploit ParsBert pre-trained models~\cite{ParsBERT} to calculate the embedding vector. At last, we repeat this procedure for all the entities and construct an embedding matrix in which row \(i^{th}\) is the contextual representation of \(i^{th}\) entity.

\noindent\textbf{(3)} By generating the mentioned matrices, we simultaneously cover lexical and contextual aspects of the tweets. In the next step, we convert occurrence and embedding matrices to entity-to-entity distance matrices separately using the cosine distance function. So far, we have generated two distance matrices representing the cosine distance of entities from each other. Afterward, we aggregate these distance matrices using a weighted average. While averaging the distance matrices, we consider $\alpha$ and $1 - \alpha$ as a weight of embedding and occurrence matrix, respectively. Eventually, we use the generated entity-to-entity distance matrix as input for the Event Clustering component.

\subsection{Event Clustering}
Since entities are representative of the tweets, at this stage, we have to cluster entities based on the obtained distance matrix in the previous module. Within this component, we can use a wide range of clustering algorithms such as distance-based clustering algorithms, e.g., K-Means, probability-based clustering algorithms, e.g., GMM, and density-based ones, e.g., DBSCAN and HDBSCAN~\cite{HDBSCAN}. Since we are working on streaming data, and the number of clusters may vary in each message block, algorithms that do not need to specify the number of clusters are the best option. Given an entity-to-entity distance matrix, we leverage HDBSCAN for this component to cluster entities so that related entities come together in the same cluster. So far, we have clustered the entities within each message block. In the next stage, we have to link these clusters. 

\subsection{Event Chain Formation}
Since events occur in an evolutionary process, we cannot identify the unspecified events statically, and we have to track the evolution of events over message blocks. Let $\mathcal{C}_i= \{c_1, c_2, \ldots, c_t\}$ and $\mathcal{C}_{i-1}=\{c_1, c_2, \ldots, c_t\}$ denote produced clusters in $\mathcal{M}_i$ and $\mathcal{M}_{i-1}$ respectively. In this step, we start building a bipartite graph using $\mathcal{C}_i$ and $\mathcal{C}_{i-1}$. We consider clusters as nodes of the graph, and we add $edge_{tk}$ between them if the number of common entities among $c_k$ and $c_k$ was more than a minimum threshold $\delta$. Note that the weight corresponding to \(edge_{tk}\) is the number of common entities among $c_k$ and $c_k$. Then, we leverage the \textbf{Hungarian algorithm}~\cite{kuhn1955hungarian} to link produced clusters in message block $\mathcal{M}_i$ to produced clusters in message block $\mathcal{M}_{i-1}$ iteratively for $i=\{2, 3, \ldots, |\mathcal{S}_i|\}$ where $|\mathcal{S}_i|$ denote the total number of message blocks. In short, the events appeared by connecting the produced clusters over continuous message blocks and generating the cluster chains. Note that a single chain represents an occurring event.

\subsection{Event Summarization}
In this stage, we try to generate summaries of the detected events by adapting the \textbf{OpinionDigest}~\cite{opiniondigest} framework to the task of event summarization. To do so, we design a 3-step procedure. \textbf{(1)} Assume $t$ is a random tweet, and we could extract key phrases from tweet $t$ by considering a context window with a constant length of $\gamma$ around the appeared entities. \textbf{(2)} In this stage, we require an NLG model that takes a set of key phrases as input and produces a fluent summary as output. Because we do not access the gold-standard summaries for training, we attempt to fine-tune a language model that encodes the extracted key phrases of a single tweet and then try to reconstruct the tweet from them. To do so, we build a synthetic dataset by mapping the existing tweets in our event detection dataset to their corresponding key phrases, similar to the first step. Furthermore, we fine-tune the GPT-2 language model on the synthetic dataset. Now, we can utilize the fine-tuned model to generate event summaries. \textbf{(3)} Suppose that we want to generate a summary for event $e$, and $T=\{t_1, t_2, \ldots, t_n\}$ is set of corresponding tweets to event $e$. First, we map all the tweets to their corresponding key phrases. Then, we leverage the DBSCAN model to cluster the key phrases using their BERT representation. In each cluster, we select the closest key phrase to the center of the clusters. Eventually, we utilize the fine-tuned GPT-2 model to generate the summary of event $e$ using the selected key phrases.

\subsection{Storage and Evaluation}
After generating the summaries, we store the details of the identified events as JSON files in the database. While saving the results, we extract informative information about the events, such as event ID, event period, event summary, details of corresponding entities/hashtags/usernames to each event, and tweets with the highest like/reply/retweet count. Concisely, our proposed framework gets the message blocks as input and returns an informative JSON file for each detected event. In the final stage, we evaluate the performance of our proposed framework from various aspects. We discuss the results and evaluation details in the following section.

\section{Experiments and Evaluation Pipeline}
% In this section, we present an evaluation pipeline that appraises different aspects of the proposed method. After running the pipeline, we evaluate the system's performance from the following aspects.
In this section, we conduct extensive experiments to answer the following research questions:
\textbf{(1)} How is the overall performance of our framework compared with the baselines?
\textbf{(2)} How does the Contextual Knowledge Enhancement component affect the clusters' quality?
\textbf{(3)} How is the overall performance of the Trending Data Extraction component, and how does it help us to achieve better results?

\subsection{Experimental Setup}
\subsubsection{Dataset}
Similar to the trend detection dataset, we have prepared a dataset to evaluate the overall performance of EnrichEvent on Twitter streaming data using TwitterAPI. We considered a two-week time window and crawled the posted Persian tweets from 2023/2/28 to 2023/3/14. We collected almost 760000 tweets in this period and divided them into daily message blocks. Since we had to label the entities manually, we sampled 500 tweets in each message block. We selected the tweets based on the words' frequency to preserve the actual distribution of tweets. In other words, if a tweet contains frequent words, the probability of choosing it will be higher. We provided more details about the event detection dataset in Appendix A.

\subsubsection{Baselines}
We compare our proposed framework to both base algorithms and related works. (1) \textbf{Word2vec}~\cite{word2vec}, which considers averages of the word2vec embedding of words as their representation. While implementing this baseline, we only utilized the word2vec embedding in the Contextual Knowledge Enhancement component and did not use lexical knowledge. (2) \textbf{Bert}~\cite{BERT}, which generates a 768-d embedding vector for the sampled sentences in which the entity occurs as its representative. Like Word2vec, we used this representation in the Contextual Knowledge Enhancement component to measure its impact on the final results. (3)~\textbf{Yang et al.}~\cite{Yang2018AnED}, which considered hashtags as their main entity and used the concatenation of hashtag-hashtags and hashtag-words co-occurrence vectors as their final feature. (4)~\textbf{Fedoryszak et al.}~\cite{RealTime_EventDetection_Twitter}, which builds an entity graph using the similarity matrix obtained from the co-occurrence vectors. Eventually, they identified the events by applying Louvain community detection to the graph and building cluster chains. Note that we have implemented all the baselines in the same setting.

\subsubsection{Evaluation Metrics}

We have evaluated the performance of our proposed framework by two metrics presented in Fedoryszak et al.~\cite{RealTime_EventDetection_Twitter}. By measuring these metrics, we can figure out how well the events are detected and separated from each other. Suppose that our framework detected event $e$ in a set of consecutive time windows $T_e$, and we want to measure the quality of the corresponding cluster chain. \textit{Consolidation(e)} and \textit{Discrimination(e)} defined as follows. Note that if the metric's higher value indicates better results, we use $\big\uparrow$ next to their names; if the lower value demonstrates better results, we use $\big\downarrow$.

\noindent(1) \textbf{Consolidation$\big\uparrow$}: We consider entity pair $(k_1, k_2)$ related if both of them are labeled as relevant entities to event $e$. Let $\mathcal{U}_t$ denote the total number of entity pairs and $\mathcal{A}_t$ indicate the number of related entity pairs that are part of the system output at time window $t$ respectively. Intuitively, the Consolidation metric calculates the average ratio of related entity pairs in cluster chains and is defined as:
\begin{equation}
    \centering
    \mathcal{C}(e) = \frac{1}{|T_e|}\sum_{t \in T_e}\frac{\mathcal{A}_t}{\mathcal{U}_t}
\end{equation}
\noindent(2) \textbf{Discrimination$\big\downarrow$}: We consider entity pair $(k_1, k_2)$ unrelated if only one of them is labeled irrelevant to event $e$. Let $B_t$ denote the number of unrelated entity pairs that are part of the system output at timestamp $t$. The Discrimination is defined as follows and measures the average ratio of unrelated entity pairs in cluster chains:
\begin{equation}
    \centering
    \mathcal{D}(e) = \frac{1}{|T_e|}\sum_{t \in T_e}\frac{\mathcal{B}_t}{\mathcal{U}_t}
\end{equation}

\subsubsection{Implementation Details}
We have implemented our proposed framework, EnrichEvent, using a machine equipped with a Tesla T4 GPU. The replication package for the EnrichEvent framework is publicly available on Github~\cite{replication2023EnrichEvent}, and you can use it to reproduce the results. Details of the hyper-parameters are shown in Table~\ref{tab:hyper}. 

\begin{table}
\begin{center}
{\caption{Details of the hyper-parameters}\label{tab:hyper}}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|P{2.2cm}|P{6.3cm}|P{0.6cm}|}
\hline
\rule{0pt}{8pt}
\textbf{Hyper-parameter}    & \textbf{Description} &  \textbf{Value}  \\
\hline
\rule{0pt}{9pt}
        $\sigma$        & Minimum threshold for the probability of referring to an event in the Trend Detection component            &   $0.3$     \\
\hline
\rule{0pt}{9pt}
        $\alpha$        & Weight of the entity-to-entity distance matrix obtained from the Embedding matrix          &   $0.5$     \\
\hline
\rule{0pt}{9pt}
        $\beta$         & Total number of selected tweets for generating the embedding vectors for entities       &   $4$    \\
\hline
\rule{0pt}{9pt}
        $\gamma$        & length of the content window for extracting key phrases in the Event Summarization component         &   $2$   \\

\hline
\rule{0pt}{9pt}
       $\delta$        & Minimum number of common entities to add an edge among clusters in the Event Chain Formation component    &   $3$   \\ 
\hline
\end{tabular}}
\end{center}
\vspace{-10pt}
\end{table}

\subsection{Manual Evaluation}
We evaluated EnrichEvent's overall performance and the selected baselines on Twitter streaming message blocks and presented the results in Table~\ref{tab:result}. To calculate the evaluation metrics, we manually labeled the entities. Note that Consolidation and Discrimination are calculated for a single event, and the average results obtained from all the detected events are presented as the final result.

\begin{table}[!h]
\begin{center}
{\caption{Manual evaluation on streaming social data}\label{tab:result}}
% \resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|c|}

\hline
\rule{0pt}{12pt}
\textbf{Method} & \textbf{Consolidation$\big\uparrow$} &\textbf{Discrimination$\big\downarrow$}
\\
\hline
\rule{0pt}{9pt}
Word2vec& 63.46\% & 28.94\% \\
\hline
\rule{0pt}{9pt}
BERT& 67.01\%& 15.97\% \\
\hline
\rule{0pt}{9pt}
Yang et al.~\cite{Yang2018AnED}& 38.42\%& 37.64\% \\
\hline
\rule{0pt}{9pt}
Fedoryszak et al.~\cite{RealTime_EventDetection_Twitter}& 65.20\%& 25.90\% \\
\hline
\rule{0pt}{9pt}
\textbf{EnrichEvent}& \textbf{87.41\%} & \textbf{10.00\%} \\
\hline
% \rule{0pt}{9pt}
% \textbf{Improvement}& 20.30\%$\big\uparrow$& 5.97\%$\big\downarrow$ \\
% \hline
\end{tabular}
\end{center}
\vspace{-10pt}
\end{table}

\noindent \textbf{Discussion}: As shown in Table~\ref{tab:result}, the results indicate that our proposed framework outperforms all the baselines. We should mention some key findings from the results are as follows:
\textbf{(1)} In section 4.3, we claimed that if we leverage the contextual and lexical knowledge simultaneously, it will empower the event detection frameworks. The obtained results validate the superiority of our proposed framework compared to other baselines. \textbf{(2)} Results of \textbf{Yang et al.} reveals that hashtags are not good representatives of tweets. They do not transfer considerable knowledge for event detection since users do not usually use hashtags while posting tweets. \textbf{(3)} Comparing the results of \textbf{Fedoryszak et al.} and \textbf{BERT} demonstrate that exploiting the contextual knowledge reduces the discrimination metric surprisingly by 10\%, but it does not affect the value of the Consolidation individually. \textbf{(4)} Comparing the results of \textbf{BERT} and \textbf{EnrichEvent} reveals that utilizing contextual knowledge along with the lexical aspects increases the ratio of related entity pairs in cluster chains by 20.30\% and is the key to achieving the best results.

\subsection{Clusters' Quality}
In section $4.3$, we claim that the Contextual Knowledge Enhancement component assists the HDBSCAN model in detecting related entities and grouping them. To prove our claim, we perform the following experiments:

\noindent(1) \textbf{Fraction of Relevant entities$\big\uparrow$}: During the construction of cluster chains and event identification, the attending clusters in the chains must include Relevant entities to the events. To investigate the effect of the Contextual Knowledge Enhancement component, we calculate the ratio of Relevant entities in clusters when using contextual knowledge compared with other baselines. 

% Figure environment removed

As shown in Figure 2, EnrichEvent yields the highest fraction of related entities compared to the baselines. That is because it fully uses contextual and lexical representations of the tweets. Compared to Fedoryszak et al., which only utilized co-occurrence vectors of named entites as their representation, we achieve \textbf{13.98\%} promotion in the fraction of related entities. It conveys that EnrichEvent achieved a good comprehension of the events and clusters them properly. To validate the quality of clusters, we also investigated the clustering metrics which measure the quality of clusters in different perspective.

\noindent(2) \textbf{Silhouette Score$\big\uparrow$}: The silhouette score measures the similarity of points inside their cluster compared to the others~\cite{Silhouette}. Inspection of Figure 3 demonstrates that using the lexical representation leads to more similar clusters in the first two windows, but exploiting the contextual knowledge has made its impact in the following windows, and the quality of clusters increased.

% Figure environment removed

\noindent(3) \textbf{Calinski-Harabasz Index$\big\uparrow$}: Also known as the Variance Ratio Criterion, it measures the sum of between-cluster dispersion against the sum of within-cluster dispersion, where dispersion is the sum of distance squared~\cite{CalinskiHarabasz}. Comparing the value of the Calinski-Harabasz index over consecutive time frames in Figure 4 signifies that the clusters are far away from the others and have a higher quality when we utilize the Contextual Knowledge Enhancement component.

% Figure environment removed

\noindent(4) \textbf{Davies-Bouldin Index$\big\downarrow$}: This index signifies the average similarity between clusters, where the similarity is a measure that compares the distance between clusters with the size of the clusters themselves~\cite{DaviesBouldin}. Figure 5 verifies that our framework, i.e., the Contextual Knowledge component, utilizes the knowledge that enhances the quality of the produced clusters.
% Figure environment removed

\subsection{Evaluation of Trending Data Extraction}
Trend detection is one of the main components of our framework that filters incoming tweets based on the probability of referring to an event. We appraise this component in 2 phases.

\noindent \textbf{(1) Efficiency}: There is immense participation from people worldwide in social media, and they invariably produce streaming social data. Scalability is one of the vital characteristics of an event detection framework. Otherwise, the proposed framework would not be practical. To investigate the effectiveness of the Trending Data Extraction component, we turn it off and calculate pipeline runtime. Compared to the previous experiments, switching off this component leads to an over 50\% increase in runtime, which is a considerable amount. In addition, the trend detection module can be used to customize the event detection process. More specifically, we can exploit the domain-specific trend detection models to identify the events in the specific domains. For instance, if we only want to detect sports-related events,  we can easily adjust the trend detection module and leverage a model trained to identify the tweets in which the user referred to an essential event in sports. 

\noindent \textbf{(2) Efficacy}: To evaluate the performance of the trend detection model, we measure commonly used classification metrics, e.g., Precision, Recall, and F1-Score. We demonstrate the results of the trend detection model in Table~\ref{tab:trend} and draw some key findings as follows:
\begin{itemize}
    \item Our implemented model is robust in detecting the tweets that do not refer to the occurring events based on its descent performance on tweets with label 0.
    \item Regarding the tweets that referred to the events, it is crucial that the model achieves high Recall and acceptable Precision simultaneously. We emphasize the Recall metric since we want to filter tweets with great confidence, and we prefer to see all tweets with label one as much as possible. Although learning discriminative patterns is strenuous in imbalanced data, the results demonstrate that the trend detection model meets our expectations.
\end{itemize}

\begin{table}[!h]
\begin{center}
{\caption{Performance of trend detection model}\label{tab:trend}}
% \resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|c|c|c|}
\hline
\rule{0pt}{12pt}
&\textbf{Precision} &\textbf{Recall} & \textbf{F1-Score} & \textbf{Support}
\\
\hline
\rule{0pt}{9pt}
\textbf{Label 0}& 0.97& 0.90& 0.93 & 312254\\
\textbf{Label 1}& 0.53& 0.78& 0.63 & 45307\\
\hline
\rule{0pt}{9pt}
\textbf{Macro Average}& 0.75& 0.84& 0.78 & 357561 \\
\textbf{Weighted Average}& 0.91 & 0.89& 0.89 & 357561 \\
\hline
\end{tabular}
\end{center}
\vspace{-15pt}
\end{table}

\section{Conclusion}
Event detection on social media platforms is an active research area, and identification of unspecified events can provide beneficial awareness for making crucial decisions in different fields. In this paper, we design a novel event detection framework to identify unspecified events from social media data streams. Our proposed language-independent framework can easily be adjusted for different data types like news, Wikipedia, etc. In this work, we utilize combinations of lexical and contextual knowledge of tweets. Contextual knowledge enriches the model's perspective and helps the model understand the relationships between tweets more sufficiently. We empirically demonstrate the superiority of our framework in detecting and distinguishing social events compared to the baselines through conducted experiments. An intriguing future research direction would be leveraging LLMs for event summarization and enhancing the process of generating event chains.

{\appendix[EnrichEvent Output]
\noindent After detecting the events, the EnrichEvent framework returns a JSON file for each event as an output, including detailed information about the detected events, which is listed in Table~\ref{tab:output}. This information contains the summary of each event, the period in which each event occurred, and detailed data about the hashtags, users, and named entities that referred to each event. 

\begin{table}[!h]
\begin{center}
{\caption{A summary of the existing information about the events in EnrichEvent's Output.}\label{tab:output}}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|P{3.35cm}|P{5.8cm}|}
\hline
\rule{0pt}{8pt}
\textbf{Key} & \textbf{Description} \\ \hline
\rule{0pt}{9pt}
Event ID & A unique identifier assigned to the event. \\ \hline
\rule{0pt}{9pt}
Event Period & The period during which the event occurs. \\ \hline
\rule{0pt}{9pt}
Event Summary & A brief description of the event. \\ \hline
\rule{0pt}{9pt}
Tweet with Most Likes & The tweet that received the highest number of likes. \\ \hline
\rule{0pt}{9pt}
Tweet with Most Retweets & The tweet that was retweeted the most. \\ \hline
\rule{0pt}{9pt}
Tweet with Most Replies & The tweet with the highest number of replies. \\ \hline
\rule{0pt}{9pt}
Count Unique Hashtags & The total number of distinct hashtags used. \\ \hline
\rule{0pt}{9pt}
Count Total Hashtags & The aggregate number of all hashtags used. \\ \hline
\rule{0pt}{9pt}
Most Frequent Hashtags & The hashtags that appear most frequently in the event. \\ \hline
\rule{0pt}{9pt}
Count Unique Users & The total count of distinct users involved in the event. \\ \hline
\rule{0pt}{9pt}
Most Frequent Users & The users who posted the most tweets. \\ \hline
\rule{0pt}{9pt}
Count Unique Entities & The total count of distinct entities mentioned in the event. \\ \hline
\rule{0pt}{9pt}
Count Total Entities & The aggregate count of all entities mentioned. \\ \hline
\rule{0pt}{9pt}
\rule{0pt}{9pt}
Most Frequent Entities & The entities mentioned most frequently in the event. \\ \hline
\rule{0pt}{9pt}
Word Cloud & A visual representation of the most common words related to the event. \\ \hline
\end{tabular}}
\end{center}
\vspace{-10pt}
\end{table}

}

{\appendix[Datasets Details]
\noindent\textbf{Labeling of Trend Detection Dataset}: To prepare a generalized trend detection dataset, we defined 12 categories for tweets' topics. Furthermore, we explored various accounts and collected all the tweets posted by experts and active users in each category using TwitterAPI. We leveraged domain-specific key phrases to label the collected tweets in each category. Specifically, we defined a collection of key phrases for each category and checked their occurrence within the tweets to label the dataset. We consider labeling one for the tweets even if one of the key phrases appears in them.

\begin{table}[!h]
\begin{center}
{\caption{Proposed categories for tweets' topics. We aimed to collect adequate tweets in each category and train our proposed trend detection model in various fields.}}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\rule{0pt}{9pt}
Sports    & Technology &  Art & Industry & Celebrities    & Video Games\\
\hline
\rule{0pt}{9pt}
Crypto & Politics & Health & Environment &  Economic & Social  \\
\hline
\end{tabular}}
\end{center}
\end{table}

\noindent\textbf{Event Detection Dataset}: In contrast to the Trend Detection Dataset, we did not consider any user specification for the Event Detection Dataset, and we only limited the language of the tweets to Persian.
}

%{\appendices
%\section*{Proof of the First Zonklar Equation}
%Appendix one text goes here.
% You can choose not to have a title for an appendix if you want by leaving the argument blank
%\section*{Proof of the Second Zonklar Equation}
%Appendix two text goes here.}

\bibliography{IEEE-Transactions-LaTeX2e-templates-and-instructions/EnrichEvent_ref}
\bibliographystyle{IEEEtran}

\end{document}


