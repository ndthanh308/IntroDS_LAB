\section{Methodology \& Contributions}\label{sec:contribution}
\subsection{Position Bias Models}\label{sec:background}
For ease of terminology but without loss of generality, assume we want to maximise the \emph{quality} ($Q$) of items that are viewed ($V$) by a user in a certain \emph{context} ($X$).
\footnote{Note that in classical web-search use-cases, \emph{view} events $V$ are unobserved, as multiple items are presented to the user simultaneously~\cite{Joachims2005}.
This is different from our use-case, where items impressed to the user take up most of their mobile screen, and we can extract labels $V$ from scrolling behaviour.}
As is typical, the true \emph{quality} is not an observable quantity, but we can estimate it from logged user interactions.
We will refer to these as \emph{clicks} ($C$) that occur when a post is both viewed and deemed quality, but they can represent more general engagement (e.g. \emph{likes}).
A ranking policy $\pi$ is in place, deciding at which \emph{rank} ($R$) a given post will appear, dependent on  the context $X$ and a quality estimate $\widehat{Q}$.
We can describe the relation between the unobservable quality $Q$ and the observable quantities $C$, $V$ and $R$ as follows (omitting item $i$):
\begin{equation}
    \mathsf{P}(Q|X) = \frac{\mathsf{P}(C|R,X)}{\mathsf{P}(V|R,X,\pi)}.
\end{equation}
This is a well-known result, showing how we can obtain unbiased estimates of quality conditional on context, by reweighting observed clicks with exposure or viewing probabilities (i.e. \emph{inverse propensity scoring}, or IPS~\cite[Ch. 9]{Owen2013}).
In this work, we do not focus on \emph{selection bias}, i.e. bias stemming from the ranking policy $\pi$ influencing the rankings~\cite{Ovasisi2020,Oosterhuis2020}.
Instead, we wish to estimate the \emph{causal effect} of rank on exposure, conditional on context.

Without considering contextual information, \citeauthor{Joachims2017} originally proposed to perform randomised interventions on the rank of a given item to obtain such estimates~\cite{Joachims2017}.
Further extensions proposed to leverage historical interventions stemming from natural experiments~\cite{Agarwal2019}, and this was further extended to be context-dependent~\cite{Fang2019}.
Whichever of these methods is adopted, we essentially obtain data from the interventional distribution describing $\mathsf{P}(V|{\rm do}(R=r), X)$, with the ${\rm do}$-operator following \citeauthor{Pearl2009}'s seminal work~\cite{Pearl2009}.
These interventions remove the dependency of empirical views on the deployed ranking policy $\pi$, and thus:
\begin{equation}
    \mathsf{P}(Q|X) = \frac{\mathsf{P}(C|{\rm do}(R),X)}{\mathsf{P}(V|{\rm do}(R),X)}.
\end{equation}
We visualise this interventional procedure with the Probabilistic Graphical Model (PGM) shown in Figure~\ref{fig:PGM} --- this causal view is often left implicit in related work.
The main benefit from this derivation is that it allows us to obtain an unbiased estimate of item quality from observable quantities alone, but downstream applications of accurate exposure probabilities are threefold:
\begin{enumerate*}
    \item ranking policies can be evaluated more reliably with \emph{offline} estimators of \emph{online} metrics that depend on exposure~\cite{Joachims2017},
    \item ranking policies can be learnt to maximise better objectives by replacing the observed labels $C$ with estimates of quality (essentially \emph{de-biasing} them)~\cite{Oosterhuis2020}, and
    \item fairness metrics related to ``\emph{equity of exposure}'' among content creators, for example, can be estimated and optimised more reliably~\cite{Diaz2020,Jeunen2021B}.
\end{enumerate*}


% Figure environment removed

Note that (1) is essentially what the DCG metric aims to do, by discounting the ``\emph{gain}'' at every rank (independent of context).
The standard inverse-logarithmic discount function for DCG is commonly adopted ($\mathsf{P}_{\rm dcg}$ in Eq.~\ref{eq:dcg}), and forms the basis for ranking evaluation in the wider IR and recommendation field.
Nevertheless, if the exposure probabilities implied by this discount function are inaccurate, DCG fails to be an unbiased estimator of online gains.
If this is the case, we can consider other parametric discount functions, with several forms.
In line with DCG, it is natural to consider an inverse logarithmically shaped function (indicating diminishing position bias effects at lower ranks), or an exponential decay function (in line with the user model adopted by RBP~\cite{Moffat2008}).
These families of functions will be the baselines for our experiments, parameterised by $\alpha \in \mathbb{R}^{+}_{0}$ and $\gamma \in [0,1]$ respectively: \footnote{We interpret them as probabilities, but these discounts were not originally motivated by sound probabilistic models of user behaviour (bar RBP~\cite{Moffat2008}).}
\begin{equation}\label{eq:dcg}
\mathsf{P}_{\rm dcg}(V=1|R=r) = \frac{1}{\log_{2}(r+1)},\qquad\quad
\mathsf{P}_{\log}(V=1|R=r) = \frac{1}{\ln(e+\alpha (r-1))}, \qquad\quad
\mathsf{P}_{\exp}(V=1|R=r) = \gamma^{r-1}.
\end{equation}
In the context of web search applications, regression- and deep neural network (DNN)-based position bias models have been proposed as well~\cite{Wang2018PB,Ai2018}.
Whilst effective, there are practical drawbacks to implementing such methods in real-world applications:
\begin{enumerate*}
    \item it is computationally intensive to obtain $\mathsf{P}(V|R)$ from a forward pass in a neural network,
    \item it requires significant engineering effort to make such models accessible when performing e.g. offline evaluation or exposure fairness analyses,
    \item DNNs do not guarantee robust estimates in low-data regimes and fail to encode desirable properties such as monotonicity of $\mathsf{P}(V|R)$ w.r.t. $R$, and
    \item the black-box nature of these models does not allow us to obtain an improved understanding of \emph{how} users interact with the rankings they are presented with.
\end{enumerate*}
For these reasons, we place simple models at the focal point of our work, with a minimal amount of learnable parameters.

Finally, note that all of the aforementioned models are \emph{independent} of contextual information $X$.
\citeauthor{Fang2019} propose a DNN-based model whose output reflects $\mathsf{P}(V|R,X)$ instead; adopting a classical Multi-Layer Perceptron (MLP) architecture while conjecturing that architectural improvements could improve results~\cite{Fang2019}.
Naturally, their method suffers from the same drawbacks as non-contextual deep models.
\citeauthor{Wu2021} leverage Gradient-Boosted Decision Trees for an e-commerce feed recommendation application, with similar concerns for practical implementations~\cite{Wu2021}.
We can address some of these shortcomings by viewing position bias through a probabilistic lens, as it provides a theoretically sound basis to reason about exposure, allowing for more sample- and parameter-efficient learning.

Next to the Position-Based Model, alternative models of user behaviour have been proposed in the web search literature~\cite{Zhang2020}.
Such methods require us to model the probability that a user continues down a ranked list, conditional on the items viewed so far.
As this significantly increases modelling complexity, it is out of scope for this short article.

\subsection{Probabilistic Position Bias Models}
The intuitive logarithmic discount originally proposed by \citeauthor{Jarvelin2002} has been widely adopted in the research literature~\cite{Jarvelin2002}, along with the exponential form that motivates RBP~\cite{Moffat2008}, or cascade-based alternatives~\cite{Craswell2008,Chapelle2009DBN}.
Model-based approaches~\cite{Wang2018PB,Ai2018,Wu2021,Fang2019} hold promise to move beyond mere intuition, but their implementation has several practical drawbacks that hinder widespread adoption. 
We adopt the Contextual Position-Based Model (CPBM) proposed by \citeauthor{Fang2019}~\cite{Fang2019}, but aim to tackle the position bias estimation problem through a probabilistic lens.

We introduce an additional random variable $D$, referring to ``\emph{scroll depth}''.
In our hierarchical use-case, users scroll through ranked posts on the 1\textsuperscript{st}-level feed until they decide to either enter a 2\textsuperscript{nd}-level feed via an item of their liking, or decide to abandon the feed altogether.
A large majority of sessions sees users entering a 2\textsuperscript{nd}-level feed via a highly ranked post, fewer sessions lead to 2\textsuperscript{nd}-level feeds at lower ranks, and a small minority sees users abandoning the feed after scrolling further.
As such, our discrete \emph{scroll depth} random variable follows a power-law distribution, such as the Yule-Simon distribution visualised in Figure~\ref{fig:yulesimon}(a)~\cite{Yule1925,Simon1955}.
This distribution includes a shape parameter $\rho \in \mathbb{R}^{+}_{0}$.
When ${\rm B}(\cdot,\cdot)$ represents the Beta function, its Probability Mass Function (PMF) at depth $D=d$ is given by:
\begin{equation}
    \mathsf{P}_{{\rm Yule-Simon}(\rho)}(D=d) = \rho {\rm B} (d, \rho+1).
\end{equation}
Having defined a distribution for scroll depth, we can define the relationship between scroll depth and position bias.
Indeed, a post ranked at position $R=r$ will be viewed if and only if the user decides to scroll at least up until that rank.
This implies a negative relationship with the Cumulative Distribution Function (CDF) of $D$:
\begin{equation}
    \mathsf{P}(V=1|R=r) = \mathsf{P}(D \geq r) = 1 - \mathsf{P}(D < r).
\end{equation}
That is, the position bias at rank $r$ can be derived from the survival function of the scroll depth distribution.
For the Yule-Simon($\rho$)-distribution, this quantity is given by:
\begin{equation}
\mathsf{P}_{{\rm prob}}(V=1|R=r) =
\begin{cases}
      1 & \text{if}~r=1,\\
      (r-1) {\rm B} (r-1, \rho+1) & \text{otherwise.}
\end{cases} \label{eq:prob}
\end{equation}
This derivation gives rise to a probabilistic position bias model that is theoretically sound, and motivated by a plausible model of user behaviour, specifically tailored to the use-case of feed recommendations.
Note that we adopt the Yule-Simon distribution largely for illustratory purposes in this Section, but that our analysis remains general.
As such, we could adopt more involved probability distributions for scroll depth to reflect position bias curves that would be unrealisable by Yule-Simon.
A promising alternative here is the generalised Waring distribution, as it can reflect a wider set of position bias curves~\cite[\S 6.2.3]{johnson2005univariate}.
As this probability distribution is defined by multiple parameters, it is out-of-scope for the purposes of this short article.
Even though the probabilistic position bias model proposed so far is neither contextual nor personalised, we expect the position bias curves emanating from Eq.~\ref{eq:prob} to be more aligned with empirical biases in feed recommendation scenarios than those produced by the classical approximations in Eq.~\ref{eq:dcg}.

We visualise the position bias curves that emanate from our proposed model in Figure~\ref{fig:yulesimon}(b), contrasting them with those arising from classical approximations.
Indeed, whilst we observe that $\mathsf{P}_{\rm dcg}$ does not discount aggressively enough, both $\mathsf{P}_{\rm log}$ and $\mathsf{P}_{\rm exp}$ cannot accurately represent similar position bias curves as our probabilistically inspired method.

\subsubsection{Connections to Mean Reciprocal Rank (MRR)~\cite{Voorhees1999}}
A commonly used offline evaluation metric in the web search domain is MRR, which averages the reciprocal rank of the first relevant document in every ranking.
When assuming binary relevance labels and a single relevant item per ranking, this metric is equivalent to DCG where the discount corresponds to the reciprocal rank: $\mathsf{P}_{\rm rr}(V=1|R=r) = \frac{1}{r}$.
Recent work in the e-commerce recommendation domain highlights how this discount function aligns much more closely with the empirical position bias on their platform, and reports improved alignment between offline and online evaluation metrics~\cite{Mei2022}.
There is an intricate connection between the reciprocal rank discount and our proposed method, when we consider the Yule-Simon distribution with parameter $\rho=1$.
To see this, recall that the Beta function can be written in terms of Gamma functions as ${\rm B}(x,y) = \frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}$, and $\Gamma(x)=(x-1)!$ for positive integers $x$.
Then, consider for $r>1$:
\begin{equation}
\mathsf{P}_{\rm prob}(V=1|R=r) = (r-1) {\rm B}(r-1, 2) =  (r-1) \frac{\Gamma(r-1)\Gamma(2)}{\Gamma(r-1+2)} = (r-1) \frac{\Gamma(r-1)}{\Gamma(r+1)} = \frac{(r-1)}{(r-1)r} = \frac{1}{r} = \mathsf{P}_{\rm rr}(V=1|R=r). \qed
\end{equation}
As such, the specific discount function that gives rise to MRR can be seen as a special case of our proposed method, when we adopt the Yule-Simon distribution with parameter $\rho=1$.
This is reassuring, given MRR's strong track record in IR research and its recent successes~\cite{Mei2022}.
Our probabilistic model for scroll depth gives rise to a theoretically sound motivation for MRR.
Furthermore, the flexibility of our framework allows us to adopt alternative probability distributions with varying parameterisations, giving rise to a rich family of position bias curves, as shown in Figure~\ref{fig:yulesimon}(b).

Existing work has connected RR-based metrics to \emph{cascade} user models in web search use-cases with graded relevance labels~\cite{Chapelle2009}.
Their derivation still holds when replacing $\mathsf{P}_{\rm rr}$ with the more general and parameterisable $\mathsf{P}_{\rm prob}$~\cite[Def. 1]{Chapelle2009}.

% Figure environment removed

\subsubsection{Contextual, Personalised, Probabilistic Position Bias Models: \texttt{C-3PO}}\label{sec:learning}
We wish to incorporate contextual information encoded in $X$, to obtain a \emph{conditional} probability distribution for the scroll depth: $\mathsf{P}(D|X)$.
To this end, we aim to learn a function that maps $X$ to the parameters that define $D$'s distribution.
In the case of Yule-Simon, this means we wish to learn a parameterised function $\rho_{\theta}(X)$ s.t. the implied conditional probability distribution for the position bias model maximises the likelihood of observed data $\mathcal{D}$:
\begin{equation}
        \prod_{(v,r,x) \in \mathcal{D}} \mathsf{P}(V=v|R=r,X=x).
\end{equation}
As is common, we minimise negative log-likelihood (NLL) instead:
\begin{equation}\label{eq:NLL}
        \ell\left(\widehat{\mathsf{P}}; \mathcal{D}\right) =  - \frac{1}{|\mathcal{D}|}\sum_{(v,r,x) \in \mathcal{D}} \log\left(\widehat{\mathsf{P}}(V=v|R=r,X=x)\right),
\end{equation}
where $\widehat{\mathsf{P}}$ denotes the estimated position bias model.
For the Yule-Simon distribution, we plug in the position bias formula from Eq.~\ref{eq:prob} with the learnt function $\rho_{\theta}(x)$ to obtain:
\begin{equation}
    \widehat{\mathsf{P}}_{\rm prob}(V=1|R=r,X=x) = 
\begin{cases}
      1 & \text{if}~r=1,\\
      (r-1) {\rm B} (r-1, \rho_{\theta}(x)+1) & \text{otherwise.}
\end{cases}
\end{equation}
Using standard gradient descent techniques, we can now aim to learn the optimal parameters $\theta$ for $\rho_{\theta}(x)$ that minimise the NLL in Eq.~\ref{eq:NLL}.
Note that we can introduce rank-based weights or cut-offs to, for example, up-weight higher positions in the list.
When the position bias model has limited capacity, this approach can help to optimise the accuracy of the model in typical top-$K$ scenarios.
Indeed, the lower exposure probabilities at the bottom of the rankings are easier to model, and this can drown out the importance of the higher positions.
We denote such cut-offs with NLL@$K$.

Finally, note that the optimisation procedure derived in this Subsection does not solely restrict itself to our probabilistically motivated position bias model.
Indeed, we can learn the parameters for the logarithmic and exponential forms in Eq.~\ref{eq:dcg} that minimise the NLL of the resulting distributions just as well, which we do in our experiments.
