\begin{thebibliography}{100}

\bibitem{EUdataregulations2018}
2018 reform of eu data protection rules.

\bibitem{noauthor_aberdeen_nodate}
Aberdeen {Facial} {Database}.

\bibitem{noauthor_gufd_nodate}
{GUFD} {Facial} {Database}.

\bibitem{noauthor_utrecht_nodate}
Utrecht {ECVP} {Facial} {Database}.

\bibitem{abiddin_development_2019}
{\sc Abiddin, W., Jailani, R., and Omar, A.}
\newblock Development of robot-human imitation program for telerehabilitation
  system.
\newblock In {\em Proceedings - {International} {Conference} on {Developments}
  in {eSystems} {Engineering}, {DeSE}\/} (2019), vol.~2018-September,
  pp.~198--201.
\newblock 1.

\bibitem{abidi_human_2013}
{\sc Abidi, S., Williams, M., and Johnston, B.}
\newblock Human pointing as a robot directive.
\newblock In {\em {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot}
  {Interaction}\/} (2013), pp.~67--68.
\newblock 25.

\bibitem{agarwal2009building}
{\sc Agarwal, S., Snavely, N., Simon, I., Seitz, S.~M., and Szeliski, R.}
\newblock Building rome in a day.
\newblock In {\em 2009 IEEE 12th International Conference on Computer Vision
  (ICCV)\/} (2009), IEEE Computer Society, pp.~72--79.

\bibitem{agrigoroaie_enrichme_2016}
{\sc Agrigoroaie, R., Ferland, F., and Tapus, A.}
\newblock The {ENRICHME} project: {Lessons} learnt from a first interaction
  with the elderly.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 9979
  LNAI\/} (2016), 735--745.
\newblock 12.

\bibitem{albanie2020bsl}
{\sc Albanie, S., Varol, G., Momeni, L., Afouras, T., Chung, J.~S., Fox, N.,
  and Zisserman, A.}
\newblock Bsl-1k: Scaling up co-articulated sign language recognition using
  mouthing cues.
\newblock In {\em European Conference on Computer Vision\/} (2020), Springer,
  pp.~35--53.

\bibitem{ali_improved_2015}
{\sc Ali, B., Ayaz, Y., Jamil, M., Gilani, S., and Muhammad, N.}
\newblock Improved method for stereo vision-based human detection for a mobile
  robot following a target person.
\newblock {\em South African Journal of Industrial Engineering 26}, 1 (2015),
  102--119.
\newblock 5.

\bibitem{ali_smart_2019}
{\sc Ali, S., Lam, A., Fukuda, H., Kobayashi, Y., and Kuno, Y.}
\newblock Smart {Wheelchair} {Maneuvering} {Among} {People}.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 11645
  LNAI\/} (2019), 32--42.
\newblock 3.

\bibitem{almonfrey_flexible_2018}
{\sc Almonfrey, D., do~Carmo, A., de~Queiroz, F., Picoreti, R., Vassallo, R.,
  and Salles, E.}
\newblock A flexible human detection service suitable for {Intelligent}
  {Spaces} based on a multi-camera network.
\newblock {\em International Journal of Distributed Sensor Networks 14}, 3
  (2018).
\newblock 7.

\bibitem{alonso-mora_human_2014}
{\sc Alonso-Mora, J., Siegwart, R., and Beardsley, P.}
\newblock Human - {Robot} swarm interaction for entertainment: {From} animation
  display to gesture based control.
\newblock In {\em {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot}
  {Interaction}\/} (2014), p.~98.
\newblock 12.

\bibitem{alvarez-santos_feature_2012}
{\sc Alvarez-Santos, V., Pardo, X., Iglesias, R., Canedo-Rodriguez, A., and
  Regueiro, C.}
\newblock Feature analysis for human recognition and discrimination:
  {Application} to a person-following behaviour in a mobile robot.
\newblock {\em Robotics and Autonomous Systems 60}, 8 (2012), 1021--1036.
\newblock 58.

\bibitem{angani_human_2020}
{\sc Angani, A., Lee, J.-W., Talluri, T., Lee, J.-y., and Shin, K.}
\newblock Human and robotic fish interaction controlled using hand gesture
  image processing.
\newblock {\em Sensors and Materials 32}, 10 (2020), 3479--3490.
\newblock 4.

\bibitem{angonese_multiple_2017}
{\sc Angonese, A., and Ferreira~Rosa, P.}
\newblock Multiple people detection and identification system integrated with a
  dynamic simultaneous localization and mapping system for an autonomous mobile
  robotic platform.
\newblock In {\em {ICMT} 2017 - 6th {International} {Conference} on {Military}
  {Technologies}\/} (2017), pp.~779--786.
\newblock 6.

\bibitem{rosa_integration_2016}
{\sc Angonese, A.~T., and Ferreira~Rosa, P.~F.}
\newblock Integration of {People} {Detection} and {Simultaneous} {Localization}
  and {Mapping} {Systems} for an {Autonomous} {Robotic} {Platform}.
\newblock In {\em 2016 {XIII} {Latin} {American} {Robotics} {Symposium} and
  {IV} {Brazilian} {Robotics} {Symposium} ({LARS}/{SBR})\/} (Oct. 2016),
  pp.~251--256.
\newblock 7.

\bibitem{anuradha_human_2020}
{\sc Anuradha, U., Kumari, K., and Chathuranga, K.}
\newblock Human detection and following robot.
\newblock {\em International Journal of Scientific and Technology Research 9},
  3 (2020), 6359--6363.
\newblock 0.

\bibitem{anzalone_multimodal_2013}
{\sc Anzalone, S., Ivaldi, S., Sigaud, O., and Chetouani, M.}
\newblock Multimodal people engagement with {iCub}.
\newblock {\em Advances in Intelligent Systems and Computing 196 AISC\/}
  (2013), 59--64.
\newblock 16.

\bibitem{araiza-lllan_dynamic_2018}
{\sc Araiza-Lllan, D., and De~San Bernabe~Clemente, A.}
\newblock Dynamic {Regions} to {Enhance} {Safety} in {Human}-{Robot}
  {Interactions}.
\newblock In {\em {IEEE} {International} {Conference} on {Emerging}
  {Technologies} and {Factory} {Automation}, {ETFA}\/} (2018),
  vol.~2018-September, pp.~693--698.
\newblock 1.

\bibitem{arenas_deep_2017}
{\sc Arenas, J., Beleno, R., and Moreno, R.}
\newblock Deep convolutional neural network for hand gesture recognition used
  for human-robot interaction.
\newblock {\em Journal of Engineering and Applied Sciences 12}, Specialissue11
  (2017), 9278--9285.
\newblock 1.

\bibitem{argall2010survey}
{\sc Argall, B.~D., and Billard, A.~G.}
\newblock A survey of tactile human--robot interactions.
\newblock {\em Robotics and autonomous systems 58}, 10 (2010), 1159--1176.

\bibitem{arnab2021vivit}
{\sc Arnab, A., Dehghani, M., Heigold, G., Sun, C., Lu{\v{c}}i{\'c}, M., and
  Schmid, C.}
\newblock Vivit: A video vision transformer.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision\/} (2021), pp.~6836--6846.

\bibitem{arras2007using}
{\sc Arras, K.~O., Mozos, O.~M., and Burgard, W.}
\newblock Using boosted features for the detection of people in 2d range data.
\newblock In {\em Proceedings 2007 IEEE International Conference on Robotics
  and Automation\/} (2007), IEEE, pp.~3402--3407.

\bibitem{arumbakkam_multi-modal_2010}
{\sc Arumbakkam, A., Yoshikawa, T., Dariush, B., and Fujimura, K.}
\newblock A multi-modal architecture for human robot communication.
\newblock In {\em 2010 10th {IEEE}-{RAS} {International} {Conference} on
  {Humanoid} {Robots}, {Humanoids} 2010\/} (2010), pp.~639--646.
\newblock 2.

\bibitem{augello_towards_2020}
{\sc Augello, A., Ciulla, A., Cuzzocrea, A., Gaglio, S., Pilato, G., and Vella,
  F.}
\newblock Towards an intelligent system for supporting gesture acquisition and
  reproduction in humanoid robots.
\newblock In {\em {DMSVIVA} 2020 - {Proceedings} of the 26th {International}
  {DMS} {Conference} on {Visualization} and {Visual} {Languages}\/} (2020),
  pp.~82--86.
\newblock 0.

\bibitem{avioz-sarig_robotic_2020}
{\sc Avioz-Sarig, O., Olatunji, S., Sarne-Fleischmann, V., and Edan, Y.}
\newblock Robotic {System} for {Physical} {Training} of {Older} {Adults}.
\newblock {\em International Journal of Social Robotics\/} (2020).
\newblock 0.

\bibitem{azari_commodifying_2019}
{\sc Azari, B., Lim, A., and Vaughan, R.}
\newblock Commodifying {Pointing} in {HRI}: {Simple} and {Fast} {Pointing}
  {Gesture} {Detection} from {RGB}-{D} {Images}.
\newblock In {\em 2019 16th {Conference} on {Computer} and {Robot} {Vision}
  ({CRV})\/} (May 2019), pp.~174--180.
\newblock 2.

\bibitem{bai_kinect-based_2018}
{\sc Bai, X., Li, C., Chen, K., Feng, Y., Yu, Z., and Xu, M.}
\newblock Kinect-based hand tracking for first-person-perspective robotic arm
  teleoperation.
\newblock In {\em 2018 {IEEE} {International} {Conference} on {Information} and
  {Automation}, {ICIA} 2018\/} (2018), pp.~684--691.
\newblock 0.

\bibitem{baron_remote_2013}
{\sc Baron, G., Czekalski, P., Malicki, D., and Tokarz, K.}
\newblock Remote control of the artificial arm model using {3D} hand tracking.
\newblock In {\em 2013 {International} {Symposium} on {Electrodynamic} and
  {Mechatronic} {Systems} ({SELM})\/} (May 2013), pp.~9--10.
\newblock 5.

\bibitem{doi:10.1177/1529100619832930}
{\sc Barrett, L.~F., Adolphs, R., Marsella, S., Martinez, A.~M., and Pollak,
  S.~D.}
\newblock Emotional expressions reconsidered: Challenges to inferring emotion
  from human facial movements.
\newblock {\em Psychological Science in the Public Interest 20}, 1 (2019),
  1--68.
\newblock PMID: 31313636.

\bibitem{barros_real-time_2014}
{\sc Barros, P., Parisi, G.~I., Jirak, D., and Wermter, S.}
\newblock Real-time gesture recognition using a humanoid robot with a deep
  neural architecture.
\newblock In {\em 2014 {IEEE}-{RAS} {International} {Conference} on {Humanoid}
  {Robots}\/} (Nov. 2014), pp.~646--651.
\newblock 41.

\bibitem{barz_evaluating_2017}
{\sc Barz, M., Poller, P., and Sonntag, D.}
\newblock Evaluating {Remote} and {Head}-{Worn} {Eye} {Trackers} in
  {Multi}-{Modal} {Speech}-{Based} {HRI}.
\newblock In {\em Proceedings of the {Companion} of the 2017 {ACM}/{IEEE}
  {International} {Conference} on {Human}-{Robot} {Interaction}\/} (New York,
  NY, USA, 2017), {HRI} '17, Association for Computing Machinery, pp.~79--80.
\newblock 6.

\bibitem{batista_probabilistic_2015}
{\sc Batista, N., and Pereira, G.}
\newblock A {Probabilistic} {Approach} for {Fusing} {People} {Detectors}.
\newblock {\em Journal of Control, Automation and Electrical Systems 26}, 6
  (2015), 616--629.
\newblock 6.

\bibitem{bauer2008human}
{\sc Bauer, A., Wollherr, D., and Buss, M.}
\newblock Human--robot collaboration: a survey.
\newblock {\em International Journal of Humanoid Robotics 5}, 01 (2008),
  47--66.

\bibitem{bay_speeded-up_2008}
{\sc Bay, H., Ess, A., Tuytelaars, T., and Van~Gool, L.}
\newblock Speeded-{Up} {Robust} {Features} ({SURF}).
\newblock {\em Comput. Vis. Image Underst. 110}, 3 (June 2008), 346--359.
\newblock 11620.

\bibitem{bayram_audio-visual_2016}
{\sc Bayram, B., and Ince, G.}
\newblock Audio-visual multi-person tracking for active robot perception.
\newblock In {\em 2015 {IEEE}/{SICE} {International} {Symposium} on {System}
  {Integration}, {SII} 2015\/} (2016), pp.~575--580.
\newblock 2.

\bibitem{bdiwi_handing-over_2013}
{\sc Bdiwi, M., Suchý, J., and Winkler, A.}
\newblock Handing-over model-free objects to human hand with the help of
  vision/force robot control.
\newblock In {\em 10th {International} {Multi}-{Conferences} on {Systems},
  {Signals} {Devices} 2013 ({SSD13})\/} (Mar. 2013), pp.~1--6.
\newblock 5.

\bibitem{beddiar2020vision}
{\sc Beddiar, D.~R., Nini, B., Sabokrou, M., and Hadid, A.}
\newblock Vision-based human activity recognition: a survey.
\newblock {\em Multimedia Tools and Applications 79}, 41 (2020), 30509--30555.

\bibitem{10.1007/s11042-020-09004-3}
{\sc Beddiar, D.~R., Nini, B., Sabokrou, M., and Hadid, A.}
\newblock Vision-based human activity recognition: A survey.
\newblock {\em Multimedia Tools Appl. 79}, 41–42 (nov 2020), 30509–30555.

\bibitem{beer2014toward}
{\sc Beer, J.~M., Fisk, A.~D., and Rogers, W.~A.}
\newblock Toward a framework for levels of robot autonomy in human-robot
  interaction.
\newblock {\em Journal of human-robot interaction 3}, 2 (2014), 74.

\bibitem{bellarbi_social_2017}
{\sc Bellarbi, A., Kahlouche, S., Achour, N., and Ouadah, N.}
\newblock A social planning and navigation for tour-guide robot in human
  environment.
\newblock In {\em Proceedings of 2016 8th {International} {Conference} on
  {Modelling}, {Identification} and {Control}, {ICMIC} 2016\/} (2017),
  pp.~622--627.
\newblock 7.

\bibitem{belo_facial_2019}
{\sc Belo, J. P.~R., Sanches, F.~P., and Romero, R. A.~F.}
\newblock Facial {Recognition} {Experiments} on a {Robotic} {System} {Using}
  {One}-{Shot} {Learning}.
\newblock In {\em 2019 {Latin} {American} {Robotics} {Symposium} ({LARS}), 2019
  {Brazilian} {Symposium} on {Robotics} ({SBR}) and 2019 {Workshop} on
  {Robotics} in {Education} ({WRE})\/} (Oct. 2019), pp.~67--73.
\newblock 0.

\bibitem{belpaeme2018social}
{\sc Belpaeme, T., Kennedy, J., Ramachandran, A., Scassellati, B., and Tanaka,
  F.}
\newblock Social robots for education: A review.
\newblock {\em Science robotics 3}, 21 (2018).

\bibitem{ben2016kinect}
{\sc Ben~Abdallah, I., Bouteraa, Y., and Rekik, C.}
\newblock Kinect-based sliding mode control for lynxmotion robotic arm.
\newblock {\em Advances in Human-Computer Interaction 2016\/} (2016).

\bibitem{benabdallah_kinect-based_2015}
{\sc Benabdallah, I., Bouteraa, Y., Boucetta, R., and Rekik, C.}
\newblock Kinect-based {Computed} {Torque} {Control} for lynxmotion robotic
  arm.
\newblock In {\em 2015 7th {International} {Conference} on {Modelling},
  {Identification} and {Control} ({ICMIC})\/} (Dec. 2015), pp.~1--6.
\newblock 14.

\bibitem{bertasius2021space}
{\sc Bertasius, G., Wang, H., and Torresani, L.}
\newblock Is space-time attention all you need for video understanding?
\newblock In {\em International Conference on Machine Learning\/} (2021), PMLR,
  pp.~813--824.

\bibitem{4415182}
{\sc Bethel, C.~L., Salomon, K., Murphy, R.~R., and Burke, J.~L.}
\newblock Survey of psychophysiology measurements applied to human-robot
  interaction.
\newblock In {\em RO-MAN 2007 - The 16th IEEE International Symposium on Robot
  and Human Interactive Communication\/} (2007), pp.~732--737.

\bibitem{beyer2018deep}
{\sc Beyer, L., Hermans, A., Linder, T., Arras, K.~O., and Leibe, B.}
\newblock Deep person detection in two-dimensional range data.
\newblock {\em IEEE Robotics and Automation Letters 3}, 3 (2018), 2726--2733.

\bibitem{bilac_gaze_2017}
{\sc Bilac, M., Chamoux, M., and Lim, A.}
\newblock Gaze and filled pause detection for smooth human-robot conversations.
\newblock In {\em {IEEE}-{RAS} {International} {Conference} on {Humanoid}
  {Robots}\/} (2017), pp.~297--304.
\newblock 2.

\bibitem{bilen2016dynamic}
{\sc Bilen, H., Fernando, B., Gavves, E., Vedaldi, A., and Gould, S.}
\newblock Dynamic image networks for action recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition\/} (2016), pp.~3034--3042.

\bibitem{bingol_practical_2020}
{\sc Bingol, M., and Aydogmus, O.}
\newblock Practical application of a safe human-robot interaction software.
\newblock {\em Industrial Robot 47}, 3 (2020), 359--368.
\newblock 2.

\bibitem{bolano_towards_2018}
{\sc Bolano, G., Tanev, A., Steffen, L., Roennau, A., and Dillmann, R.}
\newblock Towards a {Vision}-{Based} {Concept} for {Gesture} {Control} of a
  {Robot} {Providing} {Visual} {Feedback}.
\newblock In {\em 2018 {IEEE} {International} {Conference} on {Robotics} and
  {Biomimetics}, {ROBIO} 2018\/} (2018), pp.~386--392.
\newblock 2.

\bibitem{bonin2008visual}
{\sc Bonin-Font, F., Ortiz, A., and Oliver, G.}
\newblock Visual navigation for mobile robots: A survey.
\newblock {\em Journal of intelligent and robotic systems 53}, 3 (2008),
  263--296.

\bibitem{boser1992training}
{\sc Boser, B.~E., Guyon, I.~M., and Vapnik, V.~N.}
\newblock A training algorithm for optimal margin classifiers.
\newblock In {\em Proceedings of the fifth annual workshop on Computational
  learning theory\/} (1992), pp.~144--152.

\bibitem{bothe_effective_2018}
{\sc Bothe, K., Winkler, A., and Goldhahn, L.}
\newblock Effective {Use} of {Lightweight} {Robots} in {Human}-{Robot}
  {Workstations} with {Monitoring} {Via} {RGBD}-{Camera}.
\newblock In {\em 2018 23rd {International} {Conference} on {Methods} and
  {Models} in {Automation} and {Robotics}, {MMAR} 2018\/} (2018), pp.~698--702.
\newblock 1.

\bibitem{bouteraa_gesture-based_2017}
{\sc Bouteraa, Y., and Abdallah, I.}
\newblock A gesture-based telemanipulation control for a robotic arm with
  biofeedback-based grasp.
\newblock {\em Industrial Robot 44}, 5 (2017), 575--587.
\newblock 17.

\bibitem{boykov2001fast}
{\sc Boykov, Y., Veksler, O., and Zabih, R.}
\newblock Fast approximate energy minimization via graph cuts.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence
  23}, 11 (2001), 1222--1239.

\bibitem{broccia_gestural_2011}
{\sc Broccia, G., Livesu, M., and Scateni, R.}
\newblock Gestural interaction for robot motion control.
\newblock In {\em Eurographics {Italian} {Chapter} {Conference} 2011\/} (2011),
  pp.~61--66.
\newblock 13.

\bibitem{brookshire_person_2010}
{\sc Brookshire, J.}
\newblock Person following using histograms of oriented gradients.
\newblock {\em International Journal of Social Robotics 2}, 2 (2010), 137--146.
\newblock 31.

\bibitem{bras_gesture_2018}
{\sc Brás, A., Simão, M., and Neto, P.}
\newblock Gesture recognition from skeleton data for intuitive human-machine
  interaction.
\newblock In {\em Advances in {Transdisciplinary} {Engineering}\/} (2018),
  vol.~7, pp.~271--280.
\newblock 0.

\bibitem{budiharto_indoor_2010}
{\sc Budiharto, W., Jazidie, A., and Purwanto, D.}
\newblock Indoor navigation using adaptive neuro fuzzy controller for servant
  robot.
\newblock In {\em 2010 2nd {International} {Conference} on {Computer}
  {Engineering} and {Applications}, {ICCEA} 2010\/} (2010), vol.~1,
  pp.~582--586.
\newblock 29.

\bibitem{burger_two-handed_2012}
{\sc Burger, B., Ferrané, I., Lerasle, F., and Infantes, G.}
\newblock Two-handed gesture recognition and fusion with speech to command a
  robot.
\newblock {\em Autonomous Robots 32}, 2 (2012), 129--147.
\newblock 81.

\bibitem{canal_gesture_2015}
{\sc Canal, G., Angulo, C., and Escalera, S.}
\newblock Gesture based human multi-robot interaction.
\newblock In {\em Proceedings of the {International} {Joint} {Conference} on
  {Neural} {Networks}\/} (2015), vol.~2015-September.
\newblock 13.

\bibitem{Cao_2017_CVPR}
{\sc Cao, Z., Simon, T., Wei, S.-E., and Sheikh, Y.}
\newblock Realtime multi-person 2d pose estimation using part affinity fields.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)\/} (July 2017).

\bibitem{carion2020end}
{\sc Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., and
  Zagoruyko, S.}
\newblock End-to-end object detection with transformers.
\newblock In {\em European Conference on Computer Vision\/} (2020), Springer,
  pp.~213--229.

\bibitem{carreira2017quo}
{\sc Carreira, J., and Zisserman, A.}
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition\/} (2017), pp.~6299--6308.

\bibitem{1200160}
{\sc Casper, J., and Murphy, R.}
\newblock Human-robot interactions during the robot-assisted urban search and
  rescue response at the world trade center.
\newblock {\em IEEE Transactions on Systems, Man, and Cybernetics, Part B
  (Cybernetics) 33}, 3 (2003), 367--385.

\bibitem{castellano_context-sensitive_2014}
{\sc Castellano, G., Leite, I., Pereira, A., Martinho, C., Paiva, A., and
  McOwan, P.}
\newblock Context-sensitive affect recognition for a robotic game companion.
\newblock {\em ACM Transactions on Interactive Intelligent Systems 4}, 2
  (2014).
\newblock 26.

\bibitem{castellano2010inter}
{\sc Castellano, G., Leite, I., Pereira, A., Martinho, C., Paiva, A., and
  McOwan, P.~W.}
\newblock Inter-act: An affective and contextually rich multimodal video corpus
  for studying interaction with robots.
\newblock In {\em Proceedings of the 18th ACM international conference on
  Multimedia\/} (2010), pp.~1031--1034.

\bibitem{cazzato_real-time_2019}
{\sc Cazzato, D., Cimarelli, C., Sanchez-Lopez, J., Olivares-Mendez, M., and
  Voos, H.}
\newblock Real-time human head imitation for humanoid robots.
\newblock In {\em {ACM} {International} {Conference} {Proceeding} {Series}\/}
  (2019), pp.~65--69.
\newblock 1.

\bibitem{cech_active-speaker_2015}
{\sc Cech, J., Mittal, R., Deleforge, A., Sanchez-Riera, J., Alameda-Pineda,
  X., and Horaud, R.}
\newblock Active-speaker detection and localization with microphones and
  cameras embedded into a robotic head.
\newblock In {\em {IEEE}-{RAS} {International} {Conference} on {Humanoid}
  {Robots}\/} (2015), vol.~2015-February, pp.~203--210.
\newblock 23.

\bibitem{celik_development_2012}
{\sc Celik, I.~B., and Kuntalp, M.}
\newblock Development of a robotic-arm controller by using hand gesture
  recognition.
\newblock In {\em 2012 {International} {Symposium} on {Innovations} in
  {Intelligent} {Systems} and {Applications}\/} (July 2012), pp.~1--5.
\newblock 9.

\bibitem{chalvatzaki_learn_2019}
{\sc Chalvatzaki, G., Papageorgiou, X.~S., Maragos, P., and Tzafestas, C.~S.}
\newblock Learn to {Adapt} to {Human} {Walking}: {A} {Model}-{Based}
  {Reinforcement} {Learning} {Approach} for a {Robotic} {Assistant} {Rollator}.
\newblock {\em IEEE Robotics and Automation Letters 4}, 4 (Oct. 2019),
  3774--3781.
\newblock 3.

\bibitem{chan_collision-free_2020}
{\sc Chan, C.-C., and Tsai, C.-C.}
\newblock Collision-free path planning based on new navigation function for an
  industrial robotic manipulator in human-robot coexistence environments.
\newblock {\em Journal of the Chinese Institute of Engineers, Transactions of
  the Chinese Institute of Engineers,Series A 43}, 6 (2020), 508--518.
\newblock 0.

\bibitem{chao_robotic_2014}
{\sc Chao, F., Chen, F., Shen, Y., He, W., Sun, Y., Wang, Z., Zhou, C., and
  Jiang, M.}
\newblock Robotic free writing of chinese characters via human-robot
  interactions.
\newblock {\em International Journal of Humanoid Robotics 11}, 1 (2014).
\newblock 28.

\bibitem{chao2018learning}
{\sc Chao, Y.-W., Liu, Y., Liu, X., Zeng, H., and Deng, J.}
\newblock Learning to detect human-object interactions.

\bibitem{chen_online_2019}
{\sc Chen, B., Hua, C., Dai, B., He, Y., and Han, J.}
\newblock Online control programming algorithm for human–robot interaction
  system with a novel real-time human gesture recognition method.
\newblock {\em International Journal of Advanced Robotic Systems 16}, 4 (2019).
\newblock 4.

\bibitem{chen2020human}
{\sc Chen, D., He, J., Chen, G., Yu, X., He, M., Yang, Y., Li, J., and Zhou,
  X.}
\newblock Human-robot skill transfer systems for mobile robot based on multi
  sensor fusion.
\newblock In {\em 2020 29th IEEE International Conference on Robot and Human
  Interactive Communication (RO-MAN)\/} (2020), IEEE, pp.~1354--1359.

\bibitem{chen_design_2020}
{\sc Chen, H., Leu, M., Tao, W., and Yin, Z.}
\newblock Design of a real-time human-robot collaboration system using dynamic
  gestures.
\newblock In {\em {ASME} {International} {Mechanical} {Engineering} {Congress}
  and {Exposition}, {Proceedings} ({IMECE})\/} (2020), vol.~2B-2020.
\newblock 1.

\bibitem{chen_human-following_2019}
{\sc Chen, J., and Kim, W.-J.}
\newblock A {Human}-{Following} {Mobile} {Robot} {Providing} {Natural} and
  {Universal} {Interfaces} for {Control} with {Wireless} {Electronic}
  {Devices}.
\newblock {\em IEEE/ASME Transactions on Mechatronics 24}, 5 (2019),
  2377--2385.
\newblock 3.

\bibitem{chen_integrated_2010}
{\sc Chen, K.-Y., Chien, C.-C., Chang, W.-L., and Teng, J.-T.}
\newblock An integrated color and hand gesture recognition approach for an
  autonomous mobile robot.
\newblock In {\em Proceedings - 2010 3rd {International} {Congress} on {Image}
  and {Signal} {Processing}, {CISP} 2010\/} (2010), vol.~5, pp.~2496--2500.
\newblock 17.

\bibitem{chen_stereovision-only_2014}
{\sc Chen, L., Dong, Z., Gao, S., Yuan, B., and Pei, M.}
\newblock Stereovision-only based interactive mobile robot for human-robot
  face-to-face interaction.
\newblock In {\em Proceedings - {International} {Conference} on {Pattern}
  {Recognition}\/} (2014), pp.~1840--1845.
\newblock 1.

\bibitem{chen2011kalman}
{\sc Chen, S.}
\newblock Kalman filter for robot vision: a survey.
\newblock {\em IEEE Transactions on industrial electronics 59}, 11 (2011),
  4409--4420.

\bibitem{chen2011active}
{\sc Chen, S., Li, Y., and Kwok, N.~M.}
\newblock Active vision in robotic systems: A survey of recent developments.
\newblock {\em The International Journal of Robotics Research 30}, 11 (2011),
  1343--1377.

\bibitem{chen_approaches_2010}
{\sc Chen, T.-D.}
\newblock Approaches to robotic vision control using image pointing recognition
  techniques.
\newblock {\em Lecture Notes in Electrical Engineering 67 LNEE\/} (2010),
  321--328.
\newblock 0.

\bibitem{chen_person_2012}
{\sc Chen, W., and Guo, S.}
\newblock Person following of a mobile robot using kinect through features
  detection based on {SURF}.
\newblock {\em Advanced Materials Research 542-543\/} (2012), 779--784.
\newblock 2.

\bibitem{cheng_multiple-robot_2013}
{\sc Cheng, C.-Y., Zhuo, Y.-Y., and Kuo, G.-H.}
\newblock A multiple-robot system for home service.
\newblock In {\em 2013 {CACS} {International} {Automatic} {Control}
  {Conference}, {CACS} 2013 - {Conference} {Digest}\/} (2013), pp.~79--84.
\newblock 1.

\bibitem{cheng_design_2012}
{\sc Cheng, L., Sun, Q., Su, H., Cong, Y., and Zhao, S.}
\newblock Design and implementation of human-robot interactive demonstration
  system based on {Kinect}.
\newblock In {\em Proceedings of the 2012 24th {Chinese} {Control} and
  {Decision} {Conference}, {CCDC} 2012\/} (2012), pp.~971--975.
\newblock 86.

\bibitem{cherubini_unified_2015}
{\sc Cherubini, A., Passama, R., Fraisse, P., and Crosnier, A.}
\newblock A unified multimodal control framework for human-robot interaction.
\newblock {\em Robotics and Autonomous Systems 70\/} (2015), 106--115.
\newblock 42.

\bibitem{chien_navigating_2019}
{\sc Chien, J.-C., Dang, Z.-Y., and Lee, J.-D.}
\newblock Navigating a service robot for indoor complex environments.
\newblock {\em Applied Sciences (Switzerland) 9}, 3 (2019).
\newblock 3.

\bibitem{chou_development_2020}
{\sc Chou, H.-M., Chou, Y.-C., and Chen, H.-H.}
\newblock Development of a {Monocular} {Vision} {Deep} {Learning}-based {AUV}
  {Diver}-{Following} {Control} {System}.
\newblock In {\em Global {Oceans} 2020: {Singapore} – {U}.{S}. {Gulf}
  {Coast}\/} (Oct. 2020), pp.~1--4.
\newblock 0.

\bibitem{choudhary_real_2015}
{\sc Choudhary, G., and Chethan, R.}
\newblock Real time robotic arm control using hand gestures.
\newblock In {\em 2014 {International} {Conference} on {High} {Performance}
  {Computing} and {Applications}, {ICHPCA} 2014\/} (2015).
\newblock 20.

\bibitem{christiernin_interacting_2016}
{\sc Christiernin, L., and Augustsson, S.}
\newblock Interacting with industrial robots - {A} motion-based interface.
\newblock In {\em Proceedings of the {Workshop} on {Advanced} {Visual}
  {Interfaces} {AVI}\/} (2016), vol.~07-10-June-2016, pp.~310--311.
\newblock 4.

\bibitem{cicconet2013human}
{\sc Cicconet, M., Bretan, M., and Weinberg, G.}
\newblock Human-robot percussion ensemble: Anticipation on the basis of visual
  cues.
\newblock {\em IEEE Robotics \& Automation Magazine 20}, 4 (2013), 105--110.

\bibitem{cicirelli_kinect-based_2015}
{\sc Cicirelli, G., Attolico, C., Guaragnella, C., and D'Orazio, T.}
\newblock A kinect-based gesture recognition approach for a natural human robot
  interface.
\newblock {\em International Journal of Advanced Robotic Systems 12\/} (2015).
\newblock 52.

\bibitem{cid_real_2013}
{\sc Cid, F., Prado, J.~A., Bustos, P., and Núñez, P.}
\newblock A real time and robust facial expression recognition and imitation
  approach for affective human-robot interaction using {Gabor} filtering.
\newblock In {\em 2013 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems}\/} (Nov. 2013), pp.~2188--2193.
\newblock 42.

\bibitem{clark2019advancing}
{\sc Clark, K., Duckham, M., Guillemin, M., Hunter, A., McVernon, J.,
  O’Keefe, C., Pitkin, C., Prawer, S., Sinnott, R., Warr, D., et~al.}
\newblock Advancing the ethical use of digital data in human research:
  challenges and strategies to promote ethical practice.
\newblock {\em Ethics and Information Technology 21}, 1 (2019), 59--73.

\bibitem{condes_person_2019}
{\sc Condés, I., and Cañas, J.}
\newblock Person {Following} {Robot} {Behavior} {Using} {Deep} {Learning}.
\newblock {\em Advances in Intelligent Systems and Computing 855\/} (2019),
  147--161.
\newblock 1.

\bibitem{corke2011robotics}
{\sc Corke, P.~I.}
\newblock {\em Robotics, vision and control: fundamental algorithms in MATLAB},
  vol.~73.
\newblock Springer, 2011.

\bibitem{costante_personalizing_2014}
{\sc Costante, G., Bellocchio, E., Valigi, P., and Ricci, E.}
\newblock Personalizing vision-based gestural interfaces for {HRI} with {UAVs}:
  a transfer learning approach.
\newblock In {\em 2014 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems}\/} (Sept. 2014), pp.~3319--3326.
\newblock 17.

\bibitem{costanzo_multimodal_2019}
{\sc Costanzo, M., De~Maria, G., Lettera, G., Natale, C., and Perrone, D.}
\newblock A {Multimodal} {Perception} {System} for {Detection} of {Human}
  {Operators} in {Robotic} {Work} {Cells}.
\newblock In {\em 2019 {IEEE} {International} {Conference} on {Systems}, {Man}
  and {Cybernetics} ({SMC})\/} (Oct. 2019), pp.~692--699.
\newblock 5.

\bibitem{couture-beil_selecting_2010}
{\sc Couture-Beil, A., Vaughan, R.~T., and Mori, G.}
\newblock Selecting and commanding individual robots in a vision-based
  multi-robot system.
\newblock In {\em 2010 5th {ACM}/{IEEE} {International} {Conference} on
  {Human}-{Robot} {Interaction} ({HRI})\/} (Mar. 2010), pp.~355--356.
\newblock 21.

\bibitem{csapo_multimodal_2012}
{\sc Csapó, A., Gilmartin, E., Grizou, J., Han, J., Meena, R., Anastasiou, D.,
  Jokinen, K., and Wilcock, G.}
\newblock Multimodal conversational interaction with a humanoid robot.
\newblock In {\em 3rd {IEEE} {International} {Conference} on {Cognitive}
  {Infocommunications}, {CogInfoCom} 2012 - {Proceedings}\/} (2012),
  pp.~667--672.
\newblock 66.

\bibitem{dalal2005histograms}
{\sc Dalal, N., and Triggs, B.}
\newblock Histograms of oriented gradients for human detection.
\newblock In {\em Conference on Computer Vision and Pattern Recognition
  (CVPR'05)\/} (2005), vol.~1, IEEE, pp.~886--893.

\bibitem{dalal_histograms_2005}
{\sc Dalal, N., and Triggs, B.}
\newblock Histograms of oriented gradients for human detection.
\newblock In {\em Computer {Vision} and {Pattern} {Recognition} ({CVPR})\/}
  (June 2005).
\newblock 35456.

\bibitem{damacharla2018common}
{\sc Damacharla, P., Javaid, A.~Y., Gallimore, J.~J., and Devabhaktuni, V.~K.}
\newblock Common metrics to benchmark human-machine teams (hmt): A review.
\newblock {\em IEEE Access 6\/} (2018), 38637--38655.

\bibitem{das_attracting_2013}
{\sc Das, D., Kobayashi, Y., and Kuno, Y.}
\newblock Attracting attention and establishing a communication channel based
  on the level of visual focus of attention.
\newblock In {\em 2013 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems}\/} (Nov. 2013), pp.~2194--2201.
\newblock 11.

\bibitem{de_luca_integrated_2012}
{\sc De~Luca, A., and Flacco, F.}
\newblock Integrated control for {pHRI}: {Collision} avoidance, detection,
  reaction and collaboration.
\newblock In {\em 2012 4th {IEEE} {RAS} {EMBS} {International} {Conference} on
  {Biomedical} {Robotics} and {Biomechatronics} ({BioRob})\/} (June 2012),
  pp.~288--295.
\newblock 200.

\bibitem{de_schepper_towards_2020}
{\sc De~Schepper, D., Moyaers, B., Schouterden, G., Kellens, K., and Demeester,
  E.}
\newblock Towards robust human-robot mobile co-manipulation for tasks involving
  the handling of non-rigid materials using sensor-fused force-torque, and
  skeleton tracking data.
\newblock In {\em Procedia {CIRP}\/} (2020), vol.~97, pp.~325--330.
\newblock 0.

\bibitem{deepan_raj_static_2017}
{\sc Deepan~Raj, M., Gogul, I., Thangaraja, M., and Kumar, V.}
\newblock Static gesture recognition based precise positioning of 5-{DOF}
  robotic arm using {FPGA}.
\newblock In {\em Proceedings - {TIMA} 2017: 9th {International} {Conference}
  on {Trends} in {Industrial} {Measurement} and {Automation}\/} (2017).
\newblock 9.

\bibitem{del2011interaction}
{\sc del Pobil, A.~P., Prats, M., and Sanz, P.~J.}
\newblock Interaction in robotics with a combination of vision, tactile and
  force sensing.
\newblock In {\em 2011 Fifth International Conference on Sensing Technology\/}
  (2011), IEEE, pp.~21--26.

\bibitem{devanne_co-design_2018}
{\sc Devanne, M., Nguyen, S.~M., Remy-Neris, O., Le~Gals-Garnett, B.,
  Kermarrec, G., and Thepaut, A.}
\newblock A {Co}-design {Approach} for a {Rehabilitation} {Robot} {Coach} for
  {Physical} {Rehabilitation} {Based} on the {Error} {Classification} of
  {Motion} {Errors}.
\newblock In {\em 2018 {Second} {IEEE} {International} {Conference} on
  {Robotic} {Computing} ({IRC})\/} (Jan. 2018), pp.~352--357.
\newblock 9.

\bibitem{ding_optimizing_2011}
{\sc Ding, H., Wijaya, K., Reißig, G., and Stursberg, O.}
\newblock Optimizing motion of robotic manipulators in interaction with human
  operators.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 7101
  LNAI}, PART 1 (2011), 520--531.
\newblock 5.

\bibitem{do_human-robot_2014}
{\sc Do, H., Mouser, C., Liu, M., and Sheng, W.}
\newblock Human-robot collaboration in a {Mobile} {Visual} {Sensor} {Network}.
\newblock In {\em Proceedings - {IEEE} {International} {Conference} on
  {Robotics} and {Automation}\/} (2014), pp.~2203--2208.
\newblock 6.

\bibitem{dometios_real-time_2017}
{\sc Dometios, A., Papageorgiou, X., Arvanitakis, A., Tzafestas, C., and
  Maragos, P.}
\newblock Real-time end-effector motion behavior planning approach using
  on-line point-cloud data towards a user adaptive assistive bath robot.
\newblock In {\em {IEEE} {International} {Conference} on {Intelligent} {Robots}
  and {Systems}\/} (2017), vol.~2017-September, pp.~5031--5036.
\newblock 6.

\bibitem{dosovitskiy2020image}
{\sc Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.}
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em International Conference on Learning Representations\/}
  (2020).

\bibitem{driggs2017integrating}
{\sc Driggs-Campbell, K., Govindarajan, V., and Bajcsy, R.}
\newblock Integrating intuitive driver models in autonomous planning for
  interactive maneuvers.
\newblock {\em IEEE Transactions on Intelligent Transportation Systems 18}, 12
  (2017), 3461--3472.

\bibitem{droeschel_towards_2011}
{\sc Droeschel, D., Stückler, J., Holz, D., and Behnke, S.}
\newblock Towards joint attention for a domestic service robot - person
  awareness and gesture recognition using {Time}-of-{Flight} cameras.
\newblock In {\em 2011 {IEEE} {International} {Conference} on {Robotics} and
  {Automation}\/} (May 2011), pp.~1205--1210.
\newblock 50.

\bibitem{du_online_2018}
{\sc Du, G., Chen, M., Liu, C., Zhang, B., and Zhang, P.}
\newblock Online robot teaching with natural human-robot interaction.
\newblock {\em IEEE Transactions on Industrial Electronics 65}, 12 (2018),
  9571--9581.
\newblock 37.

\bibitem{du2014markerless}
{\sc Du, G., and Zhang, P.}
\newblock Markerless human--robot interface for dual robot manipulators using
  kinect sensor.
\newblock {\em Robotics and Computer-Integrated Manufacturing 30}, 2 (2014),
  150--159.

\bibitem{duffy2003anthropomorphism}
{\sc Duffy, B.~R.}
\newblock Anthropomorphism and the social robot.
\newblock {\em Robotics and autonomous systems 42}, 3-4 (2003), 177--190.

\bibitem{efthymiou_multi-_2018}
{\sc Efthymiou, N., Koutras, P., Filntisis, P., Potamianos, G., and Maragos,
  P.}
\newblock Multi- {View} {Fusion} for {Action} {Recognition} in {Child}-{Robot}
  {Interaction}.
\newblock In {\em Proceedings - {International} {Conference} on {Image}
  {Processing}, {ICIP}\/} (2018), pp.~455--459.
\newblock 9.

\bibitem{ehlers_human-robot_2016}
{\sc Ehlers, K., and Brama, K.}
\newblock A human-robot interaction interface for mobile and stationary robots
  based on real-time {3D} human body and hand-finger pose estimation.
\newblock In {\em {IEEE} {International} {Conference} on {Emerging}
  {Technologies} and {Factory} {Automation}, {ETFA}\/} (2016),
  vol.~2016-November.
\newblock 21.

\bibitem{fleet_lsd-slam_2014}
{\sc Engel, J., Schöps, T., and Cremers, D.}
\newblock {LSD}-{SLAM}: {Large}-{Scale} {Direct} {Monocular} {SLAM}.
\newblock In {\em European {Conference} on {Computer} {Vision}\/} (2014),
  D.~Fleet, T.~Pajdla, B.~Schiele, and T.~Tuytelaars, Eds.
\newblock NoCitationData[s0].

\bibitem{agapito_chalearn_2015}
{\sc Escalera, S., Baró, X., Gonzàlez, J., Bautista, M.~A., Madadi, M.,
  Reyes, M., Ponce-López, V., Escalante, H.~J., Shotton, J., and Guyon, I.}
\newblock {ChaLearn} {Looking} at {People} {Challenge} 2014: {Dataset} and
  {Results}.
\newblock In {\em Computer {Vision} - {ECCV} 2014 {Workshops}}, L.~Agapito,
  M.~M. Bronstein, and C.~Rother, Eds., vol.~8925. Springer International
  Publishing, Cham, 2015, pp.~459--473.
\newblock Series Title: Lecture Notes in Computer Science.

\bibitem{fahn_real-time_2010}
{\sc Fahn, C.-S., and Lin, Y.-T.}
\newblock Real-time face tracking techniques used for the interaction between
  humans and robots.
\newblock In {\em Proceedings of the 2010 5th {IEEE} {Conference} on
  {Industrial} {Electronics} and {Applications}, {ICIEA} 2010\/} (2010),
  pp.~12--17.
\newblock 4.

\bibitem{fallahinia_comparison_2020}
{\sc Fallahinia, N., and Mascaro, S.~A.}
\newblock Comparison of {Constrained} and {Unconstrained} {Human} {Grasp}
  {Forces} {Using} {Fingernail} {Imaging} and {Visual} {Servoing}.
\newblock In {\em 2020 {IEEE} {International} {Conference} on {Robotics} and
  {Automation} ({ICRA})\/} (May 2020), pp.~2668--2674.
\newblock 0.

\bibitem{fang_vehicle-mounted_2019}
{\sc Fang, J., Qiao, M., and Pei, Y.}
\newblock Vehicle-mounted with tracked robotic system based on the kinect.
\newblock In {\em Proceedings - 2019 2nd {World} {Conference} on {Mechanical}
  {Engineering} and {Intelligent} {Manufacturing}, {WCMEIM} 2019\/} (2019),
  pp.~521--524.
\newblock 1.

\bibitem{8876650}
{\sc Fang, Z., and López, A.~M.}
\newblock Intention recognition of pedestrians and cyclists by 2d pose
  estimation.
\newblock {\em IEEE Transactions on Intelligent Transportation Systems 21}, 11
  (2020), 4773--4783.

\bibitem{fareed_gesture_2015}
{\sc Fareed, M., Akram, Q., Anees, S., and Fakih, A.}
\newblock Gesture based wireless single-armed robot in cartesian {3D} space
  using kinect.
\newblock In {\em Proceedings - 2015 5th {International} {Conference} on
  {Communication} {Systems} and {Network} {Technologies}, {CSNT} 2015\/}
  (2015), pp.~1210--1215.
\newblock 4.

\bibitem{farulla_real-time_2014}
{\sc Farulla, G., Russo, L., Pintor, C., Pianu, D., Micotti, G., Salgarella,
  A., Camboni, D., Controzzi, M., Cipriani, C., Oddo, C., Rosa, S., and Indaco,
  M.}
\newblock Real-{Time} {Single} {Camera} {Hand} {Gesture} {Recognition} {System}
  for {Remote} {Deaf}-{Blind} {Communication}.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 8853\/}
  (2014), 35--52.
\newblock 0.

\bibitem{faudzi_real-time_2012}
{\sc Faudzi, A., Ali, M., Azman, M., and Ismail, Z.}
\newblock Real-time hand gestures system for mobile robots control.
\newblock In {\em Procedia {Engineering}\/} (2012), vol.~41, pp.~798--804.
\newblock 25.

\bibitem{feichtenhofer2019slowfast}
{\sc Feichtenhofer, C., Fan, H., Malik, J., and He, K.}
\newblock Slowfast networks for video recognition.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision\/} (2019), pp.~6202--6211.

\bibitem{felzenszwalb2009object}
{\sc Felzenszwalb, P.~F., Girshick, R.~B., McAllester, D., and Ramanan, D.}
\newblock Object detection with discriminatively trained part-based models.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence
  32}, 9 (2009), 1627--1645.

\bibitem{felzenszwalb2005pictorial}
{\sc Felzenszwalb, P.~F., and Huttenlocher, D.~P.}
\newblock Pictorial structures for object recognition.
\newblock {\em International Journal of Computer Vision 61}, 1 (2005), 55--79.

\bibitem{fermuller_prediction_2018}
{\sc Fermüller, C., Wang, F., Yang, Y., Zampogiannis, K., Zhang, Y., Barranco,
  F., and Pfeiffer, M.}
\newblock Prediction of {Manipulation} {Actions}.
\newblock {\em International Journal of Computer Vision 126}, 2 (Apr. 2018),
  358--374.
\newblock 37.

\bibitem{ferraguti_safety_2020}
{\sc Ferraguti, F., Talignani~Landi, C., Costi, S., Bonfè, M., Farsoni, S.,
  Secchi, C., and Fantuzzi, C.}
\newblock Safety barrier functions and multi-camera tracking for human–robot
  shared environment.
\newblock {\em Robotics and Autonomous Systems 124\/} (2020).
\newblock 7.

\bibitem{ferrer_robot_2013}
{\sc Ferrer, G., Garrell, A., Villamizar, M., Huerta, I., and Sanfeliu, A.}
\newblock Robot {Interactive} {Learning} through {Human} {Assistance}.
\newblock {\em Intelligent Systems Reference Library 48\/} (2013), 185--203.
\newblock 14.

\bibitem{ForsythDavid2012Cv:a}
{\sc Forsyth, D.}
\newblock {\em Computer vision : a modern approach}, 2nd ed.~ed.
\newblock Pearson, Boston, 2012.

\bibitem{foster_two_2012}
{\sc Foster, M., Gaschler, A., Giuliani, M., Isard, A., Pateraki, M., and
  Petrick, R.}
\newblock Two people walk into a bar: {Dynamic} multi-party social interaction
  with a robot agent.
\newblock In {\em {ICMI}'12 - {Proceedings} of the {ACM} {International}
  {Conference} on {Multimodal} {Interaction}\/} (2012), pp.~3--10.
\newblock 109.

\bibitem{10.1007/978-3-319-47437-3_74}
{\sc Foster, M.~E., Alami, R., Gestranius, O., Lemon, O., Niemel{\"a}, M.,
  Odobez, J.-M., and Pandey, A.~K.}
\newblock The mummer project: Engaging human-robot interaction in real-world
  public spaces.
\newblock In {\em Social Robotics\/} (Cham, 2016), A.~Agah, J.-J. Cabibihan,
  A.~M. Howard, M.~A. Salichs, and H.~He, Eds., Springer International
  Publishing, pp.~753--763.

\bibitem{zhang2021upt}
{\sc Frederic Z.~Zhang, D.~C., and Gould, S.}
\newblock Efficient two-stage detection of human–object interactions with a
  novel unary–pairwise transformer.
\newblock In {\em arXiv preprint arXiv:2112.01838\/} (2021).

\bibitem{zhang2021scg}
{\sc Frederic Z.~Zhang, D.~C., and Gould, S.}
\newblock Spatially conditioned graphs for detecting human–object
  interactions.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)\/} (October 2021), pp.~13319--13327.

\bibitem{freund1997decision}
{\sc Freund, Y., and Schapire, R.~E.}
\newblock A decision-theoretic generalization of on-line learning and an
  application to boosting.
\newblock {\em Journal of Computer and System Sciences 55}, 1 (1997), 119--139.

\bibitem{fuad_skeleton_2015}
{\sc Fuad, M.}
\newblock Skeleton based gesture to control manipulator.
\newblock In {\em 2015 {International} {Conference} on {Advanced}
  {Mechatronics}, {Intelligent} {Manufacture}, and {Industrial} {Automation}
  ({ICAMIMIA})\/} (Oct. 2015), pp.~96--101.
\newblock 8.

\bibitem{fujii_gesture_2014}
{\sc Fujii, T., Lee, J., and Okamoto, S.}
\newblock Gesture recognition system for {Human}-{Robot} {Interaction} and its
  application to robotic service task.
\newblock In {\em Lecture {Notes} in {Engineering} and {Computer} {Science}\/}
  (2014), vol.~2209, pp.~63--68.
\newblock 33.

\bibitem{gao_humanoid_2015}
{\sc Gao, X., Zheng, M., and Meng, M.-H.}
\newblock Humanoid robot locomotion control by posture recognition for
  human-robot interaction.
\newblock In {\em 2015 {IEEE} {International} {Conference} on {Robotics} and
  {Biomimetics}, {IEEE}-{ROBIO} 2015\/} (2015), pp.~1572--1577.
\newblock 1.

\bibitem{gao_user_2020}
{\sc Gao, Y., Chang, H.~J., and Demiris, Y.}
\newblock User {Modelling} {Using} {Multimodal} {Information} for
  {Personalised} {Dressing} {Assistance}.
\newblock {\em IEEE Access 8\/} (2020), 45700--45714.
\newblock 0.

\bibitem{gardel_wireless_2016}
{\sc Gardel, A., Espinosa, F., Nieto, R., Lázaro, J.~L., and Bravo, I.}
\newblock Wireless {Camera} {Nodes} on a {Cyber}-{Physical} {System}.
\newblock In {\em Proceedings of the 10th {International} {Conference} on
  {Distributed} {Smart} {Camera}\/} (New York, NY, USA, 2016), {ICDSC} '16,
  Association for Computing Machinery, pp.~31--36.
\newblock 0.

\bibitem{gemerek_video-guided_2019}
{\sc Gemerek, J., Ferrari, S., Wang, B., and Campbell, M.}
\newblock Video-guided {Camera} {Control} for {Target} {Tracking} and
  {Following}.
\newblock {\em IFAC-PapersOnLine 51}, 34 (2019), 176--183.
\newblock 7.

\bibitem{ghandour_human_2017}
{\sc Ghandour, M., Liu, H., Stoll, N., and Thurow, K.}
\newblock Human robot interaction for hybrid collision avoidance system for
  indoor mobile robots.
\newblock {\em Advances in Science, Technology and Engineering Systems 2}, 3
  (2017), 650--657.
\newblock 1.

\bibitem{girshick_fast_rcnn}
{\sc Girshick, R.}
\newblock Fast r-cnn.
\newblock In {\em Proceedings of the 2015 IEEE International Conference on
  Computer Vision (ICCV)\/} (USA, 2015), ICCV '15, IEEE Computer Society,
  p.~1440–1448.

\bibitem{gong_research_2018}
{\sc Gong, J., Wang, H., Lu, Z., Feng, N., and Hu, F.}
\newblock Research on human-robot interaction {Security} {Strategy} of
  {Movement} authorization for service robot {Based} on people's attention
  monitoring.
\newblock In {\em 2018 {International} {Conference} on {Intelligence} and
  {Safety} for {Robotics}, {ISR} 2018\/} (2018), pp.~521--526.
\newblock 2.

\bibitem{gonzalez2020audiovisual}
{\sc Gonzalez-Billandon, J., Sciutti, A., Tata, M., Sandini, G., and Rea, F.}
\newblock Audiovisual cognitive architecture for autonomous learning of face
  localisation by a humanoid robot.
\newblock In {\em 2020 IEEE International Conference on Robotics and Automation
  (ICRA)\/} (2020), IEEE, pp.~5979--5985.

\bibitem{gori_multitype_2016}
{\sc Gori, I., Aggarwal, J.~K., Matthies, L., and Ryoo, M.~S.}
\newblock Multitype {Activity} {Recognition} in {Robot}-{Centric} {Scenarios}.
\newblock {\em IEEE Robotics and Automation Letters 1}, 1 (Jan. 2016),
  593--600.
\newblock Conference Name: IEEE Robotics and Automation Letters.

\bibitem{gori_all_2012}
{\sc Gori, I., Fanello, S., Metta, G., and Odone, F.}
\newblock All gestures you can: {A} memory game against a humanoid robot.
\newblock In {\em {IEEE}-{RAS} {International} {Conference} on {Humanoid}
  {Robots}\/} (2012), pp.~330--336.
\newblock 8.

\bibitem{gould2008multi}
{\sc Gould, S., Rodgers, J., Cohen, D., Elidan, G., and Koller, D.}
\newblock Multi-class segmentation with relative location prior.
\newblock {\em International Journal of Computer Vision 80}, 3 (2008),
  300--316.

\bibitem{granata_human_2013}
{\sc Granata, C., Salini, J., Ady, R., and Bidaud, P.}
\newblock Human whole body motion characterization from embedded {Kinect}.
\newblock In {\em 2013 {IEEE} 4th {International} {Conference} on {Cognitive}
  {Infocommunications} ({CogInfoCom})\/} (Dec. 2013), pp.~133--138.
\newblock 2.

\bibitem{gu_human_2012}
{\sc Gu, Y., Do, H., Ou, Y., and Sheng, W.}
\newblock Human gesture recognition through a {Kinect} sensor.
\newblock In {\em 2012 {IEEE} {International} {Conference} on {Robotics} and
  {Biomimetics} ({ROBIO})\/} (Dec. 2012), pp.~1379--1384.
\newblock 101.

\bibitem{gui_teaching_2018}
{\sc Gui, L.-Y., Zhang, K., Wang, Y.-X., Liang, X., Moura, J., and Veloso, M.}
\newblock Teaching {Robots} to {Predict} {Human} {Motion}.
\newblock In {\em {IEEE} {International} {Conference} on {Intelligent} {Robots}
  and {Systems}\/} (2018), pp.~562--567.
\newblock 34.

\bibitem{8594452}
{\sc Gui, L.-Y., Zhang, K., Wang, Y.-X., Liang, X., Moura, J. M.~F., and
  Veloso, M.}
\newblock Teaching robots to predict human motion.
\newblock In {\em 2018 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)\/} (2018), pp.~562--567.

\bibitem{guo_control_2016}
{\sc Guo, L., Liu, C., Wen, X., Chen, H., and Zhang, J.}
\newblock A control system of human-computer interaction based on kinect
  somatosensory equipment.
\newblock In {\em 2016 {Chinese} {Control} and {Decision} {Conference}
  ({CCDC})\/} (May 2016), pp.~5170--5175.
\newblock 2.

\bibitem{gupta_robust_2015}
{\sc Gupta, M., Behera, L., Subramanian, V., and Jamshidi, M.}
\newblock A {Robust} {Visual} {Human} {Detection} {Approach} with {UKF}-{Based}
  {Motion} {Tracking} for a {Mobile} {Robot}.
\newblock {\em IEEE Systems Journal 9}, 4 (2015), 1363--1375.
\newblock 32.

\bibitem{gupta2019nofrills}
{\sc Gupta, T., Schwing, A., and Hoiem, D.}
\newblock No-frills human-object interaction detection: Factorization, layout
  encodings, and training techniques.

\bibitem{gorer_autonomous_2017}
{\sc Görer, B., Salah, A., and Akın, H.}
\newblock An autonomous robotic exercise tutor for elderly people.
\newblock {\em Autonomous Robots 41}, 3 (2017), 657--678.
\newblock 47.

\bibitem{hacinecipoglu2020pose}
{\sc Hacinecipoglu, A., Konukseven, E., and Koku, A.}
\newblock Pose invariant people detection in point clouds for mobile robots.
\newblock {\em International Journal of Mechanical Engineering and Robotics
  Research 9}, 5 (2020).

\bibitem{HaddadinSami2009RfSR}
{\sc Haddadin, S., Albu-Schäffer, A., and Hirzinger, G.}
\newblock Requirements for safe robots: Measurements, analysis and new
  insights.
\newblock {\em The International journal of robotics research 28}, 11-12
  (2009), 1507--1527.

\bibitem{haddadin2011towards}
{\sc Haddadin, S., Suppa, M., Fuchs, S., Bodenm{\"u}ller, T.,
  Albu-Sch{\"a}ffer, A., and Hirzinger, G.}
\newblock Towards the robotic co-worker.
\newblock In {\em Robotics Research}. Springer, 2011, pp.~261--282.

\bibitem{hafiane_3d_2013}
{\sc Hafiane, S., Salih, Y., and Malik, A.~S.}
\newblock {3D} hand recognition for telerobotics.
\newblock In {\em 2013 {IEEE} {Symposium} on {Computers} {Informatics}
  ({ISCI})\/} (Apr. 2013), pp.~132--137.
\newblock 8.

\bibitem{haghighi_integration_2019}
{\sc Haghighi, A., Bdiwi, M., and Putz, M.}
\newblock Integration of {Camera} and {Inertial} {Measurement} {Unit} for
  {Entire} {Human} {Robot} {Interaction} {Using} {Machine} {Learning}
  {Algorithm}.
\newblock In {\em 16th {International} {Multi}-{Conference} on {Systems},
  {Signals} and {Devices}, {SSD} 2019\/} (2019), pp.~741--746.
\newblock 0.

\bibitem{halin2021survey}
{\sc Halin, A., Verly, J.~G., and Van~Droogenbroeck, M.}
\newblock Survey and synthesis of state of the art in driver monitoring.
\newblock {\em Sensors 21}, 16 (2021), 5558.

\bibitem{halme2018review}
{\sc Halme, R.-J., Lanz, M., K{\"a}m{\"a}r{\"a}inen, J., Pieters, R.,
  Latokartano, J., and Hietanen, A.}
\newblock Review of vision-based safety systems for human-robot collaboration.
\newblock {\em Procedia CIRP 72\/} (2018), 111--116.

\bibitem{han_human_2017}
{\sc Han, J., Jang, W., Jung, D., and Lee, E.}
\newblock Human robot interaction method by using hand gesture recognition.
\newblock {\em Lecture Notes in Electrical Engineering 448\/} (2017), 97--102.
\newblock 1.

\bibitem{han2013enhanced}
{\sc Han, J., Shao, L., Xu, D., and Shotton, J.}
\newblock Enhanced computer vision with microsoft kinect sensor: A review.
\newblock {\em IEEE transactions on cybernetics 43}, 5 (2013), 1318--1334.

\bibitem{doi:10.1177/0018720811417254}
{\sc Hancock, P.~A., Billings, D.~R., Schaefer, K.~E., Chen, J. Y.~C.,
  de~Visser, E.~J., and Parasuraman, R.}
\newblock A meta-analysis of factors affecting trust in human-robot
  interaction.
\newblock {\em Human Factors 53}, 5 (2011), 517--527.
\newblock PMID: 22046724.

\bibitem{hartley2003multiple}
{\sc Hartley, R., and Zisserman, A.}
\newblock {\em Multiple view geometry in computer vision}.
\newblock Cambridge University Press, 2003.

\bibitem{hartmann_feasibility_2013}
{\sc Hartmann, F., and Schlaefer, A.}
\newblock Feasibility of touch-less control of operating room lights.
\newblock {\em International Journal of Computer Assisted Radiology and Surgery
  8}, 2 (2013), 259--268.
\newblock 29.

\bibitem{hasanuzzaman_adaptation_2010}
{\sc Hasanuzzaman, M., and Inamura, T.}
\newblock Adaptation to new user interactively using dynamically calculated
  principal components for user-specific human-robot interaction.
\newblock In {\em 2010 {IEEE}/{SICE} {International} {Symposium} on {System}
  {Integration}\/} (Dec. 2010), pp.~164--169.
\newblock 0.

\bibitem{hassan_computationally_2016}
{\sc Hassan, M., Khan, A., Khan, M., Uzair, M., and Khurshid, K.}
\newblock A computationally low cost vision based tracking algorithm for human
  following robot.
\newblock In {\em Proceedings - 2016 the 2nd {International} {Conference} on
  {Control}, {Automation} and {Robotics}, {ICCAR} 2016\/} (2016), pp.~62--65.
\newblock 4.

\bibitem{he2017mask}
{\sc He, K., Gkioxari, G., Doll{\'a}r, P., and Girshick, R.}
\newblock Mask {R-CNN}.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision\/} (2017), pp.~2961--2969.

\bibitem{he_deep_2016}
{\sc He, K., Zhang, X., Ren, S., and Sun, J.}
\newblock Deep {Residual} {Learning} for {Image} {Recognition}.
\newblock In {\em 2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern}
  {Recognition} ({CVPR})\/} (June 2016), pp.~770--778.
\newblock 73363.

\bibitem{hegger_people_2013}
{\sc Hegger, F., Hochgeschwender, N., Kraetzschmar, G., and Ploeger, P.}
\newblock People detection in 3d point clouds using local surface normals.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 7500
  LNAI\/} (2013), 154--164.
\newblock 32.

\bibitem{henriques_high-speed_2015}
{\sc Henriques, J.~F., Caseiro, R., Martins, P., and Batista, J.}
\newblock High-{Speed} {Tracking} with {Kernelized} {Correlation} {Filters}.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence
  37}, 3 (Mar. 2015), 583--596.
\newblock NoCitationData[s0].

\bibitem{hentout2019human}
{\sc Hentout, A., Aouache, M., Maoudj, A., and Akli, I.}
\newblock Human--robot interaction in industrial collaborative robotics: a
  literature review of the decade 2008--2017.
\newblock {\em Advanced Robotics 33}, 15-16 (2019), 764--799.

\bibitem{hoffman2019evaluating}
{\sc Hoffman, G.}
\newblock Evaluating fluency in human--robot collaboration.
\newblock {\em IEEE Transactions on Human-Machine Systems 49}, 3 (2019),
  209--218.

\bibitem{hong_interactive_2018}
{\sc Hong, C., Chen, Z., Zhu, J., and Zhang, X.}
\newblock Interactive humanoid robot arm imitation system using human upper
  limb motion tracking.
\newblock In {\em 2017 {IEEE} {International} {Conference} on {Robotics} and
  {Biomimetics}, {ROBIO} 2017\/} (2018), vol.~2018-January, pp.~2746--2751.
\newblock 1.

\bibitem{horn1981determining}
{\sc Horn, B.~K., and Schunck, B.~G.}
\newblock Determining optical flow.
\newblock {\em Artificial Intelligence 17}, 1-3 (1981), 185--203.

\bibitem{hsu_real-time_2020}
{\sc Hsu, R.~C., Su, P.-C., Hsu, J.-L., and Wang, C.-Y.}
\newblock Real-{Time} {Interaction} {System} of {Human}-{Robot} with {Hand}
  {Gestures}.
\newblock In {\em 2020 {IEEE} {Eurasia} {Conference} on {IOT}, {Communication}
  and {Engineering} ({ECICE})\/} (Oct. 2020), pp.~396--398.
\newblock 0.

\bibitem{hu_design_2014}
{\sc Hu, J.-S., Wang, J.-J., and Ho, D.}
\newblock Design of sensing system and anticipative behavior for human
  following of mobile robots.
\newblock {\em IEEE Transactions on Industrial Electronics 61}, 4 (2014),
  1916--1927.
\newblock 68.

\bibitem{7451737}
{\sc Huang, C.-M., and Mutlu, B.}
\newblock Anticipatory robot control for efficient human-robot collaboration.
\newblock In {\em 2016 11th ACM/IEEE International Conference on Human-Robot
  Interaction (HRI)\/} (2016), pp.~83--90.

\bibitem{hwang_interactions_2020}
{\sc Hwang, C.-L., Wang, D.-S., Weng, F.-C., and Lai, S.-L.}
\newblock Interactions between {Specific} {Human} and {Omnidirectional}
  {Mobile} {Robot} {Using} {Deep} {Learning} {Approach}: {SSD}-{FN}-{KCF}.
\newblock {\em IEEE Access 8\/} (2020), 41186--41200.
\newblock 0.

\bibitem{igorevich_behavioral_2011}
{\sc Igorevich, R., Ismoilovich, E., and Min, D.}
\newblock Behavioral synchronization of human and humanoid robot.
\newblock In {\em {URAI} 2011 - 2011 8th {International} {Conference} on
  {Ubiquitous} {Robots} and {Ambient} {Intelligence}\/} (2011), pp.~655--660.
\newblock 14.

\bibitem{ikai_robot_2016}
{\sc Ikai, T., Kamiya, S., and Ohka, M.}
\newblock Robot control using natural instructions via visual and tactile
  sensations.
\newblock {\em Journal of Computer Science 12}, 5 (2016), 246--254.
\newblock 8.

\bibitem{indrajit_development_2013}
{\sc Indrajit, W., and Muis, A.}
\newblock Development of whole body motion imitation in humanoid robot.
\newblock In {\em 2013 {International} {Conference} on {Quality} in {Research},
  {QiR} 2013 - {In} {Conjunction} with {ICCS} 2013: {The} 2nd {International}
  {Conference} on {Civic} {Space}\/} (2013), pp.~138--141.
\newblock 10.

\bibitem{ionescu_dataset_2014}
{\sc Ionescu, C., Papava, D., Olaru, V., and Sminchisescu, C.}
\newblock Human3.6m: Large scale datasets and predictive methods for 3d human
  sensing in natural environments.
\newblock {\em IEEE Trans. Pattern Anal. Mach. Intell. 36}, 7 (July 2014),
  1325–1339.

\bibitem{iqbal2017coordination}
{\sc Iqbal, T., and Riek, L.~D.}
\newblock Coordination dynamics in multihuman multirobot teams.
\newblock {\em IEEE Robotics and Automation Letters 2}, 3 (2017), 1712--1717.

\bibitem{doi:10.1177/0278364919881683}
{\sc Islam, M.~J., Hong, J., and Sattar, J.}
\newblock Person-following by autonomous robots: A categorical overview.
\newblock {\em The International Journal of Robotics Research 38}, 14 (2019),
  1581--1618.

\bibitem{izadi2011kinectfusion}
{\sc Izadi, S., Kim, D., Hilliges, O., Molyneaux, D., Newcombe, R., Kohli, P.,
  Shotton, J., Hodges, S., Freeman, D., Davison, A., et~al.}
\newblock Kinectfusion: real-time 3d reconstruction and interaction using a
  moving depth camera.
\newblock In {\em Proceedings of the 24th annual ACM symposium on User
  interface software and technology\/} (2011), pp.~559--568.

\bibitem{jaegle2021perceiver}
{\sc Jaegle, A., Borgeaud, S., Alayrac, J.-B., Doersch, C., Ionescu, C., Ding,
  D., Koppula, S., Zoran, D., Brock, A., Shelhamer, E., et~al.}
\newblock Perceiver io: A general architecture for structured inputs \&
  outputs.
\newblock {\em arXiv preprint arXiv:2107.14795\/} (2021).

\bibitem{jafari2014real}
{\sc Jafari, O.~H., Mitzel, D., and Leibe, B.}
\newblock Real-time rgb-d based people detection and tracking for mobile robots
  and head-worn cameras.
\newblock In {\em 2014 IEEE International Conference on Robotics and Automation
  (ICRA)\/} (2014), IEEE, pp.~5636--5643.

\bibitem{jaimes2007multimodal}
{\sc Jaimes, A., and Sebe, N.}
\newblock Multimodal human--computer interaction: A survey.
\newblock {\em Computer vision and image understanding 108}, 1-2 (2007),
  116--134.

\bibitem{jarosz_detecting_2019}
{\sc Jarosz, M., Nawrocki, P., Placzkiewicz, L., Sniezynski, B., Zielinski, M.,
  and Indurkhya, B.}
\newblock Detecting gaze direction using robot-mounted and mobile-device
  cameras.
\newblock {\em Computer Science 20}, 4 (2019), 455--476.
\newblock 0.

\bibitem{jevtic_comparison_2015}
{\sc Jevtić, A., Doisy, G., Parmet, Y., and Edan, Y.}
\newblock Comparison of {Interaction} {Modalities} for {Mobile} {Indoor}
  {Robot} {Guidance}: {Direct} {Physical} {Interaction}, {Person} {Following},
  and {Pointing} {Control}.
\newblock {\em IEEE Transactions on Human-Machine Systems 45}, 6 (2015),
  653--663.
\newblock 31.

\bibitem{jia2020dr}
{\sc Jia, D., Hermans, A., and Leibe, B.}
\newblock Dr-spaam: A spatial-attention and auto-regressive model for person
  detection in 2d range data.
\newblock In {\em 2020 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)\/} (2020), IEEE, pp.~10270--10277.

\bibitem{jia_autonomous_2011}
{\sc Jia, S., Zhao, L., Li, X., Cui, W., and Sheng, J.}
\newblock Autonomous robot human detecting and tracking based on stereo vision.
\newblock In {\em 2011 {IEEE} {International} {Conference} on {Mechatronics}
  and {Automation}, {ICMA} 2011\/} (2011), pp.~640--645.
\newblock 9.

\bibitem{jiang2018personalize}
{\sc Jiang, L., Wang, W., Chen, Y., and Jia, Y.}
\newblock Personalize vison-based human following for mobile robots by learning
  from human-driven demonstrations.
\newblock In {\em 2018 27th IEEE International Symposium on Robot and Human
  Interactive Communication (RO-MAN)\/} (2018), IEEE, pp.~726--731.

\bibitem{jindai_small-size_2010}
{\sc Jindai, M., and Watanabe, T.}
\newblock A small-size handshake robot system based on a handshake approaching
  motion model with a voice greeting.
\newblock In {\em 2010 {IEEE}/{ASME} {International} {Conference} on {Advanced}
  {Intelligent} {Mechatronics}\/} (July 2010), pp.~521--526.
\newblock 8.

\bibitem{ju_integrative_2017}
{\sc Ju, Z., Ji, X., Li, J., and Liu, H.}
\newblock An integrative framework of human hand gesture segmentation for
  human-robot interaction.
\newblock {\em IEEE Systems Journal 11}, 3 (2017), 1326--1336.
\newblock 40.

\bibitem{kahily_real-time_2016}
{\sc Kahily, H., and Sudheer, A.}
\newblock Real-time human detection and tracking from a mobile armed robot
  using {RGB}-{D} sensor.
\newblock In {\em {IEEE} {WCTFTR} 2016 - {Proceedings} of 2016 {World}
  {Conference} on {Futuristic} {Trends} in {Research} and {Innovation} for
  {Social} {Welfare}\/} (2016).
\newblock 3.

\bibitem{kalidolda_towards_2018}
{\sc Kalidolda, N., and Sandygulova, A.}
\newblock Towards {Interpreting} {Robotic} {System} for {Fingerspelling}
  {Recognition} in {Real} {Time}.
\newblock In {\em {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot}
  {Interaction}\/} (2018), pp.~141--142.
\newblock 0.

\bibitem{kanade_comprehensive_2000}
{\sc Kanade, T., Cohn, J., and {Yingli Tian}}.
\newblock Comprehensive database for facial expression analysis.
\newblock In {\em Proceedings {Fourth} {IEEE} {International} {Conference} on
  {Automatic} {Face} and {Gesture} {Recognition} ({Cat}. {No}. {PR00580})\/}
  (2000).
\newblock 3124.

\bibitem{kanade2000comprehensive}
{\sc Kanade, T., Cohn, J.~F., and Tian, Y.}
\newblock Comprehensive database for facial expression analysis.
\newblock In {\em Proceedings Fourth IEEE International Conference on Automatic
  Face and Gesture Recognition (Cat. No. PR00580)\/} (2000), IEEE, pp.~46--53.

\bibitem{kanazawa2018end}
{\sc Kanazawa, A., Black, M.~J., Jacobs, D.~W., and Malik, J.}
\newblock End-to-end recovery of human shape and pose.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition\/} (2018), pp.~7122--7131.

\bibitem{kanazawa2019learning}
{\sc Kanazawa, A., Zhang, J.~Y., Felsen, P., and Malik, J.}
\newblock Learning {3D} human dynamics from video.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition\/} (2019), pp.~5614--5623.

\bibitem{katsuki_high_speed_2015}
{\sc Katsuki, Y., Yamakawa, Y., and Ishikawa, M.}
\newblock High-{Speed} {Human} / {Robot} {Hand} {Interaction} {System}.
\newblock In {\em Proceedings of the {Tenth} {Annual} {ACM}/{IEEE}
  {International} {Conference} on {Human}-{Robot} {Interaction} {Extended}
  {Abstracts}\/} (New York, NY, USA, 2015), {HRI}'15 {Extended} {Abstracts},
  Association for Computing Machinery, pp.~117--118.
\newblock event-place: Portland, Oregon, USA.

\bibitem{katsuki_high-speed_2015}
{\sc Katsuki, Y., Yamakawa, Y., and Ishikawa, M.}
\newblock High-speed {Human}/{Robot} {Hand} {Interaction} {System}.
\newblock In {\em {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot}
  {Interaction}\/} (2015), vol.~02-05-March-2015, pp.~117--118.
\newblock 15.

\bibitem{kawasaki_multimodal_2020}
{\sc Kawasaki, Y., Yorozu, A., Takahashi, M., and Pagello, E.}
\newblock A {Multimodal} {Path} {Planning} {Approach} to {Human} {Robot}
  {Interaction} {Based} on {Integrating} {Action} {Modeling}.
\newblock {\em Journal of Intelligent and Robotic Systems: Theory and
  Applications 100}, 3-4 (2020), 955--972.
\newblock 1.

\bibitem{ke_vision_2016}
{\sc Ke, X., Zhu, Y., Yang, Y., Xing, J., and Luo, Z.}
\newblock Vision system of facial robot {SHFR}- {III} for human-robot
  interaction.
\newblock In {\em {ICINCO} 2016 - {Proceedings} of the 13th {International}
  {Conference} on {Informatics} in {Control}, {Automation} and {Robotics}\/}
  (2016), vol.~2, pp.~472--478.
\newblock 0.

\bibitem{khatib2017visual}
{\sc Khatib, M., Al~Khudir, K., and De~Luca, A.}
\newblock Visual coordination task for human-robot collaboration.
\newblock In {\em 2017 IEEE/RSJ international conference on intelligent robots
  and systems (IROS)\/} (2017), IEEE, pp.~3762--3768.

\bibitem{khavas2020modeling}
{\sc Khavas, Z.~R., Ahmadzadeh, S.~R., and Robinette, P.}
\newblock Modeling trust in human-robot interaction: A survey.
\newblock In {\em International Conference on Social Robotics\/} (2020),
  Springer, pp.~529--541.

\bibitem{kobayashi_people_2010}
{\sc Kobayashi, Y., and Kuno, Y.}
\newblock People tracking using integrated sensors for human robot interaction.
\newblock In {\em Proceedings of the {IEEE} {International} {Conference} on
  {Industrial} {Technology}\/} (2010), pp.~1617--1622.
\newblock 35.

\bibitem{kocabas2020vibe}
{\sc Kocabas, M., Athanasiou, N., and Black, M.~J.}
\newblock {VIBE}: Video inference for human body pose and shape estimation.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition\/} (2020), pp.~5253--5263.

\bibitem{kogkas_free-view_2019}
{\sc Kogkas, A., Ezzat, A., Thakkar, R., Darzi, A., and Mylonas, G.}
\newblock Free-{View}, {3D} {Gaze}-{Guided} {Robotic} {Scrub} {Nurse}.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 11768
  LNCS\/} (2019), 164--172.
\newblock 0.

\bibitem{kolotouros2019convolutional}
{\sc Kolotouros, N., Pavlakos, G., and Daniilidis, K.}
\newblock Convolutional mesh regression for single-image human shape
  reconstruction.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition\/} (2019), pp.~4501--4510.

\bibitem{konda_real_2012}
{\sc Konda, K.~R., Königs, A., Schulz, H., and Schulz, D.}
\newblock Real {Time} {Interaction} with {Mobile} {Robots} {Using} {Hand}
  {Gestures}.
\newblock In {\em Proceedings of the {Seventh} {Annual} {ACM}/{IEEE}
  {International} {Conference} on {Human}-{Robot} {Interaction}\/} (New York,
  NY, USA, 2012), {HRI} '12, Association for Computing Machinery, pp.~177--178.
\newblock 37.

\bibitem{koppula_anticipating_2016}
{\sc Koppula, H., and Saxena, A.}
\newblock Anticipating {Human} {Activities} {Using} {Object} {Affordances} for
  {Reactive} {Robotic} {Response}.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence
  38}, 1 (2016), 14--29.
\newblock 565.

\bibitem{koustoumpardis_human_2016}
{\sc Koustoumpardis, P., Chatzilygeroudis, K., Synodinos, A., and Aspragathos,
  N.}
\newblock Human robot collaboration for folding fabrics based on
  force/{RGB}-{D} feedback.
\newblock {\em Advances in Intelligent Systems and Computing 371\/} (2016),
  235--243.
\newblock 9.

\bibitem{krahenbuhl2011efficient}
{\sc Kr{\"a}henb{\"u}hl, P., and Koltun, V.}
\newblock Efficient inference in fully connected crfs with gaussian edge
  potentials.
\newblock {\em Advances in Neural Information Processing Systems 24\/} (2011).

\bibitem{krizhevsky2012imagenet}
{\sc Krizhevsky, A., Sutskever, I., and Hinton, G.~E.}
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Advances in neural information processing systems 25\/} (2012).

\bibitem{7451807}
{\sc Kwon, M., Jung, M.~F., and Knepper, R.~A.}
\newblock Human expectations of social robots.
\newblock In {\em 2016 11th ACM/IEEE International Conference on Human-Robot
  Interaction (HRI)\/} (2016), pp.~463--464.

\bibitem{lalejini_evaluation_2015}
{\sc Lalejini, A., Duckworth, D., Sween, R., Bethel, C., and Carruth, D.}
\newblock Evaluation of supervisory control interfaces for mobile robot
  integration with tactical teams.
\newblock In {\em Proceedings of {IEEE} {Workshop} on {Advanced} {Robotics} and
  its {Social} {Impacts}, {ARSO}\/} (2015), vol.~2015-January, pp.~1--6.
\newblock 6.

\bibitem{lam_real-time_2011}
{\sc Lam, M., Prabuwono, A., Arshad, H., and Chan, C.}
\newblock A real-time vision-based framework for human-robot interaction.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 7066
  LNCS}, PART 1 (2011), 257--267.
\newblock 5.

\bibitem{lambrecht_spatial_2012}
{\sc Lambrecht, J., and Kruger, J.}
\newblock Spatial programming for industrial robots based on gestures and
  {Augmented} {Reality}.
\newblock In {\em {IEEE} {International} {Conference} on {Intelligent} {Robots}
  and {Systems}\/} (2012), pp.~466--472.
\newblock 41.

\bibitem{landi_prediction_2019}
{\sc Landi, C., Cheng, Y., Ferraguti, F., Bonfe, M., Secchi, C., and Tomizuka,
  M.}
\newblock Prediction of {Human} {Arm} {Target} for {Robot} {Reaching}
  {Movements}.
\newblock In {\em {IEEE} {International} {Conference} on {Intelligent} {Robots}
  and {Systems}\/} (2019), pp.~5950--5957.
\newblock 4.

\bibitem{lang_research_2020}
{\sc Lang, X., Feng, Z., and Yang, X.}
\newblock Research on human-robot natural interaction algorithm based on body
  potential perception.
\newblock In {\em {ACM} {International} {Conference} {Proceeding} {Series}\/}
  (2020), pp.~260--264.
\newblock 0.

\bibitem{lathuiliere_deep_2018}
{\sc Lathuilière, S., Massé, B., Mesejo, P., and Horaud, R.}
\newblock Deep {Reinforcement} {Learning} for {Audio}-{Visual} {Gaze}
  {Control}.
\newblock In {\em 2018 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems} ({IROS})\/} (Oct. 2018), pp.~1555--1562.
\newblock 7.

\bibitem{lau2010multi}
{\sc Lau, B., Arras, K.~O., and Burgard, W.}
\newblock Multi-model hypothesis group tracking and group size estimation.
\newblock {\em International Journal of Social Robotics 2}, 1 (2010), 19--30.

\bibitem{lavanya_gesture_2018}
{\sc Lavanya, K., Shree, D., Nischitha, B., Asha, T., and Gururaj, C.}
\newblock Gesture controlled robot.
\newblock In {\em International {Conference} on {Electrical}, {Electronics},
  {Communication} {Computer} {Technologies} and {Optimization} {Techniques},
  {ICEECCOT} 2017\/} (2018), vol.~2018-January, pp.~465--469.
\newblock 5.

\bibitem{8955665}
{\sc {Leal}, D., and {Yihun}, Y.}
\newblock Progress in human-robot collaboration for object handover.
\newblock In {\em 2019 IEEE International Symposium on Measurement and Control
  in Robotics (ISMCR)\/} (2019), pp.~C3--2--1--C3--2--6.

\bibitem{lee_visual_2020}
{\sc Lee, C.-Y., Lee, H., Hwang, I., and Zhang, B.-T.}
\newblock Visual {Perception} {Framework} for an {Intelligent} {Mobile}
  {Robot}.
\newblock In {\em 2020 17th {International} {Conference} on {Ubiquitous}
  {Robots}, {UR} 2020\/} (2020), pp.~612--616.
\newblock 1.

\bibitem{lee_real-time_2020}
{\sc Lee, J., and Ahn, B.}
\newblock Real-time human action recognition with a low-cost {RGB} camera and
  mobile robot platform.
\newblock {\em Sensors (Switzerland) 20}, 10 (2020).
\newblock 2.

\bibitem{lee_learning_2017}
{\sc Lee, J., and Ryoo, M.}
\newblock Learning robot activities from first-person human videos using
  convolutional future regression.
\newblock In {\em {IEEE} {International} {Conference} on {Intelligent} {Robots}
  and {Systems}\/} (2017), vol.~2017-September, pp.~1497--1504.
\newblock 33.

\bibitem{lee_interactive_2012}
{\sc Lee, J.-E., Park, J., Kim, G.-S., Lee, J.-H., and Kim, M.-H.}
\newblock Interactive multi-resolution display using a projector mounted mobile
  robot in intelligent space.
\newblock {\em International Journal of Advanced Robotic Systems 9\/} (2012).
\newblock 4.

\bibitem{lee_human_2012}
{\sc Lee, S., Shah, G., Bhattacharya, A., and Motai, Y.}
\newblock Human tracking with an infrared camera using curve matching
  framework.
\newblock {\em Eurasip Journal on Advances in Signal Processing 2012}, 1
  (2012).
\newblock 17.

\bibitem{leichtmann2020much}
{\sc Leichtmann, B., and Nitsch, V.}
\newblock How much distance do humans keep toward robots? literature review,
  meta-analysis, and theoretical considerations on personal space in
  human-robot interaction.
\newblock {\em Journal of Environmental Psychology 68\/} (2020), 101386.

\bibitem{doi:10.1177/0278364917710318}
{\sc Levine, S., Pastor, P., Krizhevsky, A., Ibarz, J., and Quillen, D.}
\newblock Learning hand-eye coordination for robotic grasping with deep
  learning and large-scale data collection.
\newblock {\em The International Journal of Robotics Research 37}, 4-5 (2018),
  421--436.

\bibitem{li2020transferring}
{\sc Li, D., Yu, X., Xu, C., Petersson, L., and Li, H.}
\newblock Transferring cross-domain knowledge for video sign language
  recognition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition\/} (2020), pp.~6205--6214.

\bibitem{li_id-match_2016}
{\sc Li, H., Zhang, P., Al~Moubayed, S., Patel, S.~N., and Sample, A.~P.}
\newblock {ID}-{Match}: {A} {Hybrid} {Computer} {Vision} and {RFID} {System}
  for {Recognizing} {Individuals} in {Groups}.
\newblock In {\em Proceedings of the 2016 {CHI} {Conference} {Extended}
  {Abstracts} on {Human} {Factors} in {Computing} {Systems}\/} (New York, NY,
  USA, 2016), {CHI} {EA} '16, Association for Computing Machinery, p.~7.
\newblock 57.

\bibitem{li_inferring_2019}
{\sc Li, K., Sun, S., Zhao, X., Wu, J., and Tan, M.}
\newblock Inferring user intent to interact with a public service robot using
  bimodal information analysis.
\newblock {\em Advanced Robotics 33}, 7-8 (2019), 369--387.
\newblock 3.

\bibitem{li_real-time_2019}
{\sc Li, K., Wu, J., Zhao, X., and Tan, M.}
\newblock Real-{Time} {Human}-{Robot} {Interaction} for a {Service} {Robot}
  {Based} on {3D} {Human} {Activity} {Recognition} and {Human}-{Mimicking}
  {Decision} {Mechanism}.
\newblock In {\em 8th {Annual} {IEEE} {International} {Conference} on {Cyber}
  {Technology} in {Automation}, {Control} and {Intelligent} {Systems}, {CYBER}
  2018\/} (2019), pp.~498--503.
\newblock 4.

\bibitem{li_visual_2015}
{\sc Li, L., Xu, Q., Wang, G., Yu, X., Tan, Y., and Li, H.}
\newblock Visual {Perception} {Based} {Engagement} {Awareness} for {Multiparty}
  {Human}-{Robot} {Interaction}.
\newblock {\em International Journal of Humanoid Robotics 12}, 4 (2015).
\newblock 0.

\bibitem{li_cnn_2019}
{\sc Li, T.-H., Kuo, P.-H., Tsai, T.-N., and Luan, P.-C.}
\newblock {CNN} and {LSTM} {Based} {Facial} {Expression} {Analysis} {Model} for
  a {Humanoid} {Robot}.
\newblock {\em IEEE Access 7\/} (2019), 93998--94011.
\newblock 12.

\bibitem{li_learning_2018}
{\sc Li, X., Cheng, H., Ji, G., and Chen, J.}
\newblock Learning complex assembly skills from kinect based human robot
  interaction.
\newblock In {\em 2017 {IEEE} {International} {Conference} on {Robotics} and
  {Biomimetics}, {ROBIO} 2017\/} (2018), vol.~2018-January, pp.~2646--2651.
\newblock 2.

\bibitem{li_cyber-physical_2013}
{\sc Li, Y.-T., Jacob, M., Akingba, G., and Wachs, J.}
\newblock A cyber-physical management system for delivering and monitoring
  surgical instruments in the or.
\newblock {\em Surgical Innovation 20}, 4 (2013), 377--384.
\newblock 17.

\bibitem{lichtenstern_prototyping_2012}
{\sc Lichtenstern, M., Frassl, M., Perun, B., and Angermann, M.}
\newblock A prototyping environment for interaction between a human and a
  robotic multi-agent system.
\newblock In {\em {HRI}'12 - {Proceedings} of the 7th {Annual} {ACM}/{IEEE}
  {International} {Conference} on {Human}-{Robot} {Interaction}\/} (2012),
  pp.~185--186.
\newblock 37.

\bibitem{lima_real-time_2019}
{\sc Lima, B., Júnior, G., Amaral, L., Vieira, T., Ferreira, B., and Vieira,
  T.}
\newblock Real-time hand pose tracking and classification for natural
  human-robot control.
\newblock In {\em {VISIGRAPP} 2019 - {Proceedings} of the 14th {International}
  {Joint} {Conference} on {Computer} {Vision}, {Imaging} and {Computer}
  {Graphics} {Theory} and {Applications}\/} (2019), vol.~5, pp.~832--839.
\newblock 0.

\bibitem{linder2014multi}
{\sc Linder, T., and Arras, K.~O.}
\newblock Multi-model hypothesis tracking of groups of people in rgb-d data.
\newblock In {\em 17th International Conference on Information Fusion
  (FUSION)\/} (2014), IEEE, pp.~1--7.

\bibitem{liu2018gesture}
{\sc Liu, H., and Wang, L.}
\newblock Gesture recognition for human-robot collaboration: A review.
\newblock {\em International Journal of Industrial Ergonomics 68\/} (2018),
  355--367.

\bibitem{liu2018learning}
{\sc Liu, P., Glas, D.~F., Kanda, T., and Ishiguro, H.}
\newblock Learning proactive behavior for interactive social robots.
\newblock {\em Autonomous Robots 42}, 5 (2018), 1067--1085.

\bibitem{liu_ssd_2016}
{\sc Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., and
  Berg, A.~C.}
\newblock {SSD}: {Single} {Shot} {MultiBox} {Detector}.
\newblock In {\em European {Conference} on {Computer} {Vision}\/} (2016).
\newblock 13811.

\bibitem{liu_interactive_2016}
{\sc Liu, X., Zhou, X., Liu, C., Wang, J., Zhou, X., Xu, N., and Jiang, A.}
\newblock An interactive training system of motor learning by imitation and
  speech instructions for children with autism.
\newblock In {\em 2016 9th {International} {Conference} on {Human} {System}
  {Interactions} ({HSI})\/} (July 2016), pp.~56--61.
\newblock 15.

\bibitem{liu2016multirobot}
{\sc Liu, Y., and Nejat, G.}
\newblock Multirobot cooperative learning for semiautonomous control in urban
  search and rescue applications.
\newblock {\em Journal of Field Robotics 33}, 4 (2016), 512--536.

\bibitem{5508131}
{\sc Liu, Y.-c., and Dai, Q.-h.}
\newblock A survey of computer vision applied in aerial robotic vehicles.
\newblock In {\em 2010 International Conference on Optics, Photonics and Energy
  Engineering (OPEE)\/} (2010), vol.~1, pp.~277--280.

\bibitem{liu_dynamic_2020}
{\sc Liu, Z., Wang, X., Cai, Y., Xu, W., Liu, Q., Zhou, Z., and Pham, D.}
\newblock Dynamic risk assessment and active response strategy for industrial
  human-robot collaboration.
\newblock {\em Computers and Industrial Engineering 141\/} (2020).
\newblock 2.

\bibitem{long_kinect-based_2018}
{\sc Long, Y., Xu, Y., Xiao, Z., and Shen, Z.}
\newblock Kinect-based {Human} {Body} {Tracking} {System} {Control} of
  {Medical} {Care} {Service} {Robot}.
\newblock In {\em 2018 {WRC} {Symposium} on {Advanced} {Robotics} and
  {Automation}, {WRC} {SARA} 2018 - {Proceeding}\/} (2018), pp.~65--69.
\newblock 0.

\bibitem{loper2015smpl}
{\sc Loper, M., Mahmood, N., Romero, J., Pons-Moll, G., and Black, M.~J.}
\newblock {SMPL}: A skinned multi-person linear model.
\newblock {\em ACM Transactions on Graphics (TOG) 34}, 6 (2015), 1--16.

\bibitem{lovon-ramos_people_2016}
{\sc Lovon-Ramos, P.~W., Rosas-Cuevas, Y., Cervantes-Jilaja, C., Tejada-Begazo,
  M., Patiño-Escarcina, R.~E., and Barrios-Aranibar, D.}
\newblock People {Detection} and {Localization} in {Real} {Time} during
  {Navigation} of {Autonomous} {Robots}.
\newblock In {\em 2016 {XIII} {Latin} {American} {Robotics} {Symposium} and
  {IV} {Brazilian} {Robotics} {Symposium} ({LARS}/{SBR})\/} (Oct. 2016),
  pp.~239--244.
\newblock 6.

\bibitem{lowe1999object}
{\sc Lowe, D.~G.}
\newblock Object recognition from local scale-invariant features.
\newblock In {\em Proceedings of the Seventh IEEE International Conference on
  Computer Vision\/} (1999), vol.~2, Ieee, pp.~1150--1157.

\bibitem{lu_research_2020}
{\sc Lu, G., Tang, W., Zheng, J., Chen, T., and Zou, X.}
\newblock Research and {Implementation} of {Real}-{Time} {Motion} {Control} of
  {Robot} {Based} on {Kinect}.
\newblock {\em Smart Innovation, Systems and Technologies 166\/} (2020),
  779--792.
\newblock 0.

\bibitem{lucas1981iterative}
{\sc Lucas, B.~D., and Kanade, T.}
\newblock An iterative image registration technique with an application to
  stereo vision.
\newblock In {\em Proc 7th Intl Joint Conf on Artificial Intelligence (IJ
  CAI)\/} (1981).

\bibitem{lucey_extended_2010}
{\sc Lucey, P., Cohn, J.~F., Kanade, T., Saragih, J., Ambadar, Z., and
  Matthews, I.}
\newblock The {Extended} {Cohn}-{Kanade} {Dataset} ({CK}+): {A} complete
  dataset for action unit and emotion-specified expression.
\newblock In {\em 2010 {IEEE} {Computer} {Society} {Conference} on {Computer}
  {Vision} and {Pattern} {Recognition} - {Workshops}\/} (June 2010).
\newblock 3019.

\bibitem{luo_tracking_2011}
{\sc Luo, R., Chang, S.-R., and Yang, Y.-P.}
\newblock Tracking with pointing gesture recognition for human-robot
  interaction.
\newblock In {\em 2011 {IEEE}/{SICE} {International} {Symposium} on {System}
  {Integration}, {SII} 2011\/} (2011), pp.~1220--1225.
\newblock 8.

\bibitem{luo_human_2010}
{\sc Luo, R.~C., Huang, C.~H., and Lin, T.~T.}
\newblock Human tracking and following using sound source localization for
  multisensor based mobile assistive companion robot.
\newblock In {\em {IECON} 2010 - 36th {Annual} {Conference} on {IEEE}
  {Industrial} {Electronics} {Society}\/} (Nov. 2010), pp.~1552--1557.
\newblock 22.

\bibitem{luo_human-robot_2019}
{\sc Luo, X., Amighetti, A., and Zhang, D.}
\newblock A {Human}-{Robot} {Interaction} for a {Mecanum} {Wheeled} {Mobile}
  {Robot} with {Real}-{Time} {3D} {Two}-{Hand} {Gesture} {Recognition}.
\newblock In {\em Journal of {Physics}: {Conference} {Series}\/} (2019),
  vol.~1267.
\newblock 1.

\bibitem{luo_real-time_2019}
{\sc Luo, X., Zhang, D., and Jin, X.}
\newblock A {Real}-time {Moving} {Target} {Following} {Mobile} {Robot} {System}
  with {Depth} {Camera}.
\newblock In {\em {IOP} {Conference} {Series}: {Materials} {Science} and
  {Engineering}\/} (2019), vol.~491.
\newblock 1.

\bibitem{doi:10.1177/2050157919843961}
{\sc Lutz, C., Schöttler, M., and Hoffmann, C.~P.}
\newblock The privacy implications of social robots: Scoping review and expert
  interviews.
\newblock {\em Mobile Media \& Communication 7}, 3 (2019), 412--434.

\bibitem{macdonald2019active}
{\sc MacDonald, R.~A., and Smith, S.~L.}
\newblock Active sensing for motion planning in uncertain environments via
  mutual information policies.
\newblock {\em The International Journal of Robotics Research 38}, 2-3 (2019),
  146--161.

\bibitem{maher_realtime_2017}
{\sc Maher, A., Li, C., Hu, H., and Zhang, B.}
\newblock Realtime {Human}-{UAV} {Interaction} {Using} {Deep} {Learning}.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 10568
  LNCS\/} (2017), 511--519.
\newblock 12.

\bibitem{manigandan_wireless_2010}
{\sc Manigandan, M., and Jackin, I.}
\newblock Wireless vision based mobile robot control using hand gesture
  recognition through perceptual color space.
\newblock In {\em {ACE} 2010 - 2010 {International} {Conference} on {Advances}
  in {Computer} {Engineering}\/} (2010), pp.~95--99.
\newblock 44.

\bibitem{manitsaris_fingers_2016}
{\sc Manitsaris, S., Tsagaris, A., Glushkova, A., Moutarde, F., and Bevilacqua,
  F.}
\newblock Fingers {Gestures} {Early}-{Recognition} with a {Unified} {Framework}
  for {RGB} or {Depth} {Camera}.
\newblock In {\em Proceedings of the 3rd {International} {Symposium} on
  {Movement} and {Computing}\/} (New York, NY, USA, 2016), {MOCO} '16,
  Association for Computing Machinery.
\newblock 2.

\bibitem{mao_medical_2018}
{\sc Mao, L., and Zhu, P.}
\newblock The medical service robot interaction based on kinect.
\newblock In {\em Proceedings of the 2017 {IEEE} {International} {Conference}
  on {Intelligent} {Techniques} in {Control}, {Optimization} and {Signal}
  {Processing}, {INCOS} 2017\/} (2018), vol.~2018-February, pp.~1--7.
\newblock 4.

\bibitem{maraj_application_2016}
{\sc Maraj, D., Maraj, A., and Hajzeraj, A.}
\newblock Application interface for gesture recognition with {Kinect} sensor.
\newblock In {\em 2016 {IEEE} {International} {Conference} on {Knowledge}
  {Engineering} and {Applications} ({ICKEA})\/} (Sept. 2016), pp.~98--102.
\newblock 5.

\bibitem{martin_estimation_2010}
{\sc Martin, C., Steege, F.-F., and Gross, H.-M.}
\newblock Estimation of pointing poses for visually instructing mobile robots
  under real world conditions.
\newblock {\em Robotics and Autonomous Systems 58}, 2 (2010), 174--185.
\newblock 23.

\bibitem{martin_real-time_2019}
{\sc Martin, J., and Moutarde, F.}
\newblock Real-{Time} {Gestural} {Control} of {Robot} {Manipulator} {Through}
  {Deep} {Learning} {Human}-{Pose} {Inference}.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 11754
  LNCS\/} (2019), 565--572.
\newblock 1.

\bibitem{masmoudi_expressive_2011}
{\sc Masmoudi, R., Bouchouicha, M., and Gorce, P.}
\newblock Expressive robot to support elderly.
\newblock {\em Assistive Technology Research Series 29\/} (2011), 557--564.
\newblock 0.

\bibitem{massardi2020parc}
{\sc Massardi, J., Gravel, M., and Beaudry, {\'E}.}
\newblock Parc: a plan and activity recognition component for assistive robots.
\newblock In {\em 2020 IEEE International Conference on Robotics and Automation
  (ICRA)\/} (2020), IEEE, pp.~3025--3031.

\bibitem{mateus_human-aware_2016}
{\sc Mateus, A., Miraldo, P., Lima, P., and Sequeira, J.}
\newblock Human-aware navigation using external omnidirectional cameras.
\newblock {\em Advances in Intelligent Systems and Computing 417\/} (2016),
  283--295.
\newblock 4.

\bibitem{maurtua_natural_2017}
{\sc Maurtua, I., Fernández, I., Tellaeche, A., Kildal, J., Susperregi, L.,
  Ibarguren, A., and Sierra, B.}
\newblock Natural multimodal communication for human-robot collaboration.
\newblock {\em International Journal of Advanced Robotic Systems 14}, 4 (2017),
  1--12.
\newblock 28.

\bibitem{mazhar_real-time_2019}
{\sc Mazhar, O., Navarro, B., Ramdani, S., Passama, R., and Cherubini, A.}
\newblock A real-time human-robot interaction framework with robust background
  invariant hand gesture detection.
\newblock {\em Robotics and Computer-Integrated Manufacturing 60\/} (2019),
  34--48.
\newblock 20.

\bibitem{mcfassel2018prototyping}
{\sc McFassel, G., Hsieh, S.-J., and Peng, B.}
\newblock Prototyping and evaluation of interactive and customized interface
  and control algorithms for robotic assistive devices using kinect and
  infrared sensor.
\newblock {\em International Journal of Advanced Robotic Systems 15}, 2 (2018),
  1729881418769521.

\bibitem{mckeague2013hand}
{\sc McKeague, S., Liu, J., and Yang, G.-Z.}
\newblock Hand and body association in crowded environments for human-robot
  interaction.
\newblock In {\em 2013 IEEE International Conference on Robotics and
  Automation\/} (2013), IEEE, pp.~2161--2168.

\bibitem{mead_probabilistic_2012}
{\sc Mead, R., and Mataric, M.}
\newblock A probabilistic framework for autonomous proxemic control in situated
  and mobile human-robot interaction.
\newblock In {\em {HRI}'12 - {Proceedings} of the 7th {Annual} {ACM}/{IEEE}
  {International} {Conference} on {Human}-{Robot} {Interaction}\/} (2012),
  pp.~193--194.
\newblock 31.

\bibitem{medeiros_human-drone_2020}
{\sc Medeiros, A., Ratsamee, P., Uranishi, Y., Mashita, T., and Takemura, H.}
\newblock Human-{Drone} {Interaction}: {Using} {Pointing} {Gesture} to {Define}
  a {Target} {Object}.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 12182
  LNCS\/} (2020), 688--705.
\newblock 3.

\bibitem{meghdari_real-time_2017}
{\sc Meghdari, A., Shouraki, S., Siamy, A., and Shariati, A.}
\newblock The real-time facial imitation by a social humanoid robot.
\newblock In {\em 4th {RSI} {International} {Conference} on {Robotics} and
  {Mechatronics}, {ICRoM} 2016\/} (2017), pp.~524--529.
\newblock 14.

\bibitem{mehrabi2021survey}
{\sc Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., and Galstyan, A.}
\newblock A survey on bias and fairness in machine learning.
\newblock {\em ACM Computing Surveys (CSUR) 54}, 6 (2021), 1--35.

\bibitem{10.1145/3457607}
{\sc Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., and Galstyan, A.}
\newblock A survey on bias and fairness in machine learning.
\newblock {\em ACM Comput. Surv. 54}, 6 (July 2021).

\bibitem{mendes2017human}
{\sc Mendes, N., Ferrer, J., Vitorino, J., Safeea, M., and Neto, P.}
\newblock Human behavior and hand gesture classification for smart human-robot
  interaction.
\newblock {\em Procedia Manufacturing 11\/} (2017), 91--98.

\bibitem{mi2013human}
{\sc Mi, Z.-Q., and Yang, Y.}
\newblock Human-robot interaction in uvs swarming: a survey.
\newblock {\em International Journal of Computer Science Issues (IJCSI) 10}, 2
  Part 1 (2013), 273.

\bibitem{miller_self-driving_2019}
{\sc Miller, J., Hong, S., and Lu, J.}
\newblock Self-{Driving} {Mobile} {Robots} {Using} {Human}-{Robot}
  {Interactions}.
\newblock In {\em Proceedings - 2018 {IEEE} {International} {Conference} on
  {Systems}, {Man}, and {Cybernetics}, {SMC} 2018\/} (2019), pp.~1251--1256.
\newblock 0.

\bibitem{milligan_selecting_2011}
{\sc Milligan, B., Mori, G., and Vaughan, R.}
\newblock Selecting and commanding groups in a multi-robot vision based system.
\newblock In {\em 2011 6th {ACM}/{IEEE} {International} {Conference} on
  {Human}-{Robot} {Interaction} ({HRI})\/} (Mar. 2011), pp.~415--415.
\newblock 18.

\bibitem{miyoshi_above_2014}
{\sc Miyoshi, K., Konomura, R., and Hori, K.}
\newblock Above your hand: {Direct} and natural interaction with aerial robot.
\newblock In {\em {ACM} {SIGGRAPH} 2014 {Emerging} {Technologies}, {SIGGRAPH}
  2014\/} (2014).
\newblock 15.

\bibitem{moe_real-time_2013}
{\sc Moe, S., and Schjølberg, I.}
\newblock Real-time hand guiding of industrial manipulator in 5 {DOF} using
  {Microsoft} {Kinect} and accelerometer.
\newblock In {\em 2013 {IEEE} {RO}-{MAN}\/} (Aug. 2013), pp.~644--649.
\newblock 17.

\bibitem{moeslund2001survey}
{\sc Moeslund, T.~B., and Granum, E.}
\newblock A survey of computer vision-based human motion capture.
\newblock {\em Computer vision and image understanding 81}, 3 (2001), 231--268.

\bibitem{moh_gesture_2019}
{\sc Moh, J., Kijima, T., Zhang, B., and Lim, H.-O.}
\newblock Gesture {Recognition} and {Effective} {Interaction} {Based} {Dining}
  {Table} {Cleaning} {Robot}.
\newblock In {\em 2019 7th {International} {Conference} on {Robot}
  {Intelligence} {Technology} and {Applications}, {RiTA} 2019\/} (2019),
  pp.~72--77.
\newblock 1.

\bibitem{mohaimenianpour_hands_2018}
{\sc MohaimenianPour, S., and Vaughan, R.}
\newblock Hands and {Faces}, {Fast}: {Mono}-{Camera} {User} {Detection}
  {Robust} {Enough} to {Directly} {Control} a {UAV} in {Flight}.
\newblock In {\em 2018 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems} ({IROS})\/} (Oct. 2018), pp.~5224--5231.
\newblock 12.

\bibitem{mohammad_tele-operation_2013}
{\sc Mohammad, F., Sudini, K., Puligilla, V., and Kapula, P.}
\newblock Tele-operation of robot using gestures.
\newblock In {\em Proceedings - {Asia} {Modelling} {Symposium} 2013: 7th {Asia}
  {International} {Conference} on {Mathematical} {Modelling} and {Computer}
  {Simulation}, {AMS} 2013\/} (2013), pp.~67--71.
\newblock 3.

\bibitem{moher2009preferred}
{\sc Moher, D., Liberati, A., Tetzlaff, J., Altman, D.~G., Group, P., et~al.}
\newblock Preferred reporting items for systematic reviews and meta-analyses:
  the prisma statement.
\newblock {\em PLoS medicine 6}, 7 (2009), e1000097.

\bibitem{moladande2019implicit}
{\sc Moladande, M., and Madhusanka, B.}
\newblock Implicit intention and activity recognition of a human using neural
  networks for a service robot eye.
\newblock In {\em 2019 International Research Conference on Smart Computing and
  Systems Engineering (SCSE)\/} (2019), IEEE, pp.~38--43.

\bibitem{mollahosseini_affectnet_2019}
{\sc Mollahosseini, A., Hasani, B., and Mahoor, M.~H.}
\newblock {AffectNet}: {A} {Database} for {Facial} {Expression}, {Valence}, and
  {Arousal} {Computing} in the {Wild}.
\newblock {\em IEEE Transactions on Affective Computing 10}, 1 (Jan. 2019),
  18--31.
\newblock NoCitationData[s0].

\bibitem{mollaret_multi-modal_2016}
{\sc Mollaret, C., Mekonnen, A., Pinquier, J., Lerasle, F., and Ferrane, I.}
\newblock A multi-modal perception based architecture for a non-intrusive
  domestic assistant robot.
\newblock In {\em {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot}
  {Interaction}\/} (2016), vol.~2016-April, pp.~481--482.
\newblock 7.

\bibitem{monajjemi_uav_2015}
{\sc Monajjemi, M., Bruce, J., Sadat, S.~A., Wawerla, J., and Vaughan, R.}
\newblock {UAV}, do you see me? {Establishing} mutual attention between an
  uninstrumented human and an outdoor {UAV} in flight.
\newblock In {\em 2015 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems} ({IROS})\/} (Sept. 2015),
  pp.~3614--3620.
\newblock 28.

\bibitem{monajjemi_hri_2013}
{\sc Monajjemi, V.~M., Wawerla, J., Vaughan, R., and Mori, G.}
\newblock {HRI} in the sky: {Creating} and commanding teams of {UAVs} with a
  vision-mediated gestural interface.
\newblock In {\em 2013 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems}\/} (Nov. 2013), pp.~617--623.
\newblock 104.

\bibitem{morato_toward_2014}
{\sc Morato, C., Kaipa, K., Zhao, B., and Gupta, S.}
\newblock Toward safe human robot collaboration by using multiple kinects based
  real-time human tracking.
\newblock {\em Journal of Computing and Information Science in Engineering 14},
  1 (2014).
\newblock 144.

\bibitem{moreno_path_2016}
{\sc Moreno, R., Mauledoux, M., and Avilés, O.}
\newblock Path optimization planning for human-robot interaction.
\newblock {\em International Journal of Applied Engineering Research 11}, 22
  (2016), 10822--10827.
\newblock 1.

\bibitem{mronga_constraint-based_2020}
{\sc Mronga, D., Knobloch, T., de~Gea~Fernández, J., and Kirchner, F.}
\newblock A constraint-based approach for human–robot collision avoidance.
\newblock {\em Advanced Robotics 34}, 5 (2020), 265--281.
\newblock 2.

\bibitem{muller2007participatory}
{\sc Muller, M.~J.}
\newblock {\em Participatory design: the third space in HCI}.
\newblock CRC press, 2007.

\bibitem{munaro_fast_2014}
{\sc Munaro, M., and Menegatti, E.}
\newblock Fast {RGB}-{D} people tracking for service robots.
\newblock {\em Autonomous Robots 37}, 3 (2014), 227--242.
\newblock 167.

\bibitem{munaro2014fast}
{\sc Munaro, M., and Menegatti, E.}
\newblock Fast rgb-d people tracking for service robots.
\newblock {\em Autonomous Robots 37}, 3 (2014), 227--242.

\bibitem{mendez-polanco_detection_2010}
{\sc Méndez-Polanco, J., Muñoz-Meléndez, A., and Morales-Manzanares, E.}
\newblock Detection of multiple people by a mobile robot in dynamic indoor
  environments.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 6433
  LNAI\/} (2010), 522--531.
\newblock 0.

\bibitem{muller_multi-modal_2020}
{\sc Müller, S., Wengefeld, T., Trinh, T., Aganian, D., Eisenbach, M., and
  Gross, H.-M.}
\newblock A multi-modal person perception framework for socially interactive
  mobile service robots.
\newblock {\em Sensors (Switzerland) 20}, 3 (2020).
\newblock 4.

\bibitem{nagi_wisdom_2015}
{\sc Nagi, J., Ngo, H., Gambardella, L.~M., and Di~Caro, G.~A.}
\newblock Wisdom of the swarm for cooperative decision-making in human-swarm
  interaction.
\newblock In {\em 2015 {IEEE} {International} {Conference} on {Robotics} and
  {Automation} ({ICRA})\/} (May 2015), pp.~1802--1808.
\newblock 18.

\bibitem{nair_3d_2011}
{\sc Nair, S., Dean-Leon, E., and Knoll, A.}
\newblock {3D} {Position} based multiple human servoing by low-level-control of
  6 {DOF} industrial robot.
\newblock In {\em 2011 {IEEE} {International} {Conference} on {Robotics} and
  {Biomimetics}, {ROBIO} 2011\/} (2011), pp.~2816--2823.
\newblock 0.

\bibitem{nascimento_collision_2020}
{\sc Nascimento, H., Mujica, M., and Benoussaad, M.}
\newblock Collision {Avoidance} in {Human}-{Robot} {Interaction} {Using}
  {Kinect} {Vision} {System} {Combined} {With} {Robot}’s {Model} and {Data}.
\newblock In {\em 2020 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems} ({IROS})\/} (Oct. 2020),
  pp.~10293--10298.
\newblock 0.

\bibitem{nazari_simplified_2015}
{\sc Nazari, S., Charmi, M., Hassani, M., and Ahmadi, G.}
\newblock A simplified method in human to robot motion mapping schemes.
\newblock In {\em 2015 3rd {RSI} {International} {Conference} on {Robotics} and
  {Mechatronics} ({ICROM})\/} (Oct. 2015), pp.~545--550.
\newblock 0.

\bibitem{nguyen_audio-visual_2014}
{\sc Nguyen, Q., Yun, S.-S., and Choi, J.}
\newblock Audio-visual integration for human-robot interaction in multi-person
  scenarios.
\newblock In {\em 19th {IEEE} {International} {Conference} on {Emerging}
  {Technologies} and {Factory} {Automation}, {ETFA} 2014\/} (2014).
\newblock 4.

\bibitem{nishiyama_human_2013}
{\sc Nishiyama, T., Takimoto, M., and Kambayashi, Y.}
\newblock Human intervention for searching targets using mobile agents in a
  multi-robot environment.
\newblock {\em Frontiers in Artificial Intelligence and Applications 254\/}
  (2013), 154--163.
\newblock 0.

\bibitem{obo_robot_2015}
{\sc Obo, T., Loo, C.~K., and Kubota, N.}
\newblock Robot posture generation based on genetic algorithm for imitation.
\newblock In {\em 2015 {IEEE} {Congress} on {Evolutionary} {Computation}
  ({CEC})\/} (May 2015), pp.~552--557.
\newblock 5.

\bibitem{ognibene2013contextual}
{\sc Ognibene, D., Chinellato, E., Sarabia, M., and Demiris, Y.}
\newblock Contextual action recognition and target localization with an active
  allocation of attention on a humanoid robot.
\newblock {\em Bioinspiration \& biomimetics 8}, 3 (2013), 035002.

\bibitem{ortenzi2021object}
{\sc Ortenzi, V., Cosgun, A., Pardi, T., Chan, W.~P., Croft, E., and Kuli{\'c},
  D.}
\newblock Object handovers: a review for robotics.
\newblock {\em IEEE Transactions on Robotics\/} (2021).

\bibitem{paetzel_let_2019}
{\sc Paetzel, M., and Castellano, G.}
\newblock Let {Me} {Get} {To} {Know} {You} {Better}: {Can} {Interactions}
  {Help} to {Overcome} {Uncanny} {Feelings}?
\newblock In {\em Proceedings of the 7th {International} {Conference} on
  {Human}-{Agent} {Interaction}\/} (New York, NY, USA, 2019), {HAI} '19,
  Association for Computing Machinery, pp.~59--67.
\newblock 6.

\bibitem{pang_efficient_2020}
{\sc Pang, L., Zhang, Y., Coleman, S., and Cao, H.}
\newblock Efficient {Hybrid}-{Supervised} {Deep} {Reinforcement} {Learning} for
  {Person} {Following} {Robot}.
\newblock {\em Journal of Intelligent and Robotic Systems: Theory and
  Applications 97}, 2 (2020), 299--312.
\newblock 5.

\bibitem{pantic2005web}
{\sc Pantic, M., Valstar, M., Rademaker, R., and Maat, L.}
\newblock Web-based database for facial expression analysis.
\newblock In {\em 2005 IEEE international conference on multimedia and Expo\/}
  (2005), IEEE, pp.~5--pp.

\bibitem{papadopoulos2019advanced}
{\sc Papadopoulos, C., Mariolis, I., Topalidou-Kyniazopoulou, A., Piperagkas,
  G., Ioannidis, D., and Tzovaras, D.}
\newblock An advanced human-robot interaction interface for collaborative
  robotic assembly tasks.
\newblock In {\em Rapid Automation: Concepts, Methodologies, Tools, and
  Applications}. IGI Global, 2019, pp.~794--812.

\bibitem{park_real-time_2011}
{\sc Park, C.-B., and Lee, S.-W.}
\newblock Real-time {3D} pointing gesture recognition for mobile robots with
  cascade {HMM} and particle filter.
\newblock {\em Image and Vision Computing 29}, 1 (2011), 51--63.
\newblock 90.

\bibitem{pasinetti_development_2018}
{\sc Pasinetti, S., Nuzzi, C., Lancini, M., Sansoni, G., Docchio, F., and
  Fornaser, A.}
\newblock Development and {Characterization} of a {Safety} {System} for
  {Robotic} {Cells} {Based} on {Multiple} {Time} of {Flight} ({TOF}) {Cameras}
  and {Point} {Cloud} {Analysis}.
\newblock In {\em 2018 {Workshop} on {Metrology} for {Industry} 4.0 and {IoT},
  {MetroInd} 4.0 and {IoT} 2018 - {Proceedings}\/} (2018), pp.~34--39.
\newblock 3.

\bibitem{patrick2021keeping}
{\sc Patrick, M., Campbell, D., Asano, Y., Misra, I., Metze, F., Feichtenhofer,
  C., Vedaldi, A., and Henriques, J.~F.}
\newblock Keeping your eye on the ball: Trajectory attention in video
  transformers.
\newblock {\em Advances in Neural Information Processing Systems 34\/} (2021).

\bibitem{paulo_vision-based_2012}
{\sc Paulo, T., Fernando, R., and Gil, L.}
\newblock Vision-based hand segmentation techniques for human-robot interaction
  for real-time applications.
\newblock In {\em Computational {Vision} and {Medical} {Image} {Processing},
  {Proceedings} of {VipIMAGE} 2011 - 3rd {ECCOMAS} {Thematic} {Conference} on
  {Computational} {Vision} and {Medical} {Image} {Processing}\/} (2012),
  pp.~31--35.
\newblock 11.

\bibitem{pavlakos2018ordinal}
{\sc Pavlakos, G., Zhou, X., and Daniilidis, K.}
\newblock Ordinal depth supervision for {3D} human pose estimation.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition\/} (2018), pp.~7307--7316.

\bibitem{pavllo20193d}
{\sc Pavllo, D., Feichtenhofer, C., Grangier, D., and Auli, M.}
\newblock {3D} human pose estimation in video with temporal convolutions and
  semi-supervised training.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition\/} (2019), pp.~7753--7762.

\bibitem{pena2017benchmarking}
{\sc Pena, D., Forembski, A., Xu, X., and Moloney, D.}
\newblock Benchmarking of {CNNs} for low-cost, low-power robotics applications.
\newblock In {\em RSS 2017 Workshop: New Frontier for Deep Learning in
  Robotics\/} (2017), pp.~1--5.

\bibitem{pennisi_multi-robot_2015}
{\sc Pennisi, A., Previtali, F., Gennari, C., Bloisi, D., Iocchi, L., Ficarola,
  F., Vitaletti, A., and Nardi, D.}
\newblock Multi-robot surveillance through a distributed sensor network.
\newblock {\em Studies in Computational Intelligence 604\/} (2015), 77--98.
\newblock 16.

\bibitem{pentiuc_drive_2018}
{\sc Pentiuc, S.-G., and Vultur, O.-M.}
\newblock "{Drive} me": {A} interaction system between human and robot.
\newblock In {\em 2018 14th {International} {Conference} on {Development} and
  {Application} {Systems}, {DAS} 2018 - {Proceedings}\/} (2018), pp.~144--149.
\newblock 0.

\bibitem{pereira_human-robot_2013}
{\sc Pereira, F., Vassallo, R., and Salles, E.}
\newblock Human-robot interaction and cooperation through people detection and
  gesture recognition.
\newblock {\em Journal of Control, Automation and Electrical Systems 24}, 3
  (2013), 187--198.
\newblock 15.

\bibitem{petric_online_2014}
{\sc Petric, T., Gams, A., Zlajpah, L., Ude, A., and Morimoto, J.}
\newblock Online approach for altering robot behaviors based on human in the
  loop coaching gestures.
\newblock In {\em Proceedings - {IEEE} {International} {Conference} on
  {Robotics} and {Automation}\/} (2014), pp.~4770--4776.
\newblock 14.

\bibitem{pfeil_exploring_2013}
{\sc Pfeil, K., Koh, S., and LaViola~Jr., J.}
\newblock Exploring {3D} gesture metaphors for interaction with unmanned aerial
  vehicles.
\newblock In {\em International {Conference} on {Intelligent} {User}
  {Interfaces}, {Proceedings} {IUI}\/} (2013), pp.~257--266.
\newblock 114.

\bibitem{pfister2013largescale}
{\sc Pfister, T., Charles, J., and Zisserman, A.}
\newblock Large-scale learning of sign language by watching {TV} (using
  co-occurrences).
\newblock In {\em British Machine Vision Conference\/} (2013).

\bibitem{phillips1998feret}
{\sc Phillips, P.~J., Wechsler, H., Huang, J., and Rauss, P.~J.}
\newblock The feret database and evaluation procedure for face-recognition
  algorithms.
\newblock {\em Image and vision computing 16}, 5 (1998), 295--306.

\bibitem{phong_vietnamese_2020}
{\sc Phong, N., Nam, L., and Thinh, N.}
\newblock Vietnamese service robot based on artificial intelligence.
\newblock {\em International Journal of Mechanical Engineering and Robotics
  Research 9}, 5 (2020), 701--708.
\newblock 0.

\bibitem{doi:10.1080/01691864.2017.1365009}
{\sc Pierson, H.~A., and Gashler, M.~S.}
\newblock Deep learning in robotics: a review of recent research.
\newblock {\em Advanced Robotics 31}, 16 (2017), 821--835.

\bibitem{pittaluga2019revealing}
{\sc Pittaluga, F., Koppal, S.~J., Kang, S.~B., and Sinha, S.~N.}
\newblock Revealing scenes by inverting structure from motion reconstructions.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition\/} (2019), pp.~145--154.

\bibitem{pop2019control}
{\sc Pop, A., and Stan, O.}
\newblock Control a 6dof anthropomorphic robotic structure with computer vision
  as mems input.
\newblock In {\em 2019 22nd International Conference on Control Systems and
  Computer Science (CSCS)\/} (2019), IEEE, pp.~700--706.

\bibitem{potdar_learning_2016}
{\sc Potdar, S., Sawarkar, A., and Kazi, F.}
\newblock Learning by demonstration from multiple agents in humanoid robots.
\newblock In {\em 2016 {IEEE} {Students}' {Conference} on {Electrical},
  {Electronics} and {Computer} {Science}, {SCEECS} 2016\/} (2016).
\newblock 0.

\bibitem{prediger_robot-supported_2014}
{\sc Prediger, M., Braun, A., Marinc, A., and Kuijper, A.}
\newblock Robot-supported pointing interaction for intelligent environments.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 8530
  LNCS\/} (2014), 172--183.
\newblock 2.

\bibitem{pustianu_mobile_2011}
{\sc Pustianu, A.~I., Serbencu, A., and Cernega, D.~C.}
\newblock Mobile robot control using face recognition algorithms.
\newblock In {\em 15th {International} {Conference} on {System} {Theory},
  {Control} and {Computing}\/} (Oct. 2011), pp.~1--6.
\newblock 5.

\bibitem{qi2018learning}
{\sc Qi, S., Wang, W., Jia, B., Shen, J., and Zhu, S.-C.}
\newblock Learning human-object interactions by graph parsing neural networks.

\bibitem{qian_visually_2013}
{\sc Qian, K., and Hu, C.}
\newblock Visually gesture recognition for an interactive robot grasping
  application.
\newblock {\em International Journal of Multimedia and Ubiquitous Engineering
  8}, 3 (2013), 189--196.
\newblock 15.

\bibitem{quintero_interactive_2014}
{\sc Quintero, C., Fomena, R., Shademan, A., Ramirez, O., and Jagersand, M.}
\newblock Interactive teleoperation interface for semi-autonomous control of
  robot arms.
\newblock In {\em Proceedings - {Conference} on {Computer} and {Robot}
  {Vision}, {CRV} 2014\/} (2014), pp.~357--363.
\newblock 11.

\bibitem{quintero_visual_2015}
{\sc Quintero, C., Tatsambon, R., Gridseth, M., and Jagersand, M.}
\newblock Visual pointing gestures for bi-directional human robot interaction
  in a pick-and-place task.
\newblock In {\em Proceedings - {IEEE} {International} {Workshop} on {Robot}
  and {Human} {Interactive} {Communication}\/} (2015), vol.~2015-November,
  pp.~349--354.
\newblock 15.

\bibitem{bastos_robot-assisted_2019}
{\sc Ramírez-Duque, A., Frizera-Neto, A., and Bastos, T.}
\newblock Robot-{Assisted} {Autism} {Spectrum} {Disorder} {Diagnostic} {Based}
  on {Artificial} {Reasoning}.
\newblock {\em Journal of Intelligent and Robotic Systems: Theory and
  Applications 96}, 2 (2019), 267--281.
\newblock 14.

\bibitem{randelli2013knowledge}
{\sc Randelli, G., Bonanni, T.~M., Iocchi, L., and Nardi, D.}
\newblock Knowledge acquisition through human--robot multimodal interaction.
\newblock {\em Intelligent Service Robotics 6}, 1 (2013), 19--31.

\bibitem{ratul_gesture_2016}
{\sc Ratul, A., Ali, M., and Ahasan, R.}
\newblock Gesture based wireless shadow robot.
\newblock In {\em 2016 5th {International} {Conference} on {Informatics},
  {Electronics} and {Vision}, {ICIEV} 2016\/} (2016), pp.~351--355.
\newblock 0.

\bibitem{rautaray2015vision}
{\sc Rautaray, S.~S., and Agrawal, A.}
\newblock Vision based hand gesture recognition for human computer interaction:
  a survey.
\newblock {\em Artificial intelligence review 43}, 1 (2015), 1--54.

\bibitem{recht2019imagenet}
{\sc Recht, B., Roelofs, R., Schmidt, L., and Shankar, V.}
\newblock Do imagenet classifiers generalize to imagenet?, 2019.

\bibitem{redmon2016you}
{\sc Redmon, J., Divvala, S., Girshick, R., and Farhadi, A.}
\newblock You only look once: Unified, real-time object detection.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition\/} (2016), pp.~779--788.

\bibitem{rehm2013negative}
{\sc Rehm, M., and Krogsager, A.}
\newblock Negative affect in human robot interaction—impoliteness in
  unexpected encounters with robots.
\newblock In {\em 2013 IEEE RO-MAN\/} (2013), IEEE, pp.~45--50.

\bibitem{rehman_target_2017}
{\sc Rehman, S., Ashraf, T., Umair, M., Zubair, U., Ayaz, Y., and Khan, H.}
\newblock Target detection and tracking using intelligent wheelchair.
\newblock {\em International Journal of Simulation: Systems, Science and
  Technology 18}, 1 (2017), 4.1--4.8.
\newblock 0.

\bibitem{Ren_2018_ECCV}
{\sc Ren, Z., Lee, Y.~J., and Ryoo, M.~S.}
\newblock Learning to anonymize faces for privacy preserving action detection.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)\/} (September 2018).

\bibitem{rios2015proxemics}
{\sc Rios-Martinez, J., Spalanzani, A., and Laugier, C.}
\newblock From proxemics theory to socially-aware navigation: A survey.
\newblock {\em International Journal of Social Robotics 7}, 2 (2015), 137--153.

\bibitem{Robinette2017}
{\sc Robinette, P., Howard, A., and Wagner, A.~R.}
\newblock {\em Conceptualizing Overtrust in Robots: Why Do People Trust a Robot
  That Previously Failed?}
\newblock Springer International Publishing, Cham, 2017, pp.~129--155.

\bibitem{RobinsonSys}
{\sc Robinson, N.~L., Cottier, T.~V., and Kavanagh, D.~J.}
\newblock Psychosocial health interventions by social robots: Systematic review
  of randomized controlled trials.
\newblock {\em J Med Internet Res 21}, 5 (May 2019), e13203.

\bibitem{doi:10.1177/00187208211037465}
{\sc Rogers, W.~A., Kadylak, T., and Bayles, M.~A.}
\newblock Maximizing the benefits of participatory design for human–robot
  interaction research with older adults.
\newblock {\em Human Factors 0}, 0 (0), 00187208211037465.
\newblock PMID: 34461761.

\bibitem{7041588}
{\sc Roitberg, A., Perzylo, A., Somani, N., Giuliani, M., Rickert, M., and
  Knoll, A.}
\newblock Human activity recognition in the context of industrial human-robot
  interaction.
\newblock In {\em Signal and Information Processing Association Annual Summit
  and Conference (APSIPA), 2014 Asia-Pacific\/} (2014), pp.~1--10.

\bibitem{ronneberger2015unet}
{\sc Ronneberger, O., Fischer, P., and Brox, T.}
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em International Conference on Medical Image Computing and
  Computer-assisted Intervention\/} (2015), Springer, pp.~234--241.

\bibitem{sadigh2016planning}
{\sc Sadigh, D., Sastry, S., Seshia, S.~A., and Dragan, A.~D.}
\newblock Planning for autonomous cars that leverage effects on human actions.
\newblock In {\em Robotics: Science and systems\/} (2016), vol.~2, Ann Arbor,
  MI, USA, pp.~1--9.

\bibitem{saegusa_cognitive_2011}
{\sc Saegusa, R., Natale, L., Metta, G., and Sandini, G.}
\newblock Cognitive robotics-active perception of the self and others.
\newblock In {\em 4th {International} {Conference} on {Human} {System}
  {Interaction}, {HSI} 2011\/} (2011), pp.~419--426.
\newblock 9.

\bibitem{saffar_context-based_2015}
{\sc Saffar, M.~T., Nicolescu, M., Nicolescu, M., and Rekabdar, B.}
\newblock Context-based intent understanding using an {Activation} {Spreading}
  architecture.
\newblock In {\em 2015 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems} ({IROS})\/} (Sept. 2015),
  pp.~3002--3009.
\newblock 1.

\bibitem{saichinmayi_gesture_2015}
{\sc SaiChinmayi, N., Hasitha, C., Sravya, B., and Mittal, V.~K.}
\newblock Gesture signals processing for a silent spybot.
\newblock In {\em 2015 2nd {International} {Conference} on {Signal}
  {Processing} and {Integrated} {Networks} ({SPIN})\/} (Feb. 2015),
  pp.~756--761.
\newblock 7.

\bibitem{saleh_nonverbal_2015}
{\sc Saleh, S., and Berns, K.}
\newblock Nonverbal communication with a humanoid robot via head gestures.
\newblock In {\em 8th {ACM} {International} {Conference} on {PErvasive}
  {Technologies} {Related} to {Assistive} {Environments}, {PETRA} 2015 -
  {Proceedings}\/} (2015).
\newblock 8.

\bibitem{sanchez-matilla_benchmark_2020}
{\sc Sanchez-Matilla, R., Chatzilygeroudis, K., Modas, A., Duarte, N.~F.,
  Xompero, A., Frossard, P., Billard, A., and Cavallaro, A.}
\newblock Benchmark for {Human}-to-{Robot} {Handovers} of {Unseen} {Containers}
  {With} {Unknown} {Filling}.
\newblock {\em IEEE Robotics and Automation Letters 5}, 2 (Apr. 2020),
  1642--1649.
\newblock 11.

\bibitem{sanna_kinect-based_2012}
{\sc Sanna, A., Lamberti, F., Paravati, G., Henao~Ramirez, E., and Manuri, F.}
\newblock A kinect-based natural interface for quadrotor control.
\newblock {\em Lecture Notes of the Institute for Computer Sciences,
  Social-Informatics and Telecommunications Engineering 78 LNICST\/} (2012),
  48--56.
\newblock 150.

\bibitem{santos_copyrobot_2020}
{\sc Santos, L., Geminiani, A., Olivieri, I., Santos-Victor, J., and Pedrocchi,
  A.}
\newblock {CopyRobot}: {Interactive} {Mirroring} {Robotics} {Game} for {ASD}
  {Children}.
\newblock In {\em {IFMBE} {Proceedings}\/} (2020), vol.~76, pp.~2014--2027.
\newblock 3.

\bibitem{saunderson2019robots}
{\sc Saunderson, S., and Nejat, G.}
\newblock How robots influence humans: A survey of nonverbal communication in
  social human--robot interaction.
\newblock {\em International Journal of Social Robotics 11}, 4 (2019),
  575--608.

\bibitem{saveriano_safe_2014}
{\sc Saveriano, M., and Lee, D.}
\newblock Safe motion generation and online reshaping using dynamical systems.
\newblock In {\em 2014 11th {International} {Conference} on {Ubiquitous}
  {Robots} and {Ambient} {Intelligence} ({URAI})\/} (Nov. 2014), pp.~45--45.
\newblock 2.

\bibitem{scheggi_human-robot_2014}
{\sc Scheggi, S., Morbidi, F., and Prattichizzo, D.}
\newblock Human-robot formation control via visual and vibrotactile haptic
  feedback.
\newblock {\em IEEE Transactions on Haptics 7}, 4 (2014), 499--511.
\newblock 42.

\bibitem{schmidt_contact-less_2013}
{\sc Schmidt, B., and Wang, L.}
\newblock Contact-less and programming-less human-robot collaboration.
\newblock In {\em Procedia {CIRP}\/} (2013), vol.~7, pp.~545--550.
\newblock 27.

\bibitem{10.1007/978-3-030-28619-4_14}
{\sc Schmidt, T., and Fox, D.}
\newblock Self-directed lifelong learning for robot vision.
\newblock In {\em Robotics Research\/} (Cham, 2020), N.~M. Amato, G.~Hager,
  S.~Thomas, and M.~Torres-Torriti, Eds., Springer International Publishing,
  pp.~109--114.

\bibitem{scimmi_experimental_2019}
{\sc Scimmi, L., Melchiorre, M., Mauro, S., and Pastorelli, S.}
\newblock Experimental {Real}-{Time} {Setup} for {Vision} {Driven}
  {Hand}-{Over} with a {Collaborative} {Robot}.
\newblock In {\em 2019 {International} {Conference} on {Control}, {Automation}
  and {Diagnosis}, {ICCAD} 2019 - {Proceedings}\/} (2019).
\newblock 5.

\bibitem{shahroudy_ntu_2016}
{\sc Shahroudy, A., Liu, J., Ng, T., and Wang, G.}
\newblock {NTU} {RGB}+{D}: {A} {Large} {Scale} {Dataset} for {3D} {Human}
  {Activity} {Analysis}.
\newblock In {\em 2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern}
  {Recognition} ({CVPR})\/} (June 2016).
\newblock NoCitationData[s0].

\bibitem{shakev_autonomous_2018}
{\sc Shakev, N., Ahmed, S., Topalov, A., Popov, V., and Shiev, K.}
\newblock Autonomous flight control and precise gestural positioning of a small
  quadrotor.
\newblock {\em Studies in Computational Intelligence 756\/} (2018), 179--197.
\newblock 2.

\bibitem{shariatee_safe_2017}
{\sc Shariatee, M., Khosravi, H., and Fazl-Ersi, E.}
\newblock Safe collaboration of humans and {SCARA} robots.
\newblock In {\em 4th {RSI} {International} {Conference} on {Robotics} and
  {Mechatronics}, {ICRoM} 2016\/} (2017), pp.~589--594.
\newblock 6.

\bibitem{10.1007/978-3-030-58542-6_7}
{\sc Shibuya, M., Sumikura, S., and Sakurada, K.}
\newblock Privacy preserving visual slam.
\newblock In {\em Computer Vision -- ECCV 2020\/} (Cham, 2020), A.~Vedaldi,
  H.~Bischof, T.~Brox, and J.-M. Frahm, Eds., Springer International
  Publishing, pp.~102--118.

\bibitem{shieh_fuzzy_2014}
{\sc Shieh, M.-Y., Hsieh, C.-Y., and Hsieh, T.-M.}
\newblock Fuzzy visual detection for human-robot interaction.
\newblock {\em Engineering Computations (Swansea, Wales) 31}, 8 (2014),
  1709--1719.
\newblock 2.

\bibitem{shukla_probabilistic_2015}
{\sc Shukla, D., Erkent, O., and Piater, J.}
\newblock Probabilistic {Detection} of {Pointing} {Directions} for
  {Human}-{Robot} {Interaction}.
\newblock In {\em 2015 {International} {Conference} on {Digital} {Image}
  {Computing}: {Techniques} and {Applications} ({DICTA})\/} (2015), pp.~1--8.

\bibitem{shukla_proactive_2017}
{\sc Shukla, D., Erkent, O., and Piater, J.}
\newblock Proactive, incremental learning of gesture-action associations for
  human-robot collaboration.
\newblock In {\em 2017 26th {IEEE} {International} {Symposium} on {Robot} and
  {Human} {Interactive} {Communication} ({RO}-{MAN})\/} (2017), pp.~346--353.

\bibitem{silva_mirroring_2016}
{\sc Silva, V., Soares, F., and Esteves, J.~S.}
\newblock Mirroring emotion system - on-line synthesizing facial expressions on
  a robot face.
\newblock In {\em 2016 8th {International} {Congress} on {Ultra} {Modern}
  {Telecommunications} and {Control} {Systems} and {Workshops} ({ICUMT})\/}
  (Oct. 2016), pp.~213--218.
\newblock 6.

\bibitem{simul_support_2016}
{\sc Simul, N.~S., Ara, N.~M., and Islam, M.~S.}
\newblock A support vector machine approach for real time vision based human
  robot interaction.
\newblock In {\em 2016 19th {International} {Conference} on {Computer} and
  {Information} {Technology} ({ICCIT})\/} (Dec. 2016), pp.~496--500.
\newblock 6.

\bibitem{sisbot_synthesizing_2010}
{\sc Sisbot, E., Marin-Urias, L., Broquère, X., Sidobre, D., and Alami, R.}
\newblock Synthesizing robot motions adapted to human presence: {A} planning
  and control framework for safe and socially acceptable robot motions.
\newblock {\em International Journal of Social Robotics 2}, 3 (2010), 329--343.
\newblock 135.

\bibitem{song_towards_2017}
{\sc Song, H., Feng, W., Guan, N., Huang, X., and Luo, Z.}
\newblock Towards robust ego-centric hand gesture analysis for robot control.
\newblock In {\em 2016 {IEEE} {International} {Conference} on {Signal} and
  {Image} {Processing}, {ICSIP} 2016\/} (2017), pp.~661--666.
\newblock 3.

\bibitem{sorostinean_activity_2018}
{\sc Sorostinean, M., and Tapus, A.}
\newblock Activity {Recognition} {Based} on {RGB}-{D} and {Thermal} {Sensors}
  for {Socially} {Assistive} {Robots}.
\newblock In {\em 2018 15th {International} {Conference} on {Control},
  {Automation}, {Robotics} and {Vision}, {ICARCV} 2018\/} (2018),
  pp.~1298--1304.
\newblock 1.

\bibitem{sosnowski_mirror_2010}
{\sc Sosnowski, S., Mayer, C., Kühnlenz, K., and Radig, B.}
\newblock Mirror my emotions! {Combining} facial expression analysis and
  synthesis on a robot.
\newblock In {\em Proceedings of the 2nd {International} {Symposium} on {New}
  {Frontiers} in {Human}-{Robot} {Interaction} - {A} {Symposium} at the {AISB}
  2010 {Convention}\/} (2010), pp.~108--112.
\newblock 7.

\bibitem{sripada_teleoperation_2019}
{\sc Sripada, A., Asokan, H., Warrier, A., Kapoor, A., Gaur, H., Patel, R., and
  Sridhar, R.}
\newblock Teleoperation of a {Humanoid} {Robot} with {Motion} {Imitation} and
  {Legged} {Locomotion}.
\newblock In {\em {ICARM} 2018 - 2018 3rd {International} {Conference} on
  {Advanced} {Robotics} and {Mechatronics}\/} (2019), pp.~375--379.
\newblock 4.

\bibitem{sriram_mobile_2019}
{\sc Sriram, K., and Palaniswamy, S.}
\newblock Mobile robot assistance for disabled and senior citizens using hand
  gestures.
\newblock In {\em 1st {International} {Conference} on {Power} {Electronics}
  {Applications} and {Technology} in {Present} {Energy} {Scenario}, {PETPES}
  2019 - {Proceedings}\/} (2019).
\newblock 1.

\bibitem{stipancic_programming_2012}
{\sc Stipancic, T., Jerbic, B., Bucevic, A., and Curkovic, P.}
\newblock Programming an industrial robot by demonstration.
\newblock In {\em 23rd {DAAAM} {International} {Symposium} on {Intelligent}
  {Manufacturing} and {Automation} 2012\/} (2012), vol.~1, pp.~15--18.
\newblock 11.

\bibitem{suma2019computer}
{\sc Suma, V.}
\newblock Computer vision for human-machine interaction-review.
\newblock {\em Journal of trends in Computer Science and Smart technology
  (TCSST) 1}, 02 (2019), 131--139.

\bibitem{12_intelligent_2019}
{\sc Sun, X., Zhao, R., Khattak, A.~M., Shi, K., Ren, Y., Gao, W., and Wang,
  M.}
\newblock Intelligent {Interactive} {Robot} {System} for {Agricultural}
  {Knowledge} {Popularity} and {Achievements} {Display}.
\newblock In {\em 2019 {IEEE} 4th {Advanced} {Information} {Technology},
  {Electronic} and {Automation} {Control} {Conference} ({IAEAC})\/} (Dec.
  2019), vol.~1, pp.~511--518.
\newblock 0.

\bibitem{sun_visual_2019}
{\sc Sun, Y., Liang, X., Fan, H., Imran, M., and Heidari, H.}
\newblock Visual {Hand} {Tracking} on {Depth} {Image} using 2-{D} {Matched}
  {Filter}.
\newblock In {\em 2019 {UK}/ {China} {Emerging} {Technologies} ({UCET})\/}
  (Aug. 2019), pp.~1--4.
\newblock 4.

\bibitem{sunderhauf2018limits}
{\sc S{\"u}nderhauf, N., Brock, O., Scheirer, W., Hadsell, R., Fox, D.,
  Leitner, J., Upcroft, B., Abbeel, P., Burgard, W., Milford, M., et~al.}
\newblock The limits and potentials of deep learning for robotics.
\newblock {\em The International journal of robotics research 37}, 4-5 (2018),
  405--420.

\bibitem{susperregi2013rgb}
{\sc Susperregi, L., Mart{\'\i}nez-Otzeta, J.~M., Ansuategui, A., Ibarguren,
  A., and Sierra, B.}
\newblock {RGB-D}, laser and thermal sensor fusion for people following in a
  mobile robot.
\newblock {\em International Journal of Advanced Robotic Systems 10}, 6 (2013),
  271.

\bibitem{svarny_safe_2019}
{\sc Svarny, P., Tesar, M., Behrens, J.~K., and Hoffmann, M.}
\newblock Safe physical {HRI}: {Toward} a unified treatment of speed and
  separation monitoring together with power and force limiting.
\newblock In {\em 2019 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems} ({IROS})\/} (Nov. 2019), pp.~7580--7587.
\newblock 8.

\bibitem{taheri_social_2014}
{\sc Taheri, A., Alemi, M., Meghdari, A., Pouretemad, H., and Basiri, N.}
\newblock Social robots as assistants for autism therapy in {Iran}: {Research}
  in progress.
\newblock In {\em 2014 2nd {RSI}/{ISM} {International} {Conference} on
  {Robotics} and {Mechatronics}, {ICRoM} 2014\/} (2014), pp.~760--766.
\newblock 36.

\bibitem{talebpour-board_2016}
{\sc Talebpour, Z., Navarro, I., and Martinoli, A.}
\newblock On-board human-aware navigation for indoor resource-constrained
  robots: {A} case-study with the ranger.
\newblock In {\em 2015 {IEEE}/{SICE} {International} {Symposium} on {System}
  {Integration}, {SII} 2015\/} (2016), pp.~63--68.
\newblock 5.

\bibitem{tan_safety_2010}
{\sc Tan, J., Duan, F., Kato, R., and Arai, T.}
\newblock Safety strategy for human-robot collaboration: {Design} and
  development in cellular manufacturing.
\newblock {\em Advanced Robotics 24}, 5-6 (2010), 839--860.
\newblock 32.

\bibitem{tao_multilayer_2013}
{\sc Tao, C., and Liu, G.}
\newblock A multilayer hidden markov models-based method for human-robot
  interaction.
\newblock {\em Mathematical Problems in Engineering 2013\/} (2013).
\newblock 2.

\bibitem{tarbouriech_bi-objective_2020}
{\sc Tarbouriech, S., and Suleiman, W.}
\newblock Bi-objective {Motion} {Planning} {Approach} for {Safe} {Motions}:
  {Application} to a {Collaborative} {Robot}.
\newblock {\em Journal of Intelligent and Robotic Systems: Theory and
  Applications 99}, 1 (2020), 45--63.
\newblock 0.

\bibitem{taylor2020robot}
{\sc Taylor, A., Chan, D.~M., and Riek, L.~D.}
\newblock Robot-centric perception of human groups.
\newblock {\em ACM Transactions on Human-Robot Interaction (THRI) 9}, 3 (2020),
  1--21.

\bibitem{taylor2016robot}
{\sc Taylor, A., and Riek, L.~D.}
\newblock Robot perception of human groups in the real world: State of the art.
\newblock In {\em 2016 AAAI Fall Symposium Series\/} (2016).

\bibitem{terreran_low-cost_2020}
{\sc Terreran, M., Lamon, E., Michieletto, S., and Pagello, E.}
\newblock Low-cost scalable people tracking system for human-robot
  collaboration in industrial environment.
\newblock In {\em Procedia {Manufacturing}\/} (2020), vol.~51, pp.~116--124.
\newblock 2.

\bibitem{tezza2019state}
{\sc Tezza, D., and Andujar, M.}
\newblock The state-of-the-art of human--drone interaction: A survey.
\newblock {\em IEEE Access 7\/} (2019), 167438--167454.

\bibitem{10.1145/3371382.3378347}
{\sc Thellman, S., Silvervarg, A., and Ziemke, T.}
\newblock Anthropocentric attribution bias in human prediction of robot
  behavior.
\newblock In {\em Companion of the 2020 ACM/IEEE International Conference on
  Human-Robot Interaction\/} (New York, NY, USA, 2020), HRI '20, Association
  for Computing Machinery, p.~476–478.

\bibitem{socialerrorsHRI}
{\sc Tian, L., and Oviatt, S.}
\newblock A taxonomy of social errors in human-robot interaction.
\newblock {\em J. Hum.-Robot Interact. 10}, 2 (Feb. 2021).

\bibitem{tornow2013multi}
{\sc Tornow, M., Al-Hamadi, A., and Borrmann, V.}
\newblock A multi-agent mobile robot system with environment perception and hmi
  capabilities.
\newblock In {\em 2013 IEEE International Conference on Signal and Image
  Processing Applications\/} (2013), IEEE, pp.~252--257.

\bibitem{torres_implementation_2012}
{\sc Torres, N., Clark, N., Ranatunga, I., and Popa, D.}
\newblock Implementation of interactive arm playback behaviors of social robot
  {Zeno} for autism spectrum disorder therapy.
\newblock In {\em {ACM} {International} {Conference} {Proceeding} {Series}\/}
  (2012).
\newblock 18.

\bibitem{triggs2007scene}
{\sc Triggs, B., and Verbeek, J.}
\newblock Scene segmentation with crfs learned from partially labeled images.
\newblock {\em Advances in Neural Information Processing Systems 20\/} (2007).

\bibitem{tseng_multi-human_2014}
{\sc Tseng, S.-H., Hsu, Y.-H., Chiang, Y.-S., Wu, T.-Y., and Fu, L.-C.}
\newblock Multi-human spatial social pattern understanding for a multi-modal
  robot through nonverbal social signals.
\newblock In {\em {IEEE} {RO}-{MAN} 2014 - 23rd {IEEE} {International}
  {Symposium} on {Robot} and {Human} {Interactive} {Communication}:
  {Human}-{Robot} {Co}-{Existence}: {Adaptive} {Interfaces} and {Systems} for
  {Daily} {Life}, {Therapy}, {Assistance} and {Socially} {Engaging}
  {Interactions}\/} (2014), pp.~531--536.
\newblock 5.

\bibitem{tsiami_multi3_2018}
{\sc Tsiami, A., Koutras, P., Efthymiou, N., Filntisis, P.~P., Potamianos, G.,
  and Maragos, P.}
\newblock Multi3: {Multi}-{Sensory} {Perception} {System} for {Multi}-{Modal}
  {Child} {Interaction} with {Multiple} {Robots}.
\newblock In {\em 2018 {IEEE} {International} {Conference} on {Robotics} and
  {Automation} ({ICRA})\/} (May 2018), pp.~4585--4592.
\newblock ISSN: 2577-087X.

\bibitem{tolgyessy_foundations_2017}
{\sc Tölgyessy, M., Dekan, M., Duchoň, F., Rodina, J., Hubinský, P., and
  Chovanec, L.}
\newblock Foundations of {Visual} {Linear} {Human}–{Robot} {Interaction} via
  {Pointing} {Gesture} {Navigation}.
\newblock {\em International Journal of Social Robotics 9}, 4 (2017), 509--523.
\newblock 16.

\bibitem{ueno2014efficient}
{\sc Ueno, S., Naito, S., and Chen, T.}
\newblock An efficient method for human pointing estimation for robot
  interaction.
\newblock In {\em 2014 IEEE International Conference on Image Processing
  (ICIP)\/} (2014), IEEE, pp.~1545--1549.

\bibitem{uribe_mobile_2011}
{\sc Uribe, A., Alves, S., Rosário, J.~M., Filho, H.~F., and
  Pérez-Gutiérrez, B.}
\newblock Mobile robotic teleoperation using gesture-based human interfaces.
\newblock In {\em {IX} {Latin} {American} {Robotics} {Symposium} and {IEEE}
  {Colombian} {Conference} on {Automatic} {Control}, 2011 {IEEE}\/} (Oct.
  2011), pp.~1--6.
\newblock 10.

\bibitem{valipour_incremental_2017}
{\sc Valipour, S., Perez, C., and Jagersand, M.}
\newblock Incremental learning for robot perception through {HRI}.
\newblock In {\em 2017 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems} ({IROS})\/} (Sept. 2017),
  pp.~2772--2777.
\newblock 16.

\bibitem{valle_personalized_2019}
{\sc Valle, A., Alenyà, G., Chance, G., Caleb-Solly, P., Dogramadzi, S., and
  Torras, C.}
\newblock Personalized {Robot} {Assistant} for {Support} in {Dressing}.
\newblock {\em IEEE Transactions on Cognitive and Developmental Systems 11}, 3
  (2019), 363--374.
\newblock 17.

\bibitem{van_den_bergh_real-time_2011}
{\sc Van Den~Bergh, M., Carton, D., De~Nijs, R., Mitsou, N., Landsiedel, C.,
  Kuehnlenz, K., Wollherr, D., Van~Gool, L., and Buss, M.}
\newblock Real-time {3D} hand gesture interaction with a robot for
  understanding directions from humans.
\newblock In {\em Proceedings - {IEEE} {International} {Workshop} on {Robot}
  and {Human} {Interactive} {Communication}\/} (2011), pp.~357--362.
\newblock 226.

\bibitem{van_den_broek_ergonomic_2020}
{\sc Van Den~Broek, M., and Moeslund, T.}
\newblock Ergonomic adaptation of robotic movements in human-robot
  collaboration.
\newblock In {\em {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot}
  {Interaction}\/} (2020), pp.~499--501.
\newblock 0.

\bibitem{vasconcelos_socially_2016}
{\sc Vasconcelos, P., Pereira, H., Macharet, D., and Nascimento, E.}
\newblock Socially {Acceptable} {Robot} {Navigation} in the {Presence} of
  {Humans}.
\newblock In {\em Proceedings - 12th {LARS} {Latin} {American} {Robotics}
  {Symposium} and 3rd {SBR} {Brazilian} {Robotics} {Symposium}, {LARS}-{SBR}
  2015 - {Part} of the {Robotics} {Conferences} 2015\/} (2016), pp.~222--227.
\newblock 4.

\bibitem{VASCONEZ201935}
{\sc Vasconez, J.~P., Kantor, G.~A., and {Auat Cheein}, F.~A.}
\newblock Human–robot interaction in agriculture: A survey and current
  challenges.
\newblock {\em Biosystems Engineering 179\/} (2019), 35 -- 48.

\bibitem{vasquez_deep_2017}
{\sc Vasquez, A., Kollmitz, M., Eitel, A., and Burgard, W.}
\newblock Deep {Detection} of {People} and their {Mobility} {Aids} for a
  {Hospital} {Robot}.
\newblock In {\em 2017 {European} {Conference} on {Mobile} {Robots}, {ECMR}
  2017\/} (2017).
\newblock 11.

\bibitem{vaswani2017attention}
{\sc Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,
  A.~N., Kaiser, {\L}., and Polosukhin, I.}
\newblock Attention is all you need.
\newblock {\em Advances in Neural Information Processing Systems 30\/} (2017).

\bibitem{vaufreydaz_starting_2016}
{\sc Vaufreydaz, D., Johal, W., and Combe, C.}
\newblock Starting engagement detection towards a companion robot using
  multimodal features.
\newblock {\em Robotics and Autonomous Systems 75\/} (2016), 4--16.
\newblock 36.

\bibitem{vazquez2015parallel}
{\sc V{\'a}zquez, M., Steinfeld, A., and Hudson, S.~E.}
\newblock Parallel detection of conversational groups of free-standing people
  and tracking of their lower-body orientation.
\newblock In {\em 2015 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)\/} (2015), IEEE, pp.~3010--3017.

\bibitem{vazquez2016maintaining}
{\sc V{\'a}zquez, M., Steinfeld, A., and Hudson, S.~E.}
\newblock Maintaining awareness of the focus of attention of a conversation: A
  robot-centric reinforcement learning approach.
\newblock In {\em 2016 25th IEEE International Symposium on Robot and Human
  Interactive Communication (RO-MAN)\/} (2016), IEEE, pp.~36--43.

\bibitem{vignolo_computational_2017}
{\sc Vignolo, A., Sciutti, A., Rea, F., Noceti, N., Odone, F., and Sandini, G.}
\newblock Computational vision for social intelligence.
\newblock In {\em {AAAI} {Spring} {Symposium} - {Technical} {Report}\/} (2017),
  vol.~SS-17-01 - SS-17-08, pp.~647--651.
\newblock 0.

\bibitem{VILLANI2018248}
{\sc Villani, V., Pini, F., Leali, F., and Secchi, C.}
\newblock Survey on human–robot collaboration in industrial settings: Safety,
  intuitive interfaces and applications.
\newblock {\em Mechatronics 55\/} (2018), 248--266.

\bibitem{viola2001rapid}
{\sc Viola, P., and Jones, M.}
\newblock Rapid object detection using a boosted cascade of simple features.
\newblock In {\em Proceedings of the Conference on Computer Vision and Pattern
  Recognition\/} (2001), vol.~1, IEEE.

\bibitem{viola_robust_2004}
{\sc Viola, P., and Jones, M.~J.}
\newblock Robust {Real}-{Time} {Face} {Detection}.
\newblock {\em International Journal of Computer Vision\/} (2004).
\newblock 16072.

\bibitem{vircikova_teach_2015}
{\sc Virčíkova, M., and Sinčák, P.}
\newblock Teach your robot how you want it to express emotions: {On} the
  personalized affective human-humanoid interaction.
\newblock {\em Advances in Intelligent Systems and Computing 316\/} (2015),
  81--92.
\newblock 0.

\bibitem{voisan_ros-based_2015}
{\sc Voisan, E.-I., Paulis, B., Precup, R.-E., and Dragan, F.}
\newblock {ROS}-based robot navigation and human interaction in indoor
  environment.
\newblock In {\em 2015 {IEEE} 10th {Jubilee} {International} {Symposium} on
  {Applied} {Computational} {Intelligence} and {Informatics}\/} (May 2015),
  pp.~31--36.
\newblock 15.

\bibitem{vu15heads}
{\sc Vu, T., Osokin, A., and Laptev, I.}
\newblock Context-aware {CNNs} for person head detection.
\newblock In {\em International Conference on Computer Vision (ICCV)\/} (2015).

\bibitem{vysocky_interaction_2019}
{\sc Vysocký, A., Pastor, R., and Novák, P.}
\newblock Interaction with {Collaborative} {Robot} {Using} {2D} and {TOF}
  {Camera}.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 11472
  LNCS\/} (2019), 477--489.
\newblock 3.

\bibitem{wang_action_2011}
{\sc Wang, H., Klaser, A., Schmid, C., and Liu, C.-L.}
\newblock Action recognition by dense trajectories.
\newblock In {\em Computer {Vision} and {Pattern} {Recognition} ({CVPR})\/}
  (June 2011).

\bibitem{wang_vision-guided_2013}
{\sc Wang, L., Schmidt, B., and Nee, A.}
\newblock Vision-guided active collision avoidance for human-robot
  collaborations.
\newblock {\em Manufacturing Letters 1}, 1 (2013), 5--8.
\newblock 64.

\bibitem{wang_wheeled_2013}
{\sc Wang, Y., Song, G., Qiao, G., Zhang, Y., Zhang, J., and Wang, W.}
\newblock Wheeled robot control based on gesture recognition using the {Kinect}
  sensor.
\newblock In {\em 2013 {IEEE} {International} {Conference} on {Robotics} and
  {Biomimetics}, {ROBIO} 2013\/} (2013), pp.~378--383.
\newblock 15.

\bibitem{wang_collision-free_2017}
{\sc Wang, Y., Ye, X., Yang, Y., and Zhang, W.}
\newblock Collision-free trajectory planning in human-robot interaction through
  hand movement prediction from vision.
\newblock In {\em {IEEE}-{RAS} {International} {Conference} on {Humanoid}
  {Robots}\/} (2017), pp.~305--310.
\newblock 14.

\bibitem{waskito_wheeled_2020}
{\sc Waskito, T., Sumaryo, S., and Setianingsih, C.}
\newblock Wheeled {Robot} {Control} with {Hand} {Gesture} based on {Image}
  {Processing}.
\newblock In {\em Proceedings - 2020 {IEEE} {International} {Conference} on
  {Industry} 4.0, {Artificial} {Intelligence}, and {Communications}
  {Technology}, {IAICT} 2020\/} (2020), pp.~48--54.
\newblock 0.

\bibitem{weber_follow_2018}
{\sc Weber, T., Triputen, S., Danner, M., Braun, S., Schreve, K., and Rätsch,
  M.}
\newblock Follow me: {Real}-time in the wild person tracking application for
  autonomous robotics.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 11175
  LNAI\/} (2018), 156--167.
\newblock 1.

\bibitem{wei_convolutional_2016}
{\sc Wei, S.-E., Ramakrishna, V., Kanade, T., and Sheikh, Y.}
\newblock Convolutional {Pose} {Machines}.
\newblock In {\em 2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern}
  {Recognition} ({CVPR})\/} (Las Vegas, NV, USA, June 2016), IEEE,
  pp.~4724--4732.
\newblock 2026.

\bibitem{weinrich_appearance-based_2013}
{\sc Weinrich, C., Volkhardt, M., and Gross, H.-M.}
\newblock Appearance-based {3D} upper-body pose estimation and person
  re-identification on mobile robots.
\newblock In {\em Proceedings - 2013 {IEEE} {International} {Conference} on
  {Systems}, {Man}, and {Cybernetics}, {SMC} 2013\/} (2013), pp.~4384--4390.
\newblock 14.

\bibitem{weiss_robots_2010}
{\sc Weiss, A., Igelsböck, J., Tscheligi, M., Bauer, A., Kühnlenz, K.,
  Wollherr, D., and Buss, M.}
\newblock Robots {Asking} for {Directions}: {The} {Willingness} of {Passers}-by
  to {Support} {Robots}.
\newblock In {\em Proceedings of the 5th {ACM}/{IEEE} {International}
  {Conference} on {Human}-{Robot} {Interaction}\/} (2010), {HRI} '10, IEEE
  Press, pp.~23--30.
\newblock 88.

\bibitem{werner_evaluation_2013}
{\sc Werner, F., Krainer, D., Oberzaucher, J., and Werner, K.}
\newblock Evaluation of the acceptance of a social assistive robot for physical
  training support together with older users and domain experts.
\newblock {\em Assistive Technology Research Series 33\/} (2013), 137--142.
\newblock 6.

\bibitem{wu_accompanist_2012}
{\sc Wu, B.-F., Jen, C.-L., Tsou, T.-Y., Li, W.-F., and Tseng, P.-Y.}
\newblock Accompanist detection and following for wheelchair robots with fuzzy
  controller.
\newblock In {\em 2012 {International} {Conference} {onAdvanced} {Mechatronic}
  {Systems}, {ICAMechS} 2012\/} (2012), pp.~638--643.
\newblock 7.

\bibitem{wu_improved_2019}
{\sc Wu, Y., Yang, Q., and Zhou, X.}
\newblock An improved method of optical flow using human body-following wheeled
  robot.
\newblock {\em International Journal of Modeling, Simulation, and Scientific
  Computing 10}, 2 (2019).
\newblock 1.

\bibitem{wu_toward_2020}
{\sc Wu, Z., and Payandeh, S.}
\newblock Toward {Design} of a {Drip}-{Stand} {Patient} {Follower} {Robot}.
\newblock {\em Journal of Robotics 2020\/} (2020).
\newblock 1.

\bibitem{xia_vision-based_2019}
{\sc Xia, Z., Lei, Q., Yang, Y., Zhang, H., He, Y., Wang, W., and Huang, M.}
\newblock Vision-{Based} {Hand} {Gesture} {Recognition} for {Human}-{Robot}
  {Collaboration}: {A} {Survey}.
\newblock In {\em 2019 5th {International} {Conference} on {Control},
  {Automation} and {Robotics} ({ICCAR})\/} (2019), pp.~198--205.

\bibitem{xiao_human-robot_2014}
{\sc Xiao, Y., Zhang, Z., Beck, A., Yuan, J., and Thalmann, D.}
\newblock Human-{Robot} {Interaction} by {Understanding} {Upper} {Body}
  {Gestures}.
\newblock {\em Presence: Teleoperators and Virtual Environments 23}, 2 (2014),
  133--154.
\newblock 66.

\bibitem{xu_online_2014}
{\sc Xu, D., Wu, X., Chen, Y.-L., and Xu, Y.}
\newblock Online {Dynamic} {Gesture} {Recognition} for {Human} {Robot}
  {Interaction}.
\newblock {\em Journal of Intelligent and Robotic Systems: Theory and
  Applications 77}, 3-4 (2014), 583--596.
\newblock 61.

\bibitem{xu_skeleton_2020}
{\sc Xu, J., Li, J., Zhang, S., Xie, C., and Dong, J.}
\newblock Skeleton {Guided} {Conflict}-{Free} {Hand} {Gesture} {Recognition}
  for {Robot} {Control}.
\newblock In {\em 2020 11th {International} {Conference} on {Awareness}
  {Science} and {Technology} ({iCAST})\/} (Dec. 2020), pp.~1--6.
\newblock 0.

\bibitem{yamakawa2018human}
{\sc Yamakawa, Y., Matsui, Y., and Ishikawa, M.}
\newblock Human--robot collaborative manipulation using a high-speed robot hand
  and a high-speed camera.
\newblock In {\em 2018 IEEE International Conference on Cyborg and Bionic
  Systems (CBS)\/} (2018), IEEE, pp.~426--429.

\bibitem{yamamoto20112d}
{\sc Yamamoto, T., Yamada, Y., Onishi, M., and Nakabo, Y.}
\newblock A 2d safety vision system for human-robot collaborative work
  environments based upon the safety preservation design policy.
\newblock In {\em 2011 IEEE International Conference on Robotics and
  Biomimetics\/} (2011), IEEE, pp.~2049--2054.

\bibitem{yan2014survey}
{\sc Yan, H., Ang, M.~H., and Poo, A.~N.}
\newblock A survey on perception methods for human--robot interaction in social
  robots.
\newblock {\em International Journal of Social Robotics 6}, 1 (2014), 85--119.

\bibitem{yan_optimization_2020}
{\sc Yan, J., Chen, C., Wang, Z., Zhao, L., and Li, D.}
\newblock An {Optimization} {Method} for {Human}-{Robot} {Collaboration} in a
  {Production} {Unit} in the {Context} of {Intelligent} {Manufacturing}.
\newblock In {\em 2020 {The} 8th {International} {Conference} on {Information}
  {Technology}: {IoT} and {Smart} {City}\/} (New York, NY, USA, 2020), {ICIT}
  2020, Association for Computing Machinery, pp.~244--250.
\newblock 0.

\bibitem{yanco2004classifying}
{\sc Yanco, H.~A., and Drury, J.}
\newblock Classifying human-robot interaction: an updated taxonomy.
\newblock In {\em IEEE International Conference on Systems, Man and
  Cybernetics\/} (2004), vol.~3, IEEE, pp.~2841--2846.

\bibitem{yang_socially-aware_2019}
{\sc Yang, C.-T., Zhang, T., Chen, L.-P., and Fu, L.-C.}
\newblock Socially-aware navigation of omnidirectional mobile robot with
  extended social force model in multi-human environment.
\newblock In {\em Conference {Proceedings} - {IEEE} {International}
  {Conference} on {Systems}, {Man} and {Cybernetics}\/} (2019),
  vol.~2019-October, pp.~1963--1968.
\newblock 4.

\bibitem{9743954}
{\sc Yang, D., Zhang, H., Yurtsever, E., Redmill, K.~A., and Özgüner, U.}
\newblock Predicting pedestrian crossing intention with feature fusion and
  spatio-temporal attention.
\newblock {\em IEEE Transactions on Intelligent Vehicles 7}, 2 (2022),
  221--230.

\bibitem{yang_study_2013}
{\sc Yang, N., Duan, F., Wei, Y., Liu, C., Tan, J., Xu, B., and Zhang, J.}
\newblock A study of the human-robot synchronous control system based on
  skeletal tracking technology.
\newblock In {\em 2013 {IEEE} {International} {Conference} on {Robotics} and
  {Biomimetics}, {ROBIO} 2013\/} (2013), pp.~2191--2196.
\newblock 19.

\bibitem{yang2016wider}
{\sc Yang, S., Luo, P., Loy, C.~C., and Tang, X.}
\newblock Wider face: A face detection benchmark.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)\/} (2016).

\bibitem{yang_real-time_2015}
{\sc Yang, Y., Yan, H., Dehghan, M., and Ang, M.}
\newblock Real-time human-robot interaction in complex environment using kinect
  v2 image recognition.
\newblock In {\em Proceedings of the 2015 7th {IEEE} {International}
  {Conference} on {Cybernetics} and {Intelligent} {Systems}, {CIS} 2015 and
  {Robotics}, {Automation} and {Mechatronics}, {RAM} 2015\/} (2015),
  pp.~112--117.
\newblock 13.

\bibitem{yao_monocular_2017}
{\sc Yao, N., Anaya, E., Tao, Q., Cho, S., Zheng, H., and Zhang, F.}
\newblock Monocular vision-based human following on miniature robotic blimp.
\newblock In {\em Proceedings - {IEEE} {International} {Conference} on
  {Robotics} and {Automation}\/} (2017), pp.~3244--3249.
\newblock 34.

\bibitem{yoo_gaze_2017}
{\sc Yoo, B.-S., and Kim, J.-H.}
\newblock Gaze control of humanoid robot for learning from demonstration.
\newblock {\em Advances in Intelligent Systems and Computing 447\/} (2017),
  263--270.
\newblock 0.

\bibitem{yoshida_evaluation_2011}
{\sc Yoshida, K., Hibino, F., Takahashi, Y., and Maeda, Y.}
\newblock Evaluation of pointing navigation interface for mobile robot with
  spherical vision system.
\newblock In {\em {IEEE} {International} {Conference} on {Fuzzy} {Systems}\/}
  (2011), pp.~721--726.
\newblock 7.

\bibitem{yu_interactive_2019}
{\sc Yu, C., and Tapus, A.}
\newblock Interactive {Robot} {Learning} for {Multimodal} {Emotion}
  {Recognition}.
\newblock {\em Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 11876
  LNAI\/} (2019), 633--642.
\newblock 7.

\bibitem{yu_efficiency_2019}
{\sc Yu, J., and Paik, W.}
\newblock Efficiency and learnability comparison of the gesture-based and the
  mouse-based telerobotic systems.
\newblock {\em Studies in Informatics and Control 28}, 2 (2019), 213--220.
\newblock 2.

\bibitem{yuan_development_2018}
{\sc Yuan, W., and Li, Z.}
\newblock Development of a human-friendly robot for socially aware human-robot
  interaction.
\newblock In {\em 2017 2nd {International} {Conference} on {Advanced}
  {Robotics} and {Mechatronics}, {ICARM} 2017\/} (2018), vol.~2018-January,
  pp.~76--81.
\newblock 5.

\bibitem{yuan_natural_2020}
{\sc Yuan, X., Dai, S., and Fang, Y.}
\newblock A natural immersive closed-loop interaction method for
  human–{Robot} “{Rock}–{Paper}–{Scissors}” {Game}.
\newblock {\em Advances in Intelligent Systems and Computing 1031 AISC\/}
  (2020), 103--111.
\newblock 0.

\bibitem{yue_human-robot_2020}
{\sc Yue, Y., Liu, X., Wang, Y., Zhang, J., and Wang, D.}
\newblock Human-{Robot} {Teaming} and {Coordination} in {Day} and {Night}
  {Environments}.
\newblock In {\em 2020 16th {International} {Conference} on {Control},
  {Automation}, {Robotics} and {Vision} ({ICARCV})\/} (Dec. 2020),
  pp.~375--380.
\newblock 0.

\bibitem{yun_robust_2010}
{\sc Yun, S., Kim, C., Kim, M., and Choi, M.-T.}
\newblock Robust robot's attention for human based on the multi-modal sensor
  and robot behavior.
\newblock In {\em Proceedings of {IEEE} {Workshop} on {Advanced} {Robotics} and
  its {Social} {Impacts}, {ARSO}\/} (2010), pp.~117--122.
\newblock 3.

\bibitem{yun_robotic_2013}
{\sc Yun, W.-H., Cho, Y.-J., Kim, D., Lee, J., Yoon, H., and Kim, J.}
\newblock Robotic person-tracking with modified multiple instance learning.
\newblock In {\em Proceedings - {IEEE} {International} {Workshop} on {Robot}
  and {Human} {Interactive} {Communication}\/} (2013), pp.~198--203.
\newblock 1.

\bibitem{ZACHARAKI2020104667}
{\sc Zacharaki, A., Kostavelis, I., Gasteratos, A., and Dokas, I.}
\newblock Safety bounds in human robot interaction: A survey.
\newblock {\em Safety Science 127\/} (2020), 104667.

\bibitem{zambelli_multimodal_2016}
{\sc Zambelli, M., and Demiris, Y.}
\newblock Multimodal imitation using self-learned sensorimotor representations.
\newblock In {\em 2016 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems} ({IROS})\/} (Oct. 2016), pp.~3953--3958.
\newblock 5.

\bibitem{zardykhan_collision_2019}
{\sc Zardykhan, D., Svarny, P., Hoffmann, M., Shahriari, E., and Haddadin, S.}
\newblock Collision {Preventing} {Phase}-{Progress} {Control} for {Velocity}
  {Adaptation} in {Human}-{Robot} {Collaboration}.
\newblock In {\em {IEEE}-{RAS} {International} {Conference} on {Humanoid}
  {Robots}\/} (2019), vol.~2019-October, pp.~266--273.
\newblock 0.

\bibitem{zhang_gesture-based_2019}
{\sc Zhang, B., Du, G., Shen, W., and Li, F.}
\newblock Gesture-based human-robot interface for dual-robot with hybrid
  sensors.
\newblock {\em Industrial Robot: the international journal of robotics research
  and application 46}, 6 (Oct. 2019), 800--811.
\newblock 1.

\bibitem{zhang2013real}
{\sc Zhang, H., Reardon, C., and Parker, L.~E.}
\newblock Real-time multiple human perception with color-depth cameras on a
  mobile robot.
\newblock {\em IEEE Transactions on Cybernetics 43}, 5 (2013), 1429--1441.

\bibitem{zhang2019comprehensive}
{\sc Zhang, H.-B., Zhang, Y.-X., Zhong, B., Lei, Q., Yang, L., Du, J.-X., and
  Chen, D.-S.}
\newblock A comprehensive survey of vision-based human action recognition
  methods.
\newblock {\em Sensors 19}, 5 (2019), 1005.

\bibitem{zhang_human_2020}
{\sc Zhang, J., Li, P., Zhu, T., Zhang, W.-A., and Liu, S.}
\newblock Human {Motion} {Capture} {Based} on {Kinect} and {IMUs} and {Its}
  {Application} to {Human}-{Robot} {Collaboration}.
\newblock In {\em {ICARM} 2020 - 2020 5th {IEEE} {International} {Conference}
  on {Advanced} {Robotics} and {Mechatronics}\/} (2020), pp.~392--397.
\newblock 0.

\bibitem{zhang_indoor_2018}
{\sc Zhang, K., and Zhang, L.}
\newblock Indoor omni-directional mobile robot that track independently.
\newblock {\em Journal of Computers (Taiwan) 29}, 2 (2018), 118--135.
\newblock 0.

\bibitem{zhang_adaptive_2015}
{\sc Zhang, L., Mistry, K., Jiang, M., Chin~Neoh, S., and Hossain, M.}
\newblock Adaptive facial point detection and emotion recognition for a
  humanoid robot.
\newblock {\em Computer Vision and Image Understanding 140\/} (2015), 93--114.
\newblock 50.

\bibitem{zhang_optimal_2016}
{\sc Zhang, L., and Vaughan, R.}
\newblock Optimal robot selection by gaze direction in multi-human multi-robot
  interaction.
\newblock In {\em {IEEE} {International} {Conference} on {Intelligent} {Robots}
  and {Systems}\/} (2016), vol.~2016-November, pp.~5077--5083.
\newblock 13.

\bibitem{zhang_interactive_2018}
{\sc Zhang, L., and Zhang, K.}
\newblock An interactive control system for mobile robot based on cloud
  services.
\newblock {\em Concurrency Computation 30}, 24 (2018).
\newblock 3.

\bibitem{zhang_vision-based_2019}
{\sc Zhang, M., Liu, X., Xu, D., Cao, Z., and Yu, J.}
\newblock Vision-based target-following guider for mobile robot.
\newblock {\em IEEE Transactions on Industrial Electronics 66}, 12 (2019),
  9360--9371.
\newblock 15.

\bibitem{zhang_automating_2018}
{\sc Zhang, Z., Chen, Z., and Li, W.}
\newblock Automating {Robotic} {Furniture} with {A} {Collaborative}
  {Vision}-based {Sensing} {Scheme}.
\newblock In {\em {RO}-{MAN} 2018 - 27th {IEEE} {International} {Symposium} on
  {Robot} and {Human} {Interactive} {Communication}\/} (2018), pp.~719--725.
\newblock 0.

\bibitem{zhao_interactive_2013}
{\sc Zhao, C., Pan, W., and Hu, H.}
\newblock Interactive indoor environment mapping through visual tracking of
  human skeleton.
\newblock {\em International Journal of Modelling, Identification and Control
  20}, 4 (2013), 319--328.
\newblock 2.

\bibitem{zhao2016intuitive}
{\sc Zhao, L., Li, X., Liang, P., Yang, C., and Li, R.}
\newblock Intuitive robot teaching by hand guided demonstration.
\newblock In {\em 2016 IEEE International Conference on Mechatronics and
  Automation\/} (2016), IEEE, pp.~1578--1583.

\bibitem{zhao_intuitive_2016}
{\sc Zhao, L., Liu, Y., Wang, K., Liang, P., and Li, R.}
\newblock An intuitive human robot interface for tele-operation.
\newblock In {\em 2016 {IEEE} {International} {Conference} on {Real}-{Time}
  {Computing} and {Robotics}, {RCAR} 2016\/} (2016), pp.~454--459.
\newblock 9.

\bibitem{zheng_scalable_2015}
{\sc Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., and Tian, Q.}
\newblock Scalable {Person} {Re}-identification: {A} {Benchmark}.
\newblock In {\em 2015 {IEEE} {International} {Conference} on {Computer}
  {Vision} ({ICCV})\/} (Santiago, Chile, Dec. 2015), IEEE, pp.~1116--1124.
\newblock 2136.

\bibitem{zhu_real-time_2016}
{\sc Zhu, M.-D., Xia, L.-X., and Su, J.-B.}
\newblock Real-time imitation framework for humanoid robots based on posture
  classification.
\newblock In {\em Proceedings - {International} {Conference} on {Machine}
  {Learning} and {Cybernetics}\/} (2016), vol.~2, pp.~489--494.
\newblock 0.

\bibitem{zhu_robust_2017}
{\sc Zhu, T., Zhao, Q., Wan, W., and Xia, Z.}
\newblock Robust {Regression}-{Based} {Motion} {Perception} for {Online}
  {Imitation} on {Humanoid} {Robot}.
\newblock {\em International Journal of Social Robotics 9}, 5 (2017), 705--725.
\newblock 4.

\bibitem{ozgur_natural_2014}
{\sc Özgur, A., Bonardi, S., Vespignani, M., Möckel, R., and Ijspeert, A.~J.}
\newblock Natural user interface for {Roombots}.
\newblock In {\em The 23rd {IEEE} {International} {Symposium} on {Robot} and
  {Human} {Interactive} {Communication}\/} (Aug. 2014), pp.~12--17.
\newblock 10.

\end{thebibliography}
