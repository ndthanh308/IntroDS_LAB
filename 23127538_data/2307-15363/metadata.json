{
  "title": "Robotic Vision for Human-Robot Interaction and Collaboration: A Survey and Systematic Review",
  "authors": [
    "Nicole Robinson",
    "Brendan Tidd",
    "Dylan Campbell",
    "Dana KuliÄ‡",
    "Peter Corke"
  ],
  "submission_date": "2023-07-28T07:27:11+00:00",
  "revised_dates": [],
  "abstract": "Robotic vision for human-robot interaction and collaboration is a critical process for robots to collect and interpret detailed information related to human actions, goals, and preferences, enabling robots to provide more useful services to people. This survey and systematic review presents a comprehensive analysis on robotic vision in human-robot interaction and collaboration over the last 10 years. From a detailed search of 3850 articles, systematic extraction and evaluation was used to identify and explore 310 papers in depth. These papers described robots with some level of autonomy using robotic vision for locomotion, manipulation and/or visual communication to collaborate or interact with people. This paper provides an in-depth analysis of current trends, common domains, methods and procedures, technical processes, data sets and models, experimental testing, sample populations, performance metrics and future challenges. This manuscript found that robotic vision was often used in action and gesture recognition, robot movement in human spaces, object handover and collaborative actions, social communication and learning from demonstration. Few high-impact and novel techniques from the computer vision field had been translated into human-robot interaction and collaboration. Overall, notable advancements have been made on how to develop and deploy robots to assist people.",
  "categories": [
    "cs.RO"
  ],
  "primary_category": "cs.RO",
  "doi": "10.1145/3570731",
  "journal_ref": "ACM Transactions on Human-Robot Interaction (2023) Volume 12 Issue 1 Article No 12 pp 1-66",
  "arxiv_id": "2307.15363",
  "pdf_url": "https://arxiv.org/pdf/2307.15363v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 6834965,
  "size_after_bytes": 2460973
}