\textbf{Markov game (MG)} is used to model the interaction between multiple agents~\citep{littman1994markov}. A Markov game, sometimes is called a stochastic game~\citep{owen2013game} defined as a tuple $G := (\mathcal{N}, S, \{A^i\}_{i \in \mathcal{N}}, \{r^i\}_{i \in \mathcal{N}}, p, \gamma)$, where $S$ is the state space, $\mathcal{N}$ is a set of $N$ agents, $A^i$ is the action space of agent $i$, respectively  \citep{littman1994markov,owen2013game}$. \gamma \in [0,1)$ is the discounting factor. We define $A = A^1 \times \cdots \times A^N$ as the joint action space. The state transition $p: S \times A \rightarrow \Delta(S)$ is controlled by the current state and joint action, where $\Delta(S)$ represents the set of all probability distributions over the joint state space $S$. Each agent has a reward function, $r^i: S \times A \rightarrow \mathbb{R}$. At time $t$, agent $i$ chooses its action $a^i_t$ according to a policy $\pi^i: S \rightarrow \Delta(A^i)$. 
% We denote the agents' joint policy as $\pi = (\pi^1, \cdots, \pi^N)$. 
For each agent $i$, it attempts to maximize its expected sum of discounted rewards, i.e. its objective function $J^i(s,\pi) = \mathbb{E} \left[ \sum_{t=1}^{\infty} \gamma^{t-1} r_t^i(s_t,a_t) | s_1 = s, a_t \sim \pi(\cdot | {s}_t) \right]$.

