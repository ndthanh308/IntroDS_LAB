\begin{thebibliography}{83}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Azar et~al.(2017)Azar, Osband, and Munos]{azar2017ucbvi}
Mohammad~Gheshlaghi Azar, Ian Osband, and R{\'e}mi Munos.
\newblock Minimax regret bounds for reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  263--272. PMLR, 2017.

\bibitem[Ba{\c{s}}ar \& Olsder(1998)Ba{\c{s}}ar and Olsder]{bacsar1998dynamic}
Tamer Ba{\c{s}}ar and Geert~Jan Olsder.
\newblock \emph{Dynamic noncooperative game theory}.
\newblock SIAM, 1998.

\bibitem[Beyer \& Sendhoff(2007)Beyer and Sendhoff]{beyer2007robust}
Hans-Georg Beyer and Bernhard Sendhoff.
\newblock Robust optimization--a comprehensive survey.
\newblock \emph{Computer methods in applied mechanics and engineering},
  196\penalty0 (33-34):\penalty0 3190--3218, 2007.

\bibitem[Boyd \& Vandenberghe(2004)Boyd and Vandenberghe]{Bookcvx_Boyd}
Stephen Boyd and Lieven Vandenberghe.
\newblock \emph{Convex Optimization}.
\newblock Cambridge University Press, USA, 2004.
\newblock ISBN 0521833787.

\bibitem[{\v{C}}erm{\'a}k et~al.(2017){\v{C}}erm{\'a}k, Bo{\v{s}}ansky, and
  Lisy]{vcermak2017algorithm}
Ji{\v{r}}{\'\i} {\v{C}}erm{\'a}k, Branislav Bo{\v{s}}ansky, and Viliam Lisy.
\newblock An algorithm for constructing and solving imperfect recall
  abstractions of large extensive-form games.
\newblock In \emph{Proceedings of the 26th International Joint Conference on
  Artificial Intelligence}, pp.\  936--942, 2017.

\bibitem[Cesa-Bianchi et~al.(2017)Cesa-Bianchi, Gentile, Lugosi, and
  Neu]{cesa2017boltzmann}
Nicol{\`o} Cesa-Bianchi, Claudio Gentile, G{\'a}bor Lugosi, and Gergely Neu.
\newblock Boltzmann exploration done right.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Chades et~al.(2002)Chades, Scherrer, and
  Charpillet]{chades2002heuristic}
Iadine Chades, Bruno Scherrer, and Fran{\c{c}}ois Charpillet.
\newblock A heuristic approach for solving decentralized-pomdp: Assessment on
  the pursuit problem.
\newblock In \emph{Proceedings of the 2002 ACM symposium on Applied computing},
  pp.\  57--62, 2002.

\bibitem[Chen et~al.(2009)Chen, Deng, and Teng]{chen2009settling}
Xi~Chen, Xiaotie Deng, and Shang-Hua Teng.
\newblock Settling the complexity of computing two-player nash equilibria.
\newblock \emph{Journal of the ACM (JACM)}, 56\penalty0 (3):\penalty0 1--57,
  2009.

\bibitem[Chen et~al.(2022)Chen, Liu, Luo, and Yin]{chen2022robust}
Xinning Chen, Xuan Liu, Canhui Luo, and Jiangjin Yin.
\newblock Robust multi-agent reinforcement learning for noisy environments.
\newblock \emph{Peer-to-Peer Networking and Applications}, 15\penalty0
  (2):\penalty0 1045--1056, 2022.

\bibitem[Conitzer \& Sandholm(2002)Conitzer and
  Sandholm]{conitzer2002complexity}
Vincent Conitzer and Tuomas Sandholm.
\newblock Complexity results about nash equilibria.
\newblock \emph{arXiv preprint cs/0205074}, 2002.

\bibitem[Creswell et~al.(2018)Creswell, White, Dumoulin, Arulkumaran, Sengupta,
  and Bharath]{creswell2018generative}
Antonia Creswell, Tom White, Vincent Dumoulin, Kai Arulkumaran, Biswa Sengupta,
  and Anil~A Bharath.
\newblock Generative adversarial networks: An overview.
\newblock \emph{IEEE Signal Processing Magazine}, 35\penalty0 (1):\penalty0
  53--65, 2018.

\bibitem[Daskalakis et~al.(2009)Daskalakis, Goldberg, and
  Papadimitriou]{daskalakis2009complexity}
Constantinos Daskalakis, Paul~W Goldberg, and Christos~H Papadimitriou.
\newblock The complexity of computing a nash equilibrium.
\newblock \emph{SIAM Journal on Computing}, 39\penalty0 (1):\penalty0 195--259,
  2009.

\bibitem[Delage \& Ye(2010)Delage and Ye]{Ye_dro}
Erick Delage and Yinyu Ye.
\newblock Distributionally robust optimization under moment uncertainty with
  application to data-driven problems.
\newblock \emph{Operations Research}, 58\penalty0 (3):\penalty0 595--612, 2010.
\newblock \doi{10.1287/opre.1090.0741}.

\bibitem[Devore et~al.(2012)Devore, Berk, and Carlton]{devore2012modern}
Jay~L Devore, Kenneth~N Berk, and Matthew~A Carlton.
\newblock \emph{Modern mathematical statistics with applications}, volume 285.
\newblock Springer, 2012.

\bibitem[Emery-Montemerlo et~al.(2004)Emery-Montemerlo, Gordon, Schneider, and
  Thrun]{emery2004approximate}
Rosemary Emery-Montemerlo, Geoff Gordon, Jeff Schneider, and Sebastian Thrun.
\newblock Approximate solutions for partially observable stochastic games with
  common payoffs.
\newblock In \emph{Proceedings of the Third International Joint Conference on
  Autonomous Agents and Multiagent Systems, 2004. AAMAS 2004.}, pp.\  136--143.
  IEEE, 2004.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, et~al.]{espeholt2018impala}
Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Vlad Mnih, Tom Ward,
  Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, et~al.
\newblock Impala: Scalable distributed deep-rl with importance weighted
  actor-learner architectures.
\newblock In \emph{ICML}, pp.\  1407--1416. PMLR, 2018.

\bibitem[Etessami \& Yannakakis(2010)Etessami and
  Yannakakis]{etessami2010complexity}
Kousha Etessami and Mihalis Yannakakis.
\newblock On the complexity of nash equilibria and other fixed points.
\newblock \emph{SIAM Journal on Computing}, 39\penalty0 (6):\penalty0
  2531--2597, 2010.

\bibitem[Everett et~al.(2021)Everett, L{\"u}tjens, and
  How]{everett2021certifiable}
Michael Everett, Bj{\"o}rn L{\"u}tjens, and Jonathan~P How.
\newblock Certifiable robustness to adversarial state uncertainty in deep
  reinforcement learning.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  2021.

\bibitem[Fink(1964)]{fink1964equilibrium}
Arlington~M Fink.
\newblock Equilibrium in a stochastic $ n $-person game.
\newblock \emph{Journal of science of the hiroshima university, series ai
  (mathematics)}, 28\penalty0 (1):\penalty0 89--93, 1964.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{foerster2018counterfactual}
Jakob Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, and
  Shimon Whiteson.
\newblock Counterfactual multi-agent policy gradients.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~32, 2018.

\bibitem[Fujimoto et~al.(2019)Fujimoto, Meger, and Precup]{fujimoto2019off}
Scott Fujimoto, David Meger, and Doina Precup.
\newblock Off-policy deep reinforcement learning without exploration.
\newblock In \emph{International conference on machine learning}, pp.\
  2052--2062. PMLR, 2019.

\bibitem[Gomes \& Kowalczyk(2009)Gomes and Kowalczyk]{gomes2009dynamic}
Eduardo~Rodrigues Gomes and Ryszard Kowalczyk.
\newblock Dynamic analysis of multiagent q-learning with epsilon-greedy
  exploration.
\newblock In \emph{ICML’09: Proceedings of the 26th international Conference
  on Machine Learning}, volume~47, 2009.

\bibitem[Hansen et~al.(2004)Hansen, Bernstein, and
  Zilberstein]{hansen2004dynamic}
Eric~A Hansen, Daniel~S Bernstein, and Shlomo Zilberstein.
\newblock Dynamic programming for partially observable stochastic games.
\newblock In \emph{AAAI}, volume~4, pp.\  709--715, 2004.

\bibitem[He et~al.(2020)He, Pepin, Wang, Zhang, and Miao]{he2020data}
Sihong He, Lynn Pepin, Guang Wang, Desheng Zhang, and Fei Miao.
\newblock Data-driven distributionally robust electric vehicle balancing for
  mobility-on-demand systems under demand and supply uncertainties.
\newblock In \emph{2020 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pp.\  2165--2172. IEEE, 2020.

\bibitem[He et~al.(2022)He, Wang, Han, Zou, and Miao]{he2022robust}
Sihong He, Yue Wang, Shuo Han, Shaofeng Zou, and Fei Miao.
\newblock A robust and constrained multi-agent reinforcement learning framework
  for electric vehicle amod systems.
\newblock \emph{arXiv preprint arXiv:2209.08230}, 2022.

\bibitem[He et~al.(2023)He, Zhang, Han, Pepin, Wang, Zhang, Stankovic, and
  Miao]{he2023data}
Sihong He, Zhili Zhang, Shuo Han, Lynn Pepin, Guang Wang, Desheng Zhang, John~A
  Stankovic, and Fei Miao.
\newblock Data-driven distributionally robust electric vehicle balancing for
  autonomous mobility-on-demand systems under demand and supply uncertainties.
\newblock \emph{IEEE Transactions on Intelligent Transportation Systems}, 2023.

\bibitem[Hu \& Wellman(2003)Hu and Wellman]{hu2003nash}
Junling Hu and Michael~P Wellman.
\newblock Nash q-learning for general-sum stochastic games.
\newblock \emph{Journal of machine learning research}, 4\penalty0
  (Nov):\penalty0 1039--1069, 2003.

\bibitem[Hu et~al.(2020)Hu, Shao, Li, Jianye, Liu, Yang, Wang, and
  Zhu]{hu2020robust_iclr_rej}
Yizheng Hu, Kun Shao, Dong Li, HAO Jianye, Wulong Liu, Yaodong Yang, Jun Wang,
  and Zhanxing Zhu.
\newblock Robust multi-agent reinforcement learning driven by correlated
  equilibrium.
\newblock 2020.

\bibitem[Huang et~al.(2017)Huang, Papernot, Goodfellow, Duan, and
  Abbeel]{huang2017adversarial}
Sandy Huang, Nicolas Papernot, Ian Goodfellow, Yan Duan, and Pieter Abbeel.
\newblock Adversarial attacks on neural network policies.
\newblock \emph{arXiv preprint arXiv:1702.02284}, 2017.

\bibitem[Jin et~al.(2018)Jin, Allen-Zhu, Bubeck, and Jordan]{jin2018q}
Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, and Michael~I Jordan.
\newblock Is q-learning provably efficient?
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Kaelbling et~al.(1998)Kaelbling, Littman, and Cassandra]{pomdp98}
Leslie~Pack Kaelbling, Michael~L. Littman, and Anthony~R. Cassandra.
\newblock Planning and acting in partially observable stochastic domains.
\newblock \emph{Artificial Intelligence}, 101\penalty0 (1):\penalty0 99--134,
  1998.
\newblock ISSN 0004-3702.
\newblock \doi{https://doi.org/10.1016/S0004-3702(98)00023-X}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S000437029800023X}.

\bibitem[Konda \& Tsitsiklis(1999)Konda and Tsitsiklis]{konda1999actor}
Vijay Konda and John Tsitsiklis.
\newblock Actor-critic algorithms.
\newblock \emph{Advances in neural information processing systems}, 12, 1999.

\bibitem[Kos \& Song(2017)Kos and Song]{Kos2017attackP}
Jernej Kos and Dawn~Xiaodong Song.
\newblock Delving into adversarial attacks on deep policies.
\newblock \emph{ArXiv}, abs/1705.06452, 2017.

\bibitem[Kroer et~al.(2020)Kroer, Waugh, K{\i}l{\i}n{\c{c}}-Karzan, and
  Sandholm]{kroer2020faster}
Christian Kroer, Kevin Waugh, Fatma K{\i}l{\i}n{\c{c}}-Karzan, and Tuomas
  Sandholm.
\newblock Faster algorithms for extensive-form game solving via improved
  smoothing functions.
\newblock \emph{Mathematical Programming}, 179\penalty0 (1):\penalty0 385--417,
  2020.

\bibitem[Li et~al.(2014)Li, Zhang, Chen, and Smola]{li2014efficient}
Mu~Li, Tong Zhang, Yuqiang Chen, and Alexander~J Smola.
\newblock Efficient mini-batch training for stochastic optimization.
\newblock In \emph{Proceedings of the 20th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pp.\  661--670, 2014.

\bibitem[Li et~al.(2019)Li, Wu, Cui, Dong, Fang, and Russell]{li2019robust}
Shihui Li, Yi~Wu, Xinyue Cui, Honghua Dong, Fei Fang, and Stuart Russell.
\newblock Robust multi-agent reinforcement learning via minimax deep
  deterministic policy gradient.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pp.\  4213--4220, 2019.

\bibitem[Lim \& Autef(2019)Lim and Autef]{lim2019kernel_uncertainty}
Shiau~Hong Lim and Arnaud Autef.
\newblock Kernel-based reinforcement learning in robust markov decision
  processes.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3973--3981. PMLR, 2019.

\bibitem[Lin et~al.(2021)Lin, Luo, and Sycara]{lin2021online}
Chendi Lin, Wenhao Luo, and Katia Sycara.
\newblock Online connectivity-aware dynamic deployment for heterogeneous
  multi-robot systems.
\newblock In \emph{2021 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp.\  8941--8947. IEEE, 2021.

\bibitem[Lin et~al.(2020)Lin, Dzeparoska, Zhang, Leon-Garcia, and
  Papernot]{lin2020robustness}
Jieyu Lin, Kristina Dzeparoska, Sai~Qian Zhang, Alberto Leon-Garcia, and
  Nicolas Papernot.
\newblock On the robustness of cooperative multi-agent reinforcement learning.
\newblock In \emph{2020 IEEE Security and Privacy Workshops (SPW)}, pp.\
  62--68. IEEE, 2020.

\bibitem[Lin et~al.(2017)Lin, Hong, Liao, Shih, Liu, and Sun]{advDRL_ijcai17}
Yen-Chen Lin, Zhang-Wei Hong, Yuan-Hong Liao, Meng-Li Shih, Ming-Yu Liu, and
  Min Sun.
\newblock Tactics of adversarial attack on deep reinforcement learning agents.
\newblock In \emph{Proceedings of the 26th International Joint Conference on
  Artificial Intelligence}, IJCAI'17, pp.\  3756–3762. AAAI Press, 2017.
\newblock ISBN 9780999241103.

\bibitem[Littman(1994)]{littman1994markov}
Michael~L Littman.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In \emph{Machine learning proceedings 1994}, pp.\  157--163.
  Elsevier, 1994.

\bibitem[Littman \& Szepesv{\'a}ri(1996)Littman and
  Szepesv{\'a}ri]{littman1996generalized}
Michael~L Littman and Csaba Szepesv{\'a}ri.
\newblock A generalized reinforcement-learning model: Convergence and
  applications.
\newblock In \emph{ICML}, volume~96, pp.\  310--318. Citeseer, 1996.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Pieter~Abbeel, and
  Mordatch]{lowe2017multi}
Ryan Lowe, Yi~I Wu, Aviv Tamar, Jean Harb, OpenAI Pieter~Abbeel, and Igor
  Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[McFarlane(2018)]{mcfarlane2018survey}
Roger McFarlane.
\newblock A survey of exploration strategies in reinforcement learning.
\newblock \emph{McGill University}, 2018.

\bibitem[McKelvey \& McLennan(1996)McKelvey and
  McLennan]{mckelvey1996computation}
Richard~D McKelvey and Andrew McLennan.
\newblock Computation of equilibria in finite games.
\newblock \emph{Handbook of computational economics}, 1:\penalty0 87--142,
  1996.

\bibitem[Miao et~al.(2021)Miao, He, Pepin, Han, Hendawi, Khalefa, Stankovic,
  and Pappas]{miao2021data}
Fei Miao, Sihong He, Lynn Pepin, Shuo Han, Abdeltawab Hendawi, Mohamed~E
  Khalefa, John~A Stankovic, and George Pappas.
\newblock Data-driven distributionally robust optimization for vehicle
  balancing of mobility-on-demand systems.
\newblock \emph{ACM Transactions on Cyber-Physical Systems}, 5\penalty0
  (2):\penalty0 1--27, 2021.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, et~al.]{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Mémoli(2012)]{dgh-props}
Facundo Mémoli.
\newblock Some properties of gromov–hausdorff distances.
\newblock \emph{Discrete \& Computational Geometry}, pp.\  1--25, 2012.
\newblock ISSN 0179-5376.
\newblock URL \url{http://dx.doi.org/10.1007/s00454-012-9406-8}.
\newblock 10.1007/s00454-012-9406-8.

\bibitem[Nair et~al.(2002)Nair, Tambe, Yokoo, Pynadath, and
  Marsella]{nair2002towards}
R~Nair, M~Tambe, M~Yokoo, D~Pynadath, and S~Marsella.
\newblock Towards computing optimal policies for decentralized pomdps.
\newblock In \emph{Notes of the 2002 AAAI Workshop on Game Theoretic and
  Decision Theoretic Agents}, 2002.

\bibitem[Nash(1951)]{nash1951non}
John Nash.
\newblock Non-cooperative games.
\newblock \emph{Annals of mathematics}, pp.\  286--295, 1951.

\bibitem[Nisioti et~al.(2021)Nisioti, Bloembergen, and
  Kaisers]{nisioti2021robust}
Eleni Nisioti, Daan Bloembergen, and Michael Kaisers.
\newblock Robust multi-agent q-learning in cooperative games with adversaries.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2021.

\bibitem[Oliehoek et~al.(2016)Oliehoek, Amato, et~al.]{dec-pomdp2016}
Frans~A Oliehoek, Christopher Amato, et~al.
\newblock \emph{A concise introduction to decentralized POMDPs}, volume~1.
\newblock Springer, 2016.

\bibitem[Osborne \& Rubinstein(1994)Osborne and Rubinstein]{osborne1994course}
Martin~J Osborne and Ariel Rubinstein.
\newblock \emph{A course in game theory}.
\newblock MIT press, 1994.

\bibitem[Owen(2013)]{owen2013game}
Guillermo Owen.
\newblock \emph{Game theory}.
\newblock Emerald Group Publishing, 2013.

\bibitem[Puterman(2014)]{puterman2014markov}
Martin~L Puterman.
\newblock \emph{Markov decision processes: discrete stochastic dynamic
  programming}.
\newblock John Wiley \& Sons, 2014.

\bibitem[Qu \& Wierman(2020)Qu and Wierman]{qu2020finite}
Guannan Qu and Adam Wierman.
\newblock Finite-time analysis of asynchronous stochastic approximation and $ q
  $-learning.
\newblock In \emph{Conference on Learning Theory}, pp.\  3185--3205. PMLR,
  2020.

\bibitem[Rahimian \& Mehrotra(2019)Rahimian and
  Mehrotra]{rahimian2019distributionally}
Hamed Rahimian and Sanjay Mehrotra.
\newblock Distributionally robust optimization: A review.
\newblock \emph{arXiv preprint arXiv:1908.05659}, 2019.

\bibitem[Russo et~al.(2018)Russo, Van~Roy, Kazerouni, Osband, Wen,
  et~al.]{russo2018tutorial}
Daniel~J Russo, Benjamin Van~Roy, Abbas Kazerouni, Ian Osband, Zheng Wen,
  et~al.
\newblock A tutorial on thompson sampling.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  11\penalty0 (1):\penalty0 1--96, 2018.

\bibitem[Schipper(2017)]{schipper2017kuhn}
Burkhard~C Schipper.
\newblock Kuhn's theorem for extensive games with unawareness.
\newblock \emph{Available at SSRN 3063853}, 2017.

\bibitem[Shapley(1953)]{shapley1953stochastic}
Lloyd~S Shapley.
\newblock Stochastic games.
\newblock \emph{Proceedings of the national academy of sciences}, 39\penalty0
  (10):\penalty0 1095--1100, 1953.

\bibitem[Shen \& How(2021)Shen and How]{shen2021robust}
Macheng Shen and Jonathan~P How.
\newblock Robust opponent modeling via adversarial ensemble reinforcement
  learning.
\newblock In \emph{Proceedings of the International Conference on Automated
  Planning and Scheduling}, volume~31, pp.\  578--587, 2021.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, Baker, Lai, Bolton, et~al.]{silver2017mastering}
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja
  Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
  et~al.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{nature}, 550\penalty0 (7676):\penalty0 354--359, 2017.

\bibitem[Sinha et~al.(2020)Sinha, O’Kelly, et~al.]{sinha2020formulazero}
Aman Sinha, Matthew O’Kelly, et~al.
\newblock Formulazero: Distributionally robust online adaptation via offline
  population synthesis.
\newblock In \emph{ICML}, pp.\  8992--9004. PMLR, 2020.

\bibitem[Slantchev(2008)]{slantchev2008game}
B~Slantchev.
\newblock Game theory: Perfect equilibria in extensive form games.
\newblock \emph{UCSD script}, 2008.

\bibitem[Smart(1980)]{smart1980fixed}
David~Roger Smart.
\newblock \emph{Fixed point theorems}, volume~66.
\newblock Cup Archive, 1980.

\bibitem[Sohrab(2003)]{sohrab2003basic}
Houshang~H Sohrab.
\newblock \emph{Basic real analysis}, volume 231.
\newblock Springer, 2003.

\bibitem[Sun et~al.(2021)Sun, Kim, and How]{sun2021romax}
Chuangchuang Sun, Dong-Ki Kim, and Jonathan~P How.
\newblock Romax: Certifiably robust deep multiagent reinforcement learning via
  convex relaxation.
\newblock \emph{arXiv preprint arXiv:2109.06795}, 2021.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{sutton1998reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock Reinforcement learning: an introduction mit press.
\newblock \emph{Cambridge, MA}, 22447, 1998.

\bibitem[Sutton et~al.(1998)Sutton, Barto, et~al.]{sutton1998introduction}
Richard~S Sutton, Andrew~G Barto, et~al.
\newblock \emph{Introduction to reinforcement learning}, volume 135.
\newblock MIT press Cambridge, 1998.

\bibitem[Szepesv{\'a}ri \& Littman(1999)Szepesv{\'a}ri and
  Littman]{szepesvari1999unified}
Csaba Szepesv{\'a}ri and Michael~L Littman.
\newblock A unified analysis of value-function-based reinforcement-learning
  algorithms.
\newblock \emph{Neural computation}, 11\penalty0 (8):\penalty0 2017--2060,
  1999.

\bibitem[Tessler et~al.(2019)Tessler, Efroni, and Mannor]{tessler2019action}
Chen Tessler, Yonathan Efroni, and Shie Mannor.
\newblock Action robust reinforcement learning and applications in continuous
  control.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6215--6224. PMLR, 2019.

\bibitem[van~der Heiden et~al.(2020)van~der Heiden, Salge, Gavves, and van
  Hoof]{van2020robust}
Tessa van~der Heiden, C~Salge, Efstratios Gavves, and H~van Hoof.
\newblock Robust multi-agent reinforcement learning with social empowerment for
  coordination and communication.
\newblock \emph{arXiv preprint arXiv:2012.08255}, 2020.

\bibitem[Von~Neumann \& Morgenstern(2007)Von~Neumann and
  Morgenstern]{von2007theory}
John Von~Neumann and Oskar Morgenstern.
\newblock Theory of games and economic behavior.
\newblock In \emph{Theory of games and economic behavior}. Princeton university
  press, 2007.

\bibitem[Wang \& Zou(2021)Wang and Zou]{wang2021transition_uncertainty_rl}
Yue Wang and Shaofeng Zou.
\newblock Online robust reinforcement learning with model uncertainty.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 7193--7206, 2021.

\bibitem[Yang \& Wang(2020{\natexlab{a}})Yang and Wang]{Yang2020gameMARL}
Yaodong Yang and Jun Wang.
\newblock An overview of multi-agent reinforcement learning from game
  theoretical perspective.
\newblock \emph{ArXiv}, abs/2011.00583, 2020{\natexlab{a}}.

\bibitem[Yang \& Wang(2020{\natexlab{b}})Yang and Wang]{yang2020overview}
Yaodong Yang and Jun Wang.
\newblock An overview of multi-agent reinforcement learning from game
  theoretical perspective.
\newblock \emph{arXiv preprint arXiv:2011.00583}, 2020{\natexlab{b}}.

\bibitem[Yang et~al.(2018)Yang, Luo, Li, Zhou, Zhang, and Wang]{yang2018mean}
Yaodong Yang, Rui Luo, Minne Li, Ming Zhou, Weinan Zhang, and Jun Wang.
\newblock Mean field multi-agent reinforcement learning.
\newblock In \emph{International conference on machine learning}, pp.\
  5571--5580. PMLR, 2018.

\bibitem[Yin et~al.(2010)Yin, Korzhyk, Kiekintveld, Conitzer, and
  Tambe]{yin2010stackelberg}
Zhengyu Yin, Dmytro Korzhyk, Christopher Kiekintveld, Vincent Conitzer, and
  Milind Tambe.
\newblock Stackelberg vs. nash in security games: interchangeability,
  equivalence, and uniqueness.
\newblock In \emph{AAMAS}, volume~10, pp.\ ~6, 2010.

\bibitem[Yu et~al.(2021{\natexlab{a}})Yu, Velu, Vinitsky, Wang, Bayen, and
  Wu]{yu2021surprising}
Chao Yu, Akash Velu, Eugene Vinitsky, Yu~Wang, Alexandre Bayen, and Yi~Wu.
\newblock The surprising effectiveness of ppo in cooperative, multi-agent
  games.
\newblock \emph{arXiv preprint arXiv:2103.01955}, 2021{\natexlab{a}}.

\bibitem[Yu et~al.(2021{\natexlab{b}})Yu, Gehring, Sch{\"a}fer, and
  Anandkumar]{yu2021robust}
Jing Yu, Clement Gehring, Florian Sch{\"a}fer, and Animashree Anandkumar.
\newblock Robust reinforcement learning: A constrained game-theoretic approach.
\newblock In \emph{Learning for Dynamics and Control}, pp.\  1242--1254. PMLR,
  2021{\natexlab{b}}.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Chen, Xiao, Li, Liu, Boning,
  and Hsieh]{zhang2020robust}
Huan Zhang, Hongge Chen, Chaowei Xiao, Bo~Li, Mingyan Liu, Duane Boning, and
  Cho-Jui Hsieh.
\newblock Robust deep reinforcement learning against adversarial perturbations
  on state observations.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 21024--21037, 2020{\natexlab{a}}.

\bibitem[Zhang et~al.(2021)Zhang, Chen, Boning, and Hsieh]{zhang2021robust}
Huan Zhang, Hongge Chen, Duane Boning, and Cho-Jui Hsieh.
\newblock Robust reinforcement learning on state observations with learned
  optimal adversary.
\newblock \emph{arXiv preprint arXiv:2101.08452}, 2021.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Sun, Tao, Genc, Mallya, and
  Basar]{zhang2020robust_nips}
Kaiqing Zhang, Tao Sun, Yunzhe Tao, Sahika Genc, Sunil Mallya, and Tamer Basar.
\newblock Robust multi-agent reinforcement learning with model uncertainty.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 10571--10583, 2020{\natexlab{b}}.

\end{thebibliography}
