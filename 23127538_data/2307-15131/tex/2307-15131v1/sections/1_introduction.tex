% Looking back to the development of Computer Vision and Graphics, representing and manipulating objects and scenes is the eternal core topic. Previous works have made fantastic progress in reflecting the real world into 2D images, sensing and editing each and every single pixel. Based on these theories and methods, people have created a lot of tools to capture and edit 3D objects and scenes for the classical 3D representations, \eg mesh, voxel, and point cloud.

Implicit neural representations, \eg neural radiance fields (NeRF)~\cite{mildenhall2020nerf}, have gained increasing attention as novel 3D representations with neural networks to model a 3D scene. Benefiting from the high reconstruction accuracy and rendering quality with relatively low memory consumption, NeRF and its variations~\cite{kaizhang2020,barron2021mipnerf,yu_and_fridovichkeil2021plenoxels,mueller2022instant,Chen2022ECCV,yariv2021volume,wang2021neus}
% like \fcite{nerfpp, mipnerf, planoxle, ngp, monosdf} 
have demonstrated great potential in many 3D applications like 3D reconstruction, novel view synthesis, and Virtual/Augmented Reality.

With the popularity of the new implicit representations and an increasing number of implicit 3D models, there is a pressing demand for human-friendly editing tools to interact with these 3D models. Editing with implicit neural representations is a fundamental technique required to fully empower the representation. Objects reconstructed from the real world are likely to contain artifacts due to the noise of captured data and the limitations of the reconstruction algorithms. In a typical 3D scanning pipeline, manual correction and refinement to remove artifacts are common stages. On the other hand, in 3D content creation applications like 3D games, animations, and filming, artists usually need to create new content based on existing 3D models. 

Prior works have made attempts to edit 3D scenes represented by NeRF, including object segmentation~\cite{liu2021editing,yang2021objectnerf}
% \fcite{editnerf, interactiveseg, spin, objectnerf}
, object removal~\cite{liu2022nerf}
% \fcite{nerfin}
, appearance editing~\cite{kuang2022palettenerf,munkberg2022extracting}
% \fcite{hypernerf, implicitsurfacelightfield}
, and object blending~\cite{guo2021template}, \etc. These existing NeRF editing methods mainly focus on coarse-grained object-level editing and the convergence speed can not meet the demands of interactive editing. Some recent methods~\cite{Yuan22NeRFEditing,neumesh} transforms the editing of NeRF into mesh editing by introducing a mesh as an edit proxy. This requires the user to operate on an additional meshing tool, which limits the interactivity and user friendliness. To the best of our knowledge, there are no existing methods that are able to support interactive pixel-level editing of neural radiance fields with fast converging speed, which is mainly due to the challenges discussed below.

Unlike existing explicit 3D representations \eg point cloud, textured mesh, and occupancy volume, which store the explicit geometry structure of objects and scenes, implicit representations use neural networks to query features of a 3D scene including geometry and color. Existing 3D editing methods, taking mesh-based representation for example, can change object geometry by displacing vertices corresponding to target object surface areas and object textures. Without explicit explainable correspondence between the visual effects and the underlying representations, editing the implicit 3D models is indirect and challenging. 
Further, it is difficult to locate implicit network parameters in local areas of the scene,
% Further, implicit representations use a single network to model the global scene,
% the implicit functions are non-local, 
meaning that adaptations of the network parameters may lead to undesired global changes. This results in more challenges for fine-grained editing.


To bridge the gap, in this paper, we propose an interactive pixel-level editing method and system for implicit neural representations for 3D scenes, dubbed Seal-3D. The name is borrowed from the popular 2D image editing software Adobe PhotoShop~\cite{adobephotoshop}, as its seal tool provides similar editing operations. As shown in \cref{fig-teaser}, the editing system consists of four types of editing as examples: 1) Bounding box tool. It transforms and scales things inside a bounding box, like a copy-paste operation. 2) Brushing tool. It paints specified color on the selected zone, and can increase or decrease the surface height, like an oil paint brush or graver. 3) Anchor tool. It allows the user to freely move a control point and affect its neighbor space according to the user input. 4) Color tool. It edits the color of the object surfaces.

To achieve the interactive NeRF editing effects, we address the challenges of implicit representations discussed above. First, to establish the correspondence between the explicit editing instructions to the update of implicit network parameters, we propose a proxy function that maps the target 3D space (determined by the user edit instructions from an interactive GUI) to the original 3D scene space, and a teacher-student distillation strategy to update the parameters with the corresponding content supervision acquired by the proxy function from the original scenes. Second, to enable local editing, \ie mitigating the influence of the local editing effect on the global 3D scenes under the non-local implicit representations, we propose a two-stage training process: 
a pretraining stage of updating only the positional embedding grids with local losses for editing areas while freezing the subsequent MLP decoder to prevent global degeneration, and a finetuning stage of updating both the embedding grids and the MLP decoder with global photometric losses. With this design, the pretraining stage updates local editing features and the finetuning stage blends the local editing areas with global structures and colors of unedited space to achieve view consistency. This design has the benefit of an instant preview of the editing: the pretraining can converge very fast and presents local editing effects within approximately 1 second only. 


In summary, our contributions are as follows:

\begin{itemize}
\item We propose the first interactive pixel-level editing method and system for neural radiance fields, which exemplifies fine-grained multiple types of editing tools, including geometry (bounding box tool, brush tool, and anchor tool) and color edits;
\item A proxy function is proposed to establish the correspondence between the explicit editing instructions and the update of implicit network parameters and a teacher-student distillation strategy is proposed to update the parameters;
\item A two-stage training strategy is proposed to enable instant preview of local fine-grained editing without contaminating the global 3D scenes. 
\end{itemize}



%  is rapidly gaining attention as a new form of 3D representation.  
%  Benefits from the high reconstruction accuracy with relatively low resource consumption, NeRF and its variations like \fcite{nerfpp, mipnerf, planoxle, ngp, monosdf} are very popular in VR/AR, 3D reconstruction, and 3D sensing tasks.

% Among these NeRF applications\fcite{applications in related works}, there is an urgent need to NeRF edit methods and tools for many reasons. 1)The reconstructed real-world NeRF object is likely to contain artifacts due to the noise of captured data and some of the artifacts can only be corrected manually. 2)Artists who are used to traditional 3D modeling tools need a human-friendly way to interactively edit the NeRF models. 3)As NeRF is being widely used, enabling non-expert people to generate, control, and edit their NeRF models will promote the applications of NeRF in various areas, \eg 3D games, online goods displays, 3D city maps, and other situations with metaverse. These applications and tasks are calling for techniques for editing the rendered neural radiance field.





% However, unlike the explicit 3D representations that store the exact structure and texture of the target object and scene, NeRF uses a group of parameters to store the density, color, and other features in the space. This makes editing NeRF models very indirect and the traditional 3D edit tools cannot handle this complex task.

% Previous works observed NeRF editing from various perspectives, including object segmentation\fcite{editnerf, interactiveseg, spin, objectnerf}, object removal\fcite{nerfin}, appearance editing\fcite{hypernerf, implicitsurfacelightfield}, and object blending\fcite{template nerf}, \etc. However, to the best of our knowledge, there is no real-time interactive pixel-wise free editing of the neural radiance field methods.

% The major difficulties are: 1) NeRF representations do not have explicit surface or control point; 2) Some parameters of NeRF model have an effect in a global scope, which means simply editing some parameters won't give the expected result; 3)Existing NeRF editing methods mainly focus on object-wise editing, while pixel-wise free editing work is not seen.

% Here we propose a new real-time interactive free editing method and system without relying on any specific NeRF backbone, named Seal. The name is borrowed from the popular 2D image editing software Adobe PhotoShop, as its seal tool provides similar editing operations. As shown in \ref{img_editing_types}, we consider three types of editing as examples: 1)Bounding box tool. It transforms and scales things inside a bounding box, like a copy-paste operation. 2)Brush tool. It increases or decreases the surface height of the selected zone, like an oil paint brush or graver. 3)Anchor tool. It allows the user to freely move a control point and affect its neighbor space under the user's will.

% We address the challenges of interactive pixel-wise free NeRF editing by introducing a teacher-student training strategy and implementing a group of editing rules for different kinds of editing tools, which can be easily extended to more complex editing operations. First, we initialize a teacher model and a student model from a trained NeRF model. Secondly, the teacher model accepts some point mapping rules from user input of the interactive GUI program. The sampled points will be mapped with the tools' rule mentioned above. Third, the student model starts a two-stage training process. The pretraining can be very fast and gives a appoximate result in 1 second, followed by a normal NeRF model training with depth supervision. All the ground truth are generated from the teacher model using the mapped sampling points. The re-trained student model rendering result shows the editing successfully generates a new NeRF model with desired changes, while perfectly keeping the structures and colors of unedited space.

% In summary, our core contributions are as follows:

% \begin{itemize}
%     \item Probably first real-time interactive pixel-wise free neural radiance field editing framework using teacher-student structure;
%     \item Training strategies for real-time editing preview instantly;
%     \item Multiple types of pixel-wise neural radiance field editing tools, including bounding box tool, brush tool, and anchor tool;
%     \item Performance comparisons on multiple tasks and objects.
% \end{itemize}