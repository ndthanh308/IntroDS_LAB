\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{adebayo2018sanity}
Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., Kim, B.: Sanity
  checks for saliency maps. Advances in neural information processing systems
  \textbf{31} (2018)

\bibitem{adebayo2022post}
Adebayo, J., Muelly, M., Abelson, H., Kim, B.: Post hoc explanations may be
  ineffective for detecting unknown spurious correlation. In: International
  Conference on Learning Representations (2022)

\bibitem{adebayo2020debugging}
Adebayo, J., Muelly, M., Liccardi, I., Kim, B.: Debugging tests for model
  explanations. arXiv preprint arXiv:2011.05429  (2020)

\bibitem{alvarez2018robustness}
Alvarez-Melis, D., Jaakkola, T.S.: On the robustness of interpretability
  methods. arXiv preprint arXiv:1806.08049  (2018)

\bibitem{arun2021assessing}
Arun, N., Gaw, N., Singh, P., Chang, K., Aggarwal, M., Chen, B., Hoebel, K.,
  Gupta, S., Patel, J., Gidwani, M., et~al.: Assessing the trustworthiness of
  saliency maps for localizing abnormalities in medical imaging. Radiology:
  Artificial Intelligence  \textbf{3}(6),  e200267 (2021)

\bibitem{bohle2021convolutional}
Bohle, M., Fritz, M., Schiele, B.: Convolutional dynamic alignment networks for
  interpretable classifications. In: Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition. pp. 10029--10038 (2021)

\bibitem{boreiko2022visual}
Boreiko, V., Ilanchezian, I., Ayhan, M.S., M{\"u}ller, S., Koch, L.M., Faber,
  H., Berens, P., Hein, M.: Visual explanations for the detection of diabetic
  retinopathy from retinal fundus images. In: Medical Image Computing and
  Computer Assisted Intervention (2022)

\bibitem{brendel2019approximating}
Brendel, W., Bethge, M.: Approximating cnns with bag-of-local-features models
  works surprisingly well on imagenet. arXiv preprint arXiv:1904.00760  (2019)

\bibitem{cohen2021gifsplanation}
Cohen, J.P., Brooks, R., En, S., Zucker, E., Pareek, A., Lungren, M.P.,
  Chaudhari, A.: Gifsplanation via latent shift: a simple autoencoder approach
  to counterfactual generation for chest x-rays. In: Medical Imaging with Deep
  Learning. pp. 74--104. PMLR (2021)

\bibitem{djoumessi2023sparse}
Djoumessi, K.R., Ilanchezian, I., Kuehlewein, L., Faber, H., Baumgartner, C.F.,
  Bah, B., Berens, P., Koch, L.M.: Sparse activations for interpretable disease
  grading. arXiv preprint arXiv:TODO  (2023)

\bibitem{geirhos2020shortcut}
Geirhos, R., Jacobsen, J.H., Michaelis, C., Zemel, R., Brendel, W., Bethge, M.,
  Wichmann, F.A.: Shortcut learning in deep neural networks. Nature Machine
  Intelligence  \textbf{2}(11),  665--673 (2020)

\bibitem{han2022explanation}
Han, T., Srinivas, S., Lakkaraju, H.: Which explanation should i choose? a
  function approximation perspective to characterizing post hoc explanations.
  arXiv preprint arXiv:2206.01254  (2022)

\bibitem{he2016deep}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
  recognition. In: Proceedings of the IEEE conference on computer vision and
  pattern recognition. pp. 770--778 (2016)

\bibitem{irvin2019chexpert}
Irvin, J., Rajpurkar, P., Ko, M., Yu, Y., Ciurea-Ilcus, S., Chute, C.,
  Marklund, H., Haghgoo, B., Ball, R., Shpanskaya, K., et~al.: Chexpert: A
  large chest radiograph dataset with uncertainty labels and expert comparison.
  In: Proceedings of the AAAI conference on artificial intelligence. vol.~33,
  pp. 590--597 (2019)

\bibitem{lundberg2017unified}
Lundberg, S.M., Lee, S.I.: A unified approach to interpreting model
  predictions. Advances in neural information processing systems  \textbf{30}
  (2017)

\bibitem{ribeiro2016should}
Ribeiro, M.T., Singh, S., Guestrin, C.: " why should i trust you?" explaining
  the predictions of any classifier. In: Proceedings of the 22nd ACM SIGKDD
  international conference on knowledge discovery and data mining. pp.
  1135--1144 (2016)

\bibitem{rudin2019stop}
Rudin, C.: Stop explaining black box machine learning models for high stakes
  decisions and use interpretable models instead. Nature Machine Intelligence
  \textbf{1}(5),  206--215 (2019)

\bibitem{samangouei2018explaingan}
Samangouei, P., Saeedi, A., Nakagawa, L., Silberman, N.: Explaingan: Model
  explanation via decision boundary crossing transformations. In: Proceedings
  of the European Conference on Computer Vision (ECCV). pp. 666--681 (2018)

\bibitem{selvaraju2017grad}
Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.:
  Grad-cam: Visual explanations from deep networks via gradient-based
  localization. In: Proceedings of the IEEE international conference on
  computer vision. pp. 618--626 (2017)

\bibitem{singla2019explanation}
Singla, S., Pollack, B., Chen, J., Batmanghelich, K.: Explanation by
  progressive exaggeration. arXiv preprint arXiv:1911.00483  (2019)

\bibitem{sixt2020explanations}
Sixt, L., Granz, M., Landgraf, T.: When explanations lie: Why many modified bp
  attributions fail. In: International Conference on Machine Learning. pp.
  9046--9057. PMLR (2020)

\bibitem{smilkov2017smoothgrad}
Smilkov, D., Thorat, N., Kim, B., Vi{\'e}gas, F., Wattenberg, M.: Smoothgrad:
  removing noise by adding noise. arXiv preprint arXiv:1706.03825  (2017)

\bibitem{springenberg2014striving}
Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M.: Striving for
  simplicity: The all convolutional net. arXiv preprint arXiv:1412.6806  (2014)

\bibitem{sun2023inherently}
Sun, S., Woerner, S., Maier, A., Koch, L.M., Baumgartner, C.F.: Inherently
  interpretable multi-label classification using class-specific
  counterfactuals. arXiv preprint arXiv:2303.00500  (2023)

\bibitem{sundararajan2017axiomatic}
Sundararajan, M., Taly, A., Yan, Q.: Axiomatic attribution for deep networks.
  In: International conference on machine learning. pp. 3319--3328. PMLR (2017)

\bibitem{white2019measurable}
White, A., Garcez, A.d.: Measurable counterfactual local explanations for any
  classifier. arXiv preprint arXiv:1908.03020  (2019)

\bibitem{zhou2016learning}
Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.: Learning deep
  features for discriminative localization. In: Proceedings of the IEEE
  conference on computer vision and pattern recognition. pp. 2921--2929 (2016)

\end{thebibliography}
