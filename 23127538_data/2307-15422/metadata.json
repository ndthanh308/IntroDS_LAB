{
  "title": "Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?",
  "authors": [
    "Romain Egele",
    "Isabelle Guyon",
    "Yixuan Sun",
    "Prasanna Balaprakash"
  ],
  "submission_date": "2023-07-28T09:14:41+00:00",
  "revised_dates": [
    "2023-09-26T07:08:36+00:00"
  ],
  "abstract": "Hyperparameter optimization (HPO) is crucial for fine-tuning machine learning models but can be computationally expensive. To reduce costs, Multi-fidelity HPO (MF-HPO) leverages intermediate accuracy levels in the learning process and discards low-performing models early on. We compared various representative MF-HPO methods against a simple baseline on classical benchmark data. The baseline involved discarding all models except the Top-K after training for only one epoch, followed by further training to select the best model. Surprisingly, this baseline achieved similar results to its counterparts, while requiring an order of magnitude less computation. Upon analyzing the learning curves of the benchmark data, we observed a few dominant learning curves, which explained the success of our baseline. This suggests that researchers should (1) always use the suggested baseline in benchmarks and (2) broaden the diversity of MF-HPO benchmarks to include more complex cases.",
  "categories": [
    "cs.LG"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15422",
  "pdf_url": "https://arxiv.org/pdf/2307.15422v2",
  "comment": "5 pages, with extended appendices",
  "num_versions": null,
  "size_before_bytes": 34818199,
  "size_after_bytes": 1115039
}