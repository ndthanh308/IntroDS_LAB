%% ============================================================================
\section{Background, setting of the problem, and our contributions}
\label{s:intro}
%% ============================================================================

%% ----------------------------------------------------------------------------
\subsection{Nonlinear systems and their equilibria}
%% ----------------------------------------------------------------------------

Nonlinear systems arise in a vast plethora of engineering applications ranging from classical mechanics through mathematical finance and is one of the key driving engines behind the success of today's popular optimization algorithms. A nonlinear system is described by an ordinary differential equation
\begin{equation}
	\label{e:nonlinear system}
	\dot{\state}(t) = \vecfld\bigl(\state(t)\bigr),
\end{equation}
where \(\state(t)\in\R[\sysDim]\) is the vector of states of the system defined on a nonempty open set \(\domain\subset \R[\sysDim]\), and \(\vecfld:\domain\lra\R[\sysDim]\) is a \embf{vector field} that specifies at each state \(y\in\domain\) a vector \(\vecfld(y)\) describing both the instantaneous direction of motion and the magnitude of the velocity of motion in that direction. It is assumed that \(\vecfld\) is a Lipschitz continuous map. A nonlinear system is written frequently in the form of a so-called \emph{Cauchy problem}, which specifies a boundary condition such as \(\state(0) = \ol\state\); given such a boundary condition, the system \eqref{e:nonlinear system} can be solved uniquely in a small enough neighborhood of \(t = 0\); in this context, an absolutely continuous function \(\loro{-\eps}{\eps}\ni t\mapsto \soln(t, \ol\state)\in\R[\sysDim]\) for some \(\eps > 0\) such that \(\soln(0, \ol\state) = \ol\state\) and \(\pdv{\soln}{t}(s, \ol\state) = \vecfld\bigl( \soln(s, \ol\state) \bigr)\) for all \(s\in\loro{-\eps}{\eps}\) is the \embf{solution} to the nonlinear system \eqref{e:nonlinear system}, and the map \((t, x)\mapsto \soln(t, x)\) is its \embf{flow}.

An \embf{equilibrium point} of \eqref{e:nonlinear system} is a solution to the equation
\begin{equation}
    \label{e:equilibrium point}
	f(y) = 0\quad \text{for }y\in\R[\sysDim].
\end{equation}
A nonlinear system may admit no equilibrium point, and there may be finitely many equilibria or a continuum of them. In the early stages of the development of the field of dynamical systems, it was realized that the qualitative theory of equilibrium points plays a central role in both theory and applications, and the key concepts of stability of such points were developed in the late \(19\)-th century in A.\ M.\ Lyapunov's dissertation. After decades of mild obscurity, the concepts found applications in several engineering disciplines in the 1940s, and continue to be of central significance in modern day cybernetics.


%% -----------------------------------------------------------------------------
\subsection{Lyapunov's indirect method}
\label{s:intro:indirect method}
%% -----------------------------------------------------------------------------

Suppose that \(0\in\R[\sysDim]\) is an isolated equilibrium point of the vector field \(\vecfld\).\footnote{The selection of \(0\) is without loss of generality.}  Here are two key definitions (see e.g., \cite[Chapter V]{ref:Vid-02}) concerning stability of \(0\):
\begin{enumerate}[label=\textup{(S\arabic*)}, leftmargin=*, align=left]
	\item \label{stab:lyapstable} The equilibrium point \(0\) is \embf{Lyapunov stable} for every \(\eps > 0\) there exists \(\delta > 0\) such that \(\norm{\state(0)} < \delta\) implies that \(\norm{\soln\bigl(t, \state(0)\bigr)} < \eps\) for all \(t\ge 0\). Intuitively, \(0\) is Lyapunov stable if trajectories initialized close to \(0\) remain close to \(0\) for all time, and the extent of `closeness' can be made arbitrarily small (\(\eps\) is arbitrary).
	\item \label{stab:asystable} The equilibrium point \(0\) is \embf{asymptotically stable} if it is Lyapunov stable and \emph{asymptotically attractive}, i.e., for every \(\eps > 0\) there exist \(r > 0\) and \(T > 0\) such that \(\norm{\state(0)} < r\) and \(t > T\) implies \(\norm{\soln\bigl(t, \state(0)\bigr)} < \eps\).
\end{enumerate}
Both these definitions cater to local properties, and we adhere to the preceding premise throughout the sequel.

Lyapunov's indirect method (for detailed and illuminating treatments, see, e.g., \cite[Chapter 5]{ref:Vid-02}, \cite[Chapters V, VIII]{ref:BhaSze-70}, \cite[Chapter V]{ref:Hah-67}) provides a mechanism to test the nature of stability of an equilibrium point. The starting point in the case of Lyapunov stability, for instance, is a function \(\domain\ni y\mapsto \lyapfn(y)\in\R[]\)  (and \(\nbhd\subset\domain\) being a neighborhood of the origin \(0\in\R[\sysDim]\)) satisfying
\begin{equation}
	\label{e:Lyapunov function}
	\begin{aligned}
		& \lyapfn(0) = 0,\quad\text{and}\\
		& \begin{dcases}
			\lyapfn(y) > 0 & \text{for all }y\in\nbhd\setmin\set{0},\\
            \inprod{\pdv{\lyapfn}{x}(y)}{\vecfld(y)} \le 0 & \text{for all } y\in\nbhd,
		\end{dcases}
	\end{aligned}
\end{equation}
and Lyapunov's theorem asserts that if such a function \(\lyapfn\) exists, then \(0\) is Lyapunov stable. Notice that theorem substitutes the verification of a temporal property in \ref{stab:lyapstable} of the solution to the differential equation from arbitrary initial conditions sufficiently close to \(0\), with the verification of certain spatial properties of \(\lyapfn\) in \eqref{e:Lyapunov function}; in particular, one does not have to \emph{solve} the differential equation to assess stability of \(0\) via Lyapunov's indirect method. Naturally and on the one hand, finding such \embf{Lyapunov functions} \(\lyapfn\) is of tremendous utility, but on the other hand, the synthesis of Lyapunov functions is difficult since algorithmic and numerically tractable recipes for finding such functions are rare.\footnote{The situation is indeed rarified to the point of there being the folklore that arriving at suitable Lyapunov functions is more an art than science.} In certain mechanical systems one may write down with relative ease certain `energy'-based Lyapunov functions inspired by the physics of such problems, but a general recipe has proved to be elusive.


%% -----------------------------------------------------------------------------
\subsection{Our contributions}
%% -----------------------------------------------------------------------------

The central objective of this article is to fill the aforementioned lacuna: we provide a relatively general algorithmic recipe for constructing Lyapunov functions corresponding to isolated equilibria of dynamical systems. Our contributions are listed below, in the course of which we adopt comparative rhetoric to delineate them succinctly:
\begin{enumerate}[label=\textup{(\Alph*)}, align=left, widest=B, leftmargin=*]
	\item \label{contrib:} An algorithmic search for Lyapunov functions for a given equilibrium point of a continuous vector field is difficult: for one, there is no canonical parametrization of continuously differentiable positive definite functions to facilitate the construction of algorithms. Attempts have, therefore, been directed toward treating special families of vector fields and classes of admissible functions. The state of the art can be broadly classified into the following two regimes:
		\begin{itemize}[label=\(\circ\), leftmargin=*]
			\item \label{contrib:history} Algorithmic constructions of Lyapunov functions for \emph{linear vector fields} is easy \cite[\S15.10]{ref:Ber-18}. Indeed, if \(\vecfld(y) = A y\) for some matrix \(A\in\R[\sysDim\times\sysDim]\) with \(\rank A = \sysDim\),\footnote{Without the rank condition we have nontrivial subspaces of equilibria and such a situation is not within the scope of this article.} we know that quadratic Lyapunov functions of the form \(\R[\sysDim]\ni y\mapsto \lyapfn(y) = \inprod{y}{Py}\) for a suitable symmetric and positive definite matrix \(P\in\R[\sysDim\times\sysDim]\) suffice: the \embf{Lyapunov equation}
				\begin{equation}
					\label{e:Lyapunov equation}
					\trnsp{A} P + P A = -Q
				\end{equation}
				in the pair \((P, Q)\) is the centerpiece in this theory, and
				\begin{itemize}[label=\(\triangleright\), leftmargin=*]
					\item if there exists a symmetric and non-negative definite \(Q\) and a symmetric and positive definite \(P\) satisfying \eqref{e:Lyapunov equation}, then \(0\) is Lyapunov stable, and
					\item if there exist symmetric and positive definite matrices \(P\) and \(Q\) satisfying \eqref{e:Lyapunov equation}, then \(0\) is asymptotically stable.
				\end{itemize}
			\item Beyond the regime of linear systems, we have the \texttt{SOSTOOLS} library \cite{ref:SOSTOOLS, ref:TanPac-08, ref:AndPap-15, ref:JonPee-23, ref:AngMilPap-13, ref:MenWanYanXieGuo-20, ref:HanCheLuk-14, ref:KunAng-15, ref:ZhaSonWanXue-23}, developed over two decades with myriad applications, that caters to \emph{polynomial vector fields} \(\vecfld\) and works within the ambit of polynomial (sum of squares) Lyapunov functions \(\lyapfn\). The theory of \texttt{SOSTOOLS} is rooted in algebraic geometry, the constructive procedure for Lyapunov functions is algorithmic, and fast algorithms relying on semi-definite programming are available today; see \cite{ref:PraPapSelPar-05} and the references therein for a panoramic overview. See also the recent work \cite{ref:PolSze-22} for an interesting LMI based approach fine-tuned to rational polynomial vector fields, and the more classical work \cite{ref:VanVid-85} containing a procedure that leads to the construction of rational Lyapunov functions along with connections to Zubov's method. 
		\end{itemize}
		At present, and to the best of our knowledge, there is no simple and systematic tractable method for finding a Lyapunov function to assess stability of an equilibrium point of a nonlinear continuous vector field \(\vecfld\) in the absence of further algebraic structures.

		Against the preceding backdrop, our first contribution is a \emph{numerically tractable algorithmic procedure for the construction of Lyapunov functions for given equilibrium points of continuous vector fields} irrespective of their algebraic structure.
	\item \label{contrib:details} The following highlights of our algorithmic procedure lie beyond the ambit of current results:
		\begin{itemize}[label=\(\circ\), leftmargin=*]
			\item Finding a suitable Lyapunov function requires us to verify uncountably many inequality constraints as evidenced in \eqref{e:Lyapunov function}, and such an infinite family of constraints poses the chief difficulty in any algorithmic procedure (involving finite memory). \texttt{SOSTOOLS}, e.g., employs deep theorems in algebra that transform the verification of uncountably many inequalities into finitely many of them. In the absence of such algebraic structures, it is a priori unclear how to proceed with this task. One of the strengths of our algorithm becomes evident against the preceding backdrop and the fact that we \emph{do not stipulate the vector field \(\vecfld\) to be polynomial}. In particular, our algorithmic procedure applies (in the present context of finding Lyapunov functions) to every case that \texttt{SOSTOOLS} applies to in this context.
			\item Moreover, it turns out that \emph{the knowledge of the functional form (i.e., the analytical expression) of the vector field \(\vecfld\) is unnecessary} for our results to be applicable; the mere knowledge of the continuity of \(\vecfld\) coupled with the ability to evaluate \(\vecfld\) at will are sufficient. This particular feature is another key and unique strength of our approach,\footnote{Vector fields that do not admit explicit formulae are nonetheless important in control theory and frequently arise in, e.g., optimal control in the form of shooting functions associated with two-point boundary value problems, closed-loop systems for which the feedback is constructed by means of neural networks, etc.} and further discussion on this point appears in Remark \ref{r:no expression}.
		\end{itemize}
\end{enumerate}


%% -----------------------------------------------------------------------------
\subsection{Technical approach and machinery}
%% -----------------------------------------------------------------------------

Lyapunov functions for a given equilibrium point of a continuous vector field are not unique; apart from invariance relative to scaling by positive numbers, the properties in \eqref{e:Lyapunov function} are also tolerant to suitable nontrivial variations in \(\lyapfn\). This feature of `tolerance' provides a hint that the process of constructing the Lyapunov function may be approached via linear approximation algorithms,\footnote{The domain of \emph{linear approximation} consists of techniques involving the construction of approximants to a given function from a pre-specified vector subspace of some underlying Banach space.} which is at the root of our approach.

Our algorithmic procedure first casts the problem of finding an admissible Lyapunov function into the form of a convex semi-infinite program (SIP),\footnote{This particular step accounts for the uncountably many inequalities in \eqref{e:Lyapunov function}.} and then furnishes an admissible Lyapunov function by leveraging recent results pertaining to near-optimal solutions to convex SIPs \cite{ref:DasAraCheCha-22, ref:ParCha-23}. Notwithstanding the infinite family of constraints, the algorithmic approach espoused herein needs constant memory for a given problem that scales linearly with the dimension of the state-space; see Remark \ref{r:constant memory} for a detailed discussion, and the technical details may be found in \secref{s:problem}.


%% -----------------------------------------------------------------------------
\subsection{Organization and notation}
%% -----------------------------------------------------------------------------

\secref{s:problem} contains the technical formulation of our problem --- the abstract matter of finding a Lyapunov function for a given continuous vector field, and its equilibrium point is translated into a search over a finitely parametrized family of functions that must satisfy uncountably many constraints. The resulting mathematical problem turns out to be a convex semi-infinite program, and \secref{s:results} contains our main results centered around solving such programs. Numerical experiments are provided in \secref{s:numerics}, and we conclude in \secref{s:concl} with a discussion of potential directions emanating from this work.

Standard notations are employed here. The standard inner product on \(\R[\sysDim]\) is, for \(v, w\in\R[\sysDim]\), given by \(\inprod{v}{w} = \sum_{i=1}^{\sysDim} v_i w_i\), and its induced norm is the standard Euclidean norm \(\norm{v} = \sqrt{\inprod{v}{v}}\). Neighborhoods of a point in \(\R[\sysDim]\) are \emph{connected}, \emph{not necessarily open}, but are supersets of open sets containing the given point. If \(S\) is a finite set, then \(\size{S}\) denotes its cardinality.



