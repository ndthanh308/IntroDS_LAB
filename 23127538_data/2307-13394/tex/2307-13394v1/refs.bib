@inproceedings{janin2003icsi,
  title={The ICSI meeting corpus},
  author={Janin, Adam and Baron, Don and Edwards, Jane and Ellis, Dan and Gelbart, David and Morgan, Nelson and Peskin, Barbara and Pfau, Thilo and Shriberg, Elizabeth and Stolcke, Andreas and others},
  booktitle={2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP'03).},
  volume={1},
  pages={I--I},
  year={2003},
  organization={IEEE}
}

@article{purver2011topic,
  title={Topic segmentation},
  author={Purver, Matthew},
  journal={Spoken language understanding: systems for extracting semantic information from speech},
  pages={291--317},
  year={2011}
}

@article{jones2021trec,
  doi = {10.48550/ARXIV.2103.15953},
  
  author = {Jones, Rosie and Carterette, Ben and Clifton, Ann and Eskevich, Maria and Jones, Gareth J. F. and Karlgren, Jussi and Pappu, Aasish and Reddy, Sravana and Yu, Yongze},
  keywords = {Information Retrieval (cs.IR), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {TREC 2020 Podcasts Track Overview},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


% @article{jones2021trec,
%   title={Trec 2020 podcasts track overview},
%   author={Jones, Rosie and Carterette, Ben and Clifton, Ann and Eskevich, Maria and Jones, Gareth JF and Karlgren, Jussi and Pappu, Aasish and Reddy, Sravana and Yu, Yongze},
%   journal={arXiv preprint arXiv:2103.15953},
%   year={2021}
% }

@article{hearst1997text,
  title={Text tiling: Segmenting text into multi-paragraph subtopic passages},
  author={Hearst, Marti A},
  journal={Computational linguistics},
  volume={23},
  number={1},
  pages={33--64},
  year={1997}
}

@article{jones1972statistical,
  title={A statistical interpretation of term specificity and its application in retrieval},
  author={Jones, Karen Sparck},
  journal={Journal of documentation},
  year={1972},
  publisher={MCB UP Ltd}
}

@article{rose2010automatic,
  title={Automatic keyword extraction from individual documents},
  author={Rose, Stuart and Engel, Dave and Cramer, Nick and Cowley, Wendy},
  journal={Text mining: applications and theory},
  volume={1},
  pages={1--20},
  year={2010},
  publisher={Citeseer}
}

@book{marcu2000theory,
  title={The theory and practice of discourse parsing and summarization},
  author={Marcu, Daniel},
  year={2000},
  publisher={MIT press}
}

@incollection{passonneau1996empirical,
  title={Empirical analysis of three dimensions of spoken discourse: Segmentation, coherence, and linguistic devices},
  author={Passonneau, Rebecca J and Litman, Diane J},
  booktitle={Computational and conversational discourse},
  pages={161--194},
  year={1996},
  publisher={Springer}
}

@article{tur2001integrating,
  title={Integrating prosodic and lexical cues for automatic topic segmentation},
  author={T{\"u}r, G{\"o}khan and Hakkani-T{\"u}r, Dilek and Stolcke, Andreas and Shriberg, Elizabeth},
  journal={Computational linguistics},
  volume={27},
  number={1},
  pages={31--57},
  year={2001},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{beeferman1999statistical,
  title={Statistical models for text segmentation},
  author={Beeferman, Doug and Berger, Adam and Lafferty, John},
  journal={Machine learning},
  volume={34},
  number={1},
  pages={177--210},
  year={1999},
  publisher={Springer}
}

@article{hearst1997text,
  title={Text tiling: Segmenting text into multi-paragraph subtopic passages},
  author={Hearst, Marti A},
  journal={Computational linguistics},
  volume={23},
  number={1},
  pages={33--64},
  year={1997}
}

@inproceedings{gupta2020comparative,
  title={A Comparative Study of the Performance of Unsupervised Text Segmentation Techniques on Dialogue Transcripts},
  author={Gupta, Vidhi and Zhu, Guangda and Yu, Andi and Brown, Donald E},
  booktitle={2020 Systems and Information Engineering Design Symposium (SIEDS)},
  pages={1--6},
  year={2020},
  organization={IEEE}
}

@inproceedings{eisenstein2008bayesian,
  title={Bayesian unsupervised topic segmentation},
  author={Eisenstein, Jacob and Barzilay, Regina},
  booktitle={Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing},
  pages={334--343},
  year={2008}
}

@inproceedings{riedl2012topictiling,
  title={TopicTiling: a text segmentation algorithm based on LDA},
  author={Riedl, Martin and Biemann, Chris},
  booktitle={Proceedings of ACL 2012 Student Research Workshop},
  pages={37--42},
  year={2012}
}

@inproceedings{olney2005orthonormal,
  title={An orthonormal basis for topic segmentation in tutorial dialogue},
  author={Olney, Andrew and Cai, Zhiqiang},
  booktitle={Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing},
  pages={971--978},
  year={2005}
}

@inproceedings{galley2003discourse,
  title={Discourse segmentation of multi-party conversation},
  author={Galley, Michel and McKeown, Kathleen and Fosler-Lussier, Eric and Jing, Hongyan},
  booktitle={Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics},
  pages={562--569},
  year={2003}
}

@article{morris1991lexical,
  title={Lexical cohesion computed by thesaural relations as an indicator of the structure of text},
  author={Morris, Jane and Hirst, Graeme},
  journal={Computational linguistics},
  volume={17},
  number={1},
  pages={21--48},
  year={1991}
}

@article{reynar1994automatic,
  title={An automatic method of finding topic boundaries},
  author={Reynar, Jeffrey C},
  journal={arXiv preprint cmp-lg/9406017},
  year={1994}
}

@article{choi2000advances,
  title={Advances in domain independent linear text segmentation},
  author={Choi, Freddy YY},
  journal={arXiv preprint cs/0003083},
  year={2000}
}

@inproceedings{dias2007topic,
  title={Topic segmentation algorithms for text summarization and passage retrieval: An exhaustive evaluation},
  author={Dias, Ga{\"e}l and Alves, Elsa and Lopes, Jos{\'e} Gabriel Pereira},
  booktitle={AAAI},
  volume={7},
  pages={1334--1340},
  year={2007}
}

@article{alemi2015text,
  title={Text segmentation based on semantic word embeddings},
  author={Alemi, Alexander A and Ginsparg, Paul},
  journal={arXiv preprint arXiv:1503.05543},
  year={2015}
}

@inproceedings{bird2004nltk,
  title={NLTK: the natural language toolkit},
  author={Bird, SG and Loper, Edward},
  year={2004},
  organization={Association for Computational Linguistics}
}

@inproceedings{xu2021topic,
  title={Topic-aware multi-turn dialogue modeling},
  author={Xu, Yi and Zhao, Hai and Zhang, Zhuosheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={16},
  pages={14176--14184},
  year={2021}
}

@article{song2016dialogue,
  title={Dialogue session segmentation by embedding-enhanced texttiling},
  author={Song, Yiping and Mou, Lili and Yan, Rui and Yi, Li and Zhu, Zinan and Hu, Xiaohua and Zhang, Ming},
  journal={arXiv preprint arXiv:1610.03955},
  year={2016}
}



@inproceedings{he2020improvement,
  title={Improvement of Text Segmentation TextTiling Algorithm},
  author={He, Xin and Wang, Jian and Zhang, Quan and Ju, Xiaoming},
  booktitle={Journal of Physics: Conference Series},
  volume={1453},
  number={1},
  pages={012008},
  year={2020},
  organization={IOP Publishing}
}

@article{koshorek2018text,
  title={Text segmentation as a supervised learning task},
  author={Koshorek, Omri and Cohen, Adir and Mor, Noam and Rotman, Michael and Berant, Jonathan},
  journal={arXiv preprint arXiv:1803.09337},
  year={2018}
}

@article{pevzner2002critique,
  title={A critique and improvement of an evaluation metric for text segmentation},
  author={Pevzner, Lev and Hearst, Marti A},
  journal={Computational Linguistics},
  volume={28},
  number={1},
  pages={19--36},
  year={2002},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{jing2021identifying,
  title={Identifying Introductions in Podcast Episodes from Automatically Generated Transcripts},
  author={Jing, Elise and Schneck, Kristiana and Egan, Dennis and Waterman, Scott A},
  journal={arXiv preprint arXiv:2110.07096},
  year={2021}
}

@article{fuller2008using,
  title={Using term clouds to represent segment-level semantic content of podcasts},
  author={Fuller, Marguerite and Tsagkias, Manos and Newman, Eamonn and Besser, Jana and Larson, Martha and Jones, Gareth JF and de Rijke, Maarten},
  journal={CIP GEGEVENS KONINKLIJKE BIBLIOTHEEK, DEN HAAG},
  pages={12},
  year={2008},
  publisher={Citeseer}
}

@inproceedings{nangi2019offvid,
  title={Offvid: A system for linking off-topic concepts to topically relevant video lecture segments},
  author={Nangi, Sharmila Reddy and Kanchugantla, Yashasvi and Rayapati, Pavan Gopal and Bhowmik, Plaban Kumar},
  booktitle={2019 IEEE 19th International Conference on Advanced Learning Technologies (ICALT)},
  volume={2161},
  pages={37--41},
  year={2019},
  organization={IEEE}
}

@article{power2003document,
  title={Document structure},
  author={Power, Richard and Scott, Donia and Bouayad-Agha, Nadjet},
  journal={Computational Linguistics},
  volume={29},
  number={2},
  pages={211--260},
  year={2003},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{dataset,

    title = "100,000 Podcasts: A Spoken {E}nglish Document Corpus",

    author = "Clifton, Ann  and

      Reddy, Sravana  and

      Yu, Yongze  and

      Pappu, Aasish  and

      Rezapour, Rezvaneh  and

      Bonab, Hamed  and

      Eskevich, Maria  and

      Jones, Gareth  and

      Karlgren, Jussi  and

      Carterette, Ben  and

      Jones, Rosie",

    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",

    month = dec,

    year = "2020",

    address = "Barcelona, Spain (Online)",

    publisher = "International Committee on Computational Linguistics",


    pages = "5903--5917",

}

@misc{edison,

    title = "The infinite dial 2020",
    
    author = {{Edison Research and Triton Digital}},
    
    year = "2020",

   

}

@inproceedings{tombros1998advantages,
  title={Advantages of query biased summaries in information retrieval},
  author={Tombros, Anastasios and Sanderson, Mark},
  booktitle={Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={2--10},
  year={1998}
}

% ===================================================================
% Sean References 

@article{el-kassas2021automatic,
	title = {Automatic text summarization: {A} comprehensive survey},
	volume = {165},
	issn = {0957-4174},
	shorttitle = {Automatic text summarization},
	
	doi = {10.1016/j.eswa.2020.113679},
	language = {en},
	
	journal = {Expert Systems with Applications},
	author = {El-Kassas, Wafaa S. and Salama, Cherif R. and Rafea, Ahmed A. and Mohamed, Hoda K.},
	month = mar,
	year = {2021},
	keywords = {Automatic text summarization, Text summarization approaches, Text summarization evaluation, Text summarization techniques},
	pages = {113679},
	file = {ScienceDirect Snapshot:C\:\\Users\\seand\\Zotero\\storage\\X6RHVT2V\\S0957417420305030.html:text/html},
}

@INPROCEEDINGS {ledeneva2009word,
    author = {Y. Ledeneva and R. García-Hernández},
    booktitle = {International Conference on Advances in Computer-Human Interaction},
    title = {Word Sequence Models for Single Text Summarization},
    year = {2009},
    volume = {},
    issn = {},
    pages = {44-48},
    keywords = {extractive summarization; text models; text mining; maximal frequent sequences},
    doi = {10.1109/ACHI.2009.58},
    
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
    month = {feb}
}

@INPROCEEDINGS{kaikhah2004automatic,
  author={Kaikhah, K.},
  booktitle={2004 2nd International IEEE Conference on 'Intelligent Systems'. Proceedings (IEEE Cat. No.04EX791)}, 
  title={Automatic text summarization with neural networks}, 
  year={2004},
  volume={1},
  number={},
  pages={40-44 Vol.1},
  doi={10.1109/IS.2004.1344634}
}
  
  
@inproceedings{moratanch2016survey,
	title = {A survey on abstractive text summarization},
	doi = {10.1109/ICCPCT.2016.7530193},
	booktitle = {2016 {International} {Conference} on {Circuit}, {Power} and {Computing} {Technologies} ({ICCPCT})},
	author = {Moratanch, N. and Chitrakala, S.},
	month = mar,
	year = {2016},
	keywords = {Abstraction Scheme, Abstractive Summary, Computers, Data mining, Lead, Ontologies, Pragmatics, Redundancy, semantic Based Approach, Semantics, Sentence Fusion, Sentence Revision, structure Based Approach, Text Summarization},
	pages = {1--7},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\seand\\Zotero\\storage\\E92C3MJA\\Moratanch and Chitrakala - 2016 - A survey on abstractive text summarization.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\seand\\Zotero\\storage\\FJJ2SB6M\\7530193.html:text/html},
}


@inproceedings{genest2012fully,
	address = {Jeju Island, Korea},
	title = {Fully {Abstractive} {Approach} to {Guided} {Summarization}},
	
	
	booktitle = {Proceedings of the 50th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Genest, Pierre Etienne and Lapalme, Guy},
	month = jul,
	year = {2012},
	pages = {354--358},
	file = {Full Text PDF:C\:\\Users\\seand\\Zotero\\storage\\E8EEZDMU\\Genest and Lapalme - 2012 - Fully Abstractive Approach to Guided Summarization.pdf:application/pdf},
}


@article{gupta2019abstractive,
	title = {Abstractive summarization: {An} overview of the state of the art},
	volume = {121},
	issn = {0957-4174},
	shorttitle = {Abstractive summarization},
	
	doi = {10.1016/j.eswa.2018.12.011},
	language = {en},
	
	journal = {Expert Systems with Applications},
	author = {Gupta, Som and Gupta, S. K},
	month = may,
	year = {2019},
	keywords = {Abstractive summarization, Concept finding, Deep learning, Ontology-Based summarization, Semantic-Based summarization},
	pages = {49--65},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\seand\\Zotero\\storage\\U9FCDAKY\\Gupta and Gupta - 2019 - Abstractive summarization An overview of the stat.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\seand\\Zotero\\storage\\9JVPWQIE\\S0957417418307735.html:text/html},
}

@inproceedings{lewis2019bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2020.acl-main.703",
    pages = "7871--7880",
}


% @article{lewis2019bart,
% 	title = {{BART}: {Denoising} {Sequence}-to-{Sequence} {Pre}-training for {Natural} {Language} {Generation}, {Translation}, and {Comprehension}},
% 	shorttitle = {{BART}},
% 	
% 	
% 	journal = {arXiv:1910.13461 [cs, stat]},
% 	author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
% 	month = oct,
% 	year = {2019},
% 	note = {arXiv: 1910.13461},
% 	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
% 	file = {arXiv Fulltext PDF:C\:\\Users\\seand\\Zotero\\storage\\EHUCR44C\\Lewis et al. - 2019 - BART Denoising Sequence-to-Sequence Pre-training .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\seand\\Zotero\\storage\\PTQAYIKH\\1910.html:text/html},
% }


@article{nallapati2016abstractive,
  title={Abstractive text summarization using sequence-to-sequence rnns and beyond},
  author={Nallapati, Ramesh and Zhou, Bowen and Gulcehre, Caglar and Xiang, Bing and others},
  journal={arXiv preprint arXiv:1602.06023},
  year={2016}
}

% @article{nallapati2016abstractive,
% 	title = {Abstractive {Text} {Summarization} {Using} {Sequence}-to-{Sequence} {RNNs} and {Beyond}},
% 	
% 	
% 	journal = {arXiv:1602.06023 [cs]},
% 	author = {Nallapati, Ramesh and Zhou, Bowen and santos, Cicero Nogueira dos and Gulcehre, Caglar and Xiang, Bing},
% 	month = aug,
% 	year = {2016},
% 	note = {arXiv: 1602.06023},
% 	keywords = {Computer Science - Computation and Language},
% 	file = {arXiv Fulltext PDF:C\:\\Users\\seand\\Zotero\\storage\\FAKVVHXU\\Nallapati et al. - 2016 - Abstractive Text Summarization Using Sequence-to-S.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\seand\\Zotero\\storage\\2UFCMF4K\\1602.html:text/html},
% }

@inproceedings{narayan2018dont,
    title = "Don{'}t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization",
    author = "Narayan, Shashi  and
      Cohen, Shay B.  and
      Lapata, Mirella",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/D18-1206",
    pages = "1797--1807",
}


% @article{narayan2018dont,
% 	title = {Don't {Give} {Me} the {Details}, {Just} the {Summary}! {Topic}-{Aware} {Convolutional} {Neural} {Networks} for {Extreme} {Summarization}},
% 	
% 	
% 	journal = {arXiv:1808.08745 [cs]},
% 	author = {Narayan, Shashi and Cohen, Shay B. and Lapata, Mirella},
% 	month = aug,
% 	year = {2018},
% 	note = {arXiv: 1808.08745},
% 	keywords = {Computer Science - Computation and Language},
% 	annote = {Comment: 11, 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018},
% 	file = {arXiv Fulltext PDF:C\:\\Users\\seand\\Zotero\\storage\\3J89TAR8\\Narayan et al. - 2018 - Don't Give Me the Details, Just the Summary! Topic.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\seand\\Zotero\\storage\\LN562SK4\\1808.html:text/html},
% }

@inproceedings{zhang2020pegasus,
author = {Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter J.},
title = {PEGASUS: Pre-Training with Extracted Gap-Sentences for Abstractive Summarization},
year = {2020},
publisher = {JMLR.org},
abstract = {Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization. However, pre-training objectives tailored for abstractive text summarization have not been explored. Furthermore there is a lack of systematic evaluation across diverse domains. In this work, we propose pretraining large Transformer-based encoder-decoder models on massive text corpora with a new self-supervised objective. In PEGASUS, important sentences are removed/masked from an input document and are generated together as one output sequence from the remaining sentences, similar to an extractive summary. We evaluated our best PEGASUS model on 12 downstream summarization tasks spanning news, science, stories, instructions, emails, patents, and legislative bills. Experiments demonstrate it achieves state-of-the-art performance on all 12 downstream datasets measured by ROUGE scores. Our model also shows surprising performance on low-resource summarization, surpassing previous state-of-the-art results on 6 datasets with only 1000 examples. Finally we validated our results using human evaluation and show that our model summaries achieve human performance on multiple datasets.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {1051},
numpages = {12},
series = {ICML'20}
}


% @article{zhang2020pegasus,
% 	title = {{PEGASUS}: {Pre}-training with {Extracted} {Gap}-sentences for {Abstractive} {Summarization}},
% 	shorttitle = {{PEGASUS}},
% 	
% 	
% 	journal = {arXiv:1912.08777 [cs]},
% 	author = {Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter J.},
% 	month = jul,
% 	year = {2020},
% 	note = {arXiv: 1912.08777
% version: 2},
% 	keywords = {Computer Science - Computation and Language},
% 	annote = {Comment: Added results from mixed+stochastic model, test-set overlapping analysis; Code link added; Accepted for ICML 2020. arXiv admin note: text overlap with arXiv:1605.06560, arXiv:1205.2395, arXiv:0902.4351, arXiv:1610.09932, arXiv:nucl-ex/0512029 by other authors},
% 	file = {arXiv Fulltext PDF:C\:\\Users\\seand\\Zotero\\storage\\MJ3IQ685\\Zhang et al. - 2020 - PEGASUS Pre-training with Extracted Gap-sentences.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\seand\\Zotero\\storage\\K9T3GXLT\\1912.html:text/html},
% }


@inproceedings{zhang2019email,
	address = {Florence, Italy},
	title = {This {Email} {Could} {Save} {Your} {Life}: {Introducing} the {Task} of {Email} {Subject} {Line} {Generation}},
	shorttitle = {This {Email} {Could} {Save} {Your} {Life}},
	
	doi = {10.18653/v1/P19-1043},
	
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Rui and Tetreault, Joel},
	month = jul,
	year = {2019},
	pages = {446--456},
}

@article{raffel2020exploring,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
}


% @article{raffel2020exploring,
% 	title = {Exploring the {Limits} of {Transfer} {Learning} with a {Unified} {Text}-to-{Text} {Transformer}},
% 	
% 	
% 	journal = {arXiv:1910.10683 [cs, stat]},
% 	author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
% 	month = jul,
% 	year = {2020},
% 	note = {arXiv: 1910.10683
% version: 3},
% 	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
% 	annote = {Comment: Final version as published in JMLR},
% 	file = {arXiv Fulltext PDF:C\:\\Users\\seand\\Zotero\\storage\\4FV6LAN9\\Raffel et al. - 2020 - Exploring the Limits of Transfer Learning with a U.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\seand\\Zotero\\storage\\ZXTJ6IBD\\1910.html:text/html},
% }

@inproceedings{rezapour2020spotify,
  author    = {Rezvaneh Rezapour and
               Sravana Reddy and
               Ann Clifton and
               Rosie Jones},
  editor    = {Ellen M. Voorhees and
               Angela Ellis},
  title     = {Spotify at {TREC} 2020: Genre-Aware Abstractive Podcast Summarization},
  booktitle = {Proceedings of the Twenty-Ninth Text REtrieval Conference, {TREC}
               2020, Virtual Event [Gaithersburg, Maryland, USA], November 16-20,
               2020},
  series    = {{NIST} Special Publication},
  volume    = {1266},
  publisher = {National Institute of Standards and Technology {(NIST)}},
  year      = {2020}
}


% @article{rezapour2020spotify,
% 	title = {Spotify at {TREC} 2020: {Genre}-{Aware} {Abstractive} {Podcast} {Summarization}},
% 	language = {en},
% 	author = {Rezapour, Rezvaneh and Reddy, Sravana and Clifton, Ann and Jones, Rosie},
% 	year = {2020},
% 	pages = {7},
% 	file = {Rezapour et al. - Spotify at TREC 2020 Genre-Aware Abstractive Podc.pdf:C\:\\Users\\seand\\Zotero\\storage\\QHNMFYUI\\Rezapour et al. - Spotify at TREC 2020 Genre-Aware Abstractive Podc.pdf:application/pdf},
% }

@inproceedings{karlbom2020abstractive,
  author    = {Hannes Karlbom and
               Ann Clifton},
  editor    = {Ellen M. Voorhees and
               Angela Ellis},
  title     = {Abstract Podcast Summarization using {BART} with Longformer Attention},
  booktitle = {Proceedings of the Twenty-Ninth Text REtrieval Conference, {TREC}
               2020, Virtual Event [Gaithersburg, Maryland, USA], November 16-20,
               2020},
  series    = {{NIST} Special Publication},
  volume    = {1266},
  publisher = {National Institute of Standards and Technology {(NIST)}},
  year      = {2020},
}


% @inproceedings{karlbom2020abstractive,
% 	title = {Abstractive {Podcast} {Summarization} using {BART} with {Longformer} {Attention}},
% 	booktitle = {{TREC}},
% 	author = {Karlbom, Hannes and Clifton, A.},
% 	year = {2020},
% }


@misc{beltagy2020longformer,
  doi = {10.48550/ARXIV.2004.05150},
  
  author = {Beltagy, Iz and Peters, Matthew E. and Cohan, Arman},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Longformer: The Long-Document Transformer},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

% @article{beltagy2020longformer,
% 	title = {Longformer: {The} {Long}-{Document} {Transformer}},
% 	shorttitle = {Longformer},
% 	
% 	urldate = {2022-04-02},
% 	journal = {arXiv:2004.05150 [cs]},
% 	author = {Beltagy, Iz and Peters, Matthew E. and Cohan, Arman},
% 	month = dec,
% 	year = {2020},
% 	note = {arXiv: 2004.05150},
% 	keywords = {Computer Science - Computation and Language},
% 	annote = {Comment: Version 2 introduces the Longformer-Encoder-Decoder (LED) model},
% 	file = {arXiv Fulltext PDF:C\:\\Users\\seand\\Zotero\\storage\\VKVMS4KW\\Beltagy et al. - 2020 - Longformer The Long-Document Transformer.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\seand\\Zotero\\storage\\YQGKMXTN\\2004.html:text/html},
% }


@misc{graff2003english,
	title = {English {Gigaword}},
	
	
	publisher = {Linguistic Data Consortium},
	author = {Graff, David and Cieri, Christopher},
	month = jan,
	year = {2003},
	doi = {10.35111/0Z6Y-Q265},
}

@article{aghajanyan2021muppet,
	title = {Muppet: {Massive} {Multi}-task {Representations} with {Pre}-{Finetuning}},
	shorttitle = {Muppet},
	
	
	journal = {arXiv:2101.11038 [cs]},
	author = {Aghajanyan, Armen and Gupta, Anchit and Shrivastava, Akshat and Chen, Xilun and Zettlemoyer, Luke and Gupta, Sonal},
	month = jan,
	year = {2021},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\seand\\Zotero\\storage\\C797T7J3\\Aghajanyan et al. - 2021 - Muppet Massive Multi-task Representations with Pr.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\seand\\Zotero\\storage\\JD7LXRIE\\2101.html:text/html},
}


@inproceedings{wolf2020transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Wolf, Thomas  and
      Debut, Lysandre  and
      Sanh, Victor  and
      Chaumond, Julien  and
      Delangue, Clement  and
      Moi, Anthony  and
      Cistac, Pierric  and
      Rault, Tim  and
      Louf, Remi  and
      Funtowicz, Morgan  and
      Davison, Joe  and
      Shleifer, Sam  and
      von Platen, Patrick  and
      Ma, Clara  and
      Jernite, Yacine  and
      Plu, Julien  and
      Xu, Canwen  and
      Le Scao, Teven  and
      Gugger, Sylvain  and
      Drame, Mariama  and
      Lhoest, Quentin  and
      Rush, Alexander",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2020.emnlp-demos.6",
    pages = "38--45",
    abstract = "Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.",
}


% @article{wolf2020huggingfaces,
% 	title = {{HuggingFace}'s {Transformers}: {State}-of-the-art {Natural} {Language} {Processing}},
% 	shorttitle = {{HuggingFace}'s {Transformers}},
% 	
% 	
% 	journal = {arXiv:1910.03771 [cs]},
% 	author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Scao, Teven Le and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
% 	month = jul,
% 	year = {2020},
% 	note = {arXiv: 1910.03771},
% 	keywords = {Computer Science - Computation and Language},
% }

@inproceedings{clifton2020100000,
	address = {Barcelona, Spain (Online)},
	title = {100,000 {Podcasts}: {A} {Spoken} {English} {Document} {Corpus}},
	shorttitle = {100,000 {Podcasts}},
	
	doi = {10.18653/v1/2020.coling-main.519},
	
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {International Committee on Computational Linguistics},
	author = {Clifton, Ann and Reddy, Sravana and Yu, Yongze and Pappu, Aasish and Rezapour, Rezvaneh and Bonab, Hamed and Eskevich, Maria and Jones, Gareth and Karlgren, Jussi and Carterette, Ben and Jones, Rosie},
	month = dec,
	year = {2020},
	pages = {5903--5917},
}


@book{johannesson2014introduction,
	address = {Cham},
	title = {An {Introduction} to {Design} {Science}},
	isbn = {978-3-319-10631-1 978-3-319-10632-8},
	
	language = {en},
	
	publisher = {Springer International Publishing},
	author = {Johannesson, Paul and Perjons, Erik},
	year = {2014},
	doi = {10.1007/978-3-319-10632-8},
	file = {10.1007978-3-319-10632-8.pdf:C\:\\Users\\seand\\Zotero\\storage\\NGL9NCFW\\10.1007978-3-319-10632-8.pdf:application/pdf},
}



@article{casares2022embracing,
	title = {Embracing the {Podcast} {Era}: {Trends}, {Opportunities}, \& {Implications} for {Counselors}},
	volume = {17},
	issn = {1540-1383},
	shorttitle = {Embracing the {Podcast} {Era}},
	
	doi = {10.1080/15401383.2020.1816865},
	number = {1},
	
	journal = {Journal of Creativity in Mental Health},
	author = {Casares, D. Robert},
	month = jan,
	year = {2022},
	keywords = {creativity in counseling, digital technology, engaged scholarship, Podcasting, popular culture, practice support},
	pages = {123--138},
}

@software{Diacono_Spotify_Text_Segmentation_2022,
author = {Diacono, Sean and Aquilina, Andrew},
month = may,
title = {{Spotify Text Segmentation and Summarisation}},
year = {2022},
url = "https://github.com/seandiacono/Spotify-Topic-Segmentation"
}

@software{Hiroki_seg_eval,
author = {Hiroki Nakayama},
month = november,
title = {{Hiroki Nakayama}},
year = {2020},
url = "https://github.com/chakki-works/seqeval"
}

@software{textsplit,
author = {Christoph Schock},
month = may,
title = {{textsplit}},
year = {2020},
url = "https://github.com/chschock/textsplit"
}

@inproceedings{calizzano2022generating,
  title={Generating Extended and Multilingual Summaries with Pre-trained Transformers},
  author={Calizzano, R{\'e}mi and Ostendorff, Malte and Ruan, Qian and Rehm, Georg},
  booktitle={Proceedings of the Thirteenth Language Resources and Evaluation Conference},
  pages={1640--1650},
  year={2022}
}

% =====================================================================

@article{liu2021end,
  title={End-to-end segmentation-based news summarization},
  author={Liu, Yang and Zhu, Chenguang and Zeng, Michael},
  journal={arXiv preprint arXiv:2110.07850},
  year={2021}
}

@article{cho2022toward,
  title={Toward Unifying Text Segmentation and Long Document Summarization},
  author={Cho, Sangwoo and Song, Kaiqiang and Wang, Xiaoyang and Liu, Fei and Yu, Dong},
  journal={arXiv preprint arXiv:2210.16422},
  year={2022}
}

@article{miculicich2023document,
  title={Document summarization with text segmentation},
  author={Miculicich, Lesly and Han, Benjamin},
  journal={arXiv preprint arXiv:2301.08817},
  year={2023}
}