\documentclass[reqno]{amsart}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage[colorlinks=true,linkcolor=blue,citecolor={olive}]{hyperref}
%\usepackage{hyperref}
\usepackage[nocompress]{cite}
\usepackage{mathrsfs}
\usepackage{subcaption}

% For writing and debugging
%\usepackage{todonotes}
%\usepackage{showkeys}
%\usepackage{refcheck}


\newcommand{\indicator}[1]{\ensuremath{\mathbf{1}_{\{#1\}}}}
\newcommand{\oindicator}[1]{\ensuremath{\mathbf{1}_{{#1}}}}

\newcommand{\Le}{\mathcal{L}}
\DeclareMathOperator{\comp}{Comp}
\DeclareMathOperator{\incomp}{Incomp}
\DeclareMathOperator{\spread}{Spread}

\newcommand{\pre}[1]{\ensuremath{{}^{(#1)}}}

\newcommand{\1}{\mathbf{1}}
\newcommand{\BJ}{\mathbf{J}}

\newcommand{\relmiddle}[1]{\mathrel{}\middle#1\mathrel{}}


%\numberwithin{equation}{section}

\DeclareMathOperator{\cov}{Cov}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\supp}{supp}

\newcommand{\Prob}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\C}{\mathbb{C}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\D}{\mathbb{D}}
\renewcommand\Re{\operatorname{Re}}
\renewcommand\Im{\operatorname{Im}}
\newcommand{\eps}{\varepsilon}
\newcommand*\lap{\mathop{}\!\Delta}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\V}{\mathbb{V}}


\newcommand{\U}{\mathrm{U}}
\newcommand{\Or}{\mathrm{O}}
\newcommand{\SO}{\mathrm{SO}}
\newcommand{\Sp}{\mathrm{Sp}}
\def\R{\mathbb{R}}
\newcommand{\mat}{\mathbf}
\newcommand{\vect}{\mathbf}
\renewcommand{\d}{\, d }

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{thmx}{Theorem}
\renewcommand{\thethmx}{\Alph{thmx}} % "letter-numbered" theorems

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{question}[theorem]{Question}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{heuristic}[theorem]{Heuristic}


\newcommand{\rdplus}{\oplus}
\newcommand{\DiffCon}{\boxplus_D}

\newcommand{\cor}{\color{red}}

\numberwithin{equation}{section}


\begin{document}
	
	\title[The fractional free convolution of $R$-diagonal operators]{The fractional free convolution of $R$-diagonal operators and random polynomials under repeated differentiation}
	
	\author{Andrew Campbell}
	\address{Institute of Science and Technology Austria, Am Campus 1, 3400 Klosterneuburg, Austria}
	\email{andrew.campbell@ist.ac.at}
	\thanks{A. Campbell partially supported by ERC Advanced Grant ”RMTBeyond” No. 101020331}
	
	\author{Sean O'Rourke}
	\address{Department of Mathematics\\ University of Colorado\\ Campus Box 395\\ Boulder, CO 80309-0395\\USA}
	\email{sean.d.orourke@colorado.edu}
	\thanks{This material is based upon work supported by the National Science Foundation under Grant No. DMS-2143142. }
	
	\author{David Renfrew}
	\address{Department of Math and Statistics\\ Binghamton University (SUNY)\\ Binghamton, NY 3902-6000\\USA}
	\email{renfrew@math.binghamton.edu}
	
	
	\begin{abstract}
		We extend the free convolution of Brown measures of $R$-diagonal elements introduced by K\"{o}sters and Tikhomirov [Probab. Math. Statist. 38 (2018), no. 2, 359--384] to fractional powers.  We then show how this fractional free convolution arises naturally when studying the roots of random polynomials with independent coefficients under repeated differentiation.  When the proportion of derivatives to the degree approaches one, we establish central limit theorem-type behavior and discuss stable distributions.  
	\end{abstract}
	
	
	
	\maketitle 
	
	\tableofcontents
	
	
	\section{Introduction} \label{sec:intro}
	
	The definition of the free convolution $\mu \boxplus \nu$ of two compactly supported probability measures $\mu, \nu$ on the real line is due to Voiculescu \cite{MR839105}.  One can define $\mu \boxplus \nu$ to be the asymptotic limit of the empirical spectral measure of $A_n + B_n$ as $n \to \infty$, where $A_n$ and $B_n$ are independent $n \times n$ random Hermitian matrices, invariant under unitary conjugation, whose individual empirical spectral measures converge to $\mu$ and $\nu$, respectively.  Alternatively, one can define the free convolution using the $R$-transform (see \eqref{eq:RM}, below, for the definition).  Any compactly supported probability measure $\mu$ on the real line is uniquely defined by its $R$-transform $R_{\mu}(z)$ for sufficiently small values of the complex argument $z$.   Heuristically, the $R$-transform can be viewed as the free probability analogue of the cumulant generating function from classical probability theory.  

	In fact, the free convolution $\mu \boxplus \nu$ is the unique compactly supported probability measure on the real line whose $R$-transform $R_{\mu \boxplus \nu}$ satisfies 
	\[ {R}_{\mu \boxplus \nu}(z) = {R}_{\mu}(z) + {R}_{\nu}(z) \]
	for all sufficiently small values of $z$.  It follows that for an integer $k \geq 1$, $\mu^{\boxplus k}$, the free convolution of $\mu$ with itself $k$ times, can be characterized by the identity 
	\begin{equation} \label{eq:real:kdef}
		{R}_{\mu^{\boxplus k}}(z) = k {R}_{\mu}(z) 
	\end{equation} 
	for all sufficiently small $z$.  
	In fact, using \eqref{eq:real:kdef}, one can define the fractional free convolution $\mu^{\boxplus k}$ for any real $k \geq 1$.  This was first shown for $k$ sufficiently large by Bercovici and Voiculescu \cite{MR1355057} and then for all real $k \geq 1$ by Nica and Speicher \cite{MR1400060}. 
	
	
	Amazingly, as the following theorem shows, the free convolution can also be characterized in terms of random polynomials and the roots of their derivatives \cite{2009.03869,doi:10.1080/10586458.2021.1980752,2108.08489}.  We define the {\bf empirical root distribution} of a polynomial $p$ of degree $d$ and roots $x_1, \ldots, x_d$ (counted with multiplicity) to be the probability measure 
	\[ \frac{1}{d} \sum_{i=1}^d \delta_{x_i}, \]
	where $\delta_x$ is the point mass at $x$. 
	
	\begin{theorem}[Hoskins--Kabluchko, Steinerberger, Arizmendi--Garza-Vargas--Perales] \label{thm:AGP}
		Let $\mu$ be a compactly supported probability measure on the real line, and let $p_n$ be the random polynomial 
		\[ p_n(x):= \prod_{i=1}^n (x - X_i), \]
		where $X_1, X_2, \ldots$ are independent and identically distributed (iid) random variables with distribution $\mu$. 
		For any fixed $t \in (0,1)$, the empirical root distribution of the $\lceil (1-t)n \rceil$-th derivative of $p_n(tx)$ converges weakly almost surely to $\mu^{\boxplus 1/t}$ as $n \to \infty$.  
	\end{theorem}
	In other words, for a random polynomial with independent real roots, the fractional free convolution $\mu^{\boxplus 1/t}$ describes the roots of its derivatives.  	The factor of $t$ in $p_n(tx)$ simply scales the roots by $t^{-1}$.  We refer the reader to Section 3 of \cite{2108.08489} for a short proof of a more general version of Theorem \ref{thm:AGP}.  
	
	One of the goals of this paper is to extend the result above to a class of random polynomials with complex roots. In particular, we extend the notion of the free convolution of Brown measures (defined in \eqref{eq:oplus definition}) that was introduced in \cite{MR3896715} to fractional powers and show how these fractional convolution powers can be used to describe a similar relationship as in Theorem \ref{thm:AGP} for random polynomials with independent coefficients.  For a rotationally invariant measure $\mu$ in the complex plane, our result requires acting on $\mu$ by a bijection $\psi_2$, where $\psi_2\mu(\mathbb{D}_r):=\mu(\mathbb{D}_{\sqrt{r}})$ for $r > 0$ and $\mathbb{D}_r:=\{z \in \mathbb{C}: |z|< r\}$. In particular, an example of our main results is stated below in Theorem \ref{thm:A:Kacs free convolution}. The general version is given in Theorem \ref{thm:A:connection general case}, below. We discuss this example more in Section \ref{sec:Haar}.
	
	 \begin{theorem}\label{thm:A:Kacs free convolution}
					Let \begin{equation} \label{eq:kacmodel}
				p_n(z):=\sum_{k=0}^{n}\xi_kz^k 
			\end{equation} be a random polynomial such that $\xi_0,\xi_1, \ldots$ are independent identically distributed standard complex Gaussian random variables. Then the empirical root measure of $p_n$ is known to converge in probability to the uniform probability measure $\mu$ on the unit circle. 	
			For any fixed $t \in (0,1)$, the empirical root distribution of the $\lceil (1-t)n \rceil$-th derivative of $p_n(t^2x)$ converges weakly in probability to $\psi_2(\psi_2^{-1}\mu)^{\oplus 1/t}$ as $n \to \infty$, where the operation $\cdot^{\oplus\frac{1}{t}}$ is a fractional power of a convolution $\oplus$ on rotationally invariant probability measures, defined in Section \ref{sec:fracBrown}.
		\end{theorem}
		 Here it is worth noting $\psi_2^{-1}\mu=\mu$, however we chose to include $\psi_2^{-1}$ in the statement of Theorem \ref{thm:A:Kacs free convolution} to match the more general result, Theorem \ref{thm:A:connection general case}. It may be helpful to interpret the rescaling of $t^{-2}$ for the roots of the $\lceil (1-t)n \rceil$-th derivative of the polynomial as $t^{-1}t^{-1}$, where one factor of $t^{-1}$ is to account for the natural collapse of the roots under differentiation given by the Gauss--Lucas theorem and the other $t^{-1}$ is to match the diffusion under the convolution.
		The definition of $\oplus$ can be technical for those unfamiliar with free probability theory, so we illustrate the connection in Theorem \ref{thm:A:Kacs free convolution} to sums of random matrices, with an example first proved in \cite{MR3091727}. The analogous notion of the empirical root measure for an $n\times n$ random matrix $M$ is the \textbf{empirical spectral measure} $\mu_M$ given by \begin{equation*}
			\mu_{M}:=\frac{1}{n}\sum_{k=1}^n\delta_{\lambda_k(M)},
		\end{equation*} where $\lambda_1(M),\dots,\lambda_n(M) \in \mathbb{C}$ are the eigenvalues of $M$ (counted with algebraic multiplicity). \begin{proposition} [Basak--Dembo] \label{prop:sumsunitary}
			Fix an integer $k \geq 1$, and let $U_n^{(1)},\dots,U_n^{(k)}$ be independent  $n \times n$ Haar distributed unitary random matrices. Then the empirical spectral measure of $U_n^{(1)}+\cdots+U_n^{(k)}$ converges almost surely as $n \to \infty$ to $\mu^{\oplus k}$, where $\mu$ is the uniform probability measure on the unit circle. 
					\end{proposition}
		
				
				Numerical simulations of Theorem \ref{thm:A:Kacs free convolution} and Proposition \ref{prop:sumsunitary} are given in Figure \ref{fig:radial}.  
				
				The paper is organized as follows.  In Sections \ref{sec:free-prob} and \ref{sec:rand-poly}, we will give some necessary background, known results, and notation concerning free probability theory and random polynomials, respectively. In Section \ref{sec:fracBrown}, we extend the notion of the free convolution of Brown measures (see Section \ref{sec:freeprob}) of $R$-diagonal elements (see Section \ref{sec:Rdiag}) that was introduced in \cite{MR3896715} to fractional powers.  Then in Section \ref{sec:connection}, we will describe how this fractional free convolution is related to roots of derivatives of random polynomials with independent coefficients. In Section \ref{sec:repderiv}, we study the limit of the roots process, when the proportion of derivatives to the degree approaches one. Finally, in Section \ref{sec:examples} we give several examples, giving particular attention to the distributions that are stable under $\oplus$ and their relationship to the roots of derivatives of random polynomials.
				
% Figure environment removed
				
								
				\subsection*{Acknowledgments}
				The second author thanks Noah Williams for providing references.  The third author acknowledges the support of the University of Colorado Boulder, where a portion of this work was completed.  
				
				
				\section{Free probability theory background} \label{sec:free-prob}
				
				The large $n$ limit of the empirical spectral measure of $n\times n$ random matrices can often be computed using free probability. In this section, we will introduce the necessary background; we refer the reader to the texts, surveys, and research articles cited in this section for additional details.  
				
				\subsection{Free probability theory background and notation}\label{sec:freeprob}
				
We work on the non-commutative probability space $(\mathscr{M}, \tau)$, where $\mathscr{M}$ is a von Neumann algebra with normal faithful tracial state $\tau$. When working with unbounded elements we consider the von Neumann algebra that they are affiliated with, see Remarks \ref{rem:aff} and \ref{rem:aff2}, below. An element $u \in \mathscr{M}$ is called \textbf{Haar unitary} if $u^\ast u = u u^\ast = 1$ and $\tau(u^n) = 0$ for all $n \in \mathbb{N}$, where $\mathbb{N} = \{1, 2, 3, \ldots \}$ is the set of natural numbers. Here and in the future we use $1$ to denote the identity operator in $\mathscr{M}$. When $h$ is a self-adjoint element in $\mathscr{M}$, we let $\mu_h$ be the unique compactly supported probability measure on $\mathbb{R}$ so that
				\[ \tau(h^n) = \int_{\mathbb{R}} t^n \d \mu_h(t), \qquad n \in \mathbb{N}. \]
				
				We now introduce the free probability transform that we will use to characterize measures. The \textbf{moment generating function} $M_{\mu}$ of a probability measure, $\mu$, is given by:
				\[M_{\mu}(z) :=  \int \frac{zt}{1 - zt} d\mu(t) \]
				for $z \in \C \setminus \supp(\mu)$. Note that if $\mu$ is compactly supported, then for sufficiently small $z$ we have the power series expansion:
				\[\sum_{k=1}^\infty z^k \tau(h^k) =  \sum_{k=1}^\infty z^k \int_{\mathbb{R}} t^k \d \mu_h(t) .\]
				
				We then define the \textbf{$R$-transform}\footnote{We note that in the free probability literature, there are two different commonly-used $R$-transforms, which differ by a factor of $z$.} $R_\mu$ of $\mu$ to be the function that satisfies:
				\begin{equation} \label{eq:RM}  R_{\mu}(  z(1 + M_{\mu}(z)) ) =  M_{\mu}(z)) ,\end{equation}
				for $z$ in a neighborhood of the origin with $z \neq 0$. In what follows we will identify the various transforms of measures with the corresponding transform of the operator for which the measure was generated, for example $ R_{h} := R_{\mu_h}$.

				If $\int_{\mathbb{R}} t \d \mu(t) \neq 0$, we can define the \textbf{$S$-transform}, $\mathscr{S}_\mu$, of $\mu$ as in \cite{MR2266879,MR1217253}, 
				by the identity: 
				\begin{equation} \label{eq:Stran} \mathscr{S}_\mu(z) := \frac{1}{z} R_{\mu}^{\langle -1 \rangle}(z) \end{equation}
				for $z$ in neighborhood of $0$. Here $( \cdot )^{\langle -1 \rangle}$ denotes inversion with respect to composition.
				
				\begin{remark} \label{rem:Stran}
					The primary utility of the $S$-transform is that it linearizes multiplication: if $a$ and $b$ are freely independent such that $\mu_a$ and $\mu_b$ are supported on $\R^+$, then $\mathscr{S}_{a b}(z) =\mathscr{S}_{a}(z) \mathscr{S}_b(z) $. 
					In what follows it is useful to note that the $S$-transform of the delta mass $\delta_c(x)$ is $\mathscr{S}_{\delta_c}(z) = c^{-1}$ and that the $S$-transform of $\mu_{aa^*}$ can be analytically continued to the open interval $(-1+\mu_a({0}),0)$ and maps this interval monotonically into $\R^+$ (see, for instance \cite{MR1784419}, Theorem 4.4).
					The $S$-transform can alternatively be defined as 
					\[ \mathscr{S}_\mu(z) = \frac{1+z}{z} M_{\mu}^{\langle -1 \rangle}(z), \]
					where the equivalence of these definitions is shown in \cite{MR2266879}, Remarks 16.18 and 18.16. 
						\end{remark}	
				
				When considering a family of (not necessarily self-adjoint) elements  $a_1, \ldots, a_s \in \mathscr{M}$, we consider their \textbf{joint $\ast$-distribution}, given by linear functionals from non-commutative polynomials, $Q(X_1,X_1^*, \ldots, X_s,X_s^*)$, in indeterminants $X_1,X_1^*, \ldots, X_s,X_s^*$ to $\C$: 
\[ \tau( Q(a_1, a_1^*\ldots, a_s,a_s^*) ) .\]
				When $s=1$, we call this the \textbf{$\ast$-distribution} of $a_1$.
				
				
				As in the single variable case, the joint $\ast$-distribution is encoded in the multivariable $R$-transform, $R:=R_{a_1,\ldots,a_s}(z_1,\ldots,z_s),$ which we define to be the power series that satisfies the natural generalization of \eqref{eq:RM}: \[ M = R(z_1(1+M),\ldots,z_n(1+M)),\] where \[ M:=M_{a_1,\ldots,a_k}(z_1,\ldots,z_k) := \sum_{n=1}^\infty \sum_{i_1,\ldots,i_n=1}^k \tau(a_{i_1} \cdots a_{i_n})z_{i_1} \cdots z_{i_n}  ,\]
				is the multivariate moment generating function and $z_1,\ldots,z_k$ are non-commuting indeterminants. The coefficients of the $R$-transform are called the \textbf{free cumulants}, and the $n$-th free cumulant is denoted by $\kappa_n(a_{i_1},\ldots,a_{i_n})$: 
				\[ R(z_1,\ldots,z_k) = \sum_{n=1}^\infty \sum_{i_1,\ldots,i_n=1}^k \kappa_n(a_{i_1},\cdots,a_{i_n})  z_{i_1} \ldots z_{i_n}. \]
				The free cumulants are multi-linear functions. 
				We refer the reader to \cite{MR2266879}, Section 16, where the free cumulants are instead first defined through a moment-cumulant relation and then Theorem 16.15 and Corollary 16.16 show that this is an equivalent definition. In particular, the free cumulants can be recovered from the joint moments and vice versa.				
				
				
				We now use the $R$-transform to define free independence of non-commutative random variables. Once again we will give an analytic definition and refer the reader to Section 16  of \cite{MR2266879} for a combinatorial definition in terms of the free cumulants, in particular Theorem 16.6 and Remark 16.7, where the equivalence of the two definitions is shown.
				
				
				We say that a collection $a_1, \ldots, a_k$ of elements in $\mathscr{M}$ are \textbf{$\ast$-freely independent} if 
				\begin{equation} \label{eq:freeness} R_{a_1,a_1^* \ldots, a_k,a_k^*}(z_1,z_2 \ldots ,z_{2k-1},z_{2k})  =  R_{a_1,a_1^*}(z_1,z_2)+ \cdots + R_{a_k,a_k^*}(z_{2k-1},z_{2k}) ,
				\end{equation}
				in particular, the mixed cumulants vanish. 
				
				\begin{remark} \label{rem:aff}
					When considering an unbounded element $a$, one must instead treat it as an element affiliated to $W^*(a)$, the von Neumann algebra generated by the spectral projections of $|a|$. We then say unbounded elements are freely independent if all elements of their respective affiliated algebras are free. We refer the reader to \cite{MR2339369}, Section 3, for details. 
					
				\end{remark}
					
							\subsection{The fractional free convolution for self-adjoint operators}\label{sec:FFCr}
			
			
			
			
			Nica and Speicher \cite{MR1400060} give the fractional convolution powers from \eqref{eq:real:kdef} an additional free probability interpretation, for which we must first introduce additional background. Let $p \in \mathcal{M}$ be a self-adjoint projection with $\tau(p) = \lambda$ for some $\lambda \in (0,1]$, and then consider the new non-commutative probability space $(\mathcal{M}_p, \tau_p)$ given by\footnote{The brackets $[]$ are a formal symbol, which we introduce in order to distinguish $\mathscr{M}_p$ from $\mathscr{M}$.} :
			\[  \mathcal{M}_p := \{  [p a p]: a \in  \mathcal{M} \}  \]
			with 
			\[ \tau_p( [p a p]) = \lambda^{-1} \tau(p a p) \]
			for any $a \in  \mathcal{M}$. We then consider the map $\pi_{\lambda}: \mathcal{M} \to \mathcal{M}_p$ by $ \pi_{\lambda}(a) := [p a p]$, which we will call the {\bf free compression} of $a$. When $\lambda$ is fixed, we will omit it from the notation. Note that in $\mathcal{M}_p$, we have that $ \pi(a^*) = \pi(a)^*, \pi(a) + \pi(b) = \pi(a+b) ,$ and $ \pi(a)\pi(b)= \pi(apb)=\pi(papbp)$.
			In Corollary 1.14 from \cite{MR1400060}, it is shown that if $a$ is a self-adjoint element in $ \mathcal{M}$ with law $\mu$, that is freely independent of $p$, with $\tau(p)=1/k$, then $k \pi(a )$ has the law $\mu^{\boxplus k}$.
			
					
		\subsection{The Brown measure}\label{sec:Brown}
				
				
				If $a$ is a non-normal element in $\mathscr{M}$, then its distribution is not determined by its moments. Nevertheless, there is a distinguished measure associated to $a$, called its Brown measure, which we now introduce.
				We let $\Delta$ denote the Fuglede--Kadison determinant on $(\mathscr{M}, \tau)$ (see \cite{MR52696}), and let $L$ denote $\log \Delta$. It follows that, for $a \in \mathscr{M}$, 
				\[ L(a) = L(a^\ast a) / 2 = L(a^\ast) = \int_{\mathbb{R}} \log t \d \mu_{|a|}(t) \in [-\infty, \infty). \]
				The function $\lambda \mapsto \frac{1}{2 \pi} L(a - \lambda 1)$ is subharmonic on $\mathbb{C}$, and by the Riesz representation theorem can be identified with a regular probability measure, which is called the \textbf{Brown measure} for $a$ (see \cite{MR866489}) and is denoted as $\mu_a$.  The measure $\mu_a$ is defined as
				\[ \mu_a := \frac{1}{2 \pi} \nabla^2 L(a - \lambda 1)  \]
where $\nabla^2$ denotes the Laplacian, interpreted in the distributional sense. 
				Note that the notation $\mu_a$ agrees with the previously introduced notation for positive elements of $\mathscr{M}$. The Brown measure has a number of important properties\cite{MR1784419}:
				\begin{itemize}
					\item $\mu_a$ is the unique compactly supported measure that fulfills 
					\[ L(a - \lambda 1) = \int_{\mathbb{C}} \log |z - \lambda| \d \mu_a(z) \]
					for Lebesgue almost all complex numbers $\lambda$.
					\item The support of $\mu_a$ is contained in the spectrum of $a$, and for any natural number $n$
					\[ \tau(a^n) = \int_{\mathbb{C}}z^p \d \mu_a(z). \]
					\item For any arbitrary $a, b \in \mathscr{M}$, $\mu_{ab} = \mu_{ba}$. 
					\item The Brown measure for a Haar unitary operator is the Haar measure on the unit circle.  
					\item The Brown measure of $a$ is determined by its $\ast$-distribution, but it is not continuous with respect to convergence of $\ast$-moments (see, for instance, \cite{MR3585560} Section 11). 
				\end{itemize}
				
				
				
				
				
				\subsection{$R$-diagonal operators}\label{sec:Rdiag}
In general, the Brown measure is difficult to compute, but there is a class of elements, which we now introduce, for which the Brown measure can be computed.
				Let $a$ be an element of $\mathscr{M}$, and let $u$ be a Haar unitary in $\mathscr{M}$ such that $u$ and $a$ are free.  Then $a$ is said to be \textbf{$R$-diagonal} if $a$ has the same $\ast$-distribution as $ua$. See Section 5 of \cite{MR2266879} for further details about $R$-diagonal operators.

				Alternatively, an element $a$ is $R$-diagonal if all cumulants except the even cumulants which alternate between $a$ and $a^*$ vanish. We will call such cumulants the \textbf{diagonal terms} of the $R$-transform. In the tracial setting, the vanishing of the non-diagonal cumulants implies that the $R$-transform of $(a,a^*)$ is of the form \[R_{a,a^*}(z_1,z_2) = \sum_{n=1}^\infty \alpha_n (z_1 z_2)^n + \alpha_n(z_2 z_1)^n,\]  where \[\alpha_n := \kappa_{2n}(a,a^*,\ldots,a,a^*)=\kappa_{2n}(a^*,a,\ldots,a^*,a); \] 
				see \cite{MR2266879}, Example 16.9.
				
				
				\begin{remark}
					Classes of bi-unitarily invariant random matrices converge in $\ast$-distribution to $R$-diagonal elements. Although convergence in $\ast$-distribution is not strong enough to guarantee convergence of the empirical spectral measure, it was shown in \cite{MR2831116} that the empirical spectral measure does converge to the Brown measure of an $R$-diagonal operator. 
									\end{remark}

				The following theorem, from \cite{MR1784419}, see also \cite{2204.01896}, shows that the Brown measure of $R$-diagonal elements can be explicitly computed.  
				
				\begin{theorem}[Haagerup--Larsen, Zhong]
					\label{thm:BM}
					Let $a$ be an $R$-diagonal element, and define 
					\begin{equation} \label{eq:lambda12}
						\lambda_1 := \left(\int_0^{\infty} x^{-2}d\mu_{|a|}(x)\right)^{-1/2}, ~~~  \lambda_2 := \left(\int_0^{\infty} x^2 d\mu_{|a|}(x)\right)^{1/2} ,
					\end{equation}
					with the convention that $\lambda_1 = 0$ if $\int_0^{\infty} x^{-2}d\mu_{|a|}(x) = \infty$.  
					Then the Brown measure of $a$ is radially symmetric and its radial cumulative distribution function (CDF) is given by 
					\begin{equation} \label{eq:Brownmeasure} F_a ( r ): =  \mu_a(\D_r) = \begin{cases} 0 &\text{ if } r \in [0,\lambda_1] \\
							1+\mathscr{S}_{a^*a}^{\langle -1 \rangle}(r^{-2})  &\text{ if } r \in (\lambda_1,\lambda_2)  \\
							1 &\text{ if } r \geq \lambda_2 \end{cases}. \end{equation} 
				\end{theorem}
				
				\begin{remark}
					Note that the Brown measure is always supported on a (possibly degenerate) ring, centered at the origin. Furthermore, by Remark \ref{rem:Stran}, $\mu_a$ has density when $a$ is not a Haar unitary and $0$ is in its support if $\mathscr{S}_{a^*a}(z)$ is singular, and singularity occurring at $z = \mu_a(\{0\})-1$.   				\end{remark}
				
				\begin{remark} \label{rem:aff2}
					If $a$ is unbounded, it is said to be R-diagonal if there exists a von Neumann algebra
					$\mathscr{N}$, with a faithful, normal, tracial state, and $\ast$-free elements $u$ and $h$ affiliated with $\mathscr{N}$, such that $u$ is Haar unitary, $h$ is positive, and $a$ has the same $\ast$-distribution as $u h$. Once again we refer the reader to \cite{MR2339369}, Section 3. The Brown measure of an unbounded operator might not be compacted supported, but formula \eqref{eq:Brownmeasure} still holds.
				\end{remark}
				
	Products and sums of freely independent $R$-diagonal elements are also $R$-diagonal \cite{MR1784419}, making the Brown measure of sums of freely independent $R$-diagonal elements a natural object to consider. 				
				From \eqref{eq:Brownmeasure}, we see there is a bijection between the set of Brown measures of $R$-diagonal operators and measures on $\R^+$ such that 
				\[ \int \log^{+}|t| d \nu_{a} < \infty, \]
	given by the correspondence: $\mu_a \leftrightarrow \nu_{a}:=\mu_{a a^*}$.
				Furthermore, there is a bijection between symmetric probability measures on $\R$ and measures on $\R^+$, given by the mapping $x \to  x^2$. 
We denote by $\tilde \nu_a$, the inverse image of $\nu_a$ by this map. By composing these two bijections we get a bijection, $\mathcal{H}$, between a class of symmetric probability measures on $\R$ and Brown measures of $R$-diagonal operators. In \cite{MR3896715}, building on the work of \cite{MR1784419}, K\"{o}sters and Tikhomirov show that if $a$ and $b$ are $\ast$-freely independent $R$-diagonal elements, then the Brown measure of $a + b$ is given by\begin{equation}\label{eq:oplus definition}
					\mu_{a+b} = \mu_{a} \rdplus \mu_{b} := \mathcal{H}( \mathcal{H}^{-1}(\mu_a) \boxplus  \mathcal{H}^{-1}(\mu_b) ),
				\end{equation} where $\boxplus$ is the additive free convolution discussed at the beginning of Section \ref{sec:intro}. Note that $\mathcal{H}( \tilde \nu_a \boxplus  \tilde \nu_b) = \mathcal{H}( \tilde \nu_a ) \rdplus \mathcal{H}(  \tilde \nu_b)$. 
				The convolution $\rdplus$ is used in \cite{MR3896715} to compute the limiting spectrum of a certain class of polynomials of random matrices with iid entries. The authors also characterize the Brown measures that are stable under the $\rdplus$ operation, see Proposition \ref{prop:stablelaw}, below
				
				The Brown measure of an $R$-diagonal element is called \textbf{$\alpha$-$\rdplus$ stable} if for any $m\in\N$
				\[ \mu^{\rdplus m} = \mathcal{D}_{m^{1/\alpha}}\mu, \]
				where, for $c \in (0, \infty)$, $\mathcal{D}_c$ is the scaling operator which maps a probability measure to the measure induced by the mapping $x \to cx$. We also note that in \cite{MR4396250, MR4345335, MR4386403}, a related convolution, denoted $\boxplus_{RD}$, which acts on measures on $\R^+$, was studied.
				
				
				\begin{proposition}[K{\"o}sters--Tikhomirov]\label{prop:stablelaw}
					The Brown measure of $a$ is $\alpha$-$\rdplus$ stable if and only if 
					
					\begin{equation} \label{eq:stableS}  \mathscr{S}_{a a^*}(z) = \theta \frac{ (-z)^{\frac{2}{\alpha} -1}}{1+z}\end{equation}
					for some $\theta>0$.
				\end{proposition}
				 Here, and throughout this paper, we use the principle branch of the complex function $z^c$. We discuss this proposition further and give an alternative proof in Section \ref{sec:stable}.		
				
				
				

					
			
			\section{Random polynomial theory background}\label{sec:rand-poly}
			
			In this section, we review some results concerning zeros of random polynomials and their derivatives.  We focus on works which are closely related with the results in this paper.  
			
			Let $p_n$ be a (random) polynomial with complex coefficients of degree $n$ in a single complex variables.  A natural question is to describe the distribution of the roots of $p_n^{(k)}$, the $k$-th derivative of $p_n$, in terms of the distribution of roots of $p_n$.  In general, the roots of $p_n$ and $p_n^{(k)}$ are related by the Gauss--Lucas theorem, which guarantees the zeros of $p_n^{(k)}$ lie in the convex hull of the roots of $p_n$.  However, the example $p_n(z) = z^n - 1$ shows that the roots of $p_n$ and $p_n^{(k)}$ need not have similar distributions, even when $k = 1$.  
			However, for many models of random polynomials, the roots of $p_n$ and $p_n^{(k)}$ are similar when $n$ tends to infinity and $k$ is fixed (or grows slowly with $n$) \cite{MR3567254,MR3283656,MR3318313,MR3698743,MR2970701,MR4136480,MR3896083,MR4474893,MR3363974,2212.11867,MR3340325,MR3342181,MR3689975}.  
			In this section, we describe some known results for the case when $k$ is proportional to the degree $n$.  
			

			\subsection{Random polynomials with independent coefficients}
			
	
			Theorem \ref{thm:AGP} deals with polynomials with independent roots.  A different and more widely-studied model involves polynomials with independent coefficients.  Let 
			\begin{equation} \label{eq:pngen}
				p_n(z) := \sum_{k=0}^n \xi_k p_{k,n} z^k 
			\end{equation} 
			be a random polynomial with general coefficients, where $p_{k,n}$ are deterministic coefficients and $\xi_k$ are non-degenerate iid complex-valued random variables.  It will be convenient to assume that
			\begin{equation} \label{eq:xik}
				\Prob(\xi_0 = 0) = 0 \qquad \text{and} \qquad \E \log(1 + |\xi_0|) < \infty. 
			\end{equation} 
			The coefficients $p_{k,n}$ are assumed to satisfy the following assumption.
			\begin{assumption} \label{assump:a1}
				There exists a function $p:[0, \infty) \to [0, \infty)$ so that 
				\begin{enumerate}
					\item\label{assump:a1 p is non neg} $p(t) > 0$ for $t \in [0, 1)$ and $p(t) = 0$ for $t > 1$;
					\item\label{assump:a1 p is continuous} $p$ is continuous on $[0, 1)$ and left continuous at $1$;  and
					\item\label{assump:a1 coefficients converge to p} $\lim_{n \to \infty} \sup_{0 \leq k \leq n} \left| |p_{k,n}|^{1/n} - p( \frac{k}{n}) \right| = 0$. 
				\end{enumerate}
			\end{assumption}
			
			Let $p_n$ be the random polynomial from \eqref{eq:pngen}.  Heuristically, Assumption \ref{assump:a1} implies that the coefficients $p_{k,n}$ are roughly $e^{n \log p(k/n)}$ for some continuous function $p$.  In order to study the roots, we define the random measure 
			\[ \mu_n :=\frac{1}{n} \sum_{z \in \mathbb{C} : p_n(z) = 0} \delta_{z}, \]
			where $\delta_z$ is a Dirac point mass at $z$ and we agree the roots are counted with multiplicities.  
			Recall that for any $r > 0$, $\mathbb{D}_r = \{z \in \mathbb{C} : |z| < r\}$ is the open disk of radius $r$ centered at the origin.  
			In \cite{MR3262481}, Kabluchko and Zaporozhets establish several results describing the asymptotic behavior of the zeros of random analytic functions.  In the special case when the random analytic function is $p_n$, their results reduce to the following.  
			\begin{theorem}[Kabluchko--Zaporozhets  \cite{MR3262481}]
				Let $p_n$ be the random polynomial given in \eqref{eq:pngen}, where $p_{k,n}$ are deterministic coefficients satisfying Assumption \ref{assump:a1} for some function $p(t)$ and $\xi_0, \xi_1, \ldots$ are iid non-degenerate complex-valued random variables which satisfy $\E \log(1 + |\xi_0|) < \infty$.  Let $I: \mathbb{R} \to \mathbb{R} \cup \{+\infty\}$ be the Legendre-Fenchel transform of $u(t) = -\log p(t)$, where we use the convention that $\log 0 = - \infty$.  That is, 
				\[ I(s) := \sup_{t \geq 0} (st - u(t)) = \sup_{t \geq 0} (st + \log p(t)). \]
				Then $ \mu_n$ converges in probability to some deterministic measure $\mu$.  The measure $\mu$ is rotationally invariant and is characterized by 
				\[ \mu(\mathbb{D}_r) := I'(\log r), \qquad r > 0. \]
			\end{theorem}
			Here, as a convention, $I'$ is the left derivative of $I$.  Since $I$ is convex, the left derivative exists everywhere.  
			
			In \cite{MR3262481}, Kabluchko and Zaporozhets also characterize a set of rotationally invariant measures on $\mathbb{C}$ that arise when one studies the asymptotic behavior of zeros of random analytic functions.  We will need a related class of rotationally invariant probability measures on $\mathbb{C}$.  To this end, we denote by $\mathcal{RP}(\C)$ the set of rotationally invariant probability measures on $\C$ and define the set 
			\[ \mathcal{RP}_p(\C):=\left\{\mu \in \mathcal{RP}(\C)\ :\ \int_{0}^1 \mu\left(\D_r \right)r^{-1}\d r <\infty \right\}. \] 
			We note that the upper bound of $1$ in the integral is not particularly important, and could be replaced by any positive constant for an equivalent definition. 
			\begin{remark}
			Every measure $\mu\in\mathcal{RP}_p(\C)$ can arise as the limiting empirical root measure of a random polynomial with independent coefficients. This follows from the arguments given by Kabluchko and Zaporozhets in \cite{MR3262481}, Theorem 2.9.  Although Theorem 2.9 from \cite{MR3262481} is stated for random analytic functions, the proof can be specialized to random polynomials when $\mu$ is a probability measure; we now outline the argument. 
			Let $\mu\in\mathcal{RP}_p(\C)$, and define $I(s)=\int_{-\infty}^s\mu(\D_{e^r})dr$. Additionally define the  Legendre--Fenchel transform of $I$:\begin{equation*}
				u(t):=\sup_{s\in\R}(st-I(s)).
			\end{equation*}  Then the random polynomials $p_n(z) = \sum_{k=0}^n \xi_k p_{k,n} z^k$ with $p_{k,n}=e^{-nu(k/n)}$ satisfy Assumption \ref{assump:a1} with $p=e^{-u}$. This follows exactly as in \cite{MR3262481} with the observation that for any finite measure $\mu$ such that $I(s)<\infty$ for all $s\in\R$  one has \begin{equation*}
				\limsup_{t\rightarrow\infty}\frac{I(t)}{t}=\mu(\C),
			\end{equation*} and hence for a probability measure, $\mu$, $u(t)=+\infty$ for $t>1$. Thus, $p(t)=0$ for any $t>1$. 
			\end{remark}
			
			Let $p_n$ be the random polynomial from \eqref{eq:pngen}.  We are interested in the $N_n$-th derivative $p_n^{(N_n)}$ of $p_n$, which will be of degree $D_n := n - N_n$. In order to study its zeros, we slightly abuse notation and define the random measure 
			\[ \mu_{D_n} := \frac{1}{D_n}\sum_{z \in \mathbb{C} : p_n^{(N_n)}(z) = 0} \delta_{z}, \]
			where $\delta_z$ is a Dirac point mass at $z$, and we again agree the roots are counted with multiplicities.  

			
			Building on the work of Kabluchko and Zaporozhets \cite{MR3262481}, Feng and Yao \cite{MR3921311} establish the following result for the zeros of $p_n^{(N_n)}$.
			\begin{theorem}[Feng--Yao \cite{MR3921311}] \label{thm:feng-yao}
				Let $p_n$ be the random polynomial given in \eqref{eq:pngen}, where $p_{k,n}$ are deterministic coefficients satisfying Assumption \ref{assump:a1} for some function $p(t)$ and $\xi_0, \xi_1, \ldots$ are iid non-degenerate complex-valued random variables which satisfy \eqref{eq:xik}.  
				\begin{enumerate}
					\item\label{thm:part 1:feng-yao} If $\lim_{n \to \infty} N_n/n = 0$, let $I: \mathbb{R} \to \mathbb{R} \cup \{+\infty\}$ be the Legendre-Fenchel transform of $u(t) = -\log p(t)$, then $ \mu_{D_n}$ converges in probability to a rotationally invariant measure $\mu$ in the complex plane given by 
					\[ \mu(\mathbb{D}_r) := I'(\log r), \qquad r > 0. \]
					In particular, $\frac{1}{D_n} \mu_{D_n}$ has the same limit as $\frac{1}{n} \mu_{n}$. 
					\item\label{thm:part 2:feng-yao} If $\lim_{n \to \infty} N_n/n = a \in (0, 1)$, let $ u_a(t) = -\log p(t+a) - (t+a) \log (t+a) + t \log t - (1-a)\log(1-a)$ if $0 \leq t \leq 1-a$ and $-\infty$ if $t > 1 - a$.  Let $I_a: \mathbb{R} \to \mathbb{R} \cup \{+\infty\}$ be the Legendre-Fenchel transform of $ u_a$, then $ \mu_{D_n}$ converges in probability to a rotationally invariant measure $\mu_a$ in the complex plane given by
					\[ \mu_a(\mathbb{D}_r) := \frac{1}{1-a} I'_a(\log r), \qquad r > 0. \]
				\end{enumerate}
			\end{theorem}
			
			Here, as a convention, $I'$ and $I_a'$ are the left derivatives of $I$ and $I_a$, respectively.  
			
			In \cite{MR3921311}, Feng and Yao also consider certain special cases, such as the Kac and elliptic models, where they compute the limiting behavior of the zeros when $\lim_{n \to \infty} N_n / n = 1$.  We will discuss these cases and some generalizations in Section \ref{sec:repderiv}.  
			
			
			\subsection{PDEs describing the behavior of roots under repeated differentiation}
			
			Another approach to studying the distribution of zeros of $p_n$ (or its large $n$ limit) and its $\lceil tn \rceil$-th derivative for some $0 < t < 1$ is to relate them by a partial differential equation (PDE); in this case, we will often think of $t$ as time, with $t = 0$ corresponding to the empirical distribution of roots of $p_n$ (or its large $n$ limit).  

			Suppose $p_n$ is a polynomial of degree $n$ having all its roots on the real line with density $u(0, x)$.  In \cite{MR4011508}, Steinerberger introduced the following PDE for the density $u(t,x)$ of the zeros of $p_n^{(\lceil tn \rceil)}$:
			\begin{equation} \label{eq:PDEst} u_t + \frac{1}{\pi} \left( \arctan \left( \frac{ Hu}{u} \right) \right)_x = 0, \end{equation}
			where the equation holds on the support $\supp u$ and $Hu$ is the Hilbert transform of $u$.  
			
			A similar result has been introduced when the roots of $p_n$ are rotationally invariant in the complex plane.  Indeed, given the initial radial density $\psi(x,0)$ of the zeros at $t = 0$, the PDE from \cite{MR4242313} describes the radial density $\psi(x, t)$ at time $0 \leq t < 1$.  The equation is
			\begin{equation} \label{eq:OS}
				\frac{ \partial \psi(x,t) }{\partial t} = \frac{ \partial}{\partial x} \left( \frac{ \psi(x,t) }{ \frac{1}{x} \int_0^x \psi(y,t) dy } \right) \qquad x \geq 0, \quad 0 \leq t < 1. 
			\end{equation}
			Here, we use the convention that $x \geq 0$ either denotes $x \in [0, C]$ (for some finite positive constant $C$) or $x \in [0, \infty)$, depending on whether the density is compactly supported or not. In the former case, by rescaling, we will often assume without loss of generality that $C = 1$.  
			
			In \cite{doi:10.1080/10586458.2021.1980752}, Hoskins and Kabluchko relate the distribution function 
			\[ \Psi_t(x) = \Psi(x,t) = \int_0^x \psi(y, t) dy \]
			at time $t$ to the initial distribution 
			\[  \Psi_0(x) = \Psi(x, 0) = \int_0^x \psi(y, 0) dy. \]

			They show that $\Psi_t(x)$ satisfies the equation 
			\begin{equation} \label{eq:derivativeflow} \frac{ \Psi_t^{\langle -1 \rangle}(x)}{x}  =  \frac{ \Psi_0^{\langle -1 \rangle}(x+t)}{x+t} \end{equation}
			for $0 < x < 1-t$ and $0 \leq t < 1 $.
			
			In \cite{MR4488834}, Galligo derives a system of two coupled equations to model the motion of real and complex roots for real polynomials under repeated differentiation.  
			
			We explore \eqref{eq:OS} and some related PDEs more in Section \ref{sec:PDE}.  
			

			
			
			\subsection{Quantile functions under differentiation} The functions $\Psi_t$ considered in \eqref{eq:derivativeflow} are radial cumulative distribution functions of sub-probability measures, however a simple normalization results in a similar identity for radial CDFs of probability measures. The function $\Psi_t$ also need not have a true inverse for \eqref{eq:derivativeflow} to provide meaningful information on polynomial roots under differentiation. Instead, \eqref{eq:derivativeflow} can be interpreted as an identity on the generalized left-continuous inverse of the CDF, or \textbf{quantile function} of the distribution. In this section we will present some basic results on quantile functions which will be used in the proofs of our main results in Sections \ref{sec:Frac conv for R} and \ref{sec:repderiv}. 
			
			\begin{definition}
				Let $F$ be the CDF of a real valued random variable. The quantile function $Q:[0,1)\rightarrow\R$ of $F$ is the function defined by \begin{equation}\label{eq:Quantile def}
					Q(p):=\inf\{x\in \R: F(x)\geq p\}. 
				\end{equation} 
			\end{definition}
		
			The following lemma contains some essential results on quantile functions. 
			
			\begin{lemma}\label{lemma:quantile facts}
				Let $F$ be a CDF with quantile function $Q$. \begin{enumerate}
					\item\label{eq:inequality iff} For every $x\in\R$ and $p\in[0,1)$, $F(x)\geq p$ if and only if $Q(p)\leq x$.
					
					\item $Q$ is left-continuous and non-decreasing.
					
					\item If $F$ is invertible, then $Q=F^{-1}$.
				\end{enumerate} Moreover, the quantile function uniquely determines $F$ and any left-continuous non-decreasing function on $[0,1)$ is the quantile function of a unique distribution.
			\end{lemma}
		
		\begin{proof}
			See \cite{vaart_1998} Lemma 21.1 for a proof of the first three statements. For the final statements, let $Q$ be a left-continuous non-decreasing function on $[0,1)$. Define the function $F:\R\rightarrow[0,1]$ by \begin{equation}\label{eq:quantile to cdf def}
				F(x)=\max\left(\sup\{p\in[0,1): Q(p)\leq x\},0\right),
			\end{equation} with the convention that $\sup\emptyset=-\infty$. It is straightforward to check $F$ is non-decreasing, \begin{equation*}
			\lim_{x\rightarrow-\infty} F(x)=0,\quad\text{and}\quad \lim\limits_{x\rightarrow\infty}F(x)=1.
		\end{equation*} Fix $x\in\R$, and assume for the sake of contradiction that $F$ is not right-continuous at $x$. Then there exists $\delta>0$ such that for any $\eps>0$,  $F(x+\eps)-F(x)>\delta$. Let $\eps>0$, then \begin{equation}\label{eq:F eps inequality}
		F(x+\eps)> F(x)+\delta.
	\end{equation} From \eqref{eq:quantile to cdf def}, \eqref{eq:F eps inequality} and the monotonicity of $Q$ we have that\begin{equation}
		Q(F(x)+\delta)\leq x+\eps.
\end{equation} As $\eps>0$ was arbitrary, we have that \begin{equation*}
Q(F(x)+\delta)\leq x,
\end{equation*} a contradiction of \eqref{eq:quantile to cdf def}. Thus, $F$ defined by \eqref{eq:quantile to cdf def} is right-continuous on $\R$. 
	
		Let $F_1$ and $F_2$ both be the CDF of distinct distributions both with quantile function $Q$. Let $x\in\R$ be such that $F_1(x)>F_2(x)$. Let $p\in(F_2(x),F_1(x))$, then from Lemma \ref{lemma:quantile facts} \eqref{eq:inequality iff} \begin{equation*}
			F_1(x)\geq p\, \Leftrightarrow Q(p)\leq x\, \Leftrightarrow F_2(x)\geq p,
		\end{equation*} a contradiction. Hence, $F$ defined by \eqref{eq:quantile to cdf def} is unique.
		\end{proof}
		
			The following lemma describes convergence in distribution in terms of quantile functions. 
			
			\begin{lemma}[See van der Vaart \cite{vaart_1998} Lemma 21.2]\label{lemma:quntile convergence}
				Let $X_1,X_2,\dots,$ and $X_\infty$ be real valued random variables with quantile functions $Q_1, Q_2, \dots,$ and $Q_\infty$ respectively. Then $X_n$ converges in distribution to $X_\infty$ if and only if $Q_n(p)$ converges to $Q_\infty(p)$ for every continuity point $p\in[0,1)$ of $Q_\infty$. 
			\end{lemma}
			
			
			
			\subsection{Connections to free probability theory}
			

			
	The PDE in \eqref{eq:PDEst} also appeared in \cite{2009.01882} to describe the fractional free convolution. In the case of a polynomial with real roots, Steinerberger \cite{2009.03869} proposed an interpretation of the density of zeros of repeated derivatives in terms of free probability theory.  This interpretation has been further explored in \cite{doi:10.1080/10586458.2021.1980752,2108.08489}, culminating in generalized versions of Theorem \ref{thm:AGP}.  In particular, the work \cite{2108.08489} establishes a connection between the real case and finite free probability theory, a subject developed in \cite{MR4408504, 2108.07054}.  
			
			In a similar spirit, Kabluchko \cite{2112.14729} showed that the zeros of real-rooted trigonometric polynomials under repeated differentiation in the asymptotic limit can be described in terms of a free multiplicative convolution involving the free unitary Poisson distribution.  
			
			In this paper, we further explore connections between zeros of random polynomials and free probability theory in the case when the polynomials have roots in the complex plane.  
						
			
			\section{The fractional free convolution for $R$-diagonal operators}\label{sec:Frac conv for R}

			
			In this section we use the relationship given in \cite{MR1400060} between the distribution of $a$ and $\pi(a)$ to extend the $\rdplus$ operation to fractional powers. We then give an alternative expression for the Brown measure of the sum of $k$ identically distributed, freely independent $R$-diagonal elements. Our expression is more direct, as it does not require using the bijection $\mathcal{H}$ and computing the free convolution powers of symmetric probability measures.   

			\subsection{Fractional free convolution powers of the Brown measure} \label{sec:fracBrown}
			
			\begin{definition}[$R$-diagonal fractional free convolution] \label{def:fracconv}
				Let $a$ be an R-diagonal element with Brown measure $\mu_a$.  For $k\geq 1$ a real number, we define $\mu_a^{\rdplus k}$ to be the radially symmetric probability measure with radial CDF given by 
				\begin{equation} \label{eq:kBrownmeasure} \mu_a^{\rdplus k}( \D_r) := \begin{cases} 
							1 + \mathscr{S}^{\langle -1 \rangle}_k(r^{-2}) &\text{ if } r \in (0,\lambda_2^{(k)})  \\
							1 &\text{ if } r \geq \lambda_2^{(k)} \end{cases} \end{equation} 
				for $r>0$, where 
				\begin{equation} \label{eq:Slambda}
					\mathscr{S}_k(z):= \frac{1+ z/k}{k (1+z) } \mathscr{S}_{a a^*}(z/k),   
				\end{equation}
				$\lambda_2^{(k)}: = \sqrt{k} \lambda_2$, and $\lambda_2$ is given by \eqref{eq:lambda12}, applied to the measure $\mu_{|a|}$.  
			\end{definition}
			
		
	The following proposition gives elementary properties of the probability measure $\mu_a^{\rdplus k}$. Then we will give a proposition that shows the fractional free convolution agrees with the previous definition of $\rdplus$ for integer values of $k$.
			
\begin{proposition}\label{prop:oplus prop}
Let $k>1$ be a real number, and let $\mu_a$ be the Brown measure of an $R$-diagonal element $a$. Let $R \in [0,\infty]$ be the radius of the disk that $\mu_a$ is supported on.  Then
\begin{enumerate} 
					\item \label{item:oplus1} $\mu_a^{\rdplus k}(\{0\})  = \max\{0,1-k(1-\mu_a(\{0\}))\} $; 
					\item \label{item:oplus2} on $\C \setminus \{0\}$, $\mu_a^{\rdplus k} $ has density, which is supported and positive on the closed disk of radius $\sqrt{k}R$, centered at the origin. 
					%\item  
				\end{enumerate}
			\end{proposition}
			
						
			
			\begin{proposition} \label{prop:brownmeasuresum} 
				Let $k \geq 1$ be an integer and $a_1, \ldots, a_k$ be freely independent copies of an $R$-diagonal element $a$.  Then the Brown measure of $a_1 + \cdots + a_k$ is $\mu_a^{\rdplus k}$ (as defined in Definition \ref{def:fracconv}).
				Furthermore, $\mu_a^{\rdplus j}$ forms a convolution semigroup:
				\begin{equation} \label{eq:semigroup}
					\left(\mu_a^{\rdplus j}\right)^{\rdplus l} = \mu_a^{\rdplus j l} 
				\end{equation} 
				for all real $j,l \geq 1$.

			\end{proposition}

			
			\begin{proof}[Proof of Proposition \ref{prop:oplus prop}]
				Let $\nu$ be the spectral measure of $a a^*$ and $\mathscr{S}_k$ be as in \eqref{eq:Slambda}. We begin by recalling that $\mathscr{S}_{\nu}(z)$ is a decreasing function on $(-1+\nu(\{0\}),0)$ with range $(\lambda_2^{-2},\lambda_1^{-2})$.
				
				To prove \eqref{item:oplus1}, we first note that if $\mu_a(\{0\})=0$ then $\mathscr{S}_\nu$ and hence $\mathscr{S}_k$ is finite on $(-1,0)$ and thus $\mu^{\rdplus k}(\{0\})  = 0$. If $\mu_a({0})\not = 0$ then $\mathscr{S}_{\nu}$ is singular at $-1+\mu_a(\{0\})$, and thus by \eqref{eq:Slambda}, $\mathscr{S}_k$ is singular at $k(-1+\mu_a(\{0\}))$, as desired. 
				
				
				To prove \eqref{item:oplus2}, we use that the prefactor, $\frac{1 + z/k}{k(1+z)}$, and hence the entire term in \eqref{eq:Slambda} is strictly monotonic.  Thus, when combined with \eqref{eq:Brownmeasure}, we find that $\mu_a^{\rdplus k}$ has positive density (by Corollary 4.5 of \cite{MR1784419} the density of the Brown measure is positive on its support). Then showing that the inner radius of $\mu_a^{\rdplus k}$ is $0$ is equivalent to showing that the $S$-transform is singular at $-1~+~\mu_a^{\rdplus k}(\{0\})$. If $\mu_a^{\rdplus k}(\{0\})> 0$, from \eqref{item:oplus1} we see that this happens. On the other hand if $\mu_a^{\rdplus k}(\{0\})~=~0$, then from \eqref{eq:Slambda} we have that for all $k>1$, the prefactor is singular at $-1$. To compute the outer radius, we note that $\mathscr{S}_k(0) = \frac{1}{k} \mathscr{S}_{aa^*}(0) = \frac{1}{k R^2}$, so we conclude that $\mu_a^{\rdplus k}$ is supported on the disk of radius $\sqrt{k} R$, as desired.
			\end{proof}

			
			
			Before we prove Proposition \ref{prop:brownmeasuresum}, we will show that the $\ast$-distributions of $k \pi_{k^{-1}}(a)$ and $a_1 + \cdots + a_k$ are the same, and hence both elements have the same Brown measure. The proposition will then follow by computing the Brown measure of $\pi(a)$.
			
			\begin{lemma}Let $a, a_1, \ldots, a_k$  be as in Proposition \ref{prop:brownmeasuresum}. The $\ast$-distributions of $k \pi_{k^{-1}}(a)$ and $a_1 + \cdots + a_k$ are equal. Furthermore, they are both $R$-diagonal elements.
			\end{lemma}
			
			\begin{proof}
				
				We begin by relating the free cumulants of $(\pi_\lambda(a), \pi_\lambda(a)^*)$ to those of $(a,a^*)$. We then specialize to $\lambda = 1/k$. We will now omit the subscript $\lambda$ from $\pi_{\lambda}$.

				By Theorem 14.10 of \cite{MR2266879} the free cumulants of $(\pi(a), \pi( a)^*) $ are a rescaling of the free cumulants $(a,a^*)$ by $\lambda^{-1}$:
				\begin{equation}\label{eq:projfreecumulant} \kappa_n^{\mathscr{M}_p}( \pi( a^{\eps_1}),\ldots ,\pi(a^{\eps_n}) ) = \lambda^{-1} \kappa_n(\lambda a^{\eps_1},\ldots,\lambda a^{\eps_n}) \end{equation}
				with $\eps_i \in \{1,* \}$. Here we have introduced the superscript $\mathscr{M}_p$ to make it clear that all relevant quantities are computed with respect to $\tau_p$.
				In particular, because $a$ is $R$-diagonal, the non-diagonal cumulants vanish, meaning $\pi(\lambda^{-1} a)$ is also $R$-diagonal, and its diagonal cumulants are:
				\[ \kappa_n^{\mathscr{M}_p}(\pi(\lambda^{-1} a^{}), \pi(\lambda^{-1} a^{*})\ldots ,\pi  (\lambda^{-1}a^{}), \pi(\lambda^{-1}a^{*})) =  \lambda^{-1} \kappa_{n}(a, a^*,\ldots, a, a^*). \]
				On the other hand, if $a_1, \ldots, a_k$ are $\ast$-freely independent, non-commutative random variables with the same $\ast$-distribution as $a$, then $x^{(k)} := a_1 +  \cdots + a_k$ is also $R$-diagonal with
				\[ \kappa_n(x^{(k)}, x^{(k)*}, \ldots, x^{(k)}, x^{(k)*}) = \sum_{i=1}^k \kappa_n(a_i,a_i^*,\ldots, a_i, a_i^*) = k \, \kappa_n(a,a^*,\ldots, a, a^*) , \]
				where we have used that, by freeness, the mixed cumulants vanish.
				
				Setting $\lambda = k^{-1}$, we see that $x^{(k)}$ and $k \pi(a)$ have the same $\ast$-distribution, as desired.		
			\end{proof}
			
		
			
			To compute the Brown measure of $a_1+\cdots+a_k$ in Proposition \ref{prop:brownmeasuresum}, it now suffices to compute the $S$-transform of $ \pi_{1/k}(a) \pi_{1/k}(a)^*$; we will use the following lemma to compute this $S$-transform. We remark that similar computations were done in \cite{MR4085372} to study the Brown measure of products of truncations of $\ast$-freely independent Haar unitary elements.
		
		\begin{lemma} \label{lem:Spi} Let $p \in \mathscr{M}$ be a projection with $\tau(p) = \lambda \in (0,1]$, $a \in \mathscr{M}$, and $ x \in \mathscr{M}$ be self-adjoint, such that $p$ is free from $a$ and $x$. Then we have for $z$ in a neighborhood of the origin that:
			\begin{enumerate}
				\item $\mathscr{S}_p(z) = \frac{1+ z}{\lambda + z} $ \label{Spi1}
				\item $\mathscr{S}_{p a p a^*p}(z) = \left( \frac{1+ z}{\lambda + z} \right)^2 \mathscr{S}_{ a  a^*}(z)  $ \label{Spi2}
				\item $\mathscr{S}_{\pi(x)}(z) =  \frac{\lambda(z+1)}{\lambda z+1} \mathscr{S}_{pxp}(\lambda z)$ \label{Spi3}
			\end{enumerate}
		\end{lemma}
		\begin{proof}
			To prove \eqref{Spi1}, we begin by computing the moment generating function for $p$:
			\[ M_p(z) = \sum_{k=1}^\infty \tau(p^k) z^k = \sum_{k=1}^\infty \lambda z^k = \frac{ \lambda z}{ 1 - z}. \]  
			We then compute its inverse and get its $S$-transform:
			\[ M^{\langle -1 \rangle}(z) = \frac{z}{\lambda+z} \text{ and thus } \mathscr{S}_p(z) = \frac{1+z}{z} M^{\langle -1 \rangle}(z)  = \frac{ 1+z}{\lambda+z}.\]
			
			
			To prove  \eqref{Spi2}, we use that $\tau$ is tracial so the $S$-transform of $p apa^* p$ equals the $S$-transform of  $p^2 apa^* $ and hence $papa^*$. Then, because $p$ and $a$ are free, the S-transform of $p a p a^*$ factorizes as 
			\[ \mathscr{S}_{p a p a^*p}(z) =  \mathscr{S}_{ p}(z)^2 \mathscr{S}_{ a  a^*}(z) .\]
			The desired result follows by applying \eqref{Spi1}.
			
			To prove  \eqref{Spi3}, we use that the moments of $\pi(x)$ equal the corresponding moments of $pxp$, rescaled by $ \lambda$, so:
			\[ \lambda M_{\pi(x)}(z) =  M_{pxp}(z). \]
			Then the $S$-transform is  
			\[ \mathscr{S}_{\pi(x)}(z) =   \frac{z+1}{z}  M^{\langle -1 \rangle}_{\pi(x)}(z) = \frac{z+1}{z}  M_{pxp}^{\langle -1 \rangle}(\lambda  z) = \frac{\lambda(z+1)}{\lambda z+1} \mathscr{S}_{pxp}(\lambda z) ,\]
			as desired.
		\end{proof}

	We now apply the above lemma to compute the $S$-transform of \\
	$\pi(a)\pi(a^*)= \pi(p a p a^*p) = \pi(a p a^*)$. 	
			
			
			\begin{proof}[Proof of Proposition \ref{prop:brownmeasuresum}]
			
			We begin by applying \eqref{Spi3} from Lemma \ref{lem:Spi} to $p a p a^*p$ and then 
			\eqref{Spi2} to the result:
				
				\[ \mathscr{S}_{\pi( p a p a^*p)}(z) = \frac{\lambda(z+1)}{\lambda z+1}  \mathscr{S}_{p a p a^* p}(\lambda z)  =\frac{\lambda(z+1)}{\lambda z+1}   \frac{ (1+\lambda z)^2}{(\lambda+\lambda z)^2} \mathscr{S}_{a a^*}(\lambda z) = \frac{ 1+\lambda z}{\lambda(1+ z)} \mathscr{S}_{a a^*}(\lambda z) . \]

				
				
				Then using that $\mathscr{S}_{\lambda^{-2} \pi(a) \pi(a)^*} =  \lambda^{2}\mathscr{S}_{ \pi(a) \pi(a)^*}  $ gives
				\begin{equation} \label{eq:Spiaa} \mathscr{S}_{\lambda^{-2}\pi( a)  \pi (a)^*}(z) = \frac{ \lambda (1+\lambda z)}{1+ z} \mathscr{S}_{a a^*}(\lambda z).  \end{equation}
			Setting $\lambda = 1/k$ shows that the Brown measure of  $k \pi( a) $ and hence $a_1 + \cdots + a_k$ is $\mu_a^{\rdplus k}$.
				
				
				
				We see that $\mu_a^{\rdplus j}$ forms a semigroup by using \eqref{eq:Slambda} to compute the $S$-transforms of each side of \eqref{eq:semigroup}:
				\[  \frac{1+ z/l}{l (1+z) } \frac{1+ (z/l)/j}{j (1+z/l) } \mathscr{S}_{a a^*}\left(\frac{z/l}{j}\right) = 
				\frac{1+ z/(lj)}{lj (1+z) } \mathscr{S}_{a a^*}\left(\frac{z}{lj}\right). \]
			\end{proof}
			
					
			\subsection{Connection between Brown measures and derivatives of random polynomials} \label{sec:connection}
			
			We now relate the fractional free convolution to the roots of the derivatives of random polynomials.
			
			Given that the measures in $\mathcal{RP}_p$ arise as the limiting root distribution for polynomials with random coefficients, it makes sense to define $\mathcal{RP}_p$ as the domain of the differentiation flow. Additionally, we let $\Phi_t(r) := \frac{1}{1-t}\Psi_t(r) $, be a rescaling of $\Psi_t$ in \eqref{eq:derivativeflow}, in order to keep the total mass constant. It is easy to see that $\Phi_t$ satisfies the following definition. Throughout we will use $\Phi^{\langle -1 \rangle}$ to denote the quantile function of a radial CDF $\Phi$. 
			
			
			\begin{definition}
				Let $\mu \in \mathcal{RP}_p$ with radial CDF $\Phi_{0}$. The \textbf{differentiation flow} starting from $\mu$ is the subset $\{\mu^{D_t}\}_{0\leq t <1}$ of $\mathcal{RP}_p$ such that $\mu^{D_t}$ is the probability measure with radial CDF $\Phi_t$, and quantile functions satisfying \begin{equation}\label{eq:A:CDF identity}
					\Phi_t^{\langle-1\rangle}(x)=\frac{x(1-t)\Phi_0^{\langle-1\rangle}((1-t)x+t)}{x(1-t)+t},
				\end{equation} for $x\in(0,1)$, where $\Phi_t^{\langle -1 \rangle}$ is the quantile function of $\Phi_t$ and the existence of such measures follows from Lemma \ref{lemma:quantile facts} and the fact that the functions defined by \eqref{eq:A:CDF identity} are left-continuous and non-decreasing.  
			\end{definition} 
		
			\begin{remark}\label{rmk:A:connecting diff flow to feng-yao thm}
				 Equation \eqref{eq:A:CDF identity} is a rescaled version of \eqref{eq:derivativeflow} to ensure the total mass of the associated measure is $1$. Hence, if $\mu$ is the measure arising in  part \eqref{thm:part 1:feng-yao} of Theorem \ref{thm:feng-yao}, then for any $a\in(0,1)$ $\mu^{D_a}=\mu_a$ in part \ref{thm:part 2:feng-yao} of Theorem \ref{thm:feng-yao}.
			\end{remark}
			
			We now connect the differentiation flow to the fractional free convolution of Brown measures, which can be seen in Figure \ref{fig:A:Diagram of relationship}.  For a rotationally invariant measure $\mu$ in the complex plane, recall that $\psi_2\mu(\mathbb{D}_r):=\mu(\mathbb{D}_{\sqrt{r}})$ for $r > 0$, where $\mathbb{D}_r:=\{z \in \mathbb{C}: |z|< r\}$, and $\psi_2^{-1} \mu (\mathbb{D}_r) = \mu(\mathbb{D}_{r^2})$ is the inverse map.   
			
					
			% Figure environment removed

			
			
			\begin{theorem}\label{thm:A:connection general case}
				Let \begin{equation*}
					p_n(z) = \sum_{k=0}^n \xi_k p_{k,n} z^k
				\end{equation*} be a random polynomial, with $p_{k,n}$ satisfying Assumption \ref{assump:a1} and $\xi_k$ being iid random variables satisfying  \eqref{eq:xik}, such that $\mu$ is the limiting empirical root distribution of $p_n$. Additionally, assume there exists an $R$-diagonal element $a$ affiliated to some non-commutative probability space $(\mathcal{M},\tau)$ with Brown measure $\psi_2^{-1}\mu$.	For any fixed $\lambda \in (0,1)$, let $\mu_\lambda$ be the limiting empirical root distribution of the $\lceil (1-\lambda)n \rceil$-th derivative of $p_n(\lambda^2x)$  as $n \to \infty$ (whose existence is guaranteed by Theorem \ref{thm:feng-yao}), then $\mu_\lambda=\psi_2(\psi_2^{-1}\mu)^{\oplus 1/\lambda}$.
			\end{theorem}
			
			\begin{proof}
				Let $a$ be an $R$-diagonal element with Brown measure $\psi_2^{-1}\mu$.
				We then let $F_a(r)$ be the radial CDF of the Brown measure of $a$. From \eqref{eq:Brownmeasure}, we have that $F_a(r) =   1 + \mathscr{S}_{a^* a}^{\langle -1 \rangle}(r^{-2})$, for $ r \in [\lambda_1, \lambda_2]$. Solving for $F_a^{\langle -1 \rangle}$ gives:
				\[ F_a^{\langle -1 \rangle}(x) = \frac{1}{ \sqrt{\mathscr{S}_{a^* a}(x-1)}},\]
				for $x \in (0,1)$. 
				
				Let $ F_\lambda $ be the radial CDF of the measure $(\psi_2^{-1}\mu)^{\oplus 1/\lambda}$, recalling the definition of $\mathscr{S}_k$ in \eqref{eq:Slambda} and setting $k = \lambda^{-1}$, we have from \eqref{eq:kBrownmeasure} that 
				\[ F_\lambda^{\langle -1 \rangle}(x) = \frac{1}{ \sqrt{\mathscr{S}_{\lambda^{-1}}(x-1)}},\]
				for $x \in (0,1)$. 

				
				
				Evaluating \eqref{eq:Slambda} at $z = x-1$ and $k =\lambda^{-1} $ gives:
				\[  \mathscr{S}_{\lambda^{-1}}(x-1) = \frac{\lambda}{x}(\lambda (x-1)+1) \mathscr{S}_{a^* a}(\lambda(x-1)). \]
				Which in terms of $F_\lambda^{\langle -1 \rangle}$ and $F_a^{\langle -1 \rangle}(x)$  is \begin{equation}\label{eq:F evolution}
					F_\lambda^{\langle -1 \rangle}(x)=\sqrt{\frac{x}{\lambda(1+\lambda(x-1))}} F_a^{\langle -1 \rangle}((x-1)\lambda+1).
				\end{equation} 
				We let $G_\lambda$ be the radial CDF of $\psi_2(\psi_2^{-1}\mu)^{\oplus 1/\lambda}$ and $G_a$ the radial CDF of $\mu$.  We see from \eqref{eq:F evolution} that \begin{equation}\label{eq:g evolution}
				G_\lambda^{\langle -1 \rangle}(x)=\frac{x}{\lambda(1+\lambda(x-1))}G_a^{\langle -1 \rangle}((x-1)\lambda+1).
			\end{equation} After comparing \eqref{eq:g evolution} to \eqref{eq:A:CDF identity} with $t = 1- \lambda$ and initial condition $\Phi_0 = G_a$ we see that \[ G_\lambda^{\langle -1 \rangle}(x)=\frac{1}{\lambda^2}\Phi_{1-\lambda}^{\langle -1 \rangle}(x)\] for all $x\in(0,1)$. As discussed in Remark \ref{rmk:A:connecting diff flow to feng-yao thm}, $\Phi_{1-\lambda}$ is the limiting radial CDF of the $\lceil (1-\lambda)n \rceil$-th derivative of $p_n(x)$. Hence, $G_\lambda$ is the limiting radial CDF of the $\lceil (1-\lambda)n \rceil$-th derivative of $p_n(\lambda^2x)$.
			\end{proof}
		

		
			We conclude this section by translating properties of the fractional free convolution of Brown measures to the differentiation flow.
			
			
			\begin{proposition}
				Let $\mu\in\mathcal{RP}_p(\C)$. Then \begin{enumerate}
					\item For any $t\in(0,1)$, $0$ is in the support of $\mu^{D_t}$.
					\item For any $t\in(0,1)$, $\mu^{D_t}$ has density on $\C$. In particular $\mu^{D_t}(\{z:|z|=r \})=0$ for any $r>0$. 
				\end{enumerate}
			\end{proposition}
			
			\begin{proof}
				This follows in a completely analogous way to the proof of Proposition \ref{prop:oplus prop} with \eqref{eq:A:CDF identity} replacing  \eqref{eq:Slambda}.			
			\end{proof}
			
			
		

			
			
			\section{Dynamics of limiting root measures under repeated differentiation}\label{sec:repderiv}

			In this section, we consider the dynamics on probability measures described by the differentiation flow in \eqref{eq:A:CDF identity}; see Remark \ref{rmk:A:connecting diff flow to feng-yao thm} for a description of the connection to differentiation of polynomials. Section \ref{sec:limit_roots} considers the $t\rightarrow1$ limit of the measures under the differentiation flow. Section \ref{sec:PDE} focuses on PDEs describing the dynamics of the limiting radial probability density functions and radial cumulative distribution functions. 
			
			
			
	
			
			
			\subsection{Limit theorem and stable distributions}
			\label{sec:limit_roots}
			In this section we consider the limiting behavior of polynomial roots as the proportion of derivatives to the degree approaches one. With Theorem \ref{thm:A:connection general case} connecting repeated differentiation of random polynomials to sums of free random variables, it is natural to consider distributions which are stable under the differentiation flow defined by \eqref{eq:A:CDF identity} and serve as central limits for the convolution. Some random polynomial examples giving rise to stable laws are discussed in Section \ref{sec:examples}.  For $\alpha \in (0,2]$, let $\mu_\alpha\in \mathcal{RP}_p(\C)$ be the measure with radial CDF $\Phi_{0,\alpha}$ such that $\Phi_{0,\alpha}^{\langle-1\rangle}(x)=\frac{x}{(1-x)^{\frac{2}{\alpha}-1}}$. It is then easy to check (recall \eqref{eq:A:CDF identity}) that \begin{equation*}
				\Phi_{t,\alpha}^{\langle -1\rangle}(x)=(1-t)^{2-\frac{2}{\alpha}}\Phi_{0,\alpha}^{\langle-1\rangle}(x),
			\end{equation*} for all $x,t\in(0,1)$. Hence, $\mu_\alpha^{D_t}$ is $\mu_\alpha$, up to a $t$-dependent rescaling of the support, and we refer to $\mu_\alpha$ as \textbf{stable} under the differentiation flow.
			
			
			\begin{theorem}[Limit of repeated differentiation]\label{conjecture:general clt}
				Let $\mu \in \mathcal{RP}_p(\C)$ with radial CDF $\Phi_0$ such that\begin{equation}\label{eq:A:tail assumption}
					\lim\limits_{x\rightarrow 1^-}f(x)\left(1-x \right)^{\frac{2}{\alpha}-1}\Phi_0^{\langle -1\rangle}(x)=1,
				\end{equation} for some $\alpha\in (0,2]$ and some positive function $f$ on $[0,1]$ such that \begin{equation}\label{eq:A:slowly varying}
					\lim_{t \rightarrow 1^-}\frac{f(t)}{f((1-t)x+t)}=1 
				\end{equation} for every $x\in(0,1)$\footnote{\eqref{eq:A:tail assumption} is equivalent to $\mu$ having at least power law decay at infinity. \eqref{eq:A:slowly varying} is intended to capture that near $1$, $f$ behaves analogously to how a slowly-varying function behaves at infinity.}. Let $\{\Phi_t\}_{t\in[0,1)}$ be the family defined by \eqref{eq:A:CDF identity} and let $\mu_t$ be the probability measure with radial CDF $\tilde{\Phi}_t(x)=\Phi_t\left(\frac{1}{f(t)}(1-t)^{2-\frac{2}{\alpha}}x \right)$. Then $\mu_t$ converges weakly to the probability measure $\mu_{\alpha}$ with radial quantile function  $\Phi_{0,\alpha}^{\langle-1\rangle}(x)=\frac{x}{(1-x)^{\frac{2}{\alpha}-1}}$ as $t \rightarrow 1^{-}$.
			\end{theorem} 
			To understand the rescaling in Theorem \ref{conjecture:general clt} it is helpful to rewrite $(1-t)^{2-\frac{2}{\alpha}}$ as $(1-t)(1-t)^{-(\frac{2}{\alpha}-1)}$. The $(1-t)^{-(\frac{2}{\alpha}-1)}$ term is to manage the tail decay of the measure, as described by \eqref{eq:A:tail assumption}. The $(1-t)$ term corrects for the natural flow inward of polynomial roots under differentiation, as described by the Gauss-Lucas theorem. 
			
			\begin{proof}[Proof of Theorem \ref{conjecture:general clt}]
				Fix $x\in(0,1)$.  We have \begin{align*}
					\lim_{t \rightarrow 1^-}\tilde{\Phi}_{t}^{\langle -1\rangle}(x)&=\lim_{t \rightarrow 1^-}f(t)(1-t)^{-(2-\frac{2}{\alpha})}\Phi_{t}^{\langle-1\rangle}(x)\\
					&=\lim_{t \rightarrow 1^-}\frac{x}{(1-t)x+t}f(t)(1-t)^{\frac{2}{\alpha}-1}\Phi_0^{\langle-1\rangle}((1-t)x+t)\\
					&=\lim_{t \rightarrow 1^-}\frac{x}{(1-t)x+t}\cdot\frac{f(t)(1-t)^{\frac{2}{\alpha}-1}}{f((1-t)x+t)(1-((1-t)x+t))^{\frac{2}{\alpha}-1}}\\
					&=\frac{x}{(1-x)^{\frac{2}{\alpha}-1}},
				\end{align*} where the third equality follows from \eqref{eq:A:tail assumption}. Hence $\tilde{\Phi}_t^{\langle -1\rangle}$ converges to $\Phi_{0,\alpha}^{\langle -1 \rangle}$ pointwise on $(0,1)$. It then follows from Lemma \ref{lemma:quntile convergence} that $\tilde{\Phi}_t$ converges to $\Phi_{0,\alpha}$ pointwise on $(0,\infty)$ as $t\rightarrow 1^-$. This completes the proof. 
			\end{proof} 	The connection established in Section \ref{sec:connection} between sums of free random variables and the differentiation flow gives the natural interpretation of Theorem \ref{conjecture:general clt} as a generalized central limit theorem. An intuitive understanding of Theorem \ref{conjecture:general clt} directly from random polynomials is less clear. One interpretation is that the tail of the limiting root measure depends on the very high degree coefficients. These are also the coefficients which survive a very high number of derivatives. Hence, two limiting roots measure with similar tails must have similar large degree coefficients, and small differences in the coefficients become negligible under repeated differentiation.
			
			The following is a direct corollary of Theorem \ref{conjecture:general clt} with $\alpha=2$ and $f(t)=1$, i.e., measures with compact support. It is worth noting the limit is $\psi_2$ applied to the uniform distribution on the unit disk in the complex plane, i.e., the Circular Law, one of the most important measures in non-Hermitian free probability. 
			
			\begin{corollary}\label{thm:A:Derivative CLT}
				Let $\mu$ be a probability measure in $\mathcal{RP}_p(\C)$ with radial cumulative distributed function $\Phi_{0}$ such that $\inf\{x\geq0:\Phi_0(x)=1\}=1$. Then \begin{equation}\label{eq:A:limit CDF result}
					\lim_{t \rightarrow 1^-}\Phi_t((1-t)r)=r,
				\end{equation} for any fixed $r\in(0,1)$, where $\Phi_t$ is the radial CDF of $\mu^{D_t}$.
			\end{corollary} 
			
			
			%We presented Theorem \ref{thm:A:Derivative CLT} for compactly supported measures, however we expect a more general limit theorem holds. Before stating our conjecture we discuss two other limits and fixed points of the differentiation flow.
			
			
			
			
			
			
			
			\subsection{PDEs describing the limiting behavior of the roots} \label{sec:PDE}
			
			Given the initial radial density $\psi(x,0)$ of the zeros at $t = 0$, the PDE in \eqref{eq:OS} describes the radial density $\psi(x, t)$ at time $0 \leq t < 1$.  
			As shown in \cite{MR4242313}, there is a constant loss of mass for the solution: 
			\[ \frac{d}{dt} \int_0^\infty \psi(x,t) \d x = -1. \]
			In other words, if $\psi(x, 0)$ is a probability density function (PDF), then $\psi(x, t)$ has mass $1 - t$.  One can renormalize so that $\psi(x,t)$ has total mass $1$, but this new function will not satisfy \eqref{eq:OS}.  In this section, we informally derive new PDEs for this PDF and its corresponding CDF.  We will also derive a PDE for the Brown measure.  Although the derivations are informal, the purposes of this section is to show how our results and examples from the previous sections are consistent with the PDE approach \cite{MR4011508,MR4242313} to studying repeated differentiation of random polynomials.  
			%Along the way, we will describe how several of the results and examples from the previous sections satisfy these PDEs.    
			
			\subsubsection{Derivation of PDE for the PDF and CDF} \label{subsec:PDFCDF}
			We define the PDF as 
			\[ \varphi(x,t) := \frac{ \psi(x,t) }{1 - t}, \qquad x \geq 0, \quad 0 \leq t < 1, \]
			where $\psi(x,t)$ is a solution to \eqref{eq:OS}.  
			Recall that we use the convention that $x \geq 0$ either denotes $x \in [0, C]$ (for some finite positive constant $C$) or $x \in [0, \infty)$, depending on whether the density is compactly supported or not. 
			The function $\varphi(x,t)$ will then satisfy the equation 
			\begin{equation} \label{eq:OS:PDF}
				{ (1 - t) \frac{ \partial \varphi(x,t) }{\partial t} = \frac{ \partial}{\partial x} \left( \frac{ \varphi(x,t) }{ \frac{1}{x} \int_0^x \varphi(y,t) dy } \right) + \varphi(x,t), \qquad x \geq 0, \quad 0 \leq t < 1. } 
			\end{equation} 
			Indeed, from \eqref{eq:OS}, we derive
			\begin{align*}
				\frac{\partial \varphi(x,t)}{\partial t} &= \frac{1}{1 - t} \frac{ \partial \psi(x,t) }{\partial t} + \frac{1}{(1 - t)^{2}} \psi(x,t) \\
				&= \frac{1}{1 - t} \frac{ \partial}{\partial x} \left( \frac{ \psi(x,t) }{ \frac{1}{x} \int_0^x \psi(y,t) dy } \right) + \frac{1}{1 -t} \varphi(x,t) \\
				&= \frac{1}{1 - t} \frac{ \partial}{\partial x} \left( \frac{ \varphi(x,t) }{ \frac{1}{x} \int_0^x \varphi(y,t) dy } \right) + \frac{1}{1 -t} \varphi(x,t).  
			\end{align*}
			Thus, by rearranging, we obtain \eqref{eq:OS:PDF}.  
			
			It is easy to check that if $\int_0^\infty \varphi(x,0) \d x = 1$, then the solution to \eqref{eq:OS:PDF}  satisfies $\int_0^\infty \varphi(x,t) \d x = 1$ for all $0 \leq t < 1$.  In fact, from \eqref{eq:OS:PDF}, we have
			\begin{align*}
				(1 - t) \frac{ \partial}{\partial t} \int_0^\infty \varphi(x,t) \d x &= \int_0^\infty (1-t) \frac{ \partial \varphi(x,t)}{\partial t} \d x \\
				&= \int_0^\infty  \frac{ \partial}{\partial x} \left( \frac{ \varphi(x,t) }{ \frac{1}{x} \int_0^x \varphi(y,t) dy } \right) \d x + \int_0^\infty \varphi(x,t) \d x \\
				&= -\lim_{\eps \to 0} \frac{ \varphi(\eps, t)}{\frac{1}{\eps} \int_0^\eps \varphi(y,t) \d y } + \int_0^\infty \varphi(x,t) \d x \\
				&= -1 + \int_0^\infty \varphi(x,t) \d x,
			\end{align*}
			where we used the regularity of the solution, and we assumed $x \mapsto \varphi(x, 0)$ is compactly supported, which by the Gauss--Lucas theorem hints that the support of $x \mapsto \varphi(x, t)$ is contained in the support of $x \mapsto \varphi(x, 0)$ for all $0 \leq t < 1$.  Thus, if $y(t) = \int_0^\infty \varphi(x,t) \d x$, we obtain the linear ODE:
			\[ (1 - t) y' = y -1, \]
			which admits the solution
			\[ y(t) = \frac{C}{1 - t} + \frac{t}{t-1} \]
			for a constant $C$ depending on the initial value.  In fact, if $y(0) = 1$, then $C = 1$, and we find the constant solution $y(t) = 1$ for all $0 \leq t < 1$, as desired.  
			%Interestingly, for other initial values, $y(t)$ does not admit a constant solution.  
			
			Define the cumulative distribution function of the solution $\varphi(x,t)$ of \eqref{eq:OS:PDF} as 
			\[ \Phi(x,t) = \int_0^x \varphi(y,t) dy. \]
			Then, using \eqref{eq:OS:PDF}, we obtain
			\begin{align*}
				(1 - t) \frac{\partial \Phi(x,t) }{\partial t} &= \int_0^x (1 - t) \frac{\partial \varphi(y,t) }{\partial t} dy \\ 
				&= \int_0^x \frac{ \partial }{\partial y} \left( \frac{ \varphi(y, t) }{ \frac{1}{y} \int_0^y \varphi(z, t) dz } \right) dy + \int_0^x \varphi(y, t) dy \\
				&= \int_0^x \frac{ \partial }{\partial y} \left( y \frac{ \frac{ \partial \Phi(y,t)}{\partial y} }{ \int_0^y \varphi(z, t) dz } \right) dy + \Phi(x,t) \\
				&= \frac{x \frac{ \partial \Phi(x,t) }{\partial x} }{\Phi(x,t) } - 1 + \Phi(x,t).
			\end{align*} 
			We conclude that $\Phi(x,t)$ satisfies the following PDE: 
			\begin{equation} \label{eq:OS:CDF}
				{ (1 - t) \frac{\partial \Phi(x,t) }{\partial t} = \frac{x \frac{ \partial \Phi(x,t) }{\partial x} }{\Phi(x,t) } - 1 + \Phi(x,t), \qquad x \geq 0, \quad 0 \leq t < 1. } 
			\end{equation}
			Now that we have a PDE for the CDF, we can compare \eqref{eq:OS:CDF} to the examples in the previous sections.  For instance, it is easy to check that $\Phi(x,t) = \Phi_{0, 1}(x) = \frac{x}{1+x}$ from Section \ref{sec:limit_roots} satisfies \eqref{eq:OS:CDF}.  
			
			\subsubsection{Rescaling the $x$ coordinate}
			If $\Phi(x, 0)$ at $t = 0$ is supported on $x \in [0, 1]$, we expect that $\Phi(x, t)$ is supported on $x \in [0, 1 - t]$ for $0 \leq t < 1$.  If we define $\tilde \Phi(x,t) = \Phi((1-t)x, t)$, then $\tilde \Phi(x, t)$ is supported on $x \in [0, 1]$ for all $0 \leq t < 1$ but will no longer satisfy \eqref{eq:OS:CDF}.  One can easily derive the PDE that $\tilde \Phi(x, t)$ does satisfy using \eqref{eq:OS:CDF}. Indeed, by the chain rule, we have
			\begin{align*}
				\frac{ \partial \tilde \Phi(x,t)}{\partial t} &= -x \frac{ \partial \Phi( (1-t)x,t)}{\partial x} + \frac{\partial \Phi((1-t)x,t)}{\partial t}, \\
				\frac{ \tilde \Phi (x,t)}{\partial x} &= (1-t) \frac{\partial \Phi((1-t)x, t) }{\partial x}. 
			\end{align*}
			In particular, this implies that
			\[ (1 -t) \frac{ \partial \tilde \Phi(x,t)}{\partial t} = -x \frac{\partial \tilde \Phi(x,t)}{\partial x} + (1 - t) \frac{\partial \Phi((1-t)x,t)}{\partial t}. \]
			Thus, from \eqref{eq:OS:CDF}, we obtain the following PDE for $\tilde \Phi (x,t)$:
			\begin{equation} \label{eq:OS:CDF:rescale}
				{(1 - t) \frac{ \tilde \Phi (x,t) }{\partial t} = -x \frac{\partial \tilde \Phi(x,t)}{\partial x} + \frac{ x \frac{\partial \tilde \Phi(x,t)}{\partial x}}{\tilde \Phi(x,t)} - 1 + \tilde \Phi(x,t), \qquad x \geq 0, \quad 0 \leq t < 1. }
			\end{equation}
			One can now take the $t \to 1^-$ limit in \eqref{eq:OS:CDF:rescale}.  Indeed, if $\tilde \Phi(x) = \lim_{t \to 1^-} \tilde \Phi(x,t)$ and  $\lim_{t \to 1^-} \frac{\partial \tilde \Phi(x,t)}{\partial x} =   \tilde \Phi'(x)$, then one arrives at the following ODE for $\tilde \Phi(x)$:
			\begin{equation} \label{eq:OS:tode}
				x \tilde \Phi'(x)= \frac{ x \tilde \Phi'(x)}{\tilde \Phi(x)} - 1 + \tilde \Phi(x), \qquad x \geq 0. 
			\end{equation}
			It is straightforward to check that the example $\tilde \Phi(x) = x$ from Theorem \ref{thm:A:Derivative CLT} solves \eqref{eq:OS:tode}.  
			
			
			In a similar fashion, using \eqref{eq:OS:PDF}, one can also derive a PDE for the rescaled PDF $\tilde \varphi(x, t) = (1-t) \varphi((1-t)x, t)$ and take the limit $t \to 1^-$.  
			
			\subsubsection{CDF for the Brown measure}
			Using the connection between random polynomials and the Brown measure discussed in Section \ref{sec:connection}, we can similarly derive PDEs for the radial parts of the PDF and CDF for the Brown measure.  
			Let
			\[ F(x,t) = \Phi(x^2, t), \qquad x \geq 0, \quad 0 \leq t < 1 \]
			be the CDF of the radial part of the Brown measure, where $\Phi(x, t)$ is defined in Section \ref{subsec:PDFCDF} above.  Using \eqref{eq:OS:CDF}, we find
			\begin{align*}
				(1 - t) \frac{\partial F(x,t)}{\partial t} &= (1 - t) \frac{ \partial \Phi(x^2, t)}{\partial t} \\
				&= \frac{x^2 \frac{ \partial \Phi(x^2, t)}{\partial x} }{ \Phi(x^2, t) } - 1 + \Phi(x^2, t).
			\end{align*}
			Thus, since 
			\[ \frac{\partial F(x,t)}{\partial x} = 2x \frac{\partial \Phi(x^2, t)}{\partial x}, \] 
			we conclude with the following PDE for $F(x, t)$: 
			\[ { (1 - t) \frac{\partial F(x,t)}{\partial t} = \frac{ x \frac{ \partial F(x, t) }{ \partial x}}{ 2 F(x,t) } - 1 + F(x,t), \qquad x \geq 0, \quad 0 \leq t < 1. } \]
			
			Similarly, using \eqref{eq:OS:PDF}, one can also derive a PDE for the PDF of the radial part of the Brown measure given by $f(x,t) = 2x \varphi(x^2, t)$; we omit the details.  

			
			
			
			\section{Examples} \label{sec:examples}
			
			In this section, we provide examples of the relationship between the Brown measures under the convolution $\oplus$ and the limiting empirical root measures of random polynomials under repeated differentiation. 
			
			
			\subsection{Circular law and random Taylor polynomials}\label{sec:CLandTP}

			
			
			We call an element $c \in \mathscr{M}$ a standard circular element if its $R$-transform is 
			\[ R_{c,c^*}(z_1,z_2) = z_1 z_2 + z_2 z_1. \]
			The Brown measure of a standard circular element is the uniform measure on the unit disk.
			A standard computation (see, for example, \cite{MR1784419} Example 5.1) shows that the $S$-transform of $cc^*$ is:
			\[ \mathscr{S}_{c c^*}(z) = 1/(1+z). \]
			From \eqref{eq:Spiaa}, we have have that 
			\[ \mathscr{S}_{\lambda^{-2} \pi(c) \pi(c)^*}(z) =  \frac{\lambda(1 + \lambda z)}{1+z} \frac{\lambda}{1+ \lambda z} =  \frac{\lambda }{(1+z)}, \]
			which recovers the result from \cite{MR1784419} that the free compression of a standard circular element by $\pi_\lambda$ is just $\lambda^{1/2}$ times a standard circular element. Furthermore, setting $\lambda = 1/k$ verifies the well known fact that if $c_1, \ldots, c_k$ are $\ast$-freely independent standard circular elements, then $k^{-1/2} \sum_{i=1}^k c_i$ is also a standard circular element.
			
			
			We then consider the random Taylor polynomial, given by \begin{equation} \label{eq:taylor}
				p_n(z)=\sum_{k=0}^{n}\frac{\xi_k}{k!}z^k,
			\end{equation}
			 where $\xi_0,\xi_1,\dots,$ are iid random variables satisfying \eqref{eq:xik}. It is easy to see that $p_n'$ is equal in distribution to $p_{n-1}$, and hence one would expect the limiting root distributions of such polynomials to be stable under differentiation.
			The limiting root distribution, after dividing the roots by $n$, of such polynomials has density $\frac{1}{2\pi|z|}$ and radial CDF $\Phi_T(r)=r$ for $r\in[0,1]$. This limiting root distribution is in fact the measure $\mu_2$ given in Theorem \ref{conjecture:general clt}. Considering Theorem \ref{thm:A:connection general case} and  Figure \ref{fig:A:Diagram of relationship}, it is worth noting $\mu_2$ is $\psi_2$ applied to the uniform distribution on the unit disk in the complex plane.
			
			
			\subsection{Haar unitaries} \label{sec:Haar} We now discuss the example in Theorem \ref{thm:A:Kacs free convolution}. In \cite{MR1784419}, Haagerup and Larsen consider
			\[ u^{(k)} := u_1 + u_2 + \cdots+ u_k  \]
			where $u_1, u_2, \ldots, u_k$ are $\ast$-freely independent, Haar unitary elements and show that the $S$-transform of $u^{(k)}u^{(k)*}$ is 
			\begin{equation} \label{eq:Ssumhaar} S_{u^{(k)}u^{(k)*}}(z) = \frac{ z + k }{ k^2(z+1)  },   \end{equation}
			and hence the Brown measure has radial CDF
			\[ F_{\mu_{u^{(k)}}}(r) =  (k - 1)\frac{r^2}{ k^2 - r^2 } \]
			for $r \in [0,\sqrt{k}]$.
			
			On the other hand \eqref{eq:Ssumhaar} is exactly the multiplicative factor in \eqref{eq:Slambda}, so \eqref{eq:Ssumhaar} is also the $S$ transform of $u p$, where $u$ is a Haar unitary element and $p$ is a $\ast$-freely independent projection with trace $\tau(p)= 1/k=\lambda$. The example of $up$ was also considered in \cite{MR1784419}, where it is shown that the nonzero part of the Brown measure of $up$ has radial density\footnote{Haagerup and Larson \cite{MR1784419} use a different convention of \textit{radial density}.} \begin{equation*}
				f_{up}(r)=\frac{2r(1-\lambda)}{(1-r^2)^2}\oindicator{\left(0,\sqrt{\lambda}\right)}(r), 
			\end{equation*} where $\oindicator{\left(0,\sqrt{\lambda}\right)}$ is the indicator function for the set $\left(0,\sqrt{\lambda}\right)$.  Hence, the Brown measure of $\pi(u)$ has radial density \begin{equation}
				g_{\pi(u)}(r)=\frac{2r(1-\lambda)}{\lambda(1-r^2)^2}\oindicator{\left(0,\sqrt{\lambda}\right)}(r), 
			\end{equation} and therefore $\pi(u)$ has radial CDF \begin{equation}\label{eq:A:compressed unitary CDF}
				F_{\pi(u)}(r)=\begin{cases}
					\frac{1-\lambda}{\lambda}\frac{r^2}{1-r^2},&\ 0\leq r\leq \sqrt{\lambda}\\
					1,&\ r\geq \sqrt{\lambda}
				\end{cases}.
			\end{equation}
	Finally, we note that using \eqref{eq:Slambda} to compute the Brown measure of $u^{(k)}$ and $up$ is more direct than in \cite{MR1784419}.

			The Brown measure of $u$ is the uniform probability measure on the unit circle in $\C$. Hence, even after applying $\psi_2$, the natural random polynomial to compare to is the Kac polynomial \begin{equation}
				p_n(z)=\sum_{k=1}^n \xi_kz^k,
			\end{equation} where $\xi_0,\xi_1,\dots,$ are iid random variables satisfying \eqref{eq:xik}. The empirical root measure of Kac polynomials is known to converge in probability to the uniform probability measure on the unit circle. 
			
			
			Let $t=1-\lambda\in(0,1)$. Feng and Yao \cite{MR3921311} established that the empirical root measure of $p_n^{\lfloor(tn)\rfloor}$ converges (see Theorem \ref{thm:feng-yao}) in probability to the measure with radial CDF\begin{equation}\label{eq:A:Kac der CDF}
				\Phi_t(r)=\begin{cases}
					\frac{t}{1-t}\frac{r}{1-r},&\ 0\leq r\leq 1-t\\
					1,&\ r\geq 1-t
				\end{cases}.
			\end{equation} Then $\Phi_t$ is the push-forward of $F_{\pi(u)}$ under $\psi_2$, as given in Figure \ref{fig:A:Diagram of relationship}.%.
			%the map $z\mapsto z^2$.
			
			
			
					
\subsection{Commutator of $R$-diagonal operators}

In this section, we consider the (anti-)commutator of two free $R$-diagonal elements $x, y$. At the end of the section, we specialize to the case that $x$ and $y$ are both circular elements. 

\begin{proposition}\label{prop:commutator}
 Let $x$ and $y$ be free $R$-diagonal elements. Let $\lambda_2^x,\lambda_2^y$ be as in  Theorem \ref{thm:BM}, for $x$ and $y$, respectively, and let $ \lambda_2 = \sqrt{2} \lambda_2^x \lambda_2^y $ and 
\[ \mathscr{S}_{comm}(z) = \frac{2 + z}{ 4(1+z)} \mathscr{S}_{x^* x}(z/2) \mathscr{S}_{y^* y} (z/2) .\] Then the Brown measure of $xy \pm yx$ is given by:
 \[ \mu_{xy \pm yx}( \D_r)   = \begin{cases} 1 + \mathscr{S}_{comm}^{\langle -1 \rangle}(r^{-2})  & \text{ if }  0 < r < \lambda_2     \\ 1 & \text{ if } r \geq \lambda_2   \end{cases}.   \]
\end{proposition}

\begin{proof}
We prove the statement for the commutator, the anti-commutator is completely analogous. Our main goal in this proof, is to rewrite $xy -yx$ as the sum of two $\ast$-free, identically distributed $R$ diagonal elements.
We begin with a standard trick when working with $R$-diagonal elements and introduce a new Haar unitary $u$, that is $\ast$-freely independent from $x$ and $y$. Then, because $x$ and $y$ are $R$-diagonal, we have that $(ux, yu^*)$ has the same $\ast$-distribution as $(x,y)$, and thus we can instead consider the Brown measure of 
\[uxyu^* - yu^* u x = uxyu^* - yx.\]
Furthermore, $uxyu^*$ and $y x$ are $\ast$-freely independent (see for example, Exercise 5.24 \cite{MR2266879}), so we can introduce two more $R$-diagonal elements $w,z$ such that $(w,z)$ have the same $\ast$-distribution as $(x,y)$. Then, because $yx$ and $-yx$ have the same $\ast$-distributions, we can consider the Brown measure of $wz + yx$. The Brown measure of $xy$ (and thus $wz$ because they are the same) is then computed by using the relationship $\mathscr{S}_{xyy^*x^*} = \mathscr{S}_{xx^*}\mathscr{S}_{yy^*}$ for any $\ast$-free R-diagonal elements, \cite{MR1426839}. Then since the $\ast$-distribution of $yx$ and $wz$ are the same, we can apply Proposition \ref{prop:brownmeasuresum} with $k=2$ to complete the proof.
\end{proof} 

Before specializing to commutators of circular elements, we give a polynomial interpretation of the commutator of general $R$-diagonal elements. As the connection between addition and the $n/2$-th derivative has already been discussed we focus on the product $xy$. 
\begin{proposition}
	Let \begin{equation*}
	p_n(z) := \sum_{k=0}^n \xi_k p_{k,n} z^k,
	\end{equation*} and \begin{equation*}
	q_n(z) := \sum_{k=0}^n \xi_k q_{k,n} z^k,
	\end{equation*} be random polynomials where $p_{k,n}$ and $q_{k,n}$ are deterministic coefficients satisfying Assumption \ref{assump:a1} for some functions $p(t)$ and $q(t)$ respectively, and $\xi_0, \xi_1, \ldots$ are iid non-degenerate complex-valued random variables which satisfy $\E \log(1 + |\xi_0|) < \infty$. Let $\mu_{p}$ and $\mu_{q}$ be the in probability limits of the empirical root measures of $p_n$ and $q_n$ respectively. Define the random polynomial \begin{equation*}
	s_n(z):=\sum_{k=0}^n p_{k,n}q_{k,n}\xi_kz^k.
\end{equation*} Then $p_{k,n}q_{k,n}$ satisfy Assumption \ref{assump:a1} with function $s(t):=p(t)q(t)$, and the radial quantile function, $\Phi_{s}^{\langle-1\rangle}$, of the (in probability) limiting empirical root measure, $\mu_s$, is given by \begin{equation}
\Phi_{s}^{\langle-1\rangle}(x)=\Phi_{p}^{\langle-1\rangle}(x)\Phi_{q}^{\langle-1\rangle}(x),
\end{equation} where $\Phi_{p}^{\langle-1\rangle}$ and $\Phi_{q}^{\langle-1\rangle}$ are the radial quantile functions of $\mu_{p}$ and $\mu_{q}$ respectively. Moreover, if $x$ and $y$ are $\ast$-free $R$-diagonal elements such that $\mu_x=\psi_2^{-1}\mu_p$ and $\mu_y=\psi_2^{-1}\mu_q$, then $\mu_{xy}=\psi_2^{-1}\mu_s$.
\end{proposition}

\begin{proof}
	It is immediate to see $s$ satisfies points \eqref{assump:a1 p is non neg} and \eqref{assump:a1 p is continuous} of Assumption \ref{assump:a1}. For \eqref{assump:a1 coefficients converge to p}, note \begin{align*}
		\lim_{n \to \infty} \sup_{0 \leq k \leq n} &\left| |p_{k,n}q_{k,n}|^{1/n} - p\left( \frac{k}{n}\right)q\left(\frac{k}{n}\right) \right| \\
		&\leq\lim_{n \to \infty} \sup_{0 \leq k \leq n} \Bigg[ \left| |p_{k,n}q_{k,n}|^{1/n} - p\left( \frac{k}{n}\right)|q_{k,n}|^{1/n} \right| \\
			&\qquad+\left| p\left(\frac{k}{n}\right)|q_{k,n}|^{1/n} - p\left( \frac{k}{n}\right)q\left(\frac{k}{n}\right) \right| \Bigg] \\
			&=0, 
	\end{align*} where the last equality follows from the continuity, and hence boundedness, of $p$ and $q$. It remains to show the quantile function $\Phi^{\langle-1\rangle}_{s}$  factors as the radial quantile functions $\Phi^{\langle-1\rangle}_{p}$ and $\Phi^{\langle-1\rangle}_{q}$. Let $I: \mathbb{R} \to \mathbb{R} \cup \{+\infty\}$ be the Legendre--Fenchel transform of $u(t) = -\log s(t)$, then \begin{equation}\label{eq:Phi_s def}
	\Phi_s(r)=I'(\log r), \quad r>0.
\end{equation} We will assume $u$, $-\log p$, and $-\log q$ are convex functions. Otherwise, we can instead work with the second Legendre--Fenchel transforms $\tilde{u}$, $\tilde{-\log p}$, and $\tilde{-\log q}$  of $u$, $-\log p$, and $-\log q$ respectively. As the Legendre--Fenchel transform is an involution on convex functions, this change has no affect on $\Phi_{s}$, $\Phi_{p}$, or $\Phi_{q}$. To consider quantile functions, we note from general properties of Legendre--Fenchel transforms that $[I']^{\langle-1\rangle}=u'$ (See for example \cite{MR0274683}, specifically Corollary 23.5.1). Taking (generalized) inverses in \eqref{eq:Phi_s def}\begin{align*}
\Phi^{\langle-1\rangle}_{s}(x)&=\exp\left([I']^{-1}(x)\right)\\
							  &=\exp\left(u'(x)\right)\\
							  &=\exp\left(-\frac{d}{dx}\log p(x)-\frac{d}{dx}\log q(x)\right)\\
							  &=\Phi_{p}^{\langle-1\rangle}(x)\Phi_{q}^{\langle-1\rangle}(x).
\end{align*} As discussed in the proof of Proposition \ref{prop:commutator}, $\mathscr{S}_{xyy^*x^*} = \mathscr{S}_{xx^*}\mathscr{S}_{yy^*}$. Hence, from \eqref{eq:Brownmeasure} the radial quantile function of $\mu_{xy}$ is $F^{\langle-1\rangle}_{xy}=F^{\langle-1\rangle}_{x}F^{\langle-1\rangle}_{y}$. This completes the proof of the final statement by noting $\Phi_{p}^{\langle-1\rangle}=[F^{\langle-1\rangle}_{x}]^2$ and $\Phi_{q}^{\langle-1\rangle}=[F^{\langle-1\rangle}_{y}]^2$. 
\end{proof}


We now consider the Brown measure of the commutator of 2 $\ast$-free circular elements. We note that this model was considered in \cite{MR4492979}, where it is shown that the empirical spectral distribution of any quadratic polynomial in independent Ginibre random matrices converges to the Brown measure of the corresponding polynomial in $\ast$-free circular elements, but the Brown measure was not computed. 

Since $\mathscr{S}_{xx^*}(z) = \mathscr{S}_{yy^*}(z) = \frac{1}{1+ z}$, we have that 
\[ \mathcal{S}_{comm}(z) = \frac{2 + z}{ 4(1+z)} \frac{ 4  }{(2 + z)^2 } = \frac{ 1 }{(1+z)(2+ z)}. \]
Proposition \ref{prop:commutator} then gives that the radial CDF of the Brown measure of $xy - yx$ is 
\[ \mu_{xy -yx}(\D_r) = 1  + \frac{-3 + \sqrt{1 + 4 r^2}}{ 2}  =   \frac{-1 + \sqrt{1 + 4 r^2}}{ 2}   \]
for $r \in (0,\sqrt{2})$. 

			
			
			
			\subsection{Stable laws} \label{sec:stable}
			
			
			
			
			
			
			In \cite{MR3896715}, the Brown measures that are stable under the $\rdplus$ operation are characterized. One way to establish this characterization is via the bijection $\mathcal{H}$, so it suffices to determine the symmetric probability measures that are stable under $\boxplus$, and then determine their $S$-transforms. 
			This was done in \cite{MR2506464}, building upon the work of \cite{MR2128863}, where it is shown that the $S$-transform of any symmetric free stable distribution is of the form:
			\[ \mathscr{S}_{\alpha}(z) = \theta e^{i(2-\alpha) \frac{ \pi}{2 \alpha}} z^{\frac{1}{\alpha}-1} = \theta i (-z)^{1/\alpha-1} \]
			for $0 < \alpha \leq 2 $, and some constant $\theta > 0$. Additionally, they prove that for $\mu$, a symmetric probability measure on $\R$:
			\[\mathscr{S}_{\mu}^2(z) = \frac{1+z}{z} \mathscr{S}_{\mu^2}(z) ,  \]
			where $\mu^2$ is the probability measure on $\R^+$ induced by the map $x \to x^2$.
			So we see that if $\mu$ is a symmetric free stable distribution then the $S$-transform of $\mu^2$ is:
			\begin{equation}  \mathscr{S}_{\mu^2}(z) = \theta \frac{ (-z)^{\frac{2}{\alpha} -1}}{1+z}\end{equation}
			for some (possibly different) constant $\theta > 0$.  
			This is exactly the expression in \eqref{eq:stableS}. We now give an alternative, more direct, proof of Proposition \ref{prop:stablelaw}, without relying on the characterization of stable laws on $\R$.
			
			
			\begin{proof}[Proof of Proposition \ref{prop:stablelaw}]
				We will show that the $S$-transforms in \eqref{eq:stableS} are exactly the class of functions that are fixed by \eqref{eq:Spiaa}. %So the measures that are stable under our convolution of the Brown measures of $R$-diagonal elements, are in correspondence with symmetric stable distributions. This relation is clear from , but we now show that it also follows immediately from our convolution formula.
				
				If $\mathscr{S}_{a a^*} (z) = \frac{(-z)^{\frac{2}{\alpha}-1}}{1+z}$ then a simple rescaling of the argument gives:
				\[  \mathscr{S}_{a a^*} (z) = \frac{\lambda^{-2/\alpha} \lambda (1+\lambda z)}{1+z} \mathscr{S}_{a a^*} (\lambda z) .\] 
				Additionally, these are exactly the class of functions that are invariant after  rescaling by $\lambda$ and then multiplying by $c \frac{ \lambda (1+\lambda z)}{1+z} $, for some constant $c$.
				But from \eqref{eq:Spiaa}, we have that the right-hand side is equal to the $S$-transform of $\lambda^{2/\alpha-2} \pi_{\lambda}(a)\pi_{\lambda}(a)$. In other words, the Brown measure is fixed by the map $a \to \lambda^{1/\alpha-1} \pi_{\lambda^{}}(a)$, which, by Proposition \ref{prop:brownmeasuresum}, has the same law as
				\[ \frac{a_1 + \cdots + a_k  }{ k^{1/\alpha}  } \]
				when $\lambda = 1/k$.
			\end{proof}
			The case $\alpha =2$ corresponds to the circular element, considered in Section \ref{sec:CLandTP}. When $\alpha=1$, the inverse of the $S$-transform can be explicitly computed to show that the Brown measure is a complex Cauchy distribution. This case corresponds to $x y^{-1}$, with $x,y$ $\ast$-freely independent circular elements, and was first considered in \cite{MR2339369}. More generally, in \cite{MR3896715}, it is shown that if $l = 2/\alpha-1$ is an integer, then this is the Brown measure of $x_0 x_1^{-1} \cdots x_{l}^{-1}$, where the $x_i$'s are $\ast$-freely independent circular elements.	
			
			In Section \ref{sec:limit_roots} we considered measures arising as the limit of the differentiation flow. The limiting measures, $\mu_\alpha$, can be characterized by their inverse radial CDF $\Phi_{0,\alpha}^{\langle-1\rangle}(x)=\frac{x}{(1-x)^{\frac{2}{\alpha}-1}}$ for $\alpha\in (0,2]$. For each $\alpha\in(0,2]$, the measure $\mu_\alpha$ is in fact $\psi_2$ applied to the Brown measure of an $\alpha$-$\oplus$ stable element considered in Proposition \ref{prop:stablelaw}. The results of Section \ref{sec:limit_roots} can be interpreted as the iterated limit $\lim_{t \rightarrow 1^-}\lim_{n \to \infty}$, where the proportion of derivatives tends to $1$ after the degree is sent to infinity. This can somewhat obscure the connection between $\mu_\alpha$ and random polynomials. In the remainder of this section, we more directly relate $\mu_\alpha$ to random polynomials with independent coefficients and give partial answers to questions raised by Feng and Yao \cite{MR3921311}.
			
			Except for a few special cases of $\alpha\in (0,2]$, we are not aware of simple coefficients $p_{k,n}$ for the random polynomials in \eqref{eq:pngen} for which $\mu_\alpha$ is the limiting empirical root measure. Although coefficients $p_{k,n}$ giving rise to $\mu_\alpha$ can be computed from the explicit description of $\Phi_{0,\alpha}^{\langle-1\rangle}$, these coefficients are somewhat complicated and the stability under repeated differentiation is not obvious. One exceptional case is when $\alpha=2$, corresponding to the random Taylor polynomials discussed in Section \ref{sec:CLandTP}. 
			
			
			Another exceptional case is the true fixed point of the differentiation flow, $\mu_{1}$ in Theorem \ref{conjecture:general clt} with radial CDF $\Phi_{0,1}(r)=\frac{r}{1+r}$, which has inverse $\Phi_{0,1}^{\langle -1\rangle}(x)=\frac{x}{1-x}$.  In this case $\Phi_t(r)=\Phi_0(r)$ for all $t\in[0,1)$. The stability of $\mu_{1}$ under the differentiation flow can be observed directly from random polynomials. Kabluchko and Zaporozhets \cite{MR3262481} identified $\mu_{1}$ as the limiting root distribution of the random polynomial (which they refer to as a random elliptic polynomials with parameter $\alpha=1$) \begin{equation*}
				p_n(z)=\sum_{k=0}^n {n\choose k}\xi_k z^k.
			\end{equation*} If we consider the derivative of $p_n$ we see from elementary properties of binomial coefficients that \begin{align*}
				p_n'(z)&=\sum_{k=1}^n k{n\choose k}\xi_k z^{k-1}\\
				&=\sum_{k=1}^n n{n-1\choose k-1}\xi_k z^{k-1}\\
				&\overset{d}{=}np_{n-1}(z),
			\end{align*} which has the same roots as $p_{n-1}$.
			
			
			Although for $\alpha\neq 1,2$ we expect the coefficients directly giving rise to $\mu_\alpha$ to be more complicated than the example discussed above, we now demonstrate how relatively simple coefficients can be chosen if the number of derivatives is taken to be on the order of $n-o(n)$. We first remark on a result of Feng and Yao \cite{MR3921311} and its relation to Theorem \ref{conjecture:general clt}.
			
			In \cite{MR3921311} Theorem 6, Feng and Yao computed the limiting root distribution for random polynomials with coefficients\begin{equation*}
				p_{k,n}=\binom{n}{k}^{1/2},
			\end{equation*} as the proportion of derivatives tends to one with the degree. The limit, after rescaling, in their work is the measure $\mu_{1/2}$ from Theorem \ref{conjecture:general clt}. 		
			Feng and Yao \cite{MR3921311} additionally consider the limiting root distribution for derivatives of random Kac polynomials (introduced in Section \eqref{sec:Haar}) as the proportion of derivatives tend to one as the degree tends to infinity. The limit, after rescaling, matches that of Corollary \ref{thm:A:Derivative CLT}. Without rescaling, both the limit for a high number of derivatives of Kac polynomials and random elliptic polynomials would be a point mass at $0$. Feng and Yao pose the following questions for a general random polynomial as defined in \eqref{eq:pngen}:\begin{enumerate}
				\item If $N_n=n-D_n$ where $D_n=o(n)$ and $D_n\rightarrow\infty$ with $n$, then when is $\delta_0$ the limiting root distribution of $p_n^{(\lfloor N_n\rfloor)}$?
				
				\item If the limiting root distribution of $p_n^{(\lfloor N_n\rfloor)}$ is $\delta_0$, does there exist a rescaling of the roots giving a non-degenerate limit? If so, what is the scaling?
			\end{enumerate} Theorem \ref{conjecture:general clt} suggests that the answer to both questions should depend largely on the tail of the limiting root measure. However, to fully answer both questions some additional regularity on the coefficients would need to be considered (see the discussion following Theorem 5 in \cite{MR3921311}). In the following proposition we partially answer these questions. In doing so we provide a family of random polynomials with relatively simple coefficients which after taking, for example, $N_n=n-\lfloor\log n\rfloor$ derivatives have limiting empirical root measures stable under the differentiation flow. 
			\begin{proposition}\label{prop:A:limit with n for elliptic}
				For $\alpha\in(0,2]$, let $p_{n}$ be the general random polynomial defined in \eqref{eq:pngen} such that $\xi_1,\xi_2,\dots$  satisfy \eqref{eq:xik} and \begin{equation}
					p_{k,n}=\binom{n}{k}^{\frac{2}{\alpha}-1}.
				\end{equation} Let $N_n=n-D_n$ where $D_n$ is such that $D_n=o(n)$ and $D_n\rightarrow\infty$ as $n\rightarrow\infty$, and let $R_n=\left(\frac{n}{D_n} \right)^{2-\frac{2}{\alpha}}$. Let $\tilde{p}_n$ be the random polynomial defined by $\tilde{p}_n(z)=p_n(z/R_n)$. Then the empirical root measure of $\tilde{p}_n^{(\lfloor N_n\rfloor)}$ converges in probability as $n \to \infty$ to the probability measure $\mu_{\alpha}$ defined in Theorem \ref{conjecture:general clt}.
				
				Moreover, if 	\[ \mu_{D_n} = \frac{1}{D_n}\sum_{z \in \mathbb{C} : p^{(\lfloor N_n\rfloor)}(z) = 0} \delta_{z}, \] then weakly, in probability,\begin{equation}
					\lim\limits_{n\rightarrow \infty} \mu_{D_n}=\begin{cases}
						0,\ 0<\alpha<1\\
						\mu_1,\ \alpha=1\\
						\delta_0,\ 1<\alpha\leq 2						
					\end{cases},
				\end{equation} where $\delta_0$ is a point mass at the origin, $0$ is the zero measure, and $\mu_1$ is defined in Theorem \ref{conjecture:general clt}.
			\end{proposition}  
			
			
			
			Letting $t=\frac{N_n}{n}$, and noting $\frac{n}{D_n}=(1-t)^{-1}$ we see that the scaling in Proposition \ref{prop:A:limit with n for elliptic} matches that of Theorem \ref{conjecture:general clt}. We expect this phenomenon holds in more generality, i.e., under sufficient regularity conditions on the coefficients of $p_n$ the scaling should depend only on the tail of the limiting root measure and the limiting empirical measure for the rescaled roots should be $\mu_\alpha$.
			\begin{proof}[Proof of Proposition \ref{prop:A:limit with n for elliptic}]
				To simplify notation, let $\beta=\frac{2}{\alpha}-1$. Proposition \ref{prop:A:limit with n for elliptic} is a straightforward generalization of Theorem 6 in \cite{MR3921311}. We sketch the necessary changes. The $\left(\frac{n}{D_n}\right)^{-\beta}$ term in the rescaling is used to control the coefficients $p_{n,k}$, $N_n\leq k\leq n$ of $p_n$, while the additional $\left(\frac{n}{D_n}\right)$ term is used to control how the coefficients evolve under differentiation. We can then conclude that if $\tilde{p}_{k,n}$ are the coefficients of $\tilde{p}_n$, then\begin{equation}\label{eq:A:log limit}
					\lim\limits_{n\rightarrow \infty}\sup_{0 \leq k \leq D_n}\left|\frac{1}{D_n}\log \tilde{p}_{k,n}-\log \tilde{p}_\beta\left(\frac{k}{D_n}\right) \right|=0, 
				\end{equation} where \begin{equation}\label{eq:A:limiting coefficient function}
					\log p_\beta(t)=-t\log t-\beta(1-t)\log(1-t)+(1-\beta)t+\beta-1
				\end{equation} for $0\leq t\leq 1$ and $\log p_\beta(t)=-\infty$ for $t>1$. The conclusion then follows from \eqref{eq:A:log limit}, \eqref{eq:A:limiting coefficient function}, Theorem \ref{thm:feng-yao} and the observation in \cite{MR3262481} that the limiting empirical root measure is given by the push-forward of the  Lebesgue measure under the map $x\mapsto \exp\left(-\frac{d}{dt}\log p_\beta(x) \right)$.
			\end{proof}   
			
			
			


			
			
			
			
			
			%	\section{Quick example, not a real section} We now provide and example of the relationship between Brown measures under $\oplus$ and limiting empirical root measures of random polynomials under repeated differentiation. Let $u$ be a Haar unitary element and $p$ a projection freely independent of $u$ with trace $\tau(p)=\lambda$. The Brown measure of $u$ is the uniform probability measure on the unit circle in $\C$. Hence, even after squaring, the natural random polynomial to compare to is the Kac polynomial \begin{equation}
				%		p_n(z)=\sum_{k=1}^n \xi_kz^k,
				%	\end{equation} where the empirical root measure is known to converge in probability to the uniform probability measure on the unit circle. 
			
			%	It was shown in \cite{MR1784419} the nonzero part of the Brown measure of $up$ has radial density\footnote{Haagerup and Larson \cite{MR1784419} use a different convention of \textit{radial density}.} \begin{equation*}
				%		f_{up}(s)=\frac{2s(1-\lambda)}{(1-s^2)^2}\oindicator{\left(0,\sqrt{\lambda}\right)}(s).
				%	\end{equation*} Hence the Brown measure of $\pi(u)$ has radial density \begin{equation}
				%	g_{\pi(u)}(s)=\frac{2s(1-\lambda)}{\lambda(1-s^2)^2}\oindicator{\left(0,\sqrt{\lambda}\right)}(s).
				%\end{equation} Hence $\pi(u)$ has radial CDF \begin{equation}\label{eq:A:compressed unitary CDF}
				%F_{\pi(u)}(r)=\begin{cases}
					%	\frac{1-\lambda}{\lambda}\frac{r^2}{1-r^2},\ 0\leq r\leq \sqrt{\lambda}\\
					%	1,\ r\geq \sqrt{\lambda}
					%\end{cases}.
					%\end{equation} Let $t=1-\lambda\in(0,1)$. Feng and Yao \cite{MR3921311} established that empirical root measure of $p_n^{\lfloor(tn)\rfloor}$ converges in probability to the measure with radial CDF \begin{equation}\label{eq:A:Kac der CDF}
					%\Phi_t(r)=\begin{cases}
						%	\frac{t}{1-t}\frac{r}{1-r},\ 0\leq r\leq 1-t\\
						%	1,\ r\geq 1-t
						%\end{cases}.
						%\end{equation} It is then clear $\Phi_t$ is the push-forward of $F_{pup}$ under the map $z\mapsto z^2$. 
						
						
						
						
						
						
						
						% This includes all references from the .bib file; used for testing purposes
						%\nocite{*}
						
						\bibliography{fractional_convolution}
						\bibliographystyle{abbrv}
						
						
					\end{document}
