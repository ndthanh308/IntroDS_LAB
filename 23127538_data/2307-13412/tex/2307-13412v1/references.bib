
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries


@inproceedings{ha2016hypernetworks,
    title={{HyperNetworks}},
    author={David Ha and Andrew Dai and Quoc V. Le},
    year={2017},
    booktitle={International Conference on Learning Representations (ICLR)},
}


@InProceedings{pmlr-v80-qiu18a,
    title = 	 {{{DCFN}et: Deep Neural Network with Decomposed Convolutional Filters}},
    author = 	 {Qiu, Qiang and Cheng, Xiuyuan and robert Calderbank and Sapiro, Guillermo},
    booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning (ICML)},
    pages = 	 {4198--4207},
    year = 	 {2018},
    //editor = 	 {Dy, Jennifer and Krause, Andreas},
    //volume = 	 {80},
    //series = 	 {Proceedings of Machine Learning Research},
    //address = 	 {Stockholmsmässan, Stockholm Sweden},
    //month = 	 {10--15 Jul},
    //publisher = 	 {PMLR},
}

@inproceedings{fernandez2018binarycmd,
  title={{BinaryCmd: Keyword Spotting with deterministic binary basis}},
  author={Fern{\'a}ndez-Marqu{\'e}s, Javier and Vincent, W-S Tseng and Bhattachara, Sourav and Lane, Nicholas D},
  booktitle={Conference on Machine Learning and Systems (MLSys)},
  year={2018}
}

@inproceedings{ijcai2018-380,
    title     = {{Deterministic Binary Filters for Convolutional Neural Networks}},
    author    = {Vincent W.-S. Tseng and Sourav Bhattacharya and Javier Fernández Marqués and Milad Alizadeh and Catherine Tong and Nicholas D. Lane},
    booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence (IJCAI)},
    //publisher = {International Joint Conferences on Artificial Intelligence Organization},             
    pages     = {2739--2747},
    year      = {2018},
    //month     = {7},
    //doi       = {10.24963/ijcai.2018/380},
    //url       = {https://doi.org/10.24963/ijcai.2018/380},
}

@inproceedings{ovsf2018emdl, 
    author = {Fern\'{a}ndez-Marqu\'{e}s, Javier and Tseng, Vincent W.-S. and Bhattachara, Sourav and Lane, Nicholas D.}, 
    title = {{On-the-Fly Deterministic Binary Filters for Memory Efficient Keyword Spotting Applications on Embedded Devices}}, 
    year = {2018}, 
    //isbn = {9781450358446}, 
    publisher = {ACM}, 
    //address = {New York, NY, USA}, 
    //url = {https://doi.org/10.1145/3212725.3212731}, 
    //doi = {10.1145/3212725.3212731}, 
    booktitle = {Proceedings of the 2nd International Workshop on Embedded and Mobile Deep Learning (EMDL)}, 
    pages = {13–18}, 
    //numpages = {6}, 
    //location = {Munich, Germany}, 
    //series = {EMDL’18} 
    }

@inproceedings{Yang2020FSNet,
    title={{FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary}},
    author={Yingzhen Yang and Jiahui Yu and Nebojsa Jojic and Jun Huan and Thomas S. Huang},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2020},
    //url={https://openreview.net/forum?id=S1xtORNFwH}
}

@inproceedings{Andreev:2003:OCG:764808.764868,
    author = {Andreev, Boris D. and others},
    title = {{Orthogonal Code Generator for 3G Wireless Transceivers}},
    booktitle = {Proceedings of the 13th ACM Great Lakes Symposium on VLSI (GLSVLSI)},
    //series = {GLSVLSI '03},
    year = {2003},
    //isbn = {1-58113-677-3},
    //location = {Washington, D. C., USA},
    pages = {229--232},
    //numpages = {4},
    ////url = {http://doi.acm.org/10.1145/764808.764868},
    doi = {10.1145/764808.764868},
    //acmid = {764868},
    //publisher = {ACM},
    //address = {New York, NY, USA},
    //keywords = {3GPP, CDMA, OVSF codes, UMTS, VLSI, WCDMA},
}

@INPROCEEDINGS{1411169,
    author={T. Rintakoski and M. Kuulusa and J. Nurmi},
    booktitle={2004 International Symposium on System-on-Chip (ISSOC)},
    title={{Hardware unit for OVSF/Walsh/Hadamard code generation [3G mobile communication applications]}},
    year={2004},
    volume={},
    number={},
    pages={143-145},
    keywords={3G mobile communication;Hadamard codes;Walsh functions;binary codes;code division multiple access;logic design;spread spectrum communication;3G mobile communication systems;CDMA2000;Hadamard codes;NAND equivalent logic gates;OVSF codes;WCDMA;Walsh codes;binary orthogonal variable spreading factor codes;code index control input;hardware code generation unit;mode select control input;Bandwidth;Communication system control;Control system synthesis;Downlink;Error correction;Error correction codes;Frequency synchronization;Hardware;Multiaccess communication;Spread spectrum communication},
    ///doi={10.1109/ISSOC.2004.1411169},
    //ISSN={},
    //month={Nov},
}

@INPROCEEDINGS{5291322,
    author={S. Kim and M. Kim and C. Shin and J. Lee and Y. Kim},
    booktitle={2009 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing},
    title={{Efficient implementation of OVSF code generator for UMTS systems}},
    year={2009},
    volume={},
    number={},
    pages={483-486},
    keywords={3G mobile communication;CMOS integrated circuits;logic gates;orthogonal codes;CMOS;LUT;UMTS system;logic gates;multistage OVSF code generator;orthogonal variable spreading factor code;size 0.35 micron;3G mobile communication;Counting circuits;Hardware;Libraries;Logic gates;Multiaccess communication;Performance evaluation;Power dissipation;Power generation;Table lookup},
    ///doi={10.1109/PACRIM.2009.5291322},
    //ISSN={1555-5798},
    //month={Aug},
}

@INPROCEEDINGS{ovcf-fpga,
    author={G. Purohit and V. K. Chaubey and K. S. Raju and P. V. Reddy},
    booktitle={2013 International Conference on Advanced Electronic Systems (ICAES)},
    title={{FPGA based implementation and testing of OVSF code}},
    year={2013},
    volume={},
    number={},
    pages={88-92},
    keywords={code division multiple access;field programmable gate arrays;hardware description languages;logic analysers;orthogonal codes;program testing;FCHIP;FPGA devices;MATLAB Simulink;OVSF code;OVSF generation;TCHIP;VHDL;Virtex-5 XC5VLX50T-lff1136;WCDMA;Xilinx ChipScope Pro software tools;bandwidth requirements;delay synthesis;frequency 3.84 MHz;hardware components;logic analyser;orthogonal variable spreading factor code;software core;software testing;test equipment probes;timing analysis;Field programmable gate arrays;Generators;Logic gates;Multiaccess communication;Radiation detectors;Spread spectrum communication;Testing;FPGA;JTAG Co-Simulation;OVSF ChipScope Pro;System Generator;WCDMA},
    ///doi={10.1109/ICAES.2013.6659367},
    //ISSN={},
    //month={Sept},
}

% FPGA-based CNN processors
@INPROCEEDINGS{snowflake2017iscas,
    author={V. {Gokhale} and A. {Zaidy} and A. X. M. {Chang} and E. {Culurciello}},
    booktitle={2017 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
    title={{Snowflake: An Efficient Hardware Accelerator for Convolutional Neural Networks}}, 
    year={2017},
    volume={},
    number={},
    pages={1-4},
}

@article{snowflake2017compiling,
    title={{Compiling Deep Learning Models for Custom Hardware Accelerators}}, 
    author={Andre Xian Ming Chang and Aliasger Zaidy and Vinayak Gokhale and Eugenio Culurciello},
    journal={arXiv preprint arXiv:1708.00117},
    year={2017}
}

@inproceedings{lightopu2020fpga,
    author = {Yu, Yunxuan and Zhao, Tiandong and Wang, Kun and He, Lei},
    title = {{Light-OPU: An FPGA-Based Overlay Processor for Lightweight Convolutional Neural Networks}},
    year = {2020},
    //isbn = {9781450370998},
    //publisher = {Association for Computing //Machinery},
    //address = {New York, NY, USA},
    //url = {https://doi.org/10.1145/3373087.3375311},
    //doi = {10.1145/3373087.3375311},
    booktitle = {The 2020 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA)},
    pages = {122–132},
    //numpages = {11},
    //keywords = {processor, fpga acceleration, lightweight cnn, compiler},
    //location = {Seaside, CA, USA},
    //series = {FPGA ’20}
}

@ARTICLE{uniopu2020tvlsi,
    author={Y. {Yu} and T. {Zhao} and M. {Wang} and K. {Wang} and L. {He}},
    journal={IEEE Transactions on Very Large Scale Integration Systems (TVLSI)}, 
    title={{Uni-OPU: An FPGA-Based Uniform Accelerator for Convolutional and Transposed Convolutional Networks}}, 
    year={2020},
    volume={28},
    number={7},
    pages={1545-1556},
}

% FPGA-based streaming architectures
@INPROCEEDINGS{streaming2016fpl,
    author={ {Huimin Li} and  {Xitian Fan} and  {Li Jiao} and  {Wei Cao} and  {Xuegong Zhou} and  {Lingli Wang}},
    booktitle={2016 26th International Conference on Field Programmable Logic and Applications (FPL)}, 
    title={{A High Performance FPGA-based Accelerator for Large-Scale Convolutional Neural Networks}}, 
    year={2016},
    volume={},
    number={},
    pages={1-9},
}

@inproceedings{finn2017fpga,
    author = {Umuroglu, Yaman and Fraser, Nicholas J. and Gambardella, Giulio and Blott, Michaela and Leong, Philip and Jahre, Magnus and Vissers, Kees},
    title = {{FINN: A Framework for Fast, Scalable Binarized Neural Network Inference}},
    year = {2017},
    //isbn = {9781450343541},
    //publisher = {Association for Computing Machinery},
    //address = {New York, NY, USA},
    //url = {https://doi.org/10.1145/3020078.3021744},
    //doi = {10.1145/3020078.3021744},
    booktitle = {Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA)},
    pages = {65–74},
    //numpages = {10},
    //keywords = {FPGA, binarized neural network, neural networks, binary neural network, reconfigurable logic, hardware acceleration},
    //location = {Monterey, California, USA},
    //series = {FPGA ’17}
}

@article{ternaryfpga2018trets,
    author = {Prost-Boucle, Adrien and Bourge, Alban and P\'{e}trot, Fr\'{e}d\'{e}ric},
    title = {{High-Efficiency Convolutional Ternary Neural Networks with Custom Adder Trees and Weight Compression}},
    year = {2018},
    //issue_date = {December 2018},
    //publisher = {Association for Computing Machinery},
    //address = {New York, NY, USA},
    volume = {11},
    number = {3},
    //issn = {1936-7406},
    //url = {https://doi.org/10.1145/3270764},
    //doi = {10.1145/3270764},
    journal = {ACM Trans. Reconfigurable Technol. Syst. (TRETS)},
    //month = dec,
    articleno = {15},
    numpages = {24},
    //keywords = {Ternary CNN, low power inference, FPGA, hardware acceleration}
}

@article{finnr2018trets,
    author = {Blott, Michaela and Preu\ss{}er, Thomas B. and Fraser, Nicholas J. and Gambardella, Giulio and O’brien, Kenneth and Umuroglu, Yaman and Leeser, Miriam and Vissers, Kees},
    title = {{FINN-R: An End-to-End Deep-Learning Framework for Fast Exploration of Quantized Neural Networks}},
    year = {2018},
    //issue_date = {December 2018},
    //publisher = {Association for Computing Machinery},
    //address = {New York, NY, USA},
    volume = {11},
    number = {3},
    //issn = {1936-7406},
    //url = {https://doi.org/10.1145/3242897},
    //doi = {10.1145/3242897},
    journal = {ACM Trans. Reconfigurable Technol. Syst. (TRETS)},
    //month = dec,
    articleno = {16},
    numpages = {23},
    //keywords = {hardware accellerator, artificial intelligence, FPGA, convolutional neural networks, inference, Neural network, quantized neural networks, FINN}
}

@INPROCEEDINGS{multiprec2019fpt,
    author={Y. {Zhao} and X. {Gao} and X. {Guo} and J. {Liu} and E. {Wang} and R. {Mullins} and P. Y. K. {Cheung} and G. {Constantinides} and C. {Xu}},
    booktitle={2019 International Conference on Field-Programmable Technology (ICFPT)}, 
    title={{Automatic Generation of Multi-Precision Multi-Arithmetic CNN Accelerators for FPGAs}}, 
    year={2019},
    volume={},
    number={},
    pages={45-53},
}
  
@ARTICLE{fpgaconvnet2019tnnls,
    author={S. I. {Venieris} and C. {Bouganis}},
    journal={IEEE Transactions on Neural Networks and Learning Systems (TNNLS)}, 
    title={{fpgaConvNet: Mapping Regular and Irregular Convolutional Neural Networks on FPGAs}}, 
    year={2019},
    volume={30},
    number={2},
    pages={326-342},
}

@ARTICLE{lutnet2020toc,
    author={E. {Wang} and J. J. {Davis} and P. Y. K. {Cheung} and G. {Constantinides}},
    journal={IEEE Transactions on Computers (TOC)}, 
    title={{LUTNet: Learning FPGA Configurations for Highly Efficient Neural Network Inference}}, 
    year={2020},
    volume={},
    number={},
    //pages={1-1},
}

% FPGA-based CNN single computation engines
@inproceedings{cnnroofline2015fpga,
    author = {Zhang, Chen and Li, Peng and Sun, Guangyu and Guan, Yijin and Xiao, Bingjun and Cong, Jason},
    title = {{Optimizing FPGA-Based Accelerator Design for Deep Convolutional Neural Networks}},
    year = {2015},
    isbn = {9781450333153},
    //publisher = {Association for Computing Machinery},
    //address = {New York, NY, USA},
    //url = {https://doi.org/10.1145/2684746.2689060},
    //doi = {10.1145/2684746.2689060},
    booktitle = {Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA)},
    pages = {161–170},
    numpages = {10},
    //keywords = {fpga, acceleration, roofline model, convolutional neural network},
    //location = {Monterey, California, USA},
    //series = {FPGA ’15}
}

@INPROCEEDINGS{fpdnn2017fccm,
    author={Y. {Guan} and H. {Liang} and N. {Xu} and W. {Wang} and S. {Shi} and X. {Chen} and G. {Sun} and W. {Zhang} and J. {Cong}},
    booktitle={2017 IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)}, 
    title={{FP-DNN: An Automated Framework for Mapping Deep Neural Networks onto FPGAs with RTL-HLS Hybrid Templates}}, 
    year={2017},
    volume={},
    number={},
    pages={152-159},
}

@INPROCEEDINGS{latency2017fpl,
    author={S. I. {Venieris} and C. {Bouganis}},
    booktitle={2017 27th International Conference on Field Programmable Logic and Applications (FPL)}, 
    title={{Latency-Driven Design for FPGA-based Convolutional Neural Networks}}, 
    year={2017},
    volume={},
    number={},
    pages={1-8},
}

@inproceedings{opencldla2017fpga,
    author = {Aydonat, Utku and O’Connell, Shane and Capalija, Davor and Ling, Andrew C. and Chiu, Gordon R.},
    title = {{An OpenCL™ Deep Learning Accelerator on Arria 10}},
    year = {2017},
    //isbn = {9781450343541},
    //publisher = {Association for Computing Machinery},
    //address = {New York, NY, USA},
    //url = {https://doi.org/10.1145/3020078.3021738},
    //doi = {10.1145/3020078.3021738},
    booktitle = {Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA)},
    pages = {55–64},
    //numpages = {10},
    //keywords = {convolutional neural networks, deep neural networks},
    //location = {Monterey, California, USA},
    //series = {FPGA ’17}
}


@INPROCEEDINGS{dla2018fpl,  
    author={M. S. {Abdelfattah} and D. {Han} and A. {Bitar} and R. {DiCecco} and S. {O'Connell} and N. {Shanker} and J. {Chu} and I. {Prins} and J. {Fender} and A. C. {Ling} and G. R. {Chiu}},  
    booktitle={2018 28th International Conference on Field Programmable Logic and Applications (FPL)},   
    title={{DLA: Compiler and FPGA Overlay for Neural Network Inference Acceleration}},   
    year={2018},  
    volume={},  
    number={},  
    pages={411-4117},
}
  
@INPROCEEDINGS{cascadecnn2018fpl,
    author={A. {Kouris} and S. I. {Venieris} and C. {Bouganis}},
    booktitle={2018 28th International Conference on Field Programmable Logic and Applications (FPL)}, 
    title={{CascadeCNN: Pushing the Performance Limits of Quantisation in Convolutional Neural Networks}}, 
    year={2018},
    volume={},
    number={},
    pages={155-1557},
}

@INPROCEEDINGS{brainwave2018isca,
    author={J. {Fowers} and K. {Ovtcharov} and M. {Papamichael} and T. {Massengill} and M. {Liu} and D. {Lo} and S. {Alkalay} and M. {Haselman} and L. {Adams} and M. {Ghandi} and S. {Heil} and P. {Patel} and A. {Sapek} and G. {Weisz} and L. {Woods} and S. {Lanka} and S. K. {Reinhardt} and A. M. {Caulfield} and E. S. {Chung} and D. {Burger}},
    booktitle={2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)}, 
    title={{A Configurable Cloud-Scale DNN Processor for Real-Time AI}}, 
    year={2018},
    volume={},
    number={},
    pages={1-14},
}

@ARTICLE{angeleye2018tcad, 
	author={K. {Guo} and L. {Sui} and J. {Qiu} and J. {Yu} and J. {Wang} and S. {Yao} and S. {Han} and Y. {Wang} and H. {Yang}}, 
	journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)}, 
	title={{Angel-Eye: A Complete Design Flow for Mapping CNN Onto Embedded FPGA}}, 
	year={2018}, 
	volume={37}, 
	number={1}, 
	pages={35-47}, 
	//ISSN={0278-0070}, 
	//month={Jan},
}

@ARTICLE{caffeine2019tcad,
    author={C. {Zhang} and G. {Sun} and Z. {Fang} and P. {Zhou} and P. {Pan} and J. {Cong}},
    journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)}, 
    title={{Caffeine: Toward Uniformed Representation and Acceleration for Deep Convolutional Neural Networks}}, 
    year={2019},
    volume={38},
    number={11},
    pages={2072-2085},
}

@misc{xdnn2020xilinx,
 author = {Xilinx},
 title = {{Adaptive Machine Learning Acceleration}},
 howpublished = {\url{https://www.xilinx.com/products/acceleration-solutions/xilinx-machine-learning-suite.html}},
 note = {{[Retrieved: \today]}},
 year = {2020}
}

@ARTICLE{dnnvm2019tcad,
    author={Y. {Xing} and S. {Liang} and L. {Sui} and X. {Jia} and J. {Qiu} and X. {Liu} and Y. {Wang} and Y. {Shan} and Y. {Wang}},
    journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)}, 
    title={{DNNVM: End-to-End Compiler Leveraging Heterogeneous Optimizations on FPGA-based CNN Accelerators}}, 
    year={2019},
    volume={},
    number={},
}

@ARTICLE{winofft2020tcad,
    author={Y. {Liang} and L. {Lu} and Q. {Xiao} and S. {Yan}},
    journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)}, 
    title={{Evaluating Fast Algorithms for Convolutional Neural Networks on FPGAs}}, 
    year={2020},
    volume={39},
    number={4},
    pages={857-870},
}

@INPROCEEDINGS{ftdl2020dac,
  author={R. {Shi} and Y. {Ding} and X. {Wei} and H. {Li} and H. {Liu} and H. K. . -H. {So} and C. {Ding}},
  booktitle={57th ACM/IEEE Design Automation Conference (DAC)}, 
  title={{FTDL: A Tailored FPGA-Overlay for Deep Learning with High Scalability}}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
}

@inproceedings{fft2020fpga,
    author = {Niu, Yue and Kannan, Rajgopal and Srivastava, Ajitesh and Prasanna, Viktor},
    title = {{Reuse Kernels or Activations? A Flexible Dataflow for Low-Latency Spectral CNN Acceleration}},
    year = {2020},
    //isbn = {9781450370998},
    //publisher = {Association for Computing Machinery},
    //address = {New York, NY, USA},
    //url = {https://doi.org/10.1145/3373087.3375302},
    //doi = {10.1145/3373087.3375302},
    booktitle = {The 2020 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA)},
    pages = {266–276},
    //numpages = {11},
    //keywords = {accelerator, flexible dataflow, spectral cnns, sparse operation},
    location = {Seaside, CA, USA},
    //series = {FPGA ’20}
}

@INPROCEEDINGS{residaccel2017iscas,
  author={Y. {Ma} and M. {Kim} and Y. {Cao} and S. {Vrudhula} and J. {Seo}},
  booktitle={IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={{End-to-End Scalable FPGA Accelerator for Deep Residual Networks}}, 
  year={2017},
  volume={},
  number={},
  pages={1-4},
}

@ARTICLE{alamo2020tcad,
    author={Y. {Ma} and Y. {Cao} and S. {Vrudhula} and J. {Seo}},
    journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)}, 
    title={{Automatic Compilation of Diverse CNNs Onto High-Performance FPGA Accelerators}}, 
    year={2020},
    volume={39},
    number={2},
    pages={424-437},
}

@INPROCEEDINGS{cascadecnn2020date,
  author={A. {Kouris} and S. I. {Venieris} and C. {Bouganis}},
  booktitle={2020 Design, Automation   Test in Europe Conference   Exhibition (DATE)}, 
  title={{A Throughput-Latency Co-Optimised Cascade of Convolutional Neural Network Classifiers}}, 
  year={2020},
  volume={},
  number={},
  pages={1656-1661},
}

@INPROCEEDINGS{abdelfattah2020best,
    title={{Best of Both Worlds: AutoML Codesign of a CNN and its Hardware Accelerator}},
    author={Abdelfattah, Mohamed S and Dudziak, {\L}ukasz and Chau, Thomas and Lee, Royson and Kim, Hyeji and Lane, Nicholas D},
    booktitle={Design Automation Conference (DAC)},
    year={2020}
}

% FPGA-based CNN streaming vs single computation engines
@article{cnnfpgatoolflows2018csur,
    author = {Venieris, Stylianos I. and Kouris, Alexandros and Bouganis, Christos-Savvas},
    title = {{Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey and Future Directions}},
    year = {2018},
    //issue_date = {July 2018},
    //publisher = {Association for Computing Machinery},
    //address = {New York, NY, USA},
    volume = {51},
    number = {3},
    //issn = {0360-0300},
    //url = {https://doi.org/10.1145/3186332},
    //doi = {10.1145/3186332},
    journal = {ACM Comput. Surv. (CSUR)},
    //month = jun,
    articleno = {56},
    numpages = {39},
    //keywords = {FPGA toolflows, deep learning, Convolutional neural networks}
}

% Sparse CNN accelerators
@INPROCEEDINGS{sparsecnnaccel2019fccm,
  author={L. {Lu} and J. {Xie} and R. {Huang} and J. {Zhang} and W. {Lin} and Y. {Liang}},
  booktitle={IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)}, 
  title={{An Efficient Hardware Accelerator for Sparse Convolutional Neural Networks on FPGAs}}, 
  year={2019},
  volume={},
  number={},
  pages={17-25},
}

@inproceedings{DBLP:journals/corr/HeZRS15,
    author = {He, K and Zhang, X and Ren, S and Sun, J},
    booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {770--778},
    title = {{Deep Residual Learning for Image Recognition}},
    year = {2016}
}

@inproceedings{kingma2014adam,
  title={{Adam: A Method for Stochastic Optimization}},
  author={Diederik P. Kingma and Jimmy Ba},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@incollection{NIPS2019_9015,
    title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
    author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    pages = {8026--8037},
    year = {2019},
}

@inproceedings{Molchanov_2019,
   title={{Importance Estimation for Neural Network Pruning}},
   //ISBN={9781728132938},
   //url={http://dx.doi.org/10.1109/CVPR.2019.01152},
   //DOI={10.1109/cvpr.2019.01152},
   booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   author={Molchanov, Pavlo and Mallya, Arun and Tyree, Stephen and Frosio, Iuri and Kautz, Jan},
   year={2019},
}


@article{He2017ChannelPF,
  title={{Channel Pruning for Accelerating Very Deep Neural Networks}},
  author={Yihui He and Xiangyu Zhang and Jian Sun},
  journal={2017 IEEE International Conference on Computer Vision (ICCV)},
  year={2017},
  pages={1398-1406}
}

@article{Gordon2018MorphNetF,
  title={{MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks}},
  author={Ariel Gordon and Elad Eban and Ofir Nachum and Bo Chen and Tien-Ju Yang and Edward Choi},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018},
  pages={1586-1595}
}

@article{Yu2018NISPPN,
  title={{NISP: Pruning Networks Using Neuron Importance Score Propagation}},
  author={Ruichi Yu and Ang Li and Chun-Fu Chen and Jui-Hsin Lai and Vlad I. Morariu and Xintong Han and Mingfei Gao and Ching-Yung Lin and Larry S. Davis},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018},
  pages={9194-9203}
}

@INPROCEEDINGS{flexflow2017hpca,
    author={W. {Lu} and G. {Yan} and J. {Li} and S. {Gong} and Y. {Han} and X. {Li}},
    booktitle={2017 IEEE International Symposium on High Performance Computer Architecture (HPCA)}, 
    title={{FlexFlow: A Flexible Dataflow Accelerator Architecture for Convolutional Neural Networks}}, 
    year={2017},
    volume={},
    number={},
    pages={553-564},
}

@inproceedings{maeri2018asplos,
    author = {Kwon, Hyoukjun and Samajdar, Ananda and Krishna, Tushar},
    title = {{MAERI: Enabling Flexible Dataflow Mapping over DNN Accelerators via Reconfigurable Interconnects}},
    year = {2018},
    //isbn = {9781450349116},
    //publisher = {Association for Computing Machinery},
    //address = {New York, NY, USA},
    //url = {https://doi.org/10.1145/3173162.3173176},
    //doi = {10.1145/3173162.3173176},
    booktitle = {Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)},
    pages = {461–475},
    //numpages = {15},
    //keywords = {convolutional neural network, network-on-chip, deep learning accelerator, recurrent neural network, machine learning, spatial architecture},
    //location = {Williamsburg, VA, USA},
    //series = {ASPLOS ’18}
}

@article{iandola2016squeezenet,
    title={{SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and $<$ 0.5 MB model size}},
    author={Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
    journal={arXiv preprint arXiv:1602.07360},
    year={2016}
}

@ARTICLE{deeplab2018tpami,
    author={L. {Chen} and G. {Papandreou} and I. {Kokkinos} and K. {Murphy} and A. L. {Yuille}},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}, 
    title={{DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs}}, 
    year={2018},
    volume={40},
    number={4},
    pages={834-848},
}

@ARTICLE{fasterrcnn2017tpami,
    author={S. {Ren} and K. {He} and R. {Girshick} and J. {Sun}},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={{Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}}, 
    year={2017},
    volume={39},
    number={6},
    pages={1137-1149},
}

@INPROCEEDINGS{detector2019iros,
  author={A. {Kouris} and C. {Kyrkou} and C. {Bouganis}},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={{Informed Region Selection for Efficient UAV-based Object Detectors: Altitude-aware Vehicle Detection with CyCAR Dataset}}, 
  year={2019},
  volume={},
  number={},
  pages={51-58},
}

@inproceedings{mobisr2019mobicom,
    author = {Lee, Royson and Venieris, Stylianos I. and Dudziak, Lukasz and Bhattacharya, Sourav and Lane, Nicholas D.},
    title = {{MobiSR: Efficient On-Device Super-Resolution through Heterogeneous Mobile Processors}},
    year = {2019},
    //isbn = {9781450361699},
    //publisher = {Association for Computing Machinery},
    //address = {New York, NY, USA},
    //url = {https://doi.org/10.1145/3300061.3345455},
    //doi = {10.1145/3300061.3345455},
    booktitle = {The 25th Annual International Conference on Mobile Computing and Networking (MobiCom)}
}

% FPGA platforms and bandwidth
@INPROCEEDINGS{lostbw2019fpt,
    author={G. {Csordas} and M. {Asiatici} and P. {Ienne}},
    booktitle={2019 International Conference on Field-Programmable Technology (ICFPT)}, 
    title={{In Search of Lost Bandwidth: Extensive Reordering of DRAM Accesses on FPGA}}, 
    year={2019},
    volume={},
    number={},
    pages={188-196},
}

@INPROCEEDINGS{divrsemem2019fpt,
    author={K. {Manev} and A. {Vaishnav} and D. {Koch}},
    booktitle={2019 International Conference on Field-Programmable Technology (ICFPT)}, 
    title={{Unexpected Diversity: Quantitative Memory Analysis for Zynq UltraScale+ Systems}}, 
    year={2019},
    volume={},
    number={},
    pages={179-187},
}

% multi-CNN FPGA accelerators
@INPROCEEDINGS{venieris2018fpl, 
    author={S. I. Venieris and C. S. Bouganis}, 
    booktitle={2018 28th International Conference on Field Programmable Logic and Applications (FPL)}, 
    title={{f-CNN$^\text{x}$: A Toolflow for Mapping Multiple Convolutional Neural Networks on FPGAs}}, 
    year={2018}, 
    volume={}, 
    number={}, 
    pages={1-8}, 
}

% New refs
@INPROCEEDINGS{eie2016isca,
    author={S. {Han} and X. {Liu} and H. {Mao} and J. {Pu} and A. {Pedram} and M. A. {Horowitz} and W. J. {Dally}},
    booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
    title={{EIE: Efficient Inference Engine on Compressed Deep Neural Network}}, 
    year={2016},
    volume={},
    number={},
    pages={243-254},
}

@inproceedings{deepcompression2015iclr,
    title={{Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding}},
    author={Han, Song and Mao, Huizi and Dally, William J},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2015}
}

@ARTICLE{eyeriss2017jssc,
    author={Y. {Chen} and T. {Krishna} and J. S. {Emer} and V. {Sze}},
    journal={IEEE Journal of Solid-State Circuits (JSSC)}, 
    title={{Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks}}, 
    year={2017},
    volume={52},
    number={1},
    pages={127-138},
}

@ARTICLE{eyerissv22019jetcas,
    author={Y. {Chen} and T. {Yang} and J. {Emer} and V. {Sze}},
    journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems (JETCAS)}, 
    title={{Eyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices}}, 
    year={2019},
    volume={9},
    number={2},
    pages={292-308},
}

@INPROCEEDINGS{cambriconx2016micro,
    author={S. {Zhang} and Z. {Du} and L. {Zhang} and H. {Lan} and S. {Liu} and L. {Li} and Q. {Guo} and T. {Chen} and Y. {Chen}},
    booktitle={2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)}, 
    title={{Cambricon-X: An Accelerator for Sparse Neural Networks}}, 
    year={2016},
    volume={},
    number={},
    pages={1-12},
}

@INPROCEEDINGS{cambircons2018micro,
    author={X. {Zhou} and Z. {Du} and Q. {Guo} and S. {Liu} and C. {Liu} and C. {Wang} and X. {Zhou} and L. {Li} and T. {Chen} and Y. {Chen}},
    booktitle={2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)}, 
    title={{Cambricon-S: Addressing Irregularity in Sparse Neural Networks through A Cooperative Software/Hardware Approach}}, 
    year={2018},
    volume={},
    number={},
    pages={15-28},
}

@inproceedings{scalpel2017isca,
    author = {Yu, Jiecao and Lukefahr, Andrew and Palframan, David and Dasika, Ganesh and Das, Reetuparna and Mahlke, Scott},
    title = {Scalpel: Customizing DNN Pruning to the Underlying Hardware Parallelism},
    year = {2017},
    booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture (ISCA)},
    pages = {548–560},
}

@INPROCEEDINGS{fusedlayer2016micro,
    author={M. {Alwani} and H. {Chen} and M. {Ferdman} and P. {Milder}},
    booktitle={2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)}, 
    title={Fused-layer CNN accelerators}, 
    year={2016},
    volume={},
    number={},
    pages={1-12},
}

@INPROCEEDINGS{circcnn2017micro,
  author={C. {Ding} and S. {Liao} and Y. {Wang} and Z. {Li} and N. {Liu} and Y. {Zhuo} and C. {Wang} and X. {Qian} and Y. {Bai} and G. {Yuan} and X. {Ma} and Y. {Zhang} and J. {Tang} and Q. {Qiu} and X. {Lin} and B. {Yuan}},
  booktitle={2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)}, 
  title={{CirCNN: Accelerating and Compressing Deep Neural Networks Using Block-Circulant Weight Matrices}}, 
  pages={395-408},
  year={2017}
}

@inproceedings{permdnn2018micro,
    author = {Deng, Chunhua and Liao, Siyu and Xie, Yi and Parhi, Keshab K. and Qian, Xuehai and Yuan, Bo},
    title = {{PermDNN: Efficient Compressed DNN Architecture with Permuted Diagonal Matrices}},
    year = {2018},
    booktitle = {Proceedings of the 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
    pages = {189–202},
}

@INPROCEEDINGS{escher2017fccm,
  author={Y. {Shen} and M. {Ferdman} and P. {Milder}},
  booktitle={2017 IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)}, 
  title={{Escher: A CNN Accelerator with Flexible Buffering to Minimize Off-Chip Transfer}}, 
  year={2017},
  pages={93-100},
}

@inproceedings{maximising2017isca,
    author = {Shen, Yongming and Ferdman, Michael and Milder, Peter},
    title = {{Maximizing CNN Accelerator Efficiency Through Resource Partitioning}},
    year = {2017},
    booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture (ISCA)},
    //pages = {535–547},
}

@INPROCEEDINGS{logicnets2020fpl,
    author={Y. {Umuroglu} and Y. {Akhauri} and N. J. {Fraser} and M. {Blott}},
    booktitle={2020 30th International Conference on Field-Programmable Logic and Applications (FPL)}, 
    title={{LogicNets: Co-Designed Neural Networks and Circuits for Extreme-Throughput Applications}}, 
    year={2020},
    volume={},
    number={},
    pages={291-297},
    doi={10.1109/FPL50879.2020.00055}
}
  
@inproceedings{sparten2019micro,
    title={{SparTen: A Sparse Tensor Accelerator for Convolutional Neural Networks}},
    author={Gondimalla, Ashish and Chesnut, Noah and Thottethodi, Mithuna and Vijaykumar, TN},
    booktitle={Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
    pages={151--165},
    year={2019}
}

@INPROCEEDINGS{scnn2017isca,
  author={A. {Parashar} and M. {Rhu} and A. {Mukkara} and A. {Puglielli} and R. {Venkatesan} and B. {Khailany} and J. {Emer} and S. W. {Keckler} and W. J. {Dally}},
  booktitle={2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)}, 
  title={{SCNN: An Accelerator for Compressed-Sparse Convolutional Neural Networks}}, 
  year={2017},
  pages={27-40},
}

@inproceedings{pragmatic2017micro,
    title={{Bit-Pragmatic Deep Neural Network Computing}},
    author={Albericio, Jorge and Delm{\'a}s, Alberto and Judd, Patrick and Sharify, Sayeh and O'Leary, Gerard and Genov, Roman and Moshovos, Andreas},
    booktitle={Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
    pages={382--394},
    year={2017}
}

@inproceedings{shapeshifter2019micro,
    author = {Lascorz, Alberto Delm\'{a}s and Sharify, Sayeh and Edo, Isak and Stuart, Dylan Malone and Awad, Omar Mohamed and Judd, Patrick and Mahmoud, Mostafa and Nikolic, Milos and Siu, Kevin and Poulos, Zissis and Moshovos, Andreas},
    title = {{ShapeShifter: Enabling Fine-Grain Data Width Adaptation in Deep Learning}},
    year = {2019},
    booktitle = {Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
    pages = {28–41},
}

@inproceedings{cnvlutin2016isca,
    title={{Cnvlutin: Ineffectual-Neuron-Free Deep Neural Network Computing}},
    author={Albericio, Jorge and Judd, Patrick and Hetherington, Tayler and Aamodt, Tor and Jerger, Natalie Enright and Moshovos, Andreas},
    booktitle={Proceedings of the 43rd International Symposium on Computer Architecture (ISCA)},
    pages={1--13},
    year={2016}
}

@INPROCEEDINGS{mem_req2918iiswc,
    author={K. {Siu} and D. M. {Stuart} and M. {Mahmoud} and A. {Moshovos}},
    booktitle={2018 IEEE International Symposium on Workload Characterization (IISWC)}, 
    title={{Memory Requirements for Convolutional Neural Network Hardware Accelerators}}, 
    year={2018},
    volume={},
    number={},
    pages={111-121},
}

@INPROCEEDINGS{gamma2020iccad,
    author={S. -C. {Kao} and T. {Krishna}},
    booktitle={2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD)}, 
    title={{GAMMA: Automating the HW Mapping of DNN Models on Accelerators via Genetic Algorithm}}, 
    year={2020},
    volume={},
    number={},
    pages={1-9},
    doi={}
}

@INPROCEEDINGS{shidiannao2915isca,
    author={Z. {Du} and R. {Fasthuber} and T. {Chen} and P. {Ienne} and L. {Li} and T. {Luo} and X. {Feng} and Y. {Chen} and O. {Temam}},
    booktitle={2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)}, 
    title={{ShiDianNao: Shifting Vision Processing Closer to the Sensor}}, 
    year={2015},
    volume={},
    number={},
    pages={92-104},
}
  
@inproceedings{interstellar2020asplos,
    author = {Yang, Xuan and Gao, Mingyu and Liu, Qiaoyi and Setter, Jeff and Pu, Jing and Nayak, Ankita and Bell, Steven and Cao, Kaidi and Ha, Heonjae and Raina, Priyanka and Kozyrakis, Christos and Horowitz, Mark},
    title = {{Interstellar: Using Halide's Scheduling Language to Analyze DNN Accelerators}},
    year = {2020},
    booktitle = {Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)},
    pages = {369–383},
}

@INPROCEEDINGS{dnnweaver2016micro,
    author={H. {Sharma} and J. {Park} and D. {Mahajan} and E. {Amaro} and J. K. {Kim} and C. {Shao} and A. {Mishra} and H. {Esmaeilzadeh}},
    booktitle={2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)}, 
    title={{From High-Level Deep Neural Models to FPGAs}}, 
    year={2016},
    volume={},
    number={},
    pages={1-12},
}

@ARTICLE{recpatterns2017tvlsi,
  author={F. {Tu} and S. {Yin} and P. {Ouyang} and S. {Tang} and L. {Liu} and S. {Wei}},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems (TVLSI)}, 
  title={{Deep Convolutional Neural Network Architecture With Reconfigurable Computation Patterns}}, 
  year={2017},
  volume={25},
  number={8},
  pages={2220-2233},
}

@inproceedings{luo2017thinet,
      title={{ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression}}, 
      author={Jian-Hao Luo and Jianxin Wu and Weiyao Lin},
      year={2017},
      booktitle={IEEE International Conference on Computer Vision (ICCV)},
}

@inproceedings{blalock2020state,
      title={{What is the State of Neural Network Pruning?}}, 
      author={Davis Blalock and Jose Javier Gonzalez Ortiz and Jonathan Frankle and John Guttag},
      year={2020},
      booktitle={Conference on Machine Learning and Systems (MLSys)},
}

@inproceedings{he2018soft,
      title={{Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks}}, 
      author={Yang He and Guoliang Kang and Xuanyi Dong and Yanwei Fu and Yi Yang},
      year={2018},
      booktitle={International Joint Conference on Artificial Intelligence (IJCAI)},
}

@misc{krishnamoorthi2018quantizing,
      title={{Quantizing Deep Convolutional Networks for Efficient Inference: A Whitepaper}}, 
      author={Raghuraman Krishnamoorthi},
      year={2018},
      eprint={1806.08342},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{jacob2018quantization,
      title={{Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference}}, 
      author={Benoit Jacob and Skirmantas Kligys and Bo Chen and Menglong Zhu and Matthew Tang and Andrew Howard and Hartwig Adam and Dmitry Kalenichenko},
      year={2018},
      booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
}

@inproceedings{wen2016learning,
      title={{Learning Structured Sparsity in Deep Neural Networks}}, 
      author={Wei Wen and Chunpeng Wu and Yandan Wang and Yiran Chen and Hai Li},
      year={2016},
      booktitle={Proceedings of the 30th International Conference on Neural Information Processing Systems (NeurIPS)}
}

@inproceedings{wang2020apq,
      title={{APQ: Joint Search for Network Architecture, Pruning and Quantization Policy}}, 
      author={Tianzhe Wang and Kuan Wang and Han Cai and Ji Lin and Zhijian Liu and Song Han},
      year={2020},
      booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
}

@inproceedings{gale2020sparse,
      title={{Sparse GPU Kernels for Deep Learning}}, 
      author={Trevor Gale and Matei Zaharia and Cliff Young and Erich Elsen},
      year={2020},
      booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
}

@inproceedings{dong2019hawq,
      title={{HAWQ: Hessian AWare Quantization of Neural Networks with Mixed-Precision}}, 
      author={Zhen Dong and Zhewei Yao and Amir Gholami and Michael Mahoney and Kurt Keutzer},
      year={2019},
      booktitle={IEEE International Conference on Computer Vision (ICCV)}
}

@InProceedings{pmlr-v70-wang17m, 
    title = {{Beyond Filters: Compact Feature Map for Portable Deep Model}}, 
    author = {Yunhe Wang and Chang Xu and Chao Xu and Dacheng Tao}, 
    booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML)}, 
    pages = {3703--3711}, 
    year = {2017}, 
}

@inproceedings{sparsify2016sensys,
    author = {Bhattacharya, Sourav and Lane, Nicholas D.},
    title = {{Sparsification and Separation of Deep Learning Layers for Constrained Resource Inference on Wearables}},
    year = {2016},
    publisher = {ACM},
    booktitle = {Proceedings of the 14th ACM Conference on Embedded Network Sensor Systems (SenSys)},
    pages = {176–189},
    numpages = {14},
}

@INPROCEEDINGS{tensaurus2020hpca,
    author={N. {Srivastava} and H. {Jin} and S. {Smith} and H. {Rong} and D. {Albonesi} and Z. {Zhang}},
    booktitle={{2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)}}, 
    title={{Tensaurus: A Versatile Accelerator for Mixed Sparse-Dense Tensor Computations}}, 
    year={2020},
    volume={},
    number={},
    pages={689-702},
}

@inproceedings{extensor2019micro,
    author = {Hegde, Kartik and Asghari-Moghaddam, Hadi and Pellauer, Michael and Crago, Neal and Jaleel, Aamer and Solomonik, Edgar and Emer, Joel and Fletcher, Christopher W.},
    title = {ExTensor: An Accelerator for Sparse Tensor Algebra},
    year = {2019},
    booktitle = {Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
    pages = {319–333},
}

@inproceedings{codesignmultiple2020dac,
author = {Yang, Lei and Yan, Zheyu and Li, Meng and Kwon, Hyoukjun and Jiang, Weiwen and Lai, Liangzhen and Shi, Yiyu and Krishna, Tushar and Chandra, Vikas},
title = {{Co-Exploration of Neural Architectures and Heterogeneous ASIC Accelerator Designs Targeting Multiple Tasks}},
year = {2020},
booktitle = {Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference (DAC)},
}

@INPROCEEDINGS{multinn2020isca,
    author={E. {Baek} and D. {Kwon} and J. {Kim}},
    booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)}, 
    title={{A Multi-Neural Network Acceleration Architecture}}, 
    year={2020},
    volume={},
    number={},
    pages={940-953},
}

@inproceedings{fernandezmarques2020searching,
      title={{Searching for Winograd-aware Quantized Networks}}, 
      author={Javier Fernandez-Marques and Paul N. Whatmough and Andrew Mundy and Matthew Mattina},
      year={2020},
      booktitle={Conference on Machine Learning and Systems (MLSys)},
}

@inproceedings{alizadeh2018a,
    title={{A Systematic Study of Binary Neural Networks' Optimisation}},
    author={Milad Alizadeh and Javier Fernández-Marqués and Nicholas D. Lane and Yarin Gal},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2019},
}

@inproceedings{def2021aspdac,
    author = {Montgomerie-Corcoran, Alexander and Savvas-Bouganis, Christos},
    title = {{DEF: Differential Encoding of Featuremaps for Low Power Convolutional Neural Network Accelerators}},
    year = {2021},
    booktitle = {Proceedings of the 26th Asia and South Pacific Design Automation Conference (ASP-DAC},
}
@inproceedings{clouddnn2019fpga,
    author = {Chen, Yao and He, Jiong and Zhang, Xiaofan and Hao, Cong and Chen, Deming},
    title = {{Cloud-DNN: An Open Framework for Mapping DNN Models to Cloud FPGAs}},
    year = {2019},
    booktitle = {Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA)},
}

@INPROCEEDINGS{scaling_the_cascades2019fpl,
  author={Samajdar, Ananda and Garg, Tushar and Krishna, Tushar and Kapre, Nachiket},
  booktitle={2019 29th International Conference on Field Programmable Logic and Applications (FPL)}, 
  title={{Scaling the Cascades: Interconnect-Aware FPGA Implementation of Machine Learning Problems}}, 
  year={2019},
}

@ARTICLE{fullstack2021tnnls,
  author={Liu, Shuanglong and Fan, Hongxiang and Ferianc, Martin and Niu, Xinyu and Shi, Huifeng and Luk, Wayne},
  journal={IEEE Transactions on Neural Networks and Learning Systems (TNNLS)}, 
  title={{Toward Full-Stack Acceleration of Deep Convolutional Neural Networks on FPGAs}}, 
  year={2021},
}

@ARTICLE{coprocessor2018tnnls,
  author={Shah, Nimish and Chaudhari, Paragkumar and Varghese, Kuruvilla},
  journal={IEEE Transactions on Neural Networks and Learning Systems (TNNLS)}, 
  title={{Runtime Programmable and Memory Bandwidth Optimized FPGA-Based Coprocessor for Deep Convolutional Neural Network}}, 
  year={2018},
}

@article{wdscdma,
  title={Wideband DS-CDMA for next-generation mobile communications systems},
  author={Adachi, Fumiyuki and others},
  journal={IEEE communications Magazine},
  volume={36},
  number={9},
  pages={56--69},
  year={1998},
  publisher={IEEE}
}

@article{1997iet,
   author = {F. Adachi and M. Sawahashi and K. Okawa},
   ISSN = {0013-5194},
   language = {English},
   title = {Tree-structured generation of orthogonal spreading codes with different lengths for forward link of DS-CDMA mobile radio},
   journal = {Electronics Letters},
   issue = {1},   
   volume = {33},
   year = {1997},
   month = {January},
   pages = {27-28(1)},
   publisher ={Institution of Engineering and Technology}
}

@INPROCEEDINGS{unzipfpga2021fccm,
  author={Venieris, Stylianos I. and Fernandez-Marques, Javier and Lane, Nicholas D.},
  booktitle={2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)}, 
  title={{unzipFPGA: Enhancing FPGA-based CNN Engines with On-the-Fly Weights Generation}}, 
  year={2021},
  volume={},
  number={},
  pages={165-175},
}

@inproceedings{embench2019emdl,
     //author = {Almeida, Mario and Laskaridis, Stefanos and Leontiadis, Ilias and Venieris, Stylianos I. and Lane, Nicholas D.},
     author = {Almeida, Mario and others},
     title = {{EmBench}: Quantifying Performance Variations of Deep Neural Networks Across Modern Commodity Devices},
     booktitle = {EMDL},
     year = {2019},
}

@inproceedings{dl_smartphones2019www,
  author    = {Mengwei Xu and
               Jiawei Liu and
               Yuanqiang Liu and
               Felix Xiaozhu Lin and
               Yunxin Liu and
               Xuanzhe Liu},
  title     = {{A First Look at Deep Learning Apps on Smartphones}},
  booktitle = {WWW},
  year      = {2019},
}

@inproceedings{fb_edge2019hpca,
  author    = {Carole{-}Jean Wu and
               others},
  title     = {{Machine Learning at Facebook: Understanding Inference at the Edge}},
  booktitle = {HPCA},
  year      = {2019},
}

@inproceedings{ai_benchmark2019iccvw,
  author    = {Andrey Ignatov and
               others},
  title     = {{AI Benchmark: All About Deep Learning on Smartphones in 2019}},
  booktitle = {ICCVW},
  year      = {2019},
}

% DNN inference accelerators in production
@inproceedings{samsung_npu2021isca,
  title={{Sparsity-Aware and Re-configurable NPU Architecture for Samsung Flagship Mobile SoC}},
  author={Jun-Woo Jang and others},
  year={2021},
  booktitle={ISCA}
}

@inproceedings{oodin2021smartcomp,
      title={{OODIn: An Optimised On-Device Inference Framework for Heterogeneous Mobile Devices}}, 
      author={Stylianos I. Venieris and Ioannis Panopoulos and Iakovos S. Venieris},
      year={2021},
      booktitle={IEEE SMARTCOMP}
}

@ARTICLE{polymorph2021tc,
  author={Azizimazreah, Arash and Chen, Lizhong},
  journal={IEEE Transactions on Computers}, 
  title={{Polymorphic Accelerators for Deep Neural Networks}}, 
  year={2021},
  volume={},
  number={},
}

% model-specific hardware optimisations
@INPROCEEDINGS{mobilenet_accel2021fpl,
    author={ {Shun Yan} and  others},
    booktitle={2021 31st International Conference on Field Programmable Logic and Applications (FPL)}, 
    title={{An FPGA-based MobileNet Accelerator Considering Network Structure Characteristics}}, 
    year={2021},
    volume={},
    number={},
}

@ARTICLE{maestro2020micro,
  author={Kwon, Hyoukjun and Chatarasi, Prasanth and Sarkar, Vivek and Krishna, Tushar and Pellauer, Michael and Parashar, Angshuman},
  journal={IEEE Micro}, 
  title={{MAESTRO: A Data-Centric Approach to Understand Reuse, Performance, and Hardware Cost of DNN Mappings}}, 
  year={2020},
  volume={40},
  number={3},
  pages={20-29},
}

@inproceedings{
    alizadeh2018a,
    title={{A Systematic Study of Binary Neural Networks' Optimisation}},
    author={Milad Alizadeh and Javier Fernández-Marqués and Nicholas D. Lane and Yarin Gal},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2019},
}

@inproceedings{tpu2017isca,
  title={{In-Datacenter Performance Analysis of a Tensor Processing Unit}},
  author={Jouppi, Norman P and others},
  booktitle={Annual International Symposium on Computer Architecture (ISCA)},
  year={2017}
}