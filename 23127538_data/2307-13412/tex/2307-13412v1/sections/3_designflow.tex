
\begin{wrapfigure}{R}{0.5\textwidth}
    \vspace{-0.4cm}
    \centering
    % \fbox
    {
    % Figure removed
    \vspace{-0.6cm}
    }
    \captionsetup{font=small,labelfont=bf}
    \caption{\footnotesize Overview of \tool's design flow.}
    \label{fig:design_flow}
     \vspace{-0.2cm}
\end{wrapfigure}

\section{\lowercase{unzip}FPGA's Design Flow}
\label{sec:design_flow}

Our framework aims to enhance the performance of hardware CNN engines, while maintaining a high level of abstraction for deep learning developers. Fig.~\ref{fig:design_flow} shows a high-level view of \tool's design flow, comprising two software components: \textit{1)}~the \textit{OVSF Model Converter} and \textit{2)}~the \textit{Optimiser}.

As a starting point, the deep learning expert provides the CNN model, expressed in PyTorch, and the target FPGA platform. The \textit{Converter} processes the supplied CNN architecture and derives an OVSF variant, by transforming the conventional convolutional layers into OVSF convolutional (OVSF-CONV) layers. This step entails \textit{i)}~the replacement of weight filters with a trainable linear combination of OVSF bases, followed by \textit{ii)}~the selection of each layer's compression ratio $\rho$. Next, the OVSF model is passed to the \textit{Trainer}, where the model gets trained using the supplied training set.

The \textit{Optimiser} accepts the trained OVSF CNN and a given FPGA platform and, uses them to populate the CNN \textit{Performance Model} and the \textit{Resource Constraints}, respectively. Importantly, the \textit{Optimiser} navigates the hardware configuration space considering resource allocations between the CNN engine and the weights generator. Upon completion, the design space exploration (\textit{DSE}) stage yields the highest performing configuration of \tool's architecture for the given CNN-device pair and the system is deployed on the FPGA.
