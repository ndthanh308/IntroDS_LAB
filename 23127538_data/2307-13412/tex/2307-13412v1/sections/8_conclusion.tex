
\section{Conclusion}
\label{sec:conclusion}

In this work we have presented \tool, a framework for FPGA-based CNN accelerators that mitigates the limitations that prevent single computation engines from attaining high resource utilisation and throughput. By generating the layer weights on demand and selectively balancing the PE load, \tool outperforms both status-quo and pruned CNN engines for the same bandwidth, while largely improving performance density compared to diverse state-of-the-art CNN accelerators. Furthermore, we demonstrated the superiority of models optimised with \tool in terms of energy efficiency compared to these being deployed on embedded GPU platforms. %\javier{maybe here link to some potential mobile-NPU ideas mentioned in the intro?}.
The benefits of the proposed on-the-fly formulation brought the largest gains at reduced memory bandwidths, which we envision to be a turning point towards enabling multi-tenant FPGA-based CNN models running concurrently and sharing the same off-chip memory. 