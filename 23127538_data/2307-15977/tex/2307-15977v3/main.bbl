% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{nichol2021glide}
A.~Nichol, P.~Dhariwal, A.~Ramesh, P.~Shyam, P.~Mishkin, B.~McGrew, I.~Sutskever, and M.~Chen, ``Glide: Towards photorealistic image generation and editing with text-guided diffusion models,'' in \emph{ICML}, 2021.

\bibitem{ramesh2022hierarchical}
A.~Ramesh, P.~Dhariwal, A.~Nichol, C.~Chu, and M.~Chen, ``Hierarchical text-conditional image generation with clip latents,'' \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{rombach2022high}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer, ``High-resolution image synthesis with latent diffusion models,'' in \emph{CVPR}, 2022.

\bibitem{mj}
``Midjourney,'' \url{https://www.midjourney.com}.

\bibitem{marra2019gans}
F.~Marra, D.~Gragnaniello, L.~Verdoliva, and G.~Poggi, ``Do gans leave artificial fingerprints?'' in \emph{MIPR}, 2019.

\bibitem{yu2019attributing}
N.~Yu, L.~S. Davis, and M.~Fritz, ``Attributing fake images to gans: Learning and analyzing gan fingerprints,'' in \emph{ICCV}, 2019.

\bibitem{xuan2019scalable}
X.~Xuan, B.~Peng, W.~Wang, and J.~Dong, ``Scalable fine-grained generated image classification based on deep metric learning,'' \emph{arXiv preprint arXiv:1912.11082}, 2019.

\bibitem{yang2022aaai}
T.~Yang, Z.~Huang, J.~Cao, L.~Li, and X.~Li, ``Deepfake network architecture attribution,'' in \emph{AAAI}, 2022.

\bibitem{bui2022repmix}
T.~Bui, N.~Yu, and J.~Collomosse, ``Repmix: Representation mixing for robust attribution of synthesized images,'' in \emph{ECCV}, 2022.

\bibitem{yang2023progressive}
T.~Yang, D.~Wang, F.~Tang, X.~Zhao, J.~Cao, and S.~Tang, ``Progressive open space expansion for open-set model attribution,'' in \emph{CVPR}, 2023.

\bibitem{abady2024siamese}
L.~Abady, J.~Wang, B.~Tondi, and M.~Barni, ``A siamese-based verification system for open-set architecture attribution of synthetic images,'' \emph{Pattern Recognition Letters}, 2024.

\bibitem{frank2020leveraging}
J.~Frank, T.~Eisenhofer, L.~Sch{\"o}nherr, A.~Fischer, D.~Kolossa, and T.~Holz, ``Leveraging frequency analysis for deep fake image recognition,'' in \emph{ICML}, 2020.

\bibitem{corvi2023intriguing}
R.~Corvi, D.~Cozzolino, G.~Poggi, K.~Nagano, and L.~Verdoliva, ``Intriguing properties of synthetic images: from generative adversarial networks to diffusion models,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 973--982.

\bibitem{karras2019style}
T.~Karras, S.~Laine, and T.~Aila, ``A style-based generator architecture for generative adversarial networks,'' in \emph{CVPR}, 2019.

\bibitem{asnani2023reverse}
V.~Asnani, X.~Yin, T.~Hassner, and X.~Liu, ``Reverse engineering of generative models: Inferring model hyperparameters from generated images,'' 2023.

\bibitem{zhang2019detecting}
X.~Zhang, S.~Karaman, and S.-F. Chang, ``Detecting and simulating artifacts in gan fake images,'' in \emph{WIFS}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019.

\bibitem{durall2020watch}
R.~Durall, M.~Keuper, and J.~Keuper, ``Watch your up-convolution: Cnn based generative deep neural networks are failing to reproduce spectral distributions,'' in \emph{CVPR}, 2020.

\bibitem{schwarz2021frequency}
K.~Schwarz, Y.~Liao, and A.~Geiger, ``On the frequency bias of generative models,'' in \emph{NeurIPS}, 2021.

\bibitem{dzanic2020fourier}
T.~Dzanic, K.~Shah, and F.~Witherden, ``Fourier spectrum discrepancies in deep network generated images,'' in \emph{NeurIPS}, 2020.

\bibitem{khayatkhoei2022spatial}
M.~Khayatkhoei and A.~Elgammal, ``Spatial frequency bias in convolutional generative adversarial networks,'' in \emph{AAAI}, 2022.

\bibitem{chandrasegaran2021closer}
K.~Chandrasegaran, N.-T. Tran, and N.-M. Cheung, ``A closer look at fourier spectrum discrepancies for cnn-generated images detection,'' in \emph{CVPR}, 2021.

\bibitem{baradad2021learning}
M.~Baradad~Jurjo, J.~Wulff, T.~Wang, P.~Isola, and A.~Torralba, ``Learning to see by looking at noise,'' in \emph{NeurIPS}, 2021.

\bibitem{baek2022commonality}
K.~Baek and H.~Shim, ``Commonality in natural images rescues gans: Pretraining gans with generic and privacy-free synthetic data,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 7854--7864.

\bibitem{mishra2022task2sim}
S.~Mishra, R.~Panda, C.~P. Phoo, C.-F.~R. Chen, L.~Karlinsky, K.~Saenko, V.~Saligrama, and R.~S. Feris, ``Task2sim: Towards effective pre-training and transfer from synthetic data,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2022, pp. 9194--9204.

\bibitem{ioffe2015batch}
S.~Ioffe and C.~Szegedy, ``Batch normalization: Accelerating deep network training by reducing internal covariate shift,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax pmlr, 2015, pp. 448--456.

\bibitem{ulyanov2016instance}
D.~Ulyanov, A.~Vedaldi, and V.~Lempitsky, ``Instance normalization: The missing ingredient for fast stylization,'' \emph{arXiv preprint arXiv:1607.08022}, 2016.

\bibitem{heusel2017gans}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter, ``Gans trained by a two time-scale update rule converge to a local nash equilibrium,'' \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{zhang2017beyond}
K.~Zhang, W.~Zuo, Y.~Chen, D.~Meng, and L.~Zhang, ``Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising,'' \emph{IEEE transactions on image processing}, vol.~26, no.~7, pp. 3142--3155, 2017.

\bibitem{kirchner2009resampling}
M.~Kirchner and T.~Gloe, ``On resampling detection in re-compressed images,'' in \emph{2009 First IEEE international workshop on information forensics and security (WIFS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2009, pp. 21--25.

\bibitem{guo2023exposing}
Z.~Guo, G.~Yang, J.~Chen, and X.~Sun, ``Exposing deepfake face forgeries with guided residuals,'' \emph{IEEE Transactions on Multimedia}, vol.~25, pp. 8458--8470, 2023.

\bibitem{weinberger2009distance}
K.~Q. Weinberger and L.~K. Saul, ``Distance metric learning for large margin nearest neighbor classification.'' \emph{Journal of machine learning research}, vol.~10, no.~2, 2009.

\bibitem{corvi2023detection}
R.~Corvi, D.~Cozzolino, G.~Zingarini, G.~Poggi, K.~Nagano, and L.~Verdoliva, ``On the detection of synthetic images generated by diffusion models,'' in \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 1--5.

\bibitem{bammey2023synthbuster}
Q.~Bammey, ``Synthbuster: Towards detection of diffusion model generated images,'' \emph{IEEE Open Journal of Signal Processing}, 2023.

\bibitem{karras2017progressive}
T.~Karras, T.~Aila, S.~Laine, and J.~Lehtinen, ``Progressive growing of gans for improved quality, stability, and variation,'' in \emph{ICLR}, 2018.

\bibitem{binkowski2018MMD}
M.~Bi≈Ñkowski, D.~J. Sutherland, M.~Arbel, and A.~Gretton, ``Demystifying {MMD} {GAN}s,'' in \emph{ICLR}, 2018.

\bibitem{zhang2019self}
H.~Zhang, I.~Goodfellow, D.~Metaxas, and A.~Odena, ``Self-attention generative adversarial networks,'' in \emph{ICML}, 2019.

\bibitem{choi2018stargan}
Y.~Choi, M.~Choi, M.~Kim, J.-W. Ha, S.~Kim, and J.~Choo, ``Stargan: Unified generative adversarial networks for multi-domain image-to-image translation,'' in \emph{CVPR}, 2018.

\bibitem{he2019attgan}
Z.~He, W.~Zuo, M.~Kan, S.~Shan, and X.~Chen, ``Attgan: Facial attribute editing by only changing what you want,'' \emph{TIP}, vol.~28, no.~11, pp. 5464--5478, 2019.

\bibitem{karras2020stylegan2}
T.~Karras, S.~Laine, M.~Aittala, J.~Hellsten, J.~Lehtinen, and T.~Aila, ``Analyzing and improving the image quality of stylegan,'' in \emph{CVPR}, 2020.

\bibitem{karras2021alias}
T.~Karras, M.~Aittala, S.~Laine, E.~H{\"a}rk{\"o}nen, J.~Hellsten, J.~Lehtinen, and T.~Aila, ``Alias-free generative adversarial networks,'' in \emph{NeurIPS}, 2021.

\bibitem{kingma2013auto}
D.~P. Kingma and M.~Welling, ``Auto-encoding variational bayes,'' in \emph{ICLR}, 2014.

\bibitem{higgins2017beta}
I.~Higgins, L.~Matthey, A.~Pal, C.~Burgess, X.~Glorot, M.~Botvinick, S.~Mohamed, and A.~Lerchner, ``beta-vae: Learning basic visual concepts with a constrained variational framework,'' in \emph{ICLR}, 2017.

\bibitem{burgess2018understanding}
C.~P. Burgess, I.~Higgins, A.~Pal, L.~Matthey, N.~Watters, G.~Desjardins, and A.~Lerchner, ``Understanding disentangling in beta-vae,'' in \emph{NIPS workshop}, 2017.

\bibitem{zhao2017infovae}
S.~Zhao, J.~Song, and S.~Ermon, ``Infovae: Information maximizing variational autoencoders,'' \emph{arXiv preprint arXiv:1706.02262}, 2017.

\bibitem{chen2019residual}
R.~T. Chen, J.~Behrmann, D.~K. Duvenaud, and J.-H. Jacobsen, ``Residual flows for invertible generative modeling,'' in \emph{NeurIPS}, 2019.

\bibitem{kingma2018glow}
D.~P. Kingma and P.~Dhariwal, ``Glow: Generative flow with invertible 1x1 convolutions,'' in \emph{NeurIPS}, 2018.

\bibitem{dhariwal2021diffusion}
P.~Dhariwal and A.~Nichol, ``Diffusion models beat gans on image synthesis,'' in \emph{NeurIPS}, 2021.

\bibitem{ho2020denoising}
J.~Ho, A.~Jain, and P.~Abbeel, ``Denoising diffusion probabilistic models,'' in \emph{NeurIPS}, 2020.

\bibitem{liu2022pseudo}
L.~Liu, Y.~Ren, Z.~Lin, and Z.~Zhao, ``Pseudo numerical methods for diffusion models on manifolds,'' in \emph{ICLR}, 2022.

\bibitem{hudson2021generative}
D.~A. Hudson and L.~Zitnick, ``Generative adversarial transformers,'' in \emph{ICML}, 2021.

\bibitem{zhang2022styleswin}
B.~Zhang, S.~Gu, B.~Zhang, J.~Bao, D.~Chen, F.~Wen, Y.~Wang, and B.~Guo, ``Styleswin: Transformer-based gan for high-resolution image generation,'' in \emph{CVPR}, 2022.

\bibitem{jiang2021transgan}
Y.~Jiang, S.~Chang, and Z.~Wang, ``Transgan: Two pure transformers can make one strong gan, and that can scale up,'' in \emph{NeurIPS}, 2021.

\bibitem{park2022styleformer}
J.~Park and Y.~Kim, ``Styleformer: Transformer based generative adversarial networks with style vector,'' in \emph{CVPR}, 2022.

\bibitem{dalle-mini}
``Dall-e mini,'' \url{https://github.com/borisdayma/dalle-mini}.

\bibitem{betker2023improving}
J.~Betker, G.~Goh, L.~Jing, T.~Brooks, J.~Wang, L.~Li, L.~Ouyang, J.~Zhuang, J.~Lee, Y.~Guo \emph{et~al.}, ``Improving image generation with better captions,'' \emph{Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf}, vol.~2, no.~3, p.~8, 2023.

\bibitem{rousseeuw1987silhouettes}
P.~J. Rousseeuw, ``Silhouettes: a graphical aid to the interpretation and validation of cluster analysis,'' \emph{Journal of computational and applied mathematics}, vol.~20, pp. 53--65, 1987.

\bibitem{davies1979cluster}
D.~L. Davies and D.~W. Bouldin, ``A cluster separation measure,'' \emph{IEEE transactions on pattern analysis and machine intelligence}, no.~2, pp. 224--227, 1979.

\bibitem{hu2022lora}
E.~J. Hu, Y.~Shen, P.~Wallis, Z.~Allen-Zhu, Y.~Li, S.~Wang, L.~Wang, and W.~Chen, ``Lo{RA}: Low-rank adaptation of large language models,'' in \emph{International Conference on Learning Representations}, 2022.

\bibitem{miyato2018spectral}
T.~Miyato, T.~Kataoka, M.~Koyama, and Y.~Yoshida, ``Spectral normalization for generative adversarial networks,'' in \emph{ICLR}, 2018.

\bibitem{song2020denoising}
J.~Song, C.~Meng, and S.~Ermon, ``Denoising diffusion implicit models,'' in \emph{International Conference on Learning Representations}, 2021.

\bibitem{karras2022elucidating}
T.~Karras, M.~Aittala, T.~Aila, and S.~Laine, ``Elucidating the design space of diffusion-based generative models,'' \emph{Advances in Neural Information Processing Systems}, vol.~35, pp. 26\,565--26\,577, 2022.

\end{thebibliography}
