\section{Related work}
\label{sec:related_work}

\subsection{Model Attribution}
\label{subsec:generative_model_attribution}

In essence, model attribution methods rely on some relationship between the internal states of generative models and the generated images. This paper mainly focuses on fingerprint-based model attribution, which relies on the unique  fingerprint patterns on the output images of generative models. Marra et al. \cite{marra2019gans} used averaged noise residuals to represent model fingerprints and found that these fingerprints are periodic. Subsequent works \cite{yu2019attributing, yang2022aaai, bui2022repmix} confirmed the existence of these fingerprints and achieved high accuracy with a fixed, finite set of models following a closed-set classification approach. Asnani et al. \cite{asnani2023reverse} extended this research to trace the architectural components of models that generate images, which is beyond the scope of this paper. In real-world scenarios, images often originate from unseen models not present during training. Recent works \cite{yang2023progressive, abady2024siamese} addressed this by using an open-set approach, which attributes seen models and rejects unseen models not included in training. However, as generative technology continues to evolve, the variety of unseen models expands continuously, challenging the capacity of existing methods to adapt in the real-world dynamically. To bridge this gap, our goal is to develop a more generalized model fingerprint extractor capable of zero-shot model attribution, efficiently attributing unseen models without requiring any training on samples from these models. Table~\ref{tab:method_compare} summarizes the differences between our method and related works mentioned above.


\inputtable{method_compare}


\subsection{Spectrum Discrepancies of Generative Models}
\label{subsec:frequency_bias_of_generative_models}

Although fingerprints are visually imperceptible in the spatial domain, they are more noticeable in the frequency domain, often appearing as discrepancies in the spectrum. Existing studies \cite{zhang2019detecting, durall2020watch, schwarz2021frequency, dzanic2020fourier, khayatkhoei2022spatial, chandrasegaran2021closer, corvi2023intriguing} have sought to explain the spectrum discrepancies between generated and real images, particularly by studying the influence of upsampling and convolution layers.

% ~\cite{guo2023exposing}

Studies in \cite{zhang2019detecting, durall2020watch, schwarz2021frequency} find that upsampling operations lead to high-frequency discrepancies between real and generated images. Zhang et al. \cite{zhang2019detecting} showed that the upsampling layer causes a periodic grid pattern on the spectrum. Durall et al. \cite{durall2020watch} identified a high-frequency discrepancy caused by the upsampling layer, which makes generative architectures struggle to fit the real image distribution. Schwarz et al. \cite{schwarz2021frequency} discovered that different upsampling operations bias the generator toward distinct spectral properties. Other studies \cite{dzanic2020fourier, khayatkhoei2022spatial} have analyzed the influence of convolution layers and attributed the frequency differences between real and generated images to the linear dependencies in the spectrum of convolutional filters, which hinder the learning of high frequencies.

The studies above primarily focused on differences between real and generated images, with fewer analyzing the frequency discrepancies between images generated by different models. In our study, we further investigate the influence of different types of activation and normalization layers and the effects of various convolution parameters. We have newly observed the influence of different generative blocks, providing additional insights into the formation of model fingerprints.

\subsection{Pre-train on Synthetic Data}

% Since synthetic data can bypass the cumbersome data crawling process, previous works have made efforts to utilize synthetic dataset in improving the performance on real datasets.


Our study is related to using the synthetic data for improving generalization performance. Baradad\etal~\cite{baradad2021learning} find that diverse noise data with capture certain structural properties of real data, despite far from realistic, could achieve good performance when used for self-supervised learning for a image classification task. Baek\etal~\cite{baek2022commonality} develop the data synthesis strategy by adopting the generic property of the natural images in power spectrum distribution, structure, and existence of saliency. The pretrained GANs using the synthetic dataset can effectively transfer in low-shot adaptation. Mishra\etal~\cite{mishra2022task2sim} propose a task-aware synthesis strategy to find the simulation parameters (lighting, pose, materials, etc.) that best fit the downstream task. 

In contrast to these works, our research proposes synthesizing \emph{models} rather than \emph{images} to mimic the patterns of model fingerprints rather than natural images.






