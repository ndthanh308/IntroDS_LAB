\section{Related work}
\label{sec:related_work}

\subsection{Model Attribution}
\label{subsec:generative_model_attribution}

In essence, model attribution methods rely on some relationship between the internal states of generative models and the generated images. Depending on how such a relationship is created and identified, existing studies could be classified into three types: watermark-based methods, model-inversion-based methods, and fingerprint-based methods. 

Watermarking has been widely used in copyright protection for digital contents~\cite{cox2002digital, hartung1999multimedia}, database~\cite{hu2018new, ren2023robust}, and recently, generative models~\cite{yu2020artificial, zhao2023recipe, yu2020responsible, nie2023attributing}. Watermarking-based model attribution methods include those based on training data embedding~\cite{yu2020artificial, zhao2023recipe}, weight modulation~\cite{nie2023attributing, yu2020responsible}, and latent vector watermarking~\cite{nie2023attributing}. Although watermarks facilitate model attribution, the injected watermark can hurt the quality of the generated images, besides, the attribution target is limited to models that have been watermarked, rather than any model, which limits its flexibility and application scenarios. Model-inversion-based methods~\cite{albright2019source, zhang2020attribution, laszkiewicz2023single} typically involves reversing the process to map an image back to its original latent space representation, followed by an attempt to regenerate the image. This technique is applicable only to white-box models, as it relies on accessing the model's parameters. 

% Fingerprint-based methods attribute models based on a kind of verified unique fingerprints on images of generative models, which could be more evidently observed on the spectrum. Compared with the formal two techniques, fingerprint-based model attribution approaches use the intriguing characteristics of generative models without need of injecting information to the model, and are applicable to both the white-box and black-box models by only relying the output images. To name a few recent advances, Marra\etal~\cite{marra2019gans} use averaged noise residuals to represent model fingerprints and finds that model fingerprints are periodic. Later works~\cite{yu2019attributing, yang2022aaai, bui2022repmix} further verify the existence of model fingerprints and achieve high accuracy on a fixed and finite set of models following a closed-set classification formulation. Asnani\etal~\cite{asnani2023reverse} extend their investigation to tracing back the architectural components of models that generate images, which is beyond the scope of this paper. Considering an unlimited number of unknown models in the open-world scenarios, recent works~\cite{girish2021towards, yang2023progressive,abady2024siamese} solve model attribution in an open-set formalization. However, the problem of generalized model attribution remains unsolved. Existing solutions are limited by the seen/unseen unbalance issue in real-world scenarios, where only a limited number of seen models could be sampled while the number of unseen models continues to grow. How to generalize model attribution methods to unseen models remains a problem. 


Fingerprint-based methods attribute models by identifying unique fingerprints on images of generative models, which are particularly evident in the spectrum. Compared to the two previously mentioned techniques, fingerprint-based model attribution approaches utilize the distinctive characteristics of generative models without requiring the injection of information into the model. They can be applied to both white-box and black-box models by relying solely on the output images. Marra et al. \cite{marra2019gans} used averaged noise residuals to represent model fingerprints and found that these fingerprints are periodic. Subsequent works \cite{yu2019attributing, yang2022aaai, bui2022repmix} confirmed the existence of these fingerprints and achieved high accuracy with a fixed, finite set of models following a closed-set classification approach. Asnani et al. \cite{asnani2023reverse} extended this research to trace the architectural components of models that generate images, which is beyond the scope of this paper. In open-world scenarios, with an unlimited number of unknown models, recent works \cite{girish2021towards, yang2023progressive, abady2024siamese} addressed model attribution using an open-set approach. However, the challenge of generalized model attribution remains unresolved. Current solutions are hampered by the seen/unseen imbalance issue in real-world scenarios, where only a limited number of seen models can be sampled while the number of unseen models continues to grow. Finding ways to improve the generalization performance of model attribution to new, emerging models remains a challenge.

\subsection{Spectrum Discrepancies of Generative Models}
\label{subsec:frequency_bias_of_generative_models}

% Despite visually imperceptible in the spatial domain, fingerprints are more observable in the frequency domain, which are often shown as the spectrum discrepancies. Existing studies~\cite{zhang2019detecting, durall2020watch, schwarz2021frequency, dzanic2020fourier, khayatkhoei2022spatial, chandrasegaran2021closer, corvi2023intriguing} have made efforts in explaining the spectrum discrepancies between generated and real images. Specifically, the influence of upsampling and convolution layers are commonly studied.



Although fingerprints are visually imperceptible in the spatial domain, they are more noticeable in the frequency domain, often appearing as discrepancies in the spectrum. Existing studies \cite{zhang2019detecting, durall2020watch, schwarz2021frequency, dzanic2020fourier, khayatkhoei2022spatial, chandrasegaran2021closer, corvi2023intriguing} have sought to explain the spectrum discrepancies between generated and real images, particularly by studying the influence of upsampling and convolution layers.



Studies in \cite{zhang2019detecting, durall2020watch, schwarz2021frequency} find that upsampling operations lead to high-frequency discrepancies between real and generated images. Zhang et al. \cite{zhang2019detecting} showed that the upsampling layer causes a periodic grid pattern on the spectrum. Durall et al. \cite{durall2020watch} identified a high-frequency discrepancy caused by the upsampling layer, which makes generative architectures struggle to fit the real image distribution. Schwarz et al. \cite{schwarz2021frequency} discovered that different upsampling operations bias the generator toward distinct spectral properties. Other studies \cite{dzanic2020fourier, khayatkhoei2022spatial} have analyzed the influence of convolution layers and attributed the frequency differences between real and generated images to the linear dependencies in the spectrum of convolutional filters, which hinder the learning of high frequencies.

The studies above primarily focused on differences between real and generated images, with fewer analyzing the frequency discrepancies between images generated by different models. In our study, we further investigate the influence of different types of activation and normalization layers and the effects of various convolution parameters. We have newly observed the influence of different generative blocks, providing additional insights into the formation of model fingerprints.

\subsection{Pre-train on Synthetic Data}

% Since synthetic data can bypass the cumbersome data crawling process, previous works have made efforts to utilize synthetic dataset in improving the performance on real datasets.


Our study is related to using the synthetic data for improving generalization performance. Baradad\etal~\cite{baradad2021learning} find that diverse noise data with capture certain structural properties of real data, despite far from realistic, could achieve good performance when used for self-supervised learning for a image classification task. Baek\etal~\cite{baek2022commonality} develop the data synthesis strategy by adopting the generic property of the natural images in power spectrum distribution, structure, and existence of saliency. The pretrained GANs using the synthetic dataset can effectively transfer in low-shot adaptation. Mishra\etal~\cite{mishra2022task2sim} propose a task-aware synthesis strategy to find the simulation parameters (lighting, pose, materials, etc.) that best fit the downstream task. 

In contrast to these works, our research proposes synthesizing \emph{models} rather than \emph{images} to mimic the patterns of model fingerprints rather than natural images.


% \cite{baek2022commonality, mishra2022task2sim, baradad2021learning}



