% \clearpage
% \section{Analyzing 
\subsection{Network components analysis in the frequency domain}

% % \wdd{You need to define what is model fingerprint, and justify why it can be better understood in frequency domain}
% Based on theorems of signal processing, image convolution can be replaced by straightforward element-wise multiplication, which implies that model fingerprints could be better understood in the frequency domain. In this section, we delineate how each component of the generator operates in the frequency domain, and through visualization, we show how these components produce and influence frequency patterns. \textbf{Note that the DFT frequency spectrums in this section are not shifted to better observe the high-frequency regions. Thus, the corner regions correspond to low frequencies, while the center regions correspond to high frequencies.}

% \inputfigure{noise_pipeline}
% Note that to satisfy the convolution theorem, we need to first zero-pad both $I$ and $K$ to a size of $(H+k-1, W+k-1)$.
% \subsection{Generative architecture revisited}

Different generative models exhibit variations in terms of training objectives, regularizations, and architectures, making it a daunting task to consider all these factors. In this work, we specifically focus on the ``decoder", which reconstructs or generates the output image from latent representations and directly influences the output images. The latent representations could be obtained from a preceding encoder or directly sampled from a pre-defined distribution. 
The structure of a typical decoder is analogous among many generative models such as Generative Adversarial Networks (GAN), Variational Autoencoders (VAE), and Diffusion models. Typically, a decoder is composed of multiple blocks, with each block upscaling and refining input feature maps through the incorporation of upsampling, convolution, normalization, and activation layers. In this section, we delineate how each of these components operates in the frequency domain and how they contribute to the creation or transformation of frequency patterns. Note that the DFT frequency spectrums in this section are not shifted to better observe the high-frequency regions. Thus, the corner regions correspond to low frequencies, while the center regions correspond to high frequencies.

% Each block comprises several components, including upsampling, convolution, activation function, and normalization. 
% These components are combined together based on certain stacking regulations.

% Common types of generative models are Generative Adversarial Networks (GAN), Variational Autoencoders (VAE), Flow-based models, and Diffusion models. GAN provides a smart solution to model the data generation, an unsupervised learning problem, as a supervised one. The discriminator model learns to distinguish the real data from the fake samples that are produced by the generator model. Two models are trained as they are playing a minimax game. VAE is typically composed of an encoder and a decoder, the encoder network maps the input data (such as images or text) to a lower-dimensional representation in the latent space, while the decoder network reconstructs the input data from the latent space representation. Flow-based model is constructed by a sequence of invertible transformations, which are always operations like . Diffusion model takes as input a noisy image composed of white noise and image content, and generates progressively less noisy versions of it until reaching the desired noiseless output. Latent diffusion models combine VAEs with diffusion models. The VAE is used to project images into a latent space and back, and the decoder is commonly constructed as a U-Net architecture. 

% Despite their unique training objectives and architecture details respectively, they share commonality in decoders. The decoder 
\inputfigure{conv_varying_noise}

\noindent \textbf{Frequency distribution pattern caused by convolution.} 
% \noindent \textbf{Convolution.}
For an input feature map $X \in \mathbb{R}^{C_1\times H\times W}$ and a convolution layer with kernels $K \in \mathbb{R}^{C_1 \times C_2 \times k \times k}$ with stride one, where $C_1$, $C_2$, and $k$ are input channel number, output channel number, and kernel size, respectively. We first consider a simple case with single input and output channel, \ie, $C_1=1$ and $C_2=1$. According to the Convolution Theorem~\cite{oppenheim1999discrete}, the spatial convolution operation equals to multiplication operation in the frequency domain:
\begin{equation}
    \mathcal{F}\{X \otimes K\} = \mathcal{F}\{X\} \cdot \mathcal{F}\{K\}, 
\label{eq:conv1}
\end{equation}
where $\mathcal{F}\{X\}$ and $\mathcal{F}\{K\}$ are the discrete Fourier transform (DFT) of zero-padded $X$ and $K$. In the case of multiple channels, the Convolution Theorem still stands for the convolution computation of each channel:
\begin{equation}
    \mathcal{F}\{O_{j}\} = \mathcal{F}\{\sum_{i=0}^{C_1} X_{i} \otimes K_{i,j}\} = \sum_{i=0}^{C_1} \mathcal{F}\{X_{i}\} \cdot \mathcal{F}\{K_{i,j}\},
\label{eq:conv2}
\end{equation}
where $O_{j}$ is the $j$-th channel of the output feature map, $X_{i}$ is the $i$-th channel of the input feature map, $K_{i,j}$ is the $(i,j)$-th channel of $K$.

Next, we explain how convolution operations create frequency patterns. Considering the simple case of a single convolution layer operating on 2D Gaussian noises. The spectrum of Gaussian noise still displays like Gaussian noise. Thus, uniform frequency patterns would exist in the spectrum of all output noises that are convolved by this layer and exhibit the shape of the zero-padded convolution kernel's spectrum according to Eq.~\ref{eq:conv1}. This indicates that when different latent codes are sampled into the generator (or decoder), convolutions would produce similar frequency distribution patterns. 

Fig.~\ref{fig:conv_varying_noise} further shows the case of a convolution layer with multiple channels operating on features from the last block of a well-trained StyleGAN2~\cite{karras2020stylegan2} face generator. See Fig.~\ref{fig:conv_varying_noise}b and ~\ref{fig:conv_varying_noise}e, varying the latent code sent into the generator, the spectrums of feature maps output by the same convolutional layer show uniform frequency patterns and are consistently similar to the averaged kernel spectrum of the convolution layer generating them. We also plot the mean and variance map of feature spectrums varying the latent code in Fig.~\ref{fig:conv_varying_noise}c and ~\ref{fig:conv_varying_noise}d. The mean map is similar to the convolution spectrum as expected. The variance map exhibit low in the high-frequency region and high in the low-frequency region. This indicates that the variation of latent code would more significantly alter low-frequency components while keeping high-frequency patterns consistent. Thus, generated images from the same generator would share similar high-frequency patterns despite their differences in low-frequency semantics. We also emphasize that this uniform frequency pattern in high-frequencies is observed in common generators that generate low-frequency semantics. However, for other specific generators such as texture generation models, this pattern may manifest in different frequency components.

\noindent \textbf{Grid-like pattern caused by upsampling layer.}
% \noindent \textbf{Upsampling.}
Common types of upsampling layers are deconvolution (or transposed convolution) and interpolation upsamplers such as nearest neighbor (NN) and bilinear. Deconvolution is equivalent to interleaving the input features with 0â€™s and applying a standard convolutional operation. For interpolation upsamplers, the interpolated pixels are linearly dependent on their neighbors, thus they could also be regarded as a combined operation including zero-interleaving and a convolution operation with fixed parameters. Then we could summarize upsampling operations into a unified formalization:
\begin{equation}
 X_{up} = \text{ZeroInter}(X) \otimes K_{up},
 % X_{up} = ZI(X) \otimes K_{up},
 \label{eq:uniup}
\end{equation}
\inputfigure{conv_up}
where $\text{ZeroInter}$ is interleaving the input feature $X$ with 0's, and $K_{up}$ is a convolution kernel. For deconvolution, $K_{up}$ is learnable. For nearest neighbor and bilinear upsampling, $K_{up}$ has a corresponding fixed weight, see Fig.~\ref{fig:conv_up}c. 
Adopting the DFT transform, it's easy to obtain that zero-interleaving in the spatial domain brings about spectrum replicas in the frequency domain. Then we could summarize upsampling operation in the frequency domain as replicating the frequency spectrum of the input signal and pointwise multiplication with a corresponding upsampling kernel's spectrum:
\begin{equation}
 \mathcal{F}\{X_{up}\} = \text{Repeat}_{2,2}(\mathcal{F}\{X\}) \odot \mathcal{F}\{K_{up}\},
 \label{eq:uniup2}
\end{equation}
where $\text{Repeat}_{2,2}$ means repeat the spectrum of $X$ along two frequency dimensions by two times. 

Through the formulation, we could attribute the grid-like pattern observed on the spectrum to the zero-interleaving operation in the spatial domain. See Fig.~\ref{fig:conv_up}b, this operation causes low-frequency components (corners) to shift towards high-frequency regions (center) after spectrum replication, resulting in distinct lines along the horizontal and vertical axes. It can be easily deduced that the periodicity of these grids depends on the number of upsampling layers. $n$ layers of upsampling would result in grids in multiples of $1/2^n$ positions. These grids could be polished by following upsampling kernel.
See Fig.~\ref{fig:conv_up}d, NN and bilinear tend to suppress these grids as their spectrums are naturally low in the central regions. On the other hand, deconvolution kernels, which are learned without specific constraints, may not sufficiently suppress these grids like NN and bilinear, leading to stronger grid patterns on the spectrum. This analysis could also provide a unified explanation for the commonly discussed empirical observation that nearest and bilinear produce fewer artifacts than deconvolution~\cite{odena2016deconvolution, wojna2019devil, chandrasegaran2021closer, schwarz2021frequency}. 

% \inputfigure{act_norm2}
\noindent \textbf{Frequency pattern transformation by normalization and nonlinearity.}
Common types of normalization are Instance Normalization (IN) and Batch Normalization (BN), which have the same computational form, except that the mean and variance are derived from an instance or a batch. As described in ~\cite{pan2022learning}, the implementation of BN in the frequency domain has exactly the same form as the time domain. Thus, the normalization layer would normalize, shift and scale the frequency pattern of the input signal. To give an intuitive understanding of the effect of nonlinear activation functions, an approach is to apply Taylor series approximation to transform them as polynomials, and perform DFT transform based on the convolution theorem that multiplication in the spatial domain is equivalent to convolution in the frequency domain. For example, SReLU~\cite{ayat2019spectral} uses polynomial fitting to approximate the ReLU function $max(0,x)$ in the form of $0.3x + 0.021x^2$, which can be calculated in the frequency domain as $0.3X + 0.021 \cdot (X \otimes X)$, where $X$ is the DFT spectrum of $x$. As seen, the magnitude of the input signal's frequency pattern would be altered by self-convolution items, and the magnitude of changes depends on the amplitude of the input signal's spectrum.

% \noindent \textbf{Compound frequency pattern within a generative block.}
\subsection{Frequency pattern attenuation over generative blocks}
\label{sec:attenuation}
\inputfigure{attenuation_case_curve}
% Leveraging the above analysis on individual components, we could derive the compound frequency patterns for a generative block. The upsampling layer would first repeat frequency patterns from preceding layers, and polish the pattern by the upsampling kernel's spectrum, new pattern would be created by following convolution and transformed by activation and normalization layers. 
% Leveraging the above analysis of individual components, we can understand how compound frequency patterns emerge in a generative block. The process starts with the upsampling layer, which replicates the frequency patterns from preceding layers, which are then refined by the spectrum of the upsampling kernel. Next, the pattern undergoes the convolution operation, which introduces new frequency components and alters the existing ones. The activation and normalization layers further modify the pattern, potentially enhancing or attenuating specific frequency components.
See Fig.~\ref{fig:conv_up}c, interpolation upsamplers such as nearest neighbor and bilinear would cause high-frequency attenuation due to their low-pass upsampling filters. Generators like StyleGAN3~\cite{karras2021alias} even design low-pass filters with larger attenuation to suppress aliasing. These indicate that high-frequency patterns from preceding generative blocks may be filtered out when passed to consequent blocks.

Fig.~\ref{fig:attenuation_case_curve} gives an intuitive illustration of the attenuation. Fig.~\ref{fig:attenuation_case_curve}a shows the last two blocks $\mathbf{b_{128}}$ and $\mathbf{b_{256}}$ of a StyleGAN2~\cite{karras2020stylegan2} $256\times256$ face generator. Each block increases the resolution by two and contains a Biliner Up+Conv0 layer and a Conv1 layer. We visualize the spectrum (averaged along the input channels) for three output channels (column marginal) in three convolutional layers (row marginal) in Fig.~\ref{fig:attenuation_case_curve}(b,d,f), and the spectrum of output features by these output channels in Fig.~\ref{fig:attenuation_case_curve}(c,e,g). We could notice the output features' spectrum of b128.conv1 shares similar patterns with the spectrum of convolution channels on their left. However, after the Upsample and Conv0 layer, the patterns are largely attenuated and show again as the shape of Conv1's spectrum after another convolution layer. This phenomenon validates that bilinear upsampling layers would cause high-frequency attenuation and thus suppress frequency patterns produced by previous layers. 

Fig.~\ref{fig:attenuation_case_curve}h further qualifies the high-frequency component variation throughout the generation process. X-axis means every network component in the sequence of generation, and y-axis means the proportion of high frequencies of feature maps output by each network component, which is calculated as the ratio of the sum of values in the latter half of the azimuthal integral spectrum~\cite{durall2020watch} to the sum of all values. 
As seen, The ``up\_conv" upsampling layer stably suppresses high-frequency components in every generative block. The high-frequency attenuation phenomenon indicates that the last generative block would play a prominent role in producing model fingerprints for common generators with low-pass upsampling kernels. 

% \inputfigure{spectrum_vis}