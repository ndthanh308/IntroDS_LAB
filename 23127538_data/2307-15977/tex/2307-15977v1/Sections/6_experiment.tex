% \clearpage
\section{Experiments}

\inputfigure{1v1_tsne}
\inputtable{result_1v1_verification}

\noindent \textbf{Testing models.}
To demonstrate the generalization capability of our fingerprint extractor trained on synthetic data, we test it on five sets of real generative models, including GAN, Diffusion, VAE, Flow, and Text2Image Models. Details are in Tab.~\ref{tab:dataset}. As seen, for GAN, VAE, Flow, and Diffusion, we collected models with various architectures for each dataset they are trained on. 
Text2Image models are not restricted to specific domains. The images from StableDiffusion, Glide, DallE-2, and Dalle2-mini are generated by COCO captions. The Midjourney images are randomly sampled from the Kaggle Midjourney dataset~\footnote{https://www.kaggle.com/datasets/da9b9ba35ffbd86a5f97ccd068d3c74f5742cfe5f34f6aaf1f0f458d7694f55e} generated by user prompts. More details are in the Appendix.

% \subsection{Model verification}
\noindent \textbf{Model verification.} The model of a generative commercial service could be stolen by model stealing attacks, posing great threats to copyright issues. To verify whether the model behind a generative service is stolen from another, we consider the scenario of 1:1 model verification. Our verification pipeline is shown in Fig.~\ref{fig:problem_setup}a: first use the model to be verified to generate $N_{S}$ images, and then use the pre-trained fingerprint extractor to extract features from these images, obtaining the average feature as the fingerprint of the model. Model verification is performed by comparing the similarity of the fingerprints of models. For evaluation, we adopt metrics typically used in face verification: the accuracy and the area under the ROC curve (AUC). Accuracy refers to whether or not two models are correctly identified as the same model or not. AUC is the area under the Receiver Operating Characteristic (ROC) curve, which plots the true positive rate against the false positive rate. 

Tab.~\ref{tab:result_1v1_verification} shows the verification results for different values of $N_{S}$. We compare with PRNU~\cite{marra2019gans} which is also training-free for open-world models. Our method significantly outperforms PRNU~\cite{marra2019gans} in the majority of generative types. Observing the feature space visualization in Fig.~\ref{fig:1v1_tsne}, although our fingerprint extractor is trained solely on synthetic data, it could extract distinct fingerprints from a variety of real generative models. These results indicate our synthetic data could mimic the frequency patterns for most types of CNN-based generative models. 
In the ablation study presented in Tab.~\ref{tab:ablation}, we train the fingerprint extractor solely on synthetic data from each type of generator, as well as on combined data. The results demonstrate that combining both types of simulated patterns yields the best overall performance, highlighting the complementary nature of the two types of synthetic data.

% \subsection{Open-set model identification}
\noindent \textbf{Open-set model identification.}
In some cases, it is necessary to identify the specific generative model responsible for producing malicious or illegal content. To address this, we tackle the open-set 1:N model identification problem following the formulation in ~\cite{yang2023progressive}, \ie, identify the specific generative model used to create a given image among N known models, while also being able to detect images from unknown models. Our solution for this scenario is shown in Fig.~\ref{fig:problem_setup}b. In this setup, the attributor could be provided with a gallery of images containing labeled samples from multiple known models. We use them to finetune the pre-trained feature extractor for more accurate fingerprint modeling, and then extract the averaged features for each known model as their fingerprints. Given a probe image, we compare its extract feature with the fingerprints of known models. If the similarity is higher than a threshold, the image is recognized as the model with the highest similarity. Otherwise, it is detected as from an unknown model. For evaluation, we follow ~\cite{yang2023progressive} to use accuracy and AUC to evaluate the attribution ability on known models and the discrimination ability between known/unknown models. We compare against five model attribution methods. They are PRNU~\cite{marra2019gans}, Yu \etal~\cite{yu2019attributing}, DCT-CNN~\cite{frank2020leveraging}, DNA-Det~\cite{yang2022aaai}, and POSE~\cite{yang2023progressive}. Most of them are proposed under a closed-set setup, we use their output confidences and calculate metrics following the routine of open-set recognition.

Fig.~\ref{fig:1vn_result}a and ~\ref{fig:1vn_result}b shows the open-set model identification accuracy and closed/open discrimination AUC along with dataset sizes. As seen, our method achieves superior open-set model identification performance with only 100 samples involved in training, which indicates that our fingerprint extractor could be easily transferred to modeling real generative models' fingerprints with few samples.

\inputtable{ablation}
\inputfigure{1vn_result}

\textbf{Model lineage analysis.}
Our fingerprint extractor also shows potential in analyzing the lineage between different versions of models based on their generated images. In Fig.~\ref{fig:1vn_result}c, we visualize the extracted features of various versions of stable diffusion models. The versions include sd-v1.1, v1.2, v1.3, v1.4, v2-base, v2, and v2.1. We can observe that the feature spaces of v1.\# versions and v2.\# versions overlap respectively. This alignment of feature spaces is consistent with the description of the relationship between these versions on the public website. Specifically, v1.2, v1.3, and v1.4 are resumed from v1.1, while v2 and v2.1 are resumed from v2-base.

