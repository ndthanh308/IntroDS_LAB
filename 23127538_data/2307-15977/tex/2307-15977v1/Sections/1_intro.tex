\section{Introduction}
\label{sec:intro}
In recent years, advanced generative modeling technologies have revolutionized various fields such as art creation, design, and human-computer interaction~\cite{nichol2021glide, ramesh2022hierarchical, rombach2022high, mj}. Despite their positive and beneficial applications, new concerns have arisen. On the one hand, copyrighted generative models can be copied and distributed, leading to potential copyright infringement issues. On the other hand, they can be utilized to generate illegal and malicious content, posing significant challenges to content moderation and social harm prevention. To address these issues, model attribution, \ie, the process of identifying the source model of generated content, has recently garnered increasing attention~\cite{marra2019gans,yu2019attributing,xuan2019scalable,yang2022aaai,bui2022repmix, yang2023progressive}.

Several studies~\cite{marra2019gans,yu2019attributing} confirmed that generative models could leave unique fingerprints on their output images. Further works demonstrated the feasibility of attributing generated images to a limited set of models~\cite{frank2020leveraging,xuan2019scalable,yang2022aaai,bui2022repmix}. Considering an unlimited number of unknown models in the open-world scenarios, recent works ~\cite{yang2023progressive, girish2021towards} began to consider solving model attribution in an open-set formalization. However, the problem of model attribution remains unsolved. Existing solutions are limited by the known/unknown unbalance issue in real-world scenarios, where only a limited number of known models could be sampled while the number of unknown models continues to grow. Furthermore, there was little effort put into investigating the cause of fingerprints of generative models, namely, how the fingerprints depend on the network's architecture and specific parameters. Understanding this is an important first step toward more effective model attribution algorithms.

Our interest in analyzing the problem is triggered by the observation that different generative models exhibit frequency pattern discrepancies on spectra. See Fig.~\ref{fig:intro}, the major differences lie in two aspects: 1) frequency distribution, where the magnitudes of high and low-frequency components differ across the spectra. 2) grid-like patterns with varying strengths and periodicity. Then we tend to give explanations for these frequential discrepancies by interpreting network components in the frequency domain. We discover that the element-wise multiplication of spectra with the convolution kernel leads to a uniform frequency distribution pattern in the high-frequency components. Grid-like patterns are derived by upsampling-induced spectrum replication, which are further modified by upsampling kernels. 
Throughout the generation process, frequency patterns from preceding blocks would be repeated by upsampling layers, accumulated layer by layer in a multiplication form with spectra of convolution filters, weakened or enhanced by activation and normalization layers, eventually forming the frequency pattern on output images. 

Leveraging the insights gained from our analysis, we seek to alleviate the known/unknown-unbalanced model attribution problem by constructing a variety of synthetic models that exhibit frequency patterns similar to genuine generative models, but at a much lower cost. Specifically, we leverage small generative blocks with varied architectures and parameters to simulate diverse frequency patterns. Based on our analysis of frequency pattern attenuation over generative blocks, these blocks could simulate prominent frequency patterns for many common generative models. We also synthesize diverse upsampling grids by noise-to-noise generators involving multiple deconvolution-based upsampling blocks. 

% \yty{we consider more attribution scenario} 
The fingerprint extractor pre-trained on the synthetic data in a metric learning framework shows superior transferability on various types of real CNN-based generative models, such as GAN, VAE, Flow, diffusion, and state-of-the-art Text2Image models. We explore its application in various attribution scenarios, including model verification, open-set model identification, and model lineage analysis. Experimental results show that the fingerprint extractor achieves over 95\% model verification accuracy on real generative models with only 10 samples, and superior open-set model identification performance with much fewer samples involved in training. The fingerprint extractor also exhibits the potential to link different versions of models with finetuning relationships.
 % and faster convergence speed
Our key contributions are as follows: \\
$\bullet$ We make the first attempt to investigate the formation of model fingerprints of CNN-based generative models in the frequency domain. \\
$\bullet$ We pioneer solving the known-unknown-unbalanced model attribution problem by pre-training on large-scale low-cost synthetic data in a metric-learning framework. \\ 
$\bullet$ Extensive evaluations demonstrate the superior transferability of the pre-trained fingerprint extractor in verifying, identifying, and analyzing the relationship of real CNN-based generative models.
\inputfigure{intro}
