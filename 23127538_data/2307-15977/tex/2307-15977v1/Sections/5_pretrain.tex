% \clearpage
\section{Pretrained fingerprint extractor based on synthetic data}

The above analysis provides insight into the generation process of two key components of model fingerprints: 1) Convolutional operations create uniform frequency patterns in the high-frequency region, which are repeated during upsampling, normalized and altered by normalization and nonlinear activation functions. 2) Upsampling layers cause frequency replication due to zero-interleaving in the spatial domain, resulting in grids in the multiplies of $1/2^{n}$ positions. These grids are most prominent in deconvolution-based generators. Leveraging these observations, we seek to alleviate the known/unknown unbalance problem in model attribution by constructing a large number of synthetic models that exhibit similar frequency patterns to real generative models. By training the fingerprint extractor on simulated data, we can achieve superior transferability to real generative models. 

\inputfigure{simulate_data}
\noindent \textbf{Frequency distribution pattern simulation.}
CNN-based generative models have become increasingly complex with numerous parameters. Simulating the exact frequency patterns left by each individual layer becomes a daunting task. Motivated by the frequency pattern attenuation phenomenon described in Sec.~\ref{sec:attenuation}, we propose to leverage generative blocks to simulate the essential characteristics in generated images, which allows us to strike a balance between computational efficiency and simulating the key frequency patterns. Fig.~\ref{fig:simulate_data}a shows the generative block. The input image is first downscaled by half using a pooling layer. Then, a convolutional layer is applied to increase the feature dimension. The output feature is then sent into a generative block commonly used in real generative models, whose architecture is determined by $\{L, S, U, A, N\}$. $L$ represents the number of convolutional layers in the block. $S$ refers to the order of activation and normalization relative to the convolution layer. $U$ is the upsampling operation that can be nearest neighbor upsampling, bilinear upsampling, or a stride 2 deconvolution layer. $A$ is the activation function that can be ReLU, Sigmoid, Tanh, or no activation. $N$ is the normalization type that can be batch normalization, instance normalization, or no normalization. We train 20 models with different training seeds using reconstruction loss and constrain the minimum reconstruction residual to 0.005, resulting in a total of 20x2x2x3x4x3=2880 models. Due to the simplicity of the reconstruction task, each model's training only takes seconds to minutes. We admit that the single-generative-block architecture may not perfectly replicate the fingerprints' complexity of real generative models, especially those that exhibit less high-frequency attenuation utilizing deconvolution as an upsampling layer. While it is rare for two models to have identical parameters in the last generative block, our solution enables the rough simulation of fingerprints.

\noindent \textbf{Grid pattern simulation.}
We use generators involving multiple deconvolution layers to simulate upsampling grids. See Fig.~\ref{fig:simulate_data}b, the generator contains several upsampling blocks, each composed of a deconvolution layer followed by a convolution layer. We employ a magnitude loss that minimizes the magnitude of the output noise to 0.005. These noise samples are then overlapped with real images, resulting in simulated images with upsampling grids. To ensure the diversity of simulated grids, we train 500 models for each architecture of the grid generators, with the block number varying from 3, 4, to 5. We neither directly use upsampled real images nor the output noise alone, as the former would produce very blur images and the latter would generate that are totally dissimilar to natural images and harms the transferability. Additionally, we refrain from using nearest or bilinear upsampling layers, as they are equipped with fixed upsampling kernels and are unable to produce highly diverse grids. We don't overlap the output noise from the grid generators with images output by frequency pattern generators, as this would introduce ``shortcuts" and prohibit the fingerprint extractor from differentiating each type of pattern. 
\inputtable{dataset}
\inputfigure{problem_setup}

\noindent \textbf{Spectrum visualization.}
In Fig.~\ref{fig:simulate_data}c, we show the averaged spectra of samples generated by different frequency distribution pattern generators and grid pattern generators. The spectra variance map in the last column demonstrates the differences between the two types of generators. The grid pattern generators exhibit diversity primarily within the grid regions, while the frequency distribution pattern generators show diversity throughout the entire spectrum.

\textbf{Training the fingerprint extractor.}
We build the synthetic data based on CelebA dataset~\cite{liu2015celeba}. For each real image in the dataset, the image is firstly randomly cropped to a size of $128\times128$ and fed into a randomly selected model from the synthetic model pool. The generated image is then transformed using DFT and the magnitude spectrum is sent to train the fingerprint extractor. We use ResNet50 as the backbone of the fingerprint extractor. The backbone is followed by a classification head and a projection head. The classification head employs a multi-class cross-entropy loss, which guides the classifier to identify the corresponding generator for the input image. The projection head is followed by a triplet loss, which encourages generated images from the same generator to be as similar as possible in the feature space while promoting a larger dissimilarity between images from different generators.


