\begin{thebibliography}{10}

\bibitem{nichol2021glide}
Nichol, A., P.~Dhariwal, A.~Ramesh, et~al.
\newblock Glide: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock In \emph{ICML}. 2021.

\bibitem{ramesh2022hierarchical}
Ramesh, A., P.~Dhariwal, A.~Nichol, et~al.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{rombach2022high}
Rombach, R., A.~Blattmann, D.~Lorenz, et~al.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{CVPR}. 2022.

\bibitem{mj}
Midjourney.
\newblock \url{https://www.midjourney.com}.

\bibitem{marra2019gans}
Marra, F., D.~Gragnaniello, L.~Verdoliva, et~al.
\newblock Do gans leave artificial fingerprints?
\newblock In \emph{MIPR}. 2019.

\bibitem{yu2019attributing}
Yu, N., L.~S. Davis, M.~Fritz.
\newblock Attributing fake images to gans: Learning and analyzing gan
  fingerprints.
\newblock In \emph{ICCV}. 2019.

\bibitem{xuan2019scalable}
Xuan, X., B.~Peng, W.~Wang, et~al.
\newblock Scalable fine-grained generated image classification based on deep
  metric learning.
\newblock \emph{arXiv preprint arXiv:1912.11082}, 2019.

\bibitem{yang2022aaai}
Yang, T., Z.~Huang, J.~Cao, et~al.
\newblock Deepfake network architecture attribution.
\newblock In \emph{AAAI}. 2022.

\bibitem{bui2022repmix}
Bui, T., N.~Yu, J.~Collomosse.
\newblock Repmix: Representation mixing for robust attribution of synthesized
  images.
\newblock In \emph{ECCV}. 2022.

\bibitem{yang2023progressive}
Yang, T., D.~Wang, F.~Tang, et~al.
\newblock Progressive open space expansion for open-set model attribution.
\newblock In \emph{CVPR}. 2023.

\bibitem{frank2020leveraging}
Frank, J., T.~Eisenhofer, L.~Sch{\"o}nherr, et~al.
\newblock Leveraging frequency analysis for deep fake image recognition.
\newblock In \emph{ICML}. 2020.

\bibitem{girish2021towards}
Girish, S., S.~Suri, S.~S. Rambhatla, et~al.
\newblock Towards discovery and attribution of open-world gan generated images.
\newblock In \emph{ICCV}. 2021.

\bibitem{liu2015celeba}
Liu, Z., P.~Luo, X.~Wang, et~al.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{ICCV}. 2015.

\bibitem{chandrasegaran2021closer}
Chandrasegaran, K., N.-T. Tran, N.-M. Cheung.
\newblock A closer look at fourier spectrum discrepancies for cnn-generated
  images detection.
\newblock In \emph{CVPR}. 2021.

\bibitem{durall2020watch}
Durall, R., M.~Keuper, J.~Keuper.
\newblock Watch your up-convolution: Cnn based generative deep neural networks
  are failing to reproduce spectral distributions.
\newblock In \emph{CVPR}. 2020.

\bibitem{schwarz2021frequency}
Schwarz, K., Y.~Liao, A.~Geiger.
\newblock On the frequency bias of generative models.
\newblock In \emph{NeurIPS}. 2021.

\bibitem{dzanic2020fourier}
Dzanic, T., K.~Shah, F.~Witherden.
\newblock Fourier spectrum discrepancies in deep network generated images.
\newblock In \emph{NeurIPS}. 2020.

\bibitem{khayatkhoei2022spatial}
Khayatkhoei, M., A.~Elgammal.
\newblock Spatial frequency bias in convolutional generative adversarial
  networks.
\newblock In \emph{AAAI}. 2022.

\bibitem{yu2020responsible}
Yu, N., V.~Skripniuk, D.~Chen, et~al.
\newblock Responsible disclosure of generative models using scalable
  fingerprinting.
\newblock In \emph{ICLR}. 2022.

\bibitem{yu2020artificial}
Yu, N., V.~Skripniuk, S.~Abdelnabi, et~al.
\newblock Artificial gan fingerprints: Rooting deepfake attribution in training
  data.
\newblock In \emph{ICCV}. 2021.

\bibitem{kim2020decentralized}
Kim, C., Y.~Ren, Y.~Yang.
\newblock Decentralized attribution of generative models.
\newblock In \emph{ICLR}. 2021.

\bibitem{oppenheim1999discrete}
Oppenheim, A.~V.
\newblock \emph{Discrete-time signal processing}.
\newblock Pearson Education India, 1999.

\bibitem{karras2020stylegan2}
Karras, T., S.~Laine, M.~Aittala, et~al.
\newblock Analyzing and improving the image quality of stylegan.
\newblock In \emph{CVPR}. 2020.

\bibitem{odena2016deconvolution}
Odena, A., V.~Dumoulin, C.~Olah.
\newblock Deconvolution and checkerboard artifacts.
\newblock \emph{Distill}, 1(10), 2016.

\bibitem{wojna2019devil}
Wojna, Z., V.~Ferrari, S.~Guadarrama, et~al.
\newblock The devil is in the decoder: Classification, regression and gans.
\newblock \emph{IJCV}, 127(11):1694--1706, 2019.

\bibitem{pan2022learning}
Pan, H.
\newblock Learning convolutional neural networks in frequency domain.
\newblock \emph{arXiv preprint arXiv:2204.06718}, 2022.

\bibitem{ayat2019spectral}
Ayat, S.~O., M.~Khalil-Hani, A.~A.-H. Ab~Rahman, et~al.
\newblock Spectral-based convolutional neural network without multiple
  spatial-frequency domain switchings.
\newblock \emph{Neurocomputing}, 364:152--167, 2019.

\bibitem{karras2021alias}
Karras, T., M.~Aittala, S.~Laine, et~al.
\newblock Alias-free generative adversarial networks.
\newblock In \emph{NeurIPS}. 2021.

\bibitem{karras2017progressive}
Karras, T., T.~Aila, S.~Laine, et~al.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock In \emph{ICLR}. 2018.

\bibitem{binkowski2018MMD}
Bi≈Ñkowski, M., D.~J. Sutherland, M.~Arbel, et~al.
\newblock Demystifying {MMD} {GAN}s.
\newblock In \emph{ICLR}. 2018.

\bibitem{zhang2019self}
Zhang, H., I.~Goodfellow, D.~Metaxas, et~al.
\newblock Self-attention generative adversarial networks.
\newblock In \emph{ICML}. 2019.

\bibitem{lee2021infomax}
Lee, K.~S., N.-T. Tran, N.-M. Cheung.
\newblock Infomax-gan: Improved adversarial image generation via information
  maximization and contrastive learning.
\newblock In \emph{WACV}. 2021.

\bibitem{choi2018stargan}
Choi, Y., M.~Choi, M.~Kim, et~al.
\newblock Stargan: Unified generative adversarial networks for multi-domain
  image-to-image translation.
\newblock In \emph{CVPR}. 2018.

\bibitem{he2019attgan}
He, Z., W.~Zuo, M.~Kan, et~al.
\newblock Attgan: Facial attribute editing by only changing what you want.
\newblock \emph{TIP}, 28(11):5464--5478, 2019.

\bibitem{karras2019style}
Karras, T., S.~Laine, T.~Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In \emph{CVPR}. 2019.

\bibitem{brock2018large}
Brock, A., J.~Donahue, K.~Simonyan.
\newblock Large scale {GAN} training for high fidelity natural image synthesis.
\newblock In \emph{ICLR}. 2019.

\bibitem{luvcic2019high}
Lu{\v{c}}i{\'c}, M., M.~Tschannen, M.~Ritter, et~al.
\newblock High-fidelity image generation with fewer labels.
\newblock In \emph{ICML}. 2019.

\bibitem{kang2020contragan}
Kang, M., J.~Park.
\newblock Contragan: Contrastive learning for conditional image generation.
\newblock In \emph{NeurIPS}. 2020.

\bibitem{kingma2013auto}
Kingma, D.~P., M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{ICLR}. 2014.

\bibitem{higgins2017beta}
Higgins, I., L.~Matthey, A.~Pal, et~al.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock In \emph{ICLR}. 2017.

\bibitem{burgess2018understanding}
Burgess, C.~P., I.~Higgins, A.~Pal, et~al.
\newblock Understanding disentangling in beta-vae.
\newblock In \emph{NIPS workshop}. 2017.

\bibitem{zhao2017infovae}
Zhao, S., J.~Song, S.~Ermon.
\newblock Infovae: Information maximizing variational autoencoders.
\newblock \emph{arXiv preprint arXiv:1706.02262}, 2017.

\bibitem{kingma2018glow}
Kingma, D.~P., P.~Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In \emph{NeurIPS}. 2018.

\bibitem{chen2019residual}
Chen, R.~T., J.~Behrmann, D.~K. Duvenaud, et~al.
\newblock Residual flows for invertible generative modeling.
\newblock In \emph{NeurIPS}. 2019.

\bibitem{dhariwal2021diffusion}
Dhariwal, P., A.~Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock In \emph{NeurIPS}. 2021.

\bibitem{ho2020denoising}
Ho, J., A.~Jain, P.~Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In \emph{NeurIPS}. 2020.

\bibitem{liu2022pseudo}
Liu, L., Y.~Ren, Z.~Lin, et~al.
\newblock Pseudo numerical methods for diffusion models on manifolds.
\newblock In \emph{ICLR}. 2022.

\bibitem{dalle-mini}
Dall-e mini.
\newblock \url{https://github.com/borisdayma/dalle-mini}.

\bibitem{hudson2021generative}
Hudson, D.~A., L.~Zitnick.
\newblock Generative adversarial transformers.
\newblock In \emph{ICML}. 2021.

\bibitem{zhang2022styleswin}
Zhang, B., S.~Gu, B.~Zhang, et~al.
\newblock Styleswin: Transformer-based gan for high-resolution image
  generation.
\newblock In \emph{CVPR}. 2022.

\bibitem{park2022styleformer}
Park, J., Y.~Kim.
\newblock Styleformer: Transformer based generative adversarial networks with
  style vector.
\newblock In \emph{CVPR}. 2022.

\bibitem{jiang2021transgan}
Jiang, Y., S.~Chang, Z.~Wang.
\newblock Transgan: Two pure transformers can make one strong gan, and that can
  scale up.
\newblock In \emph{NeurIPS}. 2021.

\end{thebibliography}
