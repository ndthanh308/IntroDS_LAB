\section{Introduction}
\label{sec:intro}

In recent years, advanced generative modeling technologies have revolutionized various fields such as art creation, design, and human-computer interaction. While new concerns have arisen along with their positive and beneficial applications. On the one hand, generative models can be copied and distributed, leading to potential copyright infringement issues. On the other hand, they can be utilized to generate illegal and malicious content, posing significant challenges to content moderation and social harm prevention. To address these issues, model attribution, \ie, the process of identifying the source model of generated content, has recently garnered increasing attention~\cite{marra2019gans,yu2019attributing,xuan2019scalable,yang2022aaai,bui2022repmix, yang2023progressive}.

Several studies~\cite{marra2019gans,yu2019attributing} confirmed that generative models are like cameras that can leave unique fingerprints on their output images. Further works demonstrated the feasibility of attributing generated images to a fixed set of models~\cite{frank2020leveraging,xuan2019scalable,yang2022aaai,bui2022repmix} and recognizing images as from unseen models~\cite{yang2023progressive}. However, most of these methods are limited by the image data collected from a few generative models, thereby cannot easily generalize to attributing images to any unknown model. Furthermore, there was little effort put into investigating the cause of model fingerprints in generative models, namely, how the fingerprints depend on the network's architecture and specific parameters. We believe that understanding the underlying mechanism of fingerprint formation would be a primary step toward designing generalizable and data-efficient model attribution algorithms. Thereby, we look into the building blocks of CNN-based generative models to analyze the model fingerprint and propose a novel model attribution method that relies only on synthetic data to train and performs better on model verification and open-set identification tasks.
% \wdd{Cite author's name} 
% ~\cite{frank2020leveraging} also found that the frequency spectrum contains rich information about model fingerprints. 
% , as image convolution can be replaced by straightforward element-wise multiplication based on theorems of signal processing. 
% The analysis is verified on individual generative components and real generative models. The experiment shows the consistency between the visualized model fingerprints and the fingerprints calculated through model architecture and parameters.

This paper first investigates the formation process of model fingerprints, namely, the unique characteristics or patterns in a generated image, which differentiate its source model from other generative models. To better understand the cause of model fingerprints, we analyze them in the frequency domain because spectra can manifest visually imperceptible patterns of the spatial domain, and based on theorems in signal processing ~\cite{oppenheim1999discrete} image convolution can be implemented as straightforward element-wise multiplication of spectra. Through the analysis, we observe that in a CNN-based generative model, the element-wise multiplication of convolution kernels spectra can lead to a uniform frequency pattern in the high-frequency region regardless of input latent codes. \wdd{Add an example. This should be your Figure 1.} This uniform pattern repeats by upsampling layers, accumulated layer by layer in a multiplication form based on the parameters of each convolution layer and upsampling kernel, weakened or enhanced by activation and normalization layers, eventually forming the frequency pattern on output images. Our findings shed light on how model fingerprints forms in CNN-based generative models and inform the design of model attribution algorithms.  

%Another part of model fingerprints is the spectrum grid in multiples of $1/2^{n}$ positions caused by upsampling-induced spectrum replication, where $n$ is the number of upsampling layers. Due to the learnable upsampling kernel without specific constraints, deconvolution produces stronger grids than nearest and bilinear upsampling. The analysis also gives explanations for some commonly discussed empirical observations that nearest and bilinear produce fewer artifacts than deconvolution. \wdd{This paragraph is out of place here.}

% The analysis also gives explanations for some empirical observations. \yty{One such commonly discussed empirical observation is that nearest and bilinear produce fewer artifacts than deconvolution. Our analysis owing this to the upsampling kernel's difference.}
% the up+conv form of upsampling produces fewer artifacts compared to deconvolution. This potentially indicates how to reduce artifacts. 
Furthermore, existing works on model attribution suffer from the known/unknown unbalance problem in real-world scenarios. Only a limited number of models could be sampled whereas an unlimited number of models remain unknown. Additionally, copyright issues and the complexity of crawling further complicate the data collection process. Leveraging the insights gained from the aforementioned analysis, we seek to alleviate this problem by constructing a large number of synthetic models that exhibit similar frequency patterns to real generative models, but at a much lower cost. Specifically, we leverage generative blocks with varied architectures and parameters to simulate diverse frequency patterns. Based on the analysis of high-frequency attenuation over generative blocks, these blocks could simulate prominent frequency patterns for many common generative models. Besides, diverse upsampling grids are simulated by noise-to-noise generators involving multiple deconvolution-based upsampling blocks. 

The fingerprint extractor pre-trained on the synthesis data shows superior transferability on real CNN-based generative models including GAN, VAE, Flow, and diffusion models in model verification and open-set model identification scenarios. Experimental results show that the fingerprint extractor achieves over 95\% model verification accuracy on real generative models with only 10 samples, and superior open-set model identification performance with much fewer samples involved in training and faster convergence speed. The fingerprint extractor also exhibits potential in linking different versions of models with finetuning relationships.

Our key contributions are as follows: \\
% $\bullet$ \textbf{Understanding the cause of model fingerprints:} We show that the pointwise multiplication with the spectrum of convolution and the upsampling kernel can lead to a uniform frequency pattern in the high-frequency region on the generated images. \\
$\bullet$ We make the first attempt to investigate how model fingerprints form in CNN-based generative models in the frequency domain. \\
$\bullet$ Our method opens the door to modeling fingerprints of generative models by pre-training on low-cost synthetic data. \\
$\bullet$ Extensive evaluations validate that the pre-trained fingerprint extractor shows superior transferability in verifying, identifying, and analyzing the relationship of real CNN-based generative models.

% We show that the pointwise multiplication with the spectrum of convolution and the upsampling kernel can lead to a uniform frequency pattern in the high-frequency region on the generated images. \\
% The value of this is that generated images of real generative models could be collected with limited amounts and numerous costs.