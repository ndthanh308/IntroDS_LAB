
% \inputfigure{fingerprint_vis}
% \inputfigure{fingerprint_vis_conv}
% We can observe that the frequency components of the real image are mostly in the low-frequency region (four corners of the image), and after convolution, the high-frequency region has obvious components. After high-pass filtering, this part of the component becomes more apparent and close to the convolution kernel's frequency spectrum. These findings indicate that convolution adds components similar to the convolution kernel's frequency spectrum in the high-frequency region of the image. 

% 高频区域能够突显出痕迹 % 为什么会出现这样的可视化的结果？更具体的，什么是模型指纹 
% 类比PRNU，PRNU表现在图像上也是乘性噪声 % 归纳推理
% This conclusion also applies to the feature maps inside the generative model. 
% 不同噪声输入网络中，特征图的频谱方差不大；为什么方差不大，归纳推理；那如果是生成语义差异很大的内容呢？

\subsection{How frequency transformation producedure leaves fingerprints.} 
In the following \wdd{section}, we demonstrate how frequency domain transformation of network components produces uniform fingerprints in the generated images. We first consider the convolutional layer. 
% For N convolutional layers with $3\times3\times3\times3$ kernels that reconstruct an input RGB image with very small residual noise. We observe that it is easy to train a N-way CNN classifier to determine a convolved image belongs to which convolutional layer, which means even convolutional layers with different parameters leave different fingerprints on the convolved images. To investigate how convolutional layers leave fingerprints in the frequency domain,
We show in Figure~\ref{fig:cause_of_fingerprint} (a-c) the averaged DFT spectrum (not shifted) of the R channel of 1000 celebA images, convolved celebA images (each row represents a convolution layer), and high-pass filtered convolved images. Figure~\ref{fig:cause_of_fingerprint} (d) shows the averaged DFT spectrum of three zero-padded convolution kernels related to the R channel. It's \wdd{Don't use contraction in academic writing.} evident that the artifacts of convolution layers are visible in the average maps and become dominant after high-pass filtering, and show consistency with the average spectrum of convolution kernels. We also verified \wdd{Be consistent in tense. Here it should be present tense.} the universality of high-frequency features in every single image by calculating the similarity between the high-frequency spectrum of convolved images and the averaged spectrum of convolutional kernels, reaching an average of 0.85 cosine similarity. This further confirms that the convolutional layer leaves uniform high-frequency artifacts on each image.

It's evident that the high-frequency artifacts are caused by the pointwise multiplication with convolution kernel spectrums. According to Eq.~\ref{eq:eq_conv}, for each output channel of the convolved image, its frequency spectrum equals to the sum of the frequency spectra of the input channels multiplied by that of the corresponding convolution kernel. According to~\cite{baradad2021learning, baek2022commonality}, the magnitude of the Fourier transform of many natural images follows a heavy-tailed power law, $1 /(\left|f_x\right|^a+\left|f_y\right|^b)$ with $a$ and $b$ being two random numbers uniformly sampled in the range $[0.5, 0.35]$, which also applies to features of neural networks. Thus, the high-frequency magnitude usually has a small variance, resulting in the high-frequency spectrum of convolved images exhibiting a shape that resembles the averaged convolution kernel spectrum. 

We have discussed above that upsampling operation in the frequency domain could be summarized as replicating the frequency spectrum of the input signal and pointwise multiplication with the upsampling kernel's spectrum. The fingerprints of the input signal undergo a similar process as well, \ie, repeat first and multiplied by the artifacts of the upsampling kernel's spectrum. Normalization and nonlinear activation functions transform the frequency artifacts as they transform the input spectrum.

\paragraph{Fingerprints are in high-frequency regions}
% 抽出图像高频，还原出来看不出来语义，但是分类准确率很高

\inputfigure{cause_of_fingerprint}

\subsection{Fingerprint visualization}
\noindent \textbf{Visualization tool.} To verify the above analysis, we adopt a simple visualization method by extracting the weight vector of the regression classifier trained on DFT spectrums of images generated by different networks. As the weight vector connects all frequency components to the class labels, each part of the weight represents which frequency components are used for classifying to the corresponding category.

% As the formation process of each channel in the output image is similar, we only extract the output image of the first R channel for fingerprint visualization. 
\noindent \textbf{Convolution.} 
We first train $N$ networks varying the initialization seed, which are made of $3\times3\times k \times k$ kernels that reconstruct an input RGB image with very small residual noise. It's depicted in Figure~\ref{fig:} the visualized fingerprints of a single output channel and averaged DFT spectrums of kernel weights associated with the output channel, which exhibit a consistency as expected. Increasing the kernel size results in more complicated fingerprints. 

\noindent \textbf{Upsampling} 
We visualize the fingerprints of ``Conv+Up`` blocks reconstructing the input image with different upsampling types. Accordingly, we also plot the spectrum transform process. As shown in Figure~\ref{fig:}, the fingerprints of ``Conv+Up`` blocks show consistency with the spectrum. We could also observe the difference between different upsampling types. 
% 多层upsampling+conv，发现会在输出图像上产生grid

% \inputfigure{conv_act_norm}
\noindent \textbf{Normalization and activation functions.} We visualize the fingerprints "Conv+Norm" and "Conv+Act" blocks with different normalization and activation types in Figure~\ref{fig:}. As seen, different types of activation and normalization with different parameters shrink or amplify the fingerprints without influencing the distribution.
% 解释为什么有的反转了
% 解释为什么一次项站主要地位

\noindent \textbf{Skip connection.} 

\noindent \textbf{Explanation on spectrums of generated images.}

% \section{Analysis on model fingerprints.}
% \subsection{Model fingerprint discrepancy of different models.}
% \subsection{Architecture vs. parameter fingerprints.}
% \subsection{Fingerprints of untrained and trained models.}

% \subsection{Are model fingerprints globally-consistent?}
% \subsection{Locality and globality of model fingerprints}
% patch分类 % patch引入到方法里面？

% \subsection{Fingerprint decay phenomenon}
% 经证明指纹多集中在高频，那么画出每层输出特征的高频分量的变化
% 训练几个CelebA的模型，采用nearest上采样，量化decay




