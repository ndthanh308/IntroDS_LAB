% \section{Discussion on the characteristics of model fingerprints.}
% some not agreed conclusions mentioned before
% \noindent \textbf{Fingerprints are globally consistent.}
% \section{How discriminator influences model fingerprints.}
% \section{How active fingerprints are injected into generative models.}
% 看看artificial fingerprints的review
% On the other hand, in my opinion, studying and exploring how and how well the fingerprints can be learned by GANs is a more valuable contribution. If there exist some fingerprints that cannot be learned or be transfer to GAN generated images. And what the GAN will perform if we use mixed training data with different fingerprints to train it. Answering/exploring these questions may help us to solve deepfake attribution problems.
% I am curious that at what stage were the fingerprints learned when training GAN? Does the GAN model first learn how to generate images, and then learn how to generate fingerprints? Or the GAN learn to generate fingerprints and images at the same time? It is interesting because although fingerprints are almost invisible to human, they are easy to distinguish for CNN. What if a plot is provided to show when the fingerprints are embedded?
% \section{Application2: perturbation robust artifical fingerprints.}
% \section{Model fingerprint discrepancy of different architectures.}

% \inputfigure{fingerprint_decay}
% \clearpage
\section{Pretrained fingerprint extractor based on synthetic data}
The above analysis provides insight into the generation process of two key components of model fingerprints: 1) Convolutional operations create uniform frequency patterns in the high-frequency region, which are repeated during upsampling, normalized by normalization, and altered by nonlinear activation functions. 2) Upsampling layers cause frequency replication due to zero-interleaving in the spatial domain, resulting in grids in the $1/2^{n}$ positions. These grids are most prominent in deconvolution-based generators. See Figure~\ref{fig:simulate_data}(a) for the two components. Images of real generative models could be collected with limited amounts, copyright issues, and cumbersome crawling. To create a generalized fingerprint extractor, we thus leverage these observations to generate a large amount of synthetic data with similar frequency patterns as real generative models, but at a much lower cost. By training the fingerprint extractor on simulated data, we can achieve superior transferability to real generative models. 

% 经证明指纹多集中在高频，那么画出每层输出特征的高频分量的变化
% 训练几个CelebA的模型，采用nearest上采样，量化decay
% 分析生成图像的频谱主要包括两个部分组成：1) 卷积pattern 2)
% cnn becomes more complex -> hard to consider all layer parameters -> upsampling would cause frequency pattern attenuation -> generation by generative blocks.
% It is daunting to consider all these parameters. Considering the architecture of generative blocks, they are always based on the same architecture. 
% \subsection{Data synthesis}

 % and compensate for the complexity with larger convolution kernel sizes
\inputfigure{attenuation_case_curve}
\noindent \textbf{Frequency pattern simulation.}
CNN-based generative models have become increasingly complex with numerous parameters. Simulating the exact frequency patterns left by each individual layer becomes a daunting task.
To address this challenge, our solution is to leverage generative blocks to simulate the essential characteristics in generated images, which allows us to strike a balance between computational efficiency and simulating the key frequency patterns. 
 % \yty{The attenuation rates are [] and [] respectively. check how to calculate filter's attenuation rate}.
The motivation is from the high-frequency attenuation over generative blocks. As shown in Figure~\ref{fig:conv_up}, interpolation upsamplers such as nearest neighbor and bilinear would cause strong high-frequency attenuation due to their low-pass upsampling filters. Generators like StyleGAN3~\cite{karras2021alias} even design low-pass filters with larger attenuation to suppress aliasing. All these operations would filter out many high-frequency frequency patterns produced by previous generative blocks.

Figure~\ref{fig:attenuation_case_curve} gives an intuitive illustration for the attenuation. Figure~\ref{fig:attenuation_case_curve}(a) shows the last two blocks $\mathbf{b_{128}}$ and $\mathbf{b_{256}}$ of a StyleGAN2~\cite{karras2020stylegan2} $256\times256$ face generator. Each block increases the resolution by two and contains a Biliner Up+Conv0 layer and a Conv1 layer. We visualize the averaged spectrum of three output channels (column marginal) along the input channels of three convolutional layers (row marginal) in Figure~\ref{fig:attenuation_case_curve}(b)(d)(f), and the spectrum of output features by these output channels in Figure~\ref{fig:attenuation_case_curve}(c)(e)(g). We could notice the output features' spectrum of b128.conv1 shares similar patterns with the spectrum of convolution kernels on the left. However, after the Upsample and Conv0 layer, the patterns are largely attenuated and show again as the shape of Conv1's spectrum after another convolution layer. This phenomenon validates our analysis that bilinear upsampling layers would cause high-frequency attenuation and thus suppress frequency patterns produced by previous layers. 

\inputfigure{simulate_data}
\inputfigure{spectrum_vis}

Figure~\ref{fig:attenuation_case_curve}(h) further qualifies the high-frequency component variation throughout the generation process. X-axis means every network component in the sequence of generation, and y-axis means the proportion of high frequencies of feature maps output by each component, which is calculated as the ratio of the sum of values in the latter half of the azimuthal integral spectrum~\cite{durall2020watch} to the sum of all values. 
As seen, up\_conv stably suppress high-frequency components in each generative block.
% Activation and normalization functions compress or enhance as expected in our   
% We show another case of a SNGAN~\cite{zhang2019self} generator using nearest neighbor upsampling layers. 
% \inputfigure{stylegan2_decay}

% \noindent \textbf{Frequency pattern simulation based on generative block.} 
The high-frequency attenuation phenomenon indicates that the last generative block would play a prominent role in producing model fingerprints for common generators with low-pass upsampling kernels. Motivated by this, we propose a fingerprint synthesizing strategy based on generative blocks. Figure~\ref{fig:simulate_data}(b) shows the generative block. The input image is first downscaled by half using a pooling layer. Then, a convolutional layer is applied to increase the feature dimension. The output feature is then sent into a generative block commonly used in real generative models, whose architecture is determined by $\{L, S, U, A, N\}$. $L$ represents the number of convolutional layers in the block. $S$ refers to the order of activation and normalization relative to the convolution layer. $U$ is the upsampling operation that can be nearest neighbor upsampling, bilinear upsampling, or a stride 2 deconvolution layer. $A$ is the activation function that can be ReLU, Sigmoid, Tanh, or no activation. $N$ is the normalization type that can be batch normalization, instance normalization, or no normalization. We train 20 models with different training seeds using reconstruction loss and constrain the minimum reconstruction residual to 0.005, resulting in a total of 20x2x2x3x4x3=2880 models. Due to the simplicity of the reconstruction task, each model's training only takes seconds to minutes. We admit that the single-generative-block architecture may not perfectly replicate the fingerprints' complexity of real generative models, especially those that exhibit less high-frequency attenuation utilizing deconvolution as an upsampling layer. While it is rare for two models to have identical parameters in the last generative block, our solution enables the rough simulation of fingerprints.

% We compensate for these by increasing the kernel size of convolutional layers. As seen in Figure~\ref{}, a larger kernel size brings more complex frequency patterns on input signals. Training each model only takes seconds. 
% with heavy high-frequency artifacts 

\noindent \textbf{Upsampling gird simulation.}
Apart from the frequency patterns derived from convolution operations, grids in $1/2^{n}$ positions are also obvious patterns for model fingerprinting, which are a result of spectrum replication by upsampling layers, and polished by filters throughout the generation process. We thus use generators involving multiple deconvolution layers to simulate upsampling grids. 
See Figure~\ref{fig:simulate_data}(c), the generator contains several upsampling blocks, each composed of a deconvolution layer followed by a convolution layer. We employ a magnitude loss that minimizes the magnitude of the output noise to 0.005. These noisy samples are then overlapped with real images, resulting in simulated images with upsampling grids. To ensure the diversity of simulated grids, we train 500 models for each architecture of the grid generators, with the block number varying from 3, 4, to 5. We neither directly use upsampled real images nor the output noise alone, as the former would produce very blur images and the latter would generate that are totally dissimilar to natural images and harms the transferability. Additionally, we refrain from using nearest or bilinear upsampling layers, as they are equipped with fixed upsampling kernels and are unable to produce highly diverse grids. We don't overlap the output noise from the grid generators with images output by frequency pattern generators, as this would introduce ``shortcuts" and prohibit the fingerprint extractor from differentiating each type of pattern. 
\inputtable{dataset}
\inputfigure{problem_setup}

\noindent \textbf{Spectrum visualization.}
Figure~\ref{fig:spectrum_vis} displays the averaged spectra of samples generated by real generative models, frequency pattern generators, and upsampling grid generators. The spectra variance map obtained from all data of three types of generators is presented in the last column. It can be observed that the spectrum diversity exhibited by upsampling grid generators primarily exists within the grid regions, while the diversity observed in frequency pattern generators encompasses the spectrum.

% The magnitude loss is key 
% DFT magnitude spectrums of samples from different generators are shown in Figure~\ref{fig:}. As seen, different upsampling times results in different grid distribution. 
% Figure~\ref{fig:simulate_data}(b)(c) visualizes the frequency patterns of generated images of simulated data and real generated images. 

\textbf{Training the fingerprint extractor.}
We build the synthetic data based on CelebA dataset~\cite{liu2015celeba}. For each real image in the dataset, we fed it into a randomly selected model from the synthetic model pool. The generated image is then transformed using DFT and the magnitude spectrum is sent to train the fingerprint extractor. We use ResNet50 as the backbone of the fingerprint extractor. The backbone is followed by a classification head and a projection head. The classification head employs a multi-class cross-entropy loss, which guides the classifier to identify the corresponding generator for the input image. The projection head is followed by a triplet loss, which encourages generated images from the same generator to be as similar as possible in the feature space while promoting a larger dissimilarity between images from different generators.


