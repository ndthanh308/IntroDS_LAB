

\begin{restatable}[\textbf {Complexity of Decreasing Stepsize BBVI with STL}]{theorem}{prAtEndRestatexix}\label{thm:prAtEndxix}\label {thm:projsgd_bbvistl_decstepsize_complexity} The last iterate \(\vlambda _T \in \Lambda _L\) of BBVI with the STL estimator and projected SGD with a decreasing stepsize schedule applied to a \(\mu \)-strongly log-concave and \(L\)-log-smooth posterior satisfy \(\norm { \vlambda _T - \vlambda ^* }_2^2 \leq \epsilon \) if \begin {align*} T \geq 32 \kappa ^2 \left (d + k_{\varphi }\right ) \Bigg ( &\frac { \sqrt { \mathrm {D}_{\mathrm {F}^4}\left (q_{\vlambda ^*},\pi \right ) } }{ L^2 } \frac {1}{\epsilon } + \frac {1}{\sqrt {2}} \sqrt { \norm {\vlambda _0 - \vlambda ^*}_2 } \, \frac { {\left ( \mathrm {D}_{\mathrm {F}^4}\left (q_{\vlambda ^*},\pi \right ) \right )}^{1/4} }{ L } \, \frac {1}{\epsilon ^{3/4}} + \norm {\vlambda _0 - \vlambda ^*}_2 \frac {1}{\sqrt {\epsilon }} \Bigg ), \end {align*} for some decreasing stepsize schedule \(\gamma _1 \geq \ldots \geq \gamma _T\), where \(\kappa = L / \mu \) is the condition number and \(\vlambda ^* \in \Lambda \) is the optimal variational parameter.\end{restatable}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxix}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxix{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof]\phantomsection\label{proof:prAtEndxix}\label {proof:projsgd_bbvistl_decstepsize_complexity} As shown by \cref {thm:stl_upperbound}, the STL estimator satisfies an adative QV bound with the constants \begin {align*} \alpha _{\mathrm {STL}} &= 2 \left (d + k_{\varphi }\right ) \left (2 + \delta \right ) L^2 = 4 L^2 \left (d + k_{\varphi }\right ) \left (1 + \frac {1}{2}\delta \right ) \\ \beta _{\mathrm {STL}} &= \left (2 d + k_{\varphi }\right ) \left (1 + 2 \delta ^{-1}\right ) \sqrt {\mathrm {D}_{\mathrm {F}^4}\left (q_{\vlambda ^*}, \pi \right )}. \end {align*} Furthermore, for a \(\mu \)-strongly log-concave posterior and our variational parameterization,~\citet [Theorem 9]{domke_provable_2020} show that the ELBO is \(\mu \)-strongly convex. Thus, we can invoke \cref {thm:projsgd_stronglyconvex_decstepsize_adaptive_complexity} with \begin {align*} \widetilde {\alpha } = 4 L^2 \left (d + k_{\varphi }\right ), \qquad \widetilde {\beta } = \left (2 d + k_{\varphi }\right ) \sqrt { \mathrm {D}_{\mathrm {F}^4}\left (q_{\vlambda ^*}, \pi \right ) }, \qquad \text {and}\qquad C = \frac {1}{2}. \end {align*} This yields a lower bound on the number of iteration: \begin {align*} & \frac {16 \widetilde {\beta } }{ \mu ^2 } \frac {1}{\epsilon } + \frac {16 \sqrt {2}}{ \mu ^2 } \sqrt { \norm {\vlambda _0 - \vlambda ^*}_2 } \, \sqrt { \widetilde {\alpha } \widetilde {\beta } } \, \frac {1}{\epsilon ^{3/4}} + \frac {8 \widetilde {\alpha } \, \norm {\vlambda _0 - \vlambda ^*}_2 }{ \mu ^2} \frac {1}{\sqrt {\epsilon }} \\ &= \frac {16 \left (2 d + k_{\varphi }\right ) \sqrt { {D}_{\mathrm {F}^4}^* } }{ \mu ^2 } \frac {1}{\epsilon } + \frac {16 \sqrt {2}}{ \mu ^2 } \sqrt { \norm {\vlambda _0 - \vlambda ^*}_2 } \, \sqrt { 4 L^2 \left (d + k_{\varphi }\right ) \left (2 d + k_{\varphi }\right ) \sqrt { {D}_{\mathrm {F}^4}^* } } \, \frac {1}{\epsilon ^{3/4}} \\ &\qquad + \frac {32 L^2 \left (d + k_{\varphi }\right ) \, \norm {\vlambda _0 - \vlambda ^*}_2 }{ \mu ^2} \frac {1}{\sqrt {\epsilon }}, \shortintertext {using the the trivial bound \(2 d + k_{\varphi } < 2 d + 2 k_{\varphi }\),} &< \frac {32 \left (d + k_{\varphi }\right ) \sqrt { {D}_{\mathrm {F}^4}^* } }{ \mu ^2 } \frac {1}{\epsilon } + \frac {16 \sqrt {2}}{ \mu ^2 } \sqrt { \norm {\vlambda _0 - \vlambda ^*}_2 } \, \sqrt { 8 L^2 \left (d + k_{\varphi }\right ) \left (d + k_{\varphi }\right ) \sqrt { {D}_{\mathrm {F}^4}^* } } \, \frac {1}{\epsilon ^{3/4}} \\ &\qquad + \frac {32 L^2 \left (d + k_{\varphi }\right ) \, \norm {\vlambda _0 - \vlambda ^*}_2 }{ \mu ^2} \frac {1}{\sqrt {\epsilon }}, \shortintertext {pulling out the \(32 \left (d + k_{\varphi }\right ) L^2 / \mu ^2\) factors,} &= 32 \frac {L^2}{\mu ^2} \left (d + k_{\varphi }\right ) \left ( \frac { \sqrt { {D}_{\mathrm {F}^4}^* } }{ L^2 } \frac {1}{\epsilon } + \frac {1}{\sqrt {2}} \sqrt { \norm {\vlambda _0 - \vlambda ^*}_2 } \, \frac { {\left ({D}_{\mathrm {F}^4}^*\right )}^{1/4} }{ L } \, \frac {1}{\epsilon ^{3/4}} + \norm {\vlambda _0 - \vlambda ^*}_2 \frac {1}{\sqrt {\epsilon }} \right ) \\ &= 32 \kappa ^2 \left (d + k_{\varphi }\right ) \left ( \frac { \sqrt { D_{\mathrm {F}^4}^* } }{ L^2 } \frac {1}{\epsilon } + \frac {1}{\sqrt {2}} \sqrt { \norm {\vlambda _0 - \vlambda ^*}_2 } \, \frac { {\left (D_{\mathrm {F}^4}^*\right )}^{1/4} }{ L } \, \frac {1}{\epsilon ^{3/4}} + \norm {\vlambda _0 - \vlambda ^*}_2 \frac {1}{\sqrt {\epsilon }} \right ), \end {align*} where we have denoted \(D_{\mathrm {F}^4}^* = \mathrm {D}_{\mathrm {F}^4}\left (q_{\vlambda ^*},\pi \right )\). \par Also, the optimal \(\delta \) is given as \begin {align*} \delta &= \frac { \sqrt { \norm {\vlambda _0 - \vlambda ^*}_2 } \, \epsilon ^{1/4} \, \sqrt {\widetilde {\alpha }} }{ \sqrt {2} \, C \sqrt {\widetilde {\beta }} } \\ &= \frac { \sqrt { \norm {\vlambda _0 - \vlambda ^*}_2 } \, \epsilon ^{1/4} \, \sqrt {4 L^2 \left (d + k_{\varphi }\right )} }{ 2^{-1} \, \sqrt {2} \sqrt { \left (2 d + k_{\varphi }\right ) \sqrt { D_{\mathrm {F}^4}^* } } } \\ &= 2 \sqrt {2} L \sqrt { \norm {\vlambda _0 - \vlambda ^*}_2 } \, \sqrt {\frac {d + k_{\varphi }}{2 d + k_{\varphi }}} \, {\left (D_{\mathrm {F}^4}^*\right )}^{-1/2} \, \epsilon ^{1/4} \\ &= 2 \sqrt {2} L \, \sqrt { \frac { \norm {\vlambda _0 - \vlambda ^*}_2 }{ \mathrm {D}_{\mathrm {F}^4}\left (q_{\vlambda ^*},\pi \right ) } } \sqrt {\frac {d + k_{\varphi }}{2 d + k_{\varphi }}} \, \epsilon ^{1/4}. \end {align*}\end{proof}
