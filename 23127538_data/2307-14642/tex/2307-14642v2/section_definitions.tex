
\subsection{Definitions}\label{section:definitions}

\begin{definition*}[\textbf{\(L\)-Smoothness}]
  A function \(f : \mathcal{X} \to \mathbb{R}\) is \(L\)-smooth if it satisfies
  \[
    \norm{ \nabla f\left(\vx\right) - \nabla f\left(\vy\right) }_2 \leq L \norm{ \vx - \vy }_2
  \]
  for all \(\vx, \vy \in \mathcal{X}\) and some \(L > 0\).
\end{definition*}

\begin{definition*}[\textbf{\(\mu\)-Strong Convexity}]
  A function \(f : \mathcal{X} \to \mathbb{R}\) is \(\mu\)-strongly convex if it satisfies
  \[
     \frac{\mu}{2} \norm{\vx - \vy}_2^2  \leq f\left(\vy\right) - f\left(\vx\right) - \inner{ \nabla f\left(\vx\right) }{ \vy - \vx }
  \]
  for all \(\vx, \vy \in \mathcal{X}\) and some \(\mu > 0\).
\end{definition*}

\vspace{1ex}
\begin{remark}
    We say a function \(f\) is only convex if it satisfies the strong convexity inequality with \(\mu = 0\).
\end{remark}

\vspace{1ex}
\begin{remark}[\textbf{Log-Concave Measures}]
    We say a probability measure \(\Pi\) is \(\mu\)-strongly log-concave if, in a \(d\)-dimensional Euclidean measurable space \((\mathbb{R}^d, \mathcal{B}^d, \mathbb{P})\), where \(\mathcal{B}^d\) is the \(\sigma\)-algebra of Borel-measurable subsets of \(\mathbb{R}^d\) and \(\mathbb{P}\) is the Lebesgue measure, its log probability density function \(x \mapsto -\log \pi\left(x\right) : \mathbb{R}^d \to \mathbb{R}\) is \(\mu\)-strongly convex.
\end{remark}

\vspace{1ex}
\begin{remark}[\textbf{Log-Smooth Densities}]
    Similarly, we say a probability distribution is \(L\)-log-smooth if its log-probability density function function \(\log \pi\) is \(L\)-smooth.
\end{remark}

% \begin{definition*}[\textbf{Relaxed Growth}; RG; \citealp{bottou_optimization_2018}]
%   A gradient estimator \(\rvvg\) satisfies the relaxed growth condition if
%   \[
%     \mathbb{E} \norm{ \rvvg\left(\vlambda\right) }_2^2 \leq \alpha \, \norm{ \nabla F \left(\vlambda\right) }_2^2 + \beta,
%   \]
%   for some \(0 \leq \alpha, \beta < \infty\).
% \end{definition*}

% \begin{remark}[\textbf{Expected Strong Growth}; \citealp{solodov_incremental_1998,vaswani_fast_2019}]
%   A gradient estimator \(\rvvg\) satisfies the expected strong growth condition if it satisfies the RG condition with \(\beta = 0\).
% \end{remark}

% \begin{definition*}[\textbf{Convex Expected Smoothness}; CES; \citealp{gower_sgd_2019}]
%   A gradient estimator \(\rvvg\) satisfies the convex expected smoothness condition if
%   \[
%     \mathbb{E} \norm{ \rvvg\left(\vlambda\right) }_2^2 \leq 4 A \left( F\left(\vlambda\right) - F^* \right) + C,
%   \]
%   for some \(0 \leq A, C < \infty\), where \(F^* = \inf_{\vlambda \in \Lambda}F\left(\vlambda\right)\).
% \end{definition*}
