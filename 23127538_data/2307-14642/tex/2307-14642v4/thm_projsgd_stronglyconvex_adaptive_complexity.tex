
\begin{theoremEnd}[all end, category=complexityprojsgdadaptiveqvcfixed]{lemma}[\textbf{Strongly convex \(F\) with adaptive QV and Fixed Stepsize}]\label{thm:projsgd_stronglyconvex_adaptive_complexity}
  For a \(\mu\)-strongly convex \(F : \Lambda \to \mathbb{R}\) on a convex set \(\Lambda\) the last iterate \(\vlambda_T\) of projected SGD with a gradient estimator satisfying an adaptive QV bound (\cref{assumption:adaptiveqvc}) is \(\epsilon\)-close to \(\vlambda^* = \argmin_{\vlambda \in \Lambda} F\left(\vlambda\right)\) such that \(\norm{\vlambda_T - \vlambda^{*}}_2^2 < \epsilon\) if
{%
\setlength{\abovedisplayskip}{.5ex} \setlength{\abovedisplayshortskip}{.5ex}
\setlength{\belowdisplayskip}{1.ex} \setlength{\belowdisplayshortskip}{1.ex}
  \begin{align*}
    \gamma &=
    \min\left(
      \frac{1}{2}
      \frac{
        \mu
      }{
        \widetilde{\alpha} + 2 \widetilde{\beta} \epsilon^{-1} 
      }\, ,\,
      \frac{2}{\mu}
    \right)  \quad\text{and}
    \\
    %
    T &\geq
    \frac{2}{\mu^2} \max\left(\widetilde{\alpha} + 2 \widetilde{\beta} \frac{1}{\epsilon}, \; \frac{\mu^2}{4}\right) \log \left( 2 \norm{\vlambda_0 - \vlambda^*}_2^2 \, \frac{1}{\epsilon} \right).
  \end{align*}
}
\end{theoremEnd}
\vspace{-1ex}
\begin{proofEnd}\label{proof:projsgd_stronglyconvex_adaptive_complexity}
  Recall that, for a stepsize \(\gamma\) and a number of steps \(T\) satisfying 
  \begin{align*}
    \gamma \leq \min\left( \frac{\epsilon \mu}{4 \beta}, \frac{\mu}{2 \alpha}, \frac{2}{\mu} \right)
    \quad\text{and}\quad
    T \geq \max\left( \frac{ 4 \beta }{\mu^2 } \frac{1}{\epsilon}, \frac{2 \alpha}{\mu^2}, \frac{1}{2} \right) \log \left( 2 \norm{\vlambda_0 - \vlambda^*}_2^2 \, \frac{1}{\epsilon} \right),
  \end{align*}
  we can guarantee that the iterate \(\vlambda_t\) can guarantee \(\mathbb{E} \norm{\vlambda^* - \vlambda_T}_2^2 \leq \epsilon\).

  We optimize the parameter \(\delta\) to minimize the number of steps.
  That is,
  \begin{align*}
    \max\left( \frac{ 4 \beta }{\mu^2 } \frac{1}{\epsilon}, \frac{2 \alpha}{\mu^2}, \frac{1}{2} \right) \log \left( 2 \norm{\vlambda_0 - \vlambda^*}_2^2 \, \frac{1}{\epsilon} \right)
    =
    \frac{2}{\mu^2} \max\left( 2 (1 + C^{-1} \delta^{-1}) \,\widetilde{\beta} \frac{1}{\epsilon}, (1 + C \delta) \widetilde{\alpha}, \frac{\mu^2}{4}\right)
    \log \left( 2 \norm{\vlambda_0 - \vlambda^*}_2^2 \, \frac{1}{\epsilon} \right).
  \end{align*}
  Since the first and second arguments of the max function are monotonic with respect to \(\delta\), the optimum is unique, and achieved when the two terms are equal.
  That is,
  \begin{alignat*}{2}
    & &
    2 (1 + C^{-1} \delta^{-1}) \,\widetilde{\beta} \frac{1}{\epsilon}
    &=
    (1 + C \delta) \widetilde{\alpha}
    \\
    &\Leftrightarrow&\qquad
    \frac{2 \widetilde{\beta}}{\epsilon} + \frac{2 \widetilde{\beta} C^{-1}}{\epsilon} \delta^{-1} \,
    &=
    \widetilde{\alpha} + \widetilde{\alpha} C \delta 
    \\
    &\Leftrightarrow&\qquad
    \frac{2 \widetilde{\beta}}{\epsilon} \delta +  \frac{2 \widetilde{\beta} C^{-1}}{\epsilon}  \,
    &=
    \widetilde{\alpha} \delta + \widetilde{\alpha} C \delta^2
    \\
    &\Leftrightarrow&\qquad
    %
    \widetilde{\alpha} C \delta^2 + \left( \widetilde{\alpha} - \frac{2 \widetilde{\beta}}{\epsilon} \right) \delta - \frac{2 \widetilde{\beta} C^{-1}}{\epsilon}
    &=
    0
    \\
    &\Leftrightarrow&\qquad
    %
    \left(
    \widetilde{\alpha} \delta
    - 
    \frac{2 \widetilde{\beta} C^{-1}}{\epsilon}
    \right)
    \left(
      C \delta + 1
    \right)
    &=
    0.
  \end{alignat*}
  Conveniently, we have a unique feasible solution
  \begin{alignat*}{2}
    \delta
    =
    2 
    \frac{
      \widetilde{\beta}
    }{
      \widetilde{\alpha} 
    }
    C^{-1}
    \epsilon^{-1}.
  \end{alignat*}

  Thus, the optimal bound is obtained by setting
  \(
    \delta
    = 2 
    \frac{
      \widetilde{\beta}
    }{
      \widetilde{\alpha} 
    }
    C^{-1}
    \epsilon^{-1},
  \)
  such that
  \begin{align*}
    T
    &\geq
    \frac{2}{\mu^2} \max\left(  2 \beta \frac{1}{\epsilon}, \alpha, \frac{\mu^2}{4} \right) \log \left( 2 \norm{\vlambda_0 - \vlambda^*}_2^2 \, \frac{1}{\epsilon} \right)
    \\
    &=
    \frac{2}{\mu^2} \max\left( 2 \left( 1 + C^{-1} \delta^{-1} \right) \widetilde{\beta}  \frac{1}{\epsilon},  \left( 1 + C \delta \right) \widetilde{\alpha}, \frac{\mu^2}{4} \right)
    \log \left( 2 \norm{\vlambda_0 - \vlambda^*}_2^2 \, \frac{1}{\epsilon} \right)
    \\
    &=
    \frac{2}{\mu^2} \max\left( \widetilde{\alpha} + 2 \widetilde{\beta} \frac{1}{\epsilon}, \frac{\mu^2}{4} \right) \log \left( 2 \norm{\vlambda_0 - \vlambda^*}_2^2 \, \frac{1}{\epsilon} \right).
  \end{align*}
  The stepsize with the optimal \(\delta\) is consequently
  \begin{align*}
    \gamma
    &\leq
    \min\left( \frac{\epsilon \mu}{4 \beta}, \frac{\mu}{2 \alpha}, \frac{2}{\mu} \right)
    =
    \min\left( \frac{\epsilon \mu}{4 (1 + C^{-1} \delta^{-1}) \widetilde{\beta}} \,, \; \frac{\mu}{2 (1 + C \delta) \widetilde{\alpha}}, \frac{2}{\mu} \right)
    =
    \min\left(
      \frac{1}{2}
      \frac{
        \mu
      }{
        \widetilde{\alpha} + 2 \widetilde{\beta} \epsilon^{-1} 
      }\, ,\;
      \frac{2}{\mu}
    \right).
  \end{align*}
\end{proofEnd}


\begin{theoremEnd}[all end, category=complexityprojsgdadaptiveqvcdec]{lemma}[\textbf{Strongly convex \(F\) with adaptive QV and Decreasing Stepsize}]\label{thm:projsgd_stronglyconvex_decstepsize_adaptive_complexity}
  For a \(\mu\)-strongly convex \(F : \Lambda \to \mathbb{R}\) on a convex set \(\Lambda\) with a unique global minimizer \(\vlambda^* \in \Lambda\), the last iterate \(\vlambda_T\) of projected SGD with a gradient estimator satisfying an adaptive QVC bound (\cref{assumption:adaptiveqvc}) and a decreasing stepsize satisfies a suboptimality of \(\norm{\vlambda_T - \vlambda_{*}}_2^2 < \epsilon\) if
  {
  \begin{align*}
    \gamma_t
    &=
    \min\Bigg(
    \frac{
      \mu
    }{
      2 \widetilde{\alpha}
      +
      \sqrt{2 \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \widetilde{\alpha}^{3/2}
      \widetilde{\beta}^{-1/2}
    },
    \frac{4 t + 2 }{ \mu \, {\left( t + 1\right)}^2 }
    \Bigg)
    \\
    T
    &\geq
    \frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
    +
    \frac{16 \sqrt{2}}{ \mu^2 }
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    \sqrt{
      \widetilde{\alpha} \widetilde{\beta}
    }
    \,
    \frac{1}{\epsilon^{3/4}}
    +
    \frac{8 \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2}
    \frac{1}{\sqrt{\epsilon}}.
  \end{align*}
  }%
\end{theoremEnd}
\begin{proofEnd}\label{proof:projsgd_stronglyconvex_decstepsize_adaptive_complexity}
  Recall that, for a stepsize \(\gamma\) and a number of steps \(T\) such that
  \begin{align*}
    \gamma_t = \min\left( \frac{\mu}{2 \alpha}, \frac{4 t + 2 }{ \mu \, {\left( t + 1\right)}^2 } \right)
    \quad\text{and}\quad
    T \geq \frac{16 \beta}{ \mu^2 } \frac{1}{\epsilon} + \frac{8  \alpha \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}},
  \end{align*}
  we can guarantee that the iterate \(\vlambda_t\) can guarantee \(\mathbb{E} \norm{\vlambda^* - \vlambda_T}_2^2 \leq \epsilon\).

  We optimize the parameter \(\delta\) to minimize the required number of steps \(T\).
  That is, we maximize
  \begin{align*}
    \frac{16 \beta }{ \mu^2 } \frac{1}{\epsilon} + \frac{8 \sqrt{2} \, \alpha \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    = \frac{16 \left(1 + C \delta\right) \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} + \frac{8 \left(1 + C^{-1} \delta^{-1}\right) \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}.
  \end{align*}
  This is clearly a convex function with respect to \(\delta\).
  Thus, we only need to find a first-order stationary point 
  {\small%
  \begin{align*}
    \frac{\mathrm{d}}{\mathrm{d} \delta}
    \left(
      \frac{16 \left(1 + C \delta\right) \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} + \frac{8 \left(1 + C^{-1} \delta^{-1}\right) \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    \right) &= 0.
  \end{align*}
  }%
  Differentiating, we have
  \begin{alignat*}{3}
    &&
    \frac{16 C \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} - \frac{8  \, C^{-1} \delta^{-2} \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    &= 0,
\shortintertext{multiplying \(\delta^2\) to both sides,}
    &\Leftrightarrow&\qquad
    \delta^2 \frac{16 C \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} - \frac{8 \sqrt{2} \, C^{-1} \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    &= 0.
  \end{alignat*}
  Reorganizing,
  \begin{alignat*}{3}
    &\Leftrightarrow&\qquad
    \delta^2  \frac{16 C \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
    &=
    \frac{8 \sqrt{2} \, C^{-1} \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    \\
    &\Leftrightarrow&\qquad
    \delta^2  
    &=
    \left( \frac{\mu^2 \epsilon}{ 16 C \widetilde{\beta} } \right)
    \left(
    \frac{8  C^{-1} \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    \right)
    \\
    &\Leftrightarrow&\qquad
    \delta^2  
    &=
    \frac{C^{-2} \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2}{ 2 \widetilde{\beta}} \sqrt{\epsilon},
\shortintertext{and taking the square-root of both sides,}
    &\Leftrightarrow&\qquad
    \delta  
    &=
    \frac{
      \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \sqrt{\widetilde{\alpha}}
    }{
      \sqrt{2} \,
      C 
      \sqrt{\widetilde{\beta}}
    }.
  \end{alignat*}
  Recall that the required number of iterations is
  \begin{align*}
    T
    &\geq
    \frac{16 \left(1 + C \delta\right) \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
    +
      \frac{8 \left(1 + C^{-1} \delta^{-1}\right) \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    \\
    &=
    \underbrace{
      \frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
      +
      \frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
      C \delta
    }_{T_{\text{\ding{172}}}}
    +
    \underbrace{
      \frac{8 \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
      +
      \frac{8 \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
      C^{-1} \delta^{-1}
    }_{T_{\text{\ding{173}}}}.
  \end{align*}
  Plugging \(\delta\) in, we have
  \begin{align*}
    T_{\text{\ding{172}}}
    &=
    \frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
    +
    \frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon}
    C 
    \left(
    \frac{
      \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \sqrt{\widetilde{\alpha}}
    }{
      \sqrt{2} \, C
      \sqrt{\widetilde{\beta}}
    }
    \right)
    \\
    &=
    \frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
    +
    \frac{8 \sqrt{2} }{ \mu^2 }
    \sqrt{
      \widetilde{\alpha} \widetilde{\beta}
    } \,
    \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
    \,
    \epsilon^{-3/4}
    \\
    \\
    T_{\text{\ding{173}}}
    &=
    \frac{8 \, \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    +
    \frac{8 \, \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    C^{-1} 
    \left(
    \frac{
      \sqrt{2} \, C
      \sqrt{\widetilde{\beta}}
    }{
      \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \sqrt{\widetilde{\alpha}}
    }
    \right)
    \\
    &=
    \frac{8 \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    +
    \frac{8 \sqrt{2}}{ \mu^2}
    \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
    \,
    \sqrt{
      \widetilde{\alpha}
      \widetilde{\beta}
    }
    \,
    \epsilon^{-3/4}.
  \end{align*}
  Combining the results, 
  \begin{align*}
    T
    \geq
    T_{\text{\ding{172}}}
    +
    T_{\text{\ding{173}}}
    &=
    \frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
    +
    \frac{8 \sqrt{2} }{ \mu^2 }
    \sqrt{
      \widetilde{\alpha} \widetilde{\beta}
    } \,
    \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
    \,
    \epsilon^{-3/4}
    \\
    &\qquad+
    \frac{8 \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2} \frac{1}{\sqrt{\epsilon}}
    +
    \frac{8 \sqrt{2}}{ \mu^2}
    \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
    \,
    \sqrt{
      \widetilde{\alpha}
      \widetilde{\beta}
    }
    \,
    \epsilon^{-3/4}
    \\
    &=
    \frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
    +
    \frac{16 \sqrt{2}}{ \mu^2 }
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    \sqrt{
      \widetilde{\alpha} \widetilde{\beta}
    }
    \,
    \epsilon^{-3/4}
    +
    \frac{8 \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2}
    \frac{1}{\sqrt{\epsilon}}.
  \end{align*}

  For the stepsize
  \begin{align*}
    \gamma
    =
    \min\left( \frac{\mu}{2 \alpha}, \frac{4 t + 2 }{ \mu \, {\left( t + 1\right)}^2 } \right)
    =
    \min\left(
      \frac{\mu}{2 \left(1 + C \delta \right) \widetilde{\alpha}},
      \frac{4 t + 2 }{ \mu \, {\left( t + 1\right)}^2 }
    \right),
  \end{align*}
  we have 
  \begin{align*}
    2 \left(1 + C \delta \right) \widetilde{\alpha}
    &=
    2 \widetilde{\alpha} + 2 \widetilde{\alpha} C \delta 
    \\
    &=
    2 \widetilde{\alpha}
    +
    2 \widetilde{\alpha}
    C
    \left(
    \frac{
      \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \sqrt{\widetilde{\alpha}}
    }{
      \sqrt{2} \, C
      \sqrt{\widetilde{\beta}}
    }
    \right)
    \\
    &=
    2 \widetilde{\alpha}
    +
    \sqrt{2}
    \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
    \,
    \epsilon^{1/4}
    \,
    \widetilde{\alpha}^{3/2}
    \widetilde{\beta}^{-1/2}.
  \end{align*}
  Therefore, 
  \begin{align*}
    \gamma
    =
    \min\left(
      \frac{\mu}{2 \left(1 + C \delta \right) \widetilde{\alpha}},
      \frac{4 t + 2 }{ \mu \, {\left( t + 1\right)}^2 }
    \right)
    =
    \min\left(
    \frac{
      \mu
    }{
      2 \widetilde{\alpha}
      +
      \sqrt{2 \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \widetilde{\alpha}^{3/2}
      \widetilde{\beta}^{-1/2}
    },
    \frac{4 t + 2 }{ \mu \, {\left( t + 1\right)}^2 }
    \right).
  \end{align*}
\end{proofEnd}
