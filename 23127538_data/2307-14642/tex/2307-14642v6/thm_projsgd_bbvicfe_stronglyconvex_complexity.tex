
\begin{theoremEnd}[category=complexitybbvicfefixed]{theorem}[\textbf{Complexity of Fixed Stepsize BBVI with CFE}]\label{thm:projsgd_bbvicfe_complexity}
  The last iterate \(\vlambda_T \in \Lambda_L\) of BBVI with the CFE estimator and projected SGD with a fixed stepsize applied to a \(\mu\)-strongly log-concave and \(L\)-log-smooth posterior is \(\epsilon\)-close to \(\vlambda^* = \argmin_{\vlambda \in \Lambda_L} F\left(\vlambda\right)\) such that \(\mathbb{E}\norm{ \vlambda_T - \vlambda^* }_2^2 \leq \epsilon\) if
{%\small%
\setlength{\abovedisplayskip}{.5ex} \setlength{\abovedisplayshortskip}{.5ex}
\setlength{\belowdisplayskip}{1.ex} \setlength{\belowdisplayshortskip}{1.ex}
  \begin{align*}
    T
    &\geq 
    2 \kappa^2 \left(d + k_{\varphi} + 4\right) \left(1  + 2 {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon}\right) 
    \log \left( 2 \Delta^2 \, \frac{1}{\epsilon} \right)
  \end{align*}
}%
  for some fixed stepsize \(\gamma\), where \(\Delta = {\lVert \vlambda_0 - \vlambda^*\rVert}_2\), and \(\kappa = L/\mu\) is the condition number.
\end{theoremEnd}
\vspace{-1ex}
\begin{proofEnd}\label{proof:projsgd_bbvicfe_complexity}
  From \cref{thm:cfe_upperbound} with \(S = L\), the CFE estimator satisfies adaptive QV with the constants
  \begin{alignat*}{2}
    \alpha_{\mathrm{CFE}} 
    = L^2 \left( d + k_{\varphi} + 4 \right) \left(1 + \delta\right)
    \qquad\text{and}\qquad
    \beta_{\mathrm{CFE}}  
    = L^2 \left( d + k_{\varphi} \right) \left( 1 + \delta^{-1}  \right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2.
  \end{alignat*}
  Furthermore, for a \(\mu\)-strongly log-concave posterior and our variational parameterization,~\citet[Theorem 9]{domke_provable_2020} show that the ELBO is \(\mu\)-strongly convex.

  We can thus invoke \cref{thm:projsgd_stronglyconvex_adaptive_complexity} with 
  \begin{align*}
    \widetilde{\alpha} = L^2 \left(d + k_{\varphi} + 4\right),\qquad
    \widetilde{\beta}  = L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2,\quad\text{and}\quad
    C = 1.
  \end{align*}
  This yields a lower bound on the number of iteration 
  \begin{align*}
    &\frac{2}{\mu^2} \max\left(\widetilde{\alpha} + 2 \widetilde{\beta} \frac{1}{\epsilon}, \; \frac{\mu^2}{4} \right) 
    \log \left( 2 \norm{\vlambda_0 - \vlambda^*}_2^2 \, \frac{1}{\epsilon} \right)
    \\
    &\;=
    \frac{2}{\mu^2} \max\left(L^2 \left(d + k_{\varphi} + 4\right) + 2 L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon},\; \frac{\mu^2}{4}\right) 
    \log \left( 2 {\lVert \vlambda_0 - \vlambda^*\rVert}_2^2 \, \frac{1}{\epsilon} \right),
\shortintertext{pulling out \(L\),}
    &\;=
    \frac{2 L^2}{\mu^2} \max\left( \left(d + k_{\varphi} + 4\right) + 2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon},\; \frac{\mu^2}{4 L^2}\right) 
    \log \left( 2 {\lVert \vlambda_0 - \vlambda^*\rVert}_2^2 \, \frac{1}{\epsilon} \right),
\shortintertext{and since \(\frac{\mu^2}{4 L^2} < \frac{1}{4}\) and the first argument is larger than 1, the max operation is redundant that}
    &\;=
    \frac{2 L^2}{\mu^2} \left( \left(d + k_{\varphi} + 4\right) + 2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon}\right) 
    \log \left( 2 {\lVert \vlambda_0 - \vlambda^*\rVert}_2^2 \, \frac{1}{\epsilon} \right).
\shortintertext{Now, using the trivial fact \(d + k_{\varphi} < d + k_{\varphi} + 4\) simplifies the bound as,}
    &\;<
    \frac{2 L^2}{\mu^2} \left(d + k_{\varphi} + 4\right) \left(1  + 2 {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon} \right) 
    \log \left( 2 {\lVert \vlambda_0 - \vlambda^*\rVert}_2^2 \, \frac{1}{\epsilon} \right)
    \\
    &\;=
    2 \kappa^2 \left(d + k_{\varphi} + 4\right) \left(1  + 2 {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon}\right) 
    \log \left( 2 {\lVert \vlambda_0 - \vlambda^*\rVert}_2^2 \, \frac{1}{\epsilon} \right).
  \end{align*}
  The optimal \(\delta\) is given as
  \begin{align*}
    \delta 
    = \frac{2}{\epsilon} \frac{\widetilde{\beta}}{\widetilde{\alpha}} C^{-1} 
    = \frac{2}{\epsilon} 
    \frac{
      L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2
    }{
      L^2 \left(d + k_{\varphi} + 4\right)
    } 
    C^{-1} 
    =
    \frac{2}{\epsilon} \, \frac{d + k_{\varphi}}{d + k_{\varphi} + 4} \, {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 .
  \end{align*}
\end{proofEnd}

\begin{theoremEnd}[all end, category=complexitybbvicfedec]{theorem}[\textbf{Complexity of Decreasing Stepsize BBVI with CFE}]\label{thm:projsgd_bbvicfe_decstepsize_complexity}
  The last iterate \(\vlambda_T \in \Lambda_L\) of BBVI with the CFE estimator and projected SGD with a decreasing stepsize schedule applied to a \(\mu\)-strongly log-concave and \(L\)-log-smooth posterior is \(\epsilon\)-close to \(\vlambda^* = \argmin_{\vlambda \in \Lambda_L} F\left(\vlambda\right) \) such that \(\mathbb{E}\norm{ \vlambda_T - \vlambda^* }_2^2 \leq \epsilon\) if
  \begin{align*}
    T
    &\geq 
    16 \kappa^2 \left(d + k_{\varphi} + 4\right) 
    \bigg(
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon} 
    +
    2
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2
    \,
    \frac{1}{\epsilon^{3/4}}
    +
    \norm{\vlambda_0 - \vlambda^*}_2 
    \frac{1}{\sqrt{\epsilon}}
    \bigg).
  \end{align*}
  for some decreasing stepsize schedule \(\gamma_1, \ldots, \gamma_T\), where \(\kappa = L/\mu\) is the condition number and \(\vlambda^* \in \Lambda\) is the optimal variational parameter.
\end{theoremEnd}
\begin{proofEnd}\label{proof:projsgd_bbvicfe_decstepsize_complexity}
  From \cref{thm:cfe_upperbound}, the CFE estimator with \(S = L\) satisfies adaptive QV with the constants
  \begin{align*}
    \alpha_{\mathrm{CFE}} 
    = L^2 \left( d + k_{\varphi} + 4 \right) \left(1 + \delta\right)\qquad\text{and}\qquad
    %
    \beta_{\mathrm{CFE}}  
    = L^2 \left( d + k_{\varphi} \right) \left( 1 + \delta^{-1}  \right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2.
  \end{align*}
  Furthermore, for a \(\mu\)-strongly log-concave posterior and our variational parameterization,~\citet[Theorem 9]{domke_provable_2020} show that the ELBO is \(\mu\)-strongly convex.

  We thus invoke \cref{thm:projsgd_stronglyconvex_decstepsize_adaptive_complexity} with 
  \begin{alignat*}{3}
    \widetilde{\alpha} = L^2 \left(d + k_{\varphi} + 4\right),
    \qquad\quad
    \widetilde{\beta}  = L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2, \qquad\text{and}
    \qquad
    C = 1.
  \end{alignat*}
  This yields a lower bound on the number of iterations:
  \begin{align*}
    &\frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
    +
    \frac{16 \sqrt{2}}{ \mu^2 }
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    \sqrt{
      \widetilde{\alpha} \widetilde{\beta}
    }
    \,
    \frac{1}{\epsilon^{3/4}}
    +
    \frac{8 \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2}
    \frac{1}{\sqrt{\epsilon}}
    \\
    &=
    \frac{16 L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 }{ \mu^2 } \frac{1}{\epsilon} 
    +
    \frac{16 \sqrt{2}}{ \mu^2 }
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    \sqrt{
       \left( L^2 \left(d + k_{\varphi} + 4\right) \right)
       \left( L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \right)
    }
    \,
    \frac{1}{\epsilon^{3/4}}
    \\
    &\qquad+
    \frac{8 L^2 \left(d + k_{\varphi} + 4\right) \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2}
    \frac{1}{\sqrt{\epsilon}},
\shortintertext{using the trivial bound \(d + k_{\varphi} < d + k_{\varphi} + 4\),}
    &<
    \frac{16 L^2 \left(d + k_{\varphi} + 4\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 }{ \mu^2 } \frac{1}{\epsilon} 
    +
    \frac{16 \sqrt{2}}{ \mu^2 }
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    \sqrt{
       L^4 \left(d + k_{\varphi} + 4\right)
       \left(d + k_{\varphi} + 4\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 
    }
    \,
    \frac{1}{\epsilon^{3/4}}
    \\
    &\qquad+
    \frac{8 L^2 \left(d + k_{\varphi} + 4\right) \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2}
    \frac{1}{\sqrt{\epsilon}},
\shortintertext{pulling out the \(16 \left( d + k_{\varphi} + 4 \right) L^2 / \mu^2 \) factors,}
    &=
    16 \left(d + k_{\varphi} + 4\right) 
    \frac{L^2}{ \mu^2 } 
    \bigg(
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon} 
    +
    \sqrt{2}
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2
    \,
    \frac{1}{\epsilon^{3/4}}
    +
    \frac{1}{2}
    \norm{\vlambda_0 - \vlambda^*}_2 
    \frac{1}{\sqrt{\epsilon}}
    \bigg)
    \\
    &=
    16 \kappa^2 \left(d + k_{\varphi} + 4\right) 
    \bigg(
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon} 
    +
    \sqrt{2}
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2
    \,
    \frac{1}{\epsilon^{3/4}}
    +
    \frac{1}{2}
    \norm{\vlambda_0 - \vlambda^*}_2 
    \frac{1}{\sqrt{\epsilon}}
    \bigg).
  \end{align*}
  The optimal \(\delta\) is given as
  \begin{align*}
    \delta
    &=
    \frac{
      \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \sqrt{\widetilde{\alpha}}
    }{
      \sqrt{2} \, C
      \sqrt{\widetilde{\beta}}
    }
    =
    \frac{
      \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \sqrt{ L^2 \left(d + k_{\varphi} + 4\right) }
    }{
      \sqrt{2} 
      \sqrt{ L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 }
    }
    =
    \frac{1}{\sqrt{2} } \,
    \frac{\sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }}{{\lVert \bar{\vlambda} - \vlambda^* \rVert}_2}
    \,
    \sqrt{
    \frac{
       d + k_{\varphi} + 4
    }{
      d + k_{\varphi}
    }
    } \, \epsilon^{-1/4}.
  \end{align*}
\end{proofEnd}
