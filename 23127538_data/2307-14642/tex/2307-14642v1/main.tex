
%\documentclass{statsoc}
\documentclass[10pt]{article}

\usepackage{geometry}
\geometry{
  twoside=true,
  a4paper,
  includeheadfoot,
  head=13pt,
  foot=2pc,
  paperwidth=6.75in,
  paperheight=10in,
  top=30pt,
  bottom=40pt,
  inner=46pt,
  outer=46pt,
  marginparwidth=2pc,
  heightrounded
}
\usepackage{titling}
\usepackage{titlesec}

\titleformat*{\section}{\large\bfseries\sffamily}
\titleformat*{\subsection}{\bfseries\sffamily}
\titleformat*{\subsubsection}{\bfseries\sffamily}
\titleformat*{\paragraph}{\bfseries\sffamily}

\usepackage[sort&compress,round]{natbib}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{nicefrac}
\usepackage{pgfplots}
\usepackage{float}
\usepackage[inline]{enumitem}
\usepackage{pifont}
\usepackage{tabularx,booktabs,threeparttable,makecell,colortbl}

\usepackage{etoc}
\etocsettocdepth{3}

\usepackage{parskip}
\setlength{\parindent}{15pt}

\let\proof\relax 
\let\endproof\relax

\input{krkmath}

\singlespacing

\usepackage{tikz}
\usepackage{pgf}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usetikzlibrary{pgfplots.groupplots}
\usetikzlibrary{spy,calc,dsp,chains}
\pgfplotsset{compat=1.17}
\usepgfplotslibrary{external} 
%\tikzexternalize

\definecolor{color1}{HTML}{EE5396}
\definecolor{color2}{HTML}{A56EFF}
\definecolor{color3}{HTML}{4589FF}
\definecolor{color4}{HTML}{1192E8}

\allowdisplaybreaks

\pretitle{\begin{flushleft}\Large\bfseries\sffamily}
\posttitle{\par\end{flushleft}\vskip 3ex}
\preauthor{\begin{flushleft}}
\postauthor{\par\end{flushleft}}
\predate{\begin{flushleft}}
\postdate{\par\end{flushleft}\vskip 0.5em}
\date{}

\renewenvironment{abstract}
{\begin{quote}
\vspace{-6ex}
\noindent \par{\bfseries\sffamily \abstractname\hspace{.5em}}}
{\medskip\noindent 
\end{quote}
}

\begin{document}

\title{\vspace{-2cm}Linear Convergence of Black-Box Variational Inference: \\ Should We Stick the Landing?}
\author{
  {\sf{}Kyurae Kim} \\
  \textsf{E-mail}: \texttt{kyrkim@seas.upenn.edu} \\
  {\itshape%
    University of Pennsylvania, Philadelphia, United States%
  } \\ \vspace{1.ex}
  %
  {\sf{}Yian Ma} \\
  \textsf{E-mail}: \texttt{yianma@ucsd.edu} \\
  {\itshape%
    University of California San Diego, San Diego, United States%
  } \\ \vspace{1.ex} 
  %
  {\sf{}Jacob R. Gardner} \\
  \textsf{E-mail}: \texttt{jacobrg@seas.upenn.edu} \\
  {\itshape%
    University of Pennsylvania, Philadelphia, United States%
  } 
}

\maketitle
%% \begin{itemize}[label={}]
%%   \item Kyurae Kim
%%   \item University of Pennsylvania, Philadelphia, United States.
%% \end{itemize}

%\title[Linear Convergence of Black-Box Variational Inference]{Linear Convergence of Black-Box Variational Inference: \\ Should We Stick the Landing?}

\begin{abstract}
  We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called ``linear'') rate under perfect variational family specification.
  In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families.
  Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent.
  We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator, and provide explicit non-asymptotic complexity guarantees for both.
\end{abstract}

\input{section_introduction}
\input{section_background}
\input{section_main}
%\input{section_experiments}
\input{section_discussions}

\newpage
\bibliographystyle{rss}
\bibliography{references}

\newpage
\appendix

\newpage
{\hypersetup{linkcolor=black}
\tableofcontents
}

\newpage
\input{table_theorems}

\newpage
\section{Proofs}

\input{section_definitions}

\newpage
% \newpage
% \subsection{Miscellaneous Propositions}
% \vspace{1ex}
% \input{thm_peterpaul}
% \printProofs[logsobolev]
% \printProofs[misc]

\newpage
\subsection{Auxiliary Lemmas}
\vspace{1ex}
\input{section_external_lemmas}
\printProofs[external]
\printProofs[gradvarlemmas]

\newpage
\subsection{Upper Bound on Gradient Variance of STL}

\subsubsection{General Decompositions}
\vspace{1ex}
\printProofs[stlupperboundlemma]

\newpage
\subsubsection{Full-Rank Parameterization}
\vspace{1ex}
\printProofs[stlupperboundfr]

\newpage
\subsubsection{Mean-Field Parameterization}\label{section:stl_meanfield}
\vspace{1ex}
\printProofs[stlupperboundmf]

\newpage
\subsection{Lower Bound on Gradient Variance of STL}
\subsubsection{General Lower Bound}
\vspace{1ex}
\printProofs[stllowerbound]

\newpage
\subsubsection{Unimprovability}
\vspace{1ex}
\printProofs[stllowerboundunimprovability]

\newpage
\subsection{Upper Bound on Gradient Variance of CFE}
\subsubsection{Full-Rank Parameterization}
\vspace{1ex}
\printProofs[cfeupperbound]

\newpage
\subsubsection{Mean-Field Parameterization}
\vspace{1ex}
\printProofs[cfeupperboundmf]

\newpage
\subsection{Non-Asymptotic Complexity of Projected SGD}
\subsubsection{QVC Gradient Estimator}
\vspace{1ex}
\printProofs[complexityprojsgdqvc]

\newpage
\subsubsection{Adaptive QVC Gradient Estimator}\label{section:complexity_adaptiveqvc}
\vspace{1ex}
\printProofs[complexityprojsgdadaptiveqvc]

\newpage
\subsection{Non-Asymptotic Complexity of BBVI}
\subsubsection{CFE Gradient Estimator}
\vspace{1ex}
\printProofs[complexitybbvicfe]

\newpage
\subsubsection{STL Gradient Estimator}
\vspace{1ex}
\printProofs[complexitybbvistl]

%% \newpage
%% \subsection{Gaussian Special Case}
%% \subsubsection{Bounds on the Gradient Variance of STL}
%% \vspace{1ex}
%% \printProofs[stlgaussian]

%\newpage
%\subsection{Connections with Other Gradient Variance Conditions}
%\vspace{1ex}
%\printProofs[gradientconditions]


%\printProofs

\end{document}

%%% Local Variables:
%%% TeX-master: "main"
%%% End:
