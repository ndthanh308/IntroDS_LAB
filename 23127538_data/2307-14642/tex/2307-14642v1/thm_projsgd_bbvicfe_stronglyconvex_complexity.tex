
\begin{theoremEnd}[category=complexitybbvicfe]{theorem}[\textbf{Complexity of Fixed Stepsize BBVI with CFE}]\label{thm:projsgd_bbvicfe_complexity}
  The last iterate \(\vlambda_T \in \Lambda_L\) of BBVI with the CFE estimator and projected SGD with a fixed stepsize applied to a \(\mu\)-strongly log-concave and \(L\)-log-smooth posterior satisfy \(\norm{ \vlambda_T - \vlambda^* }_2^2 \leq \epsilon\) if
  \begin{align*}
    T
    \geq 
    2 \kappa^2 \left(d + k_{\varphi} + 4\right) \left(1  + 2 {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon}\right) \log \left( 2 {\lVert \vlambda_0 - \vlambda^*\rVert}_2^2 \, \frac{1}{\epsilon} \right).
  \end{align*}
  for some fixed stepsize \(\gamma\), where \(\kappa = L/\mu\) is the condition number.
\end{theoremEnd}
\begin{proofEnd}
  From \cref{thm:cfe_upperbound}, the CFE estimator satisfies adaptive QV with the constants
  \begin{align*}
    \alpha_{\mathrm{CFE}} 
    &= L^2 \left( d + k_{\varphi} + 4 \right) \left(1 + \delta\right)
    \\
    \beta_{\mathrm{CFE}}  
    &= L^2 \left( d + k_{\varphi} \right) \left( 1 + \delta^{-1}  \right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2.
  \end{align*}
  Furthermore, for a \(\mu\)-strongly log-concave posterior and our variational parameterization,~\citet[Theorem 9]{domke_provable_2020} show that the ELBO is \(\mu\)-strongly convex.

  We can thus invoke \cref{thm:projsgd_stronglyconvex_adaptive_complexity} with 
  \begin{align*}
    \widetilde{\alpha} &= L^2 \left(d + k_{\varphi} + 4\right) \\
    \widetilde{\beta}  &= L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \\
    C &= 1.
  \end{align*}
  This yields a lower bound on the number of iteration 
  \begin{align*}
    &\frac{2}{\mu^2} \left(\widetilde{\alpha} + 2 \widetilde{\beta} \frac{1}{\epsilon}\right) \log \left( 2 \norm{\vlambda_0 - \vlambda^*}_2^2 \, \frac{1}{\epsilon} \right)
    \\
    &=
    \frac{2}{\mu^2} \left(L^2 \left(d + k_{\varphi} + 4\right) + 2 L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon}\right) \log \left( 2 {\lVert \vlambda_0 - \vlambda^*\rVert}_2^2 \, \frac{1}{\epsilon} \right)
    \\
    &\leq
    \frac{2 L^2}{\mu^2} \left(d + k_{\varphi} + 4\right) \left(1  + 2 {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon}\right) \log \left( 2 {\lVert \vlambda_0 - \vlambda^*\rVert}_2^2 \, \frac{1}{\epsilon} \right)
    \\
    &=
    2 \kappa^2 \left(d + k_{\varphi} + 4\right) \left(1  + 2 {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon}\right) \log \left( 2 {\lVert \vlambda_0 - \vlambda^*\rVert}_2^2 \, \frac{1}{\epsilon} \right).
  \end{align*}
  The optimal \(\delta\) is given as
  \[
    \delta 
    = \frac{2}{\epsilon} \frac{\widetilde{\beta}}{\widetilde{\alpha}} C^{-1} 
    = \frac{2}{\epsilon} 
    \frac{
      L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2
    }{
      L^2 \left(d + k_{\varphi} + 4\right)
    } 
    C^{-1} 
    =
    \frac{2}{\epsilon} \, \frac{d + k}{d + k + 4} \, {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 .
  \]
\end{proofEnd}

\begin{theoremEnd}[all end, category=complexitybbvicfe]{theorem}[\textbf{Complexity of Decreasing Stepsize BBVI with CFE}]\label{thm:projsgd_bbvicfe_decstepsize_complexity}
  The last iterate \(\vlambda_T \in \Lambda_L\) of BBVI with the CFE estimator and projected SGD with a decreasing stepsize schedule applied to a \(\mu\)-strongly log-concave and \(L\)-log-smooth posterior satisfy \(\norm{ \vlambda_T - \vlambda^* }_2^2 \leq \epsilon\) if
  \begin{align*}
    T
    \geq 
    16 \kappa^2 \left(d + k_{\varphi} + 4\right) 
    \bigg(
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon} 
    +
    2
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2
    \,
    \frac{1}{\epsilon^{3/4}}
    +
    \norm{\vlambda_0 - \vlambda^*}_2 
    \frac{1}{\sqrt{\epsilon}}
    \bigg).
  \end{align*}
  for some decreasing stepsize schedule \(\gamma_1, \ldots, \gamma_T\), where \(\kappa = L/\mu\) is the condition number.
\end{theoremEnd}
\begin{proofEnd}
  From \cref{thm:cfe_upperbound}, the CFE estimator satisfies adaptive QV with the constants
  \begin{align*}
    \alpha_{\mathrm{CFE}} 
    &= L^2 \left( d + k_{\varphi} + 4 \right) \left(1 + \delta\right)
    \\
    \beta_{\mathrm{CFE}}  
    &= L^2 \left( d + k_{\varphi} \right) \left( 1 + \delta^{-1}  \right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2.
  \end{align*}
  Furthermore, for a \(\mu\)-strongly log-concave posterior and our variational parameterization,~\citet[Theorem 9]{domke_provable_2020} show that the ELBO is \(\mu\)-strongly convex.

  We thus invoke \cref{thm:projsgd_stronglyconvex_decstepsize_adaptive_complexity} with 
  \begin{align*}
    \widetilde{\alpha} &= L^2 \left(d + k_{\varphi} + 4\right) \\
    \widetilde{\beta}  &= L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \\
    C &= 1.
  \end{align*}
  This yields a lower bound on the number of iteration,
  \begin{align*}
    &\frac{16 \widetilde{\beta} }{ \mu^2 } \frac{1}{\epsilon} 
    +
    \frac{32}{ \mu^2 }
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    \sqrt{
      \widetilde{\alpha} \widetilde{\beta}
    }
    \,
    \frac{1}{\epsilon^{3/4}}
    +
    \frac{16 \widetilde{\alpha} \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2}
    \frac{1}{\sqrt{\epsilon}}
    \\
    &=
    \frac{16 L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 }{ \mu^2 } \frac{1}{\epsilon} 
    \\
    &\qquad+
    \frac{32}{ \mu^2 }
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    \sqrt{
       \left( L^2 \left(d + k_{\varphi} + 4\right) \right)
       \left( L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \right)
    }
    \,
    \frac{1}{\epsilon^{3/4}}
    \\
    &\qquad+
    \frac{16 L^2 \left(d + k_{\varphi} + 4\right) \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2}
    \frac{1}{\sqrt{\epsilon}}
    \\
    &\leq
    \frac{16 L^2 \left(d + k_{\varphi} + 4\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 }{ \mu^2 } \frac{1}{\epsilon} 
    \\
    &\qquad+
    \frac{32}{ \mu^2 }
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    \sqrt{
       L^4 \left(d + k_{\varphi} + 4\right)
       \left(d + k_{\varphi} + 4\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 
    }
    \,
    \frac{1}{\epsilon^{3/4}}
    \\
    &\qquad+
    \frac{16 L^2 \left(d + k_{\varphi} + 4\right) \, \norm{\vlambda_0 - \vlambda^*}_2 }{ \mu^2}
    \frac{1}{\sqrt{\epsilon}}
    \\
    &=
    16 \left(d + k_{\varphi} + 4\right) 
    \frac{L^2}{ \mu^2 } 
    \bigg(
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon} 
    +
    2
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2
    \,
    \frac{1}{\epsilon^{3/4}}
    +
    \norm{\vlambda_0 - \vlambda^*}_2 
    \frac{1}{\sqrt{\epsilon}}
    \bigg)
    \\
    &=
    16 \kappa^2 \left(d + k_{\varphi} + 4\right) 
    \bigg(
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 \frac{1}{\epsilon} 
    +
    2
    \sqrt{
      \norm{\vlambda_0 - \vlambda^*}_2
    }
    \,
    {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2
    \,
    \frac{1}{\epsilon^{3/4}}
    +
    \norm{\vlambda_0 - \vlambda^*}_2 
    \frac{1}{\sqrt{\epsilon}}
    \bigg).
  \end{align*}
  The optimal \(\delta\) is given as
  \begin{align*}
    \delta
    &=
    \frac{
      \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \sqrt{\widetilde{\alpha}}
    }{
      C \, 2^{1/4} 
      \sqrt{\widetilde{\beta}}
    }
    \\
    &=
    \frac{
      \sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }
      \,
      \epsilon^{1/4}
      \,
      \sqrt{ L^2 \left(d + k_{\varphi} + 4\right) }
    }{
      2^{1/4} 
      \sqrt{ L^2 \left(d + k_{\varphi}\right) {\lVert \bar{\vlambda} - \vlambda^* \rVert}_2^2 }
    }
    \\
    &=
    2^{-1/4} \,
    \frac{\sqrt{ \norm{\vlambda_0 - \vlambda^*}_2 }}{{\lVert \bar{\vlambda} - \vlambda^* \rVert}_2}
    \,
    \sqrt{
    \frac{
       d + k_{\varphi} + 4
    }{
      d + k_{\varphi}
    }
    } \, \epsilon^{-1/4}.
  \end{align*}
\end{proofEnd}
