%This section briefly presents works related to \emph{LtC}.

%Two recently popular trends have inspired a plethora of work on this topic: i) usage of increasingly high-quality camera sensors, and ii) pervasive use-cases of video analytics in everyday life. 
%Previous works either target spatial or temporal compression as their primary objective, however, to our best knowledge, no one has proposed a unified framework that performs spatial-temporal compression. 

%We can categorize the existing literate into two groups based on the location where the compression logic is calculated: i) source/client-driven and ii) server-driven. 
\noindent \textbf{Spatial compression.} A variety of different approaches has been developed to spatially reduce the size of video data for analytics. Preliminary designs uses source-side heuristics that are detached from the server. For example, \emph{AdaScale} \cite{chin2019adascale} and \emph{CloudSeg} \cite{wang2019bridging} reduce the outgoing video using super-resolution or other heuristics.  %\naell{Say more--how exactly?  How is it different than us?  Perhaps we can omit for now to avoid confusion}\mishkat{remember that paper, where they split half the network between clien and sever, and sends the features over the network} 
Recent works tend to use server-side feedback for real-time adaptation. For example, \emph{AWStream} \cite{zhang2018awstream} collaborates with the server in order to find the optimal running configuration. The most related approach to LtC is  \emph{DDS} \cite{du2020server}, which sends high-quality patches to the initially sent low-quality image in multiple phases per iteration, based on the feedback from the server.  Split-DNNs, such as \emph{Split-brain} \cite{emmons2019cracking}, split a DNN into initial layers on the source and remaining on the server.   
% One view of LtC is that it splits the region proposal network of a conventional vision pipeline on and places it on the client: however, we observe that even the RPN is distilled and specialized, and that the full vision pipeline continues to run on the server.  Moreover, we note that split-DNN approaches are not targeted for reducing bandwidth and may actually often increase the size of transported data.

\noindent \textbf{Temporal filtering.} There has been a number of systems that use source-side, or edge-based heuristics to filter frames. For example, \emph{Vigil} \cite{zhang2015design} uses a light-weight object counter model on the edge to filter out frames based on number of objects present.  \emph{FilterForward} \cite{canel2019scaling} uses light-weight application specific binary classifiers to assist in filtering. \emph{Glimpse} \cite{chen2015glimpse} uses a caching and object-tracking technique to fill out results in the omitted frames. Finally, similar to LtC, \emph{Reducto} is a feature-differencing  approach  \cite{li2020reducto}, which finds out the optimal action for a batch of frames by building a profile.  Reducto uses shallower features than LtC, and needs expensive retraining to identify optimal actions in the presence of scene dynamics.%\naell{I thought reducto uses pixel differencing.}\mishkat{no professor, it does pixel difference, edge, corner, sift, hog, and finds the best for the given case}

\noindent \textbf{Tiny models.} Recently, there has been developments of tiny neural network models \cite{tiny, incremental_improv} (e.g. Tiny YOLO versions) that can run in resource-constrained end devices at high FPS, and with reasonable accuracy. However, compression using these tiny models is suboptimal as they perform poorly in videos with smaller objects.

\noindent \textbf{Optimizing data transport in sensor networks.} There is a rich body of work in the sensor network community on reducing the dimensionality of transported data (e.g., ~\cite{deshpande-04}).  Network based video streaming frameworks such as LtC and others~\cite{du2020server,li2020reducto} may be viewed as an instance of this line of work for video sensors.  In the context of video sensor networks, a number of platforms also use compression.  However, they are targeted towards deeply embedded platforms and use traditional compression~\cite{seema-11}, or even just still images, for example, using camera traps~\cite{kays-09}.

% In source-driven approaches, the compression logic is entirely calculated within the source without any feedback from the outside world. \textbf{Glimpse} \cite{chen2015glimpse} uses a source-driven frame differencing to select a cache of frames for server-side analysis. Upon receiving the response from the server, it uses object-tracking heuristics to generate the rest of the results. Whereas, \textbf{Vigil} \cite{zhang2015design} uses a light-weight object counter model on the network edge and sends only those frames with a higher object count. \textbf{FilterForward} \cite{canel2019scaling} uses light-weight binary application-specific micro-classifiers on edge servers to send only relevant frames to the cloud server. 
% \textbf{Adascale} \cite{chin2019adascale} uses inexpensive vision models on the source to predict the best scaling factor for video frames. 
%Although, these client-driven approaches have low computation requirement and can run very fast, they lack in inference accuracy. 

% \textbf{Cloudseg} \cite{wang2019bridging} proposes down-sampling video frames at the source followed by a subsequent up-sampling using super-resolution at the server. Although super-resolution can restore a video frame for increased visual appeal, it fails to regain the low-level features important for object detection accuracy. 
% \textbf{Split-brain} \cite{emmons2019cracking} suggest optimally splitting the DNN black-box to process a fraction of the layers on the source and the rest on the server. This allows the trade-off between source computation and bandwidth usage based on resource availability. Source-driven approaches are sub-optimal in terms of accuracy, as they are limited by the inherent resource deficiency of the source. 
% Moreover, approaches that use tiny models (e.g., Tiny-YOLO) are fast at the cost of their accuracy compared to their larger counterparts. 

% \textbf{Server-driven compression.}
% The server-driven approaches have received more attention mainly due to their high accuracy. \textbf{SimpleProto} \cite{pakha2018reinventing} and \textbf{DDS} \cite{du2020server} propose a server-driven framework where real-time feedback from the server is used in multiple stages to refine the inference result. In the first stage, low-quality video frames are sent to the server for initial object detection, but most importantly, for generating feedback regions. The source later provides these feedback regions to the server in the form of high-quality patches that are later used to detect smaller objects missing in the initial stage. This feedback loop can go on for multiple iterations until satisfactory accuracy is achieved. Although these multi-stage feedback-based approaches can achieve good accuracy, they hinder the system's real-time performance due to multiple stages of round-trip-time (RTT) and processing delay. 

% \textbf{Profiling-based analytics.}
% \textbf{Videostorm} \cite{zhang2017live} and \textbf{Chameleon} \cite{jiang2018chameleon} work on back-end resource management of video analytics pipelines by profiling optimal configuration of pipeline knobs (e.g., video resolution, quantization, sampling rate, etc.) against different types of videos, user queries, etc. The profiling mechanism uses either offline (\textbf{Videstorm}) or online (\textbf{Chameleon}) methods to meet user-specific performance requirements. Similar works include server-driven frameworks \textbf{Reducto} \cite{li2020reducto} and \textbf{AWStream} \cite{zhang2018awstream}, which profile segments of video frames at the server and deploy them at the source for future use. \textbf{Reducto} suggests that the differencing threshold for frame filtering should be dynamic and profiles video segments against optimal thresholds. \textbf{AWStream} takes a more general approach by finding the optimal configuration for adapting to application-specific needs. However, these profiling mechanisms can achieve good accuracy but consume significant time to update and need a handful of new data. 
