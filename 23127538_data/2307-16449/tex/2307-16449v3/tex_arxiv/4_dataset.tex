\section{A New Benchmark: MovieChat-1K}

Previous works on building long video understanding benchmarks either focus on non-question-answering tasks~(\eg, language grounding~\cite{soldan2022mad}, generic event boundary detection~\cite{shou2021generic}, user engagement and movie metadata prediction~\cite{wu2021towards}, \etc) or lack long-form understanding evaluation~\cite{huang2020movienet}. To better evaluate the performance of MovieChat, we collect a new benchmark for long video understanding tasks, MovieChat-1K, which contains 1K high quality video clips sourced from various movies and TV series with 14K manual annotations. 

As shown in Fig.~\ref{fig:category}, we collect videos from 15 popular categories with varying distribution, including documentary film, detective film, animation film, and so on. Among these, each video comprises multiple alternating scenes, contributing to a diverse and dynamic visual narrative within the context of the collection. The visual representation in Fig.~\ref{fig:video_length} demonstrates the clip duration distribution of MovieChat-1K. Over 90\% of the videos exhibit a duration ranging from 10K to 12K frames, while 14.6\% of videos extending beyond 12K frames. Only 8.6\% of videos have duration less than 10k frames.

For each video, we manually set and provide 1 dense caption for the whole video, 3 question-answering pairs for global mode and 10 question-answering pairs with timestamps for breakpoint mode. Fig.~\ref{fig:question_type} illustrates the distribution of question types in MovieChat-1K. Note that MovieChat-1K is specifically designed for long video comprehension tasks, the majority of questions are open-ended, with only a quarter classified as multiple-choice questions, marked by initiators such as `Do,' `Does,' `Is,' or `Are.' We also compute the word distributions of our provided question-answer pairs. As illustrated in  Fig.~\ref{fig:wordcloud}, which includes common objects (people, clothes, etc.), time (day, night, etc.), scenes (indoor, outdoor, etc.), and so on.
More statistics information can be found in appendix.

