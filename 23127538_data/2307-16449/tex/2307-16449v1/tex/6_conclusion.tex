% \section{Limitation}

\section{Conclusion}
In conclusion, this paper presents an innovative video understanding system that integrates video foundation models and large language models. By incorporating a memory mechanism inspired by the Atkinson-Shiffrin model, consisting of short-term and long-term memory represented by tokens in Transformers, the system overcomes challenges associated with analyzing long videos.
The proposed system, named MovieChat, achieves state-of-the-art performance in long video understanding, surpassing existing systems limited to handling videos with few frames. This approach reduces computation complexity, memory cost, and addresses long-term temporal connections.

The study emphasizes the significance of memory mechanisms in video understanding, enabling the model to retain and retrieve relevant information over extended durations. MovieChat's success has practical implications in domains like video surveillance, content analysis, and video recommendation systems.
Future research can explore further improvements to the memory mechanism and the integration of other modalities, such as audio, to enhance video understanding capabilities. This work opens up opportunities for applications requiring a comprehensive understanding of visual information.