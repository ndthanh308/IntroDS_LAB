\appendix
\renewcommand\thefigure{\Alph{section}\arabic{figure}}
\section*{Appendix}

\section{LLM-Assisted Evaluation}
\label{sec:gpt-eval}
Following~\cite{maaz2023video}, we use LLM-Assisted Evaluation for short video question answering task in Section~\ref{exp:quantitative}. Given the question, correct answer, and predicted answer by model, ChatGPT should return the \textit{True} or \textit{False} judgement and relative score ($0$ to $5$). The whole prompt is shown in Figure~\ref{fig:prompt}. It takes about $250$ tokens per question. We report the baseline results of short video question answering from \url{https://github.com/mbzuai-oryx/Video-ChatGPT}.
\setcounter{figure}{0}
\input{fig/prompt}

\section{Hyper-parameter Setting}
\label{sec:hyper-param}

\input{tab/hyper-param}