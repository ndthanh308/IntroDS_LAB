% \begin{table}[t]
% \centering
% \Large
% \setlength{\tabcolsep}{8pt}
% \renewcommand{\arraystretch}{1.3}
% \resizebox{\linewidth}{!}{
% \begin{tabular}{@{} l c c c c c c @{}}
% \toprule
% \multirow{2}{*}{\textbf{Method}} & \multicolumn{2}{c}{\textbf{MSVD-QA}} & \multicolumn{2}{c}{\textbf{MSRVTT-QA}} & \multicolumn{2}{c}{\textbf{ActivityNet-QA}} \\
% \cline{2-7}
%  & \textbf{Accuracy} & \textbf{Score} & \textbf{Accuracy} & \textbf{Score} & \textbf{Accuracy} & \textbf{Score}\\
% \midrule
% FrozenBiLM~\cite{yang2022zero} & 32.2 & -- & 16.8 & -- & 24.7 & -- \\
% Video Chat~\cite{li2023videochat} & 56.3 & 2.8 & 45.0 & 2.5 & 26.5 & 2.2 \\
% LLaMA Adapter~\cite{zhang2023llama} & 54.9 & 3.1 & 43.8 & \underline{2.7} & 34.2 & 2.7 \\
% Video LLaMA~\cite{zhang2023video} & 51.6 & 2.5 & 29.6 & 1.8 & 12.4 & 1.1 \\
% Video-ChatGPT~\cite{maaz2023video} & \underline{64.9} & \underline{3.3} & \underline{49.3} & \textbf{2.8} & \underline{35.2} & \underline{2.7} \\ 
% \midrule
% MovieChat~\textit{(Ours)} & \textbf{75.2} & \textbf{3.8} &\textbf{52.7} & 2.6 & \textbf{45.7} & \textbf{3.4}\\
% \bottomrule
% \end{tabular}
% }
% \caption{Quantitative evaluation for short video question answering with GPT. MovieChat achieves comparable performance even it is not specifically designed for for short video question-answering tasks. The best result is highlighted in bold, and the second best is underlined. The best result is highlighted in bold, and the second best is underlined.}
% \label{tab:short}
% \end{table}


\begin{table}[t]
\centering
\Large
\setlength{\tabcolsep}{8pt}
\renewcommand{\arraystretch}{1.3}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{} l c c c c c c @{}}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{2}{c}{\textbf{MSVD-QA}} & \multicolumn{2}{c}{\textbf{MSRVTT-QA}} & \multicolumn{2}{c}{\textbf{ActivityNet-QA}} \\
\cline{2-7}
 & \textbf{Accuracy} & \textbf{Score} & \textbf{Accuracy} & \textbf{Score} & \textbf{Accuracy} & \textbf{Score}\\
\midrule
FrozenBiLM~\cite{yang2022zero} & 32.2 & -- & 16.8 & -- & 24.7 & -- \\
Video Chat~\cite{li2023videochat} & 56.3 & 2.8 & 45.0 & 2.5 & 26.5 & 2.2 \\
LLaMA Adapter~\cite{zhang2023llama} & 54.9 & 3.1 & 43.8 & \underline{2.7} & 34.2 & 2.7 \\
Video LLaMA~\cite{zhang2023video} & 51.6 & 2.5 & 29.6 & 1.8 & 12.4 & 1.1 \\
Video-ChatGPT~\cite{maaz2023video} & \underline{64.9} & \underline{3.3} & \underline{49.3} & \textbf{2.8} & \underline{35.2} & \underline{2.7} \\ 
\midrule
MovieChat~\textit{(Ours)} & \textbf{75.2} & \textbf{3.8} &\textbf{52.7} & 2.6 & \textbf{45.7} & \textbf{3.4}\\
\bottomrule
\end{tabular}
}
\caption{Quantitative evaluation for short video question answering with GPT-3.5~\cite{gpt3.5}. MovieChat achieves comparable performance even it is not specifically designed for for short video question-answering tasks. The best result is highlighted in bold, and the second best is underlined. }
\label{tab:short}
\end{table}