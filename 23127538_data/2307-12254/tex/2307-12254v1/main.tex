\documentclass[journal,twocolumn,10pt]{IEEEtran}
\IEEEoverridecommandlockouts
%\renewcommand{\baselinestretch}{.9775}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts,mathrsfs,amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{comment}
%\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage{adjustbox}
\usepackage{balance}
%\usepackage{caption}
\usepackage{subcaption}
\usepackage{orcidlink}
\usepackage{stfloats} %Package for adding long equations in a line at bottom
\newtheorem{theorem}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{remark}{Remark}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=teal,
    filecolor=magenta,      
    urlcolor=cyan,
    %pdfpagemode=FullScreen,
    citecolor=teal
    }
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\begin{document}

\title{Semantic Communication-Empowered Traffic Management using Vehicle Count Prediction}

\author{Sachin~Kadam$^{\orcidlink{0000-0001-7085-3365}}$~and~Dong~In~Kim$^{\orcidlink{0000-0001-7711-8072}}$,~\IEEEmembership{Fellow,~IEEE}% <-this % stops a space
\thanks{A preliminary version of this paper is submitted to a conference and is currently under review~\cite{kadam2023semantic}.}% <-this % stops a space
\thanks{S.~Kadam and D.~I.~Kim are with the Department of Electrical and Computer Engineering, Sungkyunkwan University (SKKU), Suwon 16419, Republic of Korea (e-mail: sachinkadam@skku.edu, dikim@skku.ac.kr).}}% <-this % stops a space

\maketitle

\begin{abstract}
Vehicle count prediction is an important aspect of smart city traffic management. Most major roads are monitored by cameras with computing and transmitting capabilities. These cameras provide data to the central traffic controller (CTC), which is in charge of traffic control management. In this paper, we propose a joint CNN-LSTM-based semantic communication (SemCom) model in which the semantic encoder of a camera extracts the relevant semantics from raw images. The encoded semantics are then sent to the CTC by the transmitter in the form of symbols. The semantic decoder of the CTC predicts the vehicle count on each road based on the sequence of received symbols and develops a traffic management strategy accordingly. An optimization problem to improve the quality of experience (QoE) is introduced and numerically solved, taking into account constraints such as vehicle user safety, transmit power of camera devices, vehicle count prediction accuracy, and semantic entropy. Using numerical results, we show that the proposed SemCom model reduces overhead by $54.42\%$ when compared to source encoder/decoder methods. Also, we demonstrate through simulations that the proposed model outperforms state-of-the-art models in terms of mean absolute error (MAE) and QoE.

\end{abstract}

\begin{IEEEkeywords}
Semantic Communications, Deep Learning, 6G, Traffic Control, Wireless Communications 
\end{IEEEkeywords}
%\vspace{-.2cm}
\section{Introduction} \label{Sec:Intro}
The efficient management of vehicular traffic is a key problem in smart city projects. 
The central traffic controller (CTC), which is responsible for traffic control management, requires real-time information on the vehicle density on all major roads.\footnote{Suppose there is heavy traffic on road A, and the traffic controller releases traffic on road B, leading these vehicles to road A, the average waiting time increases. Instead, it can divert some of this traffic to another road C in order to reduce the average waiting time.}
The actions of the CTC to control traffic movement can include traffic holding, releasing, diverting, etc. The CTC requires information regarding the vehicles, including the estimated count, location, size, etc. The CTC devises an optimal strategy for efficient traffic management using the information collected from all camera devices, and the actions required to implement this strategy are communicated to users via traffic lights and giant display screens.\footnote{The CTC communicates with the traffic lights and giant display screens via wired networks.}
A typical traffic model of a smart city with several entry and exit points is shown in Fig.~\ref{fig:TrafficModel}. 
% Figure environment removed
In any traffic management system of a smart city, the purpose is to minimize the average travel time of a traveler to cross a city, i.e., the average time taken between entry and exit points. The average traveling time includes the sum of the time taken while driving and the waiting time at the traffic signals. For this purpose, a fast and accurate prediction of vehicle counts across all major roads is important. 

Several cameras are strategically placed to capture a sequence of images of moving vehicles on the roads. These cameras are part of devices that have computing and transmitting capabilities. The captured raw images are large in size, and transmitting them would add unnecessary overhead to the important data while also increasing the burden on network traffic. Furthermore, the CTC discards irrelevant information from the images received from these devices. This motivates us to propose a semantic communication (SemCom)-based vehicle count prediction model that is fast and accurate. We discuss the proposed model in detail in Section~\ref{Sec:SysModel}. 

Semantic communication is a process that involves transmitting only the information that is relevant to a specific task or job to the intended recipient, resulting in a highly efficient and intelligent system with significantly reduced data traffic~\cite{qin2021semantic}. SemCom systems have attracted a research boom in recent times due to their wide applications in the context of text~\cite{xie2021deep,kadam2023knowledge}, image~\cite{kang2022personalized,lokumarambage2023wireless}, speech~\cite{han2022semantic,weng2021semantic}, and video~\cite{wang2022wireless, jiang2022wireless}, transmissions. In the context of image transmission, rather than transmitting the entire image as bit sequences, a SemCom-based transmitter extracts only the crucial elements from the source that are necessary for identifying the objects, such as vehicles in the context of traffic management. Extraneous information, such as the sky background, shadows, vegetation, buildings, etc., is eliminated to reduce the amount of data to be transferred without compromising the accuracy of prediction. As a result, there is a significant drop in demand for both power and wireless resources. This results in a more sustainable communication network.

The semantic encoders for image data are typically designed to generate a high-dimensional vector representation of an image that captures its semantic meaning or structure. The most popular semantic encoders for image data include convolutional neural networks (CNNs)~\cite{goodfellow2016deep}.  CNNs are a type of neural network that have proven to be effective for image recognition and classification tasks. They are also shown to perform well even if the sequences of images have low frame rates, heavy occlusion, poor resolution, and so on~\cite{zhang2017fcn}. CNNs are designed to extract features from images at various levels of abstraction automatically, and the resulting feature maps can be used as a semantic representation of the image. Its potential benefits are numerous, including lowered network traffic, limited transmission data overhead, reduced computing complexities at the CTC, and so on. Long short-term memory networks (LSTMs)-based semantic decoders are preferred in the receiver to leverage the temporal correlations between the sequence of images. As a result, the proposed semantic encoder and decoder architecture makes use of CNNs' ability to predict at the pixel level and the LSTM's expertise in learning complex temporal dynamics. The joint CNN-LSTM-based semantic encoder-decoder model improves feature representation and allows for an end-to-end trainable mapping from pixels to the prediction of vehicle density, resulting in a novel approach to the problem of vehicle count prediction.

The organization of the paper is as follows: A brief literature review on SemCom technologies is provided in Section~\ref{Sec:RelatedWork}. We introduce our proposed joint CNN-LSTM-based system model in Section~\ref{Sec:SysModel}. Next, we formulate an optimization problem for the enhancement of QoE of vehicle users in Section~\ref{Sec:Optimizatio}. We provide a few useful simulation results based on the SemCom system design and QoE maximization in Section~\ref{Sec:Simulations}. Finally, we conclude and provide a few directions for future research based on the paper in Section~\ref{Sec:Conclusions}.

\section{Related Work} \label{Sec:RelatedWork}
Traffic management in smart cities using Intelligent Transportation Systems (ITS) is a well-studied problem in the literature~\cite{papageorgiou2007its}.  ITS provides robust solutions for real-time traffic network monitoring, prediction, and actuation. 
Recently, due to the emergence of SemCom systems, the implementation of traffic control methods has improved~\cite{raha2023artificial}. A survey paper for a comparison of various traffic models is discussed in~\cite{storani2021analysis}. Semantic feature extraction is a crucial part of any SemCom-based system. For this purpose, based on the context, several deep learning approaches are used for feature extraction. 

The vehicle counting prediction models are designed in several works~\cite{kilic2021accurate,zhao2022vehicle,jin2022dense,hu2022wsnet,asha2018vehicle,hu2022skt,cao2022ghostcount,guo2022dense,sawah2023accurate,xu2022efficient}. A simple and effective single-shot detector model for detecting and counting cars from stationary images is proposed in~\cite{kilic2021accurate}. Another vehicle counting model that takes advantage of cross-resolution spatial consistency and intra-resolution time regularity restrictions is proposed in~\cite{zhao2022vehicle}. But these approaches work effectively when there is no temporal interrelation between the sequence of images. The synergistic attention network (SAN)-based vehicle counting approach is proposed in~\cite{jin2022dense} wherein this method performs dense counting assignments by combining the benefits of transformers and convolutions. A method for estimating local-global traffic density based on weakly supervised learning (WSNet) is proposed in~\cite{hu2022wsnet}. A handheld camera-captured traffic video on a highway is used to propose a video-based vehicle counting method in~\cite{asha2018vehicle}. In this work, three steps are used to process a video: object detection, tracking, and counting. Based on structured knowledge transfer, a lightweight traffic density estimation method (Le-SKT) is proposed in~\cite{hu2022skt}. GhostCount, a lightweight CNN, designed specifically for high-accuracy vehicle counts on edge devices, is proposed in~\cite{cao2022ghostcount}. First, they combined ResNet-18 and Lightweight RefineNet network architectures capable of extracting vehicle features in complex traffic scenes, and then they replaced the regular convolutional layers in ResNet-18 with Ghost modules. For dense traffic detection at highway-railroad crossings, a dense traffic detection net (DTDNet) is developed in~\cite{guo2022dense}. The vehicle counting methods using only gated recurrent unit (GRU) and, also only LSTM are proposed in~\cite{sawah2023accurate}.  Based on a cooperative learning framework, two vehicle counting approaches are proposed in~\cite{xu2022efficient}. Apart from vehicle counting, deep learning models are designed in different contexts like crowd counting~\cite{li2018csrnet,wang2020distribution,yan2021crowd}, object counting~\cite{moreu2022domain,cheng2022rethinking}, crowd-and-vehicle counting~\cite{yu2022frequency}, and so on.
%TODO: Add a few more papers on vehicle counting and traffic management.

However, most of these vehicle count prediction models have low accuracy, are not robust to vehicle movement, do not capture real-time data, are dependent on accurate data, have high latency in acquiring data, and so on. The most important aspect of any traffic management system is the ability to predict the vehicle count quickly and accurately, which is the focus of this paper.

The next step is to develop a traffic control strategy to maximize the QoE of a given vehicle user based on the vehicle count prediction. Some works in the literature focused on traffic management based on vehicle count predictions~\cite{chavhan2020prediction,khanna2019intelligent,jiang2021urban,afrin2022long,wismans2014real,ashwini2020data}. In~\cite{chavhan2020prediction}, using both static and mobile agents of a traffic network, a traffic management system based on the vehicle prediction is proposed. A static agent creates and distributes information such as traffic flow parameters (for example, speed, density, etc.) to mobile agents in the metropolitan area. These mobile agents use an emerging intelligence technique to quickly gather and share historical data, resource information, spatio-temporal data, and static agent analysis. The proposed system model in~\cite{khanna2019intelligent} uses machine learning algorithms to predict the best routes based on factors like vehicle classification, accident frequency, vehicle count estimation, and traffic mobilization patterns. In~\cite{jiang2021urban}, an urban traffic signal control system based on traffic flow prediction is developed by combining traffic flow prediction and traffic light schedule optimization. The goal is to reduce the overall volume of blocked traffic at all intersections in the road network. In~\cite{afrin2022long}, a paradigm for LSTM-based correlated traffic data prediction is proposed. The data is first pre-processed to identify spatial and temporal trends as well as correlations between the series of data that have been collected (using LSTM). By aggregating the temporal and spatial trend forecasts, the Kalman-filter method was also used to arrive at the final prediction. In~\cite{wismans2014real}, an approach for predicting the short-term status of traffic is discussed and implemented in a real-world scenario for the Dutch city of Assen. This forecast is based on a macroscopic dynamic traffic assignment model that links online traffic data with a real-time traffic model. In~\cite{ashwini2020data}, an effort has been made to implement a classification of data sources, including cutting-edge sources like social media and cellular network data, for traffic prediction. Under each data source, specific contributions to traffic prediction are shown. All of these studies, however, ignore the user's perspective on traffic management as well as the burden that high data transfer volumes for traffic control place on wireless channels. In this paper, these problems are also discussed.

\section{System Model}\label{Sec:SysModel}
% % Figure environment removed
% Figure environment removed 
% Figure environment removed 
The block diagram of our proposed SemCom system model is shown in Fig.~\ref{fig:NetworkModel}. In this system model, camera devices with computing and transmitting capabilities capture raw images. The semantic encoder then extracts the relevant semantics (density maps in this context) from them. Channel encoders then convert them into symbols for transmission. Before reaching the receiver, the symbols are corrupted by channel noise. The channel and semantic decoders predict density maps from the received symbols, which are then used for vehicle counting and traffic control management. 
We exploit the strengths of convolutional neural networks (CNNs) in the semantic encoder (see Section~\ref{Sec:SemEncoder}) for dense visual prediction and of long short-term memory networks (LSTMs) in the semantic decoder (see Section~\ref{Sec:SemDecoder}) for modeling temporal correlation, which are coupled in a partial residual learning framework. At the transmitter, first, the density maps ($D$) are extracted from the sequence of input raw images ($G$) in the semantic encoder using a CNN shown in Fig.~\ref{fig:CNNBlocks}. That is 
\begin{equation}
    D = \mathscr{S}_{\theta_e}(G),
\end{equation}
where $\mathscr{S}_{\theta_e}$ denotes the semantic encoder parameterized by $\theta_e$.
This process keeps only task-relevant information in the data, resulting in a substantial reduction in the overhead\footnote{An example to show this reduction is provided in Section~\ref{Sec:Simulations}.}.    
Next, these density maps are encoded into symbols using the channel encoder, $\mathscr{C}_{\phi_e}$, parameterized by $\phi_e$. After encoding $D$, we get the following set of symbols: $X = \mathscr{C}_{\phi_e} (D)$.
% \begin{equation}
%     X = \mathscr{C}_{\phi_e} (D).
% \end{equation}

The encoded set of symbols $X$ is transmitted via the log-normal channel (for channel modeling details, refer to Section~\ref{Sec:ChannelModel}). The channel must allow back-propagation for end-to-end training of the semantic encoder and decoder blocks. Simple neural networks, which may create physical channels, for example, are used to represent the log-normal channel.  Let $H$ be the channel gain and $\eta$ be the noise that gets added to $X$ during transmission. Then, the set of received symbols at the receiver is $Y = HX + \eta$. 

After receiving, this set of symbols is decoded using the channel decoder $\mathscr{C}_{\phi_d}$, parameterized by $\phi_d$. After decoding $Y$, we get the following density maps
\begin{equation}
    Z = \mathscr{C}_{\phi_d}(Y).
\end{equation}
Now, to explore the temporal correlations between the sequence of density maps, the LSTM cells are utilized in the semantic decoder. Also, instead of directly connecting the residual, as in ResNet~\cite{he2016deep}, a partial residual connection is preferred. 
For this purpose, we introduce a hyper-parameter $p \in [0,1]$, which is multiplied with $Z$ before the addition with the output of semantic decoders $\mathscr{S}_{\theta_d}$, parameterized by $\theta_d$. The output of the semantic decoder is passed through a fully connected (FC) layer, parameterized by $\alpha$, for vehicle count prediction. Hence, the vehicle count prediction is formulated as:
\begin{align}
    \widehat{n} = \mathscr{F}_{\alpha}(\mathscr{S}_{\theta_d}(Z)) + p Z.
\end{align}

\subsection{Semantic Encoder} \label{Sec:SemEncoder}
The architecture of the designed semantic encoder using a CNN is shown in  Fig.~\ref{fig:CNNBlocks}. We input the images of size $\ell \times w$, where $\ell$ and $w$ denote the length and width, respectively. The filters are applied such that the output density also has the size $\ell \times w$. The kernels of size $3\times3$ are applied to both convolution and deconvolution layers, as inspired by the VGG-net~\cite{simonyan2014very}. To compensate for the loss of spatial information caused by max pooling, the number of filter channels in the higher layers is increased. In order to reduce the number of parameters, the small filter channels are sandwiched between convolution blocks in a few higher layers. 

Next, we use Atrous convolution, which is equivalent to filter upsampling, by inserting holes between nonzero filter taps. It computes feature maps more densely, then performs simple bilinear interpolation of the feature responses back to the original image size. In comparison to regular convolution, atrous convolution effectively increases the field of view of filters without increasing the number of parameters.  Following that, a convolution layer with $1\times1$ kernels is added to perform feature re-weighting in order to encourage the weighted feature volume to distinguish between foreground and background pixels better. The input of the deconvolution network, which has two deconvolution layers, is the combined and re-weighted feature volume. Lastly, a convolution layer with $1\times1$ kernels acts as a predictor to map features into a vehicle density map.
\subsection{Semantic Decoder} \label{Sec:SemDecoder}
% Figure environment removed 
In order to incorporate the temporal correlation of vehicle counts from sequential frames, LSTM cells are used to jointly learn vehicle density and vehicle count. The schematic diagram of a single LSTM cell is shown in Fig.~\ref{fig:LSTMBlocks}(a). An LSTM cell consists of three gates: a forget gate $f_t$, an input gate $i_t$, and an output gate $o_t$. These gates allow LSTM to learn and optimize long-term dependencies in succession. Also, LSTM successfully addresses the gradient vanishing/exploding concerns that frequently arise during recurrent neural network training.  It also includes the cell activation vector $c_t$ and the hidden output vector $h_t$. The input gate uses sigmoid function $\sigma_i$ with weight parameters $W_{xi},W_{hi},W_{ci}$, and bias $b_i$; the forget gate uses sigmoid function $\sigma_f$ with weight parameters $W_{xf},W_{hf},W_{cf}$, and bias $b_f$; the output gate uses sigmoid function $\sigma_o$ with weight parameters $W_{xo},W_{ho},W_{co}$, and bias $b_o$.  Also, $\tanh$ functions are used with weight parameters $W_{xc}$, $W_{hc}$, and bias $b_c$. The update equations are obtained as follows (see Fig.~\ref{fig:LSTMBlocks}(a))~\cite{graves2013generating}: 
\begin{subequations}
\begin{align} 
& i_{t}=\sigma_{i}(x_{t}W_{xi}+h_{t-1}W_{hi}+c_{t-1}W_{ci}+b_{i}),\\ 
& f_{t}=\sigma_{f}(x_{t}W_{xf}+h_{t-1}W_{hf}+c_{t-1}W_{cf}+b_{f}),\\ 
& c_{t}=f_{t}\odot c_{t-1}+i_{t}\odot \tanh(x_{t}W_{xc}+h_{t-1}W_{hc}+b_{c}),\\ & o_{t}=\sigma_{o}(x_{t}W_{xo}+h_{t-1}W_{ho}+c_{t}W_{co}+b_{o}),\\ 
& h_{t}=\sigma_{t}\odot \tanh{(c_{t})},
\end{align}
\end{subequations}
where $\odot$ denotes the element-wise product. 

Next, the received density map $Z$ is converted into a one-dimensional vector $x_t$ and fed into the semantic decoder, which consists of three layers of 100 LSTM cells as shown in Fig.~\ref{fig:LSTMBlocks}(b). The total of the learned density map over each frame is used as a base count, and the output hidden vector of the last LSTM layer is input into one fully connected (FC) layer, parameterized by $\alpha$, to learn the difference between the ground truth count and the final estimated count. Numerically, we observed that the partial (p) residual connection simplifies training and improves counting accuracy as compared to the residual connection (see Fig.~\ref{fig:plots_Loss_MAE}(b)).
\subsection{Model Training} \label{Sec:ModelTrain}
The procedure to train the proposed joint CNN-LSTM-based SemCom model is shown in Algorithm~\ref{alg:training}. 
\begin{algorithm}
\caption{Joint CNN-LSTM-based SemCom model training algorithm}\label{alg:training}
\begin{algorithmic}
\State \textbf{Input:} $N, \{G_i,n^0_i, i \!=\! 1, .., N\},p, \lambda, H, K, \overline{T}$, $\eta \! \sim  \!AWGN$ 
\State Initialize $k=1$, $\mathscr{L}_{count} = \overline{T}$
\While{$k \le K$ OR $\mathscr{L}_{count} < \overline{T}$} \Comment{Iterate over $K$ epochs}
\State Initialize $i=1$
\While {$i \le N$} \Comment{Iterate over $N$ batches}
\State $D_i \gets \mathscr{S}_{\theta_e}(G_i)$ \Comment{Semantic Encoder}
%\State $\mathscr{L}_{Enc} \gets \frac{1}{N} \sum_{i=1}^N \Delta_i$ \Comment{Sem. Encoder Loss}
\State $\Delta_i \gets \sum_{m=1}^M \left(D_i(m) - D^0_i(m) \right)^2$
\State $X_i \gets \mathscr{C}_{\phi_e}(D_i)$ \Comment{Channel Encoder}
\State $Y_i \gets HX_i + \eta$
\State $Z_i \gets \mathscr{C}_{\phi_d}(Y_i)$ \Comment{Channel Decoder}
\State $\widehat{n}_i \gets \mathscr{F}_{\alpha}(\mathscr{S}_{\theta_d}(Z_i)) + p Z_i$ \Comment{Semantic Decoder}
%\State $\widehat{D} \gets \mathscr{S}_{\theta_d}(Z) + p Z$ \Comment{Semantic Decoder}
%\State $V \gets \mathcal{F}_{1\times1}(\widehat{D})$ \Comment{$1\times1$ Convolutional layer}
%\State $\widehat{n}_i \gets \sum_{j=1}^J V(j)$
% \State $\mathscr{L}_{Dec} \gets \frac{1}{N} \sum_{i=1}^N \left(\widehat{n}_i - n^0_i \right)^2$ \Comment{Sem. Decoder Loss}
% \State $\mathscr{L}_{count} \gets \mathscr{L}_{Enc} + \lambda \mathscr{L}_{Dec}$ \Comment{Overall Loss}
\State $i \gets i+1$
\EndWhile
\State $\mathscr{L}_{Enc} \gets \frac{1}{N} \sum_{i=1}^N \Delta_i$ \Comment{Sem. Encoder Loss}
\State $\mathscr{L}_{Dec} \gets \frac{1}{N} \sum_{i=1}^N \left(\widehat{n}_i - n^0_i \right)^2$ \Comment{Sem. Decoder Loss}
\State $\mathscr{L}_{count} \gets \mathscr{L}_{Enc} + \lambda \mathscr{L}_{Dec}$ \Comment{Overall Loss}
\State $k \gets k+1$
\EndWhile
\State \textbf{Output:} $\mathscr{S}_{\theta_e}, \mathscr{C}_{\phi_e},
\mathscr{S}_{\theta_d},  \mathscr{C}_{\phi_d}, \mathscr{F}_{\alpha}$.
\end{algorithmic}
\end{algorithm}
For each frame, the semantic encoder predicts the pixel-level density map, while the semantic decoder predicts the vehicle count. These two goals are accomplished in tandem by training the joint CNN-LSTM-based SemCom network end-to-end. The vehicle density is predicted from the feature map using the final $1\times1$ convolution layer of the semantic encoder (see Fig.~\ref{fig:CNNBlocks}). The loss function for density map estimation at the semantic encoder is as follows:
\begin{align}
    \Delta_i &= \sum_{m=1}^M \left(D_i(m) - D^0_i(m) \right)^2, \\
    \mathscr{L}_{Enc} &= \frac{1}{N} \sum_{i=1}^N \Delta_i,
\end{align}
where $D_i(m)$ and $D^0_i(m)$ denote the predicted density map and ground truth density map, respectively, for frame $i$ at pixel $m, \forall m \in \{1, \ldots, M\}$, and $N$ is the batch size. 
Next, the semantic decoder (see Fig.~\ref{fig:NetworkModel}) along with FC layer predicts the vehicle count from the reconstructed density map at the receiver by using the  following expression:  
\begin{equation}
    \widehat{n}_i = \mathscr{F}_{\alpha}(\mathscr{S}_{\theta_d}(Z_i)) + p \sum_{m=1}^M Z_i(m).
\end{equation} 
The squared loss function is used for measuring the vehicle count loss, which is defined as
\begin{equation}
    \mathscr{L}_{Dec} = \frac{1}{N} \sum_{i=1}^N \left(\widehat{n}_i - n^0_i \right)^2,
\end{equation}
where $\widehat{n}_i$ and $n^0_i$ are the predicted vehicle count and ground truth vehicle count, respectively, for frame $i$.
The overall loss $\mathscr{L}_{count}$, used for training the system model is 
\begin{equation}
    \mathscr{L}_{count} = \mathscr{L}_{Enc} + \lambda \mathscr{L}_{Dec},
\end{equation}
where $\lambda$ is a hyper-parameter. 
The batch-based Adam approach~\cite{kingma2014adam}, which is a first-order gradient-based optimization of stochastic objective functions, is used to optimize the loss function.  The model is trained over either a fixed number of $K$ epochs or until the training loss falls below a predetermined threshold value $\overline{T}$. 

\section{Optimization Problem Formulation}\label{Sec:Optimizatio}
The main goal of the optimization problem formulation is to maximize the QoE of a given vehicle user crossing a smart city whose road traffic network model is shown in Fig.~\ref{fig:TrafficModel}. Before presenting our problem formulation (see Section~\ref{Sec:ProbFormulation}), in the following subsections, we first describe the constraints that affect the QoE.
\subsection{Traffic Management}\label{Sec:TrafficModel}
In~\cite{storani2021analysis}, various traffic models are proposed. For ease of tractability, we use a simple traffic model as shown in Fig.~\ref{fig:TrafficModel}. We are minimizing the average travel time of a traveler to cross a city, i.e., the average time taken between entry and exit points. We also assume that this average travel time includes the time taken while driving and the waiting time at the traffic signals. The driving speed is such that every vehicle maintains a certain minimum distance from a nearby vehicle all the time. In our traffic model, we assume the car-following model, proposed in~\cite{krauss1998microscopic}, since in dense traffic networks there is always a vehicle in front of any other vehicle. 

Let, at a given time $t$, $v_\ell(t)$ and $v_f(t)$ be the speeds of the leading vehicle and the following vehicle, respectively. Let $g(t)$ and $\rho$ be the gap between the leading and the following vehicles and the reaction time of drivers, respectively. Similarly, $a$ and $b$ denote the acceleration and deceleration values of the vehicle, respectively. Then, from the car-following model~\cite{krauss1998microscopic}, the safe speed $v^x_{s}$ and the desired speed $v^x_{d}$ of the vehicle $x$, respectively, are
\begin{align}
v^x_{s} &= v_{\ell}(t) + \frac{{g(t) - v_{\ell} (t)\rho }}{{\frac{{v_{\ell} (t) + v_{f} (t)}}{2b} + \rho }}, \\
v^x_{d} &= \min \left[ {v_0 , v(t) + at,v^x_{s}} \right],
\end{align}
where $v_0$ denotes the maximum attainable speed of the vehicle. Additionally, traffic management enforces a speed limit of $\bar{v}$ on every vehicle in the network to ensure safe passage through the city traffic network.

Let $M_e$ and $M_x$ be the number of entry and exit points in the traffic model, as shown in Fig.~\ref{fig:TrafficModel}. Suppose the given vehicle enters the city from an entry point $A_i, i\in \{1, \ldots, M_e\}$, and exits the city from an exit point $B_j, j\in \{1, \ldots, M_x\}$. We assume that while traveling, the vehicle $x$ always travels at the desired speed $v^x_d$. Let $d(i,j), i\in \{1, \ldots, M_e\}, j\in \{1, \ldots, M_x\}$, be the distance between $A_i$ and $B_j$. Then the average time taken by the vehicle $x$ during motion, $t_m^x(i,j)$, between $A_i$ and $B_j$ is given by the following expression:
\begin{align}
    t_m^x(i,j) = \frac{d(i,j)}{v_d^x}.
\end{align}

Now, we consider the waiting time at traffic signals. Let $R(i,j)$ be the number of traffic signals between $A_i$ and $B_j$. And let $\tau_r^x$ be the waiting time for vehicle $x$ at traffic signal $r \in \{1, \ldots, R(i,j)\}$. Then the total waiting time, $t_w^x(i,j)$,  during the journey between $A_i$ and $B_j$ is
\begin{align}
    t_w^x(i,j) = \sum_{r=1}^{R(i,j)} \tau_r^x.
\end{align}

The CTC controls the waiting time $\tau_r^x$, experienced by vehicle $x$, at any traffic signal. It modifies traffic signal stoppage times based on vehicle density on each road.\footnote{We ignore the minimum holding time at a traffic junction so that pedestrians can cross the road for ease of analysis. We assume that appropriate underground and above-ground crossings are provided for pedestrians.} The CTC estimates vehicle density based on the semantics (heatmaps) received from the various devices and devises a strategy for minimizing the average travel time of any vehicle entering and exiting the city.

Let $T$ be the time period for which we plan to examine the average delay. Let $N$ be the number of vehicles that entered and exited the city limits in the time period $T$.
Without loss of generality, consider the evaluation period as $[0,T]$. Let $t_1^x(i), i\in \{1, \ldots, M_e\}$, and $t_2^x(j), j\in \{1, \ldots, M_x\}$, be the time instants of vehicle $x$ entry from $A_i$ and exit from $B_j$, respectively, where $t_1^x(i), t_2^x(j) \in [0,T]$ and $t_1^x(i) < t_2^x(j)$. Let $\delta^x(i,j) = t_2^x(j) - t_1^x(i)$. Then $\delta^x(i,j)$ indicates the time taken by the vehicle $x$ to cross the city, which is the same as the sum of time spent by it during motion and the time spent waiting at the traffic signals,\footnote{For ease of explanation, we ignore the other stoppages during the journey like parking for some emergency issue, lane changing delays, overtaking of leading vehicles, etc.} i.e.,
\begin{align}
    \delta^x(i,j) &= t_m^x(i,j) + t_w^x(i,j),
    \\
    &= \frac{d(i,j)}{v^x_d} + \sum_{r=1}^{R(i,j)} \tau^x_r. 
\end{align}
Let $\mathcal{Y}(i,j) = \{y_1(i,j), \ldots, y_{c_{ij}}(i,j)\}$ denote the set of vehicles travelled between entrance $A_i$ and exit $B_j$ during $[0,T]$ and $N_0 = |\mathcal{Y}(i,j)|$. So the total time taken by the vehicles traveling  between entrance $A_i$ and exit $B_j$ is
\begin{align}
    \Delta(i,j) = \sum_{\forall x \in \mathcal{Y}(i,j)} \delta^x(i,j). \label{eq:Delta}
\end{align}
Then the average time taken by any vehicle crossing the city limits is
\begin{align}
    \bar{t} = \frac{1}{N_0}  \sum_{i=1}^{M_e} \sum_{j=1}^{M_x} \Delta(i,j). \label{eq:t_bar}
\end{align}
The traffic management attempts to minimize $\bar{t}$ subject to the safety constraints.

%\begin{comment}
%TODO: Check we can model this: (Need to define several terms of queueing theory) The arrival process can be modeled as Poisson process. Then the expected number of vehicles can be found (there is an equation for that).
%\end{comment}

\subsection{Channel Modeling}\label{Sec:ChannelModel}
Now, we focus on the properties of the propagation channel that allow us to understand the performance of the network consisting of city camera devices and the CTC. We provide path loss models for communications between the transmitter-equipped camera devices and the receiver-equipped CTC. These path loss models specify the parameters of statistical models for large-scale attenuation; based on the large-scale attenuation outcome for a given position, one can measure the outage probability due to the shadow fading variations, whose models are also discussed. We evaluate the fading effects on the reliability of the wireless network using these path loss models for urban (city) environments.\footnote{These models cluster different conditions, such as urban, suburban, and rural settings, into a certain path loss rather than looking at the specific landscape that characterizes a specific location. There are, however, models\cite{ITU_Doc} that account for that and are therefore more accurate at predicting the actual path loss that affects a deployment in a certain geographical location. The models used require integration with a three-dimensional map of the environment, which is provided by Geographic Information System (GIS) tools. They incorporate GIS information as input and compute the path loss between two points in the map based on the standard model in \cite{ITU_Doc}.} 

\subsubsection{Path Loss Models and Outage Probability}\label{Sec:PL_Models}
Path loss is defined as the reduction in the power density of an electromagnetic signal wave as it propagates through various channels such as space, water, soil, etc. We design analytical path loss models for transmitter-equipped camera devices and receiver-equipped CTC deployments for a traffic network. The authors in \cite{5G_Doc} have studied average path loss models for line of sight (LoS) and non-line of sight (NLoS) propagation in the range of 5G frequencies between 0.5 and 100GHz, both for urban as well as rural settings. To model the great diversity of the boundary conditions for the signal propagation encountered, in wireless coverage studies the effect of path loss and shadowing is typically modeled as a random variable that has a log-normal distribution. These models are referred to as ``large scale fading'' models, to distinguish them from the multipath fading effects that are called ``small scale fading'' and occur during transmission. While the latter captures the variability of a given propagation channel, the former accounts for the placement of the transmitter and receiver positions. The log-normal shadow fading model implies that the propagation loss in dB ($ L_{dB}=10\log_{10}{\rm L}$), averaged over the small scale fading changes, for a given location, in a certain type of terrain, can be modeled as a Gaussian random variable. Path loss models provide the parameters of the distribution and, more specifically, expressions for the expected loss in dB, which is the mean of the Gaussian random variable.
The average path loss for LoS and NLoS models~\cite{5G_Doc} are provided in~\eqref{eq:PL_Los} and~\eqref{eq:PL_NLos} (at the bottom of next page), respectively.\footnote{For realistic PL models refer to ITU PL models~\cite{ITU_Doc} which explicitly account for the boundary conditions according to a path loss type (LoS or NLoS) and they are more specific to the geographic locations.}

\begin{table*}[b]
\hrule
\begin{subequations}
\begin{align}
    d_{BP} &= 4 h_th_c f_c/c_0 \label{eq:PL1}\\
    d_{3D} &= \sqrt{d^2_g + (h_t - h_c)^2} \\
    PL_{LoS} (\text{in dB})&= 
    \begin{cases}
    PL_1 &~~~10m \le d_g \le d_{BP} \\
    PL_2 &~~~d_{BP} \le d_g \le 10km
    \end{cases} \label{eq:PL_Los}
    \\
    PL_1 &= 32.4 + 21\log_{10}(d_{3D}) + 20\log_{10}(f_c) \\
    PL_2 &= 32.4 + 40\log_{10}(d_{3D}) + 20\log_{10}(f_c) - 9.5\log_{10}((d_{BP})^2+(h_t - h_c)^2) \\
    PL_{NLoS} (\text{in dB})&= \max(PL_{LoS}, PL'_{NLoS}) ~\mbox{for } 10m \le d_g \le 10km \label{eq:PL_NLos}\\
    PL'_{NLoS} &=   35.3 \log_{10}(d_{3D}) + 22.4 + 21.3\log_{10}(f_c) - 0.3(h_c-1.5) \label{eq:PL_Last}
\end{align}
\end{subequations}
The parameters: $d_{BP}$ = Breakpoint distance; $h_t$ = Height of CTC; $h_c$ = Height of camera device; $f_c$ = Carrier frequency; $c_0$ = Speed of light; $d_g$ = Ground level distance between the CTC and camera device $c$; $d_{3D}$ = 3D distance between the CTC and camera device $c$.
\end{table*}

Next, we compute the outage probabilities for our models for a given signal strength or path loss. The probability of insufficient power is called {\it outage probability}. The outage probability $P_O(d)$, which is defined as the probability that the received power at a given distance $d$, $P_r(d)$, is below a threshold power, $P_{\gamma}$, i.e., $P_O(d) = Pr (P_r(d) < P_{\gamma})$. Thus, for our case of log-normal shadow fading model, we calculate the outage probabilities using the following expression:
\begin{align}
    P_O(d) = 1 - Q((P_{min} - (P_T - P_L(d)))/\sigma_{SF}) \label{eq:OutageProb}
\end{align}
where $Q(x) =  \frac{1}{\sqrt{2\pi}} \int_{x}^{\infty}e^{-u^{2}/2}\, du$, $P_{min}$ is the minimum receive power of the CTC to decode the received signal correctly, and $P_T$ is the transmit power of the camera device, $P_L(d)$ is the path loss incurred at a distance $d=d_g$ from the transmitter (see~\eqref{eq:PL1}--\eqref{eq:PL_Last}, at the bottom of this page), and $\sigma_{SF}$ is the standard deviation parameter of the log-normal distribution. 

\subsubsection{Transmit Power of a Camera Device}\label{Sec:TransmitPower}
Since the camera devices have to be placed at appropriate places to capture the images of vehicles, distance $d_g$ from the CTC for every camera device is fixed. Hence, for the received signal from the camera device at the CTC to provide at most the threshold outage probability, $\overline{P}_O$, is controlled by the transmit power. Based on the value of $\overline{P}_O$ these camera devices adjust the transmit power and utilize the remaining power for computation purposes. 

Now, we compute the power utilized by the camera device $c$ for transmission which is sufficient for the CTC to estimate the vehicle count.  From~\eqref{eq:OutageProb}, we write
\begin{equation}
    \overline{P}_O = 1 - Q((P_{min} - (\bar{P}_c - P_L(d_c)))/\sigma_{SF}), \label{eq:OutageProbThreshold} 
\end{equation}
where $\bar{P}_c$ and $d_c$ denote the minimum sufficient transmit power of the camera device $c$ and distance between $c$ and the CTC, respectively. By making algebraic simplification on~\eqref{eq:OutageProbThreshold}, 
we get the minimum sufficient transmit power for $c$ as follows:
\begin{equation}
    \bar{P}_c = P_L(d_c) + P_{min} -  Q^{-1} (1 - \overline{P}_O)\cdot\sigma_{SF}, \label{eq:TransmitPower} 
\end{equation}
where $Q^{-1}(x)$ denotes the inverse Q-function of $x$~\cite{papoulis1984probability}.

\subsection{Semantic Entropy}\label{Sec:SemanticEntropy}
The fundamental difficulty in SemCom systems is the quantification of the evaluation efficiency of \textit{semantic information} (SI) transfer from source to destination. The appropriate meaning behind the source data is referred to as SI. More specifically, SI is the information contained in the source material that is beneficial for completing a given task. This implies that SI is based not only on the source data but also on the specific task, which differs significantly from Shannon's definition of information, and that SI is obtained by removing redundant information irrelevant to the task from the source data. As a result, the same data set may include varying levels of SI for various purposes. For example, an image has far more SI for the image reconstruction task than the image classification task since the first task requires more information from the original image.
In this case, \textit{semantic entropy} is commonly employed to quantify SI, which should vary depending on the source data and the task. Following~\cite{chattopadhyay2020quantifying}, a formal definition of semantic entropy is provided as follows:
\begin{defn}[\bf Semantic Entropy~\cite{yan2023qoe}]\label{Def:SE}
    Semantic entropy is defined as the minimum average number of semantic symbols describing data $X \in  \mathcal{X}$ that are needed to predict task $Y$, given a semantic source $\mathcal{X}$, i.e.,
    \begin{align}
        H(X;Y) &\triangleq \min_{\mathcal{E}_S} \mathrm{E} ~(dim(Code^{\mathcal{E}_S}(X))), \mathcal{E}_S \in \mathcal{E}, \nonumber \\
        &\text{s.t., }  P(Y|Code^{\mathcal{E}_S}(X)) = P(Y|X),
    \end{align}
    where $Code^{\mathcal{E}_S}(X)$ represents the semantic symbol vector extracted from $X$ using the semantic encoder $\mathcal{E}_S$, $\mathcal{E}$ represents the set of semantic encoders, and $P(Y|X)$ represents the conditional probability of $Y$ given $X$.
\end{defn} 
The semantic entropy of $X$ given $Y$ is specified in Definition~\ref{Def:SE} as an expected value for the whole data set $\mathcal{X}$, i.e., the semantic entropy is constant for the same task and dataset~\cite{yan2023qoe}. We use our proposed semantic encoder model (see Section~\ref{Sec:SemEncoder}) to compute the \textit{approximate semantic entropy} (ASE) $\Tilde{H}(X;Y)$ for a task, which can be stated as a metric that is both meaningful and manipulable for semantic communication systems. That is
\begin{align}
    %\Tilde{H}(X;Y) &\triangleq \min \mathrm{E} ~(dim(Code^{\mathcal{E}_{CNN}}(X))), \nonumber \\ Dont know why min is used in the original paper
    \Tilde{H}(X;Y) &\triangleq \mathrm{E} ~(dim(Code^{\mathcal{E}_{CNN}}(X))), \nonumber \\
    &\text{s.t., }  P(Y|Code^{\mathcal{E}_{CNN}}(X)) - P(Y|X) < \epsilon,
\end{align}
where the restriction specifies that the task performance deterioration cannot be greater than a tiny constant $\epsilon$. It should be noted that the data granularity of the ASE is determined by the granularity of the data that the CNN model at the transmitter can handle. %Furthermore, as in~\cite{yan2022resource}, the unit of ASE is defined as \textit{sut}. 

In our context, task $Y$ is equivalent to vehicle count prediction $\hat{n}$ by the CTC, and $X$ is equivalent to the image data $G$. The ASE, $\Tilde{H}(G;\hat{n})$, is the average number of semantic symbols describing data $G$ that are needed to predict the vehicle count $\hat{n}$ with an error $< \epsilon$. Let $\Tilde{H}_\epsilon$ be the sufficient number of semantic symbols needed to predict $\hat{n}$ with the error equal to $\epsilon$. Then $\bar{\beta} = \Tilde{H}(G;\hat{n}) - \Tilde{H}_\epsilon \ge 0$ denotes the additional average number of symbols used for achieving a lower error than $\epsilon$ in predicting $\hat{n}$. The value of $\bar{\beta}$ quantifies the additional overhead in the transmission of image data using semantic symbols. Let $\bar{\beta}_0\ge 0$ be a user defined threshold value for the additional overhead. From the wireless communication network perspective, the value of $\bar{\beta}_0$ needs to be as close as possible to zero. So we put the constraint on the value of additional overhead occurred due to the semantic encoding as $\bar{\beta} \le \bar{\beta}_0$. 

\subsection{Accuracy of Vehicle Count Prediction} \label{Sec:Accuracy}

The accuracy of vehicle count prediction plays an important role in smart city traffic management since the CTC adjusts the traffic signal duration at every road junction based on the estimated number of vehicles~\cite{chavhan2020prediction,karmakar2020smart,chavhan2021efficient}. If the predicted number is very high compared to the actual number, the ON traffic signal duration is longer than required, increasing waiting time for other vehicles on the junction's other roads. Similarly, if the predicted number is significantly lower than the actual number, the waiting time for several vehicles on that road will be increased unnecessarily. As a result, it is preferable to have the estimated value as close to the actual vehicle count as possible.

The accuracy in the predicted value of vehicles is measured in terms of mean absolute error (MAE) and mean squared error (MSE). They are defined as follows:
\begin{subequations}
\begin{align}
    MAE &= \frac{\sum_{i=1}^{I}|\widehat{n}_i - n^0_i|}{I}, \label{eq:MAE} \\
    MSE &= \frac{\sum_{i=1}^{I}(\widehat{n}_i - n^0_i)^2}{I}, \label{eq:MSE}
\end{align}    
\end{subequations}
where $I$ denotes the number of images in a given frame and $\widehat{n}_i$ (respectively, $n^0_i$) denotes the predicted (respectively, ground truth) vehicle count in the image $i$.
For ease of analysis, we focus only on MAE. Let $\overline{MAE}$ be the maximum tolerable MAE so that the traffic holding time set by the CTC based on its estimate at a road junction is not visibly inappropriate for the vehicle users.

\subsection{Problem Formulation}\label{Sec:ProbFormulation}
The quality of experience (QoE) of a service or application is a subjective performance metric. It is defined in ~\cite{brunnstrom2013qualinet} as the level of delight or annoyance felt by a service or application user. It is the satisfaction of the user's expectations about the utility of that service or application in light of the user's personality and current state. The factors that influence QoE can be broadly classified as human-related, system-related, and context-related~\cite{kougioumtzidis2022survey}. Two evaluation approaches, namely subjective and objective approaches, can be used to assess QoE~\cite{takahashi2009framework} .
Objective assessment approaches may be regarded as the gold standard for evaluating QoE based solely on objective quality indicators. While objective approaches are less accurate than subjective approaches, they are model-based and simple to implement.

Let us consider the ideal situation wherein the CTC knows the exact number of vehicles on each road, i.e., the ground truth values. Let the waiting time experienced by a vehicle $x$ at a traffic signal $r$ based on the exact number of vehicles be ${}^0\tau^x_r$. Then the optimum time taken by the vehicle $x$ to cross a city is
\begin{align}
    \delta_0^x(i,j) = \frac{d(i,j)}{v^x_d} + \sum_{r=1}^{R(i,j)} {}^0\tau^x_r. \label{eq:delta_0}
\end{align}
From~\eqref{eq:Delta},~\eqref{eq:t_bar}, and~\eqref{eq:delta_0}, we compute the average optimum time taken by any vehicle crossing the city limits as $\bar{t}_0$. Let $\bar{\alpha} \ge 0$ be the additional time spent by a vehicle in the traffic network due to the estimation error, i.e., $\bar{\alpha} = \bar{t} - \bar{t}_0$. In the context of road traffic  management, the QoE of the user depends on the value of $\bar{\alpha}$ and QoE increases as the value of $\bar{\alpha}$ decreases. We quantify this relation with the following equation:
\begin{align}
    QoE(\bar{\alpha}, \bar{t}) \triangleq  \frac{\kappa \bar{\alpha}\bar{t}}{\bar{\alpha}^2 + \bar{t}^2},  \label{eq:QoE}
\end{align}
where $\kappa$ is an appropriate scaling factor. The motivation for choosing the definition of QoE as shown in~\eqref{eq:QoE} are as follows:
\begin{itemize}
    \item QoE should be a function of both vehicle related parameters, hence $\bar{t}$, and the SemCom system design parameters, hence $\bar{\alpha}$.
    \item QoE should increase as $\bar{\alpha}$ reduces with $\bar{t}$ constant.
    \item QoE should increase as $\bar{t}$ reduces with $\bar{\alpha}$ constant.
    \item QoE should be dimensionless and preferably between 0 and 1.
\end{itemize} 

% \begin{align}
%     QoE \triangleq 1 - \frac{\bar{\alpha}}{\bar{t}}. \label{eq:QoE}
% \end{align}
In this paper, we consider a simple definition for QoE as defined in~\eqref{eq:QoE}.\footnote{For an advanced notion of definition of QoE meant for Autonomous Intersection Control (AIC) in Vehicular Networks, refer to~\cite{dai2016quality}. It considers vehicle safety, passenger comfort, and smoothness metric in the definition of QoE.} We analyze the average journey time of individual vehicles through a specific smart city to avoid a lengthy wait of vehicles (see Section~\ref{Sec:TrafficModel}). The main aim of city traffic management is to maximize the QoE while ensuring the safety of vehicle users, the power limitations of camera devices, SE constraints, and vehicle count accuracy. Now, we present the optimization problem formulation as follows:
\begin{subequations}
\begin{align}
    &\max_{\overline{P}_O, \bar{v}, \bar{\beta}_0, \overline{MAE}}  ~~~QoE (\bar{\alpha}, \bar{t}) \label{eq:max_QoE} \\
    &v^x_{d} \le \bar{v}, ~\text{(Safety constraint)}\\
    &P_c \ge \bar{P}_c,  
     ~\text{(Transmit Power constraint)} \\     
     &\bar{\beta} \le \bar{\beta}_0, ~\text{(Semantic Entropy constraint)}\\
     &MAE \le \overline{MAE},~\text{(Count accuracy constraint)} \\
     &\forall x=\{1, \ldots, N_0\}, c = \{1, \ldots, C\}.\label{eq:QoELast}
\end{align}
\end{subequations}

 
\section{Simulation Results}\label{Sec:Simulations}
In this section, we first provide the simulation results related to the designed SemCom system in Section~\ref{SubSec:Simu_SemCom} and then provide the  results related to the QoE maximization by solving the optimization problem in Section~\ref{SubSec:Simu_QoE}. The proposed approach is evaluated on the public dataset TRaffic ANd COngestionS (TRANCOS)~\cite{TRANCOSdataset_IbPRIA2015}. It is a benchmark dataset for vehicle density prediction in traffic congestion areas. This dataset comprises 1244 images, with 46796 automobiles labeled in total. All of the pictures were taken using publicly available video surveillance equipment from Spain's Direccin General de Trfico (\url{https://www.dgt.es/inicio/}). The simulations are performed in a computer with NVIDIA GeForce RTX 3090 GPU and Intel Core i9-10980XE CPU with 256GB RAM.

\subsection{The performance of SemCom System Model} \label{SubSec:Simu_SemCom}
% Figure environment removed
% % Figure environment removed

Our model is trained by using the procedure described in Algorithm~\ref{alg:training}. For this purpose, the dataset is divided into $4:1$ ratios for training and validation, respectively. The loss function $\mathscr{L}_{count}$ versus the number of epochs for training and validation errors are shown in Fig.~\ref{fig:plots_Loss_MAE}(a). The plot shows that the training and validation errors are close to each other, and after the $95^{th}$ epoch, the validation error begins to deviate from the training error. So, to avoid overfitting and for better results, training is stopped after 100 epochs. 
%Thus, when the trained model is applied to the TRANCOS test dataset, the resulting MAE of 6.23 is shown in Fig.~\ref{fig:Loss_vs_Epoch}. 

The accuracy in the predicted value of vehicles is measured in terms of mean absolute error (MAE) as well as mean squared error (MSE). MAE and MSE are defined in~\eqref{eq:MAE} and~\eqref{eq:MSE}, respectively.
Next, we plot MAE vs. the hyper-parameter $p$, and the results are shown in Fig.~\ref{fig:plots_Loss_MAE}(b). We can deduce from the plot that the minimum MAE value is observed at $p=0.8$, and the corresponding MAE value is 6.23. This also demonstrates that the direct addition of residuals does not always provide the best results. 

% % Figure environment removed

In Table~\ref{Tab:MAE_Compare}, the MAE and MSE values computed by the proposed method is compared to three state-of-the-art approaches applied to the TRANCOS dataset. These approaches are based on GRU, LSTM~\cite{sawah2023accurate}, and FCN-rLSTM~\cite{zhang2017fcn}, respectively. 
%For a fair comparison, we replaced our transmitter and receiver models with those proposed in~\cite{sawah2023accurate,zhang2017fcn}, and ran the experiments. 
From the MAE values shown in Table~\ref{Tab:MAE_Compare}, it is inferred that the proposed approach outperforms the approaches based on GRU, LSTM, and FCN-rLSTM, by $90.71\%$, $73.03\%$, and $19.1\%$, respectively.

\begin{table}%[]
%\vspace{+.2cm}
\caption{The comparison of the MAE and MSE values between the proposed model and three state-of-the-art models.}
    \centering
    \resizebox{0.95\columnwidth}{!}{%
    \begin{tabular}{|c|c|c|c|c|}
    \hline
        Models & GRU~\cite{sawah2023accurate} & LSTM~\cite{sawah2023accurate} & FCN-rLSTM~\cite{zhang2017fcn} & CNN-LSTM  \\ \hline
        MAE & 11.88 & 10.78 & 7.42 & 6.23 \\ \hline
        MSE & 77.79 & 67.74 & 43.28 & 38.15 \\ \hline
    \end{tabular}%
    }
    \label{Tab:MAE_Compare}
   % \vspace{-.2cm}
\end{table}

Next, we show how much overhead can be saved by incorporating SemCom technology into our model. As an example, as shown in Fig.~\ref{fig:Compression}, the sizes of raw images from the TRANCOS dataset are compared to the sizes of transmitted density maps from the transmitter. By using the test dataset, which consists of 421 raw images with a total size of $5.31MB$, we compare the overhead reduction with and without applying the SemCom technology. When the semantic encoder/decoder are used, the raw images are compressed to $2.42MB$ (the total size of all 421 encoded images in the test dataset). Hence, a total overhead reduction of $54.42\%$ is achieved by incorporating the SemCom technology for the test dataset.
% Figure environment removed

\subsection{Solutions to the Optimization Problem}\label{SubSec:Simu_QoE}
Now we provide the solutions for the optimization problem defined in~\eqref{eq:max_QoE}-\eqref{eq:QoELast}. We use Gurobi software~\cite{gurobi} as a solver to solve the optimization problem for different sets of parameters. 
Since the QoE depends on the parameters $\overline{P}_O, \bar{v}, \bar{\beta}_0,$ and $\overline{MAE}$, we plot QoE vs. each of these parameters by keeping the others fixed and observe how the QoE changes w.r.t. these parameters.\footnote{Numerical fixed values used in the computation of QoE are same as those used in~\cite{krauss1998microscopic},~\cite{yan2023qoe},~\cite{zhang2017fcn}.} We also compare the QoE metric with the three state-of-the-art works in the literature, namely LSTM and GRU based~\cite{sawah2023accurate}, and FCN-rLSTM based~\cite{zhang2017fcn} vehicle counting methods. For a fair comparison, we replaced our proposed CNN based semantic encoder and LSTM based semantic decoder with those of the above described models. From all the plots provided next, we conclude that the proposed CNN-LSTM based SemCom system outperforms the other models in terms of QoE.
% Figure environment removed

% Figure environment removed

% Figure environment removed

First, we compute the QoE in relation to the parameter $\bar{v}$, which is the speed limit restriction imposed by traffic management to ensure the safety of the vehicles. The plot of QoE vs. $\bar{v}$ is shown in Fig.~\ref{fig:QoE_vs_v_and_beta_bar}(a). QoE is small for smaller values of $\bar{v}$ because the speed of each vehicle is limited by $\bar{v}$, causing $\bar{t}$ to be higher. QoE increases as $\bar{v}$ rises because the value of $\bar{t}$ reduces while $\bar{\alpha}$ remains constant.\footnote{Since it does not depend on the speed of the moving vehicles.} It reaches saturation because the speed is now limited by the safe speed that every vehicle must maintain to avoid untoward incidents. As a result, after a certain $\bar{v}$, QoE for all methods remains roughly the same.

Next, we compute the QoE w.r.t. the parameter $\bar{\beta}_0$, which is the user-defined threshold value for additional overhead to include the effect of the semantic entropy on QoE. The plot of QoE vs. $\bar{\beta}_0$ is shown in Fig.~\ref{fig:QoE_vs_v_and_beta_bar}(b). QoE is small for smaller values of $\bar{\beta}_0$ because only additional semantic symbols on average are used for transmitting, resulting in a poor estimation of vehicle count. QoE increases as $\bar{\beta}_0$ rises because the estimation of vehicle count improves due to the higher number of average semantic symbols received. This results in a fall in the values of both $\bar{t}$ and $\bar{\alpha}$.

Now, we compute the QoE in relation to the parameter $\overline{MAE}$, which is the error metric defined in~\eqref{eq:MAE}. The plot of QoE vs. $\overline{MAE}$ is shown in Fig.~\ref{fig:QoE_vs_MAE_and_PO_bar}(a). QoE is large for smaller values of $\overline{MAE}$ because smaller the error metric, higher the vehicle estimation accuracy. QoE decreases as $\overline{MAE}$ increases because the values of both $\bar{t}$ and $\bar{\alpha}$ increase. 

Next, we compute the QoE w.r.t. the parameter $\overline{P}_0$, which is the threshold outage probability at the CTC. The plot of QoE vs. $\overline{P}_0$ is shown in Fig.~\ref{fig:QoE_vs_MAE_and_PO_bar}(b). QoE is large for significantly smaller values of $\overline{P}_0$ because of the full availability of the incoming data, resulting in a high accurate estimation of vehicle count. QoE reduces as $\overline{P}_0$ rises because the estimation of vehicle count reduces drastically due to the fall in the data availability. This results in a rise in the values of both $\bar{t}$ and $\bar{\alpha}$.

Now, we provide the numerical results related to the channel modeling described in Section~\ref{Sec:ChannelModel}. The plots in Fig.~\ref{fig:PathLoss_Outage_vs_d}(a) and Fig.~\ref{fig:PathLoss_Outage_vs_d}(b) show the path loss (in dB) and outage probabilities for both LoS and NLoS settings as a function of distance, respectively. The plots show that, for a given transmit power, as the distance between the camera device and the CTC increases, so does the path loss and outage probability. Hence, it is best to position the camera devices as close to the CTC as possible, and vice versa. Furthermore, when comparing the LoS and NLoS settings, the performance in the NLoS settings is significantly lower. So, it is best to position the camera devices higher up so that a LoS connection can be established between these devices and the CTC.

\section{Conclusions and Future Work}\label{Sec:Conclusions}
In this paper, we have proposed a joint CNN-LSTM-based SemCom model in which a camera's semantic encoder extracts density maps from raw images. The encoded density maps are then sent as symbols to the CTC by the transmitter. The CTC's semantic decoder predicts the vehicle count on each road based on the sequence of received symbols. Next, we introduced and numerically solved an optimization problem to enhance the QoE while taking into account constraints like vehicle user safety, camera device transmit power, vehicle count prediction accuracy, and semantic entropy. We showed that the proposed SemCom model on vehicle count prediction, applied to the TRANCOS dataset, reduces overhead by $54.42\%$ when compared to source encoder/decoder methods using simulations. In addition, simulations showed that the proposed model outperformed state-of-the-art models in terms of MAE, MSE, and QoE. The full operation of traffic management by the CTC, like traffic holding, traffic diverting, etc., can be explored as a future research direction. 
The numerical solver was used to solve the optimization problem of improving QoE for vehicle users. As a future research direction, a simulator-based study on traffic management can be conducted.
%\vspace{-.1cm}
\bibliographystyle{ieeetr}
%\balance
\bibliography{references.bib}
\end{document}