@inproceedings{Reiterdata2text,
 author = {Reiter, Ehud},
 title = {An Architecture for Data-to-text Systems},
 booktitle = {Proceedings of the Eleventh European Workshop on Natural Language Generation},
 series = {ENLG '07},
 year = {2007},
 location = {Germany},
 pages = {97--104},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1610163.1610180},
 acmid = {1610180},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@article{sumtime,
  title={SumTime-Mousam: Configurable marine weather forecast generator},
  author={Sripada, Somayajulu and Reiter, Ehud and Davy, Ian},
  journal={Expert Update},
  volume={6},
  number={3},
  pages={4--10},
  year={2003},
  publisher={Citeseer}
}

@inproceedings{scuba,
  title={Linguistic interpretations of scuba dive computer data},
  author={Sripada, Somayajulu G and Gao, Feng},
  booktitle={2007 11th International Conference Information Visualization (IV'07)},
  pages={436--441},
  year={2007},
  organization={IEEE}
}

@article{reiter2003lessons,
  title={Lessons from a failure: Generating tailored smoking cessation letters},
  author={Reiter, Ehud and Robertson, Roma and Osman, Liesl M},
  journal={Artificial Intelligence},
  volume={144},
  number={1-2},
  pages={41--58},
  year={2003},
  publisher={Elsevier}
}

@article{braun2018saferdrive,
  title={SaferDrive: An NLG-based behaviour change support system for drivers},
  author={Braun, Daniel and Reiter, Ehud and Siddharthan, Advaith},
  journal={Natural Language Engineering},
  volume={24},
  number={4},
  pages={551--588},
  year={2018},
  publisher={Cambridge University Press}
}

@inproceedings{kukich1983design,
  title={Design of a knowledge-based report generator},
  author={Kukich, Karen},
  booktitle={Proceedings of the 21st annual meeting on Association for Computational Linguistics},
  pages={145--150},
  year={1983},
  organization={Association for Computational Linguistics}
}

@inproceedings{harma2016probabilistic,
  title={Probabilistic scoring of validated insights for personal health services},
  author={H{\"a}rm{\"a}, Aki and Helaoui, Rim},
  booktitle={2016 IEEE Symposium Series on Computational Intelligence (SSCI)},
  pages={1--6},
  year={2016},
  organization={IEEE}
}

@inproceedings{sumtimeturbine,
  title={SumTime-turbine: a knowledge-based system to communicate gas turbine time-series data},
  author={Yu, Jin and Reiter, Ehud and Hunter, Jim and Sripada, Somayajulu},
  booktitle={International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems},
  pages={379--384},
  year={2003},
  organization={Springer}
}


@article{op2015tailored,
  title={Tailored motivational message generation: A model and practical framework for real-time physical activity coaching},
  author={op den Akker, Harm and Cabrita, Miriam and op den Akker, Rieks and Jones, Valerie M and Hermens, Hermie J},
  journal={Journal of biomedical informatics},
  volume={55},
  pages={104--115},
  year={2015},
  publisher={Elsevier}
}

@article{hingle2016there,
  title={There are thousands of apps for that: navigating mobile technology for nutrition education and behavior},
  author={Hingle, Melanie and Patrick, Heather},
  journal={Journal of nutrition education and behavior},
  volume={48},
  number={3},
  pages={213--218},
  year={2016},
  publisher={Elsevier}
}

@article{higgins2016smartphone,
  title={Smartphone applications for patients' health and fitness},
  author={Higgins, John P},
  journal={The American journal of medicine},
  volume={129},
  number={1},
  pages={11--19},
  year={2016},
  publisher={Elsevier}
}

@article{agrawal1996parallel,
  title={Parallel mining of association rules},
  author={Agrawal, Rakesh and Shafer, John C},
  journal={IEEE Transactions on knowledge and Data Engineering},
  volume={8},
  number={6},
  pages={962--969},
  year={1996},
  publisher={IEEE}
}


@incollection{freitas1999rule,
  title={On rule interestingness measures},
  author={Freitas, Alex A},
  booktitle={Research and Development in Expert Systems XV},
  pages={147--158},
  year={1999},
  publisher={Springer}
}

@article{fayyad1996data,
  title={From data mining to knowledge discovery in databases},
  author={Fayyad, Usama and Piatetsky-Shapiro, Gregory and Smyth, Padhraic},
  journal={AI magazine},
  volume={17},
  number={3},
  pages={37--37},
  year={1996}
}

@article{sudarsanam2019rate,
  title={Rate of change analysis for interestingness measures},
  author={Sudarsanam, Nandan and Kumar, Nishanth and Sharma, Abhishek and Ravindran, Balaraman},
  journal={Knowledge and Information Systems},
  pages={1--20},
  year={2019},
  publisher={Springer}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@article{tao2020toward,
  title={Toward multi-label sentiment analysis: a transfer learning based approach},
  author={Tao, Jie and Fang, Xing},
  journal={Journal of Big Data},
  volume={7},
  number={1},
  pages={1--26},
  year={2020},
  publisher={Springer}
}

@article{long2015learning,
  title={Learning transferable features with deep adaptation networks},
  author={Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael I},
  journal={arXiv preprint arXiv:1502.02791},
  year={2015}
}
@techreport{settles2009active,
  title={Active learning literature survey},
  author={Settles, Burr},
  year={2009},
  institution={University of Wisconsin-Madison Department of Computer Sciences}
}
@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}


@article{howard2018universal,
  title={Universal language model fine-tuning for text classification},
  author={Howard, Jeremy and Ruder, Sebastian},
  journal={arXiv preprint arXiv:1801.06146},
  year={2018}
}

@article{merity2016pointer,
  title={Pointer sentinel mixture models},
  author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
  journal={arXiv preprint arXiv:1609.07843},
  year={2016}
}

@inproceedings{settles2011theories,
  title={From theories to queries: Active learning in practice},
  author={Settles, Burr},
  booktitle={Active Learning and Experimental Design workshop In conjunction with AISTATS 2010},
  pages={1--18},
  year={2011}
}

    
@article{sandryhaila2014big,
  title={Big data analysis with signal processing on graphs: Representation and processing of massive data sets with irregular structure},
  author={Sandryhaila, Aliaksei and Moura, Jose MF},
  journal={IEEE Signal Processing Magazine},
  volume={31},
  number={5},
  pages={80--90},
  year={2014},
  publisher={IEEE}
}

@inproceedings{o2012data,
  title={Data Mining Office Behavioural Information from Simple Sensors.},
  author={O'Malley, Samuel J and Smith, Ross T and Thomas, Bruce H},
  booktitle={AUIC},
  pages={97--98},
  year={2012}
}

@article{stilou2001mining,
  title={Mining association rules from clinical databases: an intelligent diagnostic process in healthcare},
  author={Stilou, S and Bamidis, Panagiotis D and Maglaveras, Nicos and Pappas, Constantinos},
  journal={Studies in health technology and informatics},
  number={2},
  pages={1399--1403},
  year={2001},
  publisher={IOS Press; 1999}
}

@article{gonzalez2016recent,
  title={Recent advances and emerging applications in text and data mining for biomedical discovery},
  author={Gonzalez, Graciela H and Tahsin, Tasnia and Goodale, Britton C and Greene, Anna C and Greene, Casey S},
  journal={Briefings in bioinformatics},
  volume={17},
  number={1},
  pages={33--42},
  year={2016},
  publisher={Oxford University Press}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@misc{turing-nlg, 
    title={Turing-NLG-A 17-billion-parameter language model by Microsoft}, url={https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft}, 
    journal={Turing-NLG: A 17-billion-parameter language model by Microsoft}, 
    publisher={Microsoft Research Blog}, 
    year={2020}, 
    month={Feb}}
    
@article{gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{idrees2019study,
  title={A study of big data and its challenges},
  author={Idrees, Sheikh Mohammad and Alam, M Afshar and Agarwal, Parul},
  journal={International Journal of Information Technology},
  volume={11},
  number={4},
  pages={841--846},
  year={2019},
  publisher={Springer}
}

@article{gong2019table,
  title={Table-to-text generation with effective hierarchical encoder on three dimensions (row, column and time)},
  author={Gong, Heng and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
  journal={arXiv preprint arXiv:1909.02304},
  year={2019}
}

@article{wiseman2017challenges,
  title={Challenges in data-to-document generation},
  author={Wiseman, Sam and Shieber, Stuart M and Rush, Alexander M},
  journal={arXiv preprint arXiv:1707.08052},
  year={2017}
}

@article{mundial2012big,
  title={Big data, big impact: New possibilities for international development},
  author={Mundial, Foro Econ{\'o}mico},
  journal={Foro Econ{\'o}mico Mundial. Cologny, Suiza. Disponible en:< www3. weforum. org/docs/WEF\_TC\_MFS\_BigDataBigIm-p act\_Briefing\_2012. pdf},
  year={2012}
}
@inproceedings{hammad2015big,
  title={Big data analysis and storage},
  author={Hammad, Khalid Adam Ismail and Fakharaldien, M and Zain, J and Majid, M},
  booktitle={International Conference on Operations Excellence and Service Engineering},
  pages={10--11},
  year={2015}
}


@inproceedings{susaiyah2020towards,
  title={Towards a Generalised Framework for Behaviour Insight Mining},
  author={Susaiyah, Allmin and H{\"a}rm{\"a}, Aki and Reiter, Ehud and Helaoui, Rim and Petkovi{\'c}, Milan and others},
  booktitle={SmartPHIL: 1st Workshop on Smart Personal Health Interfaces},
  year={2020},
  organization={ACM}
}

@article{sripada2003sumtime,
  title={SumTime-Mousam: Configurable marine weather forecast generator},
  author={Sripada, Somayajulu and Reiter, Ehud and Davy, Ian},
  publisher={Citeseer}
}

@inproceedings{lin2004looking,
  title={Looking for a few good metrics: ROUGE and its evaluation},
  author={Lin, Chin-Yew and Och, FJ},
  booktitle={Ntcir Workshop},
  year={2004}
}


    
@inproceedings{sutskever,
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
title = {Sequence to Sequence Learning with Neural Networks},
year = {2014},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
pages = {3104–3112},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS’14}
}

@inproceedings{chopra2016abstractive,
  title={Abstractive sentence summarization with attentive recurrent neural networks},
  author={Chopra, Sumit and Auli, Michael and Rush, Alexander M},
  booktitle={Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={93--98},
  year={2016}
}

@article{nallapati2016abstractive,
  title={Abstractive text summarization using sequence-to-sequence rnns and beyond},
  author={Nallapati, Ramesh and Zhou, Bowen and Gulcehre, Caglar and Xiang, Bing and others},
  journal={arXiv preprint arXiv:1602.06023},
  year={2016}
}

@article{narayan2018don,
  title={Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization},
  author={Narayan, Shashi and Cohen, Shay B and Lapata, Mirella},
  journal={arXiv preprint arXiv:1808.08745},
  year={2018}
}


@article{see2017get,
  title={Get to the point: Summarization with pointer-generator networks},
  author={See, Abigail and Liu, Peter J and Manning, Christopher D},
  journal={arXiv preprint arXiv:1704.04368},
  year={2017}
}

@article{paulus2017deep,
  title={A deep reinforced model for abstractive summarization},
  author={Paulus, Romain and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1705.04304},
  year={2017}
}

@inproceedings{tan2017abstractive,
  title={Abstractive document summarization with a graph-based attentional neural model},
  author={Tan, Jiwei and Wan, Xiaojun and Xiao, Jianguo},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1171--1181},
  year={2017}
}

@article{wang2018reinforced,
  title={A reinforced topic-aware convolutional sequence-to-sequence model for abstractive text summarization},
  author={Wang, Li and Yao, Junlin and Tao, Yunzhe and Zhong, Li and Liu, Wei and Du, Qiang},
  journal={arXiv preprint arXiv:1805.03616},
  year={2018}
}

@article{zhang2019abstract,
  title={Abstract text summarization with a convolutional Seq2seq model},
  author={Zhang, Yong and Li, Dan and Wang, Yuheng and Fang, Yang and Xiao, Weidong},
  journal={Applied Sciences},
  volume={9},
  number={8},
  pages={1665},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{liu2019text,
  title={Text Summarization with Pretrained Encoders},
  author={Liu, Yang and Lapata, Mirella},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={3721--3731},
  year={2019}
}

@inproceedings{liu2018table,
  title={Table-to-text generation by structure-aware seq2seq learning},
  author={Liu, Tianyu and Wang, Kexiang and Sha, Lei and Chang, Baobao and Sui, Zhifang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@article{yan2020prophetnet,
  title={Prophetnet: Predicting future n-gram for sequence-to-sequence pre-training},
  author={Yan, Yu and Qi, Weizhen and Gong, Yeyun and Liu, Dayiheng and Duan, Nan and Chen, Jiusheng and Zhang, Ruofei and Zhou, Ming},
  journal={arXiv preprint arXiv:2001.04063},
  year={2020}
}

@article{zhang2019pegasus,
  title={Pegasus: Pre-training with extracted gap-sentences for abstractive summarization},
  author={Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter J},
  journal={arXiv preprint arXiv:1912.08777},
  year={2019}
}

@inproceedings{dong2019unified,
  title={Unified language model pre-training for natural language understanding and generation},
  author={Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13063--13075},
  year={2019}
}

@article{gptsum-hoang2019efficient,
  title={Efficient adaptation of pretrained transformers for abstractive summarization},
  author={Hoang, Andrew and Bosselut, Antoine and Celikyilmaz, Asli and Choi, Yejin},
  journal={arXiv preprint arXiv:1906.00138},
  year={2019}
}

@inproceedings{elmosum-mastronardo2019enhancing,
  title={Enhancing a Text Summarization System with ELMo.},
  author={Mastronardo, Claudio and Tamburini, Fabio},
  booktitle={CLiC-it},
  year={2019}
}


@article{sharma2017relevance,
  title={Relevance of unsupervised metrics in task-oriented dialogue for evaluating natural language generation},
  author={Sharma, Shikhar and Asri, Layla El and Schulz, Hannes and Zumer, Jeremie},
  journal={arXiv preprint arXiv:1706.09799},
  year={2017}
}

@inproceedings{simoneballoccu2020nlg,
  title={A NLG Framework for User Tailoring and Profiling in Healthcare.},
  author={Balloccu, Simone and Pauws, Steffen and Reiter, Ehud},
  booktitle={SmartPhil@ IUI},
  pages={13--32},
  year={2020}
}


@inproceedings{puduppully2019data,
  title={Data-to-text generation with content selection and planning},
  author={Puduppully, Ratish and Dong, Li and Lapata, Mirella},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={6908--6915},
  year={2019}
}
@inproceedings{zellers2019defending,
  title={Defending against neural fake news},
  author={Zellers, Rowan and Holtzman, Ari and Rashkin, Hannah and Bisk, Yonatan and Farhadi, Ali and Roesner, Franziska and Choi, Yejin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9054--9065},
  year={2019}
}

@article{wiseman2018learning,
  title={Learning neural templates for text generation},
  author={Wiseman, Sam and Shieber, Stuart M and Rush, Alexander M},
  journal={arXiv preprint arXiv:1808.10122},
  year={2018}
}

@inproceedings{siamese_neculoiu2016learning,
  title={Learning text similarity with siamese recurrent networks},
  author={Neculoiu, Paul and Versteegh, Maarten and Rotaru, Mihai},
  booktitle={Proceedings of the 1st Workshop on Representation Learning for NLP},
  pages={148--157},
  year={2016}
}

@inproceedings{siamese_berlemont2015siamese,
  title={Siamese neural network based similarity metric for inertial gesture classification and rejection},
  author={Berlemont, Samuel and Lefebvre, Gr{\'e}goire and Duffner, Stefan and Garcia, Christophe},
  booktitle={International Conference on Automatic Face and Gesture Recognition},
  pages={1--6},
  year={2015}
}


@misc{duc, 
title={DUC 2004: Documents, Tasks, and Measures}, 
url={https://duc.nist.gov/duc2004/}, 
journal={DUC 2004 Documents for Summarization, Tasks, and Measures}
}
  
@misc{sleepdevice,
    author={Philips},
    title={Connected Sleep And Wake Up Light HF3670/60}, url={https://www.usa.philips.com/shop/US\_AirFryerOnly/personal-care/light-therapy/smartsleep-connected-sleep-and-wake-up-light/p/HF3670\_60}, 
    publisher={Philips}, 
    year={2020}, 
    month={Mar}}
    
@article{gururangan2020don,
  title={Don't Stop Pretraining: Adapt Language Models to Domains and Tasks},
  author={Gururangan, Suchin and Marasovi{\'c}, Ana and Swayamdipta, Swabha and Lo, Kyle and Beltagy, Iz and Downey, Doug and Smith, Noah A},
  journal={arXiv preprint arXiv:2004.10964},
  year={2020}
}

@article{chen2019tabfact,
  title={TabFact: A large-scale dataset for table-based fact verification},
  author={Chen, Wenhu and Wang, Hongmin and Chen, Jianshu and Zhang, Yunkai and Wang, Hong and Li, Shiyang and Zhou, Xiyou and Wang, William Yang},
  journal={arXiv preprint arXiv:1909.02164},
  year={2019}
}
   
@conference{ecai-paper,
author = {Allmin Susaiyah and Aki Härmä and Ehud Reiter and Milan Petković},
title = {Iterative Neural Scoring of Validated Insight Candidates},
booktitle = {ECAI workshop on Intelligent Information Processing and Natural Language Generation.},
year = 2020,
month = {Sep},
address = {Santiago de Compostela, Spain},
url={https://intellang.github.io/papers/6-IntelLanG\_2020\_paper\_6.pdf}
}    


@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@misc{vu2020exploring,
      title={Exploring and Predicting Transferability across NLP Tasks}, 
      author={Tu Vu and Tong Wang and Tsendsuren Munkhdalai and Alessandro Sordoni and Adam Trischler and Andrew Mattarella-Micke and Subhransu Maji and Mohit Iyyer},
      year={2020},
      eprint={2005.00770},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{nlp_progress, title={Tracking Progress in Natural Language Processing}, url={https://nlpprogress.com/}, journal={NLP}, author={Ruder, Sebastian}, year={2020}} 


@article{antczak2018deep,
  title={Deep recurrent neural networks for ECG signal denoising},
  author={Antczak, Karol},
  journal={arXiv preprint arXiv:1807.11551},
  year={2018}
}

@article{kaymak2017breast,
  title={Breast cancer image classification using artificial neural networks},
  author={Kaymak, Sertan and Helwan, Abdulkader and Uzun, Dilber},
  journal={Procedia computer science},
  volume={120},
  pages={126--131},
  year={2017},
  publisher={Elsevier}
}

@article{chopra2019artificial,
  title={Artificial neural networks based indian stock market price prediction: before and after demonetization},
  author={Chopra, S and Yadav, D and Chopra, AN},
  journal={J Swarm Intel Evol Comput},
  volume={8},
  number={174},
  pages={2},
  year={2019}
}

@inproceedings{islam2017handwritten,
  title={Handwritten digits recognition with artificial neural network},
  author={Islam, Kh Tohidul and Mujtaba, Ghulam and Raj, Ram Gopal and Nweke, Henry Friday},
  booktitle={2017 International Conference on Engineering Technology and Technopreneurship (ICE2T)},
  pages={1--4},
  year={2017},
  organization={IEEE}
}

@article{SUN2016171,
title = "A sparse auto-encoder-based deep neural network approach for induction motor faults classification",
journal = "Measurement",
volume = "89",
pages = "171 - 178",
year = "2016",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2016.04.007",
url = "http://www.sciencedirect.com/science/article/pii/S0263224116300641",
author = "Wenjun Sun and Siyu Shao and Rui Zhao and Ruqiang Yan and Xingwu Zhang and Xuefeng Chen",
keywords = "Sparse auto-encoder, Deep neural network, Fault diagnosis, Denoising, Dropout",
abstract = "This paper presents a deep neural network (DNN) approach for induction motor fault diagnosis. The approach utilizes sparse auto-encoder (SAE) to learn features, which belongs to unsupervised feature learning that only requires unlabeled measurement data. With the help of the denoising coding, partial corruption is added into the input of the SAE to improve robustness of feature representation. Features learned from the SAE are then used to train a neural network classifier for identifying induction motor faults. In addition, to prevent overfitting during the training process, a recently developed regularization method called “dropout” which has been proved to be very effective in neural network was employed. An experiment performed on a machine fault simulator indicates that compared with traditional neural network, the SAE-based DNN can achieve superior performance for feature learning and classification in the field of induction motor fault diagnosis."
}

@misc{pascual2019learning,
      title={Learning Problem-agnostic Speech Representations from Multiple Self-supervised Tasks}, 
      author={Santiago Pascual and Mirco Ravanelli and Joan Serrà and Antonio Bonafonte and Yoshua Bengio},
      year={2019},
      eprint={1904.03416},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{zhai2019s4l,
  title={S4l: Self-supervised semi-supervised learning},
  author={Zhai, Xiaohua and Oliver, Avital and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1476--1485},
  year={2019}
}

@ARTICLE{noisylabels,  author={K. {Choi} and G. {Fazekas} and K. {Cho} and M. {Sandler}},  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},   title={The Effects of Noisy Labels on Deep Convolutional Neural Networks for Music Tagging},   year={2018},  volume={2},  number={2},  pages={139-149},  doi={10.1109/TETCI.2017.2771298}}

@article{chen2020logic2text,
  title={Logic2Text: High-Fidelity Natural Language Generation from Logical Forms},
  author={Chen, Zhiyu and Chen, Wenhu and Zha, Hanwen and Zhou, Xiyou and Zhang, Yunkai and Sundaresan, Sairam and Wang, William Yang},
  journal={arXiv preprint arXiv:2004.14579},
  year={2020}
}

@article{bender2021dangers,
  title={On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  journal={Proceedings of FAccT},
  year={2021}
}

@article{susaiyah2021neural,
  title={Neural Scoring of Logical Inferences from Data using Feedback.},
  author={Susaiyah, Allmin and H{\"a}rm{\"a}, Aki and Reiter, Ehud and Petkovi{\'c}, Milan},
  journal={International Journal of Interactive Multimedia \& Artificial Intelligence},
  volume={6},
  number={5},
  year={2021}
}

@inproceedings{funke2018interactive,
  title={Interactive health insight miner: an adaptive, semantic-based approach},
  author={Funke, Isabel and Helaoui, Rim and H{\"a}rm{\"a}, Aki},
  booktitle={Proceedings of the 11th International Conference on Natural Language Generation},
  pages={478--479},
  year={2018}
}

@inproceedings{jiao-etal-2020-tinybert,
    title = "{T}iny{BERT}: Distilling {BERT} for Natural Language Understanding",
    author = "Jiao, Xiaoqi  and
      Yin, Yichun  and
      Shang, Lifeng  and
      Jiang, Xin  and
      Chen, Xiao  and
      Li, Linlin  and
      Wang, Fang  and
      Liu, Qun",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.372",
    doi = "10.18653/v1/2020.findings-emnlp.372",
    pages = "4163--4174",
    abstract = "Language model pre-training, such as BERT, has significantly improved the performances of many natural language processing tasks. However, pre-trained language models are usually computationally expensive, so it is difficult to efficiently execute them on resource-restricted devices. To accelerate inference and reduce model size while maintaining accuracy, we first propose a novel Transformer distillation method that is specially designed for knowledge distillation (KD) of the Transformer-based models. By leveraging this new KD method, the plenty of knowledge encoded in a large {``}teacher{''} BERT can be effectively transferred to a small {``}student{''} TinyBERT. Then, we introduce a new two-stage learning framework for TinyBERT, which performs Transformer distillation at both the pre-training and task-specific learning stages. This framework ensures that TinyBERT can capture the general-domain as well as the task-specific knowledge in BERT. TinyBERT4 with 4 layers is empirically effective and achieves more than 96.8{\%} the performance of its teacher BERT-Base on GLUE benchmark, while being 7.5x smaller and 9.4x faster on inference. TinyBERT4 is also significantly better than 4-layer state-of-the-art baselines on BERT distillation, with only {\textasciitilde}28{\%} parameters and {\textasciitilde}31{\%} inference time of them. Moreover, TinyBERT6 with 6 layers performs on-par with its teacher BERT-Base.",
}


@book{ abelson-et-al:scheme,
  author = "Harold Abelson and Gerald~Jay Sussman and Julie Sussman",
  title = "Structure and Interpretation of Computer Programs",
  publisher = "MIT Press",
  address = "Cambridge, Massachusetts",
  year = "1985"
}

@inproceedings{ bgf:Lixto,
  author = "Robert Baumgartner and Georg Gottlob and Sergio Flesca",
  title = "Visual Information Extraction with {Lixto}",
  booktitle = "Proceedings of the 27th International Conference on Very Large Databases",
  pages = "119--128",
  publisher = "Morgan Kaufmann",
  address = "Rome, Italy",
  month = "September",
  year = "2001"
}

@article{ brachman-schmolze:kl-one,
  author = "Ronald~J. Brachman and James~G. Schmolze",
  title = "An overview of the {KL-ONE} knowledge representation system",
  journal = "Cognitive Science",
  volume = "9",
  number = "2",
  pages = "171--216",
  month = "April--June",
  year = "1985"
}

@article{ gottlob:nonmon,
  author = "Georg Gottlob",
  title = "Complexity results for nonmonotonic logics",
  journal = "Journal of Logic and Computation",
  volume = "2",
  number = "3",
  pages = "397--425",
  month = "June",
  year = "1992"
}

@article{ gls:hypertrees,
  author = "Georg Gottlob and Nicola Leone and Francesco Scarcello",
  title = "Hypertree Decompositions and Tractable Queries",
  journal = "Journal of Computer and System Sciences",
  volume = "64",
  number = "3",
  pages = "579--627",
  month = "May",
  year = "2002"
}

@article{ levesque:functional-foundations,
  author = "Hector~J. Levesque",
  title = "Foundations of a functional approach to knowledge representation",
  journal = "Artificial Intelligence",
  volume = "23",
  number = "2",
  pages = "155--212",
  month = "July",
  year = "1984"
}

@inproceedings{ levesque:belief,
  author = "Hector~J. Levesque",
  title = "A logic of implicit and explicit belief",
  booktitle = "Proceedings of the Fourth National Conference on Artificial Intelligence",
  publisher = "American Association for Artificial Intelligence",
  pages = "198--202",
  address = "Austin, Texas",
  month = "August",
  year = "1984"
}

@article{ nebel:jair-2000,
  author = "Bernhard Nebel",
  title = "On the compilability and expressive power of propositional planning formalisms",
  journal = "Journal of Artificial Intelligence Research",
  volume = "12",
  pages = "271--315",
  year = "2000"
}

 @misc{proceedings,
  author = {{IJCAI Proceedings}},
  title = {{IJCAI} Camera Ready Submission},
  howpublished = {\url{https://proceedings.ijcai.org/info}},
}


 @misc{ocupai2020,
  author = {Allmin Susaiyah and Aki Härmä and Ehud Reiter and Milan Petkovi{\'c}},
  title = {A simple Framework for Behaviour Insight Mining},
  howpublished = {\url{https://share.philips.com/sites/OCUPAI20}},
}



 @misc{ocupai2021,
  author = {Allmin Susaiyah and Aki Härmä},
  title = {Domain Transferable Insight Generator},
  howpublished = {\url{https://share.philips.com/sites/OCUPAI21}},
}

@misc{shez,
    author = {Shez Partovi},
    title = {How healthcare organizations can maximize their return on insights},
    year = 2022,
    howpublished = {\url{https://www.philips.com/a-w/about/news/archive/blogs/innovation-matters/2022/20220308-how-healthcare-organizations-can-maximize-their-return-on-insights.html}},
    note = {Accessed: 2022-19-04}
}


@misc{genig,
    author = {Allmin Susaiyah and Aki Härmä},
    title = {A fully customizable insight generator that can be used for any insight generation applications.},
    year = 2022,
    howpublished = {\url{https://github.com/philips-internal/aps_generic_ig}},
    note = {Accessed: 2022-19-04}
}

@inproceedings{FunkeHH18,
  author    = {Isabel Funke and
               Rim Helaoui and
               Aki H{\"{a}}rm{\"{a}}},
  editor    = {Emiel Krahmer and
               Albert Gatt and
               Martijn Goudbeek},
  title     = {Interactive health insight miner: an adaptive, semantic-based approach},
  booktitle = {Proceedings of the 11th International Conference on Natural Language
               Generation, Tilburg University, The Netherlands, November 5-8, 2018},
  pages     = {478--479},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
  url       = {https://doi.org/10.18653/v1/w18-6559},
  doi       = {10.18653/v1/w18-6559},
  timestamp = {Tue, 28 Jan 2020 10:29:38 +0100},
  biburl    = {https://dblp.org/rec/conf/inlg/FunkeHH18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@misc{genigpub,
    author = {Allmin Susaiyah and Aki Härmä},
    title = {a GENeric toolkit for schema-driven Insight Generation},
    year = 2022,
    howpublished = {\url{https://github.com/allmin/gen-ig}},
    note = {Accessed: 2022-10-05}
}


@inproceedings{genig_anonym,
  author = {Author and Author},
  title = {GEN-IG : an open toolkit for generalisable schema-driven insight generation},
  booktitle = {The 29th International Conference on Computational Linguistics - This same conference},
  year = {2022}
}

@inproceedings{kour2014real,
  title={Real-time segmentation of on-line handwritten arabic script},
  author={Kour, George and Saabne, Raid},
  booktitle={Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
  pages={417--422},
  year={2014},
  organization={IEEE}
}

@inproceedings{kour2014fast,
  title={Fast classification of handwritten on-line Arabic characters},
  author={Kour, George and Saabne, Raid},
  booktitle={Soft Computing and Pattern Recognition (SoCPaR), 2014 6th International Conference of},
  pages={312--318},
  year={2014},
  organization={IEEE}
}

@article{hadash2018estimate,
  title={Estimate and Replace: A Novel Approach to Integrating Deep Neural Networks with Existing Applications},
  author={Hadash, Guy and Kermany, Einat and Carmeli, Boaz and Lavi, Ofer and Kour, George and Jacovi, Alon},
  journal={arXiv preprint arXiv:1804.09028},
  year={2018}
}

@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}
@book{everett2017language,
  title={How language began: The story of humanity’s greatest invention},
  author={Everett, Daniel},
  year={2017},
  publisher={Profile Books}
}
@article{oraby2019curate,
  title={Curate and generate: A corpus and method for joint control of semantics and style in neural nlg},
  author={Oraby, Shereen and Harrison, Vrindavan and Ebrahimi, Abteen and Walker, Marilyn},
  journal={arXiv preprint arXiv:1906.01334},
  year={2019}
}


@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@misc{reback2020pandas,
    author       = {The pandas development team},
    title        = {pandas-dev/pandas: Pandas},
    month        = feb,
    year         = 2020,
    publisher    = {Zenodo},
    version      = {latest},
    doi          = {10.5281/zenodo.3509134},
    url          = {https://doi.org/10.5281/zenodo.3509134}
}

@article{knearest,
  title={Neighbourhood components analysis},
  author={Goldberger, Jacob and Hinton, Geoffrey E and Roweis, Sam and Salakhutdinov, Russ R},
  journal={Advances in neural information processing systems},
  volume={17},
  year={2004}
}

@article{kmeans,
  title={Comparing partitions},
  author={Hubert, Lawrence and Arabie, Phipps},
  journal={Journal of classification},
  volume={2},
  number={1},
  pages={193--218},
  year={1985},
  publisher={Springer}
}

@book{vapnik1974theory,
  title={Theory of pattern recognition},
  author={Vapnik, Vladimir and Chervonenkis, Alexey},
  year={1974},
  publisher={Nauka, Moscow}
}

@inproceedings{weinberger2009feature,
  title={Feature hashing for large scale multitask learning},
  author={Weinberger, Kilian and Dasgupta, Anirban and Langford, John and Smola, Alex and Attenberg, Josh},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={1113--1120},
  year={2009}
}

@article{kstest-naaman2021tight,
  title={On the tight constant in the multivariate dvoretzky--kiefer--wolfowitz inequality},
  author={Naaman, Michael},
  journal={Statistics \& Probability Letters},
  volume={173},
  pages={109088},
  year={2021},
  publisher={Elsevier}
}

@article{mannwhitney-testfay2010wilcoxon,
  title={Wilcoxon-Mann-Whitney or t-test? On assumptions for hypothesis tests and multiple interpretations of decision rules},
  author={Fay, Michael P and Proschan, Michael A},
  journal={Statistics surveys},
  volume={4},
  pages={1},
  year={2010},
  publisher={NIH Public Access}
}

@article{dey2009opinion,
  title={Opinion mining from noisy text data},
  author={Dey, Lipika and Haque, SK and others},
  journal={International Journal on Document Analysis and Recognition (IJDAR)},
  volume={12},
  number={3},
  pages={205--226},
  year={2009},
  publisher={Springer}
}

@article{kirk2021bias,
  title={Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models},
  author={Kirk, Hannah Rose and Volpin, Filippo and Iqbal, Haider and Benussi, Elias and Dreyer, Frederic and Shtedritski, Aleksandar and Asano, Yuki and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{lovering2020predicting,
  title={Predicting inductive biases of pre-trained models},
  author={Lovering, Charles and Jha, Rohan and Linzen, Tal and Pavlick, Ellie},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@misc{grootendorst2020keybert,
  author       = {Maarten Grootendorst},
  title        = {KeyBERT: Minimal keyword extraction with BERT.},
  year         = 2020,
  publisher    = {Zenodo},
  version      = {v0.3.0},
  doi          = {10.5281/zenodo.4461265},
  url          = {https://doi.org/10.5281/zenodo.4461265}
}

@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}


@misc{PPO,
  doi = {10.48550/ARXIV.1707.06347},
  
  url = {https://arxiv.org/abs/1707.06347},
  
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Proximal Policy Optimization Algorithms},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{PSQI,
title = {The Pittsburgh sleep quality index: A new instrument for psychiatric practice and research},
journal = {Psychiatry Research},
volume = {28},
number = {2},
pages = {193-213},
year = {1989},
issn = {0165-1781},
doi = {https://doi.org/10.1016/0165-1781(89)90047-4},
url = {https://www.sciencedirect.com/science/article/pii/0165178189900474},
author = {Daniel J. Buysse and Charles F. Reynolds and Timothy H. Monk and Susan R. Berman and David J. Kupfer},
keywords = {Sleep, sleep quality, depression, sleep disorders},
abstract = {Despite the prevalence of sleep complaints among psychiatric patients, few questionnaires have been specifically designed to measure sleep quality in clinical populations. The Pittsburgh Sleep Quality Index (PSQI) is a self-rated questionnaire which assesses sleep quality and disturbances over a 1-month time interval. Nineteen individual items generate seven “component” scores: subjective sleep quality, sleep latency, sleep duration, habitual sleep efficiency, sleep disturbances, use of sleeping medication, and daytime dysfunction. The sum of scores for these seven components yields one global score. Clinical and clinimetric properties of the PSQI were assessed over an 18-month period with “good” sleepers (healthy subjects, n = 52) and “poor” sleepers (depressed patients, n = 54; sleep-disorder patients, n = 62). Acceptable measures of internal homogeneity, consistency (test-retest reliability), and validity were obtained. A global PSQI score > 5 yielded a diagnostic sensitivity of 89.6% and specificity of 86.5% (kappa = 0.75, p ⩽ 0.001) in distinguishing good and poor sleepers. The clinemetric and clinical properties of the PSQI suggest its utility both in psychiatric clinical practice and research activities.}
}


@misc{challenges,
  doi = {10.48550/ARXIV.2103.05612},
  
  url = {https://arxiv.org/abs/2103.05612},
  
  author = {Riachi, Elsa and Mamdani, Muhammad and Fralick, Michael and Rudzicz, Frank},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences, J.3; I.2},
  
  title = {Challenges for Reinforcement Learning in Healthcare},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@inproceedings{zhao-etal-2021-efficient,
    title = "Efficient Dialogue Complementary Policy Learning via Deep {Q}-network Policy and Episodic Memory Policy",
    author = "Zhao, Yangyang  and
      Wang, Zhenyu  and
      Zhu, Changxi  and
      Wang, Shihan",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.354",
    doi = "10.18653/v1/2021.emnlp-main.354",
    pages = "4311--4323",
    abstract = "Deep reinforcement learning has shown great potential in training dialogue policies. However, its favorable performance comes at the cost of many rounds of interaction. Most of the existing dialogue policy methods rely on a single learning system, while the human brain has two specialized learning and memory systems, supporting to find good solutions without requiring copious examples. Inspired by the human brain, this paper proposes a novel complementary policy learning (CPL) framework, which exploits the complementary advantages of the episodic memory (EM) policy and the deep Q-network (DQN) policy to achieve fast and effective dialogue policy learning. In order to coordinate between the two policies, we proposed a confidence controller to control the complementary time according to their relative efficacy at different stages. Furthermore, memory connectivity and time pruning are proposed to guarantee the flexible and adaptive generalization of the EM policy in dialog tasks. Experimental results on three dialogue datasets show that our method significantly outperforms existing methods relying on a single learning system.",
}


@article{Young2018IntegratingEM,
  title={Integrating Episodic Memory into a Reinforcement Learning Agent using Reservoir Sampling},
  author={Kenny J. Young and Richard S. Sutton and Shuo Yang},
  journal={ArXiv},
  year={2018},
  volume={abs/1806.00540}
}


@article{A3C,
  doi = {10.48550/ARXIV.1602.01783},
  
  url = {https://arxiv.org/abs/1602.01783},
  
  author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Asynchronous Methods for Deep Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@ARTICLE{HEEM,
  author={Yang, Dujia and Qin, Xiaowei and Xu, Xiaodong and Li, Chensheng and Wei, Guo},
  journal={IEEE Access}, 
  title={Sample Efficient Reinforcement Learning Method via High Efficient Episodic Memory}, 
  year={2020},
  volume={8},
  number={},
  pages={129274-129284},
  doi={10.1109/ACCESS.2020.3009329}}
  
  
  
 @misc{SAC,
  doi = {10.48550/ARXIV.1812.05905},
  
  url = {https://arxiv.org/abs/1812.05905},
  
  author = {Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Robotics (cs.RO), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Soft Actor-Critic Algorithms and Applications},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{DDPG,
  doi = {10.48550/ARXIV.1509.02971},
  
  url = {https://arxiv.org/abs/1509.02971},
  
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Continuous control with deep reinforcement learning},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{DQN,
  doi = {10.48550/ARXIV.1312.5602},
  
  url = {https://arxiv.org/abs/1312.5602},
  
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Playing Atari with Deep Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2013},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@ARTICLE{vadim,
  
AUTHOR={Liventsev, Vadim and Härmä, Aki and Petković, Milan},   
	 
TITLE={Towards Effective Patient Simulators},      
	
JOURNAL={Frontiers in Artificial Intelligence},      
	
VOLUME={4},           
	
YEAR={2021},      
	  
URL={https://www.frontiersin.org/articles/10.3389/frai.2021.798659},       
	
DOI={10.3389/frai.2021.798659},      
	
ISSN={2624-8212},   
   
ABSTRACT={In this paper we give an overview of the field of patient simulators and provide qualitative and quantitative comparison of different modeling and simulation approaches. Simulators can be used to train human caregivers but also to develop and optimize algorithms for clinical decision support applications and test and validate interventions. In this paper we introduce three novel patient simulators with different levels of representational accuracy: HeartPole, a simplistic transparent rule-based system, GraphSim, a graph-based model trained on intensive care data, and Auto-ALS—an adjusted version of an educational software package used for training junior healthcare professionals. We provide a qualitative and quantitative comparison of the previously existing as well as proposed simulators.}
}


@misc{RLsurvey,
  doi = {10.48550/ARXIV.1908.08796},
  
  url = {https://arxiv.org/abs/1908.08796},
  
  author = {Yu, Chao and Liu, Jiming and Nemati, Shamim},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Reinforcement Learning in Healthcare: A Survey},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@misc{MIMIC,
 doi = {10.13026/C2XW26},
  
  url = {https://doi.org/10.13026/C2XW26},
  
  author = {Johnson, A. and Pollard, T. and  Mark, R.},
  
  title = {MIMIC-III Clinical Database (version 1.4)},
  
  publisher = {PhysioNet},
  
  year = {2016},
}



@misc{RLRS_survey,
  doi = {10.48550/ARXIV.2101.06286},
  
  url = {https://arxiv.org/abs/2101.06286},
  
  author = {Afsar, M. Mehdi and Crump, Trafford and Far, Behrouz},
  
  keywords = {Information Retrieval (cs.IR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Reinforcement learning based recommender systems: A survey},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{conv_RS_survey,
title = {Conversational recommender systems techniques, tools, acceptance, and adoption: A state of the art review},
journal = {Expert Systems with Applications},
volume = {203},
pages = {117539},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117539},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422008612},
author = {Dhanya Pramod and Prafulla Bafna},
keywords = {Preference elicitation, Critiquing, Interactive recommender, Conversational systems, Recommendation, Systematic review},
abstract = {Conversational recommender systems(CRS) have become popular in recent years and have gained the attention of researchers. More emphasis is given to user choices and experiences in recent research studies. This study presents a systematic review and uses PRISMA methodology for the search strategy, study selection, and extraction. The algorithmic aspects and evolution of the most common methods used in the design of conversational recommender system components are discussed to provide a comprehensive picture. The study unveils the major advantages and limitations of the user preference elicitation and recommendation techniques. It also summarizes the recommendation tools and framework for different application domains with the techniques adopted. The study further aimed to find the implementation challenges, and the same is highlighted with the recommended solutions. As the users are the key focus for the conversational recommender systems, this paper also presents the role of effective user acceptance and adoption models. The statistical analysis provided in the study gives an insight into the growing popularity of CRS research areas and their application in various domains. The results of this study provide insights to practitioners, which may help in better CRS implementations and contribute to the literature by providing a comprehensive viewpoint. The study also postulates the topics that need attention and gives future research trends.}
}


@article{graph_RS,
title = {Introducing linked open data in graph-based recommender systems},
journal = {Information Processing \& Management},
volume = {53},
number = {2},
pages = {405-435},
year = {2017},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2016.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0306457316306847},
author = {Cataldo Musto and Pierpaolo Basile and Pasquale Lops and Marco {de Gemmis} and Giovanni Semeraro},
keywords = {Recommender systems, PageRank, Graphs, Linked open data, Feature selection, Diversity},
abstract = {Thanks to the recent spread of the Linked Open Data (LOD) initiative, a huge amount of machine-readable knowledge encoded as RDF statements is today available in the so-called LOD cloud. Accordingly, a big effort is now spent to investigate to what extent such information can be exploited to develop new knowledge-based services or to improve the effectiveness of knowledge-intensive platforms as Recommender Systems (RS). To this end, in this article we study the impact of the exogenous knowledge coming from the LOD cloud on the overall performance of a graph-based recommendation framework. Specifically, we propose a methodology to automatically feed a graph-based RS with features gathered from the LOD cloud and we analyze the impact of several widespread feature selection techniques in such recommendation settings. The experimental evaluation, performed on three state-of-the-art datasets, provided several outcomes: first, information extracted from the LOD cloud can significantly improve the performance of a graph-based RS. Next, experiments showed a clear correlation between the choice of the feature selection technique and the ability of the algorithm to maximize specific evaluation metrics, as accuracy or diversity of the recommendations. Moreover, our graph-based algorithm fed with LOD-based features was able to overcome several baselines, as collaborative filtering and matrix factorization.}
}




@ARTICLE{BGMM,
  author={Roberts, S.J. and Husmeier, D. and Rezek, I. and Penny, W.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Bayesian approaches to Gaussian mixture modeling}, 
  year={1998},
  volume={20},
  number={11},
  pages={1133-1142},
  doi={10.1109/34.730550}}
  
  
@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@article{dirichlet,
author = {Blei, David and Jordan, Michael},
year = {2006},
month = {03},
pages = {},
title = {Variational inference for Dirichlet process mixtures},
volume = {1},
journal = {Bayesian Analysis},
doi = {10.1214/06-BA104}
}

@article{variational_bayesian,
author = {Attias, Hagai},
year = {2000},
month = {09},
pages = {},
title = {A Variational Bayesian Framework for Graphical Models},
volume = {12},
journal = {Adv. Neural Inf. Process. Syst}
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}



@article{gatt2018survey,
  title={Survey of the state of the art in natural language generation: Core tasks, applications and evaluation},
  author={Gatt, Albert and Krahmer, Emiel},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={65--170},
  year={2018}
}

@article{varges2010instance,
  title={Instance-based natural language generation},
  author={Varges, Sebastian and Mellish, Chris},
  journal={Natural Language Engineering},
  volume={16},
  number={3},
  pages={309--346},
  year={2010},
  publisher={Cambridge University Press}
}

@article{rajkomar_scalable,
author = {Rajkomar, Alvin and Oren, Eyal and Chen, Kai and Dai, Andrew and Hajaj, Nissan and Liu, Peter and Liu, Xiaobing and Sun, Mimi and Sundberg, Patrik and Yee, Hector and Zhang, Kun and Duggan, Gavin and Flores, Gerardo and Hardt, Michaela and Irvine, Jamie and Le, Quoc and Litsch, Kurt and Marcus, Jake and Mossin, Alexander and Dean, Jeff},
year = {2018},
month = {01},
pages = {},
title = {Scalable and accurate deep learning for electronic health records},
volume = {1},
journal = {npj Digital Medicine},
doi = {10.1038/s41746-018-0029-1}
}

@article{Purush_benchmark,
author = {Purushotham, Sanjay and Meng, Chuizheng and Che, Zhengping and Liu, Yan},
year = {2017},
month = {10},
pages = {},
title = {Benchmark of Deep Learning Models on Large Healthcare MIMIC Datasets},
volume = {83},
journal = {Journal of Biomedical Informatics},
doi = {10.1016/j.jbi.2018.04.007}
}

@article{Xiao_ooport,
author = {Xiao, Cao and Choi, Edward and Sun, J.},
year = {2018},
month = {06},
pages = {},
title = {Opportunities and challenges in developing deep learning models using electronic health records data: A systematic review},
volume = {25},
journal = {Journal of the American Medical Informatics Association},
doi = {10.1093/jamia/ocy068}
}

@INPROCEEDINGS{lillicrap,  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},   title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},   year={2017},  volume={},  number={},  pages={3389-3396},  doi={10.1109/ICRA.2017.7989385}}

@Article{AlphaFold2021, author  = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A A and Ballard, Andrew J and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis}, journal = {Nature}, title   = {Highly accurate protein structure prediction with {AlphaFold}}, year    = {2021}, volume  = {596}, number  = {7873}, pages   = {583--589}, doi     = {10.1038/s41586-021-03819-2}}

@incollection{WILSON2013169, title = {Chapter 6 - Block Diagram Modeling and System Analysis}, editor = {Peter Wilson and H. Alan Mantooth}, booktitle = {Model-Based Engineering for Complex Electronic Systems}, publisher = {Newnes}, address = {Oxford}, pages = {169-196}, year = {2013}, isbn = {978-0-12-385085-0}, doi = {https://doi.org/10.1016/B978-0-12-385085-0.00006-3}, url = {https://www.sciencedirect.com/science/article/pii/B9780123850850000063}, author = {Peter Wilson and H. Alan Mantooth}, keywords = {system level modeling, block diagram, state machines}, abstract = {This chapter describes many of the useful approaches to describe systems using a high level of abstraction. Whether this is for digital systems using finite state machines or algorithmic state machines, or for more abstract systems using Laplace or Z domain techniques this chapter introduces the approaches by which we can effectively consider complex systems with a very high level of abstraction. Examples are used to illustrate how the approach of a “block level” methodology in a graphical modeling context can help in understanding and implementation of models at this level.}}

@article{sporrel2022just,
  title={Just-in-Time Prompts for Running, Walking, and Performing Strength Exercises in the Built Environment: 4-Week Randomized Feasibility Study},
  author={Sporrel, Karlijn and Wang, Shihan and Ettema, Dick DF and Nibbeling, Nicky and Krose, Ben JA and Deutekom, Marije and de Boer, R{\'e}mi DD and Simons, Monique and others},
  journal={JMIR formative research},
  volume={6},
  number={8},
  pages={e35268},
  year={2022},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article {swang_opt,
	Title = {Optimizing Adaptive Notifications in Mobile Health Interventions Systems: Reinforcement Learning from a Data-driven Behavioral Simulator},
	Author = {Wang, Shihan and Zhang, Chao and Kröse, Ben and van Hoof, Herke},
	DOI = {10.1007/s10916-021-01773-0},
	Number = {12},
	Volume = {45},
	Month = {October},
	Year = {2021},
	Journal = {Journal of medical systems},
	ISSN = {0148-5598},
	Pages = {102},
	Abstract = {Mobile health (mHealth) intervention systems can employ adaptive strategies to interact with users. Instead of designing such complex strategies manually, reinforcement learning (RL) can be used to adaptively optimize intervention strategies concerning the user's context. In this paper, we focus on the issue of overwhelming interactions when learning a good adaptive strategy for the user in RL-based mHealth intervention agents. We present a data-driven approach integrating psychological insights and knowledge of historical data. It allows RL agents to optimize the strategy of delivering context-aware notifications from empirical data when counterfactual information (user responses when receiving notifications) is missing. Our approach also considers a constraint on the frequency of notifications, which reduces the interaction burden for users. We evaluated our approach in several simulation scenarios using real large-scale running data. The results indicate that our RL agent can deliver notifications in a manner that realizes a higher behavioral impact than context-blind strategies.},
	URL = {https://europepmc.org/articles/PMC8523513},
}

@article{bakker2022fine,
  title={Fine-tuning language models to find agreement among humans with diverse preferences},
  author={Bakker, Michiel A and Chadwick, Martin J and Sheahan, Hannah R and Tessler, Michael Henry and Campbell-Gillingham, Lucy and Balaguer, Jan and McAleese, Nat and Glaese, Amelia and Aslanides, John and Botvinick, Matthew M and others},
  journal={arXiv preprint arXiv:2211.15006},
  year={2022}
}

@article{sheng2020towards,
  title={Towards controllable biases in language generation},
  author={Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  journal={arXiv preprint arXiv:2005.00268},
  year={2020}
}

@article{khalifa2020distributional,
  title={A distributional approach to controlled text generation},
  author={Khalifa, Muhammad and Elsahar, Hady and Dymetman, Marc},
  journal={arXiv preprint arXiv:2012.11635},
  year={2020}
}


@article{dutta2022can,
  title={Can Unsupervised Knowledge Transfer from Social Discussions Help Argument Mining?},
  author={Dutta, Subhabrata and Juneja, Jeevesh and Das, Dipankar and Chakraborty, Tanmoy},
  journal={arXiv preprint arXiv:2203.12881},
  year={2022}
}

@inproceedings{chintagunta2021medically,
  title={Medically aware gpt-3 as a data generator for medical dialogue summarization},
  author={Chintagunta, Bharath and Katariya, Namit and Amatriain, Xavier and Kannan, Anitha},
  booktitle={Machine Learning for Healthcare Conference},
  pages={354--372},
  year={2021},
  organization={PMLR}
}

@inproceedings{van2021fine,
  title={Fine-tuning GPT-2 on annotated RPG quests for NPC dialogue generation},
  author={van Stegeren, Judith and My{\'s}liwiec, Jakub},
  booktitle={The 16th International Conference on the Foundations of Digital Games (FDG) 2021},
  pages={1--8},
  year={2021}
}

@article{lee2020patent,
  title={Patent claim generation by fine-tuning OpenAI GPT-2},
  author={Lee, Jieh-Sheng and Hsiang, Jieh},
  journal={World Patent Information},
  volume={62},
  pages={101983},
  year={2020},
  publisher={Elsevier}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{hoffmann2022training,
  title={Training Compute-Optimal Large Language Models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@software{gpt-neo,
  author       = {Black, Sid and
                  Gao, Leo and
                  Wang, Phil and
                  Leahy, Connor and
                  Biderman, Stella},
  title        = {{GPT-Neo: Large Scale Autoregressive Language 
                   Modeling with Mesh-Tensorflow}},
  month        = mar,
  year         = 2021,
  note         = {{If you use this software, please cite it using 
                   these metadata.}},
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.5297715},
  url          = {https://doi.org/10.5281/zenodo.5297715}
}

@article{gao2020pile,
  title={The Pile: An 800GB Dataset of Diverse Text for Language Modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@article{Zhang2022OPTOP,
  title={OPT: Open Pre-trained Transformer Language Models},
  author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.01068}
}

@article{sheng2019woman,
  title={The woman worked as a babysitter: On biases in language generation},
  author={Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  journal={arXiv preprint arXiv:1909.01326},
  year={2019}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}


 @article{loria2020textblob,
  title={TextBlob Documentation},
  author={Loria, Steven},
  journal={Release 0.16},
  volume={\url{https://textblob.readthedocs.io}},
  howpublished={\url{https://textblob.readthedocs.io}},
  year={2020}
} 

@inproceedings{morinaga2002mining,
  title={Mining product reputations on the web},
  author={Morinaga, Satoshi and Yamanishi, Kenji and Tateishi, Kenji and Fukushima, Toshikazu},
  booktitle={Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={341--349},
  year={2002}
}

@article{pang2008opinion,
  title={Opinion mining and sentiment analysis},
  author={Pang, Bo and Lee, Lillian and others},
  journal={Foundations and Trends{\textregistered} in information retrieval},
  volume={2},
  number={1--2},
  pages={1--135},
  year={2008},
  publisher={Now Publishers, Inc.}
}

@article{aihealthcoach,
author = {Mohan, Shiwali and Venkatakrishnan, Anusha and Hartzler, Andrea L.},
title = {Designing an AI Health Coach and Studying Its Utility in Promoting Regular Aerobic Exercise},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {2160-6455},
url = {https://doi.org/10.1145/3366501},
doi = {10.1145/3366501},
abstract = {Our research aims to develop interactive, social agents that can coach people to learn new tasks, skills, and habits. In this article, we focus on coaching sedentary, overweight individuals (i.e., “trainees”) to exercise regularly. We employ adaptive goal setting in which the intelligent health coach generates, tracks, and revises personalized exercise goals for a trainee. The goals become incrementally more difficult as the trainee progresses through the training program. Our approach is model-based—the coach maintains a parameterized model of the trainee’s aerobic capability that drives its expectation of the trainee’s performance. The model is continually revised based on trainee-coach interactions. The coach is embodied in a smartphone application, NutriWalking, which serves as a medium for coach-trainee interaction. We adopt a task-centric evaluation approach for studying the utility of the proposed algorithm in promoting regular aerobic exercise. We show that our approach can adapt the trainee program not only to several trainees with different capabilities but also to how a trainee’s capability improves as they begin to exercise more. Experts rate the goals selected by the coach better than other plausible goals, demonstrating that our approach is consistent with clinical recommendations. Further, in a 6-week observational study with sedentary participants, we show that the proposed approach helps increase exercise volume performed each week.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {may},
articleno = {14},
numpages = {30},
keywords = {coaching AI, human-aware AI systems, AI for social good, supporting human learning, evaluation of interactive AI, health systems, Health behavior change, AI and society}
}

@article{HEATH2012272,
title = {Evidence-based intervention in physical activity: lessons from around the world},
journal = {The Lancet},
volume = {380},
number = {9838},
pages = {272-281},
year = {2012},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(12)60816-2},
url = {https://www.sciencedirect.com/science/article/pii/S0140673612608162},
author = {Gregory W Heath and Diana C Parra and Olga L Sarmiento and Lars Bo Andersen and Neville Owen and Shifalika Goenka and Felipe Montes and Ross C Brownson},
abstract = {Summary
Promotion of physical activity is a priority for health agencies. We searched for reviews of physical activity interventions, published between 2000 and 2011, and identified effective, promising, or emerging interventions from around the world. The informational approaches of community-wide and mass media campaigns, and short physical activity messages targeting key community sites are recommended. Behavioural and social approaches are effective, introducing social support for physical activity within communities and worksites, and school-based strategies that encompass physical education, classroom activities, after-school sports, and active transport. Recommended environmental and policy approaches include creation and improvement of access to places for physical activity with informational outreach activities, community-scale and street-scale urban design and land use, active transport policy and practices, and community-wide policies and planning. Thus, many approaches lead to acceptable increases in physical activity among people of various ages, and from different social groups, countries, and communities.}
}

@article{BAUMAN2008S249,
title = {Testing a Hierarchy-of-Effects Model: Pathways from Awareness to Outcomes in the VERB™ Campaign 2002–2003},
journal = {American Journal of Preventive Medicine},
volume = {34},
number = {6, Supplement },
pages = {S249-S256},
year = {2008},
note = {The VERB™ Campaign},
issn = {0749-3797},
doi = {https://doi.org/10.1016/j.amepre.2008.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0749379708002638},
author = {Adrian Bauman and Heather R. Bowles and Marian Huhman and Carrie D. Heitzler and Neville Owen and Ben J. Smith and Bill Reger-Nash},
abstract = {Background
The McGuire hierarchy-of-effects (HOE) model, used extensively in mass-media interventions to describe the mechanisms for understanding effects, has not been tested in physical activity campaigns.
Design
Data collected at baseline (2002) and follow-up (2003) surveys in the VERB™ evaluation were used in structural equation modeling to test pathways and hierarchies of campaign effects.
Setting/participants
Population-based cohort of youth aged 9–13 years (N=2364) for whom complete baseline and follow-up data were available.
Main outcome measures
Awareness of the VERB campaign, understanding of the VERB message, attitude toward being active, outcome expectations, and physical activity participation.
Results
Among youth aged 9–13 years (tweens) in the study cohort, significant paths were identified between awareness and understanding (0.72, p<0.001) and between understanding and being physically active (0.11, p<0.05). At baseline, there was a high prevalence of positive attitudes and outcome expectations, and these were not influenced by a change in understanding or awareness. Among inactive tweens only, the same paths were identified except that, in this subgroup, the attitude was related to physical activity (0.13, p<0.05), and awareness was more strongly related to physical activity than it was for the whole sample (0.14, p<0.01).
Conclusions
These findings provided limited support for the HOE model and suggest that increased awareness and understanding were the key proximal effects that led to behavior change. A distinct sequence of effects, which bypassed attitudes and outcome expectations, was found for these U.S. young people. The findings could inform the design of future campaigns to address youth physical activity.}
}

@article{Vroege2014DoseResponseEO,
  title={Dose-Response Effects of a Web-Based Physical Activity Program on Body Composition and Metabolic Health in Inactive Older Adults: Additional Analyses of a Randomized Controlled Trial},
  author={David P Vroege and Carolien A Wijsman and Karen Broekhuizen and Anton J M de Craen and Diana van Heemst and Frans J G van der Ouderaa and Willem van Mechelen and Pieternella E Slagboom and Michael Catt and Rudi G. J. Westendorp and Evert A.L.M. Verhagen and Simon P. Mooijaart},
  journal={Journal of Medical Internet Research},
  year={2014},
  volume={16}
}

@article{berkowitz2008did,
  title={Did augmenting the VERB™ campaign advertising in select communities have an effect on awareness, attitudes, and physical activity?},
  author={Berkowitz, Judy M and Huhman, Marian and Nolin, Mary Jo},
  journal={American Journal of Preventive Medicine},
  volume={34},
  number={6},
  pages={S257--S266},
  year={2008},
  publisher={Elsevier}
}

@article{aschbrenner2022group,
  title={Group lifestyle intervention with mobile health for young adults with serious mental illness: A randomized controlled trial},
  author={Aschbrenner, Kelly A and Naslund, John A and Gorin, Amy A and Mueser, Kim T and Browne, Julia and Wolfe, Rosemarie S and Xie, Haiyi and Bartels, Stephen J},
  journal={Psychiatric Services},
  volume={73},
  number={2},
  pages={141--148},
  year={2022},
  publisher={Am Psychiatric Assoc}
}

@Article{mhealth,
author="Amagai, Saki
and Pila, Sarah
and Kaat, Aaron J
and Nowinski, Cindy J
and Gershon, Richard C",
title="Challenges in Participant Engagement and Retention Using Mobile Health Apps: Literature Review",
journal="J Med Internet Res",
year="2022",
month="Apr",
day="26",
volume="24",
number="4",
pages="e35120",
keywords="mobile phone; mHealth; retention; engagement",
abstract="Background: Mobile health (mHealth) apps are revolutionizing the way clinicians and researchers monitor and manage the health of their participants. However, many studies using mHealth apps are hampered by substantial participant dropout or attrition, which may impact the representativeness of the sample and the effectiveness of the study. Therefore, it is imperative for researchers to understand what makes participants stay with mHealth apps or studies using mHealth apps. Objective: This study aimed to review the current peer-reviewed research literature to identify the notable factors and strategies used in adult participant engagement and retention. Methods: We conducted a systematic search of PubMed, MEDLINE, and PsycINFO databases for mHealth studies that evaluated and assessed issues or strategies to improve the engagement and retention of adults from 2015 to 2020. We followed the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Notable themes were identified and narratively compared among different studies. A binomial regression model was generated to examine the factors affecting retention. Results: Of the 389 identified studies, 62 (15.9{\%}) were included in this review. Overall, most studies were partially successful in maintaining participant engagement. Factors related to particular elements of the app (eg, feedback, appropriate reminders, and in-app support from peers or coaches) and research strategies (eg, compensation and niche samples) that promote retention were identified. Factors that obstructed retention were also identified (eg, lack of support features, technical difficulties, and usefulness of the app). The regression model results showed that a participant is more likely to drop out than to be retained. Conclusions: Retaining participants is an omnipresent challenge in mHealth studies. The insights from this review can help inform future studies about the factors and strategies to improve participant retention. ",
issn="1438-8871",
doi="10.2196/35120",
url="https://www.jmir.org/2022/4/e35120",
url="https://doi.org/10.2196/35120",
url="http://www.ncbi.nlm.nih.gov/pubmed/35471414"
}

@article{mhealthengagement,
author = {Oakley-Girvan, Ingrid and Yunis, Reem and Longmire, Michelle and Ouillon, Jessey Schwartz},
title = {What Works Best to Engage Participants in Mobile App Interventions and e-Health: A Scoping Review},
journal = {Telemedicine and e-Health},
volume = {28},
number = {6},
pages = {768-780},
year = {2022},
doi = {10.1089/tmj.2021.0176},
    note ={PMID: 34637651},
URL = { https://doi.org/10.1089/tmj.2021.0176},
eprint = { https://doi.org/10.1089/tmj.2021.0176},
    abstract = { Background: Despite the growing popularity of mobile app interventions, specific engagement components of mobile apps have not been well studied. Methods: The objectives of this scoping review are to determine which components of mobile health intervention apps encouraged or hindered engagement, and examine how studies measured engagement. Results: A PubMed search on March 5, 2020 yielded 239 articles that featured the terms engagement, mobile app/mobile health, and adult. After applying exclusion criteria, only 54 studies were included in the final analysis. Discussion: Common app components associated with increased engagement included: personalized content/feedback, data visualization, reminders/push notifications, educational information/material, logging/self-monitoring functions, and goal-setting features. On the other hand, social media integration, social forums, poor app navigation, and technical difficulties appeared to contribute to lower engagement rates or decreased usage. Notably, the review revealed a great variability in how engagement with mobile health apps is measured due to lack of established processes. Conclusion: There is a critical need for controlled studies to provide guidelines and standards to help facilitate engagement and its measurement in research and clinical trial work using mobile health intervention apps. }
}

@article{kahn2002effectiveness,
  title={The effectiveness of interventions to increase physical activity: a systematic review},
  author={Kahn, Emily B and Ramsey, Leigh T and Brownson, Ross C and Heath, Gregory W and Howze, Elizabeth H and Powell, Kenneth E and Stone, Elaine J and Rajab, Mummy W and Corso, Phaedra},
  journal={American journal of preventive medicine},
  volume={22},
  number={4},
  pages={73--107},
  year={2002},
  publisher={Elsevier}
}

@article{linenger1991physical,
  title={Physical fitness gains following simple environmental change},
  author={Linenger, Jerry M and Chesson II, Charles V and Nice, D Stephen},
  journal={American Journal of Preventive Medicine},
  volume={7},
  number={5},
  pages={298--310},
  year={1991},
  publisher={Elsevier}
}

@incollection{dodson2019policy,
  title={Policy and Environmental Supports for Physical Activity and Active Living},
  author={Dodson, Elizabeth A and Heath, Gregory W},
  booktitle={Lifestyle Medicine},
  pages={1365--1373},
  year={2019},
  publisher={CRC Press}
}

@article{wang2004cost,
  title={Cost analysis of the built environment: the case of bike and pedestrian trials in Lincoln, Neb},
  author={Wang, Guijing and Macera, Caroline A and Scudder-Soucie, Barbara and Schmid, Tom and Pratt, Michael and Buchner, David and Heath, Gregory},
  journal={American Journal of Public Health},
  volume={94},
  number={4},
  pages={549--553},
  year={2004},
  publisher={American Public Health Association}
}

@article{muellmann2018effectiveness,
  title={Effectiveness of eHealth interventions for the promotion of physical activity in older adults: a systematic review},
  author={Muellmann, Saskia and Forberger, Sarah and M{\"o}llers, Tobias and Br{\"o}ring, Eileen and Zeeb, Hajo and Pischke, Claudia R},
  journal={Preventive medicine},
  volume={108},
  pages={93--110},
  year={2018},
  publisher={Elsevier}
}

@article{jonkman2018ehealth,
  title={eHealth interventions to promote objectively measured physical activity in community-dwelling older people},
  author={Jonkman, Nini H and van Schooten, Kimberley S and Maier, Andrea B and Pijnappels, Mirjam},
  journal={Maturitas},
  volume={113},
  pages={32--39},
  year={2018},
  publisher={Elsevier}
}

@article{elavsky2019mobile,
  title={Mobile health interventions for physical activity, sedentary behavior, and sleep in adults aged 50 years and older: a systematic literature review},
  author={Elavsky, Steriani and Knapova, Lenka and Klocek, Adam and Smahel, David},
  journal={Journal of aging and physical activity},
  volume={27},
  number={4},
  pages={565--593},
  year={2019},
  publisher={Human Kinetics}
}


@article{hochberg2016reinforcement,
  title={A reinforcement learning system to encourage physical activity in diabetes patients},
  author={Hochberg, Irit and Feraru, Guy and Kozdoba, Mark and Mannor, Shie and Tennenholtz, Moshe and Yom-Tov, Elad},
  journal={arXiv preprint arXiv:1605.04070},
  year={2016}
}


@article{undefined2020Effects,
	author = {An, Seonuk and Song, Rhayun},
	journal = {Patient Education and Counseling},
	number = {10},
	year = {2020},
	month = {10},
	pages = {2029--2038},
	publisher = {Elsevier BV},
	title = {Effects of health coaching on behavioral modification among adults with cardiovascular risk factors: Systematic review and meta-analysis},
	volume = {103},
	url = {http://dx.doi.org/10.1016/j.pec.2020.04.029},
	doi = {10.1016/j.pec.2020.04.029},
	abstract = {OBJECTIVES

This meta-analysis examined effects of health coaching on physical activities, dietary behaviors, health responsibility, stress management, and smoking behaviors among populations with cardiovascular risk factors.

METHODS

Multiple electronic databases were searched for randomized controlled trials utilizing health coaching for people with cardiovascular risk factors to lead behavioral changes. The included studies were pooled to estimate the effect size for health coaching interventions on each of the health behaviors.

RESULTS

This meta-analysis included 15 randomized trials. Motivational interviewing and education sessions were common coaching interventions with telephone calls or face-to-face contacts as the main contact methods. Health coaching for health behaviors showed small but significant effect sizes on physical activities, dietary behaviors, health responsibility, and stress management except for smoking behaviors.

CONCLUSION

The study findings support that health coaching can induce positive behavioral changes among individuals with cardiovascular risk factors. Health coaching delivered by either expert or peer coaches would be easy to apply in clinical settings.

PRACTICAL IMPLICATIONS

Health care professionals should be aware that health coaching could provide effective motivation strategies to improve compliance of those who need to initiate and maintain their health behaviors. Health coaching could be easily delivered via telephone calls, text messages, or short-term face-to-face coaching.},
}

@article{Wong2013Health,
	author = {Wong-Rieger, Durhane and Rieger, Francis P.},
	journal = {Canadian Journal of Diabetes},
	number = {1},
	year = {2013},
	month = {2},
	pages = {41--44},
	publisher = {Elsevier BV},
	title = {Health {Coaching} in {Diabetes}: Empowering {Patients} to {Self}-{Manage}},
	volume = {37},
	url = {http://dx.doi.org/10.1016/j.jcjd.2013.01.001},
	doi = {10.1016/j.jcjd.2013.01.001},
	abstract = {To effectively manage diabetes mellitus, patients must adhere to treatment recommendations and healthy lifestyle behaviors, but research shows many patients do not do this. Education is effective when combined with self-management support but peer-support programs do not lead to lasting changes. Health coaching, or professional support, can be highly effective if it focuses on developing self-efficacy and skills such as goal-setting, problem-solving and managing cognitive and emotional barriers. This overview discusses the benefits of patient self-management for chronic conditions such as diabetes, core competencies for health coaching, theoretical bases and principles of health coaching interventions, delivery methods and the evidence that health coaching works for diabetes self-management.},
}

@article{kaewkannate2016comparison,
  title={A comparison of wearable fitness devices},
  author={Kaewkannate, Kanitthika and Kim, Soochan},
  journal={BMC public health},
  volume={16},
  pages={1--16},
  year={2016},
  publisher={Springer}
}

@article{henriksen2018using,
  title={Using fitness trackers and smartwatches to measure physical activity in research: analysis of consumer wrist-worn wearables},
  author={Henriksen, Andr{\'e} and Haugen Mikalsen, Martin and Woldaregay, Ashenafi Zebene and Muzny, Miroslav and Hartvigsen, Gunnar and Hopstock, Laila Arnesdatter and Grimsgaard, Sameline},
  journal={Journal of medical Internet research},
  volume={20},
  number={3},
  pages={e110},
  year={2018},
  publisher={JMIR Publications Toronto, Canada}
}

@Article{info:doi/10.2196/37348,
author="McCormack, Gavin R
and Petersen, Jennie
and Ghoneim, Dalia
and Blackstaffe, Anita
and Naish, Calli
and Doyle-Baker, Patricia K",
title="Effectiveness of an 8-Week Physical Activity Intervention Involving Wearable Activity Trackers and an eHealth App: Mixed Methods Study",
journal="JMIR Form Res",
year="2022",
month="May",
day="3",
volume="6",
number="5",
pages="e37348",
keywords="activity tracker; technology; eHealth; physical activity; intervention; exercise; mHealth; fitness; wearable; sensor; digital health; COVID-19; health promotion; mixed methods study; wearable technology",
issn="2561-326X",
doi="10.2196/37348",
url="https://formative.jmir.org/2022/5/e37348",
url="https://doi.org/10.2196/37348",
url="http://www.ncbi.nlm.nih.gov/pubmed/35404832"
}

@article{DBLP:journals/corr/abs-2106-13219,
  author       = {Paul Pu Liang and
                  Chiyu Wu and
                  Louis{-}Philippe Morency and
                  Ruslan Salakhutdinov},
  title        = {Towards Understanding and Mitigating Social Biases in Language Models},
  journal      = {CoRR},
  volume       = {abs/2106.13219},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.13219},
  eprinttype    = {arXiv},
  eprint       = {2106.13219},
  timestamp    = {Wed, 30 Jun 2021 16:14:10 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2106-13219.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{gobble2013big,
  title={Big data: The next big thing in innovation},
  author={Gobble, MaryAnne M},
  journal={Research-technology management},
  volume={56},
  number={1},
  pages={64--67},
  year={2013},
  publisher={Taylor \& Francis}
}

@misc{dataibm,
  title={The IBM big data platform},
  author={Data, Big},
  publisher={Mc Graw Hill, New York, NY}
}

@book{choun2022digital,
  title={Digital health and patient data: Empowering patients in the healthcare ecosystem},
  author={Choun, Disa Lee and Petre, Anca},
  year={2022},
  publisher={CRC Press}
}

@article{rose2015internet,
  title={The internet of things: An overview},
  author={Rose, Karen and Eldridge, Scott and Chapin, Lyman},
  journal={The internet society (ISOC)},
  volume={80},
  pages={1--50},
  year={2015},
  publisher={Reston, VA}
}

@article{tasente2020twitter,
  title={Twitter discourse analysis of US president Donald Trump},
  author={Tasente, Tanase},
  journal={Technium Soc. Sci. J.},
  volume={2},
  pages={67},
  year={2020},
  publisher={HeinOnline}
}

@article{alwan2020identifying,
  title={Identifying Influential Users on Instagram Through Visual Content Analysis},
  author={Alwan, Wafaa Hasan and Fazl-Ersi, Ehsan and Vahedian, Abedin},
  journal={IEEE access},
  volume={8},
  pages={169594--169603},
  year={2020},
  publisher={IEEE}
}

@article{kashyap2022gpt,
  title={GPT-Neo for commonsense reasoning-a theoretical and practical lens},
  author={Kashyap, Rohan and Kashyap, Vivek and others},
  journal={arXiv preprint arXiv:2211.15593},
  year={2022}
}

@conference{libio1,
author = {Libio Gonçalves Braz and Allmin Susaiyah},
title = {A Controllable Lifestyle Simulator for use in Deep Reinforcement Learning Algorithms},
booktitle = {2023 IEEE International Conference on Acoustics, Speech, and Signal Processing},
year = 2023,
month = {Jun},
address = {Rhodos, Greece}
}    


@article{jorno2018constitutes,
  title={What constitutes an ‘actionable insight’in learning analytics?},
  author={J{\o}rn{\o}, Rasmus Leth and Gynther, Karsten},
  journal={Journal of Learning Analytics},
  volume={5},
  number={3},
  pages={198--221},
  year={2018}
}

@article{wold1987principal,
  title={Principal component analysis},
  author={Wold, Svante and Esbensen, Kim and Geladi, Paul},
  journal={Chemometrics and intelligent laboratory systems},
  volume={2},
  number={1-3},
  pages={37--52},
  year={1987},
  publisher={Elsevier}
}

@article{rydning2018digitization,
  title={The digitization of the world from edge to core},
  author={Rydning, David Reinsel-John Gantz-John and Reinsel, J and Gantz, J},
  journal={Framingham: International Data Corporation},
  volume={16},
  year={2018}
}

@article{lipkus2001general,
  title={General performance on a numeracy scale among highly educated samples},
  author={Lipkus, Isaac M and Samsa, Greg and Rimer, Barbara K},
  journal={Medical decision making},
  volume={21},
  number={1},
  pages={37--44},
  year={2001},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}
@article{hey2004data,
  title={The data, information, knowledge, wisdom chain: the metaphorical link},
  author={Hey, Jonathan},
  journal={Intergovernmental Oceanographic Commission},
  volume={26},
  number={1},
  pages={72--94},
  year={2004}
}

@inproceedings{law2020characterizing,
  title={Characterizing automated data insights},
  author={Law, Po-Ming and Endert, Alex and Stasko, John},
  booktitle={2020 IEEE Visualization Conference (VIS)},
  pages={171--175},
  year={2020},
  organization={IEEE}
}

@article{sacha2014knowledge,
  title={Knowledge generation model for visual analytics},
  author={Sacha, Dominik and Stoffel, Andreas and Stoffel, Florian and Kwon, Bum Chul and Ellis, Geoffrey and Keim, Daniel A},
  journal={IEEE transactions on visualization and computer graphics},
  volume={20},
  number={12},
  pages={1604--1613},
  year={2014},
  publisher={IEEE}
}

@article{saraiya2005insight,
  title={An insight-based methodology for evaluating bioinformatics visualizations},
  author={Saraiya, Purvi and North, Chris and Duca, Karen},
  journal={IEEE transactions on visualization and computer graphics},
  volume={11},
  number={4},
  pages={443--456},
  year={2005},
  publisher={IEEE}
}

@inproceedings{de2017experts,
  title={Experts get me started, peers keep me going: Comparing crowd-versus expert-designed motivational text messages for exercise behavior change},
  author={De Vries, Roelof AJ and Zaga, Cristina and Bayer, Franciszka and Drossaert, Constance HC and Truong, Khiet P and Evers, Vanessa},
  booktitle={Proceedings of the 11th EAI International Conference on Pervasive Computing Technologies for Healthcare},
  pages={155--162},
  year={2017}
}

@book{ross2018basic,
  title={Basic and advanced statistical tests: Writing results sections and creating tables and figures},
  author={Ross, Amanda and Willson, Victor L},
  year={2018},
  publisher={Springer}
}

@article{taxonomy,
author = {Abraham, Charles and Michie, Susan},
year = {2008},
month = {06},
pages = {379-87},
title = {A Taxonomy of Behavior Change Techniques Used in Interventions},
volume = {27},
journal = {Health psychology : official journal of the Division of Health Psychology, American Psychological Association},
doi = {10.1037/0278-6133.27.3.379}
}

@article{PSQI,
title = {The Pittsburgh sleep quality index: A new instrument for psychiatric practice and research},
journal = {Psychiatry Research},
volume = {28},
number = {2},
pages = {193-213},
year = {1989},
issn = {0165-1781},
doi = {https://doi.org/10.1016/0165-1781(89)90047-4},
url = {https://www.sciencedirect.com/science/article/pii/0165178189900474},
author = {Daniel J. Buysse and Charles F. Reynolds and Timothy H. Monk and Susan R. Berman and David J. Kupfer},
keywords = {Sleep, sleep quality, depression, sleep disorders},
abstract = {Despite the prevalence of sleep complaints among psychiatric patients, few questionnaires have been specifically designed to measure sleep quality in clinical populations. The Pittsburgh Sleep Quality Index (PSQI) is a self-rated questionnaire which assesses sleep quality and disturbances over a 1-month time interval. Nineteen individual items generate seven “component” scores: subjective sleep quality, sleep latency, sleep duration, habitual sleep efficiency, sleep disturbances, use of sleeping medication, and daytime dysfunction. The sum of scores for these seven components yields one global score. Clinical and clinimetric properties of the PSQI were assessed over an 18-month period with “good” sleepers (healthy subjects, n = 52) and “poor” sleepers (depressed patients, n = 54; sleep-disorder patients, n = 62). Acceptable measures of internal homogeneity, consistency (test-retest reliability), and validity were obtained. A global PSQI score > 5 yielded a diagnostic sensitivity of 89.6% and specificity of 86.5% (kappa = 0.75, p ⩽ 0.001) in distinguishing good and poor sleepers. The clinemetric and clinical properties of the PSQI suggest its utility both in psychiatric clinical practice and research activities.}
}

@article{susaiyah2022RL,
  title={Deep Reinforcement Learning based Insight Selection Policy},
  author={Braz, Libio Goncalves and Susaiyah, Allmin Pradhap Singh and Petkovic, Milan and H{\"a}rm{\"a}, Aki},
  year={2022}
}

@misc{susaiyah2023opinionmining,
  title={Privacy-preserving text insight mining in a closed domain},
  author={H{\"a}rm{\"a}, Aki Sakari and Helaoui, Rim and Pandya, Abhinay Maheshbhai and Susaiyah, Allmin Pradhap Singh},
  year={2023},
  month=may # "~25",
  publisher={Google Patents},
  note={US Patent App. 17/980,003}
}

@article{susaiyah2022aberdeen,
  title={Smart Selection of Useful Insights from Wearables},
  author={Susaiyah, Allmin and H{\"a}rm{\"a}, Aki and Balloccu, Simone and Reiter, Ehud and Petkovi{\'c}, Milan},
  year={2022}
}

@article{salahuddin2020wearable,
  title={Wearable technology: are product developers meeting consumer’s needs?},
  author={Salahuddin, Mir and Romeo, Laurel},
  journal={International Journal of Fashion Design, Technology and Education},
  volume={13},
  number={1},
  pages={58--67},
  year={2020},
  publisher={Taylor \& Francis}
}

@article{devi20235g,
  title={5g technology in healthcare and wearable devices: A review},
  author={Devi, Delshi Howsalya and Duraisamy, Kumutha and Armghan, Ammar and Alsharari, Meshari and Aliqab, Khaled and Sorathiya, Vishal and Das, Sudipta and Rashid, Nasr},
  journal={Sensors},
  volume={23},
  number={5},
  pages={2519},
  year={2023},
  publisher={MDPI}
}

@inproceedings{Fey/Lenssen/2019,
  title={Fast Graph Representation Learning with {PyTorch Geometric}},
  author={Fey, Matthias and Lenssen, Jan E.},
  booktitle={ICLR Workshop on Representation Learning on Graphs and Manifolds},
  year={2019},
}