\subsection{Hard-to-Detect Malware}
\label{sec:best_and_worst} 

\input{tbl/tbl_overall_results_grouped}
\input{tbl/tbl_best_and_worst_alltogether.tex}

This section analyzes which malware classes and families pose
a greater challenge for classifiers based on static and dynamic features.
\revision{Note that our multi-class classification models are for families. 
We only use here the coarser malware class 
(e.g., virus, worm) to draw conclusions on similar families.}

Table~\ref{tbl:overallResultsGrouped} shows 
{Recall} and F1-scores for each malware class in binary and family classification respectively. 
In binary classification, the recall value is defined as the number of correctly classified samples in the class
over the total number of samples in the class.
% \footnote{
% Classes are identified by following the tags provided by AVClass2~\cite{avclass2}, which
% categorises malware into 13 classes: adware, backdoor, clicker, dialer,
% downloader, grayware, miner, ransomware, rogueware, spyware, tool, virus, and
% worm.}
The numbers differ from those in Table~\ref{tbl:overallResults} because 
Table~\ref{tbl:overallResultsGrouped} only considers the 
classification results of malware samples, 
while Table~\ref{tbl:overallResults} covers the classification of both 
goodware and malware samples (thus taking also false positives into account).

As we can see, the recall and F1 score are not uniform across all classes 
and can widely vary depending on the task and the features used. 
Static features are considerably better at detecting
downloaders, dialers, and worms. In contrast, dynamic features perform better on rogueware, miner, and ransomware. 
%While dynamic features performs better on viruses.

These results are confirmed also if we look at individual families. We show
in Table~\ref{tbl:bestAndWorst_altogether} the 10 families with the lowest accuracy in both classification tasks using static and dynamic features. 
For instance, among the 10 malware families for which the static classifier
makes more mistakes, we count four 
\emph{viruses} (i.e., file infectors) and six \emph{grayware}.
This is even more remarkable if we consider the fact that there are only
40 families of Viruses in our entire dataset.
The fact that \emph{viruses} typically append their code to benign files 
results in a wide variation in terms of static features among samples of the same family, 
and this can explain why it is hard for a 
static classifier to differentiate them from \emph{goodware} and from other
families. 
Similarly, \emph{grayware} is defined as undesirable code, which
is not outright malicious per se, therefore making it difficult to find a 
clear boundary to isolate these families. In the worst 10 families using dynamic features,  
we can observe a similar pattern: grayware and viruses dominate the list. 
Besides, adware and spyware are also among the worst families. Malware samples in each of the classes have similar behaviors. 



% For example, for the binary static model 
% (where family labels are not used in the training) 
% the lowest classification recall happens for 
% viruses (0.885), adware (0.905), and grayware (0.932), 
% where adware is a subclass of grayware.
% In addition, of the 10 famillies with lowest detection accuracy 
% using the binary static model, 6 are grayware and 4 are viruses
% (even if only 5\% of the families in $M_B$ are viruses).

% \input{tbl/tbl_binary_bestAndWorst_static}
% \input{tbl/tbl_multiclass_bestAndWorst_static}
% \input{tbl/tbl_binary_bestAndWorst_dynamic}
% \input{tbl/tbl_binary_bestAndWorst_combined}
% \input{tbl/tbl_multiclass_bestAndWorst_dynamic}
% \input{tbl/tbl_multiclass_bestAndWorst_combined}

%Let's first talk about static
%Static is difficult for grayware and virus (family and binary)
% Tables~\ref{tbl:binary_static_bestAndWorst} and~\ref{tbl:multiclass_static_bestAndWorst} 
% list the 10 malware families that
% have the lowest binary and family classification accuracy when only
% static features are used.
% All families belong to the

%Let's introduce dynamic

% The most common families mis-classified by dynamic features also include
% downloaders 

% and adware also appear in the worst
% classified list of dynamic features. Downloaders largely dominate the
% families that are most often confused with one another. This is
% understandable, as different downloaders and adwares may largely overlap in
% term of runtime behavior. 

% It is instead interesting to note that most of
% the malware families with the lowest detection accuracy have more than half
% of the dynamic features containing missing observations, as reported by the
% Feature Missing Rate (\textbf{FMR}) column In our study, \textbf{FMR}
% captures the fraction of malware samples with at least four types of
% dynamic analysis features containing missing feature values. This clearly
% underlines the negative effect of missing dynamic features over the
% precision of the classification -- which explains why, as mentioned in the
% previous Section, dynamic features are very effective in some cases but
% perform poorly on others. This is also confirmed by the difference in F1
% scores among static and dynamic features. For instance, for the worse
% families the binary classification ranges between 0.4 and 0.62 with static
% features, but remaining consistently at 0 with dynamic features .

% The only exception is \emph{gamania}, characterized by a FMR of 20\%, and yet producing 
% a low accuracy in binary classification.
% \fix{'gamania' is a trojan which steal the xxxx}
% \fix{We can add some discussion to explain why this downloader app
% is difficult to detect.} 
%On the other hand, the static binary classifier has
%perfect accuracy on one third of the families (231).

%Table~\ref{tbl:multiclass_static_bestAndWorst} shows the 10 malware families
%that are the most difficult to classify with the random forest-based family
%classifier using {the static analysis-based features}.  These are the families
%with the highest family misclassification rates.  Similar to the binary
%classification, viruses and grayware still dominate in the most
%hard-to-classify malware families. As discussed above, most virus and grayware
%samples are composed by a mix of benign and malicious codes. Therefore, it is
%difficult to find a clear boundary separating these families from other malware
%families.  

%Dynamic performance
% When focusing on the performance scores, we observe different behaviors compared 
% to the static results. Worst predicted families have a much lower accuracy when
% considering dynamic features for both binary and family classification. In the
% latter case, all of the samples of the listed families are misclassified to other
% families. Each of these families has missing feature values, marked as NULL or
% NA, in at least 4 of the 7 dynamic features of over 80\% of the malware
% samples. More specifically, the top 10 families listed in
% Table.\ref{tbl:multiclass_dyn_bestAndWorst} are the families \emph{salgorea},
% \emph{kuluoz}, \emph{winwebsec}, \emph{kraddare}, \emph{umbra}, \emph{unruy},
% \emph{bandit}, \emph{convagent}, \emph{coins} and \emph{lazy}. 
% In each of the families, there are 60\%, 99\%, 80\%, 68\%,
% 100\%, 97\%, 98\%, 100\%, 99\% and 98\% of malware samples with at least 4
% dynamic feature classes containing NULL / NA feature values. The results confirm
% that high missing feature rate brings significant drop to malware classification
% accuracy. The empty-valued feature vectors lead to the failure of classification
% over malware samples of these families. These 10 families are dominated by
% \emph{trojans}, which typically need to connect external C\&C.  Most probably the
% server was unreachable during our analysis resulting in missing features,

% \fix{We need to discuss why there is no overlap between dynamic and static}

%A note of the combined models
% Moreover, Tables~\ref{tbl:binary_combined_bestAndWorst} and~\ref{tbl:multiclass_combined_bestAndWorst} 
% report the top-10 mispredicted families when combining static and dynamic
% features. We observe such a list mainly overlapping with the worst-predicted
% families of the static case (Tables~\ref{tbl:binary_static_bestAndWorst} 
% and~\ref{tbl:multiclass_static_bestAndWorst}), suggesting that static features
% might be dominant when combined with dynamic ones. We will come to this aspect
% later in the manuscript when analysing the feature contribution in
% \S\ref{sec:feature_classes}.

% Finally, we study to which extent the presence of off-the-shelf packers and 
% protectors harms the classification accuracy.

% In each of the previous tables the column \emph{Packed} provides the fraction 
% of packed malware samples in each family. 
% While one might expect a high correlation 
% between packing and misclassification rate in static-analysis-based
% models, we find that most of the 10 families have low packing percentages, i.e.
% on average 20\%. For models that employ static features, the category of a family
% (e.g., \emph{virus}, \emph{graywares} ) seems to have more significant impact over the
% classification performance.  A possible explanation could be that in the static-analysis
% based feature space, the intra-class difference between malware samples
% belonging to the same family is much less than the inter-class difference
% between malware and goodware, and among different families. As a result, even if some 
% of samples may be packed, the gap between intra-class and inter-class samples 
% is still large enough to provide accurate classification. 

% On the other hand, packing presence is significantly
% higher when looking at the worst classified families with dynamic-analysis-based
% models. In this respect, a higher fraction of packed files together with the missing feature values 
% have a not-negligible negative impact over the classification accuracy. 
% Malware may hide its payload or remain inactive in dynamic analysis due to
% evasive techniques, failure of connection to C\&C servers, or lack of actions triggering malicious payloads.
% The missing feature values in the derived run-time behaviour feature
% representation inject artefacts into training / testing of the binary and family
% classifier, which eventually increases the misclassification rate. 

%\yufei{Shall we also explain why salgorea and kraddare have 0 classification
%accuracy? They don't have that high feature missing rates as the other 8
%families, but still suffering from very bad classification performances.}

% \sav{Need explanation here and a clarification. Can it be that there are other
% families that are not listed with a lower percentage of packing but still 0
% accuracy?}

\summary{6}{Models employing static features find it more difficult to classify
\emph{grayware} and \emph{viruses}. 
Dynamic features can identify ransomware, spyware, and adware as malware, but they
have great difficulty in properly identifying their families, probably due to 
very similar runtime behaviors of different families in these classes.}

