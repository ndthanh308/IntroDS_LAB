\section{Experimental study} \label{sec:experimental}

This section presents the results of the experiments we conducted to answer the
research questions presented in the introduction.
We have adopted the following structure for ease of reading: 
the reader will find the discussion to \rques{x} in Section~\ref{sec:experimental}.x 
and a summary with the answer \aques{x} at the end of each subsection.

% This section presents the results of the experiments we conducted to answer the
% research questions introduced in Section~\ref{sec:introduction}. We start by
% presenting the overall binary and family classification results when the models
% are trained using static, dynamic, and combined features
% (\S\ref{sec:classification-results}).
% We then measure the impact of 
% missing feature values in dynamic analysis 
% (\S\ref{sec:eval-missing}) and
% the use of packing and protectors by attackers
% (\S\ref{sec:eval-packing}).
% Next, we then analyze which
% families are the most difficult to identify in each case
% (\S\ref{sec:best_and_worst}).
% % and rank
% %the most contributing feature classes for each task
% %(\S\ref{sec:feature_classes}). 
% In \S\ref{sec:dataset_construction} we
% turn our attention to study to
% what extent the number of families and samples used in the training phase
% influence the classifier performances.
% Finally, we look at how well the ML models generalize when tested on
% previously-unseen data (\S\ref{sec:singleton_and_unseen}).
% % and at the correlation between ground-truth confidence and model performance
% % (\S\ref{sec:avClass-confidence}).

\input{tbl/tbl_overall_results}

\subsection{Overall Classification Results} 
\label{sec:classification-results}

In this section, we examine
% address part of the research questions in \rques{1}, answering 
how static, dynamic, and combined features impact
binary and family classification.
\revision{We first discuss the results using Random Forest and then 
discuss the XGBoost results.
% whether the presence of off-the-shelf packers / protectors harms
% the classification accuracy.
% on which families does each model fail to produce accurate classification? 
% Do missing feature values in the run-time behaviours bring negative impact 
% to the classification results?
Table~\ref{tbl:overallResults} summarizes the accuracy results 
% for the three feature sets 
using Random Forest.} 
%.
The results correspond to the uniform dataset construction approach. 
Each line in the table reports the averaged precision, recall, and F1 score of 
10-fold cross validation. 
It also reports the fraction of malware families with 100\%
family-wise accuracy.
In binary classification, 100\% family-wise accuracy for a family
denotes that the family can be perfectly differentiated from goodware.
% in the cross-validation test. 
In family classification, 100\% family-wise accuracy instead means that 
samples from a malware family are not misclassified as another malware family.
%
%Each line in the table corresponds to a 10-fold cross validation of 
%5 balanced datasets, i.e., an average of 50 models.

% As expected, our results confirm that binary classification is easier 
% than family classification, resulting in F1-scores 8.3\%--26.2\% higher and 
% the number of families with 100\% accuracy being 2--3 times higher.
% \platon{This comparison feels a bit weird. We also mention it in the summary but
% I am not sure our experiments are appropriate to confirm that binary classification is easier or not from family classification?}
The static features achieve a higher F1 score than the dynamic features 
in both binary and family classification.
However, the fraction of perfectly classified malware families is higher 
for dynamic features, suggesting that  
dynamic features work very well for some malware families, but poorly on others.
%
The combination of static and dynamic features brings 
marginal improvements in F1 score over static-only features. 
It improves it by 1\% for family classification, 
but decreases it by 2\% for binary classification.
On the other hand, adding dynamic features increases the 
percentage of perfectly classified families over the static case, 
although for binary classification the fraction reduces compared to 
dynamic-only features.
%
The accuracy reduction with more features might seem counter-intuitive,
but it can happen when the two feature sets are not independent and
bring different strengths and weaknesses that lead
to mistakes on different parts of the input space. It is well known as the curse-of-dimensionality in machine learning \cite{Trunk1979pami}. 
Adding more features does not necessarily improve the overall accuracy,  more features may bring unexpected variance and noise into the classification module \cite{Lip2012}. %\leyla{I would put a citation here and mention that this is a wellknown phenomenon in the ML field. I removed Platon's comment, as this would answer his question}
% However, the boosting effects of feature fusion depends on the quality of
% individual feature representations over particular malware samples.  
% If two feature sets have large gap of classification accuracy over a malware sample,
% simply combining both may not be able to produce better results than using one
% single feature set alone, explaining why the F1 score can decrease in the combined
% models when both static and dynamic features are employed.
% Note that the combined accuracy can decrease 
% when two feature sets (static, dynamic) have a large gap of classification 
% accuracy over a malware sample.
%
%\platon{Why the reason of the negative impact provided above does not have 
%the same impact for family classification too?}

Our results may raise concerns about the value of dynamic analysis. 
On the one hand, dynamic features outperform static features for a 
fraction of families, significantly raising the number of perfectly classified 
families (e.g., nearly doubling it for binary classification).
This confirms the value of dynamic analysis, for example when researchers are interested 
to build behavioral signatures for specific malware families. 
%
On the other hand, the overall impact of adding dynamic features 
to static features is unclear. 
This might be the consequence of malware families for which dynamic features
do not work well, because of intrinsic properties of the 
malware family (or malware class), 
but also because the sandbox might fail to stimulate samples adequately 
(e.g., due to evasion techniques or to the lack of a live 
command-and-control server). 
% We will investigate these aspects in more details in the following sub-Sections.
% Is it worth it to develop and run a full sandbox
% to get those advantages?}
%
\revision{Adding dynamic features to the models may still provide other 
benefits. 
For example, recent work has shown that dynamic features are preferred 
by humans for interpretability~\cite{AonzoUsenix2022}. 
Furthermore, dynamic features can increase the robustness of the model, 
making it more resilient to obfuscations designed to hamper static analysis.}

\input{tbl/tbl_xgboost}

\paragraph{XGBoost.}
\revision{Table~\ref{tbl:overallResultsXGboost} shows the classification 
results using XGBoost for static and dynamic features.
The results correspond to the uniform dataset construction approach 
and 10-fold cross validation.
%
Similar to Random Forest, 
the static features achieve higher F1 score than the dynamic features 
in both binary and family classification, 
although the advantage of static over dynamic is smaller in this case.
%
Compared to Random Forest classifiers, 
XGBoost classifiers have lower F1-score for 
both binary classification (4.4\% lower) and
family classification (8.2\% lower).
%
We failed to run XGBoost on the combined features 
due to XGBoost's higher memory consumption, 
which becomes a bottleneck given the large number of features (roughly 100k)
in the combined model. Although the marginal contribution of a combined feature
set was shown by using a single architecture, we point out that the combined analysis 
is in nature a feature-level information fusion whose utility is not dependent on the
classifier architecture but on how complementary the two feature sources are
between each other.
%
Since Random Forest classifiers have higher accuracy, 
and they also run faster than XGBoost classifiers
while consuming less memory, 
we use Random Forest classifiers in the rest of our evaluation.
}

\paragraph{Time-aware experiments.}
\revision{To avoid the temporal bias that cross-validation may introduce,
Pendlebury et al.~\cite{tesseract} suggested to split training samples
into temporal bins.
However, since our dataset only contains 100 samples per family, 
the individual bins would be too small and thus we decided to not perform temporal binning.
Instead, in Section~\ref{sec:singleton_and_unseen} 
we perform a separate out-of-distribution (OOD) evaluation 
with unseen families and singletons not present in the training dataset,
which addresses the main bias that cross-validation introduces.}

\summary{1}{
For both binary and family classification tasks,
models trained on static features alone provide
higher accuracy than the models trained only on dynamic features.
The latter is able to perfectly classify more families, 
but perform poorly on others, producing an overall lower 
classification accuracy.

Adding dynamic features on top of the 
static features brings marginal \revision{accuracy} improvement 
for family classification 
and even negatively affects binary classification.
\revision{On the other hand, dynamic features may offer benefits for 
model robustness and interpretability.}
}
