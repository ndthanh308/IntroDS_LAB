\subsection{Impact of Ground Truth Confidence}
\label{sec:eval-avclass}

% We use \avclass as the source of family labels for our dataset. 
To assign a family to a sample 
\avclass computes a list of (tag, confidence) pairs,
e.g., (FAM:sality, 5), (CLASS:virus, 4), (FAM:zpevdo, 1).
%
Then, it selects as family the highest confidence tag 
that is either a family in its taxonomy or 
an unknown tag not in its taxonomy.
% i.e., (FAM:sality,5) in the example.
%
The confidence score roughly represents the number of AV engines that 
assign a tag to the sample, after accounting for aliases and 
discounting groups of AV engines that copy their labels.
%
% There may be cases where a sample has multiple family tags with 
% close confidence and in those cases perhaps the wrong family is selected.
This section examines whether the \avclass confidence score 
for the selected family impacts the classification accuracy. 

To examine this issue, we first compute the confidence score for each family. 
For each sample, we obtain a normalized confidence in the [0,1] range
by dividing the confidence score of the assigned family 
over the sum of the confidence scores for 
all family and unknown tags for the sample.
In the case above, this step returns 0.83 as the \emph{FAM:sality} confidence 
was 5, but \emph{FAM:zpevdo} also appeared in the output.
Then, we average the normalized confidence factor across all samples 
in the family to produce a family confidence score.

Next, we compute the correlation between the 
family-wise classification accuracy and the family confidence score.
The hypothesis is that higher family confidence scores correlate with 
higher family classification accuracy, 
i.e., the more agreement AV engines have when tagging the sample, 
the easier it should be to classify the sample. 
%
The Pearson correlation coefficient is  
0.083 for static features (p-value 0.03) 
and 0.062 for dynamic features (p-value 0.01). 
The correlation is positive but extremely small. Thus,
we can conclude that 
poor family classification is not influenced by 
a low \avclass confidence score and the result is statistically
significant.
%
This is further confirmed by examining the 10 families with the lowest 
classification accuracy using either static-only or dynamic-only features (Table~\ref{tbl:binary_static_bestAndWorst} and Table.\ref{tbl:binary_dyn_bestAndWorst}). 
Of those 20 families, all have a confidence score above 0.5 and 
15 have a confidence score above 0.8.
%
This suggests that even when the AV engines do not fully agree on the name 
of a sample, the majority vote likely selects the correct family, 
which provides further confidence on our \avclass-based 
ground truth generation approach. 

\summary{4}{The accuracy of family classification is not correlated 
    with the \avclass confidence score, which captures the agreement
    between different AV vendors on the family name of a sample.
    This observation supports that AVclass2 is a valid tool for getting ground 
    truth when it is necessary to obtain the family name of malware.
} 

% Table~\ref{tbl:multiclass_static_avClassConfidence} provides the AVClass confidence scores of the 10 families that have the lowest family classification accuracy using the static analysis-based features. These are the families that are most easy to be misclassified to other families. We can find some of them, e.g. "gendal", "dumpex, "pasta", "cobra" and "bifrose" have AVClass confidence scores higher than 80, yet producing low family classification accuracy. We observe that these 5 families also have 28\% to 60\% samples packed in our dataset. The packing operation can make the static analysis-based features less useful for differentiating different families. 

%\centering
%	% Figure removed
%	\caption{AvClass2 confidence score vs family-wise accuracy using static analysis features.}
%  \label{fig:avClassConfidenceVsCorrectness}
%\end{figure}

%% Figure environment removed

%\input{tbl/tbl_avClassConfidence_correlation.tex}
%\input{tbl/tbl_avClassConfidence_correlation_dyn.tex}

%Figure.\ref{fig:avClassConfidenceVsCorrectness} and Figure.\ref{fig:avClassConfidenceVsCorrectness_dynamic} visually illustrate the correlation between the AVClass confidence scores and the family classification accuracy scores per family using static and dynamic analysis-based features. As shown in both plots, the family-wise classification accuracy is roughly proportional to the AVClass confidence score of the corresponding malware families. The proportion relation echoes our expectation over the correlation between AVClass confidence and ML-driven classification accuracy. 

%Table~\ref{tbl:multiclass_dynamic_avClassConfidence} shows the AVClass confidence scores of the worst classified 10 families using the dynamic features, following the settings of Table~\ref{tbl:multiclass_static_avClassConfidence}. 
%The AVClass confidence scores of these 10 families are between 50 and 100. Especially "contenedor", "umbra", "kovter", "bancos", "cobra" and "winner" have AVClass confidence scores higher than 85. According to Table.8, these families also have high feature missing rates, i.e. the feature missing rates all higher than 0.7. As a large fraction of behavioural features are missing in these families, the Random Forest-based classifier can not produce accurate classification results over them. In this case, the AVClass confidence score can not be used as an indicator of the family classification performance. 

%In general, it shows similar observations as in Figure~\ref{fig:avClassConfidenceVsCorrectness}: higher AvClass confidence scores indicate more accurate  classification. In exception, there are three families whose AVClass2 confidence scores are greater than 98\%, yet the corresponding detection accuracy over these families is generally less than 33\%. Two of them are file infectors (alman~\cite{alman} and sality~\cite{sality}), while dumpex is a X 
%\yufei{explanations: why they have high AvClass confidence yet low acc.}

%% Figure environment removed

