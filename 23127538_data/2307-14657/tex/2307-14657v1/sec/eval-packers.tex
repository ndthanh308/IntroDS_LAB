\subsection{Impact of Packers and Protectors} \label{sec:eval-packing}
This section evaluates whether the presence of off-the-shelf packers and
protectors harms the classification accuracy when considering static features.
%
\revision{Our dataset comprises real malware collected from a commercial feed, 
so we expect the fraction of packed samples to approximate that in the wild. 
Overall, we identified 
119 unique known packers, including 
highly sophisticated ones like VMProtect and Themida, covering 22\% of the samples
in our dataset.
However, this ratio is certainly a lower bound as packer detection tools may not identify 
custom packers. 
Tables~\ref{tbl:binary_static_bestAndWorst}--\ref{tbl:multiclass_dyn_bestAndWorst}
show that the packing rate largely varies per family: some have
99\% of their samples packed while others have none. 
As explained in Section~\ref{sec:features-static}, 
we did not attempt to unpack samples, 
but follow prior work in extracting static features regardless of whether a file 
is packed or not. The packer information is only used for the analysis of the results.}

We first investigate whether the models overfit the packers
or instead can capture data that allows
them to classify samples correctly.
To answer this question, we first compute the family-wise classification
accuracy for both binary and family classification using static features.  We
then compute the Pearson correlation scores between the family-wise accuracy
scores and the rate of packed samples in each family.  If packing negatively
affects the ability to classify a sample, we would expect lower accuracy for
families where packing is more prevalent.
%
However, the correlation scores are 0.015 and 0.0001 respectively for binary 
and family classification. To statistically support these results, we run a T-test 
with the null hypothesis being that there is not a significant correlation 
between classification accuracy and packing presence. We respectively obtain
0.51 and 0.98 as p-values that do not allow us to reject the null hypothesis.
Thus, we conclude that there is not a statistically significant correlation 
between the two variables.
% % For family classification, the correlation score is $10^{-4}$ and the
% p-value is 0.98. So again, we can conclude that the family classification is
% not correlated with the packing rate. 
%
% We also compute the correlation on a per-sample base.  We first obtain two
% vectors.  One vector has whether each sample is predicted correctly and the
% other whether the sample is packed.  For the static features, the correlation
% between both vectors is 0.75 and there is no statistically difference between
% the mean of the two vectors using the t test.  The p-value of is
% 1.28779356e-13, which confirms the null hypothesis.
%
% The results show that packing rate of a family is not significantly correlated
% with its classification accuracy.
This might seem surprising, as one might expect a high correlation between
packing and misclassification rate at least for models that rely only on static
features. After all, packing was one of the main reasons that led researchers to
introduce malware analysis sandboxes and dynamic analysis.  However, this is a
common misconception. In fact, while packing is very effective at impeding
static \textit{analysis} (i.e., the ability to examine a sample and statically
derive its behavior), other works~\cite{aghakhani2020malware} have shown that
common packers leave certain areas of the binary untouched, thus having a
limited effect on the ability of a ML \textit{classifier} to identify a sample.
%
\revision{While our static models seem capable to detect samples 
protected with off-the-shelf packers, 
newer protectors can be designed to specifically target static models. 
Also, it is possible that some of the hard-to-detect families use 
(undetected) custom packers that indeed hamper the detection.}

\input{tbl/tbl_binary_and_multiclass_packed_and_not_packed_featImportance}

\revision{To understand which static features are more effective at  
identifying packed malware, 
we compute the importance of the feature classes separately for two sets: packed samples on one side 
and unprotected (i.e., not packed) samples on the other.
Table~\ref{tbl:binary_and_multiclass_packed_only_FeatImportance} 
summarizes the results for both binary and family classification. 
The \emph{All} column captures the feature importance for all samples 
(regardless of packing) and thus matches the values already reported in 
Table~\ref{tbl:binary_and_multiclass_FeatImportance}. 
%
The results show that for both binary and family classification of packed samples, 
the relative importance of \emph{s-bytegrams} increases significantly 
(compared to all samples) and 
there are also relevant increases in the importance of 
\emph{s-sections}, \emph{s-headers}, and \emph{s-dll}. 
On the other hand, the relative importance of \emph{s-opcodegrams} and
\emph{s-imports} is greatly reduced.}

\revision{This is likely due to the fact that much of the code in packed samples is compressed or 
encrypted, reducing the amount of useful opcodes that can be extracted statically to those in the unpacking routine. 
On the other hand, raw bytegrams are still able to capture distinctive 
sequences of bytes, which may act like signatures for the packed samples. 
Those sequences can be extracted from parts of the executable that 
are not code (e.g., PE header and data sections).
The classifier focusing on those parts for packed samples would also 
explain the increased importance of \emph{s-sections}, \emph{s-headers}, 
and \emph{s-strings}.
In addition, some packers use weak encryption schemes based on XOR operations with a fixed 
key, which may make distinctive byte sequences in the unpacked code to still 
be distinctive (in their encrypted form) in the packed executable.
%
The decrease in importance for \emph{s-imports} is likely linked to 
packers obfuscating the import table. 
Finally, most packers leave a very reduced import table that 
tends to use the same Windows libraries, 
which could explain the slight increase for \emph{s-dll}.
}

% \sav{Need to find a better way to explain here as we discussed yesterday. One 
% could be that those classes gain importance and provide for s-opcodegrams.
% Indeed we verified manually some strings which are also reported in the
% repository and some of them are present in the top 100 for all the experiments
% thus making them powerful also if the binary is packed}

% Alternatively, this could indicate that signature-based packing detection
% approaches are not able to detect all packed samples.

\summary{3}{ Packed or protected samples (with off-the-shelf tools) do not
significantly correlate with their classification accuracy using static
features.  This means that although these technologies function well to deter
static analysis (in particular reverse engineering), 
they do not significantly affect
ML classifiers, \revision{which are still able to successfully identify byte-level signatures}.}
