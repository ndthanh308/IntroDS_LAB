\section{Dynamic Results}
\label{sec:dynamic}


\subsection{The Results of Malware Family and Binary Classification without Preprocessing}
\noindent \textbf{Binary Classification.} A 500-tree \textit{Random Forest}-based classifier is built over the positive and negative data to achieve binary classification. The output from the classifier is to decide whether a sample is malicious (positive class) or benign (negative class).  To balance the training set, we inherit the same setting of training and testing data split in the test using statistical analysis features, as given in Section 4.1. The true positive rate (TPR), true negative rate (TNR), false negative rate (FNR) and false positive rate (FPR) of the detection results over the testing data are 0.9528, 0.9479, 0.0472 and 0.0521 respectively. We provide Precision, Recall and F1-score of the detection result in Table.\ref{tbl/tbl_binary_accuracy_dynamic}. 




%% Figure environment removed

%% Figure environment removed

%Figure.\ref{fig:binaryclassF1} and Figure.\ref{fig:binaryclassAcc} give the \textit{F1} score and \textit{Accuracy} scores of the binary classification task obtained with different combinations of $K$ and $M$.

%% Figure environment removed

%% Figure environment removed


\noindent \textbf{Family Classification.} Theoretically, increasingly more classes in building a machine learning classifier augments the difficulty of learning accurately the boundaries between different classes. We empirically observe the impact of the varying number of malware families over the classifier accuracy. We randomly select $K$ out of 670 families, where $K$ ranges as 70, 170, 270, 370, 470, 570 and 670. Given each level of the number of families, we repeat the family sampling step for $N$ rounds. For $K\geq{450}$ and $K<{450}$, we set $N=5$ and $N=15$ to provide as comprehensive as possible coverage the families in the dataset. Furthermore, freezing the value $K$, we randomly choose $M$ out of 100 malware samples per family as the training data. The rest $100-M$ malware samples are considered as the testing instances. We start from $M=100$ and gradually decrease $M$ as $M$=80,70,60 and 50, to demonstrate whether the varying number of training samples would bring significant changes to the resultant multi-class classification accuracy. 

%We provide the F1-score results with different settings of $N$ and $M$ using \textit{Random Forest}, \textit{GradientBoosted Trees} and \textit{2-layered Neural Network} with ReLU activation nodes in Figure.\ref{fig:multiclassF1rf}, Figure.\ref{fig:multiclassF1gbt} and Figure.\ref{fig:multiclassF12nn} respectively. The value and the varying tendency of the accuracy scores are close to those of the F1-scores. We thus choose to show the F1-score results without loss of clarity. 

We provide the \textit{F1} score and \textit{Accuracy} score results with different settings of $K$ and $M$ using \textit{Random Forest} in Figure.\ref{fig:multiclassF1_prep}. We leave the accuracy scores derived with different $K$ and $M$ in Figure.\ref{fig:multiclassAcc_prep}, given in the appendix.  

% Figure environment removed

%% Figure environment removed

%% Figure environment removed

%% Figure environment removed


%\subsection{The Results of Family and Binary Classification with Preprocessing}

%Instead of randomly selecting $K$ families, we perform the preprocessing of feature completeness check. We rank the families by the average level of missing observation per family and choose the top $K$ families with the most completed feature observations for family and binary classification. In each of the selected family, we choose $M$ malware samples to build the malware training / testing data. For the convenience of comparative study, we inherit the same settings of $K$ and $M$ in the family classification task from Figure.\ref{fig:multiclassF1} and Figure.\ref{fig:multiclassAcc}. For the binary classification task, we use the same settings from Figure.\ref{fig:binaryclassF1} and Figure.\ref{fig:binaryclassAcc}. In the followings, Figure.\ref{fig:multiclassF1_prep} and Figure.\ref{fig:multiclassAcc_prep} provide the heatmaps of \textit{F1} and \textit{Accuracy} score of the family classification task with the preprocessing step to exclude the families with a high level of missing observations in the feature vectors.  Figure.\ref{fig:binclassF1_prep} and Figure.\ref{fig:binclassAcc_prep} provide the heatmaps of \textit{F1} and \textit{Accuracy} score of the binary classification task. By comparing the classification performances with and without the feature completeness check, we can find that performing classification tests over the families of the most completed features produces significantly better classification performances than randomly selected families with more missing features. The results show the completeness of dynamic analysis features is important to build accurate ML-based classification models. As a data-driven method, ML-based classifiers are designed to capture statistical correlation between features and the expected output, e.g. the predicted class labels. The existence of missing features lead to loss of the statistical correlation and make the trained classifier unstable and inaccurate. 

 
%% Figure environment removed

%% Figure environment removed


%% Figure environment removed

%% Figure environment removed

\subsection{The Results of Binary Classification over Singletons and Unseen families}
We choose the most complete 170 families of malware samples as the positive training set in the binary classification test, which considers the trade-off between feature completeness and coverage of malware families. We train a binary classifier using the samples of the 170 malware families and 10,697 benignwares, following the definition of the training dataset given in the classification experiment setup. Once it is obtained, we apply the binary classifier over the singletons and unseen families to evaluate the detection accuracy. It is worth noting that all the singletons are malware. Same as the unseen families, the malware campaigns of the singletons never appear in the training dataset of the classifier. We thus aim to measure the out-of-distribution (OOD) performance of the classifier. We repeat the sampling of the training data for 5 times and report the averaged detection accuracy. As a result, the average accuracy score is 97.74\% over singleton files with the standard deviation of 0.08 and 98.23\% over unseen families with the standard deviation of 0.10 respectively 

\subsection{The Results of Family Classification over Singleton and Unseen families}
We are unable to measure the family classification accuracy over the singletons and malware of unseen families. No ground truth family labels of these testing samples are given by AVClass. However, we find that the uncertainty level of the family classification output over the out-of-distribution testing malware samples increase significantly, compared to those derived with the testing samples sharing the same families of the training data. To measure the uncertainty difference, we define Relative Entropy Score (RES) as below: 
\begin{equation}\label{eq:RES}
RES = \frac{\sum_{k=1}^{C} p_{k}\log{p_{k}}}{ \sum_{k=1}^{C} 1/C\log{1/C}}
\end{equation}
where $C$ is the number of the families covered by the training data building the classifier. In this experiment, as we choose the most complete 170 families of malware samples to train the family classifier, $C$ is therefore set to 170 in Eq.\ref{eq:RES}.  For a sample of singletons / unseen families, the output of the family classifier is a 170-dimensional probability-valued vector $\{p_{k}\}$ (k=1,2,3,...,C). Each $p_{k}$ gives the probabilistic confidence that the sample belongs to the corresponding family.  By definition, the numerator $\sum_{k=1}^{C} p_{k}\log{p_{k}}$ provides the entropy of the classifier's output. The denominator $\sum_{k=1}^{C} 1/C\log{1/C}$ denotes the maximum entropy that the classifier's classification output may have. More specifically, the denominator gives the entropy achieved if every class has uniformly the same decision confidence. As a result, the magnitude of RES is strictly normalized between 0 and 1. Higher/Lower RES denotes that the classifier shows higher/lower uncertainty level over the classification output. Instead of using the entropy directly, we introduce RES is to reflect the relative uncertainty level of the classification output, compared to the uniformly random classification output. The value range of the vanilla entropy is unbounded and increases / decreases globally as the number of the families $C$ becomes bigger / smaller. The normalized value of RES is hence used to set up a fair comparison of the uncertainty levels of the classifiers built with different number of malware families. 

Over the singleton malware samples, the average, median and variance of the RES scores are 0.46, 0.49 and 0.18. On the malware samples of unseen families, the average, median and variance of the RES scores are 0.56, 0.62 and 0.19 respectively. 




%There are 18 families, namely \textit{dumpex}, \textit{ruskill}, \textit{bulz}, \textit{refroso}, \textit{stop}, \textit{conduit}, \textit{tweakbit}, \textit{malmaker}, \textit{umbra}, \textit{lassorm}, \textit{utorrent}, \textit{kuaizip}, \textit{installtoolbar}, \textit{hckpk}, \textit{zlob}, \textit{guloader}, \textit{sabsik}, and \textit{spigot} that the multi-class classifier can't correctly categorise at all in the classification test.

 
%In addition in Figure.\, we also illustrate the F1-score results derived by applying \textit{Random Forest} over the time-series-based representation of the dynamic analysis traces. 

%% Figure environment removed
