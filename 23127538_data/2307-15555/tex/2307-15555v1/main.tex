\documentclass[runningheads]{llncs}
\usepackage{amsmath,graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage[capitalise, noabbrev]{cleveref}
\usepackage{glossaries}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{flushend}
\usepackage{enumitem}
\usepackage{siunitx}

\newacronym{tts}{TTS}{Text-To-Speech}
\newacronym{vc}{VC}{Voice Conversion}
\newacronym{asv}{ASV}{Automatic Speaker Verification}
\newacronym{la}{LA}{Logical Access}
\newacronym{fd}{FD}{First Digit}
\newacronym{stlt}{STLT}{short-term long-term}
\newacronym{svc}{SVC}{Support Vector Classifier}
\newacronym{rf}{RF}{Random Forest}
\newacronym{mfcc}{MFCC}{Mel-Frequency Cepstral Coefficient}
\newacronym{fc}{FC}{Fully Connected}
\newacronym{roc}{ROC}{Receiver Operating Characteristic}
\newacronym{auc}{AUC}{Area Under the Curve}

\begin{document}
 
\title{All-for-One and One-For-All: \\Deep learning-based feature fusion \\for Synthetic Speech Detection}
\author{Daniele Mari\inst{1}\orcidID{0000-0003-0727-3725} \thanks{This work was partially supported by the European Union under the Italian National Recovery and Resilience Plan (NRRP) of NextGenerationEU, partnership on “Telecommunications of the Future” (PE00000001 - program “RESTART”). Daniele Mari's activities were supported by Fondazione CaRiPaRo under the grants “Dottorati di Ricerca” 2021/2022.}
\and
Davide Salvi\inst{2}\orcidID{0000-0002-5163-3364} \and \\
Paolo Bestagini\inst{2}\orcidID{0000-0003-0406-0222} \and
Simone Milani\inst{1}\orcidID{0000-0001-8266-5839}}
\authorrunning{D. Mari et al.}
\titlerunning{Deep learning-based feature fusion for Synthetic Speech Detection}
\institute{University of Padova - Padova, Italy
\and
Politecnico di Milano - Milan, Italy\\
\email{\{daniele.mari, simone.milani\}@dei.unipd.it}\\ 
\email{\{davide.salvi, paolo.bestagini\}@polimi.it}
\\
}
\maketitle              
\begin{abstract}
Recent advances in deep learning and computer vision have made the synthesis and counterfeiting of multimedia content more accessible than ever, leading to possible threats and dangers from malicious users.
In the audio field, we are witnessing the growth of speech deepfake generation techniques, which solicit the development of synthetic speech detection algorithms to counter possible mischievous uses such as frauds or identity thefts.
In this paper, we consider three different feature sets proposed in the literature for the synthetic speech detection task and present a model that fuses them, achieving overall better performances with respect to the state-of-the-art solutions.
The system was tested on different scenarios and datasets to prove its robustness to anti-forensic attacks and its generalization capabilities.

\keywords{Audio Forensics, Speech, Deepfake, Feature Fusion}
\end{abstract}

\input{1_introduction}
\input{2_method}
\input{3_experimental_setup}
\input{4_results}
\input{5_conclusion}

\bibliographystyle{splncs04}
\bibliography{refs}

\end{document}
