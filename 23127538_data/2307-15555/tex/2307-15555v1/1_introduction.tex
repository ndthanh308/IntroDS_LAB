\section{Introduction}
\label{sec:intro}
\vskip -0.5ex
Recent developments in deep learning techniques and the increased availability of computational capabilities have made the generation and editing of multimedia content within everyone's reach.
While technological advances open the door to new possibilities~\cite{arstechnica}, their malicious utilization can produce severe consequences~\cite{bbcnews}.
An example of this phenomenon are deepfakes~\cite{nguyen2022deep}, synthetic multimedia content generated through deep learning techniques that depict individuals in actions and behaviors that do not belong to them. 
To address this rising problem, the scientific community has focused on developing detectors capable of discerning counterfeit material from authentic one~\cite{verdoliva2020media}.

In the audio field, two main categories of fake audio generation algorithms can be found, i.e., \gls{tts}~\cite{
wang2017tacotron, ren2019fastspeech} and \gls{vc}~\cite{tanaka2019atts2s, 
kaneko2019cyclegan} algorithms.
Several approaches have been proposed to detect such forged signals~\cite{zhang2017investigation}, ranging from methods that aim at detecting low-level artifacts~\cite{monteiro2020generalized, alzantot2019deep} to others that focus on more semantic aspects~\cite{conti2022deepfake, attorresi2022prosody}.
Among these, in~\cite{mari2022sound}, the errors in the \gls{fd} statistics w.r.t. the generalized Benford law are used as input to a \gls{rf} classifier to detect fake speech. The features are computed from the \gls{mfcc} of the analyzed audio tracks. Interestingly, the authors show that these are equally discriminative when computed on the whole audio track or only on the silent parts of the signal.
At the same time, in~\cite{borrelli2021synthetic}, the detection task is performed by exploiting a set of features inspired by the speech-processing literature, which are used as input of a supervised classifier.
These features aim to model speech as an auto-regressive process, simultaneously considering multiple auto-regressive orders.
Finally, the authors of~\cite{albadawy2019detecting} discriminate real and fake speech by leveraging higher-order bispectral correlations introduced by synthesis algorithms and not typically found in human speech.
The possibility of performing speech deepfake detection based on several methods is paramount in multimedia forensics.
Each method targets different footprints among the possible traces that can reveal a potential forging in forensic analysis. Combining multiple solutions makes creating a successful and undetectable threat increasingly difficult for attackers.
Furthermore, applying heterogeneous detection techniques increases the applicability of algorithms to different scenarios.

In this paper we consider three sets of features presented in state-of-the-art for synthetic speech detection and propose a model that fuses them to perform the same task.
The features we consider are: \gls{fd} features~\cite{mari2022sound}; \gls{stlt} features~\cite{borrelli2021synthetic}; bicoherence features~\cite{albadawy2019detecting}.
Then, the fusion process is performed following a deep-learning-based approach.
We consider these features as they analyze three different aspects of the audio signal: silence, speech, and bispectral correlations.
This is relevant since, as mentioned above, it can benefit the final detection performance of the model.
The proposed system outperforms the single models, as presented in the literature, and shows excellent robustness to anti-forensic attacks and good generalization capabilities on unseen datasets.

