{
  "title": "Classifying multilingual party manifestos: Domain transfer across country, time, and genre",
  "authors": [
    "Matthias AÃŸenmacher",
    "Nadja Sauter",
    "Christian Heumann"
  ],
  "submission_date": "2023-07-31T09:16:13+00:00",
  "revised_dates": [],
  "abstract": "Annotating costs of large corpora are still one of the main bottlenecks in empirical social science research. On the one hand, making use of the capabilities of domain transfer allows re-using annotated data sets and trained models. On the other hand, it is not clear how well domain transfer works and how reliable the results are for transfer across different dimensions. We explore the potential of domain transfer across geographical locations, languages, time, and genre in a large-scale database of political manifestos. First, we show the strong within-domain classification performance of fine-tuned transformer models. Second, we vary the genre of the test set across the aforementioned dimensions to test for the fine-tuned models' robustness and transferability. For switching genres, we use an external corpus of transcribed speeches from New Zealand politicians while for the other three dimensions, custom splits of the Manifesto database are used. While BERT achieves the best scores in the initial experiments across modalities, DistilBERT proves to be competitive at a lower computational expense and is thus used for further experiments across time and country. The results of the additional analysis show that (Distil)BERT can be applied to future data with similar performance. Moreover, we observe (partly) notable differences between the political manifestos of different countries of origin, even if these countries share a language or a cultural background.",
  "categories": [
    "cs.CL",
    "cs.CY",
    "cs.LG",
    "stat.ML"
  ],
  "primary_category": "cs.CL",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16511",
  "pdf_url": "https://arxiv.org/pdf/2307.16511v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 2349220,
  "size_after_bytes": 120803
}