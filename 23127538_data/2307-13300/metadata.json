{
  "title": "Mini-PointNetPlus: a local feature descriptor in deep learning model for 3d environment perception",
  "authors": [
    "Chuanyu Luo",
    "Nuo Cheng",
    "Sikun Ma",
    "Jun Xiang",
    "Xiaohan Li",
    "Shengguang Lei",
    "Pu Li"
  ],
  "submission_date": "2023-07-25T07:30:28+00:00",
  "revised_dates": [],
  "abstract": "Common deep learning models for 3D environment perception often use pillarization/voxelization methods to convert point cloud data into pillars/voxels and then process it with a 2D/3D convolutional neural network (CNN). The pioneer work PointNet has been widely applied as a local feature descriptor, a fundamental component in deep learning models for 3D perception, to extract features of a point cloud. This is achieved by using a symmetric max-pooling operator which provides unique pillar/voxel features. However, by ignoring most of the points, the max-pooling operator causes an information loss, which reduces the model performance. To address this issue, we propose a novel local feature descriptor, mini-PointNetPlus, as an alternative for plug-and-play to PointNet. Our basic idea is to separately project the data points to the individual features considered, each leading to a permutation invariant. Thus, the proposed descriptor transforms an unordered point cloud to a stable order. The vanilla PointNet is proved to be a special case of our mini-PointNetPlus. Due to fully utilizing the features by the proposed descriptor, we demonstrate in experiment a considerable performance improvement for 3D perception.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13300",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 464961,
  "size_after_bytes": 377824
}