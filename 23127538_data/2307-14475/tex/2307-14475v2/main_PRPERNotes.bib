@FOOTNOTE{Note1,key="Note1",note="More precisely, tokens are used instead of words, which are more general sequences of letters that can be added to form words. However, they have the advantage that also unseen words in the training data can be processed."}
@FOOTNOTE{Note2,key="Note2",note="Percentages are taken from \protect \url  {https://en.wikipedia.org/wiki/GPT-3\#GPT-3.5} (last access 26 May 2023) for training GPT 3."}
@FOOTNOTE{Note3,key="Note3",note="Chat can be accessed here: \protect \url  {https://chat.openai.com/share/8ae109d2-8b71-4033-8c62-749c33c2582c}, last access: June 2023; translated with: \protect \url  {https://www.deepl.com/de/translator##de/en/})"}
@CONTROL{REVTEX42Control}
@CONTROL{apsrev42Control,author="08",editor="1",pages="0",title="0",year="1"}
