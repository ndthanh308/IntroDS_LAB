\section{Introduction}
\label{sec:Introduction}

The CAGR (compound annual growth rate) for the global gaming market is projected to be 7.7\% over the next 5
years~\cite{2022Gaming}.  This will lead to a total revenue of roughly 532.97 billion USD by 2027~\cite{2021Games}. To
provide as realistic an experience as possible, displays are supporting increasingly higher refresh rates. We have moved
from 30 Hz to 120 Hz over the last few years. Such systems help players feel fully involved in the virtual world. Given
that the human vision system is exceptionally sensitive and can sometimes detect a lag as low as 2
ms~\cite{latencyforhuman}, gamers prefer ultra-high refresh rates. For newer
head-mounted displays, latencies greater than 7 ms may result in
motion sickness and dizziness~\cite{latencyinvr}. Even for non-gamers, research has shown that an inter-frame
duration of 25 ms~\cite{latencyforperf, jota2013fast} can cause issues. They will perceive a {\em high
latency} in interactive tasks.   The only solution is to render and display frames as fast as possible.

To meet these latency requirements, display vendors have launched monitors with high refresh rates such as 120 Hz, 240
Hz and 360 Hz displays~\cite{360Nvidia,360}. Recently, Dell launched the Alienware 500Hz Gaming
Monitor. Mobile companies are also incorporating such displays into their devices.~\cite{Smartphones}. Similarly, there
are GPUs such as the NVIDIA RTX series GPUs, which can render up to 360 frames per second at 1080p resolution~\cite{gpus}.
Still users are not guaranteed to have a seamless experience because the actual frame rate depends
upon various parameters such as the frame resolution, frame complexity, etc., and it varies a lot during the application
Furthermore, if the frame rate is not synchronized with the refresh rate of the
monitor, the user may experience glitches known as screen tearing and screen stuttering~\cite{tearing_stuttering}. That
is why there exist synchronization algorithms such as G-Sync and Free-Sync~\cite{gsync_freesync} in NVIDIA GPUs
that modulate the
refresh rate to synchronize it with the frame rate and prevent screen tearing and screen stuttering. However, this is
not an ideal solution. Let us assume we have a 144 Hz monitor but the GPU is only supplying frames at 45 fps, then these
synchronization techniques reduce the refresh rate to 45 Hz, which results in an ineffective use of the monitor's
capabilities. Hence, this work aims to {\em temporally} supersample the frames for enabling the use of high refresh rate
displays.

Recent works propose two ways to increase the frame rate: spatial
supersampling~\cite{herzog2010spatio,nehab2007accelerating,yang2008geometry} and temporal
supersampling~\cite{andreev2010real, bowles2012iterative, extranet,yang2011image}. These works exploit the fact that
with the increase in image resolution, there exists a similarity between neighboring pixels in spatial and temporal
domains known as spatial and temporal coherence~\cite{herzog2010spatio}. Spatial supersampling increases the frame rate
by rendering the frames at a much lower resolution and then increases the resolution of the rendered frame before
displaying them using interpolation. On the other hand, temporal supersampling generates entirely new frames on the fly
using an already rendered frame. For temporal supersampling, there are two popular methods: \textit{Interpolation} and
\textit{Extrapolation}~\cite{extranet}. Most of the existing works including NVIDIA's latest supersampling method, DLSS
3 (Deep Learning SuperSampling)~\cite{DLSS3}, use optical flow-based interpolation to generate new frames.  The problem
with the interpolation method is that one needs to wait till the next frame is rendered to start the interpolation
(figure out all frames in between). 
This introduces an unnecessary delay leading to an increased input latency (refer to
Section~\ref{subsubsec:inter_vs_extra}), which degrades the overall performance. 
The advantage of these methods is that they cover occlusion and disocclusion steps. 

ExtraNet~\cite{extranet}, an extrapolation method for temporal supersampling, proposes a
way that does not rely on optical flow and extrapolates the new frame solely based on the past few frames. To handle
occlusion and dynamic objects, ExtraNet uses a few intermediate buffers that are generated during the rendering
process. It relies on a complex neural network to do this task; hence it is slow. Due to its significant latency, it
upsamples the frame rate only by 1.5 to 2$\times$. This work proposes \exwarp --  a faster extrapolation-based method to upsample
the frame rate further for high-frequency displays: from 30 to 120 Hz.  Our primary contributions are:\\ \circled{1} We show that two
widely used methods used for predicting frames -- warping and extrapolation -- can be combined for temporal supersampling in
real-time. \\ \circled{2} We identify a few features that define the current state of the scene, i.e., the presence of
dynamic objects and camera movement.\\ \circled{3} We propose a reinforcement learning (RL) based approach that uses
these identified features to intelligently choose between extrapolation and warping based methods to increase the frame rate
by almost 4$\times$ with an almost negligible reduction in the perceived image quality.  \\ \circled{4} We are able to
supersample the frame rate by nearly 4$\times$. We record an 18.02\% increase in the PSNR and a 6.58\% increase in SSIM
as compared to the state-of-the-art baseline, ExtraNet.

The paper is organized as follows. Section \ref{sec:Background} provides the background of VR architectures and
ML-based models.  Section \ref{sec:Characterization} shows the characterization of benchmarks. The implementation details are given
in Section \ref{sec:Implementation}. Section \ref{sec:Evaluation} shows the experimental results. We discuss related
work in Section \ref{sec:RelatedWork} and finally conclude in Section \ref{sec:Conclusion}.  
