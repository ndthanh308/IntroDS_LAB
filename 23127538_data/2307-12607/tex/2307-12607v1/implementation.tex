\section{Implementation}
\label{sec:Implementation}

\subsection{Overview}
\label{sec:overview}

We propose to insert three new frames at time instances $t+0.25$, $t+0.5$, $t+0.75$ between any two consecutive frames
$F_t$ and $F_{t+1}$. As mentioned in Section~\ref{sec:Introduction}, warping and extrapolation are two options for
synthesizing these new frames. Based on these two algorithms, multiple scenarios are possible (refer to
Figure~\ref{fig_overview}).  

%Now, we have two choices for the remaining two frames- warping and extrapolation. For the first frame $P_{t+0.25}$,
%extrapolation is not an option because if we start extrapolating frame $F_{t}$ at time $t$, the extrapolation takes at
%least $t+0.5$ time. So, the remaining choice to generate $P_{t+0.25}$ is warping $F_t$. We may use warping and
%extrapolation for $P_{t+0.75}$. If we use extrapolation, we need to finish extrapolating $P_{t+0.75}$ prior before
%$t+0.75$; we start extrapolating $P_{t+0.25}$ at time $t+0.25$. Since warping takes less time, we warp the latest frame
%$P_{t+0.25}$ instead of using $P_{t+0.5}$.

% Figure environment removed

\subsection{Problem Formulation}
\label{problem}

Given two rendered frames $F_t$ and $F_{t+1}$, our goal is to insert $n$ new frames between these two frames without
using $F_{t+1}$, where $n$ $\in$ $[1,3]$. We represent these frames as $P_i$, where $i$ falls within the interval
$[1,3]$ and the frame $P_i$ is displayed on the screen at time $t+(i/4)$.  We have two options: warping and
extrapolation.  For the ensuing discussion, please refer to
Figure~\ref{fig:flow}. We need to make a decision about which frame to display -- warped or extrapolated at three time
instants: $t+0.25$, $t+0.5$, $t+0.75$. We refer to these frames as $P_1$, $P_2$, and $P_3$,
respectively.\\

\textbf{Decision at $\mathbf{t}$}: The decision ($d_1$) at this time decides which frame to display at $t+0.25$: the
warped version of $F_t$ ($=W(F_t)$) or the last displayed frame $F_t$. The second choice would also result in the
extrapolated $F_t$ ($=E(F_t)$) being displayed at $t+0.5$. This is because the extrapolated frame would only be
available at $t+0.5$.

\textbf{Decision at $\mathbf{t+0.25}$}:  The decision at this time instant decides which frame to display at $t+0.5$. If the
outcome of $d_1$ was to extrapolate, we do not need to take any decision at this point since we display $E(F_t)$ at
$t+0.5$ as explained above. If $d_1$ chose warping, then at this point we make decision $d_2$, which chooses to display
either the warped of the last displayed frame, i.e., $W(P_1)$ or the extrapolated version of $F_t$ ($E(F_t)$).  

\textbf{Decision at $\mathbf{t+0.5}$}: We decide which frame to display at $t+0.75$. Depending
on the outcomes of the previous two decisions, there are three possible cases. First, we consider the case where $d_1$ chose
extrapolation. In this case, the decision $d_3$ decides whether to display the warped version of $P_2$ ($W(P_2)$) or just
display $P_2$ since extrapolation will not be able to generate the frame by $t+0.75$.  The other two cases are relevant
if $d_1$ chose warping. For both of these cases, decisions $d_4$ and $d_5$ choose between the warped versions
of $P_2$ ($W(P_2)$) and
extrapolated $P_1$ ($E(P_1)$). However, the frames $P_1$ and $P_2$ themselves would depend on the
decision taken at $d_2$.
Based on these decisions, six scenarios or {\em decision paths} are possible (shown in Table~\ref{tab:pos_sce}).

% Figure environment removed


\begin{table}[!htb]
\footnotesize
\begin{center}
\resizebox{0.99\columnwidth}{!}{
\begin{tabular}{| l |l | l| l| l|} 

\hline
\textbf{Scenario} &
$\mathbf{P_1}$ & $\mathbf{P_2}$ & $\mathbf{P_3}$ & \textbf{Frame rate}\\
&  &  & & \textbf{upsampling} \\ 
\hline\hline
$\mathbf{S_1}$ & $F_1$  & Extrapolated $F_1$  & Extrapolated $F_1$ & 2$\times$\\
(ExtraNet) &  (No new frame)  &  &  (No new frame) &   \\ \hline
$\mathbf{S_2}$ & $F_1$   & Extrapolated $F_1$  & Warped $P_2$ & 3$\times$ \\
 & (No new frame) &  &  &   \\ \hline
$\mathbf{S_3}$ & Warped $F_1$ & Extrapolated $F_1$ & Extrapolated $P_1$ & 4$\times$\\  \hline
$\mathbf{S_4}$ & Warped $F_1$ & Extrapolated $F_1$ & Warped $P_2$ & 4$\times$\\  \hline
$\mathbf{S_5}$ & Warped $F_1$ & Warped $P_1$ & Extrapolated $P_1$ & 4$\times$\\  \hline
$\mathbf{S_6}$ & Warped $F_1$ & Warped $P_1$ & Warped $P_2$ & 4$\times$\\
\hline
\end{tabular}
}
\end{center}
%\caption{Details of the baseline system}
\caption{Possible scenarios (decision paths) based on the type of synthesized frames- $P_1$, $P_2$, and $P_3$}
\label{tab:pos_sce}
\vspace{-6mm}
\end{table}


\subsection{RL-based Decision Predictor}
\label{rlmodel}

As mentioned in Section~\ref{sec:Introduction}, we propose an RL-based model~\ref{RL} that intelligently takes the
decisions shown in Figure~\ref{fig:flow} to provide the best overall performance both in terms of quality as well
as frame rate. RL-based approaches are germane to this scenario because we take decisions in a potentially uncertain
environment, and that too with partial information.  

In this section, we define the structure, features, and parameters used in our network. As discussed in
Section~\ref{staterep}, we feed the state information of the scenes to the model. The motivation behind the choice of
values taken to represent the state has been summarized in Section ~\ref{feature}. To better understand the complexity
of the current scene, we use the past three states with the current state as the input to make a prediction. Each state
is defined by a tuple of vectors: the environment vector $E_t$ (Eqn. \ref{eqn:et}) and the temporal vector $T_t$.
The environment vector
$E_t$ for any frame $F_t$ contains the values of the features mentioned in Table~\ref{features}. We also consider
the variance in the horizontal and vertical direction of the motion vector separately. We also use the rendering
resolution ($R$) of $F_t$ as a single integer, $R = R_h \times R_w$ (horiz$\times$ vert).

\begin{equation}
\label{eqn:et}
	E_t=[ N_d, EMD_{W_n}, EMD_{W_p}, Var_x(F_{mv}), Var_y(F_{mv}), R ]
\end{equation}

To encode information about the current decision, we use another vector $T_t$ of length five, which represents the five
states in Figure~\ref{fig:flow} as a one-hot encoded vector. The state is represented as $S_t = (E_t,T_t)$. This tuple
is flattened into a single vector and the concatenation of all the 4 state vectors (current and last three frames)
are fed into the RL network. The length
of the vector is 44 (11$\times$4) 4-byte floats (represented in fixed point). The model gives an output vector of length two, which corresponds to the rewards
associated with the two choices: warping and extrapolation. The choice that gives the maximum reward is chosen
finally. Hence, the network is a mapping defined by $EW_{net}: \mathbb{R}^{44} \longrightarrow \mathbb{R}^2 $. The
predicted choice by the model at time $t$ ($A_t$) is calculated as:

\begin{equation}
	A_t=\arg_{i} max(EW_{net}([S_t,S_{t-1},S_{t-2},S{t-3}]))
\end{equation}

To train our network to potentially foresee the future frames with high variation in features, we
minimize the error between the predicted reward and the weighted sum of the current reward and the reward associated
with the next best action. This ensures that the model is able to predict future high-variance sequences and take
appropriate decisions. When the scene has less variation the model, we should prefer warping whereas when the scene
is highly dynamic, the model needs to predict that and migrate towards extrapolation. It is important for our model to anticipate the
future as the immediate best action might not be the best action (the local optima may not be global). 


\subsubsection{Reward Function}

The reward function is the sum of the below at each decision point. Here, $MSE$ refers to the mean square error.
\begin{equation}
\begin{split}
& R = \Delta PSNR + \Delta SSIM + \alpha \\
& PSNR = 10 \times log_{10} \left ( 255^2/MSE \right ) \\
& SSIM = \text{Structural similarity between two images}
\end{split}
\end{equation}


\begin{itemize}
    \item The gain/loss in PSNR~\cite{psnr} and SSIM~\cite{psnr} due to an {\em action}, which is the difference between the PSNR/SSIM of the frame
generated due to the chosen action and the PSNR/SSIM of the frame that would have been generated by the other action. 
These metrics use the ground truth as the baseline.
	\item $\alpha$ = -0.1, loss associated with dropping frames 
\end{itemize}

The network estimates the reward function $R(S_t,A_t;\theta_i)$ at state $S_t$
for an action $A_t$ with the network parameters $\theta_i$ at the $i^{th}$ training step. The function
$R(S_t,A_t;\theta_i)$ is the maximum reward in $EW_{net}([S_t,S_{t-1},S_{t-2},S{t-3}])$.  Our loss can be defined as:

\begin{equation}
	L_i = \mathbb{E}\left[ \left( r+\gamma \max_{A_{t+1}}R(S_{t+1},A_{t+1};\theta_{i-1})-R(S_t,A_t;\theta_{i}) \right) ^2 \right]
\end{equation}

where $\gamma$ (=0.95) is the discount factor, which is used to tune the importance the model gives to future moves and $r$
is the ground truth reward at that point. 

Given that our input size is small,
we can afford a network with three fully-connected+ReLU layers ($44\times 128$, $128\times 256$, $256\times 128$,
$128\times 2$) 
followed by one output layer ($2\times1$). 
Our network is trained with 3000 data points and tested with 1000 data points per benchmark. We
generate the frames at 30 fps. We employ LOOCV cross-validation to prevent overfitting: test data points corresponding to one
benchmark and use the remaining data points for training. We repeat this procedure for each benchmark (essentially, we
rotate the train-test set) and report the mean.  

\subsubsection{Hardware Implementation of the Predictor}
We train the
predictor offline and use it for online inferencing. 
We implemented the predictor in Verilog and synthesized it. We used 4 simple cores in our design
given its simplicity: each core has a four-stage pipelined
architecture. Since, most of the operations in neural network
inferencing are matrix multiplication and addition, we designed ten 8-bit multiply-accumulate (MAC) units along with one
adder and one multiplier unit for each core. Each core has a private cache of 16 KB. The system architecture of the
proposed system is shown in figure~\ref{arch}.
  
% Figure environment removed
