%\documentclass[aps, prb, notitlepage, citeautoscript, superscriptaddress, reprint, longbibliography]{revtex4-1}
\documentclass[aps, prx, notitlepage, citeautoscript, superscriptaddress, reprint]{revtex4-2}

\usepackage{xr}
\usepackage{amsmath}
\usepackage{amsfonts,amssymb,amsthm,amsxtra,physics,dsfont}
\usepackage[]{graphicx}
\pagestyle{headings}
\usepackage{grffile}
\usepackage{mathrsfs}
\usepackage{framed}
\usepackage{bbm}
\usepackage{bm}
\usepackage{braket}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{quantikz}
\usepackage[bookmarks=false,colorlinks=true,urlcolor=blue,citecolor=blue,linkcolor=blue]{hyperref}
%\usepackage[bookmarks=false,colorlinks=True,urlcolor=black,citecolor=black,linkcolor=black]{hyperref}
\usepackage{xcolor, soul}
\sethlcolor{yellow}
%\usepackage{mathdots}
%\usepackage{LatexCommands}
\usepackage{private}
\DeclareMathOperator*{\argmin}{arg\,min}
%\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\usepackage{makecell}
\usepackage{lipsum}
\usepackage{pgfplots}
\usepackage{comment}
\renewenvironment{comment}{}{}
%\usepackage[toc,page]{appendix}
\usepackage[capitalize]{cleveref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newcommand{\lat}{\selectlanguage{english}}
\newcommand{\gre}{\selectlanguage{greek}}
\newcommand{\tO}{\textbf{O}}
\newcommand{\tx}{\textbf{x}}
\newcommand{\tX}{\textbf{X}}
\newcommand{\tu}{\textbf{u}}
\newcommand{\tK}{\textbf{K}}
\newcommand{\tk}{\textbf{k}}
\newcommand{\tf}{{\textbf{f}}}
\newcommand{\bPhi}{{\bf{\Phi}}}
\newcommand{\bLambda}{{\bf{\Lambda}}}
%\SetKwComment{Comment}{/* }{ */}
\newcommand{\JY}[1]{{\color{red}{JY: #1}}}
\newcommand{\Nil}[1]{{\color{blue}{NG: #1}}}
\newcommand{\CY}[1]{{\color{green}{CY: #1}}}

\preprint{APS/123-QED}


\pgfplotsset{compat=1.17}


\begin{document}
\title{A hybrid method for quantum dynamics simulation} %variational dynamics of linear combination of statevectors}

%\author{TBD}
%\email{niladri@lbl.gov}
%\affiliation{Applied Mathematics and Computing Sciences Division, Lawrence Berkeley National Laboratory, Berkeley, California 94720, USA}


\author{Niladri Gomes}
\email{niladri@lbl.gov}


\author{Jia Yin}
\email{jiayin@lbl.gov}



\author{Siyuan Niu}

\author{Chao Yang}

\author{Wibe Albert de Jong}
\affiliation{Applied Mathematics and Computational Research Division, Lawrence Berkeley National Laboratory, Berkeley, California 94720, USA}

\begin{abstract}


 We propose a hybrid approach to simulate quantum many body dynamics by combining Trotter based quantum algorithm  with  classical dynamic mode decomposition. The interest often lies in estimating observables rather than explicitly obtaining the wave function's form.  Our method predicts observables of a quantum state in the long time by using data from a set of short time measurements from a quantum computer. The upper bound for the global error of our method scales as $O(t^{3/2})$ with a fixed set of the measurement.  We apply our method to quench dynamics in Hubbard model and nearest neighbor spin systems and show that the observable properties can be predicted up to a reasonable error by controlling the number of data points obtained from the quantum measurements. 
\end{abstract}

\date{\today}

\maketitle

%\textit{Introduction.---}
\section{Introduction}

Simulating quantum dynamics is becoming increasingly viable with the advancements in universal quantum computers \cite{Smith_2019, AVQDS, lee2022variational}. One notable advantage of utilizing quantum computers for this purpose is the flexibility they provide. Quantum computers offer the opportunity to explore previously inaccessible physics, such as simulating lattice gauge theories with dynamical gauge fields. These theories play a crucial role in the study of strongly-correlated quantum systems but have proven challenging to experimentally realize due to the complexities of multi-body couplings.  

Despite the advancements in quantum computing, the current state of the art devices still suffer from significant noise and imperfections ~\cite{nisq}. Consequently, a crucial area of research focuses on discovering methodologies to conduct meaningful scientific computations on these systems. As a result, variational algorithms have emerged as a valuable approach to investigate energy eigenstates and dynamics within spin and fermionic systems \cite{mclachlan64variational, vqe, vqe_theory, vqe_pea_h2, hardware_efficient_vqe, VQE_qcc, FengVQE}. However, beyond the assessment of energy eigenstates, there is a growing interest within the scientific community to explore the dynamic properties of electronic matter at low temperatures, presenting an immediate area of interest.


There is a significant ongoing debate about whether the currently available processors can be sufficiently improved in terms of reliability to execute shorter-depth quantum circuits on a scale that would offer practical advantages for problem-solving \cite{lee2208there}. Presently, the general consensus suggests that the implementation of even basic quantum circuits capable of surpassing classical capabilities will likely require the arrival of more advanced, fault-tolerant processors. However, with the existing NISQ (Noisy Intermediate-Scale Quantum) resources, it is feasible to leverage a combination of existing classical and numerical tools to achieve valuable outcomes. To that end, predictive techniques for a large number of obeservables to characterize quantum states are becoming popular with the advent of classical shadow methods \cite{huang2020predicting} and its derandomized version \cite{huang2021efficient}. In our current work, we will adopt a different predictive protocol to estimate observables during a long time Hamiltonian simulation. 



The primary focus of simulating dynamics in quantum mechanical systems revolves around conducting Hamiltonian simulations of quantum states. In simpler terms, to retrieve the dynamical properties of a system described by a wavefunction $\ket{\psi}$ at an initial time, and subject to a Hamiltonian $H$, one can calculate $e^{-iHt}\ket{\psi}$ to obtain the state at a time $t$.
Different methods have been proposed in the recent years to do Hamiltonian simulation using a quantum computer. Lloyd’s method for simulating  assumes a tensor product structure of smaller subsystems \cite{lloyd1996universal}. Aharonov and Ta-Shma (ATS) \cite{aharonov2003adiabatic} consider the alternative case where there is no evident tensor product structure to the Hamiltonian, but it is sparse and there is an efficient method of calculating the nonzero entries in a given column of the Hamiltonian. In recent years, variational approaches have shown promising results at generating low depth circuits \cite{variational_mclachlan,AVQDS,Steckmann2021,lee2022variational}. However, the variational methods lack a definitive proof of scaling and error bounds in the assymptotic limit. Considering efficient scaling, Hamiltonian simulation using first-order integrators of Suzuki~\cite{berry2007efficient} are one of the promising choices as scalable quantum algorithms. Despite their favorable asymptotic scaling, the Trotter-based methods suffer from increasing circuit depth which makes it hard if not impossible to do any meaningful calculation for long time simulations. 


The Trotter-based methods, which are commonly used for Hamiltonian simulation, face a significant drawback when applied to NISQ devices. The circuit depth grows exponentially with each time step, making calculations practically infeasible beyond a few steps. Although recent advancements have led to impressive scalability in terms of quantum volume, enabling the consideration of problems with a large number of qubits, meaningful results can only be obtained for a limited number of time steps. 
One possible approach is to utilize established classical extrapolation methods such as dynamic mode decomposition (DMD) to predict long time state properties collected from the hardware data. However, due to the complex nature of quantum wave functions, applying such predictions can be computationally intensive.
In scientific problems, the interest often lies in estimating observables rather than explicitly obtaining the wave function's form.  In this paper, instead of employing DMD for state vector extrapolation, we propose a method that predicts observables of a quantum state by gathering data from a quantum computer.






%Simulating dynamics for quantum mechanical systems is primarily about performing  Hamiltonian simulation of a quantum state. In other words, the dynamical properties of a system with wavefunction $\ket{\psi}$ at an initial time  and subject to a Hamiltonian $H$ can be retrieved at a time $t$ by calculating $e^{-iHt}\ket{\psi}$. 
%As mentioned earlier, although Trotter-based methods are considered the most favorable for Hamiltonian simulation, their biggest disadvantage for the NISQ devices is the exponential growth of circuit depth that makes the calculations almost impossible after a few time steps. By taking the advantage of the impressive scalability of the quantum volume in the recent years, one could attempt a problem with large number of qubits, however, meaningful results can be obtained only for a small number of time steps.   One may try using classically  established extrapolation method like dynamic mode decomposition (DMD), but a quantum wavefunction being complex, such predictions could be numerically intensive.
%In scientific problems, one is often interested in estimating the observables instead of an explicit form of the wavefunction. In this paper, instead of applying DMD  on the statevector extrapolation, we propose to predict observables of a quantum state by collecting data from a quantum computer.



%Different methods have been proposed in the recent years to do Hamiltonian simulation using a quantum computer. Lloyd’s method for simulating  assumes a tensor product structure of smaller subsystems \cite{lloyd1996universal}. Aharonov and Ta-Shma (ATS) \cite{aharonov2003adiabatic} consider the alternative case where there is no evident tensor product structure to the Hamiltonian, but it is sparse and there is an efficient method of calculating the nonzero entries in a given column of the Hamiltonian. In recent years, variational approaches have shown promising results at generating low depth circuits \cite{variational_mclachlan,AVQDS}. However, the variational methods lack a definitive proof of scaling and error bounds in the assymptotic limit. Considering efficient scaling, Hamiltonian simulation using first-order integrators of Suzuki\cite{berry2007efficient} are one of the promising choices as scalable quantum algorithms. Despite of their favorable asymptotic scaling, the Trotter-based methods suffer from increasing circuit depth making it hard if not impossible to do any meaningful calculation for long time simulations. 





% Figure environment removed

\section{Method}

 We start from the equation of motion of a spatially varying observable $\tO(\tx,t)\equiv \qty[ O(x_{1},t), O(x_{2},t), ...,O(x_{N},t) ]^{T}$ subjected to a time-independent system Hamiltonian $H$. 
 \be 
 \dv{\ev{\tO}}{t}= i \mqty[ \ev{\qty[H,O_1]}\\ \ev{\qty[H,O_2]}\\. \\. \\ \ev{\qty[H,O_N]}] 
 \label{eq:hberg}
 \ee 
In the above equation, we define $O_{j}(t)=O(x_j,t) \in \mathbb{C}^{N_H \times N_H}$, and $\ev{O} = \expval{O}{\psi}$ holds for any $N_H\times N_H$ matrix $O$. 
On the other hand, from the Koopman operator theory~\cite{DMDtoKoop,Koopman1,Koopman2}, for any $\Delta t>0$, there exists a linear, infinite-dimensional operator $\mathcal{K}_{\Delta t}$, such that
%The DMD procedure constructs the proxy, approximate locally linear dynamical system,
\be 
\ev{\tO (t+\Delta t)} = \mathcal{K}_{\Delta t} \ev{\tO (t)}, 
\label{eq:k_eq}
\ee 
holds.
Throughout our discussions, we have adopted the convention of setting the Planck's constant $\hbar = 1$. By taking the time steps $t_n = (n-1)\Delta t,\; n = 1,..,M+1$, we get a temporally  discretized equation by finite difference,
\be 
\ev{\tO(t_{n+1})} = \ev{\tO(t_n)} + i \Delta t \mqty[ \ev{\qty[H,O_1(t_n)]}\\ \ev{\qty[H,O_2(t_n)]}\\. \\. \\ \ev{\qty[H,O_N(t_n)]}].
\label{eq:dt_hberg}
\ee 
%{\color{blue}{This equation becomes identical in the limit $N\rightarrow\infty$ \cite{drmac2018data} \JY{need explanation}. 

%On the other hand, from the Koopman operator theory~\cite{DMDtoKoop,Koopman1,Koopman2}, there exists a linear, infite-dimensional operator $\mathcal{K}$, such that}
%The DMD procedure constructs the proxy, approximate locally linear dynamical system,
%\be 
%\ev{\tO (t_{n+1})} = \mathcal{K} \ev{\tO (t_{n})}, \; n = 1,\,2,\, ...,\, M
%\label{eq:k_eq}
%\ee 
%holds.}
%using a $N$-dimensional linear operator $\tK$ called the Koopman operator. 
The aim of DMD is to approximate the infinite-dimensional operator $\mathcal{K}_{\Delta t}$ with a finite-dimensional linear operator which can be written in a matrix form $\tK$. Within the DMD framework, Eq.~\eqref{eq:dt_hberg} is advanced by $m$-time steps and the resulting temporal `snapshots' are recorded in two matrices,
\bea 
\tX_1 &=& \mqty[| & | & \; & \; & | \\ \ev{{\tO}^1}& \ev{{\tO}^2}& . & . &\ev{{\tO}^{m-1}} \\ 
| & | & \; & \; & | ]\\
\tX_2 &=& \mqty[| & | & \; & \; & | \\ \ev{{\tO}^{2}}& \ev{{\tO}^{3}}& . & . &\ev{{\tO}^{m}} \\ 
| & | & \; & \; & | ]
\eea
with ${\tO}^j=\tO(t_j)$.

Elements of  $\tX_1$ and $\tX_2$ are obtained by measuring the quantity $\ev{O(\tx,t)}$ up to $m$-time steps. The time evolved state $\ket{\psi(t)} = e^{-iHt}\ket{\psi(0)}$ is prepared using the Trotter decomposition of the evolution operator $e^{-iHt}$. We will discuss more details about the Trotter method in a later subsection. 

From these data matrices, we can find an $N\times N$ matrix $\tK_m$ which approximates $\mathcal{K}_{\Delta t}$ in the sense that $\tK_m = \bPhi_m \bLambda_m  \bPhi_m^\dagger$ with its eigenvalues ($\bLambda_m$) and eigenvectors ($\bPhi_m$) close to $\mathcal{K}_{\Delta t}$'s.  The finite-dimensional approximation to the Koopman operator $\mathcal{K}_{\Delta t}$ is obtained by solving the following linear least squares problem
\begin{equation}
 \min_{\tK_m} \| \tK_m \mathbf{X}_1 - \mathbf{X}_2 \|_F^2,
\label{eq:lsq1}
\end{equation}
with the solution
\begin{equation}\label{eq:A1}
    \tK_m = \mathbf{X}_2\mathbf{X}_1^+,
\end{equation}
where $\mathbf{X}_1^+$ is the Moore-Penrose pseudoinverse of $\mathbf{X}_1$ that can be computed from the singular value decomposition (SVD)~\cite{SVD} of $\mathbf{X}_1$. In practice, if $\mathbf{X}_1$ has low-rank structure, we will take a truncated SVD instead of full SVD in order to enhance efficiency. Then after obtaining an $r\times r$ matrix $\widetilde{\tK}_m$ with $r$ the truncated rank, we need to project it back to the original $N$-dimensional observable space.

Once we get $\mathbf{X}_1^\dagger$, and hence $\tK_m$ is obtained,  from the eigendecomposition $\tK_m\bPhi_m = \bPhi_m\bLambda_m$, we can construct the solution of~\eqref{eq:dt_hberg} at a later time step $n>m$ as,
\be
\ev{\tO(t_{n})} = \bPhi_m \bLambda_m^{n-1} \bPhi_m^{\dagger}\ev{\tO(t_{1})}.
\ee
We can also get the approximation at any time $t>0$ by taking $\mathbf{\Omega}_m = {\rm{ln}}\bLambda_m/\Delta t$, and then we get
\be
\ev{\tO(t)} = \bPhi_m\exp(\mathbf{\Omega}_mt)\bPhi_m^{\dagger}\ev{\tO(t_{1})}.
\ee
Since ${\mathbf{\Omega}}_m$ is a diagonal matrix, the real part of each diagonal element describes the changes in amplitude, while the imaginary part describes the frequencies of the oscillation in the approximated dynamics.


 The above described procedure is shown in a flowchart in Fig.~\ref{fig:flowchart} and the algorithm is summarized in Algorithm~\ref{alg:DMD}.
In short, our hybrid method includes time evolution of a quantum state in a  quantum computer and simultaneous measurement of an observable of the states. Using the measured data we utilize the DMD framework to predict long time dynamics of the observable. Both Trotter based methods and DMD are popular methods in their respective communities of quantum algorithms and differential equation solvers. 
To facilitate later discussions, we summarize the main points of Trotter based time evolution and provide a predictive error bound of DMD for our application to quantum simulation. 
\begin{algorithm}[H]
\caption{The DMD procedure}\label{alg:DMD}
\begin{algorithmic}[1]
\State $\mathbf{X}_1 \gets \left[\ev{{\tO}^1}, \, ..., \, \ev{{\tO}^{m-1}}\right]$, $\mathbf{X}_2 \gets \left[\ev{{\tO}^{2}}, \, ..., \, \ev{{\tO}^{m}}\right]$
\State Truncated SVD of $\mathbf{X}_1$ with rank $r$: $\mathbf{X}_1 = \widetilde{\mathbf{U}}\widetilde{\mathbf{\Sigma}}\widetilde{\mathbf{V}}^T$
\State $\widetilde{\tK}_m \gets \widetilde{\mathbf{U}} \mathbf{X}_2 \widetilde{\mathbf{V}} \widetilde{\mathbf{\Sigma}}^{-1}$ \Comment{The projected Koopman operator}
\State Eigen-decomposition of $\widetilde{\tK}_m$: $\widetilde{\tK}_m\mathbf{W}_m = \mathbf{W}_m{\mathbf{\Lambda}_m}$
\State $\mathbf{\Phi}_m \gets \mathbf{X}_2\widetilde{\mathbf{V}}\widetilde{\mathbf{\Sigma}}^{-1}\mathbf{W}_m$ \Comment{DMD modes}
\State $\mathbf{\Omega}_m \gets {\ln{\mathbf{\Lambda}_m}}/{\Delta t}$, $\mathbf{b} = \mathbf{\Phi}_m^\dagger \ev{{\tO}^1}$ 
\State $\ev{\tO(t)}\gets \mathbf{\Phi}_m\exp(\mathbf{\Omega}_mt)\mathbf{b}$ \Comment{Reconstruction and predicion}
\end{algorithmic}
\end{algorithm}


\textit{Trotter Suzuki methods--} 
Given a Hamiltonian of the form $H = \sum_{j=1}^{J} H_j$, we want to simulate $e^{-iHT}$ by a sequence of exponentials like $e^{-iH_{j}\Delta t}$, where the total simulation time $T$ is divided into $M$ small steps of width $\Delta t$ such that $M = T/\Delta t$.  According to \cite{berry2007efficient}, this can be achieved within error $\epsilon$ by using $M_{exp} \le 4J^{2}\tau e^{2\sqrt{\ln{5}} \ln{\frac{J\tau}{\eps}}}$ ($\tau = \norm{H}T$) steps with exponentials like $e^{-iH_{j}\Delta t}$. The method is effectively optimal and hence we apply it to simulate our Hamiltonian. 

As mentioned previously, time evolution of the state $\ket{\psi(T)} = e^{-iHT}\ket{\psi(0)}$ is prepared using the Trotter decomposition. Clearly the resource required (which can be estimated by the number of CNOT gates) increases with $t$, and therefore the time of evolution is highly limited by the available resources in the quantum hardware.  
%This method can be easily extended to estimating any other time dependent observable $\mathcal{O}(t)$. 
For a time evolution of time $t$ the unitary $U = e^{-iHT}$ is approximated by a unitary $\Tilde{U}$ using the product formula,
\be 
\Tilde{U}(t) = \prod_{k=1}^{M}\prod_{j=1}^{J}e^{-iH_{j}\Delta t}
\ee 

%In scientific problems, one is often interested in estimating the observables instead of an explicit form of wavefunction. In this work we  measure the time dependent density matrix $\rho (t) = \expval{c^{\dagger}_{j}c_{k}}{\psi(t)}; \; j,k\in {1,L}$ at several time steps upto time $t$ for a finite system of size $L$.

\textit{Analysis of Predictive Accuracy--} Error analysis  for our method has two directions. First, how the error scales w.r.t time by keeping $m$, the number of snapshots we use in DMD, fixed. Second, scaling of the errors as a function of $m$ at a fixed future time. We will derive an analytical form for the first case, and provide numerical evidence for the latter. Our derivation of error upper bounds by using DMD follows as a special case of the predictive accuracy analyzed in~\cite{lu2020prediction}. The original work was done for a differential equation of the form 
\be 
\dv{\tu}{t}=\mathcal{A}\tu + \tf(\tu)
\ee 
where $\mathcal{A}$ is a linear operator, $\tu=[u_1, ..., u_N]^T\in\mathbb{C}^N$ is a vector of observables and $\tf$ is a an external source/sink  term. In terms of Koopman's operator the above equation in discretized time with a small $\Delta t$ can be written as,
\be \label{eq:pde}
\tu^{n+1} \equiv \mathcal{K}_{\Delta t} \tu^{n} \approx \mathcal{A}\tu^{n} + \Delta t\, \tf^{n}, \; n=1, ..., M,
\ee 
where $\tf^{n}$ is the $n$-th discretized snapshot of $\tf$.
Calling the approximate eigenvalues and the eigenvectors of $\mathcal{K}_{\Delta t}$ as $\bLambda_m$ and $\bPhi_m$  let us first posit the following \cite{drmac2018data}, 
\begin{lemma}\label{lemma:e_m}
Define the global truncation error on the $m$-th temporal snapshot by $\epsilon^{m}=\normalfont{\tu}^{m} - \normalfont{\tu}^{m}_{\rm{DMD}}$, then DMD is designed such that 
\be\nonumber
\|\epsilon^{m}\|_2 := \sqrt{\sum_{j=1}^N|\epsilon_j^m|^2}, \; \epsilon_j^m = u_j^m-u_{j,\rm{DMD}}^m, \; j=1, ..., N
\ee
is minimum.
\end{lemma}
%\CY{this is well known, doesn't need a proof.}
The error at the $n$-th time step ($n>m$) is then given by the following theorem \cite{lu2020prediction},
%Before stating the result we define the following quantities: global error at the $j$-the time step as $\norm{\epsilon^{(j)}}= \norm{\tu^{(j)} - \tu^{(j)}_{DMD}}$; 
\begin{theorem} 
 \label{theorem:local_error}
    Define the local truncation error 
     \be 
     {\tau^{n}} = \normalfont{\tu}^{n+1} - \normalfont{\tu}^{n}_{\rm{DMD}}\left(\normalfont{\tu^{n}}\right) 
     \ee 
     Then for any $n\ge m$,
 \bea 
 \norm{\tau^{n}}_2  &\le& \epsilon_m 
\eea
where
\be
\begin{aligned}\label{eq:local_error_bound}
\normalfont
\epsilon_m =& c_m\Bigg[ \norm{\normalfont{\tu}^{0}}^2_2 \\
&+\Delta t  \sum_{k=1}^{n-1}\max \qty{ \norm{\normalfont{\tf}^{k} }^2_2, \norm{\normalfont{\tf}^{k+1}}^2_2 }  \Bigg]^{\frac{1}{2}},
\end{aligned}
\ee
with
\be
\norm{\normalfont{\tf}^{k} }^2_2 := \sum_{j=1}^N|{\rm{f}}^k_j|^2.
\ee
 %\left[\norm{c_m}^2_2\qty( \norm{\ev{\tu(t_n)}}^2_2) 
%+ \Delta t     \right]
% \eea 
\end{theorem}
In the equation, $c_m$ is a constant depending on the number of snapshots $m$ used in DMD and satisfies $\norm{\mathcal{K}_{\Delta t}- \bPhi_m\bLambda_m\bPhi_m^{-1}}_{2}\le c_m$. Here the $2$-norm on the left hand side is defined by
\be
\begin{aligned}\nonumber
\norm{\mathcal{K}_{\Delta t}- \bPhi_m\bLambda_m\bPhi_m^{-1}}_{2}&\\
:= \max_{\substack{\phi(t)\in\mathbb{C}^N, \phi(t)\neq{\mathbf{0}},\\\tilde{t}\geq 0}}&\frac{\left\|\left(\mathcal{K}_{\Delta t}\phi(t)\right)|_{t=\tilde{t}}- \bPhi_m\bLambda_m\bPhi_m^{-1}\phi(\tilde{t})\right\|_2}{\|\phi(\tilde{t})\|_2}\\
= \max_{\substack{\phi(t)\in\mathbb{C}^N, \phi(t)\neq{\mathbf{0}},\\\tilde{t}\geq 0}}&\frac{\left\|\phi(\tilde{t}+\Delta t)- \bPhi_m\bLambda_m\bPhi_m^{-1}\phi(\tilde{t})\right\|_2}{\|\phi(\tilde{t})\|_2},
\end{aligned}
\ee
where we use a shorthand  notation $\left(\mathcal{K}_{\Delta t}\phi(t)\right)|_{t=\tilde{t}}$ to denote 
\be\nonumber
\begin{aligned}
\left(\mathcal{K}_{\Delta t}\phi(t)\right)|_{t=\tilde{t}} &:=
\begin{bmatrix}
\mathcal{K}_{\Delta t}\phi_1(t)\\\vdots \\
\mathcal{K}_{\Delta t}\phi_N(t)
\end{bmatrix}_{t=\tilde{t}} = \begin{bmatrix}
\phi_1(\tilde{t}+\Delta t)\\\vdots \\
\phi_N(\tilde{t}+\Delta t)
\end{bmatrix} \\&= \phi(\tilde{t}+\Delta t).
\end{aligned}
\ee
The $c_m$ term can be viewed as a measure of how closely we can approximate the Koopman operator in an $N$-dimensional subspace.
% & + & \left. \Delta t  \sum_{k=1}^{n-1}\max \qty{ \norm{\tf^{k}}^2_2, \norm{\tf^{k+1}}^2_2 }  \right]^{\frac{1}{2}} 
% = \epsilon_m
\begin{theorem}\label{theorem:error_b}
The global error at the n-th time step $\epsilon^n$ by using $m$ snapshot data in DMD is bounded above by
\be\label{eq:global_error_bound}
\norm{\epsilon^{n}}_{2} \le \norm{\bPhi_m}_{2} \norm{\bPhi_m^{-1}}_{2}\qty[\norm{\epsilon^{m}}_{2} + (n-m)\epsilon_m ]
\ee 
with $\epsilon_m$ defined by~\eqref{eq:local_error_bound}, if the eigenvalues of $\mathcal{A}:\{\lambda_{1}, \lambda_{2},..,\lambda_{N}\}$ satisfies $\max_{1\le k \le N} \abs{\lambda_k}\le 1.$
\end{theorem}

The proof of {\textbf{Theorem}}.~\ref{theorem:error_b} can be found in~\cite{lu2020prediction}. This theorem states that the global error mainly comes from two parts: 1) the approximation to the Koopman operator; 2) the intrinsic property of the dynamics. In the first part, the $c_m$ factor in~\eqref{eq:local_error_bound} measures how well DMD approximates the Koopman operator. Since the number of DMD modes $r$ is determined by the rank of $\tK_m$, when $N$ is small, i.e. with insufficient spatial resolution, the DMD modes does not fully represent the spectral property of the Koopman operator. Thus one way to reduce $c_m$ is by improving the spatial resolution. In the second part, the potentially large condition number $\|\bPhi_m\|_2\|\bPhi_m^{-1}\|_2$ is caused by the departure from normality of the projected Koopman operator $\tK_m$, i.e., the eigenvectors of the $\tilde{\tK}_m$ are far from orthogonal. 
%We suggest that one possible improvement for future investigation is to use pseudospectra instead of eigendecomposition~\cite{trefethen2005spectra}. 
From the theorem, we can see that for a given number of snapshots $m$ used in DMD, the global error scales as $O(t^{3/2})$ temporally.

We will now provide local and global truncation error bounds using the above two theorems for our case of quantum dynamics simulation. 
\begin{theorem} \label{theorem:local_error_quantum}
    The local and the global truncation error by using DMD for the dynamical equation~\eqref{eq:hberg} is respectively govened by,
    \bea 
    \epsilon_m &\leq& \norm{c_m}_2\norm{\normalfont{\tO}}_F\left( 1 +  2n \Delta t  \norm{H}^2_F \right)^{\frac{1}{2}},\nonumber \\
\norm{\epsilon^{n}}_2 &\le& \norm{\bPhi}_2\norm{\bPhi^{-1}}_2 \left[\Delta_m \right. \notag \\
&+& \left. (n-m) \norm{c_m}_2\norm{\normalfont{\tO}}_F\left( 1 +  2n \Delta t  \norm{H}^2_F \right)^{\frac{1}{2}} \right] \notag,
\eea 
   % \bea 
   % \normalfont
   % \norm{\epsilon^{(n)}} &\le&
   % \norm{\bPhi^{-1}}_F\notag  \left[ \Delta_m + \right. \notag \\
   %   && \left. (n-m)c_{m}\norm{\normalfont{\tO}}_F(1+2mdt\norm{H}_F) \right] \notag
   % \eea 
    where $\Delta_m > 0$ is a constant for a fixed $m$. As a result, the global truncation error scales as $O(t^{3/2})$.
\end{theorem}
\begin{proof}
 By comparing~\eqref{eq:dt_hberg} and~\eqref{eq:pde}, we notice that $\tu^{n} = \ev{\tO(t_n)}$,  $\mathcal{A}$ is an $N$-dimensional identity matrix and 
 \be 
 \tf^{n} = i\mqty[ \ev{\qty[H,O_1(t_n)]}\\ \ev{\qty[H,O_2(t_n)]}\\. \\. \\ \ev{\qty[H,O_N(t_n)]}] 
 \ee 
 Using Lemma~\ref{lemma:util} we can write %\JY{Why don't we use 2-norm?} 
 \bea 
\norm{\normalfont{\tf}^{n}}^2_2 &=& \sum_{j=1}^{N} \left|\ev{\qty[ H, O_j(t_n) ]}\right|^2\notag \\
&\le& \sum_{j=1}^{N}\norm{\qty[ H, O_j(t_n) ]}^2_F 
\le 2\sum_{j=1}^{N}\norm{H}^2_F\norm{O_j(t_n)}^2_F \notag \\
&\le& 2\norm{H}^2_F\sum_{j=1}^{N}\norm{O_j}^2_F 
= 2\norm{H}^2_F\norm{\tO}_F^2
\label{eq:fn}
 \eea 
where we take $\sum_{j=1}^{N}\norm{O_j}^2_F \equiv \norm{\tO}_F^2$. Note that $\norm{\tO}_F^2$ does not change with time. To see this, consider the simplification of the term $\norm{O_j(t_k)}^2_F$: $\norm{O_j(t_k)}^2_F = \norm{e^{iHt_k}O_je^{-iHt_k}}^2_F = \norm{O_j}^2_F$ since $e^{\pm iHt_k}$ are unitary matrices. In the above derivation, we also used the result from Ref.~\cite{bottcher2008frobenius}: $\norm{\qty[A,B]}^2_F\le 2\norm{A}^2_F\norm{B}^2_F$. 


Now by putting~\eqref{eq:fn} in~\eqref{eq:local_error_bound}, we obtain the local truncation error 
\bea
\epsilon_m &=& \norm{c_m}_2\left( \sum_{j=1}^{N} \norm{O_j(t_0)}^2_F \right. \notag \\
&+& \left.  \Delta t \sum_{k=1}^{n} \max \qty{ \norm{\normalfont{\tf^{(k)}}}^2_2, \norm{\normalfont{\tf^{(k+1)}}}^2_2} \right)^{\frac{1}{2}}  \notag \\
&\le& \norm{c_m}_2\left( \sum_{j=1}^{N} \norm{O_j}^2_F +  2\Delta t \sum_{k=1}^{n} \norm{H}^2_F\norm{\tO}_F^2 \right)^{\frac{1}{2}} \notag \\
&=& \norm{c_m}_2\norm{\tO}_F\left( 1 +  2n \Delta t  \norm{H}^2_F \right)^{\frac{1}{2}}
\eea 
The global truncation error can be obtained by substituting $\epsilon_m$ in~\eqref{eq:global_error_bound} and taking $\norm{\epsilon^{m}}_2$ as a constant $\Delta_m$ (by Lemma.~\ref{lemma:e_m}). Thus we prove Theorem.~\ref{theorem:local_error_quantum}:
\bea 
\norm{\epsilon^{n}}_2 &\leq& \norm{\bPhi}_2\norm{\bPhi^{-1}}_2 \left[\Delta_m \right. \notag \\
&+& \left. (n-m) \norm{c_m}_2\norm{\normalfont{\tO}}_F\left( 1 +  2n \Delta t  \norm{H}^2_F \right)^{\frac{1}{2}} \right] \notag
\eea 
Now considering predictions for long time $n\gg m$, we can write $(n-m)\approx t/\Delta t$. Using $n\Delta t = t$, we can rewrite the upper bound as,
\bea
\norm{\epsilon^{n}}_2 &=& \norm{\bPhi}_2\norm{\bPhi^{-1}}_2 \left[\Delta_m \right. \notag \\
&+& \left. \frac{t}{\Delta t} \norm{c_m}_2\norm{\normalfont{\tO}}_F\left( 1 +  2t  \norm{H}^2_F \right)^{\frac{1}{2}} \right] \notag
\eea 
The above result shows that the scaling of error is at most $O(t^{3/2})$, which is suboptimal.

%\bea 
%norm{\epsilon^{(n)}}_2 &=& \norm{\bPhi}_2\norm{\bPhi^{-1}}_2 \left[\Delta_m 
%+  (n-m) \epsilon_m \right] \notag
%\eea  
%\bea 
%\norm{\epsilon^{(n)}}_2 &=& \norm{\bPhi}_2\norm{\bPhi^{-1}}_2 \left[\Delta_m %\right. \notag \\
%&+& \left. (n-m) \norm{c_m}_2\norm{\tO}_F\left( 1 +  2n \Delta t  \norm{H}^2_F \right)^{\frac{1}{2}} \right] \notag
%\eea  
\end{proof}


For the second part of error analysis, our focus shifts to examining the relationship between the global truncation error at time $T=t_{M+1}$ and the number of snapshots $m$ used to construct DMD. We will only provide numerical evidence as part of this error analysis.  We notice that the error decreases initially with respect to $m$ before it levels off and oscillates around a constant value. This is most likely due to the fact that the observables of interest here do not span an invariant subspace of the Koopman operator. As a result, the approximation error $c_m$ in~\eqref{eq:local_error_bound} will not decrease to 0. As we mentioned before, one way to reduce $c_m$ is to increase the spatial resolution of the observables. We will examine the numerical results shown in  Fig.~\ref{fig:err_plot}(c \& d) in the next section to check the validity of this approach. The error estimate of the Trotter method can be found in \cite{berry2007efficient}. In this work, we only provide an error bound of DMD for quantum simulation.


%In the limit of large $m$ the value of $c_m$ decreases to $0$ and so does $\epsilon_m$~\cite{lu2020prediction}. Hence the error reduces to \JY{check the formula}
%\be 
%\norm{\epsilon^{(n)}}_2 = \Delta_m \norm{\bPhi}_2\norm{\bPhi^{-1}}_{2}
%\ee 

%\Nil{Combine the error of Trotter and DMD to give full error estimate}





\section{Results}
\textit{Hubbard Model and quenching--} To demonstrate our method, we choose the quenching process in a finite size Hubbard Hamiltonian. We start from the ground state $\ket{\psi_0}$ of a non-interacting Hamiltonian $H_0$ on $L$ sites. 
\bea 
H_0 &=& -\sum_{i,j,\sigma} \tau_0\qty(c_{i,\sigma}^{\dagger}c_{j,\sigma} + h.c.) 
\eea 
We time evolve the quantum state w.r.t. an interacting Hamiltonian $H_1$,
\be
\begin{aligned}
H_1 =& -\sum_{i,j,\sigma} \tau_1\qty(c_{i,\sigma}^{\dagger}c_{j,\sigma} + h.c.) + U\sum_{j}n_{j \uparrow}n_{j \downarrow}  \\
& - \mu \sum_{j,\sigma}n_{j,\sigma}
\end{aligned}
\ee
We choose $\tau_0 = 1.0$ and $\tau_1=0.1$ specifically in our example. To preserve particle-hole symmetry, we choose $\mu = U/2$.
%{\color{blue}The value of the hopping parameter $t$ is chosen to be unity.\JY{What does this mean?}} 
The Hamiltonian is mapped to qubits using Jordan Wigner transformation. Throughout the rest of the paper, we consider Hubbard model at half-filling with total spin and its `z' component ($S_z$) to be zero, i.e, the number of electrons is the same as the number of lattice sites $L$, $N_{\uparrow} = N_{\downarrow}$ and we assume open boundary condition. %We run calculations for finite size lattices and will denote the number of lattice sites (the size of the system) by $L$.

Quenching a non-interacting metallic state by introducing a Hubbard interaction and we can observe suppressing tunneling coherent dynamics. 
The period is determined primarily by the interaction strength between the electrons. A large number of theoretical works using analytical and classical numerical methods exist seeking to characterize and
understand nonequilibrium dynamics in quantum systems~\cite{cazalilla2010focus,dziarmaga2010dynamics, polkovnikov2011colloquium}. Such works have been motivated by experiments like ultracold-atom where far-from-equilibrium dynamics can be observed. Other physical phenomena of scientific interest include the  collapse and revival of matter waves with Bose-Einstein
condensates in optical lattices~\cite{greiner2002collapse, will2013coherent}, coherent quench dynamics of a Fermi sea in a Fermi-Bose mixture~\cite{will2015observation}, non-thermal behavior in near-integrable experimental regimes~\cite{will2015observation, gring2012relaxation}, and equilibration in Bose-Hubbard-like systems~\cite{ trotzky2012probing}.


Our simulation proceeds by the following steps. First, we create the initial state, which is done by applying the instantiation method to the default initial state of the IBM machine. We choose the set of density matrix operators $\rho_{pq} = \ev{c_{p,\sigma}^{\dagger}c_{q,\sigma}}\; : (p,q) \in \qty{1,2,..,L}$ as our set of observables $\tO$. Clearly, the lattice site indices are our position coordinates $x$ and we want to observe the dynamics of $\tO$ with time $t$. We then use Trotter method to simulate the Hamiltonian evolution upto time $t_m$ and measure the correlation function $\tO$ at every time step. After that, we use DMD on the measure set of data to predict long time values of the set $\qty{ \ev{c_{p,\sigma}^{\dagger}c_{q,\sigma}} }$.  Density matrix elements can be computed for different pairs of sites within a lattice. For the reason of compactness, we also present our results in momentum space using a linear combination of all pairs in real-space %\JY{check the formula}
\be  
n_{\tk,\sigma} = \frac{1}{L}\sum_{p,q} \ev{c_{p,\sigma}^{\dagger}c_{q,\sigma}} e^{-i\tk (p-q)}, \label{eq:rho_momentum}
\ee  
where $\tk$ is the momentum index. 



\textit{Technical Details--}
If the numerical rank $r$ of $\mathbf{X}_1$ is much smaller than $n-1$ and $L^2$, then we can  use a truncated SVD of $\mathbf{X}_1 = \widetilde{\mathbf{U}}\widetilde{\mathbf{\Sigma}}\widetilde{\mathbf{V}}^T$, where the $r\times r$ diagonal matrix $\widetilde{\mathbf{\Sigma}}$ contains the leading $r$ dominant singular values of $\mathbf{X}_1$, and $\widetilde{\mathbf{U}}$ and $\widetilde{\mathbf{V}}$ 
contain the corresponding right and left singular vectors. For more details on the numerical procedure, we refer readers to references~\cite{DMD0,kutz2016dynamic,TuRowley,DMDdiag,DMDtwotime}.

In our system, since the scales of different entries in the density matrix vary a lot, we need to preprocess the data for $j=1, ..., L^2$ before constructing the data matrices by
\be
\langle \tilde{O_j}(t)\rangle = \dfrac{\langle O_j (t) \rangle - {\rm{mean}}{(\langle O_j(t_1:t_n)\rangle )}}{{\rm{std}}(\langle O_j(t_1:t_n)\rangle)}.
\ee
DMD becomes exact if the spatial discretization is infinite. Working with finite size lattices suffer from the problem of insufficient spatial degrees of freedom. Additionally, model Hamiltonians like Hubbard model have spatial and other symmetries that make many of the discretized observables trivial. Such observables can be predicted easily from symmetry arguments or can be ignored for non-trivial dynamics simulation.  To compensate for the resulting insufficient spatial resolution, we introduce an improved higher order DMD (iHODMD) derived from the time-delay embedding theory~\cite{broomhead1986extracting,packard1980geometry,Pan2020,Taken}. 
%\Nil{Emphasize that iHODMD is similar and our algorithm and the derivation of error bounds/ other analysis still applies}. 
iHODMD is similar to Algorithm~\ref{alg:DMD}, but we construct the data matrices for each observable $\langle O_j(t)\rangle$, $j\in\{1, ..., L^2\}$ with
\begin{equation*}%\label{eq:HODMD}
\begin{aligned}
	&\mathbf{\tilde{X}}_1 = \begin{bmatrix}
    		\langle \tilde{O_j}^{1}\rangle & \langle \tilde{O_j}^{n_g+1}\rangle & \cdots & \langle \tilde{O_j}^{(n_l-1)\times n_g+1}\rangle \\
    		\langle \tilde{O_j}^{2}\rangle & \langle \tilde{O_j}^{n_g+2}\rangle & \cdots & \langle \tilde{O_j}^{(n_l-1)\times n_g+2}\rangle \\
    		\vdots & \vdots & \vdots & \vdots\\
    		\langle \tilde{O_j}^{n_s}\rangle & \langle \tilde{O_j}^{n_g+n_s}\rangle &\cdots & \langle \tilde{O_j}^{(n_l-1)\times n_g+n_s}\rangle
    	\end{bmatrix}, \\
	&\mathbf{\tilde{X}}_2 =\begin{bmatrix}
        	\langle \tilde{O_j}^{1+\tau}\rangle & \langle \tilde{O_j}^{n_g+1+\tau}\rangle & \cdots & \langle \tilde{O_j}^{(n_l-1)\times n_g+1+\tau}\rangle \\
        	\langle \tilde{O_j}^{2+\tau}\rangle & \langle \tilde{O_j}^{n_g+2+\tau}\rangle & \cdots & \langle \tilde{O_j}^{(n_l-1)\times n_g+2+\tau}\rangle \\
        	\vdots & \vdots & \vdots & \vdots\\
        	\langle \tilde{O_j}^{(n_s+\tau)}\rangle & \langle \tilde{O_j}^{n_g+n_s+\tau}\rangle &\cdots & \langle \tilde{O_j}^{(n_l-1)\times n_g+n_s+\tau}\rangle
        \end{bmatrix},
\end{aligned}
\end{equation*}
where $n_s$ is the order of iHODMD, $n_g$ denotes the time difference of two adjacent columns in the data matrices, and $\tau$ denotes the time difference between two data matrices. We call the iHODMD with the above data matrices iHODMD($n_s$,$n_g$,$\tau$). The number of columns $n_l$ is chosen by $n_l = {\rm{floor}}\left((m-n_s-\tau)/n_g\right)+1$. This iHODMD method improves the original higher order DMD method presented in~\cite{HODMD} by introducing two additional parameters $n_g$ and $\tau$, which increases the flexibility of the algorithm. Since \eqref{eq:hberg} holds for each observable $O_j$ independently, a similar error analysis still applies for iHODMD. We only need to take $\mathbf{O}(t)$ in the analysis by 
\be
\mathbf{O}(t) = \left[\tilde{O_j}(t),\, \tilde{O_j}(t+\Delta t), \,..., \, \tilde{O_j}(t+n_s\Delta t)\right]^T,
\ee
and take the time step size to be $\tau\Delta t$.

The major computational cost of iHODMD($n_s$,$n_g$,$\tau$) is in the SVD of $\mathbf{\tilde{X}}_1$, which is $O(\min(n_s^2L^4n_l, n_sL^2n_l^2))$. The memory cost of the algorithm is $O(n_sL^2n_l)$.

% Figure environment removed
\textit{Simulator results--} 
We consider the Hubbard system with $L=6$. %\JY{revise (25), (26)}. 
We first present our results for $\tk=0$ in \eqref{eq:rho_momentum} in Fig.~\ref{fig:nk_time}. Panels (a) and (b) are the results for $U=4.0$ and $8.0$, respectively.   The blue squares represent the data due to Trotter evolution and the black curve is the DMD prediction. The prediction is calculated based on the time-series data collected within the the shaded-cyan region. Here we use iHODMD once for all the $6$ trajectories in the momentum space. From these figures, we can see that DMD gives good extrapolation for both $U$s. For a larger interaction $U=8$, we can even use a smaller number of snapshots to get results accurate enough.


As mentioned earlier, due to finite size and spatial symmetries of our system, only a handful of $\rho_{pq}$ are independent. Therefore we choose $\rho_{13}$ to show the prediction error in Fig.~\ref{fig:err_plot}. We take 200 snapshots up to $t=2$ in the extrapolation for both cases. Fig.~\ref{fig:err_plot}(a) shows the difference $\Delta = \rho_{13} - \rho_{13}^{\rm{DMD}}$ as a function of $t$ for different $U$. We show that the error is upper-bounded by $\sim t^{\frac{3}{2}}$, shown in magenta. To further illustrate our result, we have applied our method to the dynamics of $\ev{S^{z}_{j}(t)S^{z}_{j+1}(t)}$ for quenching in XXZ spin model \cite{Smith_2019}, where $S^{z}_{j}$ is the spin magnetic moment at $j$-th site in a $L$ spin system. The details about the Hamiltonian and the quench protocol is given in Appendix~\ref{appendix:xxz}. The DMD error for the XXZ model simulation is shown in Fig.~\ref{fig:err_plot}(b), where $O(t) = \ev{S^{z}_{1}(t)S^{z}_{3}(t)}$ for $L=6$ and $O(t) = \ev{S^{z}_{1}(t)S^{z}_{6}(t)}$ for $L=12$. The errors are bounded above by $t^{3/2}$ following our derivation.  As the Trotter splitting gives us error at $O(10^{-2})$ with the time step size $\Delta t=0.01$, the extrapolation results with $m\geq 200$ are generally acceptable. The oscillation behavior of the error with respect to $m$ is due to the nature of data-driven methods as we have observed before~\cite{DMDdiag,DMDtwotime}. 


% Figure environment removed

In Fig.~\ref{fig:err_plot}(c \& d), we plot the  error at the final time step ($T=t_{M+1}$) as a function of number of snapshots taken in DMD for Hubbard and XXZ model, respectively. We see that the error decreases initially with an increasing $m$ before it reaches and oscillates around a constant value which is at the order of $\sim 10^{-3} - 10^{-5}$. We also notice that the error drops to a lower threshold as we go from $L=6$ to $L=12$ for the XXZ model (Fig.~\ref{fig:err_plot}(d)). This is probably because having more observables in $\tO$ with $L=12$ improves the spatial resolution of the observables, which leads to a smaller $c_m$ in~\eqref{eq:local_error_bound} and a better approximation to the Koopman's operator. We remark here that the performance of DMD can be further improved if an alternative set of observables that span an invariant subspace of the Koopman's operator are used~\cite{li2017extended,Matthew_edmd}. However, to the best of our knowledge, no systematic way has been established to determine the optimal choice of observables for DMD. Recent research suggested that combining DMD with a convolutional autoencoder for observable selection will lead to improved accuracy~\cite{lusch2018deep,haq2022dynamic}. We will examine this approach in future work.\\



%\textit{Error due to DMD--}

%\textit{Hardware results--}

\section{Conclusion}
We have successfully combined DMD, a well-known data-driven predictive method with quantum data  to predict long term observables in a quantum system. For a dynamical quantum system, the quantum data is collected in form of observable expectation values. Since the resources in terms of quantum devices (e.g, CNOTs) increase quickly as we simulate dynamics, long time simulation of large system sizes are very hard to run. By utilizing the predictive methods like DMD, we can run quantum simulations for a small number of time steps and predict future results. We have analytically shown that the error scales at most as $O(t^{3/2})$. 

Our method can be applied to any other dynamical systems as well and will find application in other forms of property prediction for quantum systems. We recently came across a work \cite{shen2023estimating} that uses a similar protocol for phase estimation. In summary, our method could be used in multiple dynamical problems to obtain meaningful results in the near term quantum devices.


\section{Acknowledgement}
The authors would like to thank Yizhi Shen and Nathan Wiebe for useful discussions. 
This work was supported by the U.S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research through the Accelerated Research in Quantum Computing Program (NG, WAdJ). This work was also supported by the Center for Computational Study of Excited-State Phenomena in Energy Materials (C2SEPEM) at the Lawrence Berkeley National Laboratory, which is funded by the U.\,S. Department of Energy, Office of Science, Basic Energy Sciences, Materials Sciences and Engineering Division, under Contract No. DE-AC02-05CH11231, as part of the Computational Materials Sciences Program (JY, CY).


\bibliography{sample.bib}
\bibliographystyle{apsrev4-1}

\appendix

\section{Operator Expectation}
\begin{lemma}\label{lemma:util}
For any unit wave function $|\psi\rangle\in\mathbb{C}^N$ and matrix $O\in\mathbb{C}^{N\times N}$,
\be
\langle\psi|O|\psi\rangle \leq \|O\|_2 \leq \|O\|_F,
\ee
where $\|\cdot\|_2$ and $\|\cdot\|_F$ stand for the $L^2$ and the Frobenius norms for matrices, respectively.
\end{lemma}
\begin{proof}
    From Cauchy inequality, we have
    \be
      \langle\psi|O|\psi\rangle \leq \langle\psi|\psi\rangle\langle O\psi|O\psi\rangle.
    \ee
    Recall the definition
    \be
      \|O\|_2 = {\rm sup}_{|\psi\rangle\neq 0}\dfrac{\langle O\psi|O\psi\rangle}{\langle\psi|\psi\rangle},
    \ee
    by using the fact that $\langle\psi|\psi\rangle=1$, we arrive at
    \be
      \langle\psi|O|\psi\rangle\leq \langle\psi|\psi\rangle\|O\|_2 = \|O\|_2\leq \|O\|_F,
    \ee
    where the last inequality holds naturally.
\end{proof}

\section{Quenching in XXZ model}
% Figure environment removed
We consider one-dimensional spin-1/2 chains consisting of $L$ spins, initially prepared in a domain wall configuration $\ket{...\uparrow\uparrow\downarrow\downarrow}...$. The time evolution after the quantum quench is led by the Hamiltonian,
\be
\begin{aligned}
H = &-\sum_{j=1}^{L-1}\qty( X_{j}X_{j+1} + Y_{j}Y_{j+1}) \\
&+ U \sum_{j=1}^{L-1}Z_{j}Z_{j+1} + h\sum_{j=1}^{L}Z_{j}
\end{aligned}
\ee
where $\qty{X,Y,Z}$ are Pauli matrices with eigenvalues $\pm 1$. In our calculation we choose $U=4.0$ and $h=0.1$. We calculate spin-spin correlation $\ev{Z_{j}Z_{j+1}}$ as a function of time. The results are shown in Fig.~\ref{fig:spin_time}. The extrapolation has been done using the data within the shaded cyan region. For clarity in vision, we show the plots for $\ev{S^{z}_{1}(t)S^{z}_{3}(t)}$ for $L=6$ and $\ev{S^{z}_{1}(t)S^{z}_{6}(t)}$ for $L=12$. We have tested our methods for other sets of correlation functions and they yield similar accuracy.

\label{appendix:xxz}


\end{document}