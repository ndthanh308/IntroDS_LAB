%comment{This file was created with betterbib v3.5.15.}

@unpublished{729T-course-project,
  author = {Priyanka Kaswan and Sagnik Bhattacharya},
  title  = {Bandit Algorithms for Most Informative Arms: Course Project for {ENEE}729{T}, {I}nformation Theoretic Methods in Learning ({UMD})},
  year   = {2021},
  note   = {unpublished}
}

@article{Aaronson_2019,
  author    = {Aaronson, Scott and Chen, Xinyi and Hazan, Elad and Kale, Satyen and Nayak, Ashwin},
  title     = {Online learning of quantum states},
  volume    = {2019},
  issn      = {1742-5468},
  url       = {https://doi.org/10.1088/1742-5468/ab3988},
  doi       = {10.1088/1742-5468/ab3988},
  number    = {12},
  journal   = {J. Stat. Mech.},
  publisher = {IOP Publishing},
  year      = {2019},
  month     = dec,
  pages     = {124019},
  source    = {Crossref}
}

@article{aaronson2018shadow,
  author  = {Aaronson, Scott},
  title   = {Shadow Tomography of Quantum States},
  journal = {SIAM Journal on Computing},
  volume  = {49},
  number  = {5},
  pages   = {STOC18-368-STOC18-394},
  year    = {2020},
  doi     = {10.1137/18M120275X},
  url     = {https://doi.org/10.1137/18M120275X},
  eprint  = {https://doi.org/10.1137/18M120275X}
}

@misc{aaronson2019gentle,
  title         = {Gentle Measurement of Quantum States and Differential Privacy},
  author        = {Scott Aaronson and Guy N. Rothblum},
  year          = {2019},
  eprint        = {1904.08747},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@article{Abdallah2010AMO,
  title   = {A measure of statistical complexity based on predictive information},
  author  = {Samer A. Abdallah and Mark D. Plumbley},
  journal = {ArXiv},
  year    = {2010},
  volume  = {abs/1012.1890}
}

@misc{acharya2017measuring,
  author        = {Acharya, Jayadev and Issa, Ibrahim and Shende, Nirmal V. and Wagner, Aaron B.},
  title         = {Measuring Quantum Entropy},
  year          = {2017},
  eprint        = {1711.00814},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@techreport{Alon-eigenvalues,
  author      = {Noga Alon and Michael Krivelevich and Van H. Vu},
  title       = {On the concentration of eigenvalues of random symmetric matrices},
  institution = {Israel J. Math},
  year        = {2000}
}

@misc{arunachalam2021private,
  title         = {Private learning implies quantum stability},
  author        = {Srinivasan Arunachalam and Yihui Quek and John Smolin},
  year          = {2021},
  eprint        = {2102.07171},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@inproceedings{audibert-best-arm-identification,
  author    = {Jean-yves Audibert and Sébastien Bubeck and Rémi Munos},
  title     = {Best arm identification in multi-armed bandits},
  booktitle = {Proceedings of the Twenty-Third Annual Conference on Learning Theory},
  year      = {2010},
  pages     = {41--53}
}

@misc{badescu2020improved,
  title         = {Improved quantum data analysis},
  author        = {Costin Bădescu and Ryan O'Donnell},
  year          = {2020},
  eprint        = {2011.10908},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@inproceedings{balle2017endtoend,
  title     = {End-to-end Optimized Image Compression},
  author    = {Johannes Ball{\'e} and Valero Laparra and Eero P. Simoncelli},
  booktitle = {International Conference on Learning Representations},
  year      = {2017},
  url       = {https://openreview.net/forum?id=rJxdQ3jeg}
}

@book{Berger1971RateDT,
  author    = {Berger, T.},
  title     = {Rate Distortion Theory: {A} Mathematical Basis for Data Compression},
  year      = {1971},
  publisher = {Prentice-Hall, Englewood Cliffs, NJ}
}


@book{bishop-prml,
  author    = {Bishop, Christopher M.},
  title     = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
  year      = {2006},
  isbn      = {0387310738},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg}
}

@article{boda-narayan-sampling-rate-distortion,
  author    = {Boda, Vinay Praneeth and Narayan, Prakash},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Sampling Rate Distortion},
  year      = {2017},
  volume    = {63},
  number    = {1},
  pages     = {563-574},
  doi       = {10.1109/tit.2016.2633256},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2016.2633256},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448, 1557-9654},
  month     = jan
}

@article{boda-narayan-universal-sampling-rate-distortion,
  author    = {Boda, Vinay Praneeth and Narayan, Prakash},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Universal Sampling Rate Distortion},
  year      = {2018},
  volume    = {64},
  number    = {12},
  pages     = {7742-7758},
  doi       = {10.1109/tit.2018.2857829},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2018.2857829},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448, 1557-9654},
  month     = dec
}

@inproceedings{boda-prashanth-correlated-bandits,
  title     = {Correlated bandits or: {H}ow to minimize mean-squared error online},
  author    = {Boda, Vinay Praneeth and Prashanth, L. A.},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {686--694},
  year      = {2019},
  volume    = {97},
  month     = {6},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/boda19a/boda19a.pdf},
  url       = {http://proceedings.mlr.press/v97/boda19a.html},
  abstract  = {While the objective in traditional multi-armed bandit problems is to find the arm with the highest mean, in many settings, finding an arm that best captures information about other arms is of interest. This objective, however, requires learning the underlying correlation structure and not just the means. Sensors placement for industrial surveillance and cellular network monitoring are a few applications, where the underlying correlation structure plays an important role. Motivated by such applications, we formulate the correlated bandit problem, where the objective is to find the arm with the lowest mean-squared error (MSE) in estimating all the arms. To this end, we derive first an MSE estimator based on sample variances/covariances and show that our estimator exponentially concentrates around the true MSE. Under a best-arm identification framework, we propose a successive rejects type algorithm and provide bounds on the probability of error in identifying the best arm. Using minimax theory, we also derive fundamental performance limits for the correlated bandit problem.}
}

@misc{brandao2019quantum,
  title         = {Quantum SDP Solvers: Large Speed-ups, Optimality, and Applications to Quantum Learning},
  author        = {Fernando G. S. L. Brandão and Amir Kalev and Tongyang Li and Cedric Yen-Yu Lin and Krysta M. Svore and Xiaodi Wu},
  year          = {2019},
  eprint        = {1710.02581},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}


@misc{bubeck2020entanglement,
  title         = {Entanglement is Necessary for Optimal Quantum Property Testing},
  author        = {Sebastien Bubeck and Sitan Chen and Jerry Li},
  year          = {2020},
  eprint        = {2004.07869},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@book{cesa-bianchi_lugosi_2006,
  place     = {Cambridge},
  title     = {Prediction, Learning, and Games},
  doi       = {10.1017/CBO9780511546921},
  publisher = {Cambridge University Press},
  author    = {Cesa-Bianchi, Nicolo and Lugosi, Gabor},
  year      = {2006}
}


@article{chan-change-of-mmi,
  author  = {Chan, Chung and Al-Bashabsheh, Ali and Zhou, Qiaoqiao},
  journal = {IEEE Transactions on Information Theory},
  title   = {Change of Multivariate Mutual Information: From Local to Global},
  year    = {2018},
  volume  = {64},
  number  = {1},
  pages   = {57-76},
  doi     = {10.1109/TIT.2017.2749372}
}

@article{chan-clustering,
  author  = {Chan, Chung and Al-Bashabsheh, Ali and Zhou, Qiaoqiao},
  journal = {IEEE Transactions on Information Theory},
  title   = {Agglomerative Info-Clustering: Maximizing Normalized Total Correlation},
  year    = {2021},
  volume  = {67},
  number  = {3},
  pages   = {2001-2011},
  doi     = {10.1109/TIT.2020.3040492}
}

@phdthesis{chan-generating-secret,
  author    = {Chung Chan},
  title     = {Generating secret in a network},
  school    = {Massachusetts Institute of Technology, Cambridge, MA, {USA}},
  year      = {2010},
  url       = {http://hdl.handle.net/1721.1/62386},
  timestamp = {Mon, 10 Apr 2017 16:55:18 +0200},
  biburl    = {https://dblp.org/rec/phd/ndltd/Chan10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{chan-hidden-flow,
  title   = {The hidden flow of information},
  author  = {Chung Chan},
  journal = {2011 IEEE International Symposium on Information Theory Proceedings},
  year    = {2011},
  pages   = {978-982}
}


@article{chan-info-clustering,
  title   = {Info-Clustering: A Mathematical Theory for Data Clustering},
  author  = {Chung Chan and Ali Al-Bashabsheh and Qiaoqiao Zhou and Tarik Kaced and Tie Liu},
  journal = {IEEE Transactions on Molecular, Biological and Multi-Scale Communications},
  year    = {2016},
  pages   = {64-91}
}

@inproceedings{chan-linear-perfect,
  author    = {Chan, Chung},
  booktitle = {2011 IEEE Information Theory Workshop},
  title     = {Linear perfect secret key agreement},
  year      = {2011},
  volume    = {},
  number    = {},
  pages     = {723-726},
  doi       = {10.1109/ITW.2011.6089530}
}

@inproceedings{chan-mutual-dependence,
  author    = {Chung Chan and Lizhong Zheng},
  booktitle = {2010 44th Annual Conference on Information Sciences and Systems (CISS)},
  title     = {Mutual dependence for secret key agreement},
  year      = {2010},
  volume    = {},
  number    = {},
  pages     = {1-6},
  doi       = {10.1109/CISS.2010.5464805}
}


@article{chan-shared-information,
  author  = {Chan, Chung and Al-Bashabsheh, Ali and Ebrahimi, Javad B. and Kaced, Tarik and Liu, Tie},
  journal = {Proceedings of the IEEE},
  title   = {Multivariate Mutual Information Inspired by Secret-Key Agreement},
  year    = {2015},
  volume  = {103},
  number  = {10},
  pages   = {1883-1913},
  doi     = {10.1109/JPROC.2015.2458316}
}

@article{chan-successive,
  author  = {Chan, Chung and Al-Bashabsheh, Ali and Zhou, Qiaoqiao and Ding, Ni and Liu, Tie and Sprintson, Alex},
  journal = {IEEE Transactions on Information Theory},
  title   = {Successive Omniscience},
  year    = {2016},
  volume  = {62},
  number  = {6},
  pages   = {3270-3289},
  doi     = {10.1109/TIT.2016.2555923}
}

@article{chan-tightness,
  title   = {On Tightness of Mutual Dependence Upperbound for Secret-key Capacity of Multiple Terminals},
  author  = {Chung Chan},
  journal = {ArXiv},
  year    = {2008},
  volume  = {abs/0805.3200}
}


@article{chow-liu-trees,
  author  = {Chow, C. and Liu, C.},
  journal = {IEEE Transactions on Information Theory},
  title   = {Approximating discrete probability distributions with dependence trees},
  year    = {1968},
  pages   = {462-467},
  doi     = {10.1109/TIT.1968.1054142}
}

@article{chow-wagner,
  author  = {Chow, C. and Wagner, T.},
  journal = {IEEE Transactions on Information Theory},
  title   = {Consistency of an estimate of tree-dependent probability distributions (Corresp.)},
  year    = {1973},
  volume  = {19},
  pages   = {369-371},
  doi     = {10.1109/TIT.1973.1055013}
}

@book{clrs,
  author    = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
  title     = {Introduction to Algorithms, Third Edition},
  year      = {2009},
  isbn      = {0262033844},
  publisher = {The MIT Press},
  edition   = {3rd},
  abstract  = {If you had to buy just one text on algorithms, Introduction to Algorithms is a magnificent choice. The book begins by considering the mathematical foundations of the analysis of algorithms and maintains this mathematical rigor throughout the work. The tools developed in these opening sections are then applied to sorting, data structures, graphs, and a variety of selected algorithms including computational geometry, string algorithms, parallel models of computation, fast Fourier transforms (FFTs), and more. This book's strength lies in its encyclopedic range, clear exposition, and powerful analysis. Pseudo-code explanation of the algorithms coupled with proof of their accuracy makes this book is a great resource on the basic tools used to analyze the performance of algorithms.}
}

@article{courtade-coded-cooperative,
  title   = {Coded Cooperative Data Exchange for a Secret Key},
  author  = {Thomas A. Courtade and Thomas R. Halford},
  journal = {IEEE Transactions on Information Theory},
  year    = {2016},
  volume  = {62},
  pages   = {3785-3795}
}

@article{csiszar-narayan-secrecy-capacities,
  author    = {Csisz{\'a}r, I. and Narayan, P.},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Secrecy Capacities for Multiple Terminals},
  year      = {2004},
  volume    = {50},
  number    = {12},
  pages     = {3047-3061},
  doi       = {10.1109/tit.2004.838380},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2004.838380},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448},
  month     = dec
}

@article{Csiszar-tusnady,
  author = {Csisz{\'{a}}r, I. and Tusn{\'{a}}dy, G.},
  file   = {:Users/brekels/Documents/Mendeley Desktop/Information Geometry and Alternating Minimization Procedures - Csisz{\'{a}}r, Tusn{\'{a}}dy.pdf:pdf},
  title  = {{Information Geometry and Alternating Minimization Procedures}}
}

@book{csiszar2011information,
  title     = {Information Theory: Coding Theorems for Discrete Memoryless Systems},
  author    = {Csisz{\'a}r, I. and K{\"o}rner, J.},
  isbn      = {9781139499989},
  url       = {https://books.google.com/books?id=2gsLkQlb8JAC},
  year      = {2011},
  publisher = {Cambridge University Press}
}

@article{Datta_2013,
  title     = {Quantum Rate Distortion, Reverse {S}hannon Theorems, and Source-Channel Separation},
  volume    = {59},
  issn      = {1557-9654},
  url       = {http://dx.doi.org/10.1109/TIT.2012.2215575},
  doi       = {10.1109/tit.2012.2215575},
  number    = {1},
  journal   = {IEEE Transactions on Information Theory},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Datta, Nilanjana and Hsieh, Min-Hsiu and Wilde, Mark M.},
  year      = {2013},
  month     = {Jan},
  pages     = {615–630}
}

@article{datta-q2c-rate-distortion,
  author  = {Datta,Nilanjana  and Hsieh,Min-Hsiu  and Wilde,Mark M.  and Winter,Andreas },
  title   = {Quantum-to-classical rate distortion coding},
  journal = {Journal of Mathematical Physics},
  volume  = {54},
  number  = {4},
  pages   = {042201},
  year    = {2013},
  doi     = {10.1063/1.4798396},
  url     = {https://doi.org/10.1063/1.4798396},
  eprint  = {https://doi.org/10.1063/1.4798396}
}

@article{datta-quantum-rate-distortion,
  author  = {Datta, Nilanjana and Hsieh, Min-Hsiu and Wilde, Mark M.},
  journal = {IEEE Transactions on Information Theory},
  title   = {Quantum Rate Distortion, Reverse {S}hannon Theorems, and Source-Channel Separation},
  year    = {2013},
  volume  = {59},
  number  = {1},
  pages   = {615-630},
  doi     = {10.1109/TIT.2012.2215575}
}

@article{dembo2003minimax,
  author    = {Dembo, A. and Weissman, T.},
  title     = {The minimax distortion redundancy in noisy source coding},
  journal   = {IEEE Transactions on Information Theory},
  volume    = {49},
  number    = {11},
  pages     = {3020-3030},
  year      = {2003},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  doi       = {10.1109/tit.2003.819336},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2003.819336},
  issn      = {0018-9448},
  month     = nov
}

@article{dempster1977maximum,
  author    = {Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
  title     = {Maximum likelihood from incomplete data via the {EM} algorithm},
  journal   = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume    = {39},
  number    = {1},
  pages     = {1--22},
  year      = {1977},
  publisher = {Wiley Online Library}
}

@article{dobrushin-tsybakov-information-transmission-with-additional-noise,
  author    = {Dobrushin, R. and Tsybakov, B.},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Information transmission with additional noise},
  year      = {1962},
  volume    = {8},
  number    = {5},
  pages     = {293-304},
  doi       = {10.1109/tit.1962.1057738},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.1962.1057738},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448},
  month     = sep
}

@article{feng-dynamic-sampling,
  title   = {Dynamic sampling from graphical models},
  author  = {Weiming Feng and Nisheeth K. Vishnoi and Yitong Yin},
  journal = {Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing},
  year    = {2019}
}

@article{gacs-common-information,
  author  = {G\'acs, Peter and K\"orner, J.},
  year    = {1973},
  month   = {01},
  pages   = {},
  title   = {Common information is far less than mutual information},
  volume  = {2},
  journal = {Problems of Control and Information Theory}
}

@book{Georgii+2011,
  author    = {Hans-Otto Georgii},
  doi       = {doi:10.1515/9783110250329},
  url       = {https://doi.org/10.1515/9783110250329},
  title     = {Gibbs Measures and Phase Transitions},
  year      = {2011},
  publisher = {De Gruyter},
  isbn      = {9783110250329}
}

@article{goppa-mi,
  year    = {1975},
  volume  = {4},
  journal = {Problems of Control and Information Theory},
  title   = {Nonprobabilistic mutual information without memory},
  pages   = {97-102},
  author  = {Valery D. Goppa}
}


@book{grimmett2010probability,
  title     = {Probability on Graphs: Random Processes on Graphs and Lattices},
  author    = {Grimmett, G.},
  isbn      = {9781139488365},
  series    = {Institute of Mathematical Statistics Textbooks},
  url       = {https://books.google.com/books?id=4gvbDUw95KEC},
  year      = {2010},
  publisher = {Cambridge University Press}
}

@book{gs009,
  author    = {Canonne, Cl{\'{e}}ment L.},
  title     = {A Survey on Distribution Testing: Your Data is Big. But is it Blue?},
  year      = {2020},
  pages     = {1--100},
  doi       = {10.4086/toc.gs.2020.009},
  publisher = {Theory of Computing Library},
  number    = {9},
  series    = {Graduate Surveys},
  url       = {http://www.theoryofcomputing.org/library.html}
}

@article{gupta-mabs-correlated-arms,
  doi       = {10.1109/tit.2021.3081508},
  url       = {https://doi.org/10.1109%2Ftit.2021.3081508},
  year      = 2021,
  month     = {oct},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume    = {67},
  number    = {10},
  pages     = {6711--6732},
  author    = {Samarth Gupta and Shreyas Chaudhari and Gauri Joshi and Osman Yagan},
  title     = {Multi-Armed Bandits With Correlated Arms},
  journal   = {{IEEE} Transactions on Information Theory}
}

@misc{guta2018fast,
  author        = {Guta, Madalin and Kahn, Jonas and Kueng, Richard and Tropp, Joel A.},
  title         = {Fast state tomography with optimal error bounds},
  year          = {2018},
  eprint        = {1809.11162},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@article{Haah_2017,
  author    = {Haah, Jeongwan and Harrow, Aram W. and Ji, Zhengfeng and Wu, Xiaodi and Yu, Nengkun},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Sample-optimal tomography of quantum states},
  year      = {2017},
  volume    = {63},
  number    = {9},
  pages     = {1-1},
  doi       = {10.1109/tit.2017.2719044},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2017.2719044},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448, 1557-9654}
}

@article{hajek-decomposition-theorem,
  author    = {Bruce Hajek and Toby Berger},
  title     = {A Decomposition Theorem for Binary {M}arkov Random Fields},
  volume    = {15},
  journal   = {The Annals of Probability},
  number    = {3},
  publisher = {Institute of Mathematical Statistics},
  pages     = {1112 -- 1125},
  keywords  = {Gibbs random field, Ising model, Markov random field, rate-distortion function},
  year      = {1987},
  doi       = {10.1214/aop/1176992084},
  url       = {https://doi.org/10.1214/aop/1176992084}
}

@inproceedings{hamilton-it-properties-of-mrfs,
  author    = {Hamilton, Linus and Koehler, Frederic and Moitra, Ankur},
  title     = {Information Theoretic Properties of {M}arkov Random Fields, and Their Algorithmic Applications},
  year      = {2017},
  isbn      = {9781510860964},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {Markov random fields are a popular model for high-dimensional probability distributions.
               Over the years, many mathematical, statistical and algorithmic problems on them have
               been studied. Until recently, the only known algorithms for provably learning them
               relied on exhaustive search, correlation decay or various incoherence assumptions.
               Bresler [4] gave an algorithm for learning general Ising models on bounded degree
               graphs. His approach was based on a structural result about mutual information in
               Ising models.Here we take a more conceptual approach to proving lower bounds on the
               mutual information. Our proof generalizes well beyond Ising models, to arbitrary Markov
               random fields with higher order interactions. As an application, we obtain algorithms
               for learning Markov random fields on bounded degree graphs on n nodes with r-order
               interactions in nr time and log n sample complexity. Our algorithms also extend to
               various partial observation models.},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages     = {2460–2469},
  numpages  = {10},
  location  = {Long Beach, California, USA},
  series    = {NIPS'17}
}

@article{han-nonnegative,
  title   = {Nonnegative entropy measures of multivariate symmetric correlations},
  journal = {Information and Control},
  volume  = {36},
  number  = {2},
  pages   = {133-156},
  year    = {1978},
  issn    = {0019-9958},
  doi     = {https://doi.org/10.1016/S0019-9958(78)90275-9},
  url     = {https://www.sciencedirect.com/science/article/pii/S0019995878902759},
  author  = {Te Sun Han}
}

@article{Huang_2020,
  author    = {Huang, Hsin-Yuan and Kueng, Richard and Preskill, John},
  title     = {Predicting many properties of a quantum system from very few measurements},
  volume    = {16},
  issn      = {1745-2473, 1745-2481},
  url       = {https://doi.org/10.1038/s41567-020-0932-7},
  doi       = {10.1038/s41567-020-0932-7},
  number    = {10},
  journal   = {Nat. Phys.},
  publisher = {Springer Science and Business Media LLC},
  year      = {2020},
  month     = jun,
  pages     = {1050-1057},
  source    = {Crossref}
}

@inproceedings{isitsub,
  author    = {Boda, Vinay Praneeth and Narayan, Prakash},
  title     = {Sampling rate distortion},
  year      = {2014},
  note      = {unpublished},
  doi       = {10.1109/isit.2014.6875396},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/isit.2014.6875396},
  booktitle = {2014 IEEE International Symposium on Information Theory},
  publisher = {IEEE},
  isbn      = {9781479951864},
  month     = jun
}

@article{jiao-minimax,
  author  = {Jiao, Jiantao and Venkat, Kartik and Han, Yanjun and Weissman, Tsachy},
  journal = {IEEE Transactions on Information Theory},
  title   = {Minimax Estimation of Functionals of Discrete Distributions},
  year    = {2015},
  volume  = {61},
  number  = {5},
  pages   = {2835-2885},
  doi     = {10.1109/TIT.2015.2412945}
}


@inproceedings{kashyap2005distributed,
  author       = {Kashyap, Akshay and Lastras-Montano, Luis Alfonso and Xia, Cathy and Liu, Zhen},
  title        = {Distributed Source Coding in Dense Sensor Networks},
  booktitle    = {Data Compression Conference},
  pages        = {13--22},
  year         = {2005},
  organization = {IEEE},
  doi          = {10.1109/dcc.2005.33},
  source       = {Crossref},
  url          = {https://doi.org/10.1109/dcc.2005.33},
  publisher    = {IEEE},
  isbn         = {0769523099}
}

@article{kaufmann-complexity,
  author     = {Kaufmann, Emilie and Capp\'{e}, Olivier and Garivier, Aur\'{e}lien},
  title      = {On the Complexity of Best-Arm Identification in Multi-Armed Bandit Models},
  year       = {2016},
  issue_date = {January 2016},
  publisher  = {JMLR.org},
  volume     = {17},
  number     = {1},
  issn       = {1532-4435},
  abstract   = {The stochastic multi-armed bandit model is a simple abstraction that has proven useful in many different contexts in statistics and machine learning. Whereas the achievable limit in terms of regret minimization is now well known, our aim is to contribute to a better understanding of the performance in terms of identifying the m best arms. We introduce generic notions of complexity for the two dominant frameworks considered in the literature: fixed-budget and fixed-confidence settings. In the fixed-confidence setting, we provide the first known distribution-dependent lower bound on the complexity that involves information-theoretic quantities and holds when m ≥ 1 under general assumptions. In the specific case of two armed-bandits, we derive refined lower bounds in both the fixedcon fidence and fixed-budget settings, along with matching algorithms for Gaussian and Bernoulli bandit models. These results show in particular that the complexity of the fixed-budget setting may be smaller than the complexity of the fixed-confidence setting, contradicting the familiar behavior observed when testing fully specified alternatives. In addition, we also provide improved sequential stopping rules that have guaranteed error probabilities and shorter average running times. The proofs rely on two technical results that are of independent interest: a deviation lemma for self-normalized sums (Lemma 7) and a novel change of measure inequality for bandit models (Lemma 1).},
  journal    = {J. Mach. Learn. Res.},
  month      = {jan},
  pages      = {1–42},
  numpages   = {42},
  keywords   = {pure exploration, multi-armed bandit, best-arm identification, information-theoretic divergences, sequential testing}
}

@article{kipnis-goldsmith-eldar-weissman-distortion-rate-function-of-sub-nyquist-sampled-gaussian-sources,
  author    = {Kipnis, Alon and Goldsmith, Andrea J. and Eldar, Yonina C. and Weissman, Tsachy},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Distortion Rate Function of Sub-Nyquist Sampled {Gaussian} Sources},
  year      = {2016},
  volume    = {62},
  number    = {1},
  pages     = {401-429},
  doi       = {10.1109/tit.2015.2485271},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2015.2485271},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448, 1557-9654},
  month     = jan
}

@misc{koh2020classical,
  title         = {Classical Shadows with Noise},
  author        = {Dax Enshan Koh and Sabee Grewal},
  year          = {2020},
  eprint        = {2011.11580},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@book{koller-friedman-pgm,
  author    = {Koller, Daphne and Friedman, Nir},
  title     = {Probabilistic Graphical Models: Principles and Techniques - Adaptive Computation and Machine Learning},
  year      = {2009},
  isbn      = {0262013193},
  publisher = {The MIT Press},
  abstract  = {Most tasks require a person or an automated system to reasonto reach conclusions based on available information. The framework of probabilistic graphical models, presented in this book, provides a general approach for this task. The approach is model-based, allowing interpretable models to be constructed and then manipulated by reasoning algorithms. These models can also be learned automatically from data, allowing the approach to be used in cases where manually constructing a model is difficult or even impossible. Because uncertainty is an inescapable aspect of most real-world applications, the book focuses on probabilistic models, which make the uncertainty explicit and provide models that are more faithful to reality. Probabilistic Graphical Models discusses a variety of models, spanning Bayesian networks, undirected Markov networks, discrete and continuous models, and extensions to deal with dynamical systems and relational data. For each class of models, the text describes the three fundamental cornerstones: representation, inference, and learning, presenting both basic concepts and advanced techniques. Finally, the book considers the use of the proposed framework for causal reasoning and decision making under uncertainty. The main text in each chapter provides the detailed technical development of the key ideas. Most chapters also include boxes with additional material: skill boxes, which describe techniques; case study boxes, which discuss empirical cases related to the approach described in the text, including applications in computer vision, robotics, natural language understanding, and computational biology; and concept boxes, which present significant concepts drawn from the material in the chapter. Instructors (and readers) can group chapters in various combinations, from core topics to more technically advanced material, to suit their particular needs. Adaptive Computation and Machine Learning series}
}

@article{konsbruck2012sampling,
  author    = {Konsbruck, Robert L. and Telatar, Emre and Vetterli, Martin},
  title     = {On Sampling and Coding for Distributed Acoustic Sensing},
  journal   = {IEEE Transactions on Information Theory},
  volume    = {58},
  number    = {5},
  pages     = {3198-3214},
  year      = {2012},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  doi       = {10.1109/tit.2012.2184849},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2012.2184849},
  issn      = {0018-9448, 1557-9654},
  month     = may
}

@article{kontoyiannis,
  author   = {Antos, András and Kontoyiannis, Ioannis},
  title    = {{Convergence properties of functional estimates for discrete distributions}},
  journal  = {Random Structures \& Algorithms},
  volume   = {19},
  number   = {3‐4},
  pages    = {163-193},
  keywords = {functional estimation, entropy estimation, rates of convergence, match lengths},
  doi      = {https://doi.org/10.1002/rsa.10019},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rsa.10019},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/rsa.10019},
  abstract = {Abstract Suppose P is an arbitrary discrete distribution on acountable alphabet ��. Given an i.i.d. sample (X1,…,Xn) drawnfrom P, we consider the problem of estimating the entropy H(P) or some other functional F=F(P) of the unknown distribution P. We show that, for additive functionals satisfying mild conditions (including the cases of the mean, the entropy, and mutual information), the plug-in estimates of F are universally consistent. We also prove that, without further assumptions, no rate-of-convergence results can be obtained for any sequence of estimators. In the case of entropy estimation, under a variety of different assumptions, we get rate-of-convergence results for the plug-in estimate and for a nonparametric estimator based on match-lengths. The behavior of the variance and the expected error of the plug-in estimate is shown to be in sharp contrast to the finite-alphabet case. A number of other important examples of functionals are also treated in some detail. © 2001 John Wiley \& Sons, Inc. Random Struct. Alg., 19: 163–193, 2001},
  year     = {2001}
}

@book{koralov2007theory,
  title     = {Theory of Probability and Random Processes},
  author    = {Koralov, L. and Sinai, Y.G. and Sinaj, {\^A}.G.},
  isbn      = {9783540254843},
  lccn      = {2012943837},
  series    = {Universitext (Berlin. Print)},
  url       = {https://books.google.com/books?id=QILj7e\_iPZEC},
  year      = {2007},
  publisher = {Springer}
}

@article{kostina-verdu-fixed-length-lossy-compression-in-the-finite-blocklength-regime,
  author    = {Kostina, Victoria and Verd{\'u}, Sergio},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Fixed-Length Lossy Compression in the Finite Blocklength Regime},
  year      = {2012},
  volume    = {58},
  number    = {6},
  pages     = {3309-3338},
  doi       = {10.1109/tit.2012.2186786},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2012.2186786},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448, 1557-9654},
  month     = jun
}

@article{kostina-verdu-nonasymptotic-noisy-lossy-source-coding,
  author    = {Kostina, Victoria and Verd{\'u}, Sergio},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Nonasymptotic Noisy Lossy Source Coding},
  year      = {2016},
  volume    = {62},
  number    = {11},
  pages     = {6111-6123},
  doi       = {10.1109/tit.2016.2562008},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2016.2562008},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448, 1557-9654},
  month     = nov
}

@inproceedings{krause-optimal-sensor-placement,
  author    = {Guestrin, Carlos and Krause, Andreas and Singh, Ajit Paul},
  title     = {Near-Optimal Sensor Placements in Gaussian Processes},
  year      = {2005},
  isbn      = {1595931805},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1102351.1102385},
  doi       = {10.1145/1102351.1102385},
  abstract  = {When monitoring spatial phenomena, which are often modeled as Gaussian Processes (GPs), choosing sensor locations is a fundamental task. A common strategy is to place sensors at the points of highest entropy (variance) in the GP model. We propose a mutual information criteria, and show that it produces better placements. Furthermore, we prove that finding the configuration that maximizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1 -- 1/e) of the optimum by exploiting the submodularity of our criterion. This algorithm is extended to handle local structure in the GP, yielding significant speedups. We demonstrate the advantages of our approach on two real-world data sets.},
  booktitle = {Proceedings of the 22nd International Conference on Machine Learning},
  pages     = {265–272},
  numpages  = {8},
  location  = {Bonn, Germany},
  series    = {ICML '05}
}

@book{lauritzen1996,
  added-at  = {2010-03-25T16:34:59.000+0100},
  author    = {Lauritzen, Steffen L.},
  biburl    = {https://www.bibsonomy.org/bibtex/2ced39d23200f7ae9a7c38e5e65b6e416/3mta3},
  interhash = {1fbc2c33d8565597e6fb80a796effff2},
  intrahash = {ced39d23200f7ae9a7c38e5e65b6e416},
  isbn      = {0-19-852219-3},
  keywords  = {},
  publisher = {Oxford University Press},
  timestamp = {2010-03-25T16:34:59.000+0100},
  title     = {Graphical Models},
  year      = 1996
}

@article{lindblad-Completely-Positive-Maps-and-Entropy-Inequalities,
  author    = {Lindblad, Göran},
  title     = {Completely positive maps and entropy inequalities},
  volume    = {40},
  journal   = {Commun.Math. Phys.},
  number    = {2},
  publisher = {Springer Science and Business Media LLC},
  pages     = {147-151},
  year      = {1975},
  doi       = {10.1007/bf01609396},
  url       = {https://doi.org/10.1007/bf01609396},
  source    = {Crossref},
  issn      = {0010-3616, 1432-0916},
  month     = jun
}

@article{linder1997empirical,
  author    = {Linder, T. and Lugosi, G. and Zeger, K.},
  title     = {Empirical quantizer design in the presence of source noise or channel noise},
  journal   = {IEEE Transactions on Information Theory},
  volume    = {43},
  number    = {2},
  pages     = {612-623},
  year      = {1997},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  doi       = {10.1109/18.556117},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/18.556117},
  issn      = {0018-9448},
  month     = mar
}

@misc{liu-bubeck-most-correlated-arms-identification,
  author        = {Liu, Che-Yu and Bubeck, Sébastien},
  title         = {Most Correlated Arms Identification},
  year          = {2014},
  eprint        = {1404.5903},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}

@article{liu-common-information,
  title   = {The common information of N dependent random variables},
  author  = {W. Liu and Ge Xu and Biao Chen},
  journal = {2010 48th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  year    = {2010},
  pages   = {836-843}
}

@article{liu2013lossy,
  author    = {Liu, Xi and Simeone, Osvaldo and Erkip, Elza},
  title     = {Lossy Computing of Correlated Sources with Fractional Sampling},
  journal   = {IEEE Trans. Commun.},
  volume    = {61},
  number    = {9},
  pages     = {3685-3696},
  year      = {2013},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  doi       = {10.1109/tcomm.2013.072913.120876},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tcomm.2013.072913.120876},
  issn      = {0090-6778},
  month     = sep
}

@book{mackay-information-theory,
  author    = {MacKay, David J. C.},
  title     = {Information Theory, Inference \& Learning Algorithms},
  year      = {2002},
  isbn      = {0521642981},
  publisher = {Cambridge University Press},
  address   = {USA}
}

@misc{montanaro2018survey,
  title         = {A Survey of Quantum Property Testing},
  author        = {Ashley Montanaro and Ronald de Wolf},
  year          = {2018},
  eprint        = {1310.2035},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@unpublished{narayan-banff,
  title  = {Interactive multiterminal communication},
  author = {Prakash Narayan},
  year   = {2014},
  note   = {Invited talk, \emph{Workshop on Optimal Cooperation, Communication, and Learning in Decentralized Systems}, Banff, AB, Canada 2014}
}

@unpublished{narayan-isit,
  title  = {Omniscience and secrecy},
  author = {Prakash Narayan},
  year   = {2012},
  note   = {Plenary Talk, \emph{IEEE International Symposium on Information Theory}, Cambridge, MA}
}


@article{nash-williams,
  author  = {Nash-Williams, C. St.J. A.},
  title   = {{Edge-Disjoint Spanning Trees of Finite Graphs}},
  journal = {Journal of the London Mathematical Society},
  volume  = {s1-36},
  number  = {1},
  pages   = {445-450},
  year    = {1961},
  month   = {01},
  issn    = {0024-6107},
  doi     = {10.1112/jlms/s1-36.1.445},
  url     = {https://doi.org/10.1112/jlms/s1-36.1.445},
  eprint  = {https://academic.oup.com/jlms/article-pdf/s1-36/1/445/2469846/s1-36-1-445.pdf}
}


@article{neuhoff1975fixed,
  author    = {Neuhoff, D. and Gray, R. and Davisson, L.},
  title     = {Fixed rate universal block source coding with a fidelity criterion},
  journal   = {IEEE Transactions on Information Theory},
  volume    = {21},
  number    = {5},
  pages     = {511-523},
  year      = {1975},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  doi       = {10.1109/tit.1975.1055439},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.1975.1055439},
  issn      = {0018-9448},
  month     = sep
}

@inproceedings{neuhoff2011information,
  author       = {Neuhoff, David L. and Pradhan, S. Sandeep},
  title        = {Information rates of densely sampled {Gaussian} data},
  booktitle    = {2011 IEEE International Symposium on Information Theory Proceedings},
  pages        = {2776--2780},
  year         = {2011},
  organization = {IEEE},
  doi          = {10.1109/isit.2011.6034079},
  source       = {Crossref},
  url          = {https://doi.org/10.1109/isit.2011.6034079},
  publisher    = {IEEE},
  isbn         = {9781457705960},
  month        = jul
}

@article{nitinawarat-perfect,
  title   = {Perfect Omniscience, Perfect Secrecy, and {S}teiner Tree Packing},
  author  = {Sirin Nitinawarat and Prakash Narayan},
  journal = {IEEE Transactions on Information Theory},
  year    = {2010},
  volume  = {56},
  pages   = {6490-6500}
}


@article{nitinawarat-secret-key,
  author     = {Nitinawarat, Sirin and Ye, Chunxuan and Barg, Alexander and Narayan, Prakash and Reznik, Alex},
  title      = {Secret Key Generation for a Pairwise Independent Network Model},
  year       = {2010},
  issue_date = {December 2010},
  publisher  = {IEEE Press},
  volume     = {56},
  number     = {12},
  issn       = {0018-9448},
  abstract   = {We consider secret key generation for a "pairwise independent network" model in which every pair of terminals observes correlated sources that are independent of sources observed by all other pairs of terminals. The terminals are then allowed to communicate publicly with all such communication being observed by all the terminals. The objective is to generate a secret key shared by a given subset of terminals at the largest rate possible, with the cooperation of any remaining terminals. Secrecy is required from an eavesdropper that has access to the public interterminal communication. A (single-letter) formula for secret key capacity brings out a natural connection between the problem of secret key generation and a combinatorial problem of maximal packing of Steiner trees in an associated multigraph. An explicit algorithm is proposed for secret key generation based on a maximal packing of Steiner trees in a multigraph; the corresponding maximum rate of Steiner tree packing is thus a lower bound for the secret key capacity. When only two of the terminals or when all the terminals seek to share a secret key, the mentioned algorithm achieves secret key capacity in which case the bound is tight.},
  journal    = {IEEE Transactions on Information Theory},
  month      = {12},
  pages      = {6482–6489},
  numpages   = {8},
  keywords   = {private key, Steiner tree packing, wiretap secret key, PIN model, steiner tree packing, public communication, spanning tree packing, security index, secret key capacity}
}

@misc{odonnell2015efficient,
  author        = {O'Donnell, Ryan and Wright, John},
  title         = {Efficient quantum tomography},
  year          = {2015},
  eprint        = {1508.01907},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@misc{odonnell2015quantum,
  title         = {Quantum Spectrum Testing},
  author        = {Ryan O'Donnell and John Wright},
  year          = {2015},
  eprint        = {1501.05028},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph}
}

@article{paninski,
  author     = {Paninski, Liam},
  title      = {Estimation of Entropy and Mutual Information},
  year       = {2003},
  issue_date = {June 2003},
  publisher  = {MIT Press},
  address    = {Cambridge, MA, USA},
  volume     = {15},
  number     = {6},
  issn       = {0899-7667},
  url        = {https://doi.org/10.1162/089976603321780272},
  doi        = {10.1162/089976603321780272},
  journal    = {Neural Computation},
  month      = {6},
  pages      = {1191–1253},
  numpages   = {63}
}

@inproceedings{pearl-bayes,
  author    = {Pearl, Judea},
  title     = {Reverend {B}ayes on Inference Engines: A Distributed Hierarchical Approach},
  year      = {1982},
  publisher = {AAAI Press},
  abstract  = {This paper presents generalizations of Bayes likelihood-ratio updating rule which facilitate an asynchronous propagation of the impacts of new beliefs and/or new evidence in hierarchically organized inference structures with multi-hypotheses variables. The computational scheme proposed specifies a set of belief parameters, communication messages and updating rules which guarantee that the diffusion of updated beliefs is accomplished in a single pass and complies with the tenets of Bayes calculus.},
  booktitle = {Proceedings of the Second AAAI Conference on Artificial Intelligence},
  pages     = {133–136},
  numpages  = {4},
  location  = {Pittsburgh, Pennsylvania},
  series    = {AAAI'82}
}

@article{reeves-gastpat-sampling-rate-distortion-tradeoff-for-sparsity-pattern-recovery,
  author    = {Reeves, Galen and Gastpar, Michael},
  journal   = {IEEE Transactions on Information Theory},
  title     = {The Sampling Rate-Distortion Tradeoff for Sparsity Pattern Recovery in Compressed Sensing},
  year      = {2012},
  volume    = {58},
  number    = {5},
  pages     = {3065-3092},
  doi       = {10.1109/tit.2012.2184848},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2012.2184848},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448, 1557-9654},
  month     = may
}

@article{russo-thompson-sampling,
  author     = {Russo, Daniel and Van Roy, Benjamin},
  title      = {An Information-Theoretic Analysis of {Thompson} Sampling},
  year       = {2016},
  issue_date = {January 2016},
  publisher  = {JMLR.org},
  volume     = {17},
  number     = {1},
  issn       = {1532-4435},
  abstract   = {We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.},
  journal    = {J. Mach. Learn. Res.},
  month      = jan,
  pages      = {2442--2471},
  numpages   = {30},
  keywords   = {mutli-armed bandit, regret bounds, online optimization, Thompson sampling, information theory}
}

@inproceedings{sb-pn-isit-2021,
  author    = {Sagnik Bhattacharya and Prakash Narayan},
  booktitle = {2021 IEEE International Symposium on Information Theory (ISIT)},
  title     = {Universal single-shot sampling rate distortion},
  year      = {2021},
  volume    = {},
  number    = {},
  publisher = {IEEE},
  month     = jun
}

@inproceedings{sb-pn-isit-2023,
  author    = {Sagnik Bhattacharya and Prakash Narayan},
  booktitle = {2023 IEEE International Symposium on Information Theory (ISIT)},
  title     = {Shared Information for the Cliqueylon Graph},
  year      = {2023},
  volume    = {},
  number    = {},
  publisher = {IEEE},
  month     = jun
}


@inproceedings{sb-pn-si-mct,
  author    = {Bhattacharya, Sagnik and Narayan, Prakash},
  booktitle = {2022 IEEE International Symposium on Information Theory},
  title     = {Shared Information for a {M}arkov Chain on a Tree},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {3049-3054},
  doi       = {10.1109/ISIT50566.2022.9834365}
}

@inproceedings{sb-pn-cliqueylon,
  author    = {Bhattacharya, Sagnik and Narayan, Prakash},
  booktitle = {2023 IEEE International Symposium on Information Theory},
  title     = {Shared Information for the {C}liqueylon {G}raph},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {boo},
  doi       = {hoo}
}


@unpublished{schmidt-inference,
  title  = {Inference in Chains and Trees},
  author = {Mark Schmidt},
  year   = {2015},
  note   = {\url{https://www.cs.ubc.ca/labs/lci/mlrg/slides/2015_MLRG_ChainTree.pdf}}
}

@inproceedings{shkel-raginsky-verdu-universal-compression-list-decoding-log-loss,
  author    = {Shkel, Yanina and Raginsky, Maxim and Verd{\'u}, Sergio},
  booktitle = {2018 IEEE International Symposium on Information Theory (ISIT)},
  title     = {Universal Compression, List Decoding, and Logarithmic Loss},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {206-210},
  doi       = {10.1109/isit.2018.8437892},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/isit.2018.8437892},
  publisher = {IEEE},
  isbn      = {9781538647813},
  month     = jun
}

@inproceedings{shkel-raginsky-verdu-universal-lossy-compression-under-logarithmic-loss,
  author    = {Shkel, Yanina and Raginsky, Maxim and Verd{\'u}, Sergio},
  booktitle = {2017 IEEE International Symposium on Information Theory (ISIT)},
  title     = {Universal lossy compression under logarithmic loss},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {1157-1161},
  doi       = {10.1109/isit.2017.8006710},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/isit.2017.8006710},
  publisher = {IEEE},
  isbn      = {9781509040964},
  month     = jun
}

@article{slepian-wolf,
  author  = {Slepian, D. and Wolf, J.},
  journal = {IEEE Transactions on Information Theory},
  title   = {Noiseless coding of correlated information sources},
  year    = {1973},
  volume  = {19},
  number  = {4},
  pages   = {471-480},
  doi     = {10.1109/TIT.1973.1055037}
}


@book{sss-ml-book,
  added-at  = {2020-06-05T00:00:00.000+0200},
  author    = {Shalev-Shwartz, Shai and Ben-David, Shai},
  biburl    = {https://www.bibsonomy.org/bibtex/293329d1cd5964dd826bba3100cd17fe4/dblp},
  ee        = {http://www.cambridge.org/de/academic/subjects/computer-science/pattern-recognition-and-machine-learning/understanding-machine-learning-theory-algorithms},
  interhash = {125d708c7b440a3cfeb6146e83ab5de3},
  intrahash = {93329d1cd5964dd826bba3100cd17fe4},
  isbn      = {978-1-10-705713-5},
  keywords  = {dblp},
  pages     = {I-XVI, 1-397},
  publisher = {Cambridge University Press},
  timestamp = {2020-06-06T11:43:42.000+0200},
  title     = {Understanding Machine Learning - From Theory to Algorithms.},
  year      = 2014
}


@article{Tutte1961OnTP,
  title   = {On the Problem of Decomposing a Graph into n Connected Factors},
  author  = {William T. Tutte},
  journal = {Journal of The London Mathematical Society-second Series},
  year    = {1961},
  pages   = {221-230}
}

@article{tyagi-common-information,
  title   = {Common Information and Secret Key Capacity},
  author  = {Himanshu Tyagi},
  journal = {IEEE Transactions on Information Theory},
  year    = {2013},
  volume  = {59},
  pages   = {5627-5640}
}

@article{tyagi-converses,
  title   = {Converses For Secret Key Agreement and Secure Computing},
  author  = {Himanshu Tyagi and Shun Watanabe},
  journal = {IEEE Transactions on Information Theory},
  year    = {2015},
  volume  = {61},
  pages   = {4809-4827}
}

@article{tyagi-how-many-queries,
  author    = {Himanshu Tyagi and
               Prakash Narayan},
  title     = {How Many Queries Will Resolve Common Randomness?},
  journal   = {{IEEE} Transactions on Information Theory},
  volume    = {59},
  number    = {9},
  pages     = {5363--5378},
  year      = {2013},
  url       = {https://doi.org/10.1109/TIT.2013.2262496},
  doi       = {10.1109/TIT.2013.2262496},
  timestamp = {Tue, 10 Mar 2020 10:46:19 +0100},
  biburl    = {https://dblp.org/rec/journals/tit/TyagiN13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tyagi-narayan-now,
  url     = {http://dx.doi.org/10.1561/0100000072},
  year    = {2016},
  volume  = {13},
  journal = {Foundations and Trends in Communications and Information Theory},
  title   = {Multiterminal Secrecy by Public Discussion},
  doi     = {10.1561/0100000072},
  issn    = {1567-2190},
  number  = {2-3},
  pages   = {129-275},
  author  = {Prakash Narayan and Himanshu Tyagi}
}

@inproceedings{vanapeldoorn_et_al:LIPIcs:2019:10675,
  author    = {Joran van Apeldoorn and Andr{\'a}s Gily{\'e}n},
  title     = {{Improvements in Quantum SDP-Solving with Applications}},
  booktitle = {46th International Colloquium on Automata, Languages, and Programming (ICALP 2019)},
  pages     = {99:1--99:15},
  series    = {Leibniz International Proceedings in Informatics (LIPIcs)},
  isbn      = {978-3-95977-109-2},
  issn      = {1868-8969},
  year      = {2019},
  volume    = {132},
  editor    = {Christel Baier and Ioannis Chatzigiannakis and Paola Flocchini and Stefano Leonardi},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address   = {Dagstuhl, Germany},
  url       = {http://drops.dagstuhl.de/opus/volltexte/2019/10675},
  urn       = {urn:nbn:de:0030-drops-106750},
  doi       = {10.4230/LIPIcs.ICALP.2019.99},
  annote    = {Keywords: quantum algorithms, semidefinite programming, shadow tomography}
}

@article{verdu-estimating-information-measures,
  author         = {Verd{\'u}, Sergio},
  title          = {Empirical Estimation of Information Measures: {A} Literature Guide},
  journal        = {Entropy-switz.},
  volume         = {21},
  year           = {2019},
  number         = {8},
  article-number = {720},
  url            = {https://doi.org/10.3390/e21080720},
  issn           = {1099-4300},
  abstract       = {We give a brief survey of the literature on the empirical estimation of entropy, differential entropy, relative entropy, mutual information and related information measures. While those quantities are of central importance in information theory, universal algorithms for their estimation are increasingly important in data science, machine learning, biology, neuroscience, economics, language, and other experimental sciences.},
  doi            = {10.3390/e21080720},
  pages          = {720},
  source         = {Crossref},
  publisher      = {MDPI AG},
  month          = jul
}

@inproceedings{verdu-non-asymptotic-achievability-bounds-in-multiuser-information-theory,
  author    = {Verd{\'u}, Sergio},
  booktitle = {2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  title     = {Non-asymptotic achievability bounds in multiuser information theory},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {1-8},
  doi       = {10.1109/allerton.2012.6483192},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/allerton.2012.6483192},
  publisher = {IEEE},
  isbn      = {9781467345392, 9781467345378, 9781467345385},
  month     = oct
}

@book{vershynin_2018,
  place      = {Cambridge},
  series     = {Cambridge Series in Statistical and Probabilistic Mathematics},
  title      = {High-Dimensional Probability: An Introduction with Applications in Data Science},
  doi        = {10.1017/9781108231596},
  publisher  = {Cambridge University Press},
  author     = {Vershynin, Roman},
  year       = {2018},
  collection = {Cambridge Series in Statistical and Probabilistic Mathematics}
}

@article{wainwright-jordan,
  url     = {http://dx.doi.org/10.1561/2200000001},
  year    = {2008},
  volume  = {1},
  journal = {Foundations and Trends in Machine Learning},
  title   = {Graphical Models, Exponential Families, and Variational Inference},
  doi     = {10.1561/2200000001},
  issn    = {1935-8237},
  number  = {1–2},
  pages   = {1-305},
  author  = {Martin J. Wainwright and Michael I. Jordan}
}

@article{watanabe-tc,
  author  = {Watanabe, Satosi},
  journal = {IBM Journal of Research and Development},
  title   = {Information Theoretical Analysis of Multivariate Correlation},
  year    = {1960},
  volume  = {4},
  number  = {1},
  pages   = {66-82},
  doi     = {10.1147/rd.41.0066}
}

@article{weissman2001universal,
  author    = {Weissman, T. and Merhav, N.},
  title     = {Universal prediction of individual binary sequences in the presence of noise},
  journal   = {IEEE Transactions on Information Theory},
  volume    = {47},
  number    = {6},
  pages     = {2151-2173},
  year      = {2001},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  doi       = {10.1109/18.945240},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/18.945240},
  issn      = {0018-9448}
}

@article{weissman2004universally,
  author    = {Weissman, T.},
  title     = {Universally Attainable Error Exponents for Rate-Distortion Coding of Noisy Sources},
  journal   = {IEEE Transactions on Information Theory},
  volume    = {50},
  number    = {6},
  pages     = {1229-1246},
  year      = {2004},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  doi       = {10.1109/tit.2004.828061},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2004.828061},
  issn      = {0018-9448},
  month     = jun
}

@article{wu-verdu-renyi-information-dimension,
  author    = {Wu, Yihong and Verd{\'u}, Sergio},
  journal   = {IEEE Transactions on Information Theory},
  title     = {R\'enyi Information Dimension: {Fundamental} Limits of Almost Lossless Analog Compression},
  year      = {2010},
  volume    = {56},
  number    = {8},
  pages     = {3721-3748},
  doi       = {10.1109/tit.2010.2050803},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.2010.2050803},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn      = {0018-9448, 1557-9654},
  month     = aug
}

@article{wu-yang-entropy,
  author  = {Wu, Yihong and Yang, Pengkun},
  journal = {IEEE Transactions on Information Theory},
  title   = {Minimax Rates of Entropy Estimation on Large Alphabets via Best Polynomial Approximation},
  year    = {2016},
  volume  = {62},
  number  = {6},
  pages   = {3702-3720},
  doi     = {10.1109/TIT.2016.2548468}
}

@article{wyner-common-information,
  author  = {Wyner, A.},
  journal = {IEEE Transactions on Information Theory},
  title   = {The common information of two dependent random variables},
  year    = {1975},
  volume  = {21},
  number  = {2},
  pages   = {163-179},
  doi     = {10.1109/TIT.1975.1055346}
}

@article{yamamoto1980source,
  author    = {Yamamoto, Hirosuke and Itoh, Kohji},
  title     = {Source coding theory for multiterminal communication systems with a remote source},
  journal   = {IEICE TRANSACTIONS (1976-1990)},
  volume    = {63},
  number    = {10},
  pages     = {700--706},
  year      = {1980},
  publisher = {The Institute of Electronics, Information and Communication Engineers}
}

@article{ziv1980distortion,
  author    = {Ziv, J.},
  title     = {Distortion-rate theory for individual sequences},
  journal   = {IEEE Transactions on Information Theory},
  volume    = {26},
  number    = {2},
  pages     = {137-143},
  year      = {1980},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  doi       = {10.1109/tit.1980.1056164},
  source    = {Crossref},
  url       = {https://doi.org/10.1109/tit.1980.1056164},
  issn      = {0018-9448},
  month     = mar
}

