\section{A universal and exclusive survival curve approximator}
\label{sec:universal_and_exclusive}
We will now introduce MONDE+, a version of MONDE~\cite{chilinski2020neural} more capable of modeling complex survival curves, and SuMo++, an improved version of SuMo~\cite{rindt2022survival} that now guarantees $S(0|x)=1$ and uses MONDE+. This makes the model not only a universal but also an exclusive approximator of survival curves, by which we mean that the model is capable of approximating any survival curve and incapable of producing anything but a survival curve. For a review of MONDE and SuMo, see appendix, Section~\ref{sec:monde_sumo}. We also refer to~\cite{saul2016gaussian} for universal approximators derived via Gaussian processes and~\cite{danks2022derivative} for ones derived via numeric integration of neural networks.

We start by introducing the notation for the cumulative hazard function, $\Lambda(t|x)$, defined via
\begin{equation}
\label{eq:chf_formulation}
S(t|x) = \exp\left[ -\Lambda(t|x)\right].
\end{equation}
One can interpret $\Lambda$ as the total accumulated risk. Since $\Lambda$ determines the model, building a good survival model is equivalent to building a good model for $\Lambda$. The model should be flexible enough to approximate any cumulative hazard. To guarantee survival curves, we have to ensure that $\Lambda$ is monotonically increasing and $\Lambda(0|\cdot)=0$.

\subsection{MONDE+}
As the main building block for such $\Lambda$ we now define the MONDE+ network 
\begin{equation}
    M_+:\mathbb{R} \times \mathbb{R}^n \ni (t, x) \mapsto M_+(t,x) \in \mathbb{R}.
\end{equation}
It is monotonically increasing in its first argument and we define it via layers
\begin{equation}
    \label{eq:monde+}
    z_{k+1}(t, z_k, z_0) = H_kz_k + \sigma_k(\tilde z_k(t, z_k) + B_kz_k + L_kz_0)
\end{equation}
with
\begin{equation}
    \tilde z_k(t, z_k) = A_k\left(\phi_k(a_kt + b_k) \circ \psi_k(G_kz_k)\right)
\end{equation}
where $a_k$ and $b_k$ are vectors, all capitalized letters represent affine maps, and $\circ$ denotes the Hadamard product. $\sigma_k, \phi_k,$ and $\psi_k$ are monotonically increasing functions with non-negative $\phi_k$ and $\psi_k$. In practice, we use $\phi_k=\psi_k=\mbox{softplus}$ and $\sigma_k=\tanh$, in the last layer we set $\sigma_K=\mbox{id}$. Similar to MONDE, we constrain the weight matrices of $A_k, B_k, G_k,$ and $H_k$ and the vector $a_k$ to be pointwise non-negative. Refer to Section~\ref{sec:initalization} of the appendix for details on the initialization.

We recall that a MONDE network  $M:\mathbb{R}^{n+1}\to\mathbb{R}$ consists of layers
\begin{equation}
    \label{eq:monde}
    z_{k+1}(z_k) = \sigma_k(B_kz_k),
\end{equation}
i.e., they cannot differentiate inputs $t, x$, have no residual connections~\cite{he2016deep}, and are a strict subset of the MONDE+ layers.

Unlike MONDE, MONDE+ is monotone in $t$ but has no unnecessary monotonicity constraint in $x$, see the following lemma.
\begin{lemma}
    \label{lemma:monde_plus}
    Let $M_+:\mathbb{R} \times \mathbb{R}^n \to \mathbb{R}$ be a MONDE+ network, i.e., a concatenation of layers defined by~\eqref{eq:monde+}. Then the output of each layer of $M_+$ is pointwise monotonically increasing in $t$.
\end{lemma}

For the proof, see Section~\ref{sec:monde_proof} of the appendix. Each MONDE+ layer contains a MONDE layer as a subset of its operations. As the universal approximation properties of the MONDE network are already established~\cite{lang2005monotonic}, this also makes MONDE+ a universal approximator. As we will show in Section~\ref{sec:numerics}, the MONDE+ component within SuMo++ can successfully model the survival curves for a broad range of applications.

\subsection{SuMo++}
As previously stated, the SuMo++ network aims to improve SuMo's ability to produce accurate survival curves while maintaining its theoretical guarantees of universal approximation.

We define the SuMo++ network as
\begin{equation}
    \mathscr{S}_{++}(t, x) = \exp\left( -\left[M_+(t, q) - M_+(0, q)\right]\right),
\end{equation}
i.e., we set the cumulative hazard function to
\begin{equation}
    \Lambda(t|q) = M_+(t, q) - M_+(0, q)
\end{equation}
with $q = Q(x)\in\mathbb{R}^k$ being some feature extracting network. The exponent in SuMo++ is monotonically decreasing in $t$ and $0$ for $t=0$. Therefore, SuMo++ is not only monotonically decreasing with values in $[0, 1]$, but also guarantees $\mathscr{S}_{++}(0, x)=1$.

In contrast, the SuMo network is defined via a MONDE network as
\begin{equation}
    \mathscr{S}(t, x) = 1 - \mbox{sigmoid}\left(M([t, Q(x)])\right),
\end{equation}
it can, at best, achieve $\mathscr{S}(0, x)=1$ up to some error $\epsilon > 0$ since $\mathscr{S}(t, x) < 1$.

Note that alternatively, one could define SuMo++ via $\mathscr{S}_{++}(t, x) = \frac{1}{1 +\left[M_+(t, q) - M_+(0, q)\right]}.$ However, we did not see any difference in performance, but the former formulation leaves the model and its interpretability closer to classical formulation in~\eqref{eq:chf_formulation}.

We formulated SuMo++ in terms of MONDE+, but we could also do so via MONDE by splitting its input into $z=(t, x)$. For simplicity, we will refer to the SuMo++ approach using MONDE as SuMo+.

Now, as we have established a universal and exclusive approximator of survival curves, we will discuss how SuMo++ is also backward compatible, i.e., how we can use it and MONDE+ to parameterize and treat Cox models as neural networks.