\section{Numerical experiments}
\label{sec:numerics}
We will now present the results of our numerical experiments. We will first compare the performance of MONDE and MONDE+ and then perform an extensive comparison of different survival models using several survival and regression datasets.
\subsection{MONDE vs. MONDE+: A toy example}
\label{sec:toy_example}
We now compare the performance of the SuMo, SuMo+, and SuMo++ networks -- i.e., MONDE without and with the initial condition enforced and MONDE+ with the initial condition enforced.

To showcase the limitations of the SuMo and SuMo+ models in recreating survival curves, we designed an experiment using six samples, each containing 32 features, each in the range $[-1,1]$. We assigned survival probabilities for each sample at 2-7 points over the time interval $[0,1]$ in a way that tests the models' ability to capture complex distributions, such as sharp declines followed by plateaus and vice versa.

% Figure environment removed

% Figure environment removed

We trained each network for 512 Adam~\cite{kingma2014adam} iterations with a step size of $10^{-3}$ using the standard binary cross-entropy loss. Figure~\ref{fig:toy_curves} compares the three models over the six samples. To show the variability of the outcome, we also provide histograms of multiple runs of these experiments in Figure~\ref{fig:hists}. The histograms show that it can be difficult for the SuMo+ model to fit the six curves, while the SuMo and SuMo++ can produce better fits.

During these and all following experiments, we used MONDE+ with five hidden layers of width 32. We also use MONDE with the same structure, but after the input layer, we change the width to $98$ to give both networks approximately $32,000$ trainable parameters.

\subsection{Classifier metrics}
\label{sec:classifier_metrics}
We will now discuss how we will evaluate the following experiments. As discussed in~\cite{rindt2022survival}, the classical scoring rules for survival models do not adequately reflect the performance of survival models. Classical scoring rules for survival models, such as time- or hazard-based concordance scores for traditionally trained Cox models, are only effective in their intended context. However, they may not accurately reflect performance in a general setting defined by~\eqref{eq:S}. For example, a model that incorrectly predicts all patients dying within milliseconds of a clinical trial may still have a perfect concordance score, as the score only considers the correct order of events and not their absolute time. This does not make time concordance useless for these models but insufficient. Ideally, one would have multiple scoring rules to choose from to judge the different aspects of a model that are relevant to a given situation.

We propose to use the general integrated Brier score (IBS). However, instead of using the mean squared as the integrated scoring rule, we propose to use general classifier scoring rules, e.g., accuracy. Interestingly this fits squarely into the original general definition of the IBS~\cite{graf1999assessment}, but we have not seen it applied this way.

As a survival model is an infinite number of probabilistic classifiers indexed by time, we can evaluate the survival model's quality from different aspects; simply by choosing from the rich pool of classifier quality measures. E.g., one could use the $F_2$-score if one considers a clinical setting where an overly optimistic prognosis may deny patients timely access to escalation.

Note that we will use threshold-free versions of all classifier scoring rules. For example, if $l\in\{0,1\}^K$ is a binary vector of length $K\in\mathbb{N}$ containing labels and $p\in[0,1]^K$ a vector containing corresponding probabilistic predictions, we define the true-positives to be their scalar product, i.e., $\sum_{k=1}^K p_kl_k$.

The IBS integrates its particular scoring rule over a given time interval. We will use the interval $[0, T_{max}]$ where we choose $T_{max}$ for each dataset based on the $90^{th}$ percentile of times provided by the dataset.

The mean squared error is arguably the most popular scoring rule in regression. Thus the standard IBS neatly connects to the regression point of view we laid out in Section~\ref{sec:sa_as_regression}, while the classifier scoring rules proposed by us connect to Section~\ref{sec:sa_as_classification}.

\subsection{Datasets}
\label{sec:datasets}
We will now provide a brief qualitative overview of the datasets we use in Section~\ref{sec:results_and_discussion}. See Table~\ref{tab:dataset_overview} for a high-level overview. Each dataset consists of samples given by triples as in~\eqref{eq:sample} i.e., $(x, e, T)$. We convert the Clocks and California regression datasets into this format by assigning $T$ the label's value and $e=1$.
\begin{table}
    \centering

    \begin{tabular}{|c||c|c|c|}
        \hline
        Name & \#Samples & \#Features & Test set \\
        \hline
        GBSG2 & 686 & 8 & 25\% \\
        Recur & 1,296 & 4 & 25\% \\
        NKI & 272 & 9 & 25\% \\
        Lymph & 686 & 8 & 25\% \\
        COVID-19 & 1,489 & 16 & 25\% \\
        Clocks & 10,000 & 6,912 & 2.5\% \\
        California & 20,640 & 8 & 2.5\% \\
        \hline
    \end{tabular}

    \caption{An overview of the datasets as we used them. Up to rounding errors, we split the data such that the validation and test have the same size, i.e., if the test set contains 25\% of the sample, the validation contains 25\%, and the training contains 50\% of the samples. For the references see, GBSG2 \cite{sauerbrei1999building}, Recur \cite{lemeshow2011applied}, NKI \cite{nicolau2011topology}, Lymph \cite{schmoor2000role}, Clocks \cite{clocks}, and California \cite{pace1997sparse}.}
    \label{tab:dataset_overview}
\end{table}

The COVID-19 dataset is a private dataset based on COVID-19 patient data from Addenbrooke's Hospital, Cambridge, UK. The seven datasets showcase diverse survival curve dynamics. For example, the dynamics of oncology treatment outcomes and that of critically ill patients differ greatly. The Clocks dataset, with deterministic outcomes, highlights sudden changes in survival curves.

As some of the datasets have relatively few samples, the random seed used to split the data into training, validation, and test sets can significantly impact the evaluation of a model. To mitigate this effect, we ran 1000 splits and selected the seed that minimizes the difference between the three Kaplan-Meier estimators for the training, validation, and test sets. Since Kaplan-Meier estimates the expected unconditioned survival curve for each set, this decreases the chance of having vastly different training, validation, and test sets.

We normalize all input features to have a $0$ mean and standard deviation of $1$. We normalize the times within the data by dividing through by $T_{max}$ as defined in Section~\ref{sec:classifier_metrics}. For more details on the datasets, see Section~\ref{sec:datasets_appendix} in the appendix.

\subsection{Results and discussion}
\label{sec:results_and_discussion}

For the Clocks dataset, containing images, we apply the methods amenable to convolutions to extract the features for the model, namely CoxDeepNN, SuMo, SuMo+, and SuMo++, as well as Kaplan-Meier. For all other datasets, which contain tabular data, we were able to train all models discussed earlier.
See Section~\ref{sec:training_details} in the appendix for training details. We used the standard and classifier metric versions of the IBS discussed in Section~\ref{sec:classifier_metrics} to evaluate the models. We use the classifier metrics accuracy, area under the precision-recall curve (AUPRC), area under the receiver operating characteristic curve (AUROC), balanced accuracy, the $F_\beta$-score for $\beta\in\{0.5, 1, 2\}$, precision, sensitivity, specificity, and the Youden's index~\cite{youden1950index}. In addition to the IBS, we also used the established concordance index based on the restricted mean survival time, restricted by the dataset's $T_{max}$. See Table~\ref{tab:stats_Concordance} and Table~\ref{tab:stats_iibs} in the appendix for the concordance index and the standard IBS. We report the mean of all scores in Table~\ref{tab:stats_Mean}. Note that the CoxDeepNN model approach is well known from other papers~\cite{katzman2018deepsurv, kvamme2019time, shahin2022survival}, commonly referred to as DeepHit or DeepSurv.
\input{tables_Mean_stats}

In Section~\ref{sec:separate_scores} of the appendix, we present tables with each separate integrated quality score, along with the non-integrated versions of the balanced accuracy and the $F_1$ score for each dataset in Section~\ref{sec:plots_non_integrated}. We chose these two scores as they are highly correlated with the mean of the scores and complement each other.

Table~\ref{tab:stats_Mean} shows that SuMo, SuMo+, and SuMo++ outperform all other models. For example, plots of survival curves see Section~\ref{sec:predicted_survival_curves} in the appendix. In particular, SuMo+ and SuMo++ slightly outperform SuMo in most cases while guaranteeing the output to be a survival curve. For the losses, the BCE loss tends to outperform the SuMo loss on survival datasets containing right-censoring; for more on the SuMo loss, see the appendix, Section~\ref{sec:training_details}, and~\cite{rindt2022survival}.

In contrast, the SuMo loss outperforms the BCE for the adapted regression datasets. We are not sure why that is, but the SuMo, unlike the BCE loss, is conditioned on whether the event was observed. This might decrease its performance if censoring is not independent of the time of the event. This would not be an issue for an entirely uncensored dataset.