\section{Introduction}

Argumentation is the field of elaboration and presentation of arguments to debate, persuade, and agree, where an argument is made of a conclusion (i.e., a claim) supported by reasons (i.e., premises)~\cite{walton2008argumentation}. By analogy with computational linguistics, \textit{computational argumentation} refers to the use of computer-based methods to analyze and create arguments and debates~\cite{gurevych-etal-2016}. It is a subfield of artificial intelligence that deals with the automated representation, evaluation, and generation of arguments. This field includes important applications such as mining arguments~\cite{al-khatib-etal-2016-cross}, assessing an argument's quality~\cite{el-baff-etal-2018-challenge}, reconstructing implicit assumptions in arguments~\cite{habernal-etal-2018-argument} or even providing constructive feedback for improving arguments~\cite{naito-etal-2022-typic}, to name a few.

In the context of education, learning argumentation (e.g., writing argumentative essays, debates, etc.) has been shown to improve students' critical thinking skills~\cite{pitchers-sodden-2000, behar-horenstein-etal-2011-teaching}. To further improve critical thinking skills, several researchers have been working on computational argumentation to support and provide tools to assist learners in improving the quality of their arguments.

Although computational models for argumentation are proven to assist students' learning and reduce teachers' workload~\cite{twardy-2004, wambsganss-etal-2021-arguetutor}, such models still lack the ability to \emph{explain} how an argument can be improved efficiently; e.g., why a particular argument was labeled bad or given a low score by their automatic evaluation rubrics. In other words, the model should be not only able to provide its results but also be able to \textit{explain and visualize the results in a comprehensive way} for the users so that users can understand, and ultimately improve their argumentation skills.

% Figure environment removed

We argue that the output for current computational models for argumentation act as a type of explanation and must be the focus of future work. For our survey, we categorize works into four different dimensions (cf., Figure~\ref{fig:overview}):
\begin{itemize}
    \item \textit{Richness}: Level of feedback details given by a model, i.e., \textit{what} is the error identified by the model and \textit{why} it is an error;
    \item \textit{Visualization}: Way of presenting feedback, i.e., \textit{how} the explanation is shown;
    \item \textit{Interactivity}: Ability to communicate with the model, other users, or a third-person, i.e., with \textit{whom} the user is talking;
    \item \textit{Personalization}: Ability to adapt the feedback to the users' background, i.e., \textit{to whom} the feedback is given.
\end{itemize}

% Figure environment removed

In Figure~\ref{fig:ex-types}, for a given argument consisting of two claims and one premise, four different feedback are shown, each highlighting a different dimension of feedback (\textit{Richness}, \textit{Visualization}, \textit{Interactivity}, and \textit{Personalization}).

Towards explainable computational argumentation, this survey aims to give an overview of computational argumentation on automated quality assessment.
We explore work providing explanations answering the following: \textit{What} (\S\ref{sec:richness-what}), \textit{Why} (\S\ref{sec:richness-why}), \textit{How} (\S\ref{sec:visualization}), \textit{Who} (\S\ref{sec:interactivity}), and \textit{To Whom} (\S\ref{sec:personalization}).
Finally, we discuss remaining challenges and potential ways to overcome them (\S\ref{sec:open_issues}) in order to develop systems that provide explanations in a way in which learners can improve their critical thinking skills.
We believe this survey can aid researchers in understanding current explanations in argumentation and broaden their horizon on argumentative feedback.\footnote{\label{foot:website}For more details, papers mentioned in this survey are categorized at \url{https://anonymized}.}

%and focus more on explanation in argumentation and apply it to newer models, thus making the system more explainable.



