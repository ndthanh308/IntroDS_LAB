\section{Richness - What is an Error?}
\label{sec:richness-what}

To improve students' critical thinking skills, we first need to evaluate their argumentative texts, i.e., identify argumentative errors. In this section, we focus on models providing shallow explanations, i.e., models that identify \textit{what} should be corrected in the arguments. We discuss recent works that identify properties such as the structure of arguments helpful to assist in this process.

\paragraph{Components}
Identifying argumentative components is one of the fundamental tasks in argumentation~\cite{teuful-zoning-1999,stab-gurevych-2014-identifying, emnlp-2020-jo}. Such works primarily focus on identifying components such as \textit{claims} and \textit{premises}.
More recently, the usefulness of identifying such components can be seen in tasks such as counter-argument generation. For example, in ~\citet{alshomary-etal-2021-counter}, weak premises are identified and ranked in order to generate counter-arguments.

\paragraph{Relations}
After identifying the different components of an argumentative text, it is necessary to distinguish the multiple relations between them to assert the quality of the arguments' quality. Indeed, supporting or refuting a claim is made of complex logical moves, such as promoting, contradicting, or acknowledging a fact. Therefore it is not trivial to use correct logic. To identify the different relations patterns, ~\citet{yuan-etal-2021-leveraging} focus on finding interactive argument pairs, whereas ~\citet{mim-etal-2022-lpattack} enables annotating complex attack relations.

\paragraph{Schemes}
In addition to components and relations, ~\citet{walton2008argumentation} proposed a set of roughly 80 logical argumentation schemes to categorize the underlying logic. Each scheme has a set of critical questions which provide a template to assess the strength of the argument depending upon the associated scheme. Since the first work on automatically detecting argumentation schemes in argumentative texts~\cite{feng-hirst-2011-classifying}, the use of such schemes has been explored in tasks such as essay scoring~\cite{song-etal-2014-applying}.

\paragraph{Fallacies}
Although a good structure with a claim and premises is necessary for a good argument, it is not sufficient. Indeed an argument has other more complex properties, such as its logical, dialectical, and rhetorical aspects.
A fallacy is a logical error or deceptive argument that undermines the validity of a conclusion or reasoning, which poses a substantial issue due to its propensity to generate miscommunication.
Towards teaching students to avoid making errors in logical reasoning, logical fallacies have received attention~\cite{habernal-etal-2017-argotario,bonial-etal-2022-search, sourati-etal-2023-fallacy}.
Motivated by the gamification method made by Habernal et al., Bonial et al. aimed to capture similar fallacy types for news articles, but the low distribution of fallacy types in the wild makes identification challenging.
Indeed most natural texts do not have recurrent specific patterns, compared to current datasets, like the Logic and LogicClimate datasets~\cite{jin-etal-2022-logical}.
Moreover, given the large number of logical fallacies that exist (over 100 types), long arguments can group multiple fallacies, resulting in difficulties in classification \cite{goffredo-etal-2022-fallacy}.

\paragraph{Debates}
In a case of a debate, an opponent is willing to give a counter-argument synchronously and interactively. Analyzing and evaluating a debate is a difficult task as we need to retrieve not only the argumentation structure of each opponent but also the relations between them.
~\citet{bao-etal-2022-arguments} focuses on argument pair extraction (APE), which consists of finding two interactive arguments from two argumentative passages of a discussion. Although the APE task gives insights into relations between different argumentative texts, it does not indicate complex relations (i.e., how claims, supports, attacks and the intention of the speakers are interrelated). To palliate this issue, ~\citet{hautli-janisz-etal-2022-qt30} identified and analyzed the dialogical argumentative structure of debates using Inference Anchoring Theory (IAT)~\cite{budsziyska2014model}.
Following the same IAT theory, ~\citet{kikteva-etal-2022-keystone} investigated the role of different types of questions (e.g., pure, assertive, and rhetorical questions) in dialogical argumentative setting and showed that different type of question leads to different argumentative discourse. Focused more on the opponent's side of a debate, ~\citet{naito-etal-2022-typic} propose diagnostic comments for assessing the quality of counter-arguments by providing expressive, informative and unique templates. The comments are then written by template selection and slot filling.

Although the identification of such argumentative structures (components, relations, and schemes) and properties (fallacies and debates pattern) is important, it has limitations in terms of effective feedback. Identifying a missing claim or a wrong premise is not enough to properly understand how to improve the argumentation. Therefore we relate the identification of structure and properties to shallow explanations in the sense that end-users can still benefit from the output of the models.

%\paragraph{Scoring: }
%Several works exists for improving argumentation using argumentative structure. Ghosh et al.~\cite{ghosh-etal-2016-coarse} used argumentative properties such as claim/premise and support/attack as features and found a correlation between them and essay scores. In addition to argumentative components, Carlile et al.~\cite{carlile-etal-2018-give} focused on argument persuasiveness as away to give feedback to learners.

%\paragraph{Quality Framework: }
%Hinton and Wagemans~\cite{hinton_2022_procedures}

%Song and Ferretti~\cite{songferettie2012} showed the effectiveness of schemes and critical questions. Students given the schemes before creating an argument were able to strengthen their arguments from being attacked via a counter-argument. 

\section{Richness - Why is This an Error?}
\label{sec:richness-why}

Although shallow explanations help end-users to identify their mistakes, they tend to be minimalist and need more guidance. Shallow explanations can be hard to understand, specially for beginners in argumentation. To explain more effectively the errors in an argument, a model should go a step further, hence by providing \textit{in-depth} explanations, which attempt to identify the argument's implicit components to explain \textit{why} there is an error in an argument.

\paragraph{Implicit Knowledge and Reasoning in Arguments}
To provide \textit{in-depth} explanations, we need to know how to refine the argument, i.e., how to identify implicit information. Recently many works have focused their attention on this aim.
The main goal of such studies is to make the structure and reasoning of arguments explicit to better explain the arguments for humans. 
Additionally, this focus can eventually help build Robust Argumentation Machines that can be enriched with language understanding capacity. 
The ExpLAIN project .~\citet{becker-etal-2021-reconstructing} and ~\citet{jo-2021-kenli} are one such example that focuses extensively on reconstructing implicit knowledge in arguments by relying on knowledge graphs among others. 
Taking a step further in this direction, ~\citet{singh-etal-2022-irac} proposed to utilize such implicit information to bridge the implicit reasoning gap in arguments to help students explain their arguments better.

%\paragraph{LLMs:} 

%\paragraph{Rules and Annotations:}
%\old{Another way to provide \textit{in-depth} explanations is to understand how a model reaches its conclusion when asserting the quality of an argument. For example, in the case of evaluation of an argument's logic, ~\citet{jo-etal-2021-classifying} provided LogBERT, a more interpretable model based on logical and theory-informed mechanisms between two statements. LogBert relies on multiple rules that specify evidence for the support and attack relations between a claim and a statement. Although the use of rules gives a glance of explanation, LogBert remains "a black-box model with some insightful explainability." If we know how a model identifies a mistake in an argument, we can use these mechanisms to explain the diagnosis of an argument, which can help refine it. }