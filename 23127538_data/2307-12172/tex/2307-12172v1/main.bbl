% Generated by IEEEtranS.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{100}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtranS.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{aldoma2012global}
A.~Aldoma, F.~Tombari, L.~Di~Stefano, and M.~Vincze, ``A global hypotheses
  verification method for 3d object recognition,'' in \emph{Computer
  Vision--ECCV 2012: 12th European Conference on Computer Vision, Florence,
  Italy, October 7-13, 2012, Proceedings, Part III 12}.\hskip 1em plus 0.5em
  minus 0.4em\relax Springer, 2012, pp. 511--524.

\bibitem{aldoma2011cad}
A.~Aldoma, M.~Vincze, N.~Blodow, D.~Gossow, S.~Gedikli, R.~B. Rusu, and
  G.~Bradski, ``Cad-model recognition and 6dof pose estimation using 3d cues,''
  in \emph{2011 IEEE international conference on computer vision workshops
  (ICCV workshops)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2011, pp.
  585--592.

\bibitem{alexandrov2019leveraging}
S.~V. Alexandrov, T.~Patten, and M.~Vincze, ``Leveraging symmetries to improve
  object detection and pose estimation from range data,'' in \emph{Computer
  Vision Systems: 12th International Conference, ICVS 2019, Thessaloniki,
  Greece, September 23--25, 2019, Proceedings 12}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2019, pp. 397--407.

\bibitem{araki2021iterative}
R.~Araki, K.~Mano, T.~Hirano, T.~Hirakawa, T.~Yamashita, and H.~Fujiyoshi,
  ``Iterative coarse-to-fine 6d-pose estimation using back-propagation,'' in
  \emph{2021 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp.
  3587--3594.

\bibitem{barbu2019objectnet}
A.~Barbu, D.~Mayo, J.~Alverio, W.~Luo, C.~Wang, D.~Gutfreund, J.~Tenenbaum, and
  B.~Katz, ``Objectnet: A large-scale bias-controlled dataset for pushing the
  limits of object recognition models,'' \emph{Advances in neural information
  processing systems}, vol.~32, 2019.

\bibitem{visda2021}
D.~Bashkirova, D.~Hendrycks, D.~Kim, H.~Liao, S.~Mishra, C.~Rajagopalan,
  K.~Saenko, K.~Saito, B.~U. Tayyab, P.~Teterwak \emph{et~al.}, ``Visda-2021
  competition: Universal domain adaptation to improve performance on
  out-of-distribution data,'' PMLR, pp. 66--79, 2022.

\bibitem{bauer2020verefine}
D.~Bauer, T.~Patten, and M.~Vincze, ``Verefine: Integrating object pose
  verification with physics-guided iterative refinement,'' \emph{IEEE Robotics
  and Automation Letters}, vol.~5, no.~3, pp. 4289--4296, 2020.

\bibitem{bauer2021reagent}
------, ``Reagent: Point cloud registration using imitation and reinforcement
  learning,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2021, pp. 14\,586--14\,594.

\bibitem{bauer2022sporeagent}
------, ``Sporeagent: Reinforced scene-level plausibility for object pose
  refinement,'' in \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, 2022, pp. 654--662.

\bibitem{bengston2021pose}
S.~H. Bengtson, H.~Åström, T.~B. Moeslund, E.~A. Topp, and V.~Krueger, ``Pose
  estimation from rgb images of highly symmetric objects using a novel
  multi-pose loss and differential rendering,'' in \emph{2021 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS)}, 2021, pp.
  4618--4624.

\bibitem{bochkovskiy2020yolov4}
A.~Bochkovskiy, C.-Y. Wang, and H.-Y.~M. Liao, ``Yolov4: Optimal speed and
  accuracy of object detection,'' \emph{arXiv preprint arXiv:2004.10934}, 2020.

\bibitem{brachmann2014learning}
E.~Brachmann, A.~Krull, F.~Michel, S.~Gumhold, J.~Shotton, and C.~Rother,
  ``Learning {6D} object pose estimation using {3D} object coordinates,'' in
  \emph{Proceedings of the European Conference on Computer Vision}, 2014, pp.
  536--551.

\bibitem{byambaa20226d}
M.~Byambaa, G.~Koutaki, and L.~Choimaa, ``6d pose estimation of transparent
  object from single rgb image for robotic manipulation,'' \emph{IEEE Access},
  vol.~10, pp. 114\,897--114\,906, 2022.

\bibitem{calli2015ycb}
B.~Calli, A.~Walsman, A.~Singh, S.~Srinivasa, P.~Abbeel, and A.~M. Dollar,
  ``Benchmarking in manipulation research: Using the yale-cmu-berkeley object
  and model set,'' \emph{IEEE Robotics \& Automation Magazine}, vol.~22, no.~3,
  pp. 36--52, 2015.

\bibitem{Cao2021suction}
H.~Cao, H.-S. Fang, W.~Liu, and C.~Lu, ``Suctionnet-1billion: A large-scale
  benchmark for suction grasping,'' \emph{IEEE Robotics and Automation
  Letters}, vol.~6, no.~4, pp. 8718--8725, 2021.

\bibitem{cao2022dgecn}
T.~Cao, F.~Luo, Y.~Fu, W.~Zhang, S.~Zheng, and C.~Xiao, ``Dgecn: A depth-guided
  edge convolutional network for end-to-end 6d pose estimation,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2022, pp. 3783--3792.

\bibitem{caron2021emerging}
M.~Caron, H.~Touvron, I.~Misra, H.~J{\'e}gou, J.~Mairal, P.~Bojanowski, and
  A.~Joulin, ``Emerging properties in self-supervised vision transformers,'' in
  \emph{Proceedings of the IEEE/CVF international conference on computer
  vision}, 2021, pp. 9650--9660.

\bibitem{chen2022epro}
H.~Chen, P.~Wang, F.~Wang, W.~Tian, L.~Xiong, and H.~Li, ``Epro-pnp:
  Generalized end-to-end probabilistic perspective-n-points for monocular
  object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, 2022, pp. 2781--2790.

\bibitem{Chen_2023_CVPR}
H.~Chen, F.~Manhardt, N.~Navab, and B.~Busam, ``Texpose: Neural texture
  learning for self-supervised 6d object pose estimation,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2023, pp. 4841--4852.

\bibitem{chen2022stereopose}
K.~Chen, S.~James, C.~Sui, Y.-H. Liu, P.~Abbeel, and Q.~Dou, ``Stereopose:
  Category-level 6d transparent object pose estimation from stereo images via
  back-view nocs,'' in \emph{2023 IEEE International Conference on Robotics and
  Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp.
  2855--2861.

\bibitem{chen2023autobag}
L.~Y. Chen, B.~Shi, D.~Seita, R.~Cheng, T.~Kollar, D.~Held, and K.~Goldberg,
  ``Autobag: Learning to open plastic bags and insert objects,'' in \emph{2023
  IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 3918--3925.

\bibitem{chen2022MP6D}
L.~Chen, H.~Yang, C.~Wu, and S.~Wu, ``Mp6d: An rgb-d dataset for metal parts’
  6d pose estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~7,
  no.~3, pp. 5912--5919, 2022.

\bibitem{chen2022clearpose}
X.~Chen, H.~Zhang, Z.~Yu, A.~Opipari, and O.~Chadwicke~Jenkins, ``Clearpose:
  Large-scale transparent object dataset and benchmark,'' in \emph{Computer
  Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October
  23--27, 2022, Proceedings, Part VIII}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2022, pp. 381--396.

\bibitem{chen2020category}
X.~Chen, Z.~Dong, J.~Song, A.~Geiger, and O.~Hilliges, ``Category level object
  pose estimation via neural analysis-by-synthesis,'' in \emph{Proceedings of
  the European Conference on Computer Vision}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2020, pp. 139--156.

\bibitem{chi2021garmentnets}
C.~Chi and S.~Song, ``Garmentnets: Category-level pose estimation for garments
  via canonical space shape completion,'' in \emph{Proceedings of the IEEE/CVF
  International Conference on Computer Vision}, 2021, pp. 3324--3333.

\bibitem{crivellaro2015novel}
A.~Crivellaro, M.~Rad, Y.~Verdie, K.~Moo~Yi, P.~Fua, and V.~Lepetit, ``A novel
  representation of parts for accurate 3d object detection and tracking in
  monocular images,'' in \emph{Proceedings of the IEEE international conference
  on computer vision}, 2015, pp. 4391--4399.

\bibitem{dai2022dreds}
Q.~Dai, J.~Zhang, Q.~Li, T.~Wu, H.~Dong, Z.~Liu, P.~Tan, and H.~Wang, ``Domain
  randomization-enhanced depth simulation and restoration for perceiving and
  grasping specular and transparent objects,'' in \emph{European Conference on
  Computer Vision (ECCV)}, 2022.

\bibitem{deng2022icaps}
X.~Deng, J.~Geng, T.~Bretl, Y.~Xiang, and D.~Fox, ``icaps: Iterative
  category-level object pose and shape estimation,'' \emph{IEEE Robotics and
  Automation Letters}, vol.~7, no.~2, pp. 1784--1791, 2022.

\bibitem{deng2021pose}
X.~Deng, A.~Mousavian, Y.~Xiang, F.~Xia, T.~Bretl, and D.~Fox, ``Poserbpf: A
  rao–blackwellized particle filter for 6-d object pose tracking,''
  \emph{IEEE Transactions on Robotics}, vol.~37, no.~5, pp. 1328--1342, 2021.

\bibitem{di2021so}
Y.~Di, F.~Manhardt, G.~Wang, X.~Ji, N.~Navab, and F.~Tombari, ``So-pose:
  Exploiting self-occlusion for direct 6d pose estimation,'' in
  \emph{Proceedings of the IEEE/CVF International Conference on Computer
  Vision}, 2021, pp. 12\,396--12\,405.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly \emph{et~al.},
  ``An image is worth 16x16 words: Transformers for image recognition at
  scale,'' in \emph{International Conference on Learning Representations},
  2020.

\bibitem{doumanoglou2016recovering}
A.~Doumanoglou, R.~Kouskouridas, S.~Malassiotis, and T.-K. Kim, ``Recovering 6d
  object pose and predicting next-best-view in the crowd,'' in
  \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern
  recognition}, 2016, pp. 3583--3592.

\bibitem{drost2017introducing}
B.~Drost, M.~Ulrich, P.~Bergmann, P.~Hartinger, and C.~Steger, ``Introducing
  mvtec itodd-a dataset for 3d object recognition in industry,'' in
  \emph{Proceedings of the IEEE international conference on computer vision
  workshops}, 2017, pp. 2200--2208.

\bibitem{drost2010model}
B.~Drost, M.~Ulrich, N.~Navab, and S.~Ilic, ``Model globally, match locally:
  Efficient and robust 3d object recognition,'' in \emph{2010 IEEE computer
  society conference on computer vision and pattern recognition}.\hskip 1em
  plus 0.5em minus 0.4em\relax Ieee, 2010, pp. 998--1005.

\bibitem{EisnerZhang2022FLOW}
B.~Eisner*, H.~Zhang*, and D.~Held, ``Flowbot3d: Learning 3d articulation flow
  to manipulate articulated objects,'' in \emph{Robotics: Science and Systems
  (RSS)}, 2022.

\bibitem{fan2022object}
Z.~Fan, Z.~Song, J.~Xu, Z.~Wang, K.~Wu, H.~Liu, and J.~He, ``Object level depth
  reconstruction for category level 6d object pose estimation from monocular
  rgb image,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2022, pp. 220--236.

\bibitem{fan2022deep}
Z.~Fan, Y.~Zhu, Y.~He, Q.~Sun, H.~Liu, and J.~He, ``Deep learning on monocular
  object pose detection and tracking: A comprehensive overview,'' \emph{ACM
  Computing Surveys}, vol.~55, no.~4, pp. 1--40, 2022.

\bibitem{fan2023pope}
Z.~Fan, P.~Pan, P.~Wang, Y.~Jiang, D.~Xu, H.~Jiang, and Z.~Wang, ``Pope: 6-dof
  promptable pose estimation of any object, in any scene, with one reference,''
  \emph{arXiv preprint arXiv:2305.15727}, 2023.

\bibitem{fang2020graspnet}
H.-S. Fang, C.~Wang, M.~Gou, and C.~Lu, ``Graspnet-1billion: A large-scale
  benchmark for general object grasping,'' in \emph{Proceedings of the IEEE/CVF
  conference on computer vision and pattern recognition}, 2020, pp.
  11\,444--11\,453.

\bibitem{fang2022transcg}
H.~Fang, H.-S. Fang, S.~Xu, and C.~Lu, ``Transcg: A large-scale real-world
  dataset for transparent object depth completion and a grasping baseline,''
  \emph{IEEE Robotics and Automation Letters}, pp. 1--8, 2022.

\bibitem{fischler1981random}
M.~A. Fischler and R.~C. Bolles, ``Random sample consensus: a paradigm for
  model fitting with applications to image analysis and automated
  cartography,'' \emph{Communications of the ACM}, vol.~24, no.~6, pp.
  381--395, 1981.

\bibitem{florence2018dense}
P.~R. Florence, L.~Manuelli, and R.~Tedrake, ``Dense object nets: Learning
  dense visual object descriptors by and for robotic manipulation,'' in
  \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax
  PMLR, 2018, pp. 373--385.

\bibitem{gard2022casapose}
\BIBentryALTinterwordspacing
N.~Gard, A.~Hilsmann, and P.~Eisert, ``Casapose: Class-adaptive and
  semantic-aware multi-object pose estimation,'' in \emph{33rd British Machine
  Vision Conference 2022, {BMVC} 2022, London, UK, November 21-24, 2022}.\hskip
  1em plus 0.5em minus 0.4em\relax {BMVA} Press, 2022, p. 899. [Online].
  Available: \url{https://bmvc2022.mpi-inf.mpg.de/899/}
\BIBentrySTDinterwordspacing

\bibitem{ge2021yolox}
Z.~Ge, S.~Liu, F.~Wang, Z.~Li, and J.~Sun, ``Yolox: Exceeding yolo series in
  2021,'' \emph{arXiv preprint arXiv:2107.08430}, 2021.

\bibitem{goodwin2022zero}
W.~Goodwin, S.~Vaze, I.~Havoutis, and I.~Posner, ``Zero-shot category-level
  object pose estimation,'' in \emph{European Conference on Computer
  Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 516--532.

\bibitem{gou2022unseen}
M.~Gou, H.~Pan, H.-S. Fang, Z.~Liu, C.~Lu, and P.~Tan, ``Unseen object 6d pose
  estimation: a benchmark and baselines,'' \emph{arXiv preprint
  arXiv:2206.11808}, 2022.

\bibitem{gu2022ossid}
Q.~Gu, B.~Okorn, and D.~Held, ``Ossid: Online self-supervised instance
  detection by (and for) pose estimation,'' \emph{IEEE Robotics and Automation
  Letters}, vol.~7, no.~2, pp. 3022--3029, 2022.

\bibitem{guo2023knowledge}
S.~Guo, Y.~Hu, J.~M. Alvarez, and M.~Salzmann, ``Knowledge distillation for 6d
  pose estimation by aligning distributions of local predictions,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2023, pp. 18\,633--18\,642.

\bibitem{hai2023shape}
Y.~Hai, R.~Song, J.~Li, and Y.~Hu, ``Shape-constraint recurrent flow for 6d
  object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, 2023, pp. 4831--4840.

\bibitem{hai2023rigidity}
Y.~Hai, R.~Song, J.~Li, M.~Salzmann, and Y.~Hu, ``Rigidity-aware detection for
  6d object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference
  on Computer Vision and Pattern Recognition}, 2023, pp. 8927--8936.

\bibitem{hand2001auroc}
D.~J. Hand and R.~J. Till, ``A simple generalisation of the area under the roc
  curve for multiple class classification problems,'' \emph{Machine learning},
  vol.~45, pp. 171--186, 2001.

\bibitem{haugaard2021surfemb}
R.~L. Haugaard and A.~G. Buch, ``Surfemb: Dense and continuous correspondence
  distributions for object pose estimation with learnt surface embeddings,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2022, pp. 6749--6758.

\bibitem{he2017mask}
K.~He, G.~Gkioxari, P.~Doll{\'a}r, and R.~Girshick, ``Mask r-cnn,'' in
  \emph{Proceedings of the IEEE/CVF international conference on computer
  vision}, 2017, pp. 2961--2969.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{Proceedings of the IEEE/CVF conference on computer
  vision and pattern recognition}, 2016, pp. 770--778.

\bibitem{he2022fs6d}
Y.~He, Y.~Wang, H.~Fan, J.~Sun, and Q.~Chen, ``Fs6d: Few-shot 6d pose
  estimation of novel objects,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6814--6824.

\bibitem{he20206d}
Z.~He, W.~Feng, X.~Zhao, and Y.~Lv, ``6d pose estimation of objects: Recent
  technologies and challenges,'' \emph{Applied Sciences}, vol.~11, no.~1, p.
  228, 2020.

\bibitem{he2022generative}
Z.~He, M.~Wu, X.~Zhao, S.~Zhang, and J.~Tan, ``A generative feature-to-image
  robotic vision framework for 6d pose measurement of metal parts,''
  \emph{IEEE/ASME Transactions on Mechatronics}, vol.~27, no.~5, pp.
  3198--3209, 2022.

\bibitem{hendrycks2020imagenet}
D.~Hendrycks, S.~Basart, N.~Mu, S.~Kadavath, F.~Wang, E.~Dorundo, R.~Desai,
  T.~Zhu, S.~Parajuli, M.~Guo \emph{et~al.}, ``The many faces of robustness: A
  critical analysis of out-of-distribution generalization,'' in
  \emph{Proceedings of the IEEE/CVF International Conference on Computer
  Vision}, 2021, pp. 8340--8349.

\bibitem{hendrycks2019imagenet}
D.~Hendrycks and T.~Dietterich, ``Benchmarking neural network robustness to
  common corruptions and perturbations,'' 2018.

\bibitem{hinterstoisser2012model}
S.~Hinterstoisser, V.~Lepetit, S.~Ilic, S.~Holzer, G.~Bradski, K.~Konolige, and
  N.~Navab, ``Model based training, detection and pose estimation of
  texture-less {3D} objects in heavily cluttered scenes,'' in \emph{Proceedings
  of the Asian Conference on Computer Vision}, 2012, pp. 548--562.

\bibitem{ho2020denoising}
J.~Ho, A.~Jain, and P.~Abbeel, ``Denoising diffusion probabilistic models,''
  \emph{Advances in Neural Information Processing Systems}, vol.~33, pp.
  6840--6851, 2020.

\bibitem{hodan2020epos}
T.~Hodan, D.~Barath, and J.~Matas, ``Epos: Estimating 6d pose of objects with
  symmetries,'' in \emph{Proceedings of the IEEE/CVF conference on computer
  vision and pattern recognition}, 2020, pp. 11\,703--11\,712.

\bibitem{hodan2017tless}
T.~Hodan, P.~Haluza, {\v{S}}.~Obdr{\v{z}}{\'a}lek, J.~Matas, M.~Lourakis, and
  X.~Zabulis, ``T-less: An rgb-d dataset for 6d pose estimation of texture-less
  objects,'' in \emph{2017 IEEE Winter Conference on Applications of Computer
  Vision}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2017, pp. 880--888.

\bibitem{hodan2018bop}
T.~Hodan, F.~Michel, E.~Brachmann, W.~Kehl, A.~GlentBuch, D.~Kraft, B.~Drost,
  J.~Vidal, S.~Ihrke, X.~Zabulis \emph{et~al.}, ``Bop: Benchmark for 6d object
  pose estimation,'' in \emph{Proceedings of the European conference on
  computer vision (ECCV)}, 2018, pp. 19--34.

\bibitem{hodan2020bop}
T.~Hoda{\v{n}}, M.~Sundermeyer, B.~Drost, Y.~Labb{\'e}, E.~Brachmann,
  F.~Michel, C.~Rother, and J.~Matas, ``{BOP} challenge 2020 on {6D} object
  localization,'' \emph{Proceedings of the European Conference on Computer
  Vision Workshops}, 2020.

\bibitem{hodan2022bop}
------, ``Placeholder,'' \emph{Proceedings of the European Conference on
  Computer Vision Workshops}, 2020.

\bibitem{hodavn2015detection}
T.~Hoda{\v{n}}, X.~Zabulis, M.~Lourakis, {\v{S}}.~Obdr{\v{z}}{\'a}lek, and
  J.~Matas, ``Detection and fine 3d pose estimation of texture-less objects in
  rgb-d images,'' in \emph{2015 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2015, pp. 4421--4428.

\bibitem{hoque2021comprehensive}
S.~Hoque, M.~Y. Arafat, S.~Xu, A.~Maiti, and Y.~Wei, ``A comprehensive review
  on 3d object detection and 6d pose estimation with deep learning,''
  \emph{IEEE Access}, vol.~9, pp. 143\,746--143\,770, 2021.

\bibitem{hu2022perspective}
Y.~Hu, P.~Fua, and M.~Salzmann, ``Perspective flow aggregation for data-limited
  6d object pose estimation,'' in \emph{European Conference on Computer
  Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 89--106.

\bibitem{hu2020single}
Y.~Hu, P.~Fua, W.~Wang, and M.~Salzmann, ``Single-stage 6d object pose
  estimation,'' in \emph{Proceedings of the IEEE/CVF conference on computer
  vision and pattern recognition}, 2020, pp. 2930--2939.

\bibitem{hu2019segpose}
Y.~Hu, J.~Hugonot, P.~Fua, and M.~Salzmann, ``Segmentation-driven 6d object
  pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, 2019.

\bibitem{huang2022neural}
L.~Huang, T.~Hodan, L.~Ma, L.~Zhang, L.~Tran, C.~Twigg, P.-C. Wu, J.~Yuan,
  C.~Keskin, and R.~Wang, ``Neural correspondence field for object pose
  estimation,'' in \emph{Computer Vision--ECCV 2022: 17th European Conference,
  Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part X}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2022, pp. 585--603.

\bibitem{huang2022confidence}
W.-L. Huang, C.-Y. Hung, and I.-C. Lin, ``Confidence-based 6d object pose
  estimation,'' \emph{IEEE Transactions on Multimedia}, vol.~24, pp.
  3025--3035, 2022.

\bibitem{ichnowski2021dex}
J.~Ichnowski, Y.~Avigal, J.~Kerr, and K.~Goldberg, ``Dex-nerf: Using a neural
  radiance field to grasp transparent objects,'' 2021.

\bibitem{ikeda2022sim2real}
T.~Ikeda, S.~Tanishige, A.~Amma, M.~Sudano, H.~Audren, and K.~Nishiwaki,
  ``Sim2real instance-level style transfer for 6d pose estimation,'' in
  \emph{2022 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)}, 2022, pp. 3225--3232.

\bibitem{iwase2021repose}
S.~Iwase, X.~Liu, R.~Khirodkar, R.~Yokota, and K.~M. Kitani, ``Repose: Fast 6d
  object pose refinement via deep texture rendering,'' in \emph{Proceedings of
  the IEEE/CVF International Conference on Computer Vision}, 2021, pp.
  3303--3312.

\bibitem{jawaid2023towards}
M.~Jawaid, E.~Elms, Y.~Latif, and T.-J. Chin, ``Towards bridging the space
  domain gap for satellite pose estimation using event sensing,'' 2023.

\bibitem{jeon2023ambiguity}
M.-H. Jeon, J.~Kim, J.-H. Ryu, and A.~Kim, ``Ambiguity-aware multi-object pose
  optimization for visually-assisted robot manipulation,'' \emph{IEEE Robotics
  and Automation Letters}, vol.~8, no.~1, pp. 137--144, 2023.

\bibitem{homebrewedDB}
R.~Kaskman, S.~Zakharov, I.~Shugurov, and S.~Ilic, ``Homebreweddb: Rgb-d
  dataset for 6d pose estimation of 3d objects,'' in \emph{Proceedings of the
  IEEE/CVF International Conference on Computer Vision Workshops}, 2019, pp.
  0--0.

\bibitem{kehl2017ssd}
W.~Kehl, F.~Manhardt, F.~Tombari, S.~Ilic, and N.~Navab, ``Ssd-6d: Making
  rgb-based 3d detection and 6d pose estimation great again,'' in
  \emph{Proceedings of the IEEE international conference on computer vision},
  2017, pp. 1521--1529.

\bibitem{kleeberger2019large}
K.~Kleeberger, C.~Landgraf, and M.~F. Huber, ``Large-scale 6d object pose
  estimation dataset for industrial bin-picking,'' in \emph{2019 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 2573--2578.

\bibitem{labbe2020cosypose}
Y.~Labb{\'e}, J.~Carpentier, M.~Aubry, and J.~Sivic, ``Cosypose: Consistent
  multi-view multi-object 6d pose estimation,'' in \emph{European Conference on
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp.
  574--591.

\bibitem{labbe2022megapose}
Y.~Labb{\'e}, L.~Manuelli, A.~Mousavian, S.~Tyree, S.~Birchfield, J.~Tremblay,
  J.~Carpentier, M.~Aubry, D.~Fox, and J.~Sivic, ``Megapose: 6d pose estimation
  of novel objects via render \& compare,'' in \emph{6th Annual Conference on
  Robot Learning}, 2022.

\bibitem{Lee2021category}
T.~Lee, B.-U. Lee, M.~Kim, and I.~S. Kweon, ``Category-level metric scale
  object shape and pose estimation,'' \emph{IEEE Robotics and Automation
  Letters}, vol.~6, no.~4, pp. 8575--8582, 2021.

\bibitem{lepetit2009epnp}
V.~Lepetit, F.~Moreno-Noguer, and P.~Fua, ``Epnp: An accurate o (n) solution to
  the pnp problem,'' \emph{International journal of computer vision}, vol.~81,
  no.~2, pp. 155--166, 2009.

\bibitem{li2022nerf}
F.~Li, H.~Yu, I.~Shugurov, B.~Busam, S.~Yang, and S.~Ilic, ``Nerf-pose: A
  first-reconstruct-then-regress approach for weakly-supervised 6d object pose
  estimation,'' \emph{arXiv preprint arXiv:2203.04802}, 2022.

\bibitem{li2018deepim}
Y.~Li, G.~Wang, X.~Ji, Y.~Xiang, and D.~Fox, ``Deepim: Deep iterative matching
  for 6d pose estimation,'' in \emph{Proceedings of the European Conference on
  Computer Vision (ECCV)}, 2018, pp. 683--698.

\bibitem{li2020robust}
Z.~Li, Y.~Hu, M.~Salzmann, and X.~Ji, ``Robust rgb-based 6-dof pose estimation
  without real pose annotations,'' \emph{arXiv preprint arXiv:2008.08391},
  2020.

\bibitem{li2019cdpn}
Z.~Li, G.~Wang, and X.~Ji, ``Cdpn: Coordinates-based disentangled pose network
  for real-time rgb-based 6-dof object pose estimation,'' in \emph{Proceedings
  of the IEEE/CVF International Conference on Computer Vision}, 2019, pp.
  7678--7687.

\bibitem{liao20212nd}
H.~Liao, X.~Song, S.~Zhao, S.~Zhang, X.~Yue, X.~Yao, Y.~Zhang, T.~Xing, P.~Xu,
  and Q.~Wang, ``2nd place solution for visda 2021 challenge--universally
  domain adaptive image recognition,'' \emph{arXiv preprint arXiv:2110.14240},
  2021.

\bibitem{lin2017focal}
T.-Y. Lin, P.~Goyal, R.~Girshick, K.~He, and P.~Doll{\'a}r, ``Focal loss for
  dense object detection,'' in \emph{Proceedings of the IEEE/CVF international
  conference on computer vision}, 2017, pp. 2980--2988.

\bibitem{corl2020softgym}
X.~Lin, Y.~Wang, J.~Olkin, and D.~Held, ``Softgym: Benchmarking deep
  reinforcement learning for deformable object manipulation,'' in
  \emph{Conference on Robot Learning}, 2020.

\bibitem{lin2022single}
Y.~Lin, J.~Tremblay, S.~Tyree, P.~A. Vela, and S.~Birchfield, ``Single-stage
  keypoint-based category-level object pose estimation from an rgb image,'' in
  \emph{2022 International Conference on Robotics and Automation (ICRA)}.\hskip
  1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 1547--1553.

\bibitem{lipson2022coupled}
L.~Lipson, Z.~Teed, A.~Goyal, and J.~Deng, ``Coupled iterative refinement for
  6d multi-object pose estimation,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6728--6737.

\bibitem{liu2022toward}
L.~Liu, H.~Xue, W.~Xu, H.~Fu, and C.~Lu, ``Toward real-world category-level
  articulation pose estimation,'' \emph{IEEE Transactions on Image Processing},
  vol.~31, pp. 1072--1083, 2022.

\bibitem{liu2021mfpn6d}
P.~Liu, Q.~Zhang, J.~Zhang, F.~Wang, and J.~Cheng, ``Mfpn-6d : Real-time
  one-stage pose estimation of objects on rgb images,'' in \emph{2021 IEEE
  International Conference on Robotics and Automation (ICRA)}, 2021, pp.
  12\,939--12\,945.

\bibitem{liu2021kdfnet}
X.~Liu, S.~Iwase, and K.~M. Kitani, ``Kdfnet: Learning keypoint distance field
  for 6d object pose estimation,'' in \emph{2021 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS)}, 2021, pp. 4631--4638.

\bibitem{liu2020keypose}
X.~Liu, R.~Jonschkowski, A.~Angelova, and K.~Konolige, ``Keypose: Multi-view 3d
  labeling and keypoint estimation for transparent objects,'' in
  \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern
  recognition}, 2020, pp. 11\,602--11\,610.

\bibitem{liu2022gen6d}
Y.~Liu, Y.~Wen, S.~Peng, C.~Lin, X.~Long, T.~Komura, and W.~Wang, ``Gen6d:
  Generalizable model-free 6-dof object pose estimation from rgb images,'' in
  \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2022, pp. 298--315.

\bibitem{liu2022convnet}
Z.~Liu, H.~Mao, C.-Y. Wu, C.~Feichtenhofer, T.~Darrell, and S.~Xie, ``A convnet
  for the 2020s,'' \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem{lopes2023cross}
I.~Lopes, T.-H. Vu, and R.~de~Charette, ``Cross-task attention mechanism for
  dense multi-task learning,'' in \emph{Proceedings of the IEEE/CVF Winter
  Conference on Applications of Computer Vision}, 2023, pp. 2329--2338.

\bibitem{lu2022slam}
Z.~Lu, Y.~Zhang, K.~Doherty, O.~Severinsen, E.~Yang, and J.~Leonard,
  ``Slam-supported self-training for 6d object pose estimation,'' in \emph{2022
  IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  2022, pp. 2833--2840.

\bibitem{ma2022robust}
W.~Ma, A.~Wang, A.~Yuille, and A.~Kortylewski, ``Robust category-level 6d pose
  estimation with coarse-to-fine rendering of neural features,'' in
  \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel,
  October 23--27, 2022, Proceedings, Part IX}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2022, pp. 492--508.

\bibitem{manhardt2019explaining}
F.~Manhardt, D.~M. Arroyo, C.~Rupprecht, B.~Busam, T.~Birdal, N.~Navab, and
  F.~Tombari, ``Explaining the ambiguity of object detection and 6d pose from
  visual data,'' in \emph{Proceedings of the IEEE/CVF International Conference
  on Computer Vision}, 2019, pp. 6841--6850.

\bibitem{manhardt2018deep}
F.~Manhardt, W.~Kehl, N.~Navab, and F.~Tombari, ``Deep model-based 6d pose
  refinement in rgb,'' in \emph{Proceedings of the European Conference on
  Computer Vision (ECCV)}, 2018, pp. 800--815.

\bibitem{mei2022spatial}
\BIBentryALTinterwordspacing
J.~Mei, X.~Jiang, and H.~Ding, ``Spatial feature mapping for 6dof object pose
  estimation,'' \emph{Pattern Recognition}, vol. 131, p. 108835, 2022.
  [Online]. Available:
  \url{https://www.sciencedirect.com/science/article/pii/S0031320322003168}
\BIBentrySTDinterwordspacing

\bibitem{mildenhall2021nerf}
B.~Mildenhall, P.~P. Srinivasan, M.~Tancik, J.~T. Barron, R.~Ramamoorthi, and
  R.~Ng, ``Nerf: Representing scenes as neural radiance fields for view
  synthesis,'' \emph{Communications of the ACM}, vol.~65, no.~1, pp. 99--106,
  2021.

\bibitem{nguyen2022templates}
V.~N. Nguyen, Y.~Hu, Y.~Xiao, M.~Salzmann, and V.~Lepetit, ``Templates for 3d
  object pose estimation revisited: Generalization to new objects and
  robustness to occlusions,'' in \emph{Proceedings of the IEEE/CVF Conference
  on Computer Vision and Pattern Recognition}, 2022, pp. 6771--6780.

\bibitem{Nie_2020_CVPR}
Y.~Nie, X.~Han, S.~Guo, Y.~Zheng, J.~Chang, and J.~J. Zhang,
  ``Total3dunderstanding: Joint layout, object pose and mesh reconstruction for
  indoor scenes from a single image,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, June 2020.

\bibitem{oberweger2018making}
M.~Oberweger, M.~Rad, and V.~Lepetit, ``Making deep heatmaps robust to partial
  occlusions for 3d object pose estimation,'' in \emph{Proceedings of the
  European Conference on Computer Vision}, 2018, pp. 119--134.

\bibitem{okorn2021zephyr}
B.~Okorn, Q.~Gu, M.~Hebert, and D.~Held, ``Zephyr: Zero-shot pose hypothesis
  rating,'' in \emph{2021 IEEE International Conference on Robotics and
  Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp.
  14\,141--14\,148.

\bibitem{park2022dprost}
J.~Park and N.~I. Cho, ``Dprost: Dynamic projective spatial transformer network
  for 6d pose estimation,'' in \emph{Computer Vision--ECCV 2022: 17th European
  Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part
  VI}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 363--379.

\bibitem{Park_2019_ICCV}
K.~Park, T.~Patten, and M.~Vincze, ``Pix2pose: Pix2pose: Pixel-wise coordinate
  regression of objects for 6d pose estimation,'' in \emph{Proceedings of the
  IEEE/CVF International Conference on Computer Vision}, Oct 2019.

\bibitem{patten2020dgcm}
T.~Patten, K.~Park, and M.~Vincze, ``Dgcm-net: dense geometrical correspondence
  matching network for incremental experience-based robotic grasping,''
  \emph{Frontiers in Robotics and AI}, p. 120, 2020.

\bibitem{peng2019pvnet}
S.~Peng, Y.~Liu, Q.~Huang, X.~Zhou, and H.~Bao, ``Pvnet: Pixel-wise voting
  network for 6dof pose estimation,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2019.

\bibitem{peng2022pvnet}
S.~Peng, X.~Zhou, Y.~Liu, H.~Lin, Q.~Huang, and H.~Bao, ``Pvnet: Pixel-wise
  voting network for 6dof object pose estimation,'' \emph{IEEE Transactions on
  Pattern Analysis and Machine Intelligence}, vol.~44, no.~6, pp. 3212--3223,
  2022.

\bibitem{rad2017bb8}
M.~Rad and V.~Lepetit, ``Bb8: A scalable, accurate, robust to partial occlusion
  method for predicting the 3d poses of challenging objects without using
  depth,'' in \emph{Proceedings of the IEEE international conference on
  computer vision}, 2017, pp. 3828--3836.

\bibitem{remus2023i2c-net}
A.~Remus, S.~D'Avella, F.~D. Felice, P.~Tripicchio, and C.~A. Avizzano,
  ``i2c-net: Using instance-level neural networks for monocular category-level
  6d pose estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~8,
  no.~3, pp. 1515--1522, 2023.

\bibitem{rennie2016rutgers}
C.~Rennie, R.~Shome, K.~E. Bekris, and A.~F. De~Souza, ``A dataset for improved
  rgbd-based object detection and pose estimation for warehouse
  pick-and-place,'' \emph{IEEE Robotics and Automation Letters}, vol.~1, no.~2,
  pp. 1179--1185, 2016.

\bibitem{richter2021handling}
J.~Richter-Klug and U.~Frese, ``Handling object symmetries in cnn-based pose
  estimation,'' in \emph{2021 IEEE International Conference on Robotics and
  Automation (ICRA)}, 2021, pp. 13\,850--13\,856.

\bibitem{rusinkiewicz2001efficient}
S.~Rusinkiewicz and M.~Levoy, ``Efficient variants of the icp algorithm,'' in
  \emph{Proceedings third international conference on 3-D digital imaging and
  modeling}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2001, pp. 145--152.

\bibitem{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein \emph{et~al.}, ``Imagenet large scale
  visual recognition challenge,'' \emph{International journal of computer
  vision}, vol. 115, no.~3, pp. 211--252, 2015.

\bibitem{sahin2020review}
C.~Sahin, G.~Garcia-Hernando, J.~Sock, and T.-K. Kim, ``A review on object pose
  recovery: from 3d bounding box detectors to full 6d pose estimators,''
  \emph{Image and Vision Computing}, vol.~96, p. 103898, 2020.

\bibitem{saxena2023generalizable}
V.~Saxena, K.~R. Malekshan, L.~Tran, and Y.~Koga, ``Generalizable pose
  estimation using implicit scene representations,'' 2023.

\bibitem{shao2020pfrl}
J.~Shao, Y.~Jiang, G.~Wang, Z.~Li, and X.~Ji, ``Pfrl: Pose-free reinforcement
  learning for 6d pose estimation,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2020, pp.
  11\,454--11\,463.

\bibitem{shi2021fastUQ}
G.~Shi, Y.~Zhu, J.~Tremblay, S.~Birchfield, F.~Ramos, A.~Anandkumar, and
  Y.~Zhu, ``Fast uncertainty quantification for deep object pose estimation,''
  in \emph{2021 IEEE International Conference on Robotics and Automation
  (ICRA)}, 2021, pp. 5200--5207.

\bibitem{shi2021stablepose}
Y.~Shi, J.~Huang, X.~Xu, Y.~Zhang, and K.~Xu, ``Stablepose: Learning 6d object
  poses from geometrically stable patches,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021, pp.
  15\,222--15\,231.

\bibitem{shugurov2022osop}
I.~Shugurov, F.~Li, B.~Busam, and S.~Ilic, ``Osop: A multi-stage one shot
  object pose estimation framework,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6835--6844.

\bibitem{shugurov2022dpodv2}
I.~Shugurov, S.~Zakharov, and S.~Ilic, ``Dpodv2: Dense correspondence-based 6
  dof pose estimation,'' \emph{IEEE Transactions on Pattern Analysis and
  Machine Intelligence}, vol.~44, no.~11, pp. 7417--7435, 2022.

\bibitem{sock2018multi}
\BIBentryALTinterwordspacing
J.~Sock, K.~I. Kim, C.~Sahin, and T.~Kim, ``Multi-task deep networks for
  depth-based 6d object pose and joint registration in crowd scenarios,'' in
  \emph{British Machine Vision Conference 2018, {BMVC} 2018, Newcastle, UK,
  September 3-6, 2018}.\hskip 1em plus 0.5em minus 0.4em\relax {BMVA} Press,
  2018, p.~90. [Online]. Available:
  \url{http://bmvc2018.org/contents/papers/0284.pdf}
\BIBentrySTDinterwordspacing

\bibitem{song2020hybridpose}
C.~Song, J.~Song, and Q.~Huang, ``Hybridpose: 6d object pose estimation under
  hybrid representations,'' in \emph{Proceedings of the IEEE/CVF conference on
  computer vision and pattern recognition}, 2020, pp. 431--440.

\bibitem{su2022zebrapose}
Y.~Su, M.~Saleh, T.~Fetzer, J.~Rambach, N.~Navab, B.~Busam, D.~Stricker, and
  F.~Tombari, ``Zebrapose: Coarse to fine surface encoding for 6dof object pose
  estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2022, pp. 6738--6748.

\bibitem{suchi20233d}
M.~Suchi, B.~Neuberger, A.~Salykov, J.-B. Weibel, T.~Patten, and M.~Vincze,
  ``3d-dat: 3d-dataset annotation toolkit for robotic vision,'' in \emph{2023
  IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 9162--9168.

\bibitem{Sun_2022_onepose}
J.~Sun, Z.~Wang, S.~Zhang, X.~He, H.~Zhao, G.~Zhang, and X.~Zhou, ``Onepose:
  One-shot object pose estimation without cad models,'' in \emph{Proceedings of
  the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  June 2022, pp. 6825--6834.

\bibitem{sundermeyer2018implicit}
M.~Sundermeyer, Z.-C. Marton, M.~Durner, M.~Brucker, and R.~Triebel, ``Implicit
  3d orientation learning for 6d object detection from rgb images,'' in
  \emph{Proceedings of the european conference on computer vision}, 2018, pp.
  699--715.

\bibitem{tan2019efficientnet}
M.~Tan and Q.~Le, ``Efficientnet: Rethinking model scaling for convolutional
  neural networks,'' in \emph{International conference on machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2019, pp. 6105--6114.

\bibitem{tekin2018real}
B.~Tekin, S.~N. Sinha, and P.~Fua, ``Real-time seamless single shot 6d object
  pose prediction,'' in \emph{Proceedings of the IEEE conference on computer
  vision and pattern recognition}, 2018, pp. 292--301.

\bibitem{thalhammer2021pyrapose}
S.~Thalhammer, M.~Leitner, T.~Patten, and M.~Vincze, ``Pyrapose: Feature
  pyramids for fast and accurate object pose estimation under domain shift,''
  in \emph{2021 IEEE International Conference on Robotics and Automation
  (ICRA)}, 2021, pp. 13\,909--13\,915.

\bibitem{thalhammer2022cope}
S.~Thalhammer, T.~Patten, and M.~Vincze, ``Cope: End-to-end trainable constant
  runtime object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Winter
  Conference on Applications of Computer Vision}, 2023, pp. 2860--2870.

\bibitem{thalhammer2023self}
S.~Thalhammer, J.-B. Weibel, M.~Vincze, and J.~Garcia-Rodriguez,
  ``Self-supervised vision transformers for 3d pose estimation of novel
  objects,'' \emph{arXiv preprint arXiv:2306.00129}, 2023.

\bibitem{tian_fcos}
Z.~Tian, C.~Shen, H.~Chen, and T.~He, ``Fcos: Fully convolutional one-stage
  object detection,'' in \emph{Proceedings of the IEEE/CVF international
  conference on computer vision}, 2019, pp. 9627--9636.

\bibitem{tyree20226}
S.~Tyree, J.~Tremblay, T.~To, J.~Cheng, T.~Mosier, J.~Smith, and S.~Birchfield,
  ``6-dof pose estimation of household objects for robotic manipulation: An
  accessible dataset and benchmark,'' in \emph{2022 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2022, pp. 13\,081--13\,088.

\bibitem{vidal20186d}
J.~Vidal, C.-Y. Lin, and R.~Mart{\'\i}, ``6d pose estimation using an improved
  method based on point pair features,'' in \emph{2018 4th international
  conference on control, automation and robotics (iccar)}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2018, pp. 405--409.

\bibitem{wang2019densefusion}
C.~Wang, D.~Xu, Y.~Zhu, R.~Mart{\'\i}n-Mart{\'\i}n, C.~Lu, L.~Fei-Fei, and
  S.~Savarese, ``Densefusion: 6d object pose estimation by iterative dense
  fusion,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 2019, pp. 3343--3352.

\bibitem{wang2021self6d++}
G.~Wang, F.~Manhardt, X.~Liu, X.~Ji, and F.~Tombari, ``Occlusion-aware
  self-supervised monocular 6d object pose estimation,'' \emph{IEEE
  Transactions on Pattern Analysis and Machine Intelligence}, pp. 1--1, 2021.

\bibitem{wang2020self6d}
G.~Wang, F.~Manhardt, J.~Shao, X.~Ji, N.~Navab, and F.~Tombari, ``Self6d:
  Self-supervised monocular 6d object pose estimation,'' in \emph{Proceedings
  of the European Conference on Computer Vision}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2020, pp. 108--125.

\bibitem{wang2021gdr}
G.~Wang, F.~Manhardt, F.~Tombari, and X.~Ji, ``Gdr-net: Geometry-guided direct
  regression network for monocular 6d object pose estimation,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2021, pp. 16\,611--16\,621.

\bibitem{wang2019normalized}
H.~Wang, S.~Sridhar, J.~Huang, J.~Valentin, S.~Song, and L.~J. Guibas,
  ``Normalized object coordinate space for category-level 6d object pose and
  size estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, 2019, pp. 2642--2651.

\bibitem{wang2022phocal}
P.~Wang, H.~Jung, Y.~Li, S.~Shen, R.~P. Srikanth, L.~Garattoni, S.~Meier,
  N.~Navab, and B.~Busam, ``Phocal: A multi-modal dataset for category-level
  object pose estimation with photometrically challenging objects,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2022, pp. 21\,222--21\,231.

\bibitem{wen2022disp6d}
Y.~Wen, X.~Li, H.~Pan, L.~Yang, Z.~Wang, T.~Komura, and W.~Wang, ``Disp6d:
  Disentangled implicit shape and pose learning for scalable 6d pose
  estimation,'' in \emph{Computer Vision--ECCV 2022: 17th European Conference,
  Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part IX}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2022, pp. 404--421.

\bibitem{xiang2017posecnn}
Y.~Xiang, T.~Schmidt, V.~Narayanan, and D.~Fox, ``Posecnn: A convolutional
  neural network for 6d object pose estimation in cluttered scenes.''\hskip 1em
  plus 0.5em minus 0.4em\relax Robotics: Science and Systems Foundation, 2018.

\bibitem{Yang_2023_CVPR}
H.~Yang and M.~Pavone, ``Object pose estimation with statistical guarantees:
  Conformal keypoint detection and geometric uncertainty propagation,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2023, pp. 8947--8958.

\bibitem{yang2022image}
X.~Yang, X.~Fan, J.~Wang, and K.~Lee, ``Image translation based synthetic data
  generation for industrial object detection and pose estimation,'' \emph{IEEE
  Robotics and Automation Letters}, vol.~7, no.~3, pp. 7201--7208, 2022.

\bibitem{yen2021inerf}
L.~Yen-Chen, P.~Florence, J.~T. Barron, A.~Rodriguez, P.~Isola, and T.-Y. Lin,
  ``inerf: Inverting neural radiance fields for pose estimation,'' in
  \emph{2021 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)}, 2021, pp. 1323--1330.

\bibitem{yu2023TGFnet}
H.~Yu, S.~Li, H.~Liu, C.~Xia, W.~Ding, and B.~Liang, ``Tgf-net: Sim2real
  transparent object 6d pose estimation based on geometric fusion,'' \emph{IEEE
  Robotics and Automation Letters}, vol.~8, no.~6, pp. 3868--3875, 2023.

\bibitem{zakharov2019dpod}
S.~Zakharov, I.~Shugurov, and S.~Ilic, ``Dpod: 6d pose object detector and
  refiner,'' in \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, 2019, pp. 1941--1950.

\bibitem{zhang2022transnet}
H.~Zhang, A.~Opipari, X.~Chen, J.~Zhu, Z.~Yu, and O.~C. Jenkins, ``Transnet:
  Category-level transparent object pose estimation,'' in \emph{European
  Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2022, pp. 148--164.

\bibitem{zhang2021keypoint}
S.~Zhang, W.~Zhao, Z.~Guan, X.~Peng, and J.~Peng, ``Keypoint-graph-driven
  learning framework for object pose estimation,'' in \emph{Proceedings of the
  IEEE/CVF conference on computer vision and pattern recognition}, 2021, pp.
  1065--1073.

\bibitem{zhou2021probabilistic}
X.~Zhou, V.~Koltun, and P.~Kr{\"a}henb{\"u}hl, ``Probabilistic two-stage
  detection,'' \emph{arXiv preprint arXiv:2103.07461}, 2021.

\bibitem{zhou2019continuity}
Y.~Zhou, C.~Barnes, J.~Lu, J.~Yang, and H.~Li, ``On the continuity of rotation
  representations in neural networks,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2019, pp. 5745--5753.

\end{thebibliography}
