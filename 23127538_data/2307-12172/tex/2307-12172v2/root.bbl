% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{100}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{patten2020dgcm}
T.~Patten, K.~Park, and M.~Vincze, ``Dgcm-net: dense geometrical correspondence matching network for incremental experience-based robotic grasping,'' \emph{Frontiers in Robotics and AI}, p. 120, 2020.

\bibitem{kleeberger2019large}
K.~Kleeberger, C.~Landgraf, and M.~F. Huber, ``Large-scale 6d object pose estimation dataset for industrial bin-picking,'' in \emph{2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 2573--2578.

\bibitem{Nie_2020_CVPR}
Y.~Nie, X.~Han, S.~Guo, Y.~Zheng, J.~Chang, and J.~J. Zhang, ``Total3dunderstanding: Joint layout, object pose and mesh reconstruction for indoor scenes from a single image,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, June 2020.

\bibitem{hodan2022bop}
T.~Hoda{\v{n}}, M.~Sundermeyer, B.~Drost, Y.~Labb{\'e}, E.~Brachmann, F.~Michel, C.~Rother, and J.~Matas, ``Placeholder,'' \emph{Proceedings of the European Conference on Computer Vision Workshops}, 2020.

\bibitem{hodan2020epos}
T.~Hodan, D.~Barath, and J.~Matas, ``Epos: Estimating 6d pose of objects with symmetries,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2020, pp. 11\,703--11\,712.

\bibitem{xiang2017posecnn}
Y.~Xiang, T.~Schmidt, V.~Narayanan, and D.~Fox, ``Posecnn: A convolutional neural network for 6d object pose estimation in cluttered scenes.''\hskip 1em plus 0.5em minus 0.4em\relax Robotics: Science and Systems Foundation, 2018.

\bibitem{he20206d}
Z.~He, W.~Feng, X.~Zhao, and Y.~Lv, ``6d pose estimation of objects: Recent technologies and challenges,'' \emph{Applied Sciences}, vol.~11, no.~1, p. 228, 2020.

\bibitem{sahin2020review}
C.~Sahin, G.~Garcia-Hernando, J.~Sock, and T.-K. Kim, ``A review on object pose recovery: from 3d bounding box detectors to full 6d pose estimators,'' \emph{Image and Vision Computing}, vol.~96, p. 103898, 2020.

\bibitem{hoque2021comprehensive}
S.~Hoque, M.~Y. Arafat, S.~Xu, A.~Maiti, and Y.~Wei, ``A comprehensive review on 3d object detection and 6d pose estimation with deep learning,'' \emph{IEEE Access}, vol.~9, pp. 143\,746--143\,770, 2021.

\bibitem{fan2022deep}
Z.~Fan, Y.~Zhu, Y.~He, Q.~Sun, H.~Liu, and J.~He, ``Deep learning on monocular object pose detection and tracking: A comprehensive overview,'' \emph{ACM Computing Surveys}, vol.~55, no.~4, pp. 1--40, 2022.

\bibitem{marullo20236d}
G.~Marullo, L.~Tanzi, P.~Piazzolla, and E.~Vezzetti, ``6d object position estimation from 2d images: A literature review,'' \emph{Multimedia Tools and Applications}, vol.~82, no.~16, pp. 24\,605--24\,643, 2023.

\bibitem{firoozi2023foundation}
R.~Firoozi, J.~Tucker, S.~Tian, A.~Majumdar, J.~Sun, W.~Liu, Y.~Zhu, S.~Song, A.~Kapoor, K.~Hausman \emph{et~al.}, ``Foundation models in robotics: Applications, challenges, and the future,'' \emph{arXiv preprint arXiv:2312.07843}, 2023.

\bibitem{padalkar2023open}
A.~Padalkar, A.~Pooley, A.~Jain, A.~Bewley, A.~Herzog, A.~Irpan, A.~Khazatsky, A.~Rai, A.~Singh, A.~Brohan \emph{et~al.}, ``Open x-embodiment: Robotic learning datasets and rt-x models,'' \emph{arXiv preprint arXiv:2310.08864}, 2023.

\bibitem{fang2023anygrasp}
H.-S. Fang, C.~Wang, H.~Fang, M.~Gou, J.~Liu, H.~Yan, W.~Liu, Y.~Xie, and C.~Lu, ``Anygrasp: Robust and efficient grasp perception in spatial and temporal domains,'' \emph{IEEE Transactions on Robotics}, 2023.

\bibitem{black2023zero}
K.~Black, M.~Nakamoto, P.~Atreya, H.~Walke, C.~Finn, A.~Kumar, and S.~Levine, ``Zero-shot robotic manipulation with pretrained image-editing diffusion models,'' \emph{arXiv preprint arXiv:2310.10639}, 2023.

\bibitem{zhang2021keypoint}
S.~Zhang, W.~Zhao, Z.~Guan, X.~Peng, and J.~Peng, ``Keypoint-graph-driven learning framework for object pose estimation,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2021, pp. 1065--1073.

\bibitem{hu2022perspective}
Y.~Hu, P.~Fua, and M.~Salzmann, ``Perspective flow aggregation for data-limited 6d object pose estimation,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 89--106.

\bibitem{nguyen2022templates}
V.~N. Nguyen, Y.~Hu, Y.~Xiao, M.~Salzmann, and V.~Lepetit, ``Templates for 3d object pose estimation revisited: Generalization to new objects and robustness to occlusions,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6771--6780.

\bibitem{wang2021self6d++}
G.~Wang, F.~Manhardt, X.~Liu, X.~Ji, and F.~Tombari, ``Occlusion-aware self-supervised monocular 6d object pose estimation,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, pp. 1--1, 2021.

\bibitem{thalhammer2021pyrapose}
S.~Thalhammer, M.~Leitner, T.~Patten, and M.~Vincze, ``Pyrapose: Feature pyramids for fast and accurate object pose estimation under domain shift,'' in \emph{2021 IEEE International Conference on Robotics and Automation (ICRA)}, 2021, pp. 13\,909--13\,915.

\bibitem{shi2021fastUQ}
G.~Shi, Y.~Zhu, J.~Tremblay, S.~Birchfield, F.~Ramos, A.~Anandkumar, and Y.~Zhu, ``Fast uncertainty quantification for deep object pose estimation,'' in \emph{2021 IEEE International Conference on Robotics and Automation (ICRA)}, 2021, pp. 5200--5207.

\bibitem{lu2022slam}
Z.~Lu, Y.~Zhang, K.~Doherty, O.~Severinsen, E.~Yang, and J.~Leonard, ``Slam-supported self-training for 6d object pose estimation,'' in \emph{2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2022, pp. 2833--2840.

\bibitem{ikeda2022sim2real}
T.~Ikeda, S.~Tanishige, A.~Amma, M.~Sudano, H.~Audren, and K.~Nishiwaki, ``Sim2real instance-level style transfer for 6d pose estimation,'' in \emph{2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2022, pp. 3225--3232.

\bibitem{yang2022image}
X.~Yang, X.~Fan, J.~Wang, and K.~Lee, ``Image translation based synthetic data generation for industrial object detection and pose estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~7, no.~3, pp. 7201--7208, 2022.

\bibitem{jawaid2023towards}
M.~Jawaid, E.~Elms, Y.~Latif, and T.-J. Chin, ``Towards bridging the space domain gap for satellite pose estimation using event sensing,'' 2023.

\bibitem{Chen_2023_CVPR}
H.~Chen, F.~Manhardt, N.~Navab, and B.~Busam, ``Texpose: Neural texture learning for self-supervised 6d object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2023, pp. 4841--4852.

\bibitem{ma2022robust}
W.~Ma, A.~Wang, A.~Yuille, and A.~Kortylewski, ``Robust category-level 6d pose estimation with coarse-to-fine rendering of neural features,'' in \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part IX}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 492--508.

\bibitem{peng2022pvnet}
S.~Peng, X.~Zhou, Y.~Liu, H.~Lin, Q.~Huang, and H.~Bao, ``Pvnet: Pixel-wise voting network for 6dof object pose estimation,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~44, no.~6, pp. 3212--3223, 2022.

\bibitem{shugurov2022dpodv2}
I.~Shugurov, S.~Zakharov, and S.~Ilic, ``Dpodv2: Dense correspondence-based 6 dof pose estimation,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~44, no.~11, pp. 7417--7435, 2022.

\bibitem{liu2021mfpn6d}
P.~Liu, Q.~Zhang, J.~Zhang, F.~Wang, and J.~Cheng, ``Mfpn-6d : Real-time one-stage pose estimation of objects on rgb images,'' in \emph{2021 IEEE International Conference on Robotics and Automation (ICRA)}, 2021, pp. 12\,939--12\,945.

\bibitem{liu2021kdfnet}
X.~Liu, S.~Iwase, and K.~M. Kitani, ``Kdfnet: Learning keypoint distance field for 6d object pose estimation,'' in \emph{2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2021, pp. 4631--4638.

\bibitem{mei2022spatial}
\BIBentryALTinterwordspacing
J.~Mei, X.~Jiang, and H.~Ding, ``Spatial feature mapping for 6dof object pose estimation,'' \emph{Pattern Recognition}, vol. 131, p. 108835, 2022. [Online]. Available: \url{https://www.sciencedirect.com/science/article/pii/S0031320322003168}
\BIBentrySTDinterwordspacing

\bibitem{hai2023rigidity}
Y.~Hai, R.~Song, J.~Li, M.~Salzmann, and Y.~Hu, ``Rigidity-aware detection for 6d object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 8927--8936.

\bibitem{xu20236d}
L.~Xu, H.~Qu, Y.~Cai, and J.~Liu, ``6d-diff: A keypoint diffusion framework for 6d object pose estimation,'' \emph{arXiv preprint arXiv:2401.00029}, 2023.

\bibitem{wang2022multiple}
J.~Wang, L.~Qiu, G.~Yi, S.~Zhang, and Y.~Wang, ``Multiple geometry representations for 6d object pose estimation in occluded or truncated scenes,'' \emph{Pattern Recognition}, vol. 132, p. 108903, 2022.

\bibitem{huang2022neural}
L.~Huang, T.~Hodan, L.~Ma, L.~Zhang, L.~Tran, C.~Twigg, P.-C. Wu, J.~Yuan, C.~Keskin, and R.~Wang, ``Neural correspondence field for object pose estimation,'' in \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part X}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 585--603.

\bibitem{di2021so}
Y.~Di, F.~Manhardt, G.~Wang, X.~Ji, N.~Navab, and F.~Tombari, ``So-pose: Exploiting self-occlusion for direct 6d pose estimation,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 12\,396--12\,405.

\bibitem{park2022dprost}
J.~Park and N.~I. Cho, ``Dprost: Dynamic projective spatial transformer network for 6d pose estimation,'' in \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part VI}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 363--379.

\bibitem{su2022zebrapose}
Y.~Su, M.~Saleh, T.~Fetzer, J.~Rambach, N.~Navab, B.~Busam, D.~Stricker, and F.~Tombari, ``Zebrapose: Coarse to fine surface encoding for 6dof object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6738--6748.

\bibitem{yen2021inerf}
L.~Yen-Chen, P.~Florence, J.~T. Barron, A.~Rodriguez, P.~Isola, and T.-Y. Lin, ``inerf: Inverting neural radiance fields for pose estimation,'' in \emph{2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2021, pp. 1323--1330.

\bibitem{liu2023linear}
F.~Liu, Y.~Hu, and M.~Salzmann, ``Linear-covariance loss for end-to-end learning of 6d pose estimation,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 14\,107--14\,117.

\bibitem{lian2023checkerpose}
R.~Lian and H.~Ling, ``Checkerpose: Progressive dense keypoint localization for object pose estimation with graph neural network,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 14\,022--14\,033.

\bibitem{li2024mrc}
Y.~Li, Y.~Mao, R.~Bala, and S.~Hadap, ``Mrc-net: 6-dof pose estimation with multiscale residual correlation,'' \emph{arXiv preprint arXiv:2403.08019}, 2024.

\bibitem{yang2023exploring}
X.~Yang, J.~Cai, K.~Li, and X.~Fan, ``Exploring multiple geometric representations for 6dof object pose estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~8, no.~10, pp. 6115--6122, 2023.

\bibitem{liu2022gen6d}
Y.~Liu, Y.~Wen, S.~Peng, C.~Lin, X.~Long, T.~Komura, and W.~Wang, ``Gen6d: Generalizable model-free 6-dof object pose estimation from rgb images,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 298--315.

\bibitem{shugurov2022osop}
I.~Shugurov, F.~Li, B.~Busam, and S.~Ilic, ``Osop: A multi-stage one shot object pose estimation framework,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6835--6844.

\bibitem{gu2022ossid}
Q.~Gu, B.~Okorn, and D.~Held, ``Ossid: Online self-supervised instance detection by (and for) pose estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~7, no.~2, pp. 3022--3029, 2022.

\bibitem{saxena2023generalizable}
V.~Saxena, K.~R. Malekshan, L.~Tran, and Y.~Koga, ``Generalizable pose estimation using implicit scene representations,'' 2023.

\bibitem{moon2024genflow}
S.~Moon, H.~Son, D.~Hur, and S.~Kim, ``Genflow: Generalizable recurrent flow for 6d pose refinement of novel objects,'' \emph{arXiv preprint arXiv:2403.11510}, 2024.

\bibitem{nguyen2023nope}
V.~N. Nguyen, T.~Groueix, Y.~Hu, M.~Salzmann, and V.~Lepetit, ``Nope: Novel object pose estimation from a single image,'' \emph{arXiv preprint arXiv:2303.13612}, 2023.

\bibitem{wen2024foundationpose}
B.~Wen, W.~Yang, J.~Kautz, and S.~Birchfield, ``Foundationpose: Unified 6d pose estimation and tracking of novel objects,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 17\,868--17\,879.

\bibitem{ausserlechner2023zs6d}
P.~Ausserlechner, D.~Haberger, S.~Thalhammer, J.-B. Weibel, and M.~Vincze, ``Zs6d: Zero-shot 6d object pose estimation using vision transformers,'' \emph{arXiv preprint arXiv:2309.11986}, 2023.

\bibitem{wang2021gdr}
G.~Wang, F.~Manhardt, F.~Tombari, and X.~Ji, ``Gdr-net: Geometry-guided direct regression network for monocular 6d object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021, pp. 16\,611--16\,621.

\bibitem{chen2022epro}
H.~Chen, P.~Wang, F.~Wang, W.~Tian, L.~Xiong, and H.~Li, ``Epro-pnp: Generalized end-to-end probabilistic perspective-n-points for monocular object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 2781--2790.

\bibitem{lipson2022coupled}
L.~Lipson, Z.~Teed, A.~Goyal, and J.~Deng, ``Coupled iterative refinement for 6d multi-object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6728--6737.

\bibitem{cao2022dgecn}
T.~Cao, F.~Luo, Y.~Fu, W.~Zhang, S.~Zheng, and C.~Xiao, ``Dgecn: A depth-guided edge convolutional network for end-to-end 6d pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 3783--3792.

\bibitem{hai2023shape}
Y.~Hai, R.~Song, J.~Li, and Y.~Hu, ``Shape-constraint recurrent flow for 6d object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 4831--4840.

\bibitem{hu2021wide}
Y.~Hu, S.~Speierer, W.~Jakob, P.~Fua, and M.~Salzmann, ``Wide-depth-range 6d object pose estimation in space,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021, pp. 15\,870--15\,879.

\bibitem{viviers2024advancing}
C.~G.~A. Viviers, L.~Filatova, M.~Termeer, P.~H.~N. de~With, and F.~van~der Sommen, ``Advancing 6-dof instrument pose estimation in variable x-ray imaging geometries,'' \emph{IEEE Transactions on Image Processing}, vol.~33, pp. 2462--2476, 2024.

\bibitem{sapienza2023underwater}
D.~Sapienza, E.~Govi, S.~Aldhaheri, M.~Bertogna, E.~Roura, E.~Pairet, M.~Verucchi, and P.~Ardón, ``Model-based underwater 6d pose estimation from rgb,'' \emph{IEEE Robotics and Automation Letters}, vol.~8, no.~11, pp. 7535--7542, 2023.

\bibitem{tang2024rov6d}
J.~Tang, Z.~Chen, B.~Fu, W.~Lu, S.~Li, X.~Li, and X.~Ji, ``Rov6d: 6d pose estimation benchmark dataset for underwater remotely operated vehicles,'' \emph{IEEE Robotics and Automation Letters}, vol.~9, no.~1, pp. 65--72, 2024.

\bibitem{sun2023panelpose}
H.~Sun, P.~Ni, Z.~Li, Y.~Wang, X.~Zhu, and Q.~Cao, ``Panelpose: A 6d pose estimation of highly-variable panel object for robotic robust cockpit panel inspection,'' in \emph{2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2023, pp. 3214--3221.

\bibitem{ulmer2024orbital}
M.~Ulmer, M.~Durner, M.~Sundermeyer, M.~Stoiber, and R.~Triebel, ``6d object pose estimation from approximate 3d models for orbital robotics,'' in \emph{2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2023, pp. 10\,749--10\,756.

\bibitem{monguzzi2024cable}
A.~Monguzzi, C.~Cella, A.~M. Zanchettin, and P.~Rocco, ``Vision-based state and pose estimation for robotic bin picking of cables,'' in \emph{2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2023, pp. 3114--3120.

\bibitem{iwase2021repose}
S.~Iwase, X.~Liu, R.~Khirodkar, R.~Yokota, and K.~M. Kitani, ``Repose: Fast 6d object pose refinement via deep texture rendering,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 3303--3312.

\bibitem{haugaard2021surfemb}
R.~L. Haugaard and A.~G. Buch, ``Surfemb: Dense and continuous correspondence distributions for object pose estimation with learnt surface embeddings,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6749--6758.

\bibitem{araki2021iterative}
R.~Araki, K.~Mano, T.~Hirano, T.~Hirakawa, T.~Yamashita, and H.~Fujiyoshi, ``Iterative coarse-to-fine 6d-pose estimation using back-propagation,'' in \emph{2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp. 3587--3594.

\bibitem{wen2022disp6d}
Y.~Wen, X.~Li, H.~Pan, L.~Yang, Z.~Wang, T.~Komura, and W.~Wang, ``Disp6d: Disentangled implicit shape and pose learning for scalable 6d pose estimation,'' in \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part IX}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 404--421.

\bibitem{richter2021handling}
J.~Richter-Klug and U.~Frese, ``Handling object symmetries in cnn-based pose estimation,'' in \emph{2021 IEEE International Conference on Robotics and Automation (ICRA)}, 2021, pp. 13\,850--13\,856.

\bibitem{bengston2021pose}
S.~H. Bengtson, H.~Åström, T.~B. Moeslund, E.~A. Topp, and V.~Krueger, ``Pose estimation from rgb images of highly symmetric objects using a novel multi-pose loss and differential rendering,'' in \emph{2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2021, pp. 4618--4624.

\bibitem{jeon2023ambiguity}
M.-H. Jeon, J.~Kim, J.-H. Ryu, and A.~Kim, ``Ambiguity-aware multi-object pose optimization for visually-assisted robot manipulation,'' \emph{IEEE Robotics and Automation Letters}, vol.~8, no.~1, pp. 137--144, 2023.

\bibitem{chaitanya2022physics}
\BIBentryALTinterwordspacing
C.~Mitash, A.~Boularias, and K.~Bekris, ``Physics-based scene-level reasoning for object pose estimation in clutter,'' \emph{The International Journal of Robotics Research}, vol.~41, no.~6, pp. 615--636, 2022. [Online]. Available: \url{https://doi.org/10.1177/0278364919846551}
\BIBentrySTDinterwordspacing

\bibitem{fan2022object}
Z.~Fan, Z.~Song, J.~Xu, Z.~Wang, K.~Wu, H.~Liu, and J.~He, ``Object level depth reconstruction for category level 6d object pose estimation from monocular rgb image,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 220--236.

\bibitem{lin2022single}
Y.~Lin, J.~Tremblay, S.~Tyree, P.~A. Vela, and S.~Birchfield, ``Single-stage keypoint-based category-level object pose estimation from an rgb image,'' in \emph{2022 International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 1547--1553.

\bibitem{Lee2021category}
T.~Lee, B.-U. Lee, M.~Kim, and I.~S. Kweon, ``Category-level metric scale object shape and pose estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~6, no.~4, pp. 8575--8582, 2021.

\bibitem{he2022generative}
Z.~He, M.~Wu, X.~Zhao, S.~Zhang, and J.~Tan, ``A generative feature-to-image robotic vision framework for 6d pose measurement of metal parts,'' \emph{IEEE/ASME Transactions on Mechatronics}, vol.~27, no.~5, pp. 3198--3209, 2022.

\bibitem{yu2023TGFnet}
H.~Yu, S.~Li, H.~Liu, C.~Xia, W.~Ding, and B.~Liang, ``Tgf-net: Sim2real transparent object 6d pose estimation based on geometric fusion,'' \emph{IEEE Robotics and Automation Letters}, vol.~8, no.~6, pp. 3868--3875, 2023.

\bibitem{he2023contour}
Z.~He, Q.~Li, X.~Zhao, J.~Wang, H.~Shen, S.~Zhang, and J.~Tan, ``Contourpose: Monocular 6-d pose estimation method for reflective textureless metal parts,'' \emph{IEEE Transactions on Robotics}, vol.~39, no.~5, pp. 4037--4050, 2023.

\bibitem{he2024ggop}
Z.~He, Y.~Chao, M.~Wu, Y.~Hu, and X.~Zhao, ``G-gop: Generative pose estimation of reflective texture-less metal parts with global-observation-point priors,'' \emph{IEEE/ASME Transactions on Mechatronics}, vol.~29, no.~1, pp. 154--165, 2024.

\bibitem{Yang_2023_CVPR}
H.~Yang and M.~Pavone, ``Object pose estimation with statistical guarantees: Conformal keypoint detection and geometric uncertainty propagation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2023, pp. 8947--8958.

\bibitem{guo2023knowledge}
S.~Guo, Y.~Hu, J.~M. Alvarez, and M.~Salzmann, ``Knowledge distillation for 6d pose estimation by aligning distributions of local predictions,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 18\,633--18\,642.

\bibitem{hai2023pseudo}
Y.~Hai, R.~Song, J.~Li, D.~Ferstl, and Y.~Hu, ``Pseudo flow consistency for self-supervised 6d object pose estimation,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 14\,075--14\,085.

\bibitem{hinterstoisser2012model}
S.~Hinterstoisser, V.~Lepetit, S.~Ilic, S.~Holzer, G.~Bradski, K.~Konolige, and N.~Navab, ``Model based training, detection and pose estimation of texture-less {3D} objects in heavily cluttered scenes,'' in \emph{Proceedings of the Asian Conference on Computer Vision}, 2012, pp. 548--562.

\bibitem{brachmann2014learning}
E.~Brachmann, A.~Krull, F.~Michel, S.~Gumhold, J.~Shotton, and C.~Rother, ``Learning {6D} object pose estimation using {3D} object coordinates,'' in \emph{Proceedings of the European Conference on Computer Vision}, 2014, pp. 536--551.

\bibitem{hodan2018bop}
T.~Hodan, F.~Michel, E.~Brachmann, W.~Kehl, A.~GlentBuch, D.~Kraft, B.~Drost, J.~Vidal, S.~Ihrke, X.~Zabulis \emph{et~al.}, ``Bop: Benchmark for 6d object pose estimation,'' in \emph{Proceedings of the European conference on computer vision (ECCV)}, 2018, pp. 19--34.

\bibitem{doumanoglou2016recovering}
A.~Doumanoglou, R.~Kouskouridas, S.~Malassiotis, and T.-K. Kim, ``Recovering 6d object pose and predicting next-best-view in the crowd,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2016, pp. 3583--3592.

\bibitem{homebrewedDB}
R.~Kaskman, S.~Zakharov, I.~Shugurov, and S.~Ilic, ``Homebreweddb: Rgb-d dataset for 6d pose estimation of 3d objects,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops}, 2019, pp. 0--0.

\bibitem{hodan2017tless}
T.~Hodan, P.~Haluza, {\v{S}}.~Obdr{\v{z}}{\'a}lek, J.~Matas, M.~Lourakis, and X.~Zabulis, ``T-less: An rgb-d dataset for 6d pose estimation of texture-less objects,'' in \emph{2017 IEEE Winter Conference on Applications of Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2017, pp. 880--888.

\bibitem{drost2017introducing}
B.~Drost, M.~Ulrich, P.~Bergmann, P.~Hartinger, and C.~Steger, ``Introducing mvtec itodd-a dataset for 3d object recognition in industry,'' in \emph{Proceedings of the IEEE international conference on computer vision workshops}, 2017, pp. 2200--2208.

\bibitem{wang2019normalized}
H.~Wang, S.~Sridhar, J.~Huang, J.~Valentin, S.~Song, and L.~J. Guibas, ``Normalized object coordinate space for category-level 6d object pose and size estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019, pp. 2642--2651.

\bibitem{chen2022clearpose}
X.~Chen, H.~Zhang, Z.~Yu, A.~Opipari, and O.~Chadwicke~Jenkins, ``Clearpose: Large-scale transparent object dataset and benchmark,'' in \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part VIII}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 381--396.

\bibitem{dai2022dreds}
Q.~Dai, J.~Zhang, Q.~Li, T.~Wu, H.~Dong, Z.~Liu, P.~Tan, and H.~Wang, ``Domain randomization-enhanced depth simulation and restoration for perceiving and grasping specular and transparent objects,'' in \emph{European Conference on Computer Vision (ECCV)}, 2022.

\bibitem{wang2022phocal}
P.~Wang, H.~Jung, Y.~Li, S.~Shen, R.~P. Srikanth, L.~Garattoni, S.~Meier, N.~Navab, and B.~Busam, ``Phocal: A multi-modal dataset for category-level object pose estimation with photometrically challenging objects,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 21\,222--21\,231.

\bibitem{liu2020keypose}
X.~Liu, R.~Jonschkowski, A.~Angelova, and K.~Konolige, ``Keypose: Multi-view 3d labeling and keypoint estimation for transparent objects,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2020, pp. 11\,602--11\,610.

\bibitem{jung2022housecat6d}
H.~Jung, G.~Zhai, S.-C. Wu, P.~Ruhkamp, H.~Schieber, G.~Rizzoli, P.~Wang, H.~Zhao, L.~Garattoni, S.~Meier \emph{et~al.}, ``Housecat6d--a large-scale multi-modal category level 6d object perception dataset with household objects in realistic scenarios,'' \emph{arXiv preprint arXiv:2212.10428}, 2022.

\bibitem{fang2022transcg}
H.~Fang, H.-S. Fang, S.~Xu, and C.~Lu, ``Transcg: A large-scale real-world dataset for transparent object depth completion and a grasping baseline,'' \emph{IEEE Robotics and Automation Letters}, pp. 1--8, 2022.

\bibitem{Cao2021suction}
H.~Cao, H.-S. Fang, W.~Liu, and C.~Lu, ``Suctionnet-1billion: A large-scale benchmark for suction grasping,'' \emph{IEEE Robotics and Automation Letters}, vol.~6, no.~4, pp. 8718--8725, 2021.

\bibitem{tyree20226}
S.~Tyree, J.~Tremblay, T.~To, J.~Cheng, T.~Mosier, J.~Smith, and S.~Birchfield, ``6-dof pose estimation of household objects for robotic manipulation: An accessible dataset and benchmark,'' in \emph{2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 13\,081--13\,088.

\bibitem{chen2022MP6D}
L.~Chen, H.~Yang, C.~Wu, and S.~Wu, ``Mp6d: An rgb-d dataset for metal parts’ 6d pose estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~7, no.~3, pp. 5912--5919, 2022.

\bibitem{fang2020graspnet}
H.-S. Fang, C.~Wang, M.~Gou, and C.~Lu, ``Graspnet-1billion: A large-scale benchmark for general object grasping,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2020, pp. 11\,444--11\,453.

\bibitem{Park_2019_ICCV}
K.~Park, T.~Patten, and M.~Vincze, ``Pix2pose: Pix2pose: Pixel-wise coordinate regression of objects for 6d pose estimation,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, Oct 2019.

\bibitem{calli2015ycb}
B.~Calli, A.~Walsman, A.~Singh, S.~Srinivasa, P.~Abbeel, and A.~M. Dollar, ``Benchmarking in manipulation research: Using the yale-cmu-berkeley object and model set,'' \emph{IEEE Robotics \& Automation Magazine}, vol.~22, no.~3, pp. 36--52, 2015.

\bibitem{gou2022unseen}
M.~Gou, H.~Pan, H.-S. Fang, Z.~Liu, C.~Lu, and P.~Tan, ``Unseen object 6d pose estimation: a benchmark and baselines,'' \emph{arXiv preprint arXiv:2206.11808}, 2022.

\bibitem{li2020robust}
Z.~Li, Y.~Hu, M.~Salzmann, and X.~Ji, ``Robust rgb-based 6-dof pose estimation without real pose annotations,'' \emph{arXiv preprint arXiv:2008.08391}, 2020.

\bibitem{wang2020self6d}
G.~Wang, F.~Manhardt, J.~Shao, X.~Ji, N.~Navab, and F.~Tombari, ``Self6d: Self-supervised monocular 6d object pose estimation,'' in \emph{Proceedings of the European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp. 108--125.

\bibitem{rad2018domain}
M.~Rad, M.~Oberweger, and V.~Lepetit, ``Domain transfer for 3d pose estimation from color images without manual annotations,'' in \emph{Asian Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2018, pp. 69--84.

\bibitem{tobin2017domain}
J.~Tobin, R.~Fong, A.~Ray, J.~Schneider, W.~Zaremba, and P.~Abbeel, ``Domain randomization for transferring deep neural networks from simulation to the real world,'' in \emph{2017 IEEE/RSJ international conference on intelligent robots and systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2017, pp. 23--30.

\bibitem{sundermeyer2018implicit}
M.~Sundermeyer, Z.-C. Marton, M.~Durner, M.~Brucker, and R.~Triebel, ``Implicit 3d orientation learning for 6d object detection from rgb images,'' in \emph{Proceedings of the european conference on computer vision}, 2018, pp. 699--715.

\bibitem{li2019cdpn}
Z.~Li, G.~Wang, and X.~Ji, ``Cdpn: Coordinates-based disentangled pose network for real-time rgb-based 6-dof object pose estimation,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2019, pp. 7678--7687.

\bibitem{zakharov2019dpod}
S.~Zakharov, I.~Shugurov, and S.~Ilic, ``Dpod: 6d pose object detector and refiner,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2019, pp. 1941--1950.

\bibitem{hodan2019photorealistic}
T.~Hoda{\v{n}}, V.~Vineet, R.~Gal, E.~Shalev, J.~Hanzelka, T.~Connell, P.~Urbina, S.~N. Sinha, and B.~Guenter, ``Photorealistic image synthesis for object instance detection,'' in \emph{2019 IEEE international conference on image processing}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 66--70.

\bibitem{liu2022gdrnpp_bop}
X.~Liu, R.~Zhang, C.~Zhang, B.~Fu, J.~Tang, X.~Liang, J.~Tang, X.~Cheng, Y.~Zhang, G.~Wang, and X.~Ji, ``Gdrnpp,'' \url{https://github.com/shanice-l/gdrnpp_bop2022}, 2022.

\bibitem{liu2022convnet}
Z.~Liu, H.~Mao, C.-Y. Wu, C.~Feichtenhofer, T.~Darrell, and S.~Xie, ``A convnet for the 2020s,'' \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image recognition,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2016, pp. 770--778.

\bibitem{visda2021}
D.~Bashkirova, D.~Hendrycks, D.~Kim, H.~Liao, S.~Mishra, C.~Rajagopalan, K.~Saenko, K.~Saito, B.~U. Tayyab, P.~Teterwak \emph{et~al.}, ``Visda-2021 competition: Universal domain adaptation to improve performance on out-of-distribution data,'' PMLR, pp. 66--79, 2022.

\bibitem{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang, A.~Karpathy, A.~Khosla, M.~Bernstein \emph{et~al.}, ``Imagenet large scale visual recognition challenge,'' \emph{International journal of computer vision}, vol. 115, no.~3, pp. 211--252, 2015.

\bibitem{hendrycks2019imagenet}
D.~Hendrycks and T.~Dietterich, ``Benchmarking neural network robustness to common corruptions and perturbations,'' 2018.

\bibitem{hendrycks2020imagenet}
D.~Hendrycks, S.~Basart, N.~Mu, S.~Kadavath, F.~Wang, E.~Dorundo, R.~Desai, T.~Zhu, S.~Parajuli, M.~Guo \emph{et~al.}, ``The many faces of robustness: A critical analysis of out-of-distribution generalization,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 8340--8349.

\bibitem{barbu2019objectnet}
A.~Barbu, D.~Mayo, J.~Alverio, W.~Luo, C.~Wang, D.~Gutfreund, J.~Tenenbaum, and B.~Katz, ``Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models,'' \emph{Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{hand2001auroc}
D.~J. Hand and R.~J. Till, ``A simple generalisation of the area under the roc curve for multiple class classification problems,'' \emph{Machine learning}, vol.~45, pp. 171--186, 2001.

\bibitem{tan2019efficientnet}
M.~Tan and Q.~Le, ``Efficientnet: Rethinking model scaling for convolutional neural networks,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2019, pp. 6105--6114.

\bibitem{liao20212nd}
H.~Liao, X.~Song, S.~Zhao, S.~Zhang, X.~Yue, X.~Yao, Y.~Zhang, T.~Xing, P.~Xu, and Q.~Wang, ``2nd place solution for visda 2021 challenge--universally domain adaptive image recognition,'' \emph{arXiv preprint arXiv:2110.14240}, 2021.

\bibitem{hu2019segpose}
Y.~Hu, J.~Hugonot, P.~Fua, and M.~Salzmann, ``Segmentation-driven 6d object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019.

\bibitem{oberweger2018making}
M.~Oberweger, M.~Rad, and V.~Lepetit, ``Making deep heatmaps robust to partial occlusions for 3d object pose estimation,'' in \emph{Proceedings of the European Conference on Computer Vision}, 2018, pp. 119--134.

\bibitem{peng2019pvnet}
S.~Peng, Y.~Liu, Q.~Huang, X.~Zhou, and H.~Bao, ``Pvnet: Pixel-wise voting network for 6dof pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019.

\bibitem{song2020hybridpose}
C.~Song, J.~Song, and Q.~Huang, ``Hybridpose: 6d object pose estimation under hybrid representations,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2020, pp. 431--440.

\bibitem{tekin2018real}
B.~Tekin, S.~N. Sinha, and P.~Fua, ``Real-time seamless single shot 6d object pose prediction,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2018, pp. 292--301.

\bibitem{thalhammer2022cope}
S.~Thalhammer, T.~Patten, and M.~Vincze, ``Cope: End-to-end trainable constant runtime object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, 2023, pp. 2860--2870.

\bibitem{zhou2019continuity}
Y.~Zhou, C.~Barnes, J.~Lu, J.~Yang, and H.~Li, ``On the continuity of rotation representations in neural networks,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019, pp. 5745--5753.

\bibitem{sock2018multi}
\BIBentryALTinterwordspacing
J.~Sock, K.~I. Kim, C.~Sahin, and T.~Kim, ``Multi-task deep networks for depth-based 6d object pose and joint registration in crowd scenarios,'' in \emph{British Machine Vision Conference 2018, {BMVC} 2018, Newcastle, UK, September 3-6, 2018}.\hskip 1em plus 0.5em minus 0.4em\relax {BMVA} Press, 2018, p.~90. [Online]. Available: \url{http://bmvc2018.org/contents/papers/0284.pdf}
\BIBentrySTDinterwordspacing

\bibitem{manhardt2018deep}
F.~Manhardt, W.~Kehl, N.~Navab, and F.~Tombari, ``Deep model-based 6d pose refinement in rgb,'' in \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, 2018, pp. 800--815.

\bibitem{kundu20183d}
A.~Kundu, Y.~Li, and J.~M. Rehg, ``3d-rcnn: Instance-level 3d object reconstruction via render-and-compare,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2018, pp. 3559--3568.

\bibitem{wohlhart2015learning}
P.~Wohlhart and V.~Lepetit, ``Learning descriptors for object recognition and 3d pose estimation,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2015, pp. 3109--3118.

\bibitem{labbe2022megapose}
Y.~Labb{\'e}, L.~Manuelli, A.~Mousavian, S.~Tyree, S.~Birchfield, J.~Tremblay, J.~Carpentier, M.~Aubry, D.~Fox, and J.~Sivic, ``Megapose: 6d pose estimation of novel objects via render \& compare,'' in \emph{6th Annual Conference on Robot Learning}, 2022.

\bibitem{crivellaro2015novel}
A.~Crivellaro, M.~Rad, Y.~Verdie, K.~Moo~Yi, P.~Fua, and V.~Lepetit, ``A novel representation of parts for accurate 3d object detection and tracking in monocular images,'' in \emph{Proceedings of the IEEE international conference on computer vision}, 2015, pp. 4391--4399.

\bibitem{rad2017bb8}
M.~Rad and V.~Lepetit, ``Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth,'' in \emph{Proceedings of the IEEE international conference on computer vision}, 2017, pp. 3828--3836.

\bibitem{lepetit2009epnp}
V.~Lepetit, F.~Moreno-Noguer, and P.~Fua, ``Epnp: An accurate o (n) solution to the pnp problem,'' \emph{International journal of computer vision}, vol.~81, no.~2, pp. 155--166, 2009.

\bibitem{hu2020single}
Y.~Hu, P.~Fua, W.~Wang, and M.~Salzmann, ``Single-stage 6d object pose estimation,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2020, pp. 2930--2939.

\bibitem{thalhammer2023self}
S.~Thalhammer, J.-B. Weibel, M.~Vincze, and J.~Garcia-Rodriguez, ``Self-supervised vision transformers for 3d pose estimation of novel objects,'' \emph{Image and Vision Computing}, vol. 139, p. 104816, 2023.

\bibitem{florence2018dense}
P.~R. Florence, L.~Manuelli, and R.~Tedrake, ``Dense object nets: Learning dense visual object descriptors by and for robotic manipulation,'' in \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2018, pp. 373--385.

\bibitem{lin2017focal}
T.-Y. Lin, P.~Goyal, R.~Girshick, K.~He, and P.~Doll{\'a}r, ``Focal loss for dense object detection,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2017, pp. 2980--2988.

\bibitem{bochkovskiy2020yolov4}
A.~Bochkovskiy, C.-Y. Wang, and H.-Y.~M. Liao, ``Yolov4: Optimal speed and accuracy of object detection,'' \emph{arXiv preprint arXiv:2004.10934}, 2020.

\bibitem{ge2021yolox}
Z.~Ge, S.~Liu, F.~Wang, Z.~Li, and J.~Sun, ``Yolox: Exceeding yolo series in 2021,'' \emph{arXiv preprint arXiv:2107.08430}, 2021.

\bibitem{tian_fcos}
Z.~Tian, C.~Shen, H.~Chen, and T.~He, ``Fcos: Fully convolutional one-stage object detection,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2019, pp. 9627--9636.

\bibitem{he2017mask}
K.~He, G.~Gkioxari, P.~Doll{\'a}r, and R.~Girshick, ``Mask r-cnn,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2017, pp. 2961--2969.

\bibitem{zhou2021probabilistic}
X.~Zhou, V.~Koltun, and P.~Kr{\"a}henb{\"u}hl, ``Probabilistic two-stage detection,'' \emph{arXiv preprint arXiv:2103.07461}, 2021.

\bibitem{gard2022casapose}
\BIBentryALTinterwordspacing
N.~Gard, A.~Hilsmann, and P.~Eisert, ``Casapose: Class-adaptive and semantic-aware multi-object pose estimation,'' in \emph{33rd British Machine Vision Conference 2022, {BMVC} 2022, London, UK, November 21-24, 2022}.\hskip 1em plus 0.5em minus 0.4em\relax {BMVA} Press, 2022, p. 899. [Online]. Available: \url{https://bmvc2022.mpi-inf.mpg.de/899/}
\BIBentrySTDinterwordspacing

\bibitem{lopes2023cross}
I.~Lopes, T.-H. Vu, and R.~de~Charette, ``Cross-task attention mechanism for dense multi-task learning,'' in \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, 2023, pp. 2329--2338.

\bibitem{drost2010model}
B.~Drost, M.~Ulrich, N.~Navab, and S.~Ilic, ``Model globally, match locally: Efficient and robust 3d object recognition,'' in \emph{2010 IEEE computer society conference on computer vision and pattern recognition}.\hskip 1em plus 0.5em minus 0.4em\relax Ieee, 2010, pp. 998--1005.

\bibitem{vidal20186d}
J.~Vidal, C.-Y. Lin, and R.~Mart{\'\i}, ``6d pose estimation using an improved method based on point pair features,'' in \emph{2018 4th international conference on control, automation and robotics (iccar)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 405--409.

\bibitem{hodavn2015detection}
T.~Hoda{\v{n}}, X.~Zabulis, M.~Lourakis, {\v{S}}.~Obdr{\v{z}}{\'a}lek, and J.~Matas, ``Detection and fine 3d pose estimation of texture-less objects in rgb-d images,'' in \emph{2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2015, pp. 4421--4428.

\bibitem{aldoma2011cad}
A.~Aldoma, M.~Vincze, N.~Blodow, D.~Gossow, S.~Gedikli, R.~B. Rusu, and G.~Bradski, ``Cad-model recognition and 6dof pose estimation using 3d cues,'' in \emph{2011 IEEE international conference on computer vision workshops (ICCV workshops)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2011, pp. 585--592.

\bibitem{rusinkiewicz2001efficient}
S.~Rusinkiewicz and M.~Levoy, ``Efficient variants of the icp algorithm,'' in \emph{Proceedings third international conference on 3-D digital imaging and modeling}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2001, pp. 145--152.

\bibitem{kehl2017ssd}
W.~Kehl, F.~Manhardt, F.~Tombari, S.~Ilic, and N.~Navab, ``Ssd-6d: Making rgb-based 3d detection and 6d pose estimation great again,'' in \emph{Proceedings of the IEEE international conference on computer vision}, 2017, pp. 1521--1529.

\bibitem{labbe2020cosypose}
Y.~Labb{\'e}, J.~Carpentier, M.~Aubry, and J.~Sivic, ``Cosypose: Consistent multi-view multi-object 6d pose estimation,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp. 574--591.

\bibitem{li2018deepim}
Y.~Li, G.~Wang, X.~Ji, Y.~Xiang, and D.~Fox, ``Deepim: Deep iterative matching for 6d pose estimation,'' in \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, 2018, pp. 683--698.

\bibitem{hodan2020bop}
T.~Hoda{\v{n}}, M.~Sundermeyer, B.~Drost, Y.~Labb{\'e}, E.~Brachmann, F.~Michel, C.~Rother, and J.~Matas, ``Bop challenge 2020 on 6d object localization,'' \emph{Proceedings of the European Conference on Computer Vision Workshops}, 2020.

\bibitem{alexandrov2019leveraging}
S.~V. Alexandrov, T.~Patten, and M.~Vincze, ``Leveraging symmetries to improve object detection and pose estimation from range data,'' in \emph{Computer Vision Systems: 12th International Conference, ICVS 2019, Thessaloniki, Greece, September 23--25, 2019, Proceedings 12}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2019, pp. 397--407.

\bibitem{manhardt2019explaining}
F.~Manhardt, D.~M. Arroyo, C.~Rupprecht, B.~Busam, T.~Birdal, N.~Navab, and F.~Tombari, ``Explaining the ambiguity of object detection and 6d pose from visual data,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2019, pp. 6841--6850.

\bibitem{shi2021stablepose}
Y.~Shi, J.~Huang, X.~Xu, Y.~Zhang, and K.~Xu, ``Stablepose: Learning 6d object poses from geometrically stable patches,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021, pp. 15\,222--15\,231.

\bibitem{ju2024robo}
Y.~Ju, K.~Hu, G.~Zhang, G.~Zhang, M.~Jiang, and H.~Xu, ``Robo-abc: Affordance generalization beyond categories via semantic correspondence for robot manipulation,'' \emph{arXiv preprint arXiv:2401.07487}, 2024.

\bibitem{he2022fs6d}
Y.~He, Y.~Wang, H.~Fan, J.~Sun, and Q.~Chen, ``Fs6d: Few-shot 6d pose estimation of novel objects,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6814--6824.

\bibitem{chen2020category}
X.~Chen, Z.~Dong, J.~Song, A.~Geiger, and O.~Hilliges, ``Category level object pose estimation via neural analysis-by-synthesis,'' in \emph{Proceedings of the European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp. 139--156.

\bibitem{remus2023i2c-net}
A.~Remus, S.~D'Avella, F.~D. Felice, P.~Tripicchio, and C.~A. Avizzano, ``i2c-net: Using instance-level neural networks for monocular category-level 6d pose estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~8, no.~3, pp. 1515--1522, 2023.

\bibitem{deng2022icaps}
X.~Deng, J.~Geng, T.~Bretl, Y.~Xiang, and D.~Fox, ``icaps: Iterative category-level object pose and shape estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~7, no.~2, pp. 1784--1791, 2022.

\bibitem{di2024zero123}
F.~Di~Felice, A.~Remus, S.~Gasperini, B.~Busam, L.~Ott, F.~Tombari, R.~Siegwart, and C.~A. Avizzano, ``Zero123-6d: Zero-shot novel view synthesis for rgb category-level 6d pose estimation,'' \emph{arXiv preprint arXiv:2403.14279}, 2024.

\bibitem{fan2024acr}
Z.~Fan, Z.~Song, Z.~Wang, J.~Xu, K.~Wu, H.~Liu, and J.~He, ``Acr-pose: Adversarial canonical representation reconstruction network for category level 6d object pose estimation,'' in \emph{Proceedings of the 2024 International Conference on Multimedia Retrieval}, 2024, pp. 55--63.

\bibitem{you2022cppf}
Y.~You, R.~Shi, W.~Wang, and C.~Lu, ``Cppf: Towards robust category-level 9d pose estimation in the wild,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 6866--6875.

\bibitem{zheng2023hs}
L.~Zheng, C.~Wang, Y.~Sun, E.~Dasgupta, H.~Chen, A.~Leonardis, W.~Zhang, and H.~J. Chang, ``Hs-pose: Hybrid scope feature extraction for category-level object pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 17\,163--17\,173.

\bibitem{Sun_2022_onepose}
J.~Sun, Z.~Wang, S.~Zhang, X.~He, H.~Zhao, G.~Zhang, and X.~Zhou, ``Onepose: One-shot object pose estimation without cad models,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2022, pp. 6825--6834.

\bibitem{goodwin2022zero}
W.~Goodwin, S.~Vaze, I.~Havoutis, and I.~Posner, ``Zero-shot category-level object pose estimation,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 516--532.

\bibitem{okorn2021zephyr}
B.~Okorn, Q.~Gu, M.~Hebert, and D.~Held, ``Zephyr: Zero-shot pose hypothesis rating,'' in \emph{2021 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp. 14\,141--14\,148.

\bibitem{fan2023pope}
Z.~Fan, P.~Pan, P.~Wang, Y.~Jiang, D.~Xu, H.~Jiang, and Z.~Wang, ``Pope: 6-dof promptable pose estimation of any object, in any scene, with one reference,'' \emph{arXiv preprint arXiv:2305.15727}, 2023.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly \emph{et~al.}, ``An image is worth 16x16 words: Transformers for image recognition at scale,'' in \emph{International Conference on Learning Representations}, 2020.

\bibitem{zhang2022transnet}
H.~Zhang, A.~Opipari, X.~Chen, J.~Zhu, Z.~Yu, and O.~C. Jenkins, ``Transnet: Category-level transparent object pose estimation,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 148--164.

\bibitem{ichnowski2021dex}
J.~Ichnowski, Y.~Avigal, J.~Kerr, and K.~Goldberg, ``Dex-nerf: Using a neural radiance field to grasp transparent objects,'' 2021.

\bibitem{chen2022stereopose}
K.~Chen, S.~James, C.~Sui, Y.-H. Liu, P.~Abbeel, and Q.~Dou, ``Stereopose: Category-level 6d transparent object pose estimation from stereo images via back-view nocs,'' in \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 2855--2861.

\bibitem{byambaa20226d}
M.~Byambaa, G.~Koutaki, and L.~Choimaa, ``6d pose estimation of transparent object from single rgb image for robotic manipulation,'' \emph{IEEE Access}, vol.~10, pp. 114\,897--114\,906, 2022.

\bibitem{mildenhall2021nerf}
B.~Mildenhall, P.~P. Srinivasan, M.~Tancik, J.~T. Barron, R.~Ramamoorthi, and R.~Ng, ``Nerf: Representing scenes as neural radiance fields for view synthesis,'' \emph{Communications of the ACM}, vol.~65, no.~1, pp. 99--106, 2021.

\bibitem{li2022nerf}
F.~Li, H.~Yu, I.~Shugurov, B.~Busam, S.~Yang, and S.~Ilic, ``Nerf-pose: A first-reconstruct-then-regress approach for weakly-supervised 6d object pose estimation,'' \emph{arXiv preprint arXiv:2203.04802}, 2022.

\bibitem{ho2020denoising}
J.~Ho, A.~Jain, and P.~Abbeel, ``Denoising diffusion probabilistic models,'' \emph{Advances in Neural Information Processing Systems}, vol.~33, pp. 6840--6851, 2020.

\bibitem{kerbl20233d}
B.~Kerbl, G.~Kopanas, T.~Leimk{\"u}hler, and G.~Drettakis, ``3d gaussian splatting for real-time radiance field rendering,'' \emph{ACM Transactions on Graphics}, vol.~42, no.~4, pp. 1--14, 2023.

\bibitem{caron2021emerging}
M.~Caron, H.~Touvron, I.~Misra, H.~J{\'e}gou, J.~Mairal, P.~Bojanowski, and A.~Joulin, ``Emerging properties in self-supervised vision transformers,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2021, pp. 9650--9660.

\bibitem{shao2020pfrl}
J.~Shao, Y.~Jiang, G.~Wang, Z.~Li, and X.~Ji, ``Pfrl: Pose-free reinforcement learning for 6d pose estimation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020, pp. 11\,454--11\,463.

\bibitem{bauer2021reagent}
D.~Bauer, T.~Patten, and M.~Vincze, ``Reagent: Point cloud registration using imitation and reinforcement learning,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021, pp. 14\,586--14\,594.

\bibitem{wang2019densefusion}
C.~Wang, D.~Xu, Y.~Zhu, R.~Mart{\'\i}n-Mart{\'\i}n, C.~Lu, L.~Fei-Fei, and S.~Savarese, ``Densefusion: 6d object pose estimation by iterative dense fusion,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2019, pp. 3343--3352.

\bibitem{bauer2022sporeagent}
D.~Bauer, T.~Patten, and M.~Vincze, ``Sporeagent: Reinforced scene-level plausibility for object pose refinement,'' in \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, 2022, pp. 654--662.

\bibitem{kiatos2019singulation}
M.~Kiatos and S.~Malassiotis, ``Robust object grasping in clutter via singulation,'' in \emph{2019 International Conference on Robotics and Automation (ICRA)}, 2019, pp. 1596--1600.

\bibitem{sarantopoulos2020singulation}
I.~Sarantopoulos, M.~Kiatos, Z.~Doulgeri, and S.~Malassiotis, ``Split deep q-learning for robust object singulation,'' in \emph{2020 IEEE International Conference on Robotics and Automation (ICRA)}, 2020, pp. 6225--6231.

\bibitem{fischler1981random}
M.~A. Fischler and R.~C. Bolles, ``Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography,'' \emph{Communications of the ACM}, vol.~24, no.~6, pp. 381--395, 1981.

\bibitem{deng2021pose}
X.~Deng, A.~Mousavian, Y.~Xiang, F.~Xia, T.~Bretl, and D.~Fox, ``Poserbpf: A rao–blackwellized particle filter for 6-d object pose tracking,'' \emph{IEEE Transactions on Robotics}, vol.~37, no.~5, pp. 1328--1342, 2021.

\bibitem{huang2022confidence}
W.-L. Huang, C.-Y. Hung, and I.-C. Lin, ``Confidence-based 6d object pose estimation,'' \emph{IEEE Transactions on Multimedia}, vol.~24, pp. 3025--3035, 2022.

\bibitem{park2023satellite}
T.~H. Park, M.~M{\"a}rtens, M.~Jawaid, Z.~Wang, B.~Chen, T.-J. Chin, D.~Izzo, and S.~D’Amico, ``Satellite pose estimation competition 2021: Results and analyses,'' \emph{Acta Astronautica}, vol. 204, pp. 640--665, 2023.

\bibitem{kisantal2020satellite}
M.~Kisantal, S.~Sharma, T.~H. Park, D.~Izzo, M.~M{\"a}rtens, and S.~D’Amico, ``Satellite pose estimation challenge: Dataset, competition design, and results,'' \emph{IEEE Transactions on Aerospace and Electronic Systems}, vol.~56, no.~5, pp. 4083--4098, 2020.

\bibitem{wang2022spacenet}
S.~Wang, S.~Wang, B.~Jiao, D.~Yang, L.~Su, P.~Zhai, C.~Chen, and L.~Zhang, ``Ca-spacenet: Counterfactual analysis for 6d pose estimation in space,'' in \emph{2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 10\,627--10\,634.

\bibitem{bechini2024robust}
M.~Bechini, G.~Gu, P.~Lunghi, and M.~Lavagna, ``Robust spacecraft relative pose estimation via cnn-aided line segments detection in monocular images,'' \emph{Acta Astronautica}, vol. 215, pp. 20--43, 2024.

\bibitem{wang2023bridging}
Z.~Wang, M.~Chen, Y.~Guo, Z.~Li, and Q.~Yu, ``Bridging the domain gap in satellite pose estimation: A self-training approach based on geometrical constraints,'' \emph{IEEE Transactions on Aerospace and Electronic Systems}, 2023.

\bibitem{joshi2020deepurl}
B.~Joshi, M.~Modasshir, T.~Manderson, H.~Damron, M.~Xanthidis, A.~Q. Li, I.~Rekleitis, and G.~Dudek, ``Deepurl: Deep pose estimation framework for underwater relative localization,'' in \emph{2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp. 1777--1784.

\bibitem{nielsen2019evaluation}
M.~C. Nielsen, M.~H. Leonhardsen, and I.~Schj{\o}lberg, ``Evaluation of posenet for 6-dof underwater pose estimation,'' in \emph{OCEANS 2019 MTS/IEEE SEATTLE}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 1--6.

\bibitem{fan2023development}
J.~Fan, X.~Wang, C.~Zhou, Y.~Ou, F.~Jing, and Z.~Hou, ``Development, calibration, and image processing of underwater structured light vision system: A survey,'' \emph{IEEE Transactions on Instrumentation and Measurement}, vol.~72, pp. 1--18, 2023.

\bibitem{wu2023tidybot}
J.~Wu, R.~Antonova, A.~Kan, M.~Lepert, A.~Zeng, S.~Song, J.~Bohg, S.~Rusinkiewicz, and T.~Funkhouser, ``Tidybot: Personalized robot assistance with large language models,'' \emph{Autonomous Robots}, vol.~47, no.~8, pp. 1087--1102, 2023.

\bibitem{corsetti2023open}
J.~Corsetti, D.~Boscaini, C.~Oh, A.~Cavallaro, and F.~Poiesi, ``Open-vocabulary object 6d pose estimation,'' \emph{arXiv preprint arXiv:2312.00690}, 2023.

\bibitem{tenorth2009knowrob}
M.~Tenorth and M.~Beetz, ``Knowrob—knowledge processing for autonomous personal robots,'' in \emph{2009 IEEE/RSJ international conference on intelligent robots and systems}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2009, pp. 4261--4266.

\bibitem{EisnerZhang2022FLOW}
B.~Eisner*, H.~Zhang*, and D.~Held, ``Flowbot3d: Learning 3d articulation flow to manipulate articulated objects,'' in \emph{Robotics: Science and Systems (RSS)}, 2022.

\bibitem{liu2022toward}
L.~Liu, H.~Xue, W.~Xu, H.~Fu, and C.~Lu, ``Toward real-world category-level articulation pose estimation,'' \emph{IEEE Transactions on Image Processing}, vol.~31, pp. 1072--1083, 2022.

\bibitem{corl2020softgym}
X.~Lin, Y.~Wang, J.~Olkin, and D.~Held, ``Softgym: Benchmarking deep reinforcement learning for deformable object manipulation,'' in \emph{Conference on Robot Learning}, 2020.

\bibitem{chi2021garmentnets}
C.~Chi and S.~Song, ``Garmentnets: Category-level pose estimation for garments via canonical space shape completion,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 3324--3333.

\bibitem{chen2023autobag}
L.~Y. Chen, B.~Shi, D.~Seita, R.~Cheng, T.~Kollar, D.~Held, and K.~Goldberg, ``Autobag: Learning to open plastic bags and insert objects,'' in \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 3918--3925.

\bibitem{aldoma2012global}
A.~Aldoma, F.~Tombari, L.~Di~Stefano, and M.~Vincze, ``A global hypotheses verification method for 3d object recognition,'' in \emph{Computer Vision--ECCV 2012: 12th European Conference on Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part III 12}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2012, pp. 511--524.

\bibitem{bauer2020verefine}
D.~Bauer, T.~Patten, and M.~Vincze, ``Verefine: Integrating object pose verification with physics-guided iterative refinement,'' \emph{IEEE Robotics and Automation Letters}, vol.~5, no.~3, pp. 4289--4296, 2020.

\bibitem{rennie2016rutgers}
C.~Rennie, R.~Shome, K.~E. Bekris, and A.~F. De~Souza, ``A dataset for improved rgbd-based object detection and pose estimation for warehouse pick-and-place,'' \emph{IEEE Robotics and Automation Letters}, vol.~1, no.~2, pp. 1179--1185, 2016.

\bibitem{suchi20233d}
M.~Suchi, B.~Neuberger, A.~Salykov, J.-B. Weibel, T.~Patten, and M.~Vincze, ``3d-dat: 3d-dataset annotation toolkit for robotic vision,'' in \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 9162--9168.

\bibitem{batra2020rearrangement}
D.~Batra, A.~X. Chang, S.~Chernova, A.~J. Davison, J.~Deng, V.~Koltun, S.~Levine, J.~Malik, I.~Mordatch, R.~Mottaghi \emph{et~al.}, ``Rearrangement: A challenge for embodied ai,'' \emph{arXiv preprint arXiv:2011.01975}, 2020.

\bibitem{mahler2017dex}
J.~Mahler, J.~Liang, S.~Niyaz, M.~Laskey, R.~Doan, X.~Liu, J.~A. Ojea, and K.~Goldberg, ``Dex-net 2.0: Deep learning to plan robust grasps with synthetic point clouds and analytic grasp metrics,'' \emph{arXiv preprint arXiv:1703.09312}, 2017.

\bibitem{sundermeyer2021contact}
M.~Sundermeyer, A.~Mousavian, R.~Triebel, and D.~Fox, ``Contact-graspnet: Efficient 6-dof grasp generation in cluttered scenes,'' in \emph{2021 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp. 13\,438--13\,444.

\bibitem{team2023octo}
O.~M. Team, D.~Ghosh, H.~Walke, K.~Pertsch, K.~Black, O.~Mees, S.~Dasari, J.~Hejna, C.~Xu, J.~Luo \emph{et~al.}, ``Octo: An open-source generalist robot policy,'' 2023.

\bibitem{jiang2023mistral}
A.~Q. Jiang, A.~Sablayrolles, A.~Mensch, C.~Bamford, D.~S. Chaplot, D.~d.~l. Casas, F.~Bressand, G.~Lengyel, G.~Lample, L.~Saulnier \emph{et~al.}, ``Mistral 7b,'' \emph{arXiv preprint arXiv:2310.06825}, 2023.

\bibitem{oquab2023dinov2}
M.~Oquab, T.~Darcet, T.~Moutakanni, H.~Vo, M.~Szafraniec, V.~Khalidov, P.~Fernandez, D.~Haziza, F.~Massa, A.~El-Nouby \emph{et~al.}, ``Dinov2: Learning robust visual features without supervision,'' \emph{arXiv preprint arXiv:2304.07193}, 2023.

\bibitem{zhang2024tale}
J.~Zhang, C.~Herrmann, J.~Hur, L.~Polania~Cabrera, V.~Jampani, D.~Sun, and M.-H. Yang, ``A tale of two features: Stable diffusion complements dino for zero-shot semantic correspondence,'' \emph{Advances in Neural Information Processing Systems}, vol.~36, 2024.

\bibitem{kirillov2023segment}
A.~Kirillov, E.~Mintun, N.~Ravi, H.~Mao, C.~Rolland, L.~Gustafson, T.~Xiao, S.~Whitehead, A.~C. Berg, W.-Y. Lo \emph{et~al.}, ``Segment anything,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 4015--4026.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry, A.~Askell, P.~Mishkin, J.~Clark \emph{et~al.}, ``Learning transferable visual models from natural language supervision,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp. 8748--8763.

\bibitem{kerr2023lerf}
J.~Kerr, C.~M. Kim, K.~Goldberg, A.~Kanazawa, and M.~Tancik, ``Lerf: Language embedded radiance fields,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 19\,729--19\,739.

\end{thebibliography}
