\section{INTRODUCTION}
\label{sec:introduction}

%% Motivation
Transparent objects such as cups, glasses, and bottles are ubiquitous around us and if robots are expected to work in unstructured scenarios such as household environments, it is essential to recognize and safely manipulate transparent objects. Reconstruction of the object shape is critical for detecting and identifying its pose and safely manipulating it~\cite{Qiang-TRO-2020}. While this is straightforward for opaque objects with off-the-shelf vision sensors, such sensors produce unreliable and erroneous data with transparent objects due to their non-Lambertian surfaces. Sophisticated custom calibrated setups with specialized scanners or modifying the transparent surface of objects are often necessary for accurate reconstruction~\cite{ihrke2010transparent,li2020through}. This is impractical for on-the-fly reconstruction of arbitrary unknown objects. On the contrary, high fidelity tactile sensing can be used for shape reconstruction of transparent objects as well as pose estimation and safe-manipulation~\cite{murali2021active, murali2022intelligent, kaboli2019tactile, kaboli2018active, kaboli2017tactile, kaboli2018robust, liu2022neuro, kaboli2016tactile}.

% \setlength{\textfloatsep}{1pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Figure environment removed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Literature
Tactile perception is inherently action-conditioned as data depends on the type of contact action performed and local as only the local surface information around the contact area is extracted~\cite{kaboli2015humanoids}. Hence, for reconstructing the surfaces of an object, multiple contact actions need to be performed by the robot. This leads to sparse information and prohibitively long data collection times.
% The prior works in literature have worked towards addressing some of these challenges.
Early works have used offline methods to collect dense tactile data and used shape-fitting primitives such as superquadratics~\cite{bierbaum2007haptic}. 
% Reconstruction of 2-D shapes of convex objects with simple shapes using tactile sensing was performed by deriving a closed-form solution for the curvature at the contact point and rotational speeds in~\cite{moll2001reconstructing}.
Aggregating contact points into a point cloud is often used to represent the shape of the objects. Some works have used Bayesian filtering techniques for defining a probabilistic model of the objects using the tactile point clouds and used them for other tasks such as classification~\cite{meier2011probabilistic}.
% Teleoperation-based sliding of tactile sensor against an object surface and using contour fitting techniques to reconstruct the surface has been used in~\cite{jia2009surface}.
Gaussian process implicit surface (GPIS) has been widely used for tactile object reconstruction~\cite{dragiev2011gaussian, yi2016active, bjorkman2013enhancing, gandler2020object, martens2016geometric, suresh2021tactile, jamali2016active}. The implicit surface described by a Gaussian process describes the shape of an object through a function that decides for each point in space whether it is part of the object or not. It produces smooth surface manifolds with a reasonable number of tactile points as input and also provides probabilistic information to guide the tactile actions. However, for complex shapes it typically requires lots of points uniformly distributed on the object's surface for reconstruction~\cite{jamali2016active}. Some works have also used tactile sensing with visual perception in order to perform shape completion with prior information observed with visual cameras~\cite{gandler2020object, smith20203d}.  
While these works focus on opaque objects, limited works exist for the reconstruction of transparent objects. 
Recently, deep learning methods have been used for point cloud based shape completion given partial or noisy input point clouds~\cite{fei2022comprehensive, murali2022deep}. Seminal works on PointNet~\cite{qi2017pointnet} allowed using raw point clouds as inputs to deep networks for the task of classification and semantic segmentation. Prior works have worked towards point cloud completion using deep networks such as~\cite{yu2018pu, yuan2018pcn} but are mainly evaluated on datasets derived from CAD models and rarely evaluated on real-world platforms with noisy and sparse sensors~\cite{fei2022comprehensive}.     

Using the constructed object shape for pose estimation of a transparent object through tactile sensing brings further challenges due to the nature of the tactile data. Typical pose-estimation methods for visual perception perform poorly with tactile data as they are sparse and extracted sequentially through contact probing~\cite{Qiang-TRO-2020, piga2021maskukf, murali2021active, murali2022empirical, murali2022towards, murali2022deep}. 
% Towards these challenges, we previously proposed a novel translation-invariant Quaternion filter (TIQF) for accurate 6 Degree-of-Freedom (DoF) pose estimation with tactile data~\cite{murali2022active}. TIQF is able to perform dense-to-sparse point cloud registration and handles sequential and noisy tactile data using the Bayesian filtering approach. It requires the prior knowledge of the object's model for pose estimation.
%% Limitations
In summary, there are limitations in the state-of-the-art for the reconstruction and further applications such as pose estimation of transparent objects with tactile perception: (a) existing reconstruction strategies such as GPIS fail to capture fine shape details with sparse tactile input data, (b) directly deploying deep learning based strategies for shape completion with sparse input data is impractical as the collection of a large dataset of tactile data for training is prohibitively expensive, (c) existing tactile-based pose estimation techniques rely upon known object models or shape primitives but category-level tactile-based pose estimation wherein objects without \textit{a priori} known CAD models but belong to a known category is necessary. 

% Figure environment removed
%% Contributions
\textbf{Contributions:} 
\begin{enumerate}[(I)]
    \item We propose \textit{ACTOR}, a novel framework for deep active tactile-based category-level perception of unknown transparent objects for reconstruction and pose estimation. Our proposed network is trained on a category-level synthetic dataset and tested on sparse tactile point clouds from real unknown transparent objects.
    \item Our proposed network consists of a feature-extraction encoder with self-attention and an upsampling decoder for accurate reconstruction of sparse input point clouds. 
    \item We propose an autonomous and active tactile-based unknown object exploration strategy based on information gain.
    % from sampling possible tactile actions leading to improved data collection efficiency.
    \item We improve our previously presented novel Translation-Invariant Quaternion Filter (TIQF)~\cite{murali2022active} to category-level pose (6DoF) and scale (3DoF) estimation and relax the need of a prior known model of the object. 
\end{enumerate}
To validate our proposed framework, we perform extensive experiments on a real robotic setup and provide baseline comparisons with state-of-the-art methods for tactile-based object reconstruction and pose estimation.
% We also show the performance of our active tactile exploration strategy against the uniform and random baseline strategies. Furthermore, we demonstrate other downstream applications of our proposed framework such as tactile-based object recognition.



%(b) prior knowledge of the object or known shape primitives are required for geometry-based curvature-fitting techniques,