\subsection{Experimental MIL Architectures}
\label{sec:arch_detals}
%
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Component} & \textbf{Configuration} 
        \\ \hline
        Input channels & 100 
        \\ \hline
        Instance encoder & linear(100 $\xrightarrow{}$ 64), ReLU, linear(64 $\xrightarrow{}$ 2), ReLU 
        \\ \hline
        Latent dimension & 2 
        \\ \hline
        Pooling & regressor guided pooling
        \\ \hline
        Classifier head & linear (100 $\xrightarrow{}$ 2)
        \\ \hline
        Loss & BCEWithLogitsLoss and TopoRegLoss
        \\ \hline
        Optimizer & Adam (lr: 0.0005)
        \\ \hline
        $\lambda$ & 0.005 
        \\ \hline
    \end{tabular}
    \caption{Architecture of the MIL model for toy experiment.}
    \label{table:toy_mil_model}
\end{table}

The RGMIL~\citep{du2023rgmil} model uses regressor guided pooling technique.
In this model, the regressor (with parameters $W$ and $B$) calculates the binary probability value of instance latent representation $z_i$ as
\begin{equation}
    (p_{i}^{+}, p_{i}^{-}) := W^T z_i + B, 
\end{equation}
where $p_{i}^{+}$ and $p_{i}^{-}$ show the probability of instance $z_i$ to belong to the positive or negative class.
%
Then it gets the difference between these two achieved probabilities,  
\begin{equation}
    p_i = p_{i}^{+} - p_{i}^{-},
\end{equation}
normalizes the result
\begin{equation}
    \omega_i = \frac{p_i - \mathbb{E}[p_i]}{\sqrt{Var(p_i)}},
\end{equation}
and applies softmax on it
\begin{equation}
    \alpha_{i} = \frac{\exp(\omega_{i})}{\sum_{j=1}^{n}\exp(\omega_j)}.
\end{equation}
where, $\alpha_{i}$ specifies the pooling weight of $z_i$.
%
Then the latent of bag is
\begin{equation}
    \zeta_{b_{m}} = \sum_{i=1}^{n}\exp(\alpha_i z_i).
\end{equation}

Table \ref{table:toy_mil_model} specifies more details of the MIL architecture we developed to classify toy dataset.


\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Components} & \textbf{Elephant, Fox, Tiger} & \textbf{Musk1, Musk} 
        \\ \hline
        Input channels & 230 & 166 
        \\ \hline
        Instance encoder & \multicolumn{2}{c|}{linear(231, 512), ReLU, linear(512, 512), ReLU}
        \\ \hline
        Latent Dimension & \multicolumn{2}{c|}{512}
        \\ \hline
        Pooling & \multicolumn{2}{c|}{regressor guided pooling}
        \\ \hline
        Classifier head & \multicolumn{2}{c|}{linear (512 $\xrightarrow{}$ 2)}
        \\ \hline        
        Loss & \multicolumn{2}{c|}{BCEWithLogitsLoss and TopoRegLoss} 
        \\ \hline
        Optimizer & \multicolumn{2}{c|}{Adam (lr: 0.00005, Betas: [0.9, 0.999])}
        \\ \hline
        Max Epochs & \multicolumn{2}{c|}{40} 
        \\ \hline
        $\lambda$ & \multicolumn{2}{c|}{0.05}
        \\ \hline
    \end{tabular}
    \caption{Architecture of the MIL Model for Benchmarks}
    \label{table:bm_mil_model}
\end{table}

Table \ref{table:bm_mil_model} shows the settings of this architecture.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{Parameter} & \textbf{Max Pooling} & \textbf{Average Pooling} & \textbf{Attention Pooling} & \textbf{RGP Pooling} 
        \\ \hline
        Pooling & Max & Average & Attention & regressor guided 
        \\ \hline
        In Dimension & \multicolumn{4}{c|}{28 $\times$ 28}
        \\ \hline
        Input channel & \multicolumn{4}{c|}{1}
        \\ \hline
        Instance encoder & \multicolumn{4}{c|}{linear(1$\xrightarrow{}$20), ReLU, linear(20$\xrightarrow{}$50), ReLU,linear(50$\xrightarrow{}$500), ReLU }
        \\ \hline
        Latent dimension & \multicolumn{4}{c|}{500} 
        \\ \hline
        Attention latent dimension & \multicolumn{4}{c|}{128} 
        \\ \hline
        Linear Layer & \multicolumn{4}{c|}{500 $\times$ 2}
        \\ \hline
        Loss & \multicolumn{4}{c|}{BCEWithLogitsLoss and TopoRegLoss} 
        \\ \hline
        Optimizer & \multicolumn{2}{c|}{Adam (LR: 0.005)} & \multicolumn{2}{c|}{Adam (LR: 0.0005)}
        \\ \hline
        Batch Size & \multicolumn{4}{c|}{1} 
        \\ \hline
        Max Epochs & \multicolumn{4}{c|}{100} 
        \\ \hline
    \end{tabular}
    \caption{General architecture and configurations of TR-MIL Model for synthetic datasets over different pooling strategies. The value $\lambda$ is not reported here as it differs between datasets, training budgets, and bag sizes. Please find its relevant value in the source code.}
    \label{table:cv_mil_model}
\end{table}

For synthetic data we employed same architecture for both MIL-MNIST and MIL-FashionMNIST datasets.
%
We explored different aggregation functions containing max pooling
\begin{equation}
    \zeta_{b_{m}} = \max_{i \le n} z_i,
\end{equation}
average pooling
\begin{equation}
    \zeta_{b_{m}} = \frac{\sum_{i=1}^{n} z_i}{n},
\end{equation}
and attention pooling with parameters $W$ and $V$
\begin{equation}
    \zeta_{b_{m}} = \sum_{i=1}^{n} a_i z_i, 
\end{equation}
where 
\begin{equation}
    a_i = \frac{\exp(W^T \tanh(V z_{i}^{T}))}{\sum_{i=1}^{n} \exp(W^{T} \tanh(V z_{i}^{T}))}.
\end{equation}
Table \ref{table:cv_mil_model} shows the settings of this architecture.


\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{Parameter} & \textbf{Max Pooling} & \textbf{Average Pooling} & \textbf{Aux Attention} & \textbf{Anomaly Detection} 
        \\ \hline
        Image dimentions & \multicolumn{4}{c|}{64 $\times$ 64}
        \\ \hline
        Image channels & \multicolumn{4}{c|}{1}
        \\ \hline
        Features channels & \multicolumn{4}{c|}{256}
        \\ \hline
        Instance encoder & \multicolumn{4}{c|}{Conv2D(256$\xrightarrow{}$301), ReLU, Conv2D(301$\xrightarrow{}$500), ReLU, Conv2D(500$\xrightarrow{}$650), Tanh, Linear(650$\xrightarrow{}$500))}
        \\ \hline
        Latent Dimension & \multicolumn{4}{c|}{500}
        \\ \hline
        Instance classifier head & \multicolumn{2}{c|}{-} & \multicolumn{2}{c|}{Linear(500 $\xrightarrow{}$ 500), Linear(500 $\xrightarrow{}$ 5) }
        \\ \hline
        Pooling & Max & Average & Attention & Anomaly 
        \\ \hline
        Attention layer & \multicolumn{2}{c|}{-} & \multicolumn{2}{c|}{Linear(500$\xrightarrow{}$128), Tanh, Linear(128$\xrightarrow{}$1)} 
        \\ \hline
        Bag classifier head & \multicolumn{4}{c|}{Linear(500 $\xrightarrow{}$ 2)}
        \\ \hline
        Loss & \multicolumn{2}{c|}{bag CrossEntropyLoss and TopoRegLoss} & \multicolumn{2}{c|}{CrossEntropyLoss (bag and instance) and TopoRegLoss}
        \\ \hline
        Optimization & \multicolumn{4}{c|}{Adam (lr=0.0005}
        \\ \hline
        Learning Rate & \multicolumn{4}{c|}{0.0005} 
        \\ \hline
        Max Epochs & \multicolumn{4}{c|}{300}
        \\ \hline
        Early Stopping & \multicolumn{4}{c|}{patience: 50}
        \\ \hline
        Image input channels & \multicolumn{4}{c|}{1}
        \\ \hline
        $\lambda$ & \multicolumn{4}{c|}{0.005} 
        \\ \hline
    \end{tabular}
    \caption{Configuration of MIL model for anemia classification with different pooling strategies}
    \label{table:mil_rbc_model}
\end{table}

For anemia classification we followed the architecture of the state of the art in this application~\citep{kazeminia2022anomaly} (Table \ref{table:mil_rbc_model}).
%
This method introduced anomaly score to be considered in addition to attention values to estimate the importance of each instance.
%
To this end the distribution of negative instances is estimated from negative bags by fitting a gaussian mixture model on their latent representation.
%
The anomaly score of each instance latent $z_i$ is calculated as
\begin{equation}
    d_{i} =  \sqrt{(z_{i}-\mu)^{T} \Sigma^{-1} (z_{i} - \mu)},
\end{equation}
where $\mu$ and $\Sigma$ are mean and covariance of the fitted GMM on negative distribution.
%
Then the pooling weight of the instance is calculated as a linear combination of attention score $a_i$ and anomaly score $d_i$.
%
With this the bag latent is
\begin{equation}
    \zeta_{b_m} = \sum_{i=1}^{n} (W_{D_{i}}d_{i} + W_{A_{i}}a_{i})z_{n}.
\end{equation}

The other consideration of this approach is the formulation of $Loss_class$ with a dual classifier head~\citep{sadafi2020attention} that comprises a bag classifier head and an instance classifier head.
%
The bag classifier head is trained using a cross-entropy loss function $L_\mathrm{bag}$, calculated as the difference between the predicted bag label and the corresponding ground truth label for the bag. 
%
The instance classifier head is trained using a cross-entropy loss function $L_\mathrm{Instance}$ that utilizes the noisy labels of instances as the repeated labels of the bag for all instances. 
% 
The final MIL classification loss is calculated as
\begin{equation}
    L_{class} = (1-\gamma) L_\mathrm{bag} + \gamma L_{Instance},
\end{equation}
where $\gamma$ is a coefficient that decreases as with epoch number increasing.


\subsection{Lurning curves on Benchmarks}
%

The RGMIL model tends to overfit when performing on benchmark datasets, given their limited data size. 
%
Figure \ref{fig:Benchmarks_LC} displays the learning curves of training RGMIL alongside TR-RGMIL.
%
The introduction of topological regularization addresses overfitting in RGMIL and resultsin a significant improvement in its classification performance.

% Figure environment removed

\subsection{Detailed performance on synthetic dataset}
%
Table \ref{fig:Mnist_Fmnist_detailed} distinctly illustrates how topological regularization addresses this issue in MIL employing both average and attention aggregation functions. 
%
This effect is particularly pronounced with smaller bags, leading to improved robustness (lower variance across multiple runs) and higher accuracy on average.

Furthermore, the figure effectively highlights the advantages of the attention mechanism over average pooling in enhancing MIL performance, especially when trained with limited data. 
%
However, for a small amount of training bags, topological regularization improves performance by generating more accurate and robust results.

% Figure environment removed
