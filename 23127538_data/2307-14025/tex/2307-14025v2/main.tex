%%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

\usepackage[english]{babel}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% \usepackage[table,xcdraw]{xcolor}
\usepackage{colortbl}

\usepackage[symbol]{footmisc}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2024} with \usepackage[nohyperref]{icml2024} above.
\usepackage{hyperref}

\PassOptionsToPackage{sort}{natbib}

% Attempt to make hyperref and algorithmic work together better:
% \newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage[accepted]{icml2024}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2024}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage{babel}
\usepackage{microtype}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Topologically Regularized Multiple Instance Learning to Harness Data Scarcity}


%%%%%%%%%%%%%%%%%%%%%%%% My packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[T1]{fontenc}
\usepackage{listings}
\lstset{language=Pascal}

\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\usepackage{xcolor}
\usepackage[export]{adjustbox}
\usepackage{tabu}
\usepackage{subcaption}
% \usepackage[hidelinks]{hyperref}
\usepackage{stackengine}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage{paralist}
\usepackage{tabularx}



\begin{document}

\twocolumn[
\icmltitle{Topologically Regularized Multiple Instance Learning to Harness Data Scarcity}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2024
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{$\dagger$}

\begin{icmlauthorlist}
\icmlauthor{Salome Kazeminia}{AIH,TUM}
\icmlauthor{Carsten Marr}{AIH,equal}
\icmlauthor{Bastian Rieck}{AIH,TUM,equal}
\end{icmlauthorlist}

\icmlaffiliation{AIH}{Institute of AI for Health, Helmholtz Zentrum München, German Research Center for Environmental Health, Neuherberg, Germany}
\icmlaffiliation{TUM}{TUM School of Computation, Information and Technology, Technical University of Munich, Munich, German}

\icmlcorrespondingauthor{Bastian Rieck}{bastian.rieck@helmholtz-munich.de}
\icmlcorrespondingauthor{Carsten Marr}{carsten.marr@helmholtz-munich.de}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
In biomedical data analysis, Multiple Instance Learning (MIL) models have emerged as a powerful tool to classify patients' microscopy samples. 
%
However, the data-intensive requirement of these models poses a significant challenge in scenarios with scarce data availability, e.g., in rare diseases. 
%
We introduce a topological regularization term to MIL to mitigate this challenge.
%
It provides a shape-preserving inductive bias that compels the encoder to maintain the essential geometrical-topological structure of input bags during projection into latent space. 
%
This enhances the performance and generalization of the MIL classifier regardless of the aggregation function, particularly for scarce training data. 
%
The effectiveness of our method is confirmed through experiments across a range of datasets, showing an average enhancement of $2.8\%$ for MIL benchmarks, $15.3\%$ for synthetic MIL datasets, and $5.5\%$ for real-world biomedical datasets over the current state-of-the-art.
%
% We make our code publicly available at https://anonymous.4open.science/r/TR-MIL-4BB4/.
\end{abstract}


\input{sections/01_introduction}	
\input{sections/02_background}
\input{sections/03_related_work}
\input{sections/04_method}
\input{sections/05_experiment}
\input{sections/06_conclusion}

% \clearpage

\section{Impact Statement}
This paper presents work with the primary goal of advancing the field of Machine Learning in healthcare. 
We have carefully considered the ethical implications of our methodology and application and have not identified any negative social impact that must be specifically highlighted here.

\section*{Acknowledgments}

We gratefully acknowledge Anna Bogdanova, Asya Makhro, and Ario Sadafi for providing the biomedical dataset used in this research. Their efforts in collecting and sharing the data have been instrumental in advancing our understanding of this field.
% Helmholtz
The Helmholtz Association supports the present contribution under the joint research school “Munich School for Data Science - MUDS”.
% Carsten funding
C.M.\ has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (Grant Agreement No. 866411).
%
B.R.\ is supported by the Bavarian state government with
funds from the \emph{Hightech Agenda Bavaria}.



% \bibliography{ref}
\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrews et~al.(2002)Andrews, Tsochantaridis, and Hofmann]{andrews2002support}
Andrews, S., Tsochantaridis, I., and Hofmann, T.
\newblock Support vector machines for multiple-instance learning.
\newblock \emph{Advances in neural information processing systems}, 15, 2002.

\bibitem[Bubenik et~al.(2020)Bubenik, Hull, Patel, and Whittle]{Bubenik20a}
Bubenik, P., Hull, M., Patel, D., and Whittle, B.
\newblock Persistent homology detects curvature.
\newblock \emph{Inverse Problems}, 36\penalty0 (2):\penalty0 025008, 2020.

\bibitem[Chazal et~al.(2009)Chazal, Cohen-Steiner, Guibas, Mémoli, and Oudot]{Chazal09a}
Chazal, F., Cohen-Steiner, D., Guibas, L.~J., Mémoli, F., and Oudot, S.~Y.
\newblock Gromov--{H}ausdorff stable signatures for shapes using persistence.
\newblock \emph{Computer Graphics Forum}, 28\penalty0 (5):\penalty0 1393--1403, 2009.

\bibitem[Chen et~al.(2019)Chen, Ni, Bai, and Wang]{Chen19a}
Chen, C., Ni, X., Bai, Q., and Wang, Y.
\newblock A topological regularizer for classifiers via persistent homology.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pp.\  2573--2582, 2019.

\bibitem[Chen et~al.(2022)Chen, Chen, Li, Chen, Trister, Krishnan, and Mahmood]{chen2022scaling}
Chen, R.~J., Chen, C., Li, Y., Chen, T.~Y., Trister, A.~D., Krishnan, R.~G., and Mahmood, F.
\newblock Scaling vision transformers to gigapixel images via hierarchical self-supervised learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  16144--16155, 2022.

\bibitem[Cormen et~al.(2022)Cormen, Leiserson, Rivest, and Stein]{cormen2022introduction}
Cormen, T.~H., Leiserson, C.~E., Rivest, R.~L., and Stein, C.
\newblock \emph{Introduction to algorithms}.
\newblock MIT press, 2022.

\bibitem[Dietterich et~al.(1997)Dietterich, Lathrop, and Lozano-P{\'e}rez]{dietterich1997solving}
Dietterich, T.~G., Lathrop, R.~H., and Lozano-P{\'e}rez, T.
\newblock Solving the multiple instance problem with axis-parallel rectangles.
\newblock \emph{Artificial intelligence}, 89\penalty0 (1-2):\penalty0 31--71, 1997.

\bibitem[Du et~al.(2023)Du, Mao, Zhang, Gou, Jiao, and Xiong]{du2023rgmil}
Du, Z., Mao, S., Zhang, Y., Gou, S., Jiao, L., and Xiong, L.
\newblock Rgmil: Guide your multiple-instance learning model with regressor.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Edelsbrunner \& Harer(2009)Edelsbrunner and Harer]{edelsbrunner2009computational}
Edelsbrunner, H. and Harer, J.
\newblock Computational topology: An introduction.
\newblock \emph{American Mathematical Society}, 9\penalty0 (2):\penalty0 117--138, 2009.

\bibitem[Goyal \& Bengio(2022)Goyal and Bengio]{goyal2022inductive}
Goyal, A. and Bengio, Y.
\newblock Inductive biases for deep learning of higher-level cognition.
\newblock \emph{Proceedings of the Royal Society A}, 478\penalty0 (2266):\penalty0 20210068, 2022.

\bibitem[Hehr et~al.(2023)Hehr, Sadafi, Matek, Lienemann, Pohlkamp, Haferlach, Spiekermann, and Marr]{hehr2023explainable}
Hehr, M., Sadafi, A., Matek, C., Lienemann, P., Pohlkamp, C., Haferlach, T., Spiekermann, K., and Marr, C.
\newblock Explainable ai identifies diagnostic cells of genetic aml subtypes.
\newblock \emph{PLOS Digital Health}, 2\penalty0 (3):\penalty0 e0000187, 2023.

\bibitem[Hensel et~al.(2021)Hensel, Moor, and Rieck]{Hensel21}
Hensel, F., Moor, M., and Rieck, B.
\newblock A survey of topological machine learning methods.
\newblock \emph{Frontiers in Artificial Intelligence}, 4, 2021.

\bibitem[Horn et~al.(2022)Horn, {De Brouwer}, Moor, Moreau, Rieck, and Borgwardt]{Horn22a}
Horn, M., {De Brouwer}, E., Moor, M., Moreau, Y., Rieck, B., and Borgwardt, K.
\newblock Topological graph neural networks.
\newblock In \emph{International Conference on Learning Representations~(ICLR)}, 2022.
\newblock URL \url{https://openreview.net/forum?id=oxxUMeFwEHd}.

\bibitem[Huang et~al.(2022)Huang, Liu, Jin, and Mu]{huang2022bag}
Huang, S., Liu, Z., Jin, W., and Mu, Y.
\newblock Bag dissimilarity regularized multi-instance learning.
\newblock \emph{Pattern Recognition}, 126:\penalty0 108583, 2022.

\bibitem[Ilse et~al.(2018)Ilse, Tomczak, and Welling]{ilse2018attention}
Ilse, M., Tomczak, J., and Welling, M.
\newblock Attention-based deep multiple instance learning.
\newblock In \emph{International conference on machine learning}, pp.\  2127--2136. PMLR, 2018.

\bibitem[Kazeminia et~al.(2022)Kazeminia, Sadafi, Makhro, Bogdanova, Albarqouni, and Marr]{kazeminia2022anomaly}
Kazeminia, S., Sadafi, A., Makhro, A., Bogdanova, A., Albarqouni, S., and Marr, C.
\newblock Anomaly-aware multiple instance learning for rare anemia disorder classification.
\newblock In \emph{25th International Conference on Medical Image Computing and Computer Assisted Intervention~(MICCAI)}, pp.\  341--350. Springer, 2022.

\bibitem[Li et~al.(2021)Li, Li, and Eliceiri]{li2021dual}
Li, B., Li, Y., and Eliceiri, K.~W.
\newblock Dual-stream multiple instance learning network for whole slide image classification with self-supervised contrastive learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  14318--14328, 2021.

\bibitem[Lu et~al.(2020)Lu, Han, Liu, Niu, Zhang, Li, Zhou, and Zhang]{lu2020clinical}
Lu, C., Han, B., Liu, Y., Niu, G., Zhang, R., Li, E., Zhou, Y., and Zhang, S.
\newblock Clinical-grade computational pathology using weakly supervised deep learning on whole slide images.
\newblock \emph{Nature Medicine}, 26\penalty0 (9):\penalty0 1301--1309, 2020.

\bibitem[Moor et~al.(2020)Moor, Horn, Rieck, and Borgwardt]{moor2020topological}
Moor, M., Horn, M., Rieck, B., and Borgwardt, K.
\newblock Topological autoencoders.
\newblock In \emph{International Conference on Machine Learning}, pp.\  7045--7054, 2020.

\bibitem[Sadafi et~al.(2020)Sadafi, Makhro, Bogdanova, Navab, Peng, Albarqouni, and Marr]{sadafi2020attention}
Sadafi, A., Makhro, A., Bogdanova, A., Navab, N., Peng, T., Albarqouni, S., and Marr, C.
\newblock Attention based multiple instance learning for classification of blood cell disorders.
\newblock In \emph{23rd International Conference on Medical Image Computing and Computer Assisted Intervention~(MICCAI)}, pp.\  246--256. Springer, 2020.

\bibitem[Shao et~al.(2021)Shao, Bian, Chen, Wang, Zhang, Ji, et~al.]{shao2021transmil}
Shao, Z., Bian, H., Chen, Y., Wang, Y., Zhang, J., Ji, X., et~al.
\newblock Transmil: Transformer based correlated multiple instance learning for whole slide image classification.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 2136--2147, 2021.

\bibitem[Sheehy(2013)]{Sheehy13a}
Sheehy, D.~R.
\newblock Linear-size approximations to the vietoris--rips filtration.
\newblock \emph{Discrete {\&} Computational Geometry}, 49\penalty0 (4):\penalty0 778--796, 2013.
\newblock \doi{10.1007/s00454-013-9513-1}.

\bibitem[Sheehy(2014)]{sheehy2014persistent}
Sheehy, D.~R.
\newblock The persistent homology of distance functions under random projection.
\newblock In \emph{Proceedings of the thirtieth annual symposium on Computational geometry}, pp.\  328--334, 2014.

\bibitem[Turkes et~al.(2022)Turkes, Montufar, and Otter]{Turkes22a}
Turkes, R., Montufar, G., and Otter, N.
\newblock On the effectiveness of persistent homology.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Vandaele et~al.(2022)Vandaele, Kang, Lijffijt, Bie, and Saeys]{Vandaele22a}
Vandaele, R., Kang, B., Lijffijt, J., Bie, T.~D., and Saeys, Y.
\newblock Topologically regularized data embeddings.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[von Rohrscheidt \& Rieck(2023)von Rohrscheidt and Rieck]{vonRohrscheidt23a}
von Rohrscheidt, J. and Rieck, B.
\newblock Topological singularity detection at multiple scales.
\newblock In Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J. (eds.), \emph{Proceedings of the 40th International Conference on Machine Learning~(ICML)}, number 202 in Proceedings of Machine Learning Research, pp.\  35175--35197. PMLR, 2023.

\bibitem[Wagner et~al.(2021)Wagner, Solomon, and Bendich]{wagner2021improving}
Wagner, A., Solomon, E., and Bendich, P.
\newblock Improving metric dimensionality reduction with distributed topology, 2021.
\newblock arXiv:2106.07613.

\bibitem[Wagner et~al.(2023)Wagner, Reisenb{\"u}chler, West, Niehues, Zhu, Foersch, Veldhuizen, Quirke, Grabsch, van~den Brandt, et~al.]{wagner2023transformer}
Wagner, S.~J., Reisenb{\"u}chler, D., West, N.~P., Niehues, J.~M., Zhu, J., Foersch, S., Veldhuizen, G.~P., Quirke, P., Grabsch, H.~I., van~den Brandt, P.~A., et~al.
\newblock Transformer-based biomarker prediction from colorectal cancer histology: A large-scale multicentric study.
\newblock \emph{Cancer Cell}, 41\penalty0 (9):\penalty0 1650--1661, 2023.

\bibitem[Waibel et~al.(2022)Waibel, Atwell, Meier, Marr, and Rieck]{Waibel22a}
Waibel, D. J.~E., Atwell, S., Meier, M., Marr, C., and Rieck, B.
\newblock Capturing shape information with multi-scale topological loss terms for {3D} reconstruction.
\newblock In \emph{25th International Conference on Medical Image Computing and Computer Assisted Intervention~(MICCAI)}, pp.\  150--159, 2022.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Yan et~al.(2018)Yan, Wang, Guo, Fang, Liu, and Huang]{yan2018deep}
Yan, Y., Wang, X., Guo, X., Fang, J., Liu, W., and Huang, J.
\newblock Deep multi-instance learning with dynamic pooling.
\newblock In \emph{Asian Conference on Machine Learning}, pp.\  662--677. PMLR, 2018.

\bibitem[Zhang et~al.(2022)Zhang, Meng, Zhao, Qiao, Yang, Coupland, and Zheng]{zhang2022dtfd}
Zhang, H., Meng, Y., Zhao, Y., Qiao, Y., Yang, X., Coupland, S.~E., and Zheng, Y.
\newblock Dtfd-mil: Double-tier feature distillation multiple instance learning for histopathology whole slide image classification.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  18802--18812, 2022.

\bibitem[Zhao et~al.(2023)Zhao, Yuan, Hao, and Wen]{zhao2023generalized}
Zhao, L., Yuan, L., Hao, K., and Wen, X.
\newblock Generalized attention-based deep multi-instance learning.
\newblock \emph{Multimedia Systems}, 29\penalty0 (1):\penalty0 275--287, 2023.

\end{thebibliography}

\bibliographystyle{icml2024}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Appendix}
\input{sections/07_appendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
