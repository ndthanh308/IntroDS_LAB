\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
%\usepackage{natbib} 
\usepackage[backend=biber, natbib=true, style=authoryear-comp, %surname-year citation and reference list, with the name appearing once for citing multiple works of the same author
maxcitenames=2, %no more than two names for citations
uniquelist=false, %use a/b year appendices to keep max 2 names
giveninits=true, %use first name initials
maxbibnames=6,  %upto six authors appearing in reference
minbibnames=6, %for more than six authors, display the first six
sortcites=false, %citations sorted by year  
uniquename=false %no initials for citations
]{biblatex}
\DeclareNameAlias{author}{family-given} %all authors appear last name first
\DeclareDelimFormat[parencite]{nameyeardelim}{\addspace} %no punctutation between name and year for citations
\renewcommand*{\newunitpunct}{\addcomma\space} %commas after year, title
\uspunctuation %punctuation within quotes
\renewbibmacro{in:}{} %remove 'in:' before journal
\usepackage{url} %allow for urls in references, url breaking
\sloppy %force margin respect for references
\addbibresource{BEST.bib}



% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{-.3in}%
\addtolength{\topmargin}{-.8in}%



% extra packages and options  
\usepackage{float}
\usepackage{caption}
\usepackage{doi} 
\usepackage{amsfonts} 
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\usepackage{xcolor}
\allowdisplaybreaks
\usepackage{titlesec}
\titlelabel{\thetitle.\quad}
\usepackage{sidecap,changepage} %for Appendix

\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \title{\bf A Flexible Framework for Incorporating Patient Preferences Into Q-Learning}
  \author{Joshua P. Zitovsky\thanks{Correspondence to: Josh Zitovsky $<$joshz@live.unc.edu$>$}\\
    Department of Biostatistics \\ UNC Chapel Hill \\
    \and 
    Leslie Wilson\\
    Department of Clinical Pharmacy \\
    UCSF \\
    \and 
    \vspace{-1.2cm} \\
    Michael R. Kosorok \\
     Department of Biostatistics \\ UNC Chapel Hill}
     \date{}
  \maketitle

\vspace{-0.3cm}
\begin{abstract}
In real-world healthcare problems, there are often multiple competing outcomes of interest, such as treatment efficacy and side effect severity. However, statistical methods for estimating dynamic treatment regimes (DTRs) usually assume a single outcome of interest, and the few methods that deal with composite outcomes suffer from important limitations. This includes restrictions to a single time point and two outcomes, the inability to incorporate self-reported patient preferences and limited theoretical guarantees. To this end, we propose a new method to address these limitations, which we dub \textit{Latent Utility Q-Learning (LUQ-Learning)}. LUQ-Learning uses a latent model approach to naturally extend Q-learning to the composite outcome setting and adopt the ideal trade-off between outcomes to each patient. Unlike previous approaches, our framework allows for an arbitrary number of time points and outcomes, incorporates stated preferences and achieves strong asymptotic performance with realistic assumptions on the data. We conduct simulation experiments based on an ongoing trial for low back pain as well as a well-known completed trial for schizophrenia. In all experiments, our method achieves highly competitive empirical performance compared to several alternative baselines. 
\end{abstract}

\noindent%
{\it Keywords:}  Dynamic Treatment Regime, Precision Medicine, Latent Variable Model, Multiple Outcomes
\vfill


\spacingset{1.1} % DON'T change the spacing!
\section{Introduction}

Precision medicine \citep{Kosorok2019} is a subfield of statistics and reinforcement learning concerned with estimating \textit{dynamic treatment regimes (DTRs)} \citep{Tsiatis2019}, or a sequence of treatment rules at different time points that depend on a patient's evolving characteristics. Precision medicine allows researchers to leverage datasets collected from clinical trials, observational studies or electronic health records in order to provide data-driven support to clinicians and policy makers. It also has the potential to shape healthcare in settings where interaction with medical professionals is undesired or difficult, as could be the case, for example, with low-income patients \citep{Wahl2018}. 

In many healthcare settings, there are multiple outcomes of interest \citep{Chan2013}. For example, this work is motivated in part by the \textit{Biomarkers for Evaluating Spine Treatments (BEST)} study \citep{UNC2022}, an ongoing NIH-funded sequential multiple assignment randomized trial (SMART) \citep{Almirall2014} directed by researchers at UNC Chapel Hill as part of the Back Pain Consortium Research Program \citep{Mauck2023}. The goal of the BEST study is to estimate a DTR for patients suffering from chronic low back pain \citep{Andersson1999}. While a naive analysis would focus solely on reducing pain, maximizing pain relief may come at a cost of side effects on fatigue and cognition. A truly optimal DTR should account for both treatment efficacy and side effect severity.

Over the last decade, methods have been proposed to estimate DTRs under a variety of settings, including settings with a single decision point \citep{Zhang2012, Zhou2017}, multiple decision points \citep{Zhao2015bowl, Liu2018}, an infinite number of decision points \citep{Luckett2020, Levine2020} and imperfect outcome measurements \citep{Zhao2015, Wu2020}. Most of these works assume a single, known outcome to maximize. In settings with multiple outcomes of interest, a common approach is to use a fixed summary measure of the outcomes known as a \textit{utility function}, and apply standard approaches to maximize the resulting utilities \citep{Hayes2022}. However, specifying the ideal utility function in advance is not always feasible. 

Several approaches have been proposed to estimate the utility function from data. For example, \citet{Jiang2021} proposed a minimax approach whereby the utility was a convex combination of outcomes and the convex weights were scalars tuned so as to maximize the minimum estimated value among the multiple outcomes. However, such an approach does not account for the possibility that some outcomes are more important than others, nor does it account for individual-level variation in the utilities such as patient preferences. \citet{Luckett2021} proposed using inverse reinforcement learning \citep{Osa2018} to learn a patient-specific utility function from decisions of expert clinicians. However, in many healthcare datasets, the observed decisions are made randomly \citep{Kosorok2015}, by the patients themselves, or by clinicians who act suboptimally \citep{Dehon2017}. Moreover, their methodology does not directly account for patient preferences.

\citet{Butler2018} allows the utility of patients to be random and uses a latent variable model to estimate it. Their framework does not assume access to expert-level data and directly incorporates stated preference surveys. However, the framework is restricted to two outcomes and a single decision point, and does not incorporate post-study satisfaction surveys. Moreover, consistency of their latent variable model was left as an assumption and its asymptotic distribution was not derived. In her dissertation, \citet{Butler2016} extended the work of \citet{Butler2018} to datasets with multiple decision points and measures of patient satisfaction. However, the extension assumes two proximal outcomes are measured after every time point, and chooses actions that maximize only the immediate next proximal outcome without accounting for outcomes occurring later in time. It also assumes a binary measure of satisfaction and a two-dimensional outcome vector at each time point, and has no theoretical guarantees.

Discrete choice experiments \citep{Johnson2013} and conjoint analysis \citep{Bridges2011} aim to extract underlying treatment preferences from stated-preference surveys, and many discrete choice models can be interpreted as estimating latent utilities which drive the choices made by respondents \citep{McFadden1974}. This is slightly different from our goal however, which is is to estimate latent utilities that measure underlying contentedness with experienced outcomes and occur \textit{after} treatment is given. Moreover, while discrete choice experiments usually focus on determining the importance of different factors in predicting the utility \citep{Hauber2016}, our primary interest is to accurately predict the utility directly so as to estimate an optimal DTR. Our goal is also closely related to that of preference-based deep reinforcement learning \citep{Christiano2017, Ibarz2018}, though such works usually assume an interactive process that is incompatible with learning from static datasets.

To this end, we propose a novel framework, \textit{Latent Utility Q-Learning (LUQ-Learning)}, that incorporates multiple outcomes into the Q-learning algorithm \citep{Schulte2014} via a latent model approach. Unlike previous approaches, our framework allows for an arbitrary finite number of decision points, outcomes of interest and treatment possibilities. Our framework also incorporates both discrete choice stated preference questionnaires and patient satisfaction questionnaires. We then derive theoretical properties of LUQ-Learning while making only modest assumptions, giving our framework strong theoretical guarantees. Finally, we apply LUQ-Learning to simulated patients from chronic low back pain and schizophrenia studies, and achieve excellent empirical performance. 

\section{Background}

\subsection{Traditional Data Setup}

In the traditional precision medicine setup \citep{Kosorok2019} with two decision points, the observed data consists of $N$ iid trajectories $\mathcal D=\{(\mathbf{X}_1^i,A_1^i,\mathbf{X}_2^i,A_2^i,Y^i)\}_{i=1}^N$ where $\mathbf{X}_1^i\in\mathcal X_1$ are the covariates measured prior to the first treatment, $A_1^i\in\mathcal A_1$ is the first treatment assigned, $\mathbf{X}_2^i\in\mathcal X_2$ are the covariates measured between the first and second treatments, $A_2^i\in\mathcal A_2$ is the second treatment assigned, and $Y\in\mathcal Y\subset\mathbb{R}$ is the observed \textit{utility} or \textit{reward} scaled so that higher values are better. We also define the observation history prior to the first and second treatments as $\mathbf{H}_1=\mathbf{X}_1\in\mathcal H_1$ and $\mathbf{H}_2=(\mathbf{X}_1,A_1,\mathbf{X}_2)\in\mathcal H_2$, respectively. The set of possible actions may depend on observation history, and we will often denote the action spaces as $\mathcal A_{\mathbf H_1}$ and $\mathcal A_{\mathbf H_2}$ to reflect this fact. The goal is to estimate a DTR, or sequence of decision rules $\pi=(\pi_1,\pi_2)$ where $\pi_1:\mathcal H_1\to\mathcal A_1$ and $\pi_2:\mathcal H_2\to \mathcal A_2$.  $V(\pi)=\mathbb E_\pi[Y]$ is known as the \textit{value} of DTR $\pi$, where $\mathbb E_\pi[Y]$ is the expected utility that would be observed if the patient population were treated according to $\pi$, and the optimal DTR $\pi^*=(\pi^*_1,\pi^*_2)$ satisfies $V(\pi^*)\geq V(\pi)$ for all other DTRs $\pi$.  While many previous works assume two outcomes $Y_1$ and $Y_2$ measured after each decision point and define the value as $V(\pi)=\mathbb E_\pi[Y_1+Y_2]$, this is just a special case of our setup with $Y=Y_1+Y_2$. 

Define the \textit{Q-functions} as $Q_2(\mathbf{h}_2,a_2)=\mathbb E[Y|\mathbf{H}_2=\mathbf{h}_2,A_2=a_2]$ and $Q_1(\mathbf{h}_1,a_1)=\mathbb E[\max_{a_2}Q_2(\mathbf{H}_2,a_2)|\mathbf{H}_1=\mathbf{h}_1,A_1=a_1]$. Under standard casual inference assumptions to be discussed shortly, it is easy to show that $\pi^*_2(\mathbf{h}_2)=\max_{a_2}Q_2(\mathbf{h}_2,a_2)$  and $\pi^*_1(\mathbf{h}_1)=\max_{a_1}Q_1(\mathbf{h}_1,a_1)$ \citep{Bertsekas2012}. To this end, the \textit{Q-learning} algorithm \citep{Schulte2014} approximates $Q_2$ as $\hat Q_2$ by using a regression algorithm with covariates $(\mathbf{H}_2,A_2)$ and responses $Y$. $Q_1$ is then estimated as $\hat Q_1$ by using a regression algorithm with covariates $(\mathbf{H}_1,A_1)$ and responses $\max_{a_2}\hat Q_2(\mathbf{H}_2,a_2)$. Finally, $\pi^*$ is estimated as $\hat\pi=(\hat\pi_1,\hat\pi_2)$ where $\hat\pi_1(\mathbf{h}_1)=\max_{a_1}\hat Q_1(\mathbf{h}_1,a_1)$ and $\hat\pi_2(\mathbf{h}_2)=\max_{a_2}\hat Q_2(\mathbf{h}_2,a_2)$.  While several alternatives to Q-learning have been proposed \citep{Liu2018, Shi2018}, our focus will be on Q-learning. Moreover, while we have assumed two decision points, the setup easily extends to more than two time points as well \citep{Schulte2014}.

\subsection{Our Data Setup}

We assume access to a dataset from a SMART with two time points and a discrete action space for simplicity. It is fairly straightforward to extend our methodological framework and theoretical results to observational data with more than two time points, though extensions to continuous action spaces would be less trivial  \citep{Antos2007}. 

In contrast to the traditional setup, we assume access to patient preference and satisfaction questionnaire responses and a vector of outcomes. Specifically, let $\mathbf{X}_1 \in\mathcal X_1$ be covariate information (excluding questionnaire data) and $\mathbf{W}_1\in\mathcal W_1$ be stated preference questionnaire responses collected prior to the first treatment; $A_1\in\mathcal A_{\mathbf{H}_1}$ be the first treatment assigned; $B_1\in\mathcal B_1\subset\mathbb{R}$ be a self-reported satisfaction measure about $A_1$ assessed prior to the second treatment, with higher values indicating greater satisfaction; $\mathbf{X}_2\in\mathcal X_2$ be covariate information and $\mathbf{W}_2\in\mathcal W_2$ be stated preferences collected between the first and second treatments; $A_2\in\mathcal A_{\mathbf{H}_2}$ be the second treatment assigned; $\mathbf{Y}\in\mathcal Y\subset \mathbb{R}^q$ be a vector of outcomes measured after $A_2$, each of which is better when higher; and $B_2\in\mathcal B_2\subset\mathbb{R}$ be a self-reported satisfaction measure recorded at the end of the study. We assume our observed data consists of $N$ iid trajectories $\mathcal D=\{(\mathbf{X}_1^i,\mathbf{W}_1^i,A_1^i,B_1^i,\mathbf{X}_2^i,\mathbf{W}_2^i,A_2^i,\mathbf{Y}^i,B_2^i)\}_{i=1}^N$. Moreover, we define our observation histories as $\mathbf{H}_1=(\mathbf{X}_1,\mathbf{W}_1)\in\mathcal H_1$, $\mathbf{H}_2=(\mathbf{H}_1,A_1,B_1,\mathbf{X}_2,\mathbf{W}_2)\in\mathcal H_2$ and $\mathbf{H}_3=(\mathbf{H}_2,A_2,\mathbf{Y},B_2)\in\mathcal H_3$. In Figure \ref{fig:setup} we summarize the temporal sequence in which relevant variables are observed. 

% Figure environment removed

Let $\mathbf A=(A_1,A_2)$, $\pi(\mathbf H_1,\mathbf H_2)=(\pi_1(\mathbf H_1),\pi_2(\mathbf H_2))$ and $\mathbf{Y}^*(\mathbf a)$ represent the outcome vector that would be observed for a patient if they received treatment sequence $\mathbf A=\mathbf a$. Note that $\mathbf{Y}=\mathbf{Y}^*(\mathbf A)$ and 
$V(\pi)=\mathbb E\left[\sum_{\mathbf a\in \mathcal A_{\mathbf{H}_1}\times\mathcal A_{\mathbf{H}_2}}I(\mathbf a=\pi(\mathbf H_1,\mathbf H_2))\mathbf{Y}^*(\mathbf a)\right]$. We assume that $\mathbf{Y}^*(\mathbf a)\perp \!\!\! \perp A_1 | \mathbf{H}_1$ and $\mathbf{Y}^*(\mathbf a)\perp \!\!\! \perp A_2 | \mathbf{H}_2$ for all $\mathbf a$. This is satisfied when there are no unmeasured variables that effect both $\mathbf A$ and $\mathbf{Y}$. A major purpose of SMARTs is to avoid unmeasured confounders by randomizing treatments.

\subsection{The BEST Study}

As our framework is partly motivated by the BEST study, we briefly describe the expected data structure from BEST here.

The study will last for 26 weeks: after an initial screening visit, covariates will be assessed over a two-week run-in period, followed by two 12-week treatment periods, the start of which assigns treatments randomly to patients, followed by assessments at the end of the study. We expect complete data for at least 600 patients. $\mathbf{X}_1$ consists of baselines related to back pain history and severity, demographics, financial security and lab work results. $\mathbf{W}_1$ (as well as $\mathbf W_2$) consists of responses to 12 binary questions, each of which asks patients to choose one set of outcome measurements over another based on seven outcome variables, as well as a question asking patients to rank the outcomes by preference. The 12 binary questions were generated using a tool similar to CAPER Treatment \citep{Wilson2023}, but with different attributes so as to focus on outcome preferences instead of treatment preferences.
$\mathcal A_1=\{1,2,3,4\}$ consists of four possible categorical treatments corresponding to acceptance and commitment therapy, duloxetine \citep{Dhaliwal2022}, enhanced self-care, and evidence-based exercise and manual therapy, respectively. The details of these treatments are not relevant to our paper and are not discussed further. 

$\mathbf{X}_2$ consists of a number of variables as well, including responses to the questionnaires Patient's Global Impression of Change (PGIC) \citep{Hurst2004} and Pain, Enjoyment and General Activity (PEG) \citep{Krebs2009}. Based on these responses, patients will be grouped into response class $C\in\mathcal C=\{1,2,3,4\}$. Patients will remain on current treatment for $C=1$, augment current treatment with an additional random treatment if $C=2$, randomly augment or switch treatment if $C=3$ and switch to a different random treatment if $C=4$. The exception is when $A_1=1,C\in\{3,4\}$, in which case a patient will always augment current treatment instead of switching. We thus have $\mathcal A_2=\{x,x+y|x,y\in\{1,2,3,4\},x<y\}$ where $A_2=x+y$ means the patient is taking medications $x$ and $y$ simultaneously. 

For simplicity, we will assume $\mathbf{Y}$ consists of three of the seven outcomes assessed in the stated  preference surveys, namely fatigue, cognition and pain after 26 weeks. $B_1$ and $B_2$ are ordinal ($\mathcal B_1,\mathcal B_2=\{1,2,....,7\}$) and assess satisfaction with the set of these three outcomes jointly.  As each component of $\mathbf{Y}$ involves some summary of a small number of ordinal and binary questions, we will assume the components of $\mathbf{Y}$ take on a discrete number of ordinal values. As before, the goal is to estimate a DTR $\pi=(\pi_1,\pi_2)$ where $\pi_1:\mathcal H_1\to\mathcal A_1$ is applied to choose treatment $A_1$ after covariates $\mathbf X_1$ and stated preferences $\mathbf W_1$ are measured for the first time point, and $\pi_2:\mathcal H_2\to \mathcal A_2$ is applied to choose treatment $A_2$ after covariates $\mathbf X_2$, stated preferences $\mathbf W_2$ and stated satisfaction $B_1$ are measured for the second time point (see Figure \ref{fig:setup}). $\pi$ should be estimated to optimize all of the outcomes in $\mathbf Y$ simultaneously, with the relative importance of each outcome tailored to patients based on their preferences. 

\section{Methodology}
\label{sec:method}

\subsection{Latent Utility Q-Learning}
\label{sec:framework}

We assume there exists an unobserved vector $\mathbf{E}\in\mathcal E$ for each patient, where $\mathcal E$ is the $q-1$-dimensional probability simplex, such that a patient with $\mathbf{E}=\mathbf{e}$ will end up preferring $\mathbf{Y}=\mathbf{y}_1$ over $\mathbf{Y}=\mathbf{y}_2$ if $\mathbf{e}^T\mathbf{y}_1>\mathbf{e}^T\mathbf{y}_2$. Define the random, unobserved utility of a patient as $U=\mathbf{E}^T\mathbf{Y}\in\mathbb{R}$.  We assume that $\mathbb E[B_2|\mathbf{H}_2,A_2]$ has a monotonic relationship with $\mathbb E[U|\mathbf{H}_2,A_2]$. Define $\pi^{\text{opt}}=(\pi_1^{\text{opt}},\pi_2^{\text{opt}})$ as the optimal DTR if and only if $\mathbb E_{\pi^{\text{opt}}}[U]\geq \mathbb E_{\pi}[U]$ for all other DTRs $\pi$. Then by using the same theory as that behind Q-learning, it is easy to see that $\pi_2^{\text{opt}}(\mathbf{h}_2)=\text{argmax}_{a_2\in\mathcal A_{\mathbf{h}_2}}Q_2(\mathbf{h}_2,a_2)$ and $\pi_1^{\text{opt}}(\mathbf{h}_1)=\text{argmax}_{a_1\in\mathcal A_{\mathbf{h}_1}}Q_1(\mathbf{h}_1,a_1)$ where $Q_2(\mathbf{H}_2,A_2)=\mathbb E[U|\mathbf{H}_2,A_2]$ and $Q_1(\mathbf{H}_1,A_1)=\mathbb E\left[\max_{a_2\in\mathcal A_{\mathbf H_2}}Q_2(\mathbf{H}_2,a_2)|\mathbf{H}_1,A_1\right]$. We also assume that $(\mathbf{Y},A_2)\perp \!\!\! \perp \mathbf{E}|\mathbf{H}_2$, following \citet{Butler2018}. Under this assumption, $\mathbb E[\mathbf{E}^T\mathbf{Y}|\mathbf{H}_2,A_2]=\mathbb E[\mathbf{E}|\mathbf{H}_2]^T\mathbb E[\mathbf{Y}|\mathbf{H}_2,A_2]$. 

To estimate $\pi^{\text{opt}}$, LUQ-Learning first estimates $\mathbb E[\mathbf{Y}|\mathbf{H}_2,A_2]$ as $\widehat{\mathbb E}[\mathbf{Y}|\mathbf{H}_2,A_2]$ using a regression algorithm and estimates $\mathbb E[\mathbf{E}|\mathbf{H}_2]$ as $\widehat{\mathbb E}[\mathbf{E}|\mathbf{H}_2]$ using a methodology to be discussed shortly. We can then estimate $Q_2$ as $\widehat{Q}_2(\mathbf{H}_2,A_2)=\widehat{\mathbb E}[\mathbf{E}|\mathbf{H}_2]^T\widehat{\mathbb E}[\mathbf{Y}|\mathbf{H}_2,A_2]$ and $\pi^{\text{opt}}$ using a typical Q-learning approach. The most complicated component is estimating $\mathbb E[\mathbf{E}|\mathbf{H}_2]$. One way to estimate this quantity is by proposing a parametric model directly for $\Pr(\mathbf{H}_2|\mathbf{E})$, similar to \citet{Butler2018}. However, this approach fails to utilize $B_2$ in the estimation. LUQ-Learning instead proposes a model $\Pr_\theta(\mathbf{H}_3|\mathbf{E})$ for $\Pr(\mathbf{H}_3|\mathbf{E})$ where $\theta$ is a parameter vector with imposed prior $\Pr(\theta)$, and estimates $\theta$ by maximizing the observed log-posterior
\begin{equation*}
\log\Pr(\theta|\mathcal D)=\log\Pr(\theta)
+\log\sum_{i=1}^N\int_{\mathcal E}\Pr(\mathbf{H}_3^i|\mathbf{E})\Pr(\mathbf{E})d\mathbf{E}.
\end{equation*}
With the right parametrization, estimating $\Pr(\mathbf{H}_2|\mathbf{E})$ will be straightforward once $\theta$ is estimated, and $\mathbb E[\mathbf{E}|\mathbf{H}_2]$ can then be estimated using an off-the-shelf random sampling algorithm \citep{Givens2012}.

We briefly elaborate on the differences between $U$ and $B_2$. $U$ is a quantity measuring the true ``goodness" of an outcome vector according to a patient's preferences, whereas $B_2$ only gives self-reported satisfaction with those outcomes. While $U$ could be continuous, $B_2$ will oftentimes be a noisy and discretized approximation of $U$, and estimating a DTR solely based on $B_2$ may not lead to optimal decisions. For example, suppose $B_2$ was binary and related to a continuous-valued $U$ via the threshold function $B_2=I(U>0)$. In other words, patients report they are satisfied ($B_2=1$) if $U$ is sufficiently large and report they are unsatisfied ($B_2=0$) otherwise. In this case, a DTR optimized solely based on $B_2$ would increase the chances that $U>0$, but such a DTR may fail to yield large positive $U$ (as it only cares whether $U>0$ and not on how large $U$ is more generally). Moreover, even in cases where optimizing $\mathbb E_\pi[U]$ and $\mathbb E_\pi[B_2]$ yield the same DTR asymptotically, using only $B_2$ in finite sample settings could lead to a significant drop in statistical efficiency. Finally, LUQ-Learning allows for estimation of a posterior distribution of $U$, which is useful for predicting patient preferences more generally as well as studying the relationship between preferences and measured covariates \citep{Muhlbacher2016, Hollin2020}. 

\subsection{Our Generative Model for BEST}

We apply LUQ-Learning to a generative model motivated by the BEST study design. We describe a few relevant components below: 
\begin{align*}
& \mathbf{V}\sim \mathcal N_{2}(0,\mathbf{I}), \\
& \mathbf{E}=\text{SoftMax}(\mathbf{V})=\frac{(\text{exp}(\mathbf{V}),1)}{1+\text{sum}(\exp(\mathbf{V}))}, \\
&W_{1j}\overset{ind}\sim \text{Bernoulli}(p=\beta_{0,j,1}+\beta^T_{1,j,1}\mathbf{V}) \quad (1\leq j \leq 12), \\
&\Pr(\mathbf{W}_1^R=\mathbf{w})=\frac{\exp(-\lambda_1 T(\mathbf{w},\mathbf{E}^R))}{\sum_{\mathbf{v}\in\mathcal P}\exp(-\lambda_1 T(\mathbf{v},\mathbf{E}^R))}, \\
&W_{2j}\overset{ind}\sim\text{Bernoulli}(p=\sigma(\beta_{0,j,2}+\beta^T_{1,j,2}\mathbf{V}))\quad (1\leq j \leq 12), \\
&\Pr(\mathbf{W}_2^R=\mathbf{w})=\frac{\exp(-\lambda_2 T(\mathbf{w},\mathbf{E}^R))}{\sum_{\mathbf{v}\in\mathcal P}\exp(-\lambda_2 T(\mathbf{v},\mathbf{E}^R))}, \\
& \Pr(B_1\leq k)=\sigma(\alpha_{0,k,1}-\alpha_{1,1}\mathbf{E}^T\mathbf{X}_2) \quad (1\leq k \leq 6),\;\mbox{and} \\
&\Pr(B_2\leq k)=\sigma(\alpha_{0,k,2}-\alpha_{1,2}\mathbf{E}^T\mathbf{Y}) \quad (1\leq k \leq 6).
\end{align*}
For computational tractability, we assume that $\mathbf{E}=\text{SoftMax}(\mathbf{V})$ where $\mathbf{V}\in\mathbb{R}^2$ is a standard normally distributed latent vector, similar to assumptions made by \citet{Butler2018}. Also similar to \citet{Butler2018}, we assume the binary preference questions $\mathbf{W}_1,\mathbf{W}_2\in[0,1]^{12}$ are related to the latent factors $\mathbf{V}$ via independent logistic regression models\footnote{We break with previous notation in that we now use $\mathbf W_1,\mathbf W_2$ to denote only the binary questions of the stated preference survey, with $\mathbf W_1^R,\mathbf W_2^R$ denoting the other questions.}. $\mathbf{W}_1^R,\mathbf{W}_2^R\in\mathcal P$ are the stated outcome rankings at each time point where $\mathcal P$ is the set of permutations of $\{1,2,3\}$. Our assumed models for $\Pr(\mathbf{W}_1^R|\mathbf{E}^R)$ and $\Pr(\mathbf{W}_2^R|\mathbf{E}^R)$ are Mallow's $\phi$ models \citep{Tang2019} where $\mathbf{E}^R\in\mathcal P$ denotes the true ranks of the components of $\mathbf{E}$ and $T$ denotes  Kendall's tau metric. While the BEST study allows for tied ranks, our distribution assumes no tied ranks for simplicity (though it is not difficult to extend the distribution to allow for ties). $B_1$ and $B_2$ are assumed to be positively related to the preference-weighted outcomes $\mathbf{E}^T\mathbf{X}_2$ and $\mathbf{E}^T\mathbf{Y}$ via proportional-odds logistic regression models ($\mathbf{X}_2$ is assumed to measure the same variables in $\mathbf{Y}$ for simplicity). 

Full details of the generative model for $(A_1,A_2,\mathbf{X}_1,\mathbf{X}_2,\mathbf{Y})$ as well as relevant model parameters $\theta=(\beta,\alpha,\lambda)$ where $\beta=(\beta_{i,j,k})_{i,j,k=1}^{i=2,j=12,k=2}$, $\alpha=(\alpha_{1,t}, \alpha_{0,k,t})_{k,t=1}^{k=6,t=2}$ and $\lambda=(\lambda_1,\lambda_2)$ are specified in Appendix \ref{append:details}. The model makes several simplifying assumptions. For example, we assume $\mathbf{X}_1$ and $\mathbf{X}_2$ consists solely of the three outcomes of interest but measured prior to the first and second randomization, respectively, and each outcome can only take values in $\{0,1,...,10\}$. We also assume $(\mathbf{X}_1,A_1,\mathbf{X}_2 )\perp \!\!\! \perp\mathbf{V} | \mathbf H_2$ similar to \citet{Butler2018}. So long as this latter assumption is satisfied,  any other assumptions made about $(A_1,A_2,\mathbf{X}_1,\mathbf{X}_2,\mathbf{Y})$ will not affect estimation of $\mathbb E[\mathbf E|\mathbf H_2]$. 

\subsection{Fitting Our Model to Simulated BEST Patients}

For our experiments, we assume our specified parametric model $\Pr_\theta(\mathbf{H}_3|\mathbf{V})$ for $\Pr(\mathbf{H}_3|\mathbf{V})$ is correct but $\theta$ is unknown. In Appendix \ref{append:tune}, we discuss how we can relax this assumption and select among multiple proposed parametric models if needed. Under our assumptions: 
\begin{align*}
\Pr(\mathbf{H}_3|\mathbf{V})=&\Pr(\mathbf{W}_1|\mathbf{V})\Pr(\mathbf{W}_1^R|\mathbf{E}^R)\Pr(B_1|\mathbf{E}^T\mathbf{X}_2)\\
\times& \Pr(\mathbf{W}_2|\mathbf{V})\Pr(\mathbf{W}_2^R|\mathbf{E}^R)\Pr(B_2|\mathbf{E}^T\mathbf{Y})g(\mathbf{H}_3),
\end{align*}
where $g(\mathbf{H}_3)$ is some function of $\mathbf{H}_3$. We also assume an improper uniform prior for $\theta$ over $\beta_{0,k,1},\beta_{0,k,2}\in\mathbb{R}$, $\alpha_{1,t},\lambda_t>0$ and $\alpha_{0,k,t}-\alpha_{0,k-1,t}>0$. Such a prior will make the posterior proportional to the log-likelihood and its mode equal to the MLE. Denote the space over which the prior for $\theta$ has positive support as $\Theta$, $B(x|p)$ as the Bernoulli density function with probability parameter $p$ and $C_d(x|p)$ as the $d$-dimensional categorical density function with probability vector $p$. Let $\mathbf{X}_3=\mathbf{Y}$, $\mathbf{V}^{(1)}_\text{MC},...,\mathbf{V}^{(N_{\text{sim}})}_\text{MC}\overset{iid}\sim\mathcal N_2(0,\mathbf{I})$ and $\Pr(B_t|\mathbf{X}_{t+1}^T\mathbf{E},\alpha)$ be a length-$6$ probability vector calculated from the cumulative distribution function $F(k|\mathbf{X}_{t+1}^T\mathbf{E}, \alpha)=\sigma(\alpha_{0,k,t}-\alpha_{1,t}\mathbf{X}_{t+1}^T\mathbf{E})$, $k\in\{1,2,...,6\}$. Under our assumptions:
\begin{align*}
\Pr(\theta|\mathcal D)\propto &\sum\limits_{i=1}^N\log \int_{\mathbb{R}^2}f_\theta(H_3^i|V)\Pr(\mathbf{V})d\mathbf{V}\approx \sum_{i=1}^N\log \sum\limits_{j=1}^{N_{\text{sim}}}f_\theta(H_3^i|V_{MC}^{(j)}
),\\
\end{align*}
where:
\begin{align*}
f_\theta(H_3^i|V)=&\prod\limits_{t=1}^2\left[\Pr\nolimits_\theta(\mathbf{W}_t^i|\mathbf{V})\Pr\nolimits_\theta(\mathbf{W}_t^{R,i}|\mathbf{E}^R)\Pr\nolimits_\theta(B_t^i|\mathbf{E}^T\mathbf{X}_t^i)\right] \\
\Pr\nolimits_\theta(\mathbf{W}_t^i|\mathbf{V})=&\prod_{k=1}^{12}\left\{B(W_{t,k}^i|\sigma(\beta_{0,k,t}+\beta_{1,k,t}^T\mathbf{V}))\right\}, \\
\Pr\nolimits_\theta(B_t^i|\mathbf{E}^T\mathbf{X}_t^i)=&C_7(B_{t}^i|p_t(\mathbf{E}^T\mathbf{X}_{t+1}^i|\alpha)),\;\mbox{and} \\
\Pr\nolimits_\theta(\mathbf{W}_t^{R,i}|\mathbf{E}^R)=&\frac{\exp(-\lambda_t T(\mathbf{W}_t^{R,i},\mathbf{E}^R))}{\sum_{\mathbf{v}\in\mathcal P}\exp(-\lambda_t T(\mathbf{v},\mathbf{E}^R))}.
\end{align*}
We approximate $\log\Pr(\theta|\mathcal D)$ using MC integration with $N_{\text{sim}}=1000$, which reduces approximation of $\log \Pr(\theta|\mathcal D)$ to $N\times N_{\text{sim}}\times\dim(\mathcal H_3)$ independent computations. We run these computations on a GPU using TensorFlow \citep{tf2015}. We also use reverse-mode automatic differentiation \citep{Geron2019} implemented in TensorFlow to compute $\nabla_\theta\log\Pr(\theta|\mathcal D)$, and conducted optimization using the L-BFGS algorithm \citep{Liu1989}. To deal with the non-convexity of our objective, we run L-BFGS from five random starting points and chose the solution with the largest observed log-likelihood. We also perform 500 simple gradient descent steps with a small learning rate prior to applying L-BFGS to improve stability. Finally, to constrain the optimization appropriately, we added the penalty $-\sum_i(1/100)e^{-100c_i}$ to the objective where $c$ is the vector of linear combinations of $\theta$ assumed to be positive in $\Theta$. Such an objective can be considered a continuous analogue of the hard constraint $-\infty I(\min(c)<0)$ or $-\infty I(\theta\notin\Theta)$. 

\subsection{Other Implementation Details}

From our fitted parameter vector $\hat\theta$, we estimate $\mathbb E\left[\mathbf{E}|\mathbf{H}_2\right]$ using MC integration as:
$$
\mathbb E_{\widehat\theta}[\mathbf{E}|\mathbf{H}_2]=\frac{\sum_{B_2\in\mathcal B_2}\sum_{j=1}^{N_{\text{sim}}}E_{\text{MC}}^{(j)}f_{\widehat\theta}(H_2,B_2|V_{\text{MC}}^{(j)})}{\sum_{B_2\in\mathcal B_2}\sum_{j=1}^{N_{\text{sim}}}f_{\widehat\theta}(H_2,B_2|V_{\text{MC}}^{(j)})}.
$$
As $\mathbf{Y}\in\{0,1,...,10\}^3$, we estimate $\mathbb E\left[\mathbf{Y}_j|\mathbf{H}_2,A_2\right], j\in\{1,2,3\}$ as $\widehat{\mathbb E}\left[\mathbf{Y}_j|\mathbf{H}_2,A_2\right]$ using beta-binomial logistic regression models with the design matrix including two-way interactions between $\mathbf{X}_{2}$ and $A_2$. We then estimate $Q_2$ as $\widehat Q_2=\mathbb E_{\widehat\theta}[\mathbf{E}|\mathbf{H}_2]^T\widehat{\mathbb E}[\mathbf{Y}|\mathbf{H}_2,A_2]$. $Q_1$ is then estimated as $\widehat Q_1$ using bagged trees with covariates $\{(\mathbf{H}_1^i,A_1^i)\}_{1\leq i \leq N}$, fitted responses $\{\max_{a_2\in\mathcal A_{\mathbf{H}_2^i}}\widehat Q_2(\mathbf{H}_2^i,a_2)\}_{1\leq i \leq N}$ and minimum node size $n_{\text{min}}=25$. Finally, $\pi^{\text{opt}}$ is estimated as $\widehat\pi=(\widehat\pi_1,\widehat\pi_2)$ where $\widehat\pi_2(\mathbf{h}_2)=\text{argmax}_{a_2\in\mathcal A_{\mathbf{h}_2}}\widehat Q_2(\mathbf{h}_2,a_2)$ and $\widehat\pi_1(\mathbf{h}_1)=\text{argmax}_{a_1\in\mathcal A_{\mathbf{h}_1}}\widehat Q_1(\mathbf{h}_1,a_1)$. 

\section{Theoretical Results}

The proofs for all of our theoretical results can be found in Appendix \ref{append:proofs}. Let $M_\theta(\mathbf{H}_3|\mathbf{E})$ be a parametric model for density $\Pr(\mathbf{H}_3|\mathbf{E})$ and $\Pr(\mathbf E)$ be known. Let  $\hat\theta_n=\text{argmax}_{\theta\in\Theta}\sum_{i=1}^n\log M_\theta(\mathbf{H}_3^i)$ where $M_\theta(\mathbf{H}_3)=\int_{\mathcal E} M_\theta(\mathbf{H}_3|\mathbf{E})\Pr(\mathbf{E})d\mathbf{E}$ and $\Theta$ is compact. As we will soon discuss, there are many cases where $M_\theta(\mathbf{H}_3|\mathbf{E})=f_\theta(\mathbf{H}_3|\mathbf{E})g(\mathbf{H}_3)$ and $g(\mathbf{H}_3)$ is unknown, but the obscurity of $g$ is not important because it is independent of both $\theta$ and $\mathbf{E}$. In these cases, $\hat\theta_n$ can be considered a maximum partial likelihood estimator \citep{Klein2003}. Let $I(\theta)$ be the information matrix for $M_\theta(\mathbf{H}_3)$. Let $\mathbb E_{\theta_0}[f(\mathbf{H}_3)]=\int_{\mathcal H_3}f(\mathbf{H}_3)dP_{\theta_0}(\mathbf{H}_3)$, $\mathbb E_{\mathbf{E}}[f(\mathbf{E})]=\int_{\mathcal E} f(\mathbf{E})dP_{\mathbf{E}}(\mathbf{E})$ and $\mathbb E_{\theta_0,E}[f(\mathbf{H}_3,\mathbf{E})]=\int_{\mathcal E\times\mathcal H_3}f(\mathbf{H}_3,\mathbf{E})dP_{\mathbf{E}}(\mathbf{E})dP_{\theta_0}(\mathbf{H}_3)$ where $P_{\theta}$ and $P_\mathbf{E}$ are the probability measures associated with $M_{\theta}(\mathbf{H}_3)$ and  $\Pr(\mathbf{E})$, respectively. Our first lemma outlines conditions under which consistency and asymptotic normality hold for various possible latent variable models, and is based on standard theory of M-estimators \citep{Kosorok2008}. 
\begin{theorem}
\label{thm1}
Assume w.p. one and all $\theta\in\Theta$: (C1) $\Pr(\mathbf{H}_3|\mathbf{E})=M_{\theta_0}(\mathbf{H}_3|\mathbf{E})$ for some $\theta_0\in\Theta$; (C2) $M_\theta(\mathbf{H}_3|\mathbf{E})$ is continuous in $\theta$; (C3) $|M_\theta(\mathbf{H}_3|\mathbf{E})|<F(\mathbf{H}_3|\mathbf{E})$ for some $\mathbb E_{\theta_0}[F(\mathbf{H}_3|\mathbf{E})]<\infty$; (C4) $|\log M_{\theta}(\mathbf{H}_3)|\leq F(\mathbf{H}_3)$ for some $\mathbb E_{\theta_0}[F(\mathbf{H}_3)]<\infty$; (C5) $M_{\theta_0}(\mathbf{H}_3)\neq M_\theta(\mathbf{H}_3)$ for all $\theta\neq\theta_0$. Then $\hat\theta_n\to_p \theta_0$. Moreover, assume w.p. one and all $\theta_1,\theta_2\in N_\epsilon(\theta_0)=\{\theta:||\theta-\theta_0||_2<\epsilon\}$: (N1) $I(\theta_0)$ is  nonsingular; (N2) $|M_{\theta_1}(\mathbf{H}_3|\mathbf{E})-M_{\theta_2}(\mathbf{H}_3|\mathbf{E})|\leq F(\mathbf{H}_3|\mathbf{E})||\theta_1-\theta_2||$ for some $\mathbb E_{\theta_0,\mathbf{E}}[F^2(\mathbf{H}_3|\mathbf{E})]<\infty$; (N3) $M_{\theta_1}(\mathbf{H}_3)>c$ for some $c>0$; (N4) $M_{\theta_1}(\mathbf{H}_3|\mathbf{E})$ is twice differentiable; (N5) $||\nabla_\theta M_{\theta_1}(\mathbf{H}_3|\mathbf{E})||_\infty<G(\mathbf{H}_3|\mathbf{E})$ for some $\mathbb E_{\theta_0,E}[G^2(\mathbf{H}_3|\mathbf{E})]<\infty$. Then $\sqrt{n}(\hat\theta_n-\theta_0)\to_d \mathcal N (0,I(\theta_0)^{-1})$.
\end{theorem}
Most conditions can be verified directly using $M_\theta(\mathbf{H}_3|\mathbf{E})$, without needing to worry about the integral $M_\theta(\mathbf{H}_3)=\int M_\theta(\mathbf{H}_3|\mathbf{E})\Pr(\mathbf{E})d\mathbf{E}$. However, conditions (C5) and (N1) cannot easily reduce to corresponding conditions on $M_\theta(\mathbf{H}_3|\mathbf{E})$, as even if $M_\theta(\mathbf{H}_3|\mathbf{E})$ is identifiable and has a  nonsingular information matrix, this does not imply identifiability and information matrix  nonsingularity of $M_\theta(\mathbf{H}_3)$. Conditions (C4) and (N3) also relate to the integral $M_\theta(\mathbf H_3)$, though these conditions are much easier to verify. For example, condition (N3) will hold for many model classes when $\Theta$ and $\mathcal H_3$ is compact. Moreover, under such conditions there will often exist constants $0<C_1<C_2<\infty$ such that for all $\theta\in\Theta$ and $\mathbf{H}_3\in\mathcal H_3$, $C_1<M_{\theta}(\mathbf{H}_3)<C_2$, in which case condition (C4) will also hold. 

Let $\hat\pi_n$ be the DTR estimated from LUQ-Learning with $M_\theta(\mathbf{H}_3|\mathbf{E})$ the specified model for $\Pr(\mathbf{H}_3|\mathbf{E})$, $\widehat{\mathbb E}_n[\mathbf{E}|\mathbf{H}_2]$ the estimate of $\mathbb E[\mathbf{E}|\mathbf{H}_2]$ from our MLE $M_{\hat\theta_n}(\mathbf{H}_3|\mathbf{E})$, $\widehat{\mathbb E}_n[\mathbf{Y}|\mathbf{H}_2,A_2]$ a bounded regression estimator of $\mathbb E[\mathbf{Y}|\mathbf{H}_2,A_2]$, $\widehat Q_{n,2}(\mathbf{H}_2,A_2)=\widehat{\mathbb E}_n[\mathbf{E}|\mathbf{H}_2]^T\widehat{\mathbb E}_n[\mathbf{Y}|\mathbf{H}_2,A_2]$ and $\widehat{\mathbb E}_n[\max_{a_2} \widehat Q_{n,2}(\mathbf{H}_2,a_2)|\mathbf{H}_1,A_1]$ a bounded estimator for ${\mathbb E}[\max_{a_2}\widehat Q_{n,2}(\mathbf{H}_2,a_2)|\mathbf{H}_1,A_1]$. Let $||f(\mathbf{H}_3)||_{P_{\theta_0}}=\sqrt{\mathbb E_{\theta_0}[f^2(\mathbf{H}_3)]}$. Our next theorem outlines conditions under which consistency holds for the estimated DTR. 
\begin{theorem}
\label{thm2}
Assume the following w.p. one, where $\epsilon>0$ is some constant:
\begin{align*}
&||\widehat{\mathbb E}_n[\mathbf{E}|\mathbf{H}_2]-\mathbb E[\mathbf{E}|\mathbf{H}_2]||_{P_{\theta_0}}\to_p 0,  
&& (V1) \\
& ||\widehat{\mathbb E}_n[\mathbf{Y}|\mathbf{H}_2,A_2]-\mathbb E[\mathbf{Y}|\mathbf{H}_2,A_2]||_{P_{\theta_0}}\to_p 0,
&& (V2) \\
& ||\widehat{\mathbb E}_n[\max_{a_2}\widehat Q_{n,2}(\mathbf{H}_2,a_2)|\mathbf{H}_1,A_1], \\
&- {\mathbb E}[\max_{a_2}\widehat Q_{n,2}(\mathbf{H}_2,a_2)|\mathbf{H}_1,A_1]||_{P_{\theta_0}}\to_p 0,\;\mbox{and} 
&& (V3) \\
& \Pr(A_2|\mathbf{H}_2),\Pr(A_1|\mathbf{H}_1)>\epsilon. 
&& (V4)
\end{align*}
Then $V(\widehat\pi_n)-V(\pi^*)\to_p 0$.
\end{theorem}
The term $||\widehat{\mathbb E}_n[\mathbf{E}|\mathbf{H}_2]-\mathbb E[\mathbf{E}|\mathbf{H}_2]||_{P_{\theta_0}}^2$ present in (V1) is equal to $\mathbb E_{\mathbf{H}_2\sim P_{\theta_0}}[\widehat{\mathbb E}_n[\mathbf{E}|\mathbf{H}_2]-\mathbb E[\mathbf{E}|\mathbf{H}_2]]$. This term is random with the expectation over the arguments of $\widehat{\mathbb E}_n[\mathbf{E}|\mathbf{H}_2]$ and not the estimator itself, as is the terms present in (V2) and (V3). (V1) and (V2) are similar to standard MLE consistency, except rather than requiring convergence of the parameters, we require convergence of the excess risk. Sufficient conditions for such convergence are discussed in \citet{Vapnik1998} and \citet{Gine2016}. (V3) is bit more complicated: A sufficient condition is that the regret of $\widehat{\mathbb E}_n[Q(\mathbf{H}_2)|\mathbf{H}_1,A_1]$ converges to zero uniformly over $Q\in \mathcal Q$ where $\max_{A_2}\widehat Q_{n,2}(\cdot,A_2)\in\mathcal Q$ almost surely. Such an assumption would be reasonable when $\mathcal Q$ has finite complexity \citep{Vapnik1998}.


For the BEST application, our specified log-parametric model is denoted as $\log p_\theta(\mathbf{H}_3|\mathbf{V})$ and is equal to:
\begin{align*}
&\log\left[\prod_{t=1}^2\Pr\nolimits_\theta(\mathbf{W}_t|\mathbf{V})\Pr\nolimits_\theta(\mathbf{W}_t^R|\mathbf{E}^R)\Pr\nolimits_\theta(B_t|\mathbf{E}^T\mathbf{X}_{t+1})\right] \\&+ \log\big[\Pr(\mathbf{X}_1)\Pr(A_1|\mathbf{H}_1)\Pr(\mathbf{X}_2|\mathbf{H}_1,A_1)\Pr(A_2|\mathbf{H}_2)\Pr(\mathbf{Y}|\mathbf{H}_2,A_2)\big]\\
=:& \log f_\theta(\mathbf{H}_3|\mathbf{V}) + \log g(\mathbf{H}_3).
\end{align*}
While $g(\mathbf{H}_3)$ (and thus $\log p_\theta(\mathbf{H}_3|\mathbf{V})$) is unknown, it is independent to both $\theta$ and $\mathbf{V}$, allowing us to calculate $\text{argmax}_{\theta} \log p_\theta(\mathbf H_3|\mathbf V)$ and estimate $\mathbb E[\mathbf{E}|\mathbf{H}_2]$ regardless. Let $\hat\theta_n=\text{argmax}_{\theta\in\Theta}\sum_{i=1}^n \log p_\theta(\mathbf{H}_3^i)=\text{argmax}_{\theta\in\Theta}\sum_{i=1}^n \log f_\theta(\mathbf{H}_3^i)$ where $p_\theta(\mathbf{H}_3)=\int_{\mathbb R^2}p_\theta(\mathbf{H}_3|\mathbf{V})\Pr(\mathbf{V})d\mathbf{V}$, $f_\theta(\mathbf{H}_3)=\int_{\mathbb R^2}f_\theta(\mathbf{H}_3|\mathbf{V})\Pr(\mathbf{V})d\mathbf{V}$ and $\Theta=\{\theta: ||\theta||_\infty\leq B, \lambda_t,\alpha_{1,t}, \alpha_{0,j+1,t}-\alpha_{0,j,t}\geq\epsilon\}$. We can treat the specification of constants $B$ and $\epsilon$ as part of our specified model. Note that $\Theta$ is compact. Our next theorem verifies all the conditions of the previous two theorems for our latent variable model proposed for BEST.

\begin{theorem}
\label{thm3}
Assume w.p. one that $p_{\theta_0}(\mathbf{H}_3|\mathbf{V})=\Pr(\mathbf{H}_3|\mathbf{V})$ for some $\theta_0\in\Theta$, $p_{\theta_0}(\mathbf{H}_3)\neq p_\theta(\mathbf{H}_3)$ for all $\theta\neq\theta_0$ and $g(\mathbf{H}_3)>c$ for some $c>0$. Then $\hat\theta_n\to_{p}\theta_0$ and $||\widehat{\mathbb E}_n[\mathbf{E}|\mathbf{H}_2]-\mathbb E[\mathbf{E}|\mathbf{H}_2]||_{P_{\theta_0}}\to_p 0$.  If $I(\theta_0)$ is also  nonsingular, then $\sqrt{n}(\hat\theta-\theta_0)\to_d \mathcal N (0,I(\theta_0)^{-1})$ 
\end{theorem}

Due to the difficulty of verifying identifiability of models involving integrals, it is standard to assume identifiability when deriving theoretical results for latent variable models \citep{Breslow1993, Bianconcini2014, Butler2018}. Assuming nonsingularity of the information matrix or a similar matrix is also standard \citep{McCullagh1989}, as satisfying this assumption usually requires making corresponding assumptions on the unknown data-generating distribution. 

\section{Empirical Results}

\subsection{Latent Model Accuracy and Optimization Performance}

We first apply LUQ-Learning to simulated patients from the BEST study. Recall that the most difficult component of our framework is estimating the latent variable model $\Pr(\mathbf{H}_3|\mathbf{V})$. Denote our parametric model for $\Pr(\mathbf{H}_3|\mathbf{V})$ as $\Pr_\theta(\mathbf{H}_3|\mathbf{V})$ with trainable parameter vector $\theta$. Denote $\theta_0$ as the true value of $\theta$ and $\hat\theta$ as the estimated parameter vector from maximizing the observed log-posterior $\Pr(\theta|\mathcal D)$ (which in this case is proportional to the log-likelihood $\Pr(\mathcal D|\theta)$). We calculate $\hat\theta$ and plot the mean absolute error $\dim(\theta)^{-1}||\hat\theta-\theta_0||_1$ for varying sample sizes in Figure \ref{fig:best}. For each sample size, results were averaged over 10 random seeds to adjust for parameter and sample variability (see Appendix \ref{append:details} for details). We can see that model error declines with sample size at an approximately linear rate, verifying the results given in Theorem \ref{thm3}. We also note that the identifiability assumption made in Theorem \ref{thm3} is a necessary condition for consistency. As our algorithm converges to values close to the true parameter vector for large sample sizes across multiple seeds, this suggests that our model is identifiable. 

% Figure environment removed

Our optimization algorithm also performed well. Across sample sizes and seeds, we consistently observed $\log \Pr(\widehat\theta|\mathcal D)\geq \log \Pr(\theta_0|\mathcal D)$ and $||\nabla_\theta\log \Pr(\widehat\theta|\mathcal D)||_\infty<10^{-7}$, indicating high convergence quality. Computation times for model fitting with varying sample sizes is reported in Figure \ref{figure:comp}. With $N=600$ simulated patients (the anticipated sample size for the BEST study),  model fitting took around $100$ seconds on average. Even with $10,000$ simulated patients, model fitting took under $900$ seconds on average. Computational performance can further be improved if needed by reducing the number of starting points and gradient descent iterations used as a warmup for L-BFGS. These results demonstrate the efficiency and scalability of our optimization algorithm. 

GPU computing and TensorFlow is usually used for optimizing deep learning models and is more common in computer science. It is less commonly used in the statistical literature to implement MC integration and quasi-Newton algorithms. Instead, other integration and optimization algorithms such as (adaptive) Gauss-Hermite quadrature, Markov Chain Monte Carlo (MCMC) or expectation-maximization (EM) combined with CPU computing are more popular \citep{Givens2012, GLIMMIX2018, Butler2018}, all of which would have taken significantly more time for our setting. We hope that our results will motivate better computational approaches in the statistical literature moving forward. 

\subsection{Performance of the Estimated DTR}

%Recall that to estimate the optimal DTR, we only require accurate estimation of $\mathbb E[\mathbf{E}|\mathbf{H}_2]$. Therefore, a better way to evaluate the accuracy of the model is by assessing the regret, or average absolute error, in our estimated conditional expectation \\ $\mathbb E_{\mathbf{H}_2\sim\mathcal D}\left[(1/3)||\mathbb E_{\theta_0}[\mathbf{E}|\mathbf{H}_2]-\mathbb E_{\hat\theta}[\mathbf{E}|\mathbf{H}_2]||_1\right]$. For $N=600$ simulated patients, the mean of this metric across 10 seeds is $0.009$ with a range of $[0.074, 0.01]$. For context,  the mean diagonal of $\sqrt{{\text{Cov}_{\mathbf H_2\sim\mathcal D}\{\mathbb E_{\theta_0}[\mathbf{E}|\mathbf{H}_2]\}}}$, is around $0.17$. This suggests that our fitted model estimates $\mathbb E[\mathbf{E}|\mathbf{H}_2]$ with very high accuracy. 

Performance for LUQ-Learning's DTR $\hat\pi_{\text{LUQL}}$ as well as various baselines is given on the left column of Table \ref{table:best}. For each DTR, we report the average (std) of policy values across 10 seeds. Here $\pi_{\text{obs}}$ is the policy that generated the observed data, $\hat\pi_{\text{known}}$ ablates our framework by replacing $\mathbb E_{\widehat\theta}[\mathbf{E}|\mathbf{H}_2]$ with the true weights $\mathbf E$, $\hat\pi_{B_2}$ comes from Q-learning with $B_2$ treated as the outcome, and $\hat\pi_{\text{naive}}$ ablates our framework by replacing $\mathbb E_{\widehat\theta}[\mathbf{E}|\mathbf{H}_2]$ with $(1/3,1/3,1/3)$. We can see that LUQ-Learning yields significant improvement over the observational policy. We can also see that it performs nearly as well as $\hat\pi_{\text{known}}$, indicating that our method is almost as efficient as if the utilities $U=\mathbf{E}^T\mathbf{Y}$ were observed. Finally, we can see that $\hat\pi_{\text{LUQL}}$ performs much better than $\hat\pi_{B_2}$: $B_2$ is a discretized and noisy approximation of the true utilities $U$, and running Q-learning with $B_2$ as the outcome leads to excess variance. Moreover, while in this case optimizing $\mathbb E_\pi[B_2]$ and $\mathbb E_\pi[U]$ would lead to the same DTRs asymptotically, this is not true in general (see Section \ref{sec:framework}). 


\begin{table*}[!b]
\centering
\captionsetup{margin=2cm}
\caption{Value of Different DTRs on Two BEST Generative Models.}\label{table:best}
\begin{tabular}{llll}
 \hline
DTR & Standard Model & Ablation Model \\
 \hline
$\pi_{\text{obs}}$ & 4.79 (0.41) & 4.97 (0.06)  \\
$\hat\pi_{\text{LUQL}}$ & 6.87 (0.61) & 5.57 (0.12) \\
$\hat\pi_{\text{known}}$ & 6.90 (0.60) & 5.60  (0.12) \\
$\hat\pi_{B_2}$ & 6.04 (0.63) & 5.23 (0.13) \\
$\hat\pi_{\text{naive}}$ & 6.78 (0.63) & 5.00  (0.04) \\
 \hline
\end{tabular}
\end{table*}

 While the previous generative model demonstrates LUQ-Learning's effectiveness in estimating the true utilities, it fails to demonstrate the importance of incorporating such utilities in the first place. For example, we can see that $\hat\pi_{\text{naive}}$ performs nearly as well as $\hat\pi_{\text{LUQL}}$, where $\widehat\pi_{\text{naive}}$ naively assumes all outcomes are equally important for all subjects. We therefore considered an ablated generative model where $A_2$ had opposing effects on the components of $\mathbf{Y}$, and such effects no longer depended on $\mathbf{X}_2$ (see Appendix 
 \ref{append:details} for details). As $\mathbf{Y}$ now consists of competing outcomes, $\widehat\pi_{\text{naive}}$ should now be expected to perform much worse. Moreover, though there is no longer heterogeneity in treatment effects, the covariates are still useful in inferring patient preferences. This ablation allows us to isolate the utility of our latent variable model in a precision medicine framework. Results can be found on the right column of Table \ref{table:best}. We can see that now $\hat\pi_{\text{LUQL}}$ performs much better than $\hat\pi_{\text{naive}}$, showing the benefits of both LUQ-Learning and of incorporating patient preferences more generally. 

\subsection{Application to Simulated Schizophrenia Patients}

To demonstrate the broad applicability of LUQ-Learning, we now consider a modified version of the simulated datasets of \citet{Butler2018}. Their simulation was loosely inspired by the first phase of the Clinical Antipsychotic Trials of Intervention Effectiveness (CATIE) trial \citep{Stroup2003}. There is one decision point and five treatments, which the authors dichotomize into traditional and atypical antipsychotics. There are two continuous outcomes representing treatment efficacy and  side effect burden. The questionnaire given to elicit patient preferences consists of 10 questions from the Drug Attitude Inventory \citep{Hogan1983}. There are assumed to be five continuous covariates that have treatment-specific effects on the outcomes. The number of simulated patients $(N=200)$ is smaller than our previous simulation study. We appended their generative model with a Poisson-distributed surrogate for patient satisfaction. The entire generative model is summarized below:
\begin{align*}
& V\sim N (0,1), \\
& \mathbf{E}=(\Phi(V), 1-\Phi(V)), \\
&X_j \overset{iid}\sim N(0,1) \quad (1 \leq j \leq 5), \\
&{W}_j\overset{ind}\sim\text{Bernoulli}(p=\beta_{0,j}+\beta_{1,j}V)\quad (1\leq j \leq 10), \\
&A \sim \text{Bernoulli}(p=0.5), \\
& \epsilon_j \overset{iid}\sim N(0,1) \quad (1 \leq j \leq 2), \\
& Y_j = \mathbf{X}_*^T\gamma_{j,0} + A\mathbf{X}_*^T\gamma_{j,1}+\epsilon_j \quad (1 \leq j \leq 2),\;\mbox{and} \\
& B \sim \text{Pois}\left(\lambda=\exp(\alpha_0+\alpha_1 U)\right).
\end{align*}
Here $\mathbf{X}_*=(1,\mathbf{X})$ and $\Phi(\cdot)$ is the standard normal CDF. We also let $\mathbf{H}_1=(\mathbf{W},\mathbf{X})$ and $\mathbf{H}_2=(\mathbf{W},\mathbf{X},A,\mathbf{Y},B)$. $\gamma=(\gamma_{i,j})_{i,j=1}^{2}$ was fixed as in \citet{Butler2018} to make the outcomes competitive, though we did allow $\beta=(\beta_{i,j})_{i,j=1}^{i=2,j=10}$ to vary between seeds (for each seed, we set $\beta_{0,j}=0$ and drew $\beta_{1,j}\sim N(0,1)$). Finally, for a given seed we set $\alpha_1=(1/6)(\max_n(U)-\min_n(U))$ and $\alpha_0=-\alpha_1\min_n(U)$ where $\max_n(U), \min_n(U)$ are the maximum and minimum latent utility for patients in the observed dataset, so that the maximum observed value of $B$ would be around $\exp(3)$. 

\begin{table*}[!b]
\centering
\captionsetup{margin=1.5cm}
\caption{Mean (IQR) of Statistics across 10 Seeds for CATIE simulations.}\label{table:catie}
\begin{tabular}{llll}
 \hline
Statistic & Our Method & Butler Method \\
 \hline
$\mathbb E\left[|\mathbb E[\mathbf{E}|\mathbf{H}_1]-\widehat{\mathbb E}[\mathbf{E}|\mathbf{H}_1]|\right]$ & 0.03 (0.02 -- 0.03) & 0.25 \hspace{0em}  (0.03 -- 0.41) \\
$V(\hat\pi)-V(\pi_{\text{obs}})$ & 0.22  (0.19 -- 0.25) &  0.07  (-0.02 -- 0.17) \\
 \hline
\end{tabular}
\end{table*}

As before, we assume a correctly-specified model for $\Pr(\mathbf H_2|\mathbf{V})$ and estimate model parameters $\theta=(\beta,\alpha)$ via partial maximum likelihood. Also like before, $\mathbb E[\mathbf{Y}|\mathbf{H}_1,A]$ is estimated via a generalized linear model with a correctly-specified design matrix, response distribution and link function. As the simulated datasets have a single decision point and two outcomes, the methodology of \citet{Butler2018}   could also be applied here. With a single decision point and two outcomes, the Butler method reduces to LUQ-Learning when measures of patient satisfaction are not incorporated into the partial likelihood and the optimizer is an EM algorithm that constraints the $\beta_{1,j}$'s to be positive. We shall use the same optimization algorithm for both methods, so that the only difference is whether satisfaction $B$ is incorporated into the model. 

Results are given in Table \ref{table:catie}. As in the BEST simulations, LUQ-Learning accurately estimates the expected preference weights and estimates a high-performing DTR. On the other hand, the Butler method has very high estimation error on average. For context, naively estimating $\mathbb E[\mathbf E|\mathbf H_1]$ as $0.5$ for all patients yields an estimation error of only $0.2$ on average. As a result, the estimated DTR in some cases performs worse than even the observational policy. 

While we previously explored bias and efficiency issues with estimating a DTR \textit{solely} from reported patient satisfaction, these results show that failing to incorporate reported patient satisfaction \textit{at all} also yields subpar results. A more narrow posterior of a latent variable oftentimes corresponds to a more narrow posterior of the parameters of the latent variable model. For example, \citet{Butler2018} found that increasing $\dim(\mathbf{W})$ actually led to lower estimation variance, even though $\dim(\theta)$ increased. This is in contrast to complete data log-likelihoods, where more parameters usually results in increased estimation variance. While the quantity we wish to estimate, $\mathbb E[\mathbf{E}|\mathbf{H}_1]$, does not depend on $B$, not using $B$ leads to estimating a model for $\Pr(\mathbf{W}|\mathbf{E})$ instead of $\Pr(\mathbf{W},B|\mathbf{E})$. As $\Pr(\mathbf{E}|\mathbf{W})$ has a  wider distribution than $\Pr(\mathbf{E}|\mathbf{W},B)$, the Butler method leads to greater estimation variance, even among those parameters solely related to $\Pr(\mathbf{E}|\mathbf{W})$. 

%In general, the amount of information lost from failing to incorporate $B$ depends on the dataset. However, for the setup of this section, failing to incorporate $B$ yields unbounded variance, as the resulting objective function $L_n(\beta)=\mathbb E_n\left[\log \int_{\mathbb R}\Pr_\beta(\mathbf{W}|V)\Pr(V)dV\right]$ is not identifiable (switching the sign of any $\beta_{1,j},1\leq j \leq 10$ does not change $L_n(\beta)$). In their theoretical results and optimizer, \citet{Butler2018} achieved identifiability by assuming the $\beta_{1,j}$'s are non-negative, but such an assumption cannot be made without loss of generality. For example, in the simulation model of this section, some of the coefficients are negative, and adding such constraints into the optimization would result in unbounded bias.

It is worth noting that Theorem \ref{thm3} can easily be extended to the latent variable model proposed here under mild assumptions, such as that $|B|,|\mathbf{Y}|<C$ w.p. one for some $C\in\mathbb{R}$.


 

\section{Conclusions}

Despite the prevalence of healthcare decision-making problems with multiple outcomes of interest, the few applicable solutions from previous work suffer from various limitations that hinder applicability to many real-world settings. To this end, we have developed a new framework, LUQ-Learning, that treats the utility function to optimize as a latent variable, and incorporates the latent variable into Q-learning using a a latent model approach. Unlike previous approaches, LUQ-Learning allows for an arbitrary number of time points and outcomes, uses questionnaire responses for both outcome preferences and satisfaction to maximize estimation accuracy of the latent utilities, and does not require access to expert-level data or extensive domain knowledge. Theoretical performance of our approach was investigated, where we demonstrated that our application to the BEST study achieves consistency and asymptotic normality under much more mild assumptions than those made by many previous methods. Our theoretical results extend easily to other proposed latent models as well, such as that proposed for the CATIE study, under mild conditions. We also demonstrated the flexibility and robust performance of our method on a diverse set of simulated datasets. In contrast, DTRs estimated to optimize over more naive utilities, such as self-reported satisfaction or a simple mean of the outcomes, perform significantly worse. Finally, the computational performance for our proposed optimization procedure demonstrates the potential of deep learning libraries like TensorFlow for fast numerical integration and optimization of statistical models, and adds to a growing body of recent literature arguing the utility of such libraries for solving statistical problems \citep{Grogan2020}.

Despite our work's progress in multi-objective, preference-based precision medicine, there remain many promising areas of future work to explore. For example, while our theoretical results make fewer assumptions than those of many previous approaches, they still assume identifiability of the latent model. Establishing identifiability of latent variable models is difficult due to the presence of the integral in the objective function, and there has not been much previous work investigating how to do this. Developing new theoretical results and proof techniques to establish identifiability of likelihoods with integrals would be helpful not only for our method, but also for other kinds of latent variable models as well as hierarchical Bayes models \citep{Givens2012}. Moreover, while we established a theoretical framework for how to adopt the proposed model of latent utilities to the data in Appendix \ref{append:tune}, the framework has yet to be empirically investigated. A promising avenue for future work would be to combine nonparametric approaches with LUQ-Learning and demonstrate its adoptability to complex data-generating distributions. Finally, extending our approach to inverse probability weighting, nonlinear utility functions and censored outcomes would all constitute meaningful future work as well. 


  \section{Acknowledgements}
  The authors thank John Sperger for relevant references and helpful discussion. 
  
  \section{Funding}
  This research was supported by the National Institutes of Health (NIH) through the NIH HEAL Initiative under award number 1U24 AR076730-01 and is part of the Back Pain Consortium (BACPAC). The BACPAC Research Program is administered by the National Institute of Arthritis and Musculoskeletal and Skin Diseases (NIAMS). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health or its NIH HEAL Initiative. 

  
  \section{Disclosure Statement}
  The authors report there are no competing interests to declare.


\printbibliography

\newpage
\appendix
\part*{Appendix}
\counterwithin{figure}{section}
\newtheorem{lemma}{Lemma}
\newcommand{\argmax}[0]{\text{argmax}}
\newcommand{\bI}[0]{\mathbf{I}}
\newcommand{\bV}[0]{\mathbf{V}}
\newcommand{\bv}[0]{\mathbf{v}}
\newcommand{\bW}[0]{\mathbf{W}}
\newcommand{\bw}[0]{\mathbf{w}}
\newcommand{\bH}[0]{\mathbf{H}}
\newcommand{\bh}[0]{\mathbf{h}}
\newcommand{\bX}[0]{\mathbf{X}}
\newcommand{\bE}[0]{\mathbf{E}}
\newcommand{\bY}[0]{\mathbf{Y}}
\newcommand{\iid}[0]{\overset{iid}\sim}
\newcommand{\Bern}[0]{\text{Bernoulli}}
\newcommand{\ind}[0]{\overset{ind}\sim}
\newcommand{\indep}{\perp \!\!\! \perp}
\newcommand{\eps}[0]{\epsilon}
\newcommand{\MC}[0]{\text{MC}}

\section{Incorporating Model Selection into LUQ-Learning}
\label{append:tune}

Note that we require specifying a parametric model $P_\theta(\bH_3|\bE)$ for $\Pr(\bH_3|\bE)$ with parameter vector $\theta$. In practice, we do not know in advance what $\Pr(\bH_3|\bE)$ is. In some cases, an approximately correct model for $\Pr(\bH_3|\bE)$ can be chosen using a combination of previous literature, statistical expertise and domain knowledge. In other cases, however, assuming a correctly-specified model for $\Pr(\bH_3|\bE)$ can be a rather strong assumption. Instead, our methodology would be more robust if there was a way to select among multiple proposed parametric models $M_1(\bH_3|\bE,\theta_1),...,M_P(\bH_3,|\bE,\theta_P)$ for $\Pr(\bH_3|\bE)$ and make a weaker assumption that only one of our models was correctly specified. Here $\theta_p$ denotes the parameter vector associated with the $p$th proposed parametric model $M_p(\bH_3|\bE,\theta_p)$ for $\Pr(\bH_3|\bE)$. One way to select among models is to partition our data as $\mathcal D=\mathcal D_T\cup \mathcal D_V$, train each parametric model $M_p(\bH_3|\bE,\theta_p),1\leq p \leq P$ as $M_p(\bH_3|\bE,\hat\theta_p)$ on training set $\mathcal D_T$ and then evaluate the estimated models using the observed log-likelihood $\sum_{\bH_3\in\mathcal D_V}\log\int_{\mathcal E}M_p(\bH_3|\bE,\hat\theta_p)\Pr(\bE)d\bE$ on the held-out validation set $\mathcal D_V$.  Under some reasonable identifiability conditions, the generalization observed log-likelihood will be minimized uniquely at the true probability model $\Pr(\bH_3|\bE)$ making it a valid loss to tune hyperparameters and select models. 

As discussed in the Theoretical Results section, there are many cases where \\
$M_1(\bH_3|\bE,\theta_1),...,M_P(\bH_3,|\bE,\theta_P)$ are technically unknown but the associated parameter vectors $\theta_1,...,\theta_P$ can still be estimated by maximizing a partial likelihood. Specifically, suppose that $\Pr(\bH_3|\bE)=f(\bH_3|\bE)g(\bH_3)$ where $g(\bH_3)$ is unknown and $f_1(\bH_3|\bE,\theta_1),...,f_P(\bH_3|\bE,\theta_P)$ are all parametric models for $f(\bH_3|\bE)$. Let $M_p(\bH_3|\bE,\theta_p)=f_p(\bH_3|\bE,\theta_p)g(\bH_3)$. As before, we can train each parametric model $M_p(\bH_3|\bE,\theta_p),1\leq p \leq P$ as $M_p(\bH_3|\bE,\hat\theta_p)$ on training set $\mathcal D_T$ by solving $\argmax_\theta\log\sum_{\bH_3\in\mathcal D_T}\int_{\mathcal E}f_p(\bH_3|\bE,\theta)\Pr(\bE)d\bE$, as this solution is equivalent to $\argmax_\theta\log\sum_{\bH_3\in\mathcal D_T}\int_{\mathcal E}M_p(\bH_3|\bE,\theta)\Pr(\bE)d\bE$. We can then evaluate the estimated models using the equivalent partial log-likelihood on the held-out validation set $\mathcal D_V$. The next lemma provides some theoretical justification for such a procedure, the proof of which is a straightforward application of Lemma 5.35 of \citet{Vaart1998}. Here $F_p(\bH_3|\bE)=f_p(\bH_3|\bE,\hat\theta_p)$ and $F_p(\bH_3)=\int_{\mathcal E}F_p(\bH_3|\bE)\Pr(\bE)d\bE$.

\begin{lemma}
Suppose $\mathcal F=\{f_1,...,f_P\}$ are models for $f(\bH_3|\bE)$ where $F_p(\bH_3|\bE)g(\bH_3),1\leq p \leq P$ define valid probability measures. Suppose too that there exists an $F_p\in\mathcal F$ such that $F_p(\bH_3|\bE)=f(\bH_3|\bE)$ and $F_p(\bH_3)\neq F(\bH_3)$ for every other $F\in\mathcal F$. Then $\argmax_{F\in\mathcal F}\mathbb E\left[\log F (\bH_3)\right]=f(\bH_3|\bE)$.
\end{lemma}

Another possibility is to use estimated satisfaction value $\mathbb E_{\mathcal D_V}\left[\frac{\pi_{p,1}(A_1|\bH_1)\pi_{p,2}(A_2|\bH_2)}{\mu_1(A_1|\bH_1)\mu_2(A_2|\bH_2)}B_2\right]$ to evaluate model $M_p$, where $\pi_p=(\pi_{p,1},\pi_{p,2})$ is the length-2 DTR sequence estimated from our procedure with $M_p$ chosen as the parametric model for $\Pr(\bH_3|\bE)$ and $\mu=(\mu_1,\mu_2)$ is the behavioral policy. This is an importance sampling or inverse probability weighted  estimator for $\mathbb E_{\pi_p}[B_2]$ \citep{Zhao2015bowl}. An advantage of this approach is that it guarantees our estimated DTR yields decent reported satisfaction even if none of the proposed models for $\Pr(\bH_3|\bE)$ are correctly specified. The drawback of this approach, however, is that it does not choose models based on accuracy of estimating $\Pr(\bH_3|\bE)$ and will thus be a poor choice if estimation and inference on the posterior distribution of $\bE$ is of interest. Moreover, as reported satisfaction is only a noisy and imperfect measure of the true latent utilities, using satisfaction-based value may fail to choose the model that maximizes the true utility-based value $V(\pi_p)$, particularly in finite-sample settings. 

\section{Extended Details of Generative Model}
\label{append:details}

Below we fully specify the standard generative model for BEST. For each variable, the specified distribution is conditioned on the variables previously introduced in the lines above. Thus for example, the specified distribution $X_{1j}$, $\text{Binomial}(n=10,p=0.5)$, is conditional on $\bV$ and $W_{1j},1\leq j \leq 12$ (and thus $X_{1j}$ is independent of these variables). 
\footnotesize
\begin{align*}
& \bV\sim \mathcal N_{2}(0,\bI), \\
& \bE=\text{SoftMax}(\bV)=\frac{(e^\bV,1)}{1+\text{sum}(e^\bV)}, \\
&W_{1j}\iid \Bern(p=\beta_{0,j,1}+\beta^T_{1,j,1}\bV), 1 \leq j \leq 12, \\
&\bW_1^R\sim\text{Cat}(p),\quad \Pr(\bW_1^R=\bw)=\frac{\exp(-\lambda_1 T(\bw,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_1 T(\bv,\bE^R))}, \\
& X_{1j}\iid \text{Bin}(n=10,p=0.5), 1 \leq j \leq 3,\\
& A_1\sim \text{Uniform}(\mathcal A_1), \\
&W_{2j} \ind\Bern(p=\beta_{0,j,2}+\beta^T_{1,j,2}\bV), 1 \leq j \leq 12, \\
&\bW_2^R\sim\text{Cat}(p),\quad \Pr(\bW_2^R=\bw)=\frac{\exp(-\lambda_2 T(\bw,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_2 T(\bv,\bE^R))}, \\
& X_{2j}\ind \text{Bin}\left(n=10,p=\sigma\left[\sum\nolimits_{k\in\{1,2,3,4\}}\gamma_{0,k,j,1}I(A_1=k)+\frac{X_{1j}-\mathbb E[X_{1j}]}{\sqrt{\text{Var}[\bX_{ij}]}}\sum\nolimits_{k\in\{1,2,3,4\}}\gamma_{1,k,j,1}I(A_1=k)\right]\right), 1 \leq j \leq 3, \\
& B_1\sim\text{Categorical}(p),\quad \Pr(B_1\leq k)=\sigma(\alpha_{0,k,1}-\alpha_{1,1}\bE^T\bX_2), \\
&C\sim\text{Uniform}(\mathcal C), \\
&A_2=\begin{cases}A_1&C=1\\A_1+a,\quad a\sim\text{Uniform}(\mathcal A_1\setminus A_1)&C=2 \text{ or } (A_1=1 \text{ and } C\geq 2)\\B(A_1+a)+(1-B)a,\quad B\sim\text{Bernoulli}(0.5),a\sim\mathcal U(\mathcal A_1\setminus A_1)&C=3 \text{ and } A_1\neq 1\\a,\quad a\sim \text{Uniform}(\mathcal A_1\setminus A_1)&C=4 \text{ and } A_1\neq 1,\end{cases} \\
&Y_j\ind \text{Bin}\left(n=10,p=\sigma\left[\sum\nolimits_{k\in\{1,2,3,4\}}\gamma_{0,k,j,2}I(k\in A_2)+\frac{X_{2j}-\mathbb E_\mu[X_{2j}]}{\sqrt{\text{Var}_\mu[X_{2j}]}}\sum\nolimits_{k\in\{1,2,3,4\}}\gamma_{1,k,j,2}I(k\in A_2)\right]\right), 1 \leq j \leq 3, \\
&B_2\sim\text{Categorical}(p),\quad \Pr(B_2\leq k)=\sigma(\alpha_{0,k,2}-\alpha_{1,2}\bE^T\bY),
\end{align*}
\normalsize
where the parameters of our generator are themselves simulated as follows:
\begin{align*}
&\theta=(\beta,\alpha,\gamma),\\
&\beta_{0,k,1}=0,\ \beta_{1,k,1}\iid \mathcal N_2(0,1) \quad (1 \leq k \leq 12),\\
&\beta_{0,k,2}=0,\ \beta_{1,k,2}=\sqrt{0.8}\beta_{1,k,1}+\sqrt{0.2}\eps_{\beta,k},\ \eps_{\beta,k}\iid \mathcal N_2(0,1) \quad (1\leq k \leq 12), \\
&\alpha_{1,1}=0.5,\ \alpha_{0,k,1}=0.75 k \quad (1\leq k \leq 6), \\
&\alpha_{1,2}=0.6,\ \alpha_{0,k,2}=\alpha_{0,k,1}+0.5 \quad (1\leq k \leq 6), \\
&\lambda_1=0.5,\lambda_2=2, \\
&\gamma_{0,i,j,1}\iid N(0,0.5^2),\  \gamma_{1,i,j,1}\iid N(0,1) \quad (1 \leq i \leq 4, 1\leq j \leq 3), \;\mbox{and}\\
&(\gamma_{0,i,j,2}, \gamma_{1,i,j,2})=\sqrt{0.8}(\gamma_{0,i,j,1},\gamma_{0,i,j,2})+\sqrt{0.2}\eps_{\gamma,i,j},\ \eps_{\gamma,i,j}\iid\mathcal N_2(0,(0.5^2,1))  \quad (1 \leq i \leq 4, 1\leq j \leq 3).
\end{align*}

Recall that our experiments are run over 10 seeds. For each seed, we first simulate model parameters from their respective priors described above, and then we simulate the dataset given the simulated model parameters. 

For the ablation generative model, we set $\gamma_{1,k,j,2}=0$, $\gamma_{0,k,0,2}=0$ and $\gamma_{0,k,3,2}=-\gamma_{0,k,2,2}$. These modifications change the distribution of the outcomes to $Y_1\sim \text{Binomial}(n=10,p=0.5)$, $Y_2\sim \text{Binomial}(n=10,p=\sigma(f(A_2)))$ and $Y_3\sim \text{Binomial}(n=10,p=\sigma(-f(A_2)))$ where $f(A_2)=\text{expit}(\Pr(Y_2|A_2,\bX_2))$. Now $Y_1$ can be thought of as a random intercept in our utilities $\bE^T\bY$, while $Y_2$ and $Y_3$ can be thought of as competing outcomes. Moreover, for each seed, we simulated $\gamma_{0,k,2,2}$ from $N(0,1)$instead of $N(0,0.5^2)$, so as to increase effect sizes and reduce signal-to-noise ratio. As $\bX_2$ is now independent of $Y$, it may appear that covariates are no longer relevant to the DTR. However, this is not the case: the observed data is still useful for estimating the expected value of $\bE$, which determines the best sequence of treatments to take. 


\section{Mathematical Proofs}
\label{append:proofs}

\begin{theorem}
$\hat\theta_n\to_p \theta_0$ provided with probability one and all $\theta\in\Theta$: (C1) $\Pr(\bH_3|\bE)=M_{\theta_0}(\bH_3|\bE)$ for some $\theta_0\in\Theta$; (C2) $M_\theta(\bH_3|\bE)$ is continuous in $\theta$; (C3) $|M_\theta(\bH_3|\bE)|<F(\bH_3|\bE)$ for some $\mathbb E_{\theta_0}[F(\bH_3|\bE)]<\infty$; (C4) $|\log M_{\theta}(\bH_3)|\leq F(\bH_3)$ for some $\mathbb E_{\theta_0}[F(\bH_3)]<\infty$; (C5) $M_{\theta_0}(\bH_3)\neq M_\theta(\bH_3)$ for all $\theta\neq\theta_0$. Moreover, $\sqrt{n}(\hat\theta_n-\theta_0)\to_d \mathcal N (0,I(\theta_0)^{-1})$, provided with probability one and all $\theta_1,\theta_2\in N_\eps(\theta_0)=\{\theta:||\theta-\theta_0||_2<\eps\}$: (N1) $I(\theta_0)$ is non-singular; (N2) $|M_{\theta_1}(\bH_3|\bE)-M_{\theta_2}(\bH_3|\bE)|\leq F(\bH_3|\bE)||\theta_1-\theta_2|$ for some $\mathbb E_{\theta_0,\bE}[F^2(\bH_3|\bE)]<\infty$; (N3) $M_\theta(\bH_3)>c$ for some $c>0$; (N4) $M_{\theta_1}(\bH_3|\bE)$ is continuously differentiable; (N5) $||\nabla_\theta M_{\theta_1}(\bH_3|\bE)||_\infty<G(\bH_3|\bE)$ for some $\mathbb E_{\theta_0,\bE}[G^2(\bH_3|\bE)]<\infty$.
\end{theorem}

\begin{proof}
By Theorem 5.7 of \citet{Vaart1998}, $\hat\theta_n\to_p \theta_0$ provided (A1) $L_n(\hat\theta_n)\geq L_n(\theta_0)-o_p(1)$; (A2) $\sup_{\theta:d(\theta,\theta_0)\geq \eps}M(\theta)<M(\theta_0)$ for all $\eps>0$; (A3) $\sup_{\theta\in\Theta}|M_n(\theta)-M(\theta)|\to_p 0$. Define $L_n(\theta)=\sum_{i=1}^n\log M_\theta(\bH_3^i)$ and $L(\theta)=\mathbb E\left[\log M_\theta(\bH_3^i)\right]$. Assumption (A1) is satisfied by definition of $\hat\theta_n$. 

By (C1), $\Pr(\bH_3)=\int_{\mathcal E}\Pr(\bH_3|\bE)\Pr(\bE)d\bE=\int_{\mathcal E}M_{\theta_0}(\bH_3|\bE)\Pr(\bE)d\bE=M_{\theta_0}(\bH_3)$. Thus by (C1) and (C5), we have by Lemma 5.35 of \citet{Vaart1998} that $L(\theta)$ is uniquely maximized at $\theta_0$. By (C3), it must be that  $M_\theta(\bH_3)=\int_{\mathcal E}M_\theta(\bH_3|\bE)\Pr(\bE)d\bE<\infty$ almost surely, and thus by (C2) and the dominated convergence theorem, $M_\theta(\bH_3)$ is continuous in $\theta$ almost surely. By (C4), $\log M_\theta(\bH_3)<\infty$ almost surely, which means $M_\theta(\bH_3)>0$ almost surely, which means $\log M_\theta(\bH_3)$ is continuous in $\theta$ almost surely. Therefore, by compactness of $\Theta$ and (C5), assumption (A2) is satisfied by Problem 5.27 of \citet{Vaart1998}. Finally, by (almost-sure) continuity of $\log M_\theta(\bH_3)$, (C4) and compactness of $\Theta$, we have by example 19.8 of \citet{Vaart1998} that $\{M_\theta(\bH_3):\theta\in\Theta\}$ defines a $P_{\theta_0}$-Glivenko-Cantelli class. Therefore assumption (A3) is satisfied.

By Theorem 5.39, $\sqrt{n}(\hat\theta_n-\theta_0)\to_d\mathcal N(0,I(\theta_0)^{-1})$ provided (B1) $\hat\theta_n\to_p \theta_0$, (B2) $I(\theta_0)$ is non-singular, (B3) $\log M_{\theta}(\bH_3)$ is Lipschitz continuous in an neighborhood of $\theta_0$ with Lipschitz constant $F(\bH_3)$ square-integrable and (B4) $M_{\theta}(\bH_3)$ is Hellinger differentiable. (B2) is satisfied by assumption and (B1) is satisfied by conditions (C1)-(C5).

By (N2) and Jensen's inequality, $|M_{\theta_1}(\bH_3)- M_{\theta_2}(\bH_3)|\leq \mathbb E_E[F(\bH_3|\bE)]||\theta_1-\theta_2|$ and by (N3), $\log'(M_\theta(\bH_3))$ is bounded by $1/c$. As the composition of Lipschitz continuous functions are also Lipschitz continuous with the Lipschitz constant being the product of those of the composing functions \citep{Shwartz2014}, $|\log M_{\theta_1}- \log M_{\theta_2}(\bH_3)|\leq \frac{1}{c}\mathbb E_E[F(\bH_3|\bE)]||\theta_1-\theta_2|$ with $\mathbb E_{\theta_0}\frac{1}{c}\mathbb E_{E}[F(\bH_3|\bE)]<\infty$. Thus condition (B3) is satisfied. 

By (N5), $\mathbb E_{E}[G(\bH_3|\bE)]<\infty$ almost surely. Thus we have by the Leibniz integral theorem and (N4) that $\nabla_\theta M_\theta(\bH_3)=\mathbb E_E [\nabla_\theta M_\theta(\bH_3|\bE)]$, and we have by the dominated convergence theorem that $\nabla_\theta M_\theta(\bH_3)$ is continuous. As $\nabla_\theta \sqrt{M_\theta(\bH_3)}=\frac{1}{\sqrt{M_\theta(\bH_3)}}\sqrt{M_\theta(\bH_3)}$ and $M_\theta(\bH_3)>c$ for some $c>0$ by (N3), $\nabla_\theta \sqrt{M_\theta(\bH_3)}$ is also continuous. Finally, under our assumptions $I(\theta)=\mathbb E_{\theta_0}\left[\frac{1}{M_\theta(\bH_3)^2}\mathbb E_E [\nabla_\theta M_\theta(\bH_3|\bE)]\mathbb E_E [\nabla_\theta M_\theta(\bH_3|\bE)]^T\right]$ with each element of this matrix bounded by $\frac{1}{c}\mathbb E_E^2[G(\bH_3|\bE)]\leq \frac{1}{c}\mathbb E_E[G^2(\bH_3|\bE)]$ and $\frac{1}{c}\mathbb E_{\bE,\theta_0}[G^2(\bH_3|\bE)]<\infty$, and thus using the dominated convergence theorem once more, we have that $I(\theta)=\mathbb E_{\theta_0}\left[\frac{1}{M_\theta(\bH_3)^2}\mathbb E_E [\nabla_\theta M_\theta(\bH_3|\bE)]\mathbb E_E [\nabla_\theta M_\theta(\bH_3|\bE)]^T\right]$ is continuous. As $\sqrt{M_\theta(\bH_3)}$ is continuously differentiable and $I(\theta)$ is continuous, we have by lemma 7.6 of \citet{Vaart1998} that $M_\theta(\bH_3)$ is Hellinger differentiable, satisfying condition (B4). 
\end{proof}

\begin{theorem}
$V(\widehat\pi_n)-V(\pi^*)\to_p 0$ provided with probability one; (V1) $||\widehat{\mathbb E}_n[\bE|\bH_2]-\mathbb E[\bE|\bH_2]||_{P_{\theta_0}}\to_p 0$; (V2) $||\widehat{\mathbb E}_n[\bY|\bH_2,A_2]-\mathbb E[\bY|\bH_2,A_2]||_{P_{\theta_0}}\to_p 0$; (V3) \newline $\widehat{\mathbb E}_n[\max_{A_2}\widehat Q_{n,2}(\bH_2,A_2)|\bH_1,A_1]-{\mathbb E}[\max_{A_2}\widehat Q_{n,2}(\bH_1,A_1)|\bH_1,A_1]|||_{P_{\theta_0}}\to_p 0$; \newline (V4) $\Pr(A_2|\bH_2),\Pr(A_1|\bH_1)>\eps$ for some $\eps>0$.
\end{theorem}

\begin{proof}
Note that:
\begin{align*}
||\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)||_{P_{\theta_0}}=&||\widehat{\mathbb E}_n[\bE|\bH_2]^T\widehat{\mathbb E}_n[\bY|\bH_2,A_2]-{\mathbb E}[\bE|\bH_2]^T{\mathbb E}[\bY|\bH_2,A_2]||_{P_{\theta_0}}\\
=& ||(\widehat{\mathbb E}_n[\bE|\bH_2]-\mathbb E[\bE|\bH_2])^T\widehat{\mathbb E}_n[\bY|\bH_2,A_2]\\&+ \mathbb E[\bE|\bH_2]^T(\widehat{\mathbb E}_n(\bY|\bH_2,A_2)-\mathbb E(\bY|\bH_2,A_2))||_{P_{\theta_0}} \\
\leq& ||\widehat{\mathbb E}_n[\bE|\bH_2]-\mathbb E[\bE|\bH_2]||_{P_{\theta_0}}^T||\widehat{\mathbb E}_n[\bY|\bH_2,A_2]||_{\infty}\\&+||\mathbb E[\bE|\bH_2]||_{\infty}^T||\widehat{\mathbb E}_n(\bY|\bH_2,A_2)-\mathbb E(\bY|\bH_2,A_2)||_{P_{\theta_0}},
\end{align*}
where the last inequality uses Minkowski's inequality. As both $\mathbb E[\bE|\bH_2]$ and $\widehat{\mathbb E}_n[\bY|\bH_2,A_2]$ are assumed to be strictly bounded, we have by (V1), (V2) and Slutsky's theorem that the term following the inequality above converges to zero in probability. We also note the obvious property that if $Y_n\to_p 0$ and $|X_n|<Y_n$, then $X_n\to_p 0$ as well. Therefore $||\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)||_{P_{\theta_0}}\to_p 0$ as well. Let $\mathcal A_2$ be the set of all possible values that could be in $\mathcal A_{\bH_2}$ for some $\bH_2\in\mathcal H_2$. Note that, by (V4):
\begin{eqnarray*}
\lefteqn{\sqrt{\mathbb E_{\bH_2\sim P_{\theta_0},A_2\sim \mathcal U(\mathcal A_{\bH_2})}\left[\left(\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)\right)^2\right]}}&&\\
&=& \sqrt{\mathbb E_{\bH_2,A_2\sim P_{\theta_0}}\left[\frac{\mathcal U(\mathcal A_{\bH_2})}{\Pr(A_2|\bH_2)}\left(\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)\right)^2\right]}\\
&\leq& 1/\sqrt{|\mathcal A_2|\eps}\sqrt{\mathbb E_{\bH_2,A_2\sim P_{\theta_0}}\left[\left(\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)\right)^2\right]}.\\
\end{eqnarray*}
As $||\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)||_{P_{\theta_0}}\to_p 0$, $||\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)||_{P_{\theta_0}(\bH_2)\mathcal U(\mathcal A_{\bH_2})}\to_p 0$ as well. It is also easy to see that $\big|\big|\max_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|\big|\big|_{P_{\theta_0}}^2\leq |\mathcal A_2|\times||\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)||_{P_{\theta_0}(\bH_2)\mathcal U(\mathcal A_{\bH_2})}^2$, which means that $\big|\big|\max_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|\big|\big|_{P_{\theta_0}}\to_p 0$.  

Note that:
\begin{eqnarray*}
\lefteqn{\big|\big|\max_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|\big|\big|_{P_{\theta_0}}^2}&&\\
&=&\mathbb E\left[\max\nolimits_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|^2\right]\\
&=& \mathbb E\left[\mathbb E\left(\max\nolimits_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|^2\big |\bH_1,A_1\right)\right] \\
&\geq& \mathbb E\left[\mathbb E^2\left(\max\nolimits_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|\big |\bH_1,A_1\right)\right] \\
&=& \big|\big|\mathbb E\left(\max\nolimits_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|\big |\bH_1,A_1\right)\big|\big|_{P_{\theta_0}}^2 \\
&\geq& \big|\big|\mathbb E\left(\max\nolimits_{A_2}\widehat Q_{n,2}(\bH_2,A_2)-\max\nolimits_{A_2}Q_2(\bH_2,A_2)\big |\bH_1,A_1\right)\big|\big|_{P_{\theta_0}}^2.
\end{eqnarray*}
The first inequality comes from Jensen's inequality. As $\big|\big|\max_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|\big|\big|_{P_{\theta_0}}\to_p 0$, $\big|\big|\mathbb E\left[\max\nolimits_{A_2}\widehat Q_{n,2}(\bH_2,A_2)-\max\nolimits_{A_2}Q_2(\bH_2,A_2)|\big |\bH_1,A_1\right]\big|\big|_{P_{\theta_0}}\to_p 0$ as well. 

Note that, by Minkowski's inequality:
\begin{align*}
||\widehat Q_{n,1}-Q_1||_{P_{\theta_0}}=&||\widehat{\mathbb E}_n[\max_{A_2}\widehat Q_{n,2}(\bH_2,A_2)|\bH_1,A_1]-{\mathbb E}[\max_{A_2}Q_{2}(\bH_2,A_2)|\bH_1,A_1]||_{P_{\theta_0}}\\
\leq& ||\widehat{\mathbb E}_n[\max_{A_2}\widehat Q_{n,2}(\bH_2,A_2)|\bH_1,A_1]-{\mathbb E}[\max_{A_2}\widehat Q_{n,2}(\bH_2,A_2)|\bH_1,A_1]||_{P_{\theta_0}}\\
&+||{\mathbb E}[\max\nolimits_{A_2}\widehat Q_{n,2}(\bH_2,A_2)|\bH_1,A_1]-\mathbb E[\max\nolimits_{A_2}Q_{2}(\bH_2,A_2)|\bH_1,A_1]||_{P_{\theta_0}}.
\end{align*}
As $\big|\big|\mathbb E\left[\max\nolimits_{A_2}\widehat Q_{n,2}(\bH_2,A_2)-\max\nolimits_{A_2}Q_2(\bH_2,A_2)|\big |\bH_1,A_1\right]\big|\big|_{P_{\theta_0}}\to_p 0$, we have by (V3) and Slutsky's theorem that $||\widehat Q_{n,1}-Q_1||_{P_{\theta_0}}\to_p 0$. 

We have thus far proven or assumed the following:
\begin{align*}
&\big|\big|\widehat Q_{n,1}(\bH_1,A_1)-Q_1(\bH_1,A_1)\big|\big|_{P_{\theta_0}}\to_p 0,\\ &\big|\big|\widehat{\mathbb E}_{n}[\max_{A_2}\widehat Q_{n,2}(\bH_2,A_2)|\bH_1,A_1]-\mathbb  E[\max_{A_2}\widehat Q_{n,2}(\bH_2,A_2)|\bH_1,A_1]\big|\big|_{P_{\theta_0}}\to_p 0,\;\mbox{and}\\ 
&\bigg|\bigg|\mathbb E\left[\max_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|\big |\bH_1,A\right] \bigg|\bigg|_{P_{\theta_0}}\to_p 0.
\end{align*}

Therefore, as $\Pr(A_1|\bH_1)>\eps$ almost surely by (V4), it is easy to see that:
\begin{align}
&\big|\big|\max_{A_1}|\widehat Q_{n,1}(\bH_1,A_1)-Q_1(\bH_1,A_1)|\big|\big|_{P_{\theta_0}}\to_p 0, \\
&\bigg|\bigg|\max_{A_1}\big|\widehat{\mathbb E}_{n}[\max_{A_2}\widehat Q_{n,2}(\bH_2,A_2)|\bH_1,A_1]-\mathbb  E[\max_{A_2}\widehat Q_{n,2}(\bH_2,A_2)|\bH_1,A_1]\big| \bigg|\bigg|_{P_{\theta_0}}\to_p 0, \\
&\bigg|\bigg| \max_{A_1}\mathbb E\left[\max_{A_2}|\widehat Q_{n,2}(\bH_2,A_2)-Q_2(\bH_2,A_2)|\big | \bH_1,A_1\right]\bigg|\bigg|_{P_{\theta_0}}\to_p 0.  
\end{align}

Finally, note that:
\begin{eqnarray*}
\lefteqn{V(\pi^*)-V(\hat\pi_n)}&&\\ 
&=&\big|\big|\max_{A_1}Q_1(\bH_1,A_1)-\mathbb E[Q_2(\bH_2,\hat\pi_{n,2}(\bH_2))|\bH_1,\hat\pi_{n,1}(\bH_1)]\big|\big|_{P_{\theta_0}}\\
&=& \big|\big|\max_{A_1}Q_1(\bH_1,A_1)-\widehat Q_{n,1}(\bH_1,\pi^*_1(A_1))\\&&+\widehat Q_{n,1}(\bH_1,\pi^*_{1}(A_1))-\mathbb E[Q_2(\bH_2,\hat\pi_{n,2}(\bH_2))|\bH_1,\hat\pi_{n,1}(\bH_1)]\big|\big|_{P_{\theta_0}} \\
&\leq& \big|\big|\max_{A_1}Q_1(\bH_1,A_1)-\widehat Q_{n,1}(\bH_1,\pi^*_1(A_1)\\&&+\widehat Q_{n,1}(\bH_1,\hat \pi_{n,1}(A_1))-\mathbb E[Q_2(\bH_2,\hat\pi_{n,2}(\bH_2))|\bH_1,\hat\pi_{n,1}(\bH_1)]\big|\big|_{P_{\theta_0}} \\
&\leq& \big| \big |Q_1(\bH_1,\pi_1^*(A_1))-\widehat Q_{n,1}(\bH_1,\pi^*_1(A_1))\big|\big|_{P_{\theta_0}}\\&&+\big|\big|\widehat Q_{n,1}(\bH_1,\hat\pi_{n,1}(A_1))-\mathbb E[Q_2(\bH_2,\hat\pi_{n,2}(\bH_2))|\bH_1,\hat\pi_{n,1}(\bH_1)]\big|\big|_{P_{\theta_0}}\\
&\leq& \big|\big|Q_1(\bH_1,\pi_1^*(A_1))-\widehat Q_{n,1}(\bH_1,\pi^*_1(A_1))\big|\big|_{P_{\theta_0}}\\&&+\big|\big|\widehat{\mathbb E}_{n}[\widehat Q_2(\bH_2,\hat\pi_{n,2}(\bH_2))|\bH_1,\hat\pi_{n,1}(\bH_1)]-\mathbb  E[\widehat Q_2(\bH_2,\hat\pi_{n,2}(\bH_2))|\bH_1,\hat\pi_{n,1}(\bH_1)]\big|\big|_{P_{\theta_0}}\\&&+\big|\big|\mathbb  E[\widehat Q_2(\bH_2,\hat\pi_{n,2}(\bH_2))|\bH_1,\hat\pi_{n,1}(\bH_1)]-\mathbb E[Q_2(\bH_2,\hat\pi_{n,2}(\bH_2))|\bH_1,\hat\pi_{n,1}(\bH_1)]\big|\big|_{P_{\theta_0}}.
\end{eqnarray*}

The first inequality uses the fact that the term inside the $||\cdot||_{P_{\theta_0}}$ operator on the second line is equal to $\mathbb E_{\pi^*}[U|\bH_1]-\mathbb E_{\hat\pi_n}[U|\bH_1]$, which is always non-negative, and the fact that $\hat Q_{n,1}(\bH_1,\hat\pi_{n,1}(A_1))\geq \hat Q_{n,1}(\bH_1,\pi^*(\bH_1))$ by definition of $\hat\pi_n$. The second and third inequalities comes from Minkowski's inequality. Therefore, by equations (1), (2) and (3), and Slutsky's theorem, we can thus conclude that $V(\pi^*)-V(\hat\pi_n)\to_p 0$.
\end{proof}


\begin{theorem}
$\hat\theta_n\to_{p}\theta_0$ and $||\widehat{\mathbb E}_n[\bE|\bH_2]-\mathbb E[\bE|\bH_2]||_{P_{\theta_0}}\to_p 0$ provided with probability one that $\Pr_{\theta_0}(\bH_3|\bV)=\Pr(\bH_3|\bV)$ for some $\theta_0\in\Theta$, $\Pr_{\theta_0}(\bH_3)\neq \Pr_\theta(\bH_3)$ for all $\theta\neq\theta_0$ and $g(\bH_3)>c$ for some $c>0$. Moreover, $\sqrt{n}(\hat\theta-\theta_0)\to_d \mathcal N (0,I(\theta_0)^{-1})$ provided $I(\theta_0)$ is non-singular. 
\end{theorem}

\begin{proof}
To show that $\hat\theta_n\to_{p}\theta_0$, we require (C1) $\Pr(\bH_3|\bE)=p_{\theta_0}(\bH_3|\bE)$ for some $\theta_0\in\Theta$; (C2) $p_\theta(\bH_3|\bE)$ is continuous in $\theta$; (C3) $p_\theta(\bH_3|\bE)<F(\bH_3|\bE)$ for some $\mathbb E_{\theta_0}[F(\bH_3|\bE)]<\infty$; (C4) $|\log p_{\theta}(\bH_3)|\leq F(\bH_3)$ for some $\mathbb E_{\theta_0}[F(\bH_3)]<\infty$; (C5) $p_{\theta_0}(\bH_3)\neq M_\theta(\bH_3)$ for all $\theta\neq\theta_0$. (C1) and (C5) is assumed. It is easy to verify that $\Pr(\bW_1|\bV,\beta)$, $\Pr(\bW_1^{R}|\bV,\lambda)$, $\Pr(B_1|\bE^T\bX_2,\alpha)$, $\Pr(\bW_2|\bV,\beta)$, $\Pr(\bW_2^{R}|\bV,\lambda)$ and $\Pr(B_2|\bE^T\bY,\alpha)$ are all continuous wrt $\theta$. Let $f_\theta(\bH_3|\bE)$ be the product of these terms and note that $f_\theta(\bH_3)=\mathbb E_E[f_\theta(\bH_3|\bE)]$ and $p_\theta(\bH_3|\bE)=f_\theta(\bH_3|\bE)g(\bH_3)$ As the product of continuous functions is continuous, (C2) is therefore satisfied. Moreover, $(\bW_t,\bW_t^R,B_t)_{1\leq  t \leq 2}$ is categorical and it is easy to verify that $p_\theta(\bH_3|\bE)\leq 1$ always, which means (C3) is satisfied. 

Showing (C4) is a bit trickier.  Recall that we assume some large pre-specified $B<\infty$ such that $||\theta||_\infty\leq B$ and some small $\eps>0$ such that $\alpha_{1,t},\lambda_t,\alpha_{0,j+1,t}-\alpha_{0,j,t}\geq\eps$, for all $\theta\in\Theta$. Then it can be seen that for all $V\in\mathbb{R}^2$, $\min_{\theta,\bH_3\in\Theta\times\mathcal H_3}\Pr(W_{tk}|\bV,\theta)\geq 1-\sigma(B+B|\bV|)=\sigma\left[-B(|\bV|+1)\right],\forall (t,k)\in\{1,2\}\times\{1,...,12\}$, $\min_{\theta,\bH_3\in\Theta\times\mathcal H_3}\Pr(\bW_t^R|\bE^R,\theta)\geq \exp(-3B)/6\equiv B_\lambda>0$ and $\min_{\theta,\bH_3\in\Theta\times\mathcal H_3}\Pr(B_t|\bE^T\bX_{t+1})\geq \min(1-\sigma(B),\sigma(\eps-10B),\sigma(B)-\sigma(B-\eps))\equiv B_\alpha>0$. Recall we also assume $\min_{\bH_3\in\mathcal H_3}g(\bH_3)>B_X$ for some small $B_X>0$. Therefore, $1\geq \log p_\theta(\bH_3) \geq \log B_\lambda^2B_\alpha^2\int_{\mathbb{R}^2}\left[\sigma\left(-B(|\bV|+1)\right)\right]^{24}d\bV+\log B_X$.

Let $C=\int_{\mathbb{R}^2}\left[\sigma\left(-B(|\bV|+1)\right)\right]^{24}d\bV<\infty$. By the triangle inequality, we can conclude that for all $\bH_3,\Theta\in\Theta\times \mathcal H_3$, $|\log p_\theta(\bH_3)|<|\log B_\lambda^2B_\alpha^2C|+|\log B_X|<\infty$. Thus by choosing $F(\bH_3)=|\log B_\lambda^2B_\alpha^2C|+|\log B_X|$, assumption (C4) is satisfied. 


We also wish to show $||\widehat{\mathbb E}_n[\bE|\bH_2]-\mathbb E[\bE|\bH_2]||_{P_{\theta_0}}\to 0$. Let $\bH_{3,D}=(\bW_1,\bW_2,\bW_1^R,\bW_2^R,B_1,B_R)$ be the components of $\bH_3$ dependent on $\bE$ and $\bH_{3,I}=(\bX_1,\bX_2,A_1,A_2,\bY)$ be the components conditionally independent of $\bE$. Note that $\bH_3=\bH_{3,D}\cup \bH_{3,I}$, $f_\theta(\bH_3|\bE)$ is a function of only $\bE$ and $\bH_{3,D}$. Note that $\widehat{\mathbb E}_n[\bE|\bH_2]=\mathbb E_{\hat\theta_n}[\bE|\bH_2]$ where $\mathbb E_{\theta}[\bE|\bH_2]=\frac{\int_{\mathcal E}\bE p_{\theta}(\bH_2|\bE)\Pr(\bE)d\bE}{\int_{\mathcal E}p_{\theta}(\bH_2)\Pr(\bE)d\bE}=\frac{\int_{\mathcal E}\bE f_{\theta}(\bH_2|\bE)\Pr(\bE)d\bE}{\int_{\mathcal E}f_{\theta}(\bH_2|\bE)\Pr(\bE)d\bE}$, $f_{\theta}(\bH_2|\bE)=\sum_{\bH_{3,D}\in\mathcal H_{3,D}(\bH_{2,D})}f_\theta(\bH_3|\bE)$, $\mathcal H_{3,D}(\bh_{2,D})$ is the set of $\bH_{3,D}$ where $\bH_{2,D}=\bh_{2,D}$ and does not depend on $\theta$, and $\bH_{2,D}=(\bW_1,\bW_2,\bW_1^R,\bW_2^R,B_1)$. This is a finite sum, and each element $f_\theta(\bH_3|\bE)$ of this sum is continuous in $\theta$. Therefore, $f_{\theta}(\bH_2|\bE)$ is continuous in $\theta$. As $f_\theta(\bH_2|\bE)<1$, we have that both the numerator and denominator is continuous in $\theta$ by the dominated convergence theorem. Then by the continuous mapping theorem, $\mathbb E_{\hat\theta_n}[\bE|\bH_2]\to_p \mathbb E_{\theta}[\bE|\bH_2]$, point-wise for almost every $\bE,\bH_2\in\mathcal E\times\mathcal H_2$. Note that $||\widehat{\mathbb E}_n[\bE|\bH_2]-\mathbb E[\bE|\bH_2]||_{P_{\theta_0}}^2=\sum_{\bH_2\in\mathcal H_{2,D}}\left[\left(\mathbb E_{\hat\theta_n}[\bE|\bH_{2,D}]-\mathbb E[\bE|\bH_{2,D}]\right)^2\right]$ is a finite sum of terms. Thus applying the continuous mapping theorem and Slutsky's theorem, we obtain our desired result. 

To show that $\sqrt{n}(\hat\theta-\theta_0)\to_d \mathcal N (0,I(\theta_0)^{-1})$, we require for all $\theta,\theta_1,\theta_2\in\mathcal N_\eps(\theta_0)$ and with probability one (N1) $I(\theta_0)$ is non-singular; (N2) $|p_{\theta_1}(\bH_3|\bE)-p_{\theta_2}(\bH_3|\bE)|\leq F(\bH_3|\bE)||\theta_1-\theta_2|$ for some $\mathbb E_{\theta_0,\bE}[F^2(\bH_3|\bE)]<\infty$; (N3) $p_\theta(\bH_3)>c$ for some $c>0$; (N4) $p_{\theta}(\bH_3|\bE)$ is continuously differentiable; (N5) $||\nabla_\theta p_{\theta}(\bH_3|\bE)||_\infty<G(\bH_3|\bE)$ for some $\mathbb E_{\theta_0,\bE}[G^2(\bH_3|\bE)]<\infty$. (N1) is satisfied by assumption, and (N3) was demonstrated previously. 

To prove the remaining conditions, we need to derive the gradient of the log-likelihood. Using elementary probability, calculus and linear algebra, we can derive the relevant marginal probabilities and their partial derivatives in closed-form:
\small
\begin{align*}
\Pr(W_{1,k}|\bV,\beta)=&\sigma(\beta_{0,k,1}+\beta_{1,k,1}^T\bV)^{W_{1k}}(1-\sigma(\beta_{0,k,1}+\beta_{1,k,1}^T\bV))^{1-W_{1k}},\\
\nabla_{\beta_{1,k,1}}\Pr(W_{1,k}|\bV,\beta)=& (2W_{1k}-1)\sigma'(\beta_{0,k,1}+\beta_{1,k,1}^T\bV)V,\\
\Pr(\bW_1^R|\bV,\lambda)=&\frac{\exp(-\lambda_1 T(\bW_1^R,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_1 T(\bv,\bE^R))},\\
\nabla_{\lambda_1}\Pr(\bW_1^R|\bV,\lambda)=& \frac{\left[\sum_{\bv\in\mathcal P}\exp(-\lambda_1 T(\bv,\bE^R))(T(\bv,\bE^R)-T(\bW_1^R,\bE^R)\right]}{\left(\sum_{\bv\in\mathcal P}\exp(-\lambda_1 T(\bv,\bE^R))\right)^2}\exp(-\lambda_1 T(\bW_1^R,\bE^R)), \\
\Pr(B_1)=&\sigma(\alpha_{0,B_1,1}-\alpha_{1,1}\bE^T\bX_2)^{1-I(B_1=7)}-I(B_1\neq 1)\sigma(\alpha_{0,B_1-1,1}-\alpha_{1,1}\bE^T\bX_2), \\
\nabla_{\alpha_{1,1}}\Pr(B_1)=& -\left[I(B_1\neq 7)\sigma'(\alpha_{0,B_1,1}-\alpha_{1,1}\bE^T\bX_2)+I(B_1\neq 1)\sigma'(\alpha_{0,B_1-1,1}-\alpha_{1,1}\bE^T\bX_2)\right](\bE^T\bX_2).
\end{align*}
\normalsize
Other partial derivatives can be derived similarly:
\begin{align*}
\nabla_{\beta_{0,k,1}}\Pr(W_{1,k}|\bV,\beta)=&(2W_{1k}-1)\sigma'(\beta_{0,k,1}+\beta^T_{1,k,1}\bV),\\
\nabla_{\beta_{1,k,2}}\Pr(W_{2,k}|\bV,\beta)=&(2W_{2k}-1)\sigma'(\beta_{0,k,2}+\beta_{1,k,2}^T\bV)V, \\
\nabla_{\beta_{0,k,2}}\Pr(W_{2,k}|\bV,\beta)=&(2W_{2k}-1)\sigma'(\beta_{0,k,2}+\beta_{1,k,2}^T\bV), \\
\nabla_{\lambda_2}\Pr(\bW_2^R|\bV,\lambda)=& \frac{\left[\sum_{\bv\in\mathcal P}\exp(-\lambda_2 T(\bv,\bE^R))(T(\bv,\bE^R)-T(\bW_2^R,\bE^R)\right]}{\left(\sum_{\bv\in\mathcal P}\exp(-\lambda_2 T(\bv,\bE^R))\right)^2}\exp(-\lambda_1 T(\bW_2^R,\bE^R)), \\
\nabla_{\alpha_{0,k,1}}\Pr(B_1)=& I(B_1=k)\sigma'(\alpha_{0,k,1}-\alpha_{1,1}\bE^T\bX_2)-I(B_1=k-1)\sigma'(\alpha_{0,k,1}-\alpha_{1,1}\bE^T\bX_2),\\
=& \left[1_{k}(B_1)-1_{k-1}(B_1)\right]\sigma'(\alpha_{0,k,1}-\alpha_{1,1}\bE^T\bX_2), \\
\nabla_{\alpha_{1,2}}\Pr(B_2)=&  -\left[I(B_2\neq 7)\sigma'(\alpha_{0,B_2,1}-\alpha_{1,1}\bE^T\bY)+I(B_2\neq 1)\sigma'(\alpha_{0,B_2-1,1}-\alpha_{1,1}\bE^T\bY)\right](\bE^T\bY), \\
\nabla_{\alpha_{0,k,2}}\Pr(B_2)=& \left[1_{k}(B_2)-1_{k-1}(B_2)\right]\sigma'(\alpha_{0,k,1}-\alpha_{1,1}\bE^T\bY). \\
\end{align*}

Let $\beta_{\cdot,k,t}=(\beta_{0,k,t},\beta_{1,k,t}^T)^T$, $\bV^*=(1,\bV^T)^T$, $\bW_t^{(-k)}=(\bW_{t,1},...,\bW_{t,k-1},\bW_{t,k+1},...,\bW_{t,12})^T$. Note that $3-t=2$ if $t=1$ and $3-t=1$ if $t=2$ (i.e. $3-t$ is the temporal inverse). We now have:
\small
\begin{adjustwidth}{0cm}{0pt}
\begin{align*}
f_\theta(\bH_3|\bV)=& \Pr_\theta(\bW_1|\bV)\Pr_\theta(\bW_2|\bV)\Pr_\theta(\bW_1^R|\bV)\Pr(\bW_2^R|\bV)\Pr_\theta(B_1|\bE^T\bX_2)\Pr_\theta(B_2|\bE^T\bY), \\
\nabla_{\beta_{\cdot,k,t}}f_\theta(\bH_3|\bV)=& \Pr_\theta(\bW_1^{R}|\bV)\Pr_\theta(B_1|\bE^T\bX_2)\Pr_\theta(\bW_2^{R}|\bV)\Pr_\theta(B_2|\bE^T\bY)\\ &\times\Pr_\theta(\bW_{3-t}|\bV)\Pr_\theta(\bW_t^{(-k)}|\bV)(2W_{t,k}-1)\sigma'(\beta_{0,k,\cdot}^T\bV^*)\bV^*,  \\
\nabla_{\lambda_t}f_\theta(\bH_3|\bV)=& \Pr_\theta(\bW_1|\bV)\Pr_\theta(B_1|\bE^T\bX_2)\Pr_\theta(\bW_2|\bV)\Pr_\theta(B_2|\bE^T\bY)\Pr_\theta(\bW_{3-t}^{R}|\bV)\\ &\times\exp(-\lambda_t T(\bW_t^R,\bE^R))\frac{\left[\sum_{\bv\in\mathcal P}\exp(-\lambda_t T(\bv,\bE^R))(T(\bv,\bE^R)-T(\bW_t^R,\bE^R)\right]}{\left(\sum_{\bv\in\mathcal P}\exp(-\lambda_t T(\bv,\bE^R))\right)^2},\\
\nabla_{\alpha_{0,k,t}}f_\theta(\bH_3|\bV)=& \Pr_\theta(\bW_1|\bV)\Pr_\theta(\bW_1^{R}|\bV)\Pr_\theta(\bW_2|\bV)\Pr_\theta(\bW_2^{R}|\bV)\Pr_\theta(B_{3-t}|\bE^T\bX_2)\left(1_{k}(B_t)-1_{k-1}(B_t)\right)\\&\times\sigma'(\alpha_{0,k,t}-\alpha_{1,t}\bE^T\bX_{t+1}),  \\
\nabla_{\alpha_{1,t}}f_\theta(\bH_3|\bV)=&\Pr_\theta(\bW_1|\bV)\Pr_\theta(\bW_1^{R}|\bV)\Pr_\theta(\bW_2|\bV)\Pr_\theta(\bW_2^{R}|\bV)\Pr_\theta(B_{3-t}|\bE^T\bX_2)\\&\times\left[I(B_t\neq 7)\sigma'(\alpha_{0,B_t,1}-\alpha_{1,1}\bE^T\bY)-I(B_t\neq 1)\sigma'(\alpha_{0,B_t-1,1}-\alpha_{1,1}\bE^T\bY)\right](\bE^T\bY).
\end{align*}
\end{adjustwidth}
\normalsize

We can see that $\nabla_\theta f_\theta(\bH_3|\bV)$ is continuous in $\theta$, and thus so is $\nabla_\theta p_\theta(\bH_3|\bV)=g(\bH_3)\nabla_\theta f_\theta(\bH_3|\bV)$. Thus (N4) is satisfied. 

We can also derive an upper bound for $||\nabla_\theta f_\theta(\bH_3|\bV)||_\infty$.  As $|\Pr(\bW_t^R|\theta)|$,
$\Pr(B_t|\theta)|$, and $|\Pr(\bW_t|\theta)\leq 1
|$, $\forall \theta\in\Theta$ and $|\sigma'(x)|\leq 1$, $\forall x\in\mathbb{R}$, we have that $|\nabla_{\beta_{\cdot,k,t}} f_\theta(\bH_3|\bV)|\leq |\bV^*|$. As $|\exp(-\lambda_t T(\bW_t^R,\bE^R)|<1$ and $|T(\bv,\bE^R)|$, and $|T(\bW_t^R,\bE^R)|\leq 3$ for $v\in\mathcal P$, $\exp(-\lambda_t T(\bv,\bE^R)=1$ for some $v\in\mathcal P$ and $|\mathcal P|=6$,  we have that $|\nabla_{\lambda_t} f_\theta(\bH_3|\bV)|\leq 18$. As $|\bE^TX|<10$, $|\nabla_{\alpha_{0,k,t}} f_\theta(\bH_3|\bV)|\leq 1$ and $|\nabla_{\alpha_{1,t}} f_\theta(\bH_3|\bV)|\leq 20$, we 
then have that $||\nabla_\theta f_\theta(\bH_3|\bV)||_\infty \leq \max(|\bV^*|, 20)$. Thus (N5) is satisfied, and by the Leibniz integral rule,
$\nabla_\theta\log p_\theta(\bH_3)=\nabla_\theta\left[\log\int_{\mathbb{R}^2}f_\theta(\bH_3|\bV)\Pr(\bV)d\bV+\log g(\bH_3)\right]=(f_\theta(\bH_3))^{-1}\int_{\mathbb{R}^2}\nabla_\theta f_\theta(\bH_3|\bV)d\bV$.

It remains to show (N2). By the mean value theorem, an everywhere-differentiable function $f:\mathcal X\to\mathbb{R}$ with bounded first derivatives will be Lipschitz continuous over $\mathcal X$  with Lipschitz constant $L$ upper-bounded as $\sup_{x\in\mathcal X} |f'(x)|$ \citep{Shwartz2014}. Then $\Pr(W_{1,k}|\bV,\theta)=W_{tk}\sigma(\beta_{0,k,t}+\beta_{1,k,t}^{T}\bV)+(1-W_{tk})(1-\sigma(\beta_{0,k,t}+\beta_{1,k,t}^{T}\bV))$ and:
\small
\begin{align*}
|\Pr(W_{t,k}|\bV,\theta^{(1)})-\Pr(W_{t,k}|\bV,\theta^{(2)})|\leq& W_{tk}\left|\sigma(\beta_{\cdot,k,t}^{(1)T}\bV^*)-\sigma(\beta_{\cdot,k,t}^{(2)T}\bV^*)\right|\\ &+(1-W_{tk})\left|\sigma(\beta_{\cdot,k,t}^{(2)T}\bV^*)-\sigma(\beta_{\cdot,k,t}^{(1)T}\bV^*)\right|\\
\leq& W_{tk}|\beta_{\cdot,k,t}^{(1)T}\bV^*-\beta_{\cdot,k,t}^{(2)T}\bV^*|+(1-W_{tk})|\beta_{\cdot,k,t}^{(2)T}\bV^*-\beta_{\cdot,k,t}^{(1)T}\bV^*| \\
=& |(\beta_{\cdot,k,t}^{(2)}-\beta_{\cdot,k,t}^{(1)})^T\bV^*|\\
\leq& ||\bV^*||_2||\beta_{\cdot,k,t}^{(2)}-\beta_{\cdot,k,t}^{(1)}||_2 \leq ||\bV^*||_2 ||\theta^{(2)}-\theta^{(1)}||_2.
\end{align*}
\normalsize
The first inequality comes from the triangle inequality. The second equality comes from the fact that the sigmoid function is everywhere-differentiable and $|\sigma'(x)|\leq 1,\forall x\in\mathbb{R}$, making it Lipschitz with constant $L=1$. The third inequality comes from the Cauchy-Schwartz inequality. 

Moreover:
\small
\begin{align*}
\Pr(B_t|\bE^T\bX_{t+1},\theta)=&I(B_t=7)+I(B_t\neq 7)\sigma(\alpha_{0,B_t,1}-\alpha_{1,t}\bE^T\bX_{t+1})-I(B_t\neq 1)\sigma(\alpha_{0,B_t-1,1}-\alpha_{1,t}\bE^T\bX_{t+1}), \\
|\Pr(B_t|\bE^T\bX_{t+1},\theta^{(1)})&-\Pr(B_t|\bE^T\bX_{t+1},\theta^{(2)})|\\\leq& I(B_t\neq 7)\left|\sigma(\alpha_{0,B_t,t}^{(1)}-\alpha_{1,t}^{(1)}\bE^T\bX_{t+1})-\sigma(\alpha_{0,B_t,t}^{(2)}-\alpha_{1,t}^{(2)}\bE^T\bX_{t+1})\right|\\&+I(B_t\neq 1)\left|\sigma(\alpha_{0,B_t-1,t}^{(1)}-\alpha_{1,t}^{(1)}\bE^T\bX_{t+1})-\sigma(\alpha_{0,B_t-1,t}^{(2)}-\alpha_{1,t}^{(2)}\bE^T\bX_{t+1})\right| \\
\leq&|(\alpha_{0,B_t,t}^{(1)}-\alpha_{0,B_t,t}^{(2)})+(\alpha_{1,t}^{(2)}-\alpha_{1,t}^{(1)})\bE^T\bX_{t+1}|\\&+|(\alpha_{0,B_t-1,t}^{(1)}-\alpha_{0,B_t-1,t}^{(2)})+(\alpha_{1,t}^{(2)}-\alpha_{1,t}^{(1)})\bE^T\bX_{t+1}| \\
\leq& |\alpha_{0,B_t,t}^{(1)}-\alpha_{0,B_t,t}^{(2)}|+|\alpha_{1,t}^{(1)}-\alpha_{1,t}^{(2)}|\bE^T\bX_{t+1}+|\alpha_{0,B_t-1,t}^{(1)}-\alpha_{0,B_t-1,t}^{(2)}|+|\alpha_{1,t}^{(1)}-\alpha_{1,t}^{(2)}|\bE^T\bX_{t+1} \\
\leq& 2||\alpha_{0,\cdot,t}^{(1)}-\alpha_{0,\cdot,t}^{(2)}||_2+20|\alpha_{1,t}^{(1)}-\alpha_{1,t}^{(2)}|\\
\leq& 22||\theta^{(2)}-\theta^{(1)}||_2.
\end{align*}
\normalsize
The first inequality uses the triangle inequality for absolute values. The second inequality uses the fact that the sigmoid has Lipschitz constant $L=1$. The third inequality uses the triangle inequality again. The fourth inequality uses the fact that $|\bE^T\bX_{t+1}|\leq 10,t\in\{1,2\}$. 

Note that $f:[0,\infty)\to[0,1]$ defined by $f(x)=\exp(-x)$ is Lipschitz with constant $L=\sup_{x\in[0,\infty)}\{f'(x)\}\leq 1$. Moreover, note that the tuple $\mathcal T=(T(\bv,\bE^R):v\in\mathcal P)=(0,1,1,2,2,3)$ is equivalent for all $E^R\in\mathcal P$. Finally, note that \\ $|\exp(-\lambda_t T(\bW_1^R,\bE^R))|, |[\sum_{\bv\in \mathcal P}\exp(-\lambda_t T(\bv,\bE^R))]^{-1}|\leq 1$,  $T(x,y)\in\{0,1,2,3\}$, and \\ $\text{length}(\mathcal T)=6$. Putting this all together we have:
\begin{align*}
\nabla_{\lambda_t}\left({\sum_{\bv\in\mathcal P}\exp(-\lambda_tT(\bv,\bE^R))}\right)^{-1}= \frac{{\sum_{T\in \mathcal T}\exp(-\lambda_tT)T}}{\left(\sum_{T\in\mathcal T}\exp(-\lambda_t T)\right)^2}\leq 18
\end{align*}

Thus $f:[0,\infty)\to\mathbb{R}$ defined as $f(x)=1/\sum_{T\in\mathcal T}\exp(-xT)$ is Lipschitz with constant $L\leq 18$. Then:
\begin{align*}
\Pr(\bW_t^R|\bV,\lambda_t)=&\frac{\exp(-\lambda_t T(\bW_t^R,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_t T(\bv,\bE^R))}\;\mbox{and}\\
|\Pr(\bW_t^R|\bV,\lambda_t^{(2)})-\Pr(\bW_t^R|\bV,\lambda_t^{(1)})|=& \left|\frac{\exp(-\lambda_t^{(2)} T(\bW_t^R,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_t^{(2)} T(\bv,\bE^R))}-\frac{\exp(-\lambda_t^{(1)} T(\bW_t^R,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_t^{(1)} T(\bv,\bE^R))}\right|\\
\leq& \left|\frac{\exp(-\lambda_t^{(2)} T(\bW_t^R,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_t^{(2)} T(\bv,\bE^R))}-\frac{\exp(-\lambda_t^{(1)} T(\bW_t^R,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_t^{(2)} T(\bv,\bE^R))}\right|\\&+
\left|\frac{\exp(-\lambda_t^{()} T(\bW_t^R,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_t^{(2)} T(\bv,\bE^R))}-\frac{\exp(-\lambda_t^{(1)} T(\bW_t^R,\bE^R))}{\sum_{\bv\in\mathcal P}\exp(-\lambda_t^{(1)} T(\bv,\bE^R))}\right| \\
\leq& \frac{}{}\left|\exp(-\lambda_t^{(2)} T(\bW_t^R,\bE^R))-\exp(-\lambda_t^{(1)} T(\bW_t^R,\bE^R))\right|\\&+
\left|\frac{1}{\sum_{\bv\in\mathcal P}\exp(-\lambda_t^{(2)} T(\bv,\bE^R))}-\frac{1}{\sum_{\bv\in\mathcal P}\exp(-\lambda_t^{(1)} T(\bv,\bE^R))}\right| \\
\leq& |\lambda_t^{(2)}T(\bW_t^R,\bE^R)-\lambda_t^{(1)}T(\bW_t^R,\bE^R)|+18|\lambda_t^{(2)}-\lambda_t^{(1)}|\\
\leq& 21 |\lambda_t^{(2)}-\lambda_t^{(1)}| \\
\leq& 21 ||\theta^{(2)}-\theta^{(1)}||.
\end{align*}
As the product of Lipschitz continuous functions is also Lipschitz continuous with the Lipschitz constant being the sum of those of the functions being multiplied \citep{Shwartz2014}, $f_\theta(\bH_3|\bV)$ is Lipschitz continuous in $\theta\in\Theta$ with constant $L\leq 24||\bV^*||_2+43$, and thus so is $p_\theta(\bH_3|\bV)$. Thus condition (N2) is satisfied, concluding the proof. 
\end{proof}

\newpage
\section{Supplementary Tables and Figures}
\label{append:figures}

\sidecaptionvpos{figure}{c}
\begin{SCfigure}[][h]
\centering
% Figure removed
\caption{Model-fitting time per sample size. Shown is the mean across seeds with standard error bars for each sample size. Optimizations were performed with a single Tesla V100-SXM2 GPU, five 2.40 GHz Intel CPU cores and 10GM of RAM.}
\label{figure:comp}
\vspace{-0.4cm}
\end{SCfigure}

\end{document}