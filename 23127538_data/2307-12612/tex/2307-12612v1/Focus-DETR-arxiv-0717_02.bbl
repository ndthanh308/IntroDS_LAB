\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{DETR}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em European Conference of Computer Vision}, 2020.

\bibitem{group_DETR}
Qiang Chen, Xiaokang Chen, Gang Zeng, and Jingdong Wang.
\newblock Group {DETR:} fast training convergence with decoupled one-to-many
  label assignment.
\newblock {\em CoRR}, abs/2207.13085, 2022.

\bibitem{conditional_DETR_v2}
Xiaokang Chen, Fangyun Wei, Gang Zeng, and Jingdong Wang.
\newblock Conditional {DETR} {V2:} efficient detection transformer with box
  queries.
\newblock {\em CoRR}, abs/2207.08914, 2022.

\bibitem{DynamicDETR}
Xiyang Dai, Yinpeng Chen, Jianwei Yang, Pengchuan Zhang, Lu Yuan, and Lei
  Zhang.
\newblock Dynamic detr: End-to-end object detection with dynamic attention.
\newblock In {\em International Conference on Computer Vision}, pages
  2968--2977, 2021.

\bibitem{upDETR}
Zhigang Dai, Bolun Cai, Yugeng Lin, and Junying Chen.
\newblock Up-detr: Unsupervised pre-training for object detection with
  transformers.
\newblock In {\em Computer Vision and Pattern Recognition}, pages 1601--1610,
  2021.

\bibitem{ImageNet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em Computer Vision and Pattern Recognition}, pages 248--255,
  2009.

\bibitem{Vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em AAAI Conference on Artificial Intelligence}. OpenReview.net,
  2021.

\bibitem{YOLOS}
Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu,
  Jianwei Niu, and Wenyu Liu.
\newblock You only look at one sequence: Rethinking transformer in vision
  through object detection.
\newblock {\em arXiv preprint arXiv:2106.00666}, 2021.

\bibitem{SMCA-R}
Peng Gao, Minghang Zheng, Xiaogang Wang, Jifeng Dai, and Hongsheng Li.
\newblock Fast convergence of detr with spatially modulated co-attention.
\newblock In {\em International Conference on Computer Vision}, pages
  3601--3610, 2021.

\bibitem{ResNet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Computer Vision and Pattern Recognition}, pages 770--778,
  2016.

\bibitem{LearnedToken}
Sehoon Kim, Sheng Shen, David Thorsley, Amir Gholami, Woosuk Kwon, Joseph
  Hassoun, and Kurt Keutzer.
\newblock Learned token pruning for transformers.
\newblock In Aidong Zhang and Huzefa Rangwala, editors, {\em Knowledge
  Discovery and Data Mining}, pages 784--794. {ACM}, 2022.

\bibitem{Adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em International
  Conference on Learning Representations}, 2015.

\bibitem{SPViT}
Zhenglun Kong, Peiyan Dong, Xiaolong Ma, Xin Meng, Wei Niu, Mengshu Sun, Bin
  Ren, Minghai Qin, Hao Tang, and Yanzhi Wang.
\newblock Spvit: Enabling faster vision transformers via soft token pruning.
\newblock {\em ArXiv}, abs/2112.13890, 2021.

\bibitem{DN_DETR}
Feng Li, Hao Zhang, Shilong Liu, Jian Guo, Lionel~M Ni, and Lei Zhang.
\newblock Dn-detr: Accelerate detr training by introducing query denoising.
\newblock In {\em Computer Vision and Pattern Recognition}, 2022.

\bibitem{VITDET}
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
\newblock Exploring plain vision transformer backbones for object detection.
\newblock {\em arXiv preprint arXiv:2203.16527}, 2022.

\bibitem{COCO}
Tsung{-}Yi Lin, Michael Maire, Serge~J. Belongie, James Hays, Pietro Perona,
  Deva Ramanan, Piotr Doll{\'{a}}r, and C.~Lawrence Zitnick.
\newblock Microsoft {COCO:} common objects in context.
\newblock In David~J. Fleet, Tom{\'{a}}s Pajdla, Bernt Schiele, and Tinne
  Tuytelaars, editors, {\em European Conference of Computer Vision}, volume
  8693 of {\em Lecture Notes in Computer Science}, pages 740--755. Springer,
  2014.

\bibitem{FocalLoss}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll√°r.
\newblock Focal loss for dense object detection.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  42(2):318--327, 2020.

\bibitem{DAB_DETR}
Shilong Liu, Feng Li, Hao Zhang, Xiao Yang, Xianbiao Qi, Hang Su, Jun Zhu, and
  Lei Zhang.
\newblock {DAB}-{DETR}: Dynamic anchor boxes are better queries for {DETR}.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{AdaptiveSparseViT}
Xiangcheng Liu, Tianyi Wu, and Guodong Guo.
\newblock Adaptive sparse vit: Towards learnable adaptive token pruning by
  fully exploiting self-attention.
\newblock {\em CoRR}, abs/2209.13802, 2022.

\bibitem{SwinTransformer}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em International Conference on Computer Vision (ICCV)}, 2021.

\bibitem{conditional_DETR}
Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei
  Sun, and Jingdong Wang.
\newblock Conditional detr for fast training convergence.
\newblock In {\em International Conference on Computer Vision (ICCV)}, 2021.

\bibitem{IA-RED}
Bowen Pan, Yifan Jiang, Rameswar Panda, Zhangyang Wang, Rog{\'{e}}rio Feris,
  and Aude Oliva.
\newblock Ia-red\({}^{\mbox{2}}\): Interpretability-aware redundancy reduction
  for vision transformers.
\newblock {\em CoRR}, abs/2106.12620, 2021.

\bibitem{DynamicViT}
Yongming Rao, Wenliang Zhao, Benlin Liu, Jiwen Lu, Jie Zhou, and Cho-Jui Hsieh.
\newblock Dynamicvit: Efficient vision transformers with dynamic token
  sparsification.
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{Faster_RCNN}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett,
  editors, {\em Advances in Neural Information Processing Systems}, volume~28.
  Curran Associates, Inc., 2015.

\bibitem{ren2023detrex}
Tianhe Ren, Shilong Liu, Feng Li, Hao Zhang, Ailing Zeng, Jie Yang, Xingyu
  Liao, Ding Jia, Hongyang Li, He Cao, Jianan Wang, Zhaoyang Zeng, Xianbiao Qi,
  Yuhui Yuan, Jianwei Yang, and Lei Zhang.
\newblock detrex: Benchmarking detection transformers, 2023.

\bibitem{sparse_DETR}
Byungseok Roh, JaeWoong Shin, Wuhyun Shin, and Saehoon Kim.
\newblock Sparse {DETR}: Efficient end-to-end object detection with learnable
  sparsity.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{TSP-RCNN-R}
Zhiqing Sun, Shengcao Cao, Yiming Yang, and Kris Kitani.
\newblock Rethinking transformer-based set prediction for object detection.
\newblock In {\em International Conference on Computer Vision}, pages
  3591--3600, 2021.

\bibitem{PatchSlimming}
Yehui Tang, Kai Han, Yunhe Wang, Chang Xu, Jianyuan Guo, Chao Xu, and Dacheng
  Tao.
\newblock Patch slimming for efficient vision transformers.
\newblock In {\em Computer Vision and Pattern Recognition (CVPR)}, pages
  12155--12164, 2022.

\bibitem{pnp_DETR}
Tao Wang, Li Yuan, Yunpeng Chen, Jiashi Feng, and Shuicheng Yan.
\newblock Pnp-detr: Towards efficient visual analysis with transformers.
\newblock In {\em International Conference on Computer Vision}, 2021.

\bibitem{anchor_DETR}
Yingming Wang, Xiangyu Zhang, Tong Yang, and Jian Sun.
\newblock Anchor detr: Query design for transformer-based detector.
\newblock In {\em AAAI Conference on Artificial Intelligence}, 2022.

\bibitem{Evo-vit}
Yifan Xu, Zhijie Zhang, Mengdan Zhang, Kekai Sheng, Ke Li, Weiming Dong, Liqing
  Zhang, Changsheng Xu, and Xing Sun.
\newblock Evo-vit: Slow-fast token evolution for dynamic vision transformer.
\newblock In {\em AAAI Conference on Artificial Intelligence}, volume~36, pages
  2964--2972, 2022.

\bibitem{efficient_DETR}
Zhuyu Yao, Jiangbo Ai, Boxun Li, and Chi Zhang.
\newblock Efficient {DETR:} improving end-to-end object detector with dense
  prior.
\newblock {\em CoRR}, abs/2104.01318, 2021.

\bibitem{AViT}
Hongxu Yin, Arash Vahdat, Jose~M. Alvarez, Arun Mallya, Jan Kautz, and Pavlo
  Molchanov.
\newblock A-vit: Adaptive tokens for efficient vision transformer.
\newblock In {\em Computer Vision and Pattern Recognition (CVPR)}, pages
  10799--10808, 2022.

\bibitem{IFMA}
Gongjie Zhang, Zhipeng Luo, Zichen Tian, Jingyi Zhang, Xiaoqin Zhang, and
  Shijian Lu.
\newblock Towards efficient use of multi-scale features in transformer-based
  object detectors.
\newblock In {\em CVPR}, 2023.

\bibitem{SAMDETR}
Gongjie Zhang, Zhipeng Luo, Yingchen Yu, Kaiwen Cui, and Shijian Lu.
\newblock Accelerating detr convergence via semantic-aligned matching.
\newblock In {\em Computer Vision and Pattern Recognition (CVPR)}, pages
  939--948, 2022.

\bibitem{DINO}
Hao Zhang, Feng Li, Shilong Liu, Lei Zhang, Hang Su, Jun Zhu, Lionel~M. Ni, and
  Heung-Yeung Shum.
\newblock Dino: Detr with improved denoising anchor boxes for end-to-end object
  detection, 2022.

\bibitem{Deformable_DETR}
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
\newblock Deformable detr: Deformable transformers for end-to-end object
  detection.
\newblock In {\em International Conference on Learning Representations}, 2021.

\end{thebibliography}
