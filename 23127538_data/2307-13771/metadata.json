{
  "title": "Accuracy Improvement in Differentially Private Logistic Regression: A Pre-training Approach",
  "authors": [
    "Mohammad Hoseinpour",
    "Milad Hoseinpour",
    "Ali Aghagolzadeh"
  ],
  "submission_date": "2023-07-25T19:07:03+00:00",
  "revised_dates": [],
  "abstract": "Machine learning (ML) models can memorize training datasets. As a result, training ML models over private datasets can lead to the violation of individuals' privacy. Differential privacy (DP) is a rigorous privacy notion to preserve the privacy of underlying training datasets. Yet, training ML models in a DP framework usually degrades the accuracy of ML models. This paper aims to boost the accuracy of a DP logistic regression (LR) via a pre-training module. In more detail, we initially pre-train our LR model on a public training dataset that there is no privacy concern about it. Then, we fine-tune our DP-LR model with the private dataset. In the numerical results, we show that adding a pre-training module significantly improves the accuracy of the DP-LR model.",
  "categories": [
    "cs.LG",
    "cs.CR"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13771",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 0,
  "size_after_bytes": 0
}