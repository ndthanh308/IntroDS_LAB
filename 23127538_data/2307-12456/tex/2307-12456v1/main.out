\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Preliminaries}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Bayesian Learning}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Bayesian Meta-learning}{section.2}% 4
\BOOKMARK [1][-]{section.3}{Exact Characterization of CMI}{}% 5
\BOOKMARK [2][-]{subsection.3.1}{Information-theoretic Decomposition of CMI}{section.3}% 6
\BOOKMARK [2][-]{subsection.3.2}{Linear Regression Model}{section.3}% 7
\BOOKMARK [2][-]{subsection.3.3}{Asymptotic Behavior}{section.3}% 8
\BOOKMARK [1][-]{section.4}{Exact Characterization of Generalization Error}{}% 9
\BOOKMARK [2][-]{subsection.4.1}{Relation to Generalization Error}{section.4}% 10
\BOOKMARK [2][-]{subsection.4.2}{Relationship between the Sensitivity and the Gibbs Test Error}{section.4}% 11
\BOOKMARK [1][-]{section.5}{Exact Characterization of CMI in Meta-learning}{}% 12
\BOOKMARK [1][-]{section.6}{Related Work}{}% 13
\BOOKMARK [1][-]{section.7}{Numerical Experiments}{}% 14
\BOOKMARK [2][-]{subsection.7.1}{Experiments in Bayesian Learning Setting}{section.7}% 15
\BOOKMARK [2][-]{subsection.7.2}{Experiments in Bayesian Meta-learning Setting}{section.7}% 16
\BOOKMARK [1][-]{section.8}{Conclusion}{}% 17
\BOOKMARK [1][-]{appendix.A}{Proof of Theorem 1}{}% 18
\BOOKMARK [1][-]{appendix.B}{Proof of Theorem 2 in Linear Regression Model}{}% 19
\BOOKMARK [1][-]{appendix.C}{Proof of the Asymptotic Result in Theorem 3}{}% 20
\BOOKMARK [1][-]{appendix.D}{Proofs of Lemma 2 and Theorem 4}{}% 21
\BOOKMARK [2][-]{subsection.D.1}{Relation to Bayesian Regret}{appendix.D}% 22
\BOOKMARK [1][-]{appendix.E}{Proof of Theorem 5}{}% 23
\BOOKMARK [1][-]{appendix.F}{Proofs of Meta-learning in Theorem 6}{}% 24
\BOOKMARK [1][-]{appendix.G}{Numerical Experiments}{}% 25
\BOOKMARK [2][-]{subsection.G.1}{Experiments in Bayesian Learning Setting}{appendix.G}% 26
\BOOKMARK [2][-]{subsection.G.2}{Experiments in Bayesian Meta-learning Setting}{appendix.G}% 27
