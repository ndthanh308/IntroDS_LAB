\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agostinelli et~al.(2023)Agostinelli, Denk, Borsos, Engel, Verzetti, Caillon, Huang, Jansen, Roberts, Tagliasacchi, Sharifi, Zeghidour, and Frank]{MusicLM}
Andrea Agostinelli, Timo~I Denk, Zalan Borsos, Jesse Engel, Mauro Verzetti, Antoine Caillon, Qingqing Huang, Aren Jansen, Adam Roberts, Marco Tagliasacchi, Matt Sharifi, Neil Zeghidour, and Christian Frank.
\newblock {MusicLM}: Generating music from text.
\newblock \emph{arXiv:2301.11325}, 2023.

\bibitem[Bresin et~al.(2010)Bresin, de~Witt, Papetti, Civolani, and Fontana]{bresin2010expressive}
Roberto Bresin, Anna de~Witt, Stefano Papetti, Marco Civolani, and Federico Fontana.
\newblock Expressive sonification of footstep sounds.
\newblock \emph{Proceedings of ISon}, 2010.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{GPT3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in Neural Information Processing Systems}, pp.\  1877--1901, 2020.

\bibitem[Choi et~al.(2023)Choi, Im, Heller, McFee, Imoto, Okamoto, Lagrange, and Takamichi]{choi2023foley}
Keunwoo Choi, Jaekwon Im, Laurie Heller, Brian McFee, Keisuke Imoto, Yuki Okamoto, Mathieu Lagrange, and Shinosuke Takamichi.
\newblock Foley sound synthesis at the dcase 2023 challenge.
\newblock \emph{arXiv preprint arXiv:2304.12521}, 2023.

\bibitem[Copet et~al.(2023)Copet, Kreuk, Gat, Remez, Kant, Synnaeve, Adi, and Defossez]{MusicGen}
Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, and Alexandre Defossez.
\newblock Simple and controllable music generation.
\newblock \emph{arXiv:2306.05284}, 2023.

\bibitem[Drossos et~al.(2020)Drossos, Lipping, and Virtanen]{clotho}
Konstantinos Drossos, Samuel Lipping, and Tuomas Virtanen.
\newblock Clotho: An audio captioning dataset.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing}, pp.\  736--740, 2020.

\bibitem[Engel et~al.(2020)Engel, Hantrakul, Gu, and Roberts]{engel2020ddsp}
Jesse Engel, Lamtharn Hantrakul, Chenjie Gu, and Adam Roberts.
\newblock {DDSP}: Differentiable digital signal processing.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Font et~al.(2013)Font, Roma, and Serra]{font2013freesound}
Frederic Font, Gerard Roma, and Xavier Serra.
\newblock Freesound technical demo.
\newblock In \emph{Proceedings of the 21st ACM International Conference on Multimedia}, pp.\  411--412, 2013.

\bibitem[Gallagher(2015)]{gallagher2015field}
Michael Gallagher.
\newblock Field recording and the sounding of spaces.
\newblock \emph{Environment and Planning D: Society and Space}, pp.\  560--576, 2015.

\bibitem[Gupta \& Kembhavi(2023)Gupta and Kembhavi]{VisualProgramming}
Tanmay Gupta and Aniruddha Kembhavi.
\newblock {Visual programming}: Compositional visual reasoning without training.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  14953--14962, 2023.

\bibitem[Hershey et~al.(2017)Hershey, Chaudhuri, Ellis, Gemmeke, Jansen, Moore, Plakal, Platt, Saurous, Seybold, et~al.]{VGGish}
Shawn Hershey, Sourish Chaudhuri, Daniel~PW Ellis, Jort~F Gemmeke, Aren Jansen, R~Channing Moore, Manoj Plakal, Devin Platt, Rif~A Saurous, Bryan Seybold, et~al.
\newblock {CNN architectures for large-scale audio classification}.
\newblock In \emph{2017 IEEE International Conference on Acoustics, Speech and Signal processing (ICASSP)}, pp.\  131--135, 2017.

\bibitem[Huang et~al.(2023{\natexlab{a}})Huang, Huang, Yang, Ren, Liu, Li, Ye, Liu, Yin, and Zhao]{huang2023make}
Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi~Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao.
\newblock {Make-an-Audio}: Text-to-audio generation with prompt-enhanced diffusion models.
\newblock \emph{arXiv:2301.12661}, 2023{\natexlab{a}}.

\bibitem[Huang et~al.(2023{\natexlab{b}})Huang, Li, Yang, Shi, Chang, Ye, Wu, Hong, Huang, Liu, et~al.]{AudioGPT}
Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jiawei Huang, Jinglin Liu, et~al.
\newblock {AudioGPT}: Understanding and generating speech, music, sound, and talking head.
\newblock \emph{arXiv:2304.12995}, 2023{\natexlab{b}}.

\bibitem[HuggingFace(2016)]{HuggingFace}
HuggingFace.
\newblock {The AI Community Building the Future}.
\newblock \url{https://huggingface.com}, 2016.

\bibitem[Kim et~al.(2019)Kim, Kim, Lee, and Kim]{AudioCaps}
Chris~Dongjoo Kim, Byeongchang Kim, Hyunmin Lee, and Gunhee Kim.
\newblock {AudioCaps}: Generating captions for audios in the wild.
\newblock In \emph{Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pp.\  119--132, 2019.

\bibitem[Koutini et~al.(2021)Koutini, Schl{\"u}ter, Eghbal-Zadeh, and Widmer]{koutini2021efficient}
Khaled Koutini, Jan Schl{\"u}ter, Hamid Eghbal-Zadeh, and Gerhard Widmer.
\newblock Efficient training of audio transformers with patchout.
\newblock \emph{arXiv preprint arXiv:2110.05069}, 2021.

\bibitem[Kreuk et~al.(2022)Kreuk, Synnaeve, Polyak, Singer, D{\'e}fossez, Copet, Parikh, Taigman, and Adi]{AudioGen}
Felix Kreuk, Gabriel Synnaeve, Adam Polyak, Uriel Singer, Alexandre D{\'e}fossez, Jade Copet, Devi Parikh, Yaniv Taigman, and Yossi Adi.
\newblock {AudioGen}: Textually guided audio generation.
\newblock In \emph{The International Conference on Learning Representations}, 2022.

\bibitem[Likert(1932)]{likert1932technique}
Rensis Likert.
\newblock A technique for the measurement of attitudes.
\newblock \emph{Archives of psychology}, 1932.

\bibitem[Liu et~al.(2022)Liu, Liu, Kong, Tian, Zhao, Wang, Huang, and Wang]{liu2022voicefixer}
Haohe Liu, Xubo Liu, Qiuqiang Kong, Qiao Tian, Yan Zhao, DeLiang Wang, Chuanzeng Huang, and Yuxuan Wang.
\newblock {VoiceFixer}: A unified framework for high-fidelity speech restoration.
\newblock In \emph{Conference of the International Speech Communication Association}, 2022.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Chen, Yuan, Mei, Liu, Mandic, Wang, and Plumbley]{AudioLDM}
Haohe Liu, Zehua Chen, Yi~Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, and Mark~D Plumbley.
\newblock {AudioLDM}: Text-to-audio generation with latent diffusion models.
\newblock In \emph{International Conference on Machine Learning}, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Li, Wu, and Lee]{llava}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock \emph{arXiv preprint arXiv:2304.08485}, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2021)Liu, Iqbal, Zhao, Huang, Plumbley, and Wang]{liu2021conditional}
Xubo Liu, Turab Iqbal, Jinzheng Zhao, Qiushi Huang, Mark~D Plumbley, and Wenwu Wang.
\newblock Conditional sound generation using neural discrete time-frequency representation learning.
\newblock In \emph{International Workshop on Machine Learning for Signal Processing}, 2021.

\bibitem[OpenAI(2022)]{ChatGPT}
OpenAI.
\newblock Introducing {ChatGPT}.
\newblock \url{https://openai.com/blog/chatgpt}, 2022.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and Khudanpur]{Librispeech}
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.
\newblock {Librispeech}: an {ASR} corpus based on public domain audio books.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing}, pp.\  5206--5210, 2015.

\bibitem[Pease \& Colton(2011)Pease and Colton]{pease2011impact}
Alison Pease and Simon Colton.
\newblock On impact and evaluation in computational creativity: A discussion of the turing test and an alternative proposal.
\newblock In \emph{Proceedings of the AISB Symposium on AI and Philosophy}, volume~39, 2011.

\bibitem[Rawte et~al.(2023)Rawte, Sheth, and Das]{rawte2023survey}
Vipula Rawte, Amit Sheth, and Amitava Das.
\newblock A survey of hallucination in large foundation models.
\newblock \emph{arXiv preprint arXiv:2309.05922}, 2023.

\bibitem[Reiss(2011)]{reiss2011intelligent}
Joshua~D Reiss.
\newblock Intelligent systems for mixing multichannel audio.
\newblock In \emph{International Conference on Digital Signal Processing}, 2011.

\bibitem[Ribeiro et~al.(2011)Ribeiro, Flor{\^e}ncio, Zhang, and Seltzer]{MOS}
Fl{\'a}vio Ribeiro, Dinei Flor{\^e}ncio, Cha Zhang, and Michael Seltzer.
\newblock Crowdmos: An approach for crowdsourcing mean opinion score studies.
\newblock In \emph{2011 IEEE international conference on acoustics, speech and signal processing (ICASSP)}, pp.\  2416--2419. IEEE, 2011.

\bibitem[Shah et~al.(2003)Shah, Smith, and Vargas-Hernandez]{shah2003metrics}
Jami~J Shah, Steve~M Smith, and Noe Vargas-Hernandez.
\newblock Metrics for measuring ideation effectiveness.
\newblock \emph{Design Studies}, 24\penalty0 (2):\penalty0 111--134, 2003.

\bibitem[Shen et~al.(2023)Shen, Song, Tan, Li, Lu, and Zhuang]{HuggingGPT}
Yongliang Shen, Kaitao Song, Xu~Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang.
\newblock {HuggingGPT: Solving AI tasks with ChatGPT and its friends in Huggingface}.
\newblock \emph{arXiv:2303.17580}, 2023.

\bibitem[Steinmetz \& Reiss(2021)Steinmetz and Reiss]{steinmetz2021pyloudnorm}
Christian~J. Steinmetz and Joshua~D. Reiss.
\newblock Pyloudnorm: {A} simple yet flexible loudness meter in {Python}.
\newblock In \emph{Audio Engineering Convention}, 2021.

\bibitem[Suno(2023)]{Bark}
Suno.
\newblock Bark.
\newblock \url{https://github.com/suno-ai/bark}, 2023.

\bibitem[Suris et~al.(2023)Suris, Menon, and Vondrick]{ViperGPT}
Didac Suris, Sachit Menon, and Carl Vondrick.
\newblock {ViperGPT}: Visual inference via {Python} execution for reasoning.
\newblock \emph{arXiv:2303.08128}, 2023.

\bibitem[Tan et~al.(2022)Tan, Chen, Liu, Cong, Zhang, Liu, Wang, Leng, Yi, He, Soong, Qin, Zhao, and Liu]{NaturalSpeech}
Xu~Tan, Jiawei Chen, Haohe Liu, Jian Cong, Chen Zhang, Yanqing Liu, Xi~Wang, Yichong Leng, Yuanhao Yi, Lei He, Frank Soong, Tao Qin, Sheng Zhao, and Tie-Yan Liu.
\newblock {NaturalSpeech}: End-to-end text to speech synthesis with human-level quality.
\newblock \emph{arXiv:2205.04421}, 2022.

\bibitem[Tokui et~al.(2000)Tokui, Iba, et~al.]{tokui2000music}
Nao Tokui, Hitoshi Iba, et~al.
\newblock Music composition with interactive evolutionary computation.
\newblock In \emph{International Conference on Generative Art}, volume~17, pp.\  215--226, 2000.

\bibitem[Touvron et~al.(2023{\natexlab{a}})Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Roziere, Goyal, Hambro, Azhar, et~al.]{llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et~al.
\newblock {LLaMA}: Open and efficient foundation language models.
\newblock \emph{arXiv:2302.13971}, 2023{\natexlab{a}}.

\bibitem[Touvron et~al.(2023{\natexlab{b}})Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{llama2}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2017)Wang, Skerry-Ryan, Stanton, Wu, Weiss, Jaitly, Yang, Xiao, Chen, Bengio, et~al.]{wang2017tacotron}
Yuxuan Wang, RJ~Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron~J Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, et~al.
\newblock {Tacotron}: Towards end-to-end speech synthesis.
\newblock \emph{arXiv:1703.10135}, 2017.

\bibitem[Wright(2014)]{wright2014footsteps}
Benjamin Wright.
\newblock {Footsteps with character: the art and craft of Foley}.
\newblock \emph{Screen}, 55\penalty0 (2):\penalty0 204--220, 2014.

\bibitem[Wu et~al.(2023)Wu, Chang, Wu, and Lee]{wu2023speechgen}
Haibin Wu, Kai-Wei Chang, Yuan-Kuei Wu, and Hung-yi Lee.
\newblock {SpeechGen}: Unlocking the generative power of speech language models with prompts.
\newblock \emph{arXiv:2306.02207}, 2023.

\bibitem[Yuan et~al.(2023{\natexlab{a}})Yuan, Liu, Liang, Liu, Plumbley, and Wang]{yuan2023leveraging}
Yi~Yuan, Haohe Liu, Jinhua Liang, Xubo Liu, Mark~D Plumbley, and Wenwu Wang.
\newblock {Leveraging pre-trained AudioLDM for sound generation: A benchmark study}.
\newblock In \emph{European Signal Processing Conference}, 2023{\natexlab{a}}.

\bibitem[Yuan et~al.(2023{\natexlab{b}})Yuan, Liu, Liu, Kang, Wu, Plumbley, and Wang]{yuan2023text}
Yi~Yuan, Haohe Liu, Xubo Liu, Xiyuan Kang, Peipei Wu, Mark~D Plumbley, and Wenwu Wang.
\newblock Text-driven foley sound generation with latent diffusion model.
\newblock In \emph{Detection and Classification of Acoustic Scenes and Events Workshop}, 2023{\natexlab{b}}.

\end{thebibliography}
