\section{Related Work}
\label{sec:relatedwork}
 %
State vector quantum computer simulators have a long history of development. The first parallel HPC quantum computer simulation approaches have been proposed by Da Raedt et al~\cite{daraedt2007parsim}, enabling the simulation of up to 36 qubits with the state vector representation, running benchmarks within 1,707 seconds when utilizing up to 4096 CPUs on the IBM BlueGene/L machine. Later on, Da Raedt et al~\cite{daraedt2019parsim} revised the massively parallel state vector simulator and provide additional performance measurements of up to 48 qubits on the Sunway TaihuLight and K supercomputers. 

Now, supercomputers have evolved to include different types of accelerators such as GPUs, whose utilization has been facilitated through high-level programming models, leading to the development of frameworks such as Qiskit that allow GPU-based quantum computer simulations. In this context, Doi et al.~\cite{doi2019} perform scaling experiments on a heterogeneous CPU-GPU setup, showing the applicability of such a setup for quantum computer simulations. Their simulator has been integrated into the Qiskit Aer framework. In a more recent work, Doi et al.~\cite{doi2020cache} implemented the cache-blocking technique that is used within Qiskit for multi-GPU acceleration. Using an IBM Power System AC922 with 6 GPUs, they simulate up to 35 qubits on a single node using the QV and QFT benchmarks, and perform further scaling experiments over multiple nodes. So far our presented work shows an in-depth analysis of the performance of this approach on a single node, leaving multi-node performance evaluation with a focus on MPI communication as a potential future work. 

Imamura et al.~\cite{imamura2022mpiqulacs} compare the aforementioned GPU performance to their CPU framework, mpiQulacs, focusing on distributed multi-node acceleration of the state vector simulator with MPI. They compare the runtime (double-precision) of their accelerator with Qiskit Aer on the Quantum Volume benchmark with the same circuit depth used in our setup running on a GPU cluster with 6 Nvidia V100 GPUs per node. In their setup, mpiQulacs outperforms Qiskit after scaling to four nodes with 32 qubits. However, for the same benchmark on our setup it was possible to scale well with up to 32 qubits on a single node with only two GPUs, requiring only 12 seconds, whereas the runtime on four CPU nodes with mpiQulacs lies above 20 seconds according to their results. This might be explained by the fact that there is no communication overhead in our setup since our evaluation is done on a single node only, which on the contrary speaks for a higher efficiency of the GPU setup over the CPU setup.