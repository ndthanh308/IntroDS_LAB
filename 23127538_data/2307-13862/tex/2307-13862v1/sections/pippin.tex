Here we briefly describe the simulation of realistic data-sets of spectroscopically confirmed SN Ia, and the analysis procedure used to produce a cosmological contour. Throughout this analysis we make use of SNANA for simulation and analysis, integrated into the Pippin pipeline.

\subsection{Simulating a Supernova Data-set}
We use the SALT2~\citep{GuyAstier2007} framework within SNANA for simulating SNe Ia. \added{This framework models type Ia supernovae with five parameters: redshift, day of peak rest-frame $B$-band brightness, stretch, color, and apparent peak brightness in rest-frame $B$-band. SNANA produces simulated observed fluxes by randomly selecting these model parameters from associated probability distributions. SNANA also applies host-galaxy extinction, k-correction, and galactic extinction.}
For this analysis we use the SALT2 model produced by~\cite{TaylorLidman2021}, which was trained on a sample of 420 SNe Ia spanning a redshift range of $\sim$0.1  to $\sim$0.9 with improved zero-point calibration offsets and Milky Way extinction compared to previous SALT2 models.

\subsubsection{Bias Correction Simulations}\label{sec:biascor}
In addition to data-like simulations, we also simulate much larger data-sets to correct observational biases. As part of this analysis, we investigate the impact of the cosmology on these bias corrections. Our principal analysis uses only a single bias correction simulation with the input cosmology set to our nominal input cosmology ($\Omega_{M}=0.3$, $w=-1.0$), but we repeat our analysis using many bias correction simulations, with input cosmologies equal to the input cosmology of the data-set they are correcting, to see if this affects the Neyman construction.

\subsection{Analysis}
The supernovae in each simulated data-set are fit to determine the SALT2 parameters: amplitude ($x_{0}$), stretch ($x_{1}$), and colour ($c$). From here, the distance modulus of each SN Ia can be computed via the Tripp equation~\citep{Tripp1998}
\begin{equation}
\mu = m_{B} + \alpha{}x_{1} - \beta{}c + \mathcal{M} - \Delta\mu_{bias}
\end{equation}
Here $\alpha$ and $\beta$ are global stretch and colour nuisance parameters, $\mathcal{M}$ is a global offset, and $\Delta\mu_{bias} = \mu - \mu_{true}$ is a distance bias correction, where $\mu_{true}$ is the true distance modulus. 

Pippin makes use of the BEAMS with Bias Correction \citep[BBC;][]{KesslerScolnic2017} framework to produce a Hubble Diagram (HD) that has been corrected for both selection effects and contamination. BBC uses the detailed simulations described in Section~\ref{sec:biascor} alongside the BEAMS~\citep{KunzHlozek2012} method to correct for both distance biases, contamination, and selection effects~\citep{KesslerBrout2019}. It then uses a cosmology-independent method \citep[SALT2mu;]{MarrinerBernstein2011} to fit for global nuisance parameters and standardise the SNe Ia magnitudes.

In order to fit $\alpha$, $\beta$, and $\mathcal{M}$, BBC adopts the likelihood $\mathcal{L} = \prod_{i=1}^{N}\mathcal{L}_{i}$ where
\begin{align}
\mathcal{L}_{i} &= P_{Ia,i}D_{Ia,i} + (1 - P_{Ia,i})D_{CC,i}
\end{align}
Here $P_{Ia,i}$ is the photometric classification probability for the $i$th supernova to be an SN Ia. This is usually calculated via a photometric classifier such as SuperNNova~\citep{MollerdeBoissiere2020}, or Scone~\citep{QuSako2021}, however for our analysis we do not simulate contamination, so $P_{Ia,i}=1$. $D_{Ia,i}$ encodes the influence of SNe Ia on the likelihood, including corrections for observational biases in the data-set. Details of $D_{Ia,i}$ are presented in~\cite{KesslerScolnic2017}. The $D_{CC,i}$ component encodes the effects of contaminants; however, since our simulations are contaminant free, it is unimportant for this analysis.

The end result of the BBC framework is a redshift-binned HD. BBC can also provide an unbinned HD which~\cite{BroutHinton2021} shows can result in smaller systematic uncertainties, but is more computationally expensive. Since our analysis only includes statistical uncertainties, we gain no benefit from using an unbinned HD, therefore we only use the default, binned HD.

This binned HD is passed to a cosmological fitter to produce the final cosmological contours. In this analysis we make use of WFit, which measures a $\chi^{2}$ likelihood over a grid within the parameter space. WFit has the advantage of being much faster than other methods, although is only suitable for simple test cases such as the one used in this paper, and not necessarily suitable for final survey cosmological analysis. We allow the parameter space of $\Omega_{M}$ to vary below 0, something which is not usual for cosmological analyses, as our analysis requires WFit to explore large sections of the $\Omega_{M}$, $w$ parameter space, and we do not wish to artificially truncate the likelihood surface we produce.

\subsection{Producing an experiment data-set}\label{sec:experiment}
Our methodology can be used to validate the contour produced by any cosmological pipeline, and is not dependent on the details of the data-set investigated by the cosmological pipeline. As such, we test our methodology on a simple, simulated dataset which mimics the 3 year DES data-set~\citep{BroutSako2019}, including the cadence\added{, spectroscopic selection, }and observational noise~\citep{DAndreaSmith2018} of this data-set. We assume a flat, cold dark matter ($wCDM$) cosmology with $H_{0}=70$km/s/Mpc, $\Omega_{M}=0.3$, and $w=-1.0$. The DES 3 year data-set includes a previously released low-$z$ sample from several sources. We simplify the low-$z$ simulation by generating a DES-like sample for $0.0\le{}z\le{}0.08$ with the same statistics as the low-$z$ sample. Additionally, we only simulate SNe Ia and do not consider contamination from core-collapse supernovae, so that we can keep our analysis as simple as possible. The true DES data-set includes data from a variety of telescopes, as well as misclassified core-collapse SNe, so if our methodology were to be used to test the DES analysis, these details will need to be included in all simulations. \added{The redshift distribution of our DES and low-$z$ simulated sample is presented in Figure~\ref{fig:redshift}. An example of a simulated lightcurve is presented in Figure~\ref{fig:lightcurve}.}

We analyse this simulated data-set with Pippin in order to produce the cosmological contour \replaced{that we aim to validate}{we check} (shown in Figure~\ref{fig:Contour}), and to calculate the best fitting cosmology:
\begin{align}\label{eq:best}
    \begin{split}
        \Omega_{M}^{best} &= 0.32^{+0.054}_{-0.075} \\
        w^{best} &= -1.00\pm0.16
    \end{split}
\end{align}

% Figure environment removed

% Figure environment removed

% Figure environment removed

