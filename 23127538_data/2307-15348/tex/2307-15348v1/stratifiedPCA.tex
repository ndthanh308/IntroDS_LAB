\documentclass[webpdf,modern,small]{oup-authoring-template}

\onecolumn % for one column layouts

%\usepackage{showframe}

\graphicspath{{Fig/}}

% line numbers
%\usepackage[mathlines, switch]{lineno}
%\usepackage[right]{lineno}

\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}%
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.
\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%
\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,      
    urlcolor=blue,
    citecolor=blue
    }


\begin{document}
\journaltitle{}
\DOI{}
\copyrightyear{2023}
\pubyear{}
\access{}
\appnotes{}

\firstpage{1}


\title[Stratified PCA]{Stratified Principal Component Analysis}

\author[]{Tom Szwagier\ORCID{0000-0002-2903-551X}}
\author[]{Xavier Pennec\ORCID{0000-0002-6617-7664}}


\authormark{Szwagier and Pennec}
\address[]{\orgname{Université Côte d’Azur and Inria}, \state{Sophia Antipolis}, \country{France}}


\corresp[]{Emails: \href{mailto:tom.szwagier@inria.fr}{tom.szwagier@inria.fr}, \href{mailto:xavier.pennec@inria.fr}{xavier.pennec@inria.fr}}

\abstract{
This paper investigates a general family of models that stratifies the space of covariance matrices by eigenvalue multiplicity. This family, coined Stratified Principal Component Analysis (SPCA), includes in particular Probabilistic PCA (PPCA) models, where the noise component is assumed to be isotropic.
We provide an explicit maximum likelihood and a geometric characterization 
relying on flag manifolds. 
A key outcome of this analysis is that PPCA's parsimony---with respect to the full covariance model---is due to the eigenvalue-equality constraint in the noise space and the subsequent inference of a multidimensional eigenspace.
The sequential nature of flag manifolds enables to extend this constraint to the signal space and bring more parsimonious models.
Moreover, the stratification and the induced partial order on SPCA yield efficient model selection heuristics.
Experiments on simulated and real datasets substantiate the interest of equalising adjacent sample eigenvalues when the gaps are small and the number of samples is limited. They notably demonstrate that SPCA models achieve a better complexity/goodness-of-fit tradeoff than PPCA.
}
\keywords{
Probabilistic principal component analysis; Parsimony; Eigenvalue multiplicity; \\Flag manifolds; Stratified space
}

\maketitle
\input{sections/1_Intro}
\input{sections/2_PPCA}
\input{sections/3_SPCA}
\input{sections/4_ModelSelection}
\input{sections/5_Examples}
\input{sections/6_Conclusion}

\section*{Acknowledgements}
This work was supported by the ERC grant \#786854 G-Statistics from the European Research Council under the European Union’s Horizon 2020 research and innovation program and by the French government through the 3IA Côte d’Azur Investments ANR-19-P3IA-0002 managed by the National Research Agency.

\begin{appendices}
\input{appendices/SPCA}
\input{appendices/ModelSelection}
\end{appendices}

%\bibliographystyle{abbrvnat}
\bibliographystyle{apalike}
\bibliography{stratifiedPCA}

\end{document}
