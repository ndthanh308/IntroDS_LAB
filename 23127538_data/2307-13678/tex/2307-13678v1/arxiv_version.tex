\documentclass[12in]{article}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor,graphicx,chemarr,amsmath,amssymb,amsthm,mathrsfs,subfigure}
\graphicspath{{fig/}}
\renewcommand\det{\mbox{det}}
%
\newcommand\ab[1]{\vert{#1}\vert}
\newcommand\bx{{\bar x}}
\newcommand\G{\Gamma}
\newcommand{\rank}{\mathop{\mbox{rank}}}
\newcommand{\argmax}{\mathop{\mbox{arg max}}}
\newcommand{\argmin}{\mathop{\mbox{arg min}}}
\newcommand{\lra}{\mathop{\longrightarrow}\limits}
\newcommand{\Rnn}{{\mathbb R}_{\ge 0}^n}
\newcommand{\uR}{\overline{R}}
\newcommand{\lR}{\underline{R}}
\newcommand{\diag}{\mathop{\mbox{diag}}}
\newcommand{\sgn}{\mathop{\mbox{sgn}}}
\newcommand{\supp}{\mathop{\mbox{supp}}}
%
\newcommand{\tV}{{\widetilde{V}}}
\newcommand{\hV}{{\widehat{V}}}
\newcommand{\cV}{{\mathcal{V}}}
\newcommand{\hxi}{{\hat{\xi}}}
\newcommand{\cW}{{\mathcal W}}
\newcommand{\co}{\mathop{\mbox{co}}}
\newcommand{\R}{{\rm \bf R}}
\renewcommand{\Im}{{\mathop{\rm Im\,}}}
\newcommand{\Rs}{{\mathscr R}}
\newcommand{\Ss}{{\mathscr S}}
\newcommand{\Ns}{{\mathscr N}}
\newcommand{\Cs}{\mathscr C}
\newcommand{\tl}{\tilde}
\newcommand\ve{\varepsilon}
\newcommand{\wt}{\widetilde}
\newcommand\graphicalLF{Graphical Lypaunov Function }
\newcommand\comment[1]{}
\definecolor{lightgray}{rgb}{0.895,.895,.895}
%
\newcommand\mybox[1]{#1}
\newtheorem{theorem}{\bfseries\sffamily Theorem}%
%
%
\newtheorem{proposition}[theorem]{\bfseries\sffamily Proposition}%
\newtheorem{lemma}[theorem]{\bfseries\sffamily Lemma}%
\newtheorem{corollary}[theorem]{\bfseries\sffamily Corollary}%
%

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{\bfseries\sffamily Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{\bfseries\sffamily Definition}%
\usepackage[font=small,labelfont=sf,bf]{caption}
\usepackage{titlesec}
\titleformat{\section}{\Large\bfseries\sffamily}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries\sffamily}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\large\bfseries\sffamily}{\thesubsubsection}{1em}{}
\renewcommand{\paragraph}[1]{\vspace{1em}\noindent{\bfseries\sffamily #1}.} 
\title{\Large\bfseries\sffamily On structural contraction   of  biological interaction networks}
\author{M. Ali Al-Radhawi, David Angeli, and Eduardo Sontag}
\date{\today}

\begin{document}

	\maketitle
	\begin{abstract}
		In previous work, we have developed an approach for characterizing the long-term dynamics of classes of Biological Interaction Networks (BINs), based on “rate-dependent Lyapunov functions”. In this work, we show that stronger notions of convergence can be established by proving \textit{structural contractivity} with respect to non-standard norms.  We illustrate our theory with examples from signaling pathways.  
	\end{abstract}	
	\section{Introduction}
Biological systems function  via intricate dynamical networks such as signaling pathways, gene regulatory networks and metabolic networks \cite{ideker01,alon06}. Such networks are amenable, in principle, to rational analysis and design using  the mathematical language of Biological Interaction Networks (BINs), also known as Chemical Reaction Networks (CRNs) \cite{feinberg87,erdi89,sontag01}.  However, unlike systems that are engineered by humans,   biological networks exhibit  many complicating factors.  First, biology pervasively employs nonlinear \textit{binding} events to relay information. Examples include the binding of enzymes to substrates, ligands to receptors, transcription factors to promoters, small molecules to proteins, etc. Such events are intrinsically nonlinear, and linearization is often unhelpful. Second, BINs suffer from severe forms of uncertainty. For instance, the kinetics governing the speed of binding events and biochemical transformations are seldom known.  Such uncertainty is not limited to the difficulty in measuring the relevant parameters and identifying the functional forms, also it includes the fact that BINs operate in highly variable environments with time-varying kinetics.
Nevertheless, despite the uncertainty and nonlinearity, biological networks are known  for their remarkable ability for maintaining homeostasis and robustness against perturbations. This latter property has been used as a \textit{defining} characteristic of biological networks  \cite{morohashi02}. A common framework to explain such robustness postulates that biology employs robust \emph{motifs} \cite{prill05}, which means that the uniform qualitative behavior is endowed by the graphical structure regardless of the parameters  \cite{bailey01,gupta22,araujo23}.


The effort for characterizing the qualitative \textit{global} long-term behavior of a BIN without knowledge of its kinetics has been strikingly successful for some classes of BINs. A notable example is Horn-Jackson-Feinberg's (HJF) theory of complex-balanced networks \cite{horn72,feinberg87} which employs the sum of all the chemical pseudo-energies stored in species as a Lyapunov function, and it can establish \textit{global stability} in many cases \cite{sontag01,anderson11}. %
Other notions of global behavior have  been studied.  \emph{Persistence} precludes species from asymptotically going extinct during the course of reaction  \cite{angeli07p}, while \emph{monotonicity} ensures that trajectories preserve a partial order, which guarantees generic convergence under mild conditions \cite{angeli10}. More recently, many important BINs have been shown to admit piecewise linear Lyapunov functions in reaction \cite{PWLRj,MA_LEARN} and concentration coordinates \cite{MA_cdc14,blanchini14,MA_LEARN}. Theses methods only require a list of reactions to  rule that the steady states of a network are unique and globally asymptotically stable relative to their stoichiometric classes. Such functions can either be constructed computationally \cite{PWLRj,blanchini14,MA_LEARN} or graphically \cite{MA_MCSS23}, where a dedicated computational package is available \cite{MA_LEARN}. Such methods have also been generalized to show that a given network can never admit oscillations \cite{MA_TAC22}.

\paragraph{Contraction analysis}
In this paper, we are interested in studying the notion of \emph{contraction}. Informally, a dynamical system is strictly contractive with respect to a given metric if the  distance between any two trajectories converges exponentially to zero, while it is called \textit{non-expansive} if that distance is non-increasing. Early results were developed in the late 1950s using the notion of logarithmic norms \cite{dahlquist58,lozinskii58}. More recently, there has been an explosion of interest in this form of analysis \cite{lohmiller98,nijmeijer06,sontag14,forni14,bullo22}.

  Contraction can be contrasted with Lyapunov-based globally stability analysis, where the latter merely requires that all trajectories converge to a steady-state. In other words, the distance between trajectories in a globally stable system can overshoot, and may not exponentially decrease to zero. Therefore, contraction is a much stronger notion compared to global stability. This offers few advantages. First, it has been argued \cite{bullo22} that the properties enjoyed by contractive systems are more akin to linear systems, and hence they offer a powerful general framework to analyze a much wider class of nonlinear systems with the same ease that we can analyze linear systems. Second, contractive systems \emph{entrain to periodic inputs} \cite{sontag10,margaliot16}, which means that the state of a contractive system will asymptotically oscillate with the same frequency of a periodic input. Third, using contraction analysis methods, a system with unbounded trajectories can sometimes be shown to be non-expansive, which greatly constrains its unstable behavior, while Lyapunov analysis does not offer further information when the trajectories are unbounded.

In the context of BINs, contraction has been only studied with respect to standard norms or with respect to diagonal scaling of such norms \cite{DiBernardo10,vaghy23}. Contraction with respect to non-standard norms has been studied recently for monotone systems \cite{jafarpour22}.
In this paper we show that the existence of the rate-dependent Lyapunov functions proposed in \cite{PWLRj,MA_LEARN} for a given reaction network implies structural non-expansivity with respect to weighted $\ell_\infty$ norms, and contractivity under additional easily verifiable conditions. %
  Therefore, the computational package \texttt{LEARN} \cite{MA_LEARN} will attempt at finding an appropriate contraction metric for a given network. 

The paper is organized as follows. Section 2 discusses preliminaries including extensions of previous results that are relevant to our current analysis. Section 3 shows that non-expansivity follows from the existence of an appropriate rate-dependent Lyapunov function. Section 4 establishes contraction over compact sets. %
Initial versions of these results have been presented in the PhD dissertation \cite{MA_dissertation}.








%


 
	\section{Preliminaries}
	
 
 \subsection{Notation}
	Let $S$ be a set, then $|S|$ denotes its cardinality. The set of $n$-tuples of positive numbers is denoted by $\mathbb R_+^n$, while the set of $n$-tuples of non-negative numbers is denoted by $\mathbb R_{\ge0}^n$. The set of $n\times m$ matrices with real entries is denoted by $\mathbb R^{n\times m}$. Let $U\subset \mathbb R^{n\times m}$, then $\bar U$ denotes its closure with respect to the standard Euclidean topology.  Let $A\in\mathbb R^{n\times m}$ be a matrix, then $\ker(A)$ is its kernel or null space, while $\Im A$ is its image space. Let $V:\mathcal X \to \mathbb R$ be a function, then $\ker V:=\{x\in\mathcal X| V(x)=0\}$. Let $\mathcal Y \subset \mathcal X$, then $\ker V|_{\mathcal Y}:=\{x\in\mathcal Y| V(x)=0\}$. Let $x=[x_1,..,x_n]^T \in \mathbb R^n$, then $\|x\|_\infty:=\max_i |x_i|$. The notation $x\gg0$ means that $x  \in\mathbb R_+^n$. Let $A\in\mathbb R^{n\times n}$, then $\sigma_i(A):= a_{ii}+\sum_{j\ne i} |a_{ij}|$, $i=1,..,n$, and $\mu_\infty(A):=\max_i \sigma_i(A)$. 
	
	
	\subsection{Biological Interaction Networks}
	We review standard material \cite{feinberg87,erdi89,sontag01,MA_LEARN}.
	
	\paragraph{Definition.} A Biological Interaction Network (BIN) (a.k.a, Chemical Reaction Network (CRN)) $\mathscr N$ is a pair $(\mathscr S,\mathscr R)$  where $\mathscr S:=\{X_1,...,X_n\}$ is the set of species, and $\mathscr R:=\{\R_1,..,\R_\nu\}$ is the set of reactions. Each reaction is written in the following form:
	\[\R_j:~~ \sum_{i=1}^n \alpha_{ij} X_i \longrightarrow \sum_{i=1}^n \beta_{ij} X_i, \]
	where $\alpha_{ij},\beta_{ij}\ge 0$ are stoichiometric coefficients. The net loss or gain of the $i$th species in the $j$th reaction is  $\gamma_{ij}=\beta_{ij}-\alpha_{ij}$. These numbers can be collected in a matrix $\Gamma \in\mathbb R^{n\times \nu}$ defined entry-wise as $[\Gamma]_{ij}= \gamma_{ij}$.  The matrix $\Gamma$ is customarily called the \textit{stoichiometry matrix}.
	
	\paragraph{Kinetics.} In order to quantify elements of the network, the species $X_1,..,X_n$ are assigned  non-negative numbers known as the \emph{concentrations} $x_1,..,x_n$, while   reactions $\R_1,..,\R_\nu$ are assigned \textit{rates} $R_j:\mathbb R_{\ge 0}^n \to \mathbb R_{\ge0}^\nu, j=1,..,\nu$.  A popular form of reaction rates is known as Mass-action kinetics written as $R_j(x) = \prod_{i=1,\alpha_{ij}>0}^n k_j x^{\alpha_{ij}}$, where $k_j>0$ is known as the kinetic constant. However, we do not assume a specific form of kinetics. Instead we only assume that $R$ is monotone with respect to its reactants. More precisely, a reaction rate $R$ is \textit{admissible} if      it satisfies the following general properties: \begin{enumerate}
		\item[\!\!] {\bf AK1}. each reaction varies smoothly with respects to its reactants, i.e $R(x)$ is $\mathscr C^1$;
		\item[\!\!] {\bf AK2}. a reaction requires all its reactants to occur, i.e.,  if $\alpha_{ij}>0$, then $x_i=0$ implies  $R_j(x)=0$; %
		\item[\!\!] {\bf AK3}. if a reactant increases, then the reaction rate increase, i.e ${\partial R_j}/{\partial x_i}(x) \ge 0$ if $\alpha_{ij}>0$ and ${\partial R_j}/{\partial x_i}(x)\equiv 0$ if $\alpha_{ij}=0$. Furthermore, the aforementioned inequality is strict whenever the reactants are strictly positive.
		%
			%
			%
		
		%
	\end{enumerate}
	In our paper, we assume that each network $\Ns$ is always equipped with a set of monotone kinetics satisfying AK1-AK3.   
	
	The admissible kinetics can be interpreted alternatively via a sign-pattern constraint on the Jacobian $\partial R/\partial x \in \mathbb R^{\nu\times n}$. More formally, let $\mathcal P_\Ns$ denote the set of reactant-reaction pairs, i.e., $\mathcal P_\Ns:=\{(i,j)| X_i~\mbox{is a reactant of}~\R_j\}$, and let $s=|\mathcal P_\Ns|$.  We define the set of all matrices that have an admissible sign pattern as $\mathcal K_\Ns := \{ K \in \mathbb R^{\nu \times n} | [K]_{ji}>0~\mbox{if}~(i,j)\in\mathcal P_\Ns,~\mbox{and}~[K]_{ji}=0~\mbox{otherwise}\}  $. Therefore, when $R$ is admissible, we have  $\partial R/\partial x(x) \in \mathcal K_\Ns$ for $x\in\mathbb R_{+}^{n}$ and $\partial R/\partial x(x) \in \overline{\mathcal K_\Ns}$ for $x\in\mathbb R_{\ge 0}^{n}$.
	
	A third formulation is stated by decomposing $R$ into a conic sum of indicator matrices. To that end,   let $E_{ji} \in \{0,1\}^{\nu \times n}$ be an indicator matrix, i.e, $E_{ij}$ is zero everywhere except for the $(j,i)$th entry where it is equal to 1. In addition, let the elements of $\mathcal P_\Ns$ be indexed as $(i_1,j_1),..,(i_s,j_s)$.  Therefore, we can write \begin{equation}\label{e.calK} \mathcal K_\Ns=\{K \in \mathbb R^{\nu\times n}|K=\sum_{\ell=1}^s \bar\rho_\ell E_{j_\ell i_\ell},~\mbox{for some}~\bar\rho_1,..,\bar\rho_s>0\}.\end{equation} Hence, the admissibility of  $R$ implies the existence of continuous functions $\rho_1(x),..,\rho_s(x)\ge 0$ such that
	\begin{equation}\label{e.dR}
		\frac{\partial R}{\partial x}(x)= \sum_{\ell=1}^s \rho_\ell(x) E_{j_\ell i_\ell},
	\end{equation}
	and $\rho_\ell(x)>0$ whenever $x\in\mathbb R_+^n$.
	
	\paragraph{Dynamics} The time evolution of the concentration vector $x=[x_1,..,x_n]$ as a function of time can be described using  the following Ordinary Differential Equation (ODE):
	\begin{equation}\label{e.ode}
		\dot x = \Gamma R(x), x(0)=x_0.
	\end{equation}
	The ODE above is an instance of what is known as a \emph{positive system}, which means that the trajectory $x(t)$ remains non-negative if the initial condition $x(0)$ is non-negative. A non-zero vector $w\in\mathbb R_{\ge 0}^n$ is called a \textit{conservation law} if $w^T\Gamma=0$, and it corresponds to a conserved quantity that stays invariant, i.e., $w^Tx(t)\equiv w^T x(0)$. In such cases, the trajectory will be confined to translates of $\Im\Gamma$ as can be seen by integrating \eqref{e.ode} to get $x(t)=x_0 + \Gamma \int_0^t R(x(\tau))\,d\tau$. Therefore, $x(t) \in \Cs_{x_0}$ for all $t\ge0$ where \[\Cs_{x_0}:= (\{x_0\} + \Im \Gamma)\cap \mathbb R_{\ge0}^n.\]
	The invariant manifold $\Cs_{x_0}$ is known as the \textit{stoichiometric class} corresponding to $x_0$. %
	
	
	
	\paragraph{Fluxes.}	A vector $v$ is called a \textit{flux} if $\Gamma v=0$.  In order to simplify the treatment, we will  assume the following about the stoichiometry of the network:
	\begin{enumerate}
		\item[ ] {\textbf{AS1.}} There exists a positive flux, i.e.,  $\exists v \in \ker \Gamma$ such that $v\gg0$.  
	\end{enumerate}
	Assumption AS1 is necessary for the existence of positive steady states for the corresponding dynamical system \eqref{e.ode}.
	
	\paragraph{Extent-of-reaction system.} A different representation of the dynamics uses the concept of the extent of reaction $\xi$   defined as  $\xi(t):=\int_0^t R(x(\tau))~d\tau+ \xi(0)$ for $\xi(0)$ to be decided.   By integrating both sides of \eqref{e.ode}, we get 
	\begin{equation}\label{rel_x_xi} x(t)- x(0) =  \Gamma (\xi(t) - \xi(0)). \end{equation} %
	
	Using the latter equation we can write the dynamics of $\xi$ in several forms by choosing $\xi(0)$. %
Assume $x(0)=x_0$,	pick a point $\bx \in \Cs_{x_0}$, then there exists $\xi_0$ such that $x_0 - \bx = \Gamma \xi_0$.  By a simple algebraic manipulation, write $x(t)-x_0=x(t)-\bx+\bx-x_0= x(t)-\bx - \Gamma \xi_0$. Substituting in \eqref{rel_x_xi}, we get $x(t)-\bx=\Gamma\xi(t)$. Since $\dot\xi=R(x)$, we can write:
	\begin{equation}\label{e.xiode} \dot\xi = R(\bx + \Gamma \xi), \xi(0)=\xi_0.
	\end{equation}
	%
	 \mybox{\paragraph{Example} Let us consider the following nonlinear network which represents a simplified post-translational modification cycle:
	 \begin{equation}\label{e.ptm} \begin{array}{rl}  S+ E \xrightarrow{\R_1} C_1 \xrightarrow{\R_2} P+E \\ P+D \xrightarrow{\R_3} C_2 \xrightarrow{\R_4} S+D \end{array}\end{equation}
	 We define the state vector as $x=[s,e,c_1,p,d,c_2]^T$. The corresponding ODEs can be written as:
	 \begin{equation} \dot x=\frac{d}{dt}\begin{bmatrix}s\\e\\c_1\\p\\d\\ c_2 \end{bmatrix}=\left[\begin{array}{rrrr} -1 & 0 & 0 & 1 \\ -1 & 1 & 0 & 0 \\  1 & -1 & 0 & 0 \\ 0 & 1 & -1 & 0  \\ 0 & 0 & -1 & 1 \\ 0 & 0 & 1 & -1 \end{array}\right]\begin{bmatrix}R_1(s,e)\\R_2(c_1)\\R_3(p,d)\\R_4(c_2) \end{bmatrix} = \Gamma R(x).
	 	\end{equation}
	 	The network admits three conservation laws which are $s+c_1+p+c_2=s_{tot}$, $e+c_1=e_{tot}$, $d+c_2=d_{tot}$. Hence, any given vector $\bx\in\mathbb R_{\ge0}^6$ determines, $s_{tot},e_{tot},d_{tot}$, and hence it determines the stoichiometric class $\Cs_\bx$ which is three dimensional, polyhedral, and compact.
	 	
	 	As mentioned before,  $R$ only need to satisfy AK1-AK3. Hence,  its Jacobian $\partial{R}/{\partial x}\in\mathscr K_\Ns$, where $\mathcal K_\Ns$ is set of all matrices with the following sign pattern over the positive orthant:
\[	 	\begin{bmatrix}  + & + & 0 & 0 & 0 &0 \\ 0 & 0 & + & 0 & 0 & 0 \\ 0  & 0 & 0 & + & + & 0 \\ 0 & 0 & 0 & 0 & 0 &+ \end{bmatrix}\]
For a given $\bx$, the corresponding extent-of-reaction dynamics can be written as:
\[\dot\xi = \left[\begin{array}{l} R_1(\bx_1-\xi_1+\xi_4,\bx_2-\xi_1+\xi_2)\\ R_2(\bx_3+\xi_1-\xi_2) \\ R_3(\bx_4+\xi_2-\xi_3,\bx_5-\xi_3+\xi_4)\\R_4(\bx_6+\xi_3-\xi_4)  \end{array}\right].\]}
		\subsection{Graphical Lyapunov Functions}
		\mybox{\paragraph{Example (continued)} Let us consider \eqref{e.ode} with an admissible $R$. Using results from \cite{MA_cdc14,PWLRj,MA_LEARN}, it can be shown that the following function: $V(x)=\max\mathcal R-\min\mathcal R$ \cite{MA_LEARN}, where $\mathcal R=\{R_1(s,e),R_2(c_1),R_3(p,d),R_4(c_2)\}$ is positive-definite with respect to the set of steady states and non-increasing for any choice of $R$.  In addition, note that it can be written as $V=\tV \circ R$, where $\tV$ is given as:
		\begin{equation}\label{e.tV_ptm}\footnotesize \tV(r)=\| C r \|_\infty=\left\| \left[ \begin{array}{rrrr} -1 & 0 & 0 & 1\\ -1 & 1 & 0 & 0\\ 1 & 0 & -1 & 0\\ 0 & 1 & -1 & 0\\ 0 & 1 & 0 & -1\\ 0 & 0 & 1 & -1 \end{array}\right] r \right\|_\infty.\end{equation}}
	
	
	In the above example, the function $\tV$ depends only on the graphical nature of a given network, we call it a robust Lyapunov function or a graphical Lyapunov function. In order to offer a formal definition of $\tV$, we examine the non-increasingness condition for $V=\tV \circ R$. This amounts to	$(\partial \tV/{\partial r})({\partial R}/{\partial x}) \Gamma R(x) \le 0$ for all $x$.  Since we need $\tV$ to work for any admissible rate $R$, it can be verified with the stronger condition $(\partial \tV/{\partial r})K \Gamma r \le 0$ for all $r$ and for any admissible Jacobian matrix $K\in\mathcal K_\Ns$.  This motivates the following definition:
		
	\begin{definition} Let $\Ns=(\Ss,\Rs)$ be given. A locally Lipschitz function $\tV: \mathbb R^\nu \to \mathbb R_{\ge 0}$ is a \graphicalLF (GLF) for  $\Ns$ if the following holds:
		\begin{enumerate} \item it is \emph{structurally positive-definite with respect to the set of steady states}, i.e., $\exists \hV:\mathbb R^n \to \mathbb R_{\ge0}$ which is locally Lipschitz, $\ker\hV|_{\Im\Gamma}=\{0\}$, and  $\tV\equiv \hV \circ \Gamma $, and
			\item $\forall r\in\mathbb R_{\ge0}^{\nu}, \forall K \in \mathcal K_\Ns$, $\frac{\partial{\tV}}{\partial r}(r) K\Gamma r \le 0$. 
		\end{enumerate}
	\end{definition}
		
	\begin{remark}Since $V$ is not assumed to be continuously differentiable, the gradient above is defined in terms of the upper Dini's derivative.\end{remark}
		\begin{remark}If the $\tV(r)=\|Cr\|$ for some norm, then condition 1 is satisfied if there exists a matrix $B$ such that $C=B\Gamma$ and $\ker(B\Gamma)=\ker(\Gamma)$.\end{remark}
	
 
	
	In order to characterize GLFs,	we write the non-increasingness condition   using \eqref{e.dR} as follows:
	\begin{equation} \label{e.rode} \frac{\partial \tV}{\partial r}K\Gamma r =  \frac{\partial \tV}{\partial r}  \sum_{\ell=1}^s \bar\rho_\ell E_{i_\ell j_\ell} \Gamma r = \sum_{\ell=1}^s \bar\rho_\ell \overbrace{(e_{j_\ell}\gamma_{i_\ell}^T)}^{Q_\ell} r=  \sum_{\ell=1}^s \bar\rho_\ell Q_\ell r\le 0,\end{equation}
		where  $e_j$ is a member of the standard basis of $\mathbb R^\nu$, and $\gamma_i$ is the $i$th row of $\Gamma$. 
	Since the coefficients $\bar\rho_1,..,\bar\rho_s$ are arbitrary nonnegative numbers, this motivates the following definition:
	\begin{definition}
		Let $\tV: \mathbb R^\nu\to\mathbb R_{\ge0}$ be a locally-Lipschitz function, and let $Q_1,..,Q_s \in \mathbb R^{\nu\times\nu}$. Then, we say that $\tV$ is a common Lyapunov function for the set of linear systems $\dot r_1=Q_1 r,..,\dot r_s=Q_s r$ if: \begin{enumerate} \item  $\ker\tV=\bigcap_{\ell=1}^s \ker Q_\ell$, and 
			\item $(\partial \tV/\partial r)Q_\ell r\le0$ for all $\ell=1,..,s$.
		\end{enumerate}
	\end{definition}
	We are ready to state our the characterization as follows:
	\begin{theorem}[\cite{MA_cdc14,MA_LEARN}] A function $\tV$ is an GLF for a given network iff $\tV$ is a common Lyapunov function for the set of linear systems $\dot r = Q_1 r, ..., \dot r = Q_s r$. 
	\end{theorem}


	\mybox{\paragraph{Example (continued)}  We are still considering the network \eqref{e.ptm}. Note that we can write the following:
		\begin{align*}\frac{\partial R}{\partial x}\Gamma&= {\footnotesize \begin{bmatrix}\rho_1 & 0 & 0 & 0 & \rho_2 & 0 \\ 0 & 0 & \rho_3 & 0 & 0 & 0 \\
					0 & \rho_4 & 0 & 0 & 0 & \rho_5 \\ 0 & 0 &0 	& \rho_6 & 0 & 0 \end{bmatrix}}{\scriptsize \left[\begin{array}{rrrr} -1 & 0 & 0 & 1 \\ 0 & 1 & -1 & 0 \\ 1 & -1 & 0 & 0 \\ 0 & 0 & 1 & -1 \\ -1 & 1 & 0 & 0 \\ 0 & 0 & -1& 1 \end{array}\right]} \\  &= {\tiny \rho_1\begin{bmatrix} -1 & 0 &0 & 1 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\  0 & 0 & 0 & 0 \end{bmatrix}+\rho_2 \begin{bmatrix} -1 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\  0 & 0 & 0 & 0 \end{bmatrix} + \rho_3 \begin{bmatrix} 0 & 0 & 0 & 0 \\ 1 & -1 & 0 & 0 \\ 0 & 0 & 0 & 0 \\  0 & 0 & 0 & 0 \end{bmatrix} } \\ & { \tiny \quad +\rho_4 \begin{bmatrix} 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 1 & -1 & 0 \\  0 & 0 & 0 & 0 \end{bmatrix} +\rho_5 \begin{bmatrix} 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\  0 & 0 & -1 & 1  \\  0 & 0 & 0 & 0 \end{bmatrix}  +\rho_6  \begin{bmatrix} 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\    0 & 0 & 0 & 0 \\ 0 & 0 & 1 & -1  \end{bmatrix} } \\
			&{\small =\sum_{\ell=1}^6 \rho_\ell Q_\ell }  
		\end{align*}
		It can be verified that the function $\tV$ defined in \eqref{e.tV_ptm} is indeed a common Lyapunov function for the set of rank-one linear systems $\dot r=Q_\ell r, \ell=1,..,6$.
		}
	%
	
	\subsubsection{Application to concentration and extent-of-reaction dynamics}
\paragraph{Concentration dynamics} The next result shows that the GLF will give us a concrete Lyapunov function for each given $R$.
	\begin{proposition}[\cite{MA_cdc14,MA_LEARN}]
		Consider a network $\Ns=(\Ss,\Rs)$, and consider \eqref{e.ode} with a fixed admissible $R$. Assume that $\tV$ is a GLF for $\Ns$. Then, $V=\tV\circ R$ is Lyapunov function for \eqref{e.ode}, i.e., it is positive definite with respect to the set of steady states, and $\dot V(x)\le0$ for all $x$.
	\end{proposition}
	\begin{remark}
		The function $\dot V$  is defined as $\dot V(x):=\limsup_{h\to 0^+} (V(x+h\Gamma R(x))-V(x))/h$, and it exists everywhere since $V$ is locally-Lipschitz \cite{yoshizawa}.
	\end{remark}
%
%
%
%
%
  
	
  \paragraph{Extent-of-reaction dynamics} We first define what it means for an extent-of-reaction system to admit a Lyapunov function:
	\begin{definition} Consider the extent-of-reaction system \eqref{e.xiode} $\dot\xi=R(\bx+\Gamma\xi)$. Then, a locally-Lipschitz function $\tV:\mathbb R^\nu\to\mathbb R_{\ge0}$ is said to be a Lyapunov function for \eqref{e.xiode} if:
		\begin{enumerate}
			\item $\tV(\xi)\ge0$ for all $\xi$ and $\ker\tV=\ker\Gamma$, and
			\item $\dot\tV(\xi)\le0$ for all $\xi$. 
		\end{enumerate}
	\end{definition}
	
	
	As might be expected, we show that a GLF gives us a Lyapunov function for the extent-of-reaction system as stated below, and is proved in the appendix:
	\begin{proposition}\label{xi_GLF}
		Consider a network $\Ns=(\Ss,\Rs)$,  and let $R$ be an admissible rate. Consider the extent-of-reaction system \eqref{e.xiode} $\dot\xi=R(\bx+\Gamma\xi)$. Assume that $\bx$ is a steady state for \eqref{e.ode}. If   $\tV$ is a GLF for $\Ns$, then $\tV$ a Lyapunov function for the extent-of-reaction system \eqref{e.xiode}. 
	\end{proposition}
 
	\subsection{Concentration dynamics as a quotient of extent-of-reaction dynamics}
	The extent-of-reaction system has some peculiarities. Considering \eqref{e.xiode}, note that $\xi(0)=\xi^*+v$ will give rise to the same exact trajectory for any $v\in\ker\Gamma$. Moreover, when the system \eqref{e.ode} is at a steady-state, the system \eqref{e.xiode} exhibits an unbounded trajectory which is linear in time.  Therefore, in this subsection, we study  the relationship between concentration dynamics \eqref{e.ode} and extent-of-reaction dynamics \eqref{e.xiode} more formally. 
 
Fix a vector $\bx\in\mathbb R_{+}^n$.	Consider a system $\dot\xi=g(\xi)=R(\bx+\Gamma x)$, $\xi\in\mathbb R^\nu$, and let $\psi_t:\mathbb R^\nu\to\mathbb R^\nu$ be the associated flow for a given $t\ge0$. Similarly, consider the system $\dot x=f(x)=\Gamma R(x)$, $\xi\in\Cs_\bx:=\bx+\Im\Gamma$, and let $\varphi_t:\Cs_\bx\to\Cs_\bx$ be the associated flow.  Define the following mapping $\Phi:\mathbb R^\nu \to\Cs_\bx$ as 
\begin{equation}\label{Phi} \Phi(\xi):=\bx+\Gamma \xi. \end{equation}
Using \eqref{rel_x_xi}, we have $\Phi\circ\psi_t=\varphi_t$ for all $t\ge 0$. We are interested now in finding an inverse $\Psi:\Cs_\bx \to \mathbb R^\nu$. To that end, let us think of the stoichiometry matrix $\Gamma$ as a surjective linear operator $\Gamma:\mathbb R^\nu\to\Im\Gamma$. Hence, there exists another linear operator $G:\Im\Gamma\to\mathbb R^\nu$ which satisfies $\Gamma G(z)=z$ for all $z\in\Im\Gamma$. Note that $G$ is not necessarily unique.\footnote{A particular construction of $G$ is as follows. Let $q=rank(\Gamma)$, then let $U_1\in\mathbb R^{\nu\times q}$ be any full-column rank matrix whose columns form a basis for $(\ker\Gamma)^\perp$, and let $U_2\in\mathbb R^{\nu\times \nu-q}$ be a matrix whose columns form a basis for $\ker\Gamma$. Then, any vector $\xi\in\mathbb R^\nu$ can be written as $\xi=U_1\xi_1+U_2\xi_2$. Recall that $x-\bx=\Gamma\xi$. Substituting the decomposition of $\xi$, we get $x-\bx=\Gamma U_1 \xi_1+\Gamma U_2 \xi_2=\Gamma U_1 \xi_1$. Since $\Gamma U_1$ has full-column rank, then it has a left inverse, which is not necessarily unique. Let $(\Gamma U_1)^\dagger$ be such an inverse, e.g. the Moore-Penrose pseudoinverse.  Hence, we can write $\xi_1=(\Gamma U_1)^\dagger(x-\bx)$. Then, we get $\xi=U_1(\Gamma U_1)^\dagger (x-\bx)+U_2 \xi_2$ where $\xi\in\mathbb R^{\nu-q}$ is any arbitrary vector. Finally, we get $G:\Im\Gamma\to\mathbb R^\nu$ as $G(z)= U_1(\Gamma U_1)^\dagger z+U_2 \xi_2$, where $\xi_2$ is arbitrary. In particular, we can set $\xi_2=0$ and get the linear operator $G= U_1(\Gamma U_1)^\dagger $ satisfying $\Gamma Gz=z$ for all $z\in\Im\Gamma$. } From now on, we fix the choice of $G$. Hence, we can write $\Psi:\Cs_\bx\to\mathbb R^\nu$ as 
\begin{equation} \label{Psi}
	\Psi(x)=G(x-\bx),
\end{equation} 

We can summarize our construction as follows:
\begin{theorem}\label{bisimulation}
Let $\Ns=(\Ss,\Rs)$ be a network, and fix $\bx\in\mathbb R_{+}^n$.  Denote $\Cs_\bx:=\bx+\Im\Gamma$. Let $\varphi_t,\psi_t$ be the flows corresponding to \eqref{e.ode},\eqref{e.xiode}, respectively. Let $\Phi$ be defined as in \eqref{Phi}, and let $\Psi$ be given as in \eqref{Psi} for some $G$ {satisfying} $\Gamma G(z)=z$ for all $z\in\Im\Gamma$.
Let $\tV:\mathbb R^\nu\to \mathbb R_{\ge0}$ be a locally Lipschitz function. Then, the following diagram commutes:
	\begin{center}
		% Figure removed
	\end{center}
\end{theorem}

\paragraph{The dual GLF}
Given a network $\Ns$ and a GLF $\tV$, note that $(\tV\circ\Psi)(x)$ is also a Lyapunov function on $\Cs_\bx$. We formalize this next.
\begin{definition}
	Given a network $\Ns$ and a GLF $\tV$. Let $G:\Im \Gamma\to\Im\Gamma$ be any operator that satisfies $\Gamma G(z)=z$. Then, $\hV:=\tV\circ G$ is called a dual GLF.
\end{definition}
 Since $G$ is non-unique, then $\hV$ is non-unique. Consider a network $\Ns$ with a given $\bx$ that has a steady state $\bx$. Then, we claim that $V(x)=\hV(x-\bx)$ is a Lyapunov function for \eqref{e.ode} whenever $x(0)\in\Cs_\bx$. Positive definiteness is evident. We can verifying non-increasingness of $\tV$ by writing:
\[	\frac{d}{dt}V(\varphi_t(x))=\frac{d}{dt}\hV(\varphi_t(x)-\bx)=\frac{d}{dt}\tV(\psi_t(\Psi(x)) \le 0,\]
where the last inequality follows from Proposition \ref{xi_GLF}. 

%
 
  
Immediate results of the discussion above can be written as follows:
 \begin{corollary}\label{th.equiv}Let $\Ns$ be given, and let $G:\Im \Gamma\to\Im\Gamma$ be any operator that satisfies $\Gamma G(z)=z$. Then, 
 	\begin{enumerate}
 		\item if $\tV$ is a GLF for $\Ns$, then  $\hV:=\tV \circ G$ is a dual GLF for $\Ns$.
 		\item if $\hV$ is a dual GLF for $\Ns$, then $\tV:=\hV\circ\Gamma$ is a GLF for $\Ns$.
 	\end{enumerate}  
 \end{corollary}
 	\begin{corollary}
 	Consider a network $\Ns=(\Ss,\Rs)$, and consider \eqref{e.ode} with a fixed admissible $R$ and a steady state $\bx$. Assume that $\hV$ is a dual GLF for $\Ns$. Then, $V(x)=\hV(x-\bx), x\in\Cs_\bx$ is Lyapunov function for \eqref{e.ode}.
 \end{corollary}
 
 
 	 	\mybox{\paragraph{Example (cont'd)}  Consider the BIN \eqref{e.ptm} and the introduced GLF \eqref{e.tV_ptm}. Then, the dual GLF is given as follows $\hV(z)=\|Bz\|_\infty$, where $B$ is any matrix satisfying $C=B\Gamma$, which is not unique in this case. One possible choice is the following,
 	 		\begin{equation}\label{Bptm}B=   \left[\begin{array}{rrrrrr} 1 & 0 & 0 & 0 & 0 & 0\\ 0 & 1 & 0 & 0 & 0 & 0\\ 0 & 0 & 1 & 1 & 0 & 0\\ 0 & 0 & 0 & 1 & 0 & 0\\ 0 & 0 & 0 & 1 & -1 & 0\\ 0 & 0 & 0 & 0 & 0 & 1 \end{array} \right ].\end{equation}
 	 	 Therefore, for any given steady state $\bx \in\mathbb R_+^n$, $\hV(x-\bx)$ is a Lyapunov function for \eqref{e.ode} on $\Cs_\bx$. 
 	
 }
 
	\subsection{The class of $\ell_\infty$-norm GLFs.} We  focus now on GLFs of the form $\tV(r)=\|C r\|_\infty$ for some matrix $C=[c_1,..,c_m]^T \in \mathbb R^{m\times \nu}$, $m>0$. We assume, without loss of generality, that $C$ is a minimal representation of $\tV$ which means that for all $k=1,..,m$, the set $\{r| \tV(r)=c_k^Tr\}$ has non-empty interior. This is since if $C$ is not minimal, we can remove rows from $C$ to make it a minimal representation. 
 
 
	
	
In our previous work, we had the following characterization:
\begin{theorem}[\cite{MA_cdc14,MA_LEARN}]\label{th.metzler}
	Given a network $(\Ns,\Rs)$. Then, the following two statements are equivalent:
	\begin{enumerate}
		\item $\tV(r)=\|Cr\|_\infty$ is a GLF for $\Ns$,
		\item 	$\ker C=\ker \Gamma$ and 
		there exist Metzler matrices $\tl\Lambda_{\ell} \in \mathbb R^{2m\times 2m}, \ell=1,..,s$  such that 
		\begin{equation}\label{e.metzler} \tilde C Q_\ell = \tl\Lambda_{\ell} \tilde C, ~\mbox{and}~ \tl\Lambda_\ell \mathbf 1 =0, \ell=1,..,s, \end{equation}  	
		where $\tilde C=[C^T,-C^T]^T$. 
	\end{enumerate}  
\end{theorem}

In this paper, we will use an alternative form of Theorem \ref{th.metzler} which is stated and proven in the appendix:

\begin{corollary}\label{cor}
	Given a network $(\Ns,\Rs)$. Then, the following two statements are equivalent:
	\begin{itemize}
		\item $\tV(r)=\|Cr\|_\infty$ is  a GLF,
		\item $\exists B$ with $\rank \Gamma=\rank (B\Gamma)$ such that $C=B\Gamma$ and 
		there exist matrices $\Lambda_{\ell} \in \mathbb R^{m\times m}, \ell=1,..,s$  such that 
		\[  C Q_\ell = \Lambda_{\ell}  C ~\mbox{and}~ \mu_\infty(\Lambda_\ell) \le 0, \ell=1,..,s. \]
	\end{itemize}
\end{corollary}
 

\paragraph{The dual $\ell_\infty$ GLF}  Using Corollary \ref{th.equiv}, and recalling that $C$ can be written as $C=B\Gamma$, we get the function $\hV$ as:
\begin{equation}
	\hV(z)=\|CG(x)\|_\infty= \|B\Gamma Gz\|_\infty= \|Bz\|_\infty,
\end{equation}
	where the last equality follows since $\Gamma G(z)=z$ for all $z\in\Im\Gamma$. 
	
	
	\begin{corollary}\label{th.equiv}Let $\Ns$ be given. Then,
		\begin{enumerate}
			\item If  $\tV(r)=\|C r\|_\infty$ is a GLF for $\Ns$, then $\hV(z)=\|Bz\|_\infty$ is a dual GLF for $\Ns$ where $C=B\Gamma$.
		\item If $\hV(z)=\|Bz\|_\infty$ is a dual GLF for $\Ns$, then $\tV(r)=\|B\Gamma\|_\infty$ is a GLF for $\Ns$.
		\end{enumerate} 
\end{corollary}

\begin{remark} A  version of Corollary \ref{th.equiv} was proven in \cite{MA_cdc14,MA_LEARN} using a different argument.
	\end{remark}
%
%
%
%
%
%

 	\mybox{\paragraph{Example (cont'd)}  Consider the BIN \eqref{e.ptm} and the introduced GLF \eqref{e.tV_ptm}. Corollary \ref{cor} asserts the existence of six matrix $\Lambda_\ell,\ell=1,..,s$.  Using the algorithms developed in \cite{PWLRj,MA_LEARN} we can find the matrices as follows:
 		{\tiny \begin{align*}\Lambda_1&=\left[\begin{array}{rrrrrrrr} -1 & 0 & 0 & 0 & 0 & 0\\ 0 & -1 & 0 & 0 & 1 & 0\\ 0 & 0 & -1 & 0 & 0 & -1\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0 \end{array}\right],\Lambda_2=\left[\begin{array}{rrrrrrrr} -1 & 0 & 0 & 0 & -1 & 0\\ 0 & -1 & 0 & 0 & 0 & 0\\ 0 & 0 & -1 & 1 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0 \end{array}\right], \Lambda_3=\left[\begin{array}{rrrrrrrr} 0 & 0 & 0 & 0 & 0 & 0\\ 0 & -1 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 1 & -1 & 0 & 0\\ -1 & 0 & 0 & 0 & -1 & 0\\ 0 & 0 & 0 & 0 & 0 & 0 \end{array}\right],\\
 			\Lambda_4&=\left[\begin{array}{rrrrrrrr} 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & -1 & -1 & 0 & 0 & 0\\ 0 & 0 & 0 & -1 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 1 & -1 \end{array}\right], \Lambda_5=\left[\begin{array}{rrrrrrrr} 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ -1 & 0 & -1 & 0 & 0 & 0\\ 0 & 0 & 0 & -1 & 1 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & -1 \end{array}\right], \Lambda_6=\left[\begin{array}{rrrrrrrr} -1 & 0 & -1 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 1 & -1 & 0\\ 0 & 0 & 0 & 0 & 0 & -1 \end{array}\right]\end{align*}.}
 		
	
}
	 
	

	
%
%
%
%

	\section{Contraction and Nonexpansivity}
	%
	\subsection{Preliminaries}

	The are several formulations of contraction theory. We are going to present the formulation that utilizes  logarithmic norms (a.k.a, matrix measures).
	
	\begin{definition}[Logarithmic Norms] Let $(\mathbb R^,|.|)$ be a normed space, and let $\|.\|_*$ be the corresponding induced matrix norm on $\mathbb R^{n\times n}$. Then, the associated matrix measure (a.k.a, logarithmic norm) can be defined as follows for a matrix $A \in \mathbb R^{n \times n}$:
		\begin{equation}\label{e.lognorm}\mu_*(A):=\lim_{h \to 0^+} \frac{ \|I+hA\|_*-1}h.\end{equation}
	%
	\end{definition}
	\begin{remark}The logarithmic norm can be evaluated explicitly for the standard norms. For instance, the following expression can be used for the $\ell_\infty$ norm:
		\begin{equation}\label{e.lognorm_inf}\mu_\infty(A) = \max_{i} \left (a_{ii} + \sum_{j \ne i} |a_{ij}|\right ).\end{equation}
		%
	\end{remark}
	
	
	For a dynamical system, negativity of the logarithmic norm can be linked to contraction. This result has been stated in different forms, we state the result as follows.
	\begin{theorem}[\cite{sontag14}] \label{th.contraction}Consider a dynamical system $\dot x = f(x)$ defined on a convex subset $X$ of $\mathbb R^n$. Let $| \cdot |_*$ be a norm in $\mathbb R^n$ and $\|.\|_*$ the induced matrix norm on $\mathbb R^{n \times n}$. Assume that
		\[ \forall x \in X, \quad \mu_*\left ( \frac{\partial f}{\partial x} (x) \right )  \le c. \]
		Then for any two solutions $\varphi(t;x), \varphi(t;y)$ of the dynamical system, the following condition holds:
		\begin{equation}
			| \varphi(t;x) - \varphi(t;y) |_* \le e^{c t} | x -y|_*.
		\end{equation}
	\end{theorem}
	
	Note that if $c<0$  the solutions of the system are exponentially contracting. If $c=0$, then the system is non-expansive. %

\subsection{Nonexpansion in  concentration coordinates}
 We state our first major result, and then develop the required theory to prove it.
 

\begin{theorem}\label{th.mainB}
	Let $\Ns=(\Ss,\Rs)$ be a given network, and let {$\tV(r) = \|B \Gamma r\|_\infty$  be a GLF.}
	Let $\bx \in \mathbb R_{\ge 0}^n$ be any positive state, and define $|{x}|_B := \|B(x-\bx)\|_\infty$.
	Then, $|.|_B$ is a norm on  $\Cs_\bx:=(\bx+\Im\Gamma)\cap\mathbb R_{\ge0}^n$, and 
	for any two solutions $x_1(\cdot)$ and $x_2(\cdot)$ of $\dot x=\Gamma R(x)$ in $\Cs_{\bx}$, we have
	\[
	|x_1(t)-x_2(t)|_B \;\leq\; |x_1(0)-x_2(0)|_B \quad \mbox{for all}\; t\geq0.
	\]
	In other words, the dynamics of $\Ns$  are non-expansive in each stoichiometric class with respect to the $B$-norm.
	%
	%
	%
	\end{theorem}
	Our approach to prove the theorem is to show that the appropriate logarithmic norm is non-positive. However, since
	Theorem \ref{th.mainB} is stated with respect to the functional $|.|_B$ on the vector space $\Im\Gamma$,   we need to introduce the necessary notions.
	

\subsubsection{Norms with non-square weightings}
	Let $(\mathbb R^n,|.|)$ be a normed space. Let $B\in\mathbb R^{m\times n}$. We are interested in studying the pair $(\cV,|.|_B)$ where $\cV$ is  a vector subspace of $\mathbb R^n$ and $|.|_B$ is the weighted operator $|.|_B: z\mapsto |Bz| $. Such operators are usually studied using the notion of Minkowski functionals or gauge functions \cite{thompson96}. However, to keep the discussion self-contained, we develop the required notions here.  For easier future reference, we state a simple equivalency first:
	\begin{lemma}\label{lem.linalg}
		Let $B\in\mathbb R^{m\times n}$, let $\cV\subset \mathbb R^n$ be a vector subspace, and let $\Gamma$ be any matrix such that $\Im\Gamma=\cV$. Then the following are equivalent:
		\begin{enumerate}
			\item $B\cV=\cV$.
			\item $\Im(B\Gamma)=\Im(\Gamma)$.
			\item $\ker(B\Gamma)=\ker(\Gamma)$.
			\item $\ker B|_{\Im \Gamma}=\{0\}$.
		\end{enumerate}
	\end{lemma}
%
%
%
%
%
%
\noindent Next, we show next that the pair $(\cV,|.|_B)$ is indeed a normed space.
	\begin{lemma}\label{lem.normB}
		Let $(\mathbb R^n,|.|)$ be a normed space. Let $B\in\mathbb R^{m\times n}$, and let $\cV\subset \mathbb R^n$ be a vector subspace. If $B\cV=\cV$, then the pair $(\cV,|.|_B)$ is a normed space.
	\end{lemma}
	\begin{proof}
		Since $\cV$ is a vector subspace of $\mathbb R^n$, we immediately get that $|.|_B$ is semi-norm on  $\cV$. To show that it is a norm, we need to show that for all $x\in\cV$, $|x|_B=0$ iff $x=0$.  But this follows immediately from the previous lemma since we assumed that $B\cV=\cV$ .  
	\end{proof}
 

\subsubsection{Induced matrix norms and logarithmic norms restricted to a subspace}
Let   $(\mathbb R^n, |.|)$ be  a normed Euclidean space, and let $\cV \subset \mathbb R^n$ be a vector space.   
Next, we can define the $\cV$-induced matrix norm of a matrix $J \in\mathbb R^{n\times n}$ as $\|J\|_{\cV}:=\sup_{|z|=1, z\in\cV} |Jz|$, which is well-defined since the set $\{z: |z|=1, z\in\cV\}$ is compact. 


   Similarly, we need to define the corresponding induced $(B,\cV)$-matrix norm of a matrix $J \in \mathbb R^{n\times n}$ as we did above.  %
   As in Lemma \ref{lem.normB}, we assume that  $B\cV=\cV$, i.e., the dimension of $\cV$ does not reduce if we multiple each vector by $B$ from the left. Using Lemma \ref{lem.linalg},  any vector $z\in\cV$ can be also written as $LBz$ for some matrix $L\in\mathbb R^{m\times n}$. Therefore, we can write:
\[ \sup_{\substack{|Bz|=1\\ z\in\cV }} |BJz|= \sup_{\substack{|Bz|=1\\ z\in\cV }} |BJLBz| \le \|BJL\| \sup_{\substack{|Bz|=1\\ z\in\cV }} |Bz|= \|BJL\| <\infty, \]
which ensures that we show that the induced $(B,\cV)$-matrix norm of any matrix $J$ is well-defined.
Therefore, we have the following definition.
\begin{definition} Consider the normed  space $(\mathbb R^n, |.|)$. Let $\cV \subset \mathbb R^n$ be a vector space, and let $B\in\mathbb R^{m\times n}$ be a matrix satisfying $B\cV=\cV$. Then,
	\begin{enumerate} \item The induced $(B,\cV)$-norm of a matrix $J\in\mathbb R^{n\times n}$ restricted to $\cV$ is defined as:
		\[ \|J\|_{B,\cV}:= \sup_{|z|_B=1,z\in\cV} |BJz|. \]
		\item The $(B,\cV)$-logarithmic norm of a matrix $J\in\mathbb R^{n\times n}$ is defined as:
		\[ \mu_{B,\cV}(J):= \lim_{h\to0^+} \frac{ \|I+hJ\|_{B,\cV} -1 } h. \] 
	\end{enumerate} 
\end{definition}
%
	%
%

\subsubsection{Computation of the logarithmic norm}
In order to proof Theorem \ref{th.mainB}, we set $\cV=\Im\Gamma$. Hence, we need to show that the $(B,\Im\Gamma)$-logarithmic norm of the Jacobian is non-positive. This is stated as follows.

%
%

\begin{lemma}\label{mainlemmaB}
	Let a network $\Ns=(\Rs,\Ss)$ be given. Fix an arbitrary $\bx \in \mathbb R_{\ge0}^n$. Assume that there exists an GLF for $\Ns$ of the form $\tV(r)=\|B\Gamma r\|_\infty$.   
	%
	Then, \[ \forall K \in \mathcal K_\Ns, \mu_{B,\Im\Gamma} ( \Gamma K ) \le 0.\]%
	
	%
\end{lemma}

 
 
Before proceeding to the proof of Lemma \ref{mainlemmaB}, we need to decompose matrices of the form $\Gamma K$, where $K\in\mathcal K_\Ns$ into a sum of rank-one matrices as we did in  \eqref{e.rode}. Using \eqref{e.calK}, we can write :
\begin{equation}\label{e.decomp} \Gamma K  = \sum_{\ell=1}^s \bar\rho_\ell  \Gamma  E_{j_\ell i_\ell }   = \sum_{\ell=1}^s \bar\rho_\ell  \overbrace{(\Gamma_{j_\ell}e_{i_\ell}^T)}^{J_\ell} =  \sum_{\ell=1}^s \bar\rho_\ell J_\ell,\end{equation}
where $\Gamma_1,..,\Gamma_n$ are the columns of $\Gamma$.  In addition, we need the following basic lemma:
\begin{lemma}\label{simplelemma} Given a network $\Ns$. Let $J_\ell, Q_\ell, \ell_1,..,s$ be defined as above. 
	\begin{enumerate}
		\item $\forall \ell, \Gamma Q_\ell = J_\ell \Gamma$.
		\item Let $C,B,\Lambda_\ell,\ell=1,..,s$ be defined as in Corollary \ref{cor}, and let $D$ be matrix whose rows form a basis for the left null space of $\Gamma$.  then there exist matrices $Y_1,..,Y_s$ such that $BJ_\ell=\Lambda_\ell B+Y_\ell D$, $\ell=1,..,s$. 
	\end{enumerate}
\end{lemma}
\begin{proof}
	\begin{enumerate} 
		\item $\Gamma Q_\ell = \Gamma e_{j_\ell} \gamma_{i_\ell}^T = \Gamma_{j_\ell} \gamma_{i_\ell}^T= \Gamma_{j_\ell} e_{i_\ell}^T \Gamma = J_\ell \Gamma $. 
		\item Using Corollary \ref{cor}, we have $CQ_\ell = \Lambda_\ell C$. Then we get:
		\[ B\Gamma Q_\ell = \Lambda_\ell B \Gamma \Longrightarrow B J_\ell \Gamma = \Lambda_\ell B \Gamma \Longrightarrow (BJ_\ell - \Lambda_\ell B) \Gamma =0.\]
		Therefore, the rows of $BJ_\ell - \Lambda_\ell B$ belong to the left null space of $\Gamma$. Hence, there exist matrices $Y_1,..,Y_s$ such that $BJ_\ell-\Lambda_\ell B=Y_\ell D$, $\ell=1,..,s$. By rearranging we get the required expression.
	\end{enumerate} 
\end{proof}

\paragraph{Proof of Lemma \ref{mainlemmaB}}
Using the previous definitions, we are interested in bounding the following expression:
\[\mu_{B,\Im\Gamma}(\Gamma K) := \limsup_{h\to 0^+} \frac{ \|I+h \Gamma K\|_{B,\Im\Gamma} -1 } h, \]
where $K\in \mathcal K_\Ns$.
We proceed as follows:
\begin{align*}
	\left \|   I + h \Gamma K    \right \|_{B,\Im\Gamma} & = \sup_{\substack{\|Bz\|_\infty =1 \\ z\in\Im\Gamma }} \left \| B \left ( I + h\Gamma K  \right ) z \right \|_\infty
	\mathop{=}^{(\star)}   \sup_{\substack{\|Bz\|_\infty =1 \\ z\in\Im\Gamma }} \left \| Bz + h   \sum_{\ell=1}^s \rho_\ell B J_\ell z   \right \|_\infty
	\\& \mathop{=}^{(\clubsuit)}   \sup_{\substack{\|Bz\|_\infty =1 \\ z\in\Im\Gamma }} \left \| Bz + h   \sum_{\ell=1}^s \rho_\ell(\Lambda_\ell B+Y_\ell D)z   \right \|_\infty \mathop{=}^{(\spadesuit)}   \sup_{\substack{\|Bz\|_\infty =1 \\ z\in\Im\Gamma }} \left \| \left ( I + h   \sum_{\ell=1}^s \rho_\ell \Lambda_\ell\right ) Bz   \right \|_\infty \\
	\\ &  \le      \sup_{\substack{\|Bz\|_\infty =1 \\ z\in\Im\Gamma }} \left \| I + h   \sum_{\ell=1}^s \rho_\ell   \Lambda_{\ell}     \right \|_\infty \|B z \|_\infty = \left \| I + h   \sum_{\ell=1}^s \rho_\ell   \Lambda^{\ell}     \right \|_\infty,
\end{align*}
where the equality $(\star)$ follows from \eqref{e.decomp}, equality $(\clubsuit)$ follows from Lemma \ref{simplelemma}, and equality $(\spadesuit)$ follows since $Dz=0$ for all $z\in\Im \Gamma$.

Therefore, the expression of the logarithmic norm above can be written as:
\begin{equation}\label{e.lognorm_ineq2}  \mu_{B,\Im\Gamma}(\Gamma K)  \le \mu_\infty \left ( \sum_{\ell=1}^s \rho_\ell   \Lambda^{\ell} \right ) \le   \sum_{\ell=1}^s \rho_\ell  \mu_\infty( \Lambda^{\ell}) = 0, \end{equation}
where the inequalities follow by the subadditivity of the logarithmic norm and Corollary \ref{cor}.  \hfill $\square$

\paragraph{Proof of Theorem \ref{th.mainB}} It follows immediately from combining Theorem \ref{th.contraction} and Lemma \ref{mainlemmaB} since the Jacobian of \eqref{e.ode} can always be written as $\Gamma K$ for some $K\in\mathcal K_\Ns$ as in \eqref{e.dR}.  \hfill $\square$

 
\subsubsection{Boundedness}

 
A BIN that is not conservative is not guaranteed to have bounded trajectories. In fact, non-expansivity does not preclude unboundedness. Nevertheless, if a network admits a steady state then we get boundedness as the following corollary shows. 

\begin{corollary}\label{cor.boundedness}
		Let $\Ns=(\Ss,\Rs)$ be a network that admits a GLF. Then, if a steady state $\bx$ exists, then all trajectories in $\Cs_\bx$ are bounded.
	\end{corollary}
	\begin{proof}
		We apply Theorem \ref{th.mainB} by comparing an arbitrary trajectory with $x_2(t)\equiv \bx$. 
	\end{proof}
 \begin{remark}
	If a network admits a GLF, 	it has been shown \cite{blanchini17} that    the existence of a non-degenerate positive steady state, implies global asymptotic stability. Non-degeneracy of the Jacobian can be tested easily as shown in \cite{blanchini14,MA_LEARN}.  However, Corollary \ref{cor.boundedness} does not assume non-degeneracy to show boundedness.
\end{remark}


\subsubsection{Alternative statement}
The results can be stated explicitly in the stoichiometric class by using a transformation. We provide the details below for completeness.  Recall that $D$ is a matrix whose rows form a basis for the left null space of $\Gamma$. Hence, let  $S=[S_1^T,D^T]^T$ where $S_1$ is any matrix chosen so $S$ is invertible.  Consider \eqref{e.ode} with a fixed vector $\bx$. We will use the following coordinate change:   \[ \tl z= S(x-\bx)=\begin{bmatrix} S_1 (x-\bx) \\ D(x-\bx) \end{bmatrix}=:\begin{bmatrix}\tl z_1 \\ \tl z_2 \end{bmatrix}. \] 
The dynamics of \eqref{e.ode} can be written as:
\[\dot{\tl z}= \begin{bmatrix} S_1 \\ D \end{bmatrix} 
\Gamma R(x)= \begin{bmatrix} S_1  \Gamma R(S^{-1} \tl z+\bx)) \\ 0 \end{bmatrix}, \]
where the second entry is zero since $D\Gamma=0$. 

Since we have $x(0)\in \Cs_{\bx}$, then $x(t)-{\bx} \in \Im \Gamma$ for all $t$, and we immediately get that $\tl z_2(t) = D(x-{\bx})=0$ for all $t$. Furthermore, let us write $S^{-1}=: [ U_1,U_2]$, where $U_1 \in \mathbb R^{n\times(n-d)},W_2\in\mathbb R^{n\times d}$, $d=\dim(\ker(\Gamma^T))$.

Therefore,

\[S^{-1} \tl z + \bx = [U_1,U_2]\begin{bmatrix}\tl z_1 \\ 0 \end{bmatrix} + \bx = U_1 \tl z_1 + \bx .\]

Finally we get the dynamics on the $n-d$ manifold as:
\begin{equation}\label{e.red_Sys} { \dot{\tilde{z}}_1 = S_1 \Gamma R(U_1 \tl z_1 + \bx ), ~\tl z_1(0)~\mbox{satisfies}~U_1 \tl z_1(0) + \bx\ge0 .}\end{equation}
In the new coordinates, the problem reduces to checking contraction of \eqref{e.red_Sys} with respect to the norm $\|.\|_{BU_1}: \tl z_1 \mapsto \|B U_1 \tl z_1 \|_{\infty}$.  Hence, we state the following corollary.
\begin{corollary}
	Let a network $\Ns$ be given.	Let $S,S_1,U_1$ be a matrices defined as above. Consider the ODE \eqref{e.red_Sys} whose Jacobian is $S_1  \Gamma \frac{\partial R}{\partial x} U_1$. Consider the norm $\|.\|_{BW_1}: \hat z_1 \mapsto \|BU_1\hat z_1\|_\infty$ and the associated logarithmic norm $\mu_{BW_1}$. Then, $\mu_{BW_1}(S_1 \Gamma \frac{\partial R}{\partial x}  U_1 )=\mu_{B,\Im\Gamma}(  \Gamma  \frac{\partial R}{\partial x}  ) \le 0$. In other words, the logarithmic norm of the reduced system is independent of the choice of $S_1$ and is non-positive. In addition,  consider any two solutions $\hat\varphi(t;\hat\ z_{1a}),\hat\varphi(t;\hat z_{1b})$ of \eqref{e.red_Sys}, then the following condition holds:
	\[ |\hat\varphi(t;\hat z_{1a})-\hat\varphi(t;\hat z_{1a})|_{BW_1} \le |\hat z_{1a}-\hat z_{1b}|_{BW_1},~\mbox{for all}~t\ge0.\]
\end{corollary}


 

\subsection{Nonexpansion of the extent-of-reaction system}
We can perform similar contraction analysis for the extent-of-reaction system, but thanks to Theorem \ref{bisimulation}, we can use Theorem \ref{th.mainB} to show the following immediately:
\begin{theorem}\label{th.mainC}
	Let $\Ns=(\Ss,\Rs)$ be a given network, and let {$\tV(r) = \|C r\|_\infty$  be a GLF.}
	Let $\bx \in \mathbb R_{\ge 0}^n$ be any positive state, and define $|{\xi}|_C := \|C\xi\|_\infty$.
	Then,  
	for any two solutions $\xi_1(\cdot)$ and $\xi_2(\cdot)$ of $\dot\xi=R(\bx+\Gamma \xi)$, we have
	\[
	|\xi_1(t)-\xi_2(t)|_C \;\leq\; |\xi_1(0)-\xi_2(0)|_C \quad \mbox{for all}\; t\geq0.
	\]
	%
	%
	%
	%
	\end{theorem}
	\begin{proof}
		With reference to the commutativity diagram in Theorem \ref{bisimulation} we have $x_1(t)=\Gamma \xi_1(t) + \bx $, and $x_2(t)=\Gamma \xi_2(t) + \bx$. Note that $x_1(t),x_2(t)\in\Cs_\bx$. Then, we can write the following:
		\begin{align*}
			|\xi_1(t)-\xi_2(t) |_C &= \| C ( \Psi(x_2(t))-\Psi(x_1(t))  ) \|_\infty = \| B\Gamma ( G(x_2(t)-\bx) - G(x_1(t)-\bx)  ) \|_\infty \\ 
			& = \| B ( x_2(t)-\bx -x_1(t) + \bx ) \|_\infty = \| B(x_2(t)-x_1(t) ) \|_\infty \\
			& \le \| B(x_2(0) - x_1(0))\|_\infty = \| B\Gamma ( \xi_2(0)- \xi_1(0)) \|_\infty = |x_2(0)-x_1(0)|_C,
		\end{align*} 
		where the first equality uses the commutativity diagram in Theorem \ref{bisimulation}, while the second equality uses \eqref{Psi}, the third equality uses the property that $\Gamma G(z)=z$ for all $z\in \Im\Gamma$, and the inequality follows from Theorem \ref{th.mainB}.
	\end{proof}
	 
	\subsection{Examples and discussion}

\mybox{\subsubsection{The PTM cycle (cont'd)}
Let us consider again the PTM cycle \eqref{e.ptm}.  Using Theorem \ref{th.mainB} the network is non-expansive with respect to the norm $|.|_B$ in each stoichiometric class, where $B$ is given by \eqref{Bptm}. 
Figure \ref{f.ptm_timetraj} shows a numerical simulation of the distance between pairs of trajectories  where it can be seen that they are approaching each other. In the next section, we will show that the system is strictly contractive over any compact set in the positive orthant. }

% Figure environment removed

\mybox{\subsubsection{An unstable system}
Non-expansivity does not imply boundedness. For example, let us consider an example studied in \cite{PWLRj}:
\begin{equation} \label{e.unstable} C \longrightarrow A, ~ \emptyset \longrightarrow B, ~ A+B \longrightarrow C.\end{equation}
	This system admits the GLF $\tV(r)=\|B\Gamma r\|_\infty$, where 
	\[B=\begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 1 & -1 & 0 \end{bmatrix}. \]
	Note, however, that the trajectories of the system can become unbounded when a steady state fails to exists. Figure \ref{f.ptm_timetraj}-b) shows unbounded trajectories. Nevertheless, the distance between the trajectories never increases.}
	
	
%
%
%
%
	
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
	
\section{Strict contraction over compact sets}

In the previous section we have shown that any network admitting a GLF is non-expansive. In this section, we will strengthen this to show strict contraction over arbitrary compact sets. 

\subsection{Background: siphons and persistence}
 We introduce the concept of siphons, which will assist us in establishing strict contraction over compact sets.
A dynamical system defined over the positive orthant is said to be persistent if trajectories that start in the interior of the positive orthant do not approach the boundary asymptotically \cite{angeli07p}. This is also known as non-extinction since it is tantamount to asking that species are initially present in the BIN do not go extinct. 

An approach that can be used to establish persistence is based on the theory of siphons \cite{angeli07p}. 

\begin{definition} Let $\Ns=(\Ss,\Rs)$ be a network. A set $P\subset\mathscr S$ is said to be a siphon if a set the satisfies the following statement:
	$\forall X \in P$, if $X$ is a product of some reaction $\R_j$, then $\exists X'\in P$ such that $X'$ is a reactant of $\R_j$. In addition,
	a siphon is \emph{trivial} if it contains no support of a conservation law, and it is \textit{critical} otherwise.
\end{definition}

 
%
%
%
%
%

If a network contains only trivial siphons, then its trajectories that start in the positive orthant do not approach the boundary asymptotically for any choice of kinetics, which is known as structural persistence \cite{angeli07p}. In fact, a slightly stronger statement can be established. If we choose all our initial conditions from a compact set $K\subset \mathbb R_+^n$, then the corresponding trajectories are uniformly separated from the boundary. This is shown in the following result which is a modification of a corresponding result in \cite{MA_TAC22}:
\begin{lemma}
	\label{eventuallyK}
	Consider a BIN with uniformly bounded solution,  {i.e.,}
	for all compact $K \subset \mathbb{R}_{+}^n$, there exists  $\tilde{K}_1$ compact such that $\varphi(t, K) \subset \tilde{K_1}$ for all $t \geq 0$.
	Assume that all siphons are trivial.
	Then, 
	for any compact $K \subset (0,+\infty)^n$, there exist a number $\ve>0$ and
	a convex and compact $\tilde{K}$  in $[\ve,+ \infty)^n$ such that
	$\varphi (t, K) \in \tilde{K}$ for all $t \geq 0$.  
\end{lemma}
\begin{proof}
Using \cite[Lemma 5]{MA_TAC22},  there exist $\ve>0$ and
$\tilde{K_1}$ compact in $[\ve,+ \infty)^n$ such that
$\varphi (t, K) \in \tilde{K}_1$ for all $t \geq 0$.
Our desired \emph{convex} $\wt K$ is any compact and convex set that satisfies $\wt K_1\subset \wt K \subset [\ve,\infty)^n$. One such set is the closed box $[\ve,x_1^*]\times .. \times [\ve,x_n^*]$, where $x^* \in\wt K_1$ is the supremum point of $\wt K_1$.
\end{proof}
 
\begin{remark}
	Using Corollary \ref{cor.boundedness}, boundedness follows for networks admitting a GLF whenever a steady state exists.
\end{remark}

 \subsection{Strict contraction over positive compact sets}
Recall that the upper bound in \eqref{e.lognorm_ineq2} is $\mu_\infty(\sum_{\ell=1}^s \rho_\ell \Lambda^\ell)$ which is written in term of the partial derivatives of $R$. Therefore, we if can establish a \emph{lower bound} on the partial derivatives of $R$, then we can hope to show strict contraction. However, for networks that contain bimolecular reactions, this is not generally possible since the partial derivatives of $R$ can get arbitrarily small when we get close to the boundary. Hence, our technique will be to establish contraction with respect to \emph{compact sets}. If we assume the absence of trivial siphons, then Lemma \ref{eventuallyK} assures us that there is a uniform positive lower bound on all the states. We will show that this can be applied to few examples and then we state the general result.


  
 
 
 \paragraph{Example 1: Three-body binding}  Unlike standard two-body binding, three-body binding \cite{douglass13} requires to a bridging molecule $B$ for the formation of a trimeric complex $\rm ABC$. The reaction network can be written as follows:
 \begin{align*} 
 	\rm A+ \rm B &\xrightleftharpoons[R_5]{R_1} {\rm AB}, ~ { \rm C+B} \xrightleftharpoons[R_6]{R_3} {\rm BC},\\
 	{\rm A+BC } & \xrightleftharpoons[R_7]{R_2} {\rm ABC} \xrightleftharpoons[R_4]{R_8} {\rm C+AB}.
 	\end{align*}
 The network admits the GLF $\tV(r)=\|\Gamma r\|_\infty$, so $B=I$. The certificate matrices $\Lambda_\ell, \ell=1,..,8$ can be computed via Corollary \ref{cor}, and hence  the upper bound \eqref{e.lognorm_ineq2} can be computed explicitly. 
 
 For that purpose, let $x_1=[{\rm A}], x_2=[{\rm C}], x_3=[{\rm B}], x_4=[{\rm AB}], x_5=[{\rm BC}],x_6=[{\rm ABC}],$ and define $\rho_{ji}:=\partial{R_j}/{\partial x_i}$, then \eqref{e.lognorm_ineq2} gives us:
 \[\mu_{\scriptscriptstyle \tiny \infty,\Im \Gamma}(J)\le -\min\{\rho_{11}+\rho_{21},\rho_{32}+\rho_{42},\rho_{13}+\rho_{43}, \rho_{34}+\rho_{54},\rho_{65}+\rho_{75},\rho_{26}+\rho_{86}\}:=\rho(x) <0, \]
 where the last inequality holds for all $x \in \mathbb R_+^n$ by assumption AK3.  Therefore, this establishes that the Jacobian has a strictly negative logarithmic norm over the positive orthant, however, this falls short of proving strict contraction.  Nevertheless, the situation can be remedied for compact sets by using Lemma \ref{eventuallyK}. So, let $K\subset \mathbb R_+^{n}$ be any positive compact. By Lemma \ref{eventuallyK} there exists an $\ve>0$ and a convex and compact $\wt K$ such that $\varphi(t;K)\in \wt K \subset [\ve,\infty)^n$ for all $t\ge0$
  So let $c :=\min_{x\in\wt K} \rho(x) >0$. So if $x(0),y(0) \in K \subset \Cs_\bx$, then we get strict contraction
  \[
  |{x(t)-y(t)}|_\infty \;\leq\; e^{-ct} |{x(0)-y(0)}|_\infty \; \mbox{for all}\; t\geq0.
  \]
 
 \paragraph{Example 2: PTM cycle (continued)} Let us continue considering the PTM cycle. In order to bound the logarithmic norm using \eqref{e.lognorm_ineq2}, we need to examine the expression $\mu_\infty(\sum_{\ell=1}^s \rho_\ell(x) \Lambda^\ell)$. By substituting the values of $\Lambda_\ell,\ell=1,..,6$ we get:  (the dependence on $x$ is dropped for notational simplicity)
\[  \left(\begin{array}{cccccc} -\rho_{1}-\rho_{2}-\rho_{6} & 0 & -\rho_{6} & 0 & -\rho_{2} & 0\\ 0 & -\rho_{1}-\rho_{2}-\rho_{3} & 0 & 0 & \rho_{1} & 0\\ -\rho_{5} & -\rho_{4} & -\rho_{1}-\rho_{2}-\rho_{4}-\rho_{5} & \rho_{2} & 0 & -\rho_{1}\\ 0 & 0 & \rho_{3} & -\rho_{3}-\rho_{4}-\rho_{5} & \rho_{5} & 0\\ -\rho_{3} & 0 & 0 & \rho_{6} & -\rho_{3}-\rho_{6} & 0\\ 0 & 0 & 0 & 0 & \rho_{4} & -\rho_{4}-\rho_{5}-\rho_{6} \end{array}\right).\]

Let $J$ be a square matrix, remember that $\mu_\infty(J)=\max_i \sigma_i(J)$, where $\sigma_i(J)=[J]_{ii}+\sum_{j\ne i} |J_{ij}|$. For the matrix above, note that $\sigma_{3}(\sum_{\ell=1}^s \rho_\ell \Lambda_\ell)$ and  $\sigma_{5}(\sum_{\ell=1}^s \rho_\ell \Lambda_\ell)$ are both \emph{identically} zero. Hence,  $\mu_\infty(\sum_{\ell=1}^s \rho_\ell \Lambda^\ell)=0$ for all possible choices of $\rho_1,..,\rho_6$. This situation precludes using an argument similar to the previous example. Nevertheless, we can adapt a trick used in \cite{margaliot16} by using a non-singular diagonal matrix $P$ to define a scaled norm $|.|_{PB}$.  Hence, the equation $B\Gamma (\sum_{\ell} \rho_\ell Q_\ell ) = (\sum_{\ell} \rho_\ell \Lambda_\ell ) B \Gamma $, can be written as 
\begin{equation}
PB\Gamma \left (\sum_{\ell} \rho_\ell Q_\ell \right ) = \left (\sum_{\ell} \rho_\ell P\Lambda_\ell P^{-1} \right )  B \Gamma.
\end{equation}
Hence, we can evaluate $\mu_\infty(\sum_{\ell=1}^s \rho_\ell P\Lambda^\ell P^{-1})$ for the scaled norm.
In our case,  let $P=\diag([1+\theta,1+\theta,1,1+\theta,1,1+\theta])$ for some small $\theta>0$. 
Then, we get
\begin{align*} \mu_\infty\left(\sum_{\ell=1}^s \rho_\ell P\Lambda^\ell P^{-1}\right)& = -\min\{\rho_1-\theta (\rho_2+\rho_6), \rho_3+\rho_2-\theta\rho_1, (\rho_1+\rho_2+\rho_4+\rho_5) \tfrac{\theta}{1+\theta}, \\ & \qquad \qquad \quad \rho_4- \theta(\rho_3+\rho_5), (\rho_3+\rho_6)\tfrac{\theta}{1+\theta}, \rho_5+\rho_6-\theta \rho_4   \}.\end{align*}


We are going to show that it is always possible to choose $\theta$ such that the expression above is negative over an appropriate set. So let $K$ be a positive compact set.  By Lemma \ref{eventuallyK} there exists an $\ve>0$ and a convex and compact $\wt K$ such that $\varphi(t;K)\in \wt K \subset [\ve,\infty)^n$ for all $t\ge0$.  Define the following constant:
\[ \bar\theta=\min_{x\in\wt K}\left\{ \frac{\rho_1}{\rho_2+\rho_6}, \frac{\rho_{3}+\rho_2}{\rho_1}, \frac{\rho_4}{\rho_3+\rho_5}, \frac{\rho_5+\rho_6}{\rho_4}\right\}>0, \]
which exists and is well-defined due to the positivity and compactness of $\wt K$. Therefore, for any choice of $\theta \in (0,\bar\theta)$, the logarithmic norm  $\mu_\infty\left(\sum_{\ell=1}^s \rho_\ell P\Lambda^\ell P^{-1}\right)$ is negative over $\wt K$, and is upper bounded by $-c$ for some $c>0$. Therefore,   if $x(0),y(0) \in K \subset \Cs_\bx$, then we get strict contraction
 \[
 |{x(t)-y(t)}|_{PB} \;\leq\; e^{-ct} |{x(0)-y(0)}|_{PB} \; \mbox{for all}\; t\geq0.
 \]
 
 \subsubsection{General results}
 \paragraph{Weakly contractive matrices} As seen in the last example, a matrix whose logarithmic norm is identically zero can be scaled using a diagonal transformation into a matrix with a \emph{negative} logarithmic norm. We state this more generally using the following definition:
 \begin{definition}\label{def.weakcontract}
 	Let $J \in \mathbb R^{n\times n}$ be matrix that satisfies $\sigma_i(J)\le 0, i=1,..,n$. Let $S_-:= \{ i \in{1,..,n} | \sigma_i(J)<0  \}$, and $S_0:= \{ i \in{1,..,n} | \sigma_i(J)=0  \}$. Assume that for any $i\in S_0$ there exists an index $k_i \in S_-$ such that $J_{ik_i}>0$, then $J$ is said to be \emph{weakly contractive}.
 \end{definition}
 
 Since we want to apply this to matrices of the form $\sum_\ell \rho_\ell \Lambda_\ell$, then we state the following basic Lemma which follows immediately.
 \begin{lemma} Let square matrices $\Lambda_\ell,\ell=1,..,s$ be given such that $\mu_\infty(\Lambda_\ell)\le0$, and denote $J(\rho_1,..,\rho_s)=\sum_\ell \rho_\ell \Lambda_\ell$. Then, $J(\rho_1,..,\rho_s)$ is weakly contractive for all $\rho_1,..,\rho_s$ iff  $J(\rho_1,..,\rho_s)$ is weakly contractive for at least one positive tuple $(\rho_1,..,\rho_s)$.
 \end{lemma}
 Therefore, we can verify that $\sum_\ell \rho_\ell \Lambda_\ell$ is weakly contractive by checking that $\sum_\ell   \Lambda_\ell$ is weakly contractive. 
 
 We state our result next. 
 \begin{theorem}
 	Let a network $\Ns=(\Ss,\Rs)$ be given and assume that it admits a GLF $\tV(r)=\|B\Gamma r\|_\infty$. Let $\Lambda_1,..,\Lambda_s$ be the corresponding matrices defined in Corollary \ref{cor}. Furthermore assume that  $J=\sum_{\ell=1}^s  \Lambda_\ell$ is weakly contractive. Let $S_0, S_-$ be as in Definition \ref{def.weakcontract}.
 	
 	
 	Let $K\subset \Cs_\bx \cap \mathbb R_+^n$ be any compact set, and assume that $\varphi(t,K)$ is uniformly bounded. Then
 	for any two solutions $x_1(\cdot)$ and $x_2(\cdot)$ of $\dot x=\Gamma R(x)$ that start in $K$, there exists $\theta>0$, $c>0$ such that
 	\[
 	|x_1(t)-x_2(t)|_{PB} \;\leq\; e^{-ct}|x_1(0)-x_2(0)|_{PB} \quad \mbox{for all}\; t\geq0,
 	\]
 	where $P$ is a diagonal matrix defined as $p_{ii}=1$ if $i\in S_0$, and $p_{ii}=1+\theta$ if $i \in S_-$.
 \end{theorem}
 
Recall the three-body binding example. Remember that we did not need to scale the norm. In general, if a GLF takes the form $\tV(r)=\| \Theta \Gamma r \|_\infty$ for some diagonal matrix $\Theta$, then no scaling is required. This is stated by the following theorem which is proved in the appendix.
\begin{theorem}\label{th.strict_contraction}	Let a network $\Ns=(\Ss,\Rs)$ be given and assume that it admits a GLF $\tV(r)=\|\Theta\Gamma r\|_\infty$ for some non-negative diagonal matrix $\Theta$.  
	
	
	Let $K\subset \Cs_\bx \cap \mathbb R_+^n$ be any compact set, and assume that $\varphi(t,K)$ is uniformly bounded. Then
	for any two solutions $x_1(\cdot)$ and $x_2(\cdot)$ of $\dot x=\Gamma R(x)$ that start in $K$, there exists   $c>0$ such that
	\[
	|x_1(t)-x_2(t)|_{\Theta} \;\leq\; e^{-ct}|x_1(0)-x_2(0)|_{\Theta} \quad \mbox{for all}\; t\geq0.
	\]
\end{theorem}




 

\appendix
\section*{Appendix: Additional Proofs}
\paragraph{Proof of Proposition \ref{xi_GLF}} Remember that $\tV$ is locally Lipschitz function. Hence, the gradient of $\tV$ exists almost everywhere. When it exists, write $\dot \tV(\xi)$ as follows:
\[\dot\tV(\xi)=\frac{\partial \tV}{\partial \xi} R(\bx+\Gamma \xi) = \frac{\partial \hV}{\partial \xi}  \left (R(\bx) + \frac{\partial R}{\partial x}(x_\xi^*)\Gamma \xi \right )= \frac{\partial \tV}{\partial \xi}   \frac{\partial R}{\partial x}(x_\xi^*)\Gamma \xi  , \]
where $x_\xi^*:=\bx+\ve \Gamma \xi$ for some $\ve\in(0,1)$. The second equality above follows from applying the Mean-value theorem to the single-valued function $h(\ve)=R(\bx+\ve\Gamma \xi)$. The third equality can be shown as follows: By definition, $\exists \hV$ such that $\tV=\hV \circ \Gamma$. Since the gradient of $\tV$ exists, we can write $\partial \tV/\partial \xi=(\partial \tV/\partial z) \Gamma$, but since $\bx$ is a steady state, then $\Gamma R(\bx)=0$, and hence the first term vanishes. Similar to \eqref{e.decomp}, we can decompose the Jacobian as follows:
\[ 	\dot\tV(\xi)=  \sum_{\ell=1}^s \rho_\ell(x_\xi^*) \frac{\partial \tV}{\partial \xi}  Q_\ell \xi \le 0,\]
where the last inequality follows since $\tV$ is a common Lyapunov function for the systems $\dot r_1=Q_1 r,...,\dot r_s=Q_s r$.  The inequality holds for all $\xi$ using Lemma 9 in \cite{MA_TAC22}.\hfill $\square$

\paragraph{Proof of Corollary \ref{cor}} 	The first statement is equivalent to the statement that $\ker\Gamma=\ker C$. Hence, we focus on the second statement. For the first direction, assume that the statement in Theorem \ref{th.metzler} holds. Fix $\ell$. Since $\tl\Lambda_\ell \in\mathbb R^{2m\times 2m}$, then we can write: (we drop the dependence on $\ell$ to simplify the notation)
\begin{equation}\label{e0}\tl\Lambda_\ell=\begin{bmatrix} \Lambda_{11} & \Lambda_{12} \\ \Lambda_{21} & \Lambda_{22} \end{bmatrix},\end{equation}
where $\Lambda_{11},\Lambda_{12},\Lambda_{21},\Lambda_{22}\in\mathbb R^{n\times n}$. By the statement in Theorem \ref{th.metzler}, $\Lambda_{11},\Lambda_{22}$ are Metzler and $\Lambda_{12},\Lambda_{21}$ are non-nonnegative. In addition, \eqref{e.metzler} can be written as:
\begin{align} \label{e2a} CQ_\ell = (\Lambda_{11}  - \Lambda_{12})  C \\ \label{e2b} CQ_\ell = (\Lambda_{22}  - \Lambda_{21} ) C \end{align}
Note that we can assume, w.l.o.g, that $\Lambda_{22} =\Lambda_{11} $, $\Lambda_{21}=\Lambda_{12} $. Hence, we define $\Lambda_{\ell}:=\Lambda_{11}  - \Lambda_{12} $. It remains to show that $\mu_{\infty}(\Lambda_{\ell}) \le 0$. To that end, recall that $\mu_\infty(\Lambda_\ell)=\max_{i} \lambda_{ii}^{(\ell)}+\sum_{j\ne i}|\lambda_{ij}^{(\ell)}|$. Hence, we write:
\begin{align}\label{e1}\lambda_{ii}^{(\ell)}+\sum_j|\lambda_{ij}^{(\ell)}|= \lambda_{ii}^{11}-\lambda_{ii}^{12}+ \sum_{j\ne i} |\lambda_{ij}^{11}-\lambda_{ij}^{12}|\mathop{\le}^{(\star)} \lambda_{ii}^{11}+\lambda_{ii}^{12}+ \sum_{j\ne i} (\lambda_{ij}^{11}+\lambda_{ij}^{12}) \mathop{=}^{(\clubsuit)}0,
\end{align}
where the inequality $(\star)$ follows since $\lambda_{ii}^{12},\lambda_{ij}^{11},\lambda_{ij}^{12}$ are nonnegative, and equality $(\clubsuit)$ follows from  $\tl\Lambda_\ell \mathbf 1=0$. Hence, we have found a matrix $\Lambda_\ell$ that satisfy $\mu_\infty(\Lambda_\ell)\le 0$. 

Next, we  show the other direction. Fix $\ell$. Assume we have a matrix $\Lambda_\ell$ that satisfies $\mu_\infty(\Lambda_\ell)\le 0$.  Hence, for all $i$ we have $\lambda_{ii}^{(\ell)}\le0$ and $\sigma_i:=-(\lambda_{ii}^{(\ell)}+\sum_j|\lambda_{ij}^{(\ell)}|)\ge0$.  We are going to construct two matrices $\Lambda_{11},\Lambda_{12}$ elementwise as follows assuming $i\ne j$: $\lambda_{ij}^{(11)}:=\max\{\lambda_{ij}^{(\ell)},0\}+\sigma_i/{(2n)}, \lambda_{ij}^{(12)}:=\max\{-\lambda_{ij}^{(\ell)},0\}+\sigma_i/{(2n)}$,  $\lambda_{ii}^{(12)}:=\sigma_i/{(2n)}$, $\lambda_{ii}^{(11)}:=\lambda_{ii}^{(\ell)}+\sigma_i/{(2n)}$, where the latter is non-positive since $\lambda_{ii}^{(\ell)}+\sigma_i/{(2n)}\le \lambda_{ii}^{(\ell)}+\sigma_i \le \lambda_{ii}^{(\ell)}-\lambda_{ii}^{(\ell)}=0$.  Finally, we define $\Lambda_{22}:=\Lambda_{11},\Lambda_{21}:=\Lambda_{12}$. Define $\tl\Lambda_{\ell}$ as in \eqref{e0} which can be verified to be a Metzler matrix  satisfying  $\tl\Lambda_\ell \mathbf 1 = 0$ and \eqref{e2a}-\eqref{e2b}. \hfill $\square$


\paragraph{Proof of Theorem \ref{th.strict_contraction}}
	Remember that $\rho_1,..,\rho_s$ correspond to the nonzero entries of $\partial R/\partial x$ which are strictly positive in $\mathbb R_+^n$ by AK3, hence the proof can be accomplished by showing that $\mu_{\infty}\left(\sum_{\ell=1}^s \rho_\ell    \Lambda_\ell \right )<0$ for any positive $\rho_1,..,\rho_s$. Assume $\Theta \in \mathbb R^{m\times m}$. Since $\Theta$ might have zero rows, the function can be written (by reordering species if necessary) as $\tV(r)=\|[\Theta_d,O] \Gamma r\|_{\infty}$, where $\Theta_d$ is an $n_d \times n_d$ positive diagonal matrix for some $n_d \le n$. Hence, $\tV(r)=\max_{i\in\{1,..,n_d\}}\gamma_i^T r$. To show the statement, it is sufficient to show that for each $i \in \{1,..,  n_d  \}$, there exists $\ell \in \{1,..s\}$ such that $\lambda_\ell^{(ii)}  + \sum_{j \ne i} |\lambda_\ell^{(ik)}| <0$. \\
	By AS1, $\gamma_i$ is orthogonal to a positive vector, and hence must have a strictly negative element, say $\gamma_{ij}$. Hence, this implies that $X_i$ is a reactant of $\mathbf R_j$, and $\partial R_j/\partial x_i$ is nonzero. Let $\Lambda_\ell$ the matrix (defined in Corollary 8) corresponding to the reactant-reactant pair $(X_i,\R_j)$. Therefore, it can be seen it is possible to choose the $i$th row of $\Lambda_\ell$ as follows: $\lambda_\ell^{(ii)}= -\theta_{ii}$ and $\lambda_\ell^{(ij)}= 0, i \ne j$. Hence, $\lambda_\ell^{(ii)} + \sum_{j \ne i} |\lambda_\ell^{(ij)}| = -\theta_{ii} <0$. \strut \hfill $\square$
 
\begin{thebibliography}{10}
	
	\bibitem{ideker01}
	Trey Ideker, Timothy Galitski, and Leroy Hood.
	\newblock A new approach to decoding life: systems biology.
	\newblock {\em Annual review of genomics and human genetics}, 2(1):343--372,
	2001.
	
	\bibitem{alon06}
	Uri Alon.
	\newblock {\em An Introduction to Systems Biology: Design Principles of
		Biological Circuits}.
	\newblock Chapman and Hall/CRC, London, United Kingdom, 2006.
	
	\bibitem{feinberg87}
	M.~Feinberg.
	\newblock Chemical reaction network structure and the stability of complex
	isothermal reactors--{I}. {T}he deficiency zero and deficiency one theorems.
	\newblock {\em Chemical Engineering Science}, 42(10):2229--2268, 1987.
	
	\bibitem{erdi89}
	P.~{\'E}rdi and J.~T{\'o}th.
	\newblock {\em Mathematical models of chemical reactions: theory and
		applications of deterministic and stochastic models}.
	\newblock Manchester University Press, Manchester, United Kingdom, 1989.
	
	\bibitem{sontag01}
	E.~D. Sontag.
	\newblock Structure and stability of certain chemical networks and applications
	to the kinetic proofreading model of {T}-cell receptor signal transduction.
	\newblock {\em IEEE Transactions on Automatic Control}, 46(7):1028--1047, 2001.
	
	\bibitem{morohashi02}
	Mineo Morohashi, Amanda~E Winn, Mark~T Borisuk, Hamid Bolouri, John Doyle, and
	Hiroaki Kitano.
	\newblock Robustness as a measure of plausibility in models of biochemical
	networks.
	\newblock {\em Journal of Theoretical Biology}, 216(1):19--30, 2002.
	
	\bibitem{prill05}
	Robert~J Prill, Pablo~A Iglesias, and Andre Levchenko.
	\newblock Dynamic properties of network motifs contribute to biological network
	organization.
	\newblock {\em PLoS biology}, 3(11):e343, 2005.
	
	\bibitem{bailey01}
	J.~E. Bailey.
	\newblock Complex biology with no parameters.
	\newblock {\em Nature Biotechnology}, 19(6):503--504, 2001.
	
	\bibitem{gupta22}
	Ankit Gupta and Mustafa Khammash.
	\newblock Universal structural requirements for maximal robust perfect
	adaptation in biomolecular networks.
	\newblock {\em Proceedings of the National Academy of Sciences},
	119(43):e2207802119, 2022.
	
	\bibitem{araujo23}
	Robyn~P Araujo and Lance~A Liotta.
	\newblock Universal structures for adaptation in biochemical reaction networks.
	\newblock {\em Nature Communications}, 14(1):2251, 2023.
	
	\bibitem{horn72}
	F.~Horn and R.~Jackson.
	\newblock General mass action kinetics.
	\newblock {\em Archive for Rational Mechanics and Analysis}, 47(2):81--116,
	1972.
	
	\bibitem{anderson11}
	D.~F. Anderson.
	\newblock A proof of the global attractor conjecture in the single linkage
	class case.
	\newblock {\em SIAM Journal on Applied Mathematics}, 71(4):1487--1508, 2011.
	
	\bibitem{angeli07p}
	D.~Angeli, P.~De~Leenheer, and E.~D. Sontag.
	\newblock A {P}etri net approach to the study of persistence in chemical
	reaction networks.
	\newblock {\em Mathematical Biosciences}, 210(2):598--618, 2007.
	
	\bibitem{angeli10}
	D.~Angeli, P.~De~Leenheer, and E.~Sontag.
	\newblock Graph-theoretic characterizations of monotonicity of chemical
	networks in reaction coordinates.
	\newblock {\em Journal of Mathematical Biology}, 61(4):581--616, 2010.
	
	\bibitem{PWLRj}
	M.~Ali Al-Radhawi and David Angeli.
	\newblock New approach to the stability of chemical reaction networks:
	Piecewise linear in rates {L}yapunov functions.
	\newblock {\em IEEE Trans. on Automatic Control}, 61(1):76--89, 2016.
	
	\bibitem{MA_LEARN}
	M~Ali Al-Radhawi, David Angeli, and Eduardo~D Sontag.
	\newblock A computational framework for a {L}yapunov-enabled analysis of
	biochemical reaction networks.
	\newblock {\em PLoS Computational Biology}, 16(2):e1007681, 2020.
	
	\bibitem{MA_cdc14}
	M.~Ali Al-Radhawi and D.~Angeli.
	\newblock Robust {L}yapunov functions for complex reaction networks: An
	uncertain system framework.
	\newblock In {\em Proceedings of the IEEE 53rd Conference on Decision and
		Control (CDC)}, pages 3101--3106, Dec 2014.
	
	\bibitem{blanchini14}
	F.~Blanchini and G.~Giordano.
	\newblock Piecewise-linear {L}yapunov functions for structural stability of
	biochemical networks.
	\newblock {\em Automatica}, 50(10):2482 -- 2493, 2014.
	
	\bibitem{MA_MCSS23}
	M~Ali Al-Radhawi.
	\newblock Graphical characterizations of robust stability in biological
	interaction networks.
	\newblock {\em Mathematics of Control, Signals, and Systems,~{\mdseries In
			press}}, 2023.
	
	\bibitem{MA_TAC22}
	David Angeli, Muhammad~Ali Al-Radhawi, and Eduardo~D Sontag.
	\newblock A robust {L}yapunov criterion for nonoscillatory behaviors in
	biological interaction networks.
	\newblock {\em IEEE Transactions on Automatic Control}, 67(7):3305--3320, 2021.
	
	\bibitem{dahlquist58}
	Germund Dahlquist.
	\newblock {\em Stability and error bounds in the numerical integration of
		ordinary differential equations}.
	\newblock PhD thesis, Almqvist \& Wiksell, 1958.
	
	\bibitem{lozinskii58}
	Sergei~Mikhailovich Lozinskii.
	\newblock Error estimate for numerical integration of ordinary differential
	equations. i.
	\newblock {\em Izvestiya Vysshikh Uchebnykh Zavedenii. Matematika}, (5):52--90,
	1958.
	
	\bibitem{lohmiller98}
	W.~Lohmiller and J-J. Slotine.
	\newblock On contraction analysis for non-linear systems.
	\newblock {\em Automatica}, 34(6):683--696, 1998.
	
	\bibitem{nijmeijer06}
	A.~V. Pavlov, N.~Wouw, and H.~Nijmeijer.
	\newblock {\em Uniform output regulation of nonlinear systems: a convergent
		dynamics approach}.
	\newblock Springer Science \& Business Media, 2006.
	
	\bibitem{sontag14}
	Z.~Aminzare and E.~D. Sontag.
	\newblock Contraction methods for nonlinear systems: A brief introduction and
	some open problems.
	\newblock In {\em Proc. 53rd IEEE Conf. on Decision and Control}, pages
	3835--3847, 2014.
	
	\bibitem{forni14}
	Fulvio Forni and Rodolphe Sepulchre.
	\newblock A differential {L}yapunov framework for contraction analysis.
	\newblock {\em IEEE Transactions on Automatic Control}, 59(3):614--628, 2014.
	
	\bibitem{bullo22}
	F~Bullo.
	\newblock Contraction theory for dynamical systems.
	\newblock {\em Kindle Direct Publishing}, 1:979--8836646806, 2022.
	
	\bibitem{sontag10}
	Eduardo~D Sontag.
	\newblock Contractive systems with inputs.
	\newblock {\em Perspectives in Mathematical System Theory, Control, and Signal
		Processing: A Festschrift in Honor of Yutaka Yamamoto on the Occasion of his
		60th Birthday}, pages 217--228, 2010.
	
	\bibitem{margaliot16}
	Michael Margaliot, Eduardo~D Sontag, and Tamir Tuller.
	\newblock Contraction after small transients.
	\newblock {\em Automatica}, 67:178--184, 2016.
	
	\bibitem{DiBernardo10}
	G.~Russo, M.~Di~Bernardo, and E.~D. Sontag.
	\newblock Global entrainment of transcriptional systems to periodic inputs.
	\newblock {\em PLoS computational biology}, 6(4):e1000739, 2010.
	
	\bibitem{vaghy23}
	Mih{\'a}ly~A V{\'a}ghy and G{\'a}bor Szederk{\'e}nyi.
	\newblock Persistence and stability of generalized ribosome flow models with
	time-varying transition rates.
	\newblock {\em Plos one}, 18(7):e0288148, 2023.
	
	\bibitem{jafarpour22}
	Saber Jafarpour and Samuel Coogan.
	\newblock Monotonicity and contraction on polyhedral cones.
	\newblock {\em arXiv preprint arXiv:2210.11576}, 2022.
	
	\bibitem{MA_dissertation}
	M.~{Ali Al-Radhawi}.
	\newblock {\em New Approach to the Stability and Control of Reaction Networks}.
	\newblock PhD thesis, Imperial College London, December 2015.
	
	\bibitem{yoshizawa}
	T.~Yoshizawa.
	\newblock {\em Stability theory by {L}iapunov's {S}econd {M}ethod}.
	\newblock Mathematical Society of Japan, Tokyo, 1966.
	
	\bibitem{thompson96}
	Anthony~C Thompson.
	\newblock {\em Minkowski geometry}.
	\newblock Cambridge University Press, 1996.
	
	\bibitem{blanchini17}
	F.~Blanchini and G.~Giordano.
	\newblock Polyhedral {L}yapunov functions structurally ensure global asymptotic
	stability of dynamical networks iff the jacobian is non-singular.
	\newblock {\em Automatica}, 86:183--191, 2017.
	
	\bibitem{douglass13}
	Eugene~F Douglass~Jr, Chad~J Miller, Gerson Sparer, Harold Shapiro, and David~A
	Spiegel.
	\newblock A comprehensive mathematical model for three-body binding equilibria.
	\newblock {\em Journal of the American Chemical Society}, 135(16):6092--6099,
	2013.
	
\end{thebibliography}

\end{document}
