We raise concerns and awareness regarding the generalization ability of deep learning models.
Despite recent methods outperforming baselines for various vision tasks, for a method to have a significant contribution to real-world applications, it must be reliable and robust.
Thus in this work, we highlight this shortcoming of recently proposed Transformer based image restoration models.
While the models proposed by \cite{chen2022simple} perform satisfactorily for image deblurring on non-perturbed samples, they fail to generalize when slight adversarial perturbations are added to the blurred images.
We acknowledge that the reduction in model complexity compared to Restormer is a step in the right direction, however, in this case, it comes at the expense of model robustness.
Therefore, we additionally employ adversarial training in an attempt to fix this shortcoming while also improving the quality of the reconstructed images.
We observe that adversarial training is able to reduce the spectral artifacts and also results in significant improvements in adversarial robustness of the image restoration models.
However, the extent of the improvement varied with the architectural design decisions.
Thus lastly, we investigate the design decisions that might lead to the occurrence of spectral artifacts and loss in robustness for the considered methods and find a an interesting ablation concerning the type of activation functions used when downsampling.