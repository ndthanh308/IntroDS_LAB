@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@misc{hooker2021compressed,
      title={What Do Compressed Deep Neural Networks Forget?}, 
      author={Sara Hooker and Aaron Courville and Gregory Clark and Yann Dauphin and Andrea Frome},
      year={2021},
      eprint={1911.05248},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hendrycks2019benchmarking,
      title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations}, 
      author={Dan Hendrycks and Thomas Dietterich},
      year={2019},
      eprint={1903.12261},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gu2022segpgd,
      title={SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and Boosting Segmentation Robustness}, 
      author={Jindong Gu and Hengshuang Zhao and Volker Tresp and Philip Torr},
      year={2022},
      eprint={2207.12391},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{hendrycks2020augmix,
      title={AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty}, 
      author={Dan Hendrycks and Norman Mu and Ekin D. Cubuk and Barret Zoph and Justin Gilmer and Balaji Lakshminarayanan},
      year={2020},
      eprint={1912.02781},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{hoffmann2021towards,
  title={Towards improving robustness of compressed CNNs},
  author={Hoffmann, J and Agnihotri, S and Saikia, Tonmoy and Brox, Thomas},
  booktitle={ICML Workshop on Uncertainty and Robustness in Deep Learning (UDL)},
  year={2021}
}

@article{relu,
  title={Deep learning using rectified linear units (relu)},
  author={Agarap, Abien Fred},
  journal={arXiv preprint arXiv:1803.08375},
  year={2018}
}

@InProceedings{ringing_artifacts,
author="Mosleh, Ali
and Langlois, J. M. Pierre
and Green, Paul",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Image Deconvolution Ringing Artifact Detection and Removal via PSF Frequency Analysis",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="247--262",
abstract="We present a new method to detect and remove ringing artifacts produced by the deconvolution process in image deblurring techniques. The method takes into account non-invertible frequency components of the blur kernel used in the deconvolution. Efficient Gabor wavelets are produced for each non-invertible frequency and applied on the deblurred image to generate a set of filter responses that reveal existing ringing artifacts. The set of Gabor filters is then employed in a regularization scheme to remove the corresponding artifacts from the deblurred image. The regularization scheme minimizes the responses of the reconstructed image to these Gabor filters through an alternating algorithm in order to suppress the artifacts. As a result of these steps we are able to significantly enhance the quality of the deblurred images produced by deconvolution algorithms. Our numerical evaluations using a ringing artifact metric indicate the effectiveness of the proposed deringing method.",
isbn="978-3-319-10593-2"
}


@ARTICLE{ssim,

  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},

  journal={IEEE Transactions on Image Processing}, 

  title={Image quality assessment: from error visibility to structural similarity}, 

  year={2004},

  volume={13},

  number={4},

  pages={600-612},

  doi={10.1109/TIP.2003.819861}}

@book{hamming,
  title     = "{T}ime {S}equence {A}nalysis in {G}eophysics",
  author    = "E.R. Kanasewich",
  year      = 1974,
  publisher = "The University of Alberta Press",
  address   = "London",
  pages =  {109,110},
  url = "https://www.uap.ualberta.ca/titles/658-9780888640741-time-sequence-analysis-in-geophysics-third-edition"  
}

@inproceedings{patchdeblur_iccp2013,
  author    = {Libin Sun and Sunghyun Cho and Jue Wang and James Hays},
  title     = {Edge-based Blur Kernel Estimation Using Patch Priors},
  booktitle = {Proc. IEEE International Conference on  Computational Photography},
  year      = {2013}}

@misc{agnihotri2023cospgd,
      title={CosPGD: a unified white-box adversarial attack for pixel-wise prediction tasks}, 
      author={Shashank Agnihotri and Steffen Jung and Margret Keuper},
      year={2023},
      eprint={2302.02213},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{pgd,
      title={Towards Deep Learning Models Resistant to Adversarial Attacks}, 
      author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
      year={2019},
      eprint={1706.06083},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{fgsm,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{grabinski2022frequencylowcut,
  title     = {FrequencyLowCut Pooling--Plug \& Play against Catastrophic Overfitting},
  author    = {Grabinski, Julia and Jung, Steffen and Keuper, Janis and Keuper, Margret},
  booktitle = {European Conference on Computer Vision},
  year      = {2022},
  url       = {https://arxiv.org/abs/2204.00491}
}

@misc{grabinski2023fix,
      title={Fix your downsampling ASAP! Be natively more robust via Aliasing and Spectral Artifact free Pooling}, 
      author={Julia Grabinski and Janis Keuper and Margret Keuper},
      year={2023},
      eprint={2307.09804},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{gelu,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2016},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@InProceedings{gopro,
  author = {Nah, Seungjun and Kim, Tae Hyun and Lee, Kyoung Mu},
  title = {Deep Multi-Scale Convolutional Neural Network for Dynamic Scene Deblurring},
  booktitle = {CVPR},
  month = {July},
  year = {2017}
}
%%Transformers
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}
@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

%%MLP mixer
@article{tolstikhin2021mlp,
  title={Mlp-mixer: An all-mlp architecture for vision},
  author={Tolstikhin, Ilya O and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and others},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={24261--24272},
  year={2021}
}
%%%ConvNext
@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11976--11986},
  year={2022}
}
%%Bit
@InProceedings{bit2020,
author="Kolesnikov, Alexander
and Beyer, Lucas
and Zhai, Xiaohua
and Puigcerver, Joan
and Yung, Jessica
and Gelly, Sylvain
and Houlsby, Neil",
title="Big Transfer (BiT): General Visual Representation Learning",
booktitle="European Conference on Computer Vision (ECCV)",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="491--507",
abstract="Transfer of pre-trained representations improves sample efficiency and simplifies hyperparameter tuning when training deep neural networks for vision. We revisit the paradigm of pre-training on large supervised datasets and fine-tuning the model on a target task. We scale up pre-training, and propose a simple recipe that we call Big Transfer (BiT). By combining a few carefully selected components, and transferring using a simple heuristic, we achieve strong performance on over 20 datasets. BiT performs well across a surprisingly wide range of data regimes---from 1 example per class to 1M total examples. BiT achieves 87.5{\%} top-1 accuracy on ILSVRC-2012, 99.4{\%} on CIFAR-10, and 76.3{\%} on the 19 task Visual Task Adaptation Benchmark (VTAB). On small datasets, BiT attains 76.8{\%} on ILSVRC-2012 with 10 examples per class, and 97.0{\%} on CIFAR-10 with 10 examples per class. We conduct detailed analysis of the main components that lead to high transfer performance.",
isbn="978-3-030-58558-7"
}
%%%%Resnet
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@article{ali2021xcit,
  title={Xcit: Cross-covariance image transformers},
  author={Ali, Alaaeldin and Touvron, Hugo and Caron, Mathilde and Bojanowski, Piotr and Douze, Matthijs and Joulin, Armand and Laptev, Ivan and Neverova, Natalia and Synnaeve, Gabriel and Verbeek, Jakob and others},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20014--20027},
  year={2021}
}
%%channel attention
@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}
%%gated linear unit
@inproceedings{dauphin2017language,
  title={Language modeling with gated convolutional networks},
  author={Dauphin, Yann N and Fan, Angela and Auli, Michael and Grangier, David},
  booktitle={International conference on machine learning},
  pages={933--941},
  year={2017},
  organization={PMLR}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Image Restoration
%%%%Restoration old
@article{richardson1972bayesian,
  title={Bayesian-based iterative method of image restoration},
  author={Richardson, William Hadley},
  journal={JoSA},
  volume={62},
  number={1},
  pages={55--59},
  year={1972},
  publisher={Optica Publishing Group}
}
@INPROCEEDINGS{nonlocalmean,
  author={Buades, A. and Coll, B. and Morel, J.-M.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={A non-local algorithm for image denoising}, 
  year={2005},
  volume={2},
  number={},
  pages={60-65 vol. 2},
  doi={10.1109/CVPR.2005.38}}
@ARTICLE{Combettes2004,
  author = {Combettes, P. L. and Pesquet, J. C.},
  title = {Image Restoration Subject to a Total Variation Constraint},
  journal = {IEEE Trans. Image Process.},
  year = {2004},
  volume = {13},
  pages = {1213--1222}
}
@article{bm3d,
  title={Image denoising by sparse 3-D transform-domain collaborative filtering},
  author={Dabov, Kostadin and Foi, Alessandro and Katkovnik, Vladimir and Egiazarian, Karen},
  journal={IEEE Transactions on image processing},
  volume={16},
  number={8},
  pages={2080--2095},
  year={2007},
  publisher={IEEE}
}
@InProceedings{Babacan2012,
author="Babacan, D. and Molina, R. Do, M. N. and Katsaggelos, A. K.",
title="Bayesian Blind Deconvolution with General Sparse Image Priors",
booktitle = {European Conference on Computer Vision},
year="2012",
pages="341--355",
}
%%%Restoration--deep learning
@article{su2022survey,
  title={A survey of deep learning approaches to image restoration},
  author={Su, Jingwen and Xu, Boyan and Yin, Hujun},
  journal={Neurocomputing},
  volume={487},
  pages={46--65},
  year={2022},
  publisher={Elsevier}
}
%%Attention--restoration
@article{zhou2020cross,
  title={Cross-scale internal graph neural network for image super-resolution},
  author={Zhou, Shangchen and Zhang, Jiawei and Zuo, Wangmeng and Loy, Chen Change},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={3499--3509},
  year={2020}
}
@inproceedings{niu2020single,
  title={Single image super-resolution via a holistic attention network},
  author={Niu, Ben and Wen, Weilei and Ren, Wenqi and Zhang, Xiangde and Yang, Lianping and Wang, Shuzhen and Zhang, Kaihao and Cao, Xiaochun and Shen, Haifeng},
  booktitle={European Conference on Computer Vision},
  pages={191--207},
  year={2020},
  organization={Springer}
}
 @InProceedings{Suin_2020_CVPR,
author = {Suin, Maitreya and Purohit, Kuldeep and Rajagopalan, A. N.},
title = {Spatially-Attentive Patch-Hierarchical Network for Adaptive Motion Deblurring},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

%%%Transformers restoration
@inproceedings{zamir2022restormer,
  title={Restormer: Efficient transformer for high-resolution image restoration},
  author={Zamir, Syed Waqas and Arora, Aditya and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5728--5739},
  year={2022}
}
@inproceedings{chen2022simple,
  title={Simple baselines for image restoration},
  author={Chen, Liangyu and Chu, Xiaojie and Zhang, Xiangyu and Sun, Jian},
  booktitle={European Conference on Computer Vision},
  pages={17--33},
  year={2022},
  organization={Springer}
}
@inproceedings{tu2022maxim,
  title={Maxim: Multi-axis mlp for image processing},
  author={Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5769--5780},
  year={2022}
}
@inproceedings{tsai2022stripformer,
  title={Stripformer: Strip transformer for fast image deblurring},
  author={Tsai, Fu-Jen and Peng, Yan-Tsung and Lin, Yen-Yu and Tsai, Chung-Chi and Lin, Chia-Wen},
  booktitle={European Conference on Computer Vision},
  pages={146--162},
  year={2022},
  organization={Springer}
}

@inproceedings{wang2022uformer,
  title={Uformer: A general u-shaped transformer for image restoration},
  author={Wang, Zhendong and Cun, Xiaodong and Bao, Jianmin and Zhou, Wengang and Liu, Jianzhuang and Li, Houqiang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={17683--17693},
  year={2022}
}
@inproceedings{liang2021swinir,
  title={Swinir: Image restoration using swin transformer},
  author={Liang, Jingyun and Cao, Jiezhang and Sun, Guolei and Zhang, Kai and Van Gool, Luc and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1833--1844},
  year={2021}
}
@inproceedings{valanarasu2022transweather,
  title={Transweather: Transformer-based restoration of images degraded by adverse weather conditions},
  author={Valanarasu, Jeya Maria Jose and Yasarla, Rajeev and Patel, Vishal M},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2353--2363},
  year={2022}
}
@article{song2023vision,
  title={Vision transformers for single image dehazing},
  author={Song, Yuda and He, Zhuqing and Qian, Hui and Du, Xin},
  journal={IEEE Transactions on Image Processing},
  volume={32},
  pages={1927--1941},
  year={2023},
  publisher={IEEE}
}
@inproceedings{conde2022swin2sr,
  title={Swin2SR: Swinv2 transformer for compressed image super-resolution and restoration},
  author={Conde, Marcos V and Choi, Ui-Jin and Burchi, Maxime and Timofte, Radu},
  booktitle={European Conference on Computer Vision},
  pages={669--687},
  year={2022},
  organization={Springer}
}

@InProceedings{pmlr-v202-xiao23a,
  title = 	 {Random Shuffle Transformer for Image Restoration},
  author =       {Xiao, Jie and Fu, Xueyang and Zhou, Man and Liu, Hongjian and Zha, Zheng-Jun},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {38039--38058},
  year = 	 {2023},
  volume = 	 {202},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/xiao23a/xiao23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/xiao23a.html},
}
@inproceedings{liang2022drt,
  title={Drt: A lightweight single image deraining recursive transformer},
  author={Liang, Yuanchu and Anwar, Saeed and Liu, Yang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={589--598},
  year={2022}
}
@inproceedings{guo2022image,
  title={Image dehazing transformer with transmission-aware 3d position embedding},
  author={Guo, Chun-Le and Yan, Qixin and Anwar, Saeed and Cong, Runmin and Ren, Wenqi and Li, Chongyi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5812--5820},
  year={2022}
}
%%%%Adversarially robust pruninig
@inproceedings{NEURIPS2020_e3a72c79,
 author = {Sehwag, Vikash and Wang, Shiqi and Mittal, Prateek and Jana, Suman},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {19655--19666},
 publisher = {Curran Associates, Inc.},
 title = {HYDRA: Pruning Adversarially Robust Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/e3a72c791a69f87b05ea7742e04430ed-Paper.pdf},
 volume = {33},
 year = {2020}
}
@inproceedings{ye2019adversarial,
  title={Adversarial robustness vs. model compression, or both?},
  author={Ye, Shaokai and Xu, Kaidi and Liu, Sijia and Cheng, Hao and Lambrechts, Jan-Henrik and Zhang, Huan and Zhou, Aojun and Ma, Kaisheng and Wang, Yanzhi and Lin, Xue},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={111--120},
  year={2019}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Robustness transformers vs cnns
@inproceedings{paul2022vision,
  title={Vision transformers are robust learners},
  author={Paul, Sayak and Chen, Pin-Yu},
  booktitle={Proceedings of the AAAI conference on Artificial Intelligence},
  volume={36},
  number={2},
  pages={2071--2081},
  year={2022}
}

@article{tang2021robustart,
title={RobustART: Benchmarking Robustness on Architecture Design and Training Techniques},
author={Shiyu Tang and Ruihao Gong and Yan Wang and Aishan Liu and Jiakai Wang and Xinyun Chen and Fengwei Yu and Xianglong Liu and Dawn Song and Alan Yuille and Philip H.S. Torr and Dacheng Tao},
journal={https://arxiv.org/pdf/2109.05211.pdf},
year={2021}}
@inproceedings{NEURIPS2021_e19347e1,
 author = {Bai, Yutong and Mei, Jieru and Yuille, Alan L and Xie, Cihang},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {26831--26843},
 publisher = {Curran Associates, Inc.},
 title = {Are Transformers more robust than CNNs? },
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/e19347e1c3ca0c0b97de5fb3b690855a-Paper.pdf},
 volume = {34},
 year = {2021}
}
@inproceedings{wang2023can,
title={Can {CNN}s Be More Robust Than Transformers?},
author={Zeyu Wang and Yutong Bai and Yuyin Zhou and Cihang Xie},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=TKIFuQHHECj}
}
@inproceedings{
shao2022on,
title={On the Adversarial Robustness of Vision Transformers},
author={Rulin Shao and Zhouxing Shi and Jinfeng Yi and Pin-Yu Chen and Cho-Jui Hsieh},
booktitle={NeurIPS ML Safety Workshop},
year={2022},
url={https://openreview.net/forum?id=x9mxhoYRtSP}
}
@InProceedings{eccv2022_cnn_vs_transformer,
author="Pinto, Francesco
and Torr, Philip H. S.
and K. Dokania, Puneet",
title="An Impartial Take to the CNN vs Transformer Robustness Contest",
booktitle="European Conferece on Computer Vision (ECCV)",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="466--480",
abstract="Following the surge of popularity of Transformers in Computer Vision, several studies have attempted to determine whether they could be more robust to distribution shifts and provide better uncertainty estimates than Convolutional Neural Networks (CNNs). The almost unanimous conclusion is that they are, and it is often conjectured more or less explicitly that the reason of this supposed superiority is to be attributed to the self-attention mechanism. In this paper we perform extensive empirical analyses showing that recent state-of-the-art CNNs (particularly, ConvNeXt [20]) can be as robust and reliable or even sometimes more than the current state-of-the-art Transformers. However, there is no clear winner. Therefore, although it is tempting to state the definitive superiority of one family of architectures over another, they seem to enjoy similar extraordinary performances on a variety of tasks while also suffering from similar vulnerabilities such as texture, background, and simplicity biases.",
isbn="978-3-031-19778-9"
}

@misc{singh2023revisiting,
      title={Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models}, 
      author={Naman D Singh and Francesco Croce and Matthias Hein},
      year={2023},
      eprint={2303.01870},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{shao2021adversarial,
title={On the Adversarial Robustness of Vision Transformers},
author={Rulin Shao and Zhouxing Shi and Jinfeng Yi and Pin-Yu Chen and Cho-Jui Hsieh},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
url={https://openreview.net/forum?id=lE7K4n1Esk},
note={}
}
@inproceedings{bhojanapalli2021understanding,
  title={Understanding robustness of transformers for image classification},
  author={Bhojanapalli, Srinadh and Chakrabarti, Ayan and Glasner, Daniel and Li, Daliang and Unterthiner, Thomas and Veit, Andreas},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10231--10241},
  year={2021}
}

@InProceedings{Mahmood_2021_ICCV,
    author    = {Mahmood, Kaleel and Mahmood, Rigel and van Dijk, Marten},
    title     = {On the Robustness of Vision Transformers to Adversarial Examples},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {7838-7847}
}
@inproceedings{debenedetti2023light,
  title={A light recipe to train robust vision transformers},
  author={Debenedetti, Edoardo and Sehwag, Vikash and Mittal, Prateek},
  booktitle={2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)},
  pages={225--253},
  year={2023},
  organization={IEEE}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Robustness- architectural components
@inproceedings{croce2022interplay,
  title={On the interplay of adversarial robustness and architecture components: patches, convolution and attention},
  author={Croce, Francesco and Hein, Matthias},
  booktitle={New Frontiers in Adversarial Machine Learning Workshop at ICML},
  year={2022}
}
@article{xie2020smooth,
  title={Smooth adversarial training},
  author={Xie, Cihang and Tan, Mingxing and Gong, Boqing and Yuille, Alan and Le, Quoc V},
  journal={arXiv preprint arXiv:2006.14536},
  year={2020}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={18th International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  pages={234--241},
  year={2015},
  organization={Springer}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Robustness:Restoration\&Reconstruction
@InProceedings{estimators_robustness,
author = {Choi, Jun-Ho and Zhang, Huan and Kim, Jun-Hyuk and Hsieh, Cho-Jui and Lee, Jong-Seok},
title = {Evaluating Robustness of Deep Image Super-Resolution Against Adversarial Attacks},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}
@INPROCEEDINGS {image-to-image,
author = {J. Choi and H. Zhang and J. Kim and C. Hsieh and J. Lee},
booktitle = {2022 26th International Conference on Pattern Recognition (ICPR)},
title = {Deep Image Destruction: Vulnerability of Deep Image-to-Image Models against Adversarial Attacks},
year = {2022},
pages = {1287-1293},
abstract = {Recently, the vulnerability of deep image classification models to adversarial attacks has been investigated. However, such an issue has not been thoroughly studied for image-to-image tasks that take an input image and generate an output image (e.g., colorization, denoising, deblurring, etc.) This paper presents comprehensive investigations into the vulnerability of deep image-to-image models to adversarial attacks. For five popular image-to-image tasks, 16 deep models are analyzed from various standpoints such as output quality degradation due to attacks, transferability of adversarial examples across different tasks, and characteristics of perturbations. We show that unlike image classification tasks, the performance degradation on image-to-image tasks largely differs depending on various factors, e.g., attack methods and task objectives. In addition, we analyze the effectiveness of conventional defense methods used for classification models in improving the robustness of the image-to-image models.},
keywords = {degradation;training;analytical models;perturbation methods;noise reduction;robustness;pattern recognition},
doi = {10.1109/ICPR56361.2022.9956577},
url = {https://doi.ieeecomputersociety.org/10.1109/ICPR56361.2022.9956577},
publisher = {IEEE Computer Society},}



@article{
antun2020instabilites,
author = {Vegard Antun  and Francesco Renna  and Clarice Poon  and Ben Adcock  and Anders C. Hansen },
title = {On instabilities of deep learning in image reconstruction and the potential costs of AI},
journal = {Proceedings of the National Academy of Sciences},
volume = {117},
number = {48},
pages = {30088-30095},
year = {2020},
doi = {10.1073/pnas.1907377117},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1907377117},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1907377117},
abstract = {Deep learning, due to its unprecedented success in tasks such as image classification, has emerged as a new tool in image reconstruction with potential to change the field. In this paper, we demonstrate a crucial phenomenon: Deep learning typically yields unstable methods for image reconstruction. The instabilities usually occur in several forms: 1) Certain tiny, almost undetectable perturbations, both in the image and sampling domain, may result in severe artefacts in the reconstruction; 2) a small structural change, for example, a tumor, may not be captured in the reconstructed image; and 3) (a counterintuitive type of instability) more samples may yield poorer performance. Our stability test with algorithms and easy-to-use software detects the instability phenomena. The test is aimed at researchers, to test their networks for instabilities, and for government agencies, such as the Food and Drug Administration (FDA), to secure safe use of deep learning methods.}}
@inproceedings{ijcai2022p211,
  title     = {Towards Adversarially Robust Deep Image Denoising},
  author    = {Yan, Hanshu and Zhang, Jingfeng and Feng, Jiashi and Sugiyama, Masashi and Tan, Vincent Y. F.},
  booktitle = {Proceedings of the Thirty-First International Joint Conference on
               Artificial Intelligence, {IJCAI-22}},
  pages     = {1516--1522},
  year      = {2022},
  month     = {7},
  doi       = {10.24963/ijcai.2022/211},
  url       = {https://doi.org/10.24963/ijcai.2022/211},
}
@InProceedings{pmlr-v119-raj20a,
  title = 	 {Improving Robustness of Deep-Learning-Based Image Reconstruction},
  author =       {Raj, Ankit and Bresler, Yoram and Li, Bo},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {7932--7942},
  year = 	 {2020},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/raj20a/raj20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/raj20a.html},
  abstract = 	 {Deep-learning-based methods for various applications have been shown vulnerable to adversarial examples. Here we address the use of deep-learning networks as inverse problem solvers, which has generated much excitement and even adoption efforts by the main equipment vendors for medical imaging including computed tomography (CT) and MRI. However, the recent demonstration that such networks suffer from a similar vulnerability to adversarial attacks potentially undermines their future. We propose to modify the training strategy of end-to-end deep-learning-based inverse problem solvers to improve robustness. To this end, we introduce an auxiliary net-work to generate adversarial examples, which is used in a min-max formulation to build robust image reconstruction networks. Theoretically, we argue that for such inverse problem solvers, one should analyze and study the effect of adversaries in the measurement-space, instead of in the signal-space used in previous work. We show for a linear reconstruction scheme that our min-max formulation results in a singular-value filter regularized solution, which suppresses the effect of adversarial examples. Numerical experiments using the proposed min-max scheme confirm convergence to this solution. We complement the theory by experiments on non-linear Compressive Sensing(CS) reconstruction by a deep neural network on two standard datasets, and, using anonymized clinical data, on a state-of-the-art published algorithm for low-dose x-ray CT reconstruction. We show a significant improvement in robustness over other methods for deep network-based reconstruction, by using the proposed approach.}
}

@INPROCEEDINGS{ga2022deblurring,
  author={Gandikota, Kanchana Vaishnavi and Chandramouli, Paramanand and Moeller, Michael},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)}, 
  title={On Adversarial Robustness of Deep Image Deblurring}, 
  year={2022},
  pages={3161-3165},
  doi={10.1109/ICIP46576.2022.9897356}}

@inproceedings{yu2022towards,
  title={Towards robust rain removal against adversarial attacks: A comprehensive benchmark analysis and beyond},
  author={Yu, Yi and Yang, Wenhan and Tan, Yap-Peng and Kot, Alex C},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6013--6022},
  year={2022}
}

@InProceedings{Choi_2020_ACCV,
    author    = {Choi, Jun-Ho and Zhang, Huan and Kim, Jun-Hyuk and Hsieh, Cho-Jui and Lee, Jong-Seok},
    title     = {Adversarially Robust Deep Image Super-Resolution using Entropy Regularization},
    booktitle = {Proceedings of the Asian Conference on Computer Vision (ACCV)},
    month     = {November},
    year      = {2020}
}

@inproceedings{Yue21RobustSR,
author = {Yue, Jiutao and Li, Haofeng and Wei, Pengxu and Li, Guanbin and Lin, Liang},
title = {Robust Real-World Image Super-Resolution against Adversarial Attacks},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3475627},
doi = {10.1145/3474085.3475627},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {5148â€“5157},
}


@article{grabinski2022aliasing,
  title={Aliasing and adversarial robust generalization of CNNs},
  author={Grabinski, Julia and Keuper, Janis and Keuper, Margret},
  journal={Machine Learning},
  pages={1--27},
  year={2022},
  publisher={Springer}
}

