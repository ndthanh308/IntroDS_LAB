In this work on image restoration, we focus on reconstructing deblurred images using a few recently proposed image restoration networks.

\subsection{Experimental Setup}
\label{subsec:exp:setup}

\noindent\textbf{Networks. } We consider Restormer proposed by \cite{zamir2022restormer}, and Baseline network and NAFNet proposed by \cite{chen2022simple} with width 32.
For understanding the design choices that lead to NAFNet producing reconstructed images with significantly different spectral artifacts than the other considered networks, we also consider an \emph{Intermediate network} and \emph{Intermediate + ReLU}.
This \emph{Intermediate network} with width 32 has also been considered by \cite{chen2022simple} when discussing design choices to arrive from the Baseline network to NAFNet.
These networks are similar to the Baseline, except it has the ``simplified channel attention" as proposed by \cite{chen2022simple} rather than the ``channel attention" used in the Baseline network. 
We visualize all the considered architectures in Figure \ref{fig:arch_blocks}.

\noindent\textbf{Dataset. } For our experiments we use the GoPro image deblurring dataset\cite{gopro}.
This dataset consists of 3~214 real-world images with realistic blur and their corresponding ground truth (deblurred images) captured using a high-speed camera.
The dataset is split into 2~103 training images and 1~111 test images.

\noindent\textbf{Metrics. } We report the PSNR and SSIM scores of the reconstructed images w.r.t. to the ground truth images, averaged over all images.
PSNR stands for Peak Signal-to-Noise ratio, a higher PSNR indicates a better quality image or an image closer to the image to which it is being compared.
SSIM stands for Structural similarity\cite{ssim}.
A higher SSIM score corresponds to better higher similarity between the reconstruction and the ground-truth image.

\noindent\textbf{Training Regimes. } For Restormer and its adversarial training counterpart (`+ADV') we follow the training procedure used by \cite{zamir2022restormer} except due to computational limitations we do not train on the last recommended patch size 384.
For the Baseline network, NAFNet, and its counterparts we follow the training regime used by \cite{chen2022simple}.

\noindent\textbf{Adversarial Training. } We used FGSM \cite{fgsm} adversarial training for efficiency. The maximum allowed perturbation for the adversaries is set to $\epsilon = \frac{8}{255}$. 
We use `+ADV' after the model name to denote that the model has been trained with FGSM adversarial training.

\noindent\textbf{Adversarial Attacks. } We consider PGD and CosPGD attacks. 
Following the procedure by \cite{agnihotri2023cospgd}, we use $\epsilon\approx\frac{8}{255}$, $\alpha$(attack step size)$=0.01$.
We consider attack iterations $\in$ \{5, 10, 20\} for our attacks.
We use MSE loss for generating adversarial samples for all networks.

\subsection{Results}
\label{subsec:exp:results}
The good performance of image restoration models on unperturbed samples is indubitably essential for possible real-world applications. 
However, the generalization ability of these models to perturbed samples has to be better understood for their reliability in safety-critical applications such as medical imaging, autonomous driving, etc. 
To this effect, we study the performance of the considered networks on both clean~(unperturbed) and adversarial~(perturbed) samples.
Further, to overcome the observed shortcomings of these models, we harden them using adversarial training. 
\input{clean_perf}

As observed in Figure~\ref{fig:teaser}, under adversarial attack both Restormer and Baseline network induce ringing-like artifacts in the restored images. 
However, NAFNet introduces aliasing like grid artifacts and color mixing in the restored images.

We report the performance of three networks along with adversarial training over clean images in Table~\ref{tab:clean_perf}.

\input{adv_perf}
Further, to study the generalization ability of these networks we adversarially attack the networks and report the findings in Table~\ref{tab:adv_perf}.

With standard training protocol, Restormer is marginally more robust in comparison to the Baseline network with fewer attack iterations, however, this difference reduces as the number of attack iterations increases. 
With adversarial training using FGSM adversarial examples, we observe improvement in the robustness of all three networks.
Interestingly,  the gain in performance of Restormer when trained with FGSM is significantly better than that of the Baseline network and NAFNet.
This indicates that Restormer has a much higher potential of being generalizable than both the Baseline network and NAFNet.
This raises doubts over the claims by \cite{chen2022simple} regarding the Baseline network and NAFNet having ``comparable or better performance" to the recent \textit{state-of-the-art} image restoration models.
Their claim holds true for clean samples, however with just slight perturbation ($\epsilon=\frac{8}{255}$), the performance of their proposed models drops significantly.
Contrary to this, \emph{Intermediate+ReLU} is significantly more robust, across attack iterations. 
We discuss this further in Section~\ref{subsec:discuss:intermediate}.
\input{mini_cospgd_attack_images}

At first, one might overlook this shortcoming, however, when considering safety-critical  real-world applications like those in the medical domain for deblurring MRI images, or in autonomous driving, such shortcomings could be very hazardous. 
This is further highlighted in Figure~\ref{fig:mini_cospgd_attack} as we observe that both the Restormer and the Baseline network introduce ringing artifacts in the reconstructed images, however, NAFNet introduces very strong aliasing and color mixing that gets worse as the attack strength increases.
While aliasing and color artifacts are significantly reduced with adversarial training (please refer to Figure~\ref{fig:mini_cospgd_attack}), the reconstructions of NAFNet and the Baseline  network are still affected by residual ringing artifacts.
Interestingly, the quality of images reconstructed by Restormer after adversarial training is significantly better, as indicated by its performance in terms of PSNR and SSIM in  Table~\ref{tab:adv_perf}. 
At a low amount of adversarial attack iterations, the artifacts present in the images reconstructed by Restormer are negligible.
To ascertain that these observations are not specific to the adversarial attack itself, we visualize the images reconstructed after PGD attack in Figure~\ref{fig:pgd_attack} and observe a similar phenomenon.  
This accentuates the strength of the architectural design of Restormer and casts doubts over that of the networks proposed by \cite{chen2022simple}.