\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{mathtools}
\newcommand{\comment}[1]{}
\usepackage{xcolor}
\usepackage{ragged2e}

\newcommand{\sct}[1]{{\color{orange}#1}}
\newcommand{\jgct}[1]{{\color{green}#1}}
\newcommand{\VG}[1]{{\color{magenta}#1}}
\newcommand{\PC}[1]{{\color{blue}#1}}
\newcommand{\mmct}[1]{{\color{brown}#1}}
\newcommand{\mkct}[1]{{\color{red}#1}}

\newcommand{\net}{\mathcal{G}_\theta}
\DeclareMathOperator{\argmax}{\arg \max}
\DeclareMathOperator{\argmin}{\arg \min}
\DeclareMathOperator*{\minimize}{minimize}
\DeclareMathOperator*{\maximize}{maximize}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{32} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ificcvfinal\pagestyle{empty}\fi
%\raggedbottom
\begin{document}

%%%%%%%%% TITLE
%\title{Are Transformers for Image Restoration Robust?\\
%\VG{Does Simplifying Transformers for Restoration Impair Robustness?}\\
%\VG{suggest alternative titles}
%}
\title{On the unreasonable vulnerability of transformers for image restoration \\-- and an easy fix}

%\title{Towards Understanding the Vulnerability of Transformers \\ to adversarial attacks for real-world image restoration}


%\title{Robustness of Image Restoration Transformers may be Broken \\-- But Not Beyond Repair}

%PC: just an example title, suggest alternatives.
%VG 

\author{%
  Shashank Agnihotri\\
  %Visual Computing Group\\
  Visual Computing, University of Siegen\\
  Germany \\ %^{1}%\thanks{~$^{1}$Visual Computing Group, University of Siegen, \\ $^{2}$Max Planck Institute for Informatics, Saarland Informatics Campus \\ email: \{firstname.lastname\}@uni-siegen.de} \\
  %\texttt{shashank.agnihotri@uni-siegen.de} \\
  % examples of more authors
 \and
  Kanchana Vaishnavi Gandikota\\  
  Computer Vision, University of Siegen\\
  Germany \\%^{1,2} \\  
  \and
  Julia Grabinski\\
  Fraunhofer ITWM, Kaiserslautern\\
  IMLA, University of Offenburg \\
  Visual Computing, University of Siegen\\
  Germany\\%^{1,2}   
  \and  
  Paramanand Chandramouli\\  
  Computer Graphics, University of Siegen\\
  Germany\\%^{1,2}   
  \and
  Margret Keuper\\
  Visual Computing, University of Siegen, and\\
  Max Planck Institute for Informatics, Saarland\\
  %Saarland Informatics Campus\\
  Germany\\
  %^{1,2} 
  %\texttt{margret.keuper@uni-siegen.de} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}
\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
Following their success in  visual recognition tasks, Vision Transformers(ViTs) are being increasingly employed for image restoration. 
As a few recent works claim that ViTs for image classification also have better robustness properties, we investigate whether the improved adversarial robustness of ViTs extends to image restoration. 
We consider the recently proposed Restormer model, as well as NAFNet and the ``Baseline network" which are both simplified versions of a Restormer. 
We use Projected Gradient Descent (PGD) and CosPGD, a recently proposed adversarial attack tailored to pixel-wise prediction tasks for our robustness evaluation. 
Our experiments are  performed on real-world images from the GoPro dataset for image deblurring.
Our analysis indicates that contrary to as advocated by ViTs in image classification works, these models are highly susceptible to adversarial attacks. 
We attempt to improve their robustness through adversarial training. 
While this yields a significant increase in robustness for Restormer, results on other networks are less promising. 
Interestingly, the design choices in NAFNet and Baselines, which were based on \emph{iid} performance, and not on robust generalization, seem to be at odds with the model robustness. 
Thus, we investigate this further and find a fix. 
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:intro}
\input{teaser}
\input{introduction}

\section{Related Work}
\label{sec:related}
\input{related_work}
%
\input{architectures}
\section{Methodology}
\label{sec:method}
\input{method}


\section{Experiments}
\label{sec:exp}
\input{experiments}

\section{Analysis and Discussion}
\label{sec:discussion}
\input{discussion}

%\newpage
\section{Conclusion}
\label{sec:conclusion}
\input{conclusion}

\clearpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\clearpage
\appendix
\input{appendix2}
\end{document}  