%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%
\section{From Relevance in IR to Relevance for Autonomous Safety-Critical Systems}\label{sec:relevanceIR}\label{sec:relatedWork}
%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Relevance in IR}
Although relevance is discussed in  many fields such as
philosophy, psychology or artificial intelligence, it is probably most prominently discussed in information science and information retrieval (IR) 
where it is considered to be among the most central challenges  \cite{historyRelevance,relevanceFramework,RelevanceRelation,ReExORel}. 
Our notion of \enquote{relevance of perceptions and knowledge of an autonomous safety-critical system \sys} is related in many ways to the notion of relevance in IR.
The later notion has its beginnings in times when librarians without computer support were trying to retrieve documents for their customers ~\cite{historyRelevance}. 
Although the task of retrieving relevant documents may seem quite different from determining what input an autonomous system needs in order to be successful, an abstract concept of relevance should be applicable to both fields alike.
Hence especially the foundational work on relevance in IR remains valid or analogies can be drawn for relevance for autonomous safety-critical systems. 
Even the more so, when we consider relevance as discussed in \cite{MobiUbi,Reichenbacher2007,DeSabbata2015} in the rather young field of mobile IR systems. 

We will discuss the relation between relevance in IR and relevance for an autonomous safety-critical system \HAS later in \autoref{sec:relHAS}. 
Here we first give a short introduction to the concept of relevance in IR and then present a condensed overview of its history.
Since the literature on relevance is vast, we do not claim to give a complete overview. The following is meant to give an introduction to relevance in IR with a focus on the line of research closest to ours.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{What is Relevance in IR?}\label{sec:relIR}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We feel urged to remark that there is not \emph{the} notion of relevance in IR,  but there is an agreement that relevance is a relationship -- basically between a document and
am information need \cite{historyRelevance}. 
The quest of understanding the nature of relevance lead to various definitions since the 1960s.
One reason for this still ongoing quest is that \enquote{relevance is not a single
notion, but many} as Wilson stated in 1973~\cite[p.457]{Wilson1973}. 
%
%
Saracevic  remarks in his influential survey \cite{relevanceFramework} that \enquote{In the most fundamental sense, relevance has to do with effectiveness of communication}~\cite[p.\ 321]{relevanceFramework}. 
He developed in \cite{Saracevic1996} a stratified system of relevance distinguishing \emph{system relevance}, \emph{topical relevance}, \emph{cognitive relevance}, \emph{situational relevance} and \emph{motivational relevance} (cf.~\autoref{tab:stratified}).
According to Saracevic the different strata dynamically interact and are interdependent.  
\emph{Topicality}, the quality of a document to convey information about the topic of the information need, lies at the heart of relevance \cite{historyRelevance,RelevanceRelation}. 
\begin{table}[htbp]
	\footnotesize
	\begin{tabular}{l p{10cm}}
		Relevance: &  Relation between \ldots\\
		\hline\\
		System  & a query and information objects (texts) in a
		collection as retrieved or as failed to be retrieved.\\
		Topical &  the topic expressed in a query and the topic covered by the retrieved texts.\\
		Cognitive & the state of knowledge and cognitive information need of a user and the retrieved texts.\\
		Situational & the situation, task, or problem and the retrieved texts.\\
		Motivational & the intent, goal, and motivation of a user and the retrieved texts.\\
	\end{tabular}
	\caption{Stratified system of relevance by Saracevic \cite{Saracevic1996} according to \cite{RelevanceRelation} }\label{tab:stratified}
	\normalsize
\end{table}


Mizzaro presented in \cite{historyRelevance} his four dimensional model of relevance recognizing that relevance also has a time dimension. Relevance is still regarded as a relation between two entities of the two groups D1 (document/surrogate(information)  and D2 (problem/information need/request/query) (cf. \autoref{fig:relevanceRelation}). As third dimension he considers D3 (topic/task/context). But since the user perceives the problem in a different way over time, the fourth dimension of Mizzaro's framework are \enquote{the various time instants from the arising problem until its solution}~\cite[p. 812]{historyRelevance}. 


% Figure environment removed


In \cite{DeSabbata2015} De Sabbata et al. apdapt Mizzaro's framework to describe relevance for mobile IR systems. 
They observe that for such systems where the user might be moving (i) \emph{the relation between space and time} and (ii) \emph{a link to the real world} is an important factor for the relevance of the retrieved information. 
The user's information need might originate at a location $l$, there information $i_l$ would be relevant, but $i_l$ may have ceased to be relevant to user, when retrieved, since the user is then at another location $l'$ \cite{Reichenbacher2011,DeSabbata2015}. 
To emphasize the spatio-temporal nature of the information seeking they introduce the new 'space-time dimension'. 
Furthermore, they introduce 'world' as a another new dimension, in order to capture the influence of different abstractions of reality.
%
They argue that since the real information need is different from the query received by the system and the real world is different
from the world perceived by the system, a relevance concept can be described as dealing with reality at the different abstraction levels: the real world; the documented world (recorded by the human and stored); the perceived world (perceived by the user); the system world (world as it is known by the system).
%
%


To summarize, early on it was recognized that relevance is determined by many factors, which was coined \enquote{multi-dimensionality} of relevance.
At the heart of relevance lies topicality. 
The retrieval process can be considered from the system and the user perspective. 
The situation the user is in, his cognitive state and the his goals and intentions influence what is relevant for him (cf. \autoref{tab:stratified}). 
With the rise applications that retrieve information about the user's surrounding, the link to the real world in space and time gained importance.

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\subsubsection{A Short History of Relevance in IR}\label{sec:history}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%
This section gives an overview of the history of relevance condensed to the works that we consider especially important with regard to our notion of relevance for an autonomous safety-critical system \HAS. 
We thereby like to stress that early on approaches were developed to formally describe relevance, that more recently there is intensified research on cognitive aspects of relevance, and that due to mobile IR, a strong link to the real world in space and time has been recognized.    
The following short compilation is based on \cite{historyRelevance,RelevanceRelation} and extended by an update.
%

In the \emph{period 1959–1976} efforts were focused on understanding the nature and conceptual subtleties of relevance and devising definitions using various mathematical tools. 
The main contributions to foundational work were 
\begin{itemize}
	\item \cite{MaronKuhns}: In the year 1960, Maron and Kuhns propose weighted indexing. 
		The computed weights are meant to reflect the probably of the document beeing relevant to that user, so that the documents can be ranked in descending order of predicted relevance. 
	\item \cite{Rees}: 1966, Rees notes that the definition of relevance should reflect the influence of \enquote{the previous knowledge} of the user and the \enquote{usefulness} of the information.
		Relevance is thereby a user construct and highly subjective.

	\item \cite{Cooper}, \cite{Wilson1973}: In 1971, Cooper uses in \cite{Cooper} mathematical logic to define relevance. 
		In particular, Cooper defines that a sentence $s$ is relevant to a sentence $r$ if $s$ belongs to a minimal set of premises $M$ entailing $r$, i.e., $\textit{relevant}(s, r)$ iff $\exists M$ $(s \in M \land M \models r \land M - s \not\models r)$. 
		A document $D = \{s_1 , s_2 , \ldots , s_n\}$ is relevant to a request $r$, $Relevant(D, r)$, iff $\exists i (relevant(s_i ,r))$.
		Thereby Cooper gives rise to the today's notion of \emph{logical relevance}.

		In \cite{Wilson1973} Wilson (1973) tries to improve Cooper's definition by taking into account a user's \enquote{situation}, \enquote{stock of information} and \enquote{goals}.
		Today this kind of relevance is referred to as \emph{situational relevance}% 
\end{itemize}
%
This period ends with the surveys \cite{relevanceFramework,TenYearsSaracevic,Saracevic1970,relevanceFramework} of Saracevic where he summarizes and classifies previous work, laying the bases for future research. 

In the following period, a new stream of works is concerned with the importance of the user.
By means of empirical end-users studies further relevance criteria, apart from topicality, are identified, based on which users judge the relevance of the retrieved such as e.g. recency, quality or verification\cite{RelevanceRelation}. 
During this period, \emph{cognitive relevance} and \emph{situational relevance} are elaborated by e.g.\ \cite{Ingwersen1996,Cosijn2000,Saracevic1996,Hjorland2002,Saracevic2007a,ResonanceRuthven2021}.

A second stream of works, concerned with defining a logic for IR, is triggered by the works of van Rijsbergen \cite{Rijsbergen1986,Rijsbergen89}.
As an example we want to mention in particular \cite{Nie1989}, where Nie formalises relevance via modal logic and
Kripke’s possible world semantics. 
The query is represented by a formula and the document by possible worlds. 




A third stream deals with the challenges induced by mobile scenarios and digitalisation.
For this domain the  need of representing the world surrounding a user was recognized~\cite{Mountain2001,Reichenbacher2004,MobiUbi,Mountain2007,Raper2007,Reichenbacher2007,DeSabbata2015}. 




Research on the notion of relevance is still ongoing.
Among the open questions is, how are the different dimensions of relevance related? 
Huang \& Soergel remark in \cite{RelevanceRelation} that \enquote{Relevance is still by and large a black box [\ldots] We may be capable of telling whether A is relevant to B, but specifying precisely in what way A is relevant to B is much harder} \cite[p.~32]{RelevanceRelation}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%
\subsection{A Notion of Relevance for Autonomous Safety-critical Systems}\label{sec:relHAS}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%
We now turn to the challenges of defining a notion of relevance for a safety-critical autonomous system \HAS. 
We survey the main differences of \enquote{relevance of perceptions and knowledge and possible beliefs for {\sys}} to the traditional information seeking problem in IR and motivate our conceptual approach to defining relevance. 
Figure \ref{fig:frame} gives an overview of the main ingredients of this approach, as will be discussed in this and the following section.

% Figure environment removed


The notion of relevance in IR originated from the document retrieval problem in libraries. 
In Mizzaro's terms (cf.~\autoref{fig:relevanceRelation}) this process can be described as follows: 
A user has a problem to solve and recognizes an information need. He hence decides to go to a library. There he requests documents. This request can in turn be translated to a system query. The system retrieves the relevant documents for the user, who's information need changes by the retrieved.

In contrast, we are interested in autonomous systems and aim to support the design process of such systems.
We hence do not have a user who formulates a request and there is no retrieval system operating on a database. % in order to satisfy his information need, in order to solve his problem. 
Instead, we assume that the design domain of the system \HAS is known and moreover a list of requirements for \HAS has been defined.
These requirements allow to define missions for \HAS.
For instance an autonomous vehicle can have a mission like
\enquote{drive on a highway from location $l_1$ to $l_2$, master this mission within time $t$, do not exceed the speed limit $v_{max}$, respect the safety distance at all times, by all means avoid severe collisions}. 
So a mission restricts the application domain to a more specific setting and assigns a \emph{prioritized list of mission goals}. 
The overall behaviour of \HAS can be described as a compilation of missions instantiated to the concrete goals and circumstances. 

In contrast to IR systems, where a rather explicit information need has to be satisfied, for an autonomous safety-critical system \HAS  the information need arises from mission goals.
\HAS has to accomplish its mission goals within the real world. 
It therefore \emph{chooses its actions} based on its assessment of the situation, which includes its prediction of the possible future evolutions.
In order to accomplish its goals, \HAS must sufficiently well predict how its actions effect the real world.
Therefore \HAS is equipped with sensors providing perceptions of its environment. 
These are then integrated by \HAS into its \emph{internal world}. 
Similarly, \HAS may receive messages from other agents conveying information. 
In due course, we do not distinguish between perceptions and messages.
%
%
So, while in IR documents are retrieved in order to satisfy an explicit information need, for \HAS the information need is implied by its goals and relates to perceptions of the world. 

A user of an IR system is assumed to have stock of prior knowledge and this knowledge evolves during her search. 
We likewise assume that \HAS gets equipped with a so-called knowledge base \kbase during design and that this knowledge base evolves. 
A \HAS may \enquote{forget} certain statements of \kbase and it may gain new statements, that are provided by trusted sources during its mission. 
We assume that the entries of \kbase are \emph{believed knowledge}/\emph{strong beliefs} of \HAS, i.e. it  believes that they are true, but they are not necessarily true. 
The \HAS uses its knowledge base when maintaining its internal world model.
\kbase may hold rules how to combine and integrate perceptions and messages, like \enquote{\emph{Cars drive on the road not under.}}, \enquote{\emph{There is a traffic jam ahead.}}. 
So, for \HAS also relates not only to perceptions of the world but also to believed knowledge. 

Note that the internal world model of \HAS  is its \emph{belief}.  
Hence \HAS chooses its actions based on this belief. 



The information need of \HAS can be highly dynamic. 
For instance, an \AV driving along a road has to know about obstacles appearing on its way and about the road conditions at the time. 
Even if the information need has not been satisfied,  \HAS often is forced to choose an action anyway. 
Even if the \AV does not get the information whether the road ahead is slippery, it has to continue to drive, since it cannot and should not stop instantaneously.
So, the systems often choose actions despite uncertainties. 

If an autonomous vehicle rather unexpectedly slips and leaves the road, a sudden reassessment of the situation takes place in order to devise a plan how to ensure its most pressing goals. A replanning has to take place. 
So the prioritized goals imply a prioritized information need.

Similar to mobile IR systems, safety-critical autonomous systems have a strong link to the real world and often the time-space dimension is also very important.
In comparison to mobile IR systems, the dynamicity can be very high for safety-critical autonomous systems. Such a system \sys must be able to suddenly reassess the situation, change its goals and hence its information need and devise a new plan.

Although a safety-critical autonomous \HAS may continuously interact with the real world under high demands an reactivity, usually \HAS does not continuously need to update every aspect of its world model. 
If the road is now slippery and it is a cold and wet January morning, it is sensible to assume that the road still will be slippery in $1ms$.
An engineer might establish the rule as part of  \HAS's knowledge base. This rule constrains what \HAS imagines is possible --\HAS believes only in worlds where the road is now and in the near future slippery.
Additionally, an engineer might decide that misclassifying a giant flower pot as litter bin is tolerable.


We conclude that \HAS implements its kind of cognitive process.
This process defines how  built-in knowledge and gained perceptions result in a belief.
Based on its beliefs \HAS decides on its actions, i.e. \HAS \emph{decides autonomously} (a notion that we will formally introduce in \autoref{def:autonomDec} on page \pageref{def:autonomDec}). 
If its beliefs deviate from the real world so that \HAS is not able to achieve its goals in the real world, then \HAS misses some relevant information (cf. \autoref{fig:fly}).
In the following we will develop a formal framework based on this concept.

% Figure environment removed

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Our Relevance Framework within the Design Process}\label{sec:designproc}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Goal of this line of work is to develop  a formal approach to determine what knowledge and observations are relevant for a safety-critical autonomous \HAS at its mission.
Thereby we aim to support an engineer that has to decide at design-time what sensors and processing power \HAS gets and how it constructs its beliefs, such that \HAS will be able to accomplish its mission goals.

We assume that the engineers capture the application domain (including test criteria of \HAS) via a formal model of the world at design time. 
We refer to this design-time model as $\universeD$. 
We will use $\universeD$ within our framework as an anchor to judge what is relevant for the real world. We refer to it also as \emph{ground truth} (cf. \autoref{fig:frame}).

We assume that the engineer has determined which artifacts the system \HAS must represent in order to build up an internal representation of the real world, a world model \world.
Since the resources of \HAS are finite, we consequently assume that there are only finitely many different world models \HAS can possibly represent.
The set of all possible world models is denoted as \Worlds.
At a time instance \HAS may deem several world models possible and it imagines itself to be currently at certain states of these worlds. 
Thus, to describe a \emph{belief} of \HAS  we use the possible world semantics. 
A world describes not only the current situation, that is the current state. 
It describes the involved objects and what they can do, how they interact, where they come from and what might happen in the future. 
\autoref{fig:possibleWorldsSemantics} illustrates the terms on a abstract example. We will formally introduce them in \autoref{sec:relFrameIR}.
% Figure environment removed


As motivated in the previous section, we moreover assume that a system \HAS has a \emph{knowledgebase} \kbase representing the knowledge built in during the design. 

We have now informally introduced the ingredients of our framework as depicted in \autoref{fig:frame}. 
Based on the built-in knowledge and its perceptions \Obs of the real world, \HAS constructs and maintains its beliefs and autonomously decides based on its beliefs, what to do. 
Within this framework we formalize, that relevant is what \HAS needs to know and observe
to form believes that enable it to act successfully in $W_d$.
Formally, we represent the construction/maintenance of beliefs via a belief formation (function). 
The belief formation \LabelB defines the current belief of \HAS. 

\emph{In a nutshell, our approach simulates what \HAS thinks when performing its maneuver in \universeD and what it does due to its beliefs.  
The criteria for having the relevant observations and the relevant hard beliefs and sufficient possible beliefs is whether \HAS achieves its goals -- or more precisely whether \HAS is able to form beliefs based on the observations and knowledge based on which it can achieve its goals.}



In contrast to Mizzaro's framework (cf.~\autoref{fig:relevanceRelation}) our notion of relevance has a strong emphasis on the cognitive dimension of relevance, since we treat belief formation as a central ingredient of our framework. \autoref{fig:relevanceRelationHAS} illustrates this conceptual difference. 
% Figure environment removed
\autoref{fig:design} illustrates that our approach aims to support the early design. We assume that an analysis of the application domain and \HAS's requirements has been done. 


Apart from providing a characterisation of what knowledge and perceptions are relevant, the framework contributes to tackling the following questions:
\begin{enumerate}
	\item\label{i:auto} Given ground truth, the set of possible beliefs, observations, knowledge, goals,
		is it possible that \HAS forms a belief based on which it performs successful?
	\item\label{i:jitter} Given ground truth, the set of possible belief universe, observations, knowledge, goals, belief formation,
		will \HAS perform successfully?
		How much jitter of perceived values is tolerable, how relevant is the exact timing, the assumed dynamics?
	\item\label{i:sharing} Given ground truth, the set of possible beliefs, observations, knowledge, goals, belief formation, a partition of percepts and required time separation of these partitions,
		will \HAS perform successfully without relying on perceptions violating the required time separation? 
\end{enumerate}
Question \ref{i:auto} occurs during the design, after the domain and requirements analysis (cf. \autoref{fig:design}). Given the application domain has been analysed and a formal model of it exists, the sensory input of \HAS has abstractly been defined, an initial proposal for the build-in knowledge and for the inner representation of the world of \HAS has been made. Then we can examine whether \HAS can somehow build and maintain a belief, that is sufficient to act successfully within the assumed world. Since beliefs are a coarse approximation --e.g. due to limited storage and computation resources-- and the belief formation may be in parts \enquote{wrong} --e.g. since it is not possible to observe certain aspects of the world--, this is an interesting question.   

Later in the design, after fixing the way \HAS constructs its inner world representation, question \ref{i:jitter} arises. 
In contrast to question \ref{i:auto}, it evaluates whether a given belief formation is sufficient for \HAS and its goals.
Question \ref{i:sharing} is future work and it is of interest when resource sharing between different sensor partitions is attempted.

% Figure environment removed


