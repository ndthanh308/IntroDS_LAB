\section{Introduction}
%
Full informedness is certainly not necessary for successful manoeuvres of highly autonomous systems.  
For instance, when an autonomous car approaches a pedestrian crossing, it has to decelerate if  pedestrians want to cross the road --irrespectively of their shirt colours or the exact number of pedestrians. Nevertheless, the number of pedestrians is relevant for the expectation when the group will have crossed the road, influencing the decision whether to take a detour circumventing the crossing. 
For the latter case, the relevance of the group size results from the goal of minimising the travel time.

The control of an autonomous system \HAS can be considered as implementation of a strategy that chooses control actions (time bounded services provided by its autonomous layer like "follow the lane and accelerate" or "emergency braking")  based on the currently agglomerated information. 
A decision for an action is based on the combination of \HAS's observations of the world and \HAS's insights into the world -- e.g. \HAS observed the upper speed limit and knows about the effect of acceleration on its speed. 
Since \HAS usually has only limited sensing and communication capabilities and hence limited means to assess the situation, it faces uncertainties in determining its current situation. Several alternative worlds seem possible at a time and it cannot tell which one actually represents the reality best (cf. \autoref{fig:comic}).
% Figure environment removed	

Our research is driven by the question "What does an autonomous system \HAS need to perceive and know for a successful autonomous manoeuvre, i.e. for manoeuvres where it takes decisions based on its beliefs?". 
We thereby strive to define a notion of relevance of observations and knowledge \footnote{We should rather write \enquote{hard believes}, since the autonomous system has no mean to access the ground truth and hence only treats certain propositions as knowledge.} for autonomous strategic decisions. 
To pave the way for a formal treatment of this question, we develop in \cite{doxFrame} a formal model that explicitly represents the beliefs of \HAS. 
Within this framework, we characterise \emph{autonomous-decisive systems} as systems that rationally take decisions based on the content of beliefs.
We regard a system as rational, when it chooses actions that it believes promise success. 
In this report, we define \emph{relevance} of observations and knowledge for an autonomous-decisive system \HAS with its goals \goalList. 
Basically, a combination of knowledge, observations and possible beliefs is relevant if we cannot omit anything of them while being equally successful.
We present an algorithmical approach based on strategy synthesis to determine relevant combinations of knowledge, observations and possible beliefs. 
Conceptually, the presented approach will be useful in the early design of \sys, where simple and abstract models are considered.
We assume that a design-time world model \universeD is given that characterises the application domain and captures test criteria of \HAS. 
Such a world model may be derived from scenario-databases and test catalogues. 
%
We moreover assume that prior to our outlined analysis, the scope of beliefs (= set of the possible beliefs)  has been defined. So it has been defined which artefacts, objects, and interrelations will possibly be represented in \HAS's beliefs. 
We envision that the starting point for this design step could be \cite{DF11}.

We expect that this work may help to guide the design of beliefs and highlight the trade-off between sensing capabilities (including communications) and  knowledge about the world.

Later design steps  will have to generalise \sys's capabilities to deal with the known unknown aspects of design-time world, taking into account that no world model will match the reality. 
The sanity of derived beliefs will also be judged regarding its robustness against the unknown.
We consider these aspects as future work.



Our notion of relevance \enquote{Relevant is what is necessary to know or to perceive in order to perform best} is based on the dynamically formed beliefs of the system \HAS and is thus subjective, dynamic, motivational and cognitive.
To formalise autonomous decision making and our notion of relevance we use a doxastic model, i.e. a model that explicitly captures beliefs using possible world semantics. 
While many approaches in literature, e.g. \cite{EpistemicsLogics,DoxasticMeyer2003}, regard a possible world as a single \enquote{flat} node, here a possible world has an inner structure. A possible world is a Kripke structure itself, that captures the past, presence and extrapolated future as imagined by \HAS and thereby explains its autonomous decisions.
%

In \cite{DF11} Damm and Finkbeiner determine the optimal perimeter of a world model as the subset of a Kripke structure's propositions that is necessary to synthesize a winning strategy. 
We generalize their idea in order to define relevance for \HASes. 
To this end, we distinguish between the model of ground truth design time model and the model of beliefs, based on which \HAS take decision which in turn effect the ground truth. 

\paragraph{Outline}
In the next section we discuss related work concerning the notion of relevance. The notion of relevance has been discussed in many fields of science, but probably most prominently in information retrieval and information science. Although IR and autonomous system design might seem very different in nature, much of the foundational work in IR regarding the notion relevance finds application also for determining what is relevant for a autonomous system.
We  present the framework within which we capture our notion of relevance  
in \autoref{sec:relFrameIR} and \autoref{sec:ingredients}. 
The latter section and \autoref{sec:autonom} on the notions of autonomous and automatic systems follow closely \cite{doxFrame} which is previous work published under the Creative Commons Attribution License. 
In this paper additional material can be found as well as sleeker proofs. \autoref{sec:autoSys} is a new addition to \autoref{sec:autonom}.  
In \autoref{sec:relevance} we develop our notion of relevance for safety-critical autonomous decisions.
