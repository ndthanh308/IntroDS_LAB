\subsection{The Notion of Autonomous System}\label{sec:autoSys}
Above we have introduced our notion of \emph{autonomous-decisive system} as a system that takes rational decisions based on its current believes.
In Def.~\ref{def:optimal} we defined an \emph{optimal autonomous-decisive system}, as an autonomous-decisive system that performs at least as well as if it knew the ground-truth.
We do not intend these terms to characterize general autonomous systems nor do we aim  to capture aspects of free-will, independence or the ability of reflection; rather, we focus on the decision making of autonomous systems.
In the following we briefly discuss the notion of autonomous system and then relate our notions to it.

\paragraph{Autonomous Systems} The literal meaning of \emph{autonomy} is derived from \emph{auto = self} and \emph{nomos = law}.
Autonomy thus means self-governance \cite{merriamAutonomous} and the concept of autonomy can be found in different kinds of sciences~\cite{LitAutom2016}. 
For systems engineering the word autonomy describes the ability of a system to make its own decisions about its actions without the need for the
involvement of an outside supervisor~\cite{AutomStage}.


Although the terms \emph{automation} and \emph{autonomy} are sometimes used interchangeably~\cite{LitAutom2016},  
a significant difference
between the term autonomous and automatic is that an automatic system will do exactly as programmed while an autonomous system can make choices \cite{huAuto}. 
  
Several level of automation (LoA) have been suggested and discussed in literature.
Many of these see autonomy as the ultimate level of automation.~\cite{LitAutom2016} 
For instance, Parasuraman, Sherdian and Wickens list  in \cite{interactionLevel2000} ten levels of automation. 
Their levels target four broad classes of functions: information acquisition, information analysis, decision \& action selection and action implementation.
At the lowest level, humans must make all decisions and control all actions; at higher levels of automation, the automatic system increasingly takes over while humans receive less and less information about its operations. At level 10 the system decides everything and acts autonomously.\footnote{
In contrast, SAE J3016 defines a taxonomy for six levels of driving automation the SAE Levels of Driving Automation$^{\textsf{TM}}$ avoiding the term autonomy. 
They range from Level 0 (no driving automation) to Level 5 (full driving automation) in the context of motor vehicles and their operation on roadways \cite{SAE}.}

According to J. Sifakis, \cite{AutoSysSifakis}, the main characteristic of autonomous systems is their
ability to handle knowledge and adaptively respond to environment changes.
Autonomous systems have to operate for extended periods of time under
significant uncertainties in the environment and they have to compensate a certain amount of system failures, both without external intervention \cite{TwIntAutCS1989}. 
Many agree with ~\cite{AutoSysSifakis} that autonomy combines perception, reflection, goal management, planning and self-adaptation~\cite{AutoSysSifakis}.
Often autonomous systems are discussed with a focus on artificial intelligence and learning \cite{industAuto,AutoSysSifakis}. 


\paragraph{Autonomous-decisive Systems} In what follows, we argue that our notion of optimal autonomous-decisive system fits well with the notion of autonomous system as outlined above.

The key asset of our notion is formalizing an \enquote{epistemic goal-directedness} for autonomous systems.
Our notion is based  on the fact that a system perceives its environment and maintains a varying knowledge base.
We introduce the explicit requirement that the devised plans have to be rational with respect to its internal world view.  
Thereby we can also distinguish autonomous systems from automatic systems in a way that is compatible with \eg \cite{huAuto}.

What about reflection, goal management, planning and self-adaptation? 
Our work is primarily concerned with decision making. We see you framework as a first step towards formalizing and studying a couple of interesting properties of autonomous systems, as we sketch below.
 
 The formal framework does not constrain what kind of information the \HAS's beliefs encode nor 
what kind of actions an autonomous systems can perform or how it perceives feedback regarding its actions' effect. 
We hence believe that the framework allows to study systems that have explorational awareness, \ie that explore the environment gathering information as part of their strategy.
For instance a robot can explore unknown paths of maze by keeping track where it has been.

Similarly, we believe that reflection can be treated within this framework. 
To this end, the \HAS's believes have to encode believes on believes -- not only represent the believed factual world.
We imagine that finite believe hierarchies could be encoded similar to \cite{perea2012}.
While the treatment of explorative system seems within the framework seems to be straight-forward, modeling believe-hierarchies is considered as future work. 

The framework as such that does not have a notion of goals or is concerned with goal management. 
We believe that the framework could be extended by a notion of subgoals, in such a way that it is possible to analyze whether there is a strategy for subgoal selection.
Conceptually, goals of autonomous system seem to be a mean for breaking down a complex global goal to more easily treatable goals.
So instead of subgoal selection, we can examine whether there is a global strategy that depends only on a certain limited simulation and planning horizon.

Finally, we want to remark that we can consider the design time universe as a training set where certain known aspects of the world are captured. A deployed \HAS then has to be equipped with a belief formation that is able to deal with unexpected events. 
Studying formal robust properties of the belief formation seems an important and interesting endeavour, \eg \enquote{Given a belief formation, how much can the real world deviate from the design-time world?} or \enquote{How much timing tolerance does a certain belief formation have?}.  
