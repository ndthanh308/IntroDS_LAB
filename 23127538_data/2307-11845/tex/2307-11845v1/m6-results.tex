\section{Emperical Results}
\label{sec:results}

In this section, we present the empirical findings from our study centered on information extraction from German company register extracts, demonstrating the application of the LayoutXLM model on a non-English document. We fine-tuned for this specific task, analyze the performance, and address the token class imbalance. This section further discusses metrics such as precision, recall, F1 scores, and overall accuracy on the validation dataset, enabling a deeper understanding of potential banking applications.


Moreover, an ablation study measures the contribution of each component of the model (text, layout, and image data) to its overall performance and explores the effect of different training sample sizes. 

As part of this analysis, the number of epochs required to fine-tune LayoutXLM is investigated. This is crucial to our understanding of the optimal balance between computational efficiency and performance outcome. By examining these empirical results, we aim to build a picture of how models like LayoutXLM can be used for document analysis tasks in banking.


\subsection{Performance Analysis of the LayoutXLM Model}


The examination of the LayoutXLM model's performance on our token classification task forms the focus of this section. Due to the complexity of our task, zero-shot learning is not feasible, and fine-tuning the model is necessary. A full learning curve analysis for better understanding will be presented in the ablation studies (\ref{sec:ablation-studies}). Table \ref{tab:results-epoch10} shows the validation results obtained after fine-tuning a pre-trained LayoutXLM model for 10 epochs. This model achieved an overall accuracy of 0.9758 on the validation dataset. 
A closer analysis of these results reveals several findings.

\begin{table}[h!]
\setlength\tabcolsep{11pt} 
\centering
\small
\caption{Token Classification Results on Validation Set}
\label{tab:results-epoch10}
\begin{tabular}{lcccr}
\toprule
\textbf{Category} & \textbf{Precision} & \textbf{Recall} & \textbf{F1 score} & \textbf{Support}\\
\midrule
authorized officer & 0.6717 & 0.8840 & 0.7634 & 1000\\
capital currency & 0.7935 & 0.8488 & 0.8202 & 86\\
capital number & 0.7536 & 0.6265 & 0.6842 & 83\\
company name & 0.8105 & 0.9245 & 0.8637 & 384\\
director & 0.7314 & 0.6059 & 0.6628 & 373\\
headquarters & 0.8246 & 0.8910 & 0.8565 & 211\\
legal form & 0.9598 & 0.9728 & 0.9663 & 368\\
limited partner & 0.6026 & 0.7344 & 0.6620 & 64\\
shareholder & 0.7143 & 0.3704 & 0.4878 & 81\\
other & 0.9906 & 0.9841 & 0.9873 & 44927\\
\midrule
\textbf{Macro Average} & 0.7852 & 0.7842 & 0.7754 & 47577\\
\textbf{Weighted Average} & 0.9776 & 0.9758 & 0.9762 & 47577\\
\bottomrule
\end{tabular}
\end{table}




First, despite the severe token class imbalance present in the dataset, the LayoutXLM model proves to be robust, as it demonstrates considerable learning capabilities across all classes. This becomes evident from the F1 scores achieved by each class, even those with a smaller number of examples (lower support). For instance, the class ``limited partner" has a support of only 64 and achieves an F1 score of 0.6620, indicating reasonable performance despite being underrepresented.

Second, the trade-off between precision and recall is noticeable in our results. For some categories, such as ``capital number", the model favors precision (0.7536) over recall (0.6265). This means that while the model is cautious in its predictions for this class (leading to fewer false positives), it is missing a significant portion of true positives, leading to lower recall. On the other hand, for categories such as ``authorized officer", the model has a higher recall (0.8840) compared to its precision (0.6717), indicating that the model is able to identify a large portion of actual positives but at the cost of including some false positives. Depending on the specific use case requirements, one may need to adjust the model or the decision threshold to optimize for either precision or recall.

These results underline the versatility of the LayoutXLM model in handling various document classes, exhibiting robustness to class imbalance, while maintaining reasonable precision and recall trade-offs in a banking context. The model's robustness, as demonstrated by the macro-average F1 score of 0.7754, indicates an overall balanced performance across all classes despite the large support of the ``other" category. The choice of the macro-average F1 score, which calculates the average over all independent class scores, provides an assessment without favoring larger classes.

To provide a more concrete understanding of how the LayoutXLM model performs in practice, the presented company register extract in Figure \ref{Fig:cr-labels} already includes a visualization of the output token labels that are being assigned by the model and can be mapped to the document.



\subsection{Ablation Studies}
\label{sec:ablation-studies}
The following ablation studies dissect the LayoutXLM model to better understand its behavior and performance. We evaluate the impact of its multimodal components and examine the effect of varying the size of the training data. Through this investigation, we aim to highlight effective ways to utilize the LayoutXLM model for its diverse applications in banking.

\subsubsection{Assessing the Contributions of Text, Bounding Boxes, and Image Data}
% Figure environment removed


In the first part of the ablation studies, we analyze the contribution of different components - specifically, text, layout information in the form of bounding boxes, and image data - in driving the performance of the token classification model. This analysis is illustrated in Figure \ref{Fig:component-importance}, which presents the learning curves initiated from the first epoch of fine-tuning on the company register extracts. To obfuscate layout and image information, we use empty bounding boxes $(0,0,0,0)$ and white pixels respectively. We also include a multilingual BERT model as a baseline comparison.

In German company register extracts, historical entries are typically highlighted with red or underlined text. Including image data thus allows the model to recognize these visually marked distinctions.
The learning curves depict rapid performance increases until reaching a plateau and convergence after approximately 10 epochs. The text-only models have a slightly delayed convergence, which begins at about 25 epochs.
The LayoutXLM model, which incorporates all three data types - text, layout, and image - shows the steepest learning curve and achieves the highest F1 scores of approx. 80\% after convergence. When the model input is reduced by obfuscating the image data, the F1 score decreases. Eliminating the positional layout data causes an even steeper drop in performance and further delays the learning progress, underscoring the crucial role of these three data inputs.

A comparison of LayoutXLM with a multilingual BERT model supports our initial assumption. BERT, which relies solely on textual data, performs similarly to the text-only variant of LayoutXLM. This confirms the efficacy of multimodal models in document analytics, which combine text, layout, and image data to achieve superior performance.

An important takeaway from this study is the rapid performance improvement within the initial 5 epochs. This suggests a time-efficient fine-tuning of the model, which is beneficial for practical applications. 


\subsubsection{Impact of Training Data Size on LayoutXLM Performance}

To evaluate the effect of training data size on LayoutXLM's performance, we subsample our dataset into smaller subsets, as illustrated in Figure \ref{Fig:train-size}. We fine-tune each subset over 30 epochs, taking into account the learning curve analysis, which indicated post-convergence at this point.


% Figure environment removed


LayoutXLM exhibits considerable learning efficiency even with a minimal amount of labeled data. In particular, only 200-300 observations - a fraction of our full dataset - are sufficient for the model to effectively distinguish between the 10 token classes. This initial learning phase is characterized by a significant increase in the F1 score, which reaches over 70\%. The performance gains slow down as the dataset size exceeds the 200-300 page mark and reaches a maximum of roughly 80\% when using the full training set. This observation underscores LayoutXLM's ability to use relatively small datasets for robust model training in practical settings.


The demonstrated efficiency of LayoutXLM in learning from limited labeled data has implications for organizations with limited resources for collecting and labeling data. It is possible to achieve respectable levels of performance with less data, although a larger dataset may still be beneficial for optimizing performance and capturing rare classes.

