\section{Experimental Design}
\label{sec:experimental}

In this section, we explain our experimental framework. We start with the motivation for our chosen use case, which involves the extraction of information from German company register extracts. These documents present textual data within a tabular structure, often incorporating historical information indicated by red text or underlining. Therefore, the chosen document type might benefit from a model that interprets not only textual data but also visual cues. The use of German data introduces an added level of complexity as it requires a model with foreign language capabilities, reflecting the common needs in global banking processes.


One particular challenge associated with Optical Character Recognition (OCR) on tabular data is its row-by-row reading pattern. Although the semantic token structure might be column-based in tabular data, tokens are read sequentially across the rows, which could potentially misalign the semantic interpretation when processing scans because the reading direction crosses the table columns.

The aim is to classify each word token into one of the following classes: company name, legal form, headquarters, capital number, capital currency, director (geschaeftsfuehrer), authorized officer (prokurist), limited partner (kommanditist), and shareholder (gesellschafter). Tokens that do not fit into any of these categories are called ``other", resulting in a total of 10 classes. A notable aspect of this token classification task is the significant class imbalance, with about 95\% of tokens falling into the ``other" category. This presents a further challenge for the model's learning and performance optimization.

% Figure environment removed

Figure \ref{Fig:cr-labels} exemplifies the typical structure of extracts from the German company register. Red underlining marks historical information, while blue boxes indicate the token labels (only tokens that do not belong to the ``other" class are visualized). 

Next, we describe our data collection and processing, detail model selection, and outline evaluation and benchmarking approaches.

\paragraph{Data Collection and Processing}
We collect extracts from the public German company register for more than 500 companies in different industries. This gives a total data set of 2441 PDF pages. Additionally, we use company metadata XML files to derive labeling information in a structured format. We then iterate over the OCR document tokens and perform a metadata-based token tagging process. This matching process is refined by analyzing the color of the text or its underlining and removing any entity labels from historical information (indicated by red highlighting). Finally, we exclude empty pages and retain only those pages containing at least three token labels with relevant company entity information, resulting in a data set of 1503 pages.


\paragraph{Model Fine-Tuning and Benchmarking}

We chose the pre-trained LayoutXLM model from Huggingface for the token classification task.
To optimize its performance for our specific use case, we put the model through additional training epochs beyond its pre-trained state. This fine-tuning is specifically aimed at the task of extracting information from company register extracts.

The evaluation relies on a hold-out validation set that comprises 30\% of the data, or approximately 480 pages. This set is used in all ablation studies and comparisons to ensure the comparability and consistency of the results. We benchmark the performance of LayoutXLM against a BERT multilingual model and GPT-3.5 Turbo, which we access through its API using the F1 score as a performance metric.
For the GPT benchmark, we use the following prompt: 


\begin{mdframed}[roundcorner=5pt,leftmargin=0cm,rightmargin=0cm,
  skipabove=1cm,skipbelow=1cm,
  frametitle=GPT Prompt,frametitlerule=true]
  \scriptsize
\texttt{Below is a list of word tokens extracted from a German company register extract scans. Please classify \\
each word token into one of the following classes: "company\_name", "legal\_form" (of the company), \\
"headquarters" (of the company), "capital\_number", "capital\_currency", "director\_(geschaeftsfuehrer)" \\
(only natural person name), "authorized\_officer\_(prokurist)" (only natural person name), \\
"limited\_partner\_(kommanditist)" (only natural person name), and "shareholder\_(gesellschafter)" (only \\
natural person name). For word tokens that do not fit into any of these categories, please label them \\
as "other". Also, if any
information is historic or outdated, assign the "other" class as well.
Your task is to create a full list of labeled tokens. Each labeled token should be in the format ["token", "class"]. The final output should be a list of the same length as the original list, with each token labeled \\ according to the appropriate class.
Note that the order of the tokens should remain the same as in the \\
original list. Here is the list of tokens for your consideration:\\
---}
\end{mdframed}