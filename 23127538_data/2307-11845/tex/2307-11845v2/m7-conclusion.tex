\section{Conclusion and Discussion}
\label{sec:conclusion}

%Summary of Findings
The study considered the diverse landscape of banking documents, seeking opportunities to improve process efficiency. In this scope, we presented an overview of promising applications that can benefit from advanced document analytics. We further illustrated the application of the multimodal, cross-lingual LayoutXLM model for information extraction from German company register extracts. Empirical results confirmed the ability of LayoutXLM to handle visually rich banking documents. The ablation analysis further confirmed that the high performance is due to the model's ability to extract relevant information from layout and visual information, which underscores the importance of taking a multimodal approach toward document analytics. For example, this architecture outperforms established unimodal models such as BERT and GPT-3. LayoutXLM also demonstrated robustness against the inherent token class imbalance in company register extracts and delivered good results with little training data, supporting its suitability for banking applications.

%Discussion of Results / Lessons learned+Implikationen / "So What?"
Based on our study, we now discuss the implications for research and banking practice. First, our analysis and prototypical implementation highlight that banking documents display much variety in terms of style and content. Thus, we propose that analytical models in this area should also be adaptive and flexible to accommodate the dynamics inherent in banking documents.
More specifically, our exploration of the banking document landscape underscores their inherent multimodality. Many banking documents are a complex mixture of text, tables, graphics, and even handwriting. Component-by-component analysis of LayoutXLM clearly demonstrates that relying solely on textual data is insufficient. By effectively combining both textual and visual cues, LayoutXLM significantly improves the performance and comprehensiveness of document analysis tasks.

A second implication of our analysis is related to the deployability of advanced NLP models. One often faces a compromise between efficient model training and performance. More specifically, training or fine-tuning of a (NLP) model can be a major obstacle, as it requires large amounts of labeled data, which is rare and costly to acquire. In the context of this study, however, we observe the ability of LayoutXML to extract information from visually rich banking documents without requiring a lot of labeled training data and also without requiring a lot of fine-tuning. These features substantially reduce the effort associated with using LayoutXML in practice.   


Relatedly, the problem of token class imbalance in banking documents is a major challenge. LayoutXLM handles this problem without the need for manual data balancing or preprocessing, which emphasizes the model's ability to adapt to the inherent complexity of banking documents. This ensures an authentic representation of document data during analysis and, again, reduces deployment times and resources.

Concerning the field of NLP, our study questions an exclusive use of zero-shot learning, even when using large language models such as GPT-3.5. Instead, these document analytics frameworks should currently be approached as few-shot learners. The amount of knowledge encapsulated in pre-trained models may not capture the intricate nuances of specialized domains such as banking.
As of now, minimal fine-tuning remains necessary to adapt models to the unique characteristics and challenges of banking documents to ensure optimal performance and accurate information extraction. In the future, this dynamic may change as NLP continues to evolve.\\

%Limitations and Future Work
Our study also shows limitations that suggest avenues for future research. In particular, handling banking documents with extreme layout variability remains a challenge. Other multimodal models such as GPT-4 have attracted much attention and yet, their lack of awareness of layout is a shortcoming. Thus, a direct comparison between a layout-aware variant of GPT and LayoutXLM would be a fruitful route for future research.

