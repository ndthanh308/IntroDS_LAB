{
  "title": "Federated Model Aggregation via Self-Supervised Priors for Highly Imbalanced Medical Image Classification",
  "authors": [
    "Marawan Elbatel",
    "Hualiang Wang",
    "Robert Mart√≠",
    "Huazhu Fu",
    "Xiaomeng Li"
  ],
  "submission_date": "2023-07-27T15:52:18+00:00",
  "revised_dates": [],
  "abstract": "In the medical field, federated learning commonly deals with highly imbalanced datasets, including skin lesions and gastrointestinal images. Existing federated methods under highly imbalanced datasets primarily focus on optimizing a global model without incorporating the intra-class variations that can arise in medical imaging due to different populations, findings, and scanners. In this paper, we study the inter-client intra-class variations with publicly available self-supervised auxiliary networks. Specifically, we find that employing a shared auxiliary pre-trained model, like MoCo-V2, locally on every client yields consistent divergence measurements. Based on these findings, we derive a dynamic balanced model aggregation via self-supervised priors (MAS) to guide the global model optimization. Fed-MAS can be utilized with different local learning methods for effective model aggregation toward a highly robust and unbiased global model. Our code is available at \\url{https://github.com/xmed-lab/Fed-MAS}.",
  "categories": [
    "cs.CV",
    "cs.LG"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14959",
  "pdf_url": "https://arxiv.org/pdf/2307.14959v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 4389586,
  "size_after_bytes": 213109
}