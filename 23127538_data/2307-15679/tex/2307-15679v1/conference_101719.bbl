% Generated by IEEEtranS.bst, version: 1.12 (2007/01/11)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtranS.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{allen2019convergence}
Z.~Allen-Zhu, Y.~Li, and Z.~Song, ``On the convergence rate of training
  recurrent neural networks,'' \emph{Advances in neural information processing
  systems}, vol.~32, 2019.

\bibitem{arjovsky2016unitary}
M.~Arjovsky, A.~Shah, and Y.~Bengio, ``Unitary evolution recurrent neural
  networks,'' in \emph{International conference on machine learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2016, pp. 1120--1128.

\bibitem{chang2019antisymmetricrnn}
B.~Chang, M.~Chen, E.~Haber, and E.~H. Chi, ``Antisymmetricrnn: A dynamical
  system view on recurrent neural networks,'' \emph{arXiv preprint
  arXiv:1902.09689}, 2019.

\bibitem{GRU}
\BIBentryALTinterwordspacing
K.~Cho, B.~van Merrienboer, {\c{C}}.~G{\"{u}}l{\c{c}}ehre, D.~Bahdanau,
  F.~Bougares, H.~Schwenk, and Y.~Bengio, ``Learning phrase representations
  using {RNN} encoder-decoder for statistical machine translation,'' in
  \emph{Proceedings of the 2014 Conference on Empirical Methods in Natural
  Language Processing, {EMNLP} 2014, October 25-29, 2014, Doha, Qatar, {A}
  meeting of SIGDAT, a Special Interest Group of the {ACL}}, A.~Moschitti,
  B.~Pang, and W.~Daelemans, Eds.\hskip 1em plus 0.5em minus 0.4em\relax {ACL},
  2014, pp. 1724--1734. [Online]. Available:
  \url{https://doi.org/10.3115/v1/d14-1179}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/corr/ElliottFSS16}
\BIBentryALTinterwordspacing
D.~Elliott, S.~Frank, K.~Sima'an, and L.~Specia, ``Multi30k: Multilingual
  english-german image descriptions,'' \emph{CoRR}, vol. abs/1605.00459, 2016.
  [Online]. Available: \url{http://arxiv.org/abs/1605.00459}
\BIBentrySTDinterwordspacing

\bibitem{glorot2010understanding}
X.~Glorot and Y.~Bengio, ``Understanding the difficulty of training deep
  feedforward neural networks,'' in \emph{Proceedings of the thirteenth
  international conference on artificial intelligence and statistics}.\hskip
  1em plus 0.5em minus 0.4em\relax JMLR Workshop and Conference Proceedings,
  2010, pp. 249--256.

\bibitem{NTM}
A.~Graves, G.~Wayne, and I.~Danihelka, ``Neural turing machines,'' \emph{arXiv
  preprint arXiv:1410.5401}, 2014.

\bibitem{DNC}
A.~Graves, G.~Wayne, M.~Reynolds, T.~Harley, I.~Danihelka,
  A.~Grabska-Barwi{\'n}ska, S.~G. Colmenarejo, E.~Grefenstette, T.~Ramalho,
  J.~Agapiou \emph{et~al.}, ``Hybrid computing using a neural network with
  dynamic external memory,'' \emph{Nature}, vol. 538, no. 7626, pp. 471--476,
  2016.

\bibitem{NeuralStack}
E.~Grefenstette, K.~M. Hermann, M.~Suleyman, and P.~Blunsom, ``Learning to
  transduce with unbounded memory,'' \emph{Advances in neural information
  processing systems}, vol.~28, 2015.

\bibitem{gu2020improving}
A.~Gu, C.~Gulcehre, T.~Paine, M.~Hoffman, and R.~Pascanu, ``Improving the
  gating mechanism of recurrent neural networks,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2020, pp. 3800--3809.

\bibitem{he2015delving}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Delving deep into rectifiers: Surpassing
  human-level performance on imagenet classification,'' in \emph{Proceedings of
  the IEEE international conference on computer vision}, 2015, pp. 1026--1034.

\bibitem{hochreiter1997long}
S.~Hochreiter and J.~Schmidhuber, ``Long short-term memory,'' \emph{Neural
  computation}, vol.~9, no.~8, pp. 1735--1780, 1997.

\bibitem{jaeger2002adaptive}
H.~Jaeger, ``Adaptive nonlinear system identification with echo state
  networks,'' \emph{Advances in neural information processing systems},
  vol.~15, 2002.

\bibitem{gatebias}
\BIBentryALTinterwordspacing
R.~Jozefowicz, W.~Zaremba, and I.~Sutskever, ``An empirical exploration of
  recurrent network architectures,'' in \emph{Proceedings of the 32nd
  International Conference on Machine Learning}, ser. Proceedings of Machine
  Learning Research, F.~Bach and D.~Blei, Eds., vol.~37.\hskip 1em plus 0.5em
  minus 0.4em\relax Lille, France: PMLR, 07--09 Jul 2015, pp. 2342--2350.
  [Online]. Available:
  \url{https://proceedings.mlr.press/v37/jozefowicz15.html}
\BIBentrySTDinterwordspacing

\bibitem{DMN}
A.~Kumar, O.~Irsoy, P.~Ondruska, M.~Iyyer, J.~Bradbury, I.~Gulrajani, V.~Zhong,
  R.~Paulus, and R.~Socher, ``Ask me anything: Dynamic memory networks for
  natural language processing,'' in \emph{International conference on machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2016, pp. 1378--1387.

\bibitem{le2015simple}
Q.~V. Le, N.~Jaitly, and G.~E. Hinton, ``A simple way to initialize recurrent
  networks of rectified linear units,'' \emph{arXiv preprint arXiv:1504.00941},
  2015.

\bibitem{lim2021noisy}
S.~H. Lim, N.~B. Erichson, L.~Hodgkinson, and M.~W. Mahoney, ``Noisy recurrent
  neural networks,'' \emph{Advances in Neural Information Processing Systems},
  vol.~34, pp. 5124--5137, 2021.

\bibitem{ma2020temporal}
Q.~Ma, Z.~Lin, E.~Chen, and G.~Cottrell, ``Temporal pyramid recurrent neural
  network,'' in \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, vol.~34, no.~04, 2020, pp. 5061--5068.

\bibitem{ma2020particle}
X.~Ma, P.~Karkus, D.~Hsu, and W.~S. Lee, ``Particle filter recurrent neural
  networks,'' in \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, vol.~34, no.~04, 2020, pp. 5101--5108.

\bibitem{massart2022coordinate}
E.~Massart and V.~Abrol, ``Coordinate descent on the orthogonal group for
  recurrent neural network training,'' in \emph{Proceedings of the AAAI
  Conference on Artificial Intelligence}, vol.~36, no.~7, 2022, pp. 7744--7751.

\bibitem{RNNEM}
B.~Peng, K.~Yao, L.~Jing, and K.-F. Wong, ``Recurrent neural networks with
  external memory for spoken language understanding,'' in \emph{Natural
  Language Processing and Chinese Computing}, J.~Li, H.~Ji, D.~Zhao, and
  Y.~Feng, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Cham: Springer
  International Publishing, 2015, pp. 25--35.

\bibitem{rotman2021shuffling}
M.~Rotman and L.~Wolf, ``Shuffling recurrent neural networks,'' in
  \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  vol.~35, no.~11, 2021, pp. 9428--9435.

\bibitem{MemN2N}
S.~Sukhbaatar, J.~Weston, R.~Fergus \emph{et~al.}, ``End-to-end memory
  networks,'' \emph{Advances in neural information processing systems},
  vol.~28, 2015.

\bibitem{talathi2015improving}
S.~S. Talathi and A.~Vartak, ``Improving performance of recurrent neural
  network with relu nonlinearity,'' \emph{arXiv preprint arXiv:1511.03771},
  2015.

\bibitem{tomita:cogsci82}
M.~Tomita, ``Dynamic construction of finite automata from examples using
  hill-climbing,'' in \emph{{P}roceedings of the Fourth Annual Conference of
  the Cognitive Science Society}, Ann Arbor, Michigan, 1982, pp. 105--108.

\bibitem{stateregularized}
C.~Wang and M.~Niepert, ``State-regularized recurrent neural networks,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2019, pp. 6596--6606.

\bibitem{whitney1984kalman}
D.~WHITNEY, ``The kalman filter family tree- a survey of state-of-the-art
  analysis methods based on the kalman filter,'' \emph{NAECON 1984}, pp.
  426--432, 1984.

\bibitem{zhang2021sbo}
Z.~Zhang, Y.~Yue, G.~Wu, Y.~Li, and H.~Zhang, ``Sbo-rnn: Reformulating
  recurrent neural networks via stochastic bilevel optimization,''
  \emph{Advances in Neural Information Processing Systems}, vol.~34, pp.
  25\,839--25\,851, 2021.

\end{thebibliography}
