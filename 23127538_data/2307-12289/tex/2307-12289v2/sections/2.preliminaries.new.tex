%!TeX root = ../lmcs-gandalf22.tex

\section{Preliminaries}
\label{sec:preliminaries}


In this section, we provide an overview of the general framework that underpins
our work. We begin by introducing the general features of timeline-based planning, and then we
discuss timeline-based games. Next, we introduce the reactive synthesis problem.
Finally, we recall the concept of \emph{difference bound matrices}
(DBMs)~\cite{dill1989timing,peron2007abstract}, which are the data structures that we will use
to represent the temporal constraints of a system.

\subsection{Timeline-based planning}
The first basic notion is that of \emph{state variable}.
\begin{defi}[State variable]
  \label{def:timelines:state-variable}
  A \emph{state variable} is a tuple $x=(V_x,T_x,D_x,\gamma)$, where:
  \begin{itemize}
  \item $V_x$ is the \emph{finite domain} of $x$;
  \item $T_x:V_x\to2^{V_x}$ is the \emph{value transition function} of $x$,
    which maps each value $v\in V_x$ to the set of values that can immediately
    follow it; %the value $v$;
  \item $D_x:V_x\to\N\times\N$ is the \emph{duration function} of $x$, mapping
    each value $v\in V_x$ to a pair $(\dmin, \dmax)$ specifying respectively the
    minimum and maximum duration of any interval where $x=v$;
  \item $\gamma:V_x\to\set{\mathsf{c},\mathsf{u}}$ is the 
    \emph{controllability tag}, that, for each value $v\in V_x$, specifies whether it is
    \emph{controllable} $\left(\gamma\left(v\right)=\mathsf{c}\right)$ or \emph{uncontrollable}
    $\left(\gamma\left(v\right)=\mathsf{u}\right)$.
  \end{itemize}
\end{defi}

A state variable  $x$ takes its values from a finite domain and represents a
finite state machine with a transition function $T_x$. The behavior over time of
a state variable $x$ is modeled by a timeline. Intuitively, a \emph{timeline}
for a state variable $x$ is a finite sequence of \textit{tokens}, that is,
contiguous time intervals where $x$ holds a given value.

Following the approach described in~\cite{GiganteMOCR20}, instead of formally
defining timelines in terms of tokens, we represent executions of timeline-based
systems as single words, called \emph{event sequences}, where each event
describe the start/end of some token in a given time point.

To this end, we first define the notion of action.

\begin{defi}
  Let $\SV$ be a set of state variables. An \emph{action} is a term of the form $\tokstart(x,v)$ or $\tokend(x,v)$, where $x\in\SV$ and $v\in V_x$.
\end{defi}

Actions of the form $\tokstart(x,v)$ are \emph{starting} actions, and those of the form $\tokend(x,v)$ are \emph{ending} actions. We denote by $\actions_\SV$ the set of all the actions definable over a set of state variables $\SV$.

\begin{defi}[Event sequence~\cite{GiganteMOCR20}]
  \label{def:event-sequence}
  %
  Let $\SV$ be a set of state variables and $\actions_\SV$ be the set of all
  the \emph{actions} $\tokstart(x,v)$ and $\tokend(x,v)$, for $x\in\SV$ 
  and $v\in V_x$. An \emph{event sequence} over $\SV$ is a sequence
  $\evseq=\seq{\event_1,\ldots,\event_n}$ of pairs $\event_i=(A_i,\delta_i)$,
  called \emph{events}, where $A_i\subseteq\actions_\SV$ %is a set of actions
  and $\delta_i\in\N^+$, such that, for any $x\in\SV$:
  \begin{enumerate}
  \item \label{def:event-sequence:start}
        for all $1\le i\le n$, if $\tokstart(x,v)\in A_i$, for some $v\in V_x$,
        then there is no $\tokstart(x,v')$ in any $\event_j$ before the
        closest event $\event_k$, with $k > i$, such that $\tokend(x,v)\in A_k$ (if
        any);
  \item \label{def:event-sequence:end}
        for all $1\le i\le n$, if $\tokend(x,v)\in A_i$, for some $v\in V_x$,
        then there is no $\tokend(x,v')$ in any $\event_j$ after the
        closest event $\event_k$, with $k < i$, such that $\tokstart(x,v)\in A_k$ (if
        any);
  \item \label{def:event-sequence:gaps-right}
        for all $1\le i < n$, if $\tokend(x,v)\in A_i$, for some $v\in V_x$, then
        $\tokstart(x,v')\in A_i$, for some $v'\in V_x$;
  \item \label{def:event-sequence:gaps-left}
        for all $1< i \le n$, if $\tokstart(x,v)\in A_i$, for some $v\in V_x$,
        then $\tokend(x,v')\in A_i$, for some $v'\in V_x$.
  \end{enumerate}
\end{defi}

The first two conditions guarantee correct parenthesis placement by identifying
the start and the end of each token in the sequence. Condition 1 prevents a
token from starting before the end of the previous one, while condition 2
prevents the occurrence of two consecutive ends not interleaved by a start.
Conditions 3 and 4 ensure seamless continuity: each token's end (resp., start)
is consistently followed (preceded) by the start (resp., end) of another, except
for the first (resp., last) event in the sequence. These latter conditions
prevent gaps in the timeline description of the represented plan.

In event sequences, a \texttt{token} for a variable $x$ is a maximal interval
with at most one occurrence of events $\event_i=(A_i,\delta_i)$ and
$\event_j=(A_j,\delta_j)$, where $\tokstart(x,v)\in A_i$ and $\tokend(x,v)\in
A_j$, for some $v\in V_x$. We say such a token \emph{starts} at position $i$ and
\emph{ends} at position $j$. Note that \cref{def:event-sequence} implies that a
token that has started is not required to end before the end of the sequence and
that it can end without the corresponding starting action ever appearing. If
this is the case, we say that an event sequence is \emph{open} either to the right or
to the left. Otherwise, it is said to be \emph{closed}. An event sequence closed
to the left and open to the right is called a \emph{partial plan}. Notice that
the empty event sequence $\epsilon$ is closed on both sides for any variable.
Furthermore, in closed event sequences, the first event contains only start
actions, while the last one contains only end actions, one for each variable
$x$.

% Each event $\event_i=(A_i,\delta_i)$ consists of a set $A_i$ of actions describing the start or the end of tokens. The actions occur $\delta_i$ time steps after the previous event.
%
% \Cref{def:event-sequence} implies that a token that has started is not required to end before the end of the sequence and that it can end without the corresponding starting action ever appearing. If this is the case, we say an event sequence is \emph{open} either on the right or left. Otherwise, it is said to be \emph{closed}. An event sequence closed on the left and open on the right is %also 
% called a \emph{partial plan}. Notice that the empty event sequence $\epsilon$ is closed on both sides for any variable. Furthermore, in closed event sequences, the first event contains only $\tokstart(x,v)$ actions, while the last event only $\tokend(x,v)$ actions, one for each variable $x$.
Given an event sequence $\evseq=\seq{\event_1,\ldots,\event_n}$ over a set of state variables $\SV$, with $\event_i=(A_i,\delta_i)$, we define $\delta(\evseq)$ as $\sum_{1<i\le n}\delta_i$, that is, $\delta(\evseq)$ is the time elapsed from the start to the end of the event sequence (its duration). For any subsequence $\seq{\event_i, \ldots,\event_j}$ of $\evseq$, abbreviated $\slice\evseq_{i,j}$, we denote by $\delta_{i,j}$ (or, equivalently, $\delta(\slice\evseq_{i,j})$) the amount of time spanning that subsequence. Notice that $\delta_{i,j}$ is defined as $\sum_{i<k\le j}\delta_k$. Finally, given an event sequence $\evseq=\seq{\event_1,\ldots,\event_n}$, we define $\evseq_{<i}$ as $\seq{\event_1,\ldots,\event_{i-1}}$, for each $1<i\le n$.

\smallskip

In timeline-based planning, the objective is to satisfy a set of \emph{synchronization rules}, that specify the desired behavior of the system (constraints and goal). These rules relate tokens, possibly belonging to different timelines, through temporal relations among their endpoints. Let \SV be a set of state variables and $\toknames = \set{a,b,\ldots}$ be 
%an arbitrary 
a set of \emph{token names}. 

\begin{defi}[Atom]
    \label{def:atom}
    An atom is a temporal relation between tokens' endpoints of the form $\production{term} \before_{l,u} \production{term}$, where $l\in\N$, $u\in\N\cup\set{+\infty}$, $l \le u$, and a \emph{term} is either $\tokstart(a)$ or $\tokend(a)$, for some $a\in\toknames$.
\end{defi}

As an example, the atom $\tokstart(a) \before_{3,7} \tokend(b)$ constrains token $a$ to start at least $3$ and at most $7$ time units before the end of token $b$, while the atom $\tokstart(a) \before_{0,+\infty} \tokstart(b)$ simply constrains  token $a$ to start before token $b$.
 
%In such a notation $l$ and $u$ are the lower and the upper bound we impose on the temporal relation between the tokens' 
%endpoints. Meaning that $\langle term_2 \rangle$ is at least $l$ and at most $u$ time units after $\langle term_1 \rangle$.


\begin{defi}[Synchronization rule]
    A synchronization rule \Rule has one of the following two forms:
\begin{gather*}\label{eq:synchronisation-rules}
  \begin{array}{rcl}
  \centering
    \langle rule \rangle &:=& a_0[x_0=v_0]\implies \langle body \rangle\quad\\
    \langle rule \rangle &:=& \top\implies \langle body \rangle\quad \\
    \langle body \rangle &:=& \E_1 \lor \E_2 \lor \dots \lor \E_k\quad \\
    \E_j&\bydef&\exists a_1[x_1=v_1] a_2[x_2=v_2]\ldots a_n[x_n=v_n] \suchdot \clause_j, \ for \ 1 \leq j \leq k,
  \end{array}  
\end{gather*} 
where $a_i \in \toknames$, $x_i \in \SV$,  $v_i \in V_{x_i}$, and $\clause_j$ is a conjunction of atoms, for $0 \leq i\leq n$.
%$a_0, \ldots, a_n \in \toknames$, $x_0,\ldots,x_n \in \SV$, with $v_0,\ldots, v_n$ satisfying $v_i \in V_{x_i}$, for $0 \leq i\leq n$, and $\clause_i$ being a conjunction of atoms.
\end{defi} 
Terms $a_i[x_i=v_i]$ are referred to as \emph{quantifiers}. The term $a_0[x_0=v_0]$ is called the \emph{trigger}. The disjuncts in the body are called \emph{existential statements}. Quantifiers refer to tokens with the corresponding variable and value. The intuitive semantics of a synchronization rule can be given as follows: for every token satisfying the trigger, at least one of the existential statements must be satisfied as well. Each existential statement $\E_j$ requires the existence of tokens that satisfy the quantifiers in its prefix and the clause $\clause_j$. A token that satisfies the trigger of a rule is said to \emph{trigger} that rule. The trigger of a rule can be empty ($\top$). In such a case, the rule is referred to as \emph{triggerless} and it requires the satisfaction of its body without any precondition.

Let $a$ and $b$ be token names.
%An atom of the form $\tokstart(a) \before_{l,u} \tokend(b)$ constrains token $a$ to start before the end of token $b$, with 
%the distance between the two endpoints being at least $l$ and at most $u$.
Here are two examples of synchronization rules (relations $=$ and $\before$ are syntactic sugar for $\before_{0,0}$ and $\before_{0,+\infty}$, respectively):
\begin{align*}
  a[x_s=\mathsf{Comm}] \implies {}
  & \exists b[x_g=\mathsf{Available}] \suchdot
    \tokstart(b) \before \tokstart(a) \land \tokend(a) \before \tokend(b)\\
  a[x_s=\mathsf{Science}] \implies {}
  & \exists b[x_s=\mathsf{Slewing}] \ c[x_s=\mathsf{Earth}] \ d[x_s=\mathsf{Comm}]
    \suchdot {}\\
  & \tokend(a) = \tokstart(b) \land \tokend(b) = \tokstart(c) \land
    \tokend(c) = \tokstart(d)
\end{align*}
where variables $x_s$ and $x_g$ represent the state of a spacecraft and the visibility of the communication ground station, respectively. The first synchronization rule requires the satellite and the ground station to coordinate their communications so that when the satellite is transmitting, the ground station is available for reception. The second one instructs the system to send data to Earth after every measurement session, interleaved by the required slewing operation. Triggerless rule can be used to state the \emph{goal} of the system. As an example, the following rule ensures that the spacecraft performs some scientific measurement:
% 
\begin{equation*}
  \true \implies\exists a[x_s=\mathsf{Science}]
\end{equation*}
Triggerless rules only require the existence of tokens specified by the existential statements, being their universal quantification trivial. 
In fact, 
%While triggerless rules can describe the goals of a planning problem, 
they are syntactic sugar, 
%on top of the syntax mentioned earlier. 
as it is possible to translate them into triggered rules, as shown in~\cite{GiganteMOCR20}.
From now on, we will not consider them anymore.

We now formalise the above intuitive account of the semantics of synchronization
rules.
\begin{defi}[Matching functions~\cite{Gigante19}]
  \label{def:matching-function}
  %
  Let $\evseq=\seq{\event_1,\ldots,\event_n}$ be a (possibly open) event
  sequence, $\E\equiv \exists a_1[x_1=v_1]\ldots
  a_k[x_k=v_k]\suchdot\clause$ be one of the existential statements of a
  synchronization rule $\Rule\equiv a_0[x_0=v_0]\implies
  \E_1\lor\ldots\lor\E_m$, and $V$ be a set of terms such that $\tokstart(a)\in
  V$ or $\tokend(a) \in V$ only if $a \in \set{a_0,\ldots, a_k}$. A
  \emph{matching function} $\gamma:V\to[1,\ldots,n]$ maps each term $T\in V$
  to an event $\event_{\gamma(T)}$ in $\evseq$, such that:
  \begin{enumerate}
  \item \label{def:matching-function:nodes}
        for each $T\in V$, with $T=\tokstart(a)$ (resp., $T=\tokend(a)$),
        if $a$ is quantified as $a[x=v]$ in $\E$, then the event
        $\event_{\gamma(T)}=(A_T,\delta_T)$ is such that $\tokstart(x,v)\in A_T$
        (resp.,~$\tokend(x,v)\in A_T$);
      \item \label{def:matching-function:tokens} if both
        $T=\tokstart(a)$ and $T'=\tokend(a)$ belong to $V$ for some token name
        $a\in\toknames$, then $\gamma(T)$ and $\gamma(T')$ identify the
        endpoints of the same token.
  \end{enumerate}
\end{defi}
As a matter of fact, in \cite{Gigante19}, matching functions are defined in terms of \emph{rule graphs}, a data structure that we do not use here. For this reason, we reformulated the original definition in terms of event sequences.

The following definition gives a formal account of the semantics of synchronization rules.
\begin{defi}[Semantics of synchronization rules]
  Let $\Rule\equiv a_0[x_0=v_0]\implies \E_1\lor\ldots\lor\E_m$ and let
  $\evseq=\seq{\event_1,\ldots,\event_n}$ be an event sequence. We say that $\Rule$
  is \emph{satisfied} by $\evseq$ if, \emph{for each} event $\event_i=(A_i,
  \delta_i)$ such that $\tokstart(x_0,v_0)\in A_i$, there exist an existential
  statement $\E_j\equiv \exists a_1[x_1=v_1]\ldots a_k[x_k=v_k]\suchdot\clause$
  and a matching function $\gamma$ such that if $T \le_{[l,u]} T'$ appears in
  $\clause$, then $l\le \gamma(T')-\gamma(T)\le u$, for any pair of terms $T$ and $T'$.
\end{defi}

\emph{Timeline-based planning problems} can be defined as follows.
\begin{defi}[Timeline-based planning problem]
  A \emph{timeline-based planning problem} is a pair $P=(\SV,\S)$, where $\SV$ is
  a set of state variables and $\S$ is a set of synchronization rules over
  $\SV$. An event sequence $\evseq$ over $\SV$ is a solution plan for $P$ if all
  the rules in $\S$ are satisfied by $\evseq$.
\end{defi}

\subsection{Timeline-based games.} We are now ready to introduce the notion of \emph{timeline-based game}, that subsumes that of \emph{timeline-based planning with uncertainty} given in~\cite{CialdeaMayerOU16}.
%, which have been designed to be strictly
%more general than \emph{timeline-based %planning with %uncertainty}~\cite{CialdeaMayerOU16} while %being able to capture its semantics precisely.

\begin{defi}[Timeline-based game]
  \label{def:games:game}
  A \emph{timeline-based game} is a tuple $G=(\SV_C,\SV_E,\S,$ $\D)$,
  where $\SV_C$ and $\SV_E$ are the sets of \emph{controlled}
  and \emph{external} state variables, respectively, and $\S$ and $\D$ are the sets of
  \emph{system}  and \emph{domain} synchronization rules, respectively, both 
  involving variables from $\SV_C$ and $\SV_E$.
\end{defi}

A partial plan for $G$ is a partial plan over the variables
$\SV_C\cup\SV_E$. Let $\partialplans_G$ be the set of all possible partial plans
for $G$, simply $\partialplans$ when there is no ambiguity.
Since the empty event sequence $\epsilon$ is closed and $\delta(\epsilon)=0$, the
\emph{empty} partial plan $\epsilon$ is a good starting point for the game.
Players incrementally build onto a partial plan, starting from $\epsilon$, by
playing actions that specify which tokens to start and (or) to end, adding an
event that extends the event sequence, or complementing the existing
last one.  

Formally, we partition the set  of all the available actions $\actions_\SV$ into those that are playable by either of the two players.\fitpar

\begin{defi}[Partition of player actions]
  \label{def:games:actions-partition}
  %
  Let $\SV=\SV_C\cup\SV_E$. The set $\actions_\SV$ of available actions over
   $\SV$ is partitioned into the sets $\actions_C$ of \charlie's actions and  
   $\actions_E$ of \eve's actions, which are defined as follows:\fitpar
  \begin{align}
    \actions_C = {} &
      \underbrace{%
        \set{\tokstart(x,v)\suchthat x\in\SV_C,\; v\in V_x}%
      }_{\text{start tokens on \charlie's timelines}}\;\cup\;
      \underbrace{%
        \set{\tokend(x,v)\suchthat x\in\SV,\; v\in V_x,\; \gamma_x(v)=\ctag}%
      }_{\text{end controllable tokens}}\\
    \actions_E = {} &
      \underbrace{%
        \set{\tokstart(x,v)\suchthat x\in\SV_E,\; v\in V_x}%
      }_{\text{start tokens on \eve's timelines}}\;\cup\;
      \underbrace{%
        \set{\tokend(x,v)\suchthat x\in\SV,\; v\in V_x,\; \gamma_x(v)=\utag}%
      }_{\text{end uncontrollable tokens}}
  \end{align}
  %
\end{defi}

Hence, players can start tokens for owned variables and end them for values that
they control. Let $d=\max(L, U)+1$, where $L$ and $U$ are the maximum lower and
(finite) upper bounds appearing in any rule of $G$. Note that, by
\cref{def:games:actions-partition}, we may have $x \in \SV_E$ and $\gamma_x(v)=
c$ for some $v \in V_x$. This means that Charlie may control the duration of a
variable that belongs to Eve. This situation is symmetrical to the more common one where Eve controls the duration of a variable that belongs to Charlie, that is, uncontrollable tokens. As an example, Charlie may decide to start a task, without
being able to foresee how long it will take. Similarly, the environment may
trigger the start of a process, \eg fixing a plant fault, but Charlie may be
able to control, to some extent, how long it will take to end it, \eg we can
decide to fix it today or tomorrow. 

Actions combine into \emph{moves} starting (resp., ending) multiple tokens simultaneously.


\begin{defi}[Move]
  \label{def:games:moves}
  %
  A \emph{move} $\move_C$ for \charlie is a term of the form $\wait(\delta_C)$
  or $\play(A_C)$, where $1 \le \delta_C \le d$ and $\emptyset\ne
  A_C\subseteq\actions_C$ is  either a set of \emph{starting} actions or 
  a set of \emph{ending} actions. A \emph{move} $\move_E$ for \eve is a term of the form $\play(A_E)$ or
  $\play(\delta_E,A_E)$, where $1 \le \delta_E \le d$ and $A_E\subseteq\actions_E$ is
  either a set of \emph{starting} actions or a set of \emph{ending} actions.
  %
\end{defi}
By \cref{def:games:moves}, moves like $\play(A_C)$ and $\play(\delta_E,A_E)$ can
play either $\tokstart(x,v)$ actions only or $\tokend(x,v)$ actions only. A move
of the former kind is called a \emph{starting} move, while a move of the latter
kind is called an \emph{ending} move. We consider $\wait$ moves as \emph{ending}
moves. Starting and ending moves must alternate during the game.

Let us denote the sets of \charlie's and \eve's moves by $\moves_C$ and $\moves_E$ , respectively. A round of the game is defined as follows.

\begin{defi}[Round]
  \label{def:games:round}
  %
  A \emph{round} $\round$ is a pair
  $(\move_C,\move_E)\in\moves_C\times\moves_E$ of moves such that:
  \begin{enumerate}
  \item \label{def:games:round:alternation}
        $\move_C$ and $\move_E$ are either both \emph{starting} or both
        \emph{ending} moves;
  \item \label{def:games:round:paring}
        either $\round=(\play(A_C),\play(A_E))$, or
        $\round=(\wait(\delta_C),\play(\delta_E,A_E))$, with
        $\delta_E\le\delta_C$;
  \end{enumerate}
  %
\end{defi}

A \emph{starting} (resp., \emph{ending}) round is one made of starting (resp., ending) moves.
Since \charlie cannot play empty moves and $\wait$ moves are ending moves, each round is unambiguously either a starting or an ending round. Moreover, since $\play(\delta_E,A_E)$ moves are always paired with 
%played only in rounds together with 
$\wait(\delta_C)$ ones, which are ending moves, then $\play(\delta_E,A_E)$ moves are necessarily ending moves (item \ref{def:games:round:alternation} of Definition 
\ref{def:games:round}).

 We can now specify how to apply a round to the current partial plan to obtain the new one. The game always starts with a single starting round.

\begin{defi}[Outcome of rounds]
  \label{def:games:round-outcome}
  %
  Let $\evseq=\seq{\event_1,\ldots,\event_n}$ be an event sequence, with
  $\event_n=(A_n,\delta_n)$ ($\event_n=(\emptyset,0)$ if $\evseq=\epsilon$). Let
  $\round=(\move_C,\move_E)$ be a round, $A_E$ and $A_C$ be the sets of actions
  of the two moves ($A_C$ is empty if $\move_C$ is a $\wait$ move), and
  $\delta_E$ and $\delta_C$ be the time increments of the moves. We define
  $\delta_C=1$ (resp., $\delta_E=1$) for $\play(A_C)$  
  (resp., $\play(A_E)$).
  
  The \emph{outcome} of the application of $\round$ on $\evseq$ is the event sequence
  $\round(\evseq)$ defined as follows:
  %
  \begin{enumerate}
  \item \label{def:games:round-outcome:starting}
        if $\round$ is a starting round, then $\round(\evseq)=\evseq_{< n}\event_n'$,
        where $\event_n'\nobreak=\nobreak(A_n\cup A_C\cup A_E,\delta_n)$;
  \item \label{def:games:round-outcome:ending}
        if $\round$ is an ending round, then $\round(\evseq)=\evseq\event'$, where
        $\event'=(A_C\cup A_E,\delta_E)$;
  \end{enumerate}
  
  We say that $\round$ is \emph{applicable} to $\evseq$ if:
  \begin{enumerate}[label=\alph*)]
  \item \label{def:games:round-outcome:integrity}
        $\round(\evseq)$ %is a well defined event sequence by 
        complies with \cref{def:event-sequence};
  \item \label{def:games:round-outcome:alternation}
        $\round$ is an ending round if and only if $\evseq$ is open for all variables that appear in the moves.
  \end{enumerate}
  %
\end{defi}

A single move by either player is applicable to $\evseq$ if there is
a move for the other player such that the resulting round is applicable to
$\evseq$.
The game starts from the empty partial plan $\epsilon$, and players play in
turn, composing a round from the move of each one, which is applied to the
current partial plan to obtain the new one.
We can now define the notion of \emph{strategy} for each player and that of \emph{winning strategy} for \charlie.

\begin{defi}[Strategy]
  \label{def:games:strategies}
  %
  A \emph{strategy for Charlie} is a function
  $\strategy_C:\partialplans\to\moves_C$ that maps any given partial plan
  $\evseq$ into a move $\move_C$ applicable to $\evseq$.
%
  A \emph{strategy for Eve} is a function
  $\strategy_E:\partialplans\times\moves_C\to\moves_E$ that maps a partial
  plan $\evseq$ and a move $\move_C\in\moves_C$ applicable to $\evseq$ into a move
  $\move_E$ such that the round $\round=(\move_C,\move_E)$ is applicable to
  $\evseq$.
  %
\end{defi}

A sequence $\rounds=\seq{\round_0,\ldots,\round_n}$ of rounds is called a
\emph{play} of the game. A play is said to be \emph{played according to} some
strategy $\strategy_C$ for \charlie, if, starting from the initial partial plan
$\evseq_0=\epsilon$, it holds that $\round_i=(\strategy_C(\Pi_{i-1}),
\move_E^i)$, for some $\move_E^i$, for all $0<i\le n$, and to be played
according to some strategy $\strategy_E$ for \eve if $\round_i=(\move_C^i,
\strategy_E(\Pi_{i-1},\move_C^i))$, for all $0<i\le n$. It can be easily seen that for
any pair of strategies $(\strategy_C,\strategy_E)$ and any $n\ge0$, there is a
unique play $\rounds_n(\strategy_C,\strategy_E)$ of length $n$ played according to both $\strategy_C$ and $\strategy_E$.

Then, we say that a partial plan $\evseq$ and the play $\rounds$ such that
$\evseq=\rounds(\epsilon)$ are \emph{admissible}, if the partial plan satisfies
the domain rules, and that they are \emph{successful} if the partial plan satisfies the
system rules.

\begin{defi}[Admissible strategy for \eve]
  \label{def:games:admissible-strategy}
  %
  A strategy $\strategy_E$ for \eve is \emph{admissible} if for each strategy
  $\strategy_C$ for \charlie, there is $k\ge 0$ such that the play
  $\rounds_k(\strategy_C,\strategy_E)$ is admissible.
  %
\end{defi}

\charlie wins if, \emph{assuming} that domain rules are respected, he manages to
satisfy the system rules no matter how \eve plays.

\begin{defi}[Winning strategy for \charlie]
  \label{def:games:winning-strategy}
  %
  Let $\strategy_C$ be a strategy for \charlie. We say that $\strategy_C$ is a
  \emph{winning strategy} for \charlie if for any \emph{admissible} strategy
  $\strategy_E$ for \eve, there exists $n\ge0$ such that the play
  $\rounds_n(\strategy_C,\strategy_E)$ is successful.
  %
\end{defi}

We say that \charlie \emph{wins} the game $G$ if he has a winning strategy,
while \eve \emph{wins} the game if a winning strategy for \charlie does not
exist.




\subsection{Synthesis}
The synthesis problem is the problem of devising an implementation that satisfies a formal specification of an input-output relation~\cite{PnueliRosner89}. Such an implementation may be a transducer, a Mealy machine, a Moore machine, a circuit, or the like. In the following, we give a short account of the roles of games and strategies in game-based synthesis.

\begin{defi}[Game Graph] A finite game graph $G$ is a triple $\left(Q, Q_C, E\right)$, where $Q$ is a finite set of nodes, $Q_C \subseteq Q$ is the subset of \charlie's nodes, and $E \subseteq Q \times Q$ is a transition relation. The relation $E$ must satisfy the condition: $\forall q \exists q' : \left(q,q'\right) \in E$ (totality). \end{defi} 

A \emph{play} on a game graph $G$ starting from the initial state $q_0$ is an infinite sequence $p = q_0 q_1 q_2\ldots$, where $(q_i, q_{i+1}) \in E$, for all  $i \ge 0$. A game is  a pair $(G, \mathcal{W})$, where $G$ is a game graph and $\mathcal{W}$ 
%\subseteq 2^Q$ 
is the winning condition of the game. In the general case, $\mathcal{W}$ consists of the set of plays won by  \charlie.



Here, we focus on reachability winning conditions, which are expressed as $\mathcal{W} \bydef \{ R \subseteq Q \mid R \cap F \neq \emptyset \}$, for a given set $F \subseteq Q$. A play $p$ is said to satisfy 
%the reachability winning condition 
$\mathcal{W}$ if the set of states visited by $p$, denoted by $occ(p) = \{q \in Q \mid \exists i \mathrel{.} p(i) = q\}$, intersects $\mathcal{W}$, that is, \charlie wins the play $p$ if $p$ visits at least one state in $F$.

\begin{defi}[Reachability game] A reachability game is a pair $(G, \mathcal{W})$, where $G = (Q, Q_C, E)$ is a game graph and $\mathcal{W}$ is a reachability winning condition. \end{defi}

A strategy for \charlie is a function $f : Q^*\cdot Q_C \rightarrow Q$. A play
$p$ adheres to strategy $f$ if, for each $q_i \in Q_C$, $q_{i+1} = f(q_0 \ldots
q_i)$. Given an initial state $q$, a strategy for \charlie is a winning strategy
if \charlie wins any play from $q$ that follows the strategy $f$. The same holds
for \eve.
%principle applies to \eve. 
\charlie (resp., \eve) wins if a winning strategy exists from $q$. 

Given a game $(G, \mathcal{W})$, with $G = (Q, Q_C, E)$,
the winning region of \charlie is defined as $W_C \bydef \{ q \in Q \, \vert \,
\charlie \text{ wins from q } \}$. The winning region $W_E$ for \eve
is defined in an analogous way.
The two sets are clearly disjoint ($W_C \cap W_E = \emptyset$). The game is
said to be \emph{determined} if $W_C \cup W_E = Q$. It is well known that
reachability games are determined~\cite{Thomas2008}. 

\smallskip

The next step is to build a Controller starting from a winning strategy $f$ such that the specification is met. We use Moore machines as \charlie plays first. 

\begin{defi}[Moore machine]
    \label{def:moore-machine}
    A Moore machine is a tuple $M = (Q, \Sigma, \Gamma, q_0, \delta, \tau)$, where $Q$ is a finite set of states, $\Sigma$ is a finite input alphabet, $\Gamma$ is a finite output alphabet, $q_0 \in Q$ is the initial state, $\delta : Q \times \Sigma \rightarrow Q$ is the transition function, and $\tau: Q \rightarrow \Gamma$ it the output function.
\end{defi}

By suitably tying $\delta$ and $\tau$ to $f$, one can effectively implement $f$. We refer the reader to \cref{def:controller-implementation} for the details on how we do it.

\subsection{Difference Bound Matrices}
\emph{Difference bound matrices} (DBMs) were introduced by
Dill~\cite{dill1989timing} as a pragmatic representation of constraints $(x - y
\leq c)$. Later on, PÃ©ron et al.~\cite{peron2007abstract} suitably expanded
the formalism. The following short account of the formalism is basically borrowed from
the latter work,

Let $\mathit{Var} = \{v_0, v_1, \ldots v_n\}$ be a finite set of variables, $\bar{V} = \mathbb{Z} \cup
\{+\infty\}$ be a set of values that variables and constants can take, and $C$ be  a set of constraints of the form $v_i - v_j \leq c$, where $v_i,v_j \in \mathit{Var}$ and $c \in \bar{V}$. 
%
The DBM that represents $C$ is an $(n+1)\times(n+1)$ matrix defined as follows: 
\begin{equation*}
    M_{ij} = \text{inf}\{c \, \mid \, (v_i - v_j \leq c) \in C\},
\end{equation*}
where $\text{inf}(\emptyset) = +\infty$. 

$M_{ij}$ equals the tightest value of
$c$ if there is some constraint $(v_i - v_j \leq c)$ in $C$; otherwise, it is
$+\infty$. The variable $v_0 \in \mathit{Var}$ is always valued to $0$, and it is
used to express bounds on variables, that is, $v_i \leq c$ is written as
$v_i - v_0 \leq c$.  In \cref{sec:automaton}, we use DBMs to conveniently
represent atoms (see \cref{def:atom}).

%%% Local Variables:
%%% TeX-master: "../lmcs-gandalf22.tex"
%%% End: