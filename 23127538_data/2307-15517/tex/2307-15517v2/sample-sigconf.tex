\documentclass[sigconf, nonacm]{acmart}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{enumitem}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{lipsum}
\usepackage{caption}
\usepackage{listings}
\usepackage{calc}
\usepackage{amsfonts}
\usepackage{tabu}
\usepackage{tikz}
\usepackage{makecell}
\usetikzlibrary{arrows.meta}
\usepackage{pgfplots}
\usepackage{multirow}
\usepackage{flushend}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{soul}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

% \setcopyright{acmlicensed}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{June 03--05,
%   2018}{Woodstock, NY}
% \acmISBN{978-1-4503-XXXX-X/18/06}


\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{jcred}{HTML}{e31a1c}
\definecolor{jcgreen}{HTML}{33a02c}
\definecolor{jcblue}{HTML}{1f78b4}
\definecolor{jcorange}{HTML}{ff7f00}
\definecolor{jcpurple}{HTML}{6a3d9a}
\definecolor{jclightred}{HTML}{fb8072}
\definecolor{jclightgreen}{HTML}{b3de69}
\definecolor{jclightblue}{HTML}{80b1d3}
\definecolor{jclightorange}{HTML}{fdb462}
\definecolor{jclightpurple}{HTML}{bebada}
\definecolor{jcredl}{HTML}{fb8072}
\definecolor{jcgreenl}{HTML}{b3de69}
\definecolor{jcbluel}{HTML}{80b1d3}
\definecolor{jcorangel}{HTML}{fdb462}
\definecolor{jcpurplel}{HTML}{bebada}
\definecolor{jcbluem}{HTML}{488bb8}

\lstdefinestyle{mystyle}{
  frame=tblr,
  commentstyle=\color{codegreen},
  keywordstyle=\color{codepurple},
  basicstyle=\scriptsize\ttfamily,
  breakatwhitespace=false,         
  breaklines=true,                 
  captionpos=b,                    
  keepspaces=true,                 
  numbers=left,                    
  numbersep=5pt,                  
  showspaces=false,                
  showstringspaces=false,
  showtabs=false,                  
  tabsize=2,
  escapeinside={(*@}{@*)},
}
\lstset{style=mystyle}

\lstdefinelanguage{maseir}{%
  language     = python,
  morekeywords = {in, return, rate, MXInt},
}

\definecolor{jcblue}{HTML}{1f78b4}
\newcommand*\az[1]{\textcolor{jcorange}{\bf AZ: #1}}
\newcommand*\jc[1]{\textcolor{jcblue}{\bf JC: #1}}
\newcommand*\zy[1]{\textcolor{jcpurple}{\bf ZY: #1}}
\newcommand*\jcp[1]{{\em #1}}
\newcommand*\todo[1]{\textcolor{jcblue}{{\bf To polish: } #1}}
\newcommand*\best[1]{\textcolor{jcgreen}{\bf #1}}

\newcommand\capped[1]{\textcolor{jcblue}{\boldsymbol{#1}}}
\newcommand\varied[1]{\textcolor{jcred}{\boldsymbol{#1}}}

\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\textcolor{jcgreen}{\ding{51}}}%
\newcommand{\xmark}{\textcolor{jcred}{\ding{55}}}%

\newcommand\gc[1]{\textcolor{blue}{{\bf [GC:} #1{\bf]}}}
\newcommand\gcc[2] {\textcolor{blue}{\st{#1} #2}}
\newcommand*\change[1]{\textcolor{blue}{#1}}

\newcommand*\sw[1]{\textcolor{jcblue}{\tt #1}}
\newcommand*\hw[1]{\textcolor{jcred}{\tt #1}}

\input{data/table_3_4}
\input{data/data_variance}
\input{data/alg_compare}
\input{data/dse_compare}

\begin{document}


\title{A Dataflow Compiler for Efficient LLM Inference using Custom Microscaling Formats}

\author{Jianyi Cheng}
\affiliation{
\institution{University of Cambridge, UK}
\country{}
}
\email{jianyi.cheng@cl.cam.ac.uk}

\author{Cheng Zhang}
\affiliation{\institution{Imperial College London, UK}
\country{}
}
\email{cheng.zhang122@imperial.ac.uk}

\author{Zhewen Yu}
\affiliation{\institution{Imperial College London, UK}
\country{}
}
\email{zhewen.yu18@imperial.ac.uk}

\author{Christos-Savvas Bouganis}
\affiliation{\institution{Imperial College London, UK}
\country{}
}
\email{christos-savvas.bouganis@imperial.ac.uk}

\author{George A. Constantinides}
\affiliation{\institution{Imperial College London, UK}
\country{}
}
\email{g.constantinides@imperial.ac.uk}

\author{Yiren Zhao}
\affiliation{\institution{Imperial College London, UK}
\country{}
}
\email{a.zhao@imperial.ac.uk}

%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Cheng, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Model quantization represents both parameters (weights) and intermediate values (activations) in a more compact format, thereby directly reducing both computational and memory cost in hardware. The quantization of recent large language models (LLMs) faces challenges to achieve competitive memory density compared to other models such as convolutional neural networks, since values in LLMs require larger dynamic ranges.

Current hardware can expedite computation for LLMs using compact numerical formats such as low-bitwidth integers or floating-point numbers. Each has advantages: integer operations simplify circuit design, whereas floating-point calculations can enhance accuracy when a wider dynamic range is required. In this work, we seek an efficient data format that combines the best of both worlds: Microscaling (MX) formats. MX formats are efficient data formats that achieve both large dynamic ranges and high memory density.

In this paper, we propose a compiler named MASE for exploring mixed-precision MX formats on dataflow hardware accelerators for LLM inference. Our main contributions are twofold. First, we propose a novel orchestration abstraction to explore both software and hardware optimizations with new data formats. Second, MASE achieves LLM inference at an average precision of 4-bits, with minimal to no accuracy degradation. To our knowledge, MASE represents the first effort to harness fine-grain multi-precision MX formats in the design of LLM hardware accelerators. Over a range of LLMs and datasets, MASE achieves an average improvement of 24\% in $\Delta$ accuracy with an overhead of only 3\% in energy efficiency compared to designs using 8-bit fixed-point numbers.
\end{abstract}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\input{content}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{ref}

\end{document}