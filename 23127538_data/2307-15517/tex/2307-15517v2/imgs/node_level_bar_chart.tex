\begin{minipage}[b][][b]{.55\textwidth}
\centering
\begin{table}[H]
\caption{Comparison between mixed-precision BFP with other approaches in accuracy and average bitwidth on {\tt sst2} task. BW = bitwidth. MI = Mixed-precision int. MBFP = Mixed-precision BFP. All the models are fine-tuned after post-training quantization except {\tt OPT-1.3B}. We highlight the \best{best} (except Float32) in each case.}
\label{tab:my_label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrrr}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Models}} & \multicolumn{5}{c}{Accuracy} & \multicolumn{2}{c}{Average BW} \\
\cmidrule(lr){2-6}
\cmidrule(lr){7-8}
 & \multicolumn{1}{c}{int8} & \multicolumn{1}{c}{MI} & \multicolumn{1}{c}{BFP} & \multicolumn{1}{c}{MBFP} & \multicolumn{1}{c}{Float32} & \multicolumn{1}{c}{MI} & \multicolumn{1}{c}{MBFP} \\
\midrule
{\tt BERT-BASE} & 0.90 & 0.74 & \best{0.92} & 0.91 & 0.93 & 7.6  & \best{4.3} \\
{\tt BERT-LARGE} & 0.74 & 0.65 & \best{0.92} & 0.90 & 0.92 & 7.5 & \best{4.3} \\
{\tt OPT-125M} & 0.91 & 0.63 & \best{0.92} & 0.88 & 0.92 & 6.8   & \best{4.3} \\
{\tt OPT-350M} & 0.94 & 0.89 & \best{0.94} & 0.91 & 0.94 & 6.5   & \best{4.1} \\
{\tt OPT-1.3B} & 0.52 & 0.60 & \best{0.80} & 0.77 & 0.82 & 6.7   & \best{5  } \\
{\tt LLaMA-160M} & 0.80 & 0.72 & \best{0.90} & 0.87 & 0.91 & 7   & \best{4.8} \\
\bottomrule
\end{tabular}
}
\end{table}
\end{minipage}
\begin{minipage}[b][][b]{.4\textwidth}
% Figure environment removed
\end{minipage}