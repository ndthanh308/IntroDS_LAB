\begin{table*}
    \centering
    \caption{The specifications for the ML models evaluated in this work. float32 = 32-bit floating-point. int8 = 8-bit fixed point. ft = fine-tuned. $^*$The accuracy of models for language modelling was measured in perplexity (smaller is better). }
    \label{tab:model_specs}
\resizebox{\textwidth}{!}{%
% \setlength{\tabcolsep}{2pt}
%     \begin{tabular}{lllrrrrrrrrrr}
% \toprule
% \multirow{2}{*}{} & \multirow{2}{*}{Categories} & \multirow{2}{*}{Models} & \multicolumn{4}{c}{Accuracy} & \multicolumn{6}{c}{Hardware Results} \\
% \cmidrule(lr){4-7}
% \cmidrule(lr){8-13}
%  &  &  & \multicolumn{1}{c}{float32} & \multicolumn{1}{c}{int8} & \multicolumn{1}{c}{float32(ft)} & \multicolumn{1}{c}{int8(ft)} & \multicolumn{1}{c}{Devices} & \multicolumn{1}{c}{LUTs} & \multicolumn{1}{c}{Registers} & \multicolumn{1}{c}{Cycles} & \multicolumn{1}{c}{Fmax} & \multicolumn{1}{c}{Throughput} \\
%  \midrule
% 1 & \multirow{6}{*}{CNN} & {\tt resnet18} &  &  &  &  &  &  &  &  &  & \\
% 2 &  & {\tt resnet50         } &  &  &  &  &  &  &  &  &  & \\
% 3 &  & {\tt mobilenetv2      } &  &  &  &  &  &  &  &  &  & \\
% 4 &  & {\tt mobilenetv3\_small} &  &  &  &  &  &  &  &  &  & \\
% 5 &  & {\tt mobilenetv3\_large} &  &  &  &  &  &  &  &  &  & \\
% 6 &  & {\tt efficientnet\_v2\_s} &  &  &  &  &  &  &  &  &  & \\
% \midrule
% %7 &  & {\tt efficientnet\_v2\_m} &  &  &  &  &  &  &  &  &  & \\
% %8 &  & {\tt efficientnet\_v2\_l} &  &  &  &  &  &  &  &  &  & \\
% 7 & \multirow{5}{*}{Transformers} & {\tt bert-base-uncased} &  &  &  &  &  &  &  &  &  & \\
% 8 &  & {\tt bert-large-uncased}&  &  &  &  &  &  &  &  &  & \\
% 9 &  & {\tt facebook/opt-125m }&  &  &  &  &  &  &  &  &  & \\
% 10 &  & {\tt facebook/opt-350m }&  &  &  &  &  &  &  &  &  & \\
% 11 &  & {\tt facebook/opt-1.3b }&  &  &  &  &  &  &  &  & & \\
% \bottomrule
% \end{tabular}
\begin{tabular}{llllllrrrrrr}
\toprule
\multirow{2}{*}{} & \multirow{2}{*}{Category} & \multirow{2}{*}{Task} & \multirow{2}{*}{Name} & \multirow{2}{*}{Sub-style} & \multirow{2}{*}{Dataset} & \multicolumn{1}{l}{\multirow{2}{*}{FLOPs (G)}} & \multicolumn{1}{l}{\multirow{2}{*}{Parameters (M)}} & \multicolumn{4}{c}{Accuracy/perplexity} \\ 
\cmidrule(lr){9-12}
 &  &  &  &  &  & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{f32} & \multicolumn{1}{l}{f32 ft} & \multicolumn{1}{l}{int8} & \multicolumn{1}{l}{int8 ft} \\
\midrule
1 & \multirow{6}{*}{CNN} & \multirow{6}{*}{Classification} & \multirow{2}{*}{ResNet} & {\tt resnet18} & \multirow{6}{*}{ImageNet} & 3.64 & 11.7  & 69.6 & -  & 58.6 & 68.5 \\
2 &  &  &  & {\tt resnet50} &  & 8.21 & 25.6 & 75.8 & - & 69.4 & 78.1 \\
3 &  &  & MobileNetV2 &{\tt mobilenetv2} &  & 0.615 & 3.50 & 72.0 & - & 58.8 & 70.8 \\
4 &  &  & \multirow{2}{*}{MobileNetV3} & {\tt mobilenetv3\_small} & & 0.117 & 2.54 & 67.4 & - & - & 60.1  \\
5 &  &  &  & {\tt mobilenetv3\_large} &  & 0.445 & 5.48 & 75.2 & -  & - & 69.9 \\
% 6 &  &  & EfficientNet & {\tt efficientnet\_v2\_s} &  & 10.7 & 21.5 & 83.9 & - & - & 71.8 \\
\midrule
6 & \multirow{5}{*}{Transformers} & \multirow{2}{*}{Question Answering} & \multirow{2}{*}{BERT} & {\tt bert-base-cased} & \multirow{2}{*}{QNLI} & 22.4 & 108 & 90.5 & -  & 49.5 & 75.3 \\
7 &  &  &  &  {\tt bert-large-cased} &  & 79.0 & 334 & 92.7 & - & 51.3 & 56.0 \\
\cmidrule(lr){3-12}
8 &  &  \multirow{3}{*}{Language Modelling} & \multirow{3}{*}{OPT} & {\tt facebook/opt-125m} & \multirow{3}{*}{WikiText2} & 32.3 & 125 & 60.3$^*$ & 21.4$^*$ & 553$^*$ & 27.9$^*$ \\
9 &  &  &  & {\tt facebook/opt-350m} &  & 85.8 & 331 & 48.7$^*$ & 18.3$^*$ & 7.42k$^*$ & 26.0$^*$ \\
10 &  &  &  & {\tt facebook/opt-1.3b} &  & 339 & 1316 & 32.1$^*$ & - & 8.28k$^*$ & - \\
\bottomrule
\end{tabular}
}
\end{table*}