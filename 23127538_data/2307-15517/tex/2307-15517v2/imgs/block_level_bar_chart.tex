\begin{minipage}[b][][b]{.55\textwidth}
\centering
\begin{table}[H]
\caption{Comparison between mixed-precision BFP with other approaches in accuracy and average bitwidth on {\tt sst2} task. BW = bitwidth. MI = Mixed-precision int. MBFP = Mixed-precision BFP. All the models are quantized with zero-shot prompting. We highlight the \best{best} (except Float32) in each case.}
\label{tab:my_label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrrr}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Models}} & \multicolumn{5}{c}{Accuracy} & \multicolumn{2}{c}{Average BW} \\
\cmidrule(lr){2-6}
\cmidrule(lr){7-8}
 & \multicolumn{1}{c}{int8} & \multicolumn{1}{c}{MI} & \multicolumn{1}{c}{BFP} & \multicolumn{1}{c}{MBFP} & \multicolumn{1}{c}{Float32} & \multicolumn{1}{c}{MI} & \multicolumn{1}{c}{MBFP} \\
\midrule
{\tt OPT-2.7B } & 0.58 & 0.54 & 0.52 & \best{0.63} & 0.51 & 8.9 & \best{4.4} \\
{\tt LLaMA-7B } & 0.53 & 0.63 & 0.83 & \best{0.84} & 0.83 & 4.7 & \best{4.5} \\
{\tt Vicuna-7B} & 0.53 & 0.59 & 0.80 & \best{0.83} & 0.84 & 5.1 & \best{4.4} \\
{\tt Alpaca-7B} & 0.56 & 0.59 & 0.82 & \best{0.89} & 0.85 & 5.1 & \best{4.5} \\
{\tt OPT-6.7B } & 0.49 & 0.54 & \best{0.76} & 0.73 & 0.76 & 4.7 & \best{4.4} \\
\bottomrule
\end{tabular}
}
\end{table}
\end{minipage}
\begin{minipage}[b][][b]{.4\textwidth}
% Figure environment removed
\end{minipage}