\begin{table}[t]
\centering
\caption{A comparison between mixed-precision {\tt MXInt} with other approaches in accuracy and average bitwidth on {\tt SST2} task. 
% The upper part of the table runs the whole model on a many-FPGA system. The lower part of the table runs a few blocks of the model on the many-FPGA system due to limited FPGA resources, and iterates computation for running the whole model. 
$^*$ means the models are fine-tuned and quantized before evaluation, and $^\dag$ denotes the models are quantized and evaluated in zero-shot prompting style.  We highlight the \best{best} results after quantization. {\tt FP32} = {\tt Float32}.}
\label{tab:self_compare}
\resizebox{0.48\textwidth}{!}{%
% {\footnotesize
\begin{tabular}{lrrrrrr}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Models}} & \multicolumn{4}{c}{Accuracy} & \multicolumn{2}{c}{Average Bitwidth} \\
\cmidrule(lr){2-5}
\cmidrule(lr){6-7}
& \multicolumn{1}{c}{{\tt Int8}} & \makecell[c]{ Mixed \\ {\tt Int}} & \makecell[c]{ Mixed \\ {\tt MXInt}} & \multicolumn{1}{c}{ {\tt FP32}} & \makecell[c]{ Mixed \\ {\tt Int}} & \makecell[c]{ Mixed \\ {\tt MXInt}} \\
\midrule
{\tt LLaMA-160M}$^*$ & 0.8 & 0.72     & \best{0.87} & 0.91 & 7 & \best{4.8} \\
{\tt BERT-BASE}$^*$ & 0.9 & 0.74      & \best{0.91} & 0.93 & 7.6 & \best{4.4} \\
{\tt BERT-LARGE}$^*$ & 0.74 & 0.65    & \best{0.89} & 0.92 & 7.5 & \best{4.3}  \\
{\tt OPT-125M}$^*$ & 0.91 & 0.63      & \best{0.88} & 0.92 & 6.8  & \best{4.4} \\
{\tt OPT-350M}$^*$  & 0.94 & 0.89     & \best{0.91} & 0.94 & 6.5 & \best{4.4} \\
{\tt OPT-1.3B}$^{\dag}$ & 0.52 & 0.60 & \best{0.76} & 0.82 & 6.7 & \best{5.1} \\
{\tt OPT-2.7B}$^\dag$ & 0.58 & 0.54  & \best{0.63} & 0.51 & 8.9 & \best{4.4}  \\
\midrule
\textbf{Geom. Mean.} & 0.74 & 0.67 & \best{0.83} & 0.86 & 7.18 & \best{4.77} \\
\midrule
{\tt OPT-6.7B}$^\dag$ & 0.49 & 0.54 & \best{0.73} & 0.76 & 4.7 & \best{4.4} \\
{\tt LLaMA-7B}$^\dag$ & 0.53 & 0.63 & \best{0.84} & 0.83 & 4.7 & \best{4.5} \\
{\tt Vicuna-7B}$^\dag$ & 0.53 & 0.59 & \best{0.83} & 0.84 & 5.1  & \best{4.4} \\
{\tt Alpaca-7B}$^\dag$ & 0.56 & 0.59 & \best{0.89} & 0.85 & 5.1 & \best{4.5} \\
\midrule
\textbf{Geom. Mean.} & 0.53 & 0.59 & \best{0.82}& 0.82 & 4.95 & \best{4.45} \\
\bottomrule
\end{tabular}
}
\end{table}
