\begin{algorithm}[H]
\caption{A transformer block of {\tt Vicuna-7B}.}
{
\footnotesize
\begin{algorithmic}[1]
\Require $X$ \Comment{Input features}
\Require $H$ \Comment{Number of heads}
\State $X_n \gets LayerNorm(X) $
\For{$i \in [0, H)$}
\State $\varied{Q_i} \gets W_{Q_i}X_n$
\State $\varied{K_i} \gets W_{K_i}X_n$ 
\State $\varied{V_i} \gets W_{V_i}X_n$ 
\State $Q'_i \gets RoPE(\varied{Q_i}$)
\State $K'_i \gets RoPE(\varied{K_i}$)
\State $\varied{A_i} \gets \frac{Q'_i{K'_i}^T}{\sqrt{d_k}} $
\State $\hat{A}_i \gets softmax(A_i) $
\State $\varied{B_i} \gets \varied{V_i}\hat{A}_i $
\EndFor
\State $B_c \gets concat(\varied{B_0..B_{H-1}})$
\State $\varied{B_o} \gets W_0B_c$
\State $B_n \gets RMSNorm(\varied{B_o} + X_n) $
\State $\varied{G} \gets W_GB_n$
\State $\varied{U} \gets W_UB_n$
\State $\varied{D} \gets W_D(SiLU(\varied{G} \bigotimes \varied{U}))$
\State $\varied{O} \gets \varied{D} + \varied{B_o} + X$
\State \Return $O$
\end{algorithmic}}
\label{alg:transformer}
\end{algorithm}