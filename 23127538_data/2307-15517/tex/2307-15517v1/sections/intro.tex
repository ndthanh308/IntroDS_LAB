
\section{Introduction}

% Figure environment removed

Machine Learning (ML) has demonstrated state-of-the-art performance in domains such as Computer Vision (CV) \cite{wang2022pvt, tan2019efficientnet} and Natural Language Processing (NLP) \cite{devlin2018bert, brown2020language}. ML has now been widely deployed in many applications, such as autonomous driving \cite{kouris2020approximate, zheng2021se}, recommendation systems \cite{adolphs2022boosting}, healthcare \cite{korngiebel2021considering}, and more.
Often, ML applications necessitate a substantial amount of energy for computation due to the craving for superior performance and the ever-growing model sizes. To facilitate meeting the demand for low-energy computing, ML hardware accelerators are proposed as they utilize a particular architecture designed for ML computation, consuming significantly less energy than general-purpose processors while attaining a similar performance level \cite{sun2022fpga, wang2021fpt}.

Designing an efficient ML accelerator requires a tremendous amount of knowledge and effort from hardware experts. It could take years to implement an ML accelerator in an application-specific integrated circuit (ASIC) and months for prototyping on a reconfigurable device such as a field-programmable gate array (FPGA). The gap between the development cycles of software ML models and hardware acceleration has been rapidly widening due to the increasing size and complexity of models. Furthermore, new models may significantly alter their program behaviour, making the hardware architecture obsolete and necessitating a complete redesign from scratch.

In order to address these challenges, two traditional approaches have been studied. The first approach involves transforming the ML model using software compilers, enabling efficient mapping onto a pre-existing accelerator architecture~\cite{niu_micro2022}. However, the fixed accelerator architecture imposes a performance upper bound. The second approach focuses on fast prototyping of hardware accelerators using high-level synthesis (HLS) tools, targeting ASICs~\cite{stratus, catapult} or FPGAs~\cite{duarte_arxiv2018, blott_trets2018}. However, these tools primarily keep the software model unchanged and aim to explore solely an efficient hardware accelerator architecture. This naturally raises the question of \emphbold{how we can systematically explore the opportunities for concurrent co-optimization of software and hardware}?

Previous research has explored the co-optimization of software and hardware for Deep Neural Networks (DNNs) from an Automated Machine Learning (AutoML) perspective. The general idea is to include hardware design parameters in the canonical AutoML search space. \emphbold{However, this approach is still relatively limited in terms of hardware architecture exploration.} Co-design AutoML typically focuses on a small set of parameters in a Processing Element (PE) array-based architecture \cite{abdelfattah2020best, choi2021dance}, such as buffer sizes and PE array dimensions. Additionally, existing Co-design AutoML strategies are constrained to a single type of network, such as Convolutional Neural Networks (CNNs), due to the hindrance posed by the underlying `template' hardware accelerator when exploring alternative network architectures, like transformers \cite{brown2020language}. Therefore, the aim of this work is to develop a system-level flow that facilitates the mapping of various networks to custom silicon.

Many prior DNN hardware accelerator design frameworks \cite{xiao2022towards, blott_trets2018, fahim2021hls4ml, venieris2016fccm} focus on automating the design of single-device accelerators. This implies that DNNs must either fit within the designated device or be reused on the same hardware. However, the emergence of large language models such as GPT and OPT \cite{brown2020language, zhang2022opt}, which consist of millions or even billions of parameters, has necessitated the exploration of multi-accelerator systems instead of traditional single-accelerator systems. Multi-accelerator systems are better suited to accommodate the ever-growing models, which raises the question of how can we automatically partition available hardware resources across multiple devices for different types of DNNs with varying runtime constraints.


In this paper, we are interested in exploiting custom hardware computing for a wide variety of ML models with optimization in both software and hardware on a many-accelerator system. Our work aims to solve the following challenges:

\noindent
\jcp{1) Unified Abstraction for Software and Hardware}

\noindent
The development flows for ML models and hardware design are currently separate. The ML models are treated as a `read-only' input to the hardware synthesis tools. \change{How can we} lift this restriction by enabling ML model optimization in the hardware flow?

\noindent
\jcp{2) Efficiency and Scalability}

\noindent
Most new ML models are large and contain millions of operations and cannot be efficiently mapped onto a single hardware device. \change{How can we} efficiently exploit parallelism  in a scalable hardware system?

\noindent
\jcp{3) Hardware Reusability }

\noindent
Hardware designers may have already implemented efficient hardware blocks that could be reused for computing new ML models. \change{How can we} efficiently explore hardware optimization with these user-defined blocks?

\noindent
\jcp{4) Correctness}

\noindent
The user-defined blocks might not work correctly or efficiently with the synthesised blocks using MASE. How to test and verify the final hardware design by making use of the software ML model?

We propose a novel hardware architecture exploration tool termed MASE, which stands  for ML Accelerator System Exploration. MASE enables fast prototyping of efficient  hardware accelerator systems for state-of-the-art ML models. The main contributions are: 

\begin{itemize}
    \item \change{A novel intermediate representation that describes \textit{both} software and hardware at module level};
    \item \change{A scalable hardware synthesis flow with automated and cross-device design space exploration that maps the state-of-the-art of ML models into efficient many-accelerator systems};
    \item \change{Two case studies demonstrating how to use MASE to automatically quantize and accelerate the latest large-language models using custom arithmetic}; and
    \item Over a set of ML models, MASE can achieve comparable performance and energy efficiency to GPUs when accelerating recent and large ML models.
\end{itemize}

The rest of the paper is organised as follows. Section~\ref{sec:overview} provides an overview of the MASE framework. Section~\ref{sec:background} provides the background of recent trends in ML model designs, design tools for streaming ML accelerator and AutoML methods.  Section~\ref{sec:methodology} explains how MASE realises the four challenges explained before. Section~\ref{sec:experiments} provides two case studies on how MASE can be used for prototyping efficient accelerators for new transformer models.