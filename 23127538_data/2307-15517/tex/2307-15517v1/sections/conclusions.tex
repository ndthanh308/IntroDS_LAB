\section{Conclusions}
% ML models today are evolving rapidly and growing significantly. This makes designing the next ML accelerators 
% for new and large models challenging. In order to reduce the gap between the development speed of software ML
% models and hardware accelerators, we propose an efficient and scalable hardware system exploration tool named MASE.

% We propose an efficient IR named MASE IR that enables both the software model and the hardware architecture 
% to be expressed at the same abstraction. This work proposes the first step of the MASE framework, enabling the
% exploration of ML accelerator system in a software compiler flow. MASE opens various opportunities for the 
% next-generation ML accelerator exploration, such as hardware-aware network architecture search~(NAS), 
% mixed and custom quantization scheme search.

% As two examples of such use cases, we present two case studies to show how to use MASE to explore \change{efficient}
% quantization of ML models and how to use newly proposed arithmetic operators for improving the efficiency of an existing accelerator system. MASE enables end-to-end flow hardware synthesis of large models. We hope MASE can contribute to the route to making designing the next-generation accelerator from months to weeks.

ML models today are evolving rapidly and growing significantly. This makes designing the next ML accelerators for new and large models challenging. In order to reduce the gap between the development speed of software ML models and hardware accelerators, we propose an efficient and scalable hardware system exploration tool named MASE.

We propose an efficient IR called MASE IR that allows the software model and the hardware architecture to be expressed at the same abstraction level. This work represents the initial step of the MASE framework, enabling ML accelerator system exploration within a software compiler flow. MASE presents various opportunities for next-generation ML accelerator exploration, including hardware-aware network architecture search (NAS) and custom quantization scheme search.

As examples of these use cases, we present two case studies demonstrating how to utilize MASE for exploring \change{efficient} quantization of ML models and incorporating newly proposed arithmetic operators to enhance the efficiency of an existing accelerator system. MASE facilitates end-to-end hardware synthesis flow for large models. Our aim is for MASE to contribute to accelerating the process of designing next-generation accelerators from months to weeks.