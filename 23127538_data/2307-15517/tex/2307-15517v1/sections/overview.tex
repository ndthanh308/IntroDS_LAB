
\begin{table*}[ht]
    \centering
    \caption{\change{Comparison between our IR and other existing IRs. MASE IR is the first \textbf{\textit{trainable}} IR that both describes the software model architecture and its hardware accelerator architecture.}}
    \label{tab:mase_ir}
\resizebox{0.95\textwidth}{!}{%
\change{
    \begin{tabular}{lcccccc}
    \toprule
Features & TorchScript~\cite{devito2022torchscript} & Torch FX~\cite{reed2022torch} & ONNX~\cite{bai2019onnx} & MASE IR & MLIR~\cite{lattner2020mlir} & LLVM~\cite{lattner2004llvm} \\
\midrule
Granularity & module & module & module & module & tensor/vector/scalar & scalar \\
Executing in software & \best{\checkmark} & \best{\checkmark} & \best{\checkmark} & \best{\checkmark} & \best{\checkmark} & \best{\checkmark} \\
Hardware mapping & \worst{$\times$}& \worst{$\times$}& \worst{$\times$}& \best{\checkmark} & \best{\checkmark} & \best{\checkmark} \\
Training & \best{\checkmark} & \best{\checkmark} & \best{\checkmark} & \best{\checkmark} & \worst{$\times$} & \worst{$\times$} \\
    \bottomrule
    \end{tabular}
}}
\end{table*}


\section{Overview}
\label{sec:overview}

This section presents an overview of MASE. MASE is integrated into PyTorch and can directly interface with PyTorch modules without requiring any rewriting. The top right of Figure~\ref{fig:overview} illustrates an example of how MASE can be used. In MASE, an ML model can undergo analysis and transformation in both software and hardware domains. The black edges in Figure~\ref{fig:overview} depict the fundamental tool flow of MASE.
\begin{enumerate}
\item A user-defined model in PyTorch with pre-trained weights is translated into an intermediate representation (IR) in MASE, named MASE IR. The MASE IR of an ML model encompasses both the software algorithm and its corresponding hardware implementation.
\item Similar to most compiler frameworks, a model in MASE IR can undergo software transformations such as post-training quantization using MASE compiler passes (explained in Section~\ref{sec:methodology:mase_ir}).
\item The MASE IR contains comprehensive model information and can be trained or fine-tuned after transformation (explained in Section~\ref{sec:methodology:modify_sw}).
\item MASE IR also describes the accelerator architecture for the model, enabling efficient and scalable hardware transformations using MASE compiler passes, akin to software development (explained in Section~\ref{sec:methodology:modify_sw}).
\item At the backend of MASE, the optimized hardware design can be generated for a scalable accelerator system.
\item MASE incorporates an efficient testing framework to verify the equivalence between the software model and the hardware implementation.
\end{enumerate}
The tool flow depicted in Figure~\ref{fig:overview} serves as an example development flow in MASE. In MASE, all the MASE passes can be applied \emphbold{out-of-order}, similar to other compiler frameworks like LLVM~\cite{lattner2004llvm} and MLIR~\cite{lattner2020mlir}.

In this paper, we demonstrate how MASE enables rapid prototyping of next-generation ML accelerators for new ML models. The red dashed edges in Figure~\ref{fig:overview} illustrate the proposed techniques for software and hardware co-optimization. Firstly, we show the efficient transformation of new ML models by leveraging the implementations of existing models in both software and hardware. Secondly, we present how the hardware can be further customized in a scalable manner in interactive coordination with software transformations.