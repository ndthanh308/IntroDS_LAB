{
  "title": "XMem++: Production-level Video Segmentation From Few Annotated Frames",
  "authors": [
    "Maksym Bekuzarov",
    "Ariana Bermudez",
    "Joon-Young Lee",
    "Hao Li"
  ],
  "submission_date": "2023-07-29T11:18:23+00:00",
  "revised_dates": [
    "2023-08-15T11:26:36+00:00"
  ],
  "abstract": "Despite advancements in user-guided video segmentation, extracting complex objects consistently for highly complex scenes is still a labor-intensive task, especially for production. It is not uncommon that a majority of frames need to be annotated. We introduce a novel semi-supervised video object segmentation (SSVOS) model, XMem++, that improves existing memory-based models, with a permanent memory module. Most existing methods focus on single frame annotations, while our approach can effectively handle multiple user-selected frames with varying appearances of the same object or region. Our method can extract highly consistent results while keeping the required number of frame annotations low. We further introduce an iterative and attention-based frame suggestion mechanism, which computes the next best frame for annotation. Our method is real-time and does not require retraining after each user input. We also introduce a new dataset, PUMaVOS, which covers new challenging use cases not found in previous benchmarks. We demonstrate SOTA performance on challenging (partial and multi-class) segmentation scenarios as well as long videos, while ensuring significantly fewer frame annotations than any existing method. Project page: https://max810.github.io/xmem2-project-page/",
  "categories": [
    "cs.CV",
    "cs.GR"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15958",
  "pdf_url": "https://arxiv.org/pdf/2307.15958v2",
  "comment": "Accepted to ICCV 2023. 18 pages, 16 figures",
  "num_versions": null,
  "size_before_bytes": 49825592,
  "size_after_bytes": 328944
}