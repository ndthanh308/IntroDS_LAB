%\section{Inference speed and memory usage}
%The addition of the permanent memory module has a linear scaling effect on both inference speed and memory usage. In the original XMem, the average time generate masks for a video of $n$ frames is defined by the dependency of $O(n k (\frac{n}{z}) + \frac{n}{q}) = O\left(n^2k (\frac{1}{z} + \frac{1}{q})\right)$, where $k$ is the maximum number of elements that can be stored in the working memory (typically $k=100$), $q$ is the memory insertion frequency (typically $k=5$, save every $5$-th frame), and $z$ is a compression factor for long-term memory. 
%The scaling law is ultimately quadratic, but for short- and medium-length videos ($n < 2000$), the $z$ is large enough (up to $600 \times$) to ignore the infinite long-term memory growth, thus the inference speed is not affected in a significant way. 

%Given $m$ annotated frames, \modelname{} loads them into permanent memory (static $+m$ factor), and has the new size of the working memory $=k+m$, thus $O\left(n^2(k+m) (\frac{1}{z} + \frac{1}{q}) + m\right)$ as well. Given that annotating frames is an expensive process, in practice $m$ is likely to be small, $m \leq 20$, thus $m \leq \frac{k}{20}$, having a slowdown of $<1.2\times$ on memory readout, and an even smaller effect on the overall segmentation process. On an RTX-3090 GPUS with a $500$-frame video with $5$ annotations provided, \modelname{} yields \textbf{32} FPS (\textbf{35} excluding loading the frames into permanent memory) and XMem yields \textbf{39}.

%Total memory usage only increases by a static factor of $+m$, as we store $m$ additional annotated frames.



