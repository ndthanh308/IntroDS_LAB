\newcommand{\bigdot}[1] {\overset{\,_{\mbox{\Huge .}}}{#1}}
\newcommand{\zt}[1][v]{z_{#1,j,t}}
\newcommand{\zts}[1][v]{\widetilde{z}_{#1,j,t}}
\newcommand{\zst}[1][v]{z_{#1,\jstar,t}}
\newcommand{\dotzt}[1][v]{\dot{z}_{#1,j,t}}
\newcommand{\dotzst}[1][v]{\dot{z}_{#1,\jstar,t}}
\newcommand{\optt}[1][v]{\text{opt}_{#1,j,t}}
\newcommand{\ztminus}{z_{v,j,t^-}}
\newcommand{\opI}{p(I)}
\newcommand{\OPT}{{\cal O}}
\newcommand{\oqI}{q(I)}
\newcommand{\oyI}{y(I)}
\newcommand{\obyI}{\mathbf{y}(I)}
\newcommand{\obyIp}[1]{\mathbf{y}(#1)}
\newcommand{\jstar}{{j^\star}}




\section{Online Algorithm}\label{sec:online}

In this section, we describe an efficient online algorithm for \wtd and prove the following result:
\Online*

We begin by re-writing the LP relaxation~(\ref{lp:original}) in terms
of the ``anti-page'' variables, as in~\cite{BBN-focs07-paging}. Recall
that (\ref{lp:original}) has variables $\yI$ representing the
(fractional) weight $W_j$ server mass present at location $v$ during
the interval $I$; instead we first rewrite it in terms of the ``page''
variables $\xt$, which denote the total amount of weight $W_j$ server
mass at location $v$ at time $t$, as given in \eqref{eq:xyrelation}.
The objective of this LP in terms of $\xt$ is:
\[
     \sum_{v, j, I} W_j \cdot \yI = \sum_{v, j, I} W_j \cdot (\xt - \xtminus)^+.
\]
We can constrain any algorithm to values 
$\xt \in [0, 1]$ for all $v, j, t$ (since having multiple servers at a
location is not beneficial). This allows us to work with
non-negative \emph{anti-page} variables $\zt := 1 - \xt$. The
objective, now rewritten in terms of these new variables $\zt$, becomes:
\begin{gather}
  \sum_{v, j, I} W_j \cdot (\xt - \xtminus)^+ = \sum_{v,j,I} W_j \cdot
  (\ztminus - \zt)^+. \label{eq:online-obj}
\end{gather}
We shall also maintain the following invariant for each server weight $W_j$ and time $t$:
\begin{gather}
  \sum_v \xt = k_j \qquad \iff \qquad \sum_v \zt =  n - k_j~ \quad \forall j, t. \label{eq:online-cons1}
\end{gather}
We write the covering constraint~\eqref{eq:covLP} (or equivalently~\eqref{eq:cons2}) in terms of $\zt$ as:
\begin{equation}\label{eq:cover}
 \sum_j \zt[\sigma_t] \leq \ell-1
\end{equation}
The algorithm follows the standard relax-and-round paradigm in the
online setting. The first step is to compute a feasible fractional
solution to an LP consisting of objective (\ref{eq:online-obj}) and
constraints~(\ref{eq:online-cons1}) and~(\ref{eq:cover}), in an online
setting. We show in \S\ref{sec:online-fract-algor} that 
we can find a fractional solution that uses
$O(\ell k_j)$ servers of weight $W_j$ for each class $j$, and has a
competitive ratio of $O(\ell^2)$. The second step is to give an online
rounding algorithm to convert this fractional solution to an integral
solution: our rounding algorithm given in \S\ref{sec:online-rounding} uses 
the standard online rounding algorithm for the paging problem and 
increases the cost of the solution by a constant factor.

\subsection{Online Fractional Algorithm}
\label{sec:online-fract-algor}


In this section, we give an online algorithm for maintaining a
fractional solution to the LP involving $\zt$ variables. We obtain 
the following result:
\begin{theorem}\label{thm:fractional}
    There is a deterministic (polynomial time) online fractional algorithm that maintains 
    the condition that for every request time $t$, there exists an index $j \in [\ell]$ such that
    there is unit server mass of weight $W_j$ at location $\sigma_t$
    at time $t$.
    The algorithm uses $2\ell k_j$ servers of weight $W_j$ for each $j \in [\ell]$, 
    and whose cost is at most $O(\ell^2 \log \ell)$ times 
    that of an optimal fractional solution.
\end{theorem}

Note that the condition in the theorem is stronger than \eqref{eq:cover},
the feasibility condition for \eqref{lp:original}, because we are using server from a single weight class to service this request.


Consider a
time $t$, and the request arriving at location $\sigma_t$. We first
set $\zt = \ztminus$ for all $v \in V, j \in \ell$. Now the algorithm
moves fractional server mass to $\sigma_t$ until a relaxed version 
of the covering constraint~\eqref{eq:cover} for time $t$ gets
satisfied. The relaxed constraint is given by
\begin{equation}\label{eq:cover-relax}
\exists j \in [\ell] \text{ such that } \zt[\sigma_t] \leq 1-\frac{1}{2\ell}.
\end{equation}

Indeed, if the constraint is violated, then 
for each vertex $v \neq \sigma_t$ and each $j \in
[\ell]$, if $v$ has non-zero server mass of weight $W_j$ (i.e., $\zt < 1$),  
then the algorithm moves server mass 
of weight $W_j$ from $v$ to $\sigma_t$ using the following differential
equation. (The derivative is with respect to a variable $s$ which starts from 0 and increases at uniform rate.)
\begin{equation}\label{eq:rate}
    \dotzt = \frac{1}{W_j |S_j|}\cdot \left(\zt+\delta\right) ~\quad \forall j \in [\ell], \forall v \in S_j. 
\end{equation}
Here, $S_j \subseteq V$ denotes the instantaneous set of locations 
(i.e., at the current value of the
variable $s$) that have $\zt < 1$, not including the location
$\sigma_t$, and
$\delta > 0$ is a parameter that we shall fix later.
Correspondingly, we reduce $\zt[\sigma_t]$ by the total amount 
of server mass of weight $W_j$ entering $\sigma_t$:
\begin{equation}\label{eq:rate-sigmat}
    \dotzt[\sigma_t] = - \frac{1}{W_j |S_j|}\cdot \sum_{v\in S_j} \left(\zt+\delta\right) ~\quad \forall j \in [\ell]. 
\end{equation}
Note that server mass is moved away other locations and 
into location $\sigma_t$ only if 
$\zt[\sigma_t] > 1-\frac{1}{2\ell}$ for all $j$.
Since $\zt[\sigma_t]\le 1$ for all $j$, it follows that 
$\zt \in [1-\frac{1}{2\ell}, 1]$ for all $j, t$.
Hence,
\begin{equation}\label{eq:z-lb}
    \zt \ge 1-\frac{1}{2\ell} \text{ for all } j, t  \quad \implies \quad |S_j| \geq 2\ell k_j - 1 \ge \frac{3\ell k_j}{2} \ge 3 \text{ for all } j, t,
\end{equation}
since $\ell \ge 2, k_j \ge 1$.

To analyze the algorithm, we use a potential function $\Phi$. 
The potential function depends on the offline (integral) optimal
solution---let us call it $\OPT$, and let $\optt$ be the indicator
variable for the location $v$ 
containing a server of weight $W_j$ at time $t$. 
The potential at time $t$ is defined as follows:
\[
    \Phi(t) := \sum_{v, j: \optt = 0} W_j \cdot \ln \left(\frac{1+\delta}{\zt+\delta}\right).
\]
Let $\cost(t)$ denote the algorithm's server movement cost at time $t$ and $\cost^{\OPT}(t)$ denote the corresponding quantity for the optimum solution $\OPT$. Our goal is to show that: 
\begin{align}
    \label{eq:pot}
    \frac{\cost(t)}{4\ell} + \Phi(t+1)-\Phi(t) \leq  \ln(1+\nf1\delta) \cdot \cost^{\OPT}(t).
\end{align}

The following properties of $\Phi(t)$ can verified easily:
\begin{itemize}
    \item {\bf Nonnegativity:} $\Phi$ is always nonnegative, since
      $\zt \le 1$.
    \item {\bf Lipschitzness property:} When the optimal solution moves a server of weight $W_j$ from one location to another, the increase in $\Phi$ is at most $W_j\cdot \ln (1+\nf1\delta)$.
\end{itemize}
The Lipschitzness property implies that~\eqref{eq:pot} holds when
$\OPT$ serves the request at $\sigma_t$.  It remains the analyze the
cost and change in potential when the algorithm changes its
solution. Consider the process when we transfer server mass to
$\sigma_t$. 

We first bound the online algorithm's cost. Since all the weight classes incur the same server movement cost while transferring to $\sigma_t$, the movement cost is $\ell$ times the movement cost incurred while transferring servers of a fixed class, say $j^\star$. 
The latter is at most 
\begin{align}
    W_\jstar \sum_{v\in S_\jstar } \dotzst 
    &\stackrel{\eqref{eq:rate}}{=}  \frac{1}{|S_\jstar|} \sum_{v\in S_\jstar} (\zst+\delta)
    \quad = \frac{|S_\jstar|+1 -k_\jstar + \delta |S_\jstar|}{|S_\jstar|} \leq 1+\delta.
\end{align}
Thus, the  upper bound on the $\frac{\cost(t)}{4\ell}$ term in the LHS of~\eqref{eq:pot} is at most 
$\frac{1+\delta}{4} \leq \nf{1}{3}$
provided $\delta \le \nf 13$.

Next, we lower bound the rate of decrease of potential $\Phi$. 
We begin by bounding the rate of decrease in potential due to because of server mass leaving all locations 
except $\sigma_t$:
\begin{align}
    \Delta^- 
    &= - \sum_{j \in [\ell], v \neq \sigma_t: \optt = 0} \frac{W_j}{\zt + \delta} \cdot \dotzt
    \quad \stackrel{\eqref{eq:rate}}{=} - \sum_{j, v \in S_j: \optt = 0} \frac{1}{\zt+\delta} \cdot \frac{\zt+\delta}{|S_j|} \notag \\
    &= -\sum_j  \frac{|\{v \in S_j: \optt = 0 \}|}{|S_j|}  
    \quad \stackrel{\eqref{eq:z-lb}}{\le}  - \sum_j \frac{|S_j| - k_j}{|S_j|} \leq -\ell \left(1 - \frac{2}{3\ell} \right) 
    = -\ell + \nf 23. \label{eq:delta-minus}
\end{align}
Next, we bound the rate of increase in potential due
to server classes $j\not=j^*$ because of server mass entering
$\sigma_t$:
\begin{align*}
    \Delta^+ 
    &= \sum_{j \not= j^*} \frac{W_j}{\zt[\sigma_t]+\delta} \cdot \dotzt[\sigma_t]
    \quad \stackrel{\eqref{eq:rate}}{=} \sum_{j \not= j^*, v\in S_j} \frac{W_j}{\zt[\sigma_t]+\delta} \cdot \frac{\zt+\delta}{|S_j|W_j}\\
    &= \sum_{j \not= j^*}   \frac{\sum_{v\in S_j} (\zt+\delta)}{|S_j|(\zt[\sigma_t]+\delta)} 
    \quad = \sum_{j \not= j^*}  \frac{(|S_j| - k_j  + (1-\zt[\sigma_t]))+\delta \cdot |S_j|}{|S_j|(\zt[\sigma_t]+\delta)} \; \\ 
    &\stackrel{\eqref{eq:z-lb}}{\le} \sum_{j \not= j^*}  \frac{(|S_j| - k_j  + \nf1{2\ell})+\delta \cdot |S_j|}{|S_j|(1-\nf{1}{2 \ell}+\delta)} 
    \quad \stackrel{\eqref{eq:z-lb}}{\le} \sum_{j \neq \jstar} \frac{1 - \nf{2}{3\ell} + \nf{1}{6\ell} + \delta}{1 - \nf{1}{2\ell} + \delta} %\leq  \sum_{j \neq \jstar} \left( 1 - \nf{1}{2 \ell} \right) \cdot \left( 1 - \nf{1}{3\ell} \right) \\
    \quad\leq \ell-1, 
\end{align*}
provided $\delta = \nf{1}{2\ell}$. Combining with
\eqref{eq:delta-minus}, we see that the overall change in potential is
$\Delta^- + \Delta^+ \leq -\nf13$. 
Consequently, we get that the change in potential pays for the
increase in the algorithm's cost (divided by $4\ell$)---which shows
\eqref{eq:pot}---when the fractional solution changes.

This implies that we have an algorithm for maintaining $\zt$ that satisfies \eqref{eq:cover-relax}. In terms of the competitive ratio, the algorithm loses $4\ell$ in \eqref{eq:pot} and $\ln(1+\nf1{\delta}) = O(\log \ell)$ in the Lipschitzness of the potential function. Note that \eqref{eq:cover-relax} implies that for all $t$, there exists $j$ such that $\xt[\sigma_t] \geq \frac{1}{2\ell}$. We scale the fractional variables to obtain $\xts := \min(2\ell\xt, 1)$; then, for all $t$, there exists $j$ such that $\xts[\sigma_t] = 1$. Note that this satisfies the condition in \Cref{thm:fractional}. Equivalently, the corresponding ``anti-page'' variables $\zts := 1-\xts$ satisfy the following condition for all $t$:
\begin{equation}\label{eq:cover-zts}
    \exists j \text{ such that } \zts[\sigma_t] = 0.
\end{equation}
The last scaling step creates a resource augmentation of $2\ell$, and increases the competitive ratio to $O(\ell^2\log \ell)$. 
This completes the proof of \Cref{thm:fractional}.


\subsection{Rounding the Fractional Solution Online}
\label{sec:online-rounding}

We round the fractional solution for each weight class $j$ separately. 
Let $T_j$ represent the request times $t$ when \eqref{eq:cover-zts} is satisfied by 
weight class $j$. Note that the solution $\zts$ for weight class $j$
represents a feasible fractional solution for an instance of the paging
problem with $2\ell k_j$ cache slots,
where there is a page request for each time $t\in T_j$ at location $\sigma_t$.

We now invoke the following known online rounding algorithm for the paging problem
separately in each weight class $j$ to complete the proof of \Cref{thm:online}.
\begin{lemma}\label{lem:page-rounding}{\cite{BlumBK99}}
    There is a randomized (polynomial time) online algorithm that converts any feasible fractional solution
    for an instance of the \page problem to an integral solution using the 
    same number of cache slots, and incurs constant times the cost of the fractional solution.
\end{lemma}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
