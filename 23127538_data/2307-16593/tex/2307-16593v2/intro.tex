\section{Introduction}

\paragraph{Context.}
\textit{Self-stabilization} is a general non-masking and lightweight
fault tolerance paradigm~\cite{Di74,AlDeDuPe19}. Precisely, a
distributed system achieving this property inherently tolerates
\textit{any} finite number of transient faults.\footnote{A {\em transient
fault} occurs at an unpredictable time, but does not result in a
permanent hardware damage. Moreover, as opposed to intermittent
faults, the frequency of transient faults is considered to be low.}
%
Indeed, starting from an arbitrary configuration, which may be the
result of such faults, a self-stabilizing system recovers \emph{within
finite time}, and without any external intervention, a so-called
\emph{legitimate configuration} from which it satisfies its
specification.

The difficulty of achieving fault tolerance in distributed systems
mainly relies on their asynchronous aspect. The impossibility of
achieving consensus in an asynchronous system in spite of at most one
 process crash~\cite{FLP85} is a famous example illustrating this fact.
% 
 Thus, fault tolerance, and in particular self-stabilization, often
 requires some kind of barrier synchronization to control the
 asynchronism of the system by making processes progress roughly at
 the same speed.

 In that spirit, the \emph{asynchronous unison problem} (unison for
 short) is a basic yet fundamental problem that helps the design of
 asynchronous distributed systems, especially self-stabilizing ones.
%
 The unison problem consists in maintaining a local clock at each
 node; the domain of clocks being infinite or bounded. Each node
 should increment its own clock infinitely often.\footnote{In case the
 clock values are bounded, increments are modulo some value $B$,
 called the \emph{period}.} Furthermore, the safety property of the
 unison requires the difference between the clocks of any two
 neighbors to always be at most one increment. Notice that this
 problem can be trivially generalized (as done here) by conditioning
 increments at each node $p$ to the satisfaction of some local
 predicate $P(p)$ (\emph{n.b.}, we retrieve the initial problem if
 $P(p) \equiv true$).

Unison has numerous applications, especially in
self-stabilization. Among others, it can be used to simulate
synchronous systems in asynchronous environments~\cite{AD17j,DDL19j},
free an asynchronous system from its fairness assumption (using the
cross-over composition)~\cite{BeGaJo01}, facilitate the termination
detection~\cite{BlJoLePe22}, or achieve infimum computation and local
resource allocation~\cite{BP08c}.

In this paper, we consider the unison problem in the most commonly
used model of the self-stabilizing area: the \emph{atomic-state}
model~\cite{Di74,AlDeDuPe19}.  This model is a locally-shared memory
model with composite atomicity: the state of each node is stored into
registers and these registers can be directly read by neighboring
nodes; moreover, in one atomic step, a node can read its state and
that of its neighbors, perform some local computations, and update its
state accordingly.
%
In the atomic-state model, asynchrony is materialized by an adversary
called \emph{daemon} that restricts the set of possible executions.
%
We consider here the weakest (\emph{i.e.}, the most general) daemon:
the \emph{distributed unfair daemon}.

Self-stabilizing algorithms are mainly compared according to their
\emph{stabilization time}, \emph{i.e.}, the worst-case time to reach a
legitimate configuration starting from an arbitrary one. In the
atomic-state model, stabilization time can be evaluated in terms of
{\em rounds} and {\em moves}.  Rounds~\cite{CDPV02c} capture the
execution time according to the speed of the slowest nodes. Moves
count the number of local state updates.  So, the move complexity is
rather a measure of work than a measure of time.

It turns out that obtaining efficient stabilization time both in
rounds and steps is a difficult issue. Usually, techniques to design
an algorithm achieving a stabilization time polynomial in moves
usually makes its rounds complexity inherently linear in $n$, the
number of nodes; see,
e.g.,~\cite{CoDeVi09,AlCoDeDuPe17,DeJo19,DeIlJo22}. Conversely, achieving the
asymptotic optimality in rounds, \emph{i.e.}, $O(D)$ where $D$ is the
network diameter, commonly makes the stabilization time in
moves exponential; see, \emph{e.g.},~\cite{DeJo16,GHIJ19}.
%
In a best-effort spirit, Cournier
\emph{et al.}~\cite{CoRoVi19} have proposed to study what they call
\emph{fully-polynomial} self-stabilizing solutions, \emph{i.e.},
self-stabilizing algorithms whose round complexity is polynomial on the
network diameter and move complexity is polynomial on the network
size.\footnote{Actually, in~\cite{CoRoVi19}, authors consider atomic
steps instead of moves. However, these two time units essentially
measure the same thing: the workload. By the way, the number of moves
and the number of atomic steps are closely related: if an execution
$e$ contains $x$ steps, then the number $y$ of moves in $e$ satisfies
$x \leq y \leq n\cdot x$.}

\paragraph{Contribution.}

We propose the first fully-polynomial self-stabilizing unison in the
atomic-state model assuming a distributed unfair daemon. This
algorithm works in an anonymous network of arbitrary
topology. Moreover, it does not require any local port labeling at
nodes. In that sense, the computational model we use is close to the
\emph{stone age} model of Emek and Wattenhofer~\cite{EmWa13}.

To the best our our knowledge, this is a first fully-polynomial
self-stabilizing algorithm solving a \emph{dynamic
  problem}.\footnote{As opposed to a \emph{static problem} that
defines a task of calculating a function that depends on the system in
which it is evaluated~\cite{Ti06}.} This is also the first
self-stabilizing unison for arbitrary anonymous networks achieving an
asymptotically optimal stabilization time in rounds (\emph{i.e.},
$O(D)$) using a bounded memory at each node.

In more detail, assuming a period $B \geq 2D+2$, our solution
stabilizes in at most $2D-2$ rounds and $O(\min(n^2B, n^3))$ moves
using $O(\log B)$ bits per node.
%
Overall, our unison achieves an outstanding trade-off
between time, workload, and space.

We also analyze the efficiency of our algorithm to simulate any
synchronous self-stabilizing algorithm in an asynchronous environment
(under the unfair daemon).  If the input synchronous self-stabilizing
algorithm is \emph{silent}\footnote{In the atomic-state model, a
self-stabilizing algorithm is silent if all its executions terminate.}
and stabilizes in at most $T$ synchronous rounds, then its simulation is also
silent and self-stabilizing; moreover, its stabilization time is at most
$5D+3T$ rounds and $O(\min(n^2B, n^3))+nT$ moves using $O(M+\log(B))$
bits per node, where $M$ is the memory requirement of the input
algorithm.

An important consequence of this latter result is that one can easily
obtain the state-of-the-art leader election and BFS spanning tree
construction of the literature for asynchronous identified and
arbitrary connected networks simply by simulating the synchronous
algorithm of Kravchik and Kutten~\cite{KrKU13}. Precisely, by
simulating this algorithm using our unison, we obtain a stabilization
time in $O(D)$ rounds and $O(\min(n^2B, n^3))$ moves using
$O(\log(N))$ bits per node, where $N$ is any upper bound on $n$.  To
the best of our knowledge, there was no such an efficient solution
until now in the literature.

\paragraph{Related Work.}

The asynchronous unison studied here is a variant of the {\em
  synchronous unison} problem proposed by Even and
Rajsbaum~\cite{ER90}. This latter problem is dedicated to synchronous
systems and requires all clocks increment infinitely often and become
eventually fully synchronized.  In~\cite{ER90}, Even and Rajsbaum
consider this problem in a non-fault-tolerant context, yet assuming
that nodes do not necessarily start at the same time.

Gouda and Herman~\cite{GH90j} have proposed the first self-stabilizing
synchronous unison. Their algorithm works in anonymous synchronous
systems of arbitrary connected topology using infinite clocks.  A
solution working with the same settings, yet implementing bounded
clocks, is proposed in~\cite{ADG91j}.
%% ci-dessous, c'est faux : en fait, ils utilisent l'algo de Boulinier
%% pour faire de la leader election
%% Je commente
%% The asynchronous
%% self-stabilizing unison problem in synchronous setting has been
%% studied in \cite{KrKU13}, an algorithm converging in $O(D)$ with
%% bounded memory is presented.

Johnen \emph{et al.} investigated  the asynchronous self-stabilizing 
unison in oriented trees in~\cite{JADT02j}.
%
The first self-stabilizing asynchronous unison for general graphs was
proposed by Couvreur \emph{et al.}~\cite{CoFrGo92} in the link-register
model (a locally-shared memory model without composite
atomicity). However, no complexity analysis was given. Another
solution which stabilizes in $O(n)$ rounds has been proposed by
Boulinier \emph{et al.}~\cite{BoPeVi04} in the atomic-state model
assuming a distributed unfair daemon. Its move complexity is shown
in~\cite{DePe12} to be in $O(Dn^3+\alpha n^2)$, where $\alpha$ is a
parameter of the algorithm that should satisfies $\alpha \geq L - 2$,
where $L$ is the length of the longest hole in the network.
%
Boulinier proposes in his PhD thesis a parametric solution which
generalizes both the solutions of
\cite{CoFrGo92} and \cite{BoPeVi04}. In particular, the complexity
analysis of this latter algorithm reveals an upper bound in
$O(D.n)$ rounds on the stabilization time of the atomic-state model version of the Couvreur \emph{et
al.}'s algorithm.


Awerbuch \emph{et al.}~\cite{AwKuMaPaVa93} proposes a self-stabilizing
unison (called clock synchronizer in their paper) that stabilizes in
$O(D)$ rounds using an infinite state space. The move complexity of
their solution is not analyzed.
%  
An asynchronous self-stabilizing unison algorithm is given
in~\cite{DeJo19}. It stabilizes in $O(n)$ rounds and $O(\Delta.n^2)$
moves using unbounded local memories.
%
Emek and Keren present in the stone age model~\cite{EmKe21} a
self-stabilizing unison that stabilizes in $O(B^3)$ rounds, where $B$
is an upper bound on $D$ known by all nodes. Their solution requires
$O(\log(B))$ bits per nodes. Moreover, since node activations are
assumed to be fair, the move complexity of their solution cannot be
bounded.

In~\cite{DIJM23}, we propose an algorithm that transforms any
terminating synchronous algorithms into an asynchronous silent
self-stabilizing fully-polynomial algorithm.  The memory requirement
of the produced algorithm is in $O(T\times M)$ bits per nodes, where
$T$ and $M$ are the time and space complexities of the input
algorithm.  This transformer thus cannot practically build solutions
for dynamic problems such as unison.  Moreover, although it works on a
strictly smaller class of algorithms, the synchronizer of the current
paper has similar round and move complexities as the transformer
of~\cite{DIJM23} while achieving a much better memory requirement.


\paragraph{Roadmap.}
The rest of the paper is organized as follows. The next section is
dedicated to the computational model and basic definitions. In
Section~\ref{sect:algo}, we present our unison algorithm, prove its
self-stabilization, and study its time complexity. In
Section~\ref{sec:synchroniseur} deals with the
simulation of synchronous self-stabilizing algorithms in an
asynchronous environment using our unison algorithm.



