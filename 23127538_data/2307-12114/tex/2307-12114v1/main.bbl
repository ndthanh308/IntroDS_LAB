\begin{thebibliography}{54}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Amalvy et~al.(2022)Amalvy, Labatut, and Dufour}]{amalvy2022bert}
A.~Amalvy, V.~Labatut, and R.~Dufour. 2022.
\newblock \href {https://univ-avignon.hal.science/hal-03972448/} {Data
  augmentation for robust character detection in fantasy novels}.
\newblock \emph{HAL}, page 03972448.

\bibitem[{Baker et~al.(2016)Baker, Silins, Guo, Ali, H{"{o}}gberg, Stenius, and
  Korhonen}]{DBLP:journals/bioinformatics/BakerSGAHSK16}
Simon Baker, Ilona Silins, Yufan Guo, Imran Ali, Johan H{"{o}}gberg, Ulla
  Stenius, and Anna Korhonen. 2016.
\newblock \href {https://doi.org/10.1093/bioinformatics/btv585} {Automatic
  semantic classification of scientific literature according to the hallmarks
  of cancer}.
\newblock \emph{Bioinform.}, 32(3):432--440.

\bibitem[{Bang et~al.(2023)Bang, Cahyawijaya, Lee, Dai, Su, Wilie, Lovenia, Ji,
  Yu, Chung et~al.}]{bang2023multitask}
Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie,
  Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et~al. 2023.
\newblock A multitask, multilingual, multimodal evaluation of chatgpt on
  reasoning, hallucination, and interactivity.
\newblock \emph{arXiv preprint arXiv:2302.04023}.

\bibitem[{Black et~al.(2022)Black, Biderman, Hallahan, Anthony, Gao, Golding,
  He, Leahy, McDonell, Phang, Pieler, Prashanth, Purohit, Reynolds, Tow, Wang,
  and Weinbach}]{black-etal-2022-gpt}
Sidney Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao,
  Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang,
  Michael Pieler, Usvsn~Sai Prashanth, Shivanshu Purohit, Laria Reynolds,
  Jonathan Tow, Ben Wang, and Samuel Weinbach. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.bigscience-1.9}
  {{GPT}-{N}eo{X}-20{B}: An open-source autoregressive language model}.
\newblock In \emph{Proceedings of BigScience Episode {\#}5 -- Workshop on
  Challenges {\&} Perspectives in Creating Large Language Models}, pages
  95--136, virtual+Dublin. Association for Computational Linguistics.

\bibitem[{Bravo et~al.(2015)Bravo, Pi{\~{n}}ero, Queralt-Rosinach, Rautschka,
  and Furlong}]{Bravo2015}
{\`{A}}lex Bravo, Janet Pi{\~{n}}ero, N{\'{u}}ria Queralt-Rosinach, Michael
  Rautschka, and Laura~I Furlong. 2015.
\newblock \href {https://doi.org/10.1186/s12859-015-0472-9} {Extraction of
  relations between genes and diseases from text and large-scale data analysis:
  implications for translational research}.
\newblock \emph{{BMC} Bioinformatics}, 16(1).

\bibitem[{Chen et~al.(2021)Chen, Allot, Leaman, Do{\u{g}}an, and
  Lu}]{chen2021overview}
Qingyu Chen, Alexis Allot, Robert Leaman, Rezarta~Islamaj Do{\u{g}}an, and
  Zhiyong Lu. 2021.
\newblock Overview of the biocreative vii litcovid track: multi-label topic
  classification for covid-19 literature annotation.
\newblock In \emph{Proceedings of the seventh BioCreative challenge evaluation
  workshop}.

\bibitem[{Chen et~al.(2023)Chen, Li, Lu, Van, Aerts, Savova, and
  Bitterman}]{chen2023evaluation}
Shan Chen, Yingya Li, Sheng Lu, Hoang Van, Hugo~JWL Aerts, Guergana~K Savova,
  and Danielle~S Bitterman. 2023.
\newblock Evaluation of chatgpt family of models for biomedical reasoning and
  classification.
\newblock \emph{arXiv preprint arXiv:2304.02496}.

\bibitem[{Chowdhery et~al.(2022)Chowdhery, Narang, Devlin, Bosma, Mishra,
  Roberts, Barham, Chung, Sutton, Gehrmann, Schuh, Shi, Tsvyashchenko, Maynez,
  Rao, Barnes, Tay, Shazeer, Prabhakaran, Reif, Du, Hutchinson, Pope, Bradbury,
  Austin, Isard, Gur-Ari, Yin, Duke, Levskaya, Ghemawat, Dev, Michalewski,
  Garcia, Misra, Robinson, Fedus, Zhou, Ippolito, Luan, Lim, Zoph, Spiridonov,
  Sepassi, Dohan, Agrawal, Omernick, Dai, Pillai, Pellat, Lewkowycz, Moreira,
  Child, Polozov, Lee, Zhou, Wang, Saeta, Diaz, Firat, Catasta, Wei,
  Meier-Hellstern, Eck, Dean, Petrov, and Fiedel}]{chowdhery2022palm}
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
  Adam Roberts, Paul Barham, Hyung~Won Chung, Charles Sutton, Sebastian
  Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
  Abhishek Rao, Parker Barnes, Yi~Tay, Noam Shazeer, Vinodkumar Prabhakaran,
  Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob
  Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm
  Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia,
  Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David
  Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David
  Dohan, Shivani Agrawal, Mark Omernick, Andrew~M. Dai,
  Thanumalayan~Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
  Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi
  Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,
  Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
  2022.
\newblock \href {http://arxiv.org/abs/2204.02311} {Palm: Scaling language
  modeling with pathways}.

\bibitem[{Chung et~al.(2022{\natexlab{a}})Chung, Hou, Longpre, Zoph, Tay,
  Fedus, Li, Wang, Dehghani, Brahma, Webson, Gu, Dai, Suzgun, Chen, Chowdhery,
  Narang, Mishra, Yu, Zhao, Huang, Dai, Yu, Petrov, Chi, Dean, Devlin, Roberts,
  Zhou, Le, and Wei}]{https://doi.org/10.48550/arxiv.2210.11416}
Hyung~Won Chung, Le~Hou, Shayne Longpre, Barret Zoph, Yi~Tay, William Fedus,
  Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson,
  Shixiang~Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha
  Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping
  Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed~H. Chi, Jeff Dean, Jacob
  Devlin, Adam Roberts, Denny Zhou, Quoc~V. Le, and Jason Wei.
  2022{\natexlab{a}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2210.11416} {Scaling
  instruction-finetuned language models}.

\bibitem[{Chung et~al.(2022{\natexlab{b}})Chung, Hou, Longpre, Zoph, Tay,
  Fedus, Li, Wang, Dehghani, Brahma, Webson, Gu, Dai, Suzgun, Chen, Chowdhery,
  Castro-Ros, Pellat, Robinson, Valter, Narang, Mishra, Yu, Zhao, Huang, Dai,
  Yu, Petrov, Chi, Dean, Devlin, Roberts, Zhou, Le, and Wei}]{chung2022scaling}
Hyung~Won Chung, Le~Hou, Shayne Longpre, Barret Zoph, Yi~Tay, William Fedus,
  Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson,
  Shixiang~Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha
  Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter,
  Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew
  Dai, Hongkun Yu, Slav Petrov, Ed~H. Chi, Jeff Dean, Jacob Devlin, Adam
  Roberts, Denny Zhou, Quoc~V. Le, and Jason Wei. 2022{\natexlab{b}}.
\newblock \href {http://arxiv.org/abs/2210.11416} {Scaling
  instruction-finetuned language models}.

\bibitem[{Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova}]{devlin-etal-2019-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.
\newblock \href {https://doi.org/10.18653/v1/N19-1423} {{BERT}: Pre-training of
  deep bidirectional transformers for language understanding}.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186,
  Minneapolis, Minnesota. Association for Computational Linguistics.

\bibitem[{DeYoung et~al.(2020)DeYoung, Lehman, Nye, Marshall, and
  Wallace}]{deyoung-etal-2020-evidence}
Jay DeYoung, Eric Lehman, Benjamin Nye, Iain Marshall, and Byron~C. Wallace.
  2020.
\newblock \href {https://www.aclweb.org/anthology/2020.bionlp-1.13} {Evidence
  inference 2.0: More data, better models}.
\newblock In \emph{Proceedings of the 19th SIGBioMed Workshop on Biomedical
  Language Processing}, pages 123--132, Online. Association for Computational
  Linguistics.

\bibitem[{Dogan et~al.(2014)Dogan, Leaman, and Lu}]{Dogan2014NCBIDC}
Rezarta~Islamaj Dogan, Robert Leaman, and Zhiyong Lu. 2014.
\newblock Ncbi disease corpus: A resource for disease name recognition and
  concept normalization.
\newblock \emph{Journal of biomedical informatics}, 47:1--10.

\bibitem[{Efrat and Levy(2020)}]{efrat2020turking}
Avia Efrat and Omer Levy. 2020.
\newblock \href {http://arxiv.org/abs/2010.11982} {The turking test: Can
  language models understand instructions?}

\bibitem[{Fries et~al.(2022)Fries, Weber, Seelam, Altay, Datta, Garda, Kang,
  Su, Kusa, Cahyawijaya, Barth, Ott, Samwald, Bach, Biderman, S{\"a}nger, Wang,
  Callahan, Peri{\~n}{\'a}n, Gigant, Haller, Chim, Posada, Giorgi, Sivaraman,
  P{\`a}mies, Nezhurina, Martin, Cullan, Freidank, Dahlberg, Mishra, Bose,
  Broad, Labrak, Deshmukh, Kiblawi, Singh, Vu, Neeraj, Golde, del Moral, and
  Beilharz}]{fries2022bigbio}
Jason~Alan Fries, Leon Weber, Natasha Seelam, Gabriel Altay, Debajyoti Datta,
  Samuele Garda, Myungsun Kang, Ruisi Su, Wojciech Kusa, Samuel Cahyawijaya,
  Fabio Barth, Simon Ott, Matthias Samwald, Stephen Bach, Stella Biderman,
  Mario S{\"a}nger, Bo~Wang, Alison Callahan, Daniel~Le{\'o}n Peri{\~n}{\'a}n,
  Th{\'e}o Gigant, Patrick Haller, Jenny Chim, Jose~David Posada, John~Michael
  Giorgi, Karthik~Rangasai Sivaraman, Marc P{\`a}mies, Marianna Nezhurina,
  Robert Martin, Michael Cullan, Moritz Freidank, Nathan Dahlberg, Shubhanshu
  Mishra, Shamik Bose, Nicholas~Michio Broad, Yanis Labrak, Shlok~S Deshmukh,
  Sid Kiblawi, Ayush Singh, Minh~Chien Vu, Trishala Neeraj, Jonas Golde,
  Albert~Villanova del Moral, and Benjamin Beilharz. 2022.
\newblock \href {https://openreview.net/forum?id=8lQDn9zTQlW} {Bigbio: A
  framework for data-centric biomedical natural language processing}.
\newblock In \emph{Thirty-sixth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track}.

\bibitem[{Gao et~al.(2020)Gao, Biderman, Black, Golding, Hoppe, Foster, Phang,
  He, Thite, Nabeshima, Presser, and Leahy}]{gao2020pile}
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles
  Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser,
  and Connor Leahy. 2020.
\newblock \href {http://arxiv.org/abs/2101.00027} {The pile: An 800gb dataset
  of diverse text for language modeling}.

\bibitem[{Gu et~al.(2021)Gu, Tinn, Cheng, Lucas, Usuyama, Liu, Naumann, Gao,
  and Poon}]{10.1145/3458754}
Yu~Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu,
  Tristan Naumann, Jianfeng Gao, and Hoifung Poon. 2021.
\newblock \href {https://doi.org/10.1145/3458754} {Domain-specific language
  model pretraining for biomedical natural language processing}.
\newblock \emph{ACM Trans. Comput. Healthcare}, 3(1).

\bibitem[{Hoffmann et~al.(2022)Hoffmann, Borgeaud, Mensch, Buchatskaya, Cai,
  Rutherford, de~Las~Casas, Hendricks, Welbl, Clark, Hennigan, Noland,
  Millican, van~den Driessche, Damoc, Guy, Osindero, Simonyan, Elsen, Rae,
  Vinyals, and Sifre}]{hoffmann2022training}
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor
  Cai, Eliza Rutherford, Diego de~Las~Casas, Lisa~Anne Hendricks, Johannes
  Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van~den
  Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich
  Elsen, Jack~W. Rae, Oriol Vinyals, and Laurent Sifre. 2022.
\newblock \href {http://arxiv.org/abs/2203.15556} {Training compute-optimal
  large language models}.

\bibitem[{Jiang et~al.(2020)Jiang, Xu, Araki, and
  Neubig}]{jiang-etal-2020-know}
Zhengbao Jiang, Frank~F. Xu, Jun Araki, and Graham Neubig. 2020.
\newblock \href {https://doi.org/10.1162/tacl_a_00324} {How can we know what
  language models know?}
\newblock \emph{Transactions of the Association for Computational Linguistics},
  8:423--438.

\bibitem[{Jin et~al.(2021)Jin, Pan, Oufattole, Weng, Fang, and
  Szolovits}]{Medical2021}
Di~Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter
  Szolovits. 2021.
\newblock \href {https://doi.org/10.3390/app11146421} {What disease does this
  patient have? a large-scale open domain question answering dataset from
  medical exams}.
\newblock \emph{Applied Sciences}, 11(14):6421.

\bibitem[{Jung et~al.(2022)Jung, Qin, Welleck, Brahman, Bhagavatula, Le~Bras,
  and Choi}]{jung-etal-2022-maieutic}
Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra Bhagavatula,
  Ronan Le~Bras, and Yejin Choi. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.82} {Maieutic
  prompting: Logically consistent reasoning with recursive explanations}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 1266--1279, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Khot et~al.(2018)Khot, Sabharwal, and Clark}]{scitail}
Tushar Khot, Ashish Sabharwal, and Peter Clark. 2018.
\newblock Scitail: A textual entailment dataset from science question
  answering.
\newblock In \emph{AAAI}.

\bibitem[{Lamichhane(2023)}]{lamichhane2023evaluation}
Bishal Lamichhane. 2023.
\newblock Evaluation of chatgpt for nlp-based mental health applications.
\newblock \emph{arXiv preprint arXiv:2303.15727}.

\bibitem[{Li et~al.(2016)Li, Sun, Johnson, Sciaky, Wei, Leaman, Davis,
  Mattingly, Wiegers, and Lu}]{DBLP:journals/biodb/LiSJSWLDMWL16}
Jiao Li, Yueping Sun, Robin~J. Johnson, Daniela Sciaky, Chih{-}Hsuan Wei,
  Robert Leaman, Allan~Peter Davis, Carolyn~J. Mattingly, Thomas~C. Wiegers,
  and Zhiyong Lu. 2016.
\newblock \href {https://doi.org/10.1093/database/baw068} {Biocreative {V}
  {CDR} task corpus: a resource for chemical disease relation extraction}.
\newblock \emph{Database J. Biol. Databases Curation}, 2016.

\bibitem[{Lin(2004)}]{lin-2004-rouge}
Chin-Yew Lin. 2004.
\newblock \href {https://aclanthology.org/W04-1013} {{ROUGE}: A package for
  automatic evaluation of summaries}.
\newblock In \emph{Text Summarization Branches Out}, pages 74--81, Barcelona,
  Spain. Association for Computational Linguistics.

\bibitem[{Liu et~al.(2023)Liu, Iter, Xu, Wang, Xu, and Zhu}]{liu2023gpteval}
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu.
  2023.
\newblock Gpteval: Nlg evaluation using gpt-4 with better human alignment.
\newblock \emph{arXiv preprint arXiv:2303.16634}.

\bibitem[{Mishra et~al.(2022{\natexlab{a}})Mishra, Khashabi, Baral, Choi, and
  Hajishirzi}]{mishra-etal-2022-reframing}
Swaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin Choi, and Hannaneh
  Hajishirzi. 2022{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/2022.findings-acl.50} {Reframing
  instructional prompts to {GPT}k{'}s language}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2022}, pages 589--612, Dublin, Ireland. Association for Computational
  Linguistics.

\bibitem[{Mishra et~al.(2022{\natexlab{b}})Mishra, Khashabi, Baral, and
  Hajishirzi}]{mishra-etal-2022-cross}
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi.
  2022{\natexlab{b}}.
\newblock \href {https://doi.org/10.18653/v1/2022.acl-long.244} {Cross-task
  generalization via natural language crowdsourcing instructions}.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 3470--3487,
  Dublin, Ireland. Association for Computational Linguistics.

\bibitem[{Neema and Toni(2020)}]{kotonya2020explainable}
Kotonya Neema and Francesca Toni. 2020.
\newblock Explainable automated fact-checking for public health claims.
\newblock \emph{arXiv preprint arXiv:2010.09926}.

\bibitem[{{Ortiz Suarez} et~al.(2019){Ortiz Suarez}, Sagot, and
  Romary}]{OrtizSuarezSagotRomary2019}
Pedro~Javier {Ortiz Suarez}, Benoit Sagot, and Laurent Romary. 2019.
\newblock \href {https://doi.org/10.14618/ids-pub-9021} {Asynchronous pipelines
  for processing huge corpora on medium to low resource infrastructures}.
\newblock Proceedings of the Workshop on Challenges in the Management of Large
  Corpora (CMLC-7) 2019. Cardiff, 22nd July 2019, pages 9 -- 16, Mannheim.
  Leibniz-Institut f{"u}r Deutsche Sprache.

\bibitem[{Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Ray, Schulman, Hilton, Kelton, Miller, Simens, Askell,
  Welinder, Christiano, Leike, and Lowe}]{NEURIPS2022_b1efde53}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John
  Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
  Askell, Peter Welinder, Paul~F Christiano, Jan Leike, and Ryan Lowe. 2022.
\newblock \href
  {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf}
  {Training language models to follow instructions with human feedback}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~35, pages 27730--27744. Curran Associates, Inc.

\bibitem[{Pal et~al.(2022)Pal, Umapathi, and Sankarasubbu}]{pmlr-v174-pal22a}
Ankit Pal, Logesh~Kumar Umapathi, and Malaikannan Sankarasubbu. 2022.
\newblock \href {https://proceedings.mlr.press/v174/pal22a.html} {Medmcqa: A
  large-scale multi-subject multi-choice dataset for medical domain question
  answering}.
\newblock In \emph{Proceedings of the Conference on Health, Inference, and
  Learning}, volume 174 of \emph{Proceedings of Machine Learning Research},
  pages 248--260. PMLR.

\bibitem[{Papineni et~al.(2002)Papineni, Roukos, Ward, and
  Zhu}]{10.3115/1073083.1073135}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.
\newblock \href {https://doi.org/10.3115/1073083.1073135} {Bleu: A method for
  automatic evaluation of machine translation}.
\newblock In \emph{Proceedings of the 40th Annual Meeting on Association for
  Computational Linguistics}, ACL '02, page 311–318, USA. Association for
  Computational Linguistics.

\bibitem[{Peng et~al.(2021)Peng, Chersoni, Hsu, and Huang}]{peng2021domain}
Bo~Peng, Emmanuele Chersoni, Yu-Yin Hsu, and Chu-Ren Huang. 2021.
\newblock Is domain adaptation worth your investment? comparing bert and
  finbert on financial tasks.
\newblock In \emph{Proceedings of the Third Workshop on Economics and Natural
  Language Processing}, pages 37--44.

\bibitem[{Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu}]{JMLR:v21:20-074}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu. 2020.
\newblock \href {http://jmlr.org/papers/v21/20-074.html} {Exploring the limits
  of transfer learning with a unified text-to-text transformer}.
\newblock \emph{Journal of Machine Learning Research}, 21(140):1--67.

\bibitem[{Rehana et~al.(2023)Rehana, {\c{C}}am, Basmaci, He, {\"O}zg{\"u}r, and
  Hur}]{rehana2023evaluation}
Hasin Rehana, Nur~Bengisu {\c{C}}am, Mert Basmaci, Yongqun He, Arzucan
  {\"O}zg{\"u}r, and Junguk Hur. 2023.
\newblock Evaluation of gpt and bert-based models on identifying
  protein-protein interactions in biomedical text.
\newblock \emph{arXiv preprint arXiv:2303.17728}.

\bibitem[{Reimers and Gurevych(2019)}]{reimers-2019-sentence-bert}
Nils Reimers and Iryna Gurevych. 2019.
\newblock \href {http://arxiv.org/abs/1908.10084} {Sentence-bert: Sentence
  embeddings using siamese bert-networks}.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing}. Association for Computational Linguistics.

\bibitem[{Sanh et~al.(2022)Sanh, Webson, Raffel, Bach, Sutawika, Alyafeai,
  Chaffin, Stiegler, Scao, Raja, Dey, Bari, Xu, Thakker, Sharma, Szczechla,
  Kim, Chhablani, Nayak, Datta, Chang, Jiang, Wang, Manica, Shen, Yong, Pandey,
  Bawden, Wang, Neeraj, Rozen, Sharma, Santilli, Fevry, Fries, Teehan, Bers,
  Biderman, Gao, Wolf, and Rush}]{sanh2022multitask}
Victor Sanh, Albert Webson, Colin Raffel, Stephen~H. Bach, Lintang Sutawika,
  Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven~Le Scao, Arun Raja,
  Manan Dey, M~Saiful Bari, Canwen Xu, Urmish Thakker, Shanya~Sharma Sharma,
  Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta,
  Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,
  Zheng~Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj,
  Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason~Alan
  Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf, and
  Alexander~M. Rush. 2022.
\newblock \href {http://arxiv.org/abs/2110.08207} {Multitask prompted training
  enables zero-shot task generalization}.

\bibitem[{Schick and Sch{\"u}tze(2021)}]{schick-schutze-2021-exploiting}
Timo Schick and Hinrich Sch{\"u}tze. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.eacl-main.20} {Exploiting
  cloze-questions for few-shot text classification and natural language
  inference}.
\newblock In \emph{Proceedings of the 16th Conference of the European Chapter
  of the Association for Computational Linguistics: Main Volume}, pages
  255--269, Online. Association for Computational Linguistics.

\bibitem[{Shivade(2017)}]{https://doi.org/10.13026/c2rs98}
Chaitanya Shivade. 2017.
\newblock \href {https://doi.org/10.13026/C2RS98} {Mednli — a natural
  language inference dataset for the clinical domain}.

\bibitem[{Singhal et~al.(2022)Singhal, Azizi, Tu, Mahdavi, Wei, Chung, Scales,
  Tanwani, Cole-Lewis, Pfohl, Payne, Seneviratne, Gamble, Kelly, Scharli,
  Chowdhery, Mansfield, y~Arcas, Webster, Corrado, Matias, Chou, Gottweis,
  Tomasev, Liu, Rajkomar, Barral, Semturs, Karthikesalingam, and
  Natarajan}]{singhal2022large}
Karan Singhal, Shekoofeh Azizi, Tao Tu, S.~Sara Mahdavi, Jason Wei, Hyung~Won
  Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry
  Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Nathaneal Scharli,
  Aakanksha Chowdhery, Philip Mansfield, Blaise~Aguera y~Arcas, Dale Webster,
  Greg~S. Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev,
  Yun Liu, Alvin Rajkomar, Joelle Barral, Christopher Semturs, Alan
  Karthikesalingam, and Vivek Natarajan. 2022.
\newblock \href {http://arxiv.org/abs/2212.13138} {Large language models encode
  clinical knowledge}.

\bibitem[{Smith et~al.(2022)Smith, Patwary, Norick, LeGresley, Rajbhandari,
  Casper, Liu, Prabhumoye, Zerveas, Korthikanti, Zhang, Child, Aminabadi,
  Bernauer, Song, Shoeybi, He, Houston, Tiwary, and Catanzaro}]{smith2022using}
Shaden Smith, Mostofa Patwary, Brandon Norick, Patrick LeGresley, Samyam
  Rajbhandari, Jared Casper, Zhun Liu, Shrimai Prabhumoye, George Zerveas,
  Vijay Korthikanti, Elton Zhang, Rewon Child, Reza~Yazdani Aminabadi, Julie
  Bernauer, Xia Song, Mohammad Shoeybi, Yuxiong He, Michael Houston, Saurabh
  Tiwary, and Bryan Catanzaro. 2022.
\newblock \href {http://arxiv.org/abs/2201.11990} {Using deepspeed and megatron
  to train megatron-turing nlg 530b, a large-scale generative language model}.

\bibitem[{Tay et~al.(2023)Tay, Dehghani, Tran, Garcia, Wei, Wang, Chung,
  Shakeri, Bahri, Schuster, Zheng, Zhou, Houlsby, and Metzler}]{tay2023ul2}
Yi~Tay, Mostafa Dehghani, Vinh~Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang,
  Hyung~Won Chung, Siamak Shakeri, Dara Bahri, Tal Schuster, Huaixiu~Steven
  Zheng, Denny Zhou, Neil Houlsby, and Donald Metzler. 2023.
\newblock \href {http://arxiv.org/abs/2205.05131} {Ul2: Unifying language
  learning paradigms}.

\bibitem[{Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux,
  Lacroix, Rozière, Goyal, Hambro, Azhar, Rodriguez, Joulin, Grave, and
  Lample}]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro,
  Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume
  Lample. 2023.
\newblock \href {http://arxiv.org/abs/2302.13971} {Llama: Open and efficient
  foundation language models}.

\bibitem[{Tsatsaronis et~al.(2015)Tsatsaronis, Balikas, Malakasiotis, Partalas,
  Zschunke, Alvers, Weissenborn, Krithara, Petridis, Polychronopoulos
  et~al.}]{tsatsaronis2015overview}
George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas,
  Matthias Zschunke, Michael~R Alvers, Dirk Weissenborn, Anastasia Krithara,
  Sergios Petridis, Dimitris Polychronopoulos, et~al. 2015.
\newblock An overview of the bioasq large-scale biomedical semantic indexing
  and question answering competition.
\newblock \emph{BMC bioinformatics}, 16(1):138.

\bibitem[{Uzuner et~al.(2008)Uzuner, Goldstein, Luo, and
  Kohane}]{uzuner2008identifying}
Ozlem Uzuner, Ira Goldstein, Yuan Luo, and Isaac Kohane. 2008.
\newblock \href {https://doi.org/10.1136/amiajnl-2011-000784} {Identifying
  patient smoking status from medical discharge records}.
\newblock \emph{Journal of the American Medical Informatics Association},
  15(1):14--24.

\bibitem[{Wang et~al.(2022{\natexlab{a}})Wang, Kordi, Mishra, Liu, Smith,
  Khashabi, and Hajishirzi}]{wang2022selfinstruct}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A. Smith, Daniel
  Khashabi, and Hannaneh Hajishirzi. 2022{\natexlab{a}}.
\newblock \href {http://arxiv.org/abs/2212.10560} {Self-instruct: Aligning
  language model with self generated instructions}.

\bibitem[{Wang et~al.(2022{\natexlab{b}})Wang, Mishra, Alipoormolabashi, Kordi,
  Mirzaei, Naik, Ashok, Dhanasekaran, Arunkumar, Stap, Pathak, Karamanolakis,
  Lai, Purohit, Mondal, Anderson, Kuznia, Doshi, Pal, Patel, Moradshahi,
  Parmar, Purohit, Varshney, Kaza, Verma, Puri, Karia, Doshi, Sampat, Mishra,
  Reddy~A, Patro, Dixit, and Shen}]{wang-etal-2022-super}
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza
  Mirzaei, Atharva Naik, Arjun Ashok, Arut~Selvan Dhanasekaran, Anjana
  Arunkumar, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai,
  Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi,
  Kuntal~Kumar Pal, Maitreya Patel, Mehrad Moradshahi, Mihir Parmar, Mirali
  Purohit, Neeraj Varshney, Phani~Rohitha Kaza, Pulkit Verma, Ravsehaj~Singh
  Puri, Rushang Karia, Savan Doshi, Shailaja~Keyur Sampat, Siddhartha Mishra,
  Sujan Reddy~A, Sumanta Patro, Tanay Dixit, and Xudong Shen.
  2022{\natexlab{b}}.
\newblock \href {https://aclanthology.org/2022.emnlp-main.340}
  {Super-{N}atural{I}nstructions: Generalization via declarative instructions
  on 1600+ {NLP} tasks}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 5085--5109, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Wei et~al.(2022{\natexlab{a}})Wei, Bosma, Zhao, Guu, Yu, Lester, Du,
  Dai, and Le}]{wei2022finetuned}
Jason Wei, Maarten Bosma, Vincent~Y. Zhao, Kelvin Guu, Adams~Wei Yu, Brian
  Lester, Nan Du, Andrew~M. Dai, and Quoc~V. Le. 2022{\natexlab{a}}.
\newblock \href {http://arxiv.org/abs/2109.01652} {Finetuned language models
  are zero-shot learners}.

\bibitem[{Wei et~al.(2022{\natexlab{b}})Wei, Wang, Schuurmans, Bosma, brian
  ichter, Xia, Chi, Le, and Zhou}]{wei2022chain}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia,
  Ed~H. Chi, Quoc~V Le, and Denny Zhou. 2022{\natexlab{b}}.
\newblock \href {https://openreview.net/forum?id=_VjQlMeSB_J} {Chain of thought
  prompting elicits reasoning in large language models}.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Welbl et~al.(2017)Welbl, Liu, and
  Gardner}]{welbl-etal-2017-crowdsourcing}
Johannes Welbl, Nelson~F. Liu, and Matt Gardner. 2017.
\newblock \href {https://doi.org/10.18653/v1/W17-4413} {Crowdsourcing multiple
  choice science questions}.
\newblock In \emph{Proceedings of the 3rd Workshop on Noisy User-generated
  Text}, pages 94--106, Copenhagen, Denmark. Association for Computational
  Linguistics.

\bibitem[{Ye et~al.(2023)Ye, Chen, Xu, Zu, Shao, Liu, Cui, Zhou, Gong, Shen,
  Zhou, Chen, Gui, Zhang, and Huang}]{ye2023comprehensive}
Junjie Ye, Xuanting Chen, Nuo Xu, Can Zu, Zekai Shao, Shichun Liu, Yuhan Cui,
  Zeyang Zhou, Chao Gong, Yang Shen, Jie Zhou, Siming Chen, Tao Gui, Qi~Zhang,
  and Xuanjing Huang. 2023.
\newblock \href {http://arxiv.org/abs/2303.10420} {A comprehensive capability
  analysis of gpt-3 and gpt-3.5 series models}.

\bibitem[{Zhang et~al.(2022)Zhang, Roller, Goyal, Artetxe, Chen, Chen, Dewan,
  Diab, Li, Lin, Mihaylov, Ott, Shleifer, Shuster, Simig, Koura, Sridhar, Wang,
  and Zettlemoyer}]{zhang2022opt}
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
  Chen, Christopher Dewan, Mona Diab, Xian Li, Xi~Victoria Lin, Todor Mihaylov,
  Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit~Singh Koura, Anjali
  Sridhar, Tianlu Wang, and Luke Zettlemoyer. 2022.
\newblock \href {http://arxiv.org/abs/2205.01068} {Opt: Open pre-trained
  transformer language models}.

\bibitem[{Zhang et~al.(2020)Zhang, Kishore, Wu, Weinberger, and
  Artzi}]{Zhang2020BERTScore}
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian~Q. Weinberger, and Yoav Artzi.
  2020.
\newblock \href {https://openreview.net/forum?id=SkeHuCVFDr} {Bertscore:
  Evaluating text generation with bert}.
\newblock In \emph{International Conference on Learning Representations}.

\end{thebibliography}
