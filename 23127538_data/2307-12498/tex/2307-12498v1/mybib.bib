@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{parada2022pmct,
  title={pMCT: Patched Multi-Condition Training for Robust Speech Recognition},
  author={Parada, Pablo Peso and Dobrowolska, Agnieszka and Saravanan, Karthikeyan and Ozay, Mete},
  journal={arXiv preprint arXiv:2207.04949},
  year={2022}
}

@article{hu2023gradient,
  title={Gradient Remedy for Multi-Task Learning in End-to-End Noise-Robust Speech Recognition},
  author={Hu, Yuchen and Chen, Chen and Li, Ruizhe and Zhu, Qiushi and Chng, Eng Siong},
  journal={arXiv preprint arXiv:2302.11362},
  year={2023}
}
@article{hu2022dual,
  title={Dual-path style learning for end-to-end noise-robust speech recognition},
  author={Hu, Yuchen and Hou, Nana and Chen, Chen and Chng, Eng Siong},
  journal={arXiv preprint arXiv:2203.14838},
  year={2022}
}
@article{fan2022draft,
  title={DRAFT: A novel framework to reduce domain shifting in self-supervised learning and its application to children's ASR},
  author={Fan, Ruchao and Alwan, Abeer},
  journal={arXiv preprint arXiv:2206.07931},
  year={2022}
}

@article{park2019specaugment,
  title={Specaugment: A simple data augmentation method for automatic speech recognition},
  author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D and Le, Quoc V},
  journal={arXiv preprint arXiv:1904.08779},
  year={2019}
}

@article{rebai2017improving,
  title={Improving speech recognition using data augmentation and acoustic model fusion},
  author={Rebai, Ilyes and BenAyed, Yessine and Mahdi, Walid and Lorr{\'e}, Jean-Pierre},
  journal={Procedia Computer Science},
  volume={112},
  pages={316--322},
  year={2017},
  publisher={Elsevier}
}
@article{damania2022combining,
  title={Combining Simple but Novel Data Augmentation Methods for Improving Low-Resource ASR},
  author={Damania, Ronit and Homan, Christopher and Prudâ€™hommeaux, Emily},
  year={2022}
}
@inproceedings{jaitly2013vocal,
  title={Vocal tract length perturbation (VTLP) improves speech recognition},
  author={Jaitly, Navdeep and Hinton, Geoffrey E},
  booktitle={Proc. ICML Workshop on Deep Learning for Audio, Speech and Language},
  volume={117},
  pages={21},
  year={2013}
}
@inproceedings{ko2015audio,
  title={Audio augmentation for speech recognition},
  author={Ko, Tom and Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Sixteenth annual conference of the international speech communication association},
  year={2015}
}
@article{cui2015data,
  title={Data augmentation for deep neural network acoustic modeling},
  author={Cui, Xiaodong and Goel, Vaibhava and Kingsbury, Brian},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={23},
  number={9},
  pages={1469--1477},
  year={2015},
  publisher={IEEE}
}


@article{sun2018training,
  title={Training augmentation with adversarial examples for robust speech recognition},
  author={Sun, Sining and Yeh, Ching-Feng and Ostendorf, Mari and Hwang, Mei-Yuh and Xie, Lei},
  journal={arXiv preprint arXiv:1806.02782},
  year={2018}
}
@article{na2021accented,
  title={Accented speech recognition based on end-to-end domain adversarial training of neural networks},
  author={Na, Hyeong-Ju and Park, Jeong-Sik},
  journal={Applied Sciences},
  volume={11},
  number={18},
  pages={8412},
  year={2021},
  publisher={MDPI}
}
@inproceedings{ramirez2019survey,
  title={A survey of the effects of data augmentation for automatic speech recognition systems},
  author={Ramirez, Jose Manuel and Montalvo, Ana and Calvo, Jose Ramon},
  booktitle={Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications: 24th Iberoamerican Congress, CIARP 2019, Havana, Cuba, October 28-31, 2019, Proceedings 24},
  pages={669--678},
  year={2019},
  organization={Springer}
}
@inproceedings{kharitonov2021data,
  title={Data augmenting contrastive learning of speech representations in the time domain},
  author={Kharitonov, Eugene and Rivi{\`e}re, Morgane and Synnaeve, Gabriel and Wolf, Lior and Mazar{\'e}, Pierre-Emmanuel and Douze, Matthijs and Dupoux, Emmanuel},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)},
  pages={215--222},
  year={2021},
  organization={IEEE}
}
@article{gandhi2022esb,
  title={ESB: A Benchmark For Multi-Domain End-to-End Speech Recognition},
  author={Gandhi, Sanchit and Von Platen, Patrick and Rush, Alexander M},
  journal={arXiv preprint arXiv:2210.13352},
  year={2022}
}
@article{zhang2022speechlm,
  title={Speechlm: Enhanced speech pre-training with unpaired textual data},
  author={Zhang, Ziqiang and Chen, Sanyuan and Zhou, Long and Wu, Yu and Ren, Shuo and Liu, Shujie and Yao, Zhuoyuan and Gong, Xun and Dai, Lirong and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2209.15329},
  year={2022}
}
@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}
@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}
@article{ardila2019common,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@article{wang2021voxpopuli,
  title={Voxpopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation},
  author={Wang, Changhan and Riviere, Morgane and Lee, Ann and Wu, Anne and Talnikar, Chaitanya and Haziza, Daniel and Williamson, Mary and Pino, Juan and Dupoux, Emmanuel},
  journal={arXiv preprint arXiv:2101.00390},
  year={2021}}
  
@inproceedings{rousseau2012ted,
  title={TED-LIUM: an Automatic Speech Recognition dedicated corpus.},
  author={Rousseau, Anthony and Del{\'e}glise, Paul and Esteve, Yannick},
  booktitle={LREC},
  pages={125--129},
  year={2012}
}
@article{o2021spgispeech,
  title={Spgispeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition},
  author={O'Neill, Patrick K and Lavrukhin, Vitaly and Majumdar, Somshubra and Noroozi, Vahid and Zhang, Yuekai and Kuchaiev, Oleksii and Balam, Jagadeesh and Dovzhenko, Yuliya and Freyberg, Keenan and Shulman, Michael D and others},
  journal={arXiv preprint arXiv:2104.02014},
  year={2021}
}

@article{del2022earnings,
  title={Earnings-22: A Practical Benchmark for Accents in the Wild},
  author={Del Rio, Miguel and Ha, Peter and McNamara, Quinten and Miller, Corey and Chandra, Shipra},
  journal={arXiv preprint arXiv:2203.15591},
  year={2022}
}
@article{carletta2007unleashing,
  title={Unleashing the killer corpus: experiences in creating the multi-everything AMI Meeting Corpus},
  author={Carletta, Jean},
  journal={Language Resources and Evaluation},
  volume={41},
  pages={181--190},
  year={2007},
  publisher={Springer}
}
@article{chen2021gigaspeech,
  title={Gigaspeech: An evolving, multi-domain asr corpus with 10,000 hours of transcribed audio},
  author={Chen, Guoguo and Chai, Shuzhou and Wang, Guanbo and Du, Jiayu and Zhang, Wei-Qiang and Weng, Chao and Su, Dan and Povey, Daniel and Trmal, Jan and Zhang, Junbo and others},
  journal={arXiv preprint arXiv:2106.06909},
  year={2021}
}
@article{vincent2017analysis,
  title={An analysis of environment, microphone and data simulation mismatches in robust speech recognition},
  author={Vincent, Emmanuel and Watanabe, Shinji and Nugraha, Aditya Arie and Barker, Jon and Marxer, Ricard},
  journal={Computer Speech \& Language},
  volume={46},
  pages={535--557},
  year={2017},
  publisher={Elsevier}
}

@article{defossez2020real,
  title={Real time speech enhancement in the waveform domain},
  author={Defossez, Alexandre and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint arXiv:2006.12847},
  year={2020}
}
@inproceedings{yang2020characterizing,
  title={Characterizing speech adversarial examples using self-attention u-net enhancement},
  author={Yang, Chao-Han and Qi, Jun and Chen, Pin-Yu and Ma, Xiaoli and Lee, Chin-Hui},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3107--3111},
  year={2020},
  organization={IEEE}
}
@inproceedings{wen2020towards,
  title={Towards understanding the regularization of adversarial robustness on neural networks},
  author={Wen, Yuxin and Li, Shuai and Jia, Kui},
  booktitle={International Conference on Machine Learning},
  pages={10225--10235},
  year={2020},
  organization={PMLR}
}

@article{ivgi2021achieving,
  title={Achieving model robustness through discrete adversarial training},
  author={Ivgi, Maor and Berant, Jonathan},
  journal={arXiv preprint arXiv:2104.05062},
  year={2021}
}
@article{mao2022enhance,
  title={Enhance the visual representation via discrete adversarial training},
  author={Mao, Xiaofeng and Chen, Yuefeng and Duan, Ranjie and Zhu, Yao and Qi, Gege and Ye, Shaokai and Li, Xiaodan and Zhang, Rong and Xue, Hui},
  journal={arXiv preprint arXiv:2209.07735},
  year={2022}
}
@inproceedings{tan2020improving,
  title={Improving robustness of deep learning based monaural speech enhancement against processing artifacts},
  author={Tan, Ke and Wang, DeLiang},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6914--6918},
  year={2020},
  organization={IEEE}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}
@inproceedings{chung2021w2v,
  title={W2v-bert: Combining contrastive learning and masked language modeling for self-supervised speech pre-training},
  author={Chung, Yu-An and Zhang, Yu and Han, Wei and Chiu, Chung-Cheng and Qin, James and Pang, Ruoming and Wu, Yonghui},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={244--250},
  year={2021},
  organization={IEEE}
}
@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}
@article{diaz2021gpurir,
  title={gpuRIR: A python library for room impulse response simulation with GPU acceleration},
  author={Diaz-Guerra, David and Miguel, Antonio and Beltran, Jose R},
  journal={Multimedia Tools and Applications},
  volume={80},
  pages={5653--5671},
  year={2021},
  publisher={Springer}
}
@inproceedings{kireev2022effectiveness,
  title={On the effectiveness of adversarial training against common corruptions},
  author={Kireev, Klim and Andriushchenko, Maksym and Flammarion, Nicolas},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1012--1021},
  year={2022},
  organization={PMLR}
}

@inproceedings{peddinti2015time,
  title={A time delay neural network architecture for efficient modeling of long temporal contexts},
  author={Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Sixteenth annual conference of the international speech communication association},
  year={2015}
}
@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
  booktitle={International conference on machine learning},
  pages={7472--7482},
  year={2019},
  organization={PMLR}
}
@article{song2019robust,
  title={Robust local features for improving the generalization of adversarial training},
  author={Song, Chuanbiao and He, Kun and Lin, Jiadong and Wang, Liwei and Hopcroft, John E},
  journal={arXiv preprint arXiv:1909.10147},
  year={2019}
}

@article{snyder2015musan,
  title={Musan: A music, speech, and noise corpus},
  author={Snyder, David and Chen, Guoguo and Povey, Daniel},
  journal={arXiv preprint arXiv:1510.08484},
  year={2015}
}

@article{gajic2006robust,
  title={Robust speech recognition in noisy environments based on subband spectral centroid histograms},
  author={Gajic, Bojana and Paliwal, Kuldip K},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={14},
  number={2},
  pages={600--608},
  year={2006},
  publisher={IEEE}
}

@inproceedings{ko2017study,
  title={A study on data augmentation of reverberant speech for robust speech recognition},
  author={Ko, Tom and Peddinti, Vijayaditya and Povey, Daniel and Seltzer, Michael L and Khudanpur, Sanjeev},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5220--5224},
  year={2017},
  organization={IEEE}
}