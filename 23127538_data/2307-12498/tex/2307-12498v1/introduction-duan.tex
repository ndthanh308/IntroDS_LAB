\documentclass{INTERSPEECH2023}
\usepackage{amsmath, amssymb}
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage{booktabs}
\usepackage{bm}
\usepackage{bigstrut}
\urlstyle{same}

\usepackage{amsmath}
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{hyperref}
\usepackage{wrapfig}

\usepackage{algorithmic}
\usepackage[ruled]{algorithm2e}
\renewcommand{\algorithmiccomment}[1]{//#1}
\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\usepackage{indentfirst}

\usepackage{booktabs}  
\usepackage{threeparttable}  
\usepackage{multicol}  
\usepackage{multirow}  
\usepackage{xspace}
\usepackage{colortbl}

\def\etal{\emph{et al.}}
\def\eg{\emph{e.g.}}
\def\ie{\emph{i.e.}}

\newcommand{\wapat}{\textsc{Wapat}\xspace}
\newcommand{\yf}[1]{{\color{blue}{[YF: #1]}}}
\newcommand{\mxf}[1]{{\color{red}{[Xiaofeng: #1]}}}


\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}

% 2023-01-06 modified by Simon King (Simon.King@ed.ac.uk)  

% **************************************
% *    DOUBLE-BLIND REVIEW SETTINGS    *
% **************************************
% Comment out \interspeechcameraready when submitting the 
% paper for review.
% If your paper is accepted, uncomment this to produce the
%  'camera ready' version to submit for publication.
% \interspeechcameraready 


% **************************************
% *                                    *
% *      STOP !   DO NOT DELETE !      *
% *          READ THIS FIRST           *
% *                                    *
% * This template also includes        *
% * important INSTRUCTIONS that you    *
% * must follow when preparing your    *
% * paper. Read it BEFORE replacing    *
% * the content with your own work.    *
% **************************************

\title{Robust Automatic Speech Recognition via WavAugment Guided Phoneme Adversarial Training}
\name{First Author Name$^1$, Second Author Name$^2$, Third Author Name$^3$}
%The maximum number of authors in the author list is 20. If the number of contributing authors is more than this, they should be listed in a footnote or the acknowledgement section.
\address{
  $^1$First Author Affiliation, CountryX\\
  $^2$Second Author Affiliation, CountryY \\
  $^3$Third Author Affiliation, CountryZ}
\email{first@university.edu, second@companyA.com, third@companyB.ai}

\begin{document}

% \linenumbers
\maketitle

\begin{abstract}
% 1000 characters. ASCII characters only. No citations.
Adversarial Training (AT) has shown promise for training robust Automatic Speech Recognition (ASR) models defending against adversarial examples. 
However, adversarially trained models often lack robust generalization on unseen testing data.
To address this problem, we propose a novel WavAugment Guided Phoneme Adversarial Training (\wapat).
By making the model invariant to small fluctuations in phoneme representation, \wapat helps the model generalize to out-of-distribution samples and boosts standard performance.
Moreover, \wapat utilizes the phoneme representation of augmented samples to guide the generation of adversaries, which helps to find more stable and diverse gradient-directions, resulting in improved generalization of target ASRs.
Extensive experiments demonstrate the effectiveness of \wapat on a challenging cross-domain End-to-end Speech Challenge Benchmark (ESB).
Notably, SpeechLM-\wapat outperforms the original model by 6.28\% WER reduction on ESB, achieving new state-of-the-art performance.

%that is able to improve generalization under cross-domain scenarios.
%By conducting the AT on symbolic phoneme space, \wapat can improve the robustness without sacrificing standard performance.
% AWA can improve performance across multiple domain datasets simultaneously.
% Leveraging five time-domain augmentations as guidance, AWA can achieve state-of-the-art results on in-domain and out-of-domain datasets simultaneously.
% However, the DA technique needs lots of knowledge of human expert, and sometimes shows the weak transferability across different datasets. 

% of augmented inputs to guide the generation of adversaries, thus without sacrificing
% By finding more stable and diverse gradient-directions for generating adversaries, \wapat can learn more robust features, thereby resulting in improving the generalization of ASRs.
% gets a 6.28\% relative WER reduction on a challenging End-to-end Speech Challenge (ESB) benchmark.
\end{abstract}
\noindent\textbf{Index Terms}: robust automatic speech recognition, data augmentation, adversarial training 
% For enhancing the robustness with no sacrificing of performance on in-domain data, the clean and adversaries are both introduced in training.

\section{Introduction}
%
% 1. 我们的目的cross-domain 的robustness
% 2. 对抗训练是一种提升鲁棒性的有效手段，
% 3. 然后对抗训练有缺陷，会损失clean, unperturbed examples 的 performance
% 4. motivated by NLP 和CV， 我们在提出了Phoneme对抗训练，在Phoneme的token空间，而不是在原始wav空间进行对抗，从而避免了clean performance的下降。
% 5. 此外，为了进一步提升模型在un seen domain上泛化性，我们引入了KL loss 以及 wav augment 来guide生成的对抗样本更加稳定和多样。
% 6. 从而使得对抗训练学到的表征能够更好地未知的domain上。
% contributions
%  1. 首次提出 我们在提出了Phoneme对抗训练
%  2. 我们提出了 wavaugment  guided  对抗训练，使得对抗样本的生成更加stable和多样化，提升ASR模型的泛化能力
%  3. esb benchmark 的performance

Nowadays, there have been remarkable advancements in Deep Neural Network (DNN) based Automatic Speech Recognition (ASR)~\cite{baevski2020wav2vec}, resulting in the emergence of numerous speech-related applications that assist humans in their daily activities. 
However, ASR's high performance is limited to specific tasks as it assumes that the training and testing data are drawn from the same distribution~\cite{parada2022pmct}.
Thus, applying ASR in real-world applications under diverse environment is still a huge challenge ~\cite{hu2022dual,fan2022draft,hu2023gradient}.

In this work, we aim to address such a challenging cross-domain scenario where an automatic speech recognition (ASR) system needs to be robust against various potential distortion. However, there are two major challenges:
  1) \textbf{Robustness against perturbation:} Real-world volume perturbation (e.g., environmental noise, reverberation, and background speakers) can significantly impact the performance of an ASR model.
  2) \textbf{Robustness Generalization:} There exist various volume perturbation in practical scenario. However, a ASR is robust against one type of perturbation not promised being robust under unknown domain of perturbation (e.g., change of speaking style). 
Existing work either adopt data augmentation to improve ASR's robustness against specific perturbation \cite{jaitly2013vocal, peddinti2015time, park2019specaugment, ko2015audio} but limited under unseen domain, or use speech enhancement as a pre-processing to deal with various potential noise \cite{tan2020improving}. Both of them fail to achieve a real-robust ASR system which can be applied in the real world. Therefore, enhancing the robustness of ASR systems while improving their robustness generalization across different perturbation remains a significant challenge need to be addressed.

To achieve the goal (or to build a real-robust ASR), in this paper, we propose a novel method called \textbf{W}av\textbf{A}ugment Guided \textbf{P}honeme \textbf{A}dversarial \textbf{T}raining (\wapat) by leveraging adversarial training (AT) technique. Previous work \cite{zhang2019theoretically} shows AT results in a trade-off between robustness and accuracy. However, research in the fields of natural language processing~\cite{ivgi2021achieving} and recent in computer vision~\cite{mao2022enhance} demonstrated that aligning the distributions of adversarial and original samples in AT can benefit standard performance and robustness simultaneously. Borrowing the idea, we propose to apply a phoneme unit AT for ASR tasks, where adversarial speech is commonly encountered. To be specific, \wapat employs a single-step attack to generate adversarial perturbations on phoneme representations. To enhance the stability and diversity of phoneme adversarial examples, we further design a data augmentation guided adversarial attack.
Specifically, with the time-domain WavAugment~\cite{kharitonov2021data} technique, we use Kullback-Leibler Divergence (KLD) to measure the similarity between the adversaries of the original samples and those of the augmented samples. Then, we constrain them to be as close as possible, thereby improving the stability of adversarial examples. Furthermore, multiple augmentations in WavAugment are used to guide phoneme adversarial training, encouraging the search for diverse gradient directions and leading to better generalization.
Figure~\ref{fig:3_1} shows the overall pipeline of WavAugment guided phoneme adversarial training.





% As for the second problem, there are two critical properties, \ie, stability and diversity, along which we can improve the transferability of adversarial examples.

% Such transferable adversarial examples are expected to introduce more robust features into target ASRs, thus improving the generalization capability.

% Figure environment removed


% which aims to improve both robustness and generalization of ASR models. 
%\textbf{First}, \wapat utilizes a single-step attack to generate adversarial perturbations on phoneme representations.
%\textbf{Second}, we design a data augmentation guided adversarial attack, aiming to increase the stability and diversity of phoneme adversarial examples. 

We further discuss whether the robustness of ASR comes from WavAugment.
Our findings indicate that while hard augmentations can improve robustness on some datasets, they fails on others.
It is reasonable to expect challenges in generalizing audio augmentations across different domains, given the inherent complexity of audio signals.
Instead, our \wapat consistently improves performance in terms of both cross-domain datasets and different types of transformations.
The stability of generalization indicates that the WavAugment-guided adversary is effective in inducing robust features into target ASR.
In summary, we make the following contributions:
\begin{itemize}
    \item To our knowledge, this is the first work that sheds light on adversarial training on phoneme-unit space for improving standard performance and generalization simultaneously.
    \item We propose WavAugment Guided Phoneme Adversarial Training (\wapat), which employs phoneme representation of the augmented audios to guide the generation of adversaries, resulting in more diverse robust features.
    \item By combining SpeechLM~\cite{zhang2022speechlm} pre-training and \wapat fine-tuning, our method achieves new state-of-the-art performance on the challenging benchmark ESB~\cite{gandhi2022esb}, which contains multiple speech datasets from a broad range of domains.
\end{itemize}


% For example, adding noise or reverberation may failed to improve the robustness of ASRs trained on datasets with varying speaking rates.


% We further give an analysis on the different of \wapat and hard data augmentation. We find, in general, single augmentation can improve robustness, but in some cases it fails. However, our \wapat has the consistently stronger generalization on multiple datasets. We also observe that, by combining multiple augmentation techniques, \wapat can lead to even better generalization.
% Our investigation provides a guidance for strengthening the robustness of ASR systems by adversarial training. 

% The reason for this is that adversarial training can cause the model to overfit to the perturbed examples used during training, making it less effective at recognizing clean, unperturbed examples.
%1我们发现现有的对抗训练基本都是使用特定的攻击算法形成对抗样本。
%2. 这类对抗样本的迁移攻击性往往很差，导致了无法泛化到更多的位置的domian上

% However, AT degrades the standard performance caused by problematic regularization~\cite{wen2020towards}.
%This in turn leads to a crucial question for AT, that is, how to generate a new adversarial example that is hard enough for the model to discriminate from the original one, in the meanwhile also helps the target model to learn various robust features?

% Surprisingly, some recent works in Natural Language Processing (NLP)~\cite{ivgi2021achieving} and Computer Vision (CV)~\cite{mao2022enhance} found that the AT can benefit for standard performance and robustness simultaneously. By automatically finding adversarial textual inputs, AT will not hurt the accuracy and even benefit for both generalization and robustness of language models~\cite{ivgi2021achieving}. DAT~\cite{mao2022enhance} trains the model on example which has the adversarially altered discrete visual representation. 

% Data augmentation is an effective technique to increase overall model robustness in standard training~\cite{rebai2017improving,park2019specaugment}. However, there has been no uncontroversial evidence showing that generalization of AT can be further improved by it.
%For reducing the robust generalization gap between the training data and the testing data, we consider to increase the diversity of generated adversaries by symbolic data augmentation. 
% On top of that, we propose a constraint called distribution alignment which could stabilize the training of \wapat. 
% Finally, the phoneme adversarial representations and clean inputs are fed into models for training. 
% Such ability of generating adversarial examples in phoneme representation space makes \wapat can improve the generalization without sacrificing the performance on in-domain datasets. 

% Data augmentation (DA) has been observed by many previous works to be effective in increasing overall model robustness~\cite{rebai2017improving,park2019specaugment}.
% Conventionally, augmented samples retain their original label, so that models effectively see a larger set of data-label training pairs.

%However, it is hard to carefully select the appropriate DA techniques based on the characteristics of the dataset and the task at hand to achieve optimal results. 
% The speech data augmentation techniques are often too narrow in scope, making it difficult to generalize them to a wide variety of cross-domain datasets. For example, adding noise or reverberation may failed to improve the robustness of ASRs trained on datasets with varying speaking rates.
% On the other hand, combining multiple data augmentation techniques makes the speech too different from the original, resulting in the loss of inherent features.

% We noticed that, as another family of augmentation schemes, Adversarial Training (AT)~\cite{sun2018training,na2021accented} automatically finds failure input cases of DNNs and augment online with these cases for enhancing the adversarial robustness.
% To some extend, the generated adversarial examples in AT have the characteristics that we expected. However, there is no undisputed evidence that adversarial robustness is helpful for generalization in the speech recognition area.

% In-so-doing, we first investigate the effects of DA and AT on the accuracy and generalization of ASRs.
% It is found that, in general, hard augmentation can alleviate overfitting and improve robustness, but in some cases it fails.
% We also observe that combining multiple DA techniques can often lead to even better results.
% On the other hand, traditional AT generally can alleviate overfitting, but at the expense of clean accuracy.
% Motivated by above observations, we propose Adversarial WavAugment (AWA) method based on the time-domain augmentations\cite{kharitonov2021data}, which utilizes phoneme representation of the augmented audios to guide the generation of adversaries, thereby increasing the hardness and the diversity of DAs. By combining both clean and AWA examples during training, the target ASRs can improve the robustness without sacrificing the performance on in-domain datasets.

%Data augmentation is an effective technique to alleviate overfitting in standard training~\cite{ramirez2019survey}, but there has been no uncontroversial evidence showing that generalization of AT can be further improved by it. 
%In this work, we explore the challenging cross-domain setting where a ASR needs to achieve \textit{domain generalization}, i.e., the ability to generalize to domains that are unseen during training. 

% We first investigate the effects of DA and AT on the accuracy and generalization of ASRs.
% It is found that, in general, hard augmentation can alleviate overfitting and improve robustness, but in some cases it fails.
% We also observe that combining multiple DA techniques can often lead to even better results.
% On the other hand, traditional AT generally can alleviate overfitting, but at the expense of clean accuracy.
% Motivated by above observations, we propose Adversarial WavAugment (AWA) method based on the time-domain augmentations\cite{kharitonov2021data}, which utilizes phoneme representation of the augmented audios to guide the generation of adversaries, thereby increasing the hardness and the diversity of DAs. By combining both clean and AWA examples during training, the target ASRs can improve the robustness without sacrificing the performance on in-domain datasets.

%Another family of augmentation schemes called adversarial training has attracted active research interest~\cite{sun2018training,na2021accented} This training regime attempts to solve the minimax optimization problem of firstly generating strong adversarial samples by maximizing a loss, and subsequently training the model to minimize loss on these adversarial samples. Data augmentation is an effective technique to alleviate overfitting in standard training~\cite{ramirez2019survey}, but there has been no uncontroversial evidence showing that robust generalization of AT can be further improved by it. 


\section{Related Work}
\textcolor{blue}{Existing approaches for improving ASR generally from two aspects:} \textbf{1) Improving ASR's robustness against specific perturbation:} Early works have shown that several data augmentation methods, such as vocal tract length perturbation~\cite{jaitly2013vocal}, volume perturbation~\cite{peddinti2015time} and speed perturbation~\cite{ko2015audio}, can improve the robustness of ASR models.
SpecAugment~\cite{park2019specaugment} is widely used to train ASR models due to its efficiency.
Specifically, SpecAugment randomly masks chunks of time or frequency channels on spectrograms.
However, these DA techniques are typically designed manually for specific domains based on domain-specific knowledge and experience.
When dealing with an unknown target domain or multiple domains, it can be challenging for experts to apply specific transformations, or to construct and fine-tune more sophisticated augmentation compositions.
For example, \cite{damania2022combining} found inconsistent results where the baseline outperformed the combinations of augmentation in terms of robustness. Besides data augmentation, several work utilize adversarial training \cite{sun2018training, yang2020characterizing} aiming to improve ASR's adversarial robustness under adversarial examples. \textcolor{blue}{However, all of these work target ASR's robustness under specific perturbation, and the improved ASR is still limited on unseen domain. }
\textbf{2). Improving ASR's performance via pre-processing:} To achive better performance, there are also several works propose using speech enhancement methods to remove noise from speech signals before passing them through a standard speech recognition system~\cite{tan2020improving}. A more recent approach that operates on raw waveform for real-time speech enhancement is~\cite{defossez2020real}. However, these methods often rely on front-end processing modules, which can decrease efficiency and add computational overhead. \textcolor{blue}{Also, the speech enhancement method do not really improve the robustness of ASR itself.}
\textcolor{blue}{In this paper, we aim to build a truly robust ASR which is robust under multiple or even unseen perturbations. It has the potential to be applied in various applications in real-world setting.}




% However, the success of DA depends on various factors such as the type and amount of augmentation applied, the quality and quantity of the original training data, and the complexity of the ASR system.


\section{Method}
\subsection{Adversarial Training on ASR}
Consider the training utterance and text label set $\mathcal{D}=\{(x_i, y_i)_{i=1}^n\}$, an ASR model with learnable parameters $\theta$, and a recognition objective given by Connectionist Temporal Classification (CTC) loss $\mathcal{L}_{ctc}$. Adversarial Training (AT) aims to optimize $\theta$ by solving a minimax optimization problem:
%
\begin{align}
\min_{\theta} \mathbb{E}_{(x, y) \sim \mathcal{D}} \left[ \max_{\delta} \mathcal{L}_{ctc}(x+\delta, y, \theta) \right] \ s.t. ||\delta||_p \leq \epsilon,
\label{equation:eq1}
\end{align}
%
where the inner optimization seeks perturbations $\delta$ on speech values that maximize the loss, and the outer minimization update $\theta$ to improve the worst-case performance of the network. The boundary $||\delta||_p \leq \epsilon$ restricts the magnitude of the perturbation.
We use projected gradient descent (PGD)~\cite{madry2017towards} for the inner optimization, which iteratively solves the $\max$ problem with a step size $\alpha$:
%
\begin{equation}
\begin{aligned}
x^0 \sim &\mathcal{U}(\mathcal{B}_{\epsilon}^{\infty
}(x)), \\
x^{t+1}=\prod\limits_{\mathcal{B}_{\epsilon}^{\infty}(x)}(x^t+ &\alpha \rm sign(\nabla_x \mathcal{L}_{ctc}(x^t,y,\theta)))
\label{equation:eq2}
\end{aligned}
\end{equation}
%
where $\mathcal{B}_{\epsilon}^{\infty}(x):=\{x^{\prime}:||x^{\prime}-x||_{\infty} \leq \epsilon\}$ defines a ball of radius $\epsilon$ around $x$ in the $l_\infty$ norm. The symbol $\mathcal{U}$ denotes the uniform distribution, and $\prod$ denotes a projection function. 
In the following section, we will tackle the challenges of mitigating performance degradation and enhancing the generalization ability of ASR models through AT techniques. 
% Although AT has shown promise in improving ASR model robustness against adversarial examples, it remains unclear if it can mitigate standard performance degradation, and a significant gap still exists between training and cross-domain testing data.

% Unlike adversarially trained models, data augmentation is a simple method to improve ASR’ robustness. To date, it is still unclear if data augmentation benefits generalization in adversarial training.

% \section{Preliminaries}

% Although such human-designed data augmentations have been used in the training of ARSs, the limited randomness will make it very difﬁcult to generate effective samples. To enforce the network learn more robust features, the adversarial policies is taken to explore harder examples for training. 

% \subsection{WavAugment Guided Phoneme Adversarial Training}
\subsection{Phoneme Adversarial Training}
% Although adversarial examples can successfully fool the models, they are still different from the real "hard" examples appeared in practice, \ie, human does not recognize utterances from speech values, but from phoneme of the input speech. 
% In the text domain, the AT on the discrete and symbolic text space will not hurt the accuracy and even benefit for both generalization and robustness of language models.
% Therefore, we borrow the symbolic nature of languages, and apply it on ASR tasks by conducting AT on the phoneme space of speech instead of inputs.

We borrow the perspective of the AT on the contextualized language representation, and propose a new Phoneme Adversarial Training (PAT) for ASRs, \ie, conducting AT on the phoneme representation space instead of raw input space.
To accomplish this, we leverage the SpeechLM framework proposed by~\cite{zhang2022speechlm} to recognize speeches. The phoneme unit sequence of input $x$ is obtained by applying a transformer based phoneme-unit tokenizer $\mathcal{T}$, \ie, $z = \mathcal{T}(x)$.
In the inner maximization step of AT, we generate phoneme adversarial examples by slightly modifying Equation~\ref{equation:eq1}. The objective of PAT can be formulated as follows:
%
\begin{align}
\min_{\theta} \mathbb{E}_{(x, y) \sim \mathcal{D}} \left[ \max_{\delta} \mathcal{L}_{ctc}(\mathcal{T}_s(x)+\delta, y, \theta) \right] \ s.t. ||\delta||_{\infty} < \epsilon,
\label{equation:eq3}
\end{align}
%
where $\epsilon$ is the magnitude of the perturbation in phoneme space.

%The loss function of our method is as follows:
% %
% \begin{align}
% \mathcal{L} = \mathcal{L}_{ctc}(x, y, \theta) + \mathcal{L}_{ctc}(\mathcal{T}_s(x)+\delta,y,\theta)  
% \label{equation:eq4}
% \end{align}
% %

% \IncMargin{-1.5em} % 行号不向外突出 
% \begin{algorithm}[t]
% \caption{\indent Pseudo code of \wapat }
% \KwInput{Speech tokenizer $\mathcal{T}$; A sampled mini-batch of clean audios $x$ with labels $y$; attack step size $\alpha$.}
% \KwOutput{Learned network parameter $\theta$} 
% \begin{algorithmic}[1]
% \STATE Fix the network parameters of $\mathcal{T}$
% \FOR{each training steps}
% \STATE $\delta_{0} \leftarrow \mathcal{U}(-\epsilon,\epsilon)$\hfill\COMMENT{Initialize perturbation}
% \STATE $z \leftarrow \mathcal{T}(x)$\hfill\COMMENT{Get the phoneme unit $z$}
% \STATE $\delta \leftarrow \alpha \rm (\nabla_z \mathcal{L}_{ctc}(z,y,\theta) +\nabla_z \mathcal{L}_{WAG}(z, z^{aug},\theta)$ \hfill\COMMENT{Estimate the WavAugment guided perturbations}
% \STATE $\hat{\delta} \leftarrow Clip(\delta,-\epsilon,\epsilon)$
% \STATE $z_{adv} \leftarrow z+\hat{\delta}$ \hfill\COMMENT{Generate discrete adversarial examples}
% \STATE Update model parameter on $\mathcal{L}_{ctc}(z_{adv},y,\theta)$
% \\
% \ENDFOR
% \end{algorithmic}
% \label{alg:awat}
% \end{algorithm}
% \DecMargin{-1.5em}
% Figure environment removed


\subsection{WavAugment Guided Phoneme Adversarial Training}
For improving the generalization of ASR by AT, we aim to generate adversarial examples that exhibit both stability and diversity.
Towards this end, we propose a novel WavAugment Guided Phoneme Adversarial Training (\wapat) method.

Adversarial examples are typically distributed near the decision boundary, and slight variations can cause them to lose their adversarial nature~\cite{goodfellow2014explaining}.
Therefore, enhancing the stability of adversarial examples is beneficial for obtaining more robust features.
To tackle the instability problem, we introduce the WavAugment guided term along with the CTC loss to form a new objective function during the generation of adversarial examples.
Specifically, we define the wavAugment operation as $\mathcal{DA(\cdot)}$. 
The adversarial examples of original samples and those of augmented samples are denoted as $x_1$ and $x_2$ respectively.
Then, the loss WavAugment guided term encourages the predictions of these two adversarial examples to be similar. 
Formally, the objective function can be written as:
%
\begin{align}
%\mathcal{L}_{wag}=-\mathcal{D}_{KL}(\mathcal{T}(x)+\delta,\mathcal{T}(DA(x)), \theta)
\mathcal{L}_{wag}(x_1,x_2,\theta)=-\mathcal{D}_{KL}\left[p_{ctc}(x_1,\theta)||p_{ctc}(x_2,\theta)\right]
\label{equation:eq5}
\end{align}
%
%&=-\mathcal{D}_{KL}\left[p_{ctc}(\mathcal{T}(x)+\delta, \theta)||p_{ctc}(\mathcal{T}(\mathcal{DA}(x) + \eta, \theta\right)]\nonumber
where $\mathcal{D}_{KL}$ is the KL-divergence.
From an optimization perspective, the WavAugment guided term helps in avoiding local optima during the perturbation generation process, leading to the creation of more stable and robust features for ASR models.
%This term encourages the predictions of adversarial examples of original samples and those of augmented samples to be similar.
% To improve the stability of adversarial examples, we can constrain the generation of adversarial examples from a regularization perspective. 
% The perturbation is iteratively learned to enlarge the difference between predictions and text label.
% However, we observe that the objective function with the loss deviation term alone has a major unstable issue,
In this paper, the basic data augmentations of WavAugment~\cite{kharitonov2021data} is reserved, including pitch modification (\texttt{pitch}), additive noise (\texttt{add}), band reject filtering (\texttt{band\_rej}), time masking (\texttt{time\_mask}) and reverberation (\texttt{reverb}).
% We denote the WavAugment set as $\mathcal{M}$ containing above augmentations.
\texttt{pitch} and \texttt{add} are intended to simulate variations in the speaker's voice and environmental noise.
\texttt{band\_rej} and \texttt{time\_mask} augmentations can introduce noise into the neural representation of speech, which can help the model learn to better handle noisy speech.
The \texttt{reverb} simulates the effect of sound reflections in a room, which can help the model learn to better handle the effects of reverberation in real-world environments.
Here, we use gpuRIR~\cite{diaz2021gpurir} to obtain acoustic room impulse responses.

To enhance the diversity of adversarial examples, we utilize all of the augmentations available in WavAugment to guide the generation process. 
During training, one of the transformations from WavAugment is applied to each batch of samples.
In Figure~\ref{fig:3_1} left, we show an example of log mel spectrograms augmented with different transformations.
%For clarity, let us restate the pipeline of our \wapat. 
Further details regarding the \wapat can be found in Algorithm~\ref{alg:awat}.
Given a SpeechLM based speech recognition model, the speech transformer $\mathcal{T}$ first yields a higher level phoneme representation from speech input $z=\mathcal{T}(x)$. The WavAugment guided perturbation $\delta$ can be obtained by computing the gradient of $z$ towards maximizing the $\mathcal{L}_{ctc}$ and $\mathcal{L}_{wag}$. 
Finally, the adversarial example $\hat{z}$ is fed into models for training.

% \texttt{pitch} serves as a transformation on the source, i.e., how the speaker talks. 
% Following WavAugment, \texttt{pitch} randomly modifies the pitch of the raw waveform by $n\in[-300,300]$ semitones.
% The \texttt{add} transformation adds random noise sampled from the MUSAN database to the input, with the scaled noise controlled by randomly sampling a signal-to-noise ratio value between 0 and 40.
% \texttt{band\_rej} and \texttt{time\_mask} can noise the neural representation of speech. The maximal width of the rejected spectrum is 150 HZ. The time mask zeroes out ten random subsequence of the input with a maximal length of 2000ms. 
% For \texttt{reverb}, we use gpuRIR~\cite{diaz2021gpurir} to obtain acoustic room impulse responses.
% The room dimensions, wall reflection coefficients, and source and receiver positions are all randomly sampled within default specified ranges~\footnote{https://github.com/DavidDiazGuerra/gpuRIR}.

% The room dimensions are randomly sampled among $[3,3,2.5]\sim[4,5,3]$, and the reflections coefficients of the walls are also selected in range [0.5, 0.6]. Moreover, the source positions is [0.1,0.1,0.1] and the receiver positions are sampled from the range (0, 1). 


% With above time-domain augmentations, 
% One of the most effective methods to improve the robustness of ASRs is data augmentation. 
% However, as shown in, given the results that even the compound time-domain data augmentations are less effective on improving the generalization. 

% More than the embedding feature space, the gradient direction of adversarial example is also guided by the corresponding augmentation. Specifically, the adversarial gradient direction in each iteration is averaged by that of augmented samples, we dESBribe this method as ‘directional’.

%The perturbed unit representation thus can be created by adding $\delta$ on $z^0$. Noted that, the target ASRs are trained by minimizing the CTC loss on clean inputs and adversarial phoneme representations simultaneously.

% \begin{table}[t]  
%     \centering
%     \caption{The effect of the transformation diversity on test sets and ESB benchmark scores (WER).}
%     \resizebox{0.8\hsize}{!}{
%     \begin{tabular}{lccc}  
%     \toprule
%     {\multirow{2}*{\textbf{\textsc{Diversity}}}}& \multicolumn{2}{c}{\textbf{\textsc{Librispeech}}} & {\multirow{2}*{\textbf{\textsc{ESB Score}}}}\\ 
%     ~ & test-clean & test-other & ~ \\
%     \midrule
%     Baseline & 3.34 & 7.38 & 36.47 \\
%     \midrule
%     DA-1N    & 3.35 & 7.37 & 34.18 \\
%     AWA-1N   & 3.32 & 7.28 & 32.58 \\
%     DA-2N    &  \\
%     AWA-2N    &  \\
%     \midrule
%     \rowcolor[RGB]{237,237,237} -3B & $\textbf{70.1}_\textbf{ ($\uparrow$ 5.4)}$  & $\textbf{60.6}_\textbf{ ($\uparrow$ 3.9)}$ & $\textbf{73.8}_\textbf{ ($\uparrow$ 4.3)}$\\
%     \bottomrule
%     \end{tabular}}
%     \label{tab:diversity}
%     % \vspace{-0.4cm}
% \end{table}


% This work focuses on improving the generalization ability of representation adversarial training guided
% by WavAUgment. We investigated the effects of individual and composed augmentations for adversarial training.
% We present our results on End-to end Speech Challenge benchmark (ESB)~\cite{gandhi2022esb}, which contains multiple speech datasets spanning different domains and speech recognition conditions. The details of ESB refers to Section~\ref{sec:exp}. During training, the model’s robustness was tracked at each epoch using PGD-1 applied to the inputs.
% \noindent \textbf{Type of transformations.}~For the individual augmentations the following five wavform transformations are choosen: \texttt{pitch}, \texttt{add}, \texttt{band\_rej}, \texttt{time\_mask} and \texttt{reverb} described in Section~\ref{sec:2.2}. 

% On analyzing single augmentations in Figure~\ref{fig:3_1}, we first observed that the standard DAs perform only slightly better than the baseline on ESB score. In all cases, AWA's ESB scores are further lower than DA. This shows that training with adversarial augmented instances of each mini-batch can indeed improve the generalization of the model. However, this gain is not consistent on all test datasets. 
% Four of the five AWAs have one lower WER. Besides, the \texttt{reverb} of AWA has lower WERs on Earnings-2 and SPGISpeech, which are similar in speaking style (Spontaneous) and collected from earnings calls.
% From the result, we can conclude that AWA makes the network have to learn more robust features.

% For \texttt{add} and \texttt{pitch}, the bad cases occur on the VoxPopuli. 
%VoxPopuli is largely sourced from non-native speakers occupied the unique domain of oratory and political speech, the \texttt{add} and \texttt{pitch} in time-domain is enough for generalization. 
% The \texttt{time\_mask} of AWA with the lower WER contains SPGISpeech only. 
%SPGISpeech is an English speech recognition corpus composed of company earnings calls. The adversarial \texttt{time\_mask} is tough for the transcription of audios with multiple silent fragments. 

% \noindent \textbf{Diversity of transformations.}
% Next, we study the performance of combinations of augmentations. Due to complex combinations, the diversity is defined as the number of transformations superimposed $N \in \{1,5\}$. With the same pool of transformations as the individual experiment, audios in a batch are augmented using $N$ transformations sampled at random.
% The results are reported in Table~\ref{tab:diversity} and show that, the standard DA-1N yields relative improvements of 6.28\% over no augmentation on ESB score. This indicates that the diversity of training data is crucial for the generation of ASR. However, the standard DA results in a performance degradation on Librispeech's clean test sets.
% AWA helps the ASR gain more robust features by generating adversarial examples in representation space.
% Compared with DA, training on these examples will reduce the shift of clean distribution, yielding both the robustness and generalization improvement.

\begin{table*}[t]
\centering
\caption{WER comparison on the ESB benchmark over various methods for enhancing the robustness of ASR. Best performances are highlighted in bold.}
\vspace{-0.1cm}
\resizebox{1\hsize}{!}{
\begin{tabular}{l|cc|c|c|c|c|c|c|c|c|cc}
\toprule
{\multirow{2}*{\textbf{Method}}} & \multicolumn{2}{c|}{\textbf{Librispeech}} & {\multirow{2}*{\textbf{Chime-4}}}  & {\multirow{2}*{\textbf{Common Voice}}}  & {\multirow{2}*{\textbf{VoxPopuli}}}&  {\multirow{2}*{\textbf{TED-LIUM}}} &  {\multirow{2}*{\textbf{GigaSpeech}}} & {\multirow{2}*{\textbf{SPGISpeech}}}  &  {\multirow{2}*{\textbf{Earnings-22}}} &  {\multirow{2}*{\textbf{AMI}}} & {\multirow{2}*{\textbf{ESB score}}} \\
     ~ & \textbf{test-clean} & \textbf{test-other} & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
\midrule
SpecAugment~\cite{park2019specaugment}  & 3.32 & 7.34 &	45.49 &	38.46 &	36.47 &	19.03 &	24.57 &	20.10 &	51.10 &	45.02 &	36.19 \\
WavAugment~\cite{kharitonov2021data}  & 3.34 & 7.35 & 35.65 & 38.16 & 36.64 & 18.12 & 25.53 & 18.99 & 52.79 & 46.10 & 34.18 \\
AdvEx~\cite{sun2018training}     & 3.36 & 7.36 & 46.10 &	38.35 & 36.74 &	18.18 &	24.49 &	19.36 &	52.01 &	44.79 &	36.24  \\
DEMUCS~\cite{defossez2020real}      & 3.33 & 7.29 &	33.57 &	43.63 &	36.71 & 18.31 & 24.39 &	26.24 &	56.76 &	44.63 &	35.32\\
\wapat        & \textbf{3.32} & \textbf{7.28} &	\textbf{32.68} &	\textbf{36.43} &	\textbf{36.38} &	\textbf{18.12} & \textbf{24.25} & \textbf{18.40} &	\textbf{49.78} & \textbf{44.53} &	\textbf{32.58} \\
\bottomrule
\end{tabular}}
\label{tab:overall}
\vspace{-0.2cm}
\end{table*}

% Figure environment removed

\section{Experiment}
\label{sec:exp}
%\subsection{Set up}
\noindent \textbf{Datasets and Settings}
We conducted experiments on the ESB~\cite{gandhi2022esb} benchmark to evaluate cross-domain ASR robustness. 
ESB comprises eight datasets with a broad range of domains, acoustic conditions, speaker styles, and transcription requirements. Notably, Librispeech~\cite{panayotov2015librispeech} and Common Voice~\cite{ardila2019common} only contain narrated style speeches, while VoxPopuli~\cite{wang2021voxpopuli} and TED-LIUM~\cite{rousseau2012ted} have oratory style speeches, and AMI ~\cite{carletta2007unleashing} contains spontaneous style speeches. GigaSpeech~\cite{chen2021gigaspeech}, SPGISpeech~\cite{o2021spgispeech}, and Earnings-22~\cite{del2022earnings} cover two different styles of speeches. Additionally, We included the optional CHiME-4~\cite{vincent2017analysis} dataset with narrated style to test generalization. We use the standard split of the above datasets and unify the transcription format as normalised.
In particular, we train models on the Librispeech-100h dataset and evaluate their robustness on both the test-clean and test-other datasets from Librispeech, as well as other datasets in ESB. 
Audio format is 16-bit WAV with 16 kHz, and transcription format is unified into the normalized form.

% Among them, Librispeech~\cite{panayotov2015librispeech} is a standard large-scale dataset derived from English audio books and contains 1000 hours of speech. 
% Common Voice~\cite{ardila2019common} is collected from Wikipedia with narrated speaking style. VoxPopuli~\cite{wang2021voxpopuli} is sourced from 2009-2020 European Parliament event recordings with oratory speaking style. TED-LIUM~\cite{rousseau2012ted} is based on English-language TED Talk conference videos with oratory speaking style. GigaSpeech~\cite{chen2021gigaspeech} is a multi-domain English speech recognition corpus curated from audiobooks, podcasts and YouTube, which covers both narrated and spontaneous speech.
% The last SPGISpeech~\cite{o2021spgispeech}, Earnings-22~\cite{del2022earnings} and AMI~\cite{carletta2007unleashing} datasets are all from meetings and narrated or oratory styles. 
\noindent \textbf{Implementation Details}
The hyper-parameters used in WavAugment are as follows: 
\texttt{pitch} randomly modifies the pitch of the waveform by $n\in[-300,300]$ semitones.
\texttt{add} randomly adds noise from MUSAN~\cite{snyder2015musan} dataset with a scaled signal-to-noise ratio between $[0,40]$.
The maximal width of the rejected spectrum in \texttt{band\_rej} is 150 Hz. 
The \texttt{time\_mask} operation zeros out ten random subsequences of the inputs with a maximum length of 2000 ms.
The room dimensions and other parameters in \texttt{reverb} are randomly sampled within default ranges~\footnote{https://github.com/DavidDiazGuerra/gpuRIR}.

% We use word error rate (WER) to evaluate predictions against target transcriptions. 
We evaluate the accuracy of our predictions against target transcriptions using the word error rate (WER). 
The ESB score is the macro-averaged value of datasets in the ESB benchmark, excluding Librispeech.
We implement \wapat on the pre-trained SpeechLM-P~\cite{zhang2022speechlm}, which consists of a Speech Transformer, a Shared Transformer and a CTC head. 
By default, we refer SpeechLM-P-Base to SpeechLM in all tables and figures.
Models are optimized by Adam with a maximum learning rate of 1e-5 and a tri-stage learning rate schedule with the warming-up, holding, and decay periods of [0.1, 0.4, 0.5]. 
We train the models for a total of 30K steps with a batch size of 800 seconds.
Perturbations are bounded with an $l_{\infty}$-norm of $0.01$. 
All experiments are conducted on four NVIDIA Tesla A100.

% \texttt{pitch} serves as a transformation on the source, i.e., how the speaker talks. 
% Following WavAugment, \texttt{pitch} randomly modifies the pitch of the raw waveform by $n\in[-300,300]$ semitones.
% The \texttt{add} transformation adds random noise sampled from the MUSAN database to the input, with the scaled noise controlled by randomly sampling a signal-to-noise ratio value between 0 and 40.
% \texttt{band\_rej} and \texttt{time\_mask} can noise the neural representation of speech. The maximal width of the rejected spectrum is 150 HZ. The time mask zeroes out ten random subsequence of the input with a maximal length of 2000ms. 
% For \texttt{reverb}, we use gpuRIR~\cite{diaz2021gpurir} to obtain acoustic room impulse responses.
% The room dimensions, wall reflection coefficients, and source and receiver positions are all randomly sampled within default specified ranges~\footnote{https://github.com/DavidDiazGuerra/gpuRIR}.

% The room dimensions are randomly sampled among $[3,3,2.5]\sim[4,5,3]$, and the reflections coefficients of the walls are also selected in range [0.5, 0.6]. Moreover, the source positions is [0.1,0.1,0.1] and the receiver positions are sampled from the range (0, 1). 

% The models in domain generalization experiments are optimized by AdamW with learning rate of 5e-6 and weight decay of 0.1. For data augmentation, simple random resize crop and random horizontal filp are used. The other hyper-parameters, such as batch size, dropout rate, and training steps, we keep consistent with the default configuration in DomainBed

\subsection{Overall Performance}
To demonstrate the effectiveness of our \wapat, we first compared it with data augmentation and adversarial training methods.
We make a fair comparison with standard WavAugment~\cite{park2019specaugment} and SpecAugment~\cite{park2019specaugment}. 
%SpecAugment is used to augment inputs on the log mel spectrogram. 
Although SpecAugment performs well on Librispeech test datasets, it shows poor performance in terms of robustness on ESB.
In addition, WavAugment has the suboptimal performance of robustness, with an ESB score of 34.18.
Notably, our \wapat achieves superior performance compared to the above data augmentation methods on both in-domain and out-of-domain datasets by a large margin.
Compared with the waveform space AT method AdvEx~\cite{sun2018training}, \wapat achieves 10.01\% improvement in ESB score.
This further verifies the strengths of \wapat in terms of generalization on the phoneme representation space.
Interestingly, \wapat shows obvious advantages on Chime-4 and Common Voice datasets, which share the same speaking style (Narrated) as the LibriSpeech set. 
To provide a more comprehensive evaluation, we test the SpeechLM with the speech enhancement-based method DEMUCS~\cite{defossez2020real}. With sacrificing of some computational efficiency, DEMUCS can achieve good performance on generalization, however, still inferior to our method.
% This indicates that the proposed \wapat is helpful to enhance ASRs for compositional generation.



% We conduct a comparison of speech enhancement-based techniques, data augmentations, and adversarial training methods for robust ASR, as shown in Table~\ref{tab:overall}. First, we demonstrate that AWA achieves the state-of-the-art on this challenging cross-domain ASR benchmark. Moreover, the enhancement technique DEMUCS~\cite{defossez2020real} has the suboptimal performance.
% Notably, AWA reach performance superior to the traditional adversarial training method AdvEx~\cite{sun2018training} by 10\% on WER.
% This even outperforms the SpecAugment~\cite{park2019specaugment} by 9.97\% on WER.
% Also, it is evident that AWA is vastly superior to other methods on in-domain data and out-of-domain data simultaneously.
% Therefore, it is vital for augmentation design to allow optimization with a hardness.

\begin{table}[t]  
    \centering
    \caption{Ablation study of the proposed \wapat on cross-domain datasets, (a) is different adversarial training variant, (b) is magnitude $\epsilon$.}
    \vspace{-0.1cm}
    \resizebox{0.99\hsize}{!}{
    \begin{tabular}{lccc}  
    \toprule
    {\multirow{2}*{\textbf{Method}}}& \multicolumn{2}{c}{\textbf{Librispeech}} & {\multirow{2}*{\textbf{ESB Score}}} \\
    ~ & \textbf{test-clean} & \textbf{test-other} & ~ \\
    \midrule
    (a) \textsc{No-AT} & 3.34 & 7.38 & 36.47 \\
     \quad \quad w/ \textsc{Phoneme AT}  & 3.32 & 7.34 & 35.18 \\
     \quad \quad w/ \textsc{WavAugment PAT} & \textbf{3.32} & \textbf{7.28} & \textbf{32.58}\\
    \midrule
    \midrule
    (b) \wapat \\
    \quad \quad $\epsilon$= \textsc{0.005} & 3.32 & 7.35 & 34.42 \\
    \quad \quad $\epsilon$= \textsc{0.01}  & \textbf{3.32} & \textbf{7.28} & \textbf{32.58} \\
    \quad \quad $\epsilon$= \textsc{0.015} & 3.32 & 7.31 & 33.24 \\
    \bottomrule
    \end{tabular}
    }
    \label{tab:ablation}
    \vspace{-0.4cm}
\end{table}

\subsection{Discussion}
% \subsection{Whether the robustness of ASR come from WavAugment?}
We further explore \textbf{whether the robustness of \wapat is attributed to WavAugment or our guided phoneme adversarial training strategy?}
We study this effect by conducting experiments on the ESB, as shown in Figure~\ref{fig:3_2}.
Specifically, we report the percentage of WER reduction for both standard WavAugment and our \wapat, compared to the baseline model.

It can be seen that WavAugment is a useful technique for improving the robustness of models.
However, there are cases where the individual augmentation perform worse than the baseline on certain datasets.
% some individual augmentations may perform worse than the baseline on certain datasets,
For example, \texttt{time\_mask} increases the WER on the TED-LIUM dataset. 
Furthermore, we note that with the same transformation, the WER reduction of \wapat is greater than that of WavAugment. 
Additionally, for all transformations, there are some oscillations in WavAugment while \wapat is consistently increased compared to the baseline.
The results accords with the expected that phoneme adversarial training with WavAugment guidance constrains stable optimization of adversaries, resulting in better generalization.

\subsection{Ablation Study}
As shown in Table~\ref{tab:ablation}, to better understand the function of each component of \wapat, ablation studies are performed and expected to answer the following questions.

\noindent \textbf{How effective is the PAT?} Echoing (a) in Tbale~\ref{tab:ablation}, SpeechLM--P with proposed phoneme adversarial training (\textsc{Phoneme AT}) can achieve the better performance on in-domain and out-of-domain datasets than baseline (\textsc{No-AT}). It indicates adversarially altered phoneme perturbations are much closer to the clean distribution, while strengthen the robustness by capturing more robust features.

\noindent \textbf{Is \wapat superior than PAT?}
With \textsc{WavAugment PAT} means that PAT is guided by the WavAugment, \ie, proposed \wapat. The ESB score of \wapat has decreased by roughly 7.4\% when compared to PAT. It is evident that WavAugment guidance AT indeed aids in finding stronger robust features.

\noindent \textbf{Does the choice of magnitude $\epsilon$ matter?}
We present the \wapat results with different magnitude $\epsilon$ in Table~\ref{tab:ablation} (b).
$\epsilon=0$ means the standard training of SpeechLM (\textsc{No-AT}), which makes the models have the worst performance on clean WER and robustness. 
With the increase of $\epsilon$ to 0.01, there is a drop of both clean WER and ESB score.
Moreover, we find the clean WER of target model has the lower sensibility on $\epsilon$.
But with the $\epsilon$ becoming larger, AT greatly damages the generalization, \eg, with $\epsilon=0.015$, ESB score increases to 33.24. This finding is also revealed by~\cite{kireev2022effectiveness}.

\section{Conclusions and Limitations}
In this paper, we propose a novel WavAugment Guided Phoneme Adversarial Training (\wapat) method, to enhance the cross-domain generalization of ASR systems.
\wapat utilizes the phoneme representation of augmented audios to guide the generation of adversarial examples, resulting in consistently stronger generalization on multiple datasets.
Our experiments demonstrate that \wapat achieves state-of-the-art robustness on challenging ESB benchmark. 
However, \wapat still costs increased training time, this limitation also holds for any adversarial training. This limitation is remained as the future optimization direction.
\bibliographystyle{IEEEtran}
\bibliography{mybib}

\end{document}
