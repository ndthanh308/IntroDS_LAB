
\IEEEraisesectionheading{\section{Introduction}}

\IEEEPARstart{O}{ptical} computing leverages the properties of light waves to facilitate high-speed data processing while reducing the energy cost~\cite{marechal1953filtre, cutrona1960optical,o1956spatial, ambs2010optical, wetzstein2020inference, lugt1964signal, zhou2019optical}. Recent advances in automatic differentiation have enabled in silico training of large-scale optical computing weights, giving rise to the realizations of diffractive neural networks~\cite{chang2018hybrid, lin2018all}, optical reservoir computing~\cite{rafayelyan2020large, verstraeten2007experimental}, and coherent nanophotonic circuits~\cite{shen2017deep}. 


\textit{Problem Statement.} Training optical computing systems presents two challenges: an intensive computational process and a performance disparity between simulation and reality when implementing pre-trained weights onto real-world systems~\cite{buckley2023photonic, lin2018all, rumelhart1986learning}.
Typically, the optical computing systems are trained in silico using differentiable simulators rooted in the first principle of optics, an approach known as simulator-based training (SBT). While SBT has proven effective within the confines of the simulator, the performance in real systems is largely contingent upon the simulator's fidelity. Factors such as misalignment and aberration, often omitted in simulations, cause significant performance degradation when optical computing weights trained exclusively within the simulator are applied to real-world systems.

To bridge the reality gap between simulation and experiments, physics-aware training (PAT) and hybrid training (HBT) have been introduced ~\cite{wright2022deep, spall2022hybrid} recently. Both training strategies include conducting the forward pass in the real-world system and back-propagating the loss from the system to its weights through the simulator. These in situ approaches allow the training process to access the optical computing system during the forward pass, which leads to more accurate weight updates than in silico training ~\cite{buckley2023photonic}.

Despite these recent advances, there is a continued reliance on a physics-based simulator during the back-propagation process in current in situ training methods. Such a setting brings three drawbacks: (1) the bias between the simulator and real system prohibits the above training process from achieving optimal results; (2) the in silico simulation requires large memory and computation, limiting the aforementioned methods from in situ training in edge devices with limited computing resources~\cite{sludds2022delocalized}; and (3) the model-based training strategies need high-fidelity images of the input object, which are costly to acquire in terms of instruments, time and storage memory. Hence, developing a memory- and computation-efficient algorithm to train the optical computing system efficiently is an open problem we address in this paper.



% Figure environment removed 


\textit{Proposed Solution.} Here, we propose an in situ model-free optimization method that does not require back-propagating errors through the simulator. Instead, we use a score gradient estimation algorithm~\cite{wierstra2014natural, williams1992simple} to solely use the forward outputs from the real system to get gradients for updating the weights of the optical computing system. As shown in Fig.~\ref{fig:mfo}, our method treats the optical system as a black box and back-propagates task-specific negative-loss as rewards to the source weight distributions (Fig.~\ref{fig:mfo}a). This process only requires knowledge of the weights and forward outputs of the optical computing system, unlike the SBT and HBT methods that require a simulator and the images of the input objects (Fig.~\ref{fig:mfo}b). 


\textit{Contributions.} We make the following contributions:

\begin{itemize}
    \item We \textit{introduce} a score-gradient estimation method to train the optical computing system in a model-free manner, providing a computation- and memory-efficient way to mitigate the reality gap to training the real optical computing system (Sec.~\ref{sec: method}). 
    \item We \textit{validate} our method on a diffractive optical computing system. Experimental results show that G-MFO outperforms hybrid training on the commonly used MNIST and FMNIST datasets~\cite{lin2018all, wright2022deep, spall2022hybrid} (Sec.~\ref{subsec: general performance}). 
    \item We \textit{show} the G-MFO training process only consumes $\sim 0.1\%$ of the GPU time and memory compared with the HBT in situ method by avoiding the computation-intensive modeling of the wave propagation process (Sec.~\ref{subsec: source efficient training by G-MFO.}).
    \item Application scenario: We \textit{demonstrate}, as a proof-of-concept, that our G-MFO-trained optical computing system's effectiveness on 
     classifying four types of white blood cells from their phase maps in a \textit{marker-free}\footnote{
    Herein, we use "marker-free" but not "label-free" to avoid confusion. This is because "label-free" in biomedical research and high-level vision have different meanings.} manner with a testing accuracy of $73.8\%$, making it a promising approach for image-free, marker-free, and high-speed cell analysis (Sec.~\ref{subsec: classify WBC.}).
\end{itemize}

\textit{Open source.} 
% Currently, most work on in situ training optical computing systems either do not open-source the code or only open-source the code related to the simulation-based demo corresponding to their proposed method. 
Upon acceptance, we will open-source all the code (including simulators, algorithm-related, hardware-related, and baselines) related to our work to facilitate research on training optical computing systems. We hope to promote the reproducibility and follow-ups for this hardware-centric research direction. 


% {\paragraph{Scope} This research employs a score-gradient-based learning approach to train the diffractive optical neural networks. We take initial steps in the broad domain of co-optimizing manufacturability with computational optics design. We believe that the insights provided by our work are invaluable and could inspire further research in computational optics and photolithography.


\begin{table*}[ht]
\centering
\arrayrulecolor{black}
\fontsize{8pt}{8pt}\selectfont
    \centering
    \begin{tabular}{c|p{1.6cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}}
    \toprule
    & Conventional &\multicolumn{2}{c|}{MBO} & \multicolumn{5}{c}{MFO} \\\midrule
    & SBT ~\cite{lin2018all, shen2017deep} & H-MBO ~\cite{wright2022deep, spall2022hybrid, zhou2021large} & L-MBO \cite{zheng2023dual, huo2023optical} & IMOB \cite{Zhou:2020pr, nakajima2022physical, hughes2018training}  & FFT ~\cite{momeni2023backpropagation, oguz2023forward} & Trial and Error~\cite{bueno2018reinforcement, liu2022programmable} &  GA ~\cite{zhang2021efficient} & \textbf {G-MFO (ours)}  \\\midrule
    In situ & \hfil\cellcolor{red!20} No & \hfil\cellcolor{green!20} Yes & \hfil\cellcolor{green!20}Yes & 
    \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes \\
 Computation overhead & \hfil\cellcolor{red!20} High & \hfil\cellcolor{red!20} High & \hfil\cellcolor{red!20} High &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low\\ 
 % \hline
    % Model-free & \hfil\cellcolor{red!20} No & \hfil\cellcolor{red!20} No & \hfil\cellcolor{green!20} Yes  \\
     Input image free & \hfil\cellcolor{red!20} No & \hfil\cellcolor{red!20} No & \hfil\cellcolor{red!20}No & 
    \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{red!20}No & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes \\
    In silico training time & \hfil\cellcolor{red!20} High & \hfil\cellcolor{red!20} High & \hfil\cellcolor{red!20} High &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low\\ 
    % Task Performance  & \hfil\cellcolor{red!20} Low & \hfil\cellcolor{red!20} Low & \hfil\cellcolor{green!20} High &  &  &   &   &  \hfil\cellcolor{orange!20} Medium\\
    Dimensionality & \hfil\cellcolor{green!20} High & \hfil\cellcolor{green!20} High & \hfil\cellcolor{green!20} High &  \hfil\cellcolor{green!20} High &  \hfil\cellcolor{green!20} High &  \hfil\cellcolor{red!20} Low &  \hfil\cellcolor{red!20} Low &  \hfil\cellcolor{orange!20} Medium\\
    Intermediate measurement & \hfil\cellcolor{green!20} No & \hfil\cellcolor{green!20} No & \hfil\cellcolor{green!20}No & \hfil\cellcolor{red!20}Yes & \hfil\cellcolor{red!20} Yes & \hfil\cellcolor{green!20}No & \hfil\cellcolor{green!20}No & \hfil\cellcolor{green!20}No\\
    Gradient & \hfil\cellcolor{green!20} Yes & \hfil\cellcolor{green!20} Yes & \hfil\cellcolor{green!20} Yes & 
    \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{red!20}No & \hfil\cellcolor{red!20}No & \hfil\cellcolor{red!20}No & \hfil\cellcolor{green!20}Yes\\
    \bottomrule
    \end{tabular}
    \caption{{\textbf{Comparison of strategies on training optical computing systems} along the axes of in situ training capability (in situ), in silico computation overhead (computation overhead), the requirement on the recording of the input object to the task (input image free), required in silico training time, the dimensionality of trainable parameters (dimensionality), requirements on intermediate measurement and whether or not use gradient-based update that is more efficient (gradient). *Denotes compatibility with adding nonlinearity to the optical computing system.
    % \gy{@shuxin, complete the full names of the methods}
    Simulator-based training (SBT), Hybrid model-based training (H-MBO), Learned model-based training (L-MBO), Intermediate measurement optical backpropagation (IMOB), Forward-forward training (FFT), Genetic algorithm (GA), Gradient-based model-free optimization (G-MFO).
    }}
    % The AFM method is slow in speed but has high lateral resolution and exhibits $2.5D$ imaging capability. Our work chooses AFM as the tool for characterization as the latter two are vital factors for the sub-diffraction-limited characterization of high-resolution OPD map in nano-prints.
    \label{tab: comparison of training methodlogies}
\vspace{-1em}
\end{table*}

\section{Related Work}
% We briefly review the the physical implementations of optical computing systems (in )

% \subsection{Optical computing modalities}
%     \begin{itemize}
%         \item A category. Including the diffractive neural network and reservoir computing. 
%         - Diffractive neural network
%         - reseivior computing
%         \item B category. Including the photonics circuits.
%         - ass.

%         Our work demonstrate diffractive 
%     \end{itemize}
    
% Optical computing uses light's diffraction, interference, and wavelength division multiplexing to conduct large-bandwidth and low-latency computations \cite{zhou2022lightcomputingreview}. The functions of optical computing can be various. Simple optical computing includes Fourier transform and edge detection by a lens at the speed of light. In recent years, more complex optical computing, i.e., optical neural networks, has evolved to conduct image classification and scene detection. The calculation capability of optical computing increases largely with more optical computing layers, adding non-linear activation layers and a mixture of optical and electronic computation units. 


We discuss the following work related to our contributions. 

% In the past several two years, there has been progress in developing situ training strategies the optical computing systems. We make a first attempt to group previous and our methods into the two categories, the model-free and model-based optimization methods, differentiating these two genres by if they use the numerical modeling of the optical computing system during the parameter updating process. Details of the illustrations and comparison are illustrated below. 

% \subsection{In Silico training.}
% For now
% Early work in this genre. For example, 

% However, there is a gap between simulation and experiment for optical computing. In the early research on optical computing, some papers are only conceptual and have simulation results. Within papers with experiment results, the pure cascaded optical computing without correction of electronic neural network or electronic nonlinear layer has far lower accuracy than simulation. For instance, accuracy of nearly $\%10$ is reported in  for an even one-layer diffractive optical neural network. 



\subsection{In situ training strategies to optimize the optical computing system}


The majority of research into optical computing system training has historically relied on in silico training. This process involves carrying out forward and backward propagation calculations on an external computer that simulates the physical system through a digital twin~\cite{lin2018all, shen2017deep}. However, this technique can lead to discrepancies between the simulation and actual reality due to inaccuracies in the physical system's representation.

In recent years, progress has been made in developing in situ training strategies that use data gathered from real-world optical computing systems to mitigate the reality gap and improve experimental performance. As a first attempt, we categorize previous and our in-situ training methods into two genres: model-free optimization (MBO) and model-based optimization (MFO) methods. We differentiate these two genres by whether they use numerical models of the optical computing system during the parameter updating process. 
A tabular comparison of the previous and our methods is in Tab.~\ref{tab: comparison of training methodlogies}. Details of the illustrations and comparisons are illustrated below. 
% \sx{need to adopt the name presented in this table}

% \underline{M}odel-\underline{B}ased \underline{O}ptimization
\textbf{MBO methods.} \textit{Physics-aware training (PAT)~\cite{wright2022deep}, hybrid training (HBT)~\cite{spall2022hybrid} or adaptive training (AT)~\cite{zhou2021large} (H-MBO)} are one type of the model-based methods that conduct forward pass in a real system and back-propagate the gradients with the aid of a physics-based simulator. 
\textit{Backpropagation through learned model (L-MBO)} is another method that gathers the real data from the optical computing system to train a neural proxy of the optical computing system~\cite{zheng2023dual, huo2023optical}. With such a learned proxy rather than the physics-based model utilized in PAT/HBT/AT, the backward parameter update process can reduce the bias from the model mismatch between the simulator and the real system. During training, one has to optimize both the task's and proxy's parameters to optimize the task performance and realize high fidelity. The task performance for the MBO, especially the L-MBO, is high, while back-propagating with the digital twin also burdens the training process. Moreover, all the MBO approaches require images of input objects during the training, imposing another burden on the overall process.   

% \begin{itemize}
%     \item \textbf {PAT / HBT / AT:} Physics-aware training (PAT), hybrid training (HBT) or adaptive training (AT) are one type of the model-based methods that conduct forward pass in a real system and back-propagate the gradients with the aid of a physics-based simulator. An updated version is dual adaptive training []. have been introduced ~\cite{wright2022deep, spall2022hybrid}. 
%     \item \textbf{Backpropagation through learned model} are recent methods that gather the real data from optical computing system to train a neural proxy of the optical computing system~\cite{zheng2023dual, huo2023optical}. With such learned proxy rather than the physics based model in PAT/HBT/AT, the backward parameter update process can reduce the bias by the model mismatch. During the training process, one has to optimize both the task's parameters and proxy's parameters.  
%     % This work uses systematic error prediction networks to correct the ideal optical neural network model and achieve high experiment accuracy.
%     % \item \textbf{}    
%     % Both training strategies include conducting the forward pass in the real-world system and back-propagating the loss from the system to its weights through the simulator. 
% \end{itemize}




\textbf{MFO methods.} Unlike the aforementioned MBO methods, MFO methods do not require constructing a digital twin of the optical computing system; they directly use the real system's output or intermediate measurements to update its parameters. \textit{Population-based algorithms} such as genetic algorithm (GA) methods~\cite{zhang2021efficient} use the output from the optical computing system to optimize parameters by simulating the process of natural selection. Still, the genetic algorithm's performance scales poorly to the dimensionality of parameters~\cite{grefenstette1986optimization}. 
% and the number of parameters it can optimize is far less than the number of neurons of a diffractive-based optical computing network. 
\textit{Forward-forward training (FFT)} is a greedy multi-layer learning procedure for mortal computation~\cite{hinton2022forward} and it has been applied to train optical computing systems reently~\cite{momeni2023backpropagation, oguz2023forward}. However, labels must be added to each input sample during the training and testing. As a result, such training strategies require masking the input, which might be unrealistic in many scenarios, and the testing process of forward-forward training is prolonged.
\textit{Intermediate measurement optical backpropagation (IMOB)} proposed using the adjoint variable method or direct feedback alignment, etc., to calculate gradients~\cite{Zhou:2020pr, nakajima2022physical, hughes2018training}. However, such methods require intermediate system measurements for every layer's output, which might be infeasible or require additional measurement setups. 

We propose an MFO training method using Monte Carlo gradient estimation to automatically update the optical computing system parameters. Our work shares similarities with Zhang et al., which uses the genetic algorithm for weight update~\cite{zhang2021efficient}, as our and their methods both generate a batch of sampled parameters during the training process. The difference is that our parameter updating process is more efficient owing to a score gradient estimator rather than their heuristic hill-climbing type algorithm. Moreover, our method does not need specific conditions, such as changing the system or manipulating the input object, which are more or less required in other MBO and MFO methods. 
% and we show it can handle tens of thousands of trainable parameters in situ. 


\subsection{Application side of optical computing}


Optical computing, outperforming electrical computing in parallelism and processing speed, is pivotal for AI progress via optical neural networks (ONN) development~\cite{wetzstein2020inference}. ONNs encode inputs using light's spatial, temporal, and spectral characteristics to enable applications such as image classification, motion detection, and medical diagnosis~\cite{scalable_optical_learning_operator, liu2022programmable, reconfigurable_onn}. Furthermore, optical computing functions as an advanced neural network platform and directly processes optical signals, facilitating applications like phase reconstruction~\cite{mengu2022classification}, denoising~\cite{icsil2024all}, edge detection~\cite{park2022metasurface}, and unidirectional imaging~\cite{li2023unidirectional}. 

As a secondary contribution, our work showcases the application of optical computing for marker-free cell classification. Particularly relevant to our research is the study by Wang~\textit{et al.}~\cite{wang2023image}, which demonstrates the classification of fluorescent-labeled cells using an optical computing system. In contrast, our approach shows cell-classification based on their phase maps, instead of relying on fluorescent markers. This illustrates that optical computing can facilitate low-storage, high-speed, and marker-free cell analysis.

% #Medium



\section{Methodology} \label{sec: method}
In what follows, we mathematically detail the problem setup on training the optical computing system and our solution. We introduce problem formation in Subsec.~\ref{subsec: problem setup} and the conventional solution of using simulator-based training (SBT) in Subsec.~\ref{subsec: simulator-based design}. We then illustrate our solution to the problem, the gradient-based model-free optimization (G-MFO) for training the optical computing system in Subsec.~\ref{subsec: G-MFO methodology}. Finally, we illustrate the optical computing system and the related simulators in Subsec.~\ref{subsec: system description}, which we will use to demonstrate the performance of our method. 


\subsection{Problem setup} \label{subsec: problem setup}
% \gy{$x_i\in \mathbb{R}^{n_1\times n_1}$}
 We are interested in learning the optimal weight $w\in\mathbb{R}^{H}$ for the optical computing system on a desired task with a training dataset $\mathcal{D} = \{x_i, y_i\}_{i=1}^N$, where $N$ is the size of the dataset, $H$ is the number of trainable parameters in $w$, and $x$ and $y$ denote the input and target of interest, respectively. A function $f_{sys}(\cdot,w)$ maps $x\rightarrow y$ through this optical computing system with $w$. Specifically, in the image classification task based on the diffractive optical computing system we work on, $f_{sys}$ denotes the optical mapping from the input image $x$ to the output label $y$, and $w$ is the optical computing weight in the form of phase value modulation. 
 % shown in Fig.~\ref{fig:mfo}.
 % We detail more about our system in subsection~\ref{subsec: system description}.
 
During training, one can minimize the cost function $J(w)$ as the mean task-specific loss across the entire training data set $\mathcal{D}$
% \cz{not sure if 'we xx' is a good way to describe problem setup, the following equations sound like you are using $J(w)$ but you are actually using $J(\theta)$}
:

\begin{subequations}
\begin{align}
          \operatorname*{arg\,min}_w J(w): &=\mathbb{E}[\mathcal{L}(\mathcal{D}, w)], \\
                    &= \frac{1}{N}\sum_{i=1}^{N}\mathcal{L}(f_{sys}(x_i, w), y_i), \label{eq:objective function}
\end{align}
\end{subequations}
% \begin{subequations}
where $\mathcal{L}$ is the task-specific loss function, we use cross-entropy loss~\cite{brier1950verification} since we deal with image classification tasks throughout this paper. 

We use gradient descent-based search to find the optimal $w$ to minimize the objective function $J(w)$:
\begin{equation} \label{eq:grad descent}
    w = w - \alpha \nabla_{w} J(w),
\end{equation}
where $\nabla_{w}$ represents the gradient operator that collects all the partial derivatives of a function concerning parameters in $w$, and $\alpha$ is the learning rate. 

It is straightforward to use the backpropagation method~\cite{rumelhart1986learning} to take the gradient through $f_{sys}$ and finds the gradient $\nabla_{w} J(w)$ as:
\begin{equation}
    \nabla_w J(w)= \frac{1}{N}\sum_{i=1}^N \nabla_w \mathcal{L}({f_{sys}(x_i, w)}, y_i),
    \label{eq: FOBG}
\end{equation}
when we have an accurate and differentiable $f_{sys}$ modeling.
However, this is the case for training digital neural networks~\cite{rumelhart1986learning}, but not when we train a real-world optical computing system. \textbf{Thus, this paper's critical aim is finding an accurate gradient estimation of $\nabla_w J(w)$ to update optical computing weight $w$ in a real-world optical system}.

% Note that we use the whole dataset for the gradient update to simplify the illustration in Eq.~\ref{eq: FOBG}. In actual implementation, We use stochastic gradient descent (SGD)~\cite{lecun2015deep} and iterate through the whole dataset with the batch-gradient-based update.


% Figure environment removed

\subsection{In silico simulator-based training (SBT)} \label{subsec: simulator-based design}



\textbf{Back-propagation through the simulator $\hat{f}_{sys}$.} In a real-world optical computing system, since we do not have an exact functional expression of $f_{sys}$, the \textbf{simulator-based training} (SBT) builds a simulator $\hat{f}_{sys}$ as the differentiable approximation of $f_{sys}$ (Fig.~\ref{fig:mfo}b). 
A naive training strategy is substituting $f_{sys}$ in Eq.~\ref{eq: FOBG} with the simulator $\hat{f}_{sys}$ and applying in silico training on the simulator:

\begin{equation}
    \nabla_w J(w)= \frac{1}{N}\sum_{i=1}^N \nabla_w \mathcal{L}({\hat{f}_{sys}(x_i, w)}, y_i).
    \label{eq: sbt}
\end{equation}
The resulting $\nabla_w J(w)$ is used in Eq.~\ref{eq:grad descent} to update $w$.
After training, the optimized $w$ is uploaded to the real optical computing system $f_{sys}$ to test the performance. 


\textbf{Simulation-to-reality gap.} The aforementioned simulator-based training is based on backpropagation through the simulator $\hat{f}_{sys}$. The "sim2real" gap is low (i.e., the gradient $\nabla_w J(w)$ is an accurate estimation) when the simulator $\hat{f}_{sys}$ is similar to $f_{sys}$. However, this assumption does not hold in many prototypes of optical computing systems where inadequate modeling and misalignment between the optical elements decay the performance of the SBT during the "sim2real" transfer. We use a simulator described in Subsec.~\ref{subsec: system description} to assess the adverse effect of misalignment on the image classification results. We impose various misalignments to a well-trained ideal optical computing system and measure drops in classification accuracy. For instance, we show in Fig.~\ref{fig: misalignment degrades the performance} that slightly laterally misaligning the optical computing layer by $41.1 \: \mu m$ reduces the classification accuracy by $31.2\%$.  
% Thus, \textbf{we aim to demonstrate a training strategy that does not suffer from the sim2real transfer and has the comparable imaging classification accuracy we have in the simulator}.

% The cost function $J$:

% \begin{equation}
% % \mathcal{F}(\distParams) := \int \dist(\vx; \distParams) \cost(\vx; \costParams) \intd\vx =
% % \expect{\dist(\vx; \distParams)}{\cost(\vx; \costParams)} .
% J(\theta) = \mathbb{E}_{\theta}[l_{\theta}(z)] = \int l(z) \pi(z\|\theta) dz
% \label{eq:expectation_function}
% \end{equation}


% \begin{equation}
%     r = R(\mathbf{y}) = \frac{\bar{\mathbf{y}}_{focus}}{\bar{\mathbf{y}}_{bg}},
% \end{equation}


\subsection{In situ G-MFO}\label{subsec: G-MFO methodology}
Our solution for solving the aforementioned "sim2real" gap issue in Subsec.~\ref{subsec: simulator-based design} is in situ learning the optical computing weight $w$ with the gradient-based model-free optimization (G-MFO). In situ learning enables us to access the output of $f_{sys}$ and is feasible on the hardware side because we can use programmable devices such as spatial light modulators to update $w$. The challenging part is designing a training strategy that efficiently uses the output of actual system $f_{sys}$ to construct an unbiased gradient estimator. Here, we use the score gradient estimator to calculate the gradient~\cite{schulman2015gradient, mohamed2020monte} for the backward update of parameters in $w$ while circumventing the construction of $\hat{f}_{sys}$, a biased and resource-intensive numerical modeling of $f_{sys}$. 

\textbf{Back-propagation through the weights distribution $p$.} In our score gradient estimator for model-free optimization, we model optical computing weight $w$ as a random variable that follows a 
probability distribution: $w\sim p(w|\theta)$ and rewrite the cost function $J(w)$ in  Eq.~\ref{eq:objective function} as a probability cost function $J(\theta)$:
\begin{subequations}
\begin{align}
        \operatorname*{arg\,min}_{\theta} J(\theta): 
        % &= \frac{1}{N}\sum_{i=1}^{N}l(f_{sys}(x_i, w), y_i)\\
          &= \frac{1}{N}\sum_{i=1}^{N} \mathbb{E}_{p(w|\theta)}[\mathcal{L}(f_{sys}(x_i, w), y_i)],\\
          &= \frac{1}{N}\sum_{i=1}^{N} \int {p(w|\theta)}\mathcal{L}(f_{sys}(x_i, w), y_i) \diff w,
\end{align}\label{eq: prob obj}
\end{subequations}
where the probability distribution $p(w|\theta)$ is continuous in its domain and differentiable concerning its distribution parameter $\theta$. 
Accordingly, the original goal of optimizing $w$ is reformulated as finding a most likely distribution $p(w|\theta)$ that minimizes the cost function $J(\theta)$ in Eq.~\ref{eq: prob obj}. 
Specifically, we model the distribution $p$ as a multivariate normal distribution with $\theta = \{\mu, \sigma^2\}$ and $p(w|\theta) = \mathcal{N}(w;\mu, \sigma^2)$ for optimizing the continuous phase-valued weight to be uploaded onto the SLM in our work. 


To update distribution parameter $\theta$ with the gradient descent Eq.~\ref{eq:grad descent}, we take the gradient of the cost function $J(\theta)$ in Eq.~\ref{eq: prob obj}:
\begin{subequations}
\begin{align}
        \nabla_{\theta} J(\theta) 
        &= \nabla_{\theta} \frac{1}{N}\sum_{i=1}^{N} \int {p(w|\theta)}\mathcal{L}(f_{sys}(x_i, w), y_i) \diff w ,\\
        &= \frac{1}{N}\sum_{i=1}^{N} \int \mathcal{L}(f_{sys}(x_i, w), y_i) \nabla_{\theta}{p(w|\theta)} \diff w .
\end{align}
\end{subequations}
Applying the log derivative trick, we have:
\begin{equation}
        \nabla_{\theta} J(\theta) 
        = \frac{1}{N}\sum_{i=1}^{N} \int p(w|\theta) \mathcal{L}(f_{sys}(x_i, w), y_i) \nabla_{\theta} \log{p(w|\theta)} \diff w .\label{eq: prob obj int}
\end{equation}
Then we apply Monte Carlo integration to approximate the integral value in Eq.~\ref{eq: prob obj int} by first drawing $M$ independent samples $\{w_j\}_{j=1}^M$ from the distribution $p(w|\theta)$ and then computing the average function value evaluated in these samples:
        \begin{subequations}
        \begin{align}
        \nabla_{\theta} J(\theta) 
        &=\frac{1}{N}\sum_{i=1}^{N} \frac{1}{M}\sum_{j=1}^{M} \mathcal{L}(f_{sys}(x_i, w_j), y_i) \nabla_{\theta} \log{p(w_j|\theta)} \label{eq: prob obj monte carlo int},\\
        &=\frac{1}{M}\sum_{j=1}^{M} [\frac{1}{N}\sum_{i=1}^{N}  \mathcal{L}(f_{sys}(x_i, w_j), y_i)] \nabla_{\theta} \log{{p(w_j|\theta)}}. \label{eq: prob grad}
\end{align}
\end{subequations}
%where $M$ is the number of samples we draw from the distribution $p(w|\theta)$. 
Here we define $r(w_j)=\frac{1}{N}\sum_{i=1}^{N} \mathcal{L}(f_{sys}(x_i, w_j), y_i)$ as the negative reward corresponding to each weight $w_j$. We use Equation~\ref{eq: prob grad} as the score gradient estimator for G-MFO, 
where the score function is $\nabla_{\theta} \log{p(w_j|\theta)}$, which has been widely used in other areas, such as policy gradient algorithms in reinforcement learning~\cite{williams1992simple} and diffusion models~\cite{song2019generative}. 


% \sx{we do not do so}  \gy{write down how we did} 

\textit{Variance reduction.} The main risk of using the score gradient estimator is the high variance that comes from the Monte Carlo integration step that transits Eq.~\ref{eq: prob obj int} to Eq.~\ref{eq: prob obj monte carlo int}. Such a sampling-based integration step has high variance because different sets of random samples may lead to significantly different integral estimates. We reduce the variance by subtracting the $r(w_j)$ with baseline value $\bar{r} = \frac{1}{M} \sum_{j=1}^M r(w_j)$ while keeping the bias of gradient unchanged~\cite{mei2023role}:
\begin{equation}
    \nabla_{\theta} J(\theta) = 
    \frac{1}{M}\sum_{j=1}^{M} (r(w_j)- \bar{r}) \nabla_{\theta} \log{{p(w_j|\theta)}}. \label{eq: prob grad simplified}
\end{equation}

\textbf{Training recipe of G-MFO.} 
% During training, we sample a group of phase-valued optical computing weights $\{w_j\}_{j=1}^M$ from the distribution: $w_j \sim p(w|\theta)$. Then, we upload the sampled weights onto the optical computing layer and test the weights with inputs from dataset $\mathcal{D}$. 
% After that, we calculate the negative rewards $r(w_j)$ and update the distribution parameter $\theta$ through Eqs.~\ref{eq:grad descent} and~\ref{eq: prob grad simplified}. 
% The algorithm iterates these steps until convergence. 
% After minimizing the objective function Eq.~\ref{eq: prob obj}, we export $w_j$ with the smallest $r(w_j)$ as the output weight $w^{\star}$. This performs better than setting $w^{\star}$ as the sampled mean $\mu$. 
We perform the following steps in each training epoch (see Fig.~\ref{fig: MFO_workflow}): 1. Sample a group of phase-valued optical computing weights $\{w_j\}_{j=1}^M$ from the distribution $w_j \sim p(w|\theta)$ and upload them to the optical computing layer. Upload classification data $\mathcal{D}=\{x_i, y_i\}_{i=1}^N$ to the input layer; 2. Collect the optical computing system's output $\{f_{sys}(x_i, w_j)\}_{i=1, j=1}^{N, M}$ for each pair of input and weight; 3. Update the distribution parameter $\theta$ in silico using Eqs.~\ref{eq:grad descent} and~\ref{eq: prob grad simplified}; 4. Sample a new group of $\{w_j\}_{j=1}^M$ from the updated distribution $w_j \sim p(w|\theta)$, which is ready to be uploaded to the optical computing layer in the next epoch.
The algorithm iterates these steps until convergence. 

After minimizing the objective function Eq.~\ref{eq: prob obj}, we export $w_j$ with the smallest $r(w_j)$ as the output weight $w^{\star}$. This performs better than setting $w^{\star}$ as the sampled mean $\mu$. 
An algorithmic overview of the above training recipe is shown in Algorithm~\ref{alg:mfo}.

\begin{algorithm}
\caption{Algorithmic overview of G-MFO.}\label{alg:mfo}
\begin{algorithmic}[1]
\State \textbf{Input: }  {Classification dataset $\mathcal{D}=\{x_i, y_i\}_{i=1}^N$, learning rate $\alpha$, number of sampled weights $M$, optical computing system $f_{sys}$, distribution parameter $\theta=\{\mu, \sigma^2\}$, loss function $\mathcal{L}$, epochs $K$.}
\State \textbf{Output: }{Optimized optical computing weight $w^{\star}$.}

\For{$k$ in range $K$}
    \State{Sample $\{w_j\}_{j=1}^M$ from distribution $p(w|\theta)$.}
    % \State{ $\{w_j\}_{j=1}^M$}
    \State{\emph{$\triangleright$ in situ evaluate $\{w_j\}_{j=1}^M$.}}
    \For{$j$ in range $M$}\\
        \State{$r(w_j)\gets \frac{1}{N}\sum_{i=1}^{N} \mathcal{L}(f_{sys}(x_i, w_j), y_i).$}
    \EndFor
    \State{\emph{$\triangleright$ in silico update $\theta$.}}
    \State{Calculate $\nabla_{\theta} J(\theta)$ via Eq.~\ref{eq: prob grad simplified}.}
    \State{$\theta \gets \theta -\alpha\nabla_{\theta} J(\theta).$ }
\EndFor
% \State $w^{\star}\gets \mu \text{ from } \theta$.
\State $w^{\star}\gets w_j$ with the smallest $r(w_j)$.
\end{algorithmic}
\end{algorithm}

% Figure environment removed

% Figure environment removed


\subsection{Experiment and simulation detail of our diffractive optical computing system} \label{subsec: system description}

\subsubsection{Experimental setups of the real single-layer and two-layer optical computing systems $f_{sys-1-layer}$ and $f_{sys-2-layer}$. } 
We build a single-layer optical computing system and a two-layer optical computing system to validate the effectiveness of the proposed G-MFO-based training strategy (see Fig.~\ref{fig: system skectch} and Supplement Fig. S.1). 

\textbf{Single-layer optical computing system:} A laser field $u_{laser}$ propagates onto the input layer (SLM1), where the phase-valued object $u_{obj}$ is displayed. The light field reflects from the input layer onto the optical computing layer $u_w$ (SLM2). A camera then detects the diffraction light at the output layer. The length $d_{IC}$ and $d_{CO}$ for $Prop_{IC}$ and $Prop_{CO}$ in Fig.~\ref{fig: system skectch}(a) are $215.1 mm$ and $201.6 mm$, respectively. As there are multiple components in the system (e.g., SLMs and cameras), it is difficult to manually align them with high accuracy. We developed a digital alignment method based on the homography technique~\cite{riba2020kornia} using SLMs to compensate for the alignment errors when we implement the baseline method HBT on the real single-layer optical computing system; otherwise, the performance will be pretty poor.
% \cz{didn't say why you need to compensate for alignment here. People would say, you don't need exact $\hat{f}_sys$, why do you need to consider misalignment }. 
Details of our digital alignment method are in Supplement Sec. S.5.  

\textbf{Double-layer optical computing system:} A DMD displays the binary intensity object $u_{obj}$ on the input layer. The light field is then reflected from the input layer onto the optical computing layer1 $u_{w1}$ (SLM1) and subsequently to the optical computing layer2 $u_{w2}$ (SLM2). Following this, a camera captures the modulated light present at the output layer. The length $d_{C_1C_2}$ and $d_{C_2O}$ for $Prop_{C_1C_2}$ and $Prop_{C_2O}$ in Fig.~\ref{fig: system skectch}(b) are $215.1 mm$ and $201.6 mm$, respectively. More details of the optical computing system are in Supplement Sec. S.1. 



 
\subsubsection{Differentiable physics-based simulators $\hat{f}_{sys-1-layer}$ and $\hat{f}_{sys-2-layer}$.} 

We construct an ideal physics-based simulator $\hat{f}_{sys}$ corresponding to the aforementioned optical computing system $f_{sys}$ as the sandbox to test different training algorithms. This simulator is also used inside the design loop of SBT and HBT, which serve as the baseline methods to compare. 


Since our system only includes free-space wave propagation $\textcolor{red}{\hat{f}_{prop}}$, wavefront modulation $\textcolor{Colorfmod}{\hat{f}_{mod}}$, and sensor detection $\textcolor{Colorfdet}{\hat{f}_{det}}$, we build the optical computing simulator by stacking these three optical modules as building blocks.
The functions of optical modules are:
\begin{subequations} \label{eq: diff modules of system}
   \begin{align}
        &\textcolor{red}{\hat{f}_{prop}}(u_{in},z): u_{out} = \mathcal{F}^{-1} (\mathcal F(u_{in}) \times \mathcal F(h_{prop}(z))), \label{eq: free-space prop} \\
        &\textcolor{Colorfmod}{\hat{f}_{mod}}(u_{in}, u_{element}): u_{out} = u_{in} * u_{element},\\
        % &\textcolor{Colorfdet}{\hat{f}_{det}}(u_{in}):I_{out} = Imnoise(|u_{in}|^2), \label{eq: camera detection.}
        &\textcolor{Colorfdet}{\hat{f}_{det}}(u_{in}):I_{out} = |u_{in}|^2, \label{eq: camera detection.}
    \end{align}
\vspace{0.2cm}
\end{subequations}
where $h_{prop}(z) = \frac {e^{jkz'}}{j\lambda z'}e^{\frac{jk}{2z}(x'^2+y'^2)}$ is the propagation kernel under Fresnel approximation~\cite{born2013principles} with a propagation distance $z'$, wavelength $\lambda$ and angular wave number $k$, $u_{element}$ denotes the wavefront modulation from the programmable optical devices, $\mathcal{F}$ denotes the Fourier transform. 
% $Imnoise$ denotes the process of imposing camera noise. 

% Figure environment removed


\textit{Simulator of a single-layer optical computing system.} Based on the modules in Eq.~\ref{eq: diff modules of system}, the simulator of a single-layer $\hat{f}_{sys-1-layer} = \{\textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfdet}{\hat{f}_{det}}\}$ 
is constructed by chaining the building blocks ${1-5}$:
\begin{subequations}\label{eq: simuator}
    \begin{align}
        & 1. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{laser}, u_{obj}), \\
        & 2. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{IC}), \\
        & 3. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{out}, u_{w}), \\
        & 4. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{CO}), \\
        & 5. I_{cam} = \textcolor{Colorfdet}{\hat{f}_{det}}(u_{out}).
    \end{align} 
\end{subequations}

\textit{Simulator of a double-layer optical computing system} is constructed similarly by stacking layers as $\hat{f}_{sys-2-layer} = \{\textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfdet}{\hat{f}_{det}}\}$:

% \begin{subequations}\label{eq: simuator}
%     \begin{align}
%         & 1. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{laser}, u_{obj}), \\
%         & 2. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{IC_1}), \\
%         & 3. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{out}, u_{w1}), \\
%         & 4. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{C_1C_2}), \\
%         & 5. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{out}, u_{w2}), \\
%         & 6. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{C_2O}), \\
%         & 7. I_{cam} = \textcolor{Colorfdet}{\hat{f}_{det}}(u_{out}).
%     \end{align} 
% \end{subequations}

% \gy{@shuxin, add some parameters of two layer system in the appropriate positions.}


% The training details of the experiment and simulation are in Supplement Sec. S.3.
%where $d_{IC}$ denotes the distance between the input plane and the optical computing layer, $d_{CO}$ denotes the distance between the optical computing layer and the output plane. %$u_{laser}$, $u_{w}$, $u_{obj}$ correspond to the complex fields of the incident laser, the optical computing layer with weight $w$, and the input layer with object $x$ displayed to classify, respectively.


% \subsection{Training details.}

% The parameters of simulators are also calibrated



% % \begin{align}
%     \left \textcolor{red}{Propagator: }f_{prop}(u_{in},z): u_{out} = \mathcal{F}^{-1} (\mathcal F(u_{in}) \times \mathcal F(h_{prop}(z))), \right \\
%     \left \text{where } 
%     h(x,y; z) = \frac {e^{jkz}}{j\lambda z}e^{\frac{jk}{2z}(x^2+y^2)};\right \\
%     \left \textcolor{red}{Modulator: } f_{mod}(u_{in}, u_{element}): u_{out} = u_{in} * u_{elment}.\right
% % \end{align}
% \end{subequations}


\section{Results}\label{sec: results}

We aim to answer the following research questions in this section:

\begin{itemize}
    \item How does G-MFO perform in the numerical simulations and experiments?
    \item What are the advantages and limitations of G-MFO?
    \item How is G-MFO's applicability on the marker-free cell classification task?
    
\end{itemize}

Thus, we numerically and experimentally evaluate the general performance of our G-MFO method on the open-source MNIST and FMNIST datasets (Subsec.~\ref{subsec: general performance}). 
We then illustrate G-MFO's advantage of memory- and computation-efficient training in Subsec.~\ref{subsec: source efficient training by G-MFO.}. Moreover, we analyze the limitation of our method in Subsec~\ref{subsec: G-MFO exhibits curse of dimensionality.}. Lastly, we demonstrate the G-MFO method on a novel application of marker-free classifying white blood cells in Subsec.~\ref{subsec: classify WBC.}.



% We evaluate our work on four robots, each with a different task, and compare its performance to
% appropriate algorithmic baselines. The experiments represent common robotic
% tasks, such as locomotion, manipulation, and navigation. The tasks pose diverse challenges,
% including continuous and discrete actions, dense and sparse rewards, proprioceptive and image
% observations, and sensor fusion. Learned world models have various properties that make them well-suited for robot learning. The goal of the experiments is to evaluate whether the recent successes of
% learned world models enable sample-efficient robot learning directly in the real world. 



% \textbf{Comparison baselines.} We primarily compare the work with the simulation 

{We compare our method with the following baselines:}

\begin{itemize}
    \item \textbf{Ideal:} The in silico simulation results without introducing any artificial misalignment during the simulation. This corresponds to the best achievable result for an optical computing system. 
    \item \textbf{SBT:} Simulator-based training with digitally aligned simulator. 
    \item \textbf{HBT:} The hybrid training strategies with the digitally aligned model. A detailed description of our implementation of the HBT method is in Supplement Sec. S.6.
\end{itemize}
Training details of all simulations and experiments are in Supplement Sec. S.3.

    % \item Does Dreamer enable robot learning directly in the real world, without simulators?
    % \item Does Dreamer succeed across various robot platforms, sensory modalities, and action spaces?
    % \item How does the data efficiency of Dreamer compare to previous reinforcement learning algorithms?

\subsection{General performance evaluation on the MNIST and FMNIST dataset}~\label{subsec: general performance}
\vspace{-0.5cm}
\subsubsection{Simulation results on the two-layer optical computing system $\hat{f}_{sys-2-layer}$.}\label{subsec: simulation results two layer}

We evaluate our method's accuracy by conducting performance tests on a two-layer optical computing simulator $\hat{f}_{sys-2-layer}$ utilizing two classical image classification datasets: MNIST~\cite{deng2012mnist} and FMNIST~\cite{xiao2017fashion}. Each optical computing layer contains $128 \times 128 = 16,384$ trainable parameter, and the system contains $128 \times 128 \times 2 = 32,768$ parameters. Furthermore, to assess the robustness of the G-MFO method against system misalignment, we intentionally introduce a slight misalignment on the positive x'-axis direction, amounting to $40\mu m$ (equivalent to 5 pixels on SLM1) on the optical computing layer1, and $18.7\mu m$ (corresponding to 5 pixels on SLM2), on the optical computing layer2.
% \gy{@shuxin, insert a sketch of this systme.} 
We use $10,000$ data to train, $10,000$ data to validate, and $10,000$ data to test.

The simulation outcomes for the MNIST and FMNIST datasets are in Table 2. 
The ideal testing accuracy reaches $89.5\%$ on MNIST and $80.5\%$ on FMNIST. However, the presence of misalignment reduces the accuracy to $78.4\%$ and $59.8\%$ using HBT, a decrease of approximately $10\%$ and $20\%$. In contrast, the G-MFO method hits an accuracy of $87.0\%$ and $74.1\%$, effectively mitigating the detrimental impact of system misalignment.                          


\begin{table}[h!]
\newcolumntype {C}[1]{>{\centering\arraybackslash}m{#1}}
\arrayrulecolor{black}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{C{0.16\linewidth} | C{0.072\linewidth} | C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}}
\hline
             &\multicolumn{3}{c|}{MNIST}          & \multicolumn{3}{c}{FMNIST} \\ \cline{2-7}
             & Train      & Val      & Test       & Train         & Val         & Test \\\hline\hline
\textcolor{gray}{Ideal}       & \textcolor{gray}{$90.0\%$}          & \textcolor{gray}{$89.3\%$}            & \textcolor{gray}{$89.5\%$}            & \textcolor{gray}{$82.2\%$}         & \textcolor{gray}{$81.2\%$}           & \textcolor{gray}{$80.5\%$} \\
\hline
HBT          & $78.0\%$         & $78.7\%$           & $78.4\%$         & $61.6\%$          & $61.4\%$           & $59.8\%$\\
% GA & & & & & &\\
G-MFO (Ours)         & $\textbf{86.2\%}$         & $\textbf{86.2\%}$           &$\textbf{87.0\%}$         & $\textbf{75.4\%}$          & $\textbf{75.4\%}$           & $\textbf{74.1\%}$ \\ 

\hline
\end{tabular}
\caption{\textbf{Numerical performance comparison on MNIST and FMNIST datasets on two-layer diffractive optical computing system.
% \gy{Make sure the results are complete.}} 
}}
\label{tab: two layer simulation result}
\vspace{-0.2cm}
\end{table}



% We experimentally evaluate the performance of our G-MFO method on the open-source MNIST and FMNIST datasets in Subsec.~\ref{subsec: problem setup}. We also demonstrate the G-MFO method on a novel application of marker-free classifying white blood cells in Subsec.~\ref{subsec: classify WBC.}. We then illustrate G-MFO's advantage of memory- and computation-efficient training in Subsec.~\ref{subsec: source efficient training by G-MFO.}.

% Lastly, we analyze the influence of sampling size $M$ on our method's final results and optimizable degree of freedom (DOF) $H$ in Subsection~\ref{subsec: G-MFO exhibits curse of dimensionality.}. 

% our solution to the problem, the model-free optimization for training the optical computing system in subsection~\ref{subsec: G-MFO}. Finally, we illustrate the optical computing system and its simulator in subsection~\ref{subsec: system description}, which we will use to demonstrate the performance of our method. 

% # and analysis of the training time cost\



\subsubsection{G-MFO outperforms hybrid training (HBT) experimentally on a single-layer optical computing system $f_{sys-1-layer}$.}\label{subsec: experiment result one layer}

% G-MFO outperforms hybrid training (HBT) in the real systems on the MNIST and FMNIST datasets


We conduct experiments on a real single-layer optical computing system $f_{sys-1-layer}$ on the MNIST and FMNIST datasets. We include in silico SBT and in situ HBT methods utilizing digitally aligned simulators as the comparison baselines. The training, validation, and testing phases each utilize a dataset of 1,000 samples. 
% We do not use a bigger dataset  $f_{sys-1-layer}$ is three times slower than that for $f_{sys-2-layer}$ (Supplement Sec. S.), but this system is easier to calibrate using the method described in Supplement Sec. S.1.

Tab.~\ref{tab: MNIST and FMNIST result} quantitatively shows that our method achieves higher classification accuracy than the HBT and SBT methods on both datasets in the experiments. The SBT method performs poorly due to the reality gap between the simulator and the real system. 
The HBT method suffers from the bias between $\hat{f}_{sys}$ and ${f}_{sys}$ in the backward process, while the G-MFO bypasses the bias-sensitive modeling and updates gradients solely with $f_{sys}$. 
We further show G-MFO's capability to fine-tune the HBT result. The last row of Tab.~\ref{tab: MNIST and FMNIST result} shows that the unbiased G-MFO method further improves the results of HBT. Moreover, we also empirically find that fine-tuning outperforms G-MFO only. Fig.~\ref{fig: G-MFO result} visualizes some experimental outputs and confusion matrices using the G-MFO method. 



\begin{table}[h!]
\newcolumntype {C}[1]{>{\centering\arraybackslash}m{#1}}
\arrayrulecolor{black}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{C{0.16\linewidth} | C{0.072\linewidth} | C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}}
\hline
             &\multicolumn{3}{c|}{MNIST}          & \multicolumn{3}{c}{FMNIST} \\ \cline{2-7}
             & Train      & Val      & Test       & Train         & Val         & Test \\\hline\hline
\textcolor{gray}{Ideal}        & \textcolor{gray}{$92.7\%$}          & \textcolor{gray}{$84.3\%$}            & \textcolor{gray}{$82.2\%$}            & \textcolor{gray}{$85.6\%$}         & \textcolor{gray}{$79.9\%$}           & \textcolor{gray}{$76.4\%$} \\
\hline
\hline
SBT          & $81.9\%$         & $74.4\%$           & $69.3\%$         & $68.3\%$          & $64.1\%$           & $60.9\%$ \\
HBT          & $81.9\%$         & $75.5\%$           & $72.8\%$         & $68.3\%$          & $68.7\%$           & $65.8\%$ \\
G-MFO (Ours)         & $\textbf{83.1\%}$         & $\textbf{77.8\%}$           &$\textbf{73.6\%}$         & $\textbf{74.0\%}$          & $\textbf{71.1\%}$           & $\textbf{70.4\%}$ \\ 
HBT+G-MFO (Ours)      & $\textbf{87.0\%}$& $\textbf{80.2\%}$  & $\textbf{77.7\%}$ &$\textbf{75.0\%}$  & $\textbf{71.7\%}$   & $\textbf{70.2\%}$  \\
\hline
\end{tabular}
\caption{\textbf{Experimental performance comparison on MNIST and FMNIST datasets on the single-layer optical computing system.} Results of the ideal mode are from the simulator, whose parameters are determined from experiments while we impose no misalignment on the simulator. The lower four rows are experimental results from SBT, HBT, G-MFO, {and HBT+G-MFO (G-MFO fine-tuning upon the result from HBT)}. 
% The SBT method results in very low experimental accuracy due to misalignment. 
Our method outperforms the SBT and HBT methods on the MNIST and FMNIST datasets in experiments.
} 
\label{tab: MNIST and FMNIST result}
\vspace{-0.2cm}
\end{table}


% Implementations of SBT and HBT methods have homography-based calibration in the loop.

\subsubsection{Experimental results on the two-layer optical computing system $f_{sys-2-layer}$.}\label{subsec: experiment result two layer}

We also perform experiments on training a real two-layer optical computing system $f_{sys-2-layer}$ on the MNIST dataset. For this experiment, we utilize a dataset comprising 10,000 instances for training, another 10,000 for validation, and a separate set of 10,000 for testing. The training, validation and testing accuracy are  $80.43\%$, $81.1\%$, and $80.3\%$, respectively. 

When compared with the simulated G-MFO outcomes presented in Table.~\ref{tab: two layer simulation result}, the experimental accuracy is lower. We hypothesize that this discrepancy is attributed, in part, to mechanical disturbances encountered during the multi-day span of the experiment. Moreover, the training accuracy from two-layer system is lower than that of single-layer system while the validation and testing accuracy is higher. This is  because we use more samples when training two-layer system, which alleviates overfitting.   




% Figure environment removed




\subsection{Advantage: memory- and computation-efficient training enabled by G-MFO.}\label{subsec: source efficient training by G-MFO.}

% Figure environment removed

In addition to the predicting accuracy discussed in the previous subsection, our G-MFO method has an advantage over other training algorithms regarding GPU time and memory efficiency. 
The SBT and HBT methods compute $\hat{f}_{sys}(x, w)$ and $\nabla_{w}\hat{f}_{sys}$ (Fig.~\ref{fig:mfo}b) for each input $x$ in silico, which requires a lot of in silico computation resources. 
In contrast, our G-MFO method executes the calculation of $f_{sys}(x, w)$ in the light-speed real optical computing system, but not in the computation- and memory-heavy simulator $\hat{f}_{sys}(x,w)$.
% the calculation of gradient in our G-MFO method relies on execution in the light-speed real optical computing system $f_{sys}$ but not in the computation- and memory-heavy simulator $\hat{f}_{sys}$. \sx{i do not think it is the calculation of gradient}
The only step of our G-MFO method that consumes in silico computational resources is the one described in Eq.~\ref{eq: prob grad simplified}, where we calculate the score gradient. The in silico computational resources consumption in this step is low because it only scales with the dimension of $w$ and has no relation to the complexity of the system's light transport $\hat{f}_{sys}$.

We compare our G-MFO method with HBT in GPU memory and time usage during experiments on a single-layer optical computing system in Fig.~\ref{fig: resource consuming}. Our G-MFO method requires far less GPU time and memory than the HBT method during the training.


\subsection{Limitation: G-MFO exhibits the curse of dimensionality.}\label{subsec: G-MFO exhibits curse of dimensionality.}
Our method is not without its limits. Our G-MFO training relies on Monte Carlo integration. It thus inherits the \textit{curse of dimensionality} from the Monte Carlo integration~\cite{bellman1959adaptive}. That is, the number of samples $M$ needed to estimate the integration in Eq.~\ref{eq: prob obj int} with a given level of accuracy grows exponentially concerning the $H$, the number of trainable parameters (i.e., dimensionality) of the function.
This is also discussed and alleviated with \textit{variance reduction} in the previous Sec.~\ref{sec: method}C. However, the G-MFO strategy presented in
this paper is still sample-inefficient, though unbiased and memory-efficient. 
We need to either limit the number of trainable parameters $H$, or sample a large number of varied optical computing weights $\{w\}^M_{j=1}$ from distribution $p(w|\theta)$ in every iteration to make G-MFO's gradient less noisy. 
The former limits our method's design DOF, while the latter requires more executions on the real system, which prolongs the training time. 
% The training speed is heavily limited by the refreshing rate of the SLM performs as the optical computing layer (see further in Sec.\ref{}).

% Figure environment removed

We quantitatively investigate the influence of this limitation in Fig.~\ref{fig: curse of dimensionality} through simulations on a one-layer optical computing system $\hat{f}_{sys-1-layer}$, employing $1,000$ training samples from the MNIST dataset. The figure demonstrates how $M$ and $H$ impact the training performance of G-MFO.
% we conduct simulations with varying $M$ across different trials ( Fig.~\ref{fig: curse of dimensionality}a). we choose $M=128$ in our experiments to have a balance between training time and accuracy.
% We limit the training dataset to $200$ samples from $4$ FMNIST classes, as the G-MFO training in simulation takes a long time. 
% We only evaluate the training accuracy because we have limited training data, and our primary concern is the G-MFO's performance in finding $w^{\star} = \operatorname*{arg\, min}_w J(w)$ but not the generalization capability. 
\vspace{-0.1cm}
Shown in Fig.~\ref{fig: curse of dimensionality}(a), G-MFO requires a $M>=128$ to achieve a training accuracy of $>90\%$ given $H=128^2$. 
Moreover, in Fig.~\ref{fig: curse of dimensionality}(b), our G-MFO method fails when increasing $H$ beyond $128^2$ while keeping the sampling size $M$ fixed to $128$. 


\subsection{Application: all-optical classification on marker-free cellular dataset.}\label{subsec: classify WBC.}

For the first time, we demonstrate the capability of an optical computing system for marker-free cell analysis, trained by our G-MFO algorithm (Fig.~\ref{fig: all-optical cell classfier}). We work on the white blood cells (WBC), whose abnormal subtype percentages indicate the immune systems malfunction or infectious disease \cite{wbcfunction1, wbcfunction2}. We include details of the WBC phase map dataset in Supplement Sec. S.2. Previously, researchers used machine learning methods to classify WBC subtypes, including monocyte, granulocyte, B cell, and T cell, by their morphology in a marker-free way~\cite{wbcbrightfield2019Nassae,wbcphase2021shu}. However, the analysis process is computationally heavy and time-consuming. 

Here, we accelerate the marker-free cell analysis process via computing with light. Our G-MFO method strikes a training/validation/testing classification accuracy of $72.1\%/73.3\%/73.8\%$ when classifying $4$ types of WBC using a one-layer optical computing system, exceeding that of the HBT method (Fig.~\ref{fig: all-optical cell classfier}c). Furthermore, Fig.~\ref{fig: all-optical cell classfier}d shows that the inference enabled by optical computing is almost instantaneous ($\frac{d_{IO}+d_{OC}}{c}=1.4 \: ns$, where $c$ is the speed of light), compared to the $1.7\: ms$ of ResNet10, the electronic machine learning model used in \cite{wbcphase2021shu}. We need $1$ more milliseconds of in silico computing of region intensities corresponding to different classes to obtain the prediction. Such a step can be skipped if we use single-photon avalanche diode (SPAD)~\cite{bruschini2019single} point detectors to count the corresponding regions' cumulative signals. Though for now, the performance of our single-layer linear optical computing system is not on par with the electronic neural network, which hits a testing classification accuracy of $90.5\%$ \cite{wbcphase2021shu}, the potential of having ultra-high inference speed and $>70\%$ classification accuracy here point out an exciting direction on further increasing the complexity of our optical computing system to improve the absolute classification accuracy on classifying cells.  
% \gy{@sx: still needs comparison of inference time and also include the comparison table (against HBT )in the supplement.}\gy{and also mention here.}
% \gy{shuxin, also add quantitative results for the test-time overhead compared to the deep learning-based work.} \sx{will finish on May 17} 
% Fig.~\ref{fig: all-optical cell classfier} further shows the classification results of the optical computing system using the G-MFO method for the WBC dataset.   
% Figure \ref{fig:false-color} shows an example figure. 




\section{Discussion}

\subsection{Future directions.}

\subsubsection{Further apply G-MFO to more complex optical computing systems.}
Exploring the scalability of the optical computing system to more complex optical structures, along with integrating more layers and non-linear activation functions, could potentially enhance absolute performance. 

\subsubsection{Further improve the performance of G-MFO.}
Future research could also consider employing more advanced techniques related to Monte Carlo integration to reduce the training variance discussed in the previous Subsec.~\ref{subsec: G-MFO exhibits curse of dimensionality.}, which we anticipate could substantially broaden the viable search space, thus further empowering the G-MFO approach. These include using more advanced sampling strategies~\cite{caflisch1998monte} or integrating G-MFO with the SBT methods~\cite{kurenkov2021guiding} or adding critic function~\cite{konda1999actor}. The latter two methods trade off the introduced bias and sampling variance.



\subsubsection{Expanding the application of G-MFO to additional computational optics tasks.}
The concept of G-MFO presents promising avenues for application in other areas of computational optics, such as computer-generated holography~\cite{zhao2022model} and lens design~\cite{sitzmann2018end}. The inherent model-free and resource-efficient characteristics of G-MFO position it as a viable alternative to prevalent model-based methods~\cite{blinder2022state, sitzmann2018end}. Future research could focus on leveraging G-MFO to these domains, potentially enhancing computational efficiency and performance.

% \rz{Including assistive network can further improve the performance.}

\subsection{Conclusion}
To conclude, our study underscores the effectiveness of a model-free strategy in training optical computing systems in situ, manifesting considerable potential in computational efficiency and reducing the simulation-to-reality performance gap. Although the study does not focus entirely on absolute image classification accuracy as it is based on a simple  single or double diffractive optical computing system without non-linearity, it shows relative improvements compared to the existing training strategies, indicating that our strategy is a potentially valuable approach. The model-agnostic nature of our technique may become even more beneficial when implemented in intricate optical systems, representing a robust and versatile alternative to current strategies. It promises a strong foundation for exploring and practically implementing optical computing in real-world applications such as high-speed marker-free cell analysis. 

\ifpeerreview
\section*{Funding} 
Hong Kong General Research Fund (14209521); Hong Kong Innovation and Technology Fund (ITS/178/20FP \& ITS/148/20); Croucher Foundation (CM/CT/CF/CIA/0688/19ay).


\section*{Acknowledgments} 
We thank \href{https://zcshinee.github.io/}{Cheng Zheng} for the discussions in the early stages of the work.

\noindent\textbf{Author Contributions.} G.Z. conceived the project, derived the formulation, and built the backbone code and system. X.S. helped with the code writing and system setup and collected the simulation and experiment results. 
% G.Z. and X.S. wrote the manuscript.
R.Z. supervised the project. G.Z. and X.S. wrote the manuscript with comments and edits from R.Z..

% \section*{Data availability} 
% % The MNIST data used in this study are available in the MNIST dataset [http://yann.lecun.com/exdb/mnist/]. 
% Raw data underlying the results presented in this paper are not publicly available but can be obtained from the authors upon request.

% \section*{Code availability} 
% % The MNIST data used in this study are available in the MNIST dataset [http://yann.lecun.com/exdb/mnist/]. 
% The code regarding this research will be released upon publication.



% \section*{Disclosures} 
% The authors declare no conflicts of interest.
% Disclosures should be listed in a separate section at the end of the manuscript. List the Disclosures codes identified on the \href{https://opg.optica.org/submit/review/conflicts-interest-policy.cfm}{Conflict of Interest policy page}. If there are no disclosures, then list ``The authors declare no conflicts of interest.''

\smallskip


\section*{Supplemental document}
See Supplement for supporting content. 

\bibliographystyle{IEEEtran}
\bibliography{iccp24_template}

\fi


