










\section*{Supplementary}
\renewcommand{\thefigure}{S.\arabic{figure}}
\setcounter{figure}{0}
\renewcommand{\thetable}{S.\arabic{table}}
\setcounter{section}{0}
\renewcommand{\thesection}{S.\arabic{section}}
\setcounter{subsection}{0}
\renewcommand{\thesubsection}{S.\arabic{subsection}}
\setcounter{table}{0}
\setcounter{equation}{0}
\setcounter{algorithm}{0}
\renewcommand{\theequation}{S.\arabic{equation}}
\renewcommand{\thealgorithm}{S.\arabic{algorithm}}

\vspace{0.3cm}
\vspace{0.5cm}
\section{Reproducibility of the hardware system} \label{subsec: Reproducibility}
\subsection{Hardware details of the optical computing system.}


% Figure environment removed


% Figure environment removed


Fig.~\ref{fig:real_system} shows our home-built optical computing systems. Table.~\ref{tab:device_type} lists models of critical components used in our home-built optical computing systems. Table.~\ref{tab:device_param} further provides dimensions and frame rates of programmable optical devices (i.e., SLM1, SLM2 and DMD) and cameras involved in this work. The definition of the modulation area is shown in Fig.~\ref{fig:effective_shape}.

\subsection{Experimental setups of the real single-layer and two-layer optical computing systems $f_{sys-1-layer}$ and $f_{sys-2-layer}$. }~\label{} 

\textbf{Single-layer optical computing system:} A laser field $u_{laser}$ propagates onto the input layer (SLM1), where the phase-valued object $u_{obj}$ is displayed. The light field reflects from the input layer onto the optical computing layer $u_w$ (SLM2). A camera then detects the diffraction light at the output layer. The length $d_{IC}$ and $d_{CO}$ for $Prop_{IC}$ and $Prop_{CO}$ in Fig.~\ref{fig: system skectch}(a) are $215.1 mm$ and $201.6 mm$, respectively. As there are multiple components in the system (e.g., SLMs and cameras), it is difficult to manually align them with high accuracy. We developed a digital alignment method based on the homography technique~\cite{riba2020kornia} using SLMs to compensate for the alignment errors when we implement the baseline method HBT on the real single-layer optical computing system; otherwise, the performance will be pretty poor.
Details of our digital alignment method are in Supplement Sec.~\ref{subsec: calibration}.  

\textbf{Double-layer optical computing system:} A DMD displays the binary intensity object $u_{obj}$ on the input layer. The light field is then reflected from the input layer onto the optical computing layer1 $u_{w1}$ (SLM1) and subsequently to the optical computing layer2 $u_{w2}$ (SLM2). Following this, a camera captures the modulated light at the output layer. The length $d_{C_1C_2}$ and $d_{C_2O}$ for $Prop_{C_1C_2}$ and $Prop_{C_2O}$ in Fig.~\ref{fig: system skectch}(b) are $215.1 mm$ and $201.6 mm$, respectively. More details of the optical computing system are in Supplement Sec. S.1. 


\subsection{Differentiable physics-based simulators $\hat{f}_{sys-1-layer}$ and $\hat{f}_{sys-2-layer}$.}\label{subsec: simulators} 

We construct an ideal physics-based simulator $\hat{f}_{sys}$ corresponding to the aforementioned optical computing system $f_{sys}$ as the sandbox to test different training algorithms. This simulator is also used inside the design loop of SBT and HBT, which serve as the baseline methods to compare. 


Since our system only includes free-space wave propagation $\textcolor{red}{\hat{f}_{prop}}$, wavefront modulation $\textcolor{Colorfmod}{\hat{f}_{mod}}$, and sensor detection $\textcolor{Colorfdet}{\hat{f}_{det}}$, we build the optical computing simulator by stacking these three optical modules as building blocks.
The functions of optical modules are:
\begin{subequations} \label{eq: diff modules of system}
   \begin{align}
        &\textcolor{red}{\hat{f}_{prop}}(u_{in},z): u_{out} = \mathcal{F}^{-1} (\mathcal F(u_{in}) \times \mathcal F(h_{prop}(z))), \label{eq: free-space prop} \\
        &\textcolor{Colorfmod}{\hat{f}_{mod}}(u_{in}, u_{element}): u_{out} = u_{in} \times u_{element},\\
        &\textcolor{Colorfdet}{\hat{f}_{det}}(u_{in}):I_{out} = |u_{in}|^2, \label{eq: camera detection.}
    \end{align}
\vspace{0.2cm}
\end{subequations}
where $h_{prop}(z) = \frac {e^{jkz}}{j\lambda z}e^{\frac{jk}{2z}(x^2+y^2)}$ is the propagation kernel under Fresnel approximation~\cite{born2013principles} with a propagation distance $z$, wavelength $\lambda$ and angular wave number $k$, $u_{element}$ denotes the wavefront modulation from the programmable optical devices, $\mathcal{F}$ denotes the Fourier transform. 

\textit{Simulator of a single-layer optical computing system.} Based on the modules in Eq.~\ref{eq: diff modules of system}, the simulator of a single-layer $\hat{f}_{sys-1-layer} = \{\textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfdet}{\hat{f}_{det}}\}$ 
is constructed by chaining the building blocks ${1-5}$:
\begin{subequations}\label{eq: simuator}
    \begin{align}
        & 1. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{laser}, u_{obj}), \\
        & 2. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{IC}), \\
        & 3. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{out}, u_{w}), \\
        & 4. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{CO}), \\
        & 5. I_{cam} = \textcolor{Colorfdet}{\hat{f}_{det}}(u_{out}).
    \end{align} 
\end{subequations}

\textit{Simulator of a double-layer optical computing system} is constructed similarly by stacking layers as $\hat{f}_{sys-2-layer} = \{\textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfmod}{\hat{f}_{mod}}, \textcolor{red}{\hat{f}_{prop}}, \textcolor{Colorfdet}{\hat{f}_{det}}\}$:
\begin{subequations}\label{eq: simuator}
    \begin{align}
        & 1. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{laser}, u_{obj}), \\
        & 2. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{IC_1}), \\
        & 3. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{out}, u_{w1}), \\
        & 4. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{C_1C_2}), \\
        & 5. u_{out} = \textcolor{Colorfmod}{\hat{f}_{mod}}(u_{out}, u_{w2}), \\
        & 6. u_{out} = \textcolor{red}{\hat{f}_{prop}}(u_{out}, d_{C_2O}), \\   
        & 7. I_{cam} = \textcolor{Colorfdet}{\hat{f}_{det}}(u_{out}).
    \end{align} 
\end{subequations}



\vspace{0.3cm}
\subsection{Parameters of the optical computing system}
We obtain the classification prediction of the optical computing system by comparing the intensities of different regions in the output layer~\cite{reconfigurable_onn, lin2018all}, as illustrated in Fig.~\ref{fig:apply mask}. 

\begin{table}[h!]
\centering
\begin{threeparttable}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\arrayrulecolor{black}
\renewcommand{\arraystretch}{1.0}
\begin{tabular}{P{0.22\linewidth} P{0.3\linewidth} P{0.28\linewidth}}
\hline
\textbf{Device} & \textbf{Part number} & \textbf{Manufacturer}\\
\hline
\rowcolor{gray!10}  SLM1        & PLUTO                & Holoeye\\
\rowcolor{white!10} SLM2        & GAEA                 & Holoeye\\
\rowcolor{gray!10}  DMD         & DLPLCR9000EVM       & TI\\
\rowcolor{white!10} Camera          & BFS-U3-13Y3C-C       & Teledyne FLIR\\
\rowcolor{gray!10}  BS              & HBS11-025-50-VIS     & Hengyang Optics\\
\rowcolor{white!10} Polarizer       & CCM5-PBS201/M        & Thorlabs\\
\hline
\end{tabular}
\caption{\textbf{Models of key components used in our optical computing system.}}
\label{tab:device_type}
\end{threeparttable}
\end{table}


\begin{table}[h!]
\centering
\begin{threeparttable}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\arrayrulecolor{black}
\renewcommand{\arraystretch}{1.0}
\begin{tabular} {P{0.12\linewidth} P{0.05\linewidth} P{0.19\linewidth} P{0.19\linewidth} P{0.15\linewidth}}
\hline
\textbf{Device} & \textbf{Pitch size ($\mu m$)} & \textbf{Full shape (pixels)} & \textbf{Modulation area shape (pixels)} & \textbf{Refreshing rate (FPS)} \\ \hline
\rowcolor{gray!10}  SLM1  & $8$       & $1080\times1920$     & $512\times512$      & $25$\tnote{*}\\
\rowcolor{white!10} SLM2   & $3.74$    & $2160\times3840$     & $1248\times1248$    & $30$\tnote{*}\\
\rowcolor{gray!10}  DMD        & $7.6$     & $1600\times2560$     & $512\times512$      & $125$\tnote{**}\\
\rowcolor{white!10} Camera     & $8$       & $1024\times1280$     & $512\times512$      & Max: $170$\\
\hline
\end{tabular}
\begin{tablenotes}
\item[*] We experimentally get 25 or 30 FPS in our self-written Python programs.
\item[**] The refresh rate of the DMD is limited by the camera's exposure time which is 4000 µs.
\end{tablenotes}
\caption{\textbf{Dimensions and frame rates of our experiments' programmable optical devices and cameras.}}
\label{tab:device_param}
\end{threeparttable}
\end{table}

% Figure environment removed
% Figure environment removed


\section{WBC dataset details}\label{sec: dataset}
The WBC phase image dataset \cite{wbcphase2021shu} has four classes of cells: granulocyte, monocyte, B cell, and T cell. Table~\ref{tab: WBC dataset} gives the number of cells in each class. 

\begin{table}[h!]
\centering
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\arrayrulecolor{black}
\renewcommand{\arraystretch}{1.0}
\begin{tabular} {P{0.3\linewidth} P{0.15\linewidth} P{0.15\linewidth} P{0.15\linewidth}}
\hline
                & \textbf{Training  set} & \textbf{Validation set} &\textbf{Testing set}\\ \hline
\rowcolor{gray!10}  Granulocyte     & $465$      & $100$           & $100$\\
\rowcolor{white!10} Monocyte        & $513$      & $100$           & $100$\\
\rowcolor{gray!10}  B cell          & $437$      & $100$           & $100$\\
\rowcolor{white!10} T cell          & $330$      & $100$           & $100$\\
\rowcolor{gray!10}  Total           & $1745$     & $400$           & $400$\\
\hline
\end{tabular}
\caption{\textbf{Number of cells of each class in the WBC dataset.}}
\label{tab: WBC dataset}
\end{table}


\section{Training details} \label{subsec: training process}

\subsection{Computing resources.}
We evaluate our method in both simulation and experiments. The simulation runs on a high-end Linux server, while physical experiments are conducted on a Windows desktop. 
Table~\ref{tab:computer_configuration} shows the Windows desktop and Linux server configurations. 



\begin{table}[h!]
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\arrayrulecolor{black}
\centering
\renewcommand{\arraystretch}{1.0}
\begin{tabular}{P{0.3\linewidth} P{0.29\linewidth} P{0.27\linewidth}}
\hline
\toprule
                                     & \textbf{Server (Simulation)}                     & \textbf{Desktop (Experiments)}\\ \hline
\rowcolor{gray!10} CPU               & Intel Xeon Silver 4210R [$\times$2] & Intel Core i7-7700\\
\rowcolor{white!10}GPU               & Nvidia A6000 [$\times$2]            & Nvidia TITAN XP\\ 
\rowcolor{gray!10}GPU memory         & $48GB$ [$\times$2]                    & $12GB$\\ 
\rowcolor{white!10}RAM               & $192GB$                               & $32GB$\\ 
\rowcolor{gray!10}Operating system   & Ubuntu 18.04                        & Windows 10\\ 
\rowcolor{white!10}Graphic interface & No                                  & Yes\\
\bottomrule
\end{tabular}
\caption{\textbf{Configurations of our server and desktop.}}
\label{tab:computer_configuration}
\end{table}
\subsection{Training parameters and time of simulations and experiments.}

The training parameters and time of simulations and experiments are shown in Table.~\ref{tab: simulation and experiment parameters}. Unless otherwise noted, we early stop the training process when the validation loss does not decrease for 10 epochs in both simulations and real system experiments. We choose the checkpoint with the lowest validation loss and use it to evaluate the test set. 

In Sec. 4.1.1 of the main text, the number of training epochs for G-MFO is set to $500$ epochs, and the number of training epochs for the two-point optimization method is set to $6400$ epochs. In contrast, the number of training epochs for the full-point optimization method is limited to $100$ due to its much longer training time per epoch. Despite these differences, all three experiments converge well by the end of training. We take the training/validation/testing accuracy in the checkpoint with the lowest training loss as the result.

Due to the extensive time required for G-MFO simulations and experiments involving 10,000 training data on the two-layer optical computing system in Sec. 4.1.4, we stop these training processes at the $10th$ epoch and $9th$ epoch, respectively.

In Sec. 4.3 of the main text, we assess the G-MFO method's potential for overfitting using a single-layer optical computing system simulator. Thus, we stop the training process at the 200th epoch or after 50 epochs of no decrease in the training loss. We take the training accuracy in the checkpoint with the lowest training loss as the result for each simulation in Sec. 4.3. 



\begin{table}[h!]
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\begin{threeparttable}
\arrayrulecolor{black}
\centering
\renewcommand{\arraystretch}{1.0}
\begin{tabular} {P{0.1\linewidth} P{0.08\linewidth} P{0.05\linewidth} P{0.05\linewidth} P{0.05\linewidth} P{0.05\linewidth} P{0.1\linewidth} P{0.1\linewidth} P{0.08\linewidth} P{0.1\linewidth}}
\hline
    & Number of trainable parameters & Sampling size & Batch size  & Optimizer & Learning rate & \textit{In silico} computation time\tnote{*} & Device waiting time for getting $f_{sys}(x,w)$\tnote{*} & Total training time\tnote{*} & Stop criteria \\ \hline
\rowcolor{gray!10} \multicolumn{10}{c}{MNIST and FMNIST simulations on the two-layer optical computing system $\hat{f}_{sys-2-layer}$}\\
\rowcolor{gray!10} \multicolumn{10}{c}{(\textit{$10,000$ data points each for training, validation and testing).}}\\
Ideal & $128^2$ & None  & $32$ & SGD & $10$ & $1m47s$ & None & $1m47s$ & ES-Val-10\\
HBT   & $128^2$ & None  & $32$ & SGD & $10$ & $2m25s$  & None & $2m25s$ & ES-Val-10\\
G-MFO   & $128^2$ & $128$ & $32$ & SGD & $20$ & $6h2m25s$ & None & $6h2m25s$ & $10th$ epoch\\
\rowcolor{gray!10} \multicolumn{10}{c}{MNIST and FMNIST experiments on the two-layer optical computing system $f_{sys-2-layer}$}\\
\rowcolor{gray!10} \multicolumn{10}{c}{(\textit{$10,000$ data points each for training, validation and testing).}}\\
G-MFO   & $128^2$ & $128$  & $32$ & SGD & $20$ & $24m53s$ & $5h38m20s$ & $6h3m13s$ & $9th$ epoch\\
\rowcolor{gray!10} \multicolumn{10}{c}{MNIST and FMNIST simulations on the single-layer optical computing system $\hat{f}_{sys-1-layer}$}\\
\rowcolor{gray!10} \multicolumn{10}{c}{(\textit{$1,000$ data points each for training, validation and testing).}}\\
Ideal \& SBT & $128^2$ & None & $32$ & Adam & $0.01$ & $17s$ & None & $17s$ & ES-Val-10\\
G-MFO          & $128^2$ & $128$& $32$ & SGD  & $15$ & $11m58s$ & None & $11m58s$ & ES-Train-50 or $200th$ epoch\\
\rowcolor{gray!10} \multicolumn{10}{c}{FMNIST simulations on the single-layer optical computing system $\hat{f}_{sys-1-layer}$}\\
\rowcolor{gray!10} \multicolumn{10}{c}{(\textit{$100$ data points each for training, validation and testing).}}\\
Two-point & $128^2$ & 2 & $32$ & SGD & $2$ & $9s$ & None & $9s$ & $6400th$ epoch\\
Full-point & $128^2$ & $128^2$ & $32$ & SGD & $20$ & $1h53m$ & None & $1h53m$ & $100th$ epoch\\
G-MFO      & $128^2$ & $128$& $32$ & SGD  & $20$ & $2m$ & None & $2m$ & $500th$ epoch\\
\rowcolor{gray!10} \multicolumn{10}{c}{MNIST and FMNIST experiments on the single-layer optical computing system $f_{sys-1-layer}$}\\
\rowcolor{gray!10} \multicolumn{10}{c}{(\textit{$1,000$ data points each for training, validation and testing).}}\\
HBT   & $128^2$ & None  & $4$ & Adam & $0.01$ & $2m16s$ & $2m18s$ & $4m34s$ & ES-Val-10\\
G-MFO   & $128^2$ & $128$ & $32$ & SGD & $100$ & $6s$ & $1h56m1s$ & $1h56m7s$ & ES-Val-10\\
HBT+G-MFO   & $128^2$ & $128$ & $32$ & SGD & $10$ & $6s$ & $1h56m1s$ & $1h56m7s$ & ES-Val-10\\
\rowcolor{gray!10} \multicolumn{10}{c}{WBC experiments on the single-layer optical computing system $f_{sys-1-layer}$}\\
HBT   & $128^2$ & None  & $4$ & Adam & $0.005$ & $4m4s$ & $2m6s$ & $6m15s$ & ES-Val-10\\
G-MFO   & $128^2$ & $64$ & $32$ & SGD & $50$ & $1m11s$ & $1h42m17s$ & $1h43m28s$ & ES-Val-10\\
\hline
\end{tabular}
\begin{tablenotes}
\item[*] Time per epoch.
\end{tablenotes}
\caption{\textbf{Training parameters and time for experiments and simulations.} ES-Val-10 denotes stopping training after 10 epochs without a decrease in validation loss, while ES-Train-50 denotes stopping training following 50 epochs of no decrease in training loss.}
\label{tab: simulation and experiment parameters}
\end{threeparttable}
\end{table}




\subsection{Training process for experiments.}

The training process for G-MFO and HBT experiments consists of getting optical computing system output $f_{sys}(x,w)$. Experiment workflow.~\ref{workflow: HBT} shows how to get $\{f_{sys}(x_i, w)\}_{i=1}^B$ in the HBT experiment. 
In the G-MFO experiment, we use different experiment workflows to get $\{f_{sys}(x_i, w_j)\}_{i=1, j=1}^{B, M}$ depending on the specific devices used as input and optical computing layers. In experiments on the single-layer optical computing system ($responsetime_I>responsetime_O$), we use Experiment workflow~\ref{workflow: MFO mask} for the sake of a shorter waiting time. In experiments on the two-layer optical computing system  ($responsetime_I<responsetime_O$), we use Experiment workflow~\ref{workflow: MFO input}. $B$ is the batch size, $M$ is the sampling size, $responsetime_I$ is the input layer device response time and $responsetime_O$ is the optical computing layer device response time. 



\begin{algorithm}[h!]
\floatname{algorithm}{Experiment workflow}
\caption{Acquiring $\{f_{sys}(x_i, w)\}_{i=1}^B$ in HBT experiment.}\label{workflow: HBT}
\begin{algorithmic}[1]
\State \textbf{Input: }  {A batch of classification dataset $\mathcal{D}_b=\{x_i, y_i\}_{i=1}^B$ with batch size $B$, optical computing weight $w$, optical computing system $f_{sys}$, input layer device response time $responsetime_I$, optical computing layer device response time $responsetime_O$.}
\State \textbf{Output: }{Optical computing system output $\{f_{sys}(x_i, w)\}_{i=1}^B$. 
}
\State{Refresh $w$ on the optical computing layer.}
\State{Wait $responsetime_O$.}  
\For{$i$ in range $B$}
    \State{Display $x_i$ on input layer.}
    \State{Wait $responsetime_I$.}
    \State{Capture $f_{sys}(x_i, w)$ with camera.}
\EndFor
\State{\textbf{Total waiting time}: $responsetime_O + B \times responsetime_I$.}
\end{algorithmic}
\vspace{-0.1cm}
\end{algorithm}


\begin{algorithm}[h!]
\floatname{algorithm}{Experiment workflow}
\caption{Acquiring $\{f_{sys}(x_i, w_j)\}_{i=1, j=1}^{B, M}$ in G-MFO experiment when optical computing layer device has a short response time.}\label{workflow: MFO mask}
\begin{algorithmic}[1]
\State \textbf{Input:} {A batch of classification dataset $\mathcal{D}_b=\{x_i, y_i\}_{i=1}^B$ with batch size $B$, a group of sampled optical computing weights $\{w_j\}_{j=1}^M$, optical computing system $f_{sys}$, input layer device response time $responsetime_I$, optical computing layer device response time $responsetime_O$.}
\State \textbf{Output:} {Optical computing system output $\{f_{sys}(x_i, w_j)\}_{i=1, j=1}^{B, M}$.}
\For{$i$ in range $B$}
    \State{Display $x_i$ on input layer.}
    \State{Wait $responsetime_I$.}
    \For{$j$ in range $M$}
        \State{Refresh $w_j$ on the optical computing layer.}
        \State{Wait $responsetime_O$.}        
        \State{Capture $f_{sys}(x_i, w_j)$ with camera.}
    \EndFor
\EndFor
\State{\textbf{Total waiting time}: $B \times M \times responsetime_O + B \times responsetime_I$}
\end{algorithmic}
\vspace{-0.1cm}
\end{algorithm}


\begin{algorithm}[!h]
\floatname{algorithm}{Experiment workflow}
\caption{Acquiring $\{f_{sys}(x_i, w_j)\}_{i=1, j=1}^{B, M}$ in G-MFO experiment when input layer device has a short response time.} \label{workflow: MFO input}
\begin{algorithmic}[1]
\State \textbf{Input: }  {A batch of classification dataset $\mathcal{D}_b=\{x_i, y_i\}_{i=1}^B$ with batch size $B$, a group of sampled optical computing weights $\{w_j\}_{j=1}^M$, optical computing system $f_{sys}$, input layer device response time $responsetime_I$, optical computing layer device response time $responsetime_O$.}
\State \textbf{Output: }{Optical computing system output $\{f_{sys}(x_i, w_j)\}_{i=1, j=1}^{B, M}$.}
\For{$j$ in range $M$}
    \State{Refresh $w_j$ on the optical computing layer}
    \State{Wait $responsetime_O$}
    \For{$i$ in range $B$}
        \State{Display $x_i$ on input layer}
        \State{Wait $responsetime_I$}        
        \State{Capture $f_{sys}(x_i, w_j)$ with camera}
    \EndFor
\EndFor
\State{\textbf{Total waiting time}: $M \times responsetime_O + B \times M \times responsetime_I$}
\end{algorithmic}
\vspace{-0.1cm}
\end{algorithm}











\section{Compare the overall training time of G-MFO and HBT}~\label{subsec: time bottleneck from refreshing time}
The maximum frame rate for the phase-SLM is approximately 30 FPS, while the DMD can reach approximately 125 FPS which is limited by the camera's exposure time (refer to Table~\ref{tab:device_param}). These low refresh rates more adversely affects the training duration of the G-MFO compared to the HBT, with the impact scaling in relation to the G-MFO's sampling size (refer to the device waiting time for computing $f_{sys}(x,w)$ in Table~\ref{tab: simulation and experiment parameters}).
This time bottleneck can be alleviated when substituting the conventional phase-SLM with the fast ones, such as the Heavily-quantized Spatial Light Modulators~\cite{choi2022time} or enhance the light intensity to reduce the camera's exposure time, thereby increasing the DMD frame rate. 













\section{Calibration of the system} \label{subsec: calibration}
The calibration of the optical computing system is critical for reproducing baseline methods that rely on the simulator $\hat{f}_{sys}$ as tiny misalignment between multiple planes will hugely degrade the performance, as we have shown in Fig. 2 in the main text. 
Our digital alignment for a single-layer optical computing system consists of estimating $2$ sets of parameters: lengths $\{d_{IO}, d_{CO}\}$ and homography transformations $\{H_{IO}, H_{CO}\}$. 
Specifically, $H_{IO}$ is the projective transformation between the input layer and output layer, $d_{IO}$ is the corresponding distance, $H_{CO}$ is the projective transformation between the optical computing layer and output layer, and $d_{CO}$ is the corresponding distance. 



\subsection{Calibrate propagation distance z using holography.}
We first use free-space holography~\cite{blinder2022state} to calibrate the distance $d$ between planes. We concatenate the building blocks Eq.~\ref{eq: free-space prop} and ~\ref{eq: camera detection.} and construct a free-space holography simulator $\hat{f}_{holo}=\{\hat{f}_{prop}, \hat{f}_{det}\}$. 
The input to the holography simulator is $u_{in}=e^{j\phi_{holo}}$ and $z=d$, where $\phi_{holo}$ is the pre-calculated phase that generates the hologram, while $d$ is the distance to optimize. 
Calculation of $\phi_{holo}$ is achieved by extracting the phase of Fourier transform of the target obj $I_{target}$:
\begin{equation}
    \phi_{holo} = \text{angle}(\mathcal{F}(\sqrt{I_{target}}))
\end{equation}
Then we upload the $\phi_{holo}$ onto the real SLM with the Holoeye SLM Pattern Generator software, add various defocus phase masks corresponding to various $d$, visually compare the quality of the output hologram and select the best fit $d$ as the calibrated distance.  

\subsection{Homography estimation among multiple planes.}
Homography is a linear transformation between corresponding points in
two images with an $8$ degree of freedom~\cite{riba2020kornia}. It is solved by minimizing dense photometric loss or by feature matching. 
Our experiment has two SLMs and a camera (Fig.~\ref{fig: system skectch}(a)). Since directly calibrating $H_{IC}$, the transformation between the two SLMs, is infeasible as we cannot put the camera on any plane of these two SLMs; we calibrate their transformations to the output plane (the camera plane), respectively. Take the estimation  of photometric-based homography between the input layer and the output layer as an example. The objective function is:
\begin{equation}
    H_{IO}^{\star} =  \operatorname*{arg\,min}_{H_{IO}} \mathcal{L}_{homo}(\sqrt{I_{target}}-warp(|\hat{f}_{prop}(u_{in}, d_{IO})|),
\end{equation}
where $warp$ is the homography warpper given the homography estimation $H_{IO}$. We solve this objective function with auto-differentiation~\cite{riba2020kornia}. 














\subsection{Rebuild the simulator with homography estimation in the loop.} 
In the previous subsection, we discuss estimating the homography transformation between planes in the real system.

To incorporate the calibrated homography matrices into our system simulator $\hat{f}_{sys}$, we rebuild the simulator with three virtual propagators instead of two. The latter is discussed in Subsec. S1.3 and depicted in Fig~\ref{fig: three_virtual_prop}(a). We use a 3-layer simulator because the homography wrapper $warp$ and the wave propagator $\hat{f}_{prop}$ are not commutative. In other words:
\begin{equation}
    warp(\hat{f}_{prop}(u_{in}, d_{IO}), H_{IO}) \neq \hat{f}_{prop}(warp(u_{in}, H_{IO}), d_{IO}). 
\end{equation}

A sketch of the rebuilt simulator is in Fig.~\ref{fig: three_virtual_prop}(b). We introduce a virtual output plane $O_{virtual}$ into the simulator so that we can incorporate the homography estimations $H_{IO}$ and $H_{CO}$ into the simulation loop. Since the homography matrix is estimated at the output planes of the optical propagator, the settings in Fig.~\ref{fig: three_virtual_prop}(b) enable the use of homography matrix at the output planes of the propagator, which cannot be done via using the original simulator in Fig.~\ref{fig: three_virtual_prop}(a). 

% Figure environment removed



\section{Baseline method -- Hybrid training.} \label{subsec: baseline}

We include the hybrid training (HBT)/physics-aware training as one of the baseline methods to compare~\cite{spall2022hybrid, wright2022deep}.
The philosophy of hybrid training is simple: when updating the optical computing system, we use the real system to do the forward pass to get the value of the objective function $J(w)$:
\begin{equation}
    J(w) = \frac{1}{N}\sum_{i=1}^{N}\mathcal{L}(f_{sys}(x_i; w), y_i).
\end{equation}

In the backward update pass, we substitute the $f_{sys}$ with its differentiable simulator $\hat{f}_{sys}$ and update the weights $w$ via:
\begin{equation}
    w =  w + \alpha \frac{\partial J(w)}{\partial \hat{f}_{sys}} \frac{\partial \hat{f}_{sys}}{w}.
\end{equation}

This trick enables the backward pass in the biased while differentiable simulator $\hat{f}_{sys}$. The critical difference between the hybrid training (HBT) method and the simulator-based training (SBT) is that the former does the forward pass in the real system ${f}_{sys}$ while the latter conducts both passes in the simulator ${\hat{f}}_{sys}$.

We visualize some experimental outputs and confusion matrices using HBT on a single-layer optical computing system in Fig.~\ref{fig: HBT result}.

% Figure environment removed


\rev{\section{Comparision between G-MFO and L-MBO.}}

\rev{In related work, Sec. 2.1, we discuss the \textit{hardware-in-the-loop} or \textit{real2sim}-style algorithm L-MBO. In this section, we compare L-MBO and our method in terms of performance.} 








\rev{\subsection{Compare G-MFO with our implementation of L-MBO.}}

\rev{We implement an L-MBO method and compare it with G-MFO on a single-layer optical computing simulator $\hat{f}_{sys-1-layer}$ using the MNIST dataset. We use $1,000$ data to train, $1,000$ data to validate, and $1,000$ data to test.
Our implementation of L–MBO on the simulator consists of:} 

\begin{itemize}
    \item Feeding the task dataset into the simulator to get an exploration dataset for training the system;
    \item Pre-training a physics-based learned proxy of a misaligned system through supervised learning;
    \item Optimizing the task performance based on the pre-trained proxy;
    \item Testing the optimized optical weights in the simulator to get train/validation/testing accuracy.
\end{itemize}

\rev{Specifically, as for the physics-based learned proxy, the model is constructed by chaining a UNet ~\cite{ronneberger2015u} with a physics-based simulator of a misalignment system. We do not use pure network-based proxy as the overfitting is evident without physics prior.}

\rev{We present the simulation results in Table~S.6.  In our L-MBO implementation, the L-MBO under-performs our method; G-MFO’s train accuracy is $90.4\%$ while the L-MBO’s is $80.2\%$. We attribute this to multiple reasons, such as not including alternating training during the task optimization process~\cite{zheng2023dual}, the proxy’s hyper-parameters not being well-tuned, etc.}



\begin{table}[h!]
\newcolumntype {C}[1]{>{\centering\arraybackslash}m{#1}}
\arrayrulecolor{black}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{C{0.16\linewidth} | C{0.08\linewidth} | C{0.08\linewidth}| C{0.08\linewidth}}
\hline
             &\multicolumn{3}{c}{Accuracy}    \\\hline
             & Train             & Val                 & Test \\\hline\hline
L-MBO        & $80.2\%$          & $69.8\%$            & $65.2\%$ \\\hline
G-MFO (Ours) & $90.4\%$          & $83.5\%$            & $81.5\%$\\\hline
\end{tabular}
\caption{\rev{\textbf{Numerical comparison of G-MFO and L-MBO (our implementation) on the MNIST dataset using a simulated single-layer diffractive optical computing system. 
} }}
\label{tab: l-mbo comparison result}
\end{table}

\rev{\subsection{Compare G-MFO with a reported L-MBO result.}}

\rev{Note that in an experimental realization of a 2-layer linear diffractive optical computing system, L-MBO's\cite{zheng2023dual} reported testing accuracy ($87.5\%$) is better than ours ($80.3\%$), but their code for the diffractive optical computing system has not been open-sourced yet.} 

Moreover, as highlighted in Table 1, our method has advantages: 
\begin{itemize}
    \item Ours is memory- and computation-efficient.
    \item  Ours does not require collecting high-fidelity images of input objects, which are costly to acquire in terms of instruments, time, and electronic storage.
\end{itemize}

\rev{We anticipate further investigation and integration of these two methods would be an interesting research.}