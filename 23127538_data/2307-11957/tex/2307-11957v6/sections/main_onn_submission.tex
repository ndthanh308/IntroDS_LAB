
\IEEEraisesectionheading{\section{Introduction}}

\IEEEPARstart{O}{ptical} computing leverages the properties of light waves to facilitate high-speed data processing while reducing the energy cost~\cite{marechal1953filtre, cutrona1960optical,o1956spatial, ambs2010optical, wetzstein2020inference, lugt1964signal, zhou2019optical}. Recent advances in automatic differentiation have enabled in silico training of large-scale optical computing weights, giving rise to the realizations of diffractive neural networks~\cite{chang2018hybrid, lin2018all}, optical reservoir computing~\cite{rafayelyan2020large, verstraeten2007experimental}, and coherent nanophotonic circuits~\cite{shen2017deep}. 


\textit{Problem Statement.} Training optical computing systems presents two challenges: an intensive computational process and a performance disparity between simulation and reality when implementing pre-trained weights onto real-world systems~\cite{buckley2023photonic, lin2018all, rumelhart1986learning}.
Typically, the optical computing systems are trained in silico using differentiable simulators rooted in the first principle of optics, an approach known as simulator-based training (SBT). While SBT has proven effective within the confines of the simulator, the performance in real systems is largely contingent upon the simulator's fidelity. Factors such as misalignment and aberration, often omitted in simulations, cause significant performance degradation when optical computing weights trained exclusively within the simulator are applied to real-world systems.

To bridge the reality gap between simulation and experiments, physics-aware training (PAT) and hybrid training (HBT) have been introduced ~\cite{wright2022deep, spall2022hybrid} recently. Both training strategies include conducting the forward pass in the real-world system and back-propagating the loss from the system to its weights through the simulator. These in situ approaches allow the training process to access the optical computing system during the forward pass, which leads to more accurate weight updates than in silico training ~\cite{buckley2023photonic}.

Despite these recent advances, there is a continued reliance on a physics-based simulator during the back-propagation process in current in situ training methods. Such a setting brings three drawbacks: (1) the bias between the simulator and real system prohibits the above training process from achieving optimal results; (2) the in silico simulation requires large memory and computation, limiting the aforementioned methods from in situ training in edge devices with limited computing resources~\cite{sludds2022delocalized}; and (3) the model-based training strategies need high-fidelity images of the input object, which are costly to acquire in terms of instruments, time and storage memory. Hence, developing a memory- and computation-efficient algorithm to train the optical computing system efficiently is an open problem we address in this paper.



% Figure environment removed 


\textit{Proposed Solution.} Here, we propose an in situ model-free optimization method that does not require back-propagating errors through the simulator. Instead, we use a score gradient estimation algorithm~\cite{wierstra2014natural, williams1992simple} to solely use the forward outputs from the real system to get gradients for updating the weights of the optical computing system. As shown in Fig.~\ref{fig:mfo}, our method treats the optical system as a black box and back-propagates task-specific negative-loss as rewards to the source weight distributions (Fig.~\ref{fig:mfo}a). This process only requires knowledge of the weights and forward outputs of the optical computing system, unlike the SBT and HBT methods that require a simulator and the images of the input objects (Fig.~\ref{fig:mfo}b). 


\textit{Contributions.} We make the following contributions:

\begin{itemize}
    \item We \textit{introduce} a score-gradient estimation method to train the optical computing system in a model-free manner, providing a computation- and memory-efficient way to mitigate the reality gap to training the real optical computing system (Sec.~\ref{sec: method}). 
    \item We \textit{validate} our method on a diffractive optical computing system. Experimental results show that G-MFO outperforms hybrid training on the commonly used MNIST and FMNIST datasets~\cite{lin2018all, wright2022deep, spall2022hybrid} (Sec.~\ref{subsec: general performance}). 
    \item We \textit{show} the G-MFO training process only consumes $\sim 0.1\%$ of the GPU time and memory compared with the HBT in situ method by avoiding the computation-intensive modeling of the wave propagation process (Sec.~\ref{subsec: source efficient training by G-MFO.}).
    \item Application scenario: We \textit{demonstrate}, as a proof-of-concept, that our G-MFO-trained optical computing system's effectiveness on 
     classifying four types of white blood cells from their phase maps in a \textit{marker-free}\footnote{
    Herein, we use "marker-free" but not "label-free" to avoid confusion. This is because "label-free" has different meanings in biomedical research and high-level vision.} manner with a testing accuracy of $73.8\%$, making it a promising approach for image-free, marker-free, and high-speed cell analysis (Sec.~\ref{subsec: classify WBC.}).
\end{itemize}

\textit{Open source.} Our code will be available at repository
\href{https://github.com/shuxin626/Model-free-Computational-Optics}{Model-free-Computational-Optics} to facilitate further research and applications on computational optics and training of optical computing systems. We hope to promote the reproducibility and follow-ups for this hardware-centric research direction. 




\begin{table*}[ht]
\centering
\arrayrulecolor{black}
\fontsize{8pt}{8pt}\selectfont
    \centering
    \begin{tabular}{c|p{1.6cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}}
    \toprule
    & Conventional &\multicolumn{2}{c|}{MBO} & \multicolumn{5}{c}{MFO} \\\midrule
    & SBT ~\cite{lin2018all, shen2017deep} & H-MBO ~\cite{wright2022deep, spall2022hybrid, zhou2021large} & L-MBO \cite{zheng2023dual, huo2023optical} & IMOB \cite{Zhou:2020pr, nakajima2022physical, hughes2018training}  & FFT ~\cite{momeni2023backpropagation, oguz2023forward} & Trial and Error~\cite{bueno2018reinforcement, liu2022programmable} &  GA ~\cite{zhang2021efficient} & \textbf {G-MFO (ours)}  \\\midrule
    In situ & \hfil\cellcolor{red!20} No & \hfil\cellcolor{green!20} Yes & \hfil\cellcolor{green!20}Yes & 
    \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes \\
 Computation overhead & \hfil\cellcolor{red!20} High & \hfil\cellcolor{red!20} High & \hfil\cellcolor{red!20} High &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low\\ 
     Input image free & \hfil\cellcolor{red!20} No & \hfil\cellcolor{red!20} No & \hfil\cellcolor{red!20}No & 
    \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{red!20}No & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{green!20}Yes \\
    In silico training time & \hfil\cellcolor{red!20} High & \hfil\cellcolor{red!20} High & \hfil\cellcolor{red!20} High &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low &  \hfil\cellcolor{green!20} Low\\ 
    Dimensionality & \hfil\cellcolor{green!20} High & \hfil\cellcolor{green!20} High & \hfil\cellcolor{green!20} High &  \hfil\cellcolor{green!20} High &  \hfil\cellcolor{green!20} High &  \hfil\cellcolor{red!20} Low &  \hfil\cellcolor{red!20} Low &  \hfil\cellcolor{orange!20} Medium\\
    Intermediate measurement & \hfil\cellcolor{green!20} No & \hfil\cellcolor{green!20} No & \hfil\cellcolor{green!20}No & \hfil\cellcolor{red!20}Yes & \hfil\cellcolor{red!20} Yes & \hfil\cellcolor{green!20}No & \hfil\cellcolor{green!20}No & \hfil\cellcolor{green!20}No\\
    Gradient & \hfil\cellcolor{green!20} Yes & \hfil\cellcolor{green!20} Yes & \hfil\cellcolor{green!20} Yes & 
    \hfil\cellcolor{green!20}Yes & \hfil\cellcolor{red!20}No & \hfil\cellcolor{red!20}No & \hfil\cellcolor{red!20}No & \hfil\cellcolor{green!20}Yes\\
    \bottomrule
    \end{tabular}
    \caption{{\textbf{Comparison of strategies on training optical computing systems} along the axes of in situ training capability (in situ), in silico computation overhead (computation overhead), the requirement on the recording of the input object to the task (input image free), required in silico training time, the dimensionality of trainable parameters (dimensionality), requirements on intermediate measurement and whether or not use gradient-based update that is more efficient (gradient). 
    Simulator-based training (SBT), Hybrid model-based training (H-MBO), Learned model-based training (L-MBO), Intermediate measurement optical backpropagation (IMOB), Forward-forward training (FFT), Trial and error, Genetic algorithm (GA), Gradient-based model-free optimization (G-MFO).
    }}
    \label{tab: comparison of training methodlogies}
\vspace{-1em}
\end{table*}

\section{Related Work}


    


We discuss the following work related to our contributions. 






\subsection{In situ training strategies to optimize the optical computing system}


Most research into optical computing system training has historically relied on in silico training. This process involves forward and backward propagation calculations on an external computer that simulates the physical system through a digital twin~\cite{lin2018all, shen2017deep}. However, this technique can lead to discrepancies between the simulation and actual reality due to inaccuracies in the physical system's representation.

In recent years, progress has been made in developing in situ training strategies that use data gathered from real-world optical computing systems to mitigate the reality gap and improve experimental performance. As a first attempt, we categorize previous and our in-situ training methods into two genres: model-based optimization (MBO) and model-free optimization (MFO) methods. We differentiate these two genres by whether they use the optical computing system emulator models during the parameter updating process. 
A tabular comparison of the previous and our methods is in Tab.~\ref{tab: comparison of training methodlogies}. Details of the illustrations and comparisons are below. 

\textbf{MBO methods.} \textit{Physics-aware training (PAT)~\cite{wright2022deep}, hybrid training (HBT)~\cite{spall2022hybrid} or adaptive training (AT)~\cite{zhou2021large} (H-MBO)} are one type of the MBO methods that conduct forward pass in a real system and back-propagate the gradients with the aid of a physics-based simulator. 
\textit{Backpropagation through learned model (L-MBO)} is another method that gathers the real data from the optical computing system to train a neural proxy of the optical computing system~\cite{zheng2023dual, huo2023optical}. With such a learned proxy rather than the physics-based model utilized in H-MBO, the backward parameter update process can reduce the bias from the model mismatch between the simulator and the real system in L-MBO. During training, one has to optimize both the task's and proxy's parameters to optimize the task performance and improve the fidelity of the simulator. 
The task performance for the MBO, especially the L-MBO, is high while back-propagating with the digital twin also burdens the training process. 
The L-MBO methods implemented in optical computing are referred as \textit{hardware (camera)-in-the-loop methods}. These methods have recently been used in computational display~\cite{chakravarthula2020learned, peng2020neural} and camera ISP~\cite{tseng2022neural}. They are also known as \textit{real2sim} in photolithography for solving computational lithography tasks~\cite{zheng2023close, liao2022line}. 
Despite the computational burden introduced by the emulation process from the digital twin, another disadvantage of the MBO methods is that all the MBO approaches require images of input objects during training, adding further burden to the overall process.   



\textbf{MFO methods.} Unlike the aforementioned MBO methods, MFO methods do not require constructing a digital twin of the optical computing system; they directly use the real system's output or intermediate measurements to update its parameters. \textit{Population-based algorithms} such as genetic algorithm (GA) methods~\cite{zhang2021efficient} use the output from the optical computing system to optimize parameters by simulating the process of natural selection. Still, the genetic algorithm's performance scales poorly to the dimensionality of parameters~\cite{grefenstette1986optimization}. 
\textit{Forward-forward training (FFT)} is a greedy multi-layer learning procedure for mortal computation~\cite{hinton2022forward} and it has been applied to train optical computing systems recently~\cite{momeni2023backpropagation, oguz2023forward}. However, labels must be added to each input sample during the training and testing. As a result, such training strategies require masking the input, which might be unrealistic in many scenarios, and the testing process of forward-forward training is prolonged.
In \textit{Trail and error}, perturbed parameters that enhance performance are retained, while those that do not are discarded, reverting to the previous state~\cite{bueno2018reinforcement, liu2022programmable}. This method, however, does not scale well with the dimensionality of parameters.
\textit{Intermediate measurement optical backpropagation (IMOB)} proposed using the adjoint variable method or direct feedback alignment, etc., to calculate gradients~\cite{Zhou:2020pr, nakajima2022physical, hughes2018training}. However, such methods require intermediate system measurements for every layer's output, which might be infeasible or require additional measurement setups. 

We propose the gradient-based MFO (G-MFO) training method using Monte Carlo gradient estimation to update the optical computing system parameters automatically. Our work shares similarities with Zhang \textit{et al.}, which uses the genetic algorithm for weight update~\cite{zhang2021efficient}, as our and their methods both generate a batch of sampled parameters during the training process. The difference is that our parameter updating process is more efficient owing to a score gradient estimator rather than their heuristic hill-climbing type algorithm. Moreover, our method does not need specific conditions, such as changing the system or manipulating the input object, which are more or less required in other MBO and MFO methods. 


\subsection{Zeroth-Order Optimization and Its Applications to Computational Optics}

The zeroth-order (ZO) optimization uses finite differences from forward evaluations instead of the first-order path-wise gradient to calculate the gradient for updating the parameters of interest~\cite{mohamed2020monte, liu2020primer}. ZO has been utilized in many areas, such as differentiating through discontinuities in computer graphics~\cite{fischer2023zero}, optimizing contact dynamics in robotics~\cite{pang2023global, suh2022bundled}, and policy learning in reinforcement learning~\cite{williams1992simple}. ZO optimization has been implemented with both full-point estimation~\cite{kiefer1952stochastic}, and stochastic two-point estimation~\cite{spall1987stochastic}.
A significant advancement in ZO is to estimate the descent direction using multiple stochastic finite differences~\cite{spall1992multivariate} where Monte Carlo approximation is used in the process, also called evolutionary strategies~\cite{beyer2002evolution}. Moreover, techniques such as antithetic sampling, control variates~\cite{sanzalonso2024course}, or more advanced methods to reduce variance~\cite{kurenkov2021guiding, lehman2018more} in the Monte Carlo approximation process are used in multiple stochastic finite differences. Our work employs Monte Carlo gradient estimation~\cite{mohamed2020monte}, which resembles multiple stochastic finite differences.


\textit{Applications of ZO Methods to Computational Optics} have been relatively sparse compared to first-order methods. In the past, there have been demonstrations in computational optics tasks such as lens design~\cite{nagata2004lens}, auto-tuning structured light for depth estimation~\cite{chen2020auto}, and computer-generated holography~\cite{zhao2022model}. Using only forward evaluations for gradient updates makes it beneficial for optical computing-related tasks, such as what was mentioned as optical stochastic gradient descent (SGD) in the auto-tuning structured light work~\cite{chen2020auto}. The reason is that forward evaluation in optical computing is inexpensive while finding the first-order gradient is computationally costly and prone to errors. Our work highlights the advantages of using zeroth-order optimization for optimizing more complex systems, such as optical computing, and the efficacy of using Monte Carlo gradient estimation for efficient optimization.



















\subsection{Application side of optical computing}


Optical computing, outperforming electrical computing in parallelism and processing speed, is pivotal for AI progress via optical neural networks (ONN) development~\cite{wetzstein2020inference}. ONNs encode inputs using light's spatial, temporal, and spectral characteristics to enable applications such as image classification, motion detection, and medical diagnosis~\cite{scalable_optical_learning_operator, liu2022programmable, reconfigurable_onn}. Furthermore, optical computing functions as an advanced neural network platform and directly processes optical signals, facilitating applications like phase reconstruction~\cite{mengu2022classification}, denoising~\cite{icsil2024all}, edge detection~\cite{park2022metasurface}, and unidirectional imaging~\cite{li2023unidirectional}. 

As a secondary contribution, our work showcases the application of optical computing for marker-free cell classification. Particularly relevant to our research is the study by Wang~\textit{et al.}~\cite{wang2023image}, which demonstrates the classification of fluorescent-labeled cells using an optical computing system. In contrast, our approach shows cell-classification based on their phase maps, instead of relying on fluorescent markers. This illustrates that optical computing can facilitate low-storage, high-speed, and marker-free cell analysis.




\section{Methodology} \label{sec: method}
In what follows, we mathematically detail the problem setup on training the optical computing system and our solution. We introduce problem formation in Subsec.~\ref{subsec: problem setup} and the conventional solution of using simulator-based training (SBT) in Subsec.~\ref{subsec: simulator-based design}. We then illustrate our solution to the problem, the gradient-based model-free optimization (G-MFO) for training the optical computing system in Subsec.~\ref{subsec: G-MFO methodology}. Finally, we illustrate the optical computing system and the related simulators in Subsec.~\ref{subsec: system description}, which we will use to demonstrate the performance of our method. 


\subsection{Problem setup} \label{subsec: problem setup}
 We are interested in learning the optimal weight $w\in\mathbb{R}^{H}$ for the optical computing system on a desired task with a training dataset $\mathcal{D} = \{x_i, y_i\}_{i=1}^N$, where $N$ is the size of the dataset, $H$ is the number of trainable parameters in $w$, and $x$ and $y$ denote the input and target of interest, respectively. A function $f_{sys}(\cdot,w)$ maps $x\rightarrow y$ through this optical computing system with $w$. Specifically, in the image classification task based on the diffractive optical computing system we work on, $f_{sys}$ denotes the optical mapping from the input image $x$ to the output label $y$, and $w$ is the optical computing weight in the form of phase value modulation. 
 
During training, one can minimize the cost function $J(w)$ as the mean task-specific loss across the entire training data set $\mathcal{D}$
:

\begin{subequations}
\begin{align}
          \operatorname*{arg\,min}_w J(w): &=\mathbb{E}[\mathcal{L}(\mathcal{D}, w)], \\
                    &= \frac{1}{N}\sum_{i=1}^{N}\mathcal{L}(f_{sys}(x_i, w), y_i), \label{eq:objective function}
\end{align}
\end{subequations}
where $\mathcal{L}$ is the task-specific loss function, we use cross-entropy loss~\cite{brier1950verification} since we deal with image classification tasks throughout this paper. 

We use gradient descent-based search to find the optimal $w$ to minimize the objective function $J(w)$:
\begin{equation} \label{eq:grad descent}
    w = w - \alpha \nabla_{w} J(w),
\end{equation}
where $\nabla_{w}$ represents the gradient operator that collects all the partial derivatives of a function concerning parameters in $w$, and $\alpha$ is the learning rate. 

It is straightforward to use the backpropagation method~\cite{rumelhart1986learning} to take the gradient through $f_{sys}$ and finds the gradient $\nabla_{w} J(w)$ as:
\begin{equation}
    \nabla_w J(w)= \frac{1}{N}\sum_{i=1}^N \nabla_w \mathcal{L}({f_{sys}(x_i, w)}, y_i),
    \label{eq: FOBG}
\end{equation}
when we have an accurate and differentiable $f_{sys}$ modeling.
However, this is the case for training digital neural networks~\cite{rumelhart1986learning}, but not when we train a real-world optical computing system. \textbf{Thus, this paper's critical aim is finding an accurate gradient estimation of $\nabla_w J(w)$ to update optical computing weight $w$ in a real-world optical system}.



% Figure environment removed

\subsection{In silico simulator-based training (SBT)} \label{subsec: simulator-based design}

\textbf{Back-propagation through the simulator $\hat{f}_{sys}$.} In a real-world optical computing system, since we do not have an exact functional expression of $f_{sys}$, the \textbf{simulator-based training} (SBT) builds a simulator $\hat{f}_{sys}$ as the differentiable approximation of $f_{sys}$ (Fig.~\ref{fig:mfo}b). 
A naive training strategy is substituting $f_{sys}$ in Eq.~\ref{eq: FOBG} with the simulator $\hat{f}_{sys}$ and applying in silico training on the simulator:

\begin{equation}
    \nabla_w J(w)= \frac{1}{N}\sum_{i=1}^N \nabla_w \mathcal{L}({\hat{f}_{sys}(x_i, w)}, y_i).
    \label{eq: sbt}
\end{equation}
The resulting $\nabla_w J(w)$ is used in Eq.~\ref{eq:grad descent} to update $w$.
After training, the optimized $w$ is uploaded to the real optical computing system $f_{sys}$ to test the performance. 


\textbf{Simulation-to-reality gap.} The aforementioned simulator-based training is based on backpropagation through the simulator $\hat{f}_{sys}$. The "sim2real" gap is low (i.e., the gradient $\nabla_w J(w)$ is an accurate estimation) when the simulator $\hat{f}_{sys}$ is similar to $f_{sys}$. However, this assumption does not hold in many prototypes of optical computing systems where inadequate modeling and misalignment between the optical elements decay the performance of the SBT during the "sim2real" transfer. We use a simulator described in Subsec.~\ref{subsec: system description} to assess the adverse effect of misalignment on the image classification results. We impose various misalignments to a well-trained ideal optical computing system and measure drops in classification accuracy. For instance, we show in Fig.~\ref{fig: misalignment degrades the performance} that slightly laterally misaligning the optical computing layer by $41.1 \: \mu m$ reduces the classification accuracy by $31.2\%$.  






\subsection{In situ G-MFO}\label{subsec: G-MFO methodology}
Our solution for solving the aforementioned "sim2real" gap issue in Subsec.~\ref{subsec: simulator-based design} is in situ learning the optical computing weight $w$ with the gradient-based model-free optimization (G-MFO). In situ learning enables us to access the output of $f_{sys}$ and is feasible on the hardware side because we can use programmable devices such as spatial light modulators to update $w$. The challenging part is designing a training strategy that efficiently uses the output of actual system $f_{sys}$ to construct an unbiased gradient estimator. Here, we use the score gradient estimator to calculate the gradient~\cite{schulman2015gradient, mohamed2020monte} for the backward update of parameters in $w$ while circumventing the construction of $\hat{f}_{sys}$, a biased and resource-intensive numerical modeling of $f_{sys}$. 

\textbf{Back-propagation through the weights distribution $p$.} In our score gradient estimator for model-free optimization, we model optical computing weight $w$ as a random variable that follows a 
probability distribution: $w\sim p(w|\theta)$ and rewrite the cost function $J(w)$ in  Eq.~\ref{eq:objective function} as a probability cost function $J(\theta)$:
\begin{subequations}
\begin{align}
        \operatorname*{arg\,min}_{\theta} J(\theta): 
          &= \frac{1}{N}\sum_{i=1}^{N} \mathbb{E}_{p(w|\theta)}[\mathcal{L}(f_{sys}(x_i, w), y_i)],\\
          &= \frac{1}{N}\sum_{i=1}^{N} \int {p(w|\theta)}\mathcal{L}(f_{sys}(x_i, w), y_i) \diff w,
\end{align}\label{eq: prob obj}
\end{subequations}
where the probability distribution $p(w|\theta)$ is continuous in its domain and differentiable concerning its distribution parameter $\theta$. 
Accordingly, the original goal of optimizing $w$ is reformulated as finding a most likely distribution $p(w|\theta)$ that minimizes the cost function $J(\theta)$ in Eq.~\ref{eq: prob obj}. 
Specifically, we model the distribution $p$ as a multivariate normal distribution with $\theta = \{\mu, \sigma^2\}$ and $p(w|\theta) = \mathcal{N}(w;\mu, \sigma^2)$ for optimizing the continuous phase-valued weight to be uploaded onto the SLM in our work. 


To update distribution parameter $\theta$ with the gradient descent Eq.~\ref{eq:grad descent}, we take the gradient of the cost function $J(\theta)$ in Eq.~\ref{eq: prob obj}:
\begin{subequations}
\begin{align}
        \nabla_{\theta} J(\theta) 
        &= \nabla_{\theta} \frac{1}{N}\sum_{i=1}^{N} \int {p(w|\theta)}\mathcal{L}(f_{sys}(x_i, w), y_i) \diff w ,\\
        &= \frac{1}{N}\sum_{i=1}^{N} \int \mathcal{L}(f_{sys}(x_i, w), y_i) \nabla_{\theta}{p(w|\theta)} \diff w .
\end{align}
\end{subequations}
Applying the log derivative trick, we have:
\begin{equation}
        \nabla_{\theta} J(\theta) 
        = \frac{1}{N}\sum_{i=1}^{N} \int p(w|\theta) \mathcal{L}(f_{sys}(x_i, w), y_i) \nabla_{\theta} \log{p(w|\theta)} \diff w .\label{eq: prob obj int}
\end{equation}
Then we apply Monte Carlo integration to approximate the integral value in Eq.~\ref{eq: prob obj int} by first drawing $M$ independent samples $\{w_j\}_{j=1}^M$ from the distribution $p(w|\theta)$ and then computing the average function value evaluated in these samples:
        \begin{subequations}
        \begin{align}
        \nabla_{\theta} J(\theta) 
        &=\frac{1}{N}\sum_{i=1}^{N} \frac{1}{M}\sum_{j=1}^{M} \mathcal{L}(f_{sys}(x_i, w_j), y_i) \nabla_{\theta} \log{p(w_j|\theta)} \label{eq: prob obj monte carlo int},\\
        &=\frac{1}{M}\sum_{j=1}^{M} [\frac{1}{N}\sum_{i=1}^{N}  \mathcal{L}(f_{sys}(x_i, w_j), y_i)] \nabla_{\theta} \log{{p(w_j|\theta)}},\\
        &=\frac{1}{M}\sum_{j=1}^{M} r(w_j) \nabla_{\theta} \log{{p(w_j|\theta)}}. 
        \label{eq: prob grad}
\end{align}
\end{subequations}
Here we define $r(w_j)=\frac{1}{N}\sum_{i=1}^{N} \mathcal{L}(f_{sys}(x_i, w_j), y_i)$ as the negative reward corresponding to each weight $w_j$. We use Equation~\ref{eq: prob grad} as the score gradient estimator for G-MFO, 
where the score function is $\nabla_{\theta} \log{p(w_j|\theta)}$, which has been widely used in other areas, such as policy gradient algorithms in reinforcement learning~\cite{williams1992simple} and diffusion models~\cite{song2019generative}. 



\textit{Variance reduction.} The main risk of using the score gradient estimator is the high variance that comes from the Monte Carlo integration step that transits Eq.~\ref{eq: prob obj int} to Eq.~\ref{eq: prob obj monte carlo int}. Such a sampling-based integration step has high variance because different sets of random samples may lead to significantly different integral estimates. We reduce the variance by subtracting the $r(w_j)$ with baseline value $\bar{r} = \frac{1}{M} \sum_{j=1}^M r(w_j)$ while keeping the bias of gradient unchanged~\cite{mei2023role}:
\begin{equation}
    \nabla_{\theta} J(\theta) = 
    \frac{1}{M}\sum_{j=1}^{M} (r(w_j)- \bar{r}) \nabla_{\theta} \log{{p(w_j|\theta)}}. \label{eq: prob grad simplified}
\end{equation}

\textbf{Training recipe of G-MFO.} 
We perform the following steps in each training epoch (see Fig.~\ref{fig: MFO_workflow}): 1. Sample a group of phase-valued optical computing weights $\{w_j\}_{j=1}^M$ from the distribution $w_j \sim p(w|\theta)$ and upload them to the optical computing layer. Upload classification data $\mathcal{D}=\{x_i, y_i\}_{i=1}^N$ to the input layer; 2. Collect the optical computing system's output $\{f_{sys}(x_i, w_j)\}_{i=1, j=1}^{N, M}$ for each pair of input and weight; 3. Update the distribution parameter $\theta$ in silico using Eqs.~\ref{eq:grad descent} and~\ref{eq: prob grad simplified}; 4. Sample a new group of $\{w_j\}_{j=1}^M$ from the updated distribution $w_j \sim p(w|\theta)$, which is ready to be uploaded to the optical computing layer in the next epoch.
The algorithm iterates these steps until convergence. 

After minimizing the objective function Eq.~\ref{eq: prob obj}, we export $w_j$ with the smallest $r(w_j)$ as the output weight $w^{\star}$. This performs better than setting $w^{\star}$ as the sampled mean $\mu$. 
An algorithmic overview of the above training recipe is shown in Algorithm~\ref{alg:mfo}.

\begin{algorithm}
\caption{Algorithmic overview of G-MFO.}\label{alg:mfo}
\begin{algorithmic}[1]
\State \textbf{Input: }  {Classification dataset $\mathcal{D}=\{x_i, y_i\}_{i=1}^N$, learning rate $\alpha$, number of sampled weights $M$, optical computing system $f_{sys}$, distribution parameter $\theta=\{\mu, \sigma^2\}$, loss function $\mathcal{L}$, epochs $K$.}
\State \textbf{Output: }{Optimized optical computing weight $w^{\star}$.}

\For{$k$ in range $K$}
    \State{Sample $\{w_j\}_{j=1}^M$ from distribution $p(w|\theta)$.}
    \State{\emph{$\triangleright$ in situ evaluate $\{w_j\}_{j=1}^M$.}}
    \For{$j$ in range $M$}\\
        \State{$r(w_j)\gets \frac{1}{N}\sum_{i=1}^{N} \mathcal{L}(f_{sys}(x_i, w_j), y_i).$}
    \EndFor
    \State{\emph{$\triangleright$ in silico update $\theta$.}}
    \State{Calculate $\nabla_{\theta} J(\theta)$ via Eq.~\ref{eq: prob grad simplified}.}
    \State{$\theta \gets \theta -\alpha\nabla_{\theta} J(\theta).$ }
\EndFor
\State $w^{\star}\gets w_j$ with the smallest $r(w_j)$.
\end{algorithmic}
\end{algorithm}

% Figure environment removed



\subsection{Experiment and Simulation Details of Our Diffractive Optical Computing System} \label{subsec: system description}

We validate the effectiveness of the proposed G-MFO-based training strategy on a single-layer optical computing system and a two-layer diffractive optical computing system.
Our work focuses on the training strategy rather than the design or adavantage of a specific optical computing system. Therefore, we do not consider nonlinearity in constructing our optical computing system, which has recently been implemented using saturation effects~\cite{zhou2021large, wang2023image, zhang2024broadband}. The validity of using a multi-layer versus a single-layer system without nonlinearity has been analyzed empirically in~\cite{kulce2021all}, where the authors attribute the improvement to increased energy resulting from the multi-layer settings. Details on the experimental setups ($f_{sys-1-layer}$, $f_{sys-2-layer}$) and the corresponding simulators ($\hat{f}_{sys-1-layer}$, $\hat{f}_{sys-2-layer}$) are in the Supplement Sec. S.1.







% Figure environment removed














\vspace{-0.2cm}
\section{Results}\label{sec: results}

We aim to answer the following research questions in this section:

\begin{itemize}
    \item How does G-MFO perform in the numerical simulations and experiments?
    \item What are the advantages and limitations of G-MFO?
    \item How is G-MFO's applicability on the marker-free cell classification task?
\end{itemize}

Thus, we numerically and experimentally evaluate the general performance of our G-MFO method on the open-source MNIST and FMNIST datasets (Subsec.~\ref{subsec: general performance}). 
We then illustrate G-MFO's advantage of memory- and computation-efficient training in Subsec.~\ref{subsec: source efficient training by G-MFO.}. Moreover, we analyze the limitation of our method in Subsec~\ref{subsec: G-MFO exhibits curse of dimensionality.}. Lastly, we demonstrate the G-MFO method on a novel application of marker-free classifying white blood cells in Subsec.~\ref{subsec: classify WBC.}.







{We compare our method with the following baselines:}

\begin{itemize}
    \item \textbf{Ideal:} The in silico simulation results without introducing any artificial misalignment during the simulation. This corresponds to the best achievable result for an optical computing system. 
    \item \textbf{SBT:} Simulator-based training with digitally aligned simulator. 
    \item \textbf{HBT:} The hybrid training strategies with a physics-based simulator.
    \item \textbf{L-MBO:}  We pre-train a proxy using the task dataset to emulate the real system and then optimize the optical computing task based on the pre-trained proxy.
    \item \textbf{Zeroth-order optimization baselines:} Including two-point estimation on a random direction~\cite{spall1987stochastic} and full-point estimation~\cite{kiefer1952stochastic, chen2020auto}.
\end{itemize}
The training details for simulations and experiments are in Supplement Sec. S.3.
Supplement Sec. S.6 provides a detailed description of our implementation of the HBT baseline. Supplement Sec. S.7 discusses and compares L-MBO.

\subsection{General performance evaluation on the MNIST and FMNIST dataset}~\label{subsec: general performance}

\vspace{-0.8cm}
\rev{\subsubsection{Simulation comparison between G-MFO and other zeroth-order optimization methods in simulation on a small dataset}\label{subsec: simulation mfo comparison}}


\rev{We use a single-layer optical computing simulator to compare our method with two zeroth-order (ZO) baselines: the full-point ZO method~\cite{chen2020auto, kiefer1952stochastic} and the two-point ZO method~\cite{spall1987stochastic}. This comparison mainly evaluates the training performance, including accuracy, execution, and convergence speed. Therefore, we use a small dataset of 100 training, 100 validation, and 100 testing samples.}


\rev{We present the simulation results and training time per epoch in Table~\ref{tab: 0th order comparison result}, and the curves of training accuracy in Fig.~\ref{fig: 0order comparison}. The results show that sufficient samples are necessary for successful optimization. Specifically, the two-point method, with two samples per epoch, only achieves a training accuracy of $22\%$, whereas both the full-point method, using $128 \times 128$ samples per epoch, and the G-MFO method, using $128$ samples per epoch, achieve a training accuracy of $99\%$. Additionally, G-MFO has improved sample efficiency than the full-point optimization method, requiring only $4\%$ of the samples to achieve an accuracy of $99\%$ compared to the full-point optimization method.}


% Figure environment removed

\begin{table}[h!]
\newcolumntype {C}[1]{>{\centering\arraybackslash}m{#1}}
\arrayrulecolor{black}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{C{0.16\linewidth} | C{0.08\linewidth} | C{0.08\linewidth}| C{0.08\linewidth} |C{0.15\linewidth}| C{0.15\linewidth}}
\hline
             &\multicolumn{3}{c|}{Accuracy}    &\# of samples per epoch  &Training time per epoch\\\hline
             & Train             & Val                 & Test \\\hline\hline
Full-point~\cite{chen2020auto, kiefer1952stochastic}         & $99.0\%$          & $75.0\%$            & $59.0\%$   & $128\times128$& $113~min$\\
Two-point~\cite{spall1987stochastic}         & $22.0\%$          & $27.0\%$            & $26.0\%$   & 2             & $2~s$ \\

G-MFO (Ours) & $99.0\%$          & $73.0\%$            & $60.0\%$   & $128$           & $2~min$\\
\hline
\end{tabular}
\caption{\rev{\textbf{Numerical comparison of G-MFO and other zeroth-order (ZO) optimization methods on FMNIST dataset on a simulated single-layer diffractive optical computing system. 
} We show results from the full-point ZO method, the two-point ZO method, and G-MFO. }}
\label{tab: 0th order comparison result}
\end{table}


\begin{table}[h!]
\newcolumntype {C}[1]{>{\centering\arraybackslash}m{#1}}
\arrayrulecolor{black}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{C{0.16\linewidth} | C{0.072\linewidth} | C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}}
\hline
             &\multicolumn{3}{c|}{MNIST}          & \multicolumn{3}{c}{FMNIST} \\ \cline{2-7}
             & Train      & Val      & Test       & Train         & Val         & Test \\\hline\hline
\textcolor{gray}{Ideal}       & \textcolor{gray}{$90.0\%$}          & \textcolor{gray}{$89.3\%$}            & \textcolor{gray}{$89.5\%$}            & \textcolor{gray}{$82.2\%$}         & \textcolor{gray}{$81.2\%$}           & \textcolor{gray}{$80.5\%$} \\
\hline
HBT          & $78.0\%$         & $78.7\%$           & $78.4\%$         & $61.6\%$          & $61.4\%$           & $59.8\%$\\
G-MFO (Ours)         & $\textbf{86.2\%}$         & $\textbf{86.2\%}$           &$\textbf{87.0\%}$         & $\textbf{75.4\%}$          & $\textbf{75.4\%}$           & $\textbf{74.1\%}$ \\ 

\hline
\end{tabular}
\caption{\textbf{Numerical performance comparison on MNIST and FMNIST datasets on two-layer diffractive optical computing system.
}}
\label{tab: two layer simulation result}
\end{table}


\vspace{0.3cm}
\subsubsection{Simulation results on the two-layer optical computing system $\hat{f}_{sys-2-layer}$.}\label{subsec: simulation results two layer}

We evaluate our method's accuracy by conducting performance tests on a two-layer optical computing simulator $\hat{f}_{sys-2-layer}$ utilizing two classical image classification datasets: MNIST~\cite{deng2012mnist} and FMNIST~\cite{xiao2017fashion}. Each optical computing layer contains $128 \times 128 = 16,384$ trainable parameter, and the system contains $128 \times 128 \times 2 = 32,768$ parameters. Furthermore, to assess the robustness of the G-MFO method against system misalignment, we intentionally introduce a slight misalignment on the positive x'-axis direction, amounting to $40\mu m$ (equivalent to 5 pixels on SLM1) on the optical computing layer1, and $18.7\mu m$ (corresponding to 5 pixels on SLM2), on the optical computing layer2.
We use $10,000$ data to train, $10,000$ data to validate, and $10,000$ data to test.

The simulation outcomes for the MNIST and FMNIST datasets are in Tab.~\ref{tab: two layer simulation result}. 
The ideal testing accuracy reaches $89.5\%$ on MNIST and $80.5\%$ on FMNIST. However, the presence of misalignment reduces the accuracy to $78.4\%$ and $59.8\%$ using HBT, a decrease of approximately $10\%$ and $20\%$. In contrast, the G-MFO method hits an accuracy of $87.0\%$ and $74.1\%$, effectively mitigating the detrimental impact of system misalignment.             




\begin{table}[h!]
\newcolumntype {C}[1]{>{\centering\arraybackslash}m{#1}}
\arrayrulecolor{black}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{C{0.16\linewidth} | C{0.072\linewidth} | C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}| C{0.072\linewidth}}
\hline
             &\multicolumn{3}{c|}{MNIST}          & \multicolumn{3}{c}{FMNIST} \\ \cline{2-7}
             & Train      & Val      & Test       & Train         & Val         & Test \\\hline\hline
\textcolor{gray}{Ideal}        & \textcolor{gray}{$92.7\%$}          & \textcolor{gray}{$84.3\%$}            & \textcolor{gray}{$82.2\%$}            & \textcolor{gray}{$85.6\%$}         & \textcolor{gray}{$79.9\%$}           & \textcolor{gray}{$76.4\%$} \\
\hline
\hline
SBT          & $81.9\%$         & $74.4\%$           & $69.3\%$         & $68.3\%$          & $64.1\%$           & $60.9\%$ \\
HBT          & $81.9\%$         & $75.5\%$           & $72.8\%$         & $68.3\%$          & $68.7\%$           & $65.8\%$ \\
G-MFO (Ours)         & $\textbf{83.1\%}$         & $\textbf{77.8\%}$           &$\textbf{73.6\%}$         & $\textbf{74.0\%}$          & $\textbf{71.1\%}$           & $\textbf{70.4\%}$ \\ 
HBT+G-MFO (Ours)      & $\textbf{87.0\%}$& $\textbf{80.2\%}$  & $\textbf{77.7\%}$ &$\textbf{75.0\%}$  & $\textbf{71.7\%}$   & $\textbf{70.2\%}$  \\
\hline
\end{tabular}
\caption{\textbf{Experimental performance comparison on MNIST and FMNIST datasets on the single-layer optical computing system.} Results of the ideal mode are from the simulator, whose parameters are determined from experiments while we impose no misalignment on the simulator. The lower four rows are experimental results from SBT, HBT, G-MFO, {and HBT+G-MFO (G-MFO fine-tuning upon the result from HBT)}. 
Our method outperforms the SBT and HBT methods on the MNIST and FMNIST datasets.
} 
\label{tab: MNIST and FMNIST result}
\vspace{-0.2cm}
\end{table}











\subsubsection{G-MFO outperforms hybrid training (HBT) experimentally on a single-layer optical computing system $f_{sys-1-layer}$.}\label{subsec: experiment result one layer}



We conduct experiments on a real single-layer optical computing system $f_{sys-1-layer}$ on the MNIST and FMNIST datasets. We include in silico SBT and in situ HBT methods utilizing digitally aligned simulators as the comparison baselines. The training, validation, and testing phases each utilize a dataset of 1,000 samples. 

Tab.~\ref{tab: MNIST and FMNIST result} quantitatively shows that our method achieves higher classification accuracy than the HBT and SBT methods on both datasets in the experiments. The SBT method performs poorly due to the reality gap between the simulator and the real system. 
The HBT method suffers from the bias between $\hat{f}_{sys}$ and ${f}_{sys}$ in the backward process, while the G-MFO bypasses the bias-sensitive modeling and updates gradients solely with $f_{sys}$. 
We further show G-MFO's capability to fine-tune the HBT result. The last row of Tab.~\ref{tab: MNIST and FMNIST result} shows that the unbiased G-MFO method further improves the results of HBT. Moreover, we also empirically find that fine-tuning outperforms G-MFO only. Fig.~\ref{fig: G-MFO result} visualizes some experimental outputs and confusion matrices using the G-MFO method. 






\subsubsection{Experimental results on the two-layer optical computing system $f_{sys-2-layer}$.}\label{subsec: experiment result two layer}

We also perform experiments on training a real two-layer optical computing system $f_{sys-2-layer}$ on the MNIST dataset. For this experiment, we utilize a dataset comprising 10,000 instances for training, another 10,000 for validation, and a separate set of 10,000 for testing. The training, validation, and testing accuracy are  $80.43\%$, $81.1\%$, and $80.3\%$, respectively. 

Compared with the simulated G-MFO outcomes presented in Tab.~\ref{tab: two layer simulation result}, the experimental accuracy is lower. We hypothesize that this discrepancy is attributed, in part, to mechanical disturbances encountered during the multi-day span of the experiment. Moreover, the training accuracy from a two-layer system is lower than that of a single-layer system, while the validation and testing accuracy is higher. This is because we use more samples when training a two-layer system, alleviating overfitting.   




% Figure environment removed




\subsection{Advantage: memory- and computation-efficient training enabled by G-MFO}\label{subsec: source efficient training by G-MFO.}

% Figure environment removed

In addition to the predicting accuracy discussed in the previous subsection, our G-MFO method has an advantage over other training algorithms regarding GPU time and memory efficiency. 
The SBT and HBT methods compute $\hat{f}_{sys}(x, w)$ and $\nabla_{w}\hat{f}_{sys}$ (Fig.~\ref{fig:mfo}b) for each input $x$ in silico, which requires a lot of in silico computation resources. 
In contrast, our G-MFO method executes the calculation of $f_{sys}(x, w)$ in the light-speed real optical computing system, but not in the computation- and memory-heavy simulator $\hat{f}_{sys}(x,w)$.
The only step of our G-MFO method that consumes in silico computational resources is the one described in Eq.~\ref{eq: prob grad simplified}, where we calculate the score gradient. The in silico computational resources consumption in this step is low because it only scales with the dimension of $w$ and has no relation to the complexity of the system's light transport $\hat{f}_{sys}$.

We compare our G-MFO method with HBT in GPU memory and time usage during experiments on a single-layer optical computing system in Fig.~\ref{fig: resource consuming}. Our G-MFO method requires far less GPU time and memory than the HBT method during the training.


\subsection{Limitation: G-MFO exhibits the curse of dimensionality}\label{subsec: G-MFO exhibits curse of dimensionality.}
Our method is not without its limits. Our G-MFO training relies on Monte Carlo integration. It thus inherits the \textit{curse of dimensionality} from the Monte Carlo integration~\cite{bellman1959adaptive}. That is, the number of samples $M$ needed to estimate the integration in Eq.~\ref{eq: prob obj int} with a given level of accuracy grows exponentially concerning the $H$, the number of trainable parameters (i.e., dimensionality) of the function.
This is also discussed and alleviated with \textit{variance reduction} in the previous Sec.~\ref{subsec: G-MFO methodology}. However, the G-MFO strategy presented in
this paper is still sample-inefficient, though unbiased and memory-efficient. 
We need to either limit the number of trainable parameters $H$, or sample a large number of varied optical computing weights $\{w\}^M_{j=1}$ from distribution $p(w|\theta)$ in every iteration to make G-MFO's gradient less noisy. 
The former limits our method's design space, while the latter requires more executions on the real system, which prolongs the training time. 

% Figure environment removed

We quantitatively investigate the influence of this limitation in Fig.~\ref{fig: curse of dimensionality} through simulations on a one-layer optical computing system $\hat{f}_{sys-1-layer}$, employing $1,000$ training samples from the MNIST dataset. The figure demonstrates how $M$ and $H$ impact the training performance of G-MFO.
\vspace{-0.1cm}
Shown in Fig.~\ref{fig: curse of dimensionality}(a), G-MFO requires a $M>=128$ to achieve a training accuracy of $>90\%$ given $H=128^2$. 
Moreover, in Fig.~\ref{fig: curse of dimensionality}(b), our G-MFO method fails when increasing $H$ beyond $128^2$ while keeping the sampling size $M$ fixed to $128$. 


\subsection{Application: all-optical classification on marker-free cellular dataset}\label{subsec: classify WBC.}

For the first time, we demonstrate the capability of an optical computing system for marker-free cell analysis, trained by our G-MFO algorithm (Fig.~\ref{fig: all-optical cell classfier}). We work on the white blood cells (WBC), whose abnormal subtype percentages indicate the immune systemâ€™s malfunction or infectious disease \cite{wbcfunction1, wbcfunction2}. We include details of the WBC phase map dataset in Supplement Sec. S.2. Previously, researchers used machine learning methods to classify WBC subtypes, including monocyte, granulocyte, B cell, and T cell, by their morphology in a marker-free way~\cite{wbcbrightfield2019Nassae,wbcphase2021shu}. However, the analysis process is computationally heavy and time-consuming. 

Here, we accelerate the marker-free cell analysis process via computing with light. Our G-MFO method strikes a training/validation/testing classification accuracy of $72.1\%/73.3\%/73.8\%$ when classifying $4$ types of WBC using a one-layer optical computing system, exceeding that of the HBT method (Fig.~\ref{fig: all-optical cell classfier}c). Furthermore, Fig.~\ref{fig: all-optical cell classfier}d shows that the inference enabled by optical computing is almost instantaneous ($\frac{d_{IO}+d_{OC}}{c}=1.4 \: ns$, where $c$ is the speed of light), compared to the $1.7\: ms$ of ResNet10, the electronic machine learning model used in \cite{wbcphase2021shu}. We need $1$ more milliseconds of in silico computing of region intensities corresponding to different classes to obtain the prediction. Such a step can be skipped if we use single-photon avalanche diode (SPAD)~\cite{bruschini2019single} point detectors to count the corresponding regions' cumulative signals. Though for now, the performance of our single-layer linear optical computing system is not on par with the electronic neural network, which hits a testing classification accuracy of $90.5\%$ \cite{wbcphase2021shu}, the potential of having ultra-high inference speed and $>70\%$ classification accuracy here point out an exciting direction on further increasing the complexity of our optical computing system to improve the absolute classification accuracy on classifying cells.  




\section{Discussion}

\subsection{Future directions}

\subsubsection{Further apply G-MFO to more complex optical computing systems.}
Exploring the scalability of the optical computing system to more complex optical structures, along with integrating more layers and non-linear activation functions, could potentially enhance absolute performance. 

\subsubsection{Further improve the performance of G-MFO.}
Future research could also consider employing more advanced techniques related to Monte Carlo integration to reduce the training variance discussed in the previous Subsec.~\ref{subsec: G-MFO exhibits curse of dimensionality.}, which we anticipate could substantially broaden the viable search space, thus further empowering the G-MFO approach. These include using more advanced sampling strategies~\cite{caflisch1998monte} or integrating G-MFO with the SBT methods~\cite{kurenkov2021guiding} or adding critic function~\cite{konda1999actor}. The latter two methods trade off the introduced bias and sampling variance.



\subsubsection{Expanding the application of G-MFO to additional computational optics tasks.}
The concept of G-MFO presents promising avenues for application in other areas of computational optics, such as computer-generated holography~\cite{zhao2022model} and lens design~\cite{sitzmann2018end}. The inherent model-free and resource-efficient characteristics of G-MFO position it as a viable alternative to prevalent model-based methods~\cite{blinder2022state, sitzmann2018end}. Future research could focus on leveraging G-MFO to these domains, potentially enhancing computational efficiency and performance.


\subsection{Conclusion}
To conclude, our study underscores the effectiveness of a model-free strategy in training optical computing systems in situ, manifesting considerable potential in computational efficiency and reducing the simulation-to-reality performance gap. Although the study does not focus entirely on absolute image classification accuracy as it is based on a simple single or double diffractive optical computing system without non-linearity, it shows relative improvements compared to the existing training strategies, indicating that our strategy is a potentially valuable approach. The model-agnostic nature of our technique may become even more beneficial when implemented in intricate optical systems, representing a robust and versatile alternative to current strategies. It promises a strong foundation for exploring and practically implementing optical computing in real-world applications such as high-speed marker-free cell analysis. 
















