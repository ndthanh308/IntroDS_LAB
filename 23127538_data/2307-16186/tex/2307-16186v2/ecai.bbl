\begin{thebibliography}{10}

\bibitem{arm}
Fabio Amadio, Adri{\`a} Colom{\'e}, and Carme Torras, `Exploiting symmetries in
  reinforcement learning of bimanual robotic tasks', {\em IEEE Robotics and
  Automation Letters}, {\bf 4}(2),  1838--1845, (2019).

\bibitem{dota2}
Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemys{\l}aw
  D~biak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris
  Hesse, et~al., `Dota 2 with large scale deep reinforcement learning', {\em
  arXiv preprint arXiv:1912.06680}, (2019).

\bibitem{geometric}
Michael~M Bronstein, Joan Bruna, Taco Cohen, and Petar Veli{\v{c}}kovi{\'c},
  `Geometric deep learning: Grids, groups, graphs, geodesics, and gauges', {\em
  arXiv preprint arXiv:2104.13478}, (2021).

\bibitem{bros}
Michael~M Bronstein, Joan Bruna, Taco Cohen, and Petar Veli{\v{c}}kovi{\'c},
  `Geometric deep learning: Grids, groups, graphs, geodesics, and gauges', {\em
  arXiv preprint arXiv:2104.13478}, (2021).

\bibitem{eqcnn}
Taco Cohen and Max Welling, `Group equivariant convolutional networks', in {\em
  International conference on machine learning}, pp. 2990--2999. PMLR, (2016).

\bibitem{stcnn}
Taco~S Cohen and Max Welling, `Steerable {CNNs}', {\em arXiv preprint
  arXiv:1612.08498}, (2016).

\bibitem{s2rphy}
Cristino De~Souza, Rhys Newbury, Akansel Cosgun, Pedro Castillo, Boris Vidolov,
  and Dana Kuli{\'c}, `Decentralized multi-agent pursuit using deep
  reinforcement learning', {\em IEEE Robotics and Automation Letters}, {\bf
  6}(3),  4552--4559, (2021).

\bibitem{ijrr}
Tingxiang Fan, Pinxin Long, Wenxi Liu, and Jia Pan, `Distributed multi-robot
  collision avoidance via deep reinforcement learning for navigation in complex
  scenarios', {\em The International Journal of Robotics Research}, {\bf
  39}(7),  856--892, (2020).

\bibitem{feng2023mact}
Pu~Feng, Xin Yu, Junkang Liang, Wenjun Wu, and Yongkai Tian, `Mact: Multi-agent
  collision avoidance with continuous transition reinforcement learning via
  mixup', in {\em International Conference on Swarm Intelligence}, pp. 74--85.
  Springer, (2023).

\bibitem{rotationm}
Jay~P. Fillmore, `A note on rotation matrices', {\em IEEE Computer Graphics and
  Applications}, {\bf 4}(2),  30--33, (1984).

\bibitem{guo2022towards}
Jun Guo, Yonghong Chen, Yihang Hao, Zixin Yin, Yin Yu, and Simin Li, `Towards
  comprehensive testing on the robustness of cooperative multi-agent
  reinforcement learning', in {\em Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, pp. 115--122, (2022).

\bibitem{otherplay}
Hengyuan Hu, Adam Lerer, Alex Peysakhovich, and Jakob Foerster, `{Other-Play}
  for {Zero-Shot Coordination}', in {\em International Conference on Machine
  Learning}, pp. 4399--4410. PMLR, (2020).

\bibitem{jiangjiechuan}
Jiechuan Jiang, Chen Dun, Tiejun Huang, and Zongqing Lu, `Graph convolutional
  reinforcement learning', {\em arXiv preprint arXiv:1810.09202}, (2018).

\bibitem{pinnsurvey}
George~Em Karniadakis, Ioannis~G Kevrekidis, Lu~Lu, Paris Perdikaris, Sifan
  Wang, and Liu Yang, `Physics-informed machine learning', {\em Nature Reviews
  Physics}, {\bf 3}(6),  422--440, (2021).

\bibitem{subopt}
Naman Khetan, Tushar Arora, Samee~Ur Rehman, and Deepak~K Gupta, `Implicit
  equivariance in convolutional networks', {\em arXiv preprint
  arXiv:2111.14157}, (2021).

\bibitem{curl}
Michael Laskin, Aravind Srinivas, and Pieter Abbeel, `{CURL}: Contrastive
  unsupervised representations for reinforcement learning', in {\em
  International Conference on Machine Learning}, pp. 5639--5650. PMLR, (2020).

\bibitem{rlaug}
Misha Laskin, Kimin Lee, Adam Stooke, Lerrel Pinto, Pieter Abbeel, and Aravind
  Srinivas, `Reinforcement learning with augmented data', {\em Advances in
  Neural Information Processing Systems}, {\bf 33}, (2020).

\bibitem{ITER}
Yijiong Lin, Jiancong Huang, Matthieu Zimmer, Yisheng Guan, Juan Rojas, and
  Paul Weng, `Invariant transform experience replay: Data augmentation for deep
  reinforcement learning', {\em IEEE Robotics and Automation Letters}, {\bf
  5}(4),  6615--6622, (2020).

\bibitem{markov}
Michael~L Littman, `Markov games as a framework for multi-agent reinforcement
  learning', in {\em Machine learning proceedings 1994},  157--163, Elsevier,
  (1994).

\bibitem{GRAPHABS}
Yong Liu, Weixun Wang, Yujing Hu, Jianye Hao, Xingguo Chen, and Yang Gao,
  `Multi-agent game abstraction via graph attention neural network', in {\em
  Proceedings of the AAAI Conference on Artificial Intelligence}, volume~34,
  pp. 7211--7218, (2020).

\bibitem{maddpg}
Ryan Lowe, Yi~Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, and Igor Mordatch,
  `Multi-agent actor-critic for mixed cooperative-competitive environments',
  {\em arXiv preprint arXiv:1706.02275}, (2017).

\bibitem{visionaug}
Guozheng Ma, Zhen Wang, Zhecheng Yuan, Xueqian Wang, Bo~Yuan, and Dacheng Tao,
  `A comprehensive survey of data augmentation in visual reinforcement
  learning', {\em arXiv preprint arXiv:2210.04561}, (2022).

\bibitem{isacgym}
Viktor Makoviychuk, Lukasz Wawrzyniak, Yunrong Guo, Michelle Lu, Kier Storey,
  Miles Macklin, David Hoeller, Nikita Rudin, Arthur Allshire, Ankur Handa,
  et~al., `Isaac {Gym}: High performance {gpu}-based physics simulation for
  robot learning', {\em arXiv preprint arXiv:2108.10470}, (2021).

\bibitem{epuck}
Francesco Mondada, Michael Bonani, Xavier Raemy, James Pugh, Christopher
  Cianci, Adam Klaptocz, Stephane Magnenat, Jean-Christophe Zufferey, Dario
  Floreano, and Alcherio Martinoli, `The {E-puck}, a robot designed for
  education in engineering', in {\em Proceedings of the 9th conference on
  autonomous robot systems and competitions}, volume~1, pp. 59--65. IPCB:
  Instituto Polit{\'e}cnico de Castelo Branco, (2009).

\bibitem{MPE}
Igor Mordatch and Pieter Abbeel, `Emergence of grounded compositional language
  in multi-agent populations', {\em arXiv preprint arXiv:1703.04908}, (2017).

\bibitem{qmix}
Tabish Rashid, Mikayel Samvelyan, Christian Schroeder, Gregory Farquhar, Jakob
  Foerster, and Shimon Whiteson, `{QMIX}: Monotonic value function
  factorisation for deep multi-agent reinforcement learning', in {\em
  International Conference on Machine Learning}, pp. 4295--4304. PMLR, (2018).

\bibitem{report}
B.~Ravindran and A.~G. Barto, `Symmetries and model minimization in markov
  decision processes', Technical report, USA, (2001).

\bibitem{airsim}
Shital Shah, Debadeepta Dey, Chris Lovett, and Ashish Kapoor, `Airsim:
  High-fidelity visual and physical simulation for autonomous vehicles', in
  {\em Field and service robotics}, pp. 621--635. Springer, (2018).

\bibitem{shi2021physics}
Rongye Shi, Zhaobin Mo, and Xuan Di, `Physics-informed deep learning for
  traffic state estimation: A hybrid paradigm informed by second-order traffic
  models', in {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pp. 540--547, (2021).

\bibitem{shi2021tits}
Rongye Shi, Zhaobin Mo, Kuang Huang, Xuan Di, and Qiang Du, `A physics-informed
  deep learning paradigm for traffic state and fundamental diagram estimation',
  {\em IEEE Transactions on Intelligent Transportation Systems}, {\bf 23}(8),
  11688--11698, (2022).

\bibitem{shi2020improving}
Rongye Shi, Peter Steenkiste, and Manuela~M. Veloso, `Improving the on-vehicle
  experience of passengers through sc-m*: A scalable multi-passenger
  multi-criteria mobility planner', {\em IEEE Transactions on Intelligent
  Transportation Systems}, {\bf 22}(2),  1026--1040, (2021).

\bibitem{scale}
Ivan Sosnovik, Micha{\l} Szmaja, and Arnold Smeulders, `Scale-equivariant
  steerable networks', {\em arXiv preprint arXiv:1910.11093}, (2019).

\bibitem{vand}
Elise van~der Pol, Herke van Hoof, Frans~A Oliehoek, and Max Welling,
  `Multi-agent {MDP} homomorphic networks', {\em arXiv preprint
  arXiv:2110.04495}, (2021).

\bibitem{homon}
Elise van~der Pol, Daniel Worrall, Herke van Hoof, Frans Oliehoek, and Max
  Welling, `{MDP} homomorphic networks: Group symmetries in reinforcement
  learning', {\em Advances in Neural Information Processing Systems}, {\bf 33},
  (2020).

\bibitem{so2}
Dian Wang, Robin Walters, and Robert Platt, `$\mathrm{SO}(2)$-equivariant
  reinforcement learning', {\em arXiv preprint arXiv:2203.04439}, (2022).

\bibitem{stee}
Maurice Weiler, Fred~A Hamprecht, and Martin Storath, `Learning steerable
  filters for rotation equivariant {CNNs}', in {\em Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition}, pp. 849--858, (2018).

\bibitem{imageallneed}
Denis Yarats, Ilya Kostrikov, and Rob Fergus, `Image augmentation is all you
  need: Regularizing deep reinforcement learning from pixels', in {\em
  International Conference on Learning Representations}, (2020).

\bibitem{homoaug}
Zhenhui Ye, Yining Chen, Xiaohong Jiang, Guanghua Song, Bowei Yang, and Sheng
  Fan, `Improving sample efficiency in multi-agent actor-critic methods', {\em
  Applied Intelligence},  1--14, (2021).

\bibitem{mappo}
Chao Yu, Akash Velu, Eugene Vinitsky, Yu~Wang, Alexandre Bayen, and Yi~Wu, `The
  surprising effectiveness of {PPO} in cooperative, multi-agent games', {\em
  arXiv preprint arXiv:2103.01955}, (2021).

\bibitem{yu2021swarm}
Xin Yu, Wenjun Wu, Pu~Feng, and Yongkai Tian, `Swarm inverse reinforcement
  learning for biological systems', in {\em 2021 IEEE International Conference
  on Bioinformatics and Biomedicine (BIBM)}, pp. 274--279. IEEE, (2021).

\bibitem{symo}
Martin Zinkevich and Tucker Balch, `Symmetry in markov decision processes and
  its implications for single agent and multi agent learning', in {\em In
  Proceedings of the 18th International Conference on Machine Learning}.
  Citeseer, (2001).

\end{thebibliography}
