\section{Framework}\label{sec:setting}
\subsection{Distributional assumptions} \label{sec:distribassumption}
We use a classical setting for multiple testing encompassing homogeneous and heterogeneous nulls, see e.g. \cite{DDR2018}. 
We observe $X$, defined on an abstract probabilistic space, valued in an observation space
$(\mathcal{X},\mathfrak{X})$ and generated by a distribution $P$ that  belongs to a set $\mathcal{P}$ of possible distributions. 
We consider $m$ null hypotheses for $P$, denoted $H_{0,i}$, $1 \leq i \leq m$,  and we denote the corresponding set of true null hypotheses by $\cH_0(P)=\{1\leq i\leq m\::\: \mbox{$H_{0,i}$ is satisfied by $P$}\}$. 
We also denote by $\cH_1(P)$ the complement of $\cH_0(P)$ in $\{1,\dots,m\}$ and by $m_0(P) =  m_{0} =|\cH_0(P)|$ the number of true nulls.\\
We assume that there exists a set of $p$-values that is a set of random variables $\{p_i(X), 1\leq i \leq m\}$, valued in $[0,1]$. 
We introduce the following dependence assumptions between the $p$-values:
%\begin{align}
%	&\mbox{For all $P\in \mathcal{P}$, $\{p_i(X),  i \in \cH_0(P)\}$ is independent of $\{p_i(X),  i \in \cH_1(P)\}$;}\label{Indep0}\tag{Indep0}\\
%	&\begin{array}{r}	\mbox{\eqref{Indep0} holds and for all $P\in \mathcal{P}$, $\{p_i(X),  i \in \cH_0(P)\}$}\\
%					 \mbox{consists of independent variables.}
%	\end{array}
%	\label{Indep}\tag{Indep}
%\end{align}
{
\begin{align}
	\mbox{All the  $p$-values  $\{p_i(X)$, $1\leq i \leq m\}$ are mutually independent in the model $\mathcal{P}$.}
%	&\mbox{For all $P\in \mathcal{P}$, $\{p_i(X),  i \in \cH_0(P)\}$ is independent of $\{p_i(X),  i \in \cH_1(P)\}$;}\label{Indep0}\tag{Indep0}\\
%	&\begin{array}{r}	\mbox{\eqref{Indep0} holds and for all $P\in \mathcal{P}$, $\{p_i(X),  i \in \cH_0(P)\}$}\\
%					 \mbox{consists of independent variables.}
%	\end{array}
	\label{Indep}\tag{Indep}
\end{align}
}
%Assumptions \eqref{Indep0} and \eqref{Indep} are both satisfied when all the  $p$-values  $\{p_i(X)$, $1\leq i \leq m\}$, are mutually independent in the model $\mathcal{P}$.\\
The (maximum) null cumulative distribution function (c.d.f) of each $p$-value is denoted 
\begin{equation}\label{equ:Fi}
	F_{i}(t) = \sup_{P\in \mathcal{P}\::\: i\in \cH_0(P)} \{\P_{X\sim P}(p_{i}(X)\leq t )\}, \:\: t\in[0,1], \:\:1\leq i\leq m.
\end{equation}
We assume that the set of c.d.f $\mathcal{F} = \{F_{i}, 1\leq i \leq m\}$ is {\it known} and we consider the following possible situations for the functions in $\mathcal{F}$:
\begin{align}
	&\mbox{For all $i \in\{1,\dots,m\}$, $F_i$ is continuous on $[0,1]$} \tag{Cont} \label{cont}\\
	&\begin{array}{c}	\mbox{For all $i \in\{1,\dots,m\}$, there exists some finite %countable 
	set $\mathcal{A}_i\subset [0,1]$ such that}\\
					\mbox{$F_i$ is a step function, right continuous, that jumps only at some points of $\mathcal{A}_i$.}
	\end{array}
	\tag{Discrete} \label{discrete}
\end{align}
The case \eqref{discrete} typically arises when for all $P\in \mathcal{P}$ and $i\in\{1,\dots,m\}$, $\P_{X\sim P}(p_i(X)\in \mathcal{A}_i)=1$ {for some given finite sets $\mathcal{A}_i\subset [0,1]$}.
Throughout the paper, we will assume that we are either in the case \eqref{cont} or \eqref{discrete} and we denote $\mathcal{A}=\cup_{i=1}^m \mathcal{A}_i$, with by convention $\mathcal{A}_i=[0,1]$ when \eqref{cont} holds.
We will also make use of the following classical assumption:
\begin{align}
	&\mbox{For all $i \in\{1,\dots,m\}$,  $F_{i}(t)\leq t$ for all $t\in[0,1]$}.\tag{SuperUnif} \label{superunif}
\end{align}
In this paper we will always assume that the $p$-values are mutually independent (\eqref{Indep} holds) and super-uniform under the null (\eqref{superunif} holds). 

\subsection{FDR control for plug-in estimates} \label{ssec:imc}
The following Theorem is a central result for plug-in FDR control, providing a sufficient condition based on bounding the inverse moment of the estimator $\widehat{m}_0$ by the inverse of $m_0$.  
Our presentation follows \cite{BR2009}, similar results can be found in \cite{benjamini2006adaptive, Sarkar2008, ZZD2011}.
%\footnote{TO DO  iqraa: verify that this equivalent to the condition in BR so we can ref the proof }. 

\begin{theorem}\label{thm:IMC}
	Let $\widehat{m}_0 = \widehat{m}_0(p_1, \ldots, p_m)$ be a coordinatewise non-decreasing function of the $p$-values $(p_1, \ldots, p_m)$. 
	Assume that $(p_1, \ldots, p_m)$ are mutually independent \eqref{Indep} and \eqref{superunif}. 
	For $h \in \nullset$, denote by $ p_{0, h}$ the set of $p$-values where $p_h$ has been replaced by $0$. If 
	\begin{align}
		\E \left( \frac{1}{\widehat{m}_0 ( p_{0, h})}\right) & \le 	
		\frac{1}{m_0} \label{eq:IMC} \tag{IMC}
	\end{align} 
	holds for all $h \in \nullset$, then the plug-in BH procedure given by \eqref{eq:khat:BH} controls FDR  at level $\alpha$.
\end{theorem}

Throughout this paper, we will only consider coordinatewise non-decreasing estimators and  will always assume that the $p$-values are mutually independent. Thus, when additionally \eqref{superunif} holds true, the inverse moment criterion \eqref{eq:IMC} is {sufficient} for establishing plug-in FDR control in our proofs. 
{We mostly present results {in term of the}  absolute number of null hypotheses $m_0$, but {clearly} equivalent statements using the proportion of null hypotheses $\pi_0=m_0/m$ hold, and in some cases we will present results in terms of $\pi_0$ instead of $m_0$.}
%Since we assume mutual independence and \eqref{superunif}  for the $p$-values throughout this paper, and since all  estimators considered here are coordinatewise non-decreasing,  




