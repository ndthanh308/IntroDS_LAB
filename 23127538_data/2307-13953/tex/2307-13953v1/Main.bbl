% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Bahari2012AgeEF}
M.~H. Bahari, M.~McLaren, H.~V. hamme, and D.~A. van Leeuwen, ``Age estimation
  from telephone speech using i-vectors,'' in \emph{Interspeech}, 2012.

\bibitem{McGilloway2000AutomaticRO}
S.~McGilloway, R.~Cowie, and E.~Douglas-Cowie, ``Automatic recognition of
  emotion from voice: a rough benchmark,'' 2000.

\bibitem{Ptacek1966AgeRF}
P.~H. Ptacek and E.~K. Sander, ``Age recognition from voice.'' \emph{Journal of
  speech and hearing research}, vol. 9 2, pp. 273--7, 1966.

\bibitem{Li2019ImprovingTS}
S.~Li, D.~Raj, X.~Lu, P.~Shen, T.~Kawahara, and H.~Kawai, ``Improving
  transformer-based speech recognition systems with compressed structure and
  speech attributes augmentation,'' in \emph{Interspeech}, 2019.

\bibitem{SnchezHevia2022AgeGC}
H.~A. S{\'a}nchez-Hevia, R.~Gil-Pita, M.~Utrilla-Manso, and M.~Rosa-Zurera,
  ``Age group classification and gender recognition from speech with temporal
  convolutional neural networks,'' \emph{Multimedia Tools and Applications},
  vol.~81, pp. 3535 -- 3552, 2022.

\bibitem{Zhang2019AttentionaugmentedEM}
Z.~Zhang, B.~Wu, and B.~Schuller, ``Attention-augmented end-to-end multi-task
  learning for emotion prediction from speech,'' \emph{ICASSP 2019 - 2019 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, pp. 6705--6709, 2019.

\bibitem{Belin2004ThinkingTV}
P.~Belin, S.~Fecteau, and C.~B{\'e}dard, ``Thinking the voice: neural
  correlates of voice perception,'' \emph{Trends in Cognitive Sciences},
  vol.~8, pp. 129--135, 2004.

\bibitem{Hardcastle1999TheHO}
W.~J. Hardcastle and J.~Laver, ``The handbook of phonetic sciences,''
  \emph{Language}, vol.~75, p. 152, 1999.

\bibitem{Oh2019Speech2FaceLT}
T.-H. Oh, T.~Dekel, C.~Kim, I.~Mosseri, W.~T. Freeman, M.~Rubinstein, and
  W.~Matusik, ``Speech2face: Learning the face behind a voice,'' \emph{2019
  IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.
  7531--7540, 2019.

\bibitem{Choi2020FromIT}
H.-S. Choi, C.~Park, and K.~Lee, ``From inference to generation: End-to-end
  fully self-supervised generation of human face from speech,'' \emph{ArXiv},
  vol. abs/2004.05830, 2020.

\bibitem{Wen2019FaceRF}
Y.~Wen, B.~Raj, and R.~Singh, ``Face reconstruction from voice using generative
  adversarial networks,'' in \emph{Neural Information Processing Systems},
  2019.

\bibitem{Goodfellow2014GenerativeAN}
I.~J. Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~C. Courville, and Y.~Bengio, ``Generative adversarial nets,'' in
  \emph{NIPS}, 2014.

\bibitem{Wu2022CrossModalPC}
C.-Y. Wu, C.-C. Hsu, and U.~Neumann, ``Cross-modal perceptionist: Can face
  geometry be gleaned from voices?'' \emph{2022 IEEE/CVF Conference on Computer
  Vision and Pattern Recognition (CVPR)}, pp. 10\,442--10\,451, 2022.

\bibitem{Wu2021Voice2MeshC3}
C.-Y. Wu, K.~Xu, C.-C. Hsu, and U.~Neumann, ``Voice2mesh: Cross-modal 3d face
  model generation from voices,'' \emph{ArXiv}, vol. abs/2104.10299, 2021.

\bibitem{Bull1983TheVA}
R.~H.~C. Bull, H.~Rathborn, and B.~R. Clifford, ``The voice-recognition
  accuracy of blind listeners,'' \emph{Perception}, vol.~12, pp. 223 -- 226,
  1983.

\bibitem{Ravanelli2018SpeakerRF}
M.~Ravanelli and Y.~Bengio, ``Speaker recognition from raw waveform with
  sincnet,'' \emph{2018 IEEE Spoken Language Technology Workshop (SLT)}, pp.
  1021--1028, 2018.

\bibitem{Wang2017LearningUR}
Z.-Q. Wang and I.~Tashev, ``Learning utterance-level representations for speech
  emotion and age/gender recognition using deep neural networks,'' \emph{2017
  IEEE International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, pp. 5150--5154, 2017.

\bibitem{riede2005vocal}
T.~Riede, E.~Bronson, H.~Hatzikirou, and K.~Zuberb{\"u}hler, ``Vocal production
  mechanisms in a non-human primate: morphological data and a model,''
  \emph{Journal of Human Evolution}, vol.~48, no.~1, pp. 85--96, 2005.

\bibitem{Singh2016ForensicAF}
R.~Singh, B.~Raj, and D.~Gençaga, ``Forensic anthropometry from voice: An
  articulatory-phonetic approach,'' \emph{2016 39th International Convention on
  Information and Communication Technology, Electronics and Microelectronics
  (MIPRO)}, pp. 1375--1380, 2016.

\bibitem{Ghiselin1974DarwinAF}
M.~T. Ghiselin, P.~Ekman, and H.~E. Gruber, ``Darwin and facial expression: A
  century of research in review.@@@darwin on man: A psychological study of
  scientific creativity.'' \emph{Systematic Biology}, vol.~23, p. 562, 1974.

\bibitem{Tan2018MnasNetPN}
M.~Tan, B.~Chen, R.~Pang, V.~Vasudevan, and Q.~V. Le, ``Mnasnet: Platform-aware
  neural architecture search for mobile,'' \emph{2019 IEEE/CVF Conference on
  Computer Vision and Pattern Recognition (CVPR)}, pp. 2815--2823, 2018.

\bibitem{He2015DeepRL}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' \emph{2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp. 770--778, 2015.

\bibitem{Xu2022SimpleAE}
Q.~Xu, A.~Baevski, and M.~Auli, ``Simple and effective zero-shot cross-lingual
  phoneme recognition,'' \emph{ArXiv}, vol. abs/2109.11680, 2022.

\bibitem{Ghafourzadeh2019PartBased3F}
D.~Ghafourzadeh, C.~Rahgoshay, S.~Fallahdoust, A.~Beauchamp, A.~Aubame,
  T.~Popa, and E.~Paquette, ``Part-based 3d face morphable model with
  anthropometric local control,'' in \emph{Graphics Interface}, 2019.

\bibitem{Shan2021AnthropometricA}
Z.~Shan, R.~T.~C. Hsung, C.~Zhang, J.~Ji, W.~S. Choi, W.~Wang, Y.~Yang, M.~Gu,
  and B.~S. Khambay, ``Anthropometric﻿ accuracy of three-dimensional average
  faces compared to conventional facial measurements,'' \emph{Scientific
  Reports}, vol.~11, 2021.

\bibitem{Zhuang2010FacialAD}
Z.~Zhuang, D.~Landsittel, S.~M. Benson, R.~J. Roberge, and R.~Shaffer, ``Facial
  anthropometric differences among gender, ethnicity, and age groups.''
  \emph{The Annals of occupational hygiene}, vol. 54 4, pp. 391--402, 2010.

\bibitem{wen2022reconstruction}
Y.~Wen, ``Reconstruction of human faces from voice,'' Ph.D. dissertation,
  Carnegie Mellon University, 2022.

\bibitem{Farkas2004AnthropometricMO}
L.~G. Farkas, O.~G. Eiben, S.~T. Sivkov, B.~Tompson, M.~Kati{\'c}, and C.~R.
  Forrest, ``Anthropometric measurements of the facial framework in adulthood:
  Age-related changes in eight age categories in 600 healthy white north
  americans of european ancestry from 16 to 90 years of age,'' \emph{Journal of
  Craniofacial Surgery}, vol.~15, pp. 288--298, 2004.

\bibitem{Kingma2014AdamAM}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,''
  \emph{CoRR}, vol. abs/1412.6980, 2014.

\end{thebibliography}
