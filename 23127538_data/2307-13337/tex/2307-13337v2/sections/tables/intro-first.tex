\newcommand{\cm}{{\ding{51}}}%
\newcommand{\xm}{{\ding{55}}}%
\begin{table}[!t]
    \centering
    \setlength{\tabcolsep}{1.3mm}
    \caption{
    \textbf{Quantization methods on SR.} For performance, existing methods rely on channel-wise quantization or input-adaptive module, which incur computational overhead. Our method achieves high accuracy without utilizing channel-wise quantization or input-adaptive modules.
    } 
    \resizebox{0.65\linewidth}{!}{
            \begin{tabular}{l cc cc}
                \toprule
                Method & Channel-wise Q & Input-adaptive Modules & PSNR & SSIM \\
                \midrule
                PAMS~\cite{Li2020pams} & \xm & \xm & 29.51 & 0.835\\
                DDTB~\cite{zhong2022ddtb} & \xm & \cm & 30.97 & 0.876\\
                DAQ~\cite{hong2022daq} & \cm & \cm & 31.01 & 0.871\\
                \midrule
                Ours & \xm & \xm & \textbf{31.50} & \textbf{0.882} \\
                \bottomrule
            \end{tabular}
    }
    \label{tab:intro-first}
\end{table}