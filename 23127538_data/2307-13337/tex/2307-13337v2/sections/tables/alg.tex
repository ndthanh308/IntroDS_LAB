\begin{algorithm}[t]
\caption{Quantization-aware training process of ODM} 
\label{algo-odm}
\textbf{Input:} Pre-trained 32-bit network $\gP$. \\
\textbf{Output:} Quantized network $\gQ$.

\begin{algorithmic}
\For{$t=1, \cdots,$ \# iters}
\For{$i=1,\cdots,$ \# layers}
    \If{$t=1$}
        \State Initialize activation quantization range $[l_a, u_a]$
        \State Initialize weight quantization range $[\Minus u_w, u_w]$
    \EndIf
    \State Given quantization range, obtain $q(\mX_i; l_a, u_a)$ using \cref{eq:quant}
    \State Given $\mX_i$ and $q(\mX_i; l_a, u_a)$, obtain mismatch using \cref{eq:mismatch}
    \State {Adjust weight quantization range} $[\Minus u_w, u_w]$ using \cref{eq:weight-ours} 
    \State Given quantization range, obtain $q(\mW_i;\Minus u_w,u_w)$ using \cref{eq:quant}
    \State Replace $\mX_i, \mW_i$ in $\gP$ with $q(\mX_i), q(\mW_i)$
\EndFor
\State Calculate {mismatch regularization loss} (\cref{eq:loss-mismatch}) and reconstruction loss (\cref{eq:loss-rec})
\State Update parameters of $\gQ$ with two losses {cooperatively} using \cref{eq:loss-coop} 
\EndFor
\end{algorithmic}
\end{algorithm}