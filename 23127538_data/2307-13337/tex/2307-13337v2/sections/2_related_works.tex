\section{Related Works}
\label{sec:related_works}
\subsection{Image Super-Resolution}
Convolutional Neural Network (CNN)-based approaches have demonstrated remarkable advancements in the image super-resolution (SR) task~\cite{ledig2017photo,lim2017enhanced}, but at the cost of substantial computational resources.
The intensive computations required by SR networks have spurred interest in developing lightweight SR architectures~\cite{dong2016srcnn,hui2019imdn,hui2018idn,zhang2018rcan,jo2021practical}.
Furthermore, various strategies for lightweight SR networks have been explored, including neural architecture search~\cite{chu2021fast,kim2022fine,li2020dhp,song2020efficient,li2021heterogeneity}, knowledge distillation~\cite{hui2018idn,hui2019imdn,zhang2021data}, and pruning~\cite{jiang2021learning,Oh_2022_CVPR,zhang2022learning}.
While these methods predominantly focus on reducing network depth or the number of channels, our work specifically aims to lower the precision of floating-point operations through network quantization.



\subsection{Network Quantization} 
By mapping 32-bit floating point values of features and weights in convolutional layers to lower-bit representations, network quantization provides a dramatic reduction in computational resources~\cite{cai2017deep,choi2018pact,esser2019learned,jung2019learning,zhou2016dorefa,zhuang2018towards}.
Recent works have successfully quantized various networks to low bit-widths with minimal compromise in accuracy~\cite{cai2020rethinking,dong2019hawq,habi2020hmq,jin2020adabits,lou2019autoq,wang2019haq,yang2020fracbits}.
However, these efforts primarily target high-level vision tasks, whereas networks for low-level vision tasks remain vulnerable to low-bit quantization.



\subsection{Quantized Super-Resolution Networks} 
In contrast to high-level vision tasks, SR poses different challenges due to its inherent high sensitivity to quantization~\cite{ignatov2021real,ma2019efficient,xin2020binarized,Wang2021fully}.
Some works have attempted to recover accuracy by modifying the network architecture~\cite{ayazoglu2021extremely,jiang2021training,xin2020binarized}
or by assigning different bits for each image~\cite{hong2022cadyq,tian2023cabm,Hong_2024_CVPR} or network stage~\cite{liu2021super}.
However, the primary challenge in quantizing SR networks lies in the vastly distinct feature distributions.
To address this, Li \etal~\cite{Li2020pams} adopted a learnable quantization range for different layers.
Subsequently, recognizing that the distributions vary not only by layer, but also by channel and input, Hong \etal~\cite{hong2022daq} introduced a channel-wise dynamic quantization function.
Additionally, Zhong \etal~\cite{zhong2022ddtb} utilized an input-adaptive dynamic module to tailor quantization ranges for each specific input image.
However, such dynamic adaptations of quantization functions during test-time incur non-negligible computational overheads.
Instead of relying on test-time adaptive modules, our approach focuses on mitigating the feature mismatch before quantization.
Our framework reduces the inherent distribution mismatch in SR networks with minimal overhead, accurately quantizing SR networks without dynamic modules.
More recently, Qin \etal~\cite{qin2024quantsr} introduced additional transformation functions in both the forward and backward processes.
However, performance degradation is still evident in ultra-low bit (\eg, 2-bit) scenarios.