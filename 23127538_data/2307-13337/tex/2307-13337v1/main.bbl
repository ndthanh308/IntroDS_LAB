\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agustsson and Timofte(2017)]{agustsson2017ntire}
Eirikur Agustsson and Radu Timofte.
\newblock {NTIRE} 2017 challenge on single image super-resolution: Dataset and
  study.
\newblock In \emph{CVPR Workshops}, 2017.

\bibitem[Ayazoglu(2021)]{ayazoglu2021extremely}
Mustafa Ayazoglu.
\newblock Extremely lightweight quantization robust real-time single-image
  super resolution for mobile devices.
\newblock In \emph{CVPR Workshops}, 2021.

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and
  Courville]{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem[Bevilacqua et~al.(2012)Bevilacqua, Roumy, Guillemot, and
  Alberi-Morel]{bevilacqua2012low}
Marco Bevilacqua, Aline Roumy, Christine Guillemot, and Marie~Line
  Alberi-Morel.
\newblock Low-complexity single-image super-resolution based on nonnegative
  neighbor embedding.
\newblock In \emph{BMVC}, 2012.

\bibitem[Cai and Vasconcelos(2020)]{cai2020rethinking}
Zhaowei Cai and Nuno Vasconcelos.
\newblock Rethinking differentiable search for mixed-precision neural networks.
\newblock In \emph{CVPR}, 2020.

\bibitem[Cai et~al.(2017)Cai, He, Sun, and Vasconcelos]{cai2017deep}
Zhaowei Cai, Xiaodong He, Jian Sun, and Nuno Vasconcelos.
\newblock Deep learning with low precision by half-wave gaussian quantization.
\newblock In \emph{CVPR}, 2017.

\bibitem[Choi et~al.(2018)Choi, Wang, Venkataramani, Chuang, Srinivasan, and
  Gopalakrishnan]{choi2018pact}
Jungwook Choi, Zhuo Wang, Swagath Venkataramani, Pierce I-Jen Chuang,
  Vijayalakshmi Srinivasan, and Kailash Gopalakrishnan.
\newblock Pact: Parameterized clipping activation for quantized neural
  networks.
\newblock \emph{arXiv preprint arXiv:1805.06085}, 2018.

\bibitem[Chu et~al.(2021)Chu, Zhang, Ma, Xu, and Li]{chu2021fast}
Xiangxiang Chu, Bo~Zhang, Hailong Ma, Ruijun Xu, and Qingyuan Li.
\newblock Fast, accurate and lightweight super-resolution with neural
  architecture search.
\newblock In \emph{ICPR}, 2021.

\bibitem[Dong et~al.(2014)Dong, Loy, He, and Tang]{dong2016srcnn}
Chao Dong, Chen~Change Loy, Kaiming He, and Xiaoou Tang.
\newblock Learning a deep convolutional network for image super-resolution.
\newblock In \emph{ECCV}, 2014.

\bibitem[Dong et~al.(2015)Dong, Loy, He, and Tang]{dong2015image}
Chao Dong, Chen~Change Loy, Kaiming He, and Xiaoou Tang.
\newblock Image super-resolution using deep convolutional networks.
\newblock \emph{IEEE TPAMI}, 38\penalty0 (2):\penalty0 295--307, 2015.

\bibitem[Dong et~al.(2019)Dong, Yao, Gholami, Mahoney, and
  Keutzer]{dong2019hawq}
Zhen Dong, Zhewei Yao, Amir Gholami, Michael~W Mahoney, and Kurt Keutzer.
\newblock Hawq: Hessian aware quantization of neural networks with
  mixed-precision.
\newblock In \emph{ICCV}, 2019.

\bibitem[Du et~al.(2018)Du, Czarnecki, Jayakumar, Farajtabar, Pascanu, and
  Lakshminarayanan]{du2018adapting}
Yunshu Du, Wojciech~M Czarnecki, Siddhant~M Jayakumar, Mehrdad Farajtabar,
  Razvan Pascanu, and Balaji Lakshminarayanan.
\newblock Adapting auxiliary losses using gradient similarity.
\newblock \emph{arXiv preprint arXiv:1812.02224}, 2018.

\bibitem[Esser et~al.(2020)Esser, McKinstry, Bablani, Appuswamy, and
  Modha]{esser2019learned}
Steven~K Esser, Jeffrey~L McKinstry, Deepika Bablani, Rathinakumar Appuswamy,
  and Dharmendra~S Modha.
\newblock Learned step size quantization.
\newblock In \emph{ICLR}, 2020.

\bibitem[Gholami et~al.(2021)Gholami, Kim, Dong, Yao, Mahoney, and
  Keutzer]{gholami2021survey}
Amir Gholami, Sehoon Kim, Zhen Dong, Zhewei Yao, Michael~W Mahoney, and Kurt
  Keutzer.
\newblock A survey of quantization methods for efficient neural network
  inference.
\newblock \emph{arXiv preprint arXiv:2103.13630}, 2021.

\bibitem[Habi et~al.(2020)Habi, Jennings, and Netzer]{habi2020hmq}
Hai~Victor Habi, Roy~H Jennings, and Arnon Netzer.
\newblock Hmq: Hardware friendly mixed precision quantization block for cnns.
\newblock In \emph{ECCV}, 2020.

\bibitem[Hong et~al.(2022{\natexlab{a}})Hong, Baik, Kim, Nah, and
  Lee]{hong2022cadyq}
Cheeun Hong, Sungyong Baik, Heewon Kim, Seungjun Nah, and Kyoung~Mu Lee.
\newblock Cadyq: Content-aware dynamic quantization for image super-resolution.
\newblock In \emph{ECCV}, 2022{\natexlab{a}}.

\bibitem[Hong et~al.(2022{\natexlab{b}})Hong, Kim, Baik, Oh, and
  Lee]{hong2022daq}
Cheeun Hong, Heewon Kim, Sungyong Baik, Junghun Oh, and Kyoung~Mu Lee.
\newblock Daq: Channel-wise distribution-aware quantization for deep image
  super-resolution networks.
\newblock In \emph{WACV}, 2022{\natexlab{b}}.

\bibitem[Hou and Kwok(2018)]{hou2018loss}
Lu~Hou and James~T. Kwok.
\newblock Loss-aware weight quantization of deep networks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Huang et~al.(2015)Huang, Singh, and Ahuja]{huang2015single}
Jia-Bin Huang, Abhishek Singh, and Narendra Ahuja.
\newblock Single image super-resolution from transformed self-exemplars.
\newblock In \emph{CVPR}, 2015.

\bibitem[Hui et~al.(2018)Hui, Wang, and Gao]{hui2018idn}
Zheng Hui, Xiumei Wang, and Xinbo Gao.
\newblock Fast and accurate single image super-resolution via information
  distillation network.
\newblock In \emph{CVPR}, 2018.

\bibitem[Hui et~al.(2019)Hui, Gao, Yang, and Wang]{hui2019imdn}
Zheng Hui, Xinbo Gao, Yunchu Yang, and Xiumei Wang.
\newblock Lightweight image super-resolution with information
  multi-distillation network.
\newblock In \emph{ACMMM}, 2019.

\bibitem[Ignatov et~al.(2021)Ignatov, Timofte, Denna, and
  Younes]{ignatov2021real}
Andrey Ignatov, Radu Timofte, Maurizio Denna, and Abdel Younes.
\newblock Real-time quantized image super-resolution on mobile npus, mobile ai
  2021 challenge: Report.
\newblock In \emph{CVPR Workshops}, 2021.

\bibitem[Jiang et~al.(2021)Jiang, Wang, Xin, Li, Yang, and
  Gao]{jiang2021training}
Xinrui Jiang, Nannan Wang, Jingwei Xin, Keyu Li, Xi~Yang, and Xinbo Gao.
\newblock Training binary neural network without batch normalization for image
  super-resolution.
\newblock In \emph{AAAI}, 2021.

\bibitem[Jin et~al.(2020)Jin, Yang, and Liao]{jin2020adabits}
Qing Jin, Linjie Yang, and Zhenyu Liao.
\newblock Adabits: Neural network quantization with adaptive bit-widths.
\newblock In \emph{CVPR}, 2020.

\bibitem[Jo and Kim(2021)]{jo2021practical}
Younghyun Jo and Seon~Joo Kim.
\newblock Practical single-image super-resolution using look-up table.
\newblock In \emph{CVPR}, 2021.

\bibitem[Jung et~al.(2019)Jung, Son, Lee, Son, Han, Kwak, Hwang, and
  Choi]{jung2019learning}
Sangil Jung, Changyong Son, Seohyung Lee, Jinwoo Son, Jae-Joon Han, Youngjun
  Kwak, Sung~Ju Hwang, and Changkyu Choi.
\newblock Learning to quantize deep networks by optimizing quantization
  intervals with task loss.
\newblock In \emph{CVPR}, 2019.

\bibitem[Kim et~al.(2019)Kim, Hong, Han, Myeong, and Lee]{kim2019fine}
Heewon Kim, Seokil Hong, Bohyung Han, Heesoo Myeong, and Kyoung~Mu Lee.
\newblock Fine-grained neural architecture search.
\newblock \emph{arXiv preprint arXiv:1911.07478}, 2019.

\bibitem[Kim et~al.(2016)Kim, Lee, and Lee]{kim2016accurate}
Jiwon Kim, Jungkwon Lee, and Kyoung~Mu Lee.
\newblock Accurate image super-resolution using very deep convolutional
  networks.
\newblock In \emph{CVPR}, 2016.

\bibitem[Ledig et~al.(2017)Ledig, Theis, Huszar, Caballero, Cunningham, Acosta,
  Aitken, Tejani, Totz, Wang, and Shi]{ledig2017photo}
Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham,
  Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang,
  and Wenzhe Shi.
\newblock Photo-realistic single image super-resolution using a generative
  adversarial network.
\newblock In \emph{CVPR}, 2017.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Yan, Lin, Zheng, Zhang, Yang, and
  Ji]{Li2020pams}
Huixia Li, Chenqian Yan, Shaohui Lin, Xiawu Zheng, B.~Zhang, F.~Yang, and
  Rongrong Ji.
\newblock Pams: Quantized super-resolution via parameterized max scale.
\newblock In \emph{ECCV}, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Gu, Zhang, Gool, and
  Timofte]{li2020dhp}
Yawei Li, Shuhang Gu, Kai Zhang, Luc~Van Gool, and Radu Timofte.
\newblock Dhp: Differentiable meta pruning via hypernetworks.
\newblock In \emph{ECCV}, 2020{\natexlab{b}}.

\bibitem[Li et~al.(2021)Li, Li, Danelljan, Zhang, Gu, Van~Gool, and
  Timofte]{li2021heterogeneity}
Yawei Li, Wen Li, Martin Danelljan, Kai Zhang, Shuhang Gu, Luc Van~Gool, and
  Radu Timofte.
\newblock The heterogeneity hypothesis: Finding layer-wise differentiated
  network architectures.
\newblock In \emph{CVPR}, 2021.

\bibitem[Lim et~al.(2017)Lim, Son, Kim, Nah, and Lee]{lim2017enhanced}
Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, and Kyoung~Mu Lee.
\newblock Enhanced deep residual networks for single image super-resolution.
\newblock In \emph{CVPR Workshops}, 2017.

\bibitem[Liu et~al.(2021)Liu, Wang, Zhang, and Shen]{liu2021super}
Jingyu Liu, Qiong Wang, Dunbo Zhang, and Li~Shen.
\newblock Super-resolution model quantized in multi-precision.
\newblock \emph{Electronics}, 10\penalty0 (17):\penalty0 2176, 2021.

\bibitem[Lou et~al.(2020)Lou, Guo, Liu, Kim, and Jiang]{lou2019autoq}
Qian Lou, Feng Guo, Lantao Liu, Minje Kim, and Lei Jiang.
\newblock Auto{Q}: Automated kernel-wise neural network quantization.
\newblock In \emph{ICLR}, 2020.

\bibitem[Ma et~al.(2019)Ma, Xiong, Hu, and Ma]{ma2019efficient}
Yinglan Ma, Hongyu Xiong, Zhe Hu, and Lizhuang Ma.
\newblock Efficient super resolution using binarized neural network.
\newblock In \emph{CVPR Workshops}, 2019.

\bibitem[Martin et~al.(2001)Martin, Fowlkes, Tal, and
  Malik]{martin2001database}
David Martin, Charless Fowlkes, Doron Tal, and Jitendra Malik.
\newblock A database of human segmented natural images and its application to
  evaluating segmentation algorithms and measuring ecological statistics.
\newblock In \emph{Proceedings Eighth IEEE International Conference on Computer
  Vision. ICCV 2001}, volume~2, pages 416--423. IEEE, 2001.

\bibitem[Oh et~al.(2022)Oh, Kim, Nah, Hong, Choi, and Lee]{Oh_2022_CVPR}
Junghun Oh, Heewon Kim, Seungjun Nah, Cheeun Hong, Jonghyun Choi, and Kyoung~Mu
  Lee.
\newblock Attentive fine-grained structured sparsity for image restoration.
\newblock In \emph{CVPR}, 2022.

\bibitem[Song et~al.(2020)Song, Xu, Jia, Chen, Xu, and Wang]{song2020efficient}
Dehua Song, Chang Xu, Xu~Jia, Yiyi Chen, Chunjing Xu, and Yunhe Wang.
\newblock Efficient residual dense block search for image super-resolution.
\newblock In \emph{AAAI}, 2020.

\bibitem[Wang et~al.(2021)Wang, Chen, Zhuang, and Shen]{Wang2021fully}
Hu~Wang, Peng Chen, Bohan Zhuang, and Chunhua Shen.
\newblock Fully quantized image super-resolution networks.
\newblock In \emph{ACMMM}, 2021.

\bibitem[Wang et~al.(2019)Wang, Liu, Lin, Lin, and Han]{wang2019haq}
Kuan Wang, Zhijian Liu, Yujun Lin, Ji~Lin, and Song Han.
\newblock Haq: Hardware-aware automated quantization with mixed precision.
\newblock In \emph{CVPR}, 2019.

\bibitem[Wang et~al.(2004)Wang, Bovik, Sheikh, Simoncelli,
  et~al.]{wang2004image}
Zhou Wang, Alan~C Bovik, Hamid~R Sheikh, Eero~P Simoncelli, et~al.
\newblock Image quality assessment: from error visibility to structural
  similarity.
\newblock \emph{IEEE TIP}, 13\penalty0 (4):\penalty0 600--612, 2004.

\bibitem[Xin et~al.(2020)Xin, Wang, Jiang, Li, Huang, and
  Gao]{xin2020binarized}
Jingwei Xin, Nannan Wang, Xinrui Jiang, Jie Li, Heng Huang, and Xinbo Gao.
\newblock Binarized neural network for single image super resolution.
\newblock In \emph{ECCV}, 2020.

\bibitem[Yang and Jin(2021)]{yang2020fracbits}
Linjie Yang and Qing Jin.
\newblock Fracbits: Mixed precision quantization via fractional bit-widths.
\newblock In \emph{AAAI}, 2021.

\bibitem[Zhang et~al.(2021)Zhang, Chen, Chen, Deng, Xu, and
  Wang]{zhang2021data}
Yiman Zhang, Hanting Chen, Xinghao Chen, Yiping Deng, Chunjing Xu, and Yunhe
  Wang.
\newblock Data-free knowledge distillation for image super-resolution.
\newblock In \emph{CVPR}, 2021.

\bibitem[Zhang et~al.(2018{\natexlab{a}})Zhang, Li, Li, Wang, Zhong, and
  Fu]{zhang2018rcan}
Yulun Zhang, Kunpeng Li, Kai Li, Lichen Wang, Bineng Zhong, and Yun Fu.
\newblock Image super-resolution using very deep residual channel attention
  networks.
\newblock In \emph{ECCV}, 2018{\natexlab{a}}.

\bibitem[Zhang et~al.(2018{\natexlab{b}})Zhang, Tian, Kong, Zhong, and
  Fu]{zhang2018residual}
Yulun Zhang, Yapeng Tian, Yu~Kong, Bineng Zhong, and Yun Fu.
\newblock Residual dense network for image super-resolution.
\newblock In \emph{CVPR}, 2018{\natexlab{b}}.

\bibitem[Zhong et~al.(2022)Zhong, Lin, Li, Li, Shen, Chao, Wu, and
  Ji]{zhong2022ddtb}
Yunshan Zhong, Mingbao Lin, Xunchao Li, Ke~Li, Yunhang Shen, Fei Chao, Yongjian
  Wu, and Rongrong Ji.
\newblock Dynamic dual trainable bounds for ultra-low precision
  super-resolution networks.
\newblock In \emph{ECCV}, 2022.

\bibitem[Zhou et~al.(2016)Zhou, Wu, Ni, Zhou, Wen, and Zou]{zhou2016dorefa}
Shuchang Zhou, Yuxin Wu, Zekun Ni, Xinyu Zhou, He~Wen, and Yuheng Zou.
\newblock Do{R}e{F}a-{N}et: Training low bitwidth convolutional neural networks
  with low bitwidth gradients.
\newblock \emph{arXiv preprint arXiv:1606.06160}, 2016.

\bibitem[Zhuang et~al.(2018)Zhuang, Shen, Tan, Liu, and
  Reid]{zhuang2018towards}
Bohan Zhuang, Chunhua Shen, Mingkui Tan, Lingqiao Liu, and Ian Reid.
\newblock Towards effective low-bitwidth convolutional neural networks.
\newblock In \emph{CVPR}, 2018.

\end{thebibliography}
