\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{setspace}
\usepackage{color}
\usepackage{graphics}
\usepackage{epstopdf}
\usepackage{lipsum}
\usepackage{mwe}
\usepackage{bm}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage[]{mdframed}

\usepackage{colortbl}

\usepackage{float}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{csquotes}
\usepackage[style=authoryear-ibid,backend=biber]{biblatex}
\addbibresource{PSIBiblio.bib} %Import the bibliography file

\usepackage{amsthm}
\theoremstyle{plain}

\newtheorem{definition}{Definition}

\newtheorem{Hypothesis}{Hypothesis}

\title{\vspace{-40pt}The Population Resemblance Statistic: A Chi-Square Measure of Fit for Banking}
\author{CJ Potgieter\footnote{Department of Mathematics, Texas Christian University}, C van Zyl\footnote{Absa Bank Limited; Centre for Business Mathematics and Informatics, North-West University}, WD Schutte\footnote{Absa Bank Limited; Centre for Business Mathematics and Informatics, North-West University}, F Lombard\footnote{University of Johannesburg, posthumous}}
\date{July 2023}

\begin{document} 
	
\doublespacing
\maketitle
\vspace{-40pt}
\begin{center}
\section*{Abstract}
\end{center}
The Population Stability Index (PSI) is a widely used measure in credit risk modeling and monitoring within the banking industry. Its purpose is to monitor for changes in the population underlying a model, such as a scorecard, to ensure that the current population closely resembles the one used during model development. If substantial differences between populations are detected, model reconstruction may be necessary. Despite its widespread use, the origins and properties of the PSI are not well documented. Previous literature has suggested using arbitrary constants as a rule-of-thumb to assess stability, regardless of sample size. However, this approach too often calls for model reconstruction in small sample sizes while not detecting the need often enough in large sample sizes.


This paper introduces an alternative discrepancy measure called the Population Resemblance statistic (PRS). It is based on the Pearson chi-square statistic. Properties of the PRS follow from the non-central chi-square distribution. Notably, the PRS accommodates sample-size dependent critical values and enables the specification of risk tolerances. Its efficacy is demonstrated in a simulation study and with real-world examples. 

\textbf{Keywords}: credit risk, discrepancy measure, low default portfolios, low volume portfolios, population stability, characteristic stability, information value


\newpage
\section{Introduction}

%\textcolor{red}{I want to talk about the outline of the paper. It is what we are proposing, so should get to that pretty fast. I think Section 2 should define PSI and then introduce PR. Then it should outline the proposed procedure in terms of PR. We can say the same type of idea can be applied to PSI, but that Section (???) will illustrate why this is a greater challenge for PSI. We can also discuss how both of the measures fit into the larger literature framework of information theory. Now that we have the PR procedure formulated, we can take a step back. Discuss the Lewis constants and why these are a problem. Show relevant simulation. Next, show convergence issues with PSI compared to PR. Fig 1 and 2 can come into play here, also show how PSI is unbounded but PR is not (check on this).}

The Population Stability Index (PSI) is a commonly used metric for assessing the degree of discrepancy, conversely similarity, between two discrete probability distributions. The PSI is used in diverse fields including banking and credit risk modeling {(see \textcite[pp. 155 ff.]{thomas2002credit} and \textcite[pp. 368 ff.]{siddiqi2017intelligent}), insurance, healthcare, and engineering {(see \textcite{huang}, \textcite{li}, \textcite{sahu}, \textcite{dong2022prediction}, \textcite{wu2010enterprise}, \textcite{mcadams2022risk}, \textcite{chou2022expert} and \textcite{karakoulas2004empirical})}.} The PSI measure is based on the Kullback-Leibler divergence, a measure of the difference between two probability distributions {\parencite[eq. (2.6)]{kullback1951information}}. Its primary use in the banking sector is to monitor the evolution  of the population underlying a model and {to} determine whether the current population {\textit{resembles}} the one used during model development, as required by prudential authorities (see \textcite{ecb2023validation, ecb2019internalmodels}, \textcite{federalreserve2023sr1107a1}, \textcite{resbank2022credit}; and \textcite{pruitt2010applied} for an application of the PSI in $SAS^\text{\textregistered}$). If there is a significant \textit{discrepancy}, the model may be at risk of misstating the outcome of interest. For instance, when scorecards are developed, the objective is to compare the distribution of scores of a current set of applicants with that of the population used during the development of the model. {Here, the word \textit{resembles} is used in the sense of difference by no more than an specified small deviation - see Definition \ref{deltaresemblance} in Section \ref{sec: measuring resemblance}.} {\textcite[p. 106]{lewis1994introduction} omits formulating a hypothesis in the statistical sense, but also describes the problem as ``If a user finds the distribution of scores \textit{close together} [not strictly equal], he can be confident that the population has not changed.''}

Despite its widespread use, the origins and properties of the PSI are not widely understood. The earliest reference to this measure can be found in Lewis (1994), who also coined the term ``Population Stability Index'', used therein as a quantification of the degree of \textit{resemblance} between the two distributions. Decision constants are used to decide whether the model development population and the current population are \textit{discrepant}. Lewis suggests {in his example} that a PSI value under 0.10 indicates that the current population resembles the original and no action is required. A value between 0.10 and 0.25 suggests that some investigation should be undertaken to identify the source of the difference. A value over 0.25 suggests that there has been a substantial change in either the incoming population or the policies of the user and may prompt a model reconstruction. The decision constants 0.1 and 0.25 will be referred to as the \textit{Lewis constants}. {The use of these constants as a ``rule of thumb'' {are} popular in the literature and practice. For instance, both of the widely read {credit risk modelling} texts of \textcite[p. 155 ff.]{thomas2002credit} and \textcite[p. 368 ff.]{siddiqi2017intelligent} mention these (while also alluding to its arbitrary nature). However, it's important to note that these decision constants are not universally accepted and their arbitrary nature has been acknowledged by several authors {(for example, \textcite{yurdakul2020statistical} and \textcite{dupisanievisagie2020})} and practitioners \parencite{moodys2021email}. Therefore, it's crucial for practitioners to be aware of the limitations of this metric and to interpret the results with caution.}

{In this paper we present an easy-to-use and novel alternative discrepancy measure - the {Population Resemblance statistic (PRS)} - based on the Pearson chi-square statistic and the non-central chi-square distribution. In Section \ref{sec: measuring resemblance} we formalise the problem and propose the PRS as solution, while listing some additional measures available in the literature. The PRS offers statistically well-founded properties, see Section \ref{sec: PRS properties}, resulting in sample-size dependent decision constants (Section \ref{sec:Critical Values}). We demonstrate the efficacy of the PRS measure in Section \ref{sec: PRS simulation} by means of a simulation study, followed by a  real-world application (Section \ref{Application}), comparing the PRS with the popular PSI and some other measures. These examples also serve to illustrate the efficacy of the PRS in small sample sizes often encountered in low default portfolios. }


\section{Measuring Population Resemblance}

\label{sec: measuring resemblance}

Consider a set of observed scores, denoted $x_1, x_2, \ldots, x_n$, assumed to be a random sample from a discrete population with distribution function $F$ taking values in the set $\{1,2,\ldots,B\}$. Thus, each score can be thought of as indicating membership in one of $B$ possible categories. Let $n_i$ represent the number of scores in category $i$, i.e. $n_i = \sum_{j=1}^{n} \mathbb{I}(x_j \in i)$. Here $\mathbb{I}(A)$ is the indicator function that equals $1$ when $A$ is true and $0$ otherwise. The total number of observed scores can be recovered $n = \sum_{i=1}^{B} n_i$. The true category probabilities are $p_{i} = F(i)-F(i-1)$ for $i=1,\ldots,B$, while the estimated probabilities based on the observed scores are $\hat{\mathbf{p}} = (\hat{p}_1, \hat{p}_2, \ldots, \hat{p}_B)$ where $\hat{p}_i = n_i/n$ for $i = 1, 2, \ldots, B$. 

The problem at hand is to determine whether the current population characterised by $\mathbf{p}$ resembles the population used to construct a model of interest, say $\mathbf{p}_0 = (p_{01}, p_{02}, \ldots, p_{0B})$. The nature of this model is not germane. Rather, the question is whether there is evidence that $\mathbf{p}$ has changed ``substantively'' from, or still ``resembles'', the model constructed $\mathbf{p}_0$. In practice, the current population $\mathbf{p}$ is unknown, but $\hat{\mathbf{p}}$ represents an unbiased estimator of this quantity. In fact, assume that $\mathbf{p}$ is a column vector, random variable $n\hat{\mathbf{p}}$ follows a multinomial distribution with $$\mathrm{E}[n\hat{\mathbf{p}}] = n\mathbf{p} \quad \mathrm{and}\quad \mathrm{Var}[n\hat{\mathbf{p}}] = n\Big[\mathrm{diag}(\mathbf{p})-\mathbf{p}\mathbf{p}^\top\Big].$$

One measure that is currently used ubiquitously to compare the model construction and current populations is the Population Stability Index (PSI) of \textcite{lewis1994introduction}. The PSI is defined as,
\begin{equation}
\mathrm{PSI} = \sum_{j=1}^{B} (\hat{p}_{j}-p_{0j})(\log{\hat{p}_j}-\log{p_{0j}})\mathbb{I}(\hat{p}_{j}>0),
\label{PSI_eqn}
\end{equation}
which is a consistent estimator of the symmetric Kullback-Leibler divergence
\begin{equation}
	\label{Kullback J2}
	J := J(\mathbf{p},\mathbf{p}_0) = \sum_{j=1}^{B} ({p}_j-{p}_{0j})(\log{{p}_j}-\log{{p}_{0j}}).
\end{equation}
The interested reader is referred to Appendix \ref{sec: info theory} for an in-depth discussion of the information-theoretic perspective on the problem. Other measures, frequently used in risk modelling, estimators of $J$, include the information value (IV) \parencite[p. 184]{siddiqi2017intelligent} and characteristic (or system) stability index (CSI) \parencite[p. 369]{siddiqi2017intelligent}, measuring for attributes in a model, respectively, the total strength to distinguish between defaults and non-defaults, and between observed and expected. Current implementation of the PSI does not rely on any considerations of the statistical properties of the underlying statistics, instead making use of arbitrary threshold values proposed by \textcite{lewis1994introduction} to evaluate the evidence for or against population stability. Suggested thresholds, also arbitrary, for the IV can be found in \textcite[p. 185]{siddiqi2017intelligent}, and they are different from the Lewis constants.

An alternative measure comparing two distributions is the chi-square divergence, 
\begin{equation}
    \label{ChiSq}
	\chi^2 := \chi^2(\mathbf{p},\mathbf{p}_0) = \sum_{i=1}^{B} \frac{(p_i-p_{0i})^2}{p_{0i}}.
\end{equation}
Based on $\chi^2$, we introduce the (unnormed) Population Resemblance statistic
\begin{equation}
\mathrm{PRS} = \sum_{j=1}^{B} \frac{(\hat{p}_{j}-p_{0j})^2}{p_{0j}},
\label{PR_eqn}
\end{equation}
noting that $\mathrm{PRS}$ is a consistent estimator of the chi-square divergence $\chi^2$.

Other measures have also been considered in the literature. For example, the Kolmogorov-Smirnov statistic \parencite{dagostino1986goodness}
$$\mathrm{KS} = \max_{j=1,\ldots,B} |\hat{F}(j) -  F_0(j)| = \max_{j=1,\ldots,B} \Big|\sum_{i=1}^{j}\hat{p}_i -  \sum_{i=1}^{j} p_{0i}\Big| $$
as well as the {coefficient of overlap} (see \textcite{inman1984behavior} and references therein)
$$\mathrm{OVL} = \sum_{j=1}^{B} \min(\hat{p}_j,p_{0j}),$$
with some distributional properties ibid. For the latter two measures, it is easily verified that $\mathrm{OVL}\geq \mathrm{KS}/2 - 1$. Moreover, \textcite{komaba2022novel} prove the equivalence of these two measures. More recently, \textcite{dupisanievisagie2020} suggested use of $$ DPV=\max_{j=1,...,B} \frac{|p_j-p_{0j}|}{{p_{0j}}},$$
using a Monte Carlo simulation to arrive at thresholds. Distributional properties for $DPV$ is not available. A class of power-divergence statistics indexed by a real parameter $\gamma$ is also given in \textcite{cressie1984multinomial},
$$\mathrm{I}_{\gamma} = \frac{1}{\gamma(\gamma-1)}\sum_{j=1}^{B}\hat{p}_j \Big\{\Big(\frac{\hat{p}_j}{p_{0j}}\Big)^\gamma - 1\Big\}, \ \gamma \in \mathbb{R}.$$
When appropriately normed, the PSI, PRS, and I$_\gamma$ measures all converge to a chi-square distribution for $\mathbf{p}=\mathbf{p}_0$. The limiting distribution of the KS measure under such a ``null hypothesis'' scenario is also known. These measures are by no means comprehensive in terms of criteria assessing the fit of multinomial distributions; \textcite{agresti2012categorical} can be consulted for a more in-depth discussion.

While all of these measures have merit, the focus of this paper is not a comprehensive review and comparison. In this paper, we focus on discussing the deficiencies of the PSI, both as currently implemented and as a measure of fit. We then show how the PRS alleviates these concerns. Furthermore, we will establish statistical properties of the PRS not only when the two populations are equal, but also under an assumption of population drift where the current population has shifted relative to the model construction population. To this end, we introduce a notion of two populations being $\delta$-resemblant, and consider the behaviour of the PRS within this framework.

\begin{definition}\label{deltaresemblance}[$\delta$-resemblance]
Let $\delta>0$. For the probability vector $\mathbf{p}_0=(p_{01},\ldots,p_{0B})$, define the region  $$\mathcal{P}(\delta|\mathbf{p}_0) = \Bigg\{\tilde{\mathbf{p}} = (\tilde{p}_1,\ldots,\tilde{p}_B) : \max_{j=1,\ldots,B} |p_{0j} - \tilde{p}_j| \leq \delta,\ \sum_{j=1}^{B}\tilde{p}_j = 1 \Bigg\}.$$ The probability vector $\mathbf{p}=(p_{1},\ldots,p_{B})$ is said to be $\delta$-resemblant of $\mathbf{p}_0$ whenever $\mathbf{p}\in \mathcal{P}(\delta|\mathbf{p}_0)$.
\end{definition}

Intuitively, $\mathcal{P}(\delta|\mathbf{p}_0)$ represents the set of all valid probability vectors where the largest deviation from any element in $\mathbf{p}_0$ is no greater than $\delta$, a tolerance constant. To illustrate, say we have $B=5$ categories with $\mathbf{p}_0 = (0.2,0.2,0.2,0.2,0.2)$. Consider $\delta=0.02$. For probabilities $\mathbf{p}_1 = (0.18,0.22,0.2,0.19,0.21)$, the maximum deviation between any two corresponding categories is $0.02$, meaning $\mathbf{p}_1$ is inside $\mathcal{P}(0.02|\mathbf{p}_0)$ and $\mathbf{p}_1$ is said to $\delta$-resemble $\mathbf{p}_0$ at $\delta=0.02$. On the other hand, $\mathbf{p}_2 = (0.15,0.2,0.2,0.2,0.25)$ is not inside $\mathcal{P}(0.02|\mathbf{p}_0)$ as some probabilities differ from $\mathbf{p}_0$ by more than $0.02$. Thus, $\mathbf{p}_2$ does not $\delta$-resemble $\mathbf{p}_0$ at $\delta=0.02$.

In light of Lewis' statement \parencite[p. 106]{lewis1994introduction}, ``If a user finds the distribution of scores \textit{close together}, he can be confident that the population has not changed'', we formulate the hypothesis as follows. 
\begin{Hypothesis}
\label{Hyp1}
Test  $H_0 : \mathbf{p} \in \mathbf{P}_0(\bm{\delta})$ against the alternative $H_A : \mathbf{p} \not\in \mathbf{P}_0(\bm{\delta})$, treating $\mathbf{p_0}$ as fixed and known.
\end{Hypothesis}
In the context of credit risk model monitoring, a hypothesis as in \ref{Hyp1}, connecting to Lewis' \parencite{lewis1994introduction} statement of ``closeness'' has to date not been formulated. To our knowledge, the null hypothesis involving exact equality is referenced universally (see, for example \textcite{pisanie2023critical}). Moreover, a two-sample formulation of the problem (treating $\mathbf{p_0}$ as a random variable) seemed natural. In practice, however, this approach faces several challenges including dependence between the model construction and current sample, which may stem from at least temporal evolution and overlapping data. To address the issue of non-independence between the samples, we have thus resorted to a one-sample problem formulation, treating the model constructed probabilities $\mathbf{p_0}$ as fixed and known. Even in situations as described where the model constructed probabilities was established using sampling tools, the one-sample approach can still be employed, providing a conditional inference solution. %Future work should aim to quantify temporal dependence and sample overlap to define a solution recognizing the variability in

%\textcolor{red}{The focus of this paper is on comparing two populations in the context of credit risk modeling, which corresponds to the goodness-of-fit problem of testing whether a sample originates from a multinomial population with known success probabilities derived from the model construction phase. However, in practice, the probabilities associated with the model construction phase are estimated from a sample. Therefore, it is desirable to develop inferential tools treating this as a two-sample problem. However, implementing the two-sample formulation poses challenges due to the lack of independence between the samples collected during the development and current phases. }

%\textcolor{red}{Dependencies between the development and current samples may stem from at least two sources: temporal evolution and overlapping data. Temporal dependence arises because the samples capture the evolution of the underlying population over time. Thus, one may think of the population itself being a temporal process. On the other hand, overlapping data occurs when organizations periodically collect data, and the same cases appear in both the development and current samples. This overlap can create inter-dependencies, even if the cases have different values.}

%\textcolor{red}{Thus, while the two-sample formulation seems natural, where one sample is used for model development and the other for assessing population stability, this approach faces several challenges in practice. To address the issue of non-independence between the samples, we have resorted to a one-sample problem formulation, treating the reference probabilities $\mathbf{p}0$ as fixed and known. Even in situations as described where the baseline was established using sampling tools, the one-sample approach can still be employed, providing a conditional inference solution. Future work should aim to quantify temporal dependence and sample overlap to define a solution recognizing the variability in }




In Section \ref{sec: PRS properties}, we consider the behaviour of the PSI and PRS under an assumption of no population drift, $\mathbf{p}=\mathbf{p}_0$. We also consider the properties of the PRS when $\mathbf{p}$ is $\delta$-resemblant of $\mathbf{p}_0$. Finally, we discuss how to choose appropriate values of $\delta$ for PRS to assess whether population drift has taken place, or whether the populations still show evidence of resembling one another.

\section{Statistical Properties of Population Resemblance}
\label{sec: PRS properties}

\subsection{Comparing the PSI and PRS}
\label{sec: comp PSI PRS}

In this section, we considered asymptotic properties of the PSI and PRS as defined in Section \ref{sec: measuring resemblance} under the assumption that the current population $\mathbf{p}$ is equal to the model constructed population $\mathbf{p}_0$. For $$T_n = n\cdot \mathrm{PSI} \quad \mathrm{and}\quad Q_n = n\cdot \mathrm{PRS},$$ we note that both $T_n$ and $Q_n$ have limiting $\chi^2_{B-1}$ distributions. Despite the asymptotic distribution of $T_n$ being well-established \parencite[Chapter 6]{kullback1978information}, in his example \textcite{lewis1994introduction} suggests PSI thresholds of $0.1$ and $0.25$, with $\mathrm{PSI}< 0.1$ indicating the current population is similar to the original and no action is necessary, and $\mathrm{PSI}\geq 0.25$ indicating model reconstruction is required. Henceforth, we refer to such constants as ``thresholds'', whereas the term ``critical value'' will allude to rules of thumb based on some probabilistic assumption.

A simulation study presented below illustrates concerns around decision making reliant on the Lewis constants. Data were generated under two scenarios, both having equal category probabilities for the reference distribution, $\mathbf{p}_0 = (1/B,\ldots,1/B)$. The first simulation scenario assumed no population drift, so that $\mathbf{p}=\mathbf{p}_0$ and $J(\mathbf{p},\mathbf{p}_0) = 0$. The second scenario assumed the current probabilities $\mathbf{p}$ differ from the model construction probabilities $\mathbf{p}_0$ so that $J(\mathbf{p},\mathbf{p}_0) = 0.1$ to be consistent with the statement by \textcite[p. 106]{lewis1994introduction}, ``If a user finds the distribution of scores \textit{close together}, he can be confident that the population has not changed.'' Of interest is evaluating the probability that model reconstruction is recommended, $P(\mathrm{PSI}\geq 0.25).$ These estimated probabilities summarized in Table \ref{TABLE1} were calculated from $K=1,000,000$ simulated datasets under each configuration so that the maximum standard error of simulation is $0.0005$.

\begin{center}
\begin{tabular}{|c|c|c|c|c|}
 \cline{2-5} 
\multicolumn{1}{c|}{} & \multicolumn{2}{|c|}{$J=0$} & \multicolumn{2}{|c|}{$J=0.1$} \\  
 \cline{2-5} 
\multicolumn{1}{c|}{} & $B=5$ & $B=10$ & $B=5$ & $B=10$ \\ \hline
$n=50$ & 0.0226 & \textbf{0.2356} & \textbf{0.2542} & \textbf{0.5459}\\ \hline 
$n=100$ &  0.0001 & 0.0086 & 0.0872 & \textbf{0.2508} \\ \hline 
$n=200$ & \textit{0.0000} & \textit{0.0000} & 0.0131 & 0.0434 \\ \hline 
$n=500$ &  \textit{0.0000} & \textit{0.0000} & \textit{0.0001} & \textit{0.0003} \\ \hline 
\end{tabular}
\captionof{table}{Monte Carlo estimates of $P(\mathrm{PSI}\geq 0.25)$ under two scenarios.}
\label{TABLE1}
\end{center}

Table \ref{TABLE1} clearly indicates that the probability of mandating a full model reconstruction is unacceptably high in several cases (indicated in boldface). Moreover, where $n$ is larger, this probability is negligibly small - almost equal to zero (indicated in italics) even when moderate population drift has taken place. This simulation study highlights the need to find a more appropriate metric and/or rules of thumb. The universal application of the Lewis constants disregards both the number of categories $B$ and the size $n$ of the dataset from the current population. 

A plausible motivation for the Lewis constants could have been that these values correspond to specific levels of discrepancy between the model construction population and the current population. Appendix \ref{sec: model deviance} examines this possible link by setting the PSI equal to one of the Lewis constants and then evaluating the implication for the underlying population, thereby gaining insight into the degree of resemblance between the two populations. We employ an optimization technique to find both minimum and maximum deviances. Two findings emerge: firstly, as a result of the unboundedness of the PSI, the deviance given a specified PSI is rapidly increasing; likewise the maximum and minimum. Secondly, a small deviance can still result in a large PSI. 

Given that $T_n$ and $Q_n$ have limiting $\chi^2_{B-1}$ distributions when there is no population drift, a naive approach to assessing population resemblance would be to consider two discrete populations to be similar if and only if their distribution functions are strictly equal. This can be formulated as the simple null hypothesis $H_0: \mathbf{p} = \mathbf{p}_0$ where $\mathbf{p}_0$ represents the model construction probabilities, and $\hat{\mathbf{p}}$ represents the estimates obtained from the current sample. The alternative is a simple contradiction of the null, $H_a: \mathbf{p} \neq \mathbf{p}_0$, meaning at least two of the underlying probabilities differ from one another. Under this naive approach (as in \textcite{yurdakul2020statistical}), PSI and/or PRS critical values (lower and upper, respectively) to assess population resemblance can be calculated as  $c_{\mathrm{l}}=F_{B-1}^{-1}(1-\alpha_1)/n$ and $c_{\mathrm{u}}=F_{B-1}^{-1}(1-\alpha_2)/n$ where $F_{m}^{-1}(\cdot)$ denotes the inverse chi-square cumulative distribution function with $m$ degrees of freedom. The significance levels $\alpha_1 > \alpha_2$ are pre-specified based on the specific context and requirements of the population comparison being carried out.

Even this naive approach does not alleviate all concerns with the PSI. Under the assumption of equal populations, we have $\mathrm{E}[T_n] \xrightarrow[\infty]{n} B-1$ and $\mathrm{E}[Q_n] \xrightarrow[\infty]{n} B-1$. Similarly, we have
$\mathrm{Var}[T_n] \xrightarrow[\infty]{n} 2(B-1)$ and $\mathrm{Var}[Q_n] \xrightarrow[\infty]{n} 2(B-1)$. The small-sample stability of the PSI and PRS can be evaluated using the ratios
$$R_{T_n}^{(1)} = \frac{\mathrm{E}[T_n]}{B-1} \qquad \mathrm{and} \qquad R_{T_n}^{(2)} = \frac{\mathrm{Var}[T_n]}{2(B-1)}$$ with similar definitions holding for $R_{Q_n}^{(1)}$ and $R_{Q_n}^{(2)}$. The required finite-sample expectations and variances can be calculated to arbitrary accuracy using Monte Carlo sampling.

This was done for sample sizes $n\in\{25,30,\ldots,100\}$, and a total of $K=100,000$ samples were generated and the measures $T_n$ and $Q_n$ were calculated. Based on these, the estimated mean stability ratios $R^{(1)}$ and variance stability ratios $R^{(2)}$ are shown for $B=5$ categories in Figures \ref{fig: Mean Stab Ratios} and \ref{fig: Var Stab Ratios}.

% Figure environment removed

It is clear from the figures that the normed PRS ($Q_n$) has stable behaviour even at the smallest sample size considered with the mean and variance ratios very close to $1$. On the other hand, the normed PSI ($T_n$) has small-sample behaviour that depends greatly on the underlying sample size. For the latter measure, at a sample size of $n=100$, the empirical mean still exceeds the asymptotic mean by about $5\%$, while the empirical variance exceeds the asymptotic variance by about $20\%$. Of course, while we need not be beholden to asymptotic results, it certainly simplifies matters when these can be relied upon as reasonable approximations in finite sample settings. To this end, we argue that the PRS is a more natural choice that the currently-used PSI.

\subsection{PRS properties under $\delta$-resemblance}

In this subsection, we consider the behaviour of the PRS based on the assumption that the two populations are $\delta$-resemblant. To this end, it is important to understand the behaviour of $Q_n = n\cdot \mathrm{PRS}$ not just when $\mathbf{p}_0$ represents the true value, but for all distributions in $\mathcal{P}(\delta|\mathbf{p}_0)$. Let $\delta_j = \xi_j/\sqrt{n}$ for $j=1,\ldots,B$, and assume the true current probabilities satisfy $p_j = p_{0j} + \delta_j = p_{0j} + \xi_j/\sqrt{n}$. Then, $Q_n  \xrightarrow[\infty]{n} \chi_{B-1}^{2}(\lambda)$ with $$\lambda = \sum_j \frac{\xi_j^2}{p_{0j}} = \sum_j n\times \frac{(p_j - p_{0j})^2}{p_{0j}}$$ i.e. the normed PRS converges to a non-central chi-square distribution with $B-1$ degrees of freedom and non-centrality parameter $\lambda$. 

Since the true value of the current probability vector $\mathbf{p}$ is unknown, the most conservative approach is to base a statistic on the largest possible value of the non-centrality parameter when the populations are $\delta$-resemblant. This requires calculating
\begin{equation}
    \lambda_{\mathrm{sup}} = \sup_{\mathbf{p}\in\mathcal{P}(\delta|\mathbf{p}_0)} \sum_j  \frac{n\ (p_j - p_{0j})^2}{p_{0j}}.
    \label{eq:noncentral parm}
\end{equation} Details of simplifying this optimization problem in a general context are presented in Appendix \ref{sec: Appendix 1}. Letting $\mathbf{x}=(x_1,\ldots,x_B)$ be a vector with entries $x_j\in\{-1,0,1\}$ and defining $$h(\mathbf{x},\mathbf{p}) = \frac{\sum_j x_j}{\sum_j p_j(1-x_j^2)} \ \mathrm{for}\ \sum_j x_j^2 < B$$ with $h(\mathbf{x},\mathbf{p})$ taking the value $0$ otherwise, we have $$\lambda_{\mathrm{sup}} = n\delta^2 \max_{\mathbf{x}:x_j\in\{- 1,0,1\}} \sum_{j=1}^{B}\frac{x_j^2-h^2(\mathbf{x},\mathbf{p}_0)(1-x_j^2)p_{0j}}{p_{0j}}.$$
Thus, the non-centrality parameter is proportional to $n$, the sample size, and $\delta^2$, the square of the specified tolerance constant. The remaining maximization problem can be found through an exhaustive search of the $3^B$ possible vectors $\mathbf{x}$ with entries restricted to $\{-1,0,1\}$. In the special case where the reference distribution specifies equal baseline probabilities, $\mathbf{p}_{0}=(1/B,\ldots,1/B)$, we have $$\lambda_{\mathrm{sup}} =
\left\{
	\begin{array}{ll}
		nB^2\delta^2  & \mbox{if } B\text{ is even,} \\
		nB(B-1)\delta^2 & \mbox{if } B\text{ is odd.}
	\end{array}
\right.$$

\subsection{Calculating Critical Values for the PRS}
\label{sec:Critical Values}

There are two approaches one can take to determine critical values for the PRS criterion. The first approach, a direct one, relies on the practitioner specifying the tolerance constant $\delta$ to define when two distributions are $\delta$-resemblant. Conversely, the indirect approach treats $\delta$ as an implicit parameter and instead requires the specification of a factor $M\geq 1$. This factor indicates that the population drift is unacceptable and model reconstruction is required if the populations are not $M\delta$-resemblant. Additionally, the indirect approach necessitates the specification of a power level, i.e. the probability with which model reconstruction should be deemed necessary when the populations are not $M\delta$-resemblant. 

While the first approach appears simpler, it is important to consider that $\delta$ should be chosen inversely proportional to sample size, $\delta \propto n^{-1/2}$ for the non-central chi-square limiting distribution to provide a valid approximation. Providing guidance on this matter may be challenging. On the other hand, the indirect approach provides critical values as well as a sample-size dependent tolerance constant $\delta$.

For the \textit{direct} approach, assume that the tolerance level $\delta$ has been specified. Furthermore, assume significance levels $\alpha_{l}>\alpha_{u}$ have also been specified. Define critical values $c_l < c_u$ according to $c_l = F^{-1}(1-\alpha_l|B-1,\lambda)/n$ and $c_u = F^{-1}(1-\alpha_u|B-1,\lambda)/n$ where $F^{-1}(q|m,\lambda)$ denotes the inverse cumulative distribution function of the non-central chi-square distribution with $m$ degrees of freedom and non-centrality parameter $\lambda$. When $Q_n = n\ \mathrm{PRS} \sim \chi^2_{B-1}(\lambda_{\mathrm{sup}})$, we have $P(\mathrm{PRS} < c_l) \approx 1-\alpha_l$ and $P(\mathrm{PRS} \geq c_u) = \alpha_u$. Thus, when $\mathrm{PRS} < c_l$ we deem the current population $\mathbf{p}$ to be $\delta$-resemblant, when $c_l\leq\mathrm{PRS} < c_u$ further investigation is warranted, while when $\mathrm{PRS} \geq c_u$ the current population is deemed to no longer be $\delta$-resemblant and model reconstruction is necessitated. 

For the \textit{indirect} approach, it is helpful to refer to the illustration in Figure \ref{fig:Mdelta}. The values $\alpha_u$ and $1-\beta$ both represent probabilities associated with model reconstruction. In the first case, $\alpha_u$ is specified with respect to a current population that is $\delta$-resemblant to $\mathbf{p}_0$, indicating model reconstruction is not necessary. In contrast, $1-\beta$ is specified with respect to a current population that is $M\delta$-resemblant to $\mathbf{p}_0$, highlighting the urgent need for model reconstruction. 

% Figure environment removed

Therefore, when calculating the upper critical value $c_u$, one must specify $\alpha_u$ (a small probability) and $1-\beta$ (a large probability), along with a constant $M$ that signifies a multiplicative factor. The factor $M$ denotes the unacceptability of deviations of $M\delta$ or greater, signalling that model reconstruction is be required. To solve for the critical value $c_u$ as well as the implied tolerance level $\delta$, the following two equations must be solved simultaneously (in terms of $c_u$ and $\lambda$),
\begin{eqnarray}
    F(c_u|B-1,\lambda) &=& 1-\alpha_u, \notag\\
    F(c_u|B-1,M^2\lambda) &=& \beta. \notag 
\end{eqnarray}
The solution $\lambda$ can then be used to identify the corresponding tolerance level $\delta$ according to \eqref{eq: delta to lambda}. This implied value $\delta$ can then be used to calculate the associated $\lambda$ and to find the lower bound $$c_l = F^{-1}(1-\alpha_l|B-1,\lambda).$$ Note that in this approach, the upper bound $c_u$ is determined based on an assumption of ``excessive population drift'', and should rarely be crossed unless model reconstruction really is necessary. On the other hand, the lower bound $c_l$ is based on an assumption of ``little to no population drift'' and therefore establishes a good baseline for establishing that populations are $\delta$-resemblant. 


\section{Efficacy of the PRS Method: a Simulation Study}
\label{sec: PRS simulation}

We conducted a simulation study to evaluate the performance of the proposed PRS procedure. We considered models with $B$ categories, where $B$ is either $5$ or $10$, and the probabilities are evenly distributed across all categories, $\bm{p}_0 = (1/B,\ldots,1/B)$. We tested different tolerance levels, $\delta_{\mathrm{tol}}$, where $\delta_{\mathrm{tol}}$ can be $0.01$, $0.02$, or $0.05$, along with sample sizes $n$ of 50, 100, or 250. For each configuration $(B, \delta_{\mathrm{tol}}, n)$, we simulated $K=100\, 000$ samples from $V=11$ different multinomial count models. The $v^{th}$ multinomial model has a success probability vector, $\bm{p}_v = (p_{v1},\ldots,p_{vB})$, where $p_{vj} = 1/B-\delta_{v}$ if $j\leq B/2$, $p_j = 1/B+\delta_{v}$ if $j\geq B/2+1$, and $p_{(B+1)/2} = 1/B$ when $(B+1)/2$ is an integer. Here, $\delta_v = v/10$ with $v=0,\ldots,10$. Note that the probability $p_{(B+1)/2}$ is only relevant when $B$ is odd. For the $k$th simulated dataset, let $\hat{\bm{p}}_k = (\hat{p}_{k1},\ldots,\hat{p}_{kB})$ denote the estimated probabilities associated with each of the $B$ categories. We calculated the chi-square statistic, $Q_k = n \sum_j (\hat{p}_{kj}-p_{0j})^2/p_{0j}$, based on the particular sample.

Now, let $L = F_{B-1}^{-1}(0.8)$, the $80$th percentile of the chi-square distribution with $B-1$ degrees of freedom, and let $U:=U_{\delta_\mathrm{tol}} = G_{B-1,\lambda}^{-1}(0.95)$, the $95$th percentile of the non-central chi-square distribution with $B-1$ degrees of freedom and non-centrality parameter $\lambda$, the latter defined in terms of $(B,\delta_{\mathrm{tol}},n)$ as in the previous sub-section. Reported below are the proportions of simulated $Q_k$ that fall below $L$, between $L$ and $U$, and above $U$. The lower reference limit $L$ corresponds to the asymptotic distribution when the no deviation from the reference population is to be tolerated, while the upper reference limit $U$ corresponds to the asymptotic distribution with maximal tolerance $\delta_{\mathrm{tol}}$. 

Note that when $\delta_v \leq \delta_{\mathrm{tol}}$, the simulated deviation from the original model given by $\bm{p}_0$ does not exceed the tolerance level. For these simulations, the current population should be deemed acceptable (insufficient change to warrant re-calibration). When  $\delta_v > \delta_{\mathrm{tol}}$, the simulated deviation exceeds the tolerance level. For these simulations, the current population should be deemed unacceptable and reconstruction should be mandated. For space constraints, only the results for the cases with sample size $n=100$ are presented here. Other cases ($n=50$ and $n=250$) can be found in an appendix. We do note that conclusions from the cases presented here do agree with results from the other sample sizes considered in the simulation.

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Status & $\delta_v$ & $\hat{P}(Q < L)$ & $\hat{P}(L \leq Q < U)$ & $\hat{P}(Q \geq U)$ \\
    \hline
Acceptable & 0.00 & \textbf{0.799} & 0.161 & 0.040 \\
 & 0.01 & 0.776 & 0.175 & \textbf{0.049} \\ 
 \hline
Unacceptable & 0.02 & 0.710 & 0.212 & 0.078 \\
 & 0.03 & 0.602 & 0.262 & 0.136 \\
 & 0.04 & 0.466 & 0.303 & 0.231 \\
 & 0.05 & 0.319 & 0.320 & 0.361 \\
 & 0.06 & 0.193 & 0.287 & 0.520 \\
 & 0.07 & 0.098 & 0.218 & 0.683 \\
 & 0.08 & 0.041 & 0.136 & 0.823 \\
 & 0.09 & 0.014 & 0.067 & 0.919 \\
 & 0.10 & 0.003 & 0.027 & 0.970 \\
 \hline
    \end{tabular}
    \caption{Empirical Classification Probabilities for $(B,\delta_{\mathrm{tol}},n)=(5,0.01,100)$}
    \label{tab:EmpClassB5n100 - 1}
\end{table}

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Status & $\delta_v$ & $\hat{P}(Q < L)$ & $\hat{P}(L \leq Q < U)$ & $\hat{P}(Q \geq U)$ \\
    \hline
Acceptable & 0.00 & \textbf{0.798} & 0.179 & 0.023 \\
& 0.01 & 0.775 & 0.196 & 0.029 \\
& 0.02 & 0.712 & 0.238 & \textbf{0.050} \\
 \hline
Unacceptable & 0.03 & 0.603 & 0.306 & 0.091 \\
& 0.04 & 0.465 & 0.366 & 0.169 \\
& 0.05 & 0.320 & 0.398 & 0.283 \\
& 0.06 & 0.192 & 0.373 & 0.435 \\
& 0.07 & 0.097 & 0.301 & 0.602 \\
& 0.08 & 0.041 & 0.197 & 0.762 \\
& 0.09 & 0.013 & 0.106 & 0.881 \\
& 0.10 & 0.004 & 0.045 & 0.951 \\
 \hline
    \end{tabular}
    \caption{Empirical Classification Probabilities for $(B,\delta_{\mathrm{tol}},n)=(5,0.02,100)$}
    \label{tab:EmpClassB5n100 - 2}
\end{table}

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Status & $\delta_v$ & $\hat{P}(Q < L)$ & $\hat{P}(L \leq Q < U)$ & $\hat{P}(Q \geq U)$ \\
    \hline
Acceptable & 0.00 & \textbf{ 0.798} & 0.201 & 0.001 \\
& 0.01 & 0.776 & 0.223 & 0.001 \\
& 0.02 & 0.712 & 0.285 & 0.003 \\
& 0.03 & 0.600 & 0.392 & 0.008 \\
& 0.04 & 0.466 & 0.514 & 0.020 \\
& 0.05 & 0.321 & 0.633 &\textbf{ 0.046} \\
 \hline
Unacceptable & 0.06 & 0.190 & 0.709 & 0.101 \\
& 0.07 & 0.099 & 0.705 & 0.196 \\
& 0.08 & 0.041 & 0.622 & 0.338 \\
& 0.09 & 0.013 & 0.473 & 0.514 \\
& 0.10 & 0.003 & 0.301 & 0.696 \\
 \hline
    \end{tabular}
    \caption{Empirical Classification Probabilities for $(B,\delta_{\mathrm{tol}},n)=(5,0.05,100)$}
    \label{tab:EmpClassB5n100 - 3}
\end{table}


\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Status & $\delta_v$ & $\hat{P}(Q < L)$ & $\hat{P}(L \leq Q < U)$ & $\hat{P}(Q \geq U)$ \\
    \hline
Acceptable & 0.00 &  \textbf{0.805} &  0.169 &  0.026 \\
& 0.01 &  0.732 &  0.217 &  \textbf{0.050} \\
 \hline
Unacceptable & 0.02 &  0.510 &  0.337 &  0.153 \\
& 0.03 &  0.226 &  0.363 &  0.411 \\
& 0.04 &  0.050 &  0.201 &  0.749 \\
& 0.05 &  0.004 &  0.042 &  0.954 \\
& 0.06 &  0.000 &  0.002 &  0.998 \\
& 0.07 &  0.000 &  0.000 &  1.000 \\
 \hline
    \end{tabular}
    \caption{Empirical Classification Probabilities for $(B,\delta_{\mathrm{tol}},n)=(10,0.01,100)$}
    \label{tab:EmpClassB10n100 - 1}
\end{table}
\clearpage
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Status & $\delta_v$ & $\hat{P}(Q < L)$ & $\hat{P}(L \leq Q < U)$ & $\hat{P}(Q \geq U)$ \\
    \hline
Acceptable & 0.00 & \textbf{0.805} & 0.190 & 0.005 \\
& 0.01 & 0.735 & 0.255 & 0.011 \\
& 0.02 & 0.512 & 0.439 & \textbf{0.050} \\
 \hline
Unacceptable & 0.03 & 0.226 & 0.580 & 0.194 \\
& 0.04 & 0.050 & 0.436 & 0.514 \\
& 0.05 & 0.004 & 0.143 & 0.853 \\
& 0.06 & 0.000 & 0.015 & 0.985 \\
& 0.07 & 0.000 & 0.000 & 1.000 \\
 \hline
    \end{tabular}
    \caption{Empirical Classification Probabilities for $(B,\delta_{\mathrm{tol}},n)=(10,0.02,100)$}
    \label{tab:EmpClassB10n100 - 2}
\end{table}

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Status & $\delta_v$ & $\hat{P}(Q < L)$ & $\hat{P}(L \leq Q < U)$ & $\hat{P}(Q \geq U)$ \\
    \hline
Acceptable & 0.00 & \textbf{0.806} & 0.194 & 0.000 \\
& 0.01 & 0.731 & 0.269 & 0.000 \\
& 0.02 & 0.514 & 0.486 & 0.000 \\
& 0.03 & 0.228 & 0.772 & 0.000 \\
& 0.04 & 0.050 & 0.946 & 0.003 \\
& 0.05 & 0.004 & 0.964 & \textbf{0.032} \\
 \hline
Unacceptable & 0.06 & 0.000 & 0.799 & 0.201 \\
& 0.07 & 0.000 & 0.361 & 0.639 \\
& 0.08 & 0.000 & 0.035 & 0.965 \\
& 0.09 & 0.000 & 0.000 & 1.000  \\
 \hline
    \end{tabular}
    \caption{Empirical Classification Probabilities for $(B,\delta_{\mathrm{tol}},n)=(5,0.05,100)$}
    \label{tab:EmpClassB10n100 - 3}
\end{table}

A couple of notes: For Tables 2 through 4 presenting results for $B=5$, the efficacy of the method is clear. In all three settings ($\delta_{\mathrm{tol}} = 0.01,\ 0.02, \text{ and } 0.05$), the cases with $\delta_v = 0$ show that the empirical probability of falling below the lower threshold $L$ is close to $0.8$, showing that the asymptotic chi-square distribution results in an accurate critical value. Similarly, the cases with $\delta_v = \delta_{\mathrm{tol}}$ show that the empirical probability of falling above the upper threshold $U$ is close to $0.05$, again supporting the use of the asymptotic non-central chi-square for calculating $U$. Furthermore, once $\delta_v > \delta_{\mathrm{tol}}$, the empirical probability of exceeding $U$ increases rapidly. This shows that larger deviations than the acceptable tolerance level would quickly be detected.

The results for Tables 5 through 7 are very similar with one minor exception. In Table 7 ($B=10$ and $\delta_{\mathrm{tol}}=0.05$, the empirical exceedance probability when $\delta_v = 0.05$ is only $0.032$, somewhat below the desired level of $0.05$ used to evaluate $U$. For the cases not reported ($n=50$ and $250$), the same smaller-than-expected exceedance probability is observed. This points to a potential breakdown of the asymptotic result when both number of categories $B$ and tolerance $\delta_{\mathrm{tol}}$ are large. However, investigating this would require simulations an order of magnitude larger than that done here. At the same time, the case with $B=10$ and $\delta_{\mathrm{tol}} = 0.05$ suggests that a deviation of up to $5\%$ in each category would be tolerated when the true probability is $10\%$. This is not a realistic scenario corresponding to what would be expected in practice and should not be of great concern. 


\section{Real-world applications}
\label{Application}
In this section we showcase some real-world examples (appropriately anonymized) from a suite of credit risk models, using a range of sample sizes and number of buckets. The first of these comprises datasets where the model constructed probabilities are chosen to be equal. The second comprise datasets where the model constructed probabilities were assigned based on a segment feature (e.g. a type of product). The suite of models have a range of sample sizes and number of buckets to illustrate the behaviour of the PRS method under plausible scenarios. Finally, we compare the PRS outcome with existing measures, the most popular being the PSI.

In the first example, the current population is of size $n=50$ and the model was constructed using $B=(3, 5)$ buckets with equal model constructed probabilities ${p_{0i}}=1/B, \ i=1,...,B$. In Table \ref{tab: n=50 example}, we present the PSI, PSR, KS, OVL and DPV measures given the data. In addition, we show the effect sizes abbreviated EFF, also examined in \textcite{pisanie2023critical}. The colours lime, maroon and orange indicate, respectively, the events $A<c_l$, $A\geq c_u$ and $c_l\leq A\leq c_u$, where $A$ indicates the measure in question. For the PSI, we use the Lewis constants. For the KS, the lower (upper) limit is breached when the p-value is lower than 5\% (1\%). For EFF, $c_u=0.8$ and $c_l=0.5$ are the commonly used thresholds. No easily obtainable critical values exist for the OVL or DPV.

For the PRS, we calculate the critical values using the \textit{indirect} method. Without loss of generality, we specify $M=1$. Using a power of 90\%, $\alpha_l=10\%$ and $\alpha_u=1\%$ results, for $B=5$, in $(c_l; c_u)=(0.1594;\ 0.2654 )$ with an implied $\delta_{tol}=0.1414$; and, for $B=3$, $(c_l; c_u)=(0.0967;\ 0.1842 )$ with an implied $\delta_{tol}=0.018$. 

In all cases the PRS less frequently mandates a model investigation or model reconstruction than the PSI using the Lewis constants. This result is commensurate with the inflated type I error probability witnessed using the Lewis constants with the PSI - see Table \ref{TABLE1}.

The comparison with the other measures is less apparent. The KS as well as the OVL (recall their equivalence) is not sensitive to shifts in buckets other than the bucket where the maximum deviance occurs. Therefore, the differences in probabilities between $t_3,\ t_5$ and $t_6$ are disregarded, while, to a practitioner, distinction between these would be required - the shifts in risk bucket 5 with the lowest credit quality is vastly different between the three sets and would need accounting for. The DPV is also biased towards the bucket with the highest deviance and the authors limited their discussion to sample sizes exceeding $10\ 000$. The EFF, au contraire, never prompts a model investigation or reconstruction, even though, for example, in bucket 4 a shift occurs from $1/B=0.2$ to 0.04 at $t_6$.


\begin{table}[h!]
  \centering
  \caption{Population resemblance comparison using the current population of size $n=50$ and population probabilities $p_i$ in $i=1,...,B$, $B=(3,5)$.}
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|r|r|}
\hline
\cline{2-13}         & \multicolumn{6}{c|}{B=5}                      & \multicolumn{6}{c|}{B=3} \\
\cline{2-13}          & \multicolumn{1}{l|}{$t_1$} & \multicolumn{1}{l|}{$t_2$} & \multicolumn{1}{l|}{$t_3$} & \multicolumn{1}{l|}{$t_4$} & \multicolumn{1}{l|}{$t_5$} & \multicolumn{1}{l|}{$t_6$} & \multicolumn{1}{l|}{$t_1$} & \multicolumn{1}{l|}{$t_2$} & \multicolumn{1}{l|}{$t_3$} & \multicolumn{1}{l|}{$t_4$} & \multicolumn{1}{l|}{$t_5$} & \multicolumn{1}{l|}{$t_6$} \\
\hline
    \multicolumn{1}{|r|}{$p_1$} & 0.28  & 0.287 & 0.287 & 0.15  & 0.287 & 0.287 & 0.38  & 0.31  & 0.387 & 0.25  & 0.2   & 0.2 \\

    \multicolumn{1}{|r|}{$p_2$} & 0.18  & 0.21  & 0.24  & 0.15  & 0.24  & 0.24  & 0.28  & 0.35  & 0.34  & 0.25  & 0.4   & 0.2 \\

    \multicolumn{1}{|r|}{$p_3$} & 0.21  & 0.21  & 0.26  & 0.35  & 0.26  & 0.26  & 0.34  & 0.34  & 0.273 & 0.5   & 0.4   & 0.6 \\
    \multicolumn{1}{|r|}{$p_4$} & 0.22  & 0.22  & 0.08  & 0.15  & 0.06  & 0.04  &       &       &       &       &       &  \\
    \multicolumn{1}{|r|}{$p_5$} & 0.11  & 0.073 & 0.133 & 0.2   & 0.153 & 0.173 &       &       &       &       &       &  \\
\hline
    PSI   &\cellcolor{lime}{ 0.085} & \cellcolor{orange}{0.162} & \cellcolor{orange}{0.192} & \cellcolor{orange}{0.127} & \cellcolor{orange}{0.236} & \cellcolor{purple}{\textcolor{white}{0.316}} & \cellcolor{lime}{0.016} & \cellcolor{lime}{0.003} & \cellcolor{lime}{0.020} & \cellcolor{orange}{0.116} & \cellcolor{lime}{0.092} & \cellcolor{purple}{\textcolor{white}{0.293}} \\

    PRS   & \cellcolor{lime}{0.077} & \cellcolor{lime}{0.122} & \cellcolor{lime}{0.158} & \cellcolor{lime}{0.150} & \cellcolor{orange}{0.173} & \cellcolor{orange}{0.196} & \cellcolor{lime}{0.015} & \cellcolor{lime}{0.003} & \cellcolor{lime}{0.020} & \cellcolor{orange}{0.125} & \cellcolor{lime}{0.080} & \cellcolor{purple}{\textcolor{white}{0.320}} \\

    KS    & \cellcolor{lime}{0.090} & \cellcolor{lime}{0.127} & \cellcolor{orange}{0.187} & \cellcolor{lime}{0.100} & \cellcolor{orange}{0.187} & \cellcolor{orange}{0.187} & \cellcolor{lime}{0.047} & \cellcolor{lime}{0.023} & \cellcolor{lime}{0.060} & \cellcolor{lime}{0.167} & \cellcolor{lime}{0.133} & \cellcolor{purple}{\textcolor{white}{0.267}} \\

    OVL   & 0.890 & 0.873 & 0.813 & 0.850 & 0.813 & 0.813 & 0.947 & 0.977 & 0.940 & 0.833 & 0.867 & 0.733 \\

    DPV   & 0.818 & 1.740 & 1.500 & 0.429 & 2.333 & 4.000 & 0.190 & 0.075 & 0.221 & 0.333 & 0.667 & 0.667 \\

    EFF   & \cellcolor{lime}{0.107} & \cellcolor{lime}{0.112} & \cellcolor{lime}{0.175} & \cellcolor{lime}{0.173} & \cellcolor{lime}{0.169} & \cellcolor{lime}{0.158} & \cellcolor{lime}{0.075} & \cellcolor{lime}{0.033} & \cellcolor{lime}{0.084} & \cellcolor{lime}{0.263} & \cellcolor{lime}{0.176} & \cellcolor{lime}{0.460} \\
\hline
    \end{tabular}%
  \label{tab: n=50 example}%
\end{table}%

Table \ref{tab:n=500,2000 example} is an analogue of Table \ref{tab: n=50 example}, except that therein we exhibit results, using $B=10$, for $n=500$ and $n=2\ 000$. When applying the PRS, in the case of $n=500$, $(c_l,\ c_u)=(0.02972, \ 0.04332)$, $\delta_{tol}=0.001$; and when $n=2\ 000$, $(c_l,\ c_u)=(0.00743,\ 0.01083)$, $\delta_{tol}=0.0007$. Table \ref{tab:n=10000 B=20 example} shows results for $n=10\ 000$ and $B=20$, with $(c_l,c_u)=(0.002735,\ 0.003619)$ and $\delta_{tol}=0.000162$. In these larger-sample cases observe that the PRS prompts a model investigation or model reconstruction more frequently than the PSI using the Lewis constants. Again, commensurate with the too-close-to-zero type I error probabilities of the PSI shown in Table \ref{TABLE1}.

% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table}[h!]
  \centering
  \caption{Population resemblance comparison using the current population of size $n=500$ or $n=2\ 000$ and population probabilities $p_i$ in $i=1,...,B$, $B=10$.}
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|r|}
    \hline
   & \multicolumn{5}{c|}{n=500, B=10}      & \multicolumn{6}{c|}{n=2 000, B=10} \\
\cline{2-12}          & \multicolumn{1}{l|}{$t_1$} & \multicolumn{1}{l|}{$t_2$} & \multicolumn{1}{l|}{$t_3$} & \multicolumn{1}{l|}{$t_4$} & \multicolumn{1}{l|}{$t_5$} & \multicolumn{1}{l|}{$t_1$} & \multicolumn{1}{l|}{$t_2$} & \multicolumn{1}{l|}{$t_3$} & \multicolumn{1}{l|}{$t_4$} & \multicolumn{1}{l|}{$t_5$} & \multicolumn{1}{l|}{$t_6$} \\
    \hline
    \multicolumn{1}{|r|}{$p_1$} & 0.140 & 0.110 & 0.150 & 0.125 & 0.130 & 0.105 & 0.100 & 0.120 & 0.110 & 0.110 & 0.130 \\
    \multicolumn{1}{|r|}{$p_2$} & 0.070 & 0.115 & 0.075 & 0.088 & 0.125 & 0.095 & 0.100 & 0.095 & 0.092 & 0.092 & 0.089 \\
    \multicolumn{1}{|r|}{$p_3$} & 0.110 & 0.090 & 0.119 & 0.100 & 0.130 & 0.090 & 0.090 & 0.090 & 0.090 & 0.090 & 0.105 \\
    \multicolumn{1}{|r|}{$p_4$} & 0.115 & 0.095 & 0.095 & 0.060 & 0.070 & 0.110 & 0.095 & 0.110 & 0.100 & 0.100 & 0.105 \\
    \multicolumn{1}{|r|}{$p_5$} & 0.130 & 0.120 & 0.090 & 0.100 & 0.080 & 0.100 & 0.105 & 0.120 & 0.095 & 0.095 & 0.110 \\
    \multicolumn{1}{|r|}{$p_6$} & 0.090 & 0.090 & 0.070 & 0.070 & 0.070 & 0.090 & 0.090 & 0.090 & 0.090 & 0.084 & 0.090 \\
    \multicolumn{1}{|r|}{$p_7$} & 0.090 & 0.080 & 0.116 & 0.110 & 0.130 & 0.120 & 0.092 & 0.120 & 0.107 & 0.107 & 0.080 \\
    \multicolumn{1}{|r|}{$p_8$} & 0.070 & 0.070 & 0.087 & 0.070 & 0.080 & 0.085 & 0.111 & 0.085 & 0.083 & 0.083 & 0.085 \\
    \multicolumn{1}{|r|}{$p_9$} & 0.095 & 0.100 & 0.089 & 0.060 & 0.040 & 0.080 & 0.120 & 0.080 & 0.057 & 0.057 & 0.085 \\
    \multicolumn{1}{|r|}{$p_{10}$} & 0.090 & 0.130 & 0.109 & 0.217 & 0.145 & 0.125 & 0.097 & 0.090 & 0.176 & 0.182 & 0.121 \\
    \hline
    PSI   & \cellcolor{lime}0.049 & \cellcolor{lime}0.032 & \cellcolor{lime}0.049 & \cellcolor{orange}0.161 & \cellcolor{orange}0.131 & \cellcolor{lime}0.020 & \cellcolor{lime}0.008 & \cellcolor{lime}0.022 & \cellcolor{lime}0.075 & \cellcolor{lime}0.083 & \cellcolor{lime}0.025 \\
    PRS   & \cellcolor{purple}\textcolor{white}{0.050} & \cellcolor{orange}0.032 & \cellcolor{purple}\textcolor{white}{0.051} & \cellcolor{purple}\textcolor{white}{0.196} & \cellcolor{purple}\textcolor{white}{0.116} & \cellcolor{purple}\textcolor{white}{0.020} & \cellcolor{orange}0.008 & \cellcolor{purple}\textcolor{white}{0.023} & \cellcolor{purple}\textcolor{white}{0.084} & \cellcolor{purple}\textcolor{white}{0.095} & \cellcolor{purple}\textcolor{white}{0.026} \\
    KS    & \cellcolor{orange}0.065 & \cellcolor{lime}0.030 & \cellcolor{lime}0.050 & \cellcolor{purple}\textcolor{white}{0.117} & \cellcolor{purple}\textcolor{white}{0.085} & \cellcolor{lime}0.025 & \cellcolor{orange}0.028 & \cellcolor{purple}\textcolor{white}{0.045} & \cellcolor{purple}\textcolor{white}{0.076} & \cellcolor{purple}\textcolor{white}{0.082} & \cellcolor{purple}\textcolor{white}{0.039} \\
    OVL   & 0.905 & 0.925 & 0.906 & 0.848 & 0.840 & 0.940 & 0.964 & 0.930 & 0.907 & 0.901 & 0.929 \\
    DPV   & 0.429 & 0.429 & 0.429 & 0.667 & 1.500 & 0.250 & 0.167 & 0.250 & 0.754 & 0.754 & 0.250 \\
    EFF   & \cellcolor{lime} 0.064 & \cellcolor{lime} 0.050 & \cellcolor{lime} 0.064 & \cellcolor{lime} 0.115 & \cellcolor{lime} 0.103 & \cellcolor{lime} 0.040 & \cellcolor{lime} 0.024 & \cellcolor{lime} 0.047 & \cellcolor{lime} 0.067 & \cellcolor{lime} 0.072 & \cellcolor{lime} 0.048 \\
    \hline
    \end{tabular}%
  \label{tab:n=500,2000 example}%
\end{table}%

% Table generated by Excel2LaTeX from sheet 'Sheet3'
\begin{table}[h!]
  \centering
  \caption{Population resemblance comparison using the current population of size $n=10\ 000$ with population probabilities $p_i$ in $i=1,...,B=20$ buckets.}
    \begin{tabular}{|l|r|r|r|r|r|r|}
    \hline
    & \multicolumn{6}{c|}{n=10 000, B=20} \\
\cline{2-7}          & \multicolumn{1}{l|}{$t_1$} & \multicolumn{1}{l|}{$t_2$} & \multicolumn{1}{l|}{$t_3$} & \multicolumn{1}{l|}{$t_4$} & \multicolumn{1}{l|}{$t_5$} & \multicolumn{1}{l|}{$t_6$} \\
    \hline
    \multicolumn{1}{|r|}{1} & 0.05025 & 0.04  & 0.065 & 0.0585 & 0.055 & 0.065 \\
    \multicolumn{1}{|r|}{2} & 0.05015 & 0.04  & 0.04  & 0.0445 & 0.0545 & 0.0545 \\
    \multicolumn{1}{|r|}{3} & 0.055 & 0.036 & 0.0725 & 0.0425 & 0.045 & 0.045 \\
    \multicolumn{1}{|r|}{4} & 0.0485 & 0.052 & 0.04  & 0.0475 & 0.0475 & 0.04 \\
    \multicolumn{1}{|r|}{5} & 0.048 & 0.052 & 0.0375 & 0.0525 & 0.0525 & 0.0525 \\
    \multicolumn{1}{|r|}{6} & 0.0495 & 0.038 & 0.035 & 0.044 & 0.045 & 0.055 \\
    \multicolumn{1}{|r|}{7} & 0.0445 & 0.042 & 0.06  & 0.046 & 0.046 & 0.046 \\
    \multicolumn{1}{|r|}{8} & 0.0455 & 0.0511 & 0.055 & 0.0555 & 0.0555 & 0.065 \\
    \multicolumn{1}{|r|}{9} & 0.054 & 0.052 & 0.035 & 0.06  & 0.06  & 0.06 \\
    \multicolumn{1}{|r|}{10} & 0.0546 & 0.2   & 0.06  & 0.049 & 0.039 & 0.017 \\
    \multicolumn{1}{|r|}{11} & 0.05025 & 0.04  & 0.065 & 0.0585 & 0.055 & 0.065 \\
    \multicolumn{1}{|r|}{12} & 0.05015 & 0.04  & 0.04  & 0.0445 & 0.0545 & 0.0545 \\
    \multicolumn{1}{|r|}{13} & 0.055 & 0.03  & 0.0725 & 0.0425 & 0.045 & 0.045 \\
    \multicolumn{1}{|r|}{14} & 0.0485 & 0.042 & 0.04  & 0.0475 & 0.0475 & 0.04 \\
    \multicolumn{1}{|r|}{15} & 0.048 & 0.051 & 0.0375 & 0.0525 & 0.0525 & 0.0525 \\
    \multicolumn{1}{|r|}{16} & 0.0495 & 0.04  & 0.035 & 0.044 & 0.045 & 0.055 \\
    \multicolumn{1}{|r|}{17} & 0.0445 & 0.04  & 0.06  & 0.046 & 0.046 & 0.046 \\
    \multicolumn{1}{|r|}{18} & 0.0455 & 0.051 & 0.055 & 0.0555 & 0.0555 & 0.065 \\
    \multicolumn{1}{|r|}{19} & 0.054 & 0.06  & 0.035 & 0.06  & 0.06  & 0.062 \\
    \multicolumn{1}{|r|}{20} & 0.0546 & 0.0029 & 0.06  & 0.049 & 0.039 & 0.015 \\
    \hline
    PSI   & \cellcolor{lime}0.005 & \cellcolor{purple}\textcolor{white}{0.378} & \cellcolor{lime}0.070 & \cellcolor{lime}0.014 & \cellcolor{lime}0.015 & \cellcolor{orange}0.106 \\
    PRS   & \cellcolor{purple}\textcolor{white}{0.005} & \cellcolor{purple}\textcolor{white}{0.526} & \cellcolor{purple}\textcolor{white}{0.070} & \cellcolor{purple}\textcolor{white}{0.014} & \cellcolor{purple}\textcolor{white}{0.015} & \cellcolor{purple}\textcolor{white}{0.073} \\
    KS    & \cellcolor{lime}0.009 & \cellcolor{purple}\textcolor{white}{0.103} & \cellcolor{purple}\textcolor{white}{0.028} & \cellcolor{orange}{0.015} & \cellcolor{lime}{0.011} & \cellcolor{purple}\textcolor{white}{0.035} \\
    OVL   & 0.972 & 0.831 & 0.875 & 0.947 & 0.945 & 0.894 \\
    DPV   & 0.124 & 16.241 & 0.429 & 0.176 & 0.282 & 2.333 \\
    EFF   & \cellcolor{lime}0.013 & \cellcolor{lime}0.106 & \cellcolor{lime}0.058 & \cellcolor{lime}0.025 & \cellcolor{lime}0.025 & \cellcolor{lime}0.044 \\
    \hline
    \end{tabular}%
  \label{tab:n=10000 B=20 example}%
\end{table}%


These results generalize to the cases where the model constructed probabilities are not equal for all buckets. To keep the exposition neat, we neglect to show these. They are, however, available from the authors upon request.

%In the next subsection, we consider the symmetric Kullback-Leibler divergence and the chi-square divergence as measures to assess population stability based on sampled data.

%At the same time, the minimum information statistic is related to the likelihood ratio test of \textcite{neyman1928use} -- see \textcite[p. 94]{kullback1978information}. Furthermore, \textcite{eguchi2006interpreting} established that the information statistic $I$ can be interpreted as the loss of power from the Neyman-Pearson likelihood ratio test when a hypothesis is mis-specified.

%\subsection{Where to Put This: Kullback-Leibler divergence versus Chi-Square???}

%{To my mind we make two valuable contributions in this paper. 1. Properly defining the hypothesis to test. 2. The chi2 is ``similar'' to the KL divergence, but the size of the dataset requires to reach its distribution is much smaller for the chi2. Hence, the chi2 is more stable at small sample sizes and that is the real win. 3. Yurdakul etc all show that the Lewis-thresholds don't really work. But what they miss is that the approximation of the PSI using chi2 at small samples is not good. Furthermore, we are able to ``target'' power through delta - confirm with Nelis?\newline \newline
%According to Kumar and Hunter (2004), the chi-square divergence (on which our test is based) is also part of the Csiszar f-divergences. Hence, also not a true distance. But statistical properties of chi-2 divergence is better than for the PSI. The chi-2 divergence is also not symmetric. Nishiyama and Sason (2020) give inequalities and relations between these two divergences, namely $ J(p,q)<=0.5 (chi2(p||q)+chi2(q||p)) $}


%\section{Limitations of the current study}

%The focus of this paper is on comparing two populations in the context of credit risk modeling, which corresponds to the goodness-of-fit problem of testing whether a sample originates from a multinomial population with known success probabilities derived from the model construction phase. However, in practice, the probabilities associated with the model construction phase are estimated from a sample. Therefore, it is desirable to develop inferential tools treating this as a two-sample problem. However, implementing the two-sample formulation poses challenges due to the lack of independence between the samples collected during the development and current phases. 

%Dependencies between the development and current samples may stem from at least two sources: temporal evolution and overlapping data. Temporal dependence arises because the samples capture the evolution of the underlying population over time. Thus, one may think of the population itself being a temporal process. On the other hand, overlapping data occurs when organizations periodically collect data, and the same cases appear in both the development and current samples. This overlap can create inter-dependencies, even if the cases have different values.

%Thus, while the two-sample formulation seems natural, where one sample is used for model development and the other for assessing population stability, this approach faces several challenges in practice. To address the issue of non-independence between the samples, we have resorted to a one-sample problem formulation, treating the reference probabilities $\mathbf{p}0$ as fixed and known. Even in situations as described where the baseline was established using sampling tools, the one-sample approach can still be employed, providing a conditional inference solution. Future work should aim to quantify temporal dependence and sample overlap to define a solution recognizing the variability in both samples.
\clearpage
\section{Conclusion}
{Monitoring for changes in the population underlying a developed model is a frequent action, especially in banking. Even though several measures have been used over the years, most prominently the PSI, shortcomings in these measures have inspired research into alternatives measures to assess population resemblance. We presented the PRS, which is based on the Pearson chi-square statistic and the non-central chi-square distribution. In this paper, we presented the relevant principles and definitions for the problem and formulated the statistical and distributional properties of the PRS. In particular, the PRS accommodates sample-size dependent critical values and enables the specification of risk tolerances. Monte Carlo simulations confirmed our expectations and demonstrated the efficacy of the measure. In the application, we used anonymous data from a portfolio within a bank to compare the PRS to other measures proposed in the literature. It became evident that the behaviour of the PRS makes it a suitable measure when assessing the resemblance between samples given both small samples sizes (often encountered in low default portfolios) or larger samples frequently encountered in retail portfolios of a bank. }

\printbibliography


\section{Appendix}

\subsection{Non-Centrality Parameter Calculation}
\label{sec: Appendix 1}

Consider the calculation of the non-centrality parameter $\lambda_{\mathrm{sup}}$ as in \eqref{eq:noncentral parm}. To this end, for $\boldsymbol{\xi} = (\xi_1,\ldots,\xi_B)$ and $\mathrm{p}_0 = (p_{01},\ldots,p_{0B})$, define the function $$f(\boldsymbol{\xi})=\sum_{j} \frac{\xi_j^2}{p_{0j}}.$$ The goal here is to maximize $f(\boldsymbol{\xi})$ subject to the constraints
$$\sum_j \xi_j = 0$$
and
$$\xi_j^2 \leq n\delta^2,\quad j=1,\ldots,B.$$
The latter set of inequality constraints can be re-formulated as equality constraints by introducing proxy variables $\epsilon_j$, $j=1,\ldots,B$ and $\tau_j$, $j=1,\ldots,B$, so that
$$c_j^2 + \epsilon_j^2 = n\delta^2,\quad j=1,\ldots,B.$$

This now permits the formulation of the problem using the method of Lagrange multipliers. The objective function is given by
$$g(\bm{\theta}) = \sum_{j=1}^{B} \frac{\xi_j^2}{p_{0j}} + \kappa \bigg( \sum_{j=1}^{B} \xi_j\bigg)+\sum_{j=1}^{B} \gamma_j \bigg(\xi_j^2 + \epsilon_j^2 - z^2 \bigg)$$
where $\bm{\theta}=(\boldsymbol{\xi},\kappa,\bm{\gamma},\bm{\epsilon})$ denotes the set of parameters being optimized over. To find the maximum of this function, we evaluate the set of partial derivatives and set these equal to $0$. Thus, we have $3B+1$ equations
\begin{eqnarray}
    \dfrac{\partial g}{\partial \xi_k} &=& \frac{2\xi_k}{p_{0k}}+\kappa+2\gamma_k\xi_k = 0, \ k = 1,\ldots,B, \label{eq:partial c_k}\\
    \notag \\ 
    \dfrac{\partial g}{\partial \kappa} &=& \sum_{j=1}^{B} \xi_j = 0, \label{eq:partial kappa}\\
    \notag\\
    \dfrac{\partial g}{\partial \epsilon_k} &=& 2\gamma_k\epsilon_k, \ k=1,\ldots,B, \label{eq:partial epsilon_k}\\
    \notag \\ 
    \dfrac{\partial g}{\partial \gamma_k} &=& \xi_k^2 + \epsilon_k^2 - n\delta^2, \ k=1,\ldots,B.\label{eq:partial gamma_k}
\end{eqnarray}

Firstly, note from \eqref{eq:partial epsilon_k} that for each category $k$, either $\gamma_k=0$ or $\epsilon_k=0$. When $\epsilon_k=0$, it follows from \eqref{eq:partial gamma_k} that $\xi_k^2 = n\delta^2$. On the other hand, when $\gamma_k=0$, it follows from \eqref{eq:partial c_k} that $\xi_k = -\kappa p_{0k}/2$. Introduce the variable $x_k \in \{-1,0,1\}$. We can then write $$\xi_k = n^{1/2}\delta x_k -\kappa p_{0k}(1-x_k^2)/2, \ k=1,\ldots,B,$$ where $\kappa$ can be found using \eqref{eq:partial kappa}. Specifically, we have
$$\sum_{j=1}^{B} \xi_j = n^{1/2}\delta \sum_{j=1}^{B} x_j - \frac{\kappa}{2}\sum_{j=1}^{B} p_{0j}(1-x_j^2) = 0$$ so that $$\kappa = \frac{2n^{1/2}\delta \sum_j x_j}{\sum_j p_{0j}(1-x_j^2)}.$$ When $\sum x_j^2 = B$, we can set $\kappa=0$ without loss of generality, as the $\xi_j$ will not depend on this value. Defining $$h(\mathbf{x},\mathbf{p}) = \frac{\sum_j x_j}{\sum_j p_j(1-x_j^2)} \ \mathrm{for}\ \sum_j x_j^2 < B$$ with $h(\mathbf{x},\mathbf{p})$ taking the value $0$ otherwise, it is possible to write $$\xi_k = n^{1/2}\delta \big[x_k - h(\mathbf{x},\mathbf{p}_0)(1-x_k^2)p_{0k}\big],  \ k=1,\ldots,B.$$
Subsequently, we have
\begin{equation}
\lambda_{\mathrm{sup}} = n\delta^2 \max_{\mathbf{x}:x_j\in\{-1,0,1\}} \sum_{j=1}^{B}\frac{x_j^2-h^2(\mathbf{x},\mathbf{p}_0)(1-x_j^2)p_{0j}}{p_{0j}}. \label{eq: delta to lambda}
\end{equation}
Note firstly that the non-centrality parameter is proportional to both the sample size $n$ and the square of the acceptable tolerance level $\delta^2$. Furthermore, the remaining maximization problem can be found through an exhaustive search of the $3^B$ possible vectors $\mathbf{x}$ with entries restricted to $\{-1,0,1\}$.

\subsection{Quantifying Model Deviance}
\label{sec: model deviance}
One plausible motivation for the Lewis constants is that these values of the PSI in \eqref{PSI_eqn} correspond to specific levels of deviation between the model construction population and the current population. {Thinking of divergence as a ``distance'' \parencite{vaart2000asymptotic} can be a useful way to conceptualize its properties and understand its application.} Therefore, by setting the PSI formula equal to one of the Lewis constants and evaluating the implications for the underlying populations, we can gain insight into the {degree of resemblance} between the two populations. 

The extent to which the Lewis constants measure deviation between populations can be further explored through the formulation of an optimization problem. For illustrative purposes, we will assume there are $B$ categories and that the model construction probabilities are equal, $\mathbf{p}_0=(1/B,\ldots,1/B)$. The goal is to investigate the minimum and maximum possible values of the PSI of $\mathbf{p}$ while restricting it to be ``close'' to $\mathbf{p}_0$. Closeness here is defined through the use of the Euclidean distance. We let $\delta$ denote the specified level of deviation. For example, if $\delta=0.01$ then the typical deviation between the model construction probability and the current probability for a given category is around $1\%$. Individual deviations may be smaller or larger, but we constrain the typical deviation.

In mathematical notation, the equivalent optimization problem is given by the following set of equations,
$$ \mathrm{opt}_{\mathbf{p}}\quad \mathrm{PSI}(\mathbf{p},\mathbf{p}_0)$$
subject to
$$\frac{1}{B}\sum_{j=1}^{B} (p_j - p_{0j})^2 = \delta^2,$$
$$\sum p_j = 1,$$
$$\min_j p_j \geq 0.$$
with $\delta$ a specified constant and $\mathbf{p}_0$ the set of equal category probabilities. Note that ``$\mathrm{opt}_{\mathbf{p}}$'' represents both a minimization and maximization problem over the set of model probabilities $\mathbf{p}$. The first constraint ensures closeness to $\mathrm{p}_0$, while the second and third constraints ensure that we are only optimizing over valid probability models.

This problem was approached using a stochastic optimization routine for the two cases $B=5$ and $B=10$. The results are presented in Figures \ref{fig:PSI B5} and \ref{fig:PSI B10} which show the minimum and maximum PSI boundaries as a function of $\delta$. Note that the plots do not extend beyond $\delta = 0.1$, as this represents a substantive deviation between the two populations. Additionally, for the sake of readability, the plots are truncated to show only PSI values below $0.4$, as the maximum PSI increases rapidly as a function of $\delta$.

% Figure environment removed

% Figure environment removed

To understand the meaning of a specific Lewis constant in relation to the underlying populations, we now interpolate specific PSI values to the range of possible $\delta$ values. For example, when $\mathrm{PSI}=0.1$, we can see that for $B=5$, this corresponds to $\delta \in (0.054,0.069)$. This means that if the underlying model has $5$ categories and the observed PSI is $0.1$, it means that the typical deviation between the current model probabilities and the model construction probabilities is at least $5.4\%$, but not larger than $6.9\%$. When $B=10$, this same Lewis constant corresponds to $\delta \in (0.025,0.036)$, meaning the typical deviation is between $2.5\%$ and $3.6\%$. Similarly, for $\mathrm{PSI}=0.25$, $\delta \in (0.069,0.076)$ for $B=10$ and $\delta \in (0.031,0.062)$ for $B=5$. 

%While this is informative \textcolor{red}{(okay, but how exactly?)} about what the population-level PSI implies about the two underlying models, this does not address sampling variability when estimating the PSI.


%\section{Extras}

%\textbf{\textcolor{red}{Made some notes. Tried to create context for these papers given the work we have been doing. However, this is something that will be ``filled in'' towards the end of the paper.}}

%Yurdakal (2020) state quite clearly the use of the PSI in banking. The literature review can be greatly extended. \textit{Note, Yurdakal (dissertation from 2018) considers asymptotic properties of the PSI. They derive the mean and variance of the asymptotic expansion, as the true distribution has $\mathrm{E}[PSI]=\infty$. Also important to note Yurdakal considers a two-sample problem and treats the two samples independently -- we do not want to do this. Depsite these concerns, Yurdakul does consider a chi-square approximation and choosing sample-size dependent constants for decision-making.} They refer to origins of the PSI thresholds but not to the degree that we have researched it. Try to find Pruitt (2010), as they state :" Recommendations for industry best practice are made by Pruitt (2010)".
%\textit{I read Pruitt (2010). They develop a SAS routine for calculating the PSI. They still use the Lewis constants for }

%They make the link between PSI and Kullback - Leibler divergence and they then derive the statistical properties that the PSI/(1/n+1/m) distributed chisquare (b-1). They show this with simulated results as well. They then discuss a "benchmark" for the PSI by performing a power analysis (through simulation) and calculating the frequency of exceeding the thresholds given no shift. They do this for a fixed B=10 and B=20 but refer the reader to the dissertation for more values of B. They then assess the 0.1 and 0.25 thresholds ito power and compare it to the Chi-square distributed PSI (and using a chi square critical value). They finally proposed the use of the chi-squared version of the PSI or the normal approximation one, without going into too much detail on how it should be implemented.

%\textcite{dupisanievisagie2020} use 

%[[SUMMARY OF Du Pisani \& Visagie(2020)]]
%Very little mathematical details are provided. They reference Yurdakul. They focus on the hypothesis testing procedure. They do not go into any details about the 0.1 and 0.25 thresholds. They then use heuristic arguments to show that the thresholds are not usefull, especially in SA where the sample size is big (as if it is not true in the rest of the world...) They use only one sample size (n) and never discuss the option than n and m might be vastly different in value, although the focus on large samples predominantly.  They describe the algorithm used to determine appropriate thresholds for large sample sizes n=1000,10k, 100k and 1m) and provide the thresholds for different alpha levels. They conclude their first contribution that the thresholds should be sample size dependent. Their second contribution is that the number of buckets are important, and they provide thresholds for different number of buckets for a fixed M and n.
%They then have a third contribution where the provide the algorithm to do power analysis (found in many textbooks). Their 4th contribution is a proposed alternative hypothesis testing regime. They propose alternatives as follows: 1. Use a composite alternative where you specify a range of acceptable changes where the population is still regarded as stable.
%2. Do not use all the buckets when calculating PSI (my comment: PA will say this is cherry picking!) They then formulate a test statistic based on the maximum deviation between the two proportions (at development vs at testing) over the selected buckets. They calculate critical values using MC simulation. 

\subsection{An Information-Theoretic View of Resemblance} \label{sec: info theory}

The PSI is based on the symmetric KullbackLeibler divergence \eqref{Kullback J2}, which is measure that has its foundation in entropy designed by \textcite{shannon1948mathematical}. For a discrete random variable $X$ taking values in a countable set $\mathcal{X}$ and with probability mass function $p(x),\ x\in\mathcal{X}$, the Shannon entropy is defined as 
$$H(X)=-\sum_{x\in\mathcal{X}} p(x)\log p(x)=-\mathrm{E}[\log p(X)].$$ 
This measure can be understood as measuring the expected amount of uncertainty associated with an outcome, with higher entropy indicating greater uncertainty. Maximum entropy occurs when the distribution is uniform across the set $\mathcal{X}$, indicating greatest uncertainty of the outcome. 

\textcite{kullback1951information} introduced a measure of relative entropy, measuring the ``expected per observation information.'' This relative entropy, often referred to as the Kullback-Leibler divergence, quantifies how much information is needed to distinguish between the two distributions. For random variables $X_1$ and $X_2$ with mass functions $p(x)$ and $q(x)$, it is defined as $$I(p,q)=\sum_{x\in\mathcal{X}} p(x) \log \bigg[\frac{p(x)}{q(x)}\bigg].$$ This measure is fundamentally asymmetric, and measures the divergence of $p(x)$ \textit{from} $q(x)$. The symmetrised version of relative entropy, $J(p,q)=I(p,q)+I(q,p)$, was first defined by \textcite{jeffreys1948theory}. This symmetric divergence also forms the basis for the PSI measure of \textcite{lewis1994introduction}.

The Kullback-Leibler divergence $I(p,q)$ and symmetric divergence $J(p,q)$ belongs to the class of $f$-divergences introduced and studied by \textcite{renyi1961measures} and \textcite{csiszar1967information}. For probability mass functions $p(x)$ and $q(x)$, the $f$-divergence is defined as $$D_f(p,q) = \sum_{x\in\mathcal{X}}q(x)f\bigg[\frac{p(x)}{q(x)}\bigg]$$ where $f(t)$ is a convex function satisfying $f(1)=0$.  The choice $f(t)=(t-1)\log(t)$ results in the symmetric divergence $J(p,q)$, while the choice $f(t)=(1-t)/t$ results in the classic chi-square divergence metric $$\chi^2(p,q) = \sum_{x\in\mathcal{X}}\frac{\big[q(x)-p(x)\big]^2}{p(x)}.$$ In fact, the chi-square divergence plays an important role with respect to $f$-divergences in general. By Theorem 4.1 of \textcite{csiszar2004information}, any $f$-divergence can be approximated by the chi-square divergence when $p(x)$ and $q(x)$ are close. By their theorem, if $f(t)$ is twice differentiable at $t=1$ and $f''(1)>0$, then $$\frac{D_f(p,q)}{\chi^2(p,q)} \rightarrow \frac{f''(1)}{2} \text{  as  } p(x)\rightarrow q(x).$$

In general, $f$-divergences are not true distances; for many choices of $f(t)$ the resulting measure is not symmetric. Also, when a specific $f(t)$ results in a symmetric divergence measure, it still may not satisfy the triangle inequality. That being said, this class of divergence measures does satisfy the basic properties of a metric divergence, see \textcite{osterreicher2003f}. In the present context, the most useful property of a metric divergence is that when $f(t)$ is strictly convex at $t=1$, $D_f(p,q)=0$ if any only if $p(x)=q(x)$ for all $x\in\mathcal{X}$. Further geometric properties of $f$-divergences are considered by \textcite{amari2010information}. 


\end{document}
