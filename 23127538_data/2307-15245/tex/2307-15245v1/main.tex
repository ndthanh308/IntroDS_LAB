\documentclass[journal]{IEEEtai}

%\usepackage[colorlinks,urlcolor=blue,linkcolor=blue,citecolor=blue]{hyperref}

\usepackage{inputenc}
%\usepackage[T1]{fontenc}
\usepackage{scalerel}
 \usepackage{xcolor}

\let\labelindent\relax

\usepackage[margin=1in]{geometry}
% \usepackage[math]{kurier}
% \usepackage[sc]{mathpazo}                   
% \renewcommand{\sfdefault}{kurier}

\usepackage{url}            
\usepackage{cite}
\usepackage{hyperref}

\definecolor{darkpastelgreen}{rgb}{0.01, 0.75, 0.24}
	\definecolor{cadmiumgreen}{rgb}{0.0, 0.42, 0.24}
\definecolor{armygreen}{rgb}{0.29, 0.33, 0.13}
\hypersetup{colorlinks,linkcolor={blue},citecolor={darkpastelgreen},urlcolor={red}}  


%\usepackage[draft]{hyperref}
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{url}
\usepackage{array}

\usepackage{amsmath}
\usepackage{color}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\usepackage{paralist}
\usepackage{dsfont}

\usepackage[square,sort,comma,numbers]{natbib}
\bibliographystyle{plainnat}

\usepackage{csquotes}
\usepackage{comment}
\usepackage{mathtools}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs} % for professional tables
\usepackage{dirtytalk}
\usepackage{subfiles}

\usepackage{caption}
\usepackage{subcaption}

%\usepackage{breqn}
%\usepackage[square,numbers]{natbib}
\usepackage{xspace}
\usepackage{forloop}
\usepackage{multirow}
%\usepackage{booktabs}
\usepackage{algorithm,algorithmic,refcount}
\usepackage{comment}

% \usepackage[pdftex,dvipsnames,table]{xcolor}
% \usepackage[colorinlistoftodos,prependcaption,textsize=small]{todonotes}
\usepackage{graphicx}
\usepackage[shortlabels]{enumitem}
\usepackage{bbm}
\usepackage{float}
\usepackage[most]{tcolorbox}

%\usepackage{minipage}

\usepackage{footnote}
\usepackage{etoolbox}
\BeforeBeginEnvironment{tcolorbox}{\savenotes}
\AfterEndEnvironment{tcolorbox}{\spewnotes}

% \DeclareMathOperator*{\argmax}{arg\,max}
% \DeclareMathOperator*{\argmin}{arg\,min}

% \makeatletter
% \def\@makefnmark{%
%   \leavevmode
%   \raise.9ex\hbox{\fontsize\sf@size\z@\normalfont\tiny\@thefnmark}}
% \makeatother

\input{macros}
%% \setcounter{secnumdepth}{0}

\definecolor{red}{gray}{0}

\begin{document}


%\title{FedZoo-Bench: A Practical Recipe for Federated Learning with Non-IID Data Experimental Design} 


\title{A Practical Recipe for Federated Learning Under Statistical Heterogeneity Experimental Design} 


\author{Mahdi Morafah, Weijia Wang, and Bill Lin
\thanks{M. Morafah, W. Wang and B. Lin are all with Electrical and Computer Engineering Department of University of California San Diego, USA (e-mail address: \{mmorafah, wweijia, billlin\}@eng.ucsd.edu).}
\thanks{Corresponding author: Mahdi Morafah.}
\thanks{}
}
%\thanks{This paragraph will include the Associate Editor who handled your paper.}}

\markboth{Journal of IEEE Transactions on Artificial Intelligence, Vol. 00, No. 0, Month 2023}
{M. Morafah \MakeLowercase{\textit{et al.}}: IEEE Journals of IEEE Transactions on Artificial Intelligence}

\maketitle

\begin{abstract}
Federated Learning (FL) has been an area of active research in recent years. There have been numerous studies in FL to make it more successful in \textcolor{red}{the} presence of data heterogeneity. However, despite the existence of many publications, the \textcolor{red}{state} of progress in the field is unknown. Many of the works use inconsistent experimental settings and there \textcolor{red}{are} no comprehensive studies on the effect of FL-specific experimental variables on the results and practical insights for a more comparable and consistent FL experimental setup. Furthermore, \textcolor{red}{the} existence of several benchmarks and confounding variables \textcolor{red}{has} further complicated the issue of inconsistency and ambiguity. In this work, we present the first comprehensive study on the effect of FL-specific experimental variables in relation to each other and performance results, \textcolor{red}{bringing} several insights and recommendations for designing a meaningful and well-incentivized FL experimental setup. We further aid the community by releasing FedZoo-Bench, an open-source library based on PyTorch with pre-implementation of 22 state-of-the-art methods\footnote{We will continue the effort to extend FedZoo-Bench by implementing more methods and adding more features. Any contributions to FedZoo-Bench would be greatly appreciated as well.}, and a broad set of standardized and customizable features available at~\url{https://github.com/MMorafah/FedZoo-Bench}. We also provide a comprehensive comparison of several state-of-the-art (SOTA) methods to better understand the current state of the field and existing limitations.
\end{abstract}

\begin{IEEEImpStatement}
Federated Learning aims to train a machine learning model using the massive decentralized data available at IoT and mobile devices, and different data centers while maintaining data privacy. However, despite {the} existence of numerous works, the state of progress in the field is not well-understood. Papers use different methodologies and experimental setups that \textcolor{red}{are} hard to compare and examine the effectiveness of methods in more general settings. Moreover, the effect of federated learning experimental design factors such as local epochs, and sample rate on the performance results have remained unstudied in the field. Our work comprehensively studies the effect of experimental design factors in federated learning, provides suggestions and insights, introduces FedZoo-Bench with \textcolor{red}{the} pre-implementation of 22 state-of-the-art algorithms under a unified setting, and finally measures the state of progress in the field. The studies and findings discussed in our work can significantly help the federated learning field by providing a more comprehensive understanding of the impact of experimental design factors, facilitating the design of better performing algorithms, and enabling \textcolor{red}{a} more accurate evaluation of the effectiveness of different methods. 
\end{IEEEImpStatement}

\begin{IEEEkeywords}
Benchmark, Data Heterogeneity, Experimental Design, Federated Learning, Machine Learning, Non-IID Data.
\end{IEEEkeywords}

%\newpage

%\input{defs.tex}

\input{Introduction}
\input{related_works}
\input{background}
%\input{Literature-Analysis}
\input{Remedies}
\input{recommendation}
\input{FedZooBench}
\input{conclusion}
%\input{algorithms}

%\appendix
\section*{APPENDIX}
\appendices
\input{SupMat}

\newpage
\clearpage
%\section*{References}
%\bibliography{Mahdi-Fed}
\bibliography{Non_IID, extra}
%\bibliography{extra}
% \newpage
% \clearpage

\begin{IEEEbiography}
    [{% Figure removed}]{Mahdi Morafah}
received the BS in Electrical Engineering from the Tehran Polytechnic University, Tehran, Iran, in 2019, and the MS degree in Electrical and Computer Engineering from the University of California, San Diego, in 2021. He is currently pursuing the PhD degree in Electrical and Computer Engineering at the University of California, San Diego. His research interests include Machine Learning and Deep Learning, Distributed Learning, Federated Learning, Continual Learning, and Optimization. 
\end{IEEEbiography}

\begin{IEEEbiography}
    [{% Figure removed}]{Weijia Wang}
received the B.S. degree in Electrical Engineering from Zhejiang University, Hangzhou, China, in 2016 and the M.S. degree in Electrical and Computer Engineering from the University of California, San Diego, in 2018. He is currently pursuing the Ph.D. degree in Electrical and Computer Engineering at the University of California, San Diego. His research interest is machine learning and deep learning, including the compression and acceleration of deep convolutional neural networks, algorithms of meta-learning and federated learning, and explainable artificial intelligence.
\end{IEEEbiography}

\begin{IEEEbiography}
    [{% Figure removed}]{Bill Lin}
received the BS, MS, and the PhD degrees in electrical engineering and computer sciences from the University of California, Berkeley in 1985, 1988, and 1991, respectively. He is a Professor in Electrical and Computer Engineering at the University of California, San Diego, where he is actively involved with the Center for Wireless Communications (CWC), the Center for Networked Systems (CNS), and the Qualcomm Institute in industry-sponsored research efforts. His research has led to over 200 journal and conference publications, including a number of Best Paper awards and nominations. He also holds 5 awarded patents. He has served as the General Chair and on the executive and technical program committee of many IEEE and ACM conferences, and he has served as an Associate or Guest Editor for several IEEE and ACM journals as well.
\end{IEEEbiography}

\end{document}
