\begin{enumerate}
    \item a meta-analysis on the literature
    \item Inconsistency in the literature (accuracy, comparison, different artificial settings)
    \item Provide a thorough evaluation metrics
    \item Re-implementation of many algorithms and release FedZoo benchmark
    \item Effectively compare different FL algorithms under settings and rank them 
    \item Design and Propose experimental suggestions for the community
\end{enumerate}

\begin{itemize}
    \item when to personalize? (different niid, epoch, alg)
    \item accuracy metrics (test sample, train sample) only for fedavg. (different niid)
    \item gain with more communication rounds? (different niid, all alg)
    \item gain with more local epochs? (different niid, algs)
    \item scailability (algs)
    \item generalization to new commers (algs) 
    \item Fairness? (algs)
    \item designing federated experimental settings
\end{itemize}


%  In Karimireddy et al. (2019), authors argue that if
% these hyperparameters are not carefully tuned, it will result in the divergence of FedAvg, as local models may drift
% significantly from each other. Therefore, in the presence of statistical data heterogeneity, the global model might
% not generalize well on the local data of each client individually (Jiang et al., 2019). This is even more crucial in
% fairness-critical systems such as medical diagnosis (Li and Wang, 2019), where poor performance on local clients
% could result in damaging consequences.