\begin{thebibliography}{85}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[fed()]{fedlearner}
Fedlearner.
\newblock \url{https://github.com/bytedance/fedlearner}.
\newblock Accessed: 2023-01-10.

\bibitem[pad()]{paddlefl}
Paddlefl.
\newblock \url{https://github.com/PaddlePaddle/PaddleFL}.
\newblock Accessed: 2023-01-10.

\bibitem[tff()]{tff}
Tff.
\newblock \url{https://github.com/tensorflow/federated}.
\newblock Accessed: 2023-01-10.

\bibitem[Acar et~al.(2021)Acar, Zhao, Navarro, Mattina, Whatmough, and
  Saligrama]{acar2021federated}
Durmus Alp~Emre Acar, Yue Zhao, Ramon~Matas Navarro, Matthew Mattina, Paul~N
  Whatmough, and Venkatesh Saligrama.
\newblock Federated learning based on dynamic regularization.
\newblock \emph{arXiv preprint arXiv:2111.04263}, 2021.

\bibitem[Arivazhagan et~al.(2019)Arivazhagan, Aggarwal, Singh, and
  Choudhary]{arivazhagan2019federated}
Manoj~Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya~Kumar Singh, and Sunav
  Choudhary.
\newblock Federated learning with personalization layers.
\newblock \emph{arXiv preprint arXiv:1912.00818}, 2019.

\bibitem[Beutel et~al.(2020)Beutel, Topal, Mathur, Qiu, Parcollet,
  de~Gusm{\~a}o, and Lane]{beutel2020flower}
Daniel~J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan Parcollet,
  Pedro~PB de~Gusm{\~a}o, and Nicholas~D Lane.
\newblock Flower: A friendly federated learning research framework.
\newblock \emph{arXiv preprint arXiv:2007.14390}, 2020.

\bibitem[Bibikar et~al.(2022)Bibikar, Vikalo, Wang, and
  Chen]{bibikar2022federated}
Sameer Bibikar, Haris Vikalo, Zhangyang Wang, and Xiaohan Chen.
\newblock Federated dynamic sparse training: Computing less, communicating
  less, yet learning better.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pages 6080--6088, 2022.

\bibitem[Briggs et~al.(2020)Briggs, Fan, and Andras]{briggs2020federated}
Christopher Briggs, Zhong Fan, and Peter Andras.
\newblock Federated learning with hierarchical clustering of local updates to
  improve training on non-iid data.
\newblock In \emph{2020 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--9. IEEE, 2020.

\bibitem[Caldas et~al.(2018)Caldas, Wu, Li, Kone{\v{c}}n{\'y}, McMahan, Smith,
  and Talwalkar]{femnist}
Sebastian Caldas, Peter Wu, Tian Li, Jakub Kone{\v{c}}n{\'y}, H.~Brendan
  McMahan, Virginia Smith, and Ameet Talwalkar.
\newblock {LEAF:} {A} benchmark for federated settings.
\newblock \emph{CoRR}, abs/1812.01097, 2018.
\newblock URL \url{http://arxiv.org/abs/1812.01097}.

\bibitem[Chen et~al.(2022)Chen, Gao, Kuang, Li, and Ding]{chen2022pfl}
Daoyuan Chen, Dawei Gao, Weirui Kuang, Yaliang Li, and Bolin Ding.
\newblock pfl-bench: A comprehensive benchmark for personalized federated
  learning.
\newblock \emph{arXiv preprint arXiv:2206.03655}, 2022.

\bibitem[Chen et~al.(2018)Chen, Luo, Dong, Li, and He]{chen2018federated}
Fei Chen, Mi~Luo, Zhenhua Dong, Zhenguo Li, and Xiuqiang He.
\newblock Federated meta-learning with fast convergence and efficient
  communication.
\newblock \emph{arXiv preprint arXiv:1802.07876}, 2018.

\bibitem[Cho et~al.(2021)Cho, Wang, Chiruvolu, and Joshi]{cho2021personalized}
Yae~Jee Cho, Jianyu Wang, Tarun Chiruvolu, and Gauri Joshi.
\newblock Personalized federated learning for heterogeneous clients with
  clustered knowledge transfer.
\newblock \emph{arXiv preprint arXiv:2109.08119}, 2021.

\bibitem[Coates et~al.(2011)Coates, Ng, and Lee]{stl-10}
Adam Coates, Andrew Ng, and Honglak Lee.
\newblock An analysis of single-layer networks in unsupervised feature
  learning.
\newblock In Geoffrey Gordon, David Dunson, and Miroslav Dud√≠k, editors,
  \emph{Proceedings of the Fourteenth International Conference on Artificial
  Intelligence and Statistics}, volume~15 of \emph{Proceedings of Machine
  Learning Research}, pages 215--223, Fort Lauderdale, FL, USA, 11--13 Apr
  2011. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v15/coates11a.html}.

\bibitem[Collins et~al.(2021)Collins, Hassani, Mokhtari, and
  Shakkottai]{collins2021exploiting}
Liam Collins, Hamed Hassani, Aryan Mokhtari, and Sanjay Shakkottai.
\newblock Exploiting shared representations for personalized federated
  learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  2089--2099. PMLR, 2021.

\bibitem[Dayan et~al.(2021)Dayan, Roth, Zhong, Harouni, Gentili, Abidin, Liu,
  Costa, Wood, Tsai, et~al.]{dayan2021federated}
Ittai Dayan, Holger~R Roth, Aoxiao Zhong, Ahmed Harouni, Amilcare Gentili,
  Anas~Z Abidin, Andrew Liu, Anthony~Beardsworth Costa, Bradford~J Wood,
  Chien-Sung Tsai, et~al.
\newblock Federated learning for predicting clinical outcomes in patients with
  covid-19.
\newblock \emph{Nature medicine}, 27\penalty0 (10):\penalty0 1735--1743, 2021.

\bibitem[Deng(2012)]{mnist}
Li~Deng.
\newblock The mnist database of handwritten digit images for machine learning
  research.
\newblock \emph{IEEE Signal Processing Magazine}, 29\penalty0 (6):\penalty0
  141--142, 2012.

\bibitem[Deng et~al.(2020)Deng, Kamani, and Mahdavi]{deng2020adaptive}
Yuyang Deng, Mohammad~Mahdi Kamani, and Mehrdad Mahdavi.
\newblock Adaptive personalized federated learning.
\newblock \emph{arXiv preprint arXiv:2003.13461}, 2020.

\bibitem[Dimitriadis et~al.(2022)Dimitriadis, Garcia, Diaz, Manoel, and
  Sim]{dimitriadis2022flute}
Dimitrios Dimitriadis, Mirian~Hipolito Garcia, Daniel~Madrigal Diaz, Andre
  Manoel, and Robert Sim.
\newblock Flute: A scalable, extensible framework for high-performance
  federated learning simulations.
\newblock \emph{arXiv preprint arXiv:2203.13789}, 2022.

\bibitem[Dinh et~al.(2021)Dinh, Vu, Tran, Dao, and Zhang]{dinh2021fedu}
Canh~T Dinh, Tung~T Vu, Nguyen~H Tran, Minh~N Dao, and Hongyu Zhang.
\newblock Fedu: A unified framework for federated multi-task learning with
  laplacian regularization.
\newblock \emph{arXiv preprint arXiv:2102.07148}, 400, 2021.

\bibitem[Duan et~al.(2021)Duan, Liu, Ji, Wu, Liang, Chen, Tan, and
  Ren]{duan2021flexible}
Moming Duan, Duo Liu, Xinyuan Ji, Yu~Wu, Liang Liang, Xianzhang Chen, Yujuan
  Tan, and Ao~Ren.
\newblock Flexible clustered federated learning for client-level data
  distribution shift.
\newblock \emph{IEEE Transactions on Parallel and Distributed Systems}, 2021.

\bibitem[Fallah et~al.(2020)Fallah, Mokhtari, and
  Ozdaglar]{fallah2020personalized}
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.
\newblock Personalized federated learning: A meta-learning approach.
\newblock \emph{arXiv preprint arXiv:2002.07948}, 2020.

\bibitem[Ghosh et~al.(2020)Ghosh, Chung, Yin, and
  Ramchandran]{ghosh2020efficient}
Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran.
\newblock An efficient framework for clustered federated learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 19586--19597, 2020.

\bibitem[Gong et~al.(2021)Gong, Sharma, Karanam, Wu, Chen, Doermann, and
  Innanje]{gong2021ensemble}
Xuan Gong, Abhishek Sharma, Srikrishna Karanam, Ziyan Wu, Terrence Chen, David
  Doermann, and Arun Innanje.
\newblock Ensemble attention distillation for privacy-preserving federated
  learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 15076--15086, 2021.

\bibitem[Haddadpour and Mahdavi(2019)]{haddadpour2019convergence}
Farzin Haddadpour and Mehrdad Mahdavi.
\newblock On the convergence of local descent methods in federated learning.
\newblock \emph{arXiv preprint arXiv:1910.14425}, 2019.

\bibitem[Hanzely et~al.(2020)Hanzely, Hanzely, Horv{\'a}th, and
  Richt{\'a}rik]{hanzely2020lower}
Filip Hanzely, Slavom{\'\i}r Hanzely, Samuel Horv{\'a}th, and Peter
  Richt{\'a}rik.
\newblock Lower bounds and optimal algorithms for personalized federated
  learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 2304--2315, 2020.

\bibitem[He et~al.(2020)He, Li, So, Zeng, Zhang, Wang, Wang, Vepakomma, Singh,
  Qiu, et~al.]{he2020fedml}
Chaoyang He, Songze Li, Jinhyun So, Xiao Zeng, Mi~Zhang, Hongyi Wang, Xiaoyang
  Wang, Praneeth Vepakomma, Abhishek Singh, Hang Qiu, et~al.
\newblock Fedml: A research library and benchmark for federated machine
  learning.
\newblock \emph{arXiv preprint arXiv:2007.13518}, 2020.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition, 2015.
\newblock URL \url{https://arxiv.org/abs/1512.03385}.

\bibitem[Hsieh et~al.(2020)Hsieh, Phanishayee, Mutlu, and
  Gibbons]{hsieh2020non}
Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons.
\newblock The non-iid data quagmire of decentralized machine learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  4387--4398. PMLR, 2020.

\bibitem[Hsu et~al.(2019)Hsu, Qi, and Brown]{hsu2019measuring}
Tzu-Ming~Harry Hsu, Hang Qi, and Matthew Brown.
\newblock Measuring the effects of non-identical data distribution for
  federated visual classification.
\newblock \emph{arXiv preprint arXiv:1909.06335}, 2019.

\bibitem[Huang et~al.(2022)Huang, Liu, Shen, He, Lin, and
  Tao]{huang2022achieving}
Tiansheng Huang, Shiwei Liu, Li~Shen, Fengxiang He, Weiwei Lin, and Dacheng
  Tao.
\newblock Achieving personalized federated learning with sparse local models.
\newblock \emph{arXiv preprint arXiv:2201.11380}, 2022.

\bibitem[{Hull}(1994)]{usps}
J.~J. {Hull}.
\newblock A database for handwritten text recognition research.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 16\penalty0 (5):\penalty0 550--554, 1994.
\newblock \doi{10.1109/34.291440}.

\bibitem[Jiang et~al.(2019)Jiang, Kone{\v{c}}n{\`y}, Rush, and
  Kannan]{jiang2019improving}
Yihan Jiang, Jakub Kone{\v{c}}n{\`y}, Keith Rush, and Sreeram Kannan.
\newblock Improving federated learning personalization via model agnostic meta
  learning.
\newblock \emph{arXiv preprint arXiv:1909.12488}, 2019.

\bibitem[Kairouz et~al.(2019)Kairouz, McMahan, Avent, Bellet, Bennis, Bhagoji,
  Bonawitz, Charles, Cormode, Cummings, et~al.]{kairouz2019advances}
Peter Kairouz, H~Brendan McMahan, Brendan Avent, Aur{\'e}lien Bellet, Mehdi
  Bennis, Arjun~Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode,
  Rachel Cummings, et~al.
\newblock Advances and open problems in federated learning.
\newblock \emph{arXiv preprint arXiv:1912.04977}, 2019.

\bibitem[Kairouz et~al.(2021)Kairouz, McMahan, Avent, Bellet, Bennis, Bhagoji,
  Bonawitz, Charles, Cormode, Cummings, et~al.]{kairouz2021advances}
Peter Kairouz, H~Brendan McMahan, Brendan Avent, Aur{\'e}lien Bellet, Mehdi
  Bennis, Arjun~Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
  Cormode, Rachel Cummings, et~al.
\newblock Advances and open problems in federated learning.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  14\penalty0 (1--2):\penalty0 1--210, 2021.

\bibitem[Karimireddy et~al.(2020{\natexlab{a}})Karimireddy, Jaggi, Kale, Mohri,
  Reddi, Stich, and Suresh]{karimireddy2020mime}
Sai~Praneeth Karimireddy, Martin Jaggi, Satyen Kale, Mehryar Mohri, Sashank~J
  Reddi, Sebastian~U Stich, and Ananda~Theertha Suresh.
\newblock Mime: Mimicking centralized stochastic algorithms in federated
  learning.
\newblock \emph{arXiv preprint arXiv:2008.03606}, 2020{\natexlab{a}}.

\bibitem[Karimireddy et~al.(2020{\natexlab{b}})Karimireddy, Kale, Mohri, Reddi,
  Stich, and Suresh]{karimireddy2020scaffold}
Sai~Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian
  Stich, and Ananda~Theertha Suresh.
\newblock Scaffold: Stochastic controlled averaging for federated learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  5132--5143. PMLR, 2020{\natexlab{b}}.

\bibitem[Krizhevsky et~al.(2009{\natexlab{a}})Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009{\natexlab{a}}.

\bibitem[Krizhevsky et~al.(2009{\natexlab{b}})]{cifar}
Alex Krizhevsky et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009{\natexlab{b}}.

\bibitem[Kulkarni et~al.(2020)Kulkarni, Kulkarni, and Pant]{kulkarni2020survey}
Viraj Kulkarni, Milind Kulkarni, and Aniruddha Pant.
\newblock Survey of personalization techniques for federated learning.
\newblock In \emph{2020 Fourth World Conference on Smart Trends in Systems,
  Security and Sustainability (WorldS4)}, pages 794--797. IEEE, 2020.

\bibitem[Le and Yang()]{tiny}
Ya~Le and Xuan Yang.
\newblock Tiny imagenet visual recognition challenge.

\bibitem[Lecun et~al.(1998)Lecun, Bottou, Bengio, and Haffner]{lenet}
Y.~Lecun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.
\newblock \doi{10.1109/5.726791}.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Sun, Wang, Duan, Li, Chen, and
  Li]{li2020lotteryfl}
Ang Li, Jingwei Sun, Binghui Wang, Lin Duan, Sicheng Li, Yiran Chen, and Hai
  Li.
\newblock Lotteryfl: Personalized and communication-efficient federated
  learning with lottery ticket hypothesis on non-iid datasets.
\newblock \emph{arXiv preprint arXiv:2008.03371}, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Sun, Zeng, Zhang, Li, and
  Chen]{li2021fedmask}
Ang Li, Jingwei Sun, Xiao Zeng, Mi~Zhang, Hai Li, and Yiran Chen.
\newblock Fedmask: Joint computation and communication-efficient personalized
  federated learning via heterogeneous masking.
\newblock In \emph{Proceedings of the 19th ACM Conference on Embedded Networked
  Sensor Systems}, pages 42--55, 2021{\natexlab{a}}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Diao, Chen, and He]{li2021federated}
Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He.
\newblock Federated learning on non-iid data silos: An experimental study.
\newblock \emph{arXiv preprint arXiv:2102.02079}, 2021{\natexlab{b}}.

\bibitem[Li et~al.(2021{\natexlab{c}})Li, He, and Song]{li2021model}
Qinbin Li, Bingsheng He, and Dawn Song.
\newblock Model-contrastive federated learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10713--10722, 2021{\natexlab{c}}.

\bibitem[Li et~al.(2019)Li, Sahu, Zaheer, Sanjabi, Talwalkar, and
  Smithy]{li2019feddane}
Tian Li, Anit~Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
  Virginia Smithy.
\newblock Feddane: A federated newton-type method.
\newblock In \emph{2019 53rd Asilomar Conference on Signals, Systems, and
  Computers}, pages 1227--1231. IEEE, 2019.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Sahu, Zaheer, Sanjabi, Talwalkar, and
  Smith]{li2020federated}
Tian Li, Anit~Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
  Virginia Smith.
\newblock Federated optimization in heterogeneous networks.
\newblock \emph{Proceedings of Machine Learning and Systems}, 2:\penalty0
  429--450, 2020{\natexlab{b}}.

\bibitem[Li et~al.(2021{\natexlab{d}})Li, Hu, Beirami, and Smith]{li2021ditto}
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith.
\newblock Ditto: Fair and robust federated learning through personalization.
\newblock In \emph{International Conference on Machine Learning}, pages
  6357--6368. PMLR, 2021{\natexlab{d}}.

\bibitem[Li et~al.(2021{\natexlab{e}})Li, Jiang, Zhang, Kamp, and
  Dou]{li2021fedbn}
Xiaoxiao Li, Meirui Jiang, Xiaofei Zhang, Michael Kamp, and Qi~Dou.
\newblock Fedbn: Federated learning on non-iid features via local batch
  normalization.
\newblock \emph{arXiv preprint arXiv:2102.07623}, 2021{\natexlab{e}}.

\bibitem[Liang et~al.(2020)Liang, Liu, Ziyin, Allen, Auerbach, Brent,
  Salakhutdinov, and Morency]{liang2020think}
Paul~Pu Liang, Terrance Liu, Liu Ziyin, Nicholas~B Allen, Randy~P Auerbach,
  David Brent, Ruslan Salakhutdinov, and Louis-Philippe Morency.
\newblock Think locally, act globally: Federated learning with local and global
  representations.
\newblock \emph{arXiv preprint arXiv:2001.01523}, 2020.

\bibitem[Lin et~al.(2020)Lin, Kong, Stich, and Jaggi]{lin2020ensemble}
Tao Lin, Lingjing Kong, Sebastian~U Stich, and Martin Jaggi.
\newblock Ensemble distillation for robust model fusion in federated learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 2351--2363, 2020.

\bibitem[Liu et~al.(2022{\natexlab{a}})Liu, Lou, Wang, Xi, Shen, and
  Yan]{liu2022deep}
Chang Liu, Chenfei Lou, Runzhong Wang, Alan~Yuhan Xi, Li~Shen, and Junchi Yan.
\newblock Deep neural network fusion via graph matching with applications to
  model ensemble and federated learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  13857--13869. PMLR, 2022{\natexlab{a}}.

\bibitem[Liu et~al.(2022{\natexlab{b}})Liu, Shi, Xie, Li, Hu, Kim, Xu, Li, and
  Song]{liu2022unifed}
Xiaoyuan Liu, Tianneng Shi, Chulin Xie, Qinbin Li, Kangping Hu, Haoyu Kim,
  Xiaojun Xu, Bo~Li, and Dawn Song.
\newblock Unifed: A benchmark for federated learning frameworks.
\newblock \emph{arXiv preprint arXiv:2207.10308}, 2022{\natexlab{b}}.

\bibitem[Liu et~al.(2021)Liu, Fan, Chen, Xu, and Yang]{liu2021fate}
Yang Liu, Tao Fan, Tianjian Chen, Qian Xu, and Qiang Yang.
\newblock Fate: An industrial grade platform for collaborative learning with
  data protection.
\newblock \emph{J. Mach. Learn. Res.}, 22\penalty0 (226):\penalty0 1--6, 2021.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{celeba}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, December 2015.

\bibitem[Lyu et~al.(2022)Lyu, Hanzely, and Kolar]{lyu2022personalized}
Boxiang Lyu, Filip Hanzely, and Mladen Kolar.
\newblock Personalized federated learning with multiple known clusters.
\newblock \emph{arXiv preprint arXiv:2204.13619}, 2022.

\bibitem[Mahlool and Abed(2022)]{mahlool2022comprehensive}
Dhurgham~Hassan Mahlool and Mohammed~Hamzah Abed.
\newblock A comprehensive survey on federated learning: Concept and
  applications.
\newblock \emph{arXiv preprint arXiv:2201.09384}, 2022.

\bibitem[Mansour et~al.(2020)Mansour, Mohri, Ro, and Suresh]{mansour2020three}
Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda~Theertha Suresh.
\newblock Three approaches for personalization with applications to federated
  learning.
\newblock \emph{arXiv preprint arXiv:2002.10619}, 2020.

\bibitem[Marfoq et~al.(2021)Marfoq, Neglia, Bellet, Kameni, and
  Vidal]{marfoq2021federated}
Othmane Marfoq, Giovanni Neglia, Aur{\'e}lien Bellet, Laetitia Kameni, and
  Richard Vidal.
\newblock Federated multi-task learning under a mixture of distributions.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 15434--15447, 2021.

\bibitem[Marfoq et~al.(2022)Marfoq, Neglia, Vidal, and
  Kameni]{marfoq2022personalized}
Othmane Marfoq, Giovanni Neglia, Richard Vidal, and Laetitia Kameni.
\newblock Personalized federated learning through local memorization.
\newblock In \emph{International Conference on Machine Learning}, pages
  15070--15092. PMLR, 2022.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and
  y~Arcas]{mcmahan2017communication}
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise~Aguera
  y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In \emph{Artificial intelligence and statistics}, pages 1273--1282.
  PMLR, 2017.

\bibitem[Mohri et~al.(2019)Mohri, Sivek, and Suresh]{mohri2019agnostic}
Mehryar Mohri, Gary Sivek, and Ananda~Theertha Suresh.
\newblock Agnostic federated learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  4615--4625. PMLR, 2019.

\bibitem[Muhammad et~al.(2020)Muhammad, Wang, O'Reilly-Morgan, Tragos, Smyth,
  Hurley, Geraci, and Lawlor]{muhammad2020fedfast}
Khalil Muhammad, Qinqin Wang, Diarmuid O'Reilly-Morgan, Elias Tragos, Barry
  Smyth, Neil Hurley, James Geraci, and Aonghus Lawlor.
\newblock Fedfast: Going beyond average for faster training of federated
  recommender systems.
\newblock In \emph{Proceedings of the 26th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 1234--1242, 2020.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and Ng]{svhn}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y.
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{NIPS Workshop on Deep Learning and Unsupervised Feature
  Learning 2011}, 2011.
\newblock URL
  \url{http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf}.

\bibitem[Pillutla et~al.(2022)Pillutla, Malik, Mohamed, Rabbat, Sanjabi, and
  Xiao]{pillutla2022federated}
Krishna Pillutla, Kshitiz Malik, Abdelrahman Mohamed, Michael Rabbat, Maziar
  Sanjabi, and Lin Xiao.
\newblock Federated learning with partial model personalization.
\newblock \emph{arXiv preprint arXiv:2204.03809}, 2022.

\bibitem[Reddi et~al.(2020)Reddi, Charles, Zaheer, Garrett, Rush,
  Kone{\v{c}}n{\`y}, Kumar, and McMahan]{reddi2020adaptive}
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush,
  Jakub Kone{\v{c}}n{\`y}, Sanjiv Kumar, and H~Brendan McMahan.
\newblock Adaptive federated optimization.
\newblock \emph{arXiv preprint arXiv:2003.00295}, 2020.

\bibitem[Sattler et~al.(2020)Sattler, M{\"u}ller, and
  Samek]{sattler2020clustered}
Felix Sattler, Klaus-Robert M{\"u}ller, and Wojciech Samek.
\newblock Clustered federated learning: Model-agnostic distributed multitask
  optimization under privacy constraints.
\newblock \emph{IEEE transactions on neural networks and learning systems},
  32\penalty0 (8):\penalty0 3710--3722, 2020.

\bibitem[Sattler et~al.(2021)Sattler, Korjakow, Rischke, and
  Samek]{sattler2021fedaux}
Felix Sattler, Tim Korjakow, Roman Rischke, and Wojciech Samek.
\newblock Fedaux: Leveraging unlabeled auxiliary data in federated learning.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  2021.

\bibitem[Simonyan and Zisserman(2014)]{vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition,
  2014.
\newblock URL \url{https://arxiv.org/abs/1409.1556}.

\bibitem[Singhal et~al.(2021)Singhal, Sidahmed, Garrett, Wu, Rush, and
  Prakash]{singhal2021federated}
Karan Singhal, Hakim Sidahmed, Zachary Garrett, Shanshan Wu, John Rush, and
  Sushant Prakash.
\newblock Federated reconstruction: Partially local federated learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11220--11232, 2021.

\bibitem[Smith et~al.(2017)Smith, Chiang, Sanjabi, and
  Talwalkar]{smith2017federated}
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet~S Talwalkar.
\newblock Federated multi-task learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Sui et~al.(2020)Sui, Chen, Zhao, Jia, Xie, and Sun]{sui2020feded}
Dianbo Sui, Yubo Chen, Jun Zhao, Yantao Jia, Yuantao Xie, and Weijian Sun.
\newblock Feded: Federated learning via ensemble distillation for medical
  relation extraction.
\newblock In \emph{Proceedings of the 2020 conference on empirical methods in
  natural language processing (EMNLP)}, pages 2118--2128, 2020.

\bibitem[T~Dinh et~al.(2020)T~Dinh, Tran, and Nguyen]{t2020personalized}
Canh T~Dinh, Nguyen Tran, and Josh Nguyen.
\newblock Personalized federated learning with moreau envelopes.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 21394--21405, 2020.

\bibitem[Tan et~al.(2022)Tan, Yu, Cui, and Yang]{tan2022towards}
Alysa~Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang.
\newblock Towards personalized federated learning.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  2022.

\bibitem[Vahidian et~al.(2021)Vahidian, Morafah, and
  Lin]{vahidian2021personalized}
Saeed Vahidian, Mahdi Morafah, and Bill Lin.
\newblock Personalized federated learning by structured and unstructured
  pruning under data heterogeneity.
\newblock In \emph{2021 IEEE 41st International Conference on Distributed
  Computing Systems Workshops (ICDCSW)}, pages 27--34. IEEE, 2021.

\bibitem[Vahidian et~al.(2022)Vahidian, Morafah, Wang, Kungurtsev, Chen, Shah,
  and Lin]{vahidian2022efficient}
Saeed Vahidian, Mahdi Morafah, Weijia Wang, Vyacheslav Kungurtsev, Chen Chen,
  Mubarak Shah, and Bill Lin.
\newblock Efficient distribution similarity identification in clustered
  federated learning via principal angles between client data subspaces.
\newblock \emph{arXiv preprint arXiv:2209.10526}, 2022.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Yurochkin, Sun, Papailiopoulos,
  and Khazaeni]{wang2020federated}
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and
  Yasaman Khazaeni.
\newblock Federated learning with matched averaging.
\newblock \emph{arXiv preprint arXiv:2002.06440}, 2020{\natexlab{a}}.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Liu, Liang, Joshi, and
  Poor]{wang2020tackling}
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H~Vincent Poor.
\newblock Tackling the objective inconsistency problem in heterogeneous
  federated optimization.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 7611--7623, 2020{\natexlab{b}}.

\bibitem[Wu et~al.(2022)Wu, Li, Charles, Xiao, Liu, Xu, and
  Smith]{wu2022motley}
Shanshan Wu, Tian Li, Zachary Charles, Yu~Xiao, Ziyu Liu, Zheng Xu, and
  Virginia Smith.
\newblock Motley: Benchmarking heterogeneity and personalization in federated
  learning.
\newblock \emph{arXiv preprint arXiv:2206.09262}, 2022.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{fmnist}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms, 2017.

\bibitem[Yang et~al.(2018)Yang, Andrew, Eichner, Sun, Li, Kong, Ramage, and
  Beaufays]{yang2018applied}
Timothy Yang, Galen Andrew, Hubert Eichner, Haicheng Sun, Wei Li, Nicholas
  Kong, Daniel Ramage, and Fran{\c{c}}oise Beaufays.
\newblock Applied federated learning: Improving google keyboard query
  suggestions.
\newblock \emph{arXiv preprint arXiv:1812.02903}, 2018.

\bibitem[Zhang et~al.(2020)Zhang, Sapra, Fidler, Yeung, and
  Alvarez]{zhang2020personalized}
Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose~M Alvarez.
\newblock Personalized federated learning with first order model optimization.
\newblock \emph{arXiv preprint arXiv:2012.08565}, 2020.

\bibitem[Zhao et~al.(2018)Zhao, Li, Lai, Suda, Civin, and
  Chandra]{zhao2018federated}
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.
\newblock Federated learning with non-iid data.
\newblock \emph{arXiv preprint arXiv:1806.00582}, 2018.

\bibitem[Zhu et~al.(2021)Zhu, Xu, Liu, and Jin]{zhu2021federated}
Hangyu Zhu, Jinjin Xu, Shiqing Liu, and Yaochu Jin.
\newblock Federated learning on non-iid data: A survey.
\newblock \emph{Neurocomputing}, 465:\penalty0 371--390, 2021.

\end{thebibliography}
