\section{FedZoo-Bench}\label{fedzoo}
We introduce FedZoo-Bench, an open-source library based on PyTorch that facilitates experimentation in federated learning by providing researchers with a comprehensive set of standardized and customizable features such as training, Non-IID data partitioning, fine-tuning, performance evaluation, fairness assessment, and generalization to newcomers, for both global and personalized FL approaches. Additionally, it comes pre-equipped with a set of models and datasets, \textcolor{red}{and} pre-implemented 22 different SOTA methods, allowing researchers to quickly test their ideas and hypotheses. FedZoo-Bench is a powerful tool that empowers researchers to explore new frontiers in federated learning and \textcolor{red}{enables} fair, consistent, and reproducible research in federated learning. We have provided more details on the implemented algorithms and available features in Appendix Section~\ref{sec:app-fedzoo}.



% our codebase has many implementations
% previous benchmarks put their effort on to make FL runnable on different platforms and implement few algorithms or only FedAvg. 
% extension of previous benchmarks to cutomizable settings is not easy or clear thus not convenient for academic research purposes. not flexible to custom implementations and research
% researchers need to compare with other baselines and usually the baselines have been implemented in different codebases for a fixed setting. Fedzoo-Bench eliminated the need for researchers to spend time re-implement the methods in their codebase to test on their customized setting. 
% By providing these features in a standardized and easy-to-use format, FedZoo-Bench enables researchers to focus on their research and not on the technicalities of implementation.
% Federated learning is a rapidly growing field with the potential to revolutionize the way we approach machine learning. However, the complex nature of federated learning can make it challenging for researchers to implement their ideas and study its full potential.

% All of the existing FL benchmarks put their focus on making different platforms to be able to perform federated learning. They mostly implement few algorithms (many just FedAvg) using their platform to realize that and their platform has less flexibility to be extended to different experimental settings for academic research purposes. However, FedZoo-Bench contains the implementation of more than XX different algorithms in PyTorch with easy extension to custom algorithm implementation and experimental setups. We defer discussions of FedZoo-Bench's implementation and use case for different settings to the project's documentation.

%Despite the extensive amount of works have been done for both FL approaches, the state of progress is not well understood. This issue comes from lack of understanding in FL experimental design setups and consistent evaluation of methods under a common experimental setup and implementation.
\subsection{Comparison of SOTA methods}\label{sec:comparison}
In this section, we present a comprehensive experimental comparison of several SOTA FL methods using FedZoo-Bench. We evaluate their performance, fairness, and generalization to new clients \textcolor{red}{in} a consistent experimental setting. Our experiments aim to provide a better understanding of the current progress in FL research.

\textbf{Training setting.} Following our recommended settings indicated in Table~\ref{tab:recommended-settings}, we choose two different training settings presented in Table~\ref{tab:training-setting} to conduct the experimental comparison of the baselines for each FL approach. We run each of the baselines 3 times and report the average and standard deviation of the results. 
%For more details of the hyperparameters used for each baseline, see Appendix Section~\ref{sec:app-hyperparameters}.

\begin{table}[hb]
\caption{Training settings}
\centering
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{c|ccccccc}
\toprule
Setting           & Dataset & Architecture & clients & sample rate & local epochs & partitioning & communication rounds  \\
\midrule
gFL \#1 & CIFAR-10 & LeNet-5 & 100 & 0.1 & 5 & Non-IID Label Skew(80\%) & 100\\
\midrule
gFL \#2 & CIFAR-100 & ResNet-9 & 20 & 0.2 & 10 & Non-IID Label Dir(0.5) & 100 \\
\midrule
pFL \#1 & CIFAR-10 & LeNet-5 & 100 & 0.1 & 10 & Non-IID Label Skew(30\%) & 100\\
\midrule
pFL \#2 & CIFAR-100 & ResNet-9 & 20 & 0.2 & 10 & Non-IID Label Dir(0.1) & 100 \\
\bottomrule
\end{tabular}
}
\label{tab:training-setting}
\end{table}

\begin{table}[ht]
\caption{Performance and fairness comparison for personalized FL baselines.}
\begin{center}
\begin{subtable}[c]{.8\linewidth}
\caption{Performance Comparison}
\label{tab:pfl-acc}
\centering
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{l|c|c}
            \toprule
Algorithm & Setting (pFL \#1) & Setting (pFL \#2)\\
            \midrule
FedAvg + FT~\cite{jiang2019improving}  & $69.26\pm0.42$ & $49.03\pm0.40$  \\
            \midrule         
LG-FedAvg~\cite{liang2020think}  & $54.03\pm2.16$ & $25.30\pm0.50$\\
            \midrule  
PerFedAvg~\cite{fallah2020personalized}  & $76.03\pm0.31$ & $2.29\pm0.07$ \\
            \midrule
IFCA~\cite{ghosh2020efficient}  & $64.84\pm3.41$ & $46.73\pm1.82$ \\
            \midrule
Ditto~\cite{li2021ditto}  & $70.97\pm1.27$ & $48.16\pm3.25$ \\
            \midrule
FedPer~\cite{arivazhagan2019federated}  & $64.64\pm0.45$ & $42.87\pm1.66$ \\
            \midrule
FedRep~\cite{collins2021exploiting}  & $54.99\pm 3.16$ & $29.39\pm0.31$ \\
            \midrule
APFL~\cite{deng2020adaptive}  & $68.91\pm0.59$ & $55.18\pm0.65$ \\
            \midrule
pFedMe~\cite{t2020personalized}  & $10.00\pm0.98$ & $2.10\pm0.30$ \\
            \midrule
CFL~\cite{sattler2020clustered}  & $16.83\pm1.6$ & $1.52\pm0.17$ \\
            \midrule
SubFedAvg~\cite{vahidian2021personalized} & $69.95\pm1.34$ & $49.83\pm1.09$ \\
            \midrule
PACFL~\cite{vahidian2022efficient}  & $67.78\pm0.11$ & $50.11\pm1.10$ \\
            \bottomrule
\end{tabular}
}
\vspace{0.2cm}
\end{subtable}
\end{center}
\begin{center}
\begin{subtable}[c]{.8\linewidth}
\caption{Fairness Comparison}
\label{tab:pfl-fairness}
\centering
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{l|c|c}
            \toprule
Algorithm & Setting (pFL \#1) & Setting (pFL \#2) \\
            \midrule
FedAvg + FT~\cite{jiang2019improving}  & $8.05\pm0.32$ & $5.40\pm0.77$  \\
            \midrule       
LG-FedAvg~\cite{liang2020think}  & $12.79\pm0.64$ & $5.11\pm0.38$\\
            \midrule  
PerFedAvg~\cite{fallah2020personalized}  & $7.32\pm0.27$ & $--$ \\
            \midrule 
IFCA~\cite{ghosh2020efficient}  & $10.56\pm2.75$ & $5.03\pm0.07$ \\
            \midrule  
Ditto~\cite{li2021ditto}  & $7.50\pm0.37$ & $4.10\pm0.73$ \\
            \midrule  
FedPer~\cite{arivazhagan2019federated}  & $7.64\pm0.59$ & $6.19\pm0.59$ \\
            \midrule  
FedRep~\cite{collins2021exploiting}  & $9.18\pm0.50$ & $5.19\pm0.73$ \\
            \midrule  
APFL~\cite{deng2020adaptive}  & $8.22\pm0.96$ & $4.60\pm1.15$ \\
            \midrule
pFedMe~\cite{t2020personalized}  & $--$ & $--$ \\
            \midrule
SubFedAvg~\cite{vahidian2021personalized} & $7.44\pm0.46$ & $4.66\pm0.56$ \\
            \midrule
CFL~\cite{sattler2020clustered} & $--$ & $--$ \\
            \midrule
PACFL~\cite{vahidian2022efficient} & $8.82\pm0.71$ & $4.68\pm0.42$ \\
            \bottomrule
\end{tabular}
}
\end{subtable}
\end{center}
\end{table}

\textbf{Performance comparison.} We use the evaluation metrics outlined in Section~\ref{def:gfl} to compare the performance results. \vspace{-0.1cm}
\begin{itemize}
    \item \textbf{Global FL.} Table~\ref{tab:gfl-acc} shows the performance results of 6 different global FL methods. As it is noticeable Scaffold and FedProx \textcolor{red}{have} given the best results in settings (gfl \#1) and (gfl \#2), respectively and FedDF has given the worst results in both settings. FedAvg which is the simplest method has appeared to be competitive in both settings and even better than 4 other algorithms in setting (gfl \#2).
    \item \textbf{Personalized FL.} In Table~\ref{tab:pfl-acc}, we present the performance results of 12 different personalized FL methods. Similar to global FL methods (Table~\ref{tab:gfl-acc}), we observe that each method performs differently in different settings. No single method consistently achieves the best results across all settings. For example, PerFedAvg performs well in setting (pfl \#1), but poorly in setting (pfl \#2). Additionally, CFL and pFedMe perform poorly in both settings. On the other hand, FedAvg + FT, the simplest baseline, performs fairly well in both settings and is competitive or even superior to several other methods.
\end{itemize} 

\textbf{Fairness comparison.} Fairness is another important aspect \textcolor{red}{of the} personalized FL approach. We use the fairness metric mentioned in~\cite{li2021ditto, mohri2019agnostic} which is the standard deviation of final local test accuracies. Table~\ref{tab:pfl-fairness} shows the fairness comparison of the methods. SubFedAvg and Ditto have achieved the best fairness results in (pfl \#1) and (pfl \#2) settings, respectively. FedAvg + FT also demonstrated competitive fairness results in both settings. For algorithms having poor results we did not report the fairness results as they would not be meaningful.

\textbf{Generalization to newcomers.} To evaluate the generalization capabilities of personalized FL methods to newcomers, we reserve 20\% of the clients as newcomers and train the FL models using the remaining 80\% clients. While the adaptation process for many methods is not explicitly clear, we follow the same procedure as in~\cite{marfoq2021federated, vahidian2022efficient} and allow the newcomers to receive the trained FL model and perform local fine-tuning. For methods like PACFL that have a different adaptation strategy, we follow their original approach. Table~\ref{tab:pfl-newcommers} shows the results of this evaluation.

% \textbf{Suggested settings.} In the previous section, we analyzed effects of different experimental design variables in FL. Now, we are ready to propose a unified FL settings  to compare algorithms. To have a comprehensive and fair comparison which reflects how all the baselines perform under different FL variables, we propose the following settings: 
% \begin{itemize}
%     \item Personalized FL: 
%     \begin{itemize}
%         \item Accuracy: \{Dir(0.1), Skew(3)\}, Epoch=\{10, 5\}, Comm=100, Clients=100, sample rate = 0.1
%         \item Communication: \{Dir(0.1), Skew(3)\}, Epoch=1, Comm=250, Clients=100, sample rate = 0.1
%         \item Sample rate: \{Dir(0.1), Skew(3)\}, Epoch=5, Comm=100, Clients=100, sample rate = 0.2, 0.5
%     \end{itemize}
%     \item Global FL
%     \begin{itemize}
%         \item Accuracy: \{Dir(0.5), Skew(9)\}, Epoch=\{10, 5\}, Comm=100, Clients=100, sample rate = 0.1
%         \item Communication: \{Dir(0.5), Skew(9)\}, Epoch=1, Comm=250, Clients=100, sample rate = 0.1
%         \item Sample rate: \{Dir(0.5), Skew(9)\}, Epoch=5, Comm=100, Clients=100, sample rate = 0.2, 0.5
%     \end{itemize}
% \end{itemize}
% Since, (dataset, architecture) is also important in the experiments, we suggest (CIFAR-10, LeNet-5) and (CIFAR-100, Resnet-9) for our study.

% \begin{table}
% \begin{center}
% \caption{pFL accuracy comparison}
% \label{tab:pfl-acc}
% \centering
% \resizebox{0.5\linewidth}{!}{
% \begin{tabular}{l|cc|cc|c}
%             \toprule
% \multirow{2}{*}{Algorithm} & \multicolumn{2}{c|}{(CIFAR-10, LeNet-5, Skew(30\%))} & \multicolumn{2}{c|}{(CIFAR-100, ResNet-9, Dir(0.1))} &  \multirow{2}{*}{Rank}\\
%           \cmidrule{2-3} \cmidrule{4-5}
%  & Epoch=5 & Epoch=10 & Epoch=5 & Epoch=10 \\
%             \midrule
% FedAvg+  & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$\\
%             \midrule         
% FedAvg+  & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$\\
%             \midrule  
% FedAvg+  & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$\\
%             \midrule  
% FedAvg+  & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$\\
%             \midrule  
% FedAvg+  & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$\\
%             \midrule  
% FedAvg+  & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$\\
%             \midrule  
% FedAvg+  & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$\\
%             \midrule  
% FedAvg+  & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$\\
%             \midrule  
% FedAvg+  & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$ & $XX\pm XX$\\
%             \midrule  
% \end{tabular}
% }
% \end{center}
% \end{table}

\textbf{Discussion.} The experimental comparison between several SOTA methods for each FL approach outlined in this section highlights the progress that has been made in FL research. While we can see that many methods have improved compared to the simple FedAvg and FedAvg + FT baselines for global and personalized FL approaches, respectively, there are also some limitations that are worth noting:
\begin{itemize}
    \item There is no method that consistently performs the best across all experimental settings. Furthermore, for the personalized FL approach, a method may achieve good fairness results but lack generalization to newcomers. Thus, evaluating FL methods from different perspectives and developing algorithms that can provide a better trade-off is crucial.
    \item Despite the existence of numerous works for each FL approach, the performance of the simple methods of FedAvg and FedAvg + FT are still competitive or even better compared to several methods. Thus, there is a need for new methods that can achieve consistent improvements across different types of statistical heterogeneity.
    \item Fairness and generalization to newcomers are two important aspects of the personalized FL approach that are often overlooked in the literature and \textcolor{red}{are} only focused on performance improvement. Therefore, it is crucial to consider these aspects in addition to performance improvement when designing new personalized FL methods.
\end{itemize}

\begin{minipage}[c][][b]{0.5\textwidth}
\centering
\captionof{table}{gFL accuracy comparison}
\label{tab:gfl-acc}
\resizebox{0.6\linewidth}{!}{
\begin{tabular}{l|c|c}
            \toprule
Algorithm & Setting (gFL \#1) & Setting (gFL \#2)\\
            \midrule
FedAvg~\cite{mcmahan2017communication}  & $44.89\pm0.20$ & $56.47\pm0.57$\\
            \midrule
FedProx~\cite{li2020federated}  & $46.01\pm0.46$ & $56.85\pm0.36$\\
            \midrule
FedNova~\cite{wang2020tackling}  & $44.59\pm0.60$ & $53.20\pm0.33$\\
            \midrule
Scaffold~\cite{karimireddy2020scaffold}  & $56.85\pm1.06$ & $51.71\pm0.65$\\
            \midrule
FedDF~\cite{lin2020ensemble} & $27.43\pm 2.32$ & $30.24\pm0.26$ \\
            \midrule
MOON~\cite{li2021model} & $45.60\pm0.31$ & $50.23\pm0.55$ \\
            \bottomrule
\end{tabular}
}
\vspace{0.2cm}
\end{minipage}
\begin{minipage}[c][][b]{0.5\textwidth}
\centering
\captionof{table}{pFL generalization to newcomers}
\label{tab:pfl-newcommers}
\resizebox{0.6\linewidth}{!}{
\begin{tabular}{l|c|c}
            \toprule
Algorithm & Setting (pFL \#1) & Setting (pFL \#2)\\
            \midrule
FedAvg + FT~\cite{jiang2019improving} & $64.19\pm4.64$ & $37.14\pm0.43$ \\
            \midrule
LG-FedAvg~\cite{liang2020think}   & $40.39\pm17.98$ & $21.22\pm2.56$ \\
            \midrule  
PerFedAvg~\cite{fallah2020personalized}   & $74.97\pm1.10$ & $2.22\pm0.20$ \\
            \midrule  
IFCA~\cite{ghosh2020efficient}   & $62.64\pm1.03$ & $14.84\pm1.86$ \\
            \midrule
Ditto~\cite{li2021ditto}   & $62.55\pm3.10$ & $38.96\pm0.26$ \\
            \midrule
FedPer~\cite{arivazhagan2019federated}   & $65.3\pm2.41$ & $35.66\pm1.61$ \\
            \midrule
FedRep~\cite{collins2021exploiting}   & $64.50\pm0.62$ & $23.85\pm1.49$ \\
            \midrule
APFL~\cite{deng2020adaptive}   & $66.38\pm1.25$ & $39.52\pm1.11$ \\
            \midrule
SubFedAvg~\cite{vahidian2021personalized} & $63.54\pm1.42$ & $30.81\pm1.28$ \\
            \midrule
PACFL~\cite{vahidian2022efficient} & $68.54\pm1.33$ & $36.50\pm1.42$ \\
            \bottomrule
\end{tabular}
}
\end{minipage}

%\subsection{Computation Cost}
%\subsection{Communication Cost}

\begin{comment}
\begin{minipage}[c]{0.5\textwidth}
\centering
\begin{table}
\captionof{table}{gFL accuracy comparison}
\label{tab:gfl-acc}
\centering
\resizebox{0.5\linewidth}{!}{
\begin{tabular}{l|c|c}
            \toprule
Algorithm & Setting (gFL \#1) & Setting (gFL \#1)\\
            \midrule
FedAvg~\cite{mcmahan2017communication}  & $44.89\pm0.20$ & $56.47\pm0.57$\\
            \midrule
FedProx~\cite{li2020federated}  & $46.01\pm0.46$ & $56.85\pm0.36$\\
            \midrule
FedNova~\cite{wang2020tackling}  & $44.59\pm0.60$ & $53.20\pm0.33$\\
            \midrule
Scaffold~\cite{karimireddy2020scaffold}  & $56.85\pm1.06$ & $51.71\pm0.65$\\
            \midrule
FedDF~\cite{lin2020ensemble} & $27.43\pm 2.32$ & $30.24\pm0.26$ \\
            \midrule
MOON~\cite{li2021model} & $45.60\pm0.31$ & $50.23\pm0.55$ \\
            \bottomrule
\end{tabular}
}
\end{table}
\begin{table}
\captionof{table}{pFL generalization to newcomers comparison}
\label{tab:pfl-newcommers}
\centering
\resizebox{0.5\linewidth}{!}{
\begin{tabular}{l|c|c}
            \toprule
Algorithm & Setting (pFL \#1) & Setting (pFL \#2)\\
            \midrule
FedAvg + FT~\cite{jiang2019improving} & $64.19\pm4.64$ & $37.14\pm0.43$ \\
            \midrule         
LG-FedAvg~\cite{liang2020think}   & $40.39\pm17.98$ & $21.22\pm2.56$ \\
            \midrule  
PerFedAvg~\cite{fallah2020personalized}   & $74.97\pm1.10$ & $2.22\pm0.20$ \\
            \midrule  
IFCA~\cite{ghosh2020efficient}   & $62.64\pm1.03$ & $14.84\pm1.86$ \\
            \midrule
Ditto~\cite{li2021ditto}   & $62.55\pm3.10$ & $38.96\pm0.26$ \\
            \midrule
FedPer~\cite{arivazhagan2019federated}   & $65.3\pm2.41$ & $35.66\pm1.61$ \\
            \midrule
FedRep~\cite{collins2021exploiting}   & $XX\pm XX$ & $XX\pm XX$ \\
            \midrule
APFL~\cite{deng2020adaptive}   & $XX\pm XX$ & $XX\pm XX$ \\
            \midrule
SubFedAvg~\cite{vahidian2021personalized} & $XX\pm XX$ & $XX\pm XX$ \\
            \midrule
PACFL~\cite{vahidian2022efficient} & $XX\pm XX$ & $XX\pm XX$ \\
            \bottomrule
\end{tabular}
}
\end{table}
\end{minipage}

\end{comment}