\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@rmstyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{Amazonconvversational}
``What is conversational ai?''
  \url{https://developer.amazon.com/alexa-skills-kit/conversational-ai},
  accessed: 2023-09-14.

\bibitem{karppi2019non}
T.~Karppi and Y.~Granata, ``Non-artificial non-intelligence: Amazon’s alexa
  and the frictions of ai,'' \emph{Ai \& Society}, vol.~34, pp. 867--876, 2019.

\bibitem{ai2thor}
E.~Kolve, R.~Mottaghi, W.~Han, E.~VanderBilt, L.~Weihs, A.~Herrasti, D.~Gordon,
  Y.~Zhu, A.~Gupta, and A.~Farhadi, ``{AI2-THOR: An Interactive 3D Environment
  for Visual AI},'' \emph{arXiv}, 2017.

\bibitem{clip}
\BIBentryALTinterwordspacing
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, G.~Krueger, and I.~Sutskever, ``Learning
  transferable visual models from natural language supervision,'' 2021.
  [Online]. Available: \url{https://arxiv.org/abs/2103.00020}
\BIBentrySTDinterwordspacing

\bibitem{pateras1995understanding}
C.~Pateras, G.~Dudek, and R.~De~Mori, ``Understanding referring expressions in
  a person-machine spoken dialogue,'' in \emph{1995 International Conference on
  Acoustics, Speech, and Signal Processing}, vol.~1.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 1995, pp. 197--200.

\bibitem{sim2001learning}
R.~Sim and G.~Dudek, ``Learning environmental features for pose estimation,''
  \emph{Image and Vision Computing}, vol.~19, no.~11, pp. 733--739, 2001.

\bibitem{shridhar2018interactive}
M.~Shridhar and D.~Hsu, ``Interactive visual grounding of referring expressions
  for human-robot interaction,'' \emph{arXiv preprint arXiv:1806.03831}, 2018.

\bibitem{shridhar2020ingress}
M.~Shridhar, D.~Mittal, and D.~Hsu, ``Ingress: Interactive visual grounding of
  referring expressions,'' \emph{The International Journal of Robotics
  Research}, vol.~39, no. 2-3, pp. 217--232, 2020.

\bibitem{vlmaps}
C.~Huang, O.~Mees, A.~Zeng, and W.~Burgard, ``Visual language maps for robot
  navigation,'' \emph{arXiv preprint arXiv:2210.05714}, 2022.

\bibitem{conceptfusion}
\BIBentryALTinterwordspacing
K.~M. Jatavallabhula, A.~Kuwajerwala, Q.~Gu, M.~Omama, T.~Chen, S.~Li, G.~Iyer,
  S.~Saryazdi, N.~Keetha, A.~Tewari, J.~B. Tenenbaum, C.~M. de~Melo,
  M.~Krishna, L.~Paull, F.~Shkurti, and A.~Torralba, ``Conceptfusion: Open-set
  multimodal 3d mapping,'' 2023. [Online]. Available:
  \url{https://arxiv.org/abs/2302.07241}
\BIBentrySTDinterwordspacing

\bibitem{clipfields}
\BIBentryALTinterwordspacing
N.~M.~M. Shafiullah, C.~Paxton, L.~Pinto, S.~Chintala, and A.~Szlam,
  ``Clip-fields: Weakly supervised semantic fields for robotic memory,'' 2022.
  [Online]. Available: \url{https://arxiv.org/abs/2210.05663}
\BIBentrySTDinterwordspacing

\bibitem{lmnav}
D.~Shah, B.~Osinski, B.~Ichter, and S.~Levine, ``Lm-nav: Robotic navigation
  with large pre-trained models of language, vision, and action,'' \emph{arXiv
  preprint arXiv:2207.04429}, 2022.

\bibitem{gpt3}
T.~Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal,
  A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal, A.~Herbert-Voss,
  G.~Krueger, T.~Henighan, R.~Child, A.~Ramesh, D.~Ziegler, J.~Wu, C.~Winter,
  C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray, B.~Chess, J.~Clark,
  C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and D.~Amodei, ``Language
  models are few-shot learners,'' in \emph{Advances in Neural Information
  Processing Systems}, H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~Balcan, and
  H.~Lin, Eds., vol.~33.\hskip 1em plus 0.5em minus 0.4em\relax Curran
  Associates, Inc., 2020, pp. 1877--1901.

\bibitem{cows}
\BIBentryALTinterwordspacing
S.~Y. Gadre, M.~Wortsman, G.~Ilharco, L.~Schmidt, and S.~Song, ``Cows on
  pasture: Baselines and benchmarks for language-driven zero-shot object
  navigation,'' 2022. [Online]. Available:
  \url{https://arxiv.org/abs/2203.10421}
\BIBentrySTDinterwordspacing

\bibitem{chen2023open}
B.~Chen, F.~Xia, B.~Ichter, K.~Rao, K.~Gopalakrishnan, M.~S. Ryoo, A.~Stone,
  and D.~Kappler, ``Open-vocabulary queryable scene representations for real
  world planning,'' in \emph{2023 IEEE International Conference on Robotics and
  Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp.
  11\,509--11\,522.

\bibitem{brohan2023can}
A.~Brohan, Y.~Chebotar, C.~Finn, K.~Hausman, A.~Herzog, D.~Ho, J.~Ibarz,
  A.~Irpan, E.~Jang, R.~Julian, \emph{et~al.}, ``Do as i can, not as i say:
  Grounding language in robotic affordances,'' in \emph{Conference on Robot
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2023, pp. 287--318.

\bibitem{ansel}
\BIBentryALTinterwordspacing
D.~Rivkin, G.~Dudek, N.~Kakodkar, D.~Meger, O.~Limoyo, X.~Liu, and F.~Hogan,
  ``Ansel photobot: A robot event photographer with semantic intelligence,''
  2023. [Online]. Available: \url{https://arxiv.org/abs/2302.07931}
\BIBentrySTDinterwordspacing

\bibitem{captionvqa}
\BIBentryALTinterwordspacing
S.~Changpinyo, D.~Kukliansky, I.~Szpektor, X.~Chen, N.~Ding, and R.~Soricut,
  ``All you may need for vqa are image captions,'' 2022. [Online]. Available:
  \url{https://arxiv.org/abs/2205.01883}
\BIBentrySTDinterwordspacing

\bibitem{scan2cap}
D.~Z. Chen, A.~Gholami, M.~Nießner, and A.~X. Chang, ``Scan2cap: Context-aware
  dense captioning in rgb-d scans,'' 2020.

\bibitem{sqa3d}
\BIBentryALTinterwordspacing
X.~Ma, S.~Yong, Z.~Zheng, Q.~Li, Y.~Liang, S.-C. Zhu, and S.~Huang, ``Sqa3d:
  Situated question answering in 3d scenes,'' 2022. [Online]. Available:
  \url{https://arxiv.org/abs/2210.07474}
\BIBentrySTDinterwordspacing

\bibitem{keyvan2022approach}
K.~Keyvan and J.~X. Huang, ``How to approach ambiguous queries in
  conversational search: A survey of techniques, approaches, tools, and
  challenges,'' \emph{ACM Computing Surveys}, vol.~55, no.~6, pp. 1--40, 2022.

\bibitem{lopez2018alexa}
G.~L{\'o}pez, L.~Quesada, and L.~A. Guerrero, ``Alexa vs. siri vs. cortana vs.
  google assistant: a comparison of speech-based natural user interfaces,'' in
  \emph{Advances in Human Factors and Systems Interaction: Proceedings of the
  AHFE 2017 International Conference on Human Factors and Systems Interaction,
  July 17- 21, 2017, The Westin Bonaventure Hotel, Los Angeles, California, USA
  8}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2018, pp. 241--250.

\bibitem{lieberman2001exploring}
H.~Lieberman, C.~Fry, and L.~Weitzman, ``Exploring the web with reconnaissance
  agents,'' \emph{Communications of the ACM}, vol.~44, no.~8, pp. 69--75, 2001.

\bibitem{hu2016natural}
R.~Hu, H.~Xu, M.~Rohrbach, J.~Feng, K.~Saenko, and T.~Darrell, ``Natural
  language object retrieval,'' in \emph{Proceedings of the IEEE conference on
  computer vision and pattern recognition}, 2016, pp. 4555--4564.

\bibitem{allen1983recognizing}
J.~Allen, ``Recognizing intention from natural language utterances,''
  \emph{Computational Model of Discourse}, pp. 107--166, 1983.

\bibitem{lieberman1995letizia}
H.~Lieberman \emph{et~al.}, ``Letizia: An agent that assists web browsing,''
  \emph{IJCAI (1)}, vol. 1995, pp. 924--929, 1995.

\bibitem{instructgpt}
\BIBentryALTinterwordspacing
S.~Changpinyo, D.~Kukliansky, I.~Szpektor, X.~Chen, N.~Ding, and R.~Soricut,
  ``All you may need for vqa are image captions,'' 2022. [Online]. Available:
  \url{https://arxiv.org/abs/2205.01883}
\BIBentrySTDinterwordspacing

\bibitem{EVA}
Y.~Fang, W.~Wang, B.~Xie, Q.~Sun, L.~Wu, X.~Wang, T.~Huang, X.~Wang, and
  Y.~Cao, ``Eva: Exploring the limits of masked visual representation learning
  at scale,'' \emph{arXiv preprint arXiv:2211.07636}, 2022.

\bibitem{lvis}
A.~Gupta, P.~Dollar, and R.~Girshick, ``{LVIS}: A dataset for large vocabulary
  instance segmentation,'' in \emph{Proceedings of the {IEEE} Conference on
  Computer Vision and Pattern Recognition}, 2019.

\bibitem{lseg}
B.~Li, K.~Q. Weinberger, S.~Belongie, V.~Koltun, and R.~Ranftl,
  ``Language-driven semantic segmentation,'' \emph{arXiv preprint
  arXiv:2201.03546}, 2022.

\end{thebibliography}
