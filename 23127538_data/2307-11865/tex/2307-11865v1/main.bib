@article{ai2thor,
  author={Eric Kolve and Roozbeh Mottaghi and Winson Han and
          Eli VanderBilt and Luca Weihs and Alvaro Herrasti and
          Daniel Gordon and Yuke Zhu and Abhinav Gupta and
          Ali Farhadi},
  title={{AI2-THOR: An Interactive 3D Environment for Visual AI}},
  journal={arXiv},
  year={2017}
}

@article{lieberman1995letizia,
  title={Letizia: An agent that assists web browsing},
  author={Lieberman, Henry and others},
  journal={IJCAI (1)},
  volume={1995},
  pages={924--929},
  year={1995}
}

@article{vlmaps,
  title={Visual Language Maps for Robot Navigation},
  author={Huang, Chenguang and Mees, Oier and Zeng, Andy and Burgard, Wolfram},
  journal={arXiv preprint arXiv:2210.05714},
  year={2022}
}

@inproceedings{hu2016natural,
  title={Natural language object retrieval},
  author={Hu, Ronghang and Xu, Huazhe and Rohrbach, Marcus and Feng, Jiashi and Saenko, Kate and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4555--4564},
  year={2016}
}

@inproceedings{lopez2018alexa,
  title={Alexa vs. Siri vs. Cortana vs. Google Assistant: a comparison of speech-based natural user interfaces},
  author={L{\'o}pez, Gustavo and Quesada, Luis and Guerrero, Luis A},
  booktitle={Advances in Human Factors and Systems Interaction: Proceedings of the AHFE 2017 International Conference on Human Factors and Systems Interaction, July 17- 21, 2017, The Westin Bonaventure Hotel, Los Angeles, California, USA 8},
  pages={241--250},
  year={2018},
  organization={Springer}
}

@article{allen1983recognizing,
  title={Recognizing intention from natural language utterances},
  author={Allen, James},
  journal={Computational Model of Discourse},
  pages={107--166},
  year={1983},
  publisher={MIT press}
}

@article{keyvan2022approach,
  title={How to Approach Ambiguous Queries in Conversational Search: A Survey of Techniques, Approaches, Tools, and Challenges},
  author={Keyvan, Kimiya and Huang, Jimmy Xiangji},
  journal={ACM Computing Surveys},
  volume={55},
  number={6},
  pages={1--40},
  year={2022},
  publisher={ACM New York, NY}
}

@article{lieberman2001exploring,
  title={Exploring the web with reconnaissance agents},
  author={Lieberman, Henry and Fry, Christopher and Weitzman, Louis},
  journal={Communications of the ACM},
  volume={44},
  number={8},
  pages={69--75},
  year={2001},
  publisher={ACM New York, NY, USA}
}

@misc{cows,
  doi = {10.48550/ARXIV.2203.10421},
  
  url = {https://arxiv.org/abs/2203.10421},
  
  author = {Gadre, Samir Yitzhak and Wortsman, Mitchell and Ilharco, Gabriel and Schmidt, Ludwig and Song, Shuran},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {CoWs on Pasture: Baselines and Benchmarks for Language-Driven Zero-Shot Object Navigation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{lmnav,
  title={Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action},
  author={Shah, Dhruv and Osinski, Blazej and Ichter, Brian and Levine, Sergey},
  journal={arXiv preprint arXiv:2207.04429},
  year={2022}
}

@misc{sqa3d,
  doi = {10.48550/ARXIV.2210.07474},
  
  url = {https://arxiv.org/abs/2210.07474},
  
  author = {Ma, Xiaojian and Yong, Silong and Zheng, Zilong and Li, Qing and Liang, Yitao and Zhu, Song-Chun and Huang, Siyuan},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {SQA3D: Situated Question Answering in 3D Scenes},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{clip,
  doi = {10.48550/ARXIV.2103.00020},
  
  url = {https://arxiv.org/abs/2103.00020},
  
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Learning Transferable Visual Models From Natural Language Supervision},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{gpt3,
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
	pages = {1877--1901},
	publisher = {Curran Associates, Inc.},
	title = {Language Models are Few-Shot Learners},
	volume = {33},
	year = {2020}}
	
@misc{conceptfusion,
  doi = {10.48550/ARXIV.2302.07241},
  
  url = {https://arxiv.org/abs/2302.07241},
  
  author = {Jatavallabhula, Krishna Murthy and Kuwajerwala, Alihusein and Gu, Qiao and Omama, Mohd and Chen, Tao and Li, Shuang and Iyer, Ganesh and Saryazdi, Soroush and Keetha, Nikhil and Tewari, Ayush and Tenenbaum, Joshua B. and de Melo, Celso Miguel and Krishna, Madhava and Paull, Liam and Shkurti, Florian and Torralba, Antonio},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {ConceptFusion: Open-set Multimodal 3D Mapping},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@misc{clipfields,
  doi = {10.48550/ARXIV.2210.05663},
  
  url = {https://arxiv.org/abs/2210.05663},
  
  author = {Shafiullah, Nur Muhammad Mahi and Paxton, Chris and Pinto, Lerrel and Chintala, Soumith and Szlam, Arthur},
  
  keywords = {Robotics (cs.RO), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {CLIP-Fields: Weakly Supervised Semantic Fields for Robotic Memory},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{scan2cap,
    title={Scan2Cap: Context-aware Dense Captioning in RGB-D Scans}, 
    author={Dave Zhenyu Chen and Ali Gholami and Matthias Nießner and Angel X. Chang},
    year={2020},
    eprint={2012.02206},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{captionvqa,
  doi = {10.48550/ARXIV.2205.01883},
  
  url = {https://arxiv.org/abs/2205.01883},
  
  author = {Changpinyo, Soravit and Kukliansky, Doron and Szpektor, Idan and Chen, Xi and Ding, Nan and Soricut, Radu},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {All You May Need for VQA are Image Captions},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{instructgpt,
  doi = {10.48550/ARXIV.2205.01883},
  
  url = {https://arxiv.org/abs/2205.01883},
  
  author = {Changpinyo, Soravit and Kukliansky, Doron and Szpektor, Idan and Chen, Xi and Ding, Nan and Soricut, Radu},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {All You May Need for VQA are Image Captions},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{EVA,
  title={EVA: Exploring the Limits of Masked Visual Representation Learning at Scale},
  author={Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2211.07636},
  year={2022}
}

@inproceedings{lvis,
  title={{LVIS}: A Dataset for Large Vocabulary Instance Segmentation},
  author={Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
  booktitle={Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
  year={2019}
}
@article{lseg,
  title={Language-driven semantic segmentation},
  author={Li, Boyi and Weinberger, Kilian Q and Belongie, Serge and Koltun, Vladlen and Ranftl, Ren{\'e}},
  journal={arXiv preprint arXiv:2201.03546},
  year={2022}
}

@misc{ansel,
  doi = {10.48550/ARXIV.2302.07931},
  
  url = {https://arxiv.org/abs/2302.07931},
  
  author = {Rivkin, Dmitriy and Dudek, Gregory and Kakodkar, Nikhil and Meger, David and Limoyo, Oliver and Liu, Xue and Hogan, Francois},
  
  keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {ANSEL Photobot: A Robot Event Photographer with Semantic Intelligence},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{droidslam,
  title={{DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras}},
  author={Teed, Zachary and Deng, Jia},
  journal={Advances in neural information processing systems},
  year={2021}
}

@misc{ohmni_robot,
url=https://ohmnilabs.com/products/ohmni-telepresence-robot}

@misc{realsense,
url=https://www.intelrealsense.com/depth-camera-d455/}


% tasks 
@misc{alfred,
  doi = {10.48550/ARXIV.1912.01734},
  
  url = {https://arxiv.org/abs/1912.01734},
  
  author = {Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{teach,
  doi = {10.48550/ARXIV.2110.00534},
  
  url = {https://arxiv.org/abs/2110.00534},
  
  author = {Padmakumar, Aishwarya and Thomason, Jesse and Shrivastava, Ayush and Lange, Patrick and Narayan-Chen, Anjali and Gella, Spandana and Piramuthu, Robinson and Tur, Gokhan and Hakkani-Tur, Dilek},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {TEACh: Task-driven Embodied Agents that Chat},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@misc{alfworld,
  doi = {10.48550/ARXIV.2010.03768},
  
  url = {https://arxiv.org/abs/2010.03768},
  
  author = {Shridhar, Mohit and Yuan, Xingdi and Côté, Marc-Alexandre and Bisk, Yonatan and Trischler, Adam and Hausknecht, Matthew},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {ALFWorld: Aligning Text and Embodied Environments for Interactive Learning},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Matterport3D,
  title={Matterport3D: Learning from RGB-D Data in Indoor Environments},
  author={Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niessner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  journal={International Conference on 3D Vision (3DV)},
  year={2017}
}

@misc{habitatchallenge2023,
  title         =     {Habitat Challenge 2023},
  author        =     {Karmesh Yadav and Jacob Krantz and Ram Ramrakhya and Santhosh Kumar Ramakrishnan and Jimmy Yang and Austin Wang and John Turner and Aaron Gokaslan and Oleksandr Maksymets and Angel X Chang and Manolis Savva and Devendra Singh Chaplot and Alexander Clegg and Dhruv Batra},
  howpublished  =     {\url{https://aihabitat.org/challenge/2023/}},
  year          =     {2023}
}

@inproceedings{bnf,
  title={c The syntax and semantics of the proposed international algebraic language of the Zurich ACM-GAMM Conference},
  author={JW,  Backus},
  booktitle={Proceedings of the International Conference of Information Processing UNESCO Paris June},
  year={1959}
}