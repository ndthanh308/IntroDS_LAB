\section{Conclusions and Future Works}
\label{sec:conclusion}

To the best of our knowledge, in this paper, we present the first two novel robust linear bandits algorithm for fixed-budget best-arm identification, \textsf{P1-RAGE} and \textsf{P1-Peace}, that tackle stationary and non-stationary environments simultaneously while being agnostic to the environment. Theoretically, we prove error probability bounds of \textsf{P1-RAGE} in both stationary and non-stationary environments. Empirically, we show that in stationary settings, both \textsf{P1-RAGE} and \textsf{P1-Peace} perform comparably with algorithms designed for such environments, and in non-stationary settings, they consistently outperform naive algorithms based on G-optimal design. 

Finally, several questions still remain open. For example, can we prove a similar guarantee for \textsf{P1-Peace}? Is the extra term in $H_{\textsf{P1-RAGE}}(\theta)$, as discussed in Section \ref{sec:bobw}, necessary and what is the optimal complexity? Answering these questions can serve as promising future directions.