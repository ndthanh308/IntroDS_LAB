\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2018)Abbasi-Yadkori, Bartlett, Gabillon, Malek,
  and Valko]{abbasi2018best}
Yasin Abbasi-Yadkori, Peter Bartlett, Victor Gabillon, Alan Malek, and Michal
  Valko.
\newblock Best of both worlds: Stochastic \& adversarial best-arm
  identification.
\newblock In \emph{Conference on Learning Theory}, pages 918--949. PMLR, 2018.

\bibitem[Audibert et~al.(2010)Audibert, Bubeck, and Munos]{audibert2010best}
Jean-Yves Audibert, S{\'e}bastien Bubeck, and R{\'e}mi Munos.
\newblock Best arm identification in multi-armed bandits.
\newblock In \emph{COLT}, pages 41--53, 2010.

\bibitem[Auer and Chiang(2016)]{auer2016algorithm}
Peter Auer and Chao-Kai Chiang.
\newblock An algorithm with nearly optimal pseudo-regret for both stochastic
  and adversarial bandits.
\newblock In \emph{Conference on Learning Theory}, pages 116--120. PMLR, 2016.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002nonstochastic}
Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert~E Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM journal on computing}, 32\penalty0 (1):\penalty0 48--77,
  2002.

\bibitem[Auer et~al.(2019)Auer, Gajane, and Ortner]{auer2019adaptively}
Peter Auer, Pratik Gajane, and Ronald Ortner.
\newblock Adaptively tracking the best bandit arm with an unknown number of
  distribution changes.
\newblock In \emph{Conference on Learning Theory}, pages 138--158. PMLR, 2019.

\bibitem[Azizi et~al.(2021)Azizi, Kveton, and Ghavamzadeh]{azizi2021fixed}
Mohammad~Javad Azizi, Branislav Kveton, and Mohammad Ghavamzadeh.
\newblock Fixed-budget best-arm identification in structured bandits.
\newblock \emph{arXiv preprint arXiv:2106.04763}, 2021.

\bibitem[Bubeck and Slivkins(2012)]{bubeck2012best}
S{\'e}bastien Bubeck and Aleksandrs Slivkins.
\newblock The best of both worlds: Stochastic and adversarial bandits.
\newblock In \emph{Conference on Learning Theory}, pages 42--1. JMLR Workshop
  and Conference Proceedings, 2012.

\bibitem[Chen et~al.(2019)Chen, Lee, Luo, and Wei]{chen2019new}
Yifang Chen, Chung-Wei Lee, Haipeng Luo, and Chen-Yu Wei.
\newblock A new algorithm for non-stationary contextual bandits: Efficient,
  optimal and parameter-free.
\newblock In \emph{Conference on Learning Theory}, pages 696--726. PMLR, 2019.

\bibitem[Degenne et~al.(2020)Degenne, M{\'e}nard, Shang, and
  Valko]{degenne2020gamification}
R{\'e}my Degenne, Pierre M{\'e}nard, Xuedong Shang, and Michal Valko.
\newblock Gamification of pure exploration for linear bandits.
\newblock In \emph{International Conference on Machine Learning}, pages
  2432--2442. PMLR, 2020.

\bibitem[Fiez et~al.(2019)Fiez, Jain, Jamieson, and
  Ratliff]{fiez2019sequential}
Tanner Fiez, Lalit Jain, Kevin~G Jamieson, and Lillian Ratliff.
\newblock Sequential experimental design for transductive linear bandits.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Freedman(1975)]{freedman1975tail}
David~A Freedman.
\newblock On tail probabilities for martingales.
\newblock \emph{the Annals of Probability}, pages 100--118, 1975.

\bibitem[Garivier and Moulines(2011)]{garivier2011upper}
Aur{\'e}lien Garivier and Eric Moulines.
\newblock On upper-confidence bound policies for switching bandit problems.
\newblock In \emph{Algorithmic Learning Theory: 22nd International Conference,
  ALT 2011, Espoo, Finland, October 5-7, 2011. Proceedings 22}, pages 174--188.
  Springer, 2011.

\bibitem[Hill et~al.(2017)Hill, Nassif, Liu, Iyer, and
  Vishwanathan]{hill2017efficient}
Daniel~N Hill, Houssam Nassif, Yi~Liu, Anand Iyer, and SVN Vishwanathan.
\newblock An efficient bandit algorithm for realtime multivariate optimization.
\newblock In \emph{Proceedings of the 23rd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 1813--1821, 2017.

\bibitem[Jedra and Proutiere(2020)]{jedra2020optimal}
Yassir Jedra and Alexandre Proutiere.
\newblock Optimal best-arm identification in linear bandits.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 10007--10017, 2020.

\bibitem[Karnin et~al.(2013)Karnin, Koren, and Somekh]{karnin2013almost}
Zohar Karnin, Tomer Koren, and Oren Somekh.
\newblock Almost optimal exploration in multi-armed bandits.
\newblock In \emph{Proceedings of the 30th International Conference on
  International Conference on Machine Learning - Volume 28}, ICML'13, page
  III–1238–III–1246. JMLR.org, 2013.

\bibitem[Karnin(2016)]{karnin2016verification}
Zohar~S Karnin.
\newblock Verification based solution for structured mab problems.
\newblock \emph{Advances in Neural Information Processing Systems}, 29, 2016.

\bibitem[Katz-Samuels et~al.(2020)Katz-Samuels, Jain, Karnin, and
  Jamieson]{katz2020empirical}
Julian Katz-Samuels, Lalit Jain, Zohar Karnin, and Kevin Jamieson.
\newblock An empirical process approach to the union bound: Practical
  algorithms for combinatorial and linear bandits.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 10371--10382, 2020.

\bibitem[Kohavi and Longbotham(2011)]{kohavi2011unexpected}
Ron Kohavi and Roger Longbotham.
\newblock Unexpected results in online controlled experiments.
\newblock \emph{ACM SIGKDD Explorations Newsletter}, 12\penalty0 (2):\penalty0
  31--35, 2011.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Lee et~al.(2021)Lee, Luo, Wei, Zhang, and Zhang]{lee2021achieving}
Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang, and Xiaojin Zhang.
\newblock Achieving near instance-optimality and minimax-optimality in
  stochastic and adversarial linear bandits simultaneously.
\newblock In \emph{International Conference on Machine Learning}, pages
  6142--6151. PMLR, 2021.

\bibitem[Optimizely(2023)]{stats-accelerator}
Optimizely.
\newblock Stats accelerator – acceleration under time-varying signals.
\newblock
  \url{https://support.optimizely.com/hc/en-us/articles/5326213705101-Stats-Accelerator-}
  \url{Acceleration-Under-Time-Varying-Signals}, May 2023.

\bibitem[Qin and Russo(2022)]{qin2022adaptivity}
Chao Qin and Daniel Russo.
\newblock Adaptivity and confounding in multi-armed bandit experiments.
\newblock \emph{arXiv preprint arXiv:2202.09036}, 2022.

\bibitem[Seldin and Lugosi(2017)]{seldin2017improved}
Yevgeny Seldin and G{\'a}bor Lugosi.
\newblock An improved parametrization and analysis of the exp3++ algorithm for
  stochastic and adversarial bandits.
\newblock In \emph{Conference on Learning Theory}, pages 1743--1759. PMLR,
  2017.

\bibitem[Seldin and Slivkins(2014)]{seldin2014one}
Yevgeny Seldin and Aleksandrs Slivkins.
\newblock One practical algorithm for both stochastic and adversarial bandits.
\newblock In \emph{International Conference on Machine Learning}, pages
  1287--1295. PMLR, 2014.

\bibitem[Soare et~al.(2014)Soare, Lazaric, and Munos]{soare2014best}
Marta Soare, Alessandro Lazaric, and R{\'e}mi Munos.
\newblock Best-arm identification in linear bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 27, 2014.

\bibitem[Suk and Kpotufe(2022)]{suk2022tracking}
Joe Suk and Samory Kpotufe.
\newblock Tracking most significant arm switches in bandits, 2022.

\bibitem[Wagenmaker and Foster(2023)]{wagenmaker2023instance}
Andrew Wagenmaker and Dylan~J Foster.
\newblock Instance-optimality in interactive decision making: Toward a
  non-asymptotic theory.
\newblock \emph{arXiv preprint arXiv:2304.12466}, 2023.

\bibitem[Wei and Luo(2021)]{wei2021non}
Chen-Yu Wei and Haipeng Luo.
\newblock Non-stationary reinforcement learning without prior knowledge: An
  optimal black-box approach.
\newblock In \emph{Conference on Learning Theory}, pages 4300--4354. PMLR,
  2021.

\bibitem[Wei et~al.(2020)Wei, Luo, and Agarwal]{wei2020taking}
Chen-Yu Wei, Haipeng Luo, and Alekh Agarwal.
\newblock Taking a hint: How to leverage loss predictors in contextual bandits?
\newblock In \emph{Conference on Learning Theory}, pages 3583--3634. PMLR,
  2020.

\bibitem[Wu et~al.(2022)Wu, Zheng, Zhang, Zhang, and Wang]{wu2022non}
Yuhang Wu, Zeyu Zheng, Guangyu Zhang, Zuohua Zhang, and Chu Wang.
\newblock Non-stationary a/b tests.
\newblock 2022.

\bibitem[Xu et~al.(2018)Xu, Honda, and Sugiyama]{xu2018fully}
Liyuan Xu, Junya Honda, and Masashi Sugiyama.
\newblock A fully adaptive algorithm for pure exploration in linear bandits.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 843--851. PMLR, 2018.

\bibitem[Yahoo!(2011)]{r6adataset}
Yahoo!
\newblock Yahoo! webscope dataset ydata-frontpage-todaymodule-clicks-v1\_0,
  2011.
\newblock URL \url{https://webscope.sandbox.yahoo.com/catalog.php?datatype=r}.

\bibitem[Yang and Tan(2022)]{yang2022minimax}
Junwen Yang and Vincent Tan.
\newblock Minimax optimal fixed-budget best arm identification in linear
  bandits.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 12253--12266, 2022.

\bibitem[Yang and Tan(2021)]{yang2021towards}
Junwen Yang and Vincent~YF Tan.
\newblock Towards minimax optimal best arm identification in linear bandits.
\newblock \emph{arXiv e-prints}, pages arXiv--2105, 2021.

\end{thebibliography}
