\section{IMPLEMENTATION DETAILS AND ADDITIONAL EXPERIMENTS}
\label{sec:experiment_details}

In this section, we provide more implementation details and additional experiment results. Experiments are executed through Python 3.10 and paralleled by a Mac M1 Pro chip with 6 cores.

First, we notice that an algorithm for stationary environments usually determines a batch of arms to pull at once during each epoch, while in non-stationary environment, the order of pulling these arms will affect the rewards it will receive. Therefore, when applying stationary algorithms (\textsf{Peace} and \textsf{OD-LinBAI}) into a non-stationary environment, we use a random permutation to determine the order of pulling for each batch of arms. 

When implementing \textsf{P1-RAGE}, to be computationally efficient, we update $\lambda_t$ in the same frequency as \textsf{P1-Peace}, which is summarized in Algorithm \ref{algo:p1_peace}. We take $m=15$ for \textsf{P1-RAGE}, which, based on Theorem \ref{theo:bobw_upper_bound}, is valid as long as $\Delta_{(1)}\geq 2^{-13}\approx 1.22\times 10^{-4}$. Furthermore, when implementing \textsf{Peace}, for simplicity, we use $\inf_{\lambda\in\triangle_{\X}}\rho(\mc{Z}, \lambda)$, defined in equation \eqref{equ:rho_z}, to replace all $\gamma(\mc{Z})$ used in \citet{katz2020empirical}. Since the paper of \textsf{OD-LinBAI} does not provide code, we implement it based on the pseudocode in \citet{yang2022minimax}. Finally, we use Frank-Wolfe algorithm with stepsize $\frac{1}{2(i+2)}$ in $i$-th iteration to solve all optimization problems in a form of $\inf_{\lambda\in\triangle_{\X}}\max_{y\in\mc{Y}}\Norm{y}^2_{A(\lambda)^{-1}}$.

As for code snippets reference, we use part of the code from \citet{katz2020empirical} to implement the rounding procedure used in \textsf{Peace}\footnote{No license information.} and part of the code from \citet{fiez2019sequential} to generate the base stationary instance for the multivariate testing example.\footnote{Under MIT License.} We also use code from \citet{xu2018fully} to preprocess the Yahoo! Webscope dataset.\footnote{No license information.}

\subsection{Additional Experiments}
\label{sec:additional_experiments}

Here, we provide experiment results on some additional examples to corroborate our theoretical findings.

\paragraph{Malicious non-stationary example} Because of the nature of arm elimination, algorithms designed for stationary environment can fail easily in some malicious non-stationary environments. Here, we pick the same $\X$ as \citet{soare2014best}'s stationary benchmark example and set $\omega=0.5$. Then, we take
$$\theta_t=\begin{cases}
    \matenv{0 & 1 & 1 & \dots & 1}^\top & \text{for }t=1, \dots, \frac{T}{3},\\
    \matenv{2 & 0 & 0 & \dots & 0}^\top & \text{for }t=\frac{T}{3}+1, \dots, T.
\end{cases}$$
We can see that the overall best arm is still $x_{(1)}=\ve{e}_1$. However, because of the $\theta_t$ in the first $1/3$ rounds, algorithms like \textsf{Peace} and \textsf{OD-LinBAI} will eliminate $\ve{e}_1$ in its initial phase; on the other hand, our algorithms will be robust to this non-stationarity. Here, we take $T=10^4$ and the results are shown in right plot of Figure \ref{fig:error_malicious}.

% Figure environment removed

% \begin{wrapfigure}{r}{0.5\textwidth}
%     \begin{center}
%         % Figure removed
%     \end{center}
%     \caption{The error probabilities are estimated through 1000 repeated trials and the error bars represent $95\%$ confidence intervals.}
%     \label{fig:error_malicious}
% \end{wrapfigure}

% % Figure environment removed



\paragraph{Stationary multivariate testing example} We also test the performance of these algorithms in multivariate testing example when there is no non-stationarity, i.e. $\theta_t=\theta^*$ for all $t$. Here, we also take $T=10^4$ and the results are shown in Figure \ref{fig:error_multi}. We can see that our robust algorithm \textsf{P1-RAGE} again performs better than \textsf{G-BAI} and comparably with \textsf{Peace}.

% Figure environment removed

\paragraph{Non-stationary benchmark example} In this example, we add non-stationarity to \citet{soare2014best}'s stationary benchmark example in a more structured instead of malicious way. In particular, we keep the arm set $\X$ the same, take $\omega=0.5$ and set
$$\theta_t=\matenv{0.3 & 0 & 0 & \dots & -s\sin\Sp{\frac{2\pi t}{L}} + 0.5}^\top, $$
where $s$ is the oscillation scale and $L$ is the oscillation period, In the first series of instances, we fix $L=200$ and take values $m\in\Bp{0, 1, \dots, 9}$; in the second series of instances, we fix $m=1$ and take values $L\in\Bp{300, 600, \dots, 3000}$. All non-stationary instances have the same optimal arm as their stationary counterparts and we take $T=10^4$ for all of these instances. The results are shown in Figure \ref{fig:adv_soare}, from which we can see similar phenomenon as in Figure \ref{fig:adv_multi}. In particular, algorithms designed for stationary environments, \textsf{Peace} and \textsf{OD-LinBAI}, are very unstable in face of non-stationarity. Meanwhile, among the other four relatively robust algorithms, our algorithms \textsf{P1-RAGE} and \textsf{P1-Peace} consistently outperform the other two.

% Figure environment removed
