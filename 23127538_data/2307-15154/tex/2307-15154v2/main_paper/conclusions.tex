\section{CONCLUSIONS AND FUTURE WORK}
\label{sec:conclusion}

To the best of our knowledge, in this paper, we present the first two novel robust linear bandits algorithm for fixed-budget best-arm identification, \textsf{P1-RAGE} and \textsf{P1-Peace}, that tackle stationary and non-stationary environments simultaneously while being agnostic to the environment. Theoretically, we prove error probability bounds of \textsf{P1-RAGE} in both stationary and non-stationary environments. Empirically, we show that in stationary settings, both \textsf{P1-RAGE} and \textsf{P1-Peace} perform comparably with algorithms designed for such environments, and in non-stationary settings, they consistently outperform naive algorithms based on G-optimal design.

Finally, several questions still remain open. Is the extra term in $H_{\textsf{P1-RAGE}}(\theta)$, as discussed in Section \ref{sec:bobw}, necessary? What is the optimal complexity for this mixed stationary/non-stationary settings? Answering these questions can serve as promising future directions.
% Note that to find the optimal complexity for this BOBW linear setting, one needs to find the optimal complexity for the stochastic setting, which is an open problem. 
