\section{BAI FOR LINEAR BANDITS IN GENERAL NON-STATIONARY ENVIRONMENTS}
\label{sec:nonstationary}

In this section, we present a simple algorithm \textsf{G-BAI} for the general non-stationary environment and analyze its theoretical guarantee. The algorithm is based on the G-optimal design, which refers to the distribution $\lambda^*\in\triangle_{\X}$ such that
\begin{equation}
    \label{equ:g_design}
    \lambda^*=\arginf_{\lambda\in\triangle_{\X}}\max_{x\in\X}\Norm{x}^2_{A(\lambda)^{-1}}.
\end{equation}
Intuitively, G-optimal design allows us to estimate unknown parameter $\theta_t$ uniformly well over all directions of the arms in $\X$ \citep{soare2014best}. which is suitable for addressing non-stationarity since $\theta_t$ may change arbitrarily and each $x\in\X$ may become the optimal at time $t$. Meanwhile, to make sure the estimation of $\theta_t$ is unbiased in a non-stationary environment, we use an IPS estimator. 

Therefore, briefly speaking, at each time $t$, \textsf{G-BAI} simply samples $x_t$ based on G-optimal design and estimate $\theta_t$ through an IPS estimator, whose details are summarized in Algorithm \ref{algo:gbai}.\footnote{We can see $\widehat{\theta}_T$ exactly becomes the more commonly-seen IPS estimator examined in Eq. \eqref{equ:usual_ips} if we apply it to the multi-armed bandits setting, in which we have $K=d$ arms and $\mc{X}=\Bp{\ve{1}_1, \dots, \ve{e}_d}$.}
% \begin{algorithm}[ht]
%     \caption{G-optimal Best-arm Identification (G-BAI)}
%     \label{algo:gbai}
%     \SetAlgoLined
%     \KwIn{budget, $T\in\mathbb{N}$; arm set $\mc{X}\subset\R^d$}
%     Compute G-optimal design $\lambda^*$ based on Eq. \eqref{equ:g_design}\\
%     \For{$t=1, 2, \dots, T$}{
%         Sample $x_t\sim\lambda^*$ and receive reward $r_t$\\
%     }
%     Estimate $\widehat{\theta}_T\leftarrow \frac{1}{T}\sum_{t=1}^T\E_{x\sim\lambda^*}\Mp{xx^\top}^{-1}x_t r_t$\\
%     \textbf{return} $\argmax_{x\in\X}x^\top\widehat{\theta}_T$
% \end{algorithm}

\begin{algorithm}[ht]
    \caption{G-optimal Best-arm Identification (G-BAI)}
    \label{algo:gbai}
    \begin{algorithmic}[1]
        \REQUIRE budget, $T\in\mathbb{N}$; arm set $\mc{X}\subset\R^d$
        \STATE Compute G-optimal design $\lambda^*$ based on Eq. \eqref{equ:g_design}
        \FOR{$t=1, 2, \dots, T$}
            \STATE Sample $x_t\sim\lambda^*$ and receive reward $r_t$
        \ENDFOR
        \STATE Estimate $\widehat{\theta}_T\leftarrow \frac{1}{T}\sum_{t=1}^T\E_{x\sim\lambda^*}\Mp{xx^\top}^{-1}x_t r_t$
        \RETURN $\argmax_{x\in\X}x^\top\widehat{\theta}_T$
    \end{algorithmic}
\end{algorithm}


By the famous Kiefer-Wolfowitz theorem, an important property of the G-optimal design is that $\max_{x\in\X}\Norm{x}^2_{A(\lambda^*)^{-1}}=d$ \citep{lattimore2020bandit}. With this property, the variance of estimator $\htheta_t$ can be easily controlled. We can then bound the error probability of \textsf{G-BAI} by this fact and the result is summarized in the following theorem.
% \begin{theorem}
%     \label{theo:adv_upper_bound}
%     Fix time horizon $T$, arm set $\X\subset\R^d$ with $\abs{\X}=K$ and arbitrary unknown parameters $\Bp{\theta_t}_{t=1}^T$. If we run Algorithm \ref{algo:gbai} and obtain $x_{J_T}$, then it holds that
%     $$\P\Sp{J_T\neq (1)}\leq K\exp\Sp{-\frac{3T\Delta_{(1)}^2}{32d}}.$$
% \end{theorem}

\begin{restatable}[Error probability of \textsf{G-BAI}]{theorem}{advupperbound}
    \label{theo:adv_upper_bound}
    Fix time horizon $T$, arm set $\X\subset\R^d$ with $\abs{\X}=K$ and arbitrary unknown parameters $\Bp{\theta_t}_{t=1}^T$. If we run Algorithm \ref{algo:gbai} in this non-stationary environment and obtain $x_{J_T}$, then it holds that
    \IfTwoColumnElse{
        \begin{align*}
            &\P_{\otheta_T}\Sp{J_T\neq (1)}\leq K\exp\Sp{-\frac{T}{12H_{\textsf{G-BAI}}\Sp{\otheta_T}}},\\
            &\text{where }H_{\textsf{G-BAI}}\left(\otheta_T\right)=\frac{d}{\Delta_{(1)}^2}.
        \end{align*}
    }{
        $$\P_{\otheta_T}\Sp{J_T\neq (1)}\leq K\exp\Sp{-\frac{T}{12H_{\textsf{G-BAI}}\Sp{\otheta_T}}},\quad\text{where }H_{\textsf{G-BAI}}\left(\otheta_T\right)=\frac{d}{\Delta_{(1)}^2}.$$
    }
\end{restatable}

The proof of Theorem \ref{theo:adv_upper_bound} is deferred to Appendix \ref{sec:g_design_proof}. Here, we briefly compare this result with the one in multi-armed bandits, which can be treated as a special case of linear bandits by taking $\X=\Bp{\ve{e}_1, \dots, \ve{e}_K}$ to be the canonical vectors (standard basis) with $K=d$. 

In particular, \citet{abbasi2018best} shows that in multi-armed bandits setting, a simple uniform sampling algorithm reaches complexity $H_{\mathrm{UNIF}}\Sp{\otheta_T}=\frac{K}{\Delta_{(1)}^2}$ and it is optimal in non-stationary environments. Meanwhile, based on Theorem \ref{theo:adv_upper_bound}, we can see the complexity of \textsf{G-BAI} is $H_{\textsf{G-BAI}}\Sp{\otheta_T}=\frac{d}{\Delta_{(1)}^2}$, which is exactly $H_{\mathsf{UNIF}}(\otheta_T)$ if we treat multi-armed bandits as a special case of linear bandits since $d=K$. Furthermore, if we directly apply \textsf{G-BAI} to multi-armed bandits, meaning to use $\X=\Bp{\ve{e}_1, \dots, \ve{e}_K}$, then $\lambda^*$ is exactly the uniform distribution over $\X$. That is, in multi-armed bandits, \textsf{G-BAI} exactly recovers the optimal complexity in non-stationary environments, which shows that \textsf{G-BAI} is minimax optimal for linear bandits.

% \begin{remark}[Comparison to \textsf{GSE} \citep{azizi2021fixed}]
%     \textsf{G-BAI} attains error probability in a same order of \textsf{GSE}, which also utilizes G-optimal design for arm allocation. However, since \textsf{GSE} is designed only for stationary environment, \textsf{G-BAI} can be viewed as a strict generalization of \textsf{GSE}.
% \end{remark}

