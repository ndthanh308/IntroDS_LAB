In this section, we show under several reasonable assumptions, the sequence of operator images $u(\vx,t)=\mathcal T_t f(\vx)$ is the solution of the convection-diffusion equation. Then we show that our convection-diffusion equation model can naturally cover various existing effective models.
% Under our convection-diffusion equation model, we focus on isotropic-type equation and theoretically illustrate its benefits for improving the robustness of models and reducing the Rademacher complexity. 
% Based on the regularity theory of PDEs, we design a training method for DNN models and theoretically illustrate its benefits for improving the robustness of models and reducing the generalization gap. we look at ResNets as a flow from a base classifier to final output.

\subsection{\texorpdfstring{The characterization of $\mathcal T_t$}{The characterization of Tt}}

% Throughout this section, we assume the base classifier by $f(\vx)$ is bounded and uniformly continuous. Our method formulates the ResNets as a flow from a linear regression classifier to the final ResNet model and use operator $\mathcal T_t$ to indicate this evolutive relationship, namely $u(\vx,t)=\mathcal T_t(f).$

Throughout this section, we assume $\mathcal T_t$ is well defined on $C^{\infty}_b$, and $\mathcal T_t f$ is a bounded continuous function. The assumption is reasonable, since typical classifiers $f$ like a linear classifier is indeed bounded (between 0 and 1) and has bounded derivatives. The operator image $\mathcal T_t f$, which we hope to be a neural network, is obviously bounded
and continuous. To get the expression of the evolution operator $\mathcal T_t$, we assume it has some fundamental properties, which fall into two categories: deep neural network type and partial differential equation type.

\subsubsection{DNN-type assumptions}
% For a DNN, the model first extracts the features $k(\vx_0)$ of the original data $\vx_0$ through the residual layer, then put the features $k(\vx_0)$ into base classifier $f$ for classification and obtain the prediction $f(k(\vx_0))$. Thus according to the property of DNN, if the confidence level for any event of one base classifier $g$ is higher than another base classifier $f$, we hope this ordering is preserved for their evolution classifier. Therefore, we require the operator $\mathcal T_t$ is provided with an order-preserving property which means that no enhancement is made. Above all, which implies

Suppose we are given two classifiers $f$ and $g$ such that $f(\vx) \geq g(\vx)$ for all data point $\vx \in \mathbb{R}^{d}$. Then $f\circ k(\vx) \geq$ $g\circ k(\vx)$ if we replace the data points with extracted features. Recall that for ResNet, $f\circ k = \mathcal T_T(f)$, which implies $\mathcal{T}_{T}\left(f\right) \geq \mathcal{T}_{T}\left(g\right)$. Since the order-preserving property holds both at initial time step $t=0$ and final time step $t=T$, it is reasonable to make the following assumption

% Consider a binary classification problem and the two categories are A and B. Assume $f$ is more confident to classify $\vx$ into class A while $g$ is more confident to classify $\vx$ into class B. At this setting, we certainly hope the evolution classifier $\mathcal T_Tf$ classify $\vx$ into class A and $\mathcal T_Tg$ classify $\vx$ into class B. Above all, which implies

\textbf{[Comparison Principle]} For all $t\geq 0$ and $f,g \in C^{\infty}_b$, if $f\leq g$, then $\mathcal T_t(f)\leq \mathcal T_t(g)$.

The prediction of a deep neural network is computed using forward propagation, i.e. the network uses output of former layer as input of current layer. Thus, for a DNN model, it's natural that the output of a DNN can be deduced from the output of intermediate $l$-th layer without any information depending upon the original data point $\vx$ and output of $m$-th layer ($m<l$). Regarding the evolution of operator $\mathcal T_t$ as stacking layers in the neural network, we should require that $\mathcal T_{t+s}$ can be computed from $\mathcal T_t$ for any $s\geq 0$, and $T_0$ is of course the identity, which implies

\textbf{[Markov Property]} $\mathcal T_{t+s} = \mathcal \mathcal T_t \circ T_{t+s,t}$, for all $s,t\geq 0$ and $t+s\leq T$. $\mathcal T_{t+s,t}$ denotes the flow from time $t$ to time $t+s$.

% Rather, we state that if we concatenate two different networks by taking weighted sum in network parameters, the output of the resulting network should equal the weighted sum of the outputs of two original networks. Actually, such linear combination is widely used in practice known as ensemble methods~\cite{zhou2012ensemble}. It is a popular method in machine learning which combines many weak classifiers and add them to obtain a strong classifier. \delete{When they are added, they are weighted in some way. Hence if we apply evolution operator to a strong classifier, we naturally require the prediction of the evolution classifier of the strong classifier equal to the combination prediction of evolution classifiers corresponding to these weak classifiers, which implies}. The above statement implies

Linearity is also an intrinsic property of deep neural networks. Notice that we are not referring to a single DNN's output v.s. input linearity, which is obviously wrong because of the activation function. Rather, we are stating that two different DNN with the same feature extractor can be merged in to a new DNN with a new classifier composed with the shared extractor, i.e.
\[(\beta_1f+\beta_2g) \circ k=\beta_1 f \circ k + \beta_2 g \circ k \]
This is linearity at $t=T$, and for $t=0$ it is trivial. Thus we assume,

\textbf{[Linearity]} For any $f,g \in C^{\infty}_b$, and real constants $\beta_1,\beta_2$, we have 
\[\mathcal T_{t}(\beta_1 f+\beta_2 g) = \beta_1\mathcal T_{t}(f)+\beta_2\mathcal T_{t}(g)\]
if $C$ is a constant function, then $\mathcal T_t(C) = C$.

\subsubsection{PDE-type assumptions}
First of all, we need an assumption to ensure the existence of a differential equation. If two classifiers $f$ and $g$ have the same derivatives of any order at some point, then we should assume same evolution at this point when $t$ is small. If we unrigorously define $\partial T_t(f)/\partial t = \left(\mathcal T_t(f)-f\right)/t$ when $t\rightarrow 0^+$ (or infinitesimal generator in our proof), then $\partial T_t(f)/\partial t$ should equal to $\partial T_t(g)/\partial t$. Thus, we give the following assumption concerning the local character of the operator $\mathcal T_t$ for $t$ small.

% Lastly, we require that $\mathcal T_t$ can be expressed as a solution operator of PDEs and for small enough $t$, which implies
% The value of $\mathcal T_t(f)$ at any point $\vx$ should be determined by the behavior of the base classifier $f$ near $\vx$

% \textbf{[Locality]} For any fixed $\vx$ and for any two given smooth base classifiers $f,g$, if 
% $$(\mathcal T_t(f)-\mathcal T_t(g))(\vx) = o(t)$$ 
% as $t\rightarrow 0^+$, then we have $D^{\alpha}f(\vx) = D^{\alpha}g(\vx)$ for all $|\alpha|\geq 0$.

\textbf{[Locality]} For all fixed $\vx$, if $f,g \in C_b^{\infty}$ satisfy $D^{\alpha}f(\vx) = D^{\alpha}g(\vx)$ for all $|\alpha|\geq 0$, then
\[\lim_{t\rightarrow 0^+}\frac{(\mathcal T_t(f)-\mathcal T_t(g))(\vx)}{t}=0\]

% \revise{We will further explain the [Locality] assumption. If the limit of $\left(\mathcal T_t(f)-f\right)/t$ exists when $t\rightarrow 0^+$, we define the limit as the generator $A[f]$. One may view it as an alternative expression for $\partial T_t(f)/\partial t$. Then [Locality] is equivalent to say
% \[ A[f](\vx) = A[g](\vx) \]
% which means that if two base classifiers have the same derivatives of any order at some point, then they have the same infinitesimal generator at this point. This assumption is a necessity in proving the existence of a particular PDE.}

Regularity is an essential component in PDE theory. Thus, when considering PDE-type assumptions on $\mathcal T_{t}$, it is necessary to study its regularity. We separate the regularity requirements into spatial and temporal. First, spatial regularity means that if we add a perturbation $\vh$ to data point $\vx$, the output $\mathcal T_t(f)(\vx+\vh)$ will not be much different from adding the same perturbation to the output $\mathcal T_t(f)(\vx)$. One can relate it to the well-known translation invariance in image processing, but our assumption is weaker, as we allow small difference rather than require strict equivalence,

\textbf{[Spatial Regularity]} There exist a positive constant $C$ dependening on $f$ such that 
\[\|\mathcal T_t(\tau_{\vh} f)-\tau_{\vh} (\mathcal T_t f)\|_{L^{\infty}}\leq Cht\]
for all $f\in C^{\infty}_b, \vh \in \mathbb R^d, t\geq 0$, where $(\tau_{\vh} f)(\vx)=f(\vx+\vh)$ and $\|\vh\|_2=h$.
\begin{remark}
    Spatial regularity is also beneficial for adversarial robustness. DNN have been shown to be vulnerable to some well-designed input samples (adversarial examples)~\cite{goodfellow2014explaining,kurakin2016adversarial}. These adversarial examples are produced by adding carefully hand-crafted perturbations to the inputs of the targeted model. Although these perturbations are imperceptible to human eyes, they can fool DNN to make wrong prediction. In some sense, the existence of these adversarial examples is due to spatial unstability of DNN. So in our method, we hope the new model $\mathcal T_t(f)$ to be spatially stable.
\end{remark}

% Similar to [Spatial Regularity], we also need an additional property for giving some temporal stability to the operator $\mathcal T_t$. Namely, in any time interval, the evolution process will not be rapid, which implies

Secondly, temporal stability requires that in any small time interval, the evolution process will not be rapid. We want a smooth operator $\mathcal T_t$ in time. Our assumption goes

% Here we define a function class $Q\subset C_b^{\infty}$, which is the space of bounded functions having bounded derivatives at any order,
% \[Q=\{f\in C_b^{\infty}: \|D^{\alpha}f\|_{L^{\infty}}\leq C, \forall |\alpha| \geq 0\} \]

\textbf{[Temporal Regularity]}
For all $t,s,t+s\in [0,T]$ and all $f\in C^{\infty}_b$, there exist a constant $C\geq 0$ depending on $f$ such that
\begin{eqnarray*}
    \|\mathcal T_{t+s,s}(f)-f\|_{L^{\infty}}&\leq& Ct\\
    \|\mathcal T_{t+s,s}(f)-\mathcal T_t(f)\|_{L^{\infty}}&\leq& Cst
\end{eqnarray*}

%To illustrate the reasonableness of these assumptions above, we give the following explanation. \\
%We first require that $\mathcal T_t$ can be expressed as a solution operator of PDEs and for small enough $t$, the value of $\mathcal T_t(f)$ at any point $\vx$ is determined by the behavior of the base classifier $f$ near $\vx$, which implies [Locality]. \\
%We then require the operator $\mathcal T_t$ is provided with an order-preserving property which means that no enhancement is made. Thus if the confidence level for an event of one base classifier $g$ is higher than another base classifier $f$, this ordering is preserved. Consider a binary classification problem and the two categories are A and B. The probability that the base model $f$ classifies the data point $\vx$ as A is 0.6 while the base model $g$ is 0.4, which means $f$ is more confident to classify $\vx$ into class A while $g$ is more confident to classify $\vx$ into class B. At this setting, we certainly hope the evolution model $\mathcal T_Tf$ classify $\vx$ into class A and $\mathcal T_Tg$ classify $\vx$ into class B. Above all, which implies [Comparison Principle]. \\
%It's natural that the output of a DNN can be deduced from the output of intermediate $l$-th layer without any information depending upon the original data point $\vx$ and output of $m$-th layer ($m<l$). So we require $\mathcal T_{t+s}$  can be computed from $\mathcal T_t$ for any $s\leq t$, and $T_0$ is of course the identity, which implies [Markov Property]. \\
%DNN have been shown to be vulnerable to some well-designed input samples(adversarial examples \cite{goodfellow2014explaining,kurakin2016adversarial}). These adversarial examples are produced by adding carefully crafted perturbations to the inputs of the targeted model. Although, these perturbations are imperceptible to human eyes but can fool the DNNs to make a wrong prediction. In some sense, the existence of these adversarial examples is due to spatial unstability of DNN. So in our method, we hope the new model $\mathcal T_t(f)$ to be spatial stable. If we add a perturbation $\vh$ to data point $\vx$, the output $\mathcal T_t(f)(\vx+\vh)$ will not change a lot, which implies [Spatial Regularity].\\
%Similar to [Spatial Regularity], we also need an additional property for giving some temporal stability to the operator $\mathcal T_t$. Namely, in any time interval, the evolution process will not be rapid, which implies [Temporal Regularity]. \\
%In practical, a complex DNN model $F$ may be composed of several sub models, and the prediction of this complex DNN model can be accumulated according to the predictions of these sub models. Mathematicaly, assume $F$ consists of two base models $f$ and $g$, and another ensemble classifier consists of base classifiers $\mathcal T_{t}(f)$ and $\mathcal T_{t}(g)$. We require the prediction $\mathcal T_t(F)$ to equal $\mathcal T_{t}(f)+\mathcal T_{t}(g)$, which implies [Ensemble Additivity].

Finally, combine all the assumptions on $\mathcal T_{t}$, we can derive the following theorem, emphasizing that the output value of neural network $T_t(f)$ with time evolution satisfies a convection-diffusion equation,
\begin{theorem}
\label{thm:main}
Under the above assumptions, there exists Lipschitz continuous function $v:\mathbb{R}^d\times [0,T]\to \mathbb{R}^d$ and Lipschitz continuous positive function $\sigma:\mathbb{R}^d\times [0,T]\to \mathbb R^{d\times d}$ such that for any bounded and uniformly continuous base classifier $f(\vx)$, $u(\vx,t) = \mathcal T_t(f)(\vx)$ is the unique solution of the following convection-diffusion equation:
\begin{equation}
	\label{eq:main}
	\begin{cases}
	\frac{\partial u(\vx,t)}{\partial t}=v(\vx,t)\cdot \nabla u(\vx,t)+\sum_{i,j}\sigma_{i,j}\frac{\partial^2u }{\partial x_i\partial x_j}(\vx,t),\\
	u(\vx,0)=f(\vx),
	\end{cases}
\end{equation}
where $\vx\in \mathbb R^{d}, t\in [0,T]$.
Here $\sigma_{i,j}$ is the $i,j$-th element of matrix function $\sigma(\vx,t)$. 
\end{theorem}
\begin{remark}
The right hands of the differential equation in \cref{eq:main} consist of two terms, the first order term $v(\vx,t)\cdot \nabla u(\vx,t)$ called convection term and the second order term $\sum_{i,j}\sigma_{i,j}\frac{\partial^2u }{\partial x_i\partial x_j}(\vx,t)$ called diffusion term. 
\end{remark}

\begin{remark}
When $\sigma(\vx,t)=\sigma^2 \Ib$, we call these type equations isotropic equations and the corresponding models isotropic models. When $\sigma(\vx,t)$ is a diagonal matrix and $\sigma(\vx,t)\neq\sigma^2 \Ib$, we call these type equations anisotropic equations that lead to anisotropic models.
\end{remark}

We will provide the proof of \Cref{thm:main} in \Cref{sec:proof_main}. In this subsection, we have introduced a convection-diffusion equation framework for ResNets. The framework is quite general, as many existing models with residual connections can be interpreted as special cases in our framework. %As examples, we briefly list some of them in the next subsection.

\subsection{Examples Convection-Diffusion Model}
Under the convection-diffusion framework, we can give interpretation to several regularization mechanisms including Gaussian noise injection~\cite{wang2020enresnet,liu2020does}, ResNet with stochastic dropping out the hidden state of residual block~\cite{srivastava2014dropout, sun2018stochastic} and randomized smoothing~\cite{cohen2019certified,li2019certified,salman2019provably}. Actually, they can be seen as convection-diffusion model with different diffusion term. Corresponding diffusion terms of these models are listed in Table \ref{tab:examples}.

\begin{table}[ht]
\centering
\caption{Examples of networks under our proposed framework\label{tab:examples}}
\begin{tabular}{ccccc}
\hline
Models & Diffusion terms\\
\hline
ResNet & 0\\
Gaussian noise injection & $\sigma^2\Delta u$\\
Dropout of Hidden Units & $\frac{1-p}{2p}\sum_{i}(v^Tv)_{i,i}\frac{\partial^2u}{\partial x_i^2}$\\
Randomized smoothing & $\sigma^2\Delta u$\\
\hline
\end{tabular}
\end{table}

\textbf{Gaussian noise injection:} Gaussian noise injection is an effective regularization mechanism for a DNN model. For a vanilla ResNet with $L$ residual mapping, the $n$-th residual mapping with Gaussian noise injected can be written as
\[\vx_{n+1}=\vx_n+\mathcal F(\vx_n,\vw_n)+a \bm{\varepsilon}_n,\,\,\,\bm{\varepsilon}_n\sim\mathcal N(0,\mathbf I)\]
where the parameter $a$ is a noise coefficient. By introducing a temporal partition: $t_{n}=nT/L$, for $n=0,1,..,L$  with the time interval $\Delta t=T/L$ and let $\vx(t_n)=\vx_n$ and $\vw(t_n)=\vw_n$. And let $a=\sigma\sqrt{\Delta t}$ and $\mathcal F(\vx_n,\vw_n)/\Delta t=v(\vx,t)$. This noise injection technique in a
discrete neural network can be viewed as the approximation of continuous dynamic 
\begin{equation}
    \label{eq:ito}
    d\vx(t)=v(\vx_n,t)dt+\sigma d\mathbf B(t)
\end{equation}
where $\mathbf B(t)$ is multidimensional Brownian motion. The output of $L$-th residual mapping can be written as I$\hat t$o process \cref{eq:ito} at terminal time $T$, $\vx(T)$. So, an ensemble prediction over all the possible sub-networks with shared parameters can be written as 
\begin{equation}
    \label{eq:expectation}
   \hat y=\mathbb E({\rm softmax}(\vw_{\text{fc}}\vx(T))|\vx(0)=\vx_0).
\end{equation}
According to Feynman-Kac formula~\cite{mao2007stochastic}, \Cref{eq:expectation} is known to solve the following convection-diffusion equation
\begin{equation*}
\begin{cases}
	\frac{\partial u(\vx,t)}{\partial t}=v(\vx,t)\cdot \nabla u+\sigma^2 \Delta u, \quad \vx\in \mathbb R^{d},t\in [0,T]\\
	u(\vx,0)={\rm softmax}(\vw_{\text{fc}}\vx).		
\end{cases}
\end{equation*}

\textbf{Dropout of Hidden Units:} Consider the case that we disable every hidden units independently from a Bernoulli distribution $\mathcal B(1,p)$ with $p\in(0,1)$ in each residual mapping
\begin{eqnarray*}
    \vx_{n+1}&=&\vx_n+\mathcal F(\vx_n,\vw_n)\odot \frac{\vz_n}{p}\\
    &=&\vx_n+\mathcal F(\vx_n,\vw_n)+\mathcal F(\vx_n,\vw_n)\odot (\frac{\vz_n}{p}-\textbf{I})
\end{eqnarray*}
where $\vz_n\sim\mathcal B(1,p)$ namely $\mathbb P(\vz_n=0)=1-p$, $\mathbb P(\vz_n=1)=p$ and $\odot$ indicates the Hadamard product. If the number of the ensemble is large enough, according to Central Limit Theorem, we have
\[\mathcal F(\vx_n,\vw_n)\odot (\frac{\vz_n}{p}-\textbf{I})\approx\mathcal F(\vx_n,\vw_n)\odot\mathcal N(0,\frac{1-p}{p})\]
The similar way with Gaussian noise injection, the ensemble prediction $\hat y$ can be viewed as the solution $u(\vx,T)$ of following equation:
\begin{equation*}
\begin{cases}
\frac{\partial u(\vx,t)}{\partial t}=v(\vx,t)\cdot \nabla u(\vx,t)+\frac{1-p}{2p}\sum_{i}(v^Tv)_{i,i}\frac{\partial^2u}{\partial x_i^2}(\vx,t), \quad \vx\in \mathbb R^{d},t\in [0,T]\\
u(\vx,0)={\rm softmax}(\vw_{\text{fc}}\vx),
\end{cases}
\end{equation*}
\begin{remark}
In fact, similar to dropout, shake-shake regularization~\cite{gastaldi2017shake,huang2018stochastic} and ResNet with stochastic depth~\cite{huang2016deep} can also be interpreted by our convection-diffusion equation model.
\end{remark}

\textbf{Randomized Smoothing:} Consider to transform a trained classifier into a new smoothed classifier by adding Gaussian noise to the input when inference time. If we denote the trained classifier by $f(\vx)$ and denote the new smoothed classifier by $g(\vx)$. Then $f(\vx)$ and $g(\vx)$ have the following relation:
\[g(\vx)=\frac{1}{N} \sum^N_{i=1} f(\vx+\bm{\varepsilon}_i) \approx \mathbb E_{\bm{\varepsilon} \sim \mathcal N(0,\sigma^2I)}[f(\vx+\bm{\varepsilon})]\]
where $\bm{\varepsilon}_i\sim \mathcal N(0,\sigma^2I)$. According to Feynman-Kac formula, $g(\vx)$ can be viewed as the solution of the following PDEs
\begin{equation}
    \begin{cases}
    \frac{\partial u(\vx,t)}{\partial t}=\frac{1}{2}\sigma^2\Delta u,t\in [0,1]\\
    u(\vx,0)=f(\vx).
    \end{cases}
\end{equation}
Especially, when $f(\vx)$ is ResNet, the smoothed classifier $g(\vx)=u(\vx,T+1)$ can be expressed as
\begin{equation*}
	\begin{cases}
         \frac{\partial u(\vx,t)}{\partial t}=v(\vx,t)\cdot \nabla u(\vx,t),\vx\in \mathbb R^{d},t\in [0,T]\\
		\frac{\partial u(\vx,t)}{\partial t}=\frac{1}{2}\sigma^2\Delta u,t\in [T,T+1]\\
		u(\vx,0)={\rm softmax}(\vw_{\text{fc}}\vx).
	\end{cases}
\end{equation*}

The differential equation formulation of randomized smoothing is similar to our method presented in the next section. However, randomized smoothing is a postprocessing step which ensures certified robustness. It does not involve the training of velocity field $v$, which is parametrized by a neural network. Moreover, our method adds regularization term in each time step $t$, while randomized smoothing only adds Gaussian noise on initial time step $t=0$.

Obviously, ResNet is no diffusion model, Gaussian noise injection and randomized smoothing are isotropic models and dropout of hidden units is anisotropic models.

The viewpoint that forward propagation of a ResNet is the solving process of a TE enables us to interpret poor robustness and generalizability as the irregularity of the solution. Moreover, we can also interpret the effectiveness of the models above-mentioned in improving generalizability as the action of diffusion term. Next, we focus on the case of isotropic models, because anisotropic models are difficult for theoretical analysis and practical experiment and we take it as our future work. 