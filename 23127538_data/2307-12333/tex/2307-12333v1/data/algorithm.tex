To verify the effectiveness of the convection-diffusion model, we design a training method for ResNet. We assume that the data point lies in an unknown domain $\mathcal D\subset \mathbb R^d$ and the label function $l(\vx)$ is defined on $\mathcal D$. Let $\mathcal S=\{(\vx_i,y_i)\}^N_{i=1} \subset \mathcal D $ be the training set, where $\vx_i$ is a data point sampled from $\mathcal D$ and $y_i=l(\vx_i)$ is the corresponding label. 

% In this subsection and in the experiment section, we assume final time step $T=1$, since time functions as a continuous analogy to discrete layers and specific value does not matter.

% Note that ResNet can be viewed as the solution of a TE with a softmax classifier as the initial value. 

% we divide the convection-diffusion equation into two parts, namely, the convection part and the diffusion part,
% \begin{align*}
% \begin{cases}\frac{\partial u(\boldsymbol{x},t)}{\partial t}= v(\boldsymbol{x},t) \cdot \nabla u(\boldsymbol{x},t), &\quad  t\in [0,T-1]\\
% \frac{\partial u(\boldsymbol{x},t)}{\partial t} = \sigma^2 \Delta u, &\quad t\in[T-1,T]\\
% u(\boldsymbol{x},0) = f(\boldsymbol{x})
% \end{cases}
% \end{align*}

As stated in the introduction, the forward propagation of ResNet corresponds to the transport equation. Denote ResNet as $g_\theta$ with trainable parameters $\theta$. Then the process from $0$ to $T-1$ in model~\cref{eq:split} corresponds to the forward propagation of $g_\theta$. In other words, the transport equation part in the convection-diffusion model~\cref{eq:split} is already inherently included in $g_\theta$. To incorporate the diffusion part, we enforce the network $g_\theta$ to satisfy the following constraint
\begin{equation}
	\begin{cases}
	\frac{\partial g_\theta(\vx,t)}{\partial t}=\sigma^2\Delta g_\theta(\vx,t), &\vx\in \mathcal D,t\in [0,1]\\
	g_\theta(\vx,t)=l(\vx), &\vx\in \mathcal S, t\in [0,1]
	\end{cases}
\end{equation}
where we set $T-1$ as the new initial time. The first equation is the diffusion part in convection-diffusion model~\cref{eq:split}. The second equation is the boundary condition for points in the training set. It is natural to require the network to classify training data correctly at any time $t\in [0,1]$. To impose the constraints, we follow the techniques in PINN~\cite{raissi2019physics} and design two loss terms for the boundary condition and differential equation respectively.

% In network training, the time interval $t\in [0,1]$ is equivalent to $t\in [0,T]$, and we choose the terminal time as 1 for convenience.

% In order to design a practical algorithm for the convection-diffusion model~\cref{diffusion}, we divide the equation into two parts, namely, the transport equation
% \begin{equation*}
% \begin{cases}
% \frac{\partial u(\vx,t)}{\partial t}=v(\vx,t)\cdot \nabla u(\vx,t), \quad \vx\in \mathcal D,t\in [0,T-1]\\
% u(\vx,0)={\rm softmax}(\vw^{\rm FC}\vx).
% \end{cases}
% \end{equation*}
% and the diffusion equation
% \[\frac{\partial u(\vx,t)}{\partial t}=\sigma^2\Delta u, \quad \vx\in \mathcal D, t\in [T-1,T]\]
% As stated in the introduction, the transport equation from $0$ to $T-1$ correspond to the forward propagation of ResNet. Thus, if we use a ResNet to represent $u$, the transport equation is already inherently included. If we let $T-1$ be the new starting time, we may rewrite the model as


% \begin{equation}\label{heat}
% \begin{cases}
% \frac{\partial u(\vx,t)}{\partial t}=\sigma^2\Delta u(\vx,t), &\vx\in \mathcal D,t\in [0,1]\\
% u(\vx,t)=l(\vx), &\vx\in \mathcal S, t\in [0,1]
% \end{cases}
% \end{equation}

%Since the terminal value of the equations $u(\vx,T)$ serves as the classifier, we enforces $u(\vx,T)$ fit the label function $l(\vx)$.
% Denote the natural trained ResNet by $f_{\widetilde{\vw}}(\vx)$, whose parameters $\widetilde{\vw}$ can be learned by minimizing the loss $l^{CE}(y_i,f_{\widetilde{\vw}}(\vx_i))$, where $l^{CE}$ is cross-entropy loss. where $\sigma^2$ is a hyperparameter.

% where $u$ is parametrized by a residual network $g_\theta$. The constraint from transport equation now becomes the initial condition $u(\vx,0)=l(\vx)$ for data points in the training set $\vx\in \mathcal S$. Moreover, after the evolution, we want the final network $u(\vx,1)$ classifies data precisely, thus the terminal condition. To train the ResNet $g_\theta$, 

% It is very difficult to solve equation (\ref{heat}) directly because of the potential high dimension of data points $\vx$. Hence we train a ResNet $g_{\vw}(\vx,t)$ parameterized by $\vw$ to approximate the real solution of (\ref{heat}). Therefore, 

%First, we use $l^{CE}(g_{\vw}(\vx_i,0),f_{\widetilde{\vw}}(\vx_i))$ and $l^{CE}(g_{\vw}(\vx_i,T),y_i)]$ to fit the initial condition of \eqref{heat}, where $l^{CE}$ is cross-entropy loss. We can write  the first loss term  as 
First, to fit the boundary condition, we use the following loss
\[L_1=\int_{\mathcal S}\int_0^1 l^{\text{CE}}\left(g_\theta(\vx,s),l(\vx)\right)\mathrm{d} s\mathrm{d} \vx
\approx\frac{1}{MN}\sum^N_{i=1}\sum_{k=1}^M l^{\text{CE}}(g_\theta(\vx_i,t_k),y_i)\]
where $l^{\text{CE}}$ denotes cross-entropy loss. $N$ is the number of data points in $\mathcal S$, and $M$ is the number of time steps. In practice, we evenly choose $t_k=(k-1)/(M-1)$ to discretize time.
% And we denote the right hand of above equation by $L_1(g_{\vw},S_N)$.

%We use mean square error loss to fit the differential equation and improve the robustness of our model,

Then, to fit the differential equation, we use the following mean square error loss
\[L_2= \int_{\mathcal D}\int^1_{0}\left(\frac{\partial g_{\theta}}{\partial t}(\vx,s)-\sigma^2\Delta g_{\theta}(\vx,s)\right)^2\mathd s \mathd \vx\]
In practice, we only have access to the training set $\mathcal S$ and do not know the underlying domain $\mathcal D$, thus we treat the neighborhood of $\mathcal S$ as the domain. The neighborhood is obtained by adding a uniform noise $\epsilon$ to $\mathcal S$. Then the integral term is approximated by
\begin{eqnarray*}
L_2 &\approx& \frac{1}{N}\sum^N_{i=1}\int^1_{0}\left(\frac{\partial g_\theta}{\partial t}(\vx_i+\epsilon,s)-\sigma^2\Delta g_{\theta}(\vx_i+\epsilon,s)\right)^2\mathd s \\
&\approx& \frac{1}{M
N}\sum^N_{i=1}\sum_{k=1}^M\left(\frac{\partial g_{\theta}}{\partial t}(\vx_i+\epsilon,t_k)-\sigma^2\Delta g_{\theta}(\vx_i+\epsilon,t_k)\right)^2.
\end{eqnarray*}

Nonetheless, in neural network, the exact computation of Laplace of output w.r.t the input is computationally intractable~\cite{martens2012estimating} because of the high dimension inputs, e.g. for CIFAR-10 pictures the dimension is 3072. Thus, we use finite difference method to approximate. Denote difference operator $\Delta_{h,\bm{v}}$ by
\[\Delta_{h,\bm{v}}g_{\theta}(\vx_i,s)=\frac{g_{\theta}(\vx_i+h\bm{v},s)+g_{\theta}(\vx_i-h\bm{v},s)-2g_{\theta}(\vx_i,s)}{h^2}\]

Using Taylor formula and law of large numbers, we have
\[\Delta g_{\theta}(\vx_i,s)=\mathbb E_{\bm{v}\sim \mathcal N(0,I)}\left(\Delta_{h,\bm{v}}g_{\theta}(\vx_i,s)\right)+O(h^2)\approx\frac{1}{K}\sum^K_{j=1}\Delta_{h,\bm{v}_{i,j}}g_{\theta}(\vx_i,s)\]
where $\{\bm{v}_{i,j}\}$ is i.i.d and standard normal distributed, $K$ is the average number. Unless otherwise specified, we set $K$ equals 1 in order to reduce the computation cost. Similarly, we introduce the time differential operator $\textbf{dt}_{\tau}$,
\[\textbf{dt}_{\tau}g_{\theta}(\vx_i,s)= \frac{g_{\theta}(\vx_i,s+\tau)-g_{\theta}(\vx_i,s-\tau)}{2\tau}\]
to substitute for $\frac{\partial g_{\theta}}{\partial t}$. Include these difference operators into $L_2$, now the loss term for differential equation becomes
\[L_2=\frac{1}{MN} \sum^N_{i=1} \sum_{k=1}^M \left( \textbf{dt}_{\tau}g_{\theta}(\vx_i+\epsilon,t_k) -\sigma^2 \frac{1}{K} \sum^K_{j=1} \Delta_{h,\bm{v}_{i,j}} g_{\theta}(\vx_i+\epsilon,t_k) \right)^2\]

The final loss function for training $g_\theta$ is a weighted sum of $L_1$ and $L_2$, $L=L_1+\lambda L_2$.

Since the input of ResNet $g_\theta$ is $(\vx,t)$, which now contains an additional time variable $t$, we modify the network input dimension from $[C\times H \times W]$ to $[(C+1)\times H \times W]$, where the additional channal represents $t$. Accordingly, we slightly change the structure of ResNet by adding an additional channel in the first convolution layer. Other than that, our ResNet structure is the same as vanilla ResNet. Obviously, when $t=0$, the additional channel has no impact on the network output, and it functions as same as vanilla ResNet. 

% Putting the two objective functions together, our training loss  combines $L_1(g_{\vw},S_N)$ and $L^{h,K}_2(v,S_N)$, i.e.,
% \begin{eqnarray}
%     {\rm Loss}(g_{\vw},S_N)=L_1(g_{\vw},S_N)+\lambda L^{h,K}_2(g_{\vw},S_N),
% \end{eqnarray}
% where $\lambda>0$ is a coefficient to balance the two loss terms. 
%In practice, we use stochastic gradient descent to optimize $g_{\vw}(\vx,t)$, and we use $g_{\vw}(\vx,T)$ as the final model. 

% Due to training ResNet110 with large $\lambda$ is
% difficult to converge, here $\lambda_k$ is changed with the number $k$, when training ResNet20 and ResNet56, we set $\lambda_k=\lambda$, and when training  ResNet110, we set
% \begin{equation}
% \lambda_k=
% \begin{cases}
% \frac{4k\lambda}{500},\ &{\rm when}\ k<100;\nonumber\\
% \frac{4\lambda}{5}+\frac{(k-100)\lambda}{250},\ &{\rm when}\ 100<k<150;\nonumber\\
% \lambda,\ &{\rm when}\ k>150.\nonumber
% \end{cases}
% \end{equation}
    
% \begin{algorithm}[tp]
%    \caption{Training ResNet model with our method}
%     \begin{algorithmic}
%        \STATE {\bfseries Input:} Training set $\mathcal S$, minibatch $\{(\vx_i,y_i)\}^{N_B}_{i=1}\in S_N$, $N_B=\#{\rm minibatches}$, hyperparameters $\lambda,\sigma^2$, learning rate $\eta_t$ and total number of epochs $k_{\max}$.\\
%        \STATE {\bfseries Output:} ResNet model trained with our method: $g_{\vw}(\vx,1)$.
%        \STATE {\bfseries Initialize:} weight parameters: $\vw$.
%        %\REPEAT
%        \FOR{$k=1$ {\bfseries to} $k_{max}$}
%        \STATE ${\rm Caculate}\,\,g_{\vw}(\vx,t)$; (Foward propagation)
%        \STATE $\mathcal L(\vw) \leftarrow L_1(g_{\vw},S_N)+\lambda_k L^{h,M}_2(g_{\vw},S_N)$; (Compute training loss)
%        \STATE $\frac{\partial \mathcal L}{\partial w} \leftarrow {\rm calculate \ gradient} (\mathcal L(\vw))$ {\rm with \ autograd}; (Backward propagation)
%        \STATE $\vw \leftarrow \vw - \eta_t\frac{\partial \mathcal L}{\partial \vw}$; (SGD update)
%        \ENDFOR
%        %\UNTIL{${\rm no \ Change}$ is ${\rm true}$}
%     \end{algorithmic}
% \label{algorithm}
% \end{algorithm}