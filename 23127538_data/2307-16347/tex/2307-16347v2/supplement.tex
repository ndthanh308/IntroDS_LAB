%\documentclass[aps,pra,superscriptaddress,showpacs,onecolumn,draft]{revtex4}
\documentclass[aps,prl,onecolumn,superscriptaddress]{revtex4}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{epstopdf}
%\usepackage{subfigure}
%\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{theorem}
\usepackage{bm}
\usepackage{url}
\usepackage[T1]{fontenc}
\usepackage{csquotes}
\MakeOuterQuote{"}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\renewcommand{\thealgorithm}{\!\!:}
\usepackage{dcolumn}
\usepackage{color}
%\usepackage[colorlinks,citecolor=blue]{hyperref}
%\usepackage{authblk}
%\usepackage{cite}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\usepackage{graphicx}


\newcommand{\red}{\color{red}}
\newcommand{\blu}{\color{blue}}
\newcommand{\blk}{\color{black}}
\definecolor{ngreen}{rgb}{0.2,0.6,0.2}
\newcommand{\grn}{\color{ngreen}}
\newcommand{\hmw}[1]{{\color{ngreen} \bf [[{#1}]]}}
\newcommand{\dwb}[1]{{\color{blue} \bf [[{#1}]]}}
\definecolor{ngold}{rgb}{0.7,0.6,0.2}
\newcommand{\gold}{\color{ngold}}
\newcommand{\blh}[1]{{\color{ngold} \bf [[{#1}]]}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% define mathematical words via abbreviations.

\def\vec#1{\mathbf{#1}} %% overiding the original command
\newcommand{\mrm}[1]{\mathrm{#1}}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\Tr}{\operatorname{Tr}}
\providecommand{\det}{\operatorname{det}}
\newcommand{\Det}{\operatorname{Det}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\sgn}{\operatorname{sgn}}
\newcommand{\ad}{\operatorname{ad}}
\newcommand{\rep}{\mathrel{\widehat{=}}}
\newcommand{\rmi}{\mathrm{i}}
\newcommand{\rme}{\mathrm{e}}
\newcommand{\rmE}{\mathrm{E}}
\newcommand{\rmd}{\mathrm{d}}
\newcommand{\rmT}{\mathrm{T}}
\newcommand{\imply}{\mathrel{\Rightarrow}}
\newcommand{\equi}{\mathrel{\Leftrightarrow}}

\newcommand{\one}{\overline{1}}
\newcommand{\zero}{\overline{0}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\be}{\begin{equation}}
	\newcommand{\ee}{\end{equation}}
\newcommand{\ba}{\begin{align}}
	\newcommand{\ea}{\end{align}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\<{\langle}  %% overiding the original command \<
\def\>{\rangle}  %% overiding the original command \>
\newcommand{\ket}[1]{| #1\>}
\newcommand{\bra}[1]{\< #1|}
\newcommand{\dket}[1]{| #1\>\!\>}
\newcommand{\Dket}[1]{\Bigl| #1\Bigr\>\!\Bigr\>}
\newcommand{\dbra}[1]{\<\!\< #1|}
\newcommand{\Dbra}[1]{\Bigl\<\!\Bigl\< #1\Bigr|}
\newcommand{\inner}[2]{\<#1|#2\>}
\def\outer#1#2{|#1\>\<#2|}       %% overiding the original command \outer
\newcommand{\dinner}[2]{\<\!\< #1| #2\>\!\>}
\newcommand{\Dinner}[2]{\Bigl\<\!\Bigl\< #1\Bigl| #2\Bigr\>\!\Bigr\>}
\newcommand{\douter}[2]{| #1\>\!\>\<\!\< #2|}
\newcommand{\Douter}[2]{\Bigl| #1\Bigr\>\!\Bigr\>\Bigl\<\!\Bigl\< #2\Bigr|}
\newcommand{\norm}[1]{\parallel\!#1\!\parallel}
\newcommand{\nfrac}[2]{\genfrac{}{}{0pt}{}{#1}{#2}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abbreviations used in quantum estimation theory
\newcommand{\mse}{\mathcal{E}}
\newcommand{\mhs}{\mathcal{E}_{\mathrm{HS}}}
\newcommand{\msh}{\mathcal{E}_{\mathrm{SH}}}
\newcommand{\msb}{\mathcal{E}_{\mathrm{SB}}}
\newcommand{\mtr}{\mathcal{E}_{\tr}}
\newcommand{\barcal}[1]{\bar{\mathcal{#1}}}
\newcommand{\bt}{\bar{t}}
\newcommand{\bid}{\bar{\mathbf{I}}}
\newcommand{\cF}{\mathcal{F}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abbreviations used in cross references and citations

%\def\eqref#1{(\ref{#1})}    %% overiding the original command \eqref
%\newcommand{\eref}[1]{Eq.~(\ref{#1})}
%\newcommand{\Eref}[1]{Equation~(\ref{#1})}
%\newcommand{\esref}[1]{Eqs.~(\ref{#1})}
%\newcommand{\Esref}[1]{Equations~(\ref{#1})}

%\def\eqref#1{\textup{(}\ref{#1}\textup{)}}  %% overiding the original command \eqref
%\newcommand{\eref}[1]{Eq.~\textup{(}\ref{#1}\textup{)}}
%\newcommand{\Eref}[1]{Equation~\textup{(}\ref{#1}\textup{)}}
%\newcommand{\esref}[1]{Eqs.~\textup{(}\ref{#1}\textup{)}}
%\newcommand{\Esref}[1]{Equations~\textup{(}\ref{#1}\textup{)}}


\def\eqref#1{\textup{(\ref{#1})}}  %% overiding the original command \eqref
\newcommand{\eref}[1]{Eq.~\textup{(\ref{#1})}}
\newcommand{\Eref}[1]{Equation~\textup{(\ref{#1})}}
\newcommand{\esref}[1]{Eqs.~\textup{(\ref{#1})}}
\newcommand{\Esref}[1]{Equations~\textup{(\ref{#1})}}


\newcommand{\fref}[1]{Fig.~\ref{#1}}
\newcommand{\Fref}[1]{Figure~\ref{#1}}
\newcommand{\fsref}[1]{Figs.~\ref{#1}}
\newcommand{\Fsref}[1]{Figures~\ref{#1}}

\newcommand{\tref}[1]{Table~\ref{#1}}
\newcommand{\Tref}[1]{Table~\ref{#1}}
\newcommand{\tsref}[1]{Tables~\ref{#1}}
\newcommand{\Tsref}[1]{Tables~\ref{#1}}

\newcommand{\sref}[1]{Sec.~\ref{#1}}
\newcommand{\Sref}[1]{Section~\ref{#1}}
\newcommand{\ssref}[1]{Secs.~\ref{#1}}
\newcommand{\Ssref}[1]{Sections~\ref{#1}}


\newcommand{\thref}[1]{Theorem~\ref{#1}}    
\newcommand{\Thref}[1]{Theorem~\ref{#1}}
\newcommand{\thsref}[1]{Theorems~\ref{#1}}
\newcommand{\Thsref}[1]{Theorems~\ref{#1}}

\newcommand{\lref}[1]{Lemma~\ref{#1}}
\newcommand{\Lref}[1]{Lemma~\ref{#1}}
\newcommand{\lsref}[1]{Lemmas~\ref{#1}}
\newcommand{\Lsref}[1]{Lemmas~\ref{#1}}

\newcommand{\crref}[1]{Corollary~\ref{#1}}
\newcommand{\Crref}[1]{Corollary~\ref{#1}}
\newcommand{\crsref}[1]{Corollaries~\ref{#1}}
\newcommand{\Crsref}[1]{Corollaries~\ref{#1}}


\newcommand{\cref}[1]{Conjecture~\ref{#1}}
\newcommand{\Cref}[1]{Conjecture~\ref{#1}}
\newcommand{\csref}[1]{Conjectures~\ref{#1}}
\newcommand{\Csref}[1]{Conjectures~\ref{#1}}

\newcommand{\chref}[1]{Chapter~\ref{#1}}
\newcommand{\Chref}[1]{Chapter~\ref{#1}}
\newcommand{\chsref}[1]{Chapters~\ref{#1}}
\newcommand{\Chsref}[1]{Chapters~\ref{#1}}

\newcommand{\aref}[1]{Appendix~\ref{#1}}
\newcommand{\asref}[1]{Appendices~\ref{#1}}
\newcommand{\Aref}[1]{Appendix~\ref{#1}}
\newcommand{\Asref}[1]{Appendices~\ref{#1}}

\newcommand{\rcite}[1]{Ref.~\cite{#1}}
\newcommand{\rscite}[1]{Refs.~\cite{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\title{Minimum-consumption discrimination of quantum states via globally optimal adaptive measurements: Supplemental Material}
\maketitle 
In the supplemental material we will discuss following things:

1. Proof: The iterative method can converge to the globally optimal adaptive strategy.

2. The POVM in GOAL strategy has no more than three elements. 

3. The fitted expression of GOAL strategy for pure state discrimination.

4. The globally optimal adaptive local strategy is the best strategy for pure state perfect discrimination even though collective measurements and weak measurements are allowed.

5.The details of the experiment setup.
\section{1. Proof: The iterative method can converge to the globally optimal adaptive strategy.}
Here we prove that the iterative method in the main text converges to the globally optimal adaptive strategy. The iterative method in the main text reads
\begin{equation}
N_{i+1}(q)=\left\{\begin{array}{c}
0 \quad \text { if } \min \left(q, 1-q\right) \leq \varepsilon,\\
\min \limits_{n,\left\{M_k\right\} \in D_n}[n+\sum\limits_k P_k N_i\left(q_k\right)] \text { otherwise. }
\end{array}\right.\label{Eq1}
\end{equation}
The initial $N_1\left(q\right)$ is self-set and realizable. We have $\forall q \in[0,1], N_1\left(q\right) \geq N_{\mathrm{GOA}}\left(q\right)$. As $N_{\mathrm{GOA}}\left(q\right)$ is the minimum average consumption, we have $\forall q \in[0,1]$ and $\forall i \in \mathrm{Z}^{+}, N_i\left(q\right) \geq$ $N_{\mathrm{GOA}}\left(q\right)$. There is at least one strategy to achieve $N_{\mathrm{GOA}}\left(q\right)$, which can be denoted as
$\left\{M_k\right\}_{\mathrm{GOA}}(q)$. 

To facilitate our proof, we use the unknown $\left\{M_k\right\}_{\mathrm{GOA}}(q)$ to define a reference function array $\left\{N_i^{\prime}\left(q\right)\right\}$, which is constructed as	$N_1^{\prime}\left(q\right)=N_1\left(q\right)$  and 
\begin{equation}
 N_{i+1}^{\prime}\left(q\right)=\left\{\begin{array}{c}
0 \quad \text { if } \min \left(q, 1-q\right) \leq \varepsilon,\\
n+\sum\limits_{\left\{M_k\right\}_{\mathrm{GOA}}(q)} P_k N_i^{\prime}\left(q_k\right) \text { otherwise. }
\end{array}\right.\label{Eq2}
\end{equation}
The difference  in \eref{Eq2} is that every round we choose the GOA measurement $\left\{M_k\right\}_{\mathrm{GOA}}(q_k)$ rather than  the optimal measurement to minimize $n+\sum\limits_k P_k N_i\left(q_k\right)$. %. As $N_1^{\prime}\left(q\right)=N_1\left(q\right)$, 
This results in $N_2^{\prime}\left(q\right) \geq N_2\left(q\right)$ because $\left\{M_k\right\}_{\mathrm{GOA}}(q_k)$ is only a possible choice to minimize $N_2\left(q\right)$ and we have $N_1^{\prime}\left(q\right)=N_1\left(q\right)$. To compare between $N_3^{\prime}\left(q\right)$ and $ N_3\left(q\right)$, we define 
\begin{equation}
 N_{i+1}^{a}\left(q\right)=\left\{\begin{array}{c}
0 \quad \text { if } \min \left(q, 1-q\right) \leq \varepsilon,\\
n+\sum\limits_{\left\{M_k\right\}_{\mathrm{GOA}}(q)} P_k N_i\left(q_k\right) \text { otherwise. }
\end{array}\right.\label{Eq3}
\end{equation}
For the same reason as $N_2^{\prime}\left(q\right) \geq N_2\left(q\right)$, we have  $N_3^{a}\left(q\right) \geq N_3\left(q\right)$. Observing the difference in eq 2 and eq 3 and $N_2^{\prime}\left(q\right) \geq N_2\left(q\right)$, we get $N_3^{\prime}\left(q\right) \geq N_3^{a}\left(q\right)$. Then we have $N_3^{\prime}\left(q\right) \geq N_3\left(q\right)$. With the same reasoning, we obtain $\forall i \in \mathrm{Z}^{+}, \forall q \in[0,1], N_i^{\prime}\left(q\right) \geq N_i\left(q\right)$. 

Note that the left-hand-side $N$ terms with index $i+1$ in eqs.1-3 are the functions of prior probability while the right-hand-side terms with index $i$ are functions of posterior probability of the corresponding measurement, implying that terms with larger index are in front of the timeline. Thus $N_i^{\prime}\left(q\right)$ means the average copy consumption realized by doing the globally optimal adaptive strategy in the first $i-1$ steps and if the first $i-1$ steps don't achieve the error rate requirement, doing the strategy corresponding to $N_1\left(q\right)$, we have
\begin{equation}
	\lim _{i \rightarrow \infty} N_i^{\prime}\left(q\right)=N_{\mathrm{GOA}}\left(q\right)\label{Eq4}
\end{equation}
As $\forall i \in \mathrm{Z}^{+}, \forall q \in[0,1], \quad N_{\mathrm{GOA}}\left(q\right) \leq N_i\left(q\right) \leq N_i^{\prime}\left(q\right)$ and $\lim\limits_{i \rightarrow \infty} N_i^{\prime}\left(q\right)=N_{\mathrm{GOA}}\left(q\right)$, finally we have 
\begin{equation}
\lim\limits_{i \rightarrow \infty} N_i\left(q\right)=N_{\mathrm{GOA}}\left(q\right)\label{Eq5}
\end{equation}

\section{2. The POVM in GOAL strategy has no more than three elements}
When searching the globally optimal adaptive local strategy, our task is to calculate the function array $\{N_i\}$ which satisfy following iterative relationship:
\begin{equation}
			N_{\mathrm{i+1}}\left(q\right)=\left\{\begin{array}{c}
				0 \qquad \text { if } \min \left(q, 1-q\right) \leq \varepsilon, \\
				1+\min\limits _{S_q(\theta)} \int_0^\pi P_\theta N_{i}\left(q_\theta\right) d\theta \ \text {otherwise.}
			\end{array}\right.\label{Eq6}
		\end{equation}
and the key problem of the calculation is how to find $S_q(\theta)$ to minimize the integral shown in \eref{Eq6}:
\begin{equation}
	I=\int_0^\pi P_\theta N_{i}\left(q_\theta\right) d\theta\equiv \int_0^\pi S_q(\theta) \operatorname{tr}\left\{\left|\psi_\theta\right\rangle\left\langle\psi_\theta\right|\left[q \rho_0+\left(1-q\right) \rho_1\right]\right\} N_i\left(q_\theta\right) \mathrm{d} \theta\label{Eq7}
\end{equation}
with $\left|\psi_\theta\right\rangle \equiv \cos \theta|0\rangle+\sin \theta|1\rangle$ under the four constraints of $S_q(\theta)$ shown in the main text.

Note that $q_\theta$ is independent of $S_q(\theta)$. Thus for any given $q$, we can separate the unknown $S_q(\theta)$ from the rest in the integral by defining $f(\theta) \equiv S_q(\theta)$ and $g(\theta) \equiv \operatorname{tr}\left\{\left|\psi_\theta\right\rangle\left\langle\psi_\theta\right|\left[q \rho_0+\left(1-q\right) \rho_1\right]\right\} N_i\left(q_\theta\right), \theta \in[0, \pi)$. Then $I=\int_0^\pi f(\theta) g(\theta) d \theta$. Due to the constraint $\int_0^\pi f(\theta) \cos (2 \theta) d \theta=0 \quad$ and $\int_0^\pi f(\theta) \sin (2 \theta) d \theta=0, \forall a, b \in \mathrm{R}$, we have $\int_0^\pi f(\theta) g(\theta) d \theta=\int_0^\pi f(\theta)[g(\theta)+a\cos(2 \theta)+b \sin (2 \theta)] d \theta$. Thus, according to the other two constraints $\int_0^\pi f(\theta)d \theta=2 \quad$ and $f(\theta)\geq0$,
if we can find $a$ and $b$ which satisfy one of two following conditions:

Condition 1: $g(\theta)+a \cos (2 \theta)+b \sin (2 \theta)$ take the minimum value at two points $\theta_1$ and $\theta_2$ and these two points satisfy $\left|\theta_1-\theta_2\right|=\frac{\pi}{2}$.

Condition 2: $g(\theta)+a \cos (2 \theta)+b \sin (2 \theta)$ take the minimum value at three points $\theta_1, \theta_2$ and $\theta_3\left(\theta_1<\theta_2<\right.$ $\theta_3$ ) and these three points satisfy $\theta_1>\theta_2-\frac{\pi}{2}$ and $\theta_2>\theta_3-\frac{\pi}{2}$ and $\theta_3>\theta_1+\frac{\pi}{2}$.

We can immediately obtain the $f(\theta)$ which minimizes the integral :

$$f(\theta)=\left\{\begin{array}{cl}
	\delta\left(\theta-\theta_1\right)+\delta\left(\theta-\theta_2\right) & \text {if} \ a \ \text{and} \ b \text { satisfy \ Condition } 1,\\
	\frac{2 \sin \left[2\left(\theta_2-\theta_1\right)\right] \delta\left(\theta-\theta_3\right)+2 \sin \left[2\left(\theta_3-\theta_2\right)\right] \delta\left(\theta-\theta_1\right)+2 \sin \left[2\left(\theta_1-\theta_3\right)\right] \delta\left(\theta-\theta_2\right)}{\sin \left[2\left(\theta_2-\theta_1\right)\right]+\sin \left[2\left(\theta_3-\theta_2\right)\right]+\sin \left[2\left(\theta_1-\theta_3\right)\right]} & \text {if} \ a \ \text{and} \ b \text { satisfy \ Condition } 2.
\end{array}\right.$$

Here the reason for why $f(\theta)$ can minimize the integral is that it only take positive value in the minimum point of $g(\theta)+a \cos (2 \theta)+b \sin (2 \theta)$, thus for any variations of $f(\theta)$ under the constraints, it is impossible to further reduce the value of integral. Thus it can minimize the value of the integral $\int_0^\pi f(\theta) g(\theta) d \theta=\int_0^\pi f(\theta)[g(\theta)+a\cos(2 \theta)+b \sin (2 \theta)] d \theta$.

For all the actual local measurement devices in the world, no matter how precise, strictly speaking, their measurement angle $\theta$ can only be taken discretely. Thus we can uniformly discretizate the function $g(\theta)$ into an array with very short step distance for $\theta$ and then we can use following method to find $a$ and $b$ which satisfy Condition 1 or Condition 2:
% Figure environment removed
\begin{enumerate}
\item Step1:Let $g(\theta)+a \cos (2 \theta)+b \sin (2 \theta)$ take the minimum value at two points $\alpha_1$ and $\alpha_2$.\\
Set $a_0=g(\frac{\pi}{2})-g(0)$ and set $g_0(\theta)=g(\theta)+\frac{a_0}{2}\cos(2\theta)$. Then we have $g_0(0)=g_0(\frac{\pi}{2})$.\\
Now  we can set $g_1(\theta)=g_0(\theta)+b_1\sin(2\theta)$. And we can found that when $b\rightarrow-\infty$ the minimum-value point of $g_1$ must in the range $[0, \frac{\pi}{2})$, and when $b\rightarrow+\infty$ the minimum-value point of $g_1$ must in the range $[\frac{\pi}{2},\pi)$. As $g_1(0)=g_1(\frac{\pi}{2})$, it is easy to prove that there must exist $\xi\in R$, when $b_1=\xi$, $g_1(\theta)$ will have at least one minimum-value point in the range $[0,\frac{\pi}{2})$ and will have at least one another minimum-value point in the range $[\frac{\pi}{2},\pi)$. Now we can set $b_1=\xi$ and $g_1(\theta)=g_0(\theta)+b_1\sin(2\theta)$ and then finish Step1. 

\item Step2: In the Step1, we have generated $g_1(\theta)$ which has at least 2 minimum-value points. If we can directly find the minimum-value points which satisfy Condition 1 or Condition 2, we can finish the search.Otherwise,

(1) if $g_1(\theta)$ has only two minimum-value points, set these two points as $\theta_1$ and $\theta_2 .\left(\theta_2>\theta_1\right)$

(2)If $g_1(\theta)$ has more than two minimum-value points, then select $\theta_1$ and $\theta_2$ in the following order:

A. If there exist $\alpha_i$ and $\alpha_j$ which are the minimum-value points of $g_1(\theta)$ and satisfy $\left|\alpha_i-\alpha_j\right|>\frac{\pi}{2}$ we select $\theta_1$ and $\theta_2$ which are the minimum-value points and satisfy $\theta_2-\theta_1=\min \limits_{\alpha_i, \alpha_j,\left|\alpha_i-\alpha_j\right|>\frac{\pi}{2}}\left|\alpha_i-\alpha_j\right|$.

B. If the judgement in A is false, select $\theta_1$ and $\theta_2$ which are the minimum-value points and satisfy
$$
\theta_2-\theta_1=\max _{\alpha_i, \alpha_j}\left|\alpha_i-\alpha_j\right|
$$

\item Step3:
After Step 2, if $\theta_2-\theta_1<\frac{\pi}{2}$, we do as follows:
Conduct transformation $g_1(\theta) \rightarrow g_1(\theta)+A \cdot \cos [2\left(\theta-\frac{\theta_2+\theta_1}{2}\right)]$, where $A=\min\limits_{\theta\in [0,\theta_1)\cup (\theta_2,\pi)}\frac{g(\theta)-g(\theta_1)}{-\cos (\theta-\theta_1-\theta_2)+\cos(\theta_1-\theta_2)}$.
As $g(\theta)$ has been discretized into an array, we can always find a positive $A$.
This transformation will generate at least one more minimum-value point $\theta_3$ in the range $[0,\theta_1)\cup (\theta_2,\pi)$,while $\theta_1$ and $\theta_2$ are still minimum-value points. Then we should do as follows:

A. If there exists minimum-value points which can satisfy Condition 1 or Condition 2, we can finish the search.

B. If all the minimum-value points can't satisfy Condition 1 or Condition 2, do as follows:

B.(1) If there exist two minimum-value points $\theta_i$ and $\theta_j$ which satisfy $\theta_i-\theta_j>\frac{\pi}{2}$, we select $\theta_1^{\prime}$ and $\theta_2^{\prime}$ which are the minimum-value points and satisfy $\theta_2^{\prime}-\theta_1^{\prime}=\min \limits_{\theta_i ,\theta_j,\left|\theta_i-\theta_j\right|>\frac{\pi}{2}}\left|\theta_i-\theta_j\right|$. Then replace $\theta_1$ and $\theta_2$ by $\theta_1^{\prime}$ and $\theta_2^{\prime}$, finish Step 3.

B.(2) If the judgement in B.(1) is false, select $\theta_1^{\prime}$ and $\theta_2^{\prime}$ which are the minimum-value points and satisfy
$\theta_2^{\prime}-\theta_1^{\prime}=\max \limits_{\theta_i, \theta_j}\left|\theta_i-\theta_j\right|$. Then replace $\theta_1$ and $\theta_2$ by $\theta_1^{\prime}$ and $\theta_2^{\prime}$, repeat Step 3.
As every time after repeating Step3, if the judgement in B.(1) is false, the value of $\theta_2-\theta_1$ will increase and be closer to $\frac{\pi}{2}$, Step3 can always finish with a finite number of repetitions.

\item Step4: After doing Step1, 2 and 3, either we have realized the search or $\theta_2-\theta_1>\frac{\pi}{2}$. If the second situation happens, we should do as follows:
Conduct transformation $g_1(\theta) \rightarrow g_1(\theta)-A \cdot \cos [ 2\left(\theta-\frac{\theta_2+\theta_1}{2}\right)]$, where $A=\min\limits_{\theta\in(\theta_1,\theta_2)}\frac{g(\theta)-g(\theta_1)}{\cos (\theta-\theta_1-\theta_2)-\cos(\theta_1-\theta_2)}$.
This transformation will generate at least one more minimum-value point $\theta_3$ in the range $[0,\theta_1)\cup (\theta_2,\pi)$,,while $\theta_1$ and $\theta_2$ are still minimum-value points, then we should do as follows:

A. If these minimum-value points satisfy Condition 1 or Condition 2 , we can finish the search.

B. If the judgement in A is false, for all the minimum-value points $\{\theta_i \}$ we select $\theta_1^{\prime}$ and $\theta_2^{\prime}$ which are the minimum-value points and satisfy  $\theta_2^{\prime}-\theta_1^{\prime}=\min \limits_{\theta_i, \theta_j,\left|\theta_i-\theta_j\right|>\frac{\pi}{2}}\left|\theta_i-\theta_j\right|$.\text Then replace $\theta_1$  and $\theta_2$ by $\theta_1^{\prime} $ and $\theta_2^{\prime}$ , repeat Step 4.

As every time after repeating Step3 and the judgement in A is false, the value of $\theta_2-\theta_1$ will reduce and be closer to  $\frac{\pi}{2}$, Step3 can always finish with a finite number of repetitions. When Step4 finish, we will search the minimum-value points which satisfy Condition 1 or Condition 2.
\end{enumerate}
For clarity, we present three computational examples in \fref{Fig.1}. It is easy to use the above methods to search the globally optimal adaptive local strategy through numerical calculation by the computer. And this method prove that the globally optimal adaptive local strategy which can achieve the local bound only need three-element POVMs and projective measurements.

\section{3. The fitted expression of GOAL strategy for pure state discrimination}
Through fitting the GOAL for pure state discrimination which are calculated by iterative method, we found the analytic expression of the GOAL for pure state discrimination. Here the two possible pure states are described as
\begin{equation}
\left|\psi_0\right\rangle=\cos \frac{x}{2}|0\rangle+\sin \frac{x}{2}|1\rangle,\left|\psi_1\right\rangle=\cos \frac{x}{2}|0\rangle-\sin \frac{x}{2}|1\rangle\label{Eq8}
\end{equation}
GOAL needs three-element POVM with following three angles $\theta_0(q),\theta_1 (q)$ and $\theta_2(q) $ or projective measurement (See \fref{Fig.2}(a)).
% Figure environment removed

		\begin{scriptsize}
	\begin{equation}
		\begin{aligned}
			& \theta_0=\pi-\frac{1}{2} \arcsin \frac{q-\varepsilon}{\sqrt{\left[\cos (2 x) \varepsilon\left(1-q\right)-(1-\varepsilon) q\right]^2+\left[\varepsilon\left(1-q\right) \sin (2 x)\right]^2}}\\
			& -\frac{1}{2} \arcsin \frac{(1-\varepsilon) q-\cos (2 x) \varepsilon\left(1-q\right)}{\sqrt{\left[\cos (2 x) \varepsilon\left(1-q\right)-(1-\varepsilon) q\right]^2+\left[\varepsilon\left(1-q\right) \sin (2 x)\right]^2}}+\frac{x}{2}, \\
			& \theta_1=-\frac{x}{2}+\frac{1}{2} \arcsin \frac{(1-\varepsilon)\left(1-q\right)-\varepsilon q \cos (2 x)}{\sqrt{\left[(1-\varepsilon)\left(1-q\right)-\varepsilon q \cos (2 x)\right]^2+\left[\varepsilon q \sin (2 x)\right]^2}} \\
			& +\frac{1}{2} \arcsin \frac{1-\varepsilon-q}{\sqrt{\left[(1-\varepsilon)\left(1-q\right)-\varepsilon q \cos (2 x)\right]^2+\left[\varepsilon q \sin (2 x)\right]^2}} ,\\
			& \theta_2=\frac{1}{2} \arcsin \frac{\frac{1}{2}-q}{\sqrt{q^2 \cos ^2 x+\frac{1}{4}-q \cos ^2 x}}
			+\frac{1}{2} \arcsin \frac{\left(\frac{1}{2}-q\right) \cos x}{\sqrt{q^2 \cos ^2 x+\frac{1}{4}-q \cos ^2 x}} .
		\end{aligned}\label{Eq9}
	\end{equation}
        \end{scriptsize}
The process of the optimal strategy is as follows:

case 1:If $q=0.5$, the measurement will be three-element fixed POVM with three angles $\theta_0,\theta_1 \ \text{and} \ \theta_2$. Here $\theta_2=0$. For every copy, if the measurement result is the element with the angle $\theta_2$, the posterior probability is equal to the priori probability. If the measurement result is the element with the angle $\theta_0$ or $\theta_1$, we can make the judgement (the state is $\psi_1$ or $\psi_0$) with the error rate which is equal to $\varepsilon$ and finish the measurement.

case 2:If $0.5>q>\frac{1-\sqrt{1-4 \varepsilon(1-\varepsilon) \cos ^{-2} x}}{2}\ \text{and}\ \theta_0(q)-\frac{\pi}{2}>\theta_2(q)$, we should do adaptive three-element POVM on the first copy with three angles $\theta_0,\theta_1 \ \text{and} \ \theta_2$. If the measurement result is the element with the angle $\theta_2$, the posterior probability will be equal to $0.5$ and the situation turns to case 1 . If the measurement result is the element with the angle $\theta_0$ or $\theta_1$, we can make the judgement (the state is $\psi_1$ or $\psi_0$) with the error rate which is equal to $\varepsilon$ and finish the measurement.

case 3:If $0.5>q>\frac{1-\sqrt{1-4 \varepsilon(1-\varepsilon) \cos ^{-2} x}}{2}\ \text{and}\ \theta_0(q)-\frac{\pi}{2}\leq\theta_2(q)$, we should do adaptive projective measurement with two angles $\theta_0 \ \text{and} \ \theta_0-\frac{\pi}{2}$ on the first copy. 
If the measurement result is the element with the angle $\theta_0$, we can make the judgement (the state is $\psi_1$) with the error rate which is equal to $\varepsilon$ and finish the measurement. If the measurement result is the element with the angle $\theta_0-\frac{\pi}{2}$, the updated posterior probability will increase. If the updated posterior probability still satisfy the condition of case3 we should do adaptive projective measurement on the next copy, otherwise, the situation turns to case 2.

case 4:If $\varepsilon<q\leq\frac{1-\sqrt{1-4 \varepsilon(1-\varepsilon) \cos ^{-2} x}}{2}$, do projective measurement with two eigenvectors of $[q\rho_0-(1-q)\rho_1]$ and then whatever the result is, we can make the judgement and finish the measurement.

case 5:If $q>0.5$, the measurement form is central symmetry about $\left(\frac{1}{2}, \frac{\pi}{2}\right)$ with the part where $q<0.5$.

Then the minimum average consumption can be expressed as follows (See \fref{Fig.2}.1(b)):
\begin{equation}
	N_{\mathrm{GOAL}}(q)=\left\{\begin{array}{c}
		\frac{2}{\lambda \operatorname{tr}\left[|0\rangle\langle 0|\left(\rho_0+\rho_1\right)\right]} \text{  case1,} \\
		1+\lambda \operatorname{tr}\left(\left|\psi_{\theta_2}\right\rangle\left\langle\psi_{\theta_2}\right| \rho\right) N_{\mathrm{GOAL}}(0.5) \text{  case2,} \\
		1+\operatorname{tr}\left(\left|\psi_{\theta_4}\right\rangle\left\langle\psi_{\theta_4}\right| \rho\right) N_{\mathrm{GOAL}}\left(q_{\theta_4}\right) \text{  case3,} \\
		1 \text{  case4,}\\
		N_{\mathrm{GOAL}}(1-q) \text{  case5.}
	\end{array}\right.\label{Eq10}
\end{equation}
where $\theta_4\equiv\theta_0-\frac{\pi}{2}$, $\quad\left|\psi_{\theta_j}\right\rangle \equiv \cos \theta_j|0\rangle+\sin\theta_j|1\rangle$,$\rho=q\left|\psi_0\right\rangle\left\langle \psi_0\left|+\left(1-q\right)\right| \psi_1\right\rangle\left\langle \psi_1\right|$,

$\qquad\lambda=\frac{2 \sin \left[2\left(\theta_1-\theta_0\right)\right]}{\sin \left[2\left(\theta_1-\theta_0\right)\right]+\sin \left[2\left(\theta_2-\theta_1\right)\right]+\sin \left[2\left(\theta_0-\theta_2\right)\right]},\rho_0=\left|\psi_0\right\rangle\left\langle \psi_0\left|, \rho_1=\right| \psi_1\right\rangle\left\langle \psi_1\right|
\text { and } q_{\theta_4}=\frac{q \operatorname{tr}\left(\left|\psi_{\theta_4}\right\rangle\left\langle\psi_{\theta_4}\right| \rho_1\right)}{\operatorname{tr}\left(\left|\psi_{\theta_4}\right\rangle\left\langle\psi_{\theta_4}\right| \rho\right)}$.

Specially, if $\varepsilon=0$, there is one critical point $q_c=\frac{\cos^2x}{1+\cos^2x}$. When $q<q_c$, we should do projective measurement with two angles $\frac{x}{2}+\frac{\pi}{2}$ and $\frac{x}{2}$.When $q_c\leq q\leq1-q$, we should do three-element POVM with three angles $\theta_0=\frac{x}{2}+\frac{\pi}{2}$,
$\theta_1=-\frac{x}{2}+\frac{\pi}{2}$, and $\theta_2=\frac{1}{2} \arcsin \frac{\frac{1}{2}-q}{\sqrt{q^2 \cos ^2 x+\frac{1}{4}-q \cos ^2 x}}+\frac{1}{2} \arcsin \frac{\left(\frac{1}{2}-q\right) \cos x}{\sqrt{q^2 \cos ^2 x+\frac{1}{4}-q \cos ^2 x}} $, and when $1-q_c\leq q$, we should do projective measurement with two angles $-\frac{x}{2}+\frac{\pi}{2}$ and $-\frac{x}{2}$ (See \fref{Fig.2}(c)).For pure states, the minimum average copy consumption is a finite value no larger than $\frac{1}{1-\cos x}$ (this conclusion is the same with [10]), but even if $q \rightarrow 0^{+} \text{or } 1^{-}$, the average copy consumption is no less than $\frac{2}{\sin ^2 x}$ (See \fref{Fig.2}(d)). 

%Though in principle for any given error rate requirement we can rewrite \eref{Eq10} as an elementary piecewise function, this function is too complex to prove through symbolic operations strictly that it is the solution to Eq.2 of the main text. Therefore, we did not strictly prove that this is the optimal one.

The  reason we infer that it is the globally optimal adaptive local strategy is that %through numerical calculation, we found for any error rate requirement, any possible states and any prior probability, the average copy consumption function calculated by \eref{Eq7} and the corresponding measurement angles satisfy Condtion 1 or Condition 2 which are shown in the second part. That means, numerically, 
if we define $g(\theta)=\operatorname{tr}\left|\psi_\theta\right\rangle\left\langle\psi_\theta\right|\left[q\left|\psi_0\right\rangle\left\langle \psi_0|+(1-q)| \psi_1\right\rangle\left\langle \psi_1\right|\right] N_{\mathrm{GOAL}}\left(q_\theta\right), \theta \in[0, \pi)$, where $N_{\mathrm{GOAL}}$ is calculated by \eref{Eq10}, we can find the suitable value of $a$ and $b$ numerically so that for case 3 and case 4, $g(\theta)+a \cos (2 \theta)+b \sin (2 \theta)$ take the minimum value at two points $\theta_0$ and $\theta_0-\frac{\pi}{2}$ and they satisfy Condition 1 and \eref{Eq9}. And for case 1 and case 2, $g(\theta)+a \cos (2 \theta)+b \sin (2 \theta)$ take the minimum value at three points $\theta_0,\theta_1$ and $\theta_2$ and they satisfy Condition 2 and \eref{Eq9}. Thus according to the second part, \eref{Eq10} may be the analytic expression of the average copy consumption realized by GOAL. And how to provide our statement based on numerical calculation evidence with a strict proof is an open problem. However, when $\varepsilon=0$, we have proved that our fitted expression is strictly correct, and the proof is shown in the next section.

\section{4.GOAL is the best strategy for minimum-consumption pure state perfect discrimination even though collective measurements and weak measurements are allowed.}
For pure state minimum-consumption discrimination, it has been known that we can discriminate the two possible states perfectly with finite average number of copies \cite{ref10}. Here we will prove that in the case $\varepsilon=0$, the fitted expression of the GOAL we provide in the last section is the strictly analytic expression and in this case $N_\mathrm{GOAL}(q)$ is the lower bound that can not be surpassed for any error rate requirement and pure state even though collective measurements and weak measurements are allowed. Here the two possible pure states are still expressed by \eref{Eq8}.

First, it is easy to prove that when $\varepsilon=0$, the strategy we provide in the last section is the measurement which maximize the local success rate for perfect discrimination in each measurement round. Thus the minimum failure probability for perfect discrimination realized by measuring $n$ copies collectively can also be calculated according to the measurements shown by \eref{Eq9} and \eref{Eq10}, only $x$ need to be replaced by $y=\arccos(\cos^n(x))$.
That means, the $n$ copies can be described as
\begin{equation}
\left|\psi_0\right\rangle^{\otimes n}=\cos \frac{y}{2}|+\rangle+\sin \frac{y}{2}|-\rangle,\left|\psi_1\right\rangle^{\otimes n}=\cos \frac{y}{2}|+\rangle-\sin \frac{y}{2}|-\rangle\label{Eq17}
\end{equation}
And there will be a critical prior probability $q_c=\frac{\cos^{2n}x}{1+\cos^{2n}x}$. To maximize the success rate for perfect disrimination through measuring these $n$ copies, if $q \in\left(0, q_c\right)$, we should do projective measurement with two angles $\frac{y}{2}+\frac{\pi}{2}$ and $\frac{y}{2}$. If $q \in\left[q_c, 1-q_c\right]$, we should do three-element POVM with three angles $\theta_0=\frac{y}{2}+\frac{\pi}{2}$,
$\theta_1=-\frac{y}{2}+\frac{\pi}{2}$, and $\theta_2=\frac{1}{2} \arcsin \frac{\frac{1}{2}-q}{\sqrt{q^2 \cos ^2 y+\frac{1}{4}-q \cos ^2 y}}+\frac{1}{2} \arcsin \frac{\left(\frac{1}{2}-q\right) \cos y}{\sqrt{q^2 \cos ^2 y+\frac{1}{4}-q \cos ^2 y}} $, and if $q \in\left(1-q_c, 1\right)$, we should do projective measurement with two angles $-\frac{y}{2}+\frac{\pi}{2}$ and $-\frac{y}{2}$.
And we set the minimum failure rate as $P_{n,\mathrm{col}}$ which can be expressed as
\begin{equation}
P_{n, \mathrm{col}}(q,x)=\left\{\begin{array}{c}
2 \sqrt{q(1-q)} \cos ^n x \quad q \in\left[q_c, 1-q_c\right] \\
\min \{q, 1-q\}+\max \{q, 1-q\} \cos ^{2 n} x \quad q \in\left(0, q_c\right) \cup\left(1-q_c, 1\right)
\end{array}\right.\label{Eq11}
\end{equation}

Besides, according to \eref{Eq11}, we can found that $P_{n,\mathrm{col}}$ has the following recursive relation:
\begin{equation}
P_{n, \mathrm{col}}(q,x)=P_{n-1, \mathrm{col}}(q,x)P_{1, \mathrm{col}}(q_{n-1},x)=\prod_{N=1}^{n}P_{1, \mathrm{col}}(q_{N-1},x)\label{Eq16}
\end{equation}
where $q_{N-1}=\min[\frac{\min(q,1-q)}{\max(q,1-q)\cos^{2N-2}x+\min(q,1-q)},0.5]$ represents the smaller one of two possible states' posterior probability. As $P_{1,\mathrm{col}}(q,x)$ is symmetric about $q=0.5$, \eref{Eq16} indicates that the the minimum failure probability $P_{n,\mathrm{col}}$ can be realized just through using the GOAL strategy we shown in the last section.

Thus, during the discrimination process, in every measurement round we can apply one copy and do projective measurement or three-element POVM on it through GOAL strategy. If we do so, the failure rate after $n$ measurement rounds will be equal to $P_{n,\mathrm{col}}$. Thus the average copy consumption will be 
\begin{equation}
\mathrm{N}=1+\sum_{n=1}^{+\infty}P_{n, \mathrm{col}} \equiv \mathrm{N}_{\text {lower bound }}\label{Eq12}
\end{equation}
So through this method we can realize the minimum average copy consumption which reach the lower bound provided in \cite{ref10}.
\section{5. Details of experiment setup}
\subsection{5.1 State Preparation}
In our photonic quantum-walk experiment, the state of each photon is described by the path and polarization\cite{ref21,ref20,ref35,ref36}, i.e.
\begin{equation}
|\psi\rangle=\sum_{p, c} A_{p, c}|p\rangle \otimes|c\rangle\label{Eq13}
\end{equation}
where $p=1,0,-1\cdots$ represents the position and $c\in\{0,1\}$ means the polarized state. Here we set $0\equiv V$ means the vertically polarized state and $1\equiv H$ means the horizontally polarized state.

Now let's consider the state preparation part shown in Fig.2(a) in the main text.
At first, the $V-$polarized photon enter through the path $p=0$. Then it goes through the wave plate H1 which can be seen as a transformation on polarization-encoded states determined by the rotation angle $\alpha_1$ (here $\alpha_1$ is the angle between the optical axis and the vertical direction),
\begin{equation}
U_1=\left(\begin{array}{cc}
\cos (2 \alpha_1) & \sin (2 \alpha_1) \\
\sin (2 \alpha_1) & -\cos (2 \alpha_1)
\end{array}\right)\label{Eq14}
\end{equation}
and the state of the photon will change to 
$|0\rangle\otimes[\cos (2 \alpha_1)|0\rangle+\sin (2 \alpha_1)|1\rangle] $. After encoding the first qubit, the photon passes the beam displacer (BD), the $H$ component is displaced
into path 1 (bottom), the $V$ component is displaced into path -1 (top) and the information of the first qubit will transfer to the path freedom. Finally, the photon will go through H2 and H3 to encode the second qubit.
% Figure environment removed
As the rotation angles shown in the table of Fig.2(a) in the main text, we can generate different states through rotating the angles of H1, H2 and H3 (set them as $\alpha_1$,$\alpha_2$ and $\alpha_3$, respectively). For example, if we set $\alpha_1=7.5^\circ$,$\alpha_2=7.5^\circ$ and $\alpha_3=52.5^\circ$, the prepared state will be described as
$$|\varphi\rangle_{\text {prepared }}=\left(\cos 15^{\circ}|-1\rangle+\sin 15^{\circ}|1\rangle\right) \otimes\left(\cos 15^{\circ}|0\rangle+\sin 15^{\circ}|1\rangle\right) \equiv\left|\varphi_1\right\rangle^{\otimes 2}.$$
Similarly we can generate $\left|\varphi_0\right\rangle^{\otimes 2}$,$\left|\varphi_0\right\rangle \otimes \left|\varphi_1\right\rangle$ and $\left|\varphi_1\right\rangle \otimes \left|\varphi_0\right\rangle$, and through randomly preparing these pure states, we can generate mixed states. When we want to generate $\rho_0^{\otimes2}$, the probabilities for preparing $\left|\varphi_0\right\rangle^{\otimes 2}$,$\left|\varphi_1\right\rangle^{\otimes 2}$,$\left|\varphi_0\right\rangle \otimes \left|\varphi_1\right\rangle$ and $\left|\varphi_1\right\rangle \otimes \left|\varphi_0\right\rangle$ are $(1-s)^2$,$s(1-s)$,$s(1-s)$ and $s^2$, respectively.When we want to generate $\rho_1^{\otimes2}$, the probabilities for preparing $\left|\varphi_0\right\rangle^{\otimes 2}$, $\left|\varphi_1\right\rangle^{\otimes 2}$, $\left|\varphi_0\right\rangle \otimes \left|\varphi_1\right\rangle$ and $\left|\varphi_1\right\rangle \otimes \left|\varphi_0\right\rangle$ are $s^2$, $s(1-s)$, $s(1-s)$ and $(1-s)^2$, respectively.
\subsection{5.2 Collective Measurement}
Now we will explain why the measurement part of our experiment platform can do two-copy collective measurement. One easy way for analysis is to consider what will happen when the input state is parallel to one of the measurement elements.

For example, if the input state is $\left|\psi_1\right\rangle=\left|\theta_{+}, \theta_{+}\right\rangle\equiv\left(\cos \theta|-1\rangle+\sin \theta|1\rangle\right) \otimes\left(\cos \theta|0\rangle+\sin \theta|1\rangle\right)$ and we set the value of the rotation angles of the wave plates H4, H5, H6, H7, H8 and H9 according to the table shown in Fig.2(a) in the main text, it's easy to find that in both two paths the photon's polarized state will be changed to $H$ by H4. In the next two steps, the two paths of beam will merge and interfere with each other and H7 and H8 will change the merged beam to $H$ polarized state and finally the photon must be received by the single-photon detector D1.
Similarly, it is easy to find that if the input state is $\left|\psi_2\right\rangle=(\left|\theta_{+}, \theta_{-}\right\rangle+\left|\theta_{-}, \theta_{+}\right\rangle)/\sqrt{2}\equiv[\left(\cos \theta|-1\rangle+\sin \theta|1\rangle\right) \otimes\left(\sin \theta|0\rangle-\cos \theta|1\rangle\right)+\left(\sin \theta|-1\rangle-\cos \theta|1\rangle\right) \otimes\left(\cos \theta|0\rangle+\sin \theta|1\rangle\right)]/\sqrt{2}$ or
$\left|\psi_3\right\rangle=(\left|\theta_{+}, \theta_{-}\right\rangle-\left|\theta_{-}, \theta_{+}\right\rangle)/\sqrt{2}\equiv[\left(\cos \theta|-1\rangle+\sin \theta|1\rangle\right) \otimes\left(\sin \theta|0\rangle-\cos \theta|1\rangle\right)-\left(\sin \theta|-1\rangle-\cos \theta|1\rangle\right) \otimes\left(\cos \theta|0\rangle+\sin \theta|1\rangle\right)]/\sqrt{2}$ or $\left|\psi_4\right\rangle=\left|\theta_{-}, \theta_{-}\right\rangle\equiv\left(\sin \theta|-1\rangle-\cos \theta|1\rangle\right) \otimes\left(\sin \theta|0\rangle-\cos \theta|1\rangle\right)$, the photon must be received by D2 or D3 or D4, respectively.

As $\psi_1$,$\psi_2$, $\psi_3$ and $\psi_4$ are orthogonal to each other, for any actually input photon which can be described by the state $|\psi\rangle=\sum_{i=1}^4\left|\psi_i\right\rangle\left\langle\psi_i \mid \psi\right\rangle$, the probability that finally it is received by the detector D$i$ ($i=$ 1 or 2 or 3 or 4) is calculated as
\begin{equation}
P_i=\left|\left\langle\psi_i \mid \psi\right\rangle\right|^2\label{Eq15}
\end{equation}

A more detailed calculation is shown in \fref{Fig.3}, it also proves that our experiment platform can do entangled two-copy collective measurement and the measurement form can be freely transformed by selecting different values of $\theta$.

%\subsection{5.3 Experimental error}
%In the experiment, the error of rotation angle (about $0.1^\circ$), the incomplete interference part of merged beams (about $\frac{1}{1000}$ of the total energy) the incomplete splitting of BD (about $\frac{1}{5000}$ of the $H$ polarized light won't 
%go down) are the main causes of the experimental errors. However, as the reatively small number of steps in our experimental circuit, we can achieve very high experimental accuracy. In our experiment, we use the 100 values of the probability distribution we measured and shown in Fig.2(b) of the main text to estimate the accuracy degree. The average probabilistic fidelity $\mathrm{F}=\frac{1}{200} \sum_{i=0}^1 \sum_{\mathrm{j}=1}^4 \sum_{\mathrm{k}=1}^{100} \sqrt{\mathrm{P}_{i j, \mathrm{experiment} }\left(\theta_{\mathrm{k}}\right)} \sqrt{\mathrm{P}_{i j, \mathrm{theory}}\left(\theta_{\mathrm{k}}\right)}=0.99994$.

%From an experimental perspective, here we want to point that though theoretically speaking we can perfectly discriminate two pure states using finite average number of copies, it is extremely difficult to achieve in the experiments. This is because according to the expression of the average probabilistic relative entropy $D_0= \sum\limits_k \operatorname{tr}\left(M_k \rho_0\right) \ln \frac{\operatorname{tr}\left(M_k \rho_0\right)}{\operatorname{tr}\left(M_k \rho_1\right)}$ and $D_1=\sum\limits_k \operatorname{tr}\left(M_k \rho_1\right) \ln \frac{\operatorname{tr}\left(M_k \rho_1\right)}{\operatorname{tr}\left(M_k \rho_0\right)}$, only when one of the pure states (such as $\rho_0$) and one of the measurement elements (set as $M_1$) are strictly orthogonal so that $\operatorname{tr}(M_1 \rho_0)=0$ and the other pure state is non-orthogonal to the same measurement element, one of $D_0$ and $D_1$ will be infinity (here $D_0$ is infinity). But if $\operatorname{tr}(M_k \rho_0)$ is little larger than $0$ (due to the quantum fluctuations of the measurement device itself, it is inevitable), even though $\operatorname{tr}(M_k \rho_0)$ may be still very small, the logarithmic function in the expression of the relative entropy will result in the relative entropy not being very large. Thus, in the actual situation, just like what we have done in the experiment shown in the main text, a more feasible and reliable scheme for pure state discrimination is to measure all the probabilistic distribution the device can realize and use the experimental data to search the GOA strategy. This conclusion shows that our GOA scheme is also a very useful theoretical tool to deal with the measurement noise. 

%\nocite{ref1,ref2,ref3,ref4,ref5,ref6,ref7,ref8,ref9,ref10,ref11,ref12,ref13,ref14,ref15,ref16,ref17,ref18,ref19,ref20,ref21,ref22,ref23,ref24,ref25,ref26,ref27,ref28,ref29,ref30,ref31,ref32,ref33,ref34}
\begin{thebibliography}{20}
\bibitem{ref1}
Carl~W Helstrom.
\newblock Quantum detection and estimation theory.
\newblock {\em Journal of Statistical Physics}, 1:231--252, 1969.

\bibitem{ref10}
Esteban Mart\'{\i}nez~Vargas, Christoph Hirche, Gael Sent\'{\i}s, Michalis
Skotiniotis, Marta Carrizo, Ramon Mu\~noz Tapia, and John Calsamiglia.
\newblock Quantum sequential hypothesis testing.
\newblock {\em Phys. Rev. Lett.}, 126:180502, May 2021.

\bibitem{ref21}
Zhibo Hou, Jun-Feng Tang, Jiangwei Shang, Huangjun Zhu, Jian Li, Yuan Yuan,
Kang-Da Wu, Guo-Yong Xiang, Chuan-Feng Li, and Guang-Can Guo.
\newblock Deterministic realization of collective measurements via photonic
quantum walks.
\newblock {\em Nature communications}, 9(1):1414, 2018.

\bibitem{ref20}
Kang-Da Wu, Elisa B\"aumer, Jun-Feng Tang, Karen~V. Hovhannisyan, Mart\'{\i}
Perarnau-Llobet, Guo-Yong Xiang, Chuan-Feng Li, and Guang-Can Guo.
\newblock Minimizing backaction through entangled measurements.
\newblock {\em Phys. Rev. Lett.}, 125:210401, Nov 2020.

\bibitem{ref35}
Kang-Da Wu, Yuan Yuan, Guo-Yong Xiang, Chuan-Feng Li, Guang-Can Guo, and MartÃ­
Perarnau-Llobet.
\newblock Experimentally reducing the quantum measurement back action in work
distributions by a collective measurement.
\newblock {\em Science Advances}, 5(3):eaav4944, 2019.

\bibitem{ref36}
Jun-Feng Tang, Zhibo Hou, Jiangwei Shang, Huangjun Zhu, Guo-Yong Xiang,
Chuan-Feng Li, and Guang-Can Guo.
\newblock Experimental optimal orienteering via parallel and antiparallel
spins.
\newblock {\em Phys. Rev. Lett.}, 124:060502, Feb 2020.
\end{thebibliography}
\end{document}

