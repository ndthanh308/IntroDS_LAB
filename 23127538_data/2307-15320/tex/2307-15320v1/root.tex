%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8


\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts         
\overrideIEEEmargins                                      % Needed to meet printer requirements.
\input{macros}
%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document



% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{graphicx} % for pdf, bitmapped graphics files
\usepackage{caption}
\usepackage{comment}
\usepackage{subcaption}


\title{\LARGE \bf
Robust visual sim-to-real transfer for robotic manipulation
}



\author{Ricardo Garcia$^1$, Robin Strudel$^1$,  Shizhe Chen$^1$, Etienne Arlaud$^1$, Ivan Laptev$^1$ and Cordelia Schmid$^1$% <-this % stops a space
\thanks{$^1$Inria, \'Ecole normale sup\'erieure, CNRS, PSL Research University, 75005, Paris, France. {\tt\small \{firstname.lastname\}@inria.fr}}
}


\begin{document}

\bstctlcite{IEEEexample:BSTcontrol}

\twocolumn[{%
\renewcommand\twocolumn[1][]{#1}%
\maketitle
\pagestyle{plain}


\vspace{-2.1em}
\begin{center}
% Figure removed
\captionof{figure}{\textbf{An overview of our approach.} We learn visuomotor manipulation policies in simulation (row 1) with domain randomization by sampling high-quality textures, lighting, object colors and camera parameters (row 2). We analyze different sampling options and demonstrate that simulator-trained policies can be directly deployed on a real robot for diverse and challenging manipulation tasks (row 3), such as rope-shaping (left) and assembling (right). 
}
\label{fig:teaser}
\end{center}
}]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Learning visuomotor policies in simulation is much safer and cheaper than in the real world. However, due to discrepancies between the simulated and real data, simulator-trained policies often fail when transferred to real robots. 
One common approach to bridge the visual sim-to-real domain gap is domain randomization (DR). 
While previous work mainly evaluates DR for disembodied tasks, such as pose estimation and object detection, 
here we systematically explore visual domain randomization methods and benchmark them on a rich set of challenging robotic manipulation tasks.
In particular, we propose an off-line proxy task of cube localization to select DR parameters for texture randomization, lighting randomization, variations of object colors and camera parameters.   
Notably, we demonstrate that DR parameters have similar impact on our off-line proxy task and on-line policies.
We, hence, use off-line optimized DR parameters to train visuomotor policies in simulation and directly apply such policies to a real robot. 
Our approach achieves 93\% success rate on average when tested on a diverse set of challenging manipulation tasks.
Moreover, we evaluate the robustness of policies to visual variations in real scenes and show that our simulator-trained policies outperform policies learned using real but limited data.
Code, simulation environment, real robot datasets and trained models are available at \url{https://www.di.ens.fr/willow/research/robust_s2r/}.

\footnotetext[1]{Inria, \'Ecole normale sup\'erieure, CNRS, PSL Research University, 75005, Paris, France.}

\vspace{-.1cm}
\end{abstract}


\input{introduction}
\input{related_work}
\input{method}
\input{dataset}
\input{experiments}

\section{Conclusion}
\vspace{-.1cm}
In this paper we address visual sim-to-real transfer of manipulation policies using domain randomization.
We explore multiple visual domain randomization components and propose a proxy task of cube localization to choose appropriate DR parameters. 
We demonstrate that under the same DR settings, the real-world performance on our proxy task strongly correlates with the performance of policies trained for diverse and challenging manipulation tasks. 
We introduce a rich set of seven manipulation tasks to benchmark visual sim-to-real transfer and demonstrate that our method significantly and consistently outperforms other approaches without DR, achieving 93\% average success rate on a real robot.
Our method also demonstrates increased robustness to visual appearance changes in real scenes.

\vspace{.1cm}

{
\small
\textbf{Acknowledgements.}
This work was partially supported by
the HPC resources from GENCI-IDRIS (Grant 20XX-AD011012122). 
It was funded in part by the French government under management of Agence Nationale de la Recherche as part of the “Investissements d’avenir” program, reference ANR19-P3IA-0001 (PRAIRIE 3IA Institute), the ANR project VideoPredict (ANR-21-FAI1-0002-01) and by Louis Vuitton ENS Chair on Artificial Intelligence.
}

\vspace{-.2cm}
\bibliographystyle{IEEEtran}
\input{bibliography}
\end{document}
