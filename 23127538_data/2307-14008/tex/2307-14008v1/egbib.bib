% add by huangzp

@inproceedings{kitaev2020reformer,
    title       = {Reformer: The Efficient Transformer},
    author      = {Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
    booktitle   = {ICLR},
    year        = {2020},
}

@inproceedings{xiong2021nystromformer,
  title={Nystr{\"o}mformer: A Nystr{\"o}m-based Algorithm for Approximating Self-Attention},
  author={Xiong, Yunyang and Zeng, Zhanpeng and Chakraborty, Rudrasis and Tan, Mingxing and Fung, Glenn and Li, Yin and Singh, Vikas},
  booktitle={AAAI},
  year={2021}
}

@inproceedings{poolingformer,
  author    = {Hang Zhang and
               Yeyun Gong and
               Yelong Shen and
               Weisheng Li and
               Jiancheng Lv and
               Nan Duan and
               Weizhu Chen},
  title     = {Poolingformer: Long Document Modeling with Pooling Attention},
  booktitle = {ICML},
  year      = {2021},
}

@inproceedings{ma2021luna,
  title={Luna: Linear unified nested attention},
  author={Ma, Xuezhe and Kong, Xiang and Wang, Sinong and Zhou, Chunting and May, Jonathan and Ma, Hao and Zettlemoyer, Luke},
  booktitle={NeurIPS},
  year={2021}
}


@article{hassani2022dilated,
  title={Dilated neighborhood attention transformer},
  author={Hassani, Ali and Shi, Humphrey},
  journal={arXiv preprint arXiv:2209.15001},
  year={2022}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{chu2021twins,
  title={Twins: Revisiting the design of spatial attention in vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{pan2022fast,
  title={Fast vision transformers with hilo attention},
  author={Pan, Zizheng and Cai, Jianfei and Zhuang, Bohan},
  booktitle={NeurIPS},
  year={2022}
}

@article{li2022next,
  title={Next-vit: Next generation vision transformer for efficient deployment in realistic industrial scenarios},
  author={Li, Jiashi and Xia, Xin and Li, Wei and Li, Huixia and Wang, Xing and Xiao, Xuefeng and Wang, Rui and Zheng, Min and Pan, Xin},
  journal={arXiv preprint arXiv:2207.05501},
  year={2022}
}

@inproceedings{zhu2021long,
  title={Long-short transformer: Efficient transformers for language and vision},
  author={Zhu, Chen and Ping, Wei and Xiao, Chaowei and Shoeybi, Mohammad and Goldstein, Tom and Anandkumar, Anima and Catanzaro, Bryan},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{ding2022scaling,
  title={Scaling up your kernels to 31x31: Revisiting large kernel design in cnns},
  author={Ding, Xiaohan and Zhang, Xiangyu and Han, Jungong and Ding, Guiguang},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{tolstikhin2021mlp,
  title={Mlp-mixer: An all-mlp architecture for vision},
  author={Tolstikhin, Ilya O and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and others},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{jia2016dynamic,
  title={Dynamic filter networks},
  author={Jia, Xu and De Brabandere, Bert and Tuytelaars, Tinne and Gool, Luc V},
  booktitle={NeurIPS},
  year={2016}
}

@inproceedings{chen2020dynamic,
  title={Dynamic convolution: Attention over convolution kernels},
  author={Chen, Yinpeng and Dai, Xiyang and Liu, Mengchen and Chen, Dongdong and Yuan, Lu and Liu, Zicheng},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{he2019dynamic,
  title={Dynamic multi-scale filters for semantic segmentation},
  author={He, Junjun and Deng, Zhongying and Qiao, Yu},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{zhang2021accurate,
  title={Accurate few-shot object detection with support-query mutual guidance and hybrid loss},
  author={Zhang, Lu and Zhou, Shuigeng and Guan, Jihong and Zhang, Ji},
  booktitle={CVPR},
  year={2021}
}


@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={ICML},
  year={2019},
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={IJCV},
  year={2015},
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  year={2014},
}

@inproceedings{liu2016ssd,
  title={Ssd: Single shot multibox detector},
  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
  booktitle={ECCV},
  year={2016},
}

@article{ge2021yolox,
  title={Yolox: Exceeding yolo series in 2021},
  author={Ge, Zheng and Liu, Songtao and Wang, Feng and Li, Zeming and Sun, Jian},
  journal={arXiv preprint arXiv:2107.08430},
  year={2021}
}

@inproceedings{tan2020efficientdet,
  title={Efficientdet: Scalable and efficient object detection},
  author={Tan, Mingxing and Pang, Ruoming and Le, Quoc V},
  booktitle={CVPR},
  pages={10781--10790},
  year={2020}
}

@article{guo2022visual,
  title={Visual attention network},
  author={Guo, Meng-Hao and Lu, Cheng-Ze and Liu, Zheng-Ning and Cheng, Ming-Ming and Hu, Shi-Min},
  journal={arXiv preprint arXiv:2202.09741},
  year={2022}
}

@inproceedings{yang2022moat,
  title={Moat: Alternating mobile convolution and attention brings strong vision models},
  author={Yang, Chenglin and Qiao, Siyuan and Yu, Qihang and Yuan, Xiaoding and Zhu, Yukun and Yuille, Alan and Adam, Hartwig and Chen, Liang-Chieh},
  booktitle={ICLR},
  year={2023}
}

@inproceedings{zhou2019semantic,
  title={Semantic understanding of scenes through the ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Xiao, Tete and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={IJCV},
  year={2019},
}

@article{everingham2015pascal,
  title={The pascal visual object classes challenge: A retrospective},
  author={Everingham, Mark and Eslami, SM Ali and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={IJCV},
  year={2015},
}

@article{chen2017rethinking,
  title={Rethinking atrous convolution for semantic image segmentation},
  author={Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  journal={arXiv preprint arXiv:1706.05587},
  year={2017}
}

@inproceedings{hariharan2011semantic,
  title={Semantic contours from inverse detectors},
  author={Hariharan, Bharath and Arbel{\'a}ez, Pablo and Bourdev, Lubomir and Maji, Subhransu and Malik, Jitendra},
  booktitle={ICCV},
  year={2011},
}

@inproceedings{mehta2019espnetv2,
  title={Espnetv2: A light-weight, power efficient, and general purpose convolutional neural network},
  author={Mehta, Sachin and Rastegari, Mohammad and Shapiro, Linda and Hajishirzi, Hannaneh},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={ICML},
  year={2020},
}

@article{guo2019low,
  title={Low-rank and locality constrained self-attention for sequence modeling},
  author={Guo, Qipeng and Qiu, Xipeng and Xue, Xiangyang and Zhang, Zheng},
  journal={IEEE Trans Audio Speech Lang Process},
  year={2019},
}

@inproceedings{chen2022mobile,
  title={Mobile-former: Bridging mobilenet and transformer},
  author={Chen, Yinpeng and Dai, Xiyang and Chen, Dongdong and Liu, Mengchen and Dong, Xiaoyi and Yuan, Lu and Liu, Zicheng},
  booktitle={CVPR},
  pages={5270--5279},
  year={2022}
}

@article{zhang2023rethinking,
  title={Rethinking Mobile Block for Efficient Neural Models},
  author={Zhang, Jiangning and Li, Xiangtai and Li, Jian and Liu, Liang and Xue, Zhucun and Zhang, Boshen and Jiang, Zhengkai and Huang, Tianxin and Wang, Yabiao and Wang, Chengjie},
  journal={arXiv preprint arXiv:2301.01146},
  year={2023}
}

@article{vasu2022improved,
  title={An improved one millisecond mobile backbone},
  author={Vasu, Pavan Kumar Anasosalu and Gabriel, James and Zhu, Jeff and Tuzel, Oncel and Ranjan, Anurag},
  journal={arXiv preprint arXiv:2206.04040},
  year={2022}
}

@inproceedings{xia2022trt,
  title={TRT-ViT: TensorRT-oriented vision transformer},
  author={Xia, Xin and Li, Jiashi and Wu, Jie and Wang, Xing and Wang, Mingkai and Xiao, Xuefeng and Zheng, Min and Wang, Rui},
  booktitle={ICCV},
  year={2022}
}

@inproceedings{yuan2021tokens,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  booktitle={CVPR},
  pages={558--567},
  year={2021}
}

@book{mcgillem1991continuous,
  title={Continuous and discrete signal and system analysis},
  author={McGillem, Clare D and Cooper, George R},
  year={1991},
  publisher={Oxford University Press, USA}
}

@inproceedings{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2021}
}


@inproceedings{yu2022metaformer,
  title={Metaformer is actually what you need for vision},
  author={Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{peng2017large,
  title={Large kernel matters--improve semantic segmentation by global convolutional network},
  author={Peng, Chao and Zhang, Xiangyu and Yu, Gang and Luo, Guiming and Sun, Jian},
  booktitle={CVPR},
  year={2017}
}


@article{liu2022more,
  title={More convnets in the 2020s: Scaling up kernels beyond 51x51 using sparsity},
  author={Liu, Shiwei and Chen, Tianlong and Chen, Xiaohan and Chen, Xuxi and Xiao, Qiao and Wu, Boqian and Pechenizkiy, Mykola and Mocanu, Decebal and Wang, Zhangyang},
  journal={ICLR},
  year={2023}
}

@article{chen2022scaling,
  title={Scaling up kernels in 3d cnns},
  author={Chen, Yukang and Liu, Jianhui and Qi, Xiaojuan and Zhang, Xiangyu and Sun, Jian and Jia, Jiaya},
  journal={arXiv preprint arXiv:2206.10555},
  year={2022}
}

@article{lian2021mlp,
  title={As-mlp: An axial shifted mlp architecture for vision},
  author={Lian, Dongze and Yu, Zehao and Sun, Xing and Gao, Shenghua},
  journal={ICLR},
  year={2022}
}

@inproceedings{xiao2021early,
  title={Early convolutions help transformers see better},
  author={Xiao, Tete and Singh, Mannat and Mintun, Eric and Darrell, Trevor and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{dai2021coatnet,
  title={Coatnet: Marrying convolution and attention for all data sizes},
  author={Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{graham2021levit,
  title={Levit: a vision transformer in convnet's clothing for faster inference},
  author={Graham, Benjamin and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and J{\'e}gou, Herv{\'e} and Douze, Matthijs},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{li2022efficientformer,
  title={Efficientformer: Vision transformers at mobilenet speed},
  author={Li, Yanyu and Yuan, Geng and Wen, Yang and Hu, Eric and Evangelidis, Georgios and Tulyakov, Sergey and Wang, Yanzhi and Ren, Jian},
  booktitle={NeurIPS},
  year={2022}
}

@article{li2022rethinking,
  title={Rethinking vision transformers for mobilenet size and speed},
  author={Li, Yanyu and Hu, Ju and Wen, Yang and Evangelidis, Georgios and Salahi, Kamyar and Wang, Yanzhi and Tulyakov, Sergey and Ren, Jian},
  journal={arXiv preprint arXiv:2212.08059},
  year={2022}
}

@article{cai2022efficientvit,
  title={Efficientvit: Enhanced linear attention for high-resolution low-computation visual recognition},
  author={Cai, Han and Gan, Chuang and Han, Song},
  journal={arXiv preprint arXiv:2205.14756},
  year={2022}
}

@inproceedings{chen2022edgevit,
  title={EdgeViT: Efficient Visual Modeling for Edge Computing},
  author={Chen, Zekai and Zhong, Fangtian and Luo, Qi and Zhang, Xiao and Zheng, Yanwei},
  booktitle={WASA},
  year={2022},
}


@inproceedings{wu2021stylespace,
  title={Stylespace analysis: Disentangled controls for stylegan image generation},
  author={Wu, Zongze and Lischinski, Dani and Shechtman, Eli},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{zhang2022parc,
  title={Parc-net: Position aware circular convolution with merits from convnets and transformer},
  author={Zhang, Haokui and Hu, Wenze and Wang, Xiaoyu},
  booktitle={ECCV},
  year={2022},
}

@inproceedings{tan2019mnasnet,
  title={Mnasnet: Platform-aware neural architecture search for mobile},
  author={Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{dai2017deformable,
  title={Deformable convolutional networks},
  author={Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
  booktitle={ICCV},
  year={2017}
}

@article{wei2022activemlp,
  title={Active token mixer},
  author={Wei, Guoqiang and Zhang, Zhizheng and Lan, Cuiling and Lu, Yan and Chen, Zhibo},
  journal={AAAI},
  year={2023}
}

@inproceedings{activemlp,
  author = {Wei, Guoqiang and Zhang, Zhizheng and Lan, Cuiling and Lu, Yan and Chen, Zhibo},  
  title = {Active Token Mixer},
  booktitle={AAAI},
  year = {2023},
}

@article{bau2020understanding,
  title={Understanding the role of individual units in a deep neural network},
  author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
  journal={PNAS},
  year={2020},
}

@InProceedings{Wu_2021_CVPR,
    author    = {Wu, Zongze and Lischinski, Dani and Shechtman, Eli},
    title     = {StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation},
    booktitle = {CVPR},
    year      = {2021},
}

% =================================
%        CNN Series
% =================================
@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{howard2019searching,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={ICCV},
  year={2019}
}

% MobileNeXt
@inproceedings{zhou2020rethinking,
  title={Rethinking bottleneck structure for efficient mobile network design},
  author={Zhou, Daquan and Hou, Qibin and Chen, Yunpeng and Feng, Jiashi and Yan, Shuicheng},
  booktitle={ECCV},
  year={2020},
  organization={Springer}
}

% Shufflenet
@inproceedings{zhang2018shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={CVPR},
  year={2018}
}

% Shufflenet V2
@inproceedings{ma2018shufflenet,
  title={Shufflenet v2: Practical guidelines for efficient cnn architecture design},
  author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
  booktitle={ECCV},
  year={2018}
}


% =================================
%        Transformer Series
% =================================

@inproceedings{mehta2021mobilevit,
  title={Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer},
  author={Mehta, Sachin and Rastegari, Mohammad},
  booktitle={ICLR},
  year={2022}
}

@article{mobilevitv2,
  author    = {Sachin Mehta and
               Mohammad Rastegari},
  title     = {Separable Self-attention for Mobile Vision Transformers},
  journal   = {TMLR},
  year      = {2022},
}

@article{wadekar2022mobilevitv3,
  title={Mobilevitv3: Mobile-friendly vision transformer with simple and effective fusion of local, global and input features},
  author={Wadekar, Shakti N and Chaurasia, Abhishek},
  journal={arXiv preprint arXiv:2209.15159},
  year={2022}
}

@inproceedings{maaz2023edgenext,
  title={Edgenext: efficiently amalgamated cnn-transformer architecture for mobile vision applications},
  author={Maaz, Muhammad and Shaker, Abdelrahman and Cholakkal, Hisham and Khan, Salman and Zamir, Syed Waqas and Anwer, Rao Muhammad and Shahbaz Khan, Fahad},
  booktitle={ECCV Workshops},
  year={2023},
}

% =================================
%        MLP Series
% =================================

@inproceedings{zhang2022morphmlp,
  title={MorphMLP: An Efficient MLP-Like Backbone for Spatial-Temporal Representation Learning},
  author={Zhang, David Junhao and Li, Kunchang and Wang, Yali and Chen, Yunpeng and Chandra, Shashwat and Qiao, Yu and Liu, Luoqi and Shou, Mike Zheng},
  booktitle={ECCV},
  year={2022},
}

@article{hou2022vision,
  title={Vision permutator: A permutable mlp-like architecture for visual recognition},
  author={Hou, Qibin and Jiang, Zihang and Yuan, Li and Cheng, Ming-Ming and Yan, Shuicheng and Feng, Jiashi},
  journal={TPAMI},
  year={2022},
}

@inproceedings{tang2022sparse,
  title={Sparse MLP for image recognition: Is self-attention really necessary?},
  author={Tang, Chuanxin and Zhao, Yucheng and Wang, Guangting and Luo, Chong and Xie, Wenxuan and Zeng, Wenjun},
  booktitle={AAAI},
  year={2022}
}

@inproceedings{wang2022shift,
  title={When shift operation meets vision transformer: An extremely simple alternative to attention mechanism},
  author={Wang, Guangting and Zhao, Yucheng and Tang, Chuanxin and Luo, Chong and Zeng, Wenjun},
  booktitle={AAAI},
  year={2022}
}

@inproceedings{chen2021cyclemlp,
  title={Cyclemlp: A mlp-like architecture for dense prediction},
  author={Chen, Shoufa and Xie, Enze and Ge, Chongjian and Liang, Ding and Luo, Ping},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{tan2019mixconv,
  title={Mixconv: Mixed depthwise convolutional kernels},
  author={Tan, Mingxing and Le, Quoc V},
  booktitle={BMVC},
  year={2019}
}

@inproceedings{chen2022cyclemlp,
    title={Cycle{MLP}: A {MLP}-like Architecture for Dense Prediction},
    author={Shoufa Chen and Enze Xie and Chongjian GE and Runjian Chen and Ding Liang and Ping Luo},
    booktitle={ICLR},
    year={2022}
}

@article{touvron2021resmlp,
  title={Resmlp: Feedforward networks for image classification with data-efficient training},
  author={Touvron, Hugo and Bojanowski, Piotr and Caron, Mathilde and Cord, Matthieu and El-Nouby, Alaaeldin and Grave, Edouard and Izacard, Gautier and Joulin, Armand and Synnaeve, Gabriel and Verbeek, Jakob and others},
  journal={arXiv preprint arXiv:2105.03404},
  year={2021}
}

@inproceedings{tolstikhin2021mlpmixer,
  title={Mlp-mixer: An all-mlp architecture for vision},
  author={Tolstikhin, Ilya O and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and others},
  booktitle={NeurIPS},
  volume={34},
  year={2021}
}

@article{zhang2021morphmlp,
  title={MorphMLP: A Self-Attention Free, MLP-Like Backbone for Image and Video},
  author={Zhang, David Junhao and Li, Kunchang and Chen, Yunpeng and Wang, Yali and Chandra, Shashwat and Qiao, Yu and Liu, Luoqi and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2111.12527},
  year={2021}
}

% =================================
%        Frequency-related
% =================================

@book{pitas2000digital,
  title={Digital image processing algorithms and applications},
  author={Pitas, Ioannis},
  year={2000},
  publisher={John Wiley \& Sons}
}

@book{baxes1994digital,
  title={Digital image processing: principles and applications},
  author={Baxes, Gregory A},
  year={1994},
  publisher={John Wiley \& Sons, Inc.}
}

@inproceedings{chi2020fast,
  title={Fast fourier convolution},
  author={Chi, Lu and Jiang, Borui and Mu, Yadong},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{rao2021global,
  title={Global filter networks for image classification},
  author={Rao, Yongming and Zhao, Wenliang and Zhu, Zheng and Lu, Jiwen and Zhou, Jie},
  booktitle={NeurIPS},
  year={2021}
}

% FNO
@article{li2020fourier,
  title={Fourier neural operator for parametric partial differential equations},
  author={Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  journal={ICLR},
  year={2021}
}

% AFNO
@article{guibas2021adaptive,
  title={Adaptive fourier neural operators: Efficient token mixers for transformers},
  author={Guibas, John and Mardani, Morteza and Li, Zongyi and Tao, Andrew and Anandkumar, Anima and Catanzaro, Bryan},
  journal={ICLR},
  year={2022}
}

@article{lin2022deep,
  title={Deep Frequency Filtering for Domain Generalization},
  author={Lin, Shiqi and Zhang, Zhizheng and Huang, Zhipeng and Lu, Yan and Lan, Cuiling and Chu, Peng and You, Quanzeng and Wang, Jiang and Liu, Zicheng and Parulkar, Amey and others},
  journal={arXiv preprint arXiv:2203.12198},
  year={2022}
}

% =================================
%        Others
% =================================

% CNNs
@article{o2015introduction,
  title={An introduction to convolutional neural networks},
  author={O'Shea, Keiron and Nash, Ryan},
  journal={arXiv preprint arXiv:1511.08458},
  year={2015}
}

% Transformers
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={NeurIPS},
  volume={30},
  year={2017}
}


@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={ICML},
  year={2021},
}

@inproceedings{tan2021efficientnetv2,
  title={Efficientnetv2: Smaller models and faster training},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={ICML},
  year={2021},
}

@inproceedings{tu2022maxvit,
  title={Maxvit: Multi-axis vision transformer},
  author={Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
  booktitle={ECCV},
  year={2022},
}

@inproceedings{wang2020high,
  title={High-frequency component helps explain the generalization of convolutional neural networks},
  author={Wang, Haohan and Wu, Xindi and Huang, Zeyi and Xing, Eric P},
  booktitle={CVPR},
  year={2020}
}

@article{xu2018understanding,
  title={Understanding training and generalization in deep learning by fourier analysis},
  author={Xu, Zhiqin John},
  journal={arXiv preprint arXiv:1808.04295},
  year={2018}
}

@inproceedings{xu2019training,
  title={Training behavior of deep neural network in frequency domain},
  author={Xu, Zhi-Qin John and Zhang, Yaoyu and Xiao, Yanyang},
  booktitle={ICONIP},
  year={2019},
}

@inproceedings{yin2019fourier,
  title={A fourier perspective on model robustness in computer vision},
  author={Yin, Dong and Gontijo Lopes, Raphael and Shlens, Jon and Cubuk, Ekin Dogus and Gilmer, Justin},
  booktitle={NeurIPS},
  year={2019}
}

@article{rabiner1975theory,
  title={Theory and application of digital signal processing},
  author={Rabiner, Lawrence R and Gold, Bernard},
  journal={Englewood Cliffs: Prentice-Hall},
  year={1975}
}

@book{oppenheim1999discrete,
  title={Discrete-time signal processing},
  author={Oppenheim, Alan V},
  year={1999},
  publisher={Pearson Education India}
}

@inproceedings{wang2018non,
  title={Non-local neural networks},
  author={Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle={CVPR},
  year={2018}
}

@article{wang2022pvt,
  title={Pvt v2: Improved baselines with pyramid vision transformer},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  journal={CVM},
  year={2022},
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={CVPRn},
  year={2017}
}

@inproceedings{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={ICCV},
  pages={568--578},
  year={2021}
}

@inproceedings{chen2021regionvit,
  title={Regionvit: Regional-to-local attention for vision transformers},
  author={Chen, Chun-Fu and Panda, Rameswar and Fan, Quanfu},
  booktitle={ICLR},
  year={2022}
}