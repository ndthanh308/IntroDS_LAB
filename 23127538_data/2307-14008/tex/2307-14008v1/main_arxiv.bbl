\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{bau2020understanding}
David Bau, Jun-Yan Zhu, Hendrik Strobelt, Agata Lapedriza, Bolei Zhou, and
  Antonio Torralba.
\newblock Understanding the role of individual units in a deep neural network.
\newblock {\em PNAS}, 2020.

\bibitem{baxes1994digital}
Gregory~A Baxes.
\newblock {\em Digital image processing: principles and applications}.
\newblock John Wiley \& Sons, Inc., 1994.

\bibitem{cai2022efficientvit}
Han Cai, Chuang Gan, and Song Han.
\newblock Efficientvit: Enhanced linear attention for high-resolution
  low-computation visual recognition.
\newblock {\em arXiv preprint arXiv:2205.14756}, 2022.

\bibitem{chen2021regionvit}
Chun-Fu Chen, Rameswar Panda, and Quanfu Fan.
\newblock Regionvit: Regional-to-local attention for vision transformers.
\newblock In {\em ICLR}, 2022.

\bibitem{chen2017rethinking}
Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam.
\newblock Rethinking atrous convolution for semantic image segmentation.
\newblock {\em arXiv preprint arXiv:1706.05587}, 2017.

\bibitem{chen2022cyclemlp}
Shoufa Chen, Enze Xie, Chongjian GE, Runjian Chen, Ding Liang, and Ping Luo.
\newblock Cycle{MLP}: A {MLP}-like architecture for dense prediction.
\newblock In {\em ICLR}, 2022.

\bibitem{chen2021cyclemlp}
Shoufa Chen, Enze Xie, Chongjian Ge, Ding Liang, and Ping Luo.
\newblock Cyclemlp: A mlp-like architecture for dense prediction.
\newblock In {\em ICLR}, 2022.

\bibitem{chen2022mobile}
Yinpeng Chen, Xiyang Dai, Dongdong Chen, Mengchen Liu, Xiaoyi Dong, Lu Yuan,
  and Zicheng Liu.
\newblock Mobile-former: Bridging mobilenet and transformer.
\newblock In {\em CVPR}, pages 5270--5279, 2022.

\bibitem{chen2020dynamic}
Yinpeng Chen, Xiyang Dai, Mengchen Liu, Dongdong Chen, Lu Yuan, and Zicheng
  Liu.
\newblock Dynamic convolution: Attention over convolution kernels.
\newblock In {\em CVPR}, 2020.

\bibitem{chen2022scaling}
Yukang Chen, Jianhui Liu, Xiaojuan Qi, Xiangyu Zhang, Jian Sun, and Jiaya Jia.
\newblock Scaling up kernels in 3d cnns.
\newblock {\em arXiv preprint arXiv:2206.10555}, 2022.

\bibitem{chen2022edgevit}
Zekai Chen, Fangtian Zhong, Qi Luo, Xiao Zhang, and Yanwei Zheng.
\newblock Edgevit: Efficient visual modeling for edge computing.
\newblock In {\em WASA}, 2022.

\bibitem{chi2020fast}
Lu Chi, Borui Jiang, and Yadong Mu.
\newblock Fast fourier convolution.
\newblock In {\em NeurIPS}, 2020.

\bibitem{chu2021twins}
Xiangxiang Chu, Zhi Tian, Yuqing Wang, Bo Zhang, Haibing Ren, Xiaolin Wei,
  Huaxia Xia, and Chunhua Shen.
\newblock Twins: Revisiting the design of spatial attention in vision
  transformers.
\newblock In {\em NeurIPS}, 2021.

\bibitem{dai2017deformable}
Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, and Yichen
  Wei.
\newblock Deformable convolutional networks.
\newblock In {\em ICCV}, 2017.

\bibitem{dai2021coatnet}
Zihang Dai, Hanxiao Liu, Quoc~V Le, and Mingxing Tan.
\newblock Coatnet: Marrying convolution and attention for all data sizes.
\newblock In {\em NeurIPS}, 2021.

\bibitem{ding2022scaling}
Xiaohan Ding, Xiangyu Zhang, Jungong Han, and Guiguang Ding.
\newblock Scaling up your kernels to 31x31: Revisiting large kernel design in
  cnns.
\newblock In {\em CVPR}, 2022.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{everingham2015pascal}
Mark Everingham, SM~Ali Eslami, Luc Van~Gool, Christopher~KI Williams, John
  Winn, and Andrew Zisserman.
\newblock The pascal visual object classes challenge: A retrospective.
\newblock {\em IJCV}, 2015.

\bibitem{ge2021yolox}
Zheng Ge, Songtao Liu, Feng Wang, Zeming Li, and Jian Sun.
\newblock Yolox: Exceeding yolo series in 2021.
\newblock {\em arXiv preprint arXiv:2107.08430}, 2021.

\bibitem{graham2021levit}
Benjamin Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin,
  Herv{\'e} J{\'e}gou, and Matthijs Douze.
\newblock Levit: a vision transformer in convnet's clothing for faster
  inference.
\newblock In {\em ICCV}, 2021.

\bibitem{guibas2021adaptive}
John Guibas, Morteza Mardani, Zongyi Li, Andrew Tao, Anima Anandkumar, and
  Bryan Catanzaro.
\newblock Adaptive fourier neural operators: Efficient token mixers for
  transformers.
\newblock {\em ICLR}, 2022.

\bibitem{guo2022visual}
Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, and Shi-Min Hu.
\newblock Visual attention network.
\newblock {\em arXiv preprint arXiv:2202.09741}, 2022.

\bibitem{guo2019low}
Qipeng Guo, Xipeng Qiu, Xiangyang Xue, and Zheng Zhang.
\newblock Low-rank and locality constrained self-attention for sequence
  modeling.
\newblock {\em IEEE Trans Audio Speech Lang Process}, 2019.

\bibitem{hariharan2011semantic}
Bharath Hariharan, Pablo Arbel{\'a}ez, Lubomir Bourdev, Subhransu Maji, and
  Jitendra Malik.
\newblock Semantic contours from inverse detectors.
\newblock In {\em ICCV}, 2011.

\bibitem{hassani2022dilated}
Ali Hassani and Humphrey Shi.
\newblock Dilated neighborhood attention transformer.
\newblock {\em arXiv preprint arXiv:2209.15001}, 2022.

\bibitem{he2019dynamic}
Junjun He, Zhongying Deng, and Yu Qiao.
\newblock Dynamic multi-scale filters for semantic segmentation.
\newblock In {\em ICCV}, 2019.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{hou2022vision}
Qibin Hou, Zihang Jiang, Li Yuan, Ming-Ming Cheng, Shuicheng Yan, and Jiashi
  Feng.
\newblock Vision permutator: A permutable mlp-like architecture for visual
  recognition.
\newblock {\em TPAMI}, 2022.

\bibitem{howard2019searching}
Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing
  Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, et~al.
\newblock Searching for mobilenetv3.
\newblock In {\em ICCV}, 2019.

\bibitem{howard2017mobilenets}
Andrew~G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang,
  Tobias Weyand, Marco Andreetto, and Hartwig Adam.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock {\em arXiv preprint arXiv:1704.04861}, 2017.

\bibitem{jia2016dynamic}
Xu Jia, Bert De~Brabandere, Tinne Tuytelaars, and Luc~V Gool.
\newblock Dynamic filter networks.
\newblock In {\em NeurIPS}, 2016.

\bibitem{katharopoulos2020transformers}
Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Fran{\c{c}}ois
  Fleuret.
\newblock Transformers are rnns: Fast autoregressive transformers with linear
  attention.
\newblock In {\em ICML}, 2020.

\bibitem{kitaev2020reformer}
Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya.
\newblock Reformer: The efficient transformer.
\newblock In {\em ICLR}, 2020.

\bibitem{li2022next}
Jiashi Li, Xin Xia, Wei Li, Huixia Li, Xing Wang, Xuefeng Xiao, Rui Wang, Min
  Zheng, and Xin Pan.
\newblock Next-vit: Next generation vision transformer for efficient deployment
  in realistic industrial scenarios.
\newblock {\em arXiv preprint arXiv:2207.05501}, 2022.

\bibitem{li2022rethinking}
Yanyu Li, Ju Hu, Yang Wen, Georgios Evangelidis, Kamyar Salahi, Yanzhi Wang,
  Sergey Tulyakov, and Jian Ren.
\newblock Rethinking vision transformers for mobilenet size and speed.
\newblock {\em arXiv preprint arXiv:2212.08059}, 2022.

\bibitem{li2022efficientformer}
Yanyu Li, Geng Yuan, Yang Wen, Eric Hu, Georgios Evangelidis, Sergey Tulyakov,
  Yanzhi Wang, and Jian Ren.
\newblock Efficientformer: Vision transformers at mobilenet speed.
\newblock In {\em NeurIPS}, 2022.

\bibitem{li2020fourier}
Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik
  Bhattacharya, Andrew Stuart, and Anima Anandkumar.
\newblock Fourier neural operator for parametric partial differential
  equations.
\newblock {\em ICLR}, 2021.

\bibitem{lian2021mlp}
Dongze Lian, Zehao Yu, Xing Sun, and Shenghua Gao.
\newblock As-mlp: An axial shifted mlp architecture for vision.
\newblock {\em ICLR}, 2022.

\bibitem{lin2022deep}
Shiqi Lin, Zhizheng Zhang, Zhipeng Huang, Yan Lu, Cuiling Lan, Peng Chu,
  Quanzeng You, Jiang Wang, Zicheng Liu, Amey Parulkar, et~al.
\newblock Deep frequency filtering for domain generalization.
\newblock {\em arXiv preprint arXiv:2203.12198}, 2022.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em ECCV}, 2014.

\bibitem{liu2022more}
Shiwei Liu, Tianlong Chen, Xiaohan Chen, Xuxi Chen, Qiao Xiao, Boqian Wu,
  Mykola Pechenizkiy, Decebal Mocanu, and Zhangyang Wang.
\newblock More convnets in the 2020s: Scaling up kernels beyond 51x51 using
  sparsity.
\newblock {\em ICLR}, 2023.

\bibitem{liu2016ssd}
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed,
  Cheng-Yang Fu, and Alexander~C Berg.
\newblock Ssd: Single shot multibox detector.
\newblock In {\em ECCV}, 2016.

\bibitem{liu2021swin}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em ICCV}, 2021.

\bibitem{ma2018shufflenet}
Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun.
\newblock Shufflenet v2: Practical guidelines for efficient cnn architecture
  design.
\newblock In {\em ECCV}, 2018.

\bibitem{ma2021luna}
Xuezhe Ma, Xiang Kong, Sinong Wang, Chunting Zhou, Jonathan May, Hao Ma, and
  Luke Zettlemoyer.
\newblock Luna: Linear unified nested attention.
\newblock In {\em NeurIPS}, 2021.

\bibitem{maaz2023edgenext}
Muhammad Maaz, Abdelrahman Shaker, Hisham Cholakkal, Salman Khan, Syed~Waqas
  Zamir, Rao~Muhammad Anwer, and Fahad Shahbaz~Khan.
\newblock Edgenext: efficiently amalgamated cnn-transformer architecture for
  mobile vision applications.
\newblock In {\em ECCV Workshops}, 2023.

\bibitem{mcgillem1991continuous}
Clare~D McGillem and George~R Cooper.
\newblock {\em Continuous and discrete signal and system analysis}.
\newblock Oxford University Press, USA, 1991.

\bibitem{mehta2021mobilevit}
Sachin Mehta and Mohammad Rastegari.
\newblock Mobilevit: light-weight, general-purpose, and mobile-friendly vision
  transformer.
\newblock In {\em ICLR}, 2022.

\bibitem{mobilevitv2}
Sachin Mehta and Mohammad Rastegari.
\newblock Separable self-attention for mobile vision transformers.
\newblock {\em TMLR}, 2022.

\bibitem{mehta2019espnetv2}
Sachin Mehta, Mohammad Rastegari, Linda Shapiro, and Hannaneh Hajishirzi.
\newblock Espnetv2: A light-weight, power efficient, and general purpose
  convolutional neural network.
\newblock In {\em CVPR}, 2019.

\bibitem{oppenheim1999discrete}
Alan~V Oppenheim.
\newblock {\em Discrete-time signal processing}.
\newblock Pearson Education India, 1999.

\bibitem{o2015introduction}
Keiron O'Shea and Ryan Nash.
\newblock An introduction to convolutional neural networks.
\newblock {\em arXiv preprint arXiv:1511.08458}, 2015.

\bibitem{pan2022fast}
Zizheng Pan, Jianfei Cai, and Bohan Zhuang.
\newblock Fast vision transformers with hilo attention.
\newblock In {\em NeurIPS}, 2022.

\bibitem{peng2017large}
Chao Peng, Xiangyu Zhang, Gang Yu, Guiming Luo, and Jian Sun.
\newblock Large kernel matters--improve semantic segmentation by global
  convolutional network.
\newblock In {\em CVPR}, 2017.

\bibitem{pitas2000digital}
Ioannis Pitas.
\newblock {\em Digital image processing algorithms and applications}.
\newblock John Wiley \& Sons, 2000.

\bibitem{rabiner1975theory}
Lawrence~R Rabiner and Bernard Gold.
\newblock Theory and application of digital signal processing.
\newblock {\em Englewood Cliffs: Prentice-Hall}, 1975.

\bibitem{rao2021global}
Yongming Rao, Wenliang Zhao, Zheng Zhu, Jiwen Lu, and Jie Zhou.
\newblock Global filter networks for image classification.
\newblock In {\em NeurIPS}, 2021.

\bibitem{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em IJCV}, 2015.

\bibitem{sandler2018mobilenetv2}
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh
  Chen.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In {\em CVPR}, 2018.

\bibitem{tan2019efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In {\em ICML}, 2019.

\bibitem{tan2021efficientnetv2}
Mingxing Tan and Quoc Le.
\newblock Efficientnetv2: Smaller models and faster training.
\newblock In {\em ICML}, 2021.

\bibitem{tan2020efficientdet}
Mingxing Tan, Ruoming Pang, and Quoc~V Le.
\newblock Efficientdet: Scalable and efficient object detection.
\newblock In {\em CVPR}, pages 10781--10790, 2020.

\bibitem{tang2022sparse}
Chuanxin Tang, Yucheng Zhao, Guangting Wang, Chong Luo, Wenxuan Xie, and Wenjun
  Zeng.
\newblock Sparse mlp for image recognition: Is self-attention really necessary?
\newblock In {\em AAAI}, 2022.

\bibitem{tolstikhin2021mlp}
Ilya~O Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua
  Zhai, Thomas Unterthiner, Jessica Yung, Andreas Steiner, Daniel Keysers,
  Jakob Uszkoreit, et~al.
\newblock Mlp-mixer: An all-mlp architecture for vision.
\newblock In {\em NeurIPS}, 2021.

\bibitem{tolstikhin2021mlpmixer}
Ilya~O Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua
  Zhai, Thomas Unterthiner, Jessica Yung, Andreas Steiner, Daniel Keysers,
  Jakob Uszkoreit, et~al.
\newblock Mlp-mixer: An all-mlp architecture for vision.
\newblock In {\em NeurIPS}, volume~34, 2021.

\bibitem{touvron2021resmlp}
Hugo Touvron, Piotr Bojanowski, Mathilde Caron, Matthieu Cord, Alaaeldin
  El-Nouby, Edouard Grave, Gautier Izacard, Armand Joulin, Gabriel Synnaeve,
  Jakob Verbeek, et~al.
\newblock Resmlp: Feedforward networks for image classification with
  data-efficient training.
\newblock {\em arXiv preprint arXiv:2105.03404}, 2021.

\bibitem{touvron2021training}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In {\em ICML}, 2021.

\bibitem{tu2022maxvit}
Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan
  Bovik, and Yinxiao Li.
\newblock Maxvit: Multi-axis vision transformer.
\newblock In {\em ECCV}, 2022.

\bibitem{vasu2022improved}
Pavan Kumar~Anasosalu Vasu, James Gabriel, Jeff Zhu, Oncel Tuzel, and Anurag
  Ranjan.
\newblock An improved one millisecond mobile backbone.
\newblock {\em arXiv preprint arXiv:2206.04040}, 2022.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em NeurIPS}, 30, 2017.

\bibitem{wang2020high}
Haohan Wang, Xindi Wu, Zeyi Huang, and Eric~P Xing.
\newblock High-frequency component helps explain the generalization of
  convolutional neural networks.
\newblock In {\em CVPR}, 2020.

\bibitem{wang2022pvt}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong
  Lu, Ping Luo, and Ling Shao.
\newblock Pvt v2: Improved baselines with pyramid vision transformer.
\newblock {\em CVM}, 2022.

\bibitem{wang2018non}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In {\em CVPR}, 2018.

\bibitem{activemlp}
Guoqiang Wei, Zhizheng Zhang, Cuiling Lan, Yan Lu, and Zhibo Chen.
\newblock Active token mixer.
\newblock In {\em AAAI}, 2023.

\bibitem{wei2022activemlp}
Guoqiang Wei, Zhizheng Zhang, Cuiling Lan, Yan Lu, and Zhibo Chen.
\newblock Active token mixer.
\newblock {\em AAAI}, 2023.

\bibitem{Wu_2021_CVPR}
Zongze Wu, Dani Lischinski, and Eli Shechtman.
\newblock Stylespace analysis: Disentangled controls for stylegan image
  generation.
\newblock In {\em CVPR}, 2021.

\bibitem{wu2021stylespace}
Zongze Wu, Dani Lischinski, and Eli Shechtman.
\newblock Stylespace analysis: Disentangled controls for stylegan image
  generation.
\newblock In {\em CVPR}, 2021.

\bibitem{xiong2021nystromformer}
Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung,
  Yin Li, and Vikas Singh.
\newblock Nystr{\"o}mformer: A nystr{\"o}m-based algorithm for approximating
  self-attention.
\newblock In {\em AAAI}, 2021.

\bibitem{xu2018understanding}
Zhiqin~John Xu.
\newblock Understanding training and generalization in deep learning by fourier
  analysis.
\newblock {\em arXiv preprint arXiv:1808.04295}, 2018.

\bibitem{xu2019training}
Zhi-Qin~John Xu, Yaoyu Zhang, and Yanyang Xiao.
\newblock Training behavior of deep neural network in frequency domain.
\newblock In {\em ICONIP}, 2019.

\bibitem{yang2022moat}
Chenglin Yang, Siyuan Qiao, Qihang Yu, Xiaoding Yuan, Yukun Zhu, Alan Yuille,
  Hartwig Adam, and Liang-Chieh Chen.
\newblock Moat: Alternating mobile convolution and attention brings strong
  vision models.
\newblock In {\em ICLR}, 2023.

\bibitem{yin2019fourier}
Dong Yin, Raphael Gontijo~Lopes, Jon Shlens, Ekin~Dogus Cubuk, and Justin
  Gilmer.
\newblock A fourier perspective on model robustness in computer vision.
\newblock In {\em NeurIPS}, 2019.

\bibitem{yu2022metaformer}
Weihao Yu, Mi Luo, Pan Zhou, Chenyang Si, Yichen Zhou, Xinchao Wang, Jiashi
  Feng, and Shuicheng Yan.
\newblock Metaformer is actually what you need for vision.
\newblock In {\em CVPR}, 2022.

\bibitem{yuan2021tokens}
Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zi-Hang Jiang,
  Francis~EH Tay, Jiashi Feng, and Shuicheng Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock In {\em CVPR}, pages 558--567, 2021.

\bibitem{zhang2021morphmlp}
David~Junhao Zhang, Kunchang Li, Yunpeng Chen, Yali Wang, Shashwat Chandra, Yu
  Qiao, Luoqi Liu, and Mike~Zheng Shou.
\newblock Morphmlp: A self-attention free, mlp-like backbone for image and
  video.
\newblock {\em arXiv preprint arXiv:2111.12527}, 2021.

\bibitem{zhang2022morphmlp}
David~Junhao Zhang, Kunchang Li, Yali Wang, Yunpeng Chen, Shashwat Chandra, Yu
  Qiao, Luoqi Liu, and Mike~Zheng Shou.
\newblock Morphmlp: An efficient mlp-like backbone for spatial-temporal
  representation learning.
\newblock In {\em ECCV}, 2022.

\bibitem{zhang2021accurate}
Lu Zhang, Shuigeng Zhou, Jihong Guan, and Ji Zhang.
\newblock Accurate few-shot object detection with support-query mutual guidance
  and hybrid loss.
\newblock In {\em CVPR}, 2021.

\bibitem{zhang2018shufflenet}
Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun.
\newblock Shufflenet: An extremely efficient convolutional neural network for
  mobile devices.
\newblock In {\em CVPR}, 2018.

\bibitem{zhou2019semantic}
Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso,
  and Antonio Torralba.
\newblock Semantic understanding of scenes through the ade20k dataset.
\newblock In {\em IJCV}, 2019.

\end{thebibliography}
