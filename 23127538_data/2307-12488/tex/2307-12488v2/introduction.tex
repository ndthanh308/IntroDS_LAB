\section{Introduction}
\label{sec:intro}
ChatGPT~\cite{chatgptlimitation}, an artificial intelligence chatbot developed by OpenAI and launched in November 2022, has garnered significant attention for its impressive capabilities. With the ability to respond to diverse prompts, ranging from answering questions in various fields to generating custom essays, people are truly astonished by its prowess. Researchers and users alike are intrigued by ChatGPT's potential to address questions across multiple domains, and they are keen to observe how its application may evolve in different areas. 

However, while ChatGPT showcases strengths in its responses, its weaknesses and potential risks remain less understood. Users who are unaware of these limitations may be susceptible to being misled by ChatGPT's outputs. For instance, in the case of requesting paper recommendations on a specific topic, we have encountered instances where some suggested papers turned out to be fake or unreliable. The following example shows a conversation with ChatGPT:

% In this study, we aim to explore the strengths, weaknesses, and potential risks associated with ChatGPT. Through an in-depth analysis of its performance, we seek to better understand its capabilities and limitations in various domains. By raising awareness of potential risks, we can empower users to make informed decisions when interacting with ChatGPT and ensure its responsible and beneficial usage.

% ChatGPT is an artificial intelligence chatbot developed by OpenAI and launched in November 2022.
% It is trained to follow an instruction in a prompt and provide a detailed response. From answering questions of may different fields to writing essay based on user's requirements, people are really astonished by its strong ability. Researchers and users are interested in it ability and potential to answer questions from different areas and see the changes of its application in many different areas. However its strength, weakness and potential risks is still unclear so far. Without aware of its weakness and potential risk, user may mislead by ChatGPT. For example, when asking ChatGPT to suggest some paper that related to a specific topic, we found that some of suggested papers are fake.

\noindent{\bf Q1:} \textit{Please provide some papers that discuss the limitations of ChatGPT.}
\begin{shaded*}
    \footnotesize
    \noindent{\bf Reply from ChatGPT:}  Certainly! Here are a few papers that discuss the limitations of language models like ChatGPT:

    \begin{enumerate}
    \item ``Language Models are Few-Shot Learners" by Tom B. Brown et al. (NeurIPS 2020)
    
    \item ``On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" by Emily M. Bender et al. (2021)
    
    \item {\color{bittersweet}``Bad Chatbot! Exploring the Limitations of Seq2Seq Models with the Help of Regular Expressions" by Mateusz Fedoryszak (ACL 2018)}
 
    \item {\color{bittersweet}``The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics" by Mathias MÃ¼ller et al. (EMNLP 2020)}
    
    \item {\color{bittersweet}``The Unreliability of GPT-3 for Answering Science Questions" by Vedanuj Goswami et al. (EMNLP 2021)}
    \end{enumerate}
\end{shaded*}
We discovered that the colored paper titles are fabricated. This example underscores the significance of understanding both the capabilities and limitations of ChatGPT to employ it responsibly.

OpenAI's release of the "GPT-4 Technical Report~\cite{openai2023gpt4}" showcases GPT-4's remarkable performance on various professional and academic benchmarks, demonstrating human-level proficiency in certain scenarios. Notably, GPT-4 successfully passed a simulated bar exam with a score ranking around the top 10\% of test takers. However, despite these achievements, OpenAI remains cognizant of ChatGPT's limitations~\cite{chatgptlimitation}: ``ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL training, there's currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.''~\cite{chatgptlimitation}

Recent papers have further analyzed ChatGPT's strengths and failures in various domains. \cite{azaria2022chatgpt} and \cite{frieder2023mathematical} explored ChatGPT's mathematical capabilities, while \cite{borji2023categorical} presented a categorical archive of ChatGPT failures, including reasoning, logic, math, factual errors, wit and humor, coding, syntactic structure, spelling, grammar, self-awareness, ethics, and morality. Additionally, Microsoft conducted experiments to assess ChatGPT's abilities in coding and mathematical tasks~\cite{bubeck2023sparks}. As security researchers, we are particularly interested in ChatGPT's potential and limitations in addressing software security challenges. Notably, there are no existing papers studying this specific area. Consequently, our paper aims to provide a case study analyzing ChatGPT's capacity in software security. Unlike previous studies that primarily focused on generative abilities, we emphasize ChatGPT's analysis capabilities.

This paper presents a set of experiments and empirical analyses aimed at unveiling ChatGPT's capabilities in security-oriented program analysis. Our paper experiments focus on 5 problems: code semantic inference, vulnerability analysis, generalization ability in code review, dynamic vulnerability discovery, and assemble code analysis. Our empirical analysis shows that ChatGPT emerges as a promising avenue for security-oriented source code analysis, efficiently learning high-level semantics. Surprisingly, ChatGPT has the ability to perform inter-procedural analysis and infer the high-level semantic of the source code.
Impressively, even at the binary level, ChatGPT exhibits the ability to comprehend low-level semantics, encompassing data flow propagation in assembly code. These remarkable learning capabilities position ChatGPT as a potential asset in security-oriented contexts.

Despite these strengths, it is essential to acknowledge certain limitations. Users and researchers should be aware that ChatGPT's performance may suffer when analyzing complex source code with insufficient information in variable, method, and function names. Instances such as code generated from decompilation~\cite{katz2018using} or non-conventional code naming~\cite{butler2015investigating} might yield reduced accuracy, as ChatGPT's generalization ability is limited to the patterns and examples present in its training data. Additionally, for very specific questions involving implementation-level details, ChatGPT's proposed solutions may possess high-level conceptual correctness but may lack precision in fully addressing the problem. These limitations underscore the need for further investigation and refinement to enhance ChatGPT's performance in such scenarios. As researchers delve deeper into these challenges, they can work towards maximizing the potential of ChatGPT in security-oriented program analysis.

We hope that our findings and analysis will offer valuable insights for future researchers in this domain and contribute to a better understanding of ChatGPT's potential and limitations in software security.

% OpenAI released ``GPT-4 Technical Report~\cite{openai2023gpt4}" which show that while less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. 
% And they has been aware of limitations~\cite{chatgptlimitation}: ``ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL training, there's currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.''~\cite{chatgptlimitation}

% Recently, a few papers have been published to analyze ChatGPT's strength and failures in different areas.
% \cite{azaria2022chatgpt,frieder2023mathematical} analyze ChatGPT's mathematical capabilities of ChatGPT. Specifically, \citeauthor{azaria2022chatgpt} took advantage of ChatGPT's inability to perform complex mathematical computations.
% \cite{borji2023categorical} shows a categorical archive of ChatGPT failures, which include the Reasoning, Logic, Math and Arithmetic, Factual Errors, Wit and Humor, Coding, Syntactic Structure, Spelling, and Grammar, Self Awareness, Ethics and Morality
% Microsoft analyze Chat-GPT's ability in different areas through some experiments~\cite{bubeck2023sparks}.
% Specifically, it analyze many use cases in the popular areas such as: Coding, Mathematical abilities and ect. 

% As a security researcher, we are very interested in the ChatGPT's potential and limitations in solve software security problem. Currently there are not such papers that study this area. Therefore, we aim to provide a case study to analyze the ChatGPT's ability in the software security. Different from the previous study on the Coding which mainly test ChatGPT's generative ability~\cite{bubeck2023sparks}. In this paper, we focus mainly on it analysis ability. 
% Specifically, in this paper we focused on the following two domains: 1) security-oriented source code analysis, security-oriented binary code analysis. 
% We found that ChatGPT have strong abilities in the security-oriented source-code analysis tasks. Therefore, we choose 5 sub-domains: algorithm semantic inference, vulnerabilities analysis, bug fixing, vulnerability discovery, generalization ability in source code analysis. 
% In the binary code analysis, we found that ChatGPT have very limited abilities, therefore, we did not explore too much. 
% We hope our analysis could provide some insights for future researchers.
% We test whether the ChatGPT is able to understand the functionality of a piece of code, whether it is able to found some vulnerabilities in programs, whether it is helpful to fix the vulnerabilities, whether it is able to translate program to another programming language.



