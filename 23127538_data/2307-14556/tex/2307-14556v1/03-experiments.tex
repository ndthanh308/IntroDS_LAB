\section{Design}
\label{design}

\begin{table}[b]
    \centering
    \begin{tabular}{|l||c|c|c|c|c|c|c|c|c|c|}
    \hline
        \textbf{cfg} & k & $d_1$ & $d_2$ & $d_3$ & $d_4$ & $d_5$ & $d_6$ & $d_7$ & $dense_1$ & $dense_2$ \\
    \hline
        \textbf{01} & 3 & 1 & 2 & 4 & 8 & 16 & 32 & 64 & 512  & 256 \\
    \hline
        \textbf{02} & 3 & 1 & 2 & 4 & 8 & 16 & 32 & 64 & 1024 & 512 \\
    \hline
        \textbf{03} & 5 & 1 & 2 & 4 & 8 & 16 & 32 & -- & 512 & 256 \\
    \hline
        \textbf{04} & 5 & 1 & 2 & 4 & 8 & 16 & 32 & -- & 1024 & 512 \\
    \hline
        \textbf{05} & 9 & 1 & 2 & 4 & 8 & 16 & -- & -- & 512 & 256 \\
    \hline 
        \textbf{06} & 9 & 1 & 2 & 4 & 8 & 16 & -- & -- & 1024 & 512 \\
    \hline 
        \textbf{07} &18 & 1 & 2 & 4 & 8 & -- & -- & -- & 512 & 256 \\
    \hline
        \textbf{08} &18 & 1 & 2 & 4 & 8 & -- & -- & -- & 1024 & 512 \\
    \hline
    \end{tabular}
    \caption{The different configurations evaluated. The kernel size $k$ is fixed over all convolutional layers (max. 7) and the dilation rate $d_i$ is adjusted to cover the whole input sequence (max. 250 characters). Furthermore $dense_i$ provides the number of internal units used.}
    \label{exp:tcn_param}
\end{table}



\begin{table*}[t]
    \centering
    \begin{tabular}{|l||c|c|c||c|c|c||c|c|c||c|c|c||c|c|c|c|c|}
    \hline
        \textbf{config} & $k_1$ & $s_1$ & $f_1$ & $k_2$ & $s_2$ & $f_2$ & $k_3$ & $s_3$ & $f_3$ & $k_4$ & $s_4$ & $f_4$ & $dense_1$ & $dense_2$ & $dense_3$ & $dense_4$ \\
    \hline
        \textbf{01} & 8 & 2 & 8 & 4 & 2 & 16 & 3 & 1 & 32 & 3 & 1 & 64 & 128 & 128 & 128 & 64 \\
    \hline
        \textbf{02} & 8 & 2 & 16 & 4 & 2 & 32 & 3 & 1 & 64 & 3 & 1 & 64 & 128 & 128 & 128 & 64 \\
    \hline
        \textbf{03} & 8 & 2 & 16 & 4 & 2 & 32 & 3 & 1 & 64 & 3 & 1 & 64 & 128 & 128 & 128 & 128 \\
    \hline
        \textbf{04} & 8 & 2 & 32 & 4 & 2 & 64 & 3 & 1 & 64 & 3 & 1 & 64 & 256 & 256 & -- & --\\
    \hline
    \end{tabular}
    \caption{Evaluated hyper-parameter configurations for the DDQN agent. The parameters $k_i$, $s_i$, $f_i$ provide the kernel size, stride and filter dimensions of the CNN layer i respectively. $dense_i$ provides the number of internal units of the dense layer i.}
    \label{exp:tbl_parameters}
\end{table*}

\subsection{TCN test case generator}
The training set was created by converting the HTML data into an integer 
sequence where each integer corresponds to a single character.
The TCN test case generator consists of four modules closely aligned
to the structure proposed by Bai et al.\cite{bai2018empirical}. First, the input
module receives an integer sequence that is translated into an n-dimensional
vector space through an embedding lookup. The embedding layer is also trained, and
the higher dimension output vector increases the distance between
different input characters. Therefore, it enables the model to learn more
quickly.

Secondly, the TCN itself utilises a configurable number of residual blocks.
The residual blocks use different kernel sizes and dilation rates
to maximize the number of steps they could look back at. This was important
to make sure that the first character in the sequence still had a potential
influence on the output. For example, when the first characters describe the
opening HTML tag the model needs this information to form the corresponding
closing tag.

Thirdly, two dense layers summarize the whole TCN output. These two layers
use a configurable amount of internal units. Finally, an output layer provides
a probability distribution over all characters. The next character in the sequence
is then predicted by sampling from the probability distribution for the last
step in the output sequence.


\subsection{DDQN agent and environment}
The DDQN setup consists of the DDQN agent itself and the environment. First,
the DDQN agent receives the generated HTML at the most recent time step as
integer sequence and applies an embedding layer. The embedding layer is 
pre-trained from the TCN generator. This enables faster training.

Secondly, convolutional layers are applied to the embedded input sequence.
The number of layers, kernel sizes and stride steps are configurable. The
DDQN agent can use conventional layers because for the agent there is no
restriction of taking future time steps into account when evaluating the
input sequence. (By way of contrast, the TCN has to be restricted to only evaluate
past time steps when predicting the next step in the sequence.)

Thirdly, there are dense layers with a configurable number of layers as well as
units. These layers summarize the information outputted by the convolutional
layers. Finally, a dense output layer provides the Q-values for the
available action. The actions were defined as inserting a HTML tag (one action
per available tag) and an action allowing the TCN generator on its own that
action does not alter the sequence and just continues the sampling from
the TCN generator.



\section{Experiments}
\label{exp}

The experiments consisted of two phases. The first phase involved
the training and evaluation of TCN generator models to find a consistently
performing set of hyper-parameters. The second phase used a DDQN agent
to maximize the code coverage performance of the TCN generator.

The main baseline for comparison was a set of 16,384 HTML tags generated by
PyFuzz2's \cite{sablotny_pyfuzz2} HTML component. The test cases
were created by inserting 128 HTML tags into a basic HTML template.
The resulting test cases were subdivided into six sets with 128 test
cases each. In order to establish the baseline, the test cases were
used as input for Firefox which was instrumented by DynamoRIO's DrCov
\cite{dynamoRIO} to record the executed basic blocks. The basic blocks were uniquely identified by their
starting offset within Firefox 57.0.1 libxul library. The libxul library
contains the full web engine of Firefox and, therefore, the
parts responsible for rendering HTML. Firefox was executed in headless
mode to skip the overhead in run-time induced by starting the graphical
user interface. The collection itself took place on Ubuntu 18.04.

All models were implemented using Tensorflow \cite{tensorflow2015-whitepaper}
in versions 1.16 and 2.3.0 on Ubuntu Server 18.04 with a single NVIDIA CUDA enabled GPU.

\subsection{TCN based test case generator}
The data set for the TCN training and validation was created by PyFuzz2's 
HTML generation component. In total, 409,000 HTML tags were generated, resulting
in a size of 36MB. The TCN embedding layer provided a 256-dimensional output. 
The number of residual blocks varied from four to seven
layers. The generator's output was a 107-dimensional vector with a scalar value 
for each available character.
It was trained and tested in eight different configurations. \Cref{exp:tcn_param} 
provides an overview of all TCN configurations. Over all configurations,
the settings for kernel size and corresponding dilation rate were chosen to
ensure that at the maximum sequence length the final output sill receives
information from the first character in the input sequence. This resulted in a
starting kernel size of three as recommended for a character based model by
Bai et al.\cite{bai2018empirical} and the largest kernel size tested was
set to 18. The maximum input sequence length was set to 250 characters.

% The
% configurations differed in the number of stacked residual blocks, the
% kernel size used in the residual blocks, and the number of units in
% the final dense layers. 

Per configuration, 15 models were trained on three different splits of the
data set. The five different splits were determined randomly but kept constant
for the experiment. During training the validation loss was computed on a validation set
that was not used during training. The validation loss indicates how well the
model performs on inputs that were not encountered during training. 
The model state that achieved the lowest validation loss was used for 
test case generation. Furthermore, early stopping
was applied if five consecutive epochs\footnote{one epoch ends when the training set was seen completely by the model} showed no improvement in validation loss. This allowed to cut down the training time when the model already
reached peak performance.

The aforementioned states with the lowest validation loss were restored
for each model to generate HTML tags for test cases. The starting input
sequence was set to \verb+"<"+ and was used to predict the next character in
the sequence which was concatenated with input sequence and then reused
as new input to the model. This was repeated up to the maximum sequence
length of 250 characters before the input sequence was cut back to the
latest 200 characters. This avoided an additional processing step each
time after the maximum sequence length was reached and therefore increased
test case generation performance. Each model was used to generate 16,384
HTML tags which were placed into 128 test cases with 128 HTML tags each.
The resulting test cases were then executed in Firefox and the
code coverage data was collected.

\subsection{DDQN agent and environment}
The overall implemented environment of the DDQN agent and world is shown in \Cref{exp:RL}. The world
included the evaluation part responsible for executing the test cases and returning
the results. The evaluation part was implemented by provisioning multiple Virtual Machines
(VMs) on an ESXi hypervisor. On these collection VMs, a gRPC network service was running, with
responsibility for receiving the test cases and returning the resulting code
coverage. It executed as the test cases as described above in an instrumented
Firefox instance. The results were returned to a VM with GPU support to perform
the execution and training of the DDQN agent. This central VM also held the experience
replay memory and was connected to a database server used as long-term
storage for the gathered experience to enable offline training and faster hyper-parameter
search. Hyper-parameter search is important because it provides the model with hyper-parameters
which enable the model to perform well. During offline training, the DDQN agent receives the experience
information from the database server directly into the replay memory. This eliminates the
overhead from collecting the code coverage.
Overall, the central VM holds the whole learning environment shown in
\Cref{exp:RL}.

The setup was used to generate and store $2,872,990$ experiences. An experience
contained the state before the DDQN agent action, the state
after the action was performed and the reward. The reward was set to 0 except
when the output size of $12,000$ characters was reached, then the reward was
set to the length of basic blocks discovered by the test cases divided by
the average basic blocks triggered by the underlying TCN generator model.

After the data generation, a hyper-parameter search was conducted. The hyper-parameters
are shown in \Cref{exp:tbl_parameters}. Each configuration was trained
fifteen times, broken down into runs with five different learning rates, each trained
three times. All models were trained on the stored data to enable reproducible
results. The model's performance was evaluated frequently during the training
phase by creating and evaluating four test cases after 20 training steps.
The average code coverage performance of the four test cases was the main indicator
of the model's performance and determined when to store a checkpoint of the model's
state.

The final step was to take the two best performing DDQN agents configurations and
train further 15 models per configuration. The best-performing checkpoint was
then used to generate 128 test cases with a maximum length of $12,000$ characters.
The test cases were then executed to gather the code coverage data and compare the
agent's performance with the underlying TCN generator, and the baseline itself.

% Figure environment removed
