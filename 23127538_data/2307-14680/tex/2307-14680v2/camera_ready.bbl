\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{bai2018empirical}
Bai, S., Kolter, J.Z., Koltun, V.: An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv:1803.01271  (2018)

\bibitem{box2015time}
Box, G.E., Jenkins, G.M., Reinsel, G.C., Ljung, G.M.: Time series analysis: forecasting and control. John Wiley \& Sons (2015)

\bibitem{cao2020spectral}
Cao, D., Wang, Y., Duan, J., Zhang, C., Zhu, X., Huang, C., Tong, Y., Xu, B., Bai, J., Tong, J., et~al.: Spectral temporal graph neural network for multivariate time-series forecasting. Advances in neural information processing systems  \textbf{33},  17766--17778 (2020)

\bibitem{chauhan2015anomaly}
Chauhan, S., Vig, L.: Anomaly detection in ecg time signals via deep long short-term memory networks. In: 2015 IEEE international conference on data science and advanced analytics (DSAA). pp.~1--7. IEEE (2015)

\bibitem{cho2014learning}
Cho, K., Van~Merri{\"e}nboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y.: Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078  (2014)

\bibitem{ding2015deep}
Ding, X., Zhang, Y., Liu, T., Duan, J.: Deep learning for event-driven stock prediction. In: Twenty-fourth international joint conference on artificial intelligence (2015)

\bibitem{donner2010recurrence}
Donner, R.V., Zou, Y., Donges, J.F., Marwan, N., Kurths, J.: Recurrence networksâ€”a novel paradigm for nonlinear time series analysis. New Journal of Physics  \textbf{12}(3),  033025 (2010)

\bibitem{gilmer2017neural}
Gilmer, J., Schoenholz, S.S., Riley, P.F., Vinyals, O., Dahl, G.E.: Neural message passing for quantum chemistry. In: International conference on machine learning. pp. 1263--1272. PMLR (2017)

\bibitem{gligorijevic2021structure}
Gligorijevi{\'c}, V., Renfrew, P.D., Kosciolek, T., Leman, J.K., Berenberg, D., Vatanen, T., Chandler, C., Taylor, B.C., Fisk, I.M., Vlamakis, H., et~al.: Structure-based protein function prediction using graph convolutional networks. Nature communications  \textbf{12}(1), ~3168 (2021)

\bibitem{hamilton2020time}
Hamilton, J.D.: Time series analysis. Princeton university press (2020)

\bibitem{hamilton2017inductive}
Hamilton, W., Ying, Z., Leskovec, J.: Inductive representation learning on large graphs. Advances in neural information processing systems  \textbf{30} (2017)

\bibitem{hochreiter1997long}
Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation  \textbf{9}(8),  1735--1780 (1997)

\bibitem{jang2016categorical}
Jang, E., Gu, S., Poole, B.: Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144  (2016)

\bibitem{kearnes2016molecular}
Kearnes, S., McCloskey, K., Berndl, M., Pande, V., Riley, P.: Molecular graph convolutions: moving beyond fingerprints. Journal of computer-aided molecular design  \textbf{30},  595--608 (2016)

\bibitem{kipf2018neural}
Kipf, T., Fetaya, E., Wang, K.C., Welling, M., Zemel, R.: Neural relational inference for interacting systems. In: International conference on machine learning. pp. 2688--2697. PMLR (2018)

\bibitem{kosma2022time}
Kosma, C., Nikolentzos, G., Xu, N., Vazirgiannis, M.: Time series forecasting models copy the past: How to mitigate. In: Artificial Neural Networks and Machine Learning--ICANN 2022: 31st International Conference on Artificial Neural Networks, Bristol, UK, September 6--9, 2022, Proceedings, Part I. pp. 366--378. Springer (2022)

\bibitem{lacasa2008time}
Lacasa, L., Luque, B., Ballesteros, F., Luque, J., Nuno, J.C.: From time series to complex networks: The visibility graph. Proceedings of the National Academy of Sciences  \textbf{105}(13),  4972--4975 (2008)

\bibitem{lai2018modeling}
Lai, G., Chang, W.C., Yang, Y., Liu, H.: Modeling long-and short-term temporal patterns with deep neural networks. In: The 41st international ACM SIGIR conference on research \& development in information retrieval. pp. 95--104 (2018)

\bibitem{le2022deep}
Le~Guen, V., Thome, N.: Deep time series forecasting with shape and temporal criteria. IEEE Transactions on Pattern Analysis and Machine Intelligence  \textbf{45}(1),  342--355 (2022)

\bibitem{lecun1998gradient}
LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE  \textbf{86}(11),  2278--2324 (1998)

\bibitem{li2017diffusion}
Li, Y., Yu, R., Shahabi, C., Liu, Y.: Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. arXiv preprint arXiv:1707.01926  (2017)

\bibitem{lim2021time}
Lim, B., Zohren, S.: Time-series forecasting with deep learning: a survey. Philosophical Transactions of the Royal Society A  \textbf{379}(2194),  20200209 (2021)

\bibitem{lin2013network}
Lin, M., Chen, Q., Yan, S.: Network in network. arXiv preprint arXiv:1312.4400  (2013)

\bibitem{oreshkin2019n}
Oreshkin, B.N., Carpov, D., Chapados, N., Bengio, Y.: N-beats: Neural basis expansion analysis for interpretable time series forecasting. arXiv preprint arXiv:1905.10437  (2019)

\bibitem{rousseau2013graph}
Rousseau, F., Vazirgiannis, M.: Graph-of-word and tw-idf: new approach to ad hoc ir. In: Proceedings of the 22nd ACM international conference on Information \& Knowledge Management. pp. 59--68 (2013)

\bibitem{rubanova2019latent}
Rubanova, Y., Chen, R.T., Duvenaud, D.K.: Latent ordinary differential equations for irregularly-sampled time series. Advances in neural information processing systems  \textbf{32} (2019)

\bibitem{rumelhart1986learning}
Rumelhart, D.E., Hinton, G.E., Williams, R.J.: Learning representations by back-propagating errors. nature  \textbf{323}(6088),  533--536 (1986)

\bibitem{seo2018structured}
Seo, Y., Defferrard, M., Vandergheynst, P., Bresson, X.: Structured sequence modeling with graph convolutional recurrent networks. In: Neural Information Processing: 25th International Conference, ICONIP 2018, Siem Reap, Cambodia, December 13-16, 2018, Proceedings, Part I 25. pp. 362--373. Springer (2018)

\bibitem{shang2021discrete}
Shang, C., Chen, J., Bi, J.: Discrete graph structure learning for forecasting multiple time series. arXiv preprint arXiv:2101.06861  (2021)

\bibitem{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, {\L}., Polosukhin, I.: Attention is all you need. Advances in neural information processing systems  \textbf{30} (2017)

\bibitem{wu2021autoformer}
Wu, H., Xu, J., Wang, J., Long, M.: Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting. Advances in Neural Information Processing Systems  \textbf{34},  22419--22430 (2021)

\bibitem{wu2020connecting}
Wu, Z., Pan, S., Long, G., Jiang, J., Chang, X., Zhang, C.: Connecting the dots: Multivariate time series forecasting with graph neural networks. In: Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \& data mining. pp. 753--763 (2020)

\bibitem{yu2017spatio}
Yu, B., Yin, H., Zhu, Z.: Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. arXiv preprint arXiv:1709.04875  (2017)

\bibitem{zhao2019t}
Zhao, L., Song, Y., Zhang, C., Liu, Y., Wang, P., Lin, T., Deng, M., Li, H.: T-gcn: A temporal graph convolutional network for traffic prediction. IEEE transactions on intelligent transportation systems  \textbf{21}(9),  3848--3858 (2019)

\bibitem{zhou2021informer}
Zhou, H., Zhang, S., Peng, J., Zhang, S., Li, J., Xiong, H., Zhang, W.: Informer: Beyond efficient transformer for long sequence time-series forecasting. In: Proceedings of the AAAI conference on artificial intelligence. vol.~35, pp. 11106--11115 (2021)

\end{thebibliography}
