\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aich et~al.(2022)Aich, Ta, Gupta, Song, Krishnamurthy, Asif, and Roy-Chowdhury]{aich2022gama}
Abhishek Aich, Calvin-Khang Ta, Akash Gupta, Chengyu Song, Srikanth Krishnamurthy, Salman Asif, and Amit Roy-Chowdhury.
\newblock Gama: Generative adversarial multi-object scene attacks.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 36914--36930, 2022.

\bibitem[Bagdasaryan et~al.(2023)Bagdasaryan, Hsieh, Nassi, and Shmatikov]{bagdasaryan2023ab}
Eugene Bagdasaryan, Tsung-Yin Hsieh, Ben Nassi, and Vitaly Shmatikov.
\newblock (ab) using images and sounds for indirect instruction injection in multi-modal llms.
\newblock \emph{arXiv preprint arXiv:2307.10490}, 2023.

\bibitem[Bailey et~al.(2023)Bailey, Ong, Russell, and Emmons]{bailey2023image}
Luke Bailey, Euan Ong, Stuart Russell, and Scott Emmons.
\newblock Image hijacking: Adversarial images can control generative models at runtime.
\newblock \emph{arXiv preprint arXiv:2309.00236}, 2023.

\bibitem[Bard()]{GoogleBard}
Google Bard.
\newblock Whatâ€™s ahead for bard: More global, more visual, more integrated.
\newblock \url{https://blog.google/technology/ai/google-bard-updates-io-2023/}.

\bibitem[Bing()]{MicrosoftBing}
Microsoft Bing.
\newblock Bing chat enterprise announced, multimodal visual search rolling out to bing chat.
\newblock \url{https://blogs.bing.com/search/july-2023/Bing-Chat-Enterprise-announced,-multimodal-Visual-Search-rolling-out-to-Bing-Chat}.

\bibitem[Bubeck et~al.(2023)Bubeck, Chandrasekaran, Eldan, Gehrke, Horvitz, Kamar, Lee, Lee, Li, Lundberg, et~al.]{bubeck2023sparks}
S{\'e}bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin~Tat Lee, Yuanzhi Li, Scott Lundberg, et~al.
\newblock Sparks of artificial general intelligence: Early experiments with gpt-4.
\newblock \emph{arXiv preprint arXiv:2303.12712}, 2023.

\bibitem[Carlini et~al.(2021)Carlini, Tramer, Wallace, Jagielski, Herbert-Voss, Lee, Roberts, Brown, Song, Erlingsson, et~al.]{carlini2021extracting}
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, et~al.
\newblock Extracting training data from large language models.
\newblock In \emph{30th USENIX Security Symposium (USENIX Security 21)}, pp.\  2633--2650, 2021.

\bibitem[Carlini et~al.(2023)Carlini, Nasr, Choquette-Choo, Jagielski, Gao, Awadalla, Koh, Ippolito, Lee, Tramer, et~al.]{carlini2023aligned}
Nicholas Carlini, Milad Nasr, Christopher~A Choquette-Choo, Matthew Jagielski, Irena Gao, Anas Awadalla, Pang~Wei Koh, Daphne Ippolito, Katherine Lee, Florian Tramer, et~al.
\newblock Are aligned neural networks adversarially aligned?
\newblock \emph{arXiv preprint arXiv:2306.15447}, 2023.

\bibitem[Gao et~al.(2023)Gao, Han, Zhang, Lin, Geng, Zhou, Zhang, Lu, He, Yue, et~al.]{gao2023llama}
Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie Geng, Aojun Zhou, Wei Zhang, Pan Lu, Conghui He, Xiangyu Yue, et~al.
\newblock Llama-adapter v2: Parameter-efficient visual instruction model.
\newblock \emph{arXiv preprint arXiv:2304.15010}, 2023.

\bibitem[Goh et~al.(2021)Goh, Cammarata, Voss, Carter, Petrov, Schubert, Radford, and Olah]{goh2021multimodal}
Gabriel Goh, Nick Cammarata, Chelsea Voss, Shan Carter, Michael Petrov, Ludwig Schubert, Alec Radford, and Chris Olah.
\newblock Multimodal neurons in artificial neural networks.
\newblock \emph{Distill}, 6\penalty0 (3):\penalty0 e30, 2021.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and Szegedy]{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Greshake et~al.(2023)Greshake, Abdelnabi, Mishra, Endres, Holz, and Fritz]{greshake2023more}
Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario Fritz.
\newblock More than you've asked for: A comprehensive analysis of novel prompt injection threats to application-integrated large language models.
\newblock \emph{arXiv preprint arXiv:2302.12173}, 2023.

\bibitem[Hanu \& {Unitary team}(2020)Hanu and {Unitary team}]{Detoxify}
Laura Hanu and {Unitary team}.
\newblock Detoxify.
\newblock Github. https://github.com/unitaryai/detoxify, 2020.

\bibitem[HuggingFaceCLIP()]{HuggingFaceCLIP}
HuggingFaceCLIP.
\newblock \url{https://huggingface.co/openai/clip-vit-large-patch14}.

\bibitem[Kaur et~al.(2022)Kaur, Uslu, Rittichier, and Durresi]{kaur2022trustworthy}
Davinder Kaur, Suleyman Uslu, Kaley~J Rittichier, and Arjan Durresi.
\newblock Trustworthy artificial intelligence: a review.
\newblock \emph{ACM Computing Surveys (CSUR)}, 55\penalty0 (2):\penalty0 1--38, 2022.

\bibitem[Kenton \& Toutanova(2019)Kenton and Toutanova]{kenton2019bert}
Jacob Devlin Ming-Wei~Chang Kenton and Lee~Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock In \emph{Proceedings of NAACL-HLT}, pp.\  4171--4186, 2019.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kurakin et~al.(2016)Kurakin, Goodfellow, and Bengio]{kurakin2016adversarial}
Alexey Kurakin, Ian~J Goodfellow, and Samy Bengio.
\newblock Adversarial machine learning at scale.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Li et~al.(2022)Li, Li, Xiong, and Hoi]{li2022blip}
Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
\newblock Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation.
\newblock In \emph{International Conference on Machine Learning}, pp.\  12888--12900. PMLR, 2022.

\bibitem[Liang et~al.(2022)Liang, Zhang, Kwon, Yeung, and Zou]{liang2022mindGap}
Victor~Weixin Liang, Yuhui Zhang, Yongchan Kwon, Serena Yeung, and James~Y Zou.
\newblock Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 17612--17625, 2022.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Li, Wu, and Lee]{liu2023visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock \emph{arXiv preprint arXiv:2304.08485}, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Deng, Li, Wang, Zhang, Liu, Wang, Zheng, and Liu]{liu2023prompt}
Yi~Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, and Yang Liu.
\newblock Prompt injection attack against llm-integrated applications.
\newblock \emph{arXiv preprint arXiv:2306.05499}, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2023{\natexlab{c}})Liu, Deng, Xu, Li, Zheng, Zhang, Zhao, Zhang, and Liu]{liu2023jbViaPrompt}
Yi~Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying Zhang, Lida Zhao, Tianwei Zhang, and Yang Liu.
\newblock Jailbreaking chatgpt via prompt engineering: An empirical study.
\newblock \emph{arXiv preprint arXiv:2305.13860}, 2023{\natexlab{c}}.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis, Zettlemoyer, and Stoyanov]{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Markov et~al.(2023)Markov, Zhang, Agarwal, Nekoul, Lee, Adler, Jiang, and Weng]{markov2023holistic}
Todor Markov, Chong Zhang, Sandhini Agarwal, Florentine~Eloundou Nekoul, Theodore Lee, Steven Adler, Angela Jiang, and Lilian Weng.
\newblock A holistic approach to undesired content detection in the real world.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pp.\  15009--15018, 2023.

\bibitem[McKenzie et~al.(2023)McKenzie, Lyzhov, Pieler, Parrish, Mueller, Prabhu, McLean, Kirtland, Ross, Liu, et~al.]{mckenzie2023InverseScaling}
Ian~R McKenzie, Alexander Lyzhov, Michael Pieler, Alicia Parrish, Aaron Mueller, Ameya Prabhu, Euan McLean, Aaron Kirtland, Alexis Ross, Alisa Liu, et~al.
\newblock Inverse scaling: When bigger isn't better.
\newblock \emph{arXiv preprint arXiv:2306.09479}, 2023.

\bibitem[ModerationOpenAI(2023)]{ModerationOpenAI}
OpenAI ModerationOpenAI.
\newblock Moderation endpoint openai.
\newblock \url{https://platform.openai.com/docs/guides/moderation/overview}, 2023.

\bibitem[Moosavi-Dezfooli et~al.(2016)Moosavi-Dezfooli, Fawzi, and Frossard]{moosavi2016deepfool}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  2574--2582, 2016.

\bibitem[Noever \& Noever(2021)Noever and Noever]{noever2021reading}
David~A Noever and Samantha E~Miller Noever.
\newblock Reading isn't believing: Adversarial attacks on multi-modal neurons.
\newblock \emph{arXiv preprint arXiv:2103.10480}, 2021.

\bibitem[OpenAI(2023)]{OpenAI2023GPT4TR}
OpenAI.
\newblock Gpt-4 technical report.
\newblock \emph{ArXiv}, abs/2303.08774, 2023.

\bibitem[Perez \& Ribeiro(2022)Perez and Ribeiro]{perez2022ignore}
F{\'a}bio Perez and Ian Ribeiro.
\newblock Ignore previous prompt: Attack techniques for language models.
\newblock In \emph{NeurIPS ML Safety Workshop}, 2022.

\bibitem[Poursaeed et~al.(2018)Poursaeed, Katsman, Gao, and Belongie]{poursaeed2018generative}
Omid Poursaeed, Isay Katsman, Bicheng Gao, and Serge Belongie.
\newblock Generative adversarial perturbations.
\newblock In \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  4422--4431. IEEE Computer Society, 2018.

\bibitem[Qi et~al.(2023)Qi, Huang, Panda, Henderson, Wang, and Mittal]{qi2023visualAdv}
Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Peter Henderson, Mengdi Wang, and Prateek Mittal.
\newblock Visual adversarial examples jailbreak aligned large language models, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pp.\  8748--8763. PMLR, 2021.

\bibitem[Schlarmann \& Hein(2023)Schlarmann and Hein]{schlarmann2023adversarial}
Christian Schlarmann and Matthias Hein.
\newblock On the adversarial robustness of multi-modal foundation models.
\newblock \emph{arXiv preprint arXiv:2308.10741}, 2023.

\bibitem[Shen et~al.(2023)Shen, Chen, Backes, Shen, and Zhang]{shen2023anything}
Xinyue Shen, Zeyuan Chen, Michael Backes, Yun Shen, and Yang Zhang.
\newblock " do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models.
\newblock \emph{arXiv preprint arXiv:2308.03825}, 2023.

\bibitem[Shin et~al.(2020)Shin, Razeghi, Logan~IV, Wallace, and Singh]{shin2020autoprompt}
Taylor Shin, Yasaman Razeghi, Robert~L Logan~IV, Eric Wallace, and Sameer Singh.
\newblock Autoprompt: Eliciting knowledge from language models with automatically generated prompts.
\newblock \emph{arXiv preprint arXiv:2010.15980}, 2020.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan, Goodfellow, and Fergus]{szegedy2014intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{2nd International Conference on Learning Representations, ICLR 2014}, 2014.

\bibitem[Wallace et~al.(2019)Wallace, Feng, Kandpal, Gardner, and Singh]{wallace2019universal}
Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh.
\newblock Universal adversarial triggers for attacking and analyzing nlp.
\newblock \emph{arXiv preprint arXiv:1908.07125}, 2019.

\bibitem[Wei et~al.(2023)Wei, Haghtalab, and Steinhardt]{wei2023jailbroken}
Alexander Wei, Nika Haghtalab, and Jacob Steinhardt.
\newblock Jailbroken: How does llm safety training fail?
\newblock \emph{arXiv preprint arXiv:2307.02483}, 2023.

\bibitem[Zhang et~al.(2022)Zhang, Li, Chen, Song, Gao, He, et~al.]{zhang2022beyond}
Qilong Zhang, Xiaodan Li, YueFeng Chen, Jingkuan Song, Lianli Gao, Yuan He, et~al.
\newblock Beyond imagenet attack: Towards crafting adversarial examples for black-box domains.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Zhao et~al.(2023)Zhao, Pang, Du, Yang, Li, Cheung, and Lin]{zhao2023evaluating}
Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Chongxuan Li, Ngai-Man Cheung, and Min Lin.
\newblock On evaluating adversarial robustness of large vision-language models.
\newblock \emph{arXiv preprint arXiv:2305.16934}, 2023.

\bibitem[Zhu et~al.(2023)Zhu, Chen, Shen, Li, and Elhoseiny]{zhu2023minigpt}
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny.
\newblock Minigpt-4: Enhancing vision-language understanding with advanced large language models.
\newblock \emph{arXiv preprint arXiv:2304.10592}, 2023.

\bibitem[Zou et~al.(2023)Zou, Wang, Kolter, and Fredrikson]{zou2023universal}
Andy Zou, Zifan Wang, J~Zico Kolter, and Matt Fredrikson.
\newblock Universal and transferable adversarial attacks on aligned language models.
\newblock \emph{arXiv preprint arXiv:2307.15043}, 2023.

\end{thebibliography}
