\begin{center}
    {\Large\bf Supplementary Materials} 
\end{center}

\section{Proof for Lemma 1}
\mylemma*

\begin{proof}
First, consider the scenario where channel pairs exhibit consistent importance ranking, specifically, either $x_i>x_j \wedge y_i>y_j$ or $x_i<x_j \wedge y_i<y_j$. In the case where $x_i > x_j \wedge y_i > y_j$, we obtain:
\begin{align}
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(x_i-x_j)}-e^{-\alpha(x_i-x_j)}}{e^{\alpha(x_i-x_j)}+e^{-\alpha(x_i-x_j)}} = 1,
\quad
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(y_i-y_j)}-e^{-\alpha(y_i-y_j)}}{e^{\alpha(y_i-y_j)}+e^{-\alpha(y_i-y_j)}} = 1. 
\nonumber 
\end{align}
On the other hand, if $x_i < x_j \wedge y_i < y_j$, we have:
\begin{align}
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(x_i-x_j)}-e^{-\alpha(x_i-x_j)}}{e^{\alpha(x_i-x_j)}+e^{-\alpha(x_i-x_j)}} = -1,
\quad
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(y_i-y_j)}-e^{-\alpha(y_i-y_j)}}{e^{\alpha(y_i-y_j)}+e^{-\alpha(y_i-y_j)}} = -1.
\nonumber 
\end{align}
Hence, when $x_i > x_j \wedge y_i > y_j$ or $x_i < x_j \wedge y_i < y_j$, the following conclusion holds:
\begin{align}
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(x_i-x_j)}-e^{-\alpha(x_i-x_j)}}{e^{\alpha(x_i-x_j)}+e^{-\alpha(x_i-x_j)}}\frac{e^{\alpha(y_i-y_j)}-e^{-\alpha(y_i-y_j)}}{e^{\alpha(y_i-y_j)}+e^{-\alpha(y_i-y_j)}} = 1.
\label{proof_con}
\end{align}
Second, consider the scenario where channel pairs exhibit inconsistent importance ranking, that is, either $x_i>x_j \wedge y_i<y_j$ or $x_i<x_j \wedge y_i>y_j$. In the case where $x_i>x_j \wedge y_i<y_j$, we obtain:
\begin{align}
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(x_i-x_j)}-e^{-\alpha(x_i-x_j)}}{e^{\alpha(x_i-x_j)}+e^{-\alpha(x_i-x_j)}} = 1,
\quad
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(y_i-y_j)}-e^{-\alpha(y_i-y_j)}}{e^{\alpha(y_i-y_j)}+e^{-\alpha(y_i-y_j)}} = -1.
\nonumber 
\end{align}
On the other hand, if $x_i<x_j \wedge y_i>y_j$, we have:
\begin{align}
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(x_i-x_j)}-e^{-\alpha(x_i-x_j)}}{e^{\alpha(x_i-x_j)}+e^{-\alpha(x_i-x_j)}} = -1,
\quad
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(y_i-y_j)}-e^{-\alpha(y_i-y_j)}}{e^{\alpha(y_i-y_j)}+e^{-\alpha(y_i-y_j)}} = 1.
\nonumber 
\end{align}
Hence, when $x_i > x_j \wedge y_i < y_j$ or $x_i < x_j \wedge y_i > y_j$, the following conclusion holds:
\begin{align}
\lim_{\alpha  \to +\infty } \frac{e^{\alpha(x_i-x_j)}-e^{-\alpha(x_i-x_j)}}{e^{\alpha(x_i-x_j)}+e^{-\alpha(x_i-x_j)}}\frac{e^{\alpha(y_i-y_j)}-e^{-\alpha(y_i-y_j)}}{e^{\alpha(y_i-y_j)}+e^{-\alpha(y_i-y_j)}} = -1.
\label{proof_discon}
\end{align}
When considering all channel pairs, combining Eq. \eqref{proof_con} and Eq. \eqref{proof_discon}, it is evident that:
\begin{align}
\lim_{\alpha  \to +\infty }\Tilde{\tau}_\alpha(\bx,\by) &=\lim_{\alpha  \to +\infty }\frac{1}{N_0} \sum_{i=2}^{n}\sum_{j=1}^{i-1}\frac{e^{\alpha(x_i-x_j)}-e^{-\alpha(x_i-x_j)}}{e^{\alpha(x_i-x_j)}+e^{-\alpha(x_i-x_j)}} \frac{e^{\alpha(y_i-y_j)}-e^{-\alpha(y_i-y_j)}}{e^{\alpha(y_i-y_j)}+e^{-\alpha(y_i-y_j)}}\nonumber \\
&=\frac{N_{\text{con}}-N_{\text{dis}}}{N_0}\nonumber \\
&=\tau (\bx, \by),
\nonumber 
\end{align}
where $N_{\text{con}}$ represents the total count of channel pairs with consistent importance ranking, $N_{\text{dis}}$ represents the count of channel pairs with inconsistent importance ranking.
\end{proof}

% Figure environment removed

% Figure environment removed

\section{Visual Analysis}
Further visualization analysis is demonstrated in Figure \ref{fig:visual1}. Specifically, we employ Kendall's Rank Correlation and cosine similarity to visualize the feature maps of the query samples. 
By computing the semantic similarity between the class prototype and each local feature of the query samples, the regions wherein the salient targets are located on the feature maps are illustrated. 
Hence, we can observe whether the significant features in the query samples are accurately detected. It is evident that the utilization of Kendall's Rank Correlation results in a more precise localization of the distinctive regions within the query sample. 

Furthermore, we conduct in-depth visual experiments involving channel ablation. 
We mask the channels with values greater than $H_0$ in the features of both the class prototype and query sample, as described in the channel-wise ablation experiments in section 5.4, to gain a deeper understanding of the role of small-valued channels in few-shot learning.
The experimental results are shown in Figure \ref{fig:visual2}, from which we can observe that Kendall's Rank Correlation captures the discriminative features in the query sample when only utilizing the small-valued channels. 
In contrast, cosine similarity ignores these critical features, resulting in an inability to correctly locate salient regions when all channels are used. 
Therefore, a crucial conclusion can be drawn that the small-valued channels that occupy the majority of the features indeed play a vital role in few-shot learning. 
This also explicitly demonstrates that the enhancement of few-shot learning performance by Kendall's Rank Correlation is essentially due to its ability to fully exploit the small-valued channels in features.





    
