============================================================================ 
SIGDIAL 2023 Reviews for Submission #19
============================================================================ 

Title: Who says what when? Why timing is mission-critical for conversational speech recognition and dialogue systems
Authors: Andreas Liesenfeld, Alianda Lopez and Mark Dingemanse
============================================================================
                            META-REVIEW
============================================================================ 

Comments: The paper presents case studies, metrics of word error rates in multiple languages, and analyzes the types of words dropped during recognition. It also discusses the impact of ASR limitations on dialogue acts. The strengths include meaningful contributions, clear writing, and empirical updates. Weaknesses lie in potential lack of novelty and unquantified factors like latency. Suggestions include additional information in figures, clarification of datasets used, and analysis of human-machine conversational recordings. Reviewers agree this is a solid paper.

============================================================================
                            REVIEWER #1
============================================================================

Summary and Contributions
---------------------------------------------------------------------------
Summary: The paper evaluates the mulitlingual and conversational capabilities of several commecial ASR engines. The evaluation is performed at three levels: word error rate and overlaps, short utterances and conversational words, and dialog flow. Results and recommendation are worthy for the research community.

Contribution 1:  study of the limitation of the commercial ASR for conversational systems

Contribution 2: evidences and arguments towards the need of good timing for conversational systems

Contribution 3:
---------------------------------------------------------------------------


Strengths
---------------------------------------------------------------------------
Strength argument 1: the paper presents 3 interesting case studies of how ASR and diarization affect in conversational systems. 

Strength argument 2: Adress the importance of timing 

Strength argument 3: Interesting discussion section over the findings in the research including some possible objections and limitations of the study

Strength argument 4:
---------------------------------------------------------------------------


Weaknesses
---------------------------------------------------------------------------
Some of the possible weakness of the paper are answered by the authors in the subsections of objections and limitations.

Weakness argument 1: 

Weakness argument 2:

Weakness argument 3:

Weakness argument 4:
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
            Overall Recommendation (1-5): 4


============================================================================
                            REVIEWER #2
============================================================================

Summary and Contributions
---------------------------------------------------------------------------
Summary: This paper evaluates a handful of 2023 era commercial speech
recognizers for their ability to handle natural interactive spoken
dialogue data, including in particular the presence of overlapping
speech.  The paper argues that focusing only on WER on "clean speech"
tends to mask a number of important factors in achieving more natural
interactive capabilities in dialogue systems.

Contribution 1: The paper provides metrics of WER in six languages for
five 2023 era commercial speech recognizers evaluated on natural
interactive speech data, including overlapping speech.  The results
show that the commonly referenced WERs of around 5% are not even close
to achievable with this data.  It also shows that WER in five
non-English languages are significantly worse than in English.  None
of the ASRs support overlapping speech at all, resulting in about 15%
of speech being simply lost.  All these numbers are useful to have in
print.

Contribution 2: The paper analyzes the types of words that are dropped
as consisting mostly of interjections, function words, and discourse
markers.

Contribution 3: The paper highlights that the distribution and
sequence of recognized dialogue acts is generally altered because of
the limitations of current ASRs in their ability to handle natural
speech, especially with its frequent overlaps.
---------------------------------------------------------------------------


Strengths
---------------------------------------------------------------------------
Strength argument 1: The paper makes several meaningful contributions 
as outlined above. 

Strength argument 2: The paper is generally well-written and is often
admirably clear.
---------------------------------------------------------------------------


Weaknesses
---------------------------------------------------------------------------
Weakness argument 1: The writing of the submission sometimes suggests
a lack of understanding that many of these issues have been well
understood to numerous researchers who have been working for many
years on turn-taking, on incremental dialogue systems, on dialogue act
segmentation, and on other aspects of achieving more fluid interactive
capabilities (e.g. backchannels).  All of these are well understood to
researchers and practitioners in this area: the frequent occurrence of
overlapping speech (which has been well studied), the tendency for
ASRs to drop many short utterances or initial words such as those in
Figure 3, and the frequent situation of NLUs failing to recognize all
the appropriate dialogue acts as a result of this.

In particular, the contribution of this paper is *not* to show for the
first time that timing matters or that overlapping speech matters in
dialogue, as these have been well understood by many researchers for a
very long time.  Any lingo suggesting that this is the contribution
here should be toned down.  I interpret the value of this paper as
providing an empirical update on the state of these issues in 2023.

Weakness argument 2: There are other factors, not quantified here,
that are also crucial to achieving fluid interaction.  In particular,
the latency of receiving results from these commercial ASRs is hugely
important.  Even if these ASRs could support overlapping speech, and
could do so at 5% WER (which as you show they currently cannot), if a
system cannot reliably get those results until a second or two has
passed, the system will not be able to react quickly enough for fluid
interaction.
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
            Overall Recommendation (1-5): 4

Additional Comments (Optional)
---------------------------------------------------------------------------
I suggest adding the percentage of each dialogue act type in the gold
annotations to Figure 4 or the accompanying text.  This will help
readers more fully understand the importance of the
under/over-representation of these "frequent" dialogue act types.

If you happened to collect latency data on the commercial ASRs
(i.e. timestamps that allow you to quantify how long it takes to send
them audio and receive results back), that would be a useful addition.
---------------------------------------------------------------------------



============================================================================
                            REVIEWER #3
============================================================================

Summary and Contributions
---------------------------------------------------------------------------
Summary: A fantastic position paper analyzing speech recognition quality (beyond what is said and also when things are said), and its impact on conversational applications, using 6 off-the-shelf speech recognizers, using conversational data from 6 languages.

Contribution 1: The paper shows that the speech recognition word error rates for conversational speech could be much higher than what is being reported on commonly used datasets, with increasing WERs for non-English data.

Contribution 2: The paper also shows that overlaps are frequent across languages for conversational speech, and the current ASR systems fall short of detecting them and recognizing both sides of the conversations during overlaps. An analysis across different types of words is also presented.

Contribution 3: Finally, the paper analyzes the impact of these errors on the quality of conversational systems, mainly for the task of dialogue act tagging.
---------------------------------------------------------------------------


Strengths
---------------------------------------------------------------------------
Strength argument 1: The paper presents a fantastic analysis and raises awareness in the community towards remaining issues for using speech recognizers for conversational applications.

Strength argument 2:

Strength argument 3:

Strength argument 4:
---------------------------------------------------------------------------


Weaknesses
---------------------------------------------------------------------------
Weakness argument 1: One question that remains in my mind is the degree of overlaps in human-machine conversational systems. As I understand, the paper mainly studies human-human conversational data. Although we assume and hope that machines will be equivalent conversational partners to humans, in many cases, humans may treat machines differently, with fewer overlaps. It would be interesting and useful to include an analysis of human-machine conversational recordings as well. That said, I think this paper would be a great contribution to SigDial, even without such an analysis.

Weakness argument 2:

Weakness argument 3:

Weakness argument 4:
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
            Overall Recommendation (1-5): 5

Additional Comments (Optional)
---------------------------------------------------------------------------
I think some of the figures are harder to interpret, and it would help to include additional information, either in text or in captions to better explain them For example, I had a hard time following Figure 3C.

It would also help to specify what datasets were used in this analysis. I checked the code base, it seems there is some useful information there, but it would be best to make this paper stand-alone, at least regarding the data.
---------------------------------------------------------------------------