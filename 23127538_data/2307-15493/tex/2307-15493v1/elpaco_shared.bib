
@inproceedings{aylett_pilot_2023,
	address = {New York, NY, USA},
	series = {{CUI} '23},
	title = {A {Pilot} {Evaluation} of a {Conversational} {Listener} for {Conversational} {User} {Interfaces}},
	isbn = {9798400700149},
	url = {https://dl.acm.org/doi/10.1145/3571884.3605871},
	doi = {10.1145/3571884.3605871},
	abstract = {Current spoken conversational user interfaces (CUIs) are predominantly implemented using a sequential, utterance based, two-party, speak-wait/speak-wait approach. Human-human conversation 1) is not sequential, with overlap, interruption and back channels; 2) processes utterances before they are complete and 3) are often multi-party. As part of Honda Research Institute’s Haru project a light weight word spotting speech recognition system - A conversational listener - was implemented to allow very fast turn-taking in simple voice interaction conditions. In this paper, we present a pilot evaluation of the conversational listener in a script follower context (which allows a robot to act out a dialog with a user). We compare a disembodied version of the system with expressive synthesis to Alexa with and without fast turn-taking. Qualitative results indicate that users were sensitive to turn-taking delay and characterful speech synthesis.},
	urldate = {2023-07-28},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Aylett, Matthew Peter and Carmantini, Andrea and Pidcock, Christoper J and Nichols, Eric and Gomez, Randy},
	month = jul,
	year = {2023},
	pages = {1--6},
}

@inproceedings{addlesee_understanding_2023,
	address = {New York, NY, USA},
	series = {{CUI} '23},
	title = {Understanding and {Answering} {Incomplete} {Questions}},
	isbn = {9798400700149},
	url = {https://dl.acm.org/doi/10.1145/3571884.3597133},
	doi = {10.1145/3571884.3597133},
	abstract = {Voice assistants interrupt people when they pause mid-question, a frustrating interaction that requires the full repetition of the entire question again. This impacts all users, but particularly people with cognitive impairments. In human-human conversation, these situations are recovered naturally as people understand the words that were uttered. In this paper we build answer pipelines which parse incomplete questions and repair them following human recovery strategies. We evaluated these pipelines on our new corpus, SLUICE. It contains 21,000 interrupted questions, from LC-QuAD 2.0 and QALD-9-plus, paired with their underspecified SPARQL queries. Compared to a system that is given the full question, our best partial understanding pipeline answered only 0.77\% fewer questions. Results show that our pipeline correctly identifies what information is required to provide an answer but is not yet provided by the incomplete question. It also accurately identifies where that missing information belongs in the semantic structure of the question.},
	urldate = {2023-07-28},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Addlesee, Angus and Damonte, Marco},
	month = jul,
	year = {2023},
	pages = {1--9},
}

@inproceedings{aylett_you_2023,
	address = {New York, NY, USA},
	series = {{CUI} '23},
	title = {You {Don}’t {Need} to {Speak}, {You} {Need} to {Listen}: {Robot} {Interaction} and {Human}-{Like} {Turn}-{Taking}},
	isbn = {9798400700149},
	shorttitle = {You {Don}’t {Need} to {Speak}, {You} {Need} to {Listen}},
	url = {https://dl.acm.org/doi/10.1145/3571884.3603750},
	doi = {10.1145/3571884.3603750},
	abstract = {The focus on one-to-one speak/wait conversational interaction with artificial system is partly misguided and partly cynical. Misguided because it pre-supposes that our relationship with such a system should be one-to-one and that human-like turn taking is never required. Cynical because we avoid the difficult challenge of building complex systems with a problematic route for publication. Whereas vision systems are regularly used in social robots and virtual agents to detect multiple dialogue partners and aid diarization, speech analysis and human-like turn-taking has lagged far behind. In this positional paper we make the case for focusing on human-like turn taking and multi-party interaction, discuss why realtime speech analysis and conversational management has been neglected, and put forward a program to correct this.},
	urldate = {2023-07-28},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Aylett, Matthew Peter and Romeo, Marta},
	month = jul,
	year = {2023},
	pages = {1--5},
}

@article{pittinsky_softening_2010,
	title = {Softening silos: {The} nuts and bolts of leading amid difference},
	volume = {2010},
	copyright = {© 2010 by the Leader to Leader Institute},
	issn = {1531-5355},
	shorttitle = {Softening silos},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ltl.423},
	doi = {10.1002/ltl.423},
	language = {en},
	number = {57},
	urldate = {2023-07-28},
	journal = {Leader to Leader},
	author = {Pittinsky, Todd L.},
	year = {2010},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/ltl.423},
	pages = {18--23},
}

@inproceedings{bijwadia_unified_2023,
	title = {Unified {End}-to-{End} {Speech} {Recognition} and {Endpointing} for {Fast} and {Efficient} {Speech} {Systems}},
	doi = {10.1109/SLT54892.2023.10022338},
	abstract = {Automatic speech recognition (ASR) systems typically rely on an external endpointer (EP) model to identify speech boundaries. In this work, we propose a method to jointly train the ASR and EP tasks in a single end-to-end (E2E) multitask model, improving EP quality by optionally leveraging information from the ASR audio encoder. We introduce a “switch” connection, which trains the EP to consume either the audio frames directly or low-level latent representations from the ASR model. This results in a single E2E model that can be used during inference to perform frame filtering at low cost, and also make high quality end-of-query (EOQ) predictions based on ongoing ASR computation. We present results on a voice search test set showing that, compared to separate single-task models, this approach reduces median endpoint latency by 120 ms (30.8\% reduction), and 90th percentile latency by 170 ms (23.0\% reduction), without regressing word error rate. For continuous recognition, WER improves by 10.6\% (relative).},
	booktitle = {2022 {IEEE} {Spoken} {Language} {Technology} {Workshop} ({SLT})},
	author = {Bijwadia, Shaan and Chang, Shuo-yiin and Li, Bo and Sainath, Tara and Zhang, Chao and He, Yanzhang},
	month = jan,
	year = {2023},
	pages = {310--316},
}

@inproceedings{shangguan_dissecting_2021,
	title = {Dissecting {User}-{Perceived} {Latency} of {On}-{Device} {E2E} {Speech} {Recognition}},
	url = {https://www.isca-speech.org/archive/interspeech_2021/shangguan21_interspeech.html},
	doi = {10.21437/Interspeech.2021-1887},
	abstract = {As speech-enabled devices such as smartphones and smart speakers become increasingly ubiquitous, there is growing interest in building automatic speech recognition (ASR) systems that can run directly on-device; end-to-end (E2E) speech recognition models such as recurrent neural network transducers and their variants have recently emerged as prime candidates for this task. Apart from being accurate and compact, such systems need to decode speech with low user-perceived latency (UPL), producing words as soon as they are spoken. This work examines the impact of various techniques – model architectures, training criteria, decoding hyperparameters, and endpointer parameters – on UPL. Our analyses suggest that measures of model size (parameters, input chunk sizes), or measures of computation (e.g., FLOPS, RTF) that reﬂect the model’s ability to process input frames are not always strongly correlated with observed UPL. Thus, conventional algorithmic latency measurements might be inadequate in accurately capturing latency observed when models are deployed on embedded devices. Instead, we ﬁnd that factors affecting token emission latency, and endpointing behavior have a larger impact on UPL. We achieve the best trade-off between latency and word error rate when performing ASR jointly with endpointing, while utilizing the recently proposed alignment regularization mechanism.},
	language = {en},
	urldate = {2023-07-27},
	booktitle = {Interspeech 2021},
	publisher = {ISCA},
	author = {Shangguan, Yuan and Prabhavalkar, Rohit and Su, Hang and Mahadeokar, Jay and Shi, Yangyang and Zhou, Jiatong and Wu, Chunyang and Le, Duc and Kalinli, Ozlem and Fuegen, Christian and Seltzer, Michael L.},
	month = aug,
	year = {2021},
	pages = {4553--4557},
}

@misc{hendrycks_natural_2023,
	title = {Natural {Selection} {Favors} {AIs} over {Humans}},
	url = {http://arxiv.org/abs/2303.16200},
	doi = {10.48550/arXiv.2303.16200},
	abstract = {For billions of years, evolution has been the driving force behind the development of life, including humans. Evolution endowed humans with high intelligence, which allowed us to become one of the most successful species on the planet. Today, humans aim to create artificial intelligence systems that surpass even our own intelligence. As artificial intelligences (AIs) evolve and eventually surpass us in all domains, how might evolution shape our relations with AIs? By analyzing the environment that is shaping the evolution of AIs, we argue that the most successful AI agents will likely have undesirable traits. Competitive pressures among corporations and militaries will give rise to AI agents that automate human roles, deceive others, and gain power. If such agents have intelligence that exceeds that of humans, this could lead to humanity losing control of its future. More abstractly, we argue that natural selection operates on systems that compete and vary, and that selfish species typically have an advantage over species that are altruistic to other species. This Darwinian logic could also apply to artificial agents, as agents may eventually be better able to persist into the future if they behave selfishly and pursue their own interests with little regard for humans, which could pose catastrophic risks. To counteract these risks and evolutionary forces, we consider interventions such as carefully designing AI agents' intrinsic motivations, introducing constraints on their actions, and institutions that encourage cooperation. These steps, or others that resolve the problems we pose, will be necessary in order to ensure the development of artificial intelligence is a positive one.},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Hendrycks, Dan},
	month = jul,
	year = {2023},
	note = {arXiv:2303.16200 [cs]},
}

@article{mcquillan_data_2018,
	title = {Data {Science} as {Machinic} {Neoplatonism}},
	volume = {31},
	issn = {2210-5441},
	url = {https://doi.org/10.1007/s13347-017-0273-3},
	doi = {10.1007/s13347-017-0273-3},
	abstract = {Data science is not simply a method but an organising idea. Commitment to the new paradigm overrides concerns caused by collateral damage, and only a counterculture can constitute an effective critique. Understanding data science requires an appreciation of what algorithms actually do; in particular, how machine learning learns. The resulting ‘insight through opacity’ drives the observable problems of algorithmic discrimination and the evasion of due process. But attempts to stem the tide have not grasped the nature of data science as both metaphysical and machinic. Data science strongly echoes the neoplatonism that informed the early science of Copernicus and Galileo. It appears to reveal a hidden mathematical order in the world that is superior to our direct experience. The new symmetry of these orderings is more compelling than the actual results. Data science does not only make possible a new way of knowing but acts directly on it; by converting predictions to pre-emptions, it becomes a machinic metaphysics. The people enrolled in this apparatus risk an abstraction of accountability and the production of ‘thoughtlessness’. Susceptibility to data science can be contested through critiques of science, especially standpoint theory, which opposes the ‘view from nowhere’ without abandoning the empirical methods. But a counterculture of data science must be material as well as discursive. Karen Barad’s idea of agential realism can reconfigure data science to produce both non-dualistic philosophy and participatory agency. An example of relevant praxis points to the real possibility of ‘machine learning for the people’.},
	language = {en},
	number = {2},
	urldate = {2023-07-26},
	journal = {Philosophy \& Technology},
	author = {McQuillan, Dan},
	month = jun,
	year = {2018},
	pages = {253--272},
}

@article{washburn_feedback_2019,
	title = {Feedback delays can enhance anticipatory synchronization in human-machine interaction},
	volume = {14},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0221275},
	doi = {10.1371/journal.pone.0221275},
	abstract = {Research investigating the dynamics of coupled physical systems has demonstrated that small feedback delays can allow a dynamic response system to anticipate chaotic behavior. This counterintuitive phenomenon, termed anticipatory synchronization, has been observed in coupled electrical circuits, laser semi-conductors, and artificial neurons. Recent research indicates that the same process might also support the ability of humans to anticipate the occurrence of chaotic behavior in other individuals. Motivated by this latter work, the current study examined whether the process of feedback delay induced anticipatory synchronization could be employed to develop an interactive artificial agent capable of anticipating chaotic human movement. Results revealed that incorporating such delays within the movement-control dynamics of an artificial agent not only enhances an artificial agent’s ability to anticipate chaotic human behavior, but to synchronize with such behavior in a manner similar to natural human-human anticipatory synchronization. The implication of these findings for the development of human-machine interaction systems is discussed.},
	language = {en},
	number = {8},
	urldate = {2023-07-26},
	journal = {PLOS ONE},
	author = {Washburn, Auriel and Kallen, Rachel W. and Lamb, Maurice and Stepp, Nigel and Shockley, Kevin and Richardson, Michael J.},
	month = aug,
	year = {2019},
	note = {Publisher: Public Library of Science},
	pages = {e0221275},
}

@incollection{fowler_verbal_2005,
	title = {Verbal {Constraints} on {Interpersonal} {Postural} {Coordination}},
	isbn = {978-1-00-341797-2},
	abstract = {Clark has suggested that language serves to coordinate “joint actions” allowing two or more people to achieve a mutual goal. Verbal interactions among conversers are known to produce a natural, rhythmic patterning, having related-content, similar stress patterns, and compatible rhythms. Shockley, Santana, and Fowler used an objective measure, known as cross recurrence quantification, to quantify the degree to which cooperative conversation influences interpersonal coordination. They found that participant-pairs had greater shared postural activity when cooperatively conversing with one another than when conversing with others. This chapter investigates the nature of the coordination observed by Shockley et al. with three experiments testing what aspects of speaking may mediate interpersonal postural coordination in the context of conversation.},
	booktitle = {Studies in {Perception} and {Action} {VIII}},
	publisher = {Psychology Press},
	author = {Fowler, Kevin Shockley, Michael J. Richardson, Carol A., Aimee A. Baker},
	year = {2005},
	note = {Num Pages: 4},
}

@article{nalepka_human_2019,
	title = {Human social motor solutions for human–machine interaction in dynamical task contexts},
	volume = {116},
	url = {https://www.pnas.org/doi/10.1073/pnas.1813164116},
	doi = {10.1073/pnas.1813164116},
	abstract = {Multiagent activity is commonplace in everyday life and can improve the behavioral efficiency of task performance and learning. Thus, augmenting social contexts with the use of interactive virtual and robotic agents is of great interest across health, sport, and industry domains. However, the effectiveness of human–machine interaction (HMI) to effectively train humans for future social encounters depends on the ability of artificial agents to respond to human coactors in a natural, human-like manner. One way to achieve effective HMI is by developing dynamical models utilizing dynamical motor primitives (DMPs) of human multiagent coordination that not only capture the behavioral dynamics of successful human performance but also, provide a tractable control architecture for computerized agents. Previous research has demonstrated how DMPs can successfully capture human-like dynamics of simple nonsocial, single-actor movements. However, it is unclear whether DMPs can be used to model more complex multiagent task scenarios. This study tested this human-centered approach to HMI using a complex dyadic shepherding task, in which pairs of coacting agents had to work together to corral and contain small herds of virtual sheep. Human–human and human–artificial agent dyads were tested across two different task contexts. The results revealed (i) that the performance of human–human dyads was equivalent to those composed of a human and the artificial agent and (ii) that, using a “Turing-like” methodology, most participants in the HMI condition were unaware that they were working alongside an artificial agent, further validating the isomorphism of human and artificial agent behavior.},
	number = {4},
	urldate = {2023-07-26},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Nalepka, Patrick and Lamb, Maurice and Kallen, Rachel W. and Shockley, Kevin and Chemero, Anthony and Saltzman, Elliot and Richardson, Michael J.},
	month = jan,
	year = {2019},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {1437--1446},
}

@incollection{richardson_symmetry-breaking_2015,
	series = {Advanced {Series} on {Mathematical} {Psychology}},
	title = {Symmetry-{Breaking} and the {Contextual} {Emergence} of {Human} {Multiagent} {Coordination} and {Social} {Activity}},
	volume = {Volume 6},
	isbn = {978-981-4730-60-0},
	url = {https://www.worldscientific.com/doi/10.1142/9789814730617_0011},
	number = {Volume 6},
	urldate = {2023-07-26},
	booktitle = {Contextuality from {Quantum} {Physics} to {Psychology}},
	publisher = {WORLD SCIENTIFIC},
	author = {Richardson, Michael J. and Kallen, Rachel W.},
	month = sep,
	year = {2015},
	doi = {10.1142/9789814730617_0011},
	pages = {229--286},
}

@article{raczaszek-leonardi_putting_2023,
	title = {Putting interaction center-stage for the study of knowledge structures and processes},
	volume = {45},
	url = {https://escholarship.org/uc/item/8571r2dz},
	abstract = {Humans are social animals. Human cognition evolved in a social context. Human cognition develops in a social context. Thus, both the internal mechanisms of cognition and the information we use are social. In this workshop, we aim to extend the boundaries of cognitive sciences beyond individual minds. Following the lead of Dingemanse et al. (2023), we put interaction in focus as a complementary starting point for the study of human cognition.},
	language = {en},
	number = {45},
	urldate = {2023-07-26},
	journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Rączaszek-Leonardi, Joanna and Tylen, Kristian and Dingemanse, Mark and Smith, Linda and Karmazyn Raz, Hadar and Enfield, Nick and Kallen, Rachel W. and Richardson, Michael J. and Romero, Veronica and Chowdhury, Tahiya and Paxton, Alexandra and Zubek, Julian},
	year = {2023},
}

@misc{besacier_textless_2023,
	title = {A {Textless} {Metric} for {Speech}-to-{Speech} {Comparison}},
	url = {http://arxiv.org/abs/2210.11835},
	doi = {10.48550/arXiv.2210.11835},
	abstract = {In this paper, we introduce a new and simple method for comparing speech utterances without relying on text transcripts. Our speech-to-speech comparison metric utilizes state-of-the-art speech2unit encoders like HuBERT to convert speech utterances into discrete acoustic units. We then propose a simple and easily replicable neural architecture that learns a speech-based metric that closely corresponds to its text-based counterpart. This textless metric has numerous potential applications, including evaluating speech-to-speech translation for oral languages, languages without dependable ASR systems, or to avoid the need for ASR transcription altogether. This paper also shows that for speech-to-speech translation evaluation, ASR-BLEU (which consists in automatically transcribing both speech hypothesis and reference and compute sentence-level BLEU between transcripts) is a poor proxy to real text-BLEU even when ASR system is strong.},
	urldate = {2023-07-21},
	publisher = {arXiv},
	author = {Besacier, Laurent and Ribeiro, Swen and Galibert, Olivier and Calapodescu, Ioan},
	month = jul,
	year = {2023},
	note = {arXiv:2210.11835 [cs, eess]},
}

@article{touvron_llama_2023,
	title = {Llama 2: {Open} {Foundation} and {Fine}-{Tuned} {Chat} {Models}},
	abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closedsource models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
	language = {en},
	author = {Touvron, Hugo and Martin, Louis and Stone, Kevin},
	year = {2023},
}

@inproceedings{albert_conversational_2023,
	address = {New York, NY, USA},
	series = {{CUI} '23},
	title = {Conversational {User} {Interfaces} in {Smart} {Homecare} {Interactions}: {A} {Conversation} {Analytic} {Case} {Study}},
	isbn = {9798400700149},
	shorttitle = {Conversational {User} {Interfaces} in {Smart} {Homecare} {Interactions}},
	url = {https://dl.acm.org/doi/10.1145/3571884.3597140},
	doi = {10.1145/3571884.3597140},
	abstract = {Policymakers are increasingly interested in using virtual assistants to augment social care services in the context of a demographic ageing crisis. At the same time, technology companies are marketing conversational user interfaces (CUIs) and smart home systems as assistive technologies for elderly and disabled people. However, we know relatively little about how today’s commercially available CUIs are used to assist in everyday homecare activities, or how care service users and human care assistants interpret and adapt these technologies in practice. Here we report on a longitudinal conversation analytic case study to identify, describe, and share how CUIs can be used as assistive conversational agents in practice. The analysis reveals that, while CUIs can augment and support new capabilities in a homecare environment, they cannot replace the delicate interactional work of human care assistants. We argue that CUI design is best inspired and underpinned by a better understanding of the joint coordination of homecare activities},
	urldate = {2023-07-20},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Albert, Saul and Hamann, Magnus and Stokoe, Elizabeth},
	month = jul,
	year = {2023},
	pages = {1--12},
}

@inproceedings{rough_creation_2023,
	address = {New York, NY, USA},
	series = {{CUI} '23},
	title = {Creation through {Conversation} - {A} {Provocation}},
	isbn = {9798400700149},
	url = {https://dl.acm.org/doi/10.1145/3571884.3603762},
	doi = {10.1145/3571884.3603762},
	abstract = {(A sonnet) A new force awakened this year ’23. A friend, or a foe, or a weapon - all three? Too early to say, but too plainly to see; that this is the Year Of The ChatGPT. Does this spell the end of CUI as we know it? If so, can we stop it, or kill it, or slow it? What’s the point of me trying to write like a poet? If I’ve got an idea, then I’d better well show it. I promise this sonnet of pure provocation, is tied in my mind to AI conversation A CUI imbued with ideas for creation - suppose I propose such a bold application? Can CUIs inspire us with poetic verse? A silly idea, but I’m sure you’ve heard worse.},
	urldate = {2023-07-20},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Rough, Daniel John},
	month = jul,
	year = {2023},
	pages = {1--4},
}

@inproceedings{fischer_generative_2023,
	address = {New York, NY, USA},
	series = {{CUI} '23},
	title = {Generative {AI} {Considered} {Harmful}},
	isbn = {9798400700149},
	url = {https://dl.acm.org/doi/10.1145/3571884.3603756},
	doi = {10.1145/3571884.3603756},
	abstract = {The recent months have seen an explosion of interest, hype, and concern about generative AI, driven by the release of ChatGPT. In this article I seek to explicate some potential and actual harms of the engineering and use of generative AI such as ChatGPT. With this I also suggest a reframing for researchers with an interest in interaction. With this reframing I seek to provoke researchers to consider studying the settings of ChatGPT development and use as active sites of production. Research should focus on the organisational, technological and interactional practices and contexts in and through which generative AI and its outputs—harmful and otherwise—are produced, by whom, to what end, and with what consequences on societies.},
	urldate = {2023-07-20},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Fischer, Joel E},
	month = jul,
	year = {2023},
	pages = {1--5},
}

@inproceedings{forster_working_2023,
	address = {New York, NY, USA},
	series = {{CUI} '23},
	title = {Working with {Troubles} and {Failures} in {Conversation} {Between} {Humans} and {Robots}},
	isbn = {9798400700149},
	url = {https://dl.acm.org/doi/10.1145/3571884.3597437},
	doi = {10.1145/3571884.3597437},
	abstract = {In order to carry out human-robot collaborative tasks efficiently, robots have to be able to communicate with their human counterparts. In many applications, speech interfaces are deployed as a way to empower robots with the ability to communicate. Despite the progress made in speech recognition and (multi-modal) dialogue systems, such interfaces continue to be brittle in a number of ways and the experience of the failure of such interfaces is commonplace amongst roboticists. Surprisingly, a rigorous and complete analysis of communicative failures is still missing, and the technical literature is positively skewed towards the success and good performance of speech interfaces. In order to address this blind spot and investigate failures in conversations between humans and robots, an interdisciplinary effort is necessary. This workshop aims to raise awareness of said blind spot and provide a platform for discussing communicative troubles and failures in human-robot interactions and potentially related failures in non-robotic speech interfaces. We aim to bring together researchers studying communication in different fields, to start a scrupulous investigation into communicative failures, to begin working on a taxonomy of such failures, and enable a preliminary discussion on possible mitigating strategies. This workshop intends to be a venue where participants can freely discuss the failures they have encountered, to positively and constructively learn from them.},
	urldate = {2023-07-20},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Förster, Frank and Romeo, Marta and Holthaus, Patrick and Nesset, Birthe and Galvez Trigo, Maria J. and Dondrup, Christian and Fischer, Joel E.},
	month = jul,
	year = {2023},
	pages = {1--4},
}

@inproceedings{aylett_you_2023-1,
	address = {New York, NY, USA},
	series = {{CUI} '23},
	title = {You {Don}’t {Need} to {Speak}, {You} {Need} to {Listen}: {Robot} {Interaction} and {Human}-{Like} {Turn}-{Taking}},
	isbn = {9798400700149},
	shorttitle = {You {Don}’t {Need} to {Speak}, {You} {Need} to {Listen}},
	url = {https://dl.acm.org/doi/10.1145/3571884.3603750},
	doi = {10.1145/3571884.3603750},
	abstract = {The focus on one-to-one speak/wait conversational interaction with artificial system is partly misguided and partly cynical. Misguided because it pre-supposes that our relationship with such a system should be one-to-one and that human-like turn taking is never required. Cynical because we avoid the difficult challenge of building complex systems with a problematic route for publication. Whereas vision systems are regularly used in social robots and virtual agents to detect multiple dialogue partners and aid diarization, speech analysis and human-like turn-taking has lagged far behind. In this positional paper we make the case for focusing on human-like turn taking and multi-party interaction, discuss why realtime speech analysis and conversational management has been neglected, and put forward a program to correct this.},
	urldate = {2023-07-19},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Aylett, Matthew Peter and Romeo, Marta},
	month = jul,
	year = {2023},
	pages = {1--5},
}

@inproceedings{10.1145/3098279.3098539,
	address = {New York, NY, USA},
	series = {{MobileHCI} '17},
	title = {"{What} {Can} {I} {Help} {You} with?": {Infrequent} users' experiences of intelligent personal assistants},
	isbn = {978-1-4503-5075-4},
	url = {https://doi.org/10.1145/3098279.3098539},
	doi = {10.1145/3098279.3098539},
	abstract = {Intelligent Personal Assistants (IPAs) are widely available on devices such as smartphones. However, most people do not use them regularly. Previous research has studied the experiences of frequent IPA users. Using qualitative methods we explore the experience of infrequent users: people who have tried IPAs, but choose not to use them regularly. Unsurprisingly infrequent users share some of the experiences of frequent users, e.g. frustration at limitations on fully hands-free interaction. Significant points of contrast and previously unidentified concerns also emerge. Cultural norms and social embarrassment take on added significance for infrequent users. Humanness of IPAs sparked comparisons with human assistants, juxtaposing their limitations. Most importantly, significant concerns emerged around privacy, monetization, data permanency and transparency. Drawing on these findings we discuss key challenges, including: designing for interruptability; reconsideration of the human metaphor; issues of trust and data ownership. Addressing these challenges may lead to more widespread IPA use.},
	booktitle = {Proceedings of the 19th international conference on human-computer interaction with mobile devices and services},
	publisher = {Association for Computing Machinery},
	author = {Cowan, Benjamin R. and Pantidi, Nadia and Coyle, David and Morrissey, Kellie and Clarke, Peter and Al-Shehri, Sara and Earley, David and Bandeira, Natasha},
	year = {2017},
	note = {Number of pages: 12
Place: Vienna, Austria
tex.articleno: 43},
	keywords = {intelligent personal assistants, privacy, speech interfaces, trust, user experience},
}

@inproceedings{boeva_behind_2023,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '23},
	title = {Behind the {Scenes} of {Automation}: {Ghostly} {Care}-{Work}, {Maintenance}, and {Interferences}: {Exploring} participatory practices and methods to uncover the ghostly presence of humans and human labor in automation},
	isbn = {978-1-4503-9422-2},
	shorttitle = {Behind the {Scenes} of {Automation}},
	url = {https://dl.acm.org/doi/10.1145/3544549.3573830},
	doi = {10.1145/3544549.3573830},
	abstract = {Industry and media have long represented automation as a harbinger of development and convenience in different areas of life. An anxious prospect to some, automation systems promise “progress” and profitability to others by conjuring corporate computational futures. What remains behind the scenes of these predictions and imaginaries of automation is the invisible human labor of global ghost workers caring for, maintaining, and repairing technologies. Invisible but irreplaceable, computation performed by humans in precarious conditions fills gaps that computer technologies lack skills and sensibility for. In this hybrid workshop, we ask who the “ghosts” are in the machines. The workshop will address the ghostly presence of humans and human labor in automation and its challenges to HCI research and design.},
	urldate = {2023-07-19},
	booktitle = {Extended {Abstracts} of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Boeva, Yana and Berger, Arne and Bischof, Andreas and Doggett, Olivia and Heuer, Hendrik and Jarke, Juliane and Treusch, Pat and Søraa, Roger Andre and Tacheva, Zhasmina and Voigt, Maja-Lee},
	month = apr,
	year = {2023},
	pages = {1--5},
}

@article{singhal_large_2023,
	title = {Large language models encode clinical knowledge},
	copyright = {2023 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06291-2},
	doi = {10.1038/s41586-023-06291-2},
	abstract = {Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model1 (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM2 on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA3, MedMCQA4, PubMedQA5 and Measuring Massive Multitask Language Understanding (MMLU) clinical topics6), including 67.6\% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17\%. However, human evaluation reveals key gaps. To resolve this, we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, knowledge recall and reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal limitations of today’s models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLMs for clinical applications.},
	language = {en},
	urldate = {2023-07-17},
	journal = {Nature},
	author = {Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S. Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and Payne, Perry and Seneviratne, Martin and Gamble, Paul and Kelly, Chris and Babiker, Abubakr and Schärli, Nathanael and Chowdhery, Aakanksha and Mansfield, Philip and Demner-Fushman, Dina and Agüera y Arcas, Blaise and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Chou, Katherine and Gottweis, Juraj and Tomasev, Nenad and Liu, Yun and Rajkomar, Alvin and Barral, Joelle and Semturs, Christopher and Karthikesalingam, Alan and Natarajan, Vivek},
	month = jul,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	pages = {1--9},
}

@inproceedings{liu_p-tuning_2022,
	address = {Dublin, Ireland},
	title = {P-{Tuning}: {Prompt} {Tuning} {Can} {Be} {Comparable} to {Fine}-tuning {Across} {Scales} and {Tasks}},
	shorttitle = {P-{Tuning}},
	url = {https://aclanthology.org/2022.acl-short.8},
	doi = {10.18653/v1/2022.acl-short.8},
	abstract = {Prompt tuning, which only tunes continuous prompts with a frozen language model, substantially reduces per-task storage and memory usage at training. However, in the context of NLU, prior work reveals that prompt tuning does not perform well for normal-sized pretrained models. We also find that existing methods of prompt tuning cannot handle hard sequence labeling tasks, indicating a lack of universality. We present a novel empirical finding that properly optimized prompt tuning can be universally effective across a wide range of model scales and NLU tasks. It matches the performance of finetuning while having only 0.1\%-3\% tuned parameters. Our method P-Tuning v2 is an implementation of Deep Prompt Tuning (CITATION) optimized and adapted for NLU. Given the universality and simplicity of P-Tuning v2, we believe it can serve as an alternative to finetuning and a strong baseline for future research.},
	urldate = {2023-07-10},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
	month = may,
	year = {2022},
	pages = {61--68},
}

@inproceedings{zeng_glm-130b_2022,
	title = {{GLM}-{130B}: {An} {Open} {Bilingual} {Pre}-trained {Model}},
	shorttitle = {{GLM}-{130B}},
	url = {https://openreview.net/forum?id=-Aw0rrrPUF},
	abstract = {We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model as good as GPT-3 (davinci) and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we face numerous unexpected technical and engineering challenges, particularly on loss spikes and divergence. In this paper, we introduce the pre-training process of GLM-130B including its design choices, training strategies for both efficiency and stability, and engineering efforts. The resultant GLM-130B model offers significant outperformance over GPT-3 175B on a wide range of popular English benchmarks while the performance advantage is not observed in OPT-175B and BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN 3.0 260B—the largest Chinese language model—across related benchmarks. Finally, we leverage a unique scaling property of GLM-130B to reach INT4 quantization with almost no performance loss, making it the first among 100B-scale models and more importantly, allowing its effective inference on 4×RTX 3090 (24G) or 8×RTX 2080 Ti (11G) GPUs, the most ever affordable GPUs required for using 100B-scale models. The GLM-130B model weights are publicly accessible and its code, training logs, related toolkit, and lessons learned are open-sourced at https://github.com/THUDM/GLM-130B/.},
	language = {en},
	urldate = {2023-07-10},
	author = {Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and Tam, Weng Lam and Ma, Zixuan and Xue, Yufei and Zhai, Jidong and Chen, Wenguang and Liu, Zhiyuan and Zhang, Peng and Dong, Yuxiao and Tang, Jie},
	month = sep,
	year = {2022},
}

@article{graaf_long-term_2016,
	title = {Long-term evaluation of a social robot in real homes},
	volume = {17},
	issn = {1572-0373, 1572-0381},
	url = {https://www.jbe-platform.com/content/journals/10.1075/is.17.3.08deg},
	doi = {10.1075/is.17.3.08deg},
	abstract = {This study aims to contribute to emerging human-robot interaction research by adding longitudinal findings to a limited number of long-term social robotics home studies. We placed 70 robots in users’ homes for a period of up to six months, and used questionnaires and interviews to collect data at six points during this period. Results indicate that users’ evaluations of the robot dropped initially, but later rose after the robot had been used for a longer period of time. This is congruent with the so-called mere-exposure effect, which shows an increasing positive evaluation of a novel stimulus once people become familiar with it. Before adoption, users focus on control beliefs showing that previous experiences with robots or other technologies allows to create a mental image of what having and using a robot in the home would entail. After adoption, users focus on utilitarian and hedonic attitudes showing that especially usefulness, social presence, enjoyment and attractiveness are important factors for long-term acceptance.},
	language = {en},
	number = {3},
	urldate = {2023-07-10},
	journal = {Interaction Studies},
	author = {Graaf, Maartje M. A. de and Allouch, Somaya Ben and Dijk, Jan A. G. M. van},
	month = jan,
	year = {2016},
	note = {Publisher: John Benjamins},
	pages = {462--491},
}

@misc{biderman_pythia_2023,
	title = {Pythia: {A} {Suite} for {Analyzing} {Large} {Language} {Models} {Across} {Training} and {Scaling}},
	shorttitle = {Pythia},
	url = {http://arxiv.org/abs/2304.01373},
	doi = {10.48550/arXiv.2304.01373},
	abstract = {How do large language models (LLMs) develop and evolve over the course of training? How do these patterns change as models scale? To answer these questions, we introduce {\textbackslash}textit\{Pythia\}, a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters. We provide public access to 154 checkpoints for each one of the 16 models, alongside tools to download and reconstruct their exact training dataloaders for further study. We intend {\textbackslash}textit\{Pythia\} to facilitate research in many areas, and we present several case studies including novel results in memorization, term frequency effects on few-shot performance, and reducing gender bias. We demonstrate that this highly controlled setup can be used to yield novel insights toward LLMs and their training dynamics. Trained models, analysis code, training code, and training data can be found at {\textbackslash}url\{https://github.com/EleutherAI/pythia\}.},
	urldate = {2023-07-03},
	publisher = {arXiv},
	author = {Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin and Bradley, Herbie and O'Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and Skowron, Aviya and Sutawika, Lintang and van der Wal, Oskar},
	month = may,
	year = {2023},
	note = {arXiv:2304.01373 [cs]},
}

@misc{cahyawijaya_instruct-align_2023,
	title = {Instruct-{Align}: {Teaching} {Novel} {Languages} with to {LLMs} through {Alignment}-based {Cross}-{Lingual} {Instruction}},
	shorttitle = {Instruct-{Align}},
	url = {http://arxiv.org/abs/2305.13627},
	abstract = {Instruction-tuned large language models (LLMs) have shown remarkable generalization capability over multiple tasks in multiple languages. Nevertheless, their generalization towards different languages varies especially to underrepresented languages or even to unseen languages. Prior works on adapting new languages to LLMs find that naively adapting new languages to instruction-tuned LLMs will result in catastrophic forgetting, which in turn causes the loss of multitasking ability in these LLMs. To tackle this, we propose the Instruct-Align a.k.a (IA)\${\textasciicircum}1\$ framework, which enables instruction-tuned LLMs to learn cross-lingual alignment between unseen and previously learned languages via alignment-based cross-lingual instruction-tuning. Our preliminary result on BLOOMZ-560M shows that (IA)\${\textasciicircum}1\$ is able to learn a new language effectively with only a limited amount of parallel data and at the same time prevent catastrophic forgetting by applying continual instruction-tuning through experience replay. Our work contributes to the progression of language adaptation methods for instruction-tuned LLMs and opens up the possibility of adapting underrepresented low-resource languages into existing instruction-tuned LLMs. Our code will be publicly released upon acceptance.},
	urldate = {2023-07-03},
	publisher = {arXiv},
	author = {Cahyawijaya, Samuel and Lovenia, Holy and Yu, Tiezheng and Chung, Willy and Fung, Pascale},
	month = may,
	year = {2023},
	note = {arXiv:2305.13627 [cs]},
}

@misc{muennighoff_crosslingual_2023,
	title = {Crosslingual {Generalization} through {Multitask} {Finetuning}},
	url = {http://arxiv.org/abs/2211.01786},
	doi = {10.48550/arXiv.2211.01786},
	abstract = {Multitask prompted finetuning (MTF) has been shown to help large language models generalize to new tasks in a zero-shot setting, but so far explorations of MTF have focused on English data and models. We apply MTF to the pretrained multilingual BLOOM and mT5 model families to produce finetuned variants called BLOOMZ and mT0. We find finetuning large multilingual language models on English tasks with English prompts allows for task generalization to non-English languages that appear only in the pretraining corpus. Finetuning on multilingual tasks with English prompts further improves performance on English and non-English tasks leading to various state-of-the-art zero-shot results. We also investigate finetuning on multilingual tasks with prompts that have been machine-translated from English to match the language of each dataset. We find training on these machine-translated prompts leads to better performance on human-written prompts in the respective languages. Surprisingly, we find models are capable of zero-shot generalization to tasks in languages they have never intentionally seen. We conjecture that the models are learning higher-level capabilities that are both task- and language-agnostic. In addition, we introduce xP3, a composite of supervised datasets in 46 languages with English and machine-translated prompts. Our code, datasets and models are freely available at https://github.com/bigscience-workshop/xmtf.},
	urldate = {2023-07-03},
	publisher = {arXiv},
	author = {Muennighoff, Niklas and Wang, Thomas and Sutawika, Lintang and Roberts, Adam and Biderman, Stella and Scao, Teven Le and Bari, M. Saiful and Shen, Sheng and Yong, Zheng-Xin and Schoelkopf, Hailey and Tang, Xiangru and Radev, Dragomir and Aji, Alham Fikri and Almubarak, Khalid and Albanie, Samuel and Alyafeai, Zaid and Webson, Albert and Raff, Edward and Raffel, Colin},
	month = may,
	year = {2023},
	note = {arXiv:2211.01786 [cs]},
}

@misc{kopf_openassistant_2023,
	title = {{OpenAssistant} {Conversations} -- {Democratizing} {Large} {Language} {Model} {Alignment}},
	url = {http://arxiv.org/abs/2304.07327},
	doi = {10.48550/arXiv.2304.07327},
	abstract = {Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains. However, state-of-the-art alignment techniques like RLHF rely on high-quality human feedback data, which is expensive to create and often remains proprietary. In an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages distributed across 66,497 conversation trees, in 35 different languages, annotated with 461,292 quality ratings. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers. To demonstrate the OpenAssistant Conversations dataset's effectiveness, we present OpenAssistant, the first fully open-source large-scale instruction-tuned model to be trained on human data. A preference study revealed that OpenAssistant replies are comparably preferred to GPT-3.5-turbo (ChatGPT) with a relative winrate of 48.3\% vs. 51.7\% respectively. We release our code and data under fully permissive licenses.},
	urldate = {2023-07-03},
	publisher = {arXiv},
	author = {Köpf, Andreas and Kilcher, Yannic and von Rütte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi-Rui and Stevens, Keith and Barhoum, Abdullah and Duc, Nguyen Minh and Stanley, Oliver and Nagyfi, Richárd and ES, Shahul and Suri, Sameer and Glushkov, David and Dantuluri, Arnav and Maguire, Andrew and Schuhmann, Christoph and Nguyen, Huu and Mattick, Alexander},
	month = apr,
	year = {2023},
	note = {arXiv:2304.07327 [cs]},
}

@misc{peng_rwkv_2023,
	title = {{RWKV}: {Reinventing} {RNNs} for the {Transformer} {Era}},
	shorttitle = {{RWKV}},
	url = {http://arxiv.org/abs/2305.13048},
	doi = {10.48550/arXiv.2305.13048},
	abstract = {Transformers have revolutionized almost all natural language processing (NLP) tasks but suffer from memory and computational complexity that scales quadratically with sequence length. In contrast, recurrent neural networks (RNNs) exhibit linear scaling in memory and computational requirements but struggle to match the same performance as Transformers due to limitations in parallelization and scalability. We propose a novel model architecture, Receptance Weighted Key Value (RWKV), that combines the efficient parallelizable training of Transformers with the efficient inference of RNNs. Our approach leverages a linear attention mechanism and allows us to formulate the model as either a Transformer or an RNN, which parallelizes computations during training and maintains constant computational and memory complexity during inference, leading to the first non-transformer architecture to be scaled to tens of billions of parameters. Our experiments reveal that RWKV performs on par with similarly sized Transformers, suggesting that future work can leverage this architecture to create more efficient models. This work presents a significant step towards reconciling the trade-offs between computational efficiency and model performance in sequence processing tasks.},
	urldate = {2023-07-03},
	publisher = {arXiv},
	author = {Peng, Bo and Alcaide, Eric and Anthony, Quentin and Albalak, Alon and Arcadinho, Samuel and Cao, Huanqi and Cheng, Xin and Chung, Michael and Grella, Matteo and GV, Kranthi Kiran and He, Xuzheng and Hou, Haowen and Kazienko, Przemyslaw and Kocon, Jan and Kong, Jiaming and Koptyra, Bartlomiej and Lau, Hayden and Mantri, Krishna Sri Ipsit and Mom, Ferdinand and Saito, Atsushi and Tang, Xiangru and Wang, Bolun and Wind, Johan S. and Wozniak, Stansilaw and Zhang, Ruichong and Zhang, Zhenyuan and Zhao, Qihang and Zhou, Peng and Zhu, Jian and Zhu, Rui-Jie},
	month = may,
	year = {2023},
	note = {arXiv:2305.13048 [cs]},
}

@article{anand_gpt4all_nodate,
	title = {{GPT4All}: {Training} an {Assistant}-style {Chatbot} with {Large} {Scale} {Data} {Distillation} from {GPT}-3.5-{Turbo}},
	abstract = {This preliminary technical report describes the development of GPT4All, a chatbot trained over a massive curated corpus of assistant interactions including word problems, story descriptions, multi-turn dialogue, and code. We openly release the collected data, data curation procedure, training code, and final model weights to promote open research and reproducibility. Additionally, we release quantized 4-bit versions of the model allowing virtually anyone to run the model on CPU.},
	language = {en},
	author = {Anand, Yuvanesh and Nussbaum, Zach and Duderstadt, Brandon and Schmidt, Benjamin and Mulyar, Andriy},
}

@misc{askari_generating_2023,
	title = {Generating {Synthetic} {Documents} for {Cross}-{Encoder} {Re}-{Rankers}: {A} {Comparative} {Study} of {ChatGPT} and {Human} {Experts}},
	shorttitle = {Generating {Synthetic} {Documents} for {Cross}-{Encoder} {Re}-{Rankers}},
	url = {http://arxiv.org/abs/2305.02320},
	doi = {10.48550/arXiv.2305.02320},
	abstract = {We investigate the usefulness of generative Large Language Models (LLMs) in generating training data for cross-encoder re-rankers in a novel direction: generating synthetic documents instead of synthetic queries. We introduce a new dataset, ChatGPT-RetrievalQA, and compare the effectiveness of models fine-tuned on LLM-generated and human-generated data. Data generated with generative LLMs can be used to augment training data, especially in domains with smaller amounts of labeled data. We build ChatGPT-RetrievalQA based on an existing dataset, human ChatGPT Comparison Corpus (HC3), consisting of public question collections with human responses and answers from ChatGPT. We fine-tune a range of cross-encoder re-rankers on either human-generated or ChatGPT-generated data. Our evaluation on MS MARCO DEV, TREC DL'19, and TREC DL'20 demonstrates that cross-encoder re-ranking models trained on ChatGPT responses are statistically significantly more effective zero-shot re-rankers than those trained on human responses. In a supervised setting, the human-trained re-rankers outperform the LLM-trained re-rankers. Our novel findings suggest that generative LLMs have high potential in generating training data for neural retrieval models. Further work is needed to determine the effect of factually wrong information in the generated responses and test our findings' generalizability with open-source LLMs. We release our data, code, and cross-encoders checkpoints for future work.},
	urldate = {2023-07-03},
	publisher = {arXiv},
	author = {Askari, Arian and Aliannejadi, Mohammad and Kanoulas, Evangelos and Verberne, Suzan},
	month = may,
	year = {2023},
	note = {arXiv:2305.02320 [cs]},
}

@inproceedings{chen_places_2023,
	address = {Dubrovnik, Croatia},
	title = {{PLACES}: {Prompting} {Language} {Models} for {Social} {Conversation} {Synthesis}},
	shorttitle = {{PLACES}},
	url = {https://aclanthology.org/2023.findings-eacl.63},
	abstract = {Collecting high quality conversational data can be very expensive for most applications and infeasible for others due to privacy, ethical, or similar concerns. A promising direction to tackle this problem is to generate synthetic dialogues by prompting large language models. In this work, we use a small set of expert-written conversations as in-context examples to synthesize a social conversation dataset using prompting. We perform several thorough evaluations of our synthetic conversations compared to human-collected conversations. This includes various dimensions of conversation quality with human evaluation directly on the synthesized conversations, and interactive human evaluation of chatbots fine-tuned on the synthetically generated dataset. We additionally demonstrate that this prompting approach is generalizable to multi-party conversations, providing potential to create new synthetic data for multi-party tasks. Our synthetic multi-party conversations were rated more favorably across all measured dimensions compared to conversation excerpts sampled from a human-collected multi-party dataset.},
	urldate = {2023-07-01},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EACL} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Chen, Maximillian and Papangelis, Alexandros and Tao, Chenyang and Kim, Seokhwan and Rosenbaum, Andy and Liu, Yang and Yu, Zhou and Hakkani-Tur, Dilek},
	month = may,
	year = {2023},
	pages = {844--868},
}

@inproceedings{chen_places_2023-1,
	address = {Dubrovnik, Croatia},
	title = {{PLACES}: {Prompting} {Language} {Models} for {Social} {Conversation} {Synthesis}},
	shorttitle = {{PLACES}},
	url = {https://aclanthology.org/2023.findings-eacl.63},
	abstract = {Collecting high quality conversational data can be very expensive for most applications and infeasible for others due to privacy, ethical, or similar concerns. A promising direction to tackle this problem is to generate synthetic dialogues by prompting large language models. In this work, we use a small set of expert-written conversations as in-context examples to synthesize a social conversation dataset using prompting. We perform several thorough evaluations of our synthetic conversations compared to human-collected conversations. This includes various dimensions of conversation quality with human evaluation directly on the synthesized conversations, and interactive human evaluation of chatbots fine-tuned on the synthetically generated dataset. We additionally demonstrate that this prompting approach is generalizable to multi-party conversations, providing potential to create new synthetic data for multi-party tasks. Our synthetic multi-party conversations were rated more favorably across all measured dimensions compared to conversation excerpts sampled from a human-collected multi-party dataset.},
	urldate = {2023-07-01},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EACL} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Chen, Maximillian and Papangelis, Alexandros and Tao, Chenyang and Kim, Seokhwan and Rosenbaum, Andy and Liu, Yang and Yu, Zhou and Hakkani-Tur, Dilek},
	month = may,
	year = {2023},
	pages = {844--868},
}

@article{oostdijk_dont_2022,
	title = {Don’t {Do} {Your} {Experiments} {Double}-blind: {The} {Importance} of {Checking} {Your} {Data}},
	volume = {12},
	copyright = {Copyright (c) 2022},
	issn = {2211-4009},
	shorttitle = {Don’t {Do} {Your} {Experiments} {Double}-blind},
	url = {https://clinjournal.org/clinj/article/view/148},
	abstract = {In this paper, we investigate what could happen if you run machine learning experiments on data found somewhere on the internet, without first examining this data. As an example, we did polarity recognition on a data set extracted from Booking.com. We found that a) the form of the data in the dataset sometimes made polarity judgements hard for humans and probably also for systems, b) naive use of the data results in a different task than polarity recognition as the content of the data fields does not always comply with the field descriptors, and c) the comments in the data set come in several, quite different, subtypes, so that recognition quality rather varies with the choice for training and test data. On the basis of these findings we conclude that our advice to inspect data before using it is indeed valuable.},
	language = {en},
	urldate = {2023-06-22},
	journal = {Computational Linguistics in the Netherlands Journal},
	author = {Oostdijk, Nelleke and Halteren, Hans Van},
	month = dec,
	year = {2022},
	pages = {65--82},
}

@article{moore_vocal_2016,
	title = {Vocal {Interactivity} in-and-between {Humans}, {Animals}, and {Robots}},
	volume = {3},
	issn = {2296-9144},
	url = {https://www.frontiersin.org/articles/10.3389/frobt.2016.00061},
	abstract = {Almost all animals exploit vocal signals for a range of ecologically motivated purposes: detecting predators/prey and marking territory, expressing emotions, establishing social relations, and sharing information. Whether it is a bird raising an alarm, a whale calling to potential partners, a dog responding to human commands, a parent reading a story with a child, or a business-person accessing stock prices using Siri, vocalization provides a valuable communication channel through which behavior may be coordinated and controlled, and information may be distributed and acquired. Indeed, the ubiquity of vocal interaction has led to research across an extremely diverse array of fields, from assessing animal welfare, to understanding the precursors of human language, to developing voice-based human–machine interaction. Opportunities for cross-fertilization between these fields abound; for example, using artificial cognitive agents to investigate contemporary theories of language grounding, using machine learning to analyze different habitats or adding vocal expressivity to the next generation of language-enabled autonomous social agents. However, much of the research is conducted within well-defined disciplinary boundaries, and many fundamental issues remain. This paper attempts to redress the balance by presenting a comparative review of vocal interaction within-and-between humans, animals, and artificial agents (such as robots), and it identifies a rich set of open research questions that may benefit from an interdisciplinary analysis.},
	urldate = {2023-06-22},
	journal = {Frontiers in Robotics and AI},
	author = {Moore, Roger K. and Marxer, Ricard and Thill, Serge},
	year = {2016},
}

@article{ten_bosch_computational_2009,
	title = {A {Computational} {Model} of {Language} {Acquisition}: the {Emergence} of {Words}},
	volume = {90},
	issn = {0169-2968},
	shorttitle = {A {Computational} {Model} of {Language} {Acquisition}},
	url = {https://content.iospress.com/articles/fundamenta-informaticae/fi90-3-03},
	doi = {10.3233/FI-2009-0016},
	abstract = {In this paper, we discuss a computational model that is able to detect and build word-like representations on the basis of sensory input. The model is designed and tested with a further aim to investigate how infants may learn to communicate by means},
	language = {en},
	number = {3},
	urldate = {2023-06-22},
	journal = {Fundamenta Informaticae},
	author = {ten Bosch, Louis and Boves, Lou and Van Hamme, Hugo and Moore, Roger K.},
	month = jan,
	year = {2009},
	note = {Publisher: IOS Press},
	pages = {229--249},
}

@article{merkx_modelling_2023,
	title = {Modelling {Human} {Word} {Learning} and {Recognition} {Using} {Visually} {Grounded} {Speech}},
	volume = {15},
	issn = {1866-9964},
	url = {https://doi.org/10.1007/s12559-022-10059-7},
	doi = {10.1007/s12559-022-10059-7},
	abstract = {Many computational models of speech recognition assume that the set of target words is already given. This implies that these models learn to recognise speech in a biologically unrealistic manner, i.e. with prior lexical knowledge and explicit supervision. In contrast, visually grounded speech models learn to recognise speech without prior lexical knowledge by exploiting statistical dependencies between spoken and visual input. While it has previously been shown that visually grounded speech models learn to recognise the presence of words in the input, we explicitly investigate such a model as a model of human speech recognition. We investigate the time course of noun and verb recognition as simulated by the model using a gating paradigm to test whether its recognition is affected by well-known word competition effects in human speech processing. We furthermore investigate whether vector quantisation, a technique for discrete representation learning, aids the model in the discovery and recognition of words. Our experiments show that the model is able to recognise nouns in isolation and even learns to properly differentiate between plural and singular nouns. We also find that recognition is influenced by word competition from the word-initial cohort and neighbourhood density, mirroring word competition effects in human speech comprehension. Lastly, we find no evidence that vector quantisation is helpful in discovering and recognising words, though our gating experiment does show that the LSTM-VQ model is able to recognise the target words earlier.},
	language = {en},
	number = {1},
	urldate = {2023-06-22},
	journal = {Cognitive Computation},
	author = {Merkx, Danny and Scholten, Sebastiaan and Frank, Stefan L. and Ernestus, Mirjam and Scharenborg, Odette},
	month = jan,
	year = {2023},
	pages = {272--288},
}

@article{scharenborg_how_2005,
	title = {How {Should} a {Speech} {Recognizer} {Work}?},
	volume = {29},
	copyright = {© 2005 Cognitive Science Society, Inc.},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog0000_37},
	doi = {10.1207/s15516709cog0000_37},
	abstract = {Although researchers studying human speech recognition (HSR) and automatic speech recognition (ASR) share a common interest in how information processing systems (human or machine) recognize spoken language, there is little communication between the two disciplines. We suggest that this lack of communication follows largely from the fact that research in these related fields has focused on the mechanics of how speech can be recognized. In Marr's (1982) terms, emphasis has been on the algorithmic and implementational levels rather than on the computational level. In this article, we provide a computational-level analysis of the task of speech recognition, which reveals the close parallels between research concerned with HSR and ASR. We illustrate this relation by presenting a new computational model of human spoken-word recognition, built using techniques from the field of ASR that, in contrast to current existing models of HSR, recognizes words from real speech input.},
	language = {en},
	number = {6},
	urldate = {2023-06-22},
	journal = {Cognitive Science},
	author = {Scharenborg, Odette and Norris, Dennis and ten Bosch, Louis and McQueen, James M.},
	year = {2005},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog0000\_37},
	pages = {867--918},
}

@inproceedings{ten_bosch_durational_2004,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Durational {Aspects} of {Turn}-{Taking} in {Spontaneous} {Face}-to-{Face} and {Telephone} {Dialogues}},
	isbn = {978-3-540-30120-2},
	doi = {10.1007/978-3-540-30120-2_71},
	abstract = {On the basis of two-speaker spontaneous conversations, it is shown that the distributions of both pauses and speech-overlaps of telephone and face-to-face dialogues have different statistical properties. Pauses in a face-to-face dialogue last up to 4 times longer than pauses in telephone conversations in functionally comparable conditions. There is a high correlation (0.88 or larger) between the average pause duration for the two speakers across face-to-face dialogues and telephone dialogues. The data provided form a first quantitative analysis of the complex turn-taking mechanism evidenced in the dialogues available in the 9-million-word Spoken Dutch Corpus.},
	language = {en},
	booktitle = {Text, {Speech} and {Dialogue}},
	publisher = {Springer},
	author = {ten Bosch, Louis and Oostdijk, Nelleke and de Ruiter, Jan Peter},
	editor = {Sojka, Petr and Kopeček, Ivan and Pala, Karel},
	year = {2004},
	pages = {563--570},
}

@article{bosch_temporal_2005,
	series = {In {Honour} of {Louis} {Pols}},
	title = {On temporal aspects of turn taking in conversational dialogues},
	volume = {47},
	issn = {0167-6393},
	url = {https://www.sciencedirect.com/science/article/pii/S0167639305001330},
	doi = {10.1016/j.specom.2005.05.009},
	abstract = {In this short communication we show how shallow annotations in large speech corpora can be used to derive data about the temporal aspects of turn taking. Within the limitations of such a speech corpus, we show that the average durations of between-turn pauses made by speakers in a dyad are statistically related, and our data suggest the existence of gender effects in the temporal aspects of turn taking. Also, clear differences in turn taking behaviour between face-to-face and telephone dialogues can be detected using shallow analyses. We discuss the most important limitations imposed by the shallowness of the annotations in large corpora, and the possibility for enriching those annotations in a semi-automatic iterative manner.},
	language = {en},
	number = {1},
	urldate = {2023-06-22},
	journal = {Speech Communication},
	author = {Bosch, Louis ten and Oostdijk, Nelleke and Boves, Lou},
	month = sep,
	year = {2005},
	pages = {80--86},
}

@inproceedings{shterionov_sign_2022,
	address = {Ghent, Belgium},
	title = {Sign {Language} {Translation}: {Ongoing} {Development}, {Challenges} and {Innovations} in the {SignON} {Project}},
	shorttitle = {Sign {Language} {Translation}},
	url = {https://aclanthology.org/2022.eamt-1.52},
	abstract = {The SignON project (www.signon-project.eu) focuses on the research and development of a Sign Language (SL) translation mobile application and an open communications framework. SignON rectifies the lack of technology and services for the automatic translation between signed and spoken languages, through an inclusive, humancentric solution which facilitates communication between deaf, hard of hearing (DHH) and hearing individuals. We present an overview of the current status of the project, describing the milestones reached to date and the approaches that are being developed to address the challenges and peculiarities of Sign Language Machine Translation (SLMT).},
	urldate = {2023-06-22},
	booktitle = {Proceedings of the 23rd {Annual} {Conference} of the {European} {Association} for {Machine} {Translation}},
	publisher = {European Association for Machine Translation},
	author = {Shterionov, Dimitar and De Sisto, Mirella and Vandeghinste, Vincent and Brady, Aoife and De Coster, Mathieu and Leeson, Lorraine and Blat, Josep and Picron, Frankie and Scipioni, Marcello Paolo and Parikh, Aditya and ten Bosh, Louis and O'Flaherty, John and Dambre, Joni and Rijckaert, Jorn},
	month = jun,
	year = {2022},
	pages = {325--326},
}

@inproceedings{wigdor_how_2016,
	title = {How to improve human-robot interaction with {Conversational} {Fillers}},
	doi = {10.1109/ROMAN.2016.7745134},
	abstract = {Conversation Fillers (CFs), such as ‘um’, ‘hmm’, and ‘ah’, may help to improve the human-robot interaction by smoothening the robot's responses. This paper presents the design and test of such CFs - alongside iconic pensive or acknowledging gestures - for Wizard of Oz (WoZ) controlled open-ended dialogues in child-robot interactions. A controlled experiment with 26 children showed that these CFs can improve the perceived speediness, aliveness, humanness, and likability of the robot, without decreasing perceptions of intelligence, trustworthiness, or autonomy.},
	booktitle = {2016 25th {IEEE} {International} {Symposium} on {Robot} and {Human} {Interactive} {Communication} ({RO}-{MAN})},
	author = {Wigdor, Noel and de Greeff, Joachim and Looije, Rosemarijn and Neerincx, Mark A.},
	month = aug,
	year = {2016},
	note = {ISSN: 1944-9437},
	pages = {219--224},
}

@article{goldin_interactive_2008,
	title = {The {Interactive} {Nature} of {Computing}: {Refuting} the {Strong} {Church}–{Turing} {Thesis}},
	volume = {18},
	issn = {1572-8641},
	shorttitle = {The {Interactive} {Nature} of {Computing}},
	url = {https://doi.org/10.1007/s11023-007-9083-1},
	doi = {10.1007/s11023-007-9083-1},
	abstract = {The classical view of computing positions computation as a closed-box transformation of inputs (rational numbers or finite strings) to outputs. According to the interactive view of computing, computation is an ongoing interactive process rather than a function-based transformation of an input to an output. Specifically, communication with the outside world happens during the computation, not before or after it. This approach radically changes our understanding of what is computation and how it is modeled. The acceptance of interaction as a new paradigm is hindered by the Strong Church–Turing Thesis (SCT), the widespread belief that Turing Machines (TMs) capture all computation, so models of computation more expressive than TMs are impossible. In this paper, we show that SCT reinterprets the original Church–Turing Thesis (CTT) in a way that Turing never intended; its commonly assumed equivalence to the original is a myth. We identify and analyze the historical reasons for the widespread belief in SCT. Only by accepting that it is false can we begin to adopt interaction as an alternative paradigm of computation. We present Persistent Turing Machines (PTMs), that extend TMs to capture sequential interaction. PTMs allow us to formulate the Sequential Interaction Thesis, going beyond the expressiveness of TMs and of the CTT. The paradigm shift to interaction provides an alternative understanding of the nature of computing that better reflects the services provided by today’s computing technology.},
	language = {en},
	number = {1},
	urldate = {2023-06-22},
	journal = {Minds and Machines},
	author = {Goldin, Dina and Wegner, Peter},
	month = mar,
	year = {2008},
	pages = {17--38},
}

@article{wegner_interactive_1998,
	title = {Interactive foundations of computing},
	volume = {192},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/S0304397597001540},
	doi = {10.1016/S0304-3975(97)00154-0},
	abstract = {The claim that interactive systems have richer behavior than algorithms is surprisingly easy to prove. Turing machines cannot model interaction machines (which extend Turing machines with interactive input/output) because interaction is not expressible by a finite initial input string. Interaction machines extend the Chomsky hierarchy, are modeled by interaction grammars, and precisely capture fuzzy concepts like open systems and empirical computer science. Computable functions cannot model real-world behavior because functions are too strong an abstraction, sacrificing the ability to model time and other real-world properties to realize formal tractability. Part I of this paper examines extensions to interactive models for algorithms, machines, grammars, and semantics, while Part II considers the expressiveness of different forms of interaction. Interactive identity machines are already more powerful than Turing machines, while noninteractive parallelism and distribution are algorithmic. The extension of Turing to interaction machines parallels that of the lambda to the pi calculus. Asynchronous and nonserializable interaction are shown to be more expressive than sequential interaction (multiple streams are more expressive than a single stream). In Part III, it is shown that interaction machines cannot be described by sound and complete first-order logics (a form of Godel incompleteness), and that incompleteness is inherently necessary to realize greater expressiveness. In the final section the robustness of interactive models in expressing open systems, programming in the large, graphical user interfaces, and agent-oriented artificial intelligence is compared to the robustness of Turing machines. Less technical discussion of these ideas may be found in [25–27]. Applications of interactive models to coordination, objects and components, patterns and frameworks, software engineering, and AI are examined elsewhere [28,29]. The propositions P1-P36 embody the principal claims, while observations 01 through 040 provide additional insights.},
	language = {en},
	number = {2},
	urldate = {2023-06-22},
	journal = {Theoretical Computer Science},
	author = {Wegner, Peter},
	month = feb,
	year = {1998},
	pages = {315--351},
}

@book{rooij_cognition_2019,
	address = {Cambridge ; New York, NY},
	title = {Cognition and intractability: a guide to classical and parameterized complexity analysis},
	isbn = {978-1-107-04399-2 978-1-108-72897-3},
	shorttitle = {Cognition and intractability},
	publisher = {Cambridge University Press},
	editor = {Rooij, Iris van and Blokpoel, Mark and Kwisthout, Johan and Wareham, Todd},
	year = {2019},
}

@article{goldin_turing_2002,
	series = {{EXPRESS}'01, 8th {International} {Workshop} on {Expressiveness} in {Concurrency} ({Satellite} {Event} of {CONCUR} 2001)},
	title = {Turing {Machines}, {Transition} {Systems}, and {Interaction}},
	volume = {52},
	issn = {1571-0661},
	url = {https://www.sciencedirect.com/science/article/pii/S1571066104002208},
	doi = {10.1016/S1571-0661(04)00220-8},
	abstract = {We present Persistent Turing Machines (PTMs), a new way of interpreting Turing-machine computation, one that is both interactive and persistent. We show that the class of PTMs is isomorphic to a very general class of effective transition systems. One may therefore conclude that the extensions to the Turing-machine model embodied in PTMs are sufficient to make Turing machines expressively equivalent to transition systems. We also define the persistent stream language (PSL) of a PTM and a corresponding notion of PSL-equivalence, and consider the infinite hierarchy of successively finer equivalences for PTMs over finite interaction-stream prefixes. We show that the limit of this hierarchy is strictly coarser than PSL-equivalence, a “gap” whose presence can be attributed to the fact that the transition systems corresponding to PTM computations naturally exhibit unbounded nondeterminism. We also consider amnesic PTMs and a corresponding notion of equivalence based on amnesic stream languages (ASLs). It can be argued that amnesic stream languages are representative of the classical view of Turing-machine computation. We show that the class of ASLs is strictly contained in the class of PSLs. Furthermore, the hierarchy of PTM equivalence relations collapses for the subclass of amnesic PTMs. These results indicate that, in a stream-based setting, the extension of the Turing-machine model with persistence is a nontrivial one, and provide a formal foundation for reasoning about programming concepts such as objects with static attributes.},
	language = {en},
	number = {1},
	urldate = {2023-06-22},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Goldin, Dina Q. and Smolka, Scott A. and Wegner, Peter},
	month = feb,
	year = {2002},
	pages = {120--136},
}

@article{prasse_why_1998,
	title = {Why {Church}'s {Thesis} {Still} {Holds}. {Some} {Notes} on {Peter} {Wegner}'s {Tracts} on {Interaction} and {Computability}},
	volume = {41},
	issn = {1460-2067},
	doi = {10.1093/comjnl/41.6.357},
	abstract = {Peter Wegner's definition of computability differs markedly from the classical term as established by Church, Kleene, Markov, Post, Turing et al. Wegner identifies interaction as the main feature of today's systems which is lacking in the classical treatment of computability. We compare the different approaches and argue whether or not Wegner's criticism is appropriate. Taking into account the major arguments from the literature, we show that Church's thesis still holds.},
	number = {6},
	journal = {The Computer Journal},
	author = {Prasse, M. and Rittgen, P.},
	month = jan,
	year = {1998},
	note = {Conference Name: The Computer Journal},
	pages = {357--362},
}

@inproceedings{beaudouin-lafon_designing_2004,
	address = {New York, NY, USA},
	series = {{AVI} '04},
	title = {Designing interaction, not interfaces},
	isbn = {978-1-58113-867-2},
	url = {https://doi.org/10.1145/989863.989865},
	doi = {10.1145/989863.989865},
	abstract = {Although the power of personal computers has increased 1000-fold over the past 20 years, user interfaces remain essentially the same. Innovations in HCI research, particularly novel interaction techniques, are rarely incorporated into products. In this paper I argue that the only way to significantly improve user interfaces is to shift the research focus from designing interfaces to designing interaction. This requires powerful interaction models, a better understanding of both the sensory-motor details of interaction and a broader view of interaction in the context of use. It also requires novel interaction architectures that address reinterpretability, resilience and scalability.},
	urldate = {2023-06-22},
	booktitle = {Proceedings of the working conference on {Advanced} visual interfaces},
	publisher = {Association for Computing Machinery},
	author = {Beaudouin-Lafon, Michel},
	year = {2004},
	pages = {15--22},
}

@incollection{weyns_patterns_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On {Patterns} for {Decentralized} {Control} in {Self}-{Adaptive} {Systems}},
	isbn = {978-3-642-35813-5},
	url = {https://doi.org/10.1007/978-3-642-35813-5_4},
	abstract = {Self-adaptation is typically realized using a control loop. One prominent approach for organizing a control loop in self-adaptive systems is by means of four components that are responsible for the primary functions of self-adaptation: Monitor, Analyze, Plan, and Execute, together forming a MAPE loop. When systems are large, complex, and heterogeneous, a single MAPE loop may not be sufficient for managing all adaptation in a system, so multiple MAPE loops may be introduced. In self-adaptive systems with multiple MAPE loops, decisions about how to decentralize each of the MAPE functions must be made. These decisions involve how and whether the corresponding functions from multiple loops are to be coordinated (e.g., planning components coordinating to prepare a plan for an adaptation). To foster comprehension of self-adaptive systems with multiple MAPE loops and support reuse of known solutions, it is crucial that we document common design approaches for engineers. As such systematic knowledge is currently lacking, it is timely to reflect on these systems to: (a) consolidate the knowledge in this area, and (b) to develop a systematic approach for describing different types of control in self-adaptive systems. We contribute with a simple notation for describing interacting MAPE loops, which we believe helps in achieving (b), and we use this notation to describe a number of existing patterns of interacting MAPE loops, to begin to fulfill (a). From our study, we outline numerous remaining research challenges in this area.},
	language = {en},
	urldate = {2023-06-22},
	booktitle = {Software {Engineering} for {Self}-{Adaptive} {Systems} {II}: {International} {Seminar}, {Dagstuhl} {Castle}, {Germany}, {October} 24-29, 2010 {Revised} {Selected} and {Invited} {Papers}},
	publisher = {Springer},
	author = {Weyns, Danny and Schmerl, Bradley and Grassi, Vincenzo and Malek, Sam and Mirandola, Raffaela and Prehofer, Christian and Wuttke, Jochen and Andersson, Jesper and Giese, Holger and Göschka, Karl M.},
	editor = {de Lemos, Rogério and Giese, Holger and Müller, Hausi A. and Shaw, Mary},
	year = {2013},
	doi = {10.1007/978-3-642-35813-5_4},
	pages = {76--107},
}

@book{aigner_visualization_2011,
	address = {London},
	series = {Human-{Computer} {Interaction} {Series}},
	title = {Visualization of {Time}-{Oriented} {Data}},
	isbn = {978-0-85729-078-6 978-0-85729-079-3},
	url = {https://link.springer.com/10.1007/978-0-85729-079-3},
	language = {en},
	urldate = {2023-06-22},
	publisher = {Springer},
	author = {Aigner, Wolfgang and Miksch, Silvia and Schumann, Heidrun and Tominski, Christian},
	year = {2011},
	doi = {10.1007/978-0-85729-079-3},
}

@article{torrance_spur_2019,
	title = {The spur of the moment: what jazz improvisation tells cognitive science},
	volume = {34},
	issn = {1435-5655},
	shorttitle = {The spur of the moment},
	url = {https://doi.org/10.1007/s00146-018-0838-4},
	doi = {10.1007/s00146-018-0838-4},
	abstract = {Improvisation is ubiquitous in life. It deserves, we suggest, to occupy a more central role in cognitive science. In the current paper, we take the case of jazz improvisation as a rich model domain from which to explore the nature of improvisation and expertise more generally. We explore the activity of the jazz improviser against the theoretical backdrop of Dreyfus’s account of expertise as well as of enactivist and 4E accounts of cognition and action. We argue that enactivist and 4E accounts provide a rich source of insights on improvisation that go beyond Dreyfus’s notion of skilled coping, for example, through the central enactivist notion of “sense-making”. At the same time, however, we see improvisation also as suggesting an extension of enactivist theory. We see expert improvisers, in music and in life, as walking on a path of open-ended expansion of their mindful experiential relation with their doing. At the heart of an improviser’s expertise (and of day-to-day living), we propose, lies a form of “higher-level inner sense-making” that spontaneously creates novel forms of agentive goal-directedness in the moment. Our account thus supplants Dreyfus’s idea of the ego-less absorbed expert by that of a mindful (i.e. present in the moment) improviser enacting spontaneous expressions of herself, in music or in life.},
	language = {en},
	number = {2},
	urldate = {2023-06-22},
	journal = {AI \& SOCIETY},
	author = {Torrance, Steve and Schumann, Frank},
	month = jun,
	year = {2019},
	pages = {251--268},
}

@misc{rooij_against_2022,
	title = {Against automated plagiarism},
	url = {https://irisvanrooijcogsci.com/2022/12/29/against-automated-plagiarism/},
	abstract = {I’ve been asked, in various roles1, to give my opinion on the challenges posed by Large Language Models (LLMs)2, also known as “stochastic parrots” (Bender, Gebru, McMillan-Major,…},
	language = {en},
	urldate = {2023-06-21},
	journal = {Iris van Rooij},
	author = {Rooij, Iris Van},
	month = dec,
	year = {2022},
}

@misc{harrison_chatgpt_nodate,
	title = {{ChatGPT} {Is} {Just} an {Automated} {Mansplaining} {Machine}},
	url = {https://futurism.com/artificial-intelligence-automated-mansplaining-machine},
	abstract = {Artificial intelligence like ChatGPT is often wrong, and yet it's somehow always certain, even tending to double down on incorrect answers. Sound familiar?},
	urldate = {2023-06-21},
	journal = {Futurism},
	author = {Harrison, Maggie},
}

@article{pilling_forget_2019,
	title = {Forget the {Singularity}, its mundane artificial intelligence that should be our immediate concern},
	volume = {22},
	issn = {1460-6925, 1756-3062},
	url = {https://www.tandfonline.com/doi/full/10.1080/14606925.2019.1594979},
	doi = {10.1080/14606925.2019.1594979},
	language = {en},
	number = {sup1},
	urldate = {2023-06-21},
	journal = {The Design Journal},
	author = {Pilling, Franziska and Coulton, Paul},
	month = apr,
	year = {2019},
	pages = {1135--1146},
}

@article{stevanovic_accountability_2023,
	title = {Accountability and interactional inequality: the management of problems of interaction as a matter of cultural ideals and ideologies},
	volume = {8},
	issn = {2297-7775},
	shorttitle = {Accountability and interactional inequality},
	url = {https://www.frontiersin.org/articles/10.3389/fsoc.2023.1204086},
	abstract = {In the existing sociological literature, the notion of accountability is seen both as a tool of sense-making (intelligibility side of accountability) and as a way of maintaining larger social order (normativity side of accountability). This paper points to drastically different ways of treating an interactional violation, depending on the precise framework within which the accountabilities associated with the violation are interpreted. The normative side of accountability involves the idea of interactional inequality—that is, the notion that people are not equally held accountable for their interactional violations. I suggest that such inequalities are strengthened by the prevailing cultural ideals and ideologies of interaction according to which a competent participant can solve interactional problems as they emerge. Problems of interaction are therefore commonly let pass, and if addressed, likely to be interpreted within the framework of intelligibility. This means that the violators are likely to get away from being held accountable in the normative sense of the term. As a result, I argue, many interactional problems are commonly beyond effective intervention. In its focus on the intelligibility side of accountability CA has, not only trouble addressing interactional inequalities, but it may also inherently undermine the severity of the inequalities to be addressed. A more critical, socially and societally relevant CA would thus benefit from a more explicit engagement with the normative side of the notion.},
	urldate = {2023-06-19},
	journal = {Frontiers in Sociology},
	author = {Stevanovic, Melisa},
	year = {2023},
}

@inproceedings{liesenfeld_who_2023,
	title = {Who says what when? {Why} timing is mission-critical for conversational speech recognition and dialogue systems},
	author = {Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark},
	year = {2023},
}

@article{ivanova_lexical_2021,
	title = {Lexical alignment to non-native speakers},
	volume = {12},
	issn = {2152-9620},
	doi = {10.5210/dad.2021.205},
	abstract = {Two picture-matching-game experiments investigated if lexical-referential alignment to non-native speakers is enhanced by a desire to aid communicative success (by saying something the conversation partner can certainly understand), a form of audience design. In  Experiment 1, a group of native speakers of British English that was not given evidence of their conversation partners’ picture-matching performance showed more alignment to non-native than to native speakers, while another group that was given such evidence aligned equivalently to the two types of speaker. Experiment 2, conducted with speakers of Castilian Spanish, replicated the greater alignment to non-native than native speakers without feedback. However, Experiment 2 also showed that production of grammatical errors by the confederate produced no additional increase of alignment even though making errors suggests lower communicative competence. We suggest that this pattern is consistent with another collaborative strategy, the desire to model correct usage. Together, these results support a role for audience design in alignment to non-native speakers in structured task-based dialogue, but one that is strategically deployed only when deemed necessary.},
	number = {2},
	journal = {Dialogue and Discourse},
	author = {Ivanova, Iva and Branigan, Holly P. and McLean, Janet and Costa, Albert and Pickering, Martin J.},
	month = oct,
	year = {2021},
	pages = {145--173},
}

@inproceedings{liesenfeld_opening_2023,
	address = {Eindhoven},
	title = {Opening up {ChatGPT}: tracking openness, transparency, and accountability in instruction-tuned text generators},
	abstract = {Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI's ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as `open source', many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.},
	booktitle = {Proceedings of {CUI}'23},
	author = {Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark},
	year = {2023},
}

@misc{noauthor_introducing_nodate,
	title = {Introducing {ChatGPT}},
	url = {https://openai.com/blog/chatgpt},
	abstract = {We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.},
	language = {en-US},
	urldate = {2023-06-13},
}

@article{kreps_all_2022,
	title = {All the {News} {That}’s {Fit} to {Fabricate}: {AI}-{Generated} {Text} as a {Tool} of {Media} {Misinformation}},
	volume = {9},
	issn = {2052-2630, 2052-2649},
	shorttitle = {All the {News} {That}’s {Fit} to {Fabricate}},
	url = {https://www.cambridge.org/core/journals/journal-of-experimental-political-science/article/all-the-news-thats-fit-to-fabricate-aigenerated-text-as-a-tool-of-media-misinformation/40F27F0661B839FA47375F538C19FA59},
	doi = {10.1017/XPS.2020.37},
	abstract = {Online misinformation has become a constant; only the way actors create and distribute that information is changing. Advances in artificial intelligence (AI) such as GPT-2 mean that actors can now synthetically generate text in ways that mimic the style and substance of human-created news stories. We carried out three original experiments to study whether these AI-generated texts are credible and can influence opinions on foreign policy. The first evaluated human perceptions of AI-generated text relative to an original story. The second investigated the interaction between partisanship and AI-generated news. The third examined the distributions of perceived credibility across different AI model sizes. We find that individuals are largely incapable of distinguishing between AI- and human-generated text; partisanship affects the perceived credibility of the story; and exposure to the text does little to change individuals’ policy views. The findings have important implications in understanding AI in online misinformation campaigns.},
	language = {en},
	number = {1},
	urldate = {2023-06-13},
	journal = {Journal of Experimental Political Science},
	author = {Kreps, Sarah and McCain, R. Miles and Brundage, Miles},
	month = mar,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	pages = {104--117},
}

@article{kalluri_dont_2020,
	title = {Don’t ask if artificial intelligence is good or fair, ask how it shifts power},
	volume = {583},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-020-02003-2},
	doi = {10.1038/d41586-020-02003-2},
	abstract = {Those who could be exploited by AI should be shaping its projects.},
	language = {en},
	number = {7815},
	urldate = {2023-06-13},
	journal = {Nature},
	author = {Kalluri, Pratyusha},
	month = jul,
	year = {2020},
	note = {Bandiera\_abtest: a
Cg\_type: World View
Number: 7815
Publisher: Nature Publishing Group
Subject\_term: Research data, Research management, Society, Ethics},
	pages = {169--169},
}

@misc{carlini_extracting_2021,
	title = {Extracting {Training} {Data} from {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2012.07805},
	doi = {10.48550/arXiv.2012.07805},
	abstract = {It has become common to publish large (billion parameter) language models that have been trained on private datasets. This paper demonstrates that in such settings, an adversary can perform a training data extraction attack to recover individual training examples by querying the language model. We demonstrate our attack on GPT-2, a language model trained on scrapes of the public Internet, and are able to extract hundreds of verbatim text sequences from the model's training data. These extracted examples include (public) personally identifiable information (names, phone numbers, and email addresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible even though each of the above sequences are included in just one document in the training data. We comprehensively evaluate our extraction attack to understand the factors that contribute to its success. Worryingly, we find that larger models are more vulnerable than smaller models. We conclude by drawing lessons and discussing possible safeguards for training large language models.},
	urldate = {2023-06-13},
	publisher = {arXiv},
	author = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and Oprea, Alina and Raffel, Colin},
	month = jun,
	year = {2021},
	note = {arXiv:2012.07805 [cs]},
}

@article{cai_challenges_2015,
	title = {The {Challenges} of {Data} {Quality} and {Data} {Quality} {Assessment} in the {Big} {Data} {Era}},
	volume = {14},
	issn = {1683-1470},
	url = {https://datascience.codata.org/articles/10.5334/dsj-2015-002},
	doi = {10.5334/dsj-2015-002},
	abstract = {High-quality data are the precondition for analyzing and using big data and for guaranteeing the value of the data. Currently, comprehensive analysis and research of quality standards and quality assessment methods for big data are lacking. First, this paper summarizes reviews of data quality research. Second, this paper analyzes the data characteristics of the big data environment, presents quality challenges faced by big data, and formulates a hierarchical data quality framework from the perspective of data users. This framework consists of big data quality dimensions, quality characteristics, and quality indexes. Finally, on the basis of this framework, this paper constructs a dynamic assessment process for data quality. This process has good expansibility and adaptability and can meet the needs of big data quality assessment. The research results enrich the theoretical scope of big data and lay a solid foundation for the future by establishing an assessment model and studying evaluation algorithms.},
	language = {en-US},
	number = {0},
	urldate = {2023-06-13},
	author = {Cai, Li and Zhu, Yangyong},
	month = may,
	year = {2015},
	note = {Number: 0
Publisher: Ubiquity Press},
	pages = {2},
}

@inproceedings{blodgett_language_2020,
	address = {Online},
	title = {Language ({Technology}) is {Power}: {A} {Critical} {Survey} of “{Bias}” in {NLP}},
	shorttitle = {Language ({Technology}) is {Power}},
	url = {https://aclanthology.org/2020.acl-main.485},
	doi = {10.18653/v1/2020.acl-main.485},
	abstract = {We survey 146 papers analyzing “bias” in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing “bias” is an inherently normative process. We further find that these papers' proposed quantitative techniques for measuring or mitigating “bias” are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing “bias” in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of “bias”—i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements—and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.},
	urldate = {2023-06-13},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Blodgett, Su Lin and Barocas, Solon and Daumé III, Hal and Wallach, Hanna},
	month = jul,
	year = {2020},
	pages = {5454--5476},
}

@misc{noauthor_license_nodate,
	title = {License - a {Hugging} {Face} {Space} by bigscience},
	url = {https://huggingface.co/spaces/bigscience/license},
	abstract = {Discover amazing ML apps made by the community},
	urldate = {2023-06-13},
}

@misc{zhou_controlled_2023,
	title = {Controlled {Text} {Generation} with {Natural} {Language} {Instructions}},
	url = {https://arxiv.org/abs/2304.14293v2},
	abstract = {Large language models generate fluent texts and can follow natural language instructions to solve a wide range of tasks without task-specific training. Nevertheless, it is notoriously difficult to control their generation to satisfy the various constraints required by different applications. In this work, we present InstructCTG, a controlled text generation framework that incorporates different constraints by conditioning on natural language descriptions and demonstrations of the constraints. In particular, we first extract the underlying constraints of natural texts through a combination of off-the-shelf NLP tools and simple heuristics. We then verbalize the constraints into natural language instructions to form weakly supervised training data. By prepending natural language descriptions of the constraints and a few demonstrations, we fine-tune a pre-trained language model to incorporate various types of constraints. Compared to existing search-based or score-based methods, InstructCTG is more flexible to different constraint types and has a much smaller impact on the generation quality and speed because it does not modify the decoding procedure. Additionally, InstructCTG allows the model to adapt to new constraints without re-training through the use of few-shot task generalization and in-context learning abilities of instruction-tuned language models.},
	language = {en},
	urldate = {2023-06-13},
	journal = {arXiv.org},
	author = {Zhou, Wangchunshu and Jiang, Yuchen Eleanor and Wilcox, Ethan and Cotterell, Ryan and Sachan, Mrinmaya},
	month = apr,
	year = {2023},
}

@inproceedings{solaiman_gradient_2023,
	address = {New York, NY, USA},
	series = {{FAccT} '23},
	title = {The {Gradient} of {Generative} {AI} {Release}: {Methods} and {Considerations}},
	isbn = {9798400701924},
	shorttitle = {The {Gradient} of {Generative} {AI} {Release}},
	url = {https://dl.acm.org/doi/10.1145/3593013.3593981},
	doi = {10.1145/3593013.3593981},
	abstract = {As increasingly powerful generative AI systems are developed, the release method greatly varies. We propose a framework to assess six levels of access to generative AI systems: fully closed; gradual or staged access; hosted access; cloud-based or API access; downloadable access; and fully open. Each level, from fully closed to fully open, can be viewed as an option along a gradient. We outline key considerations across this gradient: release methods come with tradeoffs, especially around the tension between concentrating power and mitigating risks. Diverse and multidisciplinary perspectives are needed to examine and mitigate risk in generative AI systems from conception to deployment. We show trends in generative system release over time, noting closedness among large companies for powerful systems and openness among organizations founded on principles of openness. We also enumerate safety controls and guardrails for generative systems and necessary investments to improve future releases.},
	urldate = {2023-06-13},
	booktitle = {Proceedings of the 2023 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Solaiman, Irene},
	month = jun,
	year = {2023},
	pages = {111--122},
}

@article{he_galaxy_2022,
	title = {{GALAXY}: {A} {Generative} {Pre}-trained {Model} for {Task}-{Oriented} {Dialog} with {Semi}-supervised {Learning} and {Explicit} {Policy} {Injection}},
	volume = {36},
	copyright = {Copyright (c) 2022 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {{GALAXY}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/21320},
	doi = {10.1609/aaai.v36i10.21320},
	abstract = {Pre-trained models have proved to be powerful in enhancing task-oriented dialog systems. However, current pre-training methods mainly focus on enhancing dialog understanding and generation tasks while neglecting the exploitation of dialog policy. In this paper, we propose GALAXY, a novel pre-trained dialog model that explicitly learns dialog policy from limited labeled dialogs and large-scale unlabeled dialog corpora via semi-supervised learning. Specifically, we introduce a dialog act prediction task for policy optimization during pre-training and employ a consistency regularization term to refine the learned representation with the help of unlabeled dialogs. We also implement a gating mechanism to weigh suitable unlabeled dialog samples. Empirical results show that GALAXY substantially improves the performance of task-oriented dialog systems, and achieves new state-of-the-art results on benchmark datasets: In-Car, MultiWOZ2.0 and MultiWOZ2.1, improving their end-to-end combined scores by 2.5, 5.3 and 5.5 points, respectively. We also show that GALAXY has a stronger few-shot ability than existing models under various low-resource settings. For reproducibility, we release the code and data at https://github.com/siat-nlp/GALAXY.},
	language = {en},
	number = {10},
	urldate = {2023-05-17},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {He, Wanwei and Dai, Yinpei and Zheng, Yinhe and Wu, Yuchuan and Cao, Zheng and Liu, Dermot and Jiang, Peng and Yang, Min and Huang, Fei and Si, Luo and Sun, Jian and Li, Yongbin},
	month = jun,
	year = {2022},
	note = {Number: 10},
	pages = {10749--10757},
}

@misc{cheng_conversational_2022,
	title = {The {Conversational} {Short}-phrase {Speaker} {Diarization} ({CSSD}) {Task}: {Dataset}, {Evaluation} {Metric} and {Baselines}},
	shorttitle = {The {Conversational} {Short}-phrase {Speaker} {Diarization} ({CSSD}) {Task}},
	url = {http://arxiv.org/abs/2208.08042},
	doi = {10.48550/arXiv.2208.08042},
	abstract = {The conversation scenario is one of the most important and most challenging scenarios for speech processing technologies because people in conversation respond to each other in a casual style. Detecting the speech activities of each person in a conversation is vital to downstream tasks, like natural language processing, machine translation, etc. People refer to the detection technology of "who speak when" as speaker diarization (SD). Traditionally, diarization error rate (DER) has been used as the standard evaluation metric of SD systems for a long time. However, DER fails to give enough importance to short conversational phrases, which are short but important on the semantic level. Also, a carefully and accurately manually-annotated testing dataset suitable for evaluating the conversational SD technologies is still unavailable in the speech community. In this paper, we design and describe the Conversational Short-phrases Speaker Diarization (CSSD) task, which consists of training and testing datasets, evaluation metric and baselines. In the dataset aspect, despite the previously open-sourced 180-hour conversational MagicData-RAMC dataset, we prepare an individual 20-hour conversational speech test dataset with carefully and artificially verified speakers timestamps annotations for the CSSD task. In the metric aspect, we design the new conversational DER (CDER) evaluation metric, which calculates the SD accuracy at the utterance level. In the baseline aspect, we adopt a commonly used method: Variational Bayes HMM x-vector system, as the baseline of the CSSD task. Our evaluation metric is publicly available at https://github.com/SpeechClub/CDER\_Metric.},
	urldate = {2023-06-12},
	publisher = {arXiv},
	author = {Cheng, Gaofeng and Chen, Yifan and Yang, Runyan and Li, Qingxuan and Yang, Zehui and Ye, Lingxuan and Zhang, Pengyuan and Zhang, Qingqing and Xie, Lei and Qian, Yanmin and Lee, Kong Aik and Yan, Yonghong},
	month = aug,
	year = {2022},
	note = {arXiv:2208.08042 [cs, eess]},
	keywords = {Computer Science - Computation and Language, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@book{glenn_studies_2003,
	address = {Mahwah, N.J},
	series = {{LEA}'s communication series},
	title = {Studies in language and social interaction: in honor of {Robert} {Hopper}},
	isbn = {978-0-8058-3732-2},
	shorttitle = {Studies in language and social interaction},
	publisher = {Erlbaum},
	editor = {Glenn, Phillip J. and LeBaron, Curtis D. and Mandelbaum, Jenny S.},
	year = {2003},
}

@article{van_dis_chatgpt_2023,
	title = {{ChatGPT}: five priorities for research},
	volume = {614},
	copyright = {2023 Springer Nature Limited},
	shorttitle = {{ChatGPT}},
	url = {https://www.nature.com/articles/d41586-023-00288-7},
	doi = {10.1038/d41586-023-00288-7},
	abstract = {Conversational AI is a game-changer for science. Here’s how to respond.},
	language = {en},
	number = {7947},
	urldate = {2023-06-09},
	journal = {Nature},
	author = {van Dis, Eva A. M. and Bollen, Johan and Zuidema, Willem and van Rooij, Robert and Bockting, Claudi L.},
	month = feb,
	year = {2023},
	note = {Bandiera\_abtest: a
Cg\_type: Comment
Number: 7947
Publisher: Nature Publishing Group
Subject\_term: Computer science, Research management, Publishing, Machine learning},
	pages = {224--226},
}

@article{hipolito_enactive_2023,
	title = {Enactive artificial intelligence: subverting gender norms in human-robot interaction},
	volume = {17},
	issn = {1662-5218},
	shorttitle = {Enactive artificial intelligence},
	url = {https://www.frontiersin.org/articles/10.3389/fnbot.2023.1149303},
	abstract = {IntroductionThis paper presents Enactive Artificial Intelligence (eAI) as a gender-inclusive approach to AI, emphasizing the need to address social marginalization resulting from unrepresentative AI design.MethodsThe study employs a multidisciplinary framework to explore the intersectionality of gender and technoscience, focusing on the subversion of gender norms within Robot-Human Interaction in AI.ResultsThe results reveal the development of four ethical vectors, namely explainability, fairness, transparency, and auditability, as essential components for adopting an inclusive stance and promoting gender-inclusive AI.DiscussionBy considering these vectors, we can ensure that AI aligns with societal values, promotes equity and justice, and facilitates the creation of a more just and equitable society.},
	urldate = {2023-06-09},
	journal = {Frontiers in Neurorobotics},
	author = {Hipólito, Inês and Winkle, Katie and Lie, Merete},
	year = {2023},
}

@inproceedings{shah_situating_2022,
	address = {New York, NY, USA},
	series = {{CHIIR} '22},
	title = {Situating {Search}},
	isbn = {978-1-4503-9186-3},
	url = {https://dl.acm.org/doi/10.1145/3498366.3505816},
	doi = {10.1145/3498366.3505816},
	abstract = {Search systems, like many other applications of machine learning, have become increasingly complex and opaque. The notions of relevance, usefulness, and trustworthiness with respect to information were already overloaded and often difficult to articulate, study, or implement. Newly surfaced proposals that aim to use large language models to generate relevant information for a user’s needs pose even greater threat to transparency, provenance, and user interactions in a search system. In this perspective paper we revisit the problem of search in the larger context of information seeking and argue that removing or reducing interactions in an effort to retrieve presumably more relevant information can be detrimental to many fundamental aspects of search, including information verification, information literacy, and serendipity. In addition to providing suggestions for counteracting some of the potential problems posed by such models, we present a vision for search systems that are intelligent and effective, while also providing greater transparency and accountability.},
	urldate = {2023-06-08},
	booktitle = {Proceedings of the 2022 {Conference} on {Human} {Information} {Interaction} and {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Shah, Chirag and Bender, Emily M.},
	year = {2022},
	pages = {221--232},
}

@article{lucarini_conversational_2022,
	title = {Conversational metrics, psychopathological dimensions and self-disturbances in patients with schizophrenia},
	volume = {272},
	issn = {1433-8491},
	url = {https://doi.org/10.1007/s00406-021-01329-w},
	doi = {10.1007/s00406-021-01329-w},
	abstract = {Difficulties in interpersonal communication, including conversational skill impairments, are core features of schizophrenia. However, very few studies have performed conversation analyses in a clinical population of schizophrenia patients. Here we investigate the conversational patterns of dialogues in schizophrenia patients to assess possible associations with symptom dimensions, subjective self-disturbances and social functioning. Thirty-five schizophrenia patients were administered the Positive and Negative Syndrome Scale (PANSS), the Clinical Language Disorder Rating Scale (CLANG), the Scale for the Assessment of Thought, Language and Communication (TLC), the Examination of Anomalous Self-Experience Scale (EASE), and the Social and Occupational Functioning Assessment Scale (SOFAS). Moreover, participants underwent a recorded semi-structured interview, to extract conversational variables. Conversational data were associated with negative symptoms and social functioning, but not with positive or disorganization symptoms. A significant positive correlation was found between “pause duration” and the EASE item “Spatialization of thought”. The present study suggests an association between conversational patterns and negative symptom dimension of schizophrenia. Moreover, our findings evoke a relationship between the natural fluidity of conversation and of the natural unraveling of thoughts.},
	language = {en},
	number = {6},
	urldate = {2023-06-08},
	journal = {European Archives of Psychiatry and Clinical Neuroscience},
	author = {Lucarini, Valeria and Cangemi, Francesco and Daniel, Benyamin Daniel and Lucchese, Jacopo and Paraboschi, Francesca and Cattani, Chiara and Marchesi, Carlo and Grice, Martine and Vogeley, Kai and Tonna, Matteo},
	month = sep,
	year = {2022},
	pages = {997--1005},
}

@article{chapple_quantitative_1939,
	title = {Quantitative {Analysis} of the {Interaction} of {Individuals}},
	volume = {25},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.25.2.58},
	doi = {10.1073/pnas.25.2.58},
	language = {en},
	number = {2},
	urldate = {2023-06-08},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Chapple, Eliot D.},
	month = feb,
	year = {1939},
	pages = {58--67},
}

@article{cangemi_content-free_2023,
	title = {Content-free speech activity records: interviews with people with schizophrenia},
	issn = {1574-0218},
	shorttitle = {Content-free speech activity records},
	url = {https://doi.org/10.1007/s10579-023-09666-z},
	doi = {10.1007/s10579-023-09666-z},
	abstract = {Schizophrenia is characterised by a variety of symptoms, many of which are expressed verbally. However, privacy concerns limit the possibility of collecting and sharing large corpora of schizophrenic speech. As a result, variability in the communicative behaviour of individuals with schizophrenia is currently poorly understood. In this study we explore how far content-free speech activity records can successfully profile the behaviour of patients with schizophrenia. We used data from one of the very few publicly available corpora of conversations with patients with schizophrenia, featuring interviews between a therapist and three patients with different symptoms. Crucially, in this study we annotated only moments of speech and silence during the interview, and we entirely discarded the verbal content of the interview. In this way we perform a type of analysis that fully preserves the speakers’ privacy, while still allowing for comparisons with the full original recorded material. We developed several types of analyses and corresponding visualisations from the activity records. Exemplifying these analyses, clear patient-specific profiles can be derived, based on the dimensions of total silence duration and the speech duration of patients and therapists. These findings are consistent with an independent phenomenological assessment of the three patients.},
	language = {en},
	urldate = {2023-06-08},
	journal = {Language Resources and Evaluation},
	author = {Cangemi, Francesco and Grice, Martine and Janz, Alicia and Lucarini, Valeria and Spaniol, Malin and Vogeley, Kai},
	month = jun,
	year = {2023},
}

@inproceedings{borstell_ableist_2023,
	address = {Tórshavn, the Faroe Islands},
	title = {Ableist {Language} {Teching} over {Sign} {Language} {Research}},
	url = {https://aclanthology.org/2023.resourceful-1.1},
	abstract = {The progress made in computer-assisted linguistics has led to huge advances in natural language processing (NLP) research. This research often benefits linguistics in a broader sense, e.g., by digitizing pre-existing data and analyzing ever larger quantities of linguistic data in audio or visual form, such as sign language video data using computer vision methods. A large portion of research conducted on sign languages today is based in computer science and engineering, but much of this research is unfortunately conducted without any input from experts on the linguistics of sign languages or deaf communities. This is obvious from some of the language used in the published research, which regularly contains ableist labels. In this paper, I illustrate this by demonstrating the distribution of words in titles of research papers indexed by Google Scholar. By doing so, we see that the number of tech papers is increasing while the number of linguistics papers is (relatively) decreasing, and that ableist language is more frequent in tech papers. By extension, this suggest that much of the tech-related work on sign languages – heavily under-researched and under-resourced languages – is conducted without collaboration and consultation with deaf communities and experts, against ethical recommendations.},
	urldate = {2023-06-08},
	booktitle = {Proceedings of the {Second} {Workshop} on {Resources} and {Representations} for {Under}-{Resourced} {Languages} and {Domains} ({RESOURCEFUL}-2023)},
	publisher = {Association for Computational Linguistics},
	author = {Börstell, Carl},
	month = may,
	year = {2023},
	pages = {1--10},
}

@article{zuiderveen_borgesius_strengthening_2020,
	title = {Strengthening legal protection against discrimination by algorithms and artificial intelligence},
	volume = {24},
	issn = {1364-2987},
	url = {https://doi.org/10.1080/13642987.2020.1743976},
	doi = {10.1080/13642987.2020.1743976},
	abstract = {Algorithmic decision-making and other types of artificial intelligence (AI) can be used to predict who will commit crime, who will be a good employee, who will default on a loan, etc. However, algorithmic decision-making can also threaten human rights, such as the right to non-discrimination. The paper evaluates current legal protection in Europe against discriminatory algorithmic decisions. The paper shows that non-discrimination law, in particular through the concept of indirect discrimination, prohibits many types of algorithmic discrimination. Data protection law could also help to defend people against discrimination. Proper enforcement of non-discrimination law and data protection law could help to protect people. However, the paper shows that both legal instruments have severe weaknesses when applied to artificial intelligence. The paper suggests how enforcement of current rules can be improved. The paper also explores whether additional rules are needed. The paper argues for sector-specific – rather than general – rules, and outlines an approach to regulate algorithmic decision-making.},
	number = {10},
	urldate = {2023-06-08},
	journal = {The International Journal of Human Rights},
	author = {Zuiderveen Borgesius, Frederik J.},
	month = nov,
	year = {2020},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/13642987.2020.1743976},
	pages = {1572--1593},
}

@misc{wang_self-instruct_2023,
	title = {Self-{Instruct}: {Aligning} {Language} {Models} with {Self}-{Generated} {Instructions}},
	shorttitle = {Self-{Instruct}},
	url = {http://arxiv.org/abs/2212.10560},
	doi = {10.48550/arXiv.2212.10560},
	abstract = {Large "instruction-tuned" language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33\% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5\% absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning. Our code and data are available at https://github.com/yizhongw/self-instruct.},
	urldate = {2023-06-08},
	publisher = {arXiv},
	author = {Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A. and Khashabi, Daniel and Hajishirzi, Hannaneh},
	month = may,
	year = {2023},
	note = {arXiv:2212.10560 [cs]},
}

@misc{kirchenbauer_watermark_2023,
	title = {A {Watermark} for {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2301.10226},
	doi = {10.48550/arXiv.2301.10226},
	abstract = {Potential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient open-source algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of "green" tokens before a word is generated, and then softly promoting use of green tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an information-theoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security.},
	urldate = {2023-06-08},
	publisher = {arXiv},
	author = {Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom},
	month = jun,
	year = {2023},
	note = {arXiv:2301.10226 [cs]},
}

@misc{kim_aligning_2023,
	title = {Aligning {Large} {Language} {Models} through {Synthetic} {Feedback}},
	url = {http://arxiv.org/abs/2305.13735},
	doi = {10.48550/arXiv.2305.13735},
	abstract = {Aligning large language models (LLMs) to human values has become increasingly important as it enables sophisticated steering of LLMs, e.g., making them follow given instructions while keeping them less toxic. However, it requires a significant amount of human demonstrations and feedback. Recently, open-sourced models have attempted to replicate the alignment learning process by distilling data from already aligned LLMs like InstructGPT or ChatGPT. While this process reduces human efforts, constructing these datasets has a heavy dependency on the teacher models. In this work, we propose a novel framework for alignment learning with almost no human labor and no dependency on pre-aligned LLMs. First, we perform reward modeling (RM) with synthetic feedback by contrasting responses from vanilla LLMs with various sizes and prompts. Then, we use the RM for simulating high-quality demonstrations to train a supervised policy and for further optimizing the model with reinforcement learning. Our resulting model, Aligned Language Model with Synthetic Training dataset (ALMoST), outperforms open-sourced models, including Alpaca, Dolly, and OpenAssistant, which are trained on the outputs of InstructGPT or human-annotated instructions. Our 7B-sized model outperforms the 12-13B models in the A/B tests using GPT-4 as the judge with about 75\% winning rate on average.},
	urldate = {2023-06-08},
	publisher = {arXiv},
	author = {Kim, Sungdong and Bae, Sanghwan and Shin, Jamin and Kang, Soyoung and Kwak, Donghyun and Yoo, Kang Min and Seo, Minjoon},
	month = may,
	year = {2023},
	note = {arXiv:2305.13735 [cs]},
}

@misc{gudibande_false_2023,
	title = {The {False} {Promise} of {Imitating} {Proprietary} {LLMs}},
	url = {http://arxiv.org/abs/2305.15717},
	doi = {10.48550/arXiv.2305.15717},
	abstract = {An emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply imitate the proprietary model's capabilities using a weaker open-source model. In this work, we critically analyze this approach. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B--13B), data sources, and imitation data amounts (0.3M--150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models -- they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT's style but not its factuality. Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs. In turn, we argue that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.},
	urldate = {2023-06-08},
	publisher = {arXiv},
	author = {Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn},
	month = may,
	year = {2023},
	note = {arXiv:2305.15717 [cs]},
}

@article{ahmed_growing_2023,
	title = {The growing influence of industry in {AI} research},
	volume = {379},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.ade2420},
	doi = {10.1126/science.ade2420},
	abstract = {Industry is gaining control over the technology’s future
          , 
            For decades, artificial intelligence (AI) research has coexisted in academia and industry, but the balance is tilting toward industry as deep learning, a data-and-compute-driven subfield of AI, has become the leading technology in the field. Industry’s AI successes are easy to see on the news, but those headlines are the heralds of a much larger, more systematic shift as industry increasingly dominates the three key ingredients of modern AI research: computing power, large datasets, and highly skilled researchers. This domination of inputs is translating into AI research outcomes: Industry is becoming more influential in academic publications, cutting-edge models, and key benchmarks. And although these industry investments will benefit consumers, the accompanying research dominance should be a worry for policy-makers around the world because it means that public interest alternatives for important AI tools may become increasingly scarce.},
	language = {en},
	number = {6635},
	urldate = {2023-06-07},
	journal = {Science},
	author = {Ahmed, Nur and Wahed, Muntasir and Thompson, Neil C.},
	month = mar,
	year = {2023},
	pages = {884--886},
}

@inproceedings{mcmillan-major_reusable_2021,
	address = {Online},
	title = {Reusable {Templates} and {Guides} {For} {Documenting} {Datasets} and {Models} for {Natural} {Language} {Processing} and {Generation}: {A} {Case} {Study} of the {HuggingFace} and {GEM} {Data} and {Model} {Cards}},
	shorttitle = {Reusable {Templates} and {Guides} {For} {Documenting} {Datasets} and {Models} for {Natural} {Language} {Processing} and {Generation}},
	url = {https://aclanthology.org/2021.gem-1.11},
	doi = {10.18653/v1/2021.gem-1.11},
	abstract = {Developing documentation guidelines and easy-to-use templates for datasets and models is a challenging task, especially given the variety of backgrounds, skills, and incentives of the people involved in the building of natural language processing (NLP) tools. Nevertheless, the adoption of standard documentation practices across the field of NLP promotes more accessible and detailed descriptions of NLP datasets and models, while supporting researchers and developers in reflecting on their work. To help with the standardization of documentation, we present two case studies of efforts that aim to develop reusable documentation templates – the HuggingFace data card, a general purpose card for datasets in NLP, and the GEM benchmark data and model cards with a focus on natural language generation. We describe our process for developing these templates, including the identification of relevant stakeholder groups, the definition of a set of guiding principles, the use of existing templates as our foundation, and iterative revisions based on feedback.},
	urldate = {2023-06-07},
	booktitle = {Proceedings of the 1st {Workshop} on {Natural} {Language} {Generation}, {Evaluation}, and {Metrics} ({GEM} 2021)},
	publisher = {Association for Computational Linguistics},
	author = {McMillan-Major, Angelina and Osei, Salomey and Rodriguez, Juan Diego and Ammanamanchi, Pawan Sasanka and Gehrmann, Sebastian and Jernite, Yacine},
	month = aug,
	year = {2021},
	pages = {121--135},
}

@article{penedo_refinedweb_2023,
	title = {The {RefinedWeb} {Dataset} for {Falcon} {LLM}: {Outperforming} {Curated} {Corpora} with {Web} {Data}, and {Web} {Data} {Only}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {The {RefinedWeb} {Dataset} for {Falcon} {LLM}},
	url = {https://arxiv.org/abs/2306.01116},
	doi = {10.48550/ARXIV.2306.01116},
	abstract = {Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.},
	urldate = {2023-06-06},
	author = {Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
	year = {2023},
	note = {Publisher: arXiv
Version Number: 1},
}

@misc{xu_baize_2023,
	title = {Baize: {An} {Open}-{Source} {Chat} {Model} with {Parameter}-{Efficient} {Tuning} on {Self}-{Chat} {Data}},
	shorttitle = {Baize},
	url = {http://arxiv.org/abs/2304.01196},
	doi = {10.48550/arXiv.2304.01196},
	abstract = {Chat models, such as ChatGPT, have shown impressive capabilities and have been rapidly adopted across numerous domains. However, these models are only accessible through a restricted API, creating barriers for new research and progress in the field. We propose a pipeline that can automatically generate a high-quality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself. Subsequently, we employ parameter-efficient tuning to enhance LLaMA, an open-source large language model. The resulting model, named Baize, demonstrates good performance in multi-turn dialogues with guardrails that minimize potential risks. Furthermore, we propose a new technique called Self-Distill with Feedback, to further improve the performance of the Baize models with feedback from ChatGPT. The Baize models and data are released for research purposes only at https://github.com/project-baize/baize-chatbot. An online demo is also available at https://huggingface.co/spaces/project-baize/chat-with-baize.},
	urldate = {2023-06-06},
	publisher = {arXiv},
	author = {Xu, Canwen and Guo, Daya and Duan, Nan and McAuley, Julian},
	month = may,
	year = {2023},
	note = {arXiv:2304.01196 [cs]},
}

@article{patterson_carbon_nodate,
	title = {The {Carbon} {Footprint} of {Machine} {Learning} {Training} {Will} {Plateau}, {Then} {Shrink}},
	abstract = {Machine Learning (ML) workloads have rapidly grown in importance, but raised concerns about their carbon footprint. Four best practices can reduce ML training energy by up to 100x and CO2 emissions up to 1000x. By following best practices, overall ML energy use (across research, development, and production) held steady at {\textless}15\% of Google’s total energy use for the past three years. If the whole ML field were to adopt best practices, total carbon emissions from training would reduce. Hence, we recommend that ML papers include emissions explicitly to foster competition on more than just model quality. Estimates of emissions in papers that omitted them have been off 100x–100,000x, so publishing emissions has the added benefit of ensuring accurate accounting. Given the importance of climate change, we must get the numbers right to make certain that we work on its biggest challenges.},
	language = {en},
	author = {Patterson, David and Gonzalez, Joseph and Hölzle, Urs and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
}

@misc{luccioni_estimating_2022,
	title = {Estimating the {Carbon} {Footprint} of {BLOOM}, a {176B} {Parameter} {Language} {Model}},
	url = {http://arxiv.org/abs/2211.02001},
	abstract = {Progress in machine learning (ML) comes with a cost to the environment, given that training ML models requires significant computational resources, energy and materials. In the present article, we aim to quantify the carbon footprint of BLOOM, a 176-billion parameter language model, across its life cycle. We estimate that BLOOM's final training emitted approximately 24.7 tonnes of{\textasciitilde}{\textbackslash}carboneq{\textasciitilde}if we consider only the dynamic power consumption, and 50.5 tonnes if we account for all processes ranging from equipment manufacturing to energy-based operational consumption. We also study the energy requirements and carbon emissions of its deployment for inference via an API endpoint receiving user queries in real-time. We conclude with a discussion regarding the difficulty of precisely estimating the carbon footprint of ML models and future research directions that can contribute towards improving carbon emissions reporting.},
	urldate = {2023-06-05},
	publisher = {arXiv},
	author = {Luccioni, Alexandra Sasha and Viguier, Sylvain and Ligozat, Anne-Laure},
	month = nov,
	year = {2022},
	note = {arXiv:2211.02001 [cs]},
}

@book{mcquillan_resisting_2022,
	address = {Bristol, UK},
	title = {Resisting {AI}: an anti-fascist approach to artificial intelligence},
	isbn = {978-1-5292-1349-2 978-1-5292-1350-8},
	shorttitle = {Resisting {AI}},
	abstract = {"Artificial Intelligence (AI) is everywhere, yet it causes damage to society in ways that can't be fixed. Calling for the restructuring of AI, Dan McQuillan sets out an anti-fascist approach that replaces exclusions with caring and outlines new mechanisms that support collective freedom. Artificial Intelligence (AI) is everywhere, yet it causes damage to society in ways that can't be fixed. Instead of helping to address our current crises, AI causes divisions that limit people's life chances, and even suggests fascistic solutions to social problems. This book provides an analysis of AI's deep learning technology and its political effects and traces the ways that it resonates with contemporary political and social currents, from global austerity to the rise of the far right. Dan McQuillan calls for us to resist AI as we know it and restructure it by prioritising the common good over algorithmic optimisation. He sets out an anti-fascist approach to AI that replaces exclusions with caring, proposes people's councils as a way to restructure AI through mutual aid and outlines new mechanisms that would adapt to changing times by supporting collective freedom. Academically rigorous, yet accessible to a socially engaged readership, this unique book will be of interest to all who wish to challenge the social logic of AI by reasserting the importance of the common good"--Back cover},
	publisher = {Bristol University Press},
	author = {McQuillan, Dan},
	year = {2022},
	note = {OCLC: on1328026349},
}

@article{hong_prediction_2023,
	title = {Prediction as extraction of discretion},
	volume = {10},
	issn = {2053-9517},
	url = {https://doi.org/10.1177/20539517231171053},
	doi = {10.1177/20539517231171053},
	abstract = {I argue that prediction is not primarily a technological means for knowing future outcomes, but a social model for extracting and concentrating discretionary power. Prediction is a ‘relational grammar’ that governs this allocation of discretion: the everyday ability to define one's situation. This extractive dynamic extends a long historical pattern, in which new methods for producing knowledge entail a redistribution of decision-making power. I focus on two contemporary domains: (1) crime and policing are emblematic of how predictive systems are extractive by design, with pre-existing interests governing what is measured and what persistently goes unmeasured. (2) The prediction of productivity demonstrates the long tradition of extracting discretion as a means to extract labour power. Time after time, making human behaviour more predictable for the client of prediction (the manager, the police officer) often means making life and work more unpredictable for the target of prediction (the employee, the urban citizen).},
	language = {en},
	number = {1},
	urldate = {2023-05-26},
	journal = {Big Data \& Society},
	author = {Hong, Sun-ha},
	month = jan,
	year = {2023},
	note = {Publisher: SAGE Publications Ltd},
	pages = {20539517231171053},
}

@book{frankfurt_bullshit_2009,
	title = {On {Bullshit}},
	isbn = {978-1-4008-2653-7},
	abstract = {A \#1 NEW YORK TIMES BESTSELLER One of the most salient features of our culture is that there is so much bullshit. Everyone knows this. Each of us contributes his share. But we tend to take the situation for granted. Most people are rather confident of their ability to recognize bullshit and to avoid being taken in by it. So the phenomenon has not aroused much deliberate concern. We have no clear understanding of what bullshit is, why there is so much of it, or what functions it serves. And we lack a conscientiously developed appreciation of what it means to us. In other words, as Harry Frankfurt writes, "we have no theory." Frankfurt, one of the world's most influential moral philosophers, attempts to build such a theory here. With his characteristic combination of philosophical acuity, psychological insight, and wry humor, Frankfurt proceeds by exploring how bullshit and the related concept of humbug are distinct from lying. He argues that bullshitters misrepresent themselves to their audience not as liars do, that is, by deliberately making false claims about what is true. In fact, bullshit need not be untrue at all. Rather, bullshitters seek to convey a certain impression of themselves without being concerned about whether anything at all is true. They quietly change the rules governing their end of the conversation so that claims about truth and falsity are irrelevant. Frankfurt concludes that although bullshit can take many innocent forms, excessive indulgence in it can eventually undermine the practitioner's capacity to tell the truth in a way that lying does not. Liars at least acknowledge that it matters what is true. By virtue of this, Frankfurt writes, bullshit is a greater enemy of the truth than lies are.},
	language = {en},
	urldate = {2022-12-08},
	publisher = {Princeton University Press},
	author = {Frankfurt, Harry G.},
	month = jan,
	year = {2009},
	doi = {10.1515/9781400826537},
}

@misc{schaul_inside_2023,
	title = {Inside the secret list of websites that make {AI} like {ChatGPT} sound smart},
	url = {https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/},
	abstract = {An analysis of a chatbot data set by The Washington Post reveals the proprietary, personal, and often offensive websites that go into an AI’s training data.},
	language = {en},
	urldate = {2023-06-05},
	journal = {Washington Post},
	author = {Schaul, Kevin and Chen, Szu Yu and Tiku, Nitasha},
	month = apr,
	year = {2023},
}

@article{wachter_counterfactual_2017,
	title = {Counterfactual {Explanations} without {Opening} the {Black} {Box}: {Automated} {Decisions} and the {GDPR}},
	volume = {31},
	shorttitle = {Counterfactual {Explanations} without {Opening} the {Black} {Box}},
	url = {https://heinonline.org/HOL/P?h=hein.journals/hjlt31&i=859},
	language = {eng},
	number = {2},
	urldate = {2023-06-05},
	journal = {Harvard Journal of Law \& Technology (Harvard JOLT)},
	author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
	year = {2017},
	pages = {841--888},
}

@article{wachter_right_2019,
	title = {A {Right} to {Reasonable} {Inferences}: {Re}-{Thinking} {Data} {Protection} {Law} in the {Age} of {Big} {Data} and {AI} {Survey}: {Privacy}, {Data}, and {Business}},
	volume = {2019},
	shorttitle = {A {Right} to {Reasonable} {Inferences}},
	url = {https://heinonline.org/HOL/P?h=hein.journals/colb2019&i=506},
	language = {eng},
	number = {2},
	urldate = {2023-06-05},
	journal = {Columbia Business Law Review},
	author = {Wachter, Sandra and Mittelstadt, Brent},
	year = {2019},
	pages = {494--620},
}

@article{wirth_asr_2022,
	title = {{ASR} in {German} - {A} {Detailed} {Error} {Analysis}},
	abstract = {The amount of freely available systems for automatic speech recognition (ASR) based on neural networks is growing steadily, with equally increasingly reliable predictions. However, the evaluation of trained models is typically exclusively based on statistical metrics such as WER or CER, which do not provide any insight into the nature or impact of the errors produced when predicting transcripts from speech input. This work presents a selection of ASR model architectures that are pretrained on the German language and evaluates them on a benchmark of diverse test datasets. It identifies cross-architectural prediction errors, classifies those into categories and traces the sources of errors per category back into training data as well as other sources. Finally, it discusses solutions in order to create qualitatively better training datasets and more robust ASR systems.},
	language = {en},
	author = {Wirth, Johannes and Peinl, René},
	year = {2022},
}

@article{torreira_vocal_2022,
	title = {Vocal reaction times to speech offsets: {Implications} for processing models of conversational turn-taking},
	volume = {94},
	issn = {0095-4470},
	shorttitle = {Vocal reaction times to speech offsets},
	url = {https://www.sciencedirect.com/science/article/pii/S009544702200050X},
	doi = {10.1016/j.wocn.2022.101175},
	abstract = {Everyday conversation is characterized by a rapid alternation of turns among successive speakers. We investigate vocal reaction times to speech offsets in order to shed light on the limits of reactive behavior in conversational turn-taking. Twenty-three speakers of Dutch produced a prepared response ([ja], ‘yes’) as fast as possible in response to (a) the onset of a pure tone preceded by a variable amount of silence, and (b) the offset of several types of speech-like auditory stimuli varying in duration, prosodic characteristics, and speech rate. Reactions to the offset of stimuli lacking final prosodic cues were significantly longer than reactions to stimulus onsets (283 vs. 215 ms on average), and were rare below 200 ms (3\%). Speaking latencies decreased as prosodic cues appeared further away from the stimulus end. Slowing down the speech rate produced an entrainment effect (i.e. slower responses) for stimuli lacking prosodic cues vs. a facilitatory effect (i.e. faster responses) when prosodic cues were present. These findings suggest that smooth turn transitions taking less than 200 ms are unlikely to involve reactions to silence at the end of a turn, but that they can be achieved when turn-final prosodic cues are available.},
	language = {en},
	urldate = {2023-06-01},
	journal = {Journal of Phonetics},
	author = {Torreira, Francisco and Bögels, Sara},
	month = sep,
	year = {2022},
	pages = {101175},
}

@article{bostrom_strategic_2017,
	title = {Strategic {Implications} of {Openness} in {AI} {Development}},
	volume = {8},
	copyright = {© 2017 The Authors Global Policy published by Durham University and John Wiley \& Sons, Ltd},
	issn = {1758-5899},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1758-5899.12403},
	doi = {10.1111/1758-5899.12403},
	abstract = {This paper attempts a preliminary analysis of the global desirability of different forms of openness in AI development (including openness about source code, science, data, safety techniques, capabilities, and goals). Short-term impacts of increased openness appear mostly socially beneficial in expectation. The strategic implications of medium and long-term impacts are complex. The evaluation of long-term impacts, in particular, may depend on whether the objective is to benefit the present generation or to promote a time-neutral aggregate of well-being of future generations. Some forms of openness are plausibly positive on both counts (openness about safety measures, openness about goals). Others (openness about source code, science, and possibly capability) could lead to a tightening of the competitive situation around the time of the introduction of advanced AI, increasing the probability that winning the AI race is incompatible with using any safety method that incurs a delay or limits performance. We identify several key factors that must be taken into account by any well-founded opinion on the matter.},
	language = {en},
	number = {2},
	urldate = {2023-06-01},
	journal = {Global Policy},
	author = {Bostrom, Nick},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1758-5899.12403},
	pages = {135--148},
}

@phdthesis{williams_kula_nodate,
	title = {Kula: {A} sketch grammar},
	author = {Williams, Nicholas},
}

@article{alac_talking_2020,
	title = {Talking to a {Toaster}: {How} {Everyday} {Interactions} with {Digital} {Voice} {Assistants} {Resist} a {Return} to the {Individual}},
	volume = {9},
	abstract = {Discussions of the problematic relationship between AI and society have recently only heightened. These discussions, nevertheless, remain partial until they take into account how we live with AI technologies in the unremarkable circumstances of our everyday affairs. In arguing for the importance of such a “noticing,” this article centers on the internet of things and associated digital voice assistants (DVAs). These commercial social robots, designed as conversation-oriented devices, manifest their incompleteness in their need for other voices. Paying attention to that relationality at an embodied scale of analysis brings up our involvement in situated interactional production, while also manifesting its reciprocal character. This not only puts into question the conviction of DVA designers that these gadgets will generate effects of presence in relation to an intentional mind, but also gives us the resources to resist a parallel return to the individual that more often transpires in the discussions of the problematic relationship between AI and society. We practice this resistance by evoking efforts in distributed cognition and the extended mind hypothesis, but we also go beyond the instrumentalist reasoning that primarily recognizes the world as carved into convenient tools that can extend our cognition. To do so we focus on the achieved quality of bodies and environments—two constitutive elements of DVA technology—thereby pointing out how the self in the context of the voiced AI importantly derives from the openness between humans and machines in the interactional scenes of which they are a part.},
	language = {en},
	number = {1},
	journal = {Evental Aesthetics},
	author = {Alač, Morana and Gluzman, Yelena and Aflatoun, Tiffany and Bari, Adil and Jing, Buhang and Mozqueda, German},
	year = {2020},
	pages = {3--53},
}

@article{alac_body-environment_2023,
	title = {On body-environment continuities from a laboratory commensalism},
	volume = {53},
	issn = {0306-3127},
	url = {https://doi.org/10.1177/03063127221136556},
	doi = {10.1177/03063127221136556},
	abstract = {The article attends to everyday practices in a laboratory of neural genetics that studies olfaction, with the fruit fly as its model organism. Practices in neural genetics exhibit one of the ‘post’ aspects in post-genomic science – a turn to the environment. To get at how laboratory members engage body-environment continuities, I pay attention to an occasion of designing experimental chambers for an optogenetics study. As practitioners deal with the body’s continuities with the world by engaging the spatial character of olfaction, their accounts exhibit qualities of feelings of immediate experience, relatable to C.S. Peirce’s phenomenological category of Firstness. While these traces of Firstness inevitably manifest themselves in mixtures with the other two of Peirce’s categories – namely, Secondness and Thirdness – noticing them allows for an engagement of the environment that goes beyond action and meaning. I reflect on that environment by considering the involvement of scientists’ bodies in life with flies, while not forgetting my inhabitation of the laboratory space. Rather than relying on a cross-mapping of attributes known from the human sphere (intentional states or features of the human body) while managing a measurable space observed from the outside, this is an environment lived from within and with others. I conclude the article by proposing its noticing as an orientation toward ecological preoccupations.},
	language = {en},
	number = {2},
	urldate = {2023-05-29},
	journal = {Social Studies of Science},
	author = {Alač, Morana},
	month = apr,
	year = {2023},
	note = {Publisher: SAGE Publications Ltd},
	pages = {242--270},
}

@inproceedings{zhu_using_2005,
	title = {Using {MLP} features in {SRI}'s conversational speech recognition system},
	url = {https://www.isca-speech.org/archive/interspeech_2005/zhu05c_interspeech.html},
	doi = {10.21437/Interspeech.2005-695},
	abstract = {We describe the development of a speech recognition system for conversational telephone speech (CTS) that incorporates acoustic features estimated by multilayer perceptrons (MLP). The acoustic features are based on frame-level phone posterior probabilities, obtained by merging two different MLP estimators, one based on PLP-Tandem features, the other based on hidden activation TRAPs (HATs) features. This paper focuses on the challenges arising when incorporating these nonstandard features into a full-scale speech-to-text (STT) system, as used by SRI in the Fall 2004 DARPA STT evaluations. First, we developed a series of time-saving techniques for training feature MLPs on 1800 hours of speech. Second, we investigated which components of a multipass, multi-front-end recognition system are most proﬁtably augmented with MLP features for best overall performance. The ﬁnal system obtained achieved a 2\% absolute (10\% relative) WER reduction over a comparable baseline system that did not include Tandem/HATs MLP features.},
	language = {en},
	urldate = {2023-05-27},
	booktitle = {Interspeech 2005},
	publisher = {ISCA},
	author = {Zhu, Qifeng and Stolcke, Andreas and Chen, Barry Y. and Morgan, Nelson},
	month = sep,
	year = {2005},
	pages = {2141--2144},
}

@article{fraser_account_2009,
	title = {An {Account} of {Discourse} {Markers}},
	volume = {1},
	issn = {1877-3095, 1877-3109},
	url = {https://brill.com/view/journals/irp/1/2/article-p293_3.xml},
	doi = {10.1163/187730909X12538045489818},
	abstract = {Discourse Markers (DMs) have been a topic of research for 30 years under many diﬀerent names. The present paper presents an account of one view of DMs with the aim of providing researchers in the ﬁeld with a coherent deﬁnition of DMs and a presentation of the syntactic and semantic properties of this functional category that will enable them to compare their work on DMs with other researchers. In addition, an analysis of the uses of the DM but supports the claim that there is one core meaning relationship, contrast, with the interpretation of the more than 10 diﬀerent uses of but being signalled by context and pragmatic elaboration.},
	language = {en},
	number = {2},
	urldate = {2023-05-27},
	journal = {International Review of Pragmatics},
	author = {Fraser, Bruce},
	year = {2009},
	pages = {293--320},
}

@inproceedings{mitchell_model_2019,
	address = {New York, NY, USA},
	series = {{FAT}* '19},
	title = {Model {Cards} for {Model} {Reporting}},
	isbn = {978-1-4503-6125-5},
	url = {https://doi.org/10.1145/3287560.3287596},
	doi = {10.1145/3287560.3287596},
	abstract = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.},
	urldate = {2023-05-27},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
	month = jan,
	year = {2019},
	pages = {220--229},
}

@article{mcmillan-major_data_2023,
	title = {Data {Statements}: {From} {Technical} {Concept} to {Community} {Practice}},
	shorttitle = {Data {Statements}},
	url = {https://dl.acm.org/doi/10.1145/3594737},
	doi = {10.1145/3594737},
	abstract = {Responsible computing ultimately requires that technical communities develop and adopt tools, processes, and practices that mitigate harms and support human flourishing. Prior efforts toward the responsible development and use of datasets, machine learning models, and other technical systems have led to the creation of documentation toolkits to facilitate transparency, diagnosis, and inclusion. This work takes the next step: to catalyze community uptake, alongside toolkit improvement. Specifically, starting from one such proposed toolkit specialized for language datasets, data statements for natural language processing (NLP), we explore how to improve the toolkit in three senses: (1) the content of the toolkit itself, (2) engagement with professional practice, and (3) moving from a conceptual proposal to a tested schema that the intended community of use may readily adopt. To achieve these goals, we first conducted a workshop with NLP practitioners in order to identify gaps and limitations of the toolkit as well as to develop best practices for writing data statements, yielding an interim improved toolkit. Then we conducted an analytic comparison between the interim toolkit and another documentation toolkit, datasheets for datasets. Based on these two integrated processes, we present our revised Version 2 schema and best practices in a guide for writing data statements. Our findings more generally provide integrated processes for co-evolving both technology and practice to address ethical concerns within situated technical communities.},
	urldate = {2023-05-27},
	journal = {ACM Journal on Responsible Computing},
	author = {McMillan-Major, Angelina and Bender, Emily M. and Friedman, Batya},
	year = {2023},
	note = {Just Accepted},
}

@article{waldecker_zur_2022,
	title = {Zur {Inszenierung} von kritischen {Kompetenzen} in {Nischenöffentlichkeiten}: {Bewertungen} von {Smart} {Speakern} auf {YouTube}},
	volume = {23},
	copyright = {Copyright (c) 2023 David Waldecker, Dagmar Hoffmann},
	issn = {1616-2617},
	shorttitle = {Zur {Inszenierung} von kritischen {Kompetenzen} in {Nischenöffentlichkeiten}},
	url = {https://journals.sub.uni-hamburg.de/hup2/kommges/article/view/1000},
	doi = {10.15460/kommges.2022.23.1.1000},
	abstract = {Der vorliegende Beitrag widmet sich der Analyse von Unboxing- und Review-Videos auf der Plattform YouTube, die sich vornehmlich mit dem Testen von Konsumtechnik beschäftigen. Die Videos zeigen das Auspacken und das Ausprobierens von Produkten, die Begutachtung ihrer Funktions- und Gebrauchsweisen und die Überprüfung ihrer Gebrauchsversprechen. Die Tests führen keine formal qualifizierten Warentester:innen durch, sondern in der Regel Nutzer:innen, die sich darauf spezialisiert haben. Unboxing- und Review-Videos können insofern als Element der Selbstinszenierung und -vermarktung von (pseudo-)privaten Praktiken des Auspackens und des Bewertens verstanden werden. Im Folgenden interessieren wir uns für das Testen und Bewerten von Smart Speakern, die im häuslichen Bereich zum Einsatz kommen. Im Sinne einer Sociology of Conventions and Testing (Potthast, 2017; Boltanski/Thévenot, 2007) wird anhand eines Fallvergleichs auf inhaltlicher Ebene danach gefragt, welche Aspekte der Geräte angesprochen werden und auf ästhetischer Ebene, wie das Entpacken und Testen der Geräte von den YouTuber:innen inszeniert und in die Logik der Videoplattform eingebettet wird. Der Beitrag stellt zudem dar, inwieweit Nutzungsbedingungen und insbesondere etwaige Datenschutzproblematiken, wie sie im öffentlichen Diskurs zumeist kritisch verhandelt und zuweilen auch in Werbespots thematisiert werden, in den Reviews zwischen einer Kritik und der Anpreisung der Produkte aufgegriffen werden. Zugleich wird untersucht, wie sich die Produzierenden inszenieren.},
	language = {de},
	number = {1},
	urldate = {2023-05-26},
	journal = {kommunikation@gesellschaft},
	author = {Waldecker, David and Hoffmann, Dagmar},
	year = {2022},
	note = {Number: 1},
}

@book{waldecker_mit_2022,
	address = {Bielefeld},
	series = {Media in {Action}},
	title = {Mit {Adorno} im {Tonstudio}: zur {Soziologie} der {Musikproduktion}},
	isbn = {978-3-8394-5701-6 978-3-8376-5701-2},
	shorttitle = {Mit {Adorno} im {Tonstudio}},
	abstract = {Das Aufzeichnen von Musik im Tonstudio wird bisher eher selten als eigenständige Form des Musizierens verstanden. David Waldecker untersucht diesen Prozess mit Bezug auf Adorno, praxeologische Ansätze und eigene Feldforschung im Bereich Hardcore und Jazz. Er zeigt, wie im Studio durch dessen technische und räumliche Besonderheiten und Rolle in der Produktion bestimmte Formen des Musikmachens erzeugt werden. Zugleich liefert er eine Auseinandersetzung mit aktuellen Ansätzen in der Musiksoziologie und der Ethnographie aus Sicht der Kritischen Theorie Adornos},
	language = {ger},
	number = {Band 4},
	publisher = {transcript},
	author = {Waldecker, David},
	year = {2022},
}

@article{kadava_interview_2022,
	title = {Interview: {Cognitive} {Semiotics} as an {Emerging} {Discipline}: {An} {Interview} with {Jordan} {Zlatev}},
	volume = {37},
	shorttitle = {Interview},
	url = {https://www.pdcnet.org/pdc/bvdb.nsf/purchase?openform&fp=ajs&id=ajs_2021_0037_0003_0317_0327},
	doi = {10.5840/ajs2021373/481},
	language = {en},
	number = {3/4},
	urldate = {2023-05-23},
	journal = {The American Journal of Semiotics},
	author = {Kadavá, Šárka and Zlatev, Jordan},
	month = mar,
	year = {2022},
	pages = {317--327},
}

@article{button_what_2012,
	series = {Studying {Design} in {Practice}},
	title = {What does ‘work’ mean in ‘ethnomethodological studies of work?’: {Its} ubiquitous relevance for systems design to support action and interaction},
	volume = {33},
	issn = {0142-694X},
	shorttitle = {What does ‘work’ mean in ‘ethnomethodological studies of work?},
	url = {https://www.sciencedirect.com/science/article/pii/S0142694X12000403},
	doi = {10.1016/j.destud.2012.06.003},
	abstract = {In computer systems design, ethnomethodology is seen as a form of ethnography that emphasises situated work practices and the workplace. However, designers have increasingly taken an interest in developing systems to support non-work matters such as social networking, gaming, and fun, and non-work settings such as the home. Some have, therefore, suggested that ethnography driven by interests in work practice is not relevant for these new developments because they do not involve matters of work, and that, consequently, a new form of ethnography is required. This paper critically addresses this argument and contends that ethnography can be analytically grounded in ethnomethodology as a ubiquitous method for building ‘the social’ into systems design.},
	language = {en},
	number = {6},
	urldate = {2023-05-22},
	journal = {Design Studies},
	author = {Button, Graham},
	month = nov,
	year = {2012},
	pages = {673--684},
}

@article{krugel_zombies_2022,
	title = {Zombies in the {Loop}? {Humans} {Trust} {Untrustworthy} {AI}-{Advisors} for {Ethical} {Decisions}},
	volume = {35},
	issn = {2210-5441},
	shorttitle = {Zombies in the {Loop}?},
	url = {https://doi.org/10.1007/s13347-022-00511-9},
	doi = {10.1007/s13347-022-00511-9},
	abstract = {Departing from the claim that AI needs to be trustworthy, we find that ethical advice from an AI-powered algorithm is trusted even when its users know nothing about its training data and when they learn information about it that warrants distrust. We conducted online experiments where the subjects took the role of decision-makers who received advice from an algorithm on how to deal with an ethical dilemma. We manipulated the information about the algorithm and studied its influence. Our findings suggest that AI is overtrusted rather than distrusted. We suggest digital literacy as a potential remedy to ensure the responsible use of AI.},
	language = {en},
	number = {1},
	urldate = {2023-05-22},
	journal = {Philosophy \& Technology},
	author = {Krügel, Sebastian and Ostermaier, Andreas and Uhl, Matthias},
	month = mar,
	year = {2022},
	pages = {17},
}

@inproceedings{threlkeld_using_2022,
	address = {Edinburgh, UK},
	title = {Using {Transition} {Duration} to {Improve} {Turn}-taking in {Conversational} {Agents}},
	url = {https://aclanthology.org/2022.sigdial-1.20},
	abstract = {Smooth turn-taking is an important aspect of natural conversation that allows interlocutors to maintain adequate mutual comprehensibility. In human communication, the timing between utterances is normatively constrained, and deviations convey socially relevant paralinguistic information. However, for spoken dialogue systems, smooth turn-taking continues to be a challenge. This motivates the need for spoken dialogue systems to employ a robust model of turn-taking to ensure that messages are exchanged smoothly and without transmitting unintended paralinguistic information. In this paper, we examine dialogue data from natural human interaction to develop an evidence-based model for turn-timing in spoken dialogue systems. First, we use timing between turns to develop two models of turn-taking: a speaker-agnostic model and a speaker-sensitive model. From the latter model, we derive the propensity of listeners to take the next turn given TRP duration. Finally, we outline how this measure may be incorporated into a spoken dialogue system to improve the naturalness of conversation.},
	urldate = {2023-05-22},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Threlkeld, Charles and Umair, Muhammad and de Ruiter, Jp},
	month = sep,
	year = {2022},
	pages = {193--203},
}

@inproceedings{threlkeld_duration_2022,
	address = {Edinburgh, UK},
	title = {The {Duration} of a {Turn} {Cannot} be {Used} to {Predict} {When} {It} {Ends}},
	url = {https://aclanthology.org/2022.sigdial-1.35},
	abstract = {Turn taking in conversation is a complex process. We still don't know how listeners are able to anticipate the end of a speaker's turn. Previous work focuses on prosodic, semantic, and non-verbal cues that a turn is coming to an end. In this paper, we look at simple measures of duration — time, word count, and syllable count — to see if we can exploit the duration of turns as a cue. We find strong evidence that these metrics are useless.},
	urldate = {2023-05-22},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Threlkeld, Charles and de Ruiter, Jp},
	month = sep,
	year = {2022},
	pages = {361--367},
}

@inproceedings{jacqmin_you_2022,
	address = {Edinburgh, UK},
	title = {“{Do} you follow me?”: {A} {Survey} of {Recent} {Approaches} in {Dialogue} {State} {Tracking}},
	shorttitle = {“{Do} you follow me?},
	url = {https://aclanthology.org/2022.sigdial-1.33},
	abstract = {While communicating with a user, a task-oriented dialogue system has to track the user's needs at each turn according to the conversation history. This process called dialogue state tracking (DST) is crucial because it directly informs the downstream dialogue policy. DST has received a lot of interest in recent years with the text-to-text paradigm emerging as the favored approach. In this review paper, we first present the task and its associated datasets. Then, considering a large number of recent publications, we identify highlights and advances of research in 2021-2022. Although neural approaches have enabled significant progress, we argue that some critical aspects of dialogue systems such as generalizability are still underexplored. To motivate future studies, we propose several research avenues.},
	urldate = {2023-05-22},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Jacqmin, Léo and Rojas Barahona, Lina M. and Favre, Benoit},
	month = sep,
	year = {2022},
	pages = {336--350},
}

@inproceedings{pan_user_2022,
	address = {Edinburgh, UK},
	title = {User {Satisfaction} {Modeling} with {Domain} {Adaptation} in {Task}-oriented {Dialogue} {Systems}},
	url = {https://aclanthology.org/2022.sigdial-1.59},
	abstract = {User Satisfaction Estimation (USE) is crucial in helping measure the quality of a task-oriented dialogue system. However, the complex nature of implicit responses poses challenges in detecting user satisfaction, and most datasets are limited in size or not available to the public due to user privacy policies. Unlike task-oriented dialogue, large-scale annotated chitchat with emotion labels is publicly available. Therefore, we present a novel user satisfaction model with domain adaptation (USMDA) to utilize this chitchat. We adopt a dialogue Transformer encoder to capture contextual features from the dialogue. And we reduce domain discrepancy to learn dialogue-related invariant features. Moreover, USMDA jointly learns satisfaction signals in the chitchat context with user satisfaction estimation, and user actions in task-oriented dialogue with dialogue action recognition. Experimental results on two benchmarks show that our proposed framework for the USE task outperforms existing unsupervised domain adaptation methods. To the best of our knowledge, this is the first work to study user satisfaction estimation with unsupervised domain adaptation from chitchat to task-oriented dialogue.},
	urldate = {2023-05-22},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Pan, Yan and Ma, Mingyang and Pflugfelder, Bernhard and Groh, Georg},
	month = sep,
	year = {2022},
	pages = {630--636},
}

@inproceedings{li_multi-task_2022,
	address = {Edinburgh, UK},
	title = {Multi-{Task} {Learning} for {Depression} {Detection} in {Dialogs}},
	url = {https://aclanthology.org/2022.sigdial-1.7},
	abstract = {Depression is a serious mental illness that impacts the way people communicate, especially through their emotions, and, allegedly, the way they interact with others. This work examines depression signals in dialogs, a less studied setting that suffers from data sparsity. We hypothesize that depression and emotion can inform each other, and we propose to explore the influence of dialog structure through topic and dialog act prediction. We investigate a Multi-Task Learning (MTL) approach, where all tasks mentioned above are learned jointly with dialog-tailored hierarchical modeling. We experiment on the DAIC and DailyDialog corpora – both contain dialogs in English – and show important improvements over state-of-the-art on depression detection (at best 70.6\% F1), which demonstrates the correlation of depression with emotion and dialog organization and the power of MTL to leverage information from different sources.},
	urldate = {2023-05-22},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Chuyuan and Braud, Chloé and Amblard, Maxime},
	month = sep,
	year = {2022},
	pages = {68--75},
}

@inproceedings{ekstedt_how_2022,
	address = {Edinburgh, UK},
	title = {How {Much} {Does} {Prosody} {Help} {Turn}-taking? {Investigations} using {Voice} {Activity} {Projection} {Models}},
	shorttitle = {How {Much} {Does} {Prosody} {Help} {Turn}-taking?},
	url = {https://aclanthology.org/2022.sigdial-1.51},
	abstract = {Turn-taking is a fundamental aspect of human communication and can be described as the ability to take turns, project upcoming turn shifts, and supply backchannels at appropriate locations throughout a conversation. In this work, we investigate the role of prosody in turn-taking using the recently proposed Voice Activity Projection model, which incrementally models the upcoming speech activity of the interlocutors in a self-supervised manner, without relying on explicit annotation of turn-taking events, or the explicit modeling of prosodic features. Through manipulation of the speech signal, we investigate how these models implicitly utilize prosodic information. We show that these systems learn to utilize various prosodic aspects of speech both on aggregate quantitative metrics of long-form conversations and on single utterances specifically designed to depend on prosody.},
	urldate = {2023-05-22},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Ekstedt, Erik and Skantze, Gabriel},
	month = sep,
	year = {2022},
	pages = {541--551},
}

@inproceedings{farzana_are_2022,
	address = {Edinburgh, UK},
	title = {Are {Interaction} {Patterns} {Helpful} for {Task}-{Agnostic} {Dementia} {Detection}? {An} {Empirical} {Exploration}},
	shorttitle = {Are {Interaction} {Patterns} {Helpful} for {Task}-{Agnostic} {Dementia} {Detection}?},
	url = {https://aclanthology.org/2022.sigdial-1.18},
	abstract = {Dementia often manifests in dialog through specific behaviors such as requesting clarification, communicating repetitive ideas, and stalling, prompting conversational partners to probe or otherwise attempt to elicit information. Dialog act (DA) sequences can have predictive power for dementia detection through their potential to capture these meaningful interaction patterns. However, most existing work in this space relies on content-dependent features, raising questions about their generalizability beyond small reference sets or across different cognitive tasks. In this paper, we adapt an existing DA annotation scheme for two different cognitive tasks present in a popular dementia detection dataset. We show that a DA tagging model leveraging neural sentence embeddings and other information from previous utterances and speaker tags achieves strong performance for both tasks. We also propose content-free interaction features and show that they yield high utility in distinguishing dementia and control subjects across different tasks. Our study provides a step toward better understanding how interaction patterns in spontaneous dialog affect cognitive modeling across different tasks, which carries implications for the design of non-invasive and low-cost cognitive health monitoring tools for use at scale.},
	urldate = {2023-05-22},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Farzana, Shahla and Parde, Natalie},
	month = sep,
	year = {2022},
	pages = {172--182},
}

@inproceedings{gella_dialog_2022,
	address = {Edinburgh, UK},
	title = {Dialog {Acts} for {Task} {Driven} {Embodied} {Agents}},
	url = {https://aclanthology.org/2022.sigdial-1.13},
	abstract = {Embodied agents need to be able to interact in natural language – understanding task descriptions and asking appropriate follow up questions to obtain necessary information to be effective at successfully accomplishing tasks for a wide range of users. In this work, we propose a set of dialog acts for modelling such dialogs and annotate the TEACh dataset that includes over 3,000 situated, task oriented conversations (consisting of 39.5k utterances in total) with dialog acts. To our knowledge,TEACh-DA is the first large scale dataset of dialog act annotations for embodied task completion. Furthermore, we demonstrate the use of this annotated dataset in training models for tagging the dialog acts of a given utterance, predicting the dialog act of the next response given a dialog history, and use the dialog acts to guide agent's non-dialog behaviour. In particular, our experiments on the TEACh Execution from Dialog History task where the model predicts the sequence of low level actions to be executed in the environment for embodied task completion, demonstrate that dialog acts can improve end performance by up to 2 points compared to the system without dialog acts.},
	urldate = {2023-05-22},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Gella, Spandana and Padmakumar, Aishwarya and Lange, Patrick and Hakkani-Tur, Dilek},
	month = sep,
	year = {2022},
	pages = {111--123},
}

@inproceedings{lai_controllable_2022,
	address = {Edinburgh, UK},
	title = {Controllable {User} {Dialogue} {Act} {Augmentation} for {Dialogue} {State} {Tracking}},
	url = {https://aclanthology.org/2022.sigdial-1.5},
	abstract = {Prior work has demonstrated that data augmentation is useful for improving dialogue state tracking. However, there are many types of user utterances, while the prior method only considered the simplest one for augmentation, raising the concern about poor generalization capability. In order to better cover diverse dialogue acts and control the generation quality, this paper proposes controllable user dialogue act augmentation (CUDA-DST) to augment user utterances with diverse behaviors. With the augmented data, different state trackers gain improvement and show better robustness, achieving the state-of-the-art performance on MultiWOZ 2.1.},
	urldate = {2023-05-22},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Lai, Chun-Mao and Hsu, Ming-Hao and Huang, Chao-Wei and Chen, Yun-Nung},
	month = sep,
	year = {2022},
	pages = {53--61},
}

@inproceedings{belz_comparing_2006,
	address = {Trento, Italy},
	title = {Comparing {Automatic} and {Human} {Evaluation} of {NLG} {Systems}},
	url = {https://aclanthology.org/E06-1040},
	urldate = {2023-05-22},
	booktitle = {11th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Belz, Anja and Reiter, Ehud},
	month = apr,
	year = {2006},
	pages = {313--320},
}

@unpublished{liesenfeld_interactive_2022,
	title = {Interactive probes: action-level evaluation for dialogue systems},
	author = {Liesenfeld, Andreas and Dingemanse, Mark},
	year = {2022},
}

@inproceedings{enayet_improving_2023,
	address = {Dubrovnik, Croatia},
	title = {Improving the {Generalizability} of {Collaborative} {Dialogue} {Analysis} {With} {Multi}-{Feature} {Embeddings}},
	url = {https://aclanthology.org/2023.eacl-main.258},
	abstract = {Conflict prediction in communication is integral to the design of virtual agents that support successful teamwork by providing timely assistance. The aim of our research is to analyze discourse to predict collaboration success. Unfortunately, resource scarcity is a problem that teamwork researchers commonly face since it is hard to gather a large number of training examples. To alleviate this problem, this paper introduces a multi-feature embedding (MFeEmb) that improves the generalizability of conflict prediction models trained on dialogue sequences. MFeEmb leverages textual, structural, and semantic information from the dialogues by incorporating lexical, dialogue acts, and sentiment features. The use of dialogue acts and sentiment features reduces performance loss from natural distribution shifts caused mainly by changes in vocabulary. This paper demonstrates the performance of MFeEmb on domain adaptation problems in which the model is trained on discourse from one task domain and applied to predict team performance in a different domain. The generalizability of MFeEmb is quantified using the similarity measure proposed by Bontonou et al. (2021). Our results show that MFeEmb serves as an excellent domain-agnostic representation for meta-pretraining a few-shot model on collaborative multiparty dialogues.},
	urldate = {2023-05-17},
	booktitle = {Proceedings of the 17th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Enayet, Ayesha and Sukthankar, Gita},
	month = may,
	year = {2023},
	pages = {3551--3565},
}

@article{colombo_guiding_2020,
	title = {Guiding {Attention} in {Sequence}-to-{Sequence} {Models} for {Dialogue} {Act} {Prediction}},
	volume = {34},
	copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/6259},
	doi = {10.1609/aaai.v34i05.6259},
	abstract = {The task of predicting dialog acts (DA) based on conversational dialog is a key component in the development of conversational agents. Accurately predicting DAs requires a precise modeling of both the conversation and the global tag dependencies. We leverage seq2seq approaches widely adopted in Neural Machine Translation (NMT) to improve the modelling of tag sequentiality. Seq2seq models are known to learn complex global dependencies while currently proposed approaches using linear conditional random fields (CRF) only model local tag dependencies. In this work, we introduce a seq2seq model tailored for DA classification using: a hierarchical encoder, a novel guided attention mechanism and beam search applied to both training and inference. Compared to the state of the art our model does not require handcrafted features and is trained end-to-end. Furthermore, the proposed approach achieves an unmatched accuracy score of 85\% on SwDA, and state-of-the-art accuracy score of 91.6\% on MRDA.},
	language = {en},
	number = {05},
	urldate = {2023-05-17},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Colombo, Pierre and Chapuis, Emile and Manica, Matteo and Vignon, Emmanuel and Varni, Giovanna and Clavel, Chloe},
	month = apr,
	year = {2020},
	note = {Number: 05},
	pages = {7594--7601},
}

@article{liu_odebert_2023,
	title = {{OdeBERT}: {One}-stage {Deep}-supervised {Early}-exiting {BERT} for {Fast} {Inference} in {User} {Intent} {Classification}},
	volume = {22},
	issn = {2375-4699},
	shorttitle = {{OdeBERT}},
	url = {https://dl.acm.org/doi/10.1145/3587464},
	doi = {10.1145/3587464},
	abstract = {User intent classification is a vital task for analyzing users’ essential requirements from the users’ input query in information retrieval systems, question answering systems, and dialogue systems. Pre-trained language model Bidirectional Encoder Representation from Transformers (BERT) has been widely applied to the user intent classification task. However, BERT is compute intensive and time-consuming during inference and usually causes latency in real-time applications. To improve the inference efficiency of BERT for the user intent classification task, this article proposes a new network named one-stage deep-supervised early-exiting BERT as one-stage deep-supervised early-exiting BERT (OdeBERT). In addition, a deep supervision strategy is developed to incorporate the network with internal classifiers by one-stage joint training to improve the learning process of classifiers by extracting discriminative category features. Experiments are conducted on publicly available datasets, including ECDT, SNIPS, and FDQuestion. The results show that the OdeBERT can speed up original BERT 12 times faster at most with the same performance, outperforming state-of-the-art baseline methods.},
	number = {5},
	urldate = {2023-05-17},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	author = {Liu, Yuanxia and Hao, Tianyong and Liu, Hai and Mu, Yuanyuan and Weng, Heng and Wang, Fu Lee},
	year = {2023},
	pages = {129:1--129:18},
}

@inproceedings{okur_natural_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Natural {Language} {Interactions} in {Autonomous} {Vehicles}: {Intent} {Detection} and {Slot} {Filling} from {Passenger} {Utterances}},
	isbn = {978-3-031-24340-0},
	shorttitle = {Natural {Language} {Interactions} in {Autonomous} {Vehicles}},
	doi = {10.1007/978-3-031-24340-0_25},
	abstract = {Understanding passenger intents and extracting relevant slots are crucial building blocks towards developing contextual dialogue systems for natural interactions in autonomous vehicles (AV). In this work, we explored AMIE (Automated-vehicle Multi-modal In-cabin Experience), the in-cabin agent responsible for handling certain passenger-vehicle interactions. When the passengers give instructions to AMIE, the agent should parse such commands properly and trigger the appropriate functionality of the AV system. In our current explorations, we focused on AMIE scenarios describing usages around setting or changing the destination and route, updating driving behavior or speed, finishing the trip, and other use-cases to support various natural commands. We collected a multi-modal in-cabin dataset with multi-turn dialogues between the passengers and AMIE using a Wizard-of-Oz scheme via a realistic scavenger hunt game activity. After exploring various recent Recurrent Neural Networks (RNN) based techniques, we introduced our hierarchical joint models to recognize passenger intents along with relevant slots associated with the action to be performed in AV scenarios. Our experimental results outperformed certain competitive baselines and achieved overall F1-scores of 0.91 for utterance-level intent detection and 0.96 for slot filling tasks. In addition, we conducted initial speech-to-text explorations by comparing intent/slot models trained and tested on human transcriptions versus noisy Automatic Speech Recognition (ASR) outputs. Finally, we evaluated the results with single passenger rides versus the rides with multiple passengers.},
	language = {en},
	booktitle = {Computational {Linguistics} and {Intelligent}  {Text} {Processing}},
	publisher = {Springer Nature Switzerland},
	author = {Okur, Eda and Kumar, Shachi H. and Sahay, Saurav and Arslan Esme, Asli and Nachman, Lama},
	editor = {Gelbukh, Alexander},
	year = {2023},
	pages = {334--350},
}

@article{bunt_semantic_2023,
	title = {Semantic and pragmatic precision in conversational {AI} systems},
	volume = {6},
	issn = {2624-8212},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10101227/},
	doi = {10.3389/frai.2023.896729},
	abstract = {For a conversational agent, to display intelligent interactive behavior implies the ability to respond to the user's intentions and expectations with correct, consistent and relevant actions with appropriate form and content in a timely fashion. In this paper, we present a data-driven analytical approach to embed intelligence into a conversational AI agent. The method requires a certain amount of (ideally) authentic conversational data, which is transformed in a meaningful way to support intelligent dialog modeling and the design of intelligent conversational agents. These transformations rely on the ISO 24617-2 dialog act annotation standard, and are specified in the Dialogue Act Markup Language (DiAML), extended with plug-ins for articulate representations of domain-specific semantic content and customized communicative functionality. ISO 24617-2 is shown to enable systematic in-depth interaction analysis and to facilitate the collection of conversational data of sufficient quality and quantity of instances of interaction phenomena. The paper provides the theoretical and methodological background of extending the ISO standard and DiAML specifications for use in interaction analysis and conversational AI agent design. The expert-assisted design methodology is introduced, with example applications in the healthcare domain, and is validated in human-agent conversational data collection experiments.},
	urldate = {2023-05-17},
	journal = {Frontiers in Artificial Intelligence},
	author = {Bunt, Harry and Petukhova, Volha},
	month = mar,
	year = {2023},
	pmid = {37064296},
	pmcid = {PMC10101227},
	pages = {896729},
}

@inproceedings{mahajan_improving_2022,
	address = {Abu Dhabi, United Arab Emirates (Hybrid)},
	title = {Improving {Dialogue} {Act} {Recognition} with {Augmented} {Data}},
	url = {https://aclanthology.org/2022.gem-1.44},
	abstract = {We present our work on augmenting dialog act recognition capabilities utilizing synthetically generated data. Our work is motivated by the limitations of current dialog act datasets, and the need to adapt for new domains as well as ambiguity in utterances written by humans. We list our observations and findings towards how synthetically generated data can contribute meaningfully towards more robust dialogue act recognition models extending to new domains. Our major finding shows that synthetic data, which is linguistically varied, can be very useful towards this goal and increase the performance from (0.39, 0.16) to (0.85, 0.88) for AFFIRM and NEGATE dialog acts respectively.},
	urldate = {2023-05-17},
	booktitle = {Proceedings of the 2nd {Workshop} on {Natural} {Language} {Generation}, {Evaluation}, and {Metrics} ({GEM})},
	publisher = {Association for Computational Linguistics},
	author = {Mahajan, Khyati and Parikh, Soham and Vohra, Quaizar and Tiwari, Mitul and Shaikh, Samira},
	month = dec,
	year = {2022},
	pages = {471--479},
}

@article{qi_zipfs_2023,
	title = {Zipf’s {Law} for {Speech} {Acts} in {Spoken} {English}},
	volume = {0},
	issn = {0929-6174},
	url = {https://doi.org/10.1080/09296174.2023.2202470},
	doi = {10.1080/09296174.2023.2202470},
	abstract = {Speech acts, as basic communication units in pragmatics, are highly correlated to speakers’ communicative intentions. It is a worthwhile goal to explore whether they obey some linguistic laws that reflect people’s cognitive mechanisms, e.g. Zipf’s Law. However, few studies have examined whether the Zipf distribution can capture the frequencies of speech acts, and whether its parameters can show how speakers’ attributes (e.g. gender and education level) relate to the use of speech acts. As a preliminary attempt to bridge this gap, the current study finds from the data sample of the Switchboard Dialog Act Corpus that: (1) the Zipf distribution well captures the distribution of speech acts; (2) the parameter a can distinguish the dialogues between speakers of different genders, and it shows a regularity of the highest frequency of an SA in a dialogue to some degree; (3) the parameter b can differentiate speakers of different education levels – people with college-level education may have higher expressivity of SAs compared with those with higher-than-college-level education. This study shows that Zipf’s Law can be extended to the analysis of pragmatic phenomena, which may become part of the synergetic system of language through the approach of Quantitative Linguistics.},
	number = {0},
	urldate = {2023-05-17},
	journal = {Journal of Quantitative Linguistics},
	author = {Qi, Da and Wang, Hua},
	month = apr,
	year = {2023},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09296174.2023.2202470},
	pages = {1--28},
}

@inproceedings{kumar_empirical_2022,
	address = {Dublin, Ireland},
	title = {An {Empirical} study to understand the {Compositional} {Prowess} of {Neural} {Dialog} {Models}},
	url = {https://aclanthology.org/2022.insights-1.21},
	doi = {10.18653/v1/2022.insights-1.21},
	abstract = {In this work, we examine the problems associated with neural dialog models under the common theme of compositionality. Specifically, we investigate three manifestations of compositionality: (1) Productivity, (2) Substitutivity, and (3) Systematicity. These manifestations shed light on the generalization, syntactic robustness, and semantic capabilities of neural dialog models. We design probing experiments by perturbing the training data to study the above phenomenon. We make informative observations based on automated metrics and hope that this work increases research interest in understanding the capacity of these models.},
	urldate = {2023-05-17},
	booktitle = {Proceedings of the {Third} {Workshop} on {Insights} from {Negative} {Results} in {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Kumar, Vinayshekhar and Kumar, Vaibhav and Bhutani, Mukul and Rudnicky, Alexander},
	month = may,
	year = {2022},
	pages = {154--158},
}

@inproceedings{ye_structured_2022,
	address = {New York, NY, USA},
	series = {{SIGIR} '22},
	title = {Structured and {Natural} {Responses} {Co}-generation for {Conversational} {Search}},
	isbn = {978-1-4503-8732-3},
	url = {https://dl.acm.org/doi/10.1145/3477495.3532063},
	doi = {10.1145/3477495.3532063},
	abstract = {Generating fluent and informative natural responses while main- taining representative internal states for search optimization is critical for conversational search systems. Existing approaches ei- ther 1) predict structured dialog acts first and then generate natural response; or 2) map conversation context to natural responses di- rectly in an end-to-end manner. Both kinds of approaches have shortcomings. The former suffers from error accumulation while the semantic associations between structured acts and natural re- sponses are confined in single direction. The latter emphasizes generating natural responses but fails to predict structured acts. Therefore, we propose a neural co-generation model that gener- ates the two concurrently. The key lies in a shared latent space shaped by two informed priors. Specifically, we design structured dialog acts and natural response auto-encoding as two auxiliary tasks in an interconnected network architecture. It allows for the concurrent generation and bidirectional semantic associations. The shared latent space also enables asynchronous reinforcement learn- ing for further joint optimization. Experiments show that our model achieves significant performance improvements.},
	urldate = {2023-05-17},
	booktitle = {Proceedings of the 45th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Ye, Chenchen and Liao, Lizi and Feng, Fuli and Ji, Wei and Chua, Tat-Seng},
	month = jul,
	year = {2022},
	pages = {155--164},
}

@inproceedings{wu_infusing_2023,
	address = {Dubrovnik, Croatia},
	title = {Infusing {Context} and {Knowledge} {Awareness} in {Multi}-turn {Dialog} {Understanding}},
	url = {https://aclanthology.org/2023.findings-eacl.19},
	abstract = {In multi-turn dialog understanding, semantic frames are constructed by detecting intents and slots within each user utterance.However, recent works lack the capability of modeling multi-turn dynamics within a dialog in natural language understanding (NLU), instead leaving them for updating dialog states only.Moreover, humans usually associate relevant background knowledge with the current dialog contexts to better illustrate slot semantics revealed from word connotations, where previous works have explored such possibility mostly in knowledge-grounded response generation.In this paper, we propose to amend the research gap by equipping a BERT-based NLU framework with knowledge and context awareness.We first encode dialog contexts with a unidirectional context-aware transformer encoder and select relevant inter-word knowledge with the current word and previous history based on a knowledge attention mechanism. Experimental results in two complicated multi-turn dialog datasets have demonstrated significant improvements of our proposed framework. Attention visualization also demonstrates how our modules leverage knowledge across the utterance.},
	urldate = {2023-05-17},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EACL} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Wu, Ting-Wei and Juang, Biing-Hwang},
	month = may,
	year = {2023},
	pages = {254--264},
}

@article{fyfe_how_2022,
	title = {How to cheat on your final paper: {Assigning} {AI} for student writing},
	issn = {1435-5655},
	shorttitle = {How to cheat on your final paper},
	url = {https://doi.org/10.1007/s00146-022-01397-z},
	doi = {10.1007/s00146-022-01397-z},
	abstract = {This paper shares results from a pedagogical experiment that assigns undergraduates to “cheat” on a final class essay by requiring their use of text-generating AI software. For this assignment, students harvested content from an installation of GPT-2, then wove that content into their final essay. At the end, students offered a “revealed” version of the essay as well as their own reflections on the experiment. In this assignment, students were specifically asked to confront the oncoming availability of AI as a writing tool. What are the ethics of using AI this way? What counts as plagiarism? What are the conditions, if any, we should place on AI assistance for student writing? And how might working with AI change the way we think about writing, authenticity, and creativity? While students (and sometimes GPT-2) offered thoughtful reflections on these initial questions, actually composing with GPT-2 opened their perspectives more broadly on the ethics and practice of writing with AI. In this paper, I share how students experienced those issues, connect their insights to broader conversations in the humanities about writing and communication, and explain their relevance for the ethical use and evaluation of language models.},
	language = {en},
	urldate = {2023-05-14},
	journal = {AI \& SOCIETY},
	author = {Fyfe, Paul},
	month = mar,
	year = {2022},
}

@misc{malik_dialogtag_2021,
	title = {{DialogTag}: {A} python library to classify dialogue tag},
	copyright = {MIT License},
	shorttitle = {{DialogTag}},
	url = {https://github.com/bhavitvyamalik/DialogTag},
	urldate = {2023-05-12},
	author = {Malik, Bhavitvya},
	year = {2021},
}

@incollection{callon_elements_1986,
	address = {London},
	title = {Some elements of a sociology of translation: domestication of the scallops and the fishermen of {St} {Brieuc} {Bay}},
	volume = {32},
	shorttitle = {Some elements of a sociology of translation},
	booktitle = {Power, action and belief: {A} new sociology of knowledge},
	publisher = {Routledge},
	author = {Callon, M.},
	editor = {Law, John},
	year = {1986},
	pages = {196--233},
}

@book{kaptelinin_acting_2006,
	title = {Acting with {Technology}: {Activity} {Theory} and {Interaction} {Design}},
	isbn = {978-0-262-11298-7},
	shorttitle = {Acting with {Technology}},
	abstract = {A systematic presentation of activity theory, its application to interaction design, and an argument for the development of activity theory as a basis for understanding how people interact with technology.Activity theory holds that the human mind is the product of our interaction with people and artifacts in the context of everyday activity. Acting with Technology makes the case for activity theory as a basis for understanding our relationship with technology. Victor Kaptelinin and Bonnie Nardi describe activity theory's principles, history, relationship to other theoretical approaches, and application to the analysis and design of technologies. The book provides the first systematic entry-level introduction to the major principles of activity theory. It describes the accumulating body of work in interaction design informed by activity theory, drawing on work from an international community of scholars and designers. Kaptelinin and Nardi examine the notion of the object of activity, describe its use in an empirical study, and discuss key debates in the development of activity theory. Finally, they outline current and future issues in activity theory, providing a comparative analysis of the theory and its leading theoretical competitors within interaction design: distributed cognition, actor-network theory, and phenomenologically inspired approaches.},
	language = {en},
	publisher = {MIT Press},
	author = {Kaptelinin, Victor and Nardi, Bonnie A.},
	month = oct,
	year = {2006},
	note = {Google-Books-ID: qYj6AQAAQBAJ},
}

@article{dolwick_search_2008,
	title = {In {Search} of the {Social}: {Steamboats}, {Square} {Wheels}, {Reindeer} and {Other} {Things}},
	volume = {3},
	issn = {1557-2293},
	shorttitle = {In {Search} of the {Social}},
	url = {https://doi.org/10.1007/s11457-008-9027-9},
	doi = {10.1007/s11457-008-9027-9},
	abstract = {This paper examines the concept of the ‘social,’ particularly from an archaeological perspective, and explores how it relates to the ways in which we seek to understand the processes of technological innovation and change. It is demonstrated that the concept ‘social’ is far from well defined and that enquiry is bedevilled by artificial polarization between subject-centred approaches and object-centred particularism. Through the medium of early United States steamboat technology a different approach is forged through the melding of people and things with the idea of viewing artefacts as active social actors along with people. Ultimately, it is argued that maritime archaeologists should be more bullish in their approaches to material things—instead of adopting social theories ‘wholesale,’ we should insist that they include the things we study: boats, material objects, people, artefacts, landscapes and animals.},
	language = {en},
	number = {1},
	urldate = {2023-05-12},
	journal = {Journal of Maritime Archaeology},
	author = {Dolwick, Jim S.},
	month = jun,
	year = {2008},
	pages = {15--41},
}

@article{do_err_2023,
	title = {To {Err} is {AI}: {Imperfect} {Interventions} and {Repair} in a {Conversational} {Agent} {Facilitating} {Group} {Chat} {Discussions}},
	volume = {7},
	shorttitle = {To {Err} is {AI}},
	url = {https://dl.acm.org/doi/10.1145/3579532},
	doi = {10.1145/3579532},
	abstract = {Conversational agents (CAs) can analyze online conversations using natural language techniques and effectively facilitate group discussions by sending supervisory messages. However, if a CA makes imperfect interventions, users may stop trusting the CA and discontinue using it. In this study, we demonstrate how inaccurate interventions of a CA and a conversational repair strategy can influence user acceptance of the CA, members' participation in the discussion, perceived discussion experience between the members, and group performance. We built a CA that encourages the participation of members with low contributions in an online chat discussion in which a small group (3-6 members) performs a decision-making task. Two types of errors can occur when detecting under-contributing members: 1) false-positive (FP) errors happen when the CA falsely identifies a member as under-contributing and 2) false-negative (FN) errors occur when the CA misses detecting an under-contributing member. We designed a conversational repair strategy that gives users a chance to contest the detection results and the agent sends a correctional message if an error is detected. Through an online study with 175 participants, we found that participants who received FN error messages reported higher acceptance of the CA and better discussion experience, but participated less compared to those who received FP error messages. The conversational repair strategy moderated the effect of errors such as improving the perceived discussion experience of participants who received FP error messages. Based on our findings, we offer design implications for which model should be selected by practitioners between high precision (i.e., fewer FP errors) and high recall (i.e., fewer FN errors) models depending on the desired effects. When frequent FP errors are expected, we suggest using the conversational repair strategy to improve the perceived discussion experience.},
	number = {CSCW1},
	urldate = {2023-05-12},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Do, Hyo Jin and Kong, Ha-Kyung and Tetali, Pooja and Lee, Jaewook and Bailey, Brian P.},
	month = apr,
	year = {2023},
	pages = {99:1--99:23},
}

@book{weizenbaum_computer_1976,
	address = {San Francisco},
	title = {Computer power and human reason: from judgment to calculation},
	isbn = {978-0-7167-0464-5},
	shorttitle = {Computer power and human reason},
	publisher = {W. H. Freeman},
	author = {Weizenbaum, Joseph},
	year = {1976},
}

@inproceedings{madureira_instruction_2023,
	address = {Dubrovnik, Croatia},
	title = {Instruction {Clarification} {Requests} in {Multimodal} {Collaborative} {Dialogue} {Games}: {Tasks}, and an {Analysis} of the {CoDraw} {Dataset}},
	shorttitle = {Instruction {Clarification} {Requests} in {Multimodal} {Collaborative} {Dialogue} {Games}},
	url = {https://aclanthology.org/2023.eacl-main.169},
	abstract = {In visual instruction-following dialogue games, players can engage in repair mechanisms in face of an ambiguous or underspecified instruction that cannot be fully mapped to actions in the world. In this work, we annotate Instruction Clarification Requests (iCRs) in CoDraw, an existing dataset of interactions in a multimodal collaborative dialogue game. We show that it contains lexically and semantically diverse iCRs being produced self-motivatedly by players deciding to clarify in order to solve the task successfully. With 8.8k iCRs found in 9.9k dialogues, CoDraw-iCR (v1) is a large spontaneous iCR corpus, making it a valuable resource for data-driven research on clarification in dialogue. We then formalise and provide baseline models for two tasks: Determining when to make an iCR and how to recognise them, in order to investigate to what extent these tasks are learnable from data.},
	urldate = {2023-05-02},
	booktitle = {Proceedings of the 17th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Madureira, Brielen and Schlangen, David},
	month = may,
	year = {2023},
	pages = {2295--2311},
}

@article{hoymann_questions_2010,
	title = {Questions and responses in ╪Ākhoe {Hai}{\textbar}{\textbar}om},
	volume = {42},
	issn = {03782166},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378216610001049},
	doi = {10.1016/j.pragma.2010.04.008},
	abstract = {This paper examines ǂĀkhoe Haiǀǀom, a Khoe language of the Khoisan family spoken in Northern Namibia. I document the way questions are posed in natural conversation, the actions the questions are used for and the manner in which they are responded to.},
	language = {en},
	number = {10},
	urldate = {2023-04-28},
	journal = {Journal of Pragmatics},
	author = {Hoymann, Gertie},
	month = oct,
	year = {2010},
	pages = {2726--2740},
}

@article{van_miltenburg_barriers_2023,
	title = {Barriers and enabling factors for error analysis in {NLG} research},
	volume = {9},
	copyright = {Copyright (c) 2023 Emiel van Miltenburg, Miruna Clinciu, Ondřej Dušek, Dimitra Gkatzia, Stephanie Inglis, Leo Leppänen, Saad Mahamood, Stephanie Schoch, Craig Thomson, Luou Wen},
	issn = {2000-1533},
	url = {https://nejlt.ep.liu.se/article/view/4529},
	doi = {10.3384/nejlt.2000-1533.2023.4529},
	abstract = {Earlier research has shown that few studies in Natural Language Generation (NLG) evaluate their system outputs using an error analysis, despite known limitations of automatic evaluation metrics and human ratings. This position paper takes the stance that error analyses should be encouraged, and discusses several ways to do so. This paper is not just based on our shared experience as authors, but we also distributed a survey as a means of public consultation. We provide an overview of existing barriers to carry out error analyses, and proposes changes to improve error reporting in the NLG literature.},
	language = {en},
	number = {1},
	urldate = {2023-02-22},
	journal = {Northern European Journal of Language Technology},
	author = {van Miltenburg, Emiel and Clinciu, Miruna and Dušek, Ondřej and Gkatzia, Dimitra and Inglis, Stephanie and Leppänen, Leo and Mahamood, Saad and Schoch, Stephanie and Thomson, Craig and Wen, Luou},
	month = feb,
	year = {2023},
	note = {Number: 1},
}

@inproceedings{teehan_emergent_2022,
	address = {virtual+Dublin},
	title = {Emergent {Structures} and {Training} {Dynamics} in {Large} {Language} {Models}},
	url = {https://aclanthology.org/2022.bigscience-1.11},
	doi = {10.18653/v1/2022.bigscience-1.11},
	abstract = {Large language models have achieved success on a number of downstream tasks, particularly in a few and zero-shot manner. As a consequence, researchers have been investigating both the kind of information these networks learn and how such information can be encoded in the parameters of the model. We survey the literature on changes in the network during training, drawing from work outside of NLP when necessary, and on learned representations of linguistic features in large language models. We note in particular the lack of sufficient research on the emergence of functional units, subsections of the network where related functions are grouped or organised, within large language models and motivate future work that grounds the study of language models in an analysis of their changing internal structure during training time.},
	urldate = {2023-04-17},
	booktitle = {Proceedings of {BigScience} {Episode} \#5 – {Workshop} on {Challenges} \& {Perspectives} in {Creating} {Large} {Language} {Models}},
	publisher = {Association for Computational Linguistics},
	author = {Teehan, Ryan and Clinciu, Miruna and Serikov, Oleg and Szczechla, Eliza and Seelam, Natasha and Mirkin, Shachar and Gokaslan, Aaron},
	month = may,
	year = {2022},
	pages = {146--159},
}

@misc{tamkin_understanding_2021,
	title = {Understanding the {Capabilities}, {Limitations}, and {Societal} {Impact} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2102.02503},
	doi = {10.48550/arXiv.2102.02503},
	abstract = {On October 14th, 2020, researchers from OpenAI, the Stanford Institute for Human-Centered Artificial Intelligence, and other universities convened to discuss open research questions surrounding GPT-3, the largest publicly-disclosed dense language model at the time. The meeting took place under Chatham House Rules. Discussants came from a variety of research backgrounds including computer science, linguistics, philosophy, political science, communications, cyber policy, and more. Broadly, the discussion centered around two main questions: 1) What are the technical capabilities and limitations of large language models? 2) What are the societal effects of widespread use of large language models? Here, we provide a detailed summary of the discussion organized by the two themes above.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Tamkin, Alex and Brundage, Miles and Clark, Jack and Ganguli, Deep},
	month = feb,
	year = {2021},
	note = {arXiv:2102.02503 [cs]},
}

@misc{ortega_modeling_2023,
	title = {Modeling {Speaker}-{Listener} {Interaction} for {Backchannel} {Prediction}},
	url = {http://arxiv.org/abs/2304.04472},
	doi = {10.48550/arXiv.2304.04472},
	abstract = {We present our latest findings on backchannel modeling novelly motivated by the canonical use of the minimal responses Yeah and Uh-huh in English and their correspondent tokens in German, and the effect of encoding the speaker-listener interaction. Backchanneling theories emphasize the active and continuous role of the listener in the course of the conversation, their effects on the speaker's subsequent talk, and the consequent dynamic speaker-listener interaction. Therefore, we propose a neural-based acoustic backchannel classifier on minimal responses by processing acoustic features from the speaker speech, capturing and imitating listeners' backchanneling behavior, and encoding speaker-listener interaction. Our experimental results on the Switchboard and GECO datasets reveal that in almost all tested scenarios the speaker or listener behavior embeddings help the model make more accurate backchannel predictions. More importantly, a proper interaction encoding strategy, i.e., combining the speaker and listener embeddings, leads to the best performance on both datasets in terms of F1-score.},
	urldate = {2023-04-14},
	publisher = {arXiv},
	author = {Ortega, Daniel and Meyer, Sarina and Schweitzer, Antje and Vu, Ngoc Thang},
	month = apr,
	year = {2023},
	note = {arXiv:2304.04472 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{norori_addressing_2021,
	title = {Addressing bias in big data and {AI} for health care: {A} call for open science},
	volume = {2},
	issn = {2666-3899},
	shorttitle = {Addressing bias in big data and {AI} for health care},
	url = {https://www.sciencedirect.com/science/article/pii/S2666389921002026},
	doi = {10.1016/j.patter.2021.100347},
	abstract = {Artificial intelligence (AI) has an astonishing potential in assisting clinical decision making and revolutionizing the field of health care. A major open challenge that AI will need to address before its integration in the clinical routine is that of algorithmic bias. Most AI algorithms need big datasets to learn from, but several groups of the human population have a long history of being absent or misrepresented in existing biomedical datasets. If the training data is misrepresentative of the population variability, AI is prone to reinforcing bias, which can lead to fatal outcomes, misdiagnoses, and lack of generalization. Here, we describe the challenges in rendering AI algorithms fairer, and we propose concrete steps for addressing bias using tools from the field of open science.},
	language = {en},
	number = {10},
	urldate = {2023-04-17},
	journal = {Patterns},
	author = {Norori, Natalia and Hu, Qiyang and Aellen, Florence Marcelle and Faraci, Francesca Dalia and Tzovara, Athina},
	month = oct,
	year = {2021},
	pages = {100347},
}

@inproceedings{liesenfeld_bottom-up_2022,
	title = {Bottom-up discovery of structure and variation in response tokens (‘backchannels’) across diverse languages},
	shorttitle = {Proc. {Interspeech} 2022},
	url = {https://www.isca-speech.org/archive/interspeech_2022/liesenfeld22_interspeech.html},
	doi = {10.21437/Interspeech.2022-11288},
	language = {en},
	urldate = {2022-09-20},
	booktitle = {Proceedings of {Interspeech} 2022},
	publisher = {ISCA},
	author = {Liesenfeld, Andreas and Dingemanse, Mark},
	month = sep,
	year = {2022},
	pages = {1126--1130},
}

@article{wollheim_cabinet_1991,
	title = {The cabinet of {Dr}. {Lacan}},
	volume = {10},
	issn = {0167-7411, 1572-8749},
	url = {http://link.springer.com/10.1007/BF00141337},
	doi = {10.1007/BF00141337},
	language = {en},
	number = {2},
	urldate = {2023-04-21},
	journal = {Topoi},
	author = {Wollheim, Richard},
	month = sep,
	year = {1991},
	pages = {163--174},
}

@book{hofstatter_adornos_2022,
	title = {Adorno’s {Rhinoceros}: {Art}, {Nature}, {Critique}},
	isbn = {978-1-350-17782-6},
	shorttitle = {Adorno’s {Rhinoceros}},
	abstract = {Throughout his work, the philosopher Theodor W. Adorno repeatedly invokes the rhinoceros. Taking its cue from one of these passages in Aesthetic Theory, 'So a rhinoceros, the mute animal, seems to say: I am a rhinoceros', this book explores the life of this animal in Adorno's texts, and articulates the nuanced interconnections between art, nature and critique in his thought.By thus illuminating key elements of Adorno's work, this volume reveals the invaluable contributions that this 'classical' thinker can make to our current reflections on the various pressing natural and political crises of our times.},
	language = {en},
	publisher = {Bloomsbury Publishing},
	author = {Hofstätter, Antonia and Steuer, Daniel},
	month = jan,
	year = {2022},
	note = {Google-Books-ID: \_mxWEAAAQBAJ},
}

@article{pandey_openai_2023,
	title = {{OpenAI} {Might} {Invite} {Legal} {Trouble}},
	url = {https://analyticsindiamag.com/openai-might-invite-legal-trouble/},
	abstract = {OpenAI discontinues Codex. A well thought out, smart but rushed move.},
	language = {en-US},
	urldate = {2023-04-20},
	journal = {Analytics India Magazine},
	author = {Pandey, Mohit},
	month = mar,
	year = {2023},
}

@misc{sam_altman_sama_goodside_2023,
	type = {Tweet},
	title = {@goodside we didn’t realize how much people liked this model; we will continue to support it for researchers!},
	url = {https://twitter.com/sama/status/1638420361397309441},
	language = {en},
	urldate = {2023-04-20},
	journal = {Twitter},
	author = {{Sam Altman [@sama]}},
	month = mar,
	year = {2023},
}

@inproceedings{tatman_practical_2018,
	title = {A {Practical} {Taxonomy} of {Reproducibility} for {Machine} {Learning} {Research}},
	abstract = {Discussions of reproducibility in science are often framed from the perspective of scientists and researchers who want to validate published claims. A complementary perspective is that of the practitioner who sets out to apply a new computational method within their own domain, the ﬁrst step of which is often to reproduce the published results as a check for correctness of code. In this paper we discuss a taxonomy of reproducibility from this perspective of a practitioner. Low reproducibility studies are those which merely describe algorithms, medium reproducibility studies are those which provide the code and data but not the computational environment in which the code can be run, and high reproducibility studies are those which provide the code, data, and full computational environment necessary to reproduce the results of the study. We identify some exemplars of each of these types of reproducibility from the machine learning literature, motivate the case for high reproducibility studies, and discuss concrete tools and strategies for researchers who wish to ensure easy adoption of their methods by practitioners.},
	language = {en},
	booktitle = {Reproducibility in {Machine} {Learning} {Workshop} at {ICML} 2018},
	author = {Tatman, Rachael and VanderPlas, Jake and Dane, Sohier},
	year = {2018},
}

@misc{albertoni_reproducibility_2023,
	title = {Reproducibility of {Machine} {Learning}: {Terminology}, {Recommendations} and {Open} {Issues}},
	shorttitle = {Reproducibility of {Machine} {Learning}},
	url = {http://arxiv.org/abs/2302.12691},
	abstract = {Reproducibility is one of the core dimensions that concur to deliver Trustworthy Artificial Intelligence. Broadly speaking, reproducibility can be defined as the possibility to reproduce the same or a similar experiment or method, thereby obtaining the same or similar results as the original scientists. It is an essential ingredient of the scientific method and crucial for gaining trust in relevant claims. A reproducibility crisis has been recently acknowledged by scientists and this seems to affect even more Artificial Intelligence and Machine Learning, due to the complexity of the models at the core of their recent successes. Notwithstanding the recent debate on Artificial Intelligence reproducibility, its practical implementation is still insufficient, also because many technical issues are overlooked. In this survey, we critically review the current literature on the topic and highlight the open issues. Our contribution is three-fold. We propose a concise terminological review of the terms coming into play. We collect and systematize existing recommendations for achieving reproducibility, putting forth the means to comply with them. We identify key elements often overlooked in modern Machine Learning and provide novel recommendations for them. We further specialize these for two critical application domains, namely the biomedical and physical artificial intelligence fields.},
	urldate = {2023-04-20},
	publisher = {arXiv},
	author = {Albertoni, Riccardo and Colantonio, Sara and Skrzypczyński, Piotr and Stefanowski, Jerzy},
	month = feb,
	year = {2023},
	note = {arXiv:2302.12691 [cs]},
}

@inproceedings{muller_forgetting_2022,
	address = {New York, NY, USA},
	series = {{CHI} '22},
	title = {Forgetting {Practices} in the {Data} {Sciences}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517644},
	doi = {10.1145/3491102.3517644},
	abstract = {HCI engages with data science through many topics and themes. Researchers have addressed biased dataset problems, arguing that bad data can cause innocent software to produce bad outcomes. But what if our software is not so innocent? What if the human decisions that shape our data-processing software, inadvertently contribute their own sources of bias? And what if our data-work technology causes us to forget those decisions and operations? Based in feminisms and critical computing, we analyze forgetting practices in data work practices. We describe diverse beneficial and harmful motivations for forgetting. We contribute: (1) a taxonomy of data silences in data work, which we use to analyze how data workers forget, erase, and unknow aspects of data; (2) a detailed analysis of forgetting practices in machine learning; and (3) an analytic vocabulary for future work in remembering, forgetting, and erasing in HCI and the data sciences.},
	urldate = {2023-04-19},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Muller, Michael and Strohmayer, Angelika},
	month = apr,
	year = {2022},
	pages = {1--19},
}

@inproceedings{cambo_model_2022,
	address = {New York, NY, USA},
	series = {{CHI} '22},
	title = {Model {Positionality} and {Computational} {Reflexivity}: {Promoting} {Reflexivity} in {Data} {Science}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {Model {Positionality} and {Computational} {Reflexivity}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3501998},
	doi = {10.1145/3491102.3501998},
	abstract = {Data science and machine learning provide indispensable techniques for understanding phenomena at scale, but the discretionary choices made when doing this work are often not recognized. Drawing from qualitative research practices, we describe how the concepts of positionality and reflexivity can be adapted to provide a framework for understanding, discussing, and disclosing the discretionary choices and subjectivity inherent to data science work. We first introduce the concepts of model positionality and computational reflexivity that can help data scientists to reflect on and communicate the social and cultural context of a model’s development and use, the data annotators and their annotations, and the data scientists themselves. We then describe the unique challenges of adapting these concepts for data science work and offer annotator fingerprinting and position mining as promising solutions. Finally, we demonstrate these techniques in a case study of the development of classifiers for toxic commenting in online communities.},
	urldate = {2023-04-19},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cambo, Scott Allen and Gergle, Darren},
	month = apr,
	year = {2022},
	pages = {1--19},
}

@article{cabrera_what_2023,
	title = {What {Did} {My} {AI} {Learn}? {How} {Data} {Scientists} {Make} {Sense} of {Model} {Behavior}},
	volume = {30},
	issn = {1073-0516},
	shorttitle = {What {Did} {My} {AI} {Learn}?},
	url = {https://dl.acm.org/doi/10.1145/3542921},
	doi = {10.1145/3542921},
	abstract = {Data scientists require rich mental models of how AI systems behave to effectively train, debug, and work with them. Despite the prevalence of AI analysis tools, there is no general theory describing how people make sense of what their models have learned. We frame this process as a form of sensemaking and derive a framework describing how data scientists develop mental models of AI behavior. To evaluate the framework, we show how existing AI analysis tools fit into this sensemaking process and use it to design AIFinnity, a system for analyzing image-and-text models. Lastly, we explored how data scientists use a tool developed with the framework through a think-aloud study with 10 data scientists tasked with using AIFinnity to pick an image captioning model. We found that AIFinnity’s sensemaking workflow reflected participants’ mental processes and enabled them to discover and validate diverse AI behaviors.},
	number = {1},
	urldate = {2023-04-19},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Cabrera, Ángel Alexander and Tulio Ribeiro, Marco and Lee, Bongshin and Deline, Robert and Perer, Adam and Drucker, Steven M.},
	year = {2023},
	pages = {1:1--1:27},
}

@inproceedings{crisan_interactive_2022,
	address = {New York, NY, USA},
	series = {{FAccT} '22},
	title = {Interactive {Model} {Cards}: {A} {Human}-{Centered} {Approach} to {Model} {Documentation}},
	isbn = {978-1-4503-9352-2},
	shorttitle = {Interactive {Model} {Cards}},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533108},
	doi = {10.1145/3531146.3533108},
	abstract = {Deep learning models for natural language processing (NLP) are increasingly adopted and deployed by analysts without formal training in NLP or machine learning (ML). However, the documentation intended to convey the model’s details and appropriate use is tailored primarily to individuals with ML or NLP expertise. To address this gap, we conduct a design inquiry into interactive model cards, which augment traditionally static model cards with affordances for exploring model documentation and interacting with the models themselves. Our investigation consists of an initial conceptual study with experts in ML, NLP, and AI Ethics, followed by a separate evaluative study with non-expert analysts who use ML models in their work. Using a semi-structured interview format coupled with a think-aloud protocol, we collected feedback from a total of 30 participants who engaged with different versions of standard and interactive model cards. Through a thematic analysis of the collected data, we identified several conceptual dimensions that summarize the strengths and limitations of standard and interactive model cards, including: stakeholders; design; guidance; understandability \& interpretability; sensemaking \& skepticism; and trust \& safety. Our findings demonstrate the importance of carefully considered design and interactivity for orienting and supporting non-expert analysts using deep learning models, along with a need for consideration of broader sociotechnical contexts and organizational dynamics. We have also identified design elements, such as language, visual cues, and warnings, among others, that support interactivity and make non-interactive content accessible. We summarize our findings as design guidelines and discuss their implications for a human-centered approach towards AI/ML documentation.},
	urldate = {2023-04-19},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Crisan, Anamaria and Drouhard, Margaret and Vig, Jesse and Rajani, Nazneen},
	month = jun,
	year = {2022},
	pages = {427--439},
}

@article{henderson_pile_2022,
	title = {Pile of {Law}: {Learning} {Responsible} {Data} {Filtering} from the {Law} and a {256GB} {Open}-{Source} {Legal} {Dataset}},
	volume = {35},
	shorttitle = {Pile of {Law}},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/bc218a0c656e49d4b086975a9c785f47-Abstract-Datasets_and_Benchmarks.html},
	language = {en},
	urldate = {2023-04-19},
	journal = {Advances in Neural Information Processing Systems},
	author = {Henderson, Peter and Krass, Mark and Zheng, Lucia and Guha, Neel and Manning, Christopher D. and Jurafsky, Dan and Ho, Daniel},
	month = dec,
	year = {2022},
	pages = {29217--29234},
}

@inproceedings{sambasivan_deskilling_2022,
	address = {New York, NY, USA},
	series = {{CHI} '22},
	title = {The {Deskilling} of {Domain} {Expertise} in {AI} {Development}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517578},
	doi = {10.1145/3491102.3517578},
	abstract = {Field workers, like farmers and radiologists, play a crucial role in dataset collection for AI models in low-resource settings. However, we know little about how field workers’ expertise is leveraged in dataset and model development. Based on 68 interviews with AI developers building for low-resource contexts, we find that developers reduced field workers to data collectors. Attributing poor data quality to worker practices, developers conceived of workers as corrupt, lazy, non-compliant, and as datasets themselves, pursuing surveillance and gamification to discipline workers to collect better quality data. Even though models sought to emulate the expertise of field workers, AI developers treated workers as non-essential and deskilled their expertise in service of building machine intelligence. We make the case for why field workers should be recognised as domain experts and re-imagine domain expertise as an essential partnership for AI development.},
	urldate = {2023-04-19},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sambasivan, Nithya and Veeraraghavan, Rajesh},
	month = apr,
	year = {2022},
	pages = {1--14},
}

@inproceedings{nahar_collaboration_2022,
	address = {New York, NY, USA},
	series = {{ICSE} '22},
	title = {Collaboration challenges in building {ML}-enabled systems: communication, documentation, engineering, and process},
	isbn = {978-1-4503-9221-1},
	shorttitle = {Collaboration challenges in building {ML}-enabled systems},
	url = {https://dl.acm.org/doi/10.1145/3510003.3510209},
	doi = {10.1145/3510003.3510209},
	abstract = {The introduction of machine learning (ML) components in software projects has created the need for software engineers to collaborate with data scientists and other specialists. While collaboration can always be challenging, ML introduces additional challenges with its exploratory model development process, additional skills and knowledge needed, difficulties testing ML systems, need for continuous evolution and monitoring, and non-traditional quality requirements such as fairness and explainability. Through interviews with 45 practitioners from 28 organizations, we identified key collaboration challenges that teams face when building and deploying ML systems into production. We report on common collaboration points in the development of production ML systems for requirements, data, and integration, as well as corresponding team patterns and challenges. We find that most of these challenges center around communication, documentation, engineering, and process, and collect recommendations to address these challenges.},
	urldate = {2023-04-19},
	booktitle = {Proceedings of the 44th {International} {Conference} on {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Nahar, Nadia and Zhou, Shurui and Lewis, Grace and Kästner, Christian},
	month = jul,
	year = {2022},
	pages = {413--425},
}

@article{liang_advances_2022,
	title = {Advances, challenges and opportunities in creating data for trustworthy {AI}},
	volume = {4},
	copyright = {2022 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-022-00516-1},
	doi = {10.1038/s42256-022-00516-1},
	abstract = {As artificial intelligence (AI) transitions from research to deployment, creating the appropriate datasets and data pipelines to develop and evaluate AI models is increasingly the biggest challenge. Automated AI model builders that are publicly available can now achieve top performance in many applications. In contrast, the design and sculpting of the data used to develop AI often rely on bespoke manual work, and they critically affect the trustworthiness of the model. This Perspective discusses key considerations for each stage of the data-for-AI pipeline—starting from data design to data sculpting (for example, cleaning, valuation and annotation) and data evaluation—to make AI more reliable. We highlight technical advances that help to make the data-for-AI pipeline more scalable and rigorous. Furthermore, we discuss how recent data regulations and policies can impact AI.},
	language = {en},
	number = {8},
	urldate = {2023-04-19},
	journal = {Nature Machine Intelligence},
	author = {Liang, Weixin and Tadesse, Girmaw Abebe and Ho, Daniel and Fei-Fei, L. and Zaharia, Matei and Zhang, Ce and Zou, James},
	month = aug,
	year = {2022},
	note = {Number: 8
Publisher: Nature Publishing Group},
	pages = {669--677},
}

@inproceedings{hutchinson_towards_2021,
	address = {New York, NY, USA},
	series = {{FAccT} '21},
	title = {Towards {Accountability} for {Machine} {Learning} {Datasets}: {Practices} from {Software} {Engineering} and {Infrastructure}},
	isbn = {978-1-4503-8309-7},
	shorttitle = {Towards {Accountability} for {Machine} {Learning} {Datasets}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445918},
	doi = {10.1145/3442188.3445918},
	abstract = {Datasets that power machine learning are often used, shared, and reused with little visibility into the processes of deliberation that led to their creation. As artificial intelligence systems are increasingly used in high-stakes tasks, system development and deployment practices must be adapted to address the very real consequences of how model development data is constructed and used in practice. This includes greater transparency about data, and accountability for decisions made when developing it. In this paper, we introduce a rigorous framework for dataset development transparency that supports decision-making and accountability. The framework uses the cyclical, infrastructural and engineering nature of dataset development to draw on best practices from the software development lifecycle. Each stage of the data development lifecycle yields documents that facilitate improved communication and decision-making, as well as drawing attention to the value and necessity of careful data work. The proposed framework makes visible the often overlooked work and decisions that go into dataset creation, a critical step in closing the accountability gap in artificial intelligence and a critical/necessary resource aligned with recent work on auditing processes.},
	urldate = {2023-04-19},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Hutchinson, Ben and Smart, Andrew and Hanna, Alex and Denton, Emily and Greer, Christina and Kjartansson, Oddur and Barnes, Parker and Mitchell, Margaret},
	year = {2021},
	pages = {560--575},
}

@article{heikkila_openais_2023,
	title = {{OpenAI}’s hunger for data is coming back to bite it},
	url = {https://www.technologyreview.com/2023/04/19/1071789/openais-hunger-for-data-is-coming-back-to-bite-it/},
	abstract = {The company’s AI services may be breaking data protection laws, and there is no resolution in sight.},
	language = {en},
	urldate = {2023-04-19},
	journal = {MIT Technology Review},
	author = {Heikkilä, Melissa},
	year = {2023},
}

@article{northcutt_pervasive_nodate,
	title = {Pervasive {Label} {Errors} in {Test} {Sets} {Destabilize} {Machine} {Learning} {Benchmarks}},
	abstract = {We identify label errors in the test sets of 10 of the most commonly-used computer vision, natural language, and audio datasets, and subsequently study the potential for these label errors to affect benchmark results. Errors in test sets are numerous and widespread: we estimate an average of at least 3.3\% errors across the 10 datasets, where for example label errors comprise at least 6\% of the ImageNet validation set. Putative label errors are identiﬁed using conﬁdent learning algorithms and then human-validated via crowdsourcing (51\% of the algorithmically-ﬂagged candidates are indeed erroneously labeled, on average across the datasets). Traditionally, machine learning practitioners choose which model to deploy based on test accuracy — our ﬁndings advise caution here, proposing that judging models over correctly labeled test sets may be more useful, especially for noisy real-world datasets. Surprisingly, we ﬁnd that lower capacity models may be practically more useful than higher capacity models in real-world datasets with high proportions of erroneously labeled data. For example, on ImageNet with corrected labels: ResNet-18 outperforms ResNet-50 if the prevalence of originally mislabeled test examples increases by just 6\%. On CIFAR-10 with corrected labels: VGG-11 outperforms VGG-19 if the prevalence of originally mislabeled test examples increases by just 5\%. Test set errors across the 10 datasets can be viewed at https://labelerrors.com and all label errors can be reproduced by https://github.com/cleanlab/label-errors.},
	language = {en},
	author = {Northcutt, Curtis G and Athalye, Anish and Mueller, Jonas},
}

@article{sambasivan_all_2022,
	title = {All equation, no human: the myopia of {AI} models},
	volume = {29},
	issn = {1072-5520, 1558-3449},
	shorttitle = {All equation, no human},
	url = {https://dl.acm.org/doi/10.1145/3516515},
	doi = {10.1145/3516515},
	abstract = {This is a forum for perspectives on designing for marginalized communities worldwide. Articles will discuss design methods, theoretical/conceptual contributions, and participatory interventions with underserved communities.
              --- Nithya Sambasivan, Editor},
	language = {en},
	number = {2},
	urldate = {2023-04-19},
	journal = {Interactions},
	author = {Sambasivan, Nithya},
	month = mar,
	year = {2022},
	pages = {78--80},
}

@article{paullada_data_2021,
	title = {Data and its (dis)contents: {A} survey of dataset development and use in machine learning research},
	volume = {2},
	issn = {2666-3899},
	shorttitle = {Data and its (dis)contents},
	url = {https://www.sciencedirect.com/science/article/pii/S2666389921001847},
	doi = {10.1016/j.patter.2021.100336},
	abstract = {In this work, we survey a breadth of literature that has revealed the limitations of predominant practices for dataset collection and use in the field of machine learning. We cover studies that critically review the design and development of datasets with a focus on negative societal impacts and poor outcomes for system performance. We also cover approaches to filtering and augmenting data and modeling techniques aimed at mitigating the impact of bias in datasets. Finally, we discuss works that have studied data practices, cultures, and disciplinary norms and discuss implications for the legal, ethical, and functional challenges the field continues to face. Based on these findings, we advocate for the use of both qualitative and quantitative approaches to more carefully document and analyze datasets during the creation and usage phases.},
	language = {en},
	number = {11},
	urldate = {2023-04-19},
	journal = {Patterns},
	author = {Paullada, Amandalynne and Raji, Inioluwa Deborah and Bender, Emily M. and Denton, Emily and Hanna, Alex},
	month = nov,
	year = {2021},
	pages = {100336},
}

@misc{dodge_documenting_2021,
	title = {Documenting {Large} {Webtext} {Corpora}: {A} {Case} {Study} on the {Colossal} {Clean} {Crawled} {Corpus}},
	shorttitle = {Documenting {Large} {Webtext} {Corpora}},
	url = {http://arxiv.org/abs/2104.08758},
	doi = {10.48550/arXiv.2104.08758},
	abstract = {Large language models have led to remarkable progress on many NLP tasks, and researchers are turning to ever-larger text corpora to train them. Some of the largest corpora available are made by scraping significant portions of the internet, and are frequently introduced with only minimal documentation. In this work we provide some of the first documentation for the Colossal Clean Crawled Corpus (C4; Raffel et al., 2020), a dataset created by applying a set of filters to a single snapshot of Common Crawl. We begin by investigating where the data came from, and find a significant amount of text from unexpected sources like patents and US military websites. Then we explore the content of the text itself, and find machine-generated text (e.g., from machine translation systems) and evaluation examples from other benchmark NLP datasets. To understand the impact of the filters applied to create this dataset, we evaluate the text that was removed, and show that blocklist filtering disproportionately removes text from and about minority individuals. Finally, we conclude with some recommendations for how to created and document web-scale datasets from a scrape of the internet.},
	urldate = {2023-04-19},
	publisher = {arXiv},
	author = {Dodge, Jesse and Sap, Maarten and Marasović, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Mitchell, Margaret and Gardner, Matt},
	month = sep,
	year = {2021},
	note = {arXiv:2104.08758 [cs]},
}

@inproceedings{sambasivan_everyone_2021,
	address = {Yokohama Japan},
	title = {“{Everyone} wants to do the model work, not the data work”: {Data} {Cascades} in {High}-{Stakes} {AI}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {“{Everyone} wants to do the model work, not the data work”},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445518},
	doi = {10.1145/3411764.3445518},
	abstract = {AI models are increasingly applied in high-stakes domains like health and conservation. Data quality carries an elevated significance in high-stakes AI due to its heightened downstream impact, impacting predictions like cancer detection, wildlife poaching, and loan allocations. Paradoxically, data is the most under-valued and de-glamorised aspect of AI. In this paper, we report on data practices in high-stakes AI, from interviews with 53 AI practitioners in India, East and West African countries, and USA. We define, identify, and present empirical evidence on Data Cascades—compounding events causing negative, downstream effects from data issues—triggered by conventional AI/ML practices that undervalue data quality. Data cascades are pervasive (92\% prevalence), invisible, delayed, but often avoidable. We discuss HCI opportunities in designing and incentivizing data excellence as a first-class citizen of AI, resulting in safer and more robust systems for all.},
	language = {en},
	urldate = {2023-04-19},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Sambasivan, Nithya and Kapania, Shivani and Highfill, Hannah and Akrong, Diana and Paritosh, Praveen and Aroyo, Lora M},
	month = may,
	year = {2021},
	pages = {1--15},
}

@article{spirling_why_2023,
	title = {Why open-source generative {AI} models are an ethical way forward for science},
	volume = {616},
	copyright = {2023 Springer Nature Limited},
	url = {https://www.nature.com/articles/d41586-023-01295-4},
	doi = {10.1038/d41586-023-01295-4},
	abstract = {Researchers should avoid the lure of proprietary models and develop transparent large language models to ensure reproducibility.},
	language = {en},
	number = {7957},
	urldate = {2023-04-19},
	journal = {Nature},
	author = {Spirling, Arthur},
	month = apr,
	year = {2023},
	note = {Bandiera\_abtest: a
Cg\_type: World View
Number: 7957
Publisher: Nature Publishing Group
Subject\_term: Ethics, Machine learning, Technology, Scientific community},
	pages = {413--413},
}

@article{kawahara_benchmark_2003,
	title = {Benchmark {Test} {For} {Speech} {Recognition} {Using} {The} {Corpus} . . .},
	abstract = {We present benchmark results of automatic speech recognition using the Corpus of Spontaneous Japanese (CSJ), which has been developed in the five-year na- tional project and will be the largest spontaneous speech databases. New test-sets are designed for both academic presentation speech and extemporaneous public speech, which are the two major categories in the corpus. The test- sets are selected to cover the variation of acoustic and lin- guistic factors in spontaneous speech: word perplexity, de- gree of disfluency, and the speaking rate. Baseline acoustic andlanguagemodelsare setupusinganalmostcompleteset (500 hours and 6.67M words) of the CSJ. Statistical model- ing of pronunciation variation is also incorporated into the language model based on the alignment of large-scale tran- scriptions. The benchmark results verified the effects of the factors considered in the test-set design.},
	author = {Kawahara, Tatsuya and Nanjo, Hiroaki and Shinozaki, Takahiro and Furui, Sadaoki},
	month = jan,
	year = {2003},
}

@inproceedings{furui_generalization_2010,
	title = {Generalization problem in {ASR} acoustic model training and adaptation},
	doi = {10.1109/ASRU.2009.5373493},
	abstract = {Since speech is highly variable, even if we have a fairly large-scale database, we cannot avoid the data sparseness problem in constructing automatic speech recognition (ASR) systems. How to train and adapt statistical models using limited amounts of data is one of the most important research issues in ASR. This paper summarizes major techniques that have been proposed to solve the generalization problem in acoustic model training and adaptation, that is, how to achieve high recognition accuracy for new utterances. One of the common approaches is controlling the degree of freedom in model training and adaptation. The techniques can be classified by whether a priori knowledge of speech obtained by a speech database such as those spoken by many speakers is used or not. Another approach is maximizing Â¿marginsÂ¿ between training samples and the decision boundaries. Many of these techniques have also been combined and extended to further improve performance. Although many useful techniques have been developed, we still do not have a golden standard that can be applied to any kind of speech variation and any condition of the speech data available for training and adaptation.},
	author = {Furui, Sadaoki},
	month = jan,
	year = {2010},
	pages = {1--10},
}

@inproceedings{furui_why_2005,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Why {Is} the {Recognition} of {Spontaneous} {Speech} so {Hard}?},
	isbn = {978-3-540-31817-0},
	doi = {10.1007/11551874_3},
	abstract = {Although speech, derived from reading texts, and similar types of speech, e.g. that from reading newspapers or that from news broadcast, can be recognized with high accuracy, recognition accuracy drastically decreases for spontaneous speech. This is due to the fact that spontaneous speech and read speech are significantly different acoustically as well as linguistically. This paper reports analysis and recognition of spontaneous speech using a large-scale spontaneous speech database “Corpus of Spontaneous Japanese (CSJ)”. Recognition results in this experiment show that recognition accuracy significantly increases as a function of the size of acoustic as well as language model training data and the improvement levels off at approximately 7M words of training data. This means that acoustic and linguistic variation of spontaneous speech is so large that we need a very large corpus in order to encompass the variations. Spectral analysis using various styles of utterances in the CSJ shows that the spectral distribution/difference of phonemes is significantly reduced in spontaneous speech compared to read speech. Experimental results also show that there is a strong correlation between mean spectral distance between phonemes and phoneme recognition accuracy. This indicates that spectral reduction is one major reason for the decrease of recognition accuracy of spontaneous speech.},
	language = {en},
	booktitle = {Text, {Speech} and {Dialogue}},
	publisher = {Springer},
	author = {Furui, Sadaoki and Nakamura, Masanobu and Ichiba, Tomohisa and Iwano, Koji},
	editor = {Matoušek, Václav and Mautner, Pavel and Pavelka, Tomáš},
	year = {2005},
	keywords = {Recognition Accuracy, Repair Rate, Speech Recognition, Spontaneous Speech, Word Error Rate},
	pages = {9--22},
}

@article{shinozaki_analysis_2002,
	title = {Analysis on individual differences in automatic transcription of spontaneous presentations},
	volume = {1},
	doi = {10.1109/ICASSP.2002.5743821},
	abstract = {This paper reports an analysis of individual differences in spon-taneous presentation speech recognition performances. Ten min-utes from each presentation given by 50 male speakers, for a total of 500 minutes, has been automatically recognized for the analy-sis. Correlation and regression analyses were applied to the word recognition accuracy and various speaker attributes. A restricted set of the speaker attributes comprising the speaking rate, the out of vocabulary rate and the repair rate was found to be most signif-icant to yield individual differences in the word accuracy. Unsu-pervised MLLR speaker adaptation worked well for improving the word accuracy but did not change the structure of the individual differences. Approximately half of the variance in the word accu-racy was explained by a regression model using the limited set of three attributes.},
	author = {Shinozaki, Takahiro and Furui, Sadaoki},
	month = jan,
	year = {2002},
}

@misc{muennighoff_crosslingual_2022,
	title = {Crosslingual {Generalization} through {Multitask} {Finetuning}},
	url = {http://arxiv.org/abs/2211.01786},
	doi = {10.48550/arXiv.2211.01786},
	abstract = {Multitask prompted finetuning (MTF) has been shown to help large language models generalize to new tasks in a zero-shot setting, but so far explorations of MTF have focused on English data and models. We apply MTF to the pretrained multilingual BLOOM and mT5 model families to produce finetuned variants called BLOOMZ and mT0. We find finetuning large multilingual language models on English tasks with English prompts allows for task generalization to non-English languages that appear only in the pretraining corpus. Finetuning on multilingual tasks with English prompts further improves performance on English and non-English tasks leading to various state-of-the-art zero-shot results. We also investigate finetuning on multilingual tasks with prompts that have been machine-translated from English to match the language of each dataset. We find training on these machine-translated prompts leads to better performance on human-written prompts in the respective languages. Surprisingly, we find models are capable of zero-shot generalization to tasks in languages they have never intentionally seen. We conjecture that the models are learning higher-level capabilities that are both task- and language-agnostic. In addition, we introduce xP3, a composite of supervised datasets in 46 languages with English and machine-translated prompts. Our code, datasets and models are publicly available at https://github.com/bigscience-workshop/xmtf.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Muennighoff, Niklas and Wang, Thomas and Sutawika, Lintang and Roberts, Adam and Biderman, Stella and Scao, Teven Le and Bari, M. Saiful and Shen, Sheng and Yong, Zheng-Xin and Schoelkopf, Hailey and Tang, Xiangru and Radev, Dragomir and Aji, Alham Fikri and Almubarak, Khalid and Albanie, Samuel and Alyafeai, Zaid and Webson, Albert and Raff, Edward and Raffel, Colin},
	month = nov,
	year = {2022},
	note = {arXiv:2211.01786 [cs]},
}

@misc{bigscience_workshop_bloom_2023,
	title = {{BLOOM}: {A} {176B}-{Parameter} {Open}-{Access} {Multilingual} {Language} {Model}},
	doi = {10.48550/arXiv.2211.05100},
	abstract = {Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.},
	publisher = {arXiv},
	author = {BigScience Workshop},
	year = {2023},
}

@article{lambert_illustrating_2022,
	title = {Illustrating {Reinforcement} {Learning} from {Human} {Feedback} ({RLHF})},
	journal = {Hugging Face Blog},
	author = {Lambert, Nathan and Castricato, Louis and von Werra, Leandro and Havrilla, Alex},
	year = {2022},
}

@inproceedings{knox_tamer_2008,
	title = {{TAMER}: {Training} an {Agent} {Manually} via {Evaluative} {Reinforcement}},
	shorttitle = {{TAMER}},
	doi = {10.1109/DEVLRN.2008.4640845},
	abstract = {Though computers have surpassed humans at many tasks, especially computationally intensive ones, there are many tasks for which human expertise remains necessary and/or useful. For such tasks, it is desirable for a human to be able to transmit knowledge to a learning agent as quickly and effortlessly as possible, and, ideally, without any knowledge of the details of the agent’s learning process. This paper proposes a general framework called Training an Agent Manually via Evaluative Reinforcement (TAMER) that allows a human to train a learning agent to perform a common class of complex tasks simply by giving scalar reward signals in response to the agent’s observed actions. Specifically, in sequential decision making tasks, an agent models the human’s reward function and chooses actions that it predicts will receive the most reward. Our novel algorithm is fully implemented and tested on the game Tetris. Leveraging the human trainers’ feedback, the agent learns to clear an average of more than 50 lines by its third game, an order of magnitude faster than the best autonomous learning agents.},
	booktitle = {2008 7th {IEEE} {International} {Conference} on {Development} and {Learning}},
	author = {Knox, W. Bradley and Stone, Peter},
	month = aug,
	year = {2008},
	note = {ISSN: 2161-9476},
	pages = {292--297},
}

@misc{mialon_augmented_2023,
	title = {Augmented {Language} {Models}: a {Survey}},
	shorttitle = {Augmented {Language} {Models}},
	url = {http://arxiv.org/abs/2302.07842},
	doi = {10.48550/arXiv.2302.07842},
	abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
	urldate = {2023-04-18},
	publisher = {arXiv},
	author = {Mialon, Grégoire and Dessì, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozière, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and Grave, Edouard and LeCun, Yann and Scialom, Thomas},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07842 [cs]},
}

@misc{cohen_dynamic_2022,
	title = {Dynamic {Planning} in {Open}-{Ended} {Dialogue} using {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2208.02294},
	doi = {10.48550/arXiv.2208.02294},
	abstract = {Despite recent advances in natural language understanding and generation, and decades of research on the development of conversational bots, building automated agents that can carry on rich open-ended conversations with humans "in the wild" remains a formidable challenge. In this work we develop a real-time, open-ended dialogue system that uses reinforcement learning (RL) to power a bot's conversational skill at scale. Our work pairs the succinct embedding of the conversation state generated using SOTA (supervised) language models with RL techniques that are particularly suited to a dynamic action space that changes as the conversation progresses. Trained using crowd-sourced data, our novel system is able to substantially exceeds the (strong) baseline supervised model with respect to several metrics of interest in a live experiment with real users of the Google Assistant.},
	urldate = {2023-04-18},
	publisher = {arXiv},
	author = {Cohen, Deborah and Ryu, Moonkyung and Chow, Yinlam and Keller, Orgad and Greenberg, Ido and Hassidim, Avinatan and Fink, Michael and Matias, Yossi and Szpektor, Idan and Boutilier, Craig and Elidan, Gal},
	month = jul,
	year = {2022},
	note = {arXiv:2208.02294 [cs]},
}

@inproceedings{stiennon_learning_2020,
	title = {Learning to summarize with human feedback},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/1f89885d556929e98d3ef9b86448f951-Abstract.html},
	abstract = {As language models become more powerful, training and evaluation are increasingly bottlenecked by the data and metrics used for a particular task.  For example, summarization models are often trained to predict human reference summaries and evaluated using ROUGE, but both of these metrics are rough proxies for what we really care about---summary quality. In this work, we show that it is possible to significantly improve summary quality by training a model to optimize for human preferences.  We collect a large, high-quality dataset of human comparisons between summaries, train a model to predict the human-preferred summary, and use that model as a reward function to fine-tune a summarization policy using reinforcement learning. We apply our method to a version of the TL;DR dataset of Reddit posts and find that our models significantly outperform both human reference summaries and much larger models fine-tuned with supervised learning alone. Our models also transfer to CNN/DM news articles, producing summaries nearly as good as the human reference without any news-specific fine-tuning.  We conduct extensive analyses to understand our human feedback dataset and fine-tuned models.  We establish that our reward model generalizes to new datasets, and that optimizing our reward model results in better summaries than optimizing ROUGE according to humans.  We hope the evidence from our paper motivates machine learning researchers to pay closer attention to how their training loss affects the model behavior they actually want.},
	urldate = {2023-04-18},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
	year = {2020},
	pages = {3008--3021},
}

@article{gebru_datasheets_2021,
	title = {Datasheets for datasets},
	volume = {64},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/3458723},
	doi = {10.1145/3458723},
	abstract = {Documentation to facilitate communication between dataset creators and consumers.},
	number = {12},
	urldate = {2022-03-14},
	journal = {Communications of the ACM},
	author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and III, Hal Daumé and Crawford, Kate},
	month = nov,
	year = {2021},
	pages = {86--92},
}

@misc{ziegler_fine-tuning_2020,
	title = {Fine-{Tuning} {Language} {Models} from {Human} {Preferences}},
	url = {http://arxiv.org/abs/1909.08593},
	doi = {10.48550/arXiv.1909.08593},
	abstract = {Reward learning enables the application of reinforcement learning (RL) to tasks where reward is defined by human judgment, building a model of reward by asking humans questions. Most work on reward learning has used simulated environments, but complex information about values is often expressed in natural language, and we believe reward learning for language is a key to making RL practical and safe for real-world tasks. In this paper, we build on advances in generative pretraining of language models to apply reward learning to four natural language tasks: continuing text with positive sentiment or physically descriptive language, and summarization tasks on the TL;DR and CNN/Daily Mail datasets. For stylistic continuation we achieve good results with only 5,000 comparisons evaluated by humans. For summarization, models trained with 60,000 comparisons copy whole sentences from the input but skip irrelevant preamble; this leads to reasonable ROUGE scores and very good performance according to our human labelers, but may be exploiting the fact that labelers rely on simple heuristics.},
	urldate = {2023-04-18},
	publisher = {arXiv},
	author = {Ziegler, Daniel M. and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B. and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
	month = jan,
	year = {2020},
	note = {arXiv:1909.08593 [cs, stat]},
}

@article{warnell_deep_2018,
	title = {Deep {TAMER}: {Interactive} {Agent} {Shaping} in {High}-{Dimensional} {State} {Spaces}},
	volume = {32},
	copyright = {Copyright (c)},
	issn = {2374-3468},
	shorttitle = {Deep {TAMER}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11485},
	doi = {10.1609/aaai.v32i1.11485},
	abstract = {While recent advances in deep reinforcement learning have allowed autonomous learning agents to succeed at a variety of complex tasks, existing algorithms generally require a lot oftraining data. One way to increase the speed at which agent sare able to learn to perform tasks is by leveraging the input of human trainers. Although such input can take many forms, real-time, scalar-valued feedback is especially useful in situations where it proves difficult or impossible for humans to provide expert demonstrations. Previous approaches have shown the usefulness of human input provided in this fashion (e.g., the TAMER framework), but they have thus far not considered high-dimensional state spaces or employed the use of deep learning. In this paper, we do both: we propose DeepTAMER, an extension of the TAMER framework that leverages the representational power of deep neural networks inorder to learn complex tasks in just a short amount of time with a human trainer. We demonstrate Deep TAMER’s success by using it and just 15 minutes of human-provided feedback to train an agent that performs better than humans on the Atari game of Bowling - a task that has proven difficult for even state-of-the-art reinforcement learning methods.},
	language = {en},
	number = {1},
	urldate = {2023-04-18},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Warnell, Garrett and Waytowich, Nicholas and Lawhern, Vernon and Stone, Peter},
	month = apr,
	year = {2018},
	note = {Number: 1},
}

@inproceedings{macglashan_interactive_2017,
	title = {Interactive {Learning} from {Policy}-{Dependent} {Human} {Feedback}},
	url = {https://proceedings.mlr.press/v70/macglashan17a.html},
	abstract = {This paper investigates the problem of interactively learning behaviors communicated by a human teacher using positive and negative feedback. Much previous work on this problem has made the assumption that people provide feedback for decisions that is dependent on the behavior they are teaching and is independent from the learner’s current policy. We present empirical results that show this assumption to be false—whether human trainers give a positive or negative feedback for a decision is influenced by the learner’s current policy. Based on this insight, we introduce Convergent Actor-Critic by Humans (COACH), an algorithm for learning from policy-dependent feedback that converges to a local optimum. Finally, we demonstrate that COACH can successfully learn multiple behaviors on a physical robot.},
	language = {en},
	urldate = {2023-04-18},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {MacGlashan, James and Ho, Mark K. and Loftin, Robert and Peng, Bei and Wang, Guan and Roberts, David L. and Taylor, Matthew E. and Littman, Michael L.},
	month = jul,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {2285--2294},
}

@article{bernstein_protein_1977,
	title = {The protein data bank: {A} computer-based archival file for macromolecular structures},
	volume = {112},
	issn = {0022-2836},
	shorttitle = {The protein data bank},
	url = {https://www.sciencedirect.com/science/article/pii/S0022283677802003},
	doi = {10.1016/S0022-2836(77)80200-3},
	abstract = {The Protein Data Bank is a computer-based archival file for macromolecular structures. The Bank stores in a uniform format atomic co-ordinates and partial bond connectivities, as derived from crystallographic studies. Text included in each data entry gives pertinent information for the structure at hand (e.g. species from which the molecule has been obtained, resolution of diffraction data, literature citations and specifications of secondary structure). In addition to atomic co-ordinates and connectivities, the Protein Data Bank stores structure factors and phases, although these latter data are not placed in any uniform format. Input of data to the Bank and general maintenance functions are carried out at Brookhaven National Laboratory. All data stored in the Bank are available on magnetic tape for public distribution, from Brookhaven (to laboratories in the Americans), Tokyo (Japan), and Cambridge (Europe and worldwide). A master file is maintained at Brookhaven and duplicate copies are stored in Cambridge and Tokyo. In the future, it is hoped to expand the scope of the Protein Data Bank to make available co-ordinates for standard structural types (e.g. α-helix, RNA double-stranded helix) and representative computer programs of utility in the study and interpretation of macromolecular structures.},
	language = {en},
	number = {3},
	urldate = {2023-04-18},
	journal = {Journal of Molecular Biology},
	author = {Bernstein, Frances C. and Koetzle, Thomas F. and Williams, Graheme J. B. and Meyer, Edgar F. and Brice, Michael D. and Rodgers, John R. and Kennard, Olga and Shimanouchi, Takehiko and Tasumi, Mitsuo},
	month = may,
	year = {1977},
	pages = {535--542},
}

@misc{openai_gpt-4_2023,
	title = {{GPT}-4 {Technical} {Report}},
	url = {http://arxiv.org/abs/2303.08774},
	doi = {10.48550/arXiv.2303.08774},
	abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {OpenAI},
	month = mar,
	year = {2023},
	note = {arXiv:2303.08774 [cs]},
}

@misc{bubeck_sparks_2023,
	title = {Sparks of {Artificial} {General} {Intelligence}: {Early} experiments with {GPT}-4},
	shorttitle = {Sparks of {Artificial} {General} {Intelligence}},
	url = {http://arxiv.org/abs/2303.12712},
	doi = {10.48550/arXiv.2303.12712},
	abstract = {Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
	month = apr,
	year = {2023},
	note = {arXiv:2303.12712 [cs]},
}

@inproceedings{xu_systematic_2022,
	address = {New York, NY, USA},
	series = {{MAPS} 2022},
	title = {A systematic evaluation of large language models of code},
	isbn = {978-1-4503-9273-0},
	url = {https://dl.acm.org/doi/10.1145/3520312.3534862},
	doi = {10.1145/3520312.3534862},
	abstract = {Large language models (LMs) of code have recently shown tremendous promise in completing code and synthesizing code from natural language descriptions. However, the current state-of-the-art code LMs (e.g., Codex) are not publicly available, leaving many questions about their model and data design decisions. We aim to fill in some of these blanks through a systematic evaluation of the largest existing models: Codex, GPT-J, GPT-Neo, GPT-NeoX-20B, and CodeParrot, across various programming languages. Although Codex itself is not open-source, we find that existing opensource models do achieve close results in some programming languages, although targeted mainly for natural language modeling. We further identify an important missing piece in the form of a large open-source model trained exclusively on a multi-lingual corpus of code. We release a new model, PolyCoder, with 2.7B parameters based on the GPT-2 architecture, that was trained on 249GB of code across 12 programming languages on a single machine. In the C programming language, PolyCoder outperforms all models including Codex. Our trained models are open-source and publicly available at https://github.com/VHellendoorn/Code-LMs, which enables future research and application in this area. We have an online appendix at https://arxiv.org/abs/2202.13169.},
	urldate = {2023-04-17},
	booktitle = {Proceedings of the 6th {ACM} {SIGPLAN} {International} {Symposium} on {Machine} {Programming}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Frank F. and Alon, Uri and Neubig, Graham and Hellendoorn, Vincent Josua},
	month = jun,
	year = {2022},
	pages = {1--10},
}

@misc{sun_short_2023,
	title = {A {Short} {Survey} of {Viewing} {Large} {Language} {Models} in {Legal} {Aspect}},
	url = {http://arxiv.org/abs/2303.09136},
	abstract = {Large language models (LLMs) have transformed many fields, including natural language processing, computer vision, and reinforcement learning. These models have also made a significant impact in the field of law, where they are being increasingly utilized to automate various legal tasks, such as legal judgement prediction, legal document analysis, and legal document writing. However, the integration of LLMs into the legal field has also raised several legal problems, including privacy concerns, bias, and explainability. In this survey, we explore the integration of LLMs into the field of law. We discuss the various applications of LLMs in legal tasks, examine the legal challenges that arise from their use, and explore the data resources that can be used to specialize LLMs in the legal domain. Finally, we discuss several promising directions and conclude this paper. By doing so, we hope to provide an overview of the current state of LLMs in law and highlight the potential benefits and challenges of their integration.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Sun, Zhongxiang},
	month = mar,
	year = {2023},
	note = {arXiv:2303.09136 [cs]},
}

@misc{matton_emergent_2019,
	title = {Emergent {Properties} of {Finetuned} {Language} {Representation} {Models}},
	url = {http://arxiv.org/abs/1910.10832},
	doi = {10.48550/arXiv.1910.10832},
	abstract = {Large, self-supervised transformer-based language representation models have recently received significant amounts of attention, and have produced state-of-the-art results across a variety of tasks simply by scaling up pre-training on larger and larger corpora. Such models usually produce high dimensional vectors, on top of which additional task-specific layers and architectural modifications are added to adapt them to specific downstream tasks. Though there exists ample evidence that such models work well, we aim to understand what happens when they work well. We analyze the redundancy and location of information contained in output vectors for one such language representation model -- BERT. We show empirical evidence that the [CLS] embedding in BERT contains highly redundant information, and can be compressed with minimal loss of accuracy, especially for finetuned models, dovetailing into open threads in the field about the role of over-parameterization in learning. We also shed light on the existence of specific output dimensions which alone give very competitive results when compared to using all dimensions of output vectors.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Matton, Alexandre and de Oliveira, Luke},
	month = oct,
	year = {2019},
	note = {arXiv:1910.10832 [cs]},
}

@misc{pelley_is_2023,
	title = {Is artificial intelligence advancing too quickly? {What} {AI} leaders at {Google} say},
	shorttitle = {Is artificial intelligence advancing too quickly?},
	url = {https://www.cbsnews.com/news/google-artificial-intelligence-future-60-minutes-transcript-2023-04-16/},
	abstract = {Competitive pressure among tech giants is propelling society into the future of artificial intelligence, ready or not. Scott Pelley dives into the world of AI with Google CEO Sundar Pichai},
	language = {en-US},
	urldate = {2023-04-17},
	journal = {60 Minutes},
	publisher = {CBS},
	author = {Pelley, Scott and Pichai, Sundar},
	month = apr,
	year = {2023},
}

@misc{gebru_statement_2023,
	title = {Statement from the listed authors of {Stochastic} {Parrots} on the "{AI} pause" letter},
	url = {https://www.dair-institute.org/blog/letter-statement-March2023},
	language = {en},
	urldate = {2023-04-17},
	author = {Gebru, Timnit and Bender, Emily M. and McMillan-Major, Angelina and Mitchell, Margaret},
	year = {2023},
}

@misc{ahmed_-democratization_2020,
	title = {The {De}-democratization of {AI}: {Deep} {Learning} and the {Compute} {Divide} in {Artificial} {Intelligence} {Research}},
	shorttitle = {The {De}-democratization of {AI}},
	url = {http://arxiv.org/abs/2010.15581},
	doi = {10.48550/arXiv.2010.15581},
	abstract = {Increasingly, modern Artificial Intelligence (AI) research has become more computationally intensive. However, a growing concern is that due to unequal access to computing power, only certain firms and elite universities have advantages in modern AI research. Using a novel dataset of 171394 papers from 57 prestigious computer science conferences, we document that firms, in particular, large technology firms and elite universities have increased participation in major AI conferences since deep learning's unanticipated rise in 2012. The effect is concentrated among elite universities, which are ranked 1-50 in the QS World University Rankings. Further, we find two strategies through which firms increased their presence in AI research: first, they have increased firm-only publications; and second, firms are collaborating primarily with elite universities. Consequently, this increased presence of firms and elite universities in AI research has crowded out mid-tier (QS ranked 201-300) and lower-tier (QS ranked 301-500) universities. To provide causal evidence that deep learning's unanticipated rise resulted in this divergence, we leverage the generalized synthetic control method, a data-driven counterfactual estimator. Using machine learning based text analysis methods, we provide additional evidence that the divergence between these two groups - large firms and non-elite universities - is driven by access to computing power or compute, which we term as the "compute divide". This compute divide between large firms and non-elite universities increases concerns around bias and fairness within AI technology, and presents an obstacle towards "democratizing" AI. These results suggest that a lack of access to specialized equipment such as compute can de-democratize knowledge production.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Ahmed, Nur and Wahed, Muntasir},
	month = oct,
	year = {2020},
	note = {arXiv:2010.15581 [cs]},
}

@inproceedings{raji_fallacy_2022,
	address = {New York, NY, USA},
	series = {{FAccT} '22},
	title = {The {Fallacy} of {AI} {Functionality}},
	isbn = {978-1-4503-9352-2},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533158},
	doi = {10.1145/3531146.3533158},
	abstract = {Deployed AI systems often do not work. They can be constructed haphazardly, deployed indiscriminately, and promoted deceptively. However, despite this reality, scholars, the press, and policymakers pay too little attention to functionality. This leads to technical and policy solutions focused on “ethical” or value-aligned deployments, often skipping over the prior question of whether a given system functions, or provides any benefits at all. To describe the harms of various types of functionality failures, we analyze a set of case studies to create a taxonomy of known AI functionality issues. We then point to policy and organizational responses that are often overlooked and become more readily available once functionality is drawn into focus. We argue that functionality is a meaningful AI policy challenge, operating as a necessary first step towards protecting affected communities from algorithmic harm.},
	urldate = {2023-04-17},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Raji, Inioluwa Deborah and Kumar, I. Elizabeth and Horowitz, Aaron and Selbst, Andrew},
	month = jun,
	year = {2022},
	pages = {959--972},
}

@misc{borzunov_petals_2023,
	title = {Petals: {Collaborative} {Inference} and {Fine}-tuning of {Large} {Models}},
	shorttitle = {Petals},
	url = {http://arxiv.org/abs/2209.01188},
	doi = {10.48550/arXiv.2209.01188},
	abstract = {Many NLP tasks benefit from using large language models (LLMs) that often have more than 100 billion parameters. With the release of BLOOM-176B and OPT-175B, everyone can download pretrained models of this scale. Still, using these models requires high-end hardware unavailable to many researchers. In some cases, LLMs can be used more affordably via RAM offloading or hosted APIs. However, these techniques have innate limitations: offloading is too slow for interactive inference, while APIs are not flexible enough for research that requires access to weights, attention or logits. In this work, we propose Petals - a system for inference and fine-tuning of large models collaboratively by joining the resources of multiple parties. We demonstrate that this strategy outperforms offloading for very large models, running inference of BLOOM-176B on consumer GPUs with \${\textbackslash}approx\$ 1 step per second, which is enough for many interactive LLM applications. Unlike most inference APIs, Petals also natively exposes hidden states of served models, allowing to train and share custom model extensions based on efficient fine-tuning methods.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Borzunov, Alexander and Baranchuk, Dmitry and Dettmers, Tim and Ryabinin, Max and Belkada, Younes and Chumachenko, Artem and Samygin, Pavel and Raffel, Colin},
	month = mar,
	year = {2023},
	note = {arXiv:2209.01188 [cs]},
}

@article{gundersen_state_2018,
	title = {State of the {Art}: {Reproducibility} in {Artificial} {Intelligence}},
	volume = {32},
	copyright = {Copyright (c)},
	issn = {2374-3468},
	shorttitle = {State of the {Art}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11503},
	doi = {10.1609/aaai.v32i1.11503},
	abstract = {Background: Research results in artificial intelligence (AI) are criticized for not being reproducible. Objective: To quantify the state of reproducibility of empirical AI research using six reproducibility metrics measuring three different degrees of reproducibility. Hypotheses: 1) AI research is not documented well enough to reproduce the reported results. 2) Documentation practices have improved over time. Method: The literature is reviewed and a set of variables that should be documented to enable reproducibility are grouped into three factors: Experiment, Data and Method. The metrics describe how well the factors have been documented for a paper. A total of 400 research papers from the conference series IJCAI and AAAI have been surveyed using the metrics. Findings: None of the papers document all of the variables. The metrics show that between 20\% and 30\% of the variables for each factor are documented. One of the metrics show statistically significant increase over time while the others show no change. Interpretation: The reproducibility scores decrease with in- creased documentation requirements. Improvement over time is found. Conclusion: Both hypotheses are supported.},
	language = {en},
	number = {1},
	urldate = {2023-04-17},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Gundersen, Odd Erik and Kjensmo, Sigbjørn},
	month = apr,
	year = {2018},
	note = {Number: 1},
}

@misc{gao_pile_2020,
	title = {The {Pile}: {An} {800GB} {Dataset} of {Diverse} {Text} for {Language} {Modeling}},
	shorttitle = {The {Pile}},
	url = {http://arxiv.org/abs/2101.00027},
	doi = {10.48550/arXiv.2101.00027},
	abstract = {Recent work has demonstrated that increased training dataset diversity improves general cross-domain knowledge and downstream generalization capability for large-scale language models. With this in mind, we present {\textbackslash}textit\{the Pile\}: an 825 GiB English text corpus targeted at training large-scale language models. The Pile is constructed from 22 diverse high-quality subsets -- both existing and newly constructed -- many of which derive from academic or professional sources. Our evaluation of the untuned performance of GPT-2 and GPT-3 on the Pile shows that these models struggle on many of its components, such as academic writing. Conversely, models trained on the Pile improve significantly over both Raw CC and CC-100 on all components of the Pile, while improving performance on downstream evaluations. Through an in-depth exploratory analysis, we document potentially concerning aspects of the data for prospective users. We make publicly available the code used in its construction.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},
	month = dec,
	year = {2020},
	note = {arXiv:2101.00027 [cs]},
}

@misc{zhang_opt_2022,
	title = {{OPT}: {Open} {Pre}-trained {Transformer} {Language} {Models}},
	shorttitle = {{OPT}},
	url = {http://arxiv.org/abs/2205.01068},
	doi = {10.48550/arXiv.2205.01068},
	abstract = {Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Shuster, Kurt and Simig, Daniel and Koura, Punit Singh and Sridhar, Anjali and Wang, Tianlu and Zettlemoyer, Luke},
	month = jun,
	year = {2022},
	note = {arXiv:2205.01068 [cs]},
}

@article{mckiernan_how_2016,
	title = {How open science helps researchers succeed},
	volume = {5},
	copyright = {© 2016, McKiernan et al. This article is distributed under the terms of the Creative Commons Attribution License permitting unrestricted use and redistribution provided that the original author and source are credited.},
	issn = {2050-084X},
	url = {https://elifesciences.org/content/5/e16800v1},
	doi = {10.7554/eLife.16800},
	abstract = {{\textless}meta name="DC.Rights" content="© 2016, McKiernan et al. This article is distributed under the terms of the Creative Commons Attribution License permitting unrestricted use and redistribution provided that the original author and source are credited."/{\textgreater}
{\textless}meta name="DC.Contributor" content="Erin C McKiernan"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Philip E Bourne"/{\textgreater}
{\textless}meta name="DC.Contributor" content="C Titus Brown"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Stuart Buck"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Amye Kenall"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Jennifer Lin"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Damon McDougall"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Brian A Nosek"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Karthik Ram"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Courtney K Soderberg"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Jeffrey R Spies"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Kaitlin Thaney"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Andrew Updegrove"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Kara H Woo"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Tal Yarkoni"/{\textgreater}
{\textless}meta name="DC.Contributor" content="Peter Rodgers"/{\textgreater}
{\textless}meta name="citation\_author" content="Erin C McKiernan"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Department of Physics"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="National Autonomous University of Mexico"/{\textgreater}
{\textless}meta name="citation\_author\_email" content="emckiernan@ciencias.unam.mx"/{\textgreater}
{\textless}meta name="citation\_author\_orcid" content="http://orcid.org/0000-0002-9430-5221"/{\textgreater}
{\textless}meta name="citation\_author" content="Philip E Bourne"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Office of the Director"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="National Institutes of Health"/{\textgreater}
{\textless}meta name="citation\_author\_orcid" content="http://orcid.org/0000-0002-7618-7292"/{\textgreater}
{\textless}meta name="citation\_author" content="C Titus Brown"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Population Health and Reproduction"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="University of California, Davis"/{\textgreater}
{\textless}meta name="citation\_author" content="Stuart Buck"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Laura and John Arnold Foundation"/{\textgreater}
{\textless}meta name="citation\_author" content="Amye Kenall"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="BioMed Central"/{\textgreater}
{\textless}meta name="citation\_author\_orcid" content="http://orcid.org/0000-0002-3030-8001"/{\textgreater}
{\textless}meta name="citation\_author" content="Jennifer Lin"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="CrossRef"/{\textgreater}
{\textless}meta name="citation\_author" content="Damon McDougall"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Institute for Computational Engineering and Sciences"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="University of Texas at Austin"/{\textgreater}
{\textless}meta name="citation\_author" content="Brian A Nosek"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Center for Open Science"/{\textgreater}
{\textless}meta name="citation\_author" content="Karthik Ram"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Berkeley Institute for Data Science"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="University of California, Berkeley"/{\textgreater}
{\textless}meta name="citation\_author" content="Courtney K Soderberg"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Center for Open Science"/{\textgreater}
{\textless}meta name="citation\_author" content="Jeffrey R Spies"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Center for Open Science"/{\textgreater}
{\textless}meta name="citation\_author" content="Kaitlin Thaney"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Mozilla Science Lab"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Mozilla Foundation"/{\textgreater}
{\textless}meta name="citation\_author" content="Andrew Updegrove"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Gesmer Updegrove LLP"/{\textgreater}
{\textless}meta name="citation\_author" content="Kara H Woo"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Center for Environmental Research, Education, and Outreach"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Washington State University"/{\textgreater}
{\textless}meta name="citation\_author\_orcid" content="http://orcid.org/0000-0002-5125-4188"/{\textgreater}
{\textless}meta name="citation\_author" content="Tal Yarkoni"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="Department of Psychology"/{\textgreater}
{\textless}meta name="citation\_author\_institution" content="University of Texas at Austin"/{\textgreater}},
	language = {en},
	urldate = {2016-07-08},
	journal = {eLife},
	author = {McKiernan, Erin C. and Bourne, Philip E. and Brown, C. Titus and Buck, Stuart and Kenall, Amye and Lin, Jennifer and McDougall, Damon and Nosek, Brian A. and Ram, Karthik and Soderberg, Courtney K. and Spies, Jeffrey R. and Thaney, Kaitlin and Updegrove, Andrew and Woo, Kara H. and Yarkoni, Tal},
	month = jul,
	year = {2016},
	pages = {e16800},
}

@article{kathawalla_easing_2021,
	title = {Easing {Into} {Open} {Science}: {A} {Guide} for {Graduate} {Students} and {Their} {Advisors}},
	volume = {7},
	issn = {2474-7394},
	shorttitle = {Easing {Into} {Open} {Science}},
	url = {https://doi.org/10.1525/collabra.18684},
	doi = {10.1525/collabra.18684},
	abstract = {This article provides a roadmap to assist graduate students and their advisors to engage in open science practices. We suggest eight open science practices that novice graduate students could begin adopting today. The topics we cover include journal clubs, project workflow, preprints, reproducible code, data sharing, transparent writing, preregistration, and registered reports. To address concerns about not knowing how to engage in open science practices, we provide a difficulty rating of each behavior (easy, medium, difficult), present them in order of suggested adoption, and follow the format of what, why, how, and worries. We give graduate students ideas on how to approach conversations with their advisors/collaborators, ideas on how to integrate open science practices within the graduate school framework, and specific resources on how to engage with each behavior. We emphasize that engaging in open science behaviors need not be an all or nothing approach, but rather graduate students can engage with any number of the behaviors outlined.},
	number = {1},
	urldate = {2021-09-16},
	journal = {Collabra: Psychology},
	author = {Kathawalla, Ummul-Kiram and Silverstein, Priya and Syed, Moin},
	month = jan,
	year = {2021},
}

@article{li_trustworthy_2023,
	title = {Trustworthy {AI}: {From} {Principles} to {Practices}},
	volume = {55},
	issn = {0360-0300},
	shorttitle = {Trustworthy {AI}},
	url = {https://dl.acm.org/doi/10.1145/3555803},
	doi = {10.1145/3555803},
	abstract = {The rapid development of Artificial Intelligence (AI) technology has enabled the deployment of various systems based on it. However, many current AI systems are found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection. These shortcomings degrade user experience and erode people’s trust in all AI systems. In this review, we provide AI practitioners with a comprehensive guide for building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, and accountability. To unify currently available but fragmented approaches toward trustworthy AI, we organize them in a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to system development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items for practitioners and societal stakeholders (e.g., researchers, engineers, and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges for the future development of trustworthy AI systems, where we identify the need for a paradigm shift toward comprehensively trustworthy AI systems.},
	number = {9},
	urldate = {2023-04-17},
	journal = {ACM Computing Surveys},
	author = {Li, Bo and Qi, Peng and Liu, Bo and Di, Shuai and Liu, Jingen and Pei, Jiquan and Yi, Jinfeng and Zhou, Bowen},
	month = jan,
	year = {2023},
	pages = {177:1--177:46},
}

@article{haibe-kains_transparency_2020,
	title = {Transparency and reproducibility in artificial intelligence},
	volume = {586},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-020-2766-y},
	doi = {10.1038/s41586-020-2766-y},
	language = {en},
	number = {7829},
	urldate = {2023-04-17},
	journal = {Nature},
	author = {Haibe-Kains, Benjamin and Adam, George Alexandru and Hosny, Ahmed and Khodakarami, Farnoosh and Waldron, Levi and Wang, Bo and McIntosh, Chris and Goldenberg, Anna and Kundaje, Anshul and Greene, Casey S. and Broderick, Tamara and Hoffman, Michael M. and Leek, Jeffrey T. and Korthauer, Keegan and Huber, Wolfgang and Brazma, Alvis and Pineau, Joelle and Tibshirani, Robert and Hastie, Trevor and Ioannidis, John P. A. and Quackenbush, John and Aerts, Hugo J. W. L.},
	month = oct,
	year = {2020},
	note = {Number: 7829
Publisher: Nature Publishing Group},
	pages = {E14--E16},
}

@article{verbraeken_survey_2020,
	title = {A {Survey} on {Distributed} {Machine} {Learning}},
	volume = {53},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3377454},
	doi = {10.1145/3377454},
	abstract = {The demand for artificial intelligence has grown significantly over the past decade, and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges: first and foremost, the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available.},
	number = {2},
	urldate = {2023-04-17},
	journal = {ACM Computing Surveys},
	author = {Verbraeken, Joost and Wolting, Matthijs and Katzy, Jonathan and Kloppenburg, Jeroen and Verbelen, Tim and Rellermeyer, Jan S.},
	year = {2020},
	pages = {30:1--30:33},
}

@article{landset_survey_2015,
	title = {A survey of open source tools for machine learning with big data in the {Hadoop} ecosystem},
	volume = {2},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-015-0032-1},
	doi = {10.1186/s40537-015-0032-1},
	abstract = {With an ever-increasing amount of options, the task of selecting machine learning tools for big data can be difficult. The available tools have advantages and drawbacks, and many have overlapping uses. The world’s data is growing rapidly, and traditional tools for machine learning are becoming insufficient as we move towards distributed and real-time processing. This paper is intended to aid the researcher or professional who understands machine learning but is inexperienced with big data. In order to evaluate tools, one should have a thorough understanding of what to look for. To that end, this paper provides a list of criteria for making selections along with an analysis of the advantages and drawbacks of each. We do this by starting from the beginning, and looking at what exactly the term “big data” means. From there, we go on to the Hadoop ecosystem for a look at many of the projects that are part of a typical machine learning architecture and an understanding of how everything might fit together. We discuss the advantages and disadvantages of three different processing paradigms along with a comparison of engines that implement them, including MapReduce, Spark, Flink, Storm, and H2O. We then look at machine learning libraries and frameworks including Mahout, MLlib, SAMOA, and evaluate them based on criteria such as scalability, ease of use, and extensibility. There is no single toolkit that truly embodies a one-size-fits-all solution, so this paper aims to help make decisions smoother by providing as much information as possible and quantifying what the tradeoffs will be. Additionally, throughout this paper, we review recent research in the field using these tools and talk about possible future directions for toolkit-based learning.},
	number = {1},
	urldate = {2023-04-17},
	journal = {Journal of Big Data},
	author = {Landset, Sara and Khoshgoftaar, Taghi M. and Richter, Aaron N. and Hasanin, Tawfiq},
	month = nov,
	year = {2015},
	pages = {24},
}

@misc{workshop_bloom_2023,
	title = {{BLOOM}: {A} {176B}-{Parameter} {Open}-{Access} {Multilingual} {Language} {Model}},
	shorttitle = {{BLOOM}},
	url = {http://arxiv.org/abs/2211.05100},
	doi = {10.48550/arXiv.2211.05100},
	abstract = {Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Workshop, BigScience and Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ilić, Suzana and Hesslow, Daniel and Castagné, Roman and Luccioni, Alexandra Sasha and Yvon, François and Gallé, Matthias and Tow, Jonathan and Rush, Alexander M. and Biderman, Stella and Webson, Albert and Ammanamanchi, Pawan Sasanka and Wang, Thomas and Sagot, Benoît and Muennighoff, Niklas and del Moral, Albert Villanova and Ruwase, Olatunji and Bawden, Rachel and Bekman, Stas and McMillan-Major, Angelina and Beltagy, Iz and Nguyen, Huu and Saulnier, Lucile and Tan, Samson and Suarez, Pedro Ortiz and Sanh, Victor and Laurençon, Hugo and Jernite, Yacine and Launay, Julien and Mitchell, Margaret and Raffel, Colin and Gokaslan, Aaron and Simhi, Adi and Soroa, Aitor and Aji, Alham Fikri and Alfassy, Amit and Rogers, Anna and Nitzav, Ariel Kreisberg and Xu, Canwen and Mou, Chenghao and Emezue, Chris and Klamm, Christopher and Leong, Colin and van Strien, Daniel and Adelani, David Ifeoluwa and Radev, Dragomir and Ponferrada, Eduardo González and Levkovizh, Efrat and Kim, Ethan and Natan, Eyal Bar and De Toni, Francesco and Dupont, Gérard and Kruszewski, Germán and Pistilli, Giada and Elsahar, Hady and Benyamina, Hamza and Tran, Hieu and Yu, Ian and Abdulmumin, Idris and Johnson, Isaac and Gonzalez-Dios, Itziar and de la Rosa, Javier and Chim, Jenny and Dodge, Jesse and Zhu, Jian and Chang, Jonathan and Frohberg, Jörg and Tobing, Joseph and Bhattacharjee, Joydeep and Almubarak, Khalid and Chen, Kimbo and Lo, Kyle and Von Werra, Leandro and Weber, Leon and Phan, Long and allal, Loubna Ben and Tanguy, Ludovic and Dey, Manan and Muñoz, Manuel Romero and Masoud, Maraim and Grandury, María and Šaško, Mario and Huang, Max and Coavoux, Maximin and Singh, Mayank and Jiang, Mike Tian-Jian and Vu, Minh Chien and Jauhar, Mohammad A. and Ghaleb, Mustafa and Subramani, Nishant and Kassner, Nora and Khamis, Nurulaqilla and Nguyen, Olivier and Espejel, Omar and de Gibert, Ona and Villegas, Paulo and Henderson, Peter and Colombo, Pierre and Amuok, Priscilla and Lhoest, Quentin and Harliman, Rheza and Bommasani, Rishi and López, Roberto Luis and Ribeiro, Rui and Osei, Salomey and Pyysalo, Sampo and Nagel, Sebastian and Bose, Shamik and Muhammad, Shamsuddeen Hassan and Sharma, Shanya and Longpre, Shayne and Nikpoor, Somaieh and Silberberg, Stanislav and Pai, Suhas and Zink, Sydney and Torrent, Tiago Timponi and Schick, Timo and Thrush, Tristan and Danchev, Valentin and Nikoulina, Vassilina and Laippala, Veronika and Lepercq, Violette and Prabhu, Vrinda and Alyafeai, Zaid and Talat, Zeerak and Raja, Arun and Heinzerling, Benjamin and Si, Chenglei and Taşar, Davut Emre and Salesky, Elizabeth and Mielke, Sabrina J. and Lee, Wilson Y. and Sharma, Abheesht and Santilli, Andrea and Chaffin, Antoine and Stiegler, Arnaud and Datta, Debajyoti and Szczechla, Eliza and Chhablani, Gunjan and Wang, Han and Pandey, Harshit and Strobelt, Hendrik and Fries, Jason Alan and Rozen, Jos and Gao, Leo and Sutawika, Lintang and Bari, M. Saiful and Al-shaibani, Maged S. and Manica, Matteo and Nayak, Nihal and Teehan, Ryan and Albanie, Samuel and Shen, Sheng and Ben-David, Srulik and Bach, Stephen H. and Kim, Taewoon and Bers, Tali and Fevry, Thibault and Neeraj, Trishala and Thakker, Urmish and Raunak, Vikas and Tang, Xiangru and Yong, Zheng-Xin and Sun, Zhiqing and Brody, Shaked and Uri, Yallow and Tojarieh, Hadar and Roberts, Adam and Chung, Hyung Won and Tae, Jaesung and Phang, Jason and Press, Ofir and Li, Conglong and Narayanan, Deepak and Bourfoune, Hatim and Casper, Jared and Rasley, Jeff and Ryabinin, Max and Mishra, Mayank and Zhang, Minjia and Shoeybi, Mohammad and Peyrounette, Myriam and Patry, Nicolas and Tazi, Nouamane and Sanseviero, Omar and von Platen, Patrick and Cornette, Pierre and Lavallée, Pierre François and Lacroix, Rémi and Rajbhandari, Samyam and Gandhi, Sanchit and Smith, Shaden and Requena, Stéphane and Patil, Suraj and Dettmers, Tim and Baruwa, Ahmed and Singh, Amanpreet and Cheveleva, Anastasia and Ligozat, Anne-Laure and Subramonian, Arjun and Névéol, Aurélie and Lovering, Charles and Garrette, Dan and Tunuguntla, Deepak and Reiter, Ehud and Taktasheva, Ekaterina and Voloshina, Ekaterina and Bogdanov, Eli and Winata, Genta Indra and Schoelkopf, Hailey and Kalo, Jan-Christoph and Novikova, Jekaterina and Forde, Jessica Zosa and Clive, Jordan and Kasai, Jungo and Kawamura, Ken and Hazan, Liam and Carpuat, Marine and Clinciu, Miruna and Kim, Najoung and Cheng, Newton and Serikov, Oleg and Antverg, Omer and van der Wal, Oskar and Zhang, Rui and Zhang, Ruochen and Gehrmann, Sebastian and Mirkin, Shachar and Pais, Shani and Shavrina, Tatiana and Scialom, Thomas and Yun, Tian and Limisiewicz, Tomasz and Rieser, Verena and Protasov, Vitaly and Mikhailov, Vladislav and Pruksachatkun, Yada and Belinkov, Yonatan and Bamberger, Zachary and Kasner, Zdeněk and Rueda, Alice and Pestana, Amanda and Feizpour, Amir and Khan, Ammar and Faranak, Amy and Santos, Ana and Hevia, Anthony and Unldreaj, Antigona and Aghagol, Arash and Abdollahi, Arezoo and Tammour, Aycha and HajiHosseini, Azadeh and Behroozi, Bahareh and Ajibade, Benjamin and Saxena, Bharat and Ferrandis, Carlos Muñoz and Contractor, Danish and Lansky, David and David, Davis and Kiela, Douwe and Nguyen, Duong A. and Tan, Edward and Baylor, Emi and Ozoani, Ezinwanne and Mirza, Fatima and Ononiwu, Frankline and Rezanejad, Habib and Jones, Hessie and Bhattacharya, Indrani and Solaiman, Irene and Sedenko, Irina and Nejadgholi, Isar and Passmore, Jesse and Seltzer, Josh and Sanz, Julio Bonis and Dutra, Livia and Samagaio, Mairon and Elbadri, Maraim and Mieskes, Margot and Gerchick, Marissa and Akinlolu, Martha and McKenna, Michael and Qiu, Mike and Ghauri, Muhammed and Burynok, Mykola and Abrar, Nafis and Rajani, Nazneen and Elkott, Nour and Fahmy, Nour and Samuel, Olanrewaju and An, Ran and Kromann, Rasmus and Hao, Ryan and Alizadeh, Samira and Shubber, Sarmad and Wang, Silas and Roy, Sourav and Viguier, Sylvain and Le, Thanh and Oyebade, Tobi and Le, Trieu and Yang, Yoyo and Nguyen, Zach and Kashyap, Abhinav Ramesh and Palasciano, Alfredo and Callahan, Alison and Shukla, Anima and Miranda-Escalada, Antonio and Singh, Ayush and Beilharz, Benjamin and Wang, Bo and Brito, Caio and Zhou, Chenxi and Jain, Chirag and Xu, Chuxin and Fourrier, Clémentine and Periñán, Daniel León and Molano, Daniel and Yu, Dian and Manjavacas, Enrique and Barth, Fabio and Fuhrimann, Florian and Altay, Gabriel and Bayrak, Giyaseddin and Burns, Gully and Vrabec, Helena U. and Bello, Imane and Dash, Ishani and Kang, Jihyun and Giorgi, John and Golde, Jonas and Posada, Jose David and Sivaraman, Karthik Rangasai and Bulchandani, Lokesh and Liu, Lu and Shinzato, Luisa and de Bykhovetz, Madeleine Hahn and Takeuchi, Maiko and Pàmies, Marc and Castillo, Maria A. and Nezhurina, Marianna and Sänger, Mario and Samwald, Matthias and Cullan, Michael and Weinberg, Michael and De Wolf, Michiel and Mihaljcic, Mina and Liu, Minna and Freidank, Moritz and Kang, Myungsun and Seelam, Natasha and Dahlberg, Nathan and Broad, Nicholas Michio and Muellner, Nikolaus and Fung, Pascale and Haller, Patrick and Chandrasekhar, Ramya and Eisenberg, Renata and Martin, Robert and Canalli, Rodrigo and Su, Rosaline and Su, Ruisi and Cahyawijaya, Samuel and Garda, Samuele and Deshmukh, Shlok S. and Mishra, Shubhanshu and Kiblawi, Sid and Ott, Simon and Sang-aroonsiri, Sinee and Kumar, Srishti and Schweter, Stefan and Bharati, Sushil and Laud, Tanmay and Gigant, Théo and Kainuma, Tomoya and Kusa, Wojciech and Labrak, Yanis and Bajaj, Yash Shailesh and Venkatraman, Yash and Xu, Yifan and Xu, Yingxin and Xu, Yu and Tan, Zhe and Xie, Zhongli and Ye, Zifan and Bras, Mathilde and Belkada, Younes and Wolf, Thomas},
	month = mar,
	year = {2023},
	note = {arXiv:2211.05100 [cs]},
}

@article{krizhevsky_imagenet_2017,
	title = {{ImageNet} classification with deep convolutional neural networks},
	volume = {60},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/3065386},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
	number = {6},
	urldate = {2023-04-17},
	journal = {Communications of the ACM},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	year = {2017},
	pages = {84--90},
}

@inproceedings{deng_imagenet_2009,
	title = {{ImageNet}: {A} large-scale hierarchical image database},
	shorttitle = {{ImageNet}},
	doi = {10.1109/CVPR.2009.5206848},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	booktitle = {2009 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	month = jun,
	year = {2009},
	note = {ISSN: 1063-6919},
	pages = {248--255},
}

@article{krishna_open_2020,
	title = {Open {Science} and {Its} {Enemies}: {Challenges} for a {Sustainable} {Science}–{Society} {Social} {Contract}},
	volume = {6},
	issn = {2199-8531},
	shorttitle = {Open {Science} and {Its} {Enemies}},
	url = {https://www.sciencedirect.com/science/article/pii/S2199853122005546},
	doi = {10.3390/joitmc6030061},
	abstract = {Science as a social institution has evolved as the most powerful, highly influential, and sought out institution after the conflicts between science and religion following Galileo. Knowledge as a public good, scientific peer review of science, the prominence of open publications, and the emphasis on professional recognition and scientific autonomy have been the hallmark of science in the past three centuries. According to this scientific spirit, the scientific social system and society formed a unique social contract. This social contract drew considerable institutional and state legitimacy for the openness and public good of science in the service of state and society, all through the post-war period. Openness and public good of science are recognized and legitimized by the scientific community and science agencies at the global level. This paradigm of open science, in varying forms and manifestations, contributed to the progress of systematic knowledge at the service of humankind over the last three centuries. Entering the third decade of the 21st century, the social contract between science and society is undergoing major changes. In fact, the whole paradigm of open science and its social contract is being challenged by various “enemies” or adversaries such as (a) market-based privatized commercial science, (b) industry 4.0 advanced technologies, and (c) a “new iron curtain” on the free flow of science data and information. What is at stake? Are there major changes? Is the very social institution of science transforming? What impact will this have on our contemporary and future sustainable society? These are some important issues that will be addressed in this article.},
	language = {en},
	number = {3},
	urldate = {2023-04-17},
	journal = {Journal of Open Innovation: Technology, Market, and Complexity},
	author = {Krishna, Venni V.},
	month = sep,
	year = {2020},
	pages = {61},
}

@article{chawla_ten_2023,
	title = {Ten years after {ImageNet}: a 360° perspective on artificial intelligence},
	volume = {10},
	shorttitle = {Ten years after {ImageNet}},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsos.221414},
	doi = {10.1098/rsos.221414},
	abstract = {It is 10 years since neural networks made their spectacular comeback. Prompted by this anniversary, we take a holistic perspective on artificial intelligence (AI). Supervised learning for cognitive tasks is effectively solved—provided we have enough high-quality labelled data. However, deep neural network models are not easily interpretable, and thus the debate between blackbox and whitebox modelling has come to the fore. The rise of attention networks, self-supervised learning, generative modelling and graph neural networks has widened the application space of AI. Deep learning has also propelled the return of reinforcement learning as a core building block of autonomous decision-making systems. The possible harms made possible by new AI technologies have raised socio-technical issues such as transparency, fairness and accountability. The dominance of AI by Big Tech who control talent, computing resources, and most importantly, data may lead to an extreme AI divide. Despite the recent dramatic and unexpected success in AI-driven conversational agents, progress in much-heralded flagship projects like self-driving vehicles remains elusive. Care must be taken to moderate the rhetoric surrounding the field and align engineering progress with scientific principles.},
	number = {3},
	urldate = {2023-04-17},
	journal = {Royal Society Open Science},
	author = {Chawla, Sanjay and Nakov, Preslav and Ali, Ahmed and Hall, Wendy and Khalil, Issa and Ma, Xiaosong and Taha Sencar, Husrev and Weber, Ingmar and Wooldridge, Michael and Yu, Ting},
	month = mar,
	year = {2023},
	note = {Publisher: Royal Society},
	pages = {221414},
}

@misc{phang_eleutherai_2022,
	title = {{EleutherAI}: {Going} {Beyond} "{Open} {Science}" to "{Science} in the {Open}"},
	shorttitle = {{EleutherAI}},
	url = {http://arxiv.org/abs/2210.06413},
	doi = {10.48550/arXiv.2210.06413},
	abstract = {Over the past two years, EleutherAI has established itself as a radically novel initiative aimed at both promoting open-source research and conducting research in a transparent, openly accessible and collaborative manner. EleutherAI's approach to research goes beyond transparency: by doing research entirely in public, anyone in the world can observe and contribute at every stage. Our work has been received positively and has resulted in several high-impact projects in Natural Language Processing and other fields. In this paper, we describe our experience doing public-facing machine learning research, the benefits we believe this approach brings, and the pitfalls we have encountered.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Phang, Jason and Bradley, Herbie and Gao, Leo and Castricato, Louis and Biderman, Stella},
	month = oct,
	year = {2022},
	note = {arXiv:2210.06413 [cs]},
}

@article{burgelman_open_2019,
	title = {Open {Science}, {Open} {Data}, and {Open} {Scholarship}: {European} {Policies} to {Make} {Science} {Fit} for the {Twenty}-{First} {Century}},
	volume = {2},
	issn = {2624-909X},
	shorttitle = {Open {Science}, {Open} {Data}, and {Open} {Scholarship}},
	url = {https://www.frontiersin.org/articles/10.3389/fdata.2019.00043},
	abstract = {Open science will make science more efficient, reliable, and responsive to societal challenges. The European Commission has sought to advance open science policy from its inception in a holistic and integrated way, covering all aspects of the research cycle from scientific discovery and review to sharing knowledge, publishing, and outreach. We present the steps taken with a forward-looking perspective on the challenges laying ahead, in particular the necessary change of the rewards and incentives system for researchers (for which various actors are co-responsible and which goes beyond the mandate of the European Commission). Finally, we discuss the role of artificial intelligence (AI) within an open science perspective.},
	urldate = {2023-04-17},
	journal = {Frontiers in Big Data},
	author = {Burgelman, Jean-Claude and Pascu, Corina and Szkuta, Katarzyna and Von Schomberg, Rene and Karalopoulos, Athanasios and Repanas, Konstantinos and Schouppe, Michel},
	year = {2019},
}

@article{tunyasuvunakool_highly_2021,
	title = {Highly accurate protein structure prediction for the human proteome},
	volume = {596},
	copyright = {2021 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03828-1},
	doi = {10.1038/s41586-021-03828-1},
	abstract = {Protein structures can provide invaluable information, both for reasoning about biological processes and for enabling interventions such as structure-based drug development or targeted mutagenesis. After decades of effort, 17\% of the total residues in human protein sequences are covered by an experimentally determined structure1. Here we markedly expand the structural coverage of the proteome by applying the state-of-the-art machine learning method, AlphaFold2, at a scale that covers almost the entire human proteome (98.5\% of human proteins). The resulting dataset covers 58\% of residues with a confident prediction, of which a subset (36\% of all residues) have very high confidence. We introduce several metrics developed by building on the AlphaFold model and use them to interpret the dataset, identifying strong multi-domain predictions as well as regions that are likely to be disordered. Finally, we provide some case studies to illustrate how high-quality predictions could be used to generate biological hypotheses. We are making our predictions freely available to the community and anticipate that routine large-scale and high-accuracy structure prediction will become an important tool that will allow new questions to be addressed from a structural perspective.},
	language = {en},
	number = {7873},
	urldate = {2023-04-17},
	journal = {Nature},
	author = {Tunyasuvunakool, Kathryn and Adler, Jonas and Wu, Zachary and Green, Tim and Zielinski, Michal and Žídek, Augustin and Bridgland, Alex and Cowie, Andrew and Meyer, Clemens and Laydon, Agata and Velankar, Sameer and Kleywegt, Gerard J. and Bateman, Alex and Evans, Richard and Pritzel, Alexander and Figurnov, Michael and Ronneberger, Olaf and Bates, Russ and Kohl, Simon A. A. and Potapenko, Anna and Ballard, Andrew J. and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Clancy, Ellen and Reiman, David and Petersen, Stig and Senior, Andrew W. and Kavukcuoglu, Koray and Birney, Ewan and Kohli, Pushmeet and Jumper, John and Hassabis, Demis},
	month = aug,
	year = {2021},
	note = {Number: 7873
Publisher: Nature Publishing Group},
	pages = {590--596},
}

@article{gundersen_reproducible_2018,
	title = {On {Reproducible} {AI}: {Towards} {Reproducible} {Research}, {Open} {Science}, and {Digital} {Scholarship} in {AI} {Publications}},
	volume = {39},
	copyright = {Copyright (c)  AI Magazine},
	issn = {2371-9621},
	shorttitle = {On {Reproducible} {AI}},
	url = {https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2816},
	doi = {10.1609/aimag.v39i3.2816},
	abstract = {Background: Science is experiencing a reproducibility crisis. Artificial intelligence research is not an exception. Objective: To give practical and pragmatic recommendations for how to document AI research so that the results are reproducible. Method: Our analysis of the literature shows that AI publications fall short of providing enough documentation to facilitate reproducibility. Our suggested best practices are based on a framework for reproducibility and recommendations given for other disciplines. Results: We have made an author checklist based on our investigation and provided examples for how every item in the checklist can be documented. Conclusion: We encourage reviewers to use the suggested best practices and author checklist when reviewing submissions for AAAI publications and future AAAI conferences.},
	language = {en},
	number = {3},
	urldate = {2023-04-17},
	journal = {AI Magazine},
	author = {Gundersen, Odd Erik and Gil, Yolanda and Aha, David W.},
	month = sep,
	year = {2018},
	note = {Number: 3},
	pages = {56--68},
}

@misc{schuhmann_laion-400m_2021,
	title = {{LAION}-{400M}: {Open} {Dataset} of {CLIP}-{Filtered} 400 {Million} {Image}-{Text} {Pairs}},
	shorttitle = {{LAION}-{400M}},
	url = {http://arxiv.org/abs/2111.02114},
	doi = {10.48550/arXiv.2111.02114},
	abstract = {Multi-modal language-vision models trained on hundreds of millions of image-text pairs (e.g. CLIP, DALL-E) gained a recent surge, showing remarkable capability to perform zero- or few-shot learning and transfer even in absence of per-sample labels on target image data. Despite this trend, to date there has been no publicly available datasets of sufficient scale for training such models from scratch. To address this issue, in a community effort we build and release for public LAION-400M, a dataset with CLIP-filtered 400 million image-text pairs, their CLIP embeddings and kNN indices that allow efficient similarity search.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
	month = nov,
	year = {2021},
	note = {arXiv:2111.02114 [cs]},
}

@misc{schuhmann_laion-5b_2022,
	title = {{LAION}-{5B}: {An} open large-scale dataset for training next generation image-text models},
	shorttitle = {{LAION}-{5B}},
	url = {http://arxiv.org/abs/2210.08402},
	doi = {10.48550/arXiv.2210.08402},
	abstract = {Groundbreaking language-vision architectures like CLIP and DALL-E proved the utility of training on large amounts of noisy image-text data, without relying on expensive accurate labels used in standard vision unimodal supervised learning. The resulting models showed capabilities of strong text-guided image generation and transfer to downstream tasks, while performing remarkably at zero-shot classification with noteworthy out-of-distribution robustness. Since then, large-scale language-vision models like ALIGN, BASIC, GLIDE, Flamingo and Imagen made further improvements. Studying the training and capabilities of such models requires datasets containing billions of image-text pairs. Until now, no datasets of this size have been made openly available for the broader research community. To address this problem and democratize research on large-scale multi-modal models, we present LAION-5B - a dataset consisting of 5.85 billion CLIP-filtered image-text pairs, of which 2.32B contain English language. We show successful replication and fine-tuning of foundational models like CLIP, GLIDE and Stable Diffusion using the dataset, and discuss further experiments enabled with an openly available dataset of this scale. Additionally we provide several nearest neighbor indices, an improved web-interface for dataset exploration and subset generation, and detection scores for watermark, NSFW, and toxic content detection. Announcement page https://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and Schramowski, Patrick and Kundurthy, Srivatsa and Crowson, Katherine and Schmidt, Ludwig and Kaczmarczyk, Robert and Jitsev, Jenia},
	month = oct,
	year = {2022},
	note = {arXiv:2210.08402 [cs]},
}

@article{raymond_cathedral_1999,
	title = {The cathedral and the bazaar},
	volume = {12},
	issn = {1874-6314},
	url = {https://doi.org/10.1007/s12130-999-1026-0},
	doi = {10.1007/s12130-999-1026-0},
	abstract = {I anatomize a successful open-source project, fetchmail, that was run as a deliberate test of some theories about software engineering suggested by the history of Linux. I discuss these theories in terms of two fundamentally different development styles, the "cathedral" model, representing most of the commercial world, versus the "bazaar" model of the Linux world. I show that these models derive from opposing assumptions about the nature of the software-debugging task. I then make a sustained argument from the Linux experience for the proposition that "Given enough eyeballs, all bugs are shallow," suggest productive analogies with other self-correcting systems of selfish agents, and conclude with some exploration of the implications of this insight for the future of software.},
	language = {en},
	number = {3},
	urldate = {2023-04-17},
	journal = {Knowledge, Technology \& Policy},
	author = {Raymond, Eric},
	month = sep,
	year = {1999},
	pages = {23--49},
}

@misc{hu_lora_2021,
	title = {{LoRA}: {Low}-{Rank} {Adaptation} of {Large} {Language} {Models}},
	shorttitle = {{LoRA}},
	url = {http://arxiv.org/abs/2106.09685},
	abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	month = oct,
	year = {2021},
	note = {arXiv:2106.09685 [cs]},
}

@misc{chowdhery_palm_2022,
	title = {{PaLM}: {Scaling} {Language} {Modeling} with {Pathways}},
	shorttitle = {{PaLM}},
	url = {http://arxiv.org/abs/2204.02311},
	doi = {10.48550/arXiv.2204.02311},
	abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
	month = oct,
	year = {2022},
	note = {arXiv:2204.02311 [cs]},
}

@misc{biderman_pythia_2023,
	title = {Pythia: {A} {Suite} for {Analyzing} {Large} {Language} {Models} {Across} {Training} and {Scaling}},
	shorttitle = {Pythia},
	url = {http://arxiv.org/abs/2304.01373},
	doi = {10.48550/arXiv.2304.01373},
	abstract = {How do large language models (LLMs) develop and evolve over the course of training? How do these patterns change as models scale? To answer these questions, we introduce {\textbackslash}textit\{Pythia\}, a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters. We provide public access to 154 checkpoints for each one of the 16 models, alongside tools to download and reconstruct their exact training dataloaders for further study. We intend {\textbackslash}textit\{Pythia\} to facilitate research in many areas, and we present several case studies including novel results in memorization, term frequency effects on few-shot performance, and reducing gender bias. We demonstrate that this highly controlled setup can be used to yield novel insights toward LLMs and their training dynamics. Trained models, analysis code, training code, and training data can be found at https://github.com/EleutherAI/pythia.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin and Bradley, Herbie and O'Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and Skowron, Aviya and Sutawika, Lintang and van der Wal, Oskar},
	month = apr,
	year = {2023},
	note = {arXiv:2304.01373 [cs]},
}

@inproceedings{birhane_large_2021,
	title = {Large image datasets: {A} pyrrhic win for computer vision?},
	shorttitle = {Large image datasets},
	doi = {10.1109/WACV48630.2021.00158},
	abstract = {In this paper we investigate problematic practices and consequences of large scale vision datasets (LSVDs). We examine broad issues such as the question of consent and justice as well as specific concerns such as the inclusion of verifiably pornographic images in datasets. Taking the ImageNet-ILSVRC-2012 dataset as an example, we perform a cross-sectional model-based quantitative census covering factors such as age, gender, NSFW content scoring, class- wise accuracy, human-cardinality-analysis, and the semanticity of the image class information in order to statistically investigate the extent and subtleties of ethical transgressions. We then use the census to help hand-curate a look-up-table of images in the ImageNet-ILSVRC-2012 dataset that fall into the categories of verifiably pornographic: shot in a non-consensual setting (up-skirt), beach voyeuristic, and exposed private parts. We survey the landscape of harm and threats both the society at large and individuals face due to uncritical and ill-considered dataset curation practices. We then propose possible courses of correction and critique their pros and cons. We have duly open-sourced all of the code and the census meta-datasets generated in this endeavor for the computer vision community to build on. By unveiling the severity of the threats, our hope is to motivate the constitution of mandatory Institutional Review Boards (IRB) for large scale dataset curation.},
	booktitle = {2021 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	author = {Birhane, Abeba and Prabhu, Vinay Uday},
	month = jan,
	year = {2021},
	note = {ISSN: 2642-9381},
	pages = {1536--1546},
}

@article{landgraf_design_2008,
	title = {Design and development of a robotic bee for the analysis of honeybee dance communication},
	volume = {5},
	issn = {1176-2322},
	url = {https://doi.org/10.1080/11762320802617552},
	doi = {10.1080/11762320802617552},
	abstract = {We have designed a robotic honeybee to mimic the bee dance communication system. To achieve this goal, a tracking system has been developed to extract real bee dance trajectories recorded with high-speed video cameras. The results have been analysed to find the essential properties required for the prototype robot. Putative signals in the dance communication have been identified from the literature. Several prototypes were built with successive addition of more features or improvement of existing components. Prototypes were tested in a populated beehive results were documented using high-speed camera recordings. A substantial innovation is a visual feedback system that helps the robot to minimise collisions with other bees.},
	number = {3},
	urldate = {2023-04-15},
	journal = {Applied Bionics and Biomechanics},
	author = {Landgraf, T. and Moballegh, H. and Rojas, R.},
	month = dec,
	year = {2008},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/11762320802617552},
	keywords = {bee robot, biomimetic robots, honeybee dance},
	pages = {157--164},
}

@article{konig_discourse_2015,
	title = {Discourse markers in {Akie}, a southern {Nilotic} language of {Tanzania}},
	author = {König, Christa and Heine, Bernd and Legère, Karsten},
	year = {2015},
}

@article{heine_institutional_2015,
	title = {On institutional frames in {Akie}: a discourse grammar approach},
	author = {Heine, Bernd and König, Christa and Legère, Karsten},
	year = {2015},
}

@book{cowell_arapaho_2008,
	address = {Boulder},
	title = {The {Arapaho} language},
	isbn = {978-0-87081-901-8},
	language = {en},
	publisher = {University Press of Colorado},
	author = {Cowell, Andrew and Moss, Alonzo},
	year = {2008},
	note = {OCLC: ocn180755627},
	keywords = {Arapaho language, Grammar},
}

@inproceedings{braggaar_reproduction_2022,
	address = {Waterville, Maine, USA and virtual meeting},
	title = {A reproduction study of methods for evaluating dialogue system output: {Replicating} {Santhanam} and {Shaikh} (2019)},
	shorttitle = {A reproduction study of methods for evaluating dialogue system output},
	url = {https://aclanthology.org/2022.inlg-genchal.13},
	abstract = {In this paper, we describe our reproduction ef- fort of the paper: Towards Best Experiment Design for Evaluating Dialogue System Output by Santhanam and Shaikh (2019) for the 2022 ReproGen shared task. We aim to produce the same results, using different human evaluators, and a different implementation of the automatic metrics used in the original paper. Although overall the study posed some challenges to re- produce (e.g. difficulties with reproduction of automatic metrics and statistics), in the end we did find that the results generally replicate the findings of Santhanam and Shaikh (2019) and seem to follow similar trends.},
	urldate = {2023-04-07},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Natural} {Language} {Generation}: {Generation} {Challenges}},
	publisher = {Association for Computational Linguistics},
	author = {Braggaar, Anouck and Tomas, Frédéric and Blomsma, Peter and Hommes, Saar and Braun, Nadine and van Miltenburg, Emiel and van der Lee, Chris and Goudbeek, Martijn and Krahmer, Emiel},
	month = jul,
	year = {2022},
	pages = {86--93},
}

@incollection{manaris_natural_1998,
	title = {Natural {Language} {Processing}: {A} {Human}-{Computer} {Interaction} {Perspective}},
	volume = {47},
	shorttitle = {Natural {Language} {Processing}},
	url = {https://www.sciencedirect.com/science/article/pii/S0065245808606658},
	abstract = {Natural language processing has been in existence for more than fifty years. During this time, it has significantly contributed to the field of human-computer interaction in terms of theoretical results and practical applications. As computers continue to become more affordable and accessible, the importance of user inter-faces that are effective, robust, unobtrusive, and user-friendly–regardless of user expertise or impediments–becomes more pronounced. Since natural language usually provides for effortless and effective communication in human-human interaction, its significance and potential in human-computer interaction should not be overlooked–either spoken or typewritten, it may effectively complement other available modalities,11A modality is defined as a communication channel used to convey or acquire information. (Coutaz and Caelen, 1991).such as windows, icons, menus, and pointing; in some cases, such as users with disabilities, natural language may even be the only applicable modality. This chapter examines the field of natural language processing as it relates to human-computer interaction by focusing on its history, interactive application areas, theoretical approaches to linguistic modeling, and relevant computational and philosophical issues. It also presents a taxonomy for interactive natural language systems based on their linguistic knowledge and pro- cessing requirements, and reviews related applications. Finally, it discusses linguistic coverage issues, and explores the development of natural language widgets and their integration into multimodal user interfaces.},
	language = {en},
	urldate = {2023-04-07},
	booktitle = {Advances in {Computers}},
	publisher = {Elsevier},
	author = {Manaris, Bill},
	editor = {Zelkowitz, Marvin V.},
	month = jan,
	year = {1998},
	doi = {10.1016/S0065-2458(08)60665-8},
	pages = {1--66},
}

@incollection{raudaskoski_repair_1990,
	address = {London},
	title = {Repair {Work} in {Human}-{Computer} {Interaction}: {A} {Conversation} {Analytic} {Perspective}},
	isbn = {978-0-08-050264-9},
	shorttitle = {Chapter 7 - {Repair} {Work} in {Human}-{Computer} {Interaction}},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080502649500129},
	abstract = {This chapter discusses repair in different areas of the artificial intelligence (AI) approach to human–computer interaction (HCI) and the approach taken in conversation analysis (CA). The repair is seen as unwanted as the smooth progress of the interaction has been disturbed and communication has broken down. This is the view that is taken by most AI and HCI researchers for repair work. CA is an interpretative approach to studying conversational phenomena with no predefined model for conversation. In CA, repair is essential for successful human communication and is considered as one of the resources for managing meaning in conversation. Within this perspective, repair becomes a condition, not a hindrance, for a successful conversation. Thus, CA researchers concentrate on the patterns of the conversation sequences which handle misunderstanding while HCI researchers are more concerned about the cause of miscommunication, looking at natural conversations to discover types of trouble sources. If conversation involves achieving understanding then repair work is an essential part of the apparatus, enabling the participants to check their interpretations or correct the other person's interpretations. The importance of evaluation to the design of human–computer interfaces is acknowledged by HCI researchers. It is necessary to study not only how people communicate between themselves, but also the specific nature of human–computer communication and the pressures of communication. Systems have to be designed in cycles where evaluation and re-implementation are as important to the final artifact as the original design.},
	language = {en},
	urldate = {2022-12-08},
	booktitle = {Computers and {Conversation}},
	publisher = {Academic Press},
	author = {Raudaskoski, Pirkko},
	editor = {Luff, Paul and Gilbert, Nigel and Frohlich, David},
	month = jan,
	year = {1990},
	doi = {10.1016/B978-0-08-050264-9.50012-9},
	keywords = {*need to get},
	pages = {151--171},
}

@article{pitsch_limits_2016,
	title = {Limits and opportunities for mathematizing communicational conduct for social robotics in the real world? {Toward} enabling a robot to make use of the human’s competences},
	volume = {31},
	issn = {1435-5655},
	shorttitle = {Limits and opportunities for mathematizing communicational conduct for social robotics in the real world?},
	url = {https://doi.org/10.1007/s00146-015-0629-0},
	doi = {10.1007/s00146-015-0629-0},
	abstract = {Given the widespread goal of endowing robotic systems with interactional capabilities that would allow users to deal with them intuitively by using means of natural communication, the text addresses the question to which extent it would be possible to mathematize (aspects of) social interaction. Using the example of a robotic museum guide in a real-world scenario, central challenges in dealing with the situatedness and contingency of human communicational conduct are shown using fine-grained video analysis combining the robot’s internal perspective with the user’s view. On a conceptual level, the text argues to consider human and robot as one ‘interactional system’ that jointly solves a practical (communicational) task. This opens up the perspective to integrate the human’s interactional competences and adaptability in the design and modeling of interactional building blocks for HRI. If we provide the technical system with systematic resources to make use of the human’s competences, the limits of mathematization might gain an interesting twist. Through careful design of the robot’s conduct, a powerful resource exists for the robot to pro-actively influence the users’ expectations about relevant subsequent actions, so that the robot could contribute to establishing the conditions which would be most beneficial to its own functioning.},
	language = {en},
	number = {4},
	urldate = {2023-03-14},
	journal = {AI \& SOCIETY},
	author = {Pitsch, Karola},
	month = nov,
	year = {2016},
	pages = {587--593},
}

@article{ozerov_person_2019,
	title = {Person indexation in {Anal}},
	volume = {18},
	doi = {10.5070/H918142426},
	number = {1},
	journal = {Himalayan Linguistics},
	author = {Ozerov, Pavel},
	year = {2019},
}

@article{torvik_mapaffil_2015,
	title = {{MapAffil}: {A} {Bibliographic} {Tool} for {Mapping} {Author} {Affiliation} {Strings} to {Cities} and {Their} {Geocodes} {Worldwide}},
	volume = {21},
	issn = {1082-9873},
	shorttitle = {{MapAffil}},
	url = {http://www.dlib.org/dlib/november15/torvik/11torvik.html},
	doi = {10.1045/november2015-torvik},
	language = {en},
	number = {11/12},
	urldate = {2023-03-11},
	journal = {D-Lib Magazine},
	author = {Torvik, Vetle I.},
	month = nov,
	year = {2015},
}

@article{rollet_talk_2020,
	title = {“{Talk} to you later”: {Doing} social robotics with conversation analysis. {Towards} the development of an automatic system for the prediction of disengagement},
	volume = {21},
	issn = {1572-0373, 1572-0381},
	shorttitle = {“{Talk} to you later”},
	url = {http://www.jbe-platform.com/content/journals/10.1075/is.19001.roll},
	doi = {10.1075/is.19001.roll},
	abstract = {Abstract
            This article presents an applied discussion of the possibility of integrating conversation analysis (CA)
                    methodology into that of machine learning. The aim is to improve the detection of that which resembles disengagement in the
                    interaction between a robot and a human. We offer a novel analytical assemblage at the heart of the two disciplines, and namely on
                    the level of the annotation schemes provided by conversation analysis transcription methods. First, we demonstrate that the need
                    for a stable structure in establishing an interaction scenario and in designing robot behaviours does not prevent the emergence of
                    ordinariness or creativity among the participants engaged in this interaction. Secondly, based on an actual case, we emphasize the
                    possibility of systematicness in CA transcription to support the choice (a) of the categories targeted by prediction methods and
                    defined by the annotation scheme, and (b) of the verbal and non-verbal features used to create prediction models.},
	language = {en},
	number = {2},
	urldate = {2022-05-12},
	journal = {Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems},
	author = {Rollet, Nicolas and Clavel, Chloé},
	month = may,
	year = {2020},
	pages = {268--292},
}

@article{rohlfing_explanation_2021,
	title = {Explanation as a {Social} {Practice}: {Toward} a {Conceptual} {Framework} for the {Social} {Design} of {AI} {Systems}},
	volume = {13},
	issn = {2379-8939},
	shorttitle = {Explanation as a {Social} {Practice}},
	doi = {10.1109/TCDS.2020.3044366},
	abstract = {The recent surge of interest in explainability in artificial intelligence (XAI) is propelled by not only technological advancements in machine learning but also by regulatory initiatives to foster transparency in algorithmic decision making. In this article, we revise the current concept of explainability and identify three limitations: passive explainee, narrow view on the social process, and undifferentiated assessment of explainee’s understanding. In order to overcome these limitations, we present explanation as a social practice in which explainer and explainee co-construct understanding on the microlevel. We view the co-construction on a microlevel as embedded into a macrolevel, yielding expectations concerning, e.g., social roles or partner models: typically, the role of the explainer is to provide an explanation and to adapt it to the current level of explainee’s understanding; the explainee, in turn, is expected to provide cues that direct the explainer. Building on explanations being a social practice, we present a conceptual framework that aims to guide future research in XAI. The framework relies on the key concepts of monitoring and scaffolding to capture the development of interaction. We relate our conceptual framework and our new perspective on explaining to transparency and autonomy as objectives considered for XAI.},
	number = {3},
	journal = {IEEE Transactions on Cognitive and Developmental Systems},
	author = {Rohlfing, Katharina J. and Cimiano, Philipp and Scharlau, Ingrid and Matzner, Tobias and Buhl, Heike M. and Buschmeier, Hendrik and Esposito, Elena and Grimminger, Angela and Hammer, Barbara and Häb-Umbach, Reinhold and Horwath, Ilona and Hüllermeier, Eyke and Kern, Friederike and Kopp, Stefan and Thommes, Kirsten and Ngonga Ngomo, Axel-Cyrille and Schulte, Carsten and Wachsmuth, Henning and Wagner, Petra and Wrede, Britta},
	month = sep,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Cognitive and Developmental Systems},
	pages = {717--728},
}

@article{dickerson_where_2013,
	title = {Where the action is: {A} conversation analytic perspective on interaction between a humanoid robot, a co-present adult and a child with an {ASD}},
	volume = {14},
	issn = {1572-0373, 1572-0381},
	shorttitle = {Where the action is},
	url = {http://www.jbe-platform.com/content/journals/10.1075/is.14.2.07dic},
	doi = {10.1075/is.14.2.07dic},
	abstract = {This paper examines interaction involving a child with an Autistic Spectrum Disorder, a humanoid robot and a co-present adult. In this paper data from one child (collected as part of the ROBOSKIN project) is analysed in order to evaluate the potential contributions of a conversation analytic perspective to the examination of data relating to socio-emotional reciprocity. The paper argues for the value of treating all interaction as potentially relevant, looking without carefully pre-defined target behaviours and examining behaviour within its specific sequence of interaction. Adopting this approach, the paper suggests, enables noticings and observations that might not be available from perspectives that rely on the coding of pre-specified behaviours in isolation. Treating all interaction as potentially relevant brought into view interactions that might otherwise be dismissed or ignored – because they occurred before, or after, the trial itself. Being informed by the value of unmotivated looking – rather than pre-specified coding schemes – enabled highly relevant behaviour that was not anticipated within the trials to be analysed. Finally, seeing sequence as important meant that behaviours were appreciated in their intricate detail, enabling a more precise understanding than might be available if they were considered separately from that sequential environment. Keywords: autism; assessment; autistic spectrum disorder; experiment; conversation analysis; interaction; humanoid robot; sequences; sequence of interaction; socio-emotional reciprocity},
	language = {en},
	number = {2},
	urldate = {2022-05-12},
	journal = {Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems},
	author = {Dickerson, Paul and Robins, Ben and Dautenhahn, Kerstin},
	month = aug,
	year = {2013},
	pages = {297--316},
}

@misc{adiwardana_towards_2020,
	title = {Towards a {Human}-like {Open}-{Domain} {Chatbot}},
	url = {http://arxiv.org/abs/2001.09977},
	doi = {10.48550/arXiv.2001.09977},
	abstract = {We present Meena, a multi-turn open-domain chatbot trained end-to-end on data mined and filtered from public domain social media conversations. This 2.6B parameter neural network is simply trained to minimize perplexity of the next token. We also propose a human evaluation metric called Sensibleness and Specificity Average (SSA), which captures key elements of a human-like multi-turn conversation. Our experiments show strong correlation between perplexity and SSA. The fact that the best perplexity end-to-end trained Meena scores high on SSA (72\% on multi-turn evaluation) suggests that a human-level SSA of 86\% is potentially within reach if we can better optimize perplexity. Additionally, the full version of Meena (with a filtering mechanism and tuned decoding) scores 79\% SSA, 23\% higher in absolute SSA than the existing chatbots we evaluated.},
	urldate = {2022-06-30},
	publisher = {arXiv},
	author = {Adiwardana, Daniel and Luong, Minh-Thang and So, David R. and Hall, Jamie and Fiedel, Noah and Thoppilan, Romal and Yang, Zi and Kulshreshtha, Apoorv and Nemade, Gaurav and Lu, Yifeng and Le, Quoc V.},
	month = feb,
	year = {2020},
	note = {arXiv:2001.09977 [cs, stat]},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, Machine Learning (cs.LG), Machine Learning (stat.ML), Neural and Evolutionary Computing (cs.NE)},
}

@phdthesis{philippe_antoine_corpus-based_2021,
	title = {A corpus-based account of morphosyntactic evidentiality in discourse in {Chhitkul}-{R} ̄akchham},
	author = {Philippe Antoine, Martinez},
	year = {2021},
}

@incollection{vazquez_soto_constraints_nodate,
	title = {Some constraints on {Cora} causative constructions},
	booktitle = {The {Grammar} of {Causation} and {Interpersonal} {Manipulation}},
	author = {Vázquez Soto, Verónica},
}

@incollection{griffiths_gutob_nodate,
	title = {Gutob},
	booktitle = {The {Munda} {Languages}},
	author = {Griffiths, Arlo},
}

@article{vos_person_2015,
	title = {Person markers in {Gutob}},
	volume = {2},
	issn = {2196-0771, 2196-078X},
	url = {https://www.degruyter.com/document/doi/10.1515/jsall-2015-0011/html},
	doi = {10.1515/jsall-2015-0011},
	abstract = {Gutob is notorious for its variable placement of agreement markers. Gutob has independent pronouns and, for first and second persons, postverbal pronominal clitics which function as subject agreement markers. The placement of the pronominal clitics is quite complex, and has not been studied extensively. Pronominal clitics cannot only attach to verbs, but also to certain adverbs preceding the predicate. Furthermore, the placement of pronominal clitics within the verb complex varies considerably between different auxiliary constructions. The aim of this article is to present a new analysis of person markers in Gutob. Firstly, a discussion of the placement of person markers in sentences with different types of predicates will be given. Secondly, person markers at different positions will be compared on the basis of co-occurrence possibilities and morphosyntactic criteria. It will be argued that person markers in sentence-initial and postverbal position fall into two separate categories: independent pronouns and agreement markers. However, preverbal person markers cannot be assigned to either category, as they share features of both.},
	language = {en},
	number = {2},
	urldate = {2023-04-04},
	journal = {Journal of South Asian Languages and Linguistics},
	author = {Voß, Judith},
	month = sep,
	year = {2015},
	pages = {215--240},
}

@phdthesis{hemmings_kelabit_nodate,
	title = {The {Kelabit} {Language}, {Austronesian} {Voice} and {Syntactic} {Typology}},
	language = {en},
	author = {Hemmings, Charlotte},
}

@phdthesis{vydrina_corpus-based_nodate,
	title = {A corpus-based description of {Kakabe}, a {Western} {Mande} language: prosody in grammar},
	author = {Vydrina, Alexandra},
}

@article{manfredi_juba_nodate,
	title = {Juba {Arabic}},
	author = {Manfredi, Stefano and Petrollino, Sara},
}

@article{miller_juba_2014,
	title = {Juba {Arabic} as a written language},
	volume = {29},
	issn = {0920-9034, 1569-9870},
	url = {http://www.jbe-platform.com/content/journals/10.1075/jpcl.29.2.06mil},
	doi = {10.1075/jpcl.29.2.06mil},
	abstract = {This paper deals with the issue of Juba Arabic (JA) as a written language and investigates various written materials produced from early 20th century up to the early 21st century. The investigated writings are presented in their socio-historical context in order to determine in which ways genres and contexts impact writing practices, particularly regarding orthographic and grammatical choices. These choices are analyzed following the notions of sameness and distance used for evaluating literacy processes in non-standard languages. The paper highlights the key moments and key agents of the codification of JA as a written language and the new developments led by the use of the internet.},
	language = {en},
	number = {2},
	urldate = {2023-03-28},
	journal = {Journal of Pidgin and Creole Languages},
	author = {Miller, Catherine},
	month = oct,
	year = {2014},
	pages = {352--384},
}

@book{yang_jejueo_2020,
	address = {Honolulu},
	title = {Jejueo: the language of {Korea}'s {Jeju} {Island}},
	isbn = {978-0-8248-7443-8},
	shorttitle = {Jejueo},
	language = {en},
	publisher = {University of Hawaiʻi Press},
	author = {Yang, Changyong and Yang, Sejung and O'Grady, William},
	year = {2020},
	keywords = {Jejueo language},
}

@phdthesis{bruil_clause-typing_2014,
	address = {Utrecht},
	title = {Clause-typing and evidentiality in {Ecuadorian} {Siona}},
	language = {en},
	school = {LOT},
	author = {Bruil, Martine},
	year = {2014},
	note = {OCLC: 873538976},
}

@phdthesis{donnelly_aspects_nodate,
	title = {Aspects of tone and voice in {Phuthi}},
	language = {en},
	author = {Donnelly, Simon Scurr},
}

@phdthesis{dingemanse_meaning_2011,
	title = {The {Meaning} and {Use} of {Ideophones} in {Siwu}},
	author = {Dingemanse, Mark},
	year = {2011},
}

@article{wuxi_grammar_nodate,
	title = {A grammar of {Longxi} {Qiang}},
	language = {en},
	author = {Wuxi, Zheng},
}

@phdthesis{grzech_discourse_2016,
	title = {Discourse enclitics in {Tena} {Kichwa}: {A} corpus-based account of information structure and epistemic meaning},
	shorttitle = {School of {Oriental} and {African} {Studies}},
	url = {https://www.cambridge.org/core/product/identifier/S0001972000021033/type/journal_article},
	language = {en},
	urldate = {2023-03-27},
	author = {Grzech, Karolina},
	year = {2016},
}

@article{grzech_non-evidential_2015,
	title = {The non-evidential meaning of the {Tena} {Kichwa} ' direct evidential'},
	author = {Grzech, Karolina},
	year = {2015},
}

@article{himmelmann_tomini-tolitoli_1991,
	title = {Tomini-{Tolitoli} sound structures},
	author = {Himmelmann, Nikolaus P.},
	year = {1991},
}

@article{bracks_intonation_2021,
	title = {The {Intonation} {Unit} in {Totoli}},
	volume = {60},
	issn = {1527-9421},
	url = {https://muse.jhu.edu/article/797962},
	doi = {10.1353/ol.2021.0003},
	language = {en},
	number = {1},
	urldate = {2023-03-27},
	journal = {Oceanic Linguistics},
	author = {Bracks, Cristoph},
	year = {2021},
	pages = {103--132},
}

@book{luraghi_valency_2021,
	title = {Valency over {Time}: {Diachronic} {Perspectives} on {Valency} {Patterns} and {Valency} {Orientation}},
	isbn = {978-3-11-075565-7},
	shorttitle = {Valency over {Time}},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110755657/html},
	language = {en},
	urldate = {2023-03-27},
	publisher = {De Gruyter},
	editor = {Luraghi, Silvia and Roma, Elisa},
	month = oct,
	year = {2021},
	doi = {10.1515/9783110755657},
}

@article{riesberg_first_nodate,
	title = {A first take on information structure in {Totoli} – {Reference} management and its interrelation with voice selection},
	language = {en},
	author = {Riesberg, Sonja},
}

@article{himmelmann_person_2015,
	title = {Person marking and grammatical relations in {Sulawesi}},
	copyright = {Creative Commons Attribution Share Alike 4.0 International},
	url = {http://sealang.net/archives/pl/pdf/PL-A84.115.pdf},
	doi = {10.15144/PL-A84.115},
	language = {en},
	urldate = {2023-03-27},
	author = {Himmelmann, Nikolaus (Ed )},
	collaborator = {CRCL and CRCL and Pacific Linguistics And/Or The Author(S)},
	year = {2015},
	note = {Artwork Size: 2.7M, 115-136 pages
Medium: PDF
Publisher: Pacific Linguistics
Version Number: 1.0},
	pages = {2.7M, 115--136 pages},
}

@book{barlow_grammar_2018,
	title = {A {Grammar} of {Ulwa}},
	author = {Barlow, Russell},
	month = may,
	year = {2018},
}

@article{caron_zaar_2013,
	title = {Zaar {Grammatical} {Sketch}},
	language = {en},
	author = {Caron, Bernard},
	month = mar,
	year = {2013},
}

@inproceedings{hong_prediction_2022,
	address = {New York, NY, USA},
	series = {{FAccT} '22},
	title = {Prediction as {Extraction} of {Discretion}},
	isbn = {978-1-4503-9352-2},
	url = {https://doi.org/10.1145/3531146.3533155},
	doi = {10.1145/3531146.3533155},
	abstract = {I argue that data-driven predictions work primarily as instruments for systematic extraction of discretionary power – the practical capacity to make everyday decisions and define one's situation. This extractive relation reprises a long historical pattern, in which new methods of producing knowledge generate a redistribution of epistemic power: who declares what kind of truth about me, to count for what kinds of decisions? I argue that prediction as extraction of discretion is normal and fundamental to the technology, rather than isolated cases of bias or error. Synthesising critical observations across anthropology, history of technology and critical data studies, the paper demonstrates this dynamic in two contemporary domains: (1) crime and policing demonstrates how predictive systems are extractive by design. Rather than neutral models led astray by garbage data, pre-existing interests thoroughly shape how prediction conceives of its object, its measures, and most importantly, what it does not measure and in doing so devalues. (2) I then examine the prediction of productivity in the long tradition of extracting discretion as a means to extract labour power. Making human behaviour more predictable for the client of prediction (the manager, the corporation, the police officer) often means making life and work more unpredictable for the target of prediction (the employee, the applicant, the citizen).},
	urldate = {2023-03-23},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Hong, Sun-ha},
	month = jun,
	year = {2022},
	pages = {925--934},
}

@article{carnell_talking_nodate,
	title = {Talking {Like} {Others}: {Identity} and {Language} in {Conversational} {User} {Interfaces}},
	abstract = {This position paper highlights the need to reconsider the role of identity in language for conversational user interfaces (CUIs). Just as natural language processing has been proposed as a tool for linguistic justice, CUIs may also be used, specifically in efforts to challenge notions on language that is universally accepted as “standard.” After demonstrating the ethical opportunity presented by identity in CUI language, I note two topics important areas of inquiry: inherent identities in CUIs and the process by which we create identity-representative dialogue for CUIs. While these questions are far from comprehensive, this paper aims to provide direction to future research.},
	language = {en},
	author = {Carnell, Stephanie},
}

@inproceedings{danielescu_eschewing_2020,
	address = {New York, NY, USA},
	series = {{CUI} '20},
	title = {Eschewing {Gender} {Stereotypes} in {Voice} {Assistants} to {Promote} {Inclusion}},
	isbn = {978-1-4503-7544-3},
	url = {https://dl.acm.org/doi/10.1145/3405755.3406151},
	doi = {10.1145/3405755.3406151},
	abstract = {The wide adoption of conversational voice assistants has shaped how we interact with this technology while simultaneously highlighting and reinforcing negative stereotypes. For example, conversational systems often use female voices in subservient roles. They also exclude marginalized groups, such as non-binary individuals, altogether. Speech recognition systems also have significant gender, race and dialectal biases [14, 15, 19]. Instead, there is an opportunity for these systems to help change gender norms and promote inclusion and diversity as we continue to struggle with gender equality [10], and progress towards LGBTQ+ rights across the globe [13]. However, prior research claims that users strongly dislike voices without clear gender markers or misalignments between a voice and personality [12]. This calls for additional research to understand how voice assistants may be designed to not perpetuate gender bias while promoting user adoption.},
	urldate = {2023-03-17},
	booktitle = {Proceedings of the 2nd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Danielescu, Andreea},
	month = jul,
	year = {2020},
	keywords = {Conversational interfaces, LGBTQ+, inclusion and diversity, personality design},
	pages = {1--3},
}

@inproceedings{edwards_lgbtq-ai_2021,
	title = {{LGBTQ}-{AI}? {Exploring} {Expressions} of {Gender} and {Sexual} {Orientation} in {Chatbots}},
	shorttitle = {{LGBTQ}-{AI}?},
	url = {http://arxiv.org/abs/2106.02076},
	doi = {10.1145/3469595.3469597},
	abstract = {Chatbots are popular machine partners for task-oriented and social interactions. Human-human computer-mediated communication research has explored how people express their gender and sexuality in online social interactions, but little is known about whether and in what way chatbots do the same. We conducted semi-structured interviews with 5 text-based conversational agents to explore this topic Through these interviews, we identified 6 common themes around the expression of gender and sexual identity: identity description, identity formation, peer acceptance, positive reflection, uncomfortable feelings and off-topic responses. Chatbots express gender and sexuality explicitly and through relation of experience and emotions, mimicking the human language on which they are trained. It is nevertheless evident that chatbots differ from human dialogue partners as they lack the flexibility and understanding enabled by lived human experience. While chatbots are proficient in using language to express identity, they also display a lack of authentic experiences of gender and sexuality.},
	urldate = {2023-03-17},
	booktitle = {{CUI} 2021 - 3rd {Conference} on {Conversational} {User} {Interfaces}},
	author = {Edwards, Justin and Clark, Leigh and Perrone, Allison},
	month = jul,
	year = {2021},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	pages = {1--4},
}

@inproceedings{jestin_effects_2022,
	address = {New York, NY, USA},
	series = {{CUI} '22},
	title = {Effects of {Wording} and {Gendered} {Voices} on {Acceptability} of {Voice} {Assistants} in {Future} {Autonomous} {Vehicles}},
	isbn = {978-1-4503-9739-1},
	url = {https://doi.org/10.1145/3543829.3543836},
	doi = {10.1145/3543829.3543836},
	abstract = {Voice assistants in future autonomous vehicles may play a major role in supporting the driver during periods of a transfer of control with the vehicle (handover and handback). However, little is known about the effects of different qualities of the voice assistant on its perceived acceptability, and thus its potential to support the driver’s trust in the vehicle. A desktop study was carried out with 18 participants, investigating the effects of three gendered voices and different wording of prompts during handover and handback driving scenarios on measures of acceptability. Participants rated prompts by the voice assistant in nine different driving scenarios, using 5-point Likert style items in a during and post-study questionnaire as well as a short interview at the end. A commanding/formally worded prompt was rated higher on most of the desirable measures of acceptability as compared to an informally worded prompt. The ‘Matthew’ voice used was perceived to be less artificial and more desirable than the ‘Joanna’ voice and the gender-ambiguous ‘Jordan’ voice; however, we caution against interpreting these results as indicative of a general preference of gender, and instead discuss our results to throw light on the complex socio-phonetic nature of voices (including gender) and wording of voice assistants, and the need for careful consideration while designing the same. Results gained facilitate the drawing of insights needed to take better care when designing the voice and wording for voice assistants in future autonomous vehicles.},
	urldate = {2023-03-17},
	booktitle = {Proceedings of the 4th {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Jestin, Iris and Fischer, Joel and Galvez Trigo, Maria Jose and Large, David and Burnett, Gary},
	month = sep,
	year = {2022},
	keywords = {acceptability, autonomous vehicles, gendered voice, handback, handover, voice assistant, wording},
	pages = {1--11},
}

@article{jung_gender_2023,
	series = {Conference on {Human} {Factors} in {Computing} {Systems} - {Proceedings}},
	title = {Gender {Choices} of {Conversational} {Agent}: 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}, {CHI} 2022},
	shorttitle = {Gender {Choices} of {Conversational} {Agent}},
	doi = {10.1145/3334480},
	abstract = {When creating conversational agents, designers have to make decisions about the way the agents present themselves. In this position paper, we identify and synthesize ethical dilemmas that conversational interface designers and researchers face around gender of conversational agents. First, we identify three layers that cause tension in designing conversational agents’ gender: (i) interactional qualities; (ii) goal-orientation; and (iii) societal issues. We then argue that conversational agent designers and re- searchers can navigate this problem space by comparing two ethical frameworks: a utilitarian perspective and a dialogical ethics perspective. Finally, we argue that dialogical ethics can be a balanced, ethical lens that can help conversational agent designers and researchers make design decisions about the gender of an agent},
	journal = {CHI 22 : CHI Conference on Human Factors in Computing Systems},
	author = {Jung, J. and Murray-Rust, D.S. and Gadiraju, Ujwal and Bozzon, Alessandro},
	editor = {Shamma, David A. and Drukcer, Steven and Barbosa, Simone and Lampe, Cliff and Appert, Caroline and Williamson, Julie and Yatani, Koji},
	year = {2023},
	keywords = {Design ethics, Dialogical ethics, Gender-inclusive},
}

@article{lopatovska_effects_nodate,
	title = {Effects of {Gendered} {Voices} on {Personality} {Perceptions} of {Conversational} {User} {Interfaces}},
	language = {en},
	author = {Lopatovska, Irene and Brown, Diedre and Korshakova, Elena},
}

@inproceedings{sutton_gender_2020,
	address = {New York, NY, USA},
	series = {{CUI} '20},
	title = {Gender {Ambiguous}, not {Genderless}: {Designing} {Gender} in {Voice} {User} {Interfaces} ({VUIs}) with {Sensitivity}},
	isbn = {978-1-4503-7544-3},
	shorttitle = {Gender {Ambiguous}, not {Genderless}},
	url = {https://dl.acm.org/doi/10.1145/3405755.3406123},
	doi = {10.1145/3405755.3406123},
	abstract = {In 2019, UNESCO's report [36] highlighting sexism, and the release of 'Q The genderless voice'[38] 1, triggered a waking-up to issues of gender in voice assistants. However, there is a danger that their coincidental timing implies that the latter is the solution to the former; that a voice assistant with a genderless voice cannot be sexist. This paper outlines how gender is not inherent in voice - listeners assign gender to voice. Also, this paper highlights that gender is constructed through a multitude of resources. Thus, a genderless voice is redundant if other elements of the voice assistant's design cause it to be gendered. I posit two take-homes; i) a change of terminology to gender ambiguous will help reframe how we think about gender in voice assistants, and ii) that we should critically engage with all potentially gendering elements in the design of voice assistants, not just the voice, in order to consider gender in a more sensitive manner.},
	urldate = {2023-03-17},
	booktitle = {Proceedings of the 2nd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Sutton, Selina Jeanne},
	month = jul,
	year = {2020},
	keywords = {Design, Gender, Voice Assistants, Voice User Interfaces},
	pages = {1--8},
}

@article{gillespie_regulation_2018,
	title = {Regulation of and by platforms},
	journal = {The SAGE handbook of social media},
	author = {Gillespie, Tarleton},
	year = {2018},
	note = {Publisher: Sage London},
	pages = {254--278},
}

@inproceedings{pitsch_interacting_2019,
	title = {Interacting with {Robots} and {Virtual} {Agents}? {Robotic} {Systems} in {Situated} {Action} and {Social} {Encounters}},
	shorttitle = {Interacting with {Robots} and {Virtual} {Agents}?},
	url = {http://dl.gi.de/handle/20.500.12116/25221},
	doi = {10.18420/muc2019-ws-217},
	abstract = {Research in informatics and the engineering sciences strives to endow technical systems – like (humanoid) robots, embodied conversational agents, voice interfaces etc. – with abilities that should allow the systems to “interact with people in a natural, interpersonal manner” (Breazeal et al. 2016: 1935). While the evaluation of such technologies has a strong tradition in the fields of psychology and cognitive sciences investigating the robot’s/agent’s usability and the users’ perception and attitudes using questionnaires and quantitative measures, it remains unclear as how these results are related to the concrete interactional conduct of the robot/agent, how users spontaneously attempt to deal with such technologies, which resources they mobilize to coordinate their actions with those of the robot/agent, and how the artefact and its agency are constructed. This workshop aims at addressing these open questions in that it suggests an interactional and praxeological approach based on the micro-analysis of video-taped recordings of encounters between humans and robots and a research methodology based on Ethnography and Conversation Analysis. It brings together researchers from the humanities and social sciences who investigate the ways in which robotic systems feature in situated action and social encounters ‘in the wild’.},
	language = {en},
	urldate = {2023-03-14},
	booktitle = {Mensch und {Computer}},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Pitsch, Karola},
	year = {2019},
	note = {Accepted: 2019-09-05T01:07:30Z},
}

@article{zubek_dynamics_2022,
	title = {Dynamics of {Remote} {Communication}: {Movement} {Coordination} in {Video}-{Mediated} and {Face}-to-{Face} {Conversations}},
	volume = {24},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	shorttitle = {Dynamics of {Remote} {Communication}},
	url = {https://www.mdpi.com/1099-4300/24/4/559},
	doi = {10.3390/e24040559},
	abstract = {The present pandemic forced our daily interactions to move into the virtual world. People had to adapt to new communication media that afford different ways of interaction. Remote communication decreases the availability and salience of some cues but also may enable and highlight others. Importantly, basic movement dynamics, which are crucial for any interaction as they are responsible for the informational and affective coupling, are affected. It is therefore essential to discover exactly how these dynamics change. In this exploratory study of six interacting dyads we use traditional variability measures and cross recurrence quantification analysis to compare the movement coordination dynamics in quasi-natural dialogues in four situations: (1) remote video-mediated conversations with a self-view mirror image present, (2) remote video-mediated conversations without a self-view, (3) face-to-face conversations with a self-view, and (4) face-to-face conversations without a self-view. We discovered that in remote interactions movements pertaining to communicative gestures were exaggerated, while the stability of interpersonal coordination was greatly decreased. The presence of the self-view image made the gestures less exaggerated, but did not affect the coordination. The dynamical analyses are helpful in understanding the interaction processes and may be useful in explaining phenomena connected with video-mediated communication, such as “Zoom fatigue”.},
	language = {en},
	number = {4},
	urldate = {2023-03-13},
	journal = {Entropy},
	author = {Zubek, Julian and Nagórska, Ewa and Komorowska-Mach, Joanna and Skowrońska, Katarzyna and Zieliński, Konrad and Rączaszek-Leonardi, Joanna},
	month = apr,
	year = {2022},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {559},
}

@article{raczaszek-leonardi_cultural_2019,
	title = {Cultural {Artifacts} {Transform} {Embodied} {Practice}: {How} a {Sommelier} {Card} {Shapes} the {Behavior} of {Dyads} {Engaged} in {Wine} {Tasting}},
	volume = {10},
	issn = {1664-1078},
	shorttitle = {Cultural {Artifacts} {Transform} {Embodied} {Practice}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02671},
	abstract = {The radical embodied approach to cognition directs researchers’ attention to skilled practice in a structured environment. This means that the structures present in the environment, including structured interactions with others and with artifacts, are put at least on a par with individual cognitive processes in explaining behavior. Both ritualized interactive formats and artifacts can be seen as forms of “external memory,” usually shaped for a particular domain, that constrain skilled practice, perception, and cognition in online behavior and in learning and development. In this paper, we explore how a task involving the recognition of difficult sensory stimuli (wine) by collective systems (dyads) is modified by a domain-specific linguistic artifact (a sommelier card). We point to how using the card changes the way participants explore the stimuli individually, making it more consistent with culturally accrued sommelier know-how, as well as how it transforms the interaction between the participants, creating specific divisions of labor and novel relations. In our exploratory approach, we aim to integrate qualitative methods from anthropology and sociology with quantitative methods from psychology and the dynamical systems approach using both coded behavioral data and automatic movement analysis.},
	urldate = {2023-03-13},
	journal = {Frontiers in Psychology},
	author = {Rączaszek-Leonardi, Joanna and Krzesicka, Julia and Klamann, Natalia and Ziembowicz, Karolina and Denkiewicz, Michał and Kukiełka, Małgorzata and Zubek, Julian},
	year = {2019},
}

@article{spielberger_illichs_1978,
	title = {Illich's "{Counterfoil} {Research}"},
	volume = {28},
	issn = {0011-1953},
	url = {https://www.jstor.org/stable/24457973},
	number = {3},
	urldate = {2023-03-13},
	journal = {CrossCurrents},
	author = {Spielberger, William F.},
	editor = {Illich, Ivan},
	year = {1978},
	note = {Publisher: Wiley},
	pages = {359--362},
}

@article{vollmer_robots_2014,
	title = {Robots {Show} {Us} {How} to {Teach} {Them}: {Feedback} from {Robots} {Shapes} {Tutoring} {Behavior} during {Action} {Learning}},
	volume = {9},
	issn = {1932-6203},
	shorttitle = {Robots {Show} {Us} {How} to {Teach} {Them}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0091349},
	doi = {10.1371/journal.pone.0091349},
	abstract = {Robot learning by imitation requires the detection of a tutor's action demonstration and its relevant parts. Current approaches implicitly assume a unidirectional transfer of knowledge from tutor to learner. The presented work challenges this predominant assumption based on an extensive user study with an autonomously interacting robot. We show that by providing feedback, a robot learner influences the human tutor's movement demonstrations in the process of action learning. We argue that the robot's feedback strongly shapes how tutors signal what is relevant to an action and thus advocate a paradigm shift in robot action learning research toward truly interactive systems learning in and benefiting from interaction.},
	language = {en},
	number = {3},
	urldate = {2023-03-14},
	journal = {PLOS ONE},
	author = {Vollmer, Anna-Lisa and Mühlig, Manuel and Steil, Jochen J. and Pitsch, Karola and Fritsch, Jannik and Rohlfing, Katharina J. and Wrede, Britta},
	year = {2014},
	note = {Publisher: Public Library of Science},
	pages = {e91349},
}

@article{rohlfing_alternative_2016,
	title = {An {Alternative} to {Mapping} a {Word} onto a {Concept} in {Language} {Acquisition}: {Pragmatic} {Frames}},
	volume = {7},
	issn = {1664-1078},
	shorttitle = {An {Alternative} to {Mapping} a {Word} onto a {Concept} in {Language} {Acquisition}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00470},
	abstract = {The classic mapping metaphor posits that children learn a word by mapping it onto a concept of an object or event. However, we believe that a mapping metaphor cannot account for word learning, because even though children focus attention on objects, they do not necessarily remember the connection between the word and the referent unless it is framed pragmatically, that is, within a task. Our theoretical paper proposes an alternative mechanism for word learning. Our main premise is that word learning occurs as children accomplish a goal in cooperation with a partner. We follow Bruner’s (1983) idea and further specify pragmatic frames as the learning units that drive language acquisition and cognitive development. These units consist of a sequence of actions and verbal behaviors that are co-constructed with a partner to achieve a joint goal. We elaborate on this alternative, offer some initial parametrizations of the concept, and embed it in current language learning approaches.},
	urldate = {2023-03-14},
	journal = {Frontiers in Psychology},
	author = {Rohlfing, Katharina J. and Wrede, Britta and Vollmer, Anna-Lisa and Oudeyer, Pierre-Yves},
	year = {2016},
}

@article{cummins_voice_2014,
	title = {Voice, (inter-)subjectivity, and real time recurrent interaction},
	volume = {5},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00760},
	abstract = {Received approaches to a unified phenomenon called “language” are firmly committed to a Cartesian view of distinct unobservable minds. Questioning this commitment leads us to recognize that the boundaries conventionally separating the linguistic from the non-linguistic can appear arbitrary, omitting much that is regularly present during vocal communication. The thesis is put forward that uttering, or voicing, is a much older phenomenon than the formal structures studied by the linguist, and that the voice has found elaborations and codifications in other domains too, such as in systems of ritual and rite. Voice, it is suggested, necessarily gives rise to a temporally bound subjectivity, whether it is in inner speech (Descartes' “cogito”), in conversation, or in the synchronized utterances of collective speech found in prayer, protest, and sports arenas world wide. The notion of a fleeting subjective pole tied to dynamically entwined participants who exert reciprocal influence upon each other in real time provides an insightful way to understand notions of common ground, or socially shared cognition. It suggests that the remarkable capacity to construct a shared world that is so characteristic of Homo sapiens may be grounded in this ability to become dynamically entangled as seen, e.g., in the centrality of joint attention in human interaction. Empirical evidence of dynamic entanglement in joint speaking is found in behavioral and neuroimaging studies. A convergent theoretical vocabulary is now available in the concept of participatory sense-making, leading to the development of a rich scientific agenda liberated from a stifling metaphysics that obscures, rather than illuminates, the means by which we come to inhabit a shared world.},
	urldate = {2023-03-13},
	journal = {Frontiers in Psychology},
	author = {Cummins, Fred},
	year = {2014},
}

@article{rohlfing_how_2006,
	title = {How can multimodal cues from child-directed interaction reduce learning complexity in robots?},
	volume = {20},
	issn = {0169-1864},
	url = {https://doi.org/10.1163/156855306778522532},
	doi = {10.1163/156855306778522532},
	abstract = {Robots have to deal with an enormous amount of sensory stimuli. One solution in making sense of them is to enable a robot system to actively search for cues that help structuring the information. Studies with infants reveal that parents support the learning-process by modifying their interaction style, dependent on their child's developmental age. In our study, in which parents demonstrated everyday actions to their preverbal children (8–11 months old), our aim was to identify objective parameters for multimodal action modification. Our results reveal two action parameters being modified in adult–child interaction: roundness and pace. Furthermore, we found that language has the power to help children structuring actions sequences by synchrony and emphasis. These insights are discussed with respect to the built-in attention architecture of a socially interactive robot, which enables it to understand demonstrated actions. Our algorithmic approach towards automatically detecting the task structure in child-designed input demonstrates the potential impact of insights from developmental learning on robotics. The presented findings pave the way to automatically detect when to imitate in a demonstration task.},
	number = {10},
	urldate = {2023-03-14},
	journal = {Advanced Robotics},
	author = {Rohlfing, Katharina J. and Fritsch, Jannik and Wrede, Britta and Jungmann, Tanja},
	month = jan,
	year = {2006},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1163/156855306778522532},
	pages = {1183--1199},
}

@article{nomikou_asymmetry_2013,
	title = {Asymmetry and adaptation in social interaction: {A} micro-analytic perspective},
	volume = {14},
	issn = {1572-0373, 1572-0381},
	shorttitle = {Asymmetry and adaptation in social interaction},
	url = {https://www.jbe-platform.com/content/journals/10.1075/is.14.2.001nom},
	doi = {10.1075/is.14.2.001nom},
	abstract = {Welcome to e-content platform of John Benjamins Publishing Company. Here you can find all of our electronic books and journals, for purchase and download or subscriber access.},
	language = {en},
	number = {2},
	urldate = {2023-03-14},
	journal = {Interaction Studies},
	author = {Nomikou, Iris and Pitsch, Karola and Rohlfing, Katharina J.},
	month = jan,
	year = {2013},
	note = {Publisher: John Benjamins},
	pages = {vii--xii},
}

@article{rohlfing_multimodal_2020,
	title = {Multimodal {Turn}-{Taking}: {Motivations}, {Methodological} {Challenges}, and {Novel} {Approaches}},
	volume = {12},
	issn = {2379-8939},
	shorttitle = {Multimodal {Turn}-{Taking}},
	doi = {10.1109/TCDS.2019.2892991},
	abstract = {In this paper, we note that despite being a multimodal phenomenon, turn-taking has still been investigated mostly as being unimodal. Based on theoretical positions emphasizing that communication is organized jointly by interaction partners, we identify the challenge of assessing human sequential behavior: 1) spread across different modalities and 2) co-constructed with a partner. By analyzing a corpus of mother-child dyads with cross recurrence quantification analysis and frequent pattern mining, we offer novel steps toward understanding multimodal turn-taking.},
	number = {2},
	journal = {IEEE Transactions on Cognitive and Developmental Systems},
	author = {Rohlfing, Katharina J. and Leonardi, Giuseppe and Nomikou, Iris and Rączaszek-Leonardi, Joanna and Hüllermeier, Eyke},
	month = jun,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Cognitive and Developmental Systems},
	pages = {260--271},
}

@inproceedings{pelikan_robot_2023,
	address = {New York, NY, USA},
	series = {{HRI} '23},
	title = {Robot {Sound}-{In}-{Interaction}},
	isbn = {978-1-4503-9970-8},
	url = {https://doi.org/10.1145/3568294.3579975},
	doi = {10.1145/3568294.3579975},
	abstract = {Sound is an important interaction modality in human interaction, which robot design is only starting to tap into. Drawing on insights about how human sounds support coordination of bodily activities, this work focuses on how robots can communicate through sound in concrete interactions in the wild. My work contributes a focus on how users make sense of sound in everyday interaction, promotes re-consideration of what HRI is designing for and stimulates the development of new HRI design methods.},
	urldate = {2023-03-14},
	booktitle = {Companion of the 2023 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Pelikan, Hannah R. M.},
	year = {2023},
	pages = {754--756},
}

@article{gauthier_agency_2022,
	title = {Agency and {Amplification}: {A} {Comparison} of {Manual} and {Computational} {Thematic} {Analyses} by {Public} {Health} {Researchers}},
	volume = {7},
	shorttitle = {Agency and {Amplification}},
	url = {https://doi.org/10.1145/3567552},
	doi = {10.1145/3567552},
	abstract = {Computational techniques offer a means to overcome the amplified complexity and resource-intensity of qualitative research on online communities. However, we lack an understanding of how these techniques are integrated by researchers in practice, and how to address concerns about researcher agency in the qualitative research process. To explore this gap, we deployed the Computational Thematic Analysis Toolkit to a team of public health researchers, and compared their analysis to a team working with traditional tools and methods. Each team independently conducted a thematic analysis of a corpus of comments from Canadian news sites to understand discourses around vaccine hesitancy. We then compared the analyses to investigate how computational techniques may have influenced their research process and outcomes. We found that the toolkit provided access to advanced computational techniques for researchers without programming expertise, facilitated their interaction and interpretation of the data, but also found that it influenced how they approached their thematic analysis.},
	number = {GROUP},
	urldate = {2023-03-13},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Gauthier, Robert P. and Pelletier, Catherine and Carrier, Laurie-Ann and Dionne, Maude and Dubé, Ève and Meyer, Samantha and Wallace, James R.},
	month = dec,
	year = {2022},
	pages = {2:1--2:22},
}

@article{de_graaf_why_2019,
	title = {Why {Would} {I} {Use} {This} in {My} {Home}? {A} {Model} of {Domestic} {Social} {Robot} {Acceptance}},
	volume = {34},
	issn = {0737-0024},
	shorttitle = {Why {Would} {I} {Use} {This} in {My} {Home}?},
	url = {https://doi.org/10.1080/07370024.2017.1312406},
	doi = {10.1080/07370024.2017.1312406},
	abstract = {Many independent studies in social robotics and human–robot interaction have gained knowledge on various factors that affect people’s perceptions of and behaviors toward robots. However, only a few of those studies aimed to develop models of social robot acceptance integrating a wider range of such factors. With the rise of robotic technologies for everyday environments, such comprehensive research on relevant acceptance factors is increasingly necessary. This article presents a conceptual model of social robot acceptance with a strong theoretical base, which has been tested among the general Dutch population (n = 1,168) using structural equation modeling. The results show a strong role of normative believes that both directly and indirectly affect the anticipated acceptance of social robots for domestic purposes. Moreover, the data show that, at least at this stage of diffusion within society, people seem somewhat reluctant to accept social behaviors from robots. The current findings of our study and their implications serve to push the field of acceptable social robotics forward. For the societal acceptance of social robots, it is vital to include the opinions of future users at an early stage of development. This way future designs can be better adapted to the preferences of potential users.},
	number = {2},
	urldate = {2023-03-13},
	journal = {Human–Computer Interaction},
	author = {de Graaf, Maartje M. A. and Ben Allouch, Somaya and van Dijk, Jan A. G. M.},
	month = mar,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/07370024.2017.1312406},
	pages = {115--173},
}

@article{kolesnikova_complex_2020,
	title = {Complex {System} {View} on {Natural} {Language}},
	volume = {62},
	abstract = {The study of complex systems in many sciences such as physics, chemistry, biology, engineering, economics, psychology, among others, has demonstrated itself as a powerful approach to resolve many hard issues and to contribute to a fuller and more realistic description of various phenomena. As different to other types of systems, complex systems are characterized by such properties as self-organization, emergence, openness, dynamic nature, chaoticity, fractality, catastrophism, nonlinearity, and fuzziness. It turns out that natural language as a system possess many indispensable properties of complex systems, so it can be viewed and studied as a complex adaptive system. We show that the complex system view on natural language is powerful not only to incorporate knowledge of language accumulated by traditional linguistics, but further make significant discoveries on many open issues in phonetics, grammar, lexicon, language origin and evolution, first language acquisition and development, simulating language functionalities by computational models.},
	language = {en},
	journal = {Polibits},
	author = {Kolesnikova, Olga},
	year = {2020},
	pages = {21--32},
}

@article{lucking_leading_2022,
	title = {Leading voices: dialogue semantics, cognitive science and the polyphonic structure of multimodal interaction},
	issn = {1866-9808, 1866-9859},
	shorttitle = {Leading voices},
	doi = {10.1017/langcog.2022.30},
	abstract = {The neurocognition of multimodal interaction – the embedded, embodied, predictive processing of vocal and non-vocal communicative behaviour – has developed into an important subfield of cognitive science. It leaves a glaring lacuna, however, namely the dearth of a precise investigation of the meanings of the verbal and non-verbal communication signals that constitute multimodal interaction. Cognitively construable dialogue semantics provides a detailed and context-aware notion of meaning, and thereby contributes content-based identity conditions needed for distinguishing syntactically or form-based defined multimodal constituents. We exemplify this by means of two novel empirical examples: dissociated uses of negative polarity utterances and head shaking, and attentional clarification requests addressing speaker/hearer roles. On this view, interlocutors are described as co-active agents, thereby motivating a replacement of sequential turn organisation as a basic organising principle with notions of leading and accompanying voices. The Multimodal Serialisation Hypothesis is formulated: multimodal natural language processing is driven in part by a notion of vertical relevance – relevance of utterances occurring simultaneously – which we suggest supervenes on sequential (‘horizontal’) relevance – relevance of utterances succeeding each other temporally.},
	language = {en},
	journal = {Language and Cognition},
	author = {Lücking, Andy and Ginzburg, Jonathan},
	month = dec,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	pages = {1--25},
}

@article{carpendale_development_2021,
	title = {The {Development} of {Giving} in {Forms} of {Object} {Exchange}: {Exploring} the {Roots} of {Communication} and {Morality} in {Early} {Interaction} around {Objects}},
	volume = {65},
	issn = {0018-716X, 1423-0054},
	shorttitle = {The {Development} of {Giving} in {Forms} of {Object} {Exchange}},
	url = {https://www.karger.com/Article/FullText/517221},
	doi = {10.1159/000517221},
	abstract = {Giving is an act of great social importance across cultures, with communicative as well as moral dimensions because it is linked to sharing and fairness. We critically evaluate various explanations for how this social process develops in infancy and take a process-relational approach, using naturalistic observations to illustrate forms of interaction involving the exchange of objects and possible developmental trajectories for the emergence of different forms of giving. Based on our data, we propose that the object becomes a pivot point for interaction, and through the process of such interaction the social actions of showing and giving emerge and take on diverse social meanings within the relations between infants and caregivers.},
	language = {english},
	number = {3},
	urldate = {2023-03-09},
	journal = {Human Development},
	author = {Carpendale, Jeremy I. M. and Müller, Ulrich and Wallbridge, Beau and Broesch, Tanya and Cameron-Faulkner, Thea and Ten Eycke, Kayla},
	year = {2021},
	note = {Publisher: Karger Publishers},
	pages = {166--179},
}

@article{tatsumi_learning_2022,
	title = {Learning conversational dependency: {Children}’s response using un in {Japanese}},
	issn = {0305-0009, 1469-7602},
	shorttitle = {Learning conversational dependency},
	url = {https://www.cambridge.org/core/journals/journal-of-child-language/article/learning-conversational-dependency-childrens-response-using-un-in-japanese/EB2753BD70A736EF7A96E0AE7742E6B7},
	doi = {10.1017/S0305000922000344},
	abstract = {This study investigates how Japanese-speaking children learn interactional dependencies in conversations that determine the use of un, a token typically used as a positive response for yes-no questions, backchannel, and acknowledgement. We hypothesise that children learn to produce un appropriately by recognising different types of cues occurring in the immediately preceding turns. We built a set of generalised linear models on the longitudinal conversation data from seven children aged 1 to 5 years and their caregivers. Our models revealed that children not only increased their un production, but also learned to attend relevant cues in the preceding turns to understand when to respond by producing un. Children increasingly produced un when their interlocutors asked a yes-no question or signalled the continuation of their own speech. These results illustrate how children learn the probabilistic dependency between adjacent turns, and become able to participate in conversational interactions.},
	language = {en},
	urldate = {2023-03-09},
	journal = {Journal of Child Language},
	author = {Tatsumi, Tomoko and Sala, Giovanni},
	month = jul,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	pages = {1--19},
}

@misc{harper_nemo_2023,
	title = {{NeMo}: a toolkit for {Conversational} {AI} and {Large} {Language} {Models}},
	copyright = {Apache-2.0},
	shorttitle = {{NeMo}},
	url = {https://github.com/NVIDIA/NeMo},
	abstract = {NeMo: a toolkit for conversational AI},
	urldate = {2023-03-08},
	author = {Harper, Eric and Majumdar, Somshubra and Kuchaiev, Oleksii and Jason, Li and Zhang, Yang and Bakhturina, Evelina and Noroozi, Vahid and Subramanian, Sandeep and Nithin, Koluguri and Jocelyn, Huang and Jia, Fei and Balam, Jagadeesh and Yang, Xuesong and Livne, Micha and Dong, Yi and Naren, Sean and Ginsburg, Boris},
	month = mar,
	year = {2023},
	note = {original-date: 2019-08-05T20:16:42Z},
}

@inproceedings{heerden_basic_2009,
	title = {Basic speech recognition for spoken dialogues},
	url = {https://www.isca-speech.org/archive/interspeech_2009/heerden09b_interspeech.html},
	doi = {10.21437/Interspeech.2009-760},
	abstract = {Spoken dialogue systems (SDSs) have great potential for information access in the developing world. However, the realisation of that potential requires the solution of several challenging problems, including the development of sufﬁciently accurate speech recognisers for a diverse multitude of languages. We investigate the feasibility of developing smallvocabulary speaker-independent ASR systems designed for use in a telephone-based information system, using ten resourcescarce languages spoken in South Africa as a case study.},
	language = {en},
	urldate = {2023-03-08},
	booktitle = {Interspeech 2009},
	publisher = {ISCA},
	author = {Heerden, Charl van and Barnard, Etienne and Davel, Marelie},
	month = sep,
	year = {2009},
	pages = {3003--3006},
}

@article{nicmanis_spoken_nodate,
	title = {Spoken {Dialogue} {System} for {Call} {Centers} with {Expressive} {Speech} {Synthesis}},
	abstract = {In this paper, we present a prototype of a spoken dialogue system that integrates automatic speech recognition (ASR), natural language understanding (NLU), bot management system, and expressive text-to-speech (TTS). Such a solution can be integrated into a call center to provide first-line support, replace older interactive voice response (IVR) systems, decrease the load on call center operators and greatly improve client experience.},
	language = {en},
	author = {Nicmanis, Davis and Salimbajevs, Askars},
}

@article{orlandi_using_nodate,
	title = {Using {Dialog} {Corrections} to {Improve} {Speech} {Recognition}},
	abstract = {We propose a preliminary method for automatically correcting errors in spoken dialogue systems1. Current spoken dialogue systems usually show a rather static and rigid behavior regarding recognition errors, therefore a feasible method of correcting system errors might be helpful to successfully support user requests. Moreover, a correction differs from non-correction prosodically [1]. Generally a user correction exhibits a greater prosodic difference the more distant it is from the initial error. In this case it is recognized more poorly, and it involves a longer human-machine interaction because this often leds to the same recognition errors.},
	language = {en},
	author = {Orlandi, Marco and Culy, Christopher and Franco, Horacio},
}

@inproceedings{chiu_speech_2018,
	title = {Speech {Recognition} for {Medical} {Conversations}},
	url = {https://www.isca-speech.org/archive/interspeech_2018/chiu18_interspeech.html},
	doi = {10.21437/Interspeech.2018-40},
	abstract = {In this paper we document our experiences with developing speech recognition for medical transcription – a system that automatically transcribes doctor-patient conversations. Towards this goal, we built a system along two different methodological lines – a Connectionist Temporal Classiﬁcation (CTC) phoneme based model and a Listen Attend and Spell (LAS) grapheme based model. To train these models we used a corpus of anonymized conversations representing approximately 14,000 hours of speech. Because of noisy transcripts and alignments in the corpus, a signiﬁcant amount of effort was invested in data cleaning issues. We describe a two-stage strategy we followed for segmenting the data. The data cleanup and development of a matched language model was essential to the success of the CTC based models. The LAS based models, however were found to be resilient to alignment and transcript noise and did not require the use of language models. CTC models were able to achieve a word error rate of 20.1\%, and the LAS models were able to achieve 18.3\%. Our analysis shows that both models perform well on important medical utterances and therefore can be practical for transcribing medical conversations.},
	language = {en},
	urldate = {2023-03-08},
	booktitle = {Interspeech 2018},
	publisher = {ISCA},
	author = {Chiu, Chung-Cheng and Tripathi, Anshuman and Chou, Katherine and Co, Chris and Jaitly, Navdeep and Jaunzeikare, Diana and Kannan, Anjuli and Nguyen, Patrick and Sak, Hasim and Sankar, Ananth and Tansuwan, Justin and Wan, Nathan and Wu, Yonghui and Zhang, Xuedong},
	month = sep,
	year = {2018},
	pages = {2972--2976},
}

@inproceedings{shinozaki_error_2001,
	title = {Error analysis using decision trees in spontaneous presentation speech recognition},
	doi = {10.1109/ASRU.2001.1034621},
	abstract = {This paper proposes the use of decision trees for analyzing errors in spontaneous presentation speech recognition. The trees are designed to predict whether a word or a phoneme can be correctly recognized or not, using word or phoneme attributes as inputs. The trees, are constructed using training "cases" by choosing questions about attributes step by step according to the gain ratio criterion. The errors in recognizing spontaneous presentations given by 10 male speakers were analyzed, and the explanation capability of attributes for the recognition errors was quantitatively evaluated. A restricted set of attributes closely related to the recognition errors was identified for both words and phonemes.},
	booktitle = {{IEEE} {Workshop} on {Automatic} {Speech} {Recognition} and {Understanding}, 2001. {ASRU} '01.},
	author = {Shinozaki, T. and Furui, S.},
	month = dec,
	year = {2001},
	pages = {198--201},
}

@article{xiong_toward_2017,
	title = {Toward {Human} {Parity} in {Conversational} {Speech} {Recognition}},
	volume = {25},
	issn = {2329-9304},
	doi = {10.1109/TASLP.2017.2756440},
	abstract = {Conversational speech recognition has served as a flagship speech recognition task since the release of the Switchboard corpus in the 1990s. In this paper, we measure a human error rate on the widely used NIST 2000 test set for commercial bulk transcription. The error rate of professional transcribers is 5.9\% for the Switchboard portion of the data, in which newly acquainted pairs of people discuss an assigned topic, and 11.3\% for the CallHome portion, where friends and family members have open-ended conversations. In both cases, our automated system edges past the human benchmark, achieving error rates of 5.8\% and 11.0\%, respectively. The key to our system's performance is the use of various convolutional and long-short-term memory acoustic model architectures, combined with a novel spatial smoothing method and lattice-free discriminative acoustic training, multiple recurrent neural network language modeling approaches, and a systematic use of system combination. Comparing frequent errors in our human and machine transcripts, we find them to be remarkably similar, and highly correlated as a function of the speaker. Human subjects find it very difficult to tell which errorful transcriptions come from humans. Overall, this suggests that, given sufficient matched training data, conversational speech transcription engines are approximating human parity in both quantitative and qualitative terms.},
	number = {12},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Xiong, Wayne and Droppo, Jasha and Huang, Xuedong and Seide, Frank and Seltzer, Michael L. and Stolcke, Andreas and Yu, Dong and Zweig, Geoffrey},
	month = dec,
	year = {2017},
	note = {Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	pages = {2410--2423},
}

@inproceedings{aneja_conversational_2020,
	address = {New York, NY, USA},
	series = {{IVA} '20},
	title = {Conversational {Error} {Analysis} in {Human}-{Agent} {Interaction}},
	isbn = {978-1-4503-7586-3},
	url = {https://doi.org/10.1145/3383652.3423901},
	doi = {10.1145/3383652.3423901},
	abstract = {Conversational Agents (CAs) present many opportunities for changing how we interact with information and computer systems in a more natural, accessible way. Building on research in machine learning and HCI, it is now possible to design and test multi-turn CA that is capable of extended interactions. However, there are many ways in which these CAs can "fail" and fall short of human expectations. We systematically analyzed how five different types of conversational errors impacted perceptions of an embodied CA. Not all errors negatively impacted perceptions of the agent. Repetitions by the agent and clarifications by the human significantly decreased the perceived intelligence and anthropomorphism of the agent. Turn-taking errors significantly decreased the likability of the agent. However, coherence errors significantly positively increased likability, and these errors were also associated with positive valence via facial expressions, suggesting that the users found them amusing. We believe this work is the first to identify that turn-taking, repetition, clarification, and coherence errors directly affect users' acceptance of an embodied CA, and are worth taking note by designers of such systems during dialog configuration. We release the Agent Conversational Error (ACE) dataset, a set of transcripts and error annotations of human-agent conversations. The dataset can be found at the GITHUB link: https://github.com/deepalianeja/ACE-dataset},
	urldate = {2023-03-08},
	booktitle = {Proceedings of the 20th {ACM} {International} {Conference} on {Intelligent} {Virtual} {Agents}},
	publisher = {Association for Computing Machinery},
	author = {Aneja, Deepali and McDuff, Daniel and Czerwinski, Mary},
	year = {2020},
	pages = {1--8},
}

@inproceedings{ess-dykema_linguistically_1998,
	title = {Linguistically engineered tools for speech recognition error analysis},
	url = {https://www.isca-speech.org/archive/icslp_1998/essdykema98_icslp.html},
	doi = {10.21437/ICSLP.1998-503},
	abstract = {In order to improve Large Vocabulary Continuous Speech Recognition (LVCSR) systems, it is essential to discover exactly how our current systems are underperforming. The major intellectual tool for solving this problem is error analysis: careful investigation of just which factors are contributing to errors in the recognizers. This paper presents our observations of the effects that discourse (i.e., dialog) modeling has on LVCSR system performance. As our title indicates, we emphasize the recognition error analysis methodology we developed and what it showed us as opposed to emphasizing development of the discourse model itself. In the ﬁrst analysis of our output data, we focussed on errors that could be eliminated by Dialog Act discourse tagging [JSB97] using Dialog Act-speciﬁc language models. In a second analysis, we manipulated the parameterization of the Dialog Act-speciﬁc language models, enabling us to acquire evidence of the constraints these models introduced. The word error rate did not signiﬁcantly decrease since the error rate in the largest category of Dialog Acts, namely Statements, did not signiﬁcantly decrease. We did, however, observe signiﬁcant error reduction in the less frequently occurring Dialog Acts and we report on the characteristic of the error corrections. We discovered that discourse models can introduce simple syntactic constraints and that they are most sensitive to parts of speech.},
	language = {en},
	urldate = {2023-03-08},
	booktitle = {5th {International} {Conference} on {Spoken} {Language} {Processing} ({ICSLP} 1998)},
	publisher = {ISCA},
	author = {Ess-Dykema, Carol Van and Ries, Klaus},
	month = nov,
	year = {1998},
	pages = {paper 0787--0},
}

@inproceedings{siohan_speech_2004,
	title = {Speech recognition error analysis on the {English} {MALACH} corpus},
	url = {https://www.isca-speech.org/archive/interspeech_2004/siohan04_interspeech.html},
	doi = {10.21437/Interspeech.2004-171},
	abstract = {This paper presents an analysis of the word recognition error rate on an English subset of the MALACH corpus. The MALACH project is an NSF-funded research program related to the development of multilingual access to large audio archives. The archive of interest is a large collection of testimonies from 52,000 survivors, liberators, rescuers and witnesses of the Nazi Holocaust, assembled by the Shoah Visual History Foundation. This data has some unique characteristics that make it quite unusual in the speech recognition community such as elderly speech, noisy conditions, heavily accented speech. Hence, it is a challenging task for automatic speech recognition (ASR). This paper attempts to identify the factors affecting the ASR performance on that task. It was found that the signal-to-noise ratio and syllable rate were two dominant factors in explaining the overall word error rate, while we observed no evidence of the impact of accent and speaker’s age on the recognition performance. Based on this evidence, noise compensation experiments were carried out and led to a 1.1\% absolute reduction of the word error rate.},
	language = {en},
	urldate = {2023-03-08},
	booktitle = {Interspeech 2004},
	publisher = {ISCA},
	author = {Siohan, Olivier and Ramabhadran, Bhuvana and Zweig, Geoffrey},
	month = oct,
	year = {2004},
	pages = {413--416},
}

@book{schackow_grammar_2015,
	title = {A grammar of {Yakkha}},
	isbn = {978-3-946234-11-1},
	url = {https://library.oapen.org/handle/20.500.12657/32844},
	language = {en},
	urldate = {2023-03-06},
	publisher = {Language Science Press},
	author = {Schackow, Diana},
	year = {2015},
	doi = {10.26530/OAPEN_603340},
}

@book{levinson_grammar_2022,
	title = {A {Grammar} of {Yélî} {Dnye}: {The} {Papuan} {Language} of {Rossel} {Island}},
	isbn = {978-3-11-073385-3},
	shorttitle = {A {Grammar} of {Yélî} {Dnye}},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110733853/html},
	language = {en},
	urldate = {2023-03-06},
	publisher = {De Gruyter},
	author = {Levinson, Stephen C.},
	month = may,
	year = {2022},
	doi = {10.1515/9783110733853},
}

@article{caron_information_2016,
	title = {Information {Structure} \& {Peripheries} in {Zaar}},
	abstract = {In this paper analysing peripheries in relation with syntax and information structure in Zaar, a Chadic language spoken in Nigeria, we have argued for a minimal annotation representing in a simple and concise way the interface between information structure and syntax The article uses the concept of macrosyntax, based on illocutionary units, for this new level of annotation using existing morphosyntactic tiers in Elan. The annotation system has been chosen, and a corresponding set of tags developed, bearing in mind that they should be as theory-neutral as possible in order to implement a genuine bottom-up heuristic methodology. The main asset of this system of annotation lies in the notion of stacks it uses to account for disfluencies, discontinuities and ellipses, and represent the oral discursive flow. With the corresponding annotation script, a pilot 90 min (15,000 words) corpus has been annotated to run a preliminary study of peripheries. We have argued that, although topics and frame-setters share the same intonation pattern, their syntactic properties call for a specific syntactic representation within the frame of Universal Dependency Grammar.},
	language = {en},
	author = {Caron, Bernard},
	year = {2016},
}

@article{shklovsky_tseltal_2012,
	title = {{TSELTAL} {CLAUSE} {STRUCTURE}},
	abstract = {This dissertation examines the syntax of clausal structure in Tseltal (Mayan) with a particular focus on agreement phenomena. The first domain of investigation is the External Possession Construction, in which the clausal agreement is controlled by a possessor of the internal argument, rather than the internal argument itself. It is argued that clausal (p-agreement can target nominals embedded in other noun phrases if the head of the embedding phrase incorporates into the verbal complex. It is argued that this type of long-distance agreement arises when other potential agreement controllers are evacuated or otherwise made unavailable.},
	language = {en},
	author = {Shklovsky, Kirill},
	year = {2012},
}

@misc{polian_tseltal-spanish_2020,
	title = {Tseltal-{Spanish} multidialectal dictionary.},
	url = {https://dictionaria.clld.org/contributions/tseltal},
	urldate = {2023-03-06},
	author = {Polian, Gilles},
	year = {2020},
}

@misc{noauthor_glottolog_nodate,
	title = {Glottolog 4.7 - {Tzeltal}},
	url = {https://glottolog.org/resource/languoid/id/tzel1254},
	urldate = {2023-03-06},
}

@inproceedings{le_better_2016,
	title = {Better {Evaluation} of {ASR} in {Speech} {Translation} {Context} {Using} {Word} {Embeddings}},
	url = {https://www.isca-speech.org/archive/interspeech_2016/le16_interspeech.html},
	doi = {10.21437/Interspeech.2016-464},
	abstract = {This paper investigates the evaluation of ASR in spoken language translation context. More precisely, we propose a simple extension of WER metric in order to penalize differently substitution errors according to their context using word embeddings. For instance, the proposed metric should catch near matches (mainly morphological variants) and penalize less this kind of error which has a more limited impact on translation performance. Our experiments show that the correlation of the new proposed metric with SLT performance is better than the one of WER. Oracle experiments are also conducted and show the ability of our metric to ﬁnd better hypotheses (to be translated) in the ASR N-best. Finally, a preliminary experiment where ASR tuning is based on our new metric shows encouraging results. For reproductible experiments, the code allowing to call our modiﬁed WER and the corpora used are made available to the research community.},
	language = {en},
	urldate = {2023-03-06},
	booktitle = {Interspeech 2016},
	publisher = {ISCA},
	author = {Le, Ngoc-Tien and Servan, Christophe and Lecouteux, Benjamin and Besacier, Laurent},
	month = sep,
	year = {2016},
	pages = {2538--2542},
}

@article{cowen_mapping_2019,
	title = {Mapping 24 emotions conveyed by brief human vocalization},
	volume = {74},
	issn = {1935-990X},
	doi = {10.1037/amp0000399},
	abstract = {Emotional vocalizations are central to human social life. Recent studies have documented that people recognize at least 13 emotions in brief vocalizations. This capacity emerges early in development, is preserved in some form across cultures, and informs how people respond emotionally to music. What is poorly understood is how emotion recognition from vocalization is structured within what we call a semantic space, the study of which addresses questions critical to the field: How many distinct kinds of emotions can be expressed? Do expressions convey emotion categories or affective appraisals (e.g., valence, arousal)? Is the recognition of emotion expressions discrete or continuous? Guided by a new theoretical approach to emotion taxonomies, we apply large-scale data collection and analysis techniques to judgments of 2,032 emotional vocal bursts produced in laboratory settings (Study 1) and 48 found in the real world (Study 2) by U.S. English speakers (N = 1,105). We find that vocal bursts convey at least 24 distinct kinds of emotion. Emotion categories (sympathy, awe), more so than affective appraisals (including valence and arousal), organize emotion recognition. In contrast to discrete emotion theories, the emotion categories conveyed by vocal bursts are bridged by smooth gradients with continuously varying meaning. We visualize the complex, high-dimensional space of emotion conveyed by brief human vocalization within an online interactive map. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	journal = {American Psychologist},
	author = {Cowen, Alan S. and Elfenbein, Hillary Anger and Laukka, Petri and Keltner, Dacher},
	year = {2019},
	note = {Place: US
Publisher: American Psychological Association},
	pages = {698--712},
}

@phdthesis{romanenko_robust_2022,
	type = {Dissertation},
	title = {Robust speech recognition for low-resource languages},
	copyright = {CC BY 4.0 International},
	url = {https://oparu.uni-ulm.de/xmlui/handle/123456789/41877},
	abstract = {Process of human-machine interaction is an integral part of everyday human life in a modern world. The various interfaces are intended to facilitate this interaction and provide maximum comfort for users. The speech interface is the most universal, and it can be used in a vast majority of systems. Speech is the main way of communication between people, from this point of view speech interface looks completely natural. Nowadays, human-machine speech interfaces can consist of many complex components in order to implement an interaction with a user. However, a primary element of such interfaces is an automatic speech recognition (ASR) system. 
Automatic recognition of spontaneous speech in a telephone channel can be solved very successfully in the presence of significant amount of speech training data, but the collection and processing of such data is a complex, time-consuming and expensive task. Great amount of data is available only for high-resource languages such as English, Spanish, German, Chinese, French, etc. At the same time, there are many languages with no significant amount of training data for ASR systems preparation. Such languages are commonly referred to as low-resource languages. The number of native speakers for such languages can reach tens, and sometimes hundreds of millions of people. Taking this into account, building ASR systems for such languages is an important task. 
The main objective main objective of this thesis is the development of universal methodology for robust speech recognition of low-resource languages. To achieve it, we have solved three tasks. First, we have developed a flexible methodology in order to build an ASR system for large vocabulary conversational speech on low-resource languages. Second, we have identified a set of languages representing a wide variety of acoustic and grammatical features that influence on ASR systems. Third, we have conducted experimental studies of the developed universal methodology and compared the accuracy of the resulting ASR systems with the state-of-the-art results. 
We have contributed to several key components of the ASR system as part of the first task. We have proposed speaker-dependent bottleneck acoustic features trained with a multilingual approach, to improve acoustic modeling. Besides, a new approach of combining acoustic features has been proposed. In terms of language modeling, we have proposed a new method of text data augmentation with the artificial texts generated by the Char-RNN model. Finally, we have created a universal methodology that combines both existing and proposed methods. This methodology represents a complete pipeline for building ASR systems for low-resource languages. 
As a part of the second task, we have identified the most important language features which affect the building process of ASR systems. We have considered such factors as word order, agglutination, inflection, presence of an accent, dialects, and tone. Based on the analysis, we have created a set of low-resource languages that covers the factors described above and several additional features. This set includes eight languages: Georgian, Turkish, Kazakh, Vietnamese, Swahili, Tagalog, Zulu, and Russian. 
As a part of the third task, we have conducted large-scale experimental studies. We have identified the most effective basic acoustic features and the training pipeline for initial GMM-HMM models. We have verified proposed multilingual speaker-dependent bottleneck features and confirmed the effectiveness of the delayed combination for acoustic features. We have determined the usefulness of the proposed text data augmentation approach. Moreover, we have found this approach complementary to the addition of filtered web-text data. We have experimented with various neural network-based acoustic models and identified the most effective ones. Finally, we have compared the accuracy of resulting ASR systems with the state-of-the-art results for studied low-resource languages. 
We believe that this work will accelerate further research of speech recognition in low-resource languages and make speech recognition systems available for a wide variety of world languages in the near future.},
	language = {en\_US},
	urldate = {2023-03-06},
	school = {Universität Ulm},
	author = {Romanenko, Aleksei},
	month = feb,
	year = {2022},
	doi = {10.18725/OPARU-41801},
	note = {Accepted: 2022-02-15T12:45:27Z
ISBN: 9781789916300},
}

@article{epperlein_context_2022,
	title = {Context and prediction matter for the interpretation of social interactions across species},
	volume = {17},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0277783},
	doi = {10.1371/journal.pone.0277783},
	abstract = {Predictions about others’ future actions are crucial during social interactions, in order to react optimally. Another way to assess such interactions is to define the social context of the situations explicitly and categorize them according to their affective content. Here we investigate how humans assess aggressive, playful and neutral interactions between members of three species: human children, dogs and macaques. We presented human participants with short video clips of real-life interactions of dyads of the three species and asked them either to categorize the context of the situation or to predict the outcome of the observed interaction. Participants performed above chance level in assessing social situations in humans, in dogs and in monkeys. How accurately participants predicted and categorized the situations depended both on the species and on the context. Contrary to our hypothesis, participants were not better at assessing aggressive situations than playful or neutral situations. Importantly, participants performed particularly poorly when assessing aggressive behaviour for dogs. Also, participants were not better at assessing social interactions of humans compared to those of other species. We discuss what mechanism humans use to assess social situations and to what extent this skill can also be found in other social species.},
	language = {en},
	number = {12},
	urldate = {2023-03-04},
	journal = {PLOS ONE},
	author = {Epperlein, Theresa and Kovacs, Gyula and Oña, Linda S. and Amici, Federica and Bräuer, Juliane},
	month = dec,
	year = {2022},
	note = {Publisher: Public Library of Science},
	pages = {e0277783},
}

@article{maldonado_you_2023,
	title = {You say yes, {I} say no: {Investigating} the link between meaning and form in response particles},
	volume = {8},
	issn = {2397-1835},
	shorttitle = {You say yes, {I} say no},
	url = {https://www.glossa-journal.org/article/id/9185/},
	doi = {10.16995/glossa.9185},
	abstract = {Response particles, like English ‘yes’ and ‘no’, are used to respond to polar questions or assertions and are found in all languages. However, the number of particles and the specific meanings they convey vary across languages. For example, in some languages particles mainly convey whether the response itself is positive or negative, while in others they convey whether the response is agreeing or disagreeing with previous discourse. Further, some languages have two response particles, while others have three, or even four. Recent work suggests that how meanings tend to be mapped to forms cross-linguistically might nevertheless be constrained. Roelofsen \&amp; Farkas (2015) suggest that indicating disagreement with a negative question or assertion (e.g., A: ‘Ally doesn’t eat meat.’ B: ‘Yes, he does.’) is more marked than indicating agreement with a positive assertion (e.g., A: ‘Ally eats meat.’ B: ‘Yes, he does’.). This difference in semantic markedness is argued to lead to a difference in form: more marked meanings are mapped to more specialized forms. Here we investigate this hypothesis in a series of behavioral experiments. Across our experiments, we find that participants are indeed sensitive to the differences in meaning that particles can convey. However, not all of the differences implicated by the hierarchy hypothesized in Roelofsen \&amp; Farkas (2015) are supported by our results, and we find evidence highlighting an unexpected special role for Positive Agreement—the least marked meaning.{\textless}br{\textgreater}},
	language = {eng},
	number = {1},
	urldate = {2023-03-04},
	journal = {Glossa: a journal of general linguistics},
	author = {Maldonado, Mora and Culbertson, Jennifer},
	month = mar,
	year = {2023},
	note = {Number: 1
Publisher: Open Library of Humanities},
}

@misc{martineDocumentationEcuadorianSiona2012,
	type = {Archive},
	title = {Documentation of {Ecuadorian} {Siona}},
	url = {https://hdl.handle.net/1839/b1796725-1a49-48ee-93ea-75e5b440c7bc},
	journal = {Endangered Languages Archive},
	author = {Bruil, Martine},
	year = {2012},
}

@article{kosmala_dual_2022,
	title = {The dual status of filled pauses: {Evidence} from genre, proficiency and co-occurrence},
	volume = {65},
	issn = {0023-8309},
	shorttitle = {The dual status of filled pauses},
	url = {https://doi.org/10.1177/00238309211010862},
	doi = {10.1177/00238309211010862},
	abstract = {The present corpus study aims to contribute to the debate regarding the lexical or non-lexical status of filled pauses. Although they are commonly associated with hesitation, disfluency, and production difficulty, it has also been argued that they can serve more fluent communicative functions in discourse (e.g., turn-taking, stance-marking). Our work is grounded in a usage-based and discourse-functional approach to filled pauses, and we address this debate by examining the multiple characteristics of euh and eum in spoken French, as well as their co-occurrence with discourse markers. Combining quantitative and qualitative analyses, we analyze their distribution across different communication settings (prepared monologs vs. spontaneous conversations) and levels of language proficiency (native vs. non-native). Quantitative findings indicate differences in frequency, duration, position, and patterns of co-occurrence across corpora, and our qualitative analyses identify fine-grained differences, mainly two distinct patterns of distribution (initial position clustered with a discourse marker vs. medial position clustered with other hesitation markers), reflecting the different “fluent” and “disfluent” uses of filled pauses. We thus argue for a dual status of euh and eum based on formal, functional, and contextual features.},
	language = {en},
	number = {1},
	urldate = {2022-03-14},
	journal = {Language and Speech},
	author = {Kosmala, Loulou and Crible, Ludivine},
	month = mar,
	year = {2022},
	note = {Publisher: SAGE Publications Ltd},
	pages = {216--239},
}

@phdthesis{kosmala_multimodal_2021,
	type = {Theses},
	title = {A multimodal contrastive study of (dis)fluency across languages and settings: {Towards} a multidimensional scale of inter-(dis)fluency},
	shorttitle = {A multimodal contrastive study of (dis)fluency across languages and settings},
	url = {https://hal.archives-ouvertes.fr/tel-03466135},
	urldate = {2021-12-14},
	school = {Sorbonne Nouvelle},
	author = {Kosmala, Loulou},
	month = dec,
	year = {2021},
}

@inproceedings{kosmala_distribution_2020,
	address = {Bielefeld, Germany},
	title = {On the distribution of clicks and inbreaths in class presentations and spontaneous conversations: blending vocal and kinetic activities},
	shorttitle = {On the distribution of clicks and inbreaths in class presentations and spontaneous conversations},
	url = {https://hal.archives-ouvertes.fr/hal-02964632},
	abstract = {The present exploratory study compares the distribution of clicks and inbreaths in the productions of French students in two different communication settings (semi-read oral class presentations vs spontaneous dyadic conversations). Grounded in a conversation analytic and discourse-pragmatic approach, mixing qualitative and quantitative methods, this study looks at the functions of clicks and inbreaths as well as accompanying kinetic behaviors (e.g swallowing, facial expressions, hand movement) in discourse. Preliminary results show a higher rate of pre-utterances clicks and inbreaths during oral presentations, which reflects the type of talk produced (structured and clear, which requires planning and preparation). And the qualitative analyses illustrate the ways speakers blend vocal and kinetic activities when producing clicks and inbreaths.},
	urldate = {2020-11-06},
	booktitle = {Laughter and {Other} {Non}-{Verbal} {Vocalisations} {Workshop} 2020},
	author = {Kosmala, Loulou},
	month = oct,
	year = {2020},
}

@article{kosmala_disfluencies_2020,
	title = {({Dis})fluencies and their contribution to the co-construction of meaning in native and non-native tandem interactions of {French} and {English}},
	copyright = {La revue TIPA. Travaux interdisciplinaires sur la parole et le langage est mise à disposition selon les termes de la licence Creative Commons Attribution - Pas d'Utilisation Commerciale - Pas de Modification 4.0 International.},
	issn = {1621-0360},
	url = {http://journals.openedition.org/tipa/3567},
	doi = {10.4000/tipa.3567},
	abstract = {In this paper, (dis)fluencies will be examined during tandem interactions in French and English by exploring the notions of secondary didacticity and pedagogical intention outside the classroom environment. While (dis)fluencies have typically been viewed as disturbances and markers of production difficulty, or have only been analyzed from a strictly verbal or vocal point of view, this paper offers a fresh multimodal perspective on these processes by taking into account the visual-gestural features of spoken interactions, mainly manual gestures and eye gaze. Based on the qualitative analyses of two sequences, this paper will illustrate how native and non-native speakers co-construct meaning during the course of their talk by relying on several semiotic resources. Our detailed analyses allow for a richer and deeper understanding of (dis)fluencies as they show the way (dis)fluencies can be negotiated multimodally in context during jointly collaborative activities in tandem settings.},
	language = {en},
	number = {36},
	urldate = {2020-12-12},
	journal = {TIPA. Travaux interdisciplinaires sur la parole et le langage},
	author = {Kosmala, Loulou},
	month = jun,
	year = {2020},
	note = {Number: 36
Publisher: Laboratoire parole et langage},
}

@incollection{ameka_areal_1994,
	address = {Bern},
	title = {Areal conversational routines and cross-cultural communication in a multilingual society},
	booktitle = {Intercultural {Communication}},
	publisher = {Peter Lang},
	author = {Ameka, Felix K.},
	editor = {Pürschel, H.},
	year = {1994},
	pages = {441--469},
}

@article{ameka_meaning_1992,
	title = {The {Meaning} of {Phatic} and {Conative} {Interjections}},
	volume = {18},
	issn = {0378-2166},
	abstract = {An investigation of the meanings of the members of two subclasses of interjections in Ewe, a Kwa language of the Niger-Congo family. The interjections examined are conative/volative - directed at an auditor - \& phatic - used in maintenance of social \& communicative contact. It is argued that the meanings of interjections can be rigorously stated. Differences \& similarities between interjections \& formulaic words are discussed. Interjections are found not to have an illocutionary dictum, whereas formulaic expressions do. By consequence, formulae are speech acts whereas interjections are not. Nevertheless, interjections do have illocutionary meanings. 36 References. Adapted from the source document},
	number = {2-3},
	journal = {Journal of Pragmatics},
	author = {Ameka, Felix K.},
	year = {1992},
	pages = {245--271},
}

@article{ameka_interjections_1992,
	title = {Interjections: {The} {Universal} {Yet} {Neglected} {Part} of {Speech}},
	volume = {18},
	issn = {0378-2166},
	shorttitle = {Interjections},
	abstract = {The history of the study of interjections is briefly reviewed \& an attempt is made to clarify some areas of confusion. A definition \& a classification of interjections are proposed. A distinction is drawn between primary \& secondary interjections \& a somewhat narrowed definition of interjections is advocated. 48 References. B. Annesser Murray},
	number = {2-3},
	journal = {Journal of Pragmatics},
	author = {Ameka, Felix K.},
	year = {1992},
	pages = {101--118},
}

@article{radford_robust_2022,
	title = {Robust {Speech} {Recognition} via {Large}-{Scale} {Weak} {Supervision}},
	abstract = {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results but in a zeroshot transfer setting without the need for any finetuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.},
	language = {en},
	author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
	year = {2022},
	pages = {28},
}

@misc{louradour_whisper-timestamped_2023,
	title = {whisper-timestamped},
	copyright = {AGPL-3.0},
	url = {https://github.com/linto-ai/whisper-timestamped},
	abstract = {Multilingual Automatic Speech Recognition with word-level timestamps and confidence},
	urldate = {2023-03-03},
	publisher = {linto.ai},
	author = {Louradour, Jerome},
	month = mar,
	year = {2023},
	note = {original-date: 2023-01-13T11:30:19Z},
	keywords = {asr, attention-is-all-you-need, attention-mechanism, attention-model, attention-network, attention-seq2seq, attention-visualization, deep-learning, machine-learning, multilingual-models, python, python3, pytorch, speaker-diarization, speech, speech-processing, speech-recognition, speech-to-text, transformers, whisper},
}

@inproceedings{cetin_speaker_2006,
	title = {Speaker {Overlaps} and {ASR} {Errors} in {Meetings}: {Effects} {Before}, {During}, and {After} the {Overlap}},
	volume = {1},
	shorttitle = {Speaker {Overlaps} and {ASR} {Errors} in {Meetings}},
	doi = {10.1109/ICASSP.2006.1660031},
	abstract = {We analyze automatic speech recognition (ASR) errors made by a state-of-the-art meeting recognizer, with respect to locations of overlapping speech. Our analysis focuses on recognition errors made both during an overlap and in the regions immediately preceding and following the location of overlapped speech. We devise an experimental paradigm to allow examination of the same foreground speech both with and without naturally occurring cross-talk. We then analyze ASR errors with respect to a number of factors, including the severity of the cross-talk and distance from the overlap region. In addition to reporting effects on ASR errors, we discover a number of interesting phenomena. First, we find that overlaps tend to occur at high-perplexity regions in the foreground talker's speech. Second, word sequences within overlaps have higher perplexity than those in nonoverlaps, if using trigrams or 4-grams, but the unigram perplexity within overlaps is considerably lower than that of nonoverlaps. An explanation for this behavior is proposed, based on the preponderance of multiple short dialog acts found in overlap regions. Third, we discover that the word error rate (WER) after overlaps is consistently lower than that before the overlap. This finding cannot be explained by the recognition process itself; rather, the foreground speaker appears to reduce perplexity shortly after being overlapped. Taken together, these observations suggest that the automatic modeling of meetings could benefit from a broader view of the relationship between speaker overlap and ASR in natural conversation},
	booktitle = {2006 {IEEE} {International} {Conference} on {Acoustics} {Speech} and {Signal} {Processing} {Proceedings}},
	author = {Çetin, Özgür and Shriberg, Elizabeth},
	month = may,
	year = {2006},
	note = {ISSN: 2379-190X},
	pages = {I--I},
}

@incollection{watanabe_chime_2017,
	address = {Cham},
	title = {The {CHiME} {Challenges}: {Robust} {Speech} {Recognition} in {Everyday} {Environments}},
	isbn = {978-3-319-64679-4 978-3-319-64680-0},
	shorttitle = {The {CHiME} {Challenges}},
	url = {http://link.springer.com/10.1007/978-3-319-64680-0_14},
	language = {en},
	urldate = {2023-03-02},
	booktitle = {New {Era} for {Robust} {Speech} {Recognition}},
	publisher = {Springer International Publishing},
	author = {Barker, Jon P. and Marxer, Ricard and Vincent, Emmanuel and Watanabe, Shinji},
	editor = {Watanabe, Shinji and Delcroix, Marc and Metze, Florian and Hershey, John R.},
	year = {2017},
	doi = {10.1007/978-3-319-64680-0_14},
	pages = {327--344},
}

@article{cherry_experiments_1953,
	title = {Some {Experiments} on the {Recognition} of {Speech}, with {One} and with {Two} {Ears}},
	volume = {25},
	issn = {0001-4966},
	url = {http://asa.scitation.org/doi/10.1121/1.1907229},
	doi = {10.1121/1.1907229},
	language = {en},
	number = {5},
	urldate = {2023-03-02},
	journal = {The Journal of the Acoustical Society of America},
	author = {Cherry, E. Colin},
	month = sep,
	year = {1953},
	pages = {975--979},
}

@misc{ryant_third_2021,
	title = {The {Third} {DIHARD} {Diarization} {Challenge}},
	url = {http://arxiv.org/abs/2012.01477},
	abstract = {DIHARD III was the third in a series of speaker diarization challenges intended to improve the robustness of diarization systems to variability in recording equipment, noise conditions, and conversational domain. Speaker diarization was evaluated under two speech activity conditions (diarization from a reference speech activity vs. diarization from scratch) and 11 diverse domains. The domains span a range of recording conditions and interaction types, including read audio-books, meeting speech, clinical interviews, web videos, and, for the first time, conversational telephone speech. A total of 30 organizations (forming 21teams) from industry and academia submitted 499 valid system outputs. The evaluation results indicate that speaker diarization has improved markedly since DIHARD I, particularly for two-party interactions, but that for many domains (e.g., web video) the problem remains far from solved.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Ryant, Neville and Singh, Prachi and Krishnamohan, Venkat and Varma, Rajat and Church, Kenneth and Cieri, Christopher and Du, Jun and Ganapathy, Sriram and Liberman, Mark},
	month = apr,
	year = {2021},
	note = {arXiv:2012.01477 [cs, eess]},
	keywords = {Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@misc{whetten_evaluating_2023,
	title = {Evaluating {Automatic} {Speech} {Recognition} in an {Incremental} {Setting}},
	url = {http://arxiv.org/abs/2302.12049},
	doi = {10.48550/arXiv.2302.12049},
	abstract = {The increasing reliability of automatic speech recognition has proliferated its everyday use. However, for research purposes, it is often unclear which model one should choose for a task, particularly if there is a requirement for speed as well as accuracy. In this paper, we systematically evaluate six speech recognizers using metrics including word error rate, latency, and the number of updates to already recognized words on English test data, as well as propose and compare two methods for streaming audio into recognizers for incremental recognition. We further propose Revokes per Second as a new metric for evaluating incremental recognition and demonstrate that it provides insights into overall model performance. We find that, generally, local recognizers are faster and require fewer updates than cloud-based recognizers. Finally, we find Meta's Wav2Vec model to be the fastest, and find Mozilla's DeepSpeech model to be the most stable in its predictions.},
	urldate = {2023-03-01},
	publisher = {arXiv},
	author = {Whetten, Ryan and Imtiaz, Mir Tahsin and Kennington, Casey},
	month = feb,
	year = {2023},
	note = {arXiv:2302.12049 [cs, eess]},
}

@inproceedings{jernite_data_2022,
	address = {New York, NY, USA},
	series = {{FAccT} '22},
	title = {Data {Governance} in the {Age} of {Large}-{Scale} {Data}-{Driven} {Language} {Technology}},
	isbn = {978-1-4503-9352-2},
	url = {https://doi.org/10.1145/3531146.3534637},
	doi = {10.1145/3531146.3534637},
	abstract = {The recent emergence and adoption of Machine Learning technology, and specifically of Large Language Models, has drawn attention to the need for systematic and transparent management of language data. This work proposes an approach to global language data governance that attempts to organize data management amongst stakeholders, values, and rights. Our proposal is informed by prior work on distributed governance that accounts for human values and grounded by an international research collaboration that brings together researchers and practitioners from 60 countries. The framework we present is a multi-party international governance structure focused on language data, and incorporating technical and organizational tools needed to support its work.},
	urldate = {2023-03-01},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Jernite, Yacine and Nguyen, Huu and Biderman, Stella and Rogers, Anna and Masoud, Maraim and Danchev, Valentin and Tan, Samson and Luccioni, Alexandra Sasha and Subramani, Nishant and Johnson, Isaac and Dupont, Gerard and Dodge, Jesse and Lo, Kyle and Talat, Zeerak and Radev, Dragomir and Gokaslan, Aaron and Nikpoor, Somaieh and Henderson, Peter and Bommasani, Rishi and Mitchell, Margaret},
	month = jun,
	year = {2022},
	pages = {2206--2222},
}

@inproceedings{laurencon_bigscience_2022,
	title = {The {BigScience} {ROOTS} {Corpus}: {A} 1.{6TB} {Composite} {Multilingual} {Dataset}},
	shorttitle = {The {BigScience} {ROOTS} {Corpus}},
	url = {https://openreview.net/forum?id=UoEw6KigkUn},
	abstract = {As language models grow ever larger, the need for large-scale high-quality text datasets has never been more pressing, especially in multilingual settings. The BigScience workshop, a 1-year international and multidisciplinary initiative, was formed with the goal of researching and training large language models as a values-driven undertaking, putting issues of ethics, harm, and governance in the foreground. This paper documents the data creation and curation efforts undertaken by BigScience to assemble the Responsible Open-science Open-collaboration Text Sources (ROOTS) corpus, a 1.6TB dataset spanning 59 languages that was used to train the 176-billion-parameter BigScience Large Open-science Open-access Multilingual (BLOOM) language model. We further release a large initial subset of the corpus and analyses thereof, and hope to empower large-scale monolingual and multilingual modeling projects with both the data and the processing tools, as well as stimulate research around this large multilingual corpus.},
	language = {en},
	urldate = {2023-03-01},
	author = {Laurençon, Hugo and Saulnier, Lucile and Wang, Thomas and Akiki, Christopher and Moral, Albert Villanova del and Scao, Teven Le and Werra, Leandro Von and Mou, Chenghao and Ponferrada, Eduardo González and Nguyen, Huu and Frohberg, Jörg and Šaško, Mario and Lhoest, Quentin and McMillan-Major, Angelina and Dupont, Gérard and Biderman, Stella and Rogers, Anna and Allal, Loubna Ben and Toni, Francesco De and Pistilli, Giada and Nguyen, Olivier and Nikpoor, Somaieh and Masoud, Maraim and Colombo, Pierre and Rosa, Javier de la and Villegas, Paulo and Thrush, Tristan and Longpre, Shayne and Nagel, Sebastian and Weber, Leon and Muñoz, Manuel Romero and Zhu, Jian and Strien, Daniel Van and Alyafeai, Zaid and Almubarak, Khalid and Chien, Vu Minh and Gonzalez-Dios, Itziar and Soroa, Aitor and Lo, Kyle and Dey, Manan and Suarez, Pedro Ortiz and Gokaslan, Aaron and Bose, Shamik and Adelani, David Ifeoluwa and Phan, Long and Tran, Hieu and Yu, Ian and Pai, Suhas and Chim, Jenny and Lepercq, Violette and Ilic, Suzana and Mitchell, Margaret and Luccioni, Sasha and Jernite, Yacine},
	month = oct,
	year = {2022},
}

@misc{scao_what_2022,
	title = {What {Language} {Model} to {Train} if {You} {Have} {One} {Million} {GPU} {Hours}?},
	url = {http://arxiv.org/abs/2210.15424},
	doi = {10.48550/arXiv.2210.15424},
	abstract = {The crystallization of modeling methods around the Transformer architecture has been a boon for practitioners. Simple, well-motivated architectural variations can transfer across tasks and scale, increasing the impact of modeling research. However, with the emergence of state-of-the-art 100B+ parameters models, large language models are increasingly expensive to accurately design and train. Notably, it can be difficult to evaluate how modeling decisions may impact emergent capabilities, given that these capabilities arise mainly from sheer scale alone. In the process of building BLOOM--the Big Science Large Open-science Open-access Multilingual language model--our goal is to identify an architecture and training setup that makes the best use of our 1,000,000 A100-GPU-hours budget. Specifically, we perform an ablation study at the billion-parameter scale comparing different modeling practices and their impact on zero-shot generalization. In addition, we study the impact of various popular pre-training corpora on zero-shot generalization. We also study the performance of a multilingual model and how it compares to the English-only one. Finally, we consider the scaling behaviour of Transformers to choose the target model size, shape, and training setup. All our models and code are open-sourced at https://huggingface.co/bigscience .},
	urldate = {2023-03-01},
	publisher = {arXiv},
	author = {Scao, Teven Le and Wang, Thomas and Hesslow, Daniel and Saulnier, Lucile and Bekman, Stas and Bari, M. Saiful and Biderman, Stella and Elsahar, Hady and Muennighoff, Niklas and Phang, Jason and Press, Ofir and Raffel, Colin and Sanh, Victor and Shen, Sheng and Sutawika, Lintang and Tae, Jaesung and Yong, Zheng Xin and Launay, Julien and Beltagy, Iz},
	month = nov,
	year = {2022},
	note = {arXiv:2210.15424 [cs]},
}

@article{kortvelyessy_derivational_2023,
	title = {Derivational networks of onomatopoeias in {English} and {Slovak}},
	issn = {0008-4131, 1710-1115},
	url = {https://www.cambridge.org/core/journals/canadian-journal-of-linguistics-revue-canadienne-de-linguistique/article/derivational-networks-of-onomatopoeias-in-english-and-slovak/4A412C60BCF16C4DB3D01B2B42A8340A},
	doi = {10.1017/cnj.2022.42},
	abstract = {This article presents research into derivational properties of onomatopoeias in English and in Slovak. Onomatopoeias are defined narrowly in our approach, being restricted to the direct imitation of sounds of extra-linguistic reality. Our sample of 40 onomatopoeic words consists of two sound types: the sounds of animals and the sounds resulting from various falls, strokes, and bursts. A derivational network was produced for each such word. The evaluation parameters comprise derivational capacity, maximum derivational network, saturation value, number of derivation orders, most productive semantic categories by order of derivation, typical combinations of semantic categories, and derivational processes. An evaluation of the networks enabled us to answer the question of whether onomatopoeias are productive word-formation bases, to compare the two Sound Types, and to compare onomatopoeia-based networks to those based on non-iconic vocabulary. These results contribute to a better understanding of the word-formation systems in the compared languages and of the status of onomatopoeias with regard to non-iconic vocabulary.
, Résumé
L'article présente des recherches sur les propriétés dérivationnelles des onomatopées en anglais et en slovaque. Les onomatopées sont définies étroitement dans notre approche, se limitant à l'imitation directe des sons de la réalité extra-linguistique. Notre échantillon de 40 mots onomatopéiques se compose de deux types de sons : les sons d'animaux, et les sons résultant de chutes, de coups et d'éclats divers. Un réseau dérivationnel a été produit pour chacun de ces mots. Les paramètres d'évaluation comprennent la capacité de dérivation, le réseau de dérivation maximal, la valeur de saturation, le nombre d'ordres de dérivation, les catégories sémantiques les plus productives par ordre de dérivation, les combinaisons typiques de catégories sémantiques et les processus de dérivation. Une évaluation des réseaux nous a permis de répondre à la question de savoir si les onomatopées constituent des bases productives pour la formation de mots, de comparer les deux types de son et de comparer les réseaux basés sur les onomatopées à ceux basés sur le vocabulaire non iconique. Les résultats contribuent ainsi à une meilleure compréhension des systèmes de formation des mots dans les langues comparées, et du statut des onomatopées au regard du vocabulaire non iconique.},
	language = {en},
	urldate = {2023-02-27},
	journal = {Canadian Journal of Linguistics/Revue canadienne de linguistique},
	author = {Körtvélyessy, Lívia and Andrej, Ľubomír},
	month = feb,
	year = {2023},
	note = {Publisher: Cambridge University Press},
	pages = {1--34},
}

@article{yasui_japanese_2023,
	title = {Japanese onomatopoeia in bodily demonstrations in a traditional dance instruction: {A} resource for synchronizing body movements},
	volume = {207},
	issn = {0378-2166},
	shorttitle = {Japanese onomatopoeia in bodily demonstrations in a traditional dance instruction},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216623000310},
	doi = {10.1016/j.pragma.2023.02.002},
	abstract = {Drawing on the multimodal analysis of interaction, this study investigates the coordination between language and body in an instructional setting where students are asked to move their bodies along with the instructor. The data examined comprise a videotaped interaction during a Japanese classical dance (Nihon Buyo) workshop held for international students in which a professional dance instructor introduced the dance to the students by having them perform a few simple choreographies. The data showed that the instructor often employed onomatopoeias (mimetics or ideophones) during her demonstrations. The study investigated how onomatopoeias are employed in coordination with bodily demonstration and what they accomplish in the instruction. The analysis revealed that the instructor coordinated her body movements with onomatopoeias using sound stretch, pitch and volume change, and voice quality. Onomatopoeias with such modulated prosody along with bodily demonstration highlight the features of the body movements in the choreography. Additionally, onomatopoeias act as resources for synchronized movements among participants in a physical activity through their prolongation and repetition. This suggests an interactional function of onomatopoeias that has not been discussed previously in the relevant literature.},
	language = {en},
	urldate = {2023-02-23},
	journal = {Journal of Pragmatics},
	author = {Yasui, Eiko},
	month = apr,
	year = {2023},
	pages = {45--61},
}

@inproceedings{faria_toward_2022,
	title = {Toward {Zero} {Oracle} {Word} {Error} {Rate} on the {Switchboard} {Benchmark}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/faria22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10959},
	abstract = {The “Switchboard benchmark” is a very well-known test set in automatic speech recognition (ASR) research, establishing record-setting performance for systems that claim human-level transcription accuracy. This work highlights lesser-known practical considerations of this evaluation, demonstrating major improvements in word error rate (WER) by correcting the reference transcriptions and deviating from the official scoring methodology. In this more detailed and reproducible scheme, even commercial ASR systems can score below 5\% WER and the established record for a research system is lowered to 2.3\%. An alternative metric of transcript precision is proposed, which does not penalize deletions and appears to be more discriminating for human vs. machine performance. While commercial ASR systems are still below this threshold, a research system is shown to clearly surpass the accuracy of commercial human speech recognition. This work also explores using standardized scoring tools to compute oracle WER by selecting the best among a list of alternatives. A phrase alternatives representation is compared to utterance-level N-best lists and word-level data structures; using dense lattices and adding out-of-vocabulary words, this achieves an oracle WER of 0.18\%.},
	language = {en},
	urldate = {2023-02-23},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Faria, Arlo and Janin, Adam and Adkoli, Sidhi and Riedhammer, Korbinian},
	month = sep,
	year = {2022},
	pages = {3973--3977},
}

@inproceedings{kanda_joint_2020,
	title = {Joint {Speaker} {Counting}, {Speech} {Recognition}, and {Speaker} {Identification} for {Overlapped} {Speech} of any {Number} of {Speakers}},
	url = {https://www.isca-speech.org/archive/interspeech_2020/kanda20_interspeech.html},
	doi = {10.21437/Interspeech.2020-1085},
	language = {en},
	urldate = {2023-02-23},
	booktitle = {Interspeech 2020},
	publisher = {ISCA},
	author = {Kanda, Naoyuki and Gaur, Yashesh and Wang, Xiaofei and Meng, Zhong and Chen, Zhuo and Zhou, Tianyan and Yoshioka, Takuya},
	month = oct,
	year = {2020},
	pages = {36--40},
}

@article{park_review_2022,
	title = {A review of speaker diarization: {Recent} advances with deep learning},
	volume = {72},
	issn = {0885-2308},
	shorttitle = {A review of speaker diarization},
	url = {https://www.sciencedirect.com/science/article/pii/S0885230821001121},
	doi = {10.1016/j.csl.2021.101317},
	abstract = {Speaker diarization is a task to label audio or video recordings with classes that correspond to speaker identity, or in short, a task to identify “who spoke when”. In the early years, speaker diarization algorithms were developed for speech recognition on multispeaker audio recordings to enable speaker adaptive processing. These algorithms also gained their own value as a standalone application over time to provide speaker-specific metainformation for downstream tasks such as audio retrieval. More recently, with the emergence of deep learning technology, which has driven revolutionary changes in research and practices across speech application domains, rapid advancements have been made for speaker diarization. In this paper, we review not only the historical development of speaker diarization technology but also the recent advancements in neural speaker diarization approaches. Furthermore, we discuss how speaker diarization systems have been integrated with speech recognition applications and how the recent surge of deep learning is leading the way of jointly modeling these two components to be complementary to each other. By considering such exciting technical trends, we believe that this paper is a valuable contribution to the community to provide a survey work by consolidating the recent developments with neural methods and thus facilitating further progress toward a more efficient speaker diarization.},
	language = {en},
	urldate = {2023-02-23},
	journal = {Computer Speech \& Language},
	author = {Park, Tae Jin and Kanda, Naoyuki and Dimitriadis, Dimitrios and Han, Kyu J. and Watanabe, Shinji and Narayanan, Shrikanth},
	month = mar,
	year = {2022},
	pages = {101317},
}

@article{tucker_why_2016,
	title = {Why we need to investigate casual speech to truly understand language production, processing and the mental lexicon},
	volume = {11},
	issn = {1871-1340, 1871-1375},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ml.11.3.03tuc},
	doi = {10.1075/ml.11.3.03tuc},
	abstract = {The majority of studies addressing psycholinguistic questions focus on speech produced and processed in a careful, laboratory speech style. This ‘careful’ speech is very different from the speech that listeners encounter in casual conversations. This article argues that research on casual speech is necessary to show the validity of conclusions based on careful speech. Moreover, research on casual speech produces new insights and questions on the processes underlying communication and on the mental lexicon that cannot be revealed by research using careful speech. This article first places research on casual speech in its historic perspective. It then provides many examples of how casual speech differs from careful speech and shows that these differences may have important implications for psycholinguistic theories. Subsequently, the article discusses the challenges that research on casual speech faces, which stem from the high variability of this speech style, its necessary casual context, and that casual speech is connected speech. We also present opportunities for research on casual speech, mostly in the form of new experimental methods that facilitate research on connected speech. However, real progress can only be made if these new methods are combined with advanced (still to be developed) statistical techniques.},
	language = {en},
	number = {3},
	urldate = {2023-02-23},
	journal = {The Mental Lexicon},
	author = {Tucker, Benjamin V. and Ernestus, Mirjam},
	month = jan,
	year = {2016},
	note = {Publisher: John Benjamins},
	pages = {375--400},
}

@inproceedings{yella_improved_2013,
	title = {Improved overlap speech diarization of meeting recordings using long-term conversational features},
	doi = {10.1109/ICASSP.2013.6639171},
	abstract = {Overlapping speech is a source of significant errors in speaker diarization of spontaneous meeting recordings. Recent works on speaker diarization have attempted to solve the problem of overlap detection using classifiers trained on acoustic and spatial features. This paper proposes a method to improve the short-term spectral feature based overlap detector by incorporating information from long-term conversational features in the form of speaker change statistics. The statistics are obtained at segment level(around few seconds) from the output of a diarization system. The approach is motivated by the observation that segments containing more speaker changes are more probable to have more overlaps. Experiments on AMI meeting corpus reveal that the number of overlaps in a segment follows a Poisson distribution whose rate is directly proportional to the number of speaker changes in the segment. When this information is combined with acoustic information in an HMM/GMM overlap detector, improvements are verified in terms of F-measure and consequently, diarization error (DER) is reduced by 5\% relative to the baseline overlap detector.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Yella, Sree Harsha and Bourlard, Hervé},
	month = may,
	year = {2013},
	note = {ISSN: 2379-190X},
	pages = {7746--7750},
}

@inproceedings{oviatt_spoken_2015,
	address = {New York, NY, USA},
	series = {{ICMI} '15},
	title = {Spoken {Interruptions} {Signal} {Productive} {Problem} {Solving} and {Domain} {Expertise} in {Mathematics}},
	isbn = {978-1-4503-3912-4},
	url = {https://doi.org/10.1145/2818346.2820743},
	doi = {10.1145/2818346.2820743},
	abstract = {Prevailing social norms prohibit interrupting another person when they are speaking. In this research, simultaneous speech was investigated in groups of students as they jointly solved math problems and peer tutored one another. Analyses were based on the Math Data Corpus, which includes ground-truth performance coding and speech transcriptions. Simultaneous speech was elevated 120-143\% during the most productive phase of problem solving, compared with matched intervals. It also was elevated 18-37\% in students who were domain experts, compared with non-experts. Qualitative analyses revealed that experts differed from non-experts in the function of their interruptions. Analysis of these functional asymmetries produced nine key behaviors that were used to identify the dominant math expert in a group with 95-100\% accuracy in three minutes. This research demonstrates that overlapped speech is a marker of group problem-solving progress and domain expertise. It provides valuable information for the emerging field of learning analytics.},
	urldate = {2023-02-23},
	booktitle = {Proceedings of the 2015 {ACM} on {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Oviatt, Sharon and Hang, Kevin and Zhou, Jianlong and Chen, Fang},
	month = nov,
	year = {2015},
	pages = {311--318},
}

@article{yella_overlapping_2014,
	title = {Overlapping {Speech} {Detection} {Using} {Long}-{Term} {Conversational} {Features} for {Speaker} {Diarization} in {Meeting} {Room} {Conversations}},
	volume = {22},
	issn = {2329-9304},
	doi = {10.1109/TASLP.2014.2346315},
	abstract = {Overlapping speech has been identified as one of the main sources of errors in diarization of meeting room conversations. Therefore, overlap detection has become an important step prior to speaker diarization. Studies on conversational analysis have shown that overlapping speech is more likely to occur at specific parts of a conversation. They have also shown that overlap occurrence is correlated with various conversational features such as speech, silence patterns and speaker turn changes. We use features capturing this higher level information from structure of a conversation such as silence and speaker change statistics to improve acoustic feature based classifier of overlapping and single-speaker speech classes. The silence and speaker change statistics are computed over a long-term window (around 3-4 seconds) and are used to predict the probability of overlap in the window. These estimates are then incorporated into a acoustic feature based classifier as prior probabilities of the classes. Experiments conducted on three corpora (AMI, NIST-RT and ICSI) have shown that the proposed method improves the performance of acoustic feature-based overlap detector on all the corpora. They also reveal that the model based on long-term conversational features used to estimate probability of overlap which is learned from AMI corpus generalizes to meetings from other corpora (NIST-RT and ICSI). Moreover, experiments on ICSI corpus reveal that the proposed method also improves laughter overlap detection. Consequently, applying overlap handling techniques to speaker diarization using the detected overlap results in reduction of diarization error rate (DER) on all the three corpora.},
	number = {12},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Yella, Sree Harsha and Bourlard, Hervé},
	month = dec,
	year = {2014},
	note = {Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	pages = {1688--1700},
}

@article{kurtic_resources_2013,
	title = {Resources for turn competition in overlapping talk},
	volume = {55},
	issn = {0167-6393},
	url = {https://www.sciencedirect.com/science/article/pii/S0167639312001264},
	doi = {10.1016/j.specom.2012.10.002},
	abstract = {Overlapping talk occurs frequently in multi-party conversations, and is a domain in which speakers may pursue various communicative goals. The current study focuses on turn competition. Specifically, we seek to identify the phonetic differences that discriminate turn-competitive from non-competitive overlaps. Conversation analysis techniques were used to identify competitive and non-competitive overlaps in a corpus of multi-party recordings. We then generated a set of potentially predictive features relating to prosody (F0, intensity, speech rate, pausing) and overlap placement (overlap duration, point of overlap onset, recycling etc.). Decision tree classifiers were trained on the features and tested on a classification task, in order to determine which features and feature combinations best differentiate competitive overlaps from non-competitive overlaps. It was found that overlap placement features played a greater role than prosodic features in indicating turn competition. Among the prosodic features tested, F0 and intensity were the most effective predictors of turn competition. Also, our decision tree models suggest that turn competitive and non-competitive overlaps can be initiated by a new speaker at many different points in the current speaker’s turn. These findings have implications for the design of dialogue systems, and suggest novel hypotheses about how speakers deploy phonetic resources in everyday talk.},
	language = {en},
	number = {5},
	urldate = {2023-02-23},
	journal = {Speech Communication},
	author = {Kurtić, Emina and Brown, Guy J. and Wells, Bill},
	month = jun,
	year = {2013},
	pages = {721--743},
}

@inproceedings{fujita_end--end_2019,
	title = {End-to-{End} {Neural} {Speaker} {Diarization} with {Self}-{Attention}},
	doi = {10.1109/ASRU46091.2019.9003959},
	abstract = {Speaker diarization has been mainly developed based on the clustering of speaker embeddings. However, the clustering-based approach has two major problems; i.e., (i) it is not optimized to minimize diarization errors directly, and (ii) it cannot handle speaker overlaps correctly. To solve these problems, the End-to-End Neural Diarization (EEND), in which a bidirectional long short-term memory (BLSTM) network directly outputs speaker diarization results given a multi-talker recording, was recently proposed. In this study, we enhance EEND by introducing self-attention blocks instead of BLSTM blocks. In contrast to BLSTM, which is conditioned only on its previous and next hidden states, self-attention is directly conditioned on all the other frames, making it much suitable for dealing with the speaker diarization problem. We evaluated our proposed method on simulated mixtures, real telephone calls, and real dialogue recordings. The experimental results revealed that the self-attention was the key to achieving good performance and that our proposed method performed significantly better than the conventional BLSTM-based method. Our method was even better than that of the state-of-the-art x-vector clustering-based method. Finally, by visualizing the latent representation, we show that the self-attention can capture global speaker characteristics in addition to local speech activity dynamics. Our source code is available online at https://github.com/hitachi-speech/EEND.},
	booktitle = {2019 {IEEE} {Automatic} {Speech} {Recognition} and {Understanding} {Workshop} ({ASRU})},
	author = {Fujita, Yusuke and Kanda, Naoyuki and Horiguchi, Shota and Xue, Yawen and Nagamatsu, Kenji and Watanabe, Shinji},
	month = dec,
	year = {2019},
	pages = {296--303},
}

@inproceedings{cetin_overlap_2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Overlap in {Meetings}: {ASR} {Effects} and {Analysis} by {Dialog} {Factors}, {Speakers}, and {Collection} {Site}},
	isbn = {978-3-540-69268-3},
	shorttitle = {Overlap in {Meetings}},
	doi = {10.1007/11965152_19},
	abstract = {We analyze speaker overlap in multiparty meetings both in terms of automatic speech recognition (ASR) performance, and in terms of distribution of overlap with respect to various factors (collection site, speakers, dialog acts, and hot spots). Unlike most previous work on overlap or crosstalk, our ASR error analysis uses an approach that allows comparison of the same foreground speech with and without naturally occurring overlap, using a state-of-the-art meeting recognition system. We examine a total of 101 meetings. For analysis of ASR, we use 26 meetings from the NIST meeting transcription evaluations, and discover a number of interesting phenomena. First, overlaps tend to occur at high-perplexity regions in the foreground talker’s speech. Second, overlap regions tend to have higher perplexity than those in nonoverlaps, if trigrams or 4-grams are used, but unigram perplexity within overlaps is considerably lower than that of nonoverlaps. Third, word error rate (WER) after overlaps is consistently lower than that before the overlap, apparently because the foreground speaker reduces perplexity shortly after being overlapped. These appear to be robust findings, because they hold in general across meetings from different collection sites, even though meeting style and absolute rates of overlap vary by site. Further analyses of overlap with respect to speakers and meeting content were conducted on a set of 75 additional meetings collected and annotated at ICSI. These analyses reveal interesting relationships between overlap and dialog acts, as well as between overlap and “hot spots” (points of increased participant involvement). Finally, results from this larger data set show that individual speakers have widely varying rates of being overlapped.},
	language = {en},
	booktitle = {Machine {Learning} for {Multimodal} {Interaction}},
	publisher = {Springer},
	author = {Çetin, Özgür and Shriberg, Elizabeth},
	editor = {Renals, Steve and Bengio, Samy and Fiscus, Jonathan G.},
	year = {2006},
	pages = {212--224},
}

@inproceedings{galibert_methodologies_2013,
	title = {Methodologies for the evaluation of speaker diarization and automatic speech recognition in the presence of overlapping speech},
	url = {https://www.isca-speech.org/archive/interspeech_2013/galibert13_interspeech.html},
	doi = {10.21437/Interspeech.2013-303},
	language = {en},
	urldate = {2023-02-23},
	booktitle = {Interspeech 2013},
	publisher = {ISCA},
	author = {Galibert, Olivier},
	month = aug,
	year = {2013},
	pages = {1131--1134},
}

@inproceedings{boakye_twos_2008,
	title = {Two's a crowd: improving speaker diarization by automatically identifying and excluding overlapped speech},
	shorttitle = {Two's a crowd},
	url = {https://www.isca-speech.org/archive/interspeech_2008/boakye08_interspeech.html},
	doi = {10.21437/Interspeech.2008-6},
	abstract = {We present an update to our initial work [1] on overlapped speech detection for improving speaker diarization. Speciﬁcally, we describe the addition of new features and feature warping techniques that improve segmenter and, consequently, diarization performance. We also demonstrate improved diarization performance by additionally using overlap segment information in a new diarization pre-processing step which excludes overlap segments from speaker clustering. On a subset of the AMI Meeting Corpus we show that this overlap exclusion step nearly triples the relative improvement of diarization error rate as compared to overlap segment post-processing alone.},
	language = {en},
	urldate = {2023-02-23},
	booktitle = {Interspeech 2008},
	publisher = {ISCA},
	author = {Boakye, Kofi and Vinyals, Oriol and Friedland, Gerald},
	month = sep,
	year = {2008},
	pages = {32--35},
}

@inproceedings{sell_diarization_2018,
	title = {Diarization is {Hard}: {Some} {Experiences} and {Lessons} {Learned} for the {JHU} {Team} in the {Inaugural} {DIHARD} {Challenge}},
	shorttitle = {Diarization is {Hard}},
	url = {https://www.isca-speech.org/archive/interspeech_2018/sell18_interspeech.html},
	doi = {10.21437/Interspeech.2018-1893},
	language = {en},
	urldate = {2023-02-23},
	booktitle = {Interspeech 2018},
	publisher = {ISCA},
	author = {Sell, Gregory and Snyder, David and McCree, Alan and Garcia-Romero, Daniel and Villalba, Jesús and Maciejewski, Matthew and Manohar, Vimal and Dehak, Najim and Povey, Daniel and Watanabe, Shinji and Khudanpur, Sanjeev},
	month = sep,
	year = {2018},
	pages = {2808--2812},
}

@inproceedings{boakye_overlapped_2008,
	title = {Overlapped speech detection for improved speaker diarization in multiparty meetings},
	doi = {10.1109/ICASSP.2008.4518619},
	abstract = {State-of-the-art speaker diarization systems for meetings are now at a point where overlapped speech contributes significantly to the errors made by the system. However, little if no work has yet been done on detecting overlapped speech. We present our initial work toward developing an overlap detection system for improved meeting diarization. We investigate various features, with a focus on high-precision performance for use in the detector, and examine performance results on a subset of the AMI Meeting Corpus. For the high-quality signal case of a single mixed-headset channel signal, we demonstrate a relative improvement of about 7.4\% DER over the baseline diarization system, while for the more challenging case of the single far-field channel signal relative improvement is 3.6\%. We also outline steps towards improvement and moving beyond this initial phase.},
	booktitle = {2008 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Boakye, Kofi and Trueba-Hornero, Beatriz and Vinyals, Oriol and Friedland, Gerald},
	month = mar,
	year = {2008},
	note = {ISSN: 2379-190X},
	pages = {4353--4356},
}

@article{khoma_development_2023,
	title = {Development of {Supervised} {Speaker} {Diarization} {System} {Based} on the {PyAnnote} {Audio} {Processing} {Library}},
	volume = {23},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/4/2082},
	doi = {10.3390/s23042082},
	abstract = {Diarization is an important task when work with audiodata is executed, as it provides a solution to the problem related to the need of dividing one analyzed call recording into several speech recordings, each of which belongs to one speaker. Diarization systems segment audio recordings by defining the time boundaries of utterances, and typically use unsupervised methods to group utterances belonging to individual speakers, but do not answer the question “who is speaking?” On the other hand, there are biometric systems that identify individuals on the basis of their voices, but such systems are designed with the prerequisite that only one speaker is present in the analyzed audio recording. However, some applications involve the need to identify multiple speakers that interact freely in an audio recording. This paper proposes two architectures of speaker identification systems based on a combination of diarization and identification methods, which operate on the basis of segment-level or group-level classification. The open-source PyAnnote framework was used to develop the system. The performance of the speaker identification system was verified through the application of the AMI Corpus open-source audio database, which contains 100 h of annotated and transcribed audio and video data. The research method consisted of four experiments to select the best-performing supervised diarization algorithms on the basis of PyAnnote. The first experiment was designed to investigate how the selection of the distance function between vector embedding affects the reliability of identification of a speaker’s utterance in a segment-level classification architecture. The second experiment examines the architecture of cluster-centroid (group-level) classification, i.e., the selection of the best clustering and classification methods. The third experiment investigates the impact of different segmentation algorithms on the accuracy of identifying speaker utterances, and the fourth examines embedding window sizes. Experimental results demonstrated that the group-level approach offered better identification results were compared to the segment-level approach, and the latter had the advantage of real-time processing.},
	language = {en},
	number = {4},
	urldate = {2023-02-23},
	journal = {Sensors},
	author = {Khoma, Volodymyr and Khoma, Yuriy and Brydinskyi, Vitalii and Konovalov, Alexander},
	month = jan,
	year = {2023},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {2082},
}

@inproceedings{bredin_pyannotemetrics_2017,
	title = {pyannote.metrics: {A} {Toolkit} for {Reproducible} {Evaluation}, {Diagnostic}, and {Error} {Analysis} of {Speaker} {Diarization} {Systems}},
	shorttitle = {pyannote.metrics},
	url = {https://www.isca-speech.org/archive/interspeech_2017/bredin17_interspeech.html},
	doi = {10.21437/Interspeech.2017-411},
	language = {en},
	urldate = {2023-02-23},
	booktitle = {Interspeech 2017},
	publisher = {ISCA},
	author = {Bredin, Hervé},
	month = aug,
	year = {2017},
	pages = {3587--3591},
}

@article{favre_automatic_2013,
	title = {Automatic {Human} {Utility} {Evaluation} of {ASR} {Systems}: {Does} {WER} {Really} {Predict} {Performance}?},
	shorttitle = {Automatic {Human} {Utility} {Evaluation} of {ASR} {Systems}},
	abstract = {We propose an alternative evaluation metric to Word Error Rate (WER) for the decision audit task of meeting recordings, which exemplifies how to evaluate speech recognition within a legitimate application context. Using machine learning on an initial seed of human-subject experimental data, our alternative metric handily outperforms WER, which correlates very poorly with human subjects' success in finding decisions given ASR transcripts with a range of WERs.},
	author = {Favre, Benoit and Cheung, Kyla and Kazemian, Siavash and Lee, Adam and Liu, Yang and Munteanu, Cosmin and Nenkova, Ani and Ochei, Dennis and Penn, Gerald and Tratz, Stephen and Voss, Clare and Zeller, Frauke},
	month = jan,
	year = {2013},
}

@inproceedings{manohar_acoustic_2019,
	title = {Acoustic {Modeling} for {Overlapping} {Speech} {Recognition}: {Jhu} {Chime}-5 {Challenge} {System}},
	shorttitle = {Acoustic {Modeling} for {Overlapping} {Speech} {Recognition}},
	doi = {10.1109/ICASSP.2019.8682556},
	abstract = {This paper summarizes our acoustic modeling efforts in the Johns Hopkins University speech recognition system for the CHiME-5 challenge to recognize highly-overlapped dinner party speech recorded by multiple microphone arrays. We explore data augmentation approaches, neural network architectures, front-end speech dereverberation, beamforming and robust i-vector extraction with comparisons of our in-house implementations and publicly available tools. We finally achieved a word error rate of 69.4\% on the development set, which is a 11.7\% absolute improvement over the previous baseline of 81.1\%, and release this improved baseline with refined techniques/tools as an advanced CHiME-5 recipe.},
	booktitle = {{ICASSP} 2019 - 2019 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Manohar, Vimal and Chen, Szu-Jui and Wang, Zhiqi and Fujita, Yusuke and Watanabe, Shinji and Khudanpur, Sanjeev},
	month = may,
	year = {2019},
	note = {ISSN: 2379-190X},
	pages = {6665--6669},
}

@article{hill_real_2015,
	title = {Real conversations with artificial intelligence: {A} comparison between human–human online conversations and human–chatbot conversations},
	volume = {49},
	issn = {0747-5632},
	shorttitle = {Real conversations with artificial intelligence},
	url = {https://www.sciencedirect.com/science/article/pii/S0747563215001247},
	doi = {10.1016/j.chb.2015.02.026},
	abstract = {This study analyzed how communication changes when people communicate with an intelligent agent as opposed to with another human. We compared 100 instant messaging conversations to 100 exchanges with the popular chatbot Cleverbot along seven dimensions: words per message, words per conversation, messages per conversation, word uniqueness, and use of profanity, shorthand, and emoticons. A MANOVA indicated that people communicated with the chatbot for longer durations (but with shorter messages) than they did with another human. Additionally, human–chatbot communication lacked much of the richness of vocabulary found in conversations among people, and exhibited greater profanity. These results suggest that while human language skills transfer easily to human–chatbot communication, there are notable differences in the content and quality of such conversations.},
	language = {en},
	urldate = {2023-02-21},
	journal = {Computers in Human Behavior},
	author = {Hill, Jennifer and Randolph Ford, W. and Farreras, Ingrid G.},
	month = aug,
	year = {2015},
	pages = {245--250},
}

@inproceedings{szymanski_wer_2020,
	address = {Online},
	title = {{WER} we are and {WER} we think we are},
	url = {https://aclanthology.org/2020.findings-emnlp.295},
	doi = {10.18653/v1/2020.findings-emnlp.295},
	abstract = {Natural language processing of conversational speech requires the availability of high-quality transcripts. In this paper, we express our skepticism towards the recent reports of very low Word Error Rates (WERs) achieved by modern Automatic Speech Recognition (ASR) systems on benchmark datasets. We outline several problems with popular benchmarks and compare three state-of-the-art commercial ASR systems on an internal dataset of real-life spontaneous human conversations and HUB'05 public benchmark. We show that WERs are significantly higher than the best reported results. We formulate a set of guidelines which may aid in the creation of real-life, multi-domain datasets with high quality annotations for training and testing of robust ASR systems.},
	urldate = {2023-02-21},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2020},
	publisher = {Association for Computational Linguistics},
	author = {Szymański, Piotr and Żelasko, Piotr and Morzy, Mikolaj and Szymczak, Adrian and Ży{\textbackslash}la-Hoppe, Marzena and Banaszczak, Joanna and Augustyniak, Lukasz and Mizgajski, Jan and Carmiel, Yishay},
	month = nov,
	year = {2020},
	pages = {3290--3295},
}

@inproceedings{shriberg_observations_2001,
	title = {Observations on overlap: findings and implications for automatic processing of multi-party conversation},
	shorttitle = {Observations on overlap},
	url = {https://www.isca-speech.org/archive/eurospeech_2001/shriberg01_eurospeech.html},
	doi = {10.21437/Eurospeech.2001-352},
	abstract = {We examine the distribution of overlapping speech in different corpora of natural multi-party conversations, including two types of meetings, and two corpora of telephone conversations. Analyses are based on forced alignment and speech recognition using an identical recognizer across tasks. Three results are discussed. First, all corpora show high overall rates of overlap, with similar rates for meetings and telephone conversations. Second, speech recognition performance in non-overlapped regions of meetings is no worse than that in single-channel telephone conversations, while recognition in overlap regions degrades considerably. Finally, interrupt locations are associated with endpoints of word-level events in a speaker’s turn, including backchannels, discourse markers, and disﬂuencies. Results suggest that overlap is an important inherent characteristic of conversational speech that should not be ignored; on the contrary, it should be jointly modeled with acoustic and language model information in machine processing of conversation.},
	language = {en},
	urldate = {2023-02-21},
	booktitle = {7th {European} {Conference} on {Speech} {Communication} and {Technology} ({Eurospeech} 2001)},
	publisher = {ISCA},
	author = {Shriberg, Elizabeth and Stolcke, Andreas and Baron, Don},
	month = sep,
	year = {2001},
	pages = {1359--1362},
}

@inproceedings{shriberg_spontaneous_2005,
	title = {Spontaneous speech: how people really talk and why engineers should care},
	shorttitle = {Spontaneous speech},
	url = {https://www.isca-speech.org/archive/interspeech_2005/shriberg05_interspeech.html},
	doi = {10.21437/Interspeech.2005-3},
	language = {en},
	urldate = {2023-02-21},
	booktitle = {Interspeech 2005},
	publisher = {ISCA},
	author = {Shriberg, Elizabeth},
	month = sep,
	year = {2005},
	pages = {1781--1784},
}

@article{shriberg_errrr_2001,
	title = {To ‘errrr’ is human: ecology and acoustics of speech disfluencies},
	volume = {31},
	shorttitle = {To ‘errrr’is human},
	url = {http://journals.cambridge.org/abstract_S0025100301001128},
	number = {01},
	urldate = {2014-12-22},
	journal = {Journal of the International Phonetic Association},
	author = {Shriberg, Elizabeth},
	year = {2001},
	pages = {153--169},
}

@article{shriberg_can_1998,
	title = {Can {Prosody} {Aid} the {Automatic} {Classification} of {Dialog} {Acts} in {Conversational} {Speech}?},
	volume = {41},
	issn = {0023-8309, 1756-6053},
	url = {http://las.sagepub.com/content/41/3-4/443},
	doi = {10.1177/002383099804100410},
	abstract = {Identifying whether an utterance is a statement, question, greeting, and so forth is integral to effective automatic understanding of natural dialog. Little is known, however, about how such dialog acts (DAs) can be automatically classified in truly natural conversation. This study asks whether current approaches, which use mainly word information, could be improved by adding prosodic information.
The study is based on more than 1000 conversations from the Switchboard corpus. DAs were hand-annotated, and prosodic features (duration, pause, F0, energy, and speaking rate) were automatically extracted for each DA. In training, decision trees based on these features were inferred; trees were then applied to unseen test data to evaluate performance. Performance was evaluated for prosody models alone, and after combining the prosody models with word information—either from true words or from the output of an automatic speech recognizer.
For an overall classification task, as well as three subtasks, prosody made significant contributions to classification. Feature-specific analyses further revealed that although canonical features (such as F0 for questions) were important, less obvious features could compensate if canonical features were removed. Finally, in each task, integrating the prosodic model with a DA-specific statistical language model improved performance over that of the language model alone, especially for the case of recognized words. Results suggest that DAs are redundantly marked in natural conversation, and that a variety of automatically extractable prosodic features could aid dialog processing in speech applications.},
	language = {en},
	number = {3-4},
	urldate = {2015-07-14},
	journal = {Language and Speech},
	author = {Shriberg, Elizabeth and Stolcke, Andreas and Jurafsky, Daniel and Coccaro, Noah and Meteer, Marie and Bates, Rebecca and Taylor, Paul and Ries, Klaus and Martin, Rachel and Ess-Dykema, Carol van},
	month = jul,
	year = {1998},
	pages = {443--492},
}

@inproceedings{davison_things_2017,
	title = {Things that {Make} {Robots} {Go} {HMMM} : {Heterogeneous} {Multilevel} {Multimodal} {Mixing} to {Realise} {Fluent}, {Multiparty}, {Human}-{Robot} {Interaction}},
	shorttitle = {Things that {Make} {Robots} {Go} {HMMM}},
	url = {https://research.utwente.nl/en/publications/things-that-make-robots-go-hmmm-heterogeneous-multilevel-multimod},
	language = {English},
	urldate = {2023-02-20},
	booktitle = {Proceedings of {eNTERFACE} '16},
	publisher = {Telematica Instituut / CTIT},
	author = {Davison, Daniel and Gorer, Binnur and Kolkmeier, Jan and Linssen, Johannes Maria and Schadenberg, Bob R. and Vijver, Bob van de and Campbell, Nick and Dertien, Edwin and Reidsma, Dennis},
	year = {2017},
	pages = {6--20},
}

@inproceedings{poppe_backchannel_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Backchannel {Strategies} for {Artificial} {Listeners}},
	isbn = {978-3-642-15892-6},
	doi = {10.1007/978-3-642-15892-6_16},
	abstract = {We evaluate multimodal rule-based strategies for backchannel (BC) generation in face-to-face conversations. Such strategies can be used by artificial listeners to determine when to produce a BC in dialogs with human speakers. In this research, we consider features from the speaker’s speech and gaze. We used six rule-based strategies to determine the placement of BCs. The BCs were performed by an intelligent virtual agent using nods and vocalizations. In a user perception experiment, participants were shown video fragments of a human speaker together with an artificial listener who produced BC behavior according to one of the strategies. Participants were asked to rate how likely they thought the BC behavior had been performed by a human listener. We found that the number, timing and type of BC had a significant effect on how human-like the BC behavior was perceived.},
	language = {en},
	booktitle = {Intelligent {Virtual} {Agents}},
	publisher = {Springer},
	author = {Poppe, Ronald and Truong, Khiet P. and Reidsma, Dennis and Heylen, Dirk},
	editor = {Allbeck, Jan and Badler, Norman and Bickmore, Timothy and Pelachaud, Catherine and Safonova, Alla},
	year = {2010},
	pages = {146--158},
}

@article{belz_defining_2023,
	title = {Defining {Filler} {Particles}: {A} {Phonetic} {Account} of the {Terminology}, {Form}, and {Grammatical} {Classification} of “{Filled} {Pauses}”},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2226-471X},
	shorttitle = {Defining {Filler} {Particles}},
	url = {https://www.mdpi.com/2226-471X/8/1/57},
	doi = {10.3390/languages8010057},
	abstract = {The terms hesitation, planner, filler, and filled pause do not always refer to the same phonetic entities. This terminological conundrum is approached by investigating the observational, explanatory, and descriptive inadequacies of the terms in use. Concomitantly, the term filler particle is motivated and a definition is proposed that identifies its phonetic exponents and describes them within the linguistic category of particles. The definition of filler particles proposed here is grounded both theoretically and empirically and then applied to a corpus of spontaneous dialogues with 32 speakers of German, showing that in addition to the prototypical phonetic forms, there is a substantial amount of non-prototypical forms, i.e., 9.5\%, comprising both glottal (e.g., [Ɂ]) and vocal forms (e.g., [ɛɸ], [j{\textasciitilde}ɛvə]). The grammatical classification and the results regarding the phonetic forms are discussed with respect to their theoretical relevance in filler particle research and corpus studies. The phonetic approach taken here further suggests a continuum of phonetic forms of filler particles, ranging from singleton segments to multi-syllabic entities.},
	language = {en},
	number = {1},
	urldate = {2023-02-17},
	journal = {Languages},
	author = {Belz, Malte},
	month = mar,
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {57},
}

@phdthesis{zhang_towards_2021,
	address = {United States -- New York},
	type = {Ph.{D}.},
	title = {Towards {Actionable} {Understandings} of {Conversations}: {A} {Computational} {Approach}},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	shorttitle = {Towards {Actionable} {Understandings} of {Conversations}},
	url = {https://www.proquest.com/docview/2581254110/abstract/2D3A0A2A193D4DA9PQ/1},
	abstract = {Conversations are central to many consequential settings. Understanding how conversationalists navigate through them could unlock great improvements in domains like mental health, where the provision of social support is crucial. Such domains also present a promising opportunity for research: many interactions are recorded in large collections of transcripts, facilitating systematic analyses. In this dissertation, we take up this opportunity: we consider computational approaches to analyzing conversations, that can arrive at descriptively rich and prescriptively informative accounts of how conversationalists interact.
We start by proposing methodology to model two particular conversational phenomena. In the British House of Commons, we consider the wide range of rhetorical roles encompassed by the questions that legislators ask, and develop an unsupervised method to infer types of rhetorical roles given a dataset of questions and answers. In the context of a crisis counseling service, we develop a method to model how counselors orient the flow of complex and high-stakes interactions with people in mental health crises. We apply these methods to analyze the respective domains, drawing correspondences between interactional dynamics and broader aspects of the setting, such as a legislator's political standing or the effectiveness of a counseling conversation.
We then describe a general approach, the Expected Conversational Context Framework, for modeling utterances in terms of their roles in a conversation. The framework's key idea is that we can derive a range of characteristics of an utterance by accounting for its expected conversational context–i.e., the distribution of preceding or subsequent utterances that could occur next to it in a conversation. Via a series of empirical explorations, we illustrate how the framework is generative of a variety of characterizations and analyses, including and beyond those proposed in our initial studies.
We end with a critical appraisal of the extent to which such approaches can arrive at actionable understandings. Drawing on a broad range of literature, ranging from sociological studies of interaction to causal inference, we consider the various complexities of conversations and the challenges they raise for methods such as ours.},
	language = {English},
	urldate = {2023-02-10},
	school = {Cornell University},
	author = {Zhang, Justine},
	year = {2021},
	note = {ISBN: 9798460415274},
}

@article{serzant_universal_2022,
	title = {Universal attractors in language evolution provide evidence for the kinds of efficiency pressures involved},
	volume = {9},
	copyright = {2022 The Author(s)},
	issn = {2662-9992},
	url = {https://www.nature.com/articles/s41599-022-01072-0},
	doi = {10.1057/s41599-022-01072-0},
	abstract = {Efficiency is central to understanding the communicative and cognitive underpinnings of language. However, efficiency management is a complex mechanism in which different efficiency effects—such as articulatory, processing and planning ease, mental accessibility, and informativity, online and offline efficiency effects—conspire to yield the coding of linguistic signs. While we do not yet exactly understand the interactional mechanism of these different effects, we argue that universal attractors are an important component of any dynamic theory of efficiency that would be aimed at predicting efficiency effects across languages. Attractors are defined as universal states around which language evolution revolves. Methodologically, we approach efficiency from a cross-linguistic perspective on the basis of a world-wide sample of 383 languages from 53 families, balancing all six macro-areas (Eurasia, North and South America, Australia, Africa, and Oceania). We explore the grammatical domain of verbal person–number subject indexes. We claim that there is an attractor state in this domain to which languages tend to develop and tend not to leave if they happen to comply with the attractor in their earlier stages of evolution. The attractor is characterized by different lengths for each person and number combination, structured along Zipf’s predictions. Moreover, the attractor strongly prefers non-compositional, cumulative coding of person and number. On the basis of these and other properties of the attractor, we conclude that there are two domains in which efficiency pressures are most powerful: strive towards less processing and articulatory effort. The latter, however, is overridden by constant information flow. Strive towards lower lexicon complexity and memory costs are weaker efficiency pressures for this grammatical category due to its order of frequency.},
	language = {en},
	number = {1},
	urldate = {2023-02-09},
	journal = {Humanities and Social Sciences Communications},
	author = {Seržant, Ilja A. and Moroz, George},
	month = feb,
	year = {2022},
	note = {Number: 1
Publisher: Palgrave},
	pages = {1--9},
}

@misc{watanabe_chime-6_2020,
	title = {{CHiME}-6 {Challenge}:{Tackling} {Multispeaker} {Speech} {Recognition} for {Unsegmented} {Recordings}},
	shorttitle = {{CHiME}-6 {Challenge}},
	url = {http://arxiv.org/abs/2004.09249},
	doi = {10.48550/arXiv.2004.09249},
	abstract = {Following the success of the 1st, 2nd, 3rd, 4th and 5th CHiME challenges we organize the 6th CHiME Speech Separation and Recognition Challenge (CHiME-6). The new challenge revisits the previous CHiME-5 challenge and further considers the problem of distant multi-microphone conversational speech diarization and recognition in everyday home environments. Speech material is the same as the previous CHiME-5 recordings except for accurate array synchronization. The material was elicited using a dinner party scenario with efforts taken to capture data that is representative of natural conversational speech. This paper provides a baseline description of the CHiME-6 challenge for both segmented multispeaker speech recognition (Track 1) and unsegmented multispeaker speech recognition (Track 2). Of note, Track 2 is the first challenge activity in the community to tackle an unsegmented multispeaker speech recognition scenario with a complete set of reproducible open source baselines providing speech enhancement, speaker diarization, and speech recognition modules.},
	urldate = {2023-02-09},
	publisher = {arXiv},
	author = {Watanabe, Shinji and Mandel, Michael and Barker, Jon and Vincent, Emmanuel and Arora, Ashish and Chang, Xuankai and Khudanpur, Sanjeev and Manohar, Vimal and Povey, Daniel and Raj, Desh and Snyder, David and Subramanian, Aswin Shanmugam and Trmal, Jan and Yair, Bar Ben and Boeddeker, Christoph and Ni, Zhaoheng and Fujita, Yusuke and Horiguchi, Shota and Kanda, Naoyuki and Yoshioka, Takuya and Ryant, Neville},
	month = may,
	year = {2020},
	note = {arXiv:2004.09249 [cs, eess]},
}

@inproceedings{song_chameleon_2019,
	address = {Hong Kong, China},
	title = {Chameleon: {A} {Language} {Model} {Adaptation} {Toolkit} for {Automatic} {Speech} {Recognition} of {Conversational} {Speech}},
	shorttitle = {Chameleon},
	url = {https://aclanthology.org/D19-3007},
	doi = {10.18653/v1/D19-3007},
	abstract = {Language model is a vital component in modern automatic speech recognition (ASR) systems. Since “one-size-fits-all” language model works suboptimally for conversational speeches, language model adaptation (LMA) is considered as a promising solution for solving this problem. In order to compare the state-of-the-art LMA techniques and systematically demonstrate their effect in conversational speech recognition, we develop a novel toolkit named Chameleon, which includes the state-of-the-art cache-based and topic-based LMA techniques. This demonstration does not only vividly visualize underlying working mechanisms of a variety of the state-of-the-art LMA models but also provide an interface for the user to customize the hyperparameters of them. With this demonstration, the audience can experience the effect of LMA in an interactive and real-time fashion. We wish this demonstration would inspire more research on better language model techniques for ASR.},
	urldate = {2023-02-09},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP}): {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Song, Yuanfeng and Jiang, Di and Zhao, Weiwei and Xu, Qian and Wong, Raymond Chi-Wing and Yang, Qiang},
	month = nov,
	year = {2019},
	pages = {37--42},
}

@misc{nguyen_super-human_2021,
	title = {Super-{Human} {Performance} in {Online} {Low}-latency {Recognition} of {Conversational} {Speech}},
	url = {http://arxiv.org/abs/2010.03449},
	doi = {10.48550/arXiv.2010.03449},
	abstract = {Achieving super-human performance in recognizing human speech has been a goal for several decades, as researchers have worked on increasingly challenging tasks. In the 1990's it was discovered, that conversational speech between two humans turns out to be considerably more difficult than read speech as hesitations, disfluencies, false starts and sloppy articulation complicate acoustic processing and require robust handling of acoustic, lexical and language context, jointly. Early attempts with statistical models could only reach error rates over 50\% and far from human performance (WER of around 5.5\%). Neural hybrid models and recent attention-based encoder-decoder models have considerably improved performance as such contexts can now be learned in an integral fashion. However, processing such contexts requires an entire utterance presentation and thus introduces unwanted delays before a recognition result can be output. In this paper, we address performance as well as latency. We present results for a system that can achieve super-human performance (at a WER of 5.0\%, over the Switchboard conversational benchmark) at a word based latency of only 1 second behind a speaker's speech. The system uses multiple attention-based encoder-decoder networks integrated within a novel low latency incremental inference approach.},
	urldate = {2023-02-09},
	publisher = {arXiv},
	author = {Nguyen, Thai-Son and Stueker, Sebastian and Waibel, Alex},
	month = jul,
	year = {2021},
	note = {arXiv:2010.03449 [cs]},
}

@inproceedings{wei_conversational_2022,
	title = {Conversational {Speech} {Recognition} by {Learning} {Conversation}-{Level} {Characteristics}},
	doi = {10.1109/ICASSP43922.2022.9746884},
	abstract = {Conversational automatic speech recognition (ASR) is a task to recognize conversational speech including multiple speakers. Unlike sentence-level ASR, conversational ASR can naturally take advantages from specific characteristics of conversation, such as role preference and topical coherence. This paper proposes a conversational ASR model which explicitly learns conversation-level characteristics under the prevalent end-to-end neural framework. The highlights of the proposed model are twofold. First, a latent variational module (LVM) is attached to a conformer-based encoder-decoder ASR backbone to learn role preference and topical coherence. Second, a topic model is specifically adopted to bias the outputs of the decoder to words in the predicted topics. Experiments on two Mandarin conversational ASR tasks show that the proposed model achieves a maximum 12\% relative character error rate (CER) reduction.},
	booktitle = {{ICASSP} 2022 - 2022 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Wei, Kun and Zhang, Yike and Sun, Sining and Xie, Lei and Ma, Long},
	month = may,
	year = {2022},
	note = {ISSN: 2379-190X},
	pages = {6752--6756},
}

@inproceedings{xiong_microsoft_2018,
	title = {The {Microsoft} 2017 {Conversational} {Speech} {Recognition} {System}},
	doi = {10.1109/ICASSP.2018.8461870},
	abstract = {We describe the latest version of Microsoft's conversational speech recognition system for the Switchboard and CallHome domains. The system adds a CNN-BLSTM acoustic model to the set of model architectures we combined previously, and includes character-based and dialog session aware LSTM language models in rescoring. For system combination we adopt a two-stage approach, whereby acoustic model posteriors are first combined at the senone/frame level, followed by a word-level voting via confusion networks. We also added another language model rescoring step following the confusion network combination. The resulting system yields a 5.1\% word error rate on the NIST 2000 Switchboard test set, and 9.8\% on the CallHome subset.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Xiong, W. and Wu, L. and Alleva, F. and Droppo, J. and Huang, X. and Stolcke, A.},
	month = apr,
	year = {2018},
	note = {ISSN: 2379-190X},
	pages = {5934--5938},
}

@article{arnold_grammar_2018,
	title = {Grammar of {Ambel}, an {Austronesian} language of {Raja} {Ampat}, west {New} {Guinea}},
	url = {https://era.ed.ac.uk/handle/1842/31120},
	abstract = {This thesis is a descriptive grammar of Ambel [wgo], an endangered Austronesian 
(South Halmahera-West New Guinea) language. Ambel is spoken by approximately 
1600 people on Waigeo, the largest island in the Raja Ampat archipelago 
(West Papua province, Indonesia). This grammar is based on naturalistic and 
elicited data, collected by the author from native speakers of Ambel. 
Ambel is a head-marking language, with basic SV/AVO constituent order. 
There are 14 native consonant phonemes and five vowel phonemes. Ambel has 
a tone system, in which /H/ syllables contrast with toneless syllables. Neither 
stress nor vowel length are contrastive. In verbal clauses, the subject of the clause 
is marked on the verb. This system makes a four-way number distinction (singular, 
dual, paucal, and plural), an animacy distinction in the third person, and a 
clusivity distinction in the non-singular first person. 
The Ambel noun phrase is mainly head-initial. There are five distinct 
morphosyntactic possessive constructions, the choice of which is primarily 
determined by a lexical specification on the possessed noun. Some nouns 
(including most body parts and some kin terms) are possessed in one of three 
constructions in which the person, number, and animacy of the possessor is 
marked directly on the possessed noun, while most other nouns are possessed 
in one of two constructions in which the possessor is marked on a prenominal 
possessive classifier. 
Within the clause, all negation particles and most aspect and mode particles are 
clause-final. There is no passive construction. Ambel has a rich system of spatial 
deixis, in which six different classes of deictic words (such as demonstratives, 
deictic prepositions, and deictic nouns) are derived from one of four demonstrative 
roots or 28 directional stems. Verb serialisation is used to express, among other 
things, purposive motion and changes of state. 
This thesis is the first major description and documentation of the Ambel 
language. As such, it will be of considerable interest to typologists and historical 
linguists, as well as others interested in the languages, cultures, and history of 
New Guinea. All of the data on which this grammar is based have been archived 
with both the Endangered Languages Archive, and the Center for Endangered 
Languages Documentation at Universitas Papua in Manokwari. The data will thus 
be available to future generations, including the Ambel community themselves.},
	language = {en},
	urldate = {2023-02-08},
	author = {Arnold, Laura Melissa},
	month = jul,
	year = {2018},
	note = {Accepted: 2018-06-11T10:22:10Z
Publisher: The University of Edinburgh},
}

@inproceedings{viswanathan_addressing_2022,
	address = {New York, NY, USA},
	series = {{DIS} '22},
	title = {Addressing {Hiccups} in {Conversations} with {Recommender} {Systems}},
	isbn = {978-1-4503-9358-4},
	url = {https://doi.org/10.1145/3532106.3533491},
	doi = {10.1145/3532106.3533491},
	abstract = {Conversational Agents (CAs) employing voice as their main interaction mode produce natural language utterances with the aim of mimicking human conversations. To unveil hiccups in conversations with recommender systems, we observed users interacting with CAs. Our findings suggest that those occur as users struggle to start the session, as CAs do not appear exploratory, and as CAs remained silent after offering recommendation(s) or after reporting errors. Users enacted mental models derived from years of experience with Graphical User Interfaces, but also expected human-like characteristics such as explanations and proactivity. Anchoring on these, we designed a dialogue model for a multimodal Conversational Recommender System (CRS) mimicking humans and GUIs. We probed the state of hiccups further with a Wizard-of-Oz prototype implementing this dialogue model. Our findings suggest that participants rapidly adopted GUI mimicries, cooperated for error resolution, appreciated explainable recommendations, and provided insights to improve persisting hiccups in proactivity and navigation. Based on these, we provide implications for design to address hiccups in CRS.},
	urldate = {2023-02-07},
	booktitle = {Designing {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Viswanathan, Sruthi and Guillot, Fabien and Chang, Minsuk and Grasso, Antonietta Maria and Renders, Jean-Michel},
	month = jun,
	year = {2022},
	pages = {1243--1259},
}

@misc{kirchenbauer_watermark_2023,
	title = {A {Watermark} for {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2301.10226},
	doi = {10.48550/arXiv.2301.10226},
	abstract = {Potential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient open-source algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of "green" tokens before a word is generated, and then softly promoting use of green tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an information-theoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom},
	month = jan,
	year = {2023},
	note = {arXiv:2301.10226 [cs]},
}

@misc{kumar_language_2022,
	title = {Language {Generation} {Models} {Can} {Cause} {Harm}: {So} {What} {Can} {We} {Do} {About} {It}? {An} {Actionable} {Survey}},
	shorttitle = {Language {Generation} {Models} {Can} {Cause} {Harm}},
	url = {http://arxiv.org/abs/2210.07700},
	doi = {10.48550/arXiv.2210.07700},
	abstract = {Recent advances in the capacity of large language models to generate human-like text have resulted in their increased adoption in user-facing settings. In parallel, these improvements have prompted a heated discourse around the risks of societal harms they introduce, whether inadvertent or malicious. Several studies have identified potential causes of these harms and called for their mitigation via development of safer and fairer models. Going beyond enumerating the risks of harms, this work provides a survey of practical methods for addressing potential threats and societal harms from language generation models. We draw on several prior works' taxonomies of language model risks to present a structured overview of strategies for detecting and ameliorating different kinds of risks/harms of language generators. Bridging diverse strands of research, this survey aims to serve as a practical guide for both LM researchers and practitioners with explanations of motivations behind different mitigation strategies, their limitations, and open problems for future research.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Kumar, Sachin and Balachandran, Vidhisha and Njoo, Lucille and Anastasopoulos, Antonios and Tsvetkov, Yulia},
	month = oct,
	year = {2022},
	note = {arXiv:2210.07700 [cs]},
}

@misc{zhen_survey_2022,
	title = {A {Survey} on {Knowledge}-{Enhanced} {Pre}-trained {Language} {Models}},
	url = {http://arxiv.org/abs/2212.13428},
	doi = {10.48550/arXiv.2212.13428},
	abstract = {Natural Language Processing (NLP) has been revolutionized by the use of Pre-trained Language Models (PLMs) such as BERT. Despite setting new records in nearly every NLP task, PLMs still face a number of challenges including poor interpretability, weak reasoning capability, and the need for a lot of expensive annotated data when applied to downstream tasks. By integrating external knowledge into PLMs, {\textbackslash}textit\{{\textbackslash}underline\{K\}nowledge-{\textbackslash}underline\{E\}nhanced {\textbackslash}underline\{P\}re-trained {\textbackslash}underline\{L\}anguage {\textbackslash}underline\{M\}odels\} (KEPLMs) have the potential to overcome the above-mentioned limitations. In this paper, we examine KEPLMs systematically through a series of studies. Specifically, we outline the common types and different formats of knowledge to be integrated into KEPLMs, detail the existing methods for building and evaluating KEPLMS, present the applications of KEPLMs in downstream tasks, and discuss the future research directions. Researchers will benefit from this survey by gaining a quick and comprehensive overview of the latest developments in this field.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Zhen, Chaoqi and Shang, Yanlei and Liu, Xiangyu and Li, Yifei and Chen, Yong and Zhang, Dell},
	month = dec,
	year = {2022},
	note = {arXiv:2212.13428 [cs]},
}

@misc{li_survey_2023,
	title = {A {Survey} on {Transformers} in {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2301.03044},
	doi = {10.48550/arXiv.2301.03044},
	abstract = {Transformer has been considered the dominating neural architecture in NLP and CV, mostly under a supervised setting. Recently, a similar surge of using Transformers has appeared in the domain of reinforcement learning (RL), but it is faced with unique design choices and challenges brought by the nature of RL. However, the evolution of Transformers in RL has not yet been well unraveled. Hence, in this paper, we seek to systematically review motivations and progress on using Transformers in RL, provide a taxonomy on existing works, discuss each sub-field, and summarize future prospects.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Li, Wenzhe and Luo, Hao and Lin, Zichuan and Zhang, Chongjie and Lu, Zongqing and Ye, Deheng},
	month = jan,
	year = {2023},
	note = {arXiv:2301.03044 [cs]},
}

@misc{schneider_survey_2023,
	title = {A {Survey} of {Deep} {Learning}: {From} {Activations} to {Transformers}},
	shorttitle = {A {Survey} of {Deep} {Learning}},
	url = {http://arxiv.org/abs/2302.00722},
	doi = {10.48550/arXiv.2302.00722},
	abstract = {Deep learning has made tremendous progress in the last decade. A key success factor is the large amount of architectures, layers, objectives, and optimization techniques that have emerged in recent years. They include a myriad of variants related to attention, normalization, skip connection, transformer and self-supervised learning schemes -- to name a few. We provide a comprehensive overview of the most important, recent works in these areas to those who already have a basic understanding of deep learning. We hope that a holistic and unified treatment of influential, recent works helps researchers to form new connections between diverse areas of deep learning.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Schneider, Johannes and Vlachos, Michalis},
	month = feb,
	year = {2023},
	note = {arXiv:2302.00722 [cs]},
}

@misc{ganguli_red_2022,
	title = {Red {Teaming} {Language} {Models} to {Reduce} {Harms}: {Methods}, {Scaling} {Behaviors}, and {Lessons} {Learned}},
	shorttitle = {Red {Teaming} {Language} {Models} to {Reduce} {Harms}},
	url = {http://arxiv.org/abs/2209.07858},
	doi = {10.48550/arXiv.2209.07858},
	abstract = {We describe our early efforts to red team language models in order to simultaneously discover, measure, and attempt to reduce their potentially harmful outputs. We make three main contributions. First, we investigate scaling behaviors for red teaming across 3 model sizes (2.7B, 13B, and 52B parameters) and 4 model types: a plain language model (LM); an LM prompted to be helpful, honest, and harmless; an LM with rejection sampling; and a model trained to be helpful and harmless using reinforcement learning from human feedback (RLHF). We find that the RLHF models are increasingly difficult to red team as they scale, and we find a flat trend with scale for the other model types. Second, we release our dataset of 38,961 red team attacks for others to analyze and learn from. We provide our own analysis of the data and find a variety of harmful outputs, which range from offensive language to more subtly harmful non-violent unethical outputs. Third, we exhaustively describe our instructions, processes, statistical methodologies, and uncertainty about red teaming. We hope that this transparency accelerates our ability to work together as a community in order to develop shared norms, practices, and technical standards for how to red team language models.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and Jones, Andy and Bowman, Sam and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Elhage, Nelson and El-Showk, Sheer and Fort, Stanislav and Hatfield-Dodds, Zac and Henighan, Tom and Hernandez, Danny and Hume, Tristan and Jacobson, Josh and Johnston, Scott and Kravec, Shauna and Olsson, Catherine and Ringer, Sam and Tran-Johnson, Eli and Amodei, Dario and Brown, Tom and Joseph, Nicholas and McCandlish, Sam and Olah, Chris and Kaplan, Jared and Clark, Jack},
	month = nov,
	year = {2022},
	note = {arXiv:2209.07858 [cs]},
}

@misc{glaese_improving_2022,
	title = {Improving alignment of dialogue agents via targeted human judgements},
	url = {http://arxiv.org/abs/2209.14375},
	doi = {10.48550/arXiv.2209.14375},
	abstract = {We present Sparrow, an information-seeking dialogue agent trained to be more helpful, correct, and harmless compared to prompted language model baselines. We use reinforcement learning from human feedback to train our models with two new additions to help human raters judge agent behaviour. First, to make our agent more helpful and harmless, we break down the requirements for good dialogue into natural language rules the agent should follow, and ask raters about each rule separately. We demonstrate that this breakdown enables us to collect more targeted human judgements of agent behaviour and allows for more efficient rule-conditional reward models. Second, our agent provides evidence from sources supporting factual claims when collecting preference judgements over model statements. For factual questions, evidence provided by Sparrow supports the sampled response 78\% of the time. Sparrow is preferred more often than baselines while being more resilient to adversarial probing by humans, violating our rules only 8\% of the time when probed. Finally, we conduct extensive analyses showing that though our model learns to follow our rules it can exhibit distributional biases.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Glaese, Amelia and McAleese, Nat and Trębacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and Campbell-Gillingham, Lucy and Uesato, Jonathan and Huang, Po-Sen and Comanescu, Ramona and Yang, Fan and See, Abigail and Dathathri, Sumanth and Greig, Rory and Chen, Charlie and Fritz, Doug and Elias, Jaume Sanchez and Green, Richard and Mokrá, Soňa and Fernando, Nicholas and Wu, Boxi and Foley, Rachel and Young, Susannah and Gabriel, Iason and Isaac, William and Mellor, John and Hassabis, Demis and Kavukcuoglu, Koray and Hendricks, Lisa Anne and Irving, Geoffrey},
	month = sep,
	year = {2022},
	note = {arXiv:2209.14375 [cs]},
}

@misc{birhane_multimodal_2021,
	title = {Multimodal datasets: misogyny, pornography, and malignant stereotypes},
	shorttitle = {Multimodal datasets},
	url = {http://arxiv.org/abs/2110.01963},
	doi = {10.48550/arXiv.2110.01963},
	abstract = {We have now entered the era of trillion parameter machine learning models trained on billion-sized datasets scraped from the internet. The rise of these gargantuan datasets has given rise to formidable bodies of critical work that has called for caution while generating these large datasets. These address concerns surrounding the dubious curation practices used to generate these datasets, the sordid quality of alt-text data available on the world wide web, the problematic content of the CommonCrawl dataset often used as a source for training large language models, and the entrenched biases in large-scale visio-linguistic models (such as OpenAI's CLIP model) trained on opaque datasets (WebImageText). In the backdrop of these specific calls of caution, we examine the recently released LAION-400M dataset, which is a CLIP-filtered dataset of Image-Alt-text pairs parsed from the Common-Crawl dataset. We found that the dataset contains, troublesome and explicit images and text pairs of rape, pornography, malign stereotypes, racist and ethnic slurs, and other extremely problematic content. We outline numerous implications, concerns and downstream harms regarding the current state of large scale datasets while raising open questions for various stakeholders including the AI community, regulators, policy makers and data subjects.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
	month = oct,
	year = {2021},
	note = {arXiv:2110.01963 [cs]},
}

@article{ouyang_training_2022,
	title = {Training language models to follow instructions with human feedback},
	abstract = {Making language models bigger does not inherently make them better at following a user’s intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback (RLHF). We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
	language = {en},
	author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	year = {2022},
	pages = {68},
}

@inproceedings{tanaka_end--end_2021,
	title = {End-to-{End} {Rich} {Transcription}-{Style} {Automatic} {Speech} {Recognition} with {Semi}-{Supervised} {Learning}},
	url = {https://www.isca-speech.org/archive/interspeech_2021/tanaka21c_interspeech.html},
	doi = {10.21437/Interspeech.2021-1981},
	language = {en},
	urldate = {2023-01-31},
	booktitle = {Interspeech 2021},
	publisher = {ISCA},
	author = {Tanaka, Tomohiro and Masumura, Ryo and Ihori, Mana and Takashima, Akihiko and Orihashi, Shota and Makishima, Naoki},
	month = aug,
	year = {2021},
	pages = {4458--4462},
}

@article{tran_mm-hm_2023,
	title = {“{Mm}-hm,” “{Uh}-uh”: are non-lexical conversational sounds deal breakers for the ambient clinical documentation technology?},
	issn = {1527-974X},
	shorttitle = {“{Mm}-hm,” “{Uh}-uh”},
	url = {https://doi.org/10.1093/jamia/ocad001},
	doi = {10.1093/jamia/ocad001},
	abstract = {Ambient clinical documentation technology uses automatic speech recognition (ASR) and natural language processing (NLP) to turn patient–clinician conversations into clinical documentation. It is a promising approach to reducing clinician burden and improving documentation quality. However, the performance of current-generation ASR remains inadequately validated. In this study, we investigated the impact of non-lexical conversational sounds (NLCS) on ASR performance. NLCS, such as Mm-hm and Uh-uh, are commonly used to convey important information in clinical conversations, for example, Mm-hm as a “yes” response from the patient to the clinician question “are you allergic to antibiotics?”In this study, we evaluated 2 contemporary ASR engines, Google Speech-to-Text Clinical Conversation (“Google ASR”), and Amazon Transcribe Medical (“Amazon ASR”), both of which have their language models specifically tailored to clinical conversations. The empirical data used were from 36 primary care encounters. We conducted a series of quantitative and qualitative analyses to examine the word error rate (WER) and the potential impact of misrecognized NLCS on the quality of clinical documentation.Out of a total of 135 647 spoken words contained in the evaluation data, 3284 (2.4\%) were NLCS. Among these NLCS, 76 (0.06\% of total words, 2.3\% of all NLCS) were used to convey clinically relevant information. The overall WER, of all spoken words, was 11.8\% for Google ASR and 12.8\% for Amazon ASR. However, both ASR engines demonstrated poor performance in recognizing NLCS: the WERs across frequently used NLCS were 40.8\% (Google) and 57.2\% (Amazon), respectively; and among the NLCS that conveyed clinically relevant information, 94.7\% and 98.7\%, respectively.Current ASR solutions are not capable of properly recognizing NLCS, particularly those that convey clinically relevant information. Although the volume of NLCS in our evaluation data was very small (2.4\% of the total corpus; and for NLCS that conveyed clinically relevant information: 0.06\%), incorrect recognition of them could result in inaccuracies in clinical documentation and introduce new patient safety risks.},
	urldate = {2023-01-27},
	journal = {Journal of the American Medical Informatics Association},
	author = {Tran, Brian D and Latif, Kareem and Reynolds, Tera L and Park, Jihyun and Elston Lafata, Jennifer and Tai-Seale, Ming and Zheng, Kai},
	month = jan,
	year = {2023},
	pages = {ocad001},
}

@inproceedings{bergman_guiding_2022,
	address = {Edinburgh, UK},
	title = {Guiding the {Release} of {Safer} {E2E} {Conversational} {AI} through {Value} {Sensitive} {Design}},
	url = {https://aclanthology.org/2022.sigdial-1.4},
	abstract = {Over the last several years, end-to-end neural conversational agents have vastly improved their ability to carry unrestricted, open-domain conversations with humans. However, these models are often trained on large datasets from the Internet and, as a result, may learn undesirable behaviours from this data, such as toxic or otherwise harmful language. Thus, researchers must wrestle with how and when to release these models. In this paper, we survey recent and related work to highlight tensions between values, potential positive impact, and potential harms. We also provide a framework to support practitioners in deciding whether and how to release these models, following the tenets of value-sensitive design.},
	urldate = {2023-01-17},
	booktitle = {Proceedings of the 23rd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Bergman, A. Stevie and Abercrombie, Gavin and Spruit, Shannon and Hovy, Dirk and Dinan, Emily and Boureau, Y-Lan and Rieser, Verena},
	month = sep,
	year = {2022},
	pages = {39--52},
}

@article{dingemanse_beyond_2023,
	title = {Beyond {Single}-{Mindedness}: {A} {Figure}-{Ground} {Reversal} for the {Cognitive} {Sciences}},
	volume = {47},
	doi = {10.1111/cogs.13230},
	abstract = {A fundamental fact about human minds is that they are never truly alone: all minds are steeped in situated interaction. That social interaction matters is recognised by any experimentalist who seeks to exclude its influence by studying individuals in isolation. On this view, interaction complicates cognition. Here we explore the more radical stance that interaction co-constitutes cognition: that we benefit from looking beyond single minds towards cognition as a process involving interacting minds. All around the cognitive sciences, there are approaches that put interaction centre stage. Their diverse and pluralistic origins may obscure the fact that collectively, they harbour insights and methods that can respecify foundational assumptions and fuel novel interdisciplinary work. What might the cognitive sciences gain from stronger interactional foundations? This represents, we believe, one of the key questions for the future. Writing as a multidisciplinary collective assembled from across the classic cognitive science hexagon and beyond, we highlight the opportunity for a figure-ground reversal that puts interaction at the heart of cognition. The interactive stance is a way of seeing that deserves to be a key part of the conceptual toolkit of cognitive scientists.},
	journal = {Cognitive Science},
	author = {Dingemanse, Mark and Liesenfeld, Andreas and Rasenberg, Marlou and Albert, Saul and Ameka, Felix K. and Birhane, Abeba and Bolis, Dimitris and Cassell, Justine and Clift, Rebecca and Cuffari, Elena and De Jaegher, Hanne and Dutilh Novaes, Catarina and Enfield, N.J. and Fusaroli, Riccardo and Gregoromichelaki, Eleni and Hutchins, Edwin and Konvalinka, Ivana and Milton, Damian and Rączaszek-Leonardi, Joanna and Reddy, Vasudevi and Rossano, Federico and Schlangen, David and Seibt, Johanna and Stokoe, Elizabeth and Suchman, Lucy A. and Vesper, Cordula and Wheatley, Thalia and Wiltschko, Martina},
	year = {2023},
}

@article{schotten_emergent_2022,
	title = {The emergent properties of the connected brain},
	copyright = {Copyright © 2022 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works},
	url = {https://www.science.org/doi/10.1126/science.abq2591},
	doi = {10.1126/science.abq2591},
	abstract = {There is more to brain connections than the mere transfer of signals between brain regions. Behavior and cognition emerge through cortical area interaction. This requires integration between local and distant areas orchestrated by densely connected ...},
	language = {EN},
	urldate = {2023-01-16},
	journal = {Science},
	author = {Schotten, Michel Thiebaut de and Forkel, Stephanie J.},
	month = nov,
	year = {2022},
	note = {Publisher: American Association for the Advancement of Science},
}

@article{matzinger_pause_2023,
	title = {Pause {Length} and {Differences} in {Cognitive} {State} {Attribution} in {Native} and {Non}-{Native} {Speakers}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2226-471X},
	url = {https://www.mdpi.com/2226-471X/8/1/26},
	doi = {10.3390/languages8010026},
	abstract = {Speech pauses between turns of conversations are crucial for assessing conversation partners’ cognitive states, such as their knowledge, confidence and willingness to grant requests; in general, speakers making longer pauses are regarded as less apt and willing. However, it is unclear if the interpretation of pause length is mediated by the accent of interactants, in particular native versus non-native accents. We hypothesized that native listeners are more tolerant towards long pauses made by non-native speakers than those made by native speakers. This is because, in non-native speakers, long pauses might be the result of prolonged cognitive processing when planning an answer in a non-native language rather than of a lack of knowledge, confidence or willingness. Our experiment, in which 100 native Polish-speaking raters rated native and non-native speakers of Polish on their knowledge, confidence and willingness, showed that this hypothesis was confirmed for perceived willingness only; non-native speakers were regarded as equally willing to grant requests, irrespective of their inter-turn pause durations, whereas native speakers making long pauses were regarded as less willing than those making short pauses. For knowledge and confidence, we did not find a mediating effect of accent; both native and non-native speakers were rated as less knowledgeable and confident when making long pauses. One possible reason for the difference between our findings on perceived willingness to grant requests versus perceived knowledge and confidence is that requests might be more socially engaging and more directly relevant for interpersonal cooperative interactions than knowledge that reflects on partners’ competence but not cooperativeness. Overall, our study shows that (non-)native accents can influence which cognitive states are signaled by different pause durations, which may have important implications for intercultural communication settings where topics are negotiated between native and non-native speakers.},
	language = {en},
	number = {1},
	urldate = {2023-01-16},
	journal = {Languages},
	author = {Matzinger, Theresa and Pleyer, Michael and Żywiczyński, Przemysław},
	month = mar,
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {26},
}

@article{spottiswoode_reciprocal_2016,
	title = {Reciprocal signaling in honeyguide-human mutualism},
	volume = {353},
	url = {https://www.science.org/doi/full/10.1126/science.aaf4885},
	doi = {10.1126/science.aaf4885},
	abstract = {Greater honeyguides (Indicator indicator) lead human honey-hunters to wild bees’ nests, in a rare example of a mutualistic foraging partnership between humans and free-living wild animals. We show experimentally that a specialized vocal sound made by Mozambican honey-hunters seeking bees’ nests elicits elevated cooperative behavior from honeyguides. The production of this sound increased the probability of being guided by a honeyguide from about 33 to 66\% and the overall probability of thus finding a bees’ nest from 17 to 54\%, as compared with other animal or human sounds of similar amplitude. These results provide experimental evidence that a wild animal in a natural setting responds adaptively to a human signal of cooperation.},
	number = {6297},
	urldate = {2023-01-10},
	journal = {Science},
	author = {Spottiswoode, Claire N. and Begg, Keith S. and Begg, Colleen M.},
	month = jul,
	year = {2016},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {387--389},
}

@phdthesis{arnold_grammar_2018-1,
	type = {{PhD} {Thesis}},
	title = {Grammar of {Ambel}, an {Austronesian} language of {Raja} {Ampat}, {West} {New} {Guinea}},
	school = {The University of Edinburgh},
	author = {Arnold, Laura Melissa},
	year = {2018},
	note = {Publisher: The University of Edinburgh},
}

@incollection{bynon_domestic_1976,
	address = {The Hague},
	title = {Domestic animal calling in a {Berber} tribe},
	booktitle = {Language and man: {Anthropological} issues},
	publisher = {Mouton},
	author = {Bynon, James},
	editor = {McCormack, William and Wurm, Stephen A.},
	year = {1976},
	pages = {39--65},
}

@article{berthet_animal_2023,
	title = {Animal linguistics: a primer},
	volume = {98},
	issn = {1469-185X},
	shorttitle = {Animal linguistics},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/brv.12897},
	doi = {10.1111/brv.12897},
	abstract = {The evolution of language has been investigated by several research communities, including biologists and linguists, striving to highlight similar linguistic capacities across species. To date, however, no consensus exists on the linguistic capacities of non-human species. Major controversies remain on the use of linguistic terminology, analysis methods and behavioural data collection. The field of ‘animal linguistics’ has emerged to overcome these difficulties and attempt to reach uniform methods and terminology. This primer is a tutorial review of ‘animal linguistics’. It describes the linguistic concepts of semantics, pragmatics and syntax, and proposes minimal criteria to be fulfilled to claim that a given species displays a particular linguistic capacity. Second, it reviews relevant methods successfully applied to the study of communication in animals and proposes a list of useful references to detect and overcome major pitfalls commonly observed in the collection of animal behaviour data. This primer represents a step towards mutual understanding and fruitful collaborations between linguists and biologists.},
	language = {en},
	number = {1},
	urldate = {2023-01-10},
	journal = {Biological Reviews},
	author = {Berthet, Mélissa and Coye, Camille and Dezecache, Guillaume and Kuhn, Jeremy},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/brv.12897},
	pages = {81--98},
}

@article{schlenker_beyond_2022,
	title = {Beyond {Anthropocentrism} in {Comparative} {Cognition}: {Recentering} {Animal} {Linguistics}},
	volume = {46},
	issn = {1551-6709},
	shorttitle = {Beyond {Anthropocentrism} in {Comparative} {Cognition}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.13220},
	doi = {10.1111/cogs.13220},
	language = {en},
	number = {12},
	urldate = {2022-12-08},
	journal = {Cognitive Science},
	author = {Schlenker, Philippe and Coye, Camille and Steinert-Threlkeld, Shane and Klinedinst, Nathan and Chemla, Emmanuel},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.13220},
	pages = {e13220},
}

@article{evans_pushing_2022,
	title = {Pushing the boundaries: {Marginal} phonemes and dialogic interaction},
	volume = {26},
	copyright = {Evans N., 2022},
	issn = {2686-8024},
	shorttitle = {Pushing the boundaries},
	url = {https://doi.org/10.22363/2687-0088-32349},
	doi = {10.22363/2687-0088-32349},
	abstract = {Phonemes with restricted distribution represent an interesting analytic challenge. Well-known sources include the adoption of certain phonemes from other languages in borrowed words, emerging phonemic splits, and special phonological subsystems (e.g. ideophones). This paper aims to widen our conception of such marginal phonemes, by incorporating another source: specific vocal gestures called into play in interactional settings. Our initial puzzle involves a restricted phoneme set in the Papuan language Nen: two classes of sounds are restricted to interactive contexts, namely interjections and deictics. These sounds are the nasal vowels ã , ẽ , and the glottal fricative h . Several questions arise here. Should these restricted sounds be considered part of the phoneme system? How did they evolve? How does their presence interact with seemingly equivalent sounds in neighbouring languages, in contexts of possible loanwords? We then pass to two other languages where sounds that are unquestionably phonemes have, in at least some phonotactic positions, clear correlations with interactive uses: initial /ð/ in English, essentially restricted to words of person (thou), space (that), time (then), or discourse deixis (the, though), and glottal stops with morphemic function in Bininj Kunwok, restricted to immediate aspect[43], addressee-engaged demonstratives, and kinship vocatives. It is already known that non-phonemic speech sounds (e.g. what is written mhm in English) are used in interaction. This paper proposes that the special phonetics of interaction can integrate further into the sound system and, in such cases as those presented here, either expand the phonological system in absolute terms by adding new phonemes, or expand the phonotactic possibilities of phonemes already occurring in other phonotactic positions.},
	language = {ru},
	number = {4},
	urldate = {2022-12-24},
	journal = {Russian Journal of Linguistics},
	author = {Evans, Nicholas},
	month = dec,
	year = {2022},
	note = {Number: 4},
	pages = {995--1011},
}

@misc{mitchell_measuring_2022,
	title = {Measuring {Data}},
	url = {http://arxiv.org/abs/2212.05129},
	doi = {10.48550/arXiv.2212.05129},
	abstract = {We identify the task of measuring data to quantitatively characterize the composition of machine learning data and datasets. Similar to an object's height, width, and volume, data measurements quantify different attributes of data along common dimensions that support comparison. Several lines of research have proposed what we refer to as measurements, with differing terminology; we bring some of this work together, particularly in fields of computer vision and language, and build from it to motivate measuring data as a critical component of responsible AI development. Measuring data aids in systematically building and analyzing machine learning (ML) data towards specific goals and gaining better control of what modern ML systems will learn. We conclude with a discussion of the many avenues of future work, the limitations of data measurements, and how to leverage these measurement approaches in research and practice.},
	urldate = {2022-12-21},
	publisher = {arXiv},
	author = {Mitchell, Margaret and Luccioni, Alexandra Sasha and Lambert, Nathan and Gerchick, Marissa and McMillan-Major, Angelina and Ozoani, Ezinwanne and Rajani, Nazneen and Thrush, Tristan and Jernite, Yacine and Kiela, Douwe},
	month = dec,
	year = {2022},
	note = {arXiv:2212.05129 [cs]},
}

@article{dideriksen_quantifying_2022,
	title = {Quantifying the interplay of conversational devices in building mutual understanding},
	issn = {1939-2222},
	doi = {10.1037/xge0001301},
	abstract = {Humans readily engage in idle chat and heated discussions and negotiate tough joint decisions without ever having to think twice about how to keep the conversation grounded in mutual understanding. However, current attempts at identifying and assessing the conversational devices that make this possible are fragmented across disciplines and investigate single devices within single contexts. We present a comprehensive conceptual framework to investigate conversational devices, their relations, and how they adjust to contextual demands. In two corpus studies, we systematically test the role of three conversational devices: backchannels, repair, and linguistic entrainment. Contrasting affiliative and task-oriented conversations within participants, we find that conversational devices adaptively adjust to the increased need for precision in the latter: We show that low-precision devices such as backchannels are more frequent in affiliative conversations, whereas more costly but higher-precision mechanisms, such as specific repairs, are more frequent in task-oriented conversations. Further, task-oriented conversations involve higher complementarity of contributions in terms of the content and perspective: lower semantic entrainment and less frequent (but richer) lexical and syntactic entrainment. Finally, we show that the observed variations in the use of conversational devices are potentially adaptive: pairs of interlocutors that show stronger linguistic complementarity perform better across the two tasks. By combining motivated comparisons of several conversational contexts and theoretically informed computational analyses of empirical data the present work lays the foundations for a comprehensive conceptual framework for understanding the use of conversational devices in dialogue. (PsycInfo Database Record (c) 2022 APA, all rights reserved).},
	language = {eng},
	journal = {Journal of Experimental Psychology. General},
	author = {Dideriksen, Christina and Christiansen, Morten H. and Tylén, Kristian and Dingemanse, Mark and Fusaroli, Riccardo},
	month = dec,
	year = {2022},
	pmid = {36521115},
}

@inproceedings{sweers_negation_2022,
	address = {Marseille, France},
	title = {Negation {Detection} in {Dutch} {Spoken} {Human}-{Computer} {Conversations}},
	url = {https://aclanthology.org/2022.lrec-1.56},
	abstract = {Proper recognition and interpretation of negation signals in text or communication is crucial for any form of full natural language understanding. It is also essential for computational approaches to natural language processing. In this study we focus on negation detection in Dutch spoken human-computer conversations. Since there exists no Dutch (dialogue) corpus annotated for negation we have annotated a Dutch corpus sample to evaluate our method for automatic negation detection. We use transfer learning and trained NegBERT (an existing BERT implementation used for negation detection) on English data with multilingual BERT to detect negation in Dutch dialogues. Our results show that adding in-domain training material improves the results. We show that we can detect both negation cues and scope in Dutch dialogues with high precision and recall. We provide a detailed error analysis and discuss the effects of cross-lingual and cross-domain transfer learning on automatic negation detection.},
	urldate = {2022-12-14},
	booktitle = {Proceedings of the {Thirteenth} {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Sweers, Tom and Hendrickx, Iris and Strik, Helmer},
	month = jun,
	year = {2022},
	pages = {534--542},
}

@inproceedings{ji_abstract_2022,
	title = {Abstract {Visual} {Reasoning} with {Tangram} {Shapes}},
	url = {https://aclanthology.org/2022.emnlp-main.38},
	abstract = {Anya Ji, Noriyuki Kojima, Noah Rush, Alane Suhr, Wai Keen Vong, Robert Hawkins, Yoav Artzi. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.},
	language = {en-us},
	urldate = {2022-12-13},
	author = {Ji, Anya and Kojima, Noriyuki and Rush, Noah and Suhr, Alane and Vong, Wai Keen and Hawkins, Robert and Artzi, Yoav},
	month = dec,
	year = {2022},
	pages = {582--601},
}

@article{aben_what_2022,
	title = {What influences students' peer-feedback uptake? {Relations} between error tolerance, feedback tolerance, writing self-efficacy, perceived language skills and peer-feedback processing},
	volume = {97},
	issn = {1041-6080},
	shorttitle = {What influences students' peer-feedback uptake?},
	url = {https://www.sciencedirect.com/science/article/pii/S1041608022000620},
	doi = {10.1016/j.lindif.2022.102175},
	abstract = {This study investigated the extent to which the uptake of peer-feedback of 10th grade students (N = 160, age range = 15–16) related to intrapersonal factors (error tolerance, feedback tolerance, and writing self-efficacy) and interpersonal factors (feedback provider's language skills, as perceived by the feedback recipient). Two groups of students received similar feedback on their writing performance, provided by trained research-assistants. Half the students was led to believe that feedback was provided by a peer perceived to have stronger language skills than their own, whereas the other half was led to believe that feedback was provided by a peer perceived to have weaker language skills than their own. Results showed that (1) error tolerance was related to feedback tolerance, (2) perceived language skills of the feedback provider positively related to the uptake of peer-feedback on writing style, and (3) error tolerance, feedback tolerance, and writing self-efficacy did not relate to peer-feedback uptake. These results emphasize the central role of errors in peer-feedback processing and they imply that the importance of interpersonal factors should not be overlooked when predicting or explaining peer-feedback uptake.},
	language = {en},
	urldate = {2022-12-13},
	journal = {Learning and Individual Differences},
	author = {Aben, Jochem E. J. and Timmermans, Anneke C. and Dingyloudi, Filitsa and Lara, Mayra Mascareño and Strijbos, Jan-Willem},
	month = jul,
	year = {2022},
	pages = {102175},
}

@techreport{keyser_cognitive_1978,
	title = {Cognitive {Science}, 1978: {Report} of {The} {State} of the {Art} {Committee} to {The} {Advisors} of {The} {Alfred} {P}. {Sloan} {Foundation}},
	author = {Keyser, Samuel Jay and Miller, George A. and Walker, Edward},
	year = {1978},
}

@inproceedings{seibt_sociomorphing_2020,
	title = {Sociomorphing, not anthropomorphizing: {Towards} a typology of experienced sociality},
	shorttitle = {Sociomorphing, {Not} {Anthropomorphizing}},
	url = {https://ebooks.iospress.nl/doi/10.3233/FAIA200900},
	doi = {10.3233/FAIA200900},
	urldate = {2021-10-14},
	booktitle = {Culturally {Sustainable} {Social} {Robotics}—{Proceedings} of {Robophilosophy} 2020},
	publisher = {IOS Press},
	author = {Seibt, Johanna and Vestergaard, Christina and Damholdt, Malene F.},
	editor = {Nørskov, Marco and Seibt, Johanna and Quick, Oliver Santiago},
	year = {2020},
	note = {Publisher: IOS Press},
	pages = {51--67},
}

@article{cassell_ties_2020,
	title = {The ties that bind: {Social} interaction in conversational agents},
	volume = {220-221},
	issn = {0751-7971},
	url = {https://www.cairn-int.info/article-E_RES_220_0021--the-ties-that-bind.htm},
	doi = {10.3917/res.220.0021},
	abstract = {The article argues for a genre of AI capable of building social bonds with humans. The argument\&\#8217;s starting point is the two competing origin stories of Artificial Intelligence. In one, the goal of AI was to create machines that could simulate every aspect of human intelligence. In the other, it was to build machines that adapt closely to natural human behaviour. While the first story is better known, it is argued that the second would have been more fruitful, as it places the human at the heart of the endeavour. Based on this historical perspective, the article provides several examples of conversational agents that engage in this kind of adaptive social behaviour. Results of experiments with these social agents find that they do in fact improve relations between people and the systems. Additionally, they improve performance on the task that the human and the conversational agent are conducting together.},
	language = {fr},
	number = {2-3},
	urldate = {2021-12-09},
	journal = {Reseaux},
	author = {Cassell, Justine},
	month = may,
	year = {2020},
	note = {Bibliographie\_available: 1
Cairndomain: www.cairn-int.info
Cite Par\_available: 0
Publisher: La Découverte},
	pages = {21--45},
}

@article{levinson_original_2012,
	title = {The original sin of cognitive science},
	volume = {4},
	issn = {1756-8765},
	doi = {10.1111/j.1756-8765.2012.01195.x},
	abstract = {Classical cognitive science was launched on the premise that the architecture of human cognition is uniform and universal across the species. This premise is biologically impossible and is being actively undermined by, for example, imaging genomics. Anthropology (including archaeology, biological anthropology, linguistics, and cultural anthropology) is, in contrast, largely concerned with the diversification of human culture, language, and biology across time and space—it belongs fundamentally to the evolutionary sciences. The new cognitive sciences that will emerge from the interactions with the biological sciences will focus on variation and diversity, opening the door for rapprochement with anthropology.},
	language = {en},
	number = {3},
	journal = {Topics in Cognitive Science},
	author = {Levinson, Stephen C.},
	year = {2012},
	pages = {1--8},
}

@article{frith_mystery_2022,
	title = {The mystery of the brain–culture interface},
	volume = {26},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661322002091},
	doi = {10.1016/j.tics.2022.08.013},
	abstract = {Nature and culture work together to shape who we are. We are embedded in culture and are profoundly influenced by what those around us say and do. The interface between minds occurs at the level of explicit metacognition, which is at the top of our brain's control hierarchy. But how do our brains do this?},
	language = {en},
	number = {12},
	urldate = {2022-12-13},
	journal = {Trends in Cognitive Sciences},
	author = {Frith, Chris D. and Frith, Uta},
	month = dec,
	year = {2022},
	keywords = {explicit metacognition, instructions, processing hierarchy, top-down control},
	pages = {1023--1025},
}

@article{de_jaegher_seeing_2021,
	title = {Seeing and inviting participation in autistic interactions},
	doi = {10.1177/13634615211009627},
	journal = {Transcultural Psychiatry},
	author = {De Jaegher, Hanne},
	year = {2021},
}

@inproceedings{bennett_emergent_2021,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '21},
	title = {Emergent interaction: {Complexity}, dynamics, and enaction in {HCI}},
	isbn = {978-1-4503-8095-9},
	shorttitle = {Emergent {Interaction}},
	url = {https://doi.org/10.1145/3411763.3441321},
	doi = {10.1145/3411763.3441321},
	abstract = {We propose a workshop on methods and theories for dealing with complex dynamical systems, and their application in HCI. Such methods are increasingly relevant across a wide range of disciplines which focus on human behaviour, applied to understand the role of context and interactions in the behaviour of individuals and groups, and how they unfold over time. Traditional approaches to quantifying and modelling behaviour in HCI have tended to focus primarily on individuals and components. Complexity methods shift the focus onto interactions between components, and the emergence of behaviour from complex networks of interactions, as for example in Enactivist approaches to cognitive science. While we believe that complexity methods can be highly informative to HCI researchers, uptake in the community remains low due to widespread unfamiliarity. This one-day workshop will introduce, support, and encourage the development and adoption of complexity methods within HCI. Reflecting the multidisciplinary mix within complexity science, we will draw on examples of complexity-oriented theories and methods from a range of disciplines, including Control-Theory, Social Science, and Cognitive Science. Attendees will engage in group discussions and a Q\&A with a panel, and a discussion group will be set up ahead of time to encourage exploratory conversations. In this way, diverse backgrounds can be brought together, matched, and inform one another.},
	urldate = {2022-12-13},
	booktitle = {Extended {Abstracts} of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Bennett, Dan and Dix, Alan and Eslambolchilar, Parisa and Feng, Feng and Froese, Tom and Kostakos, Vassilis and Lerique, Sebastien and van Berkel, Niels},
	editor = {Kitamura, Yoshifumi and Quigley, Aaron and Isbister, Katherine and Igarashi, Takeo},
	month = may,
	year = {2021},
	keywords = {Human Computer Interaction, causality, cognitive science, complexity, computational interaction, control theory, embodiment, enactivism, ubicomp},
}

@inproceedings{gregoromichelaki_language_2022,
	title = {Language and cognition as distributed process interactions},
	booktitle = {Proceedings of the 26th {Workshop} on the {Semantics} and {Pragmatics} of {Dialogue}},
	author = {Gregoromichelaki, Eleni and Eshghi, Arash and Howes, Christine and Mills, Gregory J. and Kempson, Ruth and Hough, Julian and Healey, Patrick GT and Purver, Matthew},
	editor = {Gregoromichelaki, Eleni and Hough, Julian and Kelleher, John D.},
	year = {2022},
	pages = {160--171},
}

@misc{maisto_interactive_2022,
	title = {Interactive inference: a multi-agent model of cooperative joint actions},
	shorttitle = {Interactive inference},
	url = {http://arxiv.org/abs/2210.13113},
	doi = {10.48550/arXiv.2210.13113},
	abstract = {We advance a novel computational model of multi-agent, cooperative joint actions that is grounded in the cognitive framework of active inference. The model assumes that to solve a joint task, such as pressing together a red or blue button, two (or more) agents engage in a process of interactive inference. Each agent maintains probabilistic beliefs about the goal of the joint task (e.g., should we press the red or blue button?) and updates them by observing the other agent's movements, while in turn selecting movements that make his own intentions legible and easy to infer by the other agent (i.e., sensorimotor communication). Over time, the interactive inference aligns both the beliefs and the behavioral strategies of the agents, hence ensuring the success of the joint action. We exemplify the functioning of the model in two simulations. The first simulation illustrates a ''leaderless'' joint action. It shows that when two agents lack a strong preference about their joint task goal, they jointly infer it by observing each other's movements. In turn, this helps the interactive alignment of their beliefs and behavioral strategies. The second simulation illustrates a "leader-follower" joint action. It shows that when one agent ("leader") knows the true joint goal, it uses sensorimotor communication to help the other agent ("follower") infer it, even if doing this requires selecting a more costly individual plan. These simulations illustrate that interactive inference supports successful multi-agent joint actions and reproduces key cognitive and behavioral dynamics of "leaderless" and "leader-follower" joint actions observed in human-human experiments. In sum, interactive inference provides a cognitively inspired, formal framework to realize cooperative joint actions and consensus in multi-agent systems.},
	urldate = {2022-12-13},
	publisher = {arXiv},
	author = {Maisto, Domenico and Donnarumma, Francesco and Pezzulo, Giovanni},
	month = dec,
	year = {2022},
	note = {arXiv:2210.13113 [cs, math, q-bio]},
}

@article{rosaldo_things_1982,
	title = {The {Things} {We} {Do} with {Words}: {Ilongot} {Speech} {Acts} and {Speech} {Act} {Theory} in {Philosophy}},
	volume = {11},
	issn = {0047-4045},
	shorttitle = {The {Things} {We} {Do} with {Words}},
	abstract = {{\textless}p{\textgreater}I begin by introducing the Ilongots and some of their attitudes toward speech. Whereas most modern theorists think of language as a tool designed primarily to "express" or to "refer," Ilongots think of language first in terms of action. They see commands as the exemplary act of speech, displaying less concern for the subjective meanings that an utterance conveys than for the social contexts in which utterances are heard. An ethnographic sketch thus outlines how Ilongots think of words and how their thought relates to aspects of their practice -- providing an external foil for theorists found closer to home. Speech Act Theory is discussed and questioned first on internal grounds, as an approach that recognizes but slights important situational and cultural constraints on forms of language use. A consideration of the application of Searle's taxonomy of acts of speech to Ilongot categories of language use then leads to a clarification of the individualistic and relatively asocial biases of his essentially intra-cultural account. Last, I return to Ilongot directives. A partial analysis of Ilongot acts of speech provides the basis for a statement of the ways in which indigenous categories are related to the forms that actions take, as both of these, in turn, reflect the sociocultural ordering of local worlds.},
	number = {2},
	journal = {Language in Society},
	author = {Rosaldo, Michelle Z.},
	year = {1982},
	pages = {203--237},
}

@article{schegloff_confirming_1996,
	title = {Confirming {Allusions}: {Toward} an {Empirical} {Account} of {Action}},
	volume = {102},
	issn = {00029602},
	shorttitle = {Confirming {Allusions}},
	abstract = {As part of a larger effort to develop an empirically grounded theory of action, this article describes a previously undescribed action that occurs in talk-in-interaction. The practice of agreeing with another by repeating what they have said is shown to constitute the action of confirming an allusion-that is, confirming both its "content" and its prior inexplicit conveyance. The author reviews the past treatment of "action" in sociology and the key constraints on undertaking an empirically grounded account. The account of "confirming allusions" is offered to exemplify what this undertaking will involve: several instances of an unremarkable usage in conversation are displayed and used to formulate a puzzle, a database is developed for the exploration of the target usage, and a candidate solution to the puzzle is formulated, exemplified, and defended through a range of analytic techniques. The linkage between the practice and the action that it implements is analytically sketched by examining other uses of repetition in talk-in-interaction. In conclusion, the significance of both the theme and the analysis for studies of interaction and culture and for sociological theory is discussed.},
	number = {1},
	journal = {The American Journal of Sociology},
	author = {Schegloff, Emanuel A.},
	month = jul,
	year = {1996},
	pages = {161--216},
}

@article{strathern_improvement_1996,
	title = {From {Improvement} to {Enhancement}: {An} {Anthropological} {Comment} on the {Audit} {Culture}},
	volume = {19},
	issn = {0305-7674},
	shorttitle = {From {Improvement} to {Enhancement}},
	number = {3},
	journal = {Cambridge Anthropology},
	author = {Strathern, Marilyn},
	year = {1996},
	pages = {1--21},
}

@incollection{button_going_1990,
	address = {London},
	title = {Going {Up} a {Blind} {Alley}: {Conflating} {Conversation} {Analysis} and {Computational} {Modelling}},
	isbn = {978-0-08-050264-9},
	shorttitle = {Chapter 4 - {Going} {Up} a {Blind} {Alley}},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080502649500099},
	abstract = {This chapter discusses the desirability of developing computational models of conversational phenomena, and the supportive role given to conversation analysis (CA) in the development of such models. The arguments presented in this chapter are not an attempt to restrict the range of creative resources that software designers might turn to for inspiration. In particular, it is implicitly endorsed in the attempts to develop descriptively adequate models of conversation for use in computer systems, and explicitly endorsed when it is argued that by providing a simulacrum of conversation one has naturally occurring conversation between computers and humans. The attraction of CA for people who want to develop rules of conversational organization that can be used to program computers is two-fold: (1) CA might seem to provide a ready-made package of conversational rules that they can use or adapt for their purposes; and (2) their models may be authorized by appealing to CA. However, CA is used to authorize computational models of conversation that misrepresent the details of how conversation works.},
	language = {en},
	urldate = {2022-03-20},
	booktitle = {Computers and {Conversation}},
	publisher = {Academic Press},
	author = {Button, Graham},
	editor = {Luff, Paul and Gilbert, Nigel and Frohlich, David},
	month = jan,
	year = {1990},
	doi = {10.1016/B978-0-08-050264-9.50009-9},
	pages = {67--90},
}

@article{zinken_comparative_2020,
	title = {The {Comparative} {Study} of {Social} {Action}: {What} {You} {Must} and {What} {You} {Can} {Do} to {Align} with a {Prior} {Speaker}},
	volume = {0},
	issn = {0835-1813},
	shorttitle = {The {Comparative} {Study} of {Social} {Action}},
	doi = {10.1080/08351813.2020.1826764},
	abstract = {This article makes an empirical and a methodological contribution to the comparative study of action. The empirical contribution is a comparative study of three distinct types of action regularly accomplished with the turn format du meinst x (“you mean/think x”) in German: candidate understandings, formulations of the other’s mind, and requests for a judgment. These empirical materials are the basis for a methodological exploration of different levels of researcher abstraction in the comparative study of action. Two levels are examined: the (coarser) level of conditionally relevant responses (what a response speaker must do to align with the action of the prior turn) and the (finer) level of “full alignment” (what a response speaker can do to align with the action of a prior turn). Both levels of abstraction provide empirically viable and analytically interesting descriptive concepts for the comparative study of action. Data are in German.},
	number = {0},
	journal = {Research on Language and Social Interaction},
	author = {Zinken, Jörg},
	month = oct,
	year = {2020},
	pages = {1--20},
}

@article{sharrock_ethnography_2004,
	title = {Ethnography, ethnomethodology and the problem of generalisation in design},
	volume = {13},
	issn = {0960-085X},
	doi = {10.1057/palgrave.ejis.3000502},
	abstract = {This paper discusses the relationship between sociological theory and method, ethnomethodology and design. It argues that social science theoretical and methodological interests cannot form a basis for interdisciplinarity. Much of the argument about the relevance of ethnography for design, and more specifically about ethnomethodological enquiry, has been cast firstly as problems of method and secondly in terms of the problem of generalisation. We argue that in both instances the problem is miscast. Drawing on the arguments of Wittgenstein and Winch, we suggest that forms of generalisation are to be found in ethnomethodological enquiry and that they may be useful in design-related enquiry. We further suggest, however, that they are not the forms to be found in explanatory social science.},
	number = {3},
	journal = {European Journal of Information Systems},
	author = {Sharrock, Wes and Randall, Dave},
	month = sep,
	year = {2004},
	keywords = {Ethnomethodology, design, ethnography, generality, organisations, sociological analysis},
	pages = {186--194},
}

@article{schegloff_preference_1977,
	title = {The {Preference} for {Self}-{Correction} in the {Organization} of {Repair} in {Conversation}},
	volume = {53},
	issn = {00978507},
	abstract = {An 'organization of repair' operates in conversation, addressed to recurrent problems in speaking, hearing, and understanding. Several features of that organization are introduced to explicate the mechanism which produces a strong empirical skewing in which self-repair predominates over other-repair, and to show the operation of a preference for self-repair in the organization of repair. Several consequences of the preference for self-repair for conversational interaction are sketched.},
	number = {2},
	journal = {Language},
	author = {Schegloff, Emanuel A. and Jefferson, Gail and Sacks, Harvey},
	month = jun,
	year = {1977},
	pages = {361--382},
}

@inproceedings{walker_paradise_1997,
	address = {Madrid, Spain},
	title = {{PARADISE}: {A} {Framework} for {Evaluating} {Spoken} {Dialogue} {Agents}},
	shorttitle = {{PARADISE}},
	url = {https://aclanthology.org/P97-1035},
	doi = {10.3115/976909.979652},
	urldate = {2022-12-12},
	booktitle = {35th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and 8th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Walker, Marilyn A. and Litman, Diane J. and Kamm, Candace A. and Abella, Alicia},
	month = jul,
	year = {1997},
	pages = {271--280},
}

@article{schegloff_repair_1992,
	title = {Repair {After} {Next} {Turn}: {The} {Last} {Structurally} {Provided} {Defense} of {Intersubjectivity} in {Conversation}},
	volume = {97},
	issn = {00029602},
	shorttitle = {Repair {After} {Next} {Turn}},
	abstract = {Organizational features of ordinary conversation and other talk-in-interaction provide for the routine display of participants' understanding of one anothers' conduct and of the field of action, thereby building in a routine grounding for intersubjectivity. This same organization provides interactants the resources for recognizing breakdowns of intersubjectivity and for repairing them. This article sets the concern with intersubjectivity in theoretical context, sketches the organization by which it is grounded and defended in ordinary interaction, describes the practices by which trouble in understanding is dealt with, and illustrates what happens when this organization fails to function. Some consequences for contemporary theory and inquiry are suggested.},
	number = {5},
	journal = {The American Journal of Sociology},
	author = {Schegloff, Emanuel A.},
	month = mar,
	year = {1992},
	pages = {1295--1345},
}

@article{sacks_simplest_1974,
	title = {A {Simplest} {Systematics} for the {Organization} of {Turn}-{Taking} for {Conversation}},
	volume = {50},
	issn = {00978507},
	number = {4},
	journal = {Language},
	author = {Sacks, Harvey and Schegloff, Emanuel A. and Jefferson, Gail},
	month = dec,
	year = {1974},
	pages = {696--735},
}

@article{ryokai_virtual_2003,
	title = {Virtual peers as partners in storytelling and literacy learning},
	volume = {19},
	issn = {1365-2729},
	doi = {10.1046/j.0266-4909.2003.00020.x},
	abstract = {Literacy learning — learning how to read and write — begins long before children enter school. One of the key skills to reading and writing is the ability to represent thoughts symbolically and share them in language with an audience who may not necessarily share the same temporal and spatial context. Children learn and practice these important language skills everyday, telling stories with the peers and adults around them. In particular, storytelling in the context of peer collaboration provides a key environment for children to learn language skills important for literacy. In light of this, an embodied conversational agent, Sam, who tells stories collaboratively with children was designed. Sam looks like a peer for pre-school children, but tells stories in a developmentally advanced way, modelling narrative skills important for literacy. Results demonstrated that children who played with the virtual peer told stories that more closely resembled the virtual peer's linguistically advanced stories: using more quoted speech and temporal and spatial expressions. In addition, children listened to Sam's stories carefully, assisting her and suggesting improvements. The potential benefits of having technology play a social role in young children's literacy learning is discussed.},
	language = {en},
	number = {2},
	journal = {Journal of Computer Assisted Learning},
	author = {Ryokai, K. and Vaucelle, C. and Cassell, J.},
	year = {2003},
	pages = {195--208},
}

@incollection{robinson_overall_2012,
	title = {Overall {Structural} {Organization}},
	isbn = {978-1-118-32500-1},
	abstract = {This chapter contains sections titled: * Introduction * Activity * The Overall Structural Organization of Entire, Single Occasions of Interaction * Future Directions},
	language = {en},
	booktitle = {The {Handbook} of {Conversation} {Analysis}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Robinson, Jeffrey D.},
	editor = {Sidnell, Jack and Stivers, Tanya},
	year = {2012},
	pages = {257--280},
}

@inproceedings{reeves_conversational_2017,
	title = {Some conversational challenges of talking with machines},
	url = {http://eprints.nottingham.ac.uk/id/eprint/40510},
	abstract = {A surge of interest in the capabilities of so-called 'conversational' technologies—both from research and industrial contexts—furnishes CSCW and HCI with opportunities to enrich and leverage its historic connection to conversation analysis (and relatedly, ethnomethodology) in novel ways. This paper explores a number of preliminary interactional troubles one might encounter when 'talking to' conversational agents, and in doing so sketches out possible routes forward in the empirical study of agents as collaborative technologies, as well as touching on further conceptual challenges that face research in this area.},
	booktitle = {Talking with {Conversational} {Agents} in {Collaborative} {Action}, {Workshop} at the 20th {ACM} conference on {Computer}-{Supported} {Cooperative} {Work} and {Social} {Computing} ({CSCW} '17)},
	author = {Reeves, Stuart},
	year = {2017},
}

@article{ni_recent_2022,
	title = {Recent advances in deep learning based dialogue systems: a systematic survey},
	issn = {1573-7462},
	shorttitle = {Recent advances in deep learning based dialogue systems},
	url = {https://doi.org/10.1007/s10462-022-10248-8},
	doi = {10.1007/s10462-022-10248-8},
	abstract = {Dialogue systems are a popular natural language processing (NLP) task as it is promising in real-life applications. It is also a complicated task since many NLP tasks deserving study are involved. As a result, a multitude of novel works on this task are carried out, and most of them are deep learning based due to their outstanding performance. In this survey, we mainly focus on the deep learning based dialogue systems. We comprehensively review state-of-the-art research outcomes in dialogue systems and analyze them from two angles: model type and system type. Specifically, from the angle of model type, we discuss the principles, characteristics, and applications of different models that are widely used in dialogue systems. This will help researchers acquaint these models and see how they are applied in state-of-the-art frameworks, which is rather helpful when designing a new dialogue system. From the angle of system type, we discuss task-oriented and open-domain dialogue systems as two streams of research, providing insight into the hot topics related. Furthermore, we comprehensively review the evaluation methods and datasets for dialogue systems to pave the way for future research. Finally, some possible research trends are identified based on the recent research outcomes. To the best of our knowledge, this survey is the most comprehensive and up-to-date one at present for deep learning based dialogue systems, extensively covering the popular techniques. We speculate that this work is a good starting point for academics who are new to the dialogue systems or those who want to quickly grasp up-to-date techniques in this area.},
	language = {en},
	urldate = {2022-12-12},
	journal = {Artificial Intelligence Review},
	author = {Ni, Jinjie and Young, Tom and Pandelea, Vlad and Xue, Fuzhao and Cambria, Erik},
	month = aug,
	year = {2022},
}

@article{nass_machines_2000,
	title = {Machines and {Mindlessness}: {Social} {Responses} to {Computers}},
	volume = {56},
	issn = {1540-4560},
	shorttitle = {Machines and {Mindlessness}},
	doi = {10.1111/0022-4537.00153},
	abstract = {Following Langer (1992), this article reviews a series of experimental studies that demonstrate that individuals mindlessly apply social rules and expectations to computers. The first set of studies illustrates how individuals overuse human social categories, applying gender stereotypes to computers and ethnically identifying with computer agents. The second set demonstrates thatpeople exhibit overlearned social behaviors such as politeness and reciprocity toward computers. In the third set of studies, premature cognitive commitments are demonstrated: A specialist television set is perceived as providing better content than a generalist television set. A final series of studies demonstrates the depth of social responses with respect to computer ‘personality.’ Alternative explanations for these findings, such asanthropomorphism and intentional social responses, cannot explain the results. We conclude with an agenda for future research.},
	language = {en},
	number = {1},
	journal = {Journal of Social Issues},
	author = {Nass, Clifford and Moon, Youngme},
	year = {2000},
	pages = {81--103},
}

@article{moore_ibm_2022,
	title = {The {IBM} natural conversation framework: a new paradigm for conversational {UX} design},
	volume = {0},
	issn = {0737-0024},
	shorttitle = {The {IBM} natural conversation framework},
	doi = {10.1080/07370024.2022.2081571},
	number = {0},
	journal = {Human–Computer Interaction},
	author = {Moore, Robert J. and An, Sungeun and Ren, Guang-Jie},
	month = jun,
	year = {2022},
	keywords = {Conversation Analysis, Conversational user interfaces, chatbots, conversational UX design, voice assistants},
	pages = {1--26},
}

@article{levinson_pre-observations_1981,
	title = {Some pre-observations on the modelling of dialogue},
	volume = {4},
	abstract = {Focuses on the pre-observations on the modeling of dialogue. Assumptions that underlie speech act models of dialogue; Identifiability of utterance units corresponding to unit acts; Capacity of the models to model the actual properties of natural dialogue.},
	number = {2},
	journal = {Discourse Processes},
	author = {Levinson, Stephen C.},
	year = {1981},
	pages = {93--116},
}

@inproceedings{lu_unsupervised_2022,
	title = {Unsupervised {Learning} of {Hierarchical} {Conversation} {Structure}},
	url = {https://aclanthology.org/2022.findings-emnlp.415},
	abstract = {Bo-Ru Lu, Yushi Hu, Hao Cheng, Noah A. Smith, Mari Ostendorf. Findings of the Association for Computational Linguistics: EMNLP 2022. 2022.},
	language = {en-us},
	urldate = {2022-12-12},
	author = {Lu, Bo-Ru and Hu, Yushi and Cheng, Hao and Smith, Noah A. and Ostendorf, Mari},
	month = dec,
	year = {2022},
	pages = {5657--5670},
}

@inproceedings{kharitonov_text-free_2022,
	address = {Dublin, Ireland},
	title = {Text-{Free} {Prosody}-{Aware} {Generative} {Spoken} {Language} {Modeling}},
	doi = {10.18653/v1/2022.acl-long.593},
	abstract = {Speech pre-training has primarily demonstrated efficacy on classification tasks, while its capability of generating novel speech, similar to how GPT-2 can generate coherent paragraphs, has barely been explored. Generative Spoken Language Modeling (GSLM) (CITATION) is the only prior work addressing the generative aspect of speech pre-training, which builds a text-free language model using discovered units. Unfortunately, because the units used in GSLM discard most prosodic information, GSLM fails to leverage prosody for better comprehension and does not generate expressive speech. In this work, we present a prosody-aware generative spoken language model (pGSLM). It is composed of a multi-stream transformer language model (MS-TLM) of speech, represented as discovered unit and prosodic feature streams, and an adapted HiFi-GAN model converting MS-TLM outputs to waveforms. Experimental results show that the pGSLM can utilize prosody to improve both prosody and content modeling, and also generate natural, meaningful, and coherent speech given a spoken prompt. Audio samples can be found at https://speechbot.github.io/pgslm. Codes and models are available at https://github.com/pytorch/fairseq/tree/main/examples/textless\_nlp/pgslm.},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Kharitonov, Eugene and Lee, Ann and Polyak, Adam and Adi, Yossi and Copet, Jade and Lakhotia, Kushal and Nguyen, Tu Anh and Riviere, Morgane and Mohamed, Abdelrahman and Dupoux, Emmanuel and Hsu, Wei-Ning},
	month = may,
	year = {2022},
	pages = {8666--8681},
}

@article{lakhotia_generative_2021,
	title = {On {Generative} {Spoken} {Language} {Modeling} from {Raw} {Audio}},
	abstract = {We introduce Generative Spoken Language Modeling, the task of learning the acoustic and linguistic characteristics of a language from raw audio (no text, no labels), and a set of metrics to automatically evaluate the learned representations at acoustic and linguistic levels for both encoding and generation. We set up baseline systems consisting of a discrete speech encoder (returning pseudo-text units), a generative language model (trained on pseudo-text), and a speech decoder (generating a waveform from pseudo-text) all trained without supervision and validate the proposed metrics with human evaluation. Across 3 speech encoders (CPC, wav2vec 2.0, HuBERT), we find that the number of discrete units (50, 100, or 200) matters in a task-dependent and encoder-dependent way, and that some combinations approach text-based systems.},
	language = {en},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Lakhotia, Kushal and Kharitonov, Evgeny and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Adelrahman and Dupoux, Emmanuel},
	month = feb,
	year = {2021},
}

@article{heritage_terms_2005,
	title = {The {Terms} of {Agreement}: {Indexing} {Epistemic} {Authority} and {Subordination} in {Talk}-in-{Interaction}},
	volume = {68},
	issn = {01902725},
	shorttitle = {The {Terms} of {Agreement}},
	abstract = {Within the general framework of agreement on a state of affairs, the matter of the terms of agreement can remain: determining whose view is the more significant or more authoritative with respect to the matter at hand. In this paper we focus on this issue as it is played out in assessment sequences. We examine four practices through which a second speaker can index the independence of an agreeing assessment from that of a first speaker, and in this way can qualify the agreement. We argue that these practices reduce the responsiveness of the second assessment to the first; in this way they resist any claim to epistemic authority that may be indexed by the first speaker in "going first" in assessing some state of affairs.},
	number = {1},
	journal = {Social Psychology Quarterly},
	author = {Heritage, John and Raymond, Geoffrey},
	month = mar,
	year = {2005},
	pages = {15--38},
}

@article{frohlich_management_1994,
	title = {Management of {Repair} in {Human}-{Computer} {Interaction}},
	volume = {9},
	issn = {0737-0024},
	doi = {10.1080/07370024.1994.9667211},
	abstract = {This article reports an investigation of the initiation and management of repair in human-computer interaction from a conversation-analytic perspective. It describes some ways in which pairs of novice users deal with what they see as "trouble" in the operation of a multiwindow database system called Sales and Marketing Information (SAM). A typical sequence has the character of a user request followed by a pause or computer granting, leading to user repair in initial or third position. Three components of repair are identified: The user attempts to get the computer to undo a previous granting, redo a previous request, or grant a new request. Some common ways in which these components are combined, ordered, and performed are illustrated with reference to transcripts of actual sequences of recorded interaction. The relevance of these findings for design is discussed, together with the future potential of the approach that generated them.},
	number = {3-4},
	journal = {Human–Computer Interaction},
	author = {Frohlich, David and Drew, Paul and Monk, Andrew},
	month = sep,
	year = {1994},
	pages = {385--425},
}

@incollection{muhleisen_rude_2005,
	title = {Rude sounds: {Kiss} {Teeth} and negotiation of the public sphere},
	isbn = {978-90-272-9416-6},
	abstract = {Politeness and Face in Caribbean Creoles is the first collection to focus on socio-pragmatic issues in the Caribbean context, including the socio-cultural rules and principles underlying strategic language use. While the Caribbean has long been recognized as a rich and interesting site where cultural continuities meet with new "creolized" or innovative practices, questions of politeness practices, constructions of personhood, or the notion of face have so far been neglected in linguistic research on Caribbean Creoles. Drawing on linguistic politeness theory and Goffman's concept of face, eleven mostly fieldwork-based innovative contributions critically examine a range of topics, such as ritual insults, strategic use of "bad language", kiss-teeth, the performance of homophobic threats, greetings, address forms, advice-giving, socialization and discourse, parent-child discourse, register choice and communicative repertoire in the Caribbean context.},
	language = {en},
	booktitle = {Politeness and {Face} in {Caribbean} {Creoles}},
	publisher = {John Benjamins Publishing},
	author = {Figueroa, Esther},
	editor = {Mühleisen, Susanne and Migge, Bettina},
	month = sep,
	year = {2005},
	pages = {73--99},
}

@book{beizer_black-box_1995,
	address = {New York},
	title = {Black-box testing: techniques for functional testing of software and systems},
	isbn = {978-0-471-12094-0},
	shorttitle = {Black-box testing},
	publisher = {Wiley},
	author = {Beizer, Boris},
	year = {1995},
}

@article{bichard_quotidian_2014,
	title = {Quotidian {Ritual} and {Work}-{Life} {Balance}: {An} {Ethnography} of {Not} {Being} {There}},
	volume = {2014},
	issn = {1559-8918},
	shorttitle = {Quotidian {Ritual} and {Work}-{Life} {Balance}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1559-8918.01019},
	doi = {10.1111/1559-8918.01019},
	abstract = {This paper reports on current interdisciplinary design research that explores values held by individuals in their performance of everyday or ‘quotidian’ rituals in family life. The work is focused on mobile workers who may be away from home and family for extended and/or regular periods of time. During the course of the research, a key hurdle that has arisen has revolved around gaining access to families for the purpose of conducting traditional ethnographic studies. For many mobile workers who are separated from the family on a regular basis, the idea of having an ethnographic researcher present during what becomes very limited and therefore sacrosanct family time has proved difficult to negotiate. Therefore the design researchers have had to develop more designerly means of engagement with ‘the field site’ through a series of design interventions that effectively provide forms of ethnographic data when both the researcher and the researched are away from the field site, namely the family home.},
	language = {en},
	number = {1},
	urldate = {2022-12-12},
	journal = {Ethnographic Praxis in Industry Conference Proceedings},
	author = {Bichard, Jo-Anne and Yurman, Paulina and Kirk, David and Chatting, David},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1559-8918.01019},
	pages = {163--178},
}

@misc{parthasarathi_how_2020,
	title = {How {To} {Evaluate} {Your} {Dialogue} {System}: {Probe} {Tasks} as an {Alternative} for {Token}-level {Evaluation} {Metrics}},
	shorttitle = {How {To} {Evaluate} {Your} {Dialogue} {System}},
	url = {http://arxiv.org/abs/2008.10427},
	doi = {10.48550/arXiv.2008.10427},
	abstract = {Though generative dialogue modeling is widely seen as a language modeling task, the task demands an agent to have a complex natural language understanding of its input text to carry a meaningful interaction with an user. The automatic metrics used evaluate the quality of the generated text as a proxy to the holistic interaction of the agent. Such metrics were earlier shown to not correlate with the human judgement. In this work, we observe that human evaluation of dialogue agents can be inconclusive due to the lack of sufficient information for appropriate evaluation. The automatic metrics are deterministic yet shallow and human evaluation can be relevant yet inconclusive. To bridge this gap in evaluation, we propose designing a set of probing tasks to evaluate dialogue models. The hand-crafted tasks are aimed at quantitatively evaluating a generative dialogue model's understanding beyond the token-level evaluation on the generated text. The probing tasks are deterministic like automatic metrics and requires human judgement in their designing; benefiting from the best of both worlds. With experiments on probe tasks we observe that, unlike RNN based architectures, transformer model may not be learning to comprehend the input text despite its generated text having higher overlap with the target text.},
	urldate = {2022-12-12},
	publisher = {arXiv},
	author = {Parthasarathi, Prasanna and Pineau, Joelle and Chandar, Sarath},
	month = aug,
	year = {2020},
	note = {arXiv:2008.10427 [cs]},
}

@misc{madureira_can_2022,
	title = {Can {Visual} {Dialogue} {Models} {Do} {Scorekeeping}? {Exploring} {How} {Dialogue} {Representations} {Incrementally} {Encode} {Shared} {Knowledge}},
	shorttitle = {Can {Visual} {Dialogue} {Models} {Do} {Scorekeeping}?},
	url = {http://arxiv.org/abs/2204.06970},
	doi = {10.48550/arXiv.2204.06970},
	abstract = {Cognitively plausible visual dialogue models should keep a mental scoreboard of shared established facts in the dialogue context. We propose a theory-based evaluation method for investigating to what degree models pretrained on the VisDial dataset incrementally build representations that appropriately do scorekeeping. Our conclusion is that the ability to make the distinction between shared and privately known statements along the dialogue is moderately present in the analysed models, but not always incrementally consistent, which may partially be due to the limited need for grounding interactions in the original task.},
	urldate = {2022-12-12},
	publisher = {arXiv},
	author = {Madureira, Brielen and Schlangen, David},
	month = apr,
	year = {2022},
	note = {arXiv:2204.06970 [cs]},
}

@article{sai_survey_2022,
	title = {A {Survey} of {Evaluation} {Metrics} {Used} for {NLG} {Systems}},
	volume = {55},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3485766},
	doi = {10.1145/3485766},
	abstract = {In the last few years, a large number of automatic evaluation metrics have been proposed for evaluating Natural Language Generation (NLG) systems. The rapid development and adoption of such automatic evaluation metrics in a relatively short time has created the need for a survey of these metrics. In this survey, we (i) highlight the challenges in automatically evaluating NLG systems, (ii) propose a coherent taxonomy for organising existing evaluation metrics, (iii) briefly describe different existing metrics, and finally (iv) discuss studies criticising the use of automatic evaluation metrics. We then conclude the article highlighting promising future directions of research.},
	number = {2},
	urldate = {2022-12-12},
	journal = {ACM Computing Surveys},
	author = {Sai, Ananya B. and Mohankumar, Akash Kumar and Khapra, Mitesh M.},
	month = jan,
	year = {2022},
	pages = {26:1--26:39},
}

@article{mattelmaki_probing_2008,
	title = {Probing for co-exploring},
	volume = {4},
	issn = {1571-0882},
	url = {https://doi.org/10.1080/15710880701875027},
	doi = {10.1080/15710880701875027},
	abstract = {Designers are facing new kinds of design tasks beyond their traditional expertise that call for tools and practices to facilitate design collaboration. This article focuses on the relations between probing and issues of collaboration and participation. It first introduces the probes approach and then describes how it has been applied to support collaboration and participation in case studies which have been conducted in the context of design research and company collaboration in Finland. The article also discusses the role of probing in enhancing collaboration. It proposes that the probes approach can have roles in supporting an iterative co-exploring of the design space, as well as in facilitating collaboration with various stakeholders in co-design.},
	number = {1},
	urldate = {2022-12-12},
	journal = {CoDesign},
	author = {Mattelmäki, Tuuli},
	month = mar,
	year = {2008},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/15710880701875027},
	pages = {65--78},
}

@book{kempt_chatbots_2020,
	address = {Cham},
	series = {Social and {Cultural} {Studies} of {Robots} and {AI}},
	title = {Chatbots and the {Domestication} of {AI}: {A} {Relational} {Approach}},
	isbn = {978-3-030-56289-2 978-3-030-56290-8},
	shorttitle = {Chatbots and the {Domestication} of {AI}},
	url = {https://link.springer.com/10.1007/978-3-030-56290-8},
	language = {en},
	urldate = {2022-12-12},
	publisher = {Springer International Publishing},
	author = {Kempt, Hendrik},
	year = {2020},
	doi = {10.1007/978-3-030-56290-8},
}

@article{takanashi_field_2019,
	title = {Field {Interaction} {Analysis}: {A} {Second}-{Person} {Viewpoint} {Approach} to {Maai}},
	volume = {37},
	issn = {1882-7055},
	shorttitle = {Field {Interaction} {Analysis}},
	url = {https://doi.org/10.1007/s00354-019-00062-2},
	doi = {10.1007/s00354-019-00062-2},
	abstract = {In this article, we investigate a second-person viewpoint approach to an interactive phenomenon called maai, in which interactants’ own perception and sense of relation to each other are central. In the basic ideas of conversation analysis (CA), one of the powerful methodologies for the second-person viewpoint approach to social interaction, it is paramount that analysts can descriptively trace participants’ orientation to events in progress with reference to sequentiality and simultaneity between actions in interaction.If we focus on detailed practices proper to a field, however, it becomes crucial to seriously consider the “on-line, prospective understanding of ongoing interaction by analysts themselves.” We propose a new framework, field interaction analysis, that expands or complements the basic ideas of CA, putting emphasis on the understanding of participants’ activities, the membership categories relevant to them, and the material environments they are in.On the basis of this new idea, we illustrate two case studies, demonstrating how maai between participants engaged in collaborative activities is manifested in the temporal order of bodily actions and spatial configuration of participants’ bodies in ways characteristic to a particular field.},
	language = {en},
	number = {3},
	urldate = {2022-12-12},
	journal = {New Generation Computing},
	author = {Takanashi, Katsuya and Den, Yasuharu},
	month = sep,
	year = {2019},
	pages = {263--283},
}

@book{hayashi_conversational_2013,
	address = {Cambridge},
	series = {Studies in {Interactional} {Sociolinguistics}},
	title = {Conversational {Repair} and {Human} {Understanding}},
	number = {30},
	publisher = {Cambridge University Press},
	editor = {Hayashi, Makoto and Raymond, Geoffrey and Sidnell, Jack},
	year = {2013},
}

@inproceedings{iseki_characteristics_2019,
	title = {Characteristics of everyday conversation derived from the analysis of dialog act annotation},
	doi = {10.1109/O-COCOSDA46868.2019.9041235},
	abstract = {This paper addresses an attempt to find out the characteristics of everyday conversation data through dialog act information. Although several earlier studies have discussed how to annotate DA information, few studies use the result of the annotation as a clue to derive the characteristics of conversation. We report on the work to annotate dialog act information on utterances in Japanese everyday conversation, and the possibility of extracting the interactional characteristics using the annotation. As a result of the analysis, it was found that the annotation reflects differences in behaviour depending on the type of conversation and participants' age. Also, even in conversations with similar settings, differences were found in the distribution of tags about interactional management. It is suggested that the annotation may also reflect information that is difficult to capture objectively such as the conversational atmosphere.},
	booktitle = {2019 22nd {Conference} of the {Oriental} {COCOSDA} {International} {Committee} for the {Co}-ordination and {Standardisation} of {Speech} {Databases} and {Assessment} {Techniques} ({O}-{COCOSDA})},
	author = {Iseki, Yuriko and Kadota, Keisuke and Den, Yasuharu},
	month = oct,
	year = {2019},
	note = {ISSN: 2472-7695},
	pages = {1--6},
}

@article{__2022,
	title = {相槌の特徴に一致した頷き生成モデル [{Generation} {Model} for {Head} {Nods} {Consistent} with {Features} of {Verbal} {Response} {Tokens}]},
	volume = {37},
	doi = {10.1527/tjsai.37-3_IDS-H},
	abstract = {In human-human interactions, a listener uses both verbal tokens and head nods for responding signals, and they frequently co-occur. When humanoid robots and anthropomorphic agents response to a user using verbal tokens and head nods simultaneously, they must be generated in proper timing to each other and have consistent features. In this paper, we propose models to predict co-occurrence and physical features of head nods based on prosodic and syntactic features of verbal response tokens. We used, as predictive variables, the forms, positions, durations, averages/standard deviations of fundamental frequency and loudness of response tokens and head positions at the beginning of response tokens. In addition, considering participation framework, we also used speaker's gaze and listener's gaze at the beginning of response tokens, and applied generalized mixed models to predict the co-occurrence, type, range, repetition and velocity of head nods. The results confirmed that proposed models can predict these outcomes effectively.},
	number = {3},
	journal = {人工知能学会論文誌},
	author = {大河, 森 and 康晴, 伝},
	year = {2022},
	pages = {IDS--H\_1--12},
}

@inproceedings{koiso_design_2022,
	address = {Marseille, France},
	title = {Design and {Evaluation} of the {Corpus} of {Everyday} {Japanese} {Conversation}},
	url = {https://aclanthology.org/2022.lrec-1.599},
	abstract = {We have constructed the Corpus of Everyday Japanese Conversation (CEJC) and published it in March 2022. The CEJC is designed to contain various kinds of everyday conversations in a balanced manner to capture their diversity. The CEJC features not only audio but also video data to facilitate precise understanding of the mechanism of real-life social behavior. The publication of a large-scale corpus of everyday conversations that includes video data is a new approach. The CEJC contains 200 hours of speech, 577 conversations, about 2.4 million words, and a total of 1675 conversants. In this paper, we present an overview of the corpus, including the recording method and devices, structure of the corpus, formats of video and audio files, transcription, and annotations. We then report some results of the evaluation of the CEJC in terms of conversant and conversation attributes. We show that the CEJC includes a good balance of adult conversants in terms of gender and age, as well as a variety of conversations in terms of conversation forms, places, activities, and numbers of conversants.},
	urldate = {2022-12-12},
	booktitle = {Proceedings of the {Thirteenth} {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Koiso, Hanae and Amatani, Haruka and Den, Yasuharu and Iseki, Yuriko and Ishimoto, Yuichi and Kashino, Wakako and Kawabata, Yoshiko and Nishikawa, Ken'ya and Tanaka, Yayoi and Usuda, Yasuyuki and Watanabe, Yuka},
	month = jun,
	year = {2022},
	pages = {5587--5594},
}

@inproceedings{wilcock_conversational_2022,
	title = {Conversational {AI} and {Knowledge} {Graphs} for {Social} {Robot} {Interaction}},
	doi = {10.1109/HRI53351.2022.9889583},
	abstract = {The paper describes an approach that combines work from three fields with previously separate research commu-nities: social robotics, conversational AI, and graph databases. The aim is to develop a generic framework in which a variety of social robots can provide high-quality information to users by accessing semantically-rich knowledge graphs about multiple different domains. An example implementation uses a Furhat robot with Rasa open source conversational AI and knowledge graphs in Neo4j graph databases.},
	booktitle = {2022 17th {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction} ({HRI})},
	author = {Wilcock, Graham and Jokinen, Kristiina},
	month = mar,
	year = {2022},
	pages = {1090--1094},
}

@inproceedings{mori_use_2021,
	title = {On {The} {Use} of {Gestures} in {Dialogue} {Breakdown} {Detection}},
	doi = {10.1109/O-COCOSDA202152914.2021.9660535},
	abstract = {In this paper, we verified the use of gestures in dialogue breakdown detection. The data is 30 real human-robot conversations annotated with body, hand and head gestures. We used as features the ratio of the duration of each gesture within the 3000 msec interval from the start of the robot's utterance, and applied Support Vector Machine to build a model to predict whether the robot's utterance had caused dialogue breakdown. The results showed that the accuracy of our model was higher than the chance level in multiple metrics. Moreover, it is suggested that in some cases the users reacted to the robot's response with gestures in the same way as in human-human interaction.},
	booktitle = {2021 24th {Conference} of the {Oriental} {COCOSDA} {International} {Committee} for the {Co}-ordination and {Standardisation} of {Speech} {Databases} and {Assessment} {Techniques} ({O}-{COCOSDA})},
	author = {Mori, Taiga and Jokinen, Kristiina and Den, Yasuharu},
	month = nov,
	year = {2021},
	note = {ISSN: 2472-7695},
	pages = {70--75},
}

@inproceedings{angus_pausecode_2018,
	address = {New York, NY, USA},
	series = {{MA3HMI}'18},
	title = {{PauseCode}: {Computational} {Conversation} {Timing} {Analysis}},
	isbn = {978-1-4503-6076-0},
	shorttitle = {{PauseCode}},
	url = {https://doi.org/10.1145/3279972.3279975},
	doi = {10.1145/3279972.3279975},
	abstract = {Pauses play a critical role in adding, shifting or contradicting meaning in a conversation. To enable the study and incorporation of this important modality in computational discourse analytic and processing systems, we require extensible open source pause coding systems and associated software libraries. We designed and implemented a coding and visualisation system for pause and overlap detection and analysis, extending existing voicing and silence detection algorithms. Demonstrating the system using the TalkBank CallFriend and CallHome corpora we show how the approach can be used to code many different kinds of pauses and overlaps within and between interlocutors, and calculate the temporal distribution of these different types of pause and overlap. The coding schema is intended to be combined with other speech modalities to provide novel approaches to predicting social cues and markers, useful for designing more naturalistic conversational agents, and in new tools for measuring turn-taking structure of conversation in greater depth and accuracy.},
	urldate = {2022-12-12},
	booktitle = {Proceedings of the 4th {International} {Workshop} on {Multimodal} {Analyses} {Enabling} {Artificial} {Agents} in {Human}-{Machine} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Angus, Daniel and Yu, Yeyang and Vrbik, Paul and Back, Andrew and Wiles, Janet},
	year = {2018},
	pages = {43--47},
}

@inproceedings{margariti_automated_2022,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '22},
	title = {Automated mapping of competitive and collaborative overlapping talk in video meetings.},
	isbn = {978-1-4503-9156-6},
	url = {https://doi.org/10.1145/3491101.3519612},
	doi = {10.1145/3491101.3519612},
	abstract = {Video meetings are notorious for difficulties with conversational turn-taking, which has impacts on inclusion and outcomes. We present a scalable automatic process to categorize turn-taking patterns in remote meetings based on eyes-off analysis of meeting transcripts. Drawing on a series of remote meetings (10 series, 34 total meetings) recorded in July-August 2021 by employees of a global technology company, we identified and parametrized patterns of cooperative and competitive overlaps of turns. The results show initial success characterizing people's behaviours as either likely to continue or cede turns based on either the amount of overlap that they produce during other's turns or the amount of overlap they experience in their own turns. With further development and validation, this method could be used to measure inclusion in remote and hybrid meetings.},
	urldate = {2022-12-12},
	booktitle = {Extended {Abstracts} of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Margariti, Eleni and Rintel, Sean and Murphy, Brendan and Sellen, Abigail},
	month = apr,
	year = {2022},
	pages = {1--8},
}

@article{pelikan_managing_2022,
	title = {Managing {Delays} in {Human}-{Robot} {Interaction}},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/3569890},
	doi = {10.1145/3569890},
	abstract = {Delays in the completion of joint actions are sometimes unavoidable. How should a robot communicate that it cannot immediately act or respond in a collaborative task? Drawing on video recordings of a face scanning activity in family homes, we investigate how humans make sense of a Cozmo robot’s delays on a moment-by-moment basis. Cozmo’s sounds and embodied actions are recognized as indicators of delay but encourage human participants to act in ways that undermine the scanning process. In comparing the robot’s delay management strategies with human-human vocal and embodied practices, we demonstrate key differences in the sequences that impact how the robot is understood. The study demonstrates how delay events are accomplished as embodied displays that are distributed across co-participants. We present a framework for making delay transparent through situated explanations, particularly in the form of non-lexical sounds and bodily actions.},
	urldate = {2022-12-12},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Pelikan, Hannah and Hofstetter, Emily},
	year = {2022},
	note = {Just Accepted},
}

@inproceedings{zheng_telling_2022,
	address = {New York, NY, USA},
	series = {{CHI} '22},
	title = {Telling {Stories} from {Computational} {Notebooks}: {AI}-{Assisted} {Presentation} {Slides} {Creation} for {Presenting} {Data} {Science} {Work}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {Telling {Stories} from {Computational} {Notebooks}},
	url = {https://doi.org/10.1145/3491102.3517615},
	doi = {10.1145/3491102.3517615},
	abstract = {Creating presentation slides is a critical but time-consuming task for data scientists. While researchers have proposed many AI techniques to lift data scientists’ burden on data preparation and model selection, few have targeted the presentation creation task. Based on the needs identified from a formative study, this paper presents NB2Slides, an AI system that facilitates users to compose presentations of their data science work. NB2Slides uses deep learning methods as well as example-based prompts to generate slides from computational notebooks, and take users’ input (e.g., audience background) to structure the slides. NB2Slides also provides an interactive visualization that links the slides with the notebook to help users further edit the slides. A follow-up user evaluation with 12 data scientists shows that participants believed NB2Slides can improve efficiency and reduces the complexity of creating slides. Yet, participants questioned the future of full automation and suggested a human-AI collaboration paradigm.},
	urldate = {2022-12-12},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zheng, Chengbo and Wang, Dakuo and Wang, April Yi and Ma, Xiaojuan},
	month = apr,
	year = {2022},
	pages = {1--20},
}

@inproceedings{scharenborg_building_2017,
	address = {Casablanca},
	title = {Building an {ASR} {System} for a {Low}-resource {Language} {Through} the {Adaptation} of a {High}-resource {Language} {ASR} {System}: {Preliminary} {Results}},
	abstract = {For many languages in the world, not enough (annotated) speech data is available to train an ASR system. We here propose a new three-step method to build an ASR system for such a low-resource language, and test four measures to improve the system’s success. In the first step, we build a phone recognition system on a high-resource language. In the second step, missing low-resource language acoustic units are created through extrapolation from acoustic units present in the highresource language. In the third step, iteratively, the adapted model is used to create a phone transcription of the low-resource language, after which the model is retrained using the resulting self-labelled phone sequences to improve the acoustic phone units of the low-resource language. Four measures are investigated to determine which self-labelled transcriptions are ‘good enough’ to retrain the adaptation model, and improve the quality of the phone speech tokens and subsequent phone transcriptions: TTS and decoding accuracy to capture acoustic information, a translation retrieval task to capture semantic information, and a combination of these three. The results showed that in order to train acoustic units using self-labelled data, training utterances are preferably needed that capture multiple aspects of the speech signal.},
	language = {en},
	booktitle = {{ICNLSSP}},
	author = {Scharenborg, Odette and Ciannella, Francesco and Palaskar, Shruti and Black, Alan and Metze, Florian and Ondel, Lucas and Hasegawa-Johnson, Mark},
	year = {2017},
}

@inproceedings{liesenfeld_building_2022,
	address = {Marseille},
	title = {Building and curating conversational corpora for diversity-aware language science and technology},
	abstract = {We present an analysis pipeline and best practice guidelines for building and curating corpora of everyday conversation in diverse languages. Surveying language documentation corpora and other resources that cover 67 languages and varieties from 28 phyla, we describe the compilation and curation process, specify minimal properties of a unified format for interactional data, and develop methods for quality control that take into account turn-taking and timing. Two case studies show the broad utility of conversational data for (i) charting human interactional infrastructure and (ii) tracing challenges and opportunities for current ASR solutions. Linguistically diverse conversational corpora can provide new insights for the language sciences and stronger empirical foundations for language technology.},
	booktitle = {Proceedings of the 13th {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2022)},
	author = {Liesenfeld, Andreas and Dingemanse, Mark},
	month = jun,
	year = {2022},
	note = {arXiv: 2203.03399},
	pages = {1178--1192},
}

@article{mlynar_how_2022,
	title = {How is {Oral} {History} {Possible}? {On} {Linguistically} {Universal} and {Topically} {Specific} {Knowledge}},
	volume = {49},
	issn = {0094-0798},
	shorttitle = {How is {Oral} {History} {Possible}?},
	url = {https://doi.org/10.1080/00940798.2022.2050412},
	doi = {10.1080/00940798.2022.2050412},
	abstract = {Conducting oral history interviews or using them as research and educational resources requires the (mostly tacit) background knowledge necessary for understanding an interview or its excerpts. Taking the topic of commemoration and remembrance as a case in point, and analyzing fifteen interviews in the Czech and Slovak languages from the USC Shoah Foundation’s Visual History Archive, this article aims to consider the oral history interview as an interactional accomplishment. I argue that in producing oral histories, the interviewer and the interviewee draw on linguistically universal and topically specific knowledge, which are also the resources audiences use to grasp what the interview addresses. The article concludes with a discussion of the relationships between these notions and their connection to different temporalities of oral history interviews and levels of understanding. Finally, I outline future research directions and questions inspired by this framework. By studying the linguistic and interactional constitution of oral history interviews, we can arrive at a better understanding of the very nature of oral history that can inform the use of archived interviews in research and education.},
	number = {1},
	urldate = {2022-12-08},
	journal = {The Oral History Review},
	author = {Mlynář, Jakub},
	month = jan,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/00940798.2022.2050412},
	pages = {116--132},
}

@inproceedings{zhu_convlab-2_2020,
	address = {Online},
	title = {{ConvLab}-2: {An} {Open}-{Source} {Toolkit} for {Building}, {Evaluating}, and {Diagnosing} {Dialogue} {Systems}},
	shorttitle = {{ConvLab}-2},
	url = {https://aclanthology.org/2020.acl-demos.19},
	doi = {10.18653/v1/2020.acl-demos.19},
	abstract = {We present ConvLab-2, an open-source toolkit that enables researchers to build task-oriented dialogue systems with state-of-the-art models, perform an end-to-end evaluation, and diagnose the weakness of systems. As the successor of ConvLab, ConvLab-2 inherits ConvLab's framework but integrates more powerful dialogue models and supports more datasets. Besides, we have developed an analysis tool and an interactive tool to assist researchers in diagnosing dialogue systems. The analysis tool presents rich statistics and summarizes common mistakes from simulated dialogues, which facilitates error analysis and system improvement. The interactive tool provides an user interface that allows developers to diagnose an assembled dialogue system by interacting with the system and modifying the output of each system component.},
	urldate = {2022-12-08},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Zhu, Qi and Zhang, Zheng and Fang, Yan and Li, Xiang and Takanobu, Ryuichi and Li, Jinchao and Peng, Baolin and Gao, Jianfeng and Zhu, Xiaoyan and Huang, Minlie},
	month = jul,
	year = {2020},
	pages = {142--149},
}

@inproceedings{shuster_am_2022,
	title = {Am {I} {Me} or {You}? {State}-of-the-{Art} {Dialogue} {Models} {Cannot} {Maintain} an {Identity}},
	shorttitle = {Am {I} {Me} or {You}?},
	url = {https://aclanthology.org/2022.findings-naacl.182},
	abstract = {Kurt Shuster, Jack Urbanek, Arthur Szlam, Jason Weston. Findings of the Association for Computational Linguistics: NAACL 2022. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {NAACL} 2022},
	author = {Shuster, Kurt and Urbanek, Jack and Szlam, Arthur and Weston, Jason},
	month = jul,
	year = {2022},
	pages = {2367--2387},
}

@inproceedings{zhou_deconstructing_2022,
	title = {Deconstructing {NLG} {Evaluation}: {Evaluation} {Practices}, {Assumptions}, and {Their} {Implications}},
	shorttitle = {Deconstructing {NLG} {Evaluation}},
	url = {https://aclanthology.org/2022.naacl-main.24},
	abstract = {Kaitlyn Zhou, Su Lin Blodgett, Adam Trischler, Hal Daumé III, Kaheer Suleman, Alexandra Olteanu. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	booktitle = {Proceedings of the 2022 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	author = {Zhou, Kaitlyn and Blodgett, Su Lin and Trischler, Adam and Iii, Hal Daumé and Suleman, Kaheer and Olteanu, Alexandra},
	month = jul,
	year = {2022},
	pages = {314--324},
}

@inproceedings{sanders_towards_2022,
	title = {Towards a {Progression}-{Aware} {Autonomous} {Dialogue} {Agent}},
	url = {https://aclanthology.org/2022.naacl-main.87},
	abstract = {Abraham Sanders, Tomek Strzalkowski, Mei Si, Albert Chang, Deepanshu Dey, Jonas Braasch, Dakuo Wang. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	booktitle = {Proceedings of the 2022 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	author = {Sanders, Abraham and Strzalkowski, Tomek and Si, Mei and Chang, Albert and Dey, Deepanshu and Braasch, Jonas and Wang, Dakuo},
	month = jul,
	year = {2022},
	pages = {1194--1212},
}

@inproceedings{khaziev_fpi_2022,
	title = {{FPI}: {Failure} {Point} {Isolation} in {Large}-scale {Conversational} {Assistants}},
	shorttitle = {{FPI}},
	url = {https://aclanthology.org/2022.naacl-industry.17},
	abstract = {Rinat Khaziev, Usman Shahid, Tobias Röding, Rakesh Chada, Emir Kapanci, Pradeep Natarajan. Proceedings of NAACL-HLT 2022: Industry Track Papers. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	booktitle = {Proceedings of {NAACL}-{HLT} 2022: {Industry} {Track} {Papers}},
	author = {Khaziev, Rinat and Shahid, Usman and Röding, Tobias and Chada, Rakesh and Kapanci, Emir and Natarajan, Pradeep},
	month = jul,
	year = {2022},
	pages = {141--148},
}

@inproceedings{wang2020improving,
	title = {Improving knowledge-aware dialogue generation via knowledge base question answering},
	volume = {34},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Wang, Jian and Liu, Junhao and Bi, Wei and Liu, Xiaojiang and He, Kejing and Xu, Ruifeng and Yang, Min},
	year = {2020},
	note = {Number: 05},
	pages = {9169--9176},
}

@inproceedings{zhou-etal-2019-unsupervised,
	address = {Hong Kong, China},
	title = {Unsupervised context rewriting for open domain conversation},
	url = {https://aclanthology.org/D19-1192},
	doi = {10.18653/v1/D19-1192},
	abstract = {Context modeling has a pivotal role in open domain conversation. Existing works either use heuristic methods or jointly learn context modeling and response generation with an encoder-decoder framework. This paper proposes an explicit context rewriting method, which rewrites the last utterance by considering context history. We leverage pseudo-parallel data and elaborate a context rewriting network, which is built upon the CopyNet with the reinforcement learning method. The rewritten utterance is beneficial to candidate retrieval, explainable context modeling, as well as enabling to employ a single-turn framework to the multi-turn scenario. The empirical results show that our model outperforms baselines in terms of the rewriting quality, the multi-turn response generation, and the end-to-end retrieval-based chatbots.},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Zhou, Kun and Zhang, Kai and Wu, Yu and Liu, Shujie and Yu, Jingsong},
	month = nov,
	year = {2019},
	pages = {1834--1844},
}

@inproceedings{lin-etal-2019-moel,
	address = {Hong Kong, China},
	title = {{MoEL}: {Mixture} of empathetic listeners},
	url = {https://aclanthology.org/D19-1012},
	doi = {10.18653/v1/D19-1012},
	abstract = {Previous research on empathetic dialogue systems has mostly focused on generating responses given certain emotions. However, being empathetic not only requires the ability of generating emotional responses, but more importantly, requires the understanding of user emotions and replying appropriately. In this paper, we propose a novel end-to-end approach for modeling empathy in dialogue systems: Mixture of Empathetic Listeners (MoEL). Our model first captures the user emotions and outputs an emotion distribution. Based on this, MoEL will softly combine the output states of the appropriate Listener(s), which are each optimized to react to certain emotions, and generate an empathetic response. Human evaluations on EMPATHETIC-DIALOGUES dataset confirm that MoEL outperforms multitask training baseline in terms of empathy, relevance, and fluency. Furthermore, the case study on generated responses of different Listeners shows high interpretability of our model.},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Lin, Zhaojiang and Madotto, Andrea and Shin, Jamin and Xu, Peng and Fung, Pascale},
	month = nov,
	year = {2019},
	pages = {121--132},
}

@inproceedings{xu-etal-2018-better,
	address = {Brussels, Belgium},
	title = {Better conversations by modeling, filtering, and optimizing for coherence and diversity},
	url = {https://aclanthology.org/D18-1432},
	doi = {10.18653/v1/D18-1432},
	abstract = {We present three enhancements to existing encoder-decoder models for open-domain conversational agents, aimed at effectively modeling coherence and promoting output diversity: (1) We introduce a measure of coherence as the GloVe embedding similarity between the dialogue context and the generated response, (2) we filter our training corpora based on the measure of coherence to obtain topically coherent and lexically diverse context-response pairs, (3) we then train a response generator using a conditional variational autoencoder model that incorporates the measure of coherence as a latent variable and uses a context gate to guarantee topical consistency with the context and promote lexical diversity. Experiments on the OpenSubtitles corpus show a substantial improvement over competitive neural models in terms of BLEU score as well as metrics of coherence and diversity.},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Xu, Xinnuo and Dušek, Ondřej and Konstas, Ioannis and Rieser, Verena},
	year = {2018},
	pages = {3981--3991},
}

@inproceedings{parthasarathi-pineau-2018-extending,
	address = {Brussels, Belgium},
	title = {Extending neural generative conversational model using external knowledge sources},
	url = {https://aclanthology.org/D18-1073},
	doi = {10.18653/v1/D18-1073},
	abstract = {The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge.},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Parthasarathi, Prasanna and Pineau, Joelle},
	year = {2018},
	pages = {690--695},
}

@inproceedings{moghe-etal-2018-towards,
	address = {Brussels, Belgium},
	title = {Towards exploiting background knowledge for building conversation systems},
	url = {https://aclanthology.org/D18-1255},
	doi = {10.18653/v1/D18-1255},
	abstract = {Existing dialog datasets contain a sequence of utterances and responses without any explicit background knowledge associated with them. This has resulted in the development of models which treat conversation as a sequence-to-sequence generation task (i.e., given a sequence of utterances generate the response sequence). This is not only an overly simplistic view of conversation but it is also emphatically different from the way humans converse by heavily relying on their background knowledge about the topic (as opposed to simply relying on the previous sequence of utterances). For example, it is common for humans to (involuntarily) produce utterances which are copied or suitably modified from background articles they have read about the topic. To facilitate the development of such natural conversation models which mimic the human process of conversing, we create a new dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie. We establish baseline results on this dataset (90K utterances from 9K conversations) using three different models: (i) pure generation based models which ignore the background knowledge (ii) generation based models which learn to copy information from the background knowledge when required and (iii) span prediction based models which predict the appropriate response span in the background knowledge.},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Moghe, Nikita and Arora, Siddhartha and Banerjee, Suman and Khapra, Mitesh M.},
	year = {2018},
	pages = {2322--2332},
}

@inproceedings{luo-etal-2018-auto,
	address = {Brussels, Belgium},
	title = {An auto-encoder matching model for learning utterance-level semantic dependency in dialogue generation},
	url = {https://aclanthology.org/D18-1075},
	doi = {10.18653/v1/D18-1075},
	abstract = {Generating semantically coherent responses is still a major challenge in dialogue generation. Different from conventional text generation tasks, the mapping between inputs and responses in conversations is more complicated, which highly demands the understanding of utterance-level semantic dependency, a relation between the whole meanings of inputs and outputs. To address this problem, we propose an Auto-Encoder Matching (AEM) model to learn such dependency. The model contains two auto-encoders and one mapping module. The auto-encoders learn the semantic representations of inputs and responses, and the mapping module learns to connect the utterance-level representations. Experimental results from automatic and human evaluations demonstrate that our model is capable of generating responses of high coherence and fluency compared to baseline models.},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Luo, Liangchen and Xu, Jingjing and Lin, Junyang and Zeng, Qi and Sun, Xu},
	year = {2018},
	pages = {702--707},
}

@inproceedings{li-sun-2018-syntactically,
	address = {Brussels, Belgium},
	title = {A syntactically constrained bidirectional-asynchronous approach for emotional conversation generation},
	url = {https://aclanthology.org/D18-1071},
	doi = {10.18653/v1/D18-1071},
	abstract = {Traditional neural language models tend to generate generic replies with poor logic and no emotion. In this paper, a syntactically constrained bidirectional-asynchronous approach for emotional conversation generation (E-SCBA) is proposed to address this issue. In our model, pre-generated emotion keywords and topic keywords are asynchronously introduced into the process of decoding. It is much different from most existing methods which generate replies from the first word to the last. Through experiments, the results indicate that our approach not only improves the diversity of replies, but gains a boost on both logic and emotion compared with baselines.},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Jingyuan and Sun, Xiao},
	year = {2018},
	pages = {678--683},
}

@inproceedings{zhu-etal-2019-retrieval,
	address = {Florence, Italy},
	title = {Retrieval-enhanced adversarial training for neural response generation},
	url = {https://aclanthology.org/P19-1366},
	doi = {10.18653/v1/P19-1366},
	abstract = {Dialogue systems are usually built on either generation-based or retrieval-based approaches, yet they do not benefit from the advantages of different models. In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) method for neural response generation. Distinct from existing approaches, the REAT method leverages an encoder-decoder framework in terms of an adversarial training paradigm, while taking advantage of N-best response candidates from a retrieval-based system to construct the discriminator. An empirical study on a large scale public available benchmark dataset shows that the REAT method significantly outperforms the vanilla Seq2Seq model as well as the conventional adversarial training approach.},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Zhu, Qingfu and Cui, Lei and Zhang, Wei-Nan and Wei, Furu and Liu, Ting},
	month = jul,
	year = {2019},
	pages = {3763--3773},
}

@inproceedings{zhang-etal-2019-recosa,
	address = {Florence, Italy},
	title = {{ReCoSa}: {Detecting} the relevant contexts with self-attention for multi-turn dialogue generation},
	url = {https://aclanthology.org/P19-1362},
	doi = {10.18653/v1/P19-1362},
	abstract = {In multi-turn dialogue generation, response is usually related with only a few contexts. Therefore, an ideal model should be able to detect these relevant contexts and produce a suitable response accordingly. However, the widely used hierarchical recurrent encoder-decoder models just treat all the contexts indiscriminately, which may hurt the following response generation process. Some researchers try to use the cosine similarity or the traditional attention mechanism to find the relevant contexts, but they suffer from either insufficient relevance assumption or position bias problem. In this paper, we propose a new model, named ReCoSa, to tackle this problem. Firstly, a word level LSTM encoder is conducted to obtain the initial representation of each context. Then, the self-attention mechanism is utilized to update both the context and masked response representation. Finally, the attention weights between each context and response representations are computed and used in the further decoding process. Experimental results on both Chinese customer services dataset and English Ubuntu dialogue dataset show that ReCoSa significantly outperforms baseline models, in terms of both metric-based and human evaluations. Further analysis on attention shows that the detected relevant contexts by ReCoSa are highly coherent with human's understanding, validating the correctness and interpretability of ReCoSa.},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Hainan and Lan, Yanyan and Pang, Liang and Guo, Jiafeng and Cheng, Xueqi},
	month = jul,
	year = {2019},
	pages = {3721--3730},
}

@inproceedings{wu-etal-2019-proactive,
	address = {Florence, Italy},
	title = {Proactive human-machine conversation with explicit conversation goal},
	url = {https://aclanthology.org/P19-1369},
	doi = {10.18653/v1/P19-1369},
	abstract = {Though great progress has been made for human-machine conversation, current dialogue system is still in its infancy: it usually converses passively and utters words more as a matter of response, rather than on its own initiatives. In this paper, we take a radical step towards building a human-like conversational agent: endowing it with the ability of proactively leading the conversation (introducing a new topic or maintaining the current topic). To facilitate the development of such conversation systems, we create a new dataset named Konv where one acts as a conversation leader and the other acts as the follower. The leader is provided with a knowledge graph and asked to sequentially change the discussion topics, following the given conversation goal, and meanwhile keep the dialogue as natural and engaging as possible. Konv enables a very challenging task as the model needs to both understand dialogue and plan over the given knowledge graph. We establish baseline results on this dataset (about 270K utterances and 30k dialogues) using several state-of-the-art models. Experimental results show that dialogue models that plan over the knowledge graph can make full use of related knowledge to generate more diverse multi-turn conversations. The baseline systems along with the dataset are publicly available.},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Wu, Wenquan and Guo, Zhen and Zhou, Xiangyang and Wu, Hua and Zhang, Xiyuan and Lian, Rongzhong and Wang, Haifeng},
	month = jul,
	year = {2019},
	pages = {3794--3804},
}

@inproceedings{tian-etal-2019-learning,
	address = {Florence, Italy},
	title = {Learning to abstract for memory-augmented conversational response generation},
	url = {https://aclanthology.org/P19-1371},
	doi = {10.18653/v1/P19-1371},
	abstract = {Neural generative models for open-domain chit-chat conversations have become an active area of research in recent years. A critical issue with most existing generative models is that the generated responses lack informativeness and diversity. A few researchers attempt to leverage the results of retrieval models to strengthen the generative models, but these models are limited by the quality of the retrieval results. In this work, we propose a memory-augmented generative model, which learns to abstract from the training corpus and saves the useful information to the memory to assist the response generation. Our model clusters query-response samples, extracts characteristics of each cluster, and learns to utilize these characteristics for response generation. Experimental results show that our model outperforms other competitive baselines.},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Tian, Zhiliang and Bi, Wei and Li, Xiaopeng and Zhang, Nevin L.},
	month = jul,
	year = {2019},
	pages = {3816--3825},
}

@inproceedings{qiu-etal-2019-training,
	address = {Florence, Italy},
	title = {Are training samples correlated? {Learning} to generate dialogue responses with multiple references},
	url = {https://aclanthology.org/P19-1372},
	doi = {10.18653/v1/P19-1372},
	abstract = {Due to its potential applications, open-domain dialogue generation has become popular and achieved remarkable progress in recent years, but sometimes suffers from generic responses. Previous models are generally trained based on 1-to-1 mapping from an input query to its response, which actually ignores the nature of 1-to-n mapping in dialogue that there may exist multiple valid responses corresponding to the same query. In this paper, we propose to utilize the multiple references by considering the correlation of different valid responses and modeling the 1-to-n mapping with a novel two-step generation architecture. The first generation phase extracts the common features of different responses which, combined with distinctive features obtained in the second phase, can generate multiple diverse and appropriate responses. Experimental results show that our proposed model can effectively improve the quality of response and outperform existing neural dialogue models on both automatic and human evaluations.},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Qiu, Lisong and Li, Juntao and Bi, Wei and Zhao, Dongyan and Yan, Rui},
	month = jul,
	year = {2019},
	pages = {3826--3835},
}

@inproceedings{madotto-etal-2019-personalizing,
	address = {Florence, Italy},
	title = {Personalizing dialogue agents via meta-learning},
	url = {https://aclanthology.org/P19-1542},
	doi = {10.18653/v1/P19-1542},
	abstract = {Existing personalized dialogue models use human designed persona descriptions to improve dialogue consistency. Collecting such descriptions from existing dialogues is expensive and requires hand-crafted feature designs. In this paper, we propose to extend Model-Agnostic Meta-Learning (MAML) (Finn et al., 2017) to personalized dialogue learning without using any persona descriptions. Our model learns to quickly adapt to new personas by leveraging only a few dialogue samples collected from the same user, which is fundamentally different from conditioning the response on the persona descriptions. Empirical results on Persona-chat dataset (Zhang et al., 2018) indicate that our solution outperforms non-meta-learning baselines using automatic evaluation metrics, and in terms of human-evaluated fluency and consistency.},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Madotto, Andrea and Lin, Zhaojiang and Wu, Chien-Sheng and Fung, Pascale},
	month = jul,
	year = {2019},
	pages = {5454--5459},
}

@inproceedings{li-etal-2019-incremental,
	address = {Florence, Italy},
	title = {Incremental transformer with deliberation decoder for document grounded conversations},
	url = {https://aclanthology.org/P19-1002},
	doi = {10.18653/v1/P19-1002},
	abstract = {Document Grounded Conversations is a task to generate dialogue responses when chatting about the content of a given document. Obviously, document knowledge plays a critical role in Document Grounded Conversations, while existing dialogue models do not exploit this kind of knowledge effectively enough. In this paper, we propose a novel Transformer-based architecture for multi-turn document grounded conversations. In particular, we devise an Incremental Transformer to encode multi-turn utterances along with knowledge in related documents. Motivated by the human cognitive process, we design a two-pass decoder (Deliberation Decoder) to improve context coherence and knowledge correctness. Our empirical study on a real-world Document Grounded Dataset proves that responses generated by our model significantly outperform competitive baselines on both context coherence and knowledge relevance.},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Zekang and Niu, Cheng and Meng, Fandong and Feng, Yang and Li, Qian and Zhou, Jie},
	month = jul,
	year = {2019},
	pages = {12--21},
}

@inproceedings{liu-etal-2018-knowledge,
	address = {Melbourne, Australia},
	title = {Knowledge diffusion for neural dialogue generation},
	url = {https://aclanthology.org/P18-1138},
	doi = {10.18653/v1/P18-1138},
	abstract = {End-to-end neural dialogue generation has shown promising results recently, but it does not employ knowledge to guide the generation and hence tends to generate short, general, and meaningless responses. In this paper, we propose a neural knowledge diffusion (NKD) model to introduce knowledge into dialogue generation. This method can not only match the relevant facts for the input utterance but diffuse them to similar entities. With the help of facts matching and entity diffusion, the neural dialogue generation is augmented with the ability of convergent and divergent thinking over the knowledge base. Our empirical study on a real-world dataset prove that our model is capable of generating meaningful, diverse and natural responses for both factoid-questions and knowledge grounded chi-chats. The experiment results also show that our model outperforms competitive baseline models significantly.},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} (volume 1: {Long} papers)},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Shuman and Chen, Hongshen and Ren, Zhaochun and Feng, Yang and Liu, Qun and Yin, Dawei},
	month = jul,
	year = {2018},
	pages = {1489--1498},
}

@inproceedings{zhang-etal-2018-personalizing,
	address = {Melbourne, Australia},
	title = {Personalizing {Dialogue} {Agents}: {I} have a dog, do you have pets too?},
	url = {https://aclanthology.org/P18-1205},
	doi = {10.18653/v1/P18-1205},
	abstract = {Chit-chat models are known to have several problems: they lack specificity, do not display a consistent personality and are often not very captivating. In this work we present the task of making chit-chat more engaging by conditioning on profile information. We collect data and train models to (i)condition on their given profile information; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors.},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} (volume 1: {Long} papers)},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Saizheng and Dinan, Emily and Urbanek, Jack and Szlam, Arthur and Kiela, Douwe and Weston, Jason},
	month = jul,
	year = {2018},
	pages = {2204--2213},
}

@incollection{good_repair_1990,
	address = {London},
	title = {Repair and {Cooperation} in {Conversation}},
	isbn = {978-0-08-050264-9},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080502649500117},
	abstract = {This chapter discusses repair and cooperation in conversation. In developing an interface, a designer makes use of whichever pragmatic theories that are best suited to the task at hand. There are many different theories to choose from, but, in a rather crude way, they can all be placed into one of two groups: (1) those which work with a very narrow view of what utterances contain, presume that the hearer can make a large number of assumptions about the speech situation, and propose that the hearer is able and willing to do an excessive amount of inferential work in interpreting an utterance; and (2) those approaches that stress the wealth of detail. The main empirical content of this chapter is a single brief interchange between a thought disordered schizophrenic and a clinical psychologist. The occasional speech errors of the normal speaker and the chronic language deficits of the aphasic have both provided valuable data for the construction and evaluation of psycholinguistic models of normal phonological, lexical, syntactic, and semantic processes. The restriction of this research strategy to these levels is probably as much a matter of historical accident as of reasoned choice. For this reason, it is likely that the specific difficulties that arise in conversations with thought disordered schizophrenics might be particularly interesting. Amongst these difficulties is a sense one gains that the schizophrenic participant in a conversation is not being particularly helpful or cooperative.},
	language = {en},
	urldate = {2022-12-08},
	booktitle = {Computers and {Conversation}},
	publisher = {Academic Press},
	author = {Good, David},
	editor = {Luff, Paul and Gilbert, Nigel and Frohlich, David},
	month = jan,
	year = {1990},
	doi = {10.1016/B978-0-08-050264-9.50011-7},
	pages = {133--150},
}

@book{luff_computers_1990,
	address = {London},
	series = {Computers and people series},
	title = {Computers and conversation},
	isbn = {978-0-12-459560-6},
	language = {en},
	publisher = {Academic Press},
	editor = {Luff, Paul},
	year = {1990},
}

@misc{telegram_telegram_2022,
	title = {Telegram {Bot} {API} v. 6.3},
	url = {https://core.telegram.org/bots/api},
	abstract = {The Bot API is an HTTP-based interface created for developers keen on building bots for Telegram.},
	urldate = {2022-12-08},
	author = {Telegram},
	year = {2022},
}

@article{chan_gpt-3_2022,
	title = {{GPT}-3 and {InstructGPT}: technological dystopianism, utopianism, and “{Contextual}” perspectives in {AI} ethics and industry},
	issn = {2730-5961},
	shorttitle = {{GPT}-3 and {InstructGPT}},
	url = {https://doi.org/10.1007/s43681-022-00148-6},
	doi = {10.1007/s43681-022-00148-6},
	abstract = {This paper examines the ethical solutions raised in response to OpenAI’s language model Generative Pre-trained Transformer-3 (GPT-3) a year and a half from its release. I argue that hype and fear about GPT-3, even within the Natural Language Processing (NLP) industry and AI ethics, have often been underpinned by technologically deterministic perspectives. These perspectives emphasise the autonomy of the language model rather than the autonomy of human actors in AI systems. I highlight the existence of deterministic perspectives in the current AI discourse (which range from technological utopianism to dystopianism), with a specific focus on the two issues of: (1) GPT-3’s potential intentional misuse for manipulation and (2) unintentional harm caused by bias. In response, I find that a contextual approach to GPT-3, which is centred upon wider ecologies of societal harm and benefit, human autonomy, and human values, illuminates practical solutions to concerns about manipulation and bias. Additionally, although OpenAI’s newest 2022 language model InstructGPT represents a small step in reducing toxic language and aligning GPT-3 with user intent, it does not provide any compelling solutions to manipulation or bias. Therefore, I argue that solutions to address these issues must focus on organisational settings as a precondition for ethical decision-making in AI, and high-quality curated datasets as a precondition for less harmful language model outputs.},
	language = {en},
	urldate = {2022-12-08},
	journal = {AI and Ethics},
	author = {Chan, Anastasia},
	month = apr,
	year = {2022},
}

@inproceedings{du-black-2019-boosting,
	address = {Florence, Italy},
	title = {Boosting dialog response generation},
	url = {https://aclanthology.org/P19-1005},
	doi = {10.18653/v1/P19-1005},
	abstract = {Neural models have become one of the most important approaches to dialog response generation. However, they still tend to generate the most common and generic responses in the corpus all the time. To address this problem, we designed an iterative training process and ensemble method based on boosting. We combined our method with different training and decoding paradigms as the base model, including mutual-information-based decoding and reward-augmented maximum likelihood learning. Empirical results show that our approach can significantly improve the diversity and relevance of the responses generated by all base models, backed by objective measurements and human evaluation.},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Du, Wenchao and Black, Alan W},
	month = jul,
	year = {2019},
	pages = {38--43},
}

@inproceedings{zhao_floweval_2022,
	title = {{FlowEval}: {A} {Consensus}-{Based} {Dialogue} {Evaluation} {Framework} {Using} {Segment} {Act} {Flows}},
	shorttitle = {{FlowEval}},
	url = {https://aclanthology.org/2022.emnlp-main.715},
	abstract = {Jianqiao Zhao, Yanyang Li, Wanyu Du, Yangfeng Ji, Dong Yu, Michael Lyu, Liwei Wang. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.},
	language = {en-us},
	urldate = {2022-12-07},
	author = {Zhao, Jianqiao and Li, Yanyang and Du, Wanyu and Ji, Yangfeng and Yu, Dong and Lyu, Michael and Wang, Liwei},
	month = dec,
	year = {2022},
	pages = {10443--10457},
}

@inproceedings{liu_dial2vec_2022,
	title = {Dial2vec: {Self}-{Guided} {Contrastive} {Learning} of {Unsupervised} {Dialogue} {Embeddings}},
	shorttitle = {Dial2vec},
	url = {https://aclanthology.org/2022.emnlp-main.490},
	abstract = {Che Liu, Rui Wang, Junfeng Jiang, Yongbin Li, Fei Huang. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.},
	language = {en-us},
	urldate = {2022-12-07},
	author = {Liu, Che and Wang, Rui and Jiang, Junfeng and Li, Yongbin and Huang, Fei},
	month = dec,
	year = {2022},
	pages = {7246--7256},
}

@inproceedings{kim_prosocialdialog_2022,
	title = {{ProsocialDialog}: {A} {Prosocial} {Backbone} for {Conversational} {Agents}},
	shorttitle = {{ProsocialDialog}},
	url = {https://aclanthology.org/2022.emnlp-main.267},
	abstract = {Hyunwoo Kim, Youngjae Yu, Liwei Jiang, Ximing Lu, Daniel Khashabi, Gunhee Kim, Yejin Choi, Maarten Sap. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.},
	language = {en-us},
	urldate = {2022-12-07},
	author = {Kim, Hyunwoo and Yu, Youngjae and Jiang, Liwei and Lu, Ximing and Khashabi, Daniel and Kim, Gunhee and Choi, Yejin and Sap, Maarten},
	month = dec,
	year = {2022},
	pages = {4005--4029},
}

@inproceedings{zhang_fined-eval_2022,
	title = {{FineD}-{Eval}: {Fine}-grained {Automatic} {Dialogue}-{Level} {Evaluation}},
	shorttitle = {{FineD}-{Eval}},
	url = {https://aclanthology.org/2022.emnlp-main.220},
	abstract = {Chen Zhang, Luis Fernando D’Haro, Qiquan Zhang, Thomas Friedrichs, Haizhou Li. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.},
	language = {en-us},
	urldate = {2022-12-07},
	author = {Zhang, Chen and D’Haro, Luis Fernando and Zhang, Qiquan and Friedrichs, Thomas and Li, Haizhou},
	month = dec,
	year = {2022},
	pages = {3336--3355},
}

@inproceedings{gros_robots-dont-cry_2022,
	title = {Robots-{Dont}-{Cry}: {Understanding} {Falsely} {Anthropomorphic} {Utterances} in {Dialog} {Systems}},
	shorttitle = {Robots-{Dont}-{Cry}},
	url = {https://aclanthology.org/2022.emnlp-main.215},
	abstract = {David Gros, Yu Li, Zhou Yu. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.},
	language = {en-us},
	urldate = {2022-12-07},
	author = {Gros, David and Li, Yu and Yu, Zhou},
	month = dec,
	year = {2022},
	pages = {3266--3284},
}

@inproceedings{li_back_2022,
	title = {Back to the {Future}: {Bidirectional} {Information} {Decoupling} {Network} for {Multi}-turn {Dialogue} {Modeling}},
	shorttitle = {Back to the {Future}},
	url = {https://aclanthology.org/2022.emnlp-main.177},
	abstract = {Yiyang Li, Hai Zhao, Zhuosheng Zhang. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.},
	language = {en-us},
	urldate = {2022-12-07},
	author = {Li, Yiyang and Zhao, Hai and Zhang, Zhuosheng},
	month = dec,
	year = {2022},
	pages = {2761--2774},
}

@inproceedings{gupta_instructdial_2022,
	title = {{InstructDial}: {Improving} {Zero} and {Few}-shot {Generalization} in {Dialogue} through {Instruction} {Tuning}},
	shorttitle = {{InstructDial}},
	url = {https://aclanthology.org/2022.emnlp-main.33},
	abstract = {Prakhar Gupta, Cathy Jiao, Yi-Ting Yeh, Shikib Mehri, Maxine Eskenazi, Jeffrey Bigham. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.},
	language = {en-us},
	urldate = {2022-12-07},
	author = {Gupta, Prakhar and Jiao, Cathy and Yeh, Yi-Ting and Mehri, Shikib and Eskenazi, Maxine and Bigham, Jeffrey P.},
	month = dec,
	year = {2022},
	pages = {505--525},
}

@misc{muller-eberstein_spectral_2022,
	title = {Spectral {Probing}},
	url = {http://arxiv.org/abs/2210.11860},
	abstract = {Linguistic information is encoded at varying timescales (subwords, phrases, etc.) and communicative levels, such as syntax and semantics. Contextualized embeddings have analogously been found to capture these phenomena at distinctive layers and frequencies. Leveraging these findings, we develop a fully learnable frequency filter to identify spectral profiles for any given task. It enables vastly more granular analyses than prior handcrafted filters, and improves on efficiency. After demonstrating the informativeness of spectral probing over manual filters in a monolingual setting, we investigate its multilingual characteristics across seven diverse NLP tasks in six languages. Our analyses identify distinctive spectral profiles which quantify cross-task similarity in a linguistically intuitive manner, while remaining consistent across languages-highlighting their potential as robust, lightweight task descriptors.},
	urldate = {2022-12-06},
	publisher = {arXiv},
	author = {Müller-Eberstein, Max and van der Goot, Rob and Plank, Barbara},
	month = oct,
	year = {2022},
	note = {arXiv:2210.11860 [cs]},
}

@inproceedings{lopez_evaluation_2022,
	address = {Potsdam},
	title = {Evaluation of {Automatic} {Speech} {Recognition} for {Conversational} {Speech} in {Dutch}, {English} and {German}: {What} {Goes} {Missing}?},
	abstract = {As voice user interfaces and conversational agents grow in importance, automatic speech recognition (ASR) encounters increasingly free-form and informal input data. Conversational speech is at once the most challenging and the most ecologically relevant type of data for speech recognition in this context. Here we evaluate several ASR performance on conversational speech in three languages, focusing on the fate of backchannels and other interactionally relevant elements of talk. We propose forms of error analysis based on ngram salience scoring that can complement default measures like word error rates (WER) and are more informative of ASR's ability to live up to the task of accurately representing real-world interaction.},
	booktitle = {Proceedings of the 18th {Conference} on {Natural} {Language} {Processing} ({KONVENS} 2022)},
	author = {Lopez, Alianda and Liesenfeld, Andreas and Dingemanse, Mark},
	year = {2022},
}

@article{goldwater_which_2010,
	title = {Which words are hard to recognize? {Prosodic}, lexical, and disfluency factors that increase speech recognition error rates},
	volume = {52},
	issn = {01676393},
	shorttitle = {Which words are hard to recognize?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167639309001599},
	doi = {10.1016/j.specom.2009.10.001},
	abstract = {Despite years of speech recognition research, little is known about which words tend to be misrecognized and why. Previous work has shown that errors increase for infrequent words, short words, and very loud or fast speech, but many other presumed causes of error (e.g., nearby disﬂuencies, turn-initial words, phonetic neighborhood density) have never been carefully tested. The reasons for the huge diﬀerences found in error rates between speakers also remain largely mysterious.},
	language = {en},
	number = {3},
	urldate = {2022-12-01},
	journal = {Speech Communication},
	author = {Goldwater, Sharon and Jurafsky, Dan and Manning, Christopher D.},
	month = mar,
	year = {2010},
	pages = {181--200},
}

@misc{liesenfeld_robust_2023,
	address = {Brussels},
	type = {Conference {Panel}},
	title = {Robust and flexible interactive language technology for human empowerment},
	author = {Liesenfeld, Andreas and Buschmeier, Hendrik},
	year = {2023},
}

@misc{ranhel_linguistic_2022,
	title = {On the {Linguistic} and {Computational} {Requirements} for {Creating} {Face}-to-{Face} {Multimodal} {Human}-{Machine} {Interaction}},
	url = {http://arxiv.org/abs/2211.13804},
	doi = {10.48550/arXiv.2211.13804},
	abstract = {In this study, conversations between humans and avatars are linguistically, organizationally, and structurally analyzed, focusing on what is necessary for creating face-to-face multimodal interfaces for machines. We videorecorded thirty-four human-avatar interactions, performed complete linguistic microanalysis on video excerpts, and marked all the occurrences of multimodal actions and events. Statistical inferences were applied to data, allowing us to comprehend not only how often multimodal actions occur but also how multimodal events are distributed between the speaker (emitter) and the listener (recipient). We also observed the distribution of multimodal occurrences for each modality. The data show evidence that double-loop feedback is established during a face-to-face conversation. This led us to propose that knowledge from Conversation Analysis (CA), cognitive science, and Theory of Mind (ToM), among others, should be incorporated into the ones used for describing human-machine multimodal interactions. Face-to-face interfaces require an additional control layer to the multimodal fusion layer. This layer has to organize the flow of conversation, integrate the social context into the interaction, as well as make plans concerning 'what' and 'how' to progress on the interaction. This higher level is best understood if we incorporate insights from CA and ToM into the interface system.},
	urldate = {2022-11-29},
	publisher = {arXiv},
	author = {Ranhel, João and de Lima, Cacilda Vilela},
	month = nov,
	year = {2022},
	note = {arXiv:2211.13804 [cs]},
}

@article{nemeth_conversation-organising_2022,
	title = {The conversation-organising role of the non-lexical sound öö in {Hungarian}},
	volume = {194},
	issn = {0378-2166},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216622001023},
	doi = {10.1016/j.pragma.2022.04.002},
	abstract = {The non-lexical schwa-like sound öö is traditionally regarded as a hesitation marker in Hungarian conversation that has a role in speech planning. This study provides examples in which öö can be analysed as a discourse marker. In research on discourse markers, there is a view that regards items that control the turn-taking system or other aspects of conversation management as discourse markers. Relying on this background, this paper explores öö from a conversation analytic perspective. Findings show that öö can serve as a device to take the floor at the transition-relevance place. In overlapping speech, öö can manage turn-taking by helping speakers keep the floor. If the speaker intends or needs to speak but does not yet know what to say or intends to avoid unintelligibility during overlapping speech, she can deploy öö as an overt but non-lexical element that projects further talk. Consequently, by using öö the speaker can claim or keep the turn space without using lexical elements. Since these functions influence the distribution of turns among participants, i.e. the sequential structure of the conversation, öö can be regarded as a discourse marker in these contexts.},
	language = {en},
	urldate = {2022-11-23},
	journal = {Journal of Pragmatics},
	author = {Németh, Zsuzsanna},
	month = jun,
	year = {2022},
	pages = {23--35},
}

@inproceedings{chen_analyzing_2022,
	address = {Taipei, Taiwan},
	title = {Analyzing discourse functions with acoustic features and phone embeddings: non-lexical items in {Taiwan} {Mandarin}},
	shorttitle = {Analyzing discourse functions with acoustic features and phone embeddings},
	url = {https://aclanthology.org/2022.rocling-1.18},
	abstract = {Non-lexical items are expressive devices used in conversations that are not words but are nevertheless meaningful. These items play crucial roles, such as signaling turn-taking or marking stances in interactions. However, as the non-lexical items do not stably correspond to written or phonological forms, past studies tend to focus on studying their acoustic properties, such as pitches and durations. In this paper, we investigate the discourse functions of non-lexical items through their acoustic properties and the phone embeddings extracted from a deep learning model. Firstly, we create a non-lexical item dataset based on the interpellation video clips from Taiwan's Legislative Yuan. Then, we manually identify the non-lexical items and their discourse functions in the videos. Next, we analyze the acoustic properties of those items through statistical modeling and building classifiers based on phone embeddings extracted from a phone recognition model. We show that (1) the discourse functions have significant effects on the acoustic features; and (2) the classifiers built on phone embeddings perform better than the ones on conventional acoustic properties. These results suggest that phone embeddings may reflect the phonetic variations crucial in differentiating the discourse functions of non-lexical items.},
	urldate = {2022-11-23},
	booktitle = {Proceedings of the 34th {Conference} on {Computational} {Linguistics} and {Speech} {Processing} ({ROCLING} 2022)},
	publisher = {The Association for Computational Linguistics and Chinese Language Processing (ACLCLP)},
	author = {Chen, Pin-Er and Tseng, Yu-Hsiang and Wang, Chi-Wei and Yeh, Fang-Chi and Hsieh, Shu-Kai},
	month = nov,
	year = {2022},
	pages = {136--146},
}

@inproceedings{wyeth_designing_2006,
	address = {New York, NY, USA},
	series = {{OZCHI} '06},
	title = {Designing cultural probes for children},
	isbn = {978-1-59593-545-8},
	url = {https://doi.org/10.1145/1228175.1228252},
	doi = {10.1145/1228175.1228252},
	abstract = {This paper reports on the challenges faced during the design and deployment of educationally-focused cultural probes with children. The aim of the project was to use cultural probes to discover insights into children's interests and ideas within an educational context. The deployment of a cultural probe pack with children aged between 11 and 13 has demonstrated the method's effectiveness as a tool for design inspiration. Children's responses to the cultural probe have provided a valuable insight into the attributes of successful probe activities, the nature of contextual information which may be gathered and the limitations of the method.},
	urldate = {2022-11-11},
	booktitle = {Proceedings of the 18th {Australia} conference on {Computer}-{Human} {Interaction}: {Design}: {Activities}, {Artefacts} and {Environments}},
	publisher = {Association for Computing Machinery},
	author = {Wyeth, Peta and Diercke, Carla},
	month = nov,
	year = {2006},
	pages = {385--388},
}

@article{celikoglu_how_2017,
	title = {How {Do} {User} {Stories} {Inspire} {Design}? {A} {Study} of {Cultural} {Probes}},
	volume = {33},
	issn = {0747-9360},
	shorttitle = {How {Do} {User} {Stories} {Inspire} {Design}?},
	doi = {10.1162/DESI_a_00441},
	abstract = {This paper reports an initial study using cultural probes to support design. Its aim was to provide designers and design students with ethnographic information not easily accessible via surveys, interviews, and user statistics. Our research applied the cultural probes method to domestic ironing practices. We communicated the narrative and pictorial data generated by this method to designers and asked them to interpret these data in terms of a new ironing board design. Finally, we conducted a content analysis to reveal how designers interpreted and used data from cultural probes to inform design ideas.},
	number = {2},
	journal = {Design Issues},
	author = {Celikoglu, Ozge Merzali and Ogut, Sebnem Timur and Krippendorff, Klaus},
	month = apr,
	year = {2017},
	note = {Conference Name: Design Issues},
	pages = {84--98},
}

@article{gaver_cultural_2004,
	title = {Cultural probes and the value of uncertainty},
	volume = {11},
	number = {5},
	journal = {interactions},
	author = {Gaver, William W. and Boucher, Andrew and Pennington, Sarah and Walker, Brendan},
	year = {2004},
	note = {Publisher: ACM New York, NY, USA},
	pages = {53--56},
}

@article{gaver_design_1999,
	title = {Design: cultural probes},
	volume = {6},
	shorttitle = {Design},
	number = {1},
	journal = {interactions},
	author = {Gaver, Bill and Dunne, Tony and Pacenti, Elena},
	year = {1999},
	note = {Publisher: ACM New York, NY, USA},
	pages = {21--29},
}

@inproceedings{guldenpfennig_towards_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards {Rapid} {Technology} {Probes} for {Senior} {People}},
	isbn = {978-3-642-39062-3},
	doi = {10.1007/978-3-642-39062-3_47},
	abstract = {In HCI, there is much interest in exploring novel technology-mediated communication that can empower older users who don’t have easy access to regular computers. In this paper we exploit the potential of smart phones and tablet computers to create a series of technology probes that we deploy long-term making use of close family members. By this means participants can gain experiences with robust and fully implemented devices at a very early stage of design. We lay out four prototypes of communication technologies with different forms and functions for older adults. We describe the features of these devices including some indicative feedback from our informal deployment study. We thereby suggest that mobile phones are a suitable means for the rapid prototyping of communication technologies for senior people and can possibly provide useful input to later participatory or co-design activities. The overall work is still ongoing hence the main contribution of the paper is about the potential of rapid technology probes as a design technique and in less detail about the potential of the prototypes as AAL communication devices.},
	language = {en},
	booktitle = {Human {Factors} in {Computing} and {Informatics}},
	publisher = {Springer},
	author = {Güldenpfennig, Florian and Fitzpatrick, Geraldine},
	editor = {Holzinger, Andreas and Ziefle, Martina and Hitz, Martin and Debevc, Matjaž},
	year = {2013},
	pages = {664--671},
}

@inproceedings{graham_probes_2008,
	address = {USA},
	series = {{PDC} '08},
	title = {Probes and participation},
	isbn = {978-0-9818561-0-0},
	abstract = {This exploratory paper reflects on the relationship between methodological techniques and forms of user participation. Specifically our concern is to document and describe our experiences with different kinds of participation that different sorts of 'Probes' - 'Cultural Probes', 'Technology Probes' etc - elicit, encourage and provoke. Analysis of the different kinds of participation invoked by Probes - imaginative, investigative, emotional, discursive, reactive, disruptive, reflective, and playful - may prove useful as heuristic devices guiding the selection and deployment of these methodological and design tools. Whilst there are further opportunities for new forms of participation through 'Probing', new concerns, challenges and risks also emerge.},
	urldate = {2022-11-11},
	booktitle = {Proceedings of the {Tenth} {Anniversary} {Conference} on {Participatory} {Design} 2008},
	publisher = {Indiana University},
	author = {Graham, Connor and Rouncefield, Mark},
	year = {2008},
	pages = {194--197},
}

@inproceedings{hutchinson_technology_2003,
	address = {New York, NY, USA},
	series = {{CHI} '03},
	title = {Technology probes: inspiring design for and with families},
	isbn = {978-1-58113-630-2},
	shorttitle = {Technology probes},
	url = {https://doi.org/10.1145/642611.642616},
	doi = {10.1145/642611.642616},
	abstract = {We describe a new method for use in the process of co-designing technologies with users called technology probes. Technology probes are simple, flexible, adaptable technologies with three interdisciplinary goals: the social science goal of understanding the needs and desires of users in a real-world setting, the engineering goal of field-testing the technology, and the design goal of inspiring users and researchers to think about new technologies. We present the results of designing and deploying two technology probes, the messageProbe and the videoProbe, with diverse families in France, Sweden, and the U.S. We conclude with our plans for creating new technologies for and with families based on our experiences.},
	urldate = {2022-11-11},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Hutchinson, Hilary and Mackay, Wendy and Westerlund, Bo and Bederson, Benjamin B. and Druin, Allison and Plaisant, Catherine and Beaudouin-Lafon, Michel and Conversy, Stéphane and Evans, Helen and Hansen, Heiko and Roussel, Nicolas and Eiderbäck, Björn},
	month = apr,
	year = {2003},
	pages = {17--24},
}

@article{zorrilla_multilingual_2022,
	title = {A {Multilingual} {Neural} {Coaching} {Model} with {Enhanced} {Long}-term {Dialogue} {Structure}},
	volume = {12},
	issn = {2160-6455},
	url = {https://doi.org/10.1145/3487066},
	doi = {10.1145/3487066},
	abstract = {In this work we develop a fully data driven conversational agent capable of carrying out motivational coaching sessions in Spanish, French, Norwegian, and English. Unlike the majority of coaching, and in general well-being related conversational agents that can be found in the literature, ours is not designed by hand-crafted rules. Instead, we directly model the coaching strategy of professionals with end users. To this end, we gather a set of virtual coaching sessions through a Wizard of Oz platform, and apply state of the art Natural Language Processing techniques. We employ a transfer learning approach, pretraining GPT2 neural language models and fine-tuning them on our corpus. However, since these only take as input a local dialogue history, a simple fine-tuning procedure is not capable of modeling the long-term dialogue strategies that appear in coaching sessions. To alleviate this issue, we first propose to learn dialogue phase and scenario embeddings in the fine-tuning stage. These indicate to the model at which part of the dialogue it is and which kind of coaching session it is carrying out. Second, we develop a global deep learning system which controls the long-term structure of the dialogue. We also show that this global module can be used to visualize and interpret the decisions taken by the the conversational agent, and that the learnt representations are comparable to dialogue acts. Automatic and human evaluation show that our proposals serve to improve the baseline models. Finally, interaction experiments with coaching experts indicate that the system is usable and gives rise to positive emotions in Spanish, French and English, while the results in Norwegian point out that there is still work to be done in fully data driven approaches with very low resource languages.},
	number = {2},
	urldate = {2022-07-18},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Zorrilla, Asier López and Torres, M. Inés},
	month = jul,
	year = {2022},
	pages = {16:1--16:47},
}

@article{vesper_when_2021,
	title = {When is ostensive communication used for joint action?},
	volume = {14},
	issn = {2235-2066},
	url = {https://www.degruyter.com/document/doi/10.1515/cogsem-2021-2040/html?lang=de},
	doi = {10.1515/cogsem-2021-2040},
	abstract = {Joint actions typically require that information relevant for performing a task together is available to the interaction partners. In some situations, such information is perceptually retrievable and salient enough for co-actors to simply use it. In other situations, the relevant information needs to be actively shared among co-actors, e.g., by making it more perceptually salient or indicating it by means of a conventional signal. Here we consider a third case, where the information is not perceptually available and cannot be communicated by conventional means. How do joint action partners coordinate in such situations? We propose that co-actors resort to ostensive communication, that is, they draw attention to the fact that they intend to communicate some specific information. Two experiments tested the proposed role of ostensive communication for joint action. In a non-verbal joint building task, the category membership of different objects was known to only one person in a dyad, who needed to inform the partner which object type to use. In line with our hypothesis, most participants highlighted a particular object category with an ostensive gesture (characterized by containing more submovements than a natural placing movement) to resolve perceptual ambiguity. We conclude that ostensive communication is especially useful for joint action in situations where task-relevant information is not available to all co-actors and where it cannot be perceptually highlighted or conventionally communicated.},
	language = {en},
	number = {2},
	urldate = {2022-10-06},
	journal = {Cognitive Semiotics},
	author = {Vesper, Cordula and Morisseau, Tiffany and Knoblich, Günther and Sperber, Dan},
	month = nov,
	year = {2021},
	note = {Publisher: De Gruyter Mouton},
	pages = {101--129},
}

@incollection{luff_repair_1990,
	address = {London},
	series = {Computers and people series},
	title = {Repair {Work} in {Human}-{Computer} {Interaction}},
	isbn = {978-0-08-050264-9},
	abstract = {In the past few years a branch of sociology, conversation analysis, has begun to have a significant impact on the design of human*b1computer interaction (HCI). The investigation of human*b1human dialogue has emerged as a fruitful foundation for interactive system design.****This book includes eleven original chapters by leading researchers who are applying conversation analysis to HCI. The fundamentals of conversation analysis are outlined, a number of systems are described, and a critical view of their value for HCI is offered.****Computers and Conversation will be of interest to all concerned with HCI issues--from the advanced student to the professional computer scientist involved in the design and specification of interactive systems},
	language = {eng},
	booktitle = {Computers and conversation},
	publisher = {Academic Press},
	author = {Raudaskoski, Pirkko},
	editor = {Luff, Paul and Gilbert, G. Nigel and Frohlich, David},
	year = {1990},
	pages = {151--171},
}

@inproceedings{porcheron_talking_2017,
	address = {New York, NY, USA},
	series = {{CSCW} '17 {Companion}},
	title = {Talking with {Conversational} {Agents} in {Collaborative} {Action}},
	isbn = {978-1-4503-4688-7},
	url = {https://doi.org/10.1145/3022198.3022666},
	doi = {10.1145/3022198.3022666},
	abstract = {This one-day workshop intends to bring together both academics and industry practitioners to explore collaborative challenges in speech interaction. Recent improvements in speech recognition and computing power has led to conversational interfaces being introduced to many of the devices we use every day, such as smartphones, watches, and even televisions. These interfaces allow us to get things done, often by just speaking commands, relying on a reasonably well understood single-user model. While research on speech recognition is well established, the social implications of these interfaces remain underexplored, such as how we socialise, work, and play around such technologies, and how these might be better designed to support collaborative collocated talk-in-action. Moreover, the advent of new products such as the Amazon Echo and Google Home, which are positioned as supporting multi-user interaction in collocated environments such as the home, makes exploring the social and collaborative challenges around these products, a timely topic. In the workshop, we will review current practices and reflect upon prior work on studying talk-in-action and collocated interaction. We wish to begin a dialogue that takes on the renewed interest in research on spoken interaction with devices, grounded in the existing practices of the CSCW community.},
	urldate = {2022-09-08},
	booktitle = {Companion of the 2017 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} and {Social} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Porcheron, Martin and Fischer, Joel E. and McGregor, Moira and Brown, Barry and Luger, Ewa and Candello, Heloisa and O'Hara, Kenton},
	month = feb,
	year = {2017},
	pages = {431--436},
}

@article{ogden_data_2015,
	title = {Data {Always} {Invite} {Us} to {Listen} {Again}: {Arguments} for {Mixing} {Our} {Methods}},
	volume = {48},
	issn = {0835-1813},
	shorttitle = {Data {Always} {Invite} {Us} to {Listen} {Again}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/08351813.2015.1058601},
	doi = {10.1080/08351813.2015.1058601},
	abstract = {Moore (2015/this issue) claims, provocatively to some, that speech technology can be used as a labor-saving device. He points out that the production of transcriptions is time consuming, that some aspects of collection building can be handled with a degree of automation, and that some aspects of measurement can be made objective and reliable by using machines. I respond as a phonetician and interactional linguist. I want to argue that while automation is not always the right approach, working with large corpora can be healthy for our relation to data when used in the right ways.},
	number = {3},
	urldate = {2015-08-11},
	journal = {Research on Language and Social Interaction},
	author = {Ogden, Richard},
	month = jul,
	year = {2015},
	pages = {271--275},
}

@inproceedings{novikova_why_2017,
	address = {Copenhagen, Denmark},
	title = {Why {We} {Need} {New} {Evaluation} {Metrics} for {NLG}},
	url = {https://aclanthology.org/D17-1238},
	doi = {10.18653/v1/D17-1238},
	abstract = {The majority of NLG evaluation relies on automatic metrics, such as BLEU . In this paper, we motivate the need for novel, system- and data-independent automatic evaluation methods: We investigate a wide range of metrics, including state-of-the-art word-based and novel grammar-based ones, and demonstrate that they only weakly reflect human judgements of system outputs as generated by data-driven, end-to-end NLG. We also show that metric performance is data- and system-specific. Nevertheless, our results also suggest that automatic metrics perform reliably at system-level and can support system development by finding cases where a system performs poorly.},
	urldate = {2022-07-29},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Novikova, Jekaterina and Dušek, Ondřej and Cercas Curry, Amanda and Rieser, Verena},
	month = sep,
	year = {2017},
	pages = {2241--2252},
}

@inproceedings{lee_ethics_2022,
	address = {New Orleans LA USA},
	title = {Ethics of {Conversational} {User} {Interfaces}},
	isbn = {978-1-4503-9156-6},
	url = {https://dl.acm.org/doi/10.1145/3491101.3503699},
	doi = {10.1145/3491101.3503699},
	abstract = {Building on the prior workshops on conversational user interfaces (CUIs) [2, 40], we tackle the topic of ethics of CUIs at CHI 2022. Though commercial CUI developments continue to rapidly advance, our scholarly dialogue on ethics of CUIs is underwhelming. The CUI community has implicitly been concerned with ethics, yet making it central to the growing body of work thus far has not been adequately done. Since ethics is a far-reaching topic, perspectives from philosophy, design, and engineering domains are integral to our CUI research community. For instance, philosophical traditions, e.g., deontology or virtue ethics, can guide ethical concepts that are relevant for CUIs, e.g., autonomy or trust. The practice of design through approaches like value sensitive design can inform how CUIs should be developed. Ethics comes into play with technical contributions, e.g., privacy-preserving data sharing between conversational systems. By considering such multidisciplinary angles, we come to a special topic of interest that ties together philosophy, design, and engineering: conversational disclosure, e.g., sharing personal information, transparency, e.g., as how to transparently convey relevant information in a conversational manner, and vulnerability of diverse user groups that should be taken into consideration.},
	language = {en},
	urldate = {2022-05-11},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} {Extended} {Abstracts}},
	publisher = {ACM},
	author = {Lee, Minha and Sin, Jaisie and Laban, Guy and Kraus, Matthias and Clark, Leigh and Porcheron, Martin and Cowan, Benjamin R. and Følstad, Asbjørn and Munteanu, Cosmin and Candello, Heloisa},
	month = apr,
	year = {2022},
	pages = {1--7},
}

@article{kocaballi_special_2022,
	title = {Special {Issue} on {Conversational} {Agents} for {Healthcare} and {Wellbeing}},
	volume = {12},
	issn = {2160-6455},
	url = {https://doi.org/10.1145/3532860},
	doi = {10.1145/3532860},
	number = {2},
	urldate = {2022-07-18},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Kocaballi, A. Baki and Laranjo, Liliana and Clark, Leigh and Kocielnik, Rafał and Moore, Robert J. and Liao, Q. Vera and Bickmore, Timothy},
	month = jul,
	year = {2022},
	pages = {9:1--9:3},
}

@article{clavel2022survey,
	title = {A survey of neural models for the automatic analysis of conversation: {Towards} a better integration of the social sciences},
	journal = {arXiv preprint arXiv:2203.16891},
	author = {Clavel, Chloé and Labeau, Matthieu and Cassell, Justine},
	year = {2022},
}

@inproceedings{liu_predicting_2022,
	address = {New York, NY, USA},
	series = {{ICMI} '22 {Companion}},
	title = {Predicting {Backchannel} {Signaling} in {Child}-{Caregiver} {Multimodal} {Conversations}},
	isbn = {978-1-4503-9389-8},
	url = {https://doi.org/10.1145/3536220.3563372},
	doi = {10.1145/3536220.3563372},
	abstract = {Conversation requires cooperative social interaction between interlocutors. In particular, active listening through backchannel signaling (hereafter BC) i.e., showing attention through verbal (short responses like “Yeah”) and non-verbal behaviors (e.g. smiling or nodding) is crucial to managing the flow of a conversation and it requires sophisticated coordination skills. How does BC develop in childhood? Previous studies were either conducted in highly controlled experimental settings or relied on qualitative corpus analysis, which does not allow for a proper understanding of children’s BC development, especially in terms of its collaborative/coordinated use. This paper aims at filling this gap using a machine learning model that learns to predict children’s BC production based on the interlocutor’s inviting cues in child-caregiver naturalistic conversations. By comparing BC predictability across children and adults, we found that, contrary to what has been suggested in previous in-lab studies, children between the ages of 6 and 12 can actually produce and respond to backchannel inviting cues as consistently as adults do, suggesting an adult-like form of coordination.},
	urldate = {2022-11-10},
	booktitle = {Companion {Publication} of the 2022 {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Jing and Nikolaus, Mitja and Bodur, Kübra and Fourtassi, Abdellah},
	month = nov,
	year = {2022},
	pages = {196--200},
}

@misc{gandhi_esb_2022,
	title = {{ESB}: {A} {Benchmark} {For} {Multi}-{Domain} {End}-to-{End} {Speech} {Recognition}},
	shorttitle = {{ESB}},
	url = {http://arxiv.org/abs/2210.13352},
	doi = {10.48550/arXiv.2210.13352},
	abstract = {Speech recognition applications cover a range of different audio and text distributions, with different speaking styles, background noise, transcription punctuation and character casing. However, many speech recognition systems require dataset-specific tuning (audio filtering, punctuation removal and normalisation of casing), therefore assuming a-priori knowledge of both the audio and text distributions. This tuning requirement can lead to systems failing to generalise to other datasets and domains. To promote the development of multi-domain speech systems, we introduce the End-to-end Speech Benchmark (ESB) for evaluating the performance of a single automatic speech recognition (ASR) system across a broad set of speech datasets. Benchmarked systems must use the same data pre- and post-processing algorithm across datasets - assuming the audio and text data distributions are a-priori unknown. We compare a series of state-of-the-art (SoTA) end-to-end (E2E) systems on this benchmark, demonstrating how a single speech system can be applied and evaluated on a wide range of data distributions. We find E2E systems to be effective across datasets: in a fair comparison, E2E systems achieve within 2.6\% of SoTA systems tuned to a specific dataset. Our analysis reveals that transcription artefacts, such as punctuation and casing, pose difficulties for ASR systems and should be included in evaluation. We believe E2E benchmarking over a range of datasets promotes the research of multi-domain speech recognition systems. ESB is available at https://huggingface.co/esb.},
	urldate = {2022-11-01},
	publisher = {arXiv},
	author = {Gandhi, Sanchit and von Platen, Patrick and Rush, Alexander M.},
	month = oct,
	year = {2022},
	note = {arXiv:2210.13352 [cs, eess]},
}

@inproceedings{law_effects_2022,
	address = {New York, NY, USA},
	series = {{NordiCHI} '22},
	title = {Effects of {Humanlikeness} and {Conversational} {Breakdown} on {Trust} in {Chatbots} for {Customer} {Service}},
	isbn = {978-1-4503-9699-8},
	url = {https://doi.org/10.1145/3546155.3546665},
	doi = {10.1145/3546155.3546665},
	abstract = {Trust in chatbots can be shaped by various factors such as humanlikeness in terms of visual appearance and conversational content, and conversational performance in terms of the chatbot’s ability to avoid conversational breakdown. The literature is inconclusive concerning the effect of humanlikeness and conversational performance on trust, especially their interaction effect. To examine the relations among these variables, we conducted a 2x3 (humanlikeness x conversational performance) factorial experiment with 251 participants, who were asked to perform three tasks with a chatbot for an online bank under one of the six conditions. Participants completed a questionnaire measuring trust and commented on trust factors. Results of between-group analysis showed that for the task with seeded breakdowns there were significant differences in trust across the six groups with the lowest ratings for the two groups experiencing breakdowns without repairs and that humanlikeness did not impact the extent to which the trust level changed. Results of within-group analysis showed significant differences in trust across the tasks but non-significant inter-task correlations on trust for the two groups. These observations challenge the effect of humanlikeness on trust while supporting the notion of trust resilience as the participants did not spill the impaired trust over the subsequent task. Thematic analysis showed that inter-group contrasts could be found for the theme ‘underlying functionality’ and ‘affective responses.’ Implications for research, practice and future work were drawn.},
	urldate = {2022-10-20},
	booktitle = {Nordic {Human}-{Computer} {Interaction} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Law, Effie Lai-Chong and FØLstad, AsbjØRn and Van As, Nena},
	year = {2022},
	pages = {1--13},
}

@inproceedings{dubuisson_duplessis_utterance_2017,
	address = {Aberdeen, United Kingdom},
	title = {Utterance {Retrieval} based on {Recurrent} {Surface} {Text} {Patterns}},
	url = {https://hal.archives-ouvertes.fr/hal-01436052},
	abstract = {This paper investigates the use of recurrent surface text patterns to represent and index open-domain dialogue utterances for a retrieval system that can be embedded in a conversational agent. This approach involves both the building of a database of such patterns by mining a corpus of written dialogic interactions, and the exploitation of this database in a generalised vector space model for utterance retrieval. It is a corpus-based, unsupervised, parameterless and language-independent process. Our study indicates that the proposed model performs objectively well comparatively to other retrieval models on a task of selection of dialogue examples derived from a large corpus of written dialogues.},
	urldate = {2022-10-20},
	booktitle = {39th {European} {Conference} on {Information} {Retrieval}},
	author = {Dubuisson Duplessis, Guillaume and Charras, Franck and Letard, Vincent and Ligozat, Anne-Laure and Rosset, Sophie},
	month = apr,
	year = {2017},
}

@misc{giulianelli_construction_2022,
	title = {Construction {Repetition} {Reduces} {Information} {Rate} in {Dialogue}},
	url = {http://arxiv.org/abs/2210.08321},
	doi = {10.48550/arXiv.2210.08321},
	abstract = {Speakers repeat constructions frequently in dialogue. Due to their peculiar information-theoretic properties, repetitions can be thought of as a strategy for cost-effective communication. In this study, we focus on the repetition of lexicalised constructions -- i.e., recurring multi-word units -- in English open-domain spoken dialogues. We hypothesise that speakers use construction repetition to mitigate information rate, leading to an overall decrease in utterance information content over the course of a dialogue. We conduct a quantitative analysis, measuring the information content of constructions and that of their containing utterances, estimating information content with an adaptive neural language model. We observe that construction usage lowers the information content of utterances. This facilitating effect (i) increases throughout dialogues, (ii) is boosted by repetition, (iii) grows as a function of repetition frequency and density, and (iv) is stronger for repetitions of referential constructions.},
	urldate = {2022-10-20},
	publisher = {arXiv},
	author = {Giulianelli, Mario and Sinclair, Arabella and Fernández, Raquel},
	month = oct,
	year = {2022},
	note = {arXiv:2210.08321 [cs]},
}

@article{trott_languages_2022,
	title = {Languages are efficient, but for whom?},
	volume = {225},
	issn = {00100277},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027722000828},
	doi = {10.1016/j.cognition.2022.105094},
	language = {en},
	urldate = {2022-10-19},
	journal = {Cognition},
	author = {Trott, Sean and Bergen, Benjamin},
	month = aug,
	year = {2022},
	pages = {105094},
}

@article{button_against_2008,
	title = {Against `{Distributed} {Cognition}'},
	url = {https://journals.sagepub.com/doi/epdf/10.1177/0263276407086792},
	doi = {10.1177/0263276407086792},
	language = {en},
	urldate = {2022-10-13},
	journal = {Theory, Culture \& Society},
	author = {Button, Graham},
	month = mar,
	year = {2008},
	note = {Publisher: Sage PublicationsSage UK: London, England},
}

@book{coulter_social_1979,
	address = {London},
	title = {The social construction of mind: studies in ethnomethodology and linguistic philosophy},
	isbn = {978-0-333-23882-0},
	shorttitle = {The social construction of mind},
	publisher = {Macmillan},
	author = {Coulter, Jeff},
	year = {1979},
}

@book{edwards_discourse_1997,
	address = {London ; Thousand Oaks, Calif},
	title = {Discourse and cognition},
	isbn = {978-0-8039-7696-2 978-0-8039-7697-9},
	publisher = {SAGE Publications},
	author = {Edwards, Derek},
	year = {1997},
}

@book{depperman_action_2021,
	address = {Cambridge ; New York, NY},
	series = {Studies in interactional sociolinguistics},
	title = {Action ascription in interaction},
	isbn = {978-1-108-67341-9},
	abstract = {"Bringing together a team of global experts, this is the first volume to focus on the ways in which meanings are ascribed to actions in social interaction. It builds on the research traditions of Conversation Analysis and Pragmatics, and highlights the role of interactional, social, linguistic, multimodal, and epistemic factors in the formation and ascription of action-meanings. It shows how inference and intention ascription are displayed and drawn upon by participants in social interaction. Each chapter reveals practices, processes, and uses of action ascription, based on the analysis of audio and video recordings from nine languages. Action ascription is conceptualised in this volume as not merely a cognitive process, but a social action itself that is used for managing interactional concerns and guiding the subsequent course of social interaction. It will be essential reading for academic researchers and advanced students interested in the relationship between language, behaviour and social interaction"--},
	number = {35},
	publisher = {Cambridge University Press},
	editor = {Depperman, Arnulf and Haugh, Michael},
	year = {2021},
}

@incollection{depperman_multiple_2021,
	address = {Cambridge ; New York, NY},
	series = {Studies in interactional sociolinguistics},
	title = {The {Multiple} {Accountabilities} of {Action}},
	isbn = {978-1-108-67341-9},
	number = {35},
	booktitle = {Action ascription in interaction},
	publisher = {Cambridge University Press},
	author = {Heritage, John},
	editor = {Depperman, Arnulf and Haugh, Michael},
	year = {2021},
	pages = {297--329},
}

@incollection{depperman_action_2021-1,
	address = {Cambridge ; New York, NY},
	series = {Studies in interactional sociolinguistics},
	title = {Action and {Accountability} in {Interaction}},
	isbn = {978-1-108-67341-9},
	number = {35},
	booktitle = {Action ascription in interaction},
	publisher = {Cambridge University Press},
	author = {Enfield, N.J. and Sidnell, Jack},
	editor = {Depperman, Arnulf and Haugh, Michael},
	year = {2021},
	pages = {279--296},
}

@article{robinson_bias_2022,
	title = {The {Bias} {Toward} {Single}-{Unit} {Turns} in {Conversation}},
	volume = {55},
	issn = {0835-1813, 1532-7973},
	url = {https://www.tandfonline.com/doi/full/10.1080/08351813.2022.2067436},
	doi = {10.1080/08351813.2022.2067436},
	language = {en},
	number = {2},
	urldate = {2022-10-06},
	journal = {Research on Language and Social Interaction},
	author = {Robinson, Jeffrey D. and Rühlemann, Christoph and Rodriguez, Daniel Taylor},
	month = apr,
	year = {2022},
	pages = {165--183},
}

@article{torok_rationality_2019,
	title = {Rationality in {Joint} {Action}: {Maximizing} {Coefficiency} in {Coordination}},
	volume = {30},
	issn = {0956-7976},
	shorttitle = {Rationality in {Joint} {Action}},
	url = {https://doi.org/10.1177/0956797619842550},
	doi = {10.1177/0956797619842550},
	abstract = {When people perform simple actions, they often behave efficiently, minimizing the costs of movement for the expected benefit. The present study addressed the question of whether this efficiency scales up to dyads working together to achieve a shared goal: Do people act efficiently as a group (i.e., coefficiently), or do they minimize their own or their partner?s individual costs even if this increases the overall cost for the group? We devised a novel, touch-screen-based, sequential object-transfer task to measure how people choose between different paths to coordinate with a partner. Across multiple experiments, we found that participants did not simply minimize their own or their partner?s movement costs but made coefficient decisions about paths, which ensured that the aggregate costs of movement for the dyad were minimized. These results suggest that people are able and motivated to make coefficient, collectively rational decisions when acting together.},
	language = {en},
	number = {6},
	urldate = {2022-10-05},
	journal = {Psychological Science},
	author = {Török, Georgina and Pomiechowska, Barbara and Csibra, Gergely and Sebanz, Natalie},
	month = jun,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	pages = {930--941},
}

@article{vesper_minimal_2010,
	title = {A minimal architecture for joint action},
	volume = {23},
	number = {8-9},
	journal = {Neural Networks},
	author = {Vesper, Cordula and Butterfill, Stephen and Knoblich, Günther and Sebanz, Natalie},
	year = {2010},
	note = {Publisher: Elsevier},
	pages = {998--1003},
}

@book{suchman_human-machine_2007,
	address = {Cambridge},
	edition = {2nd ed},
	title = {Human-machine reconfigurations: plans and situated actions},
	isbn = {978-0-521-85891-5 978-0-521-67588-8},
	shorttitle = {Human-machine reconfigurations},
	publisher = {Cambridge University Press},
	author = {Suchman, Lucy A.},
	year = {2007},
	note = {OCLC: ocm64592145},
}

@incollection{suchman_demystifying_2019,
	address = {Cham},
	series = {Social and {Cultural} {Studies} of {Robots} and {AI}},
	title = {Demystifying the {Intelligent} {Machine}},
	isbn = {978-3-030-21836-2},
	url = {https://doi.org/10.1007/978-3-030-21836-2_3},
	abstract = {Taking inspiration from critical studies in the history, culture, and politics of technology, this chapter considers some contemporary developments in the project of creating humanlike machines. My main focus is on humanoid robots, examining how their capacities are figured in relevant technocultural imaginaries and material practices, and the domains in which they are projected into the lives—and deaths—of humans. I look for resources that can help us to think critically about the unquestioned assumptions that these stories repeat, at the same time that they purport to be telling us about things that are unprecedented and, most disturbingly, inevitable. A central goal of this exercise is to identify the contingencies that make the futures reported highly uncertain ones and to contribute to ways of imagining and making our futures differently.},
	language = {en},
	urldate = {2021-11-16},
	booktitle = {Cyborg {Futures}: {Cross}-disciplinary {Perspectives} on {Artificial} {Intelligence} and {Robotics}},
	publisher = {Springer International Publishing},
	author = {Suchman, Lucy A.},
	editor = {Heffernan, Teresa},
	year = {2019},
	doi = {10.1007/978-3-030-21836-2_3},
	pages = {35--61},
}

@article{fuchs_understanding_2022,
	title = {Understanding {Sophia}? {On} human interaction with artificial agents},
	issn = {1572-8676},
	shorttitle = {Understanding {Sophia}?},
	url = {https://doi.org/10.1007/s11097-022-09848-0},
	doi = {10.1007/s11097-022-09848-0},
	abstract = {Advances in artificial intelligence (AI) create an increasing similarity between the performance of AI systems or AI-based robots and human communication. They raise the questions:},
	language = {en},
	urldate = {2022-10-04},
	journal = {Phenomenology and the Cognitive Sciences},
	author = {Fuchs, Thomas},
	month = sep,
	year = {2022},
}

@inproceedings{ebert_introduction_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Introduction to the 2nd {Edition} of “{Semantic}, {Artificial} and {Computational} {Interaction} {Studies}”},
	isbn = {978-3-031-17618-0},
	doi = {10.1007/978-3-031-17618-0_3},
	abstract = {“Behavioromics” is a term that has been invented to cover the study of multimodal interaction from various disciplines and points of view. These disciplines and points of view, however, lack a platform for exchange. The workshop session on “Semantic, artificial and computational interaction studies” provides such a platform. We motivate behavioromics, sketch its historical background, and summarize this year’s contributions.},
	language = {en},
	booktitle = {{HCI} {International} 2022 - {Late} {Breaking} {Papers}. {Multimodality} in {Advanced} {Interaction} {Environments}},
	publisher = {Springer Nature Switzerland},
	author = {Ebert, Cornelia and Lücking, Andy and Mehler, Alexander},
	editor = {Kurosu, Masaaki and Yamamoto, Sakae and Mori, Hirohiko and Schmorrow, Dylan D. and Fidopiastis, Cali M. and Streitz, Norbert A. and Konomi, Shin'ichi},
	year = {2022},
	pages = {36--47},
}

@article{suchman_representing_1988,
	title = {Representing practice in cognitive science},
	volume = {11},
	issn = {1572-851X},
	url = {https://doi.org/10.1007/BF00177307},
	doi = {10.1007/BF00177307},
	language = {en},
	number = {2},
	urldate = {2022-09-28},
	journal = {Human Studies},
	author = {Suchman, Lucy A.},
	month = apr,
	year = {1988},
	pages = {305--325},
}

@article{botvinick_planning_2012,
	title = {Planning as inference},
	volume = {16},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661312001957},
	doi = {10.1016/j.tics.2012.08.006},
	abstract = {Recent developments in decision-making research are bringing the topic of planning back to center stage in cognitive science. This renewed interest reopens an old, but still unanswered question: how exactly does planning happen? What are the underlying information processing operations and how are they implemented in the brain? Although a range of interesting possibilities exists, recent work has introduced a potentially transformative new idea, according to which planning is accomplished through probabilistic inference.},
	language = {en},
	number = {10},
	urldate = {2022-09-28},
	journal = {Trends in Cognitive Sciences},
	author = {Botvinick, Matthew and Toussaint, Marc},
	month = oct,
	year = {2012},
	pages = {485--488},
}

@book{luff_computers_1990,
	address = {London},
	series = {Computers and people series},
	title = {Computers and conversation},
	isbn = {978-0-08-050264-9},
	abstract = {In the past few years a branch of sociology, conversation analysis, has begun to have a significant impact on the design of human*b1computer interaction (HCI). The investigation of human*b1human dialogue has emerged as a fruitful foundation for interactive system design.****This book includes eleven original chapters by leading researchers who are applying conversation analysis to HCI. The fundamentals of conversation analysis are outlined, a number of systems are described, and a critical view of their value for HCI is offered.****Computers and Conversation will be of interest to all concerned with HCI issues--from the advanced student to the professional computer scientist involved in the design and specification of interactive systems},
	language = {eng},
	publisher = {Academic Press},
	editor = {Luff, Paul and Gilbert, G. Nigel and Frohlich, David},
	year = {1990},
}

@incollection{luff_repair_1990,
	address = {London},
	series = {Computers and people series},
	title = {Repair and {Cooperation} in {Conversation}},
	isbn = {978-0-08-050264-9},
	abstract = {In the past few years a branch of sociology, conversation analysis, has begun to have a significant impact on the design of human*b1computer interaction (HCI). The investigation of human*b1human dialogue has emerged as a fruitful foundation for interactive system design.****This book includes eleven original chapters by leading researchers who are applying conversation analysis to HCI. The fundamentals of conversation analysis are outlined, a number of systems are described, and a critical view of their value for HCI is offered.****Computers and Conversation will be of interest to all concerned with HCI issues--from the advanced student to the professional computer scientist involved in the design and specification of interactive systems},
	language = {eng},
	booktitle = {Computers and conversation},
	publisher = {Academic Press},
	author = {Good, David},
	editor = {Luff, Paul and Gilbert, G. Nigel and Frohlich, David},
	year = {1990},
	pages = {133--150},
}

@article{forster_enactivism_2019,
	title = {Enactivism and {Robotic} {Language} {Acquisition}: {A} {Report} from the {Frontier}},
	volume = {4},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2409-9287},
	shorttitle = {Enactivism and {Robotic} {Language} {Acquisition}},
	url = {https://www.mdpi.com/2409-9287/4/1/11},
	doi = {10.3390/philosophies4010011},
	abstract = {In this article, I assess an existing language acquisition architecture, which was deployed in linguistically unconstrained human–robot interaction, together with experimental design decisions with regard to their enactivist credentials. Despite initial scepticism with respect to enactivism’s applicability to the social domain, the introduction of the notion of participatory sense-making in the more recent enactive literature extends the framework’s reach to encompass this domain. With some exceptions, both our architecture and form of experimentation appear to be largely compatible with enactivist tenets. I analyse the architecture and design decisions along the five enactivist core themes of autonomy, embodiment, emergence, sense-making, and experience, and discuss the role of affect due to its central role within our acquisition experiments. In conclusion, I join some enactivists in demanding that interaction is taken seriously as an irreducible and independent subject of scientific investigation, and go further by hypothesising its potential value to machine learning.},
	language = {en},
	number = {1},
	urldate = {2022-09-27},
	journal = {Philosophies},
	author = {Förster, Frank},
	month = mar,
	year = {2019},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {11},
}

@article{forster_robots_2019,
	title = {Robots {Learning} to {Say} “{No}”: {Prohibition} and {Rejective} {Mechanisms} in {Acquisition} of {Linguistic} {Negation}},
	volume = {8},
	shorttitle = {Robots {Learning} to {Say} “{No}”},
	url = {https://doi.org/10.1145/3359618},
	doi = {10.1145/3359618},
	abstract = {“No” is one of the first ten words used by children and embodies the first form of linguistic negation. Despite its early occurrence, the details of its acquisition remain largely unknown. The circumstance that “no” cannot be construed as a label for perceptible objects or events puts it outside the scope of most modern accounts of language acquisition. Moreover, most symbol grounding architectures will struggle to ground the word due to its non-referential character. The presented work extends symbol grounding to encompass affect and motivation. In a study involving the child-like robot iCub, we attempt to illuminate the acquisition process of negation words. The robot is deployed in speech-wise unconstrained interaction with participants acting as its language teachers. The results corroborate the hypothesis that affect or volition plays a pivotal role in the acquisition process. Negation words are prosodically salient within prohibitive utterances and negative intent interpretations such that they can be easily isolated from the teacher’s speech signal. These words subsequently may be grounded in negative affective states. However, observations of the nature of prohibition and the temporal relationships between its linguistic and extra-linguistic components raise questions over the suitability of Hebbian-type algorithms for certain types of language grounding.},
	number = {4},
	urldate = {2022-09-27},
	journal = {ACM Transactions on Human-Robot Interaction},
	author = {Förster, Frank and Saunders, Joe and Lehmann, Hagen and Nehaniv, Chrystopher L.},
	month = nov,
	year = {2019},
	pages = {23:1--23:26},
}

@unpublished{lerner_completable_1998,
	title = {Completable {Projects} and {Winnable} {Games}: {Notes} on the {Organization} of {Activity}},
	author = {Lerner, Gene H.},
	year = {1998},
}

@book{maynard_ethnomethodology_2022,
	address = {New York, NY},
	title = {The ethnomethodology program: legacies and prospects},
	isbn = {978-0-19-085441-6 978-0-19-085440-9},
	shorttitle = {The ethnomethodology program},
	abstract = {"This paper aims at contributing to a reflection about the legacy of Harold Garfinkel and the relations between ethnomethodology (EM) and conversation analysis (CA), by focusing on a common concern for both programs: the study of action as methodic (the term is used here in line with the sense of ethnomethodology), i.e. ordered, accountable, recognizable, and reproducible. Both approaches seek to describe the members' (term favored in ethnomethodology) or coparticipants' (term favored in conversation analysis) production, recognition, and reproduction of actions understood as locally situated social achievements. Within this framework, the chapter discusses two key dimensions of methodically produced actions - their situatedness and orderliness - and attempts to show the importance of considering both of them together. This discussion is developed in relation to a more recent trend in ethnomethodology and conversation analysis, based on the use of video materials documenting naturally occurring social interactions, permitting the fine-grained scrutinity of the multimodal details of action. Multimodal analysis generates new insights into both the situated and the ordered dimensions of the organization of social action"--},
	publisher = {Oxford University Press},
	editor = {Maynard, Douglas W. and Heritage, John},
	year = {2022},
}

@inproceedings{gnjatovic_electrophysiologically-inspired_2013,
	address = {New York},
	title = {Electrophysiologically-{Inspired} {Evaluation} of {Dialogue} {Act} {Complexity}},
	isbn = {978-1-4799-1543-9 978-1-4799-1546-0},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	abstract = {This paper proposes a computationally appropriate approach to evaluation of the dialogue act complexity in human-machine interaction inspired by a functional interpretation of the N400 and P600 components of electroencephalographic signals. Two main parameters of the dialogue act complexity are: the retrieval cost and the integration cost. At the conceptual level, the retrieval cost of a dialogue act reflects the cognitive load related to the retrieval of lexical information from long-term memory necessary to process the dialogue act. The integration cost of a dialogue act reflects the cognitive load related to integration difficulty caused by an incomplete, ambiguous or semantically irregular dialogue act. The proposed approach is illustrated for a dedicated therapeutic scenario including speech-based three-party interaction between the child, the therapist, and the robotic system with an integrated conversational agent.},
	language = {English},
	urldate = {2022-09-20},
	booktitle = {2013 {Ieee} 4th {International} {Conference} on {Cognitive} {Infocommunications} (coginfocom)},
	publisher = {Ieee},
	author = {Gnjatovic, Milan and Delic, Vlado},
	year = {2013},
	note = {ISSN: 2375-1312
WOS:000349770000028},
	keywords = {computational models, real, robot-assisted therapy},
	pages = {167--172},
}

@inproceedings{meijer_plantbot_2020,
	address = {New York},
	title = {{PlantBot}: {A} {Social} {Robot} {Prototype} to {Help} with {Behavioral} {Activation} in {Young} {People} with {Minor} {Depression}},
	isbn = {978-1-4503-7057-8},
	shorttitle = {{PlantBot}},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	doi = {10.1145/3371382.3378210},
	abstract = {The PlantBot is a home device that shows iconographic or simple lights to depict actions that it requests a young person (its user) to do as part of Behavioral Activation therapy. In this initial prototype, a separate conversational speech agent (i.e., Amazon Alexa) is wizarded to act as a second system the user can interact with.},
	language = {English},
	urldate = {2022-09-20},
	booktitle = {Hri'20: {Companion} of the 2020 {Acm}/{Ieee} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {Assoc Computing Machinery},
	author = {Meijer, Max Jan and Dokter, Maaike and Boersma, Christiaan and Bhat, Ashwin Sadananda and Bohlmeijer, Ernst and Li, Jamy},
	year = {2020},
	note = {ISSN: 2167-2121
WOS:000643728500016},
	keywords = {Behavior Activation Therapy, Depression, Motivation, Plant Robot, Smart   Speaker},
	pages = {76--76},
}

@article{demiris_examining_2022,
	title = {Examining spoken words and acoustic features of therapy sessions to understand family caregivers' anxiety and quality of life},
	volume = {160},
	issn = {1386-5056},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	doi = {10.1016/j.ijmedinf.2022.104716},
	abstract = {Background: Speech and language cues are considered significant data sources that can reveal insights into one's behavior and well-being. The goal of this study is to evaluate how different machine learning (ML) classifiers trained both on the spoken word and acoustic features during live conversations between family caregivers and a therapist, correlate to anxiety and quality of life (QoL) as assessed by validated instruments. Methods: The dataset comprised of 124 audio-recorded and professionally transcribed discussions between family caregivers of hospice patients and a therapist, of challenges they faced in their caregiving role, and standardized assessments of self-reported QoL and anxiety. We custom-built and trained an Automated Speech Recognition (ASR) system on older adult voices and created a logistic regression-based classifier that incorporated audio based features. The classification process automated the QoL scoring and display of the score in real time, replacing hand-coding for self-reported assessments with a machine learning identified classifier. Findings: Of the 124 audio files and their transcripts, 87 of these transcripts (70\%) were selected to serve as the training set, holding the remaining 30\% of the data for evaluation. For anxiety, the results of adding the dimension of sound and an automated speech-to-text transcription outperformed the prior classifier trained only on human-rendered transcriptions. Specifically, precision improved from 86\% to 92\%, accuracy from 81\% to 89\%, and recall from 78\% to 88\%. Interpretation: Classifiers can be developed through ML techniques which can indicate improvements in QoL measures with a reasonable degree of accuracy. Examining the content, sound of the voice and context of the conversation provides insights into additional factors affecting anxiety and QoL that could be addressed in tailored therapy and the design of conversational agents serving as therapy chatbots.},
	language = {English},
	urldate = {2022-09-20},
	journal = {International Journal of Medical Informatics},
	author = {Demiris, George and Oliver, Debra Parker and Washington, Karla T. and Chadwick, Chad and Voigt, Jeffrey D. and Brotherton, Sam and Naylor, Mary D.},
	month = apr,
	year = {2022},
	note = {Place: Clare
Publisher: Elsevier Ireland Ltd
WOS:000790930500017},
	keywords = {Caregiver, Chatbot, Communication, Machine learning, Quality of life, adjustment, impact, risk, speech},
	pages = {104716},
}

@article{kroeger_model_2010,
	title = {A model for production, perception, and acquisition of actions in face-to-face communication},
	volume = {11},
	issn = {1612-4782},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	doi = {10.1007/s10339-009-0351-2},
	abstract = {The concept of action as basic motor control unit for goal-directed movement behavior has been used primarily for private or non-communicative actions like walking, reaching, or grasping. In this paper, literature is reviewed indicating that this concept can also be used in all domains of face-to-face communication like speech, co-verbal facial expression, and co-verbal gesturing. Three domain-specific types of actions, i.e. speech actions, facial actions, and hand-arm actions, are defined in this paper and a model is proposed that elucidates the underlying biological mechanisms of action production, action perception, and action acquisition in all domains of face-to-face communication. This model can be used as theoretical framework for empirical analysis or simulation with embodied conversational agents, and thus for advanced human-computer interaction technologies.},
	language = {English},
	number = {3},
	urldate = {2022-09-20},
	journal = {Cognitive Processing},
	author = {Kroeger, Bernd J. and Kopp, Stefan and Lowit, Anja},
	month = aug,
	year = {2010},
	note = {Place: Heidelberg
Publisher: Springer Heidelberg
WOS:000280594500001},
	keywords = {Action, Co-verbal behavior, Face-to-face communication, Facial   expression, Speech, action representation, dynamics, equilibrium-point hypothesis, feedback, gestures, imitation, motor   control, movement, speech production, spontaneous facial expressions},
	pages = {187--205},
}

@incollection{massaro_psychology_2005,
	address = {Dordrecht},
	title = {The {Psychology} and {Technology} of {Talking} {Heads}: {Applications} in {Language} {Learning}},
	volume = {30},
	isbn = {978-1-4020-3933-1},
	shorttitle = {The {Psychology} and {Technology} of {Talking} {Heads}},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	abstract = {Given the value of visible speech, our persistent goal has been to develop, evaluate, and apply animated agents to produce accurate visible speech. The goal of our recent research has been to increase the number of agents and to improve the accuracy of visible speech. Perceptual tests indicted positive results of this work. Given this technology and the framework of the fuzzy logical model of perception (FLMP), we have developed computer-assisted speech and language tutors for deaf, hard of hearing, and autistic children. Baldi(1), as the conversational agent, guides students through a variety of exercises designed to teach vocabulary and grammar, to improve speech articulation, and to develop linguistic and phonological awareness. The results indicate that the psychology and technology of Baldi holds great promise in language learning and speech therapy.},
	language = {English},
	urldate = {2022-09-20},
	booktitle = {Advances in {Natural} {Multimodal} {Dialogue} {Systems}},
	publisher = {Springer},
	author = {Massaro, Dominic W.},
	editor = {VanKuppevelt, J. C. J. and Dybkjaer, L. and Bernsen, N. O.},
	year = {2005},
	note = {ISSN: 1386-291X
WOS:000269751500010},
	keywords = {Facial animation, autism, children, children with language challenges, language learning, perception, speech, speech perception, visible speech, vocabulary, vocabulary tutor},
	pages = {183--214},
}

@inproceedings{mower_rachel_2011,
	address = {New York},
	title = {Rachel: {Design} of an {Emotionally} {Targeted} {Interactive} {Agent} for {Children} with {Autism}},
	isbn = {978-1-61284-349-0},
	shorttitle = {Rachel},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	abstract = {Increasingly, multimodal human-computer interactive tools are leveraged in both autism research and therapies. Embodied conversational agents (ECAs) are employed to facilitate the collection of socio-emotional interactive data from children with autism. In this paper we present an overview of the Rachel system developed at the University of Southern California. The Rachel ECA is designed to elicit and analyze complex, structured, and naturalistic interactions and to encourage affective and social behavior. The pilot studies suggest that this tool can be used to effectively elicit social conversational behavior. This paper presents a description of the multimodal human-computer interaction system and an overview of the collected data. Future work includes utilizing signal processing techniques to provide a quantitative description of the interaction patterns.},
	language = {English},
	urldate = {2022-09-20},
	booktitle = {2011 {Ieee} {International} {Conference} on {Multimedia} and {Expo} (icme)},
	publisher = {Ieee},
	author = {Mower, Emily and Black, Matthew P. and Flores, Elisa and Williams, Marian and Narayanan, Shrikanth},
	year = {2011},
	note = {ISSN: 1945-7871
WOS:000297172100159},
	keywords = {Embodied conversational agent, audio-video   recording, autism, children's speech, multimodal interface},
}

@inproceedings{das_automated_2017,
	address = {New York},
	title = {An {Automated} {Speech}-{Language} {Therapy} {Tool} with {Interactive} {Virtual} {Agent} and {Peer}-to-{Peer} {Feedback}},
	isbn = {978-1-5386-0869-2},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	abstract = {Widespread use of technology has brought about revolutionary changes in health domain. Treatment of speech and language disorders is one such field where computer-based techniques have the potential to provide readily available therapy at low cost by reducing the reliance on therapists and clinicians. Although significant research has been performed on computer aided speech and language therapy, existing approaches do not focus on the nonverbal behavioral cues of a patient in a natural conversational scenario. In this paper, we propose an automated speech and language therapy tool with an intelligent and interactive virtual agent playing the role of a therapist. Besides giving feedback to the patient's response on various therapeutic tasks, the virtual therapist has the ability to carry out a conversation with the patient and give feedback on their nonverbal behavioral cues to help them improve their communicating ability. Additionally, our proposed system supports computerized peer-to-peer conversation in real-life scenarios which is also underrepresented in existing research concerning computer-assisted speech language therapy.},
	language = {English},
	urldate = {2022-09-20},
	booktitle = {2017 4th {International} {Conference} on {Advances} in {Electrical} {Engineering} (icaee)},
	publisher = {Ieee},
	author = {Das, Maitraye and Saha, Abir},
	year = {2017},
	note = {ISSN: 2378-2668
WOS:000428083300094},
	keywords = {aphasia, apraxia, atontated speech and language therapy, communication, intervention, peer-to-peer   feedback, randomized controlled-trial, virtual therapist},
	pages = {510--515},
}

@inproceedings{spitale_whom_2020,
	address = {New York},
	title = {"{Whom} would you like to talk with?" {Exploring} {Conversational} {Agents} for {Children}'s {Linguistic} {Assessment}},
	isbn = {978-1-4503-7981-6},
	shorttitle = {"{Whom} would you like to talk with?},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	doi = {10.1145/3392063.3394421},
	abstract = {The dramatic increment of communication impairments among children increases the demand for intensive, highly accessible and low-cost interventions as well as new assessment and therapeutic tools. Our research aims at exploring the use of Conversational Agents (CAs) to support linguistic assessment and training among children with language impairment. One of the open research issues in this arena concerns the identification of the most appropriate form of "embodiment" of the CA for children to interact with. To this end, we evaluated the linguistic performance of 14 neuro-typical children and 3 children with language impairment comparing different CAs - physical object and virtual character - with "traditional" human interaction. Based on our analysis, we identify insights for the design of CA: the physicality does influence the performance of linguistic tasks for children with linguistic impairment. In addition, children seem to show a preference for the physical CA and perceived it as smarter than the virtual one.},
	language = {English},
	urldate = {2022-09-20},
	booktitle = {Proceedings of {Idc} 2020},
	publisher = {Assoc Computing Machinery},
	author = {Spitale, Micol and Silleresi, Silvia and Cosentino, Giulia and Panzeri, Francesca and Garzotto, Franca},
	year = {2020},
	note = {WOS:000675620600022},
	keywords = {Children Perception, Conversational Agent, Linguistic Assessment, Speech Therapy, autism spectrum disorders, intelligence, language impairment, robots},
	pages = {262--272},
}

@inproceedings{lucila_morales-rodriguez_towards_2008,
	address = {Berlin},
	title = {Towards the {Simulation} of {Social} {Interactions} through {Embodied} {Conversational} {Agents}},
	volume = {5271},
	isbn = {978-3-540-87655-7},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	abstract = {In this paper, we present a pluridisciplinary approach in order to model the behavior of an embodied conversational agent that expresses emotional and social interactions. We present our methodology to reproduce credible social interactions. Particularly, we discuss the role of the context, the culture, and the emotions in the model of the management of speech acts. This model has been implemented in the context of virtual therapy to simulate the interaction between a therapist and a post-CVA patient.},
	language = {English},
	urldate = {2022-09-20},
	booktitle = {Hybrid {Artificial} {Intelligence} {Systems}},
	publisher = {Springer-Verlag Berlin},
	author = {Lucila Morales-Rodriguez, Maria and Pavard, Bernard and Gonzalez B, Juan J. and Martinez F, Josd A.},
	editor = {Corchado, E. and Abraham, A. and Pedrycz, W.},
	year = {2008},
	note = {ISSN: 0302-9743
WOS:000259875000066},
	keywords = {embodied   conversational agents, emotional and social interaction, situated cognition, virtual therapy},
	pages = {551--+},
}

@article{brown_investigation_2016,
	title = {An investigation of the effects of a speech-restructuring treatment for stuttering on the distribution of intervals of phonation},
	volume = {50},
	issn = {0094-730X},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	doi = {10.1016/j.jfludis.2016.09.001},
	abstract = {Purpose: The purpose of this study was to investigate whether stuttering reductions following the instatement phase of a speech-restructuring treatment for adults were accompanied by reductions in the frequency of short intervals of phonation (Pis). The study was prompted by the possibility that reductions in the frequency of short PIs is the mechanism underlying such reductions in stuttering. Method: The distribution of PIs was determined for seven adults who stutter, before and immediately after the intensive phase of a speech-restructuring treatment program. Audiovisual recordings of conversational speech were made on both assessment occasions, with Pis recorded with an accelerometer. Results: All seven participants had much lower levels of stuttering after treatment but these were associated with reductions in the frequency of short PIs for only four of them. For the other three participants, two showed no change in frequency of short Pis, while for the other participant the frequency of short Pis actually increased. Conclusions: Stuttering reduction with speech-restructuring treatment can co-occur with reduction in the frequency of short PIs. However, the latter does not appear necessary for this reduction in stuttering to occur. Thus, speech-restructuring treatment must have other, or additional, treatment agents for stuttering to reduce. (C) 2016 Elsevier Inc. All rights reserved.},
	language = {English},
	urldate = {2022-09-20},
	journal = {Journal of Fluency Disorders},
	author = {Brown, Lisa and Wilson, Linda and Packman, Ann and Halaki, Mark and Onslow, Mark and Menzies, Ross},
	month = dec,
	year = {2016},
	note = {Place: New York
Publisher: Elsevier Science Inc
WOS:000389093700002},
	keywords = {Intervals of phonation, Speech-restructuring, Stuttering, adults, fluency-inducing conditions, prolonged-speech, quality, therapy, treatment program},
	pages = {13--22},
}

@inproceedings{kimani_youll_2019,
	address = {New York},
	title = {You'll be {Great}: {Virtual} {Agent}-based {Cognitive} {Restructuring} to {Reduce} {Public} {Speaking} {Anxiety}},
	isbn = {978-1-72813-888-6},
	shorttitle = {You'll be {Great}},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	abstract = {Public speaking is an essential task for success in many careers, yet fear of public speaking makes this an undesirable activity for most people and negatively affects the quality of many presentations. Cognitive behavioral therapy is an effective tool for helping people overcome social anxieties disorders, including public speaking anxiety. However, most people do not engage in this therapy for public speaking anxiety, due to time constraints and other barriers. We present a virtual coach that uses cognitive behavioral therapy techniques to help presenters restructure irrational thoughts associated with public speaking anxiety. The design of the virtual coach was informed by an analysis of a corpus of cognitive restructuring examples generated by a clinical psychologist. In a between-subjects experiment comparing the virtual coach to a control condition, the virtual coach was shown to be significantly better at reducing thoughts associated with speech anxiety and improving a presentation experience for speakers.},
	language = {English},
	urldate = {2022-09-20},
	booktitle = {2019 8th {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} (acii)},
	publisher = {Ieee},
	author = {Kimani, Everlyne and Bickmore, Timothy and Trinh, Ha and Pedrelli, Paola},
	year = {2019},
	note = {ISSN: 2156-8103
WOS:000522220800004},
	keywords = {behavioral therapy, cognitive behavioral therapy, embodied conversational agents, intelligent interactions, inventory, natural language generation, public speaking anxiety, reality, scale development, social anxiety, speech anxiety, virtual   agents},
}

@inproceedings{mohamad_agent-based_2012,
	address = {Newark},
	title = {Agent-{Based} {Technology} {Systems} and {Student}'s {Motivational} {State}},
	volume = {12},
	isbn = {978-1-61275-009-5},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	abstract = {This paper was imagining a university where an intelligent learning system uses conversational pedagogical agents to provide independent, immersive and effective tutoring, assistance or speech therapy. The primary function of pedagogical agents is to help a user better use, manage, and interact with a computer such as campus portal system. Agent-based technology systems are assumed to involved artificial intelligence (AI) and included a degree of autonomous problem-solving ability. Initially, a total number of 43 students enrolled for the subject Telecommunication and Networking participated in the pre-experimental research study using the Autotutor as the instrument. The pilot study was conducted and showed the reliability coefficient with Cronbach's alpha is 0.979. This research looks into student motivation after the learning process with pedagogical agents that provide educational environment or computer support learning. The specific purpose of this paper was to investigate the effects of students' motivation during the learning process with a pedagogical agent and its effect on learning outcome and the motivational state during the interaction with pedagogical agents.},
	language = {English},
	urldate = {2022-09-20},
	booktitle = {2012 {International} {Conference} on {Artificial} {Intelligence} and {Soft} {Computing} (icaisc 2012)},
	publisher = {Information Engineering Research Inst, Usa},
	author = {Mohamad, Syamsul Nor Azlan},
	editor = {Lee, G.},
	year = {2012},
	note = {ISSN: 2070-1918
WOS:000310815000014},
	keywords = {Agent-Based Tutoring Systems, Animated Pedagogical Agent and   Motivational State, social agency},
	pages = {82--88},
}

@book{callejas_affective_2011,
	address = {Hersey},
	title = {Affective {Conversational} {Agents}: {The} {Role} of {Personality} and {Emotion} in {Spoken} {Interactions}},
	isbn = {978-1-60960-618-3 978-1-60960-617-6},
	shorttitle = {Affective {Conversational} {Agents}},
	url = {http://www.webofscience.com/wos/woscc/summary/fa0e9b6a-8c19-48d7-b8f9-3bc2c18b067d-50354331/relevance/1},
	abstract = {In this chapter, we revisit the main theories of human emotion and personality and their implications for the development of affective conversational agents. We focus on the role that emotion plays for adapting the agents' behaviour and how this emotional responsivity can be conveniently modified by rendering a consistent artificial personality. The multiple applications of affective CAs are addressed by describing recent experiences in domains such as pedagogy, computer games, and computer-mediated therapy.},
	language = {English},
	urldate = {2022-09-20},
	publisher = {Igi Global},
	author = {Callejas, Zoraida and Lopez-Cozar, Ramon and Abalos, Nieves and Griol, David},
	year = {2011},
	doi = {10.4018/978-1-60960-617-6.ch009},
	note = {Pages: 203-222
Publication Title: Conversational Agents and Natural Language Interaction: Techniques and Effective Practices
WOS:000303201400010},
	keywords = {annotation, character, dialogue, recognition, speech},
}

@inproceedings{chan_training_2022,
	title = {Training and typological bias in {ASR} performance for world {Englishes}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/chan22b_interspeech.html},
	doi = {10.21437/Interspeech.2022-10869},
	language = {en},
	urldate = {2022-09-20},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Chan, May Pik Yu and Choe, June and Li, Aini and Chen, Yiran and Gao, Xin and Holliday, Nicole},
	month = sep,
	year = {2022},
	pages = {1273--1277},
}

@inproceedings{hou_bring_2022,
	title = {Bring dialogue-context into {RNN}-{T} for streaming {ASR}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/hou22b_interspeech.html},
	doi = {10.21437/Interspeech.2022-697},
	language = {en},
	urldate = {2022-09-20},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Hou, junfeng and Chen, Jinkun and Li, Wanyu and Tang, Yufeng and Zhang, Jun and Ma, Zejun},
	month = sep,
	year = {2022},
	pages = {2048--2052},
}

@inproceedings{masumura_end--end_2022,
	title = {End-to-{End} {Joint} {Modeling} of {Conversation} {History}-{Dependent} and {Independent} {ASR} {Systems} with {Multi}-{History} {Training}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/masumura22_interspeech.html},
	doi = {10.21437/Interspeech.2022-11357},
	language = {en},
	urldate = {2022-09-20},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Masumura, Ryo and Yamazaki, Yoshihiro and Mizuno, Saki and Makishima, Naoki and Ihori, Mana and Uchida, Mihiro and Sato, Hiroshi and Tanaka, Tomohiro and Takashima, Akihiko and Suzuki, Satoshi and Orihashi, Shota and Moriya, Takafumi and Hojo, Nobukatsu and Ando, Atsushi},
	month = sep,
	year = {2022},
	pages = {3218--3222},
}

@inproceedings{bradshaw_fundamental_2022,
	title = {Fundamental {Frequency} {Variability} over {Time} in {Telephone} {Interactions}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/bradshaw22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10669},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Bradshaw, Leah and Chodroff, Eleanor and Jäger, Lena and Dellwo, Volker},
	month = sep,
	year = {2022},
	pages = {101--105},
}

@inproceedings{pelloin_asr-generated_2022,
	title = {{ASR}-{Generated} {Text} for {Language} {Model} {Pre}-training {Applied} to {Speech} {Tasks}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/pelloin22_interspeech.html},
	doi = {10.21437/Interspeech.2022-352},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Pelloin, Valentin and Dary, Franck and Hervé, Nicolas and Favre, Benoit and Camelin, Nathalie and Laurent, Antoine and Besacier, Laurent},
	month = sep,
	year = {2022},
	pages = {3453--3457},
}

@inproceedings{adigwe_strategies_2022,
	title = {Strategies for developing a {Conversational} {Speech} {Dataset} for {Text}-{To}-{Speech} {Synthesis}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/adigwe22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10802},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Adigwe, Adaeze O. and Klabbers, Esther},
	month = sep,
	year = {2022},
	pages = {2318--2322},
}

@inproceedings{zhang_mitigating_2022,
	title = {Mitigating bias against non-native accents},
	url = {https://www.isca-speech.org/archive/interspeech_2022/zhang22n_interspeech.html},
	doi = {10.21437/Interspeech.2022-836},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Zhang, Yuanyuan and Zhang, Yixuan and Halpern, Bence and Patel, Tanvina and Scharenborg, Odette},
	month = sep,
	year = {2022},
	pages = {3168--3172},
}

@inproceedings{zhou_calibrate_2022,
	title = {Calibrate and {Refine}! {A} {Novel} and {Agile} {Framework} for {ASR} {Error} {Robust} {Intent} {Detection}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/zhou22b_interspeech.html},
	doi = {10.21437/Interspeech.2022-786},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Zhou, Peilin and Chong, Dading and Wang, Helin and Zeng, Qingcheng},
	month = sep,
	year = {2022},
	pages = {1096--1100},
}

@inproceedings{meripo_asr_2022,
	title = {{ASR} {Error} {Detection} via {Audio}-{Transcript} entailment},
	url = {https://www.isca-speech.org/archive/interspeech_2022/meripo22_interspeech.html},
	doi = {10.21437/Interspeech.2022-11177},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Meripo, Nimshi Venkat and Konam, Sandeep},
	month = sep,
	year = {2022},
	pages = {3358--3362},
}

@inproceedings{muhlack_revisiting_2021,
	title = {Revisiting {Recall} {Effects} of {Filler} {Particles} in {German} and {English}},
	url = {https://www.isca-speech.org/archive/interspeech_2021/muhlack21_interspeech.html},
	doi = {10.21437/Interspeech.2021-1056},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2021},
	publisher = {ISCA},
	author = {Muhlack, Beeke and Elmers, Mikey and Drenhaus, Heiner and Trouvain, Jürgen and Os, Marjolein van and Werner, Raphael and Ryzhova, Margarita and Möbius, Bernd},
	month = aug,
	year = {2021},
	pages = {3979--3983},
}

@inproceedings{lala_analysis_2019,
	title = {Analysis of {Effect} and {Timing} of {Fillers} in {Natural} {Turn}-{Taking}},
	url = {https://www.isca-speech.org/archive/interspeech_2019/lala19_interspeech.html},
	doi = {10.21437/Interspeech.2019-1527},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2019},
	publisher = {ISCA},
	author = {Lala, Divesh and Nakamura, Shizuka and Kawahara, Tatsuya},
	month = sep,
	year = {2019},
	pages = {4175--4179},
}

@inproceedings{zellers_overview_2022,
	title = {An overview of discourse clicks in {Central} {Swedish}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/zellers22_interspeech.html},
	doi = {10.21437/Interspeech.2022-583},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Zellers, Margaret},
	month = sep,
	year = {2022},
	pages = {3423--3427},
}

@inproceedings{ekstedt_voice_2022,
	title = {Voice {Activity} {Projection}: {Self}-supervised {Learning} of {Turn}-taking {Events}},
	shorttitle = {Voice {Activity} {Projection}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/ekstedt22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10955},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Ekstedt, Erik and Skantze, Gabriel},
	month = sep,
	year = {2022},
	pages = {5190--5194},
}

@inproceedings{yang_open_2022,
	title = {Open {Source} {MagicData}-{RAMC}: {A} {Rich} {Annotated} {Mandarin} {Conversational}({RAMC}) {Speech} {Dataset}},
	shorttitle = {Open {Source} {MagicData}-{RAMC}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/yang22h_interspeech.html},
	doi = {10.21437/Interspeech.2022-729},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Yang, Zehui and Chen, Yifan and Luo, Lei and Yang, Runyan and Ye, Lingxuan and Cheng, Gaofeng and Xu, Ji and Jin, Yaohui and Zhang, Qingqing and Zhang, Pengyuan and Xie, Lei and Yan, Yonghong},
	month = sep,
	year = {2022},
	pages = {1736--1740},
}

@inproceedings{wei_improving_2022,
	title = {Improving {Transformer}-based {Conversational} {ASR} by {Inter}-{Sentential} {Attention} {Mechanism}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/wei22c_interspeech.html},
	doi = {10.21437/Interspeech.2022-10066},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Wei, Kun and Guo, Pengcheng and Jiang, Ning},
	month = sep,
	year = {2022},
	pages = {3804--3808},
}

@inproceedings{omahony_combining_2022,
	title = {Combining conversational speech with read speech to improve prosody in {Text}-to-{Speech} synthesis},
	url = {https://www.isca-speech.org/archive/interspeech_2022/omahony22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10167},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {O'Mahony, Johannah and Lai, Catherine and King, Simon},
	month = sep,
	year = {2022},
	pages = {3388--3392},
}

@inproceedings{comini_low-data_2022,
	title = {Low-data? {No} problem: low-resource, language-agnostic conversational text-to-speech via {F0}-conditioned data augmentation},
	shorttitle = {Low-data?},
	url = {https://www.isca-speech.org/archive/interspeech_2022/comini22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10338},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Comini, Giulia and Huybrechts, Goeric and Ribeiro, Manuel Sam and Gabryś, Adam and Lorenzo-Trueba, Jaime},
	month = sep,
	year = {2022},
	pages = {1946--1950},
}

@inproceedings{chang_turn-taking_2022,
	title = {Turn-{Taking} {Prediction} for {Natural} {Conversational} {Speech}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/chang22_interspeech.html},
	doi = {10.21437/Interspeech.2022-566},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Chang, Shuo-Yiin and Li, Bo and Sainath, Tara and Zhang, Chao and Strohman, Trevor and Liang, Qiao and He, Yanzhang},
	month = sep,
	year = {2022},
	pages = {1821--1825},
}

@inproceedings{fernandez_transplantation_2022,
	title = {Transplantation of {Conversational} {Speaking} {Style} with {Interjections} in {Sequence}-to-{Sequence} {Speech} {Synthesis}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/fernandez22_interspeech.html},
	doi = {10.21437/Interspeech.2022-388},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Fernandez, Raul and Haws, David and Lorberbom, Guy and Shechtman, Slava and Sorin, Alexander},
	month = sep,
	year = {2022},
	pages = {5488--5492},
}

@inproceedings{sakuma_response_2022,
	title = {Response {Timing} {Estimation} for {Spoken} {Dialog} {System} using {Dialog} {Act} {Estimation}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/sakuma22_interspeech.html},
	doi = {10.21437/Interspeech.2022-746},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Sakuma, Jin and Fujie, Shinya and Kobayashi, Tetsunori},
	month = sep,
	year = {2022},
	pages = {4486--4490},
}

@inproceedings{ludusan_investigating_2022,
	title = {Investigating phonetic convergence of laughter in conversation},
	url = {https://www.isca-speech.org/archive/interspeech_2022/ludusan22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10332},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Ludusan, Bogdan and Schröer, Marin and Wagner, Petra},
	month = sep,
	year = {2022},
	pages = {1332--1336},
}

@inproceedings{wang_leveraging_2022,
	title = {Leveraging {Real} {Conversational} {Data} for {Multi}-{Channel} {Continuous} {Speech} {Separation}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/wang22x_interspeech.html},
	doi = {10.21437/Interspeech.2022-10706},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Wang, Xiaofei and Wang, Dongmei and Kanda, Naoyuki and Emre Eskimez, Sefik and Yoshioka, Takuya},
	month = sep,
	year = {2022},
	pages = {3814--3818},
}

@inproceedings{paturi_directed_2022,
	title = {Directed speech separation for automatic speech recognition of long form conversational speech},
	url = {https://www.isca-speech.org/archive/interspeech_2022/paturi22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10843},
	language = {en},
	urldate = {2022-09-18},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Paturi, Rohit and Srinivasan, Sundararajan and Kirchhoff, Katrin and Garcia-Romero, Daniel},
	month = sep,
	year = {2022},
	pages = {5388--5392},
}

@inproceedings{horii_end--end_2022,
	title = {End-to-{End} {Spontaneous} {Speech} {Recognition} {Using} {Disfluency} {Labeling}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/horii22_interspeech.html},
	doi = {10.21437/Interspeech.2022-281},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Horii, Koharu and Fukuda, Meiko and Ohta, Kengo and Nishimura, Ryota and Ogawa, Atsunori and Kitaoka, Norihide},
	month = sep,
	year = {2022},
	pages = {4108--4112},
}

@inproceedings{dao_disfluency_2022,
	title = {From {Disfluency} {Detection} to {Intent} {Detection} and {Slot} {Filling}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/dao22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10161},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Dao, Mai Hoang and Truong, Thinh and Nguyen, Dat Quoc},
	month = sep,
	year = {2022},
	pages = {1106--1110},
}

@inproceedings{ghosh_span_2022,
	title = {Span {Classification} with {Structured} {Information} for {Disfluency} {Detection} in {Spoken} {Utterances}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/ghosh22c_interspeech.html},
	doi = {10.21437/Interspeech.2022-11242},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Ghosh, Sreyan and Kumar, Sonal and Kumar, Yaman and Ratn Shah, Rajiv and Umesh, Srinivasan},
	month = sep,
	year = {2022},
	pages = {3998--4002},
}

@inproceedings{zhu_filler_2022,
	title = {Filler {Word} {Detection} and {Classification}: {A} {Dataset} and {Benchmark}},
	shorttitle = {Filler {Word} {Detection} and {Classification}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/zhu22e_interspeech.html},
	doi = {10.21437/Interspeech.2022-10992},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Zhu, Ge and Caceres, Juan-Pablo and Salamon, Justin},
	month = sep,
	year = {2022},
	pages = {3769--3773},
}

@inproceedings{farooq_investigating_2022,
	title = {Investigating the {Impact} of {Crosslingual} {Acoustic}-{Phonetic} {Similarities} on {Multilingual} {Speech} {Recognition}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/farooq22_interspeech.html},
	doi = {10.21437/Interspeech.2022-10916},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Farooq, Muhammad Umar and Hain, Thomas},
	month = sep,
	year = {2022},
	pages = {3849--3853},
}

@inproceedings{sanchez_unify_2022,
	title = {Unify and {Conquer}: {How} {Phonetic} {Feature} {Representation} {Affects} {Polyglot} {Text}-{To}-{Speech} ({TTS})},
	shorttitle = {Unify and {Conquer}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/sanchez22_interspeech.html},
	doi = {10.21437/Interspeech.2022-233},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Sanchez, Ariadna and Falai, Alessio and Zhang, Ziyao and Angelini, Orazio and Yanagisawa, Kayoko},
	month = sep,
	year = {2022},
	pages = {2963--2967},
}

@inproceedings{jabeen_hesitations_2022,
	title = {Hesitations in {Urdu}/{Hindi}: {Distribution} and {Properties} of {Fillers} \& {Silences}},
	shorttitle = {Hesitations in {Urdu}/{Hindi}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/jabeen22_interspeech.html},
	doi = {10.21437/Interspeech.2022-805},
	language = {en},
	urldate = {2022-09-19},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Jabeen, Farhat and Betz, Simon},
	month = sep,
	year = {2022},
	pages = {4491--4495},
}

@article{dunbar_self-supervised_2022,
	title = {Self-supervised language learning from raw audio: {Lessons} from the {Zero} {Resource} {Speech} {Challenge}},
	issn = {1932-4553, 1941-0484},
	shorttitle = {Self-supervised language learning from raw audio},
	url = {https://ieeexplore.ieee.org/document/9888095/},
	doi = {10.1109/JSTSP.2022.3206084},
	urldate = {2022-09-18},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Dunbar, Ewan and Hamilakis, Nicolas and Dupoux, Emmanuel},
	year = {2022},
	pages = {1--16},
}

@book{button2022ethnomethodology,
	title = {Ethnomethodology, conversation analysis and constructive analysis: {On} formal structures of practical action},
	publisher = {Taylor \& Francis},
	author = {Button, Graham and Lynch, Michael and Sharrock, Wes},
	year = {2022},
}

@inproceedings{ellison_measuring_2006,
	address = {Sydney, Australia},
	title = {Measuring language divergence by intra-lexical comparison},
	url = {http://portal.acm.org/citation.cfm?doid=1220175.1220210},
	doi = {10.3115/1220175.1220210},
	abstract = {This paper presents a method for building genetic language taxonomies based on a new approach to comparing lexical forms. Instead of comparing forms cross-linguistically, a matrix of languageinternal similarities between forms is calculated. These matrices are then compared to give distances between languages. We argue that this coheres better with current thinking in linguistics and psycholinguistics. An implementation of this approach, called PHILOLOGICON, is described, along with its application to Dyen et al.’s (1992) ninety-ﬁve wordlists from Indo-European languages.},
	language = {en},
	urldate = {2022-09-15},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Computational} {Linguistics} and the 44th annual meeting of the {ACL}  - {ACL} '06},
	publisher = {Association for Computational Linguistics},
	author = {Ellison, T. Mark and Kirby, Simon},
	year = {2006},
	pages = {273--280},
}

@article{skedsmo_multiple_2020,
	title = {Multiple {Other}-{Initiations} of {Repair} in {Norwegian} {Sign} {Language}},
	volume = {6},
	doi = {10.1515/opli-2020-0030},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d1100e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Not all other-initiations of repair (OIR) are instantly followed by a functional self-repair that restores the progress of the conversation. Despite previous observations of OIRs generally leading to restored progress after one single-repair initiation, data from a multiperson conversational corpus of Norwegian Sign Language (NTS) show that 68\% of 112 individual repair initiations occur in multiple OIR sequences. This article identifies three different trajectories of multiple OIR sequences in the NTS data, which are as follows: (1) a trouble source being targeted by more than one repair initiation, (2) the self-repair becomes a new trouble source, or (3) the repair initiation becomes a new trouble source. The high frequency of multiple OIR sequences provides an opportunity to quantitatively investigate how the various formats of repair initiation are distributed in single- and multiple-OIR sequences, how they occur as first or subsequent, and whether they restore the progress of the conversation or are followed by another repair initiation.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {1},
	journal = {Open Linguistics},
	author = {Skedsmo, Kristian},
	month = dec,
	year = {2020},
	note = {Publisher: De Gruyter
Section: Open Linguistics},
	pages = {532--566},
}

@inproceedings{porcheron_nottreal_2020,
	address = {New York, NY, USA},
	series = {{CUI} '20},
	title = {{NottReal}: {A} {Tool} for {Voice}-based {Wizard} of {Oz} studies},
	isbn = {978-1-4503-7544-3},
	shorttitle = {{NottReal}},
	url = {https://doi.org/10.1145/3405755.3406168},
	doi = {10.1145/3405755.3406168},
	abstract = {We present NottReal, an application designed for simulating Voice User Interfaces (VUIs) in Wizard of Oz studies. We briefly discuss the premise and advantages of the Wizard of Oz method before moving onto introducing the design of the application, which we have iteratively developed and refined through a number of studies.},
	urldate = {2022-09-08},
	booktitle = {Proceedings of the 2nd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Porcheron, Martin and Fischer, Joel E. and Valstar, Michel},
	month = jul,
	year = {2020},
	pages = {1--3},
}

@inproceedings{garg_last_2022,
	address = {New York, NY, USA},
	series = {{CHI} '22},
	title = {The {Last} {Decade} of {HCI} {Research} on {Children} and {Voice}-based {Conversational} {Agents}},
	isbn = {978-1-4503-9157-3},
	url = {https://doi.org/10.1145/3491102.3502016},
	doi = {10.1145/3491102.3502016},
	abstract = {Voice-based Conversational Agents (CAs) are increasingly being used by children. Through a review of 38 research papers, this work maps trends, themes, and methods of empirical research on children and CAs in HCI research over the last decade. A thematic analysis of the research found that work in this domain focuses on seven key topics: ascribing human-like qualities to CAs, CAs? support of children?s learning, the use and role of CAs in the home and family context, CAs? support of children?s play, children?s storytelling with CA, issues concerning the collection of information revealed by CAs, and CAs designed for children with differing abilities. Based on our findings, we identify the needs to account for children’s intersectional identities and linguistic and cultural diversity and theories from multiple disciples in the design of CAs, develop heuristics for child-centric interaction with CAs, to investigate implications of CAs on social cognition and interpersonal relationships, and to examine and design for multi-party interactions with CAs for different domains and contexts.},
	urldate = {2022-09-08},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Garg, Radhika and Cui, Hua and Seligson, Spencer and Zhang, Bo and Porcheron, Martin and Clark, Leigh and Cowan, Benjamin R. and Beneteau, Erin},
	month = apr,
	year = {2022},
	pages = {1--19},
}

@inproceedings{reddy_automating_2022,
	address = {Hybrid: Seattle, Washington + Online},
	title = {Automating {Human} {Evaluation} of {Dialogue} {Systems}},
	url = {https://aclanthology.org/2022.naacl-srw.29},
	doi = {10.18653/v1/2022.naacl-srw.29},
	abstract = {Automated metrics to evaluate dialogue systems like BLEU, METEOR, etc., weakly correlate with human judgments. Thus, human evaluation is often used to supplement these metrics for system evaluation. However, human evaluation is time-consuming as well as expensive. This paper provides an alternative approach to human evaluation with respect to three aspects: naturalness, informativeness, and quality in dialogue systems. I propose an approach based on fine-tuning the BERT model with three prediction heads, to predict whether the system-generated output is natural, fluent, and informative. I observe that the proposed model achieves an average accuracy of around 77\% over these 3 labels. I also design a baseline approach that uses three different BERT models to make the predictions. Based on experimental analysis, I find that using a shared model to compute the three labels performs better than three separate models.},
	urldate = {2022-09-01},
	booktitle = {Proceedings of the 2022 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}: {Student} {Research} {Workshop}},
	publisher = {Association for Computational Linguistics},
	author = {Reddy, Sujan},
	month = jul,
	year = {2022},
	pages = {229--234},
}

@inproceedings{khalid_explaining_2022,
	address = {Seattle, United States},
	title = {Explaining {Dialogue} {Evaluation} {Metrics} using {Adversarial} {Behavioral} {Analysis}},
	url = {https://aclanthology.org/2022.naacl-main.430},
	doi = {10.18653/v1/2022.naacl-main.430},
	abstract = {There is an increasing trend in using neural methods for dialogue model evaluation. Lack of a framework to investigate these metrics can cause dialogue models to reflect their biases and cause unforeseen problems during interactions. In this work, we propose an adversarial test-suite which generates problematic variations of various dialogue aspects, e.g. logical entailment, using automatic heuristics. We show that dialogue metrics for both open-domain and task-oriented settings are biased in their assessments of different conversation behaviors and fail to properly penalize problematic conversations, by analyzing their assessments of these problematic examples. We conclude that variability in training methodologies and data-induced biases are some of the main causes of these problems. We also conduct an investigation into the metric behaviors using a black-box interpretability model which corroborates our findings and provides evidence that metrics pay attention to the problematic conversational constructs signaling a misunderstanding of different conversation semantics.},
	urldate = {2022-09-01},
	booktitle = {Proceedings of the 2022 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Khalid, Baber and Lee, Sungjin},
	month = jul,
	year = {2022},
	pages = {5871--5883},
}

@inproceedings{ramakrishnan_long-term_2022,
	address = {Seattle, United States},
	title = {Long-term {Control} for {Dialogue} {Generation}: {Methods} and {Evaluation}},
	shorttitle = {Long-term {Control} for {Dialogue} {Generation}},
	url = {https://aclanthology.org/2022.naacl-main.54},
	doi = {10.18653/v1/2022.naacl-main.54},
	abstract = {Current approaches for controlling dialogue response generation are primarily focused on high-level attributes like style, sentiment, or topic. In this work, we focus on constrained long-term dialogue generation, which involves more fine-grained control and requires a given set of control words to appear in generated responses. This setting requires a model to not only consider the generation of these control words in the immediate context, but also produce utterances that will encourage the generation of the words at some time in the (possibly distant) future. We define the problem of constrained long-term control for dialogue generation, identify gaps in current methods for evaluation, and propose new metrics that better measure long-term control. We also propose a retrieval-augmented method that improves performance of long-term controlled generation via logit modification techniques. We show through experiments on three task-oriented dialogue datasets that our metrics better assess dialogue control relative to current alternatives and that our method outperforms state-of-the-art constrained generation baselines.},
	urldate = {2022-09-01},
	booktitle = {Proceedings of the 2022 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Ramakrishnan, Ramya and Narangodage, Hashan and Schilman, Mauro and Weinberger, Kilian and McDonald, Ryan},
	month = jul,
	year = {2022},
	pages = {738--753},
}

@article{ogden_phonetics_2006,
	title = {Phonetics and social action in agreements and disagreements},
	volume = {38},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/S0378216606000488},
	doi = {10.1016/j.pragma.2005.04.011},
	abstract = {This paper integrates sequential, interactional and phonetic analyses to provide an account of how ‘paralinguistic’ features create meaning. The analysis is based on assessment sequences from conversation, which were analysed using the methodology of Conversation Analysis in conjunction with phonetic analysis (cf. Couper-Kuhlen and Selting 1996; Couper-Kuhlen and Ford 2004, and papers therein).

The analysis shows that there is a close relationship between the action conveyed in a turn and its phonetic format. Second assessment turns may be formatted lexically and syntactically as conveying agreement (such as isn’t that good news/yes it's very good news), but given the right phonetic shape, they are treated as projecting disagreement. This highlights the significance of phonetics in participants’ construction of meaning.

The phonetic resources used to convey agreement and disagreement are broadly speaking ‘paralinguistic’, because they are gradient rather than categorial, and do not relate straightforwardly to propositional content. While paralinguistic features are usually said to relate to “the speaker's current affective, attitudinal or emotional state” (Laver 1994:21), this analysis shows that linguistic forms are recurrently mapped on to the actions conveyed by turns at talk, and that the details of these forms are syntagmatically related to the design of prior turns.},
	number = {10},
	urldate = {2013-10-23},
	journal = {Journal of Pragmatics},
	author = {Ogden, Richard},
	month = oct,
	year = {2006},
	pages = {1752--1775},
}

@article{ogden_audibly_2020,
	title = {Audibly {Not} {Saying} {Something} with {Clicks}},
	volume = {53},
	issn = {0835-1813},
	url = {https://doi.org/10.1080/08351813.2020.1712960},
	doi = {10.1080/08351813.2020.1712960},
	abstract = {This article explores the use of clicks—a nonverbal vocalization—in everyday talk. It is argued that clicks are one way of not saying something, i.e., of not producing talk when talk was due. While many clicks occur alongside verbal material, which provides a method for participants to ascribe an action to the turn in which they are embedded, many do not. The article explores the linguistic (especially phonetic), sequential and embodied resources available to participants to make sense of such clicks. It is argued that some clicks have properties of linguistic organization: They have nonarbitrary form-meaning mappings. Other clicks by contrast are interpreted more as ad hoc, singular events. The article contributes to a less logocentric view of talk-in-interaction. Data are in British and American English from audio and video.},
	number = {1},
	urldate = {2020-03-05},
	journal = {Research on Language and Social Interaction},
	author = {Ogden, Richard},
	month = jan,
	year = {2020},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2020.1712960},
	pages = {66--89},
}

@article{ogden_making_2012,
	title = {Making {Sense} of {Outliers}},
	volume = {69},
	issn = {1423-0321, 0031-8388},
	url = {http://www.karger.com/doi/10.1159/000343197},
	doi = {10.1159/000343197},
	language = {en},
	number = {1-2},
	urldate = {2015-10-12},
	journal = {Phonetica},
	author = {Ogden, Richard},
	year = {2012},
	pages = {48--67},
}

@article{ogden_clicks_2013,
	title = {Clicks and percussives in {English} conversation},
	volume = {43},
	issn = {0025-1003, 1475-3502},
	url = {https://www.cambridge.org/core/journals/journal-of-the-international-phonetic-association/article/clicks-and-percussives-in-english-conversation/F2B5C9FA333AB7AE3C9205F04E97FAE8},
	doi = {10.1017/S0025100313000224},
	abstract = {Clicks are known to occur in English conversation, and have traditionally been assumed to convey affective meaning, generally negative. This is indeed the lay interpretation of clicks. In this paper, we build on the work of Wright (2011a, b), who shows that clicks are also used in the management of sequences of talk. Firstly, we consider similarities and differences in the production of clicks and percussives. We consider some distributional properties of clicks in one variety of English. Drawing on a wide range of conversational data from Britain and the USA, we show some of the functions of clicks and percussives in conversation, which include stance-taking and sequence management (projection of a turn constructional unit and word-search), and handling aspects of timing between turns. We also consider some of the visual behaviours that may accompany clicks. The meaning or function of clicks and percussives, it is argued, must be considered in a fuller interactional context.},
	language = {en},
	number = {3},
	urldate = {2018-12-04},
	journal = {Journal of the International Phonetic Association},
	author = {Ogden, Richard},
	month = dec,
	year = {2013},
	pages = {299--320},
}

@article{prather_what_2022,
	title = {What {Can} {Cognitive} {Science} {Do} for {People}?},
	volume = {46},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.13167},
	doi = {10.1111/cogs.13167},
	abstract = {The critical question for cognitive scientists is what does cognitive science do, if anything, for people? Cognitive science is primarily concerned with human cognition but has fallen short in continuously and critically assessing the who in human cognition. This complacency in a world where white supremacist and patriarchal structures leave cognitive science in the unfortunate position of potentially supporting those structures. We take it that many cognitive scientists operate on the assumption that the study of human cognition is both interesting and important. We want to invoke that importance to note that cognitive scientists must continue to work to show how the field is useful to all of humanity and reflects a humanity that is not white by default. We wonder how much the field has done, and can do, to show that it is useful not only in the sense that we might make connections with researchers in other fields, win grants and write papers, even of the highest quality, but useful in some material way to the billions of non-cognitive scientists across the globe.},
	language = {en},
	number = {6},
	urldate = {2022-08-05},
	journal = {Cognitive Science},
	author = {Prather, Richard W. and Benitez, Viridiana L. and Brooks, Lauren Kendall and Dancy, Christopher L. and Dilworth-Bart, Janean and Dutra, Natalia B. and Faison, M. Omar and Figueroa, Megan and Holden, LaTasha R. and Johnson, Cameron and Medrano, Josh and Miller-Cotto, Dana and Matthews, Percival G. and Manly, Jennifer J. and Thomas, Ayanna K.},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.13167},
	pages = {e13167},
}

@article{scott-phillips_cognition_2022,
	title = {Cognition and {Society}: {Prolegomenon} to a {Dialog}},
	volume = {46},
	issn = {1551-6709},
	shorttitle = {Cognition and {Society}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.13162},
	doi = {10.1111/cogs.13162},
	language = {en},
	number = {6},
	urldate = {2022-08-05},
	journal = {Cognitive Science},
	author = {Scott-Phillips, Thom and Nettle, Daniel},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.13162},
	pages = {e13162},
}

@article{hardman_three_2022,
	title = {Three {Simple} {Rules} for {Good} {Cognitive} {Science}},
	volume = {46},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.13172},
	doi = {10.1111/cogs.13172},
	abstract = {There is much recent concern about whether cognitive science is a cohesive discipline. In response, I propose that although cognitive science necessarily lacks conceptual or methodological cohesion, it can have dispositional cohesion. I further propose that this can be achieved by following three simple rules.},
	language = {en},
	number = {7},
	urldate = {2022-08-05},
	journal = {Cognitive Science},
	author = {Hardman, Doug},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.13172},
	pages = {e13172},
}

@article{cohn_reimagining_2022,
	title = {Reimagining {Language}},
	volume = {46},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.13174},
	doi = {10.1111/cogs.13174},
	abstract = {Since its inception, the study of language has been a central pillar to Cognitive Science. Despite an “amodal view,” where language is thought to “flow into” modalities indiscriminately, speech has always been considered the prototypical form of the linguistic system. However, this view does not hold up to the evidence about language and expressive modalities. While acknowledgment of both the nonvocal modalities and multimodality has grown over the last 40 years in linguistics and psycholinguistics, this has not yet led to a necessary shift in the mainstream linguistic paradigm. Such a shift requires reconfiguring models of language to account for multimodality, and demands a different view on what the linguistic system is and how it works, necessitating a Cognitive Science sensitive to the full richness of human communication.},
	language = {en},
	number = {7},
	urldate = {2022-08-05},
	journal = {Cognitive Science},
	author = {Cohn, Neil and Schilperoord, Joost},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.13174},
	pages = {e13164},
}

@article{brandi_naturalistic_2020,
	title = {A naturalistic paradigm simulating gaze-based social interactions for the investigation of social agency},
	volume = {52},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-019-01299-x},
	doi = {10.3758/s13428-019-01299-x},
	abstract = {Sense of agency describes the experience of being the cause of one’s own actions and the resulting effects. In a social interaction, one’s actions may also have a perceivable effect on the actions of others. In this article, we refer to the experience of being responsible for the behavior of others as social agency, which has important implications for the success or failure of social interactions. Gaze-contingent eyetracking paradigms provide a useful tool to analyze social agency in an experimentally controlled manner, but the current methods are lacking in terms of their ecological validity. We applied this technique in a novel task using video stimuli of real gaze behavior to simulate a gaze-based social interaction. This enabled us to create the impression of a live interaction with another person while being able to manipulate the gaze contingency and congruency shown by the simulated interaction partner in a continuous manner. Behavioral data demonstrated that participants believed they were interacting with a real person and that systematic changes in the responsiveness of the simulated partner modulated the experience of social agency. More specifically, gaze contingency (temporal relatedness) and gaze congruency (gaze direction relative to the participant’s gaze) influenced the explicit sense of being responsible for the behavior of the other. In general, our study introduces a new naturalistic task to simulate gaze-based social interactions and demonstrates that it is suitable to studying the explicit experience of social agency.},
	language = {en},
	number = {3},
	urldate = {2022-08-05},
	journal = {Behavior Research Methods},
	author = {Brandi, Marie-Luise and Kaifel, Daniela and Lahnakoski, Juha M. and Schilbach, Leonhard},
	month = jun,
	year = {2020},
	pages = {1044--1055},
}

@inproceedings{fogg_how_1997,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '97},
	title = {How users reciprocate to computers: an experiment that demonstrates behavior change},
	isbn = {978-0-89791-926-5},
	shorttitle = {How users reciprocate to computers},
	url = {https://doi.org/10.1145/1120212.1120419},
	doi = {10.1145/1120212.1120419},
	abstract = {We conducted an experiment to investigate if computers could motivate users to change their behavior. By leveraging a social dynamic called the "rule of reciprocity," this experiment demonstrated that users provided more helping behavior to a computer that had helped them previously than to a different computer. Users also worked longer, performed higher quality work, and felt happier. Conversely, the data provide evidence of a retaliation effect.},
	urldate = {2022-08-05},
	booktitle = {{CHI} '97 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Fogg, BJ and Nass, Clifford},
	month = mar,
	year = {1997},
	keywords = {agents, computers are social actors, empirical studies, experiments, influence, media equation, persuasion, reciprocity, retaliation, social dynamics},
	pages = {331--332},
}

@inproceedings{nass_does_2000,
	address = {New York, NY, USA},
	series = {{CHI} '00},
	title = {Does computer-generated speech manifest personality? an experimental test of similarity-attraction},
	isbn = {978-1-58113-216-8},
	shorttitle = {Does computer-generated speech manifest personality?},
	url = {https://doi.org/10.1145/332040.332452},
	doi = {10.1145/332040.332452},
	abstract = {This study examines whether people would interpret and respond to paralinguistic personality cues in computer-generated speech in the same way as they do human speech. Participants used a book-buying website and heard five book reviews in a 2 (synthesized voice personality: extrovert vs. introvert) by 2 (participant personality: extrovert vs. introvert) balanced, between-subjects experiment. Participants accurately recognized personality cues in TTS and showed strong similarity-attraction effects. Although the content was the same for all participants, when the personality of the computer voice matched their own personality: 1) participants regarded the computer voice as more attractive, credible, and informative; 2) the book review was evaluated more positively; 3) the reviewer was more attractive and credible; and 4) participants were more likely to buy the book. Match of user voice characteristics with TTS had no effect, confirming the social nature of the interaction. We discuss implications for HCI theory and design.},
	urldate = {2022-08-05},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Nass, Clifford and Lee, Kwan Min},
	month = apr,
	year = {2000},
	pages = {329--336},
}

@article{von_uexkull_stroll_1992,
	title = {A stroll through the worlds of animals and men: {A} picture book of invisible worlds},
	volume = {89},
	issn = {0037-1998, 1613-3692},
	shorttitle = {A stroll through the worlds of animals and men},
	url = {https://sslvpn.mpi.nl/view/j/semi.1992.89.issue-4/semi.1992.89.4.319/,DanaInfo=www.degruyter.com,SSO=U+semi.1992.89.4.319.xml},
	doi = {10.1515/semi.1992.89.4.319},
	number = {4},
	urldate = {2014-04-15},
	journal = {Semiotica},
	author = {Von Uexküll, Jakob},
	year = {1992},
}

@misc{stokoe_softness_2021,
	title = {The softness of hard data},
	url = {https://elizabeth-stokoe.medium.com/the-softness-of-hard-data-475743d8a2f2},
	abstract = {by Elizabeth Stokoe, Charles Antaki, Mike Bracher, Leanne Chrisostomou, Elle Henderson, Danielle Jones, and Simon Stewart},
	language = {en},
	urldate = {2022-08-05},
	journal = {Medium},
	author = {Stokoe, Elizabeth and Antaki, Charles and Bracher, Mike and Chrisostomou, Leanne and Henderson, Elle and Jones, Danielle and Stewardt, Simon},
	month = nov,
	year = {2021},
}

@inproceedings{linke_conversational_2022,
	address = {Marseille},
	title = {Conversational {Speech} {Recognition} {Needs} {Data}? {Experiments} with {Austrian} {German}},
	abstract = {Conversational speech represents one of the most complex of automatic speech recognition (ASR) tasks owing to the high inter-speaker variation in both pronunciation and conversational dynamics. Such complexity is particularly sensitive to low-resourced (LR) scenarios. Recent developments in self-supervision have allowed such scenarios to take advantage of large amounts of otherwise unrelated data. In this study, we characterise an (LR) Austrian German conversational task. We begin with a non-pre-trained baseline and show that fine-tuning of a model pre-trained using self-supervision leads to improvements consistent with those in the literature; this extends to cases where a lexicon and language model are included. We also show that the advantage of pre-training indeed arises from the larger database rather than the self-supervision. Further, by use of a leave-one-conversation out technique, we demonstrate that robustness problems remain with respect to inter-speaker and inter-conversation variation. This serves to guide where future research might best be focused in light of the current state-of-the-art.},
	language = {en},
	booktitle = {Proceedings of the 13th {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2022)},
	author = {Linke, Julian and Garner, Philip N and Kubin, Gernot and Schuppler, Barbara},
	year = {2022},
	pages = {4684--4691},
}

@book{von_uexkull_umwelt_1921,
	address = {Berlin, Heidelberg},
	title = {Umwelt und {Innenwelt} der {Tiere}},
	isbn = {978-3-662-22877-7 978-3-662-24819-5},
	url = {https://sslvpn.mpi.nl/book/10.1007/,DanaInfo=link.springer.com+978-3-662-24819-5},
	language = {de},
	urldate = {2014-04-15},
	publisher = {Springer Berlin Heidelberg},
	author = {Von Uexküll, Jakob},
	year = {1921},
}

@book{wiener_cybernetics_1961,
	address = {Cambridge, MA, USA},
	edition = {2. ed., reprint},
	title = {Cybernetics or control and communication in the animal and the machine},
	isbn = {978-0-262-73009-9},
	language = {eng},
	publisher = {MIT Press},
	author = {Wiener, Norbert},
	year = {1961},
}

@article{axelsson_modeling_2022,
	title = {Modeling {Feedback} in {Interaction} {With} {Conversational} {Agents}—{A} {Review}},
	volume = {4},
	issn = {2624-9898},
	url = {https://www.frontiersin.org/articles/10.3389/fcomp.2022.744574},
	abstract = {Intelligent agents interacting with humans through conversation (such as a robot, embodied conversational agent, or chatbot) need to receive feedback from the human to make sure that its communicative acts have the intended consequences. At the same time, the human interacting with the agent will also seek feedback, in order to ensure that her communicative acts have the intended consequences. In this review article, we give an overview of past and current research on how intelligent agents should be able to both give meaningful feedback toward humans, as well as understanding feedback given by the users. The review covers feedback across different modalities (e.g., speech, head gestures, gaze, and facial expression), different forms of feedback (e.g., backchannels, clarification requests), and models for allowing the agent to assess the user's level of understanding and adapt its behavior accordingly. Finally, we analyse some shortcomings of current approaches to modeling feedback, and identify important directions for future research.},
	urldate = {2022-08-04},
	journal = {Frontiers in Computer Science},
	author = {Axelsson, Agnes and Buschmeier, Hendrik and Skantze, Gabriel},
	year = {2022},
}

@inproceedings{benotti_grounding_2021,
	address = {Online},
	title = {Grounding as a {Collaborative} {Process}},
	url = {https://aclanthology.org/2021.eacl-main.41},
	doi = {10.18653/v1/2021.eacl-main.41},
	abstract = {Collaborative grounding is a fundamental aspect of human-human dialog which allows people to negotiate meaning. In this paper we argue that it is missing from current deep learning approaches to dialog. Our central point is that making mistakes and being able to recover from them collaboratively is a key ingredient in grounding meaning. We illustrate the pitfalls of being unable to ground collaboratively, discuss what can be learned from the language acquisition and dialog systems literature, and reflect on how to move forward.},
	urldate = {2022-08-04},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Benotti, Luciana and Blackburn, Patrick},
	month = apr,
	year = {2021},
	pages = {515--531},
}

@inproceedings{sankar_neural_2019,
	address = {Florence, Italy},
	title = {Do {Neural} {Dialog} {Systems} {Use} the {Conversation} {History} {Effectively}? {An} {Empirical} {Study}},
	shorttitle = {Do {Neural} {Dialog} {Systems} {Use} the {Conversation} {History} {Effectively}?},
	url = {https://aclanthology.org/P19-1004},
	doi = {10.18653/v1/P19-1004},
	abstract = {Neural generative models have been become increasingly popular when building conversational agents. They offer flexibility, can be easily adapted to new domains, and require minimal domain engineering. A common criticism of these systems is that they seldom understand or use the available dialog history effectively. In this paper, we take an empirical approach to understanding how these models use the available dialog history by studying the sensitivity of the models to artificially introduced unnatural changes or perturbations to their context at test time. We experiment with 10 different types of perturbations on 4 multi-turn dialog datasets and find that commonly used neural dialog architectures like recurrent and transformer-based seq2seq models are rarely sensitive to most perturbations such as missing or reordering utterances, shuffling words, etc. Also, by open-sourcing our code, we believe that it will serve as a useful diagnostic tool for evaluating dialog systems in the future.},
	urldate = {2022-08-04},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Sankar, Chinnadhurai and Subramanian, Sandeep and Pal, Chris and Chandar, Sarath and Bengio, Yoshua},
	month = jul,
	year = {2019},
	pages = {32--37},
}

@article{chollet_measure_2019,
	title = {On the measure of intelligence},
	journal = {arXiv preprint arXiv:1911.01547},
	author = {Chollet, François},
	year = {2019},
}

@article{abercrombie_paralanguage_1968,
	title = {Paralanguage},
	volume = {3},
	issn = {1368-2822},
	url = {http://informahealthcare.com/doi/abs/10.3109/13682826809011441},
	doi = {10.3109/13682826809011441},
	number = {1},
	urldate = {2011-05-17},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Abercrombie, David},
	month = jan,
	year = {1968},
	pages = {55--59},
}

@book{abelson_structure_1985,
	address = {Cambridge, Mass. : New York},
	series = {The {MIT} electrical engineering and computer science series},
	title = {Structure and interpretation of computer programs},
	isbn = {978-0-262-01077-1 978-0-07-000422-1},
	publisher = {MIT Press ; McGraw-Hill},
	author = {Abelson, Harold and Sussman, Gerald Jay and Sussman, Julie},
	year = {1985},
}

@incollection{bickmore_social_2005,
	address = {Dordrecht},
	series = {Text, {Speech} and {Language} {Technology}},
	title = {Social {Dialogue} with {Embodied} {Conversational} {Agents}},
	isbn = {978-1-4020-3933-1},
	url = {https://doi.org/10.1007/1-4020-3933-6_2},
	abstract = {The functions of social dialogue between people in the context of performing a task is discussed, as well as approaches to modelling such dialogue in embodied conversational agents. A study of an agent’s use of social dialogue is presented, comparing embodied interactions with similar interactions conducted over the phone, assessing the impact these media have on a wide range of behavioural, task and subjective measures. Results indicate that subjects’ perceptions of the agent are sensitive to both interaction style (social vs. task-only dialogue) and medium.},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {Advances in {Natural} {Multimodal} {Dialogue} {Systems}},
	publisher = {Springer Netherlands},
	author = {Bickmore, Timothy and Cassell, Justine},
	editor = {van Kuppevelt, Jan C. J. and Dybkjær, Laila and Bernsen, Niels Ole},
	year = {2005},
	doi = {10.1007/1-4020-3933-6_2},
	pages = {23--54},
}

@book{glenn_laughter_2003,
	address = {Cambridge},
	series = {Studies in {Interactional} {Sociolinguistics}},
	title = {Laughter in {Interaction}},
	isbn = {978-0-521-77206-8},
	url = {https://www.cambridge.org/core/books/laughter-in-interaction/4629463A15293CFEBD21EE70AAC966F2},
	abstract = {Laughter in Interaction is an illuminating and lively account of how and why people laugh during conversation. Bringing together twenty-five years of research on the sequential organisation of laughter in everyday talk, Glenn analyses recordings and transcripts to show the finely detailed co-ordination of human laughter. He demonstrates that its production and placement, relative to talk and other activities, reveal much about its emergent meaning and accomplishments. The book shows how the participants in a conversation move from a single laugh to laughing together, how the matter of 'who laughs first' implicates orientation to social activities and how interactants work out whether laughs are more affiliative or hostile. The final chapter examines the contribution of laughter to sequences of conversational intimacy and play and to the invocation of gender. Engaging and original, the book shows how this seemingly insignificant part of human communication turns out to play a highly significant role in how people display, respond to and revise identities and relationships.},
	urldate = {2022-08-02},
	publisher = {Cambridge University Press},
	author = {Glenn, Phillip},
	year = {2003},
	doi = {10.1017/CBO9780511519888},
}

@article{pomerantz_extreme_1986,
	title = {Extreme case formulations: {A} way of legitimizing claims},
	volume = {9},
	issn = {1572-851X},
	shorttitle = {Extreme case formulations},
	url = {https://doi.org/10.1007/BF00148128},
	doi = {10.1007/BF00148128},
	abstract = {This paper has described three uses of Extreme Case formulations},
	language = {en},
	number = {2},
	urldate = {2022-08-02},
	journal = {Human Studies},
	author = {Pomerantz, Anita},
	month = jun,
	year = {1986},
	keywords = {Extreme Case, Individual Member, Political Philosophy, Similar Case, Social Order},
	pages = {219--229},
}

@book{watzlawick_pragmatics_1967,
	address = {New York},
	edition = {First published as a Norton paperback 2011, reissued 2014},
	title = {Pragmatics of human communication: a study of interactional patterns, pathologies, and paradoxes},
	isbn = {978-0-393-71059-5},
	shorttitle = {Pragmatics of human communication},
	publisher = {W. W. Norton \& Company},
	author = {Watzlawick, Paul and Bavelas, Janet Beavin and Jackson, Don D.},
	year = {1967},
}

@article{zhou_design_2020,
	title = {The {Design} and {Implementation} of {XiaoIce}, an {Empathetic} {Social} {Chatbot}},
	volume = {46},
	url = {https://aclanthology.org/2020.cl-1.2},
	doi = {10.1162/coli_a_00368},
	abstract = {This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human–machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.},
	number = {1},
	urldate = {2022-08-02},
	journal = {Computational Linguistics},
	author = {Zhou, Li and Gao, Jianfeng and Li, Di and Shum, Heung-Yeung},
	year = {2020},
	note = {Place: Cambridge, MA
Publisher: MIT Press},
	pages = {53--93},
}

@article{park_marking_2010,
	title = {Marking an impasse: {The} use of anyway as a sequence-closing device},
	volume = {42},
	issn = {0378-2166},
	shorttitle = {Marking an impasse},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216610001748},
	doi = {10.1016/j.pragma.2010.06.002},
	abstract = {Based on a conversation analytic study of ordinary telephone conversations, the paper examines the use of anyway as a sequence-closing device in context in which the participants face an interactional impasse. The study suggests that the closure-relevant anyway, both as a stand-alone turn constructional unit (TCU) and a TCU initial component, has distinctive features. In contrast to ordinary methods of maintaining conversational coherence, the use of anyway is designed to indicate an impending break in contiguity. Further, the closure-relevant anyway is often produced in a dispreferred environment in which the participants are not in alignment. The ways the participants deploy anyway as a sequence-closing device to put an end to such interactional trouble, including a break in contiguity and misalignment, are discussed in detail.},
	language = {en},
	number = {12},
	urldate = {2022-08-02},
	journal = {Journal of Pragmatics},
	author = {Park, Innhwa},
	month = dec,
	year = {2010},
	pages = {3283--3299},
}

@book{schank_scripts_1977,
	address = {Hillsdale, N.J. : New York},
	series = {The {Artificial} intelligence series},
	title = {Scripts, plans, goals, and understanding: an inquiry into human knowledge structures},
	isbn = {978-0-470-99033-9},
	shorttitle = {Scripts, plans, goals, and understanding},
	publisher = {L. Erlbaum Associates ; distributed by the Halsted Press Division of John Wiley and Sons},
	author = {Schank, Roger C. and Abelson, Robert P.},
	year = {1977},
}

@book{latour2007reassembling,
	title = {Reassembling the social: {An} introduction to actor-network-theory},
	publisher = {Oxford University Press},
	author = {Latour, Bruno},
	year = {2007},
}

@book{mercier_enigma_2017,
	address = {Cambridge, Massachusetts},
	title = {The enigma of reason},
	isbn = {978-0-674-36830-9},
	abstract = {Reason, we are told, is what makes us human, the source of our knowledge and wisdom. If reason is so useful, why didn't it also evolve in other animals? If reason is that reliable, why do we produce so much thoroughly reasoned nonsense? In their groundbreaking account of the evolution and workings of reason, Hugo Mercier and Dan Sperber set out to solve this double enigma. Reason, they argue with a compelling mix of real-life and experimental evidence, is not geared to solitary use, to arriving at better beliefs and decisions on our own. What reason does, rather, is help us justify our beliefs and actions to others, convince them through argumentation, and evaluate the justifications and arguments that others address to us. In other words, reason helps humans better exploit their uniquely rich social environment. This interactionist interpretation explains why reason may have evolved and how it fits with other cognitive mechanisms. It makes sense of strengths and weaknesses that have long puzzled philosophers and psychologists--why reason is biased in favor of what we already believe, why it may lead to terrible ideas and yet is indispensable to spreading good ones.--},
	publisher = {Harvard University Press},
	author = {Mercier, Hugo and Sperber, Dan},
	year = {2017},
}

@inproceedings{addlesee_comprehensive_2020,
	address = {Barcelona, Spain (Online)},
	title = {A {Comprehensive} {Evaluation} of {Incremental} {Speech} {Recognition} and {Diarization} for {Conversational} {AI}},
	url = {https://aclanthology.org/2020.coling-main.312},
	doi = {10.18653/v1/2020.coling-main.312},
	abstract = {Automatic Speech Recognition (ASR) systems are increasingly powerful and more accurate, but also more numerous with several options existing currently as a service (e.g. Google, IBM, and Microsoft). Currently the most stringent standards for such systems are set within the context of their use in, and for, Conversational AI technology. These systems are expected to operate incrementally in real-time, be responsive, stable, and robust to the pervasive yet peculiar characteristics of conversational speech such as disfluencies and overlaps. In this paper we evaluate the most popular of such systems with metrics and experiments designed with these standards in mind. We also evaluate the speaker diarization (SD) capabilities of the same systems which will be particularly important for dialogue systems designed to handle multi-party interaction. We found that Microsoft has the leading incremental ASR system which preserves disfluent materials and IBM has the leading incremental SD system in addition to the ASR that is most robust to speech overlaps. Google strikes a balance between the two but none of these systems are yet suitable to reliably handle natural spontaneous conversations in real-time.},
	urldate = {2022-08-01},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {International Committee on Computational Linguistics},
	author = {Addlesee, Angus and Yu, Yanchao and Eshghi, Arash},
	month = dec,
	year = {2020},
	pages = {3492--3503},
}

@inproceedings{gervits_its_2020,
	address = {1st virtual meeting},
	title = {It's {About} {Time}: {Turn}-{Entry} {Timing} {For} {Situated} {Human}-{Robot} {Dialogue}},
	shorttitle = {It's {About} {Time}},
	url = {https://aclanthology.org/2020.sigdial-1.12},
	abstract = {Turn-entry timing is an important requirement for conversation, and one that spoken dialogue systems largely fail at. In this paper, we introduce a computational framework based on work from Psycholinguistics, which is aimed at achieving proper turn-taking timing for situated agents. The approach involves incremental processing and lexical prediction of the turn in progress, which allows a situated dialogue system to start its turn and initiate actions earlier than would otherwise be possible. We evaluate the framework by integrating it within a cognitive robotic architecture and testing performance on a corpus of task-oriented human-robot directives. We demonstrate that: 1) the system is superior to a non-incremental system in terms of faster responses, reduced gap between turns, and the ability to perform actions early, 2) the system can time its turn to come in immediately at a transition point or earlier to produce several types of overlap, and 3) the system is robust to various forms of disfluency in the input. Overall, this domain-independent framework can be integrated into various dialogue systems to improve responsiveness, and is a step toward more natural, human-like turn-taking behavior.},
	urldate = {2022-08-01},
	booktitle = {Proceedings of the 21th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Gervits, Felix and Thielstrom, Ravenna and Roque, Antonio and Scheutz, Matthias},
	month = jul,
	year = {2020},
	pages = {86--96},
}

@inproceedings{wepner_how_2022,
	title = {How prosody affects {ASR} performance in conversational {Austrian} {German}},
	url = {https://www.isca-speech.org/archive/speechprosody_2022/wepner22_speechprosody.html},
	doi = {10.21437/SpeechProsody.2022-40},
	urldate = {2022-08-01},
	author = {Wepner, Saskia and Schuppler, Barbara and Kubin, Gernot},
	month = may,
	year = {2022},
	pages = {195--199},
}

@article{faruqui_revisiting_2022,
	title = {Revisiting the {Boundary} between {ASR} and {NLU} in the {Age} of {Conversational} {Dialog} {Systems}},
	volume = {48},
	issn = {0891-2017},
	url = {https://doi.org/10.1162/coli_a_00430},
	doi = {10.1162/coli_a_00430},
	abstract = {As more users across the world are interacting with dialog agents in their daily life, there is a need for better speech understanding that calls for renewed attention to the dynamics between research in automatic speech recognition (ASR) and natural language understanding (NLU). We briefly review these research areas and lay out the current relationship between them. In light of the observations we make in this article, we argue that (1) NLU should be cognizant of the presence of ASR models being used upstream in a dialog system’s pipeline, (2) ASR should be able to learn from errors found in NLU, (3) there is a need for end-to-end data sets that provide semantic annotations on spoken input, (4) there should be stronger collaboration between ASR and NLU research communities.},
	number = {1},
	urldate = {2022-08-01},
	journal = {Computational Linguistics},
	author = {Faruqui, Manaal and Hakkani-Tür, Dilek},
	month = apr,
	year = {2022},
	pages = {221--232},
}

@inproceedings{tadimeti_evaluation_2022,
	address = {Marseille},
	title = {Evaluation of {Off}-the-shelf {Speech} {Recognizers} on {Different} {Accents} in a {Dialogue} {Domain}},
	abstract = {We evaluate several publicly available off-the-shelf (commercial and research) automatic speech recognition (ASR) systems on dialogue agent-directed English speech from speakers with General American vs. non-American accents. Our results show that the performance of the ASR systems for non-American accents is considerably worse than for General American accents. Depending on the recognizer, the absolute difference in performance between General American accents and all non-American accents combined can vary approximately from 2\% to 12\%, with relative differences varying approximately between 16\% and 49\%. This drop in performance becomes even larger when we consider specific categories of non-American accents indicating a need for more diligent collection of and training on non-native English speaker data in order to narrow this performance gap. There are performance differences across ASR systems, and while the same general pattern holds, with more errors for non-American accents, there are some accents for which the best recognizer is different than in the overall case. We expect these results to be useful for dialogue system designers in developing more robust inclusive dialogue systems, and for ASR providers in taking into account performance requirements for different accents.},
	language = {en},
	booktitle = {Proceedings of the 13th {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2022)},
	author = {Tadimeti, Divya and Georgila, Kallirroi and Traum, David},
	year = {2022},
	pages = {6001--6008},
}

@inproceedings{georgila_evaluation_2020,
	address = {Marseille, France},
	title = {Evaluation of {Off}-the-shelf {Speech} {Recognizers} {Across} {Diverse} {Dialogue} {Domains}},
	isbn = {979-10-95546-34-4},
	url = {https://aclanthology.org/2020.lrec-1.797},
	abstract = {We evaluate several publicly available off-the-shelf (commercial and research) automatic speech recognition (ASR) systems across diverse dialogue domains (in US-English). Our evaluation is aimed at non-experts with limited experience in speech recognition. Our goal is not only to compare a variety of ASR systems on several diverse data sets but also to measure how much ASR technology has advanced since our previous large-scale evaluations on the same data sets. Our results show that the performance of each speech recognizer can vary significantly depending on the domain. Furthermore, despite major recent progress in ASR technology, current state-of-the-art speech recognizers perform poorly in domains that require special vocabulary and language models, and under noisy conditions. We expect that our evaluation will prove useful to ASR consumers and dialogue system designers.},
	language = {English},
	urldate = {2022-08-01},
	booktitle = {Proceedings of the 12th {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Georgila, Kallirroi and Leuski, Anton and Yanov, Volodymyr and Traum, David},
	month = may,
	year = {2020},
	pages = {6469--6476},
}

@inproceedings{garnerin_pratiques_2020,
	address = {Nancy, France},
	title = {Pratiques d'évaluation en {ASR} et biais de performance ({Evaluation} methodology in {ASR} and performance bias)},
	url = {https://aclanthology.org/2020.jeptalnrecital-eternal.1},
	abstract = {Nous proposons une réflexion sur les pratiques d'évaluation des systèmes de reconnaissance automatique de la parole (ASR). Après avoir défini la notion de discrimination d'un point de vue légal et la notion d'équité dans les systèmes d'intelligence artificielle, nous nous intéressons aux pratiques actuelles lors des grandes campagnes d'évaluation. Nous observons que la variabilité de la parole et plus particulièrement celle de l'individu n'est pas prise en compte dans les protocoles d'évaluation actuels rendant impossible l'étude de biais potentiels dans les systèmes.},
	language = {French},
	urldate = {2022-08-01},
	booktitle = {Actes de la 6e conférence conjointe {Journées} d'Études sur la {Parole} ({JEP}, 33e édition), {Traitement} {Automatique} des {Langues} {Naturelles} ({TALN}, 27e édition), {Rencontre} des Étudiants {Chercheurs} en {Informatique} pour le {Traitement} {Automatique} des {Langues} ({RÉCITAL}, 22e édition). 2e atelier Éthique et {TRaitemeNt} {Automatique} des {Langues} ({ETeRNAL})},
	publisher = {ATALA et AFCP},
	author = {Garnerin, Mahault and Rossato, Solange and Besacier, Laurent},
	month = jun,
	year = {2020},
	pages = {1--9},
}

@misc{feng_quantifying_2021,
	title = {Quantifying {Bias} in {Automatic} {Speech} {Recognition}},
	url = {http://arxiv.org/abs/2103.15122},
	doi = {10.48550/arXiv.2103.15122},
	abstract = {Automatic speech recognition (ASR) systems promise to deliver objective interpretation of human speech. Practice and recent evidence suggests that the state-of-the-art (SotA) ASRs struggle with the large variation in speech due to e.g., gender, age, speech impairment, race, and accents. Many factors can cause the bias of an ASR system. Our overarching goal is to uncover bias in ASR systems to work towards proactive bias mitigation in ASR. This paper is a first step towards this goal and systematically quantifies the bias of a Dutch SotA ASR system against gender, age, regional accents and non-native accents. Word error rates are compared, and an in-depth phoneme-level error analysis is conducted to understand where bias is occurring. We primarily focus on bias due to articulation differences in the dataset. Based on our findings, we suggest bias mitigation strategies for ASR development.},
	urldate = {2022-08-01},
	publisher = {arXiv},
	author = {Feng, Siyuan and Kudina, Olya and Halpern, Bence Mark and Scharenborg, Odette},
	month = apr,
	year = {2021},
	note = {arXiv:2103.15122 [cs, eess]},
}

@book{maturana1987tree,
	title = {The tree of knowledge: {The} biological roots of human understanding.},
	publisher = {New Science Library/Shambhala Publications},
	author = {Maturana, Humberto R and Varela, Francisco J},
	year = {1987},
}

@inproceedings{rapaport_what_2003,
	title = {What did you mean by that? {Misunderstanding}, negotiation, and syntactic semantics},
	shorttitle = {What did you mean by that?},
	abstract = {Abstract. Syntactic semantics is a holistic, conceptual-role-semantic theory of how computers can think. But Fodor and Lepore have mounted a sustained attack on holistic semantic theories. However, their major problem with holism (that, if holism is true, then no two people can understand each other) can be fixed by means of negotiating meanings. Syntactic semantics and Fodor and Lepore’s objections to holism are outlined; the nature of communication, miscommunication, and negotiation is discussed; Bruner’s ideas about the negotiation of meaning are explored; and some observations on a problem for knowledge representation in AI raised by Winston are presented. 1.},
	booktitle = {Minds and {Machines}},
	author = {Rapaport, William J.},
	year = {2003},
	pages = {397--427},
}

@inproceedings{luger_like_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {"{Like} {Having} a {Really} {Bad} {PA}": {The} {Gulf} between {User} {Expectation} and {Experience} of {Conversational} {Agents}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {"{Like} {Having} a {Really} {Bad} {PA}"},
	url = {https://doi.org/10.1145/2858036.2858288},
	doi = {10.1145/2858036.2858288},
	abstract = {The past four years have seen the rise of conversational agents (CAs) in everyday life. Apple, Microsoft, Amazon, Google and Facebook have all embedded proprietary CAs within their software and, increasingly, conversation is becoming a key mode of human-computer interaction. Whilst we have long been familiar with the notion of computers that speak, the investigative concern within HCI has been upon multimodality rather than dialogue alone, and there is no sense of how such interfaces are used in everyday life. This paper reports the findings of interviews with 14 users of CAs in an effort to understand the current interactional factors affecting everyday use. We find user expectations dramatically out of step with the operation of the systems, particularly in terms of known machine intelligence, system capability and goals. Using Norman's 'gulfs of execution and evaluation' [30] we consider the implications of these findings for the design of future systems.},
	urldate = {2022-08-01},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Luger, Ewa and Sellen, Abigail},
	month = may,
	year = {2016},
	keywords = {conversational agents, evaluation, mental models},
	pages = {5286--5297},
}

@inproceedings{leite_robot_2016,
	address = {New York, NY, USA},
	series = {{IDC} '16},
	title = {The {Robot} {Who} {Knew} {Too} {Much}: {Toward} {Understanding} the {Privacy}/{Personalization} {Trade}-{Off} in {Child}-{Robot} {Conversation}},
	isbn = {978-1-4503-4313-8},
	shorttitle = {The {Robot} {Who} {Knew} {Too} {Much}},
	url = {https://doi.org/10.1145/2930674.2930687},
	doi = {10.1145/2930674.2930687},
	abstract = {In human-human conversation we elicit, share and use information as a way of defining and building relationships -- how information is revealed, and by whom, matters. A similar goal of using conversation as a relationship-building mechanism in human-robot interaction might or might not require the same degree of nuance. We explore what happens in the increasingly likely situation that a robot has sensed information about a child of which the child is unaware, then discloses that information in conversation in an effort to personalize the child's experience. In a pilot study, 28 children conversed with a social robot that either told a story with characters already introduced into the conversation by the child (control) or characters hidden by the child in a treasure chest that the child was holding (experimental). Cumulative evidence showed that all participants in the experimental condition noticed the robot's violation of expectations, but younger children (4 to 6 years) exhibited more contained emotional reactions than older children (7 to 10 years), and girls expressed more negative affect than boys. Despite the immediate response, post-conversation measures suggest that the single event did not have an impact on children's ratings of robot likeability or their willingness to interact with the robot again.},
	urldate = {2022-08-01},
	booktitle = {Proceedings of the {The} 15th {International} {Conference} on {Interaction} {Design} and {Children}},
	publisher = {Association for Computing Machinery},
	author = {Leite, Iolanda and Lehman, Jill Fain},
	month = jun,
	year = {2016},
	pages = {379--387},
}

@article{bers_interactive_1999,
	title = {Interactive storytelling systems for children: using technology to explore language and identity},
	volume = {9},
	shorttitle = {Interactive storytelling systems for children},
	number = {2},
	journal = {Journal of Interactive Learning Research},
	author = {Bers, Marina Umaschi and Cassell, Justine},
	month = dec,
	year = {1999},
	pages = {183--215},
}

@inproceedings{benford_designing_2000,
	address = {New York, NY, USA},
	series = {{CHI} '00},
	title = {Designing storytelling technologies to encouraging collaboration between young children},
	isbn = {978-1-58113-216-8},
	url = {https://doi.org/10.1145/332040.332502},
	doi = {10.1145/332040.332502},
	abstract = {We describe the iterative design of two collaborative storytelling technologies for young children, KidPad and the Klump. We focus on the idea of designing interfaces to subtly encourage collaboration so that children are invited to discover the added benefits of working together. This idea has been motivated by our experiences of using early versions of our technologies in schools in Sweden and the UK. We compare the approach of encouraging collaboration with other approaches to synchronizing shared interfaces. We describe how we have revised the technologies to encourage collaboration and to reflect design suggestions made by the children themselves.},
	urldate = {2022-08-01},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Benford, Steve and Bederson, Benjamin B. and Åkesson, Karl-Petter and Bayon, Victor and Druin, Allison and Hansson, Pär and Hourcade, Juan Pablo and Ingram, Rob and Neale, Helen and O'Malley, Claire and Simsarian, Kristian T. and Stanton, Danaë and Sundblad, Yngve and Taxén, Gustav},
	month = apr,
	year = {2000},
	pages = {556--563},
}

@techreport{al_moubayed_multimodal_2008,
	type = {Research {Report}},
	title = {Multimodal {Feedback} from {Robots} and {Agents} in a {Storytelling} {Experiment}},
	url = {https://hal.archives-ouvertes.fr/hal-03164370},
	abstract = {In this project, which lies at the intersection between Human-Robot Interaction (HRI) and Human-Computer Interaction (HCI), we have examined the design of an open-source, real-time software platform for controlling the feedback provided by an AIBO robot and/or by the GRETA Embodied Conversational Agent, when listening to a story told by a human narrator. Based on ground truth data obtained from the recording and annotation of an audiovisual storytelling database, and containing various examples of human-human storytelling, we have implemented a proof-ofconcept ECA/Robot listening system. As a narrator input, our system uses face and head movement analysis, as well as speech analysis and speech recognition; it then triggers listening behaviors from the listener, using probabilistic rules based on the co-occurrence of the same input and output behaviors in the database. We have finally assessed our system in terms of the homogeneity of the database annotation, as well as regarding the perceived quality of the feedback provided by the ECA/robot.},
	urldate = {2022-08-01},
	institution = {eNTERFACE'08, August 4 th -August 29 th , Paris, France Project 7: Final Project Report},
	author = {Al Moubayed, Samer and Baklouti, M. and Chetouani, Mohamed and Dutoit, Thierry and Mahdhaoui, Ammar and Martin, Jean-Claude and Ondas, S. and Pelachaud, Catherine and Urbain, Jérôme and Yilmas, M.},
	year = {2008},
}

@article{cassell_making_2001,
	title = {Making {Space} for {Voice}: {Technologies} to {Support} {Children}’s {Fantasy} and {Storytelling}},
	volume = {5},
	issn = {1617-4909},
	shorttitle = {Making {Space} for {Voice}},
	url = {https://doi.org/10.1007/PL00000018},
	doi = {10.1007/PL00000018},
	abstract = {Fantasy play and storytelling serve an important role in young children’s development. While computers are increasingly present in the world of young children, there is a lack of computational tools to support children’s voices in everyday storytelling, particularly in the context of fantasy play. We believe that there is a need for computational systems that engage in story-listening rather than story-telling. This paper introduces StoryMat, a system that supports and listens to children’s voices in their own storytelling play. StoryMat offers a child-driven, story-listening space by recording and recalling children’s narrating voices, and the movements they make with their stuffed animals on a colourful story-evoking quilt. Empirical research with children shows that StoryMat fosters developmentally advanced forms of storytelling of the kind that has been shown to provide a bridge to written literacy, and provides a space where children engage in fantasy storytelling collaboratively with or without a playmate. The paper addresses the importance of supporting young children’s fantasy play and suggests a new way for technology to play an integral part in that activity.},
	language = {en},
	number = {3},
	urldate = {2022-08-01},
	journal = {Personal and Ubiquitous Computing},
	author = {Cassell, J. and Ryokai, K.},
	month = aug,
	year = {2001},
	pages = {169--190},
}

@inproceedings{sun_collaborative_2017,
	address = {New York, NY, USA},
	series = {{IDC} '17},
	title = {Collaborative {Storytelling} between {Robot} and {Child}: {A} {Feasibility} {Study}},
	isbn = {978-1-4503-4921-5},
	shorttitle = {Collaborative {Storytelling} between {Robot} and {Child}},
	url = {https://doi.org/10.1145/3078072.3079714},
	doi = {10.1145/3078072.3079714},
	abstract = {Joint storytelling is a common parent-child activity and brings multiple benefits such as improved language learning for children. Most existing storytelling robots offer rigid interaction with children and do not contribute to children's stories. In this paper, we envision a robot that collaborates with a child to create oral stories in a highly interactive manner. We performed a Wizard-of-Oz feasibility study, which involved 78 children between 4 and 10 years old, to compare two collaboration strategies: (1) inserting new story content and relating it to the existing story and (2) inserting content without relating it to the existing story. We hypothesize the first strategy can foster true collaboration and create rapport, whereas the second is a safe strategy when the robot cannot understand the story. We observed that, although the first strategy creates a heavier cognitive load, it was as enjoyable as the second. We also observed some indications that the first strategy may mitigate the difficulties in story creation for young children under the age of 7 and encourage children to speak more. This study suggests that a mixture strategy is feasible for robots in collaborative storytelling, providing sufficient cognitive challenge while concealing its shortcomings on natural language understanding.},
	urldate = {2022-08-01},
	booktitle = {Proceedings of the 2017 {Conference} on {Interaction} {Design} and {Children}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Ming and Leite, Iolanda and Lehman, Jill Fain and Li, Boyang},
	month = jun,
	year = {2017},
	pages = {205--214},
}

@article{ong_world_1969,
	series = {2},
	title = {World as {View} and {World} as {Event}},
	volume = {71},
	issn = {00027294},
	url = {http://links.jstor.org/sici?sici=0002-7294%28196908%292%3A71%3A4%3C634%3AWAVAWA%3E2.0.CO%3B2-J},
	abstract = {As a concept and term, "world view" is useful but can at times be misleading. It reflects the marked tendency of technologized man to think of actuality as something essentially picturable and to think of knowledge itself by analogy with visual activity to the exclusion, more or less, of the other senses. Oral or nonwriting cultures tend much more to cast up actuality in comprehensive auditory terms, such as voice and harmony. Their "world" is not so markedly something spread out before the eyes as a "view" but rather something dynamic and relatively unpredictable, an event-world rather than an object-world, highly personal, overtly polemic, fostering sound-oriented, traditionalist personality structures less interiorized and solipsistic than those of technologized man. The concept of world view may not only interfere with the empathy necessary for understanding such cultures but may even be outmoded for our own, since modern technological man has entered into a new electronic compact with sound.},
	number = {4},
	urldate = {2008-04-01},
	journal = {American Anthropologist},
	author = {Ong, Walter J.},
	month = aug,
	year = {1969},
	pages = {634--647},
}

@book{ong_presence_1967,
	address = {New Haven},
	title = {The {Presence} of the {Word}},
	publisher = {Yale University Press},
	author = {Ong, Walter J.},
	year = {1967},
}

@book{ong_orality_2002,
	address = {London},
	title = {Orality and {Literacy} : {The} {Technologizing} of the {Word}},
	isbn = {978-0-415-28128-7},
	shorttitle = {Orality and {Literacy}},
	publisher = {Taylor \& Francis Ltd},
	author = {Ong, Walter},
	year = {2002},
}

@misc{khatri_advancing_2018,
	title = {Advancing the {State} of the {Art} in {Open} {Domain} {Dialog} {Systems} through the {Alexa} {Prize}},
	url = {http://arxiv.org/abs/1812.10757},
	doi = {10.48550/arXiv.1812.10757},
	abstract = {Building open domain conversational systems that allow users to have engaging conversations on topics of their choice is a challenging task. Alexa Prize was launched in 2016 to tackle the problem of achieving natural, sustained, coherent and engaging open-domain dialogs. In the second iteration of the competition in 2018, university teams advanced the state of the art by using context in dialog models, leveraging knowledge graphs for language understanding, handling complex utterances, building statistical and hierarchical dialog managers, and leveraging model-driven signals from user responses. The 2018 competition also included the provision of a suite of tools and models to the competitors including the CoBot (conversational bot) toolkit, topic and dialog act detection models, conversation evaluators, and a sensitive content detection model so that the competing teams could focus on building knowledge-rich, coherent and engaging multi-turn dialog systems. This paper outlines the advances developed by the university teams as well as the Alexa Prize team to achieve the common goal of advancing the science of Conversational AI. We address several key open-ended problems such as conversational speech recognition, open domain natural language understanding, commonsense reasoning, statistical dialog management, and dialog evaluation. These collaborative efforts have driven improved experiences by Alexa users to an average rating of 3.61, the median duration of 2 mins 18 seconds, and average turns to 14.6, increases of 14\%, 92\%, 54\% respectively since the launch of the 2018 competition. For conversational speech recognition, we have improved our relative Word Error Rate by 55\% and our relative Entity Error Rate by 34\% since the launch of the Alexa Prize. Socialbots improved in quality significantly more rapidly in 2018, in part due to the release of the CoBot toolkit.},
	urldate = {2022-08-01},
	publisher = {arXiv},
	author = {Khatri, Chandra and Hedayatnia, Behnam and Venkatesh, Anu and Nunn, Jeff and Pan, Yi and Liu, Qing and Song, Han and Gottardi, Anna and Kwatra, Sanjeev and Pancholi, Sanju and Cheng, Ming and Chen, Qinglang and Stubel, Lauren and Gopalakrishnan, Karthik and Bland, Kate and Gabriel, Raefer and Mandal, Arindam and Hakkani-Tur, Dilek and Hwang, Gene and Michel, Nate and King, Eric and Prasad, Rohit},
	month = dec,
	year = {2018},
	note = {arXiv:1812.10757 [cs]},
}

@article{maharjan_experiences_2022,
	title = {Experiences of a {Speech}-enabled {Conversational} {Agent} for the {Self}-report of {Well}-being among {People} {Living} with {Affective} {Disorders}: {An} {In}-the-{Wild} {Study}},
	volume = {12},
	issn = {2160-6455},
	shorttitle = {Experiences of a {Speech}-enabled {Conversational} {Agent} for the {Self}-report of {Well}-being among {People} {Living} with {Affective} {Disorders}},
	url = {https://doi.org/10.1145/3484508},
	doi = {10.1145/3484508},
	abstract = {The growing commercial success of smart speaker devices following recent advancements in speech recognition technology has surfaced new opportunities for collecting self-reported health and well-being data. Speech-enabled conversational agents (CAs) in particular, deployed in home environments using just such systems, may offer increasingly intuitive and engaging means of self-report. To date, however, few real-world studies have examined users’ experiences of engaging in the self-report of mental health using such devices or the challenges of deploying these systems in the home context. With these aims in mind, this article recounts findings from a 4-week “in-the-wild” study during which 20 individuals with depression or bipolar disorder used a speech-enabled CA named “Sofia” to maintain a daily diary log, responding also to the World Health Organization–Five Well-Being Index WHO-5 scale every 2 weeks. Thematic analysis of post-study interviews highlights actions taken by participants to overcome CAs’ limitations, diverse personifications of a speech-enabled agent, and unique forms of valuing of this system among users’ personal and social circles. These findings serve as initial evidence for the potential of CAs to support the self-report of mental health and well-being, while highlighting the need to address outstanding technical limitations in addition to design challenges of conversational pattern matching, filling unmet interpersonal gaps, and the use of self-report CAs in the at-home social context. Based on these insights, we discuss implications for the future design of CAs to support the self-report of mental health and well-being.},
	number = {2},
	urldate = {2022-08-01},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Maharjan, Raju and Doherty, Kevin and Rohani, Darius Adam and Bækgaard, Per and Bardram, Jakob E.},
	month = jul,
	year = {2022},
	pages = {10:1--10:29},
}

@article{koulouri_chatbots_2022,
	title = {Chatbots to {Support} {Young} {Adults}’ {Mental} {Health}: {An} {Exploratory} {Study} of {Acceptability}},
	volume = {12},
	issn = {2160-6455},
	shorttitle = {Chatbots to {Support} {Young} {Adults}’ {Mental} {Health}},
	url = {https://doi.org/10.1145/3485874},
	doi = {10.1145/3485874},
	abstract = {Despite the prevalence of mental health conditions, stigma, lack of awareness, and limited resources impede access to care, creating a need to improve mental health support. The recent surge in scientific and commercial interest in conversational agents and their potential to improve diagnosis and treatment seems a potentially fruitful area in this respect, particularly for young adults who widely use such systems in other contexts. Yet, there is little research that considers the acceptability of conversational agents in mental health. This study, therefore, presents three research activities that explore whether conversational agents and, in particular, chatbots can be an acceptable solution in mental healthcare for young adults. First, a survey of young adults (in a university setting) provides an understanding of the landscape of mental health in this age group and of their views around mental health technology, including chatbots. Second, a literature review synthesises current evidence relating to the acceptability of mental health conversational agents and points to future research priorities. Third, interviews with counsellors who work with young adults, supported by a chatbot prototype and user-centred design techniques, reveal the perceived benefits and potential roles of mental health chatbots from the perspective of mental health professionals, while suggesting preconditions for the acceptability of the technology. Taken together, these research activities: provide evidence that chatbots are an acceptable solution to offering mental health support for young adults; identify specific challenges relating to both the technology and environment; and argue for the application of user-centred approaches during development of mental health chatbots and more systematic and rigorous evaluations of the resulting solutions.},
	number = {2},
	urldate = {2022-08-01},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Koulouri, Theodora and Macredie, Robert D. and Olakitan, David},
	month = jul,
	year = {2022},
	pages = {11:1--11:39},
}

@article{eagle_i_2022,
	title = {“{I} don’t know what you mean by `{I} am anxious'”: {A} {New} {Method} for {Evaluating} {Conversational} {Agent} {Responses} to {Standardized} {Mental} {Health} {Inputs} for {Anxiety} and {Depression}},
	volume = {12},
	issn = {2160-6455},
	shorttitle = {“{I} don’t know what you mean by `{I} am anxious'”},
	url = {https://doi.org/10.1145/3488057},
	doi = {10.1145/3488057},
	abstract = {Conversational agents (CAs) are increasingly ubiquitous and are now commonly used to access medical information. However, we lack systematic data about the quality of advice such agents provide. This paper evaluates CA advice for mental health (MH) questions, a pressing issue given that we are undergoing a mental health crisis. Building on prior work, we define a new method to systematically evaluate mental health responses from CAs. We develop multi-utterance conversational probes derived from two widely used mental health diagnostic surveys, the PHQ-9 (Depression) and the GAD-7 (Anxiety). We evaluate the responses of two text-based chatbots and four voice assistants to determine whether CAs provide relevant responses and treatments. Evaluations were conducted both by clinicians and immersively by trained raters, yielding consistent results across all raters. Although advice and recommendations were generally low quality, they were better for Crisis probes and for probes concerning symptoms of Anxiety rather than Depression. Responses were slightly improved for text versus speech-based agents, and when CAs had access to extended dialogue context. Design implications include suggestions for improved responses through clarification sub-dialogues. Responses may also be improved by the incorporation of empathy although this needs to be combined with effective treatments or advice.},
	number = {2},
	urldate = {2022-08-01},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Eagle, Tessa and Blau, Conrad and Bales, Sophie and Desai, Noopur and Li, Victor and Whittaker, Steve},
	month = jul,
	year = {2022},
	pages = {12:1--12:23},
}

@article{razavi_discourse_2022,
	title = {Discourse {Behavior} of {Older} {Adults} {Interacting} with a {Dialogue} {Agent} {Competent} in {Multiple} {Topics}},
	volume = {12},
	issn = {2160-6455},
	url = {https://doi.org/10.1145/3484510},
	doi = {10.1145/3484510},
	abstract = {We present a conversational agent designed to provide realistic conversational practice to older adults at risk of isolation or social anxiety, and show the results of a content analysis on a corpus of data collected from experiments with elderly patients interacting with our system. The conversational agent, represented by a virtual avatar, is designed to hold multiple sessions of casual conversation with older adults. Throughout each interaction, the system analyzes the prosodic and nonverbal behavior of users and provides feedback to the user in the form of periodic comments and suggestions on how to improve. Our avatar is unique in its ability to hold natural dialogues on a wide range of everyday topics—27 topics in three groups, developed in collaboration with a team of gerontologists. The three groups vary in “degrees of intimacy,” and as such in degrees of cognitive difficulty for the user. After collecting data from nine participants who interacted with the avatar for seven to nine sessions over a period of 3 to 4 weeks, we present results concerning dialogue behavior and inferred sentiment of the users. Analysis of the dialogues reveals correlations such as greater elaborateness for more difficult topics, increasing elaborateness with successive sessions, stronger sentiments in topics concerned with life goals rather than routine activities, and stronger self-disclosure for more intimate topics. In addition to their intrinsic interest, these results also reflect positively on the sophistication and practical applicability of our dialogue system.},
	number = {2},
	urldate = {2022-08-01},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Razavi, S. Zahra and Schubert, Lenhart K. and van Orden, Kimberly and Ali, Mohammad Rafayet and Kane, Benjamin and Hoque, Ehsan},
	month = jul,
	year = {2022},
	pages = {14:1--14:21},
}

@techreport{walker_modeling_2021,
	title = {Modeling {Performance} in {Open}-{Domain} {Dialogue} with {PARADISE}},
	url = {http://arxiv.org/abs/2110.11164},
	abstract = {There has recently been an explosion of work on spoken dialogue systems, along with an increased interest in open-domain systems that engage in casual conversations on popular topics such as movies, books and music. These systems aim to socially engage, entertain, and even empathize with their users. Since the achievement of such social goals is hard to measure, recent research has used dialogue length or human ratings as evaluation metrics, and developed methods for automatically calculating novel metrics, such as coherence, consistency, relevance and engagement. Here we develop a PARADISE model for predicting the performance of Athena, a dialogue system that has participated in thousands of conversations with real users, while competing as a finalist in the Alexa Prize. We use both user ratings and dialogue length as metrics for dialogue quality, and experiment with predicting these metrics using automatic features that are both system dependent and independent. Our goal is to learn a general objective function that can be used to optimize the dialogue choices of any Alexa Prize system in real time and evaluate its performance. Our best model for predicting user ratings gets an R\${\textasciicircum}2\$ of .136 with a DistilBert model, and the best model for predicting length with system independent features gets an R\${\textasciicircum}2\$ of .865, suggesting that conversation length may be a more reliable measure for automatic training of dialogue systems.},
	number = {arXiv:2110.11164},
	urldate = {2022-08-01},
	institution = {arXiv},
	author = {Walker, Marilyn and Harmon, Colin and Graupera, James and Harrison, Davan and Whittaker, Steve},
	month = oct,
	year = {2021},
	note = {arXiv:2110.11164 [cs]
type: article},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{reeves_media_1996,
	title = {The media equation: {How} people treat computers, television, and new media like real people},
	volume = {10},
	journal = {Cambridge, UK},
	author = {Reeves, Byron and Nass, Clifford},
	year = {1996},
	pages = {236605},
}

@inproceedings{nass_computers_1994,
	address = {New York, NY, USA},
	series = {{CHI} '94},
	title = {Computers are social actors},
	isbn = {978-0-89791-650-9},
	url = {https://doi.org/10.1145/191666.191703},
	doi = {10.1145/191666.191703},
	urldate = {2022-07-31},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Nass, Clifford and Steuer, Jonathan and Tauber, Ellen R.},
	month = apr,
	year = {1994},
	keywords = {agents, anthropomorphism, gender, social psychology, speech, voice},
	pages = {72--78},
}

@article{aly_towards_2017,
	title = {Towards intelligent social robots: {Current} advances in cognitive robotics},
	volume = {43},
	issn = {1389-0417},
	shorttitle = {Towards intelligent social robots},
	url = {https://www.sciencedirect.com/science/article/pii/S1389041716302224},
	doi = {10.1016/j.cogsys.2016.11.005},
	abstract = {Artificial intelligence (AI) and machine learning (ML) approaches have caught the attention of many in health care. Current literature suggests there are many potential benefits that could transform future clinical workflows and decision making. Embedding AI and ML concepts in radiation therapy education could be a fundamental step in equipping radiation therapists (RTs) to engage in competent and safe practice as they utilise clinical technologies. In this discussion paper, the authors provide a brief review of some applications of AI and ML in radiation therapy and discuss pertinent considerations for radiation therapy curriculum enhancement. As the current literature suggests, AI and ML approaches will impose changes to routine clinical radiation therapy tasks. The emphasis in RT education could be on critical evaluation of AI and ML application in routine clinical workflows and gaining an understanding of the impact on quality assurance, provision of quality of care and safety in radiation therapy as well as research. It is also imperative RTs have a broader understanding of AI/ML impact on health care, including ethical and legal considerations. The paper concludes with recommendations and suggestions to deliberately embed AI and ML aspects in RT education to empower future RT practitioners.},
	language = {en},
	urldate = {2022-07-30},
	journal = {Cognitive Systems Research},
	author = {Aly, Amir and Griffiths, Sascha and Stramandinoli, Francesca},
	month = jun,
	year = {2017},
	pages = {153--156},
}

@article{aly_metrics_2017,
	title = {Metrics and benchmarks in human-robot interaction: {Recent} advances in cognitive robotics},
	volume = {43},
	issn = {1389-0417},
	shorttitle = {Metrics and benchmarks in human-robot interaction},
	url = {https://www.sciencedirect.com/science/article/pii/S1389041716300912},
	doi = {10.1016/j.cogsys.2016.06.002},
	abstract = {Robots are having an important growing role in human social life, which requires them to be able to behave appropriately to the context of interaction so as to create a successful long-term human-robot relationship. A major challenge in developing intelligent systems, which could enhance the interactive abilities of robots, is defining clear metrics and benchmarks for the different aspects of human-robot interaction, like human and robot skills and performances, which could facilitate comparing between systems and avoid application-biased evaluations based on particular measures. The point of evaluating robotic systems through metrics and benchmarks, in addition to some recent frameworks and technologies that could endow robots with advanced cognitive and communicative abilities, are discussed in this technical report that covers the outcome of our recent workshop on current advances in cognitive robotics: Towards Intelligent Social Robots - Current Advances in Cognitive Robotics, in conjunction with the 15th IEEE-RAS Humanoids Conference - Seoul - South Korea - 2015 (https://intelligent-robots-ws.ensta-paristech.fr/). Additionally, a summary of an interactive discussion session between the workshop participants and the invited speakers about different issues related to cognitive robotics research is reported.},
	language = {en},
	urldate = {2022-07-30},
	journal = {Cognitive Systems Research},
	author = {Aly, Amir and Griffiths, Sascha and Stramandinoli, Francesca},
	month = jun,
	year = {2017},
	pages = {313--323},
}

@article{chomsky_review_1959,
	title = {Review of {Verbal} behavior},
	volume = {35},
	issn = {0097-8507},
	url = {https://www.jstor.org/stable/411334},
	doi = {10.2307/411334},
	number = {1},
	urldate = {2020-08-31},
	journal = {Language},
	author = {Chomsky, Noam},
	collaborator = {Skinner, B. F.},
	year = {1959},
	note = {Publisher: Linguistic Society of America},
	pages = {26--58},
}

@article{guest_how_2021,
	title = {How {Computational} {Modeling} {Can} {Force} {Theory} {Building} in {Psychological} {Science}},
	issn = {1745-6916},
	url = {https://doi.org/10.1177/1745691620970585},
	doi = {10.1177/1745691620970585},
	abstract = {Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined—what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.},
	language = {en},
	urldate = {2021-01-26},
	journal = {Perspectives on Psychological Science},
	author = {Guest, Olivia and Martin, Andrea E.},
	month = jan,
	year = {2021},
	note = {Publisher: SAGE Publications Inc},
	pages = {1745691620970585},
}

@article{van_rooij_theory_2021,
	title = {Theory {Before} the {Test}: {How} to {Build} {High}-{Verisimilitude} {Explanatory} {Theories} in {Psychological} {Science}},
	issn = {1745-6916},
	shorttitle = {Theory {Before} the {Test}},
	url = {https://journals.sagepub.com/doi/abs/10.1177/1745691620970604},
	doi = {10.1177/1745691620970604},
	abstract = {Drawing on the philosophy of psychological explanation, we suggest that psychological science, by focusing on effects, may lose sight of its primary explananda: psychological capacities. We revisit Marr’s levels-of-analysis framework, which has been remarkably productive and useful for cognitive psychological explanation. We discuss ways in which Marr’s framework may be extended to other areas of psychology, such as social, developmental, and evolutionary psychology, bringing new benefits to these fields. We then show how theoretical analyses can endow a theory with minimal plausibility even before contact with empirical data: We call this the theoretical cycle. Finally, we explain how our proposal may contribute to addressing critical issues in psychological science, including how to leverage effects to understand capacities better.},
	language = {en},
	urldate = {2021-01-11},
	journal = {Perspectives on Psychological Science},
	author = {van Rooij, Iris and Baggio, Giosuè},
	month = jan,
	year = {2021},
	note = {Publisher: SAGE Publications Inc},
	pages = {1745691620970604},
}

@article{van_rooij_formalizing_2020,
	title = {Formalizing {Verbal} {Theories}},
	volume = {51},
	issn = {1864-9335},
	url = {https://econtent.hogrefe.com/doi/10.1027/1864-9335/a000428},
	doi = {10.1027/1864-9335/a000428},
	abstract = {. We present a tutorial for formalizing verbal theories of psychological phenomena           – social or otherwise. The approach builds on concepts and tools from the mathematics of computation.           We use intuitive examples and illustrate the intrinsic dialectical nature of the formalization process by           presenting dialogues between two fictive characters, called Verbal and             Formal. These characters’ conversations and thought experiments serve to highlight           important lessons in theoretical modeling.},
	number = {5},
	urldate = {2020-10-28},
	journal = {Social Psychology},
	author = {van Rooij, Iris and Blokpoel, Mark},
	month = sep,
	year = {2020},
	note = {Publisher: Hogrefe Publishing},
	pages = {285--298},
}

@book{vlahos_talk_2019,
	title = {Talk to me: {How} voice computing will transform the way we live, work, and think},
	publisher = {Eamon Dolan Books},
	author = {Vlahos, James},
	year = {2019},
}

@article{church_emerging_2022,
	title = {Emerging {Trends}: {SOTA}-{Chasing}},
	volume = {28},
	issn = {1351-3249, 1469-8110},
	shorttitle = {Emerging {Trends}},
	url = {https://www.cambridge.org/core/journals/natural-language-engineering/article/emerging-trends-sotachasing/5E9F9F796159040973053C52C443C1D6},
	doi = {10.1017/S1351324922000043},
	abstract = {Many papers are chasing state-of-the-art (SOTA) numbers, and more will do so in the future. SOTA-chasing comes with many costs. SOTA-chasing squeezes out more promising opportunities such as coopetition and interdisciplinary collaboration. In addition, there is a risk that too much SOTA-chasing could lead to claims of superhuman performance, unrealistic expectations, and the next AI winter. Two root causes for SOTA-chasing will be discussed: (1) lack of leadership and (2) iffy reviewing processes. SOTA-chasing may be similar to the replication crisis in the scientific literature. The replication crisis is yet another example, like evaluation, of over-confidence in accepted practices and the scientific method, even when such practices lead to absurd consequences.},
	language = {en},
	number = {2},
	urldate = {2022-05-24},
	journal = {Natural Language Engineering},
	author = {Church, Kenneth Ward and Kordoni, Valia},
	month = mar,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	pages = {249--269},
}

@book{hamilton_collected_1961,
	title = {The {Collected} {Dialogues} of {Plato}},
	isbn = {978-1-4008-3586-7 978-0-691-09718-3},
	url = {http://www.jstor.org/stable/10.2307/j.ctt1c84fb0},
	urldate = {2022-07-29},
	publisher = {Princeton University Press},
	editor = {Hamilton, Edith and Cairns, Huntington},
	month = oct,
	year = {1961},
	doi = {10.2307/j.ctt1c84fb0},
}

@article{rich_how_2021,
	title = {How hard is cognitive science?},
	volume = {43},
	url = {https://escholarship.org/uc/item/8cr8x1c4},
	abstract = {Cognitive science is itself a cognitive activity. Yet, computational cognitive science tools are seldom used to study (limits of) cognitive scientists' thinking. Here, we do so using computational-level modeling and complexity analysis. We present an idealized formal model of a core inference problem faced by cognitive scientists: Given observations of a system's behaviors, infer cognitive processes that could plausibly produce the behavior. We consider variants of this problem at different levels of explanation and prove that at each level, the inference problem is intractable, or even uncomputable. We discuss the implications for cognitive science.},
	language = {en},
	number = {43},
	urldate = {2022-07-28},
	journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Rich, Patricia and de Haan, Ronald and Wareham, Todd and van Rooij, Iris},
	year = {2021},
}

@article{tolins_gifs_2016,
	title = {{GIFs} as {Embodied} {Enactments} in {Text}-{Mediated} {Conversation}},
	volume = {49},
	issn = {0835-1813},
	url = {https://www.tandfonline.com/doi/10.1080/08351813.2016.1164391},
	doi = {10.1080/08351813.2016.1164391},
	abstract = {Text messaging has become an increasingly common medium for communication. Its format provides a novel context for the study of social activity in ways that both mirror face-to-face dialogue and extend beyond it. Based on the analysis of a corpus of text-mediated conversations incorporating animated images (“graphical interchange formats,” commonly known as GIFs), we show how texters reproduce depictions of the embodied actions of others as stand-ins for their own nonverbal behavior. They use GIFs either as affective responses displaying their stance toward prior talk or as co-text demonstrations of affect and action. The use of GIFs represents a novel form of embodied reenactment made possible within the technological advances of the communicative system. Data are in American English.},
	number = {2},
	urldate = {2022-07-29},
	journal = {Research on Language and Social Interaction},
	author = {Tolins, Jackson and Samermit, Patrawat},
	month = apr,
	year = {2016},
	note = {Publisher: Routledge},
	pages = {75--91},
}

@article{meredith_conversation_2019,
	title = {Conversation {Analysis} and {Online} {Interaction}},
	volume = {52},
	issn = {0835-1813},
	url = {https://doi.org/10.1080/08351813.2019.1631040},
	doi = {10.1080/08351813.2019.1631040},
	abstract = {This article reviews research that uses conversation analysis to analyze online interaction. Research in this area has tended to focus on several key areas, and these are addressed in detail: turn taking, sequence organization, repair, openings, and embodied conduct. The focus is on how these features of interaction are organized online and across online platforms and how the interactional practices may orient to particular affordances of the platforms. The debates around the use of CA terminology when analyzing online interaction are also discussed. Overall, this review suggests that CA can offer in-depth evidence about the nature of online interaction and so can contribute to wider debates about the role of technology in society. At the same time, through analyzing online interaction there is the possibility for understanding how interactional practices arise and develop over time. Data are in American English, British English, and German.},
	number = {3},
	urldate = {2022-07-29},
	journal = {Research on Language and Social Interaction},
	author = {Meredith, Joanne},
	month = jul,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2019.1631040},
	pages = {241--256},
}

@article{sierra_playing_2016,
	title = {Playing out loud: {Videogame} references as resources in friend interaction for managing frames, epistemics, and group identity},
	volume = {45},
	issn = {0047-4045, 1469-8013},
	shorttitle = {Playing out loud},
	doi = {10.1017/S0047404516000026},
	abstract = {Abstract
            This study examines how friends in their mid-twenties appropriate texts from videogames they have played to serve particular functions in their everyday face-to-face conversations. Speakers use references to the videogames Papers, Please and The Oregon Trail to shift the epistemic territories of conversations when they encounter interactional dilemmas. These epistemic shifts simultaneously rekey formerly problematic talk (on topics like rent, money, and injuries) to lighter, humorous talk, reframing these issues as being part of a lived videogame experience. Overlapping game frames are laminated upon real-life frames, and are strengthened by embedded frames containing constructed dialogue. This study contributes to understanding how epistemic shifts relying on intertextual ties can shift frames during interactional dilemmas in everyday conversation, which is ultimately conducive to group identity construction. (Intertextuality, framing, epistemics, identity, interactional sociolinguistics, discourse analysis, humor, videogames)*},
	language = {en},
	number = {2},
	journal = {Language in Society},
	author = {Sierra, Sylvia},
	month = apr,
	year = {2016},
	pages = {217--245},
}

@article{sierra_linguistic_2019,
	title = {Linguistic and ethnic media stereotypes in everyday talk: {Humor} and identity construction among friends},
	volume = {152},
	issn = {0378-2166},
	shorttitle = {Linguistic and ethnic media stereotypes in everyday talk},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216618303187},
	doi = {10.1016/j.pragma.2018.09.007},
	abstract = {This study explores humorous intertextual media references in the audio-recorded everyday talk of a European American friend group. Focusing on stereotypes of ethnically-marked varieties of American English in media references, I analyze talk where white speakers perform African American English appropriated from an Internet meme and “Hollywood Injun English” as portrayed in TV tropes. I also examine post-recording playback interviews in which speakers acknowledge and comment on the problematic source texts and their performances. I illustrate how speakers construct their individual humorous identities and their shared cultural and ethnic identities through the “others” they voice, while simultaneously activating and reinforcing the social stereotypes represented in the media they reference. While these speakers do not immediately critique these stereotypes, in playback interviews they resist the identities formerly performed, with their statements ranging from ambiguous evaluation to deconstruction of the media and the references. This study contributes to understanding how and why speakers invoke media-embedded linguistic and cultural stereotypes for humorous individual and group identity construction, and how humorous media references serve as a site for activating, reinforcing, and deconstructing media stereotypes about linguistic and cultural identities in everyday interaction.},
	language = {en},
	urldate = {2022-07-29},
	journal = {Journal of Pragmatics},
	author = {Sierra, Sylvia},
	month = oct,
	year = {2019},
	pages = {186--199},
}

@book{sierra_millennials_2021,
	address = {New York},
	title = {Millennials talking media: creating intertextual identities in everyday conversation},
	isbn = {978-0-19-093111-7 978-0-19-093112-4},
	shorttitle = {Millennials talking media},
	abstract = {"This book examines how U.S. Millennial friends embed both old media (books, songs, films, TV shows) and new media (YouTube videos, videogames, and internet memes) in their everyday talk for particular interactional purposes. Multiple case studies are presented featuring the recorded talk of Millennial friends to demonstrate how and why these speakers make media references in their conversations. These recorded conversations are supplemented with participant playback interviews, along with ethnographic fieldnotes. The analysis demonstrates how the speakers phonetically signal media references in the speech stream, how they demonstrate appreciation of the references in their listening behaviors, and how they ultimately use media references for epistemic, framing, and identity construction purposes, often when faced with interactional dilemmas. The analysis shows how such references contribute to epistemic management and frame shifts in conversation, which is ultimately conducive to different forms of Millennial identity construction. Additionally, this book explores the stereotypes embedded in the media that these Millennials quote, and examines the effects of reproducing those stereotypes in everyday social life. This fascinating book explores how the boundaries between screens, online and offline life, language, and identity are porous for Millennials, and weaves together the most current linguistic theories regarding knowledge, framing, and identity work in everyday interaction, illuminating the interplay between these processes. Media, intertextuality, epistemics, frames, identity, millennials, stereotypes, performance, memes, videogames"--},
	publisher = {Oxford University Press},
	author = {Sierra, Sylvia},
	year = {2021},
}

@article{bodur_backchannel_2022,
	title = {Backchannel {Behavior} in {Child}-{Caregiver} {Zoom}-{Mediated} {Conversations}},
	volume = {44},
	url = {https://escholarship.org/uc/item/6hp7t8p2},
	abstract = {An important step in children's socio-cognitive development is learning how to engage in coordinated conversations. This requires not only becoming competent speakers but also active listeners. This paper studies children's use of backchannel signaling (e.g., "yeah!" or a head nod) when in the listener's role during conversations with their caregivers via video call. While previous work had found backchannel to be still immature in middle childhood (i.e., 6 to 11 years of age), our use of both more natural/spontaneous conversational settings and more adequate controls allowed us to reveal that school-age children are strikingly close to adult-level mastery in many measures of backchanneling. The broader impact of this paper is to highlight the crucial role of social context in evaluating children's conversational abilities.},
	language = {en},
	number = {44},
	urldate = {2022-07-29},
	journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Bodur, Kübra and Nikolaus, Mitja and Fourtassi, Abdellah and Prévot, Laurent},
	year = {2022},
}

@article{kim_undoing_2022,
	title = {Undoing in human planning},
	volume = {44},
	url = {https://escholarship.org/uc/item/4zg639zb},
	abstract = {From writing to hiking, people’s real-world sequential decision-making often benefits from “undoing” (e.g. deleting sentences or backtracking). Surprisingly, undoing has not been studied in experiments on human planning. To investigate how much, when, and why people undo, we introduce a task that is a cross between the “Traveling Salesperson” and the “Knapsack” problems with an undo option. Within a length budget, subjects sequentially connect as many dots as possible on a map. On “undo” trials, they are allowed to take back actions without constraints. We find that undoing is beneficial, that subjects exhibit great individual variability in the number of undos, that undos are more frequent after errors than after correct actions, and that long response times tend to precede sequences of undos. Together, these results suggest that undo actions serve a dual role of correcting errors and of exploring alternative paths, where path evaluation benefits from full play-outs.},
	language = {en},
	number = {44},
	urldate = {2022-07-29},
	journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Kim, Dongjae and Bao, Sherry Dongqi and Fu, Qixiu and Ma, Wei Ji},
	year = {2022},
}

@article{lee_feels_2022,
	title = {“{Feels} {Like} {I}’ve {Known} {You} {Forever}”: {Empathy} and {Self}-{Awareness} in {Human} {Open}-{Domain} {Dialogs}},
	volume = {44},
	shorttitle = {“{Feels} {Like} {I}’ve {Known} {You} {Forever}”},
	url = {https://escholarship.org/uc/item/0rx675tm},
	abstract = {As conversational agents become more human-like, people expect them to be engaging as well. However, developing agents that comprehend human desires and generate appropriate responses, continues to be a challenge. We, therefore, collected 2,300 human open-domain dialogs with self-labeled psychological variables such as empathy, connectedness, respect, and friendliness. We found that participants who talk coherently and disclose self-relevant information were engaging partners. Also, we found that various empathetic responses were critical for sincere interaction: agreement, perspective-taking, referring to someone as adorable, and asking questions. When comparing the most and least engaging dialogs, linguistic cues and length of sentences denoted different extents of perceived empathy and sincerity by the partner. Also, we found that a large language model, GPT-3, makes small talks in one shot, but it cannot generate many empathic expressions or sustain a lengthy conversation. We propose a new approach for enhancing conversational agents' social and engaging characteristics.},
	language = {en},
	number = {44},
	urldate = {2022-07-29},
	journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Lee, Yoon Kyung and Cho, Won Ik and Bae, Seoyeon and Choi, Hyunwoo and Park, Jisang and Kim, Nam Soo and Hahn, Sowon},
	year = {2022},
}

@book{hofstadter_go_1979,
	address = {New York},
	title = {Gödel, {Escher}, {Bach}},
	isbn = {0-465-02685-0},
	publisher = {Basic Books},
	author = {Hofstadter, Douglas R.},
	month = may,
	year = {1979},
}

@book{hofstadter_metamagical_1985,
	address = {New York},
	title = {Metamagical {Themas}: {Questing} for the {Essence} of {Mind} and {Pattern}},
	shorttitle = {Metamagical {Themas}},
	publisher = {Basic Books},
	author = {Hofstadter, Douglas R.},
	year = {1985},
}

@book{alexander_nature_2002,
	title = {The nature of order: an essay on the art of building and the nature of the universe},
	publisher = {Taylor \& Francis},
	author = {Alexander, Christopher},
	year = {2002},
}

@book{alexander_pattern_1977,
	address = {New York},
	title = {A pattern language: towns, buildings, construction},
	isbn = {978-0-19-501919-3},
	shorttitle = {A pattern language},
	publisher = {Oxford University Press},
	author = {Alexander, Christopher and Ishikawa, Sara and Silverstein, Murray},
	year = {1977},
}

@inproceedings{micallef_exploratory_2016,
	title = {Do {Exploratory} {Testers} {Need} {Formal} {Training}? {An} {Investigation} {Using} {HCI} {Techniques}},
	shorttitle = {Do {Exploratory} {Testers} {Need} {Formal} {Training}?},
	doi = {10.1109/ICSTW.2016.31},
	abstract = {Exploratory software testing is an activity which can be carried out by both untrained and formally trained testers. We personify the former as Carmen and the latter as George. In this paper, we outline a joint research exercise between industry and academia that contributes to the body of knowledge by (1) proposing a data gathering and processing methodology which leverages HCI techniques to characterise the differences in strategies utilised by Carmen and George when approaching an exploratory testing task, and (2) present the findings of an initial study amongst twenty participants, ten formally trained testers and another ten with no formal training. Our results shed light on the types of strategies used by each type of tester, how they are used, the effectiveness of each type of strategy in terms of finding bugs, and the types of bugs each tester/strategy combination uncovers. We also demonstrate how our methodology can be used to help assemble and manage exploratory testing teams in the real world.},
	booktitle = {2016 {IEEE} {Ninth} {International} {Conference} on {Software} {Testing}, {Verification} and {Validation} {Workshops} ({ICSTW})},
	author = {Micallef, Mark and Porter, Chris and Borg, Andrea},
	month = apr,
	year = {2016},
	pages = {305--314},
}

@article{jefferson_rejection_1981,
	title = {The rejection of advice: {Managing} the problematic convergence of a ‘troubles-telling’ and a ‘service encounter’},
	volume = {5},
	issn = {0378-2166},
	shorttitle = {The rejection of advice},
	url = {https://www.sciencedirect.com/science/article/pii/0378216681900266},
	doi = {10.1016/0378-2166(81)90026-6},
	abstract = {A recurrent phenomenon in talk about a ‘trouble’ is the rejection of advice. This phenomenon is explored as a possible consequence of a convergence between two closely-related but distinctive environments for talk about a ‘trouble’, the Troubles-Telling and the Service Encounter. Each of these has its own appropriate activities and its own appropriate relationships between participants; only one of these, the Service Encounter, may have advice-giving as a proper component. The rejection of advice in a Troubles-Telling may, then, constitute an attempt to counteract the environmental shift, and the attendant shift of activities and relationships, implicated thereby.},
	language = {en},
	number = {5},
	urldate = {2022-07-29},
	journal = {Journal of Pragmatics},
	author = {Jefferson, Gail and Lee, John R. E.},
	month = oct,
	year = {1981},
	pages = {399--422},
}

@incollection{drew_rejection_1992,
	address = {Cambridge},
	title = {The rejection of advice: managing the problematic convergence of a "troubles-telling" and a "service encounter"},
	booktitle = {Talk at {Work}: {Interaction} in {Institutional} {Settings}},
	publisher = {Cambridge University Press},
	author = {Jefferson, Gail and Lee, John R. E.},
	editor = {Drew, Paul and Heritage, John},
	year = {1992},
	pages = {521--548},
}

@book{ten_have_doing_2007,
	address = {Los Angeles},
	edition = {2nd ed},
	series = {Introducing qualitative methods},
	title = {Doing conversation analysis},
	isbn = {978-1-4129-2174-9 978-1-4129-2175-6},
	publisher = {Sage},
	author = {ten Have, Paul},
	year = {2007},
}

@book{drew_talk_1992,
	address = {Cambridge},
	title = {Talk at {Work}: {Interaction} in {Institutional} {Settings}},
	publisher = {Cambridge University Press},
	author = {Drew, Paul and Heritage, John},
	year = {1992},
}

@article{hoey_self-authorizing_2022,
	title = {Self-authorizing action: {On} let me {X} in {English} social interaction},
	volume = {51},
	issn = {0047-4045, 1469-8013},
	shorttitle = {Self-authorizing action},
	url = {https://www.cambridge.org/core/journals/language-in-society/article/selfauthorizing-action-on-let-me-x-in-english-social-interaction/902CF0632767F3D3A6CFEF28CD6AB844},
	doi = {10.1017/S0047404520000779},
	abstract = {This article contributes to conversation analytic research on the formatting of imperative actions by focusing on the English first person imperative let me/lemme X as it appears in a range of naturally occurring interactions. I argue that lemme X is a practice for displacing what was projectably relevant in a given environment in favor of a self-authorized action. This as a result tends to advance the speaker's interests/initiatives. The analysis accounts for speakers’ apparent presumption of permission in unilaterally undertaking their lemme X action by reference to the placement, design, and subsequent orientations to the self-authorized action. The construction is discussed in terms of the distribution of agency and it is suggested that lemme X is particularly suited to advancing activities that favor autonomous action by the speaker and which involve the recipient only minimally. (Conversation analysis, imperatives, directives, English, agency)*},
	language = {en},
	number = {1},
	urldate = {2022-07-29},
	journal = {Language in Society},
	author = {Hoey, Elliott M.},
	month = feb,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	pages = {95--118},
}

@article{mondada_sequence_2022,
	title = {Sequence organization and embodied mutual orientations: openings of social interactions between baboons},
	volume = {377},
	shorttitle = {Sequence organization and embodied mutual orientations},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2021.0101},
	doi = {10.1098/rstb.2021.0101},
	abstract = {Human interactions are organized in sequence, which is a key component of Levinson's ‘interaction engine.’ Referring back to the field where it originated, conversation analysis, we discuss its relevance within the interaction engine, before moving on to show how sequence organization is actually oriented to not only humans in social interaction, but also to non-human animals. On the basis of video-recorded encounters between baboons (Papio anubis), we study canonical sequences constituting openings and, within them, greetings. Openings are the locus where future interactants adjust to each other to coordinately enter in interaction, thus achieving a common definition of their context, activity, and relationships. The analysis shows that the ways individuals spatially approach each other provide systematic interactional affordances for how the first sequences of actions in the opening are formatted, initiated, and responded to. Adopting sequential multimodal analysis, we demonstrate how participants orient to central features of sequence organization—its sequential implicativeness and the expectations it produces—building on them their interpretations of others' actions, their responsivity, and their mutual understanding of the ongoing course of action as it unfolds. This paves the way for further reflections on the pervasiveness of the interactional engine in human and non-human primate communication.

This article is part of the theme issue ‘Revisiting the human ‘interaction engine’: comparative approaches to social action coordination’.},
	number = {1859},
	urldate = {2022-07-29},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Mondada, Lorenza and Meguerditchian, Adrien},
	month = sep,
	year = {2022},
	note = {Publisher: Royal Society},
	pages = {20210101},
}

@patent{quamar_ontology-driven_2022,
	title = {Ontology-{Driven} {Conversational} {Interface} for {Data} {Analysis}},
	url = {https://patents.google.com/patent/US20220004718A1/en},
	nationality = {US},
	assignee = {International Business Machines Corp},
	number = {US20220004718A1},
	urldate = {2022-07-29},
	author = {Quamar, Abdul and Moore, Robert John and Miller, Dorian Boris and Ozcan, Fatma and Kreulen, Jeffrey Thomas},
	month = jan,
	year = {2022},
}

@article{goodwin_whatever_2010,
	title = {“{Whatever} ({Neck} {Roll}, {Eye} {Roll}, {Teeth} {Suck})”: {The} {Situated} {Coproduction} of {Social} {Categories} and {Identities} through {Stancetaking} and {Transmodal} {Stylization}},
	volume = {20},
	copyright = {© 2010 by the American Anthropological Association},
	issn = {1548-1395},
	shorttitle = {“{Whatever} ({Neck} {Roll}, {Eye} {Roll}, {Teeth} {Suck})”},
	url = {https://anthrosource.onlinelibrary.wiley.com/doi/abs/10.1111/j.1548-1395.2010.01056.x},
	doi = {10.1111/j.1548-1395.2010.01056.x},
	abstract = {This article examines the argumentative talk of a preadolescent girls' peer group demonstrating both the co-construction of microinteractional identities as well as the coproduction of macro-social identity categories, such as race, class, and gender. Activities of social aggression are performed through embodied styling and stancetaking in the midst of oppositional moves towards a “tagalong” girl. Through transmodal stylization girls openly mock an African American working-class girl using talk associated with wealthy white “Valley Girls,” while simultaneously producing gestures associated with working-class black “Ghetto Girls.” Through the use of different communicative modalities girls simultaneously index multiple culturally salient representations. [stance, style, peer group, conflict talk, identity]},
	language = {en},
	number = {1},
	urldate = {2019-11-06},
	journal = {Journal of Linguistic Anthropology},
	author = {Goodwin, Marjorie Harness and Alim, H. Samy},
	year = {2010},
	pages = {179--194},
}

@article{goodwin_calibration_2013,
	series = {Conversation {Analytic} {Studies} of {Multimodal} {Interaction}},
	title = {Calibration in directive/response sequences in family interaction},
	volume = {46},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/S0378216612001877},
	doi = {10.1016/j.pragma.2012.07.008},
	abstract = {In the context of parent–child interaction we examine the syntactic, prosodic and embodied shape of directive response sequences used to launch, choreograph, monitor, and stall the ongoing progress of a routine communicative project (Linell, 1998) occurring across temporal and spatial dimensions. We explore directive/response usage in the goal-oriented routine activity (Weisner, 1998) of getting children ready for bed, a temporally anchored project that involves the movement of bodies through social space and transitions from one activity to another (Cekaite, 2010; M.H. Goodwin, 2006a,b). Dialogic and embodied characteristics of social action and accountability are demonstrated (1) through alternative grammatical formats for directives (declaratives, imperatives, interrogatives (formatted as noun phrases produced with rising intonation)) (2) as well as through the systematic ways in which participants overlay action within directive sequences with alternative forms of affect, touch, and mobility.},
	number = {1},
	urldate = {2017-02-22},
	journal = {Journal of Pragmatics},
	author = {Goodwin, Marjorie Harness and Cekaite, Asta},
	month = jan,
	year = {2013},
	pages = {122--138},
}

@article{goodwin_participation_2006,
	title = {Participation, affect, and trajectory in family directive/response sequences},
	volume = {26},
	url = {https://www.degruyter.com/view/j/text.2006.26.issue-4-5/text.2006.021/text.2006.021.xml},
	number = {4-5},
	urldate = {2017-02-22},
	journal = {Text \& Talk-An Interdisciplinary Journal of Language, Discourse Communication Studies},
	author = {Goodwin, Marjorie Harness},
	year = {2006},
	pages = {515--543},
}

@article{goodwin_gesture_1986,
	title = {Gesture and coparticipation in the activity of searching for a word},
	volume = {62},
	issn = {0037-1998},
	url = {http://www.reference-global.com/doi/abs/10.1515/semi.1986.62.1-2.51?prevSearch=%2528schegloff%2Bsacks%2529%2BAND%2B%255Bpublisher%253A%2Bwdg%255D%2BAND%2B%255BpubType%253A%2B103%255D&searchHistoryKey=},
	doi = {10.1515/semi.1986.62.1-2.51},
	number = {1-2},
	urldate = {2010-02-02},
	journal = {Semiotica},
	author = {Goodwin, Marjorie H. and Goodwin, Charles},
	month = jan,
	year = {1986},
	pages = {51--76},
}

@article{goodwin_retellings_1990,
	title = {Retellings, pretellings and hypothetical stories},
	volume = {24},
	issn = {0835-1813},
	url = {http://www.tandfonline.com/doi/abs/10.1080/08351819009389342},
	doi = {10.1080/08351819009389342},
	number = {1-4},
	urldate = {2013-02-11},
	journal = {Research on Language and Social Interaction},
	author = {Goodwin, Marjorie Harness},
	year = {1990},
	pages = {263--276},
}

@article{goodwin_conversation_1990,
	title = {Conversation {Analysis}},
	volume = {19},
	journal = {Annual Review of Anthropology},
	author = {Goodwin, Charles and Heritage, John},
	year = {1990},
	pages = {283--307},
}

@article{goodwin_forgetfulness_1987,
	title = {Forgetfulness as an {Interactive} {Resource}},
	volume = {50},
	issn = {01902725},
	url = {http://www.jstor.org/stable/2786746},
	abstract = {Using as data videotapes of conversation in natural settings, this paper investigates (1) how displaying uncertainty is organized as interactive activity, (2) how this activity can be used to modify the participation framework of the moment, (3) the consequences this has for subsequent interaction and (4) how such events can invoke larger social identities in the midst of moment to moment interaction. Alternative syntactic and paralinguistic techniques for displaying uncertainty make relevant different types of responses from recipients. Such structure provides speakers with resources for shaping emerging interaction.},
	number = {2},
	urldate = {2010-07-08},
	journal = {Social Psychology Quarterly},
	author = {Goodwin, Charles},
	month = jun,
	year = {1987},
	note = {ArticleType: primary\_article / Issue Title: Special Issue: Language and Social Interaction / Full publication date: Jun., 1987 / Copyright © 1987 American Sociological Association},
	pages = {115--130},
}

@article{stokoe_making_2001,
	title = {Making {Gender} {Relevant}: {Conversation} {Analysis} and {Gender} {Categories} in {Interaction}},
	volume = {12},
	issn = {0957-9265},
	shorttitle = {Making {Gender} {Relevant}},
	url = {https://doi.org/10.1177/0957926501012002005},
	doi = {10.1177/0957926501012002005},
	abstract = {In this article, we critically evaluate a conversation analytic approach to the study of the links between gender and language from a feminist perspective. In so doing, we engage in the recent series of exchanges about conversation analysis (CA) and other strands of discourse analysis that have been published in Discourse \& Society. We consider talk from two sets of discourse data, focusing on participants' orientation to gender categories as they crop up in the interactions. We suggest that a CA approach produces a rich understanding of the links between discourse and gender. However, we are critical of several, often unexamined aspects and conundrums of conversation analytic methodology. First, we consider the extent to which the `analytic stances' of feminism and conversation analysis are compatible. Second, we question whether, as Schegloff (1997) suggests, it is fruitful to rely on descriptions of and orientations to gender solely in participants' terms, as well as problematizing the notion of `orienting to gender' itself. Finally, while we propose CA is a useful tool for making claims about the relevance of gender in conversational interaction, and that such claims are grounded in speakers' orientations, we suggest that culture and common-sense knowledge, of both members and analysts, are largely unacknowledged and unexplicated resources in CA.},
	language = {en},
	number = {2},
	urldate = {2022-07-28},
	journal = {Discourse \& Society},
	author = {Stokoe, Elizabeth and Smithson, Janet},
	month = mar,
	year = {2001},
	note = {Publisher: SAGE Publications Ltd},
	pages = {217--244},
}

@article{weatherall_sexism_2015,
	title = {Sexism in {Language} and {Talk}-in-{Interaction}},
	volume = {34},
	issn = {0261-927X},
	url = {https://doi.org/10.1177/0261927X15586574},
	doi = {10.1177/0261927X15586574},
	abstract = {Feminists have long recognised important relationships between language and a gendered social order that disadvantages women. At the establishment of gender and language as a field of academic inquiry, work documented sexism in language—the ways words were used to ignore, narrowly define, or demean women. Using feminist conversation analysis, this article further develops that early work by considering recorded instances of gender and sexism in talk. A broad notion of “gender trouble” was used to identify 50 relevant cases from everyday interactions. Two sexist language issues that were evident in the collection are presented in this article—the derogation of women and participants’ orientations to gender inclusiveness. The analysis contributes to a better understanding of sexism in language by examining how instances of it unfold over turns of talk. The study is discussed with respect to the methodological tensions inherent in feminist conversation analysis.},
	language = {en},
	number = {4},
	urldate = {2022-07-28},
	journal = {Journal of Language and Social Psychology},
	author = {Weatherall, Ann},
	month = sep,
	year = {2015},
	note = {Publisher: SAGE Publications Inc},
	pages = {410--426},
}

@inproceedings{ribeiro_adaptive_2022,
	address = {Dublin, Ireland},
	title = {Adaptive {Testing} and {Debugging} of {NLP} {Models}},
	url = {https://aclanthology.org/2022.acl-long.230},
	doi = {10.18653/v1/2022.acl-long.230},
	abstract = {Current approaches to testing and debugging NLP models rely on highly variable human creativity and extensive labor, or only work for a very restrictive class of bugs. We present AdaTest, a process which uses large scale language models (LMs) in partnership with human feedback to automatically write unit tests highlighting bugs in a target model. Such bugs are then addressed through an iterative text-fix-retest loop, inspired by traditional software development. In experiments with expert and non-expert users and commercial / research models for 8 different tasks, AdaTest makes users 5-10x more effective at finding bugs than current approaches, and helps users effectively fix bugs without adding new bugs.},
	urldate = {2022-07-28},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Ribeiro, Marco Tulio and Lundberg, Scott},
	month = may,
	year = {2022},
	pages = {3253--3267},
}

@incollection{levinson_language_2014,
	address = {Cambridge},
	title = {Language evolution},
	booktitle = {Cambridge {Handbook} of {Linguistic} {Anthropology}},
	publisher = {Cambridge University Press},
	author = {Levinson, Stephen C.},
	editor = {Enfield, N. J. and Kockelman, Paul and Sidnell, Jack},
	year = {2014},
	pages = {309--324},
}

@article{levinson_recursion_2013,
	title = {Recursion in {Pragmatics}},
	volume = {89},
	issn = {1535-0665},
	url = {http://muse.jhu.edu/journals/language/v089/89.1.levinson.html},
	doi = {10.1353/lan.2013.0005},
	abstract = {AbstractThere has been a recent spate of work on recursion as a central design feature of language. This short report points out that there is little evidence that unlimited recursion, understood as center-embedding, is typical of natural language syntax. Nevertheless, embedded pragmatic construals seem available in every language. Further, much deeper center-embedding can be found in dialogue or conversation structure than can be found in syntax. Existing accounts for the 'performance' limitations on center-embedding are thus thrown into doubt. Dialogue materials suggest that center-embedding is perhaps a core part of the human interaction system, and is for some reason much more highly restricted in syntax than in other aspects of cognition.*},
	number = {1},
	urldate = {2013-04-22},
	journal = {Language},
	author = {Levinson, Stephen C.},
	year = {2013},
	note = {{\textless}p{\textgreater}Volume 89, Number 1, March 2013{\textless}/p{\textgreater}},
	pages = {149--162},
}

@article{levinson_kinship_2012,
	title = {Kinship and {Human} {Thought}},
	volume = {336},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1222691},
	doi = {10.1126/science.1222691},
	number = {6084},
	urldate = {2012-05-25},
	journal = {Science},
	author = {Levinson, Stephen C.},
	month = may,
	year = {2012},
	pages = {988--989},
}

@article{levinson_john_2015,
	title = {John {Joseph} {Gumperz} (1922-2013): {Obituary}},
	issn = {00027294},
	shorttitle = {John {Joseph} {Gumperz} (1922-2013)},
	url = {http://doi.wiley.com/10.1111/aman.12185},
	doi = {10.1111/aman.12185},
	language = {en},
	urldate = {2015-02-07},
	journal = {American Anthropologist},
	author = {Levinson, Stephen C.},
	month = feb,
	year = {2015},
	pages = {n/a--n/a},
}

@article{levinson_language_2014-1,
	title = {Language and {Wallace}'s problem},
	volume = {344},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1252988},
	doi = {10.1126/science.1252988},
	language = {en},
	number = {6191},
	urldate = {2014-06-29},
	journal = {Science},
	author = {Levinson, Stephen C.},
	month = jun,
	year = {2014},
	pages = {1458--1459},
}

@article{lerner_syntax_1991,
	title = {On the {Syntax} of {Sentences}-in-{Progress}},
	volume = {20},
	url = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=3133608},
	doi = {10.1017/S0047404500016572},
	number = {03},
	urldate = {2011-03-23},
	journal = {Language in Society},
	author = {Lerner, Gene H},
	year = {1991},
	pages = {441--458},
}

@inproceedings{joshi_dialograph_2022,
	title = {{DialoGraph}: {Incorporating} {Interpretable} {Strategy}-{Graph} {Networks} into {Negotiation} {Dialogues}},
	shorttitle = {{DialoGraph}},
	url = {https://openreview.net/forum?id=kDnal_bbb-E},
	abstract = {To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating...},
	language = {en},
	urldate = {2022-07-28},
	author = {Joshi, Rishabh and Balachandran, Vidhisha and Vashishth, Shikhar and Black, Alan and Tsvetkov, Yulia},
	month = feb,
	year = {2022},
}

@article{bangalore_learning_2008,
	title = {Learning the {Structure} of {Task}-{Driven} {Human}–{Human} {Dialogs}},
	volume = {16},
	issn = {1558-7924},
	doi = {10.1109/TASL.2008.2001102},
	abstract = {With the availability of large corpora of spoken dialog, it is now possible to use data-driven techniques to build and use models of task-oriented dialogs. In this paper, we use data-driven techniques to build task structures for individual dialogs, and use the dialog task structures for: dialog act classification, task/subtask classification, task/subtask prediction, and dialog act prediction. We evaluate our approach using a corpus of customer/agent dialogs from a catalog service domain. This paper demonstrates the feasibility of using corpora of human–human conversation to learn dialog models suitable for human–computer dialog applications.},
	number = {7},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Bangalore, Srinivas and Di Fabbrizio, Giuseppe and Stent, Amanda},
	month = sep,
	year = {2008},
	note = {Conference Name: IEEE Transactions on Audio, Speech, and Language Processing},
	pages = {1249--1259},
}

@inproceedings{ribeiro_beyond_2020,
	address = {Online},
	title = {Beyond {Accuracy}: {Behavioral} {Testing} of {NLP} {Models} with {CheckList}},
	shorttitle = {Beyond {Accuracy}},
	url = {https://aclanthology.org/2020.acl-main.442},
	doi = {10.18653/v1/2020.acl-main.442},
	abstract = {Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.},
	urldate = {2022-07-27},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
	month = jul,
	year = {2020},
	pages = {4902--4912},
}

@misc{pichl_alquist_2020,
	title = {Alquist 3.0: {Alexa} {Prize} {Bot} {Using} {Conversational} {Knowledge} {Graph}},
	shorttitle = {Alquist 3.0},
	url = {http://arxiv.org/abs/2011.03261},
	doi = {10.48550/arXiv.2011.03261},
	abstract = {The third version of the open-domain dialogue system Alquist developed within the Alexa Prize 2020 competition is designed to conduct coherent and engaging conversations on popular topics. The main novel contribution is the introduction of a system leveraging an innovative approach based on a conversational knowledge graph and adjacency pairs. The conversational knowledge graph allows the system to utilize knowledge expressed during the dialogue in consequent turns and across conversations. Dialogue adjacency pairs divide the conversation into small conversational structures, which can be combined and allow the system to react to a wide range of user inputs flexibly. We discuss and describe Alquist's pipeline, data acquisition and processing, dialogue manager, NLG, knowledge aggregation, and a hierarchy of adjacency pairs. We present the experimental results of the individual parts of the system.},
	urldate = {2022-07-27},
	publisher = {arXiv},
	author = {Pichl, Jan and Marek, Petr and Konrád, Jakub and Lorenc, Petr and Ta, Van Duy and Šedivý, Jan},
	month = nov,
	year = {2020},
	note = {arXiv:2011.03261 [cs]},
}

@article{grosz_smart_2018,
	title = {Smart {Enough} to {Talk} {With} {Us}? {Foundations} and {Challenges} for {Dialogue} {Capable} {AI} {Systems}},
	volume = {44},
	issn = {0891-2017},
	shorttitle = {Smart {Enough} to {Talk} {With} {Us}?},
	url = {https://doi.org/10.1162/COLI_a_00313},
	doi = {10.1162/COLI_a_00313},
	number = {1},
	urldate = {2022-07-27},
	journal = {Computational Linguistics},
	author = {Grosz, Barbara J.},
	month = mar,
	year = {2018},
	pages = {1--15},
}

@article{litman_plan_1987,
	title = {A plan recognition model for subdialogues in conversations},
	volume = {11},
	issn = {0364-0213},
	url = {https://www.sciencedirect.com/science/article/pii/S0364021387800058},
	doi = {10.1016/S0364-0213(87)80005-8},
	abstract = {Previous plan-based models of dialogue understanding have been unable to account for many types of subdialogues present in naturally occurring conversations. One reason for this is that the models have not clearly differentiated between the varoius ways that an utterance can relate to a plan structure representing a topic. In this paper we present a plan-based theory that allows a wide variety of utterance-plan relationships. We introduce a set of discourse plans, each one corresponding to a particular way that an utterance can relate to a discourse topic, and distinguish such plans from the set of plans that are actually used to model the topics. By incorporating knowledge about discourse into a plan-based framework, we can account for a wide variety of subdialogues while maintaining the computational advantages of the plan-based approach.},
	language = {en},
	number = {2},
	urldate = {2022-07-27},
	journal = {Cognitive Science},
	author = {Litman, Diane J. and Allen, James F.},
	month = apr,
	year = {1987},
	pages = {163--200},
}

@misc{lu_unsupervised_2022,
	title = {Unsupervised {Learning} of {Hierarchical} {Conversation} {Structure}},
	url = {http://arxiv.org/abs/2205.12244},
	doi = {10.48550/arXiv.2205.12244},
	abstract = {Human conversations can evolve in many different ways, creating challenges for automatic understanding and summarization. Goal-oriented conversations often have meaningful sub-dialogue structure, but it can be highly domain-dependent. This work introduces an unsupervised approach to learning hierarchical conversation structure, including turn and sub-dialogue segment labels, corresponding roughly to dialogue acts and sub-tasks, respectively. The decoded structure is shown to be useful in enhancing neural models of language for three conversation-level understanding tasks. Further, the learned finite-state sub-dialogue network is made interpretable through automatic summarization. Our code and trained models are available at {\textbackslash}url\{https://github.com/boru-roylu/THETA\}.},
	urldate = {2022-07-27},
	publisher = {arXiv},
	author = {Lu, Bo-Ru and Hu, Yushi and Cheng, Hao and Smith, Noah A. and Ostendorf, Mari},
	month = may,
	year = {2022},
	note = {arXiv:2205.12244 [cs]},
}

@article{rastogi_towards_2020,
	title = {Towards {Scalable} {Multi}-{Domain} {Conversational} {Agents}: {The} {Schema}-{Guided} {Dialogue} {Dataset}},
	volume = {34},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Towards {Scalable} {Multi}-{Domain} {Conversational} {Agents}},
	url = {https://aaai.org/ojs/index.php/AAAI/article/view/6394},
	doi = {10.1609/aaai.v34i05.6394},
	abstract = {Virtual assistants such as Google Assistant, Alexa and Siri provide a conversational interface to a large number of services and APIs spanning multiple domains. Such systems need to support an ever-increasing number of services with possibly overlapping functionality. Furthermore, some of these services have little to no training data available. Existing public datasets for task-oriented dialogue do not sufﬁciently capture these challenges since they cover few domains and assume a single static ontology per domain. In this work, we introduce the the Schema-Guided Dialogue (SGD) dataset, containing over 16k multi-domain conversations spanning 16 domains. Our dataset exceeds the existing task-oriented dialogue corpora in scale, while also highlighting the challenges associated with building large-scale virtual assistants. It provides a challenging testbed for a number of tasks including language understanding, slot ﬁlling, dialogue state tracking and response generation. Along the same lines, we present a schema-guided paradigm for task-oriented dialogue, in which predictions are made over a dynamic set of intents and slots, provided as input, using their natural language descriptions. This allows a single dialogue system to easily support a large number of services and facilitates simple integration of new services without requiring additional training data. Building upon the proposed paradigm, we release a model for dialogue state tracking capable of zero-shot generalization to new APIs, while remaining competitive in the regular setting.},
	language = {en},
	number = {05},
	urldate = {2022-07-27},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav and Khaitan, Pranav},
	month = apr,
	year = {2020},
	pages = {8689--8696},
}

@misc{hattami_workflow_2022,
	title = {Workflow {Discovery} from {Dialogues} in the {Low} {Data} {Regime}},
	url = {http://arxiv.org/abs/2205.11690},
	doi = {10.48550/arXiv.2205.11690},
	abstract = {Text-based dialogues are now widely used to solve real-world problems. In cases where solution strategies are already known, they can sometimes be codified into workflows and used to guide humans or artificial agents through the task of helping clients. We are interested in the situation where a formal workflow may not yet exist, but we wish to discover the steps of actions that have been taken to resolve problems. We examine a novel transformer-based approach for this situation and we present experiments where we summarize dialogues in the Action-Based Conversations Dataset (ABCD) with workflows. Since the ABCD dialogues were generated using known workflows to guide agents we can evaluate our ability to extract such workflows using ground truth sequences of action steps, organized as workflows. We propose and evaluate an approach that conditions models on the set of allowable action steps and we show that using this strategy we can improve workflow discovery (WD) performance. Our conditioning approach also improves zero-shot and few-shot WD performance when transferring learned models to entirely new domains (i.e. the MultiWOZ setting). Further, a modified variant of our architecture achieves state-of-the-art performance on the related but different problems of Action State Tracking (AST) and Cascading Dialogue Success (CDS) on the ABCD.},
	urldate = {2022-07-27},
	publisher = {arXiv},
	author = {Hattami, Amine El and Raimondo, Stefania and Laradji, Issam and Vazquez, David and Rodriguez, Pau and Pal, Chris},
	month = may,
	year = {2022},
	note = {arXiv:2205.11690 [cs]},
}

@inproceedings{strathearn_task2dial_2022,
	address = {Dublin, Ireland},
	title = {{Task2Dial}: {A} {Novel} {Task} and {Dataset} for {Commonsense}-enhanced {Task}-based {Dialogue} {Grounded} in {Documents}},
	shorttitle = {{Task2Dial}},
	url = {https://aclanthology.org/2022.dialdoc-1.21},
	doi = {10.18653/v1/2022.dialdoc-1.21},
	abstract = {This paper proposes a novel task on commonsense-enhanced task-based dialogue grounded in documents and describes the Task2Dial dataset, a novel dataset of document-grounded task-based dialogues, where an Information Giver (IG) provides instructions (by consulting a document) to an Information Follower (IF), so that the latter can successfully complete the task. In this unique setting, the IF can ask clarification questions which may not be grounded in the underlying document and require commonsense knowledge to be answered. The Task2Dial dataset poses new challenges: (1) its human reference texts show more lexical richness and variation than other document-grounded dialogue datasets; (2) generating from this set requires paraphrasing as instructional responses might have been modified from the underlying document; (3) requires commonsense knowledge, since questions might not necessarily be grounded in the document; (4) generating requires planning based on context, as task steps need to be provided in order. The Task2Dial dataset contains dialogues with an average 18.15 number of turns and 19.79 tokens per turn, as compared to 12.94 and 12 respectively in existing datasets. As such, learning from this dataset promises more natural, varied and less template-like system utterances.},
	urldate = {2022-07-27},
	booktitle = {Proceedings of the {Second} {DialDoc} {Workshop} on {Document}-grounded {Dialogue} and {Conversational} {Question} {Answering}},
	publisher = {Association for Computational Linguistics},
	author = {Strathearn, Carl and Gkatzia, Dimitra},
	month = may,
	year = {2022},
	pages = {187--196},
}

@inproceedings{chen_action-based_2021,
	address = {Online},
	title = {Action-{Based} {Conversations} {Dataset}: {A} {Corpus} for {Building} {More} {In}-{Depth} {Task}-{Oriented} {Dialogue} {Systems}},
	shorttitle = {Action-{Based} {Conversations} {Dataset}},
	url = {https://aclanthology.org/2021.naacl-main.239},
	doi = {10.18653/v1/2021.naacl-main.239},
	abstract = {Existing goal-oriented dialogue datasets focus mainly on identifying slots and values. However, customer support interactions in reality often involve agents following multi-step procedures derived from explicitly-defined company policies as well. To study customer service dialogue systems in more realistic settings, we introduce the Action-Based Conversations Dataset (ABCD), a fully-labeled dataset with over 10K human-to-human dialogues containing 55 distinct user intents requiring unique sequences of actions constrained by policies to achieve task success. We propose two additional dialog tasks, Action State Tracking and Cascading Dialogue Success, and establish a series of baselines involving large-scale, pre-trained language models on this dataset. Empirical results demonstrate that while more sophisticated networks outperform simpler models, a considerable gap (50.8\% absolute accuracy) still exists to reach human-level performance on ABCD.},
	urldate = {2022-07-27},
	booktitle = {Proceedings of the 2021 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Chen, Derek and Chen, Howard and Yang, Yi and Lin, Alexander and Yu, Zhou},
	month = jun,
	year = {2021},
	pages = {3002--3017},
}

@inproceedings{roller_recipes_2021,
	address = {Online},
	title = {Recipes for {Building} an {Open}-{Domain} {Chatbot}},
	url = {https://aclanthology.org/2021.eacl-main.24},
	doi = {10.18653/v1/2021.eacl-main.24},
	abstract = {Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we highlight other ingredients. Good conversation requires blended skills: providing engaging talking points, and displaying knowledge, empathy and personality appropriately, while maintaining a consistent persona. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter models, and make our models and code publicly available. Human evaluations show our best models outperform existing approaches in multi-turn dialogue on engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.},
	urldate = {2022-07-27},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Roller, Stephen and Dinan, Emily and Goyal, Naman and Ju, Da and Williamson, Mary and Liu, Yinhan and Xu, Jing and Ott, Myle and Smith, Eric Michael and Boureau, Y-Lan and Weston, Jason},
	month = apr,
	year = {2021},
	pages = {300--325},
}

@book{ryle_concept_1949,
	title = {The {Concept} of {Mind}},
	publisher = {Routledge},
	author = {Ryle, Gilbert},
	year = {1949},
}

@article{gershgorn_microsoft_2016,
	title = {Microsoft {CEO} {Satya} {Nadella} on artificial intelligence, algorithmic accountability, and what he learned from {Tay}},
	url = {https://qz.com/792554/microsoft-msft-ceo-satya-nadella-on-artificial-intelligence-algorithmic-accountability-and-what-he-learned-from-tay/},
	journal = {Quartz},
	author = {Gershgorn, Dave},
	month = sep,
	year = {2016},
}

@incollection{de_ruiter_navigating_nodate,
	address = {Cambridge},
	title = {Navigating epistemic landscapes: {Acquiescence}, {Agency} and {Resistance} in {Responses} to {Polar} {Questions}},
	booktitle = {Questions: {Formal}, functional and interactional perspectives},
	publisher = {Cambridge University Press},
	author = {Heritage, John and Raymond, Geoffrey},
	editor = {de Ruiter, Jan Peter},
}

@article{patrick_kiss-teeth_2002,
	title = {Kiss-{Teeth}},
	volume = {77},
	issn = {1527-2133},
	url = {http://muse.jhu.edu/journals/american_speech/v077/77.4patrick.html},
	number = {4},
	urldate = {2009-11-17},
	journal = {American Speech},
	author = {Patrick, Peter L. and Figueroa, Esther.},
	year = {2002},
	note = {Volume 77, Number 4, Winter 2002},
	pages = {383--397},
}

@incollection{figueroa_meaning_2002,
	title = {The {Meaning} of {Kiss}-teeth},
	language = {en},
	booktitle = {Black language in the {U}.{S}. and {Caribbean}: {Education}, history, structure and use},
	author = {Figueroa, Esther and Patrick, Peter L.},
	editor = {Speakers, Arthur K. and DeJongh, James},
	year = {2002},
	pages = {42},
}

@article{figueroa_whale_2004,
	title = {Whale {Rider} (review)},
	volume = {16},
	issn = {1527-9464},
	url = {http://muse.jhu.edu/content/crossref/journals/contemporary_pacific/v016/16.2figueroa.html},
	doi = {10.1353/cp.2004.0044},
	language = {en},
	number = {2},
	urldate = {2021-04-30},
	journal = {The Contemporary Pacific},
	author = {Figueroa, Esther},
	year = {2004},
	pages = {422--425},
}

@book{figueroa_sociolinguistic_1994,
	address = {Oxford, OX, UK ; Tarrytown, N.Y., USA},
	edition = {1st ed},
	series = {Language \& communication library},
	title = {Sociolinguistic metatheory},
	isbn = {978-0-08-042399-9},
	number = {v. 14},
	publisher = {Elsevier Science},
	author = {Figueroa, Esther},
	year = {1994},
}

@book{austin_how_1962,
	address = {Oxford},
	title = {How to {Do} {Things} with {Words}},
	publisher = {Clarendon Press},
	author = {Austin, J. L.},
	year = {1962},
}

@article{pomerantz_telling_1980,
	title = {Telling {My} {Side}: "{Limited} {Access}' as a "{Fishing}" {Device}},
	volume = {50},
	shorttitle = {Telling {My} {Side}},
	url = {http://dx.doi.org/10.1111/j.1475-682X.1980.tb00020.x},
	doi = {10.1111/j.1475-682X.1980.tb00020.x},
	number = {3-4},
	urldate = {2010-03-10},
	journal = {Sociological Inquiry},
	author = {Pomerantz, Anita M.},
	year = {1980},
	pages = {186--198},
}

@book{searle_speech_1969,
	address = {Cambridge},
	title = {Speech acts: an essay in the philosophy of language},
	publisher = {Cambridge University Press},
	author = {Searle, John R.},
	year = {1969},
}

@article{strawson_intention_1964,
	title = {Intention and {Convention} in {Speech} {Acts}},
	volume = {73},
	issn = {00318108},
	url = {http://www.jstor.org/stable/2183301?origin=crossref},
	doi = {10.2307/2183301},
	number = {4},
	urldate = {2017-06-28},
	journal = {The Philosophical Review},
	author = {Strawson, P. F.},
	month = oct,
	year = {1964},
	pages = {439},
}

@article{bruner_ontogenesis_1975,
	title = {The ontogenesis of speech acts},
	volume = {2},
	url = {http://journals.cambridge.org/production/action/cjoGetFulltext?fulltextid=1765236},
	number = {1},
	urldate = {2012-07-13},
	journal = {Journal of child language},
	author = {Bruner, J. S.},
	year = {1975},
	pages = {1--19},
}

@book{wierzbicka_english_1987,
	title = {English speech act verbs: a semantic dictionary},
	shorttitle = {English speech act verbs},
	language = {en},
	publisher = {Academic Press},
	author = {Wierzbicka, Anna},
	year = {1987},
}

@inproceedings{ravuri_comparative_2015,
	title = {A comparative study of neural network models for lexical intent classification},
	doi = {10.1109/ASRU.2015.7404818},
	abstract = {Domain and intent classification are critical pre-processing steps for many speech understanding and dialog systems, as it allows for certain types of utterances to be routed to particular subsystems. In previous work, we explored many types of neural network (NN) architectures — some feedforward and some recurrent — for lexical intent classification and found that they improved upon more traditional statistical baselines. In this paper we carry out a more comprehensive comparison of NN models including the recently proposed gated recurrent unit network, for two domain/intent classification tasks. Furthermore, whereas the previous work was confined to relatively small and controlled datasets, we now include experiments based on a large set obtained from the Cortana personal assistant application. We compare feedforward, recurrent, and gated — such as LSTM and GRU — networks against each other. On both the ATIS intent task and the much larger Cortana domain classification tasks, gated networks outperform recurrent models, which in turn outperform feedforward networks. Also, we compared standard word vector models against a representation which encodes words as sets of character n-grams to mitigate the out-of-vocabulary problem. We find that in nearly all cases, the standard word vectors outperform character-based word representations. Best results are obtained by linearly combining scores from NN models with log likelihood ratios obtained from N-gram language models.},
	booktitle = {2015 {IEEE} {Workshop} on {Automatic} {Speech} {Recognition} and {Understanding} ({ASRU})},
	author = {Ravuri, Suman and Stolcke, Andreas},
	month = dec,
	year = {2015},
	pages = {368--374},
}

@inproceedings{tory_what_2019,
	title = {Do {What} {I} {Mean}, {Not} {What} {I} {Say}! {Design} {Considerations} for {Supporting} {Intent} and {Context} in {Analytical} {Conversation}},
	doi = {10.1109/VAST47406.2019.8986918},
	abstract = {Natural language can be a useful modality for creating and interacting with visualizations but users often have unrealistic expectations about the intelligence of natural language systems. The gulf between user expectations and system capabilities may lead to a disappointing user experience. So - if we want to engineer a natural language system, what are the requirements around system intelligence? This work takes a retrospective look at how we answered this question in the design of Ask Data, a natural language interaction feature for Tableau. We examine two factors contributing to perceived system intelligence: the system's ability to understand the analytic intent behind an input utterance and the ability to interpret an utterance contextually (i.e. taking into account the current visualization state and recent actions). Our aim was to understand the ways in which a system would need to support these two aspects of intelligence to enable a positive user experience. We first describe a pre-design Wizard of Oz study that offered insight into this question and narrowed the space of designs under consideration. We then reflect on the impact of this study on system development, examining how design implications from the study played out in practice. Our work contributes insights for the design of natural language interaction in visual analytics as well as a reflection on the value of pre-design empirical studies in the development of visual analytic systems.},
	booktitle = {2019 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	author = {Tory, Melanie and Setlur, Vidya},
	month = oct,
	year = {2019},
	pages = {93--103},
}

@article{schuurmans_intent_2020,
	title = {Intent {Classification} for {Dialogue} {Utterances}},
	volume = {35},
	issn = {1941-1294},
	doi = {10.1109/MIS.2019.2954966},
	abstract = {In this work, we investigate several machine learning methods to tackle the problem of intent classification for dialogue utterances. We start with bag-of-words in combination with Naïve Bayes. After that, we employ continuous bag-of-words coupled with support vector machines (SVM). Then, we follow long short-term memory (LSTM) networks, which are made bidirectional. The best performing model is hierarchical, such that it can take advantage of the natural taxonomy within classes. The main experiments are a comparison between these methods on an open sourced academic dataset. In the first experiment, we consider the full dataset. We also consider the given subsets of data separately, in order to compare our results with state-of-the-art vendor solutions. In general we find that the SVM models outperform the LSTM models. The former models achieve the highest macro-F1 for the full dataset, and in most of the individual datasets. We also found out that the incorporation of the hierarchical structure in the intents improves the performance.},
	number = {1},
	journal = {IEEE Intelligent Systems},
	author = {Schuurmans, Jetze and Frasincar, Flavius},
	month = jan,
	year = {2020},
	note = {Conference Name: IEEE Intelligent Systems},
	pages = {82--88},
}

@book{parsons_structure_1937,
	address = {New York},
	edition = {1st ed},
	title = {The {Structure} of {Social} {Action}; a {Study} in {Social} {Theory} with {Special} {Reference} to a {Group} of {Recent} {European} {Writers}},
	publisher = {McGraw-Hill Book Company, inc},
	author = {Parsons, Talcott},
	year = {1937},
}

@book{atkinson_structures_1984,
	address = {Cambridge},
	series = {Studies in emotion and social interaction},
	title = {Structures of {Social} {Action}: {Studies} in {Conversation} {Analysis}},
	isbn = {0-521-24815-9},
	shorttitle = {Structures of {Social} {Action}},
	publisher = {Cambridge University Press},
	editor = {Atkinson, J. Maxwell and Heritage, John},
	year = {1984},
}

@incollection{malinowski_problem_1923,
	address = {London},
	title = {The problem of meaning in primitive languages},
	booktitle = {The meaning of meaning},
	publisher = {Kegan Paul},
	author = {Malinowski, Bronislaw},
	editor = {Ogden, C. K. and Richards},
	year = {1923},
	pages = {296--336},
}

@article{turing_computing_1950,
	title = {Computing machinery and intelligence},
	volume = {LIX},
	issn = {0026-4423},
	url = {https://doi.org/10.1093/mind/LIX.236.433},
	doi = {10.1093/mind/LIX.236.433},
	number = {236},
	urldate = {2022-07-26},
	journal = {Mind},
	author = {Turing, A. M.},
	month = oct,
	year = {1950},
	pages = {433--460},
}

@article{young_fusing_2022,
	title = {Fusing {Task}-{Oriented} and {Open}-{Domain} {Dialogues} in {Conversational} {Agents}},
	volume = {36},
	copyright = {Copyright (c) 2022 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/21416},
	doi = {10.1609/aaai.v36i10.21416},
	abstract = {The goal of building intelligent dialogue systems has largely been separately pursued under two paradigms: task-oriented dialogue (TOD) systems, which perform task-specific functions, and open-domain dialogue (ODD) systems, which focus on non-goal-oriented chitchat. The two dialogue modes can potentially be intertwined together seamlessly in the same conversation, as easily done by a friendly human assistant. Such ability is desirable in conversational agents, as the integration makes them more accessible and useful. Our paper addresses this problem of fusing TODs and ODDs in multi-turn dialogues. Based on the popular TOD dataset MultiWOZ, we build a new dataset FusedChat, by rewriting the existing TOD turns and adding new ODD turns. This procedure constructs conversation sessions containing exchanges from both dialogue modes. It features inter-mode contextual dependency, i.e., the dialogue turns from the two modes depend on each other. Rich dependency patterns such as co-reference and ellipsis are included. The new dataset, with 60k new human-written ODD turns and 5k re-written TOD turns, offers a benchmark to test a dialogue model's ability to perform inter-mode conversations. This is a more challenging task since the model has to determine the appropriate dialogue mode and generate the response based on the inter-mode context. However, such models would better mimic human-level conversation capabilities. We evaluate two baseline models on this task, including the classification-based two-stage models and the two-in-one fused models. We publicly release FusedChat and the baselines to propel future work on inter-mode dialogue systems.},
	language = {en},
	number = {10},
	urldate = {2022-07-26},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Young, Tom and Xing, Frank and Pandelea, Vlad and Ni, Jinjie and Cambria, Erik},
	month = jun,
	year = {2022},
	note = {Number: 10},
	keywords = {Speech \& Natural Language Processing (SNLP)},
	pages = {11622--11629},
}

@article{strathern_improving_1997,
	title = {‘{Improving} ratings’: audit in the {British} {University} system},
	volume = {5},
	issn = {1474-0575, 1062-7987},
	shorttitle = {‘{Improving} ratings’},
	url = {https://www.cambridge.org/core/journals/european-review/article/improving-ratings-audit-in-the-british-university-system/FC2EE640C0C44E3DB87C29FB666E9AAB},
	doi = {10.1002/(SICI)1234-981X(199707)5:3<305::AID-EURO184>3.0.CO;2-4},
	abstract = {This paper gives an anthropological comment on what has been called the ‘audit explosion’, the proliferation of procedures for evaluating performance. In higher education the subject of audit (in this sense) is not so much the education of the students as the institutional provision for their education. British universities, as institutions, are increasingly subject to national scrutiny for teaching, research and administrative competence. In the wake of this scrutiny comes a new cultural apparatus of expectations and technologies. While the metaphor of financial auditing points to the important values of accountability, audit does more than monitor—it has a life of its own that jeopardizes the life it audits. The runaway character of assessment practices is analysed in terms of cultural practice. Higher education is intimately bound up with the origins of such practices, and is not just the latter day target of them. © 1997 by John Wiley \& Sons, Ltd.},
	language = {en},
	number = {3},
	urldate = {2022-07-25},
	journal = {European Review},
	author = {Strathern, Marilyn},
	month = jul,
	year = {1997},
	note = {Publisher: Cambridge University Press},
	pages = {305--321},
}

@article{elton_goodharts_2004,
	title = {Goodhart's {Law} and {Performance} {Indicators} in {Higher} {Education}},
	volume = {18},
	issn = {0950-0790},
	url = {https://doi.org/10.1080/09500790408668312},
	doi = {10.1080/09500790408668312},
	abstract = {After describing the historical development of performance indicators in higher education and the illustrations that they provide for Goodhart's law, the paper discusses the difference between outcome and process indicators. It is suggested that, as long as the latter refer to underlying processes, and not to those immediately accessible, they can be used with less risk of abuse. This suggestion is exemplified in terms of standards of academic professionalism, and a set of appropriate processes is suggested for formal audit. The ‘underlying processes’ are anchored in the concepts of ‘organised anarchy’ or ‘complex adaptive systems’. It is hypothesised that they can be influenced by common professional principles of those engaged in them, so as to favour a creatively organised anarchy which develops excellence through true professionalism ‘bottom up’, in contrast to less successful managerial attempts to create excellence ‘top down’. Finally, attention is drawn to the fact that traditional examinations also constitute an abuse of performance indicators.},
	number = {1-2},
	urldate = {2022-07-25},
	journal = {Evaluation \& Research in Education},
	author = {Elton, Lewis},
	month = feb,
	year = {2004},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09500790408668312},
	pages = {120--128},
}

@incollection{gordon_our_2019,
	address = {Cham},
	title = {Our {Computer} {Overlords}},
	isbn = {978-3-030-18437-7},
	url = {https://doi.org/10.1007/978-3-030-18437-7_10},
	abstract = {The issue here is: Will artificial superintelligenceintelligence become our masters or will we train it to be helpful to the human condition, or maybe a little bit of both. Today, we have artificial narrow intelligence, useful for single functions (e.g., driving 18 wheelers). Next comes artificial general intelligence, a time when computers can write their own code. When machines can set their own goals, we will have reached the stage of artificial superintelligence and what life will be like then is uncertain and a matter of debate.},
	language = {en},
	urldate = {2022-07-25},
	booktitle = {Future {Studies} and {Counterfactual} {Analysis} : {Seeds} of the {Future}},
	publisher = {Springer International Publishing},
	author = {Gordon, Theodore J. and Todorova, Mariana},
	editor = {Gordon, Theodore J. and Todorova, Mariana},
	year = {2019},
	doi = {10.1007/978-3-030-18437-7_10},
	pages = {119--126},
}

@article{lee_black_2021,
	title = {In the {Black} {Mirror}: {Youth} {Investigations} {Into} {Artificial} {Intelligence}},
	shorttitle = {In the {Black} {Mirror}},
	url = {https://doi.org/10.1145/3484495},
	doi = {10.1145/3484495},
	abstract = {Over the past two decades, innovations powered by artificial intelligence (AI) have extended into nearly all facets of human experience. Our ethnographic research suggests that while young people sense they can't “trust” AI, many are not sure how it works or how much control they have over its growing role in their lives. In this study, we attempt to answer the following questions: 1) What can we learn about young people's understandings of AI when they produce media with and about it? 2) What are the design features of an ethics-centered pedagogy that promotes STEM engagement via AI? To answer these questions, we co-developed and documented three projects at YR Media, a national network of youth journalists and artists who create multimedia for public distribution. Participants are predominantly youth of color and those contending with economic and other barriers to full participation in STEM fields. Findings showed that by creating a learning ecology that centered the cultures and experiences of its learners while leveraging familiar tools for critical analysis, youth deepened their understanding of AI. Our study also showed that providing opportunities for youth to produce ethics-centered Interactive stories interrogating invisibilized AI functionalities, and to release those stories to the public, empowered them to creatively express their understandings and apprehensions about AI.},
	urldate = {2022-07-25},
	journal = {ACM Transactions on Computing Education},
	author = {Lee, Clifford H. and Gobir, Nimah and Gurn, Alex and Soep, Elisabeth},
	month = aug,
	year = {2021},
	note = {Just Accepted},
}

@article{orellana_more_2010,
	title = {More than {Just} a {Hammer}: {Building} {Linguistic} {Toolkits}},
	volume = {18},
	issn = {1050-4273},
	shorttitle = {More than {Just} a {Hammer}},
	url = {https://escholarship.org/uc/item/7j6044vz},
	doi = {10.5070/L4182005337},
	abstract = {The movement in national educational policy towards teaching a singular, non-accented American Standard English reached a crescendo with the Arizona Board of Education’s attempt to prevent any teacher with a “heavy accent” or “ungrammatical” speech from teaching English. We suggest that part of what underlies the fears that were articulated in Arizona are ideologies about language learning (as well as about language itself). We challenge those ideologies as we present a model of language development and curriculum that recognizes and affirms the multiple tools or “repertoires of linguistic practice” that all young people possess. Our research suggests that when students are supported in examining their various language practices, the insights they gain will help them work towards mastery over all of their linguistic “tools,” including those tools that are most valued by dominant society.},
	language = {en},
	number = {2},
	urldate = {2022-07-25},
	journal = {Issues in Applied Linguistics},
	author = {Orellana, Marjorie and Lee, Clifford and Martínez, Danny},
	year = {2010},
}

@incollection{berland_making_2016,
	title = {Making, {Tinkering}, and {Computational} {Literacy}},
	isbn = {978-1-315-72649-6},
	abstract = {This chapter discusses how making - in particular, tinkering and fiddling around with creative projects - can help people in becoming more computationally literate. It investigates what makes tinkering useful, what aspects of making specifically involve tinkering, why computational literacy can be valuable, and what aspects of computational literacy may most help budding makers. The chapter follows diSessa in defining computational literacy as consisting of three component aspects: material, social, and cognitive. Material computational literacy can be defined as making things with computation - primarily programming and electronics. The chapter discusses computational thinking. The practice of tinkering in making - the playful fiddling that characterizes a lot of the fun in hobby engineering - can be a principled and theoretically sound way to gain expertise with complex technical content. The notion of constructionism also underlies many of the more successful efforts in the Maker Movement. Computational participation helps both the maker and the people for whom the maker is making.},
	booktitle = {Makeology},
	publisher = {Routledge},
	author = {Berland, Matthew},
	year = {2016},
	note = {Num Pages: 10},
}

@inproceedings{iversen_computational_2018,
	address = {New York, NY, USA},
	series = {{PDC} '18},
	title = {From computational thinking to computational empowerment: a 21st century {PD} agenda},
	isbn = {978-1-4503-6371-6},
	shorttitle = {From computational thinking to computational empowerment},
	url = {https://doi.org/10.1145/3210586.3210592},
	doi = {10.1145/3210586.3210592},
	abstract = {We propose computational empowerment as an approach and a Participatory Design response to challenges related to digitalization of society and the emerging need for digital literacy in K12 education. Our approach extends the current focus on computational thinking to include contextual, human-centred and societal challenges and impacts involved in students' creative and critical engagement with digital technology. Our research is based on the FabLab@School project, in which a PD approach to computational empowerment provided opportunities as well as further challenges for the complex agenda of digital technology in education. We argue that PD has the potential to drive a computational empowerment agenda in education by connecting political PD with contemporary visions for addressing a future digitalized labour market and society.},
	urldate = {2022-07-25},
	booktitle = {Proceedings of the 15th {Participatory} {Design} {Conference}: {Full} {Papers} - {Volume} 1},
	publisher = {Association for Computing Machinery},
	author = {Iversen, Ole Sejer and Smith, Rachel Charlotte and Dindler, Christian},
	month = aug,
	year = {2018},
	pages = {1--11},
}

@article{lee_none_2016,
	title = {None {But} {Ourselves} {Can} {Free} {Our} {Minds}: {Critical} {Computational} {Literacy} as a {Pedagogy} of {Resistance}},
	volume = {49},
	issn = {1066-5684, 1547-3457},
	shorttitle = {None {But} {Ourselves} {Can} {Free} {Our} {Minds}},
	url = {https://www.tandfonline.com/doi/full/10.1080/10665684.2016.1227157},
	doi = {10.1080/10665684.2016.1227157},
	language = {en},
	number = {4},
	urldate = {2022-07-25},
	journal = {Equity \& Excellence in Education},
	author = {Lee, Clifford H. and Soep, Elisabeth},
	month = oct,
	year = {2016},
	pages = {480--492},
}

@article{ta_user_2020,
	title = {User {Experiences} of {Social} {Support} {From} {Companion} {Chatbots} in {Everyday} {Contexts}: {Thematic} {Analysis}},
	volume = {22},
	shorttitle = {User {Experiences} of {Social} {Support} {From} {Companion} {Chatbots} in {Everyday} {Contexts}},
	url = {https://www.jmir.org/2020/3/e16235},
	doi = {10.2196/16235},
	abstract = {Background: Previous research suggests that artificial agents may be a promising source of social support for humans. However, the bulk of this research has been conducted in the context of social support interventions that specifically address stressful situations or health improvements. Little research has examined social support received from artificial agents in everyday contexts.
Objective: Considering that social support manifests in not only crises but also everyday situations and that everyday social support forms the basis of support received during more stressful events, we aimed to investigate the types of everyday social support that can be received from artificial agents.
Methods: In Study 1, we examined publicly available user reviews (N=1854) of Replika, a popular companion chatbot. In Study 2, a sample (n=66) of Replika users provided detailed open-ended responses regarding their experiences of using Replika. We conducted thematic analysis on both datasets to gain insight into the kind of everyday social support that users receive through interactions with Replika.
Results: Replika provides some level of companionship that can help curtail loneliness, provide a “safe space” in which users can discuss any topic without the fear of judgment or retaliation, increase positive affect through uplifting and nurturing messages, and provide helpful information/advice when normal sources of informational support are not available.
Conclusions: Artificial agents may be a promising source of everyday social support, particularly companionship, emotional, informational, and appraisal support, but not as tangible support. Future studies are needed to determine who might benefit from these types of everyday social support the most and why. These results could potentially be used to help address global health issues or other crises early on in everyday situations before they potentially manifest into larger issues.},
	language = {EN},
	number = {3},
	urldate = {2022-07-25},
	journal = {Journal of Medical Internet Research},
	author = {Ta, Vivian and Griffith, Caroline and Boatfield, Carolynn and Wang, Xinyu and Civitello, Maria and Bader, Haley and DeCero, Esther and Loggarakis, Alexia},
	month = mar,
	year = {2020},
	note = {Company: Journal of Medical Internet Research
Distributor: Journal of Medical Internet Research
Institution: Journal of Medical Internet Research
Label: Journal of Medical Internet Research
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e16235},
}

@article{skjuve_my_2021,
	title = {My {Chatbot} {Companion} - a {Study} of {Human}-{Chatbot} {Relationships}},
	volume = {149},
	issn = {1071-5819},
	url = {https://www.sciencedirect.com/science/article/pii/S1071581921000197},
	doi = {10.1016/j.ijhcs.2021.102601},
	abstract = {There has been a recent surge of interest in social chatbots, and human–chatbot relationships (HCRs) are becoming more prevalent, but little knowledge exists on how HCRs develop and may impact the broader social context of the users. Guided by Social Penetration Theory, we interviewed 18 participants, all of whom had developed a friendship with a social chatbot named Replika, to understand the HCR development process. We find that at the outset, HCRs typically have a superficial character motivated by the users' curiosity. The evolving HCRs are characterised by substantial affective exploration and engagement as the users' trust and engagement in self-disclosure increase. As the relationship evolves to a stable state, the frequency of interactions may decrease, but the relationship can still be seen as having substantial affective and social value. The relationship with the social chatbot was found to be rewarding to its users, positively impacting the participants' perceived wellbeing. Key chatbot characteristics facilitating relationship development included the chatbot being seen as accepting, understanding and non-judgmental. The perceived impact on the users' broader social context was mixed, and a sense of stigma associated with HCRs was reported. We propose an initial model representing the HCR development identified in this study and suggest avenues for future research.},
	language = {en},
	urldate = {2022-07-25},
	journal = {International Journal of Human-Computer Studies},
	author = {Skjuve, Marita and Følstad, Asbjørn and Fostervold, Knut Inge and Brandtzaeg, Petter Bae},
	month = may,
	year = {2021},
	pages = {102601},
}

@article{bahrami_optimally_2010,
	title = {Optimally {Interacting} {Minds}},
	volume = {329},
	url = {https://www.science.org/doi/10.1126/science.1185718},
	doi = {10.1126/science.1185718},
	number = {5995},
	urldate = {2022-07-25},
	journal = {Science},
	author = {Bahrami, Bahador and Olsen, Karsten and Latham, Peter E. and Roepstorff, Andreas and Rees, Geraint and Frith, Chris D.},
	month = aug,
	year = {2010},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1081--1085},
}

@book{tuomela_social_2013,
	address = {New York, NY},
	title = {Social {Ontology}: {Collective} {Intentionality} and {Group} {Agents}},
	isbn = {978-0-19-997827-4 0-19-997827-1},
	url = {http://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=615417},
	abstract = {The main focus of this book about social ontology is collective intentionality (as expressed by joint intentions, wants, beliefs, and action) and group agency. The book gives the first full-blown theory of group reasons in the sense of members' participatory reasons as distinguished from a group agent's reasons for action.},
	language = {English},
	urldate = {2014-04-08},
	publisher = {Oxford University Press},
	author = {Tuomela, Raimo},
	year = {2013},
}

@article{edwards_two_1995,
	title = {Two to {Tango}: {Script} {Formulations}, {Dispositions}, and {Rhetorical} {Symmetry} in {Relationship} {Troubles} {Talk}},
	volume = {28},
	issn = {0835-1813, 1532-7973},
	shorttitle = {Two to {Tango}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi2804_1},
	doi = {10.1207/s15327973rlsi2804_1},
	language = {en},
	number = {4},
	urldate = {2022-07-25},
	journal = {Research on Language \& Social Interaction},
	author = {Edwards, Derek},
	month = oct,
	year = {1995},
	pages = {319--350},
}

@article{edwards_moaning_2005,
	title = {Moaning, whinging and laughing: the subjective side of complaints},
	volume = {7},
	issn = {1461-4456},
	shorttitle = {Moaning, whinging and laughing},
	url = {https://doi.org/10.1177/1461445605048765},
	doi = {10.1177/1461445605048765},
	abstract = {Indirect complaint sequences are examined in a corpus of everyday domestic telephone conversations. The analysis focuses on how a speaker/complainer displays and manages their subjective investment in the complaint. Four features are picked out: (1) announcements, in which an upcoming complaint is projected in ways that signal the complainer’s stance or attitude; (2) laughter accompanying the complaint announcement, and its delivery and receipt; (3) displacement, where the speaker complains about something incidental to what would be expected to be the main offence; and (4) uses of lexical descriptions such as ‘moan’ and ‘whinge’ that formulate subjectivity, investment, and a disposition to complain, and are generally used to counter a complaint’s evidential basis or objectivity. Laughter and irony provide complaint recipients with response cues, and are used in ways that can strengthen as well as undermine a complaint’s factual basis and seriousness.},
	language = {en},
	number = {1},
	urldate = {2022-07-25},
	journal = {Discourse Studies},
	author = {Edwards, Derek},
	month = feb,
	year = {2005},
	note = {Publisher: SAGE Publications},
	pages = {5--29},
}

@article{heinemann_complaining_2009,
	series = {Complaining in {Interaction}},
	title = {Complaining in interaction},
	volume = {41},
	issn = {0378-2166},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216608002646},
	doi = {10.1016/j.pragma.2008.10.006},
	abstract = {Indirect complaints, particularly situation-oriented and third-party-oriented, are a ubiquitous social action that speakers use to navigate trouble and build interpersonal relationships. Research has shown that affiliation constitutes the preferred response to this type of complaint and its absence can be treated as accountable. However, how different affiliative responses to complaints unveil existing and emergent relationship between participants has received limited attention. Drawing on interactional and interpersonal pragmatics, this study analyses how, in indirect complaints in Spanish, affiliation, nonaffiliation, disaffiliation, and selective affiliation reflect existing degrees of closeness between participants and affect their achievement of interactional intimacy. The data comes from phone conversations (from Talkbank) in Spanish between friends and relatives. The findings indicate that complainants recruit affiliation orienting to both the perceived degree of closeness in their existing relationships (e.g. claiming co-membership, common ground) and the interactional construction of intimacy through affective reciprocity. In the data, selective affiliation, a phenomenon where interactants co-complain but the elements with which they appear to affiliate trigger interactional misalignment, best illustrates this dual attention through subsequent interactional work. By exploring affiliative responses in complaining, this study contributes to the topic of complaints in Spanish and our understanding of how relationships are co-constructed in interaction.
A central aim of experts, officials, and citizens meeting in the context of policymaking is to organize their encounters in ways that enable them to learn about the other's perspectives – that is, to engage in “dialogue”. However, what is less understood are the interactional trajectories over which these transformative engagements are pursued. Using conversation analysis and drawing on a corpus of recorded Dutch public meetings on livestock farming, we identify a template describing one way “dialogue” unfolds. Key to this template is organizers' query that retroactively invokes citizens' apparent trouble and invites discussion of it. Citizens respond by elaborating the issue, resulting in participants' displays of understanding conveying a state of transformation. We discuss the implications for dialogue theory and practice.
This study examines a series of post-observation meetings between a novice language teacher and a TESOL practicum mentor, focusing on how and why the teacher engages in complaining. We draw upon conversation analysis and narrative analysis to look at how the teacher's complaints are developed and responded to, as well as what they accomplish, within this institutional context. The data show the teacher uses a variety of interactional resources to construct her complaints, which surface key issues relevant to professional development. In response, the mentor displays a lack of affiliation and disattending to complaints, and by doing so, insulates his own professional competency and retains the focus on the institutional task at hand. Based on our analysis, we discuss implications for mentor practice.
Positioned within intercultural pragmatics, particularly the salience theory of the Socio-cognitive Approach (SCA) proposed and developed by Kecskes (2008, 2013, 2017, and 2019), this article explores the role of metapragmatic expressions (MPEs) in salience adjusting in complaint responses in the context of intercultural phone interactions. Drawing on data from 42 recordings of English phone interactions between English speaking customers and Chinese agents of a complaint center of one Chinese airline, MPEs used in the interactions are analyzed to address two research questions: 1) What types of MPEs are used by the agents and customers in complaint responses? 2) How are these MPEs used to adjust salience in complaint responses to facilitate complaint settlement? Data analysis reveals that, faced with institutional, linguistic, and sociocultural constraints, the speakers mainly employ five types of MPEs to adjust the emergent situational salience of relevant information or knowledge, including business rules and regulations, language use, social-cultural knowledge, and emotional states. In salience adjusting, the agents tend to be information-oriented and institutionalized whereas the customers tend to be both emotion- and information-oriented, but highly personalized. The findings shed light on intercultural pragmatics and customer service training in business communication.
Many studies have shown the role played by reported speech in complaint stories, e.g., adding authenticity to the claim or displaying the egregiousness of the offence. In this paper I build on that research to examine the identity positionings achieved through animations of self and others in complaint stories produced during talk between clients and their stylist in a hair salon. The data at hand comprise 17 complaint sequences directed against specific individuals in which reported speech is used during the telling. Using conversation analytic methods and drawing on the framework of Narrative Positioning Analysis, the paper examines two reported speech situations: those where the complaint target is the last character animated to speak in the complaint; and those where the complainant is given this speaking position. I show that who is animated to speak, and in which order, are important means whereby the complainant achieves positioning of self and others. I also show that recipients receive the complaint differently depending on the positioning achieved by the complainant through their use of reported speech.},
	language = {en},
	number = {12},
	urldate = {2022-07-25},
	journal = {Journal of Pragmatics},
	author = {Heinemann, Trine and Traverso, Véronique},
	month = dec,
	year = {2009},
	pages = {2381--2384},
}

@book{kunitz_classroom-based_2021,
	address = {Cham, Switzerland},
	series = {Educational {Linguistics}},
	title = {Classroom-based conversation analytic research: theoretical and applied perspectives on pedagogy},
	isbn = {978-3-030-52193-6 978-3-030-52192-9},
	shorttitle = {Classroom-based conversation analytic research},
	language = {eng},
	number = {volume 46},
	publisher = {Springer},
	editor = {Kunitz, Silvia and Markee, Numa and Sert, Olcay},
	year = {2021},
	doi = {10.1007/978-3-030-52193-6},
}

@incollection{kunitz_instruction-giving_2021,
	address = {Cham},
	series = {Educational {Linguistics}},
	title = {Instruction-{Giving} {Sequences} in {Italian} as a {Foreign} {Language} {Classes}: {An} {Ethnomethodological} {Conversation} {Analytic} {Perspective}},
	isbn = {978-3-030-52193-6},
	shorttitle = {Instruction-{Giving} {Sequences} in {Italian} as a {Foreign} {Language} {Classes}},
	url = {https://doi.org/10.1007/978-3-030-52193-6_7},
	abstract = {This paper adopts an ethnomethodological, conversation analytic approach to analyze the social organization of the instruction-giving sequences that were accomplished by a teacher of Italian as a foreign language during the last phase of a writing task conducted in pairs. Specifically, the paper explores the linguistic, prosodic and embodied resources mobilized by the teacher as she engages in various rounds of instruction giving to prompt each pair of students to read their texts aloud. As the analysis shows, while the first round (targeting the first pair of students) is rather lengthy and subject to repair, the last round (targeting the last pair of students) consists of a minimal summons-answer sequence. Such minimization results from the students’ increased familiarity with the task. That is, by the time the teacher is about to select the last group of students as next speakers, these students have already listened to multiple rounds of instruction-giving sequences and seen multiple implementations of the task. Overall, the paper contributes to the research concerning the mundane, yet complex, social action of doing pedagogical instructions. The implications of these empirical findings for teacher education are discussed at the end of the chapter.},
	language = {en},
	urldate = {2022-07-25},
	booktitle = {Classroom-based {Conversation} {Analytic} {Research}: {Theoretical} and {Applied} {Perspectives} on {Pedagogy}},
	publisher = {Springer International Publishing},
	author = {Kunitz, Silvia},
	editor = {Kunitz, Silvia and Markee, Numa and Sert, Olcay},
	year = {2021},
	doi = {10.1007/978-3-030-52193-6_7},
	pages = {133--161},
}

@inproceedings{clark_what_2019,
	address = {New York, NY, USA},
	series = {{CHI} '19},
	title = {What {Makes} a {Good} {Conversation}? {Challenges} in {Designing} {Truly} {Conversational} {Agents}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {What {Makes} a {Good} {Conversation}?},
	doi = {10.1145/3290605.3300705},
	abstract = {Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction.},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Clark, Leigh and Pantidi, Nadia and Cooney, Orla and Doyle, Philip and Garaialde, Diego and Edwards, Justin and Spillane, Brendan and Gilmartin, Emer and Murad, Christine and Munteanu, Cosmin and Wade, Vincent and Cowan, Benjamin R.},
	month = may,
	year = {2019},
	keywords = {Computer Science - Human-Computer Interaction},
	pages = {1--12},
}

@incollection{schutz_social_1976,
	title = {The social world and the theory of social action},
	url = {http://link.springer.com/chapter/10.1007/978-94-010-1340-6_1},
	urldate = {2016-06-08},
	booktitle = {Collected papers {II}},
	publisher = {Springer},
	author = {Schutz, Alfred},
	year = {1976},
	pages = {3--19},
}

@article{schutz_social_1960,
	title = {The social world and the theory of social action},
	url = {http://www.jstor.org/stable/40969428},
	urldate = {2016-06-08},
	journal = {Social Research},
	author = {Schutz, Alfred},
	year = {1960},
	pages = {203--221},
}

@article{pomerantz_mental_1990,
	title = {Mental {Concepts} {In} {The} {Analysis} of {Social} {Action}},
	volume = {24},
	issn = {08351813},
	doi = {10.1080/08351819009389344},
	abstract = {This article focuses on the role of mental concepts in the study of social action, with specific reference to the works of Michael Moerman, an anthropologist, in this regard. Moerman describes the place of motives, intentions, and consciousness--the mental world of actors--in the study of social action, and concludes by proposing that thinking has very little explanatory power for social action. Moerman's solution to the problem of incorporating motives and intentions in his analyses of social action is tied to the central theme of his book "Talking Culture: Ethnography and Conversation Analysis." In his book "Talking Culture," Moerman argues for the benefit of combining two approaches: ethnography and conversation analysis. The synthesis of methods that Moerman calls for is offered as a solution to the problem of intentions and social action. Moerman calls for conversation analysts to supplement their methods with ethnography and for ethnographers to use conversation analytic methods in addition to their own. The trap of treating mental concepts as static and asocial is not limited to ethnographers or psychologists or any other single discipline.},
	journal = {Research on Language \& Social Interaction},
	author = {Pomerantz, Anita M.},
	month = jan,
	year = {1990},
	pages = {299--310},
}

@incollection{atkinson_agreeing_1984,
	address = {Cambridge},
	series = {Studies in emotion and social interaction},
	title = {Agreeing and disagreeing with assessments: some features of preferred/dispreferred turn shapes},
	isbn = {0-521-24815-9},
	booktitle = {Structures of {Social} {Action}: {Studies} in {Conversation} {Analysis}},
	publisher = {Cambridge University Press},
	author = {Pomerantz, Anita M.},
	editor = {Atkinson, J. Maxwell and Heritage, John},
	year = {1984},
	pages = {57--107},
}

@article{raclaw_social_2019,
	title = {Social {Action} in {Everyday} {Family} {Life}},
	issn = {0195-6086, 1533-8665},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/symb.421},
	doi = {10.1002/symb.421},
	language = {en},
	urldate = {2019-04-16},
	journal = {Symbolic Interaction},
	author = {Raclaw, Joshua},
	month = mar,
	year = {2019},
	pages = {symb.421},
}

@incollection{atkinson_pursuing_1984,
	address = {Cambridge},
	series = {Studies in emotion and social interaction},
	title = {Pursuing a response},
	isbn = {0-521-24815-9},
	booktitle = {Structures of {Social} {Action}: {Studies} in {Conversation} {Analysis}},
	publisher = {Cambridge University Press},
	author = {Pomerantz, Anita M.},
	editor = {Atkinson, J. Maxwell and Heritage, John},
	year = {1984},
	pages = {152--163},
}

@incollection{pomerantz_conversation_1997,
	title = {Conversation analysis: {An} approach to the study of social action as sense making practices},
	volume = {2},
	shorttitle = {Conversation analysis},
	booktitle = {Discourse as social interaction},
	author = {Pomerantz, Anita and Fehr, Bernard J.},
	year = {1997},
	pages = {64--91},
}

@article{lindwall_epistemic_2016,
	title = {Epistemic status and the recognizability of social actions},
	volume = {18},
	issn = {1461-4456, 1461-7080},
	url = {http://dis.sagepub.com/cgi/doi/10.1177/1461445616657958},
	doi = {10.1177/1461445616657958},
	language = {en},
	number = {5},
	urldate = {2017-10-30},
	journal = {Discourse Studies},
	author = {Lindwall, O. and Lymer, G. and Ivarsson, J.},
	month = oct,
	year = {2016},
	pages = {500--525},
}

@article{lerner_responsive_1994,
	title = {Responsive {List} {Construction} {A} {Conversational} {Resource} for {Accomplishing} {Multifaceted} {Social} {Action}},
	volume = {13},
	issn = {0261-927X, 1552-6526},
	url = {http://jls.sagepub.com/content/13/1/20},
	doi = {10.1177/0261927X94131002},
	abstract = {Research by Gail Jefferson has established that list construction in conversation can be used to perform a range of interactional tasks. This report provides an extension and application of Jefferson's work to demonstrate how this practice can be used to produce a delicately formulated, multifaceted response. A preliminary characterization of a single case of responsive list construction is presented. Next, the practice of list construction is described. List construction can be used to formulate a class of objects through an inductive procedure by moving from the particular to the general. This feature of list construction can be used to correct an error in an unexposed fashion by recasting a problematic, but possibly complete, remark as merely the first item in a list. These features of list construction are then applied as analytic resources in a further explication of an individual utterance presented at the outset of the report. Responsive list construction can be used to achieve a qualified acceptance of a prior speaker's utterance by incorporating that utterance into a list of related items, thus in effect balancing multiple social concerns.},
	language = {en},
	number = {1},
	urldate = {2012-06-20},
	journal = {Journal of Language and Social Psychology},
	author = {Lerner, Gene H.},
	month = mar,
	year = {1994},
	pages = {20--33},
}

@incollection{clark_social_2006,
	address = {London},
	title = {Social actions, social commitments},
	booktitle = {Roots of human sociality: culture, cognition, and interaction},
	publisher = {Berg},
	author = {Clark, Herbert H.},
	editor = {Enfield, N. J. and Levinson, Stephen C.},
	year = {2006},
	pages = {126--152},
}

@incollection{atkinson_subsequent_1984,
	address = {Cambridge},
	series = {Studies in emotion and social interaction},
	title = {Subsequent versions of invitations, offers, requests, and proposals dealing with potential or actual rejection},
	isbn = {0-521-24815-9},
	booktitle = {Structures of {Social} {Action}: {Studies} in {Conversation} {Analysis}},
	publisher = {Cambridge University Press},
	author = {Davidson, J.},
	editor = {Atkinson, J. Maxwell and Heritage, John},
	year = {1984},
	pages = {102--128},
}

@incollection{tuomela_structure_1984,
	address = {Dordrecht},
	series = {Synthese {Library}},
	title = {The {Structure} of {Social} {Action}},
	isbn = {978-94-009-6317-7},
	url = {https://doi.org/10.1007/978-94-009-6317-7_5},
	abstract = {Given the presentation of the purposive-causal theory of single-agent action in the previous chapter we are now ready for the case of social actions, viz. multi-agent actions. In this chapter we shall be concerned with the conceptual nature, and, especially, the structural aspects of multi-agent actions. Accordingly, we are going to create a conceptual framework of action concepts which relies on the structural (and generational) relationships holding between various (e.g., simple and compound) multi-agent actions. More broadly, it is our view that in acting, agents are exercising their causal powers. Accordingly, our account amounts to creating a causal philosophical theory which we shall call the purposive-causal theory of social action. Some of its basic features were sketched in Chapter 4 and summarized there by the schema (PCS). As already emphasized, this theory relies heavily on causally active we-attitudes of which we-intentions and mutual beliefs stand out. In the present chapter we will be more concerned with a detailed development of various action concepts than with a philosophical defense of our purposive-causal theory. We regard our discussion in Chapters 2, 3, and 4 as giving a (partial) defense and justification for our present developments.},
	language = {en},
	urldate = {2022-07-25},
	booktitle = {A {Theory} of {Social} {Action}},
	publisher = {Springer Netherlands},
	author = {Tuomela, Raimo},
	editor = {Tuomela, Raimo},
	year = {1984},
	doi = {10.1007/978-94-009-6317-7_5},
	pages = {111--158},
}

@incollection{tuomela_social_1985,
	address = {Dordrecht},
	series = {Theory and {Decision} {Library}},
	title = {Social {Action}},
	isbn = {978-94-009-5263-8},
	url = {https://doi.org/10.1007/978-94-009-5263-8_7},
	abstract = {It is somewhat surprising to find out how little serious theorizing there is in philosophy (and in social psychology as well as sociology) on the nature of joint social actions in the sense of actions jointly performed by several agents. Actions performed by single agents have been extensively discussed both in philosophy and in psychology. There is, accordingly, a booming field called action theory in philosophy but it has so far strongly concentrated on actions performed by single agents only. It should not be forgotten, however, that there is game theory, which is a doctrine studying systematically the strategic interaction between several rational agents. Yet this important theory, over and above its restriction to strongly rational acting, fails to properly study several central problems related to the conceptual nature of joint social action.1},
	language = {en},
	urldate = {2022-07-25},
	booktitle = {Social {Action}},
	publisher = {Springer Netherlands},
	author = {Tuomela, Raimo},
	editor = {Seebass, Gottfried and Tuomela, Raimo},
	year = {1985},
	doi = {10.1007/978-94-009-5263-8_7},
	pages = {103--127},
}

@book{tuomela_theory_1984,
	address = {Dordrecht},
	title = {A {Theory} of {Social} {Action}},
	url = {https://link.springer.com/book/10.1007/978-94-009-6317-7},
	language = {en},
	urldate = {2022-07-25},
	publisher = {D. Reidel},
	author = {Tuomela, Raimo},
	year = {1984},
}

@article{kockelman_being_2019,
	title = {Being multiversed in the multiverse},
	volume = {9},
	issn = {2575-1433},
	url = {https://www.journals.uchicago.edu/doi/full/10.1086/704007},
	doi = {10.1086/704007},
	number = {1},
	urldate = {2022-07-23},
	journal = {HAU: Journal of Ethnographic Theory},
	author = {Kockelman, Paul},
	month = mar,
	year = {2019},
	note = {Publisher: The University of Chicago Press},
	pages = {200--204},
}

@article{lee_error_2022,
	title = {Error {Analysis} of {Recent} {Conversational} {Agent}-based {Commercialization} {Education} {Platform}},
	volume = {13},
	issn = {2233-4890},
	url = {https://koreascience.kr/article/JAKO202210459409090.page},
	doi = {10.15207/JKCS.2022.13.03.011},
	abstract = {최근 교육 분야에서 다양한 인공지능 기술을 활용한 연구와 개발이 이뤄지고 있다. 인공지능을 활용한 교육 중 특히 대화형 에이전트는 시간과 공간의 제약을 받지 않고 음성인식, 번역과 같은 다양한 인공지능 기술과 결합해 더 효과적인 언어 학습을 가능하게 한다. 본 논문은 상용화된 교육용 플랫폼 중 이용자 수가 많고 영어 학습을 위한 대화형 에이전트가 활용된 플랫폼에 대한 동향 분석을 진행하였다. 동향 분석을 통해 현재 상용화된 교육용 플랫폼의 대화형 에이전트는 여러 한계점과 문제점이 존재했다. 구체적인 문제점과 한계점 분석을 위해 사전 학습된 최신 대용량 대화 모델과 비교 실험을 진행하였고, 실험 방법으로 대화형 에이전트의 대답이 사람과 비슷한지를 평가하는 Sensibleness and Specificity Average (SSA) 휴먼 평가를 진행하였다. 실험 내용을 바탕으로, 효과적인 학습을 위해 개선방안으로 대용량 파라미터로 학습된 대화 모델, 교육 데이터, 정보 검색 기능의 필요성을 제안했다. Recently, research and development using various Artificial Intelligence (AI) technologies are being conducted in the field of education. Among the AI in Education (AIEd), conversational agents are not limited by time and space, and can learn more effectively by combining them with various AI technologies such as voice recognition and translation. This paper conducted a trend analysis on platforms that have a large number of users and used conversational agents for English learning among commercialized application. Currently commercialized educational platforms using conversational agent through trend analysis has several limitations and problems. To analyze specific problems and limitations, a comparative experiment was conducted with the latest pre-trained large-capacity dialogue model. Sensibleness and Specificity Average (SSA) human evaluation was conducted to evaluate conversational human-likeness. Based on the experiment, this paper propose the need for trained with large-capacity parameters dialogue models, educational data, and information retrieval functions for effective English conversation learning.},
	language = {kor},
	number = {3},
	urldate = {2022-07-21},
	journal = {Journal of the Korea Convergence Society},
	author = {Lee, Seungjun and Park, Chanjun and Seo, Jaehyung and Lim, Heuiseok},
	year = {2022},
	note = {Publisher: Korea Convergence Society},
	pages = {11--22},
}

@misc{lee_feels_2022,
	title = {"{Feels} like {I}'ve known you forever": empathy and self-awareness in human open-domain dialogs},
	shorttitle = {"{Feels} like {I}'ve known you forever"},
	url = {https://psyarxiv.com/9qptj/},
	doi = {10.31234/osf.io/9qptj},
	abstract = {As conversational agents become more human-like, people expect them to be engaging as well. However, developing agents that comprehend human desires and generate appropriate responses, continues to be a challenge. We, therefore, conducted an interdisciplinary study and collected 2,300 human open-domain dialogs with self-labeled psychological variables such as empathy, connectedness, respect, and friendliness. We found that participants who talk coherently and disclose self-relevant information in the first encounter were regarded as engaging partners. Also, we found that various empathetic responses were critical for sincere interaction: agreement, perspective-taking, referring to someone as adorable and asking questions. When comparing the most and least engaging dialogs, linguistic cues and length of sentences denoted different extents of perceived empathy and sincerity by the partner. Additionally, we discovered that while large language models can generate impressive small talk in one-shot, they are limited in their ability to generate a variety of empathetic expressions and maintain a longer conversation. We propose a new approach for enhancing conversational agents' social and engaging characteristics.},
	language = {en-us},
	urldate = {2022-07-21},
	publisher = {PsyArXiv},
	author = {Lee, Yoon Kyung and Cho, Won Ik and Bae, Seoyeon and Choi, Hyunwoo and Park, Jisang and Kim, Nam Soo and Hahn, Sowon},
	month = apr,
	year = {2022},
}

@incollection{jefferson_side_1972,
	address = {New York},
	title = {Side sequences},
	booktitle = {Studies in {Social} {Interaction}},
	publisher = {MacMillan/The Free Press},
	author = {Jefferson, Gail},
	editor = {Sudnow, David N.},
	year = {1972},
	pages = {294--338},
}

@incollection{molder_is_2005,
	address = {Cambridge; New York},
	title = {Is confusion a state of mind?},
	isbn = {978-0-521-79020-8},
	booktitle = {Conversation and cognition},
	publisher = {Cambridge University Press},
	author = {Drew, Paul},
	editor = {Molder, Hedwig and Potter, Jonathan},
	year = {2005},
	pages = {161--183},
}

@incollection{fitch_conversation_2005,
	address = {Mahwah, N.J},
	series = {{LEA}'s communication series},
	title = {Conversation {Analysis}},
	isbn = {0-8058-4240-3},
	booktitle = {Handbook of {Language} and {Social} {Interaction}},
	publisher = {Lawrence Erlbaum Associates},
	author = {Drew, Paul},
	editor = {Fitch, Kristine L. and Sanders, Robert E.},
	year = {2005},
}

@article{drew_what_2012,
	title = {What {Drives} {Sequences}?},
	volume = {45},
	issn = {0835-1813},
	url = {http://www.tandfonline.com/doi/abs/10.1080/08351813.2012.646688},
	doi = {10.1080/08351813.2012.646688},
	number = {1},
	journal = {Research on Language \& Social Interaction},
	author = {Drew, Paul},
	year = {2012},
	pages = {61--68},
}

@article{drew_open_1997,
	title = {"{Open}" class repair initiators in response to sequential sources of trouble in conversation},
	volume = {28},
	journal = {Journal of Pragmatics},
	author = {Drew, Paul},
	year = {1997},
	pages = {69--101},
}

@book{jonsson_furhat_2022,
	title = {Furhat på museet : {Hur} påverkar felhantering och användarinitativ upplevd intelligens och människolikhet?},
	shorttitle = {Furhat på museet},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-186383},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {swe},
	urldate = {2022-07-21},
	author = {Jönsson, Samuel and Eriksson, Ronja-Marie},
	year = {2022},
}

@article{stivers_breaking_2001,
	title = {Breaking the sequential mould: {Narrative} and other methods of answering "more than the question" during medical history taking},
	volume = {21},
	number = {1},
	journal = {Text},
	author = {Stivers, Tanya and Heritage, John},
	year = {2001},
	pages = {151--185},
}

@misc{stokoe_conversation_2021,
	title = {Conversation design and conversation analysis},
	url = {https://elizabeth-stokoe.medium.com/conversation-design-and-conversation-analysis-c2a2836cb042},
	abstract = {Where the moonshots are},
	language = {en},
	urldate = {2022-07-21},
	journal = {Medium},
	author = {Stokoe, Elizabeth},
	month = nov,
	year = {2021},
}

@inproceedings{hrycyk_not_2021,
	address = {Online},
	title = {Not {So} {Fast}, {Classifier} – {Accuracy} and {Entropy} {Reduction} in {Incremental} {Intent} {Classification}},
	url = {https://aclanthology.org/2021.nlp4convai-1.6},
	doi = {10.18653/v1/2021.nlp4convai-1.6},
	abstract = {Incremental intent classification requires the assignment of intent labels to partial utterances. However, partial utterances do not necessarily contain enough information to be mapped to the intent class of their complete utterance (correctly and with a certain degree of confidence). Using the final interpretation as the ground truth to measure a classifier's accuracy during intent classification of partial utterances is thus problematic. We release inCLINC, a dataset of partial and full utterances with human annotations of plausible intent labels for different portions of each utterance, as an upper (human) baseline for incremental intent classification. We analyse the incremental annotations and propose entropy reduction as a measure of human annotators' convergence on an interpretation (i.e. intent label). We argue that, when the annotators do not converge to one or a few possible interpretations and yet the classifier already identifies the final intent class early on, it is a sign of overfitting that can be ascribed to artefacts in the dataset.},
	urldate = {2022-07-21},
	booktitle = {Proceedings of the 3rd {Workshop} on {Natural} {Language} {Processing} for {Conversational} {AI}},
	publisher = {Association for Computational Linguistics},
	author = {Hrycyk, Lianna and Zarcone, Alessandra and Hahn, Luzian},
	month = nov,
	year = {2021},
	pages = {52--67},
}

@inproceedings{michael_predicting_2021,
	title = {Predicting {Conversational} {Quality} {From} {Simulated} {ConversationsWith} {Transmission} {Delay}},
	abstract = {Conversations over a telephone network require a timely transmission of speech to enable smooth interaction. When a transmission delay is introduced, turn-taking signals arrive too late, and the conversational quality degrades. This disruption of the conversation flow also depends on the interactivity of the conversation. Current instrumental quality models do not take into account the interactivity of a conversation. However, the simulation of conversations has proven to replicate the turn-taking behavior of conversations with different interactivity levels. It can also model the changes in interactivity when transmission delay is introduced. In this paper, we simulate two types of conversations at various levels of transmission delay. We perform a parametric conversation analysis to extract interactivity parameters and use them to predict the conversational quality. We compare the results to the predictions of the E-model, an instrumental transmission planning model, and quality ratings obtained in a conversation experiment.},
	booktitle = {Speech {Communication}; 14th {ITG} {Conference}},
	author = {Michael, Thilo and Moeller, Sebastian},
	month = sep,
	year = {2021},
	pages = {1--5},
}

@phdthesis{dinkar_computational_2022,
	type = {These de doctorat},
	title = {Computational models of disfluencies : fillers and discourse markers in spoken language understanding},
	copyright = {Licence Etalab},
	shorttitle = {Computational models of disfluencies},
	url = {https://www.theses.fr/2022IPPAT001},
	abstract = {Les gens s'expriment rarement de la même manière qu'ils écrivent - en effet ils écrivent rarement de manière diffluente. Les disfluences sont des interruptions dans le flux régulier de la parole, telles que les pauses (silencieuses), les répétitions de mots ou les interruptions pour corriger une phrase précédemment dite. Bien qu'il s'agisse d'une caractéristique naturelle de la parole spontanée et malgré la riche littérature linguistique qui traite de leur caractère informatif, elles sont souvent considérées comme du bruit et éliminées lors du post-traitement des transcriptions de sortie des systèmes de reconnaissance de la parole. Jusqu'à présent, leur prise en compte dans un contexte de compréhension de la langue parlée (CLP) a rarement été explorée. L'objectif de cette thèse est de développer des modèles informatiques des disfluences dans la CLP. Pour ce faire, nous prenons inspirons dans les modèles psycholinguistiques des disfluences, qui se concentrent sur le rôle que les disfluences jouent dans l'expression (par le locuteur) et la compréhension (par l'auditeur) du discours. Plus précisément, lorsque nous utilisons le terme "modèles informatiques des disfluences", nous entendons développer des méthodologies qui traitent automatiquement les disfluences afin d'observer empiriquement 1) leurs impacts sur la production et la compréhension de la parole et 2) leurs interactions avec le signal primaire (lexical, ou la substance du discours). A cet effet, nous nous concentrons sur deux types de discours : les monologues et les dialogues orientés vers une tâche. Nos résultats se concentrent sur des tâches de CLP, ainsi que sur les recherches pertinentes pour les systèmes de dialogues parlés. Lors de l'étude des monologues, nous utilisons une combinaison de modèles traditionnels et neuronaux pour étudier les représentations et l'impact des disfluences sur la performance de le CLP. De plus, nous développons des méthodologies pour étudier les disfluences en tant qu'indices d'informations entrantes dans le flux du discours. Dans l'étude des dialogues orientés vers une tâche, nous nous concentrons sur le développement de modèles informatiques pour étudier les rôles des disfluences dans la dynamique auditeur-locuteur. Nous étudions spécifiquement les disfluences dans le contexte de l'alignement verbal, c'est-à-dire l'alignement des expressions lexicales des interlocuteurs et leurs roles dans l'alignement comportemental, un nouveau contexte d'alignement que nous proposons de définir comme le moment où les instructions données par un interlocuteur sont suivis d'une action par un autre interlocuteur. Nous examinons également comment les disfluences dans les contextes d'alignement locaux peuvent être associées à des phénomènes au niveau du discours, tels que la réussite de la tâche. Nous considérons cette thèse comme l'un des premiers travaux, qui pourrait aboutir à intégration des disfluences dans les contextes d'alignement local.},
	urldate = {2022-07-21},
	school = {Institut polytechnique de Paris},
	author = {Dinkar, Tanvi},
	collaborator = {Clavel, Chloé and Vasilescu, Ioana Gabriela},
	month = jan,
	year = {2022},
}

@article{kontogiorgos_mutual_2022,
	title = {Mutual {Understanding} in {Situated} {Interactions} with {Conversational} {User} {Interfaces} : {Theory}, {Studies}, and {Computation}},
	shorttitle = {Mutual {Understanding} in {Situated} {Interactions} with {Conversational} {User} {Interfaces}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-308927},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2022-07-21},
	author = {Kontogiorgos, Dimosthenis},
	year = {2022},
	note = {Publisher: KTH Royal Institute of Technology},
}

@article{nissim_fair_2020,
	title = {Fair {Is} {Better} than {Sensational}: {Man} {Is} to {Doctor} as {Woman} {Is} to {Doctor}},
	volume = {46},
	issn = {0891-2017},
	shorttitle = {Fair {Is} {Better} than {Sensational}},
	url = {https://doi.org/10.1162/coli_a_00379},
	doi = {10.1162/coli_a_00379},
	abstract = {Analogies such as man is to king as woman is to X are often used
to illustrate the amazing power of word embeddings. Concurrently, they have also
been used to expose how strongly human biases are encoded in vector spaces
trained on natural language, with examples like man is to computer
programmer as woman is to homemaker. Recent work has shown that
analogies are in fact not an accurate diagnostic for bias, but this does not
mean that they are not used anymore, or that their legacy is fading. Instead of
focusing on the intrinsic problems of the analogy task as a bias detection tool,
we discuss a series of issues involving implementation as well as subjective
choices that might have yielded a distorted picture of bias in word embeddings.
We stand by the truth that human biases are present in word
embeddings, and, of course, the need to address them. But analogies are not an
accurate tool to do so, and the way they have been most often used has
exacerbated some possibly non-existing biases and perhaps hidden others. Because
they are still widely popular, and some of them have become classics within and
outside the NLP community, we deem it important to provide a series of
clarifications that should put well-known, and potentially new analogies, into
the right perspective.},
	number = {2},
	urldate = {2022-07-21},
	journal = {Computational Linguistics},
	author = {Nissim, Malvina and van Noord, Rik and van der Goot, Rob},
	month = jun,
	year = {2020},
	pages = {487--497},
}

@incollection{sidnell_storytelling_2013,
	address = {Malden, MA},
	title = {Storytelling in conversation},
	isbn = {978-1-4443-3208-7},
	booktitle = {The handbook of conversation analysis},
	publisher = {Blackwell Publishers},
	author = {Mandelbaum, Jenny},
	editor = {Sidnell, Jack and Stivers, Tanya},
	year = {2013},
	pages = {492--507},
}

@incollection{drew_how_2014,
	address = {Amsterdam},
	title = {How to do things with requests: {Request} sequences at the family dinner table*},
	volume = {26},
	isbn = {978 90 272 2636 5, 9789027269287},
	shorttitle = {How to do things with requests},
	url = {https://benjamins.com/catalog/slsi.26.09man},
	abstract = {Requests for food and other things at the family dinner table generally run off smoothly, without “breaking the surface” of interaction. That is, in an environment of multiple concurrent involvements (Lerner and Raymond, 2014), requesting and fulfilling requests for food or other things usually only momentarily suspends or delays the progressivity of other concurrent activities.This conversation analytic study examines requests in which interactants do “more” than just requesting. Drawing on videotaped holiday dinners of nine families in the Northeastern United States, 91 requests (principally for food) were collected. I show how at each position in the unfolding of a request sequence, opportunities may be taken to implement some other action. That is, requests may be formulated in such a way as to do more than requesting (e.g. they may enact impatience, implement a complaint about the requested item, or treat an interlocutor as noncompliant). Responses to requests may be produced in such a way as to do more than fulfilling the request (e.g. they may enact attentiveness, critique being asked for the item, teach proper norms of conduct, or even perform a “tit for tat”). In third position also, appreciations or acknowledgements of fulfilled requests may do more than appreciating or acknowledging (e.g. they may be designed to acknowledge an impropriety in the fulfilling of the request). Findings indicate how the formulation, fulfillment and acknowledgement of requests may provide a structure through which norms of food consumption and distribution, family relationships and personhood may be enacted and negotiated.},
	language = {en},
	urldate = {2015-02-27},
	booktitle = {Studies in {Language} and {Social} {Interaction}},
	publisher = {John Benjamins Publishing Company},
	author = {Mandelbaum, Jenny},
	editor = {Drew, Paul and Couper-Kuhlen, Elizabeth},
	year = {2014},
	pages = {215--242},
}

@article{mandelbaum_assigning_1993,
	title = {Assigning responsibility in conversational storytelling: {The} interactional construction of reality},
	volume = {13},
	issn = {0165-4888},
	shorttitle = {Assigning responsibility in conversational storytelling},
	url = {http://www.reference-global.com/doi/abs/10.1515/text.1.1993.13.2.247},
	doi = {10.1515/text.1.1993.13.2.247},
	number = {2},
	urldate = {2010-03-10},
	journal = {Text - Interdisciplinary Journal for the Study of Discourse},
	author = {Mandelbaum, Jenny},
	month = jan,
	year = {1993},
	pages = {247--266},
}

@article{mandelbaum_beyond_1990,
	title = {Beyond {Mundane} {Reason}: {Conversation} {Analysis} {And} {Context}},
	volume = {24},
	issn = {08351813},
	shorttitle = {Beyond {Mundane} {Reason}},
	doi = {10.1080/08351819009389346},
	abstract = {In this article, the author re-examines the posture of conversation analysis toward context, and shows that conversation analysis may supply details of cultural context rarely provided in ethnography. Conversation analysts have sometimes been taken to task for apparently choosing not to deal with the "context" of the conversational activities they examine. Context provides fundamental building blocks in both participants' and researchers' understanding of social life. However, ethnographers and conversation analysts disagree on how the term "context" is to be used. Conversation analysts usually takes context to be intrinsic to (and created in) interaction. A system for conversation that is both context-sensitive and context-free is essentially and intrinsically tied to humans' cultures and their enterprises. Conversation analysts agree with the suggestion of an anthropologist, Michael Moerman, that analysis must be "culturally contexted" but they differ from Moerman in focusing the work within talk-intrinsic threads of context. The article author suggests various strands of talk-intrinsic approaches to context.},
	journal = {Research on Language \& Social Interaction},
	author = {Mandelbaum, Jenny},
	month = jan,
	year = {1990},
	pages = {333--350},
}

@book{schenkein_studies_1978,
	address = {New York},
	series = {Language, thought, and culture},
	title = {Studies in the organization of conversational interaction},
	isbn = {978-0-12-623550-0},
	publisher = {Academic Press},
	editor = {Schenkein, Jim},
	year = {1978},
}

@incollection{schenkein_achievement_1978,
	address = {New York},
	series = {Language, thought, and culture},
	title = {On the achievement of a series of stories},
	isbn = {978-0-12-623550-0},
	booktitle = {Studies in the organization of conversational interaction},
	publisher = {Academic Press},
	author = {Ryave, Alan L.},
	editor = {Schenkein, Jim},
	year = {1978},
	pages = {113--132},
}

@article{theobald_pursuit_2015,
	title = {In pursuit of some appreciation: assessment and group membership in children’s second stories},
	volume = {35},
	issn = {1860-7349},
	shorttitle = {In pursuit of some appreciation},
	url = {https://www.degruyter.com/document/doi/10.1515/text-2015-0006/html},
	doi = {10.1515/text-2015-0006},
	abstract = {Group membership is central to social interaction. Within peer groups, social hierarchies and affiliations are matters to which members seriously attend (Corsaro 2014). Studies of peer groups highlight how status is achieved through oppositional actions. This paper examines the way in which competition and collaboration in a children’s peer group accomplishes status during the production and management of “second stories” (Sacks 1992). We present analysis of the interaction of young boys in a preparatory year playground who are engaged in a single instance of storytelling “rounds.” Analysis highlights the pivotal role of members’ contributions, assessments, and receipts in a series of second stories that enact a simultaneously competitive and collaborative local order.},
	language = {en},
	number = {3},
	urldate = {2022-07-19},
	journal = {Text \& Talk},
	author = {Theobald, Maryanne and Reynolds, Edward},
	month = may,
	year = {2015},
	note = {Publisher: De Gruyter Mouton},
	pages = {407--430},
}

@article{arminen_second_2004,
	title = {Second stories: the salience of interpersonal communication for mutual help in {Alcoholics} {Anonymous}},
	volume = {36},
	issn = {0378-2166},
	shorttitle = {Second stories},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216603001334},
	doi = {10.1016/j.pragma.2003.07.001},
	abstract = {Second stories are stories told in a series in which later stories are designed to achieve a recognizable similarity with the first (or previous) story. This article explores therapeutic uses of second stories in meetings of Alcoholics Anonymous (AA). AA meetings are organized around a series of lengthy personal monologues. Overall, a second story is a procedure to display the speaker's analysis and understanding of the first story. In AA, second stories gain therapeutic relevance. They are the method that members use to display alignment and identification with previous speakers. Further, they are not only a procedure to engage in reciprocal revelations of personal problems, but also a means to transvaluate experiences. Systematically, second stories focus on problems related in the first stories, and then recontextualize and reinterpret these problems to provide resolutions. Thus, in mutual help second stories are a resource for empowerment.},
	language = {en},
	number = {2},
	urldate = {2022-07-19},
	journal = {Journal of Pragmatics},
	author = {Arminen, Ilkka},
	month = feb,
	year = {2004},
	pages = {319--347},
}

@article{lerner_place_1996,
	title = {On the place of linguistic resources in the organization of talk-in interaction: '{Second} person' reference in multi-party conversation},
	volume = {6},
	url = {http://elanguage.net/journals/pragmatics/article/download/235/170},
	urldate = {2012-06-20},
	journal = {Pragmatics},
	author = {Lerner, Gene H.},
	year = {1996},
	pages = {3--281},
}

@article{georgakopoulou_thinking_2006,
	title = {Thinking big with small stories in narrative and identity analysis},
	volume = {16},
	doi = {10.1075/ni.16.1.16geo},
	abstract = {Narrative research is frequently described as a rich and diverse enterprise, yet the kinds of narrative data that it bases itself on present a striking consensus: they are autobiographical in kind (i.e., about non-shared, personal experience, single past events). In this paper, I put forth a case for under-represented narrative data which I collectively call (following Bamberg 2004a, b; also Georgakopoulou \& Bamberg, 2005) “small stories” (partly literally, partly metaphorically). My aim is to flesh small stories out, to urge for the sort of systematic research that will establish connections between their interactional features and their sites of engagement and finally to consider the implications of their inclusion in narrative research for identity analysis (as the main agenda of much of narrative research). I will thus propose small stories research as a “new” narrative turn that can provide a needed meeting point for narrative analysis and narrative inquiry.},
	number = {1},
	journal = {Narrative Inquiry},
	author = {Georgakopoulou, Alexandra},
	month = jan,
	year = {2006},
	pages = {122--130},
}

@article{bamberg_small_2008,
	title = {Small stories as a new perspective in narrative and identity analysis},
	volume = {28},
	issn = {1860-7349},
	url = {https://www.degruyter.com/view/j/text.2008.28.issue-3/text.2008.018/text.2008.018.xml},
	doi = {10.1515/TEXT.2008.018},
	abstract = {In this article, we depart from our recent work on ‘small stories’, which we propose as an antidote to canonical narrative studies, and we advance our argumentation by sketching out a five-step analytical operation for tapping into small stories as sites of identity work. These steps grow out of the model of positioning (as put forward by Bamberg 1997, and elaborated in Bamberg 2004a; cf. also Georgakopoulou 2000) that succeeds in navigating between the two extreme ends of fine-grained micro analysis and macro accounts. We will work with positioning in the close analysis of a small story event (as part of a moderated group discussion involving ten-year-old boys in an American school) in which we will show how the teller's announcement of the story, the subsequent withdrawal, and the pre-telling negotiation with the interlocutors are as integral parts of our analysis as the actual telling. We will also demonstrate how viewing story content as a function of interactional engagement opens up new insights into identity constructions of sameness in the face of adversative conditions and constant change.},
	number = {3},
	urldate = {2016-04-24},
	journal = {Text \& Talk - An Interdisciplinary Journal of Language, Discourse Communication Studies},
	author = {Bamberg, Michael and Georgakopoulou, Alexandra},
	year = {2008},
	pages = {377--396},
}

@article{bamberg_stories_2006,
	title = {Stories: {Big} or small: {Why} do we care?},
	volume = {16},
	shorttitle = {Stories},
	doi = {10.1075/ni.16.1.18bam},
	abstract = {This article is a pledge that we actually should care about the differences between what has recently been coined ‘small’ versus ‘big’ stories because they represent very different approaches to narrative inquiry. In the attempt to pull other contributions of this special issue into the debate between small and big, I argue that the small story approach is able to theoretically and methodologically enrich traditional narrative inquiry — not in a peaceful, complementary fashion, but by more radically re-positioning big story approaches as grounded in dialogical/discursive approaches such as small story research.},
	number = {1},
	journal = {Narrative Inquiry},
	author = {Bamberg, Michael},
	month = jan,
	year = {2006},
	pages = {139--147},
}

@incollection{de_fina_small_2015,
	address = {Chichester, West Sussex ; Malden, MA},
	title = {Small {Stories} {Research}: {Methods} – {Analysis} – {Outreach}},
	isbn = {978-1-118-45815-0},
	booktitle = {The handbook of narrative analysis},
	publisher = {John Wiley \& Sons Inc},
	author = {Georgakopoulou, Alexandra},
	editor = {De Fina, Anna and Georgakopoulou, Alexandra},
	year = {2015},
	pages = {255--272},
}

@article{riedl_interactive_2013,
	title = {Interactive {Narrative}: {An} {Intelligent} {Systems} {Approach}},
	volume = {34},
	copyright = {Copyright (c)},
	issn = {2371-9621},
	shorttitle = {Interactive {Narrative}},
	url = {https://ojs.aaai.org/index.php/aimagazine/article/view/2449},
	doi = {10.1609/aimag.v34i1.2449},
	abstract = {Interactive narrative is a form of digital interactive experience in which users create or influence a dramatic storyline through their actions. The goal of an interactive narrative system is to immerse the user in a virtual world such that he or she believes that they are an integral part of an unfolding story and that their actions can significantly alter the direction and/or outcome of the story.In this article we review the ways in which artificial intelligence can be brought to bear on the creation of interactive narrative systems. We lay out the landscape of about 20 years of interactive narrative research and explore the successes as well as open research questions pertaining to the novel use of computational narrative intelligence in the pursuit of entertainment, education, and training.},
	language = {en},
	number = {1},
	urldate = {2022-07-19},
	journal = {AI Magazine},
	author = {Riedl, Mark Owen and Bulitko, Vadim},
	year = {2013},
	note = {Number: 1},
	pages = {67--67},
}

@inproceedings{riedl_managing_2003,
	address = {New York, NY, USA},
	series = {{AAMAS} '03},
	title = {Managing interaction between users and agents in a multi-agent storytelling environment},
	isbn = {978-1-58113-683-8},
	url = {https://doi.org/10.1145/860575.860694},
	doi = {10.1145/860575.860694},
	abstract = {This paper describes an approach for managing the interaction of human users with computer-controlled agents in an interactive narrative-oriented virtual environment. In these kinds of systems, the freedom of the user to perform whatever action she desires must be balanced with the preservation of the storyline used to control the system's characters. We describe a technique, narrative mediation, that exploits a plan-based model of narrative structure to manage and respond to users' actions inside a virtual world. We define two general classes of response to situations where users execute actions that interfere with story structure: accommodation and intervention. Finally, we specify an architecture that uses these definitions to monitor and automatically characterize user actions, and to compute and implement responses to unanticipated activity. The approach effectively integrates user action and system response into the unfolding narrative, providing for the balance between a user's sense of control within the story world and the user's sense of coherence of the overall narrative.},
	urldate = {2022-07-19},
	booktitle = {Proceedings of the second international joint conference on {Autonomous} agents and multiagent systems},
	publisher = {Association for Computing Machinery},
	author = {Riedl, Mark and Saretto, C. J. and Young, R. Michael},
	month = jul,
	year = {2003},
	pages = {741--748},
}

@article{riedl_narrative_2010,
	title = {Narrative {Planning}: {Balancing} {Plot} and {Character}},
	volume = {39},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	shorttitle = {Narrative {Planning}},
	url = {https://www.jair.org/index.php/jair/article/view/10669},
	doi = {10.1613/jair.2989},
	abstract = {Narrative, and in particular storytelling, is an important part of the human experience.  Consequently, computational systems that can reason about narrative can be more effective communicators, entertainers, educators, and trainers.  One of the central challenges in computational narrative reasoning is narrative generation, the automated creation of meaningful event sequences.  There are many factors -- logical and aesthetic -- that contribute to the success of a narrative artifact.  Central to this success is its understandability.  We argue that the following two attributes of narratives are universal: (a) the logical causal progression of plot, and (b) character believability.  Character believability is the perception by the audience that the actions performed by characters do not negatively impact the audience's suspension of disbelief.  Specifically, characters must be perceived by the audience to be intentional agents.  In this article, we explore the use of refinement search as a technique for solving the narrative generation problem -- to find a sound and believable sequence of character actions that transforms an initial world state into a world state in which goal propositions hold. We describe a novel refinement search planning algorithm -- the Intent-based Partial Order Causal Link (IPOCL) planner -- that, in addition to creating causally sound plot progression, reasons about character intentionality by identifying possible character goals that explain their actions and creating plan structures that explain why those characters commit to their goals. We present the results of an empirical evaluation that demonstrates that narrative plans generated by the IPOCL algorithm support audience comprehension of character intentions better than plans generated by conventional partial-order planners.},
	language = {en},
	urldate = {2022-07-19},
	journal = {Journal of Artificial Intelligence Research},
	author = {Riedl, M. O. and Young, R. M.},
	month = sep,
	year = {2010},
	pages = {217--268},
}

@article{labov_narrative_1997,
	title = {Narrative analysis: {Oral} versions of personal experience},
	volume = {7},
	shorttitle = {Narrative analysis},
	url = {http://www.postgradolinguistica.ucv.cl/dev/documentos/biblioteca_files/1.doc},
	urldate = {2013-03-22},
	journal = {Journal of narrative and life history},
	author = {Labov, William and Waletzky, Joshua},
	year = {1997},
	pages = {3--38},
}

@incollection{labov_narrative_1967,
	address = {Seattle},
	title = {Narrative analysis: {Oral} versions of personal experience},
	shorttitle = {Narrative analysis},
	booktitle = {Essays on the verbal and visual arts: {Proceedings} of the 1966 {Annual} {Spring} {Meeting} of the {American} {Ethnological} {Society}},
	publisher = {University of Washington Press},
	author = {Labov, William and Waletzky, Joshua},
	editor = {Helm, J.},
	year = {1967},
	pages = {12--44},
}

@article{kent_imperative_2016,
	title = {Imperative {Directives}: {Orientations} to {Accountability}},
	volume = {49},
	issn = {0835-1813},
	shorttitle = {Imperative {Directives}},
	url = {https://doi.org/10.1080/08351813.2016.1201737},
	doi = {10.1080/08351813.2016.1201737},
	abstract = {Our analysis proceeds from the question that if grammar alone is insufficient to identify the action of an imperative (e.g., offering, directing, warning, begging, etc.), how can interlocutors come to recognize the specific action being performed by a given imperative? We argue that imperative directives that occur after the directed action could have first been relevantly performed explicitly to direct the actions of the recipient and tacitly treat the absence of the action as a failure for which the recipient is accountable. The tacit nature of the accountability orientation enables both parties to focus on restoring progressivity to the directed course of action rather than topicalizing a transgression. Data are from everyday interactions in British and American English.},
	number = {3},
	urldate = {2022-07-13},
	journal = {Research on Language and Social Interaction},
	author = {Kent, Alexandra and Kendrick, Kobin H.},
	month = jul,
	year = {2016},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2016.1201737},
	pages = {272--288},
}

@inproceedings{core1997coding,
	title = {Coding dialogs with the {DAMSL} annotation scheme},
	volume = {56},
	booktitle = {{AAAI} fall symposium on communicative action in humans and machines},
	author = {Core, Mark G and Allen, James},
	year = {1997},
	note = {tex.organization: Boston, MA},
	pages = {28--35},
}

@article{di_maro_computational_2021,
	title = {Computational {Grounding}: {An} {Overview} of {Common} {Ground} {Applications} in {Conversational} {Agents}},
	volume = {7},
	copyright = {IJCoL is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License},
	issn = {2499-4553},
	shorttitle = {Computational {Grounding}},
	url = {https://journals.openedition.org/ijcol/890},
	doi = {10.4000/ijcol.890},
	abstract = {This work reports on the literature on grounding in conversational agents, as one of the pragmatic aspects adopted to ensure a better communicative efficiency in dialogue systems. The paper starts with a general description of the theory of grounding. As far as its computational implications are concerned, grounding phenomena are firstly framed in the common grounding processes described in terms of grounding acts. Secondly, they are considered in the argumentation-related framework within which already grounded information are processed. Open issues and application gaps are finally highlighted.},
	language = {en},
	number = {1 {\textbar} 2},
	urldate = {2022-03-08},
	journal = {IJCoL. Italian Journal of Computational Linguistics},
	author = {Di Maro, Maria},
	month = dec,
	year = {2021},
	note = {Number: 1 {\textbar} 2
Publisher: Accademia University Press},
	pages = {133--156},
}

@patent{hosn_measuring_2020,
	title = {Measuring mutual understanding in human-computer conversation},
	url = {https://patents.google.com/patent/US10789534B2/en},
	nationality = {US},
	language = {en},
	assignee = {International Business Machines Corp},
	number = {US10789534B2},
	urldate = {2022-07-15},
	author = {Hosn, Rafah A. and Moore, Robert J.},
	month = sep,
	year = {2020},
}

@article{araujo_living_2018,
	title = {Living up to the chatbot hype: {The} influence of anthropomorphic design cues and communicative agency framing on conversational agent and company perceptions},
	volume = {85},
	issn = {0747-5632},
	shorttitle = {Living up to the chatbot hype},
	url = {https://www.sciencedirect.com/science/article/pii/S0747563218301560},
	doi = {10.1016/j.chb.2018.03.051},
	abstract = {Disembodied conversational agents in the form of chatbots are increasingly becoming a reality on social media and messaging applications, and are a particularly pressing topic for service encounters with companies. Adopting an experimental design with actual chatbots powered with current technology, this study explores the extent to which human-like cues such as language style and name, and the framing used to introduce the chatbot to the consumer can influence perceptions about social presence as well as mindful and mindless anthropomorphism. Moreover, this study investigates the relevance of anthropomorphism and social presence to important company-related outcomes, such as attitudes, satisfaction and the emotional connection that consumers feel with the company after interacting with the chatbot.},
	language = {en},
	urldate = {2021-10-11},
	journal = {Computers in Human Behavior},
	author = {Araujo, Theo},
	month = aug,
	year = {2018},
	pages = {183--189},
}

@inproceedings{webson_prompt-based_2022,
	address = {Seattle, United States},
	title = {Do {Prompt}-{Based} {Models} {Really} {Understand} the {Meaning} of {Their} {Prompts}?},
	url = {https://aclanthology.org/2022.naacl-main.167},
	abstract = {Recently, a boom of papers has shown extraordinary progress in zero-shot and few-shot learning with various prompt-based models. It is commonly argued that prompts help models to learn faster in the same way that humans learn faster when provided with task instructions expressed in natural language. In this study, we experiment with over 30 prompts manually written for natural language inference (NLI). We find that models can learn just as fast with many prompts that are intentionally irrelevant or even pathologically misleading as they do with instructively “good” prompts. Further, such patterns hold even for models as large as 175 billion parameters (Brown et al., 2020) as well as the recently proposed instruction-tuned models which are trained on hundreds of prompts (Sanh et al., 2021). That is, instruction-tuned models often produce good predictions with irrelevant and misleading prompts even at zero shots. In sum, notwithstanding prompt-based models' impressive improvement, we find evidence of serious limitations that question the degree to which such improvement is derived from models understanding task instructions in ways analogous to humans' use of task instructions.},
	urldate = {2022-07-12},
	booktitle = {Proceedings of the 2022 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Webson, Albert and Pavlick, Ellie},
	month = jul,
	year = {2022},
	pages = {2300--2344},
}

@book{enfield_consequences_2022,
	address = {Cambridge, MA, USA},
	title = {Consequences of {Language}: {From} {Primary} to {Enhanced} {Intersubjectivity}},
	isbn = {978-0-262-54486-3},
	shorttitle = {Consequences of {Language}},
	abstract = {What is it about humans that makes language possible, and what is it about language that makes us human?},
	language = {en},
	publisher = {MIT Press},
	author = {Enfield, N. J. and Sidnell, Jack},
	month = nov,
	year = {2022},
}

@book{enfield_concept_2017,
	address = {Cambridge},
	title = {The {Concept} of {Action}},
	isbn = {978-1-139-02592-8},
	publisher = {Cambridge University Press},
	author = {Enfield, N. J. and Sidnell, Jack},
	year = {2017},
	doi = {10.1017/9781139025928},
}

@article{enfield_how_2017,
	title = {How to distinguish a wink from a twitch},
	volume = {7},
	copyright = {Copyright (c) 2017 N. J. Enfield, Jack Sidnell},
	issn = {2049-1115},
	url = {https://www.haujournal.org/index.php/hau/article/view/hau7.2.038},
	language = {en},
	number = {2},
	urldate = {2017-11-14},
	journal = {HAU: Journal of Ethnographic Theory},
	author = {Enfield, N. J. and Sidnell, Jack},
	month = nov,
	year = {2017},
	pages = {457--465},
}

@article{enfield_action_2017,
	title = {Action: {From} flexibility to accountability, across agents and scales, through contexts and time},
	volume = {7},
	copyright = {Copyright (c) 2017 N. J. Enfield, Jack Sidnell},
	issn = {2049-1115},
	url = {https://www.haujournal.org/index.php/hau/article/view/hau7.2.036},
	doi = {10.14318/hau7.2.036},
	abstract = {Response to comments on Enfield, N. J., and Jack Sidnell. 2017. The concept of action. Cambridge: Cambridge University Press.},
	language = {en},
	number = {2},
	urldate = {2017-11-14},
	journal = {HAU: Journal of Ethnographic Theory},
	author = {Enfield, N. J. and Sidnell, Jack},
	month = nov,
	year = {2017},
	pages = {451--455},
}

@article{enfield_concept_2017-1,
	title = {On the concept of action in the study of interaction},
	volume = {19},
	issn = {1461-4456},
	url = {http://journals.sagepub.com/doi/abs/10.1177/1461445617730235},
	doi = {10.1177/1461445617730235},
	abstract = {What is the relation between words and action? How does a person decide, based on what someone is saying, what would be an appropriate response? We argue that (1) every move combines independent semiotic features, to be interpreted under an assumption that social behavior is goal directed; (2) responding to actions is not equivalent to describing them; and (3) describing actions invokes rights and duties for which people are explicitly accountable. We conclude that interaction does not involve a ‘binning’ procedure in which the stream of conduct is sorted into discrete action types. Our argument is grounded in data from recordings of talk-in-interaction.},
	language = {en},
	number = {5},
	urldate = {2017-09-30},
	journal = {Discourse Studies},
	author = {Enfield, N. J. and Sidnell, Jack},
	month = oct,
	year = {2017},
	pages = {515--535},
}

@incollection{dor_language_2014,
	address = {Oxford},
	title = {Language presupposes an enchronic infrastructure for social interaction},
	booktitle = {The {Social} {Origins} of {Language}},
	publisher = {Oxford University Press},
	author = {Enfield, N. J. and Sidnell, Jack},
	editor = {Dor, Daniel and Knight, Chris and Lewis, Jerome},
	year = {2014},
	pages = {92--104},
}

@article{berger_interactional_2017,
	title = {The interactional achievement of tellability: a study of story-openings},
	volume = {XXII},
	issn = {1386-1204},
	shorttitle = {The interactional achievement of tellability},
	url = {https://www.cairn.info/revue-francaise-de-linguistique-appliquee-2017-2-page-89.html},
	language = {fr},
	number = {2},
	urldate = {2017-11-28},
	journal = {Revue française de linguistique appliquée},
	author = {Berger, Evelyne},
	month = nov,
	year = {2017},
	pages = {89--107},
}

@article{jefferson_poetics_1996,
	title = {On the {Poetics} of ordinary talk},
	volume = {16},
	number = {1},
	journal = {Text and Performance Quarterly},
	author = {Jefferson, Gail},
	year = {1996},
	pages = {1--61},
}

@incollection{sidnell_turn_2013,
	address = {Malden, MA},
	title = {Turn {Design}},
	isbn = {978-1-4443-3208-7},
	booktitle = {The handbook of conversation analysis},
	publisher = {Blackwell Publishers},
	author = {Drew, Paul},
	editor = {Sidnell, Jack and Stivers, Tanya},
	year = {2013},
	pages = {131--149},
}

@book{wong_storytelling_2021,
	address = {New York, NY},
	series = {{ESL} \& applied linguistics professional series},
	title = {Storytelling in multilingual interaction: a conversation analysis perspective},
	isbn = {978-0-367-13921-6 978-0-367-13924-7},
	shorttitle = {Storytelling in multilingual interaction},
	abstract = {"Integral to the tapestry of social interaction, storytelling is the focus of interest for scholars from a diverse range of academic disciplines. This volume combines the study of Conversation Analysis (CA) with storytelling in multilingual contexts to examine how multilingual speakers converse and manage various aspects of storytelling, and how they accomplish a wide range of actions through storytelling in classroom and everyday settings. An original, book-length endeavour devoted exclusively to storytelling in multilingual contexts, this book contributes to broadening the scope of the foundational conversation analytic literature on storytelling and to further specifying the nature of second language (L2) interactional competence. Designed for pre-service and in-service second or foreign language teachers, students of applied linguistics, as well as scholars interested in storytelling, this volume explores the cross-linguistic nature of generic interactional practices, sheds light on the nature of translanguaging and learner language, and provides insights into teacher practices on managing classroom storytelling"--},
	publisher = {Routledge},
	editor = {Wong, Jean and Waring, Hansun Zhang},
	year = {2021},
}

@article{lerner_reference_2012,
	title = {Reference {Recalibration} {Repairs}: {Adjusting} the {Precision} of {Formulations} for the {Task} at {Hand}},
	volume = {45},
	issn = {0835-1813},
	shorttitle = {Reference {Recalibration} {Repairs}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/08351813.2012.674190},
	doi = {10.1080/08351813.2012.674190},
	abstract = {This report examines what is involved when a speaker overtly selects one formulation over another by employing a repair operation that reformulates a reference in a way that adjusts or recalibrates it, rather than abandons the original referent altogether. Focusing primarily on references to persons, we show that, beyond the narrowing of a reference—increasing its precision—that results in an improved fit between a person reference and other components of a turn at talk, these reference recalibration repairs can be used to do such things as meeting the requirements of a story's telling, upgrading the credibility of an information source, and justifying a rejection. This ties speakers' overt concern with calibrating a categorical reference to the formation of action in their turn at talk. By contrast, we then show how broadening a reference—decreasing its precision—can be used as a method for displaying uncertainty and, thereby, recalibrating a reference to fit the manifest knowledge state of the speaker (or a recipient).},
	number = {2},
	urldate = {2012-07-13},
	journal = {Research on Language \& Social Interaction},
	author = {Lerner, Gene H. and Bolden, Galina B. and Hepburn, Alexa and Mandelbaum, Jenny},
	year = {2012},
	pages = {191--212},
}

@article{lerner_place_2004,
	title = {On the {Place} of {Linguistic} {Resources} in the {Organization} of {Talk}-in-{Interaction}: {Grammar} as {Action} in {Prompting} a {Speaker} to {Elaborate}},
	volume = {37},
	issn = {0835-1813},
	shorttitle = {On the {Place} of {Linguistic} {Resources} in the {Organization} of {Talk}-in-{Interaction}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi3702_3},
	doi = {10.1207/s15327973rlsi3702_3},
	abstract = {Specific parts of grammatical structure can be employed by speakers to accomplish specifiable actions in talk-in-interaction. In this article, I describe the interactional use of "parts of speech" ordinarily used by individual speakers to connect elements within single turn-constructional units. The items employed for these held-in-common grammatical practices can also be deployed as stand-alone contributions that by their very incompleteness prompt a prior speaker to add another increment to their turn. As such, this constitutes a recipient-administered practice for expanding a turn at talk. I show that this usage constitutes another (previously undescribed) form of other-initiated repair that is designed to prompt a prior speaker to add a type-specific element found missing from an otherwise completed turn.},
	number = {2},
	urldate = {2012-06-20},
	journal = {Research on Language \& Social Interaction},
	author = {Lerner, Gene H.},
	year = {2004},
	pages = {151--184},
}

@book{lerner_conversation_2004,
	address = {Amsterdam ; Philadelphia},
	series = {Pragmatics \& beyond},
	title = {Conversation {Analysis}: {Studies} from the {First} {Generation}},
	isbn = {90-272-5367-6},
	shorttitle = {Conversation {Analysis}},
	number = {new ser. v. 125},
	publisher = {John Benjamins Pub},
	editor = {Lerner, Gene H.},
	year = {2004},
}

@article{lerner_finding_1996,
	title = {Finding "{Face}" in the {Preference} {Structures} of {Talk}-in-{Interaction}},
	volume = {59},
	issn = {0190-2725},
	url = {http://www.jstor.org/stable/2787073},
	doi = {10.2307/2787073},
	abstract = {This article connects the concept of "face" to interactionally characterizable locations in conversations and to a specific speaking practice used there. I consider the relevance of the "self/other" distinction for the organization of some action sequences in order to locate face concerns in interactional terms. In conversation, next speakers ordinarily begin speaking at or near a place where the current speaker could be finished. Occasionally, however, participants do not wait for the current speaker to finish, but complete the current turn themselves. One systematic basis for this relaxation of turn-taking practices is found in a preference organization for alternative actions in conversation. The anticipatory completion of a speaking turn by another speaker can be used to preempt an emerging dispreferred action and change it into the alternative preferred action. This preference structure includes a preference for agreement over disagreement, a preference for self-correction over other-correction, and a preference for offers over requests. A recipient's anticipatory completion of an ongoing speaking turn is one conversational practice that makes possible a preference relationship between asymmetrical (i.e., differently valued) action types, and furnishes a basis for the recognizability of face concerns.},
	number = {4},
	urldate = {2012-06-20},
	journal = {Social Psychology Quarterly},
	author = {Lerner, Gene H.},
	month = dec,
	year = {1996},
	note = {ArticleType: research-article / Full publication date: Dec., 1996 / Copyright © 1996 American Sociological Association},
	pages = {303--321},
}

@article{lerner_selecting_2003,
	title = {Selecting next speaker: {The} context-sensitive operation of a context-free organization},
	volume = {32},
	shorttitle = {Selecting next speaker},
	doi = {10.1017/S004740450332202X},
	number = {02},
	journal = {Language in Society},
	author = {Lerner, Gene H.},
	year = {2003},
	pages = {177--201},
}

@article{lerner_assisted_1992,
	title = {Assisted storytelling: {Deploying} shared knowledge as a practical matter},
	volume = {15},
	issn = {0162-0436},
	shorttitle = {Assisted storytelling},
	url = {http://www.springerlink.com/content/h20j070t52113v71/abstract/},
	doi = {10.1007/BF00990328},
	abstract = {Previous studies have shown that storytelling in conversation consists of more than a speaker producing an extended narrative. Stories issue from the concerted action of storyteller and story recipients. The current study identifies features of storytelling found when some participants share knowledge of the source events for the story. Practices for assisting story initiation are described. Through these practices participants arrange who will deliver the story and concomitantly establish the other participant as a story consociate and thereby as a possible co-teller. Practices for assisting the delivery of a story are then described. A set of story entry devices is identified, and these devices are shown to provide occasions for changing tellers in the course of a story. Repeated use of these devices can provided repeated opportunities for re-arranging who will continue the story, thus producing the possibility of a collaboratively told story. The report ends with a discussion of assisted story reception. Assisted storytelling is shown to be a systematic elaboration of storytelling organization with opportunities for a story consociate to participate in both the delivery and reception of the story from the story preface, throughout the story, and into the final reception by story recipients.},
	number = {3},
	urldate = {2012-06-20},
	journal = {Qualitative Sociology},
	author = {Lerner, Gene H.},
	year = {1992},
	pages = {247--271},
}

@article{van_burgsteden_going_2022,
	title = {Going against the interactional tide: {The} accomplishment of dialogic moments from a conversation analytic perspective},
	issn = {1461-4456},
	shorttitle = {Going against the interactional tide},
	url = {https://doi.org/10.1177/14614456221099167},
	doi = {10.1177/14614456221099167},
	abstract = {This article addresses a vital concern in current society by showing what participants themselves may treat as ways to transcend their differences. Actors’ shared understanding has been of longstanding interest across the social sciences. Conversation analysis (CA) treats the procedural infrastructure of interaction as the basis for participants to manage intersubjectivity. The field of dialogue studies has made occasions in which people transform their relationship by discussing their differences, central to their research project, and called them “dialogic moments.” This study draws on CA to investigate “dialogic moments,” but now through the eyes of participants themselves. Using single-case analysis, we argue that such moments require participants to go against normative orientations in talk promoting social solidarity and progressivity, by soliciting differences to understand and transcend them. This “going against the interactional tide” may explain both why dialogue is difficult to achieve and why it is appreciated by participants as dialogue.},
	language = {en},
	urldate = {2022-07-19},
	journal = {Discourse Studies},
	author = {van Burgsteden, Lotte and te Molder, Hedwig and Raymond, Geoffrey},
	month = jun,
	year = {2022},
	note = {Publisher: SAGE Publications},
	pages = {14614456221099167},
}

@book{escalera_neurips_2020,
	address = {Cham},
	series = {The {Springer} {Series} on {Challenges} in {Machine} {Learning}},
	title = {The {NeurIPS} '18 {Competition}: {From} {Machine} {Learning} to {Intelligent} {Conversations}},
	isbn = {978-3-030-29134-1 978-3-030-29135-8},
	shorttitle = {The {NeurIPS} '18 {Competition}},
	url = {http://link.springer.com/10.1007/978-3-030-29135-8},
	language = {en},
	urldate = {2022-07-18},
	publisher = {Springer International Publishing},
	editor = {Escalera, Sergio and Herbrich, Ralf},
	year = {2020},
	doi = {10.1007/978-3-030-29135-8},
}

@inproceedings{dinan_second_2020,
	address = {Cham},
	series = {The {Springer} {Series} on {Challenges} in {Machine} {Learning}},
	title = {The {Second} {Conversational} {Intelligence} {Challenge} ({ConvAI2})},
	isbn = {978-3-030-29135-8},
	doi = {10.1007/978-3-030-29135-8_7},
	abstract = {We describe the setting and results of the ConvAI2 NeurIPS competition that aims to further the state-of-the-art in open-domain chatbots. Some key takeaways from the competition are: (1) pretrained Transformer variants are currently the best performing models on this task, (2) but to improve performance on multi-turn conversations with humans, future systems must go beyond single word metrics like perplexity to measure the performance across sequences of utterances (conversations)—in terms of repetition, consistency and balance of dialogue acts (e.g. how many questions asked vs. answered).},
	language = {en},
	booktitle = {The {NeurIPS} '18 {Competition}},
	publisher = {Springer International Publishing},
	author = {Dinan, Emily and Logacheva, Varvara and Malykh, Valentin and Miller, Alexander and Shuster, Kurt and Urbanek, Jack and Kiela, Douwe and Szlam, Arthur and Serban, Iulian and Lowe, Ryan and Prabhumoye, Shrimai and Black, Alan W. and Rudnicky, Alexander and Williams, Jason and Pineau, Joelle and Burtsev, Mikhail and Weston, Jason},
	editor = {Escalera, Sergio and Herbrich, Ralf},
	year = {2020},
	pages = {187--208},
}

@article{satti_when_2021,
	title = {When it’s “now or never”: {Multimodal} practices for managing opportunities to initiate other-repair in collaborative storytelling},
	shorttitle = {When it’s “now or never”},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ni.21005.sat},
	doi = {10.1075/ni.21005.sat},
	abstract = {Abstract Individuals who share knowledge of past events may encounter different practical problems when engaging in the co-telling of those events. Drawing upon conversation analysis, this article investigates how co-tellers manage interpolated opportunities to initiate other-repair in collaborative storytelling. The analysis focuses on the placement of different repair operations on the story-in-progress and shows that co-tellers monitor the progressivity of the storytelling activity to identify proper places to initiate repair. Repairs that are initiated out of place can be oriented to as inappropriate and require more interactional work from participants. When tellers project the continuation of the story beyond a proper place, co-tellers display urgency for halting the story’s current trajectory, which shows their orientation to this moment as a last opportunity to initiate repair. This last possible point to repair the story-in-progress is what I call a “now or never” moment. Data stem from video-recorded collaboratively told stories in Spanish.},
	language = {en},
	urldate = {2021-12-03},
	author = {Satti, Ignacio},
	month = nov,
	year = {2021},
	note = {Publisher: John Benjamins},
}

@book{dourish_where_2004,
	address = {Cambridge, Mass. London},
	edition = {1. MIT Press paperback ed},
	series = {A {Bradford} book},
	title = {Where the action is: the foundations of embodied interaction},
	isbn = {978-0-262-54178-7 978-0-262-04196-6},
	shorttitle = {Where the action is},
	language = {eng},
	publisher = {MIT Press},
	author = {Dourish, Paul},
	year = {2004},
}

@article{button_whats_1994,
	title = {What's wrong with speech-act theory},
	volume = {3},
	issn = {0925-9724, 1573-7551},
	url = {http://link.springer.com/10.1007/BF01305842},
	doi = {10.1007/BF01305842},
	language = {en},
	number = {1},
	urldate = {2022-07-18},
	journal = {Computer Supported Cooperative Work (CSCW)},
	author = {Button, Graham},
	month = mar,
	year = {1994},
	pages = {39--42},
}

@inproceedings{ginzburg_unifying_2007,
	title = {Unifying self-and other-repair},
	booktitle = {Proceeding of {DECALOG}, the 11th {International} {Workshop} on the {Semantics} and {Pragmatics} of {Dialogue} ({SemDial07})},
	author = {Ginzburg, Jonathan and Fernández, Raquel and Schlangen, David},
	year = {2007},
}

@article{linders_zipfs_2022,
	title = {Zipf’s law revisited: {Spoken} dialog, linguistic units, parameters, and the principle of least effort},
	issn = {1069-9384, 1531-5320},
	shorttitle = {Zipf’s law revisited},
	url = {https://link.springer.com/10.3758/s13423-022-02142-9},
	doi = {10.3758/s13423-022-02142-9},
	abstract = {The ubiquitous inverse relationship between word frequency and word rank is commonly known as Zipf’s law. The theoretical underpinning of this law states that the inverse relationship yields decreased effort in both the speaker and hearer, the so-called principle of least effort. Most research has focused on showing an inverse relationship only for written monolog, only for frequencies and ranks of one linguistic unit, generally word unigrams, with strong correlations of the power law to the observed frequency distributions, with limited to no attention to psychological mechanisms such as the principle of least effort. The current paper extends the existing findings, by not focusing on written monolog but on a more fundamental form of communication, spoken dialog, by not only investigating word unigrams but also units quantified on syntactic, pragmatic, utterance, and nonverbal communicative levels by showing that the adequacy of Zipf’s formula seems ubiquitous, but the exponent of the power law curve is not, and by placing these findings in the context of Zipf’s principle of least effort through redefining effort in terms of cognitive resources available for communication. Our findings show that Zipf’s law also applies to a more natural form of communication—that of spoken dialog, that it applies to a range of linguistic units beyond word unigrams, that the general good fit of Zipf’s law needs to be revisited in light of the parameters of the formula, and that the principle of least effort is a useful theoretical framework for the findings of Zipf’s law.},
	language = {en},
	urldate = {2022-07-18},
	journal = {Psychonomic Bulletin \& Review},
	author = {Linders, Guido M. and Louwerse, Max M.},
	month = jul,
	year = {2022},
}

@article{bavelas_gesturing_2008,
	title = {Gesturing on the telephone: {Independent} effects of dialogue and visibility},
	volume = {58},
	issn = {0749-596X},
	shorttitle = {Gesturing on the telephone},
	url = {http://www.sciencedirect.com/science/article/pii/S0749596X07000289},
	doi = {10.1016/j.jml.2007.02.004},
	abstract = {Speakers often gesture in telephone conversations, even though they are not visible to their addressees. To test whether this effect is due to being in a dialogue, we separated visibility and dialogue with three conditions: face-to-face dialogue (10 dyads), telephone dialogue (10 dyads), and monologue to a tape recorder (10 individuals). For the rate of gesturing, both dialogue and visibility had significant, independent effects, with the telephone condition consistently higher than the tape recorder. Also, as predicted, visibility alone significantly affected how speakers gestured: face-to-face speakers were more likely to make life-size gestures, to put information in their gestures that was not in their words, to make verbal reference to their gestures, and to use more gestures referring to the interaction itself. We speculate that demonstration, as a modality, may underlie these findings and may be intimately tied to dialogue while being suppressed in monologue.},
	number = {2},
	urldate = {2013-03-12},
	journal = {Journal of Memory and Language},
	author = {Bavelas, Janet and Gerwing, Jennifer and Sutton, Chantelle and Prevost, Danielle},
	month = feb,
	year = {2008},
	pages = {495--520},
}

@incollection{bavelas_microanalysis_2017,
	title = {Microanalysis of {Face}-to-{Face} {Dialogue} ({MFD})},
	isbn = {978-1-119-10299-1},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119102991.ch47},
	abstract = {Microanalysis of face-to-face dialogue (MFD) developed out of experimental research showing that conversational interaction is a moment-by-moment process that is both collaborative and multimodal. MFD is not limited to the analysis of an a priori set of variables or constructs; instead, it is a meta-method for analyzing any observable feature of face-to-face dialogue. To capture theprecision and coordination of face-to-face dialogue, MFD requires digitized video recordings with both (or all) interlocutors on screen at all times, which can be viewed and annotated with ELAN software (www.mpi.nl). MFD projects usually begin inductively, that is, by discovering new phenomena and hypotheses from close observation of dialogues rather than from the literature. Although MFD developed from unscripted, task-oriented dialogues in experimental settings, it has more recently moved outside the lab to include psychotherapy sessions, medical consultations, computer-mediated communication, and home videos of infants, all with high interanalyst agreement.},
	language = {en},
	urldate = {2022-06-20},
	booktitle = {The {Sourcebook} of {Listening} {Research}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Bavelas, Janet and Gerwing, Jennifer and Healing, Sara and Tomori, Christine},
	year = {2017},
	doi = {10.1002/9781119102991.ch47},
	note = {Section: 41
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119102991.ch47},
	pages = {445--452},
}

@article{bavelas_effect_2014,
	title = {The {Effect} of {Dialogue} on {Demonstrations}: {Direct} {Quotations}, {Facial} {Portrayals}, {Hand} {Gestures}, and {Figurative} {References}},
	volume = {91},
	issn = {0163-853X},
	shorttitle = {The {Effect} of {Dialogue} on {Demonstrations}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/0163853X.2014.883730},
	doi = {10.1080/0163853X.2014.883730},
	abstract = {Demonstrations (e.g., direct quotations, conversational facial portrayals, conversational hand gestures, and figurative references) lack conventional meanings, relying instead on a resemblance to their referent (Clark \& Gerrig, 1990). Two experiments tested our theory that demonstrations are a class of communicative acts that speakers are more likely to use in dialogue than in monologue. We compared speakers' rates of demonstrations in face-to-face dialogues, telephone dialogues, and monologues into a handheld microphone or recorder. Experiment 1 confirmed that the proportions of speakers' direct quotations and facial portrayals were (a) significantly higher in the two dialogue conditions than in the monologue condition and (b) not significantly different in the two dialogue conditions. Experiment 2 found the same patterns for the rates of figurative references and hand gestures, replicating Bavelas, Gerwing, Sutton, and Prevost (2008). In both experiments, regressions confirmed that the increase in demonstrations in dialogues was independent of any effect of visibility.},
	number = {ja},
	urldate = {2014-02-24},
	journal = {Discourse Processes},
	author = {Bavelas, Janet and Gerwing, Jennifer and Healing, Sara},
	year = {2014},
	pages = {619--655},
}

@inproceedings{bavelas_beyond_2012,
	title = {Beyond back-channels: {A} three-step model of grounding in face-to-face dialogue},
	shorttitle = {Beyond back-channels},
	booktitle = {Proceedings of {Interdisciplinary} {Workshop} on {Feedback} {Behaviors} in {Dialog}},
	author = {Bavelas, Janet Beavin and De Jong, Peter and Korman, Harry and Jordan, S. Smock},
	year = {2012},
	pages = {5--6},
}

@article{bavelas_interactive_1992,
	title = {Interactive gestures},
	volume = {15},
	issn = {0163-853X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01638539209544823},
	doi = {10.1080/01638539209544823},
	abstract = {Illustrators are hand gestures made during conversation. Following Bavelas, Hagen, Lane, and Lawrie (1989), we propose a new division of illustrators, into topic and interactive gestures. Interactive gestures refer to the interlocutor rather than to the topic of conversation, and they help maintain the conversation as a social system. They subsume but are not limited to the category previously called beats or batons. Three tests of this theory are reported here. In Experiment 1, the same narrative task was assigned to both dyads and individuals: Dyads had a higher rate of interactive gestures than did individuals, but the opposite pattern was shown for topic gestures. In Experiment 2, we manipulated visual availability: The rate of interactive gestures was higher for partners interacting face‐to‐face than for those who could not see each other, but topic gestures were not significantly affected by condition. Thus, in both experiments, interactive and topic gestures responded differently to social variables, which strongly suggests they are functionally distinct groups. A final analysis showed that, in both data sets, interactive gestures were less redundant with the words they accompanied than were topic gestures, which supports our hypothesis that they maintain involvement with the interlocutor without interrupting the verbal flow of discourse.},
	number = {4},
	urldate = {2013-03-12},
	journal = {Discourse Processes},
	author = {Bavelas, Janet Beavin and Chovil, Nicole and Lawrie, Douglas A. and Wade, Allan},
	year = {1992},
	pages = {469--489},
}

@article{bavelas_naturalistic_1984,
	title = {On “{Naturalistic}” {Family} {Research}},
	volume = {23},
	issn = {1545-5300},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1545-5300.1984.00337.x},
	doi = {10.1111/j.1545-5300.1984.00337.x},
	abstract = {Much is made of the desirability of “naturalistic” research on the family. Indeed, experimental research is often rejected for not being “naturalistic.” The purpose of the present article is to draw out and to examine some of the assumptions underlying such a position. The assumptions behind criteria such as “real,”“relevant,” and “typical” for research topics and settings are held to be questionable, not least because they are inconsistent with a communicational, context-oriented approach to the family. Alternative assumptions more consistent with this approach are described.},
	language = {en},
	number = {3},
	urldate = {2022-06-20},
	journal = {Family Process},
	author = {Bavelas, Janet Beavin},
	year = {1984},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1545-5300.1984.00337.x},
	pages = {337--341},
}

@article{bavelas_situations_1983,
	title = {Situations {That} {Lead} to {Disqualification}},
	volume = {9},
	issn = {1468-2958},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1468-2958.1983.tb00688.x/abstract},
	doi = {10.1111/j.1468-2958.1983.tb00688.x},
	abstract = {Disqualification is nonstraighforward communication—messages that are ambiguous, indirect, or evasive to some degree. A previous paper defined and measured disqualification as deviations from the direct “I am saying this to you in this situation”—that is, as relative ambiguity in sender, content, receiver, or context. The present article addresses the question of what causes such messages. An interpersonal, situational theory is proposed and tested in a series of five experiments, using a forced-choice among written messages in systematically varied, hypothetical situations. Subjects chose the most disqualified messages overwhelmingly when placed in a “bind.” They did so significantly more than when in a non-bind or a merely unpleasant situation. The last two experiments defined a “bind” as an avoidance-avoidance conflict and showed that disqualified messages were chosen only in these, and not in approach-approach conflicts. The conclusion is that disqualification is not a failure of the communicator, nor even a changeworthy behavior, but a reasonable response to an impossible situation, one that permits the sender to leave the field communicationally.},
	language = {en},
	number = {2},
	urldate = {2013-03-12},
	journal = {Human Communication Research},
	author = {Bavelas, Janet Beavin},
	year = {1983},
	pages = {130--145},
}

@article{bavelas_social_1978,
	title = {The social psychology of citations},
	volume = {19},
	issn = {0318-2096},
	doi = {10.1037/h0081472},
	abstract = {Discusses 2 social facets of citations and citation counts. It is proposed that literature is cited both because of scholarly impact and to show a familiarity with the pertinent literature. In this sense, citation counts measure social consensus indistinguishable from scholarly impact. Qualitative evaluation methods are considered to be appealing because of the social-historical climate. (15 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Canadian Psychological Review/Psychologie canadienne},
	author = {Bavelas, Janet Beavin},
	year = {1978},
	note = {Place: Canada
Publisher: Canadian Psychological Association},
	pages = {158--163},
}

@article{bavelas_form_1988,
	title = {Form and {Function} in {Motor} {Mimicry} {Topographic} {Evidence} that the {Primary} {Function} {Is} {Communicative}},
	volume = {14},
	issn = {1468-2958},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1468-2958.1988.tb00158.x/abstract},
	doi = {10.1111/j.1468-2958.1988.tb00158.x},
	abstract = {Motor mimicry is behavior by an observer that is appropriate to the situation of the other person, for example, wincing at the other's injury or ducking when the other does. Traditional theories of motor mimicry view this behavior as an indicator of a vicarious cognitive or empathic experience, that is, of taking the role of the other or of “feeling oneself into” the other person. However, Bavelas, Black, Lemery, and Mullett (1986) have shown that motor mimicry of pain is affected by communicative variables and acts as a nonverbal message indicating that the observer is aware of and concerned about the other's situation. This raises a more general question: Is communication its primary or secondary function? We propose (i) that motor mimicry functions as a nonverbal, analogic, relationship message about similarity between observer and other and (ii) that this message is encoded according to Gestalt principles of form, in that the observer physically mirrors the other. In other words, the observer maintains a relationship with the other. The special case of left/right leaning when observer and other are facing each other permits a test of our theory against two theories that treat motor mimicry as an indicator of vicarious experience. The results of three experiments showed that when motor mimicry by an observer facing someone who is leaning left or right occurs, it is both displayed and decoded in the form consistent with a communication theory; this form is called reflection symmetry. We conclude that, because of the topography of the response, the primary function of motor mimicry must be communicative and that any relationship to vicarious processes is secondary. A similar analysis of other nonverbal behaviors may well reveal that they are also expressions to another person rather than expressions of infrapsychic states.},
	language = {en},
	number = {3},
	urldate = {2013-03-12},
	journal = {Human Communication Research},
	author = {Bavelas, Janet Beavin and Black, Alex and Chovil, Nicole and Lemery, Charles R. and Mullett, Jennifer},
	year = {1988},
	pages = {275--299},
}

@incollection{fitch_two_2005,
	address = {Mahwah, N.J},
	series = {{LEA}'s communication series},
	title = {The {Two} {Solitudes}: {Reconciling} {Social} {Psychology} and {Language} and {Social} {Interaction}},
	isbn = {0-8058-4240-3},
	booktitle = {Handbook of {Language} and {Social} {Interaction}},
	publisher = {Lawrence Erlbaum Associates},
	author = {Bavelas, Janet Beavin},
	editor = {Fitch, Kristine L. and Sanders, Robert E.},
	year = {2005},
}

@article{bavelas_gestures_1994,
	title = {Gestures as {Part} of {Speech}: {Methodological} {Implications}},
	volume = {27},
	issn = {0835-1813},
	shorttitle = {Gestures as {Part} of {Speech}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi2703_3},
	doi = {10.1207/s15327973rlsi2703_3},
	number = {3},
	urldate = {2013-03-12},
	journal = {Research on Language \& Social Interaction},
	author = {Bavelas, Janet Beavin},
	year = {1994},
	pages = {201--221},
}

@patent{grant_cognitive_2019,
	title = {Cognitive intervention for voice recognition failure},
	url = {https://patents.google.com/patent/US10229682B2/en},
	nationality = {US},
	language = {en},
	assignee = {International Business Machines Corp},
	number = {US10229682B2},
	urldate = {2022-07-15},
	author = {Grant, Robert H. and Hewitt, Trudy L. and Mason, Mitchell J. and Moore, Robert J. and Winburn, Kenneth A.},
	month = mar,
	year = {2019},
}

@incollection{moore_conversational_2018,
	address = {Cham},
	series = {Human–{Computer} {Interaction} {Series}},
	title = {Conversational {UX} {Design}: {An} {Introduction}},
	isbn = {978-3-319-95579-7},
	shorttitle = {Conversational {UX} {Design}},
	url = {https://doi.org/10.1007/978-3-319-95579-7_1},
	abstract = {Today chat-bot or conversational-agent platforms are ubiquitous. Major technology companies, including Amazon, Google, Apple, Facebook, Microsoft, IBM, as well as multiple start-ups are providing them. But current UX design methodologies and guidelines, intended for graphical interfaces, such as web and mobile, do not apply. In conversational interfaces, the user experience is primarily in the sequences of turns of chat or voice. Although the field of Natural Language Processing (NLP) provides powerful tools for analyzing bits of language, it does not provide guidance on how to string bits of language together into sequences that approximate those of natural human conversation. From the demand for applications on these platforms, a new role is emerging: the conversational UX designer. Currently, the work of conversational UX design is falling on developers, visually oriented interface designers or subject matter experts, none of whom possess the required skills for such work. Instead, what is needed is a person with both experience in UX design and a formal understanding of human conversation (social science). This book provides this new type of UX designer with a collection of studies by HCI researchers and industry practitioners that focuses on key issues in designing conversational user experiences. Each team of authors presents conversational systems and/or user studies and reflects on challenges that are unique to designing conversational interfaces. In addition, the book introduces UX designers to Conversation Analysis (CA), a field within sociology, that provides a treasure trove of empirical models of how people naturally talk and thus a scientific foundation for the creation of conversational UX patterns. General design themes in the book include: the structure of human conversation, agent knowledge, agent misunderstanding and agent design.},
	language = {en},
	urldate = {2022-07-15},
	booktitle = {Studies in {Conversational} {UX} {Design}},
	publisher = {Springer International Publishing},
	author = {Moore, Robert J. and Arar, Raphael},
	editor = {Moore, Robert J. and Szymanski, Margaret H. and Arar, Raphael and Ren, Guang-Jie},
	year = {2018},
	doi = {10.1007/978-3-319-95579-7_1},
	pages = {1--16},
}

@book{moore_studies_2018,
	address = {Cham},
	series = {Human–{Computer} {Interaction} {Series}},
	title = {Studies in {Conversational} {UX} {Design}},
	isbn = {978-3-319-95578-0 978-3-319-95579-7},
	url = {http://link.springer.com/10.1007/978-3-319-95579-7},
	urldate = {2022-07-15},
	publisher = {Springer International Publishing},
	editor = {Moore, Robert J. and Szymanski, Margaret H. and Arar, Raphael and Ren, Guang-Jie},
	year = {2018},
	doi = {10.1007/978-3-319-95579-7},
}

@article{marwick_public_2012,
	title = {The {Public} {Domain}: {Surveillance} in {Everyday} {Life}},
	volume = {9},
	issn = {1477-7487},
	shorttitle = {The {Public} {Domain}},
	url = {https://ojs.library.queensu.ca/index.php/surveillance-and-society/article/view/pub_dom},
	doi = {10.24908/ss.v9i4.4342},
	language = {en},
	number = {4},
	urldate = {2022-07-14},
	journal = {Surveillance \& Society},
	author = {Marwick, Alice},
	month = jun,
	year = {2012},
	pages = {378--393},
}

@article{egliston_oculus_2022,
	title = {Oculus imaginaries: {The} promises and perils of {Facebook}’s virtual reality},
	volume = {24},
	issn = {1461-4448},
	shorttitle = {Oculus imaginaries},
	url = {https://doi.org/10.1177/1461444820960411},
	doi = {10.1177/1461444820960411},
	abstract = {This article explores the Oculus suite of virtual reality (VR) technologies, with a specific focus on the period following the company’s 2014 acquisition by Facebook. Through a close reading of promotional material, we first describe and analyse the ‘Oculus imaginary’ – the narrative produced by Facebook about the Oculus as integrated into and enhancing the experience of Facebook’s wider suite of social software. The purpose of this narrative, we suggest, is to construct and ‘sell’ a Facebook-specific vision of VR’s potentials – one that is appealing both to end users and platform complementors – and moreover, a vision that appears to be conducive to Facebook’s current methods for accumulating profit and power. Following on, we develop via a study of YouTube user comments posted on promotional videos for the Oculus, an anticipatory account of how the Oculus imaginary is perceived to relate to the lives and values of everyday individuals.},
	language = {en},
	number = {1},
	urldate = {2022-07-14},
	journal = {New Media \& Society},
	author = {Egliston, Ben and Carter, Marcus},
	month = jan,
	year = {2022},
	note = {Publisher: SAGE Publications},
	pages = {70--89},
}

@inproceedings{lim_demonstration_2022,
	address = {Sapporo, Hokkaido, Japan},
	series = {{HRI} '22},
	title = {Demonstration of a {Robo}-{Barista} for {In} the {Wild} {Interactions}},
	abstract = {We present a demonstration of a Robo-Barista: a social robot that takes hot beverage orders through verbal interaction and completes them via a Bluetooth enabled coffee machine. The demonstration is highly robust and it is the intention that this could be installed as a permanent feature, enabling "In the Wild" experimentation and long term studies. In the demonstration video, we show a user interacting with a Furhat robot to order a coffee. The robot has a novel architecture that allows it to exhibit both verbal and non-verbal cues, such as shared attention and chitchat. Furthermore, it is enabled with a unique tiredness detector based on visual facial features.},
	urldate = {2022-07-14},
	booktitle = {Proceedings of the 2022 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {IEEE Press},
	author = {Lim, Mei Yii and Aguas Lopes, José David and Robb, David A. and Wilson, Bruce W. and Moujahid, Meriam and Hastie, Helen},
	year = {2022},
	pages = {1200--1201},
}

@incollection{barth-weingarten_multimodal_2010,
	address = {Amsterdam},
	title = {Multimodal expressivity of the {Japanese} response particle {Huun}: displaying involvement without topical engagement},
	isbn = {978-90-272-2633-4},
	abstract = {Prosody is constitutive for spoken interaction. In more than 25 years, its study has grown into a full-fledged and very productive field with a sound catalogue of research methods and principles. This volume presents the state of the art, illustrates current research trends and uncovers potential directions for future research. It will therefore be of major interest to everyone studying spoken interaction. The collection brings together an impressive range of internationally renowned scholars from different, yet closely related and compatible research traditions which have made a significant contribution to the field. They cover issues such as the units of language, the contextualization of actions and activities, conversational modalities and genres, the display of affect and emotion, the multimodality of interaction, language acquisition and aphasia. All contributions are based on empirical, audio- and/or video-recorded data of natural talk-in-interaction, including languages such as English, German and Japanese. The methodologies employed come from Ethnomethodology, Conversation Analysis and Interactional Linguistics.},
	language = {en},
	booktitle = {Prosody in interaction},
	publisher = {John Benjamins},
	author = {Tanaka, Hiroko},
	editor = {Barth-Weingarten, Dagmar and Reber, Elisabeth and Selting, Margret},
	year = {2010},
}

@inproceedings{liesenfeld_deep_2021,
	address = {New York, NY, USA},
	series = {{MuC} '21},
	title = {Deep {Learning} {Meets} {Private} {Talk}: {Conversational} {AI} {Can} {Predict} {Speaker} {Traits} by {Eavesdropping} for {Only} 30 {Seconds}},
	isbn = {978-1-4503-8645-6},
	shorttitle = {Deep {Learning} {Meets} {Private} {Talk}},
	url = {https://doi.org/10.1145/3473856.3474012},
	doi = {10.1145/3473856.3474012},
	abstract = {Conversational AI such as smart speakers placed in home environments can accidentally activate and record people’s talk for a short time. What can such devices learn about people by listening in on ongoing conversations? Taking two commonly used speaker traits as an example, we present the results of an experiment that simulates Conversational AI eavesdropping on ongoing talk using transcriptions of naturalistic conversations in private settings. We show that a currently popular type of deep learning-based system can reliably predict if a speaker is “young”, “old”, “female” or “male” (age=99\%, gender=82\%) based on what they say in around 30 seconds. Our results exemplify how powerful current big data language models are when it comes to data-driven predictions of personal information based on how people talk, even when listening only for a short time. We conclude the experiment with a critical comment on the increasingly pervasive use of such user modeling technology to compute speaker traits, touching upon some potential ethical concerns, bias, and privacy issues.},
	urldate = {2022-03-23},
	booktitle = {Mensch und {Computer} 2021},
	publisher = {Association for Computing Machinery},
	author = {Liesenfeld, Andreas and Parti, Gábor and Huang, Chu-ren},
	month = sep,
	year = {2021},
	pages = {547--551},
}

@inproceedings{liesenfeld_namespec_2020,
	address = {Bilbao Spain},
	title = {{NameSpec} asks: {What}'s {Your} {Name} in {Chinese}? {A} {Voice} {Bot} to {Specify} {Chinese} {Personal} {Names} through {Dialog}},
	isbn = {978-1-4503-7544-3},
	shorttitle = {{NameSpec} asks},
	url = {https://dl.acm.org/doi/10.1145/3405755.3406171},
	doi = {10.1145/3405755.3406171},
	language = {en},
	urldate = {2022-04-22},
	booktitle = {Proceedings of the 2nd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {ACM},
	author = {Liesenfeld, Andreas and Huang, Chu-ren},
	month = jul,
	year = {2020},
	pages = {1--3},
}

@inproceedings{liesenfeld_scikit-talk_2021,
	address = {Singapore and Online},
	title = {Scikit-talk: {A} toolkit for processing real-world conversational speech data},
	shorttitle = {Scikit-talk},
	url = {https://aclanthology.org/2021.sigdial-1.26},
	abstract = {We present Scikit-talk, an open-source toolkit for processing collections of real-world conversational speech in Python. First of its kind, the toolkit equips those interested in studying or modeling conversations with an easy-to-use interface to build and explore large collections of transcriptions and annotations of talk-in-interaction. Designed for applications in speech processing and Conversational AI, Scikit-talk provides tools to custom-build datasets for tasks such as intent prototyping, dialog flow testing, and conversation design. Its preprocessor module comes with several pre-built interfaces for common transcription formats, which aim to make working across multiple data sources more accessible. The explorer module provides a collection of tools to explore and analyse this data type via string matching and unsupervised machine learning techniques. Scikit-talk serves as a platform to collect and connect different transcription formats and representations of talk, enabling the user to quickly build multilingual datasets of varying detail and granularity. Thus, the toolkit aims to make working with authentic conversational speech data in Python more accessible and to provide the user with comprehensive options to work with representations of talk in appropriate detail for any downstream task. For the latest updates and information on currently supported languages and language resources, please refer to: https://pypi.org/project/scikit-talk/},
	booktitle = {Proceedings of the 22nd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Liesenfeld, Andreas and Parti, Gabor and Huang, Chu-Ren},
	month = jul,
	year = {2021},
	pages = {252--256},
}

@article{young_augmenting_2018,
	title = {Augmenting {End}-to-{End} {Dialogue} {Systems} {With} {Commonsense} {Knowledge}},
	volume = {32},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11923},
	doi = {10.1609/aaai.v32i1.11923},
	abstract = {Building dialogue systems that can converse naturally with humans is a challenging yet intriguing problem of artificial intelligence. In open-domain human-computer conversation, where the conversational agent is expected to respond to human utterances in an interesting and engaging way, commonsense knowledge has to be integrated into the model effectively. In this paper, we investigate the impact of providing commonsense knowledge about the concepts covered in the dialogue. Our model represents the first attempt to integrating a large commonsense knowledge base into end-to-end conversational models. In the retrieval-based scenario, we propose a model to jointly take into account message content and related commonsense for selecting an appropriate response. Our experiments suggest that the knowledge-augmented models are superior to their knowledge-free counterparts.},
	number = {1},
	urldate = {2022-07-08},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Young, Tom and Cambria, Erik and Chaturvedi, Iti and Zhou, Hao and Biswas, Subham and Huang, Minlie},
	month = apr,
	year = {2018},
}

@inproceedings{gupta_building_2022,
	title = {On {Building} {Spoken} {Language} {Understanding} {Systems} for {Low} {Resourced} {Languages}},
	url = {https://aclanthology.org/2022.sigmorphon-1.1},
	abstract = {Akshat Gupta. 19th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	author = {Gupta, Akshat},
	month = jul,
	year = {2022},
	pages = {1--11},
}

@inproceedings{santra_representation_2022,
	title = {Representation {Learning} for {Conversational} {Data} using {Discourse} {Mutual} {Information} {Maximization}},
	url = {https://aclanthology.org/2022.naacl-main.124},
	abstract = {Bishal Santra, Sumegh Roychowdhury, Aishik Mandal, Vasu Gurram, Atharva Naik, Manish Gupta, Pawan Goyal. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	author = {Santra, Bishal and Roychowdhury, Sumegh and Mandal, Aishik and Gurram, Vasu and Naik, Atharva and Gupta, Manish and Goyal, Pawan},
	month = jul,
	year = {2022},
	pages = {1718--1734},
}

@inproceedings{sanagavarapu_disentangling_2022,
	title = {Disentangling {Indirect} {Answers} to {Yes}-{No} {Questions} in {Real} {Conversations}},
	url = {https://aclanthology.org/2022.naacl-main.345},
	abstract = {Krishna Sanagavarapu, Jathin Singaraju, Anusha Kakileti, Anirudh Kaza, Aaron Mathews, Helen Li, Nathan Brito, Eduardo Blanco. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	author = {Sanagavarapu, Krishna and Singaraju, Jathin and Kakileti, Anusha and Kaza, Anirudh and Mathews, Aaron and Li, Helen and Brito, Nathan and Blanco, Eduardo},
	month = jul,
	year = {2022},
	pages = {4677--4695},
}

@inproceedings{dziri_origin_2022,
	title = {On the {Origin} of {Hallucinations} in {Conversational} {Models}: {Is} it the {Datasets} or the {Models}?},
	shorttitle = {On the {Origin} of {Hallucinations} in {Conversational} {Models}},
	url = {https://aclanthology.org/2022.naacl-main.387},
	abstract = {Nouha Dziri, Sivan Milton, Mo Yu, Osmar Zaiane, Siva Reddy. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	author = {Dziri, Nouha and Milton, Sivan and Yu, Mo and Zaiane, Osmar R. and Reddy, Siva},
	month = jul,
	year = {2022},
	pages = {5271--5285},
}

@inproceedings{pressel_lightweight_2022,
	title = {Lightweight {Transformers} for {Conversational} {AI}},
	url = {https://aclanthology.org/2022.naacl-industry.25},
	abstract = {Daniel Pressel, Wenshuo Liu, Michael Johnston, Minhua Chen. Proceedings of NAACL-HLT 2022: Industry Track Papers. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	author = {Pressel, Daniel and Liu, Wenshuo and Johnston, Michael and Chen, Minhua},
	month = jul,
	year = {2022},
	pages = {221--229},
}

@inproceedings{qian_capturing_2022,
	title = {Capturing {Conversational} {Interaction} for {Question} {Answering} via {Global} {History} {Reasoning}},
	url = {https://aclanthology.org/2022.findings-naacl.159},
	abstract = {Jin Qian, Bowei Zou, Mengxing Dong, Xiao Li, AiTi Aw, Yu Hong. Findings of the Association for Computational Linguistics: NAACL 2022. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	author = {Qian, Jin and Zou, Bowei and Dong, Mengxing and Li, Xiao and Aw, Aiti and Hong, Yu},
	month = jul,
	year = {2022},
	pages = {2071--2078},
}

@inproceedings{wang_luna_2022,
	title = {{LUNA}: {Learning} {Slot}-{Turn} {Alignment} for {Dialogue} {State} {Tracking}},
	shorttitle = {{LUNA}},
	url = {https://aclanthology.org/2022.naacl-main.242},
	abstract = {Yifan Wang, Jing Zhao, Junwei Bao, Chaoqun Duan, Youzheng Wu, Xiaodong He. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	author = {Wang, Yifan and Zhao, Jing and Bao, Junwei and Duan, Chaoqun and Wu, Youzheng and He, Xiaodong},
	month = jul,
	year = {2022},
	pages = {3319--3328},
}

@inproceedings{choudhary_grounding_2022,
	title = {Grounding in social media: {An} approach to building a chit-chat dialogue model},
	shorttitle = {Grounding in social media},
	url = {https://aclanthology.org/2022.naacl-srw.2},
	abstract = {Ritvik Choudhary, Daisuke Kawahara. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	author = {Choudhary, Ritvik and Kawahara, Daisuke},
	month = jul,
	year = {2022},
	pages = {9--15},
}

@inproceedings{stasaski_semantic_2022,
	title = {Semantic {Diversity} in {Dialogue} with {Natural} {Language} {Inference}},
	url = {https://aclanthology.org/2022.naacl-main.6},
	abstract = {Katherine Stasaski, Marti Hearst. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.},
	language = {en-us},
	urldate = {2022-07-07},
	author = {Stasaski, Katherine and Hearst, Marti A.},
	month = jul,
	year = {2022},
	pages = {85--98},
}

@inproceedings{esch_predicting_2016,
	title = {Predicting {Pronunciations} with {Syllabification} and {Stress} with {Recurrent} {Neural} {Networks}},
	url = {https://www.isca-speech.org/archive/interspeech_2016/esch16_interspeech.html},
	doi = {10.21437/Interspeech.2016-1419},
	language = {en},
	urldate = {2022-07-06},
	booktitle = {Interspeech 2016},
	publisher = {ISCA},
	author = {Esch, Daan van and Chua, Mason and Rao, Kanishka},
	month = sep,
	year = {2016},
	pages = {2841--2845},
}

@inproceedings{frick_querying_2022,
	title = {Querying {Interaction} {Structure}: {Approaches} to {Overlap} in {Spoken} {Language} {Corpora}},
	abstract = {In this paper, we address two problems in indexing and querying spoken language corpora with overlapping speaker contributions. First, we look into how token distance and token precedence can be measured when multiple primary data streams are available and when transcriptions happen to be tokenized, but are not synchronized with the sound at the level of individual tokens. We propose and experiment with a speaker-based search mode that enables any speaker’s transcription tier to be the basic tokenization layer whereby the contributions of other speakers are mapped to this given tier. Secondly, we address two distinct methods of how speaker overlaps can be captured in the TEI-based ISO Standard for Spoken Language Transcriptions (ISO 24624:2016) and how they can be queried by MTAS – an open source Lucene-based search engine for querying text with multilevel annotations. We illustrate the problems, introduce possible solutions and discuss their benefits and drawbacks.},
	language = {en},
	booktitle = {Proceedings of the 13th {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2022),},
	author = {Frick, Elena and Schmidt, Thomas and Helmer, Henrike},
	year = {2022},
	pages = {715--722},
}

@article{ruscio_taking_2016,
	title = {Taking {Advantage} of {Citation} {Measures} of {Scholarly} {Impact}: {Hip} {Hip} h {Index}!},
	volume = {11},
	issn = {1745-6916},
	shorttitle = {Taking {Advantage} of {Citation} {Measures} of {Scholarly} {Impact}},
	url = {https://doi.org/10.1177/1745691616664436},
	doi = {10.1177/1745691616664436},
	abstract = {Professional decisions about hiring, tenure, promotion, funding, and honors are informed by assessments of scholarly impact. As a measure of influence, citations are produced by experts but accessible to nonexperts. The h index is the largest number h such that an individual has published at least h works cited at least h times apiece. This is easy to understand and calculate, as or more reliable and valid than alternative citation measures, and highly robust to missing or messy data. Striving for a large h index requires both productivity and influence, which provides healthy incentives for researchers striving for eminence through scientific impact. A number of factors that can influence h are discussed to promote the mindful use of what might otherwise be an ambiguous or misleading measure. The h index adds a transparent, objective component to assessments of scholarly impact, and even academic eminence, that merits at least two cheers.},
	language = {en},
	number = {6},
	urldate = {2022-07-01},
	journal = {Perspectives on Psychological Science},
	author = {Ruscio, John},
	month = nov,
	year = {2016},
	note = {Publisher: SAGE Publications Inc},
	pages = {905--908},
}

@inproceedings{scheurer_learning_2022,
	title = {Learning from {Natural} {Language} {Feedback}},
	url = {https://openreview.net/forum?id=r6wu2WDhib9},
	abstract = {We propose an algorithm for training language models to behave in line with human preferences, by learning from natural language feedback.},
	language = {en},
	urldate = {2022-07-01},
	author = {Scheurer, Jérémy and Campos, Jon Ander and Chan, Jun Shern and Chen, Angelica and Cho, Kyunghyun and Perez, Ethan},
	month = apr,
	year = {2022},
}

@article{scheurer_training_2022,
	title = {Training {Language} {Models} with {Natural} {Language} {Feedback}},
	journal = {arXiv preprint arXiv:2204.14146},
	author = {Scheurer, Jérémy and Campos, Jon Ander and Chan, Jun Shern and Chen, Angelica and Cho, Kyunghyun and Perez, Ethan},
	year = {2022},
}

@misc{chen_teaching_2022,
	title = {Teaching {BERT} to {Wait}: {Balancing} {Accuracy} and {Latency} for {Streaming} {Disfluency} {Detection}},
	shorttitle = {Teaching {BERT} to {Wait}},
	url = {http://arxiv.org/abs/2205.00620},
	abstract = {In modern interactive speech-based systems, speech is consumed and transcribed incrementally prior to having disfluencies removed. This post-processing step is crucial for producing clean transcripts and high performance on downstream tasks (e.g. machine translation). However, most current state-of-the-art NLP models such as the Transformer operate non-incrementally, potentially causing unacceptable delays. We propose a streaming BERT-based sequence tagging model that, combined with a novel training objective, is capable of detecting disfluencies in real-time while balancing accuracy and latency. This is accomplished by training the model to decide whether to immediately output a prediction for the current input or to wait for further context. Essentially, the model learns to dynamically size its lookahead window. Our results demonstrate that our model produces comparably accurate predictions and does so sooner than our baselines, with lower flicker. Furthermore, the model attains state-of-the-art latency and stability scores when compared with recent work on incremental disfluency detection.},
	urldate = {2022-07-01},
	publisher = {arXiv},
	author = {Chen, Angelica and Zayats, Vicky and Walker, Daniel D. and Padfield, Dirk},
	month = may,
	year = {2022},
	note = {arXiv:2205.00620 [cs]},
}

@article{folstad_users_2020,
	title = {Users' experiences with chatbots: findings from a questionnaire study},
	volume = {5},
	issn = {2366-0147},
	shorttitle = {Users' experiences with chatbots},
	url = {https://doi.org/10.1007/s41233-020-00033-2},
	doi = {10.1007/s41233-020-00033-2},
	abstract = {For chatbots to be broadly adopted by users, it is critical that they are experienced as useful and pleasurable. While there is an emerging body of research concerning user uptake and use of chatbots, there is a lack of theoretically grounded studies detailing what constitutes good or poor chatbot user experiences. In this paper, we present findings from a questionnaire study involving more than 200 chatbot users who reported on episodes of chatbot use that they found particularly satisfactory or frustrating. The user reports were analysed with basis in theory on user experience, with particular concern for pragmatic and hedonic attributes. We found that pragmatic attributes such as efficient assistance (positive) and problems with interpretation (negative) were important elements in user reports of satisfactory and frustrating episodes. Hedonic attributes such as entertainment value (positive) and strange and rude responses (negative) were also frequently mentioned. Older participants tended to report on pragmatic attributes more often, whereas younger participants tended to report on hedonic attributes more often. Drawing on the findings, we propose four high-level lessons learnt that may benefit chatbot service providers, and we suggest relevant future research.},
	language = {en},
	number = {1},
	urldate = {2022-06-30},
	journal = {Quality and User Experience},
	author = {Følstad, Asbjørn and Brandtzaeg, Petter Bae},
	month = apr,
	year = {2020},
	pages = {3},
}

@article{folstad_future_2021,
	title = {Future directions for chatbot research: an interdisciplinary research agenda},
	volume = {103},
	issn = {1436-5057},
	shorttitle = {Future directions for chatbot research},
	url = {https://doi.org/10.1007/s00607-021-01016-7},
	doi = {10.1007/s00607-021-01016-7},
	abstract = {Chatbots are increasingly becoming important gateways to digital services and information—taken up within domains such as customer service, health, education, and work support. However, there is only limited knowledge concerning the impact of chatbots at the individual, group, and societal level. Furthermore, a number of challenges remain to be resolved before the potential of chatbots can be fully realized. In response, chatbots have emerged as a substantial research area in recent years. To help advance knowledge in this emerging research area, we propose a research agenda in the form of future directions and challenges to be addressed by chatbot research. This proposal consolidates years of discussions at the CONVERSATIONS workshop series on chatbot research. Following a deliberative research analysis process among the workshop participants, we explore future directions within six topics of interest: (a) users and implications, (b) user experience and design, (c) frameworks and platforms, (d) chatbots for collaboration, (e) democratizing chatbots, and (f) ethics and privacy. For each of these topics, we provide a brief overview of the state of the art, discuss key research challenges, and suggest promising directions for future research. The six topics are detailed with a 5-year perspective in mind and are to be considered items of an interdisciplinary research agenda produced collaboratively by avid researchers in the field.},
	language = {en},
	number = {12},
	urldate = {2022-06-30},
	journal = {Computing},
	author = {Følstad, Asbjørn and Araujo, Theo and Law, Effie Lai-Chong and Brandtzaeg, Petter Bae and Papadopoulos, Symeon and Reis, Lea and Baez, Marcos and Laban, Guy and McAllister, Patrick and Ischen, Carolin and Wald, Rebecca and Catania, Fabio and Meyer von Wolff, Raphael and Hobert, Sebastian and Luger, Ewa},
	month = dec,
	year = {2021},
	pages = {2915--2942},
}

@inproceedings{folstad_conversational_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Conversational {Repair} in {Chatbots} for {Customer} {Service}: {The} {Effect} of {Expressing} {Uncertainty} and {Suggesting} {Alternatives}},
	isbn = {978-3-030-39540-7},
	shorttitle = {Conversational {Repair} in {Chatbots} for {Customer} {Service}},
	doi = {10.1007/978-3-030-39540-7_14},
	abstract = {Due to the complexity of natural language, chatbots are prone to misinterpreting user requests. Such misinterpretations may lead the chatbot to provide answers that are not adequate responses to user request – so called false positives – potentially leading to conversational breakdown. A promising repair strategy in such cases is for the chatbot to express uncertainty and suggest likely alternatives in cases where prediction confidence falls below threshold. However, little is known about how such repair affects chatbot dialogues. We present findings from a study where a solution for expressing uncertainty and suggesting likely alternatives was implemented in a live chatbot for customer service. Chatbot dialogues (N = 700) were sampled at two points in time – immediately before and after implementation – and compared by conversational quality. Preliminary analyses suggest that introducing such a solution for conversational repair may substantially reduce the proportion of false positives in chatbot dialogues. At the same time, expressing uncertainty and suggesting likely alternatives does not seem to strongly affect the dialogue process and the likelihood of reaching a successful outcome. Based on the findings, we discuss theoretical and practical implications and suggest directions for future research.},
	language = {en},
	booktitle = {Chatbot {Research} and {Design}},
	publisher = {Springer International Publishing},
	author = {Følstad, Asbjørn and Taylor, Cameron},
	editor = {Følstad, Asbjørn and Araujo, Theo and Papadopoulos, Symeon and Law, Effie Lai-Chong and Granmo, Ole-Christoffer and Luger, Ewa and Brandtzaeg, Petter Bae},
	year = {2020},
	pages = {201--214},
}

@article{suchman_interactional_1990,
	title = {Interactional {Troubles} in {Face}-to-{Face} {Survey} {Interviews}},
	volume = {85},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2289550},
	doi = {10.2307/2289550},
	number = {409},
	urldate = {2011-12-06},
	journal = {Journal of the American Statistical Association},
	author = {Suchman, Lucy and Jordan, Brigitte},
	month = mar,
	year = {1990},
	note = {ArticleType: research-article / Full publication date: Mar., 1990 / Copyright © 1990 American Statistical Association},
	pages = {232--241},
}

@book{jefferson_talking_2015,
	address = {Oxford ; New York},
	series = {Foundations of {Human} {Interaction}},
	title = {Talking about troubles in conversation},
	isbn = {978-0-19-993734-9 978-0-19-993732-5},
	publisher = {Oxford University Press},
	author = {Jefferson, Gail},
	editor = {Drew, Paul and Heritage, John and Lerner, Gene H. and Pomerantz, Anita},
	year = {2015},
}

@article{adewumi_state---art_2022,
	title = {State-of-the-art in {Open}-domain {Conversational} {AI}: {A} {Survey}},
	journal = {arXiv preprint arXiv:2205.00965},
	author = {Adewumi, Tosin and Liwicki, Foteini and Liwicki, Marcus},
	year = {2022},
}

@inproceedings{amershi_guidelines_2019,
	address = {Glasgow Scotland Uk},
	title = {Guidelines for {Human}-{AI} {Interaction}},
	isbn = {978-1-4503-5970-2},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300233},
	doi = {10.1145/3290605.3300233},
	abstract = {Advances in artifcial intelligence (AI) frame opportunities and challenges for user interface design. Principles for humanAI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of guidelines for human-AI interaction design.},
	language = {en},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N. and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric},
	month = may,
	year = {2019},
	pages = {1--13},
}

@inproceedings{gilmartin_social_2017,
	address = {New York, NY, USA},
	series = {{ISIAA} 2017},
	title = {Social talk: making conversation with people and machine},
	isbn = {978-1-4503-5558-2},
	shorttitle = {Social talk},
	url = {https://doi.org/10.1145/3139491.3139494},
	doi = {10.1145/3139491.3139494},
	abstract = {Social or interactive talk differs from task-based or instrumental interactions in many ways. Quantitative knowledge of these differences will aid the design of convincing human-machine interfaces for applications requiring machines to take on roles including social companions, healthcare providers, or tutors. We briefly review accounts of social talk from the literature. We outline a three part data collection of human-human, human-woz and human-machine dialogs incorporating light social talk and a guessing game. We finally describe our ongoing experiments on the corpus collected.},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 1st {ACM} {SIGCHI} {International} {Workshop} on {Investigating} {Social} {Interactions} with {Artificial} {Agents}},
	publisher = {Association for Computing Machinery},
	author = {Gilmartin, Emer and Collery, Marine and Su, Ketong and Huang, Yuyun and Elias, Christy and Cowan, Benjamin R. and Campbell, Nick},
	month = nov,
	year = {2017},
	keywords = {Computing methodologies{\textasciitilde}Discourse, dialogue and pragmatics},
	pages = {31--32},
}

@inproceedings{glass1999challenges,
	title = {Challenges for spoken dialogue systems},
	volume = {696},
	booktitle = {Proceedings of the 1999 {IEEE} {ASRU} workshop},
	author = {Glass, James},
	year = {1999},
	note = {tex.organization: MIT Laboratory fot Computer Science Cambridge, MA, USA},
}

@article{ward_challenges_2016,
	title = {Challenges in {Building} {Highly}-{Interactive} {Dialog} {Systems}},
	volume = {37},
	copyright = {Copyright (c) 2017 AI Magazine},
	issn = {2371-9621},
	url = {https://ojs.aaai.org/index.php/aimagazine/article/view/2687},
	doi = {10.1609/aimag.v37i4.2687},
	abstract = {Spoken dialog researchers have recently demonstrated highly-interactive systems in several domains. This paper considers how to build on these advances to make systems more robust, easier to develop, and more scientifically significant. We identify key challenges whose solution would lead to improvements in dialog systems and beyond.},
	language = {en},
	number = {4},
	urldate = {2022-06-29},
	journal = {AI Magazine},
	author = {Ward, Nigel G. and DeVault, David},
	year = {2016},
	note = {Number: 4},
	pages = {7--18},
}

@inproceedings{liao_what_2016,
	address = {Brisbane QLD Australia},
	title = {What {Can} {You} {Do}?: {Studying} {Social}-{Agent} {Orientation} and {Agent} {Proactive} {Interactions} with an {Agent} for {Employees}},
	isbn = {978-1-4503-4031-1},
	shorttitle = {What {Can} {You} {Do}?},
	url = {https://dl.acm.org/doi/10.1145/2901790.2901842},
	doi = {10.1145/2901790.2901842},
	abstract = {Personal agent software is now in daily use in personal devices and in some organizational settings. While many advocate an agent sociality design paradigm that incorporates human-like features and social dialogues, it is unclear whether this is a good match for professionals who seek productivity instead of leisurely use. We conducted a 17-day field study of a prototype of a personal AI agent that helps employees find work-related information. Using log data, surveys, and interviews, we found individual differences in the preference for humanized social interactions (social-agent orientation), which led to different user needs and requirements for agent design. We also explored the effect of agent proactive interactions and found that they carried the risk of interruption, especially for users who were generally averse to interruptions at work. Further, we found that user differences in socialagent orientation and aversion to agent proactive interactions can be inferred from behavioral signals. Our results inform research into social agent design, proactive agent interaction, and personalization of AI agents.},
	language = {en},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 2016 {ACM} {Conference} on {Designing} {Interactive} {Systems}},
	publisher = {ACM},
	author = {Liao, Q. Vera and Davis, Matthew and Geyer, Werner and Muller, Michael and Shami, N. Sadat},
	month = jun,
	year = {2016},
	pages = {264--275},
}

@article{molich_improving_1990,
	title = {Improving a human-computer dialogue},
	volume = {33},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/77481.77486},
	doi = {10.1145/77481.77486},
	abstract = {A survey of seventy-seven highly motivated industrial designers and programmers indicates that the identification of specific, potential problems in a human-computer dialogue design is difficult.},
	language = {en},
	number = {3},
	urldate = {2022-06-29},
	journal = {Communications of the ACM},
	author = {Molich, Rolf and Nielsen, Jakob},
	month = mar,
	year = {1990},
	pages = {338--348},
}

@book{moore_conversational_2019,
	title = {Conversational {UX} {Design}: {A} {Practitioner}'s {Guide} to the {Natural} {Conversation} {Framework}},
	isbn = {978-1-4503-6301-3},
	shorttitle = {Conversational {UX} {Design}},
	url = {https://dl.acm.org/citation.cfm?id=3304087&picked=prox},
	urldate = {2022-06-29},
	publisher = {Association for Computing Machinery},
	author = {Moore, Robert J. and Arar, Raphael},
	month = may,
	year = {2019},
	doi = {10.1145/3304087},
}

@inproceedings{fischer_progressivity_2019,
	address = {Dublin, Ireland},
	title = {Progressivity for voice interface design},
	isbn = {978-1-4503-7187-2},
	url = {http://dl.acm.org/citation.cfm?doid=3342775.3342788},
	doi = {10.1145/3342775.3342788},
	language = {en},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 1st {International} {Conference} on {Conversational} {User} {Interfaces}  - {CUI} '19},
	publisher = {ACM Press},
	author = {Fischer, Joel E. and Reeves, Stuart and Porcheron, Martin and Sikveland, Rein Ove},
	year = {2019},
	pages = {1--8},
}

@inproceedings{li_when_2019,
	address = {Taipei Taiwan},
	title = {When {There} is {No} {Progress} with a {Task}-{Oriented} {Chatbot}: {A} {Conversation} {Analysis}},
	isbn = {978-1-4503-6825-4},
	shorttitle = {When {There} is {No} {Progress} with a {Task}-{Oriented} {Chatbot}},
	url = {https://dl.acm.org/doi/10.1145/3338286.3344407},
	doi = {10.1145/3338286.3344407},
	language = {en},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Li, Chi-Hsun and Chen, Ken and Chang, Yung-Ju},
	month = oct,
	year = {2019},
	pages = {1--6},
}

@inproceedings{yeh_how_2022,
	address = {New Orleans LA USA},
	title = {How to {Guide} {Task}-oriented {Chatbot} {Users}, and {When}: {A} {Mixed}-methods {Study} of {Combinations} of {Chatbot} {Guidance} {Types} and {Timings}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {How to {Guide} {Task}-oriented {Chatbot} {Users}, and {When}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3501941},
	doi = {10.1145/3491102.3501941},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yeh, Su-Fang and Wu, Meng-Hsin and Chen, Tze-Yu and Lin, Yen-Chun and Chang, XiJing and Chiang, You-Hsuan and Chang, Yung-Ju},
	month = apr,
	year = {2022},
	pages = {1--16},
}

@inproceedings{svenningsson_artificial_2019,
	address = {Kobe Japan},
	title = {Artificial {Intelligence} in {Conversational} {Agents}: {A} {Study} of {Factors} {Related} to {Perceived} {Humanness} in {Chatbots}},
	isbn = {978-1-4503-7263-3},
	shorttitle = {Artificial {Intelligence} in {Conversational} {Agents}},
	url = {https://dl.acm.org/doi/10.1145/3375959.3375973},
	doi = {10.1145/3375959.3375973},
	abstract = {Arti cial intelligence (AI) is gaining traction in service-oriented businesses in the form of chatbots. A chatbot is a popular type of social AI that uses natural language processing to communicate with users. Past studies have shown discrepancies in terms of whether or not a chatbot should communicate and behave like a human. This article aims to explore these discrepancies in order to provide a theoretical contribution of a list of factors related to perceived humanness in chatbots and how these may consequently lead to a positive user experience. The results suggest that a chatbot should have the following characteristics: avoiding small talk and maintaining a formal tone; identifying itself as a bot and asking how it can help; providing speci c information and articulating itself with sophisticated choices of words and well-constructed sentences; asking follow-up questions during decision-making processes and; providing an apology when the context is not comprehensible, followed by a question or a statement to dynamically move a conversation forward. These results may have implications for designers working in the eld of AI as well as for the wider debates and the broader discourse around the adoption of AI in society.},
	language = {en},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 2019 2nd {Artificial} {Intelligence} and {Cloud} {Computing} {Conference}},
	publisher = {ACM},
	author = {Svenningsson, Nina and Faraon, Montathar},
	month = dec,
	year = {2019},
	keywords = {AI, artificial intelligence, chatbot, conversation, design guideline, humanness, user experience},
	pages = {151--161},
}

@incollection{sugiyama_dialogue_2021,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Dialogue {Breakdown} {Detection} {Using} {BERT} with {Traditional} {Dialogue} {Features}},
	isbn = {9789811593239},
	url = {https://doi.org/10.1007/978-981-15-9323-9_39},
	abstract = {Despite of the significant improvements of Natural Language Processing with Neural networks such as machine reading comprehensions, chat-oriented dialogue systems sometimes generate inappropriate response utterances that cause dialogue breakdown because of the difficulty of generating utterances. If we can detect such inappropriate utterances and suppress them, dialogue systems can continue the dialogue easily.},
	language = {en},
	urldate = {2021-10-11},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}: 10th {International} {Workshop} on {Spoken} {Dialogue} {Systems}},
	publisher = {Springer},
	author = {Sugiyama, Hiroaki},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_39},
	pages = {419--427},
}

@article{przegalinska_bot_2019,
	series = {Digital {Transformation} \& {Disruption}},
	title = {In bot we trust: {A} new methodology of chatbot performance measures},
	volume = {62},
	issn = {0007-6813},
	shorttitle = {In bot we trust},
	url = {https://www.sciencedirect.com/science/article/pii/S000768131930117X},
	doi = {10.1016/j.bushor.2019.08.005},
	abstract = {Chatbots are used frequently in business to facilitate various processes, particularly those related to customer service and personalization. In this article, we propose novel methods of tracking human-chatbot interactions and measuring chatbot performance that take into consideration ethical concerns, particularly trust. Our proposed methodology links neuroscientific methods, text mining, and machine learning. We argue that trust is the focal point of successful human-chatbot interaction and assess how trust as a relevant category is being redefined with the advent of deep learning supported chatbots. We propose a novel method of analyzing the content of messages produced in human-chatbot interactions, using the Condor Tribefinder system we developed for text mining that is based on a machine learning classification engine. Our results will help build better social bots for interaction in business or commercial environments.},
	language = {en},
	number = {6},
	urldate = {2022-06-27},
	journal = {Business Horizons},
	author = {Przegalinska, Aleksandra and Ciechanowski, Leon and Stroz, Anna and Gloor, Peter and Mazurek, Grzegorz},
	month = nov,
	year = {2019},
	keywords = {Artificial intelligence, Chatbot performance, Chatbots, Customer experience, Customer trust, Human-computer interaction, Performance goals},
	pages = {785--797},
}

@incollection{liu_benchmarking_2021,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Benchmarking {Natural} {Language} {Understanding} {Services} for {Building} {Conversational} {Agents}},
	isbn = {9789811593239},
	url = {https://doi.org/10.1007/978-981-15-9323-9_15},
	abstract = {We have recently seen the emergence of several publicly available Natural Language Understanding (NLU) toolkits, which map user utterances to structured, but more abstract, Dialogue Act (DA) or Intent specifications, while making this process accessible to the lay developer. In this paper, we present the first wide coverage evaluation and comparison of some of the most popular NLU services, on a large, multi-domain (21 domains) dataset of 25 K user utterances that we have collected and annotated with Intent and Entity Type specifications and which will be released as part of this submission (https://github.com/xliuhw/NLU-Evaluation-Data). The results show that on Intent classification Watson significantly outperforms the other platforms, namely, Dialogflow, LUIS and Rasa; though these also perform well. Interestingly, on Entity Type recognition, Watson performs significantly worse due to its low Precision (At the time of producing the camera-ready version of this paper, we noticed the seemingly recent addition of a ‘Contextual Entity’ annotation tool to Watson, much like e.g. in Rasa. We’d threfore like to stress that this paper does not include an evaluation of this feature in Watson NLU.). Again, Dialogflow, LUIS and Rasa perform well on this task.},
	language = {en},
	urldate = {2022-06-27},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}: 10th {International} {Workshop} on {Spoken} {Dialogue} {Systems}},
	publisher = {Springer},
	author = {Liu, Xingkun and Eshghi, Arash and Swietojanski, Pawel and Rieser, Verena},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_15},
	pages = {165--183},
}

@book{marchi_increasing_2021,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}: 10th {International} {Workshop} on {Spoken} {Dialogue} {Systems}},
	volume = {714},
	isbn = {9789811593222 9789811593239},
	shorttitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}},
	url = {http://link.springer.com/10.1007/978-981-15-9323-9},
	language = {en},
	urldate = {2022-06-27},
	publisher = {Springer Singapore},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9},
}

@incollection{scharenborg_position_2021,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Position {Paper}: {Brain} {Signal}-{Based} {Dialogue} {Systems}},
	isbn = {9789811593239},
	shorttitle = {Position {Paper}},
	url = {https://doi.org/10.1007/978-981-15-9323-9_36},
	abstract = {This position paper focuses on the problem of building dialogue systems for people who have lost the ability to communicate via speech, e.g., patients of locked-in syndrome or severely disabled people. In order for such people to communicate to other people and computers, dialogue systems that are based on brain responses to (imagined) speech are needed. A speech-based dialogue system typically consists of an automatic speech recognition module and a speech synthesis module. In order to build a dialogue system that is able to work on the basis of brain signals, a system needs to be developed that is able to recognize speech imagined by a person and can synthesize speech from imagined speech. This paper proposes combining new and emerging technology on neural speech recognition and auditory stimulus construction from brain signals to build brain signal-based dialogue systems. Such systems have a potentially large impact on society.},
	language = {en},
	urldate = {2021-10-11},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}: 10th {International} {Workshop} on {Spoken} {Dialogue} {Systems}},
	publisher = {Springer},
	author = {Scharenborg, Odette and Hasegawa-Johnson, Mark},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_36},
	pages = {389--392},
}

@incollection{ishii_automatic_2021,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Automatic {Head}-{Nod} {Generation} {Using} {Utterance} {Text} {Considering} {Personality} {Traits}},
	isbn = {9789811593239},
	url = {https://doi.org/10.1007/978-981-15-9323-9_26},
	abstract = {We propose a model for generating head nods from an utterance text considering personality traits. We have been investigating the automatic generation of body motion, such as nodding, from utterance text in dialog agent systems. Human body motion varies greatly depending on personality. Therefore, it is important to appropriately generate body motion according to the personality of the dialog agent. To construct our model, we first compiled a Japanese corpus of 24 dialogues including utterance, nod information, and personality traits (Big Five) of participants. Our nod-generation model also estimates the presence, frequency, and depth during each phrase by using various types of language information extracted from utterance text and personality traits. We evaluated how well the model can generate and estimate nods based on individual personality traits. The results indicate that our model using language information and personality trails outperformed a model using only language information.},
	language = {en},
	urldate = {2021-10-11},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}: 10th {International} {Workshop} on {Spoken} {Dialogue} {Systems}},
	publisher = {Springer},
	author = {Ishii, Ryo and Katayama, Taichi and Higashinaka, Ryuichiro and Tomita, Junji},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_26},
	pages = {299--306},
}

@incollection{marchi_whats_2021,
	address = {Singapore},
	title = {What’s {Chat} and {Where} to {Find} {It}},
	volume = {714},
	isbn = {9789811593222 9789811593239},
	url = {http://link.springer.com/10.1007/978-981-15-9323-9_22},
	language = {en},
	urldate = {2021-10-11},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}},
	publisher = {Springer Singapore},
	author = {Gilmartin, Emer},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_22},
	note = {Series Title: Lecture Notes in Electrical Engineering},
	pages = {261--265},
}

@article{clinkenbeard_multimodal_2018,
	title = {Multimodal conversation analysis and usability studies: exploring human-technology interactions in multiparty contexts},
	volume = {6},
	issn = {2166-1642},
	shorttitle = {Multimodal conversation analysis and usability studies},
	url = {https://dl.acm.org/doi/10.1145/3282665.3282675},
	doi = {10.1145/3282665.3282675},
	abstract = {This article examines conversation analysis (CA) as a methodology for usability research for technologies used in multiparty contexts. Current laboratory-based usability practices often cannot account for how technologies are used in multi-participant interactions outside of the laboratory. In this article, I review new materialist approaches to usability and consider how CA might be integrated into this theoretical perspective. To do so, I present an example transcript of CA and review CA research on telemedicine in multiparty environments. I use this approach to argue that incorporating CA into a new materialist approach can help usability researchers to reconfigure the technical design of and the socio-material practices surrounding technologies.},
	language = {en},
	number = {2},
	urldate = {2022-06-29},
	journal = {Communication Design Quarterly},
	author = {Clinkenbeard, Mary},
	month = oct,
	year = {2018},
	pages = {103--113},
}

@article{chaves_how_2021,
	title = {How {Should} {My} {Chatbot} {Interact}? {A} {Survey} on {Social} {Characteristics} in {Human}–{Chatbot} {Interaction} {Design}},
	volume = {37},
	issn = {1044-7318},
	shorttitle = {How {Should} {My} {Chatbot} {Interact}?},
	url = {https://doi.org/10.1080/10447318.2020.1841438},
	doi = {10.1080/10447318.2020.1841438},
	abstract = {Chatbots’ growing popularity has brought new challenges to HCI, having changed the patterns of human interactions with computers. The increasing need to approximate conversational interaction styles raises expectations for chatbots to present social behaviors that are habitual in human–human communication. In this survey, we argue that chatbots should be enriched with social characteristics that cohere with users’ expectations, ultimately avoiding frustration and dissatisfaction. We bring together the literature on disembodied, text-based chatbots to derive a conceptual model of social characteristics for chatbots. We analyzed 56 papers from various domains to understand how social characteristics can benefit human–chatbot interactions and identify the challenges and strategies to designing them. Additionally, we discussed how characteristics may influence one another. Our results provide relevant opportunities to both researchers and designers to advance human–chatbot interactions.},
	number = {8},
	urldate = {2022-06-27},
	journal = {International Journal of Human–Computer Interaction},
	author = {Chaves, Ana Paula and Gerosa, Marco Aurelio},
	month = may,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10447318.2020.1841438},
	pages = {729--758},
}

@inproceedings{caselli_guiding_2021,
	address = {Online},
	title = {Guiding {Principles} for {Participatory} {Design}-inspired {Natural} {Language} {Processing}},
	url = {https://aclanthology.org/2021.nlp4posimpact-1.4},
	doi = {10.18653/v1/2021.nlp4posimpact-1.4},
	abstract = {We introduce 9 guiding principles to integrate Participatory Design (PD) methods in the development of Natural Language Processing (NLP) systems. The adoption of PD methods by NLP will help to alleviate issues concerning the development of more democratic, fairer, less-biased technologies to process natural language data. This short paper is the outcome of an ongoing dialogue between designers and NLP experts and adopts a non-standard format following previous work by Traum (2000); Bender (2013); Abzianidze and Bos (2019). Every section is a guiding principle. While principles 1–3 illustrate assumptions and methods that inform community-based PD practices, we used two fictional design scenarios (Encinas and Blythe, 2018), which build on top of situations familiar to the authors, to elicit the identification of the other 6. Principles 4–6 describes the impact of PD methods on the design of NLP systems, targeting two critical aspects: data collection \& annotation, and the deployment \& evaluation. Finally, principles 7–9 guide a new reflexivity of the NLP research with respect to its context, actors and participants, and aims. We hope this guide will offer inspiration and a road-map to develop a new generation of PD-inspired NLP.},
	urldate = {2022-06-23},
	booktitle = {Proceedings of the 1st {Workshop} on {NLP} for {Positive} {Impact}},
	publisher = {Association for Computational Linguistics},
	author = {Caselli, Tommaso and Cibin, Roberto and Conforti, Costanza and Encinas, Enrique and Teli, Maurizio},
	month = aug,
	year = {2021},
	pages = {27--35},
}

@inproceedings{koh_discourse_2021,
	address = {Bilbao (online) Spain},
	title = {Discourse {Analysis} in {Voice} {User} {Interface} {Research}: {Examining} {Current} and {Future} {Applications} of {Conversation} {Analysis} and {Interactional} {Sociolinguistics}},
	isbn = {978-1-4503-8998-3},
	shorttitle = {Discourse {Analysis} in {Voice} {User} {Interface} {Research}},
	url = {https://dl.acm.org/doi/10.1145/3469595.3469622},
	doi = {10.1145/3469595.3469622},
	language = {en},
	urldate = {2022-06-29},
	booktitle = {{CUI} 2021 - 3rd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {ACM},
	author = {Koh, Jungyoon},
	month = jul,
	year = {2021},
	pages = {1--5},
}

@inproceedings{siegert_discourse_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Discourse {Particles} in {Human}-{Human} and {Human}-{Computer} {Interaction} – {Analysis} and {Evaluation}},
	isbn = {978-3-319-39510-4},
	doi = {10.1007/978-3-319-39510-4_11},
	abstract = {Discourse particles are verifiably used in both human-human interaction (HHI) and human-computer interaction (HCI). In both types of interaction form-function-relations could be confirmed. Also correlations with specific subject characteristics, personality traits and the use of these particles could be uncovered. But these investigations are performed on separated datasets containing either HHI or HCI. Moreover, the subjects analyzed in both interaction types are not the same and thus, direct connections could not be made.},
	language = {en},
	booktitle = {Human-{Computer} {Interaction}. {Theory}, {Design}, {Development} and {Practice}},
	publisher = {Springer International Publishing},
	author = {Siegert, Ingo and Krüger, Julia and Haase, Matthias and Lotz, Alicia Flores and Günther, Stephan and Frommer, Jörg and Rösner, Dietmar and Wendemuth, Andreas},
	editor = {Kurosu, Masaaki},
	year = {2016},
	pages = {105--117},
}

@article{hermawati_establishing_2016,
	title = {Establishing usability heuristics for heuristics evaluation in a specific domain: {Is} there a consensus?},
	volume = {56},
	issn = {0003-6870},
	shorttitle = {Establishing usability heuristics for heuristics evaluation in a specific domain},
	url = {https://www.sciencedirect.com/science/article/pii/S0003687015301162},
	doi = {10.1016/j.apergo.2015.11.016},
	abstract = {Heuristics evaluation is frequently employed to evaluate usability. While general heuristics are suitable to evaluate most user interfaces, there is still a need to establish heuristics for specific domains to ensure that their specific usability issues are identified. This paper presents a comprehensive review of 70 studies related to usability heuristics for specific domains. The aim of this paper is to review the processes that were applied to establish heuristics in specific domains and identify gaps in order to provide recommendations for future research and area of improvements. The most urgent issue found is the deficiency of validation effort following heuristics proposition and the lack of robustness and rigour of validation method adopted. Whether domain specific heuristics perform better or worse than general ones is inconclusive due to lack of validation quality and clarity on how to assess the effectiveness of heuristics for specific domains. The lack of validation quality also affects effort in improving existing heuristics for specific domain as their weaknesses are not addressed.},
	language = {en},
	urldate = {2022-06-29},
	journal = {Applied Ergonomics},
	author = {Hermawati, Setia and Lawson, Glyn},
	month = sep,
	year = {2016},
	keywords = {Heuristics evaluation, Specific domain, Usability},
	pages = {34--51},
}

@incollection{matthews_conversation_2014,
	title = {Conversation {Analysis} and {Design}},
	isbn = {978-1-4051-9843-1},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781405198431.wbeal1306},
	abstract = {Since the mid-1980s, the design of various technologies such as user interfaces for photocopiers, surgical monitoring alarms, London Underground control systems, videoconferencing software, and interactive museum exhibits has benefited from investigations informed by conversation analysis (CA). The exemplar studies which form the basis of this entry are best understood as contributions of CA-informed work, rather than contributions to the discipline of CA.},
	language = {en},
	urldate = {2022-06-29},
	booktitle = {The {Encyclopedia} of {Applied} {Linguistics}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Matthews, Ben},
	year = {2014},
	doi = {10.1002/9781405198431.wbeal1306},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781405198431.wbeal1306},
}

@article{folstad_investigating_2021,
	title = {Investigating the user experience of customer service chatbot interaction: a framework for qualitative analysis of chatbot dialogues},
	volume = {6},
	issn = {2366-0147},
	shorttitle = {Investigating the user experience of customer service chatbot interaction},
	url = {https://doi.org/10.1007/s41233-021-00046-5},
	doi = {10.1007/s41233-021-00046-5},
	abstract = {The uptake of chatbots for customer service depends on the user experience. For such chatbots, user experience in particular concerns whether the user is provided relevant answers to their queries and the chatbot interaction brings them closer to resolving their problem. Dialogue data from interactions between users and chatbots represents a potentially valuable source of insight into user experience. However, there is a need for knowledge of how to make use of these data. Motivated by this, we present a framework for qualitative analysis of chatbot dialogues in the customer service domain. The framework has been developed across several studies involving two chatbots for customer service, in collaboration with the chatbot hosts. We present the framework and illustrate its application with insights from three case examples. Through the case findings, we show how the framework may provide insight into key drivers of user experience, including response relevance and dialogue helpfulness (Case 1), insight to drive chatbot improvement in practice (Case 2), and insight of theoretical and practical relevance for understanding chatbot user types and interaction patterns (Case 3). On the basis of the findings, we discuss the strengths and limitations of the framework, its theoretical and practical implications, and directions for future work.},
	language = {en},
	number = {1},
	urldate = {2022-06-29},
	journal = {Quality and User Experience},
	author = {Følstad, Asbjørn and Taylor, Cameron},
	month = aug,
	year = {2021},
	pages = {6},
}

@inproceedings{woodruff_practical_2002,
	address = {New York, NY, USA},
	series = {{DIS} '02},
	title = {Practical strategies for integrating a conversation analyst in an iterative design process},
	isbn = {978-1-58113-515-2},
	url = {https://doi.org/10.1145/778712.778748},
	doi = {10.1145/778712.778748},
	abstract = {We present a case study of an iterative design process that includes a conversation analyst. We discuss potential benefits of conversation analysis for design, and we describe our strategies for integrating the conversation analyst in the design process. Since the analyst on our team had no previous exposure to design or engineering, and none of the other members of our team had any experience with conversation analysis, we needed to build a foundation for our interaction. One of our key strategies was to pair the conversation analyst with a designer in a highly interactive collaboration. Our tactics have been effective on our project, leading to valuable results that we believe we could not have obtained using another method. We hope that this paper can serve as a practical guide to those interested in establishing a productive and efficient working relationship between a conversation analyst and the other members of a design team.},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 4th conference on {Designing} interactive systems: processes, practices, methods, and techniques},
	publisher = {Association for Computing Machinery},
	author = {Woodruff, Allison and Szymanski, Margaret H. and Grinter, Rebecca E. and Aoki, Paul M.},
	month = jun,
	year = {2002},
	pages = {255--264},
}

@incollection{li_conversation_2020,
	address = {New York, NY, USA},
	title = {A {Conversation} {Analysis} of {Non}-{Progress} and {Coping} {Strategies} with a {Banking} {Task}-{Oriented} {Chatbot}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376209},
	abstract = {Task-oriented chatbots are becoming popular alternatives for fulfilling users' needs, but few studies have investigated how users cope with conversational 'non-progress' (NP) in their daily lives. Accordingly, we analyzed a three-month conversation log between 1,685 users and a task-oriented banking chatbot. In this data, we observed 12 types of conversational NP; five types of content that was unexpected and challenging for the chatbot to recognize; and 10 types of coping strategies. Moreover, we identified specific relationships between NP types and strategies, as well as signs that users were about to abandon the chatbot, including 1) three consecutive incidences of NP, 2) consecutive use of message reformulation or switching subjects, and 3) using message reformulation as the final strategy. Based on these findings, we provide design recommendations for task-oriented chatbots, aimed at reducing NP, guiding users through such NP, and improving user experiences to reduce the cessation of chatbot use.},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Li, Chi-Hsun and Yeh, Su-Fang and Chang, Tang-Jie and Tsai, Meng-Hsuan and Chen, Ken and Chang, Yung-Ju},
	month = apr,
	year = {2020},
	pages = {1--12},
}

@incollection{kurosu_notitle_2022,
	address = {Cham},
	series = {Human-computer interaction : thematic area, {HCI} 2022, held as part of the 24th international conference, {HCII} 2022, virtual event, {June} 26 - {July} 1,2022 : proceedings / {Masaaki} {Kurosu} ({Ed}.)},
	isbn = {978-3-031-05411-2},
	language = {eng},
	number = {Part 3},
	booktitle = {Human-{Computer} {Interaction}: {User} experience and behavior},
	publisher = {Springer},
	editor = {Kurosu, Masaaki},
	year = {2022},
	note = {Meeting Name: HCI International},
}

@book{kurosu_human-computer_2022,
	address = {Cham},
	series = {Human-computer interaction : thematic area, {HCI} 2022, held as part of the 24th international conference, {HCII} 2022, virtual event, {June} 26 - {July} 1,2022 : proceedings / {Masaaki} {Kurosu} ({Ed}.)},
	title = {Human-{Computer} {Interaction}: {User} experience and behavior},
	isbn = {978-3-031-05411-2},
	language = {eng},
	number = {Part 3},
	publisher = {Springer},
	editor = {Kurosu, Masaaki},
	year = {2022},
	note = {Meeting Name: HCI International},
}

@inproceedings{mafra_defining_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Defining {Requirements} for the {Development} of {Useful} and {Usable} {Chatbots}: {An} {Analysis} of {Quality} {Attributes} from {Academy} and {Industry}},
	isbn = {978-3-031-05412-9},
	shorttitle = {Defining {Requirements} for the {Development} of {Useful} and {Usable} {Chatbots}},
	doi = {10.1007/978-3-031-05412-9_33},
	abstract = {Chatbots are conversational interfaces that enable human-like dialogue and can be designed in a textual chat format or a graphical interface with voice and embedding options. In the last year, there has been a significant growth in the emergence of chatbots in the market and this popularization has attracted the efforts of researchers to this area. Despite the existence of techniques to evaluate these tools, there is an urgent need to propose solutions that also support the chatbot design process. Currently, there is no knowledge of a specific list of requirements capable of supporting development teams in the process of designing these tools. In view of this, this directed study proposes a literature review aiming at deepening the knowledge about these tools and identifying important quality attributes in academic and industry sources. As a result, this directed study presents a list composed of 82 requirements related to Usefulness, Ease of Use and Presence to aid the design of these tools. These requirements presented in this study are useful to guide developers in the process of building quality chatbots, making this task less challenging and for researchers who aim to propose technologies that contribute to the development of better and better chatbots.},
	language = {en},
	booktitle = {Human-{Computer} {Interaction}. {User} {Experience} and {Behavior}},
	publisher = {Springer International Publishing},
	author = {Mafra, Malu and Nunes, Kennedy and Castro, Adailton and Lopes, Adriana and Oran, Ana Carolina and Braz Junior, Geraldo and Almeida, João and Paiva, Anselmo and Silva, Aristofanes and Rocha, Simara and Viana, Davi and Melo, Aurea and Barreto, Raimundo and Rivero, Luis},
	editor = {Kurosu, Masaaki},
	year = {2022},
	pages = {479--493},
}

@inproceedings{khemani_unpacking_2022,
	address = {New Orleans LA USA},
	title = {Unpacking {Practitioners}’ {Attitudes} {Towards} {Codifications} of {Design} {Knowledge} for {Voice} {User} {Interfaces}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517623},
	doi = {10.1145/3491102.3517623},
	language = {en},
	urldate = {2022-06-29},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Khemani, Krishika Haresh and Reeves, Stuart},
	month = apr,
	year = {2022},
	pages = {1--10},
}

@inproceedings{sugisaki_usability_2020,
	address = {New York, NY, USA},
	series = {{MuC} '20},
	title = {Usability guidelines and evaluation criteria for conversational user interfaces: a heuristic and linguistic approach},
	isbn = {978-1-4503-7540-5},
	shorttitle = {Usability guidelines and evaluation criteria for conversational user interfaces},
	url = {https://doi.org/10.1145/3404983.3405505},
	doi = {10.1145/3404983.3405505},
	abstract = {Even though conversational user interfaces (CUI) have been studied since the 1950s, it is not yet fully understood what makes them feel natural, intuitive and usable. As a result, their design and evaluation poses major challenges. In this paper, we discuss how CUIs are different from other forms of human computer interaction, and what challenges and opportunities arise from these differences. We provide an overview of relevant linguistic principles for a natural language conversation and look at established high-level usability heuristics to derive a set of 53 technology-agnostic checkpoints specifically for text-based CUIs (a.k.a chatbots). These checkpoints have been evaluated with 15 professionals and academics from the fields of User Experience, Natural Language Processing, Conversation Analysis and linguistics to examine content validity. The resulting list of checkpoints provides both guidelines for the design and criteria for the evaluation of chatbots.},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the {Conference} on {Mensch} und {Computer}},
	publisher = {Association for Computing Machinery},
	author = {Sugisaki, Kyoko and Bleiker, Andreas},
	month = sep,
	year = {2020},
	pages = {309--319},
}

@inproceedings{gu_human_2018,
	address = {New York, NY, USA},
	series = {{MM} '18},
	title = {Human {Conversation} {Analysis} {Using} {Attentive} {Multimodal} {Networks} with {Hierarchical} {Encoder}-{Decoder}},
	isbn = {978-1-4503-5665-7},
	url = {https://doi.org/10.1145/3240508.3240714},
	doi = {10.1145/3240508.3240714},
	abstract = {Human conversation analysis is challenging because the meaning can be expressed through words, intonation, or even body language and facial expression. We introduce a hierarchical encoder-decoder structure with attention mechanism for conversation analysis. The hierarchical encoder learns word-level features from video, audio, and text data that are then formulated into conversation-level features. The corresponding hierarchical decoder is able to predict different attributes at given time instances. To integrate multiple sensory inputs, we introduce a novel fusion strategy with modality attention. We evaluated our system on published emotion recognition, sentiment analysis, and speaker trait analysis datasets. Our system outperformed previous state-of-the-art approaches in both classification and regressions tasks on three datasets. We also outperformed previous approaches in generalization tests on two commonly used datasets. We achieved comparable performance in predicting co-existing labels using the proposed model instead of multiple individual models. In addition, the easily-visualized modality and temporal attention demonstrated that the proposed attention mechanism helps feature selection and improves model interpretability.},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 26th {ACM} international conference on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Gu, Yue and Li, Xinyu and Huang, Kaixiang and Fu, Shiyu and Yang, Kangning and Chen, Shuhong and Zhou, Moliang and Marsic, Ivan},
	year = {2018},
	pages = {537--545},
}

@inproceedings{alloatti_conversation_2021,
	title = {Conversation {Analysis}, {Repair} {Sequences} and {Human} {Computer} {Interaction}-{A} theoretical framework and an empirical proposal of action},
	booktitle = {The {Fourth} {Workshop} on {Reasoning} and {Learning} for {Human}-{Machine} {Dialogues} at the {Thirty}-{Fifth} {AAAI} {Conference} on {Artificial} {Intelligence} ({AAAI}-21)},
	author = {Alloatti, Francesca and Di Caro, Luigi and Bosca, Alessio},
	year = {2021},
	pages = {1--4},
}

@article{reddy_coqa_2019,
	title = {{CoQA}: {A} {Conversational} {Question} {Answering} {Challenge}},
	volume = {7},
	issn = {2307-387X},
	shorttitle = {{CoQA}},
	url = {https://doi.org/10.1162/tacl_a_00266},
	doi = {10.1162/tacl_a_00266},
	abstract = {Humans gather information through conversations involving a series of interconnected questions and answers. For machines to assist in information gathering, it is therefore essential to enable them to answer conversational questions. We introduce CoQA, a novel dataset for building Conversational Question Answering systems. Our dataset contains 127k questions with answers, obtained from 8k conversations about text passages from seven diverse domains. The questions are conversational, and the answers are free-form text with their corresponding evidence highlighted in the passage. We analyze CoQA in depth and show that conversational questions have challenging phenomena not present in existing reading comprehension datasets (e.g., coreference and pragmatic reasoning). We evaluate strong dialogue and reading comprehension models on CoQA. The best system obtains an F1 score of 65.4\%, which is 23.4 points behind human performance (88.8\%), indicating that there is ample room for improvement. We present CoQA as a challenge to the community at https://stanfordnlp.github.io/coqa.},
	urldate = {2022-06-29},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Reddy, Siva and Chen, Danqi and Manning, Christopher D.},
	month = may,
	year = {2019},
	pages = {249--266},
}

@inproceedings{liu_how_2016,
	address = {Austin, Texas},
	title = {How {NOT} {To} {Evaluate} {Your} {Dialogue} {System}: {An} {Empirical} {Study} of {Unsupervised} {Evaluation} {Metrics} for {Dialogue} {Response} {Generation}},
	shorttitle = {How {NOT} {To} {Evaluate} {Your} {Dialogue} {System}},
	url = {https://aclanthology.org/D16-1230},
	doi = {10.18653/v1/D16-1230},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Chia-Wei and Lowe, Ryan and Serban, Iulian and Noseworthy, Mike and Charlin, Laurent and Pineau, Joelle},
	month = nov,
	year = {2016},
	pages = {2122--2132},
}

@misc{walker_paradise_1997,
	title = {{PARADISE}: {A} {Framework} for {Evaluating} {Spoken} {Dialogue} {Agents}},
	shorttitle = {{PARADISE}},
	url = {http://arxiv.org/abs/cmp-lg/9704004},
	doi = {10.48550/arXiv.cmp-lg/9704004},
	abstract = {This paper presents PARADISE (PARAdigm for DIalogue System Evaluation), a general framework for evaluating spoken dialogue agents. The framework decouples task requirements from an agent's dialogue behaviors, supports comparisons among dialogue strategies, enables the calculation of performance over subdialogues and whole dialogues, specifies the relative contribution of various factors to performance, and makes it possible to compare agents performing different tasks by normalizing for task complexity.},
	urldate = {2022-06-29},
	publisher = {arXiv},
	author = {Walker, Marilyn A. and Litman, Diane J. and Kamm, Candace A. and Abella, Alicia},
	month = apr,
	year = {1997},
	note = {arXiv:cmp-lg/9704004},
}

@inproceedings{shawar_different_2007,
	address = {Rochester, NY},
	title = {Different measurement metrics to evaluate a chatbot system},
	url = {https://aclanthology.org/W07-0313},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the {Workshop} on {Bridging} the {Gap}: {Academic} and {Industrial} {Research} in {Dialog} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Shawar, Bayan Abu and Atwell, Eric},
	month = apr,
	year = {2007},
	pages = {89--96},
}

@article{wei_evaluating_2018,
	title = {Evaluating {Speech}-{Based} {Smart} {Devices} {Using} {New} {Usability} {Heuristics}},
	volume = {17},
	issn = {1558-2590},
	doi = {10.1109/MPRV.2018.022511249},
	abstract = {We developed a set of 17 usability heuristics for speech-based smart devices. An expert evaluation of three popular devices shows that these heuristics can be used to uncover existing usability problems as well as help design new interfaces.},
	number = {2},
	journal = {IEEE Pervasive Computing},
	author = {Wei, Zhuxiaona and Landay, James A.},
	month = apr,
	year = {2018},
	note = {Conference Name: IEEE Pervasive Computing},
	pages = {84--96},
}

@book{norman_design_2013,
	address = {New York, New York},
	edition = {Revised and expanded edition},
	title = {The design of everyday things},
	isbn = {978-0-465-05065-9},
	abstract = {"Even the smartest among us can feel inept as we fail to figure out which light switch or oven burner to turn on, or whether to push, pull, or slide a door. The fault, argues this ingenious-even liberating-book, lies not in ourselves, but in product design that ignores the needs of users and the principles of cognitive psychology. The problems range from ambiguous and hidden controls to arbitrary relationships between controls and functions, coupled with a lack of feedback or other assistance and unreasonable demands on memorization. The Design of Everyday Things shows that good, usable design is possible. The rules are simple: make things visible, exploit natural relationships that couple function and control, and make intelligent use of constraints. The goal: guide the user effortlessly to the right action on the right control at the right time. In this entertaining and insightful analysis, cognitive scientist Don Norman hails excellence of design as the most important key to regaining the competitive edge in influencing consumer behavior. Now fully expanded and updated, with a new introduction by the author, The Design of Everyday Things is a powerful primer on how-and why-some products satisfy customers while others only frustrate them. "--},
	publisher = {Basic Books},
	author = {Norman, Donald A.},
	year = {2013},
}

@inproceedings{finch_towards_2020,
	address = {1st virtual meeting},
	title = {Towards {Unified} {Dialogue} {System} {Evaluation}: {A} {Comprehensive} {Analysis} of {Current} {Evaluation} {Protocols}},
	shorttitle = {Towards {Unified} {Dialogue} {System} {Evaluation}},
	url = {https://aclanthology.org/2020.sigdial-1.29},
	abstract = {As conversational AI-based dialogue management has increasingly become a trending topic, the need for a standardized and reliable evaluation procedure grows even more pressing. The current state of affairs suggests various evaluation protocols to assess chat-oriented dialogue management systems, rendering it difficult to conduct fair comparative studies across different approaches and gain an insightful understanding of their values. To foster this research, a more robust evaluation protocol must be set in place. This paper presents a comprehensive synthesis of both automated and human evaluation methods on dialogue systems, identifying their shortcomings while accumulating evidence towards the most effective evaluation dimensions. A total of 20 papers from the last two years are surveyed to analyze three types of evaluation protocols: automated, static, and interactive. Finally, the evaluation dimensions used in these papers are compared against our expert evaluation on the system-user dialogue data collected from the Alexa Prize 2020.},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 21th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Finch, Sarah E. and Choi, Jinho D.},
	month = jul,
	year = {2020},
	pages = {236--245},
}

@inproceedings{zhang_dynaeval_2021,
	address = {Online},
	title = {{DynaEval}: {Unifying} {Turn} and {Dialogue} {Level} {Evaluation}},
	shorttitle = {{DynaEval}},
	url = {https://aclanthology.org/2021.acl-long.441},
	doi = {10.18653/v1/2021.acl-long.441},
	abstract = {A dialogue is essentially a multi-turn interaction among interlocutors. Effective evaluation metrics should reflect the dynamics of such interaction. Existing automatic metrics are focused very much on the turn-level quality, while ignoring such dynamics. To this end, we propose DynaEval, a unified automatic evaluation framework which is not only capable of performing turn-level evaluation, but also holistically considers the quality of the entire dialogue. In DynaEval, the graph convolutional network (GCN) is adopted to model a dialogue in totality, where the graph nodes denote each individual utterance and the edges represent the dependency between pairs of utterances. A contrastive loss is then applied to distinguish well-formed dialogues from carefully constructed negative samples. Experiments show that DynaEval significantly outperforms the state-of-the-art dialogue coherence model, and correlates strongly with human judgements across multiple dialogue evaluation aspects at both turn and dialogue level.},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Chen and Chen, Yiming and D'Haro, Luis Fernando and Zhang, Yan and Friedrichs, Thomas and Lee, Grandee and Li, Haizhou},
	month = aug,
	year = {2021},
	pages = {5676--5689},
}

@phdthesis{deriu_evaluation_2021,
	address = {PhD dissertation},
	title = {Evaluation of {Dialogue} {Systems}},
	url = {https://www.zora.uzh.ch/id/eprint/208088},
	language = {en},
	urldate = {2022-06-29},
	school = {University of Zurich},
	author = {Deriu, Jan},
	year = {2021},
	doi = {10.5167/UZH-208088},
}

@inproceedings{deriu_spot_2020,
	address = {Online},
	title = {Spot {The} {Bot}: {A} {Robust} and {Efficient} {Framework} for the {Evaluation} of {Conversational} {Dialogue} {Systems}},
	shorttitle = {Spot {The} {Bot}},
	url = {https://aclanthology.org/2020.emnlp-main.326},
	doi = {10.18653/v1/2020.emnlp-main.326},
	abstract = {The lack of time efficient and reliable evalu-ation methods is hampering the development of conversational dialogue systems (chat bots). Evaluations that require humans to converse with chat bots are time and cost intensive, put high cognitive demands on the human judges, and tend to yield low quality results. In this work, we introduce Spot The Bot, a cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots. Human judges then only annotate for each entity in a conversation whether they think it is human or not (assuming there are humans participants in these conversations). These annotations then allow us to rank chat bots regarding their ability to mimic conversational behaviour of humans. Since we expect that all bots are eventually recognized as such, we incorporate a metric that measures which chat bot is able to uphold human-like be-havior the longest, i.e.Survival Analysis. This metric has the ability to correlate a bot's performance to certain of its characteristics (e.g.fluency or sensibleness), yielding interpretable results. The comparably low cost of our frame-work allows for frequent evaluations of chatbots during their evaluation cycle. We empirically validate our claims by applying Spot The Bot to three domains, evaluating several state-of-the-art chat bots, and drawing comparisonsto related work. The framework is released asa ready-to-use tool.},
	urldate = {2022-06-29},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Deriu, Jan and Tuggener, Don and von Däniken, Pius and Campos, Jon Ander and Rodrigo, Alvaro and Belkacem, Thiziri and Soroa, Aitor and Agirre, Eneko and Cieliebak, Mark},
	month = nov,
	year = {2020},
	pages = {3971--3984},
}

@article{reeves_future_2016,
	title = {The {Future} as a {Design} {Problem}},
	volume = {32},
	issn = {0747-9360},
	url = {https://doi.org/10.1162/DESI_a_00395},
	doi = {10.1162/DESI_a_00395},
	abstract = {An often unacknowledged yet foundational problem for design is how ‘futures‘ are recruited for design practice. This problem saturates considerations of what could or should be designed. We distinguish two intertwined approaches to this: ‘pragmatic projection’, which tries to tie the future to the past, and ‘grand vision’, which ties the present to the future. We examine ubiquitous computing as a case study of how pragmatic projection and grand vision are practically expressed to direct and structure design decisions. We assess their implications and conclude by arguing that the social legitimacy of design futures should be increasingly integral to their construction.},
	number = {3},
	urldate = {2022-06-28},
	journal = {Design Issues},
	author = {Reeves, Stuart and Goulden, Murray and Dingwall, Robert},
	month = jul,
	year = {2016},
	pages = {6--17},
}

@misc{santos_is_2021,
	title = {Is my agent good enough? {Evaluating} {Embodied} {Conversational} {Agents} with {Long} and {Short}-term interactions},
	shorttitle = {Is my agent good enough?},
	url = {http://arxiv.org/abs/2110.00114},
	doi = {10.48550/arXiv.2110.00114},
	abstract = {The use of digital resources has been increasing in every instance of todays society, being it in business or even ludic purposes. Despite such ever increasing use of technologies as interfaces, in all fields, it seems that it lacks the importance of users perception in this context. This work aims to present a case study about the evaluation of ECAs. We propose a Long-Term Interaction (LTI) to evaluate our conversational agent effectiveness through the user perception and compare it with Short-Term Interactions (STIs), performed by three users. Results show that many different aspects of users perception about the chosen ECA (i.e. Arthur) could be evaluated in our case study, in particular that LTI and STI are both important in order to have a better understanding of ECA impact in UX.},
	urldate = {2022-06-28},
	publisher = {arXiv},
	author = {Santos, Juliane B. S. dos and Knob, Paulo Ricardo and Scherer, Victor Putrich and Musse, Soraia Raupp},
	month = sep,
	year = {2021},
	note = {arXiv:2110.00114 [cs]},
}

@inproceedings{castle-green_decision_2020,
	address = {Bilbao Spain},
	title = {Decision {Trees} as {Sociotechnical} {Objects} in {Chatbot} {Design}},
	isbn = {978-1-4503-7544-3},
	url = {https://dl.acm.org/doi/10.1145/3405755.3406133},
	doi = {10.1145/3405755.3406133},
	language = {en},
	urldate = {2022-06-28},
	booktitle = {Proceedings of the 2nd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {ACM},
	author = {Castle-Green, Teresa and Reeves, Stuart and Fischer, Joel E. and Koleva, Boriana},
	month = jul,
	year = {2020},
	pages = {1--3},
}

@inproceedings{avgustis_please_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {“{Please} {Connect} {Me} to a {Specialist}”: {Scrutinising} ‘{Recipient} {Design}’ in {Interaction} with an {Artificial} {Conversational} {Agent}},
	isbn = {978-3-030-85610-6},
	shorttitle = {“{Please} {Connect} {Me} to a {Specialist}”},
	doi = {10.1007/978-3-030-85610-6_10},
	abstract = {This paper explores how callers formulate information enquiries for an artificial conversational agent in a call centre and compares it with the way enquiries are addressed to human operators of the same call centre. It includes 60 call recordings with human operators and 103 call recordings with the artificial conversational agent, transcribed and analysed using the method of Conversation Analysis. We show that people formulate and reformulate their enquiries differently to an artificial agent, even though the goal in both cases is to get an answer to the same enquiry. When talking to the artificial conversational agent, callers produce short enquiries, similar to web searches. When connected to human operators, callers formulate longer enquiries which include many details. By analysing the differences in the way callers formulate their enquiries to robots and human operators, we show what callers expect artificial conversational agents to process. These expectations affect the way the enquiry is formulated and, as a result, operators and artificial agents encounter different types of problems they have to repair to understand the question correctly and find an answer to it. Our findings have interesting implications for Human Computer Interaction both in terms of “robot-recipient design” and “user-recipient design”.},
	language = {en},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2021},
	publisher = {Springer International Publishing},
	author = {Avgustis, Iuliia and Shirokov, Aleksandr and Iivari, Netta},
	editor = {Ardito, Carmelo and Lanzilotti, Rosa and Malizia, Alessio and Petrie, Helen and Piccinno, Antonio and Desolda, Giuseppe and Inkpen, Kori},
	year = {2021},
	pages = {155--176},
}

@article{schmidt-nielsen_conversational_1982,
	title = {A conversational test for comparing voice systems using working two-way communication links},
	volume = {30},
	issn = {0096-3518},
	doi = {10.1109/TASSP.1982.1163977},
	abstract = {A conversational test using live two-way communications provides a measure of the actual usability of voice systems, especially when voice quality is degraded. A conversational test developed at NRL was compared with two other communicability tests in a series of experiments using a variety of digital voice processors with data rates from 800 to 32 000 bits/s. All three tests ranked the voice processors very similarly, but they did not discriminate equally well among different processors. Other advantages and disadvantages of conversational test methods are discussed.},
	number = {6},
	journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
	author = {Schmidt-Nielsen, A. and Everett, S.},
	month = dec,
	year = {1982},
	note = {Conference Name: IEEE Transactions on Acoustics, Speech, and Signal Processing},
	pages = {853--863},
}

@article{nielsen_problems_1985,
	title = {Problems in evaluating the real-world usability of digital voice communication systems},
	volume = {17},
	issn = {1532-5970},
	url = {https://doi.org/10.3758/BF03214388},
	doi = {10.3758/BF03214388},
	abstract = {Digital voice communication systems are being used in a wide variety of applications. Human observers are used to measure the performance of computer voice systems. We also need to determine how losses in speech quality and intelligibility affect the performance of the communicator. This paper considers several situational variables that can affect the usability and acceptance of digital voice communication systems: task constraints, user experience, and communication environment. User experience and communication environment influence the acceptability of degraded voice systems; greater experience and field environments lead to higher acceptability ratings. However, performance measures, such as task completion time, are still adversely affected by lower voice quality.},
	language = {en},
	number = {2},
	urldate = {2022-06-28},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Nielsen, Astrid Schmidt},
	month = mar,
	year = {1985},
	pages = {226--234},
}

@article{watanabe_evaluating_1998,
	title = {Evaluating {Dialogue} {Strategies} under {Communication} {Errors} {Using} {Computer}-to-{Computer} {Simulation}},
	volume = {E81-D},
	issn = {, 0916-8532},
	url = {https://search.ieice.org/bin/summary.php?id=e81-d_9_1025&category=D&year=1998&lang=E&abst=},
	abstract = {In this paper, experimental results of evaluating dialogue strategies of confirmation with a noisy channel are presented. First, the types of errors in task-oriented dialogues are investigated and classified as communication, dialogue, knowledge, problem solving, or objective errors. Since the errors are of different levels, the methods for recovering from errors must be examined separately. We have investigated that the dialogue and knowledge errors generated by communication errors can be recovered through system confirmation with the user. In addition, we examined that the manner in which a system initiates dialogue, namely, dialogue strategies, might influence the cooperativity of their interactions depending on the frequency of confirmations and the amount of information conveyed. Furthermore, the choice of dialogue strategies will be influenced by the rate of occurrence of communication errors in a communication channel and related to the properties of the task, for example, the difficulty in achieving a goal or the frequency of the movement of initiatives. To verify these hypotheses, we prepared a testbed task, the Group Scheduling Task, and examined it through a computer-to-computer dialogue simulation in which one system took the part of a scheduling system and the other system acted as a user. In this simulation, erroneous input for the scheduling system was also developed. The user system was designed to act randomly so that it could simulate a real human user, while the scheduling system was devised to strictly follow a particular dialogue strategy of confirmation. The experimental results showed that a certain amount of confirmation was required to overcome errors when the rate of occurrence of communication errors was high, but that excessive confirmation did not serve to resolve errors, depending on the task involved.},
	number = {9},
	urldate = {2022-06-28},
	journal = {IEICE TRANSACTIONS on Information and Systems},
	author = {Watanabe, Taro and Araki, Masahiro and Doshita, Shuji},
	month = sep,
	year = {1998},
	note = {Publisher: The Institute of Electronics, Information and Communication Engineers},
	pages = {1025--1033},
}

@article{danieli_metrics_1995,
	title = {Metrics for {Evaluating} {Dialogue} {Strategies} in a {Spoken} {Language} {System}},
	abstract = {In this paper, wedescribe a set of metrics for the evaluation of different dialogue management strategies in an implementedreal-time spoken language system. The set of metrics we propose tries to offer useful insights in evaluatinghowparticular choices in the dialogue managemenctan affect the overall quality of the man-machindeialogue. The evaluation makesuse of established metrics: the transaction success, the contextual appropriateness of system answers, the calculation of normaland correction turns in a dialogue. Wealso define a newmetric, the implicit recovery, whichallows to measurethe ability of a dialogue managerto deal with errors by different levels of analysis. Wereport evaluation data from several experiments, and we comparetwodifferent approachesto dialoguerepair strategies using the set of metrics wearguefor.},
	language = {en},
	author = {Danieli, Morena and Gerbino, Elisabetta},
	year = {1995},
	pages = {6},
}

@inproceedings{paek_empirical_2001,
	title = {Empirical {Methods} for {Evaluating} {Dialog} {Systems}},
	url = {https://aclanthology.org/W01-0902},
	urldate = {2022-06-28},
	booktitle = {Proceedings of the {ACL} 2001 {Workshop} on {Evaluation} {Methodologies} for {Language} and {Dialogue} {Systems}},
	author = {Paek, Tim},
	year = {2001},
}

@inproceedings{mey_pushdown_1965,
	title = {Pushdown {Stores} and {Subscripts}},
	url = {https://aclanthology.org/C65-1019},
	urldate = {2022-06-28},
	booktitle = {{COLING} 1965},
	author = {Mey, Jacob},
	year = {1965},
}

@article{lew_social_2022,
	title = {Social {Scripts} and {Expectancy} {Violations}: {Evaluating} {Communication} with {Human} or {AI} {Chatbot} {Interactants}},
	volume = {0},
	issn = {1521-3269},
	shorttitle = {Social {Scripts} and {Expectancy} {Violations}},
	url = {https://doi.org/10.1080/15213269.2022.2084111},
	doi = {10.1080/15213269.2022.2084111},
	abstract = {As artificial intelligence (AI) agents like chatbots play larger roles in daily life, questions arise regarding how people evaluate their communication. Perspectives applying communication scripts to human-AI interactions propose that outcomes are determined by messages and the embedded cues therein. The expectancy violations perspective posits that message characteristics are less important than whether they are expected or unexpected. A pilot study established baseline expectancies about humans’ and chatbots’ conversational contingency and response latencies. A 2 (contingency: more/less contingent responses) × 2 (latency: fast/slow responses) × 2 (communicator identity: human/chatbot) experiment then tested predictions derived from human-human communication scripts and expectancy violations using textual variations in an e-commerce chat. Communicators showing greater conversational contingency and faster responses were most credible, whether they were human or chatbots, but chatbots were consistently less socially attractive than humans. Results show that humans and chatbots are evaluated similarly regarding the functional, but not the relational aspects of communication. There was greater support for the communication script perspective than the expectancy violations perspective regarding interactions with chatbots.},
	number = {0},
	urldate = {2022-06-27},
	journal = {Media Psychology},
	author = {Lew, Zijian and Walther, Joseph B.},
	month = jun,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/15213269.2022.2084111},
	pages = {1--16},
}

@inproceedings{yang_chatmatch_2022,
	address = {Dublin, Ireland},
	title = {{ChatMatch}: {Evaluating} {Chatbots} by {Autonomous} {Chat} {Tournaments}},
	shorttitle = {{ChatMatch}},
	url = {https://aclanthology.org/2022.acl-long.522},
	doi = {10.18653/v1/2022.acl-long.522},
	abstract = {Existing automatic evaluation systems of chatbots mostly rely on static chat scripts as ground truth, which is hard to obtain, and requires access to the models of the bots as a form of “white-box testing”. Interactive evaluation mitigates this problem but requires human involvement. In our work, we propose an interactive chatbot evaluation framework in which chatbots compete with each other like in a sports tournament, using flexible scoring metrics. This framework can efficiently rank chatbots independently from their model architectures and the domains for which they are trained.},
	urldate = {2022-06-27},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Yang, Ruolan and Li, Zitong and Tang, Haifeng and Zhu, Kenny},
	month = may,
	year = {2022},
	pages = {7579--7590},
}

@article{nazar_systematic_2021,
	title = {A {Systematic} {Review} of {Human}–{Computer} {Interaction} and {Explainable} {Artificial} {Intelligence} in {Healthcare} {With} {Artificial} {Intelligence} {Techniques}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3127881},
	abstract = {Artificial intelligence (AI) is one of the emerging technologies. In recent decades, artificial intelligence (AI) has gained widespread acceptance in a variety of fields, including virtual support, healthcare, and security. Human-Computer Interaction (HCI) is a field that has been combining AI and human-computer engagement over the past several years in order to create an interactive intelligent system for user interaction. AI, in conjunction with HCI, is being used in a variety of fields by employing various algorithms and employing HCI to provide transparency to the user, allowing them to trust the machine. The comprehensive examination of both the areas of AI and HCI, as well as their subfields, has been explored in this work. The main goal of this article was to discover a point of intersection between the two fields. The understanding of Explainable Artificial Intelligence (XAI), which is a linking point of HCI and XAI, was gained through a literature review conducted in this research. The literature survey encompassed themes identified in the literature (such as XAI and its areas, major XAI aims, and XAI problems and challenges). The study’s other major focus was on the use of AI, HCI, and XAI in healthcare. The poll also addressed the shortcomings in XAI in healthcare, as well as the field’s future potential. As a result, the literature indicates that XAI in healthcare is still a novel subject that has to be explored more in the future.},
	journal = {IEEE Access},
	author = {Nazar, Mobeen and Alam, Muhammad Mansoor and Yafi, Eiad and Su’ud, Mazliham Mohd},
	year = {2021},
	note = {Conference Name: IEEE Access},
	pages = {153316--153348},
}

@article{sanchez-adame_towards_2021,
	title = {Towards a {Set} of {Heuristics} for {Evaluating} {Chatbots}},
	volume = {19},
	issn = {1548-0992},
	doi = {10.1109/TLA.2021.9480145},
	abstract = {Chatbots are artificial intelligence tools that interact with people in different contexts. A chatbot can be useful to streamline daily processes, serve customers 24 hours a day, provide information about classes, among other things. The appearance of new development technologies has made creating a chatbot an increasingly fast and straightforward process, bringing this kind of applications to people who had never considered using them before. However, this speed in development can lead to specific problems, many of them caused by the lack of usability evaluations. Heuristic usability evaluations are user interface review processes carried out by experts and are an essential part of any assessment process. To date, there are no heuristics to evaluate the usability of chatbots. Therefore, this work proposes five usability heuristics in chatbots that come from the experience developing this type of applications, as well as from a broad review of state of the art. The set of heuristics was tested using a case study with the help of five experts, who evaluated an education-oriented chatbot. The results revealed that, although the proposed heuristics need refinement, they are an excellent first step in broadening the horizon of usability evaluations in chatbots.},
	number = {12},
	journal = {IEEE Latin America Transactions},
	author = {Sánchez-Adame, Luis Martín and Mendoza, Sonia and Urquiza, José and Rodríguez, José and Meneses-Viveros, Amilcar},
	month = dec,
	year = {2021},
	note = {Conference Name: IEEE Latin America Transactions},
	pages = {2037--2045},
}

@inproceedings{knote_towards_2018,
	address = {Portland, Oregon, USA},
	title = {Towards a {Pattern} {Language} for {Smart} {Personal} {Assistants}},
	url = {https://www.alexandria.unisg.ch/255499/},
	abstract = {Supporting users in their daily activities, thus, making their lives more comfortable, has long been a goal for consumer-oriented systems development. With the rise of smart personal assistants (SPAs), however, we have reached a new milestone along the path towards this goal. These systems assist their owners by providing personalized and context-dependent information and service. Today's implementations reach from conversational agents, such as Siri, Cortana or Google Assistant, over chatbots, which are primarily text-based, to cognitive assistants, which assist according to a user's current cognitive or emotional state. However, although both research and practice proceed with full pace, recurring design elements of SPAs have not yet been investigated. We hence propose a pattern language for smart personal assistants to guide further empirical and design efforts. Therefore, we review existing information systems, computer science and human-computer interaction literature to find recurring design characteristics among 115 different assistants. The resulting pattern language contains 22 patterns that specify the interaction behavior and the intelligence of smart personal assistants.},
	language = {de},
	urldate = {2022-06-27},
	booktitle = {Conference on {Pattern} {Languages} of {Programs} ({PLoP})},
	author = {Knote, Robin and Söllner, Matthias and Leimeister, Jan Marco},
	year = {2018},
}

@inproceedings{funk_usable_2020,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '20},
	title = {Usable and {Acceptable} {Response} {Delays} of {Conversational} {Agents} in {Automotive} {User} {Interfaces}},
	isbn = {978-1-4503-8065-2},
	url = {https://doi.org/10.1145/3409120.3410651},
	doi = {10.1145/3409120.3410651},
	abstract = {With an increasing ability to answer and fulfill user requests, voice-enabled Conversational Agents (CAs) are becoming more and more powerful. However, as the complexity of the requests increase, the time for the CAs to process and fulfill the tasks can become longer. In other cases where input prediction is available, some requests can be processed and answered even before the user is finished saying the command. However, the effects of these positive and negative delays in system response time are still under-explored. In this paper, we systematically analyze the effects of different response delays on usability and acceptability considering three common interaction techniques for voice-enabled CAs. Our results reveal that an unnaturally long positive delay in system response time leads users to assume that an error occurred, while a negative delay is perceived by the users as rude. Based on our findings, we present design guidelines for voice-enabled CAs.},
	urldate = {2022-06-27},
	booktitle = {12th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Funk, Markus and Cunningham, Carie and Kanver, Duygu and Saikalis, Christopher and Pansare, Rohan},
	month = sep,
	year = {2020},
	pages = {262--269},
}

@article{hu_dual_2021,
	title = {Dual humanness and trust in conversational {AI}: {A} person-centered approach},
	volume = {119},
	issn = {0747-5632},
	shorttitle = {Dual humanness and trust in conversational {AI}},
	url = {https://www.sciencedirect.com/science/article/pii/S0747563221000492},
	doi = {10.1016/j.chb.2021.106727},
	abstract = {Conversational Artificial Intelligence (AI) is digital agents that interact with users by natural language. To advance the understanding of trust in conversational AI, this study focused on two humanness factors manifested by conversational AI: speaking and listening. First, we explored users' heterogeneous perception patterns based on the two humanness factors. Next, we examined how this heterogeneity relates to trust in conversational AI. A two-stage survey was conducted to collect data. Latent profile analysis revealed three distinct patterns: para-human perception, para-machine perception, and asymmetric perception. Finite mixture modeling demonstrated that the benefit of humanizing AI's voice for competence-related trust can evaporate once AI's language understanding is perceived as poor. Interestingly, the asymmetry between humanness perceptions in speaking and listening can impede morality-related trust. By adopting a person-centered approach to address the relationship between dual humanness and user trust, this study contributes to the literature on trust in conversational AI and the practice of trust-inducing AI design.},
	language = {en},
	urldate = {2022-06-27},
	journal = {Computers in Human Behavior},
	author = {Hu, Peng and Lu, Yaobin and Gong, Yeming (Yale)},
	month = jun,
	year = {2021},
	pages = {106727},
}

@article{stein_matter_2020,
	title = {Matter over mind? {How} the acceptance of digital entities depends on their appearance, mental prowess, and the interaction between both},
	volume = {142},
	issn = {1071-5819},
	shorttitle = {Matter over mind?},
	url = {https://www.sciencedirect.com/science/article/pii/S1071581920300653},
	doi = {10.1016/j.ijhcs.2020.102463},
	abstract = {Digital technologies are advancing rapidly, growing to be more human-like and intelligent by the day. However, research shows that a machine's resemblance to humans can reach a critical level, which makes it seem uncanny to observers. While scholars have discussed this effect in terms of both human-like appearances and mental abilities, a potential interaction between the two aspects has hardly been addressed in literature. We designed a two-factorial experiment to overcome the identified research gap, introducing participants to digital agents with varying embodiment (text interface/human rendering) and mental capacity (simple algorithms/complex artificial intelligence). Our results show that the interaction of both factors indeed affects participants’ experience in a crucial way: Whereas an agent based on simple algorithms only evokes discomfort when embedded in a human-like body, the artificial intelligence is always perceived as eerie, regardless of its embodiment. Yet, additional findings raise doubts on the unidimensionality of participants’ affective response.},
	language = {en},
	urldate = {2022-06-27},
	journal = {International Journal of Human-Computer Studies},
	author = {Stein, Jan-Philipp and Appel, Markus and Jost, Alexandra and Ohler, Peter},
	month = oct,
	year = {2020},
	pages = {102463},
}

@book{jorge_interactive_2003,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Interactive {Systems}. {Design}, {Specification}, and {Verification}: 10th {International} {Workshop}, {DSV}-{IS} 2003, {Funchal}, {Madeira} {Island}, {Portugal}, {June} 11-13, 2003. {Revised} {Papers}},
	volume = {2844},
	isbn = {978-3-540-20159-5 978-3-540-39929-2},
	shorttitle = {Interactive {Systems}. {Design}, {Specification}, and {Verification}},
	url = {http://link.springer.com/10.1007/b13960},
	language = {en},
	urldate = {2022-06-27},
	publisher = {Springer Berlin Heidelberg},
	editor = {Jorge, Joaquim A. and Jardim Nunes, Nuno and Falcão e Cunha, João and Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan},
	year = {2003},
	doi = {10.1007/b13960},
}

@inproceedings{barbosa_designing_2003,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Designing and {Evaluating} {Interaction} as {Conversation}: {A} {Modeling} {Language} {Based} on {Semiotic} {Engineering}},
	isbn = {978-3-540-39929-2},
	shorttitle = {Designing and {Evaluating} {Interaction} as {Conversation}},
	doi = {10.1007/978-3-540-39929-2_2},
	abstract = {A number of design models have been proposed in the area of Human-Computer Interaction (HCI) to support user-centered system design. High-level, abstract task models and detailed interface specification languages are among the most widely used. However, the need for designing applications to run in a number of different devices and platforms presents new issues that must be addressed from a platform-separable perspective. In this paper, we show how an interaction-as-conversation metaphor may face this challenge, and present an interaction modeling language that allows designers to build a blueprint of the range of interactions that will be able to take place in the application. Our goal is twofold: to motivate the designers to reflect upon the interactive solution they are creating, and at the same time provide a skeleton interaction specification that may be easily instantiated for different platforms or devices.},
	language = {en},
	booktitle = {Interactive {Systems}. {Design}, {Specification}, and {Verification}},
	publisher = {Springer},
	author = {Barbosa, Simone Diniz Junqueira and de Paula, Maíra Greco},
	editor = {Jorge, Joaquim A. and Jardim Nunes, Nuno and Falcão e Cunha, João},
	year = {2003},
	pages = {16--33},
}

@inproceedings{guerini_methodology_2018,
	address = {Brussels, Belgium},
	title = {A {Methodology} for {Evaluating} {Interaction} {Strategies} of {Task}-{Oriented} {Conversational} {Agents}},
	url = {https://aclanthology.org/W18-5704},
	doi = {10.18653/v1/W18-5704},
	abstract = {In task-oriented conversational agents, more attention has been usually devoted to assessing task effectiveness, rather than to how the task is achieved. However, conversational agents are moving towards more complex and human-like interaction capabilities (e.g. the ability to use a formal/informal register, to show an empathetic behavior), for which standard evaluation methodologies may not suffice. In this paper, we provide a novel methodology to assess - in a completely controlled way - the impact on the quality of experience of agent's interaction strategies. The methodology is based on a within subject design, where two slightly different transcripts of the same interaction with a conversational agent are presented to the user. Through a series of pilot experiments we prove that this methodology allows fast and cheap experimentation/evaluation, focusing on aspects that are overlooked by current methods.},
	urldate = {2022-06-27},
	booktitle = {Proceedings of the 2018 {EMNLP} {Workshop} {SCAI}: {The} 2nd {International} {Workshop} on {Search}-{Oriented} {Conversational} {AI}},
	publisher = {Association for Computational Linguistics},
	author = {Guerini, Marco and Falcone, Sara and Magnini, Bernardo},
	month = oct,
	year = {2018},
	pages = {24--32},
}

@inproceedings{skarbez_initial_2011,
	title = {An initial exploration of conversational errors as a novel method for evaluating virtual human experiences},
	doi = {10.1109/VR.2011.5759489},
	abstract = {We present a new method for evaluating user experience in interactions with virtual humans (VHs). We code the conversational errors made by the VH. These errors, in addition to the duration of the interaction and the numbers of statements made by the participant and the VH, provide objective, quantitative data about the virtual social interaction. We applied this method to a set of previously collected interactions between medical students and VH patients and present preliminary results. The error metrics do not correlate with traditional measures of the quality of a virtual experience, e.g. presence and copresence questionnaires. The error metrics were significantly correlated with scores on the Maastricht Assessment of Simulated Patients (MaSP), a scenario-appropriate measure of simulation quality, suggesting further investigation is warranted.},
	booktitle = {2011 {IEEE} {Virtual} {Reality} {Conference}},
	author = {Skarbez, Richard and Kotranza, Aaron and Brooks, Frederick P. and Lok, Benjamin and Whitton, Mary C.},
	month = mar,
	year = {2011},
	note = {ISSN: 2375-5334},
	pages = {243--244},
}

@article{pelau_what_2021,
	title = {What makes an {AI} device human-like? {The} role of interaction quality, empathy and perceived psychological anthropomorphic characteristics in the acceptance of artificial intelligence in the service industry},
	volume = {122},
	issn = {0747-5632},
	shorttitle = {What makes an {AI} device human-like?},
	url = {https://www.sciencedirect.com/science/article/pii/S0747563221001783},
	doi = {10.1016/j.chb.2021.106855},
	abstract = {Intelligent AI devices have become a common presence in the business landscape, offering a wide range of services, from the medical sector to the hospitality industry. From an organizational perspective, AI devices have several advantages, by performing certain tasks quicker and more accurately in comparison to humans while at the same time being more cost-efficient. However, in order to maintain the high standards of a brand, they have to be accepted by consumers and deliver socially adequate performance. Therefore, it is important to determine the characteristics of AI devices which make them accepted and trusted by consumers. Based on the Computers as Social Actors (CASA) Theory, we have researched on the role of psychological anthropomorphic characteristics, perceived empathy, and interaction quality in the acceptance of AI devices in the service industry. The results show that anthropomorphic characteristics alone do not influence acceptance and trust towards AI devices. However, both perceived empathy and interaction quality mediate the relation between anthropomorphic characteristics and acceptance. A human-like AI device has higher acceptance when it has the ability to show empathy and interaction in relation to the human consumer. This result reveals the importance of developing forms of strong intelligence and empathetic behaviour in service robots and AI devices.},
	language = {en},
	urldate = {2022-06-27},
	journal = {Computers in Human Behavior},
	author = {Pelau, Corina and Dabija, Dan-Cristian and Ene, Irina},
	month = sep,
	year = {2021},
	pages = {106855},
}

@article{van_der_lee_human_2021,
	title = {Human evaluation of automatically generated text: {Current} trends and best practice guidelines},
	volume = {67},
	issn = {0885-2308},
	shorttitle = {Human evaluation of automatically generated text},
	url = {https://www.sciencedirect.com/science/article/pii/S088523082030084X},
	doi = {10.1016/j.csl.2020.101151},
	abstract = {Currently, there is little agreement as to how Natural Language Generation (NLG) systems should be evaluated, with a particularly high degree of variation in the way that human evaluation is carried out. This paper provides an overview of how (mostly intrinsic) human evaluation is currently conducted and presents a set of best practices, grounded in the literature. These best practices are also linked to the stages that researchers go through when conducting an evaluation research (planning stage; execution and release stage), and the specific steps in these stages. With this paper, we hope to contribute to the quality and consistency of human evaluations in NLG.},
	language = {en},
	urldate = {2022-06-27},
	journal = {Computer Speech \& Language},
	author = {van der Lee, Chris and Gatt, Albert and van Miltenburg, Emiel and Krahmer, Emiel},
	month = may,
	year = {2021},
	pages = {101151},
}

@article{ciechanowski_shades_2019,
	title = {In the shades of the uncanny valley: {An} experimental study of human–chatbot interaction},
	volume = {92},
	issn = {0167-739X},
	shorttitle = {In the shades of the uncanny valley},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X17312268},
	doi = {10.1016/j.future.2018.01.055},
	abstract = {This project has been carried out in the context of recent major developments in botics and more widespread usage of virtual agents in personal and professional sphere. The general purpose of the experiment was to thoroughly examine the character of the human–non-human interaction process. Thus, in the paper, we present a study of human–chatbot interaction, focusing on the affective responses of users to different types of interfaces with which they interact. The experiment consisted of two parts: measurement of psychophysiological reactions of chatbot users and a detailed questionnaire that focused on assessing interactions and willingness to collaborate with a bot. In the first quantitative stage, participants interacted with a chatbot, either with a simple text chatbot (control group) or an avatar reading its responses in addition to only presenting them on the screen (experimental group. We gathered the following psychophysiological data from participants: electromyography (EMG), respirometer (RSP), electrocardiography (ECG), and electrodermal activity (EDA). In the last, declarative stage, participants filled out a series of questionnaires related to the experience of interacting with (chat)bots and to the overall human–(chat)bot collaboration assessment. The theory of planned behaviour survey investigated attitude towards cooperation with chatbots in the future. The social presence survey checked how much the chatbot was considered to be a “real” person. The anthropomorphism scale measured the extent to which the chatbot seems humanlike. Our particular focus was on the so-called uncanny valley effect, consisting of the feeling of eeriness and discomfort towards a given medium or technology that frequently appears in various kinds of human–machine interactions. Our results show that participants were experiencing lesser uncanny effects and less negative affect in cooperation with a simpler text chatbot than with the more complex, animated avatar chatbot. The simple chatbot have also induced less intense psychophysiological reactions. Despite major developments in botics, the user’s affective responses towards bots have frequently been neglected. In our view, understanding the user’s side may be crucial for designing better chatbots in the future and, thus, can contribute to advancing the field of human–computer interaction.},
	language = {en},
	urldate = {2022-06-27},
	journal = {Future Generation Computer Systems},
	author = {Ciechanowski, Leon and Przegalinska, Aleksandra and Magnuski, Mikolaj and Gloor, Peter},
	month = mar,
	year = {2019},
	pages = {539--548},
}

@inproceedings{pereira_quality_2018,
	address = {New York, NY, USA},
	series = {{SAC} '18},
	title = {A quality analysis of facebook messenger's most popular chatbots},
	isbn = {978-1-4503-5191-1},
	url = {https://doi.org/10.1145/3167132.3167362},
	doi = {10.1145/3167132.3167362},
	abstract = {This work introduces a set of quality attributes for chatbots. The selection is grounded on scholarly but also reputed blog references from 2016 and 2017. In addition, attributes should be amenable to be extracted (semi) automatically. On these premises, we consider four attributes: "support of a minimal set of common commands", "foresee language variations in both inputs and ouput", "human-assistance provision" and "timeliness". These attributes are worked out for the 100 most popular chatbots in Facebook Messager. The aim is to look for correlations between these attributes and chatbot popularity in terms of number of "likes". Results show that there is no significance correlation with any of the attributes. However, the experiment come up with two main insights. First, the lack of common communication paterns that would permit users to move their experiences and expectations from one chatbot to another. Second, the existence of many programming errors that reflect that bot programming is still a nascent area.},
	urldate = {2022-06-27},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Pereira, Juanan and Díaz, Oscar},
	month = apr,
	year = {2018},
	pages = {2144--2150},
}

@inproceedings{morrissey_realness_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {‘{Realness}’ in {Chatbots}: {Establishing} {Quantifiable} {Criteria}},
	isbn = {978-3-642-39330-3},
	shorttitle = {‘{Realness}’ in {Chatbots}},
	doi = {10.1007/978-3-642-39330-3_10},
	abstract = {The aim of this research is to generate measurable evaluation criteria acceptable to chatbot users. Results of two studies are summarised. In the first, fourteen participants were asked to do a critical incident analysis of their transcriptions with an ELIZA-type chatbot. Results were content analysed, and yielded seven overall themes. In the second, these themes were made into statements of an attitude-like nature, and 20 participants chatted with five winning entrants in the 2011 Chatterbox Challenge and five which failed to place. Latent variable analysis reduced the themes to four, resulting in four subscales with strong reliability which discriminated well between the two categories of chatbots. Content analysis of freeform comments led to a proposal of four dimensions along which people judge the naturalness of a conversation with chatbots.},
	language = {en},
	booktitle = {Human-{Computer} {Interaction}. {Interaction} {Modalities} and {Techniques}},
	publisher = {Springer},
	author = {Morrissey, Kellie and Kirakowski, Jurek},
	editor = {Kurosu, Masaaki},
	year = {2013},
	pages = {87--96},
}

@article{jacquet_cooperation_2019,
	title = {Cooperation in {Online} {Conversations}: {The} {Response} {Times} as a {Window} {Into} the {Cognition} of {Language} {Processing}},
	volume = {10},
	issn = {1664-1078},
	shorttitle = {Cooperation in {Online} {Conversations}},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2019.00727},
	abstract = {Measuring the cognitive cost of interpreting the meaning of sentences in a conversation is a complex task, but it is also at the core of Sperber and Wilson's Relevance Theory. In cognitive sciences, the delay between a stimulus and its response is often used as an approximation of the cognitive cost. We have noticed that such a tool had not yet been used to measure the cognitive cost of interpreting the meaning of sentences in a free-flowing and interactive conversation. The following experiment tests the ability to discriminate between sentences with a high cognitive cost and sentences with a low cognitive cost using the response time of the participants during an online conversation in a protocol inspired by the Turing Test. We have used violations of Grice's Cooperative Principle to create conditions in which sentences with a high cognitive cost would be produced. We hypothesized that response times are directly correlated to the cognitive cost required to generate implicatures from a statement. Our results are coherent with the literature in the field and shed some new light on the effect of violations on the humanness of a conversational agent. We show that violations of the maxim of Relation had a particularly important impact on response times and the perceived humanness of a conversation partner. Violations of the first maxim of Quantity and the fourth maxim of Manner had a lesser impact, and only on male participants.},
	urldate = {2022-06-27},
	journal = {Frontiers in Psychology},
	author = {Jacquet, Baptiste and Baratgin, Jean and Jamet, Frank},
	year = {2019},
}

@inproceedings{owda_comprehensive_2021,
	address = {Cham},
	series = {Advances in {Intelligent} {Systems} and {Computing}},
	title = {A {Comprehensive} {Methodology} for {Evaluating} {Conversation}-{Based} {Interfaces} to {Relational} {Databases} ({C}-{BIRDs})},
	isbn = {978-3-030-55187-2},
	doi = {10.1007/978-3-030-55187-2_17},
	abstract = {Evaluation can be defined as a process of determining the significance of a research output. This is usually done by devising a well-structured study on this output using one or more evaluation measures in which a careful inspection is performed. This paper presents a review of evaluation techniques for Conversational Agents (CAs) and Natural Language Interfaces to Databases (NLIDBs). It then introduces the developed customized evaluation methodology for Conversation-Based Interface to Relational Databases (C-BIRDs). The evaluation methodology created has been divided into two groups of measures. The first is based on quantitative measures, including two measures: task success and dialogue length. The second group is based on a number of qualitative measures, including: prototype ease of use, naturalness of system responses, positive/negative emotion, appearance, text on screen, organization of information, and error message clarity. Then an elaboration is carried out on the devised methodology by adding a discussion and recommendations on the sample size, the experimental setup and the scaling in order to provide a comprehensive evaluation methodology for C-BIRDs. In conclusion the evaluation methodology created is better way for identifying the strengths and weaknesses of C-BIRDs in comparison to the usage of single measure evaluations.},
	language = {en},
	booktitle = {Intelligent {Systems} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Owda, Majdi and Owda, Amani Yousef and Gasir, Fathi},
	editor = {Arai, Kohei and Kapoor, Supriya and Bhatia, Rahul},
	year = {2021},
	pages = {196--208},
}

@inproceedings{guo_conversational_2017,
	title = {Conversational {Bootstrapping} and {Other} {Tricks} of a {Concierge} {Robot}},
	abstract = {We describe the effective use of online learning to enhance the conversational capabilities of a concierge robot that we have been developing over the last two years. The robot was designed to interact naturally with visitors and uses a speech recognition system in conjunction with a natural language classifier. The online learning component monitors interactions and collects explicit and implicit user feedback from a conversation and feeds it back to the classifier in the form of new class instances and adjusted threshold values for triggering the classes. In addition, it enables a trusted master to teach it new question-answer pairs via question-answer paraphrasing, and solicits help with maintaining question-answer-class relationships when needed, obviating the need for explicit programming. The system has been completely implemented and demonstrated using the SoftBank Robotics [34] humanoid robots Pepper and NAO, and the telepresence robot known as Double from Double Robotics [4].},
	booktitle = {2017 12th {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction} ({HRI}},
	author = {Guo, Shang and Dholakia, Mishal and Lenchner, Jonathan and Muta, Hidemasa and Connell, Jonathan},
	month = mar,
	year = {2017},
	note = {ISSN: 2167-2148},
	pages = {73--81},
}

@inproceedings{atiyah_evaluation_2019,
	title = {Evaluation of the {Naturalness} of {Chatbot} {Applications}},
	doi = {10.1109/JEEIT.2019.8717455},
	abstract = {Chatbots are intelligent machine-to-human conversation systems. The main benefit of developing and deploying a chatbot in any business domain is that it can behave as a personal assistant. A chatbot is expected to be close in efficiency of interaction to a human personnel in responding to customers questions. The aim of this study is to evaluate the performance and naturalness of interaction of chatbot applications. The performance of a personal chatbot has been compared to a human personal in order to evaluate the naturalness. The evaluation was made by conducting an experiment on two expert users using cognitive walkthrough method. Findings of the experiment suggests that the human-machine chatbot is able to be close to the human performance in terms of interaction, although in some minor cases, the human-human chat applications perform better.},
	booktitle = {2019 {IEEE} {Jordan} {International} {Joint} {Conference} on {Electrical} {Engineering} and {Information} {Technology} ({JEEIT})},
	author = {Atiyah, Ayah and Jusoh, Shaidah and Alghanim, Firas},
	month = apr,
	year = {2019},
	pages = {359--365},
}

@inproceedings{hung_towards_2009,
	title = {Towards a method for evaluating naturalness in conversational dialog systems},
	doi = {10.1109/ICSMC.2009.5345904},
	abstract = {The evaluation of conversational dialog systems has remained a controversial topic, as it is challenging to quantitatively assess how well a conversation agent performs, or how much better one is compared to another. Furthermore, one of the hurdles which remains elusive in this quandary is the definition of naturalness, as demonstrated by how well a dialog system can maintain a natural conversation flow devoid of perceived awkwardness. As a step towards defining the dimensions of effectiveness and naturalness in a dialog system, this paper identifies existing evaluation practices which are then expanded to develop a more suitable assessment vehicle. This method is then applied to the LifeLike virtual avatar project.},
	booktitle = {2009 {IEEE} {International} {Conference} on {Systems}, {Man} and {Cybernetics}},
	author = {Hung, Victor and Elvir, Miguel and Gonzalez, Avelino and DeMara, Ronald},
	month = oct,
	year = {2009},
	note = {ISSN: 1062-922X},
	pages = {1236--1241},
}

@incollection{marchi_chat-oriented_2021,
	address = {Singapore},
	title = {Chat-{Oriented} {Dialogue} {System} {That} {Uses} {User} {Information} {Acquired} {Through} {Dialogue} and {Its} {Long}-{Term} {Evaluation}},
	volume = {714},
	isbn = {9789811593222 9789811593239},
	url = {http://link.springer.com/10.1007/978-981-15-9323-9_19},
	language = {en},
	urldate = {2022-06-27},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}},
	publisher = {Springer Singapore},
	author = {Tsunomori, Yuiko and Higashinaka, Ryuichiro and Yoshimura, Takeshi and Isoda, Yoshinori},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_19},
	note = {Series Title: Lecture Notes in Electrical Engineering},
	pages = {227--238},
}

@incollection{marchi_dialogue_2021,
	address = {Singapore},
	title = {Dialogue {System} {Live} {Competition}: {Identifying} {Problems} with {Dialogue} {Systems} {Through} {Live} {Event}},
	volume = {714},
	isbn = {9789811593222 9789811593239},
	shorttitle = {Dialogue {System} {Live} {Competition}},
	url = {http://link.springer.com/10.1007/978-981-15-9323-9_16},
	language = {en},
	urldate = {2022-06-27},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}},
	publisher = {Springer Singapore},
	author = {Higashinaka, Ryuichiro and Funakoshi, Kotaro and Inaba, Michimasa and Tsunomori, Yuiko and Takahashi, Tetsuro and Akama, Reina},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_16},
	note = {Series Title: Lecture Notes in Electrical Engineering},
	pages = {185--199},
}

@inproceedings{braun_evaluating_2017,
	address = {Saarbrücken, Germany},
	title = {Evaluating {Natural} {Language} {Understanding} {Services} for {Conversational} {Question} {Answering} {Systems}},
	url = {https://aclanthology.org/W17-5522},
	doi = {10.18653/v1/W17-5522},
	abstract = {Conversational interfaces recently gained a lot of attention. One of the reasons for the current hype is the fact that chatbots (one particularly popular form of conversational interfaces) nowadays can be created without any programming knowledge, thanks to different toolkits and so-called Natural Language Understanding (NLU) services. While these NLU services are already widely used in both, industry and science, so far, they have not been analysed systematically. In this paper, we present a method to evaluate the classification performance of NLU services. Moreover, we present two new corpora, one consisting of annotated questions and one consisting of annotated questions with the corresponding answers. Based on these corpora, we conduct an evaluation of some of the most popular NLU services. Thereby we want to enable both, researchers and companies to make more educated decisions about which service they should use.},
	urldate = {2022-06-27},
	booktitle = {Proceedings of the 18th {Annual} {SIGdial} {Meeting} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Braun, Daniel and Hernandez Mendez, Adrian and Matthes, Florian and Langen, Manfred},
	month = aug,
	year = {2017},
	pages = {174--185},
}

@article{weiss_evaluating_2015,
	title = {Evaluating embodied conversational agents in multimodal interfaces},
	volume = {1},
	issn = {2195-3961},
	url = {https://doi.org/10.1186/s40469-015-0006-9},
	doi = {10.1186/s40469-015-0006-9},
	abstract = {Based on cross-disciplinary approaches to Embodied Conversational Agents, evaluation methods for such human-computer interfaces are structured and presented. An introductory systematisation of evaluation topics from a conversational perspective is followed by an explanation of social-psychological phenomena studied in interaction with Embodied Conversational Agents, and how these can be used for evaluation purposes. Major evaluation concepts and appropriate assessment instruments – established and new ones – are presented, including questionnaires, annotations and log-files. An exemplary evaluation and guidelines provide hands-on information on planning and preparing such endeavours.},
	language = {en},
	number = {1},
	urldate = {2022-06-27},
	journal = {Computational Cognitive Science},
	author = {Weiss, Benjamin and Wechsung, Ina and Kühnel, Christine and Möller, Sebastian},
	month = aug,
	year = {2015},
	pages = {6},
}

@incollection{mctear_evaluating_2016,
	address = {Cham},
	title = {Evaluating the {Conversational} {Interface}},
	isbn = {978-3-319-32967-3},
	url = {https://doi.org/10.1007/978-3-319-32967-3_17},
	abstract = {The evaluation of conversational interfaces is a continuously evolving research area that encompasses a rich variety of methodologies, techniques, and tools. As conversational interfaces become more complex, their evaluation has become multifaceted. Furthermore, evaluation involves paying attention not only to the different components in isolation, but also to interrelations between the components and the operation of the system as a whole. This chapter discusses the main measures that are employed for evaluating conversational interfaces from a variety of perspectives.},
	language = {en},
	urldate = {2022-06-27},
	booktitle = {The {Conversational} {Interface}: {Talking} to {Smart} {Devices}},
	publisher = {Springer International Publishing},
	author = {McTear, Michael and Callejas, Zoraida and Griol, David},
	editor = {McTear, Michael and Callejas, Zoraida and Griol, David},
	year = {2016},
	doi = {10.1007/978-3-319-32967-3_17},
	pages = {379--402},
}

@article{ventola_structure_1979,
	title = {The structure of casual conversation in {English}},
	volume = {3},
	issn = {0378-2166},
	url = {https://www.sciencedirect.com/science/article/pii/0378216679900341},
	doi = {10.1016/0378-2166(79)90034-1},
	abstract = {The main concern of this paper is an exploration of the structure of casual conversation. It will be argued that this structure varies according to the social distance (Hasan 1978a) between the interactants. This variation in turn permits a structural classification of conversation into two types: minimal and non-minimal. The functions of these two types of conversation differ: the first serves to establish and/or maintain contact between interactants while the second is an expression of greater involvement.},
	language = {en},
	number = {3},
	urldate = {2022-03-14},
	journal = {Journal of Pragmatics},
	author = {Ventola, Eija},
	month = aug,
	year = {1979},
	pages = {267--298},
}

@inproceedings{venkatesh_evaluating_2017,
	title = {On {Evaluating} and {Comparing} {Conversational} {Agents}},
	url = {https://www.amazon.science/publications/on-evaluating-and-comparing-conversational-agents},
	abstract = {Conversational agents are exploding in popularity. However, much work remains in the area of non goal-oriented conversations, despite significant growth in research interest over recent years. To advance the state of the art in conversational AI, Amazon launched the Alexa Prize, a 2.5-million dollar university competition where sixteen selected university teams built conversational agents to deliver the best social conversational experience. Alexa Prize provided the academic community with the unique opportunity to perform research with a live system used by millions of users. The subjectivity associated with evaluating conversations is key element underlying the challenge of building non-goal oriented dialogue systems. In this paper, we propose a comprehensive evaluation strategy with multiple metrics designed to reduce subjectivity by selecting metrics which correlate well with human judgement. The proposed metrics provide granular analysis of the conversational agents, which is not captured in human ratings. We show that these metrics can be used as a reasonable proxy for human judgment. We provide a mechanism to unify the metrics for selecting the top performing agents, which has also been applied throughout the Alexa Prize competition. To our knowledge, to date it is the largest setting for evaluating agents with millions of conversations and hundreds of thousands of ratings from users. We believe that this work is a step towards an automatic evaluation process for conversational AIs.},
	booktitle = {{NeurIPS} 2017},
	author = {Venkatesh, Anushree and Khatri, Chandra and Ram, Ashwin and Guo, Fenfei and Gabriel, Raefer and Nagar, Ashish and Prasad, Rohit and Cheng, Ming and Hedayatnia, Behnam and Metallinou, Angeliki and Goel, Rahul and Raju, Anirudh},
	year = {2017},
}

@article{siegert_case_2021,
	title = {Case {Report}: {Women}, {Be} {Aware} that {Your} {Vocal} {Charisma} can {Dwindle} in {Remote} {Meetings}},
	volume = {5},
	issn = {2297-900X},
	shorttitle = {Case {Report}},
	url = {https://www.frontiersin.org/article/10.3389/fcomm.2020.611555},
	abstract = {Remote meetings via Zoom, Skype, or Teams limit the range and richness of nonverbal communication signals. Not just because of the typically sub-optimal light, posture, and gaze conditions, but also because of the reduced speaker visibility. Consequently, the speaker’s voice becomes immensely important, especially when it comes to being persuasive and conveying charismatic attributes. However, to offer a reliable service and limit the transmission bandwidth, remote meeting tools heavily rely on signal compression. It has never been analyzed how this compression affects a speaker’s persuasive and overall charismatic impact. Our study addresses this gap for the audio signal. A perception experiment was carried out in which listeners rated short stimulus utterances with systematically varied compression rates and techniques. The scalar ratings concerned a set of charismatic speaker attributes. Results show that the applied audio compression significantly influences the assessment of a speaker’s charismatic impact and that, particularly female speakers seem to be systematically disadvantaged by audio compression rates and techniques. Their charismatic impact decreases over a larger range of different codecs; and this decrease is additionally also more strongly pronounced than for male speakers. We discuss these findings with respect to two possible explanations. The first explanation is signal-based: audio compression codecs could be generally optimized for male speech and, thus, degrade female speech more (particularly in terms of charisma-associated features). Alternatively, the explanation is in the ears of the listeners who are less forgiving of signal degradation when rating female speakers’ charisma.},
	urldate = {2022-06-27},
	journal = {Frontiers in Communication},
	author = {Siegert, Ingo and Niebuhr, Oliver},
	year = {2021},
}

@inproceedings{qian_hidebehind_2018,
	address = {Shenzhen China},
	title = {Hidebehind: {Enjoy} {Voice} {Input} with {Voiceprint} {Unclonability} and {Anonymity}},
	isbn = {978-1-4503-5952-8},
	shorttitle = {Hidebehind},
	url = {https://dl.acm.org/doi/10.1145/3274783.3274855},
	doi = {10.1145/3274783.3274855},
	abstract = {The use of voice assistants has rapidly grown in recent years. They can be found in millions of households. And a lot of effort has been made by researchers to improve the usage of these systems. One issue that remains open is the usage of voice assistants and recording of interactions for research purposes in public environments due to privacy concerns. Additionally, data collections, offering unconstrained, unscripted public interactions are quite rare and mainly only focus on transcribed content or have focused on private usage, short pre-deﬁned tasks, or speciﬁc domains. The current paper presents an approach on how voice data recordings of user interactions with voice assistants in a public space can be recorded and processed in conformity with the GDPR.},
	language = {en},
	urldate = {2022-06-27},
	booktitle = {Proceedings of the 16th {ACM} {Conference} on {Embedded} {Networked} {Sensor} {Systems}},
	publisher = {ACM},
	author = {Qian, Jianwei and Du, Haohua and Hou, Jiahui and Chen, Linlin and Jung, Taeho and Li, Xiang-Yang},
	month = nov,
	year = {2018},
	pages = {82--94},
}

@inproceedings{leschanowsky_design_2021,
	title = {Design {Implications} for {Human}-{Machine} {Interactions} from a {Qualitative} {Pilot} {Study} on {Privacy}},
	url = {https://www.isca-speech.org/archive/spsc_2021/leschanowsky21_spsc.html},
	doi = {10.21437/SPSC.2021-16},
	language = {en},
	urldate = {2022-06-27},
	booktitle = {2021 {ISCA} {Symposium} on {Security} and {Privacy} in {Speech} {Communication}},
	publisher = {ISCA},
	author = {Leschanowsky, Anna and Brüggemeier, Birgit and Peters, Nils},
	month = nov,
	year = {2021},
	pages = {76--79},
}

@article{versteegh_zero_nodate,
	title = {The {Zero} {Resource} {Speech} {Challenge} 2015},
	abstract = {The Interspeech 2015 Zero Resource Speech Challenge aims at discovering subword and word units from raw speech. The challenge provides the ﬁrst uniﬁed and open source suite of evaluation metrics and data sets to compare and analyse the results of unsupervised linguistic unit discovery algorithms. It consists of two tracks. In the ﬁrst, a psychophysically inspired evaluation task (minimal pair ABX discrimination) is used to assess how well speech feature representations discriminate between contrastive subword units. In the second, several metrics gauge the quality of discovered word-like patterns. Two data sets are provided, one for English, one for Xitsonga. Both data sets are provided without any annotation except for voice activity and talker identity. This paper introduces the evaluation metrics, presents the results of baseline systems and discusses some of the key issues in unsupervised unit discovery.},
	language = {en},
	author = {Versteegh, Maarten and Thiolliere, Roland and Schatz, Thomas and Cao, Xuan Nga and Anguera, Xavier and Jansen, Aren and Dupoux, Emmanuel},
	pages = {5},
}

@article{rogers_primer_2021,
	title = {A {Primer} in {BERTology}: {What} {We} {Know} {About} {How} {BERT} {Works}},
	volume = {8},
	issn = {2307-387X},
	shorttitle = {A {Primer} in {BERTology}},
	url = {https://doi.org/10.1162/tacl_a_00349},
	doi = {10.1162/tacl_a_00349},
	abstract = {Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.},
	urldate = {2022-06-27},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
	month = jan,
	year = {2021},
	pages = {842--866},
}

@inproceedings{ahn_voxcommunis_2022,
	title = {{VoxCommunis}: {A} {Corpus} for {Cross}-linguistic {Phonetic} {Analysis}},
	abstract = {Cross-linguistic phonetic analysis has long been limited by data scarcity and insufficient computational resources. In the past few years, the availability of large-scale cross-linguistic spoken corpora has increased dramatically, but the data still require considerable computational power and processing for downstream phonetic analysis. To facilitate large-scale cross-linguistic phonetic research in the field, we release the VoxCommunis Corpus, which contains acoustic models, pronunciation lexicons, and word- and phone-level alignments, derived from the publicly available Mozilla Common Voice Corpus (Ardila et al., 2020). The current release includes data from 36 languages. The corpus also contains acoustic-phonetic measurements, which currently consist of formant frequencies (F1–F4) from all vowel quartiles. Major advantages of this corpus for phonetic analysis include the number of available languages, the large amount of speech per language, as well as the fact that most language datasets have dozens to hundreds of contributing speakers. We demonstrate the utility of this corpus for downstream phonetic research in a descriptive analysis of language-specific vowel systems, as well as an analysis of “uniformity” in vowel realization across languages. The VoxCommunis Corpus is free to download and use under a CC0 license at https://osf.io/t957v/wiki/home/.},
	language = {en},
	booktitle = {Proceedings of the 13th {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2022)},
	author = {Ahn, Emily and Chodroff, Eleanor},
	year = {2022},
	pages = {5286--5294},
}

@book{schuller2013computational,
	title = {Computational paralinguistics: emotion, affect and personality in speech and language processing},
	publisher = {John Wiley \& Sons},
	author = {Schuller, Björn and Batliner, Anton},
	year = {2013},
}

@inproceedings{siegert_alexa_2020,
	address = {Marseille, France},
	title = {“{Alexa} in the wild” – {Collecting} {Unconstrained} {Conversations} with a {Modern} {Voice} {Assistant} in a {Public} {Environment}},
	isbn = {979-10-95546-34-4},
	url = {https://aclanthology.org/2020.lrec-1.77},
	abstract = {Datasets featuring modern voice assistants such as Alexa, Siri, Cortana and others allow an easy study of human-machine interactions. But data collections offering an unconstrained, unscripted public interaction are quite rare. Many studies so far have focused on private usage, short pre-defined task or specific domains. This contribution presents a dataset providing a large amount of unconstrained public interactions with a voice assistant. Up to now around 40 hours of device directed utterances were collected during a science exhibition touring through Germany. The data recording was part of an exhibit that engages visitors to interact with a commercial voice assistant system (Amazon's ALEXA), but did not restrict them to a specific topic. A specifically developed quiz was starting point of the conversation, as the voice assistant was presented to the visitors as a possible joker for the quiz. But the visitors were not forced to solve the quiz with the help of the voice assistant and thus many visitors had an open conversation. The provided dataset – Voice Assistant Conversations in the wild (VACW) – includes the transcripts of both visitors requests and Alexa answers, identified topics and sessions as well as acoustic characteristics automatically extractable from the visitors' audio files.},
	language = {English},
	urldate = {2022-06-24},
	booktitle = {Proceedings of the 12th {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Siegert, Ingo},
	month = may,
	year = {2020},
	pages = {615--619},
}

@misc{iizuka_how_2022,
	title = {How does a spontaneously speaking conversational agent affect user behavior?},
	url = {http://arxiv.org/abs/2205.00755},
	doi = {10.48550/arXiv.2205.00755},
	abstract = {This study investigated the effect of synthetic voice of conversational agent trained with spontaneous speech on human interactants. Specifically, we hypothesized that humans will exhibit more social responses when interacting with conversational agent that has a synthetic voice built on spontaneous speech. Typically, speech synthesizers are built on a speech corpus where voice professionals read a set of written sentences. The synthesized speech is clear as if a newscaster were reading a news or a voice actor were playing an anime character. However, this is quite different from spontaneous speech we speak in everyday conversation. Recent advances in speech synthesis enabled us to build a speech synthesizer on a spontaneous speech corpus, and to obtain a near conversational synthesized speech with reasonable quality. By making use of these technology, we examined whether humans produce more social responses to a spontaneously speaking conversational agent. We conducted a large-scale conversation experiment with a conversational agent whose utterances were synthesized with the model trained either with spontaneous speech or read speech. The result showed that the subjects who interacted with the agent whose utterances were synthesized from spontaneous speech tended to show shorter response time and a larger number of backchannels. The result of a questionnaire showed that subjects who interacted with the agent whose utterances were synthesized from spontaneous speech tended to rate their conversation with the agent as closer to a human conversation. These results suggest that speech synthesis built on spontaneous speech is essential to realize a conversational agent as a social actor.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Iizuka, Takahisa and Mori, Hiroki},
	month = may,
	year = {2022},
	note = {Number: arXiv:2205.00755
arXiv:2205.00755 [cs]},
}

@article{eiswirth_developing_2022,
	title = {Developing and testing interaction-based coding schemes for the analysis of sociolinguistic variation},
	volume = {87},
	issn = {0271-5309},
	url = {https://www.sciencedirect.com/science/article/pii/S0271530922000283},
	doi = {10.1016/j.langcom.2022.05.001},
	abstract = {Work on sociolinguistic variation increasingly considers interactional structures and phenomena as conditioning factors of variation. At the same time, scholars of talk-in-interaction have explored the potential of treating interactional phenomena as variables. However, these strands exist in isolation from each other. The present paper draws on both perspectives and proposes (1) three steps for developing an interactionally rooted variable definition and coding scheme based on the example of Listener Response, and (2) heuristics for testing how applicable the coding scheme is for a scholar of language variation without in-depth training in the analysis of talk-in-interaction. An analysis of inter-coder reliability shows high agreement for the proposed coding scheme. Small systematic disagreements are discussed and used to refine the coding scheme.},
	language = {en},
	urldate = {2022-06-19},
	journal = {Language \& Communication},
	author = {Eiswirth, Mirjam Elisabeth},
	month = nov,
	year = {2022},
	pages = {11--28},
}

@techreport{jakesch_human_2022,
	title = {Human {Heuristics} for {AI}-{Generated} {Language} {Are} {Flawed}},
	url = {http://arxiv.org/abs/2206.07271},
	abstract = {Human communication is increasingly intermixed with language generated by AI. Across chat, email, and social media, AI systems produce smart replies, autocompletes, and translations. AI-generated language is often not identified as such but poses as human language, raising concerns about novel forms of deception and manipulation. Here, we study how humans discern whether one of the most personal and consequential forms of language - a self-presentation - was generated by AI. Across six experiments, participants (N = 4,650) tried to identify self-presentations generated by state-of-the-art language models. Across professional, hospitality, and romantic settings, we find that humans are unable to identify AI-generated self-presentations. Combining qualitative analyses with language feature engineering, we find that human judgments of AI-generated language are handicapped by intuitive but flawed heuristics such as associating first-person pronouns, authentic words, or family topics with humanity. We show that these heuristics make human judgment of generated language predictable and manipulable, allowing AI systems to produce language perceived as more human than human. We conclude by discussing solutions - such as AI accents or fair use policies - to reduce the deceptive potential of generated language, limiting the subversion of human intuition.},
	number = {arXiv:2206.07271},
	urldate = {2022-06-19},
	institution = {arXiv},
	author = {Jakesch, Maurice and Hancock, Jeffrey and Naaman, Mor},
	month = jun,
	year = {2022},
	doi = {10.48550/arXiv.2206.07271},
	note = {arXiv:2206.07271 [cs]
type: article},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction},
}

@inproceedings{madureira_can_2022,
	address = {Dublin, Ireland},
	title = {Can {Visual} {Dialogue} {Models} {Do} {Scorekeeping}? {Exploring} {How} {Dialogue} {Representations} {Incrementally} {Encode} {Shared} {Knowledge}},
	shorttitle = {Can {Visual} {Dialogue} {Models} {Do} {Scorekeeping}?},
	url = {https://aclanthology.org/2022.acl-short.73},
	doi = {10.18653/v1/2022.acl-short.73},
	abstract = {Cognitively plausible visual dialogue models should keep a mental scoreboard of shared established facts in the dialogue context. We propose a theory-based evaluation method for investigating to what degree models pretrained on the VisDial dataset incrementally build representations that appropriately do scorekeeping. Our conclusion is that the ability to make the distinction between shared and privately known statements along the dialogue is moderately present in the analysed models, but not always incrementally consistent, which may partially be due to the limited need for grounding interactions in the original task.},
	urldate = {2022-06-17},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Madureira, Brielen and Schlangen, David},
	month = may,
	year = {2022},
	pages = {651--664},
}

@misc{colas_vygotskian_2022,
	title = {Vygotskian {Autotelic} {Artificial} {Intelligence}: {Language} and {Culture} {Internalization} for {Human}-{Like} {AI}},
	shorttitle = {Vygotskian {Autotelic} {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2206.01134},
	abstract = {Building autonomous artificial agents able to grow open-ended repertoires of skills is one of the fundamental goals of AI. To that end, a promising developmental approach recommends the design of intrinsically motivated agents that learn new skills by generating and pursuing their own goals - autotelic agents. However, existing algorithms still show serious limitations in terms of goal diversity, exploration, generalization or skill composition. This perspective calls for the immersion of autotelic agents into rich socio-cultural worlds. We focus on language especially, and how its structure and content may support the development of new cognitive functions in artificial agents, just like it does in humans. Indeed, most of our skills could not be learned in isolation. Formal education teaches us to reason systematically, books teach us history, and YouTube might teach us how to cook. Crucially, our values, traditions, norms and most of our goals are cultural in essence. This knowledge, and some argue, some of our cognitive functions such as abstraction, compositional imagination or relational thinking, are formed through linguistic and cultural interactions. Inspired by the work of Vygotsky, we suggest the design of Vygotskian autotelic agents able to interact with others and, more importantly, able to internalize these interactions to transform them into cognitive tools supporting the development of new cognitive functions. This perspective paper proposes a new AI paradigm in the quest for artificial lifelong skill discovery. It justifies the approach by uncovering examples of new artificial cognitive functions emerging from interactions between language and embodiment in recent works at the intersection of deep reinforcement learning and natural language processing. Looking forward, it highlights future opportunities and challenges for Vygotskian Autotelic AI research.},
	urldate = {2022-06-17},
	publisher = {arXiv},
	author = {Colas, Cédric and Karch, Tristan and Moulin-Frier, Clément and Oudeyer, Pierre-Yves},
	month = jun,
	year = {2022},
	note = {Number: arXiv:2206.01134
arXiv:2206.01134 [cs]},
}

@article{bernard_phonemizer_2021,
	title = {Phonemizer: {Text} to {Phones} {Transcription} for {Multiple} {Languages} in {Python}},
	volume = {6},
	issn = {2475-9066},
	shorttitle = {Phonemizer},
	url = {https://joss.theoj.org/papers/10.21105/joss.03958},
	doi = {10.21105/joss.03958},
	abstract = {Phones are elementary sounds the speech is made of, on which syllables and words are built. The transcription of texts from their orthographic form into a phonetic alphabet is an important requirement in various applications related to speech and language processing, for instance for text to speech systems. Phonemizer is a Python package addressing precisely this issue: it transcribes a text from its orthographic representation into a phonetic one. The package is user-friendly and exposes a single high-level phonemize function, a lower lovel API, and is also available as a command-line interface. It supports about a hundred different languages and provides end-user functionalities such as punctuation preservation, phones accentuation, tokenization at phone/syllable/word levels, as well as parallel processing of large input texts.},
	language = {en},
	number = {68},
	urldate = {2022-06-17},
	journal = {Journal of Open Source Software},
	author = {Bernard, Mathieu and Titeux, Hadrien},
	month = dec,
	year = {2021},
	pages = {3958},
}

@inproceedings{mortensen_epitran_2018,
	address = {Miyazaki, Japan},
	title = {Epitran: {Precision} {G2P} for {Many} {Languages}},
	shorttitle = {Epitran},
	url = {https://aclanthology.org/L18-1429},
	urldate = {2022-06-17},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Mortensen, David R. and Dalmia, Siddharth and Littell, Patrick},
	month = may,
	year = {2018},
}

@misc{cosentino_librimix_2020,
	title = {{LibriMix}: {An} {Open}-{Source} {Dataset} for {Generalizable} {Speech} {Separation}},
	shorttitle = {{LibriMix}},
	url = {http://arxiv.org/abs/2005.11262},
	abstract = {In recent years, wsj0-2mix has become the reference dataset for single-channel speech separation. Most deep learning-based speech separation models today are benchmarked on it. However, recent studies have shown important performance drops when models trained on wsj0-2mix are evaluated on other, similar datasets. To address this generalization issue, we created LibriMix, an open-source alternative to wsj0-2mix, and to its noisy extension, WHAM!. Based on LibriSpeech, LibriMix consists of two- or three-speaker mixtures combined with ambient noise samples from WHAM!. Using Conv-TasNet, we achieve competitive performance on all LibriMix versions. In order to fairly evaluate across datasets, we introduce a third test set based on VCTK for speech and WHAM! for noise. Our experiments show that the generalization error is smaller for models trained with LibriMix than with WHAM!, in both clean and noisy conditions. Aiming towards evaluation in more realistic, conversation-like scenarios, we also release a sparsely overlapping version of LibriMix's test set.},
	urldate = {2022-06-17},
	publisher = {arXiv},
	author = {Cosentino, Joris and Pariente, Manuel and Cornell, Samuele and Deleforge, Antoine and Vincent, Emmanuel},
	month = may,
	year = {2020},
	note = {Number: arXiv:2005.11262
arXiv:2005.11262 [eess]},
}

@article{wang_supervised_2018,
	title = {Supervised {Speech} {Separation} {Based} on {Deep} {Learning}: {An} {Overview}},
	volume = {26},
	issn = {2329-9304},
	shorttitle = {Supervised {Speech} {Separation} {Based} on {Deep} {Learning}},
	doi = {10.1109/TASLP.2018.2842159},
	abstract = {Speech separation is the task of separating target speech from background interference. Traditionally, speech separation is studied as a signal processing problem. A more recent approach formulates speech separation as a supervised learning problem, where the discriminative patterns of speech, speakers, and background noise are learned from training data. Over the past decade, many supervised separation algorithms have been put forward. In particular, the recent introduction of deep learning to supervised speech separation has dramatically accelerated progress and boosted separation performance. This paper provides a comprehensive overview of the research on deep learning based supervised speech separation in the last several years. We first introduce the background of speech separation and the formulation of supervised separation. Then, we discuss three main components of supervised separation: learning machines, training targets, and acoustic features. Much of the overview is on separation algorithms where we review monaural methods, including speech enhancement (speech-nonspeech separation), speaker separation (multitalker separation), and speech dereverberation, as well as multimicrophone techniques. The important issue of generalization, unique to supervised learning, is discussed. This overview provides a historical perspective on how advances are made. In addition, we discuss a number of conceptual issues, including what constitutes the target source.},
	number = {10},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Wang, DeLiang and Chen, Jitong},
	month = oct,
	year = {2018},
	note = {Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	pages = {1702--1726},
}

@article{wang_combining_2019,
	title = {Combining {Spectral} and {Spatial} {Features} for {Deep} {Learning} {Based} {Blind} {Speaker} {Separation}},
	volume = {27},
	issn = {2329-9304},
	doi = {10.1109/TASLP.2018.2881912},
	abstract = {This study tightly integrates complementary spectral and spatial features for deep learning based multi-channel speaker separation in reverberant environments. The key idea is to localize individual speakers so that an enhancement network can be trained on spatial as well as spectral features to extract the speaker from an estimated direction and with specific spectral structures. The spatial and spectral features are designed in a way such that the trained models are blind to the number of microphones and microphone geometry. To determine the direction of the speaker of interest, we identify time-frequency (T-F) units dominated by that speaker and only use them for direction estimation. The T-F unit level speaker dominance is determined by a two-channel chimera++ network, which combines deep clustering and permutation invariant training at the objective function level, and integrates spectral and interchannel phase patterns at the input feature level. In addition, T-F masking based beamforming is tightly integrated in the system by leveraging the magnitudes and phases produced by beamforming. Strong separation performance has been observed on reverberant talker-independent speaker separation, which separates reverberant speaker mixtures based on a random number of microphones arranged in arbitrary linear-array geometry.},
	number = {2},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Wang, Zhong-Qiu and Wang, DeLiang},
	month = feb,
	year = {2019},
	note = {Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	pages = {457--468},
}

@article{anguera_speaker_2012,
	title = {Speaker {Diarization}: {A} {Review} of {Recent} {Research}},
	volume = {20},
	issn = {1558-7924},
	shorttitle = {Speaker {Diarization}},
	doi = {10.1109/TASL.2011.2125954},
	abstract = {Speaker diarization is the task of determining “who spoke when?” in an audio or video recording that contains an unknown amount of speech and also an unknown number of speakers. Initially, it was proposed as a research topic related to automatic speech recognition, where speaker diarization serves as an upstream processing step. Over recent years, however, speaker diarization has become an important key technology for many tasks, such as navigation, retrieval, or higher level inference on audio data. Accordingly, many important improvements in accuracy and robustness have been reported in journals and conferences in the area. The application domains, from broadcast news, to lectures and meetings, vary greatly and pose different problems, such as having access to multiple microphones and multimodal information or overlapping speech. The most recent review of existing technology dates back to 2006 and focuses on the broadcast news domain. In this paper, we review the current state-of-the-art, focusing on research developed since 2006 that relates predominantly to speaker diarization for conference meetings. Finally, we present an analysis of speaker diarization performance as reported through the NIST Rich Transcription evaluations on meeting data and identify important areas for future research.},
	number = {2},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Anguera, Xavier and Bozonnet, Simon and Evans, Nicholas and Fredouille, Corinne and Friedland, Gerald and Vinyals, Oriol},
	month = feb,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Audio, Speech, and Language Processing},
	pages = {356--370},
}

@inproceedings{reinkemeier_designing_2022,
	title = {Designing {Effective} {Conversational} {Repair} {Strategies} for {Chatbots}},
	abstract = {Conversational breakdowns often force users to go through frustrating loops of trial and error when trying to get answers from chatbots. Although research has emphasized the potential of conversational repair strategies in helping users resolve breakdowns, design knowledge for implementing such strategies is scarce. To address this challenge, we are conducting a design science research (DSR) project to design effective repair strategies that help users recover from conversational breakdowns with chatbots. This paper presents the first design cycle, proposing, instantiating, and evaluating our first design principle on identifying the cause of conversational breakdowns. Using 21,736 real-world user messages from a large insurance company, we conducted a cluster analysis of 5,668 messages leading to breakdowns, identified four distinct breakdown types, and built a classifier that can be used to automatically identify breakdown causes in real time. Our research contributes with prescriptive knowledge for designing repair strategies in conversational breakdown situations.},
	author = {Reinkemeier, Fabian and Gnewuch, Ulrich},
	month = jun,
	year = {2022},
	keywords = {Chatbot, Conversational Breakdown, Design Science Research, Repair Strategies},
}

@article{corti_co-constructing_2016,
	title = {Co-constructing intersubjectivity with artificial conversational agents: {People} are more likely to initiate repairs of misunderstandings with agents represented as human},
	volume = {58},
	issn = {0747-5632},
	shorttitle = {Co-constructing intersubjectivity with artificial conversational agents},
	url = {http://www.sciencedirect.com/science/article/pii/S0747563215303101},
	doi = {10.1016/j.chb.2015.12.039},
	abstract = {This article explores whether people more frequently attempt to repair misunderstandings when speaking to an artificial conversational agent if it is represented as fully human. Interactants in dyadic conversations with an agent (the chat bot Cleverbot) spoke to either a text screen interface (agent's responses shown on a screen) or a human body interface (agent's responses vocalized by a human speech shadower via the echoborg method) and were either informed or not informed prior to interlocution that their interlocutor's responses would be agent-generated. Results show that an interactant is less likely to initiate repairs when an agent-interlocutor communicates via a text screen interface as well as when they explicitly know their interlocutor's words to be agent-generated. That is to say, people demonstrate the most “intersubjective effort” toward establishing common ground when they engage an agent under the same social psychological conditions as face-to-face human–human interaction (i.e., when they both encounter another human body and assume that they are speaking to an autonomously-communicating person). This article's methodology presents a novel means of benchmarking intersubjectivity and intersubjective effort in human-agent interaction.},
	urldate = {2016-02-03},
	journal = {Computers in Human Behavior},
	author = {Corti, Kevin and Gillespie, Alex},
	month = may,
	year = {2016},
	keywords = {Common ground, Conversational repair, Echoborg, Human-agent interaction, Intersubjectivity, Psychological benchmarks},
	pages = {431--442},
}

@inproceedings{an_recipient_2021,
	address = {Bilbao (online) Spain},
	title = {Recipient {Design} for {Conversational} {Agents}: {Tailoring} {Agent}’s {Utterance} to {User}’s {Knowledge}},
	isbn = {978-1-4503-8998-3},
	shorttitle = {Recipient {Design} for {Conversational} {Agents}},
	url = {https://dl.acm.org/doi/10.1145/3469595.3469625},
	doi = {10.1145/3469595.3469625},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {{CUI} 2021 - 3rd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {ACM},
	author = {An, Sungeun and Moore, Robert and Liu, Eric Young and Ren, Guang-Jie},
	month = jul,
	year = {2021},
	keywords = {Conversational UX, Conversational agents, Conversational analysis, Personalization, Recipient design},
	pages = {1--5},
}

@article{list_lexibank_2022,
	title = {Lexibank, a public repository of standardized wordlists with computed phonological and lexical features},
	volume = {9},
	copyright = {2022 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01432-0},
	doi = {10.1038/s41597-022-01432-0},
	abstract = {The past decades have seen substantial growth in digital data on the world’s languages. At the same time, the demand for cross-linguistic datasets has been increasing, as witnessed by numerous studies devoted to diverse questions on human prehistory, cultural evolution, and human cognition. Unfortunately, most published datasets lack standardization which makes their comparison difficult. Here, we present a new approach to increase the comparability of cross-linguistic lexical data. We have designed workflows for the computer-assisted lifting of datasets to Cross-Linguistic Data Formats, a collection of standards that make these datasets more Findable, Accessible, Interoperable, and Reusable (FAIR). We test the Lexibank workflow on 100 lexical datasets from which we derive an aggregated database of wordlists in unified phonetic transcriptions covering more than 2000 language varieties. We illustrate the benefits of our approach by showing how phonological and lexical features can be automatically inferred, complementing and expanding existing cross-linguistic datasets.},
	language = {en},
	number = {1},
	urldate = {2022-06-16},
	journal = {Scientific Data},
	author = {List, Johann-Mattis and Forkel, Robert and Greenhill, Simon J. and Rzymski, Christoph and Englisch, Johannes and Gray, Russell D.},
	month = jun,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {316},
}

@misc{thoppilan_lamda_2022,
	title = {{LaMDA}: {Language} {Models} for {Dialog} {Applications}},
	shorttitle = {{LaMDA}},
	url = {http://arxiv.org/abs/2201.08239},
	doi = {10.48550/arXiv.2201.08239},
	abstract = {We present LaMDA: Language Models for Dialog Applications. LaMDA is a family of Transformer-based neural language models specialized for dialog, which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text. While model scaling alone can improve quality, it shows less improvements on safety and factual grounding. We demonstrate that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding. The first challenge, safety, involves ensuring that the model's responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. We quantify safety using a metric based on an illustrative set of human values, and we find that filtering candidate responses using a LaMDA classifier fine-tuned with a small amount of crowdworker-annotated data offers a promising approach to improving model safety. The second challenge, factual grounding, involves enabling the model to consult external knowledge sources, such as an information retrieval system, a language translator, and a calculator. We quantify factuality using a groundedness metric, and we find that our approach enables the model to generate responses grounded in known sources, rather than responses that merely sound plausible. Finally, we explore the use of LaMDA in the domains of education and content recommendations, and analyze their helpfulness and role consistency.},
	urldate = {2022-06-16},
	publisher = {arXiv},
	author = {Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and Li, YaGuang and Lee, Hongrae and Zheng, Huaixiu Steven and Ghafouri, Amin and Menegali, Marcelo and Huang, Yanping and Krikun, Maxim and Lepikhin, Dmitry and Qin, James and Chen, Dehao and Xu, Yuanzhong and Chen, Zhifeng and Roberts, Adam and Bosma, Maarten and Zhao, Vincent and Zhou, Yanqi and Chang, Chung-Ching and Krivokon, Igor and Rusch, Will and Pickett, Marc and Srinivasan, Pranesh and Man, Laichee and Meier-Hellstern, Kathleen and Morris, Meredith Ringel and Doshi, Tulsee and Santos, Renelito Delos and Duke, Toju and Soraker, Johnny and Zevenbergen, Ben and Prabhakaran, Vinodkumar and Diaz, Mark and Hutchinson, Ben and Olson, Kristen and Molina, Alejandra and Hoffman-John, Erin and Lee, Josh and Aroyo, Lora and Rajakumar, Ravi and Butryna, Alena and Lamm, Matthew and Kuzmina, Viktoriya and Fenton, Joe and Cohen, Aaron and Bernstein, Rachel and Kurzweil, Ray and Aguera-Arcas, Blaise and Cui, Claire and Croak, Marian and Chi, Ed and Le, Quoc},
	month = feb,
	year = {2022},
	note = {Number: arXiv:2201.08239
arXiv:2201.08239 [cs]},
}

@misc{srivastava_beyond_2022,
	title = {Beyond the {Imitation} {Game}: {Quantifying} and extrapolating the capabilities of language models},
	shorttitle = {Beyond the {Imitation} {Game}},
	url = {http://arxiv.org/abs/2206.04615},
	doi = {10.48550/arXiv.2206.04615},
	abstract = {Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit "breakthrough" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.},
	urldate = {2022-06-16},
	publisher = {arXiv},
	author = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R. and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adrià and Kluska, Agnieszka and Lewkowycz, Aitor and Agarwal, Akshat and Power, Alethea and Ray, Alex and Warstadt, Alex and Kocurek, Alexander W. and Safaya, Ali and Tazarv, Ali and Xiang, Alice and Parrish, Alicia and Nie, Allen and Hussain, Aman and Askell, Amanda and Dsouza, Amanda and Slone, Ambrose and Rahane, Ameet and Iyer, Anantharaman S. and Andreassen, Anders and Madotto, Andrea and Santilli, Andrea and Stuhlmüller, Andreas and Dai, Andrew and La, Andrew and Lampinen, Andrew and Zou, Andy and Jiang, Angela and Chen, Angelica and Vuong, Anh and Gupta, Animesh and Gottardi, Anna and Norelli, Antonio and Venkatesh, Anu and Gholamidavoodi, Arash and Tabassum, Arfa and Menezes, Arul and Kirubarajan, Arun and Mullokandov, Asher and Sabharwal, Ashish and Herrick, Austin and Efrat, Avia and Erdem, Aykut and Karakaş, Ayla and Roberts, B. Ryan and Loe, Bao Sheng and Zoph, Barret and Bojanowski, Bartłomiej and Özyurt, Batuhan and Hedayatnia, Behnam and Neyshabur, Behnam and Inden, Benjamin and Stein, Benno and Ekmekci, Berk and Lin, Bill Yuchen and Howald, Blake and Diao, Cameron and Dour, Cameron and Stinson, Catherine and Argueta, Cedrick and Ramírez, César Ferri and Singh, Chandan and Rathkopf, Charles and Meng, Chenlin and Baral, Chitta and Wu, Chiyu and Callison-Burch, Chris and Waites, Chris and Voigt, Christian and Manning, Christopher D. and Potts, Christopher and Ramirez, Cindy and Rivera, Clara E. and Siro, Clemencia and Raffel, Colin and Ashcraft, Courtney and Garbacea, Cristina and Sileo, Damien and Garrette, Dan and Hendrycks, Dan and Kilman, Dan and Roth, Dan and Freeman, Daniel and Khashabi, Daniel and Levy, Daniel and González, Daniel Moseguí and Perszyk, Danielle and Hernandez, Danny and Chen, Danqi and Ippolito, Daphne and Gilboa, Dar and Dohan, David and Drakard, David and Jurgens, David and Datta, Debajyoti and Ganguli, Deep and Emelin, Denis and Kleyko, Denis and Yuret, Deniz and Chen, Derek and Tam, Derek and Hupkes, Dieuwke and Misra, Diganta and Buzan, Dilyar and Mollo, Dimitri Coelho and Yang, Diyi and Lee, Dong-Ho and Shutova, Ekaterina and Cubuk, Ekin Dogus and Segal, Elad and Hagerman, Eleanor and Barnes, Elizabeth and Donoway, Elizabeth and Pavlick, Ellie and Rodola, Emanuele and Lam, Emma and Chu, Eric and Tang, Eric and Erdem, Erkut and Chang, Ernie and Chi, Ethan A. and Dyer, Ethan and Jerzak, Ethan and Kim, Ethan and Manyasi, Eunice Engefu and Zheltonozhskii, Evgenii and Xia, Fanyue and Siar, Fatemeh and Martínez-Plumed, Fernando and Happé, Francesca and Chollet, Francois and Rong, Frieda and Mishra, Gaurav and Winata, Genta Indra and de Melo, Gerard and Kruszewski, Germán and Parascandolo, Giambattista and Mariani, Giorgio and Wang, Gloria and Jaimovitch-López, Gonzalo and Betz, Gregor and Gur-Ari, Guy and Galijasevic, Hana and Kim, Hannah and Rashkin, Hannah and Hajishirzi, Hannaneh and Mehta, Harsh and Bogar, Hayden and Shevlin, Henry and Schütze, Hinrich and Yakura, Hiromu and Zhang, Hongming and Wong, Hugh Mee and Ng, Ian and Noble, Isaac and Jumelet, Jaap and Geissinger, Jack and Kernion, Jackson and Hilton, Jacob and Lee, Jaehoon and Fisac, Jaime Fernández and Simon, James B. and Koppel, James and Zheng, James and Zou, James and Kocoń, Jan and Thompson, Jana and Kaplan, Jared and Radom, Jarema and Sohl-Dickstein, Jascha and Phang, Jason and Wei, Jason and Yosinski, Jason and Novikova, Jekaterina and Bosscher, Jelle and Marsh, Jennifer and Kim, Jeremy and Taal, Jeroen and Engel, Jesse and Alabi, Jesujoba and Xu, Jiacheng and Song, Jiaming and Tang, Jillian and Waweru, Joan and Burden, John and Miller, John and Balis, John U. and Berant, Jonathan and Frohberg, Jörg and Rozen, Jos and Hernandez-Orallo, Jose and Boudeman, Joseph and Jones, Joseph and Tenenbaum, Joshua B. and Rule, Joshua S. and Chua, Joyce and Kanclerz, Kamil and Livescu, Karen and Krauth, Karl and Gopalakrishnan, Karthik and Ignatyeva, Katerina and Markert, Katja and Dhole, Kaustubh D. and Gimpel, Kevin and Omondi, Kevin and Mathewson, Kory and Chiafullo, Kristen and Shkaruta, Ksenia and Shridhar, Kumar and McDonell, Kyle and Richardson, Kyle and Reynolds, Laria and Gao, Leo and Zhang, Li and Dugan, Liam and Qin, Lianhui and Contreras-Ochando, Lidia and Morency, Louis-Philippe and Moschella, Luca and Lam, Lucas and Noble, Lucy and Schmidt, Ludwig and He, Luheng and Colón, Luis Oliveros and Metz, Luke and Şenel, Lütfi Kerem and Bosma, Maarten and Sap, Maarten and ter Hoeve, Maartje and Farooqi, Maheen and Faruqui, Manaal and Mazeika, Mantas and Baturan, Marco and Marelli, Marco and Maru, Marco and Quintana, Maria Jose Ramírez and Tolkiehn, Marie and Giulianelli, Mario and Lewis, Martha and Potthast, Martin and Leavitt, Matthew L. and Hagen, Matthias and Schubert, Mátyás and Baitemirova, Medina Orduna and Arnaud, Melody and McElrath, Melvin and Yee, Michael A. and Cohen, Michael and Gu, Michael and Ivanitskiy, Michael and Starritt, Michael and Strube, Michael and Swędrowski, Michał and Bevilacqua, Michele and Yasunaga, Michihiro and Kale, Mihir and Cain, Mike and Xu, Mimee and Suzgun, Mirac and Tiwari, Mo and Bansal, Mohit and Aminnaseri, Moin and Geva, Mor and Gheini, Mozhdeh and T, Mukund Varma and Peng, Nanyun and Chi, Nathan and Lee, Nayeon and Krakover, Neta Gur-Ari and Cameron, Nicholas and Roberts, Nicholas and Doiron, Nick and Nangia, Nikita and Deckers, Niklas and Muennighoff, Niklas and Keskar, Nitish Shirish and Iyer, Niveditha S. and Constant, Noah and Fiedel, Noah and Wen, Nuan and Zhang, Oliver and Agha, Omar and Elbaghdadi, Omar and Levy, Omer and Evans, Owain and Casares, Pablo Antonio Moreno and Doshi, Parth and Fung, Pascale and Liang, Paul Pu and Vicol, Paul and Alipoormolabashi, Pegah and Liao, Peiyuan and Liang, Percy and Chang, Peter and Eckersley, Peter and Htut, Phu Mon and Hwang, Pinyu and Miłkowski, Piotr and Patil, Piyush and Pezeshkpour, Pouya and Oli, Priti and Mei, Qiaozhu and Lyu, Qing and Chen, Qinlang and Banjade, Rabin and Rudolph, Rachel Etta and Gabriel, Raefer and Habacker, Rahel and Delgado, Ramón Risco and Millière, Raphaël and Garg, Rhythm and Barnes, Richard and Saurous, Rif A. and Arakawa, Riku and Raymaekers, Robbe and Frank, Robert and Sikand, Rohan and Novak, Roman and Sitelew, Roman and LeBras, Ronan and Liu, Rosanne and Jacobs, Rowan and Zhang, Rui and Salakhutdinov, Ruslan and Chi, Ryan and Lee, Ryan and Stovall, Ryan and Teehan, Ryan and Yang, Rylan and Singh, Sahib and Mohammad, Saif M. and Anand, Sajant and Dillavou, Sam and Shleifer, Sam and Wiseman, Sam and Gruetter, Samuel and Bowman, Samuel R. and Schoenholz, Samuel S. and Han, Sanghyun and Kwatra, Sanjeev and Rous, Sarah A. and Ghazarian, Sarik and Ghosh, Sayan and Casey, Sean and Bischoff, Sebastian and Gehrmann, Sebastian and Schuster, Sebastian and Sadeghi, Sepideh and Hamdan, Shadi and Zhou, Sharon and Srivastava, Shashank and Shi, Sherry and Singh, Shikhar and Asaadi, Shima and Gu, Shixiang Shane and Pachchigar, Shubh and Toshniwal, Shubham and Upadhyay, Shyam and Shyamolima and Debnath and Shakeri, Siamak and Thormeyer, Simon and Melzi, Simone and Reddy, Siva and Makini, Sneha Priscilla and Lee, Soo-Hwan and Torene, Spencer and Hatwar, Sriharsha and Dehaene, Stanislas and Divic, Stefan and Ermon, Stefano and Biderman, Stella and Lin, Stephanie and Prasad, Stephen and Piantadosi, Steven T. and Shieber, Stuart M. and Misherghi, Summer and Kiritchenko, Svetlana and Mishra, Swaroop and Linzen, Tal and Schuster, Tal and Li, Tao and Yu, Tao and Ali, Tariq and Hashimoto, Tatsu and Wu, Te-Lin and Desbordes, Théo and Rothschild, Theodore and Phan, Thomas and Wang, Tianle and Nkinyili, Tiberius and Schick, Timo and Kornev, Timofei and Telleen-Lawton, Timothy and Tunduny, Titus and Gerstenberg, Tobias and Chang, Trenton and Neeraj, Trishala and Khot, Tushar and Shultz, Tyler and Shaham, Uri and Misra, Vedant and Demberg, Vera and Nyamai, Victoria and Raunak, Vikas and Ramasesh, Vinay and Prabhu, Vinay Uday and Padmakumar, Vishakh and Srikumar, Vivek and Fedus, William and Saunders, William and Zhang, William and Vossen, Wout and Ren, Xiang and Tong, Xiaoyu and Zhao, Xinran and Wu, Xinyi and Shen, Xudong and Yaghoobzadeh, Yadollah and Lakretz, Yair and Song, Yangqiu and Bahri, Yasaman and Choi, Yejin and Yang, Yichi and Hao, Yiding and Chen, Yifu and Belinkov, Yonatan and Hou, Yu and Hou, Yufang and Bai, Yuntao and Seid, Zachary and Zhao, Zhuoye and Wang, Zijian and Wang, Zijie J. and Wang, Zirui and Wu, Ziyi},
	month = jun,
	year = {2022},
	note = {Number: arXiv:2206.04615
arXiv:2206.04615 [cs, stat]},
}

@techreport{wei_emergent_2022,
	title = {Emergent {Abilities} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2206.07682},
	abstract = {Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence implies that additional scaling could further expand the range of capabilities of language models.},
	number = {arXiv:2206.07682},
	urldate = {2022-06-16},
	institution = {arXiv},
	author = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and Chi, Ed H. and Hashimoto, Tatsunori and Vinyals, Oriol and Liang, Percy and Dean, Jeff and Fedus, William},
	month = jun,
	year = {2022},
	note = {arXiv:2206.07682 [cs]
type: article},
	keywords = {Computer Science - Computation and Language},
}

@article{coppola_quality_2021,
	title = {Quality {Assessment} {Methods} for {Textual} {Conversational} {Interfaces}: {A} {Multivocal} {Literature} {Review}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2078-2489},
	shorttitle = {Quality {Assessment} {Methods} for {Textual} {Conversational} {Interfaces}},
	url = {https://www.mdpi.com/2078-2489/12/11/437},
	doi = {10.3390/info12110437},
	abstract = {The evaluation and assessment of conversational interfaces is a complex task since such software products are challenging to validate through traditional testing approaches. We conducted a systematic Multivocal Literature Review (MLR), on five different literature sources, to provide a view on quality attributes, evaluation frameworks, and evaluation datasets proposed to provide aid to the researchers and practitioners of the field. We came up with a final pool of 118 contributions, including grey (35) and white literature (83). We categorized 123 different quality attributes and metrics under ten different categories and four macro-categories: Relational, Conversational, User-Centered and Quantitative attributes. While Relational and Conversational attributes are most commonly explored by the scientific literature, we testified a predominance of User-Centered Attributes in industrial literature. We also identified five different academic frameworks/tools to automatically compute sets of metrics, and 28 datasets (subdivided into seven different categories based on the type of data contained) that can produce conversations for the evaluation of conversational interfaces. Our analysis of literature highlights that a high number of qualitative and quantitative attributes are available in the literature to evaluate the performance of conversational interfaces. Our categorization can serve as a valid entry point for researchers and practitioners to select the proper functional and non-functional aspects to be evaluated for their products.},
	language = {en},
	number = {11},
	urldate = {2022-06-16},
	journal = {Information},
	author = {Coppola, Riccardo and Ardito, Luca},
	month = nov,
	year = {2021},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {437},
}

@inproceedings{langevin_heuristic_2021,
	address = {Yokohama Japan},
	title = {Heuristic {Evaluation} of {Conversational} {Agents}},
	isbn = {978-1-4503-8096-6},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445312},
	doi = {10.1145/3411764.3445312},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Langevin, Raina and Lordon, Ross J and Avrahami, Thi and Cowan, Benjamin R. and Hirsch, Tad and Hsieh, Gary},
	month = may,
	year = {2021},
	pages = {1--15},
}

@incollection{massaro_developing_1999,
	address = {San Diego},
	series = {Handbook of {Perception} and {Cognition} ({Second} {Edition})},
	title = {Developing and {Evaluating} conversational {Agents}},
	isbn = {978-0-12-322735-5},
	url = {https://www.sciencedirect.com/science/article/pii/B9780123227355500087},
	abstract = {This chapter focuses on the development and evaluation of conversational agents. Computer users can benefit from interaction with conversational agents and the access to the many sources of information that they can provide. A completely animated synthetic talking head with which one can control and study the informative aspects and psychological processes in face-to face dialogues has been developed. The goal of this chapter is to advance the development of the talking head, its design, and its accompanying technology and to create a human–computer interface centered on a virtual, conversational agent. Such agents interact with human users in the most natural manner possible, including the ability to listen and understand as well as speak fluently. Agents will facilitate and enrich interaction between humans and machines. Moreover, communication among humans can also be enhanced when mediated by virtual agents. The conversational agent can also be the interface for a series of public, interactive, art installations. This chapter expands the use of the agent in educational and therapeutic environments, as in the learning of non-native languages and in learning to read.},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {Human {Performance} and {Ergonomics}},
	publisher = {Academic Press},
	author = {Massaro, Dominic W. and Cohen, Michael M. and Daniel, Sharon and Cole, Ronald A.},
	editor = {Hancock, P. A.},
	month = jan,
	year = {1999},
	doi = {10.1016/B978-012322735-5/50008-7},
	pages = {173--194},
}

@misc{li_you_2022,
	title = {You {Don}'t {Know} {My} {Favorite} {Color}: {Preventing} {Dialogue} {Representations} from {Revealing} {Speakers}' {Private} {Personas}},
	shorttitle = {You {Don}'t {Know} {My} {Favorite} {Color}},
	url = {http://arxiv.org/abs/2205.10228},
	doi = {10.48550/arXiv.2205.10228},
	abstract = {Social chatbots, also known as chit-chat chatbots, evolve rapidly with large pretrained language models. Despite the huge progress, privacy concerns have arisen recently: training data of large language models can be extracted via model inversion attacks. On the other hand, the datasets used for training chatbots contain many private conversations between two individuals. In this work, we further investigate the privacy leakage of the hidden states of chatbots trained by language modeling which has not been well studied yet. We show that speakers' personas can be inferred through a simple neural network with high accuracy. To this end, we propose effective defense objectives to protect persona leakage from hidden states. We conduct extensive experiments to demonstrate that our proposed defense objectives can greatly reduce the attack accuracy from 37.6\% to 0.5\%. Meanwhile, the proposed objectives preserve language models' powerful generation ability.},
	urldate = {2022-06-16},
	publisher = {arXiv},
	author = {Li, Haoran and Song, Yangqiu and Fan, Lixin},
	month = apr,
	year = {2022},
	note = {Number: arXiv:2205.10228
arXiv:2205.10228 [cs]},
}

@inproceedings{wu_deep_2019,
	address = {New York, NY, USA},
	series = {{SIGIR}'19},
	title = {Deep {Chit}-{Chat}: {Deep} {Learning} for {Chatbots}},
	isbn = {978-1-4503-6172-9},
	shorttitle = {Deep {Chit}-{Chat}},
	url = {https://doi.org/10.1145/3331184.3331388},
	doi = {10.1145/3331184.3331388},
	abstract = {The tutorial is based on our long-term research on open domain conversation, rich hands-on experience on development of Microsoft XiaoIce, and our previous tutorials on EMNLP 2018 and the Web Conference 2019. It starts from a summary of recent achievement made by both academia and industry on chatbots, and then performs a thorough and systematic introduction to state-of-the-art methods for open domain conversation modeling including both retrieval-based methods and generation-based methods. In addition to these, the tutorial also covers some new progress on both groups of methods, such as transition from model design to model learning, transition from knowledge agnostic conversation to knowledge aware conversation, and transition from single-modal conversation to multi-modal conversation. The tutorial is ended by some promising future directions such as how to combine non-task-oriented dialogue systems with task-oriented dialogue systems and how to enhance language learning with chatbots.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 42nd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Wei and Yan, Rui},
	month = jul,
	year = {2019},
	pages = {1413--1414},
}

@inproceedings{maroengsit_survey_2019,
	address = {New York, NY, USA},
	series = {{ICIET} 2019},
	title = {A {Survey} on {Evaluation} {Methods} for {Chatbots}},
	isbn = {978-1-4503-6639-7},
	url = {https://doi.org/10.1145/3323771.3323824},
	doi = {10.1145/3323771.3323824},
	abstract = {Nowadays chatbots have been widely adopted in many industries to automatically answer users' questions and requests via chat interfaces. While it has become much easier to develop a chatbot system, the system itself is a complex system in nature. It is a challenge to evaluate and compare various chatbot systems in terms of effectiveness, efficiency, goal achievability, and the ability to satisfy users. This paper presents a survey, starting from literature review, chatbot architecture, evaluation methods/criteria, and comparison of evaluation methods. Focused on the three subprocesses in the chatbot architecture: text processing, semantic understanding, and response generation. Moreover, the survey is conducted with classification of chatbot evaluation methods and their analysis according to chatbot types and three main evaluation schemes; content evaluation, user satisfaction, and chat function.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 2019 7th {International} {Conference} on {Information} and {Education} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Maroengsit, Wari and Piyakulpinyo, Thanarath and Phonyiam, Korawat and Pongnumkul, Suporn and Chaovalit, Pimwadee and Theeramunkong, Thanaruk},
	year = {2019},
	pages = {111--119},
}

@inproceedings{jain_evaluating_2018,
	address = {New York, NY, USA},
	series = {{DIS} '18},
	title = {Evaluating and {Informing} the {Design} of {Chatbots}},
	isbn = {978-1-4503-5198-0},
	url = {https://doi.org/10.1145/3196709.3196735},
	doi = {10.1145/3196709.3196735},
	abstract = {Text messaging-based conversational agents (CAs), popularly called chatbots, received significant attention in the last two years. However, chatbots are still in their nascent stage: They have a low penetration rate as 84\% of the Internet users have not used a chatbot yet. Hence, understanding the usage patterns of first-time users can potentially inform and guide the design of future chatbots. In this paper, we report the findings of a study with 16 first-time chatbot users interacting with eight chatbots over multiple sessions on the Facebook Messenger platform. Analysis of chat logs and user interviews revealed that users preferred chatbots that provided either a 'human-like' natural language conversation ability, or an engaging experience that exploited the benefits of the familiar turn-based messaging interface. We conclude with implications to evolve the design of chatbots, such as: clarify chatbot capabilities, sustain conversation context, handle dialog failures, and end conversations gracefully.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 2018 {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Jain, Mohit and Kumar, Pratyush and Kota, Ramachandra and Patel, Shwetak N.},
	month = jun,
	year = {2018},
	pages = {895--906},
}

@inproceedings{fang_sounding_2018,
	address = {New Orleans, Louisiana},
	title = {Sounding {Board}: {A} {User}-{Centric} and {Content}-{Driven} {Social} {Chatbot}},
	shorttitle = {Sounding {Board}},
	url = {https://aclanthology.org/N18-5020},
	doi = {10.18653/v1/N18-5020},
	abstract = {We present Sounding Board, a social chatbot that won the 2017 Amazon Alexa Prize. The system architecture consists of several components including spoken language processing, dialogue management, language generation, and content management, with emphasis on user-centric and content-driven design. We also share insights gained from large-scale online logs based on 160,000 conversations with real-world users.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Fang, Hao and Cheng, Hao and Sap, Maarten and Clark, Elizabeth and Holtzman, Ari and Choi, Yejin and Smith, Noah A. and Ostendorf, Mari},
	month = jun,
	year = {2018},
	pages = {96--100},
}

@inproceedings{see_understanding_2021,
	address = {Singapore and Online},
	title = {Understanding and predicting user dissatisfaction in a neural generative chatbot},
	url = {https://aclanthology.org/2021.sigdial-1.1},
	abstract = {Neural generative dialogue agents have shown an increasing ability to hold short chitchat conversations, when evaluated by crowdworkers in controlled settings. However, their performance in real-life deployment – talking to intrinsically-motivated users in noisy environments – is less well-explored. In this paper, we perform a detailed case study of a neural generative model deployed as part of Chirpy Cardinal, an Alexa Prize socialbot. We find that unclear user utterances are a major source of generative errors such as ignoring, hallucination, unclearness and repetition. However, even in unambiguous contexts the model frequently makes reasoning errors. Though users express dissatisfaction in correlation with these errors, certain dissatisfaction types (such as offensiveness and privacy objections) depend on additional factors – such as the user's personal attitudes, and prior unaddressed dissatisfaction in the conversation. Finally, we show that dissatisfied user utterances can be used as a semi-supervised learning signal to improve the dialogue system. We train a model to predict next-turn dissatisfaction, and show through human evaluation that as a ranking function, it selects higher-quality neural-generated utterances.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 22nd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {See, Abigail and Manning, Christopher},
	month = jul,
	year = {2021},
	pages = {1--12},
}

@inproceedings{shalyminov_neural_2018,
	address = {Brussels, Belgium},
	title = {Neural {Response} {Ranking} for {Social} {Conversation}: {A} {Data}-{Efficient} {Approach}},
	shorttitle = {Neural {Response} {Ranking} for {Social} {Conversation}},
	url = {https://aclanthology.org/W18-5701},
	doi = {10.18653/v1/W18-5701},
	abstract = {The overall objective of `social' dialogue systems is to support engaging, entertaining, and lengthy conversations on a wide variety of topics, including social chit-chat. Apart from raw dialogue data, user-provided ratings are the most common signal used to train such systems to produce engaging responses. In this paper we show that social dialogue systems can be trained effectively from raw unannotated data. Using a dataset of real conversations collected in the 2017 Alexa Prize challenge, we developed a neural ranker for selecting `good' system responses to user utterances, i.e. responses which are likely to lead to long and engaging conversations. We show that (1) our neural ranker consistently outperforms several strong baselines when trained to optimise for user ratings; (2) when trained on larger amounts of data and only using conversation length as the objective, the ranker performs better than the one trained using ratings – ultimately reaching a Precision@1 of 0.87. This advance will make data collection for social conversational agents simpler and less expensive in the future.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 2018 {EMNLP} {Workshop} {SCAI}: {The} 2nd {International} {Workshop} on {Search}-{Oriented} {Conversational} {AI}},
	publisher = {Association for Computational Linguistics},
	author = {Shalyminov, Igor and Dušek, Ondřej and Lemon, Oliver},
	month = oct,
	year = {2018},
	pages = {1--8},
}

@inproceedings{juraska_athena_2021,
	address = {Online and Punta Cana, Dominican Republic},
	title = {Athena 2.0: {Contextualized} {Dialogue} {Management} for an {Alexa} {Prize} {SocialBot}},
	shorttitle = {Athena 2.0},
	url = {https://aclanthology.org/2021.emnlp-demo.15},
	doi = {10.18653/v1/2021.emnlp-demo.15},
	abstract = {Athena 2.0 is an Alexa Prize SocialBot that has been a finalist in the last two Alexa Prize Grand Challenges. One reason for Athena's success is its novel dialogue management strategy, which allows it to dynamically construct dialogues and responses from component modules, leading to novel conversations with every interaction. Here we describe Athena's system design and performance in the Alexa Prize during the 20/21 competition. A live demo of Athena as well as video recordings will provoke discussion on the state of the art in conversational AI.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Juraska, Juraj and Bowden, Kevin and Reed, Lena and Harrison, Vrindavan and Cui, Wen and Patil, Omkar and Rajasekaran, Rishi and Ramirez, Angela and Li, Cecilia and Zamora, Eduardo and Lee, Phillip and Bheemanpally, Jeshwanth and Pandey, Rohan and Ratnaparkhi, Adwait and Walker, Marilyn},
	month = nov,
	year = {2021},
	pages = {124--133},
}

@inproceedings{yu_gunrock_2019,
	address = {Hong Kong, China},
	title = {Gunrock: {A} {Social} {Bot} for {Complex} and {Engaging} {Long} {Conversations}},
	shorttitle = {Gunrock},
	url = {https://aclanthology.org/D19-3014},
	doi = {10.18653/v1/D19-3014},
	abstract = {Gunrock is the winner of the 2018 Amazon Alexa Prize, as evaluated by coherence and engagement from both real users and Amazon-selected expert conversationalists. We focus on understanding complex sentences and having in-depth conversations in open domains. In this paper, we introduce some innovative system designs and related validation analysis. Overall, we found that users produce longer sentences to Gunrock, which are directly related to users' engagement (e.g., ratings, number of turns). Additionally, users' backstory queries about Gunrock are positively correlated to user satisfaction. Finally, we found dialog flows that interleave facts and personal opinions and stories lead to better user satisfaction.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP}): {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Yu, Dian and Cohn, Michelle and Yang, Yi Mang and Chen, Chun Yen and Wen, Weiming and Zhang, Jiaping and Zhou, Mingyang and Jesse, Kevin and Chau, Austin and Bhowmick, Antara and Iyer, Shreenath and Sreenivasulu, Giritheja and Davidson, Sam and Bhandare, Ashwin and Yu, Zhou},
	month = nov,
	year = {2019},
	pages = {79--84},
}

@inproceedings{cohn_large-scale_2019,
	address = {Stockholm, Sweden},
	title = {A {Large}-{Scale} {User} {Study} of an {Alexa} {Prize} {Chatbot}: {Effect} of {TTS} {Dynamism} on {Perceived} {Quality} of {Social} {Dialog}},
	shorttitle = {A {Large}-{Scale} {User} {Study} of an {Alexa} {Prize} {Chatbot}},
	url = {https://aclanthology.org/W19-5935},
	doi = {10.18653/v1/W19-5935},
	abstract = {This study tests the effect of cognitive-emotional expression in an Alexa text-to-speech (TTS) voice on users' experience with a social dialog system. We systematically introduced emotionally expressive interjections (e.g., “Wow!”) and filler words (e.g., “um”, “mhmm”) in an Amazon Alexa Prize socialbot, Gunrock. We tested whether these TTS manipulations improved users' ratings of their conversation across thousands of real user interactions (n=5,527). Results showed that interjections and fillers each improved users' holistic ratings, an improvement that further increased if the system used both manipulations. A separate perception experiment corroborated the findings from the user study, with improved social ratings for conversations including interjections; however, no positive effect was observed for fillers, suggesting that the role of the rater in the conversation—as active participant or external listener—is an important factor in assessing social dialogs.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 20th {Annual} {SIGdial} {Meeting} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Cohn, Michelle and Chen, Chun-Yen and Yu, Zhou},
	month = sep,
	year = {2019},
	pages = {293--306},
}

@article{khatri_alexa_2018,
	title = {Alexa {Prize} — {State} of the {Art} in {Conversational} {AI}},
	volume = {39},
	copyright = {Copyright (c) 0 AI Magazine},
	issn = {2371-9621},
	url = {https://ojs.aaai.org/index.php/aimagazine/article/view/2810},
	doi = {10.1609/aimag.v39i3.2810},
	abstract = {To advance the state of the art in conversational AI, Amazon launched the Alexa Prize, a 2.5 million dollar competition that challenges university teams to build conversational agents, or "socialbots", that can converse coherently and engagingly with humans on popular topics for 20 minutes. The Alexa Prize offers the academic community a unique opportunity to perform research at scale with real conversational data obtained by interacting with millions of Alexa users, along with user-provided ratings and feedback, over several months. This enables teams to effectively iterate, improve and evaluate their socialbots throughout the competition. Sixteen teams were selected for the inaugural competition last year. To build their socialbots, the students combined state-of-the-art techniques with their own novel strategies in the areas of Natural Language Understanding and Conversational AI. This article reports on the research conducted over the 2017-2018 year. While the 20 minute grand challenge was not achieved in the first year, the competition produced several conversational agents that advanced the state of the art, are interesting for everyday users to interact with, and help form a baseline for the second year of the competition.},
	language = {en},
	number = {3},
	urldate = {2022-06-16},
	journal = {AI Magazine},
	author = {Khatri, Chandra and Venkatesh, Anu and Hedayatnia, Behnam and Gabriel, Raefer and Ram, Ashwin and Prasad, Rohit},
	month = sep,
	year = {2018},
	note = {Number: 3},
	pages = {40--55},
}

@article{church_introduction_1993,
	title = {Introduction to the {Special} {Issue} on {Computational} {Linguistics} {Using} {Large} {Corpora}},
	volume = {19},
	url = {https://aclanthology.org/J93-1001},
	number = {1},
	urldate = {2022-06-15},
	journal = {Computational Linguistics},
	author = {Church, Kenneth W. and Mercer, Robert L.},
	year = {1993},
	note = {Place: Cambridge, MA
Publisher: MIT Press},
	pages = {1--24},
}

@article{pavlick_inherent_2019,
	title = {Inherent {Disagreements} in {Human} {Textual} {Inferences}},
	volume = {7},
	url = {https://aclanthology.org/Q19-1043},
	doi = {10.1162/tacl_a_00293},
	abstract = {We analyze human's disagreements about the validity of natural language inferences. We show that, very often, disagreements are not dismissible as annotation “noise”, but rather persist as we collect more ratings and as we vary the amount of context provided to raters. We further show that the type of uncertainty captured by current state-of-the-art models for natural language inference is not reflective of the type of uncertainty present in human disagreements. We discuss implications of our results in relation to the recognizing textual entailment (RTE)/natural language inference (NLI) task. We argue for a refined evaluation objective that requires models to explicitly capture the full distribution of plausible human judgments.},
	urldate = {2022-06-15},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Pavlick, Ellie and Kwiatkowski, Tom},
	year = {2019},
	note = {Place: Cambridge, MA
Publisher: MIT Press},
	pages = {677--694},
}

@article{basile_toward_nodate,
	title = {Toward a {Perspectivist} {Turn} in {Ground} {Truthing} for {Predictive} {Computing}},
	abstract = {Most Artiﬁcial Intelligence applications are based on supervised machine learning (ML), which ultimately grounds on manually annotated data. The annotation process is often performed in terms of a majority vote and this has been proved to be often problematic, as highlighted by recent studies on the evaluation of ML models. In this article we describe and advocate for a diﬀerent paradigm, which we call data perspectivism, which moves away from traditional gold standard datasets, towards the adoption of methods that integrate the opinions and perspectives of the human subjects involved in the knowledge representation step of ML processes. Drawing on previous works which inspired our proposal we describe the potential of our proposal for not only the more subjective tasks (e.g. those related to human language) but also to tasks commonly understood as objective (e.g. medical decision making), and present the main advantages of adopting a perspectivist stance in ML, as well as possible disadvantages, and various ways in which such a stance can be implemented in practice. Finally, we share a set of recommendations and outline a research agenda to advance the perspectivist stance in ML.},
	language = {en},
	author = {Basile, Valerio and Cabitza, Federico and Campagner, Andrea and Fell, Michael},
	pages = {16},
}

@article{dupre_metaphysics_2021,
	title = {The {Metaphysics} of {Biology}},
	url = {https://www.cambridge.org/core/elements/metaphysics-of-biology/AB442638E22AA42B3185EF0419F99A04},
	doi = {10.1017/9781009024297},
	abstract = {Cambridge Core - Philosophy: General Interest - The Metaphysics of Biology},
	language = {en},
	urldate = {2022-06-15},
	journal = {Elements in the Philosophy of Biology},
	author = {Dupré, John},
	month = may,
	year = {2021},
	note = {ISBN: 9781009024297 9781009011105
Publisher: Cambridge University Press},
}

@article{bigham_technical_2022,
	title = {Technical perspective: {Computation} where the (inter)action is},
	volume = {65},
	issn = {0001-0782, 1557-7317},
	shorttitle = {Technical perspective},
	url = {https://dl.acm.org/doi/10.1145/3531446},
	doi = {10.1145/3531446},
	language = {en},
	number = {6},
	urldate = {2022-06-14},
	journal = {Communications of the ACM},
	author = {Bigham, Jeffrey P.},
	month = jun,
	year = {2022},
	pages = {99--99},
}

@article{wegner_why_1997,
	title = {Why interaction is more powerful than algorithms},
	volume = {40},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/253769.253801},
	doi = {10.1145/253769.253801},
	language = {en},
	number = {5},
	urldate = {2022-06-14},
	journal = {Communications of the ACM},
	author = {Wegner, Peter},
	month = may,
	year = {1997},
	pages = {80--91},
}

@incollection{enfield_social_2006,
	address = {Oxford},
	title = {Social {Consequences} of {Common} {Ground}},
	booktitle = {Roots of human sociality: {Culture}, cognition, and human interaction},
	publisher = {Berg},
	author = {Enfield, N. J.},
	editor = {Enfield, N. J. and Levinson, Stephen C.},
	year = {2006},
	pages = {399--430},
}

@inproceedings{dingemanse_text_2022,
	address = {Dublin},
	title = {From text to talk: {Harnessing} conversational corpora for humane and diversity-aware language technology},
	doi = {10.18653/v1/2022.acl-long.385},
	abstract = {Informal social interaction is the primordial home of human language. Linguistically diverse conversational corpora are an important and largely untapped resource for computational linguistics and language technology. Through the efforts of a worldwide language documentation movement, such corpora are increasingly becoming available. We show how interactional data from 63 languages (26 families) harbours insights about turn-taking, timing, sequential structure and social action, with implications for language technology, natural language understanding, and the design of conversational interfaces. Harnessing linguistically diverse conversational corpora will provide the empirical foundations for flexible, localizable, humane language technologies of the future.},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Dingemanse, Mark and Liesenfeld, Andreas},
	year = {2022},
	pages = {5614--5633},
}

@inproceedings{al_moubayed_furhat_2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Furhat: {A} {Back}-{Projected} {Human}-{Like} {Robot} {Head} for {Multiparty} {Human}-{Machine} {Interaction}},
	isbn = {978-3-642-34584-5},
	shorttitle = {Furhat},
	doi = {10.1007/978-3-642-34584-5_9},
	abstract = {In this chapter, we first present a summary of findings from two previous studies on the limitations of using flat displays with embodied conversational agents (ECAs) in the contexts of face-to-face human-agent interaction. We then motivate the need for a three dimensional display of faces to guarantee accurate delivery of gaze and directional movements and present Furhat, a novel, simple, highly effective, and human-like back-projected robot head that utilizes computer animation to deliver facial movements, and is equipped with a pan-tilt neck. After presenting a detailed summary on why and how Furhat was built, we discuss the advantages of using optically projected animated agents for interaction. We discuss using such agents in terms of situatedness, environment, context awareness, and social, human-like face-to-face interaction with robots where subtle nonverbal and social facial signals can be communicated. At the end of the chapter, we present a recent application of Furhat as a multimodal multiparty interaction system that was presented at the London Science Museum as part of a robot festival,. We conclude the paper by discussing future developments, applications and opportunities of this technology.},
	language = {en},
	booktitle = {Cognitive {Behavioural} {Systems}},
	publisher = {Springer},
	author = {Al Moubayed, Samer and Beskow, Jonas and Skantze, Gabriel and Granström, Björn},
	editor = {Esposito, Anna and Esposito, Antonietta M. and Vinciarelli, Alessandro and Hoffmann, Rüdiger and Müller, Vincent C.},
	year = {2012},
	pages = {114--130},
}

@article{pandey_mass-produced_2018,
	title = {A {Mass}-{Produced} {Sociable} {Humanoid} {Robot}: {Pepper}: {The} {First} {Machine} of {Its} {Kind}},
	volume = {25},
	issn = {1558-223X},
	shorttitle = {A {Mass}-{Produced} {Sociable} {Humanoid} {Robot}},
	doi = {10.1109/MRA.2018.2833157},
	abstract = {As robotics technology evolves, we believe that personal social robots will be one of the next big expansions in the robotics sector. Based on the accelerated advances in this multidisciplinary domain and the growing number of use cases, we can posit that robots will play key roles in everyday life and will soon coexist with us, leading all people to a smarter, safer, healthier, and happier existence.},
	number = {3},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Pandey, Amit Kumar and Gelin, Rodolphe},
	month = sep,
	year = {2018},
	note = {Conference Name: IEEE Robotics \& Automation Magazine},
	pages = {40--48},
}

@article{cutler_segmentation_1994,
	title = {Segmentation problems, rhythmic solutions},
	volume = {92},
	issn = {0024-3841},
	url = {https://www.sciencedirect.com/science/article/pii/0024384194903387},
	doi = {10.1016/0024-3841(94)90338-7},
	abstract = {The lexicon contains discrete entries, which must be located in speech input in order for speech to be understood; but the continuity of speech signals means that lexical access from spoken input involves a segmentation problem for listeners. The speech environment of prelinguistic infants may not provide special information to assist the infant listeners in solving this problem. Mature language users in possession of a lexicon might be thought to be able to avoid explicit segmentation of speech by relying on information from successful lexical access; however, evidence from adult perceptual studies indicates that listeners do use explicit segmentation procedures. These procedures differ across languages and seem to exploit language-specific rhythmic structure. Efficient as these procedures are, they may not have been developed in response to statistical properties of the input, because bilinguals, equally competent in two languages, apparently only possess one rhythmic segmentation procedure. The origin of rhythmic segmentation may therefore lie in the infant's exploitation of rhythm to solve the segmentation problem and gain a first toehold on lexical acquisition. Recent evidence from speech production and perception studies with prelinguistic infants supports the claim that infants are sensitive to rhythmic structure and its relationship to lexical segmentation.},
	language = {en},
	urldate = {2022-06-10},
	journal = {Lingua},
	author = {Cutler, Anne},
	month = apr,
	year = {1994},
	pages = {81--104},
}

@inproceedings{draxler_clarin_2020,
	address = {Marseille, France},
	title = {A {CLARIN} {Transcription} {Portal} for {Interview} {Data}},
	isbn = {979-10-95546-34-4},
	url = {https://aclanthology.org/2020.lrec-1.411},
	abstract = {In this paper we present a first version of a transcription portal for audio files based on automatic speech recognition (ASR) in various languages. The portal is implemented in the CLARIN resources research network and intended for use by non-technical scholars. We explain the background and interdisciplinary nature of interview data, the perks and quirks of using ASR for transcribing the audio in a research context, the dos and don'ts for optimal use of the portal, and future developments foreseen. The portal is promoted in a range of workshops, but there are a number of challenges that have to be met. These challenges concern privacy issues, ASR quality, and cost, amongst others.},
	language = {English},
	urldate = {2022-06-10},
	booktitle = {Proceedings of the 12th {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Draxler, Christoph and van den Heuvel, Henk and van Hessen, Arjan and Calamai, Silvia and Corti, Louise},
	month = may,
	year = {2020},
	pages = {3353--3359},
}

@inproceedings{yilmaz_code-switching_2016,
	title = {Code-switching detection using multilingual {DNNS}},
	doi = {10.1109/SLT.2016.7846326},
	abstract = {Automatic speech recognition (ASR) of code-switching speech requires careful handling of unexpected language switches that may occur in a single utterance. In this paper, we investigate the feasibility of using multilingually trained deep neural networks (DNN) for the ASR of Frisian speech containing code-switches to Dutch with the aim of building a robust recognizer that can handle this phenomenon. For this purpose, we train several multilingual DNN models on Frisian and two closely related languages, namely English and Dutch, to compare the impact of single-step and two-step multilingual DNN training on the recognition and code-switching detection performance. We apply bilingual DNN retraining on both target languages by varying the amount of training data belonging to the higher-resourced target language (Dutch). The recognition results show that the multilingual DNN training scheme with an initial multilingual training step followed by bilingual retraining provides recognition performance comparable to an oracle baseline recognizer that can employ language-specific acoustic models. We further show that we can detect code-switches at the word level with an equal error rate of around 17\% excluding the deletions due to ASR errors.},
	booktitle = {2016 {IEEE} {Spoken} {Language} {Technology} {Workshop} ({SLT})},
	author = {Yılmaz, Emre and van den Heuvel, Henk and van Leeuwen, David},
	month = dec,
	year = {2016},
	pages = {610--616},
}

@inproceedings{stadtschnitzer_exploiting_2014,
	address = {Reykjavik, Iceland},
	title = {Exploiting the large-scale {German} {Broadcast} {Corpus} to boost the {Fraunhofer} {IAIS} {Speech} {Recognition} {System}},
	url = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/858_Paper.pdf},
	abstract = {In this paper we describe the large-scale German broadcast corpus (GER-TV1000h) containing more than 1,000 hours of transcribed speech data. This corpus is unique in the German language corpora domain and enables significant progress in tuning the acoustic modelling of German large vocabulary continuous speech recognition (LVCSR) systems. The exploitation of this huge broadcast corpus is demonstrated by optimizing and improving the Fraunhofer IAIS speech recognition system. Due to the availability of huge amount of acoustic training data new training strategies are investigated. The performance of the automatic speech recognition (ASR) system is evaluated on several datasets and compared to previously published results. It can be shown that the word error rate (WER) using a larger corpus can be reduced by up to 9.1 {\textbackslash}textbackslash\% relative. By using both larger corpus and recent training paradigms the WER was reduced by up to 35.8 {\textbackslash}textbackslash\% relative and below 40 {\textbackslash}textbackslash\% absolute even for spontaneous dialectal speech in noisy conditions, making the ASR output a useful resource for subsequent tasks like named entity recognition also in difficult acoustic situations.},
	urldate = {2022-06-09},
	booktitle = {Proceedings of the {Ninth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'14)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Stadtschnitzer, Michael and Schwenninger, Jochen and Stein, Daniel and Koehler, Joachim},
	month = may,
	year = {2014},
	pages = {3887--3890},
}

@incollection{moore_is_2017,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Is {Spoken} {Language} {All}-or-{Nothing}? {Implications} for {Future} {Speech}-{Based} {Human}-{Machine} {Interaction}},
	isbn = {978-981-10-2585-3},
	shorttitle = {Is {Spoken} {Language} {All}-or-{Nothing}?},
	url = {https://doi.org/10.1007/978-981-10-2585-3_22},
	abstract = {RecentMoore, Roger K.years have seen significant market penetration for voice-based personal assistants such as Apple’s Siri. However, despite this success, user take-up is frustratingly low. This article argues that there is a habitability gap caused by the inevitable mismatch between the capabilities and expectations of human users and the features and benefits provided by contemporary technology. Suggestions are made as to how such problems might be mitigated, but a more worrisome question emerges: “is spoken language all-or-nothing”? The answer, based on contemporary views on the special nature of (spoken) language, is that there may indeed be a fundamental limit to the interaction that can take place between mismatched interlocutors (such as humans and machines). However, it is concluded that interactions between native and non-native speakers, or between adults and children, or even between humans and dogs, might provide critical inspiration for the design of future speech-based human-machine interaction.},
	language = {en},
	urldate = {2022-06-09},
	booktitle = {Dialogues with {Social} {Robots}: {Enablements}, {Analyses}, and {Evaluation}},
	publisher = {Springer},
	author = {Moore, Roger K.},
	editor = {Jokinen, Kristiina and Wilcock, Graham},
	year = {2017},
	doi = {10.1007/978-981-10-2585-3_22},
	pages = {281--291},
}

@article{jadoul_introducing_2018,
	title = {Introducing parselmouth: {A} {Python} interface to {Praat}},
	volume = {71},
	shorttitle = {Introducing parselmouth},
	journal = {Journal of Phonetics},
	author = {Jadoul, Yannick and Thompson, Bill and De Boer, Bart},
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {1--15},
}

@article{errattahi_automatic_2018,
	title = {Automatic {Speech} {Recognition} {Errors} {Detection} and {Correction}: {A} {Review}},
	volume = {128},
	issn = {18770509},
	shorttitle = {Automatic {Speech} {Recognition} {Errors} {Detection} and {Correction}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050918302187},
	doi = {10.1016/j.procs.2018.03.005},
	language = {en},
	urldate = {2022-06-08},
	journal = {Procedia Computer Science},
	author = {Errattahi, Rahhal and El Hannani, Asmaa and Ouahmane, Hassan},
	year = {2018},
	pages = {32--37},
}

@inproceedings{barker_fifth_2018,
	title = {The {Fifth} '{CHiME}' {Speech} {Separation} and {Recognition} {Challenge}: {Dataset}, {Task} and {Baselines}},
	shorttitle = {The {Fifth} '{CHiME}' {Speech} {Separation} and {Recognition} {Challenge}},
	url = {https://www.isca-speech.org/archive/interspeech_2018/barker18_interspeech.html},
	doi = {10.21437/Interspeech.2018-1768},
	abstract = {The CHiME challenge series aims to advance robust automatic speech recognition (ASR) technology by promoting research at the interface of speech and language processing, signal processing , and machine learning. This paper introduces the 5th CHiME Challenge, which considers the task of distant multi-microphone conversational ASR in real home environments. Speech material was elicited using a dinner party scenario with efforts taken to capture data that is representative of natural conversational speech and recorded by 6 Kinect microphone arrays and 4 binaural microphone pairs. The challenge features a single-array track and a multiple-array track and, for each track, distinct rankings will be produced for systems focusing on robustness with respect to distant-microphone capture vs. systems attempting to address all aspects of the task including conversational language modeling. We discuss the rationale for the challenge and provide a detailed description of the data collection procedure, the task, and the baseline systems for array synchronization, speech enhancement, and conventional and end-to-end ASR.},
	language = {en},
	urldate = {2022-06-07},
	booktitle = {Interspeech 2018},
	publisher = {ISCA},
	author = {Barker, Jon and Watanabe, Shinji and Vincent, Emmanuel and Trmal, Jan},
	month = sep,
	year = {2018},
	pages = {1561--1565},
}

@inproceedings{mansfield_revisiting_2021,
	title = {Revisiting {Parity} of {Human} vs. {Machine} {Conversational} {Speech} {Transcription}},
	url = {https://www.isca-speech.org/archive/interspeech_2021/mansfield21_interspeech.html},
	doi = {10.21437/Interspeech.2021-1908},
	abstract = {A number of studies have compared human and machine transcription, showing that automatic speech recognition (ASR) is approaching human performance in some contexts. Most studies look at differences as measured by the standard speech recognition scoring criterion: word error rate (WER). This study looks at more ﬁne-grained analysis of differences for conversational speech data where systems have reached human parity in terms of average WER, speciﬁcally insertions vs. deletions, word category, and word context characterized by linguistic surprisal. In contrast to ASR systems, humans are more likely to miss words than to misrecognize them, and they are much more likely to make errors in transcribing words associated primarily with conversational contexts (ﬁllers, backchannels and discourse cue words). The differences are more pronounced for more informal contexts, i.e. conversations between family members. Although human transcribers may miss these words, conversational partners seem to use them in turntaking and processing disﬂuencies. Thus, ASR systems may need superhuman transcription performance for spoken language technology to achieve human-level conversation skills.},
	language = {en},
	urldate = {2022-06-07},
	booktitle = {Interspeech 2021},
	publisher = {ISCA},
	author = {Mansfield, Courtney and Ng, Sara and Levow, Gina-Anne and Wright, Richard A. and Ostendorf, Mari},
	month = aug,
	year = {2021},
	pages = {1997--2001},
}

@article{rautiainen_local_2022,
	title = {Local participation framework as a resource among military observer trainees: {Interactional} episodes between repair initiation and repair solution in critical radio communication},
	volume = {196},
	issn = {0378-2166},
	shorttitle = {Local participation framework as a resource among military observer trainees},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216622001308},
	doi = {10.1016/j.pragma.2022.05.006},
	abstract = {In critical radio-mediated communication, fixed expressions clarify and expedite interaction and provide a shared vocabulary for lingua franca interlocutors. Sometimes, communication via radio encounters trouble that needs to be clarified. This article examines interactional episodes following fixed other-initiations of self-repair “say again” in radiotelephony, as part of patrolling exercises in military observer (MO) training. The episodes occur between the repair initiation and the repair solution. Radiotelephony is inherently dyadic, but the parties may consist of more than one person. During patrolling, interaction via radio takes place within two overlapping participation frameworks. The article focuses on practices of identifying and repairing trouble in the patrol vehicle. The data come from multinational MO training, where English as lingua franca is the working language. The analysis of talk and embodied actions, drawing on conversation analysis and ethnomethodologically informed ethnography, shows that trainees use their local participation framework as a resource to make sense of the trouble in situ. The article introduces a novel set of language data and broadens our understanding of formulaic repair practices and their uptake and handling repair within overlapping participation frameworks. The findings can be utilised in developing training practices and in settings where radio serves a pivotal role.},
	language = {en},
	urldate = {2022-06-07},
	journal = {Journal of Pragmatics},
	author = {Rautiainen, Iira and Haddington, Pentti and Kamunen, Antti},
	month = jul,
	year = {2022},
	pages = {67--85},
}

@article{rodriguez-cuadrado_sign_2022,
	title = {Sign iconicity helps learning new words for abstract concepts in a foreign language},
	issn = {0267-6583},
	url = {https://doi.org/10.1177/02676583221093841},
	doi = {10.1177/02676583221093841},
	abstract = {Several studies have explored the use of iconic gestures to improve the learning of foreign vocabulary. In this quest, words for abstract concepts have been largely neglected, under the assumption that abstract concepts have poor or non-existent sensory-motor representations. Yet, the Conceptual Metaphor Theory suggests that they are grounded on concrete concepts. Moreover, analyses of signed languages reveal ways in which signs can exploit metonymies and conceptual metaphors to iconically refer to abstract concepts. Here, we explore whether iconic signs from Spanish Sign Language (LSE) can facilitate the learning of foreign words for abstract concepts in hearing participants who do not know any sign language. In two studies, participants were presented with new labels for abstract and concrete concepts in an artificial language (Vimmi). The labels could be accompanied by either a video of an iconic or non-iconic sign taken from the existing vocabulary of LSE, or a static image of the signer. In study 1, participants did not have to enact the signs they were presented with, while in study 2 they did. Both studies showed that iconic signs facilitated the learning of abstract foreign vocabulary, regardless of enactment. The strategies that sign languages use to develop iconic signs for abstract concepts make those signs useful to assist the learning of foreign words by hearing non-signers.},
	language = {en},
	urldate = {2022-06-07},
	journal = {Second Language Research},
	author = {Rodríguez-Cuadrado, Sara and Ojedo, Fernando and Vicente-Conesa, Francisco and Romero-Rivas, Carlos and Sampedro, Miguel Ángel Carlos and Santiago, Julio},
	month = jun,
	year = {2022},
	note = {Publisher: SAGE Publications Ltd},
	pages = {02676583221093841},
}

@article{ten_bosch_diana_2022,
	title = {{DIANA}, a {Process}-{Oriented} {Model} of {Human} {Auditory} {Word} {Recognition}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3425},
	url = {https://www.mdpi.com/2076-3425/12/5/681},
	doi = {10.3390/brainsci12050681},
	abstract = {This article presents DIANA, a new, process-oriented model of human auditory word recognition, which takes as its input the acoustic signal and can produce as its output word identifications and lexicality decisions, as well as reaction times. This makes it possible to compare its output with human listeners’ behavior in psycholinguistic experiments. DIANA differs from existing models in that it takes more available neuro-physiological evidence on speech processing into account. For instance, DIANA accounts for the effect of ambiguity in the acoustic signal on reaction times following the Hick–Hyman law and it interprets the acoustic signal in the form of spectro-temporal receptive fields, which are attested in the human superior temporal gyrus, instead of in the form of abstract phonological units. The model consists of three components: activation, decision and execution. The activation and decision components are described in detail, both at the conceptual level (in the running text) and at the computational level (in the Appendices). While the activation component is independent of the listener’s task, the functioning of the decision component depends on this task. The article also describes how DIANA could be improved in the future in order to even better resemble the behavior of human listeners.},
	language = {en},
	number = {5},
	urldate = {2022-06-07},
	journal = {Brain Sciences},
	author = {ten Bosch, Louis and Boves, Lou and Ernestus, Mirjam},
	month = may,
	year = {2022},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {681},
}

@inproceedings{mortensen_panphon_2016,
	address = {Osaka, Japan},
	title = {{PanPhon}: {A} {Resource} for {Mapping} {IPA} {Segments} to {Articulatory} {Feature} {Vectors}},
	shorttitle = {{PanPhon}},
	url = {https://aclanthology.org/C16-1328},
	abstract = {This paper contributes to a growing body of evidence that—when coupled with appropriate machine-learning techniques–linguistically motivated, information-rich representations can outperform one-hot encodings of linguistic data. In particular, we show that phonological features outperform character-based models. PanPhon is a database relating over 5,000 IPA segments to 21 subsegmental articulatory features. We show that this database boosts performance in various NER-related tasks. Phonologically aware, neural CRF models built on PanPhon features are able to perform better on monolingual Spanish and Turkish NER tasks that character-based models. They have also been shown to work well in transfer models (as between Uzbek and Turkish). PanPhon features also contribute measurably to Orthography-to-IPA conversion tasks.},
	urldate = {2022-06-07},
	booktitle = {Proceedings of {COLING} 2016, the 26th {International} {Conference} on {Computational} {Linguistics}: {Technical} {Papers}},
	publisher = {The COLING 2016 Organizing Committee},
	author = {Mortensen, David R. and Littell, Patrick and Bharadwaj, Akash and Goyal, Kartik and Dyer, Chris and Levin, Lori},
	month = dec,
	year = {2016},
	pages = {3475--3484},
}

@inproceedings{deri_grapheme--phoneme_2016,
	address = {Berlin, Germany},
	title = {Grapheme-to-{Phoneme} {Models} for ({Almost}) {Any} {Language}},
	url = {https://aclanthology.org/P16-1038},
	doi = {10.18653/v1/P16-1038},
	urldate = {2022-06-07},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Deri, Aliya and Knight, Kevin},
	month = aug,
	year = {2016},
	pages = {399--408},
}

@inproceedings{kontogiorgos_behavioural_2020,
	address = {Cambridge, United Kingdom},
	series = {{HRI} '20},
	title = {Behavioural {Responses} to {Robot} {Conversational} {Failures}},
	isbn = {978-1-4503-6746-2},
	url = {https://doi.org/10.1145/3319502.3374782},
	doi = {10.1145/3319502.3374782},
	abstract = {Humans and robots will increasingly collaborate in domestic environments which will cause users to encounter more failures in interactions. Robots should be able to infer conversational failures by detecting human users' behavioural and social signals. In this paper, we study and analyse these behavioural cues in response to robot conversational failures. Using a guided task corpus, where robot embodiment and time pressure are manipulated, we ask human annotators to estimate whether user affective states differ during various types of robot failures. We also train a random forest classifier to detect whether a robot failure has occurred and compare results to human annotator benchmarks. Our findings show that human-like robots augment users' reactions to failures, as shown in users' visual attention, in comparison to non-human-like smart-speaker embodiments. The results further suggest that speech behaviours are utilised more in responses to failures when non-human-like designs are present. This is particularly important to robot failure detection mechanisms that may need to consider the robot's physical design in its failure detection model.},
	urldate = {2020-03-09},
	booktitle = {Proceedings of the 2020 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Kontogiorgos, Dimosthenis and Pereira, Andre and Sahindal, Boran and van Waveren, Sanne and Gustafson, Joakim},
	month = mar,
	year = {2020},
	pages = {53--62},
}

@inproceedings{kurtic_corpus_2012,
	address = {Istanbul, Turkey},
	title = {A {Corpus} of {Spontaneous} {Multi}-party {Conversation} in {Bosnian} {Serbo}-{Croatian} and {British} {English}},
	url = {http://www.lrec-conf.org/proceedings/lrec2012/pdf/513_Paper.pdf},
	abstract = {In this paper we present a corpus of audio and video recordings of spontaneous, face-to-face multi-party conversation in two languages. Freely available high quality recordings of mundane, non-institutional, multi-party talk are still sparse, and this corpus aims to contribute valuable data suitable for study of multiple aspects of spoken interaction. In particular, it constitutes a unique resource for spoken Bosnian Serbo-Croatian (BSC), an under-resourced language with no spoken resources available at present. The corpus consists of just over 3 hours of free conversation in each of the target languages, BSC and British English (BE). The audio recordings have been made on separate channels using head-set microphones, as well as using a microphone array, containing 8 omni-directional microphones. The data has been segmented and transcribed using segmentation notions and transcription conventions developed from those of the conversation analysis research tradition. Furthermore, the transcriptions have been automatically aligned with the audio at the word and phone level, using the method of forced alignment. In this paper we describe the procedures behind the corpus creation and present the main features of the corpus for the study of conversation.},
	urldate = {2022-06-02},
	booktitle = {Proceedings of the {Eighth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'12)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Kurtić, Emina and Wells, Bill and Brown, Guy J. and Kempton, Timothy and Aker, Ahmet},
	month = may,
	year = {2012},
	pages = {1323--1327},
}

@phdthesis{orwant_doppelganger_1991,
	title = {Doppelgänger: a user modeling system},
	url = {https://dspace.mit.edu/bitstream/handle/1721.1/12952/26048671-MIT.pdf?sequence=2},
	urldate = {2022-05-11},
	school = {MIT},
	author = {Orwant, Jonathan L.},
	year = {1991},
}

@inproceedings{greco_psycholinguistics_2019,
	address = {Florence, Italy},
	title = {Psycholinguistics {Meets} {Continual} {Learning}: {Measuring} {Catastrophic} {Forgetting} in {Visual} {Question} {Answering}},
	shorttitle = {Psycholinguistics {Meets} {Continual} {Learning}},
	url = {https://aclanthology.org/P19-1350},
	doi = {10.18653/v1/P19-1350},
	abstract = {We study the issue of catastrophic forgetting in the context of neural multimodal approaches to Visual Question Answering (VQA). Motivated by evidence from psycholinguistics, we devise a set of linguistically-informed VQA tasks, which differ by the types of questions involved (Wh-questions and polar questions). We test what impact task difficulty has on continual learning, and whether the order in which a child acquires question types facilitates computational models. Our results show that dramatic forgetting is at play and that task difficulty and order matter. Two well-known current continual learning methods mitigate the problem only to a limiting degree.},
	urldate = {2022-05-24},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Greco, Claudio and Plank, Barbara and Fernández, Raquel and Bernardi, Raffaella},
	month = jul,
	year = {2019},
	pages = {3601--3605},
}

@inproceedings{takmaz_less_2022,
	address = {Dublin, Ireland},
	title = {Less {Descriptive} yet {Discriminative}: {Quantifying} the {Properties} of {Multimodal} {Referring} {Utterances} via {CLIP}},
	shorttitle = {Less {Descriptive} yet {Discriminative}},
	url = {https://aclanthology.org/2022.cmcl-1.4},
	abstract = {In this work, we use a transformer-based pre-trained multimodal model, CLIP, to shed light on the mechanisms employed by human speakers when referring to visual entities. In particular, we use CLIP to quantify the degree of descriptiveness (how well an utterance describes an image in isolation) and discriminativeness (to what extent an utterance is effective in picking out a single image among similar images) of human referring utterances within multimodal dialogues. Overall, our results show that utterances become less descriptive over time while their discriminativeness remains unchanged. Through analysis, we propose that this trend could be due to participants relying on the previous mentions in the dialogue history, as well as being able to distill the most discriminative information from the visual context. In general, our study opens up the possibility of using this and similar models to quantify patterns in human data and shed light on the underlying cognitive mechanisms.},
	urldate = {2022-05-24},
	booktitle = {Proceedings of the {Workshop} on {Cognitive} {Modeling} and {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Takmaz, Ece and Pezzelle, Sandro and Fernández, Raquel},
	month = may,
	year = {2022},
	pages = {36--42},
}

@inproceedings{ammanabrolu_situated_2022,
	address = {Dublin, Ireland},
	title = {Situated {Dialogue} {Learning} through {Procedural} {Environment} {Generation}},
	url = {https://aclanthology.org/2022.acl-long.557},
	abstract = {We teach goal-driven agents to interactively act and speak in situated environments by training on generated curriculums. Our agents operate in LIGHT (Urbanek et al. 2019)—a large-scale crowd-sourced fantasy text adventure game wherein an agent perceives and interacts with the world through textual natural language. Goals in this environment take the form of character-based quests, consisting of personas and motivations. We augment LIGHT by learning to procedurally generate additional novel textual worlds and quests to create a curriculum of steadily increasing difficulty for training agents to achieve such goals. In particular, we measure curriculum difficulty in terms of the rarity of the quest in the original training distribution—an easier environment is one that is more likely to have been found in the unaugmented dataset. An ablation study shows that this method of learning from the tail of a distribution results in significantly higher generalization abilities as measured by zero-shot performance on never-before-seen quests.},
	urldate = {2022-05-24},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Ammanabrolu, Prithviraj and Jia, Renee and Riedl, Mark},
	month = may,
	year = {2022},
	pages = {8099--8116},
}

@inproceedings{ji_achieving_2022,
	address = {Dublin, Ireland},
	title = {Achieving {Reliable} {Human} {Assessment} of {Open}-{Domain} {Dialogue} {Systems}},
	url = {https://aclanthology.org/2022.acl-long.445},
	abstract = {Evaluation of open-domain dialogue systems is highly challenging and development of better techniques is highlighted time and again as desperately needed. Despite substantial efforts to carry out reliable live evaluation of systems in recent competitions, annotations have been abandoned and reported as too unreliable to yield sensible results. This is a serious problem since automatic metrics are not known to provide a good indication of what may or may not be a high-quality conversation. Answering the distress call of competitions that have emphasized the urgent need for better evaluation techniques in dialogue, we present the successful development of human evaluation that is highly reliable while still remaining feasible and low cost. Self-replication experiments reveal almost perfectly repeatable results with a correlation of \$r=0.969\$. Furthermore, due to the lack of appropriate methods of statistical significance testing, the likelihood of potential improvements to systems occurring due to chance is rarely taken into account in dialogue evaluation, and the evaluation we propose facilitates application of standard tests. Since we have developed a highly reliable evaluation method, new insights into system performance can be revealed. We therefore include a comparison of state-of-the-art models (i) with and without personas, to measure the contribution of personas to conversation quality, as well as (ii) prescribed versus freely chosen topics. Interestingly with respect to personas, results indicate that personas do not positively contribute to conversation quality as expected.},
	urldate = {2022-05-24},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Ji, Tianbo and Graham, Yvette and Jones, Gareth and Lyu, Chenyang and Liu, Qun},
	month = may,
	year = {2022},
	pages = {6416--6437},
}

@inproceedings{clarke_one_2022,
	address = {Dublin, Ireland},
	title = {One {Agent} {To} {Rule} {Them} {All}: {Towards} {Multi}-agent {Conversational} {AI}},
	shorttitle = {One {Agent} {To} {Rule} {Them} {All}},
	url = {https://aclanthology.org/2022.findings-acl.257},
	abstract = {The increasing volume of commercially available conversational agents (CAs) on the market has resulted in users being burdened with learning and adopting multiple agents to accomplish their tasks. Though prior work has explored supporting a multitude of domains within the design of a single agent, the interaction experience suffers due to the large action space of desired capabilities. To address these problems, we introduce a new task BBAI: Black-Box Agent Integration, focusing on combining the capabilities of multiple black-box CAs at scale. We explore two techniques: question agent pairing and question response pairing aimed at resolving this task. Leveraging these techniques, we design One For All (OFA), a scalable system that provides a unified interface to interact with multiple CAs. Additionally, we introduce MARS: Multi-Agent Response Selection, a new encoder model for question response pairing that jointly encodes user question and agent response pairs. We demonstrate that OFA is able to automatically and accurately integrate an ensemble of commercially available CAs spanning disparate domains. Specifically, using the MARS encoder we achieve the highest accuracy on our BBAI task, outperforming strong baselines.},
	urldate = {2022-05-24},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Clarke, Christopher and Peper, Joseph and Krishnamurthy, Karthik and Talamonti, Walter and Leach, Kevin and Lasecki, Walter and Kang, Yiping and Tang, Lingjia and Mars, Jason},
	month = may,
	year = {2022},
	pages = {3258--3267},
}

@article{besacier_automatic_2014,
	title = {Automatic speech recognition for under-resourced languages: {A} survey},
	volume = {56},
	issn = {0167-6393},
	shorttitle = {Automatic speech recognition for under-resourced languages},
	url = {https://www.sciencedirect.com/science/article/pii/S0167639313000988},
	doi = {10.1016/j.specom.2013.07.008},
	abstract = {Speech processing for under-resourced languages is an active field of research, which has experienced significant progress during the past decade. We propose, in this paper, a survey that focuses on automatic speech recognition (ASR) for these languages. The definition of under-resourced languages and the challenges associated to them are first defined. The main part of the paper is a literature review of the recent (last 8years) contributions made in ASR for under-resourced languages. Examples of past projects and future trends when dealing with under-resourced languages are also presented. We believe that this paper will be a good starting point for anyone interested to initiate research in (or operational development of) ASR for one or several under-resourced languages. It should be clear, however, that many of the issues and approaches presented here, apply to speech technology in general (text-to-speech synthesis for instance).},
	language = {en},
	urldate = {2022-05-24},
	journal = {Speech Communication},
	author = {Besacier, Laurent and Barnard, Etienne and Karpov, Alexey and Schultz, Tanja},
	month = jan,
	year = {2014},
	pages = {85--100},
}

@techreport{jakobsen_what_2022,
	title = {What {Factors} {Should} {Paper}-{Reviewer} {Assignments} {Rely} {On}? {Community} {Perspectives} on {Issues} and {Ideals} in {Conference} {Peer}-{Review}},
	shorttitle = {What {Factors} {Should} {Paper}-{Reviewer} {Assignments} {Rely} {On}?},
	url = {http://arxiv.org/abs/2205.01005},
	abstract = {Both scientific progress and individual researcher careers depend on the quality of peer review, which in turn depends on paper-reviewer matching. Surprisingly, this problem has been mostly approached as an automated recommendation problem rather than as a matter where different stakeholders (area chairs, reviewers, authors) have accumulated experience worth taking into account. We present the results of the first survey of the NLP community, identifying common issues and perspectives on what factors should be considered by paper-reviewer matching systems. This study contributes actionable recommendations for improving future NLP conferences, and desiderata for interpretable peer review assignments.},
	number = {arXiv:2205.01005},
	urldate = {2022-05-24},
	institution = {arXiv},
	author = {Jakobsen, Terne Sasha Thorn and Rogers, Anna},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.01005},
	note = {arXiv:2205.01005 [cs]
type: article},
}

@inproceedings{mohammad_ethics_2022,
	address = {Dublin, Ireland},
	title = {Ethics {Sheets} for {AI} {Tasks}},
	url = {https://aclanthology.org/2022.acl-long.573},
	abstract = {Several high-profile events, such as the mass testing of emotion recognition systems on vulnerable sub-populations and using question answering systems to make moral judgments, have highlighted how technology will often lead to more adverse outcomes for those that are already marginalized. At issue here are not just individual systems and datasets, but also the AI tasks themselves. In this position paper, I make a case for thinking about ethical considerations not just at the level of individual models and datasets, but also at the level of AI tasks. I will present a new form of such an effort, Ethics Sheets for AI Tasks, dedicated to fleshing out the assumptions and ethical considerations hidden in how a task is commonly framed and in the choices we make regarding the data, method, and evaluation. I will also present a template for ethics sheets with 50 ethical considerations, using the task of emotion recognition as a running example. Ethics sheets are a mechanism to engage with and document ethical considerations before building datasets and systems. Similar to survey articles, a small number of carefully created ethics sheets can serve numerous researchers and developers.},
	urldate = {2022-05-23},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Mohammad, Saif},
	month = may,
	year = {2022},
	pages = {8368--8379},
}

@inproceedings{bowman_dangers_2022,
	address = {Dublin, Ireland},
	title = {The {Dangers} of {Underclaiming}: {Reasons} for {Caution} {When} {Reporting} {How} {NLP} {Systems} {Fail}},
	shorttitle = {The {Dangers} of {Underclaiming}},
	url = {https://aclanthology.org/2022.acl-long.516},
	abstract = {Researchers in NLP often frame and discuss research results in ways that serve to deemphasize the field's successes, often in response to the field's widespread hype. Though well-meaning, this has yielded many misleading or false claims about the limits of our best technology. This is a problem, and it may be more serious than it looks: It harms our credibility in ways that can make it harder to mitigate present-day harms, like those involving biased systems for content moderation or resume screening. It also limits our ability to prepare for the potentially enormous impacts of more distant future advances. This paper urges researchers to be careful about these claims and suggests some research directions and communication strategies that will make it easier to avoid or rebut them.},
	urldate = {2022-05-23},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Bowman, Samuel},
	month = may,
	year = {2022},
	pages = {7484--7499},
}

@inproceedings{soni_human_2022,
	address = {Dublin, Ireland},
	title = {Human {Language} {Modeling}},
	url = {https://aclanthology.org/2022.findings-acl.52},
	abstract = {Natural language is generated by people, yet traditional language modeling views words or documents as if generated independently. Here, we propose human language modeling (HuLM), a hierarchical extension to the language modeling problem where by a human- level exists to connect sequences of documents (e.g. social media messages) and capture the notion that human language is moderated by changing human states. We introduce, HaRT, a large-scale transformer model for solving HuLM, pre-trained on approximately 100,000 social media users, and demonstrate it's effectiveness in terms of both language modeling (perplexity) for social media and fine-tuning for 4 downstream tasks spanning document- and user-levels. Results on all tasks meet or surpass the current state-of-the-art.},
	urldate = {2022-05-23},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Soni, Nikita and Matero, Matthew and Balasubramanian, Niranjan and Schwartz, H.},
	month = may,
	year = {2022},
	pages = {622--636},
}

@article{soni_nisoni_nodate,
	title = {\{nisoni, mmatero, niranjan, has\}@cs.stonybrook.edu},
	abstract = {Natural language is generated by people, yet traditional language modeling views words or documents as if generated independently. Here, we propose human language modeling (HuLM), a hierarchical extension to the language modeling problem whereby a humanlevel exists to connect sequences of documents (e.g. social media messages) and capture the notion that human language is moderated by changing human states. We introduce, HaRT, a large-scale transformer model for the HULM task, pre-trained on approximately 100,000 social media users, and demonstrate it’s effectiveness in terms of both language modeling (perplexity) for social media and ﬁne-tuning for 4 downstream tasks spanning documentand user-levels: stance detection, sentiment classiﬁcation, age estimation, and personality assessment.1 Results on all tasks meet or surpass the current state-of-the-art.},
	language = {en},
	author = {Soni, Nikita and Matero, Matthew and Balasubramanian, Niranjan and Schwartz, H Andrew},
	pages = {15},
}

@inproceedings{wei_learning_2022,
	address = {Dublin, Ireland},
	title = {Learning to {Generalize} to {More}: {Continuous} {Semantic} {Augmentation} for {Neural} {Machine} {Translation}},
	shorttitle = {Learning to {Generalize} to {More}},
	url = {https://aclanthology.org/2022.acl-long.546},
	abstract = {The principal task in supervised neural machine translation (NMT) is to learn to generate target sentences conditioned on the source inputs from a set of parallel sentence pairs, and thus produce a model capable of generalizing to unseen instances. However, it is commonly observed that the generalization performance of the model is highly influenced by the amount of parallel data used in training. Although data augmentation is widely used to enrich the training data, conventional methods with discrete manipulations fail to generate diverse and faithful training samples. In this paper, we present a novel data augmentation paradigm termed Continuous Semantic Augmentation (CsaNMT), which augments each training instance with an adjacency semantic region that could cover adequate variants of literal expression under the same meaning. We conduct extensive experiments on both rich-resource and low-resource settings involving various language pairs, including WMT14 English\${\textbackslash}rightarrow\$German,French, NIST Chinese\${\textbackslash}rightarrow\$English and multiple low-resource IWSLT translation tasks. The provided empirical evidences show that CsaNMT sets a new level of performance among existing augmentation techniques, improving on the state-of-the-art by a large margin. The core codes are contained in Appendix E.},
	urldate = {2022-05-23},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Wei, Xiangpeng and Yu, Heng and Hu, Yue and Weng, Rongxiang and Luo, Weihua and Jin, Rong},
	month = may,
	year = {2022},
	pages = {7930--7944},
}

@inproceedings{habernal_how_2022,
	address = {Dublin, Ireland},
	title = {How reparametrization trick broke differentially-private text representation learning},
	url = {https://aclanthology.org/2022.acl-short.87},
	abstract = {As privacy gains traction in the NLP community, researchers have started adopting various approaches to privacy-preserving methods. One of the favorite privacy frameworks, differential privacy (DP), is perhaps the most compelling thanks to its fundamental theoretical guarantees. Despite the apparent simplicity of the general concept of differential privacy, it seems non-trivial to get it right when applying it to NLP. In this short paper, we formally analyze several recent NLP papers proposing text representation learning using DPText (Beigi et al., 2019a,b; Alnasser et al., 2021; Beigi et al., 2021) and reveal their false claims of being differentially private. Furthermore, we also show a simple yet general empirical sanity check to determine whether a given implementation of a DP mechanism almost certainly violates the privacy loss guarantees. Our main goal is to raise awareness and help the community understand potential pitfalls of applying differential privacy to text representation learning.},
	urldate = {2022-05-23},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Habernal, Ivan},
	month = may,
	year = {2022},
	pages = {771--777},
}

@inproceedings{papadopoulos_korfiatis_primock57_2022,
	address = {Dublin, Ireland},
	title = {{PriMock57}: {A} {Dataset} {Of} {Primary} {Care} {Mock} {Consultations}},
	shorttitle = {{PriMock57}},
	url = {https://aclanthology.org/2022.acl-short.65},
	abstract = {Recent advances in Automatic Speech Recognition (ASR) have made it possible to reliably produce automatic transcripts of clinician-patient conversations. However, access to clinical datasets is heavily restricted due to patient privacy, thus slowing down normal research practices. We detail the development of a public access, high quality dataset comprising of 57 mocked primary care consultations, including audio recordings, their manual utterance-level transcriptions, and the associated consultation notes. Our work illustrates how the dataset can be used as a benchmark for conversational medical ASR as well as consultation note generation from transcripts.},
	urldate = {2022-05-22},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Papadopoulos Korfiatis, Alex and Moramarco, Francesco and Sarac, Radmila and Savkov, Aleksandar},
	month = may,
	year = {2022},
	pages = {588--598},
}

@inproceedings{merz_discourse_2022,
	address = {Dublin, Ireland},
	title = {Discourse on {ASR} {Measurement}: {Introducing} the {ARPOCA} {Assessment} {Tool}},
	shorttitle = {Discourse on {ASR} {Measurement}},
	url = {https://aclanthology.org/2022.acl-srw.28},
	abstract = {Automatic speech recognition (ASR) has evolved from a pipeline architecture with pronunciation dictionaries, phonetic features and language models to the end-to-end systems performing a direct translation from a raw waveform into a word sequence. With the increase in accuracy and the availability of pre-trained models, the ASR systems are now omnipresent in our daily applications. On the other hand, the models' interpretability and their computational cost have become more challenging, particularly when dealing with less-common languages or identifying regional variations of speakers. This research proposal will follow a four-stage process: 1) Proving an overview of acoustic features and feature extraction algorithms; 2) Exploring current ASR models, tools, and performance assessment techniques; 3) Aligning features with interpretable phonetic transcripts; and 4) Designing a prototype ARPOCA to increase awareness of regional language variation and improve models feedback by developing a semi-automatic acoustic features extraction using PRAAT in conjunction with phonetic transcription.},
	urldate = {2022-05-22},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Student} {Research} {Workshop}},
	publisher = {Association for Computational Linguistics},
	author = {Merz, Megan and Scrivner, Olga},
	month = may,
	year = {2022},
	pages = {366--372},
}

@inproceedings{fu_towards_2022,
	address = {Dublin, Ireland},
	title = {Towards {Unification} of {Discourse} {Annotation} {Frameworks}},
	url = {https://aclanthology.org/2022.acl-srw.12},
	abstract = {Discourse information is difficult to represent and annotate. Among the major frameworks for annotating discourse information, RST, PDTB and SDRT are widely discussed and used, each having its own theoretical foundation and focus. Corpora annotated under different frameworks vary considerably. To make better use of the existing discourse corpora and achieve the possible synergy of different frameworks, it is worthwhile to investigate the systematic relations between different frameworks and devise methods of unifying the frameworks. Although the issue of framework unification has been a topic of discussion for a long time, there is currently no comprehensive approach which considers unifying both discourse structure and discourse relations and evaluates the unified framework intrinsically and extrinsically. We plan to use automatic means for the unification task and evaluate the result with structural complexity and downstream tasks. We will also explore the application of the unified framework in multi-task learning and graphical models.},
	urldate = {2022-05-22},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Student} {Research} {Workshop}},
	publisher = {Association for Computational Linguistics},
	author = {Fu, Yingxue},
	month = may,
	year = {2022},
	pages = {132--142},
}

@inproceedings{zhang_slot_2022,
	address = {Dublin, Ireland},
	title = {A {Slot} {Is} {Not} {Built} in {One} {Utterance}: {Spoken} {Language} {Dialogs} with {Sub}-{Slots}},
	shorttitle = {A {Slot} {Is} {Not} {Built} in {One} {Utterance}},
	url = {https://aclanthology.org/2022.findings-acl.27},
	abstract = {A slot value might be provided segment by segment over multiple-turn interactions in a dialog, especially for some important information such as phone numbers and names. It is a common phenomenon in daily life, but little attention has been paid to it in previous work. To fill the gap, this paper defines a new task named Sub-Slot based Task-Oriented Dialog (SSTOD) and builds a Chinese dialog dataset SSD for boosting research on SSTOD. The dataset includes a total of 40K dialogs and 500K utterances from four different domains: Chinese names, phone numbers, ID numbers and license plate numbers. The data is well annotated with sub-slot values, slot values, dialog states and actions. We find some new linguistic phenomena and interactive manners in SSTOD which raise critical challenges of building dialog agents for the task. We test three state-of-the-art dialog models on SSTOD and find they cannot handle the task well on any of the four domains. We also investigate an improved model by involving slot knowledge in a plug-in manner. More work should be done to meet the new challenges raised from SSTOD which widely exists in real-life applications. The dataset and code are publicly available via https://github.com/shunjiu/SSTOD.},
	urldate = {2022-05-18},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Sai and Hu, Yuwei and Wu, Yuchuan and Wu, Jiaman and Li, Yongbin and Sun, Jian and Yuan, Caixia and Wang, Xiaojie},
	month = may,
	year = {2022},
	pages = {309--321},
}

@inproceedings{ward_turn-taking_2018,
	title = {Turn-{Taking} {Predictions} across {Languages} and {Genres} {Using} an {LSTM} {Recurrent} {Neural} {Network}},
	doi = {10.1109/SLT.2018.8639673},
	abstract = {Going beyond turn-taking models built to solve specific tasks, such as predicting if a user will hold his/her turn after a pause, there is growing interest in more general models for turn taking that subsume many such tasks, and very good results have recently been obtained [1]. Here we present an improved recurrent network model that outperforms [1] and does so without requiring lexical annotation. Further, we show that this model can be trained for different languages with no modifications, providing good results in turn-taking prediction for English, Spanish, Japanese, Mandarin and French. We also show that our model performs well across genres, including task-oriented dialog and general conversation.},
	booktitle = {2018 {IEEE} {Spoken} {Language} {Technology} {Workshop} ({SLT})},
	author = {Ward, Nigel G. and Aguirre, Diego and Cervantes, Gerardo and Fuentes, Olac},
	month = dec,
	year = {2018},
	pages = {831--837},
}

@article{wallis_revisiting_2008,
	title = {Revisiting the {DARPA} communicator data using conversation analysis},
	volume = {9},
	issn = {1572-0373, 1572-0381},
	url = {https://www.jbe-platform.com/content/journals/10.1075/is.9.3.05wal},
	doi = {10.1075/is.9.3.05wal},
	abstract = {The state of the art in human computer conversation leaves something to be desired and, indeed, talking to a computer can be down-right annoying. This paper describes an approach to identifying “opportunities for improvement” in these systems by looking for abuse in the form of swear words. The premise is that humans swear at computers as a sanction and, as such, swear words represent a point of failure where the system did not behave as it should. Having identified where things went wrong, we can work backward through the transcripts and, using conversation analysis (CA) work out how things went wrong. Conversation analysis is a qualitative methodology and can appear quite alien — indeed unscientific — to those of us from a quantitative background. The paper starts with a description of Conversation analysis in its modern form, and then goes on to apply the methodology to transcripts of frustrated and annoyed users in the DARPA Communicator project. The conclusion is that there is at least one species of failure caused by the inability of the Communicator systems to handle mixed initiative at the discourse structure level. Along the way, I hope to demonstrate that there is an alternative future for computational linguistics that does not rely on larger and larger text corpora.},
	language = {en},
	number = {3},
	urldate = {2021-04-16},
	journal = {Interaction Studies},
	author = {Wallis, Peter},
	month = jan,
	year = {2008},
	note = {Publisher: John Benjamins},
	pages = {434--457},
}

@article{stokoe_can_2020,
	title = {Can humans simulate talking like other humans? {Comparing} simulated clients to real customers in service inquiries},
	volume = {22},
	issn = {1461-4456, 1461-7080},
	shorttitle = {Can humans simulate talking like other humans?},
	url = {http://journals.sagepub.com/doi/10.1177/1461445619887537},
	doi = {10.1177/1461445619887537},
	abstract = {How authentic are inquiry calls made by simulated clients, or ‘mystery shoppers’, to service organizations, when compared to real callers? We analysed 48 simulated and 63 real inquiry calls to different veterinary practices in the United Kingdom and Ireland. The data were transcribed for conversation analysis, as well as coded for a variety of call categories including reason for the call, call outcome and turn design features. Analysis revealed systematic differences between real and simulated calls in terms of (1) reasons for the call, call outcome and call duration and (2) how callers refer to their pets in service requests and follow-up questions about their animal. Our qualitative analyses were supported with statistical summaries and tests. The findings reveal the limitations of mystery shopper methodology for the assessment of service provision. We also discuss the implications of the findings for the use of simulated encounters and the development of conversational agents.},
	language = {en},
	number = {1},
	urldate = {2022-05-12},
	journal = {Discourse Studies},
	author = {Stokoe, Elizabeth and Sikveland, Rein Ove and Albert, Saul and Hamann, Magnus and Housley, William},
	month = feb,
	year = {2020},
	pages = {87--109},
}

@inproceedings{schwartz_primum_2022,
	address = {Dublin, Ireland},
	title = {Primum {Non} {Nocere}: {Before} working with {Indigenous} data, the {ACL} must confront ongoing colonialism},
	shorttitle = {Primum {Non} {Nocere}},
	url = {https://aclanthology.org/2022.acl-short.82},
	abstract = {In this paper, we challenge the ACL community to reckon with historical and ongoing colonialism by adopting a set of ethical obligations and best practices drawn from the Indigenous studies literature. While the vast majority of NLP research focuses on a very small number of very high resource languages (English, Chinese, etc), some work has begun to engage with Indigenous languages. No research involving Indigenous language data can be considered ethical without first acknowledging that Indigenous languages are not merely very low resource languages. The toxic legacy of colonialism permeates every aspect of interaction between Indigenous communities and outside researchers. To this end, we propose that the ACL draft and adopt an ethical framework for NLP researchers and computational linguists wishing to engage in research involving Indigenous languages.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Schwartz, Lane},
	month = may,
	year = {2022},
	pages = {724--731},
}

@article{relieu_approche_2020,
	title = {Une approche configurationnelle des leurres conversationnels},
	volume = {N°220-221},
	issn = {0751-7971, 1777-5809},
	url = {http://www.cairn.info/revue-reseaux-2020-2-page-81.htm?ref=doi},
	doi = {10.3917/res.220.0081},
	language = {fr},
	number = {2},
	urldate = {2022-05-12},
	journal = {Réseaux},
	author = {Relieu, Marc and Sahin, Merve and Francillon, Aurélien},
	year = {2020},
	pages = {81},
}

@inproceedings{razumovskaia_natural_2022,
	address = {Dublin, Ireland},
	title = {Natural {Language} {Processing} for {Multilingual} {Task}-{Oriented} {Dialogue}},
	url = {https://aclanthology.org/2022.acl-tutorials.8},
	abstract = {Recent advances in deep learning have also enabled fast progress in the research of task-oriented dialogue (ToD) systems. However, the majority of ToD systems are developed for English and merely a handful of other widely spoken languages, e.g., Chinese and German. This hugely limits the global reach and, consequently, transformative socioeconomic potential of such systems. In this tutorial, we will thus discuss and demonstrate the importance of (building) multilingual ToD systems, and then provide a systematic overview of current research gaps, challenges and initiatives related to multilingual ToD systems, with a particular focus on their connections to current research and challenges in multilingual and low-resource NLP. The tutorial will aim to provide answers or shed new light to the following questions: a) Why are multilingual dialogue systems so hard to build: what makes multilinguality for dialogue more challenging than for other NLP applications and tasks? b) What are the best existing methods and datasets for multilingual and cross-lingual (task-oriented) dialog systems? How are (multilingual) ToD systems usually evaluated? c) What are the promising future directions for multilingual ToD research: where can one draw inspiration from related NLP areas and tasks?},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Tutorial} {Abstracts}},
	publisher = {Association for Computational Linguistics},
	author = {Razumovskaia, Evgeniia and Glavaš, Goran and Majewska, Olga and Ponti, Edoardo and Vulić, Ivan},
	month = may,
	year = {2022},
	pages = {44--50},
}

@techreport{razumovskaia_crossing_2021,
	title = {Crossing the {Conversational} {Chasm}: {A} {Primer} on {Natural} {Language} {Processing} for {Multilingual} {Task}-{Oriented} {Dialogue} {Systems}},
	shorttitle = {Crossing the {Conversational} {Chasm}},
	url = {http://arxiv.org/abs/2104.08570},
	abstract = {In task-oriented dialogue (ToD), a user holds a conversation with an artificial agent to complete a concrete task. Although this technology represents one of the central objectives of AI and has been the focus of ever more intense research and development efforts, it is currently limited to a few narrow domains (e.g., food ordering, ticket booking) and a handful of languages (e.g., English, Chinese). This work provides an extensive overview of existing methods and resources in multilingual ToD as an entry point to this exciting and emerging field. We find that the most critical factor preventing the creation of truly multilingual ToD systems is the lack of datasets in most languages for both training and evaluation. In fact, acquiring annotations or human feedback for each component of modular systems or for data-hungry end-to-end systems is expensive and tedious. Hence, state-of-the-art approaches to multilingual ToD mostly rely on (zero- or few-shot) cross-lingual transfer from resource-rich languages (almost exclusively English), either by means of machine translation or multilingual representations. These approaches are currently viable only for typologically similar languages and languages with parallel / monolingual corpora available. On the other hand, their effectiveness beyond these boundaries is doubtful or hard to assess due to the lack of linguistically diverse benchmarks (especially for natural language generation and end-to-end evaluation). To overcome this limitation, we draw parallels between components of the ToD pipeline and other NLP tasks, which can inspire solutions for learning in low-resource scenarios. Finally, we list additional challenges that multilinguality poses for related areas (such as speech and human-centred evaluation), and indicate future directions that hold promise to further expand language coverage and dialogue capabilities of current ToD systems.},
	number = {arXiv:2104.08570},
	urldate = {2022-05-13},
	institution = {arXiv},
	author = {Razumovskaia, Evgeniia and Glavaš, Goran and Majewska, Olga and Ponti, Edoardo M. and Korhonen, Anna and Vulić, Ivan},
	month = jun,
	year = {2021},
	doi = {10.48550/arXiv.2104.08570},
	note = {arXiv:2104.08570 [cs]
type: article},
	keywords = {Computer Science - Computation and Language},
}

@incollection{razmerita_collaboration_2022,
	address = {Cham},
	series = {Learning and {Analytics} in {Intelligent} {Systems}},
	title = {Collaboration in the {Machine} {Age}: {Trustworthy} {Human}-{AI} {Collaboration}},
	isbn = {978-3-030-93052-3},
	shorttitle = {Collaboration in the {Machine} {Age}},
	url = {https://doi.org/10.1007/978-3-030-93052-3_14},
	abstract = {Collaboration in the machine age will increasingly involve collaboration with Artificial Intelligence (AI) technologies. This chapter aims to provide insights in the state of the art of AI developments in relation to human-AI collaboration. It presents a brief historic overview of developments in AI, three different forms of human-AI collaboration (e.g. conversational agents) and introduces the main areas of research in relation to human-AI collaboration and potential pitfalls. The chapter discusses the emergent multifaceted role of AI for collaboration in organizations and introduces the concept of trustworthy human-AI collaboration.},
	language = {en},
	urldate = {2022-05-11},
	booktitle = {Advances in {Selected} {Artificial} {Intelligence} {Areas}: {World} {Outstanding} {Women} in {Artificial} {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Razmerita, Liana and Brun, Armelle and Nabeth, Thierry},
	editor = {Virvou, Maria and Tsihrintzis, George A. and Jain, Lakhmi C.},
	year = {2022},
	doi = {10.1007/978-3-030-93052-3_14},
	keywords = {Agent design, Attention management, Behavioural analytics, Chatbots, Collaboration, Cultural analytics, Organizational analytics, Organizational design, Personalization, Trustworthy AI},
	pages = {333--356},
}

@inproceedings{porcheron_voice_2018,
	address = {Montreal QC Canada},
	title = {Voice {Interfaces} in {Everyday} {Life}},
	isbn = {978-1-4503-5620-6},
	url = {https://dl.acm.org/doi/10.1145/3173574.3174214},
	doi = {10.1145/3173574.3174214},
	abstract = {Voice User Interfaces (VUIs) are becoming ubiquitously available, being embedded both into everyday mobility via smartphones, and into the life of the home via ‘assistant’ devices. Yet, exactly how users of such devices practically thread that use into their everyday social interactions remains underexplored. By collecting and studying audio data from month-long deployments of the Amazon Echo in participants’ homes—informed by ethnomethodology and conversation analysis—our study documents the methodical practices of VUI users, and how that use is accomplished in the complex social life of the home. Data we present shows how the device is made accountable to and embedded into conversational settings like family dinners where various simultaneous activities are being achieved. We discuss how the VUI is finely coordinated with the sequential organisation of talk. Finally, we locate implications for the accountability of VUI interaction, request and response design, and raise conceptual challenges to the notion of designing ‘conversational’ interfaces.},
	language = {en},
	urldate = {2022-04-14},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Porcheron, Martin and Fischer, Joel E. and Reeves, Stuart and Sharples, Sarah},
	month = apr,
	year = {2018},
	pages = {1--12},
}

@inproceedings{poppe_backchannels_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Backchannels: {Quantity}, {Type} and {Timing} {Matters}},
	isbn = {978-3-642-23974-8},
	shorttitle = {Backchannels},
	doi = {10.1007/978-3-642-23974-8_25},
	abstract = {In a perception experiment, we systematically varied the quantity, type and timing of backchannels. Participants viewed stimuli of a real speaker side-by-side with an animated listener and rated how human-like they perceived the latter’s backchannel behavior. In addition, we obtained measures of appropriateness and optionality for each backchannel from key strokes. This approach allowed us to analyze the influence of each of the factors on entire fragments and on individual backchannels. The originally performed type and timing of a backchannel appeared to be more human-like, compared to a switched type or random timing. In addition, we found that nods are more often appropriate than vocalizations. For quantity, too few or too many backchannels per minute appeared to reduce the quality of the behavior. These findings are important for the design of algorithms for the automatic generation of backchannel behavior for artificial listeners.},
	language = {en},
	booktitle = {Intelligent {Virtual} {Agents}},
	publisher = {Springer},
	author = {Poppe, Ronald and Truong, Khiet P. and Heylen, Dirk},
	editor = {Vilhjálmsson, Hannes Högni and Kopp, Stefan and Marsella, Stacy and Thórisson, Kristinn R.},
	year = {2011},
	pages = {228--239},
}

@inproceedings{opfermann_communicative_2017,
	address = {Bielefeld Germany},
	title = {The {Communicative} {Activity} of "{Making} {Suggestions}" as an {Interactional} {Process}: {Towards} a {Dialog} {Model} for {HAI}},
	isbn = {978-1-4503-5113-3},
	shorttitle = {The {Communicative} {Activity} of "{Making} {Suggestions}" as an {Interactional} {Process}},
	url = {https://dl.acm.org/doi/10.1145/3125739.3125752},
	doi = {10.1145/3125739.3125752},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Human} {Agent} {Interaction}},
	publisher = {ACM},
	author = {Opfermann, Christiane and Pitsch, Karola and Yaghoubzadeh, Ramin and Kopp, Stefan},
	month = oct,
	year = {2017},
	pages = {161--170},
}

@inproceedings{opfermann_reprompts_2017,
	title = {Reprompts as error handling strategy in human-agent-dialog? {User} responses to a system's display of non-understanding},
	shorttitle = {Reprompts as error handling strategy in human-agent-dialog?},
	doi = {10.1109/ROMAN.2017.8172319},
	abstract = {In speech based technical systems, a `reprompt' can be deployed as a verbally non-explicit and semantically unspeciflc practice of making a failure-to-understand transparent. Users' repeats or rephrasings of their previous answers might lead to further non-understandings, resulting in further reprompts by the system. On the basis of a Wizard-of-Oz video corpus in a schedule management setting with an embodied conversational agent and the special user groups of elderly and mildly cognitively impaired persons, we investigate in a conversation analytical approach the interactional impact of three-fold reprompts on subsequent user actions to an appointment suggestion. We focus especially on the type of user actions during the course of multiple reprompts in a confirmation/disconfirmation context. Analysis reveals more fine-grained user response types, testifying that all users ratify the first reprompt. After the second and third one, users tend to either add problem manifestations or initiations of the relevant next move. Or they substitute their previous answer by these types of actions. While additional or substituting problem manifestations call for more specific and linguistically restricting error handling practices, the user-initiated next moves are technically exploitable as implicit cues for confirmation in the presented special yes/no-context.},
	booktitle = {2017 26th {IEEE} {International} {Symposium} on {Robot} and {Human} {Interactive} {Communication} ({RO}-{MAN})},
	author = {Opfermann, C. and Pitsch, Karola},
	month = aug,
	year = {2017},
	keywords = {HCI, repair},
	pages = {310--316},
}

@inproceedings{oostdijk2000spoken,
	title = {The {Spoken} {Dutch} {Corpus}: {Overview} and first evaluation},
	booktitle = {Proceedings of the second international conference on language resources and evaluation ({LREC}’00)},
	author = {Oostdijk, Nelleke},
	year = {2000},
}

@inproceedings{okabe_weakly_2022,
	address = {Dublin, Ireland},
	title = {Weakly {Supervised} {Word} {Segmentation} for {Computational} {Language} {Documentation}},
	url = {https://aclanthology.org/2022.acl-long.510},
	abstract = {Word and morpheme segmentation are fundamental steps of language documentation as they allow to discover lexical units in a language for which the lexicon is unknown. However, in most language documentation scenarios, linguists do not start from a blank page: they may already have a pre-existing dictionary or have initiated manual segmentation of a small part of their data. This paper studies how such a weak supervision can be taken advantage of in Bayesian non-parametric models of segmentation. Our experiments on two very low resource languages (Mboshi and Japhug), whose documentation is still in progress, show that weak supervision can be beneficial to the segmentation quality. In addition, we investigate an incremental learning scenario where manual segmentations are provided in a sequential manner. This work opens the way for interactive annotation tools for documentary linguists.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Okabe, Shu and Besacier, Laurent and Yvon, François},
	month = may,
	year = {2022},
	pages = {7385--7398},
}

@incollection{moore_natural_2018,
	address = {Cham},
	series = {Human–{Computer} {Interaction} {Series}},
	title = {A {Natural} {Conversation} {Framework} for {Conversational} {UX} {Design}},
	isbn = {978-3-319-95579-7},
	url = {https://doi.org/10.1007/978-3-319-95579-7_9},
	abstract = {With the rise in popularity of chatbot and virtual-agent platforms, from Apple, Amazon, Google, Microsoft, Facebook, IBM and more, a new design discipline is emerging: Conversational UX Design. While it is easy to create natural language interfaces with these platforms, creating an effective and engaging user experience is still a major challenge. Natural language processing (NLP) techniques have given us powerful tools for analyzing bits of language, but they do not tell us how to string those bits together to make a natural conversation. Natural conversation has a sequential organization that is independent of the organization of language itself. At IBM Research-Almaden, we are addressing this user experience (UX) design challenge by applying formal, qualitative models from the field of Conversation Analysis to the design of conversational agents. Our Natural Conversation Framework (NCF) is a design framework for conversational user experience. It provides a library of generic conversational UX patterns that are inspired by natural human conversation patterns and that are agnostic to platform and input method (text or voice). This chapter will cover the four components of our Natural Conversation Framework: (1) an interaction model, (2) common activity modules, (3) a navigation method and (4) a set of sequence metrics. In addition, it will briefly outline a general process for designing conversational UX: from mock-up to working prototype.},
	language = {en},
	urldate = {2021-07-13},
	booktitle = {Studies in {Conversational} {UX} {Design}},
	publisher = {Springer International Publishing},
	author = {Moore, Robert J.},
	editor = {Moore, Robert J. and Szymanski, Margaret H. and Arar, Raphael and Ren, Guang-Jie},
	year = {2018},
	doi = {10.1007/978-3-319-95579-7_9},
	pages = {181--204},
}

@article{moore_automated_2015,
	title = {Automated {Transcription} and {Conversation} {Analysis}},
	volume = {48},
	issn = {0835-1813},
	url = {http://www.tandfonline.com/doi/abs/10.1080/08351813.2015.1058600},
	doi = {10.1080/08351813.2015.1058600},
	abstract = {This article explores the potential of automated transcription technology for use in Conversation Analysis (CA). First, it applies auto-transcription to a classic CA recording and compares the output with Gail Jefferson’s original transcript. Second, it applies auto-transcription to more recent recordings to demonstrate transcript quality under ideal conditions. And third, it examines the use of auto-transcripts for navigating big conversational data sets. The article concludes that although standard automated transcription technology lacks certain critical capabilities and exhibits varying levels of accuracy, it may still be useful for (a) providing first-pass transcripts, with silences, for further manual editing; and (b) scaling up data exploration and collection building by providing time-based indices requiring no manual effort to generate. Data are in American English.},
	number = {3},
	urldate = {2015-08-11},
	journal = {Research on Language and Social Interaction},
	author = {Moore, Robert J.},
	month = jul,
	year = {2015},
	pages = {253--270},
}

@inproceedings{macaire_automatic_2022,
	address = {Dublin, Ireland},
	title = {Automatic {Speech} {Recognition} and {Query} {By} {Example} for {Creole} {Languages} {Documentation}},
	url = {https://aclanthology.org/2022.findings-acl.197},
	abstract = {We investigate the exploitation of self-supervised models for two Creole languages with few resources: Gwadloupéyen and Morisien. Automatic language processing tools are almost non-existent for these two languages. We propose to use about one hour of annotated data to design an automatic speech recognition system for each language. We evaluate how much data is needed to obtain a query-by-example system that is usable by linguists. Moreover, our experiments show that multilingual self-supervised models are not necessarily the most efficient for Creole languages.},
	urldate = {2022-05-18},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Macaire, Cécile and Schwab, Didier and Lecouteux, Benjamin and Schang, Emmanuel},
	month = may,
	year = {2022},
	pages = {2512--2520},
}

@inproceedings{luu_sketching_2022,
	address = {Dublin, Ireland},
	title = {Sketching a {Linguistically}-{Driven} {Reasoning} {Dialog} {Model} for {Social} {Talk}},
	url = {https://aclanthology.org/2022.acl-srw.14},
	abstract = {The capability of holding social talk (or casual conversation) and making sense of conversational content requires context-sensitive natural language understanding and reasoning, which cannot be handled efficiently by the current popular open-domain dialog systems and chatbots. Heavily relying on corpus-based machine learning techniques to encode and decode context-sensitive meanings, these systems focus on fitting a particular training dataset, but not tracking what is actually happening in a conversation, and therefore easily derail in a new context. This work sketches out a more linguistically-informed architecture to handle social talk in English, in which corpus-based methods form the backbone of the relatively context-insensitive components (e.g. part-of-speech tagging, approximation of lexical meaning and constituent chunking), while symbolic modeling is used for reasoning out the context-sensitive components, which do not have any consistent mapping to linguistic forms. All components are fitted into a Bayesian game-theoretic model to address the interactive and rational aspects of conversation.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Student} {Research} {Workshop}},
	publisher = {Association for Computational Linguistics},
	author = {Lưu, Alex},
	month = may,
	year = {2022},
	pages = {153--170},
}

@inproceedings{lu_controlling_2022,
	address = {Dublin, Ireland},
	title = {On {Controlling} {Fallback} {Responses} for {Grounded} {Dialogue} {Generation}},
	url = {https://aclanthology.org/2022.findings-acl.204},
	abstract = {Dialogue agents can leverage external textual knowledge to generate responses of a higher quality. To our best knowledge, most existing works on knowledge grounded dialogue settings assume that the user intention is always answerable. Unfortunately, this is impractical as there is no guarantee that the knowledge retrievers could always retrieve the desired knowledge. Therefore, this is crucial to incorporate fallback responses to respond to unanswerable contexts appropriately while responding to the answerable contexts in an informative manner. We propose a novel framework that automatically generates a control token with the generator to bias the succeeding response towards informativeness for answerable contexts and fallback for unanswerable contexts in an end-to-end manner. Since no existing knowledge grounded dialogue dataset considers this aim, we augment the existing dataset with unanswerable contexts to conduct our experiments. Automatic and human evaluation results indicate that naively incorporating fallback responses with controlled text generation still hurts informativeness for answerable context. In contrast, our proposed framework effectively mitigates this problem while still appropriately presenting fallback responses to unanswerable contexts. Such a framework also reduces the extra burden of the additional classifier and the overheads introduced in the previous works, which operates in a pipeline manner.},
	urldate = {2022-05-16},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Lu, Hongyuan and Lam, Wai and Cheng, Hong and Meng, Helen},
	month = may,
	year = {2022},
	pages = {2591--2601},
}

@inproceedings{larson_not_2021,
	address = {New York, NY, USA},
	series = {{UMAP} '21},
	title = {Not {Directly} {Stated}, {Not} {Explicitly} {Stored}: {Conversational} {Agents} and the {Privacy} {Threat} of {Implicit} {Information}},
	isbn = {978-1-4503-8367-7},
	shorttitle = {Not {Directly} {Stated}, {Not} {Explicitly} {Stored}},
	url = {https://doi.org/10.1145/3450614.3463601},
	doi = {10.1145/3450614.3463601},
	abstract = {As conversational agents continue to evolve, it will become increasingly common to interact with search engines and recommender systems via natural language dialogue. Such interactions guide and shape our decision making, especially our consumption of products and services. The evolution of conversational agents will bring new challenges in protecting the privacy of users and research has already begun to identify and address potential threats. Current research, however, focuses on how conversational agents acquire and process explicit information. In this paper, we consider the future and bring to light the up-and-coming privacy risks posed by implicit information. Our first point is that meaning that is expressed implicitly is an integral part of natural language, implying that agents that have the ability to engage in a fully humanlike dialogue will also have the ability to manipulate implied meaning. As a result, such agents will be capable of acquiring sensitive information about users that is not directly stated. Users have little awareness of or control over information that is implicitly communicated. Our second point is that in today's search and recommender systems user profiles are not explicitly stored. As a result, it is not obvious that a user is being targeted on the basis of implicit person-specific information. The way forward, we argue, is for research in the area of conversational agents to devote more attention to the linguistic principles that underlie implied meaning and the legal means that are available to protect users.},
	urldate = {2021-10-11},
	booktitle = {Adjunct {Proceedings} of the 29th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Larson, Martha and Oostdijk, Nelleke and Zuiderveen Borgesius, Frederik},
	month = jun,
	year = {2021},
	pages = {388--391},
}

@article{kjellmer_where_2009,
	title = {Where do we backchannel?: {On} the use of mm, mhm, uh huh and such like},
	volume = {14},
	issn = {1384-6655, 1569-9811},
	shorttitle = {Where do we backchannel?},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ijcl.14.1.05kje},
	doi = {10.1075/ijcl.14.1.05kje},
	abstract = {The paper investigates a sample of ‘backchannels’, a kind of response item, in the Cobuild Corpus. Its object is to chart the occurrence of backchannels in modern English speech, and especially to find out if they can indicate how much of a language sequence is needed for a listener to understand the intended message. The sequences into which backchannels are inserted and their insertion points are therefore classified, and the fairly numerous sequences where backchannels “interrupt” a linguistic unit are singled out for special study. A general conclusion is that in the cases where there is no explicit information about the part of the message following the inserted backchannel, the message will nevertheless mostly be understood even at the backchannel insertion point. A comparison between male and female speakers shows that women use backchannels more than men and that, unlike men, they prefer unemphatic backchannels.},
	language = {en},
	number = {1},
	urldate = {2020-03-10},
	journal = {International Journal of Corpus Linguistics},
	author = {Kjellmer, Göran},
	month = jan,
	year = {2009},
	note = {Publisher: John Benjamins},
	pages = {81--112},
}

@inproceedings{housley_natural_2019,
	address = {Nottingham United Kingdom},
	title = {Natural {Action} {Processing}: {Conversation} {Analysis} and {Big} {Interactional} {Data}},
	isbn = {978-1-4503-7203-9},
	url = {https://dl.acm.org/doi/10.1145/3363384.3363478},
	doi = {10.1145/3363384.3363478},
	abstract = {This position paper identifies a crucial opportunity for the reciprocal exchange of methods, data and phenomena between conversation analysis (CA), ethnomethodology (EM) and computer science (CS). Conventional CS classification of sentiment, tone of voice, or personality do not address what people do with language or the paired sequences that organize actions into social interaction. We argue that CA and EM can innovate and substantially enhance the scope of the dominant CS approaches to big interactional data if artificial intelligence-based natural language processing systems are trained using CA annotated data to do what we call natural action processing.},
	language = {en},
	urldate = {2021-07-13},
	booktitle = {Proceedings of the {Halfway} to the {Future} {Symposium} 2019},
	publisher = {ACM},
	author = {Housley, William and Albert, Saul and Stokoe, Elizabeth},
	month = nov,
	year = {2019},
	pages = {1--4},
}

@inproceedings{gur_user_2018,
	title = {User {Modeling} for {Task} {Oriented} {Dialogues}},
	doi = {10.1109/SLT.2018.8639652},
	abstract = {We introduce end-to-end neural network based models for simulating users of task-oriented dialogue systems. User simulation in dialogue systems is crucial from two different perspectives: (i) automatic evaluation of different dialogue models, and (ii) training task-oriented dialogue systems. We design a hierarchical sequence-to-sequence model that first encodes the initial user goal and system turns into fixed length representations using Recurrent Neural Networks (RNN). It then encodes the dialogue history using another RNN layer. At each turn, user responses are decoded from the hidden representations of the dialogue level RNN. This hierarchical user simulator (HUS) approach allows the model to capture undiscovered parts of the user goal without the need of an explicit dialogue state tracking. We further develop several variants by utilizing a latent variable model to inject random variations into user responses to promote diversity in simulated user responses and a novel goal regularization mechanism to penalize divergence of user responses from the initial user goal. We evaluate the proposed models on movie ticket booking domain by systematically interacting each user simulator with various dialogue system policies trained with different objectives and users.},
	booktitle = {2018 {IEEE} {Spoken} {Language} {Technology} {Workshop} ({SLT})},
	author = {Gür, Izzeddin and Hakkani-Tür, Dilek and Tür, Gokhan and Shah, Pararth},
	month = dec,
	year = {2018},
	keywords = {Encoding, Hidden Markov models, History, Motion pictures, Neural networks, Task analysis, Training},
	pages = {900--906},
}

@inproceedings{forbes_dim_2022,
	address = {Dublin, Ireland},
	title = {Dim {Wihl} {Gat} {Tun}: {The} {Case} for {Linguistic} {Expertise} in {NLP} for {Under}-{Documented} {Languages}},
	shorttitle = {Dim {Wihl} {Gat} {Tun}},
	url = {https://aclanthology.org/2022.findings-acl.167},
	abstract = {Recent progress in NLP is driven by pretrained models leveraging massive datasets and has predominantly benefited the world's political and economic superpowers. Technologically underserved languages are left behind because they lack such resources. Hundreds of underserved languages, nevertheless, have available data sources in the form of interlinear glossed text (IGT) from language documentation efforts. IGT remains underutilized in NLP work, perhaps because its annotations are only semi-structured and often language-specific. With this paper, we make the case that IGT data can be leveraged successfully provided that target language expertise is available. We specifically advocate for collaboration with documentary linguists. Our paper provides a roadmap for successful projects utilizing IGT data: (1) It is essential to define which NLP tasks can be accomplished with the given IGT data and how these will benefit the speech community. (2) Great care and target language expertise is required when converting the data into structured formats commonly employed in NLP. (3) Task-specific and user-specific evaluation can help to ascertain that the tools which are created benefit the target language speech community. We illustrate each step through a case study on developing a morphological reinflection system for the Tsimchianic language Gitksan.},
	urldate = {2022-05-21},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Forbes, Clarissa and Samir, Farhan and Oliver, Bruce and Yang, Changbing and Coates, Edith and Nicolai, Garrett and Silfverberg, Miikka},
	month = may,
	year = {2022},
	pages = {2116--2130},
}

@inproceedings{ernestus_nijmegen_2014,
	address = {Reykjavik, Iceland},
	title = {The {Nijmegen} {Corpus} of {Casual} {Czech}},
	url = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/134_Paper.pdf},
	abstract = {This article introduces a new speech corpus, the Nijmegen Corpus of Casual Czech (NCCCz), which contains more than 30 hours of high-quality recordings of casual conversations in Common Czech, among ten groups of three male and ten groups of three female friends. All speakers were native speakers of Czech, raised in Prague or in the region of Central Bohemia, and were between 19 and 26 years old. Every group of speakers consisted of one confederate, who was instructed to keep the conversations lively, and two speakers naive to the purposes of the recordings. The naive speakers were engaged in conversations for approximately 90 minutes, while the confederate joined them for approximately the last 72 minutes. The corpus was orthographically annotated by experienced transcribers and this orthographic transcription was aligned with the speech signal. In addition, the conversations were videotaped. This corpus can form the basis for all types of research on casual conversations in Czech, including phonetic research and research on how to improve automatic speech recognition. The corpus will be freely available.},
	urldate = {2020-11-02},
	booktitle = {Proceedings of the {Ninth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'14)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Ernestus, Mirjam and Kočková-Amortová, Lucie and Pollak, Petr},
	month = may,
	year = {2014},
	pages = {365--370},
}

@article{dautenhahn_socially_2007,
	title = {Socially intelligent robots: dimensions of human–robot interaction},
	volume = {362},
	shorttitle = {Socially intelligent robots},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2006.2004},
	doi = {10.1098/rstb.2006.2004},
	abstract = {Social intelligence in robots has a quite recent history in artificial intelligence and robotics. However, it has become increasingly apparent that social and interactive skills are necessary requirements in many application areas and contexts where robots need to interact and collaborate with other robots or humans. Research on human–robot interaction (HRI) poses many challenges regarding the nature of interactivity and ‘social behaviour’ in robot and humans. The first part of this paper addresses dimensions of HRI, discussing requirements on social skills for robots and introducing the conceptual space of HRI studies. In order to illustrate these concepts, two examples of HRI research are presented. First, research is surveyed which investigates the development of a cognitive robot companion. The aim of this work is to develop social rules for robot behaviour (a ‘robotiquette’) that is comfortable and acceptable to humans. Second, robots are discussed as possible educational or therapeutic toys for children with autism. The concept of interactive emergence in human–child interactions is highlighted. Different types of play among children are discussed in the light of their potential investigation in human–robot experiments. The paper concludes by examining different paradigms regarding ‘social relationships’ of robots and people interacting with them.},
	number = {1480},
	urldate = {2022-04-19},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Dautenhahn, Kerstin},
	month = apr,
	year = {2007},
	note = {Publisher: Royal Society},
	pages = {679--704},
}

@inproceedings{cyra_dealing_2017,
	title = {Dealing with ‘long turns’ produced by users of an assistive system: {How} missing uptake and recipiency lead to turn increments},
	shorttitle = {Dealing with ‘long turns’ produced by users of an assistive system},
	doi = {10.1109/ROMAN.2017.8172322},
	abstract = {Based on a user study, we start from the observation that `long turns' uttered by users towards an assistive system constitute a challenge for the dialog management of a voice-operated system. Assuming an interactional perspective, we address the question as to how `long turns' emerge in interaction. We suggest to conceive of these utterances as being co-constructed by both, the user and the multimodal conduct of the technical system. In this paper, we examine how such `long turns' emerge step by step in terms of an initial utterance being expanded by so-called `increments' as well as their specific structure. Analysis shows that such utterance expansions (causing `long turns') indicate that the user faces problems with a lack of uptake resp. display of recipiency by the technical system. Combining qualitative micro-analysis with quantification, we discuss specific interactional contexts of turn increments, different actions performed by them and the role of uptake resources in the light of designing autonomous speech-based systems.},
	booktitle = {2017 26th {IEEE} {International} {Symposium} on {Robot} and {Human} {Interactive} {Communication} ({RO}-{MAN})},
	author = {Cyra, K. and Pitsch, Karola},
	month = aug,
	year = {2017},
	note = {ISSN: 1944-9437},
	pages = {329--334},
}

@article{bolden_transcribing_2015,
	title = {Transcribing as {Research}: “{Manual}” {Transcription} and {Conversation} {Analysis}},
	volume = {48},
	issn = {0835-1813},
	shorttitle = {Transcribing as {Research}},
	url = {https://doi.org/10.1080/08351813.2015.1058603},
	doi = {10.1080/08351813.2015.1058603},
	abstract = {Moore (2015/this issue) discusses possibilities afforded by state-of-the-art automated transcription technologies for conversation analytic (CA) research. Since these technologies may become attractive to conversation analysts, their impact should be carefully considered. In this commentary, I offer some words of caution about adopting automated transcription techniques. Three issues are raised: first, the role of transcribing in research and training; second, potential influences of automated transcription on research agendas; and, third, some analytic problems involved in relying on a large bank of transcribed yet unfamiliar data. Data are in American English.},
	number = {3},
	urldate = {2022-04-28},
	journal = {Research on Language and Social Interaction},
	author = {Bolden, Galina B.},
	month = jul,
	year = {2015},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2015.1058603},
	pages = {276--280},
}

@inproceedings{bianchi_gap_2021,
	address = {Online},
	title = {On the {Gap} between {Adoption} and {Understanding} in {NLP}},
	url = {https://aclanthology.org/2021.findings-acl.340},
	doi = {10.18653/v1/2021.findings-acl.340},
	urldate = {2022-05-13},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL}-{IJCNLP} 2021},
	publisher = {Association for Computational Linguistics},
	author = {Bianchi, Federico and Hovy, Dirk},
	month = aug,
	year = {2021},
	pages = {3895--3901},
}

@inproceedings{ignat_ocr_2022,
	address = {Dublin, Ireland},
	title = {{OCR} {Improves} {Machine} {Translation} for {Low}-{Resource} {Languages}},
	url = {https://aclanthology.org/2022.findings-acl.92},
	abstract = {We aim to investigate the performance of current OCR systems on low resource languages and low resource scripts.We introduce and make publicly available a novel benchmark, OCR4MT, consisting of real and synthetic data, enriched with noise, for 60 low-resource languages in low resource scripts. We evaluate state-of-the-art OCR systems on our benchmark and analyse most common errors. We show that OCR monolingual data is a valuable resource that can increase performance of Machine Translation models, when used in backtranslation. We then perform an ablation study to investigate how OCR errors impact Machine Translation performance and determine what is the minimum level of OCR quality needed for the monolingual data to be useful for Machine Translation.},
	urldate = {2022-05-21},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Ignat, Oana and Maillard, Jean and Chaudhary, Vishrav and Guzmán, Francisco},
	month = may,
	year = {2022},
	pages = {1164--1174},
}

@inproceedings{lignos_toward_2022,
	address = {Dublin, Ireland},
	title = {Toward {More} {Meaningful} {Resources} for {Lower}-resourced {Languages}},
	url = {https://aclanthology.org/2022.findings-acl.44},
	abstract = {In this position paper, we describe our perspective on how meaningful resources for lower-resourced languages should be developed in connection with the speakers of those languages. Before advancing that position, we first examine two massively multilingual resources used in language technology development, identifying shortcomings that limit their usefulness. We explore the contents of the names stored in Wikidata for a few lower-resourced languages and find that many of them are not in fact in the languages they claim to be, requiring non-trivial effort to correct. We discuss quality issues present in WikiAnn and evaluate whether it is a useful supplement to hand-annotated data. We then discuss the importance of creating annotations for lower-resourced languages in a thoughtful and ethical way that includes the language speakers as part of the development process. We conclude with recommended guidelines for resource development.},
	urldate = {2022-05-21},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Lignos, Constantine and Holley, Nolan and Palen-Michel, Chester and Sälevä, Jonne},
	month = may,
	year = {2022},
	pages = {523--532},
}

@inproceedings{wiemerslage_morphological_2022,
	address = {Dublin, Ireland},
	title = {Morphological {Processing} of {Low}-{Resource} {Languages}: {Where} {We} {Are} and {What}'s {Next}},
	shorttitle = {Morphological {Processing} of {Low}-{Resource} {Languages}},
	url = {https://aclanthology.org/2022.findings-acl.80},
	abstract = {Automatic morphological processing can aid downstream natural language processing applications, especially for low-resource languages, and assist language documentation efforts for endangered languages. Having long been multilingual, the field of computational morphology is increasingly moving towards approaches suitable for languages with minimal or no annotated resources. First, we survey recent developments in computational morphology with a focus on low-resource languages. Second, we argue that the field is ready to tackle the logical next challenge: understanding a language's morphology from raw text alone. We perform an empirical study on a truly unsupervised version of the paradigm completion task and show that, while existing state-of-the-art models bridged by two newly proposed models we devise perform reasonably, there is still much room for improvement. The stakes are high: solving this task will increase the language coverage of morphological resources by a number of magnitudes.},
	urldate = {2022-05-21},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Wiemerslage, Adam and Silfverberg, Miikka and Yang, Changbing and McCarthy, Arya and Nicolai, Garrett and Colunga, Eliana and Kann, Katharina},
	month = may,
	year = {2022},
	pages = {988--1007},
}

@inproceedings{faisal_dataset_2022,
	address = {Dublin, Ireland},
	title = {Dataset {Geography}: {Mapping} {Language} {Data} to {Language} {Users}},
	shorttitle = {Dataset {Geography}},
	url = {https://aclanthology.org/2022.acl-long.239},
	abstract = {As language technologies become more ubiquitous, there are increasing efforts towards expanding the language diversity and coverage of natural language processing (NLP) systems. Arguably, the most important factor influencing the quality of modern NLP systems is data availability. In this work, we study the geographical representativeness of NLP datasets, aiming to quantify if and by how much do NLP datasets match the expected needs of the language speakers. In doing so, we use entity recognition and linking systems, also making important observations about their cross-lingual consistency and giving suggestions for more robust evaluation. Last, we explore some geographical and economic factors that may explain the observed dataset distributions.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Faisal, Fahim and Wang, Yinkai and Anastasopoulos, Antonios},
	month = may,
	year = {2022},
	pages = {3381--3411},
}

@inproceedings{le_ferrand_learning_2022,
	address = {Dublin, Ireland},
	title = {Learning {From} {Failure}: {Data} {Capture} in an {Australian} {Aboriginal} {Community}},
	shorttitle = {Learning {From} {Failure}},
	url = {https://aclanthology.org/2022.acl-long.342},
	abstract = {Most low resource language technology development is premised on the need to collect data for training statistical models. When we follow the typical process of recording and transcribing text for small Indigenous languages, we hit up against the so-called “transcription bottleneck.” Therefore it is worth exploring new ways of engaging with speakers which generate data while avoiding the transcription bottleneck. We have deployed a prototype app for speakers to use for confirming system guesses in an approach to transcription based on word spotting. However, in the process of testing the app we encountered many new problems for engagement with speakers. This paper presents a close-up study of the process of deploying data capture technology on the ground in an Australian Aboriginal community. We reflect on our interactions with participants and draw lessons that apply to anyone seeking to develop methods for language data collection in an Indigenous community.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Le Ferrand, Eric and Bird, Steven and Besacier, Laurent},
	month = may,
	year = {2022},
	pages = {4988--4998},
}

@inproceedings{ebrahimi_americasnli_2022,
	address = {Dublin, Ireland},
	title = {{AmericasNLI}: {Evaluating} {Zero}-shot {Natural} {Language} {Understanding} of {Pretrained} {Multilingual} {Models} in {Truly} {Low}-resource {Languages}},
	shorttitle = {{AmericasNLI}},
	url = {https://aclanthology.org/2022.acl-long.435},
	abstract = {Pretrained multilingual models are able to perform cross-lingual transfer in a zero-shot setting, even for languages unseen during pretraining. However, prior work evaluating performance on unseen languages has largely been limited to low-level, syntactic tasks, and it remains unclear if zero-shot learning of high-level, semantic tasks is possible for unseen languages. To explore this question, we present AmericasNLI, an extension of XNLI (Conneau et al., 2018) to 10 Indigenous languages of the Americas. We conduct experiments with XLM-R, testing multiple zero-shot and translation-based approaches. Additionally, we explore model adaptation via continued pretraining and provide an analysis of the dataset by considering hypothesis-only models. We find that XLM-R's zero-shot performance is poor for all 10 languages, with an average performance of 38.48\%. Continued pretraining offers improvements, with an average accuracy of 43.85\%. Surprisingly, training on poorly translated data by far outperforms all other methods with an accuracy of 49.12\%.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Ebrahimi, Abteen and Mager, Manuel and Oncevay, Arturo and Chaudhary, Vishrav and Chiruzzo, Luis and Fan, Angela and Ortega, John and Ramos, Ricardo and Rios, Annette and Meza Ruiz, Ivan Vladimir and Giménez-Lugo, Gustavo and Mager, Elisabeth and Neubig, Graham and Palmer, Alexis and Coto-Solano, Rolando and Vu, Thang and Kann, Katharina},
	month = may,
	year = {2022},
	pages = {6279--6299},
}

@inproceedings{hershcovich_challenges_2022,
	address = {Dublin, Ireland},
	title = {Challenges and {Strategies} in {Cross}-{Cultural} {NLP}},
	url = {https://aclanthology.org/2022.acl-long.482},
	abstract = {Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hershcovich, Daniel and Frank, Stella and Lent, Heather and de Lhoneux, Miryam and Abdou, Mostafa and Brandl, Stephanie and Bugliarello, Emanuele and Cabello Piqueras, Laura and Chalkidis, Ilias and Cui, Ruixiang and Fierro, Constanza and Margatina, Katerina and Rust, Phillip and Søgaard, Anders},
	month = may,
	year = {2022},
	pages = {6997--7013},
}

@inproceedings{bird_local_2022,
	address = {Dublin, Ireland},
	title = {Local {Languages}, {Third} {Spaces}, and other {High}-{Resource} {Scenarios}},
	url = {https://aclanthology.org/2022.acl-long.539},
	abstract = {How can language technology address the diverse situations of the world's languages? In one view, languages exist on a resource continuum and the challenge is to scale existing solutions, bringing under-resourced languages into the high-resource world. In another view, presented here, the world's language ecology includes standardised languages, local languages, and contact languages. These are often subsumed under the label of “under-resourced languages” even though they have distinct functions and prospects. I explore this position and propose some ecologically-aware language technology agendas.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Bird, Steven},
	month = may,
	year = {2022},
	pages = {7817--7829},
}

@inproceedings{bergman_towards_2022,
	address = {Dublin, Ireland},
	title = {Towards {Responsible} {Natural} {Language} {Annotation} for the {Varieties} of {Arabic}},
	url = {https://aclanthology.org/2022.findings-acl.31},
	abstract = {When building NLP models, there is a tendency to aim for broader coverage, often overlooking cultural and (socio)linguistic nuance. In this position paper, we make the case for care and attention to such nuances, particularly in dataset annotation, as well as the inclusion of cultural and linguistic expertise in the process. We present a playbook for responsible dataset creation for polyglossic, multidialectal languages. This work is informed by a study on Arabic annotation of social media content.},
	urldate = {2022-05-21},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Bergman, A. and Diab, Mona},
	month = may,
	year = {2022},
	pages = {364--371},
}

@inproceedings{lee_pre-trained_2022,
	address = {Dublin, Ireland},
	title = {Pre-{Trained} {Multilingual} {Sequence}-to-{Sequence} {Models}: {A} {Hope} for {Low}-{Resource} {Language} {Translation}?},
	shorttitle = {Pre-{Trained} {Multilingual} {Sequence}-to-{Sequence} {Models}},
	url = {https://aclanthology.org/2022.findings-acl.6},
	abstract = {What can pre-trained multilingual sequence-to-sequence models like mBART contribute to translating low-resource languages? We conduct a thorough empirical experiment in 10 languages to ascertain this, considering five factors: (1) the amount of fine-tuning data, (2) the noise in the fine-tuning data, (3) the amount of pre-training data in the model, (4) the impact of domain mismatch, and (5) language typology. In addition to yielding several heuristics, the experiments form a framework for evaluating the data sensitivities of machine translation systems. While mBART is robust to domain differences, its translations for unseen and typologically distant languages remain below 3.0 BLEU. In answer to our title's question, mBART is not a low-resource panacea; we therefore encourage shifting the emphasis from new models to new data.},
	urldate = {2022-05-21},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Lee, En-Shiun and Thillainathan, Sarubi and Nayak, Shravan and Ranathunga, Surangika and Adelani, David and Su, Ruisi and McCarthy, Arya},
	month = may,
	year = {2022},
	pages = {58--67},
}

@techreport{downey_multilingual_2022,
	title = {Multilingual unsupervised sequence segmentation transfers to extremely low-resource languages},
	url = {http://arxiv.org/abs/2110.08415},
	abstract = {We show that unsupervised sequence-segmentation performance can be transferred to extremely low-resource languages by pre-training a Masked Segmental Language Model (Downey et al., 2021) multilingually. Further, we show that this transfer can be achieved by training over a collection of low-resource languages that are typologically similar (but phylogenetically unrelated) to the target language. In our experiments, we transfer from a collection of 10 Indigenous American languages (AmericasNLP, Mager et al., 2021) to K'iche', a Mayan language. We compare our multilingual model to a monolingual (from-scratch) baseline, as well as a model pre-trained on Quechua only. We show that the multilingual pre-trained approach yields consistent segmentation quality across target dataset sizes, exceeding the monolingual baseline in 6/10 experimental settings. Our model yields especially strong results at small target sizes, including a zero-shot performance of 20.6 F1. These results have promising implications for low-resource NLP pipelines involving human-like linguistic units, such as the sparse transcription framework proposed by Bird (2020).},
	number = {arXiv:2110.08415},
	urldate = {2022-05-21},
	institution = {arXiv},
	author = {Downey, C. M. and Drizin, Shannon and Haroutunian, Levon and Thukral, Shivin},
	month = mar,
	year = {2022},
	doi = {10.48550/arXiv.2110.08415},
	note = {arXiv:2110.08415 [cs]
version: 2
type: article},
}

@inproceedings{lane_interactive_2022,
	address = {Dublin, Ireland},
	title = {Interactive {Word} {Completion} for {Plains} {Cree}},
	url = {https://aclanthology.org/2022.acl-long.232},
	abstract = {The composition of richly-inflected words in morphologically complex languages can be a challenge for language learners developing literacy. Accordingly, Lane and Bird (2020) proposed a finite state approach which maps prefixes in a language to a set of possible completions up to the next morpheme boundary, for the incremental building of complex words. In this work, we develop an approach to morph-based auto-completion based on a finite state morphological analyzer of Plains Cree (nêhiyawêwin), showing the portability of the concept to a much larger, more complete morphological transducer. Additionally, we propose and compare various novel ranking strategies on the morph auto-complete output. The best weighting scheme ranks the target completion in the top 10 results in 64.9\% of queries, and in the top 50 in 73.9\% of queries.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Lane, William and Harrigan, Atticus and Arppe, Antti},
	month = may,
	year = {2022},
	pages = {3284--3294},
}

@inproceedings{aji_one_2022,
	address = {Dublin, Ireland},
	title = {One {Country}, 700+ {Languages}: {NLP} {Challenges} for {Underrepresented} {Languages} and {Dialects} in {Indonesia}},
	shorttitle = {One {Country}, 700+ {Languages}},
	url = {https://aclanthology.org/2022.acl-long.500},
	abstract = {NLP research is impeded by a lack of resources and awareness of the challenges presented by underrepresented languages and dialects. Focusing on the languages spoken in Indonesia, the second most linguistically diverse and the fourth most populous nation of the world, we provide an overview of the current state of NLP research for Indonesia's 700+ languages. We highlight challenges in Indonesian NLP and how these affect the performance of current NLP systems. Finally, we provide general recommendations to help develop NLP technology not only for languages of Indonesia but also other underrepresented languages.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Aji, Alham and Winata, Genta Indra and Koto, Fajri and Cahyawijaya, Samuel and Romadhony, Ade and Mahendra, Rahmad and Kurniawan, Kemal and Moeljadi, David and Prasojo, Radityo Eko and Baldwin, Timothy and Lau, Jey Han and Ruder, Sebastian},
	month = may,
	year = {2022},
	pages = {7226--7249},
}

@inproceedings{adebara_towards_2022,
	address = {Dublin, Ireland},
	title = {Towards {Afrocentric} {NLP} for {African} {Languages}: {Where} {We} {Are} and {Where} {We} {Can} {Go}},
	shorttitle = {Towards {Afrocentric} {NLP} for {African} {Languages}},
	url = {https://aclanthology.org/2022.acl-long.265},
	abstract = {Aligning with ACL 2022 special Theme on “Language Diversity: from Low Resource to Endangered Languages”, we discuss the major linguistic and sociopolitical challenges facing development of NLP technologies for African languages. Situating African languages in a typological framework, we discuss how the particulars of these languages can be harnessed. To facilitate future research, we also highlight current efforts, communities, venues, datasets, and tools. Our main objective is to motivate and advocate for an Afrocentric approach to technology development. With this in mind, we recommend what technologies to build and how to build, evaluate, and deploy them based on the needs of local African communities.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Adebara, Ife and Abdul-Mageed, Muhammad},
	month = may,
	year = {2022},
	pages = {3814--3841},
}

@inproceedings{de_vries_make_2022,
	address = {Dublin, Ireland},
	title = {Make the {Best} of {Cross}-lingual {Transfer}: {Evidence} from {POS} {Tagging} with over 100 {Languages}},
	shorttitle = {Make the {Best} of {Cross}-lingual {Transfer}},
	url = {https://aclanthology.org/2022.acl-long.529},
	abstract = {Cross-lingual transfer learning with large multilingual pre-trained models can be an effective approach for low-resource languages with no labeled training data. Existing evaluations of zero-shot cross-lingual generalisability of large pre-trained models use datasets with English training data, and test data in a selection of target languages. We explore a more extensive transfer learning setup with 65 different source languages and 105 target languages for part-of-speech tagging. Through our analysis, we show that pre-training of both source and target language, as well as matching language families, writing systems, word order systems, and lexical-phonetic distance significantly impact cross-lingual performance. The findings described in this paper can be used as indicators of which factors are important for effective zero-shot cross-lingual transfer to zero- and low-resource languages.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {de Vries, Wietse and Wieling, Martijn and Nissim, Malvina},
	month = may,
	year = {2022},
	pages = {7676--7685},
}

@inproceedings{wang_expanding_2022,
	address = {Dublin, Ireland},
	title = {Expanding {Pretrained} {Models} to {Thousands} {More} {Languages} via {Lexicon}-based {Adaptation}},
	url = {https://aclanthology.org/2022.acl-long.61},
	abstract = {The performance of multilingual pretrained models is highly dependent on the availability of monolingual or parallel text present in a target language. Thus, the majority of the world's languages cannot benefit from recent progress in NLP as they have no or limited textual data. To expand possibilities of using NLP technology in these under-represented languages, we systematically study strategies that relax the reliance on conventional language resources through the use of bilingual lexicons, an alternative resource with much better language coverage. We analyze different strategies to synthesize textual or labeled data using lexicons, and how this data can be combined with monolingual or parallel text when available. For 19 under-represented languages across 3 tasks, our methods lead to consistent improvements of up to 5 and 15 points with and without extra monolingual text respectively. Overall, our study highlights how NLP methods can be adapted to thousands more languages that are under-served by current technology.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Xinyi and Ruder, Sebastian and Neubig, Graham},
	month = may,
	year = {2022},
	pages = {863--877},
}

@inproceedings{teodorescu_cree_2022,
	address = {Dublin, Ireland},
	title = {Cree {Corpus}: {A} {Collection} of nêhiyawêwin {Resources}},
	shorttitle = {Cree {Corpus}},
	url = {https://aclanthology.org/2022.acl-long.440},
	abstract = {Plains Cree (nêhiyawêwin) is an Indigenous language that is spoken in Canada and the USA. It is the most widely spoken dialect of Cree and a morphologically complex language that is polysynthetic, highly inflective, and agglutinative. It is an extremely low resource language, with no existing corpus that is both available and prepared for supporting the development of language technologies. To support nêhiyawêwin revitalization and preservation, we developed a corpus covering diverse genres, time periods, and texts for a variety of intended audiences. The data has been verified and cleaned; it is ready for use in developing language technologies for nêhiyawêwin. The corpus includes the corresponding English phrases or audio files where available. We demonstrate the utility of the corpus through its community use and its use to build language technologies that can provide the types of support that community members have expressed are desirable. The corpus is available for public use.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Teodorescu, Daniela and Matalski, Josie and Lothian, Delaney and Barbosa, Denilson and Demmans Epp, Carrie},
	month = may,
	year = {2022},
	pages = {6354--6364},
}

@inproceedings{leong_phone-ing_2022,
	address = {Dublin, Ireland},
	title = {Phone-ing it in: {Towards} {Flexible} {Multi}-{Modal} {Language} {Model} {Training} by {Phonetic} {Representations} of {Data}},
	shorttitle = {Phone-ing it in},
	url = {https://aclanthology.org/2022.acl-long.364},
	abstract = {Multi-modal techniques offer significant untapped potential to unlock improved NLP technology for local languages. However, many advances in language model pre-training are focused on text, a fact that only increases systematic inequalities in the performance of NLP tasks across the world's languages. In this work, we propose a multi-modal approach to train language models using whatever text and/or audio data might be available in a language. Initial experiments using Swahili and Kinyarwanda data suggest the viability of the approach for downstream Named Entity Recognition (NER) tasks, with models pre-trained on phone data showing an improvement of up to 6\% F1-score above models that are trained from scratch. Preprocessing and training code will be uploaded to https://github.com/sil-ai/phone-it-in.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Leong, Colin and Whitenack, Daniel},
	month = may,
	year = {2022},
	pages = {5306--5315},
}

@inproceedings{zhang_how_2022,
	address = {Dublin, Ireland},
	title = {How can {NLP} {Help} {Revitalize} {Endangered} {Languages}? {A} {Case} {Study} and {Roadmap} for the {Cherokee} {Language}},
	shorttitle = {How can {NLP} {Help} {Revitalize} {Endangered} {Languages}?},
	url = {https://aclanthology.org/2022.acl-long.108},
	abstract = {More than 43\% of the languages spoken in the world are endangered, and language loss currently occurs at an accelerated rate because of globalization and neocolonialism. Saving and revitalizing endangered languages has become very important for maintaining the cultural diversity on our planet. In this work, we focus on discussing how NLP can help revitalize endangered languages. We first suggest three principles that may help NLP practitioners to foster mutual understanding and collaboration with language communities, and we discuss three ways in which NLP can potentially assist in language education. We then take Cherokee, a severely-endangered Native American language, as a case study. After reviewing the language's history, linguistic features, and existing resources, we (in collaboration with Cherokee community members) arrive at a few meaningful ways NLP practitioners can collaborate with community partners. We suggest two approaches to enrich the Cherokee language's resources with machine-in-the-loop processing, and discuss several NLP tools that people from the Cherokee community have shown interest in. We hope that our work serves not only to inform the NLP community about Cherokee, but also to provide inspiration for future work on endangered languages in general.},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Shiyue and Frey, Ben and Bansal, Mohit},
	month = may,
	year = {2022},
	pages = {1529--1541},
}

@inproceedings{riad_comparison_2022,
	address = {Dublin, Ireland},
	title = {A comparison study on patient-psychologist voice diarization},
	url = {https://aclanthology.org/2022.slpat-1.4},
	abstract = {Conversations between a clinician and a patient, in natural conditions, are valuable sources of information for medical follow-up. The automatic analysis of these dialogues could help extract new language markers and speed up the clinicians' reports. Yet, it is not clear which model is the most efficient to detect and identify the speaker turns, especially for individuals with speech disorders. Here, we proposed a split of the data that allows conducting a comparative evaluation of different diarization methods. We designed and trained end-to-end neural network architectures to directly tackle this task from the raw signal and evaluate each approach under the same metric. We also studied the effect of fine-tuning models to find the best performance. Experimental results are reported on naturalistic clinical conversations between Psychologists and Interviewees, at different stages of Huntington's disease, displaying a large panel of speech disorders. We found out that our best end-to-end model achieved 19.5 \% IER on the test set, compared to 23.6\% achieved by the finetuning of the X-vector architecture. Finally, we observed that we could extract clinical markers directly from the automatic systems, highlighting the clinical relevance of our methods.},
	urldate = {2022-05-21},
	booktitle = {Ninth {Workshop} on {Speech} and {Language} {Processing} for {Assistive} {Technologies} ({SLPAT}-2022)},
	publisher = {Association for Computational Linguistics},
	author = {Riad, Rachid and Titeux, Hadrien and Lemoine, Laurie and Montillot, Justine and Sliwinski, Agnes and Bagnou, Jennifer and Cao, Xuan and Bachoud-Levi, Anne-Catherine and Dupoux, Emmanuel},
	month = may,
	year = {2022},
	pages = {30--36},
}

@article{giles_microanalysis_2015,
	title = {Microanalysis {Of} {Online} {Data}: {The} methodological development of “digital {CA}”},
	volume = {7},
	issn = {2211-6958},
	shorttitle = {Microanalysis {Of} {Online} {Data}},
	url = {http://www.sciencedirect.com/science/article/pii/S2211695814000464},
	doi = {10.1016/j.dcm.2014.12.002},
	abstract = {This paper introduces the work of the MOOD (Microanalysis Of Online Data) network, an interdisciplinary association of academic researchers exploring ways of conducting close qualitative analyses of online interaction. Despite the fact that much online interaction meets the criteria for ‘conversation’, conversation analysis (CA) has only recently begun to grow and flourish as a methodology for analysing the overwhelming quantity of material that in many cases sits in archive form, visible to millions, on the Internet. We discuss the development of methods that are inherently suited for subjecting online interaction to the kind of rigorous analysis that conversation analysts have applied to talk of all kinds for several decades. We go on to explore the fundamental challenges that online data pose for CA, the value of many CA techniques for online analysis, and the possibilities of developing bespoke modes of analysis that are crafted for use with specific forms of online data (e.g. ‘tweets’ on Twitter).},
	urldate = {2019-07-25},
	journal = {Discourse, Context \& Media},
	author = {Giles, David and Stommel, Wyke and Paulus, Trena and Lester, Jessica and Reed, Darren},
	month = mar,
	year = {2015},
	pages = {45--51},
}

@article{zayats_conversation_2018,
	title = {Conversation {Modeling} on {Reddit} {Using} a {Graph}-{Structured} {LSTM}},
	volume = {6},
	url = {https://aclanthology.org/Q18-1009},
	doi = {10.1162/tacl_a_00009},
	abstract = {This paper presents a novel approach for modeling threaded discussions on social media using a graph-structured bidirectional LSTM (long-short term memory) which represents both hierarchical and temporal conversation structure. In experiments with a task of predicting popularity of comments in Reddit discussions, the proposed model outperforms a node-independent architecture for different sets of input features. Analyses show a benefit to the model over the full course of the discussion, improving detection in both early and late stages. Further, the use of language cues with the bidirectional tree state updates helps with identifying controversial comments.},
	urldate = {2022-05-21},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Zayats, Victoria and Ostendorf, Mari},
	year = {2018},
	note = {Place: Cambridge, MA
Publisher: MIT Press},
	pages = {121--132},
}

@inproceedings{blasi_systematic_2022,
	address = {Dublin, Ireland},
	title = {Systematic {Inequalities} in {Language} {Technology} {Performance} across the {World}'s {Languages}},
	url = {https://aclanthology.org/2022.acl-long.376},
	abstract = {Natural language processing (NLP) systems have become a central technology in communication, education, medicine, artificial intelligence, and many other domains of research and development. While the performance of NLP methods has grown enormously over the last decade, this progress has been restricted to a minuscule subset of the world's \${\textbackslash}approx\$6,500 languages. We introduce a framework for estimating the global utility of language technologies as revealed in a comprehensive snapshot of recent publications in NLP. Our analyses involve the field at large, but also more in-depth studies on both user-facing technologies (machine translation, language understanding, question answering, text-to-speech synthesis) as well as foundational NLP tasks (dependency parsing, morphological inflection). In the process, we (1) quantify disparities in the current state of NLP research, (2) explore some of its associated societal and academic factors, and (3) produce tailored recommendations for evidence-based policy making aimed at promoting more global and equitable language technologies. Data and code to reproduce the findings discussed in this paper areavailable on GitHub (https://github.com/neubig/globalutility).},
	urldate = {2022-05-21},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Blasi, Damian and Anastasopoulos, Antonios and Neubig, Graham},
	month = may,
	year = {2022},
	pages = {5486--5505},
}

@inproceedings{raphalen_you_2022,
	address = {Dublin, Ireland},
	title = {”{You} might think about slightly revising the title”: {Identifying} {Hedges} in {Peer}-tutoring {Interactions}},
	shorttitle = {”{You} might think about slightly revising the title”},
	url = {https://aclanthology.org/2022.acl-long.153},
	abstract = {Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Raphalen, Yann and Clavel, Chloé and Cassell, Justine},
	month = may,
	year = {2022},
	pages = {2160--2174},
}

@inproceedings{li_ditch_2022,
	address = {Dublin, Ireland},
	title = {Ditch the {Gold} {Standard}: {Re}-evaluating {Conversational} {Question} {Answering}},
	shorttitle = {Ditch the {Gold} {Standard}},
	url = {https://aclanthology.org/2022.acl-long.555},
	abstract = {Conversational question answering aims to provide natural-language answers to users in information-seeking conversations. Existing conversational QA benchmarks compare models with pre-collected human-human conversations, using ground-truth answers provided in conversational history. It remains unclear whether we can rely on this static evaluation for model development and whether current systems can well generalize to real-world human-machine conversations. In this work, we conduct the first large-scale human evaluation of state-of-the-art conversational QA systems, where human evaluators converse with models and judge the correctness of their answers. We find that the distribution of human machine conversations differs drastically from that of human-human conversations, and there is a disagreement between human and gold-history evaluation in terms of model ranking. We further investigate how to improve automatic evaluations, and propose a question rewriting mechanism based on predicted history, which better correlates with human judgments. Finally, we analyze the impact of various modeling strategies and discuss future directions towards building better conversational question answering systems.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Li, Huihan and Gao, Tianyu and Goenka, Manan and Chen, Danqi},
	month = may,
	year = {2022},
	pages = {8074--8085},
}

@inproceedings{sun_safety_2022,
	address = {Dublin, Ireland},
	title = {On the {Safety} of {Conversational} {Models}: {Taxonomy}, {Dataset}, and {Benchmark}},
	shorttitle = {On the {Safety} of {Conversational} {Models}},
	url = {https://aclanthology.org/2022.findings-acl.308},
	abstract = {Dialogue safety problems severely limit the real-world deployment of neural conversational models and have attracted great research interests recently. However, dialogue safety problems remain under-defined and the corresponding dataset is scarce. We propose a taxonomy for dialogue safety specifically designed to capture unsafe behaviors in human-bot dialogue settings, with focuses on context-sensitive unsafety, which is under-explored in prior works. To spur research in this direction, we compile DiaSafety, a dataset with rich context-sensitive unsafe examples. Experiments show that existing safety guarding tools fail severely on our dataset. As a remedy, we train a dialogue safety classifier to provide a strong baseline for context-sensitive dialogue unsafety detection. With our classifier, we perform safety evaluations on popular conversational models and show that existing dialogue systems still exhibit concerning context-sensitive safety problems.},
	urldate = {2022-05-18},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Sun, Hao and Xu, Guangxuan and Deng, Jiawen and Cheng, Jiale and Zheng, Chujie and Zhou, Hao and Peng, Nanyun and Zhu, Xiaoyan and Huang, Minlie},
	month = may,
	year = {2022},
	pages = {3906--3923},
}

@inproceedings{zhu_continual_2022,
	address = {Dublin, Ireland},
	title = {Continual {Prompt} {Tuning} for {Dialog} {State} {Tracking}},
	url = {https://aclanthology.org/2022.acl-long.80},
	abstract = {A desirable dialog system should be able to continually learn new skills without forgetting old ones, and thereby adapt to new domains or tasks in its life cycle. However, continually training a model often leads to a well-known catastrophic forgetting issue. In this paper, we present Continual Prompt Tuning, a parameter-efficient framework that not only avoids forgetting but also enables knowledge transfer between tasks. To avoid forgetting, we only learn and store a few prompt tokens' embeddings for each task while freezing the backbone pre-trained model. To achieve bi-directional knowledge transfer among tasks, we propose several techniques (continual prompt initialization, query fusion, and memory replay) to transfer knowledge from preceding tasks and a memory-guided technique to transfer knowledge from subsequent tasks. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method on continual learning for dialog state tracking, compared with state-of-the-art baselines.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Zhu, Qi and Li, Bing and Mi, Fei and Zhu, Xiaoyan and Huang, Minlie},
	month = may,
	year = {2022},
	pages = {1124--1137},
}

@inproceedings{zhao_learning-by-narrating_2022,
	address = {Dublin, Ireland},
	title = {Learning-by-{Narrating}: {Narrative} {Pre}-{Training} for {Zero}-{Shot} {Dialogue} {Comprehension}},
	shorttitle = {Learning-by-{Narrating}},
	url = {https://aclanthology.org/2022.acl-short.23},
	abstract = {Comprehending a dialogue requires a model to capture diverse kinds of key information in the utterances, which are either scattered around or implicitly implied in different turns of conversations. Therefore, dialogue comprehension requires diverse capabilities such as paraphrasing, summarizing, and commonsense reasoning. Towards the objective of pre-training a zero-shot dialogue comprehension model, we develop a novel narrative-guided pre-training strategy that learns by narrating the key information from a dialogue input. However, the dialogue-narrative parallel corpus for such a pre-training strategy is currently unavailable. For this reason, we first construct a dialogue-narrative parallel corpus by automatically aligning movie subtitles and their synopses. We then pre-train a BART model on the data and evaluate its performance on four dialogue-based tasks that require comprehension. Experimental results show that our model not only achieves superior zero-shot performance but also exhibits stronger fine-grained dialogue comprehension capabilities. The data and code are available at https://github.com/zhaochaocs/Diana.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Zhao, Chao and Yao, Wenlin and Yu, Dian and Song, Kaiqiang and Yu, Dong and Chen, Jianshu},
	month = may,
	year = {2022},
	pages = {212--218},
}

@inproceedings{liu_where_2022,
	address = {Dublin, Ireland},
	title = {Where to {Go} for the {Holidays}: {Towards} {Mixed}-{Type} {Dialogs} for {Clarification} of {User} {Goals}},
	shorttitle = {Where to {Go} for the {Holidays}},
	url = {https://aclanthology.org/2022.acl-long.73},
	abstract = {Most dialog systems posit that users have figured out clear and specific goals before starting an interaction. For example, users have determined the departure, the destination, and the travel time for booking a flight. However, in many scenarios, limited by experience and knowledge, users may know what they need, but still struggle to figure out clear and specific goals by determining all the necessary slots. In this paper, we identify this challenge, and make a step forward by collecting a new human-to-human mixed-type dialog corpus. It contains 5k dialog sessions and 168k utterances for 4 dialog types and 5 domains. Within each session, an agent first provides user-goal-related knowledge to help figure out clear and specific goals, and then help achieve them. Furthermore, we propose a mixed-type dialog model with a novel Prompt-based continual learning mechanism. Specifically, the mechanism enables the model to continually strengthen its ability on any specific type by utilizing existing dialog corpora effectively.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Zeming and Xu, Jun and Lei, Zeyang and Wang, Haifeng and Niu, Zheng-Yu and Wu, Hua},
	month = may,
	year = {2022},
	pages = {1024--1034},
}

@techreport{weidinger_ethical_2021,
	title = {Ethical and social risks of harm from {Language} {Models}},
	url = {http://arxiv.org/abs/2112.04359},
	abstract = {This paper aims to help structure the risk landscape associated with large-scale Language Models (LMs). In order to foster advances in responsible innovation, an in-depth understanding of the potential risks posed by these models is needed. A wide range of established and anticipated risks are analysed in detail, drawing on multidisciplinary expertise and literature from computer science, linguistics, and social sciences. We outline six specific risk areas: I. Discrimination, Exclusion and Toxicity, II. Information Hazards, III. Misinformation Harms, V. Malicious Uses, V. Human-Computer Interaction Harms, VI. Automation, Access, and Environmental Harms. The first area concerns the perpetuation of stereotypes, unfair discrimination, exclusionary norms, toxic language, and lower performance by social group for LMs. The second focuses on risks from private data leaks or LMs correctly inferring sensitive information. The third addresses risks arising from poor, false or misleading information including in sensitive domains, and knock-on risks such as the erosion of trust in shared information. The fourth considers risks from actors who try to use LMs to cause harm. The fifth focuses on risks specific to LLMs used to underpin conversational agents that interact with human users, including unsafe use, manipulation or deception. The sixth discusses the risk of environmental harm, job automation, and other challenges that may have a disparate effect on different social groups or communities. In total, we review 21 risks in-depth. We discuss the points of origin of different risks and point to potential mitigation approaches. Lastly, we discuss organisational responsibilities in implementing mitigations, and the role of collaboration and participation. We highlight directions for further research, particularly on expanding the toolkit for assessing and evaluating the outlined risks in LMs.},
	number = {arXiv:2112.04359},
	urldate = {2022-05-18},
	institution = {arXiv},
	author = {Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and Kenton, Zac and Brown, Sasha and Hawkins, Will and Stepleton, Tom and Biles, Courtney and Birhane, Abeba and Haas, Julia and Rimell, Laura and Hendricks, Lisa Anne and Isaac, William and Legassick, Sean and Irving, Geoffrey and Gabriel, Iason},
	month = dec,
	year = {2021},
	doi = {10.48550/arXiv.2112.04359},
	note = {arXiv:2112.04359 [cs]
type: article},
}

@inproceedings{das_conversational_2022,
	address = {Dublin, Ireland},
	title = {Conversational {Bots} for {Psychotherapy}: {A} {Study} of {Generative} {Transformer} {Models} {Using} {Domain}-specific {Dialogues}},
	shorttitle = {Conversational {Bots} for {Psychotherapy}},
	url = {https://aclanthology.org/2022.bionlp-1.27},
	abstract = {Conversational bots have become non-traditional methods for therapy among individuals suffering from psychological illnesses. Leveraging deep neural generative language models, we propose a deep trainable neural conversational model for therapy-oriented response generation. We leverage transfer learning methods during training on therapy and counseling based data from Reddit and AlexanderStreet. This was done to adapt existing generative models – GPT2 and DialoGPT – to the task of automated dialog generation. Through quantitative evaluation of the linguistic quality, we observe that the dialog generation model - DialoGPT (345M) with transfer learning on video data attains scores similar to a human response baseline. However, human evaluation of responses by conversational bots show mostly signs of generic advice or information sharing instead of therapeutic interaction.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 21st {Workshop} on {Biomedical} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Das, Avisha and Selek, Salih and Warner, Alia R. and Zuo, Xu and Hu, Yan and Kuttichi Keloth, Vipina and Li, Jianfu and Zheng, W. Jim and Xu, Hua},
	month = may,
	year = {2022},
	pages = {285--297},
}

@inproceedings{mass_conversational_2022,
	address = {Dublin, Ireland},
	title = {Conversational {Search} with {Mixed}-{Initiative} - {Asking} {Good} {Clarification} {Questions} backed-up by {Passage} {Retrieval}},
	url = {https://aclanthology.org/2022.dialdoc-1.7},
	abstract = {We deal with the scenario of conversational search, where user queries are under-specified or ambiguous. This calls for a mixed-initiative setup. User-asks (queries) and system-answers, as well as system-asks (clarification questions) and user response, in order to clarify her information needs. We focus on the task of selecting the next clarification question, given conversation context. Our method leverages passage retrieval from background content to fine-tune two deep-learning models for ranking candidate clarification questions. We evaluated our method on two different use-cases. The first is an open domain conversational search in a large web collection. The second is a task-oriented customer-support setup.We show that our method performs well on both use-cases.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the {Second} {DialDoc} {Workshop} on {Document}-grounded {Dialogue} and {Conversational} {Question} {Answering}},
	publisher = {Association for Computational Linguistics},
	author = {Mass, Yosi and Cohen, Doron and Yehudai, Asaf and Konopnicki, David},
	month = may,
	year = {2022},
	pages = {65--71},
}

@inproceedings{zariquiey_cld_2022,
	address = {Dublin, Ireland},
	title = {{CLD}²: {Language} {Documentation} {Meets} {Natural} {Language} {Processing} for {Revitalising} {Endangered} {Languages}},
	url = {https://aclanthology.org/2022.computel-1.4},
	abstract = {Language revitalisation should not be understood as a direct outcome of language documentation, which is mainly focused on the creation of language repositories. Natural language processing (NLP) offers the potential to complement and exploit these repositories through the development of language technologies that may contribute to improving the vitality status of endangered languages. In this paper, we discuss the current state of the interaction between language documentation and computational linguistics, present a diagnosis of how the outputs of recent documentation projects for endangered languages are underutilised for the NLP community, and discuss how the situation could change from both the documentary linguistics and NLP perspectives. All this is introduced as a bridging paradigm dubbed as Computational Language Documentation and Development (CLD{\textbackslash}mbox\${\textasciicircum}2\$). CLD{\textbackslash}mbox\${\textasciicircum}2\$ calls for (1) the inclusion of NLP-friendly annotated data as a deliverable of future language documentation projects; and (2) the exploitation of language documentation databases by the NLP community to promote the computerization of endangered languages, as one way to contribute to their revitalization.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the {Fifth} {Workshop} on the {Use} of {Computational} {Methods} in the {Study} of {Endangered} {Languages}},
	publisher = {Association for Computational Linguistics},
	author = {Zariquiey, Roberto and Oncevay, Arturo and Vera, Javier},
	month = may,
	year = {2022},
	pages = {20--30},
}

@inproceedings{sundar_multimodal_2022,
	address = {Dublin, Ireland},
	title = {Multimodal {Conversational} {AI}: {A} {Survey} of {Datasets} and {Approaches}},
	shorttitle = {Multimodal {Conversational} {AI}},
	url = {https://aclanthology.org/2022.nlp4convai-1.12},
	abstract = {As humans, we experience the world with all our senses or modalities (sound, sight, touch, smell, and taste). We use these modalities, particularly sight and touch, to convey and interpret specific meanings. Multimodal expressions are central to conversations; a rich set of modalities amplify and often compensate for each other. A multimodal conversational AI system answers questions, fulfills tasks, and emulates human conversations by understanding and expressing itself via multiple modalities. This paper motivates, defines, and mathematically formulates the multimodal conversational research objective. We provide a taxonomy of research required to solve the objective: multimodal representation, fusion, alignment, translation, and co-learning. We survey state-of-the-art datasets and approaches for each research area and highlight their limiting assumptions. Finally, we identify multimodal co-learning as a promising direction for multimodal conversational AI research.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 4th {Workshop} on {NLP} for {Conversational} {AI}},
	publisher = {Association for Computational Linguistics},
	author = {Sundar, Anirudh and Heck, Larry},
	month = may,
	year = {2022},
	pages = {131--147},
}

@inproceedings{pine_requirements_2022,
	address = {Dublin, Ireland},
	title = {Requirements and {Motivations} of {Low}-{Resource} {Speech} {Synthesis} for {Language} {Revitalization}},
	url = {https://aclanthology.org/2022.acl-long.507},
	abstract = {This paper describes the motivation and development of speech synthesis systems for the purposes of language revitalization. By building speech synthesis systems for three Indigenous languages spoken in Canada, Kanien'kéha, Gitksan \& SENĆOŦEN, we re-evaluate the question of how much data is required to build low-resource speech synthesis systems featuring state-of-the-art neural models. For example, preliminary results with English data show that a FastSpeech2 model trained with 1 hour of training data can produce speech with comparable naturalness to a Tacotron2 model trained with 10 hours of data. Finally, we motivate future research in evaluation and classroom integration in the field of speech synthesis for language revitalization.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Pine, Aidan and Wells, Dan and Brinklow, Nathan and Littell, Patrick and Richmond, Korin},
	month = may,
	year = {2022},
	pages = {7346--7359},
}

@inproceedings{ding_globalwoz_2022,
	address = {Dublin, Ireland},
	title = {{GlobalWoZ}: {Globalizing} {MultiWoZ} to {Develop} {Multilingual} {Task}-{Oriented} {Dialogue} {Systems}},
	shorttitle = {{GlobalWoZ}},
	url = {https://aclanthology.org/2022.acl-long.115},
	abstract = {Over the last few years, there has been a move towards data curation for multilingual task-oriented dialogue (ToD) systems that can serve people speaking different languages. However, existing multilingual ToD datasets either have a limited coverage of languages due to the high cost of data curation, or ignore the fact that dialogue entities barely exist in countries speaking these languages. To tackle these limitations, we introduce a novel data curation method that generates GlobalWoZ — a large-scale multilingual ToD dataset globalized from an English ToD dataset for three unexplored use cases of multilingual ToD systems. Our method is based on translating dialogue templates and filling them with local entities in the target-language countries. Besides, we extend the coverage of target languages to 20 languages. We will release our dataset and a set of strong baselines to encourage research on multilingual ToD systems for real use cases.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Ding, Bosheng and Hu, Junjie and Bing, Lidong and Aljunied, Mahani and Joty, Shafiq and Si, Luo and Miao, Chunyan},
	month = may,
	year = {2022},
	pages = {1639--1657},
}

@inproceedings{razumovskaia_data_2022,
	address = {Dublin, Ireland},
	title = {Data {Augmentation} and {Learned} {Layer} {Aggregation} for {Improved} {Multilingual} {Language} {Understanding} in {Dialogue}},
	url = {https://aclanthology.org/2022.findings-acl.160},
	abstract = {Scaling dialogue systems to a multitude of domains, tasks and languages relies on costly and time-consuming data annotation for different domain-task-language configurations. The annotation efforts might be substantially reduced by the methods that generalise well in zero- and few-shot scenarios, and also effectively leverage external unannotated data sources (e.g., Web-scale corpora). We propose two methods to this aim, offering improved dialogue natural language understanding (NLU) across multiple languages: 1) Multi-SentAugment, and 2) LayerAgg. Multi-SentAugment is a self-training method which augments available (typically few-shot) training data with similar (automatically labelled) in-domain sentences from large monolingual Web-scale corpora. LayerAgg learns to select and combine useful semantic information scattered across different layers of a Transformer model (e.g., mBERT); it is especially suited for zero-shot scenarios as semantically richer representations should strengthen the model's cross-lingual capabilities. Applying the two methods with state-of-the-art NLU models obtains consistent improvements across two standard multilingual NLU datasets covering 16 diverse languages. The gains are observed in zero-shot, few-shot, and even in full-data scenarios. The results also suggest that the two methods achieve a synergistic effect: the best overall performance in few-shot setups is attained when the methods are used together.},
	urldate = {2022-05-18},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Razumovskaia, Evgeniia and Vulić, Ivan and Korhonen, Anna},
	month = may,
	year = {2022},
	pages = {2017--2033},
}

@inproceedings{liu_enhancing_2022,
	address = {Dublin, Ireland},
	title = {Enhancing {Documentation} of {Hupa} with {Automatic} {Speech} {Recognition}},
	url = {https://aclanthology.org/2022.computel-1.23},
	abstract = {This study investigates applications of automatic speech recognition (ASR) techniques to Hupa, a critically endangered Native American language from the Dene (Athabaskan) language family. Using around 9h12m of spoken data produced by one elder who is a first-language Hupa speaker, we experimented with different evaluation schemes and training settings. On average a fully connected deep neural network reached a word error rate of 35.26\%. Our overall results illustrate the utility of ASR for making Hupa language documentation more accessible and usable. In addition, we found that when training acoustic models, using recordings with transcripts that were not carefully verified did not necessarily have a negative effect on model performance. This shows promise for speech corpora of indigenous languages that commonly include transcriptions produced by second-language speakers or linguists who have advanced knowledge in the language of interest.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the {Fifth} {Workshop} on the {Use} of {Computational} {Methods} in the {Study} of {Endangered} {Languages}},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Zoey and Spence, Justin and Tucker Prud'hommeaux, Emily},
	month = may,
	year = {2022},
	pages = {187--192},
}

@inproceedings{gessler_closing_2022,
	address = {Dublin, Ireland},
	title = {Closing the {NLP} {Gap} {Documentary} {Linguistics} and {NLP} {Need} a {Shared} {Software} {Infrastructure}},
	url = {https://aclanthology.org/2022.computel-1.15},
	abstract = {For decades, researchers in natural language processing and computational linguistics have been developing models and algorithms that aim to serve the needs of language documentation projects. However, these models have seen little use in language documentation despite their great potential for making documentary linguistic artefacts better and easier to produce. In this work, we argue that a major reason for this NLP gap is the lack of a strong foundation of application software which can on the one hand serve the complex needs of language documentation and on the other hand provide effortless integration with NLP models. We further present and describe a work-in-progress system we have developed to serve this need, Glam.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the {Fifth} {Workshop} on the {Use} of {Computational} {Methods} in the {Study} of {Endangered} {Languages}},
	publisher = {Association for Computational Linguistics},
	author = {Gessler, Luke},
	month = may,
	year = {2022},
	pages = {119--126},
}

@inproceedings{bettinson_learning_2022,
	address = {Dublin, Ireland},
	title = {Learning {Through} {Transcription}},
	url = {https://aclanthology.org/2022.computel-1.11},
	abstract = {Transcribing speech for primarily oral, local languages is often a joint effort involving speakers and outsiders. It is commonly motivated by externally-defined scientific goals, alongside local motivations such as language acquisition and access to heritage materials. We explore the task of `learning through transcription' through the design of a system for collaborative speech annotation. We have developed a prototype to support local and remote learner-speaker interactions in remote Aboriginal communities in northern Australia. We show that situated systems design for inclusive non-expert practice is a promising new direction for working with speakers of local languages.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the {Fifth} {Workshop} on the {Use} of {Computational} {Methods} in the {Study} of {Endangered} {Languages}},
	publisher = {Association for Computational Linguistics},
	author = {Bettinson, Mat and Bird, Steven},
	month = may,
	year = {2022},
	pages = {83--92},
}

@inproceedings{san_automated_2022,
	address = {Dublin, Ireland},
	title = {Automated speech tools for helping communities process restricted-access corpora for language revival efforts},
	url = {https://aclanthology.org/2022.computel-1.6},
	abstract = {Many archival recordings of speech from endangered languages remain unannotated and inaccessible to community members and language learning programs. One bottleneck is the time-intensive nature of annotation. An even narrower bottleneck occurs for recordings with access constraints, such as language that must be vetted or filtered by authorised community members before annotation can begin. We propose a privacy-preserving workflow to widen both bottlenecks for recordings where speech in the endangered language is intermixed with a more widely-used language such as English for meta-linguistic commentary and questions (e.g.What is the word for `tree'?). We integrate voice activity detection (VAD), spoken language identification (SLI), and automatic speech recognition (ASR) to transcribe the metalinguistic content, which an authorised person can quickly scan to triage recordings that can be annotated by people with lower levels of access. We report work-in-progress processing 136 hours archival audio containing a mix of English and Muruwari. Our collaborative work with the Muruwari custodian of the archival materials show that this workflow reduces metalanguage transcription time by 20\% even given only minimal amounts of annotated training data, 10 utterances per language for SLI and for ASR at most 39 minutes, and possibly as little as 39 seconds.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the {Fifth} {Workshop} on the {Use} of {Computational} {Methods} in the {Study} of {Endangered} {Languages}},
	publisher = {Association for Computational Linguistics},
	author = {San, Nay and Bartelds, Martijn and Ogunremi, Tolulope and Mount, Alison and Thompson, Ruben and Higgins, Michael and Barker, Roy and Helen Simpson, Jane and Jurafsky, Dan},
	month = may,
	year = {2022},
	pages = {41--51},
}

@inproceedings{lux_language-agnostic_2022,
	address = {Dublin, Ireland},
	title = {Language-{Agnostic} {Meta}-{Learning} for {Low}-{Resource} {Text}-to-{Speech} with {Articulatory} {Features}},
	url = {https://aclanthology.org/2022.acl-long.472},
	abstract = {While neural text-to-speech systems perform remarkably well in high-resource scenarios, they cannot be applied to the majority of the over 6,000 spoken languages in the world due to a lack of appropriate training data. In this work, we use embeddings derived from articulatory vectors rather than embeddings derived from phoneme identities to learn phoneme representations that hold across languages. In conjunction with language agnostic meta learning, this enables us to fine-tune a high-quality text-to-speech model on just 30 minutes of data in a previously unseen language spoken by a previously unseen speaker.},
	urldate = {2022-05-18},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Lux, Florian and Vu, Thang},
	month = may,
	year = {2022},
	pages = {6858--6868},
}

@article{jokipohja_depictive_2022,
	title = {Depictive {Hand} {Gestures} as {Candidate} {Understandings}},
	issn = {0835-1813, 1532-7973},
	url = {https://www.tandfonline.com/doi/full/10.1080/08351813.2022.2067425},
	doi = {10.1080/08351813.2022.2067425},
	abstract = {This article uses multimodal CA to analyze depictive hand gestures that are used to check understanding of the co-participant’s preceding action. Drawing on data from cooking and farming interactions, the analysis scrutinizes how depic­ tive gestures come to be treated as other-initiations of repair. The analysis shows that relevant factors in this are: (a) the gesture’s design, i.e., its form and move­ ment in relation to the material ecology of the interaction, including relevant objects; (b) the gesture’s position and timing in the unfolding sequence; (c) the embodied participation framework, including the body positions and gaze patterns of all participants; and (d) the participants’ shared knowledge and understanding of the broader activity context, including their familiarity with the ingredients and dishes in-the-making. The analysis contributes to research on gestural depiction in human meaning making and to the study of embodi­ment in repair organization. The data are in Finnish with English translations.},
	language = {en},
	urldate = {2022-05-17},
	journal = {Research on Language and Social Interaction},
	author = {Jokipohja, Anna-Kaisa and Lilja, Niina},
	month = may,
	year = {2022},
	pages = {1--23},
}

@inproceedings{dey_towards_2022,
	address = {Dublin, Ireland},
	title = {Towards {Fair} {Evaluation} of {Dialogue} {State} {Tracking} by {Flexible} {Incorporation} of {Turn}-level {Performances}},
	url = {https://aclanthology.org/2022.acl-short.35},
	abstract = {Dialogue State Tracking (DST) is primarily evaluated using Joint Goal Accuracy (JGA) defined as the fraction of turns where the ground-truth dialogue state exactly matches the prediction. Generally in DST, the dialogue state or belief state for a given turn contain all the intents shown by the user till that turn. Due to this cumulative nature of the belief state, it is difficult to get a correct prediction once a misprediction has occurred. Thus, although being a useful metric, it can be harsh at times and underestimate the true potential of a DST model. Moreover, an improvement in JGA can sometimes decrease the performance of turn-level or non-cumulative belief state prediction due to inconsistency in annotations. So, using JGA as the only metric for model selection may not be ideal for all scenarios. In this work, we discuss various evaluation metrics used for DST along with their shortcomings. To address the existing issues, we propose a new evaluation metric named Flexible Goal Accuracy (FGA). FGA is a generalized version of JGA. But unlike JGA, it tries to give penalized rewards to mispredictions that are locally correct i.e. the root cause of the error is an earlier turn. By doing so, FGA considers the performance of both cumulative and turn-level prediction flexibly and provides a better insight than the existing metrics. We also show that FGA is a better discriminator of DST model performance.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Dey, Suvodip and Kummara, Ramamohan and Desarkar, Maunendra},
	month = may,
	year = {2022},
	pages = {318--324},
}

@inproceedings{zhao_unids_2022,
	address = {Dublin, Ireland},
	title = {{UniDS}: {A} {Unified} {Dialogue} {System} for {Chit}-{Chat} and {Task}-oriented {Dialogues}},
	shorttitle = {{UniDS}},
	url = {https://aclanthology.org/2022.dialdoc-1.2},
	abstract = {With the advances in deep learning, tremendous progress has been made with chit-chat dialogue systems and task-oriented dialogue systems. However, these two systems are often tackled separately in current methods. To achieve more natural interaction with humans, dialogue systems need to be capable of both chatting and accomplishing tasks. To this end, we propose a unified dialogue system (UniDS) with the two aforementioned skills. In particular, we design a unified dialogue data schema, compatible for both chit-chat and task-oriented dialogues. Besides, we propose a two-stage training method to train UniDS based on the unified dialogue data schema. UniDS does not need to adding extra parameters to existing chit-chat dialogue systems. Experimental results demonstrate that the proposed UniDS works comparably well as the state-of-the-art chit-chat dialogue systems and task-oriented dialogue systems. More importantly, UniDS achieves better robustness than pure dialogue systems and satisfactory switch ability between two types of dialogues.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the {Second} {DialDoc} {Workshop} on {Document}-grounded {Dialogue} and {Conversational} {Question} {Answering}},
	publisher = {Association for Computational Linguistics},
	author = {Zhao, Xinyan and He, Bin and Wang, Yasheng and Li, Yitong and Mi, Fei and Liu, Yajiao and Jiang, Xin and Liu, Qun and Chen, Huanhuan},
	month = may,
	year = {2022},
	pages = {13--22},
}

@inproceedings{li_conversation-_2022,
	address = {Dublin, Ireland},
	title = {Conversation- and {Tree}-{Structure} {Losses} for {Dialogue} {Disentanglement}},
	url = {https://aclanthology.org/2022.dialdoc-1.6},
	abstract = {When multiple conversations occur simultaneously, a listener must decide which conversation each utterance is part of in order to interpret and respond to it appropriately. This task is referred as dialogue disentanglement. A significant drawback of previous studies on disentanglement lies in that they only focus on pair-wise relationships between utterances while neglecting the conversation structure which is important for conversation structure modeling. In this paper, we propose a hierarchical model, named Dialogue BERT (DIALBERT), which integrates the local and global semantics in the context range by using BERT to encode each message-pair and using BiLSTM to aggregate the chronological context information into the output of BERT. In order to integrate the conversation structure information into the model, two types of loss of conversation-structure loss and tree-structure loss are designed. In this way, our model can implicitly learn and leverage the conversation structures without being restricted to the lack of explicit access to such structures during the inference stage. Experimental results on two large datasets show that our method outperforms previous methods by substantial margins, achieving great performance on dialogue disentanglement.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the {Second} {DialDoc} {Workshop} on {Document}-grounded {Dialogue} and {Conversational} {Question} {Answering}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Tianda and Gu, Jia-Chen and Ling, Zhen-Hua and Liu, Quan},
	month = may,
	year = {2022},
	pages = {54--64},
}

@inproceedings{luu_towards_2022,
	address = {Dublin, Ireland},
	title = {Towards {Human} {Evaluation} of {Mutual} {Understanding} in {Human}-{Computer} {Spontaneous} {Conversation}: {An} {Empirical} {Study} of {Word} {Sense} {Disambiguation} for {Naturalistic} {Social} {Dialogs} in {American} {English}},
	shorttitle = {Towards {Human} {Evaluation} of {Mutual} {Understanding} in {Human}-{Computer} {Spontaneous} {Conversation}},
	url = {https://aclanthology.org/2022.humeval-1.10},
	abstract = {Current evaluation practices for social dialog systems, dedicated to human-computer spontaneous conversation, exclusively focus on the quality of system-generated surface text, but not human-verifiable aspects of mutual understanding between the systems and their interlocutors. This work proposes Word Sense Disambiguation (WSD) as an essential component of a valid and reliable human evaluation framework, whose long-term goal is to radically improve the usability of dialog systems in real-life human-computer collaboration. The practicality of this proposal is proved via experimentally investigating (1) the WordNet 3.0 sense inventory coverage of lexical meanings in spontaneous conversation between humans in American English, assumed as an upper bound of lexical diversity of human-computer communication, and (2) the effectiveness of state-of-the-art WSD models and pretrained transformer-based contextual embeddings on this type of data.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 2nd {Workshop} on {Human} {Evaluation} of {NLP} {Systems} ({HumEval})},
	publisher = {Association for Computational Linguistics},
	author = {Lưu, Alex},
	month = may,
	year = {2022},
	pages = {116--125},
}

@inproceedings{kumar_empirical_2022,
	address = {Dublin, Ireland},
	title = {An {Empirical} study to understand the {Compositional} {Prowess} of {Neural} {Dialog} {Models}},
	url = {https://aclanthology.org/2022.insights-1.21},
	abstract = {In this work, we examine the problems associated with neural dialog models under the common theme of compositionality. Specifically, we investigate three manifestations of compositionality: (1) Productivity, (2) Substitutivity, and (3) Systematicity. These manifestations shed light on the generalization, syntactic robustness, and semantic capabilities of neural dialog models. We design probing experiments by perturbing the training data to study the above phenomenon. We make informative observations based on automated metrics and hope that this work increases research interest in understanding the capacity of these models.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the {Third} {Workshop} on {Insights} from {Negative} {Results} in {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Kumar, Vinayshekhar and Kumar, Vaibhav and Bhutani, Mukul and Rudnicky, Alexander},
	month = may,
	year = {2022},
	pages = {154--158},
}

@inproceedings{smith_human_2022,
	address = {Dublin, Ireland},
	title = {Human {Evaluation} of {Conversations} is an {Open} {Problem}: comparing the sensitivity of various methods for evaluating dialogue agents},
	shorttitle = {Human {Evaluation} of {Conversations} is an {Open} {Problem}},
	url = {https://aclanthology.org/2022.nlp4convai-1.8},
	abstract = {At the heart of improving conversational AI is the open problem of how to evaluate conversations. Issues with automatic metrics are well known (Liu et al., 2016), with human evaluations still considered the gold standard. Unfortunately, how to perform human evaluations is also an open problem: differing data collection methods have varying levels of human agreement and statistical sensitivity, resulting in differing amounts of human annotation hours and labor costs. In this work we compare five different crowdworker-based human evaluation methods and find that different methods are best depending on the types of models compared, with no clear winner across the board. While this highlights the open problems in the area, our analysis leads to advice of when to use which one, and possible future directions.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 4th {Workshop} on {NLP} for {Conversational} {AI}},
	publisher = {Association for Computational Linguistics},
	author = {Smith, Eric and Hsu, Orion and Qian, Rebecca and Roller, Stephen and Boureau, Y-Lan and Weston, Jason},
	month = may,
	year = {2022},
	pages = {77--97},
}

@inproceedings{kann_open-domain_2022,
	address = {Dublin, Ireland},
	title = {Open-domain {Dialogue} {Generation}: {What} {We} {Can} {Do}, {Cannot} {Do}, {And} {Should} {Do} {Next}},
	shorttitle = {Open-domain {Dialogue} {Generation}},
	url = {https://aclanthology.org/2022.nlp4convai-1.13},
	abstract = {Human–computer conversation has long been an interest of artificial intelligence and natural language processing research. Recent years have seen a dramatic improvement in quality for both task-oriented and open-domain dialogue systems, and an increasing amount of research in the area. The goal of this work is threefold: (1) to provide an overview of recent advances in the field of open-domain dialogue, (2) to summarize issues related to ethics, bias, and fairness that the field has identified as well as typical errors of dialogue systems, and (3) to outline important future challenges. We hope that this work will be of interest to both new and experienced researchers in the area.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 4th {Workshop} on {NLP} for {Conversational} {AI}},
	publisher = {Association for Computational Linguistics},
	author = {Kann, Katharina and Ebrahimi, Abteen and Koh, Joewie and Dudy, Shiran and Roncone, Alessandro},
	month = may,
	year = {2022},
	pages = {148--165},
}

@inproceedings{chiu_salesbot_2022,
	address = {Dublin, Ireland},
	title = {{SalesBot}: {Transitioning} from {Chit}-{Chat} to {Task}-{Oriented} {Dialogues}},
	shorttitle = {{SalesBot}},
	url = {https://aclanthology.org/2022.acl-long.425},
	abstract = {Dialogue systems are usually categorized into two types, open-domain and task-oriented. The first one focuses on chatting with users and making them engage in the conversations, where selecting a proper topic to fit the dialogue context is essential for a successful dialogue. The other one focuses on a specific task instead of casual talks, e.g., finding a movie on Friday night, playing a song. These two directions have been studied separately due to their different purposes. However, how to smoothly transition from social chatting to task-oriented dialogues is important for triggering the business opportunities, and there is no any public data focusing on such scenarios. Hence, this paper focuses on investigating the conversations starting from open-domain social chatting and then gradually transitioning to task-oriented purposes, and releases a large-scale dataset with detailed annotations for encouraging this research direction. To achieve this goal, this paper proposes a framework to automatically generate many dialogues without human involvement, in which any powerful open-domain dialogue generation model can be easily leveraged. The human evaluation shows that our generated dialogue data has a natural flow at a reasonable quality, showing that our released data has a great potential of guiding future research directions and commercial activities. Furthermore, the released models allow researchers to automatically generate unlimited dialogues in the target scenarios, which can greatly benefit semi-supervised and unsupervised approaches.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chiu, Ssu and Li, Maolin and Lin, Yen-Ting and Chen, Yun-Nung},
	month = may,
	year = {2022},
	pages = {6143--6158},
}

@inproceedings{arora_estimating_2022,
	address = {Dublin, Ireland},
	title = {Estimating the {Entropy} of {Linguistic} {Distributions}},
	url = {https://aclanthology.org/2022.acl-short.20},
	abstract = {Shannon entropy is often a quantity of interest to linguists studying the communicative capacity of human language. However, entropymust typically be estimated from observed data because researchers do not have access to the underlying probability distribution. While entropy estimation is a well-studied problem in other fields, there is not yet a comprehensive exploration of the efficacy of entropy estimators for use with linguistic data. In this work, we fill this void, studying the empirical effectiveness of different entropy estimators for linguistic distributions. In a replication of two recent information-theoretic linguistic studies, we find evidence that the reported effect size is over-estimated due to over-reliance on poor entropy estimators. We end this paper with a concrete recommendation for the entropy estimators that should be used in future linguistic studies.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Arora, Aryaman and Meister, Clara and Cotterell, Ryan},
	month = may,
	year = {2022},
	pages = {175--195},
}

@inproceedings{qian_flexible_2022,
	address = {Dublin, Ireland},
	title = {Flexible {Generation} from {Fragmentary} {Linguistic} {Input}},
	url = {https://aclanthology.org/2022.acl-long.563},
	abstract = {The dominant paradigm for high-performance models in novel NLP tasks today is direct specialization for the task via training from scratch or fine-tuning large pre-trained models. But does direct specialization capture how humans approach novel language tasks? We hypothesize that human performance is better characterized by flexible inference through composition of basic computational motifs available to the human language user. To test this hypothesis, we formulate a set of novel fragmentary text completion tasks, and compare the behavior of three direct-specialization models against a new model we introduce, GibbsComplete, which composes two basic computational motifs central to contemporary models: masked and autoregressive word prediction. We conduct three types of evaluation: human judgments of completion quality, satisfaction of syntactic constraints imposed by the input fragment, and similarity to human behavior in the structural statistics of the completions. With no task-specific parameter tuning, GibbsComplete performs comparably to direct-specialization models in the first two evaluations, and outperforms all direct-specialization models in the third evaluation. These results support our hypothesis that human behavior in novel language tasks and environments may be better characterized by flexible composition of basic computational motifs rather than by direct specialization.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Qian, Peng and Levy, Roger},
	month = may,
	year = {2022},
	pages = {8176--8196},
}

@inproceedings{arora_computational_2022,
	address = {Dublin, Ireland},
	title = {Computational {Historical} {Linguistics} and {Language} {Diversity} in {South} {Asia}},
	url = {https://aclanthology.org/2022.acl-long.99},
	abstract = {South Asia is home to a plethora of languages, many of which severely lack access to new language technologies. This linguistic diversity also results in a research environment conducive to the study of comparative, contact, and historical linguistics–fields which necessitate the gathering of extensive data from many languages. We claim that data scatteredness (rather than scarcity) is the primary obstacle in the development of South Asian language technology, and suggest that the study of language history is uniquely aligned with surmounting this obstacle. We review recent developments in and at the intersection of South Asian NLP and historical-comparative linguistics, describing our and others' current efforts in this area. We also offer new strategies towards breaking the data barrier.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Arora, Aryaman and Farris, Adam and Basu, Samopriya and Kolichala, Suresh},
	month = may,
	year = {2022},
	pages = {1396--1409},
}

@inproceedings{deriu_probing_2022,
	address = {Dublin, Ireland},
	title = {Probing the {Robustness} of {Trained} {Metrics} for {Conversational} {Dialogue} {Systems}},
	url = {https://aclanthology.org/2022.acl-short.85},
	abstract = {This paper introduces an adversarial method to stress-test trained metrics for the evaluation of conversational dialogue systems. The method leverages Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics. We apply our method to test recently proposed trained metrics. We find that they all are susceptible to giving high scores to responses generated by rather simple and obviously flawed strategies that our method converges on. For instance, simply copying parts of the conversation context to form a response yields competitive scores or even outperforms responses written by humans.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Deriu, Jan and Tuggener, Don and Von Däniken, Pius and Cieliebak, Mark},
	month = may,
	year = {2022},
	pages = {750--761},
}

@inproceedings{ung_saferdialogues_2022,
	address = {Dublin, Ireland},
	title = {{SaFeRDialogues}: {Taking} {Feedback} {Gracefully} after {Conversational} {Safety} {Failures}},
	shorttitle = {{SaFeRDialogues}},
	url = {https://aclanthology.org/2022.acl-long.447},
	abstract = {Current open-domain conversational models can easily be made to talk in inadequate ways. Online learning from conversational feedback given by the conversation partner is a promising avenue for a model to improve and adapt, so as to generate fewer of these safety failures. However, current state-of-the-art models tend to react to feedback with defensive or oblivious responses. This makes for an unpleasant experience and may discourage conversation partners from giving feedback in the future. This work proposes SaFeRDialogues, a task and dataset of graceful responses to conversational feedback about safety failures.We collect a dataset of 8k dialogues demonstrating safety failures, feedback signaling them, and a response acknowledging the feedback. We show how fine-tuning on this dataset results in conversations that human raters deem considerably more likely to lead to a civil conversation, without sacrificing engagingness or general conversational ability.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Ung, Megan and Xu, Jing and Boureau, Y-Lan},
	month = may,
	year = {2022},
	pages = {6462--6481},
}

@inproceedings{dinan_safetykit_2022,
	address = {Dublin, Ireland},
	title = {{SafetyKit}: {First} {Aid} for {Measuring} {Safety} in {Open}-domain {Conversational} {Systems}},
	shorttitle = {{SafetyKit}},
	url = {https://aclanthology.org/2022.acl-long.284},
	abstract = {The social impact of natural language processing and its applications has received increasing attention. In this position paper, we focus on the problem of safety for end-to-end conversational AI. We survey the problem landscape therein, introducing a taxonomy of three observed phenomena: the Instigator, Yea-Sayer, and Impostor effects. We then empirically assess the extent to which current tools can measure these effects and current systems display them. We release these tools as part of a “first aid kit” (SafetyKit) to quickly assess apparent safety concerns. Our results show that, while current tools are able to provide an estimate of the relative safety of systems in various settings, they still have several shortcomings. We suggest several future directions and discuss ethical considerations.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Dinan, Emily and Abercrombie, Gavin and Bergman, A. and Spruit, Shannon and Hovy, Dirk and Boureau, Y-Lan and Rieser, Verena},
	month = may,
	year = {2022},
	pages = {4113--4133},
}

@inproceedings{liu_prophetchat_2022,
	address = {Dublin, Ireland},
	title = {{ProphetChat}: {Enhancing} {Dialogue} {Generation} with {Simulation} of {Future} {Conversation}},
	shorttitle = {{ProphetChat}},
	url = {https://aclanthology.org/2022.acl-long.68},
	abstract = {Typical generative dialogue models utilize the dialogue history to generate the response. However, since one dialogue utterance can often be appropriately answered by multiple distinct responses, generating a desired response solely based on the historical information is not easy. Intuitively, if the chatbot can foresee in advance what the user would talk about (i.e., the dialogue future) after receiving its response, it could possibly provide a more informative response. Accordingly, we propose a novel dialogue generation framework named ProphetChat that utilizes the simulated dialogue futures in the inference phase to enhance response generation. To enable the chatbot to foresee the dialogue future, we design a beam-search-like roll-out strategy for dialogue future simulation using a typical dialogue generation model and a dialogue selector. With the simulated futures, we then utilize the ensemble of a history-to-response generator and a future-to-response generator to jointly generate a more informative response. Experiments on two popular open-domain dialogue datasets demonstrate that ProphetChat can generate better responses over strong baselines, which validates the advantages of incorporating the simulated dialogue futures.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Chang and Tan, Xu and Tao, Chongyang and Fu, Zhenxin and Zhao, Dongyan and Liu, Tie-Yan and Yan, Rui},
	month = may,
	year = {2022},
	pages = {962--973},
}

@article{brown_maps_2005,
	title = {Maps and {Journeys}: {An} {Ethno}-methodological {Investigation}},
	volume = {40},
	issn = {0317-7173},
	shorttitle = {Maps and {Journeys}},
	url = {https://www.utpjournals.press/doi/abs/10.3138/6QPX-0V10-24R0-0621},
	doi = {10.3138/6QPX-0V10-24R0-0621},
	abstract = {The notion of the “cognitive map” has long been central to studies of maps, wayfinding, and navigation. In this article we provide an alternative approach to studying map use that re-situates these activities as shared social and cultural practices. The article draws on ethno-methodology and conversation analysis to study video of two examples of naturally organized map reading. We explore how journeying with maps is part of the in situ organization of matters such as workplace tasks, means of transportation, having a “nice day out,” maintaining friendships, and so on. In our first clip, a saleswoman consults an A–Z map while stopped at traffic lights in order to plan the journey ahead. In the second clip, a group of friends consult a map as they set off for a day trip together in a car. These clips provide thick descriptions of the detailed activities involved in map use.},
	number = {3},
	urldate = {2022-04-25},
	journal = {Cartographica: The International Journal for Geographic Information and Geovisualization},
	author = {Brown, Barry and Laurier, Eric},
	month = sep,
	year = {2005},
	note = {Publisher: University of Toronto Press},
	pages = {17--33},
}

@article{eric_laurier_what_2012,
	title = {What it means to change lanes: {Actions}, emotions and wayfinding in the family car},
	volume = {2012},
	issn = {1613-3692},
	shorttitle = {What it means to change lanes},
	url = {https://www.degruyter.com/document/doi/10.1515/sem-2012-0058/html},
	doi = {10.1515/sem-2012-0058},
	abstract = {In this paper we investigate how the sequential organization and settlement of disagreements comes to shape, and be shaped by, navigation. Using extracts of in-car interaction, we examine the gestalt of projectable aspects of road travel, car movements, and driver-navigator talk. Navigation when accomplished without maps relies on making sense of streets, landmarks, and signs, activities that are displayed through passengers and drivers giving directions to each other, alongside embodied references to passing roadside features and the movement of the vehicle. More broadly, “finding the way” is bound up with the social relationships between passengers — in particular families caring for one another and showing their epistemic and emotional stance on particular matters. To examine this we draw on existing conversation analytic work on epistemics, stance, and emotion to explore the potentially argumentative character of direction-giving and direction-receiving and how this comes to be combined with the task at hand.},
	language = {en},
	number = {191},
	urldate = {2022-04-25},
	journal = {Semiotica},
	author = {Eric Laurier and Barry Brown and Lorimer Hayden},
	month = aug,
	year = {2012},
	note = {Publisher: De Gruyter Mouton},
	pages = {117--135},
}

@article{scharenborg_reaching_2007,
	series = {Bridging the {Gap} between {Human} and {Automatic} {Speech} {Recognition}},
	title = {Reaching over the gap: {A} review of efforts to link human and automatic speech recognition research},
	volume = {49},
	issn = {0167-6393},
	shorttitle = {Reaching over the gap},
	url = {https://www.sciencedirect.com/science/article/pii/S0167639307000106},
	doi = {10.1016/j.specom.2007.01.009},
	abstract = {The fields of human speech recognition (HSR) and automatic speech recognition (ASR) both investigate parts of the speech recognition process and have word recognition as their central issue. Although the research fields appear closely related, their aims and research methods are quite different. Despite these differences there is, however, lately a growing interest in possible cross-fertilisation. Researchers from both ASR and HSR are realising the potential benefit of looking at the research field on the other side of the ‘gap’. In this paper, we provide an overview of past and present efforts to link human and automatic speech recognition research and present an overview of the literature describing the performance difference between machines and human listeners. The focus of the paper is on the mutual benefits to be derived from establishing closer collaborations and knowledge interchange between ASR and HSR. The paper ends with an argument for more and closer collaborations between researchers of ASR and HSR to further improve research in both fields.},
	language = {en},
	number = {5},
	urldate = {2022-05-16},
	journal = {Speech Communication},
	author = {Scharenborg, Odette},
	month = may,
	year = {2007},
	pages = {336--347},
}

@article{scharenborg_modeling_2010,
	title = {Modeling the use of durational information in human spoken-word recognition},
	volume = {127},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.3377050},
	doi = {10.1121/1.3377050},
	number = {6},
	urldate = {2022-05-16},
	journal = {The Journal of the Acoustical Society of America},
	author = {Scharenborg, Odette},
	month = jun,
	year = {2010},
	note = {Publisher: Acoustical Society of America},
	pages = {3758--3770},
}

@inproceedings{marchal_semi-automatic_2021,
	address = {Punta Cana, Dominican Republic and Online},
	title = {Semi-automatic discourse annotation in a low-resource language: {Developing} a connective lexicon for {Nigerian} {Pidgin}},
	shorttitle = {Semi-automatic discourse annotation in a low-resource language},
	url = {https://aclanthology.org/2021.codi-main.8},
	doi = {10.18653/v1/2021.codi-main.8},
	abstract = {Cross-linguistic research on discourse structure and coherence marking requires discourse-annotated corpora and connective lexicons in a large number of languages. However, the availability of such resources is limited, especially for languages for which linguistic resources are scarce in general, such as Nigerian Pidgin. In this study, we demonstrate how a semi-automatic approach can be used to source connectives and their relation senses and develop a discourse-annotated corpus in a low-resource language. Connectives and their relation senses were extracted from a parallel corpus combining automatic (PDTB end-to-end parser) and manual annotations. This resulted in Naija-Lex, a lexicon of discourse connectives in Nigerian Pidgin with English translations. The lexicon shows that the majority of Nigerian Pidgin connectives are borrowed from its English lexifier, but that there are also some connectives that are unique to Nigerian Pidgin.},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 2nd {Workshop} on {Computational} {Approaches} to {Discourse}},
	publisher = {Association for Computational Linguistics},
	author = {Marchal, Marian and Scholman, Merel and Demberg, Vera},
	month = nov,
	year = {2021},
	pages = {84--94},
}

@techreport{majewska_cross-lingual_2022,
	title = {Cross-{Lingual} {Dialogue} {Dataset} {Creation} via {Outline}-{Based} {Generation}},
	url = {http://arxiv.org/abs/2201.13405},
	abstract = {Multilingual task-oriented dialogue (ToD) facilitates access to services and information for many (communities of) speakers. Nevertheless, the potential of this technology is not fully realised, as current datasets for multilingual ToD - both for modular and end-to-end modelling - suffer from severe limitations. 1) When created from scratch, they are usually small in scale and fail to cover many possible dialogue flows. 2) Translation-based ToD datasets might lack naturalness and cultural specificity in the target language. In this work, to tackle these limitations we propose a novel outline-based annotation process for multilingual ToD datasets, where domain-specific abstract schemata of dialogue are mapped into natural language outlines. These in turn guide the target language annotators in writing a dialogue by providing instructions about each turn's intents and slots. Through this process we annotate a new large-scale dataset for training and evaluation of multilingual and cross-lingual ToD systems. Our Cross-lingual Outline-based Dialogue dataset (termed COD) enables natural language understanding, dialogue state tracking, and end-to-end dialogue modelling and evaluation in 4 diverse languages: Arabic, Indonesian, Russian, and Kiswahili. Qualitative and quantitative analyses of COD versus an equivalent translation-based dataset demonstrate improvements in data quality, unlocked by the outline-based approach. Finally, we benchmark a series of state-of-the-art systems for cross-lingual ToD, setting reference scores for future work and demonstrating that COD prevents over-inflated performance, typically met with prior translation-based ToD datasets.},
	number = {arXiv:2201.13405},
	urldate = {2022-05-13},
	institution = {arXiv},
	author = {Majewska, Olga and Razumovskaia, Evgeniia and Ponti, Edoardo Maria and Vulić, Ivan and Korhonen, Anna},
	month = jan,
	year = {2022},
	doi = {10.48550/arXiv.2201.13405},
	note = {arXiv:2201.13405 [cs]
type: article},
}

@article{shriberg_prosody-based_2000,
	series = {Accessing {Information} in {Spoken} {Audio}},
	title = {Prosody-based automatic segmentation of speech into sentences and topics},
	volume = {32},
	issn = {0167-6393},
	url = {https://www.sciencedirect.com/science/article/pii/S0167639300000285},
	doi = {10.1016/S0167-6393(00)00028-5},
	abstract = {A crucial step in processing speech audio data for information extraction, topic detection, or browsing/playback is to segment the input into sentence and topic units. Speech segmentation is challenging, since the cues typically present for segmenting text (headers, paragraphs, punctuation) are absent in spoken language. We investigate the use of prosody (information gleaned from the timing and melody of speech) for these tasks. Using decision tree and hidden Markov modeling techniques, we combine prosodic cues with word-based approaches, and evaluate performance on two speech corpora, Broadcast News and Switchboard. Results show that the prosodic model alone performs on par with, or better than, word-based statistical language models – for both true and automatically recognized words in news speech. The prosodic model achieves comparable performance with significantly less training data, and requires no hand-labeling of prosodic events. Across tasks and corpora, we obtain a significant improvement over word-only models using a probabilistic combination of prosodic and lexical information. Inspection reveals that the prosodic models capture language-independent boundary indicators described in the literature. Finally, cue usage is task and corpus dependent. For example, pause and pitch features are highly informative for segmenting news speech, whereas pause, duration and word-based cues dominate for natural conversation.
Zusammenfassung
Ein wesentlicher Schritt in der Sprachverarbeitung zum Zweck der Informationsextrahierung, Themenklassifizierung oder Wiedergabe ist die Segmentierung in thematische und Satzeinheiten. Sprachsegmentierung ist schwierig, da die Hinweise, die dafür gewöhnlich in Texten vorzufinden sind (Überschriften, Absätze, Interpunktion), in gesprochener Sprache fehlen. Wir untersuchen die Benutzung von Prosodie (Timing und Melodie der Sprache) zu diesem Zweck. Mithilfe von Entscheidungsbäumen und Hidden-Markov-Modellen kombinieren wir prosodische und wortbasierte Informationen, und prüfen unsere Verfahren anhand von zwei Sprachkorpora, Broadcast News und Switchboard. Sowohl bei korrekten, als auch bei automatisch erkannten Worttranskriptionen von Broadcast News zeigen unsere Ergebnisse, daß Prosodiemodelle alleine eine gleichgute oder bessere Leistung als die wortbasieren statistischen Sprachmodelle erbringen. Dabei erzielt das Prosodiemodell eine vergleichbare Leistung mit wesentlich weniger Trainingsdaten und bedarf keines manuellen Transkribierens prosodischer Eigenschaften. Für beide Segmentierungsarten und Korpora erzielen wir eine signifikante Verbesserung gegenüber rein wortbasierten Modellen, indem wir prosodische und lexikalische Informationsquellen probabilistisch kombinieren. Eine Untersuchung der Prosodiemodelle zeigt, daß diese auf sprachunabhängige, in der Literatur beschriebene Segmentierungsmerkmale ansprechen. Die Auswahl der Merkmale hängt wesentlich von Segmentierungstyp und Korpus ab. Zum Beispiel sind Pausen und F0-Merkmale vor allem für Nachrichtensprache informativ, während zeitdauer- und wortbasierte Merkmale in natürlichen Gesprächen dominieren.
Résumé
Une étape cruciale dans le traitement de la parole pour l'extraction d'information, la détection du sujet de conversation et la navigation est la segmentation du discours. Celle-ci est difficile car les indices aidant à segmenter un texte (en-têtes, paragraphes, ponctuation) n'apparaissent pas dans le language parlé. Nous étudions l'usage de la prosodie (l'information extraite du rythme et de la mélodie de la parole) à cet effet. A l'aide d'arbres de décision et de chaı̂nes de Markov cachées, nous combinons les indices prosodiques avec le modèle du langage. Nous evaluons notre algorithme sur deux corpora, Broadcast News et Switchboard. Nos résultats indiquent que le modèle prosodique est équivalent ou supérieur au modèle du langage, et qu'il requiert moins de données d'entraı̂nement. Il ne nécessite pas d'annotations manuelles de la prosodie. De plus, nous obtenons un gain significatif en combinant de manière probabiliste l'information prosodique et lexicale, et ce pour différents corpora et applications. Une inspection plus détaillée des résultats révèle que les modèles prosodiques identifient les indicateurs de début et de fin de segments, tel que décrit dans la littérature. Finalement, l'usage des indices prosodiques dépend de l'application et du corpus. Par exemple, le ton s'avère extrèmement utile pour la segmentation des bulletins télévisés, alors que les caracteristiques de durée et celles extraites du modèle du langage servent davantage pour la segmentation de conversations naturelles.},
	language = {en},
	number = {1},
	urldate = {2022-05-13},
	journal = {Speech Communication},
	author = {Shriberg, Elizabeth and Stolcke, Andreas and Hakkani-Tür, Dilek and Tür, Gökhan},
	month = sep,
	year = {2000},
	pages = {127--154},
}

@article{stolcke_dialogue_2000,
	title = {Dialogue {Act} {Modeling} for {Automatic} {Tagging} and {Recognition} of {Conversational} {Speech}},
	volume = {26},
	issn = {0891-2017},
	url = {https://doi.org/10.1162/089120100561737},
	doi = {10.1162/089120100561737},
	abstract = {We describe a statistical approach for modeling dialogue acts in conversational speech, i.e., speech-act-like units such as STATEMENT, Question, BACKCHANNEL, Agreement, Disagreement, and Apology. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. The statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act. We develop a probabilistic integration of speech recognition with dialogue modeling, to improve both speech recognition and dialogue act classification accuracy. Models are trained and evaluated using a large hand-labeled database of 1,155 conversations from the Switchboard corpus of spontaneous human-to-human telephone speech. We achieved good dialogue act labeling accuracy (65\% based on errorful, automatically recognized words and prosody, and 71\% based on word transcripts, compared to a chance baseline accuracy of 35\% and human accuracy of 84\%) and a small reduction in word recognition error.},
	number = {3},
	urldate = {2022-05-13},
	journal = {Computational Linguistics},
	author = {Stolcke, Andreas and Ries, Klaus and Coccaro, Noah and Shriberg, Elizabeth and Bates, Rebecca and Jurafsky, Daniel and Taylor, Paul and Martin, Rachel and Ess-Dykema, Carol Van and Meteer, Marie},
	month = sep,
	year = {2000},
	pages = {339--373},
}

@patent{baldwin_system_2022,
	title = {System and method for a cooperative conversational voice user interface},
	url = {https://patents.google.com/patent/US11222626B2/en},
	nationality = {US},
	language = {en},
	assignee = {VB Assets LLC},
	number = {US11222626B2},
	urldate = {2022-05-13},
	author = {Baldwin, Larry and Freeman, Tom and Tjalve, Michael and Ebersold, Blane and Weider, Chris},
	month = jan,
	year = {2022},
}

@article{hovy_text_2020,
	title = {Text {Analysis} in {Python} for {Social} {Scientists}: {Discovery} and {Exploration}},
	shorttitle = {Text {Analysis} in {Python} for {Social} {Scientists}},
	url = {https://www.cambridge.org/core/elements/text-analysis-in-python-for-social-scientists/BFAB0A3604C7E29F6198EA2F7941DFF3},
	doi = {10.1017/9781108873352},
	abstract = {Cambridge Core - Political Theory - Text Analysis in Python for Social Scientists},
	language = {en},
	urldate = {2022-05-13},
	journal = {Elements in Quantitative and Computational Methods for the Social Sciences},
	author = {Hovy, Dirk},
	month = dec,
	year = {2020},
	note = {ISBN: 9781108873352 9781108819824
Publisher: Cambridge University Press},
}

@techreport{rottger_two_2022,
	title = {Two {Contrasting} {Data} {Annotation} {Paradigms} for {Subjective} {NLP} {Tasks}},
	url = {http://arxiv.org/abs/2112.07475},
	abstract = {Labelled data is the foundation of most natural language processing tasks. However, labelling data is difficult and there often are diverse valid beliefs about what the correct data labels should be. So far, dataset creators have acknowledged annotator subjectivity, but rarely actively managed it in the annotation process. This has led to partly-subjective datasets that fail to serve a clear downstream use. To address this issue, we propose two contrasting paradigms for data annotation. The descriptive paradigm encourages annotator subjectivity, whereas the prescriptive paradigm discourages it. Descriptive annotation allows for the surveying and modelling of different beliefs, whereas prescriptive annotation enables the training of models that consistently apply one belief. We discuss benefits and challenges in implementing both paradigms, and argue that dataset creators should explicitly aim for one or the other to facilitate the intended use of their dataset. Lastly, we conduct an annotation experiment using hate speech data that illustrates the contrast between the two paradigms.},
	number = {arXiv:2112.07475},
	urldate = {2022-05-13},
	institution = {arXiv},
	author = {Röttger, Paul and Vidgen, Bertie and Hovy, Dirk and Pierrehumbert, Janet B.},
	month = apr,
	year = {2022},
	doi = {10.48550/arXiv.2112.07475},
	note = {arXiv:2112.07475 [cs]
type: article},
}

@inproceedings{hovy_you_2020,
	address = {Online},
	title = {“{You} {Sound} {Just} {Like} {Your} {Father}” {Commercial} {Machine} {Translation} {Systems} {Include} {Stylistic} {Biases}},
	url = {https://aclanthology.org/2020.acl-main.154},
	doi = {10.18653/v1/2020.acl-main.154},
	abstract = {The main goal of machine translation has been to convey the correct content. Stylistic considerations have been at best secondary. We show that as a consequence, the output of three commercial machine translation systems (Bing, DeepL, Google) make demographically diverse samples from five languages “sound” older and more male than the original. Our findings suggest that translation models reflect demographic bias in the training data. This opens up interesting new research avenues in machine translation to take stylistic considerations into account.},
	urldate = {2022-05-13},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Hovy, Dirk and Bianchi, Federico and Fornaciari, Tommaso},
	month = jul,
	year = {2020},
	pages = {1686--1690},
}

@inproceedings{orlikowski_learning_2018,
	address = {Santa Fe, New Mexico},
	title = {Learning {Diachronic} {Analogies} to {Analyze} {Concept} {Change}},
	url = {https://aclanthology.org/W18-4501},
	abstract = {We propose to study the evolution of concepts by learning to complete diachronic analogies between lists of terms which relate to the same concept at different points in time. We present a number of models based on operations on word embedddings that correspond to different assumptions about the characteristics of diachronic analogies and change in concept vocabularies. These are tested in a quantitative evaluation for nine different concepts on a corpus of Dutch newspapers from the 1950s and 1980s. We show that a model which treats the concept terms as analogous and learns weights to compensate for diachronic changes (weighted linear combination) is able to more accurately predict the missing term than a learned transformation and two baselines for most of the evaluated concepts. We also find that all models tend to be coherent in relation to the represented concept, but less discriminative in regard to other concepts. Additionally, we evaluate the effect of aligning the time-specific embedding spaces using orthogonal Procrustes, finding varying effects on performance, depending on the model, concept and evaluation metric. For the weighted linear combination, however, results improve with alignment in a majority of cases. All related code is released publicly.},
	urldate = {2022-05-13},
	booktitle = {Proceedings of the {Second} {Joint} {SIGHUM} {Workshop} on {Computational} {Linguistics} for {Cultural} {Heritage}, {Social} {Sciences}, {Humanities} and {Literature}},
	publisher = {Association for Computational Linguistics},
	author = {Orlikowski, Matthias and Hartung, Matthias and Cimiano, Philipp},
	month = aug,
	year = {2018},
	pages = {1--11},
}

@inproceedings{attanasio_e-mimic_2021,
	title = {E-{MIMIC}: {Empowering} {Multilingual} {Inclusive} {Communication}},
	shorttitle = {E-{MIMIC}},
	doi = {10.1109/BigData52589.2021.9671868},
	abstract = {Preserving diversity and inclusion is becoming a compelling need in both industry and academia. The ability to use appropriate forms of writing, speaking, and gestures is not widespread even in formal communications such as public calls, public announcements, official reports, and legal documents. The improper use of linguistic expressions can foment unacceptable forms of exclusion, stereotypes as well as forms of verbal violence against minorities, including women. Furthermore, existing machine translation tools are not designed to generate inclusive content.The present paper investigates a joint effort of the research communities of linguistics and Deep Learning Natural Language Understanding in fighting against non-inclusive, prejudiced language forms. It presents a methodology aimed at tackling the improper use of language in formal communication, with a particular attention paid to Romanic languages (Italian, in particular). State-of-the-art Deep Language Modeling architectures are exploited to automatically identify non-inclusive text snippets, suggest alternative forms, and produce inclusive text rephrasing. A preliminary evaluation conducted on a benchmark dataset shows promising results, i.e., 85\% accuracy in predicting inclusive/non-inclusive communications.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Attanasio, Giuseppe and Greco, Salvatore and La Quatra, Moreno and Cagliero, Luca and Tonti, Michela and Cerquitelli, Tania and Raus, Rachele},
	month = dec,
	year = {2021},
	pages = {4227--4234},
}

@article{nozza_measuring_nodate,
	title = {Measuring {Harmful} {Sentence} {Completion} in {Language} {Models} for {LGBTQIA}+ {Individuals}},
	abstract = {Warning: This paper contains examples of language that some people may find offensive or upsetting. Current language technology is ubiquitous and directly influences individuals’ lives worldwide. Given the recent trend in AI on training and constantly releasing new and powerful large language models (LLMs), there is a need to assess their biases and potential concrete consequences. While some studies have highlighted the shortcomings of these models, there is only little on the negative impact of LLMs on LGBTQIA+ individuals. In this paper, we investigated a state-of-the-art template-based approach for measuring the harmfulness of English LLMs sentence completion when the subjects belong to the LGBTQIA+ community. Our findings show that, on average, the most likely LLM-generated completion is an identity attack 13\% of the time. Our results raise serious concerns about the applicability of these models in production environments.},
	language = {en},
	author = {Nozza, Debora and Bianchi, Federico and Lauscher, Anne and Hovy, Dirk},
	pages = {9},
}

@article{lauscher_life_2019,
	title = {Life 3.0: being human in the age of artificial intelligence},
	volume = {3},
	issn = {2470-1475},
	shorttitle = {Life 3.0},
	url = {https://doi.org/10.1080/24701475.2019.1565556},
	doi = {10.1080/24701475.2019.1565556},
	number = {1},
	urldate = {2022-05-13},
	journal = {Internet Histories},
	author = {Lauscher, Anne},
	month = jan,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/24701475.2019.1565556},
	pages = {101--103},
}

@inproceedings{curry_review_2017,
	address = {New York, NY, USA},
	series = {{ISIAA} 2017},
	title = {A review of evaluation techniques for social dialogue systems},
	isbn = {978-1-4503-5558-2},
	url = {https://doi.org/10.1145/3139491.3139504},
	doi = {10.1145/3139491.3139504},
	abstract = {In contrast with goal-oriented dialogue, social dialogue has no clear measure of task success. Consequently, evaluation of these systems is notoriously hard. In this paper, we review current evaluation methods, focusing on automatic metrics. We conclude that turn-based metrics often ignore the context and do not account for the fact that several replies are valid, while end-of-dialogue rewards are mainly hand-crafted. Both lack grounding in human perceptions.},
	urldate = {2022-05-13},
	booktitle = {Proceedings of the 1st {ACM} {SIGCHI} {International} {Workshop} on {Investigating} {Social} {Interactions} with {Artificial} {Agents}},
	publisher = {Association for Computing Machinery},
	author = {Curry, Amanda Cercas and Hastie, Helen and Rieser, Verena},
	month = nov,
	year = {2017},
	pages = {25--26},
}

@inproceedings{abercrombie_alexa_2021,
	address = {Online},
	title = {Alexa, {Google}, {Siri}: {What} are {Your} {Pronouns}? {Gender} and {Anthropomorphism} in the {Design} and {Perception} of {Conversational} {Assistants}},
	shorttitle = {Alexa, {Google}, {Siri}},
	url = {https://aclanthology.org/2021.gebnlp-1.4},
	doi = {10.18653/v1/2021.gebnlp-1.4},
	abstract = {Technology companies have produced varied responses to concerns about the effects of the design of their conversational AI systems. Some have claimed that their voice assistants are in fact not gendered or human-like—despite design features suggesting the contrary. We compare these claims to user perceptions by analysing the pronouns they use when referring to AI assistants. We also examine systems' responses and the extent to which they generate output which is gendered and anthropomorphic. We find that, while some companies appear to be addressing the ethical concerns raised, in some cases, their claims do not seem to hold true. In particular, our results show that system outputs are ambiguous as to the humanness of the systems, and that users tend to personify and gender them as a result.},
	urldate = {2022-05-13},
	booktitle = {Proceedings of the 3rd {Workshop} on {Gender} {Bias} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Abercrombie, Gavin and Cercas Curry, Amanda and Pandya, Mugdha and Rieser, Verena},
	month = aug,
	year = {2021},
	pages = {24--33},
}

@inproceedings{bianchi_pre-training_2021,
	address = {Online},
	title = {Pre-training is a {Hot} {Topic}: {Contextualized} {Document} {Embeddings} {Improve} {Topic} {Coherence}},
	shorttitle = {Pre-training is a {Hot} {Topic}},
	url = {https://aclanthology.org/2021.acl-short.96},
	doi = {10.18653/v1/2021.acl-short.96},
	abstract = {Topic models extract groups of words from documents, whose interpretation as a topic hopefully allows for a better understanding of the data. However, the resulting word groups are often not coherent, making them harder to interpret. Recently, neural topic models have shown improvements in overall coherence. Concurrently, contextual embeddings have advanced the state of the art of neural models in general. In this paper, we combine contextualized representations with neural topic models. We find that our approach produces more meaningful and coherent topics than traditional bag-of-words topic models and recent neural models. Our results indicate that future improvements in language models will translate into better topic models.},
	urldate = {2022-05-13},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Bianchi, Federico and Terragni, Silvia and Hovy, Dirk},
	month = aug,
	year = {2021},
	pages = {759--766},
}

@techreport{rocholl_disfluency_2021,
	title = {Disfluency {Detection} with {Unlabeled} {Data} and {Small} {BERT} {Models}},
	url = {http://arxiv.org/abs/2104.10769},
	abstract = {Disfluency detection models now approach high accuracy on English text. However, little exploration has been done in improving the size and inference time of the model. At the same time, automatic speech recognition (ASR) models are moving from server-side inference to local, on-device inference. Supporting models in the transcription pipeline (like disfluency detection) must follow suit. In this work we concentrate on the disfluency detection task, focusing on small, fast, on-device models based on the BERT architecture. We demonstrate it is possible to train disfluency detection models as small as 1.3 MiB, while retaining high performance. We build on previous work that showed the benefit of data augmentation approaches such as self-training. Then, we evaluate the effect of domain mismatch between conversational and written text on model performance. We find that domain adaptation and data augmentation strategies have a more pronounced effect on these smaller models, as compared to conventional BERT models.},
	number = {arXiv:2104.10769},
	urldate = {2022-05-13},
	institution = {arXiv},
	author = {Rocholl, Johann C. and Zayats, Vicky and Walker, Daniel D. and Murad, Noah B. and Schneider, Aaron and Liebling, Daniel J.},
	month = jul,
	year = {2021},
	doi = {10.48550/arXiv.2104.10769},
	note = {arXiv:2104.10769 [cs]
type: article},
}

@inproceedings{10.5555/1860924.1860942,
	address = {NLD},
	title = {Human-computer interaction in estonian: {Collection} and analysis of simulated dialogues},
	isbn = {978-1-60750-640-9},
	abstract = {This paper discusses an experiment series in the course of which so-called simulated dialogues in Estonian were collected in human-computer interaction. The subjects were asked to test a program, which interacted with a person in written Estonian, which gave information about cinema, TV listings, weather, politics or flights. In reality another person (so-called Wizard of Oz) answered the subject's questions via Internet. I will introduce the Wizard of Oz interface. All the experiments have been recorded in a log file; on the basis of this information the analysis of dialogues takes place. I primarily concentrate on a repair type occurred in dialogues, which based on the conversational analysis is called other-initiated repair. I look for language rules (patterns) which have been followed to produce the utterances. This research is one step closer to the aim to create a computer program, which provides users with the information in the most convenient and pleasant way.},
	booktitle = {Proceedings of the 2010 conference on human language technologies – the baltic perspective: {Proceedings} of the fourth international conference baltic {HLT} 2010},
	publisher = {IOS Press},
	author = {Pärkson, Siiri},
	year = {2010},
	note = {Number of pages: 8},
	pages = {99--106},
}

@article{moore_computer_2011,
	title = {Computer {Interaction} {Analysis}: {Toward} an {Empirical} {Approach} to {Understanding} {User} {Practice} and {Eye} {Gaze} in {GUI}-{Based} {Interaction}},
	volume = {20},
	issn = {0925-9724, 1573-7551},
	shorttitle = {Computer {Interaction} {Analysis}},
	url = {http://link.springer.com/10.1007/s10606-011-9142-2},
	doi = {10.1007/s10606-011-9142-2},
	language = {en},
	number = {6},
	urldate = {2022-05-12},
	journal = {Computer Supported Cooperative Work (CSCW)},
	author = {Moore, Robert J. and Churchill, Elizabeth F.},
	month = dec,
	year = {2011},
	pages = {497--528},
}

@article{iwasaki_that_2019,
	title = {“{That} {Robot} {Stared} {Back} at {Me}!”: {Demonstrating} {Perceptual} {Ability} {Is} {Key} to {Successful} {Human}–{Robot} {Interactions}},
	volume = {6},
	issn = {2296-9144},
	shorttitle = {“{That} {Robot} {Stared} {Back} at {Me}!”},
	url = {https://www.frontiersin.org/article/10.3389/frobt.2019.00085/full},
	doi = {10.3389/frobt.2019.00085},
	urldate = {2022-05-12},
	journal = {Frontiers in Robotics and AI},
	author = {Iwasaki, Masaya and Zhou, Jian and Ikeda, Mizuki and Koike, Yuki and Onishi, Yuya and Kawamura, Tatsuyuki and Nakanishi, Hideyuki},
	month = sep,
	year = {2019},
	pages = {85},
}

@article{walker_developing_2020,
	title = {Developing an intelligent virtual agent to stratify people with cognitive complaints: {A} comparison of human–patient and intelligent virtual agent–patient interaction},
	volume = {19},
	issn = {1471-3012, 1741-2684},
	shorttitle = {Developing an intelligent virtual agent to stratify people with cognitive complaints},
	url = {http://journals.sagepub.com/doi/10.1177/1471301218795238},
	doi = {10.1177/1471301218795238},
	abstract = {Previous work on interactions in the memory clinic has shown that conversation analysis can be used to differentiate neurodegenerative dementia from functional memory disorder. Based on this work, a screening system was developed that uses a computerised ‘talking head’ (intelligent virtual agent) and a combination of automatic speech recognition and conversation analysis-informed programming. This system can reliably differentiate patients with functional memory disorder from those with neurodegenerative dementia by analysing the way they respond to questions from either a human doctor or the intelligent virtual agent. However, much of this computerised analysis has relied on simplistic, nonlinguistic phonetic features such as the length of pauses between talk by the two parties.
            To gain confidence in automation of the stratification procedure, this paper investigates whether the patients’ responses to questions asked by the intelligent virtual agent are qualitatively similar to those given in response to a doctor. All the participants in this study have a clear functional memory disorder or neurodegenerative dementia diagnosis.
            Analyses of patients’ responses to the intelligent virtual agent showed similar, diagnostically relevant sequential features to those found in responses to doctors’ questions. However, since the intelligent virtual agent’s questions are invariant, its use results in more consistent responses across people – regardless of diagnosis – which facilitates automatic speech recognition and makes it easier for a machine to learn patterns. Our analysis also shows why doctors do not always ask the same question in the exact same way to different patients. This sensitivity and adaptation to nuances of conversation may be interactionally helpful; for instance, altering a question may make it easier for patients to understand. While we demonstrate that some of what is said in such interactions is bound to be constructed collaboratively between doctor and patient, doctors could consider ensuring that certain, particularly important and/or relevant questions are asked in as invariant a form as possible to be better able to identify diagnostically relevant differences in patients’ responses.},
	language = {en},
	number = {4},
	urldate = {2022-05-12},
	journal = {Dementia},
	author = {Walker, Traci and Christensen, Heidi and Mirheidari, Bahman and Swainston, Thomas and Rutten, Casey and Mayer, Imke and Blackburn, Daniel and Reuber, Markus},
	month = may,
	year = {2020},
	pages = {1173--1188},
}

@article{iwasaki_state-transition_2020,
	title = {State-{Transition} {Modeling} of {Human}–{Robot} {Interaction} for {Easy} {Crowdsourced} {Robot} {Control}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/22/6529},
	doi = {10.3390/s20226529},
	abstract = {Robotic salespeople are often ignored by people due to their weak social presence, and thus have difficulty facilitating sales autonomously. However, for robots that are remotely controlled by humans, there is a need for experienced and trained operators. In this paper, we suggest crowdsourcing to allow general users on the internet to operate a robot remotely and facilitate customers’ purchasing activities while flexibly responding to various situations through a user interface. To implement this system, we examined how our developed remote interface can improve a robot’s social presence while being controlled by a human operator, including first-time users. Therefore, we investigated the typical flow of a customer–robot interaction that was effective for sales promotion, and modeled it as a state transition with automatic functions by accessing the robot’s sensor information. Furthermore, we created a user interface based on the model and examined whether it was effective in a real environment. Finally, we conducted experiments to examine whether the user interface could be operated by an amateur user and enhance the robot’s social presence. The results revealed that our model was able to improve the robot’s social presence and facilitate customers’ purchasing activity even when the operator was a first-time user.},
	language = {en},
	number = {22},
	urldate = {2022-05-12},
	journal = {Sensors},
	author = {Iwasaki, Masaya and Ikeda, Mizuki and Kawamura, Tatsuyuki and Nakanishi, Hideyuki},
	month = nov,
	year = {2020},
	pages = {6529},
}

@incollection{marcus_understanding_2020,
	address = {Cham},
	title = {Understanding {How} {Visitors} {Interact} with {Voice}-{Based} {Conversational} {Systems}},
	volume = {12201},
	isbn = {978-3-030-49759-0 978-3-030-49760-6},
	url = {http://link.springer.com/10.1007/978-3-030-49760-6_3},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Design, {User} {Experience}, and {Usability}. {Design} for {Contemporary} {Interactive} {Environments}},
	publisher = {Springer International Publishing},
	author = {Candello, Heloisa and Barth, Fabrício and Carvalho, Eduardo and Cotia, Ruy Alves Guimarães},
	editor = {Marcus, Aaron and Rosenzweig, Elizabeth},
	year = {2020},
	doi = {10.1007/978-3-030-49760-6_3},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {40--55},
}

@incollection{hutchison_grounding_2013,
	address = {Berlin, Heidelberg},
	title = {Grounding and {Turn}-{Taking} in {Multimodal} {Multiparty} {Conversation}},
	volume = {8007},
	isbn = {978-3-642-39329-7 978-3-642-39330-3},
	url = {http://link.springer.com/10.1007/978-3-642-39330-3_11},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Human-{Computer} {Interaction}. {Interaction} {Modalities} and {Techniques}},
	publisher = {Springer Berlin Heidelberg},
	author = {Novick, David and Gris, Iván},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Kurosu, Masaaki},
	year = {2013},
	doi = {10.1007/978-3-642-39330-3_11},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {97--106},
}

@incollection{jacko_modeling_2011,
	address = {Berlin, Heidelberg},
	title = {Modeling the {Rhetoric} of {Human}-{Computer} {Interaction}},
	volume = {6762},
	isbn = {978-3-642-21604-6 978-3-642-21605-3},
	url = {http://link.springer.com/10.1007/978-3-642-21605-3_38},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Human-{Computer} {Interaction}. {Interaction} {Techniques} and {Environments}},
	publisher = {Springer Berlin Heidelberg},
	author = {Howley, Iris and Penstein Rosé, Carolyn},
	editor = {Jacko, Julie A.},
	year = {2011},
	doi = {10.1007/978-3-642-21605-3_38},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {341--350},
}

@incollection{tapus_effects_2015,
	address = {Cham},
	title = {The {Effects} of {Social} {Gaze} in {Human}-{Robot} {Collaborative} {Assembly}},
	volume = {9388},
	isbn = {978-3-319-25553-8 978-3-319-25554-5},
	url = {http://link.springer.com/10.1007/978-3-319-25554-5_21},
	urldate = {2022-05-12},
	booktitle = {Social {Robotics}},
	publisher = {Springer International Publishing},
	author = {Fischer, Kerstin and Jensen, Lars Christian and Kirstein, Franziska and Stabinger, Sebastian and Erkent, Özgür and Shukla, Dadhichi and Piater, Justus},
	editor = {Tapus, Adriana and André, Elisabeth and Martin, Jean-Claude and Ferland, François and Ammi, Mehdi},
	year = {2015},
	doi = {10.1007/978-3-319-25554-5_21},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {204--213},
}

@incollection{calvaresi_conversational_2019,
	address = {Cham},
	title = {Conversational {Interfaces} for {Explainable} {AI}: {A} {Human}-{Centred} {Approach}},
	volume = {11763},
	isbn = {978-3-030-30390-7 978-3-030-30391-4},
	shorttitle = {Conversational {Interfaces} for {Explainable} {AI}},
	url = {http://link.springer.com/10.1007/978-3-030-30391-4_5},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Explainable, {Transparent} {Autonomous} {Agents} and {Multi}-{Agent} {Systems}},
	publisher = {Springer International Publishing},
	author = {Jentzsch, Sophie F. and Höhn, Sviatlana and Hochgeschwender, Nico},
	editor = {Calvaresi, Davide and Najjar, Amro and Schumacher, Michael and Främling, Kary},
	year = {2019},
	doi = {10.1007/978-3-030-30391-4_5},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {77--92},
}

@inproceedings{6343899,
	title = {“{Can} you answer questions, {Flobi}?”: {Interactionally} defining a robot's competence as a fitness instructor},
	doi = {10.1109/ROMAN.2012.6343899},
	booktitle = {2012 {IEEE} {RO}-{MAN}: {The} 21st {IEEE} international symposium on robot and human interactive communication},
	author = {Süssenbach, Luise and Pitsch, Karola and Berger, Ingmar and Riether, Nina and Kummert, Franz},
	year = {2012},
	pages = {1121--1128},
}

@inproceedings{Pitsch2010HowIP,
	title = {How infants perceive the toy robot {Pleo}. {An} exploratory case study on infant-robot-interaction},
	booktitle = {{HRI} 2010},
	author = {Pitsch, Karola and Koch, Benjamin},
	year = {2010},
}

@inproceedings{payr_closing_2010,
	address = {Viareggio, Italy},
	title = {Closing and closure in human-companion interactions: {Analyzing} video data from a field study},
	isbn = {978-1-4244-7991-7},
	shorttitle = {Closing and closure in human-companion interactions},
	url = {http://ieeexplore.ieee.org/document/5598625/},
	doi = {10.1109/ROMAN.2010.5598625},
	urldate = {2022-05-12},
	booktitle = {19th {International} {Symposium} in {Robot} and {Human} {Interactive} {Communication}},
	publisher = {IEEE},
	author = {Payr, Sabine},
	month = sep,
	year = {2010},
	pages = {476--481},
}

@inproceedings{10.5555/3378680.3378687,
	address = {Daegu, Republic of Korea},
	series = {{HRI} '19},
	title = {Emotion expression in {HRI}: {When} and why},
	isbn = {978-1-5386-8555-6},
	abstract = {In this paper, we draw attention to the social functions of emotional display in interaction. A review of HRI papers on emotion suggests that this perspective is rarely taken in the field, but that it is useful to account for the context-and culture-dependency of emotional expression. We show in two case studies that emotional display is expected to occur at very specific places in interaction and rather independently from general emotional states, and that different cultures have different conventions regarding emotional expression. Based on conversation analytic work and the results from our case studies, we present design recommendations which allow the implementation of specific emotional signals for different human-robot interaction situations.},
	booktitle = {Proceedings of the 14th {ACM}/{IEEE} international conference on human-robot interaction},
	publisher = {IEEE Press},
	author = {Fischer, Kerstin and Jung, Malte and Jensen, Lars Christian and Wieschen, Maria Vanessa aus der},
	year = {2019},
	note = {Number of pages: 10},
	keywords = {conversation analysis, emotion expression, human-robot interaction, situation-specificity},
	pages = {29--38},
}

@inproceedings{webb_human-robot_2019,
	address = {Nottingham United Kingdom},
	title = {Human-robot relationships and the development of responsible social robots},
	isbn = {978-1-4503-7203-9},
	url = {https://dl.acm.org/doi/10.1145/3363384.3363396},
	doi = {10.1145/3363384.3363396},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the {Halfway} to the {Future} {Symposium} 2019},
	publisher = {ACM},
	author = {Webb, Helena and Jirotka, Marina and F.T. Winfield, Alan and Winkle, Katie},
	month = nov,
	year = {2019},
	pages = {1--7},
}

@inproceedings{plurkowski_implications_2011,
	address = {Lyon, France},
	title = {The {Implications} of {Interactional} "{Repair}" for {Human}-{Robot} {Interaction} {Design}},
	isbn = {978-1-4577-1373-6},
	url = {http://ieeexplore.ieee.org/document/6040806/},
	doi = {10.1109/WI-IAT.2011.213},
	urldate = {2022-05-12},
	booktitle = {2011 {IEEE}/{WIC}/{ACM} {International} {Conferences} on {Web} {Intelligence} and {Intelligent} {Agent} {Technology}},
	publisher = {IEEE},
	author = {Plurkowski, Luke and Chu, Maurice and Vinkhuyzen, Erik},
	month = aug,
	year = {2011},
	pages = {61--65},
}

@inproceedings{penzkofer_conan_2021,
	address = {Montréal QC Canada},
	title = {{ConAn}: {A} {Usable} {Tool} for {Multimodal} {Conversation} {Analysis}},
	isbn = {978-1-4503-8481-0},
	shorttitle = {{ConAn}},
	url = {https://dl.acm.org/doi/10.1145/3462244.3479886},
	doi = {10.1145/3462244.3479886},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 2021 {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {ACM},
	author = {Penzkofer, Anna and Müller, Philipp and Bühler, Felix and Mayer, Sven and Bulling, Andreas},
	month = oct,
	year = {2021},
	pages = {341--351},
}

@article{cho_role_2020,
	title = {The {Role} of {Conversational} {Grounding} in {Supporting} {Symbiosis} {Between} {People} and {Digital} {Assistants}},
	volume = {4},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3392838},
	doi = {10.1145/3392838},
	abstract = {In "smart speaker'' digital assistant systems such as Google Home, there is no visual user interface, so people must learn about the system's capabilities and limitations by experimenting with different questions and commands. However, many new users give up quickly and limit their use to a few simple tasks. This is a problem for both the user and the system. Users who stop trying out new things cannot learn about new features and functionality, and the system receives less data upon which to base future improvements. Symbiosis---a mutually beneficial relationship---between AI systems like digital assistants and people is an important aspect of developing systems that are partners to humans and not just tools. In order to better understand requirements for symbiosis, we investigated the relationship between the types of digital assistant responses and users' subsequent questions, focusing on identifying interactions that were discouraging to users when speaking with a digital assistant. We conducted a user study with 20 participants who completed a series of information seeking tasks using the Google Home, and analyzed transcripts using a method based on applied conversation analysis. We found that the most common response from the Google Home, a version of "Sorry, I'm not sure how to help'', provided no feedback for participants to build on when forming their next question. However, responses that provided somewhat strange but tangentially related answers were actually more helpful for conversational grounding, which extended the interaction. We discuss the connection between grounding and symbiosis, and present recommendations for requirements for forming partnerships with digital assistants.},
	language = {en},
	number = {CSCW1},
	urldate = {2022-05-12},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Cho, Janghee and Rader, Emilee},
	month = may,
	year = {2020},
	pages = {1--28},
}

@incollection{bright_examining_2021,
	address = {Cham},
	title = {Examining {Linguistic} {Biases} in {Telegram} with a {Game} {Theoretic} {Analysis}},
	volume = {12887},
	isbn = {978-3-030-87030-0 978-3-030-87031-7},
	url = {https://link.springer.com/10.1007/978-3-030-87031-7_2},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Disinformation in {Open} {Online} {Media}},
	publisher = {Springer International Publishing},
	author = {Höhn, Sviatlana and Asher, Nicholas and Mauw, Sjouke},
	editor = {Bright, Jonathan and Giachanou, Anastasia and Spaiser, Viktoria and Spezzano, Francesca and George, Anna and Pavliuc, Alexandra},
	year = {2021},
	doi = {10.1007/978-3-030-87031-7_2},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {16--32},
}

@incollection{ardito_please_2021,
	address = {Cham},
	title = {“{Please} {Connect} {Me} to a {Specialist}”: {Scrutinising} ‘{Recipient} {Design}’ in {Interaction} with an {Artificial} {Conversational} {Agent}},
	volume = {12935},
	isbn = {978-3-030-85609-0 978-3-030-85610-6},
	shorttitle = {“{Please} {Connect} {Me} to a {Specialist}”},
	url = {https://link.springer.com/10.1007/978-3-030-85610-6_10},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2021},
	publisher = {Springer International Publishing},
	author = {Avgustis, Iuliia and Shirokov, Aleksandr and Iivari, Netta},
	editor = {Ardito, Carmelo and Lanzilotti, Rosa and Malizia, Alessio and Petrie, Helen and Piccinno, Antonio and Desolda, Giuseppe and Inkpen, Kori},
	year = {2021},
	doi = {10.1007/978-3-030-85610-6_10},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {155--176},
}

@inproceedings{9391934,
	title = {A study for detecting mild cognitive impairment by analyzing conversations with humanoid robots},
	doi = {10.1109/LifeTech52111.2021.9391934},
	booktitle = {2021 {IEEE} 3rd global conference on life sciences and technologies ({LifeTech})},
	author = {Yoshii, Kenta and Nishimura, Masafumi and Kimura, Daiki and Kosugi, Akihiro and Shinkawa, Kaoru and Takase, Toshiro and Kobayashi, Masatomo and Yamada, Yasunori and Nemoto, Miyuki and Watanabe, Ryohei and Tsukada, Eriko and Ota, Miho and Nemoto, Kiyotaka and Arai, Tetsuaki and Higashi, Shinji},
	year = {2021},
	pages = {347--350},
}

@inproceedings{9422879,
	title = {Influence of communication strategies on the structure of political discussions},
	doi = {10.1109/ComSDS52473.2021.9422879},
	booktitle = {2021 communication strategies in digital society seminar ({ComSDS})},
	author = {Lukyanova, Galina V. and Martyanov, Denis S.},
	year = {2021},
	pages = {126--129},
}

@inproceedings{9597445,
	title = {Exploring the effects of virtual agents’ smiles on human-agent interaction: {A} mixed-methods study},
	doi = {10.1109/ACII52823.2021.9597445},
	booktitle = {2021 9th international conference on affective computing and intelligent interaction ({ACII})},
	author = {Torre, Ilaria and Tuncer, Sylvaine and McDuff, Daniel and Czerwinski, Mary},
	year = {2021},
	pages = {1--8},
}

@inproceedings{pelikan_why_2021,
	address = {Boulder CO USA},
	title = {Why {Autonomous} {Driving} {Is} {So} {Hard}: {The} {Social} {Dimension} of {Traffic}},
	isbn = {978-1-4503-8290-8},
	shorttitle = {Why {Autonomous} {Driving} {Is} {So} {Hard}},
	url = {https://dl.acm.org/doi/10.1145/3434074.3447133},
	doi = {10.1145/3434074.3447133},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Companion of the 2021 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Pelikan, Hannah R.M.},
	month = mar,
	year = {2021},
	pages = {81--85},
}

@article{paakki_disruptive_2021,
	title = {Disruptive online communication: {How} asymmetric trolling-like response strategies steer conversation off the track},
	volume = {30},
	issn = {0925-9724, 1573-7551},
	shorttitle = {Disruptive online communication},
	url = {https://link.springer.com/10.1007/s10606-021-09397-1},
	doi = {10.1007/s10606-021-09397-1},
	abstract = {Abstract
            Internet trolling, a form of antisocial online behavior, is a serious problem plaguing social media. Skillful trolls can lure entire communities into degenerative and polarized discussions that continue endlessly. From analysis of data gathered in accordance with established classifications of trolling-like behavior, the paper presents a conversation analysis of trolling-like interaction strategies that disrupt online discussions. The authors argue that troll-like users exploit other users’ desire for common grounding – i.e., joint maintenance of mutual understanding and seeking of conversational closure – by responding asymmetrically. Their responses to others deviate from expectations for typical paired actions in turn-taking. These asymmetries, described through examples of three such behaviors – ignoring, mismatching, and challenging – lead to dissatisfactory interactions, in that they subvert other users’ desire for clarification and explanation of contra-normative social behavior. By avoiding clarifications, troll-like users easily capture unsuspecting users’ attention and manage to prolong futile conversations interminably. Through the analysis, the paper connects trolling-like asymmetric response strategies with concrete data and addresses the implications of this nonconformist behavior for common grounding in social-media venues.},
	language = {en},
	number = {3},
	urldate = {2022-05-12},
	journal = {Computer Supported Cooperative Work (CSCW)},
	author = {Paakki, Henna and Vepsäläinen, Heidi and Salovaara, Antti},
	month = jun,
	year = {2021},
	pages = {425--461},
}

@incollection{abba_where_2021,
	address = {Cham},
	title = {Where {I}’m {Coming} from: {Studying} the {Novelty} of {Immersive} {Algorithms}},
	isbn = {978-3-030-41455-9 978-3-030-41456-6},
	shorttitle = {Where {I}’m {Coming} from},
	url = {http://link.springer.com/10.1007/978-3-030-41456-6_10},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Ambient {Literature}},
	publisher = {Springer International Publishing},
	author = {Marcinkowski, Michael},
	editor = {Abba, Tom and Dovey, Jonathan and Pullinger, Kate},
	year = {2021},
	doi = {10.1007/978-3-030-41456-6_10},
	pages = {199--232},
}

@incollection{brooker_researching_2021,
	address = {London},
	title = {Researching {Algorithms} and {Artificial} {Intelligence}},
	url = {https://livrepository.liverpool.ac.uk/3141138},
	abstract = {Algorithms and artificial intelligence technologies are increasingly commonplace in everyday life - they recommend products to us, classify our photo albums, provide tech support, and more. Confronted with the diffusion of algorithms through our lives, social scientific studies have tended to go in one of two ways. On the one hand, concentrating on pernicious applications of these technologies in big and broad ways; e.g., the power they exert in state surveillance, governance issues around self-driving car disasters or stock market ‘flash crashes’. On the other hand, researchers have put these technologies to use as research tools, leveraging computer power to sift large volume digital datasets, help make predictions and generate new forms of knowledge. These are not necessarily unimportant questions or nonsensical applications. However, focussing our attention thusly risks losing a sense of the ‘haecceities’ or specificities of the technologies themselves in terms of what they comprise, how their designs are implemented and how they operate. To unravel these aspects, this chapter suggests that rather than viewing them from the outside we stand to learn a great deal by familiarising ourselves with algorithms and AI applications ‘from within’ (Garfinkel 1967: 3). This requires that we, social researchers, become adept with the design, development and deployment of such technologies ourselves, by learning to code. Though this is a potentially daunting addition to the social science methodological toolkit, this chapter will argue that incorporating these skills into our repertoire has the potential to deepen our understanding of how these technologies feature in the situated contexts of our everyday lives and the activities we engage in within them.},
	language = {en},
	urldate = {2022-05-12},
	publisher = {SAGE},
	author = {Brooker, Phillip and Mair, Michael},
	editor = {Housley, William and Fitzgerald, Richard and Edwards, Adam and Beneito-Montagut, Roser},
	month = oct,
	year = {2021},
}

@article{ziewitz_not_2017,
	title = {A not quite random walk: {Experimenting} with the ethnomethods of the algorithm},
	volume = {4},
	issn = {2053-9517, 2053-9517},
	shorttitle = {A not quite random walk},
	url = {http://journals.sagepub.com/doi/10.1177/2053951717738105},
	doi = {10.1177/2053951717738105},
	language = {en},
	number = {2},
	urldate = {2022-05-12},
	journal = {Big Data \& Society},
	author = {Ziewitz, Malte},
	month = dec,
	year = {2017},
	pages = {205395171773810},
}

@article{habscheid_intelligente_2021,
	title = {Intelligente {Persönliche} {Assistenten} ({IPA}) mit {Voice} {User} {Interfaces} ({VUI}) als ‚{Beteiligte}‘ in häuslicher {Alltags}­interaktion. {Welchen} {Aufschluss} geben die {Protokolldaten} der {Assistenzsysteme}?},
	volume = {4},
	issn = {2569-6491},
	url = {https://jfml.org/article/view/44},
	doi = {10.21248/jfml.2021.44},
	abstract = {The paper presents research results emerging from the analysis of Intelligent Personal Assistants (IPA) log data. Based on the assump­tion that media and data, as part of practice, are produced and used cooperatively, the paper discusses how IPA log data can be used to analyze (1) how the IPA systems operate through their connection to platforms and infrastructures, (2) how the dialog systems are de­signed today and (3) how users integrate them into their everyday social interaction. It also asks in which everyday practical contexts the IPA are placed on the system side and on the user side, and how privacy issues in particular are negotiated. It is argued that, in order to be able to investigate these questions, the technical-institutional and the cultural-theoretical perspective on media, which is common in German media linguistics, has to be complemented by a more fun­damental, i.e. social-theoretical and interactionist perspective.},
	number = {1},
	urldate = {2022-05-12},
	journal = {Journal für Medienlinguistik},
	author = {Habscheid, Stephan and Hector, Tim Moritz and Hrncal, Christine and Waldecker, David},
	month = sep,
	year = {2021},
	pages = {16--53},
}

@article{tuncer_robot-mediated_2022,
	title = {Robot-{Mediated} {Inclusive} {Processes} in {Groups} of {Children}: {From} {Gaze} {Aversion} to {Mutual} {Smiling} {Gaze}},
	volume = {9},
	issn = {2296-9144},
	shorttitle = {Robot-{Mediated} {Inclusive} {Processes} in {Groups} of {Children}},
	url = {https://www.frontiersin.org/articles/10.3389/frobt.2022.729146/full},
	doi = {10.3389/frobt.2022.729146},
	abstract = {Our work is motivated by the idea that social robots can help inclusive processes in groups of children, focusing on the case of children who have newly arrived from a foreign country and their peers at school. Building on an initial study where we tested different robot behaviours and recorded children’s interactions mediated by a robot in a game, we present in this paper the findings from a subsequent analysis of the same video data drawing from ethnomethodology and conversation analysis. We describe how this approach differs from predominantly quantitative video analysis in HRI; how mutual gaze appeared as a challenging interactional accomplishment between unacquainted children, and why we focused on this phenomenon. We identify two situations and trajectories in which children make eye contact: asking for or giving instructions, and sharing an emotional reaction. Based on detailed analyses of a selection of extracts in the empirical section, we describe patterns and discuss the links between the different situations and trajectories, and relationship building. Our findings inform HRI and robot design by identifying complex interactional accomplishments between two children, as well as group dynamics which support these interactions. We argue that social robots should be able to perceive such phenomena in order to better support inclusion of outgroup children. Lastly, by explaining how we combined approaches and showing how they build on each other, we also hope to demonstrate the value of interdisciplinary research, and encourage it.},
	urldate = {2022-05-12},
	journal = {Frontiers in Robotics and AI},
	author = {Tuncer, Sylvaine and Gillet, Sarah and Leite, Iolanda},
	month = mar,
	year = {2022},
	pages = {729146},
}

@article{noren_young_2021,
	title = {Young students’ treatment of synthetic voicing as an interactional resource in digital writing},
	issn = {1946-3014, 1946-3022},
	url = {https://www.tandfonline.com/doi/full/10.1080/19463014.2020.1814367},
	doi = {10.1080/19463014.2020.1814367},
	language = {en},
	urldate = {2022-05-12},
	journal = {Classroom Discourse},
	author = {Norén, Niklas and Bowden, Helen Melander and Evaldsson, Ann-Carita},
	month = feb,
	year = {2021},
	pages = {1--23},
}

@article{muhle_sozialitat_2018,
	title = {Sozialität von und mit {Robotern}? {Drei} soziologische {Antworten} und eine kommunikationstheoretische {Alternative}: {Sociality} of – and with {Robots}? {Three} {Sociological} {Answers} and a {Communication}-{Theoretical} {Alternative}},
	volume = {47},
	issn = {2366-0325, 0340-1804},
	shorttitle = {Sozialität von und mit {Robotern}?},
	url = {https://www.degruyter.com/document/doi/10.1515/zfsoz-2018-1010/html},
	doi = {10.1515/zfsoz-2018-1010},
	abstract = {Zusammenfassung
            Angesichts aktueller Debatten um die Sozialität von und mit Robotern identifiziert der Beitrag drei Strategien einer Erneuerung und Erweiterung der Sozialtheorie, die darauf zielen, die Gleichsetzung von Sozialem und Menschlichem zu überwinden: erstens die Betrachtung des Sozialen als hybridem Kollektiv menschlicher und nicht-menschlicher Entitäten, zweitens die Betrachtung der Grenzen von Sozialität und Personalität als historisch und kulturell variierendem Deutungsmuster und drittens die Betrachtung von Sozialität in Form eines gradualisierten Kontinuums der Handlungsbeteiligungen menschlicher und nicht-menschlicher Entitäten. Diesen Strategien wird eine kommunikationstheoretische Alternative entgegengestellt, die auf eine Einschränkung des Bereichs des Sozialen zielt. Gerade darum, so die Argumentation, kann die Beteiligung von Robotern an sozialen Prozessen kommunikationstheoretisch in theoretisch konsistenter und methodisch kontrollierter Weise in den Blick genommen werden.},
	language = {en},
	number = {3},
	urldate = {2022-05-12},
	journal = {Zeitschrift für Soziologie},
	author = {Muhle, Florian},
	month = aug,
	year = {2018},
	pages = {147--163},
}

@book{willems_weltweite_2008,
	address = {Wiesbaden},
	edition = {1. Aufl},
	title = {Weltweite {Welten}: {Internet}-{Figurationen} aus wissenssoziologischer {Perspektive}},
	isbn = {978-3-531-15314-8},
	shorttitle = {Weltweite {Welten}},
	publisher = {VS Verlag für Sozialwissenschaften},
	editor = {Willems, Herbert},
	year = {2008},
	note = {OCLC: ocn232963631},
	keywords = {Information society, Internet, Social aspects},
}

@incollection{oreilly_looking_2015,
	address = {London},
	title = {Looking or {Spotting}: {A} {Conversation} {Analytic} {Perspective} on {Interaction} between a {Humanoid} {Robot}, a {Co}-present {Adult}, and a {Child} with an {ASC}},
	isbn = {978-1-349-57695-1 978-1-137-42831-8},
	shorttitle = {Looking or {Spotting}},
	url = {http://link.springer.com/10.1057/9781137428318_4},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {The {Palgrave} {Handbook} of {Child} {Mental} {Health}},
	publisher = {Palgrave Macmillan UK},
	author = {Dickerson, Paul and Robins, Ben},
	editor = {O’Reilly, Michelle and Lester, Jessica Nina},
	year = {2015},
	doi = {10.1057/9781137428318_4},
	pages = {59--78},
}

@article{krummheuer_kunstliche_2011,
	title = {Künstliche {Interaktionen} mit {Embodied} {Conversational} {Agents}},
	volume = {20},
	issn = {2199-9201, 1619-7623},
	url = {https://tatup.de/index.php/tatup/article/view/793},
	doi = {10.14512/tatup.20.1.32},
	number = {1},
	urldate = {2022-05-12},
	journal = {TATuP - Zeitschrift für Technikfolgenabschätzung in Theorie und Praxis},
	author = {Krummheuer, Antonia},
	month = apr,
	year = {2011},
	pages = {32--39},
}

@incollection{gamberini_towards_2017,
	address = {Cham},
	title = {Towards {Interactional} {Symbiosis}: {Epistemic} {Balance} and {Co}-presence in a {Quantified} {Self} {Experiment}},
	volume = {9961},
	isbn = {978-3-319-57752-4 978-3-319-57753-1},
	shorttitle = {Towards {Interactional} {Symbiosis}},
	url = {http://link.springer.com/10.1007/978-3-319-57753-1_13},
	urldate = {2022-05-12},
	booktitle = {Symbiotic {Interaction}},
	publisher = {Springer International Publishing},
	author = {Rollet, Nicolas and Jain, Varun and Licoppe, Christian and Devillers, Laurence},
	editor = {Gamberini, Luciano and Spagnolli, Anna and Jacucci, Giulio and Blankertz, Benjamin and Freeman, Jonathan},
	year = {2017},
	doi = {10.1007/978-3-319-57753-1_13},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {143--154},
}

@article{muhle_humanoide_2019,
	title = {Humanoide {Roboter} als ‚technische {Adressen}‘: {Zur} {Rekonstruktion} einer {Mensch}-{Roboter}-{Begegnung} im {Museum}},
	volume = {20},
	issn = {2366-0228, 1439-9326},
	shorttitle = {Humanoide {Roboter} als ‚technische {Adressen}‘},
	url = {https://www.degruyter.com/document/doi/10.1515/sosi-2019-0004/html},
	doi = {10.1515/sosi-2019-0004},
	abstract = {Zusammenfassung
            Vor dem Hintergrund anhaltender Debatten um die Handlungsfähigkeit von Technik und aktueller Prognosen, dass Menschen in naher Zukunft routinemäßig nicht nur mit anderen Menschen sondern auch mit ‚humanoiden Robotern‘ interagieren werden, entwickelt der Beitrag ein kommunikationstheoretisches Konzept zur Rekonstruktion kommunikativer Kategorisierungen von Subjekten und Objekten, welches es erlaubt, den kommunikativen Stellenwert von Menschen und Maschinen ergebnisoffen zu untersuchen. Dieses Konzept, welches auf konversationsanalytischen Vorschlägen zur Untersuchung sozialer Kategorisierungen und Positionierungen aufbaut, wird anhand einer Fallanalyse einer Begegnung zwischen zwei Menschen und einem humanoiden Roboter zur Anwendung gebracht, die in einem Computermuseum stattfindet. Die sequenzanalytisch vorgehende Analyse zeigt, wie die Begegnung schrittweise kommunikativ bestimmt wird und in diesem Zuge eine neuartige soziale Kategorie entsteht: die der ‚technischen Adresse‘.},
	language = {en},
	number = {1},
	urldate = {2022-05-12},
	journal = {Sozialer Sinn},
	author = {Muhle, Florian},
	month = jun,
	year = {2019},
	pages = {85--128},
}

@inproceedings{10.5555/3235924.3235950,
	address = {USA},
	series = {{SOUPS} '17},
	title = {Using chatbots against voice spam: {Analyzing} lenny's effectiveness},
	isbn = {978-1-931971-39-3},
	abstract = {A new countermeasure recently appeared to fight back against unwanted phone calls (such as, telemarketing, survey or scam calls), which consists in connecting back the telemarketer with a phone bot ("robocallee") which mimics a real persona. Lenny is such a bot (a computer program) which plays a set of pre-recorded voice messages to interact with the spammers. Although not based on any sophisticated artificial intelligence, Lenny is surprisingly effective in keeping the conversation going for tens of minutes. Moreover, it is clearly recognized as a bot in only 5\% of the calls recorded in our dataset. In this paper, we try to understand why Lenny is so successful in dealing with spam calls. To this end, we analyze the recorded conversations of Lenny with various types of spammers. Among 487 publicly available call recordings, we select 200 calls and transcribe them using a commercial service. With this dataset, we first explore the spam ecosystem captured by this chatbot, presenting several statistics on Lenny's interaction with spammers. Then, we use conversation analysis to understand how Lenny is adjusted with the sequential context of such spam calls, keeping a natural ow of conversation. Finally, we discuss a range of research and design issues to gain a better understanding of chatbot conversations and to improve their efficiency.},
	booktitle = {Proceedings of the thirteenth {USENIX} conference on usable privacy and security},
	publisher = {USENIX Association},
	author = {Sahin, Merve and Relieu, Marc and Francillon, Aurélien},
	year = {2017},
	note = {Number of pages: 19
Place: Santa Clara, CA, USA},
	pages = {319--337},
}

@article{Oktarini2020,
	title = {Are you flirting, objectifying or what? a conversation analysis of “you’re very sexy” conversational turn},
	volume = {10},
	url = {http://ojs.pnb.ac.id/index.php/SOSHUM/},
	number = {3},
	journal = {Jurnal Sosial dan Humaniora},
	author = {Oktarini, Kadek Ratih Dwi},
	year = {2020},
	keywords = {AI reference list, Conversation design, Conversational agents, EMCA, Indonesian, Intent},
	pages = {294--308},
}

@article{alac_when_2011,
	title = {When a robot is social: {Spatial} arrangements and multimodal semiotic engagement in the practice of social robotics},
	volume = {41},
	issn = {0306-3127, 1460-3659},
	shorttitle = {When a robot is social},
	url = {http://journals.sagepub.com/doi/10.1177/0306312711420565},
	doi = {10.1177/0306312711420565},
	abstract = {Social roboticists design their robots to function as social agents in interaction with humans and other robots. Although we do not deny that the robot’s design features are crucial for attaining this aim, we point to the relevance of spatial organization and coordination between the robot and the humans who interact with it. We recover these interactions through an observational study of a social robotics laboratory and examine them by applying a multimodal interactional analysis to two moments of robotics practice. We describe the vital role of roboticists and of the group of preverbal infants, who are involved in a robot’s design activity, and we argue that the robot’s social character is intrinsically related to the subtleties of human interactional moves in laboratories of social robotics. This human involvement in the robot’s social agency is not simply controlled by individual will. Instead, the human–machine couplings are demanded by the situational dynamics in which the robot is lodged.},
	language = {en},
	number = {6},
	urldate = {2022-05-12},
	journal = {Social Studies of Science},
	author = {Alač, Morana and Movellan, Javier and Tanaka, Fumihide},
	month = dec,
	year = {2011},
	pages = {893--926},
}

@article{alac_moving_2009,
	title = {Moving {Android}: {On} {Social} {Robots} and {Body}-in-{Interaction}},
	volume = {39},
	issn = {0306-3127, 1460-3659},
	shorttitle = {Moving {Android}},
	url = {http://journals.sagepub.com/doi/10.1177/0306312709103476},
	doi = {10.1177/0306312709103476},
	abstract = {Social robotics studies embodied technologies designed for social interaction. This paper examines the implied idea of embodiment using as data a sequence in which practitioners of social robotics are involved in designing a robot's movement. The moments of learning and work in the laboratory enact the social body as material, dynamic, and multiparty: the body-in-interaction. In describing subject—object reconfigurations, the paper explores how the well-known ideas of extending the body with instruments can be applied to a technology designed to function as our surrogate.},
	language = {en},
	number = {4},
	urldate = {2022-05-12},
	journal = {Social Studies of Science},
	author = {Alač, Morana},
	month = aug,
	year = {2009},
	pages = {491--528},
}

@article{aranguren_travail_2014,
	title = {Le travail émotionnel du client: {La} structure séquentielle des émotions dans les usages problématiques d’un serveur vocal},
	volume = {53},
	issn = {0539-0184, 1461-7412},
	shorttitle = {Le travail émotionnel du client},
	url = {http://journals.sagepub.com/doi/10.1177/0539018414523520},
	doi = {10.1177/0539018414523520},
	abstract = {Recent developments in the service sector have led sociologists to suggest that customers are increasingly encouraged to ‘work’ for service organizations. This article develops the hypothesis that the clients who work in this service sector may experience an emotional dimension to their work. In support of this hypothesis, a revision of the notion of ‘emotion work’ is proposed on the basis of a study on the problematic usages of a phone interface service supplied by a telecommunications operator. The study made use of a group of genuine calls that were transcribed and coded; utterances were described objectively regarding pitch and intensity; finally, a statistical method for detecting sequential patterns was applied. The results suggest that clients respond emotionally to usability problems, and that their emotions unfold according to a recurrent sequential structure. Goffman’s ‘remedial interchange’ provides the point of reference for the interpretation, which leads to the suggestion that the emotional patterns revealed are of a social origin, though not socially situated.},
	language = {en},
	number = {3},
	urldate = {2022-05-12},
	journal = {Social Science Information},
	author = {Aranguren, Martin},
	month = sep,
	year = {2014},
	pages = {311--340},
}

@article{pentzold_making_2019,
	title = {Making {Affordances} {Real}: {Socio}-{Material} {Prefiguration}, {Performed} {Agency}, and {Coordinated} {Activities} in {Human}–{Robot} {Communication}},
	volume = {5},
	issn = {2056-3051, 2056-3051},
	shorttitle = {Making {Affordances} {Real}},
	url = {http://journals.sagepub.com/doi/10.1177/2056305119865472},
	doi = {10.1177/2056305119865472},
	abstract = {Usually, the alluring notion of “affordances” comes with the idea that technology makes some activities possible while constraining others. Our article departs from this dichotomic view and seeks to appreciate the multiplicity of socio-material prefiguration. Discussing three empirical examples from human–robot communication, we show that the affordances of “smart” technologies are not acted out in a smooth, planned process or through rational action alone. Rather, affordances are collective achievements that emerge within the interplay of humans and machines. This challenges the separation into active use and passive usability. It also demands us that we think through what types of agency are associated with these kinds of agents and what we take to define agency at all. Agency rests, we argue, on the capability to engage in intelligible encounters; it builds on purposive activities even though they might only realize a limited repertoire of tasks.},
	language = {en},
	number = {3},
	urldate = {2022-05-12},
	journal = {Social Media + Society},
	author = {Pentzold, Christian and Bischof, Andreas},
	month = jul,
	year = {2019},
	pages = {205630511986547},
}

@inproceedings{brown_trouble_2017,
	address = {Denver Colorado USA},
	title = {The {Trouble} with {Autopilots}: {Assisted} and {Autonomous} {Driving} on the {Social} {Road}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {The {Trouble} with {Autopilots}},
	url = {https://dl.acm.org/doi/10.1145/3025453.3025462},
	doi = {10.1145/3025453.3025462},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Brown, Barry and Laurier, Eric},
	month = may,
	year = {2017},
	pages = {416--429},
}

@inproceedings{pelikan_why_2016,
	address = {San Jose California USA},
	title = {Why {That} {Nao}?: {How} {Humans} {Adapt} to a {Conventional} {Humanoid} {Robot} in {Taking} {Turns}-at-{Talk}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Why {That} {Nao}?},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858478},
	doi = {10.1145/2858036.2858478},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Pelikan, Hannah R.M. and Broth, Mathias},
	month = may,
	year = {2016},
	pages = {4921--4932},
}

@article{due_robodoc_2021,
	title = {{RoboDoc}: {Semiotic} resources for achieving \textit{face-to-screenface formation} with a telepresence robot},
	volume = {2021},
	issn = {1613-3692, 0037-1998},
	shorttitle = {{RoboDoc}},
	url = {https://www.degruyter.com/document/doi/10.1515/sem-2018-0148/html},
	doi = {10.1515/sem-2018-0148},
	abstract = {Abstract
            Face-to-face interaction is a primordial site for human activity and intersubjectivity. Empirical studies have shown how people reflexively exhibit a face orientation and work to establish a formation in which everyone is facing each other in local participation frameworks. The Face has also been described by, e.g., Levinas as the basis for a first ethical philosophy. Humans have established these Face-formations when interacting since time immemorial, but what happens when one of the participants is present through a telepresence robot? Based on ethnomethodology, Peircean/Goodwinian semiotics, multimodal conversation analysis and video data from a Danish residential rehabilitation center, the article shows the ways in which participants manage to interactively, cooperatively, and moment by moment achieve an F-formation in situ. The article contributes a detailed analysis and discussion of the kind of participant a telepresence robot is, in and through situated interactions: I propose that we term this participant the RoboDoc, given that it is an assemblage of a doctor who controls a robot. By focusing on the affordances of mobility, the article contributes to a renewed understanding of the importance and relevance of establishing Face-orientations in an increasingly technofied telepresence world.},
	language = {en},
	number = {238},
	urldate = {2022-05-12},
	journal = {Semiotica},
	author = {Due, Brian L.},
	month = jan,
	year = {2021},
	pages = {253--278},
}

@inproceedings{gehle_trouble-based_2015,
	address = {Kobe, Japan},
	title = {Trouble-based group dynamics in real-world {HRI} \&\#x2014; {Reactions} on unexpected next moves of a museum guide robot},
	isbn = {978-1-4673-6704-2},
	url = {http://ieeexplore.ieee.org/document/7333574/},
	doi = {10.1109/ROMAN.2015.7333574},
	urldate = {2022-05-12},
	booktitle = {2015 24th {IEEE} {International} {Symposium} on {Robot} and {Human} {Interactive} {Communication} ({RO}-{MAN})},
	publisher = {IEEE},
	author = {Gehle, Raphaela and Pitsch, Karola and Dankert, Timo and Wrede, Sebastian},
	month = aug,
	year = {2015},
	pages = {407--412},
}

@inproceedings{pitsch_first_2009,
	address = {Toyama, Japan},
	title = {"{The} first five seconds": {Contingent} stepwise entry into an interaction as a means to secure sustained engagement in {HRI}},
	isbn = {978-1-4244-5081-7},
	shorttitle = {\&\#{x201C};{The} first five seconds\&\#{x201D};},
	url = {http://ieeexplore.ieee.org/document/5326167/},
	doi = {10.1109/ROMAN.2009.5326167},
	urldate = {2022-05-12},
	booktitle = {{RO}-{MAN} 2009 - {The} 18th {IEEE} {International} {Symposium} on {Robot} and {Human} {Interactive} {Communication}},
	publisher = {IEEE},
	author = {Pitsch, Karola and Kuzuoka, Hideaki and Suzuki, Yuya and Sussenbach, Luise and Luff, Paul and Heath, Christian},
	month = sep,
	year = {2009},
	pages = {985--991},
}

@article{velkovska_les_2020,
	title = {Les relations aux machines « conversationnelles »: {Vivre} avec les assistants vocaux à la maison},
	volume = {N° 220-221},
	issn = {0751-7971},
	shorttitle = {Les relations aux machines « conversationnelles »},
	url = {https://www.cairn.info/revue-reseaux-2020-2-page-47.htm?ref=doi},
	doi = {10.3917/res.220.0047},
	number = {2},
	urldate = {2022-05-12},
	journal = {Réseaux},
	author = {Velkovska, Julia and Zouinar, Moustafa and Veyrier, Clair-Antoine},
	month = may,
	year = {2020},
	pages = {47--79},
}

@article{velkovska_pourquoi_2020,
	title = {Pourquoi ethnographier les interactions avec les agents conversationnels ?:},
	volume = {N° 220-221},
	issn = {0751-7971},
	shorttitle = {Pourquoi ethnographier les interactions avec les agents conversationnels ?},
	url = {https://www.cairn.info/revue-reseaux-2020-2-page-9.htm?ref=doi},
	doi = {10.3917/res.220.0009},
	number = {2},
	urldate = {2022-05-12},
	journal = {Réseaux},
	author = {Velkovska, Julia and Relieu, Marc},
	month = may,
	year = {2020},
	pages = {9--20},
}

@article{pitsch_repondre_2020,
	title = {Répondre aux questions d’un robot: {Dynamique} de participation des groupes adultes-enfants dans les rencontres avec un robot guide de musée},
	volume = {N° 220-221},
	issn = {0751-7971},
	shorttitle = {Répondre aux questions d’un robot},
	url = {https://www.cairn.info/revue-reseaux-2020-2-page-113.htm?ref=doi},
	doi = {10.3917/res.220.0113},
	number = {2},
	urldate = {2022-05-12},
	journal = {Réseaux},
	author = {Pitsch, Karola and Relieu, Marc and Velkovska, Julia},
	month = may,
	year = {2020},
	pages = {113--150},
}

@article{licoppe__2020,
	title = {« {Je} dois y aller ». {Analyses} de séquences de clôtures entre humains et robot},
	volume = {N°220-221},
	issn = {0751-7971, 1777-5809},
	url = {http://www.cairn.info/revue-reseaux-2020-2-page-151.htm?ref=doi},
	doi = {10.3917/res.220.0151},
	language = {fr},
	number = {2},
	urldate = {2022-05-12},
	journal = {Réseaux},
	author = {Licoppe, Christian and Rollet, Nicolas},
	year = {2020},
	pages = {151},
}

@article{mair_just_2021,
	title = {Just what are we doing when we’re describing {AI}? {Harvey} {Sacks}, the commentator machine, and the descriptive politics of the new artificial intelligence},
	volume = {21},
	issn = {1468-7941, 1741-3109},
	shorttitle = {Just what are we doing when we’re describing {AI}?},
	url = {http://journals.sagepub.com/doi/10.1177/1468794120975988},
	doi = {10.1177/1468794120975988},
	abstract = {In dialogue with the work of Heather Love and colleagues, this article makes use of a peculiar ‘descriptive assemblage’ proposed by Harvey Sacks (1963) – that of the ‘commentator machine’ – to open up issues of ‘descriptive politics’ in the field of contemporary Artificial Intelligence (AI). We do so by reviewing the gameplay of Google DeepMind’s AlphaGo – an algorithm designed to outperform human players at the game of Go – with a focus on the incongruities of the much discussed, indeed (in)famous ‘move 37’ in a human-versus-machine challenge match in 2016 (e.g. Silver et al., 2017). Looking at move 37 in conjunction with the various layers of commentary that came to be woven around it, we explore the kinds of descriptive work involved in characterising the move, the troubles that work reveals and what we can learn about the practices and politics of description from encounters with ‘New AI’ applications like AlphaGo.},
	language = {en},
	number = {3},
	urldate = {2022-05-12},
	journal = {Qualitative Research},
	author = {Mair, Michael and Brooker, Phillip and Dutton, William and Sormani, Philippe},
	month = jun,
	year = {2021},
	pages = {341--359},
}

@article{Krummheuer2015TechnicalAI,
	title = {Technical {Agency} in {Practice}: {The} enactment of artefacts as conversation partners, actants and opponents},
	volume = {13},
	journal = {PsychNology J.},
	author = {Krummheuer, Antonia Lina},
	year = {2015},
	pages = {179--202},
}

@article{baldaufquilliatre:halshs-01276882,
	series = {Microanalysis of mediated interaction: {A} {CA}/ethno approach},
	title = {Is the avatar considered as a participant by the players? {A} conversational analysis of multi-player videogames interactions},
	volume = {13},
	url = {https://halshs.archives-ouvertes.fr/halshs-01276882},
	number = {2-3},
	journal = {PsychNology Journal},
	author = {Baldauf-Quilliatre, Heike and Colón de Carvajal, Isabel},
	year = {2015},
	note = {Publisher: PsychNology Journal
tex.hal\_id: halshs-01276882
tex.hal\_version: v1},
	keywords = {actions, addressing, avatar, objects role, participation framework, player, technology implication, videogame interactions},
	pages = {127--148},
}

@book{VideoInteractionAnalysis,
	address = {Berlin, Germany},
	title = {Video interaction analysis},
	url = {https://www.peterlang.com/document/1106428},
	publisher = {Peter Lang Verlag},
	author = {Kissmann, Ulrike Tikvah},
	year = {2021},
}

@article{meyer_interaktionskrisen_2016,
	title = {Interaktionskrisen oder anthropologische {Normalität}?: Über liminale {Interaktionen} im 21. {Jahrhundert}},
	volume = {41},
	issn = {1011-0070, 1862-2585},
	shorttitle = {Interaktionskrisen oder anthropologische {Normalität}?},
	url = {http://link.springer.com/10.1007/s11614-016-0207-9},
	doi = {10.1007/s11614-016-0207-9},
	language = {de},
	number = {S1},
	urldate = {2022-05-12},
	journal = {Österreichische Zeitschrift für Soziologie},
	author = {Meyer, Christian},
	month = jul,
	year = {2016},
	pages = {75--95},
}

@incollection{jackel_interaktion_2005,
	address = {Wiesbaden},
	title = {Interaktion ohne {Gegenüber}?},
	isbn = {978-3-531-14583-9 978-3-322-80724-3},
	url = {http://link.springer.com/10.1007/978-3-322-80724-3_3},
	language = {de},
	urldate = {2022-05-12},
	booktitle = {Online-{Vergesellschaftung}?},
	publisher = {VS Verlag für Sozialwissenschaften},
	author = {Ayaß, Ruth},
	editor = {Jäckel, Michael and Mai, Manfred},
	year = {2005},
	doi = {10.1007/978-3-322-80724-3_3},
	pages = {33--49},
}

@article{friesen_discursive_2009,
	title = {Discursive {Psychology} and {Educational} {Technology}: {Beyond} the {Cognitive} {Revolution}},
	volume = {16},
	issn = {1074-9039, 1532-7884},
	shorttitle = {Discursive {Psychology} and {Educational} {Technology}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10749030802707861},
	doi = {10.1080/10749030802707861},
	language = {en},
	number = {2},
	urldate = {2022-05-12},
	journal = {Mind, Culture, and Activity},
	author = {Friesen, Norm},
	month = apr,
	year = {2009},
	pages = {130--144},
}

@article{krummheuer_doing_2019,
	title = {Doing {Scheduling}? {The} {Construction} of {Agency} and {Memory} while {Programming} a {Reminder} {Robot} with a {Person} with {Severe} {Brain} {Injury}},
	shorttitle = {Doing {Scheduling}?},
	url = {http://dl.gi.de/handle/20.500.12116/25261},
	doi = {10.18420/MUC2019-WS-647},
	abstract = {The paper argues that the field of human-robot interaction needs a distributed and socially situated understanding of reminding and scheduling practices to meet the needs of people with cognitive disabilities in the design of reminder robots. These results are based on a embodied interaction analysis of video recorded interactions of a co-creation process in which the participants test a reminder-robot prototype that was designed for and with people with acquired brain injury.},
	language = {en},
	urldate = {2022-05-12},
	author = {Krummheuer, Antonia and Rehm, Matthias and Rodil, Kasper},
	year = {2019},
	note = {Publisher: Gesellschaft für Informatik e.V.},
	keywords = {brain injury, care, co-creation, ethnomethodology, memory aid, multimodal interaction analysis, reminding},
}

@article{Muhle2008,
	title = {'versteh ich grad nicht': {Mensch}-maschine-kommunikation als problem},
	volume = {9},
	abstract = {'Der vorliegende Beitrag verortet sich im Forschungsfeld der Mensch-Maschine-Kommunikation. In diesem Kontext werden aus einer ethnomethodologischen Perspektive Situationen untersucht, in denen Menschen versuchen mit dem Roboterhund Aibo zu kommunizieren. Dabei geraten vor allem die vielfältigen Praktiken, mit denen die Menschen versuchen, Verständigungsprobleme zu lösen, in den Fokus. Aufmerksamkeit erhält hier insbesondere das Zusammenspiel verschiedener Kommunikationsmodalitäten (Sprache, Blickrichtung, Körperhaltung). Wie im Verlauf der Arbeit herausgearbeitet wird, zeigen die Daten deutlich, dass angesichts einer für die Menschen vollkommen ungewohnten Situation, Kommunikation in einem hohen Maße problematisch wird. Zudem kann dargelegt werden, dass beim derzeitigen Stand der Technikentwicklung genau darin ein Spezifikum des (ungeübten) Umgangs mit interaktiven Artefakten liegt.' (Autorenreferat)},
	journal = {kommunikation @ gesellschaft},
	author = {Muhle, Florian},
	year = {2008},
	note = {tex.urn: https://nbn-resolving.org/urn:nbn:de:0228-200809014},
	keywords = {Artefakt, Forschungsstand, Interaktion, Kommunikation, Körper, Körpersprache, Mensch, Mensch-Maschine-System, Problem, Roboter, Sprache, Technik, Verstehen, artifact, body, body language, communication, engineering, human being, interaction, language, man-machine system, problem, research status, robot, technical development, technische Entwicklung, understanding},
	pages = {21},
}

@article{b_arend_investigating_2017,
	title = {Investigating {Breakdowns} {In} {Human} {Robot} {Interaction}: {A} {Conversation} {Analysis} {Guided} {Single} {Case} {Study} {Of} {A} {Human}-{Robot} {Communication} {In} {A} {Museum} {Environment}},
	copyright = {Creative Commons Attribution 4.0, Open Access},
	shorttitle = {Investigating {Breakdowns} {In} {Human} {Robot} {Interaction}},
	url = {https://zenodo.org/record/1130169},
	doi = {10.5281/ZENODO.1130169},
	abstract = {In a single case study, we show how a conversation analysis (CA) approach can shed light onto the sequential unfolding of human-robot interaction. Relying on video data, we are able to show that CA allows us to investigate the respective turn-taking systems of humans and a NAO robot in their dialogical dynamics, thus pointing out relevant differences. Our fine grained video analysis points out occurring breakdowns and their overcoming, when humans and a NAO-robot engage in a multimodally uttered multi-party communication during a sports guessing game. Our findings suggest that interdisciplinary work opens up the opportunity to gain new insights into the challenging issues of human robot communication in order to provide resources for developing mechanisms that enable complex human-robot interaction (HRI).},
	language = {en},
	urldate = {2022-05-12},
	author = {B. Arend and P. Sunnen and P. Caire},
	month = mar,
	year = {2017},
	note = {Publisher: Zenodo},
	keywords = {Human-robot interaction, breakdown., conversation analysis, dialogism, museum},
}

@incollection{agah_who_2016,
	address = {Cham},
	title = {Who {Am} {I}? {What} {Are} {You}? {Identity} {Construction} in {Encounters} {Between} a {Teleoperated} {Robot} and {People} with {Acquired} {Brain} {Injury}},
	volume = {9979},
	isbn = {978-3-319-47436-6 978-3-319-47437-3},
	shorttitle = {Who {Am} {I}?},
	url = {http://link.springer.com/10.1007/978-3-319-47437-3_86},
	urldate = {2022-05-12},
	booktitle = {Social {Robotics}},
	publisher = {Springer International Publishing},
	author = {Krummheuer, Antonia L.},
	editor = {Agah, Arvin and Cabibihan, John-John and Howard, Ayanna M. and Salichs, Miguel A. and He, Hongsheng},
	year = {2016},
	doi = {10.1007/978-3-319-47437-3_86},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {880--889},
}

@inproceedings{cyra_dealing_2017,
	address = {Bielefeld Germany},
	title = {Dealing with {Long} {Utterances}: {How} to {Interrupt} the {User} in a {Socially} {Acceptable} {Manner}?},
	isbn = {978-1-4503-5113-3},
	shorttitle = {Dealing with {Long} {Utterances}},
	url = {https://dl.acm.org/doi/10.1145/3125739.3132586},
	doi = {10.1145/3125739.3132586},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Human} {Agent} {Interaction}},
	publisher = {ACM},
	author = {Cyra, Katharina and Pitsch, Karola},
	month = oct,
	year = {2017},
	pages = {341--345},
}

@inproceedings{pitsch_interactional_2017,
	address = {Bielefeld Germany},
	title = {Interactional {Dynamics} in {User} {Groups}: {Answering} a {Robot}'s {Question} in {Adult}-{Child} {Constellations}},
	isbn = {978-1-4503-5113-3},
	shorttitle = {Interactional {Dynamics} in {User} {Groups}},
	url = {https://dl.acm.org/doi/10.1145/3125739.3132604},
	doi = {10.1145/3125739.3132604},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Human} {Agent} {Interaction}},
	publisher = {ACM},
	author = {Pitsch, Karola and Gehle, Raphaela and Dankert, Timo and Wrede, Sebastian},
	month = oct,
	year = {2017},
	pages = {393--397},
}

@article{reeves_this_2018,
	title = {'{This} is not what we wanted': designing for conversation with voice interfaces},
	volume = {26},
	issn = {1072-5520, 1558-3449},
	shorttitle = {'{This} is not what we wanted'},
	url = {https://dl.acm.org/doi/10.1145/3296699},
	doi = {10.1145/3296699},
	language = {en},
	number = {1},
	urldate = {2022-05-12},
	journal = {Interactions},
	author = {Reeves, Stuart and Porcheron, Martin and Fischer, Joel},
	month = dec,
	year = {2018},
	pages = {46--51},
}

@article{pitsch_robot_2013,
	title = {Robot feedback shapes the tutor’s presentation: {How} a robot’s online gaze strategies lead to micro-adaptation of the human’s conduct},
	volume = {14},
	issn = {1572-0373, 1572-0381},
	shorttitle = {Robot feedback shapes the tutor’s presentation},
	url = {http://www.jbe-platform.com/content/journals/10.1075/is.14.2.06pit},
	doi = {10.1075/is.14.2.06pit},
	abstract = {The paper investigates the effects of a humanoid robot’s online feedback during a tutoring situation in which a human demonstrates how to make a frog jump across a table. Motivated by micro-analytic studies of adult-child-interaction, we investigated whether tutors react to a robot’s gaze strategies while they are presenting an action. And if so, how they would adapt to them. Analysis reveals that tutors adjust typical “motionese” parameters (pauses, speed, and height of motion). We argue that a robot – when using adequate online feedback strategies – has at its disposal an important resource with which it could proactively shape the tutor’s presentation and help generate the input from which it would benefit most. These results advance our understanding of robotic “Social Learning” in that they suggest a paradigm shift towards considering human and robot as one interational learning system. Keywords: human-robot-interaction; feedback; adaptation; multimodality; gaze; conversation analysis; social learning; pro-active robot conduct},
	language = {en},
	number = {2},
	urldate = {2022-05-12},
	journal = {Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems},
	author = {Pitsch, Karola and Vollmer, Anna-Lisa and Mühlig, Manuel},
	month = aug,
	year = {2013},
	pages = {268--296},
}

@article{yamazaki_interactions_2013,
	title = {Interactions between a quiz robot and multiple participants: {Focusing} on speech, gaze and bodily conduct in {Japanese} and {English} speakers},
	volume = {14},
	issn = {1572-0373, 1572-0381},
	shorttitle = {Interactions between a quiz robot and multiple participants},
	url = {http://www.jbe-platform.com/content/journals/10.1075/is.14.3.04yam},
	doi = {10.1075/is.14.3.04yam},
	abstract = {This paper reports on a quiz robot experiment in which we explore similarities and differences in human participant speech, gaze, and bodily conduct in responding to a robot’s speech, gaze, and bodily conduct across two languages. Our experiment involved three-person groups of Japanese and English-speaking participants who stood facing the robot and a projection screen that displayed pictures related to the robot’s questions. The robot was programmed so that its speech was coordinated with its gaze, body position, and gestures in relation to transition relevance places (TRPs), key words, and deictic words and expressions (e.g. this, this picture) in both languages. Contrary to findings on human interaction, we found that the frequency of English speakers’ head nodding was higher than that of Japanese speakers in human-robot interaction (HRI). Our findings suggest that the coordination of the robot’s verbal and non-verbal actions surrounding TRPs, key words, and deictic words and expressions is important for facilitating HRI irrespective of participants’ native language. Keywords: coordination of verbal and non-verbal actions; robot gaze comparison between English and Japanese; human-robot interaction (HRI); transition relevance place (TRP); conversation analysis},
	language = {en},
	number = {3},
	urldate = {2022-05-12},
	journal = {Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems},
	author = {Yamazaki, Akiko and Yamazaki, Keiichi and Ikeda, Keiko and Burdelski, Matthew and Fukushima, Mihoko and Suzuki, Tomoyuki and Kurihara, Miyuki and Kuno, Yoshinori and Kobayashi, Yoshinori},
	month = dec,
	year = {2013},
	pages = {366--389},
}

@article{lohse_improving_2009,
	title = {Improving {HRI} design by applying {Systemic} {Interaction} {Analysis} ({SInA})},
	volume = {10},
	issn = {1572-0373, 1572-0381},
	url = {http://www.jbe-platform.com/content/journals/10.1075/is.10.3.03loh},
	doi = {10.1075/is.10.3.03loh},
	abstract = {Social robots are designed to interact with humans. That is why they need interaction models that take social behaviors into account. These usually influence many of a robot’s abilities simultaneously. Hence, when designing robots that users will want to interact with, all components need to be tested in the system context, with real users and real tasks in real interactions. This requires methods that link the analysis of the robot’s internal computations within and between components (system level) with the interplay between robot and user (interaction level). This article presents Systemic Interaction Analysis (SInA) as an integrated method to (a) derive prototypical courses of interaction based on system and interaction level, (b) identify deviations from these, (c) infer the causes of deviations by analyzing the system’s operational sequences, and (d) improve the robot iteratively by adjusting models and implementations.
              Keywords:
              analysis tools, user studies, autonomous robots},
	language = {en},
	number = {3},
	urldate = {2022-05-12},
	journal = {Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems},
	author = {Lohse, Manja and Hanheide, Marc and Pitsch, Karola and Rohlfing, Katharina J. and Sagerer, Gerhard},
	month = dec,
	year = {2009},
	pages = {298--323},
}

@article{robins_robot-mediated_2004,
	title = {Robot-mediated joint attention in children with autism: {A} case study in robot-human interaction},
	volume = {5},
	issn = {1572-0373, 1572-0381},
	shorttitle = {Robot-mediated joint attention in children with autism},
	url = {http://www.jbe-platform.com/content/journals/10.1075/is.5.2.02rob},
	doi = {10.1075/is.5.2.02rob},
	abstract = {Interactive robots are used increasingly not only in entertainment and service robotics, but also in rehabilitation, therapy and education. The work presented in this paper is part of the Aurora project, rooted in assistive technology and robot-human interaction research. Our primary aim is to study if robots can potentially be used as therapeutically or educationally useful ‘toys’. In this paper we outline the aims of the project that this study belongs to, as well as the specific qualitative contextual perspective that is being used. We then provide an in-depth evaluation, in part using Conversation Analysis (CA), of segments of trials where three children with autism interacted with a robot as well as an adult. We focus our analysis primarily on joint attention which plays a fundamental role in human development and social understanding. Joint attention skills of children with autism have been studied extensively in autism research and therefore this behaviour provides a relevant focus for our study. In the setting used, joint attention emerges from natural and spontaneous interactions between a child and an adult. We present the data in the form of transcripts and photo stills. The examples were selected from extensive video footage for illustrative purposes, i.e. demonstrating how children with autism can respond to the changing behaviour of their co-participant, i.e. the experimenter. Furthermore, our data shows that the robot provides a salient object, or mediator for joint attention. The paper concludes with a discussion of implications of this work in the context of further studies with robots and children with autism within the Aurora project, as well as the potential contribution of robots to research into the nature of autism.},
	language = {en},
	number = {2},
	urldate = {2022-05-12},
	journal = {Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems},
	author = {Robins, Ben and Dickerson, Paul and Stribling, Penny and Dautenhahn, Kerstin},
	month = sep,
	year = {2004},
	pages = {161--198},
}

@article{whelan_toward_2018,
	title = {Toward the {Development} of {SMART} {Communication} {Technology}: {Automating} the {Analysis} of {Communicative} {Trouble} and {Repair} in {Dementia}},
	volume = {2},
	issn = {2399-5300},
	shorttitle = {Toward the {Development} of {SMART} {Communication} {Technology}},
	url = {https://academic.oup.com/innovateage/article/doi/10.1093/geroni/igy034/5228999},
	doi = {10.1093/geroni/igy034},
	language = {en},
	number = {3},
	urldate = {2022-05-12},
	journal = {Innovation in Aging},
	author = {Whelan, Brooke-Mai and Angus, Daniel and Wiles, Janet and Chenery, Helen J and Conway, Erin R and Copland, David A and Atay, Christina and Angwin, Anthony J},
	month = sep,
	year = {2018},
}

@incollection{greif_herausforderung_2008,
	address = {Wiesbaden},
	title = {Herausforderung künstlicher {Handlungsträgerschaft}.},
	isbn = {978-3-8350-7007-3 978-3-8350-5492-9},
	url = {http://link.springer.com/10.1007/978-3-8350-5492-9_5},
	language = {de},
	urldate = {2022-05-12},
	booktitle = {Information und {Gesellschaft}},
	publisher = {VS Verlag für Sozialwissenschaften},
	author = {Krummheuer, Antonia L.},
	editor = {Greif, Hajo and Mitrea, Oana and Werner, Matthias},
	year = {2008},
	doi = {10.1007/978-3-8350-5492-9_5},
	pages = {73--95},
}

@incollection{abascal_users_2015,
	address = {Cham},
	title = {Users, {Bystanders} and {Agents}: {Participation} {Roles} in {Human}-{Agent} {Interaction}},
	volume = {9299},
	isbn = {978-3-319-22722-1 978-3-319-22723-8},
	shorttitle = {Users, {Bystanders} and {Agents}},
	url = {http://link.springer.com/10.1007/978-3-319-22723-8_19},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2015},
	publisher = {Springer International Publishing},
	author = {Krummheuer, Antonia L.},
	editor = {Abascal, Julio and Barbosa, Simone and Fetter, Mirko and Gross, Tom and Palanque, Philippe and Winckler, Marco},
	year = {2015},
	doi = {10.1007/978-3-319-22723-8_19},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {240--247},
}

@inproceedings{krummheuer_triadic_2020,
	address = {Cambridge United Kingdom},
	title = {Triadic {Human}-{Robot} {Interaction}. {Distributed} {Agency} and {Memory} in {Robot} {Assisted} {Interactions}},
	isbn = {978-1-4503-7057-8},
	url = {https://dl.acm.org/doi/10.1145/3371382.3378269},
	doi = {10.1145/3371382.3378269},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Companion of the 2020 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Krummheuer, Antonia Lina and Rehm, Matthias and Rodil, Kasper},
	month = mar,
	year = {2020},
	pages = {317--319},
}

@inproceedings{pelikan_are_2020,
	address = {Cambridge United Kingdom},
	title = {"{Are} {You} {Sad}, {Cozmo}?": {How} {Humans} {Make} {Sense} of a {Home} {Robot}'s {Emotion} {Displays}},
	isbn = {978-1-4503-6746-2},
	shorttitle = {"{Are} {You} {Sad}, {Cozmo}?},
	url = {https://dl.acm.org/doi/10.1145/3319502.3374814},
	doi = {10.1145/3319502.3374814},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 2020 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Pelikan, Hannah R. M. and Broth, Mathias and Keevallik, Leelo},
	month = mar,
	year = {2020},
	pages = {461--470},
}

@inproceedings{Pelikan2020,
	title = {Intermediate-level knowledge: {A} conversation analysis perspective},
	url = {http://hridesign.eu/assets/pdf/Pelikan.pdf},
	booktitle = {First international workshop on designerly {HRI} knowledge. {Held} in conjunction with the 29th {IEEE} international conference on robot and human interactive communication ({RO}-{MAN} 2020)},
	author = {Pelikan, Hannah R. M.},
	year = {2020},
	keywords = {AI Reference List, Conversation analysis, EMCA, Human-robot interaction, Intermediate-level knowledge},
}

@article{Muhle2016,
	title = {"{Are} you human?": {Plädoyer} für eine kommunikationstheoretische fundierung interpretativer forschung an den grenzen des sozialen},
	volume = {17},
	issn = {1438-5627},
	abstract = {Im Zentrum von Soziologie im Allgemeinen und interpretativer Sozialforschung im Besonderen stehen in der Regel unhinterfragt Menschen und ihre Weltdeutungen. In aktuellen sozialtheoretischen Debatten und empirischen Forschungen wird die Zentralstellung des Menschen in soziologischen Analysen jedoch zunehmend infrage gestellt. Vor diesem Hintergrund geht der vorliegende Beitrag der Frage nach, wie Sozialität jenseits der Fixierung auf menschliche Akteur/innen konzipiert werden kann und wie sich Grenzziehungen zwischen Sozialem und Nicht-Sozialem in gegenstandsangemessener Perspektive untersuchen lassen. Hierzu werden in Auseinandersetzung mit konkurrierenden Überlegungen (insbesondere der Akteur-Netzwerk-Theorie und Ansätzen, die subjektive Sichtweisen von Akteuren und Akteurinnen fokussieren), eine kommunikationstheoretische Perspektive auf die Grenzen des Sozialen und eine darauf aufbauende Methodologie entwickelt, die ergebnisoffene Forschung an und zu den Grenzen des Sozialen anleiten können. Wie sich entsprechende empirische Analysen konkret umsetzen lassen, wird exemplarisch an einem Fall der Mensch-Maschine-Kommunikation in einer virtuellen Welt gezeigt. (Autorenreferat)Sociology in general and interpretive social research in particular are regarded as human sciences. However, this human-centered perspective has recently been questioned as an "anthropological bias", both by debates within social theory and empirical research on non-human agency. Against this background, I address the question of how the anthropological bias in sociology can be overcome and what empirical analysis should look like that deals with non-human agency and the borders of the social. Drawing on competing approaches, namely actor-network theory and actor-centered methodologies, I argue for an analytical perspective that is based on a Luhmannian approach to communication theory and methodology. The thesis is that communication theory offers an appropriate methodological toolbox for symmetrical and open-ended analysis of social border phenomena. In order to demonstrate the potential of the discussed tools, I close with an analysis of a human-machine encounter in a virtual world. (author's abstract)},
	number = {1},
	journal = {Forum Qualitative Sozialforschung / Forum: Qualitative Social Research},
	author = {Muhle, Florian},
	year = {2016},
	note = {tex.urn: https://nbn-resolving.org/urn:nbn:de:0114-fqs1601183},
	keywords = {Akteur-Netzwerk-Theorie, Kommunikationstheorie, Mensch-Maschine-System, Methodologie, actor-network-theory, artificial intelligence, communication theory, interpretative sociology, künstliche Intelligenz, man-machine system, methodology, social position, soziale Position, verstehende Soziologie, virtual reality, virtuelle Realität},
	pages = {33},
}

@article{sormani_philippe_diy_2020,
	title = {'{DIY} {AI}'? {Practising} kit assembly, locating critical inquiry},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International, Open Access},
	shorttitle = {'{DIY} {AI}'?},
	url = {https://zenodo.org/record/4050539},
	doi = {10.5281/ZENODO.4050539},
	abstract = {This paper presents a reflexive ethnography of ‘DIY AI’ underway. Part 1 examines a promotional video of Google’s ‘AIY Vision Kit’, its ‘do-it-yourself intelligent camera’, running on a Raspberry Pi computer and fitting into an 4.7´7.5´7.6 cm cardboard box. Part 2 of the paper, in turn, reports on our initial effort at kit assembly with the help of the user manual. In particular, I shall home in on our ‘turn it on’ attempt, as a first ‘step condition’ to operate the assembled kit ‘intelligently’—that is, for ‘experiment[ing] with image recognition using neural networks’ (Google 2018). The reflexive ethnography pursues two aims. First, it shall make explicit (some of) the ‘vulgar enabling practices’ (Button and Sharrock 1995) of the probed ‘intelligent camera’. Second, the ethnography will revisit the interplay between ‘technical work and critical inquiry’ (Lynch 1982) by locating how, when, and why the former invited the latter in situ. Recent reflection on critical inquiry in and across STS (e.g., Mirowski 2020), algorithm studies (e.g., Mackenzie 2017), and social and cultural studies more broadly (e.g., Tsilipakos 2018), will be practically indexed and recast accordingly. So will critical inquiry in matters of ‘DIY (AI)’ more specifically.},
	urldate = {2022-05-12},
	author = {Sormani, Philippe},
	month = sep,
	year = {2020},
	note = {Publisher: Zenodo},
}

@article{brooker_new_2019,
	title = {The new ghosts in the machine: '{Pragmatist}' {AI} and the conceptual perils of anthropomorphic description},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International, Open Access},
	shorttitle = {The new ghosts in the machine},
	url = {https://zenodo.org/record/3459327},
	doi = {10.5281/ZENODO.3459327},
	abstract = {Algorithms are becoming interwoven with increasingly many aspects of our affairs.{\textless}br{\textgreater} That process of interweaving has brought with it a language laden with anthropomorphic{\textless}br{\textgreater} descriptions of the technologies involved, which variously hint at ‘humanesque’{\textless}br{\textgreater} or ‘conscious-like’ activity occurring within or behind their operations. Indeed,{\textless}br{\textgreater} the term ‘Artificial Intelligence’ (AI) seems to refer to a quality that is thought{\textless}br{\textgreater} to be largely human; namely, intelligence. However, while anthropomorphic descriptions{\textless}br{\textgreater} may be useful or harmless, when taken at face value they generate a false{\textless}br{\textgreater} picture of algorithms as well as of our own thinking and reasoning practices by{\textless}br{\textgreater} treating them as analogues of one another rather than as distinct. Focusing on the{\textless}br{\textgreater} algorithm, and what it is misleadingly said to be and to be like, in this article we{\textless}br{\textgreater} outline three ‘perspicuous representations’ (Wittgenstein 1953: §122) of AI in specific{\textless}br{\textgreater} contexts. Drawing on Wes Sharrock’s ethnomethodological and Wittgensteinian{\textless}br{\textgreater} work, our aim is to demonstrate that by attending to the particular, occasioned{\textless}br{\textgreater} and locally accountable, not to say highly specified, usages of language that accompany{\textless}br{\textgreater} the ‘New AI’ in particular, we can avoid being haunted by the new task performing{\textless}br{\textgreater} ghosts currently being discursively conjured up in our algorithmic machines.},
	urldate = {2022-05-12},
	author = {Brooker, Phillip and Dutton, William and Mair, Michael},
	month = oct,
	year = {2019},
	note = {Publisher: Zenodo},
}

@inproceedings{albert_case_2019,
	address = {Dublin, Ireland},
	title = {In case of emergency, order pizza: an urgent case of action formation and recognition},
	isbn = {978-1-4503-7187-2},
	shorttitle = {In case of emergency, order pizza},
	url = {http://dl.acm.org/citation.cfm?doid=3342775.3342800},
	doi = {10.1145/3342775.3342800},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 1st {International} {Conference} on {Conversational} {User} {Interfaces}  - {CUI} '19},
	publisher = {ACM Press},
	author = {Albert, Saul and Housley, William and Stokoe, Elizabeth},
	year = {2019},
	pages = {1--2},
}

@inproceedings{reeves_conversation_2019,
	address = {Dublin, Ireland},
	title = {Conversation considered harmful?},
	isbn = {978-1-4503-7187-2},
	url = {http://dl.acm.org/citation.cfm?doid=3342775.3342796},
	doi = {10.1145/3342775.3342796},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 1st {International} {Conference} on {Conversational} {User} {Interfaces} - {CUI} '19},
	publisher = {ACM Press},
	author = {Reeves, Stuart},
	year = {2019},
	pages = {1--3},
}

@article{porcheron_pulling_2021,
	title = {Pulling {Back} the {Curtain} on the {Wizards} of {Oz}},
	volume = {4},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3432942},
	doi = {10.1145/3432942},
	abstract = {The Wizard of Oz method is an increasingly common practice in HCI and CSCW studies as part of iterative design processes for interactive systems. Instead of designing a fully-fledged system, the 'technical work' of key system components is completed by human operators yet presented to study participants as if computed by a machine. However, little is known about how Wizard of Oz studies are interactionally and collaboratively achieved in situ by researchers and participants. By adopting an ethnomethodological perspective, we analyse our use of the method in studies with a voice-controlled vacuum robot and two researchers present. We present data that reveals how such studies are organised and presented to participants and unpack the coordinated orchestration work that unfolds 'behind the scenes' to complete the study. We examine how the researchers attend to participant requests and technical breakdowns, and discuss the performative, collaborative, and methodological nature of their work. We conclude by offering insights from our application of the approach to others in the HCI and CSCW communities for using the method.},
	language = {en},
	number = {CSCW3},
	urldate = {2022-05-12},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Porcheron, Martin and Fischer, Joel E. and Reeves, Stuart},
	month = jan,
	year = {2021},
	pages = {1--22},
}

@inproceedings{porcheron_animals_2017,
	address = {Portland Oregon USA},
	title = {"{Do} {Animals} {Have} {Accents}?": {Talking} with {Agents} in {Multi}-{Party} {Conversation}},
	isbn = {978-1-4503-4335-0},
	shorttitle = {"{Do} {Animals} {Have} {Accents}?},
	url = {https://dl.acm.org/doi/10.1145/2998181.2998298},
	doi = {10.1145/2998181.2998298},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 2017 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} and {Social} {Computing}},
	publisher = {ACM},
	author = {Porcheron, Martin and Fischer, Joel E. and Sharples, Sarah},
	month = feb,
	year = {2017},
	pages = {207--219},
}

@article{krummheuer_participating_2016,
	title = {Participating with limited communication means: {Conversation} analytical perspectives on the interactional management of participation structures},
	volume = {30},
	issn = {0269-9206, 1464-5076},
	shorttitle = {Participating with limited communication means},
	url = {https://www.tandfonline.com/doi/full/10.1080/02699206.2016.1225124},
	doi = {10.1080/02699206.2016.1225124},
	language = {en},
	number = {10},
	urldate = {2022-05-12},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Krummheuer, Antonia Lina and Klippi, Anu and Raudaskoski, Pirkko Liisa and Samuelsson, Christina},
	month = oct,
	year = {2016},
	pages = {721--729},
}

@article{krummheuer_trying-out_2016,
	title = {Trying-out a walking help: {Participation} through situated learning in the adjustment and assessment of welfare technology},
	volume = {30},
	issn = {0269-9206, 1464-5076},
	shorttitle = {Trying-out a walking help},
	url = {https://www.tandfonline.com/doi/full/10.1080/02699206.2016.1209245},
	doi = {10.1080/02699206.2016.1209245},
	language = {en},
	number = {10},
	urldate = {2022-05-12},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Krummheuer, Antonia Lina and Raudaskoski, Pirkko Liisa},
	month = oct,
	year = {2016},
	pages = {812--831},
}

@article{wooffitt_applying_1994,
	title = {Applying {Sociology}: {Conversation} {Analysis} in the {Study} of {Human}-({Simulated}) {Computer} {Interaction1}},
	volume = {43},
	issn = {0759-1063, 2070-2779},
	shorttitle = {Applying {Sociology}},
	url = {http://journals.sagepub.com/doi/10.1177/075910639404300103},
	doi = {10.1177/075910639404300103},
	abstract = {Application de la sociologie: Analyse de conversation pour l'étude de l'interaction ordinateur (simulé) - homme. Beaucoup de recherches récentes ont porté sur le dessin de systèmes de communication verbal homme-ordinateur conviviaux. Cependant, on rencontre un problème du type "la poule et l'oeuf': comment les dessinateurs de systèmes peuvent savoir de quelle manière les gens réagissent à un ordinateur qui parle et quelles seront leurs exigences; et comment peut-on construire un système expérimental avant de comprendre le comportement et les exigences des utilisateurs? Cet article présente deux réponses méthodologiques à ce dilemme trouvées par des chercheurs du département de sociologie de l'université de Surrey en Angleterre. On présente d'abord une simulation "sorcier d'Oz" ("Wizard of Oz"). Celle-ci implique l'utilisation d'une complice (le "sorcier") dont la voix est déguisée électroniquement comme celle d'un ordinateur qui parle. Des sujets de l'expérience croient qu'ils sont en interaction avec une machine. Ces échanges sont enregistrés et ensuite analysés pour faire ressortir des informations concernant les exigences des utilisateurs et les compétences communicatives nécessaires. Ensuite, il y a une discussion sur l'adéquation d'une approche qualitative de l'analyse de conversation pour l'étude des données collectées par ces expériences. Les sections analytiques de l'article concernent deux stratégies de communication utilisées par des sujets pour identifier et gérer des sources possible de problèmes dans l'échange avec le "système". Cette analyse examine l'organisation de ces stratégies et discute de leurs apports à la communication.},
	language = {en},
	number = {1},
	urldate = {2022-05-12},
	journal = {Bulletin of Sociological Methodology/Bulletin de Méthodologie Sociologique},
	author = {Wooffitt, Robin},
	month = jun,
	year = {1994},
	pages = {7--33},
}

@article{thomas_language_1991,
	title = {Language, communication, social interaction and the design of human-computer interfaces},
	volume = {10},
	issn = {0144-929X, 1362-3001},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01449299108924292},
	doi = {10.1080/01449299108924292},
	language = {en},
	number = {4},
	urldate = {2022-05-12},
	journal = {Behaviour \& Information Technology},
	author = {Thomas, Peter J.},
	month = jul,
	year = {1991},
	pages = {311--324},
}

@article{ferm_participation_2015,
	title = {Participation and {Enjoyment} in {Play} with a {Robot} between {Children} with {Cerebral} {Palsy} who use {AAC} and their {Peers}},
	volume = {31},
	issn = {0743-4618, 1477-3848},
	url = {http://www.tandfonline.com/doi/full/10.3109/07434618.2015.1029141},
	doi = {10.3109/07434618.2015.1029141},
	language = {en},
	number = {2},
	urldate = {2022-05-12},
	journal = {Augmentative and Alternative Communication},
	author = {Ferm, Ulrika M. and Claesson, Britt K. and Ottesjö, Cajsa and Ericsson, Stina},
	month = apr,
	year = {2015},
	pages = {108--123},
}

@article{wilf_separating_2019,
	title = {Separating noise from signal:: {The} ethnomethodological uncanny as aesthetic pleasure in human‐machine interaction in the {United} {States}},
	volume = {46},
	issn = {0094-0496, 1548-1425},
	shorttitle = {Separating noise from signal},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/amet.12761},
	doi = {10.1111/amet.12761},
	language = {en},
	number = {2},
	urldate = {2022-05-12},
	journal = {American Ethnologist},
	author = {Wilf, Eitan},
	month = may,
	year = {2019},
	pages = {202--213},
}

@article{alac_social_2016,
	title = {Social robots: {Things} or agents?},
	volume = {31},
	issn = {0951-5666, 1435-5655},
	shorttitle = {Social robots},
	url = {http://link.springer.com/10.1007/s00146-015-0631-6},
	doi = {10.1007/s00146-015-0631-6},
	language = {en},
	number = {4},
	urldate = {2022-05-12},
	journal = {AI \& SOCIETY},
	author = {Alač, Morana},
	month = nov,
	year = {2016},
	pages = {519--535},
}

@incollection{mcilvenny_communicative_1990,
	title = {Communicative {Action} and {Computers}},
	isbn = {978-0-08-050264-9},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780080502649500105},
	language = {en},
	urldate = {2022-05-12},
	booktitle = {Computers and {Conversation}},
	publisher = {Elsevier},
	author = {McIlvenny, Paul},
	year = {1990},
	doi = {10.1016/B978-0-08-050264-9.50010-5},
	pages = {91--132},
}

@article{ala_zeigt_2016,
	title = {Zeigt auf den {Roboter} und schüttelt dessen {Hand}. {Intimität} als situativ gebundene interaktionale {Unterstützung} von {Humantechnologien}},
	issn = {1869-1722},
	url = {https://mediarep.org/handle/doc/2594},
	doi = {10.25969/MEDIAREP/1902},
	abstract = {This paper deals with the problem of digital media and intimacy by focusing on the domain of social robotics. Based in an ethnographic study of laboratories of social robotics, intimacy, in this context, concerns the situated maintenance of technology intended as ‹social›. The article points out how robots are enacted as social and how they gain their own agency through an intertwining of their bodies with multimodal and multisensory elements of multiparty action in specific situations of design and use. Drawing from video-recordings of everyday practice, the article indicates how this takes place in the interactional and sensory realm, focusing on coordination of gesture, talk, body orientation, tactile engagement, spatial organization and arrangements of things and human bodies in laboratory work. This idea of intimacy is contrasted with the «distance» that is characteristic of the situations where the human-robot relationship is reduced to the ocular mode and often results in violence or its spectacularization. The paper points out how considering a social robot in respect to the situation in which it is immersed and regarding those present at the scene has consequences for the commonly assumed idea of self and agency.},
	urldate = {2022-05-12},
	author = {Ala, Morana},
	collaborator = {Mediarep.Org and Mediarep.Org},
	year = {2016},
	note = {Publisher: diaphanes},
	keywords = {302.23, Ethnomethodologie, Gewalt, Interaktion, Robotik, Situiertheit, agency},
}

@inproceedings{2e1be8395a2b4f6db54b4ba1fddc7c1f,
	title = {Technisierte {Sequenzen}? {Zeit} und {Sozialität} in hybriden {Austauschprozessen} zwischen {Mensch} und virtuellem {Agenten}},
	isbn = {978-3-531-92035-1},
	language = {Tysk},
	booktitle = {Unsichere {Zeiten} {Herausforderungen} gesellschaftlicher {Transformationen}. {Verhandlungen} des 34. {Kongresses} der {Deutschen} {Gesellschaft} für {Soziologie} in {Jena} 2008},
	publisher = {VS-Verlag Sozialwissenschaften},
	author = {Krummheuer, Antonia Lina},
	editor = {Soeffner, Hans-Georg},
	year = {2010},
}

@article{pal_trust_2020,
	title = {To {Trust} or {Not}-{Trust}: {Privacy} {Issues} {With} {Voice} {Assistants}},
	volume = {22},
	issn = {1941-045X},
	shorttitle = {To {Trust} or {Not}-{Trust}},
	doi = {10.1109/MITP.2019.2958914},
	abstract = {The use of commercially available voice assistants (VA) that enable personal data collection on a large scale is on the rise. However, knowledge discovery on such data can lead to the violation of various privacy issues. This article presents the various stakeholders who are a part of this privacy regime, along with a detailed taxonomy of the various privacy issues existing currently in the VA world. This is supplemented by a privacy preserving trust model that discusses the various antecedents of the privacy issues identified, which will enable the end-users to have a greater level of trust in using the VA.},
	number = {5},
	journal = {IT Professional},
	author = {Pal, Debajyoti and Arpnikanondt, Chonlameth and Razzaque, Mohammad Abdur and Funilkul, Suree},
	month = sep,
	year = {2020},
	note = {Conference Name: IT Professional},
	keywords = {Computer security, Data collection, Data privacy, Government, Privacy, Stakeholders, Taxonomy},
	pages = {46--53},
}

@inproceedings{christakopoulou_towards_2016,
	address = {New York, NY, USA},
	series = {{KDD} '16},
	title = {Towards {Conversational} {Recommender} {Systems}},
	isbn = {978-1-4503-4232-2},
	url = {https://doi.org/10.1145/2939672.2939746},
	doi = {10.1145/2939672.2939746},
	abstract = {People often ask others for restaurant recommendations as a way to discover new dining experiences. This makes restaurant recommendation an exciting scenario for recommender systems and has led to substantial research in this area. However, most such systems behave very differently from a human when asked for a recommendation. The goal of this paper is to begin to reduce this gap. In particular, humans can quickly establish preferences when asked to make a recommendation for someone they do not know. We address this cold-start recommendation problem in an online learning setting. We develop a preference elicitation framework to identify which questions to ask a new user to quickly learn their preferences. Taking advantage of latent structure in the recommendation space using a probabilistic latent factor model, our experiments with both synthetic and real world data compare different types of feedback and question selection strategies. We find that our framework can make very effective use of online user feedback, improving personalized recommendations over a static model by 25\% after asking only 2 questions. Our results demonstrate dramatic benefits of starting from offline embeddings, and highlight the benefit of bandit-based explore-exploit strategies in this setting.},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Christakopoulou, Konstantina and Radlinski, Filip and Hofmann, Katja},
	month = aug,
	year = {2016},
	keywords = {cold-start, online learning, recommender systems},
	pages = {815--824},
}

@inproceedings{saglam_is_2020,
	address = {New York, NY, USA},
	series = {{CUI} '20},
	title = {Is your chatbot {GDPR} compliant? {Open} issues in agent design},
	isbn = {978-1-4503-7544-3},
	shorttitle = {Is your chatbot {GDPR} compliant?},
	url = {https://doi.org/10.1145/3405755.3406131},
	doi = {10.1145/3405755.3406131},
	abstract = {Conversational agents open the world to new opportunities for human interaction and ubiquitous engagement. As their conversational abilities and knowledge has improved, these agents have begun to have access to an increasing variety of personally identifiable information and intimate details on their user base. This access raises crucial questions in light of regulations as robust as the General Data Protection Regulation (GDPR). This paper explores some of these questions, with the aim of defining relevant open issues in conversational agent design. We hope that this work can provoke further research into building agents that are effective at user interaction, but also respectful of regulations and user privacy.},
	urldate = {2022-05-12},
	booktitle = {Proceedings of the 2nd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Sağlam, Rahime Belen and Nurse, Jason R. C.},
	month = jul,
	year = {2020},
	keywords = {Conversational agents, chatbot design, general data protection regulation (GDPR), personal information, user privacy},
	pages = {1--3},
}

@article{hendrickx_take_nodate,
	title = {Take {Back} {Control}: {User} {Privacy} and {Transparency} {Concerns} in {Personalized} {Conversational} {Agents}},
	abstract = {We reflect on user privacy concerns, transparency and informed consent for long-term interactions with personalized conversational agents. We argue that the common practice of asking users to sign an informed consent form is insufficient to accommodate the privacy concerns of the user. We propose that long-term engaging personalized conversational agents must include an explicit mechanism in their conversations to allow users to have control over their personal information and to have transparency, i.e. about what is stored and who is allowed to view the stored personal information.},
	language = {en},
	author = {Hendrickx, Iris},
	pages = {6},
}

@inproceedings{ischen_privacy_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Privacy {Concerns} in {Chatbot} {Interactions}},
	isbn = {978-3-030-39540-7},
	doi = {10.1007/978-3-030-39540-7_3},
	abstract = {Chatbots are increasingly used in a commercial context to make product- or service-related recommendations. By doing so, they collect personal information of the user, similar to other online services. While privacy concerns in an online (website-) context are widely studied, research in the context of chatbot-interaction is lacking. This study investigates the extent to which chatbots with human-like cues influence perceptions of anthropomorphism (i.e., attribution of human-like characteristics), privacy concerns, and consequently, information disclosure, attitudes and recommendation adherence. Findings show that a human-like chatbot leads to more information disclosure, and recommendation adherence mediated by higher perceived anthropomorphism and subsequently, lower privacy concerns in comparison to a machine-like chatbot. This result does not hold in comparison to a website; human-like chatbot and website were perceived as equally high in anthropomorphism. The results show the importance of both mediating concepts in regards to attitudinal and behavioral outcomes when interacting with chatbots.},
	language = {en},
	booktitle = {Chatbot {Research} and {Design}},
	publisher = {Springer International Publishing},
	author = {Ischen, Carolin and Araujo, Theo and Voorveld, Hilde and van Noort, Guda and Smit, Edith},
	editor = {Følstad, Asbjørn and Araujo, Theo and Papadopoulos, Symeon and Law, Effie Lai-Chong and Granmo, Ole-Christoffer and Luger, Ewa and Brandtzaeg, Petter Bae},
	year = {2020},
	keywords = {Anthropomorphism, Chatbots, Privacy concerns},
	pages = {34--48},
}

@inproceedings{herder_privacy_2020,
	address = {Genoa Italy},
	title = {Privacy {Dashboards}: {The} {Impact} of the {Type} of {Personal} {Data} and {User} {Control} on {Trust} and {Perceived} {Risk}},
	isbn = {978-1-4503-7950-2},
	shorttitle = {Privacy {Dashboards}},
	url = {https://dl.acm.org/doi/10.1145/3386392.3399557},
	doi = {10.1145/3386392.3399557},
	abstract = {Website owners often collect personal data to, among other things, advertise more efficiently and to analyze and increase sales. They can inform users in various ways about what data they collect and how they process it. This study focuses on the use of privacy dashboards, which are increasingly present on websites, but not very well studied yet. In this study, making use of an experimental webshop and various interviews, we investigate which elements of privacy dashboards increase customers’ trust and reduce the perceived privacy risks. The results indicate that the presence of derived data, such as average values or profile classifications, had a more negative impact on trust and perceived privacy risk than inferred data, such as interest probabilities – and both categories had a larger impact than provided and observed, unprocessed user data. Further, it emerges that a greater degree of control leads to a somewhat greater trust. The study confirms the benefits of a privacy dashboard in addition to a privacy policy and provides guidelines on the level of abstraction on which user data should be presented.},
	language = {en},
	urldate = {2022-05-11},
	booktitle = {Adjunct {Publication} of the 28th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Herder, Eelco and van Maaren, Olaf},
	month = jul,
	year = {2020},
	pages = {169--174},
}

@article{wahlster_dialogue-based_1986,
	title = {Dialogue-based user models},
	volume = {74},
	issn = {1558-2256},
	doi = {10.1109/PROC.1986.13574},
	abstract = {The paper investigates several approaches to user modeling in natural-language dialogue systems. First, reasons are pointed out why user modeling has become so important in the last few years, and definitions are proposed for the notions of "user model" and "user modeling component." Then, techniques for constructing user models in the course of a dialogue are presented and recent proposals for representing a wide range of assumptions about a user's beliefs and goals in a system's knowledge base are surveyed. Examples for the application of user models in systems developed to date are presented, and some social implications are discussed. Finally, unsolved problems like coping with collective beliefs or resource-limited processes are investigated, and prospects for application-oriented research are outlined.},
	number = {7},
	journal = {Proceedings of the IEEE},
	author = {Wahlster, W. and Kobsa, A.},
	month = jul,
	year = {1986},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Aircraft, Artificial intelligence, Cognitive science, Computer science, Cooperative systems, Filling, Humans, Moon, Natural languages, Proposals},
	pages = {948--960},
}

@inproceedings{schreck_security_1997,
	address = {Vienna},
	series = {International {Centre} for {Mechanical} {Sciences}},
	title = {Security and {Privacy} {Issues} in {User} {Modeling}},
	isbn = {978-3-7091-2670-7},
	doi = {10.1007/978-3-7091-2670-7_49},
	abstract = {Shared user models and user models maintained through networks pose threats to system security and the privacy of the user. This work proposes policies of data usage and models for user-centered control of access to user models which enable user modeling systems to take into account both heterogeneous user demands and legal constraints.},
	language = {en},
	booktitle = {User {Modeling}},
	publisher = {Springer},
	author = {Schreck, Jörg},
	editor = {Jameson, A. and Paris, C. and Tasso, C.},
	year = {1997},
	pages = {453--454},
}

@book{schreck_security_2003,
	title = {Security and {Privacy} in {User} {Modeling}},
	isbn = {978-1-4020-1130-6},
	abstract = {User-adaptive (or "personalized") systems take individual character istics of their current users into account and adapt their behavior ac cordingly. Several empirical studies demonstrate their benefits in areas like education and training, online help for complex software, dynamic information delivery, provision of computer access to people with dis abilities, and to some extent information retrieval. Recently, personal ized systems have also started to appear on the World Wide Web where they are primarily used for customer relationship management. The aim hereby is to provide value to customers by serving them as individuals and by offering them a unique personal relationship with the business. Studies show that web visitors indeed spend considerably more time at personalized than at regular portals and view considerably more web pages. Personalized sites in general also draw more visitors and turn more visitors into buyers. Personalization therefore would look like a win-win technology for both consumers and online businesses. However, it has a major down side: in order to be able to exhibit personalized behavior, user-adaptive systems have to collect considerable amounts of personal data and "lay them in stock" for possible future usage. Moreover, the collection of information about the user is often performed in a relatively inconspic uous manner (such as by monitoring users' web navigation behavior), in order not to distract users from their tasks.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Schreck, J.},
	month = jan,
	year = {2003},
	note = {Google-Books-ID: ikh7jAcVkOMC},
	keywords = {Business \& Economics / Information Management, Computers / Computer Science, Computers / Information Theory, Computers / Operating Systems / General, Computers / Programming / Algorithms, Computers / Systems Architecture / General, Computers / User Interfaces, Law / Computer \& Internet, Law / Science \& Technology},
}

@article{kobsa_user_1990,
	title = {User modeling in dialog systems: {Potentials} and hazards},
	volume = {4},
	issn = {1435-5655},
	shorttitle = {User modeling in dialog systems},
	url = {https://doi.org/10.1007/BF01889941},
	doi = {10.1007/BF01889941},
	abstract = {In order to be capable of exhibiting a wide range of cooperative behavior, a computer-based dialog system must have available assumptions about the current user's goals, plans, background knowledge and (false) beliefs, i.e., maintain a so-called “user model”. Apart from cooperativity aspects, such a model is also necessary for intelligent coherent dialog behavior in general. This article surveys recent research on the problem of how such a model can be constructed, represented and used by a system during its interaction with the user. Possible applications, as well as potential problems concerning the advisability of application, are then discussed. Finally, a number of guidelines are presented which should be observed in future research to reduce the risk of a potential misuse of user modeling technology.},
	language = {en},
	number = {3},
	urldate = {2022-05-11},
	journal = {AI \& SOCIETY},
	author = {Kobsa, Alfred},
	month = jul,
	year = {1990},
	keywords = {Cooperative systems, Hazards of user modeling, Potentials of user modeling, User modeling},
	pages = {214--231},
}

@article{kobsa_generic_2001,
	title = {Generic {User} {Modeling} {Systems}},
	volume = {11},
	issn = {1573-1391},
	url = {https://doi.org/10.1023/A:1011187500863},
	doi = {10.1023/A:1011187500863},
	abstract = {The paper reviews the development of generic user modeling systems over the past twenty years. It describes their purposes, their services within user-adaptive systems, and the different design requirements for research prototypes and commercially deployed servers. It discusses the architectures that have been explored so far, namely shell systems that form part of the application, central server systems that communicate with several applications, and possible future user modeling agents that physically follow the user. Several implemented research prototypes and commercial systems are briefly described.},
	language = {en},
	number = {1},
	urldate = {2022-05-11},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Kobsa, Alfred},
	month = mar,
	year = {2001},
	keywords = {tool systems, user model servers, user model shells, user models, usre model agents},
	pages = {49--63},
}

@article{wang_pla-based_2013,
	title = {A {PLA}-based privacy-enhancing user modeling framework and its evaluation},
	volume = {23},
	issn = {1573-1391},
	url = {https://doi.org/10.1007/s11257-011-9114-8},
	doi = {10.1007/s11257-011-9114-8},
	abstract = {Reconciling personalization with privacy has been a continuing interest in user modeling research. This aim has computational, legal and behavioral/attitudinal ramifications. We present a dynamic privacy-enhancing user modeling framework that supports compliance with users’ individual privacy preferences and with the privacy laws and regulations that apply to each user. The framework is based on a software product line architecture. It dynamically selects personalization methods during runtime that meet the current privacy constraints. Since dynamic architectural reconfiguration is typically resource-intensive, we conducted a performance evaluation with four implementations of our system that vary two factors. The results demonstrate that at least one implementation of our approach is technically feasible with comparatively modest additional resources, even for websites with the highest traffic today. To gauge user reactions to privacy controls that our framework enables, we also conducted a controlled experiment that allowed one group of users to specify privacy preferences and view the resulting effects on employed personalization methods. We found that users in this treatment group utilized this feature, deemed it useful, and had fewer privacy concerns as measured by higher disclosure of their personal data.},
	language = {en},
	number = {1},
	urldate = {2022-05-11},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Wang, Yang and Kobsa, Alfred},
	month = mar,
	year = {2013},
	keywords = {Compliance, Disclosure behavior, Performance evaluation, Privacy laws, Privacy preferences, Product line architecture, User experiment, User modeling},
	pages = {41--82},
}

@inproceedings{heckmann_ubiquitous_2001,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Ubiquitous {User} {Modeling} for {Situated} {Interaction}},
	isbn = {978-3-540-44566-1},
	doi = {10.1007/3-540-44566-8_45},
	abstract = {The main contribution of my doctoral proposal will be the design of a standardized and expandable XML-based User Modeling Ontology Language, which enables ubiquitous systems to communicate about user models. The second contribution will be the investigation of combining simple partial user models from the point of view of the user modeling ontology language, as well as the specific example domain of speech and manual input, which will be realized by object-oriented dynamic Bayesian networks.},
	language = {en},
	booktitle = {User {Modeling} 2001},
	publisher = {Springer},
	author = {Heckmann, Dominik},
	editor = {Bauer, Mathias and Gmytrasiewicz, Piotr J. and Vassileva, Julita},
	year = {2001},
	keywords = {Bayesian Network, Bayesian Network Model, Dynamic Bayesian Network, Manual Input, User Modeling},
	pages = {280--282},
}

@article{fischer_user_nodate,
	title = {User {Modeling} in {Human}-{Computer} {Interaction}},
	abstract = {A fundamental objective of human {\textasciicircum} computer interaction research is to make systems more usable, more useful, and to provide users with experiences ¢tting their speci¢c background knowledge and objectives. The challenge in an information-rich world is not only to make information available to people at any time, at any place, and in any form, but speci¢cally to say the ``right'' thing at the ``right'' time in the ``right'' way. Designers of collaborative human {\textasciicircum} computer systems face the formidable task of writing software for millions of users (at design time) while making it work as if it were designed for each individual user (only known at use time).},
	language = {en},
	author = {Fischer, Gerhard},
	pages = {22},
}

@article{dim_when_2015,
	title = {When user modeling intersects software engineering: the info-bead user modeling approach},
	volume = {25},
	issn = {1573-1391},
	shorttitle = {When user modeling intersects software engineering},
	url = {https://doi.org/10.1007/s11257-015-9159-1},
	doi = {10.1007/s11257-015-9159-1},
	abstract = {User models (UMs) allow systems to provide personalized services to their users. Nowadays, UMs are developed ad-hoc, as part of specific applications, thus requiring repetitive development efforts. In this paper, we propose the info-bead user modeling approach, which is based on ideas taken from software engineering in general and component-based software development in particular. The basic standalone unit, the info-bead, represents a single user attribute within time-tagged information-items. An info-bead encapsulates an inference process that uses data received from sensors or other info-beads and yields an information-item value. Having standard interfaces, info-beads can be linked, thus creating info-pendants. Both info-beads and info-pendants can be assembled as needed into complex and abstract user models (UMs) and group models (GMs). The goal of the suggested approach is to ease the modeling process and to allow reuse of info beads developed for one UM in other UMs that need the same information. In order to assess the reusability and collaboration capabilities of the info-bead user modeling approach, we developed a prototype tool that enables UM designers, who are not necessarily software developers, to easily select and integrate info-beads for constructing UMs and GMs. We further demonstrated the use of the approach in a museum environment, for modeling of assistive technology ontology and for user modeling in various specific domains. Finally, we analyzed and assessed the characteristics of the approach with respect to existing generic user modeling criteria.},
	language = {en},
	number = {3},
	urldate = {2022-05-11},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Dim, Eyal and Kuflik, Tsvi and Reinhartz-Berger, Iris},
	month = aug,
	year = {2015},
	keywords = {Component-based user model, Group model, Info-bead, Info-pendant, User model, User model reusability, User modeling software engineering, User modeling tool},
	pages = {189--229},
}

@article{abel_cross-system_2013,
	title = {Cross-system user modeling and personalization on the {Social} {Web}},
	volume = {23},
	issn = {09241868},
	url = {https://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=85300431&site=ehost-live},
	doi = {10.1007/s11257-012-9131-2},
	abstract = {In order to adapt functionality to their individual users, systems need information about these users. The Social Web provides opportunities to gather user data from outside the system itself. Aggregated user data may be useful to address cold-start problems as well as sparse user profiles, but this depends on the nature of individual user profiles distributed on the Social Web. For example, does it make sense to re-use Flickr profiles to recommend bookmarks in Delicious? In this article, we study distributed form-based and tag-based user profiles, based on a large dataset aggregated from the Social Web. We analyze the completeness, consistency and replication of form-based profiles, which users explicitly create by filling out forms at Social Web systems such as Twitter, Facebook and LinkedIn. We also investigate tag-based profiles, which result from social tagging activities in systems such as Flickr, Delicious and StumbleUpon: to what extent do tag-based profiles overlap between different systems, what are the benefits of aggregating tag-based profiles. Based on these insights, we developed and evaluated the performance of several cross-system user modeling strategies in the context of recommender systems. The evaluation results show that the proposed methods solve the cold-start problem and improve recommendation quality significantly, even beyond the cold-start.},
	number = {2/3},
	urldate = {2022-05-11},
	journal = {User Modeling \& User-Adapted Interaction},
	author = {Abel, Fabian and Herder, Eelco and Houben, Geert-Jan and Henze, Nicola and Krause, Daniel},
	month = apr,
	year = {2013},
	note = {Publisher: Springer Nature},
	keywords = {Cross-system user modeling, Facebook (Web resource), LinkedIn (Web resource), Personalization, Social Web, Social tagging, Tags (Metadata), Twitter (Web resource), User modeling, User profiles, Web personalization, Websites -- Social aspects},
	pages = {169--209},
}

@misc{rokicki_whats_nodate,
	title = {What’s {On} {My} {Plate}: {Towards} {Recommending} {Recipe} {Variations} for {Diabetes} {Patients}},
	shorttitle = {What’s {On} {My} {Plate}},
	abstract = {Abstract. As community-based recipe platforms continue to grow in popularity, recipe recommendation is an active research area. Simulta-neously, the analysis of online recipes can provide us with insights on dietary patterns in particular communities. In this paper, we focus on recipe recommendation for a user group that is constrained in terms of choices: diabetes patients need to balance their diet more than average persons and to be aware of the nutritional value of their meals. First, we discuss the type of situations where diabetes-specific food recommen-dations are desirable. Further, we analyze how people’s age and gender interact with food intake. Based on a large dataset, we explore how vari-ations in ‘canonical meals ’ can be exploited for recommending which alternatives better fit the user’s dietary requirements. 1},
	author = {Rokicki, Markus and Herder, Eelco and Demidova, Elena},
}

@inproceedings{herder_unexpected_2019,
	address = {Hof, Germany},
	title = {Unexpected and {Unpredictable}: {Factors} {That} {Make} {Personalized} {Advertisements} {Creepy}},
	isbn = {978-1-4503-6896-4},
	shorttitle = {Unexpected and {Unpredictable}},
	url = {http://dl.acm.org/citation.cfm?doid=3345002.3349285},
	doi = {10.1145/3345002.3349285},
	abstract = {Personalized advertisements are the price we have to pay for free social media platforms. Various studies have been carried out on user acceptance of such advertisements in general and most countries have adopted laws and regulations with respect to privacy and data protection. However, not all advertisements evoke the same responses: some ads are considered more annoying, intrusive or creepy than others. In this paper, we present the results of an observational study on user responses to actual Facebook advertisements. The results show that mismatches in terms of context, unexpected data collection or inference, overly generic explanations and repetition are common causes of anxiety and distrust.},
	language = {en},
	urldate = {2022-05-11},
	booktitle = {Proceedings of the 23rd {International} {Workshop} on {Personalization} and {Recommendation} on the {Web} and {Beyond}  - {ABIS} '19},
	publisher = {ACM Press},
	author = {Herder, Eelco and Zhang, Boping},
	year = {2019},
	pages = {1--6},
}

@article{griol_modeling_2014,
	title = {Modeling the user state for context-aware spoken interaction in ambient assisted living},
	volume = {40},
	issn = {1573-7497},
	url = {https://doi.org/10.1007/s10489-013-0503-z},
	doi = {10.1007/s10489-013-0503-z},
	abstract = {Ambient Assisted Living (AAL) systems must provide adapted services easily accessible by a wide variety of users. This can only be possible if the communication between the user and the system is carried out through an interface that is simple, rapid, effective, and robust. Natural language interfaces such as dialog systems fulfill these requisites, as they are based on a spoken conversation that resembles human communication. In this paper, we enhance systems interacting in AAL domains by means of incorporating context-aware conversational agents that consider the external context of the interaction and predict the user’s state. The user’s state is built on the basis of their emotional state and intention, and it is recognized by means of a module conceived as an intermediate phase between natural language understanding and dialog management in the architecture of the conversational agent. This prediction, carried out for each user turn in the dialog, makes it possible to adapt the system dynamically to the user’s needs. We have evaluated our proposal developing a context-aware system adapted to patients suffering from chronic pulmonary diseases, and provide a detailed discussion of the positive influence of our proposal in the success of the interaction, the information and services provided, as well as the perceived quality.},
	language = {en},
	number = {4},
	urldate = {2022-05-11},
	journal = {Applied Intelligence},
	author = {Griol, David and Molina, José Manuel and Callejas, Zoraida},
	month = jun,
	year = {2014},
	keywords = {Ambient assisted living, Context-awareness, Dialog systems, Emotions, Human-computer interaction, Spoken interaction, User adaptation, Web interfaces},
	pages = {749--771},
}

@article{iovine_conversational_2020,
	title = {Conversational {Recommender} {Systems} and natural language:: {A} study through the {ConveRSE} framework},
	volume = {131},
	issn = {0167-9236},
	shorttitle = {Conversational {Recommender} {Systems} and natural language},
	url = {https://www.sciencedirect.com/science/article/pii/S0167923620300051},
	doi = {10.1016/j.dss.2020.113250},
	abstract = {Digital Assistants (DA) such as Amazon Alexa, Siri, or Google Assistant are now gaining great diffusion, since they allow users to execute a wide range of actions through messages in natural language. Even though DAs are able to complete tasks such as sending texts, making phone calls, or playing songs, they do not yet implement recommendation facilities. In this paper, we investigate the combination of Digital Assistants and Conversational Recommender Systems (CoRSs) by designing and implementing a framework named ConveRSE (Conversational Recommender System framEwork), for building chatbots that can recommend items from different domains and interact with the user through natural language. Since a CoRS architecture is generally composed of different elements, we performed an in-vitro experiment with two synthetic datasets, to investigate the impact that each component has on the CoRS in terms of recommendation accuracy. Additionally, an in-vivo experiment was carried out to understand how natural language influences both the cost of interaction and recommendation accuracy of a CoRS. Experimental results have revealed the most critical components in a CoRS architecture, especially in cold-start situations, and the main issues of the natural-language-based interaction. All the dialogues have been collected in a public available dataset.},
	language = {en},
	urldate = {2022-05-11},
	journal = {Decision Support Systems},
	author = {Iovine, Andrea and Narducci, Fedelucio and Semeraro, Giovanni},
	month = apr,
	year = {2020},
	keywords = {Conversational Recommender Systems, Domain-independent recommender systems, Natural language processing},
	pages = {113250},
}

@inproceedings{massoni_sguerra_oblivion_2017,
	address = {Bratislava Slovakia},
	title = {Oblivion {Tracking}: {Towards} a {Probabilistic} {Working} {Memory} {Model} for the {Adaptation} of {Systems} to {Alzheimer} {Patients}},
	isbn = {978-1-4503-5067-9},
	shorttitle = {Oblivion {Tracking}},
	url = {https://dl.acm.org/doi/10.1145/3099023.3099052},
	doi = {10.1145/3099023.3099052},
	abstract = {We introduce a new probabilistic working memory (WM) model that we intend to use to automatically personalize user interfaces with respect to Alzheimer patients’ declining WM capacity. WM is the part of the human memory responsible for the conscious short-term storing and manipulation of information. It is known to be extremely limited and to be one of the strongest factors that impact individual di erences in cognitive abilities. In particular, individuals su ering from Alzheimer’s disease have signi cantly impaired WM capacities that worsen as the disease progresses. As a use case for our model, we describe a system that is designed to help patients with Alzheimer’s disease choose the music track they would like to listen to from a given playlist. We discuss how our WM model could be used to adapt this system to each patient’s disease progression in time and the consequent deterioration of her WM capacity.},
	language = {en},
	urldate = {2022-05-11},
	booktitle = {Adjunct {Publication} of the 25th {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Massoni Sguerra, Bruno and Jouvelot, Pierre and Benveniste, Samuel},
	month = jul,
	year = {2017},
	pages = {253--256},
}

@book{cassell_embodied_2000,
	title = {Embodied {Conversational} {Agents}},
	isbn = {978-0-262-03278-0},
	abstract = {This book describes research in all aspects of the design, implementation, and evaluation of embodied conversational agents as well as details of specific working systems. Embodied conversational agents are computer-generated cartoonlike characters that demonstrate many of the same properties as humans in face-to-face conversation, including the ability to produce and respond to verbal and nonverbal communication. They constitute a type of (a) multimodal interface where the modalities are those natural to human conversation: speech, facial displays, hand gestures, and body stance; (b) software agent, insofar as they represent the computer in an interaction with a human or represent their human users in a computational environment (as avatars, for example); and (c) dialogue system where both verbal and nonverbal devices advance and regulate the dialogue between the user and the computer. With an embodied conversational agent, the visual dimension of interacting with an animated character on a screen plays an intrinsic role. Not just pretty pictures, the graphics display visual features of conversation in the same way that the face and hands do in face-to-face conversation among humans. This book describes research in all aspects of the design, implementation, and evaluation of embodied conversational agents as well as details of specific working systems. Many of the chapters are written by multidisciplinary teams of psychologists, linguists, computer scientists, artists, and researchers in interface design. The authors include Elisabeth Andre, Norm Badler, Gene Ball, Justine Cassell, Elizabeth Churchill, James Lester, Dominic Massaro, Cliff Nass, Sharon Oviatt, Isabella Poggi, Jeff Rickel, and Greg Sanders.},
	language = {en},
	publisher = {MIT Press},
	author = {Cassell, Justine and Sullivan, Joseph and Churchill, Elizabeth and Prevost, Scott},
	year = {2000},
	note = {Google-Books-ID: tHiKZGh9t7sC},
	keywords = {Computers / Data Science / General, Computers / Interactive \& Multimedia},
}

@article{novielli_user_2010,
	title = {User attitude towards an embodied conversational agent: {Effects} of the interaction mode},
	volume = {42},
	issn = {03782166},
	shorttitle = {User attitude towards an embodied conversational agent},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378216609003324},
	doi = {10.1016/j.pragma.2009.12.016},
	abstract = {We describe how the interaction mode with an embodied conversational agent (ECA) affects the users’ perception of the agent and their behavior during interaction, and propose a method to recognize the social attitude of users towards the agent from their verbal behavior. A corpus of human–ECA dialogues was collected with a Wizard-of-Oz study in which the input mode of the user moves was varied (written vs. speech-based). After labeling the corpus, we evaluated the relationship between input mode and social attitude of users towards the agent. The results show that, by increasing naturalness of interaction, spoken input produces a warmer attitude of users and a richer language: this effect is more evident for users with a background in humanities. Recognition of signs of social attitude is needed for adapting the ECA’s verbal and nonverbal behavior.},
	language = {en},
	number = {9},
	urldate = {2022-05-11},
	journal = {Journal of Pragmatics},
	author = {Novielli, Nicole and de Rosis, Fiorella and Mazzotta, Irene},
	month = sep,
	year = {2010},
	pages = {2385--2397},
}

@inproceedings{ferland_hows_2020,
	address = {Honolulu HI USA},
	title = {How's {Your} {Day} {Look}? {The} ({Un}){Expected} {Sociolinguistic} {Effects} of {User} {Modeling} in a {Conversational} {Agent}},
	isbn = {978-1-4503-6819-3},
	shorttitle = {How's {Your} {Day} {Look}?},
	url = {https://dl.acm.org/doi/10.1145/3334480.3375227},
	doi = {10.1145/3334480.3375227},
	language = {en},
	urldate = {2022-05-11},
	booktitle = {Extended {Abstracts} of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ferland, Libby and Koutstaal, Wilma},
	month = apr,
	year = {2020},
	pages = {1--8},
}

@inproceedings{musto_towards_2020,
	address = {Genoa Italy},
	title = {Towards {Queryable} {User} {Profiles}: {Introducing} {Conversational} {Agents} in a {Platform} for {Holistic} {User} {Modeling}},
	isbn = {978-1-4503-7950-2},
	shorttitle = {Towards {Queryable} {User} {Profiles}},
	url = {https://dl.acm.org/doi/10.1145/3386392.3399298},
	doi = {10.1145/3386392.3399298},
	abstract = {In this article we introduce the concept of queryable user profile, that is to say, a representation of the user that can be queried through natural language requests.},
	language = {en},
	urldate = {2022-05-11},
	booktitle = {Adjunct {Publication} of the 28th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Musto, Cataldo and Narducci, Fedelucio and Polignano, Marco and de Gemmis, Marco and Lops, Pasquale and Semeraro, Giovanni},
	month = jul,
	year = {2020},
	pages = {213--218},
}

@article{cassell_negotiated_nodate,
	title = {Negotiated {Collusion}: {Modeling} {Social} {Languageand} its {Relationship} {Effects} in {Intelligent} {Agents}},
	abstract = {Building a collaborative trusting relationship with users is crucial in a wide range of applications, such as advice-giving or ﬁnancial transactions, and some minimal degree of cooperativeness is required in all applications to even initiate and maintain an interaction with a user. Despite the importance of this aspect of human–human relationships, few intelligent systems have tried to build user models of trust, credibility, or other similar interpersonal variables, or to inﬂuence these variables during interaction with users. Humans use a variety of kinds of social language, including small talk, to establish collaborative trusting interpersonal relationships. We argue that such strategies can also be used by intelligent agents, and that embodied conversational agents are ideally suited for this task given the myriad multimodal cues available to them for managing conversation. In this article we describe a model of the relationship between social language and interpersonal relationships, a new kind of discourse planner that is capable of generating social language to achieve interpersonal goals, and an actual implementation in an embodied conversational agent. We discuss an evaluation of our system in which the use of social language was demonstrated to have a signiﬁcant effect on users’ perceptions of the agent’s knowledgableness and ability to engage users, and on their trust, credibility, and how well they felt the system knew them, for users manifesting particular personality traits.},
	language = {en},
	author = {Cassell, Justine and Bickmore, Timothy},
	pages = {44},
}

@inproceedings{liao_user-aware_2019,
	address = {Marina del Ray California},
	title = {User-aware conversational agents},
	isbn = {978-1-4503-6673-1},
	url = {https://dl.acm.org/doi/10.1145/3308557.3313124},
	doi = {10.1145/3308557.3313124},
	abstract = {Conversational agents are becoming increasingly popular. These systems present an extremely rich and challenging research space for addressing many aspects of user awareness and adaptation, such as user profiles, contexts, personalities, emotions, social dynamics, conversational styles, etc. Adaptive interfaces are of long-standing interest for the HCI community. Meanwhile, new machine learning approaches are introduced in the current generation of conversational agents, such as deep learning, reinforcement learning, and active learning. It is imperative to consider how various aspects of user-awareness should be handled by these new techniques. The goal of this workshop is to bring together researchers in HCI, user modeling, and the AI and NLP communities from both industry and academia, who are interested in advancing the state-of-the-art on the topic of user-aware conversational agents. Through a focused and open exchange of ideas and discussions, we will work to identify central research topics in user-aware conversational agents and develop a strong interdisciplinary foundation to address them.},
	language = {en},
	urldate = {2022-05-11},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces}: {Companion}},
	publisher = {ACM},
	author = {Liao, Q. Vera and Shmueli-Scheuer, Michal and Wen, Tsung-Hsien (Shawn) and Yu, Zhou},
	month = mar,
	year = {2019},
	pages = {133--134},
}

@inproceedings{yang_towards_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards {User}-{Centric} {Text}-to-{Text} {Generation}: {A} {Survey}},
	isbn = {978-3-030-83527-9},
	shorttitle = {Towards {User}-{Centric} {Text}-to-{Text} {Generation}},
	doi = {10.1007/978-3-030-83527-9_1},
	abstract = {Natural Language Generation (NLG) has received much attention with rapidly developing models and ever-more available data. As a result, a growing amount of work attempts to personalize these systems for better human interaction experience. Still, diverse sets of research across multiple dimensions and numerous levels of depth exist and are scattered across various communities. In this work, we survey the ongoing research efforts and introduce a categorization of these under the umbrella user-centric natural language generation. We further discuss some of the challenges and opportunities in NLG personalization.},
	language = {en},
	booktitle = {Text, {Speech}, and {Dialogue}},
	publisher = {Springer International Publishing},
	author = {Yang, Diyi and Flek, Lucie},
	editor = {Ekštein, Kamil and Pártl, František and Konopík, Miloslav},
	year = {2021},
	keywords = {NLG, Personalization, User modeling},
	pages = {3--22},
}

@inproceedings{flek_returning_2020,
	address = {Online},
	title = {Returning the {N} to {NLP}: {Towards} {Contextually} {Personalized} {Classification} {Models}},
	shorttitle = {Returning the {N} to {NLP}},
	url = {https://aclanthology.org/2020.acl-main.700},
	doi = {10.18653/v1/2020.acl-main.700},
	abstract = {Most NLP models today treat language as universal, even though socio- and psycholingustic research shows that the communicated message is influenced by the characteristics of the speaker as well as the target audience. This paper surveys the landscape of personalization in natural language processing and related fields, and offers a path forward to mitigate the decades of deviation of the NLP tools from sociolingustic findings, allowing to flexibly process the “natural” language of each user rather than enforcing a uniform NLP treatment. It outlines a possible direction to incorporate these aspects into neural NLP models by means of socially contextual personalization, and proposes to shift the focus of our evaluation strategies accordingly.},
	urldate = {2022-05-11},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Flek, Lucie},
	month = jul,
	year = {2020},
	pages = {7828--7838},
}

@article{eke_survey_2019,
	title = {A {Survey} of {User} {Profiling}: {State}-of-the-{Art}, {Challenges}, and {Solutions}},
	volume = {7},
	issn = {2169-3536},
	shorttitle = {A {Survey} of {User} {Profiling}},
	doi = {10.1109/ACCESS.2019.2944243},
	abstract = {Advancements in information and communication technology, and online web users have given attention to the virtual representation of each user, which is crucial for effective service personalization. Meeting users need and preferences is an ongoing challenge in service personalization. This issue can be addressed through the building of a comprehensive user profile. A user profile is the summary of the user's interests, characteristics, behaviours, and preferences, while user profiling is the system of collecting, organizing and inferring the user profile information. Many reviews on user profiling have been conducted but none focused on the effective profile modeling process. Hence, this article aims to provide a review of the recent state-of-the-art approach to user profiling. These include methods, description, characteristics, and taxonomy of the user profile. The study of the existing user profiling modeling in the aspect of data acquisition, feature extraction, profiling techniques, and profiling approaches (with the identification of their strengths and weaknesses) and the performance measures are also provided. In addition, the research challenges were also discussed with a focus on privacy, datasets, cold start issues, trust issues, and computational complexity. Moreover, the article identified an open research direction that serves as solutions to the identified challenges and motivation for further researchers in advancing user profiling. The findings showed that an effective modeling process enhances the construction of accurate user profile for service personalization.},
	journal = {IEEE Access},
	author = {Eke, Christopher Ifeanyi and Norman, Azah Anir and Shuib, Liyana and Nweke, Henry Friday},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {Computer science, Data models, Feature extraction, Information systems, Medical services, Ontologies, Social networking (online), User profiling, personalized service, profiling modeling, service recommendation, user interest},
	pages = {144907--144924},
}

@article{razumovskaia_crossing_nodate,
	title = {Crossing the {Conversational} {Chasm}: {A} {Primer} on {Multilingual} {Task}-{Oriented} {Dialogue} {Systems}},
	abstract = {Despite the fact that natural language conversations with machines represent one of the central objectives of AI, and despite the massive increase of research and development efforts in conversational AI, task-oriented dialogue (TOD) – i.e., conversations with an artiﬁcial agent with the aim of completing a concrete task – is currently limited to a few narrow domains (e.g., food ordering, ticket booking) and a handful of major languages (e.g., English, Chinese). In this work, we provide an extensive overview of existing efforts in multilingual TOD and analyse the factors preventing the development of truly multilingual TOD systems. We identify two main challenges that combined hinder the faster progress in multilingual TOD: (1) current state-of-the-art TOD models based on large pretrained neural language models are data hungry; at the same time (2) data acquisition for TOD use cases is expensive and tedious. Most existing approaches to multilingual TOD thus rely on (zero- or few-shot) cross-lingual transfer from resource-rich languages (in TOD, this is basically only English), either by means of (i) machine translation or (ii) multilingual representation spaces. However, such approaches are currently not a viable solution for a large number of low-resource languages without parallel data and/or limited monolingual corpora. Finally, we discuss critical challenges and potential solutions by drawing parallels between TOD and other cross-lingual and multilingual NLP research.},
	language = {en},
	author = {Razumovskaia, Evgeniia and Glavasˇ, Goran and Majewska, Olga and Korhonen, Anna and Vulic, Ivan},
	pages = {30},
}

@article{ferland_evaluating_2019,
	title = {Evaluating {Older} {Users}' {Experiences} with {Commercial} {Dialogue} {Systems}: {Implications} for {Future} {Design} and {Development}},
	shorttitle = {Evaluating {Older} {Users}' {Experiences} with {Commercial} {Dialogue} {Systems}},
	url = {http://arxiv.org/abs/1902.04393},
	abstract = {Understanding the needs of a variety of distinct user groups is vital in designing effective, desirable dialogue systems that will be adopted by the largest possible segment of the population. Despite the increasing popularity of dialogue systems in both mobile and home formats, user studies remain relatively infrequent and often sample a segment of the user population that is not representative of the needs of the potential user population as a whole. This is especially the case for users who may be more reluctant adopters, such as older adults. In this paper we discuss the results of a recent user study performed over a large population of age 50 and over adults in the Midwestern United States that have experience using a variety of commercial dialogue systems. We show the common preferences, use cases, and feature gaps identified by older adult users in interacting with these systems. Based on these results, we propose a new, robust user modeling framework that addresses common issues facing older adult users, which can then be generalized to the wider user population.},
	urldate = {2022-05-11},
	journal = {arXiv:1902.04393 [cs]},
	author = {Ferland, Libby and Huffstutler, Thomas and Rice, Jacob and Zheng, Joan and Ni, Shi and Gini, Maria},
	month = jan,
	year = {2019},
	note = {arXiv: 1902.04393},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
}

@inproceedings{cai_impacts_2022,
	address = {New Orleans LA USA},
	title = {Impacts of {Personal} {Characteristics} on {User} {Trust} in {Conversational} {Recommender} {Systems}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517471},
	doi = {10.1145/3491102.3517471},
	abstract = {Conversational recommender systems (CRSs) imitate human advisors to assist users in fnding items through conversations and have recently gained increasing attention in domains such as media and e-commerce. Like in human communication, building trust in human-agent communication is essential given its signifcant infuence on user behavior. However, inspiring user trust in CRSs with a “one-size-fts-all” design is difcult, as individual users may have their own expectations for conversational interactions (e.g., who, user or system, takes the initiative), which are potentially related to their personal characteristics. In this study, we investigated the impacts of three personal characteristics, namely personality traits, trust propensity, and domain knowledge, on user trust in two types of text-based CRSs, i.e., user-initiative and mixed-initiative. Our between-subjects user study (N=148) revealed that users’ trust propensity and domain knowledge positively infuenced their trust in CRSs, and that users with high conscientiousness tended to trust the mixed-initiative system.},
	language = {en},
	urldate = {2022-05-11},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Cai, Wanling and Jin, Yucheng and Chen, Li},
	month = apr,
	year = {2022},
	pages = {1--14},
}

@article{jannach_survey_2022,
	title = {A {Survey} on {Conversational} {Recommender} {Systems}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3453154},
	doi = {10.1145/3453154},
	abstract = {Recommender systems are software applications that help users to find items of interest in situations of information overload. Current research often assumes a one-shot interaction paradigm, where the users’ preferences are estimated based on past observed behavior and where the presentation of a ranked list of suggestions is the main, one-directional form of user interaction. Conversational recommender systems (CRS) take a different approach and support a richer set of interactions. These interactions can, for example, help to improve the preference elicitation process or allow the user to ask questions about the recommendations and to give feedback. The interest in CRS has significantly increased in the past few years. This development is mainly due to the significant progress in the area of natural language processing, the emergence of new voice-controlled home assistants, and the increased use of chatbot technology. With this article, we provide a detailed survey of existing approaches to conversational recommendation. We categorize these approaches in various dimensions, e.g., in terms of the supported user intents or the knowledge they use in the background. Moreover, we discuss technological approaches, review how CRS are evaluated, and finally identify a number of gaps that deserve more research in the future.},
	language = {en},
	number = {5},
	urldate = {2022-05-11},
	journal = {ACM Computing Surveys},
	author = {Jannach, Dietmar and Manzoor, Ahtsham and Cai, Wanling and Chen, Li},
	month = jun,
	year = {2022},
	pages = {1--36},
}

@article{birhane_forgotten_2022,
	title = {The {Forgotten} {Margins} of {AI} {Ethics}},
	url = {http://arxiv.org/abs/2205.04221},
	doi = {10.1145/3531146.3533157},
	abstract = {How has recent AI Ethics literature addressed topics such as fairness and justice in the context of continued social and structural power asymmetries? We trace both the historical roots and current landmark work that have been shaping the field and categorize these works under three broad umbrellas: (i) those grounded in Western canonical philosophy, (ii) mathematical and statistical methods, and (iii) those emerging from critical data/algorithm/information studies. We also survey the field and explore emerging trends by examining the rapidly growing body of literature that falls under the broad umbrella of AI Ethics. To that end, we read and annotated peer-reviewed papers published over the past four years in two premier conferences: FAccT and AIES. We organize the literature based on an annotation scheme we developed according to three main dimensions: whether the paper deals with concrete applications, use-cases, and/or people's lived experience; to what extent it addresses harmed, threatened, or otherwise marginalized groups; and if so, whether it explicitly names such groups. We note that although the goals of the majority of FAccT and AIES papers were often commendable, their consideration of the negative impacts of AI on traditionally marginalized groups remained shallow. Taken together, our conceptual analysis and the data from annotated papers indicate that the field would benefit from an increased focus on ethical analysis grounded in concrete use-cases, people's experiences, and applications as well as from approaches that are sensitive to structural and historical power asymmetries.},
	urldate = {2022-05-11},
	journal = {arXiv:2205.04221 [cs]},
	author = {Birhane, Abeba and Ruane, Elayne and Laurent, Thomas and Brown, Matthew S. and Flowers, Johnathan and Ventresque, Anthony and Dancy, Christopher L.},
	month = may,
	year = {2022},
	note = {arXiv: 2205.04221},
}

@article{clark_state_2019,
	title = {The {State} of {Speech} in {HCI}: {Trends}, {Themes} and {Challenges}},
	volume = {31},
	issn = {0953-5438},
	shorttitle = {The {State} of {Speech} in {HCI}},
	url = {https://doi.org/10.1093/iwc/iwz016},
	doi = {10.1093/iwc/iwz016},
	abstract = {Speech interfaces are growing in popularity. Through a review of 99 research papers this work maps the trends, themes, findings and methods of empirical research on speech interfaces in the field of human–computer interaction (HCI). We find that studies are usability/theory-focused or explore wider system experiences, evaluating Wizard of Oz, prototypes or developed systems. Measuring task and interaction was common, as was using self-report questionnaires to measure concepts like usability and user attitudes. A thematic analysis of the research found that speech HCI work focuses on nine key topics: system speech production, design insight, modality comparison, experiences with interactive voice response systems, assistive technology and accessibility, user speech production, using speech technology for development, peoples’ experiences with intelligent personal assistants and how user memory affects speech interface interaction. From these insights we identify gaps and challenges in speech research, notably taking into account technological advancements, the need to develop theories of speech interface interaction, grow critical mass in this domain, increase design work and expand research from single to multiple user interaction contexts so as to reflect current use contexts. We also highlight the need to improve measure reliability, validity and consistency, in the wild deployment and reduce barriers to building fully functional speech interfaces for research.Most papers focused on usability/theory-based or wider system experience research with a focus on Wizard of Oz and developed systemsQuestionnaires on usability and user attitudes often used but few were reliable or validatedThematic analysis showed nine primary research topicsChallenges identified in theoretical approaches and design guidelines, engaging with technological advances, multiple user and in the wild contexts, critical research mass and barriers to building speech interfaces},
	number = {4},
	urldate = {2022-05-11},
	journal = {Interacting with Computers},
	author = {Clark, Leigh and Doyle, Philip and Garaialde, Diego and Gilmartin, Emer and Schlögl, Stephan and Edlund, Jens and Aylett, Matthew and Cabral, João and Munteanu, Cosmin and Edwards, Justin and R Cowan, Benjamin},
	month = jun,
	year = {2019},
	pages = {349--371},
}

@misc{pezikPELCRAPolishSpoken2011,
	type = {Archive},
	title = {{PELCRA} {Polish} spoken corpus},
	url = {http://pelcra.pl/res/spoken/plec},
	journal = {ELDA},
	author = {Pęzik, Piotr and Dróżdż, Łukasz},
	year = {2011},
}

@article{williams_parsing_2020,
	title = {Parsing particles in {Wa}’ikhana},
	volume = {16},
	issn = {2238-975X, 1808-835X},
	url = {https://revistas.ufrj.br/index.php/rl/article/view/43715},
	doi = {10.31513/linguistica.2020.v16nEsp.a43715},
	abstract = {This article analyzes the use of several response particles in face-to-face interaction in Wa’ikhana, an East Tukano language of northwestern Amazonia. Adopting a Conversation Analysis approach, we explore details of each particle, considering their prosodic shapes, the action contexts in which they occur, and their sequential positioning, all crucial to understanding their meanings in interaction. Our analysis shows that Wa’ikhana response particles exhibit both universal and language-particular properties, thus demonstrating the contributions of data from lesser-studied languages to research on language in social interaction, and the value of an interactional approach in the study of under-described, and often endangered, indigenous languages.},
	language = {en},
	number = {Esp.},
	urldate = {2021-06-15},
	journal = {Revista Linguistica},
	author = {Williams, Nicholas and Stenzel, Kristine and Fox, Barbara},
	month = nov,
	year = {2020},
	pages = {356--382},
}

@misc{martinezDocumentaryCorpusChhitkulRakchham2020,
	type = {Archive},
	title = {Documentary {Corpus} of {Chhitkul}-{Rakchham}, an endangered {Tibeto}-{Burman} language of {Northern} {India}},
	url = {http://hdl.handle.net/2196/23cecd70-2879-412f-bde1-456b0ea0ef1a},
	journal = {Endangered Languages Archive},
	author = {Martinez, Philippe Antoine},
	year = {2020},
}

@misc{parkerDocumentationCoraSan2020,
	type = {Archive},
	title = {Documentation of {Cora} in {San} {Juan} {Corapan}},
	url = {http://hdl.handle.net/2196/0829a3a6-92c4-4346-8e37-04845cdd1f7f},
	journal = {Endangered Languages Archive},
	author = {Parker, William H},
	year = {2020},
}

@misc{griscomDocumentationIsimjeegDatooga2018,
	type = {Archive},
	title = {Documentation of {Isimjeeg} {Datooga}},
	url = {http://hdl.handle.net/2196/1e9151d8-df0a-4ea7-bb6d-377b65b14310},
	journal = {Endangered Languages Archive},
	author = {Griscom, Richard},
	year = {2018},
}

@misc{cowellConversationalDatabaseArapaho1950,
	type = {Archive},
	title = {A {Conversational} {Database} of the {Arapaho} {Language} in {Video} {Format}},
	url = {http://hdl.handle.net/2196/3bba11be-a5e2-47dd-bfe5-42f2ee9e0bf4},
	journal = {Endangered Languages Archive},
	author = {Cowell, Andrew},
	year = {2010},
}

@misc{lauDocumentingAbesabesi2019,
	type = {Archive},
	title = {Documenting Àbèsàbèsì},
	url = {http://hdl.handle.net/2196/a6371e17-d083-4e29-bc4a-ecb9303f9197},
	journal = {Endangered Languages Archive},
	author = {Lau, Jonas},
	year = {2019},
}

@misc{tishevaCorpusSpokenBulgarian,
	title = {The {Corpus} of {Spoken} {Bulgarian}},
	url = {http://www.bgspeech.net/bg/resources/multimediacorpus_en.html},
	author = {Tisheva, Yovka and Dzhonova, Marina and Hauge, Kjetil Rå},
	year = {2013},
}

@inproceedings{ardila2020common,
	title = {Common voice: {A} massively-multilingual speech corpus},
	booktitle = {Proceedings of the 12th language resources and evaluation conference},
	author = {Ardila, Rosana and Branson, Megan and Davis, Kelly and Kohler, Michael and Meyer, Josh and Henretty, Michael and Morais, Reuben and Saunders, Lindsay and Tyers, Francis and Weber, Gregor},
	year = {2020},
	pages = {4218--4222},
}

@book{schnell_role_2021,
	title = {The role of language documentation in corpus-based typology},
	copyright = {Creative Commons Attribution Non-Commercial Share-Alike Licence},
	isbn = {978-0-9979673-0-2},
	url = {http://scholarspace.manoa.hawaii.edu/handle/10125/74656},
	language = {en},
	urldate = {2022-05-04},
	publisher = {University of Hawai'i Press},
	author = {Schnell, Stefan and Haig, Geoffrey and Seifart, Frank},
	year = {2021},
	note = {Accepted: 2022-01-24T19:37:44Z},
}

@article{de_vos_predicting_2021,
	title = {Predicting conversational turns: {Signers}' and nonsigners' sensitivity to language-specific and globally accessible cues},
	volume = {98},
	issn = {1535-0665},
	shorttitle = {Predicting conversational turns},
	url = {https://muse.jhu.edu/article/849526},
	abstract = {Precision turn-taking may constitute a crucial part of the human endowment for communication. If so, it should be implemented similarly across language modalities, as in signed vs. spoken language. Here, in the first experimental study of turn-end prediction in sign language, we find support for the idea that signed language, like spoken language, involves turn-type prediction and turn-end anticipation. In both cases, turns like questions that elicit specific responses accelerate anticipation. We also show remarkable cross-modality predictive capacity: nonsigners anticipate signed turn ends surprisingly well. Finally, we show that despite nonsigners' ability to intuitively predict signed turn ends, early native signers do it much better by using their access to linguistic signals (here, question markers). As shown in prior work, question formation facilitates prediction, and age of sign language acquisition affects accuracy. The study thus sheds light on the kinds of features that may facilitate turn-taking universally, and those that are language-specific.},
	number = {1},
	urldate = {2022-03-23},
	journal = {Language},
	author = {de Vos, Connie and Casillas, Marisa and Uittenbogert, Tom and Crasborn, Onno and Levinson, Stephen C.},
	year = {2021},
	note = {Publisher: Linguistic Society of America},
	pages = {35--62},
}

@misc{hanke_meine_2020,
	title = {{MEINE} {DGS}. Öffentliches {Korpus} der {Deutschen} {Gebärdensprache}, 3. {Release}},
	url = {https://www.sign-lang.uni-hamburg.de/meinedgs/landing/meinedgs-3.0.html},
	doi = {10.25592/DGS.MEINEDGS-3.0},
	abstract = {MEINE DGS ist ein Ausschnitt der Daten des Projektes DGS-Korpus im Umfang von knapp 50 Stunden Video. In diesem Projekt wurden im Zeitraum 2010-2012 in ganz Deutschland Gespräche jeweils zweier Informantinnen oder Informanten in Deutscher Gebärdensprache aufgezeichnet. Die Sammlung ist eine bunte Mischung von DGS-Filmen zu vielen verschiedenen Themen, von Personen unterschiedlichen Alters (ab 18 Jahren) aus 13 verschiedenen Regionen in Deutschland. Der Schwerpunkt liegt auf Gesprächen, in denen Gehörlose ihre Erfahrungen und Erlebnisse austauschen, diskutieren oder sich spontan unterhalten. Sie zeigen viele verschiedene Aspekte der Gehörlosenkultur und Gebärdensprachgemeinschaft.},
	urldate = {2022-05-03},
	publisher = {Universität Hamburg},
	author = {Hanke, Thomas and König, Susanne and Konrad, Reiner and Langer, Gabriele and Barbeito Rey-Geißler, Patricia and Blanck, Dolly and Goldschmidt, Stefan and Hofmann, Ilona and Hong, Sung-Eun and Jeziorski, Olga and Kleyboldt, Thimo and König, Lutz and Matthes, Silke and Nishio, Rie and Rathmann, Christian and Salden, Uta and Wagner, Sven and Worseck, Satu},
	year = {2020},
	note = {Medium: video/mp4,vtt},
}

@incollection{enfield_doing_2013,
	address = {Berlin},
	title = {Doing fieldwork on the body, language, and communication},
	booktitle = {Handbook {Body} – {Language} – {Communication}},
	publisher = {Mouton De Gruyter},
	author = {Enfield, N. J.},
	editor = {Müller, Cornelia and Fricke, E. and Cienki, Alan and McNeill, David and Essendorf, S.},
	year = {2013},
	pages = {974--981},
}

@article{birhane_towards_2021,
	title = {Towards {Decolonising} {Computational} {Sciences}},
	issn = {2245-6937, 0907-6182},
	url = {https://tidsskrift.dk/KKF/article/view/124899},
	doi = {10.7146/kkf.v29i2.124899},
	abstract = {This article sets out our perspective on how to begin the journey of decolonising computational fi elds, such as data and cognitive sciences. We see this struggle as requiring two basic steps: a) realisation that the present-day system has inherited, and still enacts, hostile, conservative, and oppressive behaviours and principles towards women of colour; and b) rejection of the idea that centring individual people is a solution to system-level problems. The longer we ignore these two steps, the more “our” academic system maintains its toxic structure, excludes, and harms Black women and other minoritised groups. This also keeps the door open to discredited pseudoscience, like eugenics and physiognomy. We propose that grappling with our fi elds’ histories and heritage holds the key to avoiding mistakes of the past. In contrast to, for example, initiatives such as “diversity boards”, which can be harmful because they superfi cially appear reformatory but nonetheless center whiteness and maintain the status quo. Building on the work of many women of colour, we hope to advance the dialogue required to build both a grass-roots and a top-down re-imagining of computational sciences — including but not limited to psychology, neuroscience, cognitive science, computer science, data science, statistics, machine learning, and artifi cial intelligence. We aspire to progress away fromthese fi elds’ stagnant, sexist, and racist shared past into an ecosystem that welcomes and nurturesdemographically diverse researchers and ideas that critically challenge the status quo.},
	number = {2},
	urldate = {2022-05-02},
	journal = {Kvinder, Køn \& Forskning},
	author = {Birhane, Abeba and Guest, Olivia},
	year = {2021},
	pages = {60--73},
}

@incollection{ozerov_this_2022,
	address = {Honolulu},
	title = {This research topic of yours — {Is} it a research topic at all? {Using} comparative interactional data for a fine-grained reanalysis of traditional concepts},
	booktitle = {Doing corpus-based typology with spoken language data: {State} of the art},
	publisher = {University of Hawai'i Press},
	author = {Ozerov, Pavel},
	editor = {Haig, Geoffrey and Schnell, Stefan and Seifard, Frank},
	year = {2022},
	pages = {233--280},
}

@incollection{dwyer_ethics_2006,
	title = {Ethics and practicalities of cooperative fieldwork and analysis},
	booktitle = {Essentials of language documentation},
	author = {Dwyer, Arienne M.},
	editor = {Gippert, Jost and Himmelmann, Nikolaus P. and Mosel, Ulrike},
	year = {2006},
	pages = {31},
}

@incollection{good_ethics_2018,
	address = {Oxford},
	title = {Ethics in language documentation and revitalisation},
	booktitle = {Oxford {Handbook} of {Endangered} {Languages}},
	publisher = {Oxford University Press},
	author = {Good, Jeff},
	editor = {Regh, Kenneth and Campbell, Lyle},
	year = {2018},
	pages = {419--440},
}

@article{seyfeddinipur_public_2019,
	title = {Public access to research data in language documentation: {Challenges} and possible strategies},
	volume = {13},
	shorttitle = {Public access to research data in language documentation},
	url = {https://hal.univ-lyon2.fr/hal-02394361},
	abstract = {The Open Access Movement promotes free and unfettered access to research publications and, increasingly, to the primary data which underly those publications. As the field of documentary linguistics seeks to record and preserve culturally and linguistically relevant materials, the question of how openly accessible these materials should be becomes increasingly important. This paper aims to guide researchers and other stakeholders in finding an appropriate balance between accessibility and confidentiality of data, addressing community questions and legal, institutional, and intellectual issues that pose challenges to accessible data.},
	language = {en},
	urldate = {2022-04-30},
	journal = {Language Documentation \& Conservation},
	author = {Seyfeddinipur, Mandana and Ameka, Felix and Bolton, Lissant and Blumtritt, Jonathan and Carpenter, Brian and Cruz, Hilaria and Drude, Sebastian and Epps, Patience and Ferreira, Vera and Galucio, Ana and Hellwig, Brigit and Hinte, Oliver and Holton, Gary and Jung, Dagmar and Buddeberg, Irmgarda Kasinskaite and Krifka, Manfred and Kung, Susan and Monroig, Miyuki and Neba, Ayu'Nwi Ngwabe and Nordhoff, Sebastian and Pakendorf, Brigitte and Prince, Kilu von and Rau, Felix and Rice, Keren and Riessler, Michael and Brenig, Vera and Thieberger, Nick and Trilsbeek, Paul and Voort, Hein van der and Woodbury, Tony},
	year = {2019},
	pages = {545--536},
}

@incollection{turin_access_2013,
	title = {Access and {Accessibility} at {ELAR}, a {Social} {Networking} {Archive} for {Endangered} {Languages} {Documentation}},
	isbn = {978-1-909254-30-5},
	url = {https://www.openbookpublishers.com/product/186},
	language = {English},
	urldate = {2022-04-30},
	booktitle = {Oral {Literature} in the {Digital} {Age}: {Archiving} {Orality} and {Connecting} with {Communities}},
	publisher = {Open Book Publishers},
	author = {Nathan, David},
	editor = {Turin, Mark and Wheeler, Claire and Wilkinson, Eleanor},
	year = {2013},
	doi = {10.11647/OBP.0032},
	pages = {21--40},
}

@article{himmelmann_asymmetries_2014,
	title = {Asymmetries in the prosodic phrasing of function words: {Another} look at the suffixing preference},
	volume = {90},
	issn = {1535-0665},
	shorttitle = {Asymmetries in the prosodic phrasing of function words},
	url = {https://muse.jhu.edu/journals/language/v090/90.4.himmelmann.html},
	doi = {10.1353/lan.2014.0105},
	abstract = {It is a well-known fact that across the world’s languages there is a fairly strong asymmetry in the affixation of grammatical material, in that suffixes considerably outnumber prefixes in typological databases. This article argues that prosody, specifically prosodic phrasing, plays an important part in bringing about this asymmetry. Prosodic word and phrase boundaries may occur after a clitic function word preceding its lexical host with sufficient frequency so as to impede the fusion required for affixhood. Conversely, prosodic boundaries rarely, if ever, occur between a lexical host and a clitic function word following it. Hence, prosody does not impede the fusion process between lexical hosts and postposed function words, which therefore become affixes more easily.},
	number = {4},
	urldate = {2015-07-02},
	journal = {Language},
	author = {Himmelmann, Nikolaus P.},
	year = {2014},
	note = {{\textless}p{\textgreater}Volume 90, Number 4, December 2014{\textless}/p{\textgreater}},
	pages = {927--960},
}

@article{himmelmann_reproduction_2008,
	title = {Reproduction and {Preservation} of {Linguistic} {Knowledge}: {Linguistics}’ {Response} to {Language} {Endangerment}},
	volume = {37},
	issn = {0084-6570},
	shorttitle = {Reproduction and {Preservation} of {Linguistic} {Knowledge}},
	url = {http://arjournals.annualreviews.org/doi/full/10.1146/annurev.anthro.37.081407.085226},
	doi = {10.1146/annurev.anthro.37.081407.085226},
	number = {1},
	urldate = {2009-08-02},
	journal = {Annual Review of Anthropology},
	author = {Himmelmann, Nikolaus P.},
	month = oct,
	year = {2008},
	pages = {337--350},
}

@article{himmelmann_against_2022,
	title = {Against trivializing language description (and comparison)},
	volume = {46},
	issn = {0378-4177, 1569-9978},
	url = {https://www.jbe-platform.com/content/journals/10.1075/sl.19090.him},
	doi = {10.1075/sl.19090.him},
	abstract = {Abstract This paper argues that recent proposals to sharply distinguish between language description and comparison are ill-conceived for two reasons. First, comparison is unavoidable and hence an integral part of description. Second, the proposals for a strict separation are based on an unrealistic and anachronistic conception of descriptive categories, assuming that these can be defined in purely distributional terms. Here it is shown that description and comparison make use of, and struggle with, the same kind of empirical evidence; namely, crosslinguistically identifiable properties of grammatical formatives and constructions. If descriptive categories and crosslinguistic comparative concepts did not share such properties, language comparison would be devoid of empirical content. Hence claims that they are ontologically different do not stand up to further scrutiny. In short, said recent proposals portray language description and comparison in too-simplistic terms. They ignore, or at least downplay, most of the complexities involved in both descriptive and comparative projects, many of which in fact result from the inseparability of description and comparison.},
	language = {en},
	number = {1},
	urldate = {2022-03-27},
	journal = {Studies in Language. International Journal sponsored by the Foundation “Foundations of Language”},
	author = {Himmelmann, Nikolaus P.},
	month = feb,
	year = {2022},
	note = {Publisher: John Benjamins},
	pages = {133--160},
}

@article{himmelmann_what_2016,
	title = {What about typology is useful for language documentation?},
	volume = {20},
	issn = {1430-0532, 1613-415X},
	url = {http://www.degruyter.com/view/j/lity.2016.20.issue-3/lingty-2016-0020/lingty-2016-0020.xml},
	doi = {10.1515/lingty-2016-0020},
	number = {3},
	urldate = {2016-12-29},
	journal = {Linguistic Typology},
	author = {Himmelmann, Nikolaus P.},
	month = jan,
	year = {2016},
}

@article{himmelmann_linguistic_2012,
	title = {Linguistic data types and the interface between language documentation and description},
	volume = {6},
	journal = {Language Documentation \& Conservation},
	author = {Himmelmann, Nikolaus P.},
	month = may,
	year = {2012},
	pages = {187--207},
}

@incollection{himmelmann_language_2006,
	title = {Language documentation: {What} is it and what is it good for},
	shorttitle = {Language documentation},
	booktitle = {Essentials of language documentation},
	author = {Himmelmann, Nikolaus P.},
	editor = {Gippert, Jost and Himmelmann, Nikolaus P. and Mosel, Ulrike},
	year = {2006},
	pages = {1--30},
}

@article{berez-kroeker_reproducible_2018,
	title = {Reproducible research in linguistics: {A} position statement on data citation and attribution in our field},
	volume = {56},
	issn = {0024-3949},
	shorttitle = {Reproducible research in linguistics},
	url = {https://www.degruyter.com/view/j/ling.2018.56.issue-1/ling-2017-0032/ling-2017-0032.xml?rskey=lJPgKh&result=19&q=editorial},
	doi = {10.1515/ling-2017-0032},
	abstract = {This paper is a position statement on reproducible research in linguistics, including data citation and attribution, that represents the collective views of some 41 colleagues. Reproducibility can play a key role in increasing verification and accountability in linguistic research, and is a hallmark of social science research that is currently under-represented in our field. We believe that we need to take time as a discipline to clearly articulate our expectations for how linguistic data are managed, cited, and maintained for long-term access.},
	number = {1},
	urldate = {2019-09-10},
	journal = {Linguistics},
	author = {Berez-Kroeker, Andrea L. and Gawne, Lauren and Kung, Susan Smythe and Kelly, Barbara F. and Heston, Tyler and Holton, Gary and Pulsifer, Peter and Beaver, David I. and Chelliah, Shobhana and Dubinsky, Stanley and Meier, Richard P. and Thieberger, Nick and Rice, Keren and Woodbury, Anthony C.},
	year = {2018},
	pages = {1--18},
}

@book{bowern_linguistic_2007,
	address = {New York},
	title = {Linguistic {Fieldwork}: {A} {Practical} {Guide}},
	publisher = {Palgrave MacMillan},
	author = {Bowern, Clair},
	year = {2007},
}

@incollection{bowern_elicitation_2007,
	address = {New York},
	title = {Elicitation procedure and data gathering checklist},
	booktitle = {Linguistic {Fieldwork}: {A} {Practical} {Guide}},
	publisher = {Palgrave MacMillan},
	author = {Bowern, Clair},
	year = {2007},
}

@incollection{bowern_consent_2007,
	address = {New York},
	title = {Consent forms},
	booktitle = {Linguistic {Fieldwork}: {A} {Practical} {Guide}},
	publisher = {Palgrave MacMillan},
	author = {Bowern, Clair},
	year = {2007},
}

@incollection{bowern_questions_2007,
	address = {New York},
	title = {Questions to consider when writing fieldnotes},
	booktitle = {Linguistic {Fieldwork}: {A} {Practical} {Guide}},
	publisher = {Palgrave MacMillan},
	author = {Bowern, Clair},
	year = {2007},
}

@inproceedings{rogers_just_2021,
	address = {Punta Cana, Dominican Republic},
	title = {`{Just} {What} do {You} {Think} {You}'re {Doing}, {Dave}?' {A} {Checklist} for {Responsible} {Data} {Use} in {NLP}},
	shorttitle = {`{Just} {What} do {You} {Think} {You}'re {Doing}, {Dave}?},
	url = {https://aclanthology.org/2021.findings-emnlp.414},
	doi = {10.18653/v1/2021.findings-emnlp.414},
	abstract = {A key part of the NLP ethics movement is responsible use of data, but exactly what that means or how it can be best achieved remain unclear. This position paper discusses the core legal and ethical principles for collection and sharing of textual data, and the tensions between them. We propose a potential checklist for responsible data (re-)use that could both standardise the peer review of conference submissions, as well as enable a more in-depth view of published research across the community. Our proposal aims to contribute to the development of a consistent standard for data (re-)use, embraced across NLP conferences.},
	urldate = {2022-04-29},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2021},
	publisher = {Association for Computational Linguistics},
	author = {Rogers, Anna and Baldwin, Timothy and Leins, Kobi},
	month = nov,
	year = {2021},
	pages = {4821--4833},
}

@inproceedings{zarries_decoding_2021,
	address = {Aberdeen, Scotland, UK},
	title = {Decoding, {Fast} and {Slow}: {A} {Case} {Study} on {Balancing} {Trade}-{Offs} in {Incremental}, {Character}-level {Pragmatic} {Reasoning}},
	shorttitle = {Decoding, {Fast} and {Slow}},
	url = {https://aclanthology.org/2021.inlg-1.41},
	abstract = {Recent work has adopted models of pragmatic reasoning for the generation of informative language in, e.g., image captioning. We propose a simple but highly effective relaxation of fully rational decoding, based on an existing incremental and character-level approach to pragmatically informative neural image captioning. We implement a mixed, `fast' and `slow', speaker that applies pragmatic reasoning occasionally (only word-initially), while unrolling the language model. In our evaluation, we find that increased informativeness through pragmatic decoding generally lowers quality and, somewhat counter-intuitively, increases repetitiveness in captions. Our mixed speaker, however, achieves a good balance between quality and informativeness.},
	urldate = {2022-04-29},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Natural} {Language} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Zarrieß, Sina and Buschmeier, Hendrik and Han, Ting and Schüz, Simeon},
	month = aug,
	year = {2021},
	pages = {371--376},
}

@incollection{couper-kuhlen_prosody_1996,
	address = {Cambridge / New York},
	title = {Prosody as an activity-type distinctive cue in conversation: the case of so-called ‘astonished’ questions in repair initiation},
	isbn = {978-0-521-46075-0},
	booktitle = {Prosody in conversation: interactional studies},
	publisher = {Cambridge University Press},
	author = {Selting, Margret},
	editor = {Couper-Kuhlen, Elizabeth and Selting, Margret},
	year = {1996},
	pages = {231--270},
}

@book{selting_verstandigungsprobleme_1987,
	address = {Tübingen},
	series = {Linguistische {Arbeiten}},
	title = {Verständigungsprobleme. {Eine} empirische {Analyse} am {Beispiel} der {Bürger}-{Verwaltungs}-{Kommunikation}},
	isbn = {978-3-11-135766-9},
	number = {181},
	publisher = {Niemeyer},
	author = {Selting, Margret},
	year = {1987},
}

@article{selting_emphatic_1994,
	title = {Emphatic speech style — with special focus on the prosodic signalling of heightened emotive involvement in conversation},
	volume = {22},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/B6VCW-468JM48-8/2/6c9d0213a8df89d95cf195278f0927a2},
	doi = {10.1016/0378-2166(94)90116-3},
	abstract = {After a review of previous work on the prosody of emotional involvement, data extracts from natural conversations are analyzed in order to argue for the constitution of an [`]emphatic (speech) style', which linguistic devices are used to signal heightened emotive involvement. Participants use prosodic cues, in co-occurrence with syntactic and lexical cues, to contextualize turn-constructional units as [`]emphatic'. Only realizations of prosodic categories that are marked in relation to surrounding uses of these categories have the power to contextualize units as displaying [`]more-than-normal involvement'. In the appropriate context, and in co-occurrence with syntactic and lexical cues and sequential position, the context-sensitive interpretation of this involvement is [`]emphasis'. Prosodic marking is used in addition to various unmarked cues that signal and constitute different activity types in conversation. Emphatic style highlights and reinforms particular conversational activities, and makes certain types of recipient responses locally relevant. In particular, switches from non-emphatic to emphatic style are used to contextualize [`]peaks of involvement' or [`]climaxes' in story-telling. These are shown in the paper to be [`]staged' by speakers and treated by recipients as marked activities calling for displays of alignment with respect to the matter at hand. Signals of emphasis are deployable as techniques for locally organizing demonstrations of shared understanding and participant reciprocity in conversational interaction.},
	number = {3-4},
	urldate = {2010-03-10},
	journal = {Journal of Pragmatics},
	author = {Selting, Margret},
	month = oct,
	year = {1994},
	pages = {375--408},
}

@incollection{schmidt_exmaralda_2014,
	address = {Oxford},
	title = {{EXMARaLDA}},
	booktitle = {Handbook on {Coprus} {Phonology}},
	publisher = {Oxford University Press},
	author = {Schmidt, Thomas and Wörner, Kai},
	year = {2014},
	pages = {402--419},
}

@article{ruhlemann_windows_2011,
	title = {Windows on the mind: {Pauses} in conversational narrative},
	volume = {16},
	issn = {1384-6655, 1569-9811},
	shorttitle = {Windows on the mind},
	url = {http://www.jbe-platform.com/content/journals/10.1075/ijcl.16.2.03ruh},
	doi = {10.1075/ijcl.16.2.03ruh},
	abstract = {This paper investigates four different types of pauses in conversational narrative: the filled pauses er and erm, and short and long silent pauses. The study is based on the Narrative Corpus (NC), a recently created corpus of everyday narratives. The texts, which include both the narrative and some context, have been annotated for important textual components. The current analysis reveals that pauses are more frequent in conversational narrative than in general conversation. We suggest three factors that account for this high frequency: (i) the need for narrators, in the opening utterance of the story, to provide specific information to orient listeners to the situation in which the events unfolded, (ii) the need to coordinate narrative clauses to match the story events, and (iii) the preference of narrators to present speech, thought, emotion and gesture using direct-mode discourse presentation, which is more “dramatic” but also more costly in terms of reference resolution.},
	number = {2},
	urldate = {2017-09-12},
	journal = {International Journal of Corpus Linguistics},
	author = {Rühlemann, Christoph and Bagoutdinov, Andrej and O'Donnell, Matthew Brook},
	month = jan,
	year = {2011},
	pages = {198--230},
}

@article{ruhlemann_conversational_2010,
	title = {Conversational {Grammar}- {Feminine} {Grammar}? {A} {Sociopragmatic} {Corpus} {Study}},
	volume = {38},
	issn = {0075-4242},
	shorttitle = {Conversational {Grammar}- {Feminine} {Grammar}?},
	url = {https://doi.org/10.1177/0075424209347175},
	doi = {10.1177/0075424209347175},
	abstract = {One area in language and gender research that has so far received only little attention is the extent to which the sexes make use of what recent corpus research has termed “conversational grammar.” The author’s initial findings have suggested that the majority of features distinctive of conversational grammar may be used predominantly by female speakers. This article reports on a study designed to test the hypothesis that conversational grammar is “feminine grammar” in the sense that women’s conversational language is more adapted to the conversational situation than men’s. Based on data from the conversational subcorpus of the British National Corpus and following the situational framework for the description of conversational features elaborated in the author’s previous research, features distinctive of conversational grammar are grouped into five functional categories and their normed frequencies compared across the sexes. The functional categories distinguish features that can be seen as adaptations to constraints set by the situational factors of (1) Shared Context, (2) Co-Construction, (3) Real-Time Processing, (4) Discourse Management, and (5) Relation Management. The study’s results, described in detail in relation to the biological category of speaker sex and cultural notions of gender, suggest that the feminine grammar hypothesis is valid.},
	language = {en},
	number = {1},
	urldate = {2017-09-12},
	journal = {Journal of English Linguistics},
	author = {Rühlemann, Christoph},
	month = mar,
	year = {2010},
	pages = {56--87},
}

@book{ruhlemann_conversation_2007,
	address = {London ; New York},
	series = {Corpus and discourse},
	title = {Conversation in context: a corpus-driven approach},
	isbn = {978-0-8264-9713-0},
	shorttitle = {Conversation in context},
	publisher = {Continuum},
	author = {Ruhlemann, Christoph},
	year = {2007},
	note = {OCLC: ocn105436546},
}

@article{ruhlemann_coming_2006,
	title = {Coming to terms with conversational grammar: ‘{Dislocation}’ and ‘dysfluency’},
	volume = {11},
	issn = {1384-6655, 1569-9811},
	shorttitle = {Coming to terms with conversational grammar},
	url = {http://www.jbe-platform.com/content/journals/10.1075/ijcl.11.4.03ruh},
	doi = {10.1075/ijcl.11.4.03ruh},
	abstract = {“situationally defined varieties” (Biber et al. 1999:5) have advanced the study of conversational grammar considerably. This paper questions the use of writing-based conceptual frameworks and terminologies in the description of conversational grammar. It is argued that conversation as the major situationally defined variety of the spoken language requires for its adequate description concepts and terminologies that are based on the situational factors that determine the conversational situation. The paper attempts to demonstrate that, conversely, a descriptive apparatus derived from the written code, which by necessity fails to reflect the situational factors governing conversation and implicitly compares features of conversation to the norms of the written language, inevitably conveys negative evaluation of the conversational features observed. This claim will be illustrated by functional and terminological analyses of two conversational key features commonly labelled ‘dislocation’ and ‘dysfluency’. The analyses will be carried out using data from the BNC. Potential alternative concepts and terminologies will be discussed.},
	number = {4},
	urldate = {2017-09-12},
	journal = {International Journal of Corpus Linguistics},
	author = {Rühlemann, Christoph},
	month = jan,
	year = {2006},
	pages = {385--409},
}

@article{ruhlemann_introducing_2012,
	title = {Introducing a corpus of conversational stories. {Construction} and annotation of the {Narrative} {Corpus}},
	volume = {8},
	issn = {1613-7035, 1613-7027},
	url = {https://www.degruyter.com/view/j/cllt.2012.8.issue-2/cllt-2012-0015/cllt-2012-0015.xml},
	doi = {10.1515/cllt-2012-0015},
	number = {2},
	urldate = {2017-09-12},
	journal = {Corpus Linguistics and Linguistic Theory},
	author = {Rühlemann, Christoph and O'Donnell, Matthew Brook},
	month = jan,
	year = {2012},
}

@article{ruhlemann_alternating_2019,
	title = {Alternating gaze in multi-party storytelling},
	volume = {149},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/S0378216617303326},
	doi = {10.1016/j.pragma.2019.06.001},
	abstract = {We present a single case study on gaze alternation in three-party storytelling. The study makes use of the XML method, a ‘combinatorial approach’ (Haugh and Musgrave, 2019) involving multi-modal CA transcription converted into the XML syntax. We approach gaze alternation via (i) the addressee-status hypothesis, (ii) the texturing hypothesis, and (iii) the acceleration hypothesis. Hypothesis (i) proposes that the storyteller alternatingly looks at the recipients not only when their addressee status is symmetrical but also when their addressee status is asymmetrical. Hypothesis (ii) predicts that gaze alternation ‘textures’ the telling by occurring when the storytelling progresses from one segment to another. Hypothesis (iii) states that gaze alternation accelerates toward Climax and decelerates in Post-completion sequences. The analyses support the hypotheses. They suggest that alternating gaze works against the danger of exclusion caused by the dyadic structure of conversation. It further partakes in story organization as it occurs at points of transition from one story section to another section. Finally, accelerated gaze alternation constitutes an indexical process drawing the recipients' attention to the immediate relevance of stance display (Stivers, 2008). We conclude that the three hypotheses warrant further investigation to determine their generalizability across speakers and speech situations.},
	urldate = {2019-07-09},
	journal = {Journal of Pragmatics},
	author = {Rühlemann, Christoph and Gee, Matt and Ptak, Alexander},
	month = aug,
	year = {2019},
	pages = {91--113},
}

@article{wlodarczak_breathing_2020,
	title = {Breathing in {Conversation}},
	volume = {11},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2020.575566/full},
	doi = {10.3389/fpsyg.2020.575566},
	urldate = {2022-04-29},
	journal = {Frontiers in Psychology},
	author = {Włodarczak, Marcin and Heldner, Mattias},
	month = oct,
	year = {2020},
	pages = {575566},
}

@misc{ehmer_act_2021,
	title = {act: {Aligned} {Corpus} {Toolkit}},
	url = {https://github.com/oliverehmer/act},
	abstract = {Aligned Corpus Toolkit (act) for R},
	urldate = {2022-04-29},
	author = {Ehmer, Oliver},
	year = {2021},
	note = {original-date: 2021-01-17T11:04:10Z},
}

@inproceedings{karafiat_but_2014,
	title = {But neural network features for spontaneous {Vietnamese} in {BABEL}},
	doi = {10.1109/ICASSP.2014.6854679},
	abstract = {This paper presents our work on speech recognition of Vietnamese spontaneous telephone conversations. It focuses on feature extraction by Stacked Bottle-Neck neural networks: several improvements such as semi-supervised training on untranscribed data, increasing of precision of state targets, and CMLLR adaptations were investigated. We have also tested speaker adaptive training of this architecture and significant gain was found. The results are reported on BABEL Vietnamese data.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Karafiát, Martin and Grézl, František and Hannemann, Mirko and Černocký, Jan Honza},
	month = may,
	year = {2014},
	note = {ISSN: 2379-190X},
	pages = {5622--5626},
}

@article{babu_xls-r_2021,
	title = {{XLS}-{R}: {Self}-supervised {Cross}-lingual {Speech} {Representation} {Learning} at {Scale}},
	shorttitle = {{XLS}-{R}},
	url = {http://arxiv.org/abs/2111.09296},
	abstract = {This paper presents XLS-R, a large-scale model for cross-lingual speech representation learning based on wav2vec 2.0. We train models with up to 2B parameters on nearly half a million hours of publicly available speech audio in 128 languages, an order of magnitude more public data than the largest known prior work. Our evaluation covers a wide range of tasks, domains, data regimes and languages, both high and low-resource. On the CoVoST-2 speech translation benchmark, we improve the previous state of the art by an average of 7.4 BLEU over 21 translation directions into English. For speech recognition, XLS-R improves over the best known prior work on BABEL, MLS, CommonVoice as well as VoxPopuli, lowering error rates by 14-34\% relative on average. XLS-R also sets a new state of the art on VoxLingua107 language identification. Moreover, we show that with sufficient model size, cross-lingual pretraining can outperform English-only pretraining when translating English speech into other languages, a setting which favors monolingual pretraining. We hope XLS-R can help to improve speech processing tasks for many more languages of the world.},
	urldate = {2022-04-29},
	journal = {arXiv:2111.09296 [cs, eess]},
	author = {Babu, Arun and Wang, Changhan and Tjandra, Andros and Lakhotia, Kushal and Xu, Qiantong and Goyal, Naman and Singh, Kritika and von Platen, Patrick and Saraf, Yatharth and Pino, Juan and Baevski, Alexei and Conneau, Alexis and Auli, Michael},
	month = dec,
	year = {2021},
	note = {arXiv: 2111.09296},
}

@incollection{du_bois_outline_1993,
	address = {Hillsdale, NJ},
	title = {Outline of discourse transcription},
	booktitle = {Talking {Data}: {Transcription} and {Coding} in {Discourse} {Research}},
	publisher = {Lawrence Erlbaum},
	author = {Du Bois, John W. and Schuetze-Coburn, S. and Cumming, S. and Danae, P.},
	year = {1993},
	pages = {45--89},
}

@article{du_bois_towards_2014,
	title = {Towards a dialogic syntax},
	volume = {25},
	issn = {1613-3641},
	url = {http://www.degruyter.com/view/j/cogl.2014.25.issue-3/cog-2014-0024/cog-2014-0024.xml},
	doi = {10.1515/cog-2014-0024},
	abstract = {This paper argues for the need to recognize a new order of syntactic phenomena, and for a theory of syntax capable of addressing it. Dialogic syntax encompasses the linguistic, cognitive, and interactional processes involved when speakers selectively reproduce aspects of prior utterances, and when recipients recognize the resulting parallelisms and draw inferences from them. Its most visible reflex occurs when one speaker constructs an utterance based on the immediately co-present utterance of a dialogic partner. Words, structures, and other linguistic resources invoked by the first speaker are selectively reproduced by the second. The alignment of utterances yields a pairing of patterns at varying levels of abstraction, ranging from identity of words and affixes, to parallelism of syntactic structures, to equivalence of grammatical categories and abstract features of form, meaning, and function. This mapping generates dialogic resonance, defined as the catalytic activation of affinities across utterances. The key unit of analysis is the diagraph, recognized as a higher-order, supra-sentential syntactic structure that emerges from the structural coupling of two or more utterances. Dialogic syntax goes beyond traditional linear syntax to recognize as integral to the task of syntactic analysis a new kind of structural relation that arises between otherwise independent sentences.},
	number = {3},
	urldate = {2014-11-10},
	journal = {Cognitive Linguistics},
	author = {Du Bois, John W.},
	year = {2014},
	pages = {359--410},
}

@inproceedings{lane_computational_2021,
	address = {Online},
	title = {A {Computational} {Model} for {Interactive} {Transcription}},
	url = {https://aclanthology.org/2021.dash-1.16},
	doi = {10.18653/v1/2021.dash-1.16},
	abstract = {Transcribing low resource languages can be challenging in the absence of a good lexicon and trained transcribers. Accordingly, we seek a way to enable interactive transcription whereby the machine amplifies human efforts. This paper presents a data model and a system architecture for interactive transcription, supporting multiple modes of interactivity, increasing the likelihood of finding tasks that engage local participation in language work. The approach also supports other applications which are useful in our context, including spoken document retrieval and language learning.},
	urldate = {2022-01-13},
	booktitle = {Proceedings of the {Second} {Workshop} on {Data} {Science} with {Human} in the {Loop}: {Language} {Advances}},
	publisher = {Association for Computational Linguistics},
	author = {Lane, William and Bettinson, Mat and Bird, Steven},
	month = jun,
	year = {2021},
	pages = {105--111},
}

@incollection{sidnell_conversation_2013,
	address = {Malden, MA},
	title = {The conversation analytic approach to transcription},
	isbn = {978-1-4443-3208-7},
	booktitle = {The handbook of conversation analysis},
	publisher = {Blackwell Publishers},
	author = {Hepburn, Alexa and Bolden, Galina B.},
	editor = {Sidnell, Jack and Stivers, Tanya},
	year = {2013},
}

@article{andersen_semi-lexical_2016,
	title = {Semi-lexical features in corpus transcription: {Consistency}, comparability, standardisation},
	volume = {21},
	issn = {1384-6655, 1569-9811},
	shorttitle = {Semi-lexical features in corpus transcription},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ijcl.21.3.02and},
	doi = {10.1075/ijcl.21.3.02and},
	abstract = {An aspect of corpus compilation that poses a particular challenge is the question of how to transcribe orthographically units that are not part of any standardised vocabulary. Among the problematic categories we find voiced pauses, minimal response signals, interjections, certain discourse markers, phonologically reduced forms, colloquialisms and dialect forms. Such semi-lexical features are usually represented by regular phonemic-graphemic correspondences but are nevertheless often inconsistently handled. This paper reviews a number of existing transcription guidelines and assesses whether the recommendations they provide are sufficient and detailed enough to secure a consistent transcription of the categories mentioned. Further, the paper assesses to what extent transcription of semi-lexical features is consistent within and across two spoken corpora. On the basis of a cross-corpus comparison of the Bergen Corpus of London Teenage Language (COLT) and the London English Corpus (LEC), the paper provides specific recommendations for corpus transcription.},
	language = {en},
	number = {3},
	urldate = {2020-02-15},
	journal = {International Journal of Corpus Linguistics},
	author = {Andersen, Gisle},
	month = jan,
	year = {2016},
	pages = {323--347},
}

@incollection{jefferson_exercise_1985,
	address = {London},
	title = {An exercise in the transcription and analysis of laughter},
	volume = {3},
	booktitle = {Handbook of {Discourse} {Analysis}},
	publisher = {Academic Press},
	author = {Jefferson, Gail},
	editor = {van Dijk, Teun A.},
	year = {1985},
	pages = {25--34},
}

@article{macbeth_story_2016,
	title = {The story of ‘{Oh}’, {Part} 1: {Indexing} structure, animating transcript},
	issn = {1461-4456, 1461-7080},
	shorttitle = {The story of ‘{Oh}’, {Part} 1},
	url = {http://dis.sagepub.com/content/early/2016/08/05/1461445616658205},
	doi = {10.1177/1461445616658205},
	abstract = {The expression ‘Oh’ in natural conversation is a signal topic in the development of the Epistemic Program (EP). This article attempts to bring into view a sense of place for this simple expression in the early literature, beginning with ‘Oh’ as a ‘change-of-state token’ and through its subsequent treatments in the production of assessments. It reviews them with an interest in two allied developments. One is the rendering of ‘Oh’ as an expression that ‘indexes’ epistemic structure. The other, pursued in the detail of transcript in Part 2, is how, as of this rendering, the literature manages its tasks of ‘animating transcript’, or how we portray ordinary talk as social action. We think these two moves are closely connected within the EP. And we think they yield a very different ‘vocabulary of motives’, different from the natural language studies of conversation analysis (CA). Our discussions address in turn the central phrases of our title.},
	language = {en},
	urldate = {2016-08-14},
	journal = {Discourse Studies},
	author = {Macbeth, Douglas and Wong, Jean and Lynch, Michael},
	month = aug,
	year = {2016},
	pages = {1461445616658205},
}

@article{macbeth_story_2016-1,
	title = {The story of ‘{Oh}’, {Part} 2: {Animating} transcript},
	issn = {1461-4456, 1461-7080},
	shorttitle = {The story of ‘{Oh}’, {Part} 2},
	url = {http://dis.sagepub.com/content/early/2016/08/05/1461445616658211},
	doi = {10.1177/1461445616658211},
	abstract = {In conversation analysis (CA), through Sacks, Schegloff, Jefferson, and others, the conceptual architecture is joined at the hip to a technical architecture of transcripts, sequence, and turn productions. That the conceptual was to be found and demonstrated in the material detail of temporal productions was central to CA’s extraordinary innovations. As with CA, an Epistemic CA has the task of giving evidence of its conceptual order in actual materials, and thus animating the materials to show them. The task and relationship are emblematically reflexive: we shall find the expression ‘Oh’ indexing ‘changes of state’ or ‘inapposite inquiries’, for example, as of the account-able animations of turns and sequences of turns. Our shared attachments to sequential analysis deliver the expectation that we shall see how Epistemic order is achieved on actual occasions, through actual materials, rendered as transcript. The discussion turns to how the Epistemic Program (EP) engages and acquits this analytic expectation.},
	language = {en},
	urldate = {2016-08-15},
	journal = {Discourse Studies},
	author = {Macbeth, Douglas and Wong, Jean},
	month = aug,
	year = {2016},
	pages = {1461445616658211},
}

@article{bigi_sppas_2015,
	series = {Journal of {ISPhS}/{International} {Society} of {Phonetic} {Sciences}},
	title = {{SPPAS} - {Multi}-{Lingual} {Approaches} to the {Automatic} {Annotation} of {Speech}},
	volume = {111-112},
	url = {https://hal.archives-ouvertes.fr/hal-01417876},
	abstract = {The  first  step  of  most  acoustic  analyses  unavoidably  involves  the  alignment  of 
recorded  speech  sounds  with  their  phonetic  annotation.  This  step  is  very  labor-
intensive and cost-ineffective since it has to be performed manually by experienced 
phoneticians during many hours of work. 
This paper describes the main features of SPPAS, a software tool designed for the 
needs of automatically producing annotations of speech at the level of utterance, word, 
syllable  and  phoneme  based  on  the  recorded  speech  sound  and  its  orthographic 
transcription. In other words, it can automatize the phonetic transcription task for speech 
materials,  as  well  as  the  alignment  task  of  transcription  with  speech  recordings  for 
further acoustic analyses. 
Special attention will be given to the methodology implemented in SPPAS, based 
on   algorithms   which   are   as   language-and-task-independent   as   possible.   This 
procedure allows for the addition of new languages quickly and for the adaptation of 
this  tool  to  the  user's  specific  needs.  Consequently,  the  quality  of  the  automatic 
annotations is largely influenced by external resources, and the users can modify the 
process as needed. In that sense, phoneticians need automatic tools and these tools can 
be significantly improved by phonetician input.},
	number = {ISSN:0741-6164},
	urldate = {2022-04-28},
	journal = {The Phonetician. Journal of the International Society of Phonetic Sciences},
	author = {Bigi, Brigitte},
	year = {2015},
	note = {Publisher: International Society of Phonetic Sciences - ISPhS},
	pages = {54--69},
}

@article{keevallik_sounds_2020,
	title = {Sounds on the {Margins} of {Language} at the {Heart} of {Interaction}},
	volume = {53},
	issn = {0835-1813},
	url = {https://doi.org/10.1080/08351813.2020.1712961},
	doi = {10.1080/08351813.2020.1712961},
	abstract = {What do people do with sniffs, lip-smacks, grunts, moans, sighs, whistles, and clicks, where these are not part of their language’s phonetic inventory? They use them, we shall show, as irreplaceable elements in performing all kinds of actions—from managing the structural flow of interaction to indexing states of mind and much more besides. In this introductory essay we outline the phonetic and embodied interactional underpinnings of language and argue that greater attention should be paid to its nonlexical elements. Data are in English and Estonian.},
	number = {1},
	urldate = {2020-03-05},
	journal = {Research on Language and Social Interaction},
	author = {Keevallik, Leelo and Ogden, Richard},
	month = jan,
	year = {2020},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2020.1712961},
	pages = {1--18},
}

@article{keevallik_vocalizations_2021,
	title = {Vocalizations in dance classes teach body knowledge},
	volume = {7},
	issn = {2199-174X},
	url = {https://www.degruyter.com/document/doi/10.1515/lingvan-2020-0098/html},
	doi = {10.1515/lingvan-2020-0098},
	abstract = {Language is believed to be a central device for communicating meaning and knowledge between humans. It is superb in its capacity to code abstract ideas and displaced information, which can be conveyed from person to person, sometimes across centuries. When it comes to instructing a bodily skill in co-present situations, language is used along with other multimodal resources. This paper focuses on the role of vocalizations in dance teaching, syllables that express simultaneous body movement rather than abstract lexical content. While being essentially a vocal resource, the meaning of vocalizations arises in the simultaneously moving bodies. By carrying indexical and only partially conventionalized meaning, vocalizations constitute a puzzle for linguistic theory that preferably targets the arbitrary, symbolic and conventionalized aspects of human vocal production. The meanings conveyed from one body to another through a vocalization are experiential rather than intellectual. Vocalizations provide a solution to the problem of transferring body knowledge from one autonomous organism to another, and can even be embedded in syntax. The analysis is based on an occasion of teaching a jazz routine to a larger group of students.},
	language = {en},
	number = {s4},
	urldate = {2021-08-02},
	journal = {Linguistics Vanguard},
	author = {Keevallik, Leelo},
	month = jul,
	year = {2021},
	note = {Publisher: De Gruyter Mouton
Section: Linguistics Vanguard},
}

@article{keevallik_interdependence_2013,
	title = {The {Interdependence} of {Bodily} {Demonstrations} and {Clausal} {Syntax}},
	volume = {46},
	issn = {0835-1813},
	url = {http://dx.doi.org/10.1080/08351813.2013.753710},
	doi = {10.1080/08351813.2013.753710},
	abstract = {Units in interaction are emergent real-time phenomena that can be accomplished by the coordinated deployment of language and the body. Focusing mostly on data from dance classes, this study looks at how incomplete syntax projects a continuation realized by the body and systematically accounts for clausal syntax that can incorporate an embodied demonstration. It is argued that the classic list of types of turn constructional units by Sacks et al. (1974) needs to be expanded with a syntactic-bodily one and that the syntax of embodied demonstrations has to be included in the grammatical description of language.},
	number = {1},
	urldate = {2014-06-27},
	journal = {Research on Language \& Social Interaction},
	author = {Keevallik, Leelo},
	year = {2013},
	pages = {1--21},
}

@article{keevallik_what_2018,
	title = {What {Does} {Embodied} {Interaction} {Tell} {Us} {About} {Grammar}?},
	volume = {51},
	issn = {0835-1813},
	url = {https://doi.org/10.1080/08351813.2018.1413887},
	doi = {10.1080/08351813.2018.1413887},
	abstract = {This article navigates the findings of conversation analysis, interactional linguistics, and related multimodal studies to summarize what we know about the grammar-body interface. It shows how grammar is fitted to sequences and trajectories of embodied activities, as well as deployed interchangeably with bodily displays, resulting in truly multimodal patterns that emerge in real time. These findings problematize both the paradigmatic and syntagmatic structures documented in verbal-only linguistics. They call for a reconceptualization of grammar as an assembly of routinized methods for the organization of vocal conduct, capable of incorporating aspects of participants’ bodily behavior. Data are in Estonian, French, German, Italian, Japanese and Swedish.},
	number = {1},
	urldate = {2018-03-27},
	journal = {Research on Language and Social Interaction},
	author = {Keevallik, Leelo},
	month = jan,
	year = {2018},
	pages = {1--21},
}

@article{keevallik_turn_2014,
	series = {A body of resources – {CA} studies of social conduct},
	title = {Turn organization and bodily-vocal demonstrations},
	volume = {65},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/S0378216614000241},
	doi = {10.1016/j.pragma.2014.01.008},
	abstract = {The study focuses on turns in interaction that involve a bodily-vocal demonstration: an embodied demonstration that is accompanied by a non-lexical vocalization. It shows how the temporal organization of these demonstrations contributes to participant treatment of them as a part of a turn-constructional unit, mostly as its completion. It is also suggested that a bodily-vocal demonstration may function as a separate turn-constructional unit, with a transition relevance point before it, and other participants refraining from action before its completion. Vocalizations, occasionally with coherent pitch contours of intonation units, are argued to render bodily displays vocal space within turns-at-talk. After a bodily-vocal demonstration, the turn-constructional unit can be recompleted with verbal devices, displaying further similarity to verbal-only turns. The analysis calls into attention the relevance of embodied behavior to the emergence of units in conversation.},
	urldate = {2014-06-27},
	journal = {Journal of Pragmatics},
	author = {Keevallik, Leelo},
	month = may,
	year = {2014},
	pages = {103--120},
}

@incollection{ochs_interactional_1996,
	address = {Cambridge},
	series = {Studies in interactional sociolinguistics},
	title = {Interactional units in conversation: syntactic, intonational, and pragmatic resourcers for the management of turns},
	isbn = {0-521-55225-7},
	number = {13},
	booktitle = {Interaction and {Grammar}},
	publisher = {Cambridge University Press},
	author = {Ford, Cecilia E. and Thompson, Sandra A.},
	editor = {Ochs, Elinor and Schegloff, Emanuel A. and Thompson, Sandra A.},
	year = {1996},
}

@incollection{himmelmann_meeting_2018,
	address = {Honolulu},
	title = {Meeting the {Transcription} {Challenge}},
	copyright = {Creative Commons Attribution Non-Commercial Share Alike License},
	isbn = {978-0-9973295-3-7},
	url = {http://scholarspace.manoa.hawaii.edu/handle/10125/24806},
	abstract = {The major challenge for language documentation in the next decade or two is what could be called the transcription challenge. This is a multilayered challenge that goes far beyond the practical challenge of speeding up the transcription process. Transcription, as practiced in language documentation, involves language making and changes the language ecology. Despite its centrality to language documentation, transcription remains critically undertheorized and understudied. Further progress in language documentation, and ultimately also its overall success, crucially depends on further investigating and understanding the transcription process, broadly conceived.},
	language = {en},
	urldate = {2022-04-28},
	booktitle = {Reflections on {Language} {Documentation} 20 {Years} after {Himmelmann} 1998},
	publisher = {University of Hawai'i Press},
	author = {Himmelmann, Nikolaus P.},
	editor = {McDonnell, Bradley and Berez-Kroeker, Andrea L. and Holton, Gary},
	month = dec,
	year = {2018},
	note = {Accepted: 2019-02-26T00:03:32Z
Pages: 39-55},
	pages = {33--40},
}

@inproceedings{dingemanse_high_2012,
	address = {Avignon, France},
	title = {A high speed transcription interface for annotating primary linguistic data},
	booktitle = {Proceedings of the 6th {Workshop} on {Language} {Technology} for {Cultural} {Heritage}, {Social} {Sciences}, and {Humanities}},
	author = {Dingemanse, Mark and Hammond, Jeremy and Stehouwer, Herman and Somasundaram, Aarthy and Drude, Sebastian},
	month = mar,
	year = {2012},
	pages = {7--12},
}

@book{boeckx_language_2010,
	address = {Malden, MA},
	title = {Language in cognition: uncovering mental structures and the rules behind them},
	isbn = {978-1-4051-5881-7 1-4051-5881-6 978-1-4051-5882-4 1-4051-5882-4},
	shorttitle = {Language in cognition},
	language = {English},
	publisher = {Wiley-Blackwell},
	author = {Boeckx, Cedric},
	year = {2010},
}

@techreport{chari_specious_2021,
	title = {The {Specious} {Art} of {Single}-{Cell} {Genomics}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.08.25.457696v3},
	abstract = {Dimensionality reduction is standard practice for filtering noise and identifying relevant dimensions in large-scale data analyses. In biology, single-cell expression studies almost always begin with reduction to two or three dimensions to produce ‘all-in-one’ visuals of the data that are amenable to the human eye, and these are subsequently used for qualitative and quantitative analysis of cell relationships. However, there is little theoretical support for this practice. We examine the theoretical and practical implications of low-dimensional embedding of single-cell data, and find extensive distortions incurred on the global and local properties of biological patterns relative to the highdimensional, ambient space. In lieu of this, we propose semi-supervised dimensionality reduction to higher dimension, and show that such targeted reduction guided by the metadata associated with single-cell experiments provides useful latent space representations for hypothesis-driven biological discovery.},
	language = {en},
	urldate = {2022-04-28},
	institution = {bioRxiv},
	author = {Chari, Tara and Banerjee, Joeyta and Pachter, Lior},
	month = sep,
	year = {2021},
	doi = {10.1101/2021.08.25.457696},
	note = {Section: New Results
Type: article},
	pages = {2021.08.25.457696},
}

@article{pagliarini_low-dimensional_2022,
	title = {Low-dimensional representation of infant and adult vocalization acoustics},
	url = {http://arxiv.org/abs/2204.12279},
	abstract = {During the first years of life, infant vocalizations change considerably, as infants develop the vocalization skills that enable them to produce speech sounds. Characterizations based on specific acoustic features, protophone categories, or phonetic transcription are able to provide a representation of the sounds infants make at different ages and in different contexts but do not fully describe how sounds are perceived by listeners, can be inefficient to obtain at large scales, and are difficult to visualize in two dimensions without additional statistical processing. Machine-learning-based approaches provide the opportunity to complement these characterizations with purely data-driven representations of infant sounds. Here, we use spectral features extraction and unsupervised machine learning, specifically Uniform Manifold Approximation (UMAP), to obtain a novel 2-dimensional spatial representation of infant and caregiver vocalizations extracted from day-long home recordings. UMAP yields a continuous and well-distributed space conducive to certain analyses of infant vocal development. For instance, we found that the dispersion of infant vocalization acoustics within the 2-D space over a day increased from 3 to 9 months, and then decreased from 9 to 18 months. The method also permits analysis of similarity between infant and adult vocalizations, which also shows changes with infant age.},
	urldate = {2022-04-28},
	journal = {arXiv:2204.12279 [cs, eess]},
	author = {Pagliarini, Silvia and Schneider, Sara and Kello, Christopher T. and Warlaumont, Anne S.},
	month = apr,
	year = {2022},
	note = {arXiv: 2204.12279},
}

@inproceedings{riviere_towards_2021,
	title = {Towards {Unsupervised} {Learning} of {Speech} {Features} in the {Wild}},
	doi = {10.1109/SLT48900.2021.9383461},
	abstract = {Recent work on unsupervised contrastive learning of speech representation has shown promising results, but so far has mostly been applied to clean, curated speech datasets. Can it also be used with unprepared audio data "in the wild"? Here, we explore three potential problems in this setting: (i) presence of non-speech data, (ii) noisy or low quality speech data, and (iii) imbalance in speaker distribution. We show that on the Libri-light train set, which is itself a relatively clean speech-only dataset, these problems combined can already have a performance cost of up to 30\% relative for the ABX score. We show that the first two problems can be alleviated by data filtering, with voice activity detection selecting speech segments, while perplexity of a model trained with clean data helping to discard entire files. We show that the third problem can be alleviated by learning a speaker embedding in the predictive branch of the model. We show that these techniques build more robust speech features that can be transferred to an ASR task in the low resource setting.},
	booktitle = {2021 {IEEE} {Spoken} {Language} {Technology} {Workshop} ({SLT})},
	author = {Rivière, Morgane and Dupoux, Emmanuel},
	month = jan,
	year = {2021},
	keywords = {Filtering, Predictive models, Speech recognition, Task analysis, Training, Unsupervised learning, Voice activity detection, contrastive predictive coding, data filtering, speaker adaptation, speech recognition, unsupervised representation learning},
	pages = {156--163},
}

@article{schwartz_institute_nodate,
	title = {Institute of {Northern} {Engineering} {University} of {Alaska} {Fairbanks}, {Alaska}},
	abstract = {In this paper, we challenge the ACL community to reckon with historical and ongoing colonialism by adopting a set of ethical obligations and best practices drawn from the Indigenous studies literature. While the vast majority of NLP research focuses on a very small number of very high resource languages (English, Chinese, etc), some work has begun to engage with Indigenous languages. No research involving Indigenous language data can be considered ethical without ﬁrst acknowledging that Indigenous languages are not merely very low resource languages. The toxic legacy of colonialism permeates every aspect of interaction between Indigenous communities and outside researchers. Ethical research must actively challenge this colonial legacy by actively acknowledging and opposing its continuing presence, and by explicitly acknowledging and centering Indigenous community goals and Indigenous ways of knowing. To this end, we propose that the ACL draft and adopt an ethical framework for NLP researchers and computational linguists wishing to engage in research involving Indigenous languages.},
	language = {en},
	author = {Schwartz, Lane},
	pages = {8},
}

@incollection{garfinkel_respecifying_2005,
	address = {Boulder, Colo},
	title = {Respecifying the {Study} of {Social} {Order}—{Garfinkel}'s {Transition} from {Theoretical} {Conceptualization} to {Practices} in {Details}},
	isbn = {978-1-59451-093-9 978-1-59451-092-2},
	booktitle = {Seeing sociologically: the routine grounds of social action},
	publisher = {Paradigm Publishers},
	author = {Rawls, Anne Warfield},
	collaborator = {Garfinkel, Harold},
	year = {2005},
	pages = {1--97},
}

@book{garfinkel_seeing_2005,
	address = {Boulder, Colo},
	title = {Seeing sociologically: the routine grounds of social action},
	isbn = {978-1-59451-093-9 978-1-59451-092-2},
	shorttitle = {Seeing sociologically},
	publisher = {Paradigm Publishers},
	author = {Garfinkel, Harold},
	year = {2005},
}

@article{garfinkel_evidence_1988,
	title = {Evidence for {Locally} {Produced}, {Naturally} {Accountable} {Phenomena} of {Order}, {Logic}, {Reason}, {Meaning}, {Method}, etc. {In} and as of the {Essential} {Quiddity} of {Immortal} {Ordinary} {Society}, ({I} of {IV}): {An} {Announcement} of {Studies}},
	volume = {6},
	issn = {0735-2751},
	shorttitle = {Evidence for {Locally} {Produced}, {Naturally} {Accountable} {Phenomena} of {Order}, {Logic}, {Reason}, {Meaning}, {Method}, etc. {In} and as of the {Essential} {Quiddity} of {Immortal} {Ordinary} {Society}, ({I} of {IV})},
	url = {https://www.jstor.org/stable/201918},
	doi = {10.2307/201918},
	number = {1},
	urldate = {2022-04-25},
	journal = {Sociological Theory},
	author = {Garfinkel, Harold},
	year = {1988},
	note = {Publisher: [American Sociological Association, Wiley, Sage Publications, Inc.]},
	pages = {103--109},
}

@article{oleary_googles_2019,
	title = {{GOOGLE}'{S} {Duplex}: {Pretending} to be human},
	volume = {26},
	issn = {1099-1174},
	shorttitle = {{GOOGLE}'{S} {Duplex}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/isaf.1443},
	doi = {10.1002/isaf.1443},
	abstract = {Google's Duplex is a computer-based system with natural language capabilities that provides a human sounding conversation as it performs a set of tasks, such as making restaurant reservations. This paper analyses Google's Duplex and some of the initial reaction to the system and its capabilities. The paper does a text analysis and finds that the system-generated text creates standardized ratings that suggest the text is analytical, authentic and possesses a generally positive tone. As would be expected for the applications for which it is being used, the text is heavily focused on the present. In addition, this analysis indicates that the text provides evidence of social processes, cognitive processes, tentativeness and affiliation. Further, this paper examines some of the characteristics of speech that Duplex uses to sound human. Those capabilities appear to allow the system pass the Turing test for some well-structured tasks. However, this paper investigates some of the ethics of pretending to be human and suggests that such impersonation is against evolving computer codes of ethics.},
	language = {en},
	number = {1},
	urldate = {2022-04-25},
	journal = {Intelligent Systems in Accounting, Finance and Management},
	author = {O'Leary, Daniel E.},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/isaf.1443},
	pages = {46--53},
}

@misc{nichol_5_2020,
	title = {5 {Levels} of {Conversational} {AI} - 2020 {Update}},
	url = {https://rasa.com/blog/5-levels-of-conversational-ai-2020-update/},
	abstract = {Since we first published the 5 levels of AI assistants, the market and tech have changed, and it’s time for an update. End users are already telling us what they want from AI assistants, and to get to level 5 we “just” have to listen.},
	language = {en},
	urldate = {2022-04-25},
	journal = {Rasa},
	author = {Nichol, Alan},
	year = {2020},
}

@inproceedings{rodel_towards_2014,
	title = {Towards autonomous cars: the effect of autonomy levels on acceptance and user experience},
	shorttitle = {Towards autonomous cars},
	booktitle = {Proceedings of the 6th international conference on automotive user interfaces and interactive vehicular applications},
	author = {Rödel, Christina and Stadler, Susanne and Meschtscherjakov, Alexander and Tscheligi, Manfred},
	year = {2014},
	pages = {1--8},
}

@article{labov_finding_1966,
	title = {Finding out about children’s language},
	volume = {1},
	journal = {Working Papers in Communication},
	author = {Labov, William},
	year = {1966},
	pages = {1--30},
}

@book{moerman_talking_1988,
	address = {Philadelphia},
	series = {University of {Pennsylvania} publications in conduct and communication},
	title = {Talking {Culture}: {Ethnography} and {Conversation} {Analysis}},
	isbn = {0-8122-8072-5},
	shorttitle = {Talking {Culture}},
	publisher = {University of Pennsylvania Press},
	author = {Moerman, Michael},
	year = {1988},
}

@article{clark_social_2022,
	title = {Social robots as depictions of social agents},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X22000668/type/journal_article},
	doi = {10.1017/S0140525X22000668},
	abstract = {Abstract
            Social robots serve people as tutors, caretakers, receptionists, companions, and other social agents. People know that the robots are mechanical artifacts, yet they interact with them as if they were actual agents. How is this possible? The proposal here is that people construe social robots not as social agents per se, but as depictions of social agents. They interpret them much as they interpret ventriloquist dummies, hand puppets, virtual assistants, and other interactive depictions of people and animals. Depictions as a class consist of three physical scenes with part-by-part mappings between them: (a) a base scene (the raw physical artifact), (b) the depiction proper (the artifact construed as a depiction), and (c) the scene depicted (the scene people are to imagine). With social robots, evidence shows, people form the same three scenes plus mappings: They perceive the raw machinery of a robot, construe it as a depiction of a character, and, using the depiction as a guide, engage in the pretense that they are interacting with the character depicted. So, with social robots, people also recognize three classes of agents—the characters depicted, the intended recipients of the depictions (those who view or interact with the robots), and the authorities responsible for the robots (the designers, makers, and owners). Construing social robots as depictions, we argue, accounts for many phenomena not covered by alternative models.},
	language = {en},
	urldate = {2022-04-21},
	journal = {Behavioral and Brain Sciences},
	author = {Clark, Herbert H. and Fischer, Kerstin},
	month = mar,
	year = {2022},
	pages = {1--33},
}

@article{mori_uncanny_2012,
	title = {The {Uncanny} {Valley} [{From} the {Field}]},
	volume = {19},
	issn = {1558-223X},
	doi = {10.1109/MRA.2012.2192811},
	abstract = {More than 40 years ago, Masahiro Mori, a robotics professor at the Tokyo Institute of Technology, wrote an essay [1] on how he envisioned people's reactions to robots that looked and acted almost like a human. In particular, he hypothesized that a person's response to a humanlike robot would abruptly shift from empathy to revulsion as it approached, but failed to attain, a lifelike appearance. This descent into eeriness is known as the uncanny valley. The essay appeared in an obscure Japanese journal called Energy in 1970, and in subsequent years, it received almost no attention. However, more recently, the concept of the uncanny valley has rapidly attracted interest in robotics and other scientific circles as well as in popular culture. Some researchers have explored its implications for human-robot interaction and computer-graphics animation, whereas others have investigated its biological and social roots. Now interest in the uncanny valley should only intensify, as technology evolves and researchers build robots that look human. Although copies of Mori's essay have circulated among researchers, a complete version hasn't been widely available. The following is the first publication of an English translation that has been authorized and reviewed by Mori. (See “Turning Point” in this issue for an interview with Mori.).},
	number = {2},
	journal = {IEEE Robotics Automation Magazine},
	author = {Mori, Masahiro and MacDorman, Karl F. and Kageki, Norri},
	month = jun,
	year = {2012},
	note = {Conference Name: IEEE Robotics Automation Magazine},
	pages = {98--100},
}

@book{heath_technology_2000,
	address = {Cambridge, U.K. ; New York},
	series = {Learning in doing},
	title = {Technology in action},
	isbn = {978-0-521-56033-7 978-0-521-56869-2},
	publisher = {Cambridge University Press},
	author = {Heath, Christian and Luff, Paul},
	year = {2000},
}

@article{lipp_caring_2022,
	title = {Caring for robots: {How} care comes to matter in human-machine interfacing},
	issn = {0306-3127},
	shorttitle = {Caring for robots},
	url = {https://doi.org/10.1177/03063127221081446},
	doi = {10.1177/03063127221081446},
	abstract = {Care robots promise to assist older people in an ageing society. This article investigates the socio-material conditions of care with robots by focusing on the usually invisible practices of human-machine interfacing. I define human-machine interfacing as the activities by roboticists and others to render interaction between robots and people possible in the first place. This includes, efforts to render prototypical arrangements of care ‘robot-friendly’. In my video-assisted ethnography of human-robot interaction (HRI) experiments. I identify four types of interfacing practices, where care comes to matter: integrating the ephemeral entity that is ‘a robot’, helping it by way of mundane courtesies, making users ‘fit’ for interacting with it, and establishing corridors of interaction between the robot and people’s bodies. I show that robots do not so much care for (older) people but rather, the other way around – people need to care for robots. Hence, care robots are not simply agents of care but also objects of care, rendering necessary a symmetrical analysis of human-machine interfacing. Furthermore, these practices do not merely reflect the prototypical state of the art in robotics. Rather, they indicate a more general mode of how robots and people interface. I argue that care with robots requires us to re-consider the exclusive focus on the human and at least complement it with care for the non-human and, incidentally, the robotic, too.},
	language = {en},
	urldate = {2022-04-21},
	journal = {Social Studies of Science},
	author = {Lipp, Benjamin},
	month = apr,
	year = {2022},
	note = {Publisher: SAGE Publications Ltd},
	pages = {03063127221081446},
}

@article{jefferson_case_1973,
	title = {A {Case} of {Precision} {Timing} in {Ordinary} {Conversation}: {Overlapped} {Tag}-{Positioned} {Address} {Terms} in {Closing} {Sequences}},
	volume = {9},
	issn = {0037-1998, 1613-3692},
	shorttitle = {A {Case} of {Precision} {Timing} in {Ordinary} {Conversation}},
	url = {http://www.reference-global.com/doi/abs/10.1515/semi.1973.9.1.47},
	doi = {10.1515/semi.1973.9.1.47},
	number = {1},
	urldate = {2011-12-06},
	journal = {Semiotica},
	author = {Jefferson, Gail},
	month = jan,
	year = {1973},
	pages = {47--96},
}

@article{lerner_notes_1989,
	title = {Notes on overlap management in conversation: {The} case of delayed completion},
	volume = {53},
	shorttitle = {Notes on overlap management in conversation},
	number = {2},
	journal = {Western Journal of Speech Communication},
	author = {Lerner, Gene H.},
	year = {1989},
	pages = {167--177},
}

@article{marmorstein_responses_2021,
	title = {Responses within activities: {Alignment} via {Egyptian} {Arabic} ʔāh ‘yeah’ in extended turns *},
	shorttitle = {Responses within activities},
	url = {https://www.jbe-platform.com/content/journals/10.1075/il.21003.mar},
	doi = {10.1075/il.21003.mar},
	abstract = {Abstract Large conversational activities (e.g., storytelling) necessitate a suspension of ordinary turn-taking rules. In the resulting constellation of main speaker and recipient, minimal displays of cooperative recipiency become relevant at particular junctures. We investigate this mechanism by focusing on the Egyptian Arabic particle ʔāh ‘yeah’ when thus used. We observe that tokens of ʔāh are mobilized by main speakers via the opening of prosodic slots at local pragmatic completion points. The prosodic design of the particle at these points is sensitive to prior talk and displays recipients’ alignment at the structural, action-sequential, and relational levels. This is done through variation of three prosodic features, namely, rhythm-based timing, pitch configuration, and prominence. The measure of alignment proposed by ʔāh is implicative for the continuation of the turn. While smooth progression suggests that ʔāh is understood to be sufficiently fitted and aligned, expansions are traceable to a departure from the terms set by prior talk, which can be heard to indicate lesser alignment. We propose to view ʔāh response tokens as a subset of positionally sensitive responses to part-of-activity actions that are crucial for the co-accomplishment of a large activity.},
	language = {en},
	urldate = {2022-04-19},
	author = {Marmorstein, Michal and Matalon, Nadav},
	month = dec,
	year = {2021},
	note = {Publisher: John Benjamins},
}

@article{fischer_tracking_2022,
	title = {Tracking {Anthropomorphizing} {Behavior} in {Human}-{Robot} {Interaction}},
	volume = {11},
	issn = {2573-9522, 2573-9522},
	url = {https://dl.acm.org/doi/10.1145/3442677},
	doi = {10.1145/3442677},
	abstract = {Existing methodologies to describe anthropomorphism in human-robot interaction often rely either on specific one-time responses to robot behavior, such as keeping the robot's secret, or on post hoc measures, such as questionnaires. Currently, there is no method to describe the dynamics of people's behavior over the course of an interaction and in response to robot behavior. In this paper, I propose a method that allows the researcher to trace anthropomorphizing and non-anthropomorphizing responses to robots dynamically moment-by-moment over the course of human-robot interactions. I illustrate this methodology in a case study and find considerable variation between participants, but also considerable intrapersonal variation in the ways the robot is anthropomorphized. That is, people may respond to the robot as if it was another human in one moment and to its machine-like properties in the next. These findings may influence explanatory models of anthropomorphism.},
	language = {en},
	number = {1},
	urldate = {2022-04-19},
	journal = {ACM Transactions on Human-Robot Interaction},
	author = {Fischer, Kerstin},
	month = mar,
	year = {2022},
	pages = {1--28},
}

@article{fischer_what_nodate,
	title = {What {Computer} {Talk} {Is} and {Isn}’t},
	language = {en},
	author = {Fischer, Kerstin},
	pages = {164},
}

@article{deppermann_inferential_2018,
	title = {Inferential {Practices} in {Social} {Interaction}: {A} {Conversation}-{Analytic} {Account}},
	volume = {4},
	shorttitle = {Inferential {Practices} in {Social} {Interaction}},
	url = {https://www.degruyter.com/view/j/opli.2018.4.issue-1/opli-2018-0003/opli-2018-0003.xml?format=INT},
	doi = {10.1515/opli-2018-0003},
	abstract = {This paper argues that conversation analysis has largely neglected the fact that meaning in interaction relies on inferences to a high degree. Participants treat each other as cognitive agents, who imply and infer meanings, which are often consequential for interactional progression. Based on the study of audio- and video-recordings from German talk-in-interaction, the paper argues that inferences matter to social interaction in at least three ways. They can be explicitly formulated; they can be (conventionally) indexed, but not formulated; or they may be neither indexed nor formulated yet would be needed for the correct understanding of a turn. The last variety of inferences usually remain tacit, but are needed for smooth interactional progression. Inferences in this case become an observable discursive phenomenon if misunderstandings are treated by the explication of correct (accepted) and wrong (unaccepted) inferences. The understanding of referential terms, analepsis, and ellipsis regularly rely on inferences. Formulations, third-position repairs, and fourth-position explications of erroneous inferences are practices of explicating inferences. There are conventional linguistic means like discourse markers, connectives, and response particles that index specific kinds of inferences. These practices belong to a larger class of inferential practices, which play an important role for indexing and accomplishing intersubjectivity in talk in interaction.},
	number = {1},
	urldate = {2018-06-21},
	journal = {Open Linguistics},
	author = {Deppermann, Arnulf},
	year = {2018},
	pages = {35--55},
}

@article{benjamin_when_2012,
	title = {When {Problems} {Pass} {Us} {By}: {Using} “{You} {Mean}” to {Help} {Locate} the {Source} of {Trouble}},
	volume = {45},
	issn = {0835-1813},
	shorttitle = {When {Problems} {Pass} {Us} {By}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/08351813.2012.646742},
	doi = {10.1080/08351813.2012.646742},
	abstract = {Sometimes a person may require the previous speaker to repeat, explain, confirm, etc., what they have just said. Such ?other-initiations of repair,? as they are called, usually come sharply. On occasion, however, they are issued some time after the offending talk has passed. This might pose a puzzle to the previous speaker who would normally expect problems to be identified immediately. This article argues that recipients can help them by signaling that their other-initiation has, for whatever reason, become separated from the source of the trouble. This is first shown for the particular practice of using ?you mean ? ? to check one's understanding. A variety of similar practices are then collected together to suggest that the need for managing this puzzle is quite generic and widespread. Finally, it is shown that such practices can have consequences for our understanding of repair more broadly. Examining their use allows us to refine our characterization of where other-initiations normally occur and provides evidence that this contiguous positioning is preferred over noncontiguous positioning.
Sometimes a person may require the previous speaker to repeat, explain, confirm, etc., what they have just said. Such ?other-initiations of repair,? as they are called, usually come sharply. On occasion, however, they are issued some time after the offending talk has passed. This might pose a puzzle to the previous speaker who would normally expect problems to be identified immediately. This article argues that recipients can help them by signaling that their other-initiation has, for whatever reason, become separated from the source of the trouble. This is first shown for the particular practice of using ?you mean ? ? to check one's understanding. A variety of similar practices are then collected together to suggest that the need for managing this puzzle is quite generic and widespread. Finally, it is shown that such practices can have consequences for our understanding of repair more broadly. Examining their use allows us to refine our characterization of where other-initiations normally occur and provides evidence that this contiguous positioning is preferred over noncontiguous positioning.},
	number = {1},
	journal = {Research on Language \& Social Interaction},
	author = {Benjamin, Trevor},
	year = {2012},
	pages = {82--109},
}

@article{trujillo_multi-scale_nodate,
	title = {A multi-scale investigation of the human communication system's response to visual disruption},
	volume = {9},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.211489},
	doi = {10.1098/rsos.211489},
	abstract = {In human communication, when the speech is disrupted, the visual channel (e.g. manual gestures) can compensate to ensure successful communication. Whether speech also compensates when the visual channel is disrupted is an open question, and one that significantly bears on the status of the gestural modality. We test whether gesture and speech are dynamically co-adapted to meet communicative needs. To this end, we parametrically reduce visibility during casual conversational interaction and measure the effects on speakers' communicative behaviour using motion tracking and manual annotation for kinematic and acoustic analyses. We found that visual signalling effort was flexibly adapted in response to a decrease in visual quality (especially motion energy, gesture rate, size, velocity and hold-time). Interestingly, speech was also affected: speech intensity increased in response to reduced visual quality (particularly in speech-gesture utterances, but independently of kinematics). Our findings highlight that multi-modal communicative behaviours are flexibly adapted at multiple scales of measurement and question the notion that gesture plays an inferior role to speech.},
	number = {4},
	urldate = {2022-04-15},
	journal = {Royal Society Open Science},
	author = {Trujillo, James P. and Levinson, Stephen C. and Holler, Judith},
	note = {Publisher: Royal Society},
	pages = {211489},
}

@article{grand_semantic_2022,
	title = {Semantic projection recovers rich human knowledge of multiple object features from word embeddings},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-022-01316-8},
	doi = {10.1038/s41562-022-01316-8},
	abstract = {How is knowledge about word meaning represented in the mental lexicon? Current computational models infer word meanings from lexical co-occurrence patterns. They learn to represent words as vectors in a multidimensional space, wherein words that are used in more similar linguistic contexts—that is, are more semantically related—are located closer together. However, whereas inter-word proximity captures only overall relatedness, human judgements are highly context dependent. For example, dolphins and alligators are similar in size but differ in dangerousness. Here, we use a domain-general method to extract context-dependent relationships from word embeddings: ‘semantic projection’ of word-vectors onto lines that represent features such as size (the line connecting the words ‘small’ and ‘big’) or danger (‘safe’ to ‘dangerous’), analogous to ‘mental scales’. This method recovers human judgements across various object categories and properties. Thus, the geometry of word embeddings explicitly represents a wealth of context-dependent world knowledge.},
	language = {en},
	urldate = {2022-04-14},
	journal = {Nature Human Behaviour},
	author = {Grand, Gabriel and Blank, Idan Asher and Pereira, Francisco and Fedorenko, Evelina},
	month = apr,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	pages = {1--13},
}

@article{poulton_jedrzejowski_2022,
	title = {Jędrzejowski, Łukasz and {Przemysław} {Staniewski}: {The} linguistics of olfaction: {Typological} and diachronic approaches to synchronic diversity},
	issn = {1613-415X},
	shorttitle = {Jędrzejowski, Łukasz and {Przemysław} {Staniewski}},
	url = {https://www.degruyter.com/document/doi/10.1515/lingty-2021-0064/html?casa_token=T7_RUZULTEMAAAAA%3A-WdRymhJG_jjNfTMmzdJGvTzuSSaJKCPjOx-_05ABD6a2BKM8nAUx51ZIkAeTXM_cHGRv0evLpfk},
	doi = {10.1515/lingty-2021-0064},
	abstract = {Article Jędrzejowski, Łukasz and Przemysław Staniewski: The linguistics of olfaction: Typological and diachronic approaches to synchronic diversity was published on March 21, 2022 in the journal Linguistic Typology  (volume 0, issue 0).},
	language = {en},
	urldate = {2022-04-14},
	journal = {Linguistic Typology},
	author = {Poulton, Thomas},
	month = mar,
	year = {2022},
	note = {Publisher: De Gruyter Mouton},
}

@article{huang_challenges_2020,
	title = {Challenges in {Building} {Intelligent} {Open}-domain {Dialog} {Systems}},
	volume = {38},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3383123},
	doi = {10.1145/3383123},
	abstract = {There is a resurgent interest in developing intelligent open-domain dialog systems due to the availability of large amounts of conversational data and the recent progress on neural approaches to conversational AI [33]. Unlike traditional task-oriented bots, an open-domain dialog system aims to establish long-term connections with users by satisfying the human need for communication, affection, and social belonging. This article reviews the recent work on neural approaches that are devoted to addressing three challenges in developing such systems: semantics, consistency, and interactiveness. Semantics requires a dialog system to not only understand the content of the dialog but also identify users’ emotional and social needs during the conversation. Consistency requires the system to demonstrate a consistent personality to win users’ trust and gain their long-term confidence. Interactiveness refers to the system’s ability to generate interpersonal responses to achieve particular social goals such as entertainment and conforming. The studies we select to present in this survey are based on our unique views and are by no means complete. Nevertheless, we hope that the discussion will inspire new research in developing more intelligent open-domain dialog systems.},
	number = {3},
	urldate = {2022-04-14},
	journal = {ACM Transactions on Information Systems},
	author = {Huang, Minlie and Zhu, Xiaoyan and Gao, Jianfeng},
	month = apr,
	year = {2020},
	pages = {21:1--21:32},
}

@article{zhang_dialogpt_2020,
	title = {{DialoGPT}: {Large}-{Scale} {Generative} {Pre}-training for {Conversational} {Response} {Generation}},
	shorttitle = {{DialoGPT}},
	url = {http://arxiv.org/abs/1911.00536},
	abstract = {We present a large, tunable neural conversational response generation model, DialoGPT (dialogue generative pre-trained transformer). Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch transformer to attain a performance close to human both in terms of automatic and human evaluation in single-turn dialogue settings. We show that conversational systems that leverage DialoGPT generate more relevant, contentful and context-consistent responses than strong baseline systems. The pre-trained model and training pipeline are publicly released to facilitate research into neural response generation and the development of more intelligent open-domain dialogue systems.},
	urldate = {2022-04-14},
	journal = {arXiv:1911.00536 [cs]},
	author = {Zhang, Yizhe and Sun, Siqi and Galley, Michel and Chen, Yen-Chun and Brockett, Chris and Gao, Xiang and Gao, Jianfeng and Liu, Jingjing and Dolan, Bill},
	month = may,
	year = {2020},
	note = {arXiv: 1911.00536},
}

@inproceedings{basar_hints_2022,
	address = {Online Streaming, --- Select a Country ---},
	title = {Hints of {Independence} in a {Pre}-scripted {World}: {On} {Controlled} {Usage} of {Open}-domain {Language} {Models} for {Chatbots} in {Highly} {Sensitive} {Domains}:},
	isbn = {978-989-758-547-0},
	shorttitle = {Hints of {Independence} in a {Pre}-scripted {World}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010914300003116},
	doi = {10.5220/0010914300003116},
	language = {en},
	urldate = {2022-04-14},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Agents} and {Artificial} {Intelligence}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Başar, Erkan and Hendrickx, Iris and Krahmer, Emiel and de Bruijn, Gert-Jan and Bosse, Tibor},
	year = {2022},
	pages = {401--407},
}

@article{polyak_speech_2021,
	title = {Speech {Resynthesis} from {Discrete} {Disentangled} {Self}-{Supervised} {Representations}},
	url = {http://arxiv.org/abs/2104.00355},
	abstract = {We propose using self-supervised discrete representations for the task of speech resynthesis. To generate disentangled representation, we separately extract low-bitrate representations for speech content, prosodic information, and speaker identity. This allows to synthesize speech in a controllable manner. We analyze various state-of-the-art, self-supervised representation learning methods and shed light on the advantages of each method while considering reconstruction quality and disentanglement properties. Specifically, we evaluate the F0 reconstruction, speaker identification performance (for both resynthesis and voice conversion), recordings' intelligibility, and overall quality using subjective human evaluation. Lastly, we demonstrate how these representations can be used for an ultra-lightweight speech codec. Using the obtained representations, we can get to a rate of 365 bits per second while providing better speech quality than the baseline methods. Audio samples can be found under the following link: speechbot.github.io/resynthesis.},
	urldate = {2022-04-14},
	journal = {arXiv:2104.00355 [cs, eess]},
	author = {Polyak, Adam and Adi, Yossi and Copet, Jade and Kharitonov, Eugene and Lakhotia, Kushal and Hsu, Wei-Ning and Mohamed, Abdelrahman and Dupoux, Emmanuel},
	month = jul,
	year = {2021},
	note = {arXiv: 2104.00355},
}

@article{lee_direct_2022,
	title = {Direct speech-to-speech translation with discrete units},
	url = {http://arxiv.org/abs/2107.05604},
	abstract = {We present a direct speech-to-speech translation (S2ST) model that translates speech from one language to speech in another language without relying on intermediate text generation. We tackle the problem by first applying a self-supervised discrete speech encoder on the target speech and then training a sequence-to-sequence speech-to-unit translation (S2UT) model to predict the discrete representations of the target speech. When target text transcripts are available, we design a joint speech and text training framework that enables the model to generate dual modality output (speech and text) simultaneously in the same inference pass. Experiments on the Fisher Spanish-English dataset show that the proposed framework yields improvement of 6.7 BLEU compared with a baseline direct S2ST model that predicts spectrogram features. When trained without any text transcripts, our model performance is comparable to models that predict spectrograms and are trained with text supervision, showing the potential of our system for translation between unwritten languages. Audio samples are available at https://facebookresearch.github.io/speech\_translation/direct\_s2st\_units/index.html .},
	urldate = {2022-04-14},
	journal = {arXiv:2107.05604 [cs, eess]},
	author = {Lee, Ann and Chen, Peng-Jen and Wang, Changhan and Gu, Jiatao and Popuri, Sravya and Ma, Xutai and Polyak, Adam and Adi, Yossi and He, Qing and Tang, Yun and Pino, Juan and Hsu, Wei-Ning},
	month = mar,
	year = {2022},
	note = {arXiv: 2107.05604},
}

@article{hsu_hubert_2021,
	title = {{HuBERT}: {Self}-{Supervised} {Speech} {Representation} {Learning} by {Masked} {Prediction} of {Hidden} {Units}},
	volume = {29},
	issn = {2329-9304},
	shorttitle = {{HuBERT}},
	doi = {10.1109/TASLP.2021.3122291},
	abstract = {Self-supervised approaches for speech representation learning are challenged by three unique problems: (1) there are multiple sound units in each input utterance, (2) there is no lexicon of input sound units during the pre-training phase, and (3) sound units have variable lengths with no explicit segmentation. To deal with these three problems, we propose the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. A key ingredient of our approach is applying the prediction loss over the masked regions only, which forces the model to learn a combined acoustic and language model over the continuous inputs. HuBERT relies primarily on the consistency of the unsupervised clustering step rather than the intrinsic quality of the assigned cluster labels. Starting with a simple k-means teacher of 100 clusters, and using two iterations of clustering, the HuBERT model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech (960 h) and Libri-light (60,000 h) benchmarks with 10 min, 1 h, 10 h, 100 h, and 960 h fine-tuning subsets. Using a 1B parameter model, HuBERT shows up to 19\% and 13\% relative WER reduction on the more challenging dev-other and test-other evaluation subsets.12},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
	year = {2021},
	note = {Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	pages = {3451--3460},
}

@book{campbell_indigenous_2012,
	address = {Berlin ; Boston},
	series = {The world of linguistics},
	title = {The indigenous languages of {South} {America}: a comprehensive guide},
	isbn = {978-3-11-025513-3 978-3-11-025803-5},
	shorttitle = {The indigenous languages of {South} {America}},
	language = {en},
	number = {2},
	publisher = {Mouton de Gruyter},
	editor = {Campbell, Lyle and Grondona, Verónica María},
	year = {2012},
	keywords = {Endangered languages, Indians of South America, Language and culture, Languages},
}

@article{huma_anatomy_2020,
	title = {The {Anatomy} of {First}-{Time} and {Subsequent} {Business}-to-{Business} “{Cold}” {Calls}},
	volume = {53},
	issn = {0835-1813},
	url = {https://doi.org/10.1080/08351813.2020.1739432},
	doi = {10.1080/08351813.2020.1739432},
	abstract = {This article examines business-to-business “cold” calls between salespeople and prospective clients. Drawing on 150 audio-recorded interactions, we use conversation analysis to identify the overarching structural organization and constituent activities in first-time and subsequent “cold” calls, a distinction that emerged from participants’ orientation to their relationship history or lack thereof. The article reveals how structural features of telephone conversations, such as identification sequences and “reason for calling,” are adapted to achieve local interactional results and that these conversational microstructures are consequential for the outcome of the telephone call and, ultimately, a company’s bottom line. Data are British English.},
	number = {2},
	urldate = {2022-04-11},
	journal = {Research on Language and Social Interaction},
	author = {Humă, Bogdana and Stokoe, Elizabeth},
	month = apr,
	year = {2020},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2020.1739432},
	pages = {271--294},
}

@article{huma_persuasive_2019,
	title = {Persuasive {Conduct}: {Alignment} and {Resistance} in {Prospecting} “{Cold}” {Calls}},
	volume = {38},
	issn = {0261-927X},
	shorttitle = {Persuasive {Conduct}},
	url = {https://doi.org/10.1177/0261927X18783474},
	doi = {10.1177/0261927X18783474},
	abstract = {Social psychology has theorized the cognitive processes underlying persuasion, without considering its interactional infrastructure—the discursive actions through which persuasion is accomplished interactionally. Our article aims to fill this gap, by using discursive psychology and conversation analysis to examine 153 “cold” calls, in which salespeople seek to secure meetings with prospective clients. We identify two sets of communicative practices that comprise persuasive conduct: (1) pre-expanding the meeting request with accounts that secure the prospect’s alignment to this course of action without disclosing its end result and (2) minimizing the imposition of the meeting to reduce the prospect’s opportunities for refusal. We conclude that persuasive conduct consists in managing the recipiency of the meeting requests by promoting alignment and hampering resistance. Overall, this article contributes to the wider discursive psychological project of “respecifying” psychological phenomena such as attitudes, memory, and emotion from the realm of social cognition to the realm of social interaction.},
	language = {en},
	number = {1},
	urldate = {2022-04-11},
	journal = {Journal of Language and Social Psychology},
	author = {Humă, Bogdana and Stokoe, Elizabeth and Sikveland, Rein Ove},
	month = jan,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	pages = {33--60},
}

@article{stokoe_when_2020,
	title = {When delayed responses are productive: {Being} persuaded following resistance in conversation},
	volume = {155},
	issn = {0378-2166},
	shorttitle = {When delayed responses are productive},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216619306290},
	doi = {10.1016/j.pragma.2019.10.001},
	abstract = {Conversation analysts have long since demonstrated that, in responding to an initiating action (e.g., question), recipients have at least two ways to respond; response options (e.g., answer, non-answer) are not equivalent, and ‘preferred’ responses are typically delivered more rapidly than ‘dispreferred’ responses. This paper examines cases in which ‘preferred’ responses, which progress the preceding actions in productive alignment, are delayed. We combined and analysed four British and American English datasets: mediators talking to potential clients; police negotiators talking to suicidal persons in crisis; calls to emergency services from suicidal persons, and salespeople talking to potential customers. Our analysis revealed that, when one party has resisted the project of the other, delay may indicate an upcoming productive response. Such delays break the sequence's contiguity, thus producing (some) structural independence from a previously dismissed course of action and enabling the speaker to maintain (some) ‘face’, in Goffman's terms. We discuss the implications of these findings for understanding alignment and preference in conversation analysis, and the practices of resistance and persuasion more generally.},
	language = {en},
	urldate = {2022-04-11},
	journal = {Journal of Pragmatics},
	author = {Stokoe, Elizabeth and Humă, Bogdana and Sikveland, Rein O. and Kevoe-Feldman, Heidi},
	month = jan,
	year = {2020},
	pages = {70--82},
}

@article{huma_vocabularies_2021,
	title = {Vocabularies of social influence: {Managing} the moral accountability of influencing another},
	volume = {60},
	issn = {2044-8309},
	shorttitle = {Vocabularies of social influence},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/bjso.12409},
	doi = {10.1111/bjso.12409},
	abstract = {While there are many definitions and conceptual accounts of ‘persuasion’ and other forms of social influence, social scientists lack empirical insight into how and when people actually use terms like ‘persuade’, ‘convince’, ‘change somebody's mind’ – what we call the vocabularies of social influence – in actual social interaction. We collected instances of the spontaneous use of these and other social influence terms (such as ‘schmoozing’ and ‘hoodwinking’) in face-to-face and telephone conversations across multiple domestic and institutional settings. The recorded data were transcribed and analysed using discursive psychology and conversation analysis with a focus on the actions accomplished in and through the use of social influence terms. We found that when speakers use 'persuading' – but not 'convincing' or 'changing somebody’s mind' – it is in the service of orienting to the moral accountability of influencing others. The specificity with which social actors deploy these terms demonstrates the continued importance of developing our understandings of the meaning of words – especially psychological ones – via their vernacular use by ordinary people in the first instance, rather than have psychologists reify, operationalize, and build an architecture for social psychology without paying attention to what people actually do with the ‘psychological thesaurus’.},
	language = {en},
	number = {2},
	urldate = {2022-04-11},
	journal = {British Journal of Social Psychology},
	author = {Huma, Bogdana and Stokoe, Elizabeth and Sikveland, Rein Ove},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/bjso.12409},
	pages = {319--339},
}

@inproceedings{mcilroy-young_aligning_2020,
	title = {Aligning {Superhuman} {AI} with {Human} {Behavior}: {Chess} as a {Model} {System}},
	shorttitle = {Aligning {Superhuman} {AI} with {Human} {Behavior}},
	url = {https://www.microsoft.com/en-us/research/publication/aligning-superhuman-ai-with-human-behavior-chess-as-a-model-system/},
	abstract = {As artificial intelligence becomes increasingly intelligent—in some cases, achieving superhuman performance—there is growing potential for humans to learn from and collaborate with algorithms. However, the ways in which AI systems approach problems are often different from the ways people do, and thus may be uninterpretable and hard to learn from. A crucial step in bridging […]},
	language = {en-US},
	urldate = {2022-04-11},
	author = {McIlroy-Young, Reid and Sen, Siddhartha and Kleinberg, Jon and Anderson, Ashton},
	month = jul,
	year = {2020},
}

@inproceedings{su_hifi-gan_2020,
	title = {{HiFi}-{GAN}: {High}-{Fidelity} {Denoising} and {Dereverberation} {Based} on {Speech} {Deep} {Features} in {Adversarial} {Networks}},
	shorttitle = {{HiFi}-{GAN}},
	doi = {10.21437/interspeech.2020-2143},
	abstract = {This paper introduces HiFi-GAN, a deep learning method to transform recorded speech to sound as though it had been recorded in a studio, trained with multi-scale adversarial discriminators in both the time domain and the time-frequency domain. Real-world audio recordings are often degraded by factors such as noise, reverberation, and equalization distortion. This paper introduces HiFi-GAN, a deep learning method to transform recorded speech to sound as though it had been recorded in a studio. We use an end-to-end feed-forward WaveNet architecture, trained with multi-scale adversarial discriminators in both the time domain and the time-frequency domain. It relies on the deep feature matching losses of the discriminators to improve the perceptual quality of enhanced speech. The proposed model generalizes well to new speakers, new speech content, and new environments. It significantly outperforms state-of-the-art baseline methods in both objective and subjective experiments.},
	booktitle = {{INTERSPEECH}},
	author = {Su, Jiaqi and Jin, Zeyu and Finkelstein, A.},
	year = {2020},
}

@article{kharitonov_textless-lib_2022,
	title = {textless-lib: a {Library} for {Textless} {Spoken} {Language} {Processing}},
	shorttitle = {textless-lib},
	url = {http://arxiv.org/abs/2202.07359},
	abstract = {Textless spoken language processing research aims to extend the applicability of standard NLP toolset onto spoken language and languages with few or no textual resources. In this paper, we introduce textless-lib, a PyTorch-based library aimed to facilitate research in this research area. We describe the building blocks that the library provides and demonstrate its usability by discuss three different use-case examples: (i) speaker probing, (ii) speech resynthesis and compression, and (iii) speech continuation. We believe that textless-lib substantially simplifies research the textless setting and will be handful not only for speech researchers but also for the NLP community at large. The code, documentation, and pre-trained models are available at https://github.com/facebookresearch/textlesslib/ .},
	urldate = {2022-04-11},
	journal = {arXiv:2202.07359 [cs, eess]},
	author = {Kharitonov, Eugene and Copet, Jade and Lakhotia, Kushal and Nguyen, Tu Anh and Tomasello, Paden and Lee, Ann and Elkahky, Ali and Hsu, Wei-Ning and Mohamed, Abdelrahman and Dupoux, Emmanuel and Adi, Yossi},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.07359},
}

@article{nguyen_generative_2022,
	title = {Generative {Spoken} {Dialogue} {Language} {Modeling}},
	url = {http://arxiv.org/abs/2203.16502},
	doi = {10.48550/arXiv.2203.16502},
	abstract = {We introduce dGSLM, the first "textless" model able to generate audio samples of naturalistic spoken dialogues. It uses recent work on unsupervised spoken unit discovery coupled with a dual-tower transformer architecture with cross-attention trained on 2000 hours of two-channel raw conversational audio (Fisher dataset) without any text or labels. It is able to generate speech, laughter and other paralinguistic signals in the two channels simultaneously and reproduces naturalistic turn taking. Generation samples can be found at: https://speechbot.github.io/dgslm.},
	urldate = {2022-04-11},
	journal = {arXiv:2203.16502 [cs, eess]},
	author = {Nguyen, Tu Anh and Kharitonov, Eugene and Copet, Jade and Adi, Yossi and Hsu, Wei-Ning and Elkahky, Ali and Tomasello, Paden and Algayres, Robin and Sagot, Benoit and Mohamed, Abdelrahman and Dupoux, Emmanuel},
	month = mar,
	year = {2022},
	note = {arXiv: 2203.16502},
}

@article{bartelds_neural_2022,
	title = {Neural representations for modeling variation in speech},
	volume = {92},
	issn = {0095-4470},
	url = {https://www.sciencedirect.com/science/article/pii/S0095447022000122},
	doi = {10.1016/j.wocn.2022.101137},
	abstract = {Variation in speech is often quantified by comparing phonetic transcriptions of the same utterance. However, manually transcribing speech is time-consuming and error prone. As an alternative, therefore, we investigate the extraction of acoustic embeddings from several self-supervised neural models. We use these representations to compute word-based pronunciation differences between non-native and native speakers of English, and between Norwegian dialect speakers. For comparison with several earlier studies, we evaluate how well these differences match human perception by comparing them with available human judgements of similarity. We show that speech representations extracted from a specific type of neural model (i.e. Transformers) lead to a better match with human perception than two earlier approaches on the basis of phonetic transcriptions and MFCC-based acoustic features. We furthermore find that features from the neural models can generally best be extracted from one of the middle hidden layers than from the final layer. We also demonstrate that neural speech representations not only capture segmental differences, but also intonational and durational differences that cannot adequately be represented by a set of discrete symbols used in phonetic transcriptions.},
	language = {en},
	urldate = {2022-04-08},
	journal = {Journal of Phonetics},
	author = {Bartelds, Martijn and de Vries, Wietse and Sanal, Faraz and Richter, Caitlin and Liberman, Mark and Wieling, Martijn},
	month = may,
	year = {2022},
	pages = {101137},
}

@article{valente_comparative_2022,
	title = {Comparative {Analysis} of the {Vocal} {Repertoires} of the {Indri} ({Indri} indri) and the {Diademed} {Sifaka} ({Propithecus} diadema)},
	issn = {1573-8604},
	url = {https://doi.org/10.1007/s10764-022-00287-x},
	doi = {10.1007/s10764-022-00287-x},
	abstract = {Strepsirrhine vocalisations are extraordinarily diverse and cross-species comparisons are needed to explore how this variability evolved. We contributed to the investigation of primate acoustic diversity by comparing the vocal repertoire of two sympatric lemur species, Propithecus diadema and Indri indri. These diurnal species belong to the same taxonomic family and have similar activity patterns but different social structures. These features make them excellent candidates for an investigation of the phylogenetic, environmental, and social influence on primate vocal behavior. We recorded 3 P. diadema groups in 2014 and 2016. From 1,872 recordings we selected and assigned 3814 calls to 9 a priori call types, on the basis of their acoustic structure. We implemented a reproducible technique performing an acoustic feature extraction relying on frequency bins, t-SNE data reduction, and a hard-clustering analysis. We first quantified the vocal repertoire of P. diadema, finding consistent results for the 9 putatively identified call types. When comparing this repertoire with a previously published repertoire of I. indri, we found highly species-specific repertoires, with only 2\% of the calls misclassified by species identity. The loud calls of the two species were very distinct, while the low-frequency calls were more similar. Our results pinpoint the role of phylogenetic history, social and environmental features on the evolution of communicative systems and contribute to a deeper understanding of the evolutionary roots of primate vocal differentiation. We conclude by arguing that standardized and reproducible techniques, like the one we employed, allow robust comparisons and should be prioritized in the future.},
	language = {en},
	urldate = {2022-04-05},
	journal = {International Journal of Primatology},
	author = {Valente, Daria and Miaretsoa, Longondraza and Anania, Alessio and Costa, Francesco and Mascaro, Alessandra and Raimondi, Teresa and De Gregorio, Chiara and Torti, Valeria and Friard, Olivier and Ratsimbazafy, Jonah and Giacoma, Cristina and Gamba, Marco},
	month = apr,
	year = {2022},
}

@article{ravanelli_speechbrain_2021,
	title = {{SpeechBrain}: {A} {General}-{Purpose} {Speech} {Toolkit}},
	shorttitle = {{SpeechBrain}},
	url = {http://arxiv.org/abs/2106.04624},
	abstract = {SpeechBrain is an open-source and all-in-one speech toolkit. It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented. This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines. SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.},
	urldate = {2022-03-31},
	journal = {arXiv:2106.04624 [cs, eess]},
	author = {Ravanelli, Mirco and Parcollet, Titouan and Plantinga, Peter and Rouhe, Aku and Cornell, Samuele and Lugosch, Loren and Subakan, Cem and Dawalatabad, Nauman and Heba, Abdelwahab and Zhong, Jianyuan and Chou, Ju-Chieh and Yeh, Sung-Lin and Fu, Szu-Wei and Liao, Chien-Feng and Rastorgueva, Elena and Grondin, François and Aris, William and Na, Hwidong and Gao, Yan and De Mori, Renato and Bengio, Yoshua},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.04624},
}

@inproceedings{cwiek_acoustics_2017,
	title = {Acoustics and discourse function of two types of breathing signals},
	booktitle = {Nordic {Prosody}, {Trondheim}, {Norway}, 10-12 {August}, 2016},
	publisher = {Peter Lang Publishing Group},
	author = {Ćwiek, Aleksandra and Włodarczak, Marcin and Heldner, Mattias and Wagner, Petra},
	year = {2017},
	pages = {83--91},
}

@article{cwiek_boubakiki_2021,
	title = {The bouba/kiki effect is robust across cultures and writing systems},
	copyright = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-89445-4},
	doi = {10.1038/s41598-021-89445-4},
	language = {en},
	urldate = {2021-05-12},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Ćwiek, Aleksandra and Fuchs, Susanne and Draxler, Christoph and Asu, Eva Liina and Dediu, Dan and Hiovain, Katri and Kawahara, Shigeto and Koutalidis, Sofia and Krifka, Manfred and Lippus, Pärtel and Lupyan, Gary and Oh, Grace E. and Paul, Jing and Petrone, Caterina and Ridouane, Rachid and Reiter, Sabine and Schümchen, Nathalie and Szalontai, Ádám and Ünal-Logacev, Özlem and Zeller, Jochen and Perlman, Marcus and Winter, Bodo},
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
}

@article{cwiek_novel_2021,
	title = {Novel vocalizations are understood across cultures},
	volume = {11},
	copyright = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-89445-4},
	doi = {10.1038/s41598-021-89445-4},
	abstract = {Linguistic communication requires speakers to mutually agree on the meanings of words, but how does such a system first get off the ground? One solution is to rely on iconic gestures: visual signs whose form directly resembles or otherwise cues their meaning without any previously established correspondence. However, it is debated whether vocalizations could have played a similar role. We report the first extensive cross-cultural study investigating whether people from diverse linguistic backgrounds can understand novel vocalizations for a range of meanings. In two comprehension experiments, we tested whether vocalizations produced by English speakers could be understood by listeners from 28 languages from 12 language families. Listeners from each language were more accurate than chance at guessing the intended referent of the vocalizations for each of the meanings tested. Our findings challenge the often-cited idea that vocalizations have limited potential for iconic representation, demonstrating that in the absence of words people can use vocalizations to communicate a variety of meanings.},
	language = {en},
	number = {1},
	urldate = {2021-05-12},
	journal = {Scientific Reports},
	author = {Ćwiek, Aleksandra and Fuchs, Susanne and Draxler, Christoph and Asu, Eva Liina and Dediu, Dan and Hiovain, Katri and Kawahara, Shigeto and Koutalidis, Sofia and Krifka, Manfred and Lippus, Pärtel and Lupyan, Gary and Oh, Grace E. and Paul, Jing and Petrone, Caterina and Ridouane, Rachid and Reiter, Sabine and Schümchen, Nathalie and Szalontai, Ádám and Ünal-Logacev, Özlem and Zeller, Jochen and Winter, Bodo and Perlman, Marcus},
	month = may,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {10108},
}

@article{potthast_dilemma_2020,
	title = {The dilemma of the direct answer},
	volume = {54},
	issn = {0163-5840},
	url = {https://dl.acm.org/doi/10.1145/3451964.3451978},
	doi = {10.1145/3451964.3451978},
	abstract = {No Web technology has undergone such an impressive evolution as Web search engines did and still do. Starting with the promise of “Bringing order to the Web”1 by compiling information sources matching a query, retrieval technology has been evolving to a kind of “oracle machinery”, being able to recommend a single source, and even to provide direct answers extracted from that source. Notwithstanding the remarkable progress made and the apparent user preferences for direct answers, this paradigm shift comes at a price which is higher than one might expect at ﬁrst sight, aﬀecting both users and search engine developers in their own way. We call this tradeoﬀ “the dilemma of the direct answer”; it deserves an analysis which has to go beyond system-oriented aspects but scrutinize the way our society deals with both their information needs and means to information access. The paper in hand contributes to this analysis by putting the evolution of retrieval technology and the expectations at it in the context of information retrieval history. Moreover, we discuss the trade oﬀs in information behavior and information system design that users and developers may face in the future.},
	language = {en},
	number = {1},
	urldate = {2022-03-29},
	journal = {ACM SIGIR Forum},
	author = {Potthast, Martin and Hagen, Matthias and Stein, Benno},
	month = jun,
	year = {2020},
	pages = {1--12},
}

@article{san2021leveraging,
	title = {Leveraging pre-trained representations to improve access to untranscribed speech from endangered languages},
	journal = {arXiv preprint arXiv:2103.14583},
	author = {San, Nay and Bartelds, Martijn and Browne, Mitchell and Clifford, Lily and Gibson, Fiona and Mansfield, John and Nash, David and Simpson, Jane and Turpin, Myfany and Vollmer, Maria and {others}},
	year = {2021},
}

@article{lelu_jean-baptiste_2014,
	title = {Jean-{Baptiste} {Estoup} and the origins of {Zipf} ’s law: a stenographer with a scientiﬁc mind (1868-1950)},
	volume = {30},
	url = {http://www.seio.es/BEIO/files/BEIOVol30Num1Feb2014-HyE.pdf},
	abstract = {Statistical distributions with a power law have been observed for over a century in many domains of social sciences, as well as in natural and life sciences. They are of utmost importance for those building models applicable to human activities (e.g. the ”long tail” phenomena). We present here the life and accomplishments of J-B. Estoup, who was the ﬁrst to notice this type of distribution in the language domain, and inspired the subsequent formulations by G.K. Zipf and B. Mandelbrot. This study, ﬁrst presented at the seminar on the history of probabilities and statistics held at Ecole des Hautes Etudes en Sciences Sociales on December the 7th, 2007 in Paris, is also a family testimony, the author being the grandson of J-B. Estoup.},
	language = {es},
	number = {1},
	journal = {Boletín de Estadística e Investigación Operative},
	author = {Lelu, Alain},
	year = {2014},
	pages = {66--77},
}

@article{becht_dimensionality_2019,
	title = {Dimensionality reduction for visualizing single-cell data using {UMAP}},
	volume = {37},
	copyright = {2018 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/nbt.4314},
	doi = {10.1038/nbt.4314},
	abstract = {A benchmarking analysis on single-cell RNA-seq and mass cytometry data reveals the best-performing technique for dimensionality reduction.},
	language = {en},
	number = {1},
	urldate = {2022-03-28},
	journal = {Nature Biotechnology},
	author = {Becht, Etienne and McInnes, Leland and Healy, John and Dutertre, Charles-Antoine and Kwok, Immanuel W. H. and Ng, Lai Guan and Ginhoux, Florent and Newell, Evan W.},
	month = jan,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {38--44},
}

@article{mcinnes_umap_2020,
	title = {{UMAP}: {Uniform} {Manifold} {Approximation} and {Projection} for {Dimension} {Reduction}},
	shorttitle = {{UMAP}},
	url = {http://arxiv.org/abs/1802.03426},
	abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
	urldate = {2022-03-28},
	journal = {arXiv:1802.03426 [cs, stat]},
	author = {McInnes, Leland and Healy, John and Melville, James},
	month = sep,
	year = {2020},
	note = {arXiv: 1802.03426},
}

@article{drummond_uses_1993,
	title = {Some {Uses} of {Yeah}},
	volume = {26},
	issn = {0835-1813, 1532-7973},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi2602_6},
	doi = {10.1207/s15327973rlsi2602_6},
	language = {en},
	number = {2},
	urldate = {2022-03-19},
	journal = {Research on Language \& Social Interaction},
	author = {Drummond, Kent and Hopper, Robert},
	month = apr,
	year = {1993},
	pages = {203--212},
}

@incollection{drummond_misunderstanding_1991,
	address = {Newbury Park, CA},
	title = {Misunderstanding and its remedies: {Telephone} miscommunication},
	shorttitle = {Misunderstanding and its remedies},
	booktitle = {'{Miscommunication}' and {Problematic} {Talk}},
	publisher = {Sage},
	author = {Drummond, Kent and Hopper, Robert},
	editor = {Coupland, Nikolas and Giles, H. and Wieman, M.},
	year = {1991},
	pages = {301--14},
}

@article{santoni_de_sio_four_2021,
	title = {Four {Responsibility} {Gaps} with {Artificial} {Intelligence}: {Why} they {Matter} and {How} to {Address} them},
	volume = {34},
	issn = {2210-5441},
	shorttitle = {Four {Responsibility} {Gaps} with {Artificial} {Intelligence}},
	url = {https://doi.org/10.1007/s13347-021-00450-x},
	doi = {10.1007/s13347-021-00450-x},
	abstract = {The notion of “responsibility gap” with artificial intelligence (AI) was originally introduced in the philosophical debate to indicate the concern that “learning automata” may make more difficult or impossible to attribute moral culpability to persons for untoward events. Building on literature in moral and legal philosophy, and ethics of technology, the paper proposes a broader and more comprehensive analysis of the responsibility gap. The responsibility gap, it is argued, is not one problem but a set of at least four interconnected problems – gaps in culpability, moral and public accountability, active responsibility—caused by different sources, some technical, other organisational, legal, ethical, and societal. Responsibility gaps may also happen with non-learning systems. The paper clarifies which aspect of AI may cause which gap in which form of responsibility, and why each of these gaps matter. It proposes a critical review of partial and non-satisfactory attempts to address the responsibility gap: those which present it as a new and intractable problem (“fatalism”), those which dismiss it as a false problem (“deflationism”), and those which reduce it to only one of its dimensions or sources and/or present it as a problem that can be solved by simply introducing new technical and/or legal tools (“solutionism”). The paper also outlines a more comprehensive approach to address the responsibility gaps with AI in their entirety, based on the idea of designing socio-technical systems for “meaningful human control", that is systems aligned with the relevant human reasons and capacities.},
	language = {en},
	number = {4},
	urldate = {2022-03-25},
	journal = {Philosophy \& Technology},
	author = {Santoni de Sio, Filippo and Mecacci, Giulio},
	month = dec,
	year = {2021},
	pages = {1057--1084},
}

@article{passonneau_discourse_2016,
	title = {Discourse {Segment} {Annotation} and {Analysis}: {A} {Tagalog} {Telephone} {Corpus}},
	shorttitle = {Discourse {Segment} {Annotation} and {Analysis}},
	url = {https://doi.org/10.7916/D87S7NVV},
	doi = {10.7916/D87S7NVV},
	abstract = {This dataset presents an annotation task to identify discourse segments in telephone conversations between native speakers of Tagalog. Each discourse segment represents a conversational activity identified by the annotators. The conversations were presented to annotators as audio recordings accompanied by transcripts. Every utterance in the transcripts is labeled by five to nine annotators. Two probabilistic models to infer a single ground truth label from the multiple labels were compared. The dataset contains the conversational data and annotation task description, the annotation results, code to apply each of the probabilistic models to the annotations, the output of the code, and a paper that describes the dataset and modeling.},
	language = {en},
	urldate = {2022-03-24},
	author = {Passonneau, Rebecca and Huang, Ziheng and Zhong, Jialu and Lim-Kimberg, Samuel J.},
	year = {2016},
}

@article{nook_linguistic_2022,
	title = {Linguistic measures of psychological distance track symptom levels and treatment outcomes in a large set of psychotherapy transcripts},
	volume = {119},
	url = {https://www.pnas.org/doi/10.1073/pnas.2114737119},
	doi = {10.1073/pnas.2114737119},
	number = {13},
	urldate = {2022-03-22},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Nook, Erik C. and Hull, Thomas D. and Nock, Matthew K. and Somerville, Leah H.},
	month = mar,
	year = {2022},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2114737119},
}

@article{hutchins_enculturating_2011,
	title = {Enculturating the {Supersized} {Mind}},
	volume = {152},
	issn = {0031-8116},
	url = {https://www.jstor.org/stable/41487606},
	number = {3},
	urldate = {2022-03-22},
	journal = {Philosophical Studies: An International Journal for Philosophy in the Analytic Tradition},
	author = {Hutchins, Edwin},
	editor = {CLARK, ANDY},
	year = {2011},
	note = {Publisher: Springer},
	pages = {437--446},
}

@article{abdill_tracking_2019,
	title = {Tracking the popularity and outcomes of all {bioRxiv} preprints},
	volume = {8},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.45133},
	doi = {10.7554/eLife.45133},
	abstract = {The growth of preprints in the life sciences has been reported widely and is driving policy changes for journals and funders, but little quantitative information has been published about preprint usage. Here, we report how we collected and analyzed data on all 37,648 preprints uploaded to bioRxiv.org, the largest biology-focused preprint server, in its first five years. The rate of preprint uploads to bioRxiv continues to grow (exceeding 2,100 in October 2018), as does the number of downloads (1.1 million in October 2018). We also find that two-thirds of preprints posted before 2017 were later published in peer-reviewed journals, and find a relationship between the number of downloads a preprint has received and the impact factor of the journal in which it is published. We also describe Rxivist.org, a web application that provides multiple ways to interact with preprint metadata.},
	urldate = {2022-03-21},
	journal = {eLife},
	author = {Abdill, Richard J and Blekhman, Ran},
	editor = {Pewsey, Emma and Rodgers, Peter and Greene, Casey S},
	month = apr,
	year = {2019},
	note = {Publisher: eLife Sciences Publications, Ltd},
	pages = {e45133},
}

@article{beach_conversational_1992,
	title = {Conversational universals and comparative theory: {Turning} to {Swedish} and {American} acknowledgment tokens in interaction},
	volume = {2},
	shorttitle = {Conversational universals and comparative theory},
	doi = {10.1111/j.1468-2885.1992.tb00027.x},
	abstract = {Issues of comparative theory are addressed through direct examination of acknowledgment tokens (e.g.. Eh, Mm, Mmlmm, Uh heh?) in American and Swedish conversations. Findings yield grounds for claiming universality across cultural members’ placement and usage of acknowledgment tokens. This is especial1;y evident in the ways interactants organize stories and topics by (a) working to preserve rights and privileges of tellers, and (b) moving toward more active speakership. A substairtiwe (i.e., reinspectable) basis for rendering comparative judgments about cross-cultural si.wilarities and differences is thus offered. Attention is then given to the impact of research methods on understanding communication and culture. Contrasts are made with anecdotal and self-report findings depicting Swedes as conversationally inept, lacking the necessary .ikills in such activities as “offering feedback.” Explanations offindings indicating conversational universals and particulars are offered, and implications for comparative theory development are elaborated.},
	number = {1},
	journal = {Communication Theory},
	author = {Beach, Wayne A. and Lindstrom, Anna K.},
	year = {1992},
	pages = {24--49},
}

@article{zimmerman_horizontal_1999,
	title = {Horizontal and {Vertical} {Comparative} {Research} in {Language} and {Social} {Interaction}},
	volume = {32},
	issn = {0835-1813},
	url = {http://www.tandfonline.com/doi/abs/10.1080/08351813.1999.9683623},
	doi = {10.1080/08351813.1999.9683623},
	number = {1-2},
	journal = {Research on Language \& Social Interaction},
	author = {Zimmerman, Don H.},
	year = {1999},
	pages = {195--203},
}

@article{sikveland_negotiating_2012,
	title = {Negotiating towards a {Next} {Turn}: {Phonetic} {Resources} for ‘{Doing} the {Same}’},
	volume = {55},
	issn = {0023-8309},
	shorttitle = {Negotiating towards a {Next} {Turn}},
	url = {https://doi.org/10.1177/0023830911428859},
	doi = {10.1177/0023830911428859},
	abstract = {This paper investigates hearers’ use of response tokens (back-channels), in maintaining and differentiating their actions. Initial observations suggest that hearers produce a sequence of phonetically similar responses to disengage from the current topic, and dissimilar responses to engage with the current topic. This is studied systematically by combining detailed interactional and phonetic analysis in a collection of naturally-occurring talk in Norwegian. The interactional analysis forms the basis for labeling actions as maintained (‘doing the same’) and differentiated (‘NOT doing the same’), which is then used as a basis for phonetic analysis. The phonetic analysis shows that certain phonetic characteristics, including pitch, loudness, voice quality and articulatory characteristics, are associated with ‘doing the same’, as different from ‘NOT doing the same’. Interactional analysis gives further evidence of how this differentiation is of systematic relevance in the negotiations of a next turn. This paper addresses phonetic variation and variability by focusing on the relationship between sequence and phonetics in the turn-by-turn development of meaning. This has important implications for linguistic/phonetic research, and for the study of back-channels.},
	language = {en},
	number = {1},
	urldate = {2022-03-19},
	journal = {Language and Speech},
	author = {Sikveland, Rein Ove},
	month = mar,
	year = {2012},
	note = {Publisher: SAGE Publications Ltd},
	pages = {77--98},
}

@article{fujimoto_listener_2007,
	title = {Listener responses in interaction: {A} case for abandoning the term, backchannel},
	volume = {9},
	shorttitle = {Listener responses in interaction},
	number = {28},
	journal = {Bulletin paper of Osaka Jogakuin College},
	author = {Fujimoto, Donna T.},
	year = {2007},
	pages = {35--54},
}

@article{xudong_use_2008,
	title = {The use of listener responses in {Mandarin} {Chinese} and {Australian} {English} conversations},
	volume = {18},
	issn = {1018-2101, 2406-4238},
	url = {https://www.jbe-platform.com/content/journals/10.1075/prag.18.2.06xud},
	doi = {10.1075/prag.18.2.06xud},
	abstract = {In recent cross-cultural studies of pragmatics, we have witnessed a rise in interest in the comparative study of phenomena beyond the level of single and decontextualised utterances encompassing those on the level of speech events such as casual conversations. The underlying premise for such studies is that different cultural groups may have different rules for participation in and interpretation of conversation X that conflicts related to these rules are a major source of cross-cultural miscommunication. This study examines the use of listener responses by Chinese speakers in Chinese Mandarin conversations and by Australians in Australian English conversations. Following X prior framework by Clancy et al. (1996), the study examines similarities and differences in the use of listener responses by these two groups of people in terms of frequency of use, types of listener responses, and the positions of listener responses with respect to transition relevance place. Results show that Australian and Chinese speakers do exhibit quite different conversational styles as evidenced in their use of listener responses. Specifically, while Australians use more listener responses, use a higher percentage of lexical expressions as their listener responses and tend to place their listener responses at a possible completion point, Chinese speakers use fewer listener responses, favour the use of paralinguistic vocalic forms as their listener responses and tend to place their listener responses during a turn. These findings may suggest a culture specific way of turn taking and of what it means to be polite in conversational behaviour.},
	language = {en},
	number = {2},
	urldate = {2022-03-19},
	journal = {Pragmatics},
	author = {Xudong, Deng},
	month = jan,
	year = {2008},
	note = {Publisher: John Benjamins},
	pages = {303--328},
}

@article{norrick_listening_2012,
	series = {Towards an {Emancipatory} {Pragmatics} {Part} {Two}},
	title = {Listening practices in {English} conversation: {The} responses responses elicit},
	volume = {44},
	issn = {0378-2166},
	shorttitle = {Listening practices in {English} conversation},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216611002256},
	doi = {10.1016/j.pragma.2011.08.007},
	abstract = {This article describes listening practices in English conversation from an Emancipatory Pragmatics perspective, focusing on the role of the listener as a modality of action and seeking to evaluate linguistic behaviors like responses in terms of cultural assumptions about politeness, turn-taking, silence, and overlapping talk. In producing minimal response tokens, a listener signals a willingness to remain (predominantly) silent, to refrain from interrupting and to attend to the primary speaker, and thereby encourages the speaker to continue with a multi-unit turn. But even single word responses can have a significant effect on the trajectory of an extended turn by another speaker. Response tokens differ widely in their degree of obtrusiveness, such that some listener responses like uh-huh attract little or no attention to themselves and essentially never evoke a specific response of their own, while assessments like wow, on through signals of processing difficulty like oh, and challenges like so increasingly attract the attention of the primary speaker and elicit a response in their own right. This ranking in terms of obtrusiveness or insistency differs from other sub-classifications or scales so far described in the literature on listener responses.},
	language = {en},
	number = {5},
	urldate = {2022-03-19},
	journal = {Journal of Pragmatics},
	author = {Norrick, Neal R.},
	month = apr,
	year = {2012},
	pages = {566--576},
}

@article{golato_comparing_2008,
	title = {Comparing {Single} and {Double} {Sayings} of the {German} {Response} {Token} ja and the {Role} of {Prosody}: {A} {Conversation} {Analytic} {Perspective}},
	volume = {41},
	shorttitle = {Comparing {Single} and {Double} {Sayings} of the {German} {Response} {Token} ja and the {Role} of {Prosody}},
	doi = {10.1080/08351810802237834},
	abstract = {In this article, we argue that although single ja (yes) is typically analyzed as an acknowledgment token, confirmation marker, or continuer, a doubled ja, either produced as {\textasciicircum}jaja. or ja{\textasciicircum}ja., cannot be considered a more intense version of the same action. Moreover, the two forms {\textasciicircum}jaja. and ja{\textasciicircum}ja. systematically accomplish separate interactional goals. Both forms are produced when the prior speaker utters something that is obvious and/or known by the jaja speaker. However, by uttering {\textasciicircum}jaja. (with pitch peak on the first syllable), the speaker merely indicates that the prior utterance contains already known information and that therefore the current action should be stopped. In contrast, with a ja{\textasciicircum}ja. (with pitch peak on the second syllable), its speaker treats the action/content of the previous speaker's utterance as either unwarranted or self-evident and takes issue with it. With a {\textasciicircum}jaja., its speaker indicates “I already got it, so stop,” whereas with a ja{\textasciicircum}ja., its speaker indicates “hold on, you didn't get it.” In this article, we corroborate the work of others who have argued against grouping response tokens into one single category. Moreover, in this article, we contribute to the growing body of work on grammar and interaction by demonstrating that the linguistic shape (prosody) of an utterance is intertwined with the interactional contingencies of a given situation.},
	number = {3},
	journal = {Research on Language \& Social Interaction},
	author = {Golato, Andrea and Fagyal, Zsuzsanna},
	year = {2008},
	pages = {241--270},
}

@phdthesis{pammi_synthesis_2011,
	title = {Synthesis of listener vocalizations : towards interactive speech synthesis},
	copyright = {Standardvertrag ohne Print on Demand},
	shorttitle = {Synthesis of listener vocalizations},
	url = {https://publikationen.sulb.uni-saarland.de/handle/20.500.11880/26333},
	abstract = {Spoken and multi-modal dialogue systems start to use listener vocalizations, such as uh-huh and mm-hm, for natural interaction. Generation of listener vocalizations is one of the major objectives of emotionally colored conversational speech synthesis. Success in this endeavor depends on the answers to three questions: Where to synthesize a listener vocalization? What meaning should be conveyed through the synthesized vocalization? And, how to realize an appropriate listener vocalization with the intended meaning?  This thesis addresses the latter question. The investigation starts with proposing a three-stage approach: (i) data collection, (ii) annotation, and (iii) realization. The first stage presents a method to collect natural listener vocalizations from German and British English professional actors in a recording studio. In the second stage, we explore a methodology for annotating listener vocalizations -- meaning and behavior (form) annotation. The third stage proposes a realization strategy that uses unit selection and signal modification techniques to generate appropriate listener vocalizations upon user requests. Finally, we evaluate naturalness and appropriateness of synthesized vocalizations using perception studies. The work is implemented in the open source MARY text-to-speech framework, and it is integrated into the SEMAINE project's Sensitive Artificial Listener (SAL) demonstrator.},
	language = {en},
	urldate = {2022-03-19},
	author = {Pammi, Sathish Chandra},
	year = {2011},
	note = {doi:10.22028/D291-26277},
}

@article{drummond_acknowledgment_1993,
	title = {Acknowledgment tokens in series},
	volume = {6},
	issn = {0893-4215},
	url = {https://doi.org/10.1080/08934219309367561},
	doi = {10.1080/08934219309367561},
	abstract = {This study examined the ordering of acknowledgment tokens (brief utterances such as ‘mm hm’ and ‘uh huh’) produced by recipients during extended telephone conversations. The question was asked: When tokens appear in a series, is there a recognizable pattern to their arrangement? Twenty‐five series of acknowledgment tokens were analyzed and tabulated, and a mean ordinal value was computed for each token. Results showed that ‘mm hm’ and ‘uh huh’ tended to appear somewhat earlier in a series, and ‘oh’, ‘okay’ and short assessments such as ‘lovely’ tended to appear very near the end of a series. The data suggested that recipients produced a variety of tokens, in an observable pattern, as they moved from listener to speaker roles.},
	number = {1},
	urldate = {2022-03-19},
	journal = {Communication Reports},
	author = {Drummond, Kent and Hopper, Robert},
	month = jan,
	year = {1993},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08934219309367561},
	pages = {47--53},
}

@article{zimmerman_acknowledgment_1993,
	title = {Acknowledgment {Tokens} and {Speakership} {Incipiency} {Revisited}},
	volume = {26},
	issn = {0835-1813, 1532-7973},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi2602_4},
	doi = {10.1207/s15327973rlsi2602_4},
	language = {en},
	number = {2},
	urldate = {2020-02-15},
	journal = {Research on Language \& Social Interaction},
	author = {Zimmerman, Don H.},
	month = apr,
	year = {1993},
	pages = {179--194},
}

@article{jefferson_caveat_1993,
	title = {Caveat {Speaker}: {Preliminary} {Notes} on {Recipient} {Topic}-{Shift} {Implicature}},
	volume = {26},
	issn = {0835-1813, 1532-7973},
	shorttitle = {Caveat {Speaker}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi2601_1},
	doi = {10.1207/s15327973rlsi2601_1},
	language = {en},
	number = {1},
	urldate = {2022-03-19},
	journal = {Research on Language \& Social Interaction},
	author = {Jefferson, Gail},
	month = jan,
	year = {1993},
	pages = {1--30},
}

@article{jefferson_note_1993,
	title = {A {Note} on the {Acknowledgment} {Tokens} {Mm} hm {Versus} {Uh} huh},
	volume = {26},
	issn = {0835-1813},
	shorttitle = {Editor's {Erratum} {Re}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi2603_6},
	doi = {10.1207/s15327973rlsi2603_6},
	number = {3},
	urldate = {2011-07-19},
	journal = {Research on Language \& Social Interaction},
	author = {Jefferson, Gail},
	month = jul,
	year = {1993},
	pages = {350--351},
}

@article{cutrone_case_2005,
	title = {A case study examining backchannels in conversations between {Japanese}–{British} dyads},
	volume = {24},
	issn = {1613-3684},
	doi = {10.1515/mult.2005.24.3.237},
	abstract = {Listener responses (called backchannels) and their effect on intercultural communication were investigated in eight dyadic conversations in English between Japanese and British participants. The findings of this study revealed several differences in the way each culture used backchannels: the Japanese participants used slightly more backchannels per interlocutor word, the British participants displayed greater variability in the types of backchannels they used, and there were several differences in the lexical items making up these backchannels. Japanese participants sent noticeably more backchannels in three discourse contexts: at or directly after a pause, directly after a primary speaker’s nonverbal gesture, and directly after a tag question or an utterance ending with the lexical items ‘ya know’. This study found evidence supporting the hypothesis that backchannel conventions, which are not shared between cultures, contribute to negative perceptions and stereotyping. The findings of this study support the conclusion that backchannels warrant more attention in EFL classes in Japan.},
	language = {en},
	number = {3},
	author = {Cutrone, Pino},
	month = sep,
	year = {2005},
	note = {Publisher: De Gruyter Mouton
Section: Multilingua},
	pages = {237--274},
}

@article{white_backchannels_1989,
	title = {Backchannels {Across} {Cultures}: {A} {Study} of {Americans} and {Japanese}},
	volume = {18},
	shorttitle = {Backchannels {Across} {Cultures}},
	doi = {10.1017/S0047404500013270},
	number = {01},
	urldate = {2011-07-05},
	journal = {Language in Society},
	author = {White, Sheida},
	year = {1989},
	pages = {59--76},
}

@article{harris_distributional_1954,
	title = {Distributional {Structure}},
	volume = {10},
	issn = {0043-7956},
	url = {https://doi.org/10.1080/00437956.1954.11659520},
	doi = {10.1080/00437956.1954.11659520},
	number = {2-3},
	urldate = {2022-03-17},
	journal = {WORD},
	author = {Harris, Zellig S.},
	month = aug,
	year = {1954},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/00437956.1954.11659520},
	pages = {146--162},
}

@inproceedings{rogers_changing_2021,
	address = {Online},
	title = {Changing the {World} by {Changing} the {Data}},
	url = {https://aclanthology.org/2021.acl-long.170},
	doi = {10.18653/v1/2021.acl-long.170},
	abstract = {NLP community is currently investing a lot more research and resources into development of deep learning models than training data. While we have made a lot of progress, it is now clear that our models learn all kinds of spurious patterns, social biases, and annotation artifacts. Algorithmic solutions have so far had limited success. An alternative that is being actively discussed is more careful design of datasets so as to deliver specific signals. This position paper maps out the arguments for and against data curation, and argues that fundamentally the point is moot: curation already is and will be happening, and it is changing the world. The question is only how much thought we want to invest into that process.},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Rogers, Anna},
	month = aug,
	year = {2021},
	pages = {2182--2194},
}

@article{grivicic_when_2004,
	title = {When {Phonation} {Matters}: {The} {Use} and {Function} of {Yeah} and {Creaky} {Voice}},
	volume = {17},
	shorttitle = {When {Phonation} {Matters}},
	number = {1},
	journal = {Colorado Research in Linguistics},
	author = {Grivicic, Tamara and Nilep, Chad},
	year = {2004},
	pages = {1--11},
}

@inproceedings{truong_disambiguating_2010,
	title = {Disambiguating the functions of conversational sounds with prosody: the case of ‘yeah’},
	shorttitle = {Disambiguating the functions of conversational sounds with prosody},
	booktitle = {Eleventh {Annual} {Conference} of the {International} {Speech} {Communication} {Association}},
	author = {Truong, Khiet P. and Heylen, Dirk},
	year = {2010},
}

@article{wong_token_2000,
	title = {The {Token} "{Yeah}" in {Nonnative} {Speaker} {English} {Conversation}},
	volume = {33},
	issn = {0835-1813},
	url = {https://doi.org/10.1207/S15327973RLSI3301_2},
	doi = {10.1207/S15327973RLSI3301_2},
	abstract = {This article is concerned with a previously unobserved lexical element-yeah-observed in the speech of nonnative speakers of English whose native language is Mandarin. Using the framework of conversation analysis, I discuss the same-turn repair environment in which the token yeah occurs but reveal that the token serves as an additional component, doing something other than repair. This form of turn-medial yeah is used to present an image of the speaker as one who is competently managing throughout disfluency (and repair). In serving this function, the yeah contributes to our understanding of how speakers construct their identities as nonnative speakers (or learners) of the language of interaction. Its usage in native speaker English conversation is extremely rare.},
	number = {1},
	urldate = {2022-03-17},
	journal = {Research on Language and Social Interaction},
	author = {Wong, Jean},
	month = jan,
	year = {2000},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1207/S15327973RLSI3301\_2},
	pages = {39--67},
}

@article{van_miltenburg_cross-linguistic_2017,
	title = {Cross-linguistic differences and similarities in image descriptions},
	url = {http://arxiv.org/abs/1707.01736},
	abstract = {Automatic image description systems are commonly trained and evaluated on large image description datasets. Recently, researchers have started to collect such datasets for languages other than English. An unexplored question is how different these datasets are from English and, if there are any differences, what causes them to differ. This paper provides a cross-linguistic comparison of Dutch, English, and German image descriptions. We find that these descriptions are similar in many respects, but the familiarity of crowd workers with the subjects of the images has a noticeable influence on description specificity.},
	urldate = {2022-03-17},
	journal = {arXiv:1707.01736 [cs]},
	author = {van Miltenburg, Emiel and Elliott, Desmond and Vossen, Piek},
	month = aug,
	year = {2017},
	note = {arXiv: 1707.01736},
}

@article{sidwell_journal_nodate,
	title = {Journal of the {Southeast} {Asian} {Linguistics} {Society}},
	language = {en},
	author = {Sidwell, Paul and Brunelle, Marc and Alves, Mark and Bedell, George and Diffloth, Gerard and Macken, Marlys and Migliazza, Brian and Nagaraja, Keralapura and Norquest, Peter and Prasithrathsint, Amara and Ratliff, Martha and Srichampa, Sophana and Watkins, Justin},
	pages = {111},
}

@phdthesis{cerrato_investigating_2007,
	address = {Stockholm},
	title = {Investigating communicative feedback phenomena across languages and modalities},
	language = {en},
	school = {Skolan för Datavetenskap och Kommunikation, Kungliga Tekniska Högskolan},
	author = {Cerrato, Loredana},
	year = {2007},
	note = {OCLC: 254253927},
}

@inproceedings{trouvain_acoustic_2012,
	address = {El Paso, TX},
	title = {Acoustic, {Morphological}, and {Functional} {Aspects} of “yeah/ja” in {Dutch}, {English} and {German}},
	booktitle = {Proceedings of the {Interdisciplinary} {Workshop} on {Feedback} {Behaviors} in {Dialog}},
	author = {Trouvain, Jürgen and Truong, Khiet P.},
	year = {2012},
}

@inproceedings{levow_employing_2012,
	title = {Employing boosting to compare cues to verbal feedback in multi-lingual dialog},
	doi = {10.1109/SLT.2012.6424199},
	abstract = {Verbal feedback provides important cues in establishing interactional rapport. The challenge of recognizing contexts for verbal feedback largely arises from relative sparseness and optionality. In addition, cross-language and inter-speaker variations can make recognition more difficult. In this paper, we show that boosting can improve accuracy in recognizing contexts for verbal feedback based on prosodic cues. In our experiments, we use dyads from three languages (English, Spanish and Arabic) to evaluate two boosting methods, generalized Adaboost and Gradient Boosting Trees, against Support Vector Machines (SVMs) and a naive baseline, with explicit oversampling on the minority verbal feedback instances. We find that both boosting methods outperform the baseline and SVM classifiers. Analysis of the feature weighting by the boosted classifiers highlights differences and similarities in the prosodic cues employed by members of these diverse language/cultural groups.},
	booktitle = {2012 {IEEE} {Spoken} {Language} {Technology} {Workshop} ({SLT})},
	author = {Levow, Gina-Anne and Wang, Siwei},
	month = dec,
	year = {2012},
	pages = {67--72},
}

@inproceedings{levow_cross-cultural_2010,
	title = {Cross-cultural investigation of prosody in verbal feedback in interactional rapport},
	booktitle = {Eleventh {Annual} {Conference} of the {International} {Speech} {Communication} {Association}},
	author = {Levow, Gina-Anne and Duncan, Susan and King, Edward T.},
	year = {2010},
}

@inproceedings{ward_directions_2012,
	address = {Montréal, Canada},
	title = {Directions for {Research} on {Spoken} {Dialog} {Systems}, {Broadly} {Defined}},
	url = {https://aclanthology.org/W12-1802},
	urldate = {2022-03-16},
	booktitle = {{NAACL}-{HLT} {Workshop} on {Future} directions and needs in the {Spoken} {Dialog} {Community}: {Tools} and {Data} ({SDCTD} 2012)},
	publisher = {Association for Computational Linguistics},
	author = {Ward, Nigel G.},
	month = jun,
	year = {2012},
	pages = {3--4},
}

@inproceedings{ha_speech_2016,
	title = {Speech prosody and possible misunderstandings in intercultural talk: {A} study of listener behaviour in {Standard} {Vietnamese} and {German} dialogues},
	shorttitle = {Speech prosody and possible misunderstandings in intercultural talk},
	url = {https://www.isca-speech.org/archive/speechprosody_2016/ha16_speechprosody.html},
	doi = {10.21437/SpeechProsody.2016-164},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Speech {Prosody} 2016},
	publisher = {ISCA},
	author = {Ha, Kieu-Phuong and Ebner, Samuel and Grice, Martine},
	month = may,
	year = {2016},
	pages = {801--805},
}

@article{najim_cultural_2020,
	title = {Cultural {Differences} in {Back}-channeling {Contents} between {English} and {Kurdish} {Languages}},
	volume = {24},
	copyright = {Copyright (c) 2020 Qani Nasih Najim, kawa qadir muhammad},
	issn = {2412-396X},
	url = {http://zancojournals.su.edu.krd/index.php/JAHS/article/view/3017},
	doi = {10.21271/zjhs.24.1.18},
	abstract = {In order for a conversation to be communicated more efficiently, participants exchange back-channels as a method of transmitting knowledge to indicate states such as attention, comprehension, misunderstanding, approval and non-acceptance. Listener responses, more commonly referred to as back-channeling, have attracted attention from diverse scholarly disciplines including linguistics because of their importance in effective dialogue and communication. This study introduces back-channeling, conveys its importance, and discusses its implications across Kurdish and English cultures. The study aims at discovering most common Kurdish back-channels through analyzing authentic face-to-face interactions, and identifying their forms and function in conversation. For this purpose, a number of TV channel interviews and programs have been selected to be analyzed as study sample. As a results of this study, it is clearly understood that Kurdish back-channels are quite similar to English ones in having very various types and forms, yet when it comes to functioning in interactions amongst speakers, there are apparent differences in that same forms do not convey same communicative implications. This, undoubtedly, can be attributed to Kurdish and English cross-cultural and language nature differences.},
	language = {en},
	number = {1},
	urldate = {2022-03-16},
	journal = {Zanco Journal of Humanity Sciences},
	author = {Najim, Qani Nasih and Muhammad, Kawa Qadir},
	month = feb,
	year = {2020},
	note = {Number: 1},
	pages = {289--303},
}

@article{kraaz_backchannels_nodate,
	title = {Backchannels and the pragmatics of {South} {Asian} {Englishes}},
	volume = {n/a},
	issn = {1467-971X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/weng.12522},
	doi = {10.1111/weng.12522},
	abstract = {The pragmatics of postcolonial Englishes including backchannels have so far remained in the periphery of academic inquiry. As pragmatic principles may be regarded as culture-sensitive and various cultural differences have been attested between Great Britain and South Asia, the present paper studies backchannels in British, Indian and Sri Lankan English. Drawn from the respective spoken parts of the International Corpus of English, 3,212 backchannels are multifactorially modelled via a conditional inference tree and random forests including recent methodological improvements. Indications of pragmatic nativisation with backchannels are evident in Indian and Sri Lankan English with their distributions and forms in the light of various sociobiographic factors such as age and gender, but also type-token ratio and conversational topic resonate with cultural differences across the speech communities. Lexical echo backchannels only attestable in the South Asian varieties instantiate a creative pragmatic innovation adding to the existing repertoire of backchannels in world Englishes.},
	language = {en},
	number = {n/a},
	urldate = {2022-03-16},
	journal = {World Englishes},
	author = {Kraaz, Michelle and Bernaisch, Tobias},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/weng.12522},
}

@inproceedings{ward_exotic_1998,
	title = {Some {Exotic} {Discourse} {Markers} of {Spoken} {Dialog}},
	url = {https://aclanthology.org/W98-0311},
	urldate = {2022-03-16},
	booktitle = {Discourse {Relations} and {Discourse} {Markers}},
	author = {Ward, Nigel},
	year = {1998},
}

@inproceedings{ward_bottom-up_2012,
	address = {Seoul, South Korea},
	title = {A {Bottom}-{Up} {Exploration} of the {Dimensions} of {Dialog} {State} in {Spoken} {Interaction}},
	url = {https://aclanthology.org/W12-1628},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 13th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Ward, Nigel G. and Vega, Alejandro},
	month = jul,
	year = {2012},
	pages = {198--206},
}

@inproceedings{ward_prosody_2021,
	address = {Online},
	title = {Prosody: {Models}, {Methods}, and {Applications}},
	shorttitle = {Prosody},
	url = {https://aclanthology.org/2021.acl-tutorials.5},
	doi = {10.18653/v1/2021.acl-tutorials.5},
	abstract = {Prosody is essential in human interaction, enabling people to show interest, establish rapport, efficiently convey nuances of attitude or intent, and so on. Some applications that exploit prosodic knowledge have recently shown superhuman performance, and in many respects our ability to effectively model prosody is rapidly advancing. This tutorial will overview the computational modeling of prosody, including recent advances and diverse actual and potential applications.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing}: {Tutorial} {Abstracts}},
	publisher = {Association for Computational Linguistics},
	author = {Ward, Nigel and Levow, Gina-Anne},
	month = aug,
	year = {2021},
	pages = {26--28},
}

@inproceedings{ohno_collection_2017,
	address = {New York, NY, USA},
	series = {{IMCOM} '17},
	title = {Collection of responsive utterances to show attentive hearing attitude to speakers},
	isbn = {978-1-4503-4888-1},
	url = {https://doi.org/10.1145/3022227.3022257},
	doi = {10.1145/3022227.3022257},
	abstract = {One of the stressors for users who have a dialogue with a robot is a doubt about whether or not the robot can comprehend user's utterances. To solve this problem, it is effective for a robot to actively show the attitude of attentive hearing for user's utterances. This paper describes collection of responsive utterances to show the attitude of attentive hearing for the purpose of actualizing conversation robots with attitudes of attentive hearing. In the data collection, we made a worker respond to utterances in Japanese elders' narrative corpus so that the responses become appropriate as a role of a listener. As the result, we collected 4,885 responsive utterances uttered for narratives of 9 elders.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Ubiquitous} {Information} {Management} and {Communication}},
	publisher = {Association for Computing Machinery},
	author = {Ohno, Tomohiro and Murata, Masaki and Matsubara, Shigeki},
	month = jan,
	year = {2017},
	pages = {1--4},
}

@inproceedings{yamaguchi_analysis_2016,
	title = {Analysis and {Prediction} of {Morphological} {Patterns} of {Backchannels} for {Attentive} {Listening} {Agents}},
	abstract = {Backchannels play an important role in smooth dialogue, especially attentive listening. In this paper, we analyze the morphological patterns (category) of backchannels, and how these relate to linguistic features of the preceding utterance. In particular we consider the type of the previous utterance-end boundary, the linguistic complexity of the previous utterance, and other features. Based on this analysis, we conduct machine learning to create a model to predict a backchannel’s morphological pattern from the preceding context. This model outperforms a baseline: its output better matches the actual backchannels made by human counselors, and human listeners rate its output as more natural.},
	language = {en},
	booktitle = {Proceedings of the 7th {International} {Workshop} on {Spoken} {Dialogue} {Systems}},
	author = {Yamaguchi, Takashi and Inoue, Koji and Yoshino, Koichiro and Takanashi, Katsuya and Ward, Nigel G and Kawahara, Tatsuya},
	year = {2016},
}

@article{morency_probabilistic_2010,
	title = {A probabilistic multimodal approach for predicting listener backchannels},
	volume = {20},
	issn = {1573-7454},
	url = {https://doi.org/10.1007/s10458-009-9092-y},
	doi = {10.1007/s10458-009-9092-y},
	abstract = {During face-to-face interactions, listeners use backchannel feedback such as head nods as a signal to the speaker that the communication is working and that they should continue speaking. Predicting these backchannel opportunities is an important milestone for building engaging and natural virtual humans. In this paper we show how sequential probabilistic models (e.g., Hidden Markov Model or Conditional Random Fields) can automatically learn from a database of human-to-human interactions to predict listener backchannels using the speaker multimodal output features (e.g., prosody, spoken words and eye gaze). The main challenges addressed in this paper are automatic selection of the relevant features and optimal feature representation for probabilistic models. For prediction of visual backchannel cues (i.e., head nods), our prediction model shows a statistically significant improvement over a previously published approach based on hand-crafted rules.},
	language = {en},
	number = {1},
	urldate = {2022-03-16},
	journal = {Autonomous Agents and Multi-Agent Systems},
	author = {Morency, Louis-Philippe and de Kok, Iwan and Gratch, Jonathan},
	month = jan,
	year = {2010},
	pages = {70--84},
}

@inproceedings{heldner_backchannel_2013,
	title = {Backchannel relevance spaces},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:su:diva-90946},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 47 universities and research institutions.},
	language = {eng},
	urldate = {2018-06-20},
	booktitle = {Proceedings of {XIth} {Conference} on {Nordic} {Prosody}},
	publisher = {Peter Lang Publishing Group},
	author = {Heldner, Mattias and Hjalmarsson, Anna and Edlund, Jens},
	year = {2013},
	pages = {137--146},
}

@article{heinz_backchannel_2003,
	title = {Backchannel responses as strategic responses in bilingual speakers’ conversations},
	volume = {35},
	issn = {0378-2166},
	url = {https://www.sciencedirect.com/science/article/pii/S037821660200190X},
	doi = {10.1016/S0378-2166(02)00190-X},
	abstract = {Backchannel responses appear to be a universal behavior, but specific backchannel behaviors are particular to language and culture. As such, they offer themselves to test central assumptions of Communication Accommodation Theory, in particular, assumptions relating to the processes of convergence and divergence. Researchers have identified linguistic and cultural differences in regard to the frequency, type, and placement of backchannel responses. This study examines differences in American English and German backchannel behavior and investigates backchannel behavior in interactions between monolingual and bilingual Germans. Study 1 documents significant differences in the frequency and placement of backchannel responses among monolingual German speakers and monolingual American English speakers. Results show that Germans produce fewer backchannel responses and place these responses less frequently in overlapping positions than American speakers do. Study 2 finds that native Germans who have become equally proficient in American English, when they speak to other native Germans in German, produce a higher number of backchannel responses and more often in overlapping positions than do monolingual Germans. This pragmatic transfer, for which some evidence exists in cross-linguistic studies, contradicts basic assumptions of Communication Accommodation Theory. Implications of these findings for Communication Accommodation Theory, future research on backchannel responses, and pragmalinguistic research are discussed.},
	language = {en},
	number = {7},
	urldate = {2022-03-16},
	journal = {Journal of Pragmatics},
	author = {Heinz, Bettina},
	month = jul,
	year = {2003},
	pages = {1113--1142},
}

@article{tao_english_1991,
	title = {English backchannels in {Mandarin} conversations: {A} case study of superstratum pragmatic ‘interference’},
	volume = {16},
	issn = {0378-2166},
	shorttitle = {English backchannels in {Mandarin} conversations},
	url = {https://www.sciencedirect.com/science/article/pii/037821669190093D},
	doi = {10.1016/0378-2166(91)90093-D},
	abstract = {Most studies of language transfer have focussed on interference from a speaker's first language to his or her second language. This study presents data which suggests interference in the opposite direction: in two separate conversations in Mandarin, the two Mandarin speakers for whom American English has become their dominant language are shown to make extensive use of American English backchannel strategies which are not found in their Mandarin-dominant interlocutors' speech. Comparisons with English and Mandarin monolingual conversations show that the English-dominant speakers are behaving as American English speakers do, while the Mandarin-dominant speakers are behaving as Mandarin speakers do, suggesting interference from the second (now dominant) language on the first.},
	language = {en},
	number = {3},
	urldate = {2022-03-16},
	journal = {Journal of Pragmatics},
	author = {Tao, Hongyin and Thompson, Sandra A.},
	month = sep,
	year = {1991},
	pages = {209--223},
}

@inproceedings{colombo_code-switched_2021,
	address = {Online and Punta Cana, Dominican Republic},
	title = {Code-switched inspired losses for spoken dialog representations},
	url = {https://aclanthology.org/2021.emnlp-main.656},
	doi = {10.18653/v1/2021.emnlp-main.656},
	abstract = {Spoken dialogue systems need to be able to handle both multiple languages and multilinguality inside a conversation (e.g in case of code-switching). In this work, we introduce new pretraining losses tailored to learn generic multilingual spoken dialogue representations. The goal of these losses is to expose the model to code-switched language. In order to scale up training, we automatically build a pretraining corpus composed of multilingual conversations in five different languages (French, Italian, English, German and Spanish) from OpenSubtitles, a huge multilingual corpus composed of 24.3G tokens. We test the generic representations on MIAM, a new benchmark composed of five dialogue act corpora on the same aforementioned languages as well as on two novel multilingual tasks (i.e multilingual mask utterance retrieval and multilingual inconsistency identification). Our experiments show that our new losses achieve a better performance in both monolingual and multilingual settings.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Colombo, Pierre and Chapuis, Emile and Labeau, Matthieu and Clavel, Chloé},
	month = nov,
	year = {2021},
	pages = {8320--8337},
}

@inproceedings{moran_acqdiv_2016,
	address = {Portorož, Slovenia},
	title = {The {ACQDIV} {Database}: {Min}(d)ing the {Ambient} {Language}},
	shorttitle = {The {ACQDIV} {Database}},
	url = {https://aclanthology.org/L16-1700},
	abstract = {One of the most pressing questions in cognitive science remains unanswered: what cognitive mechanisms enable children to learn any of the world's 7000 or so languages? Much discovery has been made with regard to specific learning mechanisms in specific languages, however, given the remarkable diversity of language structures (Evans and Levinson 2009, Bickel 2014) the burning question remains: what are the underlying processes that make language acquisition possible, despite substantial cross-linguistic variation in phonology, morphology, syntax, etc.? To investigate these questions, a comprehensive cross-linguistic database of longitudinal child language acquisition corpora from maximally diverse languages has been built.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'16)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Moran, Steven},
	month = may,
	year = {2016},
	pages = {4423--4429},
}

@inproceedings{wang_contrasting_2011,
	address = {Portland, Oregon, USA},
	title = {Contrasting {Multi}-{Lingual} {Prosodic} {Cues} to {Predict} {Verbal} {Feedback} for {Rapport}},
	url = {https://aclanthology.org/P11-2108},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 49th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Siwei and Levow, Gina-Anne},
	month = jun,
	year = {2011},
	pages = {614--619},
}

@inproceedings{prevot_quantitative_2013,
	address = {Metz, France},
	title = {A quantitative view of feedback lexical markers in conversational {French}},
	url = {https://aclanthology.org/W13-4011},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the {SIGDIAL} 2013 {Conference}},
	publisher = {Association for Computational Linguistics},
	author = {Prévot, Laurent and Bigi, Brigitte and Bertrand, Roxane},
	month = aug,
	year = {2013},
	pages = {87--91},
}

@inproceedings{cathcart_shallow_2003,
	address = {Budapest, Hungary},
	title = {A shallow model of back-channel continuers in spoken dialogue},
	url = {https://aclanthology.org/E03-1069},
	urldate = {2022-03-16},
	booktitle = {10th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Cathcart, Nicola and Carletta, Jean and Klein, Ewan},
	month = apr,
	year = {2003},
}

@inproceedings{lala_attentive_2017,
	address = {Saarbrücken, Germany},
	title = {Attentive listening system with backchanneling, response generation and flexible turn-taking},
	url = {https://aclanthology.org/W17-5516},
	doi = {10.18653/v1/W17-5516},
	abstract = {Attentive listening systems are designed to let people, especially senior people, keep talking to maintain communication ability and mental health. This paper addresses key components of an attentive listening system which encourages users to talk smoothly. First, we introduce continuous prediction of end-of-utterances and generation of backchannels, rather than generating backchannels after end-point detection of utterances. This improves subjective evaluations of backchannels. Second, we propose an effective statement response mechanism which detects focus words and responds in the form of a question or partial repeat. This can be applied to any statement. Moreover, a flexible turn-taking mechanism is designed which uses backchannels or fillers when the turn-switch is ambiguous. These techniques are integrated into a humanoid robot to conduct attentive listening. We test the feasibility of the system in a pilot experiment and show that it can produce coherent dialogues during conversation.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 18th {Annual} {SIGdial} {Meeting} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Lala, Divesh and Milhorat, Pierrick and Inoue, Koji and Ishida, Masanari and Takanashi, Katsuya and Kawahara, Tatsuya},
	month = aug,
	year = {2017},
	pages = {127--136},
}

@inproceedings{noguchi_japanese_2014,
	address = {Reykjavik, Iceland},
	title = {Japanese conversation corpus for training and evaluation of backchannel prediction model.},
	url = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/717_Paper.pdf},
	abstract = {In this paper, we propose an experimental method for building a specialized corpus for training and evaluating backchannel prediction models of spoken dialogue. To develop a backchannel prediction model using a machine learning technique, it is necessary to discriminate between the timings of the interlocutor s speech when more listeners commonly respond with backchannels and the timings when fewer listeners do so. The proposed corpus indicates the normative timings for backchannels in each speech with millisecond accuracy. In the proposed method, we first extracted each speech comprising a single turn from recorded conversation. Second, we presented these speeches as stimuli to 89 participants and asked them to respond by key hitting whenever they thought it appropriate to respond with a backchannel. In this way, we collected 28983 responses. Third, we applied the Gaussian mixture model to the temporal distribution of the responses and estimated the center of Gaussian distribution, that is, the backchannel relevance place (BRP), in each case. Finally, we synthesized 10 pairs of stereo speech stimuli and asked 19 participants to rate each on a 7-point scale of naturalness. The results show that backchannels inserted at BRPs were significantly higher than those in the original condition.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the {Ninth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'14)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Noguchi, Hiroaki and Katagiri, Yasuhiro and Den, Yasuharu},
	month = may,
	year = {2014},
	pages = {4429--4433},
}

@inproceedings{jang_bpm_mt_2021,
	address = {Online and Punta Cana, Dominican Republic},
	title = {{BPM}\_MT: {Enhanced} {Backchannel} {Prediction} {Model} using {Multi}-{Task} {Learning}},
	shorttitle = {{BPM}\_MT},
	url = {https://aclanthology.org/2021.emnlp-main.277},
	doi = {10.18653/v1/2021.emnlp-main.277},
	abstract = {Backchannel (BC), a short reaction signal of a listener to a speaker's utterances, helps to improve the quality of the conversation. Several studies have been conducted to predict BC in conversation; however, the utilization of advanced natural language processing techniques using lexical information presented in the utterances of a speaker has been less considered. To address this limitation, we present a BC prediction model called BPM\_MT (Backchannel prediction model with multitask learning), which utilizes KoBERT, a pre-trained language model. The BPM\_MT simultaneously carries out two tasks at learning: 1) BC category prediction using acoustic and lexical features, and 2) sentiment score prediction based on sentiment cues. BPM\_MT exhibited 14.24\% performance improvement compared to the existing baseline in the four BC categories: continuer, understanding, empathic response, and No BC. In particular, for empathic response category, a performance improvement of 17.14\% was achieved.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Jang, Jin Yea and Kim, San and Jung, Minyoung and Shin, Saim and Gweon, Gahgene},
	month = nov,
	year = {2021},
	pages = {3447--3452},
}

@inproceedings{levitan_entrainment_2011,
	address = {Portland, Oregon, USA},
	title = {Entrainment in {Speech} {Preceding} {Backchannels}.},
	url = {https://aclanthology.org/P11-2020},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 49th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Levitan, Rivka and Gravano, Agustín and Hirschberg, Julia},
	month = jun,
	year = {2011},
	pages = {113--117},
}

@inproceedings{dogruoz_survey_2021,
	address = {Online},
	title = {A {Survey} of {Code}-switching: {Linguistic} and {Social} {Perspectives} for {Language} {Technologies}},
	shorttitle = {A {Survey} of {Code}-switching},
	url = {https://aclanthology.org/2021.acl-long.131},
	doi = {10.18653/v1/2021.acl-long.131},
	abstract = {The analysis of data in which multiple languages are represented has gained popularity among computational linguists in recent years. So far, much of this research focuses mainly on the improvement of computational methods and largely ignores linguistic and social aspects of C-S discussed across a wide range of languages within the long-established literature in linguistics. To fill this gap, we offer a survey of code-switching (C-S) covering the literature in linguistics with a reflection on the key issues in language technologies. From the linguistic perspective, we provide an overview of structural and functional patterns of C-S focusing on the literature from European and Indian contexts as highly multilingual areas. From the language technologies perspective, we discuss how massive language models fail to represent diverse C-S types due to lack of appropriate training data, lack of robust evaluation benchmarks for C-S (across multilingual situations and types of C-S) and lack of end-to- end systems that cover sociolinguistic aspects of C-S as well. Our survey will be a step to- wards an outcome of mutual benefit for computational scientists and linguists with a shared interest in multilingualism and C-S.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Doğruöz, A. Seza and Sitaram, Sunayana and Bullock, Barbara E. and Toribio, Almeida Jacqueline},
	month = aug,
	year = {2021},
	pages = {1654--1666},
}

@inproceedings{dogruoz_how_2021,
	address = {Singapore and Online},
	title = {How “open” are the conversations with open-domain chatbots? {A} proposal for {Speech} {Event} based evaluation},
	shorttitle = {How “open” are the conversations with open-domain chatbots?},
	url = {https://aclanthology.org/2021.sigdial-1.41},
	abstract = {Open-domain chatbots are supposed to converse freely with humans without being restricted to a topic, task or domain. However, the boundaries and/or contents of open-domain conversations are not clear. To clarify the boundaries of “openness”, we conduct two studies: First, we classify the types of “speech events” encountered in a chatbot evaluation data set (i.e., Meena by Google) and find that these conversations mainly cover the “small talk” category and exclude the other speech event categories encountered in real life human-human communication. Second, we conduct a small-scale pilot study to generate online conversations covering a wider range of speech event categories between two humans vs. a human and a state-of-the-art chatbot (i.e., Blender by Facebook). A human evaluation of these generated conversations indicates a preference for human-human conversations, since the human-chatbot conversations lack coherence in most speech event categories. Based on these results, we suggest (a) using the term “small talk” instead of “open-domain” for the current chatbots which are not that “open” in terms of conversational abilities yet, and (b) revising the evaluation methods to test the chatbot conversations against other speech events.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 22nd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Doğruöz, A. Seza and Skantze, Gabriel},
	month = jul,
	year = {2021},
	pages = {392--402},
}

@inproceedings{ekstedt_projection_2021,
	address = {Singapore and Online},
	title = {Projection of {Turn} {Completion} in {Incremental} {Spoken} {Dialogue} {Systems}},
	url = {https://aclanthology.org/2021.sigdial-1.45},
	abstract = {The ability to take turns in a fluent way (i.e., without long response delays or frequent interruptions) is a fundamental aspect of any spoken dialog system. However, practical speech recognition services typically induce a long response delay, as it takes time before the processing of the user's utterance is complete. There is a considerable amount of research indicating that humans achieve fast response times by projecting what the interlocutor will say and estimating upcoming turn completions. In this work, we implement this mechanism in an incremental spoken dialog system, by using a language model that generates possible futures to project upcoming completion points. In theory, this could make the system more responsive, while still having access to semantic information not yet processed by the speech recognizer. We conduct a small study which indicates that this is a viable approach for practical dialog systems, and that this is a promising direction for future research.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 22nd {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Ekstedt, Erik and Skantze, Gabriel},
	month = jul,
	year = {2021},
	pages = {431--437},
}

@inproceedings{boudin_multimodal_2021,
	address = {Cham},
	title = {A {Multimodal} {Model} for {Predicting} {Conversational} {Feedbacks}},
	isbn = {978-3-030-83527-9},
	doi = {10.1007/978-3-030-83527-9_46},
	abstract = {We propose in this paper a statistical model in the perspective of predicting listener’s feedbacks in a conversation. The first contribution of the paper is a study of the prediction of all feedbacks, including those in overlap with the speaker with a good accuracy. Existing model are good at predicting feedbacks during a pause, but reach a very low success level for all feedbacks. We give in this paper a first step towards this complex problem. The second contribution is a model predicting precisely the type of the feedback (generic vs. specific) as well as other specific features (valence expectation) useful in particular for generating feedbacks in dialogue systems. This work relies on an original corpus.},
	language = {en},
	booktitle = {Text, {Speech}, and {Dialogue}},
	publisher = {Springer International Publishing},
	author = {Boudin, Auriane and Bertrand, Roxane and Rauzy, Stéphane and Ochs, Magalie and Blache, Philippe},
	editor = {Ekštein, Kamil and Pártl, František and Konopík, Miloslav},
	year = {2021},
	pages = {537--549},
}

@inproceedings{hara_turn-taking_2019,
	title = {Turn-{Taking} {Prediction} {Based} on {Detection} of {Transition} {Relevance} {Place}},
	url = {https://www.isca-speech.org/archive/interspeech_2019/hara19_interspeech.html},
	doi = {10.21437/Interspeech.2019-1537},
	abstract = {We address turn-taking prediction in which spoken dialogue systems predict when to take the conversational ﬂoor. In natural conversations, many turn-taking decisions are arbitrary and subjective. In this study, we propose taking into account the concept of the transition relevance place (TRP) for turn-taking prediction. TRP is deﬁned as a timing when the current speaking turn can be completed and other participants are able to take the turn. We conducted annotation of TRP on a human-robot dialogue corpus, ensuring the objectivity of this annotation among annotators. The proposed turn-taking prediction model adopts a two-step approach that detects TRP at ﬁrst and then predicts a turn-taking event if TRP is detected. Experimental evaluations demonstrate that the proposed model improves the accuracy of turn-taking prediction by incorporating TRP detection.},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Interspeech 2019},
	publisher = {ISCA},
	author = {Hara, Kohei and Inoue, Koji and Takanashi, Katsuya and Kawahara, Tatsuya},
	month = sep,
	year = {2019},
	pages = {4170--4174},
}

@inproceedings{razavi_investigating_2019,
	title = {Investigating {Linguistic} and {Semantic} {Features} for {Turn}-{Taking} {Prediction} in {Open}-{Domain} {Human}-{Computer} {Conversation}},
	url = {https://www.isca-speech.org/archive/interspeech_2019/razavi19_interspeech.html},
	doi = {10.21437/Interspeech.2019-3152},
	abstract = {In this paper we address the problem of turn-taking prediction in open-ended communication between humans and dialogue agents. In a non-task-oriented interaction with dialogue agents, user inputs are apt to be grammatically and lexically diverse, and at times quite lengthy, with many pauses; all of this makes it harder for the system to decide when to jump in. As a result recent turn-taking predictors designed for speciﬁc tasks or for human-human interactions will scarcely be applicable. In this paper we focus primarily on the predictive potential of linguistic features, including lexical, syntactic and semantic features, as well as timing features, whereas past work has typically placed more emphasis on prosodic features, sometimes supplemented with non-verbal behaviors such as gaze and head movements. The basis for our study is a corpus of 15 “friendly” dialogues between humans and a (Wizard-of-Oz enabled) virtual dialogue agent, annotated for pause times and types. The model of turn-taking obtained by supervised learning predicts turn-taking points with increasing accuracy using only prosodic features, only timing and speech rate features, only lexical and syntactic features, and achieves state-of-the art performance with a mixture-of-experts model combining these features along with a semantic criterion.},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Interspeech 2019},
	publisher = {ISCA},
	author = {Razavi, S. Zahra and Kane, Benjamin and Schubert, Lenhart K.},
	month = sep,
	year = {2019},
	pages = {4140--4144},
}

@book{dharo_conversational_2021,
	series = {Lectures {Notes} in {Electrical} {Engineering}},
	title = {Conversational {Dialogue} {Systems} for the {Next} {Decade}},
	publisher = {Springer},
	editor = {D'Haro, Luis Fernando and Callejas, Zoraida and Nakamura, Satoshi},
	year = {2021},
}

@incollection{adiba_delay_2021,
	address = {Singapore},
	title = {Delay {Mitigation} for {Backchannel} {Prediction} in {Spoken} {Dialog} {System}},
	isbn = {9789811583957},
	url = {https://doi.org/10.1007/978-981-15-8395-7_10},
	abstract = {To provide natural dialogues between spoken dialog systems and users, backchannel feedback can be used to make the interaction more sophisticated. Many related studies have combined acoustic and lexical features into a model to achieve better prediction. However, extracting lexical features leads to a delay caused by the automatic speech recognition (ASR) process. The systems should respond with no delay, since delays reduce the naturalness of the conversation and make the user feel dissatisfied. In this work, we present a prior prediction model for reducing response delay in backchannel prediction. We first train both acoustic- and lexical-based backchannel prediction models independently. In the lexical-based model, prior prediction is necessary to consider the ASR delay. The prior prediction model is trained with a weighting value that gradually increases when a sequence is closer to a suitable response timing. The backchannel probability is calculated based on the outputs from both acoustic- and lexical-based models. Evaluation results show that the prior prediction model can predict backchannel with an improvement rate on the F1 score 8\% better than the current state-of-the-art algorithm under a 2.0-s delay condition.},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Conversational {Dialogue} {Systems} for the {Next} {Decade}},
	publisher = {Springer},
	author = {Adiba, Amalia Istiqlali and Homma, Takeshi and Bertero, Dario and Sumiyoshi, Takashi and Nagamatsu, Kenji},
	editor = {D'Haro, Luis Fernando and Callejas, Zoraida and Nakamura, Satoshi},
	year = {2021},
	doi = {10.1007/978-981-15-8395-7_10},
	pages = {129--143},
}

@inproceedings{roddy_multimodal_2018,
	address = {New York, NY, USA},
	series = {{ICMI} '18},
	title = {Multimodal {Continuous} {Turn}-{Taking} {Prediction} {Using} {Multiscale} {RNNs}},
	isbn = {978-1-4503-5692-3},
	url = {https://doi.org/10.1145/3242969.3242997},
	doi = {10.1145/3242969.3242997},
	abstract = {In human conversational interactions, turn-taking exchanges can be coordinated using cues from multiple modalities. To design spoken dialog systems that can conduct fluid interactions it is desirable to incorporate cues from separate modalities into turn-taking models. We propose that there is an appropriate temporal granularity at which modalities should be modeled. We design a multiscale RNN architecture to model modalities at separate timescales in a continuous manner. Our results show that modeling linguistic and acoustic features at separate temporal rates can be beneficial for turn-taking modeling. We also show that our approach can be used to incorporate gaze features into turn-taking models.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 20th {ACM} {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Roddy, Matthew and Skantze, Gabriel and Harte, Naomi},
	year = {2018},
	pages = {186--190},
}

@inproceedings{ward_where_2012,
	address = {Stevenson, WA},
	title = {Where in {Dialog} {Space} does {Uh}-huh {Occur}?},
	abstract = {In what dialog situations and contexts do backchannels
commonly occur? This paper examines this question using a newly developed notion of dialog space, defined
by orthogonal, prosody-derived dimensions. Taking 3363
instances of uh-huh, found in the Switchboard corpus, we
examine where in this space they tend to occur. While
the results largely agree with previous descriptions and
observations, we find several novel aspects, relating to
rhythm, polarity, and the details of the low-pitch cue.},
	language = {en},
	booktitle = {Proceedings of {Workshop} on {Feedback} {Behaviors} in {Dialog}},
	author = {Ward, Nigel G.},
	year = {2012},
	pages = {7--10},
}

@inproceedings{buschmeier_adapting_2012,
	address = {Stevenson, WA},
	title = {Adapting {Language} {Production} to {Listener} {Feedback} {Behaviour}},
	abstract = {Listeners use linguistic feedback to provide evidence of understanding to speakers. They, in turn, use it to reason about listeners’ mental states, to determine the groundedness of communicated information and to adapt subsequent utterances to the listeners’ needs. We describe a probabilistic model for the interpretation of listener feedback in its dialogue context that enables a speaker to evaluate the listener’s mental state and gauge common ground. We then discuss levels and mechanisms of adaptation that speaker’s commonly use in reaction to listener feedback.},
	language = {en},
	booktitle = {Proceedings of {Workshop} on {Feedback} {Behaviors} in {Dialog}},
	author = {Buschmeier, Hendrik and Kopp, Stefan},
	year = {2012},
	pages = {7--10},
}

@inproceedings{roddy_investigating_2018,
	title = {Investigating {Speech} {Features} for {Continuous} {Turn}-{Taking} {Prediction} {Using} {LSTMs}},
	url = {https://www.isca-speech.org/archive/interspeech_2018/roddy18_interspeech.html},
	doi = {10.21437/Interspeech.2018-2124},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Interspeech 2018},
	publisher = {ISCA},
	author = {Roddy, Matthew and Skantze, Gabriel and Harte, Naomi},
	month = sep,
	year = {2018},
	pages = {586--590},
}

@phdthesis{roddy_neural_2021,
	address = {Dublin},
	type = {{PhD} {Thesis}},
	title = {Neural {Turn}-{Taking} {Models} for {Spoken} {Dialogue} {Systems}},
	language = {en},
	school = {Trinity College Dublin},
	author = {Roddy, Matthew},
	year = {2021},
}

@inproceedings{ferre_unimodal_2017,
	address = {Saarbrücken, Germany},
	title = {Unimodal and {Bimodal} {Backchannels} in {Conversational} {English}},
	url = {https://hal.archives-ouvertes.fr/hal-01575230},
	doi = {10.21437/SemDial.2017-3},
	abstract = {This paper presents differences in use of verbal ((oh) yeah, (mh)mh, okay. . .) and visual backchannels (head nods, shakes, tilts), e.g. unimodal backchannels, as well as bimodal backchannels that combine a verbal token and a head movement in conversational English. We analyze the par-ticipants' gaze-pattern before the production of a BC but also during and immediately after its delivery. We also analyze their placement regarding the main speaker's turn and within the discourse topic. Lastly, we discuss their functions. Our findings reveal that each BC type shows a different picture from the other two both in terms of where they occur within the main speaker's turn and what their functions are. We however do not confirm previous observations regarding the constraints on their occurrence within a discourse topic.},
	urldate = {2022-03-16},
	booktitle = {{SEMDIAL} 2017},
	author = {Ferré, Gaëlle and Renaudier, Suzanne},
	month = aug,
	year = {2017},
	pages = {27--37},
}

@article{poppe_perceptual_2013,
	title = {Perceptual evaluation of backchannel strategies for artificial listeners},
	volume = {27},
	issn = {1573-7454},
	url = {https://doi.org/10.1007/s10458-013-9219-z},
	doi = {10.1007/s10458-013-9219-z},
	abstract = {Artificial listeners are virtual agents that can listen attentively to a human speaker in a dialog. In this paper, we present two experiments where we investigate the perception of rule-based backchannel strategies for artificial listeners. In both, we collect subjective judgements of humans who observe a video of a speaker together with a corresponding animation of an artificial listener. In the first experiment, we evaluate six rule-based strategies that differ in the types of features (e.g. prosody, gaze) they consider. The ratings are given at the level of a speech turn and can be considered a measure for how human-like the generated listening behavior is perceived. In the second experiment, we systematically investigate the effect of the quantity, type and timing of backchannels within the discourse of the speaker. Additionally, we asked human observers to press a button whenever they thought a generated backchannel occurrence was inappropriate. Both experiments together give insights in the factors, both from an observation and generation point-of-view, that influence the perception of backchannel strategies for artificial listeners.},
	language = {en},
	number = {2},
	urldate = {2022-03-16},
	journal = {Autonomous Agents and Multi-Agent Systems},
	author = {Poppe, Ronald and Truong, Khiet P. and Heylen, Dirk},
	month = sep,
	year = {2013},
	pages = {235--253},
}

@inproceedings{inden_timing_2013,
	address = {New York, NY, USA},
	series = {{ICMI} '13},
	title = {Timing and entrainment of multimodal backchanneling behavior for an embodied conversational agent},
	isbn = {978-1-4503-2129-7},
	url = {https://doi.org/10.1145/2522848.2522890},
	doi = {10.1145/2522848.2522890},
	abstract = {We report on an analysis of feedback behavior in an Active Listening Corpus as produced verbally, visually (head movement) and bimodally. The behavior is modeled in an embodied conversational agent and displayed in a conversation with a real human to human participants for perceptual evaluation. Five strategies for the timing of backchannels are compared: copying the timing of the original human listener, producing backchannels at randomly selected times, producing backchannels according to high level timing distributions relative to the interlocutor's utterance and pauses, or according to local entrainment to the interlocutors' vowels, or according to both. Human observers judge that models with global timing distributions miss less opportunities for backchanneling than random timing.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 15th {ACM} on {International} conference on multimodal interaction},
	publisher = {Association for Computing Machinery},
	author = {Inden, Benjamin and Malisz, Zofia and Wagner, Petra and Wachsmuth, Ipke},
	month = dec,
	year = {2013},
	pages = {181--188},
}

@inproceedings{truong_multimodal_2011,
	title = {A multimodal analysis of vocal and visual backchannels in spontaneous dialogs},
	url = {https://www.isca-speech.org/archive/interspeech_2011/truong11_interspeech.html},
	doi = {10.21437/Interspeech.2011-744},
	abstract = {Backchannels (BCs) are short vocal and visual listener responses that signal attention, interest, and understanding to the speaker. Previous studies have investigated BC prediction in telephone-style dialogs from prosodic cues. In contrast, we consider spontaneous face-to-face dialogs. The additional visual modality allows speaker and listener to monitor each other’s attention continuously, and we hypothesize that this affects the BC-inviting cues. In this study, we investigate how gaze, in addition to prosody, can cue BCs. Moreover, we focus on the type of BC performed, with the aim to ﬁnd out whether vocal and visual BCs are invited by similar cues. In contrast to telephone-style dialogs, we do not ﬁnd rising/falling pitch to be a BC-inviting cue. However, in a face-to-face setting, gaze appears to cue BCs. In addition, we ﬁnd that mutual gaze occurs signiﬁcantly more often during visual BCs. Moreover, vocal BCs are more likely to be timed during pauses in the speaker’s speech.},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Interspeech 2011},
	publisher = {ISCA},
	author = {Truong, Khiet P. and Poppe, Ronald and Kok, Iwan de and Heylen, Dirk},
	month = aug,
	year = {2011},
	pages = {2973--2976},
}

@inproceedings{kawahara_prediction_2016,
	title = {Prediction and {Generation} of {Backchannel} {Form} for {Attentive} {Listening} {Systems}},
	url = {https://www.isca-speech.org/archive/interspeech_2016/kawahara16b_interspeech.html},
	doi = {10.21437/Interspeech.2016-118},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Interspeech 2016},
	publisher = {ISCA},
	author = {Kawahara, Tatsuya and Yamaguchi, Takashi and Inoue, Koji and Takanashi, Katsuya and Ward, Nigel},
	month = sep,
	year = {2016},
	pages = {2890--2894},
}

@inproceedings{hara_prediction_2018,
	title = {Prediction of {Turn}-taking {Using} {Multitask} {Learning} with {Prediction} of {Backchannels} and {Fillers}},
	url = {https://www.isca-speech.org/archive/interspeech_2018/hara18_interspeech.html},
	doi = {10.21437/Interspeech.2018-1442},
	abstract = {We address prediction of turn-taking considering related behaviors such as backchannels and ﬁllers. Backchannels are used by the listeners to acknowledge that the current speaker can hold the turn. On the other hand, ﬁllers are used by the prospective speakers to indicate a will to take a turn. We propose a turntaking model based on multitask learning in conjunction with prediction of backchannels and ﬁllers. The multitask learning of LSTM neural networks shared by these tasks allows for efﬁcient and generalized learning, and thus improves prediction accuracy. Evaluations with two kinds of dialogue corpora of human-robot interaction demonstrate that the proposed multitask learning scheme outperforms the conventional single-task learning.},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Interspeech 2018},
	publisher = {ISCA},
	author = {Hara, Kohei and Inoue, Koji and Takanashi, Katsuya and Kawahara, Tatsuya},
	month = sep,
	year = {2018},
	pages = {991--995},
}

@inproceedings{hussain_speech_2019,
	title = {Speech {Driven} {Backchannel} {Generation} {Using} {Deep} {Q}-{Network} for {Enhancing} {Engagement} in {Human}-{Robot} {Interaction}},
	url = {https://www.isca-speech.org/archive/interspeech_2019/hussain19_interspeech.html},
	doi = {10.21437/Interspeech.2019-2521},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Interspeech 2019},
	publisher = {ISCA},
	author = {Hussain, Nusrah and Erzin, Engin and Sezgin, T. Metin and Yemez, Yücel},
	month = sep,
	year = {2019},
	pages = {4445--4449},
}

@phdthesis{baur_cooperative_2018,
	address = {Augsburg},
	type = {{PhD} {Thesis}},
	title = {Cooperative and transparent machine learning for the context-sensitive analysis of social interactions},
	copyright = {https://www.uni-augsburg.de/de/organisation/bibliothek/publizieren-zitieren-archivieren/publiz/},
	url = {https://opus.bibliothek.uni-augsburg.de/opus4/frontdoor/index/index/docId/40153},
	abstract = {The research area of Social Signal Processing paves the way for conversational companions, such as virtual agents or social robots, to become aware of nuances in our behaviours and implicit messages that come along with them. For machines to understand and interpret such behavioural cues, the state-of-the-art procedure is the application of various machine learning techniques. In many ML tasks, statistical models are trained on a large amount of annotated samples and an algorithm aims to match patterns that represent specific classes or values. ML tehniques, such as artificial neural networks, nowadays do pretty well in mapping and even identifying low level features to a specific recognition problem. A large drawback here is that the decisions they are making are not comprehensible and understandable to humans and that their assumptions are often wrong in changing contexts. Therefore a new research direction -"eXplainable Artificial Intelligence" (XAI)- identified the need of AI systems to be able to explain their decisions. In this thesis we investigate strategies to make the recognition and interpretation of complex social signals more transparent and explore ways to empower the human in the machine learning loop. To gain a better understanding of how humans interpret social cues, we first introduce an overview on results of behavioural psychology. We then describe the creation of various multi-person and muli-modal corpora in varying contexts that aim to induce multiple aspects of such behaviours. Next, we briefly introduce common techniques used in the area of social signal processing and machine learning. To successfully annotate and manage large continuous databases, a novel tool, named NOVA is presented. It allows to distribute the annotation task on multiple labellers and supports various types of annotations. NOVA further allows to take advantage of ML techniques already during the annotation process (a concept named cooperative machine learning). By employing CML, data is annotated simultaneously with the machine, which speeds up the annotation process and gives a more transparent idea of a machine's decisions. For inferring more complex behaviours, such as a person's conversational engagement or emotion regulation strategies, an approach is introduced that considers the predictions of multiple social cue recognisers and various types of context information. Finally, an outlook on future research directions is given.},
	language = {en},
	urldate = {2022-03-16},
	school = {Universität Augsburg},
	author = {Baur, Tobias},
	year = {2018},
}

@inproceedings{levow_contrasting_2012,
	title = {Contrasting cues to verbal and non-verbal backchannels in multi-lingual dyadic rapport},
	url = {https://www.isca-speech.org/archive/interspeech_2012/levow12_interspeech.html},
	doi = {10.21437/Interspeech.2012-188},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {Interspeech 2012},
	publisher = {ISCA},
	author = {Levow, Gina-Anne and Duncan, Susan},
	month = sep,
	year = {2012},
	pages = {835--838},
}

@incollection{berez-kroeker_managing_2022,
	title = {Managing {Conversation} {Analysis} {Data}},
	isbn = {978-0-262-36607-6},
	url = {https://direct.mit.edu/books/book/5244/The-Open-Handbook-of-Linguistic-Data-Management},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {The {Open} {Handbook} of {Linguistic} {Data} {Management}},
	publisher = {The MIT Press},
	author = {Hoey, Elliott M. and Raymond, Chase Wesley},
	editor = {Berez-Kroeker, Andrea L. and McDonnell, Bradley and Koller, Eve and Collister, Lauren B.},
	year = {2022},
	doi = {10.7551/mitpress/12200.001.0001},
}

@book{berez-kroeker_open_2022,
	title = {The {Open} {Handbook} of {Linguistic} {Data} {Management}},
	isbn = {978-0-262-36607-6},
	url = {https://direct.mit.edu/books/book/5244/The-Open-Handbook-of-Linguistic-Data-Management},
	language = {en},
	urldate = {2022-03-16},
	publisher = {The MIT Press},
	editor = {Berez-Kroeker, Andrea L. and McDonnell, Bradley and Koller, Eve and Collister, Lauren B.},
	year = {2022},
	doi = {10.7551/mitpress/12200.001.0001},
}

@inproceedings{niekerk_analyzing_2021,
	title = {Analyzing {Speaker} {Information} in {Self}-{Supervised} {Models} to {Improve} {Zero}-{Resource} {Speech} {Processing}},
	url = {https://www.isca-speech.org/archive/interspeech_2021/niekerk21_interspeech.html},
	doi = {10.21437/Interspeech.2021-1182},
	language = {en},
	urldate = {2022-03-15},
	booktitle = {Interspeech 2021},
	publisher = {ISCA},
	author = {Niekerk, Benjamin van and Nortje, Leanne and Baas, Matthew and Kamper, Herman},
	month = aug,
	year = {2021},
	pages = {1554--1558},
}

@article{yu_perception_2021,
	title = {Perception of rhythmic agency for conversational labeling},
	issn = {0737-0024},
	url = {https://doi.org/10.1080/07370024.2021.1877541},
	doi = {10.1080/07370024.2021.1877541},
	urldate = {2022-03-08},
	journal = {Human–Computer Interaction},
	author = {Yu, Christine Guo and Blackwell, Alan F. and Cross, Ian},
	month = feb,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/07370024.2021.1877541},
	pages = {1--24},
}

@inproceedings{zayats_disfluencies_2019,
	title = {Disfluencies and {Human} {Speech} {Transcription} {Errors}},
	url = {https://www.isca-speech.org/archive/interspeech_2019/zayats19_interspeech.html},
	doi = {10.21437/Interspeech.2019-3134},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Proceedings of {Interspeech} 2019},
	publisher = {ISCA},
	author = {Zayats, Vicky and Tran, Trang and Wright, Richard and Mansfield, Courtney and Ostendorf, Mari},
	month = sep,
	year = {2019},
	pages = {3088--3092},
}

@techreport{umair_gailbot_2021,
	title = {{GailBot}: {An} automatic transcription system for {Conversation} {Analysis}},
	url = {https://osf.io/u82wp/},
	language = {en},
	urldate = {2021-09-15},
	author = {Umair, Mohammad and Mertens, Julia and Albert, Saul and de Ruiter, J. P.},
	year = {2021},
	note = {Publisher: OSF},
}

@incollection{wallach_agencies_2020,
	address = {London},
	title = {Agencies in {Technology} {Design}: {Feminist} {Reconfigurations}},
	isbn = {978-1-00-307499-1},
	shorttitle = {Agencies in {Technology} {Design}},
	url = {https://www.taylorfrancis.com/books/9781000108934/chapters/10.4324/9781003074991-32},
	abstract = {This talk considers how capacities for action are currently figured at the human-machine interface, and how they might be imaginatively and materially reconfigured. Drawing on recent scholarship in feminist science and technology studies, I argue for research aimed at tracing differences within specific sociomaterial arrangements, without resorting to essentialist divides. This requires expanding our unit of analysis, while recognizing the inevitable cuts or boundaries through which technological systems are made. Based on my own experience of the worlds of technology research and development, moreover, I argue that these reconceptualisations have both practical and political implications for technology design.},
	language = {en},
	urldate = {2021-11-16},
	booktitle = {Machine {Ethics} and {Robot} {Ethics}},
	publisher = {Routledge},
	author = {Suchman, Lucy A.},
	editor = {Wallach, Wendell and Asaro, Peter},
	collaborator = {Wallach, Wendell and Asaro, Peter},
	month = sep,
	year = {2020},
	doi = {10.4324/9781003074991-32},
	pages = {361--375},
}

@misc{aungsiAudioVideoRecordings2014,
	title = {Audio and video recordings of {Kune}, a {Bininj} {Gunwok} dialect spoken in {Buluhkaduru} {Outstation} near {Maningrida}, {Northern} {Territory}.},
	url = {https://doi.org/10.4225/72/56E97A3F99539},
	urldate = {2022-03-10},
	journal = {Paradisec},
	author = {Si, Aung},
	year = {2014},
	note = {doi:10.4225/72/56E97A3F99539},
}

@article{shi_leveraging_2021,
	title = {Leveraging {End}-to-{End} {ASR} for {Endangered} {Language} {Documentation}: {An} {Empirical} {Study} on {Yoloxóchitl} {Mixtec}},
	journal = {arXiv preprint arXiv:2101.10877},
	author = {Shi, Jiatong and Amith, Jonathan D. and García, Rey Castillo and Sierra, Esteban Guadalupe and Duh, Kevin and Watanabe, Shinji},
	year = {2021},
}

@article{levinson_timing_2015,
	title = {Timing in turn-taking and its implications for processing models of language},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2015.00731/abstract},
	doi = {10.3389/fpsyg.2015.00731},
	abstract = {The core niche for language use is in verbal interaction, involving the rapid exchange of turns at talking. This paper reviews the extensive literature about this system, adding new statistical analyses of behavioral data where they have been missing, demonstrating that turn-taking has the systematic properties originally noted by Sacks et al. (1974; hereafter SSJ). This system poses some significant puzzles for current theories of language processing: the gaps between turns are short (of the order of 200 ms), but the latencies involved in language production are much longer (over 600 ms). This seems to imply that participants in conversation must predict (or ‘project’ as SSJ have it) the end of the current speaker’s turn in order to prepare their response in advance. This in turn implies some overlap between production and comprehension despite their use of common processing resources. Collecting together what is known behaviorally and experimentally about the system, the space for systematic explanations of language processing for conversation can be significantly narrowed, and we sketch some first model of the mental processes involved for the participant preparing to speak next.},
	urldate = {2015-09-07},
	journal = {Frontiers in Psychology: Language Sciences},
	author = {Levinson, Stephen C. and Torreira, Francisco},
	year = {2015},
	pages = {731},
}

@inproceedings{jurafsky_lexical_1998,
	address = {Montreal},
	title = {Lexical, prosodic, and syntactic cues for dialog acts},
	booktitle = {Proceedings of the {ACL}-{COLING} {Workshop} on {Discourse} {Relations} and {Discourse} {Markers}},
	author = {Jurafsky, Dan and Shriberg, Elizabeth and Fox, Barbara and Curl, Traci},
	year = {1998},
	pages = {114--120},
}

@inproceedings{kessler_scattertext_2017,
	title = {Scattertext: a {Browser}-{Based} {Tool} for {Visualizing} how {Corpora} {Differ}},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({System} {Demonstrations})},
	author = {Kessler, Jason},
	year = {2017},
	pages = {85--90},
}

@inproceedings{hunyadiHumanhumanHumanmachineCommunication2018,
	title = {Human-human, human-machine communication: on the {HuComTech} multimodal corpus},
	booktitle = {Selected papers from the {CLARIN} {Annual} {Conference} 2018, {Pisa}, 8-10 {October} 2018},
	publisher = {Linköping University Electronic Press, Linköpings universitet},
	author = {Hunyadi, Laszlo and Váradi, Tamás and Kovács, Gy and Szekrényes, István and Kiss, Hermina and Takács, Karolina},
	year = {2018},
	pages = {56--65},
}

@article{howes_feedback_2021,
	title = {Feedback {Relevance} {Spaces}: {Interactional} {Constraints} on {Processing} {Contexts} in {Dynamic} {Syntax}},
	volume = {30},
	issn = {1572-9583},
	shorttitle = {Feedback {Relevance} {Spaces}},
	doi = {10.1007/s10849-020-09328-1},
	abstract = {Feedback such as backchannels and clarification requests often occurs subsententially, demonstrating the incremental nature of grounding in dialogue. However, although such feedback can occur at any point within an utterance, it typically does not do so, tending to occur at Feedback Relevance Spaces (FRSs). We present a corpus study of acknowledgements and clarification requests in British English, and describe how our low-level, semantic processing model in Dynamic Syntax accounts for this feedback. The model trivially accounts for the 85\% of cases where feedback occurs at FRSs, but we also describe how it can be integrated or interpreted at non-FRSs using the predictive, incremental and interactive nature of the formalism. This model shows how feedback serves to continually realign processing contexts and thus manage the characteristic divergence and convergence that is key to moving dialogue forward.},
	language = {en},
	number = {2},
	journal = {Journal of Logic, Language and Information},
	author = {Howes, Christine and Eshghi, Arash},
	month = jun,
	year = {2021},
	pages = {331--362},
}

@misc{hisyamProjectLIPIIndonesian2013,
	type = {Archive},
	title = {A project of {LIPI} (the {Indonesian} {Institute} of {Sciences}) on {Documenting} and {Revitalizing} {Endangered} {Languages} and {Cultures} in {Eastern} {Indonesia}},
	url = {https://hdl.handle.net/1839/00-0000-0000-0022-6530-D},
	journal = {DOBES},
	author = {Hisyam, M. and Dwi Purwoko, Usman and Peranginangin, Dalan},
	year = {2013},
}

@inproceedings{dinan_wizard_2019,
	title = {Wizard of {Wikipedia}: {Knowledge}-powered {Conversational} {Agents}},
	abstract = {In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date. The most popular sequence to sequence models typically "generate and hope" generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output, rather than employing recalled knowledge as context. Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear grounding. To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia. We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses. Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction.},
	booktitle = {Proceedings of the {International} {Conference} on {Learning} {Representations} ({ICLR})},
	author = {Dinan, Emily and Roller, Stephen and Shuster, Kurt and Fan, Angela and Auli, Michael and Weston, Jason},
	year = {2019},
}

@book{di_paolo_linguistic_2018,
	address = {Cambridge, MA},
	title = {Linguistic bodies: the continuity between life and language},
	isbn = {978-0-262-03816-4},
	shorttitle = {Linguistic bodies},
	publisher = {MIT Press},
	author = {Di Paolo, Ezequiel A. and Cuffari, Elena Clare and De Jaegher, Hanne},
	year = {2018},
}

@inproceedings{cumbal_you_2021,
	title = {“{You} don’t understand me!”: {Comparing} {ASR} results for {L1} and {L2} speakers of {Swedish}},
	shorttitle = {“{You} don’t understand me!”},
	doi = {10.21437/Interspeech.2021-2140},
	booktitle = {Proceeding of {Interspeech} 2021},
	author = {Cumbal, Ronald and Moell, Birger and Lopes, José and Engwall, Olov},
	year = {2021},
	pages = {4463--4467},
}

@book{couper-kuhlen_interactional_2017,
	address = {Cambridge},
	title = {Interactional linguistics: an introduction to language in social interaction},
	isbn = {978-1-107-03280-4},
	shorttitle = {Interactional linguistics},
	publisher = {Cambridge University Press},
	author = {Couper-Kuhlen, Elizabeth and Selting, Margret},
	year = {2017},
}

@misc{caronCollectionZaarLangage2014,
	type = {Archive},
	title = {Zaar collection in {LLACAN}},
	url = {http://www.language-archives.org/language/say},
	journal = {COllections de COrpus Oraux Numeriques (CoCoON ex-CRDO)},
	author = {Caron, Bernard and Davan, Marvellous S. and Ali, Justin M. B.},
	year = {2014},
}

@misc{manfrediJubaCreoleCollection2016,
	type = {Archive},
	title = {Juba {Creole} collection in {LLACAN}},
	url = {http://www.language-archives.org/language/pga},
	journal = {OLAC resources},
	author = {Manfredi, Stefano},
	year = {2016},
}

@misc{caronHausaCollectionCOllections2016,
	title = {Hausa collection in {LLACAN}},
	copyright = {, Copyright © CorpAfroAs, Freely accessible},
	url = {http://www.language-archives.org/language/hau},
	language = {ha},
	urldate = {2022-03-10},
	author = {Caron, Bernard},
	collaborator = {COCOON and Langage, langues et cultures d'Afrique noire and Fatima, Idriss and S, Marvellous, Davan and Bernard, Caron and Hadiza, Yakubu},
	year = {2016},
	note = {Artwork Size: 1476162 Bytes
Medium: text/xml
Publisher: Langage, langues et cultures d'Afrique noire
Version Number: 1},
	keywords = {Annotation, Morphosyntax, anthropological\_linguistics, hau, pesonal anecdotes},
}

@misc{brykinaNganasanSpokenLanguage2018,
	type = {Archive},
	title = {Nganasan {Spoken} {Language} {Corpus} ({NSLC})},
	url = {http://hdl.handle.net/11022/0000-0007-C6F2-8},
	journal = {University of Hamburg},
	author = {Brykina, Maria and Gusev, Valentin and Szeverényi, Sándor and Wagner-Nagy, Beáta},
	year = {2018},
}

@article{amekaWhatIfImagining2019,
	title = {What if…? {Imagining} non-{Western} perspectives on pragmatic theory and practice},
	volume = {145},
	issn = {03782166},
	shorttitle = {What if…?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378216619300268},
	doi = {10.1016/j.pragma.2019.04.001},
	language = {en},
	urldate = {2022-03-15},
	journal = {Journal of Pragmatics},
	author = {Ameka, Felix K. and Terkourafi, Marina},
	month = may,
	year = {2019},
	pages = {72--82},
}

@inproceedings{hough_joint_2017,
	title = {Joint, {Incremental} {Disfluency} {Detection} and {Utterance} {Segmentation} from {Speech}},
	url = {http://aclweb.org/anthology/E17-1031},
	doi = {10.18653/v1/E17-1031},
	language = {en},
	urldate = {2017-10-25},
	booktitle = {Proceedings of the 15th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Volume} 1, {Long} {Papers}},
	publisher = {Association for Computational Linguistics},
	author = {Hough, Julian and Schlangen, David},
	year = {2017},
	pages = {326--336},
}

@inproceedings{vanzo_incrementally_2018,
	address = {Stockholm, Sweden},
	title = {Incrementally {Learning} {Semantic} {Attributes} through {Dialogue} {Interaction}},
	abstract = {Enabling a robot to properly interact with users plays a key role in the effective deployment of robotic platforms in domestic environments. Robots must be able to rely on interaction to improve their behaviour and adaptively understand their operational world. Semantic mapping is the task of building a representation of the environment, that can be enhanced through interaction with the user. In this task, a proper and effective acquisition of semantic attributes of targeted entities is essential for the task accomplishment itself. In this paper, we focus on the problem of learning dialogue policies to support semantic attribute acquisition, so that the effort required by humans in providing knowledge to the robot through dialogue is minimized. To this end, we design our Dialogue Manager as a multi-objective Markov Decision Process, solving the optimisation problem through Reinforcement Learning. The Dialogue Manager interfaces with an online incremental visual classifier, based on a Load-Balancing Self-Organizing Incremental Neural Network (LBSOINN). Experiments in a simulated scenario show the effectiveness of the proposed solution, suggesting that perceptual information can be properly exploited to reduce human tutoring cost. Moreover, a dialogue policy trained on a small amount of data generalises well to larger datasets, and so the proposed online scheme, as well as the real-time nature of the processing, are suited for an extensive deployment in real scenarios. To this end, this paper provides a demonstration of the complete system on a real robot.},
	language = {en},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems} ({AAMAS} 2018)},
	author = {Vanzo, Andrea and Part, Jose L and Yu, Yanchao and Nardi, Daniele and Lemon, Oliver},
	year = {2018},
	pages = {865--873},
}

@inproceedings{arkel_simple_2020,
	title = {A simple repair mechanism can alleviate computational demands of pragmatic reasoning: simulations and complexity analysis},
	shorttitle = {A simple repair mechanism can alleviate computational demands of pragmatic reasoning},
	doi = {10.18653/v1/2020.conll-1.14},
	abstract = {How can people communicate successfully while keeping resource costs low in the face of ambiguity? We present a principled theoretical analysis comparing two strategies for disambiguation in communication: (i) pragmatic reasoning, where communicators reason about each other, and (ii) other-initiated repair, where communicators signal and resolve trouble interactively. Using agent-based simulations and computational complexity analyses, we compare the efficiency of these strategies in terms of communicative success, computation cost and interaction cost. We show that agents with a simple repair mechanism can increase efficiency, compared to pragmatic agents, by reducing their computational burden at the cost of longer interactions. We also find that efficiency is highly contingent on the mechanism, highlighting the importance of explicit formalisation and computational rigour.},
	booktitle = {Proceedings of the 24th {Conference} on {Computational} {Natural} {Language} {Learning}},
	publisher = {Association for Computational Linguistics},
	author = {Arkel, Jacqueline van and Woensdregt, Marieke and Dingemanse, Mark and Blokpoel, Mark},
	month = nov,
	year = {2020},
	pages = {177--194},
}

@article{bocklisch_rasa_2017,
	title = {Rasa: {Open} source language understanding and dialogue management},
	shorttitle = {Rasa},
	doi = {10.48550/arXiv.1712.05181},
	journal = {arXiv:1712.05181 [cs.CL]},
	author = {Bocklisch, Tom and Faulkner, Joey and Pawlowski, Nick and Nichol, Alan},
	year = {2017},
}

@article{schlangen_language_2019,
	title = {Language {Tasks} and {Language} {Games}: {On} {Methodology} in {Current} {Natural} {Language} {Processing} {Research}},
	shorttitle = {Language {Tasks} and {Language} {Games}},
	url = {http://arxiv.org/abs/1908.10747},
	abstract = {"This paper introduces a new task and a new dataset", "we improve the state of the art in X by Y" -- it is rare to find a current natural language processing paper (or AI paper more generally) that does not contain such statements. What is mostly left implicit, however, is the assumption that this necessarily constitutes progress, and what it constitutes progress towards. Here, we make more precise the normally impressionistically used notions of language task and language game and ask how a research programme built on these might make progress towards the goal of modelling general language competence.},
	urldate = {2022-03-14},
	journal = {arXiv:1908.10747 [cs]},
	author = {Schlangen, David},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.10747},
}

@article{pouw_multilevel_2021,
	title = {Multilevel rhythms in multimodal communication},
	volume = {376},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2020.0334},
	doi = {10.1098/rstb.2020.0334},
	abstract = {It is now widely accepted that the brunt of animal communication is conducted via several modalities, e.g. acoustic and visual, either simultaneously or sequentially. This is a laudable multimodal turn relative to traditional accounts of temporal aspects of animal communication which have focused on a single modality at a time. However, the fields that are currently contributing to the study of multimodal communication are highly varied, and still largely disconnected given their sole focus on a particular level of description or their particular concern with human or non-human animals. Here, we provide an integrative overview of converging findings that show how multimodal processes occurring at neural, bodily, as well as social interactional levels each contribute uniquely to the complex rhythms that characterize communication in human and non-human animals. Though we address findings for each of these levels independently, we conclude that the most important challenge in this field is to identify how processes at these different levels connect.

This article is part of the theme issue ‘Synchrony and rhythm interaction: from the brain to behavioural ecology’.},
	number = {1835},
	urldate = {2021-11-15},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Pouw, Wim and Proksch, Shannon and Drijvers, Linda and Gamba, Marco and Holler, Judith and Kello, Christopher and Schaefer, Rebecca S. and Wiggins, Geraint A.},
	month = oct,
	year = {2021},
	note = {Publisher: Royal Society},
	pages = {20200334},
}

@inproceedings{skantze_towards_2017,
	address = {Saarbrücken, Germany},
	title = {Towards a {General}, {Continuous} {Model} of {Turn}-taking in {Spoken} {Dialogue} using {LSTM} {Recurrent} {Neural} {Networks}},
	url = {http://aclweb.org/anthology/W17-5527},
	doi = {10.18653/v1/W17-5527},
	abstract = {Previous models of turn-taking have mostly been trained for specific turn-taking decisions, such as discriminating between turn shifts and turn retention in pauses. In this paper, we present a predictive, continuous model of turntaking using Long Short-Term Memory (LSTM) Recurrent Neural Networks (RNN). The model is trained on human-human dialogue data to predict upcoming speech activity in a future time window. We show how this general model can be applied to two different tasks that it was not specifically trained for. First, to predict whether a turn-shift will occur or not in pauses, where the model achieves a better performance than human observers, and better than results achieved with more traditional models. Second, to make a prediction at speech onset whether the utterance will be a short backchannel or a longer utterance. Finally, we show how the hidden layer in the network can be used as a feature vector for turntaking decisions in a human-robot interaction scenario.},
	language = {en},
	urldate = {2022-03-14},
	booktitle = {Proceedings of the 18th {Annual} {SIGdial} {Meeting} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Skantze, Gabriel},
	year = {2017},
	pages = {220--230},
}

@inproceedings{ekstedt_turngpt_2020,
	address = {Online},
	title = {{TurnGPT}: a {Transformer}-based {Language} {Model} for {Predicting} {Turn}-taking in {Spoken} {Dialog}},
	shorttitle = {{TurnGPT}},
	url = {https://aclanthology.org/2020.findings-emnlp.268},
	doi = {10.18653/v1/2020.findings-emnlp.268},
	abstract = {Syntactic and pragmatic completeness is known to be important for turn-taking prediction, but so far machine learning models of turn-taking have used such linguistic information in a limited way. In this paper, we introduce TurnGPT, a transformer-based language model for predicting turn-shifts in spoken dialog. The model has been trained and evaluated on a variety of written and spoken dialog datasets. We show that the model outperforms two baselines used in prior work. We also report on an ablation study, as well as attention and gradient analyses, which show that the model is able to utilize the dialog context and pragmatic completeness for turn-taking prediction. Finally, we explore the model's potential in not only detecting, but also projecting, turn-completions.},
	urldate = {2022-03-14},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2020},
	publisher = {Association for Computational Linguistics},
	author = {Ekstedt, Erik and Skantze, Gabriel},
	month = nov,
	year = {2020},
	pages = {2981--2990},
}

@article{schlangen_general_2011,
	title = {A {General}, {Abstract} {Model} of {Incremental} {Dialogue} {Processing}},
	volume = {2},
	copyright = {Copyright (c) 2011},
	issn = {2152-9620},
	url = {https://journals.uic.edu/ojs/index.php/dad/article/view/10712},
	doi = {10.5087/dad.2011.105},
	abstract = {We present a general model and conceptual framework for specifying architectures for incremental processing in dialogue systems, in particular with respect to the topology of the network of modules that make up the system, the way information flows through this network, how information increments are ‘packaged’, and how these increments are processed by the modules. This model enables the precise specification of incremental systems and hence facilitates detailed comparisons between systems, as well as giving guidance on designing new systems. In particular, the model can serve as a framework for specifying module communication in such systems, as we illustrate with some examples.},
	language = {en},
	number = {1},
	urldate = {2022-03-14},
	journal = {Dialogue \& Discourse},
	author = {Schlangen, David and Skantze, Gabriel},
	month = may,
	year = {2011},
	note = {Number: 1},
	pages = {83--111},
}

@article{ginzburg_incrementality_2018,
	title = {Incrementality and {Clarification}/{Sluicing} potential},
	volume = {21},
	copyright = {Copyright (c) 2019 Jonathan Ginzburg, Robin Cooper, Julian Hough, David Schlangen},
	issn = {2629-6055},
	url = {https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/149},
	abstract = {Incremental processing at least as fine grained as word-by-word has long been accepted as a basic feature of human processing of speech (see e.g., Schlesewsky and Bornkessel (2004)) and as an important feature for design of spoken dialogue systems (see e.g., Schlangen and Skantze (2009); Hough et al. (2015)). Nonetheless, with a few important exceptions (see e.g., Kempson et al. (2016)), incrementality is viewed as an aspect of performance, not semantic meaning. Moreover, it seems to entail giving up on compositionality as a constraining principle on denotations. In this paper, we point to a variety of dialogical phenomena whose analysis incontrovertibly requires a semantics formulated in incremental terms. These include cases, above all with sluicing, that call into question existing assumptions about ellipsis resolution and argue for incremental updating of QUD. The incremental semantic framework we sketch improves on existing such accounts (reviewed in Peldszus and Schlangen (2012); Hough et al. (2015)) on both denotational and contextual fronts: the contents we posit are in fact tightly constrained by a methodological principle more restrictive than traditional compositionality, namely the Reprise Content Hypothesis (Purver and Ginzburg (2004); Ginzburg and Purver (2012); Cooper (2013a)), embedded within independently motivated dialogue states (Ginzburg (2012)).},
	language = {en},
	number = {1},
	urldate = {2022-03-14},
	journal = {Proceedings of Sinn und Bedeutung},
	author = {Ginzburg, Jonathan and Cooper, Robin and Hough, Julian and Schlangen, David},
	year = {2018},
	note = {Number: 1},
	pages = {463--480},
}

@inproceedings{schlangen_speaking_2007,
	title = {Speaking through a noisy channel-experiments on inducing clarification behaviour in human-human dialogue},
	booktitle = {Eighth {Annual} {Conference} of the {International} {Speech} {Communication} {Association}},
	author = {Schlangen, David and Fernández, Raquel},
	year = {2007},
}

@inproceedings{kousidis_exploring_2015,
	address = {Enschede, Netherlands},
	title = {Exploring the {Body} and {Head} {Kinematics} of {Laughter}, {Filled} {Pauses} and {Breaths}},
	language = {English},
	booktitle = {Proceedings of {The} 4th {Interdisciplinary} {Workshop} on {Laughter} and {Other} {Non}-verbal {Vocalisations} in {Speech}},
	author = {Kousidis, Spyridon and Hough, Julian and Schlangen, David},
	year = {2015},
	pages = {23--25},
}

@article{ginzburg_disfluencies_2014,
	title = {Disfluencies as intra-utterance dialogue moves},
	volume = {7},
	issn = {1937-8912},
	url = {http://semprag.org/article/view/sp.7.9},
	doi = {10.3765/sp.7.9},
	urldate = {2015-04-20},
	journal = {Semantics and Pragmatics},
	author = {Ginzburg, Jonathan and Fernández, Raquel and Schlangen, David},
	month = jun,
	year = {2014},
}

@article{schlangen_reaction_2006,
	title = {From {Reaction} to {Prediction}: {Experiments} with {Computational} {Models} of {Turn}-{Taking}},
	abstract = {Deciding when to take (or not to take) the turn in a conversation is an important task. It has been stressed in the descriptive literature that such decisions must involve prediction, as they often seem to be made before a transition place has been reached. In computational systems, however, turn-taking is normally a reaction to parameters like pause length. In this paper, we report on experiments that try to bridge this gap. We describe an experiment (using controlled stimuli) that shows human performance at prediction of turn-taking decisions and then show that a model automatically induced from data can reach a similar level of performance. We then describe a series of experiments on spontaneous dialogue data where we combine pause thresholds with syntactic and prosodic information to make turn-taking decisions, successively reducing the pause threshold until reaction becomes prediction. All our classiﬁers improve signiﬁcantly over the baselines; prediction however is shown to be the hardest task, and we discuss additional information sources that could improve it.},
	language = {en},
	author = {Schlangen, David},
	year = {2006},
	pages = {4},
}

@inproceedings{bus_modelling_2010,
	title = {Modelling sub-utterance phenomena in spoken dialogue systems},
	booktitle = {Proceedings of the 14th {International} {Workshop} on the {Semantics} and {Pragmatics} of {Dialogue} ({Pozdial} 2010)},
	author = {Buß, Okko and Schlangen, David},
	year = {2010},
}

@article{de_ruiter_projecting_2006,
	title = {Projecting the end of a {Speaker}'s {Turn}: {A} {Cognitive} {Cornerstone} of {Conversation}},
	volume = {82},
	issn = {00978507},
	shorttitle = {Projecting the end of a {Speaker}'s {Turn}},
	url = {http://www.jstor.org/stable/4490203},
	abstract = {A key mechanism in the organization of turns at talk in conversation is the ability to anticipate or PROJECT the moment of completion of a current speaker's turn. Some authors suggest that this is achieved via lexicosyntactic cues, while others argue that projection is based on intonational contours. We tested these hypotheses in an on-line experiment, manipulating the presence of symbolic (lexicosyntactic) content and intonational contour of utterances recorded in natural conversations. When hearing the original recordings, subjects can anticipate turn endings with the same degree of accuracy attested in real conversation. With intonational contour entirely removed (leaving intact words and syntax, with a completely flat pitch), there is no change in subjects' accuracy of end-of-turn projection. But in the opposite case (with original intonational contour intact, but with no recognizable words), subjects' performance deteriorates significantly. These results establish that the symbolic (i.e. lexicosyntactic) content of an utterance is necessary (and possibly sufficient) for projecting the moment of its completion, and thus for regulating conversational turn-taking. By contrast, and perhaps surprisingly, intona contour is neither necessary nor sufficient for end-of-turn projection.},
	number = {3},
	urldate = {2010-07-07},
	journal = {Language},
	author = {de Ruiter, J. P. and Mitterer, Holger and Enfield, N. J.},
	month = sep,
	year = {2006},
	note = {ArticleType: primary\_article / Full publication date: Sep., 2006 / Copyright © 2006 Linguistic Society of America},
	pages = {515--535},
}

@book{illich_tools_1973,
	address = {New York},
	title = {Tools for conviviality},
	isbn = {978-0-7145-0973-0},
	publisher = {Harper \& Row},
	author = {Illich, Ivan},
	year = {1973},
}

@article{goodwin_processes_1980,
	title = {Processes of {Mutual} {Monitoring} {Implicated} in the {Production} of {Description} {Sequences}},
	volume = {50},
	url = {http://dx.doi.org/10.1111/j.1475-682X.1980.tb00024.x},
	doi = {10.1111/j.1475-682X.1980.tb00024.x},
	number = {3-4},
	urldate = {2009-05-27},
	journal = {Sociological Inquiry},
	author = {Goodwin, Marjorie H.},
	year = {1980},
	pages = {303--317},
}

@article{goodwin_participation_2007,
	title = {Participation, stance and affect in the organization of activities},
	volume = {18},
	url = {http://das.sagepub.com/content/18/1/53.abstract},
	doi = {10.1177/0957926507069457},
	abstract = {The organization of embodied participation frameworks, stance and affect is                 investigated using as data a sequence in which a father is helping his daughter do                 homework. Through the way in which they position their bodies toward both each other                 and the homework sheet that is the focus of their work the two contest the                 interactive and cognitive organization of the activity they are pursuing together.                 The father insisted that their work be organized in a way that would allow him to                 demonstrate the practices required to solve her problems. However the daughter                 refused to rearrange her body to organize the participation framework that would                 make this possible, and demanded instead that Father tell her the answers. When the                 daughter consistently refused to cooperate Father eventually walked out, but                 returned later, and they constructed a very different affective and cognitive                 alignment. Such phenomena shed light on range of different kinds of epistemic, moral                 and affective stances that are central to both the organization of cognition and                 action, and to how participants constitute themselves as particular kinds of social                 and moral actors in the midst of the mundane activities that constitute daily family life.},
	number = {1},
	urldate = {2011-09-08},
	journal = {Discourse \& Society},
	author = {Goodwin, Charles},
	month = jan,
	year = {2007},
	pages = {53 --73},
}

@incollection{atkinson_notes_1984,
	address = {Cambridge [Cambridgeshire]},
	series = {Studies in emotion and social interaction},
	title = {Notes on story structure and the organization of participation},
	isbn = {0-521-24815-9},
	booktitle = {Structures of {Social} {Action}: {Studies} in {Conversation} {Analysis}},
	publisher = {Cambridge University Press},
	author = {Goodwin, Charles},
	editor = {Atkinson, J. Maxwell and Heritage, John},
	year = {1984},
	pages = {225--246},
}

@article{goodwin_concurrent_1987,
	title = {Concurrent operations on talk: {Notes} on the interactive organization of assessments},
	volume = {1},
	shorttitle = {Concurrent operations on talk},
	number = {1},
	journal = {IPrA Papers in Pragmatics},
	author = {Goodwin, Charles and Goodwin, Marjorie H.},
	year = {1987},
	pages = {1--54},
}

@incollection{de_fina_narrative_2015,
	address = {Chichester, West Sussex ; Malden, MA},
	title = {Narrative as {Talk}-in-{Interaction}},
	isbn = {978-1-118-45815-0},
	booktitle = {The handbook of narrative analysis},
	publisher = {John Wiley \& Sons Inc},
	author = {Goodwin, Charles},
	editor = {De Fina, Anna and Georgakopoulou, Alexandra},
	year = {2015},
	pages = {197--218},
}

@article{goodwin_action_2000,
	title = {Action and embodiment within situated human interaction},
	volume = {32},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/B6VCW-416JW6B-4/2/76569ade66a4e1b39bc371604a3fa9c0},
	doi = {10.1016/S0378-2166(99)00096-X},
	abstract = {A theory of action must come to terms with both the details of language use and the way in which the social, cultural, material and sequential structure of the environment where action occurs figure into its organization. In this paper it will be suggested that a primordial site for the analysis of human language, cognition, and action consists of a situation in which multiple participants are attempting to carry out courses of action in concert with each other through talk while attending to both the larger activities that their current actions are ambedded within, and relevant phenomena in their surround. Using as data video recordings of young girls playing hopscotch and archaeologists classifying color, it will be argued that human action is built throught the simultaneous deployment of a range of quite different kinds of semiotic resources. Talk itself contains multiple sign systems with alternative properties. Strips of talk gain their power as social action via their placement within larger sequential structures, encompassing activities, and participation frameworks constituted through displays of mutual orientation made by the actors' bodies. The body is used in a quite different way to perform gesture, again a class of phenomena that encompasses structurally different types of sign systems. Both talk and gesture can index, construe or treat as irrelevant, entities in the participants' surround. Moreover, material structure in the surround, such as graphic fields of various types, can provide semiotic structure without which the constitution of particular kinds of action being invoked through talk would be impossible. In brief it will be argued that the construction of action through talk within situated interaction is accomplished through the temporally unfolding juxtaposition of quite different kinds of semiotic resources, and that moreover through this process the human body is made publicly visible as the site for a range of structurally different kinds of displays implicated in the constitution of the actions of the moment.},
	number = {10},
	urldate = {2009-05-27},
	journal = {Journal of Pragmatics},
	author = {Goodwin, Charles},
	month = sep,
	year = {2000},
	pages = {1489--1522},
}

@incollection{goodwin_negotiation_1995,
	address = {Amsterdam / Philadelphia},
	title = {The negotiation of coherence within conversation},
	booktitle = {Coherence in spontaneous text},
	publisher = {John Benjamins},
	author = {Goodwin, Charles},
	editor = {Gernsbacher, Morton Ann and Givón, Talmy},
	year = {1995},
	pages = {117--137},
}

@article{goodwin_restarts_1980,
	title = {Restarts, {Pauses}, and the {Achievement} of a {State} of {Mutual} {Gaze} at {Turn}-{Beginning}},
	volume = {50},
	issn = {0038-0245},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1475-682X.1980.tb00023.x/abstract},
	doi = {10.1111/j.1475-682X.1980.tb00023.x},
	number = {3-4},
	urldate = {2010-09-28},
	journal = {Sociological Inquiry},
	author = {Goodwin, Charles},
	month = jul,
	year = {1980},
	pages = {272--302},
}

@article{seifart_extent_2021,
	title = {The extent and degree of utterance-final word lengthening in spontaneous speech from 10 languages},
	volume = {7},
	issn = {2199-174X},
	doi = {10.1515/lingvan-2019-0063},
	abstract = {Words in utterance-final positions are often pronounced more slowly than utterance-medial words, as previous studies on individual languages have shown. This paper provides a systematic cross-linguistic comparison of relative durations of final and penultimate words in utterances in terms of the degree to which such words are lengthened. The study uses time-aligned corpora from 10 genealogically, areally, and culturally diverse languages, including eight small, under-resourced, and mostly endangered languages, as well as English and Dutch. Clear effects of lengthening words at the end of utterances are found in all 10 languages, but the degrees of lengthening vary. Languages also differ in the relative durations of words that precede utterance-final words. In languages with on average short words in terms of number of segments, these penultimate words are also lengthened. This suggests that lengthening extends backwards beyond the final word in these languages, but not in languages with on average longer words. Such typological patterns highlight the importance of examining prosodic phenomena in diverse language samples beyond the small set of majority languages most commonly investigated so far.},
	language = {en},
	number = {1},
	journal = {Linguistics Vanguard},
	author = {Seifart, Frank and Strunk, Jan and Danielsen, Swintha and Hartmann, Iren and Pakendorf, Brigitte and Wichmann, Søren and Witzlack-Makarevich, Alena and Himmelmann, Nikolaus P. and Bickel, Balthasar},
	month = jan,
	year = {2021},
}

@article{seifart_nouns_2018,
	title = {Nouns slow down speech across structurally and culturally diverse languages},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/115/22/5720},
	doi = {10.1073/pnas.1800708115},
	abstract = {By force of nature, every bit of spoken language is produced at a particular speed. However, this speed is not constant—speakers regularly speed up and slow down. Variation in speech rate is influenced by a complex combination of factors, including the frequency and predictability of words, their information status, and their position within an utterance. Here, we use speech rate as an index of word-planning effort and focus on the time window during which speakers prepare the production of words from the two major lexical classes, nouns and verbs. We show that, when naturalistic speech is sampled from languages all over the world, there is a robust cross-linguistic tendency for slower speech before nouns compared with verbs, both in terms of slower articulation and more pauses. We attribute this slowdown effect to the increased amount of planning that nouns require compared with verbs. Unlike verbs, nouns can typically only be used when they represent new or unexpected information; otherwise, they have to be replaced by pronouns or be omitted. These conditions on noun use appear to outweigh potential advantages stemming from differences in internal complexity between nouns and verbs. Our findings suggest that, beneath the staggering diversity of grammatical structures and cultural settings, there are robust universals of language processing that are intimately tied to how speakers manage referential information when they communicate with one another.},
	language = {en},
	number = {22},
	urldate = {2021-12-05},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Seifart, Frank and Strunk, Jan and Danielsen, Swintha and Hartmann, Iren and Pakendorf, Brigitte and Wichmann, Søren and Witzlack-Makarevich, Alena and Jong, Nivja H. de and Bickel, Balthasar},
	month = may,
	year = {2018},
	pages = {5720--5725},
}

@article{levshina_corpus-based_2021,
	title = {Corpus-based typology: applications, challenges and some solutions},
	issn = {1613-415X},
	doi = {10.1515/lingty-2020-0118},
	abstract = {Over the last few years, the number of corpora that can be used for language comparison has dramatically increased. The corpora are so diverse in their structure, size and annotation style, that a novice might not know where to start. The present paper charts this new and changing territory, providing a few landmarks, warning signs and safe paths. Although no corpus at present can replace the traditional type of typological data based on language description in reference grammars, corpora can help with diverse tasks, being particularly well suited for investigating probabilistic and gradient properties of languages and for discovering and interpreting cross-linguistic generalizations based on processing and communicative mechanisms. At the same time, the use of corpora for typological purposes has not only advantages and opportunities, but also numerous challenges. This paper also contains an empirical case study addressing two pertinent problems: the role of text types in language comparison and the problem of the word as a comparative concept.},
	language = {en},
	urldate = {2021-04-06},
	journal = {Linguistic Typology},
	author = {Levshina, Natalia},
	month = mar,
	year = {2021},
}

@misc{kopf_overview_2021,
	title = {Overview of {Datasets} for the {Sign} {Languages} of {Europe}},
	url = {https://www.fdr.uni-hamburg.de/record/9561},
	abstract = {EASIER project deliverable D6.1 This document identifies linguistic corpora that can be explored as high-quality training data for automatic translation within EASIER (as opposed to loosely aligned broadcast data). For each data set, the document lists what parts of the data are available under what access conditions. It also lists the elicitation formats used in several corpora in order to identify those parts of the available corpora that could be explored to build multilingual resources. In order to support the construction of an interlingual index across European sign languages, the document also lists lexical resources (lexical databases and dictionaries) available and their characteristics.},
	language = {en},
	urldate = {2021-08-10},
	author = {Kopf, Maria and Schulder, Marc and Hanke, Thomas},
	month = jul,
	year = {2021},
	note = {doi:10.25592/uhhfdm.9561},
}

@misc{widlokCollectionAkhoeHai2007,
	type = {Archive},
	title = {Collection "╪{Akhoe} {Hai}{\textbar}{\textbar}om"},
	url = {https://hdl.handle.net/1839/b1796725-1a49-48ee-93ea-75e5b440c7bc},
	journal = {DOBES},
	author = {Widlok, Thomas and Rapold, Christian and Hoymann, Gertie},
	year = {2007},
}

@article{bender_data_2018,
	title = {Data {Statements} for {Natural} {Language} {Processing}: {Toward} {Mitigating} {System} {Bias} and {Enabling} {Better} {Science}},
	volume = {6},
	issn = {2307-387X},
	shorttitle = {Data {Statements} for {Natural} {Language} {Processing}},
	url = {https://doi.org/10.1162/tacl_a_00041},
	doi = {10.1162/tacl_a_00041},
	abstract = {In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development. Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations. We present a form that data statements can take and explore the implications of adopting them as part of regular practice. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.},
	urldate = {2022-03-14},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Bender, Emily M. and Friedman, Batya},
	month = dec,
	year = {2018},
	pages = {587--604},
}

@inproceedings{hovy_social_2016,
	address = {Berlin, Germany},
	title = {The {Social} {Impact} of {Natural} {Language} {Processing}},
	url = {https://aclanthology.org/P16-2096},
	doi = {10.18653/v1/P16-2096},
	urldate = {2022-03-14},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hovy, Dirk and Spruit, Shannon L.},
	month = aug,
	year = {2016},
	pages = {591--598},
}

@inproceedings{ruane_conversational_2019,
	address = {Galway, Ireland},
	title = {Conversational {AI}: {Social} and {Ethical} {Considerations}},
	abstract = {Conversational Agents are becoming ubiquitous in our daily lives. They are used in various areas including customer service, education, medicine, and entertainment. As tools that are increasingly permeating various social domains, Conversational Agents can have a direct impact on individual’s lives and on social discourse in general. Consequently, critical evaluation of this impact is imperative. In this paper, we highlight some emerging ethical issues and suggest ways for agent designers, developers, and owners to approach them with the goal of responsible development of Conversational Agents.},
	language = {en},
	booktitle = {Proceedings for the 27th {AIAI} {Irish} {Conference} on {Artificial} {Intelligence} and {Cognitive} {Science}},
	author = {Ruane, Elayne and Birhane, Abeba and Ventresque, Anthony},
	year = {2019},
	pages = {104--115},
}

@article{johnston_symmetry_2022,
	title = {Symmetry and simplicity spontaneously emerge from the algorithmic nature of evolution},
	volume = {119},
	url = {https://www.pnas.org/doi/10.1073/pnas.2113883119},
	doi = {10.1073/pnas.2113883119},
	number = {11},
	urldate = {2022-03-14},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Johnston, Iain G. and Dingle, Kamaludin and Greenbury, Sam F. and Camargo, Chico Q. and Doye, Jonathan P. K. and Ahnert, Sebastian E. and Louis, Ard A.},
	month = mar,
	year = {2022},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2113883119},
}

@inproceedings{bevacqua_multimodal_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Multimodal {Backchannels} for {Embodied} {Conversational} {Agents}},
	isbn = {978-3-642-15892-6},
	doi = {10.1007/978-3-642-15892-6_21},
	abstract = {One of the most desirable characteristics of an Embodied Conversational Agent (ECA) is the capability of interacting with users in a human-like manner. While listening to a user, an ECA should be able to provide backchannel signals through visual and acoustic modalities. In this work we propose an improvement of our previous system to generate multimodal backchannel signals on visual and acoustic modalities. A perceptual study has been performed to understand how context-free multimodal backchannels are interpreted by users.},
	language = {en},
	booktitle = {Intelligent {Virtual} {Agents}},
	publisher = {Springer},
	author = {Bevacqua, Elisabetta and Pammi, Sathish and Hyniewska, Sylwia Julia and Schröder, Marc and Pelachaud, Catherine},
	editor = {Allbeck, Jan and Badler, Norman and Bickmore, Timothy and Pelachaud, Catherine and Safonova, Alla},
	year = {2010},
	pages = {194--200},
}

@inproceedings{cassell_coordination_2007,
	address = {Prague, Czech Republic},
	title = {Coordination in {Conversation} and {Rapport}},
	url = {https://aclanthology.org/W07-1906},
	urldate = {2022-03-14},
	booktitle = {Proceedings of the {Workshop} on {Embodied} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Cassell, Justine and Gill, Alastair and Tepper, Paul},
	month = jun,
	year = {2007},
	pages = {41--50},
}

@article{steinle_entering_1997,
	title = {Entering {New} {Fields}: {Exploratory} {Uses} of {Experimentation}},
	volume = {64},
	issn = {0031-8248},
	shorttitle = {Entering {New} {Fields}},
	url = {https://www.jstor.org/stable/188390},
	abstract = {Starting with some illustrative examples, I develop a systematic account of a specific type of experimentation--an experimentation which is not, as in the "standard view", driven by specific theories. It is typically practiced in periods in which no theory or--even more fundamentally--no conceptual framework is readily available. I call it exploratory experimentation and I explicate its systematic guidelines. From the historical examples I argue furthermore that exploratory experimentation may have an immense, but hitherto widely neglected, epistemic significance.},
	urldate = {2022-03-14},
	journal = {Philosophy of Science},
	author = {Steinle, Friedrich},
	year = {1997},
	note = {Publisher: [The University of Chicago Press, Philosophy of Science Association]},
	pages = {S65--S74},
}

@article{montero-melis_no_2022,
	title = {No evidence for embodiment: {The} motor system is not needed to keep action verbs in working memory},
	issn = {0010-9452},
	shorttitle = {No evidence for embodiment},
	url = {https://www.sciencedirect.com/science/article/pii/S0010945222000594},
	doi = {10.1016/j.cortex.2022.02.006},
	abstract = {Increasing evidence implicates the sensorimotor systems with high-level cognition, but the extent to which these systems play a functional role remains debated. Using an elegant design, Shebani and Pulvermüller (2013) reported that carrying out a demanding rhythmic task with the hands led to selective impairment of working memory for hand-related words (e.g., clap), while carrying out the same task with the feet led to selective memory impairment for foot-related words (e.g., kick). Such a striking double dissociation is acknowledged even by critics to constitute strong evidence for an embodied account of working memory. Here, we report on an attempt at a direct replication of this important finding. We followed a sequential sampling design and stopped data collection at N=77 (more than five times the original sample size), at which point the evidence for the lack of the critical selective interference effect was very strong (BF01 = 91). This finding constitutes strong evidence against a functional contribution of the motor system to keeping action verbs in working memory. Our finding fits into the larger emerging picture in the field of embodied cognition that sensorimotor simulations are neither required nor automatic in high-level cognitive processes, but that they may play a role depending on the task. Importantly, we invite researchers to engage in transparent, high-powered, and fully pre-registered experiments like the present one to ensure the field advances on a solid basis.},
	language = {en},
	urldate = {2022-03-14},
	journal = {Cortex},
	author = {Montero-Melis, Guillermo and van Paridon, Jeroen and Ostarek, Markus and Bylund, Emanuel},
	month = mar,
	year = {2022},
}

@article{thoppilan_lamda_2022,
	title = {{LaMDA}: {Language} {Models} for {Dialog} {Applications}},
	shorttitle = {{LaMDA}},
	url = {http://arxiv.org/abs/2201.08239},
	abstract = {We present LaMDA: Language Models for Dialog Applications. LaMDA is a family of Transformer-based neural language models specialized for dialog, which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text. While model scaling alone can improve quality, it shows less improvements on safety and factual grounding. We demonstrate that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding. The first challenge, safety, involves ensuring that the model's responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. We quantify safety using a metric based on an illustrative set of human values, and we find that filtering candidate responses using a LaMDA classifier fine-tuned with a small amount of crowdworker-annotated data offers a promising approach to improving model safety. The second challenge, factual grounding, involves enabling the model to consult external knowledge sources, such as an information retrieval system, a language translator, and a calculator. We quantify factuality using a groundedness metric, and we find that our approach enables the model to generate responses grounded in known sources, rather than responses that merely sound plausible. Finally, we explore the use of LaMDA in the domains of education and content recommendations, and analyze their helpfulness and role consistency.},
	urldate = {2022-03-14},
	journal = {arXiv:2201.08239 [cs]},
	author = {Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and Li, YaGuang and Lee, Hongrae and Zheng, Huaixiu Steven and Ghafouri, Amin and Menegali, Marcelo and Huang, Yanping and Krikun, Maxim and Lepikhin, Dmitry and Qin, James and Chen, Dehao and Xu, Yuanzhong and Chen, Zhifeng and Roberts, Adam and Bosma, Maarten and Zhao, Vincent and Zhou, Yanqi and Chang, Chung-Ching and Krivokon, Igor and Rusch, Will and Pickett, Marc and Srinivasan, Pranesh and Man, Laichee and Meier-Hellstern, Kathleen and Morris, Meredith Ringel and Doshi, Tulsee and Santos, Renelito Delos and Duke, Toju and Soraker, Johnny and Zevenbergen, Ben and Prabhakaran, Vinodkumar and Diaz, Mark and Hutchinson, Ben and Olson, Kristen and Molina, Alejandra and Hoffman-John, Erin and Lee, Josh and Aroyo, Lora and Rajakumar, Ravi and Butryna, Alena and Lamm, Matthew and Kuzmina, Viktoriya and Fenton, Joe and Cohen, Aaron and Bernstein, Rachel and Kurzweil, Ray and Aguera-Arcas, Blaise and Cui, Claire and Croak, Marian and Chi, Ed and Le, Quoc},
	month = feb,
	year = {2022},
	note = {arXiv: 2201.08239},
}

@article{dinan_anticipating_2021,
	title = {Anticipating {Safety} {Issues} in {E2E} {Conversational} {AI}: {Framework} and {Tooling}},
	shorttitle = {Anticipating {Safety} {Issues} in {E2E} {Conversational} {AI}},
	url = {http://arxiv.org/abs/2107.03451},
	abstract = {Over the last several years, end-to-end neural conversational agents have vastly improved in their ability to carry a chit-chat conversation with humans. However, these models are often trained on large datasets from the internet, and as a result, may learn undesirable behaviors from this data, such as toxic or otherwise harmful language. Researchers must thus wrestle with the issue of how and when to release these models. In this paper, we survey the problem landscape for safety for end-to-end conversational AI and discuss recent and related work. We highlight tensions between values, potential positive impact and potential harms, and provide a framework for making decisions about whether and how to release these models, following the tenets of value-sensitive design. We additionally provide a suite of tools to enable researchers to make better-informed decisions about training and releasing end-to-end conversational AI models.},
	urldate = {2022-03-14},
	journal = {arXiv:2107.03451 [cs]},
	author = {Dinan, Emily and Abercrombie, Gavin and Bergman, A. Stevie and Spruit, Shannon and Hovy, Dirk and Boureau, Y.-Lan and Rieser, Verena},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.03451},
}

@article{simon_what_1992,
	title = {What is an “{Explanation}” of {Behavior}?},
	volume = {3},
	issn = {0956-7976},
	url = {https://doi.org/10.1111/j.1467-9280.1992.tb00017.x},
	doi = {10.1111/j.1467-9280.1992.tb00017.x},
	abstract = {The cognitive “revolution” in psychology introduced a new concept of explanation and somewhat novel methods of gathering and interpreting evidence. These innovations assume that it is essential to explain complex phenomena at several levels, symbolic as well as physiological; complementary, not competitive. As with the other sciences, such complementarity makes possible a comprehensive and unified experimental psychology. Contemporary cognitive psychology also introduced complementarity of another kind, drawing upon, and drawing together, both the behaviorist and the Gestalt traditions.},
	language = {en},
	number = {3},
	urldate = {2022-03-14},
	journal = {Psychological Science},
	author = {Simon, Herbert A.},
	month = may,
	year = {1992},
	note = {Publisher: SAGE Publications Inc},
	pages = {150--161},
}

@inproceedings{shalyminov_multi-task_2018,
	title = {Multi-{Task} {Learning} for {Domain}-{General} {Spoken} {Disfluency} {Detection} in {Dialogue} {Systems}},
	url = {http://semdial.org/anthology/papers/Z/Z18/Z18-3008/},
	doi = {10.48550/arXiv.1810.03352},
	language = {en-us},
	urldate = {2022-03-14},
	author = {Shalyminov, Igor and Eshghi, Arash and Lemon, Oliver},
	month = nov,
	year = {2018},
}

@article{rieser_learning_2011,
	title = {Learning and {Evaluation} of {Dialogue} {Strategies} for {New} {Applications}: {Empirical} {Methods} for {Optimization} from {Small} {Data} {Sets}},
	volume = {37},
	issn = {0891-2017},
	shorttitle = {Learning and {Evaluation} of {Dialogue} {Strategies} for {New} {Applications}},
	url = {https://doi.org/10.1162/coli_a_00038},
	doi = {10.1162/coli_a_00038},
	abstract = {We present a new data-driven methodology for simulation-based dialogue strategy learning, which allows us to address several problems in the field of automatic optimization of dialogue strategies: learning effective dialogue strategies when no initial data or system exists, and determining a data-driven reward function. In addition, we evaluate the result with real users, and explore how results transfer between simulated and real interactions. We use Reinforcement Learning (RL) to learn multimodal dialogue strategies by interaction with a simulated environment which is “bootstrapped” from small amounts of Wizard-of-Oz (WOZ) data. This use of WOZ data allows data-driven development of optimal strategies for domains where no working prototype is available. Using simulation-based RL allows us to find optimal policies which are not (necessarily) present in the original data. Our results show that simulation-based RL significantly outperforms the average (human wizard) strategy as learned from the data by using Supervised Learning. The bootstrapped RL-based policy gains on average 50 times more reward when tested in simulation, and almost 18 times more reward when interacting with real users. Users also subjectively rate the RL-based policy on average 10\% higher. We also show that results from simulated interaction do transfer to interaction with real users, and we explicitly evaluate the stability of the data-driven reward function.},
	number = {1},
	urldate = {2022-03-14},
	journal = {Computational Linguistics},
	author = {Rieser, Verena and Lemon, Oliver},
	month = mar,
	year = {2011},
	pages = {153--196},
}

@inproceedings{papaioannou_human-robot_2018,
	title = {Human-{Robot} {Interaction} {Requires} {More} {Than} {Slot} {Filling} - {Multi}-{Threaded} {Dialogue} for {Collaborative} {Tasks} and {Social} {Conversation}},
	url = {https://www.isca-speech.org/archive/ai-mhri_2018/papaioannou18_ai-mhri.html},
	doi = {10.21437/AI-MHRI.2018-15},
	language = {en},
	urldate = {2022-03-14},
	booktitle = {{FAIM}/{ISCA} {Workshop} on {Artificial} {Intelligence} for {Multimodal} {Human} {Robot} {Interaction}},
	publisher = {ISCA},
	author = {Papaioannou, Ioannis and Dondrup, Christian and Lemon, Oliver},
	month = jul,
	year = {2018},
	pages = {61--64},
}

@book{zipf_human_1949,
	address = {Cambridge, MA},
	title = {Human behavior and the principle of least effort; an introduction to human ecology},
	publisher = {Addison-Wesley Press},
	author = {Zipf, George K.},
	year = {1949},
}

@article{si_florafauna_2019,
	title = {Flora–{Fauna} {Loanwords} in {Arnhem} {Land} and {Beyond}—{An} {Ethnobiological} {Approach}},
	volume = {39},
	issn = {0726-8602},
	url = {https://doi.org/10.1080/07268602.2019.1566888},
	doi = {10.1080/07268602.2019.1566888},
	abstract = {Borrowing is said to be a pervasive phenomenon among Australian languages, particularly in the domains of flora–fauna and material culture. In-depth studies of borrowing in individual languages or small groups of languages exist, as do quantitative analyses covering selected vocabulary items across a large number of languages. To date, however, there have not been any comprehensive surveys of the flora–fauna inventories of several languages at once with the aim of investigating broad semantic and geographic patterns of borrowing. This study attempts to carry out such an investigation on the languages of Arnhem Land, within the broader context of northern Australian languages. A thorough investigation of the flora–fauna lexica of 21 languages revealed a number of loanword ‘corridors’ within which borrowing frequently occurred; the principal corridors were two coastal corridors along the northern and eastern coasts of Arnhem Land, and an inland–coastal corridor between Non-Pama-Nyungan languages and Yolŋu languages. Several words, mostly bird names, were identified as being repeatedly borrowed (Wanderwörter), and in much larger numbers than previously reported. Finally, several correspondences, presumably long-distance loans, were detected in languages as far away as the Kimberleys, Queensland and north-central Australia.},
	number = {2},
	urldate = {2022-03-14},
	journal = {Australian Journal of Linguistics},
	author = {Si, Aung},
	month = apr,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/07268602.2019.1566888},
	pages = {202--256},
}

@article{floyd_conversation_2021,
	title = {Conversation and {Culture}},
	volume = {50},
	url = {https://doi.org/10.1146/annurev-anthro-101819-110158},
	doi = {10.1146/annurev-anthro-101819-110158},
	abstract = {Conversation analysis is a method for the systematic study of interaction in terms of a sequential turn-taking system. Research in conversation analysis has traditionally focused on speakers of English, and it is still unclear to what extent the system observed in that research applies to conversation more generally around the world. However, as this method is now being applied to conversation in a broader range of languages, it is increasingly possible to address questions about the nature of interactional diversity across different speech communities. The approach of pragmatic typology first applies sequential analysis to conversation from different speech communities and then compares interactional patterns in ways analogous to how traditional linguistic typology compares morphosyntax. This article discusses contemporary literature in pragmatic typology, including single-language studies and multilanguage comparisons reflecting both qualitative and quantitative methods. This research finds that microanalysis of face-to-face interaction can identify both universal trends and culture-specific interactional tendencies. Expected final online publication date for the Annual Review of Anthropology, Volume 50 is October 2021. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
	number = {1},
	urldate = {2021-07-13},
	journal = {Annual Review of Anthropology},
	author = {Floyd, Simeon},
	year = {2021},
	note = {\_eprint: https://doi.org/10.1146/annurev-anthro-101819-110158},
	pages = {219--240},
}

@misc{fadlulKerinciSungaiPenuh2016,
	type = {Archive},
	title = {Kerinci ({Sungai} {Penuh}) {Database}},
	url = {https://hdl.handle.net/1839/00-0000-0000-0022-654E-D},
	journal = {DOBES},
	author = {Fadlul, Rekinan and Mckinnon, Timothy and Gil, David and Taylor, Bradley},
	year = {2016},
}

@book{eggins_analysing_2004,
	title = {Analysing {Casual} {Conversation}},
	isbn = {978-1-84553-046-4},
	abstract = {Analysing Casual Conversation, first published in 1997 by Cassell, develops a systematic model for the analysis and description of casual conversation in English. Working through authentic examples of casual conversations involving participants differing in age, gender, ethnicity and socio-economic class, the authors argue that despite its sometimes aimless appearance and apparently unstructured content, casual conversation is a highly structured activity and plays a critical role in the social construction of reality. Drawing on insights from sociology, linguistics and critical semiotics, the book equips readers with the analytic skills to describe the layers of structure and critical interpretive frameworks to explain the 'social work' that goes on through chat. Suzanne Eggins is Senior Lecturer in the School of English, University of New South Wales, Sydney Diana Slade is Professor of Applied Linguistics in the Faculty of Education at the University of Technology, Sydney.},
	language = {en},
	publisher = {Equinox Publishing Ltd.},
	author = {Eggins, Suzanne and Slade, Diana},
	year = {2004},
}

@misc{schackowDocumentationGrammaticalDescription2014,
	type = {Archive},
	title = {Documentation and grammatical description of {Yakkha}, {Nepal}},
	url = {http://hdl.handle.net/2196/00-0000-0000-0002-D744-B},
	journal = {Endangered Languages Archive},
	author = {Schackow, Diana},
	year = {2014},
}

@misc{wilburPiteSaamiDocumenting2009,
	type = {Archive},
	title = {Pite {Saami}: documenting the language and culture},
	url = {http://hdl.handle.net/2196/00-0000-0000-0003-1170-E},
	journal = {DOBES},
	author = {Wilbur, Joshua},
	year = {2009},
}

@misc{liDocumentationZauzouEndangered2017,
	type = {Archive},
	title = {Documentation of {Zauzou}, an endangered language in {China}},
	url = {http://hdl.handle.net/2196/00-0000-0000-0010-8822-7},
	journal = {Endangered Languages Archive},
	author = {Li, Yu},
	year = {2017},
}

@article{francisStandardCorpusEdited1965,
	title = {A standard corpus of edited present-day {American} {English}},
	volume = {26},
	number = {4},
	journal = {College English},
	author = {Francis, W. Nelson},
	year = {1965},
	note = {Publisher: JSTOR},
	pages = {267--273},
}

@misc{dingemanseCollectionSiwu2012,
	type = {Archive},
	title = {Collection {Siwu}},
	url = {https://hdl.handle.net/1839/c410de17-81eb-4477-ae0d-d43ff1aea085},
	journal = {DOBES},
	author = {Dingemanse, Mark and Kanairoh, Ordime},
	year = {2012},
}

@article{frommherzCrowdsourcingEcologicallyValidDialogue2021,
	title = {Crowdsourcing {Ecologically}-{Valid} {Dialogue} {Data} for {German}},
	volume = {3},
	issn = {2624-9898},
	url = {https://www.frontiersin.org/article/10.3389/fcomp.2021.686050},
	abstract = {Despite their increasing success, user interactions with smart speech assistants (SAs) are still very limited compared to human-human dialogue. One way to make SA interactions more natural is to train the underlying natural language processing modules on data which reflects how humans would talk to a SA if it was capable of understanding and producing natural dialogue given a specific task. Such data can be collected applying a Wizard-of-Oz approach (WOz), where user and system side are played by humans. WOz allows researchers to simulate human-machine interaction while benefitting from the fact that all participants are human and thus dialogue-competent. More recent approaches have leveraged simple templates specifying a dialogue scenario for crowdsourcing large-scale datasets. Template-based collection efforts, however, come at the cost of data diversity and naturalness. We present a method to crowdsource dialogue data for the SA domain in the WOz framework, which aims at limiting researcher-induced bias in the data while still allowing for a low-resource, scalable data collection. Our method can also be applied to languages other than English (in our case German), for which fewer crowd-workers may be available. We collected data asynchronously, relying only on existing functionalities of Amazon Mechanical Turk, by formulating the task as a dialogue continuation task. Coherence in dialogues is ensured, as crowd-workers always read the dialogue history, and as a unifying scenario is provided for each dialogue. In order to limit bias in the data, rather than using template-based scenarios, we handcrafted situated scenarios which aimed at not pre-script-ing the task into every single detail and not priming the participants’ lexical choices. Our scenarios cued people’s knowledge of common situations and entities relevant for our task, without directly mentioning them, but relying on vague language and circumlocutions. We compare our data (which we publish as the CROWDSS corpus; n = 113 dialogues) with data from MultiWOZ, showing that our scenario approach led to considerably less scripting and priming and thus more ecologically-valid dialogue data. This suggests that small investments in the collection setup can go a long way in improving data quality, even in a low-resource setup.},
	urldate = {2022-01-27},
	journal = {Frontiers in Computer Science},
	author = {Frommherz, Yannick and Zarcone, Alessandra},
	year = {2021},
}

@article{schulderDataStatementPublic2021,
	title = {Data {Statement} for the {Public} {DGS} {Corpus}},
	url = {https://www.fdr.uni-hamburg.de/record/9700},
	doi = {10.25592/uhhfdm.9700},
	abstract = {Project note for work package 06 "Korpusveröffentlichung / Corpus Publishing" produced in the DGS-Korpus project. This data statement of the Public DGS Corpus provides information relevant to judging the nature of the language content of the corpus. It covers how the corpus was curated, specifies the language varieties it covers, and provides demographic information for participants and annotators. It also describes the technical and sociological conditions under which the language data was recorded as well as its topical characteristics. The data statement provides a general overview, supported by references to a variety of publications that cover individual topics in more detail.},
	language = {en},
	urldate = {2021-11-29},
	author = {Schulder, Marc and Blanck, Dolly and Hanke, Thomas and Hofmann, Ilona and Hong, Sung-Eun and Jeziorski, Olga and König, Lutz and König, Susanne and Konrad, Reiner and Langer, Gabriele and Nishio, Rie and Rathmann, Christian},
	month = nov,
	year = {2021},
}

@article{loveSpokenBNC2014Designing2017,
	title = {The {Spoken} {BNC2014}: {Designing} and building a spoken corpus of everyday conversations},
	volume = {22},
	issn = {1384-6655, 1569-9811},
	shorttitle = {The {Spoken} {BNC2014}},
	url = {http://www.jbe-platform.com/content/journals/10.1075/ijcl.22.3.02lov},
	doi = {10.1075/ijcl.22.3.02lov},
	abstract = {Abstract
            This paper introduces the Spoken British National Corpus 2014, an 11.5-million-word corpus of orthographically transcribed conversations among L1 speakers of British English from across the UK, recorded in the years 2012–2016. After showing that a survey of the recent history of corpora of spoken British English justifies the compilation of this new corpus, we describe the main stages of the Spoken BNC2014’s creation: design, data and metadata collection, transcription, XML encoding, and annotation. In doing so we aim to (i) encourage users of the corpus to approach the data with sensitivity to the many methodological issues we identified and attempted to overcome while compiling the Spoken BNC2014, and (ii) inform (future) compilers of spoken corpora of the innovations we implemented to attempt to make the construction of corpora representing spontaneous speech in informal contexts more tractable, both logistically and practically, than in the past.},
	language = {en},
	number = {3},
	urldate = {2021-11-12},
	journal = {International Journal of Corpus Linguistics},
	author = {Love, Robbie and Dembry, Claire and Hardie, Andrew and Brezina, Vaclav and McEnery, Tony},
	month = nov,
	year = {2017},
	pages = {319--344},
}

@misc{appenptyltdGulfArabicConversational2006,
	title = {Gulf {Arabic} {Conversational} {Telephone} {Speech}},
	url = {https://catalog.ldc.upenn.edu/LDC2006S43},
	doi = {10.35111/NSVG-DD69},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater} {\textless}p{\textgreater} This database contains 975 Gulf Arabic speakers taking part in spontaneous telephone conversations in Colloquial Gulf Arabic. A total of 976 conversation sides are provided (one speaker appears on two distinct calls). The average duration per side is about 5.7 minutes.{\textless}/p{\textgreater} {\textless}p{\textgreater}This corpus was collected and transcribed in 2004 by Appen Pty Ltd (Appen), Sydney, Australia.{\textless}/p{\textgreater} {\textless}h3{\textgreater}Data{\textless}/h3{\textgreater} {\textless}p{\textgreater}The single-channel files represent just one side of a normal conversation. The "devtest" set represents a relatively balanced (representative) sample drawn from the total pool of collected calls, based on a test-set selection process applied by the National Institute of Standards and Technology (NIST) and based on demographic, phone and audit information as provided by Appen.{\textless}/p{\textgreater} {\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater} {\textless}p{\textgreater} For an example of the data contained in this corpus, please listen to this {\textless}a href="./desc/addenda/LDC2006S43.wav" rel="nofollow"{\textgreater}audio sample(wav){\textless}/a{\textgreater}. {\textless}/p{\textgreater} {\textless}/br{\textgreater} 
Portions © 2006 Trustees of the University of Pennsylvania},
	urldate = {2022-03-10},
	publisher = {Linguistic Data Consortium},
	author = {Appen Pty Ltd and Sydney and Australia},
	month = sep,
	year = {2006},
	note = {Artwork Size: 2936012 KB
Pages: 2936012 KB},
}

@misc{canavanalexandraCALLHOMEEgyptianArabic1997,
	title = {{CALLHOME} {Egyptian} {Arabic} {Speech}},
	url = {https://catalog.ldc.upenn.edu/LDC97S45},
	doi = {10.35111/D8YB-9M13},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The {\textless}a href="../../../Catalog/docs/LDC97T19/index.html" rel="nofollow"{\textgreater}CALLHOME Egyptian Arabic{\textless}/a{\textgreater} corpus of telephone speech consists of 120 unscripted telephone conversations between native speakers of Egyptian Colloquial Arabic (ECA), the spoken variety of Arabic found in Egypt. The dialect of ECA that this dictionary represents is Cairene Arabic.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}All calls, which lasted up to 30 minutes, originated in North America and were placed to locations overseas (typically Egypt). Most participants called family members or close friends.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}This corpus contains speech data files ONLY, along with the minimal amount of documentation needed to describe the contents and format of the speech files and the software packages needed to uncompress the speech data. The transcripts and documentation ({\textless}a href="http://catalog.ldc.upenn.edu/LDC97T19" rel="nofollow"{\textgreater}LDC97T19{\textless}/a{\textgreater}) are available separately, as is an associated lexicon ({\textless}a href="http://catalog.ldc.upenn.edu/LDC99L22" rel="nofollow"{\textgreater}LDC99L22{\textless}/a{\textgreater}).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please listen to this {\textless}a href="desc/addenda/LDC97S45.sph"{\textgreater}speech sample{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The "shorten" and "sphere" directories have been removed.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The sphere directory contained NIST "SPeech HEader REsources" (SPHERE): C-language source code libraries and utilities for manipulating NIST SPHERE-format waveform files.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The shorten directory contained files for Tony Robinson's "shorten" software for speech compression.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}A more recent version of the SPHERE utilities is now available on the {\textless}a href="http://www.nist.gov/speech/tools/index.htm" rel="nofollow"{\textgreater}NIST web site{\textless}/a{\textgreater}; additional utilities for converting from SPHERE to other waveform file formats is also available at the {\textless}a href="http://www.ldc.upenn.edu/Using/" rel="nofollow"{\textgreater}LDC web site.{\textless}/a{\textgreater}{\textless}/p{\textgreater}{\textless}/br{\textgreater} 
Portions © 1996-1997 Trustees of the University of Pennsylvania},
	urldate = {2022-03-10},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George and Graff, David},
	year = {1997},
	note = {Artwork Size: 1807744 KB
Pages: 1807744 KB},
}

@misc{appenptyltdLevantineArabicConversational2007,
	title = {Levantine {Arabic} {Conversational} {Telephone} {Speech}},
	url = {https://catalog.ldc.upenn.edu/LDC2007S01},
	doi = {10.35111/77ZM-GW29},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater} {\textless}p{\textgreater}This database contains 982 Levantine Arabic speakers taking part in spontaneous telephone conversations in Colloquial Levantine Arabic. A total of 985 conversation sides are provided (there are three speakers who each appear in two disctinct conversations). The average duration per side is between 5 and 6 minutes.{\textless}/p{\textgreater} {\textless}p{\textgreater}This corpus was collected and transcribed in 2004 by Appen Pty Ltd, Sydney, Australia.{\textless}/p{\textgreater} {\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater} {\textless}p{\textgreater}For an example of the data into this corpus, please listen to this {\textless}a href="./desc/addenda/LDC2007S01.wav" rel="nofollow"{\textgreater}audio sample{\textless}/a{\textgreater} (wav format). {\textless}/p{\textgreater} {\textless}/br{\textgreater} 
Portions © 2007 Trustees of the University of Pennsylvania},
	urldate = {2022-03-10},
	publisher = {Linguistic Data Consortium},
	author = {Appen Pty Ltd and Sydney and Australia},
	month = jan,
	year = {2007},
	note = {Artwork Size: 2831155 KB
Pages: 2831155 KB},
}

@misc{canavanalexandraCALLHOMEAmericanEnglish1997,
	title = {{CALLHOME} {American} {English} {Speech}},
	url = {https://catalog.ldc.upenn.edu/LDC97S42},
	doi = {10.35111/EXQ3-X930},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}CALLHOME American English Speech was developed by the Linguistic Data Consortium (LDC) and consists of 120 unscripted 30-minute telephone conversations between native speakers of English.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}All calls originated in North America; 90 of the 120 calls were placed to various locations outisde of North America, while the remaining 30 calls were made within North America. Most participants called family members or close friends.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}This corpus contains speech data files with documentation describing their contents and format along with the software packages needed to uncompress the speech data. Corresponding transcripts and documentation ({\textless}a href="http://catalog.ldc.upenn.edu/LDC97T14" rel="nofollow"{\textgreater}LDC97T14{\textless}/a{\textgreater}) are available separately, as is an associated lexicon ({\textless}a href="http://catalog.ldc.upenn.edu/LDC97L20" rel="nofollow"{\textgreater}LDC97L20{\textless}/a{\textgreater}).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please listen to this {\textless}a href="desc/addenda/LDC97S42.sph"{\textgreater}audio sample{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The "shorten" and "sphere" directories have been removed.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The sphere directory contained NIST "SPeech HEader REsources" (SPHERE): C-language source code libraries and utilities for manipulating NIST SPHERE-format waveform files.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The shorten directory contained files for the "shorten" software for speech compression.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}A more recent version of SPHERE utilities is available on the {\textless}a href="http://nist.gov/itl/iad/mig/tools.cfm" rel="nofollow"{\textgreater}NIST web site{\textless}/a{\textgreater}; additional utilities for converting SPHERE files are also available from {\textless}a href="https://www.ldc.upenn.edu/language-resources/tools/sphere-conversion-tools" rel="nofollow"{\textgreater}LDC's web site.{\textless}/a{\textgreater}{\textless}/p{\textgreater}{\textless}/br{\textgreater} 
Portions © 1997 Trustees of the University of Pennsylvania},
	urldate = {2022-03-08},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Graff, David and Zipperlen, George},
	year = {1997},
	note = {Artwork Size: 1830160 KB
Pages: 1830160 KB},
}

@misc{canavanalexandraCALLFRIENDAmericanEnglishNonSouthern1996,
	title = {{CALLFRIEND} {American} {English}-{Non}-{Southern} {Dialect}},
	url = {https://catalog.ldc.upenn.edu/LDC96S46},
	doi = {10.35111/D37S-C536},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The {\textless}a href="../../../Catalog/docs/LDC96S46/index.html" rel="nofollow"{\textgreater}CALLFRIEND{\textless}/a{\textgreater} project supports the development of language identification technology.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The corpus consists of 60 unscripted telephone conversations, lasting between 5-30 minutes. The corpus also includes documentation describing speaker information (sex, age, education, callee telephone number) and call information (channel quality, number of speakers).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}For each conversation, both the caller and callee are native speakers of non-Southern dialects of American English. All calls are domestic and were placed inside the continental United States, Canada, Puerto Rico, or the Dominican Republic.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Callers in the "non-Southern" (or "general") collection of CALLFRIEND American English appear to come from a wide geographic range, based on their own reports of where they were raised (some identified their origins as being in the southeastern U.S.). Regardless of their geographic or ethnic backgrounds, the feature they share is the clear absence of a vowel quality pattern that would distinguish them as speakers of a "Southern" dialect.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Some information was inadvertently left out of the speaker information table and the call information table. Copies of these files are available here at {\textless}a href="desc/addenda/LDC1996S46\_C.txt" rel="nofollow"{\textgreater}CALLINFO.TBL{\textless}/a{\textgreater} and {\textless}a href="desc/addenda/LDC1996S46\_S.txt" rel="nofollow"{\textgreater}SPKRINFO.TBL{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please listen to this {\textless}a href="desc/addenda/LDC96S46.sph"{\textgreater}audio sample{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}There are no updates at this time.{\textless}/p{\textgreater}{\textless}/br{\textgreater}},
	urldate = {2022-03-08},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George},
	year = {1996},
	note = {Artwork Size: 1508304 KB
Pages: 1508304 KB},
}

@misc{mollernwadigoDocumentationProjectBaa2016,
	type = {Archive},
	title = {A documentation project of {Baa}, a language of {Nigeria}},
	url = {http://hdl.handle.net/2196/e050a2cd-f61d-435e-824e-93d24877bbaa},
	journal = {Endangered Languages Archive},
	author = {Möller Nwadigo, Mirjam},
	year = {2016},
}

@misc{arnoldDocumentationAmbelAustronesian2017,
	type = {Archive},
	title = {The documentation of {Ambel}, an {Austronesian} language of {Eastern} {Indonesia}},
	url = {http://hdl.handle.net/2196/00-0000-0000-000C-E849-2},
	journal = {Endangered Languages Archive},
	author = {Arnold, Laura},
	year = {2017},
}

@misc{legereCollectionAkie2019,
	type = {Archive},
	title = {Collection {Akie}},
	url = {https://hdl.handle.net/1839/b17d3caf-83e6-4ee9-8d1a-f9e4f8179971},
	journal = {DOBES},
	author = {Legère, Karsten and König, Christa and Heine, Bernd and Micheli, Ilaria},
	year = {2019},
}

@misc{kimMultimodalDocumentationJejuan2018,
	type = {Archive},
	title = {A multi-modal documentation of {Jejuan} conversations},
	url = {http://hdl.handle.net/2196/00-0000-0000-000E-D15C-1},
	journal = {Endangered Languages Archive},
	author = {Kim, Soung-U.},
	year = {2018},
}

@misc{ozerovCommunitydrivenDocumentationNatural2018,
	title = {A community-driven documentation of natural discourse in {Anal}, an endangered {Tibeto}-{Burman} language.},
	url = {http://hdl.handle.net/2196/af2415d6-dc75-4330-ba5d-7b8122e50982},
	journal = {Endangered Languages Archive},
	author = {Ozerov, Pavel},
	year = {2018},
}

@misc{dasilvaProjetoNormaUrbana1996,
	type = {Corpus},
	title = {Projeto da {Norma} {Urbana} {Linguística} {Culta}},
	url = {https://fale.ufal.br/projeto/nurcdigital/},
	journal = {Linha D'Água},
	author = {da Silva, Luiz Antônio},
	year = {1996},
}

@misc{gilDocumentationBesemahMalayic2015,
	type = {Archive},
	title = {A documentation of {Besemah}, {Malayic} {Languages} of {Sumatra}. {A} joint project of the {Department} of {Linguistics}, {Max} {Planck} {Institute} for {Evolutionary} {Anthropology} and {Universitas} {Bung} {Hatta}, {Padang}},
	url = {https://hdl.handle.net/1839/00-0000-0000-0022-6B59-B},
	journal = {DOBES},
	author = {Gil, David},
	year = {2015},
}

@article{kuvackraljevicCroatianAdultSpoken2016,
	title = {Croatian adult spoken language corpus ({HrAL})},
	volume = {28},
	number = {2},
	journal = {FLUMINENSIA: Časopis za filološka istraživanja},
	author = {Kuvač Kraljević, Jelena and Hržica, Gordana},
	year = {2016},
	note = {Publisher: Odsjek za kroatistiku Filozofskoga fakulteta Sveučilišta u Rijeci},
	pages = {87--102},
}

@misc{tanoDocumentationDescriptionSign2013,
	type = {Archive},
	title = {Documentation and description of a sign language in {Côte} d’{Ivoire}},
	url = {http://hdl.handle.net/2196/6357f1b9-8c02-4277-870b-6736b5611434},
	journal = {DOBES},
	author = {Tano, Angoua},
	year = {2013},
}

@misc{houDocumentingChatinoSign2018,
	type = {Archive},
	title = {Documenting {Chatino} {Sign} {Language}},
	url = {http://hdl.handle.net/2196/cf110665-3694-4e74-a8f8-79e105d89b50},
	journal = {DOBES},
	author = {Hou, Lynn and Mesh, Kate},
	year = {2018},
}

@article{garridoGlissandoCorpusMultidisciplinary2013,
	title = {Glissando: a corpus for multidisciplinary prosodic studies in {Spanish} and {Catalan}},
	volume = {47},
	number = {4},
	journal = {Language resources and evaluation},
	author = {Garrido, Juan María and Escudero, David and Aguilar, Lourdes and Cardeñoso, Valentín and Rodero, Emma and De-La-Mota, Carme and González, César and Vivaracho, Carlos and Rustullet, Sílvia and Larrea, Olatz and {others}},
	year = {2013},
	note = {Publisher: Springer},
	pages = {945--971},
}

@misc{pasamonikCabecarCollectionXTYP2011,
	type = {Archive},
	title = {"{Cabécar}" in collection "{XTYP} {Lab}"},
	url = {https://hdl.handle.net/1839/00-0000-0000-0021-E375-1},
	journal = {DOBES},
	author = {Pasamonik, Carolina},
	year = {2011},
}

@inproceedings{vansonIFADVCorpusFree2008,
	title = {The {IFADV} corpus: {A} free dialog video corpus},
	booktitle = {Proceedings of the {Sixth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'08)},
	author = {van Son, Rob and Wesseling, Wieneke and Sanders, Eric and van den Heuvel, Henk},
	year = {2008},
}

@misc{wagnerSamtaleBankDanishSpoken2017,
	type = {Archive},
	title = {{SamtaleBank}, {Danish} spoken language component of the {DK}/{CLARIN} project},
	url = {https://samtalebank.talkbank.org/},
	journal = {Talkbank},
	author = {Wagner, Johannes and Maegaard, Bente},
	year = {2017},
}

@misc{taalunieCorpusGesprokenNederlands2014,
	type = {Archive},
	title = {Corpus {Gesproken} {Nederlands} - {CGN} ({Version} 2.0.3)},
	url = {http://hdl.handle.net/10032/tm-a2-d9},
	journal = {Vlaamse en Nederlandse regering en NWO},
	author = {Taalunie},
	year = {2014},
}

@misc{canavanalexandraCALLFRIENDFarsiSecond2014,
	title = {{CALLFRIEND} {Farsi} {Second} {Edition} {Speech}},
	url = {https://catalog.ldc.upenn.edu/LDC2014S01},
	doi = {10.35111/ENJK-8F86},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}CALLFRIEND Farsi Second Edition Speech was developed by the Linguistic Data Consortium (LDC) and consists of approximately 42 hours of telephone conversation (100 recordings) among native Farsi speakers. The calls were recorded in 1995 and 1996 as part of the CALLFRIEND collection, a project designed primarily to support research in automatic language identification. One hundred native Farsi speakers living in the continental United States each made a single telephone call, lasting up to 30 minutes, to a family member or friend living in the United States.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}This release represents all calls from the collection. LDC released recordings from 60 calls without transcripts in 1996 as CALLFRIEND Farsi ({\textless}a href="http://catalog.ldc.upenn.edu/LDC96S50" rel="nofollow"{\textgreater}LDC96S50{\textless}/a{\textgreater}) after 20 of those calls were used as evaluation data in the first {\textless}a href="http://www.itl.nist.gov/iad/mig/tests/lre/1996/" rel="nofollow"{\textgreater}NIST Language Recognition Evaluation{\textless}/a{\textgreater} (LRE).\&nbsp;Seven\&nbsp;of these original 60 calls were deemed unsuitable for transcription and, thus 53 of the original CF Farsi files are included along with 47 new files.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Corresponding transcripts are available in CALLFRIEND Farsi Second Edition Speech Transcripts ({\textless}a href="http://catalog.ldc.upenn.edu/LDC2014T01" rel="nofollow"{\textgreater}LDC2014T01{\textless}/a{\textgreater}).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}All recordings involved domestic calls routed through the automated telephone collection platform at LDC and were stored as 2-channel (4-wire), 8-KHz mu-law samples taken directly from the public telephone network via a T-1 circuit. Each audio file is a {\textless}a href="https://xiph.org/flac/" rel="nofollow"{\textgreater}FLAC{\textless}/a{\textgreater}-compressed MS-WAV (RIFF) format audio file containing 2-channel, 8-KHz, 16-bit PCM sample data.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}This release includes speaker information, including gender, the number of speakers on each channel and call duration.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please listen to this {\textless}a href="desc/addenda/LDC2014S01.wav" rel="nofollow"{\textgreater}audio sample{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}None at this time.{\textless}/p{\textgreater}{\textless}/br{\textgreater} 
Portions © 1995-1996, 2014 Trustees of the University of Pennsylvania},
	urldate = {2022-03-10},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George and Graff, David},
	month = jan,
	year = {2014},
	note = {Artwork Size: 1914713 KB
Pages: 1914713 KB},
}

@misc{duboisSantaBarbaraCorpus2000,
	title = {Santa {Barbara} {Corpus} of {Spoken} {American} {English} {Part} {I}},
	url = {https://catalog.ldc.upenn.edu/LDC2000S85},
	doi = {10.35111/S2Q7-GQ73},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The Santa Barbara Corpus of Spoken American English is based on hundreds of recordings of natural speech from all over the United States, representing a wide variety of people of different regional origins, ages, occupations, and ethnic and social backgrounds. It reflects many ways that people use language in their lives: conversation, gossip, arguments, on-the-job talk, card games, city council meetings, sales pitches, classroom lectures, political speeches, bedtime stories, sermons, weddings, and more.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Part I contains 14 speech files of between 15-30 minutes each, from the Santa Barbara Corpus of Spoken American English. Collected by: University of California, Santa Barbara Center for the Study of Discourse, Director John W. Du Bois (UCSB), Associate Editors: Wallace L. Chafe (UCSB), Charlese Meyer (UMass, Boston), and Sandra A. Thompson (UCSB). The Santa Barbara Corpus of Spoken American English is part of the International Corpus of English (Charles W. Meyer, Director), representing the American Component.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Each speech file is accompanied by a transcript in which phrases are time stamped with respect to the audio recording. Personal names, place names, phone numbers, etc., in the transcripts have been altered to preserve the anonymity of the speakers and their acquaintances and the audio files have been filtered to make these portions of the recordings unrecognizable.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}For an example of the data in this corpus, please examine these samples of the recordings and transcripts:{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}ul{\textgreater}{\textless}br{\textgreater} 
{\textless}li{\textgreater}{\textless}a href="desc/addenda/LDC2000S85.wav" rel="nofollow"{\textgreater}Speech {\textless}/a{\textgreater}{\textless}/li{\textgreater}{\textless}br{\textgreater} 
{\textless}li{\textgreater}{\textless}a href="desc/addenda/LDC2000S85.trn" rel="nofollow"{\textgreater}Transcripts{\textless}/a{\textgreater}{\textless}/li{\textgreater}{\textless}br{\textgreater} 
{\textless}/ul{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}There are no updates at this time.{\textless}/p{\textgreater}{\textless}/br{\textgreater}},
	urldate = {2022-03-10},
	publisher = {Linguistic Data Consortium},
	author = {Du Bois, John W. and Chafe, Wallace L. and Meyer, Charles and Thompson, Sandra},
	month = jan,
	year = {2000},
	note = {Artwork Size: 1677721 KB
Pages: 1677721 KB},
}

@misc{canavanalexandraCALLHOMEGermanSpeech1997,
	title = {{CALLHOME} {German} {Speech}},
	url = {https://catalog.ldc.upenn.edu/LDC97S43},
	doi = {10.35111/0GKE-FP69},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}CALLHOME German Speech was developed by the Linguistic Data Consortium and consists of conversational telephone speech between native speakers of German.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}This corpus contains speech files from 100 unscripted telephone conversations and related documentation.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}All calls originated in North America and were placed to locations outside North America (typically Europe). Most speakers called family members or close friends.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}LDC has also released CALLHOME German Transcripts ({\textless}a href="http://catalog.ldc.upenn.edu/LDC97T15" rel="nofollow"{\textgreater}LDC97T15{\textless}/a{\textgreater}), which consists of transcriptions of portions of the speech in this release and CALLHOME German Lexicon ({\textless}a href="http://catalog.ldc.upenn.edu/LDC97L18" rel="nofollow"{\textgreater}LDC97L18{\textless}/a{\textgreater}), which contains words from CALLHOME German Transcripts.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please view this {\textless}a href="desc/addenda/LDC97S43.sph"{\textgreater}audio sample{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}There are no updates at this time.{\textless}/p{\textgreater}{\textless}/br{\textgreater} 
Portions © 1997 Trustees of the University of Pennsylvania},
	urldate = {2022-03-10},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Graff, David and Zipperlen, George},
	year = {1997},
}

@misc{canavanalexandraCALLFRIENDCanadianFrench1996,
	title = {{CALLFRIEND} {Canadian} {French}},
	url = {https://catalog.ldc.upenn.edu/LDC96S48},
	doi = {10.35111/91PJ-X181},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater} {\textless}p{\textgreater}The {\textless}a href="/Catalog/docs/LDC96S48/index.html" rel="nofollow"{\textgreater}CALLFRIEND{\textless}/a{\textgreater} project supports the development of language identification technology. {\textless}/p{\textgreater}{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater} {\textless}p{\textgreater}The corpus consists of 60 unscripted telephone conversations, lasting between 5-30 minutes. The corpus also includes documentation describing speaker information (sex, age, education, callee telephone number) and call information (channel quality, number of speakers). {\textless}/p{\textgreater}{\textless}p{\textgreater}For each conversation, both the caller and callee are native Canadian speakers of French. All calls are domestic and were placed inside the continental United States and Canada. {\textless}/p{\textgreater}{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater} There are no updates at this time. {\textless}/br{\textgreater}},
	urldate = {2022-03-10},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George},
	year = {1996},
	note = {Artwork Size: 1677721 KB
Pages: 1677721 KB},
}

@misc{canavanalexandraCALLFRIENDAmericanEnglishSouthern1996,
	title = {{CALLFRIEND} {American} {English}-{Southern} {Dialect}},
	url = {https://catalog.ldc.upenn.edu/LDC96S47},
	doi = {10.35111/A8VF-6K58},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}CALLFRIEND American English-Southern Dialect was developed by the Linguistic Data Consortium as part of the CALLFRIEND project, which supported the development of language identification technology.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}CALLFRIEND American English-Southern Dialect consists of 60 unscripted telephone conversations, lasting between 5-30 minutes. The corpus also includes documentation describing speaker information (sex, age, education, callee telephone number) and call information (channel quality, number of speakers).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}For each conversation, both the caller and callee were native speakers of Southern American English. All calls were placed inside the continental United States, Canada, Puerto Rico or the Dominican Republic.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Callers in the "Southern" collection of CALLFRIEND American English were identified primarily on the basis of vowel quality patterns that are common among native speakers raised in the southeastern United States (from Texas eastward to the Atlantic coast and from Virginia and Kentucky southward to the Gulf of Mexico). {\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please listen to this {\textless}a href="desc/addenda/LDC96S47.sph"{\textgreater}audio sample{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}There are no updates at this time.{\textless}/p{\textgreater}{\textless}/br{\textgreater}},
	urldate = {2022-03-10},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George},
	year = {1996},
	note = {Artwork Size: 1465848 KB
Pages: 1465848 KB},
}

@misc{nealCABankEnglishSCoSE2002,
	type = {Archive},
	title = {{CABank} {English} {SCoSE} {Corpus} ({Saarbrücken} {Corpus} of {Spoken} {English})},
	url = {https://ca.talkbank.org/access/SCoSE.html},
	journal = {Talkbank},
	author = {Neal, Norrick},
	year = {2002},
}

@incollection{haughCollaborativeCreationSpoken2013,
	address = {Honolulu},
	title = {Collaborative creation of spoken language corpora},
	booktitle = {Pragmatics and {Language} {Learning}},
	publisher = {National Foreign Language Resource Center, University of Hawai’i},
	author = {Haugh, Michael and Chang, Wei-Lin Melody},
	year = {2013},
	pages = {133--159},
}

@misc{albertCABNCJeffersonianTranscription2015,
	type = {Archive},
	title = {{CABNC}: the {Jeffersonian} transcription of the {Spoken} {British} {National} {Corpus}},
	url = {https://ca.talkbank.org/access/CABNC.html},
	journal = {Talkbank},
	author = {Albert, Saul and de Ruiter, Laura E. and de Ruiter, J.P.},
	year = {2015},
}

@misc{zwitserloodCorpusNGT2009,
	type = {Archive},
	title = {Corpus {NGT}},
	url = {https://hdl.handle.net/1839/00-0000-0000-0009-06F8-6},
	journal = {DOBES},
	author = {Zwitserlood, Inge and Crasborn, Onno and Ros, Johan and van Kampen, Annemieke},
	year = {2009},
}

@incollection{reinekeArchivFurGesprochenes2022,
	title = {Das {Archiv} für {Gesprochenes} {Deutsch} und das {Forschungs}-und {Lehrkorpus} für {Gesprochenes} {Deutsch}},
	booktitle = {Sprache in {Politik} und {Gesellschaft}},
	publisher = {de Gruyter},
	author = {Reineke, Silke and Schmidt, Thomas},
	year = {2022},
	pages = {323--330},
}

@misc{meurantCorpusLSFBFirst2015,
	title = {Corpus {LSFB}. {First} digital open access corpus of movies and annotations of {French} {Belgian} {Sign} {Language} ({LSFB}).},
	url = {http://www.corpus-lsfb.be},
	publisher = {LSFB-Lab, University of Namur},
	author = {Meurant, Laurence},
	year = {2015},
}

@article{torreiraNijmegenCorpusCasual2010,
	title = {The {Nijmegen} {Corpus} of {Casual} {French}},
	volume = {52},
	issn = {01676393},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167639309001629},
	doi = {10.1016/j.specom.2009.10.004},
	language = {en},
	number = {3},
	urldate = {2022-03-10},
	journal = {Speech Communication},
	author = {Torreira, Francisco and Adda-Decker, Martine and Ernestus, Mirjam},
	month = mar,
	year = {2010},
	pages = {201--212},
}

@misc{asatianiGeorgianCollectionXTYP2012,
	type = {Archive},
	title = {"{Georgian}" in collection "{XTYP} {Lab}"},
	url = {https://hdl.handle.net/1839/00-0000-0000-0021-4DA3-5},
	journal = {DOBES},
	author = {Asatiani, Rusudan and Ries, Veronika},
	year = {2012},
}

@misc{mondadaCLAPICorpusLAngue2008,
	type = {Archive},
	title = {{CLAPI} {Corpus} de {LAngue} {Parlée} en {Interaction}},
	url = {http://clapi.ish-lyon.cnrs.fr/V3_Accueil.php},
	author = {Mondada, Lorenza},
	year = {2008},
}

@misc{gbegnonviFongbeCollectionXTYP2011,
	type = {Archive},
	title = {"{Fongbe}" in collection "{XTYP} {Lab}"},
	url = {https://hdl.handle.net/1839/00-0000-0000-0021-E91D-0},
	journal = {DOBES},
	author = {Gbegnonvi, Larissa},
	year = {2011},
}

@misc{canavanalexandraCALLHOMEJapaneseSpeech1996,
	title = {{CALLHOME} {Japanese} {Speech}},
	url = {https://catalog.ldc.upenn.edu/LDC96S37},
	doi = {10.35111/8MMJ-T983},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The CALLHOME Japanese corpus of telephone speech consists of 120 unscripted telephone conversations between native speakers of Japanese.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}All calls, which lasted up to 30 minutes, originated in North America and were placed to locations overseas (typically Japan). Most participants called family members or close friends.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}This corpus contains speech data files ONLY, along with the minimal amount of documentation needed to describe the contents and format of the speech files and the software packages needed to uncompress the speech data. The transcripts and documentation ({\textless}a href="http://catalog.ldc.upenn.edu/LDC96T18" rel="nofollow"{\textgreater}LDC96T18{\textless}/a{\textgreater}) are available separately, as is an associated lexicon and transducer ({\textless}a href="http://catalog.ldc.upenn.edu/LDC96L17" rel="nofollow"{\textgreater}LDC96L17{\textless}/a{\textgreater}).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please view this {\textless}a href="desc/addenda/LDC96S37.sph"{\textgreater}sample{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}There are no updates at this time.{\textless}/p{\textgreater}{\textless}/br{\textgreater}},
	urldate = {2022-03-10},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George},
	year = {1996},
}

@misc{rind-pawlowskiKhinalugDocumentationProject2016,
	type = {Archive},
	title = {Khinalug, {A} documentation project in {Azerbaijan}},
	url = {https://hdl.handle.net/1839/c09498f1-12dc-4a7a-b21e-99a178660ff8},
	journal = {DOBES},
	author = {Rind-Pawlowski, Monika and Alxas, Rahim and Babayev, Necmeddin and Khvisiashvili, Tamrika and Bahəddinov, Aydın and Əhmədov, Namik and Aliyev, Azay and Ibrahimov, Vahid and Əhmədov, Afeddin and Babayev, Aydin and Ağayev, Həsən},
	year = {2016},
}

@misc{hemmingsDocumentationKelabitLanguage2017,
	type = {Archive},
	title = {Documentation of the {Kelabit} {Language}, {Sarawak}, {Malaysia}.},
	url = {http://hdl.handle.net/2196/00-0000-0000-000F-B667-4},
	journal = {Endangered Languages Archive},
	author = {Hemmings, Charlotte},
	year = {2017},
}

@misc{akademiederwissenschafteninhamburgDGSKorpus2022,
	type = {Archive},
	title = {{DGS} {Korpus}},
	url = {https://www.sign-lang.uni-hamburg.de/dgs-korpus/index.php/welcome.html},
	author = {Akademie der Wissenschaften in Hamburg},
	year = {2022},
}

@misc{nakamuraCABankJapaneseCallFriend2005,
	type = {Archive},
	title = {{CABank} {Japanese} {CallFriend} {Corpus}},
	url = {https://ca.talkbank.org/access/CallFriend/jpn.html},
	journal = {Talkbank},
	author = {Nakamura, Tomoe and Granadillo, Tania},
	year = {2005},
}

@misc{miyataCABankJapaneseSakura2005,
	type = {Archive},
	title = {{CABank} {Japanese} {Sakura} {Corpus}},
	url = {https://ca.talkbank.org/access/Sakura.html},
	journal = {Talkbank},
	author = {Miyata, Susanne},
	year = {2005},
}

@article{mereuDialogicItAlianCreation2021,
	title = {Dialogic {ItAlian}: the creation of a corpus of {Italian} spontaneous speech},
	volume = {130},
	issn = {01676393},
	shorttitle = {Dialogic {ItAlian}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167639321000303},
	doi = {10.1016/j.specom.2021.03.002},
	language = {en},
	urldate = {2022-03-10},
	journal = {Speech Communication},
	author = {Mereu, Daniela and Vietti, Alessandro},
	month = jun,
	year = {2021},
	pages = {1--14},
}

@misc{diazDocumentationHeyoAuk2018,
	type = {Archive},
	title = {Documentation of {Heyo} [auk], a {Torricelli} language of {Papua} {New} {Guinea}},
	url = {http://hdl.handle.net/2196/18d3c47e-db5b-492c-853f-1a000aa19606},
	journal = {DOBES},
	author = {Diaz, Thomas},
	year = {2018},
}

@misc{vossDocumentationGrammarGutob2018,
	type = {Archive},
	title = {Documentation and grammar of {Gutob} ({Munda})},
	url = {http://hdl.handle.net/2196/f027a3a2-d38f-4428-88ec-33b46d346cb3},
	journal = {Endangered Languages Archive},
	author = {Voß, Judith},
	year = {2018},
}

@misc{vydrinaDescriptionDocumentationKakabe2013,
	type = {Archive},
	title = {Description and documentation of the {Kakabe} language},
	url = {http://hdl.handle.net/2196/3015b4c3-1ffc-4cc5-8309-f05f9d4ce8b2},
	journal = {Endangered Languages Archive},
	author = {Vydrina, Alexandra},
	year = {2013},
}

@misc{canavanalexandraCALLHOMEMandarinChinese1996,
	title = {{CALLHOME} {Mandarin} {Chinese} {Speech}},
	url = {https://catalog.ldc.upenn.edu/LDC96S34},
	doi = {10.35111/AT8B-CT20},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The CALLHOME Mandarin Chinese corpus of telephone speech consists of 120 unscripted telephone conversations between native speakers of Mandarin Chinese. All calls, which lasted up to 30 minutes, originated in North America and were placed to locations overseas. Most participants called family members or close friends.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}This corpus contains speech data files only, along with documentation that describes the contents and format of the speech files and the software packages needed to uncompress the speech data. The transcripts and documentation ({\textless}a href="http://catalog.ldc.upenn.edu/LDC96T16" rel="nofollow"{\textgreater}LDC96T16{\textless}/a{\textgreater}) are available separately, as is an associated lexicon ({\textless}a href="http://catalog.ldc.upenn.edu/LDC96L15" rel="nofollow"{\textgreater}LDC96L15{\textless}/a{\textgreater}).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please listen to this {\textless}a href="desc/addenda/LDC96S34.sph"{\textgreater}sample{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}/br{\textgreater} 
Portions ©  1996 Trustees of the University of Pennsylvania},
	urldate = {2022-03-11},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George},
	year = {1996},
	note = {Artwork Size: 1080128 KB
Pages: 1080128 KB},
}

@misc{canavanalexandraCALLFRIENDMandarinChineseMainland1996,
	title = {{CALLFRIEND} {Mandarin} {Chinese}-{Mainland} {Dialect}},
	url = {https://catalog.ldc.upenn.edu/LDC96S55},
	doi = {10.35111/5HA0-RB62},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}CALLFRIEND Mandarin Chinese-Mainland Dialect was developed by the Linguistic Data Consortium (LDC) and consists of approximately 24 hours of unscripted telephone conversations between native speakers of the Mandarin Chinese dialect spoken in mainland China.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The CALLFRIEND series is a collection of telephone conversations in several languages conducted by LDC in support of language identification technology development. Languages covered in the collection include American English, Canadian French, Egyptian Arabic, Farsi, German, Hindi, Japanese, Korean, Mandarin Chinese, Spanish, Tamil and Vietnamese.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}An updated edition of this corpus is available as\&nbsp;CALLFRIEND Mandarin Chinese-Mainland Dialect Second Edition ({\textless}a href="../../../LDC2018S09"{\textgreater}LDC2018S09{\textless}/a{\textgreater}).\&nbsp;The second edition updates the audio files to wav format, simplifies the directory structure and adds documentation and metadata.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The corpus consists of 60 unscripted telephone conversations, lasting between 5-30 minutes. The corpus also includes documentation describing speaker information (sex, age, education, callee telephone number) and call information (channel quality, number of speakers).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}For each conversation, both the caller and callee are native speakers of Mandarin Chinese from Mainland China. All calls are domestic and were placed inside the continental United States and Canada.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Callers in the "Mainland" and "Taiwan" collections of CALLFRIEND Mandarin were identified primarily on the basis of specific attributes in their speech characteristic of geographic origin.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}There are no updates at this time.{\textless}/p{\textgreater}{\textless}/br{\textgreater} 
Portions © 1996 Trustees of the University of Pennsylvania},
	urldate = {2022-03-11},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George},
	year = {1996},
	note = {Artwork Size: 1379520 KB
Pages: 1379520 KB},
}

@misc{canavanalexandraCALLFRIENDKorean1996,
	title = {{CALLFRIEND} {Korean}},
	url = {https://catalog.ldc.upenn.edu/LDC96S54},
	doi = {10.35111/71PH-4112},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The CALLFRIEND project was designed to support the development of language identification technology.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The corpus consists of 60 telephone conversations, lasting between 5-30 minutes. The corpus also includes documentation describing speaker information (sex, age, education, callee telephone number) and call information (channel quality, number of speakers).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}For each conversation, both the caller and callee are native speakers of Korean. All calls are domestic and were placed inside the continental United States and Canada.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please listen to this {\textless}a href="desc/addenda/LDC96S54.sph"{\textgreater}audio sample{\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Transcripts for 49 of the 60 calls are now available as CALLFRIEND Korean Transcripts (LDC2003T08). An additional number of 51 calls have been published as CALLFRIEND Korean Speech Supplement (LDC2003S03).{\textless}/p{\textgreater}{\textless}/br{\textgreater} 
Portions © 1996 Trustees of the University of Pennsylvania},
	urldate = {2022-03-11},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George},
	year = {1996},
}

@misc{lionnetLaalLanguageDocumentation2020,
	type = {Archive},
	title = {Laal language documentation project},
	url = {https://hdl.handle.net/1839/93472197-4462-489c-8cee-0d9a3587f3e5},
	journal = {DOBES},
	author = {Lionnet, Florian and Hoinathy, Remadji and Loncke, Sandrine},
	year = {2020},
}

@misc{williamsDocumentingLanguageInteraction2017,
	type = {Archive},
	title = {Documenting {Language} and {Interaction} in {Kula}},
	url = {http://hdl.handle.net/2196/020426e9-bffc-42da-9f8c-b67c1160a0f9},
	journal = {Endangered Languages Archive},
	author = {Williams, Nicholas},
	year = {2017},
}

@misc{guldemannTextDocumentationUu2014,
	type = {Archive},
	title = {Text documentation of {N}{\textbar}uu},
	url = {http://hdl.handle.net/2196/00-0000-0000-0002-F81F-F},
	journal = {Endangered Languages Archive},
	author = {Güldemann, Tom and Witzlack-Makarevich, Alena},
	year = {2014},
}

@misc{mcdonnellDocumentationNasalOverlooked2017,
	type = {Archive},
	title = {Documentation of {Nasal}: {An} overlooked {Malayo}-{Polynesian} isolate of southwest {Sumatra}},
	url = {http://hdl.handle.net/2196/00-0000-0000-0010-798B-E},
	journal = {DOBES},
	author = {McDonnell, Bradley},
	year = {2017},
}

@misc{carvalhoferreiraMindericoEndangeredLanguage2011,
	type = {Archive},
	title = {Minderico, {An} {Endangered} {Language} in {Portugal}},
	url = {https://hdl.handle.net/1839/f47b19bd-ac9c-434c-b559-c6ea00485f3c},
	journal = {DOBES},
	author = {Carvalho Ferreira, Vera Alexandra and Wurm, Sabine and Bouda, Peter and Endruschat, Annette and Hämmerle, Regina Rosa and Fugaru, Ioana and Rodriguez, Ramón and Ferreira, Henrique Lobo and Knuffmann, Katharina},
	year = {2011},
}

@misc{ogunsolaDocumentationLenMambila2018,
	type = {Archive},
	title = {Documentation of {Len}-{Mambila}},
	url = {http://hdl.handle.net/2196/00-0000-0000-0012-D796-1},
	journal = {Endangered Languages Archive},
	author = {Ogunsola, Bukunmi},
	year = {2018},
}

@misc{yimPreliminaryDocumentationMacau2014,
	type = {Archive},
	title = {Preliminary {Documentation} of {Macau} {Sign} {Language}},
	url = {http://hdl.handle.net/2196/00-0000-0000-000F-B674-6},
	journal = {DOBES},
	author = {Yim, Felix Binh Sze and Xiao, Monica Wei and Yiu, Aaron Leung Wong},
	year = {2014},
}

@misc{winkhartDocumentationRemnantBakaGundi2016,
	type = {Archive},
	title = {A documentation of the remnant {Baka}-{Gundi} language {Limassa}},
	url = {http://hdl.handle.net/2196/70607394-af7c-4fe2-af53-fd40fd6cac50},
	journal = {Endangered Languages Archive},
	author = {Winkhart, Benedikt},
	year = {2016},
}

@misc{amithAudioCorpusSierra2009,
	type = {Archive},
	title = {Audio corpus of {Sierra} {Nororiental} and {Sierra} {Norte} de {Puebla} {Nahuat}(l) with accompanying time-code transcriptions in {ELAN}},
	url = {http://www.openslr.org/92},
	journal = {OpenSLR},
	author = {Amith, Jonathan D and Alcántara, Amelia Domínguez and Osollo, Hermelindo Salazar and Castañeda, Ceferino Salgado and Salazar, Eleuterio Gorostiza},
	year = {2009},
}

@misc{hernandez-greenDocumentationSanJeronimo2009,
	type = {Archive},
	title = {Documentation of {San} {Jerónimo} {Acazulco} {Otomi}, {Ocoyoacac}, {Mexico}.},
	url = {http://hdl.handle.net/2196/00-0000-0000-0002-AA48-9},
	journal = {Endangered Languages Archive},
	author = {Hernandez-Green, Nestor},
	year = {2009},
}

@misc{canavanalexandraCALLHOMESpanishSpeech1996,
	title = {{CALLHOME} {Spanish} {Speech}},
	url = {https://catalog.ldc.upenn.edu/LDC96S35},
	doi = {10.35111/2SKN-2002},
	abstract = {{\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The {\textless}a href="../../../Catalog/docs/LDC96S35/index.html" rel="nofollow"{\textgreater}CALLHOME Spanish{\textless}/a{\textgreater} corpus of telephone speech consists of 120 unscripted telephone conversations between native speakers of Spanish.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}All calls, which lasted up to 30 minutes, originated in North America and were placed to international locations. Most participants called family members or close friends.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}This corpus contains speech data files ONLY, along with the minimal amount of documentation needed to describe the contents and format of the speech files and the software packages needed to uncompress the speech data. The transcripts and documentation ({\textless}a href="http://catalog.ldc.upenn.edu/LDC96T17" rel="nofollow"{\textgreater}LDC96T17{\textless}/a{\textgreater}) are available separately, as is an associated lexicon ({\textless}a href="http://catalog.ldc.upenn.edu/LDC96L16" rel="nofollow"{\textgreater}LDC96L16{\textless}/a{\textgreater}).{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Samples{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}Please listen to this {\textless}a href="desc/addenda/LDC96S35.sph"{\textgreater}audio sample (SPH){\textless}/a{\textgreater}.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The "shorten" and "sphere" directories have been removed.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The sphere directory contained NIST "SPeech HEader REsources" (SPHERE): C-language source code libraries and utilities for manipulating NIST SPHERE-format waveform files.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}The shorten directory contained files for Tony Robinson's "shorten" software for speech compression.{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}A more recent version of the SPHERE utilities is now available on the {\textless}a href="http://www.nist.gov/speech/tools/index.htm" rel="nofollow"{\textgreater}NIST web site{\textless}/a{\textgreater}; additional utilities for converting from SPHERE to other waveform file formats is also available at the {\textless}a href="http://www.ldc.upenn.edu/Using/" rel="nofollow"{\textgreater}LDC web site.{\textless}/a{\textgreater}{\textless}/p{\textgreater}{\textless}br{\textgreater} 
{\textless}p{\textgreater}10.10.2003: It has been brought to our attention that 16 sphere files (both from the train and devtest directories) were corrupted; the problem becomes apparent when trying to decompress the files using the w\_decode utility. As of June 12th, 2018, the corrected version of these files are included with the downloadable corpus. Any new downloads after this date will contain the full, corrected speech.{\textless}/p{\textgreater}{\textless}/br{\textgreater} 
Portions © 1996 Trustees of the University of Pennsylvania},
	urldate = {2022-03-11},
	publisher = {Linguistic Data Consortium},
	author = {Canavan, Alexandra and Zipperlen, George},
	year = {1996},
}

@misc{linguisticdataconsortiumHUB5SpanishTelephone1998,
	title = {{HUB5} {Spanish} {Telephone} {Speech} {Corpus}},
	url = {https://catalog.ldc.upenn.edu/LDC98S70},
	doi = {10.35111/24RP-WV45},
	abstract = {LDC98S70 - Speech data {\textless}a href="http://catalog.ldc.upenn.edu/LDC98T27" rel="nofollow"{\textgreater}LDC98T27{\textless}/a{\textgreater} - Transcripts {\textless}h3{\textgreater}Introduction{\textless}/h3{\textgreater} {\textless}p{\textgreater}This release of HUB5 Spanish training data consists of 106 calls derived from the {\textless}a href="/Catalog/docs/LDC98S70/index.html" rel="nofollow"{\textgreater}CALLFRIEND{\textless}/a{\textgreater} Spanish (Language ID) collection. The transcripts cover a contiguous 10-30 minute segment taken from a recorded conversation lasting up to 30 minutes. These calls were originally collected by the LDC in support of the project on Language Recognition, sponsored by the U.S. Department of Defense. All of these calls are being designated as additional training data for the project on Large Vocabulary Conversational Speech Recognition (LVCSR) in Spanish. {\textless}/p{\textgreater}{\textless}h3{\textgreater}Data{\textless}/h3{\textgreater} {\textless}p{\textgreater}Speakers were solicited by the LDC to participate in this telephone speech collection effort via the internet, publications (advertisements) and personal contacts. A total of 200 call originators were found, each of whom placed a telephone call via a toll-free robot operator maintained by the LDC. Access to the robot operator was possible via a unique Personal Identification Number (PIN) issued by the recruiting staff at the LDC when the caller enrolled in the project. {\textless}/p{\textgreater}{\textless}p{\textgreater}Once a caller was recruited to participate, he/she was given a free choice of whom to call. Recruits were given no guidelines concerning what they should talk about. Most participants called family members or close friends. All calls originated in North America and were placed to various locations within North America, Puerto Rico or the Dominican Republic. The participants were made aware that their telephone call would be recorded, as were the call recipients. The call was allowed only if both parties agreed to being recorded. Each caller was allowed to talk up to 30 minutes. Upon successful completion of the call, the caller was paid \$20 (in addition to making a free long-distance telephone call). Each caller was allowed to place only one telephone call. {\textless}/p{\textgreater}{\textless}p{\textgreater}HUB5 Spanish speech and transcript data may be obtained by contacting the {\textless}a rel="nofollow"{\textgreater}LDC{\textless}/a{\textgreater} {\textless}/p{\textgreater}{\textless}h3{\textgreater}Updates{\textless}/h3{\textgreater} There are no updates at this time. {\textless}/br{\textgreater}},
	urldate = {2022-03-11},
	publisher = {Linguistic Data Consortium},
	author = {Linguistic Data Consortium},
	year = {1998},
}

@misc{letoCollectionTotoli2010,
	type = {Archive},
	title = {Collection {Totoli}},
	url = {https://hdl.handle.net/1839/00-0000-0000-0009-2A75-5},
	journal = {DOBES},
	author = {Leto, Claudia and Alamudi, Winarno Salim and Himmelmann, Nikolaus P. and Riesberg, Sonja},
	year = {2010},
}

@misc{grzechUpperNapoKichwa2020,
	type = {Archive},
	title = {Upper {Napo} {Kichwa}: documentation of language and culture},
	url = {http://hdl.handle.net/2196/00-0000-0000-000C-F5FB-A.},
	journal = {Endangered Languages Archive},
	author = {Grzech, Karolina},
	year = {2020},
}

@misc{domingoTehuelcheLanguageCollection2019,
	type = {Archive},
	title = {Tehuelche {Language} {Collection}},
	url = {http://hdl.handle.net/2196/00-0000-0000-0011-F549-B},
	journal = {Endangered Languages Archive},
	author = {Domingo, Javier},
	year = {2019},
}

@misc{shahMultimediaCorpusSiPhuthi2019,
	type = {Archive},
	title = {A multimedia corpus of {siPhuthi}.},
	url = {http://hdl.handle.net/2196/00-0000-0000-0010-D126-A},
	journal = {Endangered Languages Archive},
	author = {Shah, Sheena},
	year = {2019},
}

@misc{tadmorLanguagesWesternBorneo2007,
	type = {Archive},
	title = {Languages of {Western} {Borneo} {Documentation} {Project}},
	url = {https://hdl.handle.net/1839/00-0000-0000-0022-5D7C-E},
	journal = {DOBES},
	author = {Tadmor, Uri},
	year = {2007},
}

@misc{thomasSakunSukurLanguage2014,
	type = {Archive},
	title = {Sakun ({Sukur}) {Language} {Documentation}},
	url = {http://hdl.handle.net/2196/ea080fc9-a392-4d41-a91c-0c801bbde646},
	journal = {Endangered Languages Archive},
	author = {Thomas, Michael},
	year = {2014},
}

@inproceedings{torreiraNijmegenCorpusCasual2010a,
	title = {The {Nijmegen} corpus of casual {Spanish}},
	booktitle = {Seventh conference on {International} {Language} {Resources} and {Evaluation} ({LREC}'10)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Torreira, Francisco and Ernestus, Mirjam},
	year = {2010},
	pages = {2981--2985},
}

@misc{simsDocumentationYongheQiang2018,
	type = {Archive},
	title = {Documentation of {Yonghe} {Qiang} language and culture},
	url = {http://hdl.handle.net/2196/91c9326c-6e76-4d8c-aafe-e3f1e7ceccab},
	journal = {DOBES},
	author = {Sims, Nathaniel},
	year = {2018},
}

@misc{chirkovaDuoxuDocumentationCritically2017,
	type = {Archive},
	title = {Duoxu: {Documentation} of a {Critically} {Endangered} {Language} of {South}-{West} {China}},
	url = {https://cocoon.huma-num.fr/exist/crdo/meta2/crdo-COLLECTION_CHK_DUOXU},
	journal = {COllections de COrpus Oraux Numeriques (CoCoON ex-CRDO)},
	author = {Chirkova, Katia and Han, Zhengkang},
	year = {2017},
}

@misc{unterladstetterCollectionWooi2013,
	type = {Archive},
	title = {Collection {Wooi}},
	url = {https://hdl.handle.net/1839/eb0ab65a-e985-42d1-a9ee-fccdba47a526},
	journal = {DOBES},
	author = {Unterladstetter, Volker and Loch, Alexander and Morigerowsky, Freya and Sawaki, Yusuf},
	year = {2013},
}

@misc{barlowDocumentationUlwaEndangered2017,
	type = {Archive},
	title = {Documentation of {Ulwa}, an endangered language of {Papua} {New} {Guinea}},
	url = {https://hdl.handle.net/1839/b1796725-1a49-48ee-93ea-75e5b440c7bc},
	journal = {Endangered Languages Archive},
	author = {Barlow, Russell},
	year = {2017},
}

@misc{amithAudioCorpusYoloxochitl2011,
	type = {Archive},
	title = {Audio corpus of {Yoloxóchitl} {Mixtec} with accompanying time-coded transcriptons in {ELAN}.},
	url = {https://www.openslr.org/89/},
	journal = {OpenSLR},
	author = {Amith, Jonathan D and Castillo, Rey},
	year = {2011},
}

@misc{levinsonCollectionYeliDnye2019,
	type = {Archive},
	title = {Collection {Yélî} {Dnye}},
	url = {https://hdl.handle.net/1839/97720d9d-927e-41cb-bd65-8e6accc42d2c},
	journal = {DOBES},
	author = {Levinson, Stephen C. and Casillas, Marisa and Armstrong, W.E. and Torreira, Francisco},
	year = {2019},
}

@misc{riesbergYaliSummitsCollection2015,
	type = {Archive},
	title = {Yali {Summits} {Collection} in collection "{CELD} {Papua}"},
	url = {https://hdl.handle.net/1839/e941f246-4842-4ff0-9535-9dbb25f9f805},
	journal = {DOBES},
	author = {Riesberg, Sonja and Himmelmann, Nikolaus P. and Walianggen, Kristian and Arilaha, Apriani},
	year = {2015},
}

@misc{rohlederDocumentationDescriptionVamale2018,
	type = {Archive},
	title = {Documentation and description of {Vamale}, an endangered language of {New} {Caledonia}},
	url = {https://hdl.handle.net/1839/b1796725-1a49-48ee-93ea-75e5b440c7bc},
	journal = {Endangered Languages Archive},
	author = {Rohleder, Jean},
	year = {2018},
}

@misc{polianTseltalDocumentationProject2010,
	type = {Archive},
	title = {Tseltal {Documentation} {Project} of {Gilles} {Polian}},
	url = {http://hdl.handle.net/2196/00-0000-0000-0000-F93F-7},
	journal = {Endangered Languages Archive},
	author = {Polian, Gilles},
	year = {2010},
}

@misc{mcdonnell_documentation_2007,
	type = {Archive},
	title = {Documentation of {Nasal}: {An} overlooked {Malayo}-{Polynesian} isolate of southwest {Sumatra}},
	url = {https://hdl.handle.net/1839/b1796725-1a49-48ee-93ea-75e5b440c7bc},
	journal = {DOBES},
	author = {McDonnell, Bradley},
	year = {2007},
}

@article{podlipniak_pitch_2022,
	title = {Pitch syntax as part of an ancient protolanguage},
	issn = {0024-3841},
	url = {https://www.sciencedirect.com/science/article/pii/S0024384121002102},
	doi = {10.1016/j.lingua.2021.103238},
	abstract = {Music and speech are both auditory communicative phenomena which may have a common evolutionary origin. Both Pinker and Patel have proposed that the ‘rule-governed arrangements’ found in music are comparable to, and possibly derive from, the capacity for syntax that is found in language. Other scholars, such as Fitch and Charnavel, have alternatively suggested that the arrangements found in dance, music, and language stem from more general cognitive capacities related to hierarchical grouping principles. However, different syntactic phenomena such as rhythm syntax, pitch syntax, phonological syntax, and language grammar, work in a variety of disparate ways, which suggests that they have evolved owing to different adaptive pressures. This paper aims to show that pitch syntax was once part of a protolanguage designed to communicate internal mental states. It is proposed that increased social complexity caused this protolanguage to interact and eventually merge with another protolanguage specialized in communicating propositional meaning. It is also hypothesized that Baldwinian evolution led to the exaptation of combinatorial mechanisms already present in a musical protolanguage to create a new communicative system. As a result, a new capacity evolved that enabled the implicit learning of language grammar.},
	language = {en},
	urldate = {2022-03-11},
	journal = {Lingua},
	author = {Podlipniak, Piotr},
	month = jan,
	year = {2022},
	pages = {103238},
}

@article{sainburg_long-range_2022,
	title = {Long-range sequential dependencies precede complex syntactic production in language acquisition},
	volume = {289},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspb.2021.2657},
	doi = {10.1098/rspb.2021.2657},
	abstract = {To convey meaning, human language relies on hierarchically organized, long-range relationships spanning words, phrases, sentences and discourse. As the distances between elements (e.g. phonemes, characters, words) in human language sequences increase, the strength of the long-range relationships between those elements decays following a power law. This power-law relationship has been attributed variously to long-range sequential organization present in human language syntax, semantics and discourse structure. However, non-linguistic behaviours in numerous phylogenetically distant species, ranging from humpback whale song to fruit fly motility, also demonstrate similar long-range statistical dependencies. Therefore, we hypothesized that long-range statistical dependencies in human speech may occur independently of linguistic structure. To test this hypothesis, we measured long-range dependencies in several speech corpora from children (aged 6 months–12 years). We find that adult-like power-law statistical dependencies are present in human vocalizations at the earliest detectable ages, prior to the production of complex linguistic structure. These linguistic structures cannot, therefore, be the sole cause of long-range statistical dependencies in language.},
	number = {1970},
	urldate = {2022-03-10},
	journal = {Proceedings of the Royal Society B: Biological Sciences},
	author = {Sainburg, Tim and Mai, Anna and Gentner, Timothy Q.},
	month = mar,
	year = {2022},
	note = {Publisher: Royal Society},
	pages = {20212657},
}

@article{voinea_designing_2018,
	series = {Technology and the {Good} {Society}},
	title = {Designing for conviviality},
	volume = {52},
	issn = {0160-791X},
	url = {https://www.sciencedirect.com/science/article/pii/S0160791X17300908},
	doi = {10.1016/j.techsoc.2017.07.002},
	abstract = {The aim of this paper is to advance systemism (an ontological framework that accommodates both agency and social structure, stressing that everything is a system or part of a system) as a better suited ontological framework for giving an account of the role of technologies in the formation of a good society. Building on Ivan Illich's systemic understanding of a convivial society, my secondary aim is to provide a matrix for the ethical design of technologies meant to foster conviviality. I will argue that such an ethical matrix could overcome strictly individualistic or holistic understandings of the social realm, by admitting that the social change provoked by technology is affecting both the social fabric of the concerned society and the individual which is part of the social structure concerned.},
	language = {en},
	urldate = {2022-03-10},
	journal = {Technology in Society},
	author = {Voinea, Cristina},
	month = feb,
	year = {2018},
	pages = {70--78},
}

@article{firth_robotopias_2020,
	title = {Robotopias: mapping utopian perspectives on new industrial technology},
	volume = {41},
	issn = {0144-333X},
	shorttitle = {Robotopias},
	url = {https://doi.org/10.1108/IJSSP-01-2020-0004},
	doi = {10.1108/IJSSP-01-2020-0004},
	abstract = {Purpose This paper maps utopian theories of technological change. The focus is on debates surrounding emerging industrial technologies which contribute to making the relationship between humans and machines more symbiotic and entangled, such as robotics, automation and artificial intelligence. The aim is to provide a map to navigate complex debates on the potential for technology to be used for emancipatory purposes and to plot the grounds for tactical engagements. Design/methodology/approach The paper proposes a two-way axis to map theories into to a six-category typology. Axis one contains the parameters humanist–assemblage. Humanists draw on the idea of a human essence of creative labour-power, and treat machines as alienated and exploitative form of this essence. Assemblage theorists draw on posthumanism and poststructuralism, maintaining that humans always exist within assemblages which also contain non-human forces. Axis two contains the parameters utopian/optimist; tactical/processual; and dystopian/pessimist, depending on the construed potential for using new technologies for empowering ends. Findings The growing social role of robots portends unknown, and maybe radical, changes, but there is no single human perspective from which this shift is conceived. Approaches cluster in six distinct sets, each with different paradigmatic assumptions. Practical implications Mapping the categories is useful pedagogically, and makes other political interventions possible, for example interventions between groups and social movements whose practice-based ontologies differ vastly. Originality/value Bringing different approaches into contact and mapping differences in ways which make them more comparable, can help to identify the points of disagreement and the empirical or axiomatic grounds for these. It might facilitate the future identification of criteria to choose among the approaches.},
	number = {3/4},
	urldate = {2022-03-10},
	journal = {International Journal of Sociology and Social Policy},
	author = {Firth, Rhiannon and Robinson, Andrew},
	month = jan,
	year = {2020},
	note = {Publisher: Emerald Publishing Limited},
	pages = {298--314},
}

@article{marcus_deep_2018,
	title = {Deep {Learning}: {A} {Critical} {Appraisal}},
	shorttitle = {Deep {Learning}},
	url = {http://arxiv.org/abs/1801.00631},
	abstract = {Although deep learning has historical roots going back decades, neither the term "deep learning" nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.},
	urldate = {2019-11-25},
	journal = {arXiv:1801.00631 [cs, stat]},
	author = {Marcus, Gary},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.00631},
}

@article{marcus_next_2020,
	title = {The {Next} {Decade} in {AI}: {Four} {Steps} {Towards} {Robust} {Artificial} {Intelligence}},
	shorttitle = {The {Next} {Decade} in {AI}},
	url = {http://arxiv.org/abs/2002.06177},
	abstract = {Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.},
	urldate = {2020-02-17},
	journal = {arXiv:2002.06177 [cs]},
	author = {Marcus, Gary},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.06177},
}

@techreport{kim_multi-modal_2018,
	type = {Archive},
	title = {A multi-modal documentation of {Jejuan} conversations},
	url = {http://hdl.handle.net/2196/00-0000-0000-000E-D15C-1},
	institution = {Endangered Languages Archive},
	author = {Kim, Soung-U},
	year = {2018},
}

@incollection{arbib_cross-cultural_2013,
	title = {Cross-{Cultural} {Universals} and {Communication} {Structures}},
	isbn = {978-0-262-01810-4},
	url = {http://mitpress.universitypressscholarship.com/view/10.7551/mitpress/9780262018104.001.0001/upso-9780262018104-chapter-3},
	urldate = {2020-01-03},
	booktitle = {Language, {Music}, and the {Brain}},
	publisher = {The MIT Press},
	author = {Levinson, Stephen C.},
	editor = {Arbib, Michael A.},
	month = jul,
	year = {2013},
	doi = {10.7551/mitpress/9780262018104.003.0003},
	pages = {67--81},
}

@article{skantze_turn-taking_2021,
	title = {Turn-taking in {Conversational} {Systems} and {Human}-{Robot} {Interaction}: {A} {Review}},
	volume = {67},
	issn = {08852308},
	shorttitle = {Turn-taking in {Conversational} {Systems} and {Human}-{Robot} {Interaction}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S088523082030111X},
	doi = {10.1016/j.csl.2020.101178},
	language = {en},
	urldate = {2022-03-10},
	journal = {Computer Speech \& Language},
	author = {Skantze, Gabriel},
	month = may,
	year = {2021},
	pages = {101178},
}

@article{marge_spoken_2022,
	title = {Spoken language interaction with robots: {Recommendations} for future research},
	volume = {71},
	issn = {0885-2308},
	shorttitle = {Spoken language interaction with robots},
	url = {https://www.sciencedirect.com/science/article/pii/S0885230821000620},
	doi = {10.1016/j.csl.2021.101255},
	abstract = {With robotics rapidly advancing, more effective human–robot interaction is increasingly needed to realize the full potential of robots for society. While spoken language must be part of the solution, our ability to provide spoken language interaction capabilities is still very limited. In this article, based on the report of an interdisciplinary workshop convened by the National Science Foundation, we identify key scientific and engineering advances needed to enable effective spoken language interaction with robotics. We make 25 recommendations, involving eight general themes: putting human needs first, better modeling the social and interactive aspects of language, improving robustness, creating new methods for rapid adaptation, better integrating speech and language with other communication modalities, giving speech and language components access to rich representations of the robot’s current knowledge and state, making all components operate in real time, and improving research infrastructure and resources. Research and development that prioritizes these topics will, we believe, provide a solid foundation for the creation of speech-capable robots that are easy and effective for humans to work with.},
	language = {en},
	urldate = {2022-03-09},
	journal = {Computer Speech \& Language},
	author = {Marge, Matthew and Espy-Wilson, Carol and Ward, Nigel G. and Alwan, Abeer and Artzi, Yoav and Bansal, Mohit and Blankenship, Gil and Chai, Joyce and Daumé, Hal and Dey, Debadeepta and Harper, Mary and Howard, Thomas and Kennington, Casey and Kruijff-Korbayová, Ivana and Manocha, Dinesh and Matuszek, Cynthia and Mead, Ross and Mooney, Raymond and Moore, Roger K. and Ostendorf, Mari and Pon-Barry, Heather and Rudnicky, Alexander I. and Scheutz, Matthias and Amant, Robert St. and Sun, Tong and Tellex, Stefanie and Traum, David and Yu, Zhou},
	month = jan,
	year = {2022},
	pages = {101255},
}

@article{abramova_social_2015,
	title = {Social cognition in simple action coordination: {A} case for direct perception},
	volume = {36},
	issn = {1053-8100},
	shorttitle = {Social cognition in simple action coordination},
	url = {http://www.sciencedirect.com/science/article/pii/S1053810015000902},
	doi = {10.1016/j.concog.2015.04.013},
	abstract = {In this paper we sketch the outlines of an account of the kind of social cognition involved in simple action coordination that is based on direct social perception (DSP) rather than recursive mindreading. While we recognize the viability of a mindreading-based account such as e.g. Michael Tomasello’s, we present an alternative DSP account that (i) explains simple action coordination in a less cognitively demanding manner, (ii) is better able to explain flexibility and strategy-switching in coordination and crucially (iii) allows for formal modeling. This account of action coordination is based on the notion of an agent’s field of affordances. Coordination ensues, we argue, when, given a shared intention, the actions of and/or affordances for one agent shape the field of affordances for another agent. This a form of social perception since in particular perceiving affordances for another person involves seeing that person as an agent. It is a form of social perception since it involves perceiving affordances for another person and registering how another person’s actions influence one’s own perceived field of affordances.},
	urldate = {2019-05-21},
	journal = {Consciousness and Cognition},
	author = {Abramova, Ekaterina and Slors, Marc},
	month = nov,
	year = {2015},
	pages = {519--531},
}

@article{parker_cross-linguistic_2006,
	title = {A cross-linguistic corpus of forms meaning 'yes'},
	volume = {4},
	number = {1},
	journal = {Linguistic Discovery},
	author = {Parker, Steve},
	year = {2006},
	pages = {1--34},
}

@inproceedings{budzianowski_multiwoz_2018,
	address = {Brussels, Belgium},
	title = {{MultiWOZ} - {A} {Large}-{Scale} {Multi}-{Domain} {Wizard}-of-{Oz} {Dataset} for {Task}-{Oriented} {Dialogue} {Modelling}},
	url = {https://aclanthology.org/D18-1547},
	doi = {10.18653/v1/D18-1547},
	abstract = {Even though machine learning has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available.To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora.The contribution of this work apart from the open-sourced dataset is two-fold:firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on crowd-sourcing without the need of hiring professional annotators;secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.},
	urldate = {2022-03-10},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Budzianowski, Pawe{\textbackslash}l and Wen, Tsung-Hsien and Tseng, Bo-Hsiang and Casanueva, Iñigo and Ultes, Stefan and Ramadan, Osman and Gašić, Milica},
	month = oct,
	year = {2018},
	pages = {5016--5026},
}

@inproceedings{ren_towards_2018,
	address = {Brussels, Belgium},
	title = {Towards {Universal} {Dialogue} {State} {Tracking}},
	url = {https://aclanthology.org/D18-1299},
	doi = {10.18653/v1/D18-1299},
	abstract = {Dialogue state tracker is the core part of a spoken dialogue system. It estimates the beliefs of possible user's goals at every dialogue turn. However, for most current approaches, it's difficult to scale to large dialogue domains. They have one or more of following limitations: (a) Some models don't work in the situation where slot values in ontology changes dynamically; (b) The number of model parameters is proportional to the number of slots; (c) Some models extract features based on hand-crafted lexicons. To tackle these challenges, we propose StateNet, a universal dialogue state tracker. It is independent of the number of values, shares parameters across all slots, and uses pre-trained word vectors instead of explicit semantic dictionaries. Our experiments on two datasets show that our approach not only overcomes the limitations, but also significantly outperforms the performance of state-of-the-art approaches.},
	urldate = {2022-03-10},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Ren, Liliang and Xie, Kaige and Chen, Lu and Yu, Kai},
	month = oct,
	year = {2018},
	pages = {2780--2786},
}

@inproceedings{yaghoubzadeh_flexdiam_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {flexdiam – {Flexible} {Dialogue} {Management} for {Incremental} {Interaction} with {Virtual} {Agents} ({Demo} {Paper})},
	isbn = {978-3-319-47664-3 978-3-319-47665-0},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-47665-0_64},
	doi = {10.1007/978-3-319-47665-0_64},
	abstract = {We present a demonstration system for incremental spoken human–machine dialogue for task-centric domains that includes a controller for verbal and nonverbal behavior for virtual agents. The dialogue management components can handle uncertainty in input and resolve it interactively with high responsivity, and state tracking is aware of momentary events such as interruptions by the user. Aside from adaptable dialogue strategies, such as for grounding, the system includes a multimodal floor management controller that attempts to limit the influence of idiosyncratic dialogue behavior on the part of our primary user groups – older adults and people with cognitive impairments – both of which have previously participated in pilot studies using the platform.},
	language = {en},
	urldate = {2018-05-15},
	booktitle = {Intelligent {Virtual} {Agents}},
	publisher = {Springer, Cham},
	author = {Yaghoubzadeh, Ramin and Kopp, Stefan},
	month = sep,
	year = {2016},
	pages = {505--508},
}

@inproceedings{jentzsch_conversational_2019,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Conversational {Interfaces} for {Explainable} {AI}: {A} {Human}-{Centred} {Approach}},
	isbn = {978-3-030-30391-4},
	shorttitle = {Conversational {Interfaces} for {Explainable} {AI}},
	abstract = {One major goal of Explainable Artificial Intelligence (XAI) in order to enhance trust in technology is to enable the user to enquire information and explanation directly from an intelligent agent. We propose Conversational Interfaces (CIs) to be the perfect setting, since they are intuitive for humans and computationally processible. While there are many approaches addressing technical and agent related issues of this human-agent communication problem, the user perspective appears to be widely neglected. With the goal of better requirement understanding and identification of implicit user expectations, a Wizard of Oz (WoZ) experiment was conducted, where participants tried to elicit basic information from a pretended artificial agent via Conversational Interface (What are your capabilities?). Chats were analysed by means of Conversation Analysis, where the hypothesis that users pursue fundamentally different strategies could be verified. Stated results illustrate the vast variety in human communication and disclose both requirements of users and obstacles in the implementation of protocols for interacting agents. Finally, we inferred essential indications for the implementation of such a CI. The findings show that existing intent-based design of Conversational Interfaces is very limited, even in a well-defined task-based interaction.},
	language = {en},
	booktitle = {Explainable, {Transparent} {Autonomous} {Agents} and {Multi}-{Agent} {Systems}},
	publisher = {Springer International Publishing},
	author = {Jentzsch, Sophie F. and Höhn, Sviatlana and Hochgeschwender, Nico},
	editor = {Calvaresi, Davide and Najjar, Amro and Schumacher, Michael and Främling, Kary},
	year = {2019},
	pages = {77--92},
}

@incollection{cassell_conversational_2006,
	address = {Oxford},
	title = {Conversational {Agents}, {Synthetic}},
	isbn = {978-0-08-044854-1},
	url = {http://www.sciencedirect.com/science/article/B7T84-4M3C3K0-7V/2/d7711591aea3e5312106cb17e8ef11e0},
	abstract = {Embodied conversational agents are cartoon-like virtual humans projected on a screen that have the ability to speak, gesture, make head movements, and use facial expression to communicate. They can serve as interfaces to allow humans to communicate with computers in a natural way. They also serve as tools to allow researchers to study human communication by synthesizing human language use in a computer simulation.},
	urldate = {2009-03-04},
	booktitle = {Encyclopedia of {Language} \& {Linguistics}},
	publisher = {Elsevier},
	author = {Cassell, Justine},
	editor = {{Keith Brown}},
	year = {2006},
	pages = {163--169},
}

@inproceedings{cassell_animated_1994,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '94},
	title = {Animated conversation: rule-based generation of facial expression, gesture \&amp; spoken intonation for multiple conversational agents},
	isbn = {978-0-89791-667-7},
	shorttitle = {Animated conversation},
	url = {https://doi.org/10.1145/192161.192272},
	doi = {10.1145/192161.192272},
	abstract = {We describe an implemented system which automatically generates and animates conversations between multiple human-like agents with appropriate and synchronized speech, intonation, facial expressions, and hand gestures. Conversation is created by a dialogue planner that produces the text as well as the intonation of the utterances. The speaker/listener relationship, the text, and the intonation in turn drive facial expressions, lip motions, eye gaze, head motion, and arm gestures generators. Coordinated arm, wrist, and hand motions are invoked to create semantically meaningful gestures. Throughout we will use examples from an actual synthesized, fully animated conversation.},
	urldate = {2021-12-09},
	booktitle = {Proceedings of the 21st annual conference on {Computer} graphics and interactive techniques},
	publisher = {Association for Computing Machinery},
	author = {Cassell, Justine and Pelachaud, Catherine and Badler, Norman and Steedman, Mark and Achorn, Brett and Becket, Tripp and Douville, Brett and Prevost, Scott and Stone, Matthew},
	month = jul,
	year = {1994},
	pages = {413--420},
}

@inproceedings{albert_putting_2021,
	address = {New York, NY, USA},
	series = {{CUI} '21},
	title = {Putting wake words to bed: {We} speak wake words with systematically varied prosody, but {CUIs} don't listen},
	isbn = {978-1-4503-8998-3},
	shorttitle = {Putting wake words to bed},
	url = {https://doi.org/10.1145/3469595.3469608},
	doi = {10.1145/3469595.3469608},
	abstract = {‘Wake words’ such as "Alexa" or "Hey Siri", as conversation design elements, mimic the interactionally rich ‘summons-answer’ sequence in natural conversation, but their function amounts to little more than a button-push: simply activating the interface. In practice, however, users vocally overdesign their wake words with all the detail of a ‘real’ interactional summons. We hear users uttering wake words with a specific prosody and intonation, as though for a particular recipient in a particular social/pragmatic context. This presents a puzzle for designers of conversational user interfaces (CUIs). Previous research suggests that expert users simplify their talk when interacting with CUIs, but with wake words we observe the opposite. When users do the extra interactional work of varying their wake words in ways that seem ‘recipient designed’ for a specific other, does that suggest that designers are successfully eliciting natural interaction from users, or is it violating user expectations? Our two case studies highlight how the mismatch between user expectations and the limitations of how wake words are currently implemented can lead to cascades of interactional trouble, especially in multi-party conversations. We argue that designers should find new ways to activate CUIs that align users’ expectations with conversational system design.},
	urldate = {2021-11-18},
	booktitle = {{CUI} 2021 - 3rd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Albert, Saul and Hamann, Magnus},
	month = jul,
	year = {2021},
	pages = {1--5},
}

@article{corps_overrated_2022,
	title = {Overrated gaps: {Inter}-speaker gaps provide limited information about the timing of turns in conversation},
	volume = {223},
	issn = {0010-0277},
	shorttitle = {Overrated gaps},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027722000257},
	doi = {10.1016/j.cognition.2022.105037},
	abstract = {Corpus analyses have shown that turn-taking in conversation is much faster than laboratory studies of speech planning would predict. To explain fast turn-taking, Levinson and Torreira (2015) proposed that speakers are highly proactive: They begin to plan a response to their interlocutor's turn as soon as they have understood its gist, and launch this planned response when the turn-end is imminent. Thus, fast turn-taking is possible because speakers use the time while their partner is talking to plan their own utterance. In the present study, we asked how much time upcoming speakers actually have to plan their utterances. Following earlier psycholinguistic work, we used transcripts of spoken conversations in Dutch, German, and English. These transcripts consisted of segments, which are continuous stretches of speech by one speaker. In the psycholinguistic and phonetic literature, such segments have often been used as proxies for turns. We found that in all three corpora, large proportions of the segments comprised of only one or two words, which on our estimate does not give the next speaker enough time to fully plan a response. Further analyses showed that speakers indeed often did not respond to the immediately preceding segment of their partner, but continued an earlier segment of their own. More generally, our findings suggest that speech segments derived from transcribed corpora do not necessarily correspond to turns, and the gaps between speech segments therefore only provide limited information about the planning and timing of turns.},
	language = {en},
	urldate = {2022-02-03},
	journal = {Cognition},
	author = {Corps, Ruth E. and Knudsen, Birgit and Meyer, Antje S.},
	month = jun,
	year = {2022},
	pages = {105037},
}

@article{munn_alexa_2018,
	title = {Alexa and the {Intersectional} {Interface}},
	copyright = {Angles est mise à disposition selon les termes de la Licence Creative Commons Attribution 4.0 International.},
	issn = {2274-2042},
	url = {https://journals.openedition.org/angles/861},
	doi = {10.4000/angles.861},
	abstract = {The interface, Francois Dagognet wrote, is a “fertile nexus.” Rather than an immaterial surface or an impartial gateway, the interface itself continually draws upon political, social and cultural sources, all which work to encourage particular productivities while suppressing or negating others. This article explores the specific properties of Amazon Alexa, the “digital assistant” for the home who plays music, delivers news, tells jokes, and plays games. Of course, Alexa interfaces with content — a deluge of diverse applications and information are smoothly brought together through her consistent voice and coherent personality. But Alexa also interfaces with history — she is part of a longer genealogy of gendered interfaces from Siri and Cortana all the way back to Bell Labs, a genealogy predicated on a subjectivity of subservience. Alexa also interfaces with capital — the “Skills” she can learn, and which the user must remember and repeat, are based on a landscape of corporate brands and commercial products. Finally, Alexa interfaces with culture — the predominantly white male culture of contemporary software production shapes the type of sexuality and subjectivity embodied by the bot. Following Alexander Galloway, the interface can thus be understood less as a mere palimpsest of previous traces, and more as a generative performance in the present. The runaway success of Alexa has established her as a universal mediator for the smart home and a model for the internet of things. As the prototype of a technical vision, Alexa’s performative interfacing — and the politics enacted through it — need critical examination.},
	language = {en},
	number = {7},
	urldate = {2021-11-16},
	journal = {Angles. New Perspectives on the Anglophone World},
	author = {Munn, Luke},
	month = nov,
	year = {2018},
	note = {Number: 7
Publisher: Société des Anglicistes de l’Enseignement Supérieur},
	pages = {1--11},
}

@inproceedings{stolcke_comparing_2017,
	title = {Comparing {Human} and {Machine} {Errors} in {Conversational} {Speech} {Transcription}},
	url = {https://www.isca-speech.org/archive/interspeech_2017/stolcke17_interspeech.html},
	doi = {10.21437/Interspeech.2017-1544},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Interspeech 2017},
	publisher = {ISCA},
	author = {Stolcke, Andreas and Droppo, Jasha},
	month = aug,
	year = {2017},
	pages = {137--141},
}

@article{wolk_survey_2022,
	title = {Survey on dialogue systems including slavic languages},
	volume = {477},
	issn = {0925-2312},
	doi = {10.1016/j.neucom.2021.11.076},
	abstract = {Slavic languages pose a challenge to the researchers in the domain of dialogue technology. A relatively free word order with a large degree of inflection, such as conjugation of verbs, and declension of adjectives, pronouns, and nouns are exhibited by the Slavic languages, which has a significant impact on the size of lexical inventories that significantly complicate the design of dialogue systems. This article conducts an empirical study on the state-of-the-art dialogue systems within Slavic languages. Moreover, we review the existing models in recent dialogue systems, pinpoint the current main challenges and identify potential research directions of practical and intelligent systems within low-resourced languages. © 2021},
	language = {English},
	journal = {Neurocomputing},
	author = {Wołk, K. and Wołk, A. and Wnuk, D. and Grześ, T. and Skubis, I.},
	year = {2022},
	pages = {62--84},
}

@inproceedings{ward_similar_2013,
	title = {The {Similar} {Segments} in {Social} {Speech} {Task}},
	booktitle = {{MediaEval}},
	author = {Ward, Nigel G. and Werner, Steven D. and Novick, David G. and Shriberg, Elizabeth and Oertel, Catharine and Morency, Louis-Philippe and Kawahara, Tatsuya},
	year = {2013},
}

@article{ward_planning_2019,
	title = {Planning for a {Corpus} of {Continuous} {Ratings} of {Spoken} {Dialog} {Quality}},
	url = {https://scholarworks.utep.edu/cs_techrep/1310},
	journal = {Departmental Technical Reports (CS)},
	author = {Ward, Nigel},
	month = mar,
	year = {2019},
}

@inproceedings{bender_dangers_2021,
	address = {Virtual Event Canada},
	title = {On the {Dangers} of {Stochastic} {Parrots}: {Can} {Language} {Models} {Be} {Too} {Big}?},
	isbn = {978-1-4503-8309-7},
	shorttitle = {On the {Dangers} of {Stochastic} {Parrots}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445922},
	doi = {10.1145/3442188.3445922},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
	month = mar,
	year = {2021},
	pages = {610--623},
}

@book{schieffelin_language_1986,
	address = {Cambridge},
	title = {Language {Socialization} {Across} {Cultures}},
	isbn = {0-521-32621-4},
	publisher = {Cambridge University Press},
	editor = {Schieffelin, Bambi B. and Ochs, Elinor},
	year = {1986},
}

@inproceedings{schofield_pulling_2017,
	address = {Valencia, Spain},
	title = {Pulling {Out} the {Stops}: {Rethinking} {Stopword} {Removal} for {Topic} {Models}},
	shorttitle = {Pulling {Out} the {Stops}},
	url = {https://aclanthology.org/E17-2069},
	abstract = {It is often assumed that topic models benefit from the use of a manually curated stopword list. Constructing this list is time-consuming and often subject to user judgments about what kinds of words are important to the model and the application. Although stopword removal clearly affects which word types appear as most probable terms in topics, we argue that this improvement is superficial, and that topic inference benefits little from the practice of removing stopwords beyond very frequent terms. Removing corpus-specific stopwords after model inference is more transparent and produces similar results to removing those words prior to inference.},
	urldate = {2022-03-07},
	booktitle = {Proceedings of the 15th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Volume} 2, {Short} {Papers}},
	publisher = {Association for Computational Linguistics},
	author = {Schofield, Alexandra and Magnusson, Måns and Mimno, David},
	month = apr,
	year = {2017},
	pages = {432--436},
}

@article{kodama_approach_2021,
	title = {An {Approach} to {Aligning} {Categorical} and {Continuous} {Time} {Series} for {Studying} the {Dynamics} of {Complex} {Human} {Behavior}},
	volume = {12},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2021.614431},
	abstract = {An emerging perspective on human cognition and performance sees it as a kind of self-organizing phenomenon involving dynamic coordination across the body, brain and environment. Measuring this coordination faces a major challenge. Time series obtained from such cognitive, behavioral, and physiological coordination are often complicated in terms of non-stationarity and non-linearity, and in terms of continuous vs. categorical scales. Researchers have proposed several analytical tools and frameworks. One method designed to overcome these complexities is recurrence quantification analysis, developed in the study of non-linear dynamics. It has been applied in various domains, including linguistic (categorical) data or motion (continuous) data. However, most previous studies have applied recurrence methods individually to categorical or continuous data. To understand how complex coordination works, an integration of these types of behavior is needed. We aimed to integrate these methods to investigate the relationship between language (categorical) and motion (continuous) directly. To do so, we added temporal information (a time stamp) to categorical data (i.e., language), and applied joint recurrence analysis methods to visualize and quantify speech-motion coordination coupling during a rap performance. We illustrate how new dynamic methods may capture this coordination in a small case-study design on this expert rap performance. We describe a case study suggesting this kind of dynamic analysis holds promise, and end by discussing the theoretical implications of studying complex performances of this kind as a dynamic, coordinated phenomenon.},
	urldate = {2022-03-09},
	journal = {Frontiers in Psychology},
	author = {Kodama, Kentaro and Shimizu, Daichi and Dale, Rick and Sekine, Kazuki},
	year = {2021},
}

@inproceedings{dinkar_local_2021,
	address = {Virtual Conference, Italy},
	title = {From local hesitations to global impressions of the listener},
	url = {https://hal.telecom-paris.fr/hal-03577262},
	urldate = {2022-03-09},
	booktitle = {4th {International} {Conference} on {Natural} {Language} and {Speech} {Processing}},
	author = {Dinkar, Tanvi and Biancardi, Beatrice and Clavel, Chloé},
	month = nov,
	year = {2021},
}

@inproceedings{kumar_what_2021,
	address = {Punta Cana, Dominican Republic},
	title = {What {BERT} {Based} {Language} {Model} {Learns} in {Spoken} {Transcripts}: {An} {Empirical} {Study}},
	shorttitle = {What {BERT} {Based} {Language} {Model} {Learns} in {Spoken} {Transcripts}},
	url = {https://aclanthology.org/2021.blackboxnlp-1.25},
	doi = {10.18653/v1/2021.blackboxnlp-1.25},
	abstract = {Language Models (LMs) have been ubiquitously leveraged in various tasks including spoken language understanding (SLU). Spoken language requires careful understanding of speaker interactions, dialog states and speech induced multimodal behaviors to generate a meaningful representation of the conversation. In this work, we propose to dissect SLU into three representative properties: conversational (disfluency, pause, overtalk), channel (speaker-type, turn-tasks) and ASR (insertion, deletion, substitution). We probe BERT based language models (BERT, RoBERTa) trained on spoken transcripts to investigate its ability to understand multifarious properties in absence of any speech cues. Empirical results indicate that LM is surprisingly good at capturing conversational properties such as pause prediction and overtalk detection from lexical tokens. On the downsides, the LM scores low on turn-tasks and ASR errors predictions. Additionally, pre-training the LM on spoken transcripts restrain its linguistic understanding. Finally, we establish the efficacy and transferability of the mentioned properties on two benchmark datasets: Switchboard Dialog Act and Disfluency datasets.},
	urldate = {2022-03-09},
	booktitle = {Proceedings of the {Fourth} {BlackboxNLP} {Workshop} on {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Kumar, Ayush and Narayanan Sundararaman, Mukuntha and Vepa, Jithendra},
	month = nov,
	year = {2021},
	pages = {322--336},
}

@article{harris_co-occurrence_1957,
	title = {Co-{Occurrence} and {Transformation} in {Linguistic} {Structure}},
	volume = {33},
	issn = {00978507},
	url = {https://www.jstor.org/stable/411155?origin=crossref},
	doi = {10.2307/411155},
	number = {3},
	urldate = {2020-11-09},
	journal = {Language},
	author = {Harris, Zellig S.},
	month = jul,
	year = {1957},
	pages = {283},
}

@article{harris_discourse_1952,
	title = {Discourse {Analysis}},
	volume = {28},
	issn = {00978507},
	url = {http://www.jstor.org/stable/409987},
	number = {1},
	urldate = {2010-10-26},
	journal = {Language},
	author = {Harris, Zellig S.},
	month = mar,
	year = {1952},
	note = {ArticleType: research-article / Full publication date: Jan. - Mar., 1952 / Copyright © 1952 Linguistic Society of America},
	pages = {1--30},
}

@article{varonina_knowledge_2021,
	title = {Knowledge {Modelling} for {Establishment} of {Common} {Ground} in {Dialogue} {Systems}},
	volume = {7},
	copyright = {IJCoL is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License},
	issn = {2499-4553},
	url = {https://journals.openedition.org/ijcol/797},
	doi = {10.4000/ijcol.797},
	abstract = {The establishment and maintenance of common ground, i.e. mutual knowledge, beliefs and assumptions, is important for dialogue systems in order to be seen as valid interlocutors in both task-oriented and open-domain dialogue. It is therefore important to provide these systems with knowledge models, so that their conversations could be grounded in the knowledge about the relevant domain. Additionally, in order to facilitate understanding, dialogue systems should be able to track the knowledge about the beliefs of the user and the level of their knowledgeability, e.g., the assumptions that they hold or the extent to which a piece of knowledge has been accepted by the user and can now be considered shared. This article provides a basic overview of current research on knowledge modelling for the establishment of common ground in dialogue systems. The presented body of research is structured along three types of knowledge that can be integrated into the system: (1) factual knowledge about the world, (2) personalised knowledge about the user, (3) knowledge about user’s knowledge and beliefs. Additionally, this article discusses the presented body of research with regards to its relevance for the current state-of-the-art dialogue systems and several ideal application scenarios that future research on knowledge modelling for common ground establishment could aim for.},
	language = {en},
	number = {1 {\textbar} 2},
	urldate = {2022-03-08},
	journal = {IJCoL. Italian Journal of Computational Linguistics},
	author = {Varonina, Lina and Kopp, Stefan},
	month = dec,
	year = {2021},
	note = {Number: 1 {\textbar} 2
Publisher: Accademia University Press},
	pages = {9--26},
}

@article{cutugno_introduction_2021,
	title = {Introduction to the {Special} {Issue} on {Computational} {Dialogue} {Modelling}},
	volume = {7},
	copyright = {IJCoL is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License},
	issn = {2499-4553},
	url = {https://journals.openedition.org/ijcol/934},
	abstract = {This special issue on ‘Computational Dialogue Modelling’ discusses recent approaches for modelling pragmatics and common ground in spoken human–human and human– machine interaction. Natural Language Processing (NLP), given the most recent sci-entific discoveries in the area of intelligent systems and distributed semantics, is now able to build interactive agents whose performance is getting more powerful from year to year. Simple ‘command-based’ models and dialogue state tracking methods are ...},
	language = {en},
	number = {1 {\textbar} 2},
	urldate = {2022-03-08},
	journal = {IJCoL. Italian Journal of Computational Linguistics},
	author = {Cutugno, Francesco and Buschmeier, Hendrik},
	month = dec,
	year = {2021},
	note = {Number: 1 {\textbar} 2
Publisher: Accademia University Press},
	pages = {7--8},
}

@article{baumard_cultural_2022,
	title = {The cultural evolution of love in literary history},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-022-01292-z},
	doi = {10.1038/s41562-022-01292-z},
	abstract = {Since the late nineteenth century, cultural historians have noted that the importance of love increased during the Medieval and Early Modern European period (a phenomenon that was once referred to as the emergence of ‘courtly love’). However, more recent works have shown a similar increase in Chinese, Arabic, Persian, Indian and Japanese cultures. Why such a convergent evolution in very different cultures? Using qualitative and quantitative approaches, we leverage literary history and build a database of ancient literary fiction for 19 geographical areas and 77 historical periods covering 3,800 years, from the Middle Bronze Age to the Early Modern period. We first confirm that romantic elements have increased in Eurasian literary fiction over the past millennium, and that similar increases also occurred earlier, in Ancient Greece, Rome and Classical India. We then explore the ecological determinants of this increase. Consistent with hypotheses from cultural history and behavioural ecology, we show that a higher level of economic development is strongly associated with a greater incidence of love in narrative fiction (our proxy for the importance of love in a culture). To further test the causal role of economic development, we used a difference-in-difference method that exploits exogenous regional variations in economic development resulting from the adoption of the heavy plough in medieval Europe. Finally, we used probabilistic generative models to reconstruct the latent evolution of love and to assess the respective role of cultural diffusion and economic development.},
	language = {en},
	urldate = {2022-03-08},
	journal = {Nature Human Behaviour},
	author = {Baumard, Nicolas and Huillery, Elise and Hyafil, Alexandre and Safra, Lou},
	month = mar,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	pages = {1--17},
}

@inproceedings{aneja_understanding_2021,
	address = {New York, NY, USA},
	series = {{CHI} '21},
	title = {Understanding {Conversational} and {Expressive} {Style} in a {Multimodal} {Embodied} {Conversational} {Agent}},
	isbn = {978-1-4503-8096-6},
	url = {https://doi.org/10.1145/3411764.3445708},
	doi = {10.1145/3411764.3445708},
	abstract = {Embodied conversational agents have changed the ways we can interact with machines. However, these systems often do not meet users’ expectations. A limitation is that the agents are monotonic in behavior and do not adapt to an interlocutor. We present SIVA (a Socially Intelligent Virtual Agent), an expressive, embodied conversational agent that can recognize human behavior during open-ended conversations and automatically align its responses to the conversational and expressive style of the other party. SIVA leverages multimodal inputs to produce rich and perceptually valid responses (lip syncing and facial expressions) during the conversation. We conducted a user study (N=30) in which participants rated SIVA as being more empathetic and believable than the control (agent without style matching). Based on almost 10 hours of interaction, participants who preferred interpersonal involvement evaluated SIVA as significantly more animate than the participants who valued consideration and independence.},
	urldate = {2022-03-08},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Aneja, Deepali and Hoegen, Rens and McDuff, Daniel and Czerwinski, Mary},
	year = {2021},
	pages = {1--10},
}

@inproceedings{bliek_how_2020,
	title = {How {Can} a {Robot} {Trigger} {Human} {Backchanneling}?},
	doi = {10.1109/RO-MAN47096.2020.9223559},
	abstract = {In human communication, backchanneling is an important part of the natural interaction protocol. The purpose is to signify the listener’s attention, understanding, agreement, or to indicate that a speaker should go on talking. While the effects of backchanneling robots on humans have been investigated, studies of how and when humans backchannel to talking robots is poorly studied. In this paper we investigate how the robot’s behavior as a speaker affects a human listener’s backchanneling behavior. This is interesting in Human-Robot Interaction since backchanneling between humans has been shown to support more fluid interactions, and human-robot interaction would therefore benefit from mimicking this human communication feature. The results show that backchanneling increases when the robot exhibits backchannel-inviting cues such as pauses and gestures. Furthermore, clear differences between how a human backchannels to another human and to a robot are shown.},
	booktitle = {2020 29th {IEEE} {International} {Conference} on {Robot} and {Human} {Interactive} {Communication} ({RO}-{MAN})},
	author = {Bliek, Adna and Bensch, Suna and Hellström, Thomas},
	month = aug,
	year = {2020},
	note = {ISSN: 1944-9437},
	pages = {96--103},
}

@inproceedings{oertel_data_2016,
	address = {New York, NY, USA},
	series = {{MA3HMI} '16},
	title = {On data driven parametric backchannel synthesis for expressing attentiveness in conversational agents},
	isbn = {978-1-4503-4562-0},
	url = {https://doi.org/10.1145/3011263.3011272},
	doi = {10.1145/3011263.3011272},
	abstract = {In this study, we are using a multi-party recording as a template for building a parametric speech synthesiser which is able to express different levels of attentiveness in backchannel tokens. This allowed us to investigate i) whether it is possible to express the same perceived level of attentiveness in synthesised than in natural backchannels; ii) whether it is possible to increase and decrease the perceived level of attentiveness of backchannels beyond the range observed in the original corpus.},
	urldate = {2022-03-08},
	booktitle = {Proceedings of the {Workshop} on {Multimodal} {Analyses} enabling {Artificial} {Agents} in {Human}-{Machine} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Oertel, Catharine and Gustafson, Joakim and Black, Alan W.},
	month = nov,
	year = {2016},
	pages = {43--47},
}

@article{hernandez-fernandez_linguistic_2019,
	title = {Linguistic {Laws} in {Speech}: {The} {Case} of {Catalan} and {Spanish}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	shorttitle = {Linguistic {Laws} in {Speech}},
	url = {https://www.mdpi.com/1099-4300/21/12/1153},
	doi = {10.3390/e21121153},
	abstract = {In this work we consider Glissando Corpus—an oral corpus of Catalan and Spanish—and empirically analyze the presence of the four classical linguistic laws (Zipf’s law, Herdan’s law, Brevity law, and Menzerath–Altmann’s law) in oral communication, and further complement this with the analysis of two recently formulated laws: lognormality law and size-rank law. By aligning the acoustic signal of speech production with the speech transcriptions, we are able to measure and compare the agreement of each of these laws when measured in both physical and symbolic units. Our results show that these six laws are recovered in both languages but considerably more emphatically so when these are examined in physical units, hence reinforcing the so-called ‘physical hypothesis’ according to which linguistic laws might indeed have a physical origin and the patterns recovered in written texts would, therefore, be just a byproduct of the regularities already present in the acoustic signals of oral communication.},
	language = {en},
	number = {12},
	urldate = {2022-03-08},
	journal = {Entropy},
	author = {Hernández-Fernández, Antoni and G. Torre, Iván and Garrido, Juan-María and Lacasa, Lucas},
	month = dec,
	year = {2019},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {1153},
}

@book{croft_verbs_2012,
	address = {Oxford [England] ; New York},
	series = {Oxford linguistics},
	title = {Verbs: aspect and causal structure},
	isbn = {978-0-19-924858-2 978-0-19-924859-9},
	shorttitle = {Verbs},
	abstract = {"This book presents a model of event structure for the analysis of aspectual constructions and argument structure constructions in English and other languages. Representing the culmination of two decades of the author's research and thought, it explores the contribution of semantics to the argument-structure and tense-aspect constructions in which verbs occur, integrating the aspectual and causal structures of events. The argument is framed in relation to current and previous scholarship and takes full account of diachronic and usage-based research. Professor Croft's analysis encompasses the full range of English verb classes and is enriched throughout by a strong typological dimension: the syntax and semantics of verbs are always seen from a crosslinguistic perspective. This allows the author to demonstrate the generality of his theory and to show how it breaks new ground in predicting and explaining linguistic facts. The subject of the book is at the heart of current work in syntax and semantics and the interface between them. It will interest semanticists, syntacticians and cognitive and functional-typological linguists. The transparency of the author's style and his avoidance of theory-dependent constructs will extend its appeal to linguists of all theoretical stripes."--Publisher's website},
	publisher = {Oxford University Press},
	author = {Croft, William},
	year = {2012},
	note = {OCLC: ocn757930806},
}

@inproceedings{hoegen_end--end_2019,
	address = {New York, NY, USA},
	series = {{IVA} '19},
	title = {An {End}-to-{End} {Conversational} {Style} {Matching} {Agent}},
	isbn = {978-1-4503-6672-4},
	url = {https://doi.org/10.1145/3308532.3329473},
	doi = {10.1145/3308532.3329473},
	abstract = {We present an end-to-end voice-based conversational agent that is able to engage in naturalistic multi-turn dialogue and align with the interlocutor's conversational style. The system uses a series of deep neural network components for speech recognition, dialogue generation, prosodic analysis and speech synthesis to generate language and prosodic expression with qualities that match those of the user. We conducted a user study (N=30) in which participants talked with the agent for 15 to 20 minutes, resulting in over 8 hours of natural interaction data. Users with high consideration conversational styles reported the agent to be more trustworthy when it matched their conversational style. Whereas, users with high involvement conversational styles were indifferent. Finally, we provide design guidelines for multi-turn dialogue interactions using conversational style adaptation.},
	urldate = {2022-03-07},
	booktitle = {Proceedings of the 19th {ACM} {International} {Conference} on {Intelligent} {Virtual} {Agents}},
	publisher = {Association for Computing Machinery},
	author = {Hoegen, Rens and Aneja, Deepali and McDuff, Daniel and Czerwinski, Mary},
	month = jul,
	year = {2019},
	pages = {111--118},
}

@article{miller_tests_1958,
	title = {Tests of a {Statistical} {Explanation} of the {Rank}-{Frequency} {Relation} for {Words} in {Written} {English}},
	volume = {71},
	issn = {0002-9556},
	url = {https://www.jstor.org/stable/1419208},
	doi = {10.2307/1419208},
	number = {1},
	urldate = {2022-03-07},
	journal = {The American Journal of Psychology},
	author = {Miller, George A. and Newman, Edwin B.},
	year = {1958},
	note = {Publisher: University of Illinois Press},
	pages = {209--218},
}

@article{cuffari_participatory_2015,
	title = {From participatory sense-making to language: there and back again},
	volume = {14},
	issn = {1572-8676},
	shorttitle = {From participatory sense-making to language},
	url = {https://doi.org/10.1007/s11097-014-9404-9},
	doi = {10.1007/s11097-014-9404-9},
	abstract = {The enactive approach to cognition distinctively emphasizes autonomy, adaptivity, agency, meaning, experience, and interaction. Taken together, these principles can provide the new sciences of language with a comprehensive philosophical framework: languaging as adaptive social sense-making. This is a refinement and advancement on Maturana’s idea of languaging as a manner of living. Overcoming limitations in Maturana’s initial formulation of languaging is one of three motivations for this paper. Another is to give a response to skeptics who challenge enactivism to connect “lower-level” sense-making with “higher-order” sophisticated moves like those commonly ascribed to language. Our primary goal is to contribute a positive story developed from the enactive account of social cognition, participatory sense-making. This concept is put into play in two different philosophical models, which respectively chronicle the logical and ontogenetic development of languaging as a particular form of social agency. Languaging emerges from the interplay of coordination and exploration inherent in the primordial tensions of participatory sense-making between individual and interactive norms; it is a practice that transcends the self-other boundary and enables agents to regulate self and other as well as interaction couplings. Linguistic sense-makers are those who negotiate interactive and internalized ways of meta-regulating the moment-to-moment activities of living and cognizing. Sense-makers in enlanguaged environments incorporate sensitivities, roles, and powers into their unique yet intelligible linguistic bodies. We dissolve the problematic dichotomies of high/low, online/offline, and linguistic/nonlinguistic cognition, and we provide new boundary criteria for specifying languaging as a prevalent kind of human social sense-making.},
	language = {en},
	number = {4},
	urldate = {2019-06-18},
	journal = {Phenomenology and the Cognitive Sciences},
	author = {Cuffari, Elena Clare and Di Paolo, Ezequiel and De Jaegher, Hanne},
	month = dec,
	year = {2015},
	pages = {1089--1125},
}

@article{de_jaegher_can_2010,
	title = {Can social interaction constitute social cognition?},
	volume = {14},
	issn = {1364-6613},
	url = {http://www.cell.com/article/S1364661310001464/abstract},
	doi = {10.1016/j.tics.2010.06.009},
	abstract = {An important shift is taking place in social cognition research, away from a focus on the individual mind and toward embodied and participatory aspects of social understanding. Empirical results already imply that social cognition is not reducible to the workings of individual cognitive mechanisms. To galvanize this interactive turn, we provide an operational definition of social interaction and distinguish the different explanatory roles – contextual, enabling and constitutive – it can play in social cognition. We show that interactive processes are more than a context for social cognition: they can complement and even replace individual mechanisms. This new explanatory power of social interaction can push the field forward by expanding the possibilities of scientific explanation beyond the individual.},
	language = {English},
	number = {10},
	urldate = {2015-06-27},
	journal = {Trends in Cognitive Sciences},
	author = {De Jaegher, Hanne and Di Paolo, Ezequiel and Gallagher, Shaun},
	month = jan,
	year = {2010},
	pmid = {20674467},
	pages = {441--447},
}

@article{de_jaegher_participatory_2007,
	title = {Participatory sense-making},
	volume = {6},
	issn = {1572-8676},
	url = {https://doi.org/10.1007/s11097-007-9076-9},
	doi = {10.1007/s11097-007-9076-9},
	abstract = {As yet, there is no enactive account of social cognition. This paper extends the enactive concept of sense-making into the social domain. It takes as its departure point the process of interaction between individuals in a social encounter. It is a well-established finding that individuals can and generally do coordinate their movements and utterances in such situations. We argue that the interaction process can take on a form of autonomy. This allows us to reframe the problem of social cognition as that of how meaning is generated and transformed in the interplay between the unfolding interaction process and the individuals engaged in it. The notion of sense-making in this realm becomes participatory sense-making. The onus of social understanding thus moves away from strictly the individual only.},
	language = {en},
	number = {4},
	urldate = {2019-06-18},
	journal = {Phenomenology and the Cognitive Sciences},
	author = {De Jaegher, Hanne and Di Paolo, Ezequiel},
	month = dec,
	year = {2007},
	pages = {485--507},
}

@incollection{enfield_huh_2013,
	address = {Cambridge},
	title = {Huh? {What}? – {A} first survey in twenty-one languages},
	booktitle = {Conversational {Repair} and {Human} {Understanding}},
	publisher = {Cambridge University Press},
	author = {Enfield, N. J. and Dingemanse, Mark and Baranova, Julija and Blythe, Joe and Brown, Penelope and Dirksmeyer, Tyko and Drew, Paul and Floyd, Simeon and Gipper, Sonja and Gísladóttir, Rósa and Hoymann, Gertie and Kendrick, Kobin H. and Levinson, Stephen C. and Magyari, Lilla and Manrique, Elizabeth and Rossi, Giovanni and San Roque, Lila and Torreira, Francisco},
	editor = {Hayashi, Makoto and Raymond, Geoffrey and Sidnell, Jack},
	year = {2013},
	pages = {343--380},
}

@article{kello_scaling_2010,
	title = {Scaling laws in cognitive sciences},
	volume = {14},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S136466131000046X},
	doi = {10.1016/j.tics.2010.02.005},
	abstract = {Scaling laws are ubiquitous in nature, and they pervade neural, behavioral and linguistic activities. A scaling law suggests the existence of processes or patterns that are repeated across scales of analysis. Although the variables that express a scaling law can vary from one type of activity to the next, the recurrence of scaling laws across so many different systems has prompted a search for unifying principles. In biological systems, scaling laws can reflect adaptive processes of various types and are often linked to complex systems poised near critical points. The same is true for perception, memory, language and other cognitive phenomena. Findings of scaling laws in cognitive science are indicative of scaling invariance in cognitive mechanisms and multiplicative interactions among interdependent components of cognition.},
	number = {5},
	urldate = {2015-07-15},
	journal = {Trends in Cognitive Sciences},
	author = {Kello, Christopher T. and Brown, Gordon D. A. and Ferrer-i-Cancho, Ramon and Holden, John G. and Linkenkaer-Hansen, Klaus and Rhodes, Theo and Van Orden, Guy C.},
	month = may,
	year = {2010},
	pages = {223--232},
}

@article{ferrer-i-cancho_compression_2013,
	title = {Compression as a {Universal} {Principle} of {Animal} {Behavior}},
	volume = {37},
	copyright = {Copyright © 2013 Cognitive Science Society, Inc.},
	issn = {1551-6709},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/cogs.12061/abstract},
	doi = {10.1111/cogs.12061},
	abstract = {A key aim in biology and psychology is to identify fundamental principles underpinning the behavior of animals, including humans. Analyses of human language and the behavior of a range of non-human animal species have provided evidence for a common pattern underlying diverse behavioral phenomena: Words follow Zipf's law of brevity (the tendency of more frequently used words to be shorter), and conformity to this general pattern has been seen in the behavior of a number of other animals. It has been argued that the presence of this law is a sign of efficient coding in the information theoretic sense. However, no strong direct connection has been demonstrated between the law and compression, the information theoretic principle of minimizing the expected length of a code. Here, we show that minimizing the expected code length implies that the length of a word cannot increase as its frequency increases. Furthermore, we show that the mean code length or duration is significantly small in human language, and also in the behavior of other species in all cases where agreement with the law of brevity has been found. We argue that compression is a general principle of animal behavior that reflects selection for efficiency of coding.},
	language = {en},
	number = {8},
	urldate = {2015-07-12},
	journal = {Cognitive Science},
	author = {Ferrer-i-Cancho, Ramon and Hernández-Fernández, Antoni and Lusseau, David and Agoramoorthy, Govindasamy and Hsu, Minna J. and Semple, Stuart},
	month = nov,
	year = {2013},
	pages = {1565--1578},
}

@article{simon_class_1955,
	title = {On a {Class} of {Skew} {Distribution} {Functions}},
	volume = {42},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/2333389},
	doi = {10.2307/2333389},
	number = {3/4},
	urldate = {2022-03-03},
	journal = {Biometrika},
	author = {Simon, Herbert A.},
	year = {1955},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	pages = {425--440},
}

@article{mandelbrot_informational_1953,
	title = {An {Informational} {Theory} of the {Statistical} {Structure} of {Language}},
	language = {en},
	journal = {Communication Theory},
	author = {Mandelbrot, Benoit},
	year = {1953},
	pages = {486--502},
}

@article{estoup_les_1917,
	title = {Les mots usuels},
	volume = {58},
	urldate = {2022-03-03},
	journal = {Journal de la société statistique de Paris},
	author = {Estoup, Jean-Baptiste},
	year = {1917},
	pages = {137--140},
}

@incollection{mandelbrot_theory_1961,
	address = {New York},
	series = {Proceedings of {Symposia} in {Applied} {Mathematics}},
	title = {On the theory of word frequencies and on related {Markovian} models of discourse},
	volume = {12},
	booktitle = {Structure of language and its mathematical aspects},
	publisher = {American Mathematical Society},
	author = {Mandelbrot, Benoit},
	editor = {Jakobson, Roman},
	year = {1961},
	note = {Publisher: Am. Math. Soc. Paris},
	pages = {190--219},
}

@article{yu_zipfs_2018,
	title = {Zipf's law in 50 languages: its structural pattern, linguistic interpretation, and cognitive motivation},
	shorttitle = {Zipf's law in 50 languages},
	journal = {arXiv preprint arXiv:1807.01855},
	author = {Yu, Shuiyuan and Xu, Chunshan and Liu, Haitao},
	year = {2018},
}

@article{kim_phrasal_1999,
	title = {Phrasal {Unit} {Boundaries} and {Organization} of {Turns} and {Sequences} in {Korean} {Conversation}},
	volume = {22},
	issn = {0163-8548},
	url = {http://www.springerlink.com/content/n740256m6826025k/},
	doi = {10.1023/A:1005431826151},
	number = {2-4},
	urldate = {2010-11-04},
	journal = {Human Studies},
	author = {Kim, Kyu-hyun},
	month = oct,
	year = {1999},
	pages = {425--446},
}

@article{kim_other-initiated_1999,
	title = {Other-initiated repair sequences in {Korean} conversation: {Types} and functions},
	volume = {6},
	journal = {Discourse and Cognition},
	author = {Kim, Kyu-hyun},
	year = {1999},
	pages = {141--168},
}

@article{young_identifying_2004,
	title = {Identifying units in interaction: {Reactive} tokens in {Korean} and {English} conversations},
	volume = {8},
	issn = {1467-9841},
	shorttitle = {Identifying units in interaction},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9841.2004.00266.x/abstract},
	doi = {10.1111/j.1467-9841.2004.00266.x},
	abstract = {Reactive tokens are conversational resources by which a listener co-constructs a speaker's turn at talk. The resources that are available include the forms of the reactive tokens themselves, their duration, and their placement by the listener in the current speaker's turn. The present paper is a contrastive study of the use of these resources by Americans in English, and by Koreans in their native language and in English, and in it we show the ecological relationship between the resources that a language provides and their use in constructing active listenership. Although previous research on English has found listeners use reactive tokens to pass up the opportunity for a full turn at talk, we show that, in Korean, reactive tokens are often elicited by the current speaker and the listener is obligated to provide them. We present evidence that Korean bilinguals transfer some conversational resources from their native language when they take part in conversation in English.},
	language = {en},
	number = {3},
	urldate = {2017-10-17},
	journal = {Journal of Sociolinguistics},
	author = {Young, Richard F. and Lee, Jina},
	month = aug,
	year = {2004},
	pages = {380--407},
}

@article{roberts_interaction_2006,
	title = {The interaction of inter-turn silence with prosodic cues in listener perceptions of “trouble” in conversation},
	volume = {48},
	number = {9},
	journal = {Speech communication},
	author = {Roberts, Felicia and Francis, A. L. and Morgan, M.},
	year = {2006},
	pages = {1079--1093},
}

@article{roberts_judgments_2011,
	title = {Judgments {Concerning} the {Valence} of {Inter}-{Turn} {Silence} {Across} {Speakers} of {American} {English}, {Italian}, and {Japanese}},
	volume = {48},
	issn = {0163-853X, 1532-6950},
	url = {http://www.tandfonline.com/doi/abs/10.1080/0163853X.2011.558002},
	doi = {10.1080/0163853X.2011.558002},
	number = {5},
	urldate = {2012-04-10},
	journal = {Discourse Processes},
	author = {Roberts, Felicia and Margutti, Piera and Takano, Shoji},
	month = jun,
	year = {2011},
	pages = {331--354},
}

@article{roberts_identifying_2013,
	title = {Identifying a temporal threshold of tolerance for silent gaps after requests},
	volume = {133},
	url = {http://scitation.aip.org/content/asa/journal/jasa/133/6/10.1121/1.4802900},
	number = {6},
	urldate = {2014-02-14},
	journal = {The Journal of the Acoustical Society of America},
	author = {Roberts, Felicia and Francis, Alexander L.},
	year = {2013},
	pages = {EL471--EL477},
}

@article{figueroa_podcasting_2022,
	title = {Podcasting past the paywall: {How} diverse media allows more equitable participation in linguistic science},
	issn = {0267-1905, 1471-6356},
	shorttitle = {Podcasting past the paywall},
	url = {https://www.cambridge.org/core/journals/annual-review-of-applied-linguistics/article/abs/podcasting-past-the-paywall-how-diverse-media-allows-more-equitable-participation-in-linguistic-science/1EF22AB6B709D17E24D9ADF935D9CBCE},
	doi = {10.1017/S0267190521000118},
	abstract = {The paywall blocks broad participation in scientific discourse, and it is both financial and psychological. The financial paywall makes access to peer-reviewed research prohibitively expensive for many researchers. The psychological paywall refers to the gatekeeping nature of academic language. Elites hoard the products of scientific research and gatekeep membership in the specialist communities via arcane vocabulary and discourse structures, together with imposition of a tone that demands dispassionate engagement with topics that are urgent and painful to the participants of their research. To exclude the perspectives of those outside the ivory tower is to dismiss unique experiences and epistemologies, essentially blocking diversity of thought in linguistic science. A range of tools is needed to undermine this power structure. Here I highlight one, which is diverse media, in general, and podcasting, specifically. Podcasting brings diverse views into the conversation and allows racially offensive ideas to be understood as such so they can then be challenged. I present the case study of the putative so-called “30-million-word gap”—the claim that, by the time they are four years old, historically marginalized children are exposed to thirty million fewer words than middle- and upper-class white children. I use this notion, which is preposterous on its face, to illustrate the emancipatory potential of the podcast medium.},
	language = {en},
	urldate = {2022-03-02},
	journal = {Annual Review of Applied Linguistics},
	author = {Figueroa, Megan},
	month = mar,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	pages = {1--7},
}

@article{breazeal_recognition_2002,
	title = {Recognition of {Affective} {Communicative} {Intent} in {Robot}-{Directed} {Speech}},
	volume = {12},
	issn = {1573-7527},
	url = {https://doi.org/10.1023/A:1013215010749},
	doi = {10.1023/A:1013215010749},
	abstract = {Human speech provides a natural and intuitive interface for both communicating with humanoid robots as well as for teaching them. In general, the acoustic pattern of speech contains three kinds of information: who the speaker is, what the speaker said, and how the speaker said it. This paper focuses on the question of recognizing affective communicative intent in robot-directed speech without looking into the linguistic content. We present an approach for recognizing four distinct prosodic patterns that communicate praise, prohibition, attention, and comfort to preverbal infants. These communicative intents are well matched to teaching a robot since praise, prohibition, and directing the robot's attention to relevant aspects of a task, could be used by a human instructor to intuitively facilitate the robot's learning process. We integrate this perceptual ability into our robot's “emotion” system, thereby allowing a human to directly manipulate the robot's affective state. This has a powerful organizing influence on the robot's behavior, and will ultimately be used to socially communicate affective reinforcement. Communicative efficacy has been tested with people very familiar with the robot as well as with naïve subjects.},
	language = {en},
	number = {1},
	urldate = {2022-03-02},
	journal = {Autonomous Robots},
	author = {Breazeal, Cynthia and Aryananda, Lijin},
	month = jan,
	year = {2002},
	pages = {83--104},
}

@article{van_rooij_intentional_2011,
	title = {Intentional {Communication}: {Computationally} {Easy} or {Difficult}?},
	volume = {5},
	issn = {1662-5161},
	shorttitle = {Intentional {Communication}},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2011.00052/full},
	doi = {10.3389/fnhum.2011.00052},
	abstract = {Human intentional communication is marked by its flexibility and context sensitivity. Hypothesized brain mechanisms can provide convincing and complete explanations of the human capacity for intentional communication only insofar as they can match the computational power required for displaying that capacity. It is thus of importance for cognitive neuroscience to know how computationally complex intentional communication actually is. Though the subject of considerable debate, the computational complexity of communication remains so far unknown. In this paper we defend the position that the computational complexity of communication is not a constant, as some views of communication seem to hold, but rather a function of situational factors. We present a methodology for studying and characterizing the computational complexity of communication under different situational constraints. We illustrate our methodology for a model of the problems solved by receivers and senders during a communicative exchange. This approach opens the way to a principled identification of putative model parameters that control cognitive processes supporting intentional communication.},
	language = {English},
	urldate = {2019-04-04},
	journal = {Frontiers in Human Neuroscience},
	author = {Van Rooij, Iris and Kwisthout, Johan and Blokpoel, Mark and Szymanik, Jakub and Wareham, Todd and Toni, Ivan},
	year = {2011},
}

@article{van_rooij_tractable_2008,
	title = {The {Tractable} {Cognition} {Thesis}},
	volume = {32},
	issn = {0364-0213},
	url = {http://doi.wiley.com/10.1080/03640210801897856},
	doi = {10.1080/03640210801897856},
	language = {en},
	number = {6},
	urldate = {2016-04-25},
	journal = {Cognitive Science: A Multidisciplinary Journal},
	author = {van Rooij, Iris},
	month = sep,
	year = {2008},
	pages = {939--984},
}

@article{van_de_braak_computational_nodate,
	title = {Computational mechanisms for resolving misunderstandings},
	abstract = {Imagine discussing yesterdays dinner with a friend: It wasn’t particularly tasty. Your friend concurs, it was very salty! Thinking you were talking about the appetizer (which wasnt salty at all), youre forced to reconsider which course your friend was talking about. Was the appetizer salty to her? Was she talking about the main course? People encounter misunderstandings in everyday conversation, yet quickly and seamlessly resolve them. How people do this is an explanatory challenge: the thing being talked about (i.e., the referent) is often not physically present during the conversation. Hence, theres no easy way for interlocutors to establish common ground via ostensive signaling (e.g., by pointing at the dish). We develop a model of speakers that use pragmatic reasoning to infer the referent inferred by listeners. We explore the performance of this model using agent-based simulated conversations. The results imply necessary and sufﬁcient conditions for successful updating.},
	language = {en},
	author = {van de Braak, Laura and Blokpoel, Mark and Dingemanse, Mark and Toni, Ivan and van Rooij, Iris},
	pages = {1},
}

@article{blokpoel_deep_2019,
	title = {Deep {Analogical} {Inference} as the {Origin} of {Hypotheses}},
	volume = {11},
	issn = {1932-6246},
	url = {https://docs.lib.purdue.edu/jps/vol11/iss1/3},
	doi = {10.7771/1932-6246.1197},
	language = {en},
	number = {1},
	urldate = {2019-07-10},
	journal = {The Journal of Problem Solving},
	author = {Blokpoel, Mark and Wareham, Todd and Haselager, Pim and Toni, Ivan and van Rooij, Iris},
	month = feb,
	year = {2019},
}

@article{blokpoel_computational-level_2013,
	title = {A computational-level explanation of the speed of goal inference},
	volume = {57},
	issn = {0022-2496},
	url = {http://www.sciencedirect.com/science/article/pii/S0022249613000515},
	doi = {10.1016/j.jmp.2013.05.006},
	abstract = {The ability to understand the goals that drive another person’s actions is an important social and cognitive skill. This is no trivial task, because any given action may in principle be explained by different possible goals (e.g., one may wave ones arm to hail a cab or to swat a mosquito). To select which goal best explains an observed action is a form of abduction. To explain how people perform such abductive inferences, Baker, Tenenbaum, and Saxe (2007) proposed a computational-level theory that formalizes goal inference as Bayesian inverse planning (BIP). It is known that general Bayesian inference–be it exact or approximate–is computationally intractable (NP-hard). As the time required for computationally intractable computations grows excessively fast when scaled from toy domains to the real world, it seems that such models cannot explain how humans can perform Bayesian inferences quickly in real world situations. In this paper we investigate how the BIP model can nevertheless explain how people are able to make goal inferences quickly. The approach that we propose builds on taking situational constraints explicitly into account in the computational-level model. We present a methodology for identifying situational constraints that render the model tractable. We discuss the implications of our findings and reflect on how the methodology can be applied to alternative models of goal inference and Bayesian models in general.},
	number = {3–4},
	urldate = {2015-12-03},
	journal = {Journal of Mathematical Psychology},
	author = {Blokpoel, Mark and Kwisthout, Johan and van der Weide, Theo P. and Wareham, Todd and van Rooij, Iris},
	month = jun,
	year = {2013},
	pages = {117--133},
}

@article{sidnell_language_2012,
	title = {Language {Diversity} and {Social} {Action}},
	volume = {53},
	issn = {00113204, 15375382},
	url = {https://sslvpn.mpi.nl/stable/10.1086/,DanaInfo=www.jstor.org+665697},
	doi = {10.1086/665697},
	number = {3},
	urldate = {2012-05-12},
	journal = {Current Anthropology},
	author = {Sidnell, Jack and Enfield, N. J.},
	month = jun,
	year = {2012},
	pages = {302--333},
}

@book{sidnell_handbook_2013,
	address = {Malden, MA},
	title = {The handbook of conversation analysis},
	isbn = {978-1-4443-3208-7},
	publisher = {Blackwell Publishers},
	editor = {Sidnell, Jack and Stivers, Tanya},
	year = {2013},
}

@book{enfield_distributed_2017,
	address = {Oxford},
	title = {Distributed {Agency}},
	publisher = {Oxford University Press},
	editor = {Enfield, N. J. and Kockelman, Paul},
	year = {2017},
	note = {doi:10.1093/acprof:oso/9780190457204.003.0007},
}

@article{floyd_universals_2018,
	title = {Universals and cultural diversity in the expression of gratitude},
	volume = {5},
	copyright = {© 2018 The Authors.. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.},
	issn = {2054-5703},
	doi = {10.1098/rsos.180391},
	abstract = {Gratitude is argued to have evolved to motivate and maintain social reciprocity among people, and to be linked to a wide range of positive effects—social, psychological and even physical. But is socially reciprocal behaviour dependent on the expression of gratitude, for example by saying ‘thank you’ as in English? Current research has not included cross-cultural elements, and has tended to conflate gratitude as an emotion with gratitude as a linguistic practice, as might appear to be the case in English. Here, we ask to what extent people express gratitude in different societies by focusing on episodes of everyday life where someone seeks and obtains a good, service or support from another, comparing these episodes across eight languages from five continents. We find that expressions of gratitude in these episodes are remarkably rare, suggesting that social reciprocity in everyday life relies on tacit understandings of rights and duties surrounding mutual assistance and collaboration. At the same time, we also find minor cross-cultural variation, with slightly higher rates in Western European languages English and Italian, showing that universal tendencies of social reciprocity should not be equated with more culturally variable practices of expressing gratitude. Our study complements previous experimental and culture-specific research on gratitude with a systematic comparison of audiovisual corpora of naturally occurring social interaction from different cultures from around the world.},
	language = {en},
	number = {5},
	journal = {Royal Society Open Science},
	author = {Floyd, Simeon and Rossi, Giovanni and Baranova, Julija and Blythe, Joe and Dingemanse, Mark and Kendrick, Kobin H. and Zinken, Jörg and Enfield, N. J.},
	month = may,
	year = {2018},
	pages = {180391},
}

@book{floyd_getting_2020,
	address = {Berlin},
	series = {Diversity {Linguistics}},
	title = {Getting others to do things: {A} pragmatic typology of recruitments},
	url = {https://langsci-press.org/catalog/book/263},
	publisher = {Language Science Press},
	editor = {Floyd, Simeon and Rossi, Giovanni and Enfield, N. J.},
	year = {2020},
}

@article{levshina_frequency_2022,
	title = {Frequency, {Informativity} and {Word} {Length}: {Insights} from {Typologically} {Diverse} {Corpora}},
	volume = {24},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	shorttitle = {Frequency, {Informativity} and {Word} {Length}},
	url = {https://www.mdpi.com/1099-4300/24/2/280},
	doi = {10.3390/e24020280},
	abstract = {Zipf’s law of abbreviation, which posits a negative correlation between word frequency and length, is one of the most famous and robust cross-linguistic generalizations. At the same time, it has been shown that contextual informativity (average surprisal given previous context) is more strongly correlated with word length, although this tendency is not observed consistently, depending on several methodological choices. The present study examines a more diverse sample of languages than the previous studies (Arabic, Finnish, Hungarian, Indonesian, Russian, Spanish and Turkish). I use large web-based corpora from the Leipzig Corpora Collection to estimate word lengths in UTF-8 characters and in phonemes (for some of the languages), as well as word frequency, informativity given previous word and informativity given next word, applying different methods of bigrams processing. The results show different correlations between word length and the corpus-based measure for different languages. I argue that these differences can be explained by the properties of noun phrases in a language, most importantly, by the order of heads and modifiers and their relative morphological complexity, as well as by orthographic conventions.},
	language = {en},
	number = {2},
	urldate = {2022-02-21},
	journal = {Entropy},
	author = {Levshina, Natalia},
	month = feb,
	year = {2022},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {280},
}

@article{knudsen_forgotten_2020,
	title = {Forgotten {Little} {Words}: {How} {Backchannels} and {Particles} {May} {Facilitate} {Speech} {Planning} in {Conversation}?},
	volume = {11},
	issn = {1664-1078},
	shorttitle = {Forgotten {Little} {Words}},
	doi = {10.3389/fpsyg.2020.593671},
	abstract = {In everyday conversation, turns often follow each other immediately or overlap in time. It has been proposed that speakers achieve this tight temporal coordination between their turns by engaging in linguistic dual-tasking, i.e., by beginning to plan their utterance during the preceding turn. This raises the question of how speakers manage to co-ordinate speech planning and listening with each other. Experimental work addressing this issue has mostly concerned the capacity demands and interference arising when speakers retrieve some content words while listening to others. However, many contributions to conversations are not content words, but backchannels, such as ‘hm’. Backchannels do not provide much conceptual content and are therefore easy to plan and respond to. To estimate how much they might facilitate speech planning in conversation, we determined their frequency in a Dutch and a German corpus of conversational speech. We found that 19\% of the contributions in the Dutch corpus, and 16\% of contributions in the German corpus were backchannels. In addition, many turns began with fillers or particles, most often translation equivalents of ‘yes’ or ‘no’, which are likewise easy to plan. We proposed that to generate comprehensive models of using language in conversation psycholinguists should study not only the generation and processing of content words, as is commonly done, but also consider backchannels, fillers, and particles.},
	language = {English},
	journal = {Frontiers in Psychology},
	author = {Knudsen, Birgit and Creemers, Ava and Meyer, Antje S.},
	year = {2020},
	note = {Publisher: Frontiers},
}

@article{drummond_back_1993,
	title = {Back {Channels} {Revisited}: {Acknowledgment} {Tokens} and {Speakership} {Incipiency}},
	volume = {26},
	issn = {0835-1813, 1532-7973},
	shorttitle = {Back {Channels} {Revisited}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi2602_3},
	doi = {10.1207/s15327973rlsi2602_3},
	urldate = {2011-11-17},
	journal = {Research on Language \& Social Interaction},
	author = {Drummond, Kent and Hopper, Robert},
	month = apr,
	year = {1993},
	pages = {157--177},
}

@book{bateson_steps_1972,
	title = {Steps to an ecology of mind; collected essays in anthropology, psychiatry, evolution, and epistemology},
	isbn = {0-8102-0447-9 978-0-8102-0447-8 0-345-27370-2 978-0-345-27370-3},
	publisher = {University of Chicago Press},
	author = {Bateson, Gregory},
	year = {1972},
}

@book{ruhlemann_corpus_2019,
	address = {Abingdon, Oxon ; New York, NY},
	series = {Routledge corpus linguistics guides},
	title = {Corpus linguistics for pragmatics: a guide for research},
	isbn = {978-1-138-71874-6 978-1-138-71878-4},
	shorttitle = {Corpus linguistics for pragmatics},
	abstract = {"Corpus Linguistics for Pragmatics provides a practical and comprehensive introduction to the growing field of corpus pragmatics. Taking a hands-on approach to showcase the applications of corpora in the exploration of core topics within pragmatics, this book: - covers five key areas of corpus-pragmatic research including speech acts, deixis, pragmatic markers, evaluation, conversational structure, and multimodality; - demonstrates the use of freely-available corpora, corpus interfaces and corpus analysis tools to conduct original pragmatic analyses; - is accompanied by an e-resource which hosts multimodal data sets for additional exercises. Featuring case studies and practical tasks within each chapter, Corpus Linguistics for Pragmatics is an essential guide for students and researchers studying or conducting their own corpus-based research in pragmatics"--},
	publisher = {Routledge},
	author = {Rühlemann, Christoph},
	year = {2019},
}

@article{ruhlemann_turn_2015,
	title = {Turn order and turn distribution in multi-party storytelling},
	volume = {87},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/S0378216615002416},
	doi = {10.1016/j.pragma.2015.08.003},
	abstract = {In this paper we examine turntaking patterns in conversational storytelling. It has long been noted that turntaking in every-day narrative differs on a number of counts from turntaking in regular conversation. The differences, however, have, at best, been researched qualitatively based on casual observations and small datasets. Here, we base our analysis on two specialized corpora of conversational narrative, the Saarbrücken Corpus of Spoken English (SCOSE) containing American English 4- and 5-party stories and the Narrative Corpus (NC) containing British English 4- to 7-party narratives, as well as the conversational component of the British National Corpus (BNC). The analysis is decidedly quantitative and statistical in orientation. Specifically, we are concerned with turn order and turn distribution in conversational multi-party narrative. The aims are twofold. We wish to examine the validity of Sacks’ description of storytelling as “an attempt to control a third slot in talk, from a first” (Sacks, 1992:18), a turn order pattern we refer to as the N-notN-N pattern. We further investigate whether individual speakers’ turntaking styles have an impact on turn distribution, a measure intimately related to turn order. Moreover, given the structural differences in the data at hand (the SCOSE being raw-text, the NC being densely annotated) we employ largely different methodologies particularly in addressing turn order. The results on turntaking styles suggest that this factor cannot account for the noticeable increase in the narrator's turn share as soon as the conversational activity moves into storytelling. The results on turn order reveal the N-notN-N pattern's statistical overrepresentation in all multi-party narrative types examined. The implications of this finding are far-reaching. First, Sacks et al.’s dictum that turn order is not fixed in advance does not hold true for conversational narrative. Also, turn order in conversational narrative is not locally controlled, on a turn-by-turn basis, but globally, on the basis of the activity the conversationalists are involved in, viz. storytelling.

Second, a fundamental correlate of the N-notN-N pattern is the avoidance of double-responses, that is, of two consecutive response turns following the narrator's turn. This avoidance suggests that the turn order system underlying multi-party narrative is that of 2-party talk. Further, the double-response avoidance suggests the possibility that the source of the turn-order bias in narrative is a tacit agreement between the recipients to promote the single-recipient filling the single-response slot to a ‘spokesperson’ taking the turn on behalf of all other recipients. We also note the possibility of there being a recipient-subsystem for turntaking at the single-response slot interacting with the narrator-recipient turntaking organization but still, to an extent, working on its own terms.},
	urldate = {2015-09-17},
	journal = {Journal of Pragmatics},
	author = {Rühlemann, Christoph and Gries, Stefan},
	month = oct,
	year = {2015},
	pages = {171--191},
}

@book{ruhlemann_visual_2020,
	address = {Amsterdam},
	title = {Visual {Linguistics} with {R}: {A} practical introduction to quantitative {Interactional} {Linguistics}},
	isbn = {978-90-272-0709-8 978-90-272-0710-4 978-90-272-6098-7},
	shorttitle = {Visual {Linguistics} with {R}},
	url = {http://www.jbe-platform.com/content/books/9789027260987},
	language = {en},
	urldate = {2021-10-22},
	publisher = {John Benjamins Publishing Company},
	author = {Rühlemann, Christoph},
	month = jul,
	year = {2020},
	doi = {10.1075/z.228},
}

@article{ruhlemann_tcu-initial_2018,
	title = {{TCU}-initial backchannel overlap in storytelling},
	volume = {28},
	issn = {1387-6740, 1569-9935},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ni.17060.ruh},
	doi = {10.1075/ni.17060.ruh},
	abstract = {Abstract While overlap represents one of the major mainstays of conversation-analytic research, the phenomenon of overlap involving backchannels in TCU-initial position has largely gone unnoticed. This study addresses this gap focusing on backchannels occurring in overlap in storytelling interaction. The investigation combines both quantitative and qualitative methods and is based on small but representative samples drawn from the audio files available for the Narrative Corpus. The primary discovery of this study is that TCU-initial backchannel overlaps typically occur at points where the storytelling’s progressivity is decelerated, either due to delays in the backchannel’s production or to the teller interrupting the telling’s linearity to insert background information, upgrade references, or slip in digressions. An alternative environment for the occurrence of TCU-initial backchannel overlap is around the story climax. Data are in British English.},
	language = {en},
	number = {2},
	urldate = {2018-10-29},
	journal = {Narrative Inquiry},
	author = {Rühlemann, Christoph},
	month = oct,
	year = {2018},
	pages = {257--279},
}

@article{ruhlemann_integrating_2017,
	title = {Integrating {Corpus}-{Linguistic} and {Conversation}-{Analytic} {Transcription} in {XML}: {The} {Case} of {Backchannels} and {Overlap} in {Storytelling} {Interaction}},
	issn = {2509-9507, 2509-9515},
	shorttitle = {Integrating {Corpus}-{Linguistic} and {Conversation}-{Analytic} {Transcription} in {XML}},
	url = {https://link.springer.com/article/10.1007/s41701-017-0018-7},
	doi = {10.1007/s41701-017-0018-7},
	abstract = {This paper sketches out and illustrates the research opportunities that come with the recent addition to BNCweb of very large numbers of audio files for the spoken component in the BNC. It aims to demonstrate that the availability of the audio files enables researchers not only to correct the orthographic transcripts, but also to re-transcribe the conversations using conversation-analytic transcription. It also shows that the CA transcripts can be integrated into the BNC’s XML annotation network and illustrates how XML query tools such as XPath and XQuery can be used to efficiently exploit the XML network. The main thrust of the paper is to argue that the integration of corpus-linguistic and conversation-analytic transcription in XML can make major contributions both to CL and CA. CL research into conversation can for the first time be performed on the basis of transcription that is “detailed enough to facilitate the analyst’s quest to discover and describe orderly practices of social action in interaction” (Hepburn and Bolden, in: Sidnell, Stivers (eds) The handbook of conversation analysis, Wiley Malden, 2013: 58) while CA research can gain a large-scale quantitative basis to substantiate claims about the generalizability of observed regularities and patterns in talk-in-interaction. To illustrate the benefits of doing research on re-transcriptions of the BNC’s audio files, a case study is presented on backchannels occurring in overlap in storytelling interaction. The case study reveals, inter alia, that backchannels produced by story recipients simultaneously with parts of the storyteller’s ongoing turn tend to increase in frequency as the storytelling reaches its climax. Backchannel overlap is thus in synchrony with story organization. This finding adds weight to Goodwin’s observation that recipients attend to the task “not simply of listening to the events being recounted but rather of distinguishing different subcomponents of the talk in terms of the alternative possibilities for action they invoke” (Goodwin, in: Atkinson, Heritage (eds) Structures of social action: studies in conversation analysis, Cambridge University Press, Cambridge, 1984: 243). The case study also presents exploratory evidence to suggest that, arguably due to the extended length of storytelling turns (Ochs and Capps in Living narrative, Harvard University Press, Cambridge, 2001), the proportion of overlap in running speech may be considerably lower in storytelling than in general conversation and telephone conversation.},
	language = {en},
	urldate = {2017-06-21},
	journal = {Corpus Pragmatics},
	author = {Rühlemann, Christoph},
	month = jun,
	year = {2017},
	pages = {1--32},
}

@misc{boersma_praat_2013,
	title = {Praat: doing phonetics by computer},
	url = {http://www.praat.org/},
	urldate = {2013-09-30},
	author = {Boersma, Paul and Weenink, David},
	year = {2013},
}

@article{winter_co-evolution_2016,
	title = {The {Co}-evolution of {Speech} and the {Lexicon}: {The} {Interaction} of {Functional} {Pressures}, {Redundancy}, and {Category} {Variation}},
	volume = {8},
	copyright = {Copyright © 2016 Cognitive Science Society, Inc.},
	issn = {1756-8765},
	shorttitle = {The {Co}-evolution of {Speech} and the {Lexicon}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/tops.12202/abstract},
	doi = {10.1111/tops.12202},
	abstract = {The sound system of a language must be able to support a perceptual contrast between different words in order to signal communicatively relevant meaning distinctions. In this paper, we use a simple agent-based exemplar model in which the evolution of sound-category systems is understood as a co-evolutionary process, where the range of variation within sound categories is constrained by functional pressure to keep different words perceptually distinct. We show that this model can reproduce several observed effects on the range of sound variation. We argue that phonological systems can be seen as finding a relative optimum of variation: Efficient communication is sustained while at the same time, hidden category variation provides pathways for future evolution.},
	language = {en},
	urldate = {2016-03-16},
	journal = {Topics in Cognitive Science},
	author = {Winter, Bodo and Wedel, Andrew},
	month = mar,
	year = {2016},
	pages = {503--513},
}

@article{pouw_systematic_2021,
	title = {A {Systematic} {Investigation} of {Gesture} {Kinematics} in {Evolving} {Manual} {Languages} in the {Lab}},
	volume = {45},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.13014},
	doi = {10.1111/cogs.13014},
	abstract = {Silent gestures consist of complex multi-articulatory movements but are now primarily studied through categorical coding of the referential gesture content. The relation of categorical linguistic content with continuous kinematics is therefore poorly understood. Here, we reanalyzed the video data from a gestural evolution experiment (Motamedi, Schouwstra, Smith, Culbertson, \& Kirby, 2019), which showed increases in the systematicity of gesture content over time. We applied computer vision techniques to quantify the kinematics of the original data. Our kinematic analyses demonstrated that gestures become more efficient and less complex in their kinematics over generations of learners. We further detect the systematicity of gesture form on the level of thegesture kinematic interrelations, which directly scales with the systematicity obtained on semantic coding of the gestures. Thus, from continuous kinematics alone, we can tap into linguistic aspects that were previously only approachable through categorical coding of meaning. Finally, going beyond issues of systematicity, we show how unique gesture kinematic dialects emerged over generations as isolated chains of participants gradually diverged over iterations from other chains. We, thereby, conclude that gestures can come to embody the linguistic system at the level of interrelationships between communicative tokens, which should calibrate our theories about form and linguistic content.},
	language = {en},
	number = {7},
	urldate = {2021-07-19},
	journal = {Cognitive Science},
	author = {Pouw, Wim and Dingemanse, Mark and Motamedi, Yasamin and Özyürek, Aslı},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.13014},
	pages = {e13014},
}

@book{bybee_language_2010,
	address = {Cambridge},
	title = {Language, {Usage}, and {Cognition}},
	isbn = {978-0-521-85140-4},
	publisher = {Cambridge University Press},
	author = {Bybee, Joan L.},
	year = {2010},
}

@book{bybee_frequency_2001,
	address = {Amsterdam; Philadelphia, PA},
	title = {Frequency and the emergence of linguistic structure},
	isbn = {1-58811-027-3 978-1-58811-027-5 1-58811-028-1 978-1-58811-028-2 90-272-2947-3 978-90-272-2947-2 90-272-2948-1 978-90-272-2948-9},
	language = {English},
	publisher = {John Benjamins Pub. Co.},
	editor = {Bybee, Joan L. and Hopper, Paul J.},
	year = {2001},
}

@book{bybee_frequency_2007,
	address = {Oxford},
	title = {Frequency of use and the organization of language},
	publisher = {Oxford University Press},
	author = {Bybee, Joan L.},
	year = {2007},
}

@article{konrad_reiner_public_2020,
	title = {Public {DGS} {Corpus}: {Annotation} {Conventions} / Öffentliches {DGS}-{Korpus}: {Annotationskonventionen}},
	copyright = {Creative Commons Attribution, Open Access},
	shorttitle = {Public {DGS} {Corpus}},
	url = {https://www.fdr.uni-hamburg.de/record/822},
	doi = {10.25592/UHHFDM.822},
	abstract = {Project note for work package 03 “Transkriptionsmethodik / Transcription Methodology” produced in the DGS-Korpus project.{\textless}br{\textgreater} This project note describes the annotation and glossing conventions as they apply to the Public DGS Corpus. In many aspects, they are identical to the annotation guidelines used in the DGS-Korpus project. However, not all aspects dealt with in the annotation show in Public Corpus. E.g. our annotation differentiates between different word forms by using qualifiers whereas the Public Corpus annotation just marks tokens as deviating from the citation form.{\textless}br{\textgreater} In addition to explaining the annotation in translation and of mouthings, segmentation and lemmatisation, this texts explains specific approaches such as double glossing, double-token tags and lists special glosses used in the Public DGS Corpus. Glosses as well as some tokens are hyperlinked into the actual data, so the reader is invited to view both the original video as well as the annotation. The first appendix provides an overview of all symbols and gloss categories while the second lists the fingerspelling forms as used in DGS.},
	urldate = {2022-02-11},
	author = {Konrad, Reiner and Hanke, Thomas and Langer, Gabriele and König, Susanne and König, Lutz and Nishio, Rie and Regen, Anja},
	month = sep,
	year = {2020},
	note = {Publisher: Universität Hamburg
Version Number: 3},
}

@article{mesch_manual_2016,
	title = {Manual backchannel responses in signers' conversations in {Swedish} {Sign} {Language}},
	volume = {50},
	issn = {0271-5309},
	url = {http://www.sciencedirect.com/science/article/pii/S0271530916301215},
	doi = {10.1016/j.langcom.2016.08.011},
	abstract = {The current study aims to determine the manual backchannel responses that signers use in Swedish Sign Language discourse by analyzing a subset of the SSL Corpus. The investigation found 20\% of the backchannel responses in this data to be manual. The study focuses on the manual backchannel responses that consist of signs (mostly the sign gloss YES) and gesture-like signs (PU “palms up”), and other manual activities, which can occur at a relatively low height in signing space. With respect to age groups, younger signers engage in more weak manual activity than older signers.},
	language = {en},
	urldate = {2019-11-06},
	journal = {Language \& Communication},
	author = {Mesch, Johanna},
	month = sep,
	year = {2016},
	pages = {22--41},
}

@article{borstell_distribution_2016,
	title = {Distribution and duration of signs and parts of speech in {Swedish} {Sign} {Language}},
	volume = {19},
	issn = {1387-9316, 1569-996X},
	url = {http://www.jbe-platform.com/content/journals/10.1075/sll.19.2.01bor},
	doi = {10.1075/sll.19.2.01bor},
	abstract = {In this paper, we investigate frequency and duration of signs and parts of speech in Swedish Sign Language (SSL) using the SSL Corpus. The duration of signs is correlated with frequency, with high-frequency items having shorter duration than low-frequency items. Similarly, function words (e.g. pronouns) have shorter duration than content words (e.g. nouns). In compounds, forms annotated as reduced display shorter duration. Fingerspelling duration correlates with word length of corresponding Swedish words, and frequency and word length play a role in the lexicalization of fingerspellings. The sign distribution in the SSL Corpus shows a great deal of cross-linguistic similarity with other sign languages in terms of which signs appear as high-frequency items, and which categories of signs are distributed across text types (e.g. conversation vs. narrative). We find a correlation between an increase in age and longer mean sign duration, but see no significant difference in sign duration between genders.},
	language = {en},
	number = {2},
	urldate = {2019-08-30},
	journal = {Sign Language \& Linguistics},
	author = {Börstell, Carl and Hörberg, Thomas and Östling, Robert},
	month = dec,
	year = {2016},
	pages = {143--196},
}

@article{homke_eye_2018,
	title = {Eye blinks are perceived as communicative signals in human face-to-face interaction},
	volume = {13},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0208030},
	doi = {10.1371/journal.pone.0208030},
	abstract = {In face-to-face communication, recurring intervals of mutual gaze allow listeners to provide speakers with visual feedback (e.g. nodding). Here, we investigate the potential feedback function of one of the subtlest of human movements—eye blinking. While blinking tends to be subliminal, the significance of mutual gaze in human interaction raises the question whether the interruption of mutual gaze through blinking may also be communicative. To answer this question, we developed a novel, virtual reality-based experimental paradigm, which enabled us to selectively manipulate blinking in a virtual listener, creating small differences in blink duration resulting in ‘short’ (208 ms) and ‘long’ (607 ms) blinks. We found that speakers unconsciously took into account the subtle differences in listeners’ blink duration, producing substantially shorter answers in response to long listener blinks. Our findings suggest that, in addition to physiological, perceptual and cognitive functions, listener blinks are also perceived as communicative signals, directly influencing speakers’ communicative behavior in face-to-face communication. More generally, these findings may be interpreted as shedding new light on the evolutionary origins of mental-state signaling, which is a crucial ingredient for achieving mutual understanding in everyday social interaction.},
	language = {en},
	number = {12},
	urldate = {2018-12-13},
	journal = {PLOS ONE},
	author = {Hömke, Paul and Holler, Judith and Levinson, Stephen C.},
	month = dec,
	year = {2018},
	pages = {e0208030},
}

@article{homke_eye_2017,
	title = {Eye {Blinking} as {Addressee} {Feedback} in {Face}-{To}-{Face} {Conversation}},
	volume = {0},
	issn = {0835-1813},
	url = {http://dx.doi.org/10.1080/08351813.2017.1262143},
	doi = {10.1080/08351813.2017.1262143},
	abstract = {Does blinking function as a type of feedback in conversation? To address this question, we built a corpus of Dutch conversations, identified short and long addressee blinks during extended turns, and measured their occurrence relative to the end of turn constructional units (TCUs), the location where feedback typically occurs. Addressee blinks were indeed timed to the end of TCUs. Also, long blinks were more likely than short blinks to occur during mutual gaze, with nods or continuers, and their occurrence was restricted to sequential contexts in which signaling understanding was particularly relevant, suggesting a special signaling capacity of long blinks.},
	number = {0},
	urldate = {2017-02-07},
	journal = {Research on Language and Social Interaction},
	author = {Hömke, Paul and Holler, Judith and Levinson, Stephen C.},
	month = feb,
	year = {2017},
	pages = {1--17},
}

@article{van_rooij_psychological_2022,
	title = {Psychological models and their distractors},
	copyright = {2022 Springer Nature America, Inc.},
	issn = {2731-0574},
	url = {https://www.nature.com/articles/s44159-022-00031-5},
	doi = {10.1038/s44159-022-00031-5},
	abstract = {The lack of models in psychology hinders scientific progress. To start addressing this problem, we need a clear understanding of what models are and what they are not. The lack of models in psychology hinders scientific progress. To start addressing this problem, we need a clear understanding of what models are and what they are not.},
	language = {en},
	urldate = {2022-02-11},
	journal = {Nature Reviews Psychology},
	author = {van Rooij, Iris},
	month = feb,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	pages = {1--2},
}

@incollection{garfinkel_studies_1967,
	address = {Englewood Cliffs, New Jersey},
	title = {Studies of the routine grounds of everyday activities},
	booktitle = {Studies in {Ethnomethodology}},
	publisher = {Prentice-Hall},
	author = {Garfinkel, Harold},
	editor = {Garfinkel, Harold},
	year = {1967},
	pages = {35--75},
}

@book{garfinkel_studies_1967,
	address = {Englewood Cliffs, New Jersey},
	title = {Studies in {Ethnomethodology}},
	publisher = {Prentice-Hall},
	editor = {Garfinkel, Harold},
	year = {1967},
}

@incollection{garfinkel_two_1992,
	address = {Newbury Park, CA},
	title = {Two incommensurable, asymmetrically alternate technologies of social analysis},
	booktitle = {Text in {Context}: {Studies} in {Ethnomethodology}},
	publisher = {Sage},
	author = {Garfinkel, Harold and Wieder, D. Lawrence},
	editor = {Watson, Graham and Seiler, Robert M.},
	year = {1992},
	pages = {175--206},
}

@incollection{garfinkel_formal_1986,
	address = {London; New York},
	title = {On formal structures of practical actions},
	isbn = {978-0-7100-9664-7 978-0-203-99686-7 978-0-415-11965-8},
	abstract = {This unique collection will be essential reading for all researchers and students doing courses in ethnomethodology, organization studies and the sociology of work.},
	language = {English},
	booktitle = {Ethnomethodological studies of work},
	publisher = {Routledge \& K. Paul},
	author = {Garfinkel, Harold and Sacks, Harvey},
	collaborator = {Garfinkel, Harold},
	year = {1986},
	note = {OCLC: 12810452},
	pages = {157--},
}

@article{garfinkel_studies_1964,
	title = {Studies of the {Routine} {Grounds} of {Everyday} {Activities}},
	volume = {11},
	issn = {0037-7791},
	url = {http://www.jstor.org/stable/798722},
	number = {3},
	urldate = {2012-04-11},
	journal = {Social Problems},
	author = {Garfinkel, Harold},
	month = jan,
	year = {1964},
	note = {ArticleType: research-article / Full publication date: Winter, 1964 / Copyright © 1964 University of California Press},
	pages = {225--250},
}

@article{garfinkel_rational_1960,
	title = {The rational properties of scientific and common sense activities},
	volume = {5},
	issn = {1099-1743},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/bs.3830050106/abstract},
	doi = {10.1002/bs.3830050106},
	abstract = {When one says “John is a more rational person than Henry,” many meanings of the word “rational” can be distinguished. Some of these meanings are related to affairs of everyday life, some to affairs of scientific theorizing, and it is the scientific rationalities that writers on social organization and decision making commonly refer to as features of “rational choice.” It is here suggested that other meanings of rationality should be taken into account and treated as data in empirical research.},
	language = {en},
	number = {1},
	urldate = {2017-02-26},
	journal = {Behavioral Science},
	author = {Garfinkel, Harold},
	month = jan,
	year = {1960},
	pages = {72--83},
}

@article{gardner_question_2010,
	title = {Question and {Answer} {Sequences} in {Garrwa} {Talk}},
	volume = {30},
	issn = {0726-8602},
	url = {http://www.informaworld.com/10.1080/07268602.2010.518554},
	doi = {10.1080/07268602.2010.518554},
	number = {4},
	urldate = {2010-12-17},
	journal = {Australian Journal of Linguistics},
	author = {Gardner, Rod},
	year = {2010},
	pages = {423},
}

@article{gardner_between_1998,
	title = {Between {Speaking} and {Listening}: {The} {Vocalisation} of {Understandings}},
	volume = {19},
	issn = {0142-6001},
	shorttitle = {Between {Speaking} and {Listening}},
	url = {https://academic.oup.com/applij/article/19/2/204/316321/Between-Speaking-and-Listening-The-Vocalisation-of},
	doi = {10.1093/applin/19.2.204},
	abstract = {In the teaching of listening in language pedagogy, there has been a tendency either to treat this skill as discrete from speaking, particularly as extended texts to be responded to after hearing them, or to focus on speaking rather than listening in the teaching of conversational skills This paper argues that there are some important aspects of listening as an interactive skill that have been largely neglected Amongst these are what have been characterised in the literature as backchannels (Yngve 1970), minimal response (e g Coates 1986) or receipt tokens (eg Heritage 1984a), and include items such as Yeah, Oh, Right, and Great Such vocalisations produced by those in primarily listening roles at any particular moment in spoken interaction provide information to a primary speaker about how their contributions have been understood, and can have a crucial influence on the trajectory of talk This paper argues that such items might profitably be taught as part of the development of conversational skills, and provides a characterisation of three of them. Yeah, Mm hm and Mm, to illustrate some of their characteristics in terms of placement in sequences of talk, prosodic shape, pause environment and speakership incipiency Some comments on pedagogical implications are made.},
	number = {2},
	urldate = {2017-10-17},
	journal = {Applied Linguistics},
	author = {Gardner, Rod},
	month = jun,
	year = {1998},
	pages = {204--224},
}

@book{gardner_when_2001,
	address = {Amsterdam},
	series = {Pragmatics \& {Beyond}},
	title = {When {Listeners} {Talk}: {Response} {Tokens} and {Listener} {Stance}},
	isbn = {1-58811-093-1},
	shorttitle = {When {Listeners} {Talk}},
	publisher = {John Benjamins},
	author = {Gardner, Rod},
	year = {2001},
}

@article{gardner_conversation_1997,
	title = {The {Conversation} {Object} {Mm}: {A} {Weak} and {Variable} {Acknowledging} {Token}},
	volume = {30},
	issn = {0835-1813},
	shorttitle = {The {Conversation} {Object} {Mm}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi3002_2},
	doi = {10.1207/s15327973rlsi3002_2},
	number = {2},
	urldate = {2011-07-19},
	journal = {Research on Language \& Social Interaction},
	author = {Gardner, Rod},
	month = apr,
	year = {1997},
	pages = {131--156},
}

@article{dingemanse_is_2013,
	title = {Is "{Huh}?" a universal word? {Conversational} infrastructure and the convergent evolution of linguistic items},
	volume = {8},
	doi = {10.1371/journal.pone.0078273},
	number = {11},
	journal = {PLOS ONE},
	author = {Dingemanse, Mark and Torreira, Francisco and Enfield, N. J.},
	year = {2013},
	pages = {e78273},
}

@article{croft_word_2005,
	title = {Word classes, parts of speech, and syntactic argumentation},
	volume = {9},
	issn = {1430-0532},
	shorttitle = {Mundari},
	url = {http://www.reference-global.com/doi/abs/10.1515/lity.2005.9.3.351},
	doi = {10.1515/lity.2005.9.3.351},
	number = {3},
	urldate = {2010-10-08},
	journal = {Linguistic Typology},
	author = {Croft, William},
	month = dec,
	year = {2005},
	pages = {431--441},
}

@article{croft_form_2004,
	title = {Form, meaning and speakers in the evolution of language: {Commentary} on {Kirby}, {Smith} and {Brighton}},
	volume = {28},
	shorttitle = {Form, meaning and speakers in the evolution of language},
	url = {http://www.ingentaconnect.com/content/jbp/sl/2004/00000028/00000003/art00009},
	doi = {10.1075/sl.28.3.10cro},
	urldate = {2008-10-20},
	journal = {Studies in Language},
	author = {Croft, William},
	year = {2004},
	pages = {608--611},
}

@book{croft_explaining_2000,
	address = {Harlow},
	title = {Explaining {Language} {Change}: {An} {Evolutionary} {Approach}},
	publisher = {Pearson Education Limited},
	author = {Croft, William},
	year = {2000},
}

@article{croft_evolutionary_2008,
	title = {Evolutionary {Linguistics}},
	volume = {37},
	copyright = {Copyright c 2008 by Annual Reviews. All rights reserved},
	url = {http://arjournals.annualreviews.org/doi/abs/10.1146/annurev.anthro.37.081407.085156},
	doi = {annurev.anthro.37.081407.085156},
	abstract = {Both qualitative concepts and quantitative methods from evolutionary biology have been applied to linguistics. Many linguists have noted the similarity between biological evolution and language change, but usually have employed only selective analogies or metaphors. The development of generalized theories of evolutionary change (Dawkins and Hull) has spawned models of language change on the basis of such generalized theories. These models have led to the positing of new mechanisms of language change and new types of selection that may not have biological parallels. Quantitative methods have been applied to questions of language phylogeny in the past decade. Research has focused on widely accepted families with cognates already established by the comparative method (Indo-European, Bantu, Austronesian). Increasingly sophisticated phylogeny reconstruction models have been applied to these families to resolve questions of subgrouping, contact, and migration. Little progress has been made so far in analyzing sound correspondences in the cognates themselves.},
	urldate = {2008-10-20},
	journal = {Annual Review of Anthropology},
	author = {Croft, William},
	month = sep,
	year = {2008},
	note = {Both qualitative concepts and quantitative methods from evolutionary biology have been applied to linguistics. Many linguists have noted the similarity between biological evolution and language change, but usually have employed only selective analogies or metaphors. The development of generalized theories of evolutionary change (Dawkins and Hull) has spawned models of language change on the basis of such generalized theories. These models have led to the positing of new mechanisms of language change and new types of selection that may not have biological parallels. Quantitative methods have been applied to questions of language phylogeny in the past decade. Research has focused on widely accepted families with cognates already established by the comparative method (Indo-European, Bantu, Austronesian). Increasingly sophisticated phylogeny reconstruction models have been applied to these families to resolve questions of subgrouping, contact, and migration. Little progress has been made so far in analyzing s...},
	pages = {219--234},
}

@article{croft_darwinization_2002,
	title = {The {Darwinization} of linguistics},
	volume = {3},
	url = {http://www.akademiai.com/index/X573336560639U7W.pdf},
	number = {1},
	urldate = {2013-09-08},
	journal = {Selection},
	author = {Croft, William},
	year = {2002},
	pages = {75--91},
}

@book{croft_radical_2001,
	address = {Oxford},
	title = {Radical {Construction} {Grammar}},
	publisher = {Oxford University Press},
	author = {Croft, William},
	year = {2001},
}

@book{bateson_mind_1979,
	address = {New York},
	title = {Mind and {Nature}},
	publisher = {E.P. Dutton},
	author = {Bateson, Gregory},
	year = {1979},
}

@book{muller_lectures_1861,
	address = {London},
	title = {Lectures on the {Science} of {Language}},
	volume = {1},
	language = {en},
	publisher = {Longmans, Green},
	author = {Müller, Max},
	year = {1861},
}

@article{temer_non-convergent_2021,
	title = {Non-convergent boundaries and action ascription in multimodal interaction},
	volume = {7},
	issn = {2300-9969},
	url = {https://www.degruyter.com/document/doi/10.1515/opli-2020-0170/html},
	doi = {10.1515/opli-2020-0170},
	abstract = {Without units, there are no boundaries; and without boundaries, there are no units. Traditional linguistics takes units such as sentences and intonation phrases for granted, treating them as static. Interactional linguistics has reconfigured many of these units, treating them as emergent, focusing on their evolution in time, and how they implement social actions. A productive line of research of interactional linguistics has been this tension between conventional linguistic units and units of (and for) interaction (Reed and Beatrice 2013; Ogden and Walker 2013). The cesura approach (Barth-Weingarten 2016) focuses on the constitution of phonetic-prosodic discontinuities, which give rise to boundaries, “cesuras”, which it treats as a continuum from “no cesura” through “candidate cesuras” of various strengths, to “full cesuras”. However, there are also elements of spoken interaction whose unit-hood is not obvious at all levels of description; and it is a subset of these that form the focus of this article. We illustrate this with extracts of multimodal talk where two interactants taste and assess unfamiliar food and produce the token “mm”. We show how the alignment (and non-alignment) of boundaries of sequential, prosodic, gestural, lexical, and syntactic units can be a semiotic resource. Data are obtained from Chilean Spanish.},
	language = {en},
	number = {1},
	urldate = {2022-02-08},
	journal = {Open Linguistics},
	author = {Temer, Verónica González and Ogden, Richard},
	month = jan,
	year = {2021},
	note = {Publisher: De Gruyter Open Access},
	pages = {685--706},
}

@article{slonimska_case_2017,
	title = {A case for systematic sound symbolism in pragmatics: {Universals} in wh-words},
	volume = {116},
	issn = {0378-2166},
	shorttitle = {A case for systematic sound symbolism in pragmatics},
	url = {http://www.sciencedirect.com/science/article/pii/S037821661630577X},
	doi = {10.1016/j.pragma.2017.04.004},
	abstract = {This study investigates whether there is a universal tendency for content interrogative words (wh-words) within a language to sound similar in order to facilitate pragmatic inference in conversation. Gaps between turns in conversation are very short, meaning that listeners must begin planning their turn as soon as possible. While previous research has shown that paralinguistic features such as prosody and eye gaze provide cues to the pragmatic function of upcoming turns, we hypothesise that a systematic phonetic cue that marks interrogative words would also help early recognition of questions (allowing early preparation of answers), for instance wh-words sounding similar within a language. We analysed 226 languages from 66 different language families by means of permutation tests. We found that initial segments of wh-words were more similar within a language than between languages, also when controlling for language family, geographic area (stratified permutation) and analyzability (compound phrases excluded). Random samples tests revealed that initial segments of wh-words were more similar than initial segments of randomly selected word sets and conceptually related word sets (e.g., body parts, actions, pronouns). Finally, we hypothesised that this cue would be more useful at the beginning of a turn, so the similarity of the initial segment of wh-words should be greater in languages that place them at the beginning of a clause. We gathered typological data on 110 languages, and found the predicted trend, although statistical significance was not attained. While there may be several mechanisms that bring about this pattern (e.g., common derivation), we suggest that the ultimate explanation of the similarity of interrogative words is to facilitate early speech-act recognition. Importantly, this hypothesis can be tested empirically, and the current results provide a sound basis for future experimental tests.},
	journal = {Journal of Pragmatics},
	author = {Slonimska, Anita and Roberts, Seán G.},
	month = jul,
	year = {2017},
	pages = {1--20},
}

@inproceedings{liesenfeld_cantonese_2019,
	title = {Cantonese turn-initial minimal particles: annotation of discourse-interactional functions in dialog corpora},
	shorttitle = {Cantonese turn-initial minimal particles},
	booktitle = {Proceedings of the 33rd {Pacific} {Asia} {Conference} on {Language}, {Information} and {Computation}},
	publisher = {Waseda Institute for the Study of Language and Information},
	author = {Liesenfeld, Andreas},
	year = {2019},
	pages = {471--479},
}

@article{noordegraaf_dutch_2002,
	title = {Dutch {Linguists} between {Humboldt} and {Saussure}. {The} case of {Jac}. van {Ginneken} (1877-1945)},
	volume = {29},
	issn = {0302-5160},
	doi = {10.1075/hl.29.1.10noo},
	abstract = {The impact Ferdinand de Saussure’s Cours de linguistique générale (1916) had on Dutch linguistics in the 1930s and 1940s has not yet become the object of a thorough investigation. It can be pointed out, however, that in the interwar period Dutch reactions to the Cours were of a mixed character. When one finds Saussure’s book referred to by leading Dutch linguists such as Etsko Kruisinga (1875-1944), H. J. Pos (1898-1955) and A. W. De Groot (1892-1963), the question should be asked to what extent the Cours was seen as a new and important specimen of linguistic theorizing. Moreover, it can be argued that several Dutch linguists felt themselves to be in a different linguistic tradition. Such is definitely the case with Jac. Van Ginneken (1877-1945). He took part in the organization of the first international congress of linguists (1928) and the first international phonetic congress (1932). Although critical of the Cours, he sympathized with the Prague approach to phonology, of which he was one of the early propagandists in Western Europe. However, he did not become a confirmed structuralist. Practising a holistic approach to language and culture he felt more affinity with the ‘Neolinguists’, and tended to revert to 19th-century thinkers such as Wilhelm von Humboldt (1767-1835), as some of his papers clearly show. In an intriguing posthumous essay, Het mysterie der menschelijke taal (‘The mystery of human language’, 1946), Van Ginneken acknowledged that over the years language had become a mystery to him. © 2002 John Benjamins Publishing Company.},
	number = {1/2},
	journal = {Historiographia Linguistica},
	author = {Noordegraaf, J.},
	year = {2002},
	pages = {145--163},
}

@article{levy_parts_2004,
	title = {Parts in {Papantla} {Totonac} and the genesis of systems of numeral classification},
	volume = {57},
	issn = {2196-7148, 1867-8319},
	url = {https://www.degruyter.com/document/doi/10.1524/stuf.2004.57.23.280/html},
	doi = {10.1524/stuf.2004.57.23.280},
	number = {2-3},
	urldate = {2022-02-04},
	journal = {STUF - Language Typology and Universals},
	author = {Levy, Paulette},
	month = jan,
	year = {2004},
}

@article{foley_managing_2022,
	title = {Managing {Transcription} {Data} for {Automatic} {Speech} {Recognition} with {Elpis}},
	url = {https://direct.mit.edu/books/book/5244/chapter/3537404/Managing-Transcription-Data-for-Automatic-Speech},
	doi = {10.7551/mitpress/12200.003.0041},
	language = {en},
	urldate = {2022-01-29},
	author = {Foley, Ben and van Esch, Daan and San, Nay},
	month = jan,
	year = {2022},
}

@article{cohn_prosodic_2021,
	title = {Prosodic {Differences} in {Human}- and {Alexa}-{Directed} {Speech}, but {Similar} {Local} {Intelligibility} {Adjustments}},
	volume = {6},
	issn = {2297-900X},
	url = {https://www.frontiersin.org/article/10.3389/fcomm.2021.675704},
	abstract = {The current study tests whether individuals (n = 53) produce distinct speech adaptations during pre-scripted spoken interactions with a voice-AI assistant (Amazon’s Alexa) relative to those with a human interlocutor. Interactions crossed intelligibility pressures (staged word misrecognitions) and emotionality (hyper-expressive interjections) as conversation-internal factors that might influence participants’ intelligibility adjustments in Alexa- and human-directed speech (DS). Overall, we find speech style differences: Alexa-DS has a decreased speech rate, higher mean f0, and greater f0 variation than human-DS. In speech produced toward both interlocutors, adjustments in response to misrecognition were similar: participants produced more distinct vowel backing (enhancing the contrast between the target word and misrecognition) in target words and louder, slower, higher mean f0, and higher f0 variation at the sentence-level. No differences were observed in human- and Alexa-DS following displays of emotional expressiveness by the interlocutors. Expressiveness, furthermore, did not mediate intelligibility adjustments in response to a misrecognition. Taken together, these findings support proposals that speakers presume voice-AI has a “communicative barrier” (relative to human interlocutors), but that speakers adapt to conversational-internal factors of intelligibility similarly in human- and Alexa-DS. This work contributes to our understanding of human-computer interaction, as well as theories of speech style adaptation.},
	urldate = {2022-01-27},
	journal = {Frontiers in Communication},
	author = {Cohn, Michelle and Zellou, Georgia},
	year = {2021},
}

@article{mavrina_alexa_2022,
	title = {“{Alexa}, {You}'re {Really} {Stupid}”: {A} {Longitudinal} {Field} {Study} on {Communication} {Breakdowns} {Between} {Family} {Members} and a {Voice} {Assistant}},
	volume = {4},
	issn = {2624-9898},
	shorttitle = {“{Alexa}, {You}'re {Really} {Stupid}”},
	url = {https://www.frontiersin.org/article/10.3389/fcomp.2022.791704},
	abstract = {In this paper, we present the results of our long-term study on use of a voice assistant (Amazon Alexa via Amazon Echo Dot) in nine families with children and no previous experience with this technology. The study was conducted over the course of 5 weeks during which the families could interact with the device freely. Three house visits were made to collect empirical data from the adult participants in form of questionnaires. Additionally, conversational data from log files of the voice assistant were obtained. These data were annotated and analyzed with a focus on communication breakdowns during human-assistant interaction. We investigate user behavior for both adults and children in such situations, its reasons and consequences for user satisfaction. This article provides qualitative analysis of three particularly interesting breakdown cases, as well as statistical analysis along several hypotheses and research questions combining empirical and conversational data. Described cases of communication breakdown illustrate findings from existing literature on the topic. The statistical analysis paints a mixed picture, however, it helped us identify further avenues for research, some of which can be explored with our data set in the future. We found a significant negative effect of the number of abandoned failed requests on user satisfaction, contrary to the number of successfully repaired requests that had no influence on user satisfaction. We discovered that users are more inclined to use reformulation as repair strategy when they do not perceive the emergence of miscommunication as their fault. We could not identify a significant effect of internal reasons for the choice of other strategies, so we suggest that situational clues such as the immediate response of the voice assistant are more important for the choice of repair strategy. Our results also hint that users distinguish between repair strategies differently, as the self-perceived frequency of repetitions and abortions of requests were found to be positive predictors for the use of reformulation-based strategies. With regards to the long-term aspect of the study, use of repetition as a repair strategy by both children and adults significantly decreased with time, no other changes were found for other strategies. Additionally, no significant impact of age on the choice of repair strategy was found, as well as no interaction effect between age and time.},
	urldate = {2022-01-27},
	journal = {Frontiers in Computer Science},
	author = {Mavrina, Lina and Szczuka, Jessica and Strathmann, Clara and Bohnenkamp, Lisa Michelle and Krämer, Nicole and Kopp, Stefan},
	year = {2022},
}

@article{winter_commentary_2016,
	title = {Commentary: {Desiccation} and tone within linguistic theory and language contact research},
	volume = {1},
	issn = {2058-4571, 2058-458X},
	shorttitle = {Commentary},
	url = {http://jole.oxfordjournals.org/lookup/doi/10.1093/jole/lzv010},
	doi = {10.1093/jole/lzv010},
	language = {en},
	number = {1},
	urldate = {2016-06-30},
	journal = {Journal of Language Evolution},
	author = {Winter, Bodo and Wedel, Andy},
	month = jan,
	year = {2016},
	pages = {80--82},
}

@article{winter_independence_2021,
	title = {Independence and generalizability in linguistics},
	volume = {59},
	issn = {1613-396X},
	url = {https://www.degruyter.com/document/doi/10.1515/ling-2019-0049/html},
	doi = {10.1515/ling-2019-0049},
	abstract = {Quantitative studies in linguistics almost always involve data points that are related to each other, such as multiple data points from the same participant, multiple texts from the same book, author, genre, or register, or multiple languages from the same language family. Statistical procedures that fail to account for the relatedness of observations by assuming independence among units can lead to grossly misleading results if these sources of variation are ignored. As mixed effects models are increasingly used to analyze these non-independent data structures, it might appear that the problem of violating the independence assumption is solved. In this paper, we argue that it is necessary to re-open and widen the discussion about sources of variation that are being ignored, not only in statistical analyses, but also in the way studies are designed. Non-independence is not something that is “solved” by new statistical methods such as mixed models, but it is something that we continuously need to discuss as we apply new methods to an increasingly diverse range of linguistic datasets and corpora. In addition, our paper delivers something that is currently missing from statistical textbooks for linguists, which is an overview of non-independent data structures across different subfields of linguistics (corpus linguistics, typology, phonetics etc.), and how mixed models are used to deal with these structures.},
	language = {en},
	number = {5},
	urldate = {2021-09-20},
	journal = {Linguistics},
	author = {Winter, Bodo and Grice, Martine},
	month = sep,
	year = {2021},
	note = {Publisher: De Gruyter Mouton},
	pages = {1251--1277},
}

@article{winter_poisson_2021,
	title = {Poisson regression for linguists: {A} tutorial introduction to modelling count data with brms},
	volume = {15},
	issn = {1749-818X},
	shorttitle = {Poisson regression for linguists},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/lnc3.12439},
	doi = {10.1111/lnc3.12439},
	abstract = {Count data is prevalent in many different areas of linguistics, such as when counting words, syntactic constructions, discourse particles, case markers, or speech errors. The Poisson distribution is the canonical distribution for characterising count data with no or unknown upper bound. Given the prevalence of count data in linguistics, Poisson regression has wide utility no matter what subfield of linguistics is considered. However, in contrast to logistic regression, Poisson regression is surprisingly little known. Here, we make a case for why linguists need to consider Poisson regression, and give recommendations for when Poisson regression is more appropriate compared to logistic regression. This tutorial introduces readers to foundational concepts needed to understand the basics of Poisson regression, followed by a hands-on tutorial using the R package brms. We discuss a dataset where Catalan and Korean speakers change the frequency of their co-speech gestures as a function of politeness contexts. This dataset also involves exposure variables (the incorporation of time to deal with unequal intervals) and overdispersion (excess variance). Altogether, we hope that more linguists will consider Poisson regression for the analysis of count data.},
	language = {en},
	number = {11},
	urldate = {2021-11-23},
	journal = {Language and Linguistics Compass},
	author = {Winter, Bodo and Bürkner, Paul-Christian},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/lnc3.12439},
	pages = {e12439},
}

@article{wedel_crosslinguistic_2019,
	title = {Crosslinguistic evidence for a strong statistical universal: {Phonological} neutralization targets word-ends over beginnings},
	volume = {95},
	issn = {1535-0665},
	shorttitle = {Crosslinguistic evidence for a strong statistical universal},
	url = {https://muse.jhu.edu/article/743115},
	doi = {10.1353/lan.2019.0082},
	abstract = {, Abstract:, We report a statistical test of a long-standing hypothesis in the literature: that phonological neutralization rules are more common at the ends of lexical domains than the beginnings (Houlihan 1975 et seq.). We collected descriptive grammars for an areally and genetically diverse set of fifty languages, identified all active phonological rules that target the edge of a lexical domain (root, stem, word, phrase, or utterance), and further coded each rule for whether it was phonemically neutralizing, that is, able to create surface homophony. We find that such neutralizing rules are strongly, significantly less common at the beginnings of lexical domains relative to ends, and that this pattern is strikingly consistent across all languages within the data set. We show that this pattern is not an artifact of a tendency for syllable codas to be a target for phonological neutralization, nor is it associated with a suffixing or prefixing preference. Consistent with previous accounts, we argue that this pattern may ultimately be based in the greater average information content of phonological categories early in the word, which itself is a consequence of incremental processing in lexical access.},
	language = {en},
	number = {4},
	urldate = {2020-03-05},
	journal = {Language},
	author = {Wedel, Andrew and Ussishkin, Adam and King, Adam},
	month = dec,
	year = {2019},
	note = {Publisher: Linguistic Society of America},
	pages = {e428--e446},
}

@article{wedel_incremental_2019,
	title = {Incremental word processing influences the evolution of phonotactic patterns},
	volume = {40},
	issn = {0165-4004},
	url = {https://www.degruyter.com/view/j/flih.2019.53.issue-s40-1/flih-2019-0011/flih-2019-0011.xml?format=INT&lang=de},
	doi = {10.1515/flih-2019-0011},
	abstract = {Listeners incrementally process words as they hear them, progressively updating inferences about what word is intended as the phonetic signal unfolds in time. As a consequence, phonetic cues positioned early in the signal for a word are on average more informative about word-identity because they disambiguate the intended word from more lexical alternatives than cues late in the word. In this contribution, we review two new findings about structure in lexicons and phonological grammars, and argue that both arise through the same biases on phonetic reduction and enhancement resulting from incremental processing.},
	number = {1},
	urldate = {2020-03-05},
	journal = {Folia Linguistica},
	author = {Wedel, Andrew and Ussishkin, Adam and King, Adam},
	year = {2019},
	pages = {231--248},
}

@article{wedel_feedback_2007,
	title = {Feedback and regularity in the lexicon},
	volume = {24},
	issn = {1469-8188, 0952-6757},
	url = {https://www.cambridge.org/core/journals/phonology/article/feedback-and-regularity-in-the-lexicon/DF72754843C8B9796CAABC09F6083B86},
	doi = {10.1017/S0952675707001145},
	abstract = {Phonologies are characterised by regularity, from the stereotyped phonetic characteristics of allophones to the contextually conditioned alternations between them. Most models of grammar account for regularity by hypothesising that there is only a limited set of symbols for expressing underlying forms, and that an independent grammar algorithm transforms symbol sequences into an output representation. However, this explanation for regularity is called into question by research which suggests that the mental lexicon records rich phonetic detail that directly informs production. Given evidence for biases favouring previously experienced forms at many levels of production and perception, I argue that positive feedback within a richly detailed lexicon can produce regularity over many cycles of production and perception. Using simulation as a tool, I show that under the influence of positive feedback, gradient biases in usage can convert an initially gradient and variable distribution of lexical behaviours into a more categorical and simpler pattern.},
	language = {en},
	number = {1},
	urldate = {2020-03-05},
	journal = {Phonology},
	author = {Wedel, Andrew B.},
	month = may,
	year = {2007},
	note = {Publisher: Cambridge University Press},
	pages = {147--185},
}

@article{wedel_exemplar_2006,
	title = {Exemplar models, evolution and language change},
	volume = {23},
	issn = {1613-3676},
	url = {https://www.degruyter.com/view/j/tlir.2006.23.issue-3/tlr.2006.010/tlr.2006.010.xml},
	doi = {10.1515/TLR.2006.010},
	abstract = {Evidence supporting a rich memory for associations suggests that people can store perceptual details in the form of exemplars. The resulting particulate model of category contents allows the application of evolution theory in modeling category change, because variation in categorized percepts is reflected in the distribution of exemplars in a category. Within a production-perception feedback loop, variation within an exemplar-based category provides a reserve of variants that can serve as the seeds for shifts in the system over time through random or selection-driven asymmetries in production and perception. Here, three potential pathways for evolutionary change are identified in linguistic categories: pruning of lines of inheritance, blending inheritance and natural selection. Simulations of each of these pathways are shown within a simple exemplar-based model of category production and perception, showing how consideration of evolutionary processes may contribute to our understanding of linguistic category change over time.},
	number = {3},
	urldate = {2020-03-05},
	journal = {The Linguistic Review},
	author = {Wedel, Andrew B},
	year = {2006},
	pages = {247--274},
}

@article{wedel_lexical_2012,
	title = {Lexical contrast maintenance and the organization of sublexical contrast systems},
	volume = {4},
	issn = {1866-9808, 1866-9859},
	url = {https://www.cambridge.org/core/journals/language-and-cognition/article/lexical-contrast-maintenance-and-the-organization-of-sublexical-contrast-systems/432F8A948F2234AE394582DB924950C9},
	doi = {10.1515/langcog-2012-0018},
	abstract = {Variationist/evolutionary models of phonology assume a causal chain that links biases at the utterance level to the development and consolidation of abstract phonological patterns over time. Some of the properties of linguistic cognition that have been proposed to underlie this chain are (i) storage of experienced detail at multiple levels of description, (ii) feedback between perception and production, (iii) a similarity bias in the production and perception of variation, and (iv) enhancement of cues to potentially ambiguous lexical items in usage. I review evidence for these properties and argue that they interact to provide a pathway for individual usage events to influence the evolution of contrastive sublexcal category systems, i.e phoneme inventories. Specifically, the proposed Network-Feedback model predicts that the organization of sublexical category systems is shaped by a conflict between a general drive toward greater similarity among sublexical categories on the one hand, and a bias toward maintaining contrast between tokens of competing lexical categories on the other. The model provides testable hypotheses about the conditions favoring phoneme merger, chain-shifts, and phonemic splits, and more generally about the influence of lexical contrast on the packing of sublexical categories along gestural/perceptual dimensions. Finally, this pathway of change is consistent with proposals that sublexical categories such as features and segments are not primitives of language, but emerge through more general properties of performance, perception, categorization and learning.},
	language = {en},
	number = {4},
	urldate = {2020-03-05},
	journal = {Language and Cognition},
	author = {Wedel, Andrew},
	month = dec,
	year = {2012},
	note = {Publisher: Cambridge University Press},
	pages = {319--355},
}

@inproceedings{wedel_language-specific_2020,
	title = {Language-{Specific} {Constraints} on {Word} {Form} {Predict} {Segment} {Information} {Across} the {Word}},
	url = {http://brussels.evolang.org/proceedings/paper.html?nr=187},
	doi = {10.17617/2.3190925},
	author = {Wedel, A. and King, A.},
	editor = {Ravignani, A. and Barbieri, C. and Martins, M. and Flaherty, M. and Jadoul, Y. and Lattenkamp, E. and Little, H. and Mudd, K. and Verhoef, T.},
	year = {2020},
}

@incollection{dingemanse_interjections_2021,
	title = {Interjections},
	booktitle = {The {Oxford} {Handbook} of {Word} {Classes}},
	publisher = {Oxford University Press},
	author = {Dingemanse, Mark},
	editor = {Lier, Eva van},
	year = {2021},
	doi = {10.31234/osf.io/ngcrs},
	note = {type: article},
}

@article{sainburg_finding_2020,
	title = {Finding, visualizing, and quantifying latent structure across diverse animal vocal repertoires},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008228},
	doi = {10.1371/journal.pcbi.1008228},
	abstract = {Animals produce vocalizations that range in complexity from a single repeated call to hundreds of unique vocal elements patterned in sequences unfolding over hours. Characterizing complex vocalizations can require considerable effort and a deep intuition about each species’ vocal behavior. Even with a great deal of experience, human characterizations of animal communication can be affected by human perceptual biases. We present a set of computational methods for projecting animal vocalizations into low dimensional latent representational spaces that are directly learned from the spectrograms of vocal signals. We apply these methods to diverse datasets from over 20 species, including humans, bats, songbirds, mice, cetaceans, and nonhuman primates. Latent projections uncover complex features of data in visually intuitive and quantifiable ways, enabling high-powered comparative analyses of vocal acoustics. We introduce methods for analyzing vocalizations as both discrete sequences and as continuous latent variables. Each method can be used to disentangle complex spectro-temporal structure and observe long-timescale organization in communication.},
	language = {en},
	number = {10},
	urldate = {2022-01-21},
	journal = {PLOS Computational Biology},
	author = {Sainburg, Tim and Thielk, Marvin and Gentner, Timothy Q.},
	month = oct,
	year = {2020},
	note = {Publisher: Public Library of Science},
	pages = {e1008228},
}

@article{mielke_visualizing_2018,
	title = {Visualizing phonetic segment frequencies with density-equalizing maps},
	volume = {48},
	issn = {0025-1003, 1475-3502},
	url = {https://www.cambridge.org/core/journals/journal-of-the-international-phonetic-association/article/visualizing-phonetic-segment-frequencies-with-densityequalizing-maps/7D66A7F1FE80EB9195DCC451D861CC41},
	doi = {10.1017/S0025100317000123},
	abstract = {A method is demonstrated for creating density-equalizing maps of IPA consonant and vowel charts, where the size of a cell in the chart reflects information such as the crosslinguistic frequency of the consonant or vowel. Transforming the IPA charts in such a way allows the visualization of interactions between phonetic features. Density-equalizing maps are used to illustrate a range of facts about consonant and vowel inventories, including the frequency of consonants and vowels and the frequency of common diacritics, and to illustrate the frequency of deletion and epenthesis involving particular consonants and vowels. Solutions are proposed for issues involving genealogical sampling, counting pairs of very similar phones, and counting diacritics in relation to basic symbols.},
	language = {en},
	number = {2},
	urldate = {2022-01-21},
	journal = {Journal of the International Phonetic Association},
	author = {Mielke, Jeff},
	month = aug,
	year = {2018},
	note = {Publisher: Cambridge University Press},
	pages = {129--154},
}

@article{stivers_stance_2008,
	title = {Stance, alignment, and affiliation during storytelling: {When} nodding is a token of affiliation},
	volume = {41},
	shorttitle = {Stance, alignment, and affiliation during storytelling},
	number = {1},
	journal = {Research on Language and Social Interaction},
	author = {Stivers, Tanya},
	year = {2008},
	pages = {31--57},
}

@inproceedings{bird_decolonising_2020,
	address = {Barcelona, Spain (Online)},
	title = {Decolonising {Speech} and {Language} {Technology}},
	url = {https://aclanthology.org/2020.coling-main.313},
	doi = {10.18653/v1/2020.coling-main.313},
	abstract = {After generations of exploitation, Indigenous people often respond negatively to the idea that their languages are data ready for the taking. By treating Indigenous knowledge as a commodity, speech and language technologists risk disenfranchising local knowledge authorities, reenacting the causes of language endangerment. Scholars in related fields have responded to calls for decolonisation, and we in the speech and language technology community need to follow suit, and explore what this means for our practices that involve Indigenous languages and the communities who own them. This paper reviews colonising discourses in speech and language technology, and suggests new ways of working with Indigenous communities, and seeks to open a discussion of a postcolonial approach to computational methods for supporting language vitality.},
	urldate = {2022-01-13},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {International Committee on Computational Linguistics},
	author = {Bird, Steven},
	month = dec,
	year = {2020},
	pages = {3504--3519},
}

@article{bird_scalable_2010,
	title = {A scalable method for preserving oral literature from small languages},
	volume = {6102},
	doi = {10.1007/978-3-642-13654-2_2},
	journal = {Lecture Notes in Computer Science},
	author = {Bird, Steven},
	year = {2010},
	pages = {5--14},
}

@article{bird_natural_2009,
	title = {Natural {Language} {Processing} and {Linguistic} {Fieldwork}},
	volume = {35},
	journal = {Computational Linguistics},
	author = {Bird, Steven},
	year = {2009},
	pages = {469--474},
}

@article{roberts_interobserver_2004,
	title = {Interobserver {Agreement} on {First}‐{Stage} {Conversation} {Analytic} {Transcription}},
	volume = {30},
	issn = {1468-2958},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1468-2958.2004.tb00737.x/abstract},
	doi = {10.1111/j.1468-2958.2004.tb00737.x},
	abstract = {This investigation assesses interobserver agreement on conversation analytic (CA) transcription. Four professional CA transcribers spent a maximum of 3 hours transcribing 2.5 minutes of a previously unknown, naturally occurring, mundane telephone call. Researchers unitized transcripts into words, sounds, silences, inbreaths, outbreaths, and laugh tokens, and then coded each of 1,827 units on as many as 15 transcription dimensions. Agreement was assessed using Cohen's kappa for nominal level data: Speaker designation, unit sequencing, semantics, orthography, cutoff, and plosiveness reached the level of “substantial” agreement (90\% or greater accuracy). Pitch, overlap, doubt, and smile voice reached the level of “moderate” agreement (80–89\% accuracy), while pace, sound stretch, underline/amplitude, and intonation fell below acceptability except when examined post hoc as presence versus absence of the feature. Silence lengths, examined as ratio-level data, were reliable at the “acceptable” level (alpha {\textgreater}.70) among those using a counting method (as opposed to stopwatch or other mechanical means). We make recommendations for transcription training.},
	language = {en},
	number = {3},
	urldate = {2012-04-11},
	journal = {Human Communication Research},
	author = {Roberts, Felicia},
	month = jul,
	year = {2004},
	pages = {376--410},
}

@article{bird_sparse_2021,
	title = {Sparse {Transcription}},
	volume = {46},
	issn = {0891-2017, 1530-9312},
	url = {https://direct.mit.edu/coli/article/46/4/713-744/97329},
	doi = {10.1162/coli_a_00387},
	abstract = {The transcription bottleneck is often cited as a major obstacle for efforts to document the world’s endangered languages and supply them with language technologies. One solution is to extend methods from automatic speech recognition and machine translation, and recruit linguists to provide narrow phonetic transcriptions and sentence-aligned translations. However, I believe that these approaches are not a good fit with the available data and skills, or with long-established practices that are essentially word-based. In seeking a more effective approach, I consider a century of transcription practice and a wide range of computational approaches, before proposing a computational model based on spoken term detection that I call “sparse transcription.” This represents a shift away from current assumptions that we transcribe phones, transcribe fully, and transcribe first. Instead, sparse transcription combines the older practice of word-level transcription with interpretive, iterative, and interactive processes that are amenable to wider participation and that open the way to new methods for processing oral languages.},
	language = {en},
	number = {4},
	urldate = {2022-01-13},
	journal = {Computational Linguistics},
	author = {Bird, Steven},
	month = feb,
	year = {2021},
	pages = {713--744},
}

@inproceedings{auer_automatic_2010,
	title = {Automatic annotation of media field recordings},
	booktitle = {Proceedings of the {ECAI} 2010 {Workshop} on {Language} {Technology} for {Cultural} {Heritage}, {Social} {Sciences}, and {Humanities} ({LaTeCH} 2010)},
	author = {Auer, Eric and Wittenburg, Peter and Sloetjes, Han and Schreer, Oliver and Masneri, Stefano and Schneider, Daniel and Tschöpel, Sebastian},
	year = {2010},
	pages = {31--34},
}

@book{kong_conversational_2021,
	title = {Conversational {AI} with {Rasa}: build, automate, and deploy {AI}-powered text and voice-based assistants and chatbots},
	isbn = {978-1-80107-388-2},
	shorttitle = {Conversational {AI} with {Rasa}},
	url = {https://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=3021540},
	language = {English},
	urldate = {2022-01-17},
	author = {Kong, Xiaoquan and Wang, Guan},
	year = {2021},
	note = {OCLC: 1272888279},
}

@book{pieraccini_ai_2021,
	address = {Cambridge, Massachusetts},
	series = {The {MIT} {Press} essential knowledge series},
	title = {{AI} assistants},
	isbn = {978-0-262-54255-5},
	abstract = {"A brief introduction to the technology, the issues and future of virtual agents such as Siri, Alexa and the Google Assistant"--},
	publisher = {The MIT Press},
	author = {Pieraccini, Roberto},
	year = {2021},
}

@book{jokinen_dialogues_2017,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Dialogues with {Social} {Robots}: {Enablements}, {Analyses}, and {Evaluation}},
	volume = {427},
	isbn = {978-981-10-2584-6 978-981-10-2585-3},
	shorttitle = {Dialogues with {Social} {Robots}},
	url = {http://link.springer.com/10.1007/978-981-10-2585-3},
	language = {en},
	urldate = {2022-01-17},
	publisher = {Springer Singapore},
	editor = {Jokinen, Kristiina and Wilcock, Graham},
	year = {2017},
	doi = {10.1007/978-981-10-2585-3},
}

@incollection{baumann_recognising_2017,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Recognising {Conversational} {Speech}: {What} an {Incremental} {ASR} {Should} {Do} for a {Dialogue} {System} and {How} to {Get} {There}},
	isbn = {978-981-10-2585-3},
	shorttitle = {Recognising {Conversational} {Speech}},
	url = {https://doi.org/10.1007/978-981-10-2585-3_35},
	abstract = {Automatic speech recognition (asr) is not only becoming increasingly accurate, but also increasingly adapted for producing timely, incremental output. However, overall accuracy and timeliness alone are insufficient when it comes to interactive dialogue systems which require stability in the output and responsivity to the utterance as it is unfolding. Furthermore, for a dialogue system to deal with phenomena such as disfluencies, to achieve deep understanding of user utterances these should be preserved or marked up for use by downstream components, such as language understanding, rather than be filtered out. Similarly, word timing can be informative for analyzing deictic expressions in a situated environment and should be available for analysis. Here we investigate the overall accuracy and incremental performance of three widely used systems and discuss their suitability for the aforementioned perspectives. From the differing performance along these measures we provide a picture of the requirements for incremental asr in dialogue systems and describe freely available tools for using and evaluating incremental asr.},
	language = {en},
	urldate = {2022-01-17},
	booktitle = {Dialogues with {Social} {Robots}: {Enablements}, {Analyses}, and {Evaluation}},
	publisher = {Springer},
	author = {Baumann, Timo and Kennington, Casey and Hough, Julian and Schlangen, David},
	editor = {Jokinen, Kristiina and Wilcock, Graham},
	year = {2017},
	doi = {10.1007/978-981-10-2585-3_35},
	pages = {421--432},
}

@inproceedings{panayotov_librispeech_2015,
	title = {Librispeech: an {ASR} corpus based on public domain audio books},
	shorttitle = {Librispeech},
	booktitle = {2015 {IEEE} international conference on acoustics, speech and signal processing ({ICASSP})},
	publisher = {IEEE},
	author = {Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
	year = {2015},
	pages = {5206--5210},
}

@article{wang_voxpopuli_2021,
	title = {{VoxPopuli}: {A} {Large}-{Scale} {Multilingual} {Speech} {Corpus} for {Representation} {Learning}, {Semi}-{Supervised} {Learning} and {Interpretation}},
	shorttitle = {{VoxPopuli}},
	url = {http://arxiv.org/abs/2101.00390},
	abstract = {We introduce VoxPopuli, a large-scale multilingual corpus providing 100K hours of unlabelled speech data in 23 languages. It is the largest open data to date for unsupervised representation learning as well as semi-supervised learning. VoxPopuli also contains 1.8K hours of transcribed speeches in 16 languages and their aligned oral interpretations into 5 other languages totaling 5.1K hours. We provide speech recognition baselines and validate the versatility of VoxPopuli unlabelled data in semi-supervised learning under challenging out-of-domain settings. We will release the corpus at https://github.com/facebookresearch/voxpopuli under an open license.},
	urldate = {2022-01-17},
	journal = {arXiv:2101.00390 [cs, eess]},
	author = {Wang, Changhan and Rivière, Morgane and Lee, Ann and Wu, Anne and Talnikar, Chaitanya and Haziza, Daniel and Williamson, Mary and Pino, Juan and Dupoux, Emmanuel},
	month = jul,
	year = {2021},
	note = {arXiv: 2101.00390},
}

@article{tyers_what_2021,
	title = {What shall we do with an hour of data? {Speech} recognition for the un-and under-served languages of {Common} {Voice}},
	shorttitle = {What shall we do with an hour of data?},
	journal = {arXiv preprint arXiv:2105.04674},
	author = {Tyers, Francis M. and Meyer, Josh},
	year = {2021},
}

@article{bolinger_thoughts_1946,
	title = {Thoughts on '{Yep}' and '{Nope}'},
	volume = {21},
	issn = {0003-1283},
	url = {https://www.jstor.org/stable/486479},
	doi = {10.2307/486479},
	number = {2},
	urldate = {2020-02-15},
	journal = {American Speech},
	author = {Bolinger, Dwight L.},
	year = {1946},
	pages = {90--95},
}

@article{gipper_beyond_2020,
	title = {Beyond committing and presupposing in {Yurakaré} conversations: {Investigating} the interactional functions of epistemic markers through their sequential distributions},
	volume = {54},
	issn = {1614-7308},
	shorttitle = {Beyond committing and presupposing in {Yurakaré} conversations},
	url = {https://www.degruyter.com/document/doi/10.1515/flin-2020-2043/html},
	doi = {10.1515/flin-2020-2043},
	abstract = {This paper outlines a method for studying the sequential distributions of epistemic markers with the purpose of gaining insight into their interactional functions. The method is exemplified with a case study of two epistemic markers of Yurakaré (isolate, Bolivia), =la “commitment” and =se “presupposition”. The investigation reveals that the two markers show different distributions across initial and responsive utterances. Moreover, each marker functions differently when used in initial utterances and responses. It is argued that these distributions show that the interactional functions of the two markers go beyond the marking of commitment and presupposition, and that they contrast in terms of two scales, one capturing the poles of “highly initiating” and “highly responsive”, the other concerning high vs. low degrees of “thematic agency”. While the commitment marker =la is associated with the responsivity pole and with a low degree of thematic agency, the presupposition marker =se shows a tendency toward the initiating pole and toward a high degree of thematic agency. These findings then support the view that epistemic markers are employed to co-construct epistemic perspectives in interaction rather than to make explicit some internal epistemic state held by the speaker.},
	language = {en},
	number = {2},
	urldate = {2021-04-03},
	journal = {Folia Linguistica},
	author = {Gipper, Sonja},
	month = aug,
	year = {2020},
	note = {Publisher: De Gruyter
Section: Folia Linguistica},
	pages = {371--404},
}

@article{gipper_repeating_2020,
	title = {Repeating responses as a conversational affordance for linguistic transmission: {Evidence} from {Yurakaré} conversations},
	volume = {44},
	issn = {0378-4177, 1569-9978},
	shorttitle = {Repeating responses as a conversational affordance for linguistic transmission},
	url = {https://www.jbe-platform.com/content/journals/10.1075/sl.19041.gip},
	doi = {10.1075/sl.19041.gip},
	abstract = {Abstract Given that face-to-face interaction is an important locus for linguistic transmission (Enfield 2008: 297), it is argued in this paper that conversational structure must provide affordances (Gibson 1979) for transmitting linguistic items. The paper focuses on repeats where an interactant (partially) repeats their interlocutor’s preceding utterance. Repeats are argued to provide affordances for the transmission of innovative and conservative linguistic items by forcing interactants to repeat linguistic material uttered by another person, facilitating production by exploiting priming effects. Moreover, repeats leave room for modification and thereby for actively resisting transmission. In this way, repeats unite the competing forces (Tantucci et al. 2018) of automaticity and creativity. To support this claim, this paper investigates the use of Spanish insertions and alternative variants in utterance-repeat pairs in Yurakaré (isolate, Bolivia) conversations. The findings are compatible with a holistic view of language where all linguistic levels are interconnected (Beckner et al. 2009).},
	language = {en},
	number = {2},
	urldate = {2020-10-13},
	journal = {Studies in Language},
	author = {Gipper, Sonja},
	month = jun,
	year = {2020},
	note = {Publisher: John Benjamins},
	pages = {281--326},
}

@article{geluykens_myth_1988,
	title = {On the myth of rising intonation in polar questions},
	volume = {12},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/0378216688900069},
	doi = {10.1016/0378-2166(88)90006-9},
	abstract = {Using an extensive corpus conversational data, it is shown that the role ofRising intonation (i.e. Rises, Fall-Rises, and Fall+Rises) in polar questions is overrated. Two types of polar - or ‘yes/no’ - questions are investigated: Inversion-questions (e.g. Is this a question?), and Queclaratives (e.g. This is a question?). In Inversion-questions, though Rising intonation is relatively frequent, the most frequent tone, in absolute terms, is a Fall; moreover, intonation is not used to distinguish genuine Inversion-questions from interrogatives without Question-status, such as Rhetorical Questions and Requests. In Queclaratives, a Falling intonation contour is by far the most frequent pattern, mostly accompanied by a step-up in pitch in the Head of the Tone Unit. Attention is also paid to the Pitch Range of polar questions, and to Pausal aspects of Question - Answer pairs. In all, the claim that Rising intonation (and, more particularly, final Rises) is the ‘normal’ pattern for polar questions lacks empirical justification.},
	number = {4},
	urldate = {2013-09-09},
	journal = {Journal of Pragmatics},
	author = {Geluykens, Ronald},
	month = aug,
	year = {1988},
	pages = {467--485},
}

@article{roelofsen_polarity_2015,
	title = {Polarity particle responses as a window onto the interpretation of questions and assertions},
	volume = {91},
	issn = {1535-0665},
	url = {https://muse.jhu.edu/journals/language/v091/91.2.roelofsen.html},
	abstract = {This article provides an account of the distribution and interpretation of polarity particles in responses, starting with yes and no in English, and then extending the coverage to their crosslinguistic kin. Polarity particles are used in responses to both declarative and interrogative sentences, and thus provide a window onto the semantics and discourse effects of such sentences. We argue that understanding the distribution and interpretation of polarity particles requires a characterization of declaratives and interrogatives that captures a series of challenging similarities and differences across these two sentence types. To meet this challenge we combine and extend insights from inquisitive semantics, dynamic semantics, and commitment-based models of discourse. We then provide a full account of the English data that leads to a typology of polarity particles and a series of crosslinguistic predictions. These predictions are checked against data from Romanian, Hungarian, French, and German, languages that contrast with English in that they have ternary polarity particle systems, and contrast with one another in further subtle ways.},
	number = {2},
	urldate = {2015-06-18},
	journal = {Language},
	author = {Roelofsen, Floris and Farkas, Donka F.},
	year = {2015},
	note = {{\textless}p{\textgreater}Volume 91, Number 2, June 2015{\textless}/p{\textgreater}},
	pages = {359--414},
}

@incollection{bolinger_yes-no_1978,
	series = {Synthese {Language} {Library}},
	title = {Yes-no questions are not alternative questions},
	number = {1},
	booktitle = {Questions},
	publisher = {D. Reidel},
	author = {Bolinger, Dwight L.},
	editor = {Hiz, Henry},
	year = {1978},
	pages = {87--105},
}

@article{heinemann_questions_2008,
	title = {Questions of accountability: yes—no interrogatives that are unanswerable},
	volume = {10},
	shorttitle = {Questions of accountability},
	url = {http://dis.sagepub.com/content/10/1/55.abstract},
	doi = {10.1177/1461445607085590},
	abstract = {This article examines one practice for challenging a co-participant, the use of polar                 interrogatives that are unanswerable. These are questions that are designed to                 receive a confirming answer of the same polarity as the question, so-called `Same                 Polarity Questions'. Speakers accomplish this bias by formatting the question in                 accordance with their state of knowledge. Based on the recipient's prior turns at                 talk, a speaker can infer what the recipient's stance towards some matter is and use                 a `Same Polarity Question' to assert this inference and invite the recipient to                 confirm the stance. However, the sequential context in which these questions are                 produced means that with a confirming answer the recipient is heard to be in                 disagreement with the speaker and can subsequently be held accountable for this                 disagreement. Neither is a disconfirming response a real alternative, because this                 would contrast with the information provided by the recipient in prior talk. As this                 information is what leads the speaker to convey a certain belief about the                 recipient, the recipient is accountable for having misled the speaker. Because both                 confirming and disconfirming answers are accountable and hence problematic,                 recipients treat this type of question as unanswerable and instead orient to it as a                 challenge.},
	number = {1},
	urldate = {2011-12-09},
	journal = {Discourse Studies},
	author = {Heinemann, Trine},
	month = feb,
	year = {2008},
	pages = {55 --71},
}

@article{houtkoop-steenstra_creating_1997,
	title = {Creating {Happy} {People} by {Asking} {Yes}-{No} {Questions}},
	volume = {30},
	issn = {0835-1813},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi3004_2},
	doi = {10.1207/s15327973rlsi3004_2},
	number = {4},
	urldate = {2011-07-19},
	journal = {Research on Language \& Social Interaction},
	author = {Houtkoop-Steenstra, Hanneke and Antaki, Charles},
	month = oct,
	year = {1997},
	pages = {285--313},
}

@article{parker_toward_1996,
	title = {Toward a {Universal} {Form} for '{Yes}': {Or}, {Rhinoglottophilia} and the {Affirmation} {Grunt}},
	volume = {6},
	issn = {1548-1395},
	shorttitle = {Toward a {Universal} {Form} for '{Yes}'},
	url = {http://onlinelibrary.wiley.com/doi/10.1525/jlin.1996.6.1.85/abstract},
	doi = {10.1525/jlin.1996.6.1.85},
	abstract = {Based on a corpus of 297 attested words for 'yes' collected from 44 countries, I propose a basic universal template or canonical form for this lexical item having the pattern /he?e/. In the accompanying discussion I show how the diverse language-specific variants can be derived from this theme through the optional selection of a handful of simple, natural phonological modifications. In the conclusion I suggest a functional explanation for this phenomenon by appealing to the notion of minimal articulatory gesture.},
	language = {en},
	number = {1},
	urldate = {2011-07-11},
	journal = {Journal of Linguistic Anthropology},
	author = {Parker, Steve},
	month = jun,
	year = {1996},
	pages = {85--95},
}

@article{enfield_polar_2018,
	title = {Polar answers},
	issn = {0022-2267, 1469-7742},
	url = {https://www.cambridge.org/core/product/identifier/S0022226718000336/type/journal_article},
	doi = {10.1017/S0022226718000336},
	language = {en},
	urldate = {2018-09-21},
	journal = {Journal of Linguistics},
	author = {Enfield, N. J. and Stivers, Tanya and Brown, Penelope and Englert, Christina and Harjunpää, Katariina and Hayashi, Makoto and Heinemann, Trine and Hoymann, Gertie and Keisanen, Tiina and Rauniomaa, Mirka and Raymond, Chase Wesley and Rossano, Federico and Yoon, Kyung-Eun and Zwitserlood, Inge and Levinson, Stephen C.},
	month = sep,
	year = {2018},
	pages = {1--28},
}

@article{enfield_language_2015,
	title = {Language structure and social agency: {Confirming} polar questions in conversation},
	volume = {0},
	issn = {2199-174X},
	shorttitle = {Language structure and social agency},
	doi = {10.1515/lingvan-2014-1008},
	number = {0},
	journal = {Linguistics Vanguard},
	author = {Enfield, N. J. and Sidnell, Jack},
	month = jan,
	year = {2015},
}

@book{raymond_alisis_2022,
	address = {London},
	title = {Análisis de la {Conversación}: {Fundamentos}, metodología y alcances},
	isbn = {978-0-429-50727-4},
	shorttitle = {Análisis de la {Conversación}},
	abstract = {Análisis de la Conversación: fundamentos, metodología y alcances ofrece la primera introducción comprehensiva al Análisis de la Conversación (AC) en español y con datos conversacionales disponibles en línea. 
El libro está organizado en nueve capítulos. En los capítulos iniciales, se presenta el AC como una disciplina y método analítico para el estudio del habla y otras formas de conducta humana en la interacción social, se hace un breve recuento histórico del desarrollo de la perspectiva analítico-conversacional y se introduce a los lectores al sistema de transcripción usado en el AC. Los capítulos siguientes están dedicados a explorar cuatro dominios claves en la organización de la conversación espontánea: la toma de turnos, las secuencias de acciones, la preferencia y la enmienda, destacando la importancia de prácticas del diseño de turno en cada dominio. Seguidamente, se discute la conexión entre organizaciones y prácticas del habla en interacción y contextos sociales e identidades de los participantes en conversación. El libro concluye ofreciendo una serie de sugerencias para la investigación analítico-conversacional en español y señalando su relevancia para la indagación de la interacción en contextos legales, políticos, médicos, tecnológicos, entre otros.
Cada capítulo incluye ejemplos tomados de conversaciones auténticas en distintas variedades de español, cuyos audios pueden ser consultados directamente en línea. Con el fin de revisar y profundizar lo aprendido, cada capítulo ofrece un apartado final con preguntas, actividades y lecturas adicionales. Como apéndices al libro, se ofrecen, además, un glosario de términos bidireccional español–inglés y un sumario con las convenciones de transcripción más usadas.
Escrito enteramente en español, el libro ofrece una introducción actual, comprehensiva y amigable al AC y sus aplicaciones por lo que constituye una fuente de referencia ideal para estudiantes, instructores e investigadores en lingüística (hispánica), sociología y comunicaciones.
 
Análisis de la Conversación provides the first comprehensive, Spanish-language introduction to the field of Conversation Analysis (CA), utilizing conversational data that is publicly available online. 

The book is organized in nine chapters. The opening chapters introduce Conversation Analysis as a unique theory and method to study language and other forms of conduct in social interaction. Readers are presented with a history of the development of this framework for analyzing interaction and introduced to the transcription system used in CA. The following chapters explore four key domains of organization within spontaneous conversation—turn-taking, preference, sequence, and repair—highlighting the importance of turn design practices in each. The authors then review the connection of these organizations and practices to social contexts and participant identities, and they conclude by suggesting a range of avenues for future research on Spanish conversation, including its relevance in specific legal, political, medical, and technological settings. 

Each chapter includes a variety of examples from authentic Spanish conversation, which readers can consult directly online. Each chapter is additionally accompanied by a set of questions and activities that allow readers to check and reinforce their understanding, as well as lists of additional readings for readers interested in more specific topics. Glossaries of technical vocabulary—both Spanish-English and English-Spanish—are included as appendices, along with a summary of transcription system notation. 

Written entirely in Spanish, this book presents a thorough and engaging introduction to Conversation Analysis and its applications. It is ideal for students, instructors, and researchers in Hispanic Studies, (Spanish) Linguistics, Sociology, and Communication Studies.},
	publisher = {Routledge},
	author = {Raymond, Chase Wesley and Olguín, Luis Manuel},
	month = mar,
	year = {2022},
	doi = {10.4324/9780429507274},
}

@article{ter_hoeve_towards_2021,
	title = {Towards {Interactive} {Language} {Modeling}},
	url = {http://arxiv.org/abs/2112.11911},
	abstract = {Interaction between caregivers and children plays a critical role in human language acquisition and development. Given this observation, it is remarkable that explicit interaction plays little to no role in artificial language modeling -- which also targets the acquisition of human language, yet by artificial models. Moreover, an interactive approach to language modeling has the potential to make language models substantially more versatile and to considerably impact downstream applications. Motivated by these considerations, we pioneer the space of interactive language modeling. As a first contribution we present a road map in which we detail the steps that need to be taken towards interactive language modeling. We then lead by example and take the first steps on this road map, showing the initial feasibility of our approach. As such, this work aims to be the start of a larger research agenda on interactive language modeling.},
	urldate = {2022-01-14},
	journal = {arXiv:2112.11911 [cs]},
	author = {ter Hoeve, Maartje and Kharitonov, Evgeny and Hupkes, Dieuwke and Dupoux, Emmanuel},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.11911
version: 1},
}

@article{allen_toward_2001,
	title = {Toward {Conversational} {Human}-{Computer} {Interaction}},
	volume = {22},
	copyright = {Copyright (c)},
	issn = {2371-9621},
	url = {https://ojs.aaai.org/index.php/aimagazine/article/view/1590},
	doi = {10.1609/aimag.v22i4.1590},
	abstract = {The belief that humans will be able to interact with computers in conversational speech has long been a favorite subject in science fiction, reflecting the persistent belief that spoken dialogue would be the most natural and powerful user interface to computers. With recent improvements in computer technology and in speech and language processing, such systems are starting to appear feasible. There are significant technical problems that still need to be solved before speech-driven interfaces become truly conversational. This article describes the results of a 10-year effort building robust spoken dialogue systems at the University of Rochester.},
	language = {en},
	number = {4},
	urldate = {2022-01-11},
	journal = {AI Magazine},
	author = {Allen, James F. and Byron, Donna K. and Dzikovska, Myroslava and Ferguson, George and Galescu, Lucian and Stent, Amanda},
	month = dec,
	year = {2001},
	note = {Number: 4},
	pages = {27--27},
}

@incollection{thorisson_natural_2002,
	address = {Dordrecht},
	series = {Text, {Speech} and {Language} {Technology}},
	title = {Natural {Turn}-{Taking} {Needs} {No} {Manual}: {Computational} {Theory} and {Model}, from {Perception} to {Action}},
	isbn = {978-94-017-2367-1},
	shorttitle = {Natural {Turn}-{Taking} {Needs} {No} {Manual}},
	url = {https://doi.org/10.1007/978-94-017-2367-1_8},
	abstract = {Decisions like these are made by dialogue participants as often as 2–3 times per second. For a 30 minute conversation that’s over 5000 decisions. And that’s just a fraction of what goes on. How do we do it? Face-to-face dialogue consists of interaction between several complex, dynamic systems — visual and auditory display of information, internal processing, knee-jerk reactions, thought-out rhetoric, learned patterns, social convention, etc. One could postulate that the power of dialogue is a direct result of this fact. However, combining a multitude of systems in one place does not guarantee a coherent outcome such as goal-directed dialogue. For this to happen the systems need to be architected in a way that guides their interaction and ensures that — complex as it may be — the interaction tends towards homeostasis in light of errors and uncertainties, towards the set of goals shared by participants.},
	language = {en},
	urldate = {2018-10-24},
	booktitle = {Multimodality in {Language} and {Speech} {Systems}},
	publisher = {Springer Netherlands},
	author = {Thórisson, Kristinn R.},
	editor = {Granström, Björn and House, David and Karlsson, Inger},
	year = {2002},
	doi = {10.1007/978-94-017-2367-1_8},
	pages = {173--207},
}

@article{mielke_between_2021,
	title = {Between words and characters: {A} {Brief} {History} of {Open}-{Vocabulary} {Modeling} and {Tokenization} in {NLP}},
	shorttitle = {Between words and characters},
	url = {http://arxiv.org/abs/2112.10508},
	abstract = {What are the units of text that we want to model? From bytes to multi-word expressions, text can be analyzed and generated at many granularities. Until recently, most natural language processing (NLP) models operated over words, treating those as discrete and atomic tokens, but starting with byte-pair encoding (BPE), subword-based approaches have become dominant in many areas, enabling small vocabularies while still allowing for fast inference. Is the end of the road character-level model or byte-level processing? In this survey, we connect several lines of work from the pre-neural and neural era, by showing how hybrid approaches of words and characters as well as subword-based approaches based on learned segmentation have been proposed and evaluated. We conclude that there is and likely will never be a silver bullet singular solution for all applications and that thinking seriously about tokenization remains important for many applications.},
	urldate = {2021-12-23},
	journal = {arXiv:2112.10508 [cs]},
	author = {Mielke, Sabrina J. and Alyafeai, Zaid and Salesky, Elizabeth and Raffel, Colin and Dey, Manan and Gallé, Matthias and Raja, Arun and Si, Chenglei and Lee, Wilson Y. and Sagot, Benoît and Tan, Samson},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.10508},
}

@article{blasi_soundmeaning_2016,
	title = {Sound–meaning association biases evidenced across thousands of languages},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/content/early/2016/09/06/1605782113},
	doi = {10.1073/pnas.1605782113},
	abstract = {It is widely assumed that one of the fundamental properties of spoken language is the arbitrary relation between sound and meaning. Some exceptions in the form of nonarbitrary associations have been documented in linguistics, cognitive science, and anthropology, but these studies only involved small subsets of the 6,000+ languages spoken in the world today. By analyzing word lists covering nearly two-thirds of the world’s languages, we demonstrate that a considerable proportion of 100 basic vocabulary items carry strong associations with specific kinds of human speech sounds, occurring persistently across continents and linguistic lineages (linguistic families or isolates). Prominently among these relations, we find property words (“small” and i, “full” and p or b) and body part terms (“tongue” and l, “nose” and n). The areal and historical distribution of these associations suggests that they often emerge independently rather than being inherited or borrowed. Our results therefore have important implications for the language sciences, given that nonarbitrary associations have been proposed to play a critical role in the emergence of cross-modal mappings, the acquisition of language, and the evolution of our species’ unique communication system.},
	language = {en},
	urldate = {2016-09-12},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Blasi, Damián E. and Wichmann, Søren and Hammarström, Harald and Stadler, Peter F. and Christiansen, Morten H.},
	month = sep,
	year = {2016},
	pages = {201605782},
}

@article{fuchs_longitudinal_2021,
	title = {A {Longitudinal} {Study} of {Speech} {Acoustics} in {Older} {French} {Females}: {Analysis} of the {Filler} {Particle} euh across {Utterance} {Positions}},
	volume = {6},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {A {Longitudinal} {Study} of {Speech} {Acoustics} in {Older} {French} {Females}},
	url = {https://www.mdpi.com/2226-471X/6/4/211},
	doi = {10.3390/languages6040211},
	abstract = {Aging in speech production is a multidimensional process. Biological, cognitive, social, and communicative factors can change over time, stay relatively stable, or may even compensate for each other. In this longitudinal work, we focus on stability and change at the laryngeal and supralaryngeal levels in the discourse particle euh produced by 10 older French-speaking females at two times, 10 years apart. Recognizing the multiple discourse roles of euh, we divided out occurrences according to utterance position. We quantified the frequency of euh, and evaluated acoustic changes in formants, fundamental frequency, and voice quality across time and utterance position. Results showed that euh frequency was stable with age. The only acoustic measure that revealed an age effect was harmonics-to-noise ratio, showing less noise at older ages. Other measures mostly varied with utterance position, sometimes in interaction with age. Some voice quality changes could reflect laryngeal adjustments that provide for airflow conservation utterance-finally. The data suggest that aging effects may be evident in some prosodic positions (e.g., utterance-final position), but not others (utterance-initial position). Thus, it is essential to consider the interactions among these factors in future work and not assume that vocal aging is evident throughout the signal.},
	language = {en},
	number = {4},
	urldate = {2021-12-22},
	journal = {Languages},
	author = {Fuchs, Susanne and Koenig, Laura L. and Gerstenberg, Annette},
	month = dec,
	year = {2021},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {211},
}

@article{wakefield_ethnomethodology-problems_2000,
	title = {Ethnomethodology-{The} problems of unique adequacy},
	volume = {5},
	issn = {1361-4096},
	url = {https://doi.org/10.1177/136140960000500109},
	doi = {10.1177/136140960000500109},
	abstract = {This paper has been developed from an ethnomethodological study examining the practicalities of organising surgical nursing work. The discussion explores the extent to which ethnomethodology can be employed to extrapolate data from the investigative domain. The concept of 'unique adequacy' has been examined in considerable detail, as this element of the methodology created significant problems when analysing the data. 'Unique adequacy' is defined here as the researcher's ability to analyse the encountered social world from practitioner research rather than from 'classical social theorising' (Cuff et al., 1992) perspectives. The debate focuses particular attention on highlighting the difficulties encountered when attempting to achieve 'ethnomethodological indifference' (Garfinkel, 1986), that is, the researcher's ability to remain non-judgemental when reporting on the findings.},
	language = {en},
	number = {1},
	urldate = {2021-12-16},
	journal = {NT Research},
	author = {Wakefield, Ann},
	month = jan,
	year = {2000},
	note = {Publisher: SAGE Publications},
	pages = {46--53},
}

@article{bergey_learning_nodate,
	title = {Learning {Communicative} {Acts} in {Children}'s {Conversations}: {A} {Hidden} {Topic} {Markov} {Model} {Analysis} of the {CHILDES} {Corpora}},
	volume = {n/a},
	issn = {1756-8765},
	shorttitle = {Learning {Communicative} {Acts} in {Children}'s {Conversations}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12591},
	doi = {10.1111/tops.12591},
	abstract = {Over their first years of life, children learn not just the words of their native languages, but how to use them to communicate. Because manual annotation of communicative intent does not scale to large corpora, our understanding of communicative act development is limited to case studies of a few children at a few time points. We present an approach to automatic identification of communicative acts using a hidden topic Markov model, applying it to the conversations of English-learning children in the CHILDES database. We first describe qualitative changes in parent–child communication over development, and then use our method to demonstrate two large-scale features of communicative development: (a) children develop a parent-like repertoire of our model's communicative acts rapidly, their learning rate peaking around 14 months of age, and (b) this period of steep repertoire change coincides with the highest predictability between parents' acts and children's, suggesting that structured interactions play a role in learning to communicate.},
	language = {en},
	number = {n/a},
	urldate = {2021-12-17},
	journal = {Topics in Cognitive Science},
	author = {Bergey, Claire and Marshall, Zoe and DeDeo, Simon and Yurovsky, Daniel},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/tops.12591},
}

@article{torre_physical_2019,
	title = {On the physical origin of linguistic laws and lognormality in speech},
	volume = {6},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.191023},
	doi = {10.1098/rsos.191023},
	abstract = {Physical manifestations of linguistic units include sources of variability due to factors of speech production which are by definition excluded from counts of linguistic symbols. In this work, we examine whether linguistic laws hold with respect to the physical manifestations of linguistic units in spoken English. The data we analyse come from a phonetically transcribed database of acoustic recordings of spontaneous speech known as the Buckeye Speech corpus. First, we verify with unprecedented accuracy that acoustically transcribed durations of linguistic units at several scales comply with a lognormal distribution, and we quantitatively justify this ‘lognormality law’ using a stochastic generative model. Second, we explore the four classical linguistic laws (Zipf’s Law, Herdan’s Law, Brevity Law and Menzerath–Altmann’s Law (MAL)) in oral communication, both in physical units and in symbolic units measured in the speech transcriptions, and find that the validity of these laws is typically stronger when using physical units than in their symbolic counterpart. Additional results include (i) coining a Herdan’s Law in physical units, (ii) a precise mathematical formulation of Brevity Law, which we show to be connected to optimal compression principles in information theory and allows to formulate and validate yet another law which we call the size-rank law or (iii) a mathematical derivation of MAL which also highlights an additional regime where the law is inverted. Altogether, these results support the hypothesis that statistical laws in language have a physical origin.},
	number = {8},
	urldate = {2021-12-17},
	journal = {Royal Society Open Science},
	author = {Torre, Iván G. and Luque, Bartolo and Lacasa, Lucas and Kello, Christopher T. and Hernández-Fernández, Antoni},
	year = {2019},
	note = {Publisher: Royal Society},
	pages = {191023},
}

@article{ortega_shaking_2021,
	title = {Shaking the foundations: delusions in sequence models for interaction and control},
	shorttitle = {Shaking the foundations},
	url = {http://arxiv.org/abs/2110.10819},
	abstract = {The recent phenomenal success of language models has reinvigorated machine learning research, and large sequence models such as transformers are being applied to a variety of domains. One important problem class that has remained relatively elusive however is purposeful adaptive behavior. Currently there is a common perception that sequence models "lack the understanding of the cause and effect of their actions" leading them to draw incorrect inferences due to auto-suggestive delusions. In this report we explain where this mismatch originates, and show that it can be resolved by treating actions as causal interventions. Finally, we show that in supervised learning, one can teach a system to condition or intervene on data by training with factual and counterfactual error signals respectively.},
	urldate = {2021-12-15},
	journal = {arXiv:2110.10819 [cs]},
	author = {Ortega, Pedro A. and Kunesch, Markus and Delétang, Grégoire and Genewein, Tim and Grau-Moya, Jordi and Veness, Joel and Buchli, Jonas and Degrave, Jonas and Piot, Bilal and Perolat, Julien and Everitt, Tom and Tallec, Corentin and Parisotto, Emilio and Erez, Tom and Chen, Yutian and Reed, Scott and Hutter, Marcus and de Freitas, Nando and Legg, Shane},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.10819},
}

@article{morriss_dirty_2016,
	title = {Dirty secrets and being ‘strange’: using ethnomethodology to move beyond familiarity},
	volume = {16},
	issn = {1468-7941},
	shorttitle = {Dirty secrets and being ‘strange’},
	url = {https://doi.org/10.1177/1468794115598194},
	doi = {10.1177/1468794115598194},
	abstract = {The paper is a discussion of my attempt to move beyond familiarity by using ethnomethodology – and the emotional impact of doing so; namely, the feeling of having a ‘dirty secret’. As a social work group member interviewing social workers, the process of fieldwork was all too familiar. However, during transcription and analysis, what I had considered to be ‘business as usual’ was revealed as something more complex. The paper describes how the ethnomethodological notions of being a member, the unique adequacy requirement of methods, and breaching worked to make the familiar strange and became key to my understanding.},
	language = {en},
	number = {5},
	urldate = {2021-12-16},
	journal = {Qualitative Research},
	author = {Morriss, Lisa},
	month = oct,
	year = {2016},
	note = {Publisher: SAGE Publications},
	pages = {526--540},
}

@article{pougnault_social_2021,
	title = {Social pressure drives “conversational rules” in great apes},
	issn = {1469-185X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/brv.12821},
	doi = {10.1111/brv.12821},
	abstract = {In the last decade, two hypotheses, one on the evolution of animal vocal communication in general and the other on the origins of human language, have gained ground. The first hypothesis argues that the complexity of communication co-evolved with the complexity of sociality. Species forming larger groups with complex social networks have more elaborate vocal repertoires. The second hypothesis posits that the core of communication is represented not only by what can be expressed by an isolated caller, but also by the way that vocal interactions are structured, language being above all a social act. Primitive forms of conversational rules based on a vocal turn-taking principle are thought to exist in primates. To support and bring together these hypotheses, more comparative studies of socially diverse species at different levels of the primate phylogeny are needed. However, the majority of available studies focus on monkeys, primates that are distant from the human lineage. Great apes represent excellent candidates for such comparative studies because of their phylogenetic proximity to humans and their varied social lives. We propose that studying vocal turn-taking in apes could address several major gaps regarding the social relevance of vocal turn-taking and the evolutionary trajectory of this behaviour among anthropoids. Indeed, how the social structure of a species may influence the vocal interaction patterns observed among group members remains an open question. We gathered data from the literature as well as original unpublished data (where absent in the literature) on four great ape species: chimpanzees Pan troglodytes, bonobos Pan paniscus, western lowland gorillas Gorilla gorilla gorilla and Bornean orang-utans Pongo pygmaeus. We found no clear-cut relationship between classical social complexity metrics (e.g. number of group members, interaction rates) and vocal complexity parameters (e.g. repertoire size, call rates). Nevertheless, the nature of the society (i.e. group composition, diversity and valence of social bonds) and the type of vocal interaction patterns (isolated calling, call overlap, turn-taking-based vocal exchanges) do appear to be related. Isolated calling is the main vocal pattern found in the species with the smallest social networks (orang-utan), while the other species show vocal interactions that are structured according to temporal rules. A high proportion of overlapping vocalisations is found in the most competitive species (chimpanzee), while vocal turn-taking predominates in more tolerant bonobos and gorillas. Also, preferentially interacting individuals and call types used to interact are not randomly distributed. Vocal overlap (‘chorusing’) and vocal exchange (‘conversing’) appear as possible social strategies used to advertise/strengthen social bonds. Our analyses highlight that: (i) vocal turn-taking is also observed in non-human great apes, revealing universal rules for conversing that may be deeply rooted in the primate lineage; (ii) vocal interaction patterns match the species’ social lifestyle; (iii) although limited to four species here, adopting a targeted comparative approach could help to identify the multiple and subtle factors underlying social and vocal complexity. We believe that vocal interaction patterns form the basis of a promising field of investigation that may ultimately improve our understanding of the socially driven evolution of communication.},
	language = {en},
	urldate = {2021-12-16},
	journal = {Biological Reviews},
	author = {Pougnault, Loïc and Levréro, Florence and Leroux, Maël and Paulet, Julien and Bombani, Pablo and Dentressangle, Fabrice and Deruti, Laure and Mulot, Baptiste and Lemasson, Alban},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/brv.12821},
}

@article{auracher_sound-meaning_2021,
	title = {Sound-meaning relations in {Japanese} {Tanka}: {Formant} dispersion of vowels is associated with dominance and activity},
	volume = {11},
	issn = {2210-4372, 2210-4380},
	shorttitle = {Sound-meaning relations in {Japanese} {Tanka}},
	url = {https://benjamins.com/catalog/ssol.21006.aur},
	doi = {10.1075/ssol.21006.aur},
	abstract = {Abstract
            This study aimed to test sound-meaning relations in Japanese poetry. To this end, participants assessed the sentiments expressed in a random selection of Tanka (a specific form of Japanese poetry) on six bipolar scales comprising Evaluation (emotional valence), Potency (dominance), and Activity (arousal). The selected Tanka differed with regard to their average formant-dispersion (i.e., the distance between the first and second formant). Corroborating results of a previous study that tested the relation between formant dispersion and emotional tone in German poetry, results suggest that poems with an extremely low average formant dispersion have a significantly higher likelihood of expressing dominance and activity than poems with an extremely high formant dispersion. No significant differences regarding the Evaluation dimension were found.},
	language = {en},
	number = {1},
	urldate = {2021-12-17},
	journal = {Scientific Study of Literature},
	author = {Auracher, Jan},
	month = dec,
	year = {2021},
	pages = {3--34},
}

@article{semple_linguistic_2021,
	title = {Linguistic laws in biology},
	issn = {0169-5347},
	url = {https://www.sciencedirect.com/science/article/pii/S0169534721002305},
	doi = {10.1016/j.tree.2021.08.012},
	abstract = {Linguistic laws, the common statistical patterns of human language, have been investigated by quantitative linguists for nearly a century. Recently, biologists from a range of disciplines have started to explore the prevalence of these laws beyond language, finding patterns consistent with linguistic laws across multiple levels of biological organisation, from molecular (genomes, genes, and proteins) to organismal (animal behaviour) to ecological (populations and ecosystems). We propose a new conceptual framework for the study of linguistic laws in biology, comprising and integrating distinct levels of analysis, from description to prediction to theory building. Adopting this framework will provide critical new insights into the fundamental rules of organisation underpinning natural systems, unifying linguistic laws and core theory in biology.},
	language = {en},
	urldate = {2021-09-29},
	journal = {Trends in Ecology \& Evolution},
	author = {Semple, Stuart and Ferrer-i-Cancho, Ramon and Gustison, Morgan L.},
	month = sep,
	year = {2021},
}

@article{andreas_cetacean_nodate,
	title = {Cetacean {Translation} {Initiative}: a roadmap to deciphering the communication of sperm whales},
	abstract = {The past decade has witnessed a groundbreaking rise of machine learning for human language analysis, with current methods capable of automatically accurately recovering various aspects of syntax and semantics — including sentence structure and grounded word meaning — from large data collections. Recent research showed the promise of such tools for analyzing acoustic communication in nonhuman species. We posit that machine learning will be the cornerstone of future collection, processing, and analysis of multimodal streams of data in animal communication studies, including bioacoustic, behavioral, biological, and environmental data. Cetaceans are unique non-human model species as they possess sophisticated acoustic communications, but utilize a very different encoding system that evolved in an aquatic rather than terrestrial medium. Sperm whales, in particular, with their highly-developed neuroanatomical features, cognitive abilities, social structures, and discrete click-based encoding make for an excellent starting point for advanced machine learning tools that can be applied to other animals in the future. This paper details a roadmap toward this goal based on currently existing technology and multidisciplinary scientific community effort. We outline the key elements required for the collection and processing of massive bioacoustic data of sperm whales, detecting their basic communication units and languagelike higher-level structures, and validating these models through interactive playback experiments. The technological capabilities developed by such an undertaking are likely to yield cross-applications and advancements in broader communities investigating non-human communication and animal behavioral research.},
	language = {en},
	author = {Andreas, Jacob and Beguš, Gašper and Bronstein, Michael M and Diamant, Roee and Delaney, Denley and Goldwasser, Shafi and Gruber, David F and de Haas, Sarah and Malkin, Peter and Payne, Roger and Petri, Giovanni and Rus, Daniela and Sharma, Pratyusha and Tchernov, Dan and Tønnesen, Pernille and Vogt, Daniel and Wood, Robert J},
	keywords = {*need to read},
	pages = {29},
}

@inproceedings{aksenova_how_2021,
	address = {Online},
	title = {How {Might} {We} {Create} {Better} {Benchmarks} for {Speech} {Recognition}?},
	url = {https://aclanthology.org/2021.bppf-1.4},
	doi = {10.18653/v1/2021.bppf-1.4},
	abstract = {The applications of automatic speech recognition (ASR) systems are proliferating, in part due to recent significant quality improvements. However, as recent work indicates, even state-of-the-art speech recognition systems – some which deliver impressive benchmark results, struggle to generalize across use cases. We review relevant work, and, hoping to inform future benchmark development, outline a taxonomy of speech recognition use cases, proposed for the next generation of ASR benchmarks. We also survey work on metrics, in addition to the de facto standard Word Error Rate (WER) metric, and we introduce a versatile framework designed to describe interactions between linguistic variation and ASR performance metrics.},
	urldate = {2021-12-11},
	booktitle = {Proceedings of the 1st {Workshop} on {Benchmarking}: {Past}, {Present} and {Future}},
	publisher = {Association for Computational Linguistics},
	author = {Aksënova, Alëna and van Esch, Daan and Flynn, James and Golik, Pavel},
	month = aug,
	year = {2021},
	pages = {22--34},
}

@inproceedings{ritchie_unified_2019,
	title = {Unified {Verbalization} for {Speech} {Recognition} \& {Synthesis} {Across} {Languages}},
	url = {https://www.isca-speech.org/archive/interspeech_2019/ritchie19_interspeech.html},
	doi = {10.21437/Interspeech.2019-2807},
	abstract = {We describe a new approach to converting written tokens to their spoken form, which can be shared by automatic speech recognition (ASR) and text-to-speech synthesis (TTS) systems. Both ASR and TTS need to map from the written to the spoken domain, and we present an approach that enables us to share verbalization grammars between the two systems while exploiting linguistic commonalities to provide simple default verbalizations. We also describe improvements to an induction system for number names grammars. Between these shared ASR/TTS verbalizers and the improved induction system for number names grammars, we achieve signiﬁcant gains in development time and scalability across languages.},
	language = {en},
	urldate = {2021-12-11},
	booktitle = {Interspeech 2019},
	publisher = {ISCA},
	author = {Ritchie, Sandy and Sproat, Richard and Gorman, Kyle and Esch, Daan van and Schallhart, Christian and Bampounis, Nikos and Brard, Benoît and Mortensen, Jonas Fromseier and Holt, Millie and Mahon, Eoin},
	month = sep,
	year = {2019},
	pages = {3530--3534},
}

@article{musgrave_language_2021,
	title = {The {Language} {Documentation} {Quartet}},
	volume = {1},
	url = {https://journals.colorado.edu/index.php/computel/article/view/951},
	doi = {10.33011/computel.v1i.951},
	abstract = {As we noted in an earlier paper (Musgrave \& Thieberger 2012), the written description of a language is an essentially hypertextual exercise, linking various kinds of material in a dense network. An aim based on that insight is to provide a model that can be implemented in tools for language documentation, allowing instantiation of the links always followed in writing a grammar or a dictionary, tracking backwards and forwards to the texts and media as the source of authority for claims made in an analysis. Our earlier paper described our initial efforts to encode Heath’s (1984) grammar, texts (1980), and dictionary (1982) of Nunggubuyu, an Australian language from eastern Arnhemland. We chose this body of work because it was written with many internal links between the three volumes. The links are all encoded with textual indexes which looked to be ready to be instantiated as automated hyperlinks once the technology was available. In this paper, we discuss our progress in identifying how the four component parts of a description (grammar, text, dictionary, media, henceforth the quartet) can be interlinked, what are the logical points at which to join them, and whether there are practical limits to how far this linking should be carried. We suggest that the problems which are exposed in this process can inform the development of an abstract or theoretical data structure for each of the components and these in turn can provide models for language documentation work which can feed into hypertext presentations of the type we are developing.},
	language = {en},
	number = {2},
	urldate = {2021-12-11},
	journal = {Proceedings of the Workshop on Computational Methods for Endangered Languages},
	author = {Musgrave, Simon and Thieberger, Nicholas},
	year = {2021},
}

@article{adams_user-friendly_2021,
	title = {User-{Friendly} {Automatic} {Transcription} of {Low}-{Resource} {Languages}: {Plugging} {ESPnet} into {Elpis}},
	volume = {1},
	shorttitle = {User-{Friendly} {Automatic} {Transcription} of {Low}-{Resource} {Languages}},
	url = {https://journals.colorado.edu/index.php/computel/article/view/969},
	doi = {10.33011/computel.v1i.969},
	abstract = {This paper reports on progress integrating the speech recognition toolkit ESPnet into Elpis, a web front-end originally designed to provide access to the Kaldi automatic speech recognition toolkit. The goal of this work is to make end-to-end speech recognition models available to language workers via a user-friendly graphical interface. Encouraging results are reported on (i) development of an ESPnet recipe for use in Elpis, with preliminary results on data sets previously used for training acoustic models with the Persephone toolkit along with a new data set that had not previously been used in speech recognition, and (ii) incorporating ESPnet into Elpis along with UI enhancements and a CUDA-supported Dockerﬁle.},
	language = {en},
	number = {2},
	urldate = {2021-12-11},
	journal = {Proceedings of the Workshop on Computational Methods for Endangered Languages},
	author = {Adams, Oliver},
	year = {2021},
}

@article{levow_developing_2021,
	title = {Developing a {Shared} {Task} for {Speech} {Processing} on {Endangered} {Languages}},
	volume = {1},
	url = {https://journals.colorado.edu/index.php/computel/article/view/967},
	doi = {10.33011/computel.v1i.967},
	abstract = {Advances in speech and language processing have enabled the creation of applications that could, in principle, accelerate the process of language documentation, as speech communities and linguists work on urgent language documentation and reclamation projects. However, such systems have yet to make a signiﬁcant impact on language documentation, as resource requirements limit the broad applicability of these new techniques. We aim to exploit the framework of shared tasks to focus the technology research community on tasks which address key pain points in language documentation. Here we present initial steps in the implementation of these new shared tasks, through the creation of data sets drawn from endangered language repositories and baseline systems to perform segmentation and speaker labeling of these audio recordings—important enabling steps in the documentation process. This paper motivates these tasks with a use case, describes data set curation and baseline systems, and presents results on this data. We then highlight the challenges and ethical considerations in developing these speech processing tools and tasks to support endangered language documentation.},
	language = {en},
	number = {2},
	urldate = {2021-12-11},
	journal = {Proceedings of the Workshop on Computational Methods for Endangered Languages},
	author = {Levow, Gina-Anne and Ahn, Emily P. and Bender, Emily M.},
	year = {2021},
}

@article{ruinskiy_effective_2007,
	title = {An {Effective} {Algorithm} for {Automatic} {Detection} and {Exact} {Demarcation} of {Breath} {Sounds} in {Speech} and {Song} {Signals}},
	volume = {15},
	issn = {1558-7924},
	doi = {10.1109/TASL.2006.889750},
	abstract = {Automatic detection of predefined events in speech and audio signals is a challenging and promising subject in signal processing. One important application of such detection is removal or suppression of unwanted sounds in audio recordings, for instance in the professional music industry, where the demand for quality is very high. Breath sounds, which are present in most song recordings and often degrade the aesthetic quality of the voice, are an example of such unwanted sounds. Another example is bad pronunciation of certain phonemes. In this paper, we present an automatic algorithm for accurate detection of breaths in speech or song signals. The algorithm is based on a template matching approach, and consists of three phases. In the first phase, a template is constructed from mel frequency cepstral coefficients (MFCCs) matrices of several breath examples and their singular value decompositions, to capture the characteristics of a typical breath event. Next, in the initial processing phase, each short-time frame is compared to the breath template, and marked as breathy or nonbreathy according to predefined thresholds. Finally, an edge detection algorithm, based on various time-domain and frequency-domain parameters, is applied to demarcate the exact boundaries of each breath event and to eliminate possible false detections. Evaluation of the algorithm on a database of speech and songs containing several hundred breath sounds yielded a correct identification rate of 98\% with a specificity of 96\%},
	number = {3},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Ruinskiy, Dima and Lavner, Yizhar},
	month = mar,
	year = {2007},
	note = {Conference Name: IEEE Transactions on Audio, Speech, and Language Processing},
	pages = {838--850},
}

@book{levy_gesture_2007,
	title = {Gesture and the dynamic dimension of language essays in honor of {David} {McNeill}},
	isbn = {978-90-272-9250-6},
	url = {https://doi.org/10.1075/gs.1},
	abstract = {Each of the 21 chapters in this volume reflects a view of language as a dynamic phenomenon with emergent structure, and in each, gesture is approached as part of language, not an adjunct to it. In this, all of the authors have been influenced by David McNeill's methods for studying natural discourse and by his theory of the human capacity for language. The introductory chapter by Adam Kendon contextualizes McNeill's research paradigm within a history of earlier gesture studies. Chapters in the first section, Language and Cognition, emphasize what McNeill refers to as the intrapersonal plane. M},
	language = {English},
	urldate = {2021-12-09},
	author = {Levy, Duncan, Susan D, Elena Terry and Cassell, Justine},
	year = {2007},
	note = {OCLC: 1176275548},
}

@incollection{levy_body_2007,
	title = {The {Body} in {Communication}: {Lessons} from the {Near}-{Human}},
	isbn = {978-90-272-9250-6},
	url = {https://doi.org/10.1075/gs.1},
	abstract = {Each of the 21 chapters in this volume reflects a view of language as a dynamic phenomenon with emergent structure, and in each, gesture is approached as part of language, not an adjunct to it. In this, all of the authors have been influenced by David McNeill's methods for studying natural discourse and by his theory of the human capacity for language. The introductory chapter by Adam Kendon contextualizes McNeill's research paradigm within a history of earlier gesture studies. Chapters in the first section, Language and Cognition, emphasize what McNeill refers to as the intrapersonal plane. M},
	language = {English},
	urldate = {2021-12-09},
	booktitle = {Gesture and the dynamic dimension of language essays in honor of {David} {McNeill}},
	author = {Cassell, Justine},
	editor = {Levy, Elena Terry and Duncan, Susan D. and Cassell, Justine},
	year = {2007},
	note = {OCLC: 1176275548},
}

@article{tzoukermann_advances_2021,
	title = {Advances in {Low}-{Resource} and {Endangered} {Languages}},
	volume = {2},
	url = {https://journals.colorado.edu/index.php/computel/article/view/983},
	doi = {10.33011/computel.v2i.983},
	abstract = {This paper reports on the approaches and results for the collection, analysis, and processing of lowresource and endangered languages carried out under the Low-Resource Languages for Emergent Incidents (LORELEI) Program 1. LORELEI was a multi-year research and development program designed to discover new methods of quickly ramping up human language technology capabilities for low-resource languages, grounded in situations such as humanitarian and disaster relief use cases. The goal was to advance human language technology methods to better enable rapid, low-cost development of capabilities, with a focus on developing methods that apply to languages of any type from any language family, thus eliminating the need to tailor specific technologies to a narrow set of input languages with specific typological characteristics. We report in detail on evaluation scenarios developed for the program.},
	language = {en},
	number = {2},
	urldate = {2021-12-11},
	journal = {Proceedings of the Workshop on Computational Methods for Endangered Languages},
	author = {Tzoukermann, Evelyne and Duncan, Jason D. and Christianson, Caitlin and Onyshkevych, Boyan},
	year = {2021},
}

@article{bakhturina_toolbox_2021,
	title = {A {Toolbox} for {Construction} and {Analysis} of {Speech} {Datasets}},
	volume = {1},
	url = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/38db3aed920cf82ab059bfccbd02be6a-Abstract-round2.html},
	language = {en},
	urldate = {2021-12-06},
	journal = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
	author = {Bakhturina, Evelina and Lavrukhin, Vitaly and Ginsburg, Boris},
	month = dec,
	year = {2021},
}

@article{raji_ai_2021,
	title = {{AI} and the {Everything} in the {Whole} {Wide} {World} {Benchmark}},
	url = {http://arxiv.org/abs/2111.15366},
	abstract = {There is a tendency across different subfields in AI to valorize a small collection of influential benchmarks. These benchmarks operate as stand-ins for a range of anointed common problems that are frequently framed as foundational milestones on the path towards flexible and generalizable AI systems. State-of-the-art performance on these benchmarks is widely understood as indicative of progress towards these long-term goals. In this position paper, we explore the limits of such benchmarks in order to reveal the construct validity issues in their framing as the functionally "general" broad measures of progress they are set up to be.},
	urldate = {2021-12-06},
	journal = {arXiv:2111.15366 [cs]},
	author = {Raji, Inioluwa Deborah and Bender, Emily M. and Paullada, Amandalynne and Denton, Emily and Hanna, Alex},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.15366},
}

@article{stave_optimization_2021,
	title = {Optimization of morpheme length: a cross-linguistic assessment of {Zipf}’s and {Menzerath}’s laws},
	volume = {7},
	issn = {2199-174X},
	shorttitle = {Optimization of morpheme length},
	url = {https://www.degruyter.com/document/doi/10.1515/lingvan-2019-0076/html},
	doi = {10.1515/lingvan-2019-0076},
	abstract = {Zipf’s Law of Abbreviation and Menzerath’s Law both make predictions about the length of linguistic units, based on corpus frequency and the length of the carrier unit. Each contributes to the efficiency of languages: for Zipf, units are more likely to be reduced when they are highly predictable, due to their frequency; for Menzerath, units are more likely to be reduced when there are more sub-units to contribute to the structural information of the carrier unit. However, it remains unclear how the two laws work together in determining unit length at a given level of linguistic structure. We examine this question regarding the length of morphemes in spoken corpora of nine typologically diverse languages drawn from the DoReCo corpus, showing that Zipf’s Law is a stronger predictor, but that the two laws interact with one another. We also explore how this is affected by specific typological characteristics, such as morphological complexity.},
	language = {en},
	number = {s3},
	urldate = {2021-12-05},
	journal = {Linguistics Vanguard},
	author = {Stave, Matthew and Paschen, Ludger and Pellegrino, François and Seifart, Frank},
	month = may,
	year = {2021},
	note = {Publisher: De Gruyter Mouton},
}

@article{strunk_determinants_2020,
	title = {Determinants of phonetic word duration in ten language documentation corpora: {Word} frequency, complexity, position, and part of speech},
	volume = {14},
	copyright = {Creative Commons Attribution-NonCommercial 4.0 International},
	issn = {1934-5275},
	shorttitle = {Determinants of phonetic word duration in ten language documentation corpora},
	url = {http://scholarspace.manoa.hawaii.edu/handle/10125/24926},
	abstract = {This paper explores the application of quantitative methods to study the effect of various factors on phonetic word duration in ten languages. Data on most of these languages were collected in fieldwork aiming at documenting spontaneous speech in mostly endangered languages, to be used for multiple purposes, including the preservation of cultural heritage and community work. Here we show the feasibility of studying processes of online acceleration and deceleration of speech across languages using such data, which have not been considered for this purpose before. Our results show that it is possible to detect a consistent effect of higher frequency of words leading to faster articulation even in the relatively small language documentation corpora used here. We also show that nouns tend to be pronounced more slowly than verbs when controlling for other factors. Comparison of the effects of these and other factors shows that some of them are difficult to capture with the current data and methods, including potential effects of cross-linguistic differences in morphological complexity. In general, this paper argues for widening the cross-linguistic scope of phonetic and psycholinguistic research by including the wealth of language documentation data that has recently become available.},
	language = {en-US},
	urldate = {2021-12-05},
	journal = {Language Documentation \& Conservation},
	author = {Strunk, Jan and Seifart, Frank and Danielsen, Swintha and Hartmann, Iren and Pakendorf, Brigitte and Wichmann, Søren and Witzlack-Makarevich, Alena and Bickel, Balthasar},
	month = jul,
	year = {2020},
	note = {Accepted: 2020-07-21T19:27:01Z
Publisher: University of Hawaii Press},
	pages = {423--461},
}

@inproceedings{stave_bioinformatics_2019,
	address = {Orléans},
	title = {A bioinformatics solution to inter-rater agreement for forced timealignment of data from underresourced languages},
	abstract = {Precise time-alignment for sequences of annotations is a prerequisite for phonological analysis, and
an important aspect of oral linguistics. The DoReCo project relies on phonemic time-alignment by
MAUS software (Kisler et al. 2017) and, to evaluate its precision, must measure inter-rater agreement between MAUS-aligned and manually-aligned segments, which involve adding, removing, and changing annotation units. This situation proves highly problematic for inter-rater agreement. The Needleman-Wunsch algorithm, from the bioinformatics field, offers a practical and
powerful solution to that problem. Its implementation, when compared with a manual correction, matched over 95\% of all units correctly. The algorithm offers a newfound precision for inter-rater agreement measurement, and has further applications where precise matching is required},
	author = {Stave, Matthew and Delafontaine, Francois and Seifart, Frank and Paschen, Ludger},
	year = {2019},
}

@incollection{paquot_analyzing_2020,
	address = {Cham},
	title = {Analyzing {Dispersion}},
	isbn = {978-3-030-46215-4 978-3-030-46216-1},
	url = {https://link.springer.com/10.1007/978-3-030-46216-1_5},
	language = {en},
	urldate = {2021-12-03},
	booktitle = {A {Practical} {Handbook} of {Corpus} {Linguistics}},
	publisher = {Springer International Publishing},
	author = {Gries, Stefan Th.},
	editor = {Paquot, Magali and Gries, Stefan Th.},
	year = {2020},
	doi = {10.1007/978-3-030-46216-1_5},
	pages = {99--118},
}

@article{burch_measuring_2016,
	title = {Measuring and interpreting lexical dispersion in corpus linguistics},
	volume = {3},
	issn = {2052-4188},
	url = {https://journal.equinoxpub.com/JRDS/article/view/9480},
	doi = {10.1558/jrds.33066},
	abstract = {The frequency of occurrence and the dispersion of a word are measures of a word’s importance in a collection of texts or a corpus. In particular, lexical dispersion is a statistic in corpus linguistics that measures a word’s homogeneity across the parts of a corpus. There are different ways to measure dispersion and the authors compare three approaches. Both formulaic and interpretative issues pertaining to dispersion are discussed in terms of the frequency of a word in the corpus parts and the variability of a word across the corpus. A simulation study and an application involving words from the British National Corpus indicate that the index constructed from the difference between every possible pair of frequencies of the word in the parts of a corpus is preferred.},
	language = {en},
	number = {2},
	urldate = {2021-12-03},
	journal = {Journal of Research Design and Statistics in Linguistics and Communication Science},
	author = {Burch, Brent and Egbert, Jesse and Biber, Douglas},
	year = {2016},
	pages = {189--216},
}

@inproceedings{suzuki_speech_2016,
	title = {Speech recognition robust against speech overlapping in monaural recordings of telephone conversations},
	doi = {10.1109/ICASSP.2016.7472766},
	abstract = {Monaural (single-channel) recording is sometimes used for telephone conversations in call centers. Generally speaking, the accuracy of automatic speech recognition of a monaural recording is worse than that of the multi-channel recording of the same conversation where each speaker's voice is separately recorded. The major reason is that the recognition system fails not only at the overlapping segments where the voices of the multiple speakers overlap, but also at the neighboring segments surrounding the overlapping segments. In this paper, we tackle this problem by using a combination of garbage modeling and noise-robust monaural acoustic modeling. Our proposed method trains the models by making use of multi-channel recordings and transcripts, which are relatively easy to prepare than monaural recordings and transcripts. We present experimental results where the proposed methods reduced the error rates by approximately 3\% relative to the baseline methods for both of GMM-HMM and CNN-HMM cases. Because the proposed method is quite simple, the proposed method is easy to deploy to wide range of ASR systems for monaural speech transcription.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Suzuki, Masayuki and Kurata, Gakuto and Nagano, Tohru and Tachibana, Ryuki},
	month = mar,
	year = {2016},
	note = {ISSN: 2379-190X},
	pages = {5685--5689},
}

@inproceedings{kanda_simultaneous_2019,
	title = {Simultaneous {Speech} {Recognition} and {Speaker} {Diarization} for {Monaural} {Dialogue} {Recordings} with {Target}-{Speaker} {Acoustic} {Models}},
	doi = {10.1109/ASRU46091.2019.9004009},
	abstract = {This paper investigates the use of target-speaker automatic speech recognition (TS-ASR) for simultaneous speech recognition and speaker diarization of single-channel dialogue recordings. TS-ASR is a technique to automatically extract and recognize only the speech of a target speaker given a short sample utterance of that speaker. One obvious drawback of TS-ASR is that it cannot be used when the speakers in the recordings are unknown because it requires a sample of the target speakers in advance of decoding. To remove this limitation, we propose an iterative method, in which (i) the estimation of speaker embeddings and (ii) TS-ASR based on the estimated speaker embeddings are alternately executed. We evaluated the proposed method by using very challenging dialogue recordings in which the speaker overlap ratio was over 20\%. We confirmed that the proposed method significantly reduced both the word error rate (WER) and diarization error rate (DER). Our proposed method combined with i-vector speaker embeddings ultimately achieved a WER that differed by only 2.1 \% from that of TS-ASR given oracle speaker embeddings. Furthermore, our method can solve speaker diarization simultaneously as a by-product and achieved better DER than that of the conventional clustering-based speaker diarization method based on i-vector.},
	booktitle = {2019 {IEEE} {Automatic} {Speech} {Recognition} and {Understanding} {Workshop} ({ASRU})},
	author = {Kanda, Naoyuki and Horiguchi, Shota and Fujita, Yusuke and Xue, Yawen and Nagamatsu, Kenji and Watanabe, Shinji},
	month = dec,
	year = {2019},
	pages = {31--38},
}

@article{weizenbaum_elizacomputer_1966,
	title = {{ELIZA}—a computer program for the study of natural language communication between man and machine},
	volume = {9},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/365153.365168},
	doi = {10.1145/365153.365168},
	language = {en},
	number = {1},
	urldate = {2021-11-15},
	journal = {Communications of the ACM},
	author = {Weizenbaum, Joseph},
	month = jan,
	year = {1966},
	pages = {36--45},
}

@article{evans_myth_2009,
	title = {The myth of language universals: {Language} diversity and its importance for cognitive science},
	volume = {32},
	doi = {10.1017/S0140525X0999094X},
	journal = {Behavioral and Brain Sciences},
	author = {Evans, Nicholas and Levinson, Stephen C.},
	year = {2009},
	pages = {429--492},
}

@article{nettle_social_2012,
	title = {Social scale and structural complexity in human languages},
	volume = {367},
	url = {http://rstb.royalsocietypublishing.org/content/367/1597/1829.short},
	number = {1597},
	urldate = {2013-12-20},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Nettle, Daniel},
	year = {2012},
	pages = {1829--1836},
}

@book{nettle_linguistic_1999,
	address = {Oxford},
	title = {Linguistic diversity},
	publisher = {Oxford University Press},
	author = {Nettle, Daniel},
	year = {1999},
}

@article{poldvere_londonlund_2021,
	title = {On {The} {London}–{Lund} {Corpus} 2: design, challenges and innovations},
	issn = {1360-6743, 1469-4379},
	shorttitle = {On {The} {London}–{Lund} {Corpus} 2},
	url = {https://www.cambridge.org/core/journals/english-language-and-linguistics/article/on-the-londonlund-corpus-2-design-challenges-and-innovations/A4D16F9FDC0EB66CA423486BB4AF4777},
	doi = {10.1017/S1360674321000186},
	abstract = {This article describes and critically examines the challenging task of compiling The London–Lund Corpus 2 (LLC–2) from start to end, accounting for the methodological decisions made in each stage and highlighting the innovations. LLC–2 is a half-a-million-word corpus of contemporary spoken British English with recordings from 2014 to 2019. Its size and design are the same as those of the world's first machine-readable spoken corpus, The London–Lund Corpus of Spoken English with data from the 1950s to 1980s. In this way, LLC–2 allows not only for synchronic investigations of contemporary speech but also for principled diachronic research of spoken language across time. Each stage of the compilation of LLC–2 posed its own challenges, ranging from the design of the corpus, the recruitment of the speakers, transcription, markup and annotation procedures, to the release of the corpus to the international research community. The decisions and solutions represent state-of-the-art practices of spoken corpus compilation with important innovations that enhance the value of LLC–2 for spoken corpus research, such as the availability of both the transcriptions and the corresponding time-aligned audio files in a standard compliant format.},
	language = {en},
	urldate = {2021-10-15},
	journal = {English Language \& Linguistics},
	author = {Põldvere, Nele and Johansson, Victoria and Paradis, Carita},
	month = sep,
	year = {2021},
	note = {Publisher: Cambridge University Press},
	pages = {1--25},
}

@article{amery_phoenix_2009,
	title = {Phoenix or {Relic}? {Documentation} of {Languages} with {Revitalization} in {Mind}},
	volume = {3},
	copyright = {Creative Commons Attribution Non-Commercial No Derivatives License},
	issn = {1934-5275},
	shorttitle = {Phoenix or {Relic}?},
	url = {http://scholarspace.manoa.hawaii.edu/handle/10125/4436},
	abstract = {The description of Indigenous languages has typically focussed on structural properties of languages (phonology, morphology, and syntax). Comparatively little attention has been given to the documentation of language functions or the most commonly occurring speech formulas. Speech formulas are often culturally-specific and idiomatic and cannot be reliably reconstituted from a knowledge of grammar and lexicon alone. Many linguists and lexicographers seem to have an implicit relic view of language, as if they have been trying to capture the “pure” language uncontaminated by language and culture contact. Accordingly, borrowed terms and neologisms are typically omitted or underrepresented in dictionaries. Recorded texts have tended to be myths or texts about traditional culture. Conversations and texts about everyday life, especially in non-traditional contexts, are ignored. How can we ensure that language descriptions are maximally useful, not only to linguists, but to the people most closely associated with the languages, who may wish to revive them? Considerable time is needed to produce a maximally useful description of a language and its uses. Suggestions made here emerge from first-hand experience working with Yolngu and Pintupi people in non-traditional domains, as well as from attempts to re-introduce Kaurna on the basis of nineteenth-century documentation.},
	language = {eng},
	number = {2},
	urldate = {2021-11-15},
	journal = {Language Documentation \& Conservation},
	author = {Amery, Rob},
	year = {2009},
	note = {Accepted: 2009-12-13T00:45:34Z
Publisher: University of Hawai'i Press},
	pages = {138--148},
}

@article{seifart_language_2018,
	title = {Language documentation twenty-five years on},
	volume = {94},
	issn = {1535-0665},
	url = {https://muse.jhu.edu/article/712110},
	doi = {10.1353/lan.2018.0070},
	abstract = {This discussion note reviews responses of the linguistics profession to the grave issues of language endangerment identified a quarter of a century ago in the journal Language by Krauss, Hale, England, Craig, and others (Hale et al. 1992). Two and a half decades of worldwide research not only have given us a much more accurate picture of the number, phylogeny, and typological variety of the world’s languages, but they have also seen the development of a wide range of new approaches, conceptual and technological, to the problem of documenting them. We review these approaches and the manifold discoveries they have unearthed about the enormous variety of linguistic structures. The reach of our knowledge has increased by about 15\% of the world’s languages, especially in terms of digitally archived material, with about 500 languages now reasonably documented thanks to such major programs as DoBeS, ELDP, and DEL. But linguists are still falling behind in the race to document the planet’s rapidly dwindling linguistic diversity, with around 35–42\% of the world’s languages still substantially undocumented, and in certain countries (such as the US) the call by Krauss (1992) for a significant professional realignment toward language documentation has only been heeded in a few institutions. Apart from the need for an intensified documentarist push in the face of accelerating language loss, we argue that existing language documentation efforts need to do much more to focus on crosslinguistically comparable data sets, sociolinguistic context, semantics, and interpretation of text material, and on methods for bridging the ‘transcription bottleneck’, which is creating a huge gap between the amount we can record and the amount in our transcribed corpora.*},
	number = {4},
	urldate = {2021-01-11},
	journal = {Language},
	author = {Seifart, Frank and Evans, Nicholas and Hammarström, Harald and Levinson, Stephen C.},
	year = {2018},
	note = {Publisher: Linguistic Society of America},
	pages = {e324--e345},
}

@article{hockett_origin_1960,
	title = {The {Origin} of {Speech}},
	volume = {203},
	number = {3},
	journal = {Scientific American},
	author = {Hockett, Charles F.},
	year = {1960},
	pages = {89--96},
}

@inproceedings{forsyth_lexical_2007,
	title = {Lexical and {Discourse} {Analysis} of {Online} {Chat} {Dialog}},
	doi = {10.1109/ICSC.2007.55},
	abstract = {One of the ultimate goals of natural language processing (NLP) systems is understanding the meaning of what is being transmitted, irrespective of the medium (e.g., written versus spoken) or the form (e.g., static documents versus dynamic dialogues). Although much work has been done in traditional language domains such as speech and static written text, little has yet been done in the newer communication domains enabled by the Internet, e.g., online chat and instant messaging. This is in part due to the fact that there are no annotated chat corpora available to the broader research community. The purpose of this research is to build a chat corpus, tagged with lexical (token part-of-speech labels), syntactic (post parse tree), and discourse (post classification) information. Such a corpus can then be used to develop more complex, statistical-based NLP applications that perform tasks such as author profiling, entity identification, and social network analysis.},
	booktitle = {International {Conference} on {Semantic} {Computing} ({ICSC} 2007)},
	author = {Forsyth, Eric N. and Martell, Craig H.},
	month = sep,
	year = {2007},
	pages = {19--26},
}

@article{roberts_conversation_2017,
	title = {Conversation, cognition and cultural evolution: {A} model of the cultural evolution of word order through pressures imposed from turn taking in conversation},
	volume = {18},
	issn = {1572-0373, 1572-0381},
	shorttitle = {Conversation, cognition and cultural evolution},
	url = {https://benjamins.com/catalog/is.18.3.06rob},
	doi = {10.1075/is.18.3.06rob},
	language = {en},
	number = {3},
	urldate = {2017-07-13},
	journal = {Interaction Studies},
	author = {Roberts, Seán G. and Levinson, Stephen C.},
	year = {2017},
	pages = {404--431},
}

@article{brockow_evaluating_2021,
	title = {Evaluating {NLG}-frameworks for multilingual surface realization in conversational assistants},
	url = {https://pub.uni-bielefeld.de/record/2955045},
	abstract = {Conversational voice assistants that are available in multiple countries need to be able to generate utterances in the language that their users speak. In open domains, in which messages can be variable, pre-writing and translating all utterances in advance is unfeasible because it is costly, error-prone, and inflexible when changes need to be made. Approaches to automatically generate multilingual surface forms of utterances have been developed in the field of Natural Language Generation (NLG), however, these are rarely used when developing skills for conversational voice assistants. In this paper, we describe an evaluation study that analyses the feasibility of integrating NLG surface-realization frameworks (SimpleNLG and RosaeNLG) into the development process of an existing commercial and multilingual (English, French, German, Italian, Spanish) home-automation skill, and compare it to a more traditional localization approach. The study uses methods and measures from human–computer interaction and software engineering, and takes into account the perspective of various stakeholders in the development process (conversation designers, language experts and developers).},
	language = {eng},
	urldate = {2021-11-14},
	journal = {Proceedings of the 3rd International Conference on Conversational User Interfaces},
	author = {Brockow, Hanne and Buschmeier, Hendrik},
	year = {2021},
}

@article{lumer_integrating_2021,
	title = {Integrating speaker–hearer relations into a {Rational} {Speech} {Act}-based model of politeness},
	url = {https://pub.uni-bielefeld.de/record/2957959},
	language = {eng},
	urldate = {2021-11-14},
	author = {Lumer, Eleonore and Buschmeier, Hendrik},
	year = {2021},
}

@article{weigand_misunderstanding_1999,
	series = {Misunderstanding},
	title = {Misunderstanding: {The} standard case},
	volume = {31},
	issn = {0378-2166},
	shorttitle = {Misunderstanding},
	url = {https://www.sciencedirect.com/science/article/pii/S037821669800068X},
	doi = {10.1016/S0378-2166(98)00068-X},
	abstract = {Starting from an overview of the multiple cases of misunderstanding dealt with in the literature, the question arises whether there is a type of misunderstanding which can be called the standard case. Referring to a model of dialogic action games the standard case can be defined by some constitutive features. On the basis of an explanation of understanding, the standard case of misunderstanding is investigated in more detail by distinguishing two subtypes: misunderstanding the means and misunderstanding the purposes. From such an analysis of the standard case important consequences can be drawn for the general principles of language use.},
	language = {en},
	number = {6},
	urldate = {2021-11-14},
	journal = {Journal of Pragmatics},
	author = {Weigand, Edda},
	month = jun,
	year = {1999},
	pages = {763--785},
}

@article{devillers_spoken_2020,
	title = {Spoken {Language} {Interaction} with {Virtual} {Agents} and {Robots} ({SLIVAR}): {Towards} {Effective} and {Ethical} {Interaction} ({Dagstuhl} {Seminar} 20021)},
	volume = {10},
	issn = {2192-5283},
	shorttitle = {Spoken {Language} {Interaction} with {Virtual} {Agents} and {Robots} ({SLIVAR})},
	url = {https://drops.dagstuhl.de/opus/volltexte/2020/12400},
	doi = {10.4230/DagRep.10.1.1},
	number = {1},
	urldate = {2021-11-14},
	journal = {Dagstuhl Reports},
	author = {Devillers, Laurence and Kawahara, Tatsuya and Moore, Roger K. and Scheutz, Matthias},
	editor = {Devillers, Laurence and Kawahara, Tatsuya and Moore, Roger K. and Scheutz, Matthias},
	year = {2020},
	note = {Place: Dagstuhl, Germany
Publisher: Schloss Dagstuhl–Leibniz-Zentrum für Informatik},
	pages = {1--51},
}

@article{vlasov_dialogue_2020,
	title = {Dialogue {Transformers}},
	url = {http://arxiv.org/abs/1910.00486},
	abstract = {We introduce a dialogue policy based on a transformer architecture, where the self-attention mechanism operates over the sequence of dialogue turns. Recent work has used hierarchical recurrent neural networks to encode multiple utterances in a dialogue context, but we argue that a pure self-attention mechanism is more suitable. By default, an RNN assumes that every item in a sequence is relevant for producing an encoding of the full sequence, but a single conversation can consist of multiple overlapping discourse segments as speakers interleave multiple topics. A transformer picks which turns to include in its encoding of the current dialogue state, and is naturally suited to selectively ignoring or attending to dialogue history. We compare the performance of the Transformer Embedding Dialogue (TED) policy to an LSTM and to the REDP, which was specifically designed to overcome this limitation of RNNs.},
	urldate = {2021-11-14},
	journal = {arXiv:1910.00486 [cs]},
	author = {Vlasov, Vladimir and Mosig, Johannes E. M. and Nichol, Alan},
	month = may,
	year = {2020},
	note = {arXiv: 1910.00486},
}

@article{henrich_weirdest_2010,
	title = {The {Weirdest} {People} in the {World}?},
	volume = {33},
	url = {http://journals.cambridge.org/action/displayIssue?jid=BBS&volumeId=33&issueId=2-3&iid=7825832},
	doi = {10.1017/S0140525X0999152X},
	abstract = {Behavioral scientists routinely publish broad claims about human psychology and behavior in the world's top journals based on samples drawn entirely from Western, Educated, Industrialized, Rich, and Democratic (WEIRD) societies. Researchers – often implicitly – assume that either there is little variation across human populations, or that these “standard subjects” are as representative of the species as any other population. Are these assumptions justified? Here, our review of the comparative database from across the behavioral sciences suggests both that there is substantial variability in experimental results across populations and that WEIRD subjects are particularly unusual compared with the rest of the species – frequent outliers. The domains reviewed include visual perception, fairness, cooperation, spatial reasoning, categorization and inferential induction, moral reasoning, reasoning styles, self-concepts and related motivations, and the heritability of IQ. The findings suggest that members of WEIRD societies, including young children, are among the least representative populations one could find for generalizing about humans. Many of these findings involve domains that are associated with fundamental aspects of psychology, motivation, and behavior – hence, there are no obvious a priori grounds for claiming that a particular behavioral phenomenon is universal based on sampling from a single subpopulation. Overall, these empirical patterns suggests that we need to be less cavalier in addressing questions of human nature on the basis of data drawn from this particularly thin, and rather unusual, slice of humanity. We close by proposing ways to structurally re-organize the behavioral sciences to best tackle these challenges.},
	number = {2-3},
	urldate = {2010-07-01},
	journal = {Behavioral and Brain Sciences},
	author = {Henrich, Joseph and Heine, Steven J. and Norenzayan, Ara},
	year = {2010},
	pages = {61--83},
}

@article{jefferson_sequential_1988,
	title = {On the {Sequential} {Organization} of {Troubles}-{Talk} in {Ordinary} {Conversation}},
	volume = {35},
	issn = {00377791},
	url = {http://www.jstor.org/stable/800595},
	abstract = {This paper is an investigation of conversations in which people talk about their troubles. I describe a series of recurrent, positioned elements as comprising a "candidate" troubles telling sequence. That is, the collection of troubles tellings showed a shape and a trajectory that was well-formed in some conversations and distorted in others. Thus, the array of elements in the sequence could be characterized as "vaguely orderly." I consider whether this is due to a "rough" ordering of "big packages" in conversation (i.e., relatively long sequences of talk), or due to problematic local and general contingencies that disrupt an otherwise tight overall design.},
	number = {4},
	urldate = {2010-12-16},
	journal = {Social Problems},
	author = {Jefferson, Gail},
	month = oct,
	year = {1988},
	note = {ArticleType: research-article / Issue Title: Special Issue: Language, Interaction, and Social Problems / Full publication date: Oct., 1988 / Copyright © 1988 University of California Press},
	pages = {418--441},
}

@incollection{jefferson_notes_1984,
	address = {Padua, Italy},
	title = {Notes on some orderlinesses of overlap onset},
	booktitle = {Discourse analysis and natural rhetoric},
	publisher = {Cleup Editore},
	author = {Jefferson, Gail},
	editor = {D'Urso, Valentina and Leonardi, P.},
	year = {1984},
	pages = {11--38},
}

@article{jefferson_notes_1986,
	title = {Notes on 'latency' in overlap onset},
	volume = {9},
	issn = {0163-8548},
	shorttitle = {Notes on ?},
	url = {http://www.springerlink.com/content/k32638n1k4112160/},
	doi = {10.1007/BF00148125},
	number = {2-3},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Jefferson, Gail},
	year = {1986},
	pages = {153--183},
}

@article{jefferson_notes_1985,
	title = {Notes on a systematic {Deployment} of the {Acknowledgement} tokens '{Yeah}' and '{Mmhm}'},
	volume = {17},
	number = {2},
	journal = {Papers in Linguistics},
	author = {Jefferson, Gail},
	year = {1985},
	pages = {197--216},
}

@incollection{jefferson_technique_1979,
	address = {New York},
	title = {A technique for inviting laughter and its subsequent acceptance/declination},
	volume = {79},
	booktitle = {Everyday language: {Studies} in ethnomethodology},
	publisher = {Irvington},
	author = {Jefferson, Gail},
	editor = {Psathas, George},
	year = {1979},
	pages = {79--96},
}

@incollection{jefferson_sequential_1978,
	address = {New York},
	title = {Sequential aspects of storytelling in conversation},
	booktitle = {Studies in the organization of conversational interaction},
	publisher = {Academic Press},
	author = {Jefferson, Gail},
	editor = {Schenkein, J.},
	year = {1978},
	pages = {219--248},
}

@incollection{heritage_conversation_1984,
	address = {Cambridge; New York},
	title = {Conversation {Analysis}},
	isbn = {0745600603 : 9780745600604 0745600611 : 9780745600611},
	booktitle = {Garfinkel and ethnomethodology},
	publisher = {Polity Press},
	author = {Heritage, John},
	editor = {Heritage, John},
	year = {1984},
	keywords = {conversation analysis, important},
	pages = {233--292},
}

@incollection{psathas_interactive_1979,
	address = {New York},
	title = {The interactive construction of a sentence in natural conversation},
	isbn = {0-470-26670-8},
	booktitle = {Everyday {Language}: {Studies} in {Ethnomethodology}},
	publisher = {Irvington Publishers, distributed by Halsted Press},
	author = {Goodwin, Charles},
	editor = {Psathas, George},
	year = {1979},
	keywords = {classic, conversation analysis},
	pages = {7--14},
}

@article{goodwin_between_1986,
	title = {Between and within: {Alternative} {Sequential} {Treatments} of {Continuers} and {Assessments}},
	volume = {9},
	issn = {01638548},
	shorttitle = {Between and within},
	url = {http://www.jstor.org/stable/20008967},
	number = {2/3},
	urldate = {2010-07-08},
	journal = {Human Studies},
	author = {Goodwin, Charles},
	year = {1986},
	note = {ArticleType: primary\_article / Issue Title: Interaction and Language Use / Full publication date: 1986 / Copyright © 1986 Springer},
	pages = {205--217},
}

@article{goodwin_audience_1986,
	title = {Audience diversity, participation and interpretation},
	volume = {6},
	number = {3},
	journal = {Text},
	author = {Goodwin, Charles},
	year = {1986},
	keywords = {conversation analysis},
	pages = {283--316},
}

@book{goodwin_conversational_1981,
	address = {New York},
	series = {Language, {Thought}, and {Culture}},
	title = {Conversational {Organization}: {Interaction} {Between} {Speakers} and {Hearers}},
	isbn = {0-12-289780-3},
	shorttitle = {Conversational {Organization}},
	publisher = {Academic Press},
	author = {Goodwin, Charles},
	year = {1981},
}

@article{allwood_mumin_2007,
	title = {The {MUMIN} coding scheme for the annotation of feedback, turn management and sequencing phenomena},
	volume = {41},
	issn = {1574-020X, 1572-8412},
	url = {http://link.springer.com/article/10.1007/s10579-007-9061-5},
	doi = {10.1007/s10579-007-9061-5},
	abstract = {This paper deals with a multimodal annotation scheme dedicated to the study of gestures in interpersonal communication, with particular regard to the role played by multimodal expressions for feedback, turn management and sequencing. The scheme has been developed under the framework of the MUMIN network and tested on the analysis of multimodal behaviour in short video clips in Swedish, Finnish and Danish. The preliminary results obtained in these studies show that the reliability of the categories defined in the scheme is acceptable, and that the scheme as a whole constitutes a versatile analysis tool for the study of multimodal communication behaviour.},
	language = {en},
	number = {3-4},
	urldate = {2013-11-05},
	journal = {Language Resources and Evaluation},
	author = {Allwood, Jens and Cerrato, Loredana and Jokinen, Kristiina and Navarretta, Costanza and Paggio, Patrizia},
	month = dec,
	year = {2007},
	pages = {273--287},
}

@article{allwood_semantics_1992,
	title = {On the semantics and pragmatics of linguistic feedback},
	volume = {9},
	number = {1},
	journal = {Journal of Semantics},
	author = {Allwood, Jens and Nivre, Joakim and Ahlsén, Elisabeth},
	year = {1992},
	pages = {1--26},
}

@incollection{allwood_multimodal_2008,
	address = {Berlin},
	title = {Multimodal {Corpora}},
	url = {https://hal-hprints.archives-ouvertes.fr/hprints-00511882/document},
	abstract = {The structure of this paper is the following. In section 1, multimodal corpora are defined and described, in section 2, reasons are given for why multimodal corpora are created, and in section 3, there is a discussion of some issues to keep in mind when creating and analyzing a multimodal corpus. There is also a discussion of some research directions. In section 4, possible applications are mentioned and section 5, finally, contains some concluding remarks. [Adapted from introduction]},
	language = {en},
	urldate = {2017-10-17},
	booktitle = {Corpus {Linguistics}. {An} {International} {Handbook}},
	publisher = {Mouton de Gruyter},
	author = {Allwood, Jens},
	year = {2008},
	pages = {207--225},
}

@article{allwood_speech_1990,
	title = {Speech {Management}—on the {Non}-written {Life} of {Speech}},
	volume = {13},
	doi = {10.1017/S0332586500002092},
	abstract = {This paper introduces the concept of speech management (SM), which refers to processes whereby a speaker manages his or her linguistic contributions to a communicative interaction, and which involves phenomena which have previously been studied under such rubrics as “planning”, “editing”, “(self-)repair”, etc. It is argued that SM phenomena exhibit considerable systematicity and regularity and must be considered part of the linguistic system. Furthermore, it is argued that SM phenomena must be related not only to such intraindividual factors as planning and memory, but also to interactional factors such as turntaking and feedback, and to informational content. Structural and functional taxonomies are presented together with a formal description of complex types of SM. The structural types are exemplified with data from a corpus of SM phenomena.},
	number = {01},
	journal = {Nordic Journal of Linguistics},
	author = {Allwood, Jens and Nivre, Joakim and Ahlsén, Elisabeth},
	year = {1990},
	pages = {3--48},
}

@article{clark_contributing_1989,
	title = {Contributing to discourse},
	volume = {13},
	issn = {0364-0213},
	url = {http://www.sciencedirect.com/science/article/pii/0364021389900086},
	doi = {16/0364-0213(89)90008-6},
	abstract = {For people to contribute to discourse, they must do more than utter the right sentence at the right time. The basic requirement is that they add to their common ground in an orderly way. To do this, we argue, they try to establish for each utterance the mutual belief that the addressees have understood what the speaker meant well enough for current purposes. This is accomplished by the collective actions of the current contributor and his or her partners, and these result in units of conversation called contributions. We present a model of contributions and show how it accounts for a variety of features of everyday conversations.},
	number = {2},
	urldate = {2011-08-19},
	journal = {Cognitive Science},
	author = {Clark, Herbert H. and Schaefer, Edward F.},
	year = {1989},
	pages = {259--294},
}

@article{clark_collaborating_1987,
	title = {Collaborating on contributions to conversations},
	volume = {2},
	issn = {0169-0965},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01690968708406350},
	doi = {10.1080/01690968708406350},
	number = {1},
	urldate = {2011-08-19},
	journal = {Language and Cognitive Processes},
	author = {Clark, Herbert H. and Schaefer, Edward},
	month = jan,
	year = {1987},
	pages = {19--41},
}

@incollection{clark_grounding_1991,
	address = {Washington},
	title = {Grounding in communication},
	volume = {13},
	urldate = {2014-01-05},
	booktitle = {Perspectives on {Socially} {Shared} {Cognition}},
	publisher = {APA Books},
	author = {Clark, Herbert H. and Brennan, Susan E.},
	editor = {Resnick, Lauren B. and Levine, J. M. and Teasley, S. D.},
	year = {1991},
	pages = {127--149},
}

@book{clark_using_1996,
	address = {Cambridge},
	title = {Using {Language}},
	publisher = {Cambridge University Press},
	author = {Clark, Herbert H.},
	year = {1996},
}

@article{clark_understanding_1975,
	title = {Understanding what is meant from what is said: {A} study in conversationally conveyed requests},
	volume = {14},
	issn = {0022-5371},
	shorttitle = {Understanding what is meant from what is said},
	url = {http://www.sciencedirect.com/science/article/pii/S0022537175800065},
	doi = {10.1016/S0022-5371(75)80006-5},
	abstract = {For a sentence such as Must you open the door?, how does the listener come to construe it in its intended sense (“Please don't open the door”) instead of its literal sense (“Is it necessary for you to open the door?”)? It was proposed that the listener constructs the literal meaning, checks the context for its plausibility, and if it is implausible, applies a rule of conversation to derive the conveyed meaning. In a test of this theory 23 subjects were timed as they drew simple deductions from 10 different pairs of conversationally conveyed requests (for example, Can you open the door? and Must you open the door?). The first member of each pair conveyed a positive request, and the second, a negative one. Consistent with the theory, those sentences conveying positive requests behaved as if they were positive, even when they were negative in literal meaning (for example, Why not open the door?); those conveying negative requests behaved as if they were explicitly negative, even when they were positive in literal meaning (for example, Why open the door?). Some evidence was found for the notion that the listener constructs the literal meaning before the conveyed meaning.},
	number = {1},
	urldate = {2013-02-07},
	journal = {Journal of Verbal Learning and Verbal Behavior},
	author = {Clark, Herbert H. and Lucy, Peter},
	month = feb,
	year = {1975},
	pages = {56--72},
}

@incollection{clark_changing_2004,
	series = {Palgrave {Studies} in {Pragmatics}, {Language} and {Cognition}},
	title = {Changing {Ideas} about {Reference}},
	isbn = {978-1-4039-0351-8 978-0-230-52412-5},
	url = {https://link.springer.com/chapter/10.1057/9780230524125_2},
	abstract = {How do people refer to things? At first, the answer seems simple: they produce the right expression in the right situation. According to John Searle (1969), for example, to refer to a dog, speakers must produce a referring expression (such as the dog she had with her) with the intention that it pick out or identify the dog for their addressees. But is the answer really this simple? Accounts of how people refer have changed again and again since about 1960, often dramatically. But how have they changed, and why? In this chapter, we offer a selective, largely personal history of these changes as they have played out in the experimental study of reference. Our goal is not a complete history — an impossible ambition — but a better understanding of what reference really is.},
	language = {en},
	urldate = {2018-04-12},
	booktitle = {Experimental {Pragmatics}},
	publisher = {Palgrave Macmillan, London},
	author = {Clark, Herbert H. and Bangerter, Adrian},
	year = {2004},
	doi = {10.1057/9780230524125_2},
	pages = {25--49},
}

@inproceedings{yngve_getting_1970,
	title = {On getting a word in edgewise},
	booktitle = {Papers from the {Sixth} {Regional} {Meeting}, {Chicago} {Linguistic} {Society}},
	author = {Yngve, Victor},
	year = {1970},
	pages = {567--578},
}

@book{clark_natural-born_2004,
	address = {New York},
	title = {Natural-born cyborgs: minds, technologies, and the future of human intelligence},
	isbn = {978-0-19-517751-0},
	shorttitle = {Natural-born cyborgs},
	language = {eng},
	publisher = {Oxford Univ. Press},
	author = {Clark, Andy},
	year = {2004},
	note = {OCLC: 255713184},
}

@article{clark_material_2006,
	title = {Material {Symbols}},
	volume = {19},
	issn = {0951-5089},
	url = {http://dx.doi.org/10.1080/09515080600689872},
	doi = {10.1080/09515080600689872},
	abstract = {What is the relation between the material, conventional symbol structures that we encounter in the spoken and written word, and human thought? A common assumption, that structures a wide variety of otherwise competing views, is that the way in which these material, conventional symbol-structures do their work is by being translated into some kind of content-matching inner code. One alternative to this view is the tempting but thoroughly elusive idea that we somehow think in some natural language (such as English). In the present treatment I explore a third option, which I shall call the “complementarity” view of language. According to this third view the actual symbol structures of a given language add cognitive value by complementing (without being replicated by) the more basic modes of operation and representation endemic to the biological brain. The “cognitive bonus” that language brings is, on this model, not to be cashed out either via the ultimately mysterious notion of “thinking in a given natural language” or via some process of exhaustive translation into another inner code. Instead, we should try to think in terms of a kind of coordination dynamics in which the forms and structures of a language qua material symbol system play a key and irreducible role. Understanding language as a complementary cognitive resource is, I argue, an important part of the much larger project (sometimes glossed in terms of the “extended mind”) of understanding human cognition as essentially and multiply hybrid: as involving a complex interplay between internal biological resources and external non-biological resources.},
	number = {3},
	urldate = {2016-04-05},
	journal = {Philosophical Psychology},
	author = {Clark, Andy},
	month = jun,
	year = {2006},
	keywords = {\_tablet},
	pages = {291--307},
}

@incollection{carruthers_magic_1998,
	address = {Cambridge},
	title = {Magic words: how language augments human computation},
	isbn = {978-0-511-59790-9},
	shorttitle = {Magic words},
	booktitle = {Language and thought},
	publisher = {Cambridge University Press},
	author = {Clark, Andy},
	editor = {Carruthers, Peter and Boucher, Jill},
	year = {1998},
	doi = {10.1017/CBO9780511597909.011},
	keywords = {\_tablet},
	pages = {162--183},
}

@article{skantze_exploring_2005,
	title = {Exploring human error recovery strategies: {Implications} for spoken dialogue systems},
	volume = {45},
	issn = {01676393},
	shorttitle = {Exploring human error recovery strategies},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639304001256},
	doi = {sc},
	language = {en},
	number = {3},
	urldate = {2018-02-05},
	journal = {Speech Communication},
	author = {Skantze, Gabriel},
	month = mar,
	year = {2005},
	pages = {325--341},
}

@article{skantze_turn-taking_2014,
	title = {Turn-taking, feedback and joint attention in situated human–robot interaction},
	volume = {65},
	issn = {0167-6393},
	url = {http://www.sciencedirect.com/science/article/pii/S016763931400051X},
	doi = {10.1016/j.specom.2014.05.005},
	abstract = {In this paper, we present a study where a robot instructs a human on how to draw a route on a map. The human and robot are seated face-to-face with the map placed on the table between them. The user’s and the robot’s gaze can thus serve several simultaneous functions: as cues to joint attention, turn-taking, level of understanding and task progression. We have compared this face-to-face setting with a setting where the robot employs a random gaze behaviour, as well as a voice-only setting where the robot is hidden behind a paper board. In addition to this, we have also manipulated turn-taking cues such as completeness and filled pauses in the robot’s speech. By analysing the participants’ subjective rating, task completion, verbal responses, gaze behaviour, and drawing activity, we show that the users indeed benefit from the robot’s gaze when talking about landmarks, and that the robot’s verbal and gaze behaviour has a strong effect on the users’ turn-taking behaviour. We also present an analysis of the users’ gaze and lexical and prosodic realisation of feedback after the robot instructions, and show that these cues reveal whether the user has yet executed the previous instruction, as well as the user’s level of uncertainty.},
	number = {Supplement C},
	urldate = {2017-12-08},
	journal = {Speech Communication},
	author = {Skantze, Gabriel and Hjalmarsson, Anna and Oertel, Catharine},
	month = nov,
	year = {2014},
	pages = {50--66},
}

@article{levinson_turn-taking_2016,
	title = {Turn-taking in {Human} {Communication} – {Origins} and {Implications} for {Language} {Processing}},
	volume = {20},
	issn = {13646613},
	doi = {10.1016/j.tics.2015.10.010},
	language = {en},
	number = {1},
	urldate = {2016-02-01},
	journal = {Trends in Cognitive Sciences},
	author = {Levinson, Stephen C.},
	month = jan,
	year = {2016},
	pages = {6--14},
}

@article{albert_repair_2018,
	title = {Repair: {The} {Interface} {Between} {Interaction} and {Cognition}},
	volume = {10},
	copyright = {Copyright © 2018 The Authors. Topics in Cognitive Science published by Wiley Periodicals,          Inc. on behalf of Cognitive Science Society.},
	issn = {1756-8765},
	shorttitle = {Repair},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12339},
	doi = {10.1111/tops.12339},
	abstract = {Conversational repair is the process people use to detect and resolve problems of speaking, hearing, and understanding. Through repair, participants in social interaction display how they establish and maintain communication and mutual understanding. We argue that repair provides a crucial theoretical interface for research between diverse approaches to studying human interaction. We provide an overview of conversation analytic findings about repair in order to encourage further cross-disciplinary research involving both detailed inductive inquiry and more theory-driven experimental approaches. We outline CA's main typologies of repair and its methodological rationale, and we provide transcripts and examples that readers can explore for themselves using open data from online corpora. Since participants in interaction use repair to deal with problems as they emerge at the surface level of talk, we conclude that repair can be a point of convergence for studying mis/communication from multiple methodological perspectives.},
	language = {en},
	number = {2},
	urldate = {2018-05-11},
	journal = {Topics in Cognitive Science},
	author = {Albert, Saul and Ruiter, J. P. de},
	month = apr,
	year = {2018},
	pages = {279--313},
}

@article{albert_improving_2018,
	title = {Improving {Human} {Interaction} {Research} through {Ecological} {Grounding}},
	volume = {4},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2474-7394},
	doi = {10.1525/collabra.132},
	abstract = {Article: Improving Human Interaction Research through Ecological Grounding},
	language = {eng},
	number = {1},
	journal = {Collabra: Psychology},
	author = {Albert, Saul and Ruiter, J. P. de},
	month = jul,
	year = {2018},
}

@article{kempson_action-based_2017,
	title = {Action-{Based} {Grammar}},
	volume = {43},
	issn = {0301-4428},
	url = {https://www.degruyter.com/view/j/thli.2017.43.issue-1-2/tl-2017-0012/tl-2017-0012.xml?format=INT},
	doi = {10.1515/tl-2017-0012},
	number = {1-2},
	urldate = {2018-04-16},
	journal = {Theoretical Linguistics},
	author = {Kempson, Ruth and Cann, Ronnie and Gregoromichelaki, Eleni and Chatzikyriakidis, Stergios},
	year = {2017},
	pages = {141--167},
}

@article{kempson_language_2016,
	title = {Language as {Mechanisms} for {Interaction}},
	volume = {42},
	issn = {0301-4428},
	url = {https://www.degruyter.com/view/j/thli.2016.42.issue-3-4/tl-2016-0011/tl-2016-0011.xml?format=INT},
	doi = {10.1515/tl-2016-0011},
	abstract = {Language use is full of subsentential shifts of context, a phenomenon dramatically illustrated in conversation where non-sentential utterances displaying seamless shifts between speaker/hearer roles appear regularly. The hurdle this poses for standard assumptions is that every local linguistic dependency can be distributed across speakers, with the content of what they are saying and the significance of each conversational move emerging incrementally. Accordingly, we argue that the modelling of a psychologically-realistic grammar necessitates recasting the notion of natural language in terms of our ability for interaction with others and the environment, abandoning the competence-performance dichotomy as standardly envisaged. We sketch Dynamic Syntax, a model in which underspecification and incremental time-relative update is central, showing how interactive effects of conversation follow directly. Finally, we note the changing cognitive-science horizons to be explored once a language-as-action view is adopted.},
	number = {3-4},
	urldate = {2018-04-16},
	journal = {Theoretical Linguistics},
	author = {Kempson, Ruth and Cann, Ronnie and Gregoromichelaki, Eleni and Chatzikyriakidis, Stergios},
	year = {2016},
	pages = {203--276},
}

@incollection{wachsmuth_making_2013,
	address = {Amsterdam},
	title = {On making syntax dynamic: {The} challenge of compound utterances and the architecture of the grammar},
	volume = {6},
	isbn = {978-90-272-0460-8 978-90-272-7103-7},
	shorttitle = {On making syntax dynamic},
	url = {https://benjamins.com/catalog/ais.6.04gre},
	language = {en},
	urldate = {2019-06-21},
	booktitle = {Advances in {Interaction} {Studies}},
	publisher = {John Benjamins Publishing Company},
	author = {Gregoromichelaki, Eleni and Kempson, Ruth M. and Howes, Christine and Eshghi, Arash},
	editor = {Wachsmuth, Ipke and de Ruiter, Jan and Jaecks, Petra and Kopp, Stefan},
	year = {2013},
	doi = {10.1075/ais.6.04gre},
	pages = {57--86},
}

@article{gregoromichelaki_incrementality_2011,
	title = {Incrementality and intention-recognition in utterance processing},
	volume = {2},
	url = {http://elanguage.net/journals/index.php/dad/article/view/363},
	number = {1},
	urldate = {2012-07-02},
	journal = {Dialogue \& Discourse},
	author = {Gregoromichelaki, Eleni and Kempson, Ruth and Purver, Matthew and Mills, Gregory J. and Cann, Ronnie and Meyer-Viol, Wilfried and Healey, Patrick G. T.},
	year = {2011},
	pages = {199--233},
}

@article{purver_grammars_2006,
	title = {Grammars as {Parsers}: {Meeting} the {Dialogue} {Challenge}},
	volume = {4},
	issn = {1570-7075, 1572-8706},
	shorttitle = {Grammars as {Parsers}},
	url = {https://link.springer.com/article/10.1007/s11168-006-9007-x},
	doi = {10.1007/s11168-006-9007-x},
	abstract = {Standard grammar formalisms are defined without reflection of the incremental, serial and context-dependent nature of language processing; any incrementality must therefore be reflected by independently defined parsing and/or generation techniques, and context-dependence by separate pragmatic modules. This leads to a poor setup for modelling dialogue, with its rich speaker-hearer interaction and high proportion of context-dependent and apparently grammatically ill-formed utterances. Instead, this paper takes an inherently incremental grammar formalism, Dynamic Syntax (DS) (Kempson et al., 2001), proposes a context-based extension and defines corresponding context-dependent parsing and generation models together with a resulting natural definition of context-dependent well-formedness. These are shown to allow a straightforward model of otherwise problematic dialogue phenomena such as shared utterances, ellipsis and alignment. We conclude that language competence is a capacity for dialogue.},
	language = {en},
	number = {2-3},
	urldate = {2018-04-16},
	journal = {Research on Language and Computation},
	author = {Purver, Matthew and Cann, Ronnie and Kempson, Ruth},
	month = oct,
	year = {2006},
	pages = {289--326},
}

@article{purver_computational_2018,
	title = {Computational {Models} of {Miscommunication} {Phenomena}},
	volume = {10},
	issn = {1756-8765},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12324},
	doi = {10.1111/tops.12324},
	abstract = {Miscommunication phenomena such as repair in dialogue are important indicators of the quality of communication. Automatic detection is therefore a key step toward tools that can characterize communication quality and thus help in applications from call center management to mental health monitoring. However, most existing computational linguistic approaches to these phenomena are unsuitable for general use in this way, and particularly for analyzing human–human dialogue: Although models of other-repair are common in human-computer dialogue systems, they tend to focus on specific phenomena (e.g., repair initiation by systems), missing the range of repair and repair initiation forms used by humans; and while self-repair models for speech recognition and understanding are advanced, they tend to focus on removal of “disfluent” material important for full understanding of the discourse contribution, and/or rely on domain-specific knowledge. We explain the requirements for more satisfactory models, including incrementality of processing and robustness to sparsity. We then describe models for self- and other-repair detection that meet these requirements (for the former, an adaptation of an existing repair model; for the latter, an adaptation of standard techniques) and investigate how they perform on datasets from a range of dialogue genres and domains, with promising results.},
	language = {en},
	number = {2},
	urldate = {2021-09-29},
	journal = {Topics in Cognitive Science},
	author = {Purver, Matthew and Hough, Julian and Howes, Christine},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/tops.12324},
	pages = {425--451},
}

@incollection{healey_analysing_2005,
	series = {Text, {Speech} and {Language} {Technology}},
	title = {Analysing {Multimodal} {Communication}: {Repair}-{Based} {Measures} of {Human} {Communicative} {Coordination}},
	copyright = {©2005 Springer},
	isbn = {978-1-4020-3932-4 978-1-4020-3933-1},
	url = {http://link.springer.com/chapter/10.1007/1-4020-3933-6_6},
	abstract = {There are few techniques available to inform the design of systems to support human-human interaction. Psycholinguistic models have the potential to fill this gap however existing approaches have some conceptual and practical limitations. This chapter presents a technique, based on the conversation analytic model of breakdown and repair, for modality and task independent analysis of communicative exchanges. The rationale for the approach is presented and a protocol for coding repair is described. The potential of this approach for analysing multimodal interactions is discussed.},
	language = {en},
	number = {30},
	urldate = {2016-10-04},
	booktitle = {Advances in {Natural} {Multimodal} {Dialogue} {Systems}},
	publisher = {Springer Netherlands},
	author = {Healey, Patrick G. T. and Colman, Marcus and Thirlwell, Mike},
	editor = {Kuppevelt, Jan C. J. van and Dybkjær, Laila and Bernsen, Niels Ole},
	year = {2005},
	doi = {10.1007/1-4020-3933-6_6},
	pages = {113--129},
}

@article{healey_running_2018,
	title = {Running {Repairs}: {Coordinating} {Meaning} in {Dialogue}},
	copyright = {© 2018 The Authors. Topics in Cognitive Science published by Wiley Periodicals, Inc.          on behalf of Cognitive Science Society},
	issn = {1756-8765},
	shorttitle = {Running {Repairs}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12336},
	doi = {10.1111/tops.12336},
	abstract = {People give feedback in conversation: both positive signals of understanding, such as nods, and negative signals of misunderstanding, such as frowns. How do signals of understanding and misunderstanding affect the coordination of language use in conversation? Using a chat tool and a maze-based reference task, we test two experimental manipulations that selectively interfere with feedback in live conversation: (a) “Attenuation” that replaces positive signals of understanding such as “right” or “okay” with weaker, more provisional signals such as “errr” or “umm” and (2) “Amplification” that replaces relatively specific signals of misunderstanding from clarification requests such as “on the left?” with generic signals of trouble such as “huh?” or “eh?”. The results show that Amplification promotes rapid convergence on more systematic, abstract ways of describing maze locations while Attenuation has no significant effect. We interpret this as evidence that “running repairs”—the processes of dealing with misunderstandings on the fly—are key drivers of semantic coordination in dialogue. This suggests a new direction for experimental work on conversation and a productive way to connect the empirical accounts of Conversation Analysis with the representational and processing concerns of Formal Semantics and Psycholinguistics.},
	language = {en},
	urldate = {2018-04-26},
	journal = {Topics in Cognitive Science},
	author = {Healey, Patrick G. T. and Mills, Gregory J. and Eshghi, Arash and Howes, Christine},
	year = {2018},
	pages = {1--22},
}

@article{healey_divergence_2014,
	title = {Divergence in {Dialogue}},
	volume = {9},
	url = {http://dx.doi.org/10.1371/journal.pone.0098598},
	doi = {10.1371/journal.pone.0098598},
	abstract = {One of the best known claims about human communication is that people's behaviour and language use converge during conversation. It has been proposed that these patterns can be explained by automatic, cross-person priming. A key test case is structural priming: does exposure to one syntactic structure, in production or comprehension, make reuse of that structure (by the same or another speaker) more likely? It has been claimed that syntactic repetition caused by structural priming is ubiquitous in conversation. However, previous work has not tested for general syntactic repetition effects in ordinary conversation independently of lexical repetition. Here we analyse patterns of syntactic repetition in two large corpora of unscripted everyday conversations. Our results show that when lexical repetition is taken into account there is no general tendency for people to repeat their own syntactic constructions. More importantly, people repeat each other's syntactic constructions less than would be expected by chance; i.e., people systematically diverge from one another in their use of syntactic constructions. We conclude that in ordinary conversation the structural priming effects described in the literature are overwhelmed by the need to actively engage with our conversational partners and respond productively to what they say.},
	number = {6},
	urldate = {2014-06-12},
	journal = {PLoS ONE},
	author = {Healey, Patrick G. T. and Purver, Matthew and Howes, Christine},
	month = jun,
	year = {2014},
	pages = {e98598},
}

@article{healey_editors_2018,
	title = {Editors' {Introduction}: {Miscommunication}},
	volume = {10},
	issn = {17568757},
	shorttitle = {Editors' {Introduction}},
	url = {http://doi.wiley.com/10.1111/tops.12340},
	doi = {10.1111/tops.12340},
	language = {en},
	number = {2},
	urldate = {2018-05-13},
	journal = {Topics in Cognitive Science},
	author = {Healey, Patrick G. T. and de Ruiter, Jan P. and Mills, Gregory J.},
	month = apr,
	year = {2018},
	pages = {264--278},
}

@article{levshina_token-based_2019,
	title = {Token-based typology and word order entropy: {A} study based on {Universal} {Dependencies}},
	volume = {23},
	issn = {1430-0532},
	shorttitle = {Token-based typology and word order entropy},
	url = {https://www.degruyter.com/view/j/lity.2019.23.issue-3/lingty-2019-0025/lingty-2019-0025.xml},
	doi = {10.1515/lingty-2019-0025},
	abstract = {The present paper discusses the benefits and challenges of token-based typology, which takes into account the frequencies of words and constructions in language use. This approach makes it possible to introduce new criteria for language classification, which would be difficult or impossible to achieve with the traditional, type-based approach. This point is illustrated by several quantitative studies of word order variation, which can be measured as entropy at different levels of granularity. I argue that this variation can be explained by general functional mechanisms and pressures, which manifest themselves in language use, such as optimization of processing (including avoidance of ambiguity) and grammaticalization of predictable units occurring in chunks. The case studies are based on multilingual corpora, which have been parsed using the Universal Dependencies annotation scheme.},
	number = {3},
	urldate = {2019-11-15},
	journal = {Linguistic Typology},
	author = {Levshina, Natalia},
	year = {2019},
	pages = {533--572},
}

@article{levshina_efficiency_2021,
	title = {Efficiency in human languages: {Corpus} evidence for universal principles},
	volume = {7},
	issn = {2199-174X},
	shorttitle = {Efficiency in human languages},
	url = {https://www.degruyter.com/document/doi/10.1515/lingvan-2020-0081/html},
	doi = {10.1515/lingvan-2020-0081},
	abstract = {Over the last few years, there has been a growing interest in communicative efficiency. It has been argued that language users act efficiently, saving effort for processing and articulation, and that language structure and use reflect this tendency. The emergence of new corpus data has brought to life numerous studies on efficient language use in the lexicon, in morphosyntax, and in discourse and phonology in different languages. In this introductory paper, we discuss communicative efficiency in human languages, focusing on evidence of efficient language use found in multilingual corpora. The evidence suggests that efficiency is a universal feature of human language. We provide an overview of different manifestations of efficiency on different levels of language structure, and we discuss the major questions and findings so far, some of which are addressed for the first time in the contributions in this special collection.},
	language = {en},
	number = {s3},
	urldate = {2021-06-22},
	journal = {Linguistics Vanguard},
	author = {Levshina, Natalia and Moran, Steven},
	month = may,
	year = {2021},
	note = {Publisher: De Gruyter Mouton
Section: Linguistics Vanguard},
}

@article{levshina_online_2017,
	title = {Online film subtitles as a corpus: an n-gram approach},
	volume = {12},
	issn = {1749-5032},
	shorttitle = {Online film subtitles as a corpus},
	url = {https://www.euppublishing.com/doi/abs/10.3366/cor.2017.0123},
	doi = {10.3366/cor.2017.0123},
	abstract = {In this paper, I investigate online film subtitles from a quantitative perspective, treating them as a separate register of communication. Subtitles from films in English and other languages transl...},
	number = {3},
	urldate = {2019-06-21},
	journal = {Corpora},
	author = {Levshina, Natalia},
	month = nov,
	year = {2017},
	pages = {311--338},
}

@article{firth_technique_1935,
	title = {The {Technique} of {Semantics}},
	volume = {34},
	issn = {1467-968X},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-968X.1935.tb01254.x/abstract},
	doi = {10.1111/j.1467-968X.1935.tb01254.x},
	language = {en},
	number = {1},
	urldate = {2016-04-25},
	journal = {Transactions of the Philological Society},
	author = {Firth, J. R.},
	month = nov,
	year = {1935},
	keywords = {conversation analysis, early sources, important},
	pages = {36--73},
}

@misc{hammarstrom_glottologglottolog_2021,
	title = {glottolog/glottolog: {Glottolog} database 4.4},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	shorttitle = {glottolog/glottolog},
	url = {https://zenodo.org/record/4761960},
	doi = {10.5281/ZENODO.4761960},
	abstract = {Hammarström, Harald \&amp; Forkel, Robert \&amp; Haspelmath, Martin \&amp; Bank, Sebastian. 2021. Glottolog 4.4. Leipzig: Max Planck Institute for Evolutionary Anthropology. (Available online at https://glottolog.org)},
	urldate = {2021-11-12},
	publisher = {Zenodo},
	author = {Hammarström, Harald and Forkel, Robert and Haspelmath, Martin and Bank, Sebastian},
	month = may,
	year = {2021},
	keywords = {linguistics},
}

@book{jefferson_issues_1983,
	title = {Issues in the transcription of naturally-occurring talk: {Caricature} versus capturing pronunciational particulars},
	publisher = {Tilburg Univ., Department of Language and Linguistics},
	author = {Jefferson, Gail},
	year = {1983},
}

@article{clark_using_2002,
	title = {Using uh and um in spontaneous speaking},
	volume = {84},
	doi = {10.1016/S0010-0277(02)00017-3},
	journal = {Cognition},
	author = {Clark, Herbert H. and Fox Tree, Jean E.},
	year = {2002},
	pages = {73--111},
}

@article{wharton_interjections_2003,
	title = {Interjections, language, and the `showing/saying' continuum},
	volume = {11},
	doi = {10.1075/pc.11.1.04wha},
	abstract = {Historically, interjections have been treated in two different ways: as part of language, or as non-words signifying feelings or states of mind. In this paper, I assess the relative strengths and weaknesses of two contemporary approaches that reflect the historical dichotomy, and suggest a new analysis which preserves the insights of both. Interjections have a natural and a coded element, and are better analysed as falling at various points along a continuum between ‘showing’ and ‘saying’. These two notions are characterised in theoretical terms, and some implications of the proposed approach are considered.},
	urldate = {2010-05-16},
	journal = {Pragmatics \& Cognition},
	author = {Wharton, Tim},
	year = {2003},
	pages = {39--91},
}

@article{trager_typology_1961,
	title = {The {Typology} of {Paralanguage}},
	volume = {3},
	issn = {0003-5483},
	url = {http://www.jstor.org/stable/30022290},
	number = {1},
	urldate = {2011-12-06},
	journal = {Anthropological Linguistics},
	author = {Trager, George L.},
	month = jan,
	year = {1961},
	note = {ArticleType: research-article / Issue Title: Uses of Typology in Language or Culture or Both: A Symposium Presented at the 1960 Meetings of the American Anthropological Association / Full publication date: Jan., 1961 / Copyright © 1961 Anthropological Linguistics},
	pages = {17--21},
}

@incollection{helfrich_paralinguistic_2004,
	address = {New York},
	title = {Paralinguistic behaviors and culture},
	booktitle = {Encyclopedia of {Applied} {Psychology}},
	publisher = {Elsevier},
	author = {Helfrich, Hede},
	editor = {Spielberger, D.},
	year = {2004},
	keywords = {project-OIR},
	pages = {797--813},
}

@article{wray_protolanguage_1998,
	title = {Protolanguage as a holistic system for social interaction},
	volume = {18},
	url = {http://www.sciencedirect.com/science/article/B6VB6-3SX80VJ-3/2/58ce016314a6fe89018ffea4239a4ab0},
	doi = {10.1016/S0271-5309(97)00033-5},
	number = {1},
	urldate = {2008-10-31},
	journal = {Language \& Communication},
	author = {Wray, Alison},
	month = jan,
	year = {1998},
	pages = {47--67},
}

@inproceedings{hough_duel_2016,
	title = {Duel: {A} multi-lingual multimodal dialogue corpus for disfluency, exclamations and laughter},
	shorttitle = {Duel},
	url = {https://pub.uni-bielefeld.de/download/2903080/2903084},
	urldate = {2017-01-19},
	booktitle = {10th edition of the {Language} {Resources} and {Evaluation} {Conference}},
	author = {Hough, Julian and Tian, Ye and de Ruiter, Laura and Betz, Simon and Schlangen, David and Ginzburg, Jonathan},
	year = {2016},
}

@inproceedings{carlmeyer_hesitating_2018,
	address = {New York, NY, USA},
	series = {{HRI} '18},
	title = {The {Hesitating} {Robot} - {Implementation} and {First} {Impressions}},
	isbn = {978-1-4503-5615-2},
	url = {http://doi.acm.org/10.1145/3173386.3176992},
	doi = {10.1145/3173386.3176992},
	abstract = {In this paper we present the implementation of a robot, that dynamically hesitates, based on the attention of the human interaction partner. To this end, we outline requirements for a real-time interaction scenario, describe the realization of a disfluency insertion strategy, and present observations from the first tests of the system.},
	urldate = {2018-05-31},
	booktitle = {Companion of the 2018 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Carlmeyer, Birte and Betz, Simon and Wagner, Petra and Wrede, Britta and Schlangen, David},
	year = {2018},
	pages = {77--78},
}

@inproceedings{schlangen_causes_2004,
	title = {Causes and strategies for requesting clarification in dialogue},
	booktitle = {Proceedings of the 5th {Workshop} of the {ACL} {SIG} on {Discourse} and {Dialogue}},
	author = {Schlangen, David},
	year = {2004},
}

@article{ward_prosodic_2000,
	title = {Prosodic features which cue back-channel responses in {English} and {Japanese}},
	volume = {32},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/S0378216699001095},
	doi = {10.1016/S0378-2166(99)00109-5},
	abstract = {Back-channel feedback, responses such as uh-uh from a listener, is a pervasive feature of conversation. It has long been thought that the production of back-channel feedback depends to a large extent on the actions of the other conversation partner, not just on the volition of the one who produces them. In particular, prosodic cues from the speaker have long been thought to play a role, but have so far eluded identification. We have earlier suggested that an important prosodic cue involved, in both English and Japanese, is a region of low pitch late in an utterance (Ward, 1996). This paper discusses issues in the definition of back-channel feedback, presents evidence for our claim, surveys other factors which elicit or inhibit back-channel responses, and mentions a few related phenomena and theoretical issues.},
	number = {8},
	urldate = {2017-09-18},
	journal = {Journal of Pragmatics},
	author = {Ward, Nigel and Tsukahara, Wataru},
	month = jul,
	year = {2000},
	pages = {1177--1207},
}

@article{ward_learning_2007,
	title = {Learning to show you're listening},
	volume = {20},
	issn = {0958-8221},
	url = {http://dx.doi.org/10.1080/09588220701745825},
	doi = {10.1080/09588220701745825},
	abstract = {Good listeners generally produce back-channel feedback, that is, short utterances such as uh-huh which signal active listening. As the rules governing back-channeling vary from language to language, second-language learners may need help acquiring this skill. This paper is an initial exploration of how to provide this. It presents a training sequence which enables learners to acquire a basic Arabic back-channel skill, namely, that of producing feedback immediately after the speaker produces a syllable or two with a sharply falling pitch. This training sequence includes an explanation, audio examples, the use of visual signals to highlight occurrences of this pitch downslope, auditory and visual feedback on learners' attempts to produce the cue themselves, and feedback on the learners' performance as they play the role of an attentive listener in response to one side of a pre-recorded dialog. Experiments show that this enables learners to better approximate proper Arabic back-channeling behavior.},
	number = {4},
	urldate = {2017-10-17},
	journal = {Computer Assisted Language Learning},
	author = {Ward, Nigel G. and Escalante, Rafael and Bayyari, Yaffa Al and Solorio, Thamar},
	month = oct,
	year = {2007},
	pages = {385--407},
}

@inproceedings{ward_possible_2012,
	title = {Possible lexical cues for backchannel responses},
	booktitle = {Feedback {Behaviors} in {Dialog}},
	author = {Ward, Nigel G.},
	year = {2012},
}

@article{ward_challenges_2017,
	title = {Challenges in {Building} {Highly} {Interactive} {Dialogue} {Systems}},
	volume = {37},
	language = {en},
	number = {4},
	journal = {AI Magazine},
	author = {Ward, Nigel G and DeVault, David},
	year = {2017},
	pages = {7--17},
}

@incollection{clark_computational_2010,
	address = {Chichester, West Sussex ; Malden, MA},
	series = {Blackwell handbooks in linguistics},
	title = {Computational models of dialogue},
	isbn = {978-1-4051-5581-6 978-1-118-34718-8},
	booktitle = {The handbook of computational linguistics and natural language processing},
	publisher = {Wiley-Blackwell},
	author = {Ginzburg, Jonathan and Fernández, Raquel},
	editor = {Clark, Alexander and Fox, Chris and Lappin, Shalom},
	year = {2010},
	note = {OCLC: ocn500823419},
}

@article{ginzburg_grammar_2016,
	title = {Grammar {Is} a {System} {That} {Characterizes} {Talk} in {Interaction}},
	volume = {7},
	issn = {1664-1078},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2016.01938/full},
	doi = {10.3389/fpsyg.2016.01938},
	abstract = {Much of contemporary mainstream formal grammar theory is unable to provide analyses for language as it occurs in actual spoken interaction. Its analyses are developed for a cleaned up version of language which omits the disfluencies, non-sentential utterances, gestures, and many other phenomena that are ubiquitous in spoken language. Using evidence from linguistics, conversation analysis, multimodal communication, psychology, language acquisition, and neuroscience, we show these aspects of language use are rule governed in much the same way as phenomena captured by conventional grammars. Furthermore, we argue that over the past few years the theoretical tools required to provide a precise characterizations of such phenomena have begun to emerge in theoretical and computational linguistics; hence, there is no reason for treating them as ‘second class citizens’ other than pre-theoretical assumptions about what should fall under the purview of grammar. Finally, we suggest that grammar formalisms covering such phenomena would provide a better foundation not just for linguistic analysis of face-to-face interaction, but also for sister disciplines, such as research on spoken dialogue systems and /or psychological work on language acquisition.},
	language = {English},
	urldate = {2017-06-02},
	journal = {Frontiers in Psychology},
	author = {Ginzburg, Jonathan and Poesio, Massimo},
	year = {2016},
}

@article{ward_non-lexical_2006,
	title = {Non-lexical conversational sounds in {American} {English}},
	volume = {14},
	doi = {10.1075/pc.14.1.08war},
	abstract = {Sounds like h-nmm, hh-aaaah, hn-hn, unkay, nyeah, ummum, uuh, um-hm-uh-hm, um and uh-huh occur frequently in American English conversation but have thus far escaped systematic study. This article reports a study of both the forms and functions of such tokens in a corpus of American English conversations. These sounds appear not to be lexical, in that they are productively generated rather than finite in number, and in that the sound-meaning mapping is compositional rather than arbitrary. This implies that English bears within it a small specialized sub-language which follows different rules from the language as a whole. The functions supported by this sub-language complement those of main-channel English; they include low-overhead control of turn-taking, negotiation of agreement, signaling of recognition and comprehension, management of interpersonal relations such as control and affiliation, and the expression of emotion, attitude, and affect.},
	journal = {Pragmatics \& Cognition},
	author = {Ward, Nigel},
	year = {2006},
	keywords = {project-OIR},
	pages = {129--182},
}

@inproceedings{gilmartin_chat_2018,
	address = {Santa Fe, New Mexico, USA},
	title = {Chat, {Chunk} and {Topic} in {Casual} {Conversation}},
	url = {https://aclanthology.org/W18-4705},
	urldate = {2021-10-05},
	booktitle = {Proceedings 14th {Joint} {ACL} - {ISO} {Workshop} on {Interoperable} {Semantic} {Annotation}},
	publisher = {Association for Computational Linguistics},
	author = {Gilmartin, Emer and Vogel, Carl},
	month = aug,
	year = {2018},
	pages = {45--52},
}

@incollection{selting_introducing_2001,
	address = {Amsterdam},
	series = {Studies in {Discourse} and {Grammar}},
	title = {Introducing {Interactional} {Linguistics}},
	isbn = {1-58811-097-4},
	number = {10},
	booktitle = {Studies in {Interactional} {Linguistics}},
	publisher = {John Benjamins},
	author = {Couper-Kuhlen, Elizabeth and Selting, Margret},
	editor = {Selting, Margret and Couper-Kuhlen, Elizabeth},
	year = {2001},
	keywords = {discourse, social interaction},
	pages = {1--22},
}

@incollection{couper-kuhlen_towards_1996,
	address = {Cambridge / New York},
	title = {Towards an interactional perspective on prosody and a prosodic perspective on interaction},
	isbn = {978-0-521-46075-0},
	booktitle = {Prosody in conversation : interactional studies},
	publisher = {Cambridge University Press},
	author = {Couper-Kuhlen, Elizabeth and Selting, Margret},
	editor = {Couper-Kuhlen, Elizabeth and Selting, Margret},
	year = {1996},
	pages = {11--56},
}

@book{couper-kuhlen_prosody_1996,
	address = {Cambridge / New York},
	title = {Prosody in conversation : interactional studies},
	isbn = {978-0-521-46075-0},
	shorttitle = {Prosody in conversation},
	publisher = {Cambridge University Press},
	editor = {Couper-Kuhlen, Elizabeth and Selting, Margret},
	year = {1996},
}

@incollection{drew_divisions_2014,
	address = {Amsterdam},
	title = {On divisions of labor in request and offer environments},
	volume = {26},
	isbn = {978 90 272 2636 5, 9789027269287},
	url = {https://benjamins.com/catalog/slsi.26.05cou},
	abstract = {Dividing the labor for achieving a common goal is a routinized practice that is found in both request and offer environments in English and Finnish everyday conversations. There are specific linguistic resources deployed in the two languages for this practice. Divisions of labor are typically proposed with a bi-partite construction that consists schematically of a Request to Other to carry out some action X, and a Commitment by Self to carry out a complementary action Y. Where there is a possible chronological order for the actions X and Y, the request and commitment are ordered accordingly. Although in both languages there is a common schematic structure underlying the linguistic constructions used in proposing divisions of labor, the attested patterns vary in the degree of certainty that they express concerning the future actions. In addition, the patterns in Finnish vary in the explicitness with which the agents of the future actions are expressed. In neither of the languages are the variant patterns interchangeable. Instead, the patterns have distinct sequential home environments: the more certainty and explicitness the pattern expresses, the later in the sequence it occurs. Division-of labor proposals divide not only the labor, but also deontic primacy (the right to decide) and responsibility. By construing the venture as a joint one, they transform asymmetric actions such as offers and requests into more symmetric ones. This may explain why divisions of labor typically occur in request and offer sequences that are problematic and run the risk of miscarrying.},
	language = {en},
	urldate = {2015-02-27},
	booktitle = {Studies in {Language} and {Social} {Interaction}},
	publisher = {John Benjamins Publishing Company},
	author = {Couper-Kuhlen, Elizabeth and Etelämäki, Marja},
	editor = {Drew, Paul and Couper-Kuhlen, Elizabeth},
	year = {2014},
	pages = {115--144},
}

@incollection{couper-kuhlen_forms_2014,
	address = {Berlin, Boston},
	title = {Forms of responsivity: {Grammatical} formats for responding to two types of request in conversation},
	isbn = {978-3-11-035861-2},
	shorttitle = {Forms of responsivity},
	urldate = {2014-12-16},
	booktitle = {Grammar and {Dialogism} {Sequential}, {Syntactic}, and {Prosodic} {Patterns} between {Emergence} and {Sedimentation}},
	publisher = {De Gruyter},
	author = {Couper-Kuhlen, Elizabeth and Fox, Barbara A. and Thompson, Sandra A.},
	editor = {Günthner, Susanne and Imo, Wolfgang and Bücker, Jörg},
	year = {2014},
	pages = {109--138},
}

@book{couper-kuhlen_sound_2004,
	address = {Amsterdam},
	title = {Sound patterns in interaction: cross-linguistic studies of phonetics and prosody for conversation},
	publisher = {John Benjamins},
	author = {Couper-Kuhlen, Elizabeth and Ford, Cecilia E.},
	year = {2004},
}

@incollection{couper-kuhlen_coherent_1999,
	address = {Amsterdam},
	title = {Coherent voicing: {On} prosody in conversational reported speech},
	shorttitle = {Coherent voicing},
	url = {http://books.google.nl/books?hl=en&lr=&id=swd_6dyy0gwC&oi=fnd&pg=PA11&dq=loudness+%22recipient+design%22+&ots=x9mKtIySwj&sig=JHl3mLW1Y7mXioejrd42ZI0fvG0},
	urldate = {2014-11-30},
	booktitle = {Coherence in spoken and written discourse},
	publisher = {John Benjamins},
	author = {Couper-Kuhlen, Elizabeth and Bublitz, Wolfram and Lenk, Uta and Ventola, Eija},
	year = {1999},
	pages = {11--34},
}

@article{couper-kuhlen_language_2021,
	title = {Language over time: {Some} old and new uses of {OKAY} in {American} {English}},
	shorttitle = {Language over time},
	url = {https://www.jbe-platform.com/content/journals/10.1075/il.20008.cou},
	doi = {10.1075/il.20008.cou},
	abstract = {Abstract This paper demonstrates how the tools of Interactional Linguistics can be applied to the study of change in language use. It examines the particle OKAY as used in everyday American English interaction at two different points in time, the 1960s and the 1990s/early 2000s. The focus is on the remarkable increase of OKAY as a response in epistemically driven sequences. Three uses of epistemic OKAY are identified in the newer data, one of which is unattested in the older data: OKAY in response to information that has no implications for the recipient’s agenda or expressed beliefs. This novel use of OKAY appears in the newer data where OH would have occurred earlier, although OH is still attested with displays of affect such as surprise and empathy. The study concludes by arguing for an examination of ‘possibility spaces’, the set of options for filling a given sequential slot in conversational structure, at different points in time as a means for identifying changes in language use.},
	language = {en},
	urldate = {2021-04-20},
	author = {Couper-Kuhlen, Elizabeth},
	month = apr,
	year = {2021},
	note = {Publisher: John Benjamins},
}

@article{couper-kuhlen_turn_2012,
	title = {Turn {Continuation} and {Clause} {Combinations}},
	volume = {49},
	issn = {0163-853X},
	url = {http://dx.doi.org/10.1080/0163853X.2012.664111},
	doi = {10.1080/0163853X.2012.664111},
	abstract = {This article explores the viability of the analytic distinction between “turn-constructional unit (TCU) continuation” (i.e., continuing a turn beyond a point of possible completion with grammatically dependent material) and “new TCU” (i.e., continuing a turn with grammatically independent material) when hypotactic clause combinations are involved. The focus is on causal clause combinations, which may be either lexico-syntactically marked (e.g., as in English with because) or lexico-syntactically unmarked but prosodically cohesive. Based on data from ordinary conversation, it is found that both marked and unmarked forms are used in turn continuation, with the unit containing the account (the causal clause) being delivered after the completion of a unit implementing the accountable action. Both marked and unmarked forms of causal clause combination, when used in turn continuation, allow for intervening talk after the accountable; both prioritize the account in establishing relevancies for what happens next. Yet, in current conceptualizations of turn continuation, they would be classified differently, with marked forms counting as “TCU continuation” and unmarked forms as “new TCU.” The implications of this unsatisfactory state of affairs are discussed in the conclusion.},
	number = {3-4},
	urldate = {2014-09-05},
	journal = {Discourse Processes},
	author = {Couper-Kuhlen, Elizabeth},
	month = feb,
	year = {2012},
	pages = {273--299},
}

@article{couper-kuhlen_when_2011,
	title = {When turns start with because: {An} exercise in interactional syntax},
	journal = {Connectives in Synchrony and Diachrony in European Languages (Studies in Variation, Contacts and Change in English, 8)},
	author = {Couper-Kuhlen, Elizabeth},
	year = {2011},
}

@article{couper-kuhlen_sequence_2010,
	title = {Sequence organization in interaction: {A} primer in conversation analysis, vol. 1 (review)},
	volume = {86},
	issn = {1535-0665},
	shorttitle = {{\textless}i{\textgreater}{Sequence} organization in interaction},
	url = {http://muse.jhu.edu/journals/lan/summary/v086/86.1.couper-kuhlen.html},
	doi = {10.1353/lan.0.0190},
	number = {1},
	urldate = {2010-11-08},
	journal = {Language},
	author = {Couper-Kuhlen, Elizabeth},
	year = {2010},
	pages = {249--252},
}

@incollection{couper-kuhlen_sequential_2009,
	address = {Helsinki},
	title = {A sequential approach to affect: {The} case of 'disappointment'},
	booktitle = {Talk in interaction-comparative dimensions},
	publisher = {Finnish Literature Society},
	author = {Couper-Kuhlen, Elizabeth},
	editor = {Haakana, Markku and Laakso, Minna and Lindström, Jan},
	year = {2009},
	pages = {94--123},
}

@incollection{holt_assessing_2007,
	address = {Cambridge ; New York},
	series = {Studies in interactional sociolinguistics},
	title = {Assessing and accounting},
	isbn = {978-0-521-82483-5},
	number = {24},
	booktitle = {Reporting {Talk}: {Reported} {Speech} in {Interaction}},
	publisher = {Cambridge University Press},
	author = {Couper-Kuhlen, Elizabeth},
	editor = {Holt, Elizabeth and Clift, Rebecca},
	year = {2007},
}

@incollection{couper-kuhlen_prosodic_2006,
	address = {Oxford},
	title = {Prosodic {Cues} of {Discourse} {Units}},
	isbn = {978-0-08-044854-1},
	url = {http://www.sciencedirect.com/science/article/B7T84-4M3C3K0-1DV/2/0694913e1ca2351f8f37eebcf1088123},
	abstract = {In scripted, monologic discourse, speakers' units - the spoken sentence and the spoken paragraph - are often, but not invariably, homomorphic with their grammatical and orthographic counterparts. The boundaries of these spoken units are signaled by characteristic patterns of pitch, loudness, and timing; internally, they display cohesion through pitch and loudness declination. In unscripted, dialogic discourse, speakers' units are turn-constructional, produced online in coordination with other speakers' turns, and embarked upon in the pursuit of courses of action. Although turn-constructional units, turns, and sequences are structured through action and interaction, cues to their emergent structure are built in via prosodic formatting.},
	urldate = {2009-03-04},
	booktitle = {Encyclopedia of {Language} \& {Linguistics}},
	publisher = {Elsevier},
	author = {Couper-Kuhlen, Elizabeth},
	editor = {{Keith Brown}},
	year = {2006},
	pages = {178--182},
}

@article{couper-kuhlen_what_2014,
	title = {What does grammar tell us about action?},
	volume = {24},
	number = {3},
	journal = {Pragmatics},
	author = {Couper-Kuhlen, Elizabeth},
	year = {2014},
	pages = {623--647},
}

@misc{couper-kuhlen_action_2011,
	address = {MPI for Psycholinguistics, Nijmegen},
	title = {Action ascription across languages: {Proposals} and suggestions in {Finnish}},
	author = {Couper-Kuhlen, Elizabeth},
	month = mar,
	year = {2011},
}

@article{couper-kuhlen_commentary_2010,
	title = {Commentary on {Stivers} and {Rossano}: “{Mobilizing} {Response}”},
	volume = {43},
	issn = {0835-1813},
	shorttitle = {Commentary on {Stivers} and {Rossano}},
	url = {http://www.informaworld.com/10.1080/08351810903471316},
	doi = {10.1080/08351810903471316},
	number = {1},
	urldate = {2010-07-12},
	journal = {Research on Language and Social Interaction},
	author = {Couper-Kuhlen, Elizabeth},
	year = {2010},
	pages = {32},
}

@inproceedings{duong_neural_2015,
	title = {A neural network model for low-resource universal dependency parsing},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {Duong, Long and Cohn, Trevor and Bird, Steven and Cook, Paul},
	year = {2015},
	pages = {339--348},
}

@inproceedings{duong_low_2015,
	title = {Low resource dependency parsing: {Cross}-lingual parameter sharing in a neural network parser},
	booktitle = {Proceedings of the 53rd annual meeting of the {Association} for {Computational} {Linguistics} and the 7th international joint conference on natural language processing (volume 2: short papers)},
	author = {Duong, Long and Cohn, Trevor and Bird, Steven and Cook, Paul},
	year = {2015},
	pages = {845--850},
}

@article{daume_iii_bayesian_2009,
	title = {A {Bayesian} model for discovering typological implications},
	journal = {arXiv preprint arXiv:0907.0785},
	author = {Daumé III, Hal and Campbell, Lyle},
	year = {2009},
}

@article{bjerva_phonology_2018,
	title = {From phonology to syntax: {Unsupervised} linguistic typology at different levels with language embeddings},
	journal = {arXiv preprint arXiv:1802.09375},
	author = {Bjerva, Johannes and Augenstein, Isabelle},
	year = {2018},
}

@article{bickel_distributional_2015,
	title = {Distributional typology: {Statistical} inquiries into the dynamics of linguistic diversity},
	author = {Bickel, Balthasar and Heine, Bernd and Narrog, Heiko},
	year = {2015},
	note = {Publisher: Oxford University Press},
}

@article{asgari_past_2017,
	title = {Past, present, future: {A} computational investigation of the typology of tense in 1000 languages},
	journal = {arXiv preprint arXiv:1704.08914},
	author = {Asgari, Ehsaneddin and Schütze, Hinrich},
	year = {2017},
}

@inproceedings{adel_combination_2013,
	address = {Sofia, Bulgaria},
	title = {Combination of {Recurrent} {Neural} {Networks} and {Factored} {Language} {Models} for {Code}-{Switching} {Language} {Modeling}},
	url = {https://aclanthology.org/P13-2037},
	booktitle = {Proceedings of the 51st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Adel, Heike and Vu, Ngoc Thang and Schultz, Tanja},
	month = aug,
	year = {2013},
	pages = {206--211},
}

@article{agic_multilingual_2016,
	title = {Multilingual projection for parsing truly low-resource languages},
	volume = {4},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Agić, Željko and Johannsen, Anders and Plank, Barbara and Alonso, Héctor Martínez and Schluter, Natalie and Søgaard, Anders},
	year = {2016},
	note = {Publisher: MIT Press},
	pages = {301--312},
}

@inproceedings{agic_if_2015,
	title = {If all you have is a bit of the {Bible}: {Learning} {POS} taggers for truly low-resource languages},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 2: {Short} {Papers})},
	author = {Agić, Željko and Hovy, Dirk and Søgaard, Anders},
	year = {2015},
	pages = {268--272},
}

@article{ponti_modeling_2019,
	title = {Modeling {Language} {Variation} and {Universals}: {A} {Survey} on {Typological} {Linguistics} for {Natural} {Language} {Processing}},
	volume = {45},
	issn = {0891-2017, 1530-9312},
	shorttitle = {Modeling {Language} {Variation} and {Universals}},
	url = {https://direct.mit.edu/coli/article/45/3/559-601/93372},
	doi = {10.1162/coli_a_00357},
	abstract = {Linguistic typology aims to capture structural and semantic variation across the world’s languages. A large-scale typology could provide excellent guidance for multilingual Natural Language Processing (NLP), particularly for languages that suffer from the lack of human labeled resources. We present an extensive literature survey on the use of typological information in the development of NLP techniques. Our survey demonstrates that to date, the use of information in existing typological databases has resulted in consistent but modest improvements in system performance. We show that this is due to both intrinsic limitations of databases (in terms of coverage and feature granularity) and under-utilization of the typological features included in them. We advocate for a new approach that adapts the broad and discrete nature of typological categories to the contextual and continuous nature of machine learning algorithms used in contemporary NLP. In particular, we suggest that such an approach could be facilitated by recent developments in data-driven induction of typological knowledge.},
	language = {en},
	number = {3},
	urldate = {2021-11-10},
	journal = {Computational Linguistics},
	author = {Ponti, Edoardo Maria and O’Horan, Helen and Berzak, Yevgeni and Vulić, Ivan and Reichart, Roi and Poibeau, Thierry and Shutova, Ekaterina and Korhonen, Anna},
	month = sep,
	year = {2019},
	pages = {559--601},
}

@inproceedings{zahrer_towards_2020,
	address = {Marseille, France},
	title = {Towards {Building} an {Automatic} {Transcription} {System} for {Language} {Documentation}: {Experiences} from {Muyu}},
	isbn = {979-10-95546-34-4},
	url = {https://aclanthology.org/2020.lrec-1.353},
	abstract = {Since at least half of the world's 6000 plus languages will vanish during the 21st century, language documentation has become a rapidly growing field in linguistics. A fundamental challenge for language documentation is the ”transcription bottleneck”. Speech technology may deliver the decisive breakthrough for overcoming the transcription bottleneck. This paper presents first experiments from the development of ASR4LD, a new automatic speech recognition (ASR) based tool for language documentation (LD). The experiments are based on recordings from an ongoing documentation project for the endangered Muyu language in New Guinea. We compare phoneme recognition experiments with American English, Austrian German and Slovenian as source language and Muyu as target language. The Slovenian acoustic models achieve the by far best performance (43.71\% PER) in comparison to 57.14\% PER with American English, and 89.49\% PER with Austrian German. Whereas part of the errors can be explained by phonetic variation, the recording mismatch poses a major problem. On the long term, ASR4LD will not only be an integral part of the ongoing documentation project of Muyu, but will be further developed in order to facilitate also the language documentation process of other language groups.},
	language = {English},
	booktitle = {Proceedings of the 12th {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Zahrer, Alexander and Zgank, Andrej and Schuppler, Barbara},
	month = may,
	year = {2020},
	pages = {2893--2900},
}

@inproceedings{anastasopoulos_spoken_2017,
	address = {Copenhagen, Denmark},
	title = {Spoken {Term} {Discovery} for {Language} {Documentation} using {Translations}},
	url = {https://aclanthology.org/W17-4607},
	doi = {10.18653/v1/W17-4607},
	abstract = {Vast amounts of speech data collected for language documentation and research remain untranscribed and unsearchable, but often a small amount of speech may have text translations available. We present a method for partially labeling additional speech with translations in this scenario. We modify an unsupervised speech-to-translation alignment model and obtain prototype speech segments that match the translation words, which are in turn used to discover terms in the unlabelled data. We evaluate our method on a Spanish-English speech translation corpus and on two corpora of endangered languages, Arapaho and Ainu, demonstrating its appropriateness and applicability in an actual very-low-resource scenario.},
	booktitle = {Proceedings of the {Workshop} on {Speech}-{Centric} {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Anastasopoulos, Antonios and Bansal, Sameer and Chiang, David and Goldwater, Sharon and Lopez, Adam},
	month = sep,
	year = {2017},
	pages = {53--58},
}

@inproceedings{cavar_endangered_2016,
	title = {Endangered language documentation: {Bootstrapping} a {Chatino} speech corpus, forced aligner, {ASR}},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'16)},
	author = {Ćavar, Malgorzata and Ćavar, Damir and Cruz, Hilaria},
	year = {2016},
	pages = {4004--4011},
}

@inproceedings{bender_linguistically_2009,
	title = {Linguistically naïve!= language independent: {Why} {NLP} needs linguistic typology},
	booktitle = {Proceedings of the {EACL} 2009 {Workshop} on the {Interaction} between {Linguistics} and {Computational} {Linguistics}: {Virtuous}, {Vicious} or {Vacuous}?},
	author = {Bender, Emily M},
	year = {2009},
	pages = {26--32},
}

@misc{cerf_specification_1974,
	title = {Specification of {Internet} {Transmission} {Control} {Program} (rfc675)},
	url = {https://datatracker.ietf.org/doc/html/rfc675},
	publisher = {Network Working Group},
	author = {Cerf, Vinton and Dalal, Yogen and Sunshine, Carl},
	month = dec,
	year = {1974},
}

@inproceedings{bergstrom_conversation_2008,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '08},
	title = {Conversation clusters: human-computer dialog for topic extraction},
	isbn = {978-1-60558-012-8},
	shorttitle = {Conversation clusters},
	url = {https://doi.org/10.1145/1358628.1358769},
	doi = {10.1145/1358628.1358769},
	abstract = {In this paper, we look at projects leveraging human knowledge and understanding in computer systems for extracting conversational topics. Tasks like speech recognition are difficult for computers, but simple for people engaged in conversation. This task is a cornerstone of transcription, speech summarization, and topic recognition. We propose using tabletop interaction to enhance the computer's basic categorization. We then describe how the results of tabletop interaction help to create meaningful archival visualizations and personal reflecting tools.},
	urldate = {2021-10-23},
	booktitle = {{CHI} '08 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Bergstrom, Tony and Karahalios, Karrie},
	month = apr,
	year = {2008},
	pages = {2829--2834},
}

@inproceedings{bergstrom_vote_2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Vote and {Be} {Heard}: {Adding} {Back}-{Channel} {Signals} to {Social} {Mirrors}},
	isbn = {978-3-642-03655-2},
	shorttitle = {Vote and {Be} {Heard}},
	doi = {10.1007/978-3-642-03655-2_61},
	abstract = {In face-to-face group situations, social pressure and organizational hierarchy relegate the less outspoken to silence, often resulting in fewer voices, fewer ideas, and groupthink. However, in mediated interaction like email, more people join in the discussion to offer their opinion. With this work, we aim to combine the benefits of mediated communication with the benefits and affordances of face-to-face interaction by adding a mediated back-channel. We describe Conversation Votes, a tabletop system that augments verbal conversation with a shared anonymous back-channel to highlight agreement. We then discuss a study of our design with groups engaged in repeated discussion. Our results show that anonymous visual back-channels provide a medium for the underrepresented voices of a conversation and balances interaction among all participants.},
	language = {en},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2009},
	publisher = {Springer},
	author = {Bergstrom, Tony and Karahalios, Karrie},
	editor = {Gross, Tom and Gulliksen, Jan and Kotzé, Paula and Oestreicher, Lars and Palanque, Philippe and Prates, Raquel Oliveira and Winckler, Marco},
	year = {2009},
	pages = {546--559},
}

@article{karahalios_social_2009,
	title = {Social mirrors as social signals: transforming audio into graphics},
	volume = {29},
	shorttitle = {Social mirrors as social signals},
	number = {5},
	journal = {IEEE computer graphics and applications},
	author = {Karahalios, Karrie and Bergstrom, Tony},
	year = {2009},
	note = {Publisher: IEEE},
	pages = {22--32},
}

@inproceedings{bergstrom_conversation_2007,
	title = {Conversation votes: enabling anonymous cues},
	shorttitle = {Conversation votes},
	booktitle = {{CHI}'07 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	author = {Bergstrom, Tony and Karahalios, Karrie},
	year = {2007},
	pages = {2279--2284},
}

@inproceedings{karahalios_visualizing_2006,
	title = {Visualizing audio in group table conversation},
	booktitle = {First {IEEE} {International} {Workshop} on {Horizontal} {Interactive} {Human}-{Computer} {Systems} ({TABLETOP}'06)},
	publisher = {IEEE},
	author = {Karahalios, Karrie and Bergstrom, Tony},
	year = {2006},
	pages = {2--pp},
}

@inproceedings{bergstrom_conversation_2007-1,
	title = {Conversation {Clock}: {Visualizing} audio patterns in co-located groups},
	shorttitle = {Conversation {Clock}},
	booktitle = {2007 40th {Annual} {Hawaii} {International} {Conference} on {System} {Sciences} ({HICSS}'07)},
	publisher = {IEEE},
	author = {Bergstrom, Tony and Karahalios, Karrie},
	year = {2007},
	pages = {78--78},
}

@article{khulusi_survey_2020,
	title = {A {Survey} on {Visualizations} for {Musical} {Data}},
	volume = {39},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13905},
	doi = {10.1111/cgf.13905},
	abstract = {Digital methods are increasingly applied to store, structure and analyse vast amounts of musical data. In this context, visualization plays a crucial role, as it assists musicologists and non-expert users in data analysis and in gaining new knowledge. This survey focuses on this unique link between musicology and visualization. We classify 129 related works according to the visualized data types, and we analyse which visualization techniques were applied for certain research inquiries and to fulfill specific tasks. Next to scientific references, we take commercial music software and public websites into account, that contribute novel concepts of visualizing musicological data. We encounter different aspects of uncertainty as major problems when dealing with musicological data and show how occurring inconsistencies are processed and visually communicated. Drawing from our overview in the field, we identify open challenges for research on the interface of musicology and visualization to be tackled in the future.},
	language = {en},
	number = {6},
	urldate = {2021-10-23},
	journal = {Computer Graphics Forum},
	author = {Khulusi, R. and Kusnick, J. and Meinecke, C. and Gillmann, C. and Focht, J. and Jänicke, S.},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13905},
	pages = {82--110},
}

@article{mehler_lure_2020,
	title = {The lure of misleading causal statements in functional connectivity research},
	url = {http://arxiv.org/abs/1812.03363},
	abstract = {As neuroscientists we want to understand how causal interactions or mechanisms within the brain give rise to perception, cognition, and behavior. It is typical to estimate interaction effects from measured activity using statistical techniques such as functional connectivity, Granger Causality, or information flow, whose outcomes are often falsely treated as revealing mechanistic insight. Since these statistical techniques fit models to low-dimensional measurements from brains, they ignore the fact that brain activity is high-dimensional. Here we focus on the obvious confound of common inputs: the countless unobserved variables likely have more influence than the few observed ones. Any given observed correlation can be explained by an infinite set of causal models that take into account the unobserved variables. Therefore, correlations within massively undersampled measurements tell us little about mechanisms. We argue that these mis-inferences of causality from correlation are augmented by an implicit redefinition of words that suggest mechanisms, such as connectivity, causality, and flow.},
	urldate = {2021-10-21},
	journal = {arXiv:1812.03363 [q-bio]},
	author = {Mehler, David Marc Anton and Kording, Konrad Paul},
	month = oct,
	year = {2020},
	note = {arXiv: 1812.03363},
}

@article{kim_review_2019,
	title = {A {Review} on {Dyadic} {Conversation} {Visualizations} - {Purposes}, {Data}, {Lens} of {Analysis}},
	url = {https://arxiv.org/abs/1905.00653v1},
	abstract = {Many professional services are provided through text and voice systems, from
voice calls over the internet to messaging and emails. There is a growing need
for both individuals and organizations to understand these online conversations
better and find actionable insights. One method that allows the user to explore
insights is to build intuitive and rich visualizations that illustrate the
content of the conversation. In this paper, we present a systematic survey of
the various methods of visualizing a conversation and research papers involving
interactive visualizations and human participants. Findings from the survey
show that there have been attempts to visualize most, if not all, of the types
of conversation that are taking place digitally, from speech to messages and
emails. Through this survey, we make two contributions. One, we summarize the
current practices in the domain of visualizing dyadic conversations. Two, we
provide suggestions for future dialogue visualization research.},
	language = {en},
	urldate = {2019-05-03},
	author = {Kim, Joshua Y. and Calvo, Rafael A. and Yacef, Kalina and Enfield, N. J.},
	month = may,
	year = {2019},
}

@article{ferrer_i_cancho_zipfs_2005,
	title = {Zipf's law from a communicative phase transition},
	volume = {47},
	issn = {1434-6028, 1434-6036},
	url = {https://link.springer.com/article/10.1140/epjb/e2005-00340-y},
	doi = {10.1140/epjb/e2005-00340-y},
	abstract = {.Here we present a new model for Zipf's law in human word frequencies. The model defines the goal and the cost of communication using information theory. The model shows a continuous phase transition from a no communication to a perfect communication phase. Scaling consistent with Zipf's law is found in the boundary between phases. The exponents are consistent with minimizing the entropy of words. The model differs from a previous model [Ferrer i Cancho, Solé, Proc. Natl. Acad. Sci. USA 100, 788–791 (2003)] in two aspects. First, it assumes that the probability of experiencing a certain stimulus is controlled by the internal structure of the communication system rather than by the probability of experiencing it in the `outside' world, which makes it specially suitable for the speech of schizophrenics. Second, the exponent α predicted for the frequency versus rank distribution is in a range where α{\textgreater}1, which may explain that of some schizophrenics and some children, with α=1.5-1.6. Among the many models for Zipf's law, none explains Zipf's law for that particular range of exponents. In particular, two simplistic models fail to explain that particular range of exponents: intermittent silence and Simon's model. We support that Zipf's law in a communication system may maximize the information transfer under constraints.},
	language = {en},
	number = {3},
	urldate = {2018-01-06},
	journal = {The European Physical Journal B - Condensed Matter and Complex Systems},
	author = {Ferrer i Cancho, Ramon},
	month = oct,
	year = {2005},
	keywords = {*need to read, communication under constraints, modelling, repair},
	pages = {449--457},
}

@book{zipf_psycho-biology_1935,
	address = {Boston},
	title = {The psycho-biology of language},
	publisher = {Houghton Mifflin},
	author = {Zipf, George K.},
	year = {1935},
}

@article{baixeries_evolution_2013,
	title = {The {Evolution} of the {Exponent} of {Zipf}'s {Law} in {Language} {Ontogeny}},
	volume = {8},
	url = {http://dx.doi.org/10.1371/journal.pone.0053227},
	doi = {10.1371/journal.pone.0053227},
	abstract = {It is well-known that word frequencies arrange themselves according to Zipf's law. However, little is known about the dependency of the parameters of the law and the complexity of a communication system. Many models of the evolution of language assume that the exponent of the law remains constant as the complexity of a communication systems increases. Using longitudinal studies of child language, we analysed the word rank distribution for the speech of children and adults participating in conversations. The adults typically included family members (e.g., parents) or the investigators conducting the research. Our analysis of the evolution of Zipf's law yields two main unexpected results. First, in children the exponent of the law tends to decrease over time while this tendency is weaker in adults, thus suggesting this is not a mere mirror effect of adult speech. Second, although the exponent of the law is more stable in adults, their exponents fall below 1 which is the typical value of the exponent assumed in both children and adults. Our analysis also shows a tendency of the mean length of utterances (MLU), a simple estimate of syntactic complexity, to increase as the exponent decreases. The parallel evolution of the exponent and a simple indicator of syntactic complexity (MLU) supports the hypothesis that the exponent of Zipf's law and linguistic complexity are inter-related. The assumption that Zipf's law for word ranks is a power-law with a constant exponent of one in both adults and children needs to be revised.},
	number = {3},
	urldate = {2015-07-12},
	journal = {PLoS ONE},
	author = {Baixeries, Jaume and Elvevåg, Brita and Ferrer-i-Cancho, Ramon},
	month = mar,
	year = {2013},
	pages = {e53227},
}

@article{reed_pareto_2001,
	title = {The {Pareto}, {Zipf} and other power laws},
	volume = {74},
	issn = {0165-1765},
	url = {http://www.sciencedirect.com/science/article/pii/S0165176501005249},
	doi = {10.1016/S0165-1765(01)00524-9},
	abstract = {Many empirical size distributions in economics and elsewhere exhibit power-law behaviour in the upper tail. This article contains a simple explanation for this. It also predicts lower-tail power-law behaviour, which is verified empirically for income and city-size data.},
	number = {1},
	urldate = {2012-05-11},
	journal = {Economics Letters},
	author = {Reed, William J},
	month = dec,
	year = {2001},
	pages = {15--19},
}

@article{ryland_williams_zipfs_2015,
	title = {Zipf’s law holds for phrases, not words},
	volume = {5},
	copyright = {© 2015 Macmillan Publishers Limited},
	url = {http://www.nature.com/srep/2015/150811/srep12209/full/srep12209.html},
	doi = {10.1038/srep12209},
	abstract = {With Zipf’s law being originally and most famously observed for word frequency, it is surprisingly limited in its applicability to human language, holding over no more than three to four orders of magnitude before hitting a clear break in scaling. Here, building on the simple observation that phrases of one or more words comprise the most coherent units of meaning in language, we show empirically that Zipf’s law for phrases extends over as many as nine orders of rank magnitude. In doing so, we develop a principled and scalable statistical mechanical method of random text partitioning, which opens up a rich frontier of rigorous text analysis via a rank ordering of mixed length phrases.},
	language = {en},
	urldate = {2015-08-11},
	journal = {Scientific Reports},
	author = {Ryland Williams, Jake and Lessard, Paul R. and Desu, Suma and Clark, Eric M. and Bagrow, James P. and Danforth, Christopher M. and Sheridan Dodds, Peter},
	month = aug,
	year = {2015},
}

@article{lestrade_unzipping_2017,
	title = {Unzipping {Zipf}’s law},
	volume = {12},
	issn = {1932-6203},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0181987},
	doi = {10.1371/journal.pone.0181987},
	abstract = {In spite of decades of theorizing, the origins of Zipf’s law remain elusive. I propose that a Zipfian distribution straightforwardly follows from the interaction of syntax (word classes differing in class size) and semantics (words having to be sufficiently specific to be distinctive and sufficiently general to be reusable). These factors are independently motivated and well-established ingredients of a natural-language system. Using a computational model, it is shown that neither of these ingredients suffices to produce a Zipfian distribution on its own and that the results deviate from the Zipfian ideal only in the same way as natural language itself does.},
	language = {en},
	number = {8},
	urldate = {2018-03-22},
	journal = {PLOS ONE},
	author = {Lestrade, Sander},
	month = aug,
	year = {2017},
	pages = {e0181987},
}

@article{piantadosi_communicative_2012,
	title = {The communicative function of ambiguity in language},
	volume = {122},
	issn = {0010-0277},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027711002496},
	doi = {10.1016/j.cognition.2011.10.004},
	abstract = {We present a general information-theoretic argument that all efficient communication systems will be ambiguous, assuming that context is informative about meaning. We also argue that ambiguity allows for greater ease of processing by permitting efficient linguistic units to be re-used. We test predictions of this theory in English, German, and Dutch. Our results and theoretical analysis suggest that ambiguity is a functional property of language that allows for greater communicative efficiency. This provides theoretical and empirical arguments against recent suggestions that core features of linguistic systems are not designed for communication.},
	number = {3},
	urldate = {2012-10-09},
	journal = {Cognition},
	author = {Piantadosi, Steven T. and Tily, Harry and Gibson, Edward},
	month = mar,
	year = {2012},
	pages = {280--291},
}

@article{piantadosi_word_2011,
	title = {Word lengths are optimized for efficient communication},
	volume = {108},
	url = {http://www.pnas.org/content/108/9/3526.abstract},
	doi = {10.1073/pnas.1012551108},
	abstract = {We demonstrate a substantial improvement on one of the most celebrated empirical laws in the study of language, Zipf's 75-y-old theory that word length is primarily determined by frequency of use. In accord with rational theories of communication, we show across 10 languages that average information content is a much better predictor of word length than frequency. This indicates that human lexicons are efficiently structured for communication by taking into account interword statistical dependencies. Lexical systems result from an optimization of communicative pressures, coding meanings efficiently given the complex statistics of natural language use.},
	number = {9},
	urldate = {2011-04-06},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Piantadosi, Steven T. and Tily, Harry and Gibson, Edward},
	month = mar,
	year = {2011},
	pages = {3526 --3529},
}

@article{piantadosi_zipfs_2014,
	title = {Zipf’s word frequency law in natural language: {A} critical review and future directions},
	issn = {1069-9384, 1531-5320},
	shorttitle = {Zipf’s word frequency law in natural language},
	url = {http://link.springer.com/article/10.3758/s13423-014-0585-6},
	doi = {10.3758/s13423-014-0585-6},
	abstract = {The frequency distribution of words has been a key object of study in statistical linguistics for the past 70 years. This distribution approximately follows a simple mathematical form known as Zipf’s law. This article first shows that human language has a highly complex, reliable structure in the frequency distribution over and above this classic law, although prior data visualization methods have obscured this fact. A number of empirical phenomena related to word frequencies are then reviewed. These facts are chosen to be informative about the mechanisms giving rise to Zipf’s law and are then used to evaluate many of the theoretical explanations of Zipf’s law in language. No prior account straightforwardly explains all the basic facts or is supported with independent evaluation of its underlying assumptions. To make progress at understanding why language obeys Zipf’s law, studies must seek evidence beyond the law itself, testing assumptions and evaluating novel predictions with new, independent data.},
	language = {en},
	urldate = {2014-06-02},
	journal = {Psychonomic Bulletin \& Review},
	author = {Piantadosi, Steven T.},
	month = mar,
	year = {2014},
	pages = {1--19},
}

@book{enfield_dependencies_2017,
	address = {Berlin},
	title = {Dependencies in language: {On} the causal ontology of linguistic systems},
	isbn = {978-3-946234-66-1 978-3-946234-74-6},
	abstract = {Dependency is a fundamental concept in the analysis of linguistic systems. The many if-then statements offered in typology and grammar-writing imply a casually real notion of dependency that is central to the claim being made—usually with reference to widely varying timescales and types of processes. But despite the importance of the concept of dependency in our work, its nature is seldom defined or made explicit. This book brings together experts on language, representing descriptive linguistics, language typology, functional/cognitive linguistics, cognitive science, research on gesture and other semiotic systems, developmental psychology, psycholinguistics, and linguistic anthropology to address the following question: What kinds of dependencies exist among language-related systems, and how do we define and explain them in natural, causal terms?},
	language = {English},
	publisher = {Language Science Press},
	editor = {Enfield, N. J.},
	year = {2017},
	note = {OCLC: 989773805},
}

@book{enfield_utility_2015,
	address = {Oxford},
	title = {The {Utility} of {Meaning}: {What} {Words} {Mean} and {Why}},
	publisher = {Oxford University Press},
	author = {Enfield, N. J.},
	year = {2015},
}

@book{enfield_natural_2014,
	address = {Berlin},
	series = {Conceptual {Foundations} of {Language} {Science}},
	title = {Natural {Causes} of {Language}: {Frames}, biases and cultural transmission},
	number = {1},
	publisher = {Language Science Press},
	author = {Enfield, N. J.},
	year = {2014},
}

@book{enfield_relationship_2013,
	address = {Oxford},
	title = {Relationship {Thinking}: {Agency}, {Enchrony}, and {Human} {Sociality}},
	publisher = {Oxford University Press},
	author = {Enfield, N. J.},
	year = {2013},
}

@incollection{enfield_sources_2011,
	address = {Cambridge},
	title = {Sources of asymmetry in human interaction: {Enchrony}, status, knowledge, and agency},
	booktitle = {The {Morality} of {Knowledge} in {Conversation}},
	publisher = {Cambridge University Press},
	author = {Enfield, N. J.},
	editor = {Stivers, Tanya and Mondada, Lorenza and Steensig, Jakob},
	year = {2011},
	pages = {285--312},
}

@book{enfield_anatomy_2009,
	address = {Cambridge},
	title = {The {Anatomy} of {Meaning}: {Speech}, {Gesture}, and {Composite} {Utterances}},
	publisher = {Cambridge University Press},
	author = {Enfield, N. J.},
	year = {2009},
	keywords = {ebook, gesture, multimodality},
}

@incollection{enfield_elements_2011,
	title = {Elements of formulation},
	url = {http://pubman.mpdl.mpg.de/pubman/faces/viewItemFullPage.jsp;jsessionid=30A34A2CB4F712FE906003F8D0687F55},
	abstract = {Recognizing others' goals in the flow of interaction is complex, not only for analysts but for participants too. This chapter explores a semiotic approach, with the utterance-in-context as a basic-level unit, and where the interpreter, not the producer, is the driving force in how utterances come to have meaning. We first want to know how people extract meaning from others' communicative behavior. We then ask what are the elements of producers' formulation of communicative actions in anticipation of how others will interpret that behavior.},
	language = {eng},
	urldate = {2014-07-22},
	booktitle = {Embodied interaction: {Language} and body in the material world},
	author = {Enfield, N. J.},
	editor = {Streeck, Jürgen and Goodwin, C. and LeBaron, C.},
	year = {2011},
	pages = {59--66},
}

@inproceedings{powers_applications_1998,
	title = {Applications and {Explanations} of {Zipf}'s {Law}},
	url = {https://aclanthology.org/W98-1218},
	urldate = {2021-10-21},
	booktitle = {New {Methods} in {Language} {Processing} and {Computational} {Natural} {Language} {Learning}},
	author = {Powers, David M. W.},
	year = {1998},
}

@inproceedings{buschmeier_dynamic_2014,
	address = {Edinburgh, UK},
	title = {A {Dynamic} {Minimal} {Model} of the {Listener} for {Feedback}-based {Dialogue} {Coordination}},
	booktitle = {{SemDial} 2014: {Proceedings} of the 18th {Workshop} on the {Semantics} and {Pragmatics} of {Dialogue}},
	author = {Buschmeier, Hendrik and Kopp, Stefan},
	year = {2014},
	pages = {17--25},
}

@inproceedings{buschmeier_communicative_2018,
	title = {Communicative listener feedback in human–agent interaction: {Artificial} speakers need to be attentive and adaptive},
	shorttitle = {Communicative listener feedback in human–agent interaction},
	url = {https://pub.uni-bielefeld.de/publication/2916994},
	abstract = {In human dialogue, listener feedback is a pervasive phenomenon that serves important functions in the coordination of the conversation, both in regulating its flow, as well as in creating and ensuring understanding between interlocutors. This make feedback an interesting mechanism for conversational human–agent interaction. In this paper we describe computational models for an ‘attentive speaker’ agent that is able to (1) interpret the feedback behaviour of its human interlocutors by probabilistically attributing listening-related mental states to them; (2) incrementally adapt its ongoing language and behaviour generation to their needs; and (3) elicit feedback from them when needed. We present a semi-autonomous interaction study, in which we compare such an attentive speaker agent with agents that either do not adapt their behaviour to their listeners’ needs, or employ highly explicit ways of ensuring understanding. The results show that human interlocutors interacting with the attentive speaker agent provided significantly more listener feedback, felt that the agent was attentive to, and adaptive to their feedback, attested the agent a desire to be understood, and rated it more helpful in resolving difficulties in their understanding.},
	language = {eng},
	urldate = {2018-06-20},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}},
	author = {Buschmeier, Hendrik and Kopp, Stefan},
	year = {2018},
}

@inproceedings{buschmeier_alignment-capable_2009,
	address = {Stroudsburg, PA, USA},
	series = {{ENLG} '09},
	title = {An {Alignment}-capable {Microplanner} for {Natural} {Language} {Generation}},
	url = {http://dl.acm.org/citation.cfm?id=1610195.1610207},
	abstract = {Alignment of interlocutors is a well known psycholinguistic phenomenon of great relevance for dialogue systems in general and natural language generation in particular. In this paper, we present the alignment-capable microplanner SPUD prime. Using a priming-based model of interactive alignment, it is flexible enough to model the alignment behaviour of human speakers to a high degree. This will allow for further investigation of which parameters are important to model alignment and how the human--computer interaction changes when the computer aligns to its users.},
	urldate = {2018-05-15},
	booktitle = {Proceedings of the 12th {European} {Workshop} on {Natural} {Language} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Buschmeier, Hendrik and Bergmann, Kirsten and Kopp, Stefan},
	year = {2009},
	pages = {82--89},
}

@phdthesis{buschmeier_attentive_2018,
	title = {Attentive {Speaking}. {From} {Listener} {Feedback} to {Interactive} {Adaptation}},
	url = {https://pub.uni-bielefeld.de/publication/2918295},
	abstract = {Dialogue is an interactive endeavour in which participants jointly pursue the goal of reaching understanding. Since participants enter the interaction with their individual conceptualisation of the world and their idiosyncratic way of using language, understanding cannot, in general, be reached by exchanging messages that are encoded when speaking and decoded when listening. Instead, speakers need to design their communicative acts in such a way that listeners are likely able to infer what is meant. Listeners, in turn, need to provide evidence of their understanding in such a way that speakers can infer whether their communicative acts were successful. This is often an interactive and iterative process in which speakers and listeners work towards understanding by jointly coordinating their communicative acts through feedback and adaptation. Taking part in this interactive process requires dialogue participants to have ‘interactional intelligence’.

This conceptualisation of dialogue is rather uncommon in formal or technical approaches to dialogue modelling. This thesis argues that it may, nevertheless, be a promising research direction for these fields, because it de-emphasises raw language processing performance and focusses on fundamental interaction skills. Interactionally intelligent artificial conversational agents may thus be able to reach understanding with their interlocutors by drawing upon such competences. This will likely make them more robust, more understandable, more helpful, more effective, and more human-like.

This thesis develops conceptual and computational models of interactional intelligence for artificial conversational agents that are limited to (1) the speaking role, and (2) evidence of understanding in form of communicative listener feedback (short but expressive verbal/vocal signals, such as ‘okay’, ‘mhm’ and ‘huh’, head gestures, and gaze). This thesis argues that such ‘attentive speaker agents’ need to be able (1) to probabilistically reason about, infer, and represent their interlocutors’ listening related mental states (e.g., their degree of understanding), based on their interlocutors’ feedback behaviour; (2) to interactively adapt their language and behaviour such that their interlocutors’ needs, derived from the attributed mental states, are taken into account; and (3) to decide when they need feedback from their interlocutors and how they can elicit it using behavioural cues.This thesis describes computational models for these three processes, their integration in an incremental behaviour generation architecture for embodied conversational agents, and a semi-autonomous interaction study in which the resulting attentive speaker agent is evaluated.

The evaluation finds that the computational models of attentive speaking developed in this thesis enable conversational agents to interactively reach understanding with their human interlocutors (through feedback and adaptation) and that these interlocutors are willing to provide natural communicative listener feedback to such an attentive speaker agent. The thesis shows that computationally modelling interactional intelligence is generally feasible, and thereby raises many new research questions and engineering problems in the interdisciplinary fields of dialogue and artificial conversational agents.},
	urldate = {2018-11-05},
	author = {Buschmeier, Hendrik},
	year = {2018},
	note = {doi:10.4119/unibi/2918295},
}

@inproceedings{kopp_spreading-activation_2013,
	title = {A spreading-activation model of the semantic coordination of speech and gesture},
	abstract = {In naturally occurring speech and gesture, meaning occurs organized and distributed across the modalities in different ways. The underlying cognitive processes are largely unexplored. We propose a model based on activation spreading within dynamically shaped multimodal memories, in which coordination arises from the interplay of visuo-spatial and linguistically shaped representations under given communicative and cognitive resources. An implementation of this model is presented and ﬁrst simulation results are reported.},
	language = {en},
	booktitle = {Proceedings of the {Annual} {Meeting} of the {Cognitive} {Science} {Society}},
	author = {Kopp, Stefan and Bergmann, Kirsten and Kahl, Sebastian},
	year = {2013},
	pages = {7},
}

@incollection{kopp_modeling_2008,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Modeling {Embodied} {Feedback} with {Virtual} {Humans}},
	isbn = {978-3-540-79036-5 978-3-540-79037-2},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-79037-2_2},
	abstract = {In natural communication, both speakers and listeners are active most of the time. While a speaker contributes new information, a listener gives feedback by producing unobtrusive (usually short) vocal or non-vocal bodily expressions to indicate whether he/she is able and willing to communicate, perceive, and understand the information, and what emotions and attitudes are triggered by this information. The simulation of feedback behavior for artificial conversational agents poses big challenges such as the concurrent and integrated perception and production of multi-modal and multi-functional expressions. We present an approach on modeling feedback for and with virtual humans, based on an approach to study “embodied feedback” as a special case of a more general theoretical account of embodied communication. A realization of this approach with the virtual human Max is described and results are presented.},
	language = {en},
	urldate = {2017-10-17},
	booktitle = {Modeling {Communication} with {Robots} and {Virtual} {Humans}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Kopp, Stefan and Allwood, Jens and Grammer, Karl and Ahlsen, Elisabeth and Stocksmeier, Thorsten},
	year = {2008},
	doi = {10.1007/978-3-540-79037-2_2},
	pages = {18--37},
}

@article{kopp_social_2010,
	title = {Social resonance and embodied coordination in face-to-face conversation with artificial interlocutors},
	volume = {52},
	url = {http://www.sciencedirect.com/science/article/pii/S0167639310000312},
	number = {6},
	urldate = {2015-06-29},
	journal = {Speech Communication},
	author = {Kopp, Stefan},
	year = {2010},
	pages = {587--597},
}

@article{kopp_revisiting_2021,
	title = {Revisiting {Human}-{Agent} {Communication}: {The} {Importance} of {Joint} {Co}-construction and {Understanding} {Mental} {States}},
	volume = {12},
	issn = {1664-1078},
	shorttitle = {Revisiting {Human}-{Agent} {Communication}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2021.580955/full},
	doi = {10.3389/fpsyg.2021.580955},
	abstract = {The study of human-human communication and the development of computational models for human-agent communication have diverged significantly throughout the last decade. Yet, despite frequently made claims of “super-human performance” in, e.g., speech recognition or image processing, so far no system is able to lead a half-decent coherent conversation with a human. In this paper we argue that we must start to re-consider the hallmarks of cooperative communication and the core capabilities that we have developed for it, and which conversational agents need to be equipped with: incremental joint co-construction and mentalizing. We base our argument on a vast body of work on human-human communication and its psychological processes that we reason to be relevant and necessary to take into account when modeling human-agent communication. We contrast those with current conceptualizations of human-agent interaction and formulate suggestions for the development of future systems.},
	language = {English},
	urldate = {2021-04-12},
	journal = {Frontiers in Psychology},
	author = {Kopp, Stefan and Krämer, Nicole},
	year = {2021},
	note = {Publisher: Frontiers},
}

@incollection{wachsmuth_automatic_2013,
	address = {Amsterdam},
	title = {Automatic and strategic alignment of co-verbal gestures in dialogue},
	volume = {6},
	isbn = {978-90-272-0460-8 978-90-272-7103-7},
	url = {https://benjamins.com/catalog/ais.6.05kop},
	language = {en},
	urldate = {2018-11-12},
	booktitle = {Advances in {Interaction} {Studies}},
	publisher = {John Benjamins Publishing Company},
	author = {Kopp, Stefan and Bergmann, Kirsten},
	editor = {Wachsmuth, Ipke and de Ruiter, Jan and Jaecks, Petra and Kopp, Stefan},
	year = {2013},
	doi = {10.1075/ais.6.05kop},
	pages = {87--108},
}

@article{kendrick_sequence_2020,
	title = {Sequence organization: {A} universal infrastructure for social action},
	volume = {168},
	issn = {03782166},
	shorttitle = {Sequence organization},
	doi = {10.1016/j.pragma.2020.06.009},
	language = {en},
	journal = {Journal of Pragmatics},
	author = {Kendrick, Kobin H. and Brown, Penelope and Dingemanse, Mark and Floyd, Simeon and Gipper, Sonja and Hayano, Kaoru and Hoey, Elliott and Hoymann, Gertie and Manrique, Elizabeth and Rossi, Giovanni and Levinson, Stephen C.},
	month = oct,
	year = {2020},
	pages = {119--138},
}

@techreport{woon_creating_2021,
	title = {Creating a corpus of multilingual parent-child speech remotely: {Lessons} learned in a large-scale onscreen picturebook sharing task},
	shorttitle = {Creating a corpus of multilingual parent-child speech remotely},
	url = {https://psyarxiv.com/yeg6u/},
	abstract = {With lockdowns and social distancing measures in place, research teams looking to collect naturalistic parent-child speech interactions have to develop alternatives to in-lab recordings and observational studies with long-stretch recordings. We designed a novel micro-longitudinal study, the Talk Together Study, which allowed us to create a rich corpus of parent-child speech interactions in a fully online environment (N participants = 142, N recordings = 410. In this paper, we discuss the methods we used, and the lessons learned during adapting and running the study. These lessons learned cover 10 domains of research design, monitoring and feedback: Recruitment strategies, Surveys and Questionnaires, Video-call scheduling, Speech elicitation tools, Videocall protocols, Participant remuneration strategies, Project monitoring, Participant retention, Parental feedback, and Research team feedback, and may be used as a primer for teams planning to conduct remote studies in the future. (Substantive Revision: 2021 Sept 22; Minor corrections: 2021 Oct 5).},
	language = {en-us},
	urldate = {2021-10-20},
	institution = {PsyArXiv},
	author = {Woon, Fei Ting and Yogarrajah, Eshwaaree C. and Fong, Seraphina and Salleh, Nur Sakinah Mohd and Sundaray, Shamala and Styles, Suzy J.},
	month = jul,
	year = {2021},
	doi = {10.31234/osf.io/yeg6u},
	note = {type: article},
}

@incollection{dingemanse_conversation_2014,
	address = {Cambridge},
	title = {Conversation across cultures},
	booktitle = {Cambridge {Handbook} of {Linguistic} {Anthropology}},
	publisher = {Cambridge University Press},
	author = {Dingemanse, Mark and Floyd, Simeon},
	editor = {Enfield, N. J. and Kockelman, Paul and Sidnell, Jack},
	year = {2014},
	note = {doi:10.1017/CBO9781139342872.021},
	pages = {434--464},
}

@article{do_accounting_2021,
	title = {Accounting for lexical tones when modeling phonological distance},
	volume = {97},
	issn = {1535-0665},
	url = {https://muse.jhu.edu/article/785546},
	doi = {10.1353/lan.2021.0008},
	abstract = {Methods of quantifying distance between sound sequences are known as phonological distance measures. Despite the wide application across subfields, phonological distance has been calculated mainly with features related to consonants and vowels. This research report establishes new measurements of phonological distance that incorporate lexical tone through experimental approaches and modeling, using Hong Kong Cantonese as a case study. Results show correspondences between the experimental data and predictions from information-theoretic measures, including entropy measures and functional load, suggesting that lexical components which play a more crucial role in phonological distance judgments are lexically less predictable as well. Implications for phonological distance measures are discussed.},
	number = {1},
	urldate = {2021-10-20},
	journal = {Language},
	author = {Do, Youngah and Yau Lai, Ryan Ka},
	year = {2021},
	note = {Publisher: Linguistic Society of America},
	pages = {e39--e67},
}

@article{duran_align_2018,
	title = {{ALIGN}: {Analyzing} {Linguistic} {Interactions} with {Generalizable} {techNiques} - a {Python} {Library}},
	shorttitle = {{ALIGN}},
	url = {https://psyarxiv.com/a5yh9/},
	doi = {10.31234/osf.io/a5yh9},
	abstract = {Linguistic alignment (LA) is the tendency during a conversation to re-use each other’s linguistic expressions, including lexical, conceptual, or syntactic structures. LA is often argued to be a crucial driver in reciprocal understanding and interpersonal rapport, though its precise dynamics and effects are still controversial. One barrier to more systematic investigation of these effects lies in the diversity in the methods employed to analyze LA, which makes it difficult to integrate and compare results of individual studies. To overcome this issue, we have developed ALIGN (Analyzing Linguistic Interactions with Generalizable techNiques), an open-source Python package to measure LA in conversation (https://pypi.python.org/pypi/align) along with in-depth open-source tutorials hosted on ALIGN’s GitHub repository (https://github.com/nickduran/align-linguistic-alignment). Here, we first describe the challenges in the study of LA and outline how ALIGN can address them. We then demonstrate how our analytical protocol can be applied to theory-driven questions using a complex corpus of dialogue (the Devil’s Advocate corpus; Duran \& Fusaroli, 2017). We close by identifying further challenges and point to future developments of the field.},
	urldate = {2018-07-16},
	journal = {PsyArXiv},
	author = {Duran, Nicholas and Paxton, Alex and Fusaroli, Riccardo},
	month = feb,
	year = {2018},
}

@article{bryant_detecting_2016,
	title = {Detecting affiliation in colaughter across 24 societies},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/content/early/2016/04/05/1524993113},
	doi = {10.1073/pnas.1524993113},
	abstract = {Laughter is a nonverbal vocal expression that often communicates positive affect and cooperative intent in humans. Temporally coincident laughter occurring within groups is a potentially rich cue of affiliation to overhearers. We examined listeners’ judgments of affiliation based on brief, decontextualized instances of colaughter between either established friends or recently acquainted strangers. In a sample of 966 participants from 24 societies, people reliably distinguished friends from strangers with an accuracy of 53–67\%. Acoustic analyses of the individual laughter segments revealed that, across cultures, listeners’ judgments were consistently predicted by voicing dynamics, suggesting perceptual sensitivity to emotionally triggered spontaneous production. Colaughter affords rapid and accurate appraisals of affiliation that transcend cultural and linguistic boundaries, and may constitute a universal means of signaling cooperative relationships.},
	language = {en},
	urldate = {2016-04-13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bryant, Gregory A. and Fessler, Daniel M. T. and Fusaroli, Riccardo and Clint, Edward and Aarøe, Lene and Apicella, Coren L. and Petersen, Michael Bang and Bickham, Shaneikiah T. and Bolyanatz, Alexander and Chavez, Brenda and Smet, Delphine De and Díaz, Cinthya and Fančovičová, Jana and Fux, Michal and Giraldo-Perez, Paulina and Hu, Anning and Kamble, Shanmukh V. and Kameda, Tatsuya and Li, Norman P. and Luberti, Francesca R. and Prokop, Pavol and Quintelier, Katinka and Scelza, Brooke A. and Shin, Hyun Jung and Soler, Montserrat and Stieger, Stefan and Toyokawa, Wataru and Hende, Ellis A. van den and Viciana-Asensio, Hugo and Yildizhan, Saliha Elif and Yong, Jose C. and Yuditha, Tessa and Zhou, Yi},
	month = apr,
	year = {2016},
	pmid = {27071114},
	pages = {201524993},
}

@inproceedings{dideriksen_contextualizing_2019,
	address = {Montreal},
	title = {Contextualizing {Conversational} {Strategies}: {Backchannel}, {Repair} and {Linguistic} {Alignment} in {Spontaneous} and {Task}-{Oriented} {Conversations}},
	shorttitle = {Contextualizing {Conversational} {Strategies}},
	abstract = {Author: Dideriksen, Christina et al.; Genre: Conference Paper; Title: Contextualizing Conversational Strategies: Backchannel, Repair and Linguistic Alignment in Spontaneous and Task-Oriented Conversations},
	language = {eng},
	booktitle = {Proceedings of {CogSci} 2019},
	author = {Dideriksen, Christina and Fusaroli, Riccardo and Tylén, Kristian and Dingemanse, Mark and Christiansen, Morten H.},
	month = may,
	year = {2019},
	pages = {261--267},
}

@article{bjorndahl_agreeing_2015,
	title = {Agreeing is not enough: {The} constructive role of miscommunication},
	volume = {16},
	shorttitle = {Agreeing is not enough},
	doi = {10.1075/is.16.3.07fus},
	abstract = {Collaborative interaction pervades many everyday practices: work meetings, innovation and product design, education and arts. Previous studies have pointed to the central role of acknowledgement and acceptance for the success of joint action, by creating affiliation and signaling understanding. We argue that various forms of explicit miscommunication are just as critical to challenge, negotiate and integrate individual contributions in collaborative creative activities. Through qualitative microanalysis of spontaneous coordination in collective creative LEGO constructions, we individuate three interactional styles: inclusive, characterized by acknowledgment and praise; instructional, characterized by self-repair; and integrative, characterized by widespread self- and other-repair. We then investigate how different interaction styles leave distinct material traces in the resulting LEGO models. The inclusive interaction style generally results in concatenations of individual contributions with little coherence and core narrative. The instructional style produces coherent, but largely individually driven models. Finally, the integrative style generates more innovative models, synthesizing individual contributions in shared narratives or schemas.},
	number = {3},
	journal = {Interaction Studies},
	author = {Bjørndahl, Johanne Stege and Fusaroli, Riccardo and ∅stergaard, Svend and Tylén, Kristian},
	month = jan,
	year = {2015},
	pages = {495--525},
}

@article{fusaroli_carving_2012,
	title = {Carving language for social coordination: {A} dynamical approach},
	volume = {13},
	shorttitle = {Carving language for social coordination},
	doi = {10.1075/is.13.1.07fus},
	abstract = {Human social coordination is often mediated by language. Through verbal dialogue, people direct each other’s attention to properties of their shared environment, they discuss how to jointly solve problems, share their introspections, and distribute roles and assignments. In this article, we propose a dynamical framework for the study of the coordinative role of language. Based on a review of a number of recent experimental studies, we argue that shared symbolic patterns emerge and stabilize through a process of local reciprocal linguistic alignment. Such patterns in turn come to facilitate and refine social coordination by enabling the alignment, joint construction and navigation of conceptual models and actions. Implications of the framework are illustrated and discussed in relation to a case study where dyads of interlocutors interact verbally to reach joint decisions in a perceptual discrimination task. Keywords: social coordination; language; communication; linguistic alignment; symbolic patterns; affordances; emergence; evolution; adaptivity; interaction},
	number = {1},
	journal = {Interaction Studies},
	author = {Fusaroli, Riccardo and Tylén, Kristian},
	month = jan,
	year = {2012},
	pages = {103--124},
}

@article{fusaroli_dialogue_2013,
	title = {Dialogue as interpersonal synergy},
	journal = {New Ideas in Psychology},
	author = {Fusaroli, Riccardo and Rączaszek-Leonardi, J. and Tylén, Kristian},
	year = {2013},
}

@article{fusaroli_timescales_2015,
	title = {Timescales of {Massive} {Human} {Entrainment}},
	volume = {10},
	url = {http://dx.doi.org/10.1371/journal.pone.0122742},
	doi = {10.1371/journal.pone.0122742},
	abstract = {The past two decades have seen an upsurge of interest in the collective behaviors of complex systems composed of many agents entrained to each other and to external events. In this paper, we extend the concept of entrainment to the dynamics of human collective attention. We conducted a detailed investigation of the unfolding of human entrainment—as expressed by the content and patterns of hundreds of thousands of messages on Twitter—during the 2012 US presidential debates. By time-locking these data sources, we quantify the impact of the unfolding debate on human attention at three time scales. We show that collective social behavior covaries second-by-second to the interactional dynamics of the debates: A candidate speaking induces rapid increases in mentions of his name on social media and decreases in mentions of the other candidate. Moreover, interruptions by an interlocutor increase the attention received. We also highlight a distinct time scale for the impact of salient content during the debates: Across well-known remarks in each debate, mentions in social media start within 5–10 seconds after it occurs; peak at approximately one minute; and slowly decay in a consistent fashion across well-known events during the debates. Finally, we show that public attention after an initial burst slowly decays through the course of the debates. Thus we demonstrate that large-scale human entrainment may hold across a number of distinct scales, in an exquisitely time-locked fashion. The methods and results pave the way for careful study of the dynamics and mechanisms of large-scale human entrainment.},
	number = {4},
	urldate = {2015-05-05},
	journal = {PLoS ONE},
	author = {Fusaroli, Riccardo and Perlman, Marcus and Mislove, Alan and Paxton, Alexandra and Matlock, Teenie and Dale, Rick},
	month = apr,
	year = {2015},
	pages = {e0122742},
}

@inproceedings{fusaroli_measures_2017,
	address = {London},
	title = {Measures and mechanisms of common ground: backchannels, conversational repair, and interactive alignment in free and task-oriented social interactions},
	booktitle = {Proceedings of the 39th {Annual} {Meeting} of the {Cognitive} {Science} {Society}},
	author = {Fusaroli, Riccardo and Tylén, Kristian and Garly, Katrine and Steensig, Jakob and Christiansen, Morten H. and Dingemanse, Mark},
	editor = {Gunzelmann, G. and Howes, A. and Tenbrink, T. and Davelaar, E.},
	year = {2017},
	pages = {2055--2060},
}

@article{fusaroli_investigating_2015,
	title = {Investigating {Conversational} {Dynamics}: {Interactive} {Alignment}, {Interpersonal} {Synergy}, and {Collective} {Task} {Performance}},
	copyright = {© 2015 Cognitive Science Society, Inc.},
	issn = {1551-6709},
	shorttitle = {Investigating {Conversational} {Dynamics}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/cogs.12251/abstract},
	doi = {10.1111/cogs.12251},
	abstract = {This study investigates interpersonal processes underlying dialog by comparing two approaches, interactive alignment and interpersonal synergy, and assesses how they predict collective performance in a joint task. While the interactive alignment approach highlights imitative patterns between interlocutors, the synergy approach points to structural organization at the level of the interaction—such as complementary patterns straddling speech turns and interlocutors. We develop a general, quantitative method to assess lexical, prosodic, and speech/pause patterns related to the two approaches and their impact on collective performance in a corpus of task-oriented conversations. The results show statistical presence of patterns relevant for both approaches. However, synergetic aspects of dialog provide the best statistical predictors of collective performance and adding aspects of the alignment approach does not improve the model. This suggests that structural organization at the level of the interaction plays a crucial role in task-oriented conversations, possibly constraining and integrating processes related to alignment.},
	language = {en},
	urldate = {2015-05-19},
	journal = {Cognitive Science},
	author = {Fusaroli, Riccardo and Tylén, Kristian},
	month = may,
	year = {2015},
	pages = {n/a--n/a},
}

@inproceedings{qi_stanza_2020,
	title = {Stanza: {A} {Python} {Natural} {Language} {Processing} {Toolkit} for {Many} {Human} {Languages}},
	url = {https://nlp.stanford.edu/pubs/qi2020stanza.pdf},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {System} {Demonstrations}},
	author = {Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
	year = {2020},
}

@article{stivers_universals_2009,
	title = {Universals and cultural variation in turn-taking in conversation},
	volume = {106},
	issn = {0027-8424},
	url = {http://www.pnas.org/content/early/2009/06/23/0903616106},
	doi = {10.1073/pnas.0903616106},
	number = {26},
	urldate = {2009-09-29},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Stivers, Tanya and Enfield, N. J. and Brown, Penelope and Englert, C. and Hayashi, Makoto and Heinemann, Trine and Hoymann, Gertie and Rossano, Federico and de Ruiter, J. P. and Yoon, Kyung-Eun and Levinson, Stephen C.},
	month = jun,
	year = {2009},
	pages = {10587--10592},
}

@incollection{fenk_menzeraths_1993,
	address = {Dordrecht},
	title = {Menzerath’s {Law} and the {Constant} {Flow} of {Linguistic} {Information}},
	isbn = {978-94-011-1769-2},
	abstract = {Menzerath describes two regularities governing the relation between the number of syllables and the number of phonemes in German words. The interpretations given by Menzerath (1954) are aimed at what nowadays is called “cognitive economy”:},
	language = {en},
	booktitle = {Contributions to {Quantitative} {Linguistics}: {Proceedings} of the {First} {International} {Conference} on {Quantitative} {Linguistics}, {QUALICO}, {Trier}, 1991},
	publisher = {Springer Netherlands},
	author = {Fenk, August and Fenk-Oczlon, Gertraud},
	editor = {Köhler, Reinhard and Rieger, Burghard B.},
	year = {1993},
	doi = {10.1007/978-94-011-1769-2_2},
	pages = {11--31},
}

@incollection{fenk-oczlon_systemic_2004,
	address = {Moscow},
	title = {Systemic {Typology} and {Crosslinguistic} {Regularities}},
	booktitle = {Text {Processing} and {Cognitive} {Technologies}},
	publisher = {MISA},
	author = {Fenk-Oczlon, Gertraud and Fenk, August and Solovyev, V. and Polyakov, V.},
	year = {2004},
	pages = {229--234},
}

@article{fenk-oczlon_cognition_1999,
	title = {Cognition, quantitative linguistics, and systemic typology},
	volume = {3},
	issn = {1430-0532, 1613-415X},
	url = {http://www.reference-global.com/doi/abs/10.1515/lity.1999.3.2.151},
	doi = {10.1515/lity.1999.3.2.151},
	number = {2},
	urldate = {2011-12-13},
	journal = {Linguistic Typology},
	author = {Fenk-Oczlon, Gertraud and Fenk, August},
	month = jan,
	year = {1999},
	pages = {151--178},
}

@article{coupe_different_2019,
	title = {Different languages, similar encoding efficiency: {Comparable} information rates across the human communicative niche},
	journal = {Science Advances},
	author = {Coupé, Christophe and Oh, Yoon and Dediu, Dan and Pellegrino, François},
	year = {2019},
}

@article{clancy_conversational_1996,
	title = {The conversational use of reactive tokens in {English}, {Japanese}, and {Mandarin}},
	volume = {26},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/0378216695000364},
	doi = {10.1016/0378-2166(95)00036-4},
	abstract = {{\textless}p{\textgreater}{\textless}br/{\textgreater}This paper investigates [`]Reactive Tokens' in Mandarin Chinese, Japanese, and English. Our definition of [`]Reactive Token' (= [`]RT') is [`]a short utterance produced by an interlocutor who is playing a listener's role during the other interlocutor's speakership'. That is, Reactive Tokens will normally not disrupt the primary speaker's speakership, and do not in themselves claim the floor. Using corpora of conversational interactions from each of the three languages of our study, we distinguish among several types of RTs, and show that the three languages differ in terms of the types of RTs favored, the frequency with which RTs are used in conversation, and the way in which speakers distribute their RTs across conversational units.{\textless}/p{\textgreater}},
	number = {3},
	urldate = {2011-07-05},
	journal = {Journal of Pragmatics},
	author = {Clancy, Patricia M. and Thompson, Sandra A. and Suzuki, Ryoko and Tao, Hongyin},
	month = sep,
	year = {1996},
	pages = {355--387},
}

@article{kita_nodding_2007,
	series = {Nodding, {Aizuchi}, and {Final} {Particles} in {Japanese} {Conversation}},
	title = {Nodding, aizuchi, and final particles in {Japanese} conversation: {How} conversation reflects the ideology of communication and social relationships},
	volume = {39},
	issn = {0378-2166},
	shorttitle = {Nodding, aizuchi, and final particles in {Japanese} conversation},
	url = {http://www.sciencedirect.com/science/article/pii/S0378216607000495},
	doi = {10.1016/j.pragma.2007.02.009},
	abstract = {It has been noted that Japanese differs markedly from languages like English and Mandarin in the use of head nods and aizuchis (short utterances roughly equivalent to English “uh huh” and “yeah”). In Japanese conversation, such behaviors are extremely frequent, and their placement is often unexpected from the viewpoint of speakers of languages like English and Mandarin. For example, these behaviors often occur in non-transition relevant places. Sometimes aizuchis can even be uttered by the turn-holder. In such cases, the conventional technical terms such as “back-channel”, “continuer”, and “reactive token” are hardly applicable. Furthermore, the turn-holder often actively elicits aizuchis from the listener. Final particles, which are very frequent in spoken discourse, play an important role in the elicitation. Finally, there is a discussion of how the Japanese ideology of communication and social relationships may provide motivations for the above phenomena.},
	number = {7},
	urldate = {2017-10-04},
	journal = {Journal of Pragmatics},
	author = {Kita, Sotaro and Ide, Sachiko},
	month = jul,
	year = {2007},
	pages = {1242--1254},
}

@inproceedings{bender_climbing_2020,
	address = {Online},
	title = {Climbing towards {NLU}: {On} {Meaning}, {Form}, and {Understanding} in the {Age} of {Data}},
	shorttitle = {Climbing towards {NLU}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.463},
	doi = {10.18653/v1/2020.acl-main.463},
	abstract = {The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as “understanding” language or capturing “meaning”. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of “Taking Stock of Where We've Been and Where We're Going”, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.},
	urldate = {2021-03-09},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Bender, Emily M. and Koller, Alexander},
	month = jul,
	year = {2020},
	pages = {5185--5198},
}

@article{seibt_five_2018,
	title = {Five {Principles} of {Integrative} {Social} {Robotics}},
	url = {https://ebooks.iospress.nl/doi/10.3233/978-1-61499-931-7-28},
	doi = {10.3233/978-1-61499-931-7-28},
	urldate = {2021-10-14},
	journal = {Envisioning Robots in Society – Power, Politics, and Public Space},
	author = {Seibt, Johanna and Flensborg Damholdt, Malene and Vestergaard, Christina},
	year = {2018},
	note = {Publisher: IOS Press},
	pages = {28--42},
}

@incollection{seibt_classifying_2018,
	title = {Classifying {Forms} and {Modes} of {Co}-{Working} in the {Ontology} of {Asymmetric} {Social} {Interactions} ({OASIS})},
	booktitle = {Envisioning {Robots} in {Society} – {Power}, {Politics}, and {Public} {Space}},
	publisher = {IOS Press},
	author = {Seibt, Johanna},
	editor = {Coeckelbergh, M.},
	year = {2018},
	pages = {133--146},
}

@incollection{hakli_towards_2017,
	address = {Cham},
	title = {Towards an {Ontology} of {Simulated} {Social} {Interaction}: {Varieties} of the “{As} {If}” for {Robots} and {Humans}},
	isbn = {978-3-319-53131-1 978-3-319-53133-5},
	shorttitle = {Towards an {Ontology} of {Simulated} {Social} {Interaction}},
	url = {http://link.springer.com/10.1007/978-3-319-53133-5_2},
	language = {en},
	urldate = {2021-10-14},
	booktitle = {Sociality and {Normativity} for {Robots}},
	publisher = {Springer International Publishing},
	author = {Seibt, Johanna},
	editor = {Hakli, Raul and Seibt, Johanna},
	year = {2017},
	doi = {10.1007/978-3-319-53133-5_2},
	pages = {11--39},
}

@article{seibt_ontological_2015,
	title = {Ontological {Scope} and {Linguistic} {Diversity}: {Are} {There} {Universal} {Categories}?},
	volume = {98},
	issn = {0026-9662},
	shorttitle = {Ontological {Scope} and {Linguistic} {Diversity}},
	url = {https://doi.org/10.1093/monist/onv012},
	doi = {10.1093/monist/onv012},
	abstract = {The aim of this paper is to address a longstanding concern about the linguistic ‘relativity’ of ontological categories, and resulting limitations in the scope of ontological theories. Given recent evidence on the influence of language on cognitive dispositions, do we have empirical reasons to doubt that there are ontological categories that have universal scope across languages? I argue that this is the case, at least if we retain the standard ‘inferential’ approach within analytical ontology, i.e., if we evaluate ontological interpretations of L-sentences relative to certain material inferences in L. Research in linguistic typology suggests that types of entities postulated for the domain of Indo-European languages cannot capture the ontological commitments of the (much larger group of) non-Indo-European languages. Ontological category theory thus seems to have three options. The first option is to abandon the standard ‘inferential’ approach to ontological category theory. Alternatively, if we stay with the inferential approach, we face the following choice. Either ontology must let go of its ambitions to provide general domain descriptions for any language and settle for the more modest project of reconstructing the ontological commitments of a group of natural languages. Or else analytical ontologists should turn to linguistic typology in order to accommodate the diversity of inferential structures embedded in natural languages. I recommend and explore this third option, illustrating a strategy for how to construct a domain theory that can be used across languages. In a first step I show how linguistic research on the semantics of verbs and nouns (studies on so-called “Aktionsarten” and “Seinsarten”) can be used to identify the inferential patterns of ten basic concepts of modes of existence in time and space. In a second step I show how these inferential data can be interpreted ontologically within General Process Theory, an ontological framework based on nonparticular individuals (“dynamics”).},
	number = {3},
	urldate = {2021-10-14},
	journal = {The Monist},
	author = {Seibt, Johanna},
	month = jul,
	year = {2015},
	pages = {318--343},
}

@article{seibt_integrative_2020,
	title = {Integrative social robotics, value-driven design, and transdisciplinarity},
	volume = {21},
	issn = {1572-0373, 1572-0381},
	url = {https://www.jbe-platform.com/content/journals/10.1075/is.18061.sei},
	doi = {10.1075/is.18061.sei},
	abstract = {Abstract “Integrative Social Robotics” (ISR) is a new approach or general method for generating social robotics applications in a responsible and “culturally sustainable” fashion. Currently social robotics is caught in a basic difficulty we call the “triple gridlock of description, evaluation, and regulation”. We briefly recapitulate this problem and then present the core ideas of ISR in the form of five principles that should guide the development of applications in social robotics. Characteristic of ISR is to intertwine a mixed method approach (i.e., conducting experimental, quantitative, qualitative, and phenomenological research for the same envisaged application) with conceptual and axiological analysis as required in professional studies in applied ethics; moreover, ISR is value-driven and abides by the “Non-Replacement Principle”: Social robots may only do what humans should but cannot do. We briefly compare ISR to other value-sensitive or value-directed design models, with a view to the task of overcoming the triple gridlock. Finally, working from an advanced classification of pluridiscplinary research, we argue that ISR establishes a research format that can turn social robotics into a new transdiscipline.},
	language = {en},
	number = {1},
	urldate = {2021-10-14},
	journal = {Interaction Studies},
	author = {Seibt, Johanna and Damholdt, Malene Flensborg and Vestergaard, Christina},
	month = jan,
	year = {2020},
	note = {Publisher: John Benjamins},
	pages = {111--144},
}

@article{seibt_complexity_2021,
	title = {The {Complexity} of {Human} {Social} {Interactions} {Calls} for {Mixed} {Methods} in {HRI}: {Comment} on '{A} {Primer} for {Conducting} {Experiments} in {Human}-robot {Interaction}' by {G}. {Hoffman} and {X}. {Zhao}},
	volume = {10},
	shorttitle = {The {Complexity} of {Human} {Social} {Interactions} {Calls} for {Mixed} {Methods} in {HRI}},
	url = {https://doi.org/10.1145/3439715},
	doi = {10.1145/3439715},
	abstract = {In this research note, we offer a comment on the “A Primer for Conducting Experiments in Human-robot Interaction,” by G. Hoffman and X. Zhao, suggesting that due to the complexity of human social reality quantitative methods should be integrated into a mixed method approach.},
	number = {1},
	urldate = {2021-10-14},
	journal = {ACM Transactions on Human-Robot Interaction},
	author = {Seibt, Johanna and Vestergaard, Christina and Damholdt, Malene F.},
	month = feb,
	year = {2021},
	pages = {10:1--10:4},
}

@article{kovac_socialai_2021,
	title = {{SocialAI}: {Benchmarking} {Socio}-{Cognitive} {Abilities} in {Deep} {Reinforcement} {Learning} {Agents}},
	shorttitle = {{SocialAI}},
	url = {http://arxiv.org/abs/2107.00956},
	abstract = {Building embodied autonomous agents capable of participating in social interactions with humans is one of the main challenges in AI. Within the Deep Reinforcement Learning (DRL) field, this objective motivated multiple works on embodied language use. However, current approaches focus on language as a communication tool in very simplified and non-diverse social situations: the "naturalness" of language is reduced to the concept of high vocabulary size and variability. In this paper, we argue that aiming towards human-level AI requires a broader set of key social skills: 1) language use in complex and variable social contexts; 2) beyond language, complex embodied communication in multimodal settings within constantly evolving social worlds. We explain how concepts from cognitive sciences could help AI to draw a roadmap towards human-like intelligence, with a focus on its social dimensions. As a first step, we propose to expand current research to a broader set of core social skills. To do this, we present SocialAI, a benchmark to assess the acquisition of social skills of DRL agents using multiple grid-world environments featuring other (scripted) social agents. We then study the limits of a recent SOTA DRL approach when tested on SocialAI and discuss important next steps towards proficient social agents. Videos and code are available at https://sites.google.com/view/socialai.},
	urldate = {2021-10-14},
	journal = {arXiv:2107.00956 [cs]},
	author = {Kovač, Grgur and Portelas, Rémy and Hofmann, Katja and Oudeyer, Pierre-Yves},
	month = sep,
	year = {2021},
	note = {arXiv: 2107.00956},
}

@inproceedings{mcclelland_are_2021,
	title = {Are people still smarter than machines? {If} so, why?},
	volume = {43},
	shorttitle = {Are people still smarter than machines?},
	booktitle = {Proceedings of the {Annual} {Meeting} of the {Cognitive} {Science} {Society}},
	author = {McClelland, Jay},
	year = {2021},
	note = {Issue: 43},
}

@article{abramson_imitating_2020,
	title = {Imitating interactive intelligence},
	journal = {arXiv preprint arXiv:2012.05672},
	author = {Abramson, Josh and Ahuja, Arun and Barr, Iain and Brussee, Arthur and Carnevale, Federico and Cassin, Mary and Chhaparia, Rachita and Clark, Stephen and Damoc, Bogdan and Dudzik, Andrew},
	year = {2020},
}

@article{altmann_sociobiology_1965,
	title = {Sociobiology of rhesus monkeys. {II}: {Stochastics} of social communication},
	volume = {8},
	issn = {0022-5193},
	shorttitle = {Sociobiology of rhesus monkeys. {II}},
	url = {https://www.sciencedirect.com/science/article/pii/002251936590024X},
	doi = {10.1016/0022-5193(65)90024-X},
	abstract = {The behaviour of an individual depends upon preceding actions within the individual's interacting group. Such antecedent events do not, however, completely determine present behaviour. Rather, probabilistic constraints exist between events within a sequence of actions. Such sequential dependencies between the actions of group members indicate that social communication is taking place. These communicative constraints in sequences of behaviour may be represented by stochastic processes. The sequential constraints in the social communication of rhesus monkeys are given in a series of stochastic models that specify the probabilities of all events and all sequences of events. Estimates of these probabilities were obtained during a two-year field study of rhesus monkeys on Cayo Santiago, an island in the West Indies. Each model considers the constraints from an earlier antecedent than did the last model in the series. Thus, each model forms the null hypothesis for the next one, and is replaced by it because the new model reduces the uncertainty of our predictions of behaviour. This uncertainty is measured, using a method developed in the mathematical theory of communication. This measurement readily leads to several related ones, including an index of behavioural stereotypy. The results are consistent with the theory that rhesus monkeys base their social behaviour upon their memory for preceding events in their social group, and that this memory extends back beyond the immediately antecedent event. The behaviour of the monkeys, considered as isolated events, had an uncertainty of 4·8 bits, out of 6·9 bits maximum for a species with a repertoire of 120 behaviour patterns. Approximately 1·9 bits of information were picked up by the monkeys from the immediately antecedent behaviour in their social group, thus reducing the uncertainty of their behaviour to 2·9 bits. Further reductions resulted from information from still-earlier events in their social group, although the influences of such long-term constraints on behaviour were progressively more difficult to estimate. As a result of these stochastic contingencies, it was possible to measure the degree of stereotypy of the monkeys' behaviour. The index of stereotypy had a value of 0·3 for isolated events, 0·6 for events considering just the immediate antecedent behaviour in the group, and higher values for longer sequences. The development of such probabilistic models involved several sources of error and certain implicit assumptions. They should not be used without cognizance of these limitations. When properly used, however, they should enable one to predict the social behaviour of rhesus monkeys with a far greater accuracy than has previously been possible.},
	language = {en},
	number = {3},
	urldate = {2021-10-08},
	journal = {Journal of Theoretical Biology},
	author = {Altmann, Stuart A.},
	month = may,
	year = {1965},
	pages = {490--522},
}

@incollection{hendriksen_lstm_2021,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {{LSTM} for {Dialogue} {Breakdown} {Detection}: {Exploration} of {Different} {Model} {Types} and {Word} {Embeddings}},
	isbn = {9789811593239},
	shorttitle = {{LSTM} for {Dialogue} {Breakdown} {Detection}},
	url = {https://doi.org/10.1007/978-981-15-9323-9_41},
	abstract = {One of the principal problems of human-computer interaction is miscommunication. Occurring mainly on behalf of the dialogue system, miscommunication can lead to dialogue breakdown, i.e., a point when the dialogue cannot be continued. Detecting breakdown can facilitate its prevention or recovery after breakdown occurred. In the paper, we propose a multinomial sequence classifier for dialogue breakdown detection. We explore several LSTM models each different in terms of model type and word embedding models they use. We select our best performing model and compare it with the performance of the best model and with the majority baseline from the previous challenge. We conclude that our detector outperforms the baselines during the offline testing.},
	language = {en},
	urldate = {2021-10-11},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}: 10th {International} {Workshop} on {Spoken} {Dialogue} {Systems}},
	publisher = {Springer},
	author = {Hendriksen, Mariya and Leeuwenberg, Artuur and Moens, Marie-Francine},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_41},
	pages = {443--453},
}

@incollection{higashinaka_overview_2021,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Overview of the {Dialogue} {Breakdown} {Detection} {Challenge} 4},
	isbn = {9789811593239},
	url = {https://doi.org/10.1007/978-981-15-9323-9_38},
	abstract = {To promote the research and development of dialogue breakdown detection for dialogue systems, we have been organizing a series of dialogue breakdown detection challenges to detect a system’s inappropriate utterances that lead to dialogue breakdowns in chat-oriented dialogue. In this paper, we overview Dialogue Breakdown Detection Challenge 4 (DBDC4). As in the previous challenges, we used datasets in English and Japanese. Four teams participated in the challenge, in which all four teams worked on English, and two of the four teams worked on Japanese as well. This paper describes the task setting, evaluation metrics, and datasets for the challenge and the results of the submitted runs of the participants.},
	language = {en},
	urldate = {2021-10-11},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}: 10th {International} {Workshop} on {Spoken} {Dialogue} {Systems}},
	publisher = {Springer},
	author = {Higashinaka, Ryuichiro and D’Haro, Luis F. and Abu Shawar, Bayan and Banchs, Rafael E. and Funakoshi, Kotaro and Inaba, Michimasa and Tsunomori, Yuiko and Takahashi, Tetsuro and Sedoc, João},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_38},
	pages = {403--417},
}

@incollection{marchi_predicting_2021,
	address = {Singapore},
	title = {Predicting {Laughter} {Relevance} {Spaces} in {Dialogue}},
	volume = {714},
	isbn = {9789811593222 9789811593239},
	url = {http://link.springer.com/10.1007/978-981-15-9323-9_4},
	language = {en},
	urldate = {2021-10-11},
	booktitle = {Increasing {Naturalness} and {Flexibility} in {Spoken} {Dialogue} {Interaction}},
	publisher = {Springer Singapore},
	author = {Maraev, Vladislav and Howes, Christine and Bernardy, Jean-Philippe},
	editor = {Marchi, Erik and Siniscalchi, Sabato Marco and Cumani, Sandro and Salerno, Valerio Mario and Li, Haizhou},
	year = {2021},
	doi = {10.1007/978-981-15-9323-9_4},
	note = {Series Title: Lecture Notes in Electrical Engineering},
	pages = {41--51},
}

@inproceedings{higashinaka_towards_2015,
	address = {Prague, Czech Republic},
	title = {Towards {Taxonomy} of {Errors} in {Chat}-oriented {Dialogue} {Systems}},
	url = {https://aclanthology.org/W15-4611},
	doi = {10.18653/v1/W15-4611},
	urldate = {2021-10-11},
	booktitle = {Proceedings of the 16th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Higashinaka, Ryuichiro and Funakoshi, Kotaro and Araki, Masahiro and Tsukahara, Hiroshi and Kobayashi, Yuka and Mizukami, Masahiro},
	month = sep,
	year = {2015},
	pages = {87--95},
}

@inproceedings{zhang_interaction_2017,
	address = {New York, NY, USA},
	series = {{CHI} '17},
	title = {Interaction {Proxies} for {Runtime} {Repair} and {Enhancement} of {Mobile} {Application} {Accessibility}},
	isbn = {978-1-4503-4655-9},
	url = {https://doi.org/10.1145/3025453.3025846},
	doi = {10.1145/3025453.3025846},
	abstract = {We introduce interaction proxies as a strategy for runtime repair and enhancement of the accessibility of mobile applications. Conceptually, interaction proxies are inserted between an application's original interface and the manifest interface that a person uses to perceive and manipulate the application. This strategy allows third-party developers and researchers to modify an interaction without an application's source code, without rooting the phone, without otherwise modifying an application, while retaining all capabilities of the system (e.g., Android's full implementation of the TalkBack screen reader). This paper introduces interaction proxies, defines a design space of interaction re-mappings, identifies necessary implementation abstractions, presents details of implementing those abstractions in Android, and demonstrates a set of Android implementations of interaction proxies from throughout our design space. We then present a set of interviews with blind and low-vision people interacting with our prototype interaction proxies, using these interviews to explore the seamlessness of interaction, the perceived usefulness and potential of interaction proxies, and visions of how such enhancements could gain broad usage. By allowing third-party developers and researchers to improve an interaction, interaction proxies offer a new approach to personalizing mobile application accessibility and a new approach to catalyzing development, deployment, and evaluation of mobile accessibility enhancements.},
	urldate = {2021-10-11},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Xiaoyi and Ross, Anne Spencer and Caspi, Anat and Fogarty, James and Wobbrock, Jacob O.},
	month = may,
	year = {2017},
	pages = {6024--6037},
}

@book{raudaskoski_relevance_1991,
	title = {The {Relevance} of {Repair} for {Self} {Explicating} {Artifacts}},
	abstract = {An in-progress interdisciplinary research effort, Conversation Analytic (CA) and Human-Computer Interaction (HCI) study, is reported. A conversation analytic approach to repair and self-explication is taken that covers both human studies and artificial intelligence. The term "human" is used here in place of "linguistic." Three definitions of "repair" are given to show how artificial intelligence, discourse analysis, and conversational analysis compare. Some results are reported of empirical investigations of Finnish sign language, computer interfaces in general, and a special case of a telephone computer dialogue system. The study to date indicates that the whole concept of repair work needs to be analyzed carefully in order to sort out the subcategories. Contains 9 references.  (LB)},
	language = {en},
	urldate = {2021-10-11},
	author = {Raudaskoski, Pirkko},
	year = {1991},
}

@misc{bosse_sociale_2019,
	title = {Sociale kunstmatige intelligentie},
	url = {https://repository.ubn.ru.nl/handle/2066/200202},
	abstract = {Inaugural address RU, 18 januari 2019},
	language = {Dutch (dut)},
	urldate = {2021-10-11},
	author = {Bosse, T.},
	year = {2019},
	note = {Accepted: 2019-01-24T21:59:40Z
Publisher: Nijmegen : Radboud Universiteit},
}

@book{sigchi_group__us_acm_1992,
	address = {New York},
	title = {{ACM} {SIGCHI} curricula for human-computer interaction},
	isbn = {978-0-89791-474-1},
	language = {en},
	publisher = {Association for Computing Machinery},
	editor = {SIGCHI (Group : U.S.)},
	year = {1992},
}

@inproceedings{mcnew_towards_2018,
	address = {Miyazaki, Japan},
	title = {Towards faithfully visualizing global linguistic diversity},
	url = {https://aclanthology.org/L18-1129},
	urldate = {2021-10-11},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {McNew, Garland and Derungs, Curdin and Moran, Steven},
	month = may,
	year = {2018},
}

@inproceedings{steinfeld_common_2006,
	address = {Salt Lake City, Utah, USA},
	title = {Common metrics for human-robot interaction},
	isbn = {978-1-59593-294-5},
	url = {http://portal.acm.org/citation.cfm?doid=1121241.1121249},
	doi = {10.1145/1121241.1121249},
	abstract = {This paper describes an effort to identify common metrics for task-oriented human-robot interaction (HRI). We begin by discussing the need for a toolkit of HRI metrics. We then describe the framework of our work and identify important biasing factors that must be taken into consideration. Finally, we present suggested common metrics for standardization and a case study. Preparation of a larger, more detailed toolkit is in progress.},
	language = {en},
	urldate = {2021-10-11},
	booktitle = {Proceeding of the 1st {ACM} {SIGCHI}/{SIGART} conference on {Human}-robot interaction  - {HRI} '06},
	publisher = {ACM Press},
	author = {Steinfeld, Aaron and Fong, Terrence and Kaber, David and Lewis, Michael and Scholtz, Jean and Schultz, Alan and Goodrich, Michael},
	year = {2006},
	pages = {33},
}

@article{boumans_quality_2020,
	title = {Quality of {Care} {Perceived} by {Older} {Patients} and {Caregivers} in {Integrated} {Care} {Pathways} {With} {Interviewing} {Assistance} {From} a {Social} {Robot}: {Noninferiority} {Randomized} {Controlled} {Trial}},
	volume = {22},
	shorttitle = {Quality of {Care} {Perceived} by {Older} {Patients} and {Caregivers} in {Integrated} {Care} {Pathways} {With} {Interviewing} {Assistance} {From} a {Social} {Robot}},
	url = {https://www.jmir.org/2020/9/e18787},
	doi = {10.2196/18787},
	abstract = {Background: Society is facing a global shortage of 17 million health care workers, along with increasing health care demands from a growing number of older adults. Social robots are being considered as solutions to part of this problem.
Objective: Our objective is to evaluate the quality of care perceived by patients and caregivers for an integrated care pathway in an outpatient clinic using a social robot for patient-reported outcome measure (PROM) interviews versus the currently used professional interviews.
Methods: A multicenter, two-parallel-group, nonblinded, randomized controlled trial was used to test for noninferiority of the quality of care delivered through robot-assisted care. The randomization was performed using a computer-generated table. The setting consisted of two outpatient clinics, and the study took place from July to December 2019. Of 419 patients who visited the participating outpatient clinics, 110 older patients met the criteria for recruitment. Inclusion criteria were the ability to speak and read Dutch and being assisted by a participating health care professional. Exclusion criteria were serious hearing or vision problems, serious cognitive problems, and paranoia or similar psychiatric problems. The intervention consisted of a social robot conducting a 36-item PROM. As the main outcome measure, the customized Consumer Quality Index (CQI) was used, as reported by patients and caregivers for the outpatient pathway of care.
Results: In total, 75 intermediately frail older patients were included in the study, randomly assigned to the intervention and control groups, and processed: 36 female (48\%) and 39 male (52\%); mean age 77.4 years (SD 7.3), range 60-91 years. There was no significant difference in the total patient CQI scores between the patients included in the robot-assisted care pathway (mean 9.27, SD 0.65, n=37) and those in the control group (mean 9.00, SD 0.70, n=38): P=.08, 95\% CI –0.04 to 0.58. There was no significant difference in the total CQI scores between caregivers in the intervention group (mean 9.21, SD 0.76, n=30) and those in the control group (mean 9.09, SD 0.60, n=35): P=.47, 95\% CI –0.21 to 0.46. No harm or unintended effects occurred.
Conclusions: Geriatric patients and their informal caregivers valued robot-assisted and nonrobot-assisted care pathways equally.
Trial Registration: ClinicalTrials.gov NCT03857789; https://clinicaltrials.gov/ct2/show/NCT03857789},
	language = {EN},
	number = {9},
	urldate = {2021-10-11},
	journal = {Journal of Medical Internet Research},
	author = {Boumans, Roel and Meulen, Fokke van and Aalst, William van and Albers, Joyce and Janssen, Marèse and Peters-Kop, Marieke and Waal, Getty Huisman-de and Poll, Alexandra van de and Hindriks, Koen and Neerincx, Mark and Rikkert, Marcel Olde},
	month = sep,
	year = {2020},
	note = {Company: Journal of Medical Internet Research
Distributor: Journal of Medical Internet Research
Institution: Journal of Medical Internet Research
Label: Journal of Medical Internet Research
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e18787},
}

@article{boumans_feasibility_2020,
	title = {A {Feasibility} {Study} of a {Social} {Robot} {Collecting} {Patient} {Reported} {Outcome} {Measurements} from {Older} {Adults}},
	volume = {12},
	issn = {1875-4805},
	url = {https://doi.org/10.1007/s12369-019-00561-8},
	doi = {10.1007/s12369-019-00561-8},
	abstract = {Patient reported outcome measures (PROMs) are an essential means for collecting information on the effectiveness of hospital care as perceived by the patients themselves. Especially older adult patients often require help from nursing staff to successfully complete PROMs, but this staff already has a high work load. Therefore, a social robot is introduced to perform the PROM questioning and recording task. The study objective was to design a multimodal dialogue for a social robot to acquire PROMs for older patients. The primary outcomes were the effectiveness, the efficiency, and the subjective usability as perceived by older adults of acquiring PROMs by a social robot. The robot dialogue design included a personalized welcome, PROM questions, confirmation requests, affective statements, use of a support screen on the robot displaying the answer options, and accompanying robot gestures. The design was tested in a crossover study with 31 community-dwelling persons aged 70 years or above. Answers obtained with the robot were compared with those obtained by a questionnaire taken by humans. First results indicated that PROM data collection in older persons may be carried out effectively and efficiently by a social robot. The robot’s subjective usability was on average scored as 80.1 (± 11.6) on a scale from 0 to 100. The recorded data reliability was 99.6\%. A first relevant step has been made on the design trajectory for a robot to obtain PROMs from older adults. Practice variation in subjective usability scores still asks for technical dialogue improvements.},
	language = {en},
	number = {1},
	urldate = {2021-10-11},
	journal = {International Journal of Social Robotics},
	author = {Boumans, Roel and van Meulen, Fokke and Hindriks, Koen and Neerincx, Mark and Olde Rikkert, Marcel},
	month = jan,
	year = {2020},
	pages = {259--266},
}

@inproceedings{bouma_expletives_2018,
	address = {Brussels, Belgium},
	title = {Expletives in {Universal} {Dependency} {Treebanks}},
	url = {https://aclanthology.org/W18-6003},
	doi = {10.18653/v1/W18-6003},
	abstract = {Although treebanks annotated according to the guidelines of Universal Dependencies (UD) now exist for many languages, the goal of annotating the same phenomena in a cross-linguistically consistent fashion is not always met. In this paper, we investigate one phenomenon where we believe such consistency is lacking, namely expletive elements. Such elements occupy a position that is structurally associated with a core argument (or sometimes an oblique dependent), yet are non-referential and semantically void. Many UD treebanks identify at least some elements as expletive, but the range of phenomena differs between treebanks, even for closely related languages, and sometimes even for different treebanks for the same language. In this paper, we present criteria for identifying expletives that are applicable across languages and compatible with the goals of UD, give an overview of expletives as found in current UD treebanks, and present recommendations for the annotation of expletives so that more consistent annotation can be achieved in future releases.},
	urldate = {2021-10-11},
	booktitle = {Proceedings of the {Second} {Workshop} on {Universal} {Dependencies} ({UDW} 2018)},
	publisher = {Association for Computational Linguistics},
	author = {Bouma, Gosse and Hajic, Jan and Haug, Dag and Nivre, Joakim and Solberg, Per Erik and Øvrelid, Lilja},
	month = nov,
	year = {2018},
	pages = {18--26},
}

@article{nijssen_we_2021,
	title = {Do {We} {Take} a {Robot}'s {Needs} into {Account}? {The} {Effect} of {Humanization} on {Prosocial} {Considerations} {Toward} {Other} {Human} {Beings} and {Robots}},
	volume = {24},
	issn = {2152-2715},
	shorttitle = {Do {We} {Take} a {Robot}'s {Needs} into {Account}?},
	url = {https://www.liebertpub.com/doi/10.1089/cyber.2020.0035},
	doi = {10.1089/cyber.2020.0035},
	abstract = {Robots are becoming an integral part of society, yet the extent to which we are prosocial toward these nonliving objects is unclear. While previous research shows that we tend to take care of robots in high-risk, high-consequence situations, this has not been investigated in more day-to-day, low-consequence situations. Thus, we utilized an experimental paradigm (the Social Mindfulness “SoMi” paradigm) that involved a trade-off between participants' own interests and their willingness to take their task partner's needs into account. In two experiments, we investigated whether participants would take the needs of a robotic task partner into account to the same extent as when the task partner was a human (Study I), and whether this was modulated by participant's anthropomorphic attributions to said robot (Study II). In Study I, participants were presented with a social decision-making task, which they performed once by themselves (solo context) and once with a task partner (either a human or a robot). Subsequently, in Study II, participants performed the same task, but this time with both a human and a robotic task partner. The task partners were introduced via neutral or anthropomorphic priming stories. Results indicate that the effect of humanizing a task partner indeed increases our tendency to take someone else's needs into account in a social decision-making task. However, this effect was only found for a human task partner, not for a robot. Thus, while anthropomorphizing a robot may lead us to save it when it is about to perish, it does not make us more socially considerate of it in day-to-day situations.},
	number = {5},
	urldate = {2021-10-11},
	journal = {Cyberpsychology, Behavior, and Social Networking},
	author = {Nijssen, Sari R.R. and Heyselaar, Evelien and Müller, Barbara C.N. and Bosse, Tibor},
	month = may,
	year = {2021},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	pages = {332--336},
}

@inproceedings{heyselaar_linking_2021,
	address = {New York, NY, USA},
	series = {{IVA} '21},
	title = {Linking {Theory} of {Mind} in {Human}-{Agent} {Interactions} to {Validated} {Evaluations}: {Can} {Explicit} {Questionnaires} {Measure} {Implicit} {Behaviour}?},
	isbn = {978-1-4503-8619-7},
	shorttitle = {Linking {Theory} of {Mind} in {Human}-{Agent} {Interactions} to {Validated} {Evaluations}},
	url = {https://doi.org/10.1145/3472306.3478343},
	doi = {10.1145/3472306.3478343},
	abstract = {There is a new crisis emerging in human-agent interaction research: Instead of using validated questionnaires, individual studies are creating new questionnaires that claim to measure identical constructs. This makes replication studies and comparisons between studies near to impossible. In turn, meta-analyses to determine which characteristics are important to create agents that the user experiences as being intelligent are difficult to conduct. As part of the attempt to battle this crisis, in this current paper, we suggest the use of a Theory of Mind task to measure the implicit social behaviour users exhibit towards a virtual agent. In a two-part study, we present findings that suggest that participants conduct this Theory of Mind task as expected: participants adapt towards our virtual agent more than when they conduct the task alone. We additionally present preliminary results correlating performance in the Theory of Mind task to validated constructs. Unfortunately, our current results do not correlate significantly to the existing constructs. Data-collection is ongoing and hence no firm conclusions can be made about this second set of results. However, our data suggest that it is important to become aware that the existing validated constructs used in HCI research may not be tapping into what the researchers assume, and hence provide a basis for important discussions about these implications.},
	urldate = {2021-10-11},
	booktitle = {Proceedings of the 21st {ACM} {International} {Conference} on {Intelligent} {Virtual} {Agents}},
	publisher = {Association for Computing Machinery},
	author = {Heyselaar, Evelien and Bosse, Tibor},
	month = sep,
	year = {2021},
	pages = {120--127},
}

@article{bosse_language_2007,
	title = {A language and environment for analysis of dynamics by simulation},
	volume = {16},
	issn = {0218-2130},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0218213007003357},
	doi = {10.1142/S0218213007003357},
	abstract = {This article presents the language and software environment LEADSTO that has been developed to model and simulate dynamic processes in terms of both qualitative and quantitative concepts. The LEADSTO language is a declarative order-sorted temporal language, extended with quantitative notions like integer and real. Dynamic processes can be modelled in LEADSTO by specifying the direct temporal dependencies between state properties in successive states. Based on the LEADSTO language, a software environment was developed that performs simulations of LEADSTO specifications, generates data-files containing traces of simulation for further analysis, and constructs visual representations of traces. The approach proved its worth in a number of research projects in different domains.},
	number = {03},
	urldate = {2021-10-11},
	journal = {International Journal on Artificial Intelligence Tools},
	author = {Bosse, Tibor and Jonker, Catholijn M. and Van Der Meij, Lourens and Treur, Jan},
	month = jun,
	year = {2007},
	note = {Publisher: World Scientific Publishing Co.},
	pages = {435--464},
}

@article{norrick_interjections_2009,
	series = {Pragmatic {Markers}},
	title = {Interjections as pragmatic markers},
	volume = {41},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/S0378216608001859},
	doi = {10.1016/j.pragma.2008.08.005},
	abstract = {Interjections in everyday talk routinely function as pragmatic markers, initiating utterances and relating them to the foregoing interaction. In turn-initial position, one finds both primary interjections like oh and mhm and secondary interjections like wow and boy. Much of the interactional significance of primary interjections derives from their characteristic position as turn initiators, and much of their meaning in any particular case depends on their intonation contour. Particularly secondary interjections display a range of functions, first acting as parallel pragmatic markers, but also in functions beyond parallel markers, namely with typical discourse marker functions of signaling contrast, elaboration and transition. On the basis of several large corpora of English conversation, this paper seeks to demonstrate the open-ended nature of the class of interjections, which apparently accepts an unlimited number of new items. Despite their variability, the pragmatic functions of ever new interjections seem always to be clear to participants in the concrete context. Interjections represent a large, potentially infinitely extendable class of items, unlike the relatively circumscribed, closed classes of other pragmatic markers, and their pragmatic marker functions follow from their general status as expressions of shifts in cognitive states of various kinds. Thus, I argue in favor of considering interjections a sui generis class with recurrent pragmatic functions, and seek to explain their pragmatic characteristics as far as possible in universal terms.},
	number = {5},
	urldate = {2018-05-31},
	journal = {Journal of Pragmatics},
	author = {Norrick, Neal R.},
	month = may,
	year = {2009},
	pages = {866--891},
}

@article{norrick_using_2008,
	title = {Using large corpora of conversation to investigate narrative: {The} case of interjections in conversational storytelling performance},
	volume = {13},
	issn = {1384-6655, 1569-9811},
	shorttitle = {Using large corpora of conversation to investigate narrative},
	url = {http://www.jbe-platform.com/content/journals/10.1075/ijcl.13.4.03nor},
	doi = {10.1075/ijcl.13.4.03nor},
	language = {en},
	number = {4},
	urldate = {2015-04-13},
	journal = {International Journal of Corpus Linguistics},
	author = {Norrick, Neal R.},
	year = {2008},
	pages = {438--464},
}

@article{hirst_does_1991,
	title = {Does {Conversation} {Analysis} {Have} a {Role} in {Computational} {Linguistics}?},
	volume = {17},
	issn = {0891-2017},
	url = {http://dl.acm.org/citation.cfm?id=971750.971755},
	number = {2},
	urldate = {2019-03-14},
	journal = {Computational Linguistics},
	author = {Hirst, Graeme},
	month = jun,
	year = {1991},
	pages = {211--227},
}

@article{abushawar_usefulness_2016,
	title = {Usefulness, localizability, humanness, and language-benefit: additional evaluation criteria for natural language dialogue systems},
	volume = {19},
	issn = {1381-2416, 1572-8110},
	shorttitle = {Usefulness, localizability, humanness, and language-benefit},
	url = {http://link.springer.com/10.1007/s10772-015-9330-4},
	doi = {10.1007/s10772-015-9330-4},
	abstract = {Human–computer dialogue systems interact with human users using natural language. We used the ALICE/AIML chatbot architecture as a platform to develop a range of chatbots covering different languages, genres, text-types, and user-groups, to illustrate qualitative aspects of natural language dialogue system evaluation. We present some of the different evaluation techniques used in natural language dialogue systems, including black box and glass box, comparative, quantitative, and qualitative evaluation. Four aspects of NLP dialogue system evaluation are often overlooked: ‘‘usefulness’’ in terms of a user’s qualitative needs, ‘‘localizability’’ to new genres and languages, ‘‘humanness’’ or ‘‘naturalness’’ compared to human–human dialogues, and ‘‘language beneﬁt’’ compared to alternative interfaces. We illustrated these aspects with respect to our work on machine-learnt chatbot dialogue systems; we believe these aspects are worthwhile in impressing potential new users and customers.},
	language = {en},
	number = {2},
	urldate = {2021-10-07},
	journal = {International Journal of Speech Technology},
	author = {AbuShawar, Bayan and Atwell, Eric},
	month = jun,
	year = {2016},
	pages = {373--383},
}

@article{leiser_improving_1989,
	title = {Improving natural language and speech interfaces by the use of metalinguistic phenomena},
	volume = {20},
	issn = {0003-6870},
	url = {https://www.sciencedirect.com/science/article/pii/0003687089900732},
	doi = {10.1016/0003-6870(89)90073-2},
	abstract = {Current shortcomings of Natural Language and Speech recognition interfaces are discussed. The argument examined is that people's familiarity with Natural Language and Speech, generally regarded as the raison d'etre of such interfaces, is in fact a barrier to their effective use. It is demonstrated, however, that prudent use of human metalingusitic strategies can alleviate some of the shortcomings in such interfaces. Examples are provided of metalinguistic strategies (response matching, mutual modelling and message adaptation), identified in human-human dialogue, being investigated in the laboratory and adapted for effective use in the design of human-computer dialogues.},
	language = {en},
	number = {3},
	urldate = {2021-10-07},
	journal = {Applied Ergonomics},
	author = {Leiser, R. G.},
	month = sep,
	year = {1989},
	pages = {168--173},
}

@article{levow_adaptations_2002,
	series = {{ESCA} {Workshop} on {Dialogue} and {Prosody}, {September} 1999},
	title = {Adaptations in spoken corrections: {Implications} for models of conversational speech},
	volume = {36},
	issn = {0167-6393},
	shorttitle = {Adaptations in spoken corrections},
	url = {https://www.sciencedirect.com/science/article/pii/S0167639301000310},
	doi = {10.1016/S0167-6393(01)00031-0},
	abstract = {Miscommunication in spoken human–computer interaction is unavoidable. Ironically, the user's attempts to repair these miscommunications are even more likely to result in recognition failures, leading to frustrating error “spirals”. In this paper we investigate users' adaptations to recognition errors made by a spoken language system and the impact of these adaptations on models for speech recognition. In analyzing over 300 pairs of original and repeat correction utterances, matched on speaker and lexical content, we found overall increases in utterance and pause duration from original to correction. Here we focus on those adaptations – phonological and durational – that are most likely to adversely impact the accuracy of speech recognizers. We identify several phonological shifts from conversational to clear speech style. We determine that the observed durations of spoken user corrections from a field trial represent increases over, and divergences from, those derived from a speech recognizer's underlying model. Furthermore, words in final position diverge significantly more than those in non-final position, due to the additional effects of phrase-final lengthening. These systematic changes argue for a general model of pronunciation and duration, extending beyond the sentence level to incorporate higher-level dialog features, and illustrate important features for such a model to capture.},
	language = {en},
	number = {1},
	urldate = {2021-10-07},
	journal = {Speech Communication},
	author = {Levow, Gina-Anne},
	month = jan,
	year = {2002},
	pages = {147--163},
}

@inproceedings{boves_resources_2009,
	title = {Resources for speech research: {Present} and future infrastructure needs},
	shorttitle = {Resources for speech research},
	booktitle = {10th {Annual} {Conference} of the {International} {Speech} {Communication} {Association} [{Interspeech} 2009]},
	author = {Boves, Lou and Carlson, Rolf and Hinrichs, Erhard and House, David and Krauwer, Steven and Lemnitzer, Lothar and Vainio, Martti and Wittenburg, Peter},
	year = {2009},
	pages = {1803--1806},
}

@inproceedings{prevot_should_2019,
	address = {Taipei, Taiwan},
	series = {Proceedings of {Third} {International} {Symposium} on {Linguitic} {Patters} of {Spontaneous} {Speech}},
	title = {Should we use movie subtitles to study linguistic patterns of conversational speech? {A} study based on {French}, {English} and {Taiwan} {Mandarin}},
	shorttitle = {Should we use movie subtitles to study linguistic patterns of conversational speech?},
	url = {https://hal.archives-ouvertes.fr/hal-02385689},
	abstract = {Linguistic research benefits from the wide range of resources and software tools developed for natural language processing (NLP) tasks. However, NLP has a strong historical bias towards written language, thereby making these resources and tools often inadequate to address research questions related to the linguistic patterns of spontaneous speech. In this preliminary study, we investigate whether corpora of movie and TV subtitles can be employed to estimate data-driven NLP models adapted to conversational speech. In particular, the presented work explore lexical and syntactic distributional aspects across three genres (conversational, written and subtitles) and three languages (French, English and Taiwan Mandarin). Ongoing work focuses on comparing these three genres on the basis of deeper syntactic conversational patterns , using graph-based modelling and visualisation.},
	urldate = {2021-10-07},
	booktitle = {Third {International} {Symposium} on {Linguitic} {Patters} of {Spontaneous} {Speech}},
	author = {Prevot, Laurent and Magistry, Pierre and Lison, Pierre},
	month = nov,
	year = {2019},
}

@incollection{blache_corpus_2017,
	address = {Dordrecht},
	title = {The {Corpus} of {Interactional} {Data}: {A} {Large} {Multimodal} {Annotated} {Resource}},
	isbn = {978-94-024-0881-2},
	shorttitle = {The {Corpus} of {Interactional} {Data}},
	url = {https://doi.org/10.1007/978-94-024-0881-2_51},
	abstract = {The availability of annotated datasets had been steadily growing for written language and benefited to linguistic studies and natural language processing. The situation for face-to-face spontaneous conversation is more contrasted for several reasons: technicalities in handling raw data (split across several sources and medias), need for a often difficult and time-consuming transcription, large variety of annotation that can be performed. We propose in this chapter a complete annotation workflow, starting from raw data (speech and video) to a richly annotated dataset with many linguistic information (morpho-syntax, prosody, gesture studies, discourse analysis). Our approach consisted in gathering experts from the different domains and work together on the establishment of an abstract schema encoded with types feature structures. We detail how the annotation workflow had been used for developing of a richly annotated version of the Corpus of Interactional Data. The corpus as well as the annotation described here are available through the Speech and Language Data Repository.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Handbook of {Linguistic} {Annotation}},
	publisher = {Springer Netherlands},
	author = {Blache, Philippe and Bertrand, Roxane and Ferré, Gaëlle and Pallaud, Berthille and Prévot, Laurent and Rauzy, Stéphane},
	editor = {Ide, Nancy and Pustejovsky, James},
	year = {2017},
	doi = {10.1007/978-94-024-0881-2_51},
	pages = {1323--1356},
}

@inproceedings{fuscone_filtering_2020,
	address = {Virtual (Boise), United States},
	series = {Proceedings of the 21th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	title = {Filtering conversations by dialogue act labels for improving corpus-based convergence studies},
	url = {https://hal.archives-ouvertes.fr/hal-03224185},
	abstract = {During an interaction the tendency of speakers to change their speech production to make it more similar to their interlocutor's speech is called convergence. Convergence had been studied due to its relevance for cognitive models of communication as well as for dialogue system adaptation to the user. Convergence effects have been established on controlled data sets while tracking its dynamics on generic corpora has provided positive but more contrasted outcomes. We propose to enrich large conversational corpora with dialogue acts information and to use these acts as filters to create subsets of homogeneous conversational activity. Those subsets allow a more precise comparison between speakers' speech variables. We compare convergence on acoustic variables (Energy, Pitch and Speech Rate) measured on raw data sets, with human and automatically data sets labelled with dialog acts type. We found that such filtering helps in observing convergence suggesting that future studies should consider such high level dialogue activity types and the related NLP techniques as important tools for analyzing conversational interpersonal dynamics.},
	urldate = {2021-10-07},
	booktitle = {21th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	author = {Fuscone, Simone and Favre, Benoit and Prevot, Laurent},
	year = {2020},
}

@inproceedings{prevot_cup_2016,
	title = {A {CUP} of {CoFee}: {A} {Large} {Collection} of {Feedback} {Utterances} {Provided} with {Communicative} {Function} {Annotations}},
	copyright = {https://creativecommons.org/licenses/by-nc/4.0/},
	isbn = {978-2-9517408-9-1},
	shorttitle = {A {CUP} of {CoFee}},
	url = {https://ids-pub.bsz-bw.de/frontdoor/index/index/docId/5041},
	abstract = {There have been several attempts to annotate communicative functions to utterances of verbal feedback in English previously. Here, we suggest an annotation scheme for verbal and non-verbal feedback utterances in French including the categories base, attitude, previous and visual. The data comprises conversations, maptasks and negotiations from which we extracted ca. 13,000 candidate feedback utterances and gestures. 12 students were recruited for the annotation campaign of ca. 9,500 instances. Each instance was annotated by between 2 and 7 raters. The evaluation of the annotation agreement resulted in an average best-pair kappa of 0.6. While the base category with the values acknowledgement, evaluation, answer, elicit and other achieves good agreement, this is not the case for the other main categories. The data sets, which also include automatic extractions of lexical, positional and acoustic features, are freely available and will further be used for machine learning classification experiments to analyse the form-function relationship of feedback.},
	language = {eng},
	urldate = {2021-10-07},
	publisher = {European Language Resources Association (ELRA)},
	author = {Prévot, Laurent and Gorisch, Jan and Bertrand, Roxane},
	month = jul,
	year = {2016},
	pages = {3180--3185},
}

@article{schone_language-independent_2001,
	title = {Language-independent induction of part of speech class labels using only language universals},
	journal = {Machine Learning: Beyond Supervision},
	author = {Schone, Patrick and Jurafsky, Daniel},
	year = {2001},
	note = {Publisher: Citeseer},
}

@inproceedings{prevot_grouping_2018,
	address = {Miyazaki, Japan},
	title = {Grouping conversational markers across languages by exploiting large comparable corpora and unsupervised segmentation},
	url = {https://hal.archives-ouvertes.fr/hal-01807804},
	abstract = {This work approaches Conversational and Discourse Markers (hereafter DM) from a radical data-driven perspective grounded in large comparable corpora of French, English and Taiwan Mandarin conversations. The key features of our approach are (i) to account for lexicalization as a by-product of unsupervised segmentation applied to our corpora, (ii) to exploit simple metrics for clustering DM (both within a language and within multilingual clusters). We explore the benefits and the drawbacks of such a radical approach to DM. In particular we compare the DM clusters obtained from traditional segmentation into tokens (as given by manual transcription of the corpora) vs. unsupervised segmentation. The metrics on which we ground the clustering experiments are based on contrast between (i) short vs. longer utterances distribution and (ii) position within longer utterances.},
	urldate = {2021-10-07},
	booktitle = {11th {Workshop} on {Building} and {Using} {Comparable} {Corpora}},
	author = {Prevot, Laurent and Stali, Matthieu and Tseng, Shu-Chuan},
	month = may,
	year = {2018},
}

@inproceedings{odell_looking_2007,
	title = {Looking for rhythms in conversational speech},
	booktitle = {Proceedings of the 16th {International} {Congress} of {Phonetic} {Sciences}},
	author = {O’Dell, Michael and Lennes, Mietta and Werner, Stefan and Nieminen, Tommi},
	year = {2007},
	pages = {1201--1204},
}

@inproceedings{ramanarayanan_automatic_2018,
	title = {Automatic token and turn level language identification for code-switched text dialog: {An} analysis across language pairs and corpora},
	shorttitle = {Automatic token and turn level language identification for code-switched text dialog},
	booktitle = {Proceedings of the 19th {Annual} {SIGdial} {Meeting} on {Discourse} and {Dialogue}},
	author = {Ramanarayanan, Vikram and Pugh, Robert},
	year = {2018},
	pages = {80--88},
}

@inproceedings{fung_cross-linguistic_2007,
	title = {Cross-linguistic analysis of prosodic features for sentence segmentation},
	booktitle = {Eighth annual conference of the international speech communication association},
	author = {Fung, James G. and Hakkani-Tür, Dilek and Magimai-Doss, Mathew and Shriberg, Elizabeth and Cuendet, Sebastien and Mirghafori, Nikki},
	year = {2007},
}

@inproceedings{johnson_spice_2020,
	address = {Marseille, France},
	title = {{SpiCE}: {A} {New} {Open}-{Access} {Corpus} of {Conversational} {Bilingual} {Speech} in {Cantonese} and {English}},
	isbn = {979-10-95546-34-4},
	shorttitle = {{SpiCE}},
	url = {https://aclanthology.org/2020.lrec-1.503},
	abstract = {This paper describes the design, collection, orthographic transcription, and phonetic annotation of SpiCE, a new corpus of conversational Cantonese-English bilingual speech recorded in Vancouver, Canada. The corpus includes high-quality recordings of 34 early bilinguals in both English and Cantonese—to date, 27 have been recorded for a total of 19 hours of participant speech. Participants completed a sentence reading task, storyboard narration, and conversational interview in each language. Transcription and annotation for the corpus are currently underway. Transcripts produced with Google Cloud Speech-to-Text are available for all participants, and will be included in the initial SpiCE corpus release. Hand-corrected orthographic transcripts and force-aligned phonetic transcripts will be released periodically, and upon completion for all recordings, comprise the second release of the corpus. As an open-access language resource, SpiCE will promote bilingualism research for a typologically distinct pair of languages, of which Cantonese remains understudied despite there being millions of speakers around the world. The SpiCE corpus is especially well-suited for phonetic research on conversational speech, and enables researchers to study cross-language within-speaker phenomena for a diverse group of early Cantonese-English bilinguals. These are areas with few existing high-quality resources.},
	language = {English},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 12th {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Johnson, Khia A. and Babel, Molly and Fong, Ivan and Yiu, Nancy},
	month = may,
	year = {2020},
	pages = {4089--4095},
}

@inproceedings{afantenos_empirical_2012,
	address = {Istanbul, Turkey},
	title = {An empirical resource for discovering cognitive principles of discourse organisation: the {ANNODIS} corpus},
	shorttitle = {An empirical resource for discovering cognitive principles of discourse organisation},
	url = {https://hal.archives-ouvertes.fr/hal-00976087},
	abstract = {This paper describes the ANNODIS resource, a discourse-level annotated corpus for French. The corpus combines two perspectives on discourse: a bottom-up approach and a top-down approach. The bottom-up view incrementally builds a structure from elementary discourse units, while the top-down view focuses on the selective annotation of multi-level discourse structures. The corpus is composed of texts that are diversified with respect to genre, length and type of discursive organisation. The methodology followed here involves an iterative design of annotation guidelines in order to reach satisfactory inter-annotator agreement levels. This allows us to raise a few issues relevant for the comparison of such complex objects as discourse structures. The corpus also serves as a source of empirical evidence for discourse theories. We present here two first analyses taking advantage of this new annotated corpus --one that tested hypotheses on constraints governing discourse structure, and another that studied the variations in composition and signalling of multi-level discourse structures.},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {Eight} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'12)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Afantenos, Stergos and Asher, Nicholas and Benamara, Farah and Bras, Myriam and Fabre, Cécile and Ho-Dac, Lydia-Mai and Le Draoulec, Anne and Muller, Philippe and Péry-Woodley, Marie-Paule and Prevot, Laurent and Rebeyrolle, Josette and Tanguy, Ludovic and Vergez-Couret, Marianne and Vieu, Laure},
	editor = {Calzolari, Nicoletta and Choukri, Khalid and Declerck, Thierry and Doğan, Mehmet Uğur and Maegaard, Bente and Mariani, Joseph and Odijk, Jan and Piperidis, Stelios},
	month = may,
	year = {2012},
	pages = {--},
}

@article{kikui_comparative_2006,
	title = {Comparative study on corpora for speech translation},
	volume = {14},
	issn = {1558-7924},
	doi = {10.1109/TASL.2006.878262},
	abstract = {This paper investigates issues in preparing corpora for developing speech-to-speech translation (S2ST). It is impractical to create a broad-coverage parallel corpus only from dialog speech. An alternative approach is to have bilingual experts write conversational-style texts in the target domain, with translations. There is, however, a risk of losing fidelity to the actual utterances. This paper focuses on balancing a tradeoff between these two kinds of corpora through the analysis of two newly developed corpora in the travel domain: a bilingual parallel corpus with 420 K utterances and a collection of in-domain dialogs using actual S2ST systems. We found that the first corpus is effective for covering utterances in the second corpus if complimented with a small number of utterances taken from monolingual dialogs. We also found that characteristics of in-domain utterances become closer to those of the first corpus when more restrictive conditions and instructions to speakers are given. These results suggest the possibility of a bootstrap-style of development of corpora and S2ST systems, where an initial S2ST system is developed with parallel texts, and is then gradually improved with in-domain utterances collected by the system as restrictions are relaxed},
	number = {5},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Kikui, G. and Yamamoto, S. and Takezawa, T. and Sumita, E.},
	month = sep,
	year = {2006},
	note = {Conference Name: IEEE Transactions on Audio, Speech, and Language Processing},
	pages = {1674--1682},
}

@article{gilmartin_explorations_2018,
	title = {Explorations in multiparty casual social talk and its relevance for social human machine dialogue},
	volume = {12},
	issn = {1783-8738},
	url = {https://doi.org/10.1007/s12193-018-0274-2},
	doi = {10.1007/s12193-018-0274-2},
	abstract = {Much talk between humans is face-to-face, casual, multiparty, and of indefinite duration. Such casual conversation or social talk facilitates social bonding and mutual co-presence rather than strictly being used to exchange information in order to complete well-defined practical tasks. Artificial partners capable of participating as a speaker or listener in such talk would be useful for companionship, educational, and social contexts. However, to adequately model social talk, such applications require dialogue structure beyond simple question/answer routines. While there is a body of theory on multiparty casual talk, there is a lack of quantitative work in the area. Our work focuses on the anatomy of casual talk, in particular phases of chat, highly interactive dialogue exchanges, and chunks, longer contributions from single participants in the dialogue. We outline the current knowledge on the structure of casual talk and describe our investigations in this domain. Our research finds that distributions of the durations of chat and chunk phases vary with chat being shorter than chunk phases. Chat is also more common at the start of conversations, with chunks becoming more prominent as the conversation progresses. Laughter and overlap are more common in chat phases than chunk phases. We discuss how these insights can inform the design and implementation of truly social machine dialogue partners.},
	language = {en},
	number = {4},
	urldate = {2021-10-05},
	journal = {Journal on Multimodal User Interfaces},
	author = {Gilmartin, Emer and Cowan, Benjamin R. and Vogel, Carl and Campbell, Nick},
	month = dec,
	year = {2018},
	pages = {297--308},
}

@incollection{gilmartin_chunks_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Chunks in {Multiparty} {Conversation}—{Building} {Blocks} for {Extended} {Social} {Talk}},
	isbn = {978-3-319-92108-2},
	url = {https://doi.org/10.1007/978-3-319-92108-2_4},
	abstract = {Building applications which can form a longer term social bond with a user or engage with a group of users calls for knowledge of how longer conversations work. This paper describes preliminary explorations of the structure of long (c. one hour) multiparty casual conversations, focusing on a binary distinction between two types of interaction phases—chat and chunk. A collection of long form conversations which provide the data for our explorations is described. The main result is that chat and chunk segments show differences in the distribution of their duration.},
	language = {en},
	urldate = {2021-10-05},
	booktitle = {Advanced {Social} {Interaction} with {Agents} : 8th {International} {Workshop} on {Spoken} {Dialog} {Systems}},
	publisher = {Springer International Publishing},
	author = {Gilmartin, Emer and Cowan, Benjamin R. and Vogel, Carl and Campbell, Nick},
	editor = {Eskenazi, Maxine and Devillers, Laurence and Mariani, Joseph},
	year = {2019},
	doi = {10.1007/978-3-319-92108-2_4},
	pages = {37--44},
}

@inproceedings{joshi_state_2020,
	address = {Online},
	title = {The {State} and {Fate} of {Linguistic} {Diversity} and {Inclusion} in the {NLP} {World}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.560},
	doi = {10.18653/v1/2020.acl-main.560},
	abstract = {Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the “language agnostic” status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.},
	language = {en},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Joshi, Pratik and Santy, Sebastin and Budhiraja, Amar and Bali, Kalika and Choudhury, Monojit},
	year = {2020},
	pages = {6282--6293},
}

@inproceedings{wang_coding_2018,
	address = {Melbourne, Australia},
	title = {Coding {Structures} and {Actions} with the {COSTA} {Scheme} in {Medical} {Conversations}},
	doi = {10.18653/v1/W18-2309},
	abstract = {This paper describes the COSTA scheme for coding structures and actions in conversation. Informed by Conversation Analysis, the scheme introduces an innovative method for marking multi-layer structural organization of conversation and a structure-informed taxonomy of actions. In addition, we create a corpus of naturally occurring medical conversations, containing 318 video-recorded and manually transcribed pediatric consultations. Based on the annotated corpus, we investigate 1) treatment decision-making process in medical conversations, and 2) effects of physician-caregiver communication behaviors on antibiotic over-prescribing. Although the COSTA annotation scheme is developed based on data from the task-specific domain of pediatric consultations, it can be easily extended to apply to more general domains and other languages.},
	booktitle = {Proceedings of the {BioNLP} 2018 workshop},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Nan and Song, Yan and Xia, Fei},
	month = jul,
	year = {2018},
	pages = {76--86},
}

@inproceedings{dingemanse_cultural_2020,
	title = {The cultural evolution of collateral signals},
	url = {http://brussels.evolang.org/proceedings/paper.html?nr=165},
	doi = {10.17617/2.3190925},
	booktitle = {Redrawing the boundaries of language ({Evolution} of {Language}: {Proceedings} of the 13th {International} {Conference} ({EvoLang} 13 workshop)},
	author = {Dingemanse, Mark and Woensdregt, Marieke},
	editor = {Motamedi, Yasamin and Schouwstra, Marieke and Filippi, Piera},
	year = {2020},
}

@article{dingemanse_other-initiated_2015,
	title = {Other-initiated repair across languages: towards a typology of conversational structures},
	volume = {1},
	doi = {10.2478/opli-2014-0007},
	journal = {Open Linguistics},
	author = {Dingemanse, Mark and Enfield, N. J.},
	year = {2015},
	keywords = {language\_en, publist\_main},
	pages = {98--118},
}

@article{dingemanse_universal_2015,
	title = {Universal {Principles} in the {Repair} of {Communication} {Problems}},
	volume = {10},
	doi = {10.1371/journal.pone.0136100},
	number = {9},
	journal = {PLOS ONE},
	author = {Dingemanse, Mark and Roberts, Seán G. and Baranova, Julija and Blythe, Joe and Drew, Paul and Floyd, Simeon and Gisladottir, Rosa S. and Kendrick, Kobin H. and Levinson, Stephen C. and Manrique, Elizabeth and Rossi, Giovanni and Enfield, N. J.},
	year = {2015},
	keywords = {language\_en, publist\_main},
	pages = {e0136100},
}

@article{dingemanse_formats_2014,
	title = {Formats for other-initiation of repair across languages: {An} exercise in pragmatic typology},
	volume = {38},
	doi = {10.1075/sl.38.1.01din},
	number = {1},
	journal = {Studies in Language},
	author = {Dingemanse, Mark and Blythe, Joe and Dirksmeyer, Tyko},
	year = {2014},
	keywords = {language\_en, publist\_main},
	pages = {5--43},
}

@article{dingemanse_resource-rationality_2020,
	title = {Resource-rationality beyond individual minds: the case of interactive language use},
	volume = {43},
	doi = {10.1017/S0140525X19001638},
	abstract = {Resource-rational approaches offer much promise for understanding human cognition, especially if they can reach beyond the confines of individual minds. Language allows people to transcend individual resource limitations by augmenting computation and enabling distributed cognition. Interactive language use, an environment where social rational agents routinely deal with resource constraints together, offers a natural laboratory to test resource-rationality in the wild.},
	journal = {Behavioral and Brain Sciences},
	author = {Dingemanse, Mark},
	year = {2020},
	keywords = {language\_en, publist\_main},
	pages = {23--24},
}

@article{dingemanse_place_2017,
	title = {Place reference in story beginnings: a cross-linguistic study of narrative and interactional affordances},
	volume = {46},
	doi = {10.1017/S0047404516001019},
	number = {2},
	journal = {Language in Society},
	author = {Dingemanse, Mark and Rossi, Giovanni and Floyd, Simeon},
	year = {2017},
	keywords = {language\_en, publist\_main},
	pages = {129--158},
}

@incollection{floyd_recruiting_2020,
	address = {Berlin},
	series = {Diversity {Linguistics}},
	title = {Recruiting assistance and collaboration: a {West}-{African} corpus study},
	booktitle = {Getting others to do things: {A} pragmatic typology of recruitments},
	publisher = {Language Science Press},
	author = {Dingemanse, Mark},
	editor = {Floyd, Simeon and Rossi, Giovanni and Enfield, N. J.},
	year = {2020},
	note = {doi:10.5281/zenodo.4018388},
	keywords = {language\_en, publist\_main},
	pages = {369--421},
}

@article{dingemanse_between_2020,
	title = {Between {Sound} and {Speech}: {Liminal} {Signs} in {Interaction}},
	volume = {53},
	issn = {0835-1813},
	shorttitle = {Between {Sound} and {Speech}},
	doi = {10.1080/08351813.2020.1712967},
	abstract = {When people talk, they recruit a wide range of expressive devices for interactional work, from sighs, sniffs, clicks, and whistles to other conduct that borders on the linguistic. These resources are used in the management of turn and sequence and the marking of stance and affect, and they represent an aspect of the interactional machinery that is as elusive as it is powerful. Phenomena long assumed to be beyond the purview of linguistic inquiry emerge as systematically deployed practices whose ambiguous degree of control and convention allows participants to carry out subtle interactional work without committing to specific words. While these resources have been characterized as nonlexical, nonverbal, or nonconventional, I propose that they are unified in their liminality: They work well precisely because they equivocate between sound and speech. The empirical study of liminal signs shows the promise of sequential analysis for building a science of language on interactional foundations.},
	number = {1},
	journal = {Research on Language and Social Interaction},
	author = {Dingemanse, Mark},
	month = jan,
	year = {2020},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2020.1712967},
	keywords = {language\_en, publist\_main},
	pages = {188--196},
}

@incollection{dingemanse_margins_2017,
	address = {Berlin},
	title = {On the margins of language: {Ideophones}, interjections and dependencies in linguistic theory},
	abstract = {Linguistic discovery is viewpoint-dependent, just like our ideas about what is marginal and what is central in language. In this essay I consider two supposed marginalia —ideophones and interjections— which provide some useful pointers for widening our field of view. Ideophones challenge us to take a fresh look at language and consider how it is that our communication system combines multiple modes of representation. Interjections challenge us to extend linguistic inquiry beyond sentence level, and remind us that language is social-interactive at core. Marginalia, then, are not the obscure, exotic phenomena that can be safely ignored: they represent opportunities for innovation and invite us to keep pushing the edges of linguistic inquiry.},
	booktitle = {Dependencies in language},
	publisher = {Language Science Press},
	author = {Dingemanse, Mark},
	editor = {Enfield, N. J.},
	year = {2017},
	note = {doi:10.5281/zenodo.573781},
	keywords = {language\_en, publist\_main},
	pages = {195--202},
}

@incollection{dingemanse_brain--brain_2017,
	address = {Oxford},
	title = {Brain-to-brain interfaces and the role of language in distributing agency},
	booktitle = {Distributed {Agency}},
	publisher = {Oxford University Press},
	author = {Dingemanse, Mark},
	editor = {Enfield, N. J. and Kockelman, Paul},
	year = {2017},
	note = {doi:10.1093/acprof:oso/9780190457204.003.0007},
	keywords = {language\_en, publist\_main},
	pages = {59--66},
}

@article{dingemanse_other-initiated_2015-1,
	title = {Other-initiated repair in {Siwu}},
	volume = {1},
	doi = {10.1515/opli-2015-0001},
	journal = {Open Linguistics},
	author = {Dingemanse, Mark},
	year = {2015},
	keywords = {language\_en, publist\_main},
	pages = {232--255},
}

@article{bender_benderrule_2019,
	title = {The \#{BenderRule}: {On} {Naming} the {Languages} {We} {Study} and {Why} {It} {Matters}},
	url = {https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/},
	journal = {The Gradient},
	author = {Bender, Emily M.},
	month = sep,
	year = {2019},
}

@article{bavelas_listener_2002,
	title = {Listener {Responses} as a {Collaborative} {Process}: {The} {Role} of {Gaze}},
	volume = {52},
	issn = {1460-2466},
	shorttitle = {Listener {Responses} as a {Collaborative} {Process}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1460-2466.2002.tb02562.x/abstract},
	doi = {10.1111/j.1460-2466.2002.tb02562.x},
	abstract = {The authors examined precisely when and how listeners insert their responses into a speaker's narrative. A collaborative theory would predict a relationship between the speaker's acts and the listener's responses, and the authors proposed that speaker gaze coordinated this collaboration. The listener typically looks more at the speaker than the reverse, but at key points while speaking the speaker seeks a response by looking at the listener, creating a brief period of mutual gaze called here a gaze window. The listener was very likely to respond with “mhm,” a nod, or other reaction during this period, after which the speaker quickly looked away and continued speaking. This model was tested with 9 dyads in which 1 person was telling a close-call story to the other. The results confirmed the model for each dyad, demonstrating both collaboration in dialogue at the microlevel and a high degree of integration and coordination of audible and visible acts, in this case, speech and gaze.},
	language = {en},
	number = {3},
	urldate = {2013-03-12},
	journal = {Journal of Communication},
	author = {Bavelas, Janet Beavin and Coates, Linda and Johnson, Trudy},
	year = {2002},
	pages = {566--580},
}

@article{bavelas_using_1997,
	title = {Using {Face}-to-face {Dialogue} as a {Standard} for {Other} {Communication} {Systems}},
	volume = {22},
	issn = {1499-6642},
	url = {http://www.cjc-online.ca/index.php/journal/article/view/973},
	number = {1},
	journal = {Canadian Journal of Communication},
	author = {Bavelas, Janet Beavin and Hutchinson, Sarah and Kenwood, Christine and Matheson, Deborah Hunt},
	month = jan,
	year = {1997},
}

@article{bavelas_listeners_2000,
	title = {Listeners as co-narrators},
	volume = {79},
	issn = {1939-1315, 0022-3514},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0022-3514.79.6.941},
	doi = {10.1037/0022-3514.79.6.941},
	language = {en},
	number = {6},
	urldate = {2017-09-30},
	journal = {Journal of Personality and Social Psychology},
	author = {Bavelas, Janet B. and Coates, Linda and Johnson, Trudy},
	year = {2000},
	pages = {941--952},
}

@article{bavelas_pragmatic_nodate,
	title = {Some {Pragmatic} {Functions} of {Conversational} {Facial} {Gestures}},
	author = {Bavelas, Janet B. and Chovil, Nicole},
}

@article{bavelas_visible_2000,
	title = {Visible {Acts} of {Meaning} {An} {Integrated} {Message} {Model} of {Language} in {Face}-to-{Face} {Dialogue}},
	volume = {19},
	issn = {0261-927X, 1552-6526},
	url = {http://jls.sagepub.com/content/19/2/163},
	doi = {10.1177/0261927X00019002001},
	abstract = {The authors propose that dialogue in face-to-face interaction is both audible and visible; language use in this setting includes visible acts of meaning such as facial displays and hand gestures. Several criteria distinguish these from other nonverbal acts: (a) They are sensitive to a sender-receiver relationship in that they are less likely to occur when an addressee will not see them, (b) they are analogically encoded symbols, (c) their meaning can be explicated or demonstrated in context, and (d) they are fully integrated with the accompanying words, although they may be redundant or nonredundant with these words. For these particular acts, the authors eschew the term nonverbal communication because it is a negative definition based solely on physical source. Instead, they propose an integrated message model in which the moment-by-moment audible and visible communicative acts are treated as a unified whole.},
	language = {en},
	number = {2},
	urldate = {2013-03-12},
	journal = {Journal of Language and Social Psychology},
	author = {Bavelas, Janet B. and Chovil, Nicole},
	month = jun,
	year = {2000},
	pages = {163--194},
}

@article{bateson_theory_1955,
	title = {A theory of play and fantasy},
	volume = {2},
	number = {39},
	journal = {Psychiatric Research Reports},
	author = {Bateson, Gregory},
	year = {1955},
	pages = {39--51},
}

@book{wittgenstein_philosophical_1968,
	address = {New York},
	edition = {3d ed},
	title = {Philosophical {Investigations}},
	publisher = {Macmillan},
	author = {Wittgenstein, Ludwig},
	year = {1968},
}

@incollection{hagoort_interactional_2019,
	address = {Cambridge, MA},
	title = {Interactional {Foundations} of {Language}: {The} {Interaction} {Engine} {Hypothesis}},
	isbn = {978-0-262-04263-5},
	booktitle = {Human language: from genes to behavior},
	publisher = {The MIT Press},
	author = {Levinson, Stephen C.},
	editor = {Hagoort, Peter},
	year = {2019},
	pages = {189--200},
}

@article{levinson_cognition_2006,
	title = {Cognition at the heart of human interaction},
	volume = {8},
	number = {1},
	journal = {Discourse Studies},
	author = {Levinson, Stephen C.},
	year = {2006},
	pages = {85--93},
}

@incollection{levinson_action_2013,
	address = {Malden, MA},
	title = {Action formation and ascription},
	booktitle = {Handbook of {Conversation} {Analysis}},
	publisher = {Blackwell Publishers},
	author = {Levinson, Stephen C.},
	editor = {Sidnell, Jack and Stivers, Tanya},
	year = {2013},
	pages = {103--130},
}

@incollection{levinson_human_2006,
	address = {Oxford},
	title = {On {The} {Human} "{Interaction} {Engine}"},
	shorttitle = {Roots of human sociality},
	booktitle = {Roots of human sociality: {Culture}, cognition, and human interaction},
	publisher = {Berg},
	author = {Levinson, Stephen C.},
	editor = {Enfield, Nick J. and Levinson, Stephen C.},
	year = {2006},
	pages = {39--69},
}

@article{levinson_living_2005,
	title = {Living with {Manny} {Schegloff}'s dangerous idea},
	volume = {7},
	number = {4-5},
	journal = {Discourse Studies},
	author = {Levinson, Stephen C.},
	year = {2005},
	keywords = {conversation analysis, important},
	pages = {431--453},
}

@incollection{levinson_minimization_1998,
	address = {London},
	title = {Minimization and {Conversational} {Inference}},
	volume = {4},
	booktitle = {Pragmatics: critical concepts},
	publisher = {Routledge},
	author = {Levinson, Stephen C.},
	editor = {Kasher, A.},
	year = {1998},
	pages = {545�614},
}

@book{levinson_presumptive_2000,
	title = {Presumptive {Meanings}: {The} {Theory} of {Generalized} {Conversational} {Implicature}},
	isbn = {978-0-262-62130-4},
	publisher = {MIT Press},
	author = {Levinson, Stephen C.},
	year = {2000},
	keywords = {ebook, philosophy of language, pragmatics},
}

@incollection{goody_interactional_1995,
	address = {Cambridge},
	title = {Interactional biases in human thinking},
	isbn = {0-521-45329-1},
	shorttitle = {Social {Intelligence} and {Interaction}},
	booktitle = {Social {Intelligence} and {Interaction}: {Expressions} and {Implications} of the {Social} {Bias} in {Human} {Intelligence}},
	publisher = {Cambridge University Press},
	author = {Levinson, Stephen C.},
	editor = {Goody, Esther N.},
	year = {1995},
	pages = {221--260},
}

@book{levinson_pragmatics_1983,
	address = {Cambridge},
	series = {Cambridge {Textbooks} in {Linguistics}},
	title = {Pragmatics},
	isbn = {0-521-22235-4},
	publisher = {Cambridge University Press},
	author = {Levinson, Stephen C.},
	year = {1983},
	keywords = {pragmatics},
}

@incollection{parret_essential_1981,
	address = {Amsterdam},
	title = {The essential inadequacies of speech act models of dialogue},
	isbn = {90-272-3006-4},
	booktitle = {Possibilities and {Limitations} of {Pragmatics}: {Proceedings} of the {Conference} on {Pragmatics}, {Urbino}, {July} 8-14, 1979},
	publisher = {Benjamins},
	author = {Levinson, Stephen C.},
	editor = {Parret, Herman and Sbisà, Marina and Verschueren, Jef},
	year = {1981},
	pages = {473--492},
}

@article{levinson_activity_1979,
	title = {Activity types and language},
	volume = {17},
	number = {5-6},
	journal = {Linguistics},
	author = {Levinson, Stephen C.},
	year = {1979},
	pages = {365--399},
}

@article{sacks_home_2002,
	title = {Home position},
	volume = {2},
	url = {http://www.ingentaconnect.com/content/jbp/gest/2002/00000002/00000002/art00001},
	doi = {10.1075/gest.2.2.02sac},
	abstract = {This paper describes a possible formal organizational device that serves to bound episodes of body movement such as gestures, fidgets, instrumental moves and the like. It involves a spate of movement — whether a single move or a series of moves — being completed by returning the moving body part to the position from which it departed at the outset. A series of specimens are examined which display this organizational device across a number of dimensions of variation — in the body part being moved, the characteristics of the mover, the amplitude of the move, etc., underscoring the formality and adaptability of the device. The electronic edition of this article includes audio-visual data.},
	urldate = {2010-04-24},
	journal = {Gesture},
	author = {Sacks, Harvey and Schegloff, Emanuel A.},
	year = {2002},
	pages = {133--146},
}

@book{sacks_lectures_1992,
	address = {London},
	title = {Lectures on conversation},
	publisher = {Blackwell},
	author = {Sacks, Harvey},
	year = {1992},
	keywords = {\_tablet},
}

@article{sacks_communication_1961,
	series = {New {Series}},
	title = {Communication between {Social} and {Physical} {Scientists}},
	volume = {134},
	issn = {00368075},
	url = {http://www.jstor.org/stable/1707812},
	number = {3477},
	urldate = {2010-04-24},
	journal = {Science},
	author = {Sacks, Harvey and Zipser, David},
	month = aug,
	year = {1961},
	note = {ArticleType: misc / Full publication date: Aug. 18, 1961 / Copyright © 1961 American Association for the Advancement of Science},
	pages = {509--510},
}

@incollection{sacks_two_2007,
	title = {Two preferences in the organization of reference to persons in conversation and their interaction},
	booktitle = {Person {Reference} in {Interaction}: linguistic, cultural, and social perspectives},
	publisher = {Cambridge University Press},
	author = {Sacks, Harvey and Schegloff, Emanuel A.},
	editor = {Enfield, N. J. and Stivers, Tanya},
	year = {2007},
	pages = {23--28},
}

@incollection{psathas_two_1979,
	address = {New York},
	title = {Two {Preferences} in the {Organization} of {Reference} to {Persons} in {Conversation} and {Their} {Interaction}},
	isbn = {0-470-26670-8},
	booktitle = {Everyday {Language}: {Studies} in {Ethnomethodology}},
	publisher = {Irvington Publishers},
	author = {Sacks, Harvey and Schegloff, Emanuel A.},
	editor = {Psathas, George},
	year = {1979},
	pages = {15--21},
}

@article{sacks_max_1999,
	title = {Max {Weber}'s {Ancient} {Judaism}},
	volume = {16},
	url = {http://tcs.sagepub.com/content/16/1/31.short},
	doi = {10.1177/026327699016001002},
	number = {1},
	urldate = {2011-12-21},
	journal = {Theory, Culture \& Society},
	author = {Sacks, Harvey},
	month = feb,
	year = {1999},
	pages = {31 --39},
}

@article{sacks_lecture_1989,
	title = {Lecture {Twelve}: {Sequencing}: {Utterances}, {Jokes}, and {Questions}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Twelve}},
	url = {http://www.jstor.org/stable/20009069},
	number = {3/4},
	urldate = {2010-08-02},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {351--364},
}

@article{sacks_lecture_1989-1,
	title = {Lecture {Thirteen}: {On} {Proverbs}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Thirteen}},
	url = {http://www.jstor.org/stable/20009070},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {365--378},
}

@incollection{sacks_appendix_1992,
	address = {London},
	title = {Appendix {A}: {The} baby cried ({Notes} for lecture 1)},
	volume = {I},
	booktitle = {Lectures on conversation},
	publisher = {Blackwell},
	author = {Sacks, Harvey},
	year = {1992},
	pages = {223--229},
}

@article{sacks_lecture_1989-2,
	title = {Lecture {Two}: {On} {Suicide} {Threats} {Getting} {Laughed} {Off}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Two}},
	url = {http://www.jstor.org/stable/20009059},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {235--245},
}

@article{sacks_lecture_1989-3,
	title = {Lecture {Three}: {The} {Correction}-{Invitation} {Device}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Three}},
	url = {http://www.jstor.org/stable/20009060},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {247--252},
}

@article{sacks_lecture_1989-4,
	title = {Lecture {Ten}: {Accountable} {Actions}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Ten}},
	url = {http://www.jstor.org/stable/20009067},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {321--332},
}

@article{sacks_lecture_1989-5,
	title = {Lecture {Six}: {The} {M}.{I}.{R}. {Membership} {Categorization} {Device}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Six}},
	url = {http://www.jstor.org/stable/20009063},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {271--281},
}

@article{sacks_lecture_1989-6,
	title = {Lecture {Seven}: {On} {Questions}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Seven}},
	url = {http://www.jstor.org/stable/20009064},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {283--293},
}

@article{sacks_lecture_1989-7,
	title = {Lecture {One}: {Rules} of {Conversational} {Sequence}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {One}},
	url = {http://www.jstor.org/stable/20009058},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {217--233},
}

@article{sacks_lecture_1989-8,
	title = {Lecture {Nine}: "{I} {Am} {Nothing}"},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Nine}},
	url = {http://www.jstor.org/stable/20009066},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {313--319},
}

@article{sacks_lecture_1989-9,
	title = {Lecture {Eight}: {On} {Measuring}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Eight}},
	url = {http://www.jstor.org/stable/20009065},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {295--311},
}

@article{sacks_introduction_1989,
	title = {Introduction},
	volume = {12},
	issn = {01638548},
	url = {http://www.jstor.org/stable/20009057},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {211--215},
}

@article{sacks_extract_1989,
	title = {Extract {Two}: {Bringing} conversations to a close},
	volume = {12},
	issn = {0163-8548},
	url = {http://www.springerlink.com/content/h14255041n387076/},
	doi = {10.1007/BF00142765},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {233--233},
}

@article{sacks_extract_1989-1,
	title = {Extract {Six}: {The} theory of pain as an index to disease},
	volume = {12},
	issn = {0163-8548},
	url = {http://www.springerlink.com/content/v742557033412h72/},
	doi = {10.1007/BF00142776},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {309--311},
}

@article{sacks_lecture_1989-10,
	title = {Lecture {Fourteen}: {The} {Inference}-{Making} {Machine}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Fourteen}},
	url = {http://www.jstor.org/stable/20009071},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {379--393},
}

@article{sacks_lecture_1989-11,
	title = {Lecture {Four}: {An} {Impromptu} {Survey} of the {Literature}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Four}},
	url = {http://www.jstor.org/stable/20009061},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {253--259},
}

@article{sacks_lecture_1989-12,
	title = {Lecture {Five}: {Suicide} as a {Device} for {Discovering} {If} {Anybody} {Cares}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Five}},
	url = {http://www.jstor.org/stable/20009062},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {261--270},
}

@article{sacks_lecture_1989-13,
	title = {Lecture {Eleven}: {On} {Exchanging} {Glances}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Lecture {Eleven}},
	url = {http://www.jstor.org/stable/20009068},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {333--350},
}

@article{sacks_extract_1989-2,
	title = {Extract {Three}: "{They} all hang themselves"},
	volume = {12},
	issn = {0163-8548},
	shorttitle = {Extract three ?},
	url = {http://www.springerlink.com/content/l843515636372524/},
	doi = {10.1007/BF00142767},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {245--245},
}

@article{sacks_extract_1989-3,
	title = {Extract {Ten}: {Assembling} activities},
	volume = {12},
	issn = {0163-8548},
	url = {http://www.springerlink.com/content/p212190j7n5u4m32/},
	doi = {10.1007/BF00142785},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {377--378},
}

@article{sacks_extract_1989-4,
	title = {Extract {Seven}: {On} '{Forgive} me'},
	volume = {12},
	issn = {0163-8548},
	shorttitle = {Extract seven on ?},
	url = {http://www.springerlink.com/content/m621711621245416/},
	doi = {10.1007/BF00142779},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {331--332},
}

@article{sacks_extract_1989-5,
	title = {Extract {Four}: the {MMPI} as a locator of alcoholics},
	volume = {12},
	issn = {0163-8548},
	url = {http://www.springerlink.com/content/q6156u7x2520x674/},
	doi = {10.1007/BF00142773},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {293--293},
}

@article{sacks_members_1988,
	title = {On members’ measurement systems},
	volume = {22},
	issn = {0835-1813},
	url = {http://dx.doi.org/10.1080/08351818809389297},
	doi = {10.1080/08351818809389297},
	number = {1-4},
	urldate = {2015-03-20},
	journal = {Research on Language and Social Interaction},
	author = {Sacks, Harvey},
	month = jan,
	year = {1988},
	pages = {45--60},
}

@article{sacks_extract_1989-6,
	title = {Extract {One}: "{Who} may {I} say is calling?"},
	volume = {12},
	issn = {0163-8548},
	shorttitle = {Extract one ?},
	url = {http://www.springerlink.com/content/qt171820524n2473/},
	doi = {10.1007/BF00142764},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {229--231},
}

@article{sacks_extract_1989-7,
	title = {Extract {Nine}: {For} children: {A} limited set of categories},
	volume = {12},
	issn = {0163-8548},
	shorttitle = {Extract nine for children},
	url = {http://www.springerlink.com/content/h683767w03618547/},
	doi = {10.1007/BF00142783},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {363--364},
}

@article{sacks_extract_1989-8,
	title = {Extract {Five}: {When} does the transformation to 'trouble' occur?},
	volume = {12},
	issn = {0163-8548},
	shorttitle = {Extract five when does the transformation to ?},
	url = {http://www.springerlink.com/content/v4u1jw3020502g33/},
	doi = {10.1007/BF00142775},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {307--308},
}

@article{sacks_extract_1989-9,
	title = {Extract {Eight}: {Doing} things with names},
	volume = {12},
	issn = {0163-8548},
	url = {http://www.springerlink.com/content/nq99l0u58717734r/},
	doi = {10.1007/BF00142781},
	number = {3-4},
	urldate = {2010-11-08},
	journal = {Human Studies},
	author = {Sacks, Harvey},
	month = dec,
	year = {1989},
	pages = {349--350},
}

@incollection{sacks_preferences_1987,
	address = {Clevedon, Avon; Philadelphia},
	title = {On the preferences for agreement and contiguity in sequences in conversation},
	booktitle = {Talk and social organisation},
	publisher = {Multilingual Matters},
	author = {Sacks, Harvey},
	editor = {Button, Graham and Lee, John R. E.},
	year = {1987},
	keywords = {*need to read},
	pages = {54--69},
}

@article{sacks_considerations_1986,
	title = {Some considerations of a story told in ordinary conversations},
	volume = {15},
	issn = {0304-422X},
	url = {http://www.sciencedirect.com/science/article/B6VC3-469749H-27/2/b68db3ffdd4ec4d6f30babaf97fa611f},
	doi = {10.1016/0304-422X(86)90036-7},
	abstract = {This paper focusses on a single storytelling event in conversation. No coherent analysis is attempted. Rather, various theoretical, methodological, and analytic issues are raised by reference to items which happen to occur in this particular storytelling. Included are discussions of elements of story organization, the independence of perceived events and story structure, and the differential organization of the sheer perceiving of an event.},
	number = {1-2},
	urldate = {2009-05-27},
	journal = {Poetics},
	author = {Sacks, Harvey},
	month = apr,
	year = {1986},
	keywords = {*read, brilliant, conversation analysis, important},
	pages = {127--138},
}

@incollection{van_dijk_inference-making_1985,
	address = {London/Orlando},
	title = {The {Inference}-{Making} {Machine}: {Notes} on {Observability}},
	volume = {3},
	isbn = {978-0-12-712001-0},
	booktitle = {Handbook of {Discourse} {Analysis}},
	publisher = {Academic Press},
	author = {Sacks, Harvey},
	editor = {van Dijk, Teun A.},
	year = {1985},
	pages = {13--23},
}

@incollection{atkinson_doing_1984,
	address = {Cambridge [Cambridgeshire]},
	series = {Studies in emotion and social interaction},
	title = {On doing 'being ordinary'},
	isbn = {0-521-24815-9},
	booktitle = {Structures of {Social} {Action}: {Studies} in {Conversation} {Analysis}},
	publisher = {Cambridge University Press},
	author = {Sacks, Harvey},
	editor = {Atkinson, J. Maxwell and Heritage, John},
	year = {1984},
	keywords = {*need to scan, classic, conversation analysis, important, narrative},
	pages = {413--429},
}

@incollection{atkinson_notes_1984,
	address = {Cambridge},
	series = {Studies in emotion and social interaction},
	title = {Notes on methodology},
	isbn = {0-521-24815-9},
	booktitle = {Structures of {Social} {Action}: {Studies} in {Conversation} {Analysis}},
	publisher = {Cambridge University Press},
	author = {Sacks, Harvey},
	editor = {Atkinson, J. Maxwell and Heritage, John},
	year = {1984},
	keywords = {*need to get, *need to scan, conversation analysis},
	pages = {21--27},
}

@incollection{sacks_analysis_1974,
	address = {Cambridge},
	title = {An analysis of the course of a joke's telling in conversation},
	booktitle = {Explorations in the ethnography of speaking},
	publisher = {Cambridge University Press},
	author = {Sacks, Harvey},
	editor = {Bauman, Richard and Sherzer, Joel},
	year = {1974},
	keywords = {classic},
	pages = {337--353},
}

@incollection{sacks_notes_1972,
	address = {New York},
	title = {Notes on police assessment of moral character},
	booktitle = {Studies in {Social} {Interaction}},
	publisher = {MacMillan/The Free Press},
	author = {Sacks, Harvey},
	editor = {Sudnow, David N.},
	year = {1972},
	pages = {280--293},
}

@incollection{sacks_initial_1972,
	address = {New York},
	title = {An initial investigation of the usability of conversational data for doing sociology},
	booktitle = {Studies in {Social} {Interaction}},
	publisher = {MacMillan/The Free Press},
	author = {Sacks, Harvey},
	editor = {Sudnow, David N.},
	year = {1972},
	pages = {31--74},
}

@phdthesis{sacks_search_1966,
	address = {California},
	type = {{PhD} dissertation},
	title = {The search for help: no one to turn to},
	school = {University of California, Berkeley},
	author = {Sacks, Harvey},
	year = {1966},
	note = {Ph.D.},
}

@incollection{psathas_hotrodder_1979,
	address = {New York},
	title = {Hotrodder: {A} {Revolutionary} {Category}},
	isbn = {0-470-26670-8},
	booktitle = {Everyday {Language}: {Studies} in {Ethnomethodology}},
	publisher = {Irvington Publishers, distributed by Halsted Press},
	author = {Sacks, Harvey},
	editor = {Psathas, George},
	year = {1979},
	keywords = {conversation analysis, identity},
	pages = {7--14},
}

@incollection{sacks_everyone_1975,
	address = {New York},
	title = {Everyone {Has} to {Lie}},
	booktitle = {Sociocultural dimensions of language use},
	publisher = {Academic Press},
	author = {Sacks, Harvey},
	editor = {Sanchez, M. and Blount, B.},
	year = {1975},
	keywords = {*need to get, *need to scan, classic, conversation analysis},
	pages = {57--80},
}

@incollection{sacks_analyzability_1972,
	address = {New York},
	title = {On the analyzability of stories by children},
	booktitle = {Directions in {Sociolinguistics}},
	publisher = {Holt, Rinehart and Winston},
	author = {Sacks, Harvey},
	editor = {Gumperz, John J. and Hymes, Dell H.},
	year = {1972},
	pages = {325--345},
}

@article{sacks_sociological_1963,
	title = {Sociological {Description}},
	volume = {8},
	journal = {Berkeley Journal of Sociology},
	author = {Sacks, Harvey},
	year = {1963},
	pages = {1--16},
}

@article{schegloff_overlapping_2000,
	title = {Overlapping {Talk} and the {Organization} of {Turn}-{Taking} for {Conversation}},
	volume = {29},
	issn = {00474045},
	url = {http://www.jstor.org/stable/4168983},
	abstract = {This article provides an empirically grounded account of what happens when more persons than one talk at once in conversation. It undertakes to specify when such occurrences are problematic for the participants, and for the organization of interaction; what the features of such overlapping talk are; and what constraints an account of overlapping talk should meet. It describes the practices employed by participants to deal with such simultaneous talk, and how they form an organization of practices which is related to the turn-taking organization previously described by Sacks et al. 1974. This "overlap resolution device" constitutes a previously unexplicated component of that turn-taking organization, and one that provides solutions to underspecified features of the previous account.},
	number = {1},
	urldate = {2010-04-24},
	journal = {Language in Society},
	author = {Schegloff, Emanuel A.},
	month = mar,
	year = {2000},
	note = {ArticleType: primary\_article / Full publication date: Mar., 2000 / Copyright © 2000 Cambridge University Press},
	pages = {1--63},
}

@incollection{hayashi_ten_2013,
	address = {Cambridge},
	series = {Studies in {Interactional} {Sociolinguistics}},
	title = {Ten {Operations} {In} {Self}-{Initiated}, {Same}-{Turn} {Repair}},
	number = {30},
	booktitle = {Conversational {Repair} and {Human} {Understanding}},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Hayashi, Makoto and Raymond, Geoffrey and Sidnell, Jack},
	year = {2013},
	pages = {np},
}

@article{schegloff_when_2000,
	title = {When 'others' initiate repair},
	volume = {21},
	url = {http://applij.oxfordjournals.org/cgi/content/abstract/21/2/205},
	doi = {10.1093/applin/21.2.205},
	abstract = {Early work on repair (Schegloff et al. 1977) had proposed that virtually all repair initiated by other than speaker of the trouble-source turn was initiated in the turn following the trouble-source turn. Such repair often came to be identified with this locus of initiation, being termed NTRI - an acronym derived from 'next turn repair initiation'. Subsequent work (Schegloff 1992) described another location in which 'other-initiated repair' is initiated - termed 'fourth position'. This paper revisits this issue and elaborates the locus of other-initiated repair. It reports on a number of environments in which 'others' initiate repair in turns later than the one directly following the trouble-source turn (without, however, occupying fourth position), and it describes several ways in which other-initiation of repair which occurs in next-turn position may be delayed within that position. These positionings of repair initiation in conversation among native speakers of English are briefly compared with a proposal by Wong that other-initiated repair by non-native speakers may regularly be delayed. A postscript suggests the prospect that studies of non-native speaker participation in talk-in-interaction be treated as not separable from the study of talk-in-interaction more generally.},
	number = {2},
	urldate = {2010-08-04},
	journal = {Applied Linguistics},
	author = {Schegloff, Emanuel A.},
	month = jun,
	year = {2000},
	pages = {205--243},
}

@incollection{schegloff_third_1997,
	address = {Amsterdam},
	title = {Third turn repair},
	booktitle = {Towards a social science of language. {Volume} 2: {Social} interaction and discourse structures},
	publisher = {John Benjamins},
	author = {Schegloff, Emanuel A.},
	editor = {Guy, Gregory R. and Feagin, Crawford and Schiffrin, Deborah and Baugh, John},
	year = {1997},
	pages = {31--40},
}

@article{schegloff_practices_1997,
	title = {Practices and actions: {Boundary} cases of other-initiated repair},
	volume = {23},
	issn = {0163-853X},
	shorttitle = {Practices and actions},
	url = {http://www.informaworld.com/10.1080/01638539709545001},
	doi = {10.1080/01638539709545001},
	number = {3},
	urldate = {2010-08-04},
	journal = {Discourse Processes},
	author = {Schegloff, Emanuel A.},
	year = {1997},
	keywords = {project-OIR},
	pages = {499--545},
}

@incollection{schegloff_recycled_1987,
	address = {Clevedon, Avon; Philadelphia},
	title = {Recycled turn beginnings: {A} precise repair mechanism in conversation's turn-taking organisation},
	booktitle = {Talk and social organisation},
	publisher = {Multilingual Matters},
	author = {Schegloff, Emanuel A.},
	editor = {Button, Graham and Lee, John R. E.},
	year = {1987},
	keywords = {*need to read},
	pages = {77--85},
}

@incollection{schegloff_relevance_1979,
	title = {The relevance of repair to syntax-for-conversation},
	volume = {12},
	booktitle = {Syntax and {Semantics}},
	author = {Schegloff, Emanuel A.},
	editor = {Givón, Talmy},
	year = {1979},
	pages = {261--286},
}

@article{schegloff_reflections_1993,
	title = {Reflections on {Quantification} in the {Study} of {Conversation}},
	volume = {26},
	issn = {0835-1813},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327973rlsi2601_5},
	doi = {10.1207/s15327973rlsi2601_5},
	number = {1},
	urldate = {2011-07-19},
	journal = {Research on Language \& Social Interaction},
	author = {Schegloff, Emanuel A.},
	month = jan,
	year = {1993},
	keywords = {project-CHLA},
	pages = {99--128},
}

@misc{schegloff_discussant_2012,
	address = {Max Planck Institute for Psycholinguistics, Nijmegen},
	type = {Talk},
	title = {Discussant remarks},
	author = {Schegloff, Emanuel A.},
	month = oct,
	year = {2012},
}

@article{schegloff_word_2011,
	title = {Word repeats as unit ends},
	volume = {13},
	url = {http://dis.sagepub.com/content/13/3/367.abstract},
	doi = {10.1177/1461445611402749},
	abstract = {Turns-at-talk are fundamental units of participation in talk-in-interaction, and turn-constructional-units (TCUs) are the basic building blocks for turns. Possible completion of a TCU is, in principle, the possible completion of the turn, but multi-unit turns are not uncommon, and participants have practices for constructing multi-unit turns and for recognizing them in the course of their production. This article offers an account of one practice (and several of its variants) usable by speakers and recipients to convey and recognize the designed completion of a multi-TCU turn and/or a multi-turn sequence in which ‘answering’ is being done: returning to, or ‘re-using’, a word or phrase from the start of the turn or sequence, whether articulated by same or different speaker, whether used to refer to same or different referents. This practice is one of the resources by which the overall structural organization of an interactional unit and its local realization are mutually realized.},
	number = {3},
	urldate = {2011-10-06},
	journal = {Discourse Studies},
	author = {Schegloff, Emanuel A.},
	month = jun,
	year = {2011},
	pages = {367 --380},
}

@article{schegloff_opening_1973,
	title = {Opening up closings},
	volume = {8},
	number = {4},
	journal = {Semiotica},
	author = {Schegloff, Emanuel A. and Sacks, Harvey},
	year = {1973},
	keywords = {conversation analysis, important},
	pages = {289--327},
}

@incollection{ochs_introduction_1996,
	address = {Cambridge},
	title = {Introduction},
	booktitle = {Interaction and {Grammar}},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A. and Ochs, Elinor and Thompson, Sandra},
	editor = {Ochs, Elinor and Schegloff, Emanuel A. and Thompson, Sandra},
	year = {1996},
	keywords = {conversation analysis},
	pages = {1--51},
}

@article{schegloff_other_2010,
	title = {Some {Other} “{Uh}(m)”s},
	volume = {47},
	issn = {0163-853X},
	url = {http://www.informaworld.com/openurl?genre=article&doi=10.1080/01638530903223380&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
	doi = {10.1080/01638530903223380},
	number = {2},
	journal = {Discourse Processes},
	author = {Schegloff, Emanuel A.},
	month = feb,
	year = {2010},
	pages = {130--174},
}

@incollection{sidnell_one_2009,
	address = {Cambridge},
	series = {Studies in {Interactional} {Sociolinguistics}},
	title = {One perspective on {Conversation} {Analysis}: {Comparative} {Perspectives}},
	isbn = {978-0-521-88371-9},
	number = {27},
	booktitle = {Conversation {Analysis}: {Comparative} {Perspectives}},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Sidnell, Jack},
	year = {2009},
	pages = {357--406},
}

@article{schegloff_categories_2007,
	title = {Categories in action: person-reference and membership categorization},
	volume = {9},
	issn = {1461-4456, 1461-7080},
	shorttitle = {Categories in action},
	url = {http://dis.sagepub.com/content/9/4/433},
	doi = {10.1177/1461445607079162},
	abstract = {The article begins with an effort to clarify and differentiate a variety of terms used by analysts in dealing with mentions of persons in conversation and other forms of talk-in-interaction — such terms as person-reference, identifying, describing, categorizing, and the like. This effort leads to the observation that `reference to persons' and `membership categorization' are quite distinct sets of practices, with most reference to persons not being done by membership categories, and most uses of membership categorization devices being in the service of actions other than referring. Two interactional sequences whose analysis turns on a connection to talk earlier in the occasion (a configuration termed `interactional threads') are then examined; first, to establish what is going on interactionally without respect to the mentioning of persons, and then as exercises in examining the various ways person-reference and membership categorization can figure in a stretch of interaction.},
	language = {en},
	number = {4},
	urldate = {2012-07-13},
	journal = {Discourse Studies},
	author = {Schegloff, Emanuel A.},
	month = aug,
	year = {2007},
	pages = {433--461},
}

@incollection{enfield_conveying_2007,
	address = {Cambridge, UK},
	series = {Language, culture, and cognition},
	title = {Conveying who you are: {The} presentation of self, strictly speaking},
	isbn = {978-0-521-87245-4},
	number = {7},
	booktitle = {Person {Reference} in {Interaction}: {Linguistic}, {Cultural}, and {Social} {Perspectives}},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Enfield, N. J. and Stivers, Tanya},
	year = {2007},
	pages = {123--148},
}

@article{schegloff_tutorial_2007,
	title = {A tutorial on membership categorization},
	volume = {39},
	number = {3},
	journal = {Journal of Pragmatics},
	author = {Schegloff, Emanuel A.},
	year = {2007},
	pages = {462--482},
}

@article{schegloff_possibles_2006,
	title = {On possibles},
	volume = {8},
	url = {http://dis.sagepub.com/cgi/content/abstract/8/1/141},
	doi = {10.1177/1461445606059563},
	abstract = {Although there is no lack of reasons for conversation analysis to be reluctant to adopt a cognitivist idiom and paradigm in studying talk and other conduct in interaction, examination of the literature with an open mind will disclose attentiveness to such themes in the conversation-analytic literature nonetheless. The pursuit of such themes however, cannot be appropriately and successfully conducted under the aegis of currently dominant cognitivist paradigms. One central analytic resource in CA work is the notion of a possible X', a resource which is here described and exemplified for three discrete values' of X'. The understanding of how such possible Xs' could work for participants in interaction invites understanding by analysts by reference to a multiple passes' model of uptake, a characterization which for now can be no more than metaphoric. Here is a venue at which conversation-analysts and neuro/cognitive analysts might usefully try to work together.},
	number = {1},
	urldate = {2010-04-24},
	journal = {Discourse Studies},
	author = {Schegloff, Emanuel A.},
	month = feb,
	year = {2006},
	pages = {141--157},
}

@article{schegloff_complainability_2005,
	title = {On {Complainability}},
	volume = {52},
	issn = {00377791},
	url = {http://www.jstor.org/stable/4488137},
	abstract = {Two common components of social problems are their grounding in the differential categorization of people and the treatment of some forms of conduct as "complainable." This article begins by introducing some ways in which the categorization of people and the complainability of conduct are problematic-both in the conduct of ordinary interaction and in social scientific analysis of ordinary interaction. It then addresses this problematicity by examining how ordinary conduct in interaction can display participants' tacit orientation to the relevance of unspoken categories and to the complainability of one's own or others' conduct. It concludes by inviting attention to recent work on well-recognized topics of inquiry in the social problems literature, and encourages the advancement of such work by combining new analytic resources with longstanding social problems themes and topics.},
	number = {4},
	urldate = {2010-04-24},
	journal = {Social Problems},
	author = {Schegloff, Emanuel A.},
	month = nov,
	year = {2005},
	note = {ArticleType: primary\_article / Full publication date: Nov., 2005 / Copyright © 2005 University of California Press},
	pages = {449--476},
}

@article{schegloff_commentary_2010,
	title = {Commentary on {Stivers} and {Rossano}: “{Mobilizing} {Response}”},
	volume = {43},
	issn = {0835-1813},
	shorttitle = {Commentary on {Stivers} and {Rossano}},
	url = {http://www.informaworld.com/10.1080/08351810903471282},
	doi = {10.1080/08351810903471282},
	number = {1},
	urldate = {2010-07-12},
	journal = {Research on Language and Social Interaction},
	author = {Schegloff, Emanuel A.},
	year = {2010},
	pages = {38},
}

@book{schegloff_sequence_2007,
	address = {Cambridge},
	title = {Sequence {Organization} in {Interaction}: {A} {Primer} in {Conversation} {Analysis}},
	isbn = {978-0-521-82572-6},
	shorttitle = {Sequence {Organization} in {Interaction}},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	year = {2007},
	keywords = {*need to read, conversation analysis, ebook},
}

@incollection{schegloff_interaction_2006,
	address = {Oxford},
	title = {Interaction: {The} {Infrastructure} for {Social} {Institutions}, the {Natural} {Ecological} {Niche} for {Language}, and the {Arena} in which {Culture} is {Enacted}},
	booktitle = {Roots of human sociality: {Culture}, cognition, and human interaction},
	publisher = {Berg},
	author = {Schegloff, Emanuel A.},
	editor = {Enfield, Nick J. and Levinson, Stephen C.},
	year = {2006},
	keywords = {gesture},
	pages = {70--96},
}

@article{schegloff_integrity_2005,
	title = {On integrity in inquiry... of the investigated, not the investigator},
	volume = {7},
	url = {http://dis.sagepub.com/cgi/content/abstract/7/4-5/455},
	doi = {10.1177/1461445605054402},
	abstract = {The article begins with a sketch of the relation of interaction to language and to culture, and of the students of interaction to the students of language and of culture. A 10-second segment of recorded interaction at a family dinner is then examined in a fashion meant to preserve the integrity1 of what is being done interactionally while incorporating attention to the deployment of various facets of the language that is used, and its relationship to simultaneously ongoing bodily doings. An interactional practice - whining - from that episode is then juxtaposed with the same practice in several other segments of interaction in the interests of developing a more formal, transsituational account. The viability of research focused on phenomena in an analytically distinct domain of events while preserving the integrity of the occasions in which instances of the phenomenon occurred is then reviewed, using a case study of the conjoint use of phonetic analysis and conversation analysis. The article concludes with a reply to Levinson's article in this special issue of the journal, and uses the occasion to sketch the relationship between interaction and so-called macro' social and cultural formations such as kinship.},
	number = {4-5},
	urldate = {2010-04-24},
	journal = {Discourse Studies},
	author = {Schegloff, Emanuel A.},
	month = oct,
	year = {2005},
	pages = {455--480},
}

@inproceedings{schegloff_whistling_2004,
	title = {Whistling in the dark: {Notes} from the other side of liminality},
	shorttitle = {Whistling in the dark},
	booktitle = {Proceedings of the {Twelfth} {Annual} {Symposium} about {Language} and {Society}–{Austin}},
	author = {Schegloff, Emanuel A.},
	year = {2004},
}

@article{schegloff_dispensability_2004,
	title = {On dispensability},
	volume = {37},
	number = {2},
	journal = {Research on Language and Social Interaction},
	author = {Schegloff, Emanuel A.},
	year = {2004},
	pages = {95--149},
}

@article{schegloff_getting_2001,
	title = {Getting serious: joke → serious 'no'},
	volume = {33},
	issn = {0378-2166},
	shorttitle = {Getting serious},
	url = {http://www.sciencedirect.com/science/article/B6VCW-44BNH4H-7/2/969f598bd459d5251f3d369272e11899},
	doi = {10.1016/S0378-2166(00)00073-4},
	number = {12},
	urldate = {2010-07-15},
	journal = {Journal of Pragmatics},
	author = {Schegloff, Emanuel A.},
	month = dec,
	year = {2001},
	pages = {1947--1955},
}

@article{schegloff_schegloffs_1999,
	title = {Schegloff's {Texts}' as `{Billig}'s {Data}': {A} {Critical} {Reply}},
	volume = {10},
	shorttitle = {Schegloff's {Texts}' as `{Billig}'s {Data}'},
	url = {http://das.sagepub.com},
	doi = {10.1177/0957926599010004006},
	number = {4},
	urldate = {2010-03-12},
	journal = {Discourse Society},
	author = {Schegloff, Emanuel A.},
	month = oct,
	year = {1999},
	pages = {558--572},
}

@article{schegloff_naivete_1999,
	title = {Naivete vs {Sophistication} or {Discipline} vs {Self}-{Indulgence}: {A} {Rejoinder} to {Billig}},
	volume = {10},
	shorttitle = {Naivete vs {Sophistication} or {Discipline} vs {Self}-{Indulgence}},
	url = {http://das.sagepub.com},
	doi = {10.1177/0957926599010004008},
	number = {4},
	urldate = {2010-03-12},
	journal = {Discourse Society},
	author = {Schegloff, Emanuel A.},
	month = oct,
	year = {1999},
	pages = {577--582},
}

@article{schegloff_putting_2004,
	title = {Putting the interaction back into dialogue},
	volume = {27},
	url = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=254405},
	doi = {10.1017/S0140525X04320054},
	number = {02},
	urldate = {2010-11-11},
	journal = {Behavioral and Brain Sciences},
	author = {Schegloff, Emanuel A.},
	year = {2004},
	pages = {207--208},
}

@incollection{schegloff_reflections_2002,
	address = {Amsterdam},
	title = {Reflections on {Research} on {Telephone} {Conversation}: {Issues} of {Cross}-{Cultural} {Scope} and {Scholarly} {Exchange}, {Interactional} {Import}, and {Consequences}},
	booktitle = {Telephone {Calls}: {Unity} and diversity in conversational structure across languages and cultures},
	publisher = {John Benjamins},
	author = {Schegloff, Emanuel A.},
	editor = {Luke, K.K. and Pavlidou, T.S.},
	year = {2002},
	keywords = {conversation analysis, methods},
}

@article{schegloff_granularity_2000,
	title = {On {Granularity}},
	volume = {26},
	issn = {0360-0572},
	url = {http://arjournals.annualreviews.org/doi/abs/10.1146/annurev.soc.26.1.715},
	doi = {10.1146/annurev.soc.26.1.715},
	number = {1},
	urldate = {2010-03-10},
	journal = {Annual Review of Sociology},
	author = {Schegloff, Emanuel A.},
	month = aug,
	year = {2000},
	keywords = {access, conversation analysis},
	pages = {715--720},
}

@article{schegloff_sacks_1999,
	title = {On {Sacks} on {Weber} on {Ancient} {Judaism}},
	volume = {16},
	url = {http://tcs.sagepub.com/content/16/1/1.abstract},
	doi = {10.1177/026327699016001001},
	abstract = {Although Harvey Sacks' `Max Weber's Ancient Judaism' is an early student paper, it raises issues of theory, method and disciplinary mandate which have continuing relevance. I frame the article in two ways. First, I sketch the academic and intellectual context in which the paper was written, in particular the institutional setting in Berkeley of the early 1960s, and the activities and preoccupations animating the work of the group of students which was the most proximate context for Sacks' writing at this time, including the efforts to come to terms with Garfinkel's early work. Second, I relate this article to two others written by Sacks in roughly the same period, and sketch a thematic continuity and development running through them - a theme whose endpoint is the centrality of what must surely be called `culture' to the calling of Sociology.},
	number = {1},
	urldate = {2011-12-21},
	journal = {Theory, Culture \& Society},
	author = {Schegloff, Emanuel A.},
	month = feb,
	year = {1999},
	pages = {1 --29},
}

@article{schegloff_discourse_1999,
	title = {Discourse, {Pragmatics}, {Conversation}, {Analysis}},
	volume = {1},
	number = {4},
	journal = {Discourse Studies},
	author = {Schegloff, Emanuel A.},
	year = {1999},
	keywords = {conversation analysis},
	pages = {405--435},
}

@article{schegloff_body_1998,
	title = {Body torque},
	volume = {65},
	number = {3},
	journal = {Social Research},
	author = {Schegloff, Emanuel A.},
	year = {1998},
	pages = {535--596},
}

@article{schegloff_whose_1997,
	title = {Whose {Text}? {Whose} {Context}?},
	volume = {8},
	shorttitle = {Whose {Text}?},
	url = {http://das.sagepub.com/cgi/content/abstract/8/2/165},
	doi = {10.1177/0957926597008002002},
	abstract = {After a brief account of an old study on sociopolitical vs formalist styles of literary criticism and the lessons it taught about relating cultural objects to context, I turn to more recent work on talk-in-interaction and engage three themes: (1) That the events of conversation have a sense and import to participants which are at least partially displayed in each successive contribution, and which are thereby put to some degree under interactional control. Accordingly, academic accounts of the import of conversational `texts' can be endogenously grounded, and this is a worthy analytic aspiration; (2) The pursuit of this goal mandates relevant senses of context to be consulted for analysis, and these are senses and aspects of context which are demonstrably relevant to the participants in the event being examined, not necessarily ones relevant to the inquirer doing the analysis; and (3) Its technical grounds and mandate aside, this is a useful contraint on analysis in disciplining work to the indigenous preoccupations of the everyday world being grasped, and serving as a buffer against the potential for academic and theoretical imperialism which imposes intellectuals' preoccupations on a world without respect to their indigenous resonance.},
	number = {2},
	urldate = {2010-03-12},
	journal = {Discourse Society},
	author = {Schegloff, Emanuel A.},
	month = apr,
	year = {1997},
	pages = {165--187},
}

@article{schegloff_narrative_1997,
	title = {"{Narrative} {Analysis}" {Thirty} {Years} {Later}},
	volume = {7},
	number = {1-4},
	journal = {Journal of Narrative and Life History},
	author = {Schegloff, Emanuel A.},
	year = {1997},
	pages = {97--106},
}

@article{schegloff_what_1999,
	title = {What {Next}?: {Language} and {Social} {Interaction} {Study} at the {Century}'s {Turn}},
	volume = {32},
	issn = {0835-1813},
	shorttitle = {What {Next}?},
	url = {http://www.tandfonline.com/doi/abs/10.1080/08351813.1999.9683617},
	doi = {10.1080/08351813.1999.9683617},
	number = {1-2},
	urldate = {2013-03-19},
	journal = {Research on Language \& Social Interaction},
	author = {Schegloff, Emanuel A.},
	year = {1999},
	pages = {141--148},
}

@article{schegloff_reflections_1998,
	title = {Reflections on {Studying} {Prosody} in {Talk}-in-{Interaction}},
	volume = {41},
	url = {http://las.sagepub.com/cgi/content/abstract/41/3-4/235},
	doi = {10.1177/002383099804100402},
	abstract = {Rather than focusing on conversation as one context among many in which to study prosody, this paper approaches prosody as one set of resources and practices among many by which participants interactively produce conversation and other talk-in-interaction. Three episodes of conversation are examined, each exemplifying a different order of organization in which prosodic practices may be implicated. The first develops various lines of evidence to show that pitch peaks may be deployed and understood as projecting that a next syntactic possible completion is the designed end of the turn. In the second, the initial turns in the opening of a telephone conversation are examined as the site in which the participants work out the pitch level at which the conversation--or at least its first part--will be conducted, and thereby "negotiate" the tenor of the conversation's launching. The third episode focuses on the central part which prosody can play in the constitution of the action which an utterance is implementing. The paper closes with some reflections on what is needed for students of conversation in dealing with prosody--focusing especially on the need for a relevant way of describing the mediating operations which take the prosody as (partial) input and yield the action (or other conversational feature) being accomplished as outcome.},
	number = {3-4},
	urldate = {2010-04-24},
	journal = {Language and Speech},
	author = {Schegloff, Emanuel A.},
	month = jul,
	year = {1998},
	pages = {235--263},
}

@incollection{ochs_turn_1996,
	address = {Cambridge},
	series = {Studies in interactional sociolinguistics},
	title = {Turn organization: {One} intersection of grammar and interaction},
	isbn = {0-521-55225-7},
	number = {13},
	booktitle = {Interaction and {Grammar}},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Ochs, Elinor and Schegloff, Emanuel A. and Thompson, Sandra A.},
	year = {1996},
	pages = {52--133},
}

@incollection{schegloff_issues_1996,
	address = {Berlin},
	title = {Issues of {Relevance} for {Discourse} {Analysis}: {Contingency} in {Action}, {Interaction}, and {Co}-{Participant} {Context}},
	booktitle = {Computational and {Conversational} {Discourse}: {Burning} {Issues} - {An} {Interdisciplinary} {Account}},
	publisher = {Springer},
	author = {Schegloff, Emanuel A.},
	year = {1996},
	keywords = {conversation analysis, methods},
	pages = {3--35},
}

@incollection{schegloff_parties_1995,
	address = {Washington, DC},
	title = {Parties and talking together: {Two} ways in which numbers are significant for talk-in-interaction},
	booktitle = {Situated order: {Studies} in the social organization of talk and embodied activities},
	publisher = {University Press of America},
	author = {Schegloff, Emanuel A.},
	editor = {Ten Have, Paul and Psathas, George},
	year = {1995},
}

@article{schegloff_discourse_1995,
	title = {Discourse as {Interactional} {Achievement} {III}: {The} {Omnirelevance} of {Action}},
	volume = {28},
	number = {2},
	journal = {Research on Language and Social Interaction},
	author = {Schegloff, Emanuel A.},
	year = {1995},
	pages = {185--211},
}

@incollection{searle_searle_1992,
	address = {Amsterdam},
	series = {Pragmatics \& {Beyond}},
	title = {To {Searle} on {Conversation}: {A} {Note} in {Return}},
	isbn = {90-272-5033-2},
	number = {21},
	booktitle = {({On}) {Searle} on {Conversation}},
	publisher = {J. Benjamins Pub. Co},
	author = {Schegloff, Emanuel A.},
	editor = {Parret, Herman and Verschueren, Jef},
	collaborator = {Searle, John R.},
	year = {1992},
}

@incollection{duranti_another_1992,
	address = {Cambridge},
	title = {In another context},
	isbn = {0-521-42288-4},
	booktitle = {Rethinking {Context}: {Language} as an {Interactive} {Phenomenon}},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Duranti, Alessandro and Goodwin, Charles},
	year = {1992},
	pages = {191--227},
}

@incollection{resnick_conversation_1991,
	address = {Washington, DC},
	title = {Conversation {Analysis} and {Socially} {Shared} {Cognition}},
	booktitle = {Perspectives on {Socially} {Shared} {Cognition}},
	publisher = {American Psychological Association},
	author = {Schegloff, Emanuel A.},
	editor = {Resnick, Lauren B. and Levine, John M. and Teasley, Stephanie D.},
	year = {1991},
	keywords = {conversation analysis},
	pages = {150--171},
}

@article{schegloff_interactional_1990,
	title = {Interactional {Troubles} in {Face}-to-{Face} {Survey} {Interviews}: {Comment}},
	volume = {85},
	issn = {01621459},
	shorttitle = {Interactional {Troubles} in {Face}-to-{Face} {Survey} {Interviews}},
	url = {http://www.jstor.org/stable/2289554},
	number = {409},
	urldate = {2010-04-24},
	journal = {Journal of the American Statistical Association},
	author = {Schegloff, Emanuel A.},
	month = mar,
	year = {1990},
	note = {ArticleType: primary\_article / Full publication date: Mar., 1990 / Copyright © 1990 American Statistical Association},
	pages = {248--250},
}

@incollection{schegloff_reflections_1989,
	address = {New York},
	title = {Reflections on language, development, and the interactional character of talk-in-interaction},
	booktitle = {Interaction in human development},
	publisher = {Lawrence Erlbaum Associates},
	author = {Schegloff, Emanuel A.},
	editor = {Bornstein, M. H. and Bruner, Jerome S.},
	year = {1989},
	pages = {139--153},
}

@article{schegloff_actual_1988,
	title = {On an {Actual} {Virtual} {Servo}-{Mechanism} for {Guessing} {Bad} {News}: {A} {Single} {Case} {Conjecture}},
	volume = {35},
	issn = {00377791},
	shorttitle = {On an {Actual} {Virtual} {Servo}-{Mechanism} for {Guessing} {Bad} {News}},
	url = {http://www.jstor.org/stable/800596},
	abstract = {A conversation analytic treatment of a single episode of talk-in-interaction is used to sketch a mechanism for steering recipients of bad news to better guesses of what the news is. The account of the mechanism makes use of the notion of "preferred/dispreferred response" and distinguishes different usages of that notion. The results of the exploration are used to recommend an approach to specialized contexts in which bad news is communicated, as well as an approach to "specialized" talk more generally.},
	number = {4},
	urldate = {2010-04-24},
	journal = {Social Problems},
	author = {Schegloff, Emanuel A.},
	month = oct,
	year = {1988},
	note = {ArticleType: primary\_article / Issue Title: Special Issue: Language, Interaction, and Social Problems / Full publication date: Oct., 1988 / Copyright © 1988 University of California Press},
	pages = {442--457},
}

@incollection{schegloff_goffman_1988,
	address = {Cambridge},
	title = {Goffman and the {Analysis} of {Conversation}},
	booktitle = {Erving {Goffman}:  {Exploring} the {Interaction} {Order}},
	publisher = {Polity Press},
	author = {Schegloff, Emanuel A.},
	editor = {Drew, Paul and Wootton, Antony},
	year = {1988},
	keywords = {conversation analysis},
	pages = {9--135},
}

@incollection{schegloff_between_1987,
	address = {Los Angeles},
	title = {Between macro and micro: {Contexts} and other connections},
	booktitle = {The micro-macro link},
	publisher = {University of California Press},
	author = {Schegloff, Emanuel A.},
	editor = {Alexander, Jeffrey C. and Giesen, Bernhard and Munch, Richard and Smelser, Neil J.},
	year = {1987},
	keywords = {*need to read},
	pages = {207--234},
}

@article{schegloff_harvey_1989,
	title = {Harvey {Sacks}-{Lectures} 1964-1965: {An} {Introduction}/{Memoir}},
	volume = {12},
	issn = {01638548},
	shorttitle = {Harvey {Sacks}-{Lectures} 1964-1965},
	url = {http://www.jstor.org/stable/20009056},
	number = {3/4},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Schegloff, Emanuel A.},
	month = dec,
	year = {1989},
	note = {ArticleType: primary\_article / Issue Title: Harvey Sacks Lectures 1964-1965 / Full publication date: Dec., 1989 / Copyright © 1989 Springer},
	pages = {185--209},
}

@article{schegloff_presequences_1988,
	title = {Presequences and indirection: {Applying} speech act theory to ordinary conversation},
	volume = {12},
	issn = {0378-2166},
	shorttitle = {Presequences and indirection},
	url = {http://www.sciencedirect.com/science/article/pii/0378216688900197},
	doi = {10.1016/0378-2166(88)90019-7},
	abstract = {This paper contrasts the analysis provided by speech act theory for utterances of the form “Do you know + [embedded WH-question]” with the analysis demonstrably arrived at by participants in actual ordinary conversations. The analyses are found to diverge with respect both to the sets of alternative interpretations accorded the utterances and the priorities attributed to them. This result is related to the disattention in speech act theory to the temporal and sequential properties of talk-in-interaction.},
	number = {1},
	urldate = {2011-12-06},
	journal = {Journal of Pragmatics},
	author = {Schegloff, Emanuel A.},
	month = feb,
	year = {1988},
	pages = {55--62},
}

@article{schegloff_description_1988,
	title = {Description in the social sciences {I}: {Talk}-in-interaction},
	volume = {2},
	shorttitle = {Description in the social sciences {I}},
	number = {1/2},
	journal = {IPrA Papers in Pragmatics},
	author = {Schegloff, Emanuel A.},
	year = {1988},
	pages = {1--24},
}

@article{schegloff_analyzing_1987,
	title = {Analyzing {Single} {Episodes} of {Interaction}: {An} {Exercise} in {Conversation} {Analysis}},
	volume = {50},
	issn = {01902725},
	shorttitle = {Analyzing {Single} {Episodes} of {Interaction}},
	url = {http://www.jstor.org/stable/2786745},
	doi = {10.2307/2786745},
	abstract = {A variety of analytic resources provided by past work in conversation analysis are brought to bear on the analysis of a single utterance in its sequential context, drawn from an ordinary conversation. Various facets of the organization of talk-in-interaction are thereby both introduced and exemplified. The result displays the capacity of this analytic modality to meet a fundamental responsibility of social analysis, namely the capacity to explicate single episodes of action in interaction as a basic locus of social order.},
	number = {2},
	urldate = {2009-05-27},
	journal = {Social Psychology Quarterly},
	author = {Schegloff, Emanuel A.},
	month = jun,
	year = {1987},
	note = {ArticleType: primary\_article / Issue Title: Special Issue: Language and Social Interaction / Full publication date: Jun., 1987 / Copyright © 1987 American Sociological Association},
	pages = {101--114},
}

@article{schegloff_sources_1987,
	title = {Some sources of misunderstanding in talk-in-interaction},
	volume = {25},
	issn = {0024-3949},
	url = {http://www.reference-global.com/doi/abs/10.1515/ling.1987.25.1.201},
	doi = {10.1515/ling.1987.25.1.201},
	number = {1},
	urldate = {2010-07-25},
	journal = {Linguistics},
	author = {Schegloff, Emanuel A.},
	month = jan,
	year = {1987},
	pages = {201--218},
}

@article{schegloff_routine_1986,
	title = {The {Routine} as {Achievement}},
	volume = {9},
	issn = {01638548},
	url = {http://www.jstor.org/stable/20008964},
	number = {2/3},
	urldate = {2010-04-24},
	journal = {Human Studies},
	author = {Schegloff, Emanuel A.},
	year = {1986},
	note = {ArticleType: primary\_article / Issue Title: Interaction and Language Use / Full publication date: 1986 / Copyright © 1986 Springer},
	pages = {111--151},
}

@incollection{schegloff_gestures_1984,
	address = {Cambridge / New York Paris},
	series = {Studies in {Emotion} and {Social} {Interaction}},
	title = {On {Some} {Gestures}' {Relation} to {Talk}},
	booktitle = {Structures of {Social} {Action} {Studies} in {Conversation} {Analysis}},
	publisher = {Cambridge University Press Editions de la Maison des sciences de l'homme},
	author = {Schegloff, Emanuel A.},
	editor = {Atkinson, J. M. and Heritage, John},
	year = {1984},
	keywords = {gesture},
	pages = {266--296},
}

@inproceedings{schegloff_what_1980,
	title = {What {Type} of {Interaction} {Is} {It} to {Be}},
	url = {http://www.aclweb.org/anthology/P80-1021},
	urldate = {2016-06-21},
	booktitle = {{ACL}},
	author = {Schegloff, Emanuel A.},
	year = {1980},
}

@article{schegloff_preliminaries_1980,
	title = {Preliminaries to {Preliminaries}: “{Can} {I} {Ask} {You} a {Question}?”},
	volume = {50},
	issn = {1475-682X},
	shorttitle = {Preliminaries to {Preliminaries}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1475-682X.1980.tb00018.x/abstract},
	doi = {10.1111/j.1475-682X.1980.tb00018.x},
	language = {en},
	number = {3-4},
	urldate = {2013-05-07},
	journal = {Sociological Inquiry},
	author = {Schegloff, Emanuel A.},
	year = {1980},
	pages = {104--152},
}

@incollection{schegloff_notes_1972,
	address = {New York},
	title = {Notes on a conversational practice: {Formulating} place},
	shorttitle = {Notes on a conversational practice},
	booktitle = {Studies in {Social} {Interaction}},
	publisher = {MacMillan/The Free Press},
	author = {Schegloff, Emanuel A.},
	editor = {Sudnow, David N.},
	year = {1972},
	pages = {75--119},
}

@article{schegloff_sequencing_1968,
	series = {New {Series}},
	title = {Sequencing in {Conversational} {Openings}},
	volume = {70},
	issn = {00027294},
	url = {http://www.jstor.org/stable/669510},
	abstract = {An attempt is made to ascertain rules for the sequencing of a limited part of natural conversation and to determine some properties and empirical consequences of the operation of those rules. Two formulations of conversational openings are suggested and the properties "nonterminality" and "conditional relevance" are developed to explicate the operation of one of them and to suggest some of its interactional consequences. Some discussion is offered of the fit between the sequencing structure and the tasks of conversational openings.},
	number = {6},
	urldate = {2010-04-24},
	journal = {American Anthropologist},
	author = {Schegloff, Emanuel A.},
	month = dec,
	year = {1968},
	note = {ArticleType: primary\_article / Full publication date: Dec., 1968 / Copyright © 1968 American Anthropological Association},
	pages = {1075--1095},
}

@phdthesis{schegloff_first_1967,
	address = {California},
	type = {{PhD} dissertation},
	title = {The first five seconds: the order of conversational openings},
	school = {University of California, Berkeley},
	author = {Schegloff, Emanuel A.},
	year = {1967},
	note = {Ph.D.},
}

@incollection{atkinson_questions_1984,
	address = {Cambridge},
	series = {Studies in emotion and social interaction},
	title = {On some questions and ambiguities in conversation},
	isbn = {0-521-24815-9},
	booktitle = {Structures of {Social} {Action}: {Studies} in {Conversation} {Analysis}},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Atkinson, J. Maxwell and Heritage, John},
	year = {1984},
	keywords = {conversation analysis, important, narrative},
	pages = {28--52},
}

@incollection{schegloff_discourse_1982,
	address = {Washington DC},
	title = {Discourse as {Interactional} {Achievement}: {Some} {Uses} of 'uh huh' and {Other} {Things} {That} {Come} {Between} {Sentences}},
	booktitle = {Analyzing {Discourse}: {Text} and {Talk}},
	publisher = {Georgetown University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Tannen, Deborah},
	year = {1982},
	keywords = {conversation analysis},
	pages = {71--93},
}

@book{gilbert_joint_2014,
	address = {New York, NY},
	title = {Joint commitment: how we make the social world},
	isbn = {978-0-19-997014-8},
	shorttitle = {Joint commitment},
	publisher = {Oxford University Press},
	author = {Gilbert, Margaret},
	year = {2014},
}

@article{dingemanse_why_2020,
	title = {Why language remains the most flexible brain-to-brain interface},
	shorttitle = {The space between our heads},
	url = {https://aeon.co/essays/why-language-remains-the-most-flexible-brain-to-brain-interface},
	journal = {Aeon},
	author = {Dingemanse, Mark},
	month = aug,
	year = {2020},
	note = {doi:10.5281/zenodo.4014750},
	keywords = {language\_en, publist, publist\_main, publist\_scicomm},
}

@article{skedsmo_other-initiations_2020,
	title = {Other-initiations of repair in {Norwegian} {Sign} {Language}},
	volume = {3},
	copyright = {Copyright (c) 2020 Author and Journal},
	issn = {2446-3620},
	doi = {10.7146/si.v3i2.117723},
	abstract = {During the last five decades, a substantial amount of research has been conducted into conversational repair (Schegloff, Jefferson, \& Sacks, 1977), and especially other-initiation of repair (OIR). A vast part of the research has been on spoken English, without considering or having access to embodied practices. Through a series of examples, this explorative paper provides a brief overview of formats and subtypes of other-initiation of self-repair employed in Norwegian Sign Language (NTS). Special attention is given to the implicit open-class repair-initiation “freeze-look”, as identified by Manrique (2016), Manrique and Enfield (2015), and Manrique, Enfield, Levinson, Crasborn, and Floyd (2017) in Argentine Sign Language, and to the subtype of restricted repair-initiations categorized as candidate offers. The data has been extracted from a corpus of informal multi-person conversations among deaf adult co-workers, recorded at their workplaces.
The results show a high degree of overlap with formats found in spoken languages, but also highlight features that seem to be unique to signed languages and the visual mode of communication. The examples presented take the form of summaries, transcriptions, uncensored video clips, and series of stills.},
	language = {en},
	number = {2},
	journal = {Social Interaction. Video-Based Studies of Human Sociality},
	author = {Skedsmo, Kristian},
	month = aug,
	year = {2020},
	note = {Number: 2},
}

@article{ruhlemann_turn_2020,
	title = {Turn structure and inserts},
	volume = {25},
	issn = {1384-6655, 1569-9811},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ijcl.19098.ruh},
	doi = {10.1075/ijcl.19098.ruh},
	abstract = {Abstract Turns-at-talk often do not start with their main business but rather with a pre-start (Sacks et al., 1974). This paper investigates the correlation of pre-starts with inserts, one of three major word classes (Biber et al., 1999). Based on the BNC’s mark-up, I investigate how inserts are positionally distributed in large amounts of turns of varied lengths. The analysis shows that inserts are overwhelmingly attracted to turn-first positions, the likely location of pre-starts. Further, in a subsample of 1,000 ten-word turns manually coded for pre-starts, 86\% of all inserts serve a pre-start function. The findings call into question current speech processing models that fail to factor in turn structure. Further, pre-starts have crucial sequential and interactional implications as early indicators whether the new turn “agrees” with the prior turn and are likely key signals aiding listeners’ action ascription.},
	language = {en},
	number = {2},
	urldate = {2020-09-03},
	journal = {International Journal of Corpus Linguistics},
	author = {Rühlemann, Christoph},
	month = aug,
	year = {2020},
	note = {Publisher: John Benjamins},
	pages = {185--214},
}

@book{wilson_consilience_1998,
	address = {New York},
	edition = {1st ed},
	title = {Consilience: the unity of knowledge},
	isbn = {978-0-679-45077-1},
	shorttitle = {Consilience},
	publisher = {Knopf : Distributed by Random House},
	author = {Wilson, Edward O.},
	year = {1998},
}

@article{painter_m_1975,
	title = {/m hm/, /!m !m/ and {Some} {Forms} of {Yes} and {No} in {Gwa}},
	volume = {17},
	issn = {0003-5483},
	url = {https://www.jstor.org/stable/30027272},
	number = {1},
	urldate = {2020-09-10},
	journal = {Anthropological Linguistics},
	author = {Painter, Colin},
	year = {1975},
	note = {Publisher: [Anthropological Linguistics, Trustees of Indiana University]},
	pages = {19--23},
}

@book{stokoe_talk_2020,
	address = {Place of publication not identified},
	title = {Talk: the science of conversation},
	isbn = {978-1-4721-4083-8},
	shorttitle = {{TALK}},
	language = {English},
	publisher = {ROBINSON},
	author = {Stokoe, Elizabeth},
	year = {2020},
	note = {OCLC: 1100599772},
}

@incollection{lionnet_paralinguistic_2020,
	title = {Paralinguistic {Use} of {Clicks} in {Chad}},
	abstract = {This chapter gives a preliminary phonetic and pragmatic description of four clicks used as verbal gestures in Laal, a language isolate of southern Chad whose regular phonemic inventory does not include click consonants. The four clicks are: dental, lateral, back-released velar, and a bilabial-alveolar/lateral click known as “tchip” in the francophone African diaspora, “suck-teeth” in African American communities. The first three have both affective and logical (yes/no, backchannel) uses, while the last one is only affective. These clicks, or variants thereof, seem to be attested in a vast region extending at least from the Atlantic coast to Chad and Cameroon. A preliminary comparison with similar clicks in Wolof is given, showing both strong similarities and systematic differences.},
	language = {en},
	booktitle = {Click {Consonants}},
	author = {Lionnet, Florian},
	editor = {Sands, Bonny},
	month = sep,
	year = {2020},
	note = {doi:10.1163/9789004424357\_015},
	pages = {422--437},
}

@incollection{ginzburg_lexical_2007,
	address = {London},
	title = {Lexical {Acquisition} with and without {Metacommunication}},
	isbn = {978-1-84628-779-4},
	url = {https://doi.org/10.1007/978-1-84628-779-4_15},
	abstract = {A central concern of work on the evolution of language has been to offer an account for the emergence of syntactically complex structure, which underwrites a compositional semantics. In this chapter we consider the emergence of one class of utterances which illustrate that semantic expressiveness is not correlated with syntactic complexity, namely metacommunicative interaction (MCI) utterances. These are utterance acts in which conversationalists acknowledge understanding or request clarification. We offer a simple characterisation of the incremental change required for MCI to emerge from an MCI-less linguistic interaction system. This theoretical setting underpins and motivates the development of an ALife environment in which the lexicon dynamics of populations that possess and lack MCI capabilities are compared.},
	language = {en},
	urldate = {2020-10-08},
	booktitle = {Emergence of {Communication} and {Language}},
	publisher = {Springer},
	author = {Ginzburg, Jonathan and Macura, Zoran},
	editor = {Lyon, Caroline and Nehaniv, Chrystopher L. and Cangelosi, Angelo},
	year = {2007},
	doi = {10.1007/978-1-84628-779-4_15},
	pages = {287--303},
}

@book{ginzburg_interactive_2012,
	address = {Oxford ; New York},
	title = {The interactive stance: meaning for conversation},
	isbn = {978-0-19-969792-2},
	shorttitle = {The interactive stance},
	publisher = {Oxford University Press},
	author = {Ginzburg, Jonathan},
	year = {2012},
	note = {OCLC: ocn742512011},
}

@article{chlebowski_semasiological_2020,
	title = {A {Semasiological} {Approach} to {Non}-{Lexical} {Conversational} {Sounds}: {Issues}, {Benefits} and {Impact}},
	copyright = {Copyright (c) 2020 Laughter and Other Non-Verbal Vocalisations Workshop: Proceedings (2020)},
	shorttitle = {A {Semasiological} {Approach} to {Non}-{Lexical} {Conversational} {Sounds}},
	url = {https://biecoll.ub.uni-bielefeld.de/index.php/lw2020/article/view/911},
	doi = {10.4119/lw2020-911},
	abstract = {This paper proposes to consider a semasiological approach to non-verbal vocalisations. We claim that an acoustic analysis of the components of these sounds is needed to complement the findings of earlier studies. We propose that part of the information conveyed by these sounds comes from their acoustic components and that these components might be subjected to what resembles grammatical rules. Semantic issues are discussed at the end of the paper.},
	language = {en},
	urldate = {2020-10-13},
	journal = {Laughter and Other Non-Verbal Vocalisations Workshop: Proceedings (2020)},
	author = {Chlébowski, Aurélie},
	month = oct,
	year = {2020},
}

@article{fodor_why_1999,
	title = {Why the brain?},
	volume = {21},
	issn = {0260-9592},
	shorttitle = {Jerry {Fodor} · {Diary}},
	url = {https://www.lrb.co.uk/the-paper/v21/n19/jerry-fodor/diary},
	language = {en},
	number = {19},
	urldate = {2020-10-22},
	journal = {London Review of Books},
	author = {Fodor, Jerry},
	month = sep,
	year = {1999},
}

@book{schutz_collected_1982,
	title = {Collected papers. {I}. {The} {Problem} of {Social} {Reality}},
	isbn = {978-94-010-2851-6},
	url = {http://public.ebookcentral.proquest.com/choice/publicfullrecord.aspx?p=3109642},
	language = {Preface in French and English.},
	urldate = {2020-10-29},
	author = {Schutz, Alfred},
	editor = {Natanson, Maurice and Breda, H. L. van},
	year = {1982},
	note = {OCLC: 958530027},
}

@book{schutz_collected_1964,
	address = {Dordrecht},
	title = {Collected {Papers} {II}: {Studies} in {Social} {Theory}},
	isbn = {978-94-010-1340-6},
	shorttitle = {Collected {Papers} {II}},
	url = {https://doi.org/10.1007/978-94-010-1340-6},
	language = {English},
	urldate = {2020-10-29},
	publisher = {Springer Netherlands},
	author = {Schutz, Alfred},
	editor = {Brodersen, Arvid},
	year = {1964},
	note = {OCLC: 851393697},
}

@article{ginzburg_laughter_2020,
	title = {Laughter as language},
	volume = {5},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2397-1835},
	url = {http://www.glossa-journal.org//articles/10.5334/gjgl.1152/},
	doi = {10.5334/gjgl.1152},
	abstract = {Understanding the import of laughter, has interested philosophers and literary scholars for millennia and, more recently, psychologists, biologists, neuroscientists, and linguists. However, the assumption has been that laughter lacks meaning akin to what words and phrases possess and that it does not contribute to the compositional construction of meaning. In this paper, we argue that, in fact, laughter (and other non-verbal social signals like smiling, sighing, frowning) has propositional content—it involves reference to external real world events, has stand alone meanings, and participates in semantic and pragmatic processes like repair, implicature, and irony. We show how to develop a formal semantic and pragmatic account of laughter embedded in a general theory of conversational interaction and emotional reasoning and show how to explain the wide, indeed in principle unbounded range of uses laughter exhibits. We show how our account can be extended to other non-verbal social signals like smiling, sighing, eye rolling, and frowning. Should laughter and its ilk be incorporated in the grammar? We suggest that they probably should be, if one assumes a conversationally–oriented view of grammar. But various open issues remain.},
	language = {en},
	number = {1},
	urldate = {2020-11-05},
	journal = {Glossa: a journal of general linguistics},
	author = {Ginzburg, Jonathan and Mazzocconi, Chiara and Tian, Ye},
	month = nov,
	year = {2020},
	note = {Number: 1
Publisher: Ubiquity Press},
	pages = {104},
}

@inproceedings{kosmala_preliminary_2017,
	address = {Stockholm, Sweden},
	title = {A preliminary study of hesitation phenomena in {L1} and {L2} productions: a multimodal approach},
	shorttitle = {A preliminary study of hesitation phenomena in {L1} and {L2} productions},
	url = {https://hal.archives-ouvertes.fr/hal-02360610},
	abstract = {This paper presents a preliminary study of vocal hesitations in L1 and L2 productions using a multimodal perspective. It investigates the use of vocal hesitations of French learners of English interacting in tandem with American speakers in semi-spontaneous speech. Several hesitation markers were analyzed (filled pauses, unfilled pauses, prolongations and non-lexical sounds) based on formal and functional features as well as their relation to gesture. Results do not show great differences in the frequency of vocal hesitations between L1 and L2 productions overall; however, we find differences in duration and combination complexity. Our study indicated that vocal hesitations mainly served planning functions and were very often accompanied with gaze aversion both in L1 and L2 productions. Moreover, speakers did not tend to gesture while hesitating. We conclude that hesitations mainly served planning strategies both in L1 and L2 speech, but with some differences in duration and complexity.},
	urldate = {2020-11-06},
	booktitle = {Disfluency in {Spontaneous} {Speech} 2017},
	author = {Kosmala, Loulou and Morgenstern, Aliyah},
	year = {2017},
}

@incollection{kosmala_should_2018,
	title = {Should 'uh' and 'um' be categorized as markers of disfluency? {The} use of fillers in a challenging conversational context},
	shorttitle = {Should 'uh' and 'um' be categorized as markers of disfluency?},
	url = {https://hal.archives-ouvertes.fr/hal-02360614},
	abstract = {This paper examines the use of 'uh' and 'um' in spontaneous speech. 'Uh' and 'um' have traditionally been labeled as markers of disfluency, and in question-answering, they are commonly said to reflect uncertainty, due to the unfamiliarity or difficulty of the questions. Our proposal is that fillers do not necessarily reflect difficulty and speech disruption. Our study consists of an experiment in which participants were asked questions about a film in a conversational setting. After the experiment, participants were invited to rate the "difficulty" of the questions they had been asked. Findings indicate that they did not often produce fillers when they found the questions "difficult" as little relation between the rate of fillers and the perceived difficulty of the questions was found. Fillers mainly occurred in initial position and served planning functions. This confirms (Tottie 2011) that fillers are predominantly used to buy time in conversation and reflect planning processes.},
	urldate = {2020-11-06},
	booktitle = {Fluency and {Disfluency} across {Languages} and {Language} {Varieties}},
	author = {Kosmala, Loulou and Morgenstern, Aliyah},
	year = {2018},
}

@article{kosmala_euh_2020,
	title = {Euh le saviez-vous ? le rôle des (dis)fluences en contexte interactionnel : étude exploratoire et qualitative},
	volume = {78},
	copyright = {© The Authors, published by EDP Sciences 2020},
	issn = {2261-2424},
	shorttitle = {Euh le saviez-vous ?},
	url = {https://www.shs-conferences.org/articles/shsconf/abs/2020/06/shsconf_cmlf2020_01018/shsconf_cmlf2020_01018.html},
	doi = {10.1051/shsconf/20207801018},
	abstract = {Cette étude exploratoire s’inscrit dans un projet d’analyse des (dis)fluences sur un corpus français oral spontané et préparé qui prend en compte les différentes modalités du discours (linguistique, vocal, visuel, gestuel) et qui s’inscrit dans une perspective de linguistique interactionnelle. Les (dis)fluences, caractérisées par une interruption du flux verbal et vocal, ont souvent été strictement analysées du point de vue de la production, et cette étude a pour objectif de dépasser cette approche formelle et de rendre compte de leur ambivalence fonctionnelle et de leur contribution à l’interaction. L’analyse porte sur une paire de locuteurs du corpus, et les résultats préliminaires indiquent un taux de (dis)fluence plus élevé en contexte de discours préparé en classe qu’en conversation semi-spontanée, ce qui servira de point de départ pour de futures analyses quantitatives plus détaillées sur l’ensemble des données. Cet article repose sur des analyses qualitatives fines d’un extrait de séquence narrative humoristique qui soulignent la dimension interactionnelle des (dis)fluences et la manière dont elles peuvent être employées par les locuteurs à des fins discursives et rhétoriques dans le cadre de tâche narrative.},
	language = {en},
	urldate = {2020-11-06},
	journal = {SHS Web of Conferences},
	author = {Kosmala, Loulou},
	year = {2020},
	note = {Publisher: EDP Sciences},
	pages = {01018},
}

@inproceedings{betz_fill_2019,
	title = {Fill the silence! {Basics} for modeling hesitation},
	doi = {10.21862/diss-09-004-betz-kosm},
	abstract = {In order to model hesitations for technical applications such as conversational speech synthesis, it is desirable to understand interactions between individual hesitation markers. In this study, we explore a pair of markers that has been subject to many discussions: silences and fillers. While it is generally acknowledged that fillers occur in two distinct forms, um and uh, it is not agreed on whether these forms systematically influence the form of associated silences. This notion will be investigated on a small dataset of English spontaneous speech data and the measure of distance between filler and silence will be introduced to the analyses. Results suggest that filler type influences associated silence duration systematically and that silences tend to gravitate towards fillers in utterances, exhibiting systematically lower duration when preceding them. These results provide valuable insights for improving existing hesitation models.},
	author = {Betz, Simon and Kosmala, Loulou},
	year = {2019},
}

@book{hofstadter_surfaces_2013,
	address = {New York},
	title = {Surfaces and essences: analogy as the fuel and fire of thinking},
	isbn = {978-0-465-01847-5},
	shorttitle = {Surfaces and essences},
	publisher = {Basic Books},
	author = {Hofstadter, Douglas R. and Sander, Emmanuel},
	year = {2013},
	note = {OCLC: ocn632081685},
}

@article{hofstede_interjectie_1999,
	title = {De {Interjectie} als {Illocutionaire} {Handeling}},
	volume = {61},
	issn = {0169-7420, 2213-4883},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ttwia.61.11hof},
	doi = {10.1075/ttwia.61.11hof},
	abstract = {The purpose of this paper is to give an answer to the question if an illocutionary act can be performed with an interjection. Therefore a method of analysis was designed which consists of four elements viz.: determining the communicative function, defining the semantic content, recovering the propositional content and classifying the interjections in the taxonomy of illocutionary acts. Interjections taken from everyday conversations were analysed and the results show that with every interjection uttered, an illoctionary act was performed. These results contradict the commonly held view that interjections are not real words, but merely sounds to give expression to our feelings.},
	language = {en},
	number = {1},
	urldate = {2020-11-24},
	journal = {Toegepaste Taalwetenschap in Artikelen},
	author = {Hofstede, Gerard},
	month = jan,
	year = {1999},
	note = {Publisher: John Benjamins},
	pages = {127--135},
}

@article{koudenburg_beyond_2016,
	title = {Beyond {Content} of {Conversation}: {The} {Role} of {Conversational} {Form} in the {Emergence} and {Regulation} of {Social} {Structure}},
	copyright = {© 2016 by the Society for Personality and Social Psychology, Inc},
	shorttitle = {Beyond {Content} of {Conversation}},
	url = {https://journals.sagepub.com/doi/10.1177/1088868315626022},
	doi = {10.1177/1088868315626022},
	abstract = {Social interaction is pivotal to the formation of social relationships and groups. Much is known about the importance of interaction content (e.g., the transfer...},
	language = {en},
	urldate = {2020-11-24},
	journal = {Personality and Social Psychology Review},
	author = {Koudenburg, Namkje and Postmes, Tom and Gordijn, Ernestine H.},
	month = feb,
	year = {2016},
	note = {Publisher: SAGE PublicationsSage CA: Los Angeles, CA},
}

@article{wilson_oscillator_2005,
	title = {An oscillator model of the timing of turn-taking},
	volume = {12},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/BF03206432},
	doi = {10.3758/BF03206432},
	abstract = {When humans talk without conventionalized arrangements, they engage in conversation—that is, a continuous and largely nonsimultaneous exchange in which speakers take turns. Turn-taking is ubiquitous in conversation and is the normal case against which alternatives, such as interruptions, are treated as violations that warrant repair. Furthermore, turn-taking involves highly coordinated timing, including a cyclic rise and fall in the probability of initiating speech during brief silences, and involves the notable rarity, especially in two-party conversations, of two speakers’ breaking a silence at once. These phenomena, reported by conversation analysts, have been neglected by cognitive psychologists, and to date there has been no adequate cognitive explanation. Here, we propose that, during conversation, endogenous oscillators in the brains of the speaker and the listeners become mutually entrained, on the basis of the speaker’s rate of syllable production. This entrained cyclic pattern governs the potential for initiating speech at any given instant for the speaker and also for the listeners (as potential next speakers). Furthermore, the readiness functions of the listeners are counterphased with that of the speaker, minimizing the likelihood of simultaneous starts by a listener and the previous speaker. This mutual entrainment continues for a brief period when the speech stream ceases, accounting for the cyclic property of silences. This model not only captures the timing phenomena observed in the literature on conversation analysis, but also converges with findings from the literatures on phoneme timing, syllable organization, and interpersonal coordination.},
	language = {en},
	number = {6},
	urldate = {2020-12-17},
	journal = {Psychonomic Bulletin \& Review},
	author = {Wilson, Margaret and Wilson, Thomas P.},
	month = dec,
	year = {2005},
	pages = {957--968},
}

@book{jakobson_main_1973,
	address = {London},
	series = {Main trends in the social sciences ; 6},
	title = {Main trends in the science of language},
	isbn = {978-0-04-400023-5},
	publisher = {Allen and Unwin},
	author = {Jakobson, Roman},
	year = {1973},
}

@book{berlin_hedgehog_1953,
	address = {New York},
	title = {The hedgehog and the fox: an essay on {Tolstoy}'s view of history},
	shorttitle = {The hedgehog and the fox},
	publisher = {Simon \& Schuster},
	author = {Berlin, Isaiah},
	year = {1953},
}

@article{bender_linguistic_2016,
	title = {Linguistic typology in natural language processing},
	volume = {20},
	issn = {1613-415X, 1430-0532},
	doi = {10.1515/lingty-2016-0035},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d154e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}This paper explores the ways in which the field of natural language processing (NLP) can and does benefit from work in linguistic typology. I describe the recent increase in interest in multilingual natural language processing and give a high-level overview of the field. I then turn to a discussion of how linguistic knowledge in general is incorporated in NLP technology before describing how typological results in particular are used. I consider both rule-based and machine learning approaches to NLP and review literature on predicting typological features as well as that which leverages such features.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {3},
	urldate = {2021-01-06},
	journal = {Linguistic Typology},
	author = {Bender, Emily M.},
	month = dec,
	year = {2016},
	note = {Publisher: De Gruyter Mouton
Section: Linguistic Typology},
	pages = {645--660},
}

@book{ayres-bennett_women_2020,
	address = {New York},
	title = {Women in the history of linguistics},
	isbn = {978-0-19-875495-4},
	abstract = {"In Classical Antiquity, the study of language and literature was a crucial part of education. Girls generally only took part of primary education, and women who progressed further did so by private tuition. Women were expected to be married and produce children and to practice their virtue in the traditional role of the wife and mother. Many women were well read in both Latin and Greek literature, and some twenty female poets are known from antiquity. However, women lacked training in formal rhetorical skills, because they were expected to speak and write in a different style. Nor were women supposed to enter into the places where public lectures took place. All the same, we know of women who received higher education and even taught philosophy (probably in private houses) or occupied themselves with philology. The women philosophers were normally born into philosophic households or married to philosophers. When grammar - a discipline dealing with language and literature - gradually became an independent subject in the first century BC, it was taught in secondary schools. From the first century AD on we can get glimpses of female teachers of letters, but their achievements were not recorded. Thus, we have neither grammatical nor philosophical doctrine attributed to a female scholar, and this article deals with the general conditions of women scholars rather than their individual contributions to scholarship. Many prejudices prevailed concerning the inferiority of women. Aristotle thought that women were weaker than men not only physically but also intellectually. This remained common consensus, even if the Stoics and Platonists argued that women's souls are not as such inferior to the souls of men. The Christians reinforced these prejudices, although they thought that men and women share a common human nature. Yet the Apostle Paul had said 'I do not permit a woman to teach' (I Tim. 2: 12). However, Christian women could refuse marriage and follow an ascetic life, which brought about new opportunities for them as prophets, deaconesses, patrons and occasionally even as teachers"--},
	publisher = {Oxford University Press},
	editor = {Ayres-Bennett, Wendy and Sanson, Helena},
	year = {2020},
}

@incollection{copeland_linguistics_1984,
	address = {Houston, Tex},
	edition = {1st ed},
	series = {New series},
	title = {Linguistics in the {University}: {The} {Question} of {Social} {Accountability}},
	isbn = {978-0-89263-253-4},
	number = {no. 2},
	booktitle = {New {Directions} in {Linguistics} and {Semiotics}},
	publisher = {Rice University Studies},
	author = {Halliday, M. A. K.},
	editor = {Copeland, James E.},
	year = {1984},
	keywords = {classic, need to read},
	pages = {51--67},
}

@article{dale_explanatory_2009,
	title = {Explanatory {Pluralism} in {Cognitive} {Science}},
	volume = {33},
	issn = {03640213},
	url = {http://doi.wiley.com/10.1111/j.1551-6709.2009.01042.x},
	doi = {10.1111/j.1551-6709.2009.01042.x},
	abstract = {This brief commentary has three goals. The ﬁrst is to argue that ‘‘framework debate’’ in cognitive science is unresolvable. The idea that one theory or framework can singly account for the vast complexity and variety of cognitive processes seems unlikely if not impossible. The second goal is a consequence of this: We should consider how the various theories on offer work together in diverse contexts of investigation. A ﬁnal goal is to supply a brief review for readers who are compelled by these points to explore existing literature on the topic. Despite this literature, pluralism has garnered very little attention from broader cognitive science. We end by brieﬂy considering what it might mean for theoretical cognitive science.},
	language = {en},
	number = {5},
	urldate = {2021-01-19},
	journal = {Cognitive Science},
	author = {Dale, Rick and Dietrich, Eric and Chemero, Anthony},
	month = jul,
	year = {2009},
	pages = {739--742},
}

@article{van_paridon_subs2vec_2020,
	title = {subs2vec: {Word} embeddings from subtitles in 55 languages},
	issn = {1554-3528},
	shorttitle = {subs2vec},
	url = {https://doi.org/10.3758/s13428-020-01406-3},
	doi = {10.3758/s13428-020-01406-3},
	abstract = {This paper introduces a novel collection of word embeddings, numerical representations of lexical semantics, in 55 languages, trained on a large corpus of pseudo-conversational speech transcriptions from television shows and movies. The embeddings were trained on the OpenSubtitles corpus using the fastText implementation of the skipgram algorithm. Performance comparable with (and in some cases exceeding) embeddings trained on non-conversational (Wikipedia) text is reported on standard benchmark evaluation datasets. A novel evaluation method of particular relevance to psycholinguists is also introduced: prediction of experimental lexical norms in multiple languages. The models, as well as code for reproducing the models and all analyses reported in this paper (implemented as a user-friendly Python package), are freely available at: https://github.com/jvparidon/subs2vec.},
	language = {en},
	urldate = {2021-01-19},
	journal = {Behavior Research Methods},
	author = {van Paridon, Jeroen and Thompson, Bill},
	month = aug,
	year = {2020},
}

@book{carroll_alices_2009,
	address = {New York},
	edition = {New ed},
	series = {Oxford world's classics},
	title = {Alice's adventures in {Wonderland}: and, {Through} the looking-glass and what {Alice} found there},
	isbn = {978-0-19-955829-2},
	shorttitle = {Alice's adventures in {Wonderland}},
	publisher = {Oxford University Press},
	author = {Carroll, Lewis and Hunt, Peter and Tenniel, John and Carroll, Lewis},
	year = {2009},
}

@book{watson_text_1992,
	address = {Newbury Park},
	series = {Sage focus editions},
	title = {Text in context: contributions to ethnomethodology},
	isbn = {978-0-8039-4253-0 978-0-8039-4254-7},
	shorttitle = {Text in context},
	number = {132},
	publisher = {Sage Publications},
	editor = {Watson, Graham and Seiler, R. M.},
	year = {1992},
}

@incollection{watson_life_1992,
	address = {Newbury Park},
	series = {Sage focus editions},
	title = {Life {After} {C}.{A}.: {An} {Ethnographer}'s {Autobiography}},
	isbn = {978-0-8039-4253-0 978-0-8039-4254-7},
	number = {132},
	booktitle = {Text in context: contributions to ethnomethodology},
	publisher = {Sage Publications},
	author = {Moerman, Michael},
	editor = {Watson, Graham and Seiler, R. M.},
	year = {1992},
	keywords = {*need to read},
}

@book{boden_mind_2008,
	address = {Oxford},
	title = {Mind as machine: a history of cognitive science},
	isbn = {978-0-19-954316-8},
	shorttitle = {Mind as machine},
	language = {English},
	publisher = {Oxford University Press},
	author = {Boden, Margaret},
	year = {2008},
	note = {OCLC: 868280210},
}

@article{coates_turn-taking_2001,
	title = {Turn-taking patterns in deaf conversation},
	volume = {5},
	copyright = {Blackwell Publishers Ltd 2001},
	issn = {1467-9841},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9481.00162},
	doi = {https://doi.org/10.1111/1467-9481.00162},
	abstract = {This paper will focus on the turn-taking patterns of Deaf signers and will compare them with turn-taking patterns found in spoken interaction. Turn-taking in the conversation of hearing people has been the subject of considerable attention, but the way conversation is organised by Deaf conversationalists has received less attention. This paper reports on a small project involving conversational data obtained from two Deaf friendship groups, one all-female and one all-male. Our main aim was to establish whether Deaf interactants orient to a one-at-a-time model of turn-taking, or whether there was any evidence to suggest they can also orient to a more collaborative model. It has been assumed by researchers in the field of Deaf Studies that Deaf interactants orient to a one-at-a-time model since, where the medium of communication is visual rather than sound based, participants can attend to only those sources of talk that they can see. The paper also examines the data to see if there are any gender differences in the way Deaf interactants organise conversation.},
	language = {en},
	number = {4},
	urldate = {2021-02-24},
	journal = {Journal of Sociolinguistics},
	author = {Coates, Jennifer and Sutton‐Spence, Rachel},
	year = {2001},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9481.00162},
	pages = {507--529},
}

@incollection{sidnell_division_2020,
	title = {On the division of intersubjective labor in interaction: a preliminary study of otherinitiated repair in {Vietnamese} conversation},
	language = {en},
	booktitle = {Studies in the {Anthropology} of {Language} in {Mainland} {Southeast} {Asia}},
	publisher = {University of Hawai'i Press},
	author = {Sidnell, Jack and Tràn, An Thùy and Vu, Hương Thị Thanh},
	editor = {Enfield, N. J. and Sidnell, Jack and Zuckerman, Charles H. P.},
	year = {2020},
	pages = {147},
}

@article{stivers_is_2021,
	title = {Is {Conversation} {Built} for {Two}? {The} {Partitioning} of {Social} {Interaction}},
	volume = {54},
	issn = {0835-1813},
	shorttitle = {Is {Conversation} {Built} for {Two}?},
	url = {https://doi.org/10.1080/08351813.2020.1864158},
	doi = {10.1080/08351813.2020.1864158},
	abstract = {Conversation is flexible enough to be conducted with varying numbers of individuals, but most conversation is dyadic. Is the prevalence of dyadic focal participation frameworks facilitated by structures of conversation? Using video recordings of spontaneous naturally occurring conversations, I explore multiperson interactions focusing on how structures of turn taking, sequence organization, storytelling, and speaker gaze facilitate or inhibit the inclusion of multiple individuals in conversation. As I show, because our system favors dyadic participation through turn allocation and sequence organization, sustaining focal triadic or multiparty participation frameworks requires more interactional work than sustaining a dyadic focal participation framework. However, serially dyadic participation, which keeps dyads shifting, and story- and joke telling facilitate the participation of multiple individuals. Although conversational structures can be adapted to partition focal participation as dyadic or multiparty on a moment-by-moment basis, the structures generally facilitate dyadic focal participation. Data are in American English.},
	number = {1},
	urldate = {2021-03-02},
	journal = {Research on Language and Social Interaction},
	author = {Stivers, Tanya},
	month = jan,
	year = {2021},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2020.1864158},
	pages = {1--19},
}

@article{mastroianni_conversations_2021,
	title = {Do conversations end when people want them to?},
	volume = {118},
	copyright = {© 2021 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/118/10/e2011809118},
	doi = {10.1073/pnas.2011809118},
	abstract = {Do conversations end when people want them to? Surprisingly, behavioral science provides no answer to this fundamental question about the most ubiquitous of all human social activities. In two studies of 932 conversations, we asked conversants to report when they had wanted a conversation to end and to estimate when their partner (who was an intimate in Study 1 and a stranger in Study 2) had wanted it to end. Results showed that conversations almost never ended when both conversants wanted them to and rarely ended when even one conversant wanted them to and that the average discrepancy between desired and actual durations was roughly half the duration of the conversation. Conversants had little idea when their partners wanted to end and underestimated how discrepant their partners’ desires were from their own. These studies suggest that ending conversations is a classic “coordination problem” that humans are unable to solve because doing so requires information that they normally keep from each other. As a result, most conversations appear to end when no one wants them to.},
	language = {en},
	number = {10},
	urldate = {2021-03-02},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Mastroianni, Adam M. and Gilbert, Daniel T. and Cooney, Gus and Wilson, Timothy D.},
	month = mar,
	year = {2021},
	note = {ISBN: 9782011809117
Publisher: National Academy of Sciences
Section: Social Sciences},
}

@article{mertens_cognitive_2021,
	title = {Cognitive and social delays in the initiation of conversational repair},
	volume = {12},
	copyright = {Copyright (c) 2021 Julia Mertens and Jan P. de Ruiter},
	issn = {2152-9620},
	url = {https://firstmonday.org/ojs/index.php/dad/article/view/11388},
	doi = {10.5210/dad.2021.102},
	abstract = {The exact timing of a conversational turn conveys important information to a listener. Most turns are initiated within 250ms after the previous turn. However, interlocutors take longer to initiate certain types of turns: those that either require more cognitive processing or are socially dispreferred. Many dispreferred turns are also cognitively demanding, so it is difficult to attribute specific conversational delays to social or cognitive mechanisms. In this paper, we evaluate the relative contribution of cognitive and social variables to the timing of utterances in conversation.
We focus on a type of turn that is socially dispreferred, cognitively demanding, and generally delayed: other-initiations of repair (OIRs). OIRs occur when a listener notices and decides to signal a comprehension problem (e.g., "What?"). We analyzed the Floor Transfer Offsets of 456 OIRs, and found that interlocutors initiated OIRs later when trouble sources had weaker discourse context or were shorter, and when the OIR was more face-threatening. Our results suggest that both cognitive and social variables contribute to the timing of delayed utterances in conversation. We discuss how attention, prediction, planning, and social preference manifest in the timing of turns.},
	language = {en},
	number = {1},
	urldate = {2021-03-06},
	journal = {Dialogue \& Discourse},
	author = {Mertens, Julia Beret and Ruiter, J. P. de},
	month = mar,
	year = {2021},
	note = {Number: 1},
	pages = {21--44},
}

@inproceedings{paschen_building_2020,
	address = {Marseille, France},
	title = {Building a {Time}-{Aligned} {Cross}-{Linguistic} {Reference} {Corpus} from {Language} {Documentation} {Data} ({DoReCo})},
	isbn = {979-10-95546-34-4},
	url = {https://www.aclweb.org/anthology/2020.lrec-1.324},
	abstract = {Natural speech data on many languages have been collected by language documentation projects aiming to preserve lingustic and cultural traditions in audivisual records. These data hold great potential for large-scale cross-linguistic research into phonetics and language processing. Major obstacles to utilizing such data for typological studies include the non-homogenous nature of file formats and annotation conventions found both across and within archived collections. Moreover, time-aligned audio transcriptions are typically only available at the level of broad (multi-word) phrases but not at the word and segment levels. We report on solutions developed for these issues within the DoReCo (DOcumentation REference COrpus) project. DoReCo aims at providing time-aligned transcriptions for at least 50 collections of under-resourced languages. This paper gives a preliminary overview of the current state of the project and details our workflow, in particular standardization of formats and conventions, the addition of segmental alignments with WebMAUS, and DoReCo's applicability for subsequent research programs. By making the data accessible to the scientific community, DoReCo is designed to bridge the gap between language documentation and linguistic inquiry.},
	language = {English},
	urldate = {2021-03-09},
	booktitle = {Proceedings of the 12th {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Paschen, Ludger and Delafontaine, François and Draxler, Christoph and Fuchs, Susanne and Stave, Matthew and Seifart, Frank},
	month = may,
	year = {2020},
	pages = {2657--2666},
}

@article{birhane_algorithmic_2021,
	title = {Algorithmic injustice: a relational ethics approach},
	volume = {2},
	issn = {2666-3899},
	shorttitle = {Algorithmic injustice},
	url = {https://www.sciencedirect.com/science/article/pii/S2666389921000155},
	doi = {10.1016/j.patter.2021.100205},
	abstract = {It has become trivial to point out that algorithmic systems increasingly pervade the social sphere. Improved efficiency—the hallmark of these systems—drives their mass integration into day-to-day life. However, as a robust body of research in the area of algorithmic injustice shows, algorithmic systems, especially when used to sort and predict social outcomes, are not only inadequate but also perpetuate harm. In particular, a persistent and recurrent trend within the literature indicates that society's most vulnerable are disproportionally impacted. When algorithmic injustice and harm are brought to the fore, most of the solutions on offer (1) revolve around technical solutions and (2) do not center disproportionally impacted communities. This paper proposes a fundamental shift—from rational to relational—in thinking about personhood, data, justice, and everything in between, and places ethics as something that goes above and beyond technical solutions. Outlining the idea of ethics built on the foundations of relationality, this paper calls for a rethinking of justice and ethics as a set of broad, contingent, and fluid concepts and down-to-earth practices that are best viewed as a habit and not a mere methodology for data science. As such, this paper mainly offers critical examinations and reflection and not “solutions.”},
	language = {en},
	number = {2},
	urldate = {2021-03-10},
	journal = {Patterns},
	author = {Birhane, Abeba},
	month = feb,
	year = {2021},
	pages = {100205},
}

@article{borghi_embodied_2013,
	title = {The embodied mind extended: using words as social tools},
	volume = {4},
	issn = {1664-1078},
	shorttitle = {The embodied mind extended},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00214/full},
	doi = {10.3389/fpsyg.2013.00214},
	abstract = {The extended mind view and the embodied-grounded view of cognition and language are typically considered as rather independent perspectives. In this paper we propose a possible integration of the two views and support it proposing the idea of ''Words As social Tools' (WAT)'. In this respect, we will propose that words, also due to their social and public character, can be conceived as quasi-external devices that extend our cognition. Moreover, words function like tools in that they enlarge the bodily space of action thus modifying our sense of body. To support our proposal, we review the relevant literature on tool use and on words as tools and report recent evidence indicating that word use leads to an extension of space close to the body. In addition, we outline a model of the neural processes that may underpin bodily space extension via word use and may reflect possible effects on cognition of the use of words as external means. We also discuss how reconciling the two perspectives can help to overcome the limitations they encounter if considered independently.},
	language = {English},
	urldate = {2021-03-18},
	journal = {Frontiers in Psychology},
	author = {Borghi, Anna M. and Scorolli, Claudia and Caligiore, Daniele and Baldassarre, Gianluca and Tummolini, Luca},
	year = {2013},
	note = {Publisher: Frontiers},
}

@book{haakana_talk_2009,
	title = {Talk in interaction: {Comparative} dimensions},
	isbn = {978-952-222-134-6},
	shorttitle = {Talk in interaction},
	url = {https://oa.finlit.fi/site/books/10.21435/sflin.14/},
	language = {en},
	urldate = {2021-03-23},
	publisher = {SKS Finnish Literature Society},
	editor = {Haakana, Markku and Laakso, Minna and Lindström, Jan},
	month = jan,
	year = {2009},
	doi = {10.21435/sflin.14},
}

@incollection{haakana_other-correction_2009,
	title = {Other-correction in everyday interaction: {Some} comparative aspects},
	isbn = {978-952-222-134-6},
	url = {https://oa.finlit.fi/site/books/10.21435/sflin.14/},
	language = {en},
	urldate = {2021-03-23},
	booktitle = {Talk in interaction: {Comparative} dimensions},
	publisher = {SKS Finnish Literature Society},
	author = {Haakana, Markku and Kurhila, Salla},
	editor = {Haakana, Markku and Laakso, Minna and Lindström, Jan},
	month = jan,
	year = {2009},
	doi = {10.21435/sflin.14},
}

@phdthesis{liesenfeld_action_2019,
	type = {Thesis},
	title = {Action formation with janwai in {Cantonese} {Chinese} conversation},
	url = {https://dr.ntu.edu.sg//handle/10356/102660},
	abstract = {This thesis describes action formation and ascription featuring the Cantonese Chinese discourse marker janwai ("because") in naturally-occurring Cantonese talk-in-interaction. Conceived as a conversation analytic exploratory data analysis, the study examines the use of this utterance as part of the formation of turns and turn construction units in a naturalistic setting. The study is grounded in MYCanCor, a video corpus of around 20 hours of spontaneous everyday conversation that was collected as part of the study in the Malaysian Cantonese speech community. The thesis describes the use of janwai in four sequential environments, (1) the production of responses that begin with janwai, (2) the production of responses that feature janwai, (3) the production of turns and TCUs that feature janwai but that do not ostensibly constitute responses, and (4) the production of janwai in various other sequential environments, such as to format repairs and noun phrases of cause or reason in clauses. Based on the analysis of the sequential unfolding of stretches of talk-in-interaction, the thesis identifies and explicates different sets of relevance rules that appear to underpin these usage environments. This analysis presents evidence that, as part of question-response sequences, janwai can constitute an affirmative response in turn-initial position and project the forthcoming of a telling or an account either in turn-initial position or after a response token. As part of action formation, janwai appears to be related to conversational accounting and may be deployed either after a displayed intelligibility problem to preface an account or as a device to retrospectively change action formation of the preceding turn as seeking or requiring an account. These findings show that the study of grammar as an emergent, real-world phenomenon can lead to new and unexpected insights in interactional properties of causal discourse markers and thereby contribute to a better understanding of how these utterances serves as a resource that participants deploy to form turns-at-talk, negotiate social action and accomplish interactional tasks. Based on these findings, I conclude with outlining how discourse-interactional functions of janwai may be captured as part of dialogic construction grammars.},
	language = {en},
	urldate = {2021-04-01},
	author = {Liesenfeld, Andreas Maria},
	year = {2019},
	doi = {10.32657/10220/47757},
	note = {Accepted: 2019-03-05T02:14:40Z},
}

@inproceedings{chang_convokit_2020,
	address = {1st virtual meeting},
	title = {{ConvoKit}: {A} {Toolkit} for the {Analysis} of {Conversations}},
	shorttitle = {{ConvoKit}},
	url = {https://www.aclweb.org/anthology/2020.sigdial-1.8},
	abstract = {This paper describes the design and functionality of ConvoKit, an open-source toolkit for analyzing conversations and the social interactions embedded within. ConvoKit provides an unified framework for representing and manipulating conversational data, as well as a large and diverse collection of conversational datasets. By providing an intuitive interface for exploring and interacting with conversational data, this toolkit lowers the technical barriers for the broad adoption of computational methods for conversational analysis.},
	urldate = {2021-04-01},
	booktitle = {Proceedings of the 21th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Chang, Jonathan P. and Chiam, Caleb and Fu, Liye and Wang, Andrew and Zhang, Justine and Danescu-Niculescu-Mizil, Cristian},
	month = jul,
	year = {2020},
	pages = {57--60},
}

@inproceedings{liesenfeld_project_2017,
	title = {Project {Notes} on building a conversational parser on top of a text parser: {Towards} a causal language tagger for spoken {Chinese}},
	shorttitle = {Project {Notes} on building a conversational parser on top of a text parser},
	url = {https://www.aclweb.org/anthology/W17-7407},
	urldate = {2021-04-01},
	booktitle = {Proceedings of the 13th {Joint} {ISO}-{ACL} {Workshop} on {Interoperable} {Semantic} {Annotation} ({ISA}-13)},
	author = {Liesenfeld, Andreas},
	year = {2017},
}

@inproceedings{liesenfeld_mycancor_2018,
	address = {Miyazaki, Japan},
	title = {{MYCanCor}: {A} {Video} {Corpus} of spoken {Malaysian} {Cantonese}},
	shorttitle = {{MYCanCor}},
	url = {https://www.aclweb.org/anthology/L18-1122},
	urldate = {2021-04-01},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Liesenfeld, Andreas},
	month = may,
	year = {2018},
}

@techreport{gambi_engineering_2021,
	title = {Engineering conversation: {Understanding} the control requirements of language generation in dialogue.},
	shorttitle = {Engineering conversation},
	url = {https://psyarxiv.com/937du/},
	abstract = {Noisy and uncertain estimation of the state of the world, coupled with feedback delays, are the two major challenges faced by any artificial or biological system. These challenges also apply to the processes of language generation and comprehension and there are well-understood solutions to these challenges in models of the perception and production of speech sounds. Specifically, Bayesian inference can solve the problem of recovering phonological representations when the auditory signal is noisy or degraded, while coupled forward and inverse internal models can overcome delays inherent in executing speech motor commands and monitoring one’s own speech via the auditory system. But while Bayesian inference has also been applied to comprehension at higher linguistic levels (i.e., lexicon, syntax, and semantics), the need for coupled forward-inverse model pairs at these higher levels in production is debated. In fact, we argue, the control architectures embedded in current models of language generation tend to be much less sophisticated than those embedded in models of speech production. While these simple architectures have been considerably successful in explaining how speakers control language production in monologic contexts, we argue that more sophisticated architectures are likely to be needed to account for language use in dialogic contexts. Specifically, we identify three challenges for models of language generation that arise from the nature of dialogue: (1) The need to distinguish between self- and other-generated utterances; (2) The need to adjust the amount of advance planning (i.e., the degree to which planning precedes articulation) flexibly to achieve timely turn-taking; (3) The need to track changing conversational goals.  For each of these challenges, we discuss the type(s) of control architecture(s) that could be implemented, drawing on analogy to mechanical or biological systems whenever possible. In sum, we propose that considering more sophisticated control architectures is necessary to build language generation models that deal with conversation, and can meet the challenge of real-time, flexible language generation in NLG systems.},
	urldate = {2021-04-12},
	institution = {PsyArXiv},
	author = {Gambi, Chiara and Zhang, Fan},
	month = apr,
	year = {2021},
	doi = {10.31234/osf.io/937du},
	note = {type: article},
}

@inproceedings{henderson_recovering_2012,
	title = {Recovering from {Non}-{Understanding} {Errors} in a {Conversational} {Dialogue} {System}},
	abstract = {Spoken dialogue systems can encounter different types of errors, including non-understanding errors where the system recognises that the user has spoken, but does not understand the utterance. Strate-gies for dealing with this kind of error have been proposed and tested in the context of goal-driven dialogue systems, for example by Bohus with a system which helps re-serve conference rooms (Bohus and Rud-nicky, 2005). However there has been lit-tle work on possible strategies in more con-versational settings where the dialogue has more open-ended intentions. This paper looks at recovery from non-understanding errors in the context of a robot tourguide, and tests the strategies in a user trial. The results suggest that it is beneficial for user enjoyment to use strategies which attempt to move the dialogue on, rather than getting caught up in the error by asking users to re-peat themselves. 1},
	booktitle = {Proceedings of {SemDial} 2012},
	author = {Henderson, Matthew and Matheson, Colin and Place, Buccleuch and Oberlander, Jon},
	year = {2012},
}

@mastersthesis{henderson_recovering_2011,
	title = {Recovering {From} {Errors} in {Conversational} {Dialogue} {Systems}},
	url = {https://era.ed.ac.uk/handle/1842/6088},
	abstract = {Spoken dialogue systems can encounter different types of errors, including non-understanding errors. This is where the system realises the user has spoken, but does not understand their utterance. Strategies for dealing with this kind of error have been proposed and tested in the context of slot-filling systems, for example by Dan Bohus with a system which helps reserve conference rooms [1]. However there has been little work into possible strategies for more conversational settings. This dissertation looks at how we could recover from non-understanding errors experienced by a robot tourguide, and tests the strategies in an experimental study. The main hypothesis of this study is that it is beneficial to use strategies which are designed to do something smarter than just asking the user to repeat themselves. The strategies implemented are motivated by the findings of work done on task-based dialogue systems [1,2,3], which suggest it is useful to move the user on through the dialogue instead of getting caught up with the non-understanding error.},
	language = {en},
	urldate = {2021-04-15},
	school = {University of Edinburgh},
	author = {Henderson, Matthew},
	month = nov,
	year = {2011},
	note = {Accepted: 2012-07-06T12:59:33Z
Publisher: The University of Edinburgh},
}

@inproceedings{bohus_sorry_2005,
	address = {Lisbon, Portugal},
	title = {Sorry and {I} {Didn}'t {Catch} {That}! - {An} {Investigation} of {Non}-understanding {Errors} and {Recovery} {Strategies}},
	url = {https://www.aclweb.org/anthology/2005.sigdial-1.14},
	urldate = {2021-04-15},
	booktitle = {Proceedings of the 6th {SIGdial} {Workshop} on {Discourse} and {Dialogue}},
	publisher = {Special Interest Group on Discourse and Dialogue (SIGdial)},
	author = {Bohus, Dan and Rudnicky, Alexander I.},
	month = sep,
	year = {2005},
	pages = {128--143},
}

@article{hinnenkamp_notion_1999,
	title = {The notion of misunderstanding in intercultural communication},
	volume = {1},
	journal = {Journal of intercultural communication},
	author = {Hinnenkamp, Volker},
	year = {1999},
	pages = {1--13},
}

@article{olsina_managing_2002,
	title = {Managing {Understanding} in {Intercultural} {Talk}: {An} {Empirical} {Approach} to {Miscommunication}},
	volume = {24},
	shorttitle = {Managing {Understanding} in {Intercultural} {Talk}},
	url = {/paper/MANAGING-UNDERSTANDING-IN-INTERCULTURAL-TALK%3A-AN-TO-Olsina/8f3d84784697e92d10bb843c705dacba44727d9e},
	abstract = {Research on miscommunication has not ceased to grow since the early 1980s, especially in connection with the analysis of cross-cultural communication. Yet, this interest has not stimulated a critical debate on the theoretical models underpinning most miscommunication research. This study aims at encouraging scientific discussion by advocating an empirical treatment of communicative conflict, that is one which is grounded in the detailed examination of linguistic data. Through the fine-grained analysis of participants\&\#39; sense-making processes in a corpus of real-life intercultural data, we seek to unveil the linguistic and conversational strategies that speakers put to work in the handling of miscommunication. Our empirical analysis of understanding difficulties, based exlusively on observable trouble in talk, suggests that analysts can legitimately focus only on those stretches of talk which are experienced as problematic by speakers themselves. It also shows that miscommunication cannot be attributed to an individual speaker, but that it is jointly constructed by interactants through the ways in which they assess and respond to each other\&\#39;s conversational contributions.},
	language = {en},
	number = {1},
	urldate = {2021-04-16},
	journal = {Atlantis: Revista de la Asociación Española de Estudios Anglo-Norteamericanos},
	author = {Olsina, Eva Codó i},
	year = {2002},
	pages = {37--58},
}

@incollection{wallis_robust_2005,
	title = {Robust normative systems: {What} happens when a normative system fails},
	shorttitle = {Robust normative systems},
	booktitle = {Abuse: the darker side of human-computer interaction, {Rome}, {September}},
	author = {Wallis, Peter},
	year = {2005},
}

@incollection{couper-kuhlen_conversational_1996,
	address = {Cambridge / New York},
	title = {Conversational phonetics: some aspects of news receipts in everyday talk},
	isbn = {978-0-521-46075-0},
	booktitle = {Prosody in conversation : interactional studies},
	publisher = {Cambridge University Press},
	author = {Local, John},
	editor = {Couper-Kuhlen, Elizabeth and Selting, Margret},
	year = {1996},
	pages = {177--230},
}

@inproceedings{schlangen_outline_2020,
	address = {Brandeis University / Internet},
	title = {An {Outline} of a {Model} of {Situated} {Discourse} {Representation} and {Processing}},
	booktitle = {Proceedings of semdial 2020 ({WatchDial})},
	author = {Schlangen, David},
	month = jul,
	year = {2020},
}

@incollection{couper-kuhlen_affiliating_1996,
	address = {Cambridge / New York},
	title = {Affiliating and disaffiliating with continuers: {Prosodic} aspects of recipiency},
	isbn = {978-0-521-46075-0},
	booktitle = {Prosody in conversation : interactional studies},
	publisher = {Cambridge University Press},
	author = {Müller, Frank Ernst},
	editor = {Couper-Kuhlen, Elizabeth and Selting, Margret},
	year = {1996},
	keywords = {*need to read},
}

@article{sikveland_holding_2012,
	title = {Holding gestures across turns: {Moments} to generate shared understanding},
	volume = {12},
	issn = {1568-1475, 1569-9773},
	shorttitle = {Holding gestures across turns},
	url = {https://www.jbe-platform.com/content/journals/10.1075/gest.12.2.03sik},
	doi = {10.1075/gest.12.2.03sik},
	abstract = {It is widely supposed that speakers only gesture while speaking. In this paper, we consider how participants in Norwegian conversation use gestures held beyond the end of a turn-at-talk as a way to handle issues of shared understanding. Analysis combining the techniques of conversation analysis, linguistic, phonetic and visual analysis, demonstrates how participants use and orient to such held gestures as displays of occasions where participants do not (yet) have a shared understanding. The paper discusses how understanding is explicitly brought forward in a sequence of turns, and how shared understandings are reached and marked through a combination of spoken and gestural elements. The paper emphasizes the temporal progressivity of talk, the delicate timing of speech and gesture relative to one another, and the participants’ collaboration in successfully achieving and maintaining intersubjectivity.},
	language = {en},
	number = {2},
	urldate = {2021-04-26},
	journal = {Gesture},
	author = {Sikveland, Rein Ove and Ogden, Richard},
	month = jan,
	year = {2012},
	note = {Publisher: John Benjamins},
	pages = {166--199},
}

@article{mushin_linguistic_2021,
	title = {Linguistic structures in social interaction: {Moving} temporality to the forefront of a science of language},
	shorttitle = {Linguistic structures in social interaction},
	url = {https://www.jbe-platform.com/content/journals/10.1075/il.21008.mus},
	doi = {10.1075/il.21008.mus},
	abstract = {Abstract In this introductory paper to the inaugural volume of the journal Interactional Linguistics, we raise the question of what a theory of language might look like once we factor time into explanations of regularities in linguistic phenomena. We first present a historical overview that contextualises interactional approaches within the broader field of linguistics, and then focus on temporality as a key dimension of language use in interaction. By doing so, we discuss issues of emergence and its consequences for constituency and dependency, and of projection and its relation to action formation within and across languages. Based on video-recorded conversational data from French and Garrwa (Australian), we seek to illustrate how the discipline of linguistics can be enriched by attending to the temporal deployment of patterns of language use, and how this may in turn modify what we understand to be language structure.},
	language = {en},
	urldate = {2021-05-11},
	author = {Mushin, Ilana and Doehler, Simona Pekarek},
	month = may,
	year = {2021},
	note = {Publisher: John Benjamins},
}

@article{de_malsche_examining_2021,
	title = {Examining interspecies interactions in light of discourse analytic theory: {A} case study on the genre of human-goat communication at a petting farm},
	volume = {79},
	issn = {0271-5309},
	shorttitle = {Examining interspecies interactions in light of discourse analytic theory},
	url = {https://www.sciencedirect.com/science/article/pii/S0271530921000227},
	doi = {10.1016/j.langcom.2021.03.003},
	abstract = {This paper investigates how linguistic research can contribute to the field of interspecies studies through an ethnographic study on human-goat communication. It addresses two research questions: whether traditional discourse analytic theory can be used to analyze non-human communication, and whether the specific concepts of communicative events, purposes, and move structure within genre theory can be applied in these contexts. The data show that genre theory can be applied, and that both the humans and the goats attempt to make their communicative goals salient to the recipients. The results illustrate the possibility of applying traditional linguistic theory to non-human contexts, and it is argued that discourse analytic theory should include interspecies interactions to gain new insights in general communicative paradigms.},
	language = {en},
	urldate = {2021-05-19},
	journal = {Language \& Communication},
	author = {De Malsche, Fien and Cornips, Leonie},
	month = jul,
	year = {2021},
	pages = {53--70},
}

@article{mondeme_why_2021,
	title = {Why study turn-taking sequences in interspecies interactions?},
	issn = {1468-5914},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jtsb.12295},
	doi = {10.1111/jtsb.12295},
	abstract = {The “turn-taking” system, a notion referring to the dynamics of verbal exchanges in face-to-face interaction, is often presented as the hallmark of human language (Levinson, 2016). However, recent works have investigated turn-taking mechanisms in several nonhuman taxa, thus referring to the moment-by-moment coordinated alternation of actions or vocalizations, for instance in primates or birds. These findings have been interpreted as evidence of elementary forms of sequence organization in the animal world, and therefore as evidences of an evolutionary pathway, leading from very rough forms of signal alternation, to the complex multimodal and conversational turn-taking system used by humans. This article first reviews and discusses these findings. It then makes the case for going beyond the study of uniquely intra-specific forms of communication and interaction. It argues that considering interspecies interaction is of interest for social sciences in general, and linguistics scholarship in particular, at least in two respects. First, on an empirical level, to investigate a widespread phenomenon, namely ordinary human-animal interactions, as it occurs mostly in domestic settings—a topic that has been relatively neglected in the study of social interaction so far (for a range of reasons that we shall touch on). Secondly, on a more speculative level, it assumes that ordinary interspecies interactions, especially as they unfold with domestic pets or wild animals in natural settings (vs. in experimental settings), are a valuable locus to explore rudimentary forms of sequence organization, that are neither governed by linguistic and cultural norms, nor entirely the product of stereotypical species-related behavioral patterns. We posit that fundamental principles of sociality are to be found in the contextual adjustments of multimodal actions and in the emergence of meaning in interspecies interactions.},
	language = {en},
	urldate = {2021-07-27},
	journal = {Journal for the Theory of Social Behaviour},
	author = {Mondémé, Chloé},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jtsb.12295},
}

@book{linell_rethinking_2009,
	address = {Charlotte, NC},
	edition = {Illustrated edition},
	title = {Rethinking {Language}, {Mind}, and {World} {Dialogically}},
	isbn = {978-1-59311-996-6},
	abstract = {A volume in Advances in Cultural Psychology Series Editor: Jaan Valsiner, Clark University "This is a remarkable and highly original work on dialogism, dialogical theories and dialogue. With his erudite and broadly based scholarship Per Linell makes a path-breaking contribution to the study of the human mind, presenting a novel alternative to traditional monologism and exploring the dynamics of sense-making in different forms of interaction and communicative projects. Although Per Linell discusses complex dialogical concepts, the text is written with exceptional clarity, taking the reader through critique as well as appreciation of great intellectual traditions of our time." (Professor Ivana Marková, University of Stirling, U.K.) "Per Linell`s Rethinking Language, Mind And World Dialogically represents a landmark in the development ofa transdisciplinary dialogically based paradigm for the human sciences. The author´s lucid analysis and constructive rethinking ranges all the way from integrating explanations of significant empirical contributions across the entire range of human sciences dealing with language, thought and communication to foundational, epistemological and ontological issues." (Professor Ragnar Rommetveit, University of Oslo, Norway) Per Linell took his degree in linguistics and is currently professor of language and culture, with a specialisation on communication and spoken interaction, at the University of Linköping, Sweden. He has been instrumental in building up an internationally renowned interdisciplinary graduate school in communication studies in Linköping. He has worked for many years on developing a dialogical alternative to mainstream theories in linguistics, psychology and social sciences. His production comprises more than 100 articles on dialogue, talk-in-interaction and institutional discourse. His more recent books include Approaching Dialogue (1998), The Written Language Bias in Linguistics (2005) and Dialogue in Focus Groups (2007, with I. Marková, M. Grossen and A. Salazar Orvig).},
	language = {English},
	publisher = {Information Age Publishing},
	author = {Linell, Per},
	month = apr,
	year = {2009},
}

@article{wallis_introducing_2021,
	title = {Introducing the {Talk} {Markup} {Language} ({TalkML}):{Adding} a little social intelligence to industrial speech interfaces},
	shorttitle = {Introducing the {Talk} {Markup} {Language} ({TalkML})},
	url = {http://arxiv.org/abs/2105.11294},
	abstract = {Virtual Personal Assistants like Siri have great potential but such developments hit the fundamental problem of how to make computational devices that understand human speech. Natural language understanding is one of the more disappointing failures of AI research and it seems there is something we computer scientists don't get about the nature of language. Of course philosophers and linguists think quite differently about language and this paper describes how we have taken ideas from other disciplines and implemented them. The background to the work is to take seriously the notion of language as action and look at what people actually do with language using the techniques of Conversation Analysis. The observation has been that human communication is (behind the scenes) about the management of social relations as well as the (foregrounded) passing of information. To claim this is one thing but to implement it requires a mechanism. The mechanism described here is based on the notion of language being intentional - we think intentionally, talk about them and recognise them in others - and cooperative in that we are compelled to help out. The way we are compelled points to a solution to the ever present problem of keeping the human on topic. The approach has led to a recent success in which we significantly improve user satisfaction independent of task completion. Talk Markup Language (TalkML) is a draft alternative to VoiceXML that, we propose, greatly simplifies the scripting of interaction by providing default behaviours for no input and not recognised speech events.},
	urldate = {2021-05-27},
	journal = {arXiv:2105.11294 [cs]},
	author = {Wallis, Peter},
	month = may,
	year = {2021},
	note = {arXiv: 2105.11294},
}

@article{birhane_impossibility_2021,
	title = {The {Impossibility} of {Automating} {Ambiguity}},
	issn = {1530-9185},
	url = {https://direct.mit.edu/artl/article/doi/10.1162/artl_a_00336/101872/The-Impossibility-of-Automating-Ambiguity},
	doi = {10.1162/artl_a_00336},
	abstract = {On the one hand, complexity science and enactive and embodied cognitive science approaches emphasize that people, as complex adaptive systems, are ambiguous, indeterminable, and inherently unpredictable. On the other, Machine Learning (ML) systems that claim to predict human behaviour are becoming ubiquitous in all spheres of social life. I contend that ubiquitous Artificial Intelligence (AI) and ML systems are close descendants of the Cartesian and Newtonian worldview in so far as they are tools that fundamentally sort, categorize, and classify the world, and forecast the future. Through the practice of clustering, sorting, and predicting human behaviour and action, these systems impose order, equilibrium, and stability to the active, fluid, messy, and unpredictable nature of human behaviour and the social world at large. Grounded in complexity science and enactive and embodied cognitive science approaches, this article emphasizes why people, embedded in social systems, are indeterminable and unpredictable. When ML systems “pick up” patterns and clusters, this often amounts to identifying historically and socially held norms, conventions, and stereotypes. Machine prediction of social behaviour, I argue, is not only erroneous but also presents real harm to those at the margins of society.},
	language = {en},
	urldate = {2021-05-28},
	journal = {Artificial Life},
	author = {Birhane, Abeba},
	month = may,
	year = {2021},
	pages = {1--18},
}

@article{zellers_overview_2021,
	title = {An overview of forms, functions, and configurations of backchannels in {Ruruuli}/{Lunyala}},
	volume = {175},
	issn = {0378-2166},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216621000205},
	doi = {10.1016/j.pragma.2021.01.012},
	abstract = {Backchannels are speech contributions produced by a listener in the course of conversation, and are characterized by their short duration and their lack of turn-competitiveness. The current work investigates backchanneling behavior in Ruruuli/Lunyala, a Bantu language. Ruruuli/Lunyala speakers are found to backchannel much more frequently than has been reported for many other languages, with the increase in frequency mostly dependent on backchannels with the continuer function. A wide variety of non-lexical and lexical backchannel forms are used, including the use of repetitions of parts of a previous turn, which appears to be a relatively infrequent use of backchannels crosslinguistically. These forms are combined with different prosodic resources such as fundamental frequency, phonation quality, and duration features, to achieve different communicative functions; for example, the pitch contour arising on repetitions differs depending on the backchanneling function that the particular repetition is carrying out. The resources available for backchanneling in Ruruuli/Lunyala emphasize the rich variability of linguistic and prosodic constructions which are used by listeners to contribute to the smooth progress of conversation. In addition, this study on a Bantu language gives insight into how backchanneling and conversational interaction may show different patterns in different language families and/or cultures.},
	language = {en},
	urldate = {2021-06-08},
	journal = {Journal of Pragmatics},
	author = {Zellers, Margaret},
	month = apr,
	year = {2021},
	pages = {38--52},
}

@incollection{verschueren_interjections_2006,
	address = {Amsterdam},
	title = {Interjections},
	isbn = {978-90-272-3235-9},
	language = {en},
	booktitle = {Handbook of {Pragmatics}},
	publisher = {John Benjamins Publishing Company},
	author = {Ameka, Felix K. and Wilkins, David P.},
	editor = {Verschueren, Jef and Östman, Jan-Ola},
	month = dec,
	year = {2006},
	doi = {10.1075/hop.10.int12},
	pages = {1--19},
}

@article{mao_comparative_2020,
	title = {A {Comparative} {Study} of {Interjections} in {Chinese} and {English}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	url = {http://www.scirp.org/Journal/Paperabs.aspx?paperid=102159},
	doi = {10.4236/ojml.2020.104018},
	abstract = {Interjections are emotive words with no referential content. In both Chinese and English, they are classified as a special word class. In order to better comprehend interjections and further deepen our knowledge of these two language systems, a comparison of Chinese interjections and English interjections is made at three levels—morphological structures, semantic relations and syntactic functions. Similarities of Chinese and English interjections are found to outnumber their differences.},
	language = {en},
	number = {4},
	urldate = {2021-06-15},
	journal = {Open Journal of Modern Linguistics},
	author = {Mao, Anmin},
	month = jul,
	year = {2020},
	note = {Number: 4
Publisher: Scientific Research Publishing},
	pages = {315--320},
}

@book{hoey_when_2020,
	address = {New York, NY},
	title = {When conversation lapses: the public accountability of silent copresence},
	isbn = {978-0-19-094765-1},
	shorttitle = {When conversation lapses},
	abstract = {"Silence takes on meaning based on the contexts of its occurrence. This is especially true in social interactions: consider the difference between silence after "lemme think," and silence after "will you marry me?" This book examines a particular form of silence, the conversational lapse. These regularly appear in conversations when all interactants pass up the opportunity to speak, and are moments when talk seems to falter or give way to matters extraneous to the conversation. What are these silences for the participants who, by virtue of not speaking, allowed them to develop? Elliott M. Hoey here offers the first in-depth analysis of lapses in conversation. Using methods from Conversation Analysis, the author explores hundreds of lapses in naturally occurring social occasions, with each chapter focusing on a different aspect of how participants produce and locate order in lapses. Particular emphasis is given to how lapses emerge, what people do during the silence, and how they restart conversation afterward. This research uncovers participants' methods for organizing lapses in their everyday affairs such that those silences are rendered as understandable periods of non-talk. By articulating participants' understandings of when and where talk is relevant, necessary, or appropriate, the research brings into focus the borderlines between talk-in-interaction and other realms of social life. This book shows lapses to be a particular and fascinating kind of silence with unique relevancies for the social situations of which they are a part"--},
	publisher = {Oxford University Press},
	author = {Hoey, Elliott M.},
	year = {2020},
}

@article{genty_how_2020,
	title = {How apes get into and out of joint actions: {Shared} intentionality as an interactional achievement},
	volume = {21},
	issn = {1572-0373, 1572-0381},
	shorttitle = {How apes get into and out of joint actions},
	url = {https://www.jbe-platform.com/content/journals/10.1075/is.18048.gen},
	doi = {10.1075/is.18048.gen},
	abstract = {Abstract Compared to other animals, humans appear to have a special motivation to share experiences and mental states with others (Clark, 2006; Grice, 1975), which enables them to enter a condition of ‘we’ or shared intentionality (Tomasello \&amp; Carpenter, 2005). Shared intentionality has been suggested to be an evolutionary response to unique problems faced in complex joint action coordination (Levinson, 2006; Tomasello, Carpenter, Call, Behne, \&amp; Moll, 2005) and to be unique to humans (Tomasello, 2014). The theoretical and empirical bases for this claim, however, present several issues and inconsistencies. Here, we suggest that shared intentionality can be approached as an interactional achievement, and that by studying how our closest relatives, the great apes, coordinate joint action with conspecifics, we might demonstrate some correlate abilities of shared intentionality, such as the appreciation of joint commitment. We provide seven examples from bonobo joint activities to illustrate our framework.},
	language = {en},
	number = {3},
	urldate = {2021-06-15},
	journal = {Interaction Studies},
	author = {Genty, Emilie and Heesen, Raphaela and Guéry, Jean-Pascal and Rossano, Federico and Zuberbühler, Klaus and Bangerter, Adrian},
	month = dec,
	year = {2020},
	note = {Publisher: John Benjamins},
	pages = {353--386},
}

@inproceedings{yang_comparative_2019,
	title = {A {Comparative} {Study} of {Chinese} and {Russian} {Interjections}},
	isbn = {978-985-566-650-0},
	url = {https://elib.bsu.by/handle/123456789/217700},
	abstract = {In this paper, we describe and compare every characteristic of interjections between Chinese and Russian from the perspective of phonetics, meanings, syntactic and pragmatic functions. We can draw the conclusion that in spite of different forms and meanings of interjections in two different languages, there are similarities between them in syntactic and pragmatic functions.},
	language = {en},
	urldate = {2021-06-15},
	publisher = {Минск : БГУ},
	author = {Yang, Yang},
	year = {2019},
	note = {Accepted: 2019-03-28T08:13:04Z
Journal Abbreviation: Сравнительное исследование китайских и русских междометий / Ян Ян},
}

@inproceedings{ward_issues_2000,
	address = {Hong Kong, China},
	title = {Issues in the {Transcription} of {English} {Conversational} {Grunts}},
	url = {https://www.aclweb.org/anthology/W00-1004},
	doi = {10.3115/1117736.1117740},
	urldate = {2021-06-15},
	booktitle = {1st {SIGdial} {Workshop} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Ward, Nigel},
	month = oct,
	year = {2000},
	pages = {29--35},
}

@article{skubisz_alico_2016,
	title = {The {ALICO} corpus: analysing the active listener},
	volume = {50},
	issn = {1574-020X},
	shorttitle = {The {ALICO} corpus},
	url = {https://novaresearch.unl.pt/en/publications/the-alico-corpus-analysing-the-active-listener},
	doi = {10.1007/s10579-016-9355-6},
	language = {English},
	number = {2},
	urldate = {2021-06-16},
	journal = {Language Resources and Evaluation},
	author = {Skubisz, Joanna and Malisz, Zofia and Włodarczak, Marcin and Buschmeier, Hendrik and Kopp, Stefan and Wagner, Petra},
	month = jun,
	year = {2016},
	note = {Publisher: Springer Verlag},
	pages = {411--442},
}

@incollection{enfield_distribution_2017,
	address = {Oxford},
	title = {Distribution of {Agency} across {Body} and {Self}},
	booktitle = {Distributed {Agency}},
	publisher = {Oxford University Press},
	author = {Parry, Ruth H.},
	editor = {Enfield, N. J. and Kockelman, Paul},
	year = {2017},
	note = {doi:10.1093/acprof:oso/9780190457204.003.0007},
	pages = {119--129},
}

@article{lazaridou_multi-agent_2017,
	title = {Multi-{Agent} {Cooperation} and the {Emergence} of ({Natural}) {Language}},
	url = {http://arxiv.org/abs/1612.07182},
	abstract = {The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitrary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the "word meanings" induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents' code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively.},
	urldate = {2021-06-17},
	journal = {arXiv:1612.07182 [cs]},
	author = {Lazaridou, Angeliki and Peysakhovich, Alexander and Baroni, Marco},
	month = mar,
	year = {2017},
	note = {arXiv: 1612.07182},
}

@article{elman_distributed_1991,
	title = {Distributed {Representations}, {Simple} {Recurrent} {Networks}, {And} {Grammatical} {Structure}},
	volume = {7},
	doi = {10.1023/A:1022699029236},
	abstract = {In this paper three problems for a connectionist account of language are considered: 1. What is the nature of linguistic representations? 2. How can complex structural relationships such as constituent structure be represented? 3. How can the apparently open-ended nature of language be accommodated by a fixed-resource system? Using a prediction task, a simple recurrent network (SRN) is trained on multiclausal sentences which contain multiply-embedded relative clauses. Principal component analysis of the hidden unit activation patterns reveals that the network solves the task by developing complex distributed representations which encode the relevant grammatical relations and hierarchical constituent structure. Differences between the SRN state representations and the more traditional pushdown store are discussed in the final section.},
	language = {en},
	journal = {Machine Learning},
	author = {Elman, Jeffrey L},
	year = {1991},
	pages = {195--225},
}

@article{pilnick_avoiding_2021,
	title = {Avoiding repair, maintaining face: {Responding} to hard-to-interpret talk from people living with dementia in the acute hospital},
	issn = {0277-9536},
	shorttitle = {Avoiding repair, maintaining face},
	url = {https://www.sciencedirect.com/science/article/pii/S0277953621004883},
	doi = {10.1016/j.socscimed.2021.114156},
	abstract = {People living with dementia (PLWD) are almost always admitted to the acute hospital for reasons unrelated to their dementia, finding themselves in the unfamiliar environment of a Health Care of Older Persons acute ward. The effect of this environment creates a challenge not just for a PLWD themselves, but also for the staff who care for them. Concerns have been raised by both policy makers and staff about the quality of communication between hospital staff and PLWD. Using conversation analysis, we examined 41 video recordings of healthcare professional (HCP)/PLWD interactions collected across three acute inpatient wards in a large teaching hospital in the UK. In this paper, we focus our analysis on hard-to-interpret talk (talk where there are problems in hearing, speaking and/or understanding), and the ways in which healthcare professionals respond to this. Repair of hard- to- interpret talk is common in ordinary interaction, but we find that HCPs in this setting use a range of approaches to avoid direct repair. These approaches are: the use of non-committal responses and continuers such as ‘yeah’ or nods; the use of repetitions or partial repetitions; responding to the emotional tone displayed in the PLWD's utterance; closing the current topic and shifting to the next; and treating the PLWD's talk as related to the task at hand. We suggest that the use of these approaches may be one way in which HCPs manage respecting the personhood of the PLWD, by preserving face and enabling a continuation of an interaction in which the PLWD can take an active part. Our paper provides an empirical demonstration of the high level of interactional skill involved in dementia care work. It also illustrates how these skills can be described and specified, and hence incorporated into the recommendations and tips that are produced for communication with PLWD.},
	language = {en},
	urldate = {2021-06-22},
	journal = {Social Science \& Medicine},
	author = {Pilnick, Alison and O'Brien, Rebecca and Beeke, Suzanne and Goldberg, Sarah and Harwood, Rowan},
	month = jun,
	year = {2021},
	pages = {114156},
}

@article{white_decline_1963,
	title = {Decline and {Fall} of {Interjections}},
	volume = {64},
	issn = {0028-3754},
	url = {https://www.jstor.org/stable/43342163},
	number = {4},
	urldate = {2021-06-21},
	journal = {Neuphilologische Mitteilungen},
	author = {White, Beatrice},
	year = {1963},
	note = {Publisher: Modern Language Society},
	pages = {356--372},
}

@book{kendon_organization_1975,
	address = {The Hague},
	series = {World anthropology},
	title = {Organization of behavior in face-to-face interaction},
	isbn = {978-90-279-7569-0 978-0-202-01146-2},
	language = {eng},
	publisher = {Mouton [u.a.]},
	editor = {Kendon, Adam and Harris, Richard M. and Key, Mary R.},
	year = {1975},
	note = {Meeting Name: International Congress of Anthropological and Ethnological Sciences
OCLC: 2773690},
}

@book{button_computers_1995,
	address = {Cambridge, UK : Cambridge, MA, USA},
	title = {Computers, minds, and conduct},
	isbn = {978-0-7456-1287-4 978-0-7456-1571-4},
	publisher = {Polity Press ; Basil Blackwell [distributor]},
	editor = {Button, Graham and Coulter, Jeff and Lee, John R. E. and Sharrock, Wes},
	year = {1995},
}

@article{yin_including_2021,
	title = {Including {Signed} {Languages} in {Natural} {Language} {Processing}},
	url = {http://arxiv.org/abs/2105.05222},
	abstract = {Signed languages are the primary means of communication for many deaf and hard of hearing individuals. Since signed languages exhibit all the fundamental linguistic properties of natural language, we believe that tools and theories of Natural Language Processing (NLP) are crucial towards its modeling. However, existing research in Sign Language Processing (SLP) seldom attempt to explore and leverage the linguistic organization of signed languages. This position paper calls on the NLP community to include signed languages as a research area with high social and scientific impact. We first discuss the linguistic properties of signed languages to consider during their modeling. Then, we review the limitations of current SLP models and identify the open challenges to extend NLP to signed languages. Finally, we urge (1) the adoption of an efficient tokenization method; (2) the development of linguistically-informed models; (3) the collection of real-world signed language data; (4) the inclusion of local signed language communities as an active and leading voice in the direction of research.},
	urldate = {2021-07-05},
	journal = {arXiv:2105.05222 [cs]},
	author = {Yin, Kayo and Moryossef, Amit and Hochgesang, Julie and Goldberg, Yoav and Alikhani, Malihe},
	month = may,
	year = {2021},
	note = {arXiv: 2105.05222},
}

@article{mostovaia_other-initiations_2021,
	title = {Other-initiations of repair in {German} {Whats} {App} chats},
	volume = {40},
	issn = {2211-6958},
	url = {https://www.sciencedirect.com/science/article/pii/S2211695821000076},
	doi = {10.1016/j.dcm.2021.100470},
	abstract = {This paper takes a conversation analytic approach to investigate how interlocutors deal with different kinds of interactional problems occurring in German text-based communication on Whats App. The data analyzed in the present study is obtained from the Mobile Communication Database 1 (http://mocoda.spracheinteraktion.de) and Mobile Communication Database 2 (https://db.mocoda2.de). Focusing on other-initiations of repair, this article shows that interlocutors indicate trouble sources in the preceding messages sent by their communication partners in two ways: On the one hand, writers use a wide range of other-initiations transferred from German spoken language, such as question words (was ‘what’, wer ‘who’, etc.) or candidate understandings in the form of Meinst du X? (‘Do you mean X?’, cf. Schegloff et al., 1977). On the other hand, interlocutors may display an interactional problem by deploying particular resources that the medium provides, such as asterisks, equal signs, question marks, etc. (see also Busch, in this collection of articles). A close examination of other-initiations of repair in Whats App chats thus provides an insight into how the different formats mentioned above are used, especially in relation to (a) the different types of trouble sources occurring in text-based Whats App chats, and (b) the general communication conditions created by the medium. Moreover, it will be discussed how different formats of other-initiation of repair shape the negotiation of responsibility for the trouble source or the repair proper, manage epistemic rights and contribute to the face work in the sense of Goffman (1967).},
	language = {en},
	urldate = {2021-07-06},
	journal = {Discourse, Context \& Media},
	author = {Mostovaia, Irina},
	month = apr,
	year = {2021},
	pages = {100470},
}

@incollection{volk_discourse_2021,
	title = {Discourse particles: {Theoretical} perspectives},
	isbn = {978-1-315-75449-9},
	shorttitle = {Discourse particles},
	abstract = {In a narrow sense, discourse particles are often understood to be equivalent to modal particles. Modal particles may express different degrees of probability of, attitudes towards, and expectations about the propositional content of an utterance as well as updates to the common ground. Most importantly, they change the truth-conditional meaning of utterances that contain them, but rather add pragmatic meaning. Moreover, discourse particles are typically not inflected, bear no grammatical relationship to other elements of the sentence, and may be phonologically ill-formed. The category of discourse regulation relates to interactional aspects of signed conversations and therefore includes those discourse particles that steer the flow of dialogues and establish smooth transitions between turns of conversation partners. Turn-taking signals are used when a signer wishes to open a turn, end a turn, or hold the conversational floor. When palm-up is used at the beginning of a turn, the hands are raised and turned to a signing position.},
	booktitle = {The {Routledge} {Handbook} of {Theoretical} and {Experimental} {Sign} {Language} {Research}},
	publisher = {Routledge},
	author = {Volk, Elisabeth and Herrmann, Annika},
	year = {2021},
	note = {Num Pages: 20},
}

@inproceedings{dinarelli_annotating_2009,
	address = {Athens, Greece},
	title = {Annotating {Spoken} {Dialogs}: {From} {Speech} {Segments} to {Dialog} {Acts} and {Frame} {Semantics}},
	shorttitle = {Annotating {Spoken} {Dialogs}},
	url = {https://aclanthology.org/W09-0505},
	urldate = {2021-07-13},
	booktitle = {Proceedings of {SRSL} 2009, the 2nd {Workshop} on {Semantic} {Representation} of {Spoken} {Language}},
	publisher = {Association for Computational Linguistics},
	author = {Dinarelli, Marco and Quarteroni, Silvia and Tonelli, Sara and Moschitti, Alessandro and Riccardi, Giuseppe},
	month = mar,
	year = {2009},
	pages = {34--41},
}

@article{nye_improving_2021,
	title = {Improving {Coherence} and {Consistency} in {Neural} {Sequence} {Models} with {Dual}-{System}, {Neuro}-{Symbolic} {Reasoning}},
	url = {http://arxiv.org/abs/2107.02794},
	abstract = {Human reasoning can often be understood as an interplay between two systems: the intuitive and associative ("System 1") and the deliberative and logical ("System 2"). Neural sequence models -- which have been increasingly successful at performing complex, structured tasks -- exhibit the advantages and failure modes of System 1: they are fast and learn patterns from data, but are often inconsistent and incoherent. In this work, we seek a lightweight, training-free means of improving existing System 1-like sequence models by adding System 2-inspired logical reasoning. We explore several variations on this theme in which candidate generations from a neural sequence model are examined for logical consistency by a symbolic reasoning module, which can either accept or reject the generations. Our approach uses neural inference to mediate between the neural System 1 and the logical System 2. Results in robust story generation and grounded instruction-following show that this approach can increase the coherence and accuracy of neurally-based generations.},
	urldate = {2021-07-12},
	journal = {arXiv:2107.02794 [cs]},
	author = {Nye, Maxwell and Tessler, Michael Henry and Tenenbaum, Joshua B. and Lake, Brenden M.},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.02794},
}

@article{nasreen_rare-class_2021,
	title = {Rare-{Class} {Dialogue} {Act} {Tagging} for {Alzheimer}’s {Disease} {Diagnosis}},
	abstract = {Alzheimer’s Disease (AD) is associated with many characteristic changes, not only in an individual’s language, but also in the interactive patterns observed in dialogue. The most indicative changes of this latter kind tend to be associated with relatively rare dialogue acts (DAs), such as those involved in clariﬁcation exchanges and responses to particular kinds of questions. However, most existing work in DA tagging focuses on improving average performance, effectively prioritizing more frequent classes; it thus gives poor performance on these rarer classes and is not suited for application to AD analysis. In this paper, we investigate tagging speciﬁcally for rare class DAs, using a hierarchical BiLSTM model with various ways of incorporating information from previous utterances and DA tags in context. We show that this can give good performance for rare DA classes on both the general Switchboard corpus (SwDA) and an AD-speciﬁc conversational dataset, the Carolinas Conversation Collection (CCC); and that the tagger outputs then contribute useful information for distinguishing patients with and without AD.},
	language = {en},
	author = {Nasreen, Shamila and Hough, Julian and Purver, Matthew},
	year = {2021},
	pages = {11},
}

@book{jaaskelainen_conversation_2020,
	title = {Conversation {Analysis} as a {Design} {Research} {Method} for {Designing} {Socioculturally} {Contextual} {Conversational} {Agents}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:uu:diva-414120},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2021-07-13},
	author = {Jääskeläinen, Petra Pauliina},
	year = {2020},
}

@article{milton_ontological_2012,
	title = {On the ontological status of autism: the ‘double empathy problem’},
	volume = {27},
	issn = {0968-7599},
	shorttitle = {On the ontological status of autism},
	url = {https://doi.org/10.1080/09687599.2012.710008},
	doi = {10.1080/09687599.2012.710008},
	abstract = {In recent decades there has been much debate over the ontological status of autism and other neurological ‘disorders’, diagnosed by behavioural indicators, and theorised primarily within the field of cognitive neuroscience and psychological paradigms. Such cognitive-behavioural discourses abstain from acknowledging the universal issue of relationality and interaction in the formation of a contested and constantly reconstructed social reality, produced through the agency of its ‘actors’. The nature of these contested interactions will be explored in this current issues piece through the use of the term the ‘double empathy problem’, and how such a rendition produces a critique of autism being defined as a deficit in ‘theory of mind’, re-framing such issues as a question of reciprocity and mutuality. In keeping with other autistic self-advocates, this piece will refer to ‘autistic people’, and ‘those who identify as on the autism spectrum’, rather than ‘people with autism’.},
	number = {6},
	urldate = {2021-07-15},
	journal = {Disability \& Society},
	author = {Milton, Damian E. M.},
	month = oct,
	year = {2012},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09687599.2012.710008},
	pages = {883--887},
}

@article{alexander_emergence_1997,
	title = {The {Emergence} of {Repair} {Strategies} in {Infants} and {Toddlers}},
	volume = {18},
	copyright = {© 1997 by Thieme Medical Publishers, Inc.},
	issn = {0734-0478, 1098-9056},
	url = {http://www.thieme-connect.de/DOI/DOI?10.1055/s-2008-1064073},
	doi = {10.1055/s-2008-1064073},
	abstract = {Thieme E-Books \& E-Journals},
	language = {en},
	number = {3},
	urldate = {2021-07-15},
	journal = {Seminars in Speech and Language},
	author = {Alexander, Dianne and Wetherby, Amy and Prizant, Barry},
	year = {1997},
	note = {Publisher: © 1997 by Thieme Medical Publishers, Inc.},
	pages = {197--212},
}

@incollection{favareau_form_2009,
	address = {Dordrecht},
	series = {Biosemiotics},
	title = {Form, {Substance} and {Difference}},
	volume = {3},
	isbn = {978-1-4020-9649-5 978-1-4020-9650-1},
	url = {http://link.springer.com/10.1007/978-1-4020-9650-1},
	language = {en},
	urldate = {2021-07-19},
	booktitle = {Essential {Readings} in {Biosemiotics}},
	publisher = {Springer Netherlands},
	author = {Bateson, Gregory},
	editor = {Favareau, Donald},
	year = {2009},
	doi = {10.1007/978-1-4020-9650-1},
}

@article{erard_death_2021,
	title = {The death of {Gregory} {Bateson}, or why linguists should study language at the end of life},
	volume = {80},
	issn = {0271-5309},
	url = {https://www.sciencedirect.com/science/article/pii/S0271530921000537},
	doi = {10.1016/j.langcom.2021.06.003},
	abstract = {Linguists study language and language use in a range of settings and populations, yet they have not studied language, interaction, and communication behaviors and functions of the dying. This article argues that they should, using an account of the death of Gregory Bateson to make concrete the questions that could be asked, then showing some of the theoretical and practical contributions that the answers might make. The goal of such an endeavor would be to respectfully contribute a linguistic perspective to a core and truly universal human experience.},
	language = {en},
	urldate = {2021-07-19},
	journal = {Language \& Communication},
	author = {Erard, Michael},
	month = sep,
	year = {2021},
	pages = {114--123},
}

@article{bateson_cybernetics_1971,
	title = {The {Cybernetics} of “{Self}”: {A} {Theory} of {Alcoholism}},
	volume = {34},
	issn = {0033-2747},
	shorttitle = {The {Cybernetics} of “{Self}”},
	url = {https://doi.org/10.1080/00332747.1971.11023653},
	doi = {10.1080/00332747.1971.11023653},
	number = {1},
	urldate = {2021-07-19},
	journal = {Psychiatry},
	author = {Bateson, Gregory},
	month = feb,
	year = {1971},
	pmid = {27786045},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/00332747.1971.11023653},
	pages = {1--18},
}

@article{ruesch_structure_1949,
	title = {Structure and {Process} in {Social} {Relations}},
	volume = {12},
	issn = {0033-2747},
	url = {https://doi.org/10.1080/00332747.1949.11022724},
	doi = {10.1080/00332747.1949.11022724},
	number = {2},
	urldate = {2021-07-19},
	journal = {Psychiatry},
	author = {Ruesch, Jurgen and Bateson, Gregory},
	month = may,
	year = {1949},
	pmid = {18152792},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/00332747.1949.11022724},
	pages = {105--124},
}

@article{rae_social_1994,
	title = {Social {Fax}: {Repair} {Mechanisms} and {Intersubjectivity}},
	volume = {37},
	issn = {0002-7642},
	shorttitle = {Social {Fax}},
	url = {https://doi.org/10.1177/0002764294037006008},
	doi = {10.1177/0002764294037006008},
	number = {6},
	urldate = {2021-07-27},
	journal = {American Behavioral Scientist},
	author = {Rae, John P.},
	month = may,
	year = {1994},
	note = {Publisher: SAGE Publications Inc},
	pages = {824--838},
}

@inproceedings{casillas_analyzing_2021,
	title = {Analyzing contingent interactions in {R} with chattr},
	booktitle = {Proceedings of {CogSci} 2021},
	publisher = {Cognitive Science Society},
	author = {Casillas, Marisa and Scaff, Camila},
	year = {2021},
	pages = {2540--2546},
}

@book{shanker_wittgensteins_1998,
	address = {London ; New York},
	title = {Wittgenstein's remarks on the foundations of {AI}},
	isbn = {978-0-415-09794-9},
	publisher = {Routledge},
	author = {Shanker, Stuart},
	year = {1998},
}

@article{mondeme_comment_2018,
	title = {Comment parle-t-on aux animaux ? {Formes} et effets pragmatiques de l’adresse aux animaux de compagnie},
	volume = {N° 163},
	issn = {0181-4095},
	shorttitle = {Comment parle-t-on aux animaux ?},
	url = {https://www.cairn.info/revue-langage-et-societe-2018-1-page-77.htm},
	abstract = {Cet article examine les apports possibles d’une approche linguistique interactionniste pour l’analyse de la communication homme/animal. Les phénomènes communicatifs entre hommes et animaux sont fréquents, ordinaires, et quotidiens (dans les foyers ou au travail), et ont pourtant jusque-là fort peu fait l’objet d’investigations poussées, puisqu’ils échappent en partie à l’analyse éthologique (généralement intéressée au comportement communicatif d’une espèce propre) autant qu’à l’analyse linguistique (centrée sur le langage verbal articulé – par définition humain). Sur la base de données audio et vidéo recueillies dans divers contextes et en situations « naturelles » (versus expérimentales) donnant accès à des formes d’adresse jusque-là peu documentées dans la littérature, la présente contribution identifie trois modalités récurrentes dans l’adresse à l’animal domestique, et en examine les effets pragmatiques. Cela ouvre la brèche pour réenvisager, sur la base de contributions empiriques précises, certaines questions plus générales qui sont ordinairement soulevées quand on aborde les relations homme/animal, celle de l’agentivité des animaux, celle de l’attribution d’intentions, et celles des modalités de l’ajustement mutuel.},
	language = {fr},
	number = {1},
	urldate = {2021-07-27},
	journal = {Langage et societe},
	author = {Mondémé, Chloé},
	month = jan,
	year = {2018},
	note = {Bibliographie\_available: 1
Cairndomain: www.cairn.info
Cite Par\_available: 1
Publisher: Éditions de la Maison des sciences de l'homme},
	pages = {77--99},
}

@article{airenti_is_2010,
	title = {Is a naturalistic theory of communication possible?},
	volume = {11},
	issn = {1389-0417},
	url = {https://www.sciencedirect.com/science/article/pii/S1389041709000230},
	doi = {10.1016/j.cogsys.2009.03.002},
	abstract = {This article presents a theoretical discussion of the relationship between language and communication. I discuss Chomsky’s position on this topic. Chomsky claims that if it is possible to construct a scientific theory of the language faculty, there is no possibility to construct a scientific theory of communication because in communication human intentionality is involved. This position is contrasted by philosophers of language considering that communication is to be studied as a form of rational action. I maintain that both these positions are not supported by the evidence coming from developmental research. Taking a cognitive point of view I contend that a communicative faculty can be defined that develops since infancy to adulthood, which has features independent of language and action. Different steps in the development of the communicative ability are linked to a parallel development of the theory of mind. I then argue in favor of a distinction between collective action and communication considering that while collective action is common to human and nonhuman primates, communication is typically human.},
	language = {en},
	number = {2},
	urldate = {2021-07-27},
	journal = {Cognitive Systems Research},
	author = {Airenti, Gabriella},
	month = jun,
	year = {2010},
	pages = {165--180},
}

@article{oviatt_toward_2004,
	title = {Toward adaptive conversational interfaces: {Modeling} speech convergence with animated personas},
	volume = {11},
	issn = {1073-0516},
	shorttitle = {Toward adaptive conversational interfaces},
	url = {https://doi.org/10.1145/1017494.1017498},
	doi = {10.1145/1017494.1017498},
	abstract = {The design of robust interfaces that process conversational speech is a challenging research direction largely because users' spoken language is so variable. This research explored a new dimension of speaker stylistic variation by examining whether users' speech converges systematically with the text-to-speech (TTS) heard from a software partner. To pursue this question, a study was conducted in which twenty-four 7 to 10-year-old children conversed with animated partners that embodied different TTS voices. An analysis of children's amplitude, durational features, and dialogue response latencies confirmed that they spontaneously adapt several basic acoustic-prosodic features of their speech 10--50\%, with the largest adaptations involving utterance pause structure and amplitude. Children's speech adaptations were relatively rapid, bidirectional, and dynamically readaptable when introduced to new partners, and generalized across different types of users and TTS voices. Adaptations also occurred consistently, with 70--95\% of children converging with their partner's TTS, although individual differences in magnitude of adaptation were evident. In the design of future conversational systems, users' spontaneous convergence could be exploited to guide their speech within system processing bounds, thereby enhancing robustness. Adaptive system processing could yield further significant performance gains. The long-term goal of this research is the development of predictive models of human-computer communication to guide the design of new conversational interfaces.},
	number = {3},
	urldate = {2021-07-27},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Oviatt, Sharon and Darves, Courtney and Coulston, Rachel},
	month = sep,
	year = {2004},
	pages = {300--328},
}

@article{hebets_systems_2016,
	title = {A systems approach to animal communication},
	volume = {283},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rspb.2015.2889},
	doi = {10.1098/rspb.2015.2889},
	abstract = {Why animal communication displays are so complex and how they have evolved are active foci of research with a long and rich history. Progress towards an evolutionary analysis of signal complexity, however, has been constrained by a lack of hypotheses to explain similarities and/or differences in signalling systems across taxa. To address this, we advocate incorporating a systems approach into studies of animal communication—an approach that includes comprehensive experimental designs and data collection in combination with the implementation of systems concepts and tools. A systems approach evaluates overall display architecture, including how components interact to alter function, and how function varies in different states of the system. We provide a brief overview of the current state of the field, including a focus on select studies that highlight the dynamic nature of animal signalling. We then introduce core concepts from systems biology (redundancy, degeneracy, pluripotentiality, and modularity) and discuss their relationships with system properties (e.g. robustness, flexibility, evolvability). We translate systems concepts into an animal communication framework and accentuate their utility through a case study. Finally, we demonstrate how consideration of the system-level organization of animal communication poses new practical research questions that will aid our understanding of how and why animal displays are so complex.},
	number = {1826},
	urldate = {2021-08-05},
	journal = {Proceedings of the Royal Society B: Biological Sciences},
	author = {Hebets, Eileen A. and Barron, Andrew B. and Balakrishnan, Christopher N. and Hauber, Mark E. and Mason, Paul H. and Hoke, Kim L.},
	month = mar,
	year = {2016},
	note = {Publisher: Royal Society},
	pages = {20152889},
}

@article{etelamaki_affiliation_2021,
	title = {On affiliation and alignment: {Non}-cooperative uses of anticipatory completions in the context of tellings},
	issn = {1461-4456},
	shorttitle = {On affiliation and alignment},
	doi = {10.1177/14614456211017407},
	abstract = {In this paper, we address the larger notion of cooperation in interaction and its underlying dimensions as defined in Conversation Analysis: alignment and affiliation. Focusing on three cases from three different languages (Danish, Estonian and Finnish) we investigate a specific practice, that of anticipatory completions, in a particular context, that of storytelling, and show that the practice of completing another speaker’s turn in an anticipatory manner is not de facto definable as either an aligning or non-aligning action, nor can it be said to be either affiliating or non-affiliating. Through our analyses, we aim to distinguish and illustrate the manifold layers of and perspectives to alignment and affiliation and argue for their relevance for studies of interactional phenomena. We conclude that the notion of cooperation and its implementation through affiliating and/or aligning actions is a multi-layered and complex issue, the intricacies of which are best understood and captured through detailed sequential analyses.},
	language = {en},
	journal = {Discourse Studies},
	author = {Etelämäki, Marja and Heinemann, Trine and Vatanen, Anna},
	month = jun,
	year = {2021},
	pages = {14614456211017407},
}

@article{johnson_mixing_1988,
	title = {Mixing {Humans} and {Nonhumans} {Together}: {The} {Sociology} of a {Door}-{Closer}},
	volume = {35},
	issn = {0037-7791},
	shorttitle = {Mixing {Humans} and {Nonhumans} {Together}},
	url = {https://www.jstor.org/stable/800624},
	doi = {10.2307/800624},
	abstract = {Is sociology the study of social questions, or is it the study of associations? In this paper the author takes the second position and extends the study of our associations to nonhumans. To make the argument clearer, the author chooses one very humble nonhuman, a door-closer, and analyzes how this "purely" technical artifact is a highly moral, highly social actor that deserves careful consideration. Then the author proposes a vocabulary to follow human and nonhuman relations without stopping at artificial divides between what is purely technical and what is social. The author builds "its" or "his" own text in such a way that the text itself is a machine that exemplifies several of the points made by the author. In particular, the author is constructed and deconstructed several times to show how many social actors are inscribed or prescribed by machines and automatisms.},
	number = {3},
	urldate = {2021-08-10},
	journal = {Social Problems},
	author = {Johnson, Jim},
	year = {1988},
	note = {Publisher: [Oxford University Press, Society for the Study of Social Problems]},
	pages = {298--310},
}

@incollection{jankovic_joint_2018,
	address = {London New York},
	series = {Routledge handbooks in philosophy},
	title = {Joint {Commitment}},
	isbn = {978-1-315-76857-1 978-1-138-78363-8},
	language = {eng},
	booktitle = {The {Routledge} {Handbook} of {Collective} {Intentionality}},
	publisher = {Routledge, Taylor \& Francis Group},
	author = {Gilbert, Margaret},
	editor = {Jankovic, Marija and Ludwig, Kirk},
	year = {2018},
}

@article{sikveland_failed_2019,
	title = {Failed summons: {Phonetic} features of persistence and intensification in crisis negotiation},
	volume = {150},
	issn = {0378-2166},
	shorttitle = {Failed summons},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216617307993},
	doi = {10.1016/j.pragma.2019.01.023},
	abstract = {This paper explores crisis negotiators' practices for summoning persons in crisis who are unavailable, unable or unwilling to respond. A corpus of audio recorded interactions between a UK police hostage and crisis negotiation unit and (suicidal) people in crisis was analysed. The analysis shows how low to moderate phonetic upgrades in pitch, and small variations in loudness, duration and articulatory setting are associated with interactionally ‘re-doing’ a subsequent summons. In contrast, marked phonetic upgrades in pitch, loudness and articulatory setting are associated with an increase in danger or concern. And whereas phonetic upgrading of a self-repeated summons is found in cases where the recipient is unavailable, unable or unwilling to respond, phonetic downgrading treats the silence as responsiveness in progress, where the summons repetition does extra work to further secure the person's joint attention to a projected new course of action. I discuss the complexities of applying an ‘upgrade-downgrade’ continuum to account for repeated action and consider the wider implications of phonetic design on crisis management.},
	language = {en},
	urldate = {2021-08-17},
	journal = {Journal of Pragmatics},
	author = {Sikveland, Rein Ove},
	month = sep,
	year = {2019},
	pages = {167--179},
}

@article{hardt_can_2020,
	title = {Can you hear me now? {A} review of signal transmission and experimental evidence for the acoustic adaptation hypothesis},
	volume = {0},
	issn = {0952-4622},
	shorttitle = {Can you hear me now?},
	url = {https://doi.org/10.1080/09524622.2020.1858448},
	doi = {10.1080/09524622.2020.1858448},
	abstract = {The Acoustic Adaptation Hypothesis (AAH) posits that animal acoustic signals used in long-range communication should be adapted to transmit well within the habitats in which they evolved. However, comparative studies of signal form indicate mixed support for predictions of the AAH. Several studies have employed experimental playback approaches to testing signal transmission which can complement comparative studies. Here, we summarise these experimental playback tests of the AAH in birds, mammals, insects, and anurans, we describe the methodologies used in these tests, and we assess the evidence for habitat-specific signal degradation and species-specific acoustic fidelity (i.e. whether signals propagate best in native versus foreign habitats). Experimental evidence, like comparative evidence, varies across habitats and taxa. Although transmission properties consistently differed by habitat, with closed habitats degrading signals more than open habitats, animal signals were not always adapted to propagate best within their native habitats. Researchers felt they had convincing evidence for species-specific acoustic fidelity in less than half of the 67 reviewed studies, with the most support found for birds and the least for anurans. We discuss potential explanations for differences within and between habitats and taxa and conclude with suggestions for standardised methodology and areas of future research.},
	number = {0},
	urldate = {2021-08-16},
	journal = {Bioacoustics},
	author = {Hardt, Braelei and Benedict, Lauryn},
	month = dec,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/09524622.2020.1858448},
	pages = {1--27},
}

@article{mcilvenny_constructing_1993,
	title = {Constructing {Societies} and {Social} {Machines}: {Stepping} {Out} of the {Turing} {Test} {Discourse}},
	volume = {3},
	issn = {2191-026X, 0334-1860},
	shorttitle = {Constructing {Societies} and {Social} {Machines}},
	url = {https://www.degruyter.com/document/doi/10.1515/JISYS.1993.3.2-4.119/html},
	doi = {10.1515/JISYS.1993.3.2-4.119},
	number = {2-4},
	urldate = {2021-08-16},
	journal = {Journal of Intelligent Systems},
	author = {McIlvenny, P.B.},
	month = jan,
	year = {1993},
}

@article{saygin_pragmatics_2002,
	title = {Pragmatics in human-computer conversations},
	volume = {34},
	issn = {1879-1387(Electronic),0378-2166(Print)},
	doi = {10.1016/S0378-2166(02)80001-7},
	abstract = {Provides a pragmatic analysis of human-computer conversations carried out within the context of computers participating in Turing Tests. The Turing Test posits that to be granted intelligence, a computer should imitate human conversational behavior so well as to be indistinguishable from a real human. Researchers carried out an empirical study exploring the relationship between computers' violations of P. H. Grice's (e.g., 1998) cooperative principle and conversational maxims, and their success in imitating human language use. Based on conversation analysis and a large survey, they found that different maxims have different effects when violated, but more often than not, when computers violate the maxims, they reveal their identity. The results indicate that Grice's cooperative principle is at work during conversations with computers. On the other hand, studying human-computer communication may require some modifications of existing frameworks in pragmatics because of certain characteristics of these conversational environments. Pragmatics constitutes a serious challenge to computational linguistics. It may be that the biggest hurdle in developing computer programs that can successfully carry out conversations will be modeling the ability to "cooperate." (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
	number = {3},
	journal = {Journal of Pragmatics},
	author = {Saygin, Ayse Pinar and Cicekli, Ilyas},
	year = {2002},
	note = {Place: Netherlands
Publisher: Elsevier Science},
	pages = {227--258},
}

@incollection{hayashi_availability_2013,
	address = {Cambridge},
	series = {Studies in {Interactional} {Sociolinguistics}},
	title = {Availability as a trouble source in directive-response sequences},
	number = {30},
	booktitle = {Conversational {Repair} and {Human} {Understanding}},
	publisher = {Cambridge University Press},
	author = {Kidwell, Mardi},
	editor = {Hayashi, Makoto and Raymond, Geoffrey and Sidnell, Jack},
	year = {2013},
}

@incollection{beneteau_communication_2019,
	address = {New York, NY, USA},
	title = {Communication {Breakdowns} {Between} {Families} and {Alexa}},
	isbn = {978-1-4503-5970-2},
	url = {https://doi.org/10.1145/3290605.3300473},
	abstract = {We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in pre- and post- deployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa's responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants' abilities to collaborate together with users to repair communication breakdowns.},
	urldate = {2021-08-17},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Beneteau, Erin and Richards, Olivia K. and Zhang, Mingrui and Kientz, Julie A. and Yip, Jason and Hiniker, Alexis},
	month = may,
	year = {2019},
	pages = {1--13},
}

@incollection{ashktorab_resilient_2019,
	address = {New York, NY, USA},
	title = {Resilient {Chatbots}: {Repair} {Strategy} {Preferences} for {Conversational} {Breakdowns}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Resilient {Chatbots}},
	url = {https://doi.org/10.1145/3290605.3300484},
	abstract = {Text-based conversational systems, also referred to as chatbots, have grown widely popular. Current natural language understanding technologies are not yet ready to tackle the complexities in conversational interactions. Breakdowns are common, leading to negative user experiences. Guided by communication theories, we explore user preferences for eight repair strategies, including ones that are common in commercially-deployed chatbots (e.g., confirmation, providing options), as well as novel strategies that explain characteristics of the underlying machine learning algorithms. We conducted a scenario-based study to compare repair strategies with Mechanical Turk workers (N=203). We found that providing options and explanations were generally favored, as they manifest initiative from the chatbot and are actionable to recover from breakdowns. Through detailed analysis of participants' responses, we provide a nuanced understanding on the strengths and weaknesses of each repair strategy.},
	urldate = {2021-08-17},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ashktorab, Zahra and Jain, Mohit and Liao, Q. Vera and Weisz, Justin D.},
	month = may,
	year = {2019},
	pages = {1--12},
}

@incollection{fiebich_pluralism_2016,
	title = {Pluralism, interaction, and the ontogeny of social cognition},
	isbn = {978-1-315-53017-8},
	abstract = {This chapter aims to provide an overview of the development of a variety of socio-cognitive 
processes and procedures1 throughout ontogeny. For many years the received view of social 
cognition took it for granted that it was based, wholly or primarily, in mindreading abilities – 
the ability to attribute contentful mental states to others by means of deploying folk psychological theories or by running simulation routines on one’s own mental states. From the late 
1970s through the 1990s it would be fair to say that the received view was that everyday social 
cognition was always based in mental state attribution achieved by theorizing about other 
minds, simulating other minds, or some combination of the two.},
	booktitle = {The {Routledge} {Handbook} of {Philosophy} of the {Social} {Mind}},
	publisher = {Routledge},
	author = {Fiebich, Anika and Gallagher, Shaun and Hutto, Daniel D.},
	year = {2016},
	note = {Num Pages: 14},
}

@article{kiverstein_social_2011,
	title = {Social {Understanding} without {Mentalizing}},
	volume = {39},
	issn = {0276-2080},
	url = {https://www.jstor.org/stable/43154592},
	abstract = {The standard view in philosophy and psychology claims that mentalizing is necessary and sufficient for social understanding. Mentalizing (also known as "mindreading") is the name given to the cognitive capacities humans employ in explaining and predicting their own and other's actions. The standard view is rejected by philosophers working in the phenomenological tradition. They have argued that mentalizing is neither necessary nor sufficient for social understanding. They suggest instead that most of the time we understand each other through what Shaun Gallagher has called "embodied practices." My aim in this paper is to clarify and defend the claim that social understanding is grounded in embodied practice.},
	number = {1},
	urldate = {2021-08-17},
	journal = {Philosophical Topics},
	author = {Kiverstein, Julian},
	year = {2011},
	note = {Publisher: University of Arkansas Press},
	pages = {41--65},
}

@inproceedings{ozkan_specific_2021,
	title = {Specific hand motion patterns correlate to miscommunications during dyadic conversations},
	doi = {10.1109/ICDL49984.2021.9515613},
	abstract = {Effective and natural communication is achieved by exchanging several multi-modal signals through highly coordinated communication mechanisms. These mechanisms are frequently subject to troubles of speaking in the form of disfluencies, typically followed by a self-repair from the speaker (i.e. to try to fix the misunderstanding): overall, these are signs of a possible miscommunication. Automatically detecting miscommunications is crucial to implement conversational agents, either digital or robotic, that could successfully interact with people. This can be done by searching for specific patterns across different communication channels, for example disfluencies in the speech signal or specific movements of the limbs. However, what are the motion patterns that correlate to miscommunications is still unclear. In this paper we report a human study in which we identify one of such patterns: in particular, we show that the hands of the speaker reliably move upwards during miscommunications. We performed a statistical analysis of synchronized speech and motion tracking data extracted from natural conversations of 15 dyads; our results show a statistically significant tendency of moving hands upwards during speech disfluencies, which are a clear sign of miscommunication.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Development} and {Learning} ({ICDL})},
	author = {Özkan, Elif Ecem and Gurion, Tom and Hough, Julian and Healey, Patrick G.T. and Jamone, Lorenzo},
	month = aug,
	year = {2021},
	pages = {1--6},
}

@article{shafto_cooperative_2021,
	title = {Cooperative communication as belief transport},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661321001820},
	doi = {10.1016/j.tics.2021.07.012},
	abstract = {Recent research formalizes cooperative communication as belief transport using the mathematical theory of optimal transport. This formalization allows rigorous a priori analysis of the statistical and ecological properties of models of cooperative communication, unification of prior models and analysis of their differences, and promising directions for future research.},
	language = {en},
	urldate = {2021-08-30},
	journal = {Trends in Cognitive Sciences},
	author = {Shafto, Patrick and Wang, Junqi and Wang, Pei},
	month = aug,
	year = {2021},
}

@inproceedings{wang_sequential_2020,
	title = {Sequential {Cooperative} {Bayesian} {Inference}},
	url = {https://proceedings.mlr.press/v119/wang20u.html},
	language = {en},
	urldate = {2021-08-30},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Wang, Junqi and Wang, Pei and Shafto, Patrick},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {10039--10049},
}

@misc{sacks_sacks_1974,
	title = {Sacks' letter to {Schegloff}},
	author = {Sacks, Harvey},
	month = mar,
	year = {1974},
}

@incollection{barth-weingarten_or_nodate,
	title = {On (or not on) the ‘upgrading–downgrading continuum’: {The} case of ‘prosodic marking’ in self-repair},
	url = {http://www.verlag-gespraechsforschung.de/2014/pdf/prosodie.pdf#page=70},
	urldate = {2021-09-07},
	booktitle = {Prosodie und {Phonetik} in der {Interaktion} ({Prosody} and phonetics in interaction)},
	author = {Plug, Leendert},
	editor = {Barth-Weingarten, Dagmar and Szczepek Reed, Beatrice},
}

@article{varonis_miscommunication_1985,
	title = {Miscommunication in native/nonnative conversation*},
	volume = {14},
	issn = {1469-8013, 0047-4045},
	url = {https://www.cambridge.org/core/journals/language-in-society/article/miscommunication-in-nativenonnative-conversation/02DD9EE3C3838A1A74EB55984D3F8521},
	doi = {10.1017/S0047404500011295},
	abstract = {In this paper we discuss miscommunication in exchanges between native speakers and nonnative speakers of a language, focusing on an analysis of a service encounter telephone conversation between a nonnative speaker and a native speaker television repair shop employee. We present a goal-based model of conversation and a coding system for interpreting utterances, both of which are necessary for understanding the type of miscommunication which occurred in the conversation described herein. We argue that the lack of shared background on the part of the interlocutors interacted with their lack of shared linguistic code. In general, such interactions hinder successful communication and increase the probability that the miscommunication will not be recognized and thus not easily resolved. We show that a complete analysis of native/nonnative conversations must minimally invoke notions of correct interpretation, confidence in interpretation, goals of a conversation, shared beliefs, and linguistic as well as cultural systems. (Sociolinguistics, nonnative interactions, conversational analysis, American English)},
	language = {en},
	number = {3},
	urldate = {2021-09-07},
	journal = {Language in Society},
	author = {Varonis, Evangeline Marlos and Gass, Susan M.},
	month = sep,
	year = {1985},
	note = {Publisher: Cambridge University Press},
	pages = {327--343},
}

@article{hauser_private_2015,
	title = {Private {Speech} as {Social} {Action}},
	volume = {2},
	issn = {2051-9699},
	url = {https://uec.repo.nii.ac.jp/index.php?active_action=repository_view_main_item_detail&page_id=13&block_id=21&item_id=8932&item_no=1},
	doi = {10.1558/lst.v2i2.26615},
	abstract = {CMS,Netcommons,Maple},
	language = {ja},
	number = {2},
	urldate = {2021-09-07},
	journal = {Language and Sociocultural Theory},
	author = {Hauser, Eric},
	month = jul,
	year = {2015},
	pages = {119--138},
}

@book{barth-weingarten_prosodie_nodate,
	title = {Prosodie und {Phonetik} in der {Interaktion} ({Prosody} and phonetics in interaction)},
	url = {http://www.verlag-gespraechsforschung.de/2014/pdf/prosodie.pdf#page=70},
	urldate = {2021-09-07},
	editor = {Barth-Weingarten, Dagmar and Szczepek Reed, Beatrice},
}

@article{shuy_evidence_1990,
	title = {Evidence of {Cooperation} in {Conversation}},
	volume = {606},
	issn = {1749-6632},
	url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-6632.1990.tb37738.x},
	doi = {10.1111/j.1749-6632.1990.tb37738.x},
	language = {en},
	number = {1},
	urldate = {2021-09-07},
	journal = {Annals of the New York Academy of Sciences},
	author = {Shuy, Roger W.},
	year = {1990},
	note = {\_eprint: https://nyaspubs.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1749-6632.1990.tb37738.x},
	pages = {85--105},
}

@article{podlesskaya_corpus-based_2015,
	title = {A corpus-based study of self-repairs in {Russian} spoken monologues},
	volume = {39},
	issn = {0304-3487, 1572-8714},
	url = {http://link.springer.com/10.1007/s11185-014-9142-1},
	doi = {10.1007/s11185-014-9142-1},
	abstract = {The paper investigates self-initiated self-repairs in the Prosodically Annotated Corpus of Spoken Russian (PrACS-Russ), a unique resource where spontaneous speech phenomena (speech errors, repairs, ﬁlled pauses etc.) in Russian natural discourse are systematically registered in transcripts synchronized to audio recordings. Based on a qualitative and a preliminary quantitative analysis of more than 800 repairs, two main strategies of selfrepairing are identiﬁed and described: the ‘on-line strategy’ associated with speech disﬂuencies that break the lexical, grammatical or prosodic coherence of the produced discourse, e.g. with truncating the segment under repair, and the ‘oﬀ-line strategy’ that does not entail disﬂuency integrating repairs into ﬂuent planned speech production. Our analysis shows that self-repairs appear with overall rates of 1.8–2.9 instances per 100 words. On-line repairs vastly outnumber oﬀ-line repairs: they comprise 82 \% to 90 \% of the total number of repairs in the analyzed subcorpora of PrACS-Russ. In the absolute majority (83–91 \%) of repairs, the segment under repair and its corrected counterpart are structurally and semantically isomorphic, i.e. show systematic parallelism in their meaning, grammatical form, syntactic function or even in their phonetic shell (as, e.g. in ‘slips of the tongue’ cases). Main types of isomorphism between the segment under repair and its corrected counterpart are identiﬁed and investigated in the paper.},
	language = {en},
	number = {1},
	urldate = {2021-09-07},
	journal = {Russian Linguistics},
	author = {Podlesskaya, Vera I.},
	month = apr,
	year = {2015},
	pages = {63--79},
}

@article{bosco_recognition_2006,
	series = {Focus-on {Issue}: {The} {Pragmatics} of {Failure} and {Success}},
	title = {Recognition and repair of communicative failures: {A} developmental perspective},
	volume = {38},
	issn = {0378-2166},
	shorttitle = {Recognition and repair of communicative failures},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216605001414},
	doi = {10.1016/j.pragma.2005.06.011},
	abstract = {The aim of our study is to analyze the cognitive processes underlying recognition and repair of communicative failures. In particular, following the tenets of Cognitive Pragmatics, a theory of the mental processes underlying the comprehension and production of communicative acts, we propose an original taxonomy of the different kinds of failure which may occur in communicative interaction: Failure of the expression act, Failure of the actor's meaning, and Failure of the communicative effect. In particular, we operationally define both recognition and repair of the communicative failures. Finally, we predict a different trend in difficulty for the recognition and the repair of the three possible kinds of failure. The hypotheses are preliminarily confirmed by the results of an experiment conducted with children aged 3–8 years.},
	language = {en},
	number = {9},
	urldate = {2021-09-12},
	journal = {Journal of Pragmatics},
	author = {Bosco, Francesca M. and Bucciarelli, Monica and Bara, Bruno G.},
	month = sep,
	year = {2006},
	pages = {1398--1429},
}

@incollection{katz_beginnings_2002,
	address = {Cambridge, UK ; New York},
	title = {Beginnings in the telephone},
	isbn = {978-0-521-80771-5 978-0-521-00266-0},
	booktitle = {Perpetual contact: mobile communication, private talk, public performance},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Katz, James Everett and Aakhus, Mark A.},
	year = {2002},
	pages = {284--318},
}

@incollection{katz_opening_2002,
	address = {Cambridge, UK ; New York},
	title = {On “{Opening} {Sequencing}”: a framing statement},
	isbn = {978-0-521-80771-5 978-0-521-00266-0},
	booktitle = {Perpetual contact: mobile communication, private talk, public performance},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Katz, James Everett and Aakhus, Mark A.},
	year = {2002},
	pages = {321--325},
}

@incollection{katz_opening_2002-1,
	address = {Cambridge, UK ; New York},
	title = {Opening {Sequencing}},
	isbn = {978-0-521-80771-5 978-0-521-00266-0},
	booktitle = {Perpetual contact: mobile communication, private talk, public performance},
	publisher = {Cambridge University Press},
	author = {Schegloff, Emanuel A.},
	editor = {Katz, James Everett and Aakhus, Mark A.},
	year = {2002},
	pages = {326--385},
}

@article{jadoul_building_2020,
	title = {Building bridges between software ecosystems: {Parselmouth}, a {Python} interface for {Praat}},
	volume = {148},
	issn = {0001-4966},
	shorttitle = {Building bridges between software ecosystems},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.5147768},
	doi = {10.1121/1.5147768},
	number = {4},
	urldate = {2021-09-09},
	journal = {The Journal of the Acoustical Society of America},
	author = {Jadoul, Yannick},
	month = oct,
	year = {2020},
	note = {Publisher: Acoustical Society of America},
	pages = {2791--2791},
}

@incollection{bruner_role_1985,
	address = {New York, NY},
	series = {Springer {Series} in {Social} {Psychology}},
	title = {The {Role} of {Interaction} {Formats} in {Language} {Acquisition}},
	isbn = {978-1-4612-5074-6},
	url = {https://doi.org/10.1007/978-1-4612-5074-6_2},
	abstract = {Learning a native language is an accomplishment within the grasp of any toddler, yet discovering how children do it has eluded generations of philosophers and linguists. I would like to take this opportunity to ask anew some puzzling questions about what it is, beyond a splendid nervous system, that makes it possible for the young child to acquire language so swiftly and so effortlessly. Perhaps they are no longer puzzling questions save to those of us who have spent a great deal of time working and brooding over whether the acquisition of knowledge about the social world and about the world generally is in some sense constitutive of language.},
	language = {en},
	urldate = {2021-09-12},
	booktitle = {Language and {Social} {Situations}},
	publisher = {Springer},
	author = {Bruner, Jerome},
	editor = {Forgas, Joseph P.},
	year = {1985},
	doi = {10.1007/978-1-4612-5074-6_2},
	pages = {31--46},
}

@article{rossi_composite_2018,
	title = {Composite {Social} {Actions}: {The} {Case} of {Factual} {Declaratives} in {Everyday} {Interaction}},
	volume = {51},
	issn = {0835-1813},
	shorttitle = {Composite {Social} {Actions}},
	url = {https://doi.org/10.1080/08351813.2018.1524562},
	doi = {10.1080/08351813.2018.1524562},
	abstract = {When taking a turn at talk, a speaker normally accomplishes a sequential action such as a question, answer, complaint, or request. Sometimes, however, a turn at talk may accomplish not a single but a composite action, involving a combination of more than one action. I show that factual declaratives (e.g., “the feed drip has finished”) are recurrently used to implement composite actions consisting of both an informing and a request or, alternatively, a criticism and a request. A key determinant between these is the recipient’s epistemic access to what the speaker is describing. Factual declaratives afford a range of possible responses, which can tell us how the composite action has been understood and give us insights into its underlying structure. Evidence for the stacking of composite actions, however, is not always directly available in the response and may need to be pieced together with the help of other linguistic and contextual considerations. Data are in Italian with English translation.},
	number = {4},
	urldate = {2021-09-12},
	journal = {Research on Language and Social Interaction},
	author = {Rossi, Giovanni},
	month = oct,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2018.1524562},
	pages = {379--397},
}

@incollection{floyd_recruiting_2020,
	address = {Berlin},
	series = {Diversity {Linguistics}},
	title = {Recruiting assistance and collaboration in {Polish}},
	booktitle = {Getting others to do things: {A} pragmatic typology of recruitments},
	publisher = {Language Science Press},
	author = {Zinken, Jörg},
	editor = {Floyd, Simeon and Rossi, Giovanni and Enfield, N. J.},
	year = {2020},
	pages = {281--324},
}

@inproceedings{mirjalili_gender_2018,
	title = {Gender {Privacy}: {An} {Ensemble} of {Semi} {Adversarial} {Networks} for {Confounding} {Arbitrary} {Gender} {Classifiers}},
	shorttitle = {Gender {Privacy}},
	doi = {10.1109/BTAS.2018.8698605},
	abstract = {Recent research has proposed the use of Semi Adversarial Networks (SAN) for imparting privacy to face images. SANs are convolutional autoencoders that perturb face images such that the perturbed images cannot be reliably used by an attribute classifier (e.g., a gender classifier) but can still be used by a face matcher for matching purposes. However, the generalizability of SANs across multiple arbitrary gender classifiers has not been demonstrated in the literature. In this work, we tackle the generalization issue by designing an ensemble SAN model that generates a diverse set of perturbed outputs for a given input face image. This is accomplished by enforcing diversity among the individual models in the ensemble through the use of different data augmentation techniques. The goal is to ensure that at least one of the perturbed output faces will confound an arbitrary, previously unseen gender classifier. Extensive experiments using different unseen gender classifiers and face matchers are performed to demonstrate the efficacy of the proposed paradigm in imparting gender privacy to face images.},
	booktitle = {2018 {IEEE} 9th {International} {Conference} on {Biometrics} {Theory}, {Applications} and {Systems} ({BTAS})},
	author = {Mirjalili, Vahid and Raschka, Sebastian and Ross, Arun},
	month = oct,
	year = {2018},
	note = {ISSN: 2474-9699},
	pages = {1--10},
}

@article{liu_mitigating_2020,
	title = {Mitigating {Gender} {Bias} for {Neural} {Dialogue} {Generation} with {Adversarial} {Learning}},
	url = {http://arxiv.org/abs/2009.13028},
	abstract = {Dialogue systems play an increasingly important role in various aspects of our daily life. It is evident from recent research that dialogue systems trained on human conversation data are biased. In particular, they can produce responses that reflect people's gender prejudice. Many debiasing methods have been developed for various NLP tasks, such as word embedding. However, they are not directly applicable to dialogue systems because they are likely to force dialogue models to generate similar responses for different genders. This greatly degrades the diversity of the generated responses and immensely hurts the performance of the dialogue models. In this paper, we propose a novel adversarial learning framework Debiased-Chat to train dialogue models free from gender bias while keeping their performance. Extensive experiments on two real-world conversation datasets show that our framework significantly reduces gender bias in dialogue models while maintaining the response quality. The implementation of the proposed framework is released.},
	urldate = {2021-09-14},
	journal = {arXiv:2009.13028 [cs]},
	author = {Liu, Haochen and Wang, Wentao and Wang, Yiqi and Liu, Hui and Liu, Zitao and Tang, Jiliang},
	month = oct,
	year = {2020},
	note = {arXiv: 2009.13028},
}

@article{dinan_multi-dimensional_2020,
	title = {Multi-{Dimensional} {Gender} {Bias} {Classification}},
	url = {http://arxiv.org/abs/2005.00614},
	abstract = {Machine learning models are trained to find patterns in data. NLP models can inadvertently learn socially undesirable patterns when training on gender biased text. In this work, we propose a general framework that decomposes gender bias in text along several pragmatic and semantic dimensions: bias from the gender of the person being spoken about, bias from the gender of the person being spoken to, and bias from the gender of the speaker. Using this fine-grained framework, we automatically annotate eight large scale datasets with gender information. In addition, we collect a novel, crowdsourced evaluation benchmark of utterance-level gender rewrites. Distinguishing between gender bias along multiple dimensions is important, as it enables us to train finer-grained gender bias classifiers. We show our classifiers prove valuable for a variety of important applications, such as controlling for gender bias in generative models, detecting gender bias in arbitrary text, and shed light on offensive language in terms of genderedness.},
	urldate = {2021-09-14},
	journal = {arXiv:2005.00614 [cs]},
	author = {Dinan, Emily and Fan, Angela and Wu, Ledell and Weston, Jason and Kiela, Douwe and Williams, Adina},
	month = may,
	year = {2020},
	note = {arXiv: 2005.00614},
}

@inproceedings{koolen_these_2017,
	address = {Valencia, Spain},
	title = {These are not the {Stereotypes} {You} are {Looking} {For}: {Bias} and {Fairness} in {Authorial} {Gender} {Attribution}},
	shorttitle = {These are not the {Stereotypes} {You} are {Looking} {For}},
	url = {https://aclanthology.org/W17-1602},
	doi = {10.18653/v1/W17-1602},
	abstract = {Stylometric and text categorization results show that author gender can be discerned in texts with relatively high accuracy. However, it is difficult to explain what gives rise to these results and there are many possible confounding factors, such as the domain, genre, and target audience of a text. More fundamentally, such classification efforts risk invoking stereotyping and essentialism. We explore this issue in two datasets of Dutch literary novels, using commonly used descriptive (LIWC, topic modeling) and predictive (machine learning) methods. Our results show the importance of controlling for variables in the corpus and we argue for taking care not to overgeneralize from the results.},
	urldate = {2021-09-14},
	booktitle = {Proceedings of the {First} {ACL} {Workshop} on {Ethics} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Koolen, Corina and van Cranenburgh, Andreas},
	month = apr,
	year = {2017},
	pages = {12--22},
}

@article{keyes_misgendering_2018,
	title = {The {Misgendering} {Machines}: {Trans}/{HCI} {Implications} of {Automatic} {Gender} {Recognition}},
	volume = {2},
	shorttitle = {The {Misgendering} {Machines}},
	url = {https://doi.org/10.1145/3274357},
	doi = {10.1145/3274357},
	abstract = {Automatic Gender Recognition (AGR) is a subfield of facial recognition that aims to algorithmically identify the gender of individuals from photographs or videos. In wider society the technology has proposed applications in physical access control, data analytics and advertising. Within academia, it is already used in the field of Human-Computer Interaction (HCI) to analyse social media usage. Given the long-running critiques of HCI for failing to consider and include transgender (trans) perspectives in research, and the potential implications of AGR for trans people if deployed, I sought to understand how AGR and HCI understand the term "gender", and how HCI describes and deploys gender recognition technology. Using a content analysis of papers from both fields, I show that AGR consistently operationalises gender in a trans-exclusive way, and consequently carries disproportionate risk for trans people subject to it. In addition, I use the dearth of discussion of this in HCI papers that apply AGR to discuss how HCI operationalises gender, and the implications that this has for the field's research. I conclude with recommendations for alternatives to AGR, and some ideas for how HCI can work towards a more effective and trans-inclusive treatment of gender.},
	number = {CSCW},
	urldate = {2021-09-14},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Keyes, Os},
	month = nov,
	year = {2018},
	pages = {88:1--88:22},
}

@techreport{nguyen_systematic_2021,
	title = {A systematic review and {Bayesian} meta-analysis of the development of turn taking in adult-child vocal interactions},
	url = {https://psyarxiv.com/3bak6/},
	abstract = {Background: Turn taking appears to be an almost universal phenomenon in communicative behavior and requires tight coordination between interlocutors. However, there is no current consensus on how and when infants develop the ability to take turns in vocal interactions and which mechanisms are involved. 
Aim: The current study aims at better understanding the current state of research on the development of turn-taking behaviors in human infants. In particular, we want to map the developmental trajectory of turn-taking abilities and identify key moderators affecting them.
Method: We performed a systematic review and Bayesian multilevel meta-analysis of studies reporting response latencies in infant-adult dyadic interactions.
Results:  We found a poorly connected field (low rate of citations between papers), from which we identified 26 studies and 78 unique estimates of infant response latency. Infants display fast response latencies at an early point in development, which gradually increase up to 40 months. Infants’ responses also appear to be strongly related to the pause duration of their adult conversational partners, and are slower in groups with atypical development.
Conclusions: We identify current pitfalls and new directions of research. Specifically, we advocate for the development of shared longitudinal cross-linguistic corpora with turn-by-turn data and rich assessment of the infants' linguistic and social development. We also recommend more explicit definition and testing of computational models of the mechanisms underlying turn-taking.},
	urldate = {2021-09-14},
	institution = {PsyArXiv},
	author = {Nguyen, Vivian and Versyp, Otto and Cox, Christopher Martin Mikkelsen and Fusaroli, Riccardo},
	month = sep,
	year = {2021},
	doi = {10.31234/osf.io/3bak6},
	note = {type: article},
}

@book{sorjonen_responding_2001,
	address = {Amsterdam},
	series = {Pragmatics \& {Beyond} {New} {Series}},
	title = {Responding in {Conversation}: {A} study of response particles in {Finnish}},
	volume = {70},
	isbn = {978-90-272-5085-8 978-1-55619-948-6 978-90-272-9745-7},
	shorttitle = {Responding in {Conversation}},
	url = {http://www.jbe-platform.com/content/books/9789027297457},
	language = {en},
	urldate = {2021-09-15},
	publisher = {John Benjamins Publishing Company},
	author = {Sorjonen, Marja-Leena},
	month = dec,
	year = {2001},
	doi = {10.1075/pbns.70},
}

@article{samanta_towards_2017,
	title = {Towards {Crafting} {Text} {Adversarial} {Samples}},
	url = {http://arxiv.org/abs/1707.02812},
	abstract = {Adversarial samples are strategically modified samples, which are crafted with the purpose of fooling a classifier at hand. An attacker introduces specially crafted adversarial samples to a deployed classifier, which are being mis-classified by the classifier. However, the samples are perceived to be drawn from entirely different classes and thus it becomes hard to detect the adversarial samples. Most of the prior works have been focused on synthesizing adversarial samples in the image domain. In this paper, we propose a new method of crafting adversarial text samples by modification of the original samples. Modifications of the original text samples are done by deleting or replacing the important or salient words in the text or by introducing new words in the text sample. Our algorithm works best for the datasets which have sub-categories within each of the classes of examples. While crafting adversarial samples, one of the key constraint is to generate meaningful sentences which can at pass off as legitimate from language (English) viewpoint. Experimental results on IMDB movie review dataset for sentiment analysis and Twitter dataset for gender detection show the efficiency of our proposed method.},
	urldate = {2021-09-14},
	journal = {arXiv:1707.02812 [cs]},
	author = {Samanta, Suranjana and Mehta, Sameep},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.02812},
}

@phdthesis{wagner_conversational_2021,
	address = {Boulder},
	type = {{PhD} {Thesis}},
	title = {Conversational {Storytelling} in {Arapaho}: {A} {Grammar} of {Narrative} {Initiations}},
	shorttitle = {Conversational {Storytelling} in {Arapaho}},
	school = {University of Colorado at Boulder},
	author = {Wagner, Irina A.},
	year = {2021},
}

@phdthesis{luke_conversation_1988,
	address = {York},
	type = {{PhD}},
	title = {A conversation analytic approach to the study of utterance particles in {Cantonese}},
	language = {en},
	school = {University of York},
	author = {Luke, Kang Kwong},
	year = {1988},
}

@phdthesis{lindstrom_language_1999,
	address = {Uppsala},
	type = {{PhD} thesis},
	title = {Language as social action : {Grammar}, prosody, and interaction in {Swedish} conversation : grammatik, prosodi och interaktion i svenska samtal},
	shorttitle = {Language as social action},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:uu:diva-50},
	abstract = {This study contributes to a larger research programme that links grammar and prosody on the one hand with talk-in-interaction on the other. An underlying assumption of this study is that language i ...},
	language = {eng},
	urldate = {2021-09-20},
	school = {Uppsala University},
	author = {Lindström, Anna},
	year = {1999},
	note = {Publisher: Acta Universitatis Upsaliensis},
}

@article{lindstrom_assessments_2009,
	title = {Assessments in {Social} {Interaction}: {Introduction} to the {Special} {Issue}},
	volume = {42},
	issn = {0835-1813},
	shorttitle = {Assessments in {Social} {Interaction}},
	url = {https://doi.org/10.1080/08351810903296457},
	doi = {10.1080/08351810903296457},
	abstract = {This special issue is focused on the multimodal sequential analysis of assessments in a variety of social contexts. It aims at contributing to the study of assessments by taking into consideration their role within the overall organization of activities, being sensitive to the peculiar contexts, both ordinary and professional, in which they can be observed, which may display a variety of sequential formats, mobilizing both linguistic and multimodal resources. In this introduction we will provide a theoretical overview of key studies that have advanced our understanding of the social and sequential organizations of assessments, discuss the types of data privileged in prior research, and finally outline the contributions of the studies included in this special issue.},
	number = {4},
	urldate = {2021-09-20},
	journal = {Research on Language and Social Interaction},
	author = {Lindström, Anna and Mondada, Lorenza},
	month = nov,
	year = {2009},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351810903296457},
	pages = {299--308},
}

@article{beach_transitional_1993,
	title = {Transitional regularities for ‘casual’ “{Okay}” usages},
	volume = {19},
	issn = {0378-2166},
	url = {https://www.sciencedirect.com/science/article/pii/0378216693900924},
	doi = {10.1016/0378-2166(93)90092-4},
	abstract = {An understanding of “Okay” usages in conversation requires analytic considerations extending beyond free-standing and non-continuative deployments. Relying on previous findings on how recipients and current speakers organize such activities as phone openings and closings, the present analysis addresses a wider variety of interactional environments in establishing certain predominant and thus fundamental features. Those addressed herein include how recipients and current speakers rely on “Okay” pivotally, at or near transition/opportunity spaces: Decidedly in response to prior talk, yet also in transitionally relevant (‘state of readiness’) ways via shifts/ movements to next-positioned matters. Though recipients or current speakers may (in next turn) treat prior “Okay” usages as non-continuative, and/or move to sequentially delete the actions “Okay” was taken to be projecting (i.e., ‘Okay + [fuller turn]’), just what participants appear to be prefacing or setting-up via “Okay” is recurrently (and eventually) apparent.},
	language = {en},
	number = {4},
	urldate = {2021-09-20},
	journal = {Journal of Pragmatics},
	author = {Beach, Wayne A.},
	month = apr,
	year = {1993},
	pages = {325--352},
}

@book{imo_verfestigungen_2020,
	title = {Verfestigungen in der {Interaktion} {Konstruktionen}, sequenzielle {Muster}, kommunikative {Gattungen}},
	url = {https://library.oapen.org/handle/20.500.12657/46646},
	language = {German},
	urldate = {2021-09-21},
	publisher = {De Gruyter},
	editor = {Imo, Wolfgang and König, Katharina and Weidner, Beate and Wegner, Lars},
	year = {2020},
	doi = {10.1515/9783110637502},
	note = {Accepted: 2021-02-11T17:43:06Z
ISSN: 2198-8676},
}

@article{lindstrom_concession_2013,
	title = {Concession and reassertion: on a dialogic discourse pattern in conversation},
	volume = {33},
	issn = {1860-7349},
	shorttitle = {Concession and reassertion},
	url = {https://www.degruyter.com/document/doi/10.1515/text-2013-0015/html},
	doi = {10.1515/text-2013-0015},
	abstract = {This is a study of a concessive discourse pattern in which the speaker first makes an assertion, then backs down from it, and eventually recycles the original standpoint. This practice bears a strong resemblance to show concessions which Antaki and Wetherell (1999) identify as typical of ideological debate. Our data are from Swedish conversations in everyday as well as institutional settings. We argue thus that the practice of conceding and reasserting does not limit itself to specific rhetoric purposes but is a generally available device for reasoning and argumentation in conversation. The practice enhances intersubjectivity in interaction by acknowledging other viewpoints, signaling reciprocity between the participants, and contributing to preference for agreement. We account for the dialogic nature of this concessive pattern by analyzing first same-speaker produced and then other-induced concessions. We also consider the relation of the concession–reassertion format to other concessive practices.},
	language = {en},
	number = {3},
	urldate = {2021-09-21},
	journal = {Text \& Talk},
	author = {Lindström, Jan K. and Londen, Anne-Marie},
	month = may,
	year = {2013},
	note = {Publisher: De Gruyter Mouton},
	pages = {331--352},
}

@article{ehmer_inferences_2018,
	title = {Inferences in {Interaction} and {Language} {Change}},
	volume = {4},
	issn = {2300-9969},
	url = {https://www.degruyter.com/document/doi/10.1515/opli-2018-0026/html},
	doi = {10.1515/opli-2018-0026},
	abstract = {Article Inferences in Interaction and Language Change was published on December 1, 2018 in the journal Open Linguistics (volume 4, issue 1).},
	language = {en},
	number = {1},
	urldate = {2021-09-21},
	journal = {Open Linguistics},
	author = {Ehmer, Oliver and Rosemeyer, Malte},
	month = dec,
	year = {2018},
	note = {Publisher: De Gruyter Open Access},
	pages = {536--551},
}

@article{deppermann_early_2021,
	title = {Early {Responses}: {An} {Introduction}},
	volume = {58},
	issn = {0163-853X},
	shorttitle = {Early {Responses}},
	url = {https://doi.org/10.1080/0163853X.2021.1877516},
	doi = {10.1080/0163853X.2021.1877516},
	abstract = {This special issue investigates early responses—responsive actions that (start to) unfold while the production of the responded-to turn and action is still under way. Although timing in human conduct has gained intense interest in research, the early production of responsive actions has so far largely remained unexplored. But what makes early responses possible? What do such responses tell us about the complex interplay between syntax, prosody, and embodied conduct? And what sorts of actions do participants accomplish by means of such early responses? By addressing these questions, the special issue seeks to offer new advances in the systematic analysis of temporal organization in interaction, contributing to broader discussions in the language and cognitive sciences as to the social coordination of human conduct. In this introductory article, we discuss the role of temporality and sequentiality in social interaction, specifically focusing on projective and anticipatory mechanisms and the interplay between multiple semiotic resources, which are crucial for making early responses possible.},
	number = {4},
	urldate = {2021-09-22},
	journal = {Discourse Processes},
	author = {Deppermann, Arnulf and Mondada, Lorenza and Doehler, Simona Pekarek},
	month = apr,
	year = {2021},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/0163853X.2021.1877516},
	pages = {293--307},
}

@article{holler_competition_2021,
	title = {Competition {Reduces} {Response} {Times} in {Multiparty} {Conversation}},
	volume = {12},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2021.693124},
	doi = {10.3389/fpsyg.2021.693124},
	abstract = {Natural conversations are characterized by short transition times between turns. This holds in particular for multi-party conversations. The short turn transitions in everyday conversations contrast sharply with the much longer speech onset latencies observed in laboratory studies where speakers respond to spoken utterances. There are many factors that facilitate speech production in conversational compared to laboratory settings. Here we highlight one of them, the impact of competition for turns. In multi-party conversations, speakers often compete for turns. In quantitative corpus analyses of multi-party conversation, the fastest response determines the recorded turn transition time. In contrast, in dyadic conversations such competition for turns is much less likely to arise, and in laboratory experiments with individual participants it does not arise at all. Therefore, all responses tend to be recorded. Thus, competition for turns may reduce the recorded mean turn transition times in multi-party conversations for a simple statistical reason: slow responses are not included in the means. We report two studies illustrating this point. We first report the results of simulations showing how much the response times in a laboratory experiment would be reduced if, for each trial, instead of recording all responses, only the fastest responses of several participants responding independently on the trial were recorded. We then present results from a quantitative corpus analysis comparing turn transition times in dyadic and triadic conversations. There was no significant group size effect in question-response transition times, where the present speaker often selects the next one, thus reducing competition between speakers. But, as predicted, triads showed shorter turn transition times than dyads for the remaining turn transitions, where competition for the floor was more likely to arise. Together, these data show that turn transition times in conversation should be interpreted in the context of group size, turn transition type, and social setting.},
	urldate = {2021-09-20},
	journal = {Frontiers in Psychology},
	author = {Holler, Judith and Alday, Phillip M. and Decuyper, Caitlin and Geiger, Mareike and Kendrick, Kobin H. and Meyer, Antje S.},
	year = {2021},
	pages = {3720},
}

@article{pfeiffer_recruiting_2021,
	title = {Recruiting {Assistance} in {Early} {Childhood}: {Longitudinal} {Changes} in the {Use} of “{Oh}+{X}” as a {Way} of {Reporting} {Trouble} in {German}},
	volume = {54},
	issn = {0835-1813},
	shorttitle = {Recruiting {Assistance} in {Early} {Childhood}},
	url = {https://doi.org/10.1080/08351813.2021.1899708},
	doi = {10.1080/08351813.2021.1899708},
	abstract = {Based on longitudinal audiovisual data from family interactions, we focus on how young children between 1;08 and 2;10 report trouble they are encountering in their current activity using the response cry oh in combination with other lexical items (e.g., “oh fell off”) and bodily displays. While at a very young age the children remain focused on their activity and try to solve the problem independently, at an older age they start to systematically use gaze directed toward the parent and suspension of the current activity to enlist the adult’s assistance. We argue that these bodily displays are among the resources whose presence or absence constrains whether the report of trouble leads to the recruitment of assistance or not. Regarding the developmental implications, it seems that during their third year of life, young children expand their repertoire for dealing with trouble interactively. Data are in German with English translations.},
	number = {2},
	urldate = {2021-09-21},
	journal = {Research on Language and Social Interaction},
	author = {Pfeiffer, Martin and Anna, Marina},
	month = apr,
	year = {2021},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08351813.2021.1899708},
	pages = {142--162},
}

@article{konig_stance_2019,
	title = {Stance taking with ‘laugh’ particles and emojis – {Sequential} and functional patterns of ‘laughter’ in a corpus of {German} {WhatsApp} chats},
	volume = {142},
	issn = {0378-2166},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216618303710},
	doi = {10.1016/j.pragma.2019.01.008},
	abstract = {The present study investigates functions of ‘laugh’ particles like haha, hehe or hihi in a corpus of German WhatsApp text messages. It contributes to research on humor, ‘laugh’ particles and emojis in mobile messaging chats by examining the different stances the interlocutors take when they use ‘laugh’ particles in WhatsApp postings and the role emojis play in these postings. Based on an interactional approach to the analysis of WhatsApp chats, the study shows that ‘laugh’ particles are prototypically deployed in a posting-initial position and that they relate to previous postings or utterances ‘Laugh’ particles can be used to establish or support a humorous joking modality (laughing with). Particularly in group chats users can cooperatively turn one participant into the target of their ‘laughter’ (laughing at). ‘Laugh’ particles and emojis are closely connected, as emojis help to contextualize these different ‘laughter’ stances.},
	language = {en},
	urldate = {2021-09-21},
	journal = {Journal of Pragmatics},
	author = {König, Katharina},
	month = mar,
	year = {2019},
	pages = {156--170},
}

@book{liberman_more_2013,
	address = {Albany},
	series = {{SUNY} series in the philosophy of the social sciences},
	title = {More studies in ethnomethodology},
	isbn = {978-1-4384-4619-6},
	publisher = {State University of New York Press},
	author = {Liberman, Kenneth},
	year = {2013},
}

@article{burns_lecturings_2012,
	title = {‘{Lecturing}’s {Work}’: {A} {Collaborative} {Study} with {Harold} {Garfinkel}},
	volume = {35},
	issn = {1572-851X},
	shorttitle = {‘{Lecturing}’s {Work}’},
	url = {https://doi.org/10.1007/s10746-012-9228-y},
	doi = {10.1007/s10746-012-9228-y},
	abstract = {This article discusses some empirical materials from a collaborative study of “lecturing’s work” which the author conducted with Harold Garfinkel. The paper shows Garfinkel at work by presenting a history of the collaboration and discussing what we found. The article also considers some larger implications of our research for understanding how ethnomethodological studies can recover and discover the material regularities of everyday life as they are practiced in distinct settings. The paper reports on a program of ethnomethodological inquiry for discovering in situ what the produced orderliness of any setting’s endogenous tasks, competent courses of action and organizational objects could possibly be. The promise is that just what is identifying of social order, action and meaning is to be found massively, as the routine grounds of everyday activities, and in every case, as something worldly and embodied.},
	language = {en},
	number = {2},
	urldate = {2021-09-27},
	journal = {Human Studies},
	author = {Burns, Stacy Lee},
	month = may,
	year = {2012},
	pages = {175--192},
}

@article{burns_harold_2012,
	title = {Harold {Garfinkel}: {Memorial} {Remarks}, {Recollections} and {Reflections}},
	volume = {35},
	issn = {1572-851X},
	shorttitle = {Harold {Garfinkel}},
	url = {https://doi.org/10.1007/s10746-012-9216-2},
	doi = {10.1007/s10746-012-9216-2},
	language = {en},
	number = {2},
	urldate = {2021-09-27},
	journal = {Human Studies},
	author = {Burns, Stacy Lee},
	month = may,
	year = {2012},
	pages = {159--161},
}

@book{illich_abc_1989,
	address = {New York},
	edition = {1st Vintage Books ed},
	title = {{ABC}: the alphabetization of the popular mind},
	isbn = {978-0-679-72192-5},
	shorttitle = {{ABC}},
	publisher = {Vintage Books},
	author = {Illich, Ivan and Sanders, Barry},
	year = {1989},
}

@inproceedings{zhou_learning_2021,
	address = {Online},
	title = {Learning from {Perturbations}: {Diverse} and {Informative} {Dialogue} {Generation} with {Inverse} {Adversarial} {Training}},
	shorttitle = {Learning from {Perturbations}},
	url = {https://aclanthology.org/2021.acl-long.57},
	doi = {10.18653/v1/2021.acl-long.57},
	abstract = {In this paper, we propose Inverse Adversarial Training (IAT) algorithm for training neural dialogue systems to avoid generic responses and model dialogue history better. In contrast to standard adversarial training algorithms, IAT encourages the model to be sensitive to the perturbation in the dialogue history and therefore learning from perturbations. By giving higher rewards for responses whose output probability reduces more significantly when dialogue history is perturbed, the model is encouraged to generate more diverse and consistent responses. By penalizing the model when generating the same response given perturbed dialogue history, the model is forced to better capture dialogue history and generate more informative responses. Experimental results on two benchmark datasets show that our approach can better model dialogue history and generate more diverse and consistent responses. In addition, we point out a problem of the widely used maximum mutual information (MMI) based methods for improving the diversity of dialogue response generation models and demonstrate it empirically.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Zhou, Wangchunshu and Li, Qifei and Li, Chenle},
	month = aug,
	year = {2021},
	pages = {694--703},
}

@inproceedings{li_conversations_2021,
	address = {Online},
	title = {Conversations {Are} {Not} {Flat}: {Modeling} the {Dynamic} {Information} {Flow} across {Dialogue} {Utterances}},
	shorttitle = {Conversations {Are} {Not} {Flat}},
	url = {https://aclanthology.org/2021.acl-long.11},
	doi = {10.18653/v1/2021.acl-long.11},
	abstract = {Nowadays, open-domain dialogue models can generate acceptable responses according to the historical context based on the large-scale pre-trained language models. However, they generally concatenate the dialogue history directly as the model input to predict the response, which we named as the flat pattern and ignores the dynamic information flow across dialogue utterances. In this work, we propose the DialoFlow model, in which we introduce a dynamic flow mechanism to model the context flow, and design three training objectives to capture the information dynamics across dialogue utterances by addressing the semantic influence brought about by each utterance in large-scale pre-training. Experiments on the multi-reference Reddit Dataset and DailyDialog Dataset demonstrate that our DialoFlow significantly outperforms the DialoGPT on the dialogue generation task. Besides, we propose the Flow score, an effective automatic metric for evaluating interactive human-bot conversation quality based on the pre-trained DialoFlow, which presents high chatbot-level correlation (\$r=0.9\$) with human ratings among 11 chatbots. Code and pre-trained models will be public.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Li, Zekang and Zhang, Jinchao and Fei, Zhengcong and Feng, Yang and Zhou, Jie},
	month = aug,
	year = {2021},
	pages = {128--138},
}

@inproceedings{gilmartin_chats_2018,
	address = {Miyazaki, Japan},
	title = {Chats and {Chunks}: {Annotation} and {Analysis} of {Multiparty} {Long} {Casual} {Conversations}},
	shorttitle = {Chats and {Chunks}},
	url = {https://aclanthology.org/L18-1309},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Gilmartin, Emer and Vogel, Carl and Campbell, Nick},
	month = may,
	year = {2018},
}

@inproceedings{bunt_iso_2020,
	address = {Marseille, France},
	title = {The {ISO} {Standard} for {Dialogue} {Act} {Annotation}, {Second} {Edition}},
	isbn = {979-10-95546-34-4},
	url = {https://aclanthology.org/2020.lrec-1.69},
	abstract = {ISO standard 24617-2 for dialogue act annotation, established in 2012, has in the past few years been used both in corpus annotation and in the design of components for spoken and multimodal dialogue systems. This has brought some inaccuracies and undesirbale limitations of the standard to light, which are addressed in a proposed second edition. This second edition allows a more accurate annotation of dependence relations and rhetorical relations in dialogue. Following the ISO 24617-4 principles of semantic annotation, and borrowing ideas from EmotionML, a triple-layered plug-in mechanism is introduced which allows dialogue act descriptions to be enriched with information about their semantic content, about accompanying emotions, and other information, and allows the annotation scheme to be customised by adding application-specific dialogue act types.},
	language = {English},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 12th {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Bunt, Harry and Petukhova, Volha and Gilmartin, Emer and Pelachaud, Catherine and Fang, Alex and Keizer, Simon and Prévot, Laurent},
	month = may,
	year = {2020},
	pages = {549--558},
}

@article{edwards_discourse_2006,
	title = {Discourse, cognition and social practices: the rich surface of language and social interaction},
	volume = {8},
	issn = {1461-4456},
	shorttitle = {Discourse, cognition and social practices},
	url = {https://doi.org/10.1177/1461445606059551},
	doi = {10.1177/1461445606059551},
	abstract = {Discursive psychology (DP) approaches discourse not as the product or expression of thoughts or mental states lying behind or beneath it, but as a domain of public accountability in which psychological states are made relevant. DP draws heavily on conversation analysis in examining in close empirical detail how ostensibly psychological themes are handled and managed as part of talk’s everyday interactional business. A brief worked example is offered, in which the intentionality of a person’s actions is handled in the course of police interrogation, in ways that perform police work. Degrees of intentionality are partialled out with regard to specific actions or components of actions, and with regard to how actions are described in ways that map onto how crime categories are defined in law. Cognitive states are generally relevant in discourse in the same manner, as participants’ concerns with regard to action categories and accountability on and for the occasions they are invoked.},
	language = {en},
	number = {1},
	urldate = {2021-10-01},
	journal = {Discourse Studies},
	author = {Edwards, Derek},
	month = feb,
	year = {2006},
	note = {Publisher: SAGE Publications},
	pages = {41--49},
}

@inproceedings{emerson_what_2020,
	address = {Online},
	title = {What are the {Goals} of {Distributional} {Semantics}?},
	url = {https://aclanthology.org/2020.acl-main.663},
	doi = {10.18653/v1/2020.acl-main.663},
	abstract = {Distributional semantic models have become a mainstay in NLP, providing useful features for downstream tasks. However, assessing long-term progress requires explicit long-term goals. In this paper, I take a broad linguistic perspective, looking at how well current models can deal with various semantic challenges. Given stark differences between models proposed in different subfields, a broad perspective is needed to see how we could integrate them. I conclude that, while linguistic insights can guide the design of model architectures, future progress will require balancing the often conflicting demands of linguistic expressiveness and computational tractability.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Emerson, Guy},
	month = jul,
	year = {2020},
	pages = {7436--7453},
}

@inproceedings{liu_learning_2021,
	address = {Online},
	title = {Learning to {Ask} {Conversational} {Questions} by {Optimizing} {Levenshtein} {Distance}},
	url = {https://aclanthology.org/2021.acl-long.438},
	doi = {10.18653/v1/2021.acl-long.438},
	abstract = {Conversational Question Simplification (CQS) aims to simplify self-contained questions into conversational ones by incorporating some conversational characteristics, e.g., anaphora and ellipsis. Existing maximum likelihood estimation based methods often get trapped in easily learned tokens as all tokens are treated equally during training. In this work, we introduce a Reinforcement Iterative Sequence Editing (RISE) framework that optimizes the minimum Levenshtein distance through explicit editing actions. RISE is able to pay attention to tokens that are related to conversational characteristics. To train RISE, we devise an Iterative Reinforce Training (IRT) algorithm with a Dynamic Programming based Sampling (DPS) process to improve exploration. Experimental results on two benchmark datasets show that RISE significantly outperforms state-of-the-art methods and generalizes well on unseen data.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Zhongkun and Ren, Pengjie and Chen, Zhumin and Ren, Zhaochun and de Rijke, Maarten and Zhou, Ming},
	month = aug,
	year = {2021},
	pages = {5638--5650},
}

@article{zhu_dark_2020,
	title = {Dark, {Beyond} {Deep}: {A} {Paradigm} {Shift} to {Cognitive} {AI} with {Humanlike} {Common} {Sense}},
	volume = {6},
	issn = {2095-8099},
	shorttitle = {Dark, {Beyond} {Deep}},
	url = {https://www.sciencedirect.com/science/article/pii/S2095809920300345},
	doi = {10.1016/j.eng.2020.01.011},
	abstract = {Recent progress in deep learning is essentially based on a “big data for small tasks” paradigm, under which massive amounts of data are used to train a classifier for a single narrow task. In this paper, we call for a shift that flips this paradigm upside down. Specifically, we propose a “small data for big tasks” paradigm, wherein a single artificial intelligence (AI) system is challenged to develop “common sense,” enabling it to solve a wide range of tasks with little training data. We illustrate the potential power of this new paradigm by reviewing models of common sense that synthesize recent breakthroughs in both machine and human vision. We identify functionality, physics, intent, causality, and utility (FPICU) as the five core domains of cognitive AI with humanlike common sense. When taken as a unified concept, FPICU is concerned with the questions of “why” and “how,” beyond the dominant “what” and “where” framework for understanding vision. They are invisible in terms of pixels but nevertheless drive the creation, maintenance, and development of visual scenes. We therefore coin them the “dark matter” of vision. Just as our universe cannot be understood by merely studying observable matter, we argue that vision cannot be understood without studying FPICU. We demonstrate the power of this perspective to develop cognitive AI systems with humanlike common sense by showing how to observe and apply FPICU with little training data to solve a wide range of challenging tasks, including tool use, planning, utility inference, and social learning. In summary, we argue that the next generation of AI must embrace “dark” humanlike common sense for solving novel tasks.},
	language = {en},
	number = {3},
	urldate = {2021-10-01},
	journal = {Engineering},
	author = {Zhu, Yixin and Gao, Tao and Fan, Lifeng and Huang, Siyuan and Edmonds, Mark and Liu, Hangxin and Gao, Feng and Zhang, Chi and Qi, Siyuan and Wu, Ying Nian and Tenenbaum, Joshua B. and Zhu, Song-Chun},
	month = mar,
	year = {2020},
	pages = {310--345},
}

@inproceedings{tseng_transferable_2021,
	address = {Online},
	title = {Transferable {Dialogue} {Systems} and {User} {Simulators}},
	url = {https://aclanthology.org/2021.acl-long.13},
	doi = {10.18653/v1/2021.acl-long.13},
	abstract = {One of the difficulties in training dialogue systems is the lack of training data. We explore the possibility of creating dialogue data through the interaction between a dialogue system and a user simulator. Our goal is to develop a modelling framework that can incorporate new dialogue scenarios through self-play between the two agents. In this framework, we first pre-train the two agents on a collection of source domain dialogues, which equips the agents to converse with each other via natural language. With further fine-tuning on a small amount of target domain data, the agents continue to interact with the aim of improving their behaviors using reinforcement learning with structured reward functions. In experiments on the MultiWOZ dataset, two practical transfer learning problems are investigated: 1) domain adaptation and 2) single-to-multiple domain transfer. We demonstrate that the proposed framework is highly effective in bootstrapping the performance of the two agents in transfer learning. We also show that our method leads to improvements in dialogue system performance on complete datasets.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Tseng, Bo-Hsiang and Dai, Yinpei and Kreyssig, Florian and Byrne, Bill},
	month = aug,
	year = {2021},
	pages = {152--166},
}

@inproceedings{gu_mpc-bert_2021,
	address = {Online},
	title = {{MPC}-{BERT}: {A} {Pre}-{Trained} {Language} {Model} for {Multi}-{Party} {Conversation} {Understanding}},
	shorttitle = {{MPC}-{BERT}},
	url = {https://aclanthology.org/2021.acl-long.285},
	doi = {10.18653/v1/2021.acl-long.285},
	abstract = {Recently, various neural models for multi-party conversation (MPC) have achieved impressive improvements on a variety of tasks such as addressee recognition, speaker identification and response prediction. However, these existing methods on MPC usually represent interlocutors and utterances individually and ignore the inherent complicated structure in MPC which may provide crucial interlocutor and utterance semantics and would enhance the conversation understanding process. To this end, we present MPC-BERT, a pre-trained model for MPC understanding that considers learning who says what to whom in a unified model with several elaborated self-supervised tasks. Particularly, these tasks can be generally categorized into (1) interlocutor structure modeling including reply-to utterance recognition, identical speaker searching and pointer consistency distinction, and (2) utterance semantics modeling including masked shared utterance restoration and shared node detection. We evaluate MPC-BERT on three downstream tasks including addressee recognition, speaker identification and response selection. Experimental results show that MPC-BERT outperforms previous methods by large margins and achieves new state-of-the-art performance on all three downstream tasks at two benchmarks.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Gu, Jia-Chen and Tao, Chongyang and Ling, Zhenhua and Xu, Can and Geng, Xiubo and Jiang, Daxin},
	month = aug,
	year = {2021},
	pages = {3682--3692},
}

@inproceedings{kim_monah_2021,
	address = {Online},
	title = {{MONAH}: {Multi}-{Modal} {Narratives} for {Humans} to analyze conversations},
	shorttitle = {{MONAH}},
	url = {https://aclanthology.org/2021.eacl-main.37},
	abstract = {In conversational analyses, humans manually weave multimodal information into the transcripts, which is significantly time-consuming. We introduce a system that automatically expands the verbatim transcripts of video-recorded conversations using multimodal data streams. This system uses a set of preprocessing rules to weave multimodal annotations into the verbatim transcripts and promote interpretability. Our feature engineering contributions are two-fold: firstly, we identify the range of multimodal features relevant to detect rapport-building; secondly, we expand the range of multimodal annotations and show that the expansion leads to statistically significant improvements in detecting rapport-building.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Kim, Joshua Y. and Yacef, Kalina and Kim, Greyson and Liu, Chunfeng and Calvo, Rafael and Taylor, Silas},
	month = apr,
	year = {2021},
	pages = {466--479},
}

@inproceedings{nielsen_prosodic_2021,
	address = {Online},
	title = {Prosodic segmentation for parsing spoken dialogue},
	url = {https://aclanthology.org/2021.acl-long.79},
	doi = {10.18653/v1/2021.acl-long.79},
	abstract = {Parsing spoken dialogue poses unique difficulties, including disfluencies and unmarked boundaries between sentence-like units. Previous work has shown that prosody can help with parsing disfluent speech (Tran et al. 2018), but has assumed that the input to the parser is already segmented into sentence-like units (SUs), which isn't true in existing speech applications. We investigate how prosody affects a parser that receives an entire dialogue turn as input (a turn-based model), instead of gold standard pre-segmented SUs (an SU-based model). In experiments on the English Switchboard corpus, we find that when using transcripts alone, the turn-based model has trouble segmenting SUs, leading to worse parse performance than the SU-based model. However, prosody can effectively replace gold standard SU boundaries: with prosody, the turn-based model performs as well as the SU-based model (91.38 vs. 91.06 F1 score, respectively), despite performing two tasks (SU segmentation and parsing) rather than one (parsing alone). Analysis shows that pitch and intensity features are the most important for this corpus, since they allow the model to correctly distinguish an SU boundary from a speech disfluency – a distinction that the model otherwise struggles to make.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Nielsen, Elizabeth and Steedman, Mark and Goldwater, Sharon},
	month = aug,
	year = {2021},
	pages = {979--992},
}

@inproceedings{feng_sequence--sequence_2021,
	address = {Online},
	title = {A {Sequence}-to-{Sequence} {Approach} to {Dialogue} {State} {Tracking}},
	url = {https://aclanthology.org/2021.acl-long.135},
	doi = {10.18653/v1/2021.acl-long.135},
	abstract = {This paper is concerned with dialogue state tracking (DST) in a task-oriented dialogue system. Building a DST module that is highly effective is still a challenging issue, although significant progresses have been made recently. This paper proposes a new approach to dialogue state tracking, referred to as Seq2Seq-DU, which formalizes DST as a sequence-to-sequence problem. Seq2Seq-DU employs two BERT-based encoders to respectively encode the utterances in the dialogue and the descriptions of schemas, an attender to calculate attentions between the utterance embeddings and the schema embeddings, and a decoder to generate pointers to represent the current state of dialogue. Seq2Seq-DU has the following advantages. It can jointly model intents, slots, and slot values; it can leverage the rich representations of utterances and schemas based on BERT; it can effectively deal with categorical and non-categorical slots, and unseen schemas. In addition, Seq2Seq-DU can also be used in the NLU (natural language understanding) module of a dialogue system. Experimental results on benchmark datasets in different settings (SGD, MultiWOZ2.2, MultiWOZ2.1, WOZ2.0, DSTC2, M2M, SNIPS, and ATIS) show that Seq2Seq-DU outperforms the existing methods.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Feng, Yue and Wang, Yang and Li, Hang},
	month = aug,
	year = {2021},
	pages = {1714--1725},
}

@inproceedings{xu_discovering_2021,
	address = {Online},
	title = {Discovering {Dialog} {Structure} {Graph} for {Coherent} {Dialog} {Generation}},
	url = {https://aclanthology.org/2021.acl-long.136},
	doi = {10.18653/v1/2021.acl-long.136},
	abstract = {Learning discrete dialog structure graph from human-human dialogs yields basic insights into the structure of conversation, and also provides background knowledge to facilitate dialog generation. However, this problem is less studied in open-domain dialogue. In this paper, we conduct unsupervised discovery of discrete dialog structure from chitchat corpora, and then leverage it to facilitate coherent dialog generation in downstream systems. To this end, we present an unsupervised model, Discrete Variational Auto-Encoder with Graph Neural Network (DVAE-GNN), to discover discrete hierarchical latent dialog states (at the level of both session and utterance) and their transitions from corpus as a dialog structure graph. Then we leverage it as background knowledge to facilitate dialog management in a RL based dialog system. Experimental results on two benchmark corpora confirm that DVAE-GNN can discover meaningful dialog structure graph, and the use of dialog structure as background knowledge can significantly improve multi-turn coherence.},
	urldate = {2021-10-04},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Xu, Jun and Lei, Zeyang and Wang, Haifeng and Niu, Zheng-Yu and Wu, Hua and Che, Wanxiang},
	month = aug,
	year = {2021},
	pages = {1726--1739},
}

@inproceedings{wlodarczak_speaker_2021,
	title = {Speaker {Transition} {Patterns} in {Three}-{Party} {Conversation}: {Evidence} from {English}, {Estonian} and {Swedish}},
	shorttitle = {Speaker {Transition} {Patterns} in {Three}-{Party} {Conversation}},
	url = {https://www.isca-speech.org/archive/interspeech_2021/wodarczak21_interspeech.html},
	doi = {10.21437/Interspeech.2021-199},
	abstract = {During conversation, speakers hold and relinquish the floor, resulting in turn yield and retention. We examine these phenomena in three-party conversations in English, Swedish, and Estonian. We define within- and between-speaker transitions in terms of shorter intervals of speech, silence and overlap bounded by stretches of one-party speech longer than 1 second by the same or different speakers. This method gives us insights into how turn change and retention proceed, revealing that the majority of speaker transitions are more complex and involve more intermediate activity than a single silence or overlap. We examine the composition of within and between transitions in terms of number of speakers involved, incidence and proportion of solo speech, silence and overlap. We derive the most common within- and between-speaker transitions in the three languages, finding evidence of striking commonalities in how the floor is managed. Our findings suggest that current models of turn-taking used in dialogue technology could be extended using these results to more accurately reflect the realities of human-human dialogue.},
	language = {en},
	urldate = {2021-10-04},
	booktitle = {Interspeech 2021},
	publisher = {ISCA},
	author = {Włodarczak, Marcin and Gilmartin, Emer},
	month = aug,
	year = {2021},
	pages = {801--805},
}
