%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
%%%% Small single column format, used for CIE, CSUR, DTRAP, JACM, JDIQ, JEA, JERIC, JETC, PACMCGIT, TAAS, TACCESS, TACO, TALG, TALLIP (formerly TALIP), TCPS, TDSCI, TEAC, TECS, TELO, THRI, TIIS, TIOT, TISSEC, TIST, TKDD, TMIS, TOCE, TOCHI, TOCL, TOCS, TOCT, TODAES, TODS, TOIS, TOIT, TOMACS, TOMM (formerly TOMCCAP), TOMPECS, TOMS, TOPC, TOPLAS, TOPS, TOS, TOSEM, TOSN, TQC, TRETS, TSAS, TSC, TSLP, TWEB.
% \documentclass[acmsmall]{acmart}

%%%% Large single column format, used for IMWUT, JOCCH, PACMPL, POMACS, TAP, PACMHCI
% \documentclass[acmlarge,screen]{acmart}

%%%% Large double column format, used for TOG
% \documentclass[acmtog, authorversion]{acmart}

%%%% Generic manuscript mode, required for submission
%%%% and peer review
% \documentclass[manuscript,screen,review]{acmart}
\documentclass[sigconf,natbib]{acmart}
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% \setcopyright{acmcopyright}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{June 03--05,
%   2018}{Woodstock, NY}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
% \acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\hypersetup{
colorlinks=true,
linkcolor=black}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{multicol}
% \usepackage{wrapfig}
\usepackage{balance}

\copyrightyear{2023}
\acmYear{2023}
\setcopyright{acmlicensed}\acmConference[SIGIR '23]{Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval}{July 23--27, 2023}{Taipei, Taiwan}
\acmBooktitle{Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '23), July 23--27, 2023, Taipei, Taiwan}
\acmPrice{15.00}
\acmDOI{10.1145/3539618.3591963}
\acmISBN{978-1-4503-9408-6/23/07}


\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Click-Conversion Multi-Task Model with Position Bias Mitigation for Sponsored Search in eCommerce}

% %%
% %% The "author" command and its associated commands are used to define
% %% the authors and their affiliations.
% %% Of note is the shared affiliation of the first two authors, and the
% %% "authornote" and "authornotemark" commands
% %% used to denote shared contribution to the research.
\settopmatter{authorsperrow=4}

\author{Yibo Wang}
\email{ywang633@uic.edu}
\orcid{0000-0001-8872-1811}
\affiliation{
  \institution{\mbox{\!\!\!\!\!University of Illinois Chicago}}
  \city{Chicago}
  \state{IL}
  \country{USA}
  \postcode{60607}
}
\author{Yanbing Xue}
\email{yanbing.xue@walmart.com}
\affiliation{%
  \institution{Walmart eCommerce}
  \city{Sunnyvale}
  \state{CA}
  \country{USA}
}
\author{Bo Liu}
\email{bo.liu1@walmart.com}
\affiliation{%
  \institution{Walmart eCommerce}
  \city{Sunnyvale}
  \state{CA}
  \country{USA}
}
\author{Musen Wen}
\email{musen.wen@walmart.com}
\affiliation{%
  \institution{Walmart eCommerce}
  \city{Sunnyvale}
  \state{CA}
  \country{USA}
}
\author{Wenting Zhao}
\email{wzhao41@uic.edu}
\affiliation{%
  \institution{\mbox{\!\!\!\!\!\!University of Illinois Chicago}}
  \city{Chicago}
  \state{IL}
  \country{USA}
  \postcode{60607}
}
\author{Stephen Guo}
\email{sguo@indeed.com}
\affiliation{%
  \institution{Indeed}
  \city{Sunnyvale}
  \state{CA}
  \country{USA}
}
\author{Philip S. Yu}
\email{psyu@uic.edu}
\affiliation{%
  \institution{\mbox{\!\!\!\!\!\!University of Illinois Chicago}}
  \city{Chicago}
  \state{IL}
  \country{USA}
  \postcode{60607}
}


% %%
% %% By default, the full list of authors will be used in the page
% %% headers. Often, this list is too long, and will overlap
% %% other information printed in the page headers. This command allows
% %% the author to define a more concise list
% %% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Yibo, et al.}
\renewcommand{\shortauthors}{Yibo Wang et al.}
%% No italics and no comma
%% If needed use a foot or author note to identify equal contribution

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
% \begin{abstract}
% Position bias, the phenomenon whereby users tend to focus and act (e.g. click) on items at higher positions of the search result list regardless of the actual relevance between queries and items, is prevailing in many ranking and information retrieval systems. Position bias in the training data biases the ranking model, leading to increasingly unfair item rankings, click-through-rate (CTR), or conversion rate (CVR) predictions. 
% To jointly mitigate the position bias effect in both item CTR prediction and CVR prediction, we propose two position-bias-free CTR and CVR prediction models: Position-Aware Click-Conversion (PACC) and PACC via Position Embedding (PACC-PE). 
% PACC is built upon probability decomposition and position information is modeled as a probability.
% PACC-PE utilizes deep neural networks to model product-specific position information as embedding.
% Experimental results on the e-commerce sponsored product search dataset show that our proposed models have much better ranking effectiveness and can greatly alleviate the position bias problem in both CTR prediction and CVR prediction.
% \end{abstract}

\begin{abstract}
% In many informational retrieval and ranking systems, 
% the position bias, whereby users tend to focus and act (e.g. click) on items at higher positions of the search result list regardless of the actual relevance between queries and items, 
Position bias, the phenomenon whereby users tend to focus on higher-ranked items of the search result list regardless of the actual relevance to queries, is prevailing in many ranking systems. Position bias in training data biases the ranking model, leading to increasingly unfair item rankings, click-through-rate (CTR), and conversion rate (CVR) predictions. 
To jointly mitigate position bias in both item CTR and CVR prediction, we propose two position-bias-free CTR and CVR prediction models: Position-Aware Click-Conversion (PACC) and PACC via Position Embedding (PACC-PE). PACC is built upon probability decomposition and models position information as a probability. PACC-PE utilizes neural networks to model product-specific position information as embedding. Experiments on the E-commerce sponsored product search dataset show that our proposed models have better ranking effectiveness and can greatly alleviate position bias in both CTR and CVR prediction.
\end{abstract}
% %%
% %% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
% %% Please copy and paste the code instead of the example below.
% %%
\vspace{-1cm}
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010405.10003550</concept_id>
       <concept_desc>Applied computing~Electronic commerce</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257</concept_id>
       <concept_desc>Computing methodologies~Machine learning</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Applied computing~Electronic commerce}
\ccsdesc[500]{Computing methodologies~Machine learning}

%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\vspace{-1cm}
\keywords{Multi-task Learning; Sponsored Product Search; Position Bias}

% %% A "teaser" image appears between the author and affiliation
% %% information and the body of the document, and typically spans the
% %% page.
% \begin{teaserfigure}
%   % Figure removed
%   \caption{Seattle Mariners at Spring Training, 2010.}
%   \Description{Enjoying the baseball game from the third-base
%   seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\vspace{-0.1cm}
\section{Introduction}
The phenomenon of position bias is commonly observed in many ranking and information retrieval systems, including digital advertising and recommender systems. 
% Position bias refers to the tendency of users to pay greater attention to items that appear higher in a ranked list, regardless of their actual relevance to the query.
Position bias is the tendency of users to pay greater attention to higher-ranked items, regardless of their actual relevance to the query.
% Position bias is the tendency to prioritize higher-ranked items over their actual relevance in a ranked list.
For example, the eye-tracking study~\cite{eyetracking1} and~\cite{eyetracking2} show that in web search, the highest-ranked items receive the most attention; the study of digital library recommendation system~\cite{library} discovers that items shown at the top positions are more often clicked regardless of their actual relevance.

A common practice from machine-learned ranking (MLR) models is to use implicit user feedback, such as click/no-click as training data labels. However, due to inherited position bias, these models tend to exhibit lower predicted click-through rates (CTR) for 
% items appearing in lower-ranked positions. 
lower-ranked items.
This bias in prediction can then 
affect subsequent training data collection,
% influence the subsequent collection of training data, 
leading to a persistent and cyclical effect.

The accumulative position bias of the training data will skew the MLR model, leading to increasingly unfair item rank prediction~\cite{craswell2008experimental}.
To address this position bias problem, various approaches have been proposed, including factorization models~\cite{chen2012position}, inverse propensity scores~\cite{ubiased_ltr, metrics,guo2020debiasing}, deep neural network-based CTR prediction models~\cite{ling2017model,guo2019pal,zhuang2021cross}, and more. 
Pioneering approaches such as~\cite{chen2012position} proposed a factorization model that decouples CTR into position-normalized CTR and position bias, which are then estimated by an Expectation-Maximization (EM) algorithm framework.
To remove the position bias for learning to rank models, a propensity-weighted empirical risk minimization framework is proposed in~\cite{ubiased_ltr}. In~\cite{hu2019unbiased}, an unbiased LambdaMART model is proposed, which jointly estimates the biases at click positions and unclick positions and learns an unbiased ranker. Several literatures dedicate to the propensity estimation, such as~\cite{ai2018unbiased,vardasbi2020cascade,agarwal2019estimating}. 
Recently, increasing research studies correcting position bias in the deep-ranking models. 
In~\cite{jin2020deep}, the authors propose to combine recurrent neural network and survival analysis techniques to model unbiased user behaviors. 
~\cite{chen2020context} designs a neural-based Context-Aware Click Model with an examination predictor able to automatically learn the position bias during training. 

The existing methods primarily
consider single-task objectives like CTR prediction.
% concentrate on addressing position bias in CTR prediction. 
However, in E-commerce, typical ranking models can have multiple objectives, such as maximizing both CTR and CVR.
% However, both CTR and CVR (conversion rate) are critical metrics in ranking systems. Besides, item impression, click and conversion processes have sequential dependencies and are all affected by position bias. Hence, it is imperative to model the relationship between CTR and CVR and mitigate position bias for both metrics in order to improve ranking systems.
Deep Multifaceted Transformers (DMT)~\cite{dmt} learns both CTR and CVR predictors by modeling multiple user behaviors simultaneously with 
% training data 
bias mitigation and treats CTR and CVR prediction as two parallel tasks. However, item impression, click, and conversion processes have sequential dependencies and are all affected by position bias. Such dependencies are not leveraged in DMT.
% DMT~\cite{dmt} proposes Deep Multifaceted Transformers to model multiple user behaviors simultaneously while reducing the selection bias in the training data. However, DMT considers predicting different user behaviors as parallel tasks, ignoring the sequential order that exists between click and conversion.

% Motivated by the above observation, 
In this paper, two models, 
Position Aware Click-Conversion (PACC) and PACC with Position Embedding (PACC-PE) are proposed to model the sequential relationship and jointly mitigate position bias in both CTR prediction and CVR prediction. 
PACC is based on the following two assumptions: 
(1). whether an item will be seen is only related to its position; (2). after an item is seen, whether it will be clicked/purchased is independent of its position.
PACC is built upon the probability decomposition presented in \S\ref{ssect:theory}.
% PACC is built upon the probability decomposition presented in \S\ref{ssect:theory}. For each position, its probability of being seen is computed. Then two modules sharing the same feature embedding layers are devised for CTR and CVR prediction, given the prior probability of each position being seen. The sequential dependency of click and conversion are also modeled in PACC.
PACC-PE is a variant of PACC, which adopts a neural network to model the product-specific position information as embedding. Compared to PACC, learning the product-specific position embedding with a neural network enables PACC-PE to achieve richer information and superior performance than PACC.
% We further propose a variant of PACC, called PACC-PE, which adopts a neural network to model the product-specific position information as embedding. Then the embedding is fed into the CTR prediction module. Compared to PACC, learning the product-specific position embedding with a neural network enables PACC-PE to achieve superior performance than PACC.

Specifically, our work has the following contributions: 
\begin{itemize}
    \item We propose to jointly learn position-bias-free CTR and CVR prediction models in a multi-task learning framework. By mitigating position bias, the proposed models achieve comparable performance as state-of-the-art models on CTR prediction and significant performance improvement on CVR prediction regarding weighted Mean-Reciprocal-Rank (MRR)~\cite{metrics}, MRR, position-wise AUC (PAUC)~\cite{huang2021metrics2}, and AUC.
    % \item We 
    \item We conduct experiments on real-world E-commerce sponsored product searches. Our proposed models achieve better ranking effectiveness and greatly mitigate position bias.
\end{itemize}
% \noindent(1) We propose to jointly learn position-bias-free CTR and CVR prediction models in a multi-task learning framework. By removing position bias, the proposed models achieve a significant performance improvement, in terms of weighted Mean-Reciprocal-Rank (MRR) ~\cite{metrics} and position-wise AUC (PAUC)~\cite{huang2021metrics2}.  \\
% \noindent(2) We first design a PACC model. PACC is based on the following two assumptions: 
% a. whether an item will be seen is only related to its position;
% b. after an item is seen, whether it will be clicked/purchased is independent of its position.
% PACC is built upon the probability decomposition presented in \S\ref{ssect:theory}. For each position, its probability of being seen is computed. Then two modules sharing the same feature embedding layers are devised for CTR and CVR prediction, given the prior probability of each position being seen. The sequential dependency of click and conversion are also modelled in PACC. \\
% \noindent(3) We further propose a variant of PACC, called PACC-PE, which adopts a neural network to model the product specific position information as embedding. Then the embedding is fed into the CTR prediction module. 
% Compared to PACC, learning the product specific position embedding 
% with neural network 
% enables PACC-PE to achieve superior performance than PACC.
% \noindent (4) We conduct experiments on real-world ecommerce sponsored product search. Our proposed models achieve better ranking effectiveness and greatly mitigate position bias.



% \section{Relate Work}
% \subsection{Position Bias in Ranking}
% % Although using click-through data has benefited the ranking model learning with accessible training data, various types of bias tend to be inherited by the model~\cite{yue2010beyond,zhu2020measuring}. 
% Items with lower rank at initial stage tend to be under-represented in the training dataset. Position bias issue in ranking model learning has been studied for decades~\cite{craswell2008experimental,yue2010beyond}.  Pioneering approaches such as~\cite{chapelle2009dynamic} model the hidden variables affecting the click probability and decompose the click probability with a dynamic Bayesian network. To remove the position bias for the learning to rank model, a propensity-weighted empirical risk minimization framework is proposed in~\cite{ubiased_ltr}. In~\cite{hu2019unbiased}, an unbiased LambdaMART model is proposed, which jointly estimates the biases at click positions and the biases at unclick positions, and learn an unbiased ranker. Several literature dedicates in the propensity estimation, such as~\cite{ai2018unbiased,vardasbi2020cascade,agarwal2019estimating}. Recently, increasing research studies correcting the position bias in deep ranking model. 
% In~\cite{jin2020deep}, the authors propose to combine recurrent neural network and survival analysis techniques to model unbiased user behaviors. 
% ~\cite{chen2020context} designs a neural-based Context-Aware Click Model with an examination predictor able to automatically learn the position bias during training. 

% \subsection{Multi-task Learning in E-commerce Applications}
% % Shared-Bottom, MoE, MMoE, PLE, MoSE
% Multi-task learning (MTL)~\cite{shared-bottom} is an actively studied research topic. In E-commerce applications such as recommender system and web ads ranking, a desirable ML model needs to balance multiple expectations, which fits the MTL framework. In~\cite{hadash2018rank}, a multi-task recommendation model is proposed, which jointly optimizes the user interaction number and rating. 
% As for model architecture, Multi-gate Mixture-of-Experts framework (MMoE) \cite{MMoE} is proposed to design multiple parallel modules as experts for multiple tasks.
% % As for model architecture, one recent popular MTL framework is proposed by~\cite{MMoE}, which proposes an Multi-gate Mixture-of-Experts framework (MMoE). MMoE designs multiple parallel modules as experts. The output of these experts is weighted by a gate module output and fed into the following module. 
% There have been several variants of MMoE. The progressive layered extraction framework~\cite{PLE} separates shared parameters and task-specific parameters. The works like~\cite{other_multi1}, \cite{other_multi2} and \cite{other_multi3} consider the task relationships to avoid optimization conflicts.
% Several MTL works model the sequential dependency user behavior in E-commerce applications. \cite{MMSE} proposes Mixture of Sequential Experts (MoSE) to model sequential user behaviors using Long Short-Term Memory in the MMoE framework. The Adaptive Information Transfer Multi-task (AITM) framework~\cite{AITM} models the multi-step audience conversion process in credit business. 
% % It adaptively learns how much information to transfer from former task to latter task with the proposed AIT module. A behavioral expectation calibrator is formulated in the training loss to alleviate the probability value scale difference between the steps.

% However, few previous studies have been conducted on jointly mitigating position bias on CTR and CVR. DMT~\cite{dmt} proposes Deep Multifaceted Transformers to model multiple user behaviors simultaneously while reducing the selection bias in the training data. However, DMT considers predicting different user behaviors as parallel tasks, ignoring the sequential order that exists between click and conversion.

% Figure environment removed

\vspace{-0.3cm}
\section{Methodology}
\label{sec: methods}
In this section, we first introduce our problem formulation and then present assumptions and theoretical basis. Finally, detailed explanations of our proposed PACC and PACC-PE models are provided.

\vspace{-0.1cm}
\subsection{Notation and Problem Formulation}
We assume the training set to be $T = \{(f_i, p_i) \rightarrow (y^{ctr}_i, y^{cvr}_i)\}|_{i=1}^N$, where
$f_i$ is features other than position of sample $i$, $p_i$ is the position of sample $i$, $y^{ctr}_i\in\{0,1\}$ is the click label of sample $i$,
% ($y^{ctr}_i = 1$ if the item is clicked by the user, $y^{ctr}_i = 0$ otherwise), 
$y^{cvr}_i\in\{0,1\}$ is the conversion label of sample $i$, 
% ($y^{cvr}_i = 1$ if the item is purchased by the user, $y^{cvr}_i = 0$ otherwise) 
and $N$ is the number of samples in $T$. 
Therefore, our models estimate the two probabilities: $P(y^{ctr}_i=1|f_i, p_i)$, the probability of an item to be clicked according to features and position, and $P(y^{cvr}_i=1|f_i, p_i)$, the probability of an item to be purchased according to features and position. Besides, we use $s_i\in\{0,1\}$ to represent whether an item is seen by the user or not.
% , where $s_i = 1$ means the item is seen by the user, otherwise $s_i = 0$.

\vspace{-0.1cm}
\subsection{Assumptions and Theoretical Basis}
\label{ssect:theory}
PACC is based on two assumptions: 
1) whether an item will be seen by the user is only related to item position, which is $P(s_i|f_i, p_i) = P(s_i|p_i)$; 
2) if an item is already seen, whether it will be clicked/purchased is independent of item position, which is $P(y^{ctr}_i|f_i, p_i, s_i=1) = P(y^{ctr}_i|f_i, s_i=1)$ and $P(y^{cvr}_i|f_i, p_i, s_i=1) = P(y^{cvr}_i|f_i, s_i=1)$. 

In addition to these two assumptions, two facts underlie PACC: 
1) an item has to be seen before it can be clicked, which is $P(y^{ctr}_i=1|f_i, p_i) = P(y^{ctr}_i=1 \cap s_i=1|f_i, p_i)$; 
2) an item has to be clicked and seen before it can be purchased, which is $P(y^{cvr}_i=1|f_i, p_i) = P(y^{cvr}_i=1 \cap y^{ctr}_i=1|f_i, p_i)$ and $P(y^{cvr}_i=1|f_i, p_i, y^{ctr}_i) = P(y^{cvr}_i=1 \cap s_i=1|f_i, p_i, y^{ctr}_i)$. 

The probability of an item being clicked
% by the user
is represented as:
\begin{equation}
    \begin{aligned}
        P(y^{ctr}_i=1|f_i, p_i) 
        &= P(y^{ctr}_i=1|f_i, p_i, s_i=1) \cdot P(s_i=1|f_i, p_i)\\
        &= P(y^{ctr}_i=1|f_i, s_i=1) \cdot P(s_i=1|p_i).\\
    \end{aligned}
\label{eq:1}
\end{equation}
% where the fact 1, assumption 2 and assumption 1 are applied in order.


The probability of an item to be purchased is represented as:
\begin{equation}
    \begin{aligned}
        P(y^{cvr}_i=1|f_i, p_i)
        &= P(y^{cvr}_i=1 \cap y^{ctr}_i=1|f_i, p_i)\\
        % &= P(y^{cvr}_i=1 \cap s_i=1|f_i, p_i, y^{ctr}_i=1) * P(y^{ctr}_i=1|f_i, p_i) \\
        &= P(y^{cvr}_i=1|f_i, y^{ctr}_i, s_i) \cdot P(y^{ctr}_i = 1|f_i, p_i).\\
    \end{aligned}
\label{eq:2}
\end{equation}
% where the fact 2 and fact 1 are applied in order.

\vspace{-0.1cm}
\subsection{Proposed Framework}

% ========================================================================
% provide an overview for the framework
\vspace{-0.05cm}
\subsubsection{Overview}
% \textbf{Overview}
Figure~\ref{fig:models} illustrates the architecture of our proposed models. 
% As shown in Fig. \ref{fig:models}, 
In both models, CTR prediction and CVR prediction share the same feature embedding but have different model architectures and parameters. A neural network is utilized to adaptively learn what and how much information to transfer from CTR prediction to CVR prediction. Position information is modeled separately and combined in innovative ways with the click-conversion multi-task model. With this novel framework, our proposed models can jointly alleviate the position bias of both CTR and CVR prediction.
\vspace{-0.05cm}
\subsubsection{Position Aware Click-Conversion Model}
% \textbf{Position Aware Click-Conversion Model}
The model architecture of PACC is shown in Fig. \ref{fig:model1}. 
% Given the input feature list $f = [f_1, f_2, \dots, f_{|f|}]$, each feature $f_i (1\leq i \leq |f|)$ is embedded to $v_i$, and then concatenated to the shared feature embedding $v = [v_1;v_2;\dots;v_{|f|}]$.
Given the input feature $f_i$ embedded as $v_i$,
for task $k \in \{ctr, cvr \}$, the output of $k$ Tower is defined as $T_k = g^k_t(v_i)$,
% \begin{equation}
%     T_k = g^k_t(v),
% \end{equation}
where $g^k_t(\cdot)$ is three linear layers each followed by a ReLU activation function and a drop-out layer.
Then $T_{ctr}$ is fed into a linear layer with a sigmoid function to calculate $P(y^{ctr}_i|f_i, s_i=1)$, which is the probability of an item to be clicked after it is seen. $T_{ctr}$ is also fed into a linear layer followed by a ReLU activation function and a drop-out layer, whose output is $INFO_{ctr}$. Then $T_{cvr}$ and $INFO_{ctr}$ are concatenated and fed into an attention layer as $A_{cvr} = g^{cvr}_{a}([T_{cvr};INFO_{ctr}])$,
% \begin{equation}
%     A_{cvr} = g^{cvr}_{a}([T_{cvr};INFO_{ctr}]),
% \end{equation}
where $g^{cvr}_{a}$ is the function of the attention layer and $A_{cvr}$ is the output. Then $A_{cvr}$ is fed into a linear layer with a sigmoid function to calculate $P(y^{cvr}_i|f_i, y^{ctr}_i=1, s_i=1)$, which is the probability of an item to be purchased if it is already seen and clicked.

$P(s_i|p_i)$, the probability of an item to be seen given the position, is modeled using a linear layer and a sigmoid function. Then $P(s_i|p_i)$ is multiplied by $P(y^{ctr}_i|f_i, s_i=1)$ for $P(y_i^{ctr}=1|f_i, p_i)$ and $P(y_i^{ctr}=1|f_i, p_i)$ is multiplied by $P(y^{cvr}_i|f_i, y^{ctr}_i=1, s_i=1)$ for $P(y_i^{cvr}|f_i, p_i)$ according to Eq.(\ref{eq:1}) and Eq.(\ref{eq:2}).
\vspace{-0.05cm}
\subsubsection{Position Aware Click-Conversion Model with Position Embedding}
The architecture of PACC-PE is shown in Fig. \ref{fig:model2}. Given $v_i$ as the shared feature embedding of sample $i$, for task $k \in \{pos, ctr, cvr \}$, the output of $k$ Tower is defined as $T_k = g^k_t(v_i)$, 
% \begin{equation}
%     T_k = g^k_t(v),
% \end{equation}
where $g^k_t(\cdot)$ encodes $v_i$ through three linear layers each followed by a ReLU activation function and a drop-out layer.
$T_{pos}$ is then fed into a linear layer followed by a ReLU activation function and a drop-out layer, whose output is $INFO_{pos}$. Then $T_{ctr}$ and $INFO_{pos}$ are concatenated and fed into an attention layer as $A_{ctr} = g^{ctr}_{a}([T_{ctr};INFO_{pos}])$,
% \begin{equation}
%     A_{ctr} = g^{ctr}_{a}([T_{ctr};INFO_{pos}]),
% \end{equation}
where $g^{ctr}_{a}$ is the function of the attention layer and $A_{ctr}$ is the output. Then $A_{ctr}$ is fed into a linear layer with a sigmoid function to calculate $P(y^{ctr}_i|f_i, p_i)$, which is the probability of an item to be clicked.
$P(y^{cvr}_i|f_i, p_i)$ is obtained similar as $P(y^{ctr}_i|f_i, p_i)$. 

The difference between PACC and PACC-PE is that PACC models position information into a scalar while PACC-PE models product-specific position information into an embedding. Thus, PACC-PE focuses on representing product-related position information, which is richer and more useful. Besides, PACC-PE has high fault tolerance compared with PACC, where subsequent tasks will be greatly affected if the probability of a former task is predicted wrongly.
\vspace{-0.05cm}
\subsubsection{Loss Function}
The loss function of our proposed models is
\begin{equation}
    \mathcal{L_(\theta)} = \mathcal{L}_{CTR}(\theta) + \mathcal{L}_{CVR}(\theta) + \mathcal{L}_{res}(\theta),
\label{eq:3}
\end{equation}
where $\mathcal{L}_{CTR}(\theta)$ is the binary cross entropy loss of the CTR prediction task, $\mathcal{L}_{CVR}(\theta)$ is the binary cross entropy loss of the CVR prediction task and $\mathcal{L}_{res}(\theta)$ is a restriction loss. The restriction loss is based on the fact that an item has to be clicked before it can be purchased, which is defined as
\begin{equation}
    \mathcal{L}_{res}(\theta) = \sum_{i=0}^{N} max(P(y_i^{ctr}|f_i, p_i) - P(y_i^{cvr}|f_i, p_i), 0).
\label{eq:4}
\end{equation}

\vspace{-0.3cm}
\section{Experiments}
% In this section, we explore the following experimental questions:
% \begin{itemize}
%     \item \textbf{RQ1. } Do our proposed models achieve better ranking effectiveness than the baseline model?
%     \item \textbf{RQ2. } Do our proposed models mitigate the problem of position bias in ads ranking system?
%     \item \textbf{RQ3. } Is there any difference in model performance between PACC and PACC-PE?
%     \item \textbf{RQ4. } How do our proposed models and the baseline model behave differently in different positions, respectively?
% \end{itemize}

\vspace{-0.1cm}
\subsection{Dataset and Data Preprocessing}
% \subsubsection{Dataset}
% This paper focuses on addressing the problem of position bias in sponsored advertising. Thus, we choose the query-item pair sponsored ads dataset provided by Walmart \footnote{https://www.walmart.com} as our testbed. This dataset is a real-world dataset containing position bias. The dataset includes 4.2M training data, 1.1M validation data, and 7.5M test data. 
The training and testing query-item pair data are collected using Walmart\footnote{https://www.walmart.com} sponsored ads logs. The dataset is a real-world dataset with position bias, containing 4.2M training samples, 1.1M validation samples, and 7.5M testing samples. 

The extracted features are categorized into three types: categorical features, numeric features, and text features. 
The categorical features are transformed into one-hot vectors; the numeric features are normalized; and the text features are embedded using BERT~\cite{kenton2019bert} to calculate cosine similarity scores and element-wise product between query and ad item. 
% The element-wise product has 768 dimensions computed using $BERT_{base}$. Thus, in case the element-wise product will overwhelm other features, whose dimension is 38, we use PCA to reduce the dimension of the element-wise product to 5. 
The element-wise product obtained using $BERT_{base}$ has a dimension of 768, whereas the dimensions of other features are much smaller. To prevent the element-wise product from overwhelming other features, we use PCA to reduce its dimensionality to 5.
In addition, the position feature is transformed into a one-hot format.

% \subsubsection{Data Preprocessing}
% For different types of features, we use different preprocessing methods. We formulate our input feature from three perspectives: categorical features, numeric features, and text features.  For categorical features, we first fill NaN with mode value and then transform these features into the one-hot format. 
% For numeric features, we first fill NaN with mean value and then normalize feature values. For text features, we use BERT embedding to obtain cosine similarity scores and element wise product between query and ad name. The element wise product has 768 dimensions computed using $BERT_{base}$.
% Thus, in case the element wise product will overwhelm other features, whose dimension is 38, we use PCA to reduce dimension of the element wise product to 5. In addition, the position feature is transformed to one-hot format.

\vspace{-0.1cm}
\subsection{Evaluation Metrics}
Since the standard Mean Reciprocal Rank (MRR) assumes that the clicked/purchased items are relevant while ignoring the position bias, we use weighted MRR \cite{metrics} to evaluate ranking effectiveness, which is formulated as $MRR^{m} = \frac{1}{\sum_{i=1, \tilde{y}_i^m=1}^N w_i^m} \sum_{i=1, \tilde{y}_i^m=1}^N w_i^m \frac{1}{p_i}$,
% \begin{align}
%     \label{eq:MRR}
%     MRR^{m} &= \frac{1}{\sum_{i=1, \tilde{y}_i^m=1}^N w_i^m} \sum_{i=1, \tilde{y}_i^m=1}^N w_i^m \frac{1}{p_i},\\
%     \label{eq:6}
%     w_i^m &= \frac{1}{P(s_i|f_i, p_i)},
% \end{align}
where $m\in \{ctr, cvr\}$, $N$ is the number of samples, $w_i^m = \frac{1}{P(s_i|f_i, p_i)}$ is a weight of $i$-th sample, $p_i$ is the position of the $i$-th sample and $\tilde{y}_i^m$ is the predicted label. 
$w_i^m$ is defined through the reciprocal of $P(s_i|p_i)$ which reflects the impact of position.

For PACC, $w_i^m$ can be calculated in a straightforward way since $P(s_i|p_i)=P(s_i|f_i, p_i)$ is obtained after training.
% while $P(s_i|f_i, p_i)$ cannot be directly obtained for PACC-PE.

To compute $P(s_i|f_i, p_i)$ for PACC-PE as mentioned in \cite{ubiased_ltr}, we first swap $p_i$ with $p_i=r$ for item $i$. 
% Based on the assumption that once the item is seen whether it will be clicked/purchased is independent of position, 
The probability of this item being clicked at position $p_i=r$ is
\begin{equation}
    \label{eq:9}
    P(y_i^{ctr}=1|f_i, p_i=r) = P(y_i^{ctr}=1|f_i, s_i=1)\cdot P(s_i|f_i, p_i=r).
\end{equation}
The probability of this item being clicked at position $p_i$ is
\begin{equation}
    \label{eq:10}
    P(y_i^{ctr}=1|f_i, p_i) = P(y_i^{ctr}=1|f_i, s_i=1) \cdot P(s_i|f_i, p_i).
\end{equation}
With Eq. (\ref{eq:9}) and Eq. (\ref{eq:10}), the ratio $\frac{P(s_i|f_i, p_i)}{P(s_i|f_i, p_i=r)} = \frac{P(y_i^{ctr}=1|f_i, p_i)}{P(y_i^{ctr}=1|f_i, p_i=r)}$ is obtained.
Thus, the weight $w_i^{ctr}$ for PACC-PE is
\begin{equation}
    \label{eq:w_pacc-pe}
    w_i^{ctr} = \frac{P(y_i^{ctr}=1|f_i, p_i=r)}{P(y_i^{ctr}=1|f_i, p_i)} \cdot \frac{1}{P(s_i|f_i, p_i=r)},
\end{equation}
which is proportional to $\frac{P(y_i^{ctr}=1|f_i, p_i=r)}{P(y_i^{ctr}=1|f_i, p_i)}$ since $P(s_i|p_i=r)$ is a constant for a fixed position $r$. $w_i^{cvr}$ can be calculated similarly.

In addition to the weighted MRR, we also apply the widely-used evaluation metrics: standard MRR, AUC, and position-wise AUC (PAUC) \cite{huang2021metrics2} to evaluate model performance.

% \subsection{Implementation Details}
% To preprocess text features, we use $BERT_{base}$ model with 12 Transformer layers, 768 hidden state dimensions, and 110M parameters in total to collect embedding for both ad name and query, then cosine similarity and element-wise product between query and ad name are calculated.

% We train the model on Walmart sponsored ads dataset by setting the maximum epoch number as 10, batch size as 2000, learning rate as $5e-5$, and the AdamW optimizer is used with weight decay $1e-6$ on one 32G memory Tesla V100 GPU.

\vspace{-0.1cm}
\subsection{Experimental Results and Analysis}


\begin{table}[t!]
% \vspace{-0.4cm}
\caption{Ranking Performance Comparison Results with Based Models}
\vspace{-0.3cm}
\centering
\resizebox{\linewidth}{!}{% <-
\begin{tabular}{l|c|c|c|c|c|c|c|c}
\hline 
\multirow{2}*{\textbf{Models}} & \multicolumn{4}{c|}{CTR} & \multicolumn{4}{c}{CVR} \\
\cline{2-9}
~ & \textbf{Weighted MRR} & \textbf{MRR} & \textbf{PAUC} & \textbf{AUC} & \textbf{Weighted MRR} & \textbf{MRR} & \textbf{PAUC} & \textbf{AUC} \\
% \multirow{2}*{\textbf{Models}} & \textbf{Weighted $MRR^{ctr}$} & \textbf{Weighted $MRR^{cvr}$} & \textbf{PAUC$^{ctr}$} & \textbf{PAUC$^{cvr}$} \\
% ~ & & & \\
\hline
DMT~\cite{dmt} & 39.65 & \textbf{39.68} & 88.43 & 87.75 & 42.38 & 42.31 & 56.60 & 83.82 \\
PAL~\cite{guo2019pal} & \textbf{39.67} & 39.44 & 88.67 & 88.02 & 42.52 & 43.37 & 55.22 & 80.82 \\
AITM~\cite{AITM} & 39.40 & 39.25 & 88.89 & 89.04 & 40.64 & 43.18 & 60.39 & 89.56 \\
% AITM (position 5) & 35.44\% & 32.87\% & & \\
PACC & 39.56 & 39.35 & 88.96 & 88.28 & 43.73 & 43.53 & \textbf{60.79} & \textbf{90.05}  \\
PACC-PE & 39.43 & 39.43 & \textbf{92.16} & \textbf{91.68} & \textbf{47.44} & \textbf{47.44} & 60.72 & 89.28 \\
% PACC-PE (position 5) & 38.15\%~(\uparrow 2.83\%/2.71\%) & 48.19\%~(\uparrow 15.94\%/15.32\%) & & \\
\hline
\end{tabular}
}
\label{tab:experimental results}
\vspace{-0.6cm}
\end{table}


\subsubsection{Ranking Effectiveness}
We compare the weighted MRR, MRR, PAUC, and AUC of our proposed models and the baselines PAL~\cite{guo2019pal}, AITM~\cite{AITM}, and DMT~\cite{dmt} models. 
% Weight in weighted MRR for PACC is estimated by Eq. (\ref{eq:6}). Weight in weighted MRR for PACC-PE and AITM is estimated by Eq. (\ref{eq:w_pacc-pe}). 
% To reduce the error of the weight estimation by swapping positions, we calculate two weighed MRR by swapping the original position with position 1 and position 5 respectively.
PAL is a single-task position bias mitigation model; AITM is a multi-task model; DMT is a multi-task position bias mitigation model.
The evaluation results are reported in Table~\ref{tab:experimental results}. 

For CTR prediction, all models perform similarly in terms of weighted MRR and MRR. PACC-PE outperforms the best baseline by 3.27\%/2.64\% in terms of PAUC/AUC with p-value = 0.0072 and confidence level > 99\%. 
For CVR prediction, PACC-PE significantly outperforms all other baseline models regarding weighted MRR and MRR, increasing weighted MRR/MRR by 4.92\%/4.07\% with p-value = 0.0088 and confidence level > 99\%. PACC also outperforms other baseline models. 

% To evaluate significance of model improvement, we perform a two-sided T-test comparing AITM to PACC and PACC-PE. We consider the null hypothesis that AITM has an identical evaluation values as PACC and PACC-PE. The null hypothesis is rejected with $p\_value= / $ and $confidence level > / $ for comparison between AITM and PACC/PACC-PE.

The substantial improvement in CVR prediction of our proposed models indicates that jointly mitigating position bias for both CTR and CVR and considering the sequential dependencies in order between click and purchase is effective for performance improvement.

\begin{comment}
From this table, we can see that our proposed models outperform the baselines significantly on both CTR prediction and CVR prediction. 
\textcolor{red}{
For CTR prediction, PACC increases weighted $MRR^{ctr}$ by 2.29\%/2.27\%; 
PACC-PE increases weighted $MRR^{ctr}$ by 2.64\%/2.52\%;
% PACC-PE swapping with position 5 increases weighted $MRR^{ctr}$ by 2.83\%/2.71\% compared to the baseline model swapping with position 1/5. 
For CVR prediction, PACC increases weighted $MRR^{cvr}$ by 3.21\%/2.59\%;
PACC-PE increases weighted $MRR^{cvr}$ by 26.93\%/26.31\%;
% PACC-PE swapping with position 5 increases weighted $MRR^{cvr}$ by 15.94\%/15.32\% compared to the baseline model swapping with position 1/5. 
The experimental results show that our proposed models achieve better ranking effectiveness than the baseline model.}
Compared with PACC, PACC-PE performs better on both the CTR prediction task and CVR prediction task, improving weighted MRR by 0.35\%/0.54\% and 23.72\%/12.73\% \textcolor{red}{ and PAUC by }. 
One possible reason is that PACC-PE models produce specific position information as embedding information for the subsequent CTR prediction task and CVR prediction task, which conveys richer and more useful information than PACC, which models position as a scalar probability. Besides, the positive samples of the CVR prediction task are more sparse, resulting in a relatively larger fluctuation of the weighted $MRR^{cvr}$ \textcolor{red}{ and ?}.
\end{comment}

\subsubsection{Position Bias}
To generally evaluate the ability of our proposed model in mitigating position bias, we randomly select 500 query-item pairs and visualize their probability of being clicked and purchased before and after swapping positions. To better interpret the predicted probabilities, the log odds function is used to project probabilities in log odds space. From Fig~\ref{fig:three_models} and Fig~\ref{fig:three_models2}, the sample points of PACC and PACC-PE fit better on $y=x$ compared to AITM, indicating that swapping item positions with position 1 has less influence on the predicted probabilities of being clicked and purchased by PACC and PACC-PE.


% Figure environment removed

% Figure environment removed
% % Figure environment removed
% % Figure environment removed


% Figure environment removed

\subsubsection{Position Bias on Different Positions}
To evaluate the ability of our proposed models in mitigating position bias on different positions, we investigate the differences in model prediction changes for items at different positions due to swapping positions with position 1. The smaller the position bias, the smaller the prediction changes due to swapping positions.
The impact of swapping item positions is visualized in Fig~\ref{fig:AITM_AITM_ait}. 
In Fig~\ref{fig:AITM} and Fig~\ref{fig:PAATM}, $\frac{P(y_i^{ctr}=1|f_i, p_i=1)}{P(y_i^{ctr}=1|f_i, p_i)}$ and $\frac{P(y_i^{cvr}=1|f_i,p_i=1)}{P(y_i^{cvr}=1|f_i, p_i)}$ are used to measure the impact of swapping item positions on CTR prediction and CVR prediction, respectively. As in Fig~\ref{fig:PAATM}, swapping item positions almost has no effect on both CTR and CVR prediction for PACC-PE on all positions, indicating that PACC-PE has the ability to mitigate position bias on all positions. In Fig~\ref{fig:AITM} swapping item positions has a large impact on the top few items and the last item in the ranking list for AITM. For items on the top, swapping them to position 1 improves the probability of being clicked and purchased, while for the last items swapping them to position 1 decreases the probability of being clicked and purchased. This phenomenon is counter-intuitive because intuitively swapping items to position 1 should increase the probability of being clicked and purchased. 
One possible explanation is that 
some items are safe choices, but not preferred. For these items, if they are ranked high, users will not click on them. But if they are ranked low, users may click them given no better items at the end of their browsing.
% in this dataset, items with too low relevance would instead highlight their low relevance if they were placed in position 1, resulting in not being clicked and purchased.
In Fig~\ref{fig:PAPTM}, $\frac{P(s_i| p_i=1)}{P(s_i| p_i)}$ is used to measure the impact of swapping item positions. The impact of swapping item positions for PACC is low compared to AITM, demonstrating the ability of PACC to alleviate position bias. For items at most positions, swapping positions to position 1 increases the probability of being clicked and purchased a little bit.

One difference between PACC-PE and PACC from Fig~\ref{fig:PAATM} and Fig~\ref{fig:PAPTM} is that for PACC, position bias of different items at the same position is the same, while for PACC-PE position bias of different items at the same position is different. This difference makes PACC-PE more flexible to different items and conveys richer information.

\vspace{-0.3cm}
\section{Conclusion}
To jointly mitigate position bias that exists in both item CTR and CVR prediction, we propose two position-bias-free CTR and CVR prediction models: Position Aware Click-Conversion and PACC with Position Embedding. In PACC, the position is modeled as a probability while in PACC-PE position is modeled into embedding. Our experiments and analyses illustrate that our proposed models achieve better ranking effectiveness than the state-of-the-art models and effectively mitigate position bias in all positions. Besides, PACC-PE outperforms PACC in ranking effectiveness and position debias due to the rich information by modeling product-specific position information as embedding.


% \vspace{-0.3cm}

% %%
% %% The acknowledgments section is defined using the "acks" environment
% %% (and NOT an unnumbered section). This ensures the proper
% %% identification of the section in the article metadata, and the
% %% consistent spelling of the heading.
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\balance
\bibliography{sigir_short}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

% \section{Research Methods}

% \section{Online Resources}

\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.
