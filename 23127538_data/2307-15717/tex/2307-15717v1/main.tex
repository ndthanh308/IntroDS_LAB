%%
%% This is file `sample-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `authordraft')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-authordraft.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers
%% NOTE that a single column version may required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2018}{Woodstock, NY}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
\let\SUP\textsuperscript
\usepackage{multirow}
\usepackage{graphicx}  
\usepackage{booktabs}  
% \usepackage[super]{natbib}  
% \usepackage{hyperref}  

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Utilizing Large Language Models for Natural Interface to Pharmacology Databases}

\author{Hong Lu, Chuan Li, Yinheng Li, Jie Zhao}
\email{{honglu, chuanl, yinhengli, zhaojie}@microsoft.com}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
% \author{Hong Lu}
% \affiliation{%
%   \institution{Microsoft Corporation}}
% \email{honglu@microsoft.com}

% \author{Chuan Li}
% \affiliation{%
%   \institution{Microsoft Corporation}}
% \email{chuanl@microsoft.com}

% \author{Jie Zhao}
% \affiliation{%
%   \institution{Microsoft Corporation}}
% \email{zhaojie@microsoft.com}
%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
% Pharmacologists play a pivotal role in identifying novel target genes and developing new drugs to cure diseases. In the process of drug development, pharmacologists review literature, form hypothesis, design experiments, and interpret the results. Each of these stages requires pharmacologists to query and access a wealth of information. We propose a Large Language Model (LLM) based Natural Language Interface to structured information stored in databases. We conduct experiments to showcase its high performance and effectiveness, and further evaluate the importance of each component through ablation tests. The framework can be extended to query other databases, and is widely applicable to other fields of research. We expect our end-to-end solution to significantly reduce the time spent by researchers on data exploration, leading to more efficient research and comprehensive insights.
% Pharmacologists play a crucial role in identifying novel target genes and developing new drugs to combat diseases. 
The drug development process necessitates that pharmacologists undertake various tasks, such as reviewing literature, formulating hypotheses, designing experiments, and interpreting results. Each stage requires accessing and querying vast amounts of information. In this abstract, we introduce a Large Language Model (LLM)-based Natural Language Interface designed to interact with structured information stored in databases. Our experiments demonstrate the feasibility and effectiveness of the proposed framework. This framework can generalize to query a wide range of pharmaceutical data and knowledge bases.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>10010520.10010553.10010562</concept_id>
%   <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010575.10010755</concept_id>
%   <concept_desc>Computer systems organization~Redundancy</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010553.10010554</concept_id>
%   <concept_desc>Computer systems organization~Robotics</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10003033.10003083.10003095</concept_id>
%   <concept_desc>Networks~Network reliability</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
% \keywords{datasets, neural networks, gaze detection, text tagging}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
% \begin{teaserfigure}
%   % Figure removed
%   \caption{Seattle Mariners at Spring Training, 2010.}
%   \Description{Enjoying the baseball game from the third-base
%   seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\vspace{-0.2cm}
\section{Introduction}
% There are many commonly used databases in pharmacology \cite{kamburov2009consensuspathdb, chandak2023building}, capturing various properties of biological entities (genes, proteins, drugs, phenotypes, and diseases, etc.) and their relationships. Through querying such databases, pharmacologists gather data and make informed decisions. Simple queries include retrieving GO terms of a specific protein, while complex queries may involve analyzing the diseases associated with the dysregulation of a genetic pathway. 

% However, formulating SQL queries and understanding these databases can be challenging and time-consuming. Some previous work, such as DIN-SQL\citep{pourreza2023dinsql}, explored techniques to generate SQL queries based on texts. In other work, Huang, et al.\cite{huang2021knowledge} for example, have developed a knowledge base question answering system leveraging the graph structure of the database.  For better performance, user-friendliness and broad applicability, we utilize LLMs and developed a natural language interface that enables pharmacologists to query any public or private databases. 
% Pharmacologists play a pivotal role in identifying novel target genes and developing new drugs to cure diseases. 
Numerous databases are commonly used in pharmacology \cite{mo-etal-2022-knowledge, chandak2023building}, encompassing various properties of biological entities (such as genes, proteins, drugs, phenotypes, and diseases) and their relationships. Simple queries might involve retrieving GO terms for a specific protein, while complex queries could necessitate analyzing diseases associated with the dysregulation of a genetic pathway. However, formulating SQL queries and comprehending these databases can be challenging and time-consuming for pharmacologists \cite{pourreza2023dinsql, huang2021knowledge}. 
% Some prior work, like DIN-SQL\citep{pourreza2023dinsql}, has investigated techniques for generating SQL queries based on text input. In another study, Huang et al.\cite{huang2021knowledge} developed a knowledge base question-answering system that leverages the graph structure of the database. 
In this work, we study employing Large Language Models (LLMs) to develop a natural language interface that enables pharmacologists to query public or private databases.

\vspace{-0.2cm}
\section{Method}
% Our end-to-end solution allows researchers to ask natural language questions, which are then translated into SQL queries by GPT4. Using these queries, the SQL database retrieves the relevant information from the databases, and the GPT4 model generates a coherent answer based on the original question and retrieved results. The system also enables auto-correction of the generated SQL query and allows for reruns if the user is unsatisfied with the results (Figure~\ref{fig:pipeline}).

% The solution are tested on both synthetic and realistic questions. Our synthetic dataset contains 60 single-hop questions and 204 two-hop questions on the knowledge graph of entities. These generated questions were also reviewed by domain experts to ensure their quality and relevance. Our realistic dataset contains 50 expert curated question-answering pairs.
As illustrated in Fig.~\ref{fig:pipeline}, our end-to-end Question Answering (QA) system allows users to ask natural language questions, which are then translated into SQL queries by GPT-4. Using these queries, the SQL database retrieves relevant information from the databases. Our system employs an in-house Named Entity Recognition (NER) model, followed by an entity linker built on Cognitive Search. Detected entities are replaced with their type-aware placeholders. The GPT-4 powered SQL generator facilitates schema linking, question decomposition, Chain-of-Thought, and self-correction of the generated SQL query.

In addition to the QA system, there is a separate question generation pipeline. This pipeline serves two purposes: generating a synthetic dataset to evaluate the QA model and providing in-context demonstrations for few-shot QA. This dual functionality ensures that the system is effective, accurate, and user-friendly, streamlining the research process and enhancing data exploration efficiency.

\vspace{-0.2cm}
\section{Results}
% Pharmacologists play a pivotal role in identifying novel target genes and developing new drugs to cure diseases. 
We evaluated our solution using both synthetic and realistic questions. Our synthetic dataset comprises 60 single-hop questions and 204 two-hop questions, based on the knowledge graph of entities. Domain experts reviewed these generated questions to ensure their quality and relevance. Furthermore, our realistic dataset includes 50 question-answer pairs curated by experts who are unaware of the database schema. This dataset represents the system's effectiveness and applicability to real-world scenarios, further demonstrating its practical utility.

% We use PrimeKG\cite{chandak2023building} as the knowledge graph, which comprehensively include 10 types of entities and 30 types of relations with over 8M edges. We use Exact Match (EM) and F1-score as metrics. To evaluate the importance of each module, we performed an ablation test and evaluate model performance on the realistic dataset with and without name entity recognition or self-correction (Table~\ref{tab:realistic}), highlighting the importance of both modules. Our model also demonstrated reasonable performances on synthetic questions (Table~\ref{tab:synthetic}). The results show that NER is a bottle-neck and verify that two-hop reasoning can be more difficult for LLMs.
We utilize PrimeKG\cite{chandak2023building} as the knowledge graph, which comprehensively includes 10 types of entities and 30 types of relations with over 8 million edges, aggregated from 20 bio-medical data sources. We employ Exact Match (EM) and F1-score as evaluation metrics. To assess the importance of each module, we conducted an ablation test and evaluated model performance on the realistic dataset with and without named entity recognition (NER) or self-correction (Table\ref{tab:realistic}). This test highlights the significance of both modules. Our model also demonstrated reasonable performance on synthetic questions (Table\ref{tab:synthetic}). The results indicate that NER is a bottleneck and confirm that two-hop reasoning can be more challenging for LLMs.

 
% In conclusion, our approach is accurate, efficient, and broadly applicable to enhance information retrieval across complex databases through natural language queries. This advancement is expected to accelerate research efforts in various fields, including drug discovery, disease diagnostics, and personalized medicine.

% Figure environment removed  


\begin{table}[h]  
\centering  
\caption{Realistic dataset ablation results. "$-$" denotes removing NER (using oracle entity names) or self-correction (SC).}  
\vspace{-0.4cm}
\label{tab:realistic}
\resizebox{0.7\columnwidth}{!}{
\begin{tabular}{l|l l|l l}  
\toprule  
\multirow{2}{*}{Setting} & \multicolumn{2}{c|}{ChatGPT} & \multicolumn{2}{c}{GPT-4} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5}  
& EM           & F1           & EM         & F1         \\ \midrule  
Full                         & 0.396            & 0.433            & 0.708          & 0.712        \\  
\quad$-$~{\footnotesize NER} & 0.458            & 0.491            & 0.792          & 0.797          \\  
\quad$-$~{\footnotesize SC}  & 0.313            & 0.316            & 0.708          & 0.712          \\  
\quad$-$~{\footnotesize NER} $-$~{\footnotesize SC} & 0.375            & 0.399            &  0.792         & 0.797          \\ \bottomrule  
\end{tabular}  
}
\end{table} 

\vspace{-0.2cm}
  
\begin{table}[h]    
\centering    
\caption{Evaluation on the synthetic dataset.}    
\vspace{-0.4cm}
\label{tab:synthetic}
\resizebox{\columnwidth}{!}{  
\begin{tabular}{l|l|ll|ll|ll}    
\toprule    
\multirow{2}{*}{LLM} & \multirow{2}{*}{Setting} & \multicolumn{2}{c|}{single-hop} & \multicolumn{2}{c|}{two-hop} & \multicolumn{2}{c}{Overall} \\ \cline{3-8}     
& & EM          & F1          & EM          & F1         & EM          & F1         \\ \midrule    
% \multirow{2}{*}{Chat-GPT} & Full           &            &            &            &           &            &           \\ \cline{2-8}     
%                           & Full $-$~NER   &            &            &            &           &            &           \\ \hline    
\multirow{2}{*}{GPT-4}     & Full           & 0.450      & 0.496      & 0.320    & 0.343   & 0.378    & 0.350    \\ \cline{2-8}     
                          & Full $-$~{\footnotesize NER}   & 0.700      & 0.746      & 0.458    & 0.483   & 0.513    & 0.543    \\   
\bottomrule                           
\end{tabular}    
}  
\end{table}   


%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{main}

%%
%% If your work has an appendix, this is the place to put it.
\clearpage

% \appendix
% \section{Supplementary Materials}

\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.


Figure 3: Example questions (optional)
Potential applications of our Natural Language to SQL (NL2SQL) system include answering questions related to protein properties (e.g., "What are the key biological processes in which protein ADD1 is involved?"), associated diseases (e.g., "Are there any known phenotypes associated with mutations or dysfunctions in protein KRAS?"), and existing drugs targeting specific proteins (e.g., "Are there any existing drugs that target protein TP53 or its associated pathways?").

Figure 4: Model performance
Two parts: entity linking / semantic parsing

Exact match(EM) and F1-score are used as metrics for evaluation. The model is evaluated under different settings on synthetic data including 60 single-hop instances and 204 two-hop instances.
