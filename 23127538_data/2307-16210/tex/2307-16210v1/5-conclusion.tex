\section{Conclusion}
In this work, we discussed the challenges and limitations of existing MMEA methods in dealing with modality incompleteness and visual ambiguity. Our analysis revealed that certain models overfit to modality noise and suffer from oscillating or declining performance at high modality missing rates, emphasizing the need for a more robust approach. Thus, we introduced UMAEA which introduces multi-scale modality hybrid and circularly missing modality imagination to tackle this problem, performing well across all benchmarks. 
There remain opportunities for future research, such as evaluating our techniques for the incompleteness of other modalities (e.g., attribute), and investigating effective techniques to  utilize more detailed visual contents for MMEA.


\subsubsection{Acknowledgments.}
This work was supported by the National Natural Science Foundation of China (NSFCU19B2027/NSFC91846204), joint project DH-2022ZY0012 from Donghai Lab, and the EPSRC project ConCur (EP/V050869/1).
