% Figure environment removed
\subsection{Details Analysis} \label{sec:analysis}
\subsubsection{{Component Analysis.}}
We further analyze the impact of each training objective on our model's performance in Figure \ref{fig:ablation}, where the absence of any objective results in varying performance degradation. 
As mentioned in Section \ref{sec:iir}, IIR serves as an enhancement for ECIA, and its influence is comparatively less significant than that of $\mathcal{L}_{GMI}$ and $\mathcal{L}_{ECIA}$.
%Notably, we discuss performance changes without the CMMI module for an independent comparison. 
The CMMI module's influence is detailed in Table \ref{tab:overall}, where it becomes more significant when $R_{img}$ is low. CMMI's primary function is to mitigate noise in the missing modalities,  facilitating efficient learning at high noise levels and minimizing the noise to existing information.

\subsubsection{{Efficiency Analysis.}}
Concurrently, we briefly compare the relationship between model parameter size, training time, and performance. Our model improves the  performance with only a minor increase in parameters and time consumption. 
This indicates that in many cases, our method can directly substitute these models with minimal additional overhead.
While there is potential for enhancing UMAEA's efficiency, we view this as a direction for future research.

\begin{table}[!htbp]
    \centering
%    \footnotesize
	\tabcolsep=0.3cm
    \renewcommand\arraystretch{1.0}
    \caption{Efficiency Analysis. Non-iterative model performance on three datasets with $R_{img}=0.4$, where ``Para.'' refers to the number of learnable parameters and ``Time'' refers to the total time required for model to reach the optimal performance.
    }
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{l|ccc|ccc|ccc}
        \toprule
         \multirow{2}*{\makebox[2cm][c]{Models}} & \multicolumn{3}{c|}{DBP15K$_{JA-EN}$} & \multicolumn{3}{c|}{DBP15K$_{FR-EN}$} & \multicolumn{3}{c}{OpenEA$_{EN-FR}$} \\
        & {\scriptsize Para. (M) } & {\scriptsize Time (Min) } & {\scriptsize MRR } & {\scriptsize Para. (M) } & {\scriptsize Time (Min) } & {\scriptsize MRR } & {\scriptsize Para. (M) } & {\scriptsize Time (Min) } & {\scriptsize MRR } \\
        \midrule
         EVA* {\footnotesize \cite{DBLP:conf/aaai/0001CRC21}} 
        & 13.27 & 30.9 & .711 & 13.29 & 30.8 & .721 & 9.81 & 17.8 & .642   \\
         MCLEA* {\footnotesize {\cite{DBLP:conf/coling/LinZWSW022}}}  
        & 13.22 & 15.3 & .703 & 13.24 & 15.7 & .702 & 9.75 & 19.5 & .637   \\
        \CC{w/o CMMI}  
        & \CC{13.82} & \CC{30.2} & \CC{.810} & \CC{13.83} & \CC{28.8} & \CC{.828} & \CC{10.35} & \CC{17.9} & \CC{.715}   \\
        \CC{UMAEA}  
        & \CC{14.72} & \CC{33.4} & \CC{.813} & \CC{14.74} & \CC{32.7} & \CC{.838} & \CC{11.26} & \CC{23.1} & \CC{.718} \\
        \bottomrule
    \end{tabular}
    }
    \label{tab:overall-iter-2}
\end{table}

% Figure environment removed
\subsubsection{Entity Distribution Analysis.} \label{sec:dist}
To further evaluate the robustness of our method,
% in various multi-modal entity pair scenarios
we analyze the model's prediction performance under different distributions of entity's visual modality.  Concretely, we compare five testing sets under $R_{img} \in  \{0.2, 0.4, 0.6\}$ with details presented in Figure \ref{fig:case},
% sorted based on the average expected number of images contained in each entity pair. 
where we exclude the CMMI module during the comparison.
We observe that EVA's performance is generally stable but underperforms when visual modality is  complete (TS 1), suggesting its overfitting to modality noise in the training stage.
In contrast, MCLEA exhibits more extreme performance fluctuations, performing worse than EVA does when there's incomplete visual information within the entity pairs (TS 2, 3, 4, 5).
Our superior performance reflects the intuition that the optimal performance occurs in TS 1, with tolerable fluctuations in other scenarios.
% More experimental results on other datasets are available in appendix.






