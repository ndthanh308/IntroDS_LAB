\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[T1]{fontenc}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}


% \iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{3696} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Supplementary Material of ``DRAW: Defending Camera-shooted RAW against Image Manipulation"}
\maketitle

\input{command}
In this supplementary material, we provide the details of the hybrid attack layer, the baseline designs and the experimental settings.
Also, more experimental results on the imperceptibility of RAW protection and the performance of robust image manipulation detection are presented.
Finally, we extend our RAW protection method by applying it to the existing RGB images from two famous image manipulation detection datasets, i.e., CASIA~\cite{CASIA} and Defacto~\cite{Defacto}, with the help of RGB2RAW inversion.
The code for implementing DRAW is included in the attached file, where the ``README.md" file shows detailed procedures how to generate protected images, how to conduct automatic image manipulation and how to determine the forged areas. Due to file size limit, we are only able to include the checkpoint of the protection model, while those of the localization networks are too large to upload, e.g., 252MB for HRNet and 163MB for MVSS.

\section{Details of the Hybrid Attack Layer.}
\noindent\textbf{Manipulation Mask Generation.}
Real-world image tampering may be oriented on regions of interest within a targeted image. 
However, code-driven realistic image manipulation can be expensive and time-consuming. 
We study the natural distribution of tampered areas by observing the binary masks in CASIA dataset~\cite{CASIA}.
The location of forgery within an image roughly follows a uniform distribution except for corners, and for most manipulated images, the total area of forged contents is within the range of 5\%-30\%. 
For simplification, we assume that the location of forgery within an image during training roughly follows a uniform distribution and the accumulated manipulated squared area is within the range of $[0,0.3]$.
% We restrict the rate of the tampered region as $r_{t}\in[0.0,0.5]$.

% \noindent\textbf{Setting of Attacks.}
We apply free-form mask generation~\cite{yu2019free} to arbitrarily select areas within $\hat{\mathbf{I}}$ according to a binary mask $\mathbf{M}$. 
% The manipulated image $\hat{\mathbf{I}}^{\emph{t}}$ is generated by altering 5\%-30\% of all pixels.
\begin{equation}
\label{eqn_manipulate}
\hat{\mathbf{I}}^{\emph{t}}=\hat{\mathbf{I}}\cdot(1-\mathbf{M})+\mathbf{R}\cdot\mathbf{M},
\end{equation}
where $\mathbf{R}$ is the source of manipulation.

% We restrict the rate of the tampered region as $r_{t}\in[0.0,0.5]$.
\noindent\textbf{Image Manipulation Simulation.}
For image manipulation, we simulate the most common types of tampering, which include \textit{copy-move}, \textit{splicing} and \textit{inpainting}.
The simulation of different kinds of attacks can be reflected by the composition of $\mathbf{R}$ in Eq.~(\ref{eqn_manipulate}).
For \textit{copy-move}, we let $\mathbf{R}$ in Eq.~(\ref{eqn_manipulate}) as a spatially-shifted version of $\hat{\mathbf{I}}^{\emph{t}}$. 
For \textit{splicing}, we use another random RGB image as $\mathbf{R}$. 
However, we find that this setting of attack will encourage the network to widen the distribution gap between $\hat{\mathbf{I}}$ and natural RGB images to better distinguish each other, thus greatly decreasing the overall image quality.
To address this, we also apply an enhanced \textit{splicing} attack named \textit{coincident-splicing} that ``coincidentally" use another protected RGB $\hat{\mathbf{I}}'$ as $\mathbf{R}$.   
For \textit{inpainting}, we use the open-source model from LAMA~\cite{LAMA} and ZITS~\cite{ZITS} to generate the inpainted result as $\mathbf{R}$.
We iteratively and evenly perform the above \textit{three} types of attacks for balanced training. 

\noindent\textbf{Image Distortion Simulation.}
Similar to HiDDeN~\cite{zhu2018deep}, we simulate typical image lossy post-processing operations to enhance the robustness of the proposed method.
The involved attacks include the following: 
(1) \textit{rescaling}, which resizes the image by an arbitrarily resizing rate $r\in[50\%,150\%]$, 
(2) \textit{median blurring}, which blurs the image using median filter whose kernel size $k$ is arbitrarily selected from $[3,5]$, 
(3) \textit{Additive White Gaussian Noise} (AWGN), which adds Gaussian noise evenly on the image, where the standard value s ranges from zero to one, 
(4) Gaussian blurring, which is similar to the median blurring but the kernel is different,
(5) \textit{JPEG compression}, which compresses the image using the popular Diff-JPEG~\cite{shin2017jpeg} with tunable JPEG quality factors.

\noindent\textbf{Color Adjustment Simulation.}
Most users prefer manually adjusting the brightness or contrast after RAW files are automatically rendered into RGBs.
Therefore, we also simulate typical color adjustment operations to mitigate their impacts on the performance of our method.
The involved attacks include the following:
(1) \textit{Hue adjustment}: the image hue is adjusted by converting the image to HSV and cyclically shifting the intensities in the hue channel. The image is then converted back to the original image mode.
The hue factor is set within the range of $[-0.05.0.05]$.
(2) \textit{contrast enhancement}: we adjust the contrast of an image, where the contrast factor is set within the range of $[0.7,1.5]$.
% (3) \textit{gamma correction}: we conduct gamma correction on the image, where the factor is set within the range of $[-0.05,0.05]$. Note that it differs from the default gamma correction method performed by modern ISP pipelines during image rendering. The reason for a second gamma correction is that the correction curves vary among different enterprises and therefore might not be preferred by the user.
(3) \textit{saturation adjustment}: we adjust the color saturation of the image, where the factor is set within the range of $[0.7,1.5]$.
(4) \textit{brightness adjustment}: we adjust the brightness of the image, where the factor is set within the range of $[0.7,1.5]$.
The differentiable data augmentation functions applied during training are implemented by the APIs from the ``torchvision" package.


\noindent\textbf{Attack Generation during Testing.}
For quantitative evaluation for \textit{splicing}, we borrow the segmentation masks from MS-COCO~\cite{lin2014microsoft} dataset, crop out the corresponding objects and iteratively add them onto the protected images $\hat{\mathbf{I}}$ until the total manipulation rate exceeds 5\%. 
For \textit{copy-move}, we generate the attacked image under the same principle that was used during training.
% For \textit{inpainting}, we additionally involve a new scheme, i.e., EdgeConnect~\cite{edge}
% For fair comparison with image forgery detection schemes, we perform the attacks using the exact same setting on the original images $\mathbf{I}$. 

\noindent\textbf{Real-world Attack Involvement.}
The real-world attacks are implemented by the APIs from the ``cv2" package, e.g., \textit{cv2.GaussianBlur} for Gaussian blurring and \textit{cv2.imencode} for JPEG compression.
These functions are performed on PIL images in ``ndarray" format, which requires that we transform the 32-bit float-typed tensors into 8-bit integer-based arrays.
Therefore, quantization attack is also automatically considered by the introduction of real-world attacks. 
In each iteration of the training stage, we perform the corresponding real-world attacks using the same setting from the simulated methods.

\section{Frequency Learning in Deep Networks}
\noindent\textbf{Existing Methodologies.}
Frequency-learning is an efficient way to reduce computation resource costs. For example, Xu et al.~\cite{xu2020learning} proposes a learning-based frequency selection method to identify trivial frequency components in the input images, which can be removed without performance loss. According to ~\cite{lee2021fnet}, self-attention layers can be replaced with simple Fourier transformations to spped up Transformer encoder architectures under limited accurary sacriface. FEDformer~\cite{zhou2022fedformer} exploits the sparse representation in Fourier transform to capture the global view of time series. 
In addition, frequency-domain information has shown great potential in revealing subtle differences between real and fake images, such as in face forgery detection tasks, where it can help detect generated faces~\cite{dzanic2020fourier, chandrasegaran2021closer, wang2020cnn} or synthesized images~\cite{qian2020thinking, li2021frequency, liu2021spatial} based on face-swapping techniques.

However, the above-listed work only replaces interpolation with DWT or DCT, which still requires heavy computation. In order to design a new lightweight network with frequency learning, we must effectively combine the advantages of wavelet transform and CNN architecture.
% for CNN to enlarge the receptive field. 

% Figure environment removed
\noindent\textbf{DT-CWT Transformation.}
The Dual-Tree Complex Wavelet Transform (DT-CWT) is a type of wavelet transform used in signal and image processing. 
It was introduced by Kingsbury~\cite{DTCWT} and is an extension of the discrete wavelet transform (DWT) that uses complex wavelets.
The DT-CWT is a two-dimensional transform that decomposes an image into six frequency subbands at each level of the transform. These subbands are formed by filtering the image with two sets of filters, one for the real part of the wavelet and the other for the imaginary part. 
The filters are designed to have good directional selectivity and to be approximately shift-invariant.

The DT-CWT has several advantages over other wavelet transforms, e.g., the Haar Wavelet Transform~\cite{stankovic2003haar} and the Daubechies Wavelet Transform~\cite{vonesch2007generalized}. 
1) Directionality. The DT-CWT is designed to be directional, meaning it can capture edges and other features that have a preferred orientation. This is particularly useful in image processing tasks, where many objects have a characteristic orientation.
2) Phase information. The DT-CWT provides complex coefficients, which contain both magnitude and phase information. This phase information can be useful in certain applications, such as texture analysis, where the phase information can help distinguish between different types of textures.
3) Redundancy. The DT-CWT is redundant, meaning that some of the information is duplicated across different subbands. This redundancy can be useful in denoising or other signal processing tasks, where the redundant information can help to improve the robustness of the algorithm.


% Figure environment removed

The DT-CWT has been successfully applied to various computer vision tasks, including image denoising~\cite{hill2012undecimated}, image super-resolution~\cite{izadpanahi2013motion}, and object detection~\cite{sun2006face,sengar2020moving}. For example, in object detection, the DT-CWT can be used to extract features that are both scale and orientation invariant, which can improve the accuracy of the detector. In image super-resolution, the DT-CWT can be used to extract high-frequency information that is lost during image downsampling, which can then be used to reconstruct a higher-resolution image.
With the development of modern CNN networks, researchers prefer learning end-to-end feature extractors in favor of pre-designed filters, which possibly results in a downgraded role of wavelet transform played in computer vision tasks. However, compared to cascaded learnable convolutional layers, DT-CWT transform still contain several advantages as follows.

\noindent\textbf{Bringing DT-CWT into CNNs.}
Introducing DT-CWT into CNNs can have several advantages for our task and beyond. First, the DT-CWT is robust to noise in image data, as it can extract features at multiple scales and orientations. This can help improve the performance of CNNs on modifying the higher-frequency details.
Second, the DT-CWT can extract rich features that are both scale and orientation invariant, which can improve the discriminative power of CNNs. This can be particularly useful in content-aware protective signal embedding.
Thirdly, the DT-CWT can reduce the complexity of CNNs by reducing the number of filters required in the initial layers. It also provides both magnitude and phase information, which can be used to visualize and interpret the learned features.

In MPF-Net, we combine the benefit of DT-CWT with Fourier frequency learning, where FFT can mitigate the issue of focusing too much on local patterns. 
Besides, global information aggregation and lower computational complexity is achieved by the proposed HFC and PFF mechanisms.

% Here is the general equation for the DT-CWT transform:

% \begin{equation}
% W_{j,k,l}(m,n) = \sum_{p=0}^{1} \sum_{q=0}^{1} h_{p,q} g_{j-1}(m-2p,n-2q) e^{-j2\pi [(2p+1)m+(2q+1)n]/2^{j+1}} + j\sum_{p=0}^{1} \sum_{q=0}^{1} g_{p,q} h_{j-1}(m-2p,n-2q) e^{-j2\pi [(2p+1)m+(2q+1)n]/2^{j+1}}
% \end{equation}

% where $W_{j,k,l}(m,n)$ represents the coefficient at scale $j$, position $(m,n)$ and orientation $k$ in the $l$-th subband. The coefficients are computed using the real filters $h$ and the imaginary filters $g$, which are convolved with the image at different scales and orientations.

\section{More Experimental Results}

% Figure environment removed

% Figure environment removed

% Figure environment removed


\setlength{\tabcolsep}{1.05mm}{
\begin{table}[!t]
\footnotesize
%\renewcommand{\arraystretch}{1.1}
    \caption{\textbf{Average performance against color adjustment attacks and hybrid attacks on RAISE dataset.} The detector can successfully locate the forged areas in most cases.}
    	\label{table_comparison_hybrid}
    \centering
	\begin{tabular}{c|ccc|ccc|ccc}
		\hline
		\multirow{2}{*}{Attack} & 
		 \multicolumn{3}{c|}{splicing} &
		 \multicolumn{3}{c|}{copy-move} &
		 \multicolumn{3}{c}{inpainting} \\
        \cline{2-10}
        & Rec. & F1 & IoU 
        & Rec. & F1 & IoU 
        & Rec. & F1 & IoU \\
        \hline
        Hue Adjust.
        & .938 & .949 & .905 & .973 & .974 & .962 & .779 & .794 & .736 \\
        Contra. Enhan.
        & .935 & .945 & .900 & .971 & .969 & .958 & .773 & .783 & .726  \\
        Satur. Adjust.
        & .937 & .948 & .904 & .969 & .968 & .958 & .784 & .795 & .738 \\
        Bright. Adjust.
        & .936 & .947 & .903 & .960 & .960 & .948 & .771 & .782 & .725  \\
		\hline
% 		copy move\cite{kwon2022learning}
		JPEG70+Hue.
        & .900 & .855 & .769 & .906 & .872 & .824 & .489 & .508 & .396  \\
        G-Blur+Contra.
        & .553 & .637 & .520 & .895 & .902 & .866 & .755 & .774 & .692 \\
        M-Blur+Satur.
        & .927 & .939 & .890 & .960 & .956 & .938 & .821 & .832 & .754  \\
        AWGN+Bright.
        & .930 & .935 & .885 & .952 & .944 & .925 & .842 & .842 & .778 \\
		\hline
  
	\end{tabular}
\end{table}
}

Fig.~\ref{image_protection_isp} and Fig.~\ref{image_detection_hrnet} show more experimental results on the imperceptibility of RAW protection and the performance of robust image manipulation detection after applying for RAW protection.
From the results, we see that the injected signal is weak and the generated protected RGB images are not affected in their overall visual quality.
While previous forgery detection methods strive hard to find traces for unveiling manipulation with the presence of loss image operations, we could successfully locate the tampered area on the forged protected image. 
% Therefore, DRAW helps promoting 
% \noindent\textbf{Performance against Color Adjustment Attacks and Hybrid Attacks.}
In Table~\ref{table_comparison_hybrid}, we further conduct color adjustment attacks and hybrid attacks on the protected images and let the networks detect the forged areas. The experiments show that our network can also detect forged areas, which proves the effectiveness of our scheme.

Fig.~\ref{image_improve_MVSS} and Fig.~\ref{image_improve_RIML} respectively show some examples of performance gain on MVSS~\cite{dong2021mvss} and RIML~\cite{RIML} with DRAW. 
The protection helps the two detectors locate the forged area despite the presence of lossy image operations.


\section{Details of the Baseline Methods.}
Fig.~\ref{fig_baseline_illustrate} illustrates the pipeline overview of the two baseline methods, namely, image forgery detection with pure robust training and image forgery detection using RGB protection.
Detailed settings are specified as follows.

\noindent\textbf{RAW Protection vs Pure Robust Training.}
We validate the impact of RAW protection on the performance of DRAW by first removing the RAW protection stage.
The corresponding fidelity terms are also removed.
In this case, no camera imaging pipeline is considered and the training technique of hybrid attacking layer involvement is solely responsible for improving the robustness of image manipulation localization, which is close to RIML.
According to the experiments, the baseline can indeed noticeably boost the performance of manipulation detection under lossy image operations, but the overall accuracy is worse than that of DRAW.
The reason is that finding a universally-existing trace to unveil manipulation is difficult in the real world, unlike injecting an outer-sourced signal for later retrieval.

% Figure environment removed

% Figure environment removed

% Figure environment removed

\noindent\textbf{RAW protection vs RGB protection.}
We compare RAW protection with RGB protection, in which we modify the original image for anti-manipulation protection. The ISP process is also ruled out in the pipeline.
The RAW protection term is therefore removed and the hyper-parameters are changed as $\beta=1,\gamma=0.01, \epsilon=0.005$.
Though the two schemes ideally can come up with the same solution where after image rendering, the protective signal embedded within RAW could be the same or close compared with that embedded directly within RGB, the experimental results show that successful RGB protection is more difficult compared to RAW protection.
The reason is that RAW data offers a much larger dynamic range compared to 8-bit RGB images, therefore offering way more possible solutions for effective image protection.

\section{Other Implementation Details}
We train all network-based ISP pipelines using RGB images rendered by the libraw library as supervision and these pre-trained ISPs will be frozen when training the RAW protection network.
We find that for different RAW datasets, the performances of cross-dataset RGB image rendering of ISP networks are not satisfactory.
Therefore, for each RAW dataset, we separately train their exclusive ISP networks.
In contrast, our protection network is transferable, and we train the network based on a single benchmark dataset, e.g., RAISE, and conduct experiments on other datasets on this model without further fine-tuning.

\setlength{\tabcolsep}{1.1mm}{
\begin{table}
\footnotesize
\renewcommand{\arraystretch}{1}
    \caption{\textbf{Average performance of RAW protection applied on the existing RGB images.} We revert images from typical manipulation datasets and perform RAW protection.}
    	\label{table_comparison_supp}
    \centering
    
	\begin{tabular}{c|cc|cc|cc|cc}
		\hline
		\multirow{2}{*}{Datasets} & 
		 \multicolumn{2}{c}{No attack} &
		 \multicolumn{2}{c}{Rescaling} &
            \multicolumn{2}{c}{AWGN} &  \multicolumn{2}{c}{GBlur} \\
        \cline{2-9}
        & F1 & IoU 
        & F1 & IoU 
        & F1 & IoU 
        & F1 & IoU \\
        \hline
        % & Resfcn${^{*}}$
        % & .440 & .528 & .408 & .064 & .096 & .062 & .396 & .489 & .371 & .181 & .250 & .172 & .457 & .554 & .430 & .443 & .535 & .413 & .443 & .533 & .412 \\
        CASIA v2.0
        & .911 & .855 & .771 & .676 & .854 & .774 & .679 & .563  \\
        Defacto-splicing
        & .806 & .757 & .858 & .811 & .810 & .760 & .869 & .823  \\
        Defacto-inpainting
        & .869 & .812 & .902 & .846 & .864 & .807 & .920 & .862   \\
		\hline
	\end{tabular}
\end{table}
}
\section{Extending RAW Protection on the Existing RGB Images}

We further extend our method to include RAW protection into existing RGB images.
Considering that most RGB images do not have their corresponding RAW data, we train an RGB2RAW reversion network, denoted as $\mathcal{R}$, using InvISP~\cite{InvISP}, which is based on an invertible neural network~\cite{dinh2014nice}.
We train the reversion network based on the RAISE dataset. In the forward pass, the RAW data is transformed into the corresponding RGB image, and the RAW data is retrieved in the backward pass given the ground-truth RGB image.
After training this network, we feed it with the RGB images from CASIA and Defacto and generate their approximate RAW data.
Because the reverting network is trained on the RAISE dataset, we also use the ISP network trained on the RAISE dataset.
The pipeline is shown in Fig~\ref{fig_invert_illustrate}.

Note that CASIA and Defacto only provide forgery images and the manipulation masks, with no original clean images given.
Alternatively, after reverting RGBs into RAWs, we protect the entire image as a whole that includes the forged area, after image rendering, we alter the manipulated content using Eq.~(\ref{eqn_manipulate}), where the protective signal within the manipulated areas will be therefore lost.
We skip the testing on the \textit{copy-move} attack because we cannot obtain the original location of the source and therefore cannot introduce the shifted version of the protective signal on the forged area.
We use the default HRNet as the detector.

In Table~\ref{table_comparison_supp} and Fig.~\ref{fig_results_casia}, we respectively present the quantitative and qualitative experimental results of extending RAW protection on the images from CASIA and Defacto.
The averaged PSNR between the protected RGB images and their original versions is 42.15dB on CASIA and 41.43dB on Defacto, which shows pleasing visual results. 
Besides, the quantitative results on image manipulation detection show that even if we post-process the already forged images, the detector can successfully locate the forged areas.
The results show a promising direction of involving RAW protection in the study of image trust and authenticity where once the images are shot, they can be no longer easily manipulated at one's free will.


% \noindent\textbf{\share{Shared Questions: 1) Benefits and Motivation of RAW-domain protection.}} \textbf{A:} \highlight{\textbf{Practicality.}} The lightweight MPF-Net is designed to be integrated into cameras for image protection in the shooting stage, thereby changing the current situation where digital images can be freely manipulated.
% \highlight{\textbf{Quality.}} RAWs are the source of digital images with larger dynamic range.
% Compared to RGB-domain protection, DRAW enjoys a much larger searching space that the RGBs rendered from the protected RAWs have higher fidelity \& sampling probabilistic density. 
% % In the supplement, we show that we can also apply DRAW on existed RGBs by RGB2RAW reversion.
% % RGB-domain image protection methods so far leave noticeable artifacts (PSNR\textless~35dB) that might fall short in practical application. 
% % We explore image protection in the RAW domain and transfer the protection from RAW to RGB, with averaged PSNR\textgreater~40dB. 
% % , and the forgery detection results on these protected RGBs are also promising.
% % \highlight{2) Larger searching space.}
% % RGBs are subject to the restriction of 8-bit integer decimal (255). 
% % It can inspire futher works.
% % \highlight{3) Promoting robustness via ISP}.
% \highlight{\textbf{Robustness.}} 
% % Apart from post-processing operations, DRAW requires the protective signal to successfully travel through different ISP pipelines and reside on the RGBs. 
% % The demand of protective signal traveling through ISP adds randomness and improves robustness.
% Apart from RGB-domain attacks, 
% DRAW can additionally resist RAW-domain ISP-based post-processing.

% \noindent\textbf{\share{2) Experiments on more unseen, stronger, real attacks.}}
% \textbf{A:} \highlight{In Table 1, we show more experiments to justify the generalizability.} We upload 150 of the same manipulated images included in Table 2 (paper) onto several famous OSNs and download them for detection.
% % The setting is close to RIML [24].
% % We find that OSN transmission attack mainly comprise of lossy JPEG compression.
% \highlight{Also, we test the performance against dual JPEG and salt\&pepper attack ($p=5\%$).}
% We see the performances do not drop remarkably.

% \noindent\textbf{\share{3) What does the protective signal look like?}}
% \textbf{A:} We show three examples of augmented residuals in the RGB domain.
% Repeated patterns are evenly scattered in the images adaptive to the image content, serving as \highlight{\textit{locks} onto the pixels.}
% They are tolerant to benign post-processing attacks like compression. 
% % The pattern does not exist in natural image distribution. 
% % For passive image forgery detection schemes, localization is done by finding fragile and universal traces, which is proven to be difficult.
% \highlight{Localization is conducted by observing whether these \textit{locks} are destroyed by manipulation.}
% % The patterns are augmented 20 times for illustration.
% % , and is imperceptible since averaged PSNR \textgreater~40dB.

% \noindent\textbf{\Rone{Reviewer fNjQ: 1) Some notations are not clear.}}
% \textbf{A:} 
% \highlight{\textbf{We thank the rigid review! We will add explanations, details for these issues.}}
% % Thanks for pointing out the issues. 
% % We will fix them and further polish the paper. 
% % The explanations are as follows.
% \highlight{The process of Eq.(1)} is contained in ISP layer $\mathcal{S}$ in Fig.3. 
% % We will illustrate that. 
% % \highlight{L286-L298} introduces the composition of the attack layer that was initially specified in the supplement.
% % We will add more details for \highlight{L286-L298}. 
% \highlight{Manipulated images} contains simulated manipulation which should be detected. \highlight{Authentic (or non-manipulated) images} force the detector to lower false alarm rate. \highlight{$\hat{\mathbf{I}}_\emph{t/nt}$} means either tampered ($\emph{t}$) or non-tampered ($\emph{nt}$) images. 
% % We will alter the way of representing it.
% % \highlight{``tamper" operation} in Fig.3(b) is the same as "Image Manipulation Simulation".
% \highlight{Inpainting} is a typical type of manipulation for forgery detection [5,11,24,25]. 
% \highlight{``representation flooding"} refers to relying on only some of the subbands while the rest is unused, resulting in non-robust solutions.
% % and therefore we reserve a portion of features in each stage to prevent it.
% % and directly concatenate them with the fused output in each PFF. 

% \noindent\textbf{\Rone{2) How is the manipulation decision made and how to calculate F1 and recall.}}
% \textbf{A:} We follow [5,11,24,25] that \highlight{only estimates forgery mask, but do not make binary classification.} 
% The calculation of F1 and recall also follows their common criteria. 
% We will refer readers to these works.
% % we first calculate precision, recall and F1 score by pixelwisely comparing the predicted mask and the ground truth of each image. Then we report the averaged values over the whole test sets. 

% \noindent\textbf{\Rone{3) Comparisons are not fairly conducted.}}
% \textbf{A:} [5,11,24,25] are passive methods that cannot be directly compared. 
% We made two attempts for reasonable comparison: 
% \highlight{1) Fine-tuning these models on the RAW datasets} and strengthening them using our attack layer (Table 2, paper). \highlight{2) Extending our method} by reverting the RGBs from the forgery detection datasets to allow DRAW protection (Table 2, supplement).
% During experiment, we found that \highlight{the performance of MVSS-Net and RIML surpass that of MantraNet}.
% We will include the performance in the supplement.

% % Figure environment removed
%  \setlength{\tabcolsep}{1.05mm}{
% \begin{table}[!t]
% \footnotesize
% %\renewcommand{\arraystretch}{1.1}
%     \caption{Additional performance of DRAW-HRNet.}
%     	\label{table_comparison_hybrid}
%     \centering
% 	\begin{tabular}{c|cc|cc|cc|cc|cc}
% 		\hline
% 		\multirow{2}{*}{Forgery} & 
% 		 \multicolumn{2}{c|}{S\&P} &
% 		 \multicolumn{2}{c|}{Dual JPEG} &
% 		 \multicolumn{2}{c|}{Facebook} &
% 		 \multicolumn{2}{c|}{Weibo} &
% 		 \multicolumn{2}{c}{WeChat}\\
%         \cline{2-11}
%         & F1 & IoU 
%         & F1 & IoU 
%         & F1 & IoU
%         & F1 & IoU
%         & F1 & IoU\\
%         \hline
%         splicing
%         & .839 & .855 & .657 & .683 & .917 & .920 & .902 & .897 & .763 & .728\\
%         copymove
%         & .854 & .850 & .692 & .729 & .905 & .910 & .859 & .870 & .637 & .688\\
%         inpainting
%         & .687 & .711 & .377 & .423 & .665 & .598 & .623 & .577 & .410 & .355\\
% 		\hline
  
% 	\end{tabular}
% \end{table}
% }

% \noindent\textbf{\Rtwo{Reviewer NDyB: 1) About the evaluation protocol.}} \textbf{A:} The details of test setting are specified in ``Attack Generation during Testing" of the supplement. 
% % \highlight{We also include hand-crafted attacks by volunteers, which accounts for 20\% of the test samples.}
% \highlight{For splicing, the difference is that we borrow the segmentation masks from MS-COCO dataset.} 
% Our applied criterion is close to that in RIML and ``Zhou et al. Learning rich features for image manipulation detection. CVPR 2018", in the hope to circumvent the expense of handcrafting thousands of images on RAW datasets.
% \highlight{We provide performance against large-scale hand-crafted datasets in Table 2 of the supplement} using RGB2RAW reversion.
% The source for splicing are not protected images.
% $C_\emph{in}=3$, $C_\emph{out}=3$ and $C_f=32$.

% , which other tasks might also benefit from.

% \noindent\textbf{\Rtwo{3) Near 35dB [27] can have decent results?}}
% \textbf{A:} [27] produces noticeable artifacts when zoomed in, which might not be acceptable in real world. 
% % It falls short in practical application.
% \textgreater~40dB as objective benchmark is more in line with the watermarking works [30-32].

% \noindent\textbf{\Rthree{Reviewer B8fF: 1) Explain transferability. Is there generalizability?}}
% \textbf{A:} Transferability is interpreted as \highlight{we embed protective signal on RAW and it can travel through ISP and exist in RGBs.}
% We do not train individual networks to combat each attack. 
% \highlight{The performances against typical attacks are from a single ``combined" network.}
% Besides, we conduct experiments against more untrained attacks in Table.1. 

% \noindent\textbf{\Rthree{2) Meaning of ``sync"?}}
% \textbf{A:} We take JPEG(QF=80) as an example according to L293-298. $\hat{I}_\emph{rw}$ in Fig.3(b) is generated by storing $\hat{I}$ into ``png" and then ``jpg" using ``libjpeg" on the disk.
% $\hat{I}_\emph{syn}$ is generated using DiffJPEG [6] with QF=80.
% The difference $d$ is added onto $\hat{I}_\emph{syn}$ to enable gradient. 
% \highlight{``Sync" is from $\hat{I}_\emph{syn}=\hat{I}_\emph{rw}$ in value, which closer their gap.}
% % between simulated and real attacks during training. 

% \noindent\textbf{\Rthree{3) No real-world attack is provided during testing?}}
% \textbf{A:} In our experimental results, the attacks follow real-world setting, i.e., conducted on the disk rather than simulated. \highlight{Besides, we include more experiments in Table 1.}


%------------------------------------------------------------------------
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
