
@article{jamila_diagnostic_2022,
	title = {a {Diagnostic} {Model} for the {Prediction} of {Liver} {Cirrhosis} {Using} {Machine} {Learning} {Techniques}},
	volume = {3},
	issn = {2709-0043},
	doi = {10.51594/csitrj.v3i1.296},
	abstract = {Liver cirrhosis is the most common type of chronic liver disease in the globe. The ability to forecast the onset of liver cirrhosis sickness is critical for successful treatment and the prevention of catastrophic health implications. As a result, the researchers created a prediction model using machine learning techniques. This study was based on a dataset from the Federal Medical Centre, Yola, which included 583 patient instances and 11 attributes. The proposed model for the prediction of liver cirrhosis sickness employed Nave Bayes, Classification and Regression Tree (CART), and Support Vector Machine (SVM) with 10-fold cross-validation. Accuracy, precision, recall, and F1 Score were used to evaluate the model's performance. Among all the strategies used in this study, the Support Vector Machine (SVM) technique produces the best results, with accuracy of 73\%, precision of 73\%, recall of 100\%, and F1 Score of 84\%. Based on medical data from FMC, Yola, this study shows that machine learning methods, specifically the Support Vector Machine, provide a more accurate prediction for liver cirrhosis sickness. This approach can be used to help doctors make better clinical decisions.},
	number = {1},
	journal = {Computer Science \& IT Research Journal},
	author = {Jamila, Ganty and Wajiga, Gregory Msksha and Malgwi, Yusuf Musa and Maidabara, Abba Hamman},
	year = {2022},
	pages = {36--51},
}

@article{rahman_comparative_2019,
	title = {A comparative study on liver disease prediction using supervised machine learning algorithms},
	volume = {8},
	issn = {22778616},
	abstract = {Chronic Liver Disease is the leading cause of global death that impacts the massive quantity of humans around the world. This disease is caused by an assortment of elements that harm the liver. For example, obesity, an undiagnosed hepatitis infection, alcohol misuse. Which is responsible for abnormal nerve function, coughing up or vomiting blood, kidney failure, liver failure, jaundice, liver encephalopathy and there are many more. This disease diagnosis is very costly and complicated. Therefore, the goal of this work is to evaluate the performance of different Machine Learning algorithms in order to reduce the high cost of chronic liver disease diagnosis by prediction. In this work, we used six algorithms Logistic Regression, K Nearest Neighbors, Decision Tree, Support Vector Machine, Naïve Bayes, and Random Forest. The performance of different classification techniques was evaluated on different measurement techniques such as accuracy, precision, recall, f-1 score, and specificity. We found the accuracy 75\%, 74\%, 69\%, 64\%, 62\% and 53\% for LR, RF, DT, SVM, KNN and NB. The analysis result shown the LR achieved the highest accuracy. Moreover, our present study mainly focused on the use of clinical data for liver disease prediction and explore different ways of representing such data through our analysis.},
	number = {11},
	journal = {International Journal of Scientific and Technology Research},
	author = {Rahman, A. K.M.Sazzadur and Javed Mehedi Shamrat, F. M. and Tasnim, Zarrin and Roy, Joy and Hossain, Syed Akhter},
	year = {2019},
	keywords = {Classification, Supervised learning, Support Vector Machine, Random Forest, Regression, Machine Learning, Computational Intelligence, Decision Tree, K-Nearest Neighbors, Liver Disease, Naïve Bayes},
	pages = {419--422},
}

@article{thirunavukkarasu_prediction_2018,
	title = {Prediction of liver disease using classification {Algorithms}},
	doi = {10.1109/CCAA.2018.8777655},
	abstract = {The industry that are providing healthcare is producing a large amount of data. We know that Machine Learning algorithms can also be used to find hidden information for diagnosis and effective decision making. In recent years, Liver disorders have increased rapidly and it is considered to be a very fatal disease in many countries like - Egypt, Moldava etc. For this research paper, the main aim is to predict liver disease using different classification algorithms. The algorithms used for this purpose of work is Logistic Regression, K-Nearest Neighbour and Support Vector Machines. Accuracy score and confusion matrix is used to compare this classification algorithm.},
	number = {July 2020},
	journal = {2018 4th International Conference on Computing Communication and Automation, ICCCA 2018},
	author = {Thirunavukkarasu, K. and Singh, Ajay S. and Irfan, Md and Chowdhury, Abhishek},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538669471},
	keywords = {Machine Learning, K-Nearest Neighbour, Logistic Regression, Support Vector Machines Classifications},
	pages = {1--3},
}

@article{afrin_supervised_2021,
	title = {Supervised machine learning based liver disease prediction approach with {LASSO} feature selection},
	volume = {10},
	issn = {23029285},
	doi = {10.11591/eei.v10i6.3242},
	abstract = {In this contemporary era, the uses of machine learning techniques are increasing rapidly in the field of medical science for detecting various diseases such as liver disease (LD). Around the globe, a large number of people die because of this deadly disease. By diagnosing the disease in a primary stage, early treatment can be helpful to cure the patient. In this research paper, a method is proposed to diagnose the LD using supervised machine learning classification algorithms, namely logistic regression, decision tree, random forest, AdaBoost, KNN, linear discriminant analysis, gradient boosting and support vector machine (SVM). We also deployed a least absolute shrinkage and selection operator (LASSO) feature selection technique on our taken dataset to suggest the most highly correlated attributes of LD. The predictions with 10 fold cross-validation (CV) made by the algorithms are tested in terms of accuracy, sensitivity, precision and f1-score values to forecast the disease. It is observed that the decision tree algorithm has the best performance score where accuracy, precision, sensitivity and f1-score values are 94.295\%, 92\%, 99\% and 96\% respectively with the inclusion of LASSO. Furthermore, a comparison with recent studies is shown to prove the significance of the proposed system.},
	number = {6},
	journal = {Bulletin of Electrical Engineering and Informatics},
	author = {Afrin, Saima and Javed Mehedi Shamrat, F. M. and Nibir, Tafsirul Islam and Muntasim, Mst Fahmida and Moharram, Md Shakil and Imran, M. M. and Abdulla, Md},
	year = {2021},
	keywords = {Classification, Machine learning, 10 fold cross-validation, LASSO, Liver disease, Supervised algorithms},
	pages = {3369--3376},
}

@article{hatami_machine_2022,
	title = {Machine learning-based system for prediction of ascites grades in patients with liver cirrhosis using laboratory and clinical data: {Design} and implementation study},
	volume = {60},
	issn = {14374331},
	doi = {10.1515/cclm-2022-0454},
	abstract = {The aim of the study was to implement a non-invasive model to predict ascites grades among patients with cirrhosis. In the present study, we used modern machine learning (ML) methods to develop a scoring system solely based on routine laboratory and clinical data to help physicians accurately diagnose and predict different degrees of ascites. We used ANACONDA3-5.2.0 64 bit, free and open-source platform distribution of Python programming language with numerous modules, packages, and rich libraries that provide various methods for classification problems. Through the 10-fold cross-validation, we employed three common learning models on our dataset, k-nearest neighbors (KNN), support vector machine (SVM), and neural network classification algorithms. According to the data received from the research institute, three types of data analysis have been performed. The algorithms used to predict ascites were KNN, cross-validation (CV), and multilayer perceptron neural networks (MLPNN), which achieved an average accuracy of 94, 91, and 90\%, respectively. Also, in the average accuracy of the algorithms, KNN had the highest accuracy of 94\%. We applied well-known ML approaches to predict ascites. The findings showed a strong performance compared to the classical statistical approaches. This ML-based approach can help to avoid unnecessary risks and costs for patients with acute stages of the disease.},
	number = {12},
	journal = {Clinical Chemistry and Laboratory Medicine},
	author = {Hatami, Behzad and Asadi, Farkhondeh and Bayani, Azadeh and Zali, Mohammad Reza and Kavousi, Kaveh},
	year = {2022},
	pmid = {35607284},
	keywords = {machine learning, ascites, liver cirrhosis},
	pages = {1946--1954},
}

@article{keerthana_co_2020,
	title = {Co 3 {RD} {INTERNATIONAL} {CONFERENCE} {ON} {INNOVATIVE} {COMPUTING} {AND} {COMMUNICATION} ({ICICC}-2020) {A} {Prediction} {Model} of {Detecting} {Liver} {Diseases} in {Patients} using {Logistic} {Regression} of {Machine} {Learning}},
	url = {https://ssrn.com/abstract=3562951},
	abstract = {Liver Diseases are prevalent in India accounting for 2.4\% of Indian deaths per year [1]. According to the WHO, liver disease is one of the most common causes of death in India. Liver diseases have become a menacing threat in India with around 10 lakh patients being newly diagnosed with it every year. Liver disease owing to its subtle symptoms remains obscure and hence leading to an onerous diagnosis, often the symptoms become apparent when it is too late [2]. Therefore, an endeavour is made for the forecast of liver sickness in patients utilizing machine learning techniques. In this paper, we thus used the Machine Learning method of Logistic Regression to predict liver disease in patients.},
	author = {Keerthana, Psm and Phalinkar, Nimish and Mehere, Riya and Bhanu, Koppula and Reddy, Prakash and Lal, Nidhi},
	year = {2020},
	keywords = {Machine Learning, Logistic Regression, Confusion Matrix, Cross-Validation, Liver Diseases},
	pages = {1--5},
}

@article{mostafa_statistical_2021,
	title = {Statistical {Machine} {Learning} {Approaches} to {Liver} {Disease} {Prediction}},
	volume = {1},
	doi = {10.3390/livers1040023},
	abstract = {Medical diagnoses have important implications for improving patient care, research, and policy. For a medical diagnosis, health professionals use different kinds of pathological methods to make decisions on medical reports in terms of the patients’ medical conditions. Recently, clinicians have been actively engaged in improving medical diagnoses. The use of artificial intelligence and machine learning in combination with clinical findings has further improved disease detection. In the modern era, with the advantage of computers and technologies, one can collect data and visualize many hidden outcomes such as dealing with missing data in medical research. Statistical machine learning algorithms based on specific problems can assist one to make decisions. Machine learning (ML), data-driven algorithms can be utilized to validate existing methods and help researchers to make potential new decisions. The purpose of this study was to extract significant predictors for liver disease from the medical analysis of 615 humans using ML algorithms. Data visualizations were implemented to reveal significant findings such as missing values. Multiple imputations by chained equations (MICEs) were applied to generate missing data points, and principal component analysis (PCA) was used to reduce the dimensionality. Variable importance ranking using the Gini index was implemented to verify significant predictors obtained from the PCA. Training data (ntrain=399) for learning and testing data (ntest=216) in the ML methods were used for predicting classifications. The study compared binary classifier machine learning algorithms (i.e., artificial neural network, random forest (RF), and support vector machine), which were utilized on a published liver disease data set to classify individuals with liver diseases, which will allow health professionals to make a better diagnosis. The synthetic minority oversampling technique was applied to oversample the minority class to regulate overfitting problems. The RF significantly contributed (p{\textless}0.001) to a higher accuracy score of 98.14\% compared to the other methods. Thus, this suggests that ML methods predict liver disease by incorporating the risk factors, which may improve the inference-based diagnosis of patients.},
	number = {4},
	journal = {Livers},
	author = {Mostafa, Fahad and Hasan, Easin and Williamson, Morgan and Khan, Hafiz},
	year = {2021},
	pages = {294--312},
}

@article{anand_liver_2019,
	title = {Liver disease classification using deep learning algorithm},
	volume = {8},
	issn = {22783075},
	doi = {10.35940/ijitee.L2747.1081219},
	abstract = {Data Mining is one of the prevalent elucidating portions of programmed request and distinguishing proof. It involves data mining counts and strategies to examine helpful data. Of late, liver dissents have disproportionately expanded and liver infections are complimenting one of the most human pains in different countries. Early assurance of Liver Disorder is essential for the welfare of human culture. This complaint should be considered sincerely by setting up watchful structures for the early break down and expectation of Liver contaminations. The robotized gathering system suffers with non attendance of precision results when differentiated and cautious biopsy. We propose another model for liver issue request for separating the patient's helpful, data using ANN algorithm. The remedial records are organized whether there is a believability of essence of disorder or not. This proposed methodology uses extracted features using M-PSO and ANN for classifying the features. The ANN methodology improves the accuracy when appeared differently in relation to existing request computations. This paper focuses classification of selected features for classification.},
	number = {12},
	journal = {International Journal of Innovative Technology and Exploring Engineering},
	author = {Anand, L. and Neelanarayanan, Venkataraman},
	year = {2019},
	pages = {5105--5111},
}

@article{srivenkatesh_performance_2019,
	title = {Performance {Evolution} of {Different} {Machine} {Learning} {Algorithms} for {Prediction} of {Liver} {Disease}},
	volume = {9},
	doi = {10.35940/ijitee.l3619.129219},
	abstract = {Liver malady is an overall medical issue that is related with different inconveniences and high mortality. It is of basic significance that illness be recognized before such huge numbers of these lives can be spared. The phases of liver ailment are a significant viewpoint for focused treatment. It is a terribly troublesome undertaking for therapeutic analysts to foresee the disease inside the beginning times on account of sensitive manifestations. Generally the side effects become evident once it's past the point of no return. To beat this issue, we have liver infection forecast. Liver sickness might be distinguished with incalculable order systems, and these have been classified the utilization forecast of a number highlights and classifier blends. In this investigation, we applied five sort of classifiers that is Naïve Bayes, logistic regression, support vector machines, Random Forest, K Nearest Neighbour for the examination of liver malady. The classification exhibitions are assessed with 5 distinctive by and large execution measurements, i.e., precision, kappa, Mean absolute error (MAE), Root mean square error (RMSE), and F measures. The objective of this query work is to foresee liver infection with different machine learning and pick most efficient algorithm.},
	number = {2},
	journal = {International Journal of Innovative Technology and Exploring Engineering},
	author = {Srivenkatesh*, Dr. M.},
	year = {2019},
	keywords = {already been, hard to identify even, illness, in the beginning times, it is exceptionally, liver disease, machine learning algorithms, of liver, performance evaluators, though liver tissue has, toxins},
	pages = {1115--1122},
}

@article{tanwar_machine_2021,
	title = {Machine learning in liver disease diagnosis: {Current} progress and future opportunities},
	volume = {1022},
	issn = {1757899X},
	doi = {10.1088/1757-899X/1022/1/012029},
	abstract = {There has been a rapid growth in the use of automatic decision-making systems and tools in the medical domain. By using the concepts of big data, deep learning, and machine learning, these systems extract useful information from large medical datasets and help physicians in making accurate and timely decisions regarding predictions and diagnosis of diseases. In this regard, this study provides an extensive review of the progress of applying Artificial Intelligence in forecasting and detecting liver diseases and then summarizes related limitations of the studies followed by future research.},
	number = {1},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Tanwar, Neha and Rahman, Khandakar Faridar},
	year = {2021},
	keywords = {Deep Learning, Machine Learning, Liver Diseases, Data Mining},
}

@article{supriya_disease_2022,
	title = {Disease {Diagnosis} {Using} {Machine} {Learning}},
	volume = {21},
	issn = {00440477},
	doi = {10.37896/YMER21.05/86},
	abstract = {A diagnosis is made based on medical signs and patient-reported symptoms, rather than diagnostic tests. The whole program is done and executed in Python language mainly using file operations in Python and HTML for creating webpages. This project mainly deals with how the diagnosis is made by listing out all the symptoms faced by the patients from the given diseases on the website. This project gives you the list of seven diseases spread over our country according to the WHO (World Health Organization). The seven diseases are Heart, Diabetics, Breast Cancer, Liver, Kidney, Malaria, and Pneumonia. So based on the patient givens details under a particular disease, it finds out whether the patient is having the disease or not. If the person is suffering from that particular disease it shows that person is positive with that particular disease and shows a warning that the person should consult the doctor. We also created a user-based login page where the user can create his login page, thereby creating an account that person can fill in the details. If the person is registered then that person can log in directly. The health diagnosis website was designed by using web technology and languages such as HTML \& CSS and python respectively. *. If the person is not suffering from that particular disease and shows the result as great you are healthy….! * If a person is suffering from a particular disease then it shows the result as please consult the doctor…...!},
	number = {5},
	journal = {Ymer},
	author = {Supriya, Pastham and Chaitanya, Aeddalinti and Mounika, Addula and Niharika, Bommidi and Sabitha, B.},
	year = {2022},
	keywords = {liver disease, knn, random forest, svm},
	pages = {753--761},
}

@article{b_liver_2021,
	title = {Liver {Disease} {Prediction} {System} using {Machine} {Learning} {Techniques}},
	volume = {10},
	issn = {2278-0181},
	url = {www.ijert.org},
	abstract = {In this paper we are going discuss how to predict risk of liver disease for a person, based on the blood test report results of the user. In this paper, the risk of liver disease was predicted using various machine learning algorithms.The final output was predicted based on the most accurate machine learning algorithm.Based on the accurate model we designed a system which asks a person to enter the details of his/her blood test report. Then the system uses the most accurate model which is trained to predict, whether a person has risk of liver disease or not.},
	number = {6},
	journal = {International Journal of Engineering Research \& Technology},
	author = {B, Rakshith D and Srivastava, Mrigank and {Ashwani Kumar} and P, Gururaj S},
	year = {2021},
	keywords = {Machine learning, Liver disease, backpropagation algorithm, Confusion matrix, Use case diagram},
	pages = {949--952},
}

@article{al_telaq_prediction_2021,
	title = {Prediction of {Liver} {Disease} using {Machine} {Learning} {Models} with {PCA}},
	volume = {25},
	doi = {10.1109/ICDABI53623.2021.9655897},
	abstract = {The liver is one of the most vital organs of the human body. There are various disorders of liver that need early treatment by doctors. Early diagnosis and treating the patients are significant to reduce the risk. Healthcare system can benefit from various Machine Learning (ML) models to predict diseases in early stage. The aim of this study is to predict liver disease using different ML models applied on Indian Liver Patient Dataset (ILPD). The models used on this work are Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Random Forest (RF), Artificial Neural Network (ANN) and various versions of Ensemble Learning (EL). The results show that ensemble learning of KNN, RF, and SVM achieved the highest accuracy of 88\%. Moreover, ensemble learning of KNN with RF obtained the highest True Positive Rate (TPR) of 99\% on negative cases. In addition, this paper found that the Principal Component Analysis (PCA) technique has good impact to increase the accuracy.},
	number = {4},
	journal = {2021 International Conference on Data Analytics for Business and Industry, ICDABI 2021},
	author = {Al Telaq, Burair Hassan and Hewahi, Nabil},
	year = {2021},
	note = {ISBN: 9781665416566},
	keywords = {machine learning, liver disease, prediction},
	pages = {250--254},
}

@article{latha_c_m_prediction_2022,
	title = {Prediction of {Liver} {Disease} using {Machine} {Learning}},
	volume = {2},
	doi = {10.48175/ijarsct-5673},
	abstract = {Healthcare system is becoming a significant factor of every human being. So in this paper we are discussing about the vital organ of the human body i.e. Liver. Early analysis of liver disease prediction is highly challenging. As a result, liver disease has become more common which is gradually improved, enhancing people's troubles. To recognize the causes and the identification phases are more important. For this, we applied a machine learning technique that was highly promising for studies with regard to healthcare and health. To uncover hidden data for precise diagnosis and decision-making, ML can also be used. Any form of liver disease is hazardous to your health. Poisons, narcotics, and excessive drinking are the main causes of this condition. In this study, we will use several associated features and KNN technology to enhance liver disease prediction. The accuracy forecast is provided by this algorithm.},
	number = {1},
	journal = {International Journal of Advanced Research in Science, Communication and Technology},
	author = {{Latha C M}},
	year = {2022},
	keywords = {machine learning, liver disease, ilpd, k-nearest neighbor},
	pages = {234--241},
}

@article{ghosh_comparative_2021,
	title = {A comparative analysis of machine learning algorithms to predict liver disease},
	volume = {30},
	issn = {2326005X},
	doi = {10.32604/iasc.2021.017989},
	abstract = {The liver is considered an essential organ in the human body. Liver disorders have risen globally at an unprecedented pace due to unhealthy lifestyles and excessive alcohol consumption. Chronic liver disease is one of the principal causes of death affecting large portions of the global population. An accumulation of liver-damaging factors deteriorates this condition. Obesity, an undiagnosed hepatitis infection, alcohol abuse, coughing or vomiting blood, kidney or hepatic failure, jaundice, liver encephalopathy, and many more disorders are responsible for it. Thus, immediate intervention is needed to diagnose the ailment before it is too late. Therefore, this work aims to evaluate several machine learning algorithm outputs, namely logistic regression, random forest, XGBoost, support vector machine (SVM), AdaBoost, K-NN, and decision tree for predicting and diagnos-ing chronic liver disease. The classification algorithms are evaluated based on various measurement criteria, such as accuracy, precision, recall, F1 score, an area under the curve (AUC), and specificity. Among the algorithms, the random forest algorithm showed better performance in liver disease prediction with an accuracy of 83.70\%. Furthermore, the random forest algorithm also showed better preci-sion, F1, recall, and AUC metrics. Hence, random forest is considered the best algorithm for early liver disease prediction.},
	number = {3},
	journal = {Intelligent Automation and Soft Computing},
	author = {Ghosh, Mounita and Raihan, Md Mohsin Sarker and Raihan, M. and Akter, Laboni and Bairagi, Anupam Kumar and Alshamrani, Sultan S. and Masud, Mehedi},
	year = {2021},
	keywords = {Classification, Machine learning, Random forest, Logistic regression, Liver disease, Prediction},
	pages = {917--928},
}

@article{priya_m_b_juliet_p_l__tamilselvi_performance_2018,
	title = {Performance {Analysis} of {Liver} {Disease} {Prediction} {Using} {Machine} {Learning} {Algorithms}},
	volume = {5},
	issn = {2395-0056},
	url = {www.irjet.net},
	abstract = {Data Mining is one of the most critical aspects of automated disease diagnosis and disease prediction. It involves data mining algorithms and techniques to analyze medical data. In recent years, liver disorders have excessively increased and liver diseases are becoming one of the most fatal diseases in several countries. In this thesis, liver patient datasets are investigate for building classification models in order to predict liver disease. This thesis implemented a feature model construction and comparative analysis for improving prediction accuracy of Indian liver patients in three phases. In first phase, min max normalization algorithm is applied on the original liver patient datasets collected from UCI repository. In liver dataset prediction second phase, by the use of PSO feature selection, subset (data) of liver patient dataset from whole normalized liver patient datasets is obtained which comprises only significant attributes. Third phase, classification algorithms are applied on the data set. In the fourth phase, the accuracy will be calculated using root mean Square value, root mean error value.J48 algorithm is considered as the better performance algorithm after applying PSO feature selection. Finally, the evaluation is done based on accuracy values. Thus outputs shows from proposed classification implementations indicate that J48 algorithm performances all other classification algorithm with the help of feature selection with an accuracy of 95.04\%.},
	number = {1},
	journal = {International Research Journal of Engineering and Technology (IRJET)},
	author = {Priya, M. B., Juliet, P. L., \& Tamilselvi, P. R.},
	year = {2018},
	keywords = {Classification, Random Forest, SVM, Bayesian Network, J48, MLP},
	pages = {206--211},
}

@article{thirunavukkarasu_prediction_2018-1,
	title = {Prediction of liver disease using classification {Algorithms}},
	volume = {6},
	doi = {10.1109/CCAA.2018.8777655},
	abstract = {The industry that are providing healthcare is producing a large amount of data. We know that Machine Learning algorithms can also be used to find hidden information for diagnosis and effective decision making. In recent years, Liver disorders have increased rapidly and it is considered to be a very fatal disease in many countries like - Egypt, Moldava etc. For this research paper, the main aim is to predict liver disease using different classification algorithms. The algorithms used for this purpose of work is Logistic Regression, K-Nearest Neighbour and Support Vector Machines. Accuracy score and confusion matrix is used to compare this classification algorithm.},
	number = {9},
	journal = {2018 4th International Conference on Computing Communication and Automation, ICCCA 2018},
	author = {Thirunavukkarasu, K. and Singh, Ajay S. and Irfan, Md and Chowdhury, Abhishek},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538669471},
	keywords = {Machine Learning, K-Nearest Neighbour, Logistic Regression, Support Vector Machines Classifications},
	pages = {1--3},
}

@article{doo_prediction_nodate,
	title = {Prediction of liver disorders using machine learning algorithms: a comparative study},
	author = {Doo, Revhuylqj and Wkhvh, R I and Ru, Grfwruv and Ghflgh, Sudfwlwlrqhuv and Gldjqrvlv, Glvhdvh and Wuhdwphqwv, D Q G and Grqh, Ehhq and Pdfklqh, Xvlqj and Dqg, Ohduqlqj and Plqlqj, Gdwd and Wkh, Pdnh and Gliilfxow, Suhglfwlrq and Uhprydo, W K H and Uhgxqgdqw, R I and Ryhuvdpsolqj, Ihdwxuhv and Xvhg, L V and Wkh, Plwljdwh and Fodvv, Lpedodqfhg and Sureohp, Glvwulexwlrq and Wkh, Lqfuhdvh and Ri, Shuirupdqfh and Fodvvlilfdwlrq, Hdfk and Uhodwhg, Suhvhqwv and Grqh, Zrunv and Wkh, L Q and Ghwdlohg, Suhvhqwv D and Sdshu, Frqfoxghv W K H and Rujdq, Ylvfhudo and Yhuwheudwhv, R I and Fdq, Wkdw and Lwvhoi, Uhjhqhudwh and Idwdo, Vhyhudo and Vxfk, Glvhdvhv and Idvflroldvlv, D V and Khsdwlwlv, Fluukrvlv},
	note = {ISBN: 9780738123233},
	pages = {111--116},
}

@article{li_forecasting_2023,
	title = {Forecasting the lithium mineral resources prices in {China}: {Evidence} with {Facebook} {Prophet} ({Fb}-{P}) and {Artificial} {Neural} {Networks} ({ANN}) methods},
	volume = {82},
	issn = {03014207},
	url = {https://doi.org/10.1016/j.resourpol.2023.103580},
	doi = {10.1016/j.resourpol.2023.103580},
	abstract = {Combining lithium real-time series data with recently developed advanced Artificial Neural Networks (ANN) and Facebook Prophet (Fb-P) algorithms is of particular relevance for identifying and delivering policy-insightful patterns by learning from experimental data without being pre-conditioned and managing investment risk. The prime objective of this study is to forecast lithium mineral resource prices in China. This study uses the Fb-P and ANN techniques to estimate lithium prices utilizing daily historical data between 5 November 2018 and 1 November 2022. In doing so, the empirical estimates help to predict future prices until 20 April 2023. The findings of the Facebook Prophet technique demonstrate that lithium mineral pricing has a very high degree of accuracy and has a long short-term memory at differential frequency days intervals. In contrast to the current price of 572,500 yuan/tonne, it may have been noticed that the market would suddenly surge in the next six months, reaching more than 800000 yuan/tonne. The study attempts to draw novel implications in the context of mineral resource prices in China.},
	number = {April},
	journal = {Resources Policy},
	author = {Li, Xiaobin and Sengupta, Tuhin and Si Mohammed, Kamel and Jamaani, Fouad},
	year = {2023},
	note = {Publisher: Elsevier Ltd},
	keywords = {Forecasting, Machine learning, ANN, China, Lithium price, Mineral resources},
	pages = {103580},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\SV4P5VSD\\1-s2.0-S030142072300291X-main.pdf:application/pdf},
}

@article{hu_vaccine_2023,
	title = {Vaccine supply chain management: {An} intelligent system utilizing blockchain, {IoT} and machine learning},
	volume = {156},
	issn = {01482963},
	url = {https://doi.org/10.1016/j.jbusres.2022.113480},
	doi = {10.1016/j.jbusres.2022.113480},
	abstract = {Vaccination offers health, economic, and social benefits. However, three major issues—vaccine quality, demand forecasting, and trust among stakeholders—persist in the vaccine supply chain (VSC), leading to inefficiencies. The COVID-19 pandemic has exacerbated weaknesses in the VSC, while presenting opportunities to apply digital technologies to manage it. For the first time, this study establishes an intelligent VSC management system that provides decision support for VSC management during the COVID-19 pandemic. The system combines blockchain, internet of things (IoT), and machine learning that effectively address the three issues in the VSC. The transparency of blockchain ensures trust among stakeholders. The real-time monitoring of vaccine status by the IoT ensures vaccine quality. Machine learning predicts vaccine demand and conducts sentiment analysis on vaccine reviews to help companies improve vaccine quality. The present study also reveals the implications for the management of supply chains, businesses, and government.},
	number = {December 2022},
	journal = {Journal of Business Research},
	author = {Hu, Hui and Xu, Jiajun and Liu, Mengqi and Lim, Ming K.},
	year = {2023},
	note = {Publisher: Elsevier Inc.},
	keywords = {Machine learning, Blockchain, COVID-19 pandemic, Intelligent system, Internet of things, Vaccine supply chain},
	pages = {113480},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\EHEV54EI\\1-s2.0-S0148296322009456-main.pdf:application/pdf},
}

@article{mehmood_egd-snet_2022,
	title = {{EGD}-{SNet}: {A} computational search engine for predicting an end-to-end machine learning pipeline for {Energy} {Generation} \& {Demand} {Forecasting}},
	volume = {324},
	issn = {03062619},
	url = {https://doi.org/10.1016/j.apenergy.2022.119754},
	doi = {10.1016/j.apenergy.2022.119754},
	abstract = {Load forecasting avoids energy wastage by accurately estimating the future quantity of energy generation and demand. Existing load forecasting approaches do not utilize the potential of feature selection and dimensionality reduction approaches that remove irrelevant/redundant features and improve the performance of machine learning (ML) regressors. This research presents an end-to-end framework named Energy Generation and Demand forecasting Search Net (EGD-SNet) capable of predicting energy generation, demand and temperature in multiple regions. EGD-SNet framework contains 13 different feature selection and 11 dimensionality reduction algorithms along with 10 most widely used ML regressors. It makes use of Particle Swarm Optimizer (PSO) to smartly train regressors by finding optimal hyperparameters. Further, it has potential to design an end to end pipeline by finding appropriate combination of regressor and feature selection or dimensionality reduction approaches for precisely predicting energy generation or demand for a particular regional data based on the characteristics of data. EGD-SNet as web service is accessible here. http://111.68.102.19:8000/},
	number = {March},
	journal = {Applied Energy},
	author = {Mehmood, Faiza and Ghani, Muhammad Usman and Ghafoor, Hina and Shahzadi, Rehab and Asim, Muhammad Nabeel and Mahmood, Waqar},
	year = {2022},
	note = {Publisher: Elsevier Ltd},
	keywords = {Feature selection, Machine learning, Dimensionality reduction, Computational methodologies, Load forecasting},
	pages = {119754},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\FPGZQ8YT\\1-s2.0-S0306261922010388-main.pdf:application/pdf},
}

@article{bassiouni_advanced_2023,
	title = {Advanced deep learning approaches to predict supply chain risks under {COVID}-19 restrictions},
	volume = {211},
	issn = {09574174},
	url = {https://doi.org/10.1016/j.eswa.2022.118604},
	doi = {10.1016/j.eswa.2022.118604},
	abstract = {The ongoing COVID-19 pandemic has created an unprecedented predicament for global supply chains (SCs). Shipments of essential and life-saving products, ranging from pharmaceuticals, agriculture, and healthcare, to manufacturing, have been significantly impacted or delayed, making the global SCs vulnerable. A better understanding of the shipment risks can substantially reduce that nervousness. Thenceforth, this paper proposes a few Deep Learning (DL) approaches to mitigate shipment risks by predicting ”if a shipment can be exported from one source to another”, despite the restrictions imposed by the COVID-19 pandemic. The proposed DL methodologies have four main stages: data capturing, de-noising or pre-processing, feature extraction, and classification. The feature extraction stage depends on two main variants of DL models. The first variant involves three recurrent neural networks (RNN) structures (i.e., long short-term memory (LSTM), Bidirectional long short-term memory (BiLSTM), and gated recurrent unit (GRU)), and the second variant is the temporal convolutional network (TCN). In terms of the classification stage, six different classifiers are applied to test the entire methodology. These classifiers are SoftMax, random trees (RT), random forest (RF), k-nearest neighbor (KNN), artificial neural network (ANN), and support vector machine (SVM). The performance of the proposed DL models is evaluated based on an online dataset (taken as a case study). The numerical results show that one of the proposed models (i.e., TCN) is about 100\% accurate in predicting the risk of shipment to a particular destination under COVID-19 restrictions. Unarguably, the aftermath of this work will help the decision-makers to predict supply chain risks proactively to increase the resiliency of the SCs.},
	number = {August 2022},
	journal = {Expert Systems with Applications},
	author = {Bassiouni, Mahmoud M. and Chakrabortty, Ripon K. and Hussain, Omar K. and Rahman, Humyun Fuad},
	year = {2023},
	note = {Publisher: Elsevier Ltd},
	keywords = {Deep learning, COVID-19, Classifiers, Convolutional network, Supply chain risk, Temporal convolutional network},
	pages = {118604},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\6UFYWXNZ\\1-s2.0-S0957417422016566-main.pdf:application/pdf},
}

@article{migueis_reducing_2022,
	title = {Reducing fresh fish waste while ensuring availability: {Demand} forecast using censored data and machine learning},
	volume = {359},
	issn = {09596526},
	doi = {10.1016/j.jclepro.2022.131852},
	abstract = {Food waste reduction represents a potential opportunity to enhance environmental sustainability. This is especially important in fresh products such as fresh seafood, where waste levels are substantially higher than those of other food products. In this particular case, reducing waste is also vital to meet demand while conserving fisheries. This paper aims to promote more sustainable supply chains by proposing daily fresh fish demand forecasting models that can be used by grocery retailers to align supply and demand, and hence prevent the production of food waste. To accomplish this goal, we explored the potential of different machine learning models, namely Long Short-Term Memory networks, Feedforward neural networks, Support Vector Regression, and Random Forests, as well as a Holt-Winters statistical model. Demand censorship was considered to capture real demand. To validate the proposed methodology, we estimated the demand for fresh fish in a representative store of a large European retailing company used as a case study. The results revealed that the machine learning models provided accurate forecasts in comparison to the baseline models and the statistical model, with the Long Short-Term Memory networks model yielding, in general, the best results in terms of root mean squared error (27.82), mean absolute error (20.63) and mean positive error (17.86). Thus, the implementation of these types of models can thus have a positive impact on the sustainability of fresh fish species and customer satisfaction.},
	number = {March},
	journal = {Journal of Cleaner Production},
	author = {Miguéis, Vera Lucia and Pereira, André and Pereira, João and Figueira, Gonçalo},
	year = {2022},
	keywords = {Machine learning, Demand forecasting, Censored demand, Food waste, Time series forecasting},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\STUUIEYX\\1-s2.0-S0959652622014627-main.pdf:application/pdf},
}

@article{haider_deep_2022,
	title = {Deep learning and statistical methods for short- and long-term solar irradiance forecasting for {Islamabad}},
	volume = {198},
	issn = {18790682},
	url = {https://doi.org/10.1016/j.renene.2022.07.136},
	doi = {10.1016/j.renene.2022.07.136},
	abstract = {The growing threat of global climate change stemming from the huge carbon footprint left behind by fossil fuels has prompted interest in exploring and utilizing renewable energy resources. Several statistical, Machine and Deep Learning techniques exist and have been used for many years for a range of forecasting problems. This study is based on the data recorded for 4 years and 9 months using precise instruments, in Islamabad, Pakistan. For this purpose we use statistical and Deep Learning architectures for forecasting solar Global Horizontal Irradiance which not only helps in grid management and power distribution, but also brings attention towards the potential of solar power production in Pakistan and its part to play in tackling global climate change. We have used statistical methods such as Seasonal Auto-Regressive Integrated Moving Average Exogenous (SARIMAX) and Prophet, and Machine Learning methods such as Long Short-Term Memory (LSTM) which is an extension of Recurrent Neural Networks (RNN), Convolutional Neural Network (CNN) and Artificial Neural Network (ANN). The selected forecast methods in our study are based on their ability to work with time series data and we have used different models configurations to see which performs best for our dataset. The performance of every model is studied using different error metrics such as Coefficient of Determination (R2), Mean Absolute Error (MAE), Mean Square Error (MSE), and Root Mean Square Error (RMSE). The major contribution of this study is the data collected to carry out research towards the goal of renewable energy future, and from the test methods used on the data in this study, it can be intuitively determined that ANN, CNN, and LSTM architectures perform best for short-term forecasts, while SARIMAX and Prophet are efficient for long-term forecasts.},
	number = {February},
	journal = {Renewable Energy},
	author = {Haider, Syed Altan and Sajid, Muhammad and Sajid, Hassan and Uddin, Emad and Ayaz, Yasar},
	year = {2022},
	note = {Publisher: Elsevier Ltd},
	keywords = {Forecasting, Deep learning, Convolutional neural network, Long short term memory, Recurrent neural network, Solar irradiance},
	pages = {51--60},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\QLTJQZ7A\\1-s2.0-S0960148122011387-main.pdf:application/pdf},
}

@article{shukla_stockout_2022,
	title = {Stockout {Prediction} in {Multi} {Echelon} {Supply} {Chain} using {Machine} {Learning} {Algorithms}},
	abstract = {The main objective of a supply chain is to fulfil the customer demands in the right quantity at the right time. If an organization cannot meet the customer demand, stockout or out-of-stock situations happen. Inventory stockouts are costly to the organization and are very common in supply chains. It not only results in the loss of revenue but also affects the service level, which results in a loss of competitive advantage. Stockouts can be prevented by proper inventory planning and control. For any organization, it is crucial to maintain optimum inventory levels to ensure customer satisfaction. These days, technologies like Artificial Intelligence and Machine Learning give organizations the ability to foresee the future and proactively manage their inventory in the supply chain. This study investigates various supervised machine learning classifiers. It proposes the best machine learning stock out prediction model for each member of a four-stage divergent supply chain with eight members. Since the dataset for such a supply chain is not available, a supply chain operation simulation has been conducted under three distinct inventory replenishing policies such as Order-Up-To (OUT), Order-Up-To Smoothing (OUTS) and (s, S). Data generated from the simulation is divided into two sets, the train set and the test set. Various supervised machine learning algorithms are trained using training dataset. A five-fold cross-validation technique is adopted for the validation of the model. A random search cross-validation technique adjusts the hyperparameters of each classifier. The performance of the model is evaluated on the test dataset based on the assessment matrices, and it is found that boosting algorithms perform better than the other classifiers. This study proposes a meta-learning-based stacked ensemble model, using XG boost, Ada boost and random forest classifiers as the base model. The performance evaluation shows that for each supply chain member, the stacked ensemble model performs better than other classifiers, including boosting classifiers.},
	journal = {Proceedings of the 2nd Indian International Conference on Industrial Engineering and Operations Management Warangal, Telangana, India},
	author = {Shukla, Saurav and Pillai, V Madhusudanan},
	year = {2022},
	keywords = {Supply Chain, Inventory Policy, Machine Learning Algorithms and Simulation, Stockout Prediction},
	pages = {1258--1270},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\NB65VDLG\\368.pdf:application/pdf},
}

@article{singha_application_2022,
	title = {Application of different {Machine} {Learning} models for {Supply} {Chain} {Demand} {Forecasting}: {Comparative} {Analysis}},
	volume = {2},
	doi = {10.1109/ICIPTM54933.2022.9753864},
	abstract = {Demand is defined as the propensity or willingness of customers to pay a certain amount of price for a product or service they desire. Business entities use various forecasting techniques to anticipate customer demands in advance to make crucial strategic decisions related to various aspects of the supply chain, such as customer service level, inventory management, manufacturing planning, and control, etc. But the error related to forecasting models creates uncertainty and poses a great challenge to decision-makers. With the ever-changing market dynamics, it is becoming more and more important for businesses to minimize those forecasting errors. In this paper, we have analysed the application of various advanced Machine Learning algorithms like Multi-layered Perceptron model (MLP), Convolution Neural Network (CNN), Long-Short Term Memory (LSTM) Networks, etc. in Time Series Forecasting, thereafter, performed a comparative analysis to understand which of them yields the better result. To perform the analysis, we have considered the 'Store Item Demand Forecasting' dataset available at Kaggle.},
	journal = {Proceedings of 2nd International Conference on Innovative Practices in Technology and Management, ICIPTM 2022},
	author = {Singha, D. and Panse, Chetan},
	year = {2022},
	note = {ISBN: 9781665466431
Publisher: IEEE},
	keywords = {Supply chain, Neural networks, Machine learning, Demand forecasting, Time series model},
	pages = {312--318},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\VWFPFVWZ\\Application_of_different_Machine_Learning_models_for_Supply_Chain_Demand_Forecasting_Comparative_Analysis.pdf:application/pdf},
}

@article{vithitsoontorn_demand_2022,
	title = {Demand {Forecasting} in {Production} {Planning} for {Dairy} {Products} {Using} {Machine} {Learning} and {Statistical} {Method}},
	doi = {10.1109/iEECON53204.2022.9741683},
	abstract = {Demand forecasting is an essential task of every industry. Efficient forecasting relieves the excessive stock and out-of-stock problem, reducing revenue loss. This research performs a direct multistep forecast approach of demand forecasting on 8 dairy products of 5 different dairy production plants with 5-year data. Widely used traditional statistical method and the stage of the art deep learning method for sequence problems are picked. ARIMA and LSTM. The models are compared in many aspects, monthly observations against weekly observations, univariate against multivariate, and statistical against deep learning using model error and business metrics. The result shows that both statistical and deep learning method are reliable and are suitable to be used in demand forecasting. There is no single best optimization algorithm. ARIMAs predict the future in an average straight line. It shows the best result on few wavering series, whereas LSTMs predict the future value follow the seasonal of series. It beats ARIMAs on strong trend series. Training the model on monthly observations provide better error score.},
	number = {1},
	journal = {Proceedings of the 2022 International Electrical Engineering Congress, iEECON 2022},
	author = {Vithitsoontorn, Chayuth and Chongstitvatana, Prabhas},
	year = {2022},
	note = {ISBN: 9781665402064
Publisher: IEEE},
	keywords = {Demand Forecasting, Deep Learning, Autoregressive Integrated Moving Average (ARIMA), Long Short-Term Memory (LSTM), Time Series Data},
	pages = {1--4},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\CMMI2SZR\\Demand_Forecasting_in_Production_Planning_for_Dairy_Products_Using_Machine_Learning_and_Statistical_Method.pdf:application/pdf},
}

@article{ribeiro_short-and_2022,
	title = {Short-and {Very} {Short}-{Term} {Firm}-{Level} {Load} {Forecasting} for {Warehouses}: {A} {Comparison} of {Machine} {Learning} and {Deep} {Learning} {Models}},
	volume = {15},
	issn = {19961073},
	url = {https://www.mdpi.com/1996-1073/15/3/750},
	doi = {10.3390/en15030750},
	abstract = {Commercial buildings are a significant consumer of energy worldwide. Logistics facilities, and specifically warehouses, are a common building type which remain under-researched in the demand-side energy forecasting literature. Warehouses have an idiosyncratic profile when compared to other commercial and industrial buildings with a significant reliance on a small number of energy systems. As such, warehouse owners and operators are increasingly entering energy performance contracts with energy service companies (ESCOs) to minimise environmental impact, reduce costs, and improve competitiveness. ESCOs and warehouse owners and operators require accurate forecasts of their energy consumption so that precautionary and mitigation measures can be taken. This paper explores the performance of three machine learning models (Support Vector Regression (SVR), Random Forest, and Extreme Gradient Boosting (XGBoost)), three deep learning models (Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU)), and a classical time series model, Autoregressive Integrated Moving Average (ARIMA) for predicting daily energy consumption. The dataset comprises 8040 records generated over an 11-month period from January to November 2020 from a non-refrigerated logistics facility located in Ireland. The grid search method was used to identify the best configurations for each model. The proposed XGBoost models outperformed other models for both very short-term load forecasting (VSTLF) and short-term load forecasting (STLF); the ARIMA model performed the worst.},
	number = {3},
	journal = {Energies},
	author = {Ribeiro, Andrea Maria N.C. and Do Carmo, Pedro Rafael X. and Endo, Patricia Takako and Rosati, Pierangelo and Lynn, Theo},
	year = {2022},
	keywords = {Machine learning, Deep learning, Random Forest, ARIMA, LSTM, Energy consumption, Extreme Gradient Boosting, GRU, RNN, Short-term load forecasting, STLF, SVR, Time series prediction, Very short-term load forecasting, VSTLF},
	pages = {750},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\AC4GFKXV\\energies-15-00750-v2.pdf:application/pdf},
}

@article{zheng_federated_2023,
	title = {Federated machine learning for privacy preserving, collective supply chain risk prediction},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2022.2164628},
	doi = {10.1080/00207543.2022.2164628},
	abstract = {The use of Artificial Intelligence (AI) for predicting supply chain risk has gained popularity. However, proposed approaches are based on the premise that organisations act alone, rather than a collective when predicting risk, despite the interconnected nature of supply chains. This yields a problem: organisations that have inadequate datasets cannot predict risk. While data-sharing has been proposed to evaluate risk, in practice this does not happen due to privacy concerns. We propose a federated learning approach for collective risk prediction without the risk of data exposure. We ask: Can organisations who have inadequate datasets tap into collective knowledge? This raises a second question: Under what circumstances would collective risk prediction be beneficial? We present an empirical case study where buyers predict order delays from their shared suppliers before and after Covid-19. Results show that federated learning can indeed help supply chain members predict risk effectively, especially for buyers with limited datasets. Training data-imbalance, disruptions, and algorithm choice are significant factors in the efficacy of this approach. Interestingly, data-sharing or collective risk prediction is not always the best choice for buyers with disproportionately larger order-books. We thus call for further research on on local and collective learning paradigms in supply chains. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor \& Francis Group.},
	journal = {International Journal of Production Research},
	author = {Zheng, Ge and Kong, Lingxuan and Brintrup, Alexandra},
	year = {2023},
	keywords = {Supply chain, machine learning, artificial, artificial intelligence, federated, federated learning, intelligence, learning, machine, privacy preserving, risk, supply chain},
	pages = {1--18},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\BU4RVXDG\\Federated machine learning for privacy preserving collective supply chain risk prediction.pdf:application/pdf},
}

@article{ben_elmir_smart_2023,
	title = {Smart {Platform} for {Data} {Blood} {Bank} {Management}: {Forecasting} {Demand} in {Blood} {Supply} {Chain} {Using} {Machine} {Learning}},
	volume = {14},
	issn = {20782489},
	doi = {10.3390/info14010031},
	abstract = {Despite the efforts of the World Health Organization, blood transfusions and delivery are still the crucial challenges in blood supply chain management, especially when there is a high demand and not enough blood inventory. Consequently, reducing uncertainty in blood demand, waste, and shortages has become a primary goal. In this paper, we propose a smart platform-oriented approach that will create a robust blood demand and supply chain able to achieve the goals of reducing uncertainty in blood demand by forecasting blood collection/demand, and reducing blood wastage and shortage by balancing blood collection and distribution based on an effective blood inventory management. We use machine learning and time series forecasting models to develop an AI/ML decision support system. It is an effective tool with three main modules that directly and indirectly impact all phases of the blood supply chain: (i) the blood demand forecasting module is designed to forecast blood demand; (ii) blood donor classification helps predict daily unbooked donors thereby enhancing the ability to control the volume of blood collected based on the results of blood demand forecasting; and (iii) scheduling blood donation appointments according to the expected number and type of blood donations, thus improving the quantity of blood by reducing the number of canceled appointments, and indirectly improving the quality and quantity of blood supply by decreasing the number of unqualified donors, thereby reducing the amount of invalid blood after and before preparation. As a result of the system's improvements, blood shortages and waste can be reduced. The proposed solution provides robust and accurate predictions and identifies important clinical predictors for blood demand forecasting. Compared with the past year's historical data, our integrated proposed system increased collected blood volume by 11\%, decreased inventory wastage by 20\%, and had a low incidence of shortages.},
	number = {1},
	journal = {Information (Switzerland)},
	author = {Ben Elmir, Walid and Hemmak, Allaoua and Senouci, Benaoumeur},
	year = {2023},
	keywords = {machine learning algorithms, blood bank management, blood supply chain, time series forecasting models},
	pages = {1--24},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\AS8PG7ZJ\\information-14-00031-v2.pdf:application/pdf},
}

@article{nithin_retail_2022,
	title = {Retail {Demand} {Forecasting} using {CNN}-{LSTM} {Model}},
	doi = {10.1109/ICEARS53579.2022.9752283},
	abstract = {This paper proposes a deep learning model to predict the stock that would be required by a store in a particular period with the help of historic information such as past sales. This task could help a business to run smoothly and make sound decisions but are very hard to predict accurately. A CNN-LSTM (Convolutional Neural Network-Long Short-Term Memory Network) model is proposed to forecast retail demand. This model equips the Swish Activation Function. This works better than the traditional and most successful activation function ReLU (Rectified Linear Unit). Data from 10 stores each consisting of 50 items are taken as input. This proposed work has implemented various other models such as Multilayer Perceptron, Long Short-Term Memory cells, Convolutional Neural Networks to predict sales. The experiment results suggest using CNN-LSTM Model as it has considerably lower RMSE (Root Mean-Squared Error).},
	number = {Icears},
	journal = {Proceedings of the International Conference on Electronics and Renewable Systems, ICEARS 2022},
	author = {Nithin, Soundar S.J. and Rajasekar, T. and Jayanthy, S. and Karthik, K. and Rithick, Roshan R.},
	year = {2022},
	note = {ISBN: 9781665484251
Publisher: IEEE},
	keywords = {Demand Forecasting, Convolutional Neural Networks (CNN), Long Short-Term Memory Cells (LSTM), Multilayer Perceptron, Neural Networks, ReLU Activation Function, Swish Activation Function, Tensor Flow},
	pages = {1751--1756},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\5GSNE4YZ\\Retail_Demand_Forecasting_using_CNN-LSTM_Model.pdf:application/pdf},
}

@article{rathipriya_demand_2023,
	title = {Demand forecasting model for time-series pharmaceutical data using shallow and deep neural network model},
	volume = {35},
	issn = {14333058},
	url = {https://doi.org/10.1007/s00521-022-07889-9},
	doi = {10.1007/s00521-022-07889-9},
	abstract = {Demand forecasting is a scientific and methodical assessment of future demand for a critical product.The effective Demand Forecast Model (DFM) enables pharmaceutical companies to be successful in the global market. The purpose of this research paper is to validate various shallow and deep neural network methods for demand forecasting, with the aim of recommending sales and marketing strategies based on the trend/seasonal effects of eight different groups of pharmaceutical products with different characteristics. The root mean squared error (RMSE) is used as the predictive accuracy of DFMs. This study also found that the mean RMSE value of the shallow neural network-based DFMs was 6.27 for all drug categories, which was lower than deep neural network models. According to the findings, DFMs based on shallow neural networks can effectively estimate future demand for pharmaceutical products.},
	number = {2},
	journal = {Neural Computing and Applications},
	author = {Rathipriya, R. and Abdul Rahman, Abdul Aziz and Dhamodharavadhani, S. and Meero, Abdelrhman and Yoganandan, G.},
	year = {2023},
	note = {ISBN: 0123456789
Publisher: Springer London},
	keywords = {Demand forecasting, Deep learning models, Pharmaceuticalindustry, Shallow neural network models},
	pages = {1945--1957},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\P8L2RPTH\\s00521-022-07889-9.pdf:application/pdf},
}

@article{chaudhuri_hybrid_2022,
	title = {A hybrid extreme learning machine model with harris hawks optimisation algorithm: an optimised model for product demand forecasting applications},
	volume = {52},
	issn = {15737497},
	url = {https://doi.org/10.1007/s10489-022-03251-7},
	doi = {10.1007/s10489-022-03251-7},
	abstract = {Accurate and real-time product demand forecasting is the need of the hour in the world of supply chain management. Predicting future product demand from historical sales data is a highly non-linear problem, subject to various external and environmental factors. In this work, we propose an optimised forecasting model - an extreme learning machine (ELM) model coupled with the Harris Hawks optimisation (HHO) algorithm to forecast product demand in an e-commerce company. ELM is preferred over traditional neural networks mainly due to its fast computational speed, which allows efficient demand forecasting in real-time. Our ELM-HHO model performed significantly better than ARIMA models that are commonly used in industries to forecast product demand. The performance of the proposed ELM-HHO model was also compared with traditional ELM, ELM auto-tuned using Bayesian Optimisation (ELM-BO), Gated Recurrent Unit (GRU) based recurrent neural network and Long Short Term Memory (LSTM) recurrent neural network models. Different performance metrics, i.e., Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE) and Mean Percentage Error (MPE) were used for the comparison of the selected models. Horizon forecasting at 3 days and 7 days ahead was also performed using the proposed approach. The results revealed that the proposed approach is superior to traditional product demand forecasting models in terms of prediction accuracy and it can be applied in real-time to predict future product demand based on the previous week's sales data. In particular, considering RMSE of forecasting, the proposed ELM-HHO model performed 62.73\% better than the statistical ARIMA(7,1,0) model, 40.73\% better than the neural network based GRU model, 34.05\% better than the neural network based LSTM model, 27.16\% better than the traditional non-optimised ELM model with 100 hidden nodes and 11.63\% better than the ELM-BO model in forecasting product demand for future 3 months. The novelty of the proposed approach lies in the way the fast computational speed of ELMs has been combined with the accuracy gained by tuning hyperparameters using HHO. An increased number of hyperparameters has been optimised in our methodology compared to available models. The majority of approaches to improve the accuracy of ELM so far have only focused on tuning the weights and the biases of the hidden layer. In our hybrid model, we tune the number of hidden nodes, the number of input time lags and even the type of activation function used in the hidden layer in addition to tuning the weights and the biases. This has resulted in a significant increase in accuracy over previous methods. Our work presents an original way of performing product demand forecasting in real-time in industry with highly accurate results which are much better than pre-existing demand forecasting models.},
	number = {10},
	journal = {Applied Intelligence},
	author = {Chaudhuri, Koushiki Dasgupta and Alkan, Bugra},
	year = {2022},
	note = {ISBN: 0123456789
Publisher: Springer US},
	keywords = {Supply chain management, Artificial neural networks, Demand forecasting, ARIMA, Extreme learning machines, Harris hawks optimisation, Hyperparameter tuning, Optimisation},
	pages = {11489--11505},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\CJ8ZT7AC\\s10489-022-03251-7.pdf:application/pdf},
}

@article{hamdan_machine_2023,
	title = {Machine learning in supply chain: prediction of real-time e-order arrivals using {ANFIS}},
	volume = {14},
	issn = {09764348},
	url = {https://doi.org/10.1007/s13198-022-01851-7},
	doi = {10.1007/s13198-022-01851-7},
	abstract = {Accurate demand forecasting throughout the multi-channel supply chain (SC) enhances the managers' decision-making capability in operational, tactical, and strategic aspects. However, the problem is that earlier publications about the real-time prediction of e-commerce order arrivals in the SC show some inadequacies. According to a systematic review from Tsolaki (ICT Express, 2022. https://doi.org/10.1016/j.icte.2022.02.001) who integrate logistics and machine learning (ML) methods in the past ten years, there are very few studies that focus on arrival time prediction like this study does, and none of them uses an adaptive neuro-fuzzy inference system (ANFIS) framework to predict e-order arrivals. Besides, (Policarpo in Comput Sci Rev 41:100414, 2021) review the existing publications that integrate e-commerce and ML techniques in the past five years; they reveal that previous studies pay heavier attentions to e-commerce initiative goals such as purchase and repurchase predictions, and none of them focuses on predicting e-order arrivals like this study does. Previous scholars investigate SC orders and prediction issues in a broader space, while this study attempts to predict hour-to-hour, actual-time order arrivals. Thus, this study presents a new data-empowered forecasting method to fill these research gaps. The motivation of this study is to build a method for predicting real-time e-orders arrivals in distribution hubs, enabling third-party logistics providers to handle the hourly-based e-order arrival rates more efficiently. This study tries to find the solution for the problem by developing a new ML forecasting method by integrating time-series data features and ANFIS, which has been proven to significantly reduce the issues' computational complexity. This study creates a four-phase operation model to enable managers to adopt the suggested framework, and develops a systematized forecasting model to cross-confirm the framework's outcomes. This study employs a descriptive case study and shows a satisfactory degree of precision of the suggested ML method in predicting the actual e-order arrivals in three e-retailers at three-hour cycle times. The findings reveal that the real-time forecasting is significant to boost the values of e-order arrivals in every day business operations. The novelty of this study lies on its novel contribution and purpose to build a method for predicting real-time e-orders arrivals in distribution hubs, enabling third-party logistics providers to handle the hourly-based e-order arrival rates more efficiently; and to develop a new ML forecasting method by integrating ANFIS and time-series data features.},
	number = {s1},
	journal = {International Journal of System Assurance Engineering and Management},
	author = {Hamdan, Ihab K.A. and Aziguli, Wulamu and Zhang, Dezheng and Sumarliah, Eli},
	year = {2023},
	note = {ISBN: 0123456789
Publisher: Springer India},
	keywords = {Supply chain management, Machine learning, E-commerce, Real-time demand prediction, Third-party logistics},
	pages = {549--568},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\G4MCUIT2\\s13198-022-01851-7.pdf:application/pdf},
}

@article{zohdi_demand_2022,
	title = {Demand forecasting based machine learning algorithms on customer information: an applied approach},
	volume = {14},
	issn = {25112112},
	url = {https://doi.org/10.1007/s41870-022-00875-3},
	doi = {10.1007/s41870-022-00875-3},
	abstract = {Demand forecasting has always been a concern for business owners as one of the main activities in supply chain management. Unlike the past, that forecasting was done with the help of a limited amount of information, today, using advanced technologies and data analytics, forecasting is performed with machine learning algorithms and data-driven methods. Patterns and trends of demand, customer information, preferences, suggestions, and post-consumption feedbacks are some types of data that are used in various demand forecasting efforts. Traditional statistical methods and techniques are biased in demand prediction and are not accurate; so, machine learning algorithms as more popular techniques have been replaced in recent researches in the literature. Until the time of conducting this research, extreme learning machine has not been used for intermittent demand prediction, so the novelty of our research is to adopt this algorithm and also other machine learning algorithms such as K-nearest neighbors, decision tree, gradient boosting, and multi-layer perceptron to examine its accuracy and performance in comparison to other approaches. Finally, it is demonstrated that artificial neural network-based methods outperform the other employed techniques through conducting a comparison among the above-mentioned predictors in terms of mean squared error, mean absolute error, coefficient of determination, and computational time. Furthermore, extreme learning machine is the best or at least among the best predictors. At last, for determining whether the obtained results are statistically significant or not, analysis of variance is conducted and the Kolmogorov–Smirnov technique is adopted to test the normality of outcomes.},
	number = {4},
	journal = {International Journal of Information Technology (Singapore)},
	author = {Zohdi, Maryam and Rafiee, Majid and Kayvanfar, Vahid and Salamiraad, Amirhossein},
	year = {2022},
	note = {ISBN: 4187002200
Publisher: Springer Singapore},
	keywords = {Supply chain management, Machine learning algorithms, Demand forecasting, Big data analytics, Customer information},
	pages = {1937--1947},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\QHFQR57D\\s41870-022-00875-3.pdf:application/pdf},
}

@article{li_comparative_2022,
	title = {A {Comparative} {Study} of {Demand} {Forecasting} {Models} for a {Multi}-{Channel} {Retail} {Company}: {A} {Novel} {Hybrid} {Machine} {Learning} {Approach}},
	volume = {14},
	issn = {14333058},
	url = {https://doi.org/10.1007/s43069-022-00166-4 https://doi.org/10.1007/s41870-022-00875-3 https://doi.org/10.1007/s13198-022-01851-7 https://doi.org/10.1007/s10489-022-03251-7 https://doi.org/10.1007/s00521-022-07889-9 https://doi.org/10.1080/00207543.2022.21},
	doi = {10.1080/00207543.2022.2164628},
	abstract = {Demand forecasting has been a major concern of operational strategy to manage the inventory and optimize the customer satisfaction level. The researchers have proposed many conventional and advanced forecasting techniques, but no one leads to complete accuracy. Forecasting is equally important in manufacturing as well as retail companies. In this study, the performances of five regression techniques of machine learning, viz. random forest (RF), extreme gradient boosting (XGBoost), gradient boosting, adaptive boosting (AdaBoost), and artificial neural network (ANN) algorithms, are compared with a proposed hybrid (RF-XGBoost-LR) model for sales forecasting of a retail chain considering the various parameters of forecasting accuracy. The weekly sales data of a US-based retail company is considered in the analysis of the forecasts undertaking the attributes affecting the sale such as the temperature of the region and the size of the store. It is observed that the hybrid RF-XGBoost-LR outperformed the other models measured against various metrics of performance. This study may help the industry decision-maker to understand and improve the methods of forecasting.},
	number = {1},
	journal = {International Journal of Production Research},
	author = {Li, Xiaobin and Sengupta, Tuhin and Si Mohammed, Kamel and Jamaani, Fouad and Hu, Hui and Xu, Jiajun and Liu, Mengqi and Lim, Ming K. and Mehmood, Faiza and Ghani, Muhammad Usman and Ghafoor, Hina and Shahzadi, Rehab and Asim, Muhammad Nabeel and Mahmood, Waqar and Bassiouni, Mahmoud M. and Chakrabortty, Ripon K. and Hussain, Omar K. and Rahman, Humyun Fuad and Miguéis, Vera Lucia and Pereira, André and Pereira, João and Figueira, Gonçalo and Haider, Syed Altan and Sajid, Muhammad and Sajid, Hassan and Uddin, Emad and Ayaz, Yasar and Singha, D. and Panse, Chetan and Vithitsoontorn, Chayuth and Chongstitvatana, Prabhas and Ribeiro, Andrea Maria N C and Rafael, Pedro and Carmo, X and Endo, Patricia Takako and Rosati, Pierangelo and Lynn, Theo and Zheng, Ge and Kong, Lingxuan and Brintrup, Alexandra and Ben Elmir, Walid and Hemmak, Allaoua and Senouci, Benaoumeur and Nithin, Soundar S.J. and Rajasekar, T. and Jayanthy, S. and Karthik, K. and Rithick, Roshan R. and Rathipriya, R. and Abdul Rahman, Abdul Aziz and Dhamodharavadhani, S. and Meero, Abdelrhman and Yoganandan, G. and Chaudhuri, Koushiki Dasgupta and Alkan, Bugra and Hamdan, Ihab K.A. and Aziguli, Wulamu and Zhang, Dezheng and Sumarliah, Eli and Zohdi, Maryam and Rafiee, Majid and Kayvanfar, Vahid and Salamiraad, Amirhossein and Mitra, Arnab and Jain, Arnav and Kishore, Avinash and Kumar, Pravin and Sandhya, Pasala and Bandi, Raswitha and Himabindu, D. Dakshayani},
	year = {2022},
	note = {ISBN: 0123456789
Publisher: IEEE},
	keywords = {Supply chain, Supply chain management, Forecasting, Neural networks, Feature selection, Machine learning, Machine learning algorithms, machine learning, Deep learning, Artificial neural networks, Demand forecasting, Demand Forecasting, Random Forest, ARIMA, XGBoost, Dimensionality reduction, Blockchain, LSTM, Random forest, Big data analytics, deep learning, COVID-19, Deep Learning, machine learning algorithms, ANN, China, Lithium price, Mineral resources, COVID-19 pandemic, Intelligent system, Internet of things, Vaccine supply chain, Computational methodologies, Load forecasting, Classifiers, Convolutional network, Supply chain risk, Temporal convolutional network, Censored demand, Food waste, Time series forecasting, Convolutional neural network, Long short term memory, Recurrent neural network, Solar irradiance, Time series model, Autoregressive Integrated Moving Average (ARIMA), Long Short-Term Memory (LSTM), Time Series Data, Extreme Gradient Boosting, GRU, RNN, STLF, SVR, VSTLF, artificial, artificial intelligence, federated, federated learning, intelligence, learning, machine, privacy preserving, risk, supply chain, blood bank management, blood supply chain, time series forecasting models, Convolutional Neural Networks (CNN), Long Short-Term Memory Cells (LSTM), Multilayer Perceptron, Neural Networks, ReLU Activation Function, Swish Activation Function, Tensor Flow, Deep learning models, Pharmaceuticalindustry, Shallow neural network models, Extreme learning machines, Harris hawks optimisation, Hyperparameter tuning, Optimisation, E-commerce, Real-time demand prediction, Third-party logistics, Customer information, AdaBoost, an output layer, Close price, energy consumption, gate forget, Gradient boosting, hidden layer, input gate, input layer, long shorter-term memory, output gate, recurring neural networks, short-term load forecasting, sigmoid gate, Statistical methods, time series prediction, very short-term load forecasting},
	pages = {11489--11505},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\387YGESX\\Demand_Forecasting_in_Production_Planning_for_Dairy_Products_Using_Machine_Learning_and_Statistical_Method.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\RUCLCIZC\\Application_of_different_Machine_Learning_models_for_Supply_Chain_Demand_Forecasting_Comparative_Analysis.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\6H4QREVZ\\1-s2.0-S030142072300291X-main.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\CVKXFAMB\\1-s2.0-S0960148122011387-main.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\QL32NY7T\\1-s2.0-S0959652622014627-main.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\Y57DG8ID\\1-s2.0-S0148296322009456-main.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\D44RERYM\\1-s2.0-S0957417422016566-main.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\FDGMP7ZD\\1-s2.0-S0306261922010388-main.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\VCLATKWG\\energies-15-00750-v2.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\G774B9S2\\Federated machine learning for privacy preserving collective supply chain risk prediction.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\SF4AP6K8\\s41870-022-00875-3.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\6MK2SDCN\\Stock_Price_Prediction_using_Recurrent_Neural_Network_and_LSTM.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\Q39V6SNE\\s43069-022-00166-4.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\9MBPYBPT\\s13198-022-01851-7.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\LGF7Z9CY\\s10489-022-03251-7.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\EM437LHK\\information-14-00031-v2.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\S8RZ7Q4J\\s00521-022-07889-9.pdf:application/pdf;Attachment:C\:\\Users\\abrar\\Zotero\\storage\\B8ERYLY6\\Retail_Demand_Forecasting_using_CNN-LSTM_Model.pdf:application/pdf},
}

@article{sandhya_stock_2022,
	title = {Stock {Price} {Prediction} using {Recurrent} {Neural} {Network} and {LSTM}},
	doi = {10.1109/ICCMC53470.2022.9753764},
	abstract = {Predicting stock prices is a tough task simulated to anticipate stock returns by machine learning. A range of approaches and techniques are used for stock market forecasting. The stock market is considered quite active and advanced. A precise estimate of future pricing could give investors an increased profit margin. According to the estimates, investors can select equities to produce a higher return. Various approaches to machine learning have been used in stock markets over the years. Still, deep learning models, which have shown superior to prior machine learning methods as far as predictive accuracy and speed are concerned, are being used with the growing data and wish for forecasts. In this research, a common deeper study model for stock market prediction, the Long-Short Memory (LSTM) recurring neural network has been utilized. In this task, Python modules are used to automatically download historical market data to forecast future stock prices by fitting an LSTM model to data.},
	number = {Iccmc},
	journal = {Proceedings - 6th International Conference on Computing Methodologies and Communication, ICCMC 2022},
	author = {Sandhya, Pasala and Bandi, Raswitha and Himabindu, D. Dakshayani},
	year = {2022},
	note = {ISBN: 9781665410281
Publisher: IEEE},
	keywords = {an output layer, Close price, gate forget, hidden layer, input gate, input layer, long shorter-term memory, output gate, recurring neural networks, sigmoid gate},
	pages = {1723--1728},
	file = {Attachment:C\:\\Users\\abrar\\Zotero\\storage\\Y4CF8IJW\\Stock_Price_Prediction_using_Recurrent_Neural_Network_and_LSTM.pdf:application/pdf},
}

@article{nimmy_explainability_2022,
	title = {Explainability in supply chain operational risk management: {A} systematic literature review},
	volume = {235},
	issn = {0950-7051},
	shorttitle = {Explainability in supply chain operational risk management},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705121008492},
	doi = {10.1016/j.knosys.2021.107587},
	abstract = {It is important to manage operational disruptions to ensure the success of supply chain operations. To achieve this aim, researchers have developed techniques that determine the occurrence of operational risk events which assists supply chain operational risk managers develop plans to manage them by detection/monitoring, mitigation/management, or optimization techniques. Various artificial intelligence (AI) approaches have been used to develop such techniques in the broad activities of operational risk management. However, all of these techniques are black box in their working nature. This means that the chosen technique cannot explain why it has given that output and whether it is correct and free from bias. To address this, researchers argue the need for supply chain management professionals to move towards using explainable AI methods for operational risk management. In this paper, we conduct a systematic literature review on the techniques used to determine operational risks and analyse whether they satisfy the requirement of them being explainable. The findings highlight the shortcomings and inspires directions for future research. From a managerial perspective, the paper encourages risk managers to choose techniques for supply chain operational risk management that can be auditable as this will ensure that the risk managers know why they should take a particular risk management action rather than just what they should do to manage the operational risks.},
	language = {en},
	urldate = {2023-06-12},
	journal = {Knowledge-Based Systems},
	author = {Nimmy, Sonia Farhana and Hussain, Omar K. and Chakrabortty, Ripon K. and Hussain, Farookh Khadeer and Saberi, Morteza},
	month = jan,
	year = {2022},
	keywords = {Big data, Artificial Intelligence (AI), Explainable AI (XAI), Supply chain operational risk management (SCORM)},
	pages = {107587},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\HT3GM9J4\\Nimmy et al. - 2022 - Explainability in supply chain operational risk ma.pdf:application/pdf},
}

@inproceedings{azizsafaei_critical_2021,
	address = {Cham},
	series = {Advanced {Sciences} and {Technologies} for {Security} {Applications}},
	title = {A {Critical} {Overview} of {Food} {Supply} {Chain} {Risk} {Management}},
	isbn = {978-3-030-68534-8},
	doi = {10.1007/978-3-030-68534-8_26},
	abstract = {Due to the increasing occurrence of disruptive events caused by both human and also natural disasters, supply chain risk management has become an emerging research field in recent years, aiming to protect supply chains from various disruptions and deliver sustainable and long-term benefits to stakeholders across the value chain. Implementing optimum designed risk-oriented supply chain management can provide a privileged position for various businesses to extend their global reach. In addition, using a proactive supply chain risk management system, enterprises can predict their potential risk factors in their supply chains, and achieve the best early warning time, which leads to higher firms’ performance. However, relatively little is known about sustainable risks in food supply chains. In order to manage the ever-growing challenges of food supply chains effectively, a deeper insight regarding the complex food systems is required. Supply chain risk management embraces broad strategies to address, identify, evaluate, monitor, and control unpredictable risks or events with direct and indirect effect, mostly negative, on food supply chain processes. To fill this gap, in this paper we have critically discussed the related supply chain risk management literature. Finally, we propose a number of significant directions for future research.},
	language = {en},
	booktitle = {Cybersecurity, {Privacy} and {Freedom} {Protection} in the {Connected} {World}},
	publisher = {Springer International Publishing},
	author = {Azizsafaei, Maryam and Sarwar, Dilshad and Fassam, Liam and Khandan, Rasoul and Hosseinian-Far, Amin},
	editor = {Jahankhani, Hamid and Jamal, Arshad and Lawson, Shaun},
	year = {2021},
	keywords = {Supply chain risk, Food supply chain risk, Risk assessment, Sustainable development},
	pages = {413--429},
}

@article{tang_perspectives_2006,
	title = {Perspectives in supply chain risk management},
	volume = {103},
	issn = {0925-5273},
	url = {https://www.sciencedirect.com/science/article/pii/S0925527306000405},
	doi = {10.1016/j.ijpe.2005.12.006},
	abstract = {To gain cost advantage and market share, many firms implemented various initiatives such as outsourced manufacturing and product variety. These initiatives are effective in a stable environment, but they could make a supply chain more vulnerable to various types of disruptions caused by uncertain economic cycles, consumer demands, and natural and man-made disasters. In this paper, we review various quantitative models for managing supply chain risks. We also relate various supply chain risk management (SCRM) strategies examined in the research literature with actual practices. The intent of this paper is three-fold. First, we develop a unified framework for classifying SCRM articles. Second, we hope this review can serve as a practical guide for some researchers to navigate through the sea of research articles in this important area. Third, by highlighting the gap between theory and practice, we hope to motivate researchers to develop new models for mitigating supply chain disruptions.},
	language = {en},
	number = {2},
	urldate = {2023-06-12},
	journal = {International Journal of Production Economics},
	author = {Tang, Christopher S.},
	month = oct,
	year = {2006},
	keywords = {Review, Quantitative models, Supply chain risk management},
	pages = {451--488},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\KJFHHMCZ\\Tang - 2006 - Perspectives in supply chain risk management.pdf:application/pdf},
}

@article{schroeder_systematic_2021,
	title = {A {Systematic} {Investigation} of the {Integration} of {Machine} {Learning} into {Supply} {Chain} {Risk} {Management}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2305-6290},
	url = {https://www.mdpi.com/2305-6290/5/3/62},
	doi = {10.3390/logistics5030062},
	abstract = {The main objective of the paper is to analyze and synthesize existing scientific literature related to supply chain areas where machine learning (ML) has already been implemented within the supply chain risk management (SCRM) field, both in theory and in practice. Furthermore, we analyzed which risks were addressed in the use cases as well as how ML might shape SCRM. For this purpose, we conducted a systematic literature review. The results showed that the applied examples relate primarily to the early identification of production, transport, and supply risks in order to counteract potential supply chain problems quickly. Through the analyzed case studies, we were able to identify the added value that ML integration can bring to the SCRM (e.g., the integration of new data sources such as social media or weather data). From the systematic literature analysis results, we developed four propositions, which can be used as motivation for further research.},
	language = {en},
	number = {3},
	urldate = {2023-06-12},
	journal = {Logistics},
	author = {Schroeder, Meike and Lodemann, Sebastian},
	month = sep,
	year = {2021},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {machine learning, supply chain, cases, propositions, supply chain risk management},
	pages = {62},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\WX7RDGAY\\Schroeder and Lodemann - 2021 - A Systematic Investigation of the Integration of M.pdf:application/pdf},
}

@article{li_developing_2023,
	title = {Developing capabilities for supply chain resilience in a post-{COVID} world: {A} machine learning-based thematic analysis},
	volume = {0},
	issn = {2472-5854},
	shorttitle = {Developing capabilities for supply chain resilience in a post-{COVID} world},
	url = {https://doi.org/10.1080/24725854.2023.2176951},
	doi = {10.1080/24725854.2023.2176951},
	abstract = {This study examines the past, present, and future of Supply Chain Resilience (SCR) research in the context of COVID-19. Specifically, a total of 1717 papers in the SCR field are classified into 11 thematic clusters, which are subsequently verified by a supervised machine learning approach. Each cluster is then analyzed within the context of COVID-19, leading to the identification of three associated capabilities (i.e., interconnectedness, transformability, and sharing) on which firms should focus to build a more resilient supply chain in the post-COVID world. The derived insights offer invaluable guidance not only for practicing managers, but also for scholars as they design their future research projects related to SCR for greatest impact.},
	number = {0},
	urldate = {2023-06-12},
	journal = {IISE Transactions},
	author = {Li, Dun and Zhi, Bangdong and Schoenherr, Tobias and Wang, Xiaojun},
	month = feb,
	year = {2023},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/24725854.2023.2176951},
	keywords = {Supply chain resilience, literature review, post-COVID world, supervised machine learning, thematic analysis},
	pages = {1--21},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\BIMR9ZMK\\Li et al. - 2023 - Developing capabilities for supply chain resilienc.pdf:application/pdf},
}

@article{baryannis_supply_2019,
	title = {Supply chain risk management and artificial intelligence: state of the art and future research directions},
	volume = {57},
	issn = {0020-7543},
	shorttitle = {Supply chain risk management and artificial intelligence},
	url = {https://doi.org/10.1080/00207543.2018.1530476},
	doi = {10.1080/00207543.2018.1530476},
	abstract = {Supply chain risk management (SCRM) encompasses a wide variety of strategies aiming to identify, assess, mitigate and monitor unexpected events or conditions which might have an impact, mostly adverse, on any part of a supply chain. SCRM strategies often depend on rapid and adaptive decision-making based on potentially large, multidimensional data sources. These characteristics make SCRM a suitable application area for artificial intelligence (AI) techniques. The aim of this paper is to provide a comprehensive review of supply chain literature that addresses problems relevant to SCRM using approaches that fall within the AI spectrum. To that end, an investigation is conducted on the various definitions and classifications of supply chain risk and related notions such as uncertainty. Then, a mapping study is performed to categorise existing literature according to the AI methodology used, ranging from mathematical programming to Machine Learning and Big Data Analytics, and the specific SCRM task they address (identification, assessment or response). Finally, a comprehensive analysis of each category is provided to identify missing aspects and unexplored areas and propose directions for future research at the confluence of SCRM and AI.},
	number = {7},
	urldate = {2023-06-12},
	journal = {International Journal of Production Research},
	author = {Baryannis, George and Validi, Sahar and Dani, Samir and Antoniou, Grigoris},
	month = apr,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2018.1530476},
	keywords = {artificial intelligence, supply chain risk management, decision-making, SCRM strategy, supply chain disruption},
	pages = {2179--2202},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\XNAGY5XC\\Baryannis et al. - 2019 - Supply chain risk management and artificial intell.pdf:application/pdf},
}

@article{naz_is_2022,
	title = {Is artificial intelligence an enabler of supply chain resiliency post {COVID}-19? {An} exploratory state-of-the-art review for future research},
	volume = {15},
	issn = {1936-9743},
	shorttitle = {Is artificial intelligence an enabler of supply chain resiliency post {COVID}-19?},
	url = {https://doi.org/10.1007/s12063-021-00208-w},
	doi = {10.1007/s12063-021-00208-w},
	abstract = {The challenging situations and disruptions that occurred due to the outbreak of the COVID-19 pandemic have created a severe need for supply chain resiliency (SCR). There has been a growing interest among researchers to investigate the resiliency in supply chain operations to overcome risks and disruptions and to achieve successful project management. The supply chain of every business requires innovative projects to accomplish competitive advantage in the market. This study was conducted to identify the significance of artificial intelligence (AI) for creating a sustainable and resilient supply chain, and also to provide optimum solutions for supply chain risk mitigation. A systematic literature review has been conducted to examine the potential research contribution or directions in the field of AI and SCR. In total, 162 articles were shortlisted from the SCOPUS database in the chosen field of research. Structural Topic Modeling (STM), a big data-based approach, was employed to generate several thematic topics of AI in SCR based on the shortlisted articles, and all topics were discussed. Furthermore, the bibliometric analysis was conducted using R-package to investigate the research trends in the area of AI in SCR. Based on the conducted review of literature, a research framework was proposed for AI in SCR that will facilitate researchers and practitioners to improve technological development in supply chain firms. The purpose is to combat sudden risks and disruptions so that project management will perform well Post COVID-19. The study will be also helpful for future researchers and practitioners to identify research directions based on existing literature covered in this paper in the field of SCR. Future research directions are proposed for AI-enabled resilient supply chain management. This study will also provide several implications for supply chain managers to achieve the required resilience in their supply chains post COVID-19 by focusing on the elements of the proposed research framework.},
	language = {en},
	number = {1},
	urldate = {2023-06-12},
	journal = {Operations Management Research},
	author = {Naz, Farheen and Kumar, Anil and Majumdar, Abhijit and Agrawal, Rohit},
	month = jun,
	year = {2022},
	keywords = {Supply chain, Artificial intelligence, Big data analytics, COVID-19, Project management, Resiliency, STM, Text mining},
	pages = {378--398},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\G8C9RGLR\\Naz et al. - 2022 - Is artificial intelligence an enabler of supply ch.pdf:application/pdf},
}

@article{shi_machine_2022,
	title = {Machine learning-driven credit risk: a systemic review},
	volume = {34},
	issn = {1433-3058},
	shorttitle = {Machine learning-driven credit risk},
	url = {https://doi.org/10.1007/s00521-022-07472-2},
	doi = {10.1007/s00521-022-07472-2},
	abstract = {Credit risk assessment is at the core of modern economies. Traditionally, it is measured by statistical methods and manual auditing. Recent advances in financial artificial intelligence stemmed from a new wave of machine learning (ML)-driven credit risk models that gained tremendous attention from both industry and academia. In this paper, we systematically review a series of major research contributions (76 papers) over the past eight years using statistical, machine learning and deep learning techniques to address the problems of credit risk. Specifically, we propose a novel classification methodology for ML-driven credit risk algorithms and their performance ranking using public datasets. We further discuss the challenges including data imbalance, dataset inconsistency, model transparency, and inadequate utilization of deep learning models. The results of our review show that: 1) most deep learning models outperform classic machine learning and statistical algorithms in credit risk estimation, and 2) ensemble methods provide higher accuracy compared with single models. Finally, we present summary tables in terms of datasets and proposed models.},
	language = {en},
	number = {17},
	urldate = {2023-06-12},
	journal = {Neural Computing and Applications},
	author = {Shi, Si and Tse, Rita and Luo, Wuman and D’Addona, Stefano and Pau, Giovanni},
	month = sep,
	year = {2022},
	keywords = {Machine learning, Deep learning, Credit risk, Statistical learning},
	pages = {14327--14339},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\MEHKZMM5\\Shi et al. - 2022 - Machine learning-driven credit risk a systemic re.pdf:application/pdf},
}

@article{ni_systematic_2020,
	title = {A systematic review of the research trends of machine learning in supply chain management},
	volume = {11},
	issn = {1868-808X},
	url = {https://doi.org/10.1007/s13042-019-01050-0},
	doi = {10.1007/s13042-019-01050-0},
	abstract = {Research interests in machine learning (ML) and supply chain management (SCM) have yielded an enormous amount of publications during the last two decades. However, in the literature, there was no systematic examination on the research development in the discipline of ML application, in particular in SCM. Therefore, this study was carried out to present the latest research trends in the discipline by analyzing the publications between 1998/01/01 and 2018/12/31 in five major databases. The quantitative analysis of 123 shortlisted articles showed that ML applications in SCM were still in a developmental stage since there were not enough high-yielding authors to form a strong group force in the research of ML applications in SCM and their publications were still at a low level; even though 10 ML algorithms were found to be frequently used in SCM, the use of these algorithms were unevenly distributed across the SCM activities most frequently reported in the articles of the literature. The aim of this study is to provide a comprehensive view of ML applications in SCM, working as a reference for future research directions for SCM researchers and application insight for SCM practitioners.},
	language = {en},
	number = {7},
	urldate = {2023-06-12},
	journal = {International Journal of Machine Learning and Cybernetics},
	author = {Ni, Du and Xiao, Zhi and Lim, Ming K.},
	month = jul,
	year = {2020},
	keywords = {Supply chain management, Machine learning, Algorithms, Application, Research trends},
	pages = {1463--1482},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\F5RJN9V4\\Ni et al. - 2020 - A systematic review of the research trends of mach.pdf:application/pdf},
}

@article{yang_supply_2023,
	title = {Supply chain risk management with machine learning technology: {A} literature review and future research directions},
	volume = {175},
	issn = {0360-8352},
	shorttitle = {Supply chain risk management with machine learning technology},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835222008476},
	doi = {10.1016/j.cie.2022.108859},
	abstract = {Coronavirus disease 2019 (COVID-19) has placed tremendous pressure on supply chain risk management (SCRM) worldwide. Recent technological advances, especially machine learning (ML) technology, have shown the possibility to prevent supply chain risk (SCR) by decreasing the need for human labor, increasing response speed, and predicting risk. However, the literature lacks a comprehensive analysis of the relationship between ML and SCRM. This work conducts a comprehensive review of the relatively limited literature in this field. An analysis of 67 shortlisted articles from 9 databases shows that this area is still in the rapid development stage and that researchers have shown extraordinary interest in it. The main purpose of this study is to review the current research status so that researchers have a clear understanding of the research gaps in this area. Moreover, this study provides an opportunity for researchers and practitioners to pay attention to ML algorithms for SCRM during the COVID-19 pandemic.},
	language = {en},
	urldate = {2023-06-12},
	journal = {Computers \& Industrial Engineering},
	author = {Yang, Mei and Lim, Ming K. and Qu, Yingchi and Ni, Du and Xiao, Zhi},
	month = jan,
	year = {2023},
	keywords = {Machine learning, COVID-19, Algorithm, Supply chain risk management, Research status},
	pages = {108859},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\ZKD7C9BJ\\Yang et al. - 2023 - Supply chain risk management with machine learning.pdf:application/pdf},
}

@article{deiva_ganesh_future_2022,
	title = {Future of artificial intelligence and its influence on supply chain risk management – {A} systematic review},
	volume = {169},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835222002765},
	doi = {10.1016/j.cie.2022.108206},
	abstract = {Supply Chain Risk Management (SCRM) is a rapidly growing field of research encompassing identification, assessment, mitigation, and monitoring of the risks or unexpected and unprecedented events. Among the researchers, there has been a significant focus on identifying, mitigating, and managing the risks that affect the supply chain (SC). Though the research on SCRM remains for an extended period, still the industries are facing difficulties in managing the SC risks. Also, the SC managers have begun to focus on decision-making based on numerous data sources for predicting the uncertainties more accurately to achieve a proactive and predictive intelligent risk management mechanism. These attributes make Artificial Intelligence (AI) and Machine learning (ML) suitable techniques in the SCRM field. The application of these techniques in SCRM is in a nascent stage. In this view, this paper presents a systematic and descriptive review of the literature and identifies the various AI and ML methods applied in different phases related to SCRM. Also, it investigates the different categories of SC risks and the existing articles based on the AI technique used. This analysis focuses on research articles related to SCRM from three scientific databases published between 2010 and 2021 for detailed study. Finally, this review provides unexplored and missing aspects in current research, challenges on implementing AI technologies, and describes promising avenues for the future.},
	language = {en},
	urldate = {2023-06-12},
	journal = {Computers \& Industrial Engineering},
	author = {Deiva Ganesh, A. and Kalpana, P.},
	month = jul,
	year = {2022},
	keywords = {Risk management, Machine learning, Artificial intelligence, Proactive decision-making},
	pages = {108206},
}

@article{al-zogbi_autonomous_2021,
	title = {Autonomous {Robotic} {Point}-of-{Care} {Ultrasound} {Imaging} for {Monitoring} of {COVID}-19–{Induced} {Pulmonary} {Diseases}},
	volume = {8},
	issn = {2296-9144},
	url = {https://www.frontiersin.org/articles/10.3389/frobt.2021.645756},
	abstract = {The COVID-19 pandemic has emerged as a serious global health crisis, with the predominant morbidity and mortality linked to pulmonary involvement. Point-of-Care ultrasound (POCUS) scanning, becoming one of the primary determinative methods for its diagnosis and staging, requires, however, close contact of healthcare workers with patients, therefore increasing the risk of infection. This work thus proposes an autonomous robotic solution that enables POCUS scanning of COVID-19 patients’ lungs for diagnosis and staging. An algorithm was developed for approximating the optimal position of an ultrasound probe on a patient from prior CT scans to reach predefined lung infiltrates. In the absence of prior CT scans, a deep learning method was developed for predicting 3D landmark positions of a human ribcage given a torso surface model. The landmarks, combined with the surface model, are subsequently used for estimating optimal ultrasound probe position on the patient for imaging infiltrates. These algorithms, combined with a force–displacement profile collection methodology, enabled the system to successfully image all points of interest in a simulated experimental setup with an average accuracy of 20.6 ± 14.7 mm using prior CT scans, and 19.8 ± 16.9 mm using only ribcage landmark estimation. A study on a full torso ultrasound phantom showed that autonomously acquired ultrasound images were 100\% interpretable when using force feedback with prior CT and 88\% with landmark estimation, compared to 75 and 58\% without force feedback, respectively. This demonstrates the preliminary feasibility of the system, and its potential for offering a solution to help mitigate the spread of COVID-19 in vulnerable environments.},
	urldate = {2023-06-13},
	journal = {Frontiers in Robotics and AI},
	author = {Al-Zogbi, Lidia and Singh, Vivek and Teixeira, Brian and Ahuja, Avani and Bagherzadeh, Pooyan Sahbaee and Kapoor, Ankur and Saeidi, Hamed and Fleiter, Thorsten and Krieger, Axel},
	year = {2021},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\UATGZIPY\\Al-Zogbi et al. - 2021 - Autonomous Robotic Point-of-Care Ultrasound Imagin.pdf:application/pdf},
}

@inproceedings{almeida_lung_2020,
	title = {Lung ultrasound for point-of-care {COVID}-19 pneumonia stratification: computer-aided diagnostics in a smartphone. {First} experiences classifying semiology from public datasets},
	shorttitle = {Lung ultrasound for point-of-care {COVID}-19 pneumonia stratification},
	doi = {10.1109/IUS46767.2020.9251716},
	abstract = {Lung ultrasound (LUS) has demonstrated potential in managing pneumonia patients, and is actively used at the point-of-care in COVID-19 patient stratification. However, image interpretation is presently both time-consuming and operator-dependent. We explore computer-aided diagnostics of pneumonia semiology based on light-weight neural networks (MobileNets). For proof-of-concept, multi-task learning is performed from online available COVID-19 datasets, for which semiology (overall abnormality, B-lines, consolidations and pleural thickening) is annotated by two radiologists. Initial results suggest that individual indications can be classified with good performance in a smartphone. Neural networks may also help to reduce inter-reader variability and objectivize LUS interpretation, especially for early-stage pathological indications.},
	booktitle = {2020 {IEEE} {International} {Ultrasonics} {Symposium} ({IUS})},
	author = {Almeida, Aitor and Bilbao, Aritz and Ruby, Lisa and Rominger, Marga B and López-De-Ipiña, Diego and Dahl, Jeremy and ElKaffas, Ahmed and Sanabria, Sergio J},
	month = sep,
	year = {2020},
	note = {ISSN: 1948-5727},
	keywords = {Neural networks, Training, convolutional neural network, COVID-19, B-lines, Lung, lung ultrasound (LUS), MobileNets, pneumonia, point-of-care ultrasound (POCUS), semiology, Semiotics, subpleural consolidations, Ultrasonic imaging, Videos},
	pages = {1--4},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\3EACD7D6\\Almeida et al. - 2020 - Lung ultrasound for point-of-care COVID-19 pneumon.pdf:application/pdf},
}

@article{awasthi_mini-covidnet_2021,
	title = {Mini-{COVIDNet}: {Efficient} {Lightweight} {Deep} {Neural} {Network} for {Ultrasound} {Based} {Point}-of-{Care} {Detection} of {COVID}-19},
	volume = {68},
	issn = {1525-8955},
	shorttitle = {Mini-{COVIDNet}},
	doi = {10.1109/TUFFC.2021.3068190},
	abstract = {Lung ultrasound (US) imaging has the potential to be an effective point-of-care test for detection of COVID-19, due to its ease of operation with minimal personal protection equipment along with easy disinfection. The current state-of-the-art deep learning models for detection of COVID-19 are heavy models that may not be easy to deploy in commonly utilized mobile platforms in point-of-care testing. In this work, we develop a lightweight mobile friendly efficient deep learning model for detection of COVID-19 using lung US images. Three different classes including COVID-19, pneumonia, and healthy were included in this task. The developed network, named as Mini-COVIDNet, was bench-marked with other lightweight neural network models along with state-of-the-art heavy model. It was shown that the proposed network can achieve the highest accuracy of 83.2\% and requires a training time of only 24 min. The proposed Mini-COVIDNet has 4.39 times less number of parameters in the network compared to its next best performing network and requires a memory of only 51.29 MB, making the point-of-care detection of COVID-19 using lung US imaging plausible on a mobile platform. Deployment of these lightweight networks on embedded platforms shows that the proposed Mini-COVIDNet is highly versatile and provides optimal performance in terms of being accurate as well as having latency in the same order as other lightweight networks. The developed lightweight models are available at https://github.com/navchetan-awasthi/Mini-COVIDNet.},
	number = {6},
	journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
	author = {Awasthi, Navchetan and Dayal, Aveen and Cenkeramaddi, Linga Reddy and Yalavarthy, Phaneendra K.},
	month = jun,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
	keywords = {deep learning, COVID-19, Lung, Ultrasonic imaging, Computed tomography, Coronavirus, detection, Diseases, Imaging, lung ultrasound (US) imaging, point-of-care testing, X-ray imaging},
	pages = {2023--2037},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\3S8985LU\\Awasthi et al. - 2021 - Mini-COVIDNet Efficient Lightweight Deep Neural N.pdf:application/pdf},
}

@misc{noauthor_sensors_nodate,
	title = {Sensors {\textbar} {Free} {Full}-{Text} {\textbar} {Pulmonary} {COVID}-19: {Learning} {Spatiotemporal} {Features} {Combining} {CNN} and {LSTM} {Networks} for {Lung} {Ultrasound} {Video} {Classification}},
	url = {https://www.mdpi.com/1424-8220/21/16/5486},
	urldate = {2023-06-13},
}

@misc{noauthor_deep-learning_nodate,
	title = {Deep-learning based detection of {COVID}-19 using lung ultrasound imagery {\textbar} {PLOS} {ONE}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255886},
	urldate = {2023-06-13},
}

@article{ebadi_covidx-us_2022,
	title = {{COVIDx}-{US}: {An} {Open}-{Access} {Benchmark} {Dataset} of {Ultrasound} {Imaging} {Data} for {AI}-{Driven} {COVID}-19 {Analytics}},
	volume = {27},
	issn = {2768-6701},
	shorttitle = {{COVIDx}-{US}},
	url = {https://www.imrpress.com/journal/FBL/27/7/10.31083/j.fbl2707198},
	doi = {10.31083/j.fbl2707198},
	abstract = {Background: The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. Apart from the global health crises, the pandemic has also caused significant economic and financial difficulties and socio-physiological implications. Effective screening, triage, treatment planning, and prognostication of outcome play a key role in controlling the pandemic. Recent studies have highlighted the role of point-of-care ultrasound imaging for COVID-19 screening and prognosis, particularly given that it is non-invasive, globally available, and easy-to-sanitize. COVIDx-US Dataset: Motivated by these attributes and the promise of artificial intelligence tools to aid clinicians, we introduce COVIDx-US, an open-access benchmark dataset of COVID-19 related ultrasound imaging data. The COVIDx-US dataset was curated from multiple data sources and its current version, i.e., v1.5., consists of 173 ultrasound videos and 21,570 processed images across 147 patients with COVID-19 infection, non-COVID-19 infection, other lung diseases/conditions, as well as normal control cases. Conclusions: The COVIDx-US dataset was released as part of a large open-source initiative, the COVID-Net initiative, and will be continuously growing, as more data sources become available. To the best of the authors’ knowledge, COVIDx-US is the first and largest open-access fully-curated benchmark lung ultrasound imaging dataset that contains a standardized and unified lung ultrasound score per video file, providing better interpretation while enabling other research avenues such as severity assessment. In addition, the dataset is reproducible, easy-to-use, and easy-to-scale thanks to the well-documented modular design.},
	number = {7},
	urldate = {2023-06-13},
	journal = {Frontiers in Bioscience-Landmark},
	author = {Ebadi, Ashkan and Xi, Pengcheng and MacLean, Alexander and Florea, Adrian and Tremblay, Stéphane and Kohli, Sonny and Wong, Alexander},
	month = jun,
	year = {2022},
	note = {Number: 7
Publisher: IMR Press},
	pages = {198},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\34DE5JNZ\\Ebadi et al. - 2022 - COVIDx-US An Open-Access Benchmark Dataset of Ult.pdf:application/pdf},
}

@article{diaz-escobar_deep-learning_2021,
	title = {Deep-learning based detection of {COVID}-19 using lung ultrasound imagery},
	volume = {16},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255886},
	doi = {10.1371/journal.pone.0255886},
	abstract = {Background The COVID-19 pandemic has exposed the vulnerability of healthcare services worldwide, especially in underdeveloped countries. There is a clear need to develop novel computer-assisted diagnosis tools to provide rapid and cost-effective screening in places where massive traditional testing is not feasible. Lung ultrasound is a portable, easy to disinfect, low cost and non-invasive tool that can be used to identify lung diseases. Computer-assisted analysis of lung ultrasound imagery is a relatively recent approach that has shown great potential for diagnosing pulmonary conditions, being a viable alternative for screening and diagnosing COVID-19. Objective To evaluate and compare the performance of deep-learning techniques for detecting COVID-19 infections from lung ultrasound imagery. Methods We adapted different pre-trained deep learning architectures, including VGG19, InceptionV3, Xception, and ResNet50. We used the publicly available POCUS dataset comprising 3326 lung ultrasound frames of healthy, COVID-19, and pneumonia patients for training and fine-tuning. We conducted two experiments considering three classes (COVID-19, pneumonia, and healthy) and two classes (COVID-19 versus pneumonia and COVID-19 versus non-COVID-19) of predictive models. The obtained results were also compared with the POCOVID-net model. For performance evaluation, we calculated per-class classification metrics (Precision, Recall, and F1-score) and overall metrics (Accuracy, Balanced Accuracy, and Area Under the Receiver Operating Characteristic Curve). Lastly, we performed a statistical analysis of performance results using ANOVA and Friedman tests followed by post-hoc analysis using the Wilcoxon signed-rank test with the Holm’s step-down correction. Results InceptionV3 network achieved the best average accuracy (89.1\%), balanced accuracy (89.3\%), and area under the receiver operating curve (97.1\%) for COVID-19 detection from bacterial pneumonia and healthy lung ultrasound data. The ANOVA and Friedman tests found statistically significant performance differences between models for accuracy, balanced accuracy and area under the receiver operating curve. Post-hoc analysis showed statistically significant differences between the performance obtained with the InceptionV3-based model and POCOVID-net, VGG19-, and ResNet50-based models. No statistically significant differences were found in the performance obtained with InceptionV3- and Xception-based models. Conclusions Deep learning techniques for computer-assisted analysis of lung ultrasound imagery provide a promising avenue for COVID-19 screening and diagnosis. Particularly, we found that the InceptionV3 network provides the most promising predictive results from all AI-based techniques evaluated in this work. InceptionV3- and Xception-based models can be used to further develop a viable computer-assisted screening tool for COVID-19 based on ultrasound imagery.},
	language = {en},
	number = {8},
	urldate = {2023-06-13},
	journal = {PLOS ONE},
	author = {Diaz-Escobar, Julia and Ordóñez-Guillén, Nelson E. and Villarreal-Reyes, Salvador and Galaviz-Mosqueda, Alejandro and Kober, Vitaly and Rivera-Rodriguez, Raúl and Rizk, Jose E. Lozano},
	month = aug,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Computed axial tomography, COVID 19, Pleurae, Pneumonia, Pulmonary imaging, Ultrasound imaging, Virus testing, X-ray radiography},
	pages = {e0255886},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\PVGFLJBB\\Diaz-Escobar et al. - 2021 - Deep-learning based detection of COVID-19 using lu.pdf:application/pdf},
}

@article{sadik_specmen-dl_2021,
	title = {{SpecMEn}-{DL}: spectral mask enhancement with deep learning models to predict {COVID}-19 from lung ultrasound videos},
	volume = {9},
	issn = {2047-2501},
	shorttitle = {{SpecMEn}-{DL}},
	url = {https://doi.org/10.1007/s13755-021-00154-8},
	doi = {10.1007/s13755-021-00154-8},
	abstract = {Lung Ultrasound (LUS) images are considered to be effective for detecting Coronavirus Disease (COVID-19) as an alternative to the existing reverse transcription-polymerase chain reaction (RT-PCR)-based detection scheme. However, the recent literature exhibits a shortage of works dealing with LUS image-based COVID-19 detection. In this paper, a spectral mask enhancement (SpecMEn) scheme is introduced along with a histogram equalization pre-processing stage to reduce the noise effect in LUS images prior to utilizing them for feature extraction. In order to detect the COVID-19 cases, we propose to utilize the SpecMEn pre-processed LUS images in the deep learning (DL) models (namely the SpecMEn-DL method), which offers a better representation of some characteristics features in LUS images and results in very satisfactory classification performance. The performance of the proposed SpecMEn-DL technique is appraised by implementing some state-of-the-art DL models and comparing the results with related studies. It is found that the use of the SpecMEn scheme in DL techniques offers an average increase in accuracy and \$\$F\_\{1\}\$\$score of \$\$11{\textbackslash}\%\$\$and \$\$11.75{\textbackslash}\%\$\$, respectively, at the video-level. Comprehensive analysis and visualization of the intermediate steps manifest a very satisfactory detection performance creating a flexible and safe alternative option for the clinicians to get assistance while obtaining the immediate evaluation of the patients.},
	language = {en},
	number = {1},
	urldate = {2023-06-13},
	journal = {Health Information Science and Systems},
	author = {Sadik, Farhan and Dastider, Ankan Ghosh and Fattah, Shaikh Anowarul},
	month = jul,
	year = {2021},
	keywords = {COVID-19, Disease classification, Image processing, Lung ultrasound, Spectral mask},
	pages = {28},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\8TTT89IJ\\Sadik et al. - 2021 - SpecMEn-DL spectral mask enhancement with deep le.pdf:application/pdf},
}

@article{andrawis_combination_2011,
	title = {Combination of long term and short term forecasts, with application to tourism demand forecasting},
	volume = {27},
	issn = {01692070},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207010001147},
	doi = {10.1016/j.ijforecast.2010.05.019},
	language = {en},
	number = {3},
	urldate = {2023-06-19},
	journal = {International Journal of Forecasting},
	author = {Andrawis, Robert R. and Atiya, Amir F. and El-Shishiny, Hisham},
	month = jul,
	year = {2011},
	pages = {870--886},
}

@article{arauzo-azofra_empirical_2011,
	title = {Empirical study of feature selection methods based on individual feature evaluation for classification problems},
	volume = {38},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S095741741001523X},
	doi = {10.1016/j.eswa.2010.12.160},
	language = {en},
	number = {7},
	urldate = {2023-06-19},
	journal = {Expert Systems with Applications},
	author = {Arauzo-Azofra, Antonio and Aznarte, José Luis and Benítez, José M.},
	month = jul,
	year = {2011},
	pages = {8170--8177},
}

@incollection{armstrong_principles_nodate,
	series = {International {Series} in {Operations} {Research} \& {Management} {Science}},
	title = {Principles of {Forecasting}: {A} {Handbook} for {Researchers} and {Practitioners}},
	author = {Armstrong, J. Scott},
}

@book{armstrong_principles_2001,
	address = {Boston, MA},
	series = {International {Series} in {Operations} {Research} \& {Management} {Science}},
	title = {Principles of {Forecasting}: {A} {Handbook} for {Researchers} and {Practitioners}},
	volume = {30},
	isbn = {978-0-7923-7401-5 978-0-306-47630-3},
	shorttitle = {Principles of {Forecasting}},
	url = {http://link.springer.com/10.1007/978-0-306-47630-3},
	language = {en},
	urldate = {2023-06-19},
	publisher = {Springer US},
	editor = {Armstrong, J. Scott and Hillier, Frederick S.},
	year = {2001},
	doi = {10.1007/978-0-306-47630-3},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\WBEPM7FL\\Armstrong - 2001 - Principles of Forecasting A Handbook for Research.pdf:application/pdf},
}

@article{asrol_risk_2021,
	title = {Risk {Management} for {Improving} {Supply} {Chain} {Performance} of {Sugarcane} {Agroindustry}},
	volume = {20},
	issn = {1598-7248, 2234-6473},
	url = {http://www.dbpia.co.kr/Journal/ArticleDetail/NODE10541489},
	doi = {10.7232/iems.2021.20.1.9},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Industrial Engineering \& Management Systems},
	author = {Asrol, Muhammad and Marimin, Marimin and Machfud, Machfud and Yani, Mohamad and Taira, Eizo},
	month = mar,
	year = {2021},
	pages = {9--26},
}

@article{bagshaw_workforce_2017,
	title = {{WORKFORCE} {BIG} {DATA} {ANALYTICS} {AND} {PRODUCTION} {EFFICIENCY}: {A} {Manager}’s {Guide}},
	volume = {5},
	issn = {20547404},
	shorttitle = {{WORKFORCE} {BIG} {DATA} {ANALYTICS} {AND} {PRODUCTION} {EFFICIENCY}},
	url = {http://scholarpublishing.org/index.php/ABR/article/view/3168},
	doi = {10.14738/abr.57.3168},
	number = {7},
	urldate = {2023-06-19},
	journal = {Archives of Business Research},
	author = {Bagshaw, Karibo Benaiah},
	month = jul,
	year = {2017},
}

@article{barnard_applications_1999,
	title = {Applications of multiple imputation in medical studies: from {AIDS} to {NHANES}},
	volume = {8},
	issn = {0962-2802, 1477-0334},
	shorttitle = {Applications of multiple imputation in medical studies},
	url = {http://journals.sagepub.com/doi/10.1177/096228029900800103},
	doi = {10.1177/096228029900800103},
	abstract = {Rubin's multiple imputation is a three-step method for handling complex missing data, or more generally, incomplete-data problems, which arise frequently in medical studies. At the first step, m ({\textgreater} 1) completed-data sets are created by imputing the unobserved data m times using m independent draws from an imputation model, which is constructed to reasonably approximate the true distributional relationship between the unobserved data and the available information, and thus reduce potentially very serious nonresponse bias due to systematic difference between the observed data and the unobserved ones. At the second step, m complete-data analyses are performed by treating each completed-data set as a real complete-data set, and thus standard complete-data procedures and software can be utilized directly. At the third step, the results from the m complete-data analyses are combined in a simple, appropriate way to obtain the so-called repeated-imputation inference, which properly takes into account the uncertainty in the imputed values. This paper reviews three applications of Rubin's method that are directly relevant for medical studies. The first is about estimating the reporting delay in acquired immune deficiency syndrome (AIDS) surveillance systems for the purpose of estimating survival time after AIDS diagnosis. The second focuses on the issue of missing data and noncompliance in randomized experiments, where a school choice experiment is used as an illustration. The third looks at handling nonresponse in United States National Health and Nutrition Examination Surveys (NHANES). The emphasis of our review is on the building of imputation models (i.e. the first step), which is the most fundamental aspect of the method.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Statistical Methods in Medical Research},
	author = {Barnard, John and Meng, Xiao-Li},
	month = feb,
	year = {1999},
	pages = {17--36},
}

@article{batista_analysis_2003,
	title = {An analysis of four missing data treatment methods for supervised learning},
	volume = {17},
	issn = {0883-9514, 1087-6545},
	url = {http://www.tandfonline.com/doi/abs/10.1080/713827181},
	doi = {10.1080/713827181},
	language = {en},
	number = {5-6},
	urldate = {2023-06-19},
	journal = {Applied Artificial Intelligence},
	author = {Batista, Gustavo E. A. P. A. and Monard, Maria Carolina},
	month = may,
	year = {2003},
	pages = {519--533},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\ZJEY7AZS\\Batista and Monard - 2003 - An analysis of four missing data treatment methods.pdf:application/pdf},
}

@inproceedings{bergstra_making_2013,
	title = {Making a {Science} of {Model} {Search}: {Hyperparameter} {Optimization} in {Hundreds} of {Dimensions} for {Vision} {Architectures}},
	shorttitle = {Making a {Science} of {Model} {Search}},
	url = {https://proceedings.mlr.press/v28/bergstra13.html},
	abstract = {Many computer vision algorithms depend on configuration settings that are typically hand-tuned in the course of evaluating the algorithm for a particular data set. While such parameter tuning is often presented as being incidental to the algorithm, correctly setting these parameter choices is frequently critical to realizing a method’s full potential. Compounding matters, these parameters often must be re-tuned when the algorithm is applied to a new problem domain, and the tuning process itself often depends on personal experience and intuition in ways that are hard to quantify or describe. Since the performance of a given technique depends on both the fundamental quality of the algorithm and the details of its tuning, it is sometimes difficult to know whether a given technique is genuinely better, or simply better tuned.     In this work, we propose a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process. Our approach is to expose the underlying expression graph of how a performance metric (e.g. classification accuracy on validation examples) is computed from hyperparameters that govern not only how individual processing steps are applied, but even which processing steps are included.  A hyperparameter optimization algorithm transforms this graph into a program for optimizing that performance metric.  Our approach yields state of the art results on three disparate computer vision problems: a face-matching verification task (LFW), a face identification task (PubFig83) and an object recognition task (CIFAR-10), using a single broad class of feed-forward vision architectures.},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Bergstra, James and Yamins, Daniel and Cox, David},
	month = feb,
	year = {2013},
	note = {ISSN: 1938-7228},
	pages = {115--123},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\UEUINITJ\\Bergstra et al. - 2013 - Making a Science of Model Search Hyperparameter O.pdf:application/pdf},
}

@inproceedings{bergstra_algorithms_2011,
	title = {Algorithms for {Hyper}-{Parameter} {Optimization}},
	volume = {24},
	url = {https://proceedings.neurips.cc/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html},
	abstract = {Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [Larochelle et al., 2007] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P (y{\textbar}x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements.},
	urldate = {2023-06-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Bergstra, James and Bardenet, Rémi and Bengio, Yoshua and Kégl, Balázs},
	year = {2011},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\JUSWWTLT\\Bergstra et al. - 2011 - Algorithms for Hyper-Parameter Optimization.pdf:application/pdf},
}

@article{bernardes_examination_2008,
	title = {An examination of strategic supply management benefits and performance implications},
	volume = {14},
	issn = {14784092},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1478409208000496},
	doi = {10.1016/j.pursup.2008.06.004},
	language = {en},
	number = {4},
	urldate = {2023-06-19},
	journal = {Journal of Purchasing and Supply Management},
	author = {Bernardes, Ednilson S. and Zsidisin, George A.},
	month = dec,
	year = {2008},
	pages = {209--219},
}

@incollection{camarinha-matos_systematic_2005,
	address = {New York},
	title = {A {Systematic} {Approach} for {VE} {Partners} {Selection} {Using} the {SCOR} {Model} and the {AHP} {Method}},
	volume = {186},
	isbn = {978-0-387-28259-6},
	url = {http://link.springer.com/10.1007/0-387-29360-4_10},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Collaborative {Networks} and {Their} {Breeding} {Environments}},
	publisher = {Springer-Verlag},
	author = {Bittencourt, Felipe and Rabelo, Ricardo J.},
	editor = {Camarinha-Matos, Luis M. and Afsarmanesh, Hamideh and Ortiz, Angel},
	year = {2005},
	doi = {10.1007/0-387-29360-4_10},
	note = {Series Title: IFIP — The International Federation for Information Processing},
	pages = {99--108},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\59EMKRKI\\Bittencourt and Rabelo - 2005 - A Systematic Approach for VE Partners Selection Us.pdf:application/pdf},
}

@article{bolon-canedo_review_2013,
	title = {A review of feature selection methods on synthetic data},
	volume = {34},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-012-0487-8},
	doi = {10.1007/s10115-012-0487-8},
	language = {en},
	number = {3},
	urldate = {2023-06-19},
	journal = {Knowledge and Information Systems},
	author = {Bolón-Canedo, Verónica and Sánchez-Maroño, Noelia and Alonso-Betanzos, Amparo},
	month = mar,
	year = {2013},
	pages = {483--519},
}

@article{brown_conditional_2012,
	title = {Conditional {Likelihood} {Maximisation}: {A} {Unifying} {Framework} for {Information} {Theoretic} {Feature} {Selection}},
	volume = {13},
	url = {http://jmlr.org/papers/v13/brown12a.html},
	number = {2},
	journal = {Journal of Machine Learning Research},
	author = {Brown, Gavin and Pocock, Adam and Zhao, Ming-Jie and Luján, Mikel},
	year = {2012},
	pages = {27--66},
}

@article{brown_conditional_nodate,
	title = {Conditional {Likelihood} {Maximisation}: {A} {Unifying} {Framework} for {Information} {Theoretic} {Feature} {Selection}},
	volume = {13},
	abstract = {We present a unifying framework for information theoretic feature selection, bringing almost two decades of research on heuristic ﬁlter criteria under a single theoretical interpretation. This is in response to the question: “what are the implicit statistical assumptions of feature selection criteria based on mutual information?”. To answer this, we adopt a different strategy than is usual in the feature selection literature—instead of trying to deﬁne a criterion, we derive one, directly from a clearly speciﬁed objective function: the conditional likelihood of the training labels. While many hand-designed heuristic criteria try to optimize a deﬁnition of feature ‘relevancy’ and ‘redundancy’, our approach leads to a probabilistic framework which naturally incorporates these concepts. As a result we can unify the numerous criteria published over the last two decades, and show them to be low-order approximations to the exact (but intractable) optimisation problem. The primary contribution is to show that common heuristics for information based feature selection (including Markov Blanket algorithms as a special case) are approximate iterative maximisers of the conditional likelihood. A large empirical study provides strong evidence to favour certain classes of criteria, in particular those that balance the relative size of the relevancy/redundancy terms. Overall we conclude that the JMI criterion (Yang and Moody, 1999; Meyer et al., 2008) provides the best tradeoff in terms of accuracy, stability, and ﬂexibility with small data samples.},
	language = {en},
	journal = {The Journal of Machine Learning Research},
	author = {Brown, Gavin and Pocock, Adam and Zhao, Ming-Jie and Lujan, Mikel},
	pages = {27--66},
	file = {Brown et al. - Conditional Likelihood Maximisation A Unifying Fr.pdf:C\:\\Users\\abrar\\Zotero\\storage\\CKB2D8K4\\Brown et al. - Conditional Likelihood Maximisation A Unifying Fr.pdf:application/pdf},
}

@article{buchatskaya_forecasting_2015,
	title = {Forecasting {Methods} {Classification} and its {Applicability}},
	volume = {8},
	issn = {09746846, 09745645},
	url = {https://indjst.org/articles/forecasting-methods-classification-and-its-applicability},
	doi = {10.17485/ijst/2015/v8i30/84224},
	number = {1},
	urldate = {2023-06-19},
	journal = {Indian Journal of Science and Technology},
	author = {Buchatskaya, Viktoria},
	month = jan,
	year = {2015},
	pages = {1--8},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\RK5Q8ESC\\Buchatskaya - 2015 - Forecasting Methods Classification and its Applica.pdf:application/pdf},
}

@article{isaac_biochemical_1975,
	title = {[{Biochemical} studies on camomile components/{III}. {In} vitro studies about the antipeptic activity of (--)-alpha-bisabolol (author's transl)]},
	volume = {25},
	issn = {0004-4172},
	abstract = {(--)-alpha-Bisabolol has a primary antipeptic action depending on dosage, which is not caused by an alteration of the pH-value. The proteolytic activity of pepsin is reduced by 50 percent through addition of bisabolol in the ratio of 1/0.5. The antipeptic action of bisabolol only occurs in case of direct contact. In case of a previous contact with the substrate, the inhibiting effect is lost.},
	language = {ger},
	number = {9},
	journal = {Arzneimittel-Forschung},
	author = {Isaac, O. and Thiemer, K.},
	month = sep,
	year = {1975},
	pmid = {21},
	keywords = {Dose-Response Relationship, Drug, Hemoglobins, Hydrogen-Ion Concentration, In Vitro Techniques, Methods, Pepsin A, Plants, Medicinal, Sesquiterpenes, Spectrophotometry, Ultraviolet, Trichloroacetic Acid, Tyrosine},
	pages = {1352--1354},
}

@misc{noauthor_how_nodate,
	title = {How to {Choose} the {Right} {Forecasting} {Technique}},
	url = {https://hbr.org/1971/07/how-to-choose-the-right-forecasting-technique},
	urldate = {2023-06-19},
}

@article{chambers_how_1971,
	title = {How to {Choose} the {Right} {Forecasting} {Technique}},
	issn = {0017-8012},
	url = {https://hbr.org/1971/07/how-to-choose-the-right-forecasting-technique},
	abstract = {What every manager ought to know about the different kinds of forecasting and the times when they should be used.},
	urldate = {2023-06-19},
	journal = {Harvard Business Review},
	author = {Chambers, John C. and Mullick, Satinder K. and Smith, Donald D.},
	month = jul,
	year = {1971},
	note = {Section: Financial analysis},
	keywords = {Sales, Financial analysis, Financial performance measurement},
}

@article{chan_performance_2003,
	title = {Performance {Measurement} in a {Supply} {Chain}},
	volume = {21},
	issn = {0268-3768, 1433-3015},
	url = {http://link.springer.com/10.1007/s001700300063},
	doi = {10.1007/s001700300063},
	number = {7},
	urldate = {2023-06-19},
	journal = {The International Journal of Advanced Manufacturing Technology},
	author = {Chan, F.T.S.},
	month = may,
	year = {2003},
	pages = {534--548},
}

@inproceedings{peng-wei_chen_model_2004,
	address = {Budapest, Hungary},
	title = {Model selection of {SVMs} using {GA} approach},
	volume = {3},
	isbn = {978-0-7803-8359-3},
	url = {http://ieeexplore.ieee.org/document/1380929/},
	doi = {10.1109/IJCNN.2004.1380929},
	urldate = {2023-06-19},
	booktitle = {2004 {IEEE} {International} {Joint} {Conference} on {Neural} {Networks} ({IEEE} {Cat}. {No}.{04CH37541})},
	publisher = {IEEE},
	author = {{Peng-Wei Chen} and {Jung-Ying Wang} and {Hahn-Ming Lee}},
	year = {2004},
	pages = {2035--2040},
}

@article{cochinwala_efficient_2001,
	title = {Efficient data reconciliation},
	volume = {137},
	issn = {00200255},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025500000700},
	doi = {10.1016/S0020-0255(00)00070-0},
	language = {en},
	number = {1-4},
	urldate = {2023-06-19},
	journal = {Information Sciences},
	author = {Cochinwala, Munir and Kurien, Verghese and Lalk, Gail and Shasha, Dennis},
	month = sep,
	year = {2001},
	pages = {1--15},
}

@article{cornelis_attribute_2010,
	title = {Attribute selection with fuzzy decision reducts},
	volume = {180},
	issn = {00200255},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025509003995},
	doi = {10.1016/j.ins.2009.09.008},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {Information Sciences},
	author = {Cornelis, Chris and Jensen, Richard and Hurtado, Germán and Śle¸zak, Dominik},
	month = jan,
	year = {2010},
	pages = {209--224},
	file = {Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\5U4NM7AM\\Cornelis et al. - 2010 - Attribute selection with fuzzy decision reducts.pdf:application/pdf},
}

@article{debaets_forecasting_2018,
	title = {Forecasting from time series subject to sporadic perturbations: {Effectiveness} of different types of forecasting support},
	volume = {34},
	issn = {01692070},
	shorttitle = {Forecasting from time series subject to sporadic perturbations},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207017301048},
	doi = {10.1016/j.ijforecast.2017.09.007},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {International Journal of Forecasting},
	author = {De Baets, Shari and Harvey, Nigel},
	month = apr,
	year = {2018},
	pages = {163--180},
	file = {Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\F3C9UT9Z\\De Baets and Harvey - 2018 - Forecasting from time series subject to sporadic p.pdf:application/pdf},
}

@inproceedings{dey_entity_1998,
	address = {Kohala Coast, HI, USA},
	title = {Entity matching in heterogeneous databases: a distance-based decision model},
	volume = {7},
	isbn = {978-0-8186-8255-1},
	shorttitle = {Entity matching in heterogeneous databases},
	url = {http://ieeexplore.ieee.org/document/649225/},
	doi = {10.1109/HICSS.1998.649225},
	urldate = {2023-06-19},
	booktitle = {Proceedings of the {Thirty}-{First} {Hawaii} {International} {Conference} on {System} {Sciences}},
	publisher = {IEEE Comput. Soc},
	author = {Dey, D. and Sarkar, S. and De, P.},
	year = {1998},
	pages = {305--313},
}

@article{droge_does_2012,
	title = {Does supply chain integration mediate the relationships between product/process strategy and service performance? {An} empirical study},
	volume = {137},
	issn = {09255273},
	shorttitle = {Does supply chain integration mediate the relationships between product/process strategy and service performance?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925527312000631},
	doi = {10.1016/j.ijpe.2012.02.005},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {International Journal of Production Economics},
	author = {Droge, Cornelia and Vickery, Shawnee K. and Jacobs, Mark A.},
	month = jun,
	year = {2012},
	pages = {250--262},
}

@article{duarte_use_2006,
	title = {The {Use} of {Qualitative} {Information} for {Forecasting} {Exports}},
	url = {https://ideas.repec.org//a/ptu/bdpart/b200615.html},
	abstract = {No abstract is available for this item.},
	language = {en},
	urldate = {2023-06-19},
	journal = {Economic Bulletin and Financial Stability Report Articles and Banco de Portugal Economic Studies},
	author = {Duarte, Cláudia and Cardoso, Fátima},
	year = {2006},
	note = {Publisher: Banco de Portugal, Economics and Research Department},
	file = {Fullext PDF:C\:\\Users\\abrar\\Zotero\\storage\\RCGTX6A7\\Duarte and Cardoso - 2006 - The Use of Qualitative Information for Forecasting.pdf:application/pdf;Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\DPE9UNLK\\b200615.html:text/html},
}

@article{efendigil_decision_2009,
	title = {A decision support system for demand forecasting with artificial neural networks and neuro-fuzzy models: {A} comparative analysis},
	volume = {36},
	issn = {09574174},
	shorttitle = {A decision support system for demand forecasting with artificial neural networks and neuro-fuzzy models},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417408005800},
	doi = {10.1016/j.eswa.2008.08.058},
	language = {en},
	number = {3},
	urldate = {2023-06-19},
	journal = {Expert Systems with Applications},
	author = {Efendigil, Tuğba and Önüt, Semih and Kahraman, Cengiz},
	month = apr,
	year = {2009},
	pages = {6697--6707},
}

@incollection{hutchison_big_2014,
	address = {Cham},
	title = {Big {Data} {Analytics}: {A} {Literature} {Review} {Paper}},
	volume = {8557},
	isbn = {978-3-319-08975-1 978-3-319-08976-8},
	shorttitle = {Big {Data} {Analytics}},
	url = {http://link.springer.com/10.1007/978-3-319-08976-8_16},
	urldate = {2023-06-19},
	booktitle = {Advances in {Data} {Mining}. {Applications} and {Theoretical} {Aspects}},
	publisher = {Springer International Publishing},
	author = {Elgendy, Nada and Elragal, Ahmed},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard and Perner, Petra},
	year = {2014},
	doi = {10.1007/978-3-319-08976-8_16},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {214--227},
}

@article{elghazel_unsupervised_2015,
	title = {Unsupervised feature selection with ensemble learning},
	volume = {98},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/10.1007/s10994-013-5337-8},
	doi = {10.1007/s10994-013-5337-8},
	language = {en},
	number = {1-2},
	urldate = {2023-06-19},
	journal = {Machine Learning},
	author = {Elghazel, Haytham and Aussem, Alex},
	month = jan,
	year = {2015},
	pages = {157--180},
}

@article{elmagarmid_duplicate_2007,
	title = {Duplicate {Record} {Detection}: {A} {Survey}},
	volume = {19},
	issn = {1041-4347},
	shorttitle = {Duplicate {Record} {Detection}},
	url = {http://ieeexplore.ieee.org/document/4016511/},
	doi = {10.1109/TKDE.2007.250581},
	number = {1},
	urldate = {2023-06-19},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Elmagarmid, Ahmed K. and Ipeirotis, Panagiotis G. and Verykios, Vassilios S.},
	month = jan,
	year = {2007},
	pages = {1--16},
	file = {Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\U3FWQ48G\\Elmagarmid et al. - 2007 - Duplicate Record Detection A Survey.pdf:application/pdf},
}

@inproceedings{escalante_ensemble_2010,
	address = {Barcelona, Spain},
	title = {Ensemble particle swarm model selection},
	isbn = {978-1-4244-6916-1},
	url = {http://ieeexplore.ieee.org/document/5596915/},
	doi = {10.1109/IJCNN.2010.5596915},
	urldate = {2023-06-19},
	booktitle = {The 2010 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Escalante, Hugo Jair and Montes, Manuel and Sucar, Enrique},
	month = jul,
	year = {2010},
	pages = {1--8},
	file = {Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\WLW6TANN\\Escalante et al. - 2010 - Ensemble particle swarm model selection.pdf:application/pdf},
}

@article{estevez_normalized_2009,
	title = {Normalized {Mutual} {Information} {Feature} {Selection}},
	volume = {20},
	issn = {1045-9227, 1941-0093},
	url = {http://ieeexplore.ieee.org/document/4749258/},
	doi = {10.1109/TNN.2008.2005601},
	number = {2},
	urldate = {2023-06-19},
	journal = {IEEE Transactions on Neural Networks},
	author = {Estevez, P.A. and Tesmer, M. and Perez, C.A. and Zurada, J.M.},
	month = feb,
	year = {2009},
	pages = {189--201},
}

@inproceedings{falkner_bohb_2018,
	title = {{BOHB}: {Robust} and {Efficient} {Hyperparameter} {Optimization} at {Scale}},
	shorttitle = {{BOHB}},
	url = {https://proceedings.mlr.press/v80/falkner18a.html},
	abstract = {Modern deep learning methods are very sensitive to many hyperparameters, and, due to the long training times of state-of-the-art models, vanilla Bayesian hyperparameter optimization is typically computationally infeasible. On the other hand, bandit-based configuration evaluation approaches based on random search lack guidance and do not converge to the best configurations as quickly. Here, we propose to combine the benefits of both Bayesian optimization and bandit-based methods, in order to achieve the best of both worlds: strong anytime performance and fast convergence to optimal configurations. We propose a new practical state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks, Bayesian neural networks, deep reinforcement learning, and convolutional neural networks. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Falkner, Stefan and Klein, Aaron and Hutter, Frank},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {1437--1446},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\DXZ9CBTB\\Falkner et al. - 2018 - BOHB Robust and Efficient Hyperparameter Optimiza.pdf:application/pdf;Supplementary PDF:C\:\\Users\\abrar\\Zotero\\storage\\P9X3HXSR\\Falkner et al. - 2018 - BOHB Robust and Efficient Hyperparameter Optimiza.pdf:application/pdf},
}

@article{farhangfar_novel_2007,
	title = {A {Novel} {Framework} for {Imputation} of {Missing} {Values} in {Databases}},
	volume = {37},
	issn = {1083-4427},
	url = {http://ieeexplore.ieee.org/document/4292217/},
	doi = {10.1109/TSMCA.2007.902631},
	number = {5},
	urldate = {2023-06-19},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
	author = {Farhangfar, Alireza and Kurgan, Lukasz A. and Pedrycz, Witold},
	month = sep,
	year = {2007},
	pages = {692--709},
}

@article{fellegi_theory_1969,
	title = {A {Theory} for {Record} {Linkage}},
	volume = {64},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1969.10501049},
	doi = {10.1080/01621459.1969.10501049},
	language = {en},
	number = {328},
	urldate = {2023-06-19},
	journal = {Journal of the American Statistical Association},
	author = {Fellegi, Ivan P. and Sunter, Alan B.},
	month = dec,
	year = {1969},
	pages = {1183--1210},
}

@incollection{hutter_hyperparameter_2019,
	address = {Cham},
	title = {Hyperparameter {Optimization}},
	isbn = {978-3-030-05317-8 978-3-030-05318-5},
	url = {http://link.springer.com/10.1007/978-3-030-05318-5_1},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Automated {Machine} {Learning}},
	publisher = {Springer International Publishing},
	author = {Feurer, Matthias and Hutter, Frank},
	editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
	year = {2019},
	doi = {10.1007/978-3-030-05318-5_1},
	note = {Series Title: The Springer Series on Challenges in Machine Learning},
	pages = {3--33},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\82Q3YJEK\\Feurer and Hutter - 2019 - Hyperparameter Optimization.pdf:application/pdf},
}

@article{demeter_impact_2007,
	title = {The impact of forecast information quality on supply chain performance},
	volume = {27},
	issn = {0144-3577},
	url = {https://www.emerald.com/insight/content/doi/10.1108/01443570710714556/full/html},
	doi = {10.1108/01443570710714556},
	abstract = {Purpose
              This paper aims to describe the extent of supplier access to customer forecast information and the perceived quality of such information and also to explain the impact of forecast information access and forecast information quality (FIQ) on supply chain performance.
            
            
              Design/methodology/approach
              FIQ is defined, and a measurement instrument is developed from theory. The analysis is based on a survey of the most important suppliers of 136 Swedish companies.
            
            
              Findings
              Findings show that a large proportion of the suppliers receive customer forecasts, but that the FIQ is lower further upstream in the supply chain and, in some variables, lower for make‐to‐order suppliers. The greatest information quality deficiency of the forecast was that it was considered unreliable. The only significant difference in supply chain performance found between make‐to‐stock suppliers with and without access to forecast was related to the use of safety stock in finished goods inventory.
            
            
              Research limitations/implications
              The study contains two types of conclusions: those developed from the conceptual discussion in the theoretical framework and those of the empirical study. In the theoretical framework, measurement instruments for FIQ and supply chain performance (corrective actions, preventive actions and customer service performance) were developed. The study identified several empirical relationships, but it was conducted on a sample with a lot of variation.
            
            
              Practical implications
              The understanding of the performance impact of FIQ. FIQ shows quality deficiencies on all variables, which indicates room for improvement.
            
            
              Originality/value
              Research on supply chain information quality as well as dyadic research approaches are rare.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {International Journal of Operations \& Production Management},
	author = {Forslund, Helena and Jonsson, Patrik},
	editor = {Demeter, Krisztina},
	month = jan,
	year = {2007},
	pages = {90--107},
	file = {Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\5G5AMMF4\\Forslund and Jonsson - 2007 - The impact of forecast information quality on supp.pdf:application/pdf},
}

@article{friedrichs_evolutionary_2005,
	title = {Evolutionary tuning of multiple {SVM} parameters},
	volume = {64},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231204005223},
	doi = {10.1016/j.neucom.2004.11.022},
	language = {en},
	urldate = {2023-06-19},
	journal = {Neurocomputing},
	author = {Friedrichs, Frauke and Igel, Christian},
	month = mar,
	year = {2005},
	pages = {107--117},
}

@inproceedings{frohlich_efficient_2005,
	address = {Montreal, QC, Canada},
	title = {Efficient parameter selection for support vector machines in classification and regression via model-based global optimization},
	volume = {3},
	isbn = {978-0-7803-9048-5},
	url = {http://ieeexplore.ieee.org/document/1556085/},
	doi = {10.1109/IJCNN.2005.1556085},
	urldate = {2023-06-19},
	booktitle = {Proceedings. 2005 {IEEE} {International} {Joint} {Conference} on {Neural} {Networks}, 2005.},
	publisher = {IEEE},
	author = {Frohlich, H. and Zell, A.},
	year = {2005},
	pages = {1431--1436},
}

@article{gandomi_beyond_2015,
	title = {Beyond the hype: {Big} data concepts, methods, and analytics},
	volume = {35},
	issn = {02684012},
	shorttitle = {Beyond the hype},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0268401214001066},
	doi = {10.1016/j.ijinfomgt.2014.10.007},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {International Journal of Information Management},
	author = {Gandomi, Amir and Haider, Murtaza},
	month = apr,
	year = {2015},
	pages = {137--144},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\S877BBTW\\Gandomi and Haider - 2015 - Beyond the hype Big data concepts, methods, and a.pdf:application/pdf},
}

@incollection{garcia_data_2015,
	address = {Cham},
	title = {Data {Preparation} {Basic} {Models}},
	volume = {72},
	isbn = {978-3-319-10246-7 978-3-319-10247-4},
	url = {https://link.springer.com/10.1007/978-3-319-10247-4_3},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Data {Preprocessing} in {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	collaborator = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	year = {2015},
	doi = {10.1007/978-3-319-10247-4_3},
	note = {Series Title: Intelligent Systems Reference Library},
	pages = {39--57},
}

@incollection{garcia_dealing_2015,
	address = {Cham},
	title = {Dealing with {Missing} {Values}},
	volume = {72},
	isbn = {978-3-319-10246-7 978-3-319-10247-4},
	url = {https://link.springer.com/10.1007/978-3-319-10247-4_4},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Data {Preprocessing} in {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	collaborator = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	year = {2015},
	doi = {10.1007/978-3-319-10247-4_4},
	note = {Series Title: Intelligent Systems Reference Library},
	pages = {59--105},
}

@incollection{garcia_data_2015-1,
	address = {Cham},
	title = {Data {Reduction}},
	volume = {72},
	isbn = {978-3-319-10246-7 978-3-319-10247-4},
	url = {https://link.springer.com/10.1007/978-3-319-10247-4_6},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Data {Preprocessing} in {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	collaborator = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	year = {2015},
	doi = {10.1007/978-3-319-10247-4_6},
	note = {Series Title: Intelligent Systems Reference Library},
	pages = {147--162},
}

@incollection{garcia_discretization_2015,
	address = {Cham},
	title = {Discretization},
	volume = {72},
	isbn = {978-3-319-10246-7 978-3-319-10247-4},
	url = {https://link.springer.com/10.1007/978-3-319-10247-4_9},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Data {Preprocessing} in {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	collaborator = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	year = {2015},
	doi = {10.1007/978-3-319-10247-4_9},
	note = {Series Title: Intelligent Systems Reference Library},
	pages = {245--283},
}

@misc{garnier_multi-series_2019,
	title = {A multi-series framework for demand forecasts in {E}-commerce},
	url = {http://arxiv.org/abs/1905.13614},
	doi = {10.48550/arXiv.1905.13614},
	abstract = {Sales forecasts are crucial for the E-commerce business. State-of-the-art techniques typically apply only univariate methods to make prediction for each series independently. However, due to the short nature of sales times series in E-commerce, univariate methods don't apply well. In this article, we propose a global model which outperforms state-of-the-art models on real dataset. It is achieved by using Tree Boosting Methods that exploit non-linearity and cross-series information. We also proposed a preprocessing framework to overcome the inherent difficulties in the E-commerce data. In particular, we use different schemes to limit the impact of the volatility of the data.},
	urldate = {2023-06-19},
	publisher = {arXiv},
	author = {Garnier, Rémy and Belletoile, Arnaud},
	month = may,
	year = {2019},
	note = {arXiv:1905.13614 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Presented at APIA 2019 conference},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\RR2227AB\\Garnier and Belletoile - 2019 - A multi-series framework for demand forecasts in E.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\R2DDVJPV\\1905.html:text/html},
}

@article{grewal_future_2017,
	title = {The {Future} of {Retailing}},
	volume = {93},
	issn = {00224359},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022435916300872},
	doi = {10.1016/j.jretai.2016.12.008},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Journal of Retailing},
	author = {Grewal, Dhruv and Roggeveen, Anne L. and Nordfält, Jens},
	month = mar,
	year = {2017},
	pages = {1--6},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\8T5S8XSE\\Grewal et al. - 2017 - The Future of Retailing.pdf:application/pdf},
}

@incollection{hutchison_handling_2005,
	address = {Berlin, Heidelberg},
	title = {Handling {Missing} {Attribute} {Values} in {Preterm} {Birth} {Data} {Sets}},
	volume = {3642},
	isbn = {978-3-540-28660-8 978-3-540-31824-8},
	url = {http://link.springer.com/10.1007/11548706_36},
	urldate = {2023-06-19},
	booktitle = {Rough {Sets}, {Fuzzy} {Sets}, {Data} {Mining}, and {Granular} {Computing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Grzymala-Busse, Jerzy W. and Goodwin, Linda K. and Grzymala-Busse, Witold J. and Zheng, Xinqun},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Ślęzak, Dominik and Yao, JingTao and Peters, James F. and Ziarko, Wojciech and Hu, Xiaohua},
	year = {2005},
	doi = {10.1007/11548706_36},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {342--351},
	file = {Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\P4RM2RWE\\Grzymala-Busse et al. - 2005 - Handling Missing Attribute Values in Preterm Birth.pdf:application/pdf},
}

@inproceedings{guha_merging_2004,
	address = {Toronto, Canada},
	series = {{VLDB} '04},
	title = {Merging the results of approximate match operations},
	isbn = {978-0-12-088469-8},
	abstract = {Data Cleaning is an important process that has been at the center of research interest in recent years. An important end goal of effective data cleaning is to identify the relational tuple or tuples that are "most related" to a given query tuple. Various techniques have been proposed in the literature for efficiently identifying approximate matches to a query string against a single attribute of a relation. In addition to constructing a ranking (i.e., ordering) of these matches, the techniques often associate, with each match, scores that quantify the extent of the match. Since multiple attributes could exist in the query tuple, issuing approximate match operations for each of them separately will effectively create a number of ranked lists of the relation tuples. Merging these lists to identify a final ranking and scoring, and returning the top-K tuples, is a challenging task. In this paper, we adapt the well-known footrule distance (for merging ranked lists) to effectively deal with scores. We study efficient algorithms to merge rankings, and produce the top-K tuples, in a declarative way. Since techniques for approximately matching a query string against a single attribute in a relation are typically best deployed in a database, we introduce and describe two novel algorithms for this problem and we provide SQL specifications for them. Our experimental case study, using real application data along with a realization of our proposed techniques on a commercial data base system, highlights the benefits of the proposed algorithms and attests to the overall effectiveness and practicality of our approach.},
	urldate = {2023-06-19},
	booktitle = {Proceedings of the {Thirtieth} international conference on {Very} large data bases - {Volume} 30},
	publisher = {VLDB Endowment},
	author = {Guha, Sudipto and Koudas, Nick and Marathe, Amit and Srivastava, Divesh},
	month = aug,
	year = {2004},
	pages = {636--647},
}

@article{gunasekaran_performance_2001,
	title = {Performance measures and metrics in a supply chain environment},
	volume = {21},
	issn = {0144-3577},
	url = {https://doi.org/10.1108/01443570110358468},
	doi = {10.1108/01443570110358468},
	number = {1/2},
	urldate = {2023-06-19},
	journal = {International Journal of Operations \& Production Management},
	author = {Gunasekaran, A. and Patel, C. and Tirtiroglu, E.},
	month = jan,
	year = {2001},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Customer satisfaction, Performance measurement, Supply-chain management},
	pages = {71--87},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\FH3M9XNE\\html.html:text/html},
}

@article{gupta_managing_2003,
	title = {Managing demand uncertainty in supply chain planning},
	volume = {27},
	issn = {00981354},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0098135403000486},
	doi = {10.1016/S0098-1354(03)00048-6},
	language = {en},
	number = {8-9},
	urldate = {2023-06-19},
	journal = {Computers \& Chemical Engineering},
	author = {Gupta, Anshuman and Maranas, Costas D.},
	month = sep,
	year = {2003},
	pages = {1219--1227},
}

@inproceedings{gurnani_forecasting_2017,
	address = {Pune},
	title = {Forecasting of sales by using fusion of machine learning techniques},
	isbn = {978-1-5090-4083-4},
	url = {https://ieeexplore.ieee.org/document/8073492/},
	doi = {10.1109/ICDMAI.2017.8073492},
	urldate = {2023-06-19},
	booktitle = {2017 {International} {Conference} on {Data} {Management}, {Analytics} and {Innovation} ({ICDMAI})},
	publisher = {IEEE},
	author = {Gurnani, Mohit and Korke, Yogesh and Shah, Prachi and Udmale, Sandeep and Sambhe, Vijay and Bhirud, Sunil},
	month = feb,
	year = {2017},
	pages = {93--101},
}

@article{hajek_profit_2020,
	title = {A {Profit} {Function}-{Maximizing} {Inventory} {Backorder} {Prediction} {System} {Using} {Big} {Data} {Analytics}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9046037/},
	doi = {10.1109/ACCESS.2020.2983118},
	urldate = {2023-06-19},
	journal = {IEEE Access},
	author = {Hajek, Petr and Abedin, Mohammad Zoynul},
	year = {2020},
	pages = {58982--58994},
	file = {Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\GQ8R6H4L\\Hajek and Abedin - 2020 - A Profit Function-Maximizing Inventory Backorder P.pdf:application/pdf},
}

@misc{noauthor_data_nodate,
	title = {Data {Mining}: {Concepts} and {Techniques} - 3rd {Edition}},
	url = {https://shop.elsevier.com/books/data-mining-concepts-and-techniques/han/978-0-12-381479-1},
	urldate = {2023-06-19},
	file = {Data Mining\: Concepts and Techniques - 3rd Edition:C\:\\Users\\abrar\\Zotero\\storage\\BX4QELWI\\978-0-12-381479-1.html:text/html},
}

@misc{noauthor_data_nodate-1,
	title = {Data {Mining}: {Concepts} and {Techniques} - 3rd {Edition}},
	url = {https://shop.elsevier.com/books/data-mining-concepts-and-techniques/han/978-0-12-381479-1},
	urldate = {2023-06-19},
	file = {Data Mining\: Concepts and Techniques - 3rd Edition:C\:\\Users\\abrar\\Zotero\\storage\\KFAHYYXR\\978-0-12-381479-1.html:text/html},
}

@article{hardgrave_does_2009,
	title = {Does {RFID} improve inventory accuracy? {A} preliminary analysis},
	volume = {1},
	issn = {1754-5730, 1754-5749},
	shorttitle = {Does {RFID} improve inventory accuracy?},
	url = {http://www.tandfonline.com/doi/abs/10.1080/17545730802338333},
	doi = {10.1080/17545730802338333},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {International Journal of RF Technologies: Research and Applications},
	author = {Hardgrave, Bill C. and Aloysius, John and Goyal, Sandeep},
	month = mar,
	year = {2009},
	pages = {44--56},
}

@article{hassanzadeh_framework_2009,
	title = {Framework for evaluating clustering algorithms in duplicate detection},
	volume = {2},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/1687627.1687771},
	doi = {10.14778/1687627.1687771},
	abstract = {The presence of duplicate records is a major data quality concern in large databases. To detect duplicates,
              entity resolution
              also known as
              duplication detection
              or
              record linkage
              is used as a part of the data cleaning process to identify records that potentially refer to the same real-world entity. We present the Stringer system that provides an evaluation framework for understanding what barriers remain towards the goal of truly scalable and general purpose duplication detection algorithms. In this paper, we use Stringer to evaluate the quality of the clusters (groups of potential duplicates) obtained from several unconstrained clustering algorithms used in concert with approximate join techniques. Our work is motivated by the recent significant advancements that have made approximate join algorithms highly scalable. Our extensive evaluation reveals that some clustering algorithms that have never been considered for duplicate detection, perform extremely well in terms of both accuracy and scalability.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Proceedings of the VLDB Endowment},
	author = {Hassanzadeh, Oktie and Chiang, Fei and Lee, Hyun Chul and Miller, Renée J.},
	month = aug,
	year = {2009},
	pages = {1282--1293},
	file = {Hassanzadeh et al. - 2009 - Framework for evaluating clustering algorithms in .pdf:C\:\\Users\\abrar\\Zotero\\storage\\TWLSMEYJ\\Hassanzadeh et al. - 2009 - Framework for evaluating clustering algorithms in .pdf:application/pdf},
}

@article{hazen_back_2018,
	title = {Back in business: operations research in support of big data analytics for operations and supply chain management},
	volume = {270},
	issn = {0254-5330, 1572-9338},
	shorttitle = {Back in business},
	url = {http://link.springer.com/10.1007/s10479-016-2226-0},
	doi = {10.1007/s10479-016-2226-0},
	language = {en},
	number = {1-2},
	urldate = {2023-06-19},
	journal = {Annals of Operations Research},
	author = {Hazen, Benjamin T. and Skipper, Joseph B. and Boone, Christopher A. and Hill, Raymond R.},
	month = nov,
	year = {2018},
	pages = {201--211},
}

@article{durbin_letter_1975,
	title = {Letter: {Acid} secretion by gastric mucous membrane},
	volume = {229},
	issn = {0002-9513},
	shorttitle = {Letter},
	doi = {10.1152/ajplegacy.1975.229.6.1726},
	language = {eng},
	number = {6},
	journal = {The American Journal of Physiology},
	author = {Durbin, R. P.},
	month = dec,
	year = {1975},
	pmid = {2020},
	keywords = {Hydrogen-Ion Concentration, Methods, Animals, Gastric Juice, Gastric Mucosa},
	pages = {1726},
}

@article{anderson_maturation_1975,
	title = {Maturation of the adrenal medulla--{IV}. {Effects} of morphine},
	volume = {24},
	issn = {1873-2968},
	doi = {10.1016/0006-2952(75)90020-9},
	language = {eng},
	number = {16},
	journal = {Biochemical Pharmacology},
	author = {Anderson, T. R. and Slotkin, T. A.},
	month = aug,
	year = {1975},
	pmid = {7},
	keywords = {In Vitro Techniques, Animals, Adrenal Medulla, Aging, Animals, Newborn, Body Weight, Catecholamines, Dopamine beta-Hydroxylase, Epinephrine, Female, Humans, Maternal-Fetal Exchange, Metaraminol, Morphine, Morphine Dependence, Pregnancy, Rats, Tyrosine 3-Monooxygenase},
	pages = {1469--1474},
}

@article{ho_measuring_2007,
	title = {Measuring system performance of an {ERP}-based supply chain},
	volume = {45},
	issn = {0020-7543, 1366-588X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00207540600635235},
	doi = {10.1080/00207540600635235},
	language = {en},
	number = {6},
	urldate = {2023-06-19},
	journal = {International Journal of Production Research},
	author = {Ho, Chrwan-Jyh},
	month = mar,
	year = {2007},
	pages = {1255--1277},
}

@article{holmqvist_smart_2006,
	title = {‘{SMART} {GOODS}’ {AND} {MOBILE} {RFID} {A} {CASE} {WITH} {INNOVATION} {FROM} {VOLVO}},
	volume = {27},
	issn = {07353766},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/j.2158-1592.2006.tb00225.x},
	doi = {10.1002/j.2158-1592.2006.tb00225.x},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {Journal of Business Logistics},
	author = {Holmqvist, Magnus and Stefansson, Gunnar},
	month = sep,
	year = {2006},
	pages = {251--272},
}

@incollection{hutchison_svm_2005,
	address = {Berlin, Heidelberg},
	title = {A {SVM} {Regression} {Based} {Approach} to {Filling} in {Missing} {Values}},
	volume = {3683},
	isbn = {978-3-540-28896-1 978-3-540-31990-0},
	url = {http://link.springer.com/10.1007/11553939_83},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Knowledge-{Based} {Intelligent} {Information} and {Engineering} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Honghai, Feng and Guoshun, Chen and Cheng, Yin and Bingru, Yang and Yumei, Chen},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Khosla, Rajiv and Howlett, Robert J. and Jain, Lakhmi C.},
	year = {2005},
	doi = {10.1007/11553939_83},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {581--587},
}

@article{javed_feature_2012,
	title = {Feature {Selection} {Based} on {Class}-{Dependent} {Densities} for {High}-{Dimensional} {Binary} {Data}},
	volume = {24},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/5677524/},
	doi = {10.1109/TKDE.2010.263},
	number = {3},
	urldate = {2023-06-19},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Javed, Kashif and Babri, Haroon A. and Saeed, Mehreen},
	month = mar,
	year = {2012},
	pages = {465--477},
}

@misc{javeri_improving_2021,
	title = {Improving {Neural} {Networks} for {Time} {Series} {Forecasting} using {Data} {Augmentation} and {AutoML}},
	url = {http://arxiv.org/abs/2103.01992},
	abstract = {Statistical methods such as the Box-Jenkins method for time-series forecasting have been prominent since their development in 1970. Many researchers rely on such models as they can be efficiently estimated and also provide interpretability. However, advances in machine learning research indicate that neural networks can be powerful data modeling techniques, as they can give higher accuracy for a plethora of learning problems and datasets. In the past, they have been tried on time-series forecasting as well, but their overall results have not been significantly better than the statistical models especially for intermediate length times series data. Their modeling capacities are limited in cases where enough data may not be available to estimate the large number of parameters that these non-linear models require. This paper presents an easy to implement data augmentation method to significantly improve the performance of such networks. Our method, Augmented-Neural-Network, which involves using forecasts from statistical models, can help unlock the power of neural networks on intermediate length time-series and produces competitive results. It shows that data augmentation, when paired with Automated Machine Learning techniques such as Neural Architecture Search, can help to find the best neural architecture for a given time-series. Using the combination of these, demonstrates significant enhancement in the forecasting accuracy of three neural network-based models for a COVID-19 dataset, with a maximum improvement in forecasting accuracy by 21.41\%, 24.29\%, and 16.42\%, respectively, over the neural networks that do not use augmented data.},
	urldate = {2023-06-19},
	publisher = {arXiv},
	author = {Javeri, Indrajeet Y. and Toutiaee, Mohammadhossein and Arpinar, Ismailcem B. and Miller, Tom W. and Miller, John A.},
	month = may,
	year = {2021},
	note = {arXiv:2103.01992 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Applications, Statistics - Methodology},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\XAUP7S6D\\Javeri et al. - 2021 - Improving Neural Networks for Time Series Forecast.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\FD5KGQJB\\2103.html:text/html},
}

@article{jensen_fuzzy-rough_2007,
	title = {Fuzzy-{Rough} {Sets} {Assisted} {Attribute} {Selection}},
	volume = {15},
	issn = {1063-6706},
	url = {http://ieeexplore.ieee.org/document/4088988/},
	doi = {10.1109/TFUZZ.2006.889761},
	number = {1},
	urldate = {2023-06-19},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Jensen, Richard and Shen, Qiang},
	month = feb,
	year = {2007},
	pages = {73--89},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\CJA3WRGC\\Jensen and Shen - 2007 - Fuzzy-Rough Sets Assisted Attribute Selection.pdf:application/pdf},
}

@article{hardgrave_does_2009-1,
	title = {Does {RFID} improve inventory accuracy? {A} preliminary analysis},
	volume = {1},
	issn = {1754-5730, 1754-5749},
	shorttitle = {Does {RFID} improve inventory accuracy?},
	url = {http://www.tandfonline.com/doi/abs/10.1080/17545730802338333},
	doi = {10.1080/17545730802338333},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {International Journal of RF Technologies: Research and Applications},
	author = {Hardgrave, Bill C. and Aloysius, John and Goyal, Sandeep},
	month = mar,
	year = {2009},
	pages = {44--56},
}

@article{durbin_letter_1975-1,
	title = {Letter: {Acid} secretion by gastric mucous membrane},
	volume = {229},
	issn = {0002-9513},
	shorttitle = {Letter},
	doi = {10.1152/ajplegacy.1975.229.6.1726},
	language = {eng},
	number = {6},
	journal = {The American Journal of Physiology},
	author = {Durbin, R. P.},
	month = dec,
	year = {1975},
	pmid = {2020},
	keywords = {Hydrogen-Ion Concentration, Methods, Animals, Gastric Juice, Gastric Mucosa},
	pages = {1726},
}

@article{anderson_maturation_1975-1,
	title = {Maturation of the adrenal medulla--{IV}. {Effects} of morphine},
	volume = {24},
	issn = {1873-2968},
	doi = {10.1016/0006-2952(75)90020-9},
	language = {eng},
	number = {16},
	journal = {Biochemical Pharmacology},
	author = {Anderson, T. R. and Slotkin, T. A.},
	month = aug,
	year = {1975},
	pmid = {7},
	keywords = {In Vitro Techniques, Animals, Adrenal Medulla, Aging, Animals, Newborn, Body Weight, Catecholamines, Dopamine beta-Hydroxylase, Epinephrine, Female, Humans, Maternal-Fetal Exchange, Metaraminol, Morphine, Morphine Dependence, Pregnancy, Rats, Tyrosine 3-Monooxygenase},
	pages = {1469--1474},
}

@article{ho_measuring_2007-1,
	title = {Measuring system performance of an {ERP}-based supply chain},
	volume = {45},
	issn = {0020-7543, 1366-588X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00207540600635235},
	doi = {10.1080/00207540600635235},
	language = {en},
	number = {6},
	urldate = {2023-06-19},
	journal = {International Journal of Production Research},
	author = {Ho, Chrwan-Jyh},
	month = mar,
	year = {2007},
	pages = {1255--1277},
}

@article{holmqvist_smart_2006-1,
	title = {‘{SMART} {GOODS}’ {AND} {MOBILE} {RFID} {A} {CASE} {WITH} {INNOVATION} {FROM} {VOLVO}},
	volume = {27},
	issn = {07353766},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/j.2158-1592.2006.tb00225.x},
	doi = {10.1002/j.2158-1592.2006.tb00225.x},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {Journal of Business Logistics},
	author = {Holmqvist, Magnus and Stefansson, Gunnar},
	month = sep,
	year = {2006},
	pages = {251--272},
}

@incollection{joachims_making_1999,
	address = {Cambridge, MA, USA},
	title = {Making large-scale support vector machine learning practical},
	isbn = {978-0-262-19416-7},
	urldate = {2023-06-19},
	booktitle = {Advances in kernel methods: support vector learning},
	publisher = {MIT Press},
	author = {Joachims, Thorsten},
	month = feb,
	year = {1999},
	pages = {169--184},
}

@techreport{john_cross-validated_1994,
	address = {Stanford, CA, USA},
	title = {Cross-{Validated} {C4}.5: {Using} {Error} {Estimation} for {Automatic} {Parameter} {Selection}},
	abstract = {Machine learning algorithms for supervised learning are in wide use. An important issue in the use of these algorithms is how to set the parameters of the algorithm. While the default parameter values may be appropriate for a wide variety of tasks, they are not necessarily optimal for a given task. In this paper, we investigate the use of cross-validation to select parameters for the C4.5 decision tree learning algorithm. Experimental results on ve datasets show that when cross-validation is applied to selecting an important parameter for C4.5, the accuracy of the induced trees on independent test sets is generally higher than the accuracy when using the default paramter value.},
	language = {en},
	institution = {Stanford University},
	author = {John, George H},
	year = {1994},
	pages = {1--4},
	file = {John - Cross-Validated C4.5 Using Error Estimation for A.pdf:C\:\\Users\\abrar\\Zotero\\storage\\Y3VH9LJT\\John - Cross-Validated C4.5 Using Error Estimation for A.pdf:application/pdf},
}

@article{kalousis_stability_2007,
	title = {Stability of feature selection algorithms: a study on high-dimensional spaces},
	volume = {12},
	issn = {0219-1377, 0219-3116},
	shorttitle = {Stability of feature selection algorithms},
	url = {https://link.springer.com/10.1007/s10115-006-0040-8},
	doi = {10.1007/s10115-006-0040-8},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Knowledge and Information Systems},
	author = {Kalousis, Alexandros and Prados, Julien and Hilario, Melanie},
	month = may,
	year = {2007},
	pages = {95--116},
	file = {Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\MW3CHP9N\\Kalousis et al. - 2007 - Stability of feature selection algorithms a study.pdf:application/pdf},
}

@article{kang_information_2005,
	title = {Information inaccuracy in inventory systems: stock loss and stockout},
	volume = {37},
	issn = {0740-817X, 1545-8830},
	shorttitle = {Information inaccuracy in inventory systems},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07408170590969861},
	doi = {10.1080/07408170590969861},
	language = {en},
	number = {9},
	urldate = {2023-06-19},
	journal = {IIE Transactions},
	author = {Kang, Yun and Gershwin, Stanley B.},
	month = sep,
	year = {2005},
	pages = {843--859},
}

@misc{karingula_boosted_2021,
	title = {Boosted {Embeddings} for {Time} {Series} {Forecasting}},
	url = {http://arxiv.org/abs/2104.04781},
	doi = {10.48550/arXiv.2104.04781},
	abstract = {Time series forecasting is a fundamental task emerging from diverse data-driven applications. Many advanced autoregressive methods such as ARIMA were used to develop forecasting models. Recently, deep learning based methods such as DeepAr, NeuralProphet, Seq2Seq have been explored for time series forecasting problem. In this paper, we propose a novel time series forecast model, DeepGB. We formulate and implement a variant of Gradient boosting wherein the weak learners are DNNs whose weights are incrementally found in a greedy manner over iterations. In particular, we develop a new embedding architecture that improves the performance of many deep learning models on time series using Gradient boosting variant. We demonstrate that our model outperforms existing comparable state-of-the-art models using real-world sensor data and public dataset.},
	urldate = {2023-06-19},
	publisher = {arXiv},
	author = {Karingula, Sankeerth Rao and Ramanan, Nandini and Tahmasbi, Rasool and Amjadi, Mehrnaz and Jung, Deokwoo and Si, Ricky and Thimmisetty, Charanraj and Cabrera, Luisa Polania and Sayer, Marjorie and Coelho Jr, Claudionor Nunes},
	month = jul,
	year = {2021},
	note = {arXiv:2104.04781 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, I.2},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\7SWG6VCS\\Karingula et al. - 2021 - Boosted Embeddings for Time Series Forecasting.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\NUKTV6LK\\2104.html:text/html},
}

@article{kilimci_improved_2019,
	title = {An {Improved} {Demand} {Forecasting} {Model} {Using} {Deep} {Learning} {Approach} and {Proposed} {Decision} {Integration} {Strategy} for {Supply} {Chain}},
	volume = {2019},
	issn = {1076-2787, 1099-0526},
	url = {https://www.hindawi.com/journals/complexity/2019/9067367/},
	doi = {10.1155/2019/9067367},
	abstract = {Demand forecasting is one of the main issues of supply chains. It aimed to optimize stocks, reduce costs, and increase sales, profit, and customer loyalty. For this purpose, historical data can be analyzed to improve demand forecasting by using various methods like machine learning techniques, time series analysis, and deep learning models. In this work, an intelligent demand forecasting system is developed. This improved model is based on the analysis and interpretation of the historical data by using different forecasting methods which include time series analysis techniques, support vector regression algorithm, and deep learning models. To the best of our knowledge, this is the first study to blend the deep learning methodology, support vector regression algorithm, and different time series analysis models by a novel decision integration strategy for demand forecasting approach. The other novelty of this work is the adaptation of boosting ensemble strategy to demand forecasting system by implementing a novel decision integration model. The developed system is applied and tested on real life data obtained from SOK Market in Turkey which operates as a fast-growing company with 6700 stores, 1500 products, and 23 distribution centers. A wide range of comparative and extensive experiments demonstrate that the proposed demand forecasting system exhibits noteworthy results compared to the state-of-art studies. Unlike the state-of-art studies, inclusion of support vector regression, deep learning model, and a novel integration strategy to the proposed forecasting system ensures significant accuracy improvement.},
	language = {en},
	urldate = {2023-06-19},
	journal = {Complexity},
	author = {Kilimci, Zeynep Hilal and Akyuz, A. Okay and Uysal, Mitat and Akyokus, Selim and Uysal, M. Ozan and Atak Bulbul, Berna and Ekmis, Mehmet Ali},
	month = mar,
	year = {2019},
	pages = {1--15},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\5ESMQDVF\\Kilimci et al. - 2019 - An Improved Demand Forecasting Model Using Deep Le.pdf:application/pdf},
}

@incollection{kohavi_automatic_1995,
	address = {San Francisco (CA)},
	title = {Automatic {Parameter} {Selection} by {Minimizing} {Estimated} {Error}},
	isbn = {978-1-55860-377-6},
	url = {https://www.sciencedirect.com/science/article/pii/B9781558603776500451},
	abstract = {We address the problem of finding the parameter settings that will result in optimal performance of a given learning algorithm using a particular dataset as training data. We describe a “wrapper” method, considering determination of the best parameters as a discrete function optimization problem. The method uses best-first search and crossvalidation to wrap around the basic induction algorithm: the search explores the space of parameter values, running the basic algorithm many times on training and holdout sets produced by crossvalidation to get an estimate of the expected error of each parameter setting. Thus, the final selected parameter settings are tuned for the specific induction algorithm and dataset being studied. We report experiments with this method on 33 datasets selected from the UCI and StatLog collections using C4.5 as the basic induction algorithm. At a 90\% confidence level, our method improves the performance of C4.5 on nine domains, degrades performance on one, and is statistically indistinguishable from C4.5 on the rest. On the sample of datasets used for comparison, our method yields an average 13\% relative decrease in error rate. We expect to see similar performance improvements when using our method with other machine learning algorithms.},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Machine {Learning} {Proceedings} 1995},
	publisher = {Morgan Kaufmann},
	author = {Kohavi, Ron and John, George H.},
	editor = {Prieditis, Armand and Russell, Stuart},
	month = jan,
	year = {1995},
	doi = {10.1016/B978-1-55860-377-6.50045-1},
	pages = {304--312},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\6D444BHS\\B9781558603776500451.html:text/html},
}

@inproceedings{kumar_jha_time_2021,
	address = {Erode, India},
	title = {Time {Series} {Forecasting} {Model} for {Supermarket} {Sales} using {FB}-{Prophet}},
	isbn = {978-1-66540-360-3},
	url = {https://ieeexplore.ieee.org/document/9418033/},
	doi = {10.1109/ICCMC51019.2021.9418033},
	urldate = {2023-06-19},
	booktitle = {2021 5th {International} {Conference} on {Computing} {Methodologies} and {Communication} ({ICCMC})},
	publisher = {IEEE},
	author = {Kumar Jha, Bineet and Pande, Shilpa},
	month = apr,
	year = {2021},
	pages = {547--554},
}

@article{kuo_integration_2016,
	title = {Integration of fuzzy neural network and artificial immune system-based back-propagation neural network for sales forecasting using qualitative and quantitative data},
	volume = {27},
	issn = {0956-5515, 1572-8145},
	url = {http://link.springer.com/10.1007/s10845-014-0944-1},
	doi = {10.1007/s10845-014-0944-1},
	language = {en},
	number = {6},
	urldate = {2023-06-19},
	journal = {Journal of Intelligent Manufacturing},
	author = {Kuo, R. J. and Tseng, Y. S. and Chen, Zhen-Yao},
	month = dec,
	year = {2016},
	pages = {1191--1207},
}

@article{kwak_input_2002,
	title = {Input feature selection for classification problems},
	volume = {13},
	issn = {10459227},
	url = {http://ieeexplore.ieee.org/document/977291/},
	doi = {10.1109/72.977291},
	number = {1},
	urldate = {2023-06-19},
	journal = {IEEE Transactions on Neural Networks},
	author = {Kwak, N. and {Chong-Ho Choi}},
	month = jan,
	year = {2002},
	pages = {143--159},
}

@article{kwak_input_2002-1,
	title = {Input feature selection by mutual information based on {Parzen} window},
	volume = {24},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/1114861/},
	doi = {10.1109/TPAMI.2002.1114861},
	language = {en},
	number = {12},
	urldate = {2023-06-19},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Kwak, N. and {Chong-Ho Choi}},
	month = dec,
	year = {2002},
	pages = {1667--1671},
}

@article{li_greedy_2018,
	title = {A greedy aggregation–decomposition method for intermittent demand forecasting in fashion retailing},
	volume = {269},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221718301449},
	doi = {10.1016/j.ejor.2018.02.029},
	language = {en},
	number = {3},
	urldate = {2023-06-19},
	journal = {European Journal of Operational Research},
	author = {Li, Chongshou and Lim, Andrew},
	month = sep,
	year = {2018},
	pages = {860--869},
}

@misc{noauthor_statistical_nodate,
	title = {Statistical {Analysis} with {Missing} {Data}, 2nd {Edition} {\textbar} {Wiley}},
	url = {https://www.wiley.com/en-us/Statistical+Analysis+with+Missing+Data%2C+2nd+Edition-p-9781119013563},
	abstract = {* Emphasizes the latest trends in the field. * Includes a new chapter on evolving methods. * Provides updated or revised material in most of the chapters.},
	language = {en-us},
	urldate = {2023-06-19},
	journal = {Wiley.com},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\9UTPE7KJ\\Statistical+Analysis+with+Missing+Data,+2nd+Edition-p-9781119013563.html:text/html},
}

@misc{noauthor_statistical_nodate-1,
	title = {Statistical {Analysis} with {Missing} {Data}, 2nd {Edition} {\textbar} {Wiley}},
	url = {https://www.wiley.com/en-us/Statistical+Analysis+with+Missing+Data%2C+2nd+Edition-p-9781119013563},
	abstract = {* Emphasizes the latest trends in the field. * Includes a new chapter on evolving methods. * Provides updated or revised material in most of the chapters.},
	language = {en-us},
	urldate = {2023-06-19},
	journal = {Wiley.com},
}

@misc{noauthor_statistical_nodate-2,
	title = {Statistical {Analysis} with {Missing} {Data}, 2nd {Edition} {\textbar} {Wiley}},
	url = {https://www.wiley.com/en-us/Statistical+Analysis+with+Missing+Data%2C+2nd+Edition-p-9781119013563},
	abstract = {* Emphasizes the latest trends in the field. * Includes a new chapter on evolving methods. * Provides updated or revised material in most of the chapters.},
	language = {en-us},
	urldate = {2023-06-19},
	journal = {Wiley.com},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\JVTWYAGN\\Statistical+Analysis+with+Missing+Data,+2nd+Edition-p-9781119013563.html:text/html},
}

@article{liu_no_2002,
	title = {[{No} title found]},
	volume = {6},
	issn = {13845810},
	url = {http://link.springer.com/10.1023/A:1016304305535},
	doi = {10.1023/A:1016304305535},
	number = {4},
	urldate = {2023-06-19},
	journal = {Data Mining and Knowledge Discovery},
	author = {Liu, Huan and Hussain, Farhad and Tan, Chew Lim and Dash, Manoranjan},
	year = {2002},
	pages = {393--423},
}

@article{liu_no_2002-1,
	title = {[{No} title found]},
	volume = {6},
	issn = {13845810},
	url = {http://link.springer.com/10.1023/A:1016304305535},
	doi = {10.1023/A:1016304305535},
	number = {4},
	urldate = {2023-06-19},
	journal = {Data Mining and Knowledge Discovery},
	author = {Liu, Huan and Hussain, Farhad and Tan, Chew Lim and Dash, Manoranjan},
	year = {2002},
	pages = {393--423},
}

@article{liu_discretization_2002,
	title = {Discretization: {An} {Enabling} {Technique}},
	volume = {6},
	issn = {1573-756X},
	shorttitle = {Discretization},
	url = {https://doi.org/10.1023/A:1016304305535},
	doi = {10.1023/A:1016304305535},
	abstract = {Discrete values have important roles in data mining and knowledge discovery. They are about intervals of numbers which are more concise to represent and specify, easier to use and comprehend as they are closer to a knowledge-level representation than continuous values. Many studies show induction tasks can benefit from discretization: rules with discrete values are normally shorter and more understandable and discretization can lead to improved predictive accuracy. Furthermore, many induction algorithms found in the literature require discrete features. All these prompt researchers and practitioners to discretize continuous features before or during a machine learning or data mining task. There are numerous discretization methods available in the literature. It is time for us to examine these seemingly different methods for discretization and find out how different they really are, what are the key components of a discretization process, how we can improve the current level of research for new development as well as the use of existing methods. This paper aims at a systematic study of discretization methods with their history of development, effect on classification, and trade-off between speed and accuracy. Contributions of this paper are an abstract description summarizing existing discretization methods, a hierarchical framework to categorize the existing methods and pave the way for further development, concise discussions of representative discretization methods, extensive experiments and their analysis, and some guidelines as to how to choose a discretization method under various circumstances. We also identify some issues yet to solve and future research for discretization.},
	language = {en},
	number = {4},
	urldate = {2023-06-19},
	journal = {Data Mining and Knowledge Discovery},
	author = {Liu, Huan and Hussain, Farhad and Tan, Chew Lim and Dash, Manoranjan},
	month = oct,
	year = {2002},
	keywords = {data mining, classification, continuous feature, discretization},
	pages = {393--423},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\H5IYZXL5\\Liu et al. - 2002 - Discretization An Enabling Technique.pdf:application/pdf},
}

@article{liu_feature_2009,
	title = {Feature selection with dynamic mutual information},
	volume = {42},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320308004615},
	doi = {10.1016/j.patcog.2008.10.028},
	abstract = {Feature selection plays an important role in data mining and pattern recognition, especially for large scale data. During past years, various metrics have been proposed to measure the relevance between different features. Since mutual information is nonlinear and can effectively represent the dependencies of features, it is one of widely used measurements in feature selection. Just owing to these, many promising feature selection algorithms based on mutual information with different parameters have been developed. In this paper, at first a general criterion function about mutual information in feature selector is introduced, which can bring most information measurements in previous algorithms together. In traditional selectors, mutual information is estimated on the whole sampling space. This, however, cannot exactly represent the relevance among features. To cope with this problem, the second purpose of this paper is to propose a new feature selection algorithm based on dynamic mutual information, which is only estimated on unlabeled instances. To verify the effectiveness of our method, several experiments are carried out on sixteen UCI datasets using four typical classifiers. The experimental results indicate that our algorithm achieved better results than other methods in most cases.},
	language = {en},
	number = {7},
	urldate = {2023-06-19},
	journal = {Pattern Recognition},
	author = {Liu, Huawen and Sun, Jigui and Liu, Lei and Zhang, Huijie},
	month = jul,
	year = {2009},
	keywords = {Classification, Mutual information, Feature selection, Filter method},
	pages = {1330--1339},
}

@article{locke_new_2006,
	title = {New {Directions} in {Goal}-{Setting} {Theory}},
	volume = {17},
	issn = {0963-7214},
	url = {https://doi.org/10.1111/j.1467-8721.2006.00449.x},
	doi = {10.1111/j.1467-8721.2006.00449.x},
	abstract = {Goal-setting theory is summarized regarding the effectiveness of specific, difficult goals; the relationship of goals to affect; the mediators of goal effects; the relation of goals to self-efficacy; the moderators of goal effects; and the generality of goal effects across people, tasks, countries, time spans, experimental designs, goal sources (i.e., self-set, set jointly with others, or assigned), and dependent variables. Recent studies concerned with goal choice and the factors that influence it, the function of learning goals, the effect of goal framing, goals and affect (well-being), group goal setting, goals and traits, macro-level goal setting, and conscious versus subconscious goals are described. Suggestions are given for future research.},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {Current Directions in Psychological Science},
	author = {Locke, Edwin A. and Latham, Gary P.},
	month = oct,
	year = {2006},
	note = {Publisher: SAGE Publications Inc},
	pages = {265--268},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\847WLTKH\\Locke and Latham - 2006 - New Directions in Goal-Setting Theory.pdf:application/pdf},
}

@article{lopez-arevalo_memory-efficient_2020,
	title = {A {Memory}-{Efficient} {Encoding} {Method} for {Processing} {Mixed}-{Type} {Data} on {Machine} {Learning}},
	volume = {22},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/22/12/1391},
	doi = {10.3390/e22121391},
	abstract = {The most common machine-learning methods solve supervised and unsupervised problems based on datasets where the problem’s features belong to a numerical space. However, many problems often include data where numerical and categorical data coexist, which represents a challenge to manage them. To transform categorical data into a numeric form, preprocessing tasks are compulsory. Methods such as one-hot and feature-hashing have been the most widely used encoding approaches at the expense of a significant increase in the dimensionality of the dataset. This effect introduces unexpected challenges to deal with the overabundance of variables and/or noisy data. In this regard, in this paper we propose a novel encoding approach that maps mixed-type data into an information space using Shannon’s Theory to model the amount of information contained in the original data. We evaluated our proposal with ten mixed-type datasets from the UCI repository and two datasets representing real-world problems obtaining promising results. For demonstrating the performance of our proposal, this was applied for preparing these datasets for classification, regression, and clustering tasks. We demonstrate that our encoding proposal is remarkably superior to one-hot and feature-hashing encoding in terms of memory efficiency. Our proposal can preserve the information conveyed by the original data.},
	language = {en},
	number = {12},
	urldate = {2023-06-19},
	journal = {Entropy},
	author = {Lopez-Arevalo, Ivan and Aldana-Bobadilla, Edwin and Molina-Villegas, Alejandro and Galeana-Zapién, Hiram and Muñiz-Sanchez, Victor and Gausin-Valle, Saul},
	month = dec,
	year = {2020},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {categorical data, data preprocessing, machine learning},
	pages = {1391},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\N7XU24EC\\Lopez-Arevalo et al. - 2020 - A Memory-Efficient Encoding Method for Processing .pdf:application/pdf},
}

@misc{loshchilov_cma-es_2016,
	title = {{CMA}-{ES} for {Hyperparameter} {Optimization} of {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1604.07269},
	doi = {10.48550/arXiv.1604.07269},
	abstract = {Hyperparameters of deep neural networks are often optimized by grid search, random search or Bayesian optimization. As an alternative, we propose to use the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), which is known for its state-of-the-art performance in derivative-free optimization. CMA-ES has some useful invariance properties and is friendly to parallel evaluations of solutions. We provide a toy example comparing CMA-ES and state-of-the-art Bayesian optimization algorithms for tuning the hyperparameters of a convolutional neural network for the MNIST dataset on 30 GPUs in parallel.},
	urldate = {2023-06-19},
	publisher = {arXiv},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = apr,
	year = {2016},
	note = {arXiv:1604.07269 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\HTMMFWYF\\Loshchilov and Hutter - 2016 - CMA-ES for Hyperparameter Optimization of Deep Neu.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\P7VN9SUA\\1604.html:text/html},
}

@article{maccarthy_supply_2016,
	title = {Supply chain evolution – theory, concepts and science},
	volume = {36},
	issn = {0144-3577},
	url = {https://doi.org/10.1108/IJOPM-02-2016-0080},
	doi = {10.1108/IJOPM-02-2016-0080},
	abstract = {Purpose Supply chains evolve and change in size, shape and configuration, and in how they are coordinated, controlled and managed. Some supply chains are mature and relatively unchanging. Some are subject to significant change. New supply chains may emerge and evolve for a variety of reasons. The purpose of this paper is to examine the nature of supply chain evolution and address the question “What makes a supply chain like it is?” Design/methodology/approach The paper analyses and develops key aspects, concepts and principal themes concerning the emergence and evolution of supply chains over their lifecycle. Findings The paper defines the supply chain lifecycle and identifies six factors that interact and may affect a supply chain over its lifecycle – technology and innovation, economics, markets and competition, policy and regulation, procurement and sourcing, supply chain strategies and re-engineering. A number of emergent themes and propositions on factors affecting a supply chain’s characteristics over its lifecycle are presented. The paper argues that a new science is needed to investigate and understand the supply chain lifecycle. Practical implications Supply chains are critical for the world economy and essential for modern life. Understanding the supply chain lifecycle and how supply chains evolve provides new perspectives for contemporary supply chain design and management. Originality/value The paper presents detailed analysis, critique and reflections from leading researchers on emerging, evolving and mature supply chains.},
	number = {12},
	urldate = {2023-06-19},
	journal = {International Journal of Operations \& Production Management},
	author = {MacCarthy, Bart L. and Blome, Constantin and Olhager, Jan and Srai, Jagjit Singh and Zhao, Xiande},
	month = jan,
	year = {2016},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Differentiation, Emergence, Evolution, Life cycle, Segmentation, Supply Chain},
	pages = {1696--1718},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\CTBMW5DF\\MacCarthy et al. - 2016 - Supply chain evolution – theory, concepts and scie.pdf:application/pdf},
}

@article{mitra_unsupervised_2002,
	title = {Unsupervised feature selection using feature similarity},
	volume = {24},
	issn = {1939-3539},
	doi = {10.1109/34.990133},
	abstract = {In this article, we describe an unsupervised feature selection algorithm suitable for data sets, large in both dimension and size. The method is based on measuring similarity between features whereby redundancy therein is removed. This does not need any search and, therefore, is fast. A new feature similarity measure, called maximum information compression index, is introduced. The algorithm is generic in nature and has the capability of multiscale representation of data sets. The superiority of the algorithm, in terms of speed and performance, is established extensively over various real-life data sets of different sizes and dimensions. It is also demonstrated how redundancy and information loss in feature selection can be quantified with an entropy measure.},
	number = {3},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Mitra, P. and Murthy, C.A. and Pal, S.K.},
	month = mar,
	year = {2002},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Entropy, Loss measurement},
	pages = {301--312},
}

@article{modha_feature_2003,
	title = {Feature {Weighting} in k-{Means} {Clustering}},
	volume = {52},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1024016609528},
	doi = {10.1023/A:1024016609528},
	abstract = {Data sets with multiple, heterogeneous feature spaces occur frequently. We present an abstract framework for integrating multiple feature spaces in the k-means clustering algorithm. Our main ideas are (i) to represent each data object as a tuple of multiple feature vectors, (ii) to assign a suitable (and possibly different) distortion measure to each feature space, (iii) to combine distortions on different feature spaces, in a convex fashion, by assigning (possibly) different relative weights to each, (iv) for a fixed weighting, to cluster using the proposed convex k-means algorithm, and (v) to determine the optimal feature weighting to be the one that yields the clustering that simultaneously minimizes the average within-cluster dispersion and maximizes the average between-cluster dispersion along all the feature spaces. Using precision/recall evaluations and known ground truth classifications, we empirically demonstrate the effectiveness of feature weighting in clustering on several different application domains.},
	language = {en},
	number = {3},
	urldate = {2023-06-19},
	journal = {Machine Learning},
	author = {Modha, Dharmendra S. and Spangler, W. Scott},
	month = sep,
	year = {2003},
	keywords = {feature selection, text mining, clustering, convex k-means algorithm, convexity, feature combination, Fisher's discriminant analysis, unsupervised learning},
	pages = {217--237},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\JV5J26VN\\Modha and Spangler - 2003 - Feature Weighting in k-Means Clustering.pdf:application/pdf},
}

@book{little_statistical_1987,
	title = {Statistical {Analysis} {With} {Missing} {Data}},
	isbn = {978-0-471-80254-9},
	abstract = {Acknowledged experts on the subject bring together diverse sources on methods for statistical analysis of data sets with missing values, a pervasive problem for which standard methods are of limited value. Blending theory and application, it reviews historical approaches to the subject, and rigorous yet simple methods for multivariate analysis with missing values. Goes on to provide a coherent theory for analysis of problems based on likelihoods derived from statistical models for the data and the missing data mechanism. The theory is applied to a wide range of important missing-data problems. Extensive references, examples, and exercises.},
	language = {en},
	publisher = {Wiley},
	author = {Little, Roderick J. A. and Rubin, Donald B.},
	month = may,
	year = {1987},
	note = {Google-Books-ID: w40QAQAAIAAJ},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
}

@article{minnich_supply_nodate,
	title = {Supply {Chain} {Responsiveness} and {Efficiency} – {Complementing} or {Contradicting} {Each} {Other}?},
	abstract = {Balancing responsiveness to market requirements with overall efficiency is an important issue in supply chain design and management. The objective of the system dynamics model introduced in this paper is to capture generic structures and the intrinsic dynamic behaviour modes of supply chains considering aspects of responsiveness and efficiency. The research strives for a better understanding of these aspects: what are the structural consequences of implementing strategies striving for efficiency or responsiveness in the real world, and how can they be represented in a System Dynamics model? Furthermore, simulations will be used to assess the dynamic consequences of these different strategic alternatives. Future research will then focus on identifying policies to balance responsiveness and efficiency in a specific industry and by that resolve the trade-off between the two.},
	language = {en},
	author = {Minnich, Dennis and Maier, Frank H},
	file = {Minnich and Maier - Supply Chain Responsiveness and Efficiency – Compl.pdf:C\:\\Users\\abrar\\Zotero\\storage\\DI7ZMW62\\Minnich and Maier - Supply Chain Responsiveness and Efficiency – Compl.pdf:application/pdf},
}

@inproceedings{minnich_supply_2006,
	title = {Supply {Chain} {Responsiveness} and {Efficiency} – {Complementing} or {Contradicting} {Each} {Other} ?},
	url = {https://www.semanticscholar.org/paper/Supply-Chain-Responsiveness-and-Efficiency-%E2%80%93-or-Minnich-Maier/ac570a977dba95a48d073b43b0ef1d9e82d06604},
	abstract = {Balancing responsiveness to market requirements with overall efficiency is an important issue in supply chain design and management. The objective of the system dynamics model introduced in this paper is to capture generic structures and the intrinsic dynamic behaviour modes of supply chains considering aspects of responsiveness and efficiency. The research strives for a better understanding of these aspects: what are the structural consequences of implementing strategies striving for efficiency or responsiveness in the real world, and how can they be represented in a System Dynamics model? Furthermore, simulations will be used to assess the dynamic consequences of these different strategic alternatives. Future research will then focus on identifying policies to balance responsiveness and efficiency in a specific industry and by that resolve the trade-off between the two.},
	urldate = {2023-06-19},
	author = {Minnich, D. and Maier, Frank H.},
	year = {2006},
}

@book{michie_machine_1995,
	address = {USA},
	title = {Machine learning, neural and statistical classification},
	isbn = {978-0-13-106360-0},
	publisher = {Ellis Horwood},
	editor = {Michie, Donald and Spiegelhalter, D. J. and Taylor, C. C. and Campbell, John},
	month = may,
	year = {1995},
}

@inproceedings{monge_field_1996,
	address = {Portland, Oregon},
	series = {{KDD}'96},
	title = {The field matching problem: {Algorithms} and applications},
	shorttitle = {The field matching problem},
	abstract = {To combine information from heterogeneous sources, equivalent data in the multiple sources must be identified. This task is the field matching problem. Specifically, the task is to determine whether or not two syntactic values are alternative designations of the same semantic entity. For example the addresses Dept. of Comput. Sci. and Eng., University of California, San Diego, 9500 Gilman Dr. Dept. 0114, La Jolla. CA 92093 and UCSD, Computer Science and Engineering Department, CA 92093-0114 do designate the same department. This paper describes three field matching algorithms, and evaluates their performance on real-world datasets. One proposed method is the well-known Smith-Waterman algorithm for comparing DNA and protein sequences. Several applications of field matching in knowledge discovery are described briefly, including WEBFIND, which is a new software tool that discovers scientific papers published on the worldwide web. WEBFIND uses external information sources to guide its search for authors and papers. Like many other worldwide web tools, WEBFIND needs to solve the field matching problem in order to navigate between information sources.},
	urldate = {2023-06-19},
	booktitle = {Proceedings of the {Second} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {AAAI Press},
	author = {Monge, Alvaro E. and Elkan, Charles P.},
	month = aug,
	year = {1996},
	pages = {267--270},
}

@article{rabbitt_there_2001,
	title = {There are stable individual differences in performance variability, both from moment to moment and from day to day},
	volume = {54},
	issn = {0272-4987},
	url = {https://doi.org/10.1080/713756013},
	doi = {10.1080/713756013},
	abstract = {Individual differences in decision speed have been regarded as direct reflections of a “primitiv” functional neurophysiological characteristic, which affects performance on all cognitive tasks and so may be regarded as the “biological basis of intelligence”, or of age-related changes in mental abilities. More detailed analyses show that variability within an experimental session (WSV) is a stable individual difference characteristic and that mean choice reaction times (CRTs) are gross summary statistics that reflect variability, rather than maximum speed of performance. A total of 98 people aged from 60 to 80 years completed 36 weekly sessions on six different letter categorization tasks. After effects of practice and of circadian variability had been eliminated, individuals with lower scores on the Cattell Culture Fair intelligence test had slower CRTs and greater WSV on all tasks. A simulation study showed that the greater WSVs of low Cattell scorers led directly to the significantly greater variability of their mean CRTs from session to session. However because CRTs on tasks co-varied from session to session it was apparent that, besides being affected by WSV, individuals’ between-session variabilities (BSVs) also vary because of state changes that affect their performance from day to day. It seems that both variability in performance from trial to trial during a session and variability in average performance from day to day are correlated, stable, individual difference characteristics that vary inversely with intelligence test performance. Methodological consequences of these results for interpretations of age-related cognitive changes, for variability between as well as within individuals, for individual differences in decision speed, and for circadian variability in performance are discussed.},
	language = {en},
	number = {4},
	urldate = {2023-06-19},
	journal = {The Quarterly Journal of Experimental Psychology Section A},
	author = {Rabbitt, Patrick and Osman, Paul and Moore, Belinda and Stollery, Brian},
	month = nov,
	year = {2001},
	note = {Publisher: SAGE Publications},
	pages = {981--1003},
}

@article{neely_performance_1995,
	title = {Performance measurement system design: {A} literature review and research agenda},
	volume = {15},
	issn = {0144-3577},
	shorttitle = {Performance measurement system design},
	url = {https://doi.org/10.1108/01443579510083622},
	doi = {10.1108/01443579510083622},
	abstract = {The importance of performance measurement has long been recognized by academics and practitioners from a variety of functional disciplines. Seeks to bring together this diverse body of knowledge into a coherent whole. To ensure that the key issues are identified, focuses on the process of performance measurement system design, rather than the detail of specific measures. Following a comprehensive review of the literature, proposes a research agenda.},
	number = {4},
	urldate = {2023-06-19},
	journal = {International Journal of Operations \& Production Management},
	author = {Neely, Andy and Gregory, Mike and Platts, Ken},
	month = jan,
	year = {1995},
	note = {Publisher: MCB UP Ltd},
	keywords = {Activity‐based costing, Management, Manufacturing strategy, Operations management, Performance management, Production management, Systems design},
	pages = {80--116},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\NUEPMJNC\\html.html:text/html},
}

@inproceedings{noack_simulation_2008,
	title = {A simulation based optimization algorithm for slack reduction and workforce scheduling},
	doi = {10.1109/WSC.2008.4736293},
	abstract = {In an assembly line with high labor proportion, the workforce planning and scheduling is a very complex problem. At the background of increasing labor costs, it is very important to increase workforce efficiency. It is essential for companies to remain competitive on global markets. Increasing efficiency is our motivation to work on simulation-based workforce scheduling for complex assembly lines. In this paper, we will focus on the heuristic algorithm in our simulation-based optimization approach. The objective is workforce quantity and slack reduction. To improve the objective, an algorithm assigns the number of workers for activities, scheduled in the simulation run. We will present three different strategies implemented in these optimization algorithms. They basically use the performance indicator slack time, work center utilization and a mix of both parameters. We will compare the algorithms according to their achieved objective and the required computation time.},
	booktitle = {2008 {Winter} {Simulation} {Conference}},
	author = {Noack, Daniel and Rose, Oliver},
	month = dec,
	year = {2008},
	note = {ISSN: 1558-4305},
	keywords = {Heuristic algorithms, Computational modeling, Security, Assembly, Delay, Job shop scheduling, Process planning, Processor scheduling, Production facilities, Scheduling algorithm},
	pages = {1989--1994},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\FW3ZCP5M\\Noack and Rose - 2008 - A simulation based optimization algorithm for slac.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\abrar\\Zotero\\storage\\TVFM8VUJ\\4736293.html:text/html},
}

@article{peng_feature_2005,
	title = {Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy},
	volume = {27},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2005.159},
	abstract = {Feature selection is an important problem for pattern classification systems. We study how to select good features according to the maximal statistical dependency criterion based on mutual information. Because of the difficulty in directly implementing the maximal dependency condition, we first derive an equivalent form, called minimal-redundancy-maximal-relevance criterion (mRMR), for first-order incremental feature selection. Then, we present a two-stage feature selection algorithm by combining mRMR and other more sophisticated feature selectors (e.g., wrappers). This allows us to select a compact set of superior features at very low cost. We perform extensive experimental comparison of our algorithm and other methods using three different classifiers (naive Bayes, support vector machine, and linear discriminate analysis) and four different data sets (handwritten digits, arrhythmia, NCI cancer cell lines, and lymphoma tissues). The results confirm that mRMR leads to promising improvement on feature selection and classification accuracy.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Peng, Hanchuan and Long, Fuhui and Ding, C.},
	month = aug,
	year = {2005},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Performance analysis, Mutual information, Algorithm design and analysis, Cancer, classification., Costs, Diversity reception, Index Terms- Feature selection, maximal dependency, maximal relevance, minimal redundancy, mutual information, Pattern classification, Redundancy, Support vector machine classification, Support vector machines},
	pages = {1226--1238},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\abrar\\Zotero\\storage\\VNACC5E2\\1453511.html:text/html},
}

@article{potdar_comparative_2017,
	title = {A {Comparative} {Study} of {Categorical} {Variable} {Encoding} {Techniques} for {Neural} {Network} {Classifiers}},
	volume = {175},
	url = {https://www.ijcaonline.org/archives/volume175/number4/28474-2017915495},
	abstract = {IJCA is a computer science and electronics journal related with Theoretical Informatics, Quantum Computing, Software Testing, Computer Vision, Digital Systems, Pervasive Computing, Computational Topology etc.},
	language = {en-gb},
	number = {4},
	urldate = {2023-06-19},
	journal = {International Journal of Computer Applications},
	author = {Potdar, Kedar and Pardawala, Taher S. and Pai, Chinmay D.},
	month = oct,
	year = {2017},
	note = {Publisher: Foundation of Computer Science (FCS), NY, USA},
	pages = {7--9},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\CJZQ7IBA\\Potdar et al. - 2017 - A Comparative Study of Categorical Variable Encodi.pdf:application/pdf},
}

@article{robnik-sikonja_theoretical_2003,
	title = {Theoretical and {Empirical} {Analysis} of {ReliefF} and {RReliefF}},
	volume = {53},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1025667309714},
	doi = {10.1023/A:1025667309714},
	abstract = {Relief algorithms are general and successful attribute estimators. They are able to detect conditional dependencies between attributes and provide a unified view on the attribute estimation in regression and classification. In addition, their quality estimates have a natural interpretation. While they have commonly been viewed as feature subset selection methods that are applied in prepossessing step before a model is learned, they have actually been used successfully in a variety of settings, e.g., to select splits or to guide constructive induction in the building phase of decision or regression tree learning, as the attribute weighting method and also in the inductive logic programming.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Machine Learning},
	author = {Robnik-Šikonja, Marko and Kononenko, Igor},
	month = oct,
	year = {2003},
	keywords = {feature selection, classification, attribute evaluation, regression, Relief algorithm},
	pages = {23--69},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\PWJNTPLV\\Robnik-Šikonja and Kononenko - 2003 - Theoretical and Empirical Analysis of ReliefF and .pdf:application/pdf},
}

@article{roweis_nonlinear_2000,
	title = {Nonlinear {Dimensionality} {Reduction} by {Locally} {Linear} {Embedding}},
	volume = {290},
	url = {https://www.science.org/doi/10.1126/science.290.5500.2323},
	doi = {10.1126/science.290.5500.2323},
	abstract = {Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.},
	number = {5500},
	urldate = {2023-06-19},
	journal = {Science},
	author = {Roweis, Sam T. and Saul, Lawrence K.},
	month = dec,
	year = {2000},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {2323--2326},
}

@book{varela_rozados_big_2014,
	title = {Big {Data} {Analytics} in {Supply} {Chain} {Management}: {Trends} and {Related} {Research}},
	shorttitle = {Big {Data} {Analytics} in {Supply} {Chain} {Management}},
	abstract = {Big Data Analytics offers vast prospects in today's business transformation. Whilst big data have remarkably captured the attentions of both practitioners and researchers especially in the financial services and marketing sectors, there is a myriad of premises that big data analytics can play even more crucial roles in Supply Chain Management (SCM). This paper therefore intends to explore these premises. The investigation ranges from the fundamentals of big data analytics, its taxonomy and the level of maturity of big data analytics solutions in each of them, to implementation issues and best practices. Finally, some examples of advanced analytics applications will also be presented as a way of unveiling some of the relatively unexplored territories in big data analytics research.},
	author = {Varela Rozados, Ivan and Tjahjono, Benny},
	month = dec,
	year = {2014},
	doi = {10.13140/RG.2.1.4935.2563},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\PUJVKEM3\\Varela Rozados and Tjahjono - 2014 - Big Data Analytics in Supply Chain Management Tre.pdf:application/pdf},
}

@article{saeys_review_2007,
	title = {A review of feature selection techniques in bioinformatics},
	volume = {23},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/btm344},
	doi = {10.1093/bioinformatics/btm344},
	abstract = {Feature selection techniques have become an apparent need in many bioinformatics applications. In addition to the large pool of techniques that have already been developed in the machine learning and data mining fields, specific applications in bioinformatics have led to a wealth of newly proposed techniques.In this article, we make the interested reader aware of the possibilities of feature selection, providing a basic taxonomy of feature selection techniques, and discussing their use, variety and potential in a number of both common as well as upcoming bioinformatics applications.Contact:  yvan.saeys@psb.ugent.beSupplementary information:  http://bioinformatics.psb.ugent.be/supplementary\_data/yvsae/fsreview},
	number = {19},
	urldate = {2023-06-19},
	journal = {Bioinformatics},
	author = {Saeys, Yvan and Inza, Iñaki and Larrañaga, Pedro},
	month = oct,
	year = {2007},
	pages = {2507--2517},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\RU767A74\\Saeys et al. - 2007 - A review of feature selection techniques in bioinf.pdf:application/pdf;Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\8PPWKWQC\\185254.html:text/html},
}

@article{safarishahrbijari_workforce_2018,
	title = {Workforce forecasting models: {A} systematic review},
	volume = {37},
	copyright = {© 2018 John Wiley \& Sons, Ltd.},
	issn = {1099-131X},
	shorttitle = {Workforce forecasting models},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/for.2541},
	doi = {10.1002/for.2541},
	abstract = {Workforce analytics involves using models that integrate internal and external data to predict future workforce and help organizations in any industry examine factors that have a prognostic effect. This paper assesses workforce modeling and prediction methods by examining their rationale, strengths, and constraints. It aims to identify enhancements for further development of workforce forecasting models and compares the capacity and reliability of different forecasting methods. Past and present modeling trends are described and critiqued based on their relevance to current requirements. Several approaches are reviewed, such as time series modeling and system dynamics simulation. Sensitivity analysis in models is assessed. The models are decomposed into three modes: supply-based, demand-based, and need-based, which in some cases provide substantially different estimates of future workforce need. The chronological progression of models' development is analyzed. The articles are also classified based on the countries and the sectors that have paid great attention to workforce prediction research. Consideration of the use of workforce models and the inputs into such models is not within the scope of this paper.},
	language = {en},
	number = {7},
	urldate = {2023-06-19},
	journal = {Journal of Forecasting},
	author = {Safarishahrbijari, Anahita},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/for.2541},
	keywords = {labor forecasting, manpower planning, organizational studies, workforce, workforce modeling},
	pages = {739--753},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\FZY4P3P6\\Safarishahrbijari - 2018 - Workforce forecasting models A systematic review.pdf:application/pdf;Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\HJ35TBQ2\\for.html:text/html},
}

@article{sanders_how_2016,
	title = {How to {Use} {Big} {Data} to {Drive} {Your} {Supply} {Chain}},
	volume = {58},
	issn = {0008-1256},
	url = {https://doi.org/10.1525/cmr.2016.58.3.26},
	doi = {10.1525/cmr.2016.58.3.26},
	abstract = {Big data analytics has become an imperative for business leaders across every industry sector. Analytics applications that can deliver a competitive advantage appear all along the supply chain decision spectrum—from targeted location-based marketing to optimizing supply chain inventories to enabling supplier risk assessment. While many companies have used it to extract new insights and create new forms of value, other companies have yet to leverage big data to transform their supply chain operations. This article examines how leading companies use big data analytics to drive their supply chains and offers a framework for implementation based on lessons learned.},
	language = {en},
	number = {3},
	urldate = {2023-06-19},
	journal = {California Management Review},
	author = {Sanders, Nada R.},
	month = may,
	year = {2016},
	note = {Publisher: SAGE Publications Inc},
	pages = {26--48},
}

@article{schliephake_making_2009,
	series = {Advances in {Life}-{Cycle} {Approaches} to {Business} and {Resource} {Management} in the {Asia}-{Pacific} {Region}},
	title = {Making resources work more efficiently – the importance of supply chain partnerships},
	volume = {17},
	issn = {0959-6526},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652609001085},
	doi = {10.1016/j.jclepro.2009.03.020},
	abstract = {State and federal governments in Australia have implemented a range of assistance programs for manufacturing industries to become more resource efficient and reduce waste. While many of these programs focus on Cleaner Production at single sites, an increasing number of assistance programs are offered across supply chains. Sustainability Victoria, a Victorian government authority, supports projects that focus on resource efficiencies across supply chains in key industry sectors. In this study, tools were adapted and utilised to identify efficiency potentials and losses across supply chains in the timber furniture manufacturing and the food industry sector. In this respect, waste generation and value loss due to inefficient use of critical materials within the processes were estimated from purchase and waste handling data. Primary companies were chosen to undertake efficiency trials that could demonstrate value gain across the supply chain. This study describes the realisation of greater efficiencies in material usage when engaging proactively with supply chain partners immediately adjacent to the primary company. Demonstration trials confirmed that through a more integrated approach among supply chain partners the potential in using materials more efficiently and design processes can lead to enhanced productivity without compromising environmental burden. Hence, the study describes targeted resource efficiency, recycling and process optimisation opportunities as identified in the supply chain trials on timber furniture manufacturing and food industries.},
	language = {en},
	number = {14},
	urldate = {2023-06-19},
	journal = {Journal of Cleaner Production},
	author = {Schliephake, Kirsten and Stevens, Graeme and Clay, Simon},
	month = sep,
	year = {2009},
	keywords = {Food industry, Resource efficiency, Supply chain, Timber furniture industry, Waste minimisation},
	pages = {1257--1263},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\P7FIGUZ8\\S0959652609001085.html:text/html},
}

@inproceedings{siami-namini_comparison_2018,
	title = {A {Comparison} of {ARIMA} and {LSTM} in {Forecasting} {Time} {Series}},
	doi = {10.1109/ICMLA.2018.00227},
	abstract = {Forecasting time series data is an important subject in economics, business, and finance. Traditionally, there are several techniques to effectively forecast the next lag of time series data such as univariate Autoregressive (AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and more notably Autoregressive Integrated Moving Average (ARIMA) with its many variations. In particular, ARIMA model has demonstrated its outperformance in precision and accuracy of predicting the next lags of time series. With the recent advancement in computational power of computers and more importantly development of more advanced machine learning algorithms and approaches such as deep learning, new algorithms are developed to analyze and forecast time series data. The research question investigated in this article is that whether and how the newly developed deep learning-based algorithms for forecasting time series data, such as "Long Short-Term Memory (LSTM)", are superior to the traditional algorithms. The empirical studies conducted and reported in this article show that deep learning-based algorithms such as LSTM outperform traditional-based algorithms such as ARIMA model. More specifically, the average reduction in error rates obtained by LSTM was between 84 - 87 percent when compared to ARIMA indicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that the number of training times, known as "epoch" in deep learning, had no effect on the performance of the trained forecast model and it exhibited a truly random behavior.},
	booktitle = {2018 17th {IEEE} {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	author = {Siami-Namini, Sima and Tavakoli, Neda and Siami Namin, Akbar},
	month = dec,
	year = {2018},
	keywords = {Forecasting, Autoregressive processes, Data models, Deep learning, Deep Learning, Long Short-Term Memory (LSTM), Autoregressive Integrated Moving Average (ARIMA), Forecasting, Time Series Data, Economics, Predictive models, Time series analysis},
	pages = {1394--1401},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\abrar\\Zotero\\storage\\IYUAHQ3P\\8614252.html:text/html},
}

@article{swiniarski_rough_2003,
	title = {Rough set methods in feature selection and recognition},
	volume = {24},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865502001964},
	doi = {10.1016/S0167-8655(02)00196-4},
	abstract = {We present applications of rough set methods for feature selection in pattern recognition. We emphasize the role of the basic constructs of rough set approach in feature selection, namely reducts and their approximations, including dynamic reducts. In the overview of methods for feature selection we discuss feature selection criteria, including the rough set based methods. Our algorithm for feature selection is based on an application of a rough set method to the result of principal components analysis (PCA) used for feature projection and reduction. Finally, the paper presents numerical results of face and mammogram recognition experiments using neural network, with feature selection based on proposed PCA and rough set methods.},
	language = {en},
	number = {6},
	urldate = {2023-06-19},
	journal = {Pattern Recognition Letters},
	author = {Swiniarski, Roman W. and Skowron, Andrzej},
	month = mar,
	year = {2003},
	keywords = {Feature selection, Pattern recognition, Rough sets},
	pages = {833--849},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\H9WDL9VC\\S0167865502001964.html:text/html},
}

@article{strack_integrated_2010,
	title = {An integrated model for warehouse and inventory planning},
	volume = {204},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221709005670},
	doi = {10.1016/j.ejor.2009.09.006},
	abstract = {The purpose of this article is to evaluate the value of integrating tactical warehouse and inventory decisions. Therefore, a global warehouse and inventory model is presented and solved. In order to solve this mathematical model, two solution methodologies are developed which offer different level of integration of warehouse and inventory decisions. Computational tests are performed on a real world database using multiple scenarios differing by the warehouse capacity limits and the warehouse and inventory costs. Our observation is that the total cost of the inventory and warehouse systems can be reduced drastically by taking into account the warehouse capacity restrictions in the inventory planning decisions, in an aggregate way. Moreover additional inventory and warehouse savings can be achieved by using more sophisticated integration methods for inventory and warehouse decisions.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {European Journal of Operational Research},
	author = {Strack, Géraldine and Pochet, Yves},
	month = jul,
	year = {2010},
	keywords = {Integrated model, Lagrangian relaxation, Multi-item inventory model, Tactical warehouse model},
	pages = {35--50},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\H4E484ET\\S0377221709005670.html:text/html},
}

@inproceedings{sun_towards_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards a {Framework} for {Designing} {Full} {Model} {Selection} and {Optimization} {Systems}},
	isbn = {978-3-642-38067-9},
	doi = {10.1007/978-3-642-38067-9_23},
	abstract = {People from a variety of industrial domains are beginning to realise that appropriate use of machine learning techniques for their data mining projects could bring great benefits. End-users now have to face the new problem of how to choose a combination of data processing tools and algorithms for a given dataset. This problem is usually termed the Full Model Selection (FMS) problem. Extended from our previous work [10], in this paper, we introduce a framework for designing FMS algorithms. Under this framework, we propose a novel algorithm combining both genetic algorithms (GA) and particle swarm optimization (PSO) named GPS (which stands for GA-PSO-FMS), in which a GA is used for searching the optimal structure for a data mining solution, and PSO is used for searching optimal parameters for a particular structure instance. Given a classification dataset, GPS outputs a FMS solution as a directed acyclic graph consisting of diverse data mining operators that are available to the problem. Experimental results demonstrate the benefit of the algorithm. We also present, with detailed analysis, two model-tree-based variants for speeding up the GPS algorithm.},
	language = {en},
	booktitle = {Multiple {Classifier} {Systems}},
	publisher = {Springer},
	author = {Sun, Quan and Pfahringer, Bernhard and Mayo, Michael},
	editor = {Zhou, Zhi-Hua and Roli, Fabio and Kittler, Josef},
	year = {2013},
	keywords = {Binary Tree Structure, Genetic Algorithm Generation, Logistic Model Tree, Particle Swarm Optimization, Swarm Size},
	pages = {259--270},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\SNUI5VPG\\Sun et al. - 2013 - Towards a Framework for Designing Full Model Selec.pdf:application/pdf},
}

@article{sun_local-learning-based_2010,
	title = {Local-{Learning}-{Based} {Feature} {Selection} for {High}-{Dimensional} {Data} {Analysis}},
	volume = {32},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2009.190},
	abstract = {This paper considers feature selection for data classification in the presence of a huge number of irrelevant features. We propose a new feature-selection algorithm that addresses several major issues with prior work, including problems with algorithm implementation, computational complexity, and solution accuracy. The key idea is to decompose an arbitrarily complex nonlinear problem into a set of locally linear ones through local learning, and then learn feature relevance globally within the large margin framework. The proposed algorithm is based on well-established machine learning and numerical analysis techniques, without making any assumptions about the underlying data distribution. It is capable of processing many thousands of features within minutes on a personal computer while maintaining a very high accuracy that is nearly insensitive to a growing number of irrelevant features. Theoretical analyses of the algorithm's sample complexity suggest that the algorithm has a logarithmical sample complexity with respect to the number of features. Experiments on 11 synthetic and real-world data sets demonstrate the viability of our formulation of the feature-selection problem for supervised learning and the effectiveness of our algorithm.},
	number = {9},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Sun, Yijun and Todorovic, Sinisa and Goodison, Steve},
	month = sep,
	year = {2010},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Data analysis, Algorithm design and analysis, Support vector machine classification, Support vector machines, Feature selection, Machine learning, Machine learning algorithms, Computational complexity, {\textbackslash}ell\_1 regularization, local learning, logistical regression, Microcomputers, Numerical analysis, sample complexity., Sun},
	pages = {1610--1626},
	file = {Accepted Version:C\:\\Users\\abrar\\Zotero\\storage\\UJ7N2LV7\\Sun et al. - 2010 - Local-Learning-Based Feature Selection for High-Di.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\abrar\\Zotero\\storage\\4VL5PF6M\\5342431.html:text/html},
}

@article{tranfield_towards_2003,
	title = {Towards a {Methodology} for {Developing} {Evidence}-{Informed} {Management} {Knowledge} by {Means} of {Systematic} {Review}},
	volume = {14},
	issn = {1467-8551},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8551.00375},
	doi = {10.1111/1467-8551.00375},
	abstract = {Undertaking a review of the literature is an important part of any research project. The researcher both maps and assesses the relevant intellectual territory in order to specify a research question which will further develop the knowledge base. However, traditional ‘narrative’ reviews frequently lack thoroughness, and in many cases are not undertaken as genuine pieces of investigatory science. Consequently they can lack a means for making sense of what the collection of studies is saying. These reviews can be biased by the researcher and often lack rigour. Furthermore, the use of reviews of the available evidence to provide insights and guidance for intervention into operational needs of practitioners and policymakers has largely been of secondary importance. For practitioners, making sense of a mass of often-contradictory evidence has become progressively harder. The quality of evidence underpinning decision-making and action has been questioned, for inadequate or incomplete evidence seriously impedes policy formulation and implementation. In exploring ways in which evidence-informed management reviews might be achieved, the authors evaluate the process of systematic review used in the medical sciences. Over the last fifteen years, medical science has attempted to improve the review process by synthesizing research in a systematic, transparent, and reproducible manner with the twin aims of enhancing the knowledge base and informing policymaking and practice. This paper evaluates the extent to which the process of systematic review can be applied to the management field in order to produce a reliable knowledge stock and enhanced practice by developing context-sensitive research. The paper highlights the challenges in developing an appropriate methodology.},
	language = {en},
	number = {3},
	urldate = {2023-06-19},
	journal = {British Journal of Management},
	author = {Tranfield, David and Denyer, David and Smart, Palminder},
	year = {2003},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-8551.00375},
	pages = {207--222},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\IDBRFFNX\\Tranfield et al. - 2003 - Towards a Methodology for Developing Evidence-Info.pdf:application/pdf;Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\B8QSTCAC\\1467-8551.html:text/html},
}

@article{thatte_impact_2013,
	title = {Impact {Of} {SCM} {Practices} {Of} {A} {Firm} {On} {Supply} {Chain} {Responsiveness} {And} {Competitive} {Advantage} {Of} {A} {Firm}},
	volume = {29},
	copyright = {Copyright (c)},
	issn = {2157-8834},
	url = {https://clutejournals.com},
	doi = {10.19030/jabr.v29i2.7653},
	abstract = {Today’s supply chains are expected to respond rapidly, effectively, and efficiently to changes in the marketplace to sustain, succeed and create competitive advantage in this increasingly global marketplace by focusing on time, flexibility, and speed of response. The focus of this study is the supply chain responsiveness construct and a firm’s practices to respond to customer’s demands and constantly changing market conditions to create competitive advantage.   This research conceptualizes three dimensions of supply chain responsiveness and develops a reliable and valid instrument for measuring this construct. The study further tests the relationships between supply chain management (SCM) practices, supply chain responsiveness, and competitive advantage using structural equation modeling based on 294 responses from industry professionals in the manufacturing and supply chain area. Research findings point out that higher level of SCM practices can lead to improved supply chain responsiveness and enhanced competitive advantage of a firm. Also supply chain responsiveness can have a direct positive impact on competitive advantage of a firm.},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {Journal of Applied Business Research (JABR)},
	author = {Thatte, Ashish A. and Rao, Subba S. and Ragu-Nathan, T. S.},
	month = feb,
	year = {2013},
	note = {Number: 2},
	pages = {499--530},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\F7M7CDKM\\Thatte et al. - 2013 - Impact Of SCM Practices Of A Firm On Supply Chain .pdf:application/pdf},
}

@inproceedings{snoek_practical_2012,
	title = {Practical {Bayesian} {Optimization} of {Machine} {Learning} {Algorithms}},
	volume = {25},
	url = {https://proceedings.neurips.cc/paper/2012/hash/05311655a15b75fab86956663e1819cd-Abstract.html},
	abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a “black art” requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expert-level performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including Latent Dirichlet Allocation, Structured SVMs and convolutional neural networks.},
	urldate = {2023-06-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
	year = {2012},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\3DSFGVQW\\Snoek et al. - 2012 - Practical Bayesian Optimization of Machine Learnin.pdf:application/pdf},
}

@article{van_den_berg_literature_1999,
	title = {A literature survey on planning and control of warehousing systems},
	volume = {31},
	issn = {0740-817X},
	url = {https://doi.org/10.1080/07408179908969874},
	doi = {10.1080/07408179908969874},
	abstract = {We present a literature survey on methods and techniques for the planning and control of warehousing systems. Planning refers to management decisions that affect the intermediate term (one or multiple months), such as inventory management and storage location assignment. Control refers to the operational decisions that affect the short term (hours, day), such as routing, sequencing, scheduling and order-batching. Prior to the literature survey, we give an introduction into warehousing systems and a classification of warehouse management problems},
	number = {8},
	urldate = {2023-06-19},
	journal = {IIE Transactions},
	author = {van den BERG, JEROEN P.},
	month = aug,
	year = {1999},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/07408179908969874},
	pages = {751--762},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\H7DFHSRP\\van den BERG - 1999 - A literature survey on planning and control of war.pdf:application/pdf},
}

@article{vanpoucke_supply_2009,
	title = {Supply chain information flow strategies: an empirical taxonomy},
	volume = {29},
	issn = {0144-3577},
	shorttitle = {Supply chain information flow strategies},
	url = {https://doi.org/10.1108/01443570911005974},
	doi = {10.1108/01443570911005974},
	abstract = {Purpose – The purpose of this paper is to identify different information flow strategies to enhance integration in strategic alliances and studies these strategies with respect to contextual factors and the impact on performance. Design/methodology/approach – The paper examines empirical data gathered from 56 manufacturing companies, describing 112 supply chain relationships. An empirical taxonomy is created based on cluster analysis. Findings – Based on a parsimonious description of inter‐firm information flows in the literature and this paper's empirical findings, three types of alliances are identified: Silent; Communicative; and IT intensive. While Silent alliances have the poorest overall performance, substantial similarities are found between Communicative and IT intensive alliances. In particular, the analysis suggests that IT intensive alliances, albeit performing better on operational capabilities, are not performing better on relationship satisfaction compared to Communicative alliances. Additional analyses indicate that partners of an IT intensive alliance are substantially more interdependent and larger in size. Research limitations/implications – This research presents a taxonomy of information flow strategies in a supply chain context. This research is not describing causality, since the data are not longitudinal in nature. Practical implications – Managers need to selectively invest in IT according to an overall supply chain integration strategy, which also takes softer, less technological forms of integration into consideration. Originality/value – This research provides insight into inter‐firm information flows from a contingency perspective, recognizing heterogeneity of firms and supply chain practices.},
	number = {12},
	urldate = {2023-06-19},
	journal = {International Journal of Operations \& Production Management},
	author = {Vanpoucke, Evelyne and Boyer, Kenneth K. and Vereecke, Ann},
	month = jan,
	year = {2009},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Supply chain management, Communication technologies, Information transfer, Manufacturing industries, Strategic alliances},
	pages = {1213--1241},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\GEWKNVUD\\html.html:text/html;Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\XHCDA9TM\\Vanpoucke et al. - 2009 - Supply chain information flow strategies an empir.pdf:application/pdf},
}

@article{verykios_automating_2000,
	title = {Automating the approximate record-matching process},
	volume = {126},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S002002550000013X},
	doi = {10.1016/S0020-0255(00)00013-X},
	abstract = {Data quality has many dimensions one of which is accuracy. Accuracy is usually compromised by errors accidentally or intensionally introduced in a database system. These errors result in inconsistent, incomplete, or erroneous data elements. For example, a small variation in the representation of a data object, produces a unique instantiation of the object being represented. In order to improve the accuracy of the data stored in a database system, we need to compare them either with real-world counterparts or with other data stored in the same or a different system. In this paper, we address the problem of matching records which refer to the same entity by computing their similarity. Exact record matching has limited applicability in this context since even simple errors like character transpositions cannot be captured in the record-linking process. Our methodology deploys advanced data-mining techniques for dealing with the high computational and inferential complexity of approximate record matching.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Information Sciences},
	author = {Verykios, Vassilios S and Elmagarmid, Ahmed K and Houstis, Elias N},
	month = jul,
	year = {2000},
	pages = {83--98},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\U97TXJ4I\\S002002550000013X.html:text/html},
}

@article{waller_data_2013,
	title = {Data {Science}, {Predictive} {Analytics}, and {Big} {Data}: {A} {Revolution} {That} {Will} {Transform} {Supply} {Chain} {Design} and {Management}},
	volume = {34},
	copyright = {© Council of Supply Chain Management Professionals},
	issn = {2158-1592},
	shorttitle = {Data {Science}, {Predictive} {Analytics}, and {Big} {Data}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jbl.12010},
	doi = {10.1111/jbl.12010},
	abstract = {We illuminate the myriad of opportunities for research where supply chain management (SCM) intersects with data science, predictive analytics, and big data, collectively referred to as DPB. We show that these terms are not only becoming popular but are also relevant to supply chain research and education. Data science requires both domain knowledge and a broad set of quantitative skills, but there is a dearth of literature on the topic and many questions. We call for research on skills that are needed by SCM data scientists and discuss how such skills and domain knowledge affect the effectiveness of an SCM data scientist. Such knowledge is crucial to develop future supply chain leaders. We propose definitions of data science and predictive analytics as applied to SCM. We examine possible applications of DPB in practice and provide examples of research questions from these applications, as well as examples of research questions employing DPB that stem from management theories. Finally, we propose specific steps interested researchers can take to respond to our call for research on the intersection of SCM and DPB.},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {Journal of Business Logistics},
	author = {Waller, Matthew A. and Fawcett, Stanley E.},
	year = {2013},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jbl.12010},
	keywords = {big data, collaboration, data science, design, education, integration, logistics, predictive analytics, supply chain management},
	pages = {77--84},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\39YVUS47\\Waller and Fawcett - 2013 - Data Science, Predictive Analytics, and Big Data .pdf:application/pdf;Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\NVVBKU72\\jbl.html:text/html},
}

@article{waller_measuring_2006,
	title = {Measuring the impact of inaccurate inventory information on a retail outlet},
	volume = {17},
	issn = {0957-4093},
	url = {https://doi.org/10.1108/09574090610717527},
	doi = {10.1108/09574090610717527},
	abstract = {Purpose – This research aims to consider the impact of common inventory system inaccuracies that occur in retail outlets on the inventory levels, fill rate, and service level of those outlets by simulating daily customer demand and random error in the inventory system. Design/methodology/approach – The simulation experiments vary the amount of inventory system error, the frequency of inventory record error correction, the size of the daily demand, the number of days in the replenishment system's review interval, and the replenishment system's customer service level. Findings – Inventory system error and the frequency with which the error is corrected are statistically significant for fill rate and service level. Thus, inaccuracies in inventory levels affect a retail outlet's ability to service its customers, though at the single SKU level, the results do not indicate a practical impact due to countervailing effects. Practical implications – Retail outlets must be aware that error exists and can influence the behavior of their replenishment systems, but the overall impact may not be as significant as it might appear. Originality/value – This research extends prior work on the effects of inventory inaccuracies and clarifies the debate pertaining to their ultimate effects on retail performance outcomes.},
	number = {3},
	urldate = {2023-06-19},
	journal = {The International Journal of Logistics Management},
	author = {Waller, Matthew A. and Nachtmann, Heather and Hunter, Justin},
	month = jan,
	year = {2006},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Retailing, Simulation, Inventory},
	pages = {355--376},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\HCMLRVY9\\html.html:text/html},
}

@article{wan_similarity-based_2021,
	title = {Similarity-based sales forecasting using improved {ConvLSTM} and prophet},
	volume = {25},
	issn = {1088-467X},
	url = {https://content.iospress.com/articles/intelligent-data-analysis/ida205103},
	doi = {10.3233/IDA-205103},
	abstract = {Sales forecasting is an important part of e-commerce and is critical to smart business decisions. The traditional forecasting methods mainly focus on building a forecasting model, training the model through historical data, and then using it to forec},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {Intelligent Data Analysis},
	author = {Wan, Yongquan and Chen, Yizhou and Yan, Cairong and Zhang, Bofeng},
	month = jan,
	year = {2021},
	note = {Publisher: IOS Press},
	pages = {383--396},
}

@article{wang_m-gan-xgboost_2021,
	title = {M-{GAN}-{XGBOOST} model for sales prediction and precision marketing strategy making of each product in online stores},
	volume = {55},
	issn = {2514-9288},
	url = {https://doi.org/10.1108/DTA-11-2020-0286},
	doi = {10.1108/DTA-11-2020-0286},
	abstract = {Purpose The rapid development of e-commerce has brought not only great convenience to people but a great challenge to online stores. Phenomenon such as out of stock and slow sales has been common in recent years. These issues can be managed only when the occurrence of the sales volume is predicted in advance, and sufficient warnings can be executed in time. Thus, keeping in mind the importance of the sales prediction system, the purpose of this paper is to propose an effective sales prediction model and make digital marketing strategies with the machine learning model. Design/methodology/approach Based on the consumer purchasing behavior decision theory, we discuss the factors affecting product sales, including external factors, consumer perception, consumer potential purchase behavior and consumer traffic. Then we propose a sales prediction model, M-GNA-XGBOOST, using the time-series prediction that ensures the effective prediction of sales about each product in a short time on online stores based on the sales data in the previous term or month or year. The proposed M-GNA-XGBOOST model serves as an adaptive prediction model, for which the instant factors and the sales data of the previous period are the input, and the optimal computation is based on the proposed methodology. The adaptive prediction using the proposed model is developed based on the LSTM (Long Short-Term Memory), GAN (Generative Adversarial Networks) and XGBOOST (eXtreme Gradient Boosting). The model inherits the advantages among the algorithms with better accuracy and forecasts the sales of each product in the store with instant data characteristics for the first time. Findings The analysis using Jingdong dataset proves the effectiveness of the proposed prediction method. The effectiveness of the proposed method is enhanced and the accuracy that instant data as input is found to be better compared with the model that lagged data as input. The root means squared error and mean absolute error of the proposed model are found to be around 11.9 and 8.23. According to the sales prediction of each product, the resource can be arranged in advance, and the marketing strategy of product positioning, product display optimization, inventory management and product promotion is designed for online stores. Originality/value The paper proposes and implements a new model, M-GNA-XGBOOST, to predict sales of each product for online stores. Our work provides reference and enlightenment for the establishment of accurate sales-based digital marketing strategies for online stores.},
	number = {5},
	urldate = {2023-06-19},
	journal = {Data Technologies and Applications},
	author = {Wang, Song and Yang, Yang},
	month = jan,
	year = {2021},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Deep learning, Integration model, Neural network, Precision marketing strategy, Sales forecast, XGBOOST},
	pages = {749--770},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\IU2L6S2A\\Wang and Yang - 2021 - M-GAN-XGBOOST model for sales prediction and preci.pdf:application/pdf},
}

@article{wang_feature_2007,
	title = {Feature selection based on rough sets and particle swarm optimization},
	volume = {28},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865506002327},
	doi = {10.1016/j.patrec.2006.09.003},
	abstract = {We propose a new feature selection strategy based on rough sets and particle swarm optimization (PSO). Rough sets have been used as a feature selection method with much success, but current hill-climbing rough set approaches to feature selection are inadequate at finding optimal reductions as no perfect heuristic can guarantee optimality. On the other hand, complete searches are not feasible for even medium-sized datasets. So, stochastic approaches provide a promising feature selection mechanism. Like Genetic Algorithms, PSO is a new evolutionary computation technique, in which each potential solution is seen as a particle with a certain velocity flying through the problem space. The Particle Swarms find optimal regions of the complex search space through the interaction of individuals in the population. PSO is attractive for feature selection in that particle swarms will discover best feature combinations as they fly within the subset space. Compared with GAs, PSO does not need complex operators such as crossover and mutation, it requires only primitive and simple mathematical operators, and is computationally inexpensive in terms of both memory and runtime. Experimentation is carried out, using UCI data, which compares the proposed algorithm with a GA-based approach and other deterministic rough set reduction algorithms. The results show that PSO is efficient for rough set-based feature selection.},
	language = {en},
	number = {4},
	urldate = {2023-06-19},
	journal = {Pattern Recognition Letters},
	author = {Wang, Xiangyang and Yang, Jie and Teng, Xiaolong and Xia, Weijun and Jensen, Richard},
	month = mar,
	year = {2007},
	keywords = {Feature selection, Genetic algorithms, Rough sets, Hill-climbing method, Particle swarm optimization, Reduct, Stochastic method},
	pages = {459--471},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\QU6VGT63\\S0167865506002327.html:text/html;Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\FS9T9FC2\\Wang et al. - 2007 - Feature selection based on rough sets and particle.pdf:application/pdf},
}

@article{wei_feature_2007,
	title = {Feature {Subset} {Selection} and {Ranking} for {Data} {Dimensionality} {Reduction}},
	volume = {29},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2007.250607},
	abstract = {A new unsupervised forward orthogonal search (FOS) algorithm is introduced for feature selection and ranking. In the new algorithm, features are selected in a stepwise way, one at a time, by estimating the capability of each specified candidate feature subset to represent the overall features in the measurement space. A squared correlation function is employed as the criterion to measure the dependency between features and this makes the new algorithm easy to implement. The forward orthogonalization strategy, which combines good effectiveness with high efficiency, enables the new algorithm to produce efficient feature subsets with a clear physical interpretation},
	number = {1},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Wei, Hua-liang and Billings, Stephen A.},
	month = jan,
	year = {2007},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Data mining, Information analysis, Principal component analysis, Support vector machines, Feature extraction, feature selection, Dimensionality reduction, Extraterrestrial measurements, high-dimensional data., Inspection, Libraries, Time measurement, Unsupervised learning},
	pages = {162--166},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\7HWWLN8U\\Wei and Billings - 2007 - Feature Subset Selection and Ranking for Data Dime.pdf:application/pdf},
}

@article{wei_research_2021,
	title = {Research on sales {Forecast} based on {XGBoost}-{LSTM} algorithm {Model}},
	volume = {1754},
	issn = {1742-6596},
	url = {https://dx.doi.org/10.1088/1742-6596/1754/1/012191},
	doi = {10.1088/1742-6596/1754/1/012191},
	abstract = {Reasonable sales forecast is very important for enterprises. The short-term and long-term sales changes of a product are helpful for enterprises to make marketing strategies and sales decisions. On the basis of in-depth analysis of the characteristics of a certain algorithm model and long and short memory neural network, and according to the data set provided by a supermarket chain in kaggle competition, a XGBoost-LSTM neural network combination model for sales forecasting and a classical time series prediction model are constructed to compare the experimental results. The experimental results show that the XGBoost-LSTM neural network prediction model has higher accuracy than the time series prediction model, which can provide an important scientific basis for the supermarket chain to make sales forecast.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Journal of Physics: Conference Series},
	author = {Wei, He and Zeng, QingTao},
	month = feb,
	year = {2021},
	note = {Publisher: IOP Publishing},
	pages = {012191},
	file = {IOP Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\C9KFQT67\\Wei and Zeng - 2021 - Research on sales Forecast based on XGBoost-LSTM a.pdf:application/pdf},
}

@article{wieland_selecting_2013,
	title = {Selecting the right supply chain based on risks},
	volume = {24},
	issn = {1741-038X},
	url = {https://doi.org/10.1108/17410381311327954},
	doi = {10.1108/17410381311327954},
	abstract = {Purpose – The purpose of this paper is to propose a model that enables a company to select the supply chain strategy based on risk probability p (measure of how likely/often a detrimental event occurs) and risk impact i (expression of the significance of a loss when that event occurs). Design/methodology/approach – This paper discusses four supply chain strategies: agility, robustness, resilience and rigidity. Mathematical models are used for the strategies' cost functions, which reveal optimal solutions and break‐even points in dependence of p and i. Findings – This paper proposes that resilience is appropriate in the case of high supply chain risk probability and impact, and rigidity if both values are low. When only risk impact is low, robustness is optimal, whereas agility is optimal when only risk probability is low. Research limitations/implications – This research extends existing models for selecting the appropriate supply chain strategy. Practical implications – Knowledge of the interplay between the strategies' cost functions and risk probability and risk impact is vital for companies. This may encourage managers to become more familiar with their strategy costs and supply chain risks. Originality/value – To the author's knowledge, no corresponding model exists so far that links risk impact and risk probability to the four supply chain strategies.},
	number = {5},
	urldate = {2023-06-19},
	journal = {Journal of Manufacturing Technology Management},
	author = {Wieland, Andreas},
	month = jan,
	year = {2013},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Strategy, Agility, Resilience, Risk management, Robustness, Supply chain management},
	pages = {652--668},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\826HN7WD\\html.html:text/html},
}

@inproceedings{wilson_beyond_2011,
	title = {Beyond probabilistic record linkage: {Using} neural networks and complex features to improve genealogical record linkage},
	shorttitle = {Beyond probabilistic record linkage},
	doi = {10.1109/IJCNN.2011.6033192},
	abstract = {Probabilistic record linkage has been used for many years in a variety of industries, including medical, government, private sector and research groups. The formulas used for probabilistic record linkage have been recognized by some as being equivalent to the naïve Bayes classifier. While this method can produce useful results, it is not difficult to improve accuracy by using one of a host of other machine learning or neural network algorithms. Even a simple single-layer perceptron tends to outperform the naïve Bayes classifier-and thus traditional probabilistic record linkage methods-by a substantial margin. Furthermore, many record linkage system use simple field comparisons rather than more complex features, partially due to the limits of the probabilistic formulas they use. This paper presents an overview of probabilistic record linkage, shows how to cast it in machine learning terms, and then shows that it is equivalent to a naïve Bayes classifier. It then discusses how to use more complex features than simple field comparisons, and shows how probabilistic record linkage formulas can be modified to handle this. Finally, it demonstrates a huge improvement in accuracy through the use of neural networks and higher-level matching features, compared to traditional probabilistic record linkage on a large (80,000 pair) set of labeled pairs of genealogical records used by FamilySearch.org.},
	booktitle = {The 2011 {International} {Joint} {Conference} on {Neural} {Networks}},
	author = {Wilson, D. Randall},
	month = jul,
	year = {2011},
	note = {ISSN: 2161-4407},
	keywords = {Classification algorithms, Neural networks, Accuracy, Couplings, Training, Fires, Probabilistic logic},
	pages = {9--14},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\945IK7U3\\Wilson - 2011 - Beyond probabilistic record linkage Using neural .pdf:application/pdf},
}

@article{yang_stock_2021,
	title = {Stock {Price} {Prediction} {Based} on {XGBoost} and {LightGBM}},
	volume = {275},
	copyright = {© The Authors, published by EDP Sciences, 2021},
	issn = {2267-1242},
	url = {https://www.e3s-conferences.org/articles/e3sconf/abs/2021/51/e3sconf_eilcd2021_01040/e3sconf_eilcd2021_01040.html},
	doi = {10.1051/e3sconf/202127501040},
	abstract = {Stock trading, as a kind of high frequency trading, generally seeks profits in extremely short market changes. And effective stock price forecasting can help investors obtain higher returns. Based on the data set provided by Jane Street, this paper makes use of XGBoost model and LightGBM model to realize the prediction of stock price. Since the given training set has a large amount of data and includes abnormal data such as missing value, we first carry out feature engineering processing on the original data and take the mean value of the missing value, so as to obtain the preprocessed data that can be used in modeling.The experimental results show that the combined model of XGBoost and LightGBM has better prediction performance than the single model and neural network.},
	language = {en},
	urldate = {2023-06-19},
	journal = {E3S Web of Conferences},
	author = {Yang, Yue and Wu, Yang and Wang, Peikun and Jiali, Xu},
	year = {2021},
	note = {Publisher: EDP Sciences},
	pages = {01040},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\VZ3TLF6C\\Yang et al. - 2021 - Stock Price Prediction Based on XGBoost and LightG.pdf:application/pdf},
}

@article{wu_examination_2005,
	title = {An examination of variability and its basic properties for a factory},
	volume = {18},
	issn = {1558-2345},
	doi = {10.1109/TSM.2004.840525},
	abstract = {Variability is a key performance index of a factory. In order to characterize variability of a factory, definitions of bottleneck, utilization, and variability of a single machine are reexamined and clarified. The clarification leads to the introduction of a detail expression for the relationship between cycle time and work-in-progress. In order to quantify variability for factories, the author uses a single machine system to gauge the behaviors, and subsequently derives an explicit expression for the variability, of a simple factory, making use of analogy and the clarified definitions. The obtained results can be applied to many subjects in the field of manufacturing management, such as factory performance analysis, capacity planning, and cycle time reduction. With the derived results, properties of variability for a simple factory in the aspects of utilization versus throughput bottlenecks and nonthroughput bottlenecks, gap effects, and bounds on variability, are examined in detail to shed light on the insights of the stochastic behaviors of a complex factory.},
	number = {1},
	journal = {IEEE Transactions on Semiconductor Manufacturing},
	author = {Wu, Kan},
	month = feb,
	year = {2005},
	note = {Conference Name: IEEE Transactions on Semiconductor Manufacturing},
	keywords = {Performance analysis, Investments, Productivity, Production management, Production facilities, Bottleneck, Capacity planning, performance, Production equipment, Semiconductor device manufacture, Stochastic processes, Throughput, utilization, variability},
	pages = {214--221},
	file = {Accepted Version:C\:\\Users\\abrar\\Zotero\\storage\\R7F35D2V\\Wu - 2005 - An examination of variability and its basic proper.pdf:application/pdf},
}

@article{yu_data-driven_2018,
	title = {Data-driven supply chain capabilities and performance: {A} resource-based view},
	volume = {114},
	issn = {1366-5545},
	shorttitle = {Data-driven supply chain capabilities and performance},
	url = {https://www.sciencedirect.com/science/article/pii/S1366554516300795},
	doi = {10.1016/j.tre.2017.04.002},
	abstract = {Despite the importance and relevance of data-driven supply chains, there has been very limited empirical research that investigates how big data-driven supply chains affect supply chain capabilities. Drawing on the resource-based view, this study explores the effect of data-driven supply chain capabilities on financial performance. The data for this study were gathered from China’s manufacturing industry and analysed using structural equation modelling. The results indicate that a data-driven supply chain has a significant positive effect on the four dimensions of supply chain capabilities. Coordination and supply chain responsiveness are positively and significantly related to financial performance.},
	language = {en},
	urldate = {2023-06-19},
	journal = {Transportation Research Part E: Logistics and Transportation Review},
	author = {Yu, Wantao and Chavez, Roberto and Jacobs, Mark A. and Feng, Mengying},
	month = jun,
	year = {2018},
	keywords = {Big data, Data-driven supply chains, Performance, Supply chain capabilities},
	pages = {371--385},
	file = {Accepted Version:C\:\\Users\\abrar\\Zotero\\storage\\XN8JPETN\\Yu et al. - 2018 - Data-driven supply chain capabilities and performa.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\9LI6VF6W\\S1366554516300795.html:text/html},
}

@inproceedings{yue_selective_2010,
	title = {Selective and {Heterogeneous} {SVM} {Ensemble} for {Demand} {Forecasting}},
	doi = {10.1109/CIT.2010.270},
	abstract = {An accurate demand forecasting model has both academic and practical significance to supply chain management for China's retail industry. In this paper, we proposed a novel demand forecasting model named SHEnSVM (Selective and Heterogeneous Ensemble of Support Vector Machines), in which the individual SVMs are trained by different samples generated by bootstrap algorithm and different parameters generated by grid search method in order to improve the diversity among them, and then Genetic Algorithm is employed for retrieving the best individual combination schema. Finally, SHEnSVM is applied to demand forecasting of one beer retail company. The experiment results prove the model has stronger generalization ability.},
	booktitle = {2010 10th {IEEE} {International} {Conference} on {Computer} and {Information} {Technology}},
	author = {Yue, Liu and Zhenjiang, Liao and Yafeng, Yin and Zaixia, Teng and Junjun, Gao and Bofeng, Zhang},
	month = jun,
	year = {2010},
	keywords = {Support vector machines, Predictive models, Demand forecasting, Demand Forecasting, Marketing and sales, Support Vector Machine, Feature Selection, Genetic Algorithm, Industries, Safety, Training},
	pages = {1519--1524},
}

@article{zhao_massively_2013,
	title = {Massively parallel feature selection: an approach based on variance preservation},
	volume = {92},
	issn = {1573-0565},
	shorttitle = {Massively parallel feature selection},
	url = {https://doi.org/10.1007/s10994-013-5373-4},
	doi = {10.1007/s10994-013-5373-4},
	abstract = {Advances in computer technologies have enabled corporations to accumulate data at an unprecedented speed. Large-scale business data might contain billions of observations and thousands of features, which easily brings their scale to the level of terabytes. Most traditional feature selection algorithms are designed and implemented for a centralized computing architecture. Their usability significantly deteriorates when data size exceeds tens of gigabytes. High-performance distributed computing frameworks and protocols, such as the Message Passing Interface (MPI) and MapReduce, have been proposed to facilitate software development on grid infrastructures, enabling analysts to process large-scale problems efficiently. This paper presents a novel large-scale feature selection algorithm that is based on variance analysis. The algorithm selects features by evaluating their abilities to explain data variance. It supports both supervised and unsupervised feature selection and can be readily implemented in most distributed computing environments. The algorithm was implemented as a SAS High-Performance Analytics procedure, which can read data in distributed form and perform parallel feature selection in both symmetric multiprocessing mode (SMP) and massively parallel processing mode (MPP). Experimental results demonstrated the superior performance of the proposed method for large scale feature selection.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Machine Learning},
	author = {Zhao, Zheng and Zhang, Ruiwen and Cox, James and Duling, David and Sarle, Warren},
	month = jul,
	year = {2013},
	keywords = {Feature selection, Model selection, Big-data, Parallel processing},
	pages = {195--220},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\7G6UX26D\\Zhao et al. - 2013 - Massively parallel feature selection an approach .pdf:application/pdf},
}

@inproceedings{yue_demand_2007,
	title = {Demand {Forecasting} by {Using} {Support} {Vector} {Machine}},
	volume = {3},
	doi = {10.1109/ICNC.2007.324},
	abstract = {Demand forecasting plays a crucial role for supply chain management of retail industry. The future demand for a certain product constructs the basis of its relevant replenishment system. In this research, the technique of support vector machine (SVM) is employed for demand forecasting. Various factors that affect the product demand such as seasonal and promotional factors have been taken into consideration in the model. Meanwhile, different other approaches such as statistical model, Winter model and radius basis function neural network (RBFNN) are also used for comparison and evaluation. The experiment results show that the performance of SVM is superior to other models, which will lead simultaneously to fewer sales failure and lower inventory levels.},
	booktitle = {Third {International} {Conference} on {Natural} {Computation} ({ICNC} 2007)},
	author = {Yue, Liu and Yafeng, Yin and Junjun, Gao and Chongli, Tan},
	month = aug,
	year = {2007},
	note = {ISSN: 2157-9563},
	keywords = {Supply chain management, Neural networks, Support vector machines, Predictive models, Artificial neural networks, Computer industry, Demand forecasting, Demand Forecasting, Econometrics, Economic forecasting, Marketing and sales, Support Vector Machine},
	pages = {272--276},
}

@misc{ravikumar_hierarchical_2012,
	title = {A {Hierarchical} {Graphical} {Model} for {Record} {Linkage}},
	url = {http://arxiv.org/abs/1207.4180},
	doi = {10.48550/arXiv.1207.4180},
	abstract = {The task of matching co-referent records is known among other names as rocord linkage. For large record-linkage problems, often there is little or no labeled data available, but unlabeled data shows a reasonable clear structure. For such problems, unsupervised or semi-supervised methods are preferable to supervised methods. In this paper, we describe a hierarchical graphical model framework for the linakge-problem in an unsupervised setting. In addition to proposing new methods, we also cast existing unsupervised probabilistic record-linkage methods in this framework. Some of the techniques we propose to minimize overfitting in the above model are of interest in the general graphical model setting. We describe a method for incorporating monotinicity constraints in a graphical model. We also outline a bootstrapping approach of using "single-field" classifiers to noisily label latent variables in a hierarchical model. Experimental results show that our proposed unsupervised methods perform quite competitively even with fully supervised record-linkage methods.},
	urldate = {2023-06-19},
	publisher = {arXiv},
	author = {Ravikumar, Pradeep and Cohen, William},
	month = jul,
	year = {2012},
	note = {arXiv:1207.4180 [cs, stat]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Appears in Proceedings of the Twentieth Conference on Uncertainty in Artificial Intelligence (UAI2004)},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\KJZMJAPS\\Ravikumar and Cohen - 2012 - A Hierarchical Graphical Model for Record Linkage.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\HQ737AJA\\1207.html:text/html},
}

@book{refaat_data_2010,
	title = {Data {Preparation} for {Data} {Mining} {Using} {SAS}},
	isbn = {978-0-08-049100-4},
	abstract = {Are you a data mining analyst, who spends up to 80\% of your time assuring data quality, then preparing that data for developing and deploying predictive models? And do you find lots of literature on data mining theory and concepts, but when it comes to practical advice on developing good mining views find little “how to information? And are you, like most analysts, preparing the data in SAS?This book is intended to fill this gap as your source of practical recipes. It introduces a framework for the process of data preparation for data mining, and presents the detailed implementation of each step in SAS. In addition, business applications of data mining modeling require you to deal with a large number of variables, typically hundreds if not thousands. Therefore, the book devotes several chapters to the methods of data transformation and variable selection. A complete framework for the data preparation process, including implementation details for each step. The complete SAS implementation code, which is readily usable by professional analysts and data miners. A unique and comprehensive approach for the treatment of missing values, optimal binning, and cardinality reduction. Assumes minimal proficiency in SAS and includes a quick-start chapter on writing SAS macros.},
	language = {en},
	publisher = {Elsevier},
	author = {Refaat, Mamdouh},
	month = jul,
	year = {2010},
	note = {Google-Books-ID: FkH9gjihLqMC},
	keywords = {Computers / Artificial Intelligence / General, Computers / Database Administration \& Management},
}

@article{rodriguez-lujan_quadratic_2010,
	title = {Quadratic {Programming} {Feature} {Selection}},
	volume = {11},
	issn = {1532-4435},
	abstract = {Identifying a subset of features that preserves classification accuracy is a problem of growing importance, because of the increasing size and dimensionality of real-world data sets. We propose a new feature selection method, named Quadratic Programming Feature Selection (QPFS), that reduces the task to a quadratic optimization problem. In order to limit the computational complexity of solving the optimization problem, QPFS uses the Nyström method for approximate matrix diagonalization. QPFS is thus capable of dealing with very large data sets, for which the use of other methods is computationally expensive. In experiments with small and medium data sets, the QPFS method leads to classification accuracy similar to that of other successful techniques. For large data sets, QPFS is superior in terms of computational efficiency.},
	journal = {The Journal of Machine Learning Research},
	author = {Rodriguez-Lujan, Irene and Huerta, Ramon and Elkan, Charles and Cruz, Carlos Santa},
	month = aug,
	year = {2010},
	pages = {1491--1516},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\Y22U2NR6\\Rodriguez-Lujan et al. - 2010 - Quadratic Programming Feature Selection.pdf:application/pdf},
}

@article{winkler_improved_1997,
	title = {Improved {Decision} {Rules} {In} {The} {Fellegi}-{Sunter} {Model} {Of} {Record} {Linkage}},
	volume = {1},
	abstract = {Many applications of the Fellegi-Sunter model use simplifying assumptions and ad hoc modifications to improve matching efficacy. Because of model misspecification, distinctive approaches developed in one application typically cannot be used in other applications and do not always make use of advances in statistical and computational theory. An ExpectationMaximization (EMH) algorithm that constrains the estimates to a convex subregion of the parameter space is given. The EMH algorithm provides probability estimates that yield better decision rules than unconstrained estimates. The algorithm is related to results of Meng and Rubin (1993) on Multi-Cycle Expectation-Conditional Maximization algorithms and make use of results of Haberman (1977) that hold for large classes of loglinear models. Key Words: MCECM Algorithm, Latent Class, Computer Matching, Error Rate This paper provides a theory for obtaining constrained maximum likelihood estimates for latent-class, loglinear models on finite ...},
	journal = {Proceedings of the Section on Survey Research Methods, American Statistical Association},
	author = {Winkler, William},
	month = sep,
	year = {1997},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\JSAQBCKC\\Winkler - 1997 - Improved Decision Rules In The Fellegi-Sunter Mode.pdf:application/pdf},
}

@article{domingos_multi-relational_nodate,
	title = {Multi-{Relational} {Record} {Linkage}},
	abstract = {Data cleaning and integration is typically the most expensive step in the KDD process. A key part, known as record linkage or de-duplication, is identifying which records in a database refer to the same entities. This problem is traditionally solved separately for each candidate record pair (followed by transitive closure). We propose to use instead a multi-relational approach, performing simultaneous inference for all candidate pairs, and allowing information to propagate from one candidate match to another via the attributes they have in common. Our formulation is based on conditional random ﬁelds, and allows an optimal solution to be found in polynomial time using a graph cut algorithm. Parameters are learned using a voted perceptron algorithm. Experiments on real and synthetic databases show that multi-relational record linkage outperforms the standard approach.},
	language = {en},
	author = {Domingos, Pedro},
	file = {Domingos - Multi-Relational Record Linkage.pdf:C\:\\Users\\abrar\\Zotero\\storage\\2T2YYHLQ\\Domingos - Multi-Relational Record Linkage.pdf:application/pdf},
}

@inproceedings{domingos_multi-relational_2003,
	title = {Multi-{Relational} {Record} {Linkage}},
	url = {https://www.semanticscholar.org/paper/Multi-Relational-Record-Linkage-Domingos/b2d3a6598944463687115e369a0223d4826bbe26},
	abstract = {Data cleaning and integration is typically the most expen- sive step in the KDD process. A key part, known as record linkage or de-duplication, is identifying which records in a database refer to the same entities. This problem is traditionally solved separately for each candidate record pair (followed by transitive closure). We propose to use instead a multi-relational approach, performing simultaneous inference for all candidate pairs, and allowing information to propagate from one candidate match to another via the attributes they have in common. Our formulation is based on conditional random elds, and allows an optimal solution to be found in polynomial time using a graph cut algorithm. Pa- rameters are learned using a voted perceptron algorithm. Experiments on real and synthetic databases show that multi-relational record linkage outperforms the standard approach.},
	urldate = {2023-06-19},
	author = {Domingos, Pedro M.},
	year = {2003},
	annote = {[TLDR] Experiments on real and synthetic databases show that multi-relational record linkage outperforms the standard approach, and allows an optimal solution to be found in polynomial time using a graph cut algorithm.},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\7V7AEBZZ\\Domingos - 2003 - Multi-Relational Record Linkage.pdf:application/pdf},
}

@article{tuv_feature_2009,
	title = {Feature {Selection} with {Ensembles}, {Artificial} {Variables}, and {Redundancy} {Elimination}},
	volume = {10},
	issn = {1532-4435},
	abstract = {Predictive models benefit from a compact, non-redundant subset of features that improves interpretability and generalization. Modern data sets are wide, dirty, mixed with both numerical and categorical predictors, and may contain interactive effects that require complex models. This is a challenge for filters, wrappers, and embedded feature selection methods. We describe details of an algorithm using tree-based ensembles to generate a compact subset of non-redundant features. Parallel and serial ensembles of trees are combined into a mixed method that can uncover masking and detect features of secondary effect. Simulated and actual examples illustrate the effectiveness of the approach.},
	journal = {The Journal of Machine Learning Research},
	author = {Tuv, Eugene and Borisov, Alexander and Runger, George and Torkkola, Kari},
	month = dec,
	year = {2009},
	pages = {1341--1366},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\3AHDLAP5\\Tuv et al. - 2009 - Feature Selection with Ensembles, Artificial Varia.pdf:application/pdf},
}

@inproceedings{sandhya_stock_2022-1,
	title = {Stock {Price} {Prediction} using {Recurrent} {Neural} {Network} and {LSTM}},
	doi = {10.1109/ICCMC53470.2022.9753764},
	abstract = {Predicting stock prices is a tough task simulated to anticipate stock returns by machine learning. A range of approaches and techniques are used for stock market forecasting. The stock market is considered quite active and advanced. A precise estimate of future pricing could give investors an increased profit margin. According to the estimates, investors can select equities to produce a higher return. Various approaches to machine learning have been used in stock markets over the years. Still, deep learning models, which have shown superior to prior machine learning methods as far as predictive accuracy and speed are concerned, are being used with the growing data and wish for forecasts. In this research, a common deeper study model for stock market prediction, the Long-Short Memory (LSTM) recurring neural network has been utilized. In this task, Python modules are used to automatically download historical market data to forecast future stock prices by fitting an LSTM model to data.},
	booktitle = {2022 6th {International} {Conference} on {Computing} {Methodologies} and {Communication} ({ICCMC})},
	author = {Sandhya, Pasala and Bandi, Raswitha and Himabindu, D. Dakshayani},
	month = mar,
	year = {2022},
	keywords = {Data models, Predictive models, Computational modeling, an output layer, Close price, gate forget, hidden layer, input gate, input layer, long shorter-term memory, output gate, recurring neural networks, sigmoid gate, Logic gates, Neurons, Pricing, Recurrent neural networks},
	pages = {1723--1728},
}

@article{mitra_comparative_2022,
	title = {A {Comparative} {Study} of {Demand} {Forecasting} {Models} for a {Multi}-{Channel} {Retail} {Company}: {A} {Novel} {Hybrid} {Machine} {Learning} {Approach}},
	volume = {3},
	issn = {2662-2556},
	shorttitle = {A {Comparative} {Study} of {Demand} {Forecasting} {Models} for a {Multi}-{Channel} {Retail} {Company}},
	url = {https://doi.org/10.1007/s43069-022-00166-4},
	doi = {10.1007/s43069-022-00166-4},
	abstract = {Demand forecasting has been a major concern of operational strategy to manage the inventory and optimize the customer satisfaction level. The researchers have proposed many conventional and advanced forecasting techniques, but no one leads to complete accuracy. Forecasting is equally important in manufacturing as well as retail companies. In this study, the performances of five regression techniques of machine learning, viz. random forest (RF), extreme gradient boosting (XGBoost), gradient boosting, adaptive boosting (AdaBoost), and artificial neural network (ANN) algorithms, are compared with a proposed hybrid (RF-XGBoost-LR) model for sales forecasting of a retail chain considering the various parameters of forecasting accuracy. The weekly sales data of a US-based retail company is considered in the analysis of the forecasts undertaking the attributes affecting the sale such as the temperature of the region and the size of the store. It is observed that the hybrid RF-XGBoost-LR outperformed the other models measured against various metrics of performance. This study may help the industry decision-maker to understand and improve the methods of forecasting.},
	language = {en},
	number = {4},
	urldate = {2023-06-19},
	journal = {Operations Research Forum},
	author = {Mitra, Arnab and Jain, Arnav and Kishore, Avinash and Kumar, Pravin},
	month = sep,
	year = {2022},
	keywords = {Machine learning, Demand forecasting, XGBoost, Random forest, AdaBoost, Gradient boosting, Statistical methods},
	pages = {58},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\PXT8P8TG\\Mitra et al. - 2022 - A Comparative Study of Demand Forecasting Models f.pdf:application/pdf},
}

@article{zohdi_demand_2022-1,
	title = {Demand forecasting based machine learning algorithms on customer information: an applied approach},
	volume = {14},
	issn = {2511-2112},
	shorttitle = {Demand forecasting based machine learning algorithms on customer information},
	url = {https://doi.org/10.1007/s41870-022-00875-3},
	doi = {10.1007/s41870-022-00875-3},
	abstract = {Demand forecasting has always been a concern for business owners as one of the main activities in supply chain management. Unlike the past, that forecasting was done with the help of a limited amount of information, today, using advanced technologies and data analytics, forecasting is performed with machine learning algorithms and data-driven methods. Patterns and trends of demand, customer information, preferences, suggestions, and post-consumption feedbacks are some types of data that are used in various demand forecasting efforts. Traditional statistical methods and techniques are biased in demand prediction and are not accurate; so, machine learning algorithms as more popular techniques have been replaced in recent researches in the literature. Until the time of conducting this research, extreme learning machine has not been used for intermittent demand prediction, so the novelty of our research is to adopt this algorithm and also other machine learning algorithms such as K-nearest neighbors, decision tree, gradient boosting, and multi-layer perceptron to examine its accuracy and performance in comparison to other approaches. Finally, it is demonstrated that artificial neural network-based methods outperform the other employed techniques through conducting a comparison among the above-mentioned predictors in terms of mean squared error, mean absolute error, coefficient of determination, and computational time. Furthermore, extreme learning machine is the best or at least among the best predictors. At last, for determining whether the obtained results are statistically significant or not, analysis of variance is conducted and the Kolmogorov–Smirnov technique is adopted to test the normality of outcomes.},
	language = {en},
	number = {4},
	urldate = {2023-06-19},
	journal = {International Journal of Information Technology},
	author = {Zohdi, Maryam and Rafiee, Majid and Kayvanfar, Vahid and Salamiraad, Amirhossein},
	month = jun,
	year = {2022},
	keywords = {Supply chain management, Machine learning algorithms, Demand forecasting, Big data analytics, Customer information},
	pages = {1937--1947},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\RXU5QMAH\\Zohdi et al. - 2022 - Demand forecasting based machine learning algorith.pdf:application/pdf},
}

@article{hamdan_machine_2023-1,
	title = {Machine learning in supply chain: prediction of real-time e-order arrivals using {ANFIS}},
	volume = {14},
	issn = {0976-4348},
	shorttitle = {Machine learning in supply chain},
	url = {https://doi.org/10.1007/s13198-022-01851-7},
	doi = {10.1007/s13198-022-01851-7},
	abstract = {Accurate demand forecasting throughout the multi-channel supply chain (SC) enhances the managers’ decision-making capability in operational, tactical, and strategic aspects. However, the problem is that earlier publications about the real-time prediction of e-commerce order arrivals in the SC show some inadequacies. According to a systematic review from Tsolaki (ICT Express, 2022. https://doi.org/10.1016/j.icte.2022.02.001) who integrate logistics and machine learning (ML) methods in the past ten years, there are very few studies that focus on arrival time prediction like this study does, and none of them uses an adaptive neuro-fuzzy inference system (ANFIS) framework to predict e-order arrivals. Besides, (Policarpo in Comput Sci Rev 41:100414, 2021) review the existing publications that integrate e-commerce and ML techniques in the past five years; they reveal that previous studies pay heavier attentions to e-commerce initiative goals such as purchase and repurchase predictions, and none of them focuses on predicting e-order arrivals like this study does. Previous scholars investigate SC orders and prediction issues in a broader space, while this study attempts to predict hour-to-hour, actual-time order arrivals. Thus, this study presents a new data-empowered forecasting method to fill these research gaps. The motivation of this study is to build a method for predicting real-time e-orders arrivals in distribution hubs, enabling third-party logistics providers to handle the hourly-based e-order arrival rates more efficiently. This study tries to find the solution for the problem by developing a new ML forecasting method by integrating time-series data features and ANFIS, which has been proven to significantly reduce the issues’ computational complexity. This study creates a four-phase operation model to enable managers to adopt the suggested framework, and develops a systematized forecasting model to cross-confirm the framework’s outcomes. This study employs a descriptive case study and shows a satisfactory degree of precision of the suggested ML method in predicting the actual e-order arrivals in three e-retailers at three-hour cycle times. The findings reveal that the real-time forecasting is significant to boost the values of e-order arrivals in every day business operations. The novelty of this study lies on its novel contribution and purpose to build a method for predicting real-time e-orders arrivals in distribution hubs, enabling third-party logistics providers to handle the hourly-based e-order arrival rates more efficiently; and to develop a new ML forecasting method by integrating ANFIS and time-series data features.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {International Journal of System Assurance Engineering and Management},
	author = {Hamdan, Ihab K. A. and Aziguli, Wulamu and Zhang, Dezheng and Sumarliah, Eli},
	month = mar,
	year = {2023},
	keywords = {Supply chain management, Machine learning, E-commerce, Real-time demand prediction, Third-party logistics, C45},
	pages = {549--568},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\3ARR4UD7\\Hamdan et al. - 2023 - Machine learning in supply chain prediction of re.pdf:application/pdf},
}

@article{chaudhuri_hybrid_2022-1,
	title = {A hybrid extreme learning machine model with harris hawks optimisation algorithm: an optimised model for product demand forecasting applications},
	volume = {52},
	issn = {1573-7497},
	shorttitle = {A hybrid extreme learning machine model with harris hawks optimisation algorithm},
	url = {https://doi.org/10.1007/s10489-022-03251-7},
	doi = {10.1007/s10489-022-03251-7},
	abstract = {Accurate and real-time product demand forecasting is the need of the hour in the world of supply chain management. Predicting future product demand from historical sales data is a highly non-linear problem, subject to various external and environmental factors. In this work, we propose an optimised forecasting model - an extreme learning machine (ELM) model coupled with the Harris Hawks optimisation (HHO) algorithm to forecast product demand in an e-commerce company. ELM is preferred over traditional neural networks mainly due to its fast computational speed, which allows efficient demand forecasting in real-time. Our ELM-HHO model performed significantly better than ARIMA models that are commonly used in industries to forecast product demand. The performance of the proposed ELM-HHO model was also compared with traditional ELM, ELM auto-tuned using Bayesian Optimisation (ELM-BO), Gated Recurrent Unit (GRU) based recurrent neural network and Long Short Term Memory (LSTM) recurrent neural network models. Different performance metrics, i.e., Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE) and Mean Percentage Error (MPE) were used for the comparison of the selected models. Horizon forecasting at 3 days and 7 days ahead was also performed using the proposed approach. The results revealed that the proposed approach is superior to traditional product demand forecasting models in terms of prediction accuracy and it can be applied in real-time to predict future product demand based on the previous week’s sales data. In particular, considering RMSE of forecasting, the proposed ELM-HHO model performed 62.73\% better than the statistical ARIMA(7,1,0) model, 40.73\% better than the neural network based GRU model, 34.05\% better than the neural network based LSTM model, 27.16\% better than the traditional non-optimised ELM model with 100 hidden nodes and 11.63\% better than the ELM-BO model in forecasting product demand for future 3 months. The novelty of the proposed approach lies in the way the fast computational speed of ELMs has been combined with the accuracy gained by tuning hyperparameters using HHO. An increased number of hyperparameters has been optimised in our methodology compared to available models. The majority of approaches to improve the accuracy of ELM so far have only focused on tuning the weights and the biases of the hidden layer. In our hybrid model, we tune the number of hidden nodes, the number of input time lags and even the type of activation function used in the hidden layer in addition to tuning the weights and the biases. This has resulted in a significant increase in accuracy over previous methods. Our work presents an original way of performing product demand forecasting in real-time in industry with highly accurate results which are much better than pre-existing demand forecasting models.},
	language = {en},
	number = {10},
	urldate = {2023-06-19},
	journal = {Applied Intelligence},
	author = {Chaudhuri, Koushiki Dasgupta and Alkan, Bugra},
	month = aug,
	year = {2022},
	keywords = {Supply chain management, Artificial neural networks, Demand forecasting, ARIMA, Extreme learning machines, Harris hawks optimisation, Hyperparameter tuning, Optimisation},
	pages = {11489--11505},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\7PHNZA9I\\Chaudhuri and Alkan - 2022 - A hybrid extreme learning machine model with harri.pdf:application/pdf},
}

@article{rathipriya_demand_2023-1,
	title = {Demand forecasting model for time-series pharmaceutical data using shallow and deep neural network model},
	volume = {35},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-022-07889-9},
	doi = {10.1007/s00521-022-07889-9},
	abstract = {Demand forecasting is a scientific and methodical assessment of future demand for a critical product.The effective Demand Forecast Model (DFM) enables pharmaceutical companies to be successful in the global market. The purpose of this research paper is to validate various shallow and deep neural network methods for demand forecasting, with the aim of recommending sales and marketing strategies based on the trend/seasonal effects of eight different groups of pharmaceutical products with different characteristics. The root mean squared error (RMSE) is used as the predictive accuracy of DFMs. This study also found that the mean RMSE value of the shallow neural network-based DFMs was 6.27 for all drug categories, which was lower than deep neural network models. According to the findings, DFMs based on shallow neural networks can effectively estimate future demand for pharmaceutical products.},
	language = {en},
	number = {2},
	urldate = {2023-06-19},
	journal = {Neural Computing and Applications},
	author = {Rathipriya, R. and Abdul Rahman, Abdul Aziz and Dhamodharavadhani, S. and Meero, Abdelrhman and Yoganandan, G.},
	month = jan,
	year = {2023},
	keywords = {Pharmaceuticalindustry, Shallow neural network models, Deep learning models, Demand forecasting},
	pages = {1945--1957},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\KFZK4TWL\\Rathipriya et al. - 2023 - Demand forecasting model for time-series pharmaceu.pdf:application/pdf},
}

@inproceedings{nithin_retail_2022-1,
	title = {Retail {Demand} {Forecasting} using {CNN}-{LSTM} {Model}},
	doi = {10.1109/ICEARS53579.2022.9752283},
	abstract = {This paper proposes a deep learning model to predict the stock that would be required by a store in a particular period with the help of historic information such as past sales. This task could help a business to run smoothly and make sound decisions but are very hard to predict accurately. A CNN-LSTM (Convolutional Neural Network-Long Short-Term Memory Network) model is proposed to forecast retail demand. This model equips the Swish Activation Function. This works better than the traditional and most successful activation function ReLU (Rectified Linear Unit). Data from 10 stores each consisting of 50 items are taken as input. This proposed work has implemented various other models such as Multilayer Perceptron, Long Short-Term Memory cells, Convolutional Neural Networks to predict sales. The experiment results suggest using CNN-LSTM Model as it has considerably lower RMSE (Root Mean-Squared Error).},
	booktitle = {2022 {International} {Conference} on {Electronics} and {Renewable} {Systems} ({ICEARS})},
	author = {Nithin, Soundar S J and Rajasekar, T and Jayanthy, S and Karthik, K and Rithick, Roshan R},
	month = mar,
	year = {2022},
	keywords = {Multilayer perceptrons, Data models, Deep learning, Predictive models, Demand forecasting, Demand Forecasting, Prediction algorithms, Convolutional Neural Networks (CNN), Long Short-Term Memory Cells (LSTM), Multilayer Perceptron, Neural Networks, ReLU Activation Function, Swish Activation Function, Tensor Flow, Renewable energy sources},
	pages = {1751--1756},
}

@article{ben_elmir_smart_2023-1,
	title = {Smart {Platform} for {Data} {Blood} {Bank} {Management}: {Forecasting} {Demand} in {Blood} {Supply} {Chain} {Using} {Machine} {Learning}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2078-2489},
	shorttitle = {Smart {Platform} for {Data} {Blood} {Bank} {Management}},
	url = {https://www.mdpi.com/2078-2489/14/1/31},
	doi = {10.3390/info14010031},
	abstract = {Despite the efforts of the World Health Organization, blood transfusions and delivery are still the crucial challenges in blood supply chain management, especially when there is a high demand and not enough blood inventory. Consequently, reducing uncertainty in blood demand, waste, and shortages has become a primary goal. In this paper, we propose a smart platform-oriented approach that will create a robust blood demand and supply chain able to achieve the goals of reducing uncertainty in blood demand by forecasting blood collection/demand, and reducing blood wastage and shortage by balancing blood collection and distribution based on an effective blood inventory management. We use machine learning and time series forecasting models to develop an AI/ML decision support system. It is an effective tool with three main modules that directly and indirectly impact all phases of the blood supply chain: (i) the blood demand forecasting module is designed to forecast blood demand; (ii) blood donor classification helps predict daily unbooked donors thereby enhancing the ability to control the volume of blood collected based on the results of blood demand forecasting; and (iii) scheduling blood donation appointments according to the expected number and type of blood donations, thus improving the quantity of blood by reducing the number of canceled appointments, and indirectly improving the quality and quantity of blood supply by decreasing the number of unqualified donors, thereby reducing the amount of invalid blood after and before preparation. As a result of the system’s improvements, blood shortages and waste can be reduced. The proposed solution provides robust and accurate predictions and identifies important clinical predictors for blood demand forecasting. Compared with the past year’s historical data, our integrated proposed system increased collected blood volume by 11\%, decreased inventory wastage by 20\%, and had a low incidence of shortages.},
	language = {en},
	number = {1},
	urldate = {2023-06-19},
	journal = {Information},
	author = {Ben Elmir, Walid and Hemmak, Allaoua and Senouci, Benaoumeur},
	month = jan,
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {machine learning algorithms, blood bank management, blood supply chain, time series forecasting models},
	pages = {31},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\7R9CS5LR\\Ben Elmir et al. - 2023 - Smart Platform for Data Blood Bank Management For.pdf:application/pdf},
}

@article{zheng_federated_2023-1,
	title = {Federated {Machine} {Learning} for {Privacy} {Preserving}, {Collective} {Supply} {Chain} {Risk} {Prediction}},
	doi = {10.1080/00207543.2022.2164628},
	abstract = {The development and use of Artificial Intelligence technology for predicting supply chain risk has gained popularity. However, proposed approaches are based on the premise that organisations act alone, rather than as a collective when predicting risk, despite the interconnected nature of supply chains. This yields a problem: organisations that have inadequate datasets cannot predict risk. While data-sharing has long been proposed to help coordinate risk evaluation, in practice this does not happen due to privacy concerns. In this paper we propose a novel technique from the field of AI, namely federated learning, to facilitate collective risk prediction in supply chains without the risk of data leakage. We ask: Can organisations who have inadequate datasets tap into collective knowledge? This consequently raises the secondary question: Under what circumstances would collective risk prediction be beneficial? Our approach is tested on empirical case study to help buyers predict order delays from their shared suppliers before and after Covid19. Results show that federated learning can indeed help supply chain members predict risk effectively, especially for buyers who have limited datasets. We also find that training data imbalance, disruption levels, and algorithm choice are significant factors in the efficacy of this approach. Interestingly, data-sharing or collective risk prediction is not always the best choice for buyers who have disproportionately larger order books and they should pursue prediction alone. We thus call for further research on the trade offs between risk prediction with local and collective learning paradigms in supply chains.},
	journal = {International Journal of Production Research},
	author = {Zheng, Ge and Kong, Lingxuan and Brintrup, Alexandra},
	month = jan,
	year = {2023},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\LP7DHDN3\\Zheng et al. - 2023 - Federated Machine Learning for Privacy Preserving,.pdf:application/pdf},
}

@misc{noauthor_energies_nodate,
	title = {Energies {\textbar} {Free} {Full}-{Text} {\textbar} {Short}- and {Very} {Short}-{Term} {Firm}-{Level} {Load} {Forecasting} for {Warehouses}: {A} {Comparison} of {Machine} {Learning} and {Deep} {Learning} {Models}},
	url = {https://www.mdpi.com/1996-1073/15/3/750},
	urldate = {2023-06-19},
}

@inproceedings{singha_application_2022-1,
	title = {Application of different {Machine} {Learning} models for {Supply} {Chain} {Demand} {Forecasting}: {Comparative} {Analysis}},
	volume = {2},
	shorttitle = {Application of different {Machine} {Learning} models for {Supply} {Chain} {Demand} {Forecasting}},
	doi = {10.1109/ICIPTM54933.2022.9753864},
	abstract = {Demand is defined as the propensity or willingness of customers to pay a certain amount of price for a product or service they desire. Business entities use various forecasting techniques to anticipate customer demands in advance to make crucial strategic decisions related to various aspects of the supply chain, such as customer service level, inventory management, manufacturing planning, and control, etc. But the error related to forecasting models creates uncertainty and poses a great challenge to decision-makers. With the ever-changing market dynamics, it is becoming more and more important for businesses to minimize those forecasting errors. In this paper, we have analysed the application of various advanced Machine Learning algorithms like Multi-layered Perceptron model (MLP), Convolution Neural Network (CNN), Long-Short Term Memory (LSTM) Networks, etc. in Time Series Forecasting, thereafter, performed a comparative analysis to understand which of them yields the better result. To perform the analysis, we have considered the ‘Store Item Demand Forecasting’ dataset available at Kaggle.},
	booktitle = {2022 2nd {International} {Conference} on {Innovative} {Practices} in {Technology} and {Management} ({ICIPTM})},
	author = {Singha, D and Panse, Chetan},
	month = feb,
	year = {2022},
	keywords = {Uncertainty, machine learning, Predictive models, Time series analysis, Demand forecasting, Training, Computational modeling, Analytical models, neural networks, Supply chains, supply chain, time series model},
	pages = {312--318},
}

@article{haider_deep_2022-1,
	title = {Deep learning and statistical methods for short- and long-term solar irradiance forecasting for {Islamabad}},
	volume = {198},
	issn = {0960-1481},
	url = {https://www.sciencedirect.com/science/article/pii/S0960148122011387},
	doi = {10.1016/j.renene.2022.07.136},
	abstract = {The growing threat of global climate change stemming from the huge carbon footprint left behind by fossil fuels has prompted interest in exploring and utilizing renewable energy resources. Several statistical, Machine and Deep Learning techniques exist and have been used for many years for a range of forecasting problems. This study is based on the data recorded for 4 years and 9 months using precise instruments, in Islamabad, Pakistan. For this purpose we use statistical and Deep Learning architectures for forecasting solar Global Horizontal Irradiance which not only helps in grid management and power distribution, but also brings attention towards the potential of solar power production in Pakistan and its part to play in tackling global climate change. We have used statistical methods such as Seasonal Auto-Regressive Integrated Moving Average Exogenous (SARIMAX) and Prophet, and Machine Learning methods such as Long Short-Term Memory (LSTM) which is an extension of Recurrent Neural Networks (RNN), Convolutional Neural Network (CNN) and Artificial Neural Network (ANN). The selected forecast methods in our study are based on their ability to work with time series data and we have used different models configurations to see which performs best for our dataset. The performance of every model is studied using different error metrics such as Coefficient of Determination (R2), Mean Absolute Error (MAE), Mean Square Error (MSE), and Root Mean Square Error (RMSE). The major contribution of this study is the data collected to carry out research towards the goal of renewable energy future, and from the test methods used on the data in this study, it can be intuitively determined that ANN, CNN, and LSTM architectures perform best for short-term forecasts, while SARIMAX and Prophet are efficient for long-term forecasts.},
	language = {en},
	urldate = {2023-06-19},
	journal = {Renewable Energy},
	author = {Haider, Syed Altan and Sajid, Muhammad and Sajid, Hassan and Uddin, Emad and Ayaz, Yasar},
	month = oct,
	year = {2022},
	pages = {51--60},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\5VTF8YJM\\S0960148122011387.html:text/html},
}

@article{migueis_reducing_2022-1,
	title = {Reducing fresh fish waste while ensuring availability: {Demand} forecast using censored data and machine learning},
	volume = {359},
	issn = {0959-6526},
	shorttitle = {Reducing fresh fish waste while ensuring availability},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652622014627},
	doi = {10.1016/j.jclepro.2022.131852},
	abstract = {Food waste reduction represents a potential opportunity to enhance environmental sustainability. This is especially important in fresh products such as fresh seafood, where waste levels are substantially higher than those of other food products. In this particular case, reducing waste is also vital to meet demand while conserving fisheries. This paper aims to promote more sustainable supply chains by proposing daily fresh fish demand forecasting models that can be used by grocery retailers to align supply and demand, and hence prevent the production of food waste. To accomplish this goal, we explored the potential of different machine learning models, namely Long Short-Term Memory networks, Feedforward neural networks, Support Vector Regression, and Random Forests, as well as a Holt-Winters statistical model. Demand censorship was considered to capture real demand. To validate the proposed methodology, we estimated the demand for fresh fish in a representative store of a large European retailing company used as a case study. The results revealed that the machine learning models provided accurate forecasts in comparison to the baseline models and the statistical model, with the Long Short-Term Memory networks model yielding, in general, the best results in terms of root mean squared error (27.82), mean absolute error (20.63) and mean positive error (17.86). Thus, the implementation of these types of models can thus have a positive impact on the sustainability of fresh fish species and customer satisfaction.},
	language = {en},
	urldate = {2023-06-19},
	journal = {Journal of Cleaner Production},
	author = {Miguéis, Vera Lucia and Pereira, André and Pereira, João and Figueira, Gonçalo},
	month = jul,
	year = {2022},
	keywords = {Machine learning, Demand forecasting, Censored demand, Food waste, Time series forecasting},
	pages = {131852},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\X77TQQN4\\Miguéis et al. - 2022 - Reducing fresh fish waste while ensuring availabil.pdf:application/pdf},
}

@article{bassiouni_advanced_2023-1,
	title = {Advanced deep learning approaches to predict supply chain risks under {COVID}-19 restrictions},
	volume = {211},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417422016566},
	doi = {10.1016/j.eswa.2022.118604},
	abstract = {The ongoing COVID-19 pandemic has created an unprecedented predicament for global supply chains (SCs). Shipments of essential and life-saving products, ranging from pharmaceuticals, agriculture, and healthcare, to manufacturing, have been significantly impacted or delayed, making the global SCs vulnerable. A better understanding of the shipment risks can substantially reduce that nervousness. Thenceforth, this paper proposes a few Deep Learning (DL) approaches to mitigate shipment risks by predicting ”if a shipment can be exported from one source to another”, despite the restrictions imposed by the COVID-19 pandemic. The proposed DL methodologies have four main stages: data capturing, de-noising or pre-processing, feature extraction, and classification. The feature extraction stage depends on two main variants of DL models. The first variant involves three recurrent neural networks (RNN) structures (i.e., long short-term memory (LSTM), Bidirectional long short-term memory (BiLSTM), and gated recurrent unit (GRU)), and the second variant is the temporal convolutional network (TCN). In terms of the classification stage, six different classifiers are applied to test the entire methodology. These classifiers are SoftMax, random trees (RT), random forest (RF), k-nearest neighbor (KNN), artificial neural network (ANN), and support vector machine (SVM). The performance of the proposed DL models is evaluated based on an online dataset (taken as a case study). The numerical results show that one of the proposed models (i.e., TCN) is about 100\% accurate in predicting the risk of shipment to a particular destination under COVID-19 restrictions. Unarguably, the aftermath of this work will help the decision-makers to predict supply chain risks proactively to increase the resiliency of the SCs.},
	language = {en},
	urldate = {2023-06-19},
	journal = {Expert Systems with Applications},
	author = {Bassiouni, Mahmoud M. and Chakrabortty, Ripon K. and Hussain, Omar K. and Rahman, Humyun Fuad},
	month = jan,
	year = {2023},
	keywords = {Deep learning, COVID-19, Classifiers, Convolutional network, Supply chain risk, Temporal convolutional network},
	pages = {118604},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\G6Y3SEVD\\Bassiouni et al. - 2023 - Advanced deep learning approaches to predict suppl.pdf:application/pdf},
}

@article{mehmood_egd-snet_2022-1,
	title = {{EGD}-{SNet}: {A} computational search engine for predicting an end-to-end machine learning pipeline for {Energy} {Generation} \& {Demand} {Forecasting}},
	volume = {324},
	issn = {0306-2619},
	shorttitle = {{EGD}-{SNet}},
	url = {https://www.sciencedirect.com/science/article/pii/S0306261922010388},
	doi = {10.1016/j.apenergy.2022.119754},
	abstract = {Load forecasting avoids energy wastage by accurately estimating the future quantity of energy generation and demand. Existing load forecasting approaches do not utilize the potential of feature selection and dimensionality reduction approaches that remove irrelevant/redundant features and improve the performance of machine learning (ML) regressors. This research presents an end-to-end framework named Energy Generation and Demand forecasting Search Net (EGD-SNet) capable of predicting energy generation, demand and temperature in multiple regions. EGD-SNet framework contains 13 different feature selection and 11 dimensionality reduction algorithms along with 10 most widely used ML regressors. It makes use of Particle Swarm Optimizer (PSO) to smartly train regressors by finding optimal hyperparameters. Further, it has potential to design an end to end pipeline by finding appropriate combination of regressor and feature selection or dimensionality reduction approaches for precisely predicting energy generation or demand for a particular regional data based on the characteristics of data. EGD-SNet as web service is accessible here. http://111.68.102.19:8000/},
	language = {en},
	urldate = {2023-06-19},
	journal = {Applied Energy},
	author = {Mehmood, Faiza and Ghani, Muhammad Usman and Ghafoor, Hina and Shahzadi, Rehab and Asim, Muhammad Nabeel and Mahmood, Waqar},
	month = oct,
	year = {2022},
	keywords = {Feature selection, Machine learning, Dimensionality reduction, Computational methodologies, Load forecasting},
	pages = {119754},
}

@article{hu_vaccine_2023-1,
	title = {Vaccine supply chain management: {An} intelligent system utilizing blockchain, {IoT} and machine learning},
	volume = {156},
	issn = {0148-2963},
	shorttitle = {Vaccine supply chain management},
	url = {https://www.sciencedirect.com/science/article/pii/S0148296322009456},
	doi = {10.1016/j.jbusres.2022.113480},
	abstract = {Vaccination offers health, economic, and social benefits. However, three major issues—vaccine quality, demand forecasting, and trust among stakeholders—persist in the vaccine supply chain(VSC), leading to inefficiencies.The COVID-19 pandemic has exacerbatedweaknesses in the VSC,while presenting opportunities to apply digital technologies to manageit.For the first time, this study establishes an intelligent VSC management system that provides decision support for VSC management during the COVID-19 pandemic. The system combines blockchain, internet of things (IoT), and machine learning that effectively address the three issues in the VSC. The transparency of blockchain ensures trust among stakeholders. The real-time monitoring of vaccine status by the IoT ensures vaccine quality. Machine learning predicts vaccine demand and conducts sentiment analysis on vaccine reviews to help companies improve vaccine quality. The present study also reveals the implications for the management of supply chains, businesses, and government.},
	language = {en},
	urldate = {2023-06-19},
	journal = {Journal of Business Research},
	author = {Hu, Hui and Xu, Jiajun and Liu, Mengqi and Lim, Ming K.},
	month = feb,
	year = {2023},
	keywords = {Machine learning, Blockchain, COVID-19 pandemic, Intelligent system, Internet of things, Vaccine supply chain},
	pages = {113480},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\M79VC9RZ\\Hu et al. - 2023 - Vaccine supply chain management An intelligent sy.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\R7FQEQPG\\S0148296322009456.html:text/html},
}

@article{li_forecasting_2023-1,
	title = {Forecasting the lithium mineral resources prices in {China}: {Evidence} with {Facebook} {Prophet} ({Fb}-{P}) and {Artificial} {Neural} {Networks} ({ANN}) methods},
	volume = {82},
	issn = {0301-4207},
	shorttitle = {Forecasting the lithium mineral resources prices in {China}},
	url = {https://www.sciencedirect.com/science/article/pii/S030142072300291X},
	doi = {10.1016/j.resourpol.2023.103580},
	abstract = {Combining lithium real-time series data with recently developed advanced Artificial Neural Networks (ANN) and Facebook Prophet (Fb-P) algorithms is of particular relevance for identifying and delivering policy-insightful patterns by learning from experimental data without being pre-conditioned and managing investment risk. The prime objective of this study is to forecast lithium mineral resource prices in China. This study uses the Fb-P and ANN techniques to estimate lithium prices utilizing daily historical data between 5 November 2018 and 1 November 2022. In doing so, the empirical estimates help to predict future prices until 20 April 2023. The findings of the Facebook Prophet technique demonstrate that lithium mineral pricing has a very high degree of accuracy and has a long short-term memory at differential frequency days intervals. In contrast to the current price of 572,500 yuan/tonne, it may have been noticed that the market would suddenly surge in the next six months, reaching more than 800000 yuan/tonne. The study attempts to draw novel implications in the context of mineral resource prices in China.},
	language = {en},
	urldate = {2023-06-19},
	journal = {Resources Policy},
	author = {Li, Xiaobin and Sengupta, Tuhin and Si Mohammed, Kamel and Jamaani, Fouad},
	month = may,
	year = {2023},
	keywords = {Forecasting, Machine learning, ANN, China, Lithium price, Mineral resources},
	pages = {103580},
}

@inproceedings{vithitsoontorn_demand_2022-1,
	address = {Khon Kaen, Thailand},
	title = {Demand {Forecasting} in {Production} {Planning} for {Dairy} {Products} {Using} {Machine} {Learning} and {Statistical} {Method}},
	isbn = {978-1-66540-206-4},
	url = {https://ieeexplore.ieee.org/document/9741683/},
	doi = {10.1109/iEECON53204.2022.9741683},
	abstract = {Demand forecasting is an essential task of every industry. Efficient forecasting relieves the excessive stock and out-of-stock problem, reducing revenue loss. This research performs a direct multistep forecast approach of demand forecasting on 8 dairy products of 5 different dairy production plants with 5-year data. Widely used traditional statistical method and the stage of the art deep learning method for sequence problems are picked. ARIMA and LSTM. The models are compared in many aspects, monthly observations against weekly observations, univariate against multivariate, and statistical against deep learning using model error and business metrics. The result shows that both statistical and deep learning method are reliable and are suitable to be used in demand forecasting. There is no single best optimization algorithm. ARIMAs predict the future in an average straight line. It shows the best result on few wavering series, whereas LSTMs predict the future value follow the seasonal of series. It beats ARIMAs on strong trend series. Training the model on monthly observations provide better error score.},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {2022 {International} {Electrical} {Engineering} {Congress} ({iEECON})},
	publisher = {IEEE},
	author = {Vithitsoontorn, Chayuth and Chongstitvatana, Prabhas},
	month = mar,
	year = {2022},
	pages = {1--4},
	file = {Vithitsoontorn and Chongstitvatana - 2022 - Demand Forecasting in Production Planning for Dair.pdf:C\:\\Users\\abrar\\Zotero\\storage\\BNCGHYX8\\Vithitsoontorn and Chongstitvatana - 2022 - Demand Forecasting in Production Planning for Dair.pdf:application/pdf},
}

@book{russom_big_nodate,
	title = {Big {Data} {Analytics}},
	author = {Russom, Philip},
}

@incollection{han_3_2012,
	address = {Boston},
	series = {The {Morgan} {Kaufmann} {Series} in {Data} {Management} {Systems}},
	title = {3 - {Data} {Preprocessing}},
	isbn = {978-0-12-381479-1},
	url = {https://www.sciencedirect.com/science/article/pii/B9780123814791000034},
	abstract = {This chapter introduces the basic concepts of data preprocessing and the methods for data preprocessing are organized into the following categories: data cleaning, data integration, data reduction, and data transformation. Data have quality if they satisfy the requirements of the intended use. There are many factors comprising data quality, including accuracy, completeness, consistency, timeliness, believability, and interpretability. There are several data preprocessing techniques. Data cleaning can be applied to remove noise and correct inconsistencies in data. Data integration merges data from multiple sources into a coherent data store such as a data warehouse. Data reduction can reduce data size by, for instance, aggregating, eliminating redundant features, or clustering. Data transformations (e.g., normalization) may be applied, where data are scaled to fall within a smaller range. This can improve the accuracy and efficiency of mining algorithms involving distance measurements. These techniques are not mutually exclusive; they may work together. For example, data cleaning can involve transformations to correct wrong data, such as by transforming all entries for a date field to a common format. The different attribute types and data characteristics can help identify erroneous values and outliers, which will be useful in the data cleaning and integration steps. Data processing techniques, when applied before mining, can substantially improve the overall quality of the patterns mined and/or the time required for the actual mining.},
	language = {en},
	urldate = {2023-06-23},
	booktitle = {Data {Mining} ({Third} {Edition})},
	publisher = {Morgan Kaufmann},
	author = {Han, Jiawei and Kamber, Micheline and Pei, Jian},
	editor = {Han, Jiawei and Kamber, Micheline and Pei, Jian},
	month = jan,
	year = {2012},
	doi = {10.1016/B978-0-12-381479-1.00003-4},
	pages = {83--124},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\J2FGPXAN\\data-mining-concepts-and-techniques.html:text/html},
}

@incollection{hitchcock_causal_2020,
	edition = {Summer 2020},
	title = {Causal {Models}},
	url = {https://plato.stanford.edu/archives/sum2020/entries/causal-models/},
	abstract = {Causal models are mathematical models representing causalrelationships within an individual system or population. Theyfacilitate inferences about causal relationships from statisticaldata. They can teach us a good deal about the epistemology ofcausation, and about the relationship between causation andprobability. They have also been applied to topics of interest tophilosophers, such as the logic of counterfactuals, decision theory,and the analysis of actual causation.},
	urldate = {2023-06-23},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Hitchcock, Christopher},
	editor = {Zalta, Edward N. and Nodelman, Uri},
	year = {2020},
	keywords = {causation: and manipulability, causation: counterfactual theories of, causation: probabilistic, causation: the metaphysics of, conditionals: counterfactual, decision theory, decision theory: causal, logic: conditionals, probability, interpretations of, quantum theory: the Einstein-Podolsky-Rosen argument in, rational choice, normative: expected utility, Reichenbach, Hans: common cause principle},
	file = {SEP - Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\8NB8FHE7\\causal-models.html:text/html},
}

@incollection{hitchcock_causal_2023,
	edition = {Spring 2023},
	title = {Causal {Models}},
	url = {https://plato.stanford.edu/archives/spr2023/entries/causal-models/},
	abstract = {Causal models are mathematical models representing causalrelationships within an individual system or population. Theyfacilitate inferences about causal relationships from statisticaldata. They can teach us a good deal about the epistemology ofcausation, and about the relationship between causation andprobability. They have also been applied to topics of interest tophilosophers, such as the logic of counterfactuals, decision theory,and the analysis of actual causation.},
	urldate = {2023-06-23},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Hitchcock, Christopher},
	editor = {Zalta, Edward N. and Nodelman, Uri},
	year = {2023},
	keywords = {causation: and manipulability, causation: counterfactual theories of, causation: probabilistic, causation: the metaphysics of, conditionals: counterfactual, decision theory, decision theory: causal, logic: conditionals, probability, interpretations of, quantum theory: the Einstein-Podolsky-Rosen argument in, rational choice, normative: expected utility, Reichenbach, Hans: common cause principle},
	file = {SEP - Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\IRH38RNB\\causal-models.html:text/html},
}

@misc{noauthor_author_nodate,
	title = {Author and {Citation} {Information} for "{Causal} {Models}"},
	url = {https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=causal-models&archive=sum2020},
	urldate = {2023-06-23},
	file = {Author and Citation Information for "Causal Models":C\:\\Users\\abrar\\Zotero\\storage\\TVZKJ7YJ\\archinfo.html:text/html},
}

@incollection{hitchcock_causal_2020-1,
	edition = {Summer 2020},
	title = {Causal {Models}},
	url = {https://plato.stanford.edu/archives/sum2020/entries/causal-models/},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Hitchcock, Christopher},
	editor = {Zalta, Edward N. and Nodelman, Uri},
	year = {2020},
}

@book{johnson_applied_2007,
	address = {Upper Saddle River, N.J},
	edition = {6th edition},
	title = {Applied {Multivariate} {Statistical} {Analysis}},
	isbn = {978-0-13-187715-3},
	abstract = {This market leader offers a readable introduction to the statistical analysis of multivariate observations. Gives readers the knowledge necessary to make proper interpretations and select appropriate techniques for analyzing multivariate data. Starts with a formulation of the population models, delineates the corresponding sample results, and liberally illustrates everything with examples.  Offers an abundance of examples and exercises based on real data.  Appropriate for experimental scientists in a variety of disciplines.},
	language = {English},
	publisher = {Pearson},
	author = {Johnson, Richard A. and Wichern, Dean W.},
	month = apr,
	year = {2007},
}

@article{lapide_new_1999,
	title = {New {Developments} in {Business} {Forecasting}},
	volume = {17},
	number = {2},
	journal = {The Journal of Business Forecasting Methods \& Systems},
	author = {Lapide, Larry},
	year = {1999},
	pages = {28--29},
}

@misc{noauthor_new_nodate,
	title = {New developments in business forecasting - {ProQuest}},
	url = {https://www.proquest.com/openview/b6101a663d68648d36f2a35480d926a3/1?pq-origsite=gscholar&cbl=28144},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
	language = {en},
	urldate = {2023-06-23},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\RF8GHNVB\\1.html:text/html},
}

@misc{noauthor_new_nodate-1,
	title = {New developments in business forecasting - {ProQuest}},
	url = {https://www.proquest.com/openview/b6101a663d68648d36f2a35480d926a3/1?pq-origsite=gscholar&cbl=28144},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
	language = {en},
	urldate = {2023-06-23},
}

@misc{noauthor_new_nodate-2,
	title = {New developments in business forecasting - {ProQuest}},
	url = {https://www.proquest.com/docview/226920994?pq-origsite=gscholar&fromopenview=true},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
	language = {en},
	urldate = {2023-06-23},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\83DI7S4E\\226920994.html:text/html},
}

@article{locke_new_2006-1,
	title = {New {Directions} in {Goal}-{Setting} {Theory}},
	volume = {15},
	issn = {0963-7214, 1467-8721},
	url = {http://journals.sagepub.com/doi/10.1111/j.1467-8721.2006.00449.x},
	doi = {10.1111/j.1467-8721.2006.00449.x},
	abstract = {Goal-setting theory is summarized regarding the effectiveness of specific, difficult goals; the relationship of goals to affect; the mediators of goal effects; the relation of goals to self-efficacy; the moderators of goal effects; and the generality of goal effects across people, tasks, countries, time spans, experimental designs, goal sources (i.e., self-set, set jointly with others, or assigned), and dependent variables. Recent studies concerned with goal choice and the factors that influence it, the function of learning goals, the effect of goal framing, goals and affect (well-being), group goal setting, goals and traits, macro-level goal setting, and conscious versus subconscious goals are described. Suggestions are given for future research.},
	language = {en},
	number = {5},
	urldate = {2023-06-23},
	journal = {Current Directions in Psychological Science},
	author = {Locke, Edwin A. and Latham, Gary P.},
	month = oct,
	year = {2006},
	pages = {265--268},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\CRUACDZG\\Locke and Latham - 2006 - New Directions in Goal-Setting Theory.pdf:application/pdf},
}

@article{russom_big_2011,
	title = {Big data analytics},
	volume = {19},
	number = {4},
	journal = {TDWI best practices report, fourth quarter},
	author = {Russom, Philip and {others}},
	year = {2011},
	pages = {1--34},
}

@article{maccarthy_supply_2016-1,
	title = {Supply chain evolution – theory, concepts and science},
	volume = {36},
	issn = {0144-3577},
	url = {https://doi.org/10.1108/IJOPM-02-2016-0080},
	doi = {10.1108/IJOPM-02-2016-0080},
	abstract = {Purpose Supply chains evolve and change in size, shape and configuration, and in how they are coordinated, controlled and managed. Some supply chains are mature and relatively unchanging. Some are subject to significant change. New supply chains may emerge and evolve for a variety of reasons. The purpose of this paper is to examine the nature of supply chain evolution and address the question “What makes a supply chain like it is?” Design/methodology/approach The paper analyses and develops key aspects, concepts and principal themes concerning the emergence and evolution of supply chains over their lifecycle. Findings The paper defines the supply chain lifecycle and identifies six factors that interact and may affect a supply chain over its lifecycle – technology and innovation, economics, markets and competition, policy and regulation, procurement and sourcing, supply chain strategies and re-engineering. A number of emergent themes and propositions on factors affecting a supply chain’s characteristics over its lifecycle are presented. The paper argues that a new science is needed to investigate and understand the supply chain lifecycle. Practical implications Supply chains are critical for the world economy and essential for modern life. Understanding the supply chain lifecycle and how supply chains evolve provides new perspectives for contemporary supply chain design and management. Originality/value The paper presents detailed analysis, critique and reflections from leading researchers on emerging, evolving and mature supply chains.},
	number = {12},
	urldate = {2023-06-26},
	journal = {International Journal of Operations \& Production Management},
	author = {MacCarthy, Bart L. and Blome, Constantin and Olhager, Jan and Srai, Jagjit Singh and Zhao, Xiande},
	month = jan,
	year = {2016},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Differentiation, Emergence, Evolution, Life cycle, Segmentation, Supply Chain},
	pages = {1696--1718},
	file = {Accepted Version:C\:\\Users\\abrar\\Zotero\\storage\\Q5PXMWZU\\MacCarthy et al. - 2016 - Supply chain evolution – theory, concepts and scie.pdf:application/pdf;Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\QP29FGL8\\html.html:text/html},
}

@inproceedings{singla_multi-relational_2004,
	title = {Multi-relational record linkage},
	booktitle = {Proc. {KDD}-2004 {Workshop} {Multi}-{Relational} {Data} {Mining}},
	author = {Singla, Parag and Domingos, Pedro},
	year = {2004},
	pages = {31--48},
}

@article{spitzer_monte_1978,
	title = {A {Monte} {Carlo} {Investigation} of the {Box}-{Cox} {Transformation} in {Small} {Samples}},
	volume = {73},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2286587},
	doi = {10.2307/2286587},
	abstract = {The small-sample properties of models which transform both the dependent and independent variables using the same Box-Cox transformation are investigated in sampling experiments. Bias does not appear to be a serious problem; however, the sign and size of the transformation parameter, which changes the coefficient of variation of the dependent variable, seriously affects the variances of the estimators. Hypothesis tests reveal that t statistics frequently lead to incorrect decisions since the actual sampling distributions have heavier tail areas than the t distribution.},
	number = {363},
	urldate = {2023-06-26},
	journal = {Journal of the American Statistical Association},
	author = {Spitzer, John J.},
	year = {1978},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {488--495},
}

@article{bickel_analysis_1981,
	title = {An {Analysis} of {Transformations} {Revisited}},
	volume = {76},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1981.10477649},
	doi = {10.1080/01621459.1981.10477649},
	abstract = {Following Box and Cox (1964), we assume that a transform Z i = h(Yi , λ) of our original data Yi satisfies a linear model. Consistency properties of the Box-Cox estimates (MLE's) of λ and the parameters in the linear model, as well as the asymptotic variances of these estimates, are considered. We find that in some structured models such as transformed linear regression with small to moderate error variances, the asymptotic variances of the estimates of the parameters in the linear model are much larger when the transformation parameter λ is unknown than when it is known. In some unstructured models such as transformed one-way analysis of variance with moderate to large error variances, the cost of not knowing λ is moderate to small. The case where the error distribution in the linear model is not normal but actually unknown is considered, and robust methods in the presence of transformations are introduced for this case. Asymptotics and simulation results for the transformed additive two-way layout show that much is gained by this robustification of the Box-Cox methods when the ratios of the means to the error standard deviation are moderate to large. However, the performance of all Box-Cox type procedures is unstable and highly dependent on the parameters of the model in structured models with small to moderate error variances.},
	number = {374},
	urldate = {2023-06-26},
	journal = {Journal of the American Statistical Association},
	author = {Bickel, Peter J. and Doksum, Kjell A.},
	month = jun,
	year = {1981},
	note = {Publisher: Taylor \& Francis
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1981.10477649},
	keywords = {Robustness, Linear model, Small σ asymptotics, Transformations},
	pages = {296--311},
}

@misc{noauthor_feature_nodate,
	title = {Feature {Selection} with {Ensembles}, {Artificial} {Variables}, and {Redundancy} {Elimination} {\textbar} {The} {Journal} of {Machine} {Learning} {Research}},
	url = {https://dl.acm.org/doi/abs/10.5555/1577069.1755828},
	urldate = {2023-06-26},
	file = {Feature Selection with Ensembles, Artificial Variables, and Redundancy Elimination | The Journal of Machine Learning Research:C\:\\Users\\abrar\\Zotero\\storage\\PZFLT9AA\\1577069.html:text/html},
}

@misc{noauthor_feature_nodate-1,
	title = {Feature {Selection} with {Ensembles}, {Artificial} {Variables}, and {Redundancy} {Elimination} {\textbar} {The} {Journal} of {Machine} {Learning} {Research}},
	url = {https://dl.acm.org/doi/abs/10.5555/1577069.1755828},
	urldate = {2023-06-26},
}

@article{tuv_feature_2009-1,
	title = {Feature {Selection} with {Ensembles}, {Artificial} {Variables}, and {Redundancy} {Elimination}},
	volume = {10},
	issn = {1532-4435},
	abstract = {Predictive models benefit from a compact, non-redundant subset of features that improves interpretability and generalization. Modern data sets are wide, dirty, mixed with both numerical and categorical predictors, and may contain interactive effects that require complex models. This is a challenge for filters, wrappers, and embedded feature selection methods. We describe details of an algorithm using tree-based ensembles to generate a compact subset of non-redundant features. Parallel and serial ensembles of trees are combined into a mixed method that can uncover masking and detect features of secondary effect. Simulated and actual examples illustrate the effectiveness of the approach.},
	journal = {The Journal of Machine Learning Research},
	author = {Tuv, Eugene and Borisov, Alexander and Runger, George and Torkkola, Kari},
	month = dec,
	year = {2009},
	pages = {1341--1366},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\N7DUBSMV\\Tuv et al. - 2009 - Feature Selection with Ensembles, Artificial Varia.pdf:application/pdf},
}

@article{peng_feature_2005-1,
	title = {Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy},
	volume = {27},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2005.159},
	abstract = {Feature selection is an important problem for pattern classification systems. We study how to select good features according to the maximal statistical dependency criterion based on mutual information. Because of the difficulty in directly implementing the maximal dependency condition, we first derive an equivalent form, called minimal-redundancy-maximal-relevance criterion (mRMR), for first-order incremental feature selection. Then, we present a two-stage feature selection algorithm by combining mRMR and other more sophisticated feature selectors (e.g., wrappers). This allows us to select a compact set of superior features at very low cost. We perform extensive experimental comparison of our algorithm and other methods using three different classifiers (naive Bayes, support vector machine, and linear discriminate analysis) and four different data sets (handwritten digits, arrhythmia, NCI cancer cell lines, and lymphoma tissues). The results confirm that mRMR leads to promising improvement on feature selection and classification accuracy.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Peng, Hanchuan and Long, Fuhui and Ding, C.},
	month = aug,
	year = {2005},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Performance analysis, Mutual information, Algorithm design and analysis, Cancer, classification., Costs, Diversity reception, Index Terms- Feature selection, maximal dependency, maximal relevance, minimal redundancy, mutual information, Pattern classification, Redundancy, Support vector machine classification, Support vector machines},
	pages = {1226--1238},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\abrar\\Zotero\\storage\\YDHEC6TA\\1453511.html:text/html},
}

@misc{jahin_bda-scm_nodate,
	title = {{BDA}-{SCM}},
	url = {https://www.overleaf.com/project/649055358be9118719081bf6},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2023-06-27},
	author = {Jahin, Md Abrar},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\WP7YUB5H\\649055358be9118719081bf6.html:text/html},
}

@article{mitra_comparative_2022-1,
	title = {A {Comparative} {Study} of {Demand} {Forecasting} {Models} for a {Multi}-{Channel} {Retail} {Company}: {A} {Novel} {Hybrid} {Machine} {Learning} {Approach}},
	volume = {3},
	issn = {2662-2556},
	shorttitle = {A {Comparative} {Study} of {Demand} {Forecasting} {Models} for a {Multi}-{Channel} {Retail} {Company}},
	url = {https://doi.org/10.1007/s43069-022-00166-4},
	doi = {10.1007/s43069-022-00166-4},
	abstract = {Demand forecasting has been a major concern of operational strategy to manage the inventory and optimize the customer satisfaction level. The researchers have proposed many conventional and advanced forecasting techniques, but no one leads to complete accuracy. Forecasting is equally important in manufacturing as well as retail companies. In this study, the performances of five regression techniques of machine learning, viz. random forest (RF), extreme gradient boosting (XGBoost), gradient boosting, adaptive boosting (AdaBoost), and artificial neural network (ANN) algorithms, are compared with a proposed hybrid (RF-XGBoost-LR) model for sales forecasting of a retail chain considering the various parameters of forecasting accuracy. The weekly sales data of a US-based retail company is considered in the analysis of the forecasts undertaking the attributes affecting the sale such as the temperature of the region and the size of the store. It is observed that the hybrid RF-XGBoost-LR outperformed the other models measured against various metrics of performance. This study may help the industry decision-maker to understand and improve the methods of forecasting.},
	language = {en},
	number = {4},
	urldate = {2023-06-27},
	journal = {Operations Research Forum},
	author = {Mitra, Arnab and Jain, Arnav and Kishore, Avinash and Kumar, Pravin},
	month = sep,
	year = {2022},
	keywords = {Machine learning, Demand forecasting, XGBoost, Random forest, AdaBoost, Gradient boosting, Statistical methods},
	pages = {58},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\XF8L3NJZ\\Mitra et al. - 2022 - A Comparative Study of Demand Forecasting Models f.pdf:application/pdf},
}

@inproceedings{de_santis_predicting_2017,
	title = {Predicting material backorders in inventory management using machine learning},
	doi = {10.1109/LA-CCI.2017.8285684},
	abstract = {Material backorder is a common supply chain problem, impacting an inventory system service level and effectiveness. Identifying parts with the highest chances of shortage prior its occurrence can present a high opportunity to improve an overall company's performance. In this paper, machine learning classifiers are investigated in order to propose a predictive model for this imbalanced class problem, where the relative frequency of items that goes into backorder is rare when compared to items that do not. Specific metrics such as area under the Receiver Operator Characteristic and precision-recall curves, sampling techniques and ensemble learning are employed in this particular task.},
	booktitle = {2017 {IEEE} {Latin} {American} {Conference} on {Computational} {Intelligence} ({LA}-{CCI})},
	author = {de Santis, Rodrigo Barbosa and de Aguiar, Eduardo Pestana and Goliatt, Leonardo},
	month = nov,
	year = {2017},
	keywords = {Supervised learning, Supply chain management, Predictive models, Training, Sampling methods, Prediction algorithms, Biological system modeling, ensembles of classifiers, imbalanced learning, inventory planning and control, Measurement, sampling methods},
	pages = {1--6},
}

@article{hajek_profit_2020-1,
	title = {A {Profit} {Function}-{Maximizing} {Inventory} {Backorder} {Prediction} {System} {Using} {Big} {Data} {Analytics}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2983118},
	abstract = {Inventory backorder prediction is widely recognized as an important component of inventory models. However, backorder prediction is traditionally based on stochastic approximation, thus neglecting the substantial amount of useful information hidden in historical inventory data. To provide those inventory models with a big data-driven backorder prediction, we propose a machine learning model equipped with an undersampling procedure to maximize the expected profit of backorder decisions. This is achieved by integrating the proposed profit-based measure into the prediction model and optimizing the decision threshold to identify the optimal backorder strategy. We show that the proposed inventory backorder prediction model shows better prediction and profit function performance than the state-of-the-art machine learning methods used for large imbalanced data. Notably, the proposed model is computationally effective and robust to variation in both warehousing/inventory cost and sales margin. In addition, the model predicts both major (non-backorder items) and minor (backorder items) classes in a benchmark dataset.},
	journal = {IEEE Access},
	author = {Hajek, Petr and Abedin, Mohammad Zoynul},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Big Data, Big data, machine learning, Data models, Economics, Predictive models, Computational modeling, prediction, Biological system modeling, inventory backorder, Inventory management},
	pages = {58982--58994},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\TRYT2DHN\\Hajek and Abedin - 2020 - A Profit Function-Maximizing Inventory Backorder P.pdf:application/pdf},
}

@article{srivastav_multi-objective_2016,
	title = {Multi-objective optimization of hybrid backorder inventory model},
	volume = {51},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417415008404},
	doi = {10.1016/j.eswa.2015.12.032},
	abstract = {This paper addresses inventory problem for the products that are sold in monopolistic and captive markets experiencing hybrid backorder (i.e., fixed backorder and time-weighted backorder). The problem with stochastic demand is studied first by developing single objective (cost) inventory model. Computational results of a numerical problem show the effectiveness of hybrid backorder inventory model over fixed backorder inventory model. The model is later extended to multi-objective inventory model. Three objectives of multi-objective inventory model are the minimization of total cost, minimization of stockout units and minimization of the frequency of stockout. A multi-objective particle swarm optimization (MOPSO) algorithm is used to solve the inventory model and generate Pareto curves. The Pareto curves obtained for hybrid backorder inventory model are compared with the existing Pareto curves that are based on fixed backorder. The results show a substantial reduction in stockout units and frequency of stockout with a marginal rise in cost with proposed hybrid backorder inventory system in comparison to existing fixed backorder inventory system. Sensitivity analysis is done to study the robustness of total cost, order quantity, and safety stock factor with the change in holding cost. In the end, the performance of the MOPSO algorithm is compared with the multi-objective genetic algorithm (MOGA). The metrics that are used for the performance measurement of the algorithms are error ratio, spacing and maximum spread.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Expert Systems with Applications},
	author = {Srivastav, Achin and Agrawal, Sunil},
	month = jun,
	year = {2016},
	keywords = {Inventory, Multi-objective particle swarm optimization, Backorder, Multi-objective genetic algorithm, Pareto},
	pages = {76--84},
}

@inproceedings{de_santis_predicting_2017-1,
	title = {Predicting material backorders in inventory management using machine learning},
	doi = {10.1109/LA-CCI.2017.8285684},
	abstract = {Material backorder is a common supply chain problem, impacting an inventory system service level and effectiveness. Identifying parts with the highest chances of shortage prior its occurrence can present a high opportunity to improve an overall company's performance. In this paper, machine learning classifiers are investigated in order to propose a predictive model for this imbalanced class problem, where the relative frequency of items that goes into backorder is rare when compared to items that do not. Specific metrics such as area under the Receiver Operator Characteristic and precision-recall curves, sampling techniques and ensemble learning are employed in this particular task.},
	booktitle = {2017 {IEEE} {Latin} {American} {Conference} on {Computational} {Intelligence} ({LA}-{CCI})},
	author = {de Santis, Rodrigo Barbosa and de Aguiar, Eduardo Pestana and Goliatt, Leonardo},
	month = nov,
	year = {2017},
	keywords = {Supervised learning, Supply chain management, Predictive models, Training, Sampling methods, Prediction algorithms, Biological system modeling, ensembles of classifiers, imbalanced learning, inventory planning and control, Measurement, sampling methods},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\abrar\\Zotero\\storage\\96J6H3YV\\8285684.html:text/html},
}

@phdthesis{li_backorder_2017,
	title = {Backorder {Prediction} {Using} {Machine} {Learning} {For} {Danish} {Craft} {Beer} {Breweries}},
	language = {en},
	school = {Aalborg University},
	author = {Li, Yuqi},
	year = {2017},
	file = {Li - Backorder Prediction Using Machine Learning For Da.pdf:C\:\\Users\\abrar\\Zotero\\storage\\D7DK5DB8\\Li - Backorder Prediction Using Machine Learning For Da.pdf:application/pdf},
}

@inproceedings{kang_robust_2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Robust} {Classifier} for {Imbalanced} {Datasets}},
	isbn = {978-3-319-06608-0},
	doi = {10.1007/978-3-319-06608-0_18},
	abstract = {Imbalanced dataset classification is a challenging problem, since many classifiers are sensitive to class distribution so that the classifiers’ prediction has bias towards majority class. Hellinger Distance has been proven that it is skew-insensitive and the decision trees that employ Hellinger Distance as a splitting criterion have shown better performance than other decision trees based on Information Gain. We propose a new decision tree induction classifier (HeDEx) based on Hellinger Distance that is randomized ensemble trees selecting both attribute and split-point at random. We also propose hyperplane as a decision surface for HeDEx to improve the performance. A new pattern-based oversampling method is also proposed in this paper to reduce the bias towards majority class. The patterns are detected from HeDEx and the new instances generated are applied after verification process using Hellinger Distance Decision Trees. Our experiments show that the proposed methods show performance improvements on imbalanced datasets over the state-of-the-art Hellinger Distance Decision Trees.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {Kang, Sori and Ramamohanarao, Kotagiri},
	editor = {Tseng, Vincent S. and Ho, Tu Bao and Zhou, Zhi-Hua and Chen, Arbee L. P. and Kao, Hung-Yu},
	year = {2014},
	keywords = {Class Distribution, Ensemble Method, Hellinger Distance, Minority Class, Random Subspace},
	pages = {212--223},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\XQX84Y96\\Kang and Ramamohanarao - 2014 - A Robust Classifier for Imbalanced Datasets.pdf:application/pdf},
}

@article{garcia_dynamic_2018,
	title = {Dynamic ensemble selection for multi-class imbalanced datasets},
	volume = {445-446},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025518301725},
	doi = {10.1016/j.ins.2018.03.002},
	abstract = {Many real-world classification tasks suffer from the class imbalanced problem, in which some classes are highly underrepresented as compared to other classes. In this paper, we focus on multi-class imbalance problems which are considerably more difficult to address than two-class imbalanced problems. On this account, we develop a novel and effective procedure, called dynamic ensemble selection for multi-class imbalanced datasets (DES-MI), in which the competence of the candidate classifiers are assessed with weighted instances in the neighborhood. The proposed DES-MI consists of two key components: the generation of balanced training datasets and the selection of appropriate classifiers. To do so, we develop a preprocessing procedure to balance the training dataset which relies on random balance. To select the most appropriate classifiers in the scenario of multi-class imbalance problems, we propose a weighting mechanism to highlight the competence of classifiers that are more powerful in classifying examples in the region of underrepresented competence. We develop a thorough experimental study in order to verify the benefits of DES-MI in handling multi-class imbalanced datasets. The obtained results, supported by the proper statistical analysis, indicate that DES-MI is able to improve the classification performance for multi-class imbalanced datasets.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Information Sciences},
	author = {García, Salvador and Zhang, Zhong-Liang and Altalhi, Abdulrahman and Alshomrani, Saleh and Herrera, Francisco},
	month = jun,
	year = {2018},
	keywords = {Binary decomposition, Ensemble learning, Imbalanced datasets, Multi-class classification, Multiple classifier system, Resampling techniques},
	pages = {22--37},
}

@article{chawla_smote_2002,
	title = {{SMOTE}: {Synthetic} {Minority} {Over}-sampling {Technique}},
	volume = {16},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	shorttitle = {{SMOTE}},
	url = {https://www.jair.org/index.php/jair/article/view/10302},
	doi = {10.1613/jair.953},
	abstract = {An approach to the construction of classifiers from    imbalanced datasets is described. A dataset is imbalanced if the    classification categories are not approximately equally    represented. Often real-world data sets are predominately composed of    ``normal'' examples with only a small percentage of ``abnormal'' or    ``interesting'' examples. It is also the case that the cost of    misclassifying an abnormal (interesting) example as a normal example    is often much higher than the cost of the reverse    error. Under-sampling of the majority (normal) class has been proposed    as a good means of increasing the sensitivity of a classifier to the    minority class. This paper shows that a combination of our method of    over-sampling the minority (abnormal) class and under-sampling the    majority (normal) class can achieve better classifier performance (in    ROC space) than only under-sampling the majority class.  This paper    also shows that a combination of our method of over-sampling the    minority class and under-sampling the majority class can achieve    better classifier performance (in ROC space) than varying the loss    ratios in Ripper or class priors in Naive Bayes. Our method of    over-sampling the minority class involves creating synthetic minority    class examples.  Experiments are performed using C4.5, Ripper and a    Naive Bayes classifier. The method is evaluated using the area under    the Receiver Operating Characteristic curve (AUC) and the ROC convex    hull strategy.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Journal of Artificial Intelligence Research},
	author = {Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
	month = jun,
	year = {2002},
	pages = {321--357},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\JIM2NQK9\\Chawla et al. - 2002 - SMOTE Synthetic Minority Over-sampling Technique.pdf:application/pdf},
}

@article{mart_tactical_2013,
	series = {Focusing on {Inventories}: {Research} and {Applications}},
	title = {Tactical inventory and backorder decisions for systems with predictable production yield},
	volume = {143},
	issn = {0925-5273},
	url = {https://www.sciencedirect.com/science/article/pii/S092552731200031X},
	doi = {10.1016/j.ijpe.2012.01.029},
	abstract = {We consider a manufacturing system with stochastic demand and predictable production yield. The manufacturer has predetermined prices and limited production capacity in each period. The manufacturer also has the option to save some inventory for future periods even if there is demand in the current period. The demand that is not met is lost or may be backordered for only one period. Our objective is to maximize the expected profit by choosing optimal produce-up-to level (Yt¯⁎), save (St⁎) and backorder quantities (Bt⁎) in each period t. We formulate this problem as a Markov Decision Process where the state of the system is represented by the net inventory and the yield rate. We show that a modified order-up-to policy (Yt¯⁎,St⁎,Bt⁎) is optimal in each period t. We also perform computational analysis to examine the effects of production yield on the optimal decisions.},
	language = {en},
	number = {2},
	urldate = {2023-07-07},
	journal = {International Journal of Production Economics},
	author = {Mart, Turgut and Duran, Serhan and Bakal, İsmail Serdar},
	month = jun,
	year = {2013},
	keywords = {Dynamic programming, Production yield, Tactical inventory},
	pages = {294--303},
	file = {Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\F4DUFY7F\\Mart et al. - 2013 - Tactical inventory and backorder decisions for sys.pdf:application/pdf},
}

@article{xu_finite-horizon_2017,
	title = {A finite-horizon inventory system with partial backorders and inventory holdback},
	volume = {45},
	issn = {0167-6377},
	url = {https://www.sciencedirect.com/science/article/pii/S0167637717302286},
	doi = {10.1016/j.orl.2017.04.007},
	abstract = {We consider a periodic-review base stock inventory system with partial backorders. At the beginning of each period t of a T period problem, an order of size qt is placed for delivery one period later. As the stochastic demand is realized, as much as possible of it is filled immediately from the inventory on-hand. If the realized demand exceeds the inventory on-hand, up to qt–kt units of excess demand are backordered to be filled from the pipeline inventory or future orders. The on-order quantity kt denotes the reservation quantity held back for use in subsequent periods. The case kt=qt yields the full lost sales model while the case kt=−∞ yields the full backorder model.},
	language = {en},
	number = {4},
	urldate = {2023-07-07},
	journal = {Operations Research Letters},
	author = {Xu, Yanyi and Bisi, Arnab and Dada, Maqbool},
	month = jul,
	year = {2017},
	keywords = {Inventory, Backorders, Base-stock system, Lost sales, Optimal policy, Stochastic demand},
	pages = {315--322},
}

@article{prak_general_2019,
	series = {Special {Section}: {Supply} {Chain} {Forecasting}},
	title = {A general method for addressing forecasting uncertainty in inventory models},
	volume = {35},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207017301358},
	doi = {10.1016/j.ijforecast.2017.11.004},
	abstract = {In practice, inventory decisions depend heavily on demand forecasts, but the literature typically assumes that demand distributions are known. This means that estimates are substituted directly for the unknown parameters, leading to insufficient safety stocks, stock-outs, low service, and high costs. We propose a framework for addressing this estimation uncertainty that is applicable to any inventory model, demand distribution, and parameter estimator. The estimation errors are modeled and a predictive lead time demand distribution obtained, which is then substituted into the inventory model. We illustrate this framework for several different demand models. When the estimates are based on ten observations, the relative savings are typically between 10\% and 30\% for mean-stationary demand. However, the savings are larger when the estimates are based on fewer observations, when backorders are costlier, or when the lead time is longer. In the presence of a trend, the savings are between 50\% and 80\% for several scenarios.},
	language = {en},
	number = {1},
	urldate = {2023-07-07},
	journal = {International Journal of Forecasting},
	author = {Prak, Dennis and Teunter, Ruud},
	month = jan,
	year = {2019},
	keywords = {Bayesian methods, Demand forecasting, Inventory control, Parameter uncertainty, Safety stock},
	pages = {224--238},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\WW46X5E9\\Prak and Teunter - 2019 - A general method for addressing forecasting uncert.pdf:application/pdf},
}

@article{chaharsooghi_reinforcement_2008,
	series = {Information {Technology} and {Systems} in the {Internet}-{Era}},
	title = {A reinforcement learning model for supply chain ordering management: {An} application to the beer game},
	volume = {45},
	issn = {0167-9236},
	shorttitle = {A reinforcement learning model for supply chain ordering management},
	url = {https://www.sciencedirect.com/science/article/pii/S0167923608000560},
	doi = {10.1016/j.dss.2008.03.007},
	abstract = {A major challenge in supply chain ordering management is the coordination of ordering policies adopted by each level of the chain, so as to minimize inventory costs. This paper describes a new approach to decide on ordering policies of supply chain members in an integrated manner. In the first step supply chain ordering management has been considered as a multi-agent system and formulated as a reinforcement learning (RL) model. In the final step a Q-learning algorithm is proposed to solve the RL model. Results show that the reinforcement learning ordering mechanism (RLOM) is better than two other known algorithms.},
	language = {en},
	number = {4},
	urldate = {2023-07-07},
	journal = {Decision Support Systems},
	author = {Chaharsooghi, S. Kamal and Heydari, Jafar and Zegordi, S. Hessameddin},
	month = nov,
	year = {2008},
	keywords = {Supply chain, Reinforcement learning, Multi-agent systems, Beer game, Ordering policy},
	pages = {949--959},
}

@article{abdul-jalbar_two-echelon_2009,
	title = {A two-echelon inventory/distribution system with power demand pattern and backorders},
	volume = {122},
	issn = {0925-5273},
	url = {https://www.sciencedirect.com/science/article/pii/S0925527309001248},
	doi = {10.1016/j.ijpe.2009.04.017},
	abstract = {This paper addresses the implications of considering power demand pattern and backorders in the one-warehouse N-retailer problem. Specifically, we assume that items at the retailers are withdrawn from the inventory following a power pattern. The objective function consists of the sum of ordering, holding and backordering costs at all installations. This objective function depends on the class of inventory policies that we choose for the formulation of the problem. In general, obtaining the cost function is an arduous task since the average inventory at the warehouse could be difficult to determine. However, if we apply single-cycle policies the computation of the total average cost becomes possible. Under these assumptions we show that the one-warehouse N-retailer system with power demand pattern and backorders can be formulated as a mixed non linear programming problem.},
	language = {en},
	number = {2},
	urldate = {2023-07-07},
	journal = {International Journal of Production Economics},
	author = {Abdul-Jalbar, Beatriz and Gutiérrez, José M. and Sicilia, Joaquín},
	month = dec,
	year = {2009},
	keywords = {Supply chain management, Single-cycle policies, Two-echelon inventory system},
	pages = {519--524},
}

@article{brahimi_multi-item_2016,
	title = {Multi-item production routing problem with backordering: a {MILP} approach},
	volume = {54},
	issn = {0020-7543},
	shorttitle = {Multi-item production routing problem with backordering},
	url = {https://doi.org/10.1080/00207543.2015.1047971},
	doi = {10.1080/00207543.2015.1047971},
	abstract = {The aim of this paper is to present mixed integer linear programming formulations for the production routing problem with backordering (PRP-B) and a new hybrid heuristic to solve the problem. The PRP-B is considered in the context of a supply chain consisting of a production facility with limited production and storage capacities and geographically dispersed points of sale with limited storage capacities. The PRP-B integrates multiple item lot sizing decisions and vehicle routing decisions to the points of sale, where backordering of end customer demands is allowed at a penalty. Two integrated mixed integer programming models are formulated and a solution procedure consisting of a relax-and-fix heuristic combined with a local search algorithm is proposed. The numerical results show that this hybrid heuristic outperforms a state-of-the-art MIP commercial solver, in terms of solution quality and CPU times.},
	number = {4},
	urldate = {2023-07-07},
	journal = {International Journal of Production Research},
	author = {Brahimi, Nadjib and Aouam, Tarik},
	month = feb,
	year = {2016},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2015.1047971},
	keywords = {backordering, lot sizing problem, production planning, production routing problem, relax-and-fix heuristic, vehicle routing problem},
	pages = {1076--1093},
}

@article{van_foreest_base-stock_2018,
	title = {Base-stock policies with reservations},
	volume = {81},
	issn = {0305-0483},
	url = {https://www.sciencedirect.com/science/article/pii/S0305048316309586},
	doi = {10.1016/j.omega.2017.09.008},
	abstract = {All intensively studied and widely applied inventory control policies satisfy demand in accordance with the First-Come-First-Served (FCFS) rule, whether this demand is in backorder or not. Interestingly, this rule is sub-optimal when the fill-rate is constrained or when the backorder cost structure includes fixed costs per backorder and costs per backorder per unit time. In this paper we study the degree of sub-optimality of the FCFS rule for inventory systems controlled by the well-known base-stock policy. As an alternative to the FCFS rule, we propose and analyze a class of generalized base-stock policies that reserve some maximum number of items in stock for future demands, even if backorders exist. Our analytic results and numerical investigations show that such alternative stock reservation policies are indeed very simple and considerably improve either the fillrate or reduce the total cost, without having much effect on the backorder level.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Omega},
	author = {Van Foreest, Nicky D. and Teunter, Ruud H. and Syntetos, Aris A.},
	month = dec,
	year = {2018},
	keywords = {Base-stock models, Inventory Theory and Control, Stock reservation policies},
	pages = {48--56},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\BIYPFCB6\\Van Foreest et al. - 2018 - Base-stock policies with reservations.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\QEAAH3VS\\S0305048316309586.html:text/html},
}

@article{ghiami_planning_2016,
	title = {Planning for shortages? {Net} {Present} {Value} analysis for a deteriorating item with partial backlogging},
	volume = {178},
	issn = {0925-5273},
	shorttitle = {Planning for shortages?},
	url = {https://www.sciencedirect.com/science/article/pii/S092552731630055X},
	doi = {10.1016/j.ijpe.2016.04.021},
	abstract = {This paper develops inventory models to help answer strategic questions concerning whether planning for shortages offers financial benefits. A production-inventory system producing a deteriorating product in batches at a finite production rate with partial backordering is considered. Customers pay a deposit when placing a backorder. Backordered items receive a discount on the sales price. As lost sales may lead to customers not returning, the demand rate may depend on the fraction of lost sales. We develop a cash-flow based profit maximising Net Present Value (NPV) model without the inventory cost parameters commonly used in this context: unit holding cost, unit backorder cost, unit deterioration cost, and unit lost sales cost. The model finds the optimal inventory policy just like NPV models that discount the traditional parameters but has the advantage of not needing to estimate the value of the traditional parameters. It is shown that in models based on discounting the traditional parameters, the parameters are not exogenously determinable but are non-trivial functions of non-financial endogenous system parameters such as the production rate, annual demand rate, and backorder rate. Extensive numerical experiments illustrate how cash-flow NPV models provide insights into the value of planning for shortages and strategic choices about the design of the production-inventory system. It also provides insight into the classical problem of how to interpret unit backorder cost and unit lost sales cost. The study indicates that these insights cannot be reliably obtained from NPV models based on discounting unit backorder costs and unit lost sales costs.},
	language = {en},
	urldate = {2023-07-07},
	journal = {International Journal of Production Economics},
	author = {Ghiami, Yousef and Beullens, Patrick},
	month = aug,
	year = {2016},
	keywords = {Deteriorating inventory, Finite production rate, Net Present Value, Shortages},
	pages = {1--11},
	file = {Accepted Version:C\:\\Users\\abrar\\Zotero\\storage\\M97ILF9A\\Ghiami and Beullens - 2016 - Planning for shortages Net Present Value analysis.pdf:application/pdf},
}

@article{ganesh_kumar_multi-item_2019,
	title = {Multi-item inventory model with variable backorder and price discount under trade credit policy in stochastic demand},
	volume = {57},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2018.1480839},
	doi = {10.1080/00207543.2018.1480839},
	abstract = {In this paper, a two echelon supply chain with one manufacturer and one retailer is developed for multi products. The retailer faced with the uncertain demand for all products which follows a normal distribution. The production process is assumed to be imperfect, and the defectiveness is assumed to follow a beta distribution. The manufacturer produces and delivers the products in a number of equal-sized batches to the manufacturer's warehouse, and thereby it is delivers in a number of equal batches to the retailer's warehouse. Shortages are allowed to occur, at the retailer side, and it is backordered partially. The retailer offers a price discount for backordered items to his customers. Both the lead time crashing cost and the partial backorder ratio are considered as the inverse function of lead time. Under these assumptions, there are three inventory models proposed in this paper, one with non-integrated approach, the other with an integrated approach without trade credit and finally an integrated approach with trade credit. A new iterative algorithmic procedure has been developed to minimise the total cost. Finally, numerical examples are given to illustrate the models and the sensitivity analysis is conducted over various model parameters.},
	number = {1},
	urldate = {2023-07-07},
	journal = {International Journal of Production Research},
	author = {Ganesh Kumar, M. and Uthayakumar, R.},
	month = jan,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2018.1480839},
	keywords = {imperfect production, inventory control, lead time reduction, multi-item, variable backorder},
	pages = {298--320},
}

@article{ganesh_kumar_multi-item_2019-1,
	title = {Multi-item inventory model with variable backorder and price discount under trade credit policy in stochastic demand},
	volume = {57},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2018.1480839},
	doi = {10.1080/00207543.2018.1480839},
	abstract = {In this paper, a two echelon supply chain with one manufacturer and one retailer is developed for multi products. The retailer faced with the uncertain demand for all products which follows a normal distribution. The production process is assumed to be imperfect, and the defectiveness is assumed to follow a beta distribution. The manufacturer produces and delivers the products in a number of equal-sized batches to the manufacturer's warehouse, and thereby it is delivers in a number of equal batches to the retailer's warehouse. Shortages are allowed to occur, at the retailer side, and it is backordered partially. The retailer offers a price discount for backordered items to his customers. Both the lead time crashing cost and the partial backorder ratio are considered as the inverse function of lead time. Under these assumptions, there are three inventory models proposed in this paper, one with non-integrated approach, the other with an integrated approach without trade credit and finally an integrated approach with trade credit. A new iterative algorithmic procedure has been developed to minimise the total cost. Finally, numerical examples are given to illustrate the models and the sensitivity analysis is conducted over various model parameters.},
	number = {1},
	urldate = {2023-07-07},
	journal = {International Journal of Production Research},
	author = {Ganesh Kumar, M. and Uthayakumar, R.},
	month = jan,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2018.1480839},
	keywords = {imperfect production, inventory control, lead time reduction, multi-item, variable backorder},
	pages = {298--320},
}

@article{brahimi_multi-item_2016-1,
	title = {Multi-item production routing problem with backordering: a {MILP} approach},
	volume = {54},
	issn = {0020-7543},
	shorttitle = {Multi-item production routing problem with backordering},
	url = {https://doi.org/10.1080/00207543.2015.1047971},
	doi = {10.1080/00207543.2015.1047971},
	abstract = {The aim of this paper is to present mixed integer linear programming formulations for the production routing problem with backordering (PRP-B) and a new hybrid heuristic to solve the problem. The PRP-B is considered in the context of a supply chain consisting of a production facility with limited production and storage capacities and geographically dispersed points of sale with limited storage capacities. The PRP-B integrates multiple item lot sizing decisions and vehicle routing decisions to the points of sale, where backordering of end customer demands is allowed at a penalty. Two integrated mixed integer programming models are formulated and a solution procedure consisting of a relax-and-fix heuristic combined with a local search algorithm is proposed. The numerical results show that this hybrid heuristic outperforms a state-of-the-art MIP commercial solver, in terms of solution quality and CPU times.},
	number = {4},
	urldate = {2023-07-07},
	journal = {International Journal of Production Research},
	author = {Brahimi, Nadjib and Aouam, Tarik},
	month = feb,
	year = {2016},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2015.1047971},
	keywords = {backordering, lot sizing problem, production planning, production routing problem, relax-and-fix heuristic, vehicle routing problem},
	pages = {1076--1093},
}

@article{rong_heuristics_2017,
	title = {Heuristics for {Base}-{Stock} {Levels} in {Multi}-{Echelon} {Distribution} {Networks}},
	volume = {26},
	copyright = {© 2017 Production and Operations Management Society},
	issn = {1937-5956},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/poms.12717},
	doi = {10.1111/poms.12717},
	abstract = {We study inventory optimization for locally controlled, continuous-review distribution systems with stochastic customer demands. Each node follows a base-stock policy and a first-come, first-served allocation policy. We develop two heuristics, the recursive optimization (RO) heuristic and the decomposition-aggregation (DA) heuristic, to approximate the optimal base-stock levels of all the locations in the system. The RO heuristic applies a bottom-up approach that sequentially solves single-variable, convex problems for each location. The DA heuristic decomposes the distribution system into multiple serial systems, solves for the base-stock levels of these systems using the newsvendor heuristic of Shang and Song (2003), and then aggregates the serial systems back into the distribution system using a procedure we call “backorder matching.” A key advantage of the DA heuristic is that it does not require any evaluation of the cost function (a computationally costly operation that requires numerical convolution). We show that, for both RO and DA, changing some of the parameters, such as leadtime, unit backordering cost, and demand rate, of a location has an impact only on its own local base-stock level and its upstream locations’ local base-stock levels. An extensive numerical study shows that both heuristics perform well, with the RO heuristic providing more accurate results and the DA heuristic consuming less computation time. We show that both RO and DA are asymptotically optimal along multiple dimensions for two-echelon distribution systems. Finally, we show that, with minor changes, both RO and DA are applicable to the balanced allocation policy.},
	language = {en},
	number = {9},
	urldate = {2023-07-07},
	journal = {Production and Operations Management},
	author = {Rong, Ying and Atan, Zümbül and Snyder, Lawrence V.},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/poms.12717},
	keywords = {heuristics, asymptotic analysis, distribution network, inventory, multi-echelon supply chain},
	pages = {1760--1777},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\EUF8KZAV\\Rong et al. - 2017 - Heuristics for Base-Stock Levels in Multi-Echelon .pdf:application/pdf},
}

@article{bjork_analytical_2009,
	series = {Special {Section} on {Bayesian} {Modelling}},
	title = {An analytical solution to a fuzzy economic order quantity problem},
	volume = {50},
	issn = {0888-613X},
	url = {https://www.sciencedirect.com/science/article/pii/S0888613X08001655},
	doi = {10.1016/j.ijar.2008.10.001},
	abstract = {This paper contributes to the set of models capturing the economic order quantity with backorders. In real life situations, both the demand and the lead times are uncertain. These uncertainties are handled with fuzzy numbers and the analytical solution to the optimization problem, where both the demand and the lead times are formulated as a triangular fuzzy numbers, is obtained. Finally the solution from the new approach is compared to earlier work and through an example, it is shown that the uncertainties result in increased order quantities.},
	language = {en},
	number = {3},
	urldate = {2023-07-07},
	journal = {International Journal of Approximate Reasoning},
	author = {Björk, Kaj-Mikael},
	month = mar,
	year = {2009},
	keywords = {Fuzzy numbers, Inventory management, Economic order quantity},
	pages = {485--493},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\5PYCW3UP\\Björk - 2009 - An analytical solution to a fuzzy economic order q.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\6H8AZG3H\\S0888613X08001655.html:text/html},
}

@article{kazemi_incorporating_2015,
	title = {Incorporating human learning into a fuzzy {EOQ} inventory model with backorders},
	volume = {87},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835215002272},
	doi = {10.1016/j.cie.2015.05.014},
	abstract = {Even though publications on fuzzy inventory problems are constantly increasing, modelling the decision maker’s characteristics and their effect on his/her decisions and consequently on the planning outcome has not attracted much attention in the literature. In order to fill this research gap and model reality more accurately, this paper develops a new fuzzy EOQ inventory model with backorders that considers human learning over the planning horizon. The paper is an extension of an existing EOQ inventory model with backorders in which both demand and lead times are fuzzified. Here, the assumption of constant fuzziness is relaxed by incorporating the concept of learning in fuzziness into the model considering that the degree of fuzziness reduces over the planning horizon. The proposed fuzzy EOQ inventory model with backorders and learning in fuzziness has a good performance in efficiency. Finally, it is worth mentioning that learning in fuzziness decreases the total inventory cost.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Computers \& Industrial Engineering},
	author = {Kazemi, Nima and Shekarian, Ehsan and Cárdenas-Barrón, Leopoldo Eduardo and Olugu, Ezutah Udoncy},
	month = sep,
	year = {2015},
	keywords = {Backorders, EOQ, Fuzzy inventory management, Human learning, Learning in fuzziness},
	pages = {540--542},
}

@article{srivastav_multi-objective_2016-1,
	title = {Multi-objective optimization of hybrid backorder inventory model},
	volume = {51},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417415008404},
	doi = {10.1016/j.eswa.2015.12.032},
	abstract = {This paper addresses inventory problem for the products that are sold in monopolistic and captive markets experiencing hybrid backorder (i.e., fixed backorder and time-weighted backorder). The problem with stochastic demand is studied first by developing single objective (cost) inventory model. Computational results of a numerical problem show the effectiveness of hybrid backorder inventory model over fixed backorder inventory model. The model is later extended to multi-objective inventory model. Three objectives of multi-objective inventory model are the minimization of total cost, minimization of stockout units and minimization of the frequency of stockout. A multi-objective particle swarm optimization (MOPSO) algorithm is used to solve the inventory model and generate Pareto curves. The Pareto curves obtained for hybrid backorder inventory model are compared with the existing Pareto curves that are based on fixed backorder. The results show a substantial reduction in stockout units and frequency of stockout with a marginal rise in cost with proposed hybrid backorder inventory system in comparison to existing fixed backorder inventory system. Sensitivity analysis is done to study the robustness of total cost, order quantity, and safety stock factor with the change in holding cost. In the end, the performance of the MOPSO algorithm is compared with the multi-objective genetic algorithm (MOGA). The metrics that are used for the performance measurement of the algorithms are error ratio, spacing and maximum spread.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Expert Systems with Applications},
	author = {Srivastav, Achin and Agrawal, Sunil},
	month = jun,
	year = {2016},
	keywords = {Inventory, Multi-objective particle swarm optimization, Backorder, Multi-objective genetic algorithm, Pareto},
	pages = {76--84},
}

@article{lin_economic_2010,
	title = {An economic order quantity with imperfect quality and quantity discounts},
	volume = {34},
	issn = {0307-904X},
	url = {https://www.sciencedirect.com/science/article/pii/S0307904X1000051X},
	doi = {10.1016/j.apm.2010.02.004},
	abstract = {Previous studies in the issue of inventory models with imperfect quality assumed the defectives could be sold in a batch by the end of the inspection process and the manufacturing systems were push systems. However, the above assumptions may not be true in the pull system in which buyer is powerful. Therefore, in this paper, we develop a new inventory model for items with imperfect quality and quantity discounts where buyer has exerted power over its supplier. Based on the concept of powerful buyer, there are three considerations included in this new model: (1) the order quantity is manufactured at one setup and is shipped over multiple deliveries, (2) the defectives are screened out by a 100\% inspection for each shipment but sold in a batch by the end of inspection at the last shipment of each cycle, and (3) the supplier offers quantity discounts to response the request of the powerful buyer. Further, an algorithm is developed to help the powerful buyer to determine the optimal order policy accurately and quickly. Two numerical examples are available in this paper to illustrate the proposed model and algorithm. Besides, based on the numerical examples, a sensitivity analysis is made to investigate the effects of four important parameters (the inspection rate, the defective rate, the receiving cost, and the ordering cost) on the optimal solution.},
	language = {en},
	number = {10},
	urldate = {2023-07-07},
	journal = {Applied Mathematical Modelling},
	author = {Lin, Tien-Yu},
	month = oct,
	year = {2010},
	keywords = {Inventory, Imperfect quality, Multiple deliveries, Powerful buyer, Quantity discounts},
	pages = {3158--3165},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\Q2BMLF2K\\Lin - 2010 - An economic order quantity with imperfect quality .pdf:application/pdf},
}

@article{taleizadeh_economic_2012,
	title = {An economic order quantity model with partial backordering and a special sale price},
	volume = {221},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S037722171200241X},
	doi = {10.1016/j.ejor.2012.03.032},
	abstract = {A constant unit purchase cost is one of the main assumptions in the classic economic order quantity model. In practice, suppliers sometimes offer special sale prices to stimulate sales or decrease inventories of certain items. In this paper we develop an EOQ model with a special sale price and partial backordering. We prove the convexity of the cost-reduction function if a special order is placed at the special sale price. A solution method is proposed and numerical examples are presented.},
	language = {en},
	number = {3},
	urldate = {2023-07-07},
	journal = {European Journal of Operational Research},
	author = {Taleizadeh, Ata Allah and Pentico, David W. and Aryanezhad, Mirbahador and Ghoreyshi, Seyed Mohammad},
	month = sep,
	year = {2012},
	keywords = {Inventory, EOQ, Partial backordering, Special sale prices},
	pages = {571--583},
}

@article{kim_improved_2018,
	title = {An improved way to calculate imperfect items during long-run production in an integrated inventory model with backorders},
	volume = {47},
	issn = {0278-6125},
	url = {https://www.sciencedirect.com/science/article/pii/S0278612518300578},
	doi = {10.1016/j.jmsy.2018.04.016},
	abstract = {This paper investigates an improved way to calculate imperfect items in an integrated inventory model with distribution free approach for lead time demand to simultaneously optimize lot size, safety factor, number of shipments, and lead time. The backorder rate depends on the reduced lead time. Due to the quality of products, each item is inspected by the buyer and defective items are sent to the supplier during delivery of the next lot. Some investments are used to improve the quality of products and reduce the setup cost. The model is solved by using distribution free approach with known mean and standard deviation. An improved solution methodology is designed and a lemma is constructed to obtain global optimum solution of the integrated model. An improved algorithm is designed to approach the global optimal solution. Five numerical examples and two special cases are provided to validate the suggested model. A case study is conducted for which the global optimum solution is obtained using the proposed solution methodology. Simplified versions of the proposed model, illustrated through numerical examples as special cases, converged over the existing theories. Some managerial insights are provided to help managers implement the suggested model in real time situations.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Journal of Manufacturing Systems},
	author = {Kim, Min-Soo and Kim, Jong-Soo and Sarkar, Biswajit and Sarkar, Mitali and Iqbal, Muhammad Waqas},
	month = apr,
	year = {2018},
	keywords = {Backorder, Inventory management, Distribution systems, Imperfect production, Quality control},
	pages = {153--167},
}

@article{kazemi_inventory_2010,
	series = {North {American} {Fuzzy} {Information} {Processing} {Society} {Annual} {Conference} {NAFIPS} ’2007},
	title = {An inventory model with backorders with fuzzy parameters and decision variables},
	volume = {51},
	issn = {0888-613X},
	url = {https://www.sciencedirect.com/science/article/pii/S0888613X10000812},
	doi = {10.1016/j.ijar.2010.07.001},
	abstract = {The paper considers an inventory model with backorders in a fuzzy situation by employing two types of fuzzy numbers, which are trapezoidal and triangular. A full-fuzzy model is developed where the input parameters and the decision variables are fuzzified. The optimal policy for the developed model is determined using the Kuhn–Tucker conditions after the defuzzification of the cost function with the graded mean integration (GMI) method. Numerical examples and a sensitivity analysis study are provided to highlight the differences between crisp and the fuzzy cases.},
	language = {en},
	number = {8},
	urldate = {2023-07-07},
	journal = {International Journal of Approximate Reasoning},
	author = {Kazemi, N. and Ehsani, E. and Jaber, M. Y.},
	month = oct,
	year = {2010},
	keywords = {EOQ, backorders, fuzzy sets, Graded mean integration, Kuhn–Tucker, Trapezoidal/triangular fuzzy number},
	pages = {964--972},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\W6WJQ3L2\\Kazemi et al. - 2010 - An inventory model with backorders with fuzzy para.pdf:application/pdf},
}

@article{guo_decisions_2019,
	title = {Decisions on spare parts allocation for repairable isolated system with dependent backorders},
	volume = {127},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835218305825},
	doi = {10.1016/j.cie.2018.11.042},
	abstract = {The accuracy of spare parts allocation is essential for an isolated system performing its intended function and reducing the waste of resources. The backorders of different types of components for an isolated system are interdependent. The isolation time has a relatively large impact on the interdependent. Ignoring dependence among the component backorders will overestimate the spares stock for an isolated system. In this paper, we focus on backorder dependence to model spare parts allocation for an isolated system consisting of multiple types of components. We analyze the effect of isolation time on system availability and aggregate the backorder probabilities of the failed components to calculate the transition rate of available states for the rest of the functional components. We formulate the replenishment process of spare parts for the components in the isolated system using the state transition diagrams and matrixes. Multiple Markov processes are established for the multi-component isolated system considering backorder dependence. An optimization model of spares allocation for the isolated system is constructed with the constraint of the total spares cost considering the backorder dependence. We obtain the closed-form expression of the system stationary availability when the spare part reorder is sent out upon backorder occurrence. We find that the stationary availability function is a convex function. Several numerical examples of decisions on spare parts allocation for an isolated system is presented. We compare the output of our model with simulation software to verify the accuracy of the proposed method. The impact of prolonged isolation time on the expected number of backorders (EBO) is analyzed. We obtain higher availability for the isolated system with a lower stock level by employing the novel decision approach to spare parts allocation.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Computers \& Industrial Engineering},
	author = {Guo, Linhan and Wang, Yu and Kong, Dandan and Zhang, Zhiyuan and Yang, Yi},
	month = jan,
	year = {2019},
	keywords = {Backorder dependence, Isolated system, Markov, Repairable, Spares allocation},
	pages = {8--20},
}

@inproceedings{feng_demand_2012,
	title = {Demand {Prediction} of {LRU} {Parts} with {Backorder} for {SRU}},
	volume = {2},
	doi = {10.1109/ISCID.2012.265},
	abstract = {For the problem that the demand of vari-indenture Recoverable Parts did not submit to the Poisson distribution, put forward the Negative binomial distribution to improve the forecasting accuracy. Used the fill rate to estimate the supply degree of Recoverable Parts, the restricted total security funds and the lowest fill rate as the constraint conditions, searching for the fill rate maximization as the objective function, established the demand forecasting model of Recoverable Parts, through the marginal analysis to solve it. The example proves that the model has good prediction effect.},
	booktitle = {2012 {Fifth} {International} {Symposium} on {Computational} {Intelligence} and {Design}},
	author = {Feng, Guo and Chen-Yu, Liu and Feng-Lei, Xu and Wei-Ling, Li},
	month = oct,
	year = {2012},
	keywords = {Predictive models, Optimization, Aerospace electronics, Atmospheric modeling, demand prediction, Maintenance engineering, Negative binomial distribution, Pipelines, Recoverable Parts, vari-indenture},
	pages = {530--532},
}

@article{shin_development_2012,
	series = {Soft {Computing} for {Management} {Systems}},
	title = {Development of risk based dynamic backorder replenishment planning framework using {Bayesian} {Belief} {Network}},
	volume = {62},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S036083521100338X},
	doi = {10.1016/j.cie.2011.11.015},
	abstract = {Due to the rapid changes in circumstances of cooperates such as globalization, technical innovation and competition, inter-dependence among cooperates which compose supply chain has been intensified. This make cooperates be exposed to various risk and even a small uncertainty can disrupt the balance of whole supply chain. Therefore, in this paper, the framework to develop alternative backorder replenishment plan to minimize the total replenishment cost and expected risk cost has been devised. In order to model the relationship between risks and risk propagation, Bayesian Belief Network has been applied. Moreover, with the fast heuristic algorithm, breath first search and elementary stepwise system based reverse Dijkstra, the alternative backorder replenishment plan can be established. The numerical example shows how to apply the proposed framework and make dynamic backorder replenishment plan considering impact of risk.},
	language = {en},
	number = {3},
	urldate = {2023-07-07},
	journal = {Computers \& Industrial Engineering},
	author = {Shin, KwangSup and Shin, YongWoo and Kwon, Ji-Hye and Kang, Suk-Ho},
	month = apr,
	year = {2012},
	keywords = {Supply chain, Risk management, Backorder replenishment, BBN},
	pages = {716--725},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\MJ9UVVKM\\S036083521100338X.html:text/html},
}

@article{wang_dynamic_2014,
	series = {The {Economics} of {Industrial} {Production}},
	title = {Dynamic inventory rationing with mixed backorders and lost sales},
	volume = {149},
	issn = {0925-5273},
	url = {https://www.sciencedirect.com/science/article/pii/S0925527313004453},
	doi = {10.1016/j.ijpe.2013.10.004},
	abstract = {Customers may react differently when stockouts occur. In this paper we investigate the rationing policy for an inventory system with a mixture of demand classes of backorder type and lost sales type. Since the penalty cost of backorders varies with time, the priorities of demand classes also alter with time. This totally changes the problem structure compared with the classic rationing models. A dynamic rationing policy is studied in this paper by considering the dynamics of demand priorities. A Markov decision model is developed to obtain the optimal dynamic rationing levels for multiple demand classes. The results indicate that between the priority switching points, rationing levels often exhibit different patterns. For lost sales demand classes, the rationing levels always decrease as the remaining time approaches to zero. For backorder demand classes, the rationing levels increase in some parts due to declining of the priorities. The rationing levels of all demand classes finally decline to zero to reduce the inventory holding cost. The application of dynamic rationing is further extended from a single period model to a multi-period (S,T) model where unit cost has to be included. The optimal ordering policy is proved to be a myopic base stock policy and the dynamic rationing policy in the single period model can still be applied with modified time-independent penalty costs for lost sales classes. To overcome the computational complexity, a heuristic dynamic rationing policy is introduced. Due to its good outcome, implementing such a heuristic dynamic rationing policy can be a practical solution for inventory system with mixed backorders and lost sales, in order to enhance the system performance.},
	language = {en},
	urldate = {2023-07-07},
	journal = {International Journal of Production Economics},
	author = {Wang, Daqin and Tang, Ou},
	month = mar,
	year = {2014},
	keywords = {Backorders, Lost sales, Dynamic rationing, Inventory rationing, Multiple demand classes},
	pages = {56--67},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\TB3J7SAZ\\S0925527313004453.html:text/html},
}

@article{bao_decomposition_2018,
	title = {On the decomposition property for a dynamic inventory rationing problem with multiple demand classes and backorder},
	volume = {265},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221717306483},
	doi = {10.1016/j.ejor.2017.07.021},
	abstract = {In this paper, we study a dynamic inventory rationing problem of a single item with multiple demand classes and backorder. Demand classes are differentiated by their unit backlogging costs. The corresponding dynamic programming problem is multidimensional and computationally challenging. With a novel state transformation, we find that the optimal policy can be described by a nested base stock policy. In particular, we can decompose the value function as the sum of single-variable convex functions. This property breaks the curse of dimensionality and significantly reduces computational effort in computing optimal policies. Our approach allows us to extend the results to systems with ordering, exogenous supply, priority upgrading.},
	language = {en},
	number = {1},
	urldate = {2023-07-07},
	journal = {European Journal of Operational Research},
	author = {Bao, Lina and Liu, Zhiying and Yu, Yimin and Zhang, Wei},
	month = feb,
	year = {2018},
	keywords = {Multiple demand classes, (T) Inventory, Decomposability, Rationing},
	pages = {99--106},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\8GAXPXYX\\S0377221717306483.html:text/html},
}

@article{trapero_empirical_2019,
	title = {Empirical safety stock estimation based on kernel and {GARCH} models},
	volume = {84},
	issn = {0305-0483},
	url = {https://www.sciencedirect.com/science/article/pii/S0305048316306090},
	doi = {10.1016/j.omega.2018.05.004},
	abstract = {Supply chain risk management has drawn the attention of practitioners and academics alike. One source of risk is demand uncertainty. Demand forecasting and safety stock levels are employed to address this risk. Most previous work has focused on point demand forecasting, given that the forecast errors satisfy the typical normal i.i.d. assumption. However, the real demand for products is difficult to forecast accurately, which means that—at minimum—the i.i.d. assumption should be questioned. This work analyzes the effects of possible deviations from the i.i.d. assumption and proposes empirical methods based on kernel density estimation (non-parametric) and GARCH(1,1) models (parametric), among others, for computing the safety stock levels. The results suggest that for shorter lead times, the normality deviation is more important, and kernel density estimation is most suitable. By contrast, for longer lead times, GARCH models are more appropriate because the autocorrelation of the variance of the forecast errors is the most important deviation. In fact, even when no autocorrelation is present in the original demand, such autocorrelation can be present as a consequence of the overlapping process used to compute the lead time forecasts and the uncertainties arising in the estimation of the parameters of the forecasting model. Improvements are shown in terms of cycle service level, inventory investment and backorder volume. Simulations and real demand data from a manufacturer are used to illustrate our methodology.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Omega},
	author = {Trapero, Juan R. and Cardós, Manuel and Kourentzes, Nikolaos},
	month = apr,
	year = {2019},
	keywords = {Supply chain, Forecasting, GARCH, Safety stock, Kernel density estimation, Prediction intervals, Risk, Volatility},
	pages = {199--211},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\H7LRLM4Q\\Trapero et al. - 2019 - Empirical safety stock estimation based on kernel .pdf:application/pdf},
}

@article{trapero_quantile_2019,
	series = {Special {Section}: {Supply} {Chain} {Forecasting}},
	title = {Quantile forecast optimal combination to enhance safety stock estimation},
	volume = {35},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207018300918},
	doi = {10.1016/j.ijforecast.2018.05.009},
	abstract = {The safety stock calculation requires a measure of the forecast error uncertainty. Such errors are usually assumed to be Gaussian iid (independently and identically distributed). However, deviations from iid lead to a deterioration in the performance of the supply chain. Recent research has shown that, contrary to theoretical approaches, empirical techniques that do not rely on the aforementioned assumptions can enhance the calculation of safety stocks. In particular, GARCH models cope with time-varying heterocedastic forecast error, and kernel density estimation does not need to rely on a determined distribution. However, if the forecast errors are time-varying heterocedastic and do not follow a determined distribution, the previous approaches are inadequate. We overcome this by proposing an optimal combination of the empirical methods that minimizes the asymmetric piecewise linear loss function, also known as the tick loss. The results show that combining quantile forecasts yields safety stocks with a lower cost. The methodology is illustrated with simulations and real data experiments for different lead times.},
	language = {en},
	number = {1},
	urldate = {2023-07-07},
	journal = {International Journal of Forecasting},
	author = {Trapero, Juan R. and Cardós, Manuel and Kourentzes, Nikolaos},
	month = jan,
	year = {2019},
	keywords = {Supply chain, GARCH, Safety stock, Kernel density estimation, Risk, Combination, Quantile forecasting, Tick loss},
	pages = {239--250},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\YAALCKFY\\Trapero et al. - 2019 - Quantile forecast optimal combination to enhance s.pdf:application/pdf},
}

@article{preskill_quantum_2018,
	title = {Quantum {Computing} in the {NISQ} era and beyond},
	volume = {2},
	url = {https://quantum-journal.org/papers/q-2018-08-06-79/},
	doi = {10.22331/q-2018-08-06-79},
	abstract = {John Preskill,
Quantum 2, 79 (2018).
Noisy Intermediate-Scale Quantum (NISQ) technology will be available in the near future. Quantum computers with 50-100 qubits may be able to perform tasks which surpass the capabilities of t…},
	language = {en-GB},
	urldate = {2023-07-07},
	journal = {Quantum},
	author = {Preskill, John},
	month = aug,
	year = {2018},
	note = {Publisher: Verein zur Förderung des Open Access Publizierens in den Quantenwissenschaften},
	pages = {79},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\B4UQGBDJ\\Preskill - 2018 - Quantum Computing in the NISQ era and beyond.pdf:application/pdf},
}

@misc{noauthor_phys_nodate,
	title = {Phys. {Rev}. {Lett}. 122, 040504 (2019) - {Quantum} {Machine} {Learning} in {Feature} {Hilbert} {Spaces}},
	url = {https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.122.040504},
	urldate = {2023-07-07},
	file = {Phys. Rev. Lett. 122, 040504 (2019) - Quantum Machine Learning in Feature Hilbert Spaces:C\:\\Users\\abrar\\Zotero\\storage\\UFPKH4KL\\PhysRevLett.122.html:text/html},
}

@article{havlicek_supervised_2019,
	title = {Supervised learning with quantum-enhanced feature spaces},
	volume = {567},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-0980-2},
	doi = {10.1038/s41586-019-0980-2},
	abstract = {Machine learning and quantum computing are two technologies that each have the potential to alter how computation is performed to address previously untenable problems. Kernel methods for machine learning are ubiquitous in pattern recognition, with support vector machines (SVMs) being the best known method for classification problems. However, there are limitations to the successful solution to such classification problems when the feature space becomes large, and the kernel functions become computationally expensive to estimate. A core element in the computational speed-ups enabled by quantum algorithms is the exploitation of an exponentially large quantum state space through controllable entanglement and interference. Here we propose and experimentally implement two quantum algorithms on a superconducting processor. A key component in both methods is the use of the quantum state space as feature space. The use of a quantum-enhanced feature space that is only efficiently accessible on a quantum computer provides a possible path to quantum advantage. The algorithms solve a problem of supervised learning: the construction of a classifier. One method, the quantum variational classifier, uses a variational quantum circuit1,2 to classify the data in a way similar to the method of conventional SVMs. The other method, a quantum kernel estimator, estimates the kernel function on the quantum computer and optimizes a classical SVM. The two methods provide tools for exploring the applications of noisy intermediate-scale quantum computers3 to machine learning.},
	language = {en},
	number = {7747},
	urldate = {2023-07-07},
	journal = {Nature},
	author = {Havlíček, Vojtěch and Córcoles, Antonio D. and Temme, Kristan and Harrow, Aram W. and Kandala, Abhinav and Chow, Jerry M. and Gambetta, Jay M.},
	month = mar,
	year = {2019},
	note = {Number: 7747
Publisher: Nature Publishing Group},
	keywords = {Computer science, Quantum information, Quantum simulation, Qubits, Statistics},
	pages = {209--212},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\KVY2C7P8\\Havlíček et al. - 2019 - Supervised learning with quantum-enhanced feature .pdf:application/pdf},
}

@article{johri_nearest_2021,
	title = {Nearest centroid classification on a trapped ion quantum computer},
	volume = {7},
	copyright = {2021 The Author(s)},
	issn = {2056-6387},
	url = {https://www.nature.com/articles/s41534-021-00456-5},
	doi = {10.1038/s41534-021-00456-5},
	abstract = {Quantum machine learning has seen considerable theoretical and practical developments in recent years and has become a promising area for finding real world applications of quantum computers. In pursuit of this goal, here we combine state-of-the-art algorithms and quantum hardware to provide an experimental demonstration of a quantum machine learning application with provable guarantees for its performance and efficiency. In particular, we design a quantum Nearest Centroid classifier, using techniques for efficiently loading classical data into quantum states and performing distance estimations, and experimentally demonstrate it on a 11-qubit trapped-ion quantum machine, matching the accuracy of classical nearest centroid classifiers for the MNIST handwritten digits dataset and achieving up to 100\% accuracy for 8-dimensional synthetic data.},
	language = {en},
	number = {1},
	urldate = {2023-07-07},
	journal = {npj Quantum Information},
	author = {Johri, Sonika and Debnath, Shantanu and Mocherla, Avinash and Singk, Alexandros and Prakash, Anupam and Kim, Jungsang and Kerenidis, Iordanis},
	month = aug,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Quantum information, Information theory and computation},
	pages = {1--11},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\TFRHHSRR\\Johri et al. - 2021 - Nearest centroid classification on a trapped ion q.pdf:application/pdf},
}

@misc{noauthor_phys_nodate-1,
	title = {Phys. {Rev}. {A} 106, 042431 (2022) - {Training} quantum embedding kernels on near-term quantum computers},
	url = {https://journals.aps.org/pra/abstract/10.1103/PhysRevA.106.042431},
	urldate = {2023-07-07},
	file = {Phys. Rev. A 106, 042431 (2022) - Training quantum embedding kernels on near-term quantum computers:C\:\\Users\\abrar\\Zotero\\storage\\YGMVVVCC\\PhysRevA.106.html:text/html},
}

@misc{noauthor_experimental_nodate,
	title = {Experimental quantum speed-up in reinforcement learning agents {\textbar} {Nature}},
	url = {https://www.nature.com/articles/s41586-021-03242-7},
	urldate = {2023-07-07},
}

@article{tomono_performance_2022,
	title = {Performance of quantum kernel on initial learning process},
	volume = {9},
	copyright = {2022 The Author(s)},
	issn = {2196-0763},
	url = {https://epjquantumtechnology.springeropen.com/articles/10.1140/epjqt/s40507-022-00157-8},
	doi = {10.1140/epjqt/s40507-022-00157-8},
	abstract = {For many manufacturing companies, the production line is very important. In recent years, the number of small-quantity, high-mix products have been increasing, and the identification of good and defective products must be carried out efficiently. At that time, machine learning is a very important issue on shipping inspection using small amounts of data. Quantum machine learning is one of most exciting prospective applications of quantum technologies. SVM using kernel estimation is one of most popular methods for classifiers. Our purpose is to search quantum advantage on classifier to enable us to classifier in inspection test for small size datasets. In this study, we made clear the difference between classical and quantum kernel learning in initial state and propose analysis of learning process by plotting ROC space. To meet the purpose, we investigated the effect of each feature map compared to classical one, using evaluation index. The simulation results show that the learning model construction process between quantum and classical kernel learning is different in initial state. Moreover, the result indicates that the learning model of quantum kernel is the method to decrease the false positive rate (FPR) from high FPR, keeping high true positive rates on several datasets. We demonstrate that learning process on quantum kernel is different from classical one in initial state and plotting to ROC space graph is effective when we analyse the learning model process.},
	language = {en},
	number = {1},
	urldate = {2023-07-07},
	journal = {EPJ Quantum Technology},
	author = {Tomono, Takao and Natsubori, Satoko},
	month = dec,
	year = {2022},
	note = {Number: 1
Publisher: SpringerOpen},
	pages = {1--12},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\5W9AFU9Y\\Tomono and Natsubori - 2022 - Performance of quantum kernel on initial learning .pdf:application/pdf},
}

@article{saggio_experimental_2021,
	title = {Experimental quantum speed-up in reinforcement learning agents},
	volume = {591},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03242-7},
	doi = {10.1038/s41586-021-03242-7},
	abstract = {As the field of artificial intelligence advances, the demand for algorithms that can learn quickly and efficiently increases. An important paradigm within artificial intelligence is reinforcement learning1, where decision-making entities called agents interact with environments and learn by updating their behaviour on the basis of the obtained feedback. The crucial question for practical applications is how fast agents learn2. Although various studies have made use of quantum mechanics to speed up the agent’s decision-making process3,4, a reduction in learning time has not yet been demonstrated. Here we present a reinforcement learning experiment in which the learning process of an agent is sped up by using a quantum communication channel with the environment. We further show that combining this scenario with classical communication enables the evaluation of this improvement and allows optimal control of the learning progress. We implement this learning protocol on a compact and fully tunable integrated nanophotonic processor. The device interfaces with telecommunication-wavelength photons and features a fast active-feedback mechanism, demonstrating the agent’s systematic quantum advantage in a setup that could readily be integrated within future large-scale quantum communication networks.},
	language = {en},
	number = {7849},
	urldate = {2023-07-07},
	journal = {Nature},
	author = {Saggio, V. and Asenbeck, B. E. and Hamann, A. and Strömberg, T. and Schiansky, P. and Dunjko, V. and Friis, N. and Harris, N. C. and Hochberg, M. and Englund, D. and Wölk, S. and Briegel, H. J. and Walther, P.},
	month = mar,
	year = {2021},
	note = {Number: 7849
Publisher: Nature Publishing Group},
	keywords = {Quantum information, Integrated optics, Mathematics and computing},
	pages = {229--233},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\25ANPR7B\\Saggio et al. - 2021 - Experimental quantum speed-up in reinforcement lea.pdf:application/pdf},
}

@article{hubregtsen_training_2022,
	title = {Training quantum embedding kernels on near-term quantum computers},
	volume = {106},
	url = {https://link.aps.org/doi/10.1103/PhysRevA.106.042431},
	doi = {10.1103/PhysRevA.106.042431},
	abstract = {Kernel methods are a cornerstone of classical machine learning. The idea of using quantum computers to compute kernels has recently attracted attention. Quantum embedding kernels (QEKs), constructed by embedding data into the Hilbert space of a quantum computer, are a particular quantum kernel technique that is particularly suitable for noisy intermediate-scale quantum devices. Unfortunately, kernel methods face three major problems: Constructing the kernel matrix has quadratic computational complexity in the number of training samples, choosing the right kernel function is nontrivial, and the effects of noise are unknown. In this work, we addressed the latter two. In particular, we introduced the notion of trainable QEKs, based on the idea of classical model optimization methods. To train the parameters of the QEK, we proposed the use of kernel-target alignment. We verified the feasibility of this method, and showed that for our experimental setup we could reduce the training error significantly. Furthermore, we investigated the effects of device and finite sampling noise, and we evaluated various mitigation techniques numerically on classical hardware. We took the best performing strategy and evaluated it on data from a real quantum processing unit. We found that using this mitigation strategy demonstrated an increased kernel matrix quality.},
	number = {4},
	urldate = {2023-07-07},
	journal = {Physical Review A},
	author = {Hubregtsen, Thomas and Wierichs, David and Gil-Fuster, Elies and Derks, Peter-Jan H. S. and Faehrmann, Paul K. and Meyer, Johannes Jakob},
	month = oct,
	year = {2022},
	note = {Publisher: American Physical Society},
	pages = {042431},
	file = {APS Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\6BF9L9WI\\PhysRevA.106.html:text/html;Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\J7TGYXZ4\\Hubregtsen et al. - 2022 - Training quantum embedding kernels on near-term qu.pdf:application/pdf},
}

@article{schuld_quantum_2019,
	title = {Quantum {Machine} {Learning} in {Feature} {Hilbert} {Spaces}},
	volume = {122},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.122.040504},
	doi = {10.1103/PhysRevLett.122.040504},
	abstract = {A basic idea of quantum computing is surprisingly similar to that of kernel methods in machine learning, namely, to efficiently perform computations in an intractably large Hilbert space. In this Letter we explore some theoretical foundations of this link and show how it opens up a new avenue for the design of quantum machine learning algorithms. We interpret the process of encoding inputs in a quantum state as a nonlinear feature map that maps data to quantum Hilbert space. A quantum computer can now analyze the input data in this feature space. Based on this link, we discuss two approaches for building a quantum model for classification. In the first approach, the quantum device estimates inner products of quantum states to compute a classically intractable kernel. The kernel can be fed into any classical kernel method such as a support vector machine. In the second approach, we use a variational quantum circuit as a linear model that classifies data explicitly in Hilbert space. We illustrate these ideas with a feature map based on squeezing in a continuous-variable system, and visualize the working principle with two-dimensional minibenchmark datasets.},
	number = {4},
	urldate = {2023-07-07},
	journal = {Physical Review Letters},
	author = {Schuld, Maria and Killoran, Nathan},
	month = feb,
	year = {2019},
	note = {Publisher: American Physical Society},
	pages = {040504},
	file = {APS Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\H45J6SXP\\PhysRevLett.122.html:text/html;Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\QQ5G3XN4\\Schuld and Killoran - 2019 - Quantum Machine Learning in Feature Hilbert Spaces.pdf:application/pdf},
}

@misc{martin_abadi_tensorflow_2015,
	title = {{TensorFlow}: {Large}-{Scale} {Machine} {Learning} on {Heterogeneous} {Systems}},
	url = {https://www.tensorflow.org/},
	author = {{Martín Abadi} and {Ashish Agarwal} and {Paul Barham} and {Eugene Brevdo} and {Zhifeng Chen} and {Craig Citro} and {Greg S. Corrado} and {Andy Davis} and {Jeffrey Dean} and {Matthieu Devin} and {Sanjay Ghemawat} and {Ian Goodfellow} and {Andrew Harp} and {Geoffrey Irving} and {Michael Isard} and Jia, Yangqing and {Rafal Jozefowicz} and {Lukasz Kaiser} and {Manjunath Kudlur} and {Josh Levenberg} and {Dandelion Mané} and {Rajat Monga} and {Sherry Moore} and {Derek Murray} and {Chris Olah} and {Mike Schuster} and {Jonathon Shlens} and {Benoit Steiner} and {Ilya Sutskever} and {Kunal Talwar} and {Paul Tucker} and {Vincent Vanhoucke} and {Vijay Vasudevan} and {Fernanda Viégas} and {Oriol Vinyals} and {Pete Warden} and {Martin Wattenberg} and {Martin Wicke} and {Yuan Yu} and {Xiaoqiang Zheng}},
	year = {2015},
	annote = {Software available from tensorflow.org},
}

@misc{guadarrama_tf-agents_2018,
	title = {{TF}-{Agents}: {A} library for {Reinforcement} {Learning} in {TensorFlow}},
	url = {https://github.com/tensorflow/agents},
	author = {Guadarrama, Sergio and Korattikara, Anoop and Ramirez, Oscar and Castro, Pablo and Holly, Ethan and Fishman, Sam and Wang, Ke and Gonina, Ekaterina and Wu, Neal and Kokiopoulou, Efi and Sbaiz, Luciano and Smith, Jamie and Bartók, Gábor and Berent, Jesse and Harris, Chris and Vanhoucke, Vincent and Brevdo, Eugene},
	year = {2018},
	annote = {[Online; accessed 25-June-2019]},
}

@misc{lin_deep_2019,
	title = {Deep {Reinforcement} {Learning} for {Imbalanced} {Classification}},
	url = {http://arxiv.org/abs/1901.01379},
	doi = {10.48550/arXiv.1901.01379},
	abstract = {Data in real-world application often exhibit skewed class distribution which poses an intense challenge for machine learning. Conventional classification algorithms are not effective in the case of imbalanced data distribution, and may fail when the data distribution is highly imbalanced. To address this issue, we propose a general imbalanced classification model based on deep reinforcement learning. We formulate the classification problem as a sequential decision-making process and solve it by deep Q-learning network. The agent performs a classification action on one sample at each time step, and the environment evaluates the classification action and returns a reward to the agent. The reward from minority class sample is larger so the agent is more sensitive to the minority class. The agent finally finds an optimal classification policy in imbalanced data under the guidance of specific reward function and beneficial learning environment. Experiments show that our proposed model outperforms the other imbalanced classification algorithms, and it can identify more minority samples and has great classification performance.},
	urldate = {2023-07-08},
	publisher = {arXiv},
	author = {Lin, Enlu and Chen, Qiong and Qi, Xiaoming},
	month = jan,
	year = {2019},
	note = {arXiv:1901.01379 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\PTFHNY78\\Lin et al. - 2019 - Deep Reinforcement Learning for Imbalanced Classif.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\FPV3RAMY\\1901.html:text/html},
}

@article{killoran_continuous-variable_2019,
	title = {Continuous-variable quantum neural networks},
	volume = {1},
	url = {https://link.aps.org/doi/10.1103/PhysRevResearch.1.033063},
	doi = {10.1103/PhysRevResearch.1.033063},
	abstract = {We introduce a general method for building neural networks on quantum computers. The quantum neural network is a variational quantum circuit built in the continuous-variable (CV) architecture, which encodes quantum information in continuous degrees of freedom such as the amplitudes of the electromagnetic field. This circuit contains a layered structure of continuously parameterized gates which is universal for CV quantum computation. Affine transformations and nonlinear activation functions, two key elements in neural networks, are enacted in the quantum network using Gaussian and non-Gaussian gates, respectively. The non-Gaussian gates provide both the nonlinearity and the universality of the model. Due to the structure of the CV model, the CV quantum neural network can encode highly nonlinear transformations while remaining completely unitary. We show how a classical network can be embedded into the quantum formalism and propose quantum versions of various specialized models such as convolutional, recurrent, and residual networks. Finally, we present numerous modeling experiments built with the strawberry fields software library. These experiments, including a classifier for fraud detection, a network which generates tetris images, and a hybrid classical-quantum autoencoder, demonstrate the capability and adaptability of CV quantum neural networks.},
	number = {3},
	urldate = {2023-07-08},
	journal = {Physical Review Research},
	author = {Killoran, Nathan and Bromley, Thomas R. and Arrazola, Juan Miguel and Schuld, Maria and Quesada, Nicolás and Lloyd, Seth},
	month = oct,
	year = {2019},
	note = {Publisher: American Physical Society},
	pages = {033063},
	file = {APS Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\VXTSGZ56\\PhysRevResearch.1.html:text/html;Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\DBMAKUPF\\Killoran et al. - 2019 - Continuous-variable quantum neural networks.pdf:application/pdf},
}

@misc{bergholm_pennylane_2022,
	title = {{PennyLane}: {Automatic} differentiation of hybrid quantum-classical computations},
	shorttitle = {{PennyLane}},
	url = {http://arxiv.org/abs/1811.04968},
	doi = {10.48550/arXiv.1811.04968},
	abstract = {PennyLane is a Python 3 software framework for differentiable programming of quantum computers. The library provides a unified architecture for near-term quantum computing devices, supporting both qubit and continuous-variable paradigms. PennyLane's core feature is the ability to compute gradients of variational quantum circuits in a way that is compatible with classical techniques such as backpropagation. PennyLane thus extends the automatic differentiation algorithms common in optimization and machine learning to include quantum and hybrid computations. A plugin system makes the framework compatible with any gate-based quantum simulator or hardware. We provide plugins for hardware providers including the Xanadu Cloud, Amazon Braket, and IBM Quantum, allowing PennyLane optimizations to be run on publicly accessible quantum devices. On the classical front, PennyLane interfaces with accelerated machine learning libraries such as TensorFlow, PyTorch, JAX, and Autograd. PennyLane can be used for the optimization of variational quantum eigensolvers, quantum approximate optimization, quantum machine learning models, and many other applications.},
	urldate = {2023-07-08},
	publisher = {arXiv},
	author = {Bergholm, Ville and Izaac, Josh and Schuld, Maria and Gogolin, Christian and Ahmed, Shahnawaz and Ajith, Vishnu and Alam, M. Sohaib and Alonso-Linaje, Guillermo and AkashNarayanan, B. and Asadi, Ali and Arrazola, Juan Miguel and Azad, Utkarsh and Banning, Sam and Blank, Carsten and Bromley, Thomas R. and Cordier, Benjamin A. and Ceroni, Jack and Delgado, Alain and Di Matteo, Olivia and Dusko, Amintor and Garg, Tanya and Guala, Diego and Hayes, Anthony and Hill, Ryan and Ijaz, Aroosa and Isacsson, Theodor and Ittah, David and Jahangiri, Soran and Jain, Prateek and Jiang, Edward and Khandelwal, Ankit and Kottmann, Korbinian and Lang, Robert A. and Lee, Christina and Loke, Thomas and Lowe, Angus and McKiernan, Keri and Meyer, Johannes Jakob and Montañez-Barrera, J. A. and Moyard, Romain and Niu, Zeyue and O'Riordan, Lee James and Oud, Steven and Panigrahi, Ashish and Park, Chae-Yeun and Polatajko, Daniel and Quesada, Nicolás and Roberts, Chase and Sá, Nahum and Schoch, Isidor and Shi, Borun and Shu, Shuli and Sim, Sukin and Singh, Arshpreet and Strandberg, Ingrid and Soni, Jay and Száva, Antal and Thabet, Slimane and Vargas-Hernández, Rodrigo A. and Vincent, Trevor and Vitucci, Nicola and Weber, Maurice and Wierichs, David and Wiersema, Roeland and Willmann, Moritz and Wong, Vincent and Zhang, Shaoming and Killoran, Nathan},
	month = jul,
	year = {2022},
	note = {arXiv:1811.04968 [physics, physics:quant-ph]},
	keywords = {Computer Science - Machine Learning, Computer Science - Emerging Technologies, Physics - Computational Physics, Quantum Physics},
	annote = {Comment: Code available at https://github.com/XanaduAI/pennylane/ . Significant contributions to the code (new features, new plugins, etc.) will be recognized by the opportunity to be a co-author on this paper},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\SG69EWYE\\Bergholm et al. - 2022 - PennyLane Automatic differentiation of hybrid qua.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\WJGIJVXF\\1811.html:text/html},
}

@misc{qiskit_contributors_qiskit_2023,
	title = {Qiskit: {An} {Open}-source {Framework} for {Quantum} {Computing}},
	author = {{Qiskit contributors}},
	year = {2023},
	doi = {10.5281/zenodo.2573505},
}

@inproceedings{rocklin_dask_2015,
	title = {Dask: {Parallel} computation with blocked algorithms and task scheduling},
	booktitle = {Proceedings of the 14th python in science conference},
	publisher = {Citeseer},
	author = {Rocklin, Matthew},
	year = {2015},
	note = {Issue: 130-136},
}

@article{pedregosa_scikit-learn_nodate,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simpliﬁed BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	language = {en},
	journal = {MACHINE LEARNING IN PYTHON},
	author = {Pedregosa, Fabian and Varoquaux, Gael and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David},
	file = {Pedregosa et al. - Scikit-learn Machine Learning in Python.pdf:C\:\\Users\\abrar\\Zotero\\storage\\B6DV6SAN\\Pedregosa et al. - Scikit-learn Machine Learning in Python.pdf:application/pdf},
}

@article{pedregosa_scikit-learn_nodate-1,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simpliﬁed BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	language = {en},
	journal = {MACHINE LEARNING IN PYTHON},
	author = {Pedregosa, Fabian and Varoquaux, Gael and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David},
	file = {Pedregosa et al. - Scikit-learn Machine Learning in Python.pdf:C\:\\Users\\abrar\\Zotero\\storage\\RY4Q95WF\\Pedregosa et al. - Scikit-learn Machine Learning in Python.pdf:application/pdf},
}

@inproceedings{liu_novel_2022,
	title = {A novel hybrid sampling method based on {CWGAN} for extremely imbalanced backorder prediction},
	doi = {10.1109/SMC53654.2022.9945161},
	abstract = {Product backorder is a common problem in supply chain management systems. It is essential for entrepreneurs to predict the likelihood of backorder accurately to minimize a company’s losses. However, existing methods are hard to achieve satisfactory results since the number of backorders and non-backorders are extremely imbalanced. Besides, the backorder data’s attributes are complex to oversample them effectively. To address these problems, a novel hybrid sampling method is proposed to help predict extremely imbalanced backorder. The Randomized Undersampling (RUS) and a Conditional Wasserstein Generative Adversarial Network (CWGAN) are innovatively introduced into backorder prediction. First, RUS is used to reduce the majority non-backorder samples. Second, CWGAN is served as an oversampling technique to generate high-quality backorder samples. It utilizes unique structures in the generator and the discriminator to effectively model both numerical and categorical variables. Finally, the training dataset is balanced, and the Random Forest Classifier (RFC) is adopted to make backordering prediction. In the experiments of Kaggle’s dataset ‘Can you predict product backorder?’, our proposed method is superior to all benchmark methods in terms of standard evaluation metrics. The results show that our proposed product backorder prediction model is effective.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Liu, Haoyue and Liu, Qing and Liu, Min},
	month = oct,
	year = {2022},
	note = {ISSN: 2577-1655},
	keywords = {Supply chain management, Predictive models, Training, Sampling methods, Supply chains, Measurement, backorder prediction, extremely class imbalance problem, Generative adversarial networks, Generators, hybrid sampling},
	pages = {768--773},
}

@article{shajalal_product_2023,
	title = {Product backorder prediction using deep neural network on imbalanced data},
	volume = {61},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2021.1901153},
	doi = {10.1080/00207543.2021.1901153},
	abstract = {Taking backorders on products is a common scenario in inventory and supply chain management systems. The ability to predict the likelihood of backorders can surely minimise a company's losses. Because the number of backorders is much lower than the number of orders that ship on time, applying a predictive model for this domain is a challenging task. This paper proposes a model that uses a deep neural network to predict backorders; it handles the data imbalance between backorders and filled orders with efficient techniques. To make the dataset balanced, we employ different techniques that include minority class weight boosting, randomised oversampling, SMOTE oversampling, and a combination of oversampling and undersampling. The balanced training data are used in our proposed, fully connected deep neural networks model to train the predictive model. The predictive model learns the likelihood of product backorders by using the training samples. We conduct experiments on a large benchmark dataset to test the performance of our proposed deep neural network–based model. The experimental results achieve a new state-of-the-art performance and outperform some prominent classification models in terms of standard evaluation metrics and expected profit measure.},
	number = {1},
	urldate = {2023-07-08},
	journal = {International Journal of Production Research},
	author = {Shajalal, Md and Hajek, Petr and Abedin, Mohammad Zoynul},
	month = jan,
	year = {2023},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2021.1901153},
	keywords = {prediction, deep neural network, imbalanced data, Product backorder, synthetic oversampling},
	pages = {302--319},
}

@misc{noauthor_quantum_nodate,
	title = {Quantum {Computation} and {Quantum} {Information}},
	url = {https://michaelnielsen.org/qcqi/},
	urldate = {2023-07-15},
	file = {Quantum Computation and Quantum Information:C\:\\Users\\abrar\\Zotero\\storage\\SH6U3MKB\\qcqi.html:text/html},
}

@article{nielsen_errata_nodate,
	title = {Errata list for “{Quantum} {Computation} and {Quantum} {Information}”},
	language = {en},
	author = {Nielsen, Michael A and Chuang, Isaac L},
	file = {Nielsen and Chuang - Errata list for “Quantum Computation and Quantum I.pdf:C\:\\Users\\abrar\\Zotero\\storage\\53MQRNLY\\Nielsen and Chuang - Errata list for “Quantum Computation and Quantum I.pdf:application/pdf},
}

@misc{nielsen_quantum_2010,
	title = {Quantum {Computation} and {Quantum} {Information}: 10th {Anniversary} {Edition}},
	shorttitle = {Quantum {Computation} and {Quantum} {Information}},
	url = {https://www.cambridge.org/highereducation/books/quantum-computation-and-quantum-information/01E10196D0A682A6AEFFEA52D53BE9AE},
	abstract = {One of the most cited books in physics of all time, Quantum Computation and Quantum Information remains the best textbook in this exciting field of science. This 10th anniversary edition includes an introduction from the authors setting the work in context. This comprehensive textbook describes such remarkable effects as fast quantum algorithms, quantum teleportation, quantum cryptography and quantum error-correction. Quantum mechanics and computer science are introduced before moving on to describe what a quantum computer is, how it can be used to solve problems faster than 'classical' computers and its real-world implementation. It concludes with an in-depth treatment of quantum information. Containing a wealth of figures and exercises, this well-known textbook is ideal for courses on the subject, and will interest beginning graduate students and researchers in physics, computer science, mathematics, and electrical engineering.},
	language = {en},
	urldate = {2023-07-15},
	journal = {Higher Education from Cambridge University Press},
	author = {Nielsen, Michael A. and Chuang, Isaac L.},
	month = dec,
	year = {2010},
	doi = {10.1017/CBO9780511976667},
	note = {ISBN: 9780511976667
Publisher: Cambridge University Press},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\G33GJHNZ\\01E10196D0A682A6AEFFEA52D53BE9AE.html:text/html},
}

@misc{mottonen_transformation_2004,
	title = {Transformation of quantum states using uniformly controlled rotations},
	url = {http://arxiv.org/abs/quant-ph/0407010},
	doi = {10.48550/arXiv.quant-ph/0407010},
	abstract = {We consider a unitary transformation which maps any given state of an \$n\$-qubit quantum register into another one. This transformation has applications in the initialization of a quantum computer, and also in some quantum algorithms. Employing uniformly controlled rotations, we present a quantum circuit of \$2{\textasciicircum}\{n+2\}-4n-4\$ CNOT gates and \$2{\textasciicircum}\{n+2\}-5\$ one-qubit elementary rotations that effects the state transformation. The complexity of the circuit is noticeably lower than the previously published results. Moreover, we present an analytic expression for the rotation angles needed for the transformation.},
	urldate = {2023-07-15},
	publisher = {arXiv},
	author = {Mottonen, Mikko and Vartiainen, Juha J. and Bergholm, Ville and Salomaa, Martti M.},
	month = jul,
	year = {2004},
	note = {arXiv:quant-ph/0407010},
	keywords = {Quantum Physics},
	annote = {Comment: 4 pages, 3 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\BJL87JQP\\Mottonen et al. - 2004 - Transformation of quantum states using uniformly c.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\DILLXF7D\\0407010.html:text/html},
}

@misc{jahin_dit4bears_2021,
	title = {{DIT4BEARs} {Smart} {Roads} {Internship}},
	url = {http://arxiv.org/abs/2107.06755},
	doi = {10.48550/arXiv.2107.06755},
	abstract = {The research internship at UiT - The Arctic University of Norway was offered for our team being the winner of the 'Smart Roads - Winter Road Maintenance 2021' Hackathon. The internship commenced on 3 May 2021 and ended on 21 May 2021 with meetings happening twice each week. In spite of having different nationalities and educational backgrounds, we both interns tried to collaborate as a team as much as possible. The most alluring part was working on this project made us realize the critical conditions faced by the arctic people, where it was hard to gain such a unique experience from our residence. We developed and implemented several deep learning models to classify the states (dry, moist, wet, icy, snowy, slushy). Depending upon the best model, the weather forecast app will predict the state taking the Ta, Tsurf, Height, Speed, Water, etc. into consideration. The crucial part was to define a safety metric which is the product of the accident rates based on friction and the accident rates based on states. We developed a regressor that will predict the safety metric depending upon the state obtained from the classifier and the friction obtained from the sensor data. A pathfinding algorithm has been designed using the sensor data, open street map data, weather data.},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Jahin, Md Abrar and Krutsylo, Andrii},
	month = jul,
	year = {2021},
	note = {arXiv:2107.06755 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 6 pages},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\HT87WYH4\\Jahin and Krutsylo - 2021 - DIT4BEARs Smart Roads Internship.pdf:application/pdf},
}

@misc{jahin_big_2023,
	title = {Big {Data} - {Supply} {Chain} {Management} {Framework} for {Forecasting}: {Data} {Preprocessing} and {Machine} {Learning} {Techniques}},
	shorttitle = {Big {Data} - {Supply} {Chain} {Management} {Framework} for {Forecasting}},
	url = {http://arxiv.org/abs/2307.12971},
	doi = {10.48550/arXiv.2307.12971},
	abstract = {This article intends to systematically identify and comparatively analyze state-of-the-art supply chain (SC) forecasting strategies and technologies. A novel framework has been proposed incorporating Big Data Analytics in SC Management (problem identification, data sources, exploratory data analysis, machine-learning model training, hyperparameter tuning, performance evaluation, and optimization), forecasting effects on human-workforce, inventory, and overall SC. Initially, the need to collect data according to SC strategy and how to collect them has been discussed. The article discusses the need for different types of forecasting according to the period or SC objective. The SC KPIs and the error-measurement systems have been recommended to optimize the top-performing model. The adverse effects of phantom inventory on forecasting and the dependence of managerial decisions on the SC KPIs for determining model performance parameters and improving operations management, transparency, and planning efficiency have been illustrated. The cyclic connection within the framework introduces preprocessing optimization based on the post-process KPIs, optimizing the overall control process (inventory management, workforce determination, cost, production and capacity planning). The contribution of this research lies in the standard SC process framework proposal, recommended forecasting data analysis, forecasting effects on SC performance, machine learning algorithms optimization followed, and in shedding light on future research.},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Jahin, Md Abrar and Shovon, Md Sakib Hossain and Shin, Jungpil and Ridoy, Istiyaque Ahmed and Tomioka, Yoichi and Mridha, M. F.},
	month = jul,
	year = {2023},
	note = {arXiv:2307.12971 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\NTDU6G52\\Jahin et al. - 2023 - Big Data - Supply Chain Management Framework for F.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\4HZXNJBJ\\2307.html:text/html},
}

@misc{jahin_qamplifynet_2023,
	title = {{QAmplifyNet}: {Pushing} the {Boundaries} of {Supply} {Chain} {Backorder} {Prediction} {Using} {Interpretable} {Hybrid} {Quantum} - {Classical} {Neural} {Network}},
	shorttitle = {{QAmplifyNet}},
	url = {http://arxiv.org/abs/2307.12906},
	doi = {10.48550/arXiv.2307.12906},
	abstract = {Supply chain management relies on accurate backorder prediction for optimizing inventory control, reducing costs, and enhancing customer satisfaction. However, traditional machine-learning models struggle with large-scale datasets and complex relationships, hindering real-world data collection. This research introduces a novel methodological framework for supply chain backorder prediction, addressing the challenge of handling large datasets. Our proposed model, QAmplifyNet, employs quantum-inspired techniques within a quantum-classical neural network to predict backorders effectively on short and imbalanced datasets. Experimental evaluations on a benchmark dataset demonstrate QAmplifyNet's superiority over classical models, quantum ensembles, quantum neural networks, and deep reinforcement learning. Its proficiency in handling short, imbalanced datasets makes it an ideal solution for supply chain management. To enhance model interpretability, we use Explainable Artificial Intelligence techniques. Practical implications include improved inventory control, reduced backorders, and enhanced operational efficiency. QAmplifyNet seamlessly integrates into real-world supply chain management systems, enabling proactive decision-making and efficient resource allocation. Future work involves exploring additional quantum-inspired techniques, expanding the dataset, and investigating other supply chain applications. This research unlocks the potential of quantum computing in supply chain optimization and paves the way for further exploration of quantum-inspired machine learning models in supply chain management. Our framework and QAmplifyNet model offer a breakthrough approach to supply chain backorder prediction, providing superior performance and opening new avenues for leveraging quantum-inspired techniques in supply chain management.},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Jahin, Md Abrar and Shovon, Md Sakib Hossain and Islam, Md Saiful and Shin, Jungpil and Mridha, M. F. and Okuyama, Yuichi},
	month = jul,
	year = {2023},
	note = {arXiv:2307.12906 [quant-ph]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Quantum Physics},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\W5I7NSQ8\\Jahin et al. - 2023 - QAmplifyNet Pushing the Boundaries of Supply Chai.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\2IX39XEH\\2307.html:text/html},
}

@inproceedings{zifcakova_perfectly_2022,
	title = {Perfectly conserved sequences ({PCS}) between human and mouse are significantly enriched for small proteins},
	volume = {11},
	url = {https://f1000research.com/posters/11-1473},
	doi = {10.7490/f1000research.1119288.1},
	abstract = {Read this work by Zifcakova L, at F1000Research.},
	urldate = {2023-07-26},
	booktitle = {Bioinformatics and {Computational} {Biology} {Conference} ({BBCC}), 2022},
	author = {Zifcakova, Lucia and Jahin, Md Abrar and Miller, Jonathan},
	month = dec,
	year = {2022},
}

@misc{morshed_ultrasound-based_2023,
	title = {Ultrasound-{Based} {AI} for {COVID}-19 {Detection}: {A} {Comprehensive} {Review} of {Public} and {Private} {Lung} {Ultrasound} {Datasets} and {Studies}},
	shorttitle = {Ultrasound-{Based} {AI} for {COVID}-19 {Detection}},
	url = {https://www.preprints.org/manuscript/202303.0296/v3},
	doi = {10.20944/preprints202303.0296.v3},
	abstract = {The COVID-19 pandemic has affected millions of people globally, with respiratory organs being strongly affected in individuals with comorbidities. Medical imaging-based diagnosis and prognosis have become increasingly popular in clinical settings to detect COVID-19 lung infections. Among various medical imaging modalities, ultrasound stands out as low-cost, mobile, and radiation-safe imaging technology. In this comprehensive review, we focus on ultrasound-based AI studies for COVID-19 detection that use public or private lung ultrasound datasets. We surveyed articles that used publicly available lung ultrasound datasets for COVID-19 and reviewed publicly available datasets and organize ultrasound-based AI studies per dataset. We analyzed and tabulated studies in several dimensions, such as data preprocessing, AI models, cross-validation, and evaluation criteria. In total, we reviewed 42 articles, where 28 articles used public datasets, and the rest used private data. Our findings suggest that ultrasound-based AI studies for the detection of COVID-19 have great potential for clinical use, especially for children and pregnant women. Our review also provides a useful summary for future researchers and clinicians who may be interested in the field.},
	language = {en},
	urldate = {2023-07-26},
	publisher = {Preprints},
	author = {Morshed, Abrar and Shihab, Abdulla Al and Jahin, Md Abrar and Nahian, Md Jaber Al and Sarker, Md Murad Hossain and Wadud, Md Sharjis Ibne and Uddin, Mohammad Istiaq and Siraji, Muntequa Imtiaz and Anjum, Nafisa and Shristy, Sumiya Rajjab and Rahman, Tanvin and Khatun, Mahmuda and Dewan, Md Rubel and Hossain, Mosaddeq and Sultana, Razia and Chakma, Ripel and Emon, Sonet Barua and Islam, Towhidul and Hussain, Mohammad},
	month = may,
	year = {2023},
	keywords = {Deep learning, COVID-19, Artificial Intelligence, Review, Ultrasound},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\IBGZ8A49\\Morshed et al. - 2023 - Ultrasound-Based AI for COVID-19 Detection A Comp.pdf:application/pdf},
}

@misc{jahin_extended_2023,
	title = {Extended {Covid} {Twitter} {Datasets}},
	url = {https://data.mendeley.com/datasets/2ynwykrfgf/1},
	doi = {10.17632/2ynwykrfgf.1},
	abstract = {Wider spatiotemporal English COVID-19 Tweets},
	language = {en},
	urldate = {2023-07-26},
	author = {Jahin, Md Abrar},
	month = may,
	year = {2023},
	note = {Publisher: Mendeley Data},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\7MFE5RIP\\1.html:text/html},
}

@inproceedings{ashton_that_1999,
	title = {That ‘{Internet} of {Things}’ {Thing}},
	url = {https://www.semanticscholar.org/paper/That-%E2%80%98Internet-of-Things%E2%80%99-Thing-Ashton/4ea759dc35b564d4d795c554f407fdb8652b8bed},
	abstract = {Jun 22, 2009—I could be wrong, but I'm fairly sure the phrase "Internet of Things" started life as the title of a presentation I made at Procter \& Gamble (P\&G) in 1999. Linking the new idea of RFID in P\&G's supply chain to the then-red-hot topic of the Internet was more than just a good way to get executive attention. It summed up an important insight—one that 10 years later, after the Internet of Things has become the title of everything from an article in Scientific American to the name of a European Union conference, is still often misunderstood.},
	urldate = {2023-08-26},
	author = {Ashton, Kevin},
	year = {1999},
}

@inproceedings{ashton_that_1999-1,
	title = {That ‘{Internet} of {Things}’ {Thing}},
	url = {https://www.semanticscholar.org/paper/That-%E2%80%98Internet-of-Things%E2%80%99-Thing-Ashton/4ea759dc35b564d4d795c554f407fdb8652b8bed},
	abstract = {Jun 22, 2009—I could be wrong, but I'm fairly sure the phrase "Internet of Things" started life as the title of a presentation I made at Procter \& Gamble (P\&G) in 1999. Linking the new idea of RFID in P\&G's supply chain to the then-red-hot topic of the Internet was more than just a good way to get executive attention. It summed up an important insight—one that 10 years later, after the Internet of Things has become the title of everything from an article in Scientific American to the name of a European Union conference, is still often misunderstood.},
	urldate = {2023-08-26},
	author = {Ashton, Kevin},
	year = {1999},
}

@article{ashton_that_nodate,
	title = {That '{Internet} of {Things}' {Thing}},
	language = {en},
	author = {Ashton, Kevin},
	file = {Ashton - That 'Internet of Things' Thing.pdf:C\:\\Users\\abrar\\Zotero\\storage\\N5GIYESS\\Ashton - That 'Internet of Things' Thing.pdf:application/pdf},
}

@article{ashton_that_2009,
	title = {That ‘internet of things’ thing},
	volume = {22},
	number = {7},
	journal = {RFID journal},
	author = {Ashton, Kevin},
	year = {2009},
	note = {Publisher: Hauppauge, New York},
	pages = {97--114},
}

@article{asir_internet_2015,
	title = {Internet of things and {India}’s readiness},
	volume = {10},
	abstract = {The Internet of Things (IoT) is the next emerging wave in the development of internet, after its fixed internet and mobile waves. By year 2020, over 30 million devices are expected to get wirelessly connected. Internet of things refers to the concept that not only about the indulgence of internet which is considered as way the people communicate globally among one another using computers, but it is also extended acting as a platform where electronic devices connected over a network would communicate with other similar devices present in the same network. Indeed, India is focusing to start 100 smart city projects in the next 5 years, with plans to spend 500 crores of Indian Rupees per smart city. The benefits of IoT implementation spans across variety of applications, including transport, healthcare, emergency services, traffic management, water management, environment. With an introduction of IoT, this paper describes the readiness of India, leveraging Smart city project, application areas and the challenges ahead that towards successful IoT implementation in India and the immediate opportunities.},
	author = {Asir, Reuban and Anandaraj, W. and Sivaranjani, K.},
	month = jan,
	year = {2015},
	pages = {274--279},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\653RAD6D\\Asir et al. - 2015 - Internet of things and India’s readiness.pdf:application/pdf},
}

@article{asir_internet_2015-1,
	title = {Internet of things and {India}’s readiness},
	volume = {10},
	abstract = {The Internet of Things (IoT) is the next emerging wave in the development of internet, after its fixed internet and mobile waves. By year 2020, over 30 million devices are expected to get wirelessly connected. Internet of things refers to the concept that not only about the indulgence of internet which is considered as way the people communicate globally among one another using computers, but it is also extended acting as a platform where electronic devices connected over a network would communicate with other similar devices present in the same network. Indeed, India is focusing to start 100 smart city projects in the next 5 years, with plans to spend 500 crores of Indian Rupees per smart city. The benefits of IoT implementation spans across variety of applications, including transport, healthcare, emergency services, traffic management, water management, environment. With an introduction of IoT, this paper describes the readiness of India, leveraging Smart city project, application areas and the challenges ahead that towards successful IoT implementation in India and the immediate opportunities.},
	journal = {International Journal of Applied Engineering Research},
	author = {Asir, Reuban and Anandaraj, W. and Sivaranjani, K.},
	month = jan,
	year = {2015},
	pages = {274--279},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\QT7CJ3HB\\Asir et al. - 2015 - Internet of things and India’s readiness.pdf:application/pdf},
}

@article{alonso_consistency_2006,
	title = {Consistency in the analytic hierarchy process: a new approach},
	volume = {14},
	issn = {0218-4885},
	shorttitle = {Consistency in the analytic hierarchy process},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0218488506004114},
	doi = {10.1142/S0218488506004114},
	abstract = {In this paper, we present a statistical criterion for accepting/rejecting the pairwise reciprocal comparison matrices in the analytic hierarchy process. We have studied the consistency in random matrices of different sizes. We do not agree with the traditional criterion of accepting matrices due to their inflexibility and because it is too restrictive when the size of the matrix increases. Our system is capable of adapting the acceptance requirements to different scopes and consistency necessities. The advantages of our consistency system are the introduction of adaptability in the acceptance criterion and the simplicity of the index we have used, the eigenvalue (λmax) and the simplicity of the criterion.},
	number = {04},
	urldate = {2023-08-26},
	journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
	author = {Alonso, José Antonio and Lamata, M. Teresa},
	month = aug,
	year = {2006},
	note = {Publisher: World Scientific Publishing Co.},
	keywords = {Analytic hierarchy process, consistency, eigenvalue, judgement matrix, random index},
	pages = {445--459},
}

@article{arnold_how_2016,
	title = {How the industrial internet of things changes business models in different manufacturing industries},
	volume = {20},
	issn = {1363-9196},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S1363919616400156},
	doi = {10.1142/S1363919616400156},
	abstract = {The Industrial Internet of Things (IIoT) poses large impacts on business models (BM) of established manufacturing companies within several industries. Thus, this paper aims at analyzing the influence of the IIoT on these BMs with particular respect to differences and similarities dependent on varying industry sectors. For this purpose, we employ an exploratory multiple case study approach based on semi-structured expert interviews in 69 manufacturing companies from the five most important German industries. Owing the lack of previous research, our study contributes to the current state of management literature by revealing the following valuable insights with regard to industry-specific BM changes: The machine and plant engineering companies are mainly facing changing workforce qualifications, the electrical engineering and information and communication technology companies are particularly concerned with the importance of novel key partner networks, and automotive suppliers predominantly exploit IIoT-inherent benefits in terms of an increasing cost efficiency.},
	number = {08},
	urldate = {2023-08-26},
	journal = {International Journal of Innovation Management},
	author = {Arnold, Christian and Kiel, Daniel and Voigt, Kai-Ingo},
	month = dec,
	year = {2016},
	note = {Publisher: World Scientific Publishing Co.},
	keywords = {business model, business model innovation, expert interviews, German industry sectors, Industrial Internet of Things, Industrie 4.0, manufacturing companies, multiple case study, qualitative study},
	pages = {1640015},
}

@article{mendhurwar_emerging_2018,
	title = {Emerging synergies between {Internet} of {Things} and social technologies},
	volume = {21},
	issn = {1097-198X},
	url = {https://doi.org/10.1080/1097198X.2018.1462918},
	doi = {10.1080/1097198X.2018.1462918},
	abstract = {This essay discusses the phenomena of amalgamation of two prominent technologies: Internet of Things (IoT) and Social technologies. IoT devices are primarily used for connectivity between physical objects while Social technologies are responsible for collaboration and social interaction. The domain of Social Internet of Things (SIoTs) points toward social interactions of IoT devices. This phenomenon will further enhance the collaboration capabilities of IoTs to deliver huge amounts of human–computer interactions with very limited interventions from humans. Thus, high degrees of human–computer interfaces can be created among physical objects by enabling them with human-like capabilities and social interactions. In this context, we discuss relevant research developments, contextually analyze the drivers and challenges of SIoTs, and describe some interesting business use cases along with suitable recommendations going forward.},
	number = {2},
	urldate = {2023-08-26},
	journal = {Journal of Global Information Technology Management},
	author = {Mendhurwar, Subodh and Mishra, Rajhans},
	month = apr,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1097198X.2018.1462918},
	keywords = {Social Internet of Things; technology convergence; cyber-physical-social systems},
	pages = {75--80},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\72T6YHG2\\Mendhurwar and Mishra - 2018 - Emerging synergies between Internet of Things and .pdf:application/pdf},
}

@article{atzori_internet_2010,
	title = {The {Internet} of {Things}: {A} survey},
	volume = {54},
	issn = {1389-1286},
	shorttitle = {The {Internet} of {Things}},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128610001568},
	doi = {10.1016/j.comnet.2010.05.010},
	abstract = {This paper addresses the Internet of Things. Main enabling factor of this promising paradigm is the integration of several technologies and communications solutions. Identification and tracking technologies, wired and wireless sensor and actuator networks, enhanced communication protocols (shared with the Next Generation Internet), and distributed intelligence for smart objects are just the most relevant. As one can easily imagine, any serious contribution to the advance of the Internet of Things must necessarily be the result of synergetic activities conducted in different fields of knowledge, such as telecommunications, informatics, electronics and social science. In such a complex scenario, this survey is directed to those who want to approach this complex discipline and contribute to its development. Different visions of this Internet of Things paradigm are reported and enabling technologies reviewed. What emerges is that still major issues shall be faced by the research community. The most relevant among them are addressed in details.},
	number = {15},
	urldate = {2023-08-26},
	journal = {Computer Networks},
	author = {Atzori, Luigi and Iera, Antonio and Morabito, Giacomo},
	month = oct,
	year = {2010},
	keywords = {Internet of Things, Pervasive computing, RFID systems},
	pages = {2787--2805},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\SAVRNKBD\\S1389128610001568.html:text/html},
}

@misc{kaushik_internet_2020,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Internet of {Things} ({IOT}): {Implications} in {Society}},
	shorttitle = {Internet of {Things} ({IOT})},
	url = {https://papers.ssrn.com/abstract=3563104},
	doi = {10.2139/ssrn.3563104},
	abstract = {Real-time information through the Internet of Things (IoT) enabled devices to give advantage in many walks of life. It gives opportunities to estimate \& illustrate the social implications of IoT in human life. The proliferation of smart devices across the globe along with communication, sensors, actuators \& prodigious information gives birth to the Internet of Things (IoT). Real-time data emanate information, which creates a knowledge database and finally aggrandizes the wisdom in the society. Adding technology to things creates smart homes, smart transport, smart way to monitor health, security \& safety. Smart things or devices leads to ameliorate the quality of life in society.},
	language = {en},
	urldate = {2023-08-26},
	author = {Kaushik, Neeraj and Bagga, Teena},
	month = mar,
	year = {2020},
	keywords = {Big Data, Internet of Things, IoT, Security \& safety, Smart health, Smart home, Smart transport},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\YP5B4EAX\\Kaushik and Bagga - 2020 - Internet of Things (IOT) Implications in Society.pdf:application/pdf},
}

@article{bandyopadhyay_internet_2011,
	title = {Internet of {Things}: {Applications} and {Challenges} in {Technology} and {Standardization}},
	volume = {58},
	issn = {1572-834X},
	shorttitle = {Internet of {Things}},
	url = {https://doi.org/10.1007/s11277-011-0288-5},
	doi = {10.1007/s11277-011-0288-5},
	abstract = {The phrase Internet of Things (IoT) heralds a vision of the future Internet where connecting physical things, from banknotes to bicycles, through a network will let them take an active part in the Internet, exchanging information about themselves and their surroundings. This will give immediate access to information about the physical world and the objects in it—leading to innovative services and increase in efficiency and productivity. This paper studies the state-of-the-art of IoT and presents the key technological drivers, potential applications, challenges and future research areas in the domain of IoT. IoT definitions from different perspective in academic and industry communities are also discussed and compared. Finally some major issues of future research in IoT are identified and discussed briefly.},
	language = {en},
	number = {1},
	urldate = {2023-08-26},
	journal = {Wireless Personal Communications},
	author = {Bandyopadhyay, Debasis and Sen, Jaydip},
	month = may,
	year = {2011},
	keywords = {Security, Internet of Things (IoT), Interoperability, Network protoocl, Privacy, Wireless networks},
	pages = {49--69},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\ANRB6GCY\\Bandyopadhyay and Sen - 2011 - Internet of Things Applications and Challenges in.pdf:application/pdf},
}

@article{bi_internet_2014,
	title = {Internet of {Things} for {Enterprise} {Systems} of {Modern} {Manufacturing}},
	volume = {10},
	issn = {1941-0050},
	doi = {10.1109/TII.2014.2300338},
	abstract = {Design and operation of a manufacturing enterprise involve numerous types of decision-making at various levels and domains. A complex system has a large number of design variables and decision-making requires real-time data collected from machines, processes, and business environments. Enterprise systems (ESs) are used to support data acquisition, communication, and all decision-making activities. Therefore, information technology (IT) infrastructure for data acquisition and sharing affects the performance of an ES greatly. Our objective is to investigate the impact of emerging Internet of Things (IoT) on ESs in modern manufacturing. To achieve this objective, the evolution of manufacturing system paradigms is discussed to identify the requirements of decision support systems in dynamic and distributed environments; recent advances in IT are overviewed and associated with next-generation manufacturing paradigms; and the relation of IT infrastructure and ESs is explored to identify the technological gaps in adopting IoT as an IT infrastructure of ESs. The future research directions in this area are discussed.},
	number = {2},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Bi, Zhuming and Xu, Li Da and Wang, Chengen},
	month = may,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {Decision making, literature review, Internet of Things (IoT), Data acquisition, Enterprise modeling, enterprise systems (ESs), Internet, manufacturing enterprise, Manufacturing systems, Sensors, system paradigms, Wireless sensor networks},
	pages = {1537--1546},
}

@article{chan_determinants_2013,
	title = {Determinants of mobile supply chain management system diffusion: a structural equation analysis of manufacturing firms},
	volume = {51},
	issn = {0020-7543},
	shorttitle = {Determinants of mobile supply chain management system diffusion},
	url = {https://doi.org/10.1080/00207543.2012.693961},
	doi = {10.1080/00207543.2012.693961},
	abstract = {Mobile supply chain management (SCM) is gaining recognition as a major source of cost reduction and supply chain performance improvement. The current literature related to mobile SCM needs to be extended further in order to provide insights into how manufacturing firms can implement mobile SCM successfully. Specifically, there is a need to provide empirical and systematic analysis of the variables that can explain the various stages of mobile SCM diffusion. A review of recent literature suggests that existing e-supply chain technology adoption literature is not strongly grounded in theory. A theoretical model with six hypotheses was proposed based on the technology–organisation–environment (TOE) framework and innovation diffusion theory (IDT). This study draws its survey responses from a group of manufacturing firms in order to investigate the factors that affect the diffusion of mobile SCM. The results show that the variables derived from TOE and IDT can explain mobile SCM diffusion well. However, interorganisational relationships (IORs) play a crucial role in determining the success of mobile SCM routinisation. This is one of the first known empirical studies on the factors influencing the diffusion of mobile SCM. The results of this study will help decision makers better understand the implementation process of mobile SCM and formulate strategies for successful diffusion of mobile SCM.},
	number = {4},
	urldate = {2023-08-26},
	journal = {International Journal of Production Research},
	author = {Chan, Felix   T.S. and Chong, Alain   Yee-Loong},
	month = feb,
	year = {2013},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2012.693961},
	keywords = {information technology, manufacturing management, mobile supply chain management, structural equation modelling, survey research/design},
	pages = {1196--1213},
}

@article{chang_determinants_2008,
	title = {The {Determinants} of {RFID} {Adoption} in the {Logistics} {Industry} - {A} {Supply} {Chain} {Management} {Perspective}},
	volume = {23},
	issn = {15293181},
	url = {https://aisel.aisnet.org/cais/vol23/iss1/12},
	doi = {10.17705/1CAIS.02312},
	abstract = {Despite the literature exploring the factors of adopting information technology (IT) applications for the logistics industry, Radio Frequency Identification (RFID) is still considered an innovative technology, because of its unique characteristics compared with other IT applications. To avoid the negative effects derived from careless IT investments, companies in Taiwan’s logistics industry must evaluate the factors that could affect the adoption of RFID prior to its introduction. This research employed encoding and utilized a questionnaire survey with the aim of assessing the factors that affect the adoption of this technology within the industry. Based on the results of discriminant analysis and verification, this investigation found that competition in the marketplace, pressure of transaction partners, suppliers’ industry environment, cost, integration of supply chain strategy, complexity of RFID, and mutual standard were among the critical factors. This research anticipates these factors as crucial and beneficial for the initial introduction phase of RFID adoption.},
	language = {en},
	urldate = {2023-08-26},
	journal = {Communications of the Association for Information Systems},
	author = {Chang, She-I and Hung, Shin-Yuan and Yen, David C. and Chen, Yi-Jiun},
	year = {2008},
	file = {Chang et al. - 2008 - The Determinants of RFID Adoption in the Logistics.pdf:C\:\\Users\\abrar\\Zotero\\storage\\NAU2EVSQ\\Chang et al. - 2008 - The Determinants of RFID Adoption in the Logistics.pdf:application/pdf},
}

@article{chang_determinants_2008-1,
	title = {The {Determinants} of {RFID} {Adoption} in the {Logistics} {Industry} - {A} {Supply} {Chain} {Management} {Perspective}},
	volume = {23},
	issn = {1529-3181},
	url = {https://aisel.aisnet.org/cais/vol23/iss1/12},
	doi = {10.17705/1CAIS.02312},
	number = {1},
	journal = {Communications of the Association for Information Systems},
	author = {Chang, She-I and Hung, Shin-Yuan and Yen, David and Chen, Yi-Jiun},
	month = sep,
	year = {2008},
	file = {"The Determinants of RFID Adoption in the Logistics Industry - A Supply" by She-I Chang, Shin-Yuan Hung et al.:C\:\\Users\\abrar\\Zotero\\storage\\B5S4UIIC\\12.html:text/html;Full Text:C\:\\Users\\abrar\\Zotero\\storage\\6B33NVDT\\Chang et al. - 2008 - The Determinants of RFID Adoption in the Logistics.pdf:application/pdf},
}

@article{chen_empirical_2012,
	title = {An empirical study for radio frequency identification ({RFID}) adoption by {SMEs} in the taiwanese information technology ({IT}) industry},
	volume = {17},
	abstract = {Radio Frequency Identification (RFID) technology represents a common standard for data storage and retrieval that could improve collaboration and data sharing between non-competing organisations. With the advent of RFID, organisations have the opportunity to rethink how their organisation will operate and integrate in the supply chain. Especially for Small to Medium Sized Enterprises (SMEs), that they have limited resources adopting such an innovative technology (i.e. RFID) the adoption decision can be daunting. Literature indicates that SMEs that decide to go on with implementation have so far only a few guidelines from either private companies or public authorities regarding awareness on specific opportunities and risks. This research is therefore trying to explore in detail the factors that affect SMEs' RFID adoption in the Taiwan Information Technology (IT) manufacturing industry. We are employing Exploratory Factor Analysis (EFA) techniques and utilising a questionnaire survey in order to collect and analyse our data. After classifying the responding SMEs into three different adopters categories named ready adopter, initiator adopter and unprepared adopter using EFA technique our results show that each category has some specific adoption factors related to their unique situation. These are for ready adopters: cost and management, for initiator adopters: competitiveness and process efficiency and unprepared adopters: IT management difficulties, IT implementation difficulties and cost of implementation. A SMEs RFID adoption model is then proposed. It is anticipated that the findings of this research will not only enhance the research in RFID adoption in SMEs, but can also act as a reference for practitioners in the industry and researchers in the academic field. © Asian Academy of Management and Penerbit Universiti Sains Malaysia, 2012.},
	number = {2},
	journal = {Asian Academy of Management Journal},
	author = {Chen, Hsin and Papazafeiropoulou, Anastasia},
	month = jul,
	year = {2012},
	pages = {39--58},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\PCMDDTWJ\\Chen and Papazafeiropoulou - 2012 - An empirical study for radio frequency identificat.pdf:application/pdf},
}

@article{contreras_importance_2018,
	title = {Importance of the {Use} of the {Internet} of {Things} and its {Implications} in the {Manufacturing} {Industry}},
	volume = {14},
	copyright = {Copyright (c) 2018 European Scientific Journal, ESJ},
	issn = {1857-7431},
	url = {https://eujournal.org/index.php/esj/article/view/10754},
	doi = {10.19044/esj.2018.v14n10p378},
	abstract = {The research presented in this paper is a literary analysis of 91 papers of 31 different journals of world recognition from different countries (England, Poland, Spain, China, Switzerland, Netherlands); focusing on productivity improvement inside a business through Internet of Things (IoT) in the manufacturing industry. It is essential to know the implications in the use of IoT for productivity improvement because IoT is having great influence in different context, one of them is businesses. The objective of this paper is to know the implications of the use of IoT to increase productivity, focusing on security and data privacy in the manufacturing sector. Suggestions are made regarding big data, digital manufacturing, the supply chain, cybersecurity, and monitoring and control systems for implementing IoT to improve productivity in a manufacturing industry. The use of new tools and technologies for improving productivity imply that the detailed aspects for its implementation must be analyze.},
	language = {en},
	number = {10},
	urldate = {2023-08-26},
	journal = {European Scientific Journal, ESJ},
	author = {Contreras, Laura and Perez, Juan},
	month = apr,
	year = {2018},
	note = {Number: 10},
	pages = {378--378},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\BPR7XIP6\\Contreras and Perez - 2018 - Importance of the Use of the Internet of Things an.pdf:application/pdf},
}

@article{ribeiro_da_silva_pursuit_2019,
	title = {In pursuit of {Digital} {Manufacturing}: 7th {International} {Conference} on {Changeable}, {Agile}, {Reconfigurable} and {Virtual} {Production}},
	volume = {28},
	issn = {2351-9789},
	shorttitle = {In pursuit of {Digital} {Manufacturing}},
	doi = {10.1016/j.promfg.2018.12.011},
	abstract = {Companies are adopting several new technologies that form the pillars of Industry 4.0 production framework, of which Digital Manufacturing (DM) stands out by combining conventional manufacturing technologies with digital techniques. These are used to assist in the design and analysis of the product and manufacturing processes. The adoption of digital manufacturing is partly about technological change, but it also entails significant organizational issues, which often are overlooked by managers. The purpose of this study is to identify the key factors that enable or prevent DM implementation, considering the production paradigm of Industry 4.0. Based on a literature review that identified a preliminary list of key factors, the appropriateness of these factors is empirically tested and refined in a two-fold approach: an in-depth pilot case in a multinational automotive company that is adopting DM technologies, and a survey of 113 users, managers, implementers and researchers working on digital manufacturing and Industry 4.0. The study identified 24 key factors to be considered when firms implement DM. These are categorized into technical, organizational, project based and external factors. The findings also indicate how each factor should be considered, and that they cannot be generalized due to cultural differences inherent to each individual company. As such, this research contributes to the current research debate by identifying the critical factors to be considered when conceiving and applying models for planning and executing DM implementation.},
	journal = {Procedia Manufacturing},
	author = {Ribeiro da Silva, Elias and Angelis, Jannis and Pinheiro de Lima, Edson},
	year = {2019},
	keywords = {Survey, Critical Factors, Digital Manufacturing, Implementation Process, Industry 4.0},
	pages = {63--69},
	annote = {Conference code: 7},
}

@article{fosso_wamba_determinants_2016,
	title = {Determinants of {RFID} adoption intention by {SMEs}: an empirical investigation},
	volume = {27},
	issn = {0953-7287},
	shorttitle = {Determinants of {RFID} adoption intention by {SMEs}},
	url = {https://doi.org/10.1080/09537287.2016.1167981},
	doi = {10.1080/09537287.2016.1167981},
	abstract = {Radio frequency identification (RFID) technology has been considered as one of the 10 technologies that will transform firm across industries. However, the adoption and use of the technology has been slower than predicted, mainly because of technological, organisation and environment factors related to RFID. This study develops a conceptual model that explores the role that technological, organisational, environmental and managerial characteristics of small and mid-sized enterprises (SMEs) play in their intention to adopt RFID technology. To test the model, a web-based survey was administered to 453 SME managers from the USA, the UK, Australia and India. Logistic hierarchical regression is used to test the proposed model. Implications for RFID technology research, theory and practice are discussed.},
	number = {12},
	urldate = {2023-08-26},
	journal = {Production Planning \& Control},
	author = {Fosso Wamba, Samuel and Gunasekaran, Angappa and Bhattacharya, Mithu and Dubey, Rameshwar},
	month = sep,
	year = {2016},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/09537287.2016.1167981},
	keywords = {adoption intention, determinants, RFID technology, SMEs},
	pages = {979--990},
}

@article{govindan_evaluating_2016,
	title = {Evaluating the essential barrier to off-shore wind energy – an {Indian} perspective},
	volume = {10},
	issn = {1750-6220},
	url = {https://doi.org/10.1108/IJESM-04-2015-0010},
	doi = {10.1108/IJESM-04-2015-0010},
	abstract = {Purpose The purpose of this paper is to evaluate the essential barrier and reveal the priority among common barriers to offshore wind energy in an Indian context with the assistance of the proposed framework. Design/methodology/approach Based on the proposed framework, a five-phase methodology was adapted to explore the essential barrier step by step. The common barriers, which were collected from the existing literatures through a systematic review, were further validated by field experts. The collected common barriers were evaluated with the assistance of the case industry’s field professionals through an analytical hierarchy process, a multi-criteria decision-making tool, to evaluate the barriers to Indian offshore wind energy. Findings Among the 12 common barriers to offshore wind energy, it is clear that “high capital cost” is the most essential barrier involved in the implementation of offshore wind energy farms in the Indian context. Practical implications This study reveals the importance of offshore wind power as a long-term profitable strategy to the case company within the Indian context. By addressing the essential barriers to the implementation of offshore wind farms, the Indian offshore wind system managers can train their employees to counteract the hindrances through the benchmarking of pioneering global offshore wind power developers such as Denmark and the UK. Further, this study provides useful suggestions to the Indian Government regarding policies for offshore wind energy; it also clearly projects the current status of the Indian offshore wind farm implementation. Originality/value This study assists Indian key stakeholders of offshore wind energy by indicating the essential barrier in an Indian context; they can remove the particular barrier instead of focusing on others that previous studies have identified. Further, this study brings out the importance of offshore wind power in an Indian context, which can urge stakeholders to invest more in offshore wind farms.},
	number = {2},
	urldate = {2023-08-26},
	journal = {International Journal of Energy Sector Management},
	author = {Govindan, Kannan and Shankar, Madan},
	month = jan,
	year = {2016},
	note = {Publisher: Emerald Group Publishing Limited},
	pages = {266--282},
}

@article{haddud_examining_2017,
	title = {Examining potential benefits and challenges associated with the {Internet} of {Things} integration in supply chains},
	volume = {28},
	issn = {1741-038X},
	url = {https://doi.org/10.1108/JMTM-05-2017-0094},
	doi = {10.1108/JMTM-05-2017-0094},
	abstract = {Purpose The Internet of Things (IoT) is expected to have a huge impact on businesses and, especially, the way we think about supply chain management (SCM). However, there is still a paucity of studies on the impact of IoT adoption on supply chains and on different aspects of the business in general. The purpose of this paper is to examine the perception of the academic community of the impact of the IoT adoption in organizational supply chains with a view to verify potential key benefits and challenges existent in the literature. The research presents the impact on an organization along with the impact across its entire supply chain. Design/methodology/approach Data were collected through the use of an online survey and 87 participants completed the survey. Participants were mainly from the academic community and were university scholars based in different countries located in six continents. Participants were authors, or co-authors, of academic papers published in the Decision Science Institute 2015 and 2016 annual conference proceedings, the 21st International Symposium of Sustainable Transport and Supply Chain Innovations, the Supply Chain Management: An International Journal 2016 issues, and the Operations and Supply Chain Management: An International Journal 2016 issues. Findings The authors were able to confirm the significance of some of the examined potential benefits to individual organizations and their entire supply chains. However, the study identified other potential benefits that were not seen as a direct impact of IoT adoption. Most of the examined potential benefits were found to contribute to a number of critical success factors for implementing successful SCM. The authors were also able to confirm that some of the examined potential challenges were still perceived as key hinders to IoT adoption but examined potential challenges were not seen as hurdles to IoT adoption. Originality/value To the best of the authors’ knowledge, this is the first study of its kind. Although some literature attempted to provide an overview about the IoT management, no study has specifically explored potential benefits and challenges related to the adoption of IoT in supply chains and ranked them based on their significance. The results can be beneficial to academic scholars interested in the researched topic, business professionals, organizations within different sectors, and any other party interested in understanding more about the impact of adopting IoT on SCM.},
	number = {8},
	urldate = {2023-08-26},
	journal = {Journal of Manufacturing Technology Management},
	author = {Haddud, Abubaker and DeSouza, Arthur and Khare, Anshuman and Lee, Huei},
	month = jan,
	year = {2017},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Supply chain management, Supply chains, Adoption, Benefits, Challenges, Information management, Information technology, Internet of things (IoT), Risks, Technology, Value chain},
	pages = {1055--1085},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\RLVLAFMZ\\Haddud et al. - 2017 - Examining potential benefits and challenges associ.pdf:application/pdf},
}

@article{gubbi_internet_2013,
	series = {Including {Special} sections: {Cyber}-enabled {Distributed} {Computing} for {Ubiquitous} {Cloud} and {Network} {Services} \& {Cloud} {Computing} and {Scientific} {Applications} — {Big} {Data}, {Scalable} {Analytics}, and {Beyond}},
	title = {Internet of {Things} ({IoT}): {A} vision, architectural elements, and future directions},
	volume = {29},
	issn = {0167-739X},
	shorttitle = {Internet of {Things} ({IoT})},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X13000241},
	doi = {10.1016/j.future.2013.01.010},
	abstract = {Ubiquitous sensing enabled by Wireless Sensor Network (WSN) technologies cuts across many areas of modern day living. This offers the ability to measure, infer and understand environmental indicators, from delicate ecologies and natural resources to urban environments. The proliferation of these devices in a communicating–actuating network creates the Internet of Things (IoT), wherein sensors and actuators blend seamlessly with the environment around us, and the information is shared across platforms in order to develop a common operating picture (COP). Fueled by the recent adaptation of a variety of enabling wireless technologies such as RFID tags and embedded sensor and actuator nodes, the IoT has stepped out of its infancy and is the next revolutionary technology in transforming the Internet into a fully integrated Future Internet. As we move from www (static pages web) to web2 (social networking web) to web3 (ubiquitous computing web), the need for data-on-demand using sophisticated intuitive queries increases significantly. This paper presents a Cloud centric vision for worldwide implementation of Internet of Things. The key enabling technologies and application domains that are likely to drive IoT research in the near future are discussed. A Cloud implementation using Aneka, which is based on interaction of private and public Clouds is presented. We conclude our IoT vision by expanding on the need for convergence of WSN, the Internet and distributed computing directed at technological research community.},
	number = {7},
	urldate = {2023-08-26},
	journal = {Future Generation Computer Systems},
	author = {Gubbi, Jayavardhana and Buyya, Rajkumar and Marusic, Slaven and Palaniswami, Marimuthu},
	month = sep,
	year = {2013},
	keywords = {Internet of Things, Wireless sensor networks, Cloud computing, RFID, Smart environments, Ubiquitous sensing},
	pages = {1645--1660},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\V9QNQLXA\\S0167739X13000241.html:text/html;Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\2BSYNK37\\Gubbi et al. - 2013 - Internet of Things (IoT) A vision, architectural .pdf:application/pdf},
}

@article{ho_integrated_2008,
	title = {Integrated analytic hierarchy process and its applications – {A} literature review},
	volume = {186},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221707000872},
	doi = {10.1016/j.ejor.2007.01.004},
	abstract = {Due to its wide applicability and ease of use, the analytic hierarchy process (AHP) has been studied extensively for the last 20years. Recently, it is observed that the focus has been confined to the applications of the integrated AHPs rather than the stand-alone AHP. The five tools that commonly combined with the AHP include mathematical programming, quality function deployment (QFD), meta-heuristics, SWOT analysis, and data envelopment analysis (DEA). This paper reviews the literature of the applications of the integrated AHPs. Related articles appearing in the international journals from 1997 to 2006 are gathered and analyzed so that the following three questions can be answered: (i) which type of the integrated AHPs was paid most attention to? (ii) which area the integrated AHPs were prevalently applied to? (iii) is there any inadequacy of the approaches? Based on the inadequacy, if any, some improvements and possible future work are recommended. This research not only provides evidence that the integrated AHPs are better than the stand-alone AHP, but also aids the researchers and decision makers in applying the integrated AHPs effectively.},
	number = {1},
	urldate = {2023-08-26},
	journal = {European Journal of Operational Research},
	author = {Ho, William},
	month = apr,
	year = {2008},
	keywords = {Analytic hierarchy process, Data envelopment analysis, Mathematical programming, Meta-heuristics, Quality function deployment, SWOT analysis},
	pages = {211--228},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\3QG8HV7B\\S0377221707000872.html:text/html;Submitted Version:C\:\\Users\\abrar\\Zotero\\storage\\YH2FXXPI\\Ho - 2008 - Integrated analytic hierarchy process and its appl.pdf:application/pdf},
}

@article{hsu_understanding_2017,
	title = {Understanding the factors affecting the adoption of the {Internet} of {Things}},
	volume = {29},
	issn = {0953-7325},
	url = {https://doi.org/10.1080/09537325.2016.1269160},
	doi = {10.1080/09537325.2016.1269160},
	abstract = {The Internet of Things (IoTs) is widely considered as one of the most important infrastructures for promoting economic development and technological innovation. The purpose of this study is to find the key factors influencing IoT adoptions, specifically in Taiwan’s logistics industry. In this study adopts a model which is a hybrid of technology, organisation and environment (TOE) and the decision-making trial and evaluation laboratory method (DEMA℡) to evaluate the complex factors influencing the adoption of IoT. The study employs the TOE framework as a basis to develop a general evaluation framework, and the DEMA℡ technique conceptualises a structural model and then identifies the causal relationships among factors through a cause-effect relationship diagram. Finally, we also divided the complex influencing factors into cause and effect groups to better clarify the causal relationships for decision-making, to ensure the efficiency of IoT adoption.},
	number = {9},
	urldate = {2023-08-26},
	journal = {Technology Analysis \& Strategic Management},
	author = {Hsu, Ching-Wen and Yeh, Ching-Chiang},
	month = oct,
	year = {2017},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09537325.2016.1269160},
	keywords = {Internet of Things, critical factors, decision-making trial and evaluation laboratory, organisation and environment, technology},
	pages = {1089--1102},
}

@article{kiel_influence_2017,
	title = {The influence of the {Industrial} {Internet} of {Things} on business models of established manufacturing companies – {A} business level perspective},
	volume = {68},
	issn = {0166-4972},
	url = {https://www.sciencedirect.com/science/article/pii/S0166497216303169},
	doi = {10.1016/j.technovation.2017.09.003},
	abstract = {The emergence of the Industrial Internet of Things (IIoT) poses a large impact on established business models of manufacturing companies. This study aims at analyzing the influence of the IIoT on these business models from a business level perspective. In particular, it focuses on the interrelationships between business model component changes. While the sparse body of extant management literature examines just a subset of business model elements as affected by the IIoT, a framework comprising an entire set of elements is provided. Besides, their direct and indirect interrelationships, and the most important changes in each of the elements, are investigated. For this purpose, an exploratory multiple case study approach is employed, which is based on relevant IIoT-related experiences of 76 German manufacturing companies. By triangulating data from semi-structured expert interviews and archival company material, the study provides in-depth insights and a better understanding of IIoT-driven effects on manufacturing business models. It contributes to extant management literature by revealing the value proposition, internal infrastructure management, and customer relationships predominantly influenced by the IIoT. Moreover, it is shown that IIoT-triggered business model changes are offer-driven, particularly by production and process optimization within customers' production systems. These value proposition changes result in subsequent modifications of the remaining business model elements.},
	urldate = {2023-08-26},
	journal = {Technovation},
	author = {Kiel, Daniel and Arnold, Christian and Voigt, Kai-Ingo},
	month = dec,
	year = {2017},
	keywords = {Industrial Internet of Things, Industrie 4.0, Business model, Business model innovation, Expert interviews, Manufacturing, Multiple case study},
	pages = {4--19},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\N938YA7C\\S0166497216303169.html:text/html},
}

@article{lee_internet_2015,
	title = {The {Internet} of {Things} ({IoT}): {Applications}, investments, and challenges for enterprises},
	volume = {58},
	issn = {0007-6813},
	shorttitle = {The {Internet} of {Things} ({IoT})},
	url = {https://www.sciencedirect.com/science/article/pii/S0007681315000373},
	doi = {10.1016/j.bushor.2015.03.008},
	abstract = {The Internet of Things (IoT), also called the Internet of Everything or the Industrial Internet, is a new technology paradigm envisioned as a global network of machines and devices capable of interacting with each other. The IoT is recognized as one of the most important areas of future technology and is gaining vast attention from a wide range of industries. This article presents five IoT technologies that are essential in the deployment of successful IoT-based products and services and discusses three IoT categories for enterprise applications used to enhance customer value. In addition, it examines the net present value method and the real option approach widely used in the justification of technology projects and illustrates how the real option approach can be applied for IoT investment. Finally, this article discusses five technical and managerial challenges.},
	number = {4},
	urldate = {2023-08-26},
	journal = {Business Horizons},
	author = {Lee, In and Lee, Kyoochun},
	month = jul,
	year = {2015},
	keywords = {Supply chain management, Real options, Internet of Things, Cloud computing, Radio frequency identification},
	pages = {431--440},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\KGNHQE3H\\S0007681315000373.html:text/html},
}

@article{lim_rfid_2013,
	title = {{RFID} in the warehouse: {A} literature analysis (1995–2010) of its applications, benefits, challenges and future trends},
	volume = {145},
	issn = {0925-5273},
	shorttitle = {{RFID} in the warehouse},
	url = {https://www.sciencedirect.com/science/article/pii/S0925527313002314},
	doi = {10.1016/j.ijpe.2013.05.006},
	abstract = {Radio Frequency Identification (RFID) has been identified as a crucial technology for the modern 21st century knowledge-based economy. Some businesses have realised benefits of RFID adoption through improvements in operational efficiency, additional cost savings, and opportunities for higher revenues. RFID research in warehousing operations has been less prominent than in other application domains. To investigate how RFID technology has had an impact in warehousing, a comprehensive analysis of research findings available from articles through leading scientific article databases has been conducted. Articles from years 1995 to 2010 have been reviewed and analysed with respect to warehouse operations, RFID application domains, benefits achieved and obstacles encountered. Four discussion topics are presented covering RFID in warehousing focusing on its applications, perceived benefits, obstacles to its adoption and future trends. This is aimed at elucidating the current state of RFID in the warehouse and providing insights for researchers to establish new research agendas and for practitioners to consider and assess the adoption of RFID in warehousing functions.},
	number = {1},
	urldate = {2023-08-26},
	journal = {International Journal of Production Economics},
	author = {Lim, Ming K. and Bahr, Witold and Leung, Stephen C. H.},
	month = sep,
	year = {2013},
	keywords = {RFID, Literature analysis, Warehouse operations},
	pages = {409--430},
	file = {Accepted Version:C\:\\Users\\abrar\\Zotero\\storage\\UEQCBIQH\\Lim et al. - 2013 - RFID in the warehouse A literature analysis (1995.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\67D6LIAR\\S0925527313002314.html:text/html},
}

@article{lin_integrated_2009,
	title = {An integrated framework for the development of radio frequency identification technology in the logistics and supply chain management},
	volume = {57},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835209000783},
	doi = {10.1016/j.cie.2009.02.010},
	abstract = {Radio Frequency Identification (RFID) features high storage capacity, remote access, excellent data security, and multiple-tag reading. Hence, RFID technology attracts attention from various industries, especially the logistics and retail industries. Due to the swift development of technology and the trend of globalization, the logistics managers are assigned the task to integrate the supply chain via information technology such as RFID. The goal is to achieve information sharing and reduction of total cost, thus the operation efficiency can be improved and competitive advantage can be enhanced. Thus, this research would first identify the key factors of RFID technology development in the logistics and supply chain management. A complete set of five dimensions and 24 factors with a hierarchy structure is presented. The Fuzzy Delphi and Fuzzy Analytic Hierarchy Process methods are adopted for analysis. A structural procedure of RFID system establishment is also constructed based on the key dimensions and factors, with the expectation of establishing the RFID system in an effective and efficient manner. Then, based on the experience of Taiwanese government and industry, the sequence of companies for adopting the RFID technology is discussed. Thus, an integrated framework for the development of RFID technology, which includes the hierarchy of factors, structural procedure, and sequence of adoption, is presented in this research; and it can be applied in other scenarios after the users make some modifications according to their specific needs.},
	number = {3},
	urldate = {2023-08-26},
	journal = {Computers \& Industrial Engineering},
	author = {Lin, L. C.},
	month = oct,
	year = {2009},
	keywords = {Supply chain management, Analytic Hierarchy Process (AHP), Logistics management, Radio Frequency Identification (RFID)},
	pages = {832--842},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\ULYY2FNC\\S0360835209000783.html:text/html},
}

@misc{noauthor_manufacturing_nodate,
	title = {Manufacturing {Sector} in {India}: {Market} {Size}, {FDI}, {Govt} {Initiatives} {\textbar} {IBEF}},
	shorttitle = {Manufacturing {Sector} in {India}},
	url = {https://www.ibef.org/industry/manufacturing-sector-india},
	abstract = {Read the Latest News and Updates on Manufacturing Sector in India. Get all the News about Indian Manufacturing Industry.},
	language = {en},
	urldate = {2023-08-26},
	journal = {India Brand Equity Foundation},
}

@article{mishra_investigate_2018,
	title = {To investigate the critical risk criteria of business continuity management by using analytical hierarchy process},
	volume = {11},
	url = {https://ideas.repec.org//a/ids/ijmcph/v11y2018i1p94-115.html},
	abstract = {Business continuity management (BCM) is a management process which is practised to counteract the negative impacts of possible threats to the continuity of organisational activities. This paper provides the criteria that contribute to the risk amplification for the disruption of business. Over the last two decades, global concerns have emerged due to natural disasters, and human-made disasters, which are also responsible for the business interruption. The purpose of this paper is to investigate the critical risk criteria of business continuity management/process and their potential impact on the businesses as well as their supply chain. Six criteria and 28 sub-criteria were selected from the literature review, and views of experts' (academicians, and industry practitioners), and an AHP methodology has been adopted to rank the same. A criteria namely 'organisational and management risk (OMR)' and a sub-criteria namely 'management policies failure' were found to be the most significant. These research findings are intended to help the decision and policy makers in understanding the significance of critical risk criteria and for the formulation of effective policies and strategies for their elimination.},
	language = {en},
	number = {1},
	urldate = {2023-08-26},
	journal = {International Journal of Management Concepts and Philosophy},
	author = {Mishra, Swati and Raut, Rakesh D. and Narkhede, Balkrishna E. and Gardas, Bhaskar B. and Priyadarshinee, Pragati},
	year = {2018},
	note = {Publisher: Inderscience Enterprises Ltd},
	keywords = {MCDM, AHP, analytical hierarchy process, BCM, BCP, business continuity management, business continuity plan, critical risk criteria, supply chain management.},
	pages = {94--115},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\PBVSW4YM\\v11y2018i1p94-115.html:text/html},
}

@article{pool_rfid_2015,
	title = {{RFID} acceptance in {SMEs} using {TOE} framework: an empirical investigation on {Iranian} {SMEs}},
	volume = {21},
	issn = {1742-7967, 1742-7975},
	shorttitle = {{RFID} acceptance in {SMEs} using {TOE} framework},
	url = {http://www.inderscience.com/link.php?id=69731},
	doi = {10.1504/IJLSM.2015.069731},
	language = {en},
	number = {3},
	urldate = {2023-08-26},
	journal = {International Journal of Logistics Systems and Management},
	author = {Pool, Javad Khazaei and Arabzad, S. Mohammad and Asadi, Ali and Ansari, Mohammad Reza},
	year = {2015},
	pages = {335},
}

@article{raut_modeling_2018,
	title = {Modeling the drivers of post-harvest losses – {MCDM} approach},
	volume = {154},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169917301795},
	doi = {10.1016/j.compag.2018.09.035},
	abstract = {Post-harvest losses (PHL) in India are significant and cause massive economic deficit. The reduction of PHL can help achieve sustainability in balancing economic, social, and environmental dimensions. The objective of this research article is to identify the crucial causal factors of PHL in the fruits and vegetables (F\&V) supply chain in the Indian context. From the exhaustive literature review and expert opinions, sixteen causal factors were identified, and the analytic hierarchy process (AHP) was applied to ascertain the relative importance of these factors on a comparative basis. The developed model highlighted the most critical factors that should be prioritized for progressive PHL reduction. The top three significant causal factors are lack of linkages between institution, industry, and Government (F8) with an intensity of 0.164313, climate and weather conditions (F15) with a magnitude of 0.103817, and lack of linkages in the marketing channel, from farm gate to the market because of small land sizing farmers (F9) with a value of 0.101895. In future studies, for improving the accuracy and reliability of the developed model, other Multi-Criteria Decision Making (MCDM) tools may be employed along with the AHP. Also, for validation purpose, the Structural Equation Modeling (SEM) methodology, which is a statistical approach, may be applied. The proposed model is intended to guide various supply chain members and decision-makers for reducing PHL and improving the performance of the F\&V supply chain.},
	urldate = {2023-08-26},
	journal = {Computers and Electronics in Agriculture},
	author = {Raut, Rakesh D. and Gardas, Bhaskar B. and Kharat, Manoj and Narkhede, Balkrishna},
	month = nov,
	year = {2018},
	keywords = {Multi-Criteria Decision Making (MCDM), Analytic hierarchy process, Drivers, Fruits and vegetables (F\&V) supply chain, India, Post-harvest losses (PHL), Sustainability},
	pages = {426--433},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\BPQJEY3Z\\S0168169917301795.html:text/html},
}

@misc{noauthor_inderscience_nodate,
	title = {Inderscience {Publishers} - linking academia, business and industry through research},
	url = {https://www.inderscience.com/offers.php?id=10022454},
	urldate = {2023-08-26},
	file = {Inderscience Publishers - linking academia, business and industry through research:C\:\\Users\\abrar\\Zotero\\storage\\2DZW4ETY\\offers.html:text/html},
}

@article{jha_analysing_2019,
	title = {Analysing the challenges in sustainable agricultural supply chain system in {India}},
	volume = {18},
	doi = {10.1504/IJBEX.2019.10022454},
	abstract = {An effective, sustainable agricultural supply chain system (SASCS) plays an important role in sustaining and stimulating development and growth in the agricultural and food sector. It covers all the activities involved in moving the agricultural produce from the farm to the end user. There are some challenges to this domain, which are constricting its growth in India. The objective of the present investigation is to identify the most crucial problems in the agricultural supply chain system through a literature survey and expert judgements. The explored challenges are modelled using the analytic hierarchy process (AHP). After analysing the factors, the top three identified significant challenges of the hierarchical model are-lack of agricultural supply chain infrastructure (C1), lack of integration among the national agricultural markets (C2) and seasonality of the agricultural produce and long gestation period for the projects of infrastructure (C4). The developed AHP model will guide the decision and policy makers in formulating the appropriate sustainable policies for improving the overall agricultural supply chain performance.

Keywords: challenges; barriers; hindrances; agricultural supply chain system; sustainability; food security; analytic hierarchy process; AHP; India.},
	number = {3},
	journal = {International Journal of Business Excellence},
	author = {Jha, Manoj and Narkhede, Balkrishna and Raut, Rakesh and Gardas, Bhaskar},
	month = jan,
	year = {2019},
	pages = {336--359},
}

@misc{noauthor_internet_nodate,
	title = {The {Internet} of {Things}},
	url = {https://mitpress.mit.edu/9780262527736/the-internet-of-things/},
	abstract = {A guided tour through the Internet of Things, a networked world of connected devices, objects, and people that is changing the way we live and work.We turn o...},
	language = {en-US},
	urldate = {2023-08-26},
	journal = {MIT Press},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\KPSHNNKJ\\the-internet-of-things.html:text/html},
}

@book{greengard_internet_2015,
	address = {Cambridge, Massachusetts},
	title = {The {Internet} of {Things}},
	isbn = {978-0-262-52773-6},
	abstract = {A guided tour through the Internet of Things, a networked world of connected devices, objects, and people that is changing the way we live and work.We turn on the lights in our house from a desk in an office miles away. Our refrigerator alerts us to buy milk on the way home. A package of cookies on the supermarket shelf suggests that we buy it, based on past purchases. The cookies themselves are on the shelf because of a “smart” supply chain. When we get home, the thermostat has already adjusted the temperature so that it's toasty or bracing, whichever we prefer. This is the Internet of Things―a networked world of connected devices, objects, and people. In this book, Samuel Greengard offers a guided tour through this emerging world and how it will change the way we live and work.Greengard explains that the Internet of Things (IoT) is still in its early stages. Smart phones, cloud computing, RFID (radio-frequency identification) technology, sensors, and miniaturization are converging to make possible a new generation of embedded and immersive technology. Greengard traces the origins of the IoT from the early days of personal computers and the Internet and examines how it creates the conceptual and practical framework for a connected world. He explores the industrial Internet and machine-to-machine communication, the basis for smart manufacturing and end-to-end supply chain visibility; the growing array of smart consumer devices and services―from Fitbit fitness wristbands to mobile apps for banking; the practical and technical challenges of building the IoT; and the risks of a connected world, including a widening digital divide and threats to privacy and security. Finally, he considers the long-term impact of the IoT on society, narrating an eye-opening “Day in the Life” of IoT connections circa 2025.},
	language = {English},
	publisher = {The MIT Press},
	author = {Greengard, Samuel},
	month = mar,
	year = {2015},
}

@article{xu_internet_2014,
	title = {Internet of {Things} in {Industries}: {A} {Survey}},
	volume = {10},
	issn = {1941-0050},
	shorttitle = {Internet of {Things} in {Industries}},
	doi = {10.1109/TII.2014.2300753},
	abstract = {Internet of Things (IoT) has provided a promising opportunity to build powerful industrial systems and applications by leveraging the growing ubiquity of radio-frequency identification (RFID), and wireless, mobile, and sensor devices. A wide range of industrial IoT applications have been developed and deployed in recent years. In an effort to understand the development of IoT in industries, this paper reviews the current research of IoT, key enabling technologies, major IoT applications in industries, and identifies research trends and challenges. A main contribution of this review paper is that it summarizes the current state-of-the-art IoT in industries systematically.},
	number = {4},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Xu, Li Da and He, Wu and Li, Shancang},
	month = nov,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {Big data, Big data analytics, Wireless sensor networks, enterprise systems, industrial informatics, information and communications technology (ICT), internet of things (IoT), near field communications, radio-frequency identification (RFID), Radiofrequency identification, Service-oriented architecture, Wireless communication, wireless sensor networks (WSNs)},
	pages = {2233--2243},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\abrar\\Zotero\\storage\\RVKHNH3B\\6714496.html:text/html},
}

@inproceedings{zhou_industry_2015,
	title = {Industry 4.0: {Towards} future industrial opportunities and challenges},
	shorttitle = {Industry 4.0},
	doi = {10.1109/FSKD.2015.7382284},
	abstract = {Industry 4.0 (the fourth industrial revolution) encapsulates future industry development trends to achieve more intelligent manufacturing processes, including reliance on Cyber-Physical Systems (CPS), construction of Cyber-Physical Production Systems (CPPS), and implementation and operation of smart factories. This paper introduces relevant aspects of Industry 4.0 in relation to strategic planning, key technologies, opportunities, and challenges. Strategic planning includes construction of a CPS network, discussion of two major themes which are based on the smart factory and intelligent production, achieving three integrations (horizontal integration, vertical integration and end-to-end integration) and achieving eight plans which consist of the formulation of system standardization, efficient management etc. Finally, it referred to the enlightenment for China's manufacturing industries, to build China's Industry 4.0.},
	booktitle = {2015 12th {International} {Conference} on {Fuzzy} {Systems} and {Knowledge} {Discovery} ({FSKD})},
	author = {Zhou, Keliang and Liu, Taigang and Zhou, Lifeng},
	month = aug,
	year = {2015},
	keywords = {big data, Industries, Artificial intelligence, Production facilities, Internet, Industry 4.0, Manufacturing, cloud computing, CPPS, CPS, intelligent manufacturing, Mobile communication},
	pages = {2147--2152},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\abrar\\Zotero\\storage\\XQP65IY2\\7382284.html:text/html},
}

@article{kagermann_secure_2012,
	title = {Secure the future of {Germany} as a production location, implementation recommendations for the future project industry 4.0},
	volume = {4},
	journal = {Deutschlands Zukunft als Produktionsstandort sichern, Umsetzungsempfehlungen für das Zukunftsprojekt Industrie},
	author = {Kagermann, H. and Wahlster, W. and Helbig, J.},
	year = {2012},
}

@misc{noauthor_recommendations_nodate,
	title = {Recommendations for {Implementing} the {Strategic} {Initiative} {INDUSTRIE} 4.0 -- {Securing} the {Future} of {German} {Manufacturing} {Industry} {\textbar} {BibSonomy}},
	url = {https://www.bibsonomy.org/bibtex/25c352acf1857c1c1839c1a11fe9b7e6c/flint63},
	urldate = {2023-08-26},
}

@misc{noauthor_recommendations_nodate-1,
	title = {Recommendations for {Implementing} the {Strategic} {Initiative} {INDUSTRIE} 4.0 -- {Securing} the {Future} of {German} {Manufacturing} {Industry} {\textbar} {BibSonomy}},
	url = {https://www.bibsonomy.org/bibtex/25c352acf1857c1c1839c1a11fe9b7e6c/flint63},
	urldate = {2023-08-26},
}

@article{cheng_industry_2016,
	title = {Industry 4.1 for {Wheel} {Machining} {Automation}},
	volume = {1},
	issn = {2377-3766},
	doi = {10.1109/LRA.2016.2517208},
	abstract = {Industry 4.0 is set to be one of the new manufacturing objectives. The technologies involved to achieve Industry 4.0 are Internet of Things (IoT), cyber physical systems (CPS), and cloud manufacturing (CM). However, the current objectives defined by Industry 4.0 do not include zero defects; it only keeps the faith of achieving nearly zero-defects state. The purpose of this paper is to propose a platform denoted advanced manufacturing cloud of things (AMCoT) to not only achieve the objectives of Industry 4.0 but also accomplish the goal of zero defects by applying the technology of automatic virtual metrology (AVM). As such, by applying Industry 4.0 together with AVM to achieve the goal of zero defects, the era of Industry 4.1 is taking place. The application of wheel machining automation is adopted in this letter to illustrate how AMCoT and Industry 4.1 work.},
	number = {1},
	journal = {IEEE Robotics and Automation Letters},
	author = {Cheng, Fan-Tien and Tieng, Hao and Yang, Haw-Ching and Hung, Min-Hsiung and Lin, Yu-Chuan and Wei, Chun-Fan and Shieh, Zih-Yan},
	month = jan,
	year = {2016},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Industries, Inspection, automatic virtual metrology (AVM), Automatic Virtual Metrology (AVM), factory automation, industry 4.1, Industry 4.1, Intelligent and flexible manufacturing, Intelligent and Flexible Manufacturing, Factory Automation, Machining, Metrology, Wheels, zero defects, Zero Defects},
	pages = {332--339},
}

@article{tu_exploratory_2018,
	title = {An exploratory study of {Internet} of {Things} ({IoT}) adoption intention in logistics and supply chain management: {A} mixed research approach},
	volume = {29},
	issn = {0957-4093},
	shorttitle = {An exploratory study of {Internet} of {Things} ({IoT}) adoption intention in logistics and supply chain management},
	url = {https://doi.org/10.1108/IJLM-11-2016-0274},
	doi = {10.1108/IJLM-11-2016-0274},
	abstract = {Purpose The Internet of Things (IoT) envisions a global infrastructure of networked physical objects that render radical transparency to supply chain management. Despite the perceived advantages of IoT, industry has still not widely adopted IoT-enabled logistics and supply chain management. The purpose of this paper is to understand the incentives and concerns behind firms’ decisions to adopt IoT, explore the determinant factors affecting IoT adoption in logistics and supply chain management. Design/methodology/approach This study uses mixed methods research to explore the determinants of IoT adoption intention in logistics and supply chain management. Qualitative analysis using the Grounded Theory methodology reveals the underlying perceptions regarding logistic innovation with IoT. Quantitative hypotheses are then developed based on qualitative investigation and adoption literature. Survey data were collected from the managerial staff of Taiwanese firms across various industries. Structural equation modeling with partial least square is used for data analysis. Findings The results of the qualitative study identify uncertainties and issues regarding firms’ intention to accept or reject IoT technology in logistics and supply chain management, including the benefit and cost aspects of adopting IoT, uncertainties about the trustworthiness of IoT technology, and the external motivating force to embrace IoT. The resulting quantitative model shows that perceived benefits, perceived costs, and external pressure are significant determinants of IoT adoption intention, while technology trust is not. However, technology trust does indirectly influence IoT adoption intention through perceived benefits. Practical implications The empirical findings of this study provide some guidelines for logistics and supply chain managers to evaluate IoT adoption in their firms. Likewise, IoT solution providers can also benefit from this study by improving their solutions to mitigate the IoT adoption concerns addressed herein. Originality/value This paper is among the first known to examine IoT adoption intention in logistics and supply chain management using mixed methods research. The mixed methods approach offers a better insight in understanding incentives behind firms’ decisions to adopt IoT vs the use of either a qualitative or quantitative method alone.},
	number = {1},
	urldate = {2023-08-26},
	journal = {The International Journal of Logistics Management},
	author = {Tu, Mengru},
	month = jan,
	year = {2018},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Internet of Things, RFID, Asia, IoT adoption intention, Logistics and supply chain management, Mixed method, Mixed research approach},
	pages = {131--151},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\NZKKCLJU\\Tu - 2018 - An exploratory study of Internet of Things (IoT) a.pdf:application/pdf},
}

@article{reyes_determinants_2016,
	title = {Determinants of {RFID} adoption stage and perceived benefits},
	volume = {254},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221716301977},
	doi = {10.1016/j.ejor.2016.03.051},
	abstract = {This study identifies the determinants of radio frequency identification (RFID) adoption stage and explores the perceived benefits from RFID adoption. RFID adoption is divided into three stages, starting from not considering the adoption (Stage 1), to begin considering the adoption (Stage 2) and to finally implementing RFID (Stage 3). It is argued that a firm's RFID adoption stage is influenced by the following factors: Drivers (Internal Drivers and External Drivers), Management Leadership (Top Management Leadership and Middle-level Management Leadership), and Barriers (Cost Issues, Lack of Understanding, Technical Issues and Privacy Issues). The RFID adoption stage will in turn impact the level of perceived Benefits from RFID implementation. Benefits we measure are Customer Service, Productivity, Asset Management and Communication. Through an on-line survey we collected data from 175 organizations and we used an ordered probit regression model to test the factors influencing RFID adoption stage. Business sector and firm size were entered as control variables. The results show that internal drivers, top management leadership, cost barrier and firm size are significant determinants of the stage of RFID adoption. In addition, two-factor ANOVA were conducted to investigate the impact of RFID adoption stage/firm size on perceived benefits. The findings show that RFID adoption stage has a significant positive impact on each perceived benefit. The results also show that firm size has a significant impact on perceived customer service and productivity benefits. Our results offer new insights into RFID adoption factors and broaden our understanding of RFID technology in the supply chain.},
	number = {3},
	urldate = {2023-08-26},
	journal = {European Journal of Operational Research},
	author = {Reyes, Pedro M. and Li, Suhong and Visich, John K.},
	month = nov,
	year = {2016},
	keywords = {Supply chain management, Survey, Adoption, RFID, Factor analysis},
	pages = {801--812},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\88DVJJF3\\S0377221716301977.html:text/html},
}

@article{viriyasitavat_blockchain_2019,
	title = {Blockchain and {Internet} of {Things} for {Modern} {Business} {Process} in {Digital} {Economy}—the {State} of the {Art}},
	volume = {6},
	issn = {2329-924X},
	doi = {10.1109/TCSS.2019.2919325},
	abstract = {In addition to functionalities, business process management (BPM) involves several key indicators such as openness, security, flexibility, and scalability. Optimizing system performance is becoming a great challenge for an ever-increasing large-scale distributed application system in the digital economy on the Internet of Things (IoT) era. In a centralized BPM, many indicators, such as security and openness, or cost and flexibility, are conflicting with each other. For example, inviting new partners across enterprises, domains, and regions to form a service workflow exposes new risks and needs additional security mechanisms for scrutiny; enhancing the flexibility of business workflow compositions increases the cost of security assurance. Blockchain technology (BCT) has thrown the light on the development of vital solutions to various BPM problems. BCT has to be integrated with other BPM system components that often involve IoT devices to implement specified functionalities related to the application. Currently, the potentials of using BCT have been explored although still at an early stage. In this paper, the states of the art are presented to identify emerging research topics, challenges, and promising applications in integrating BCT into the development of BPM.},
	number = {6},
	journal = {IEEE Transactions on Computational Social Systems},
	author = {Viriyasitavat, Wattana and Xu, Li Da and Bi, Zhuming and Pungpapong, Vitara},
	month = dec,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Computational Social Systems},
	keywords = {Blockchain, Internet of Things, Internet of Things (IoT), Industry 4.0, Business process management, business process management (BPM), cyber physical system, Scalability, service composition, service selection, service workflow, service-oriented architecture (SoA), smart contract, specification language, System performance},
	pages = {1420--1432},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\abrar\\Zotero\\storage\\66VU8BHA\\8744245.html:text/html},
}

@article{radziwon_smart_2014,
	series = {24th {DAAAM} {International} {Symposium} on {Intelligent} {Manufacturing} and {Automation}, 2013},
	title = {The {Smart} {Factory}: {Exploring} {Adaptive} and {Flexible} {Manufacturing} {Solutions}},
	volume = {69},
	issn = {1877-7058},
	shorttitle = {The {Smart} {Factory}},
	url = {https://www.sciencedirect.com/science/article/pii/S1877705814003543},
	doi = {10.1016/j.proeng.2014.03.108},
	abstract = {Nowadays we live in a world,whicha decade ago would only be described in the science fiction literature. More and more things become smart and both scientists and engineers strive for developing not only new and innovative devices, but also homes, factories, or even cities. Despite of continuous development, many of those concepts are still being just a vision of the future, which still needs a lot of effort to become true. This paper reviews the usage of adjective smartin respect to technology and with a special emphasis on the smart factory concept placement among contemporary studies. Due to a lack of a consensus of common understanding of this term,a unified definition is proposed. The conceptualization will not only refer to varioussmart factory visions reported in the literature, but also link the crucial characteristics of this emerging manufacturing concept to usual manufacturing practice.Subsequently, the authors discuss the challenges of the potential smart factory applications in SMEs, and also propose a future research outlook in order to further develop the smart factory concept.},
	urldate = {2023-08-26},
	journal = {Procedia Engineering},
	author = {Radziwon, Agnieszka and Bilberg, Arne and Bogers, Marcel and Madsen, Erik Skov},
	month = jan,
	year = {2014},
	keywords = {SMEs, adaptive, automation, flexible, Manufacturing of the Future, Real-Time Factory, Smart Factory, U-Factory},
	pages = {1184--1190},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\N5DIAFLC\\Radziwon et al. - 2014 - The Smart Factory Exploring Adaptive and Flexible.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\NU6CIQWX\\S1877705814003543.html:text/html},
}

@inproceedings{silva_requirements_2019,
	address = {New York, NY, USA},
	series = {{SBQS} '19},
	title = {A {Requirements} {Engineering} {Process} for {IoT} {Systems}},
	isbn = {978-1-4503-7282-4},
	url = {https://doi.org/10.1145/3364641.3364664},
	doi = {10.1145/3364641.3364664},
	abstract = {Nowadays there is a great interest in IoT systems and many applications take advantage of this technology. The elicitation, specification and management of requirements for IoT systems present new challenges to requirements engineering. There is a lack of systematic approaches to the development of IoT applications and more specifically for IoT-based requirements engineering. To fill this gap this paper presents the definition of a Requirements Engineering process for IoT systems. This process is a tailored and harmonized version of the following processes of ISO IEC/IEEE 12207:2017 aiming to accomplish the needs of IoT systems: Business or Mission Analysis process, Stakeholder Needs and Requirements Definition process and System/Software Requirements Definition process.},
	urldate = {2023-08-26},
	booktitle = {Proceedings of the {XVIII} {Brazilian} {Symposium} on {Software} {Quality}},
	publisher = {Association for Computing Machinery},
	author = {Silva, Danyllo and Gonçalves, Taisa Guidini and da Rocha, Ana Regina C.},
	month = oct,
	year = {2019},
	keywords = {Internet of Things, ISO/IEC/IEEE 12207, process, Requirements engineering},
	pages = {204--209},
}

@article{da_silva_conceptual_2019,
	title = {A conceptual model for quality of experience management to provide context-aware {eHealth} services},
	volume = {101},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X18314079},
	doi = {10.1016/j.future.2019.07.033},
	abstract = {The emergence of new Information and Communication Technologies (ICT), such as the Internet of Things (IoT) and the Software-Defined Networking (SDN) approach, together with Autonomic Network Management (ANM), have improved the provision of eHealth services. However, proposals must evolve in order to ensure that eHealth data be transported with quality assurance and delivered with quality information. This perspective substantiates our proposal and the respective validation of a Quality of Experience (QoE) Management model in a Future Internet Architecture. A knowledge representation model of QoE was incorporated into a service delivery platform oriented to user’s needs, thus measuring UX (User Experience). An experimental environment was configured to provide eHealth services from an AAL environment to a healthcare facility. Experiments were performed to verify whether the components of the proposed approach had better quality performance in service provision when compared to the components of the native approach of the SDN controller. Experimental results pointed out that, with a 95\% confidence interval, all eHealth services utilizing components of the proposed model showed superior quality when compared with those from the native approach.},
	urldate = {2023-08-26},
	journal = {Future Generation Computer Systems},
	author = {da Silva, Madalena Pereira and Gonçalves, Alexandre Leopoldo and Dantas, Mário Antônio Ribeiro},
	month = dec,
	year = {2019},
	keywords = {AAL, ICT, QoC, QoE, SDN, UX},
	pages = {1041--1061},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\U7BXFAZC\\S0167739X18314079.html:text/html},
}

@book{haddud_digitalizing_2019,
	title = {Digitalizing {Supply} {Chains}: {Potential} {Business} {Benefits} and {Challenges}},
	shorttitle = {Digitalizing {Supply} {Chains}},
	abstract = {Digital transformation continues to change business landscapes and it is important to understand aspects related to such transformation. We present a research examining potential benefits and challenges associated with digitalizing supply chains. We analyze survey data collected from 74 respondents examining predetermined 10 potential benefits and 10 potential challenges. We ranked these benefits and challenges to highlight their degree of importance. This paper can greatly benefit parties interested in understanding aspects related to supply chain digitalization and how to effectively manage digital transformation within the entire value chain. Such understanding helps managers identify key business areas digitalizing supply chains directly impacts.},
	author = {Haddud, Abu and Khare, Anshuman},
	month = nov,
	year = {2019},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\MH6P5HZK\\Haddud and Khare - 2019 - Digitalizing Supply Chains Potential Business Ben.pdf:application/pdf},
}

@article{haddud_digitalizing_2020,
	title = {Digitalizing supply chains potential benefits and impact on lean operations},
	volume = {11},
	issn = {2040-4166},
	url = {https://doi.org/10.1108/IJLSS-03-2019-0026},
	doi = {10.1108/IJLSS-03-2019-0026},
	abstract = {Purpose New technological trends continue to emerge, and businesses adopt them in different capacity in a pursuit of improving current ways of doing things and to gain competitive advantages over rivals. One of the key business functions that is impacted by the implementation of different disruptive technologies is the supply chain management. As a result, there is a continuous need to identify where digitalizing supply chains may provide businesses with benefits to capitalize such gains. This study aims to examine potential impacts of digitalizing supply chains on five selected lean operations practices through the identification of key areas and benefits under each of these practices. Design/methodology/approach Data were collected from 74 participants mainly from the academic community and who were university scholars through the use of an online survey. The used online survey consists of six main parts in total, but three were included in this paper and these were designed to gather data about participants’ general information, level of influence of seven technological trends on supply chain performance and management and potential impact of digitalizing supply chains on five lean operations practices. Findings The authors were able to confirm the significant impact of digitalizing supply chains on the five examined lean operations practices. Most of the examined potential impacts were found to improve certain areas that directly improve the practices of the explored five lean operations practices as well as the overall supply chain and business performance. They were also able to determine the level of influence of the seven examined enabling technologies on supply chain performance and management. Originality/value To the best of the authors’ knowledge, this study is the first of its kind. Although some literature explored different aspects related to the concept of Industry 4.0 and digitalizing supply chains, no study has specifically explored potential impacts of digitalizing supply chains on lean operations. The results from this study can be beneficial to academic scholars interested in the researched themes, business professionals specializing in supply chain management and lean operations, organizations within different industrial sectors particularly manufacturing where lean thinking is adopted and any other party interested in understanding more about the impact of digitalizing supply chain on lean operations and on an overall business performance.},
	number = {4},
	urldate = {2023-08-26},
	journal = {International Journal of Lean Six Sigma},
	author = {Haddud, Abubaker and Khare, Anshuman},
	month = jan,
	year = {2020},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Supply chain management, Adoption, Benefits, Technology, Digital supply chains, Lean operations},
	pages = {731--765},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\A8BVE97L\\html.html:text/html},
}

@article{wang_literature_2019,
	title = {A literature review of sustainable consumption and production: {A} comparative analysis in developed and developing economies},
	volume = {206},
	issn = {0959-6526},
	shorttitle = {A literature review of sustainable consumption and production},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652618329019},
	doi = {10.1016/j.jclepro.2018.09.172},
	abstract = {Sustainable consumption and production is identified as one of the essential requirements for sustainable development. Due to different economic conditions and socio-cultural factors, sustainable consumption and production requires a diverse focus in developing and developed economies. To date, few efforts have been made to systematically compare the status of sustainable consumption and production and its direction from the perspective of developing and developed economies. This paper provides a literature review of published articles in international scientific journals related to sustainable consumption and production between 1998 and 2018 inclusive. Three carefully designed questions are proposed and answered in this article, forming the basis for conducting a comprehensive comparative analysis of the differences and challenges in sustainable consumption and production practices within developed and developing economies. The findings strongly suggest that countries in Europe hold international leadership in sustainable consumption and production practices. This finding, alongside others, is analyzed and discussed in greater detail in this paper, resulting in the articulation of gaps and future research opportunities in the current body of the literature.},
	urldate = {2023-08-26},
	journal = {Journal of Cleaner Production},
	author = {Wang, Chao and Ghadimi, Pezhman and Lim, Ming K. and Tseng, Ming-Lang},
	month = jan,
	year = {2019},
	keywords = {Sustainable development, Developed economies, Developing economies, Sustainable consumption and production, Sustainable supply chain management},
	pages = {741--754},
	file = {Accepted Version:C\:\\Users\\abrar\\Zotero\\storage\\DLXTSLFG\\Wang et al. - 2019 - A literature review of sustainable consumption and.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\EI4BDB8K\\S0959652618329019.html:text/html},
}

@article{wang_evolution_2021,
	title = {The evolution of the {Internet} of {Things} ({IoT}) over the past 20 years},
	volume = {155},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835221000784},
	doi = {10.1016/j.cie.2021.107174},
	abstract = {To reveal the origin of the IoT, evaluate its mainstream research topics, and discuss the challenges facing the IoT in the future, this paper conducts a bibliometric study of the IoT from 2000 to 2019. First, this paper presents a basic bibliometric overview of the IoT. Second, co-citation, coupling and cluster analysis methods are used to analyse collaboration networks, and VOSviewer is used to visualize the networks. Third, biblioshiny is used to analyse the thematic trends of IoT. Finally, this paper discusses IoT challenges and provides some suggestions to address them. The limitations of this paper are also summarized. Research results show that, the mainstream studies in this field mainly focus on IoT security, wireless sensor networks, IoT management, IoT challenges and privacy. In addition, the thematic evolution of keywords shows that security and algorithm issues have become basic themes in the field of IoT research in recent years.},
	urldate = {2023-08-26},
	journal = {Computers \& Industrial Engineering},
	author = {Wang, Jianxin and Lim, Ming K. and Wang, Chao and Tseng, Ming-Lang},
	month = may,
	year = {2021},
	keywords = {Internet of things, Bibliometric, Biblioshiny, Network analysis, Thematic trends analysis, VOSviewer},
	pages = {107174},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\4832S3LQ\\Wang et al. - 2021 - The evolution of the Internet of Things (IoT) over.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\ELV7ENCB\\S0360835221000784.html:text/html},
}

@article{zhu_relationships_2004,
	title = {Relationships between operational practices and performance among early adopters of green supply chain management practices in {Chinese} manufacturing enterprises},
	volume = {22},
	copyright = {© 2004 APICS},
	issn = {1873-1317},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1016/j.jom.2004.01.005},
	doi = {10.1016/j.jom.2004.01.005},
	abstract = {Globalization results in both pressure and drivers for Chinese enterprises to improve their environmental performance. As a developing country, China has to balance economic and environmental performance. Green supply chain management (GSCM) is emerging to be an important approach for Chinese enterprises to improve performance, possibly on both these dimensions. Using empirical results from 186 respondents on GSCM practice in Chinese manufacturing enterprises, we examine the relationships between GSCM practice and environmental and economic performance. Using moderated hierarchical regression analysis, we evaluate the general relationships between specific GSCM practices and performance. We then investigate how two primary types of management operations philosophies, quality management and just-in-time (or lean) manufacturing principles, influence the relationship between GSCM practices and performance. Significant findings were determined for a number of relationships. Managerial implications are also identified.},
	language = {en},
	number = {3},
	urldate = {2023-08-31},
	journal = {Journal of Operations Management},
	author = {Zhu, Qinghua and Sarkis, Joseph},
	year = {2004},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1016/j.jom.2004.01.005},
	keywords = {Empirical study, Green supply chain management, International management, Moderated hierarchical regression},
	pages = {265--289},
}

@article{afzal_impact_2022,
	title = {The {Impact} of {Green} {Supply} {Chain} {Management} {Practices} on {Firm} {Performance}: {Evidence} from {Manufacturing} {Industry}},
	issn = {0972-1509},
	shorttitle = {The {Impact} of {Green} {Supply} {Chain} {Management} {Practices} on {Firm} {Performance}},
	url = {https://doi.org/10.1177/09721509221125576},
	doi = {10.1177/09721509221125576},
	abstract = {Global climate change, environmental pollution and depleting natural resources have necessitated major changes in the way businesses undertake procurement, manufacturing, operations and provision of goods and services to customers. Therefore, green supply chain management (GSCM) practices have caught the attention of researchers in many different countries. However, the adoption of GSCM practices and their influence on firm performance is still in its early stages. This study examines the influence of GSC determinants on firm performance in Pakistan’s manufacturing industry. Survey data was collected from 317 respondents working at various managerial levels in supply chains from manufacturing firms of Pakistan. Green supply chain management practices were assessed using five variables; ‘eco-design, green purchasing, green information systems, cooperation with customers and green manufacturing’. Multiple linear regression analysis indicated that green supply chain (GSC) initiatives had a significant impact on firm performance. Excluding green purchasing, the remaining four elements of GSC were shown to be statistically significant in predicting firm performance. This study highlights the importance of employing green strategies and practices in supply chains in order to improve overall organizational performance. In addition to practical implications for supply chain related environmental concerns, some directions for future research have also been suggested.},
	language = {en},
	urldate = {2023-08-31},
	journal = {Global Business Review},
	author = {Afzal, Nimra and Hanif, Aamer},
	month = nov,
	year = {2022},
	note = {Publisher: SAGE Publications India},
	pages = {09721509221125576},
}

@article{samad_green_2021,
	title = {Green {Supply} {Chain} {Management} practices and impact on firm performance: {The} moderating effect of collaborative capability},
	volume = {67},
	issn = {0160-791X},
	shorttitle = {Green {Supply} {Chain} {Management} practices and impact on firm performance},
	url = {https://www.sciencedirect.com/science/article/pii/S0160791X21002414},
	doi = {10.1016/j.techsoc.2021.101766},
	abstract = {The environmental effects of supply chain operations are under the significant influence of Green Supply Chain Management (GSCM), with a potential enhancement of organizational sustainability performance. Even though previous studies have pointed to the contribution of integration of various activities associated with GSCM, no investigations have been carried out for the possible interdependencies of these activities and their application effects. Consequently, this paper aims at investigating the associations of GSCM methods and performance of manufacturing firms using the Natural Resource-Based View (NRBV) as well as Institutional Theory. The collected data from manufacturing firms were analyzed using the partial least squares technique. Accordingly, mimetic, normative, and coercive pressures were found to affect GSCM positively and significantly. Moreover, the GSCM and the firms’ environmental, operational and economic performances were found to be positively and significantly associated. In addition, according to the moderation analysis, collaborative capabilities had significant moderating effects on the association of green chain management and environmental as well as economic performance. However, collaborative capabilities could not moderate the association of GSCM and operational performance. Managers, supply chain specialists and also policy makers would benefit from the findings of the present study along with the inspirations resulting from the contribution of specific drivers in implementing GSCM methods, while application of the mentioned methods could be effective in achieving the desired performance levels. Furthermore, industrial sectors are provided with managerial and theoretical insights by the results obtained in the present paper to concentrate on environmental awareness through the adoption of GSCM methods.},
	urldate = {2023-08-31},
	journal = {Technology in Society},
	author = {Samad, Sarminah and Nilashi, Mehrbakhsh and Almulihi, Ahmed and Alrizq, Mesfer and Alghamdi, Abdullah and Mohd, Saidatulakmal and Ahmadi, Hossein and Syed Azhar, Sharifah Nurlaili Farhana},
	month = nov,
	year = {2021},
	keywords = {Green supply chain management, Firm's performance, Manufacturer, Moderator},
	pages = {101766},
}

@article{shahriar_exploring_2016,
	title = {Exploring {Internet} of {Things} {Adoption} {Challenges} in {Manufacturing} {Firms}: {A} {Fuzzy} {Analytical} {Hierarchy} {Process} {Approach}},
	volume = {4},
	abstract = {Innovation is the key to gaining a sustainable edge in an increasingly competitive global manufacturing landscape. For Bangladesh’s manufacturing sector to survive and thrive in today’s cutthroat business environment, adopting transformative technologies like the Internet of Things (IoT) is not a luxury but a necessity. This article tackles the formidable task of identifying and comprehensively evaluating the impediments to IoT adoption within the Bangladeshi manufacturing industry. Drawing upon a synthesis of expert insights and a meticulously selected body of contemporary literature, we delve deep into the complex terrain of IoT adoption challenges. We employ a robust methodology combining the Delphi method with the Fuzzy Analytical Hierarchy Process to analyze and prioritize these challenges systematically. Through this approach, we harness the collective wisdom of experts in the field and then apply the power of fuzzy logic to navigate the inherent uncertainties. Our findings illuminate a clear path forward. They reveal that among the myriad barriers, "Lack of top management commitment to implementing new technology" (B10), "High initial implementation investment costs" (B9), and "Risks associated with switching to a new business model" (B7) loom most extensive, demanding immediate attention. These insights are not confined to the realm of academia but serve as a pragmatic guide for industrial managers. Armed with the knowledge gleaned from this study, managers can craft tailored strategies, set well-informed priorities, and embark on a transformational journey toward harnessing the vast potential of IoT in the Bangladeshi industrial sector. This article provides a comprehensive understanding of IoT adoption challenges and equips industry leaders with the tools necessary to navigate these challenges effectively. This strategic navigation, in turn, contributes significantly to enhancing the competitiveness and sustainability of the Bangladeshi manufacturing sector in the IoT era.},
	language = {en},
	author = {Shahriar, Hasan and Islam, Saiful and Jahin, Abrar and Ahmed, Istiyaque and Suzuki, Taro and Shin, Jungpil},
	year = {2016},
	file = {Shahriar et al. - 2016 - Exploring Internet of Things Adoption Challenges i.pdf:C\:\\Users\\abrar\\Zotero\\storage\\B79YJ6MA\\Shahriar et al. - 2016 - Exploring Internet of Things Adoption Challenges i.pdf:application/pdf},
}

@article{rupa_impact_2022,
	title = {Impact of {Green} {Supply} {Chain} {Management} ({GSCM}) on {Business} {Performance} and {Environmental} {Sustainability}: {Case} of a {Developing} {Country}},
	volume = {10},
	issn = {2278-5337},
	shorttitle = {Impact of {Green} {Supply} {Chain} {Management} ({GSCM}) on {Business} {Performance} and {Environmental} {Sustainability}},
	url = {https://doi.org/10.1177/2278533720983089},
	doi = {10.1177/2278533720983089},
	abstract = {In this Fourth Industrial Revolution (4IR), sustainable development for business firms depends on maintaining sustained performance and environmental sustainability to a great extent. The current study discovers the impact of green supply chain management (GSCM) practices on business performance and the environmental sustainability of a developing country, Bangladesh. Cost and profit are the two important indicators of business performance. On the other hand, environmental sustainability is expressed by waste disposal, resource consumption, and greenhouse gas emission. Primary data were collected through the distribution of web links and direct interaction with the participants of different firms practicing GSCM practices in Bangladesh. A structured questionnaire was used for data collection. Hypotheses were formulated and evaluated accordingly. This study found that the impact of implementation of GSCM practices differs with respect to cost, profit, waste disposal, resource consumption, and greenhouse gas emission. GSCM practices have a statistically significant impact on cost, waste disposal, resource consumption, and greenhouse gas emission. The impact of GSCM practices on profit was statistically insignificant. It was found that lack of IT implementation, high cost of waste disposal, uncertainty and competition in the market, resistance to change, and lack of top management support are the major barriers to implement GSCM practices in Bangladesh.},
	language = {en},
	number = {1},
	urldate = {2023-09-01},
	journal = {Business Perspectives and Research},
	author = {Rupa, Rasheda Akter and Saif, Abu Naser Mohammad},
	month = jan,
	year = {2022},
	note = {Publisher: SAGE Publications India},
	pages = {140--163},
	file = {SAGE PDF Full Text:C\:\\Users\\abrar\\Zotero\\storage\\LXH77YJ2\\Rupa and Saif - 2022 - Impact of Green Supply Chain Management (GSCM) on .pdf:application/pdf},
}

@article{pahlevi_integrated_2020,
	title = {The integrated model of green loyalty: {Evidence} from eco-friendly plastic products},
	volume = {257},
	issn = {0959-6526},
	shorttitle = {The integrated model of green loyalty},
	url = {https://www.sciencedirect.com/science/article/pii/S095965262030891X},
	doi = {10.1016/j.jclepro.2020.120844},
	abstract = {The rise of pollution due to massive use of plastic products has increased public awareness in environmental protection through the increased consumption of eco-friendly plastic products. However, as its cost of production is expensive, the consumption of eco-friendly plastic product is low. In this business environment, understanding and developing a strategy to create customer loyalty is a key factor to ensure business success. Driven by this research gap, this study is intended to gain a comprehensive understanding of loyalty formation towards eco-friendly plastic products by integrating the trust and perceived risk in the loyalty model. This study used data collected through the distribution of questionnaires to 400 consumers of eco-friendly plastic products in Bandung, Indonesia. This research used partial least squares structural equation modelling to examine the hypotheses proposed. The results note that the integration of green trust and green perceived risk in the Quality-Loyalty Model can increase the prediction of loyalty towards eco-friendly plastic products. Further, this research reveals that green perceived quality and green perceived value are the main drivers of loyalty towards eco-friendly plastic product. The identified relationships between the variables provide a guide for eco-friendly business players to enhance their innovative and competitive capabilities as well as encourage them to face the environmental challenges.},
	urldate = {2023-09-01},
	journal = {Journal of Cleaner Production},
	author = {Pahlevi, Mohamad Reza and Suhartanto, Dwi},
	month = jun,
	year = {2020},
	keywords = {Eco-friendly plastic, Green loyalty, Green perceived value, Green satisfaction, Green trust},
	pages = {120844},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\TBPRDDLK\\S095965262030891X.html:text/html},
}

@article{karaman_green_2020,
	title = {Green logistics performance and sustainability reporting practices of the logistics sector: {The} moderating effect of corporate governance},
	volume = {258},
	issn = {0959-6526},
	shorttitle = {Green logistics performance and sustainability reporting practices of the logistics sector},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652620307654},
	doi = {10.1016/j.jclepro.2020.120718},
	abstract = {Drawing on the signaling theory, this study investigates the association between green logistics performance and sustainability reporting. In addition to this direct link, whether corporate governance moderates this relation or not is tested. The analysis of data collected for 117 countries covers the period from 2007 to 2016. Primarily, the study provides robust evidence that green logistics performance has a significant and positive association with the existence and the number of sustainability reports within the logistics sector. This association is validated for the composite Logistics Performance Index (LPI) as well as all six individual logistics performance indicators. Furthermore, moderation analysis indicated that in weak corporate governance environments characterized by ineffective boards of directors, the logistics performance and sustainability reporting link is stronger. This means that sustainability reporting fills the gap arising from poor corporate governance. This study extends existing green supply chain management literature by testing, for the first time, the association between green logistics practices and sustainability reporting. It is hoped that it helps to align the logistics sector with more eco-friendly practices and alleviate growing concerns of environmental degradation it is assumed to cause. In the end, the study provides implications for sector representatives, supply-chain managers, and developing countries in particular. It suggests guidelines about how to improve each dimension of six LPI to contribute to the sustainable development of the sector. Moreover, as one of the dimensions of this study is sustainability reporting, communication of sustainable supply chain practices to customers and other stakeholders may help supply chain managers augment the competitive posture of companies in the market. The sector can benefit from the Global Reporting Initiative’s individual metrics including materials usage, energy efficiency, recycling, and waste management metrics in developing environmentally friendly supply chains. The findings are particularly relevant for developing countries which are quite low scorers in terms of LPI than developed countries. Engaging in green logistics practices and developing policies accordingly may help them attenuate growing international environmental concerns and overcome trade barriers in international trade. The highlighted dimensions of green logistics performance may foster the circular economy while promoting the overall economic development of the countries.},
	urldate = {2023-09-01},
	journal = {Journal of Cleaner Production},
	author = {Karaman, Abdullah S. and Kilic, Merve and Uyar, Ali},
	month = jun,
	year = {2020},
	keywords = {Global reporting initiative, Green logistics, Logistics performance index, Sustainability report},
	pages = {120718},
}

@article{laari_supply_2017,
	title = {Supply chain perspective on competitive strategies and green supply chain management strategies},
	volume = {141},
	issn = {0959-6526},
	url = {https://www.sciencedirect.com/science/article/pii/S095965261631455X},
	doi = {10.1016/j.jclepro.2016.09.114},
	abstract = {Due to strategic motivations and pressures from various stakeholders, firms are adopting green supply chain management (GSCM) practices to extend environmental sustainability objectives to suppliers. Although it seems that an increasing number of firms is seeing environmental sustainability as a source of competitive advantage, there is a large gap of research focusing explicitly on the connection between competitive strategy and GSCM. It is also necessary to examine GSCM practices in several operational contexts. This article refines the competitive strategy approach and examines external GSCM strategies along the tiers of supply chain from the perspective of logistics users and providers using a dataset of 128 manufacturing, 110 trading and 144 logistics firms operating in Finland. The results reveal a connection between competitive strategy and GSCM strategy. Marketing differentiators and firms pursuing hybrid strategies tend to use more advanced GSCM strategies to manage the environmental performance of their suppliers. For them, GSCM seems to be a way to differentiate products and services, and to minimise the risk of potential losses resulting from poor environmental performance by suppliers. The results highlight the need to understand the role of competitive strategy in GSCM adoption, both in academia and in business.},
	urldate = {2023-09-01},
	journal = {Journal of Cleaner Production},
	author = {Laari, Sini and Töyli, Juuso and Ojala, Lauri},
	month = jan,
	year = {2017},
	keywords = {Strategy, Green supply chain management, Buyer-supplier relationships},
	pages = {1303--1315},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\6RB4CQ26\\S095965261631455X.html:text/html},
}

@article{testa_shadows_2010,
	title = {Shadows and lights of {GSCM} ({Green} {Supply} {Chain} {Management}): determinants and effects of these practices based on a multi-national study},
	volume = {18},
	issn = {0959-6526},
	shorttitle = {Shadows and lights of {GSCM} ({Green} {Supply} {Chain} {Management})},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652610001058},
	doi = {10.1016/j.jclepro.2010.03.005},
	abstract = {Green Supply Chain Management (GSCM) is an increasingly widely-diffused practice among companies that are seeking to improve their environmental performance. The motivation for the introduction of GSCM may be ethical (e.g., reflecting the values of managers) and/or commercial (e.g., gaining a possible competitive advantage by signalling environmental concern). Drawing upon a database of over 4000 manufacturing facilities in seven OECD countries this paper assesses the determinants and motivations for the implementation of GSCM. We find that GSCM is strongly complementary with other advanced management practices, and that it contributes to improved environmental performance. The effects on commercial performance are more ambiguous.},
	number = {10},
	urldate = {2023-09-01},
	journal = {Journal of Cleaner Production},
	author = {Testa, Francesco and Iraldo, Fabio},
	month = jul,
	year = {2010},
	keywords = {Green supply chain management, Competitiveness, Environmental management system, Environmental performance},
	pages = {953--962},
	file = {Full Text:C\:\\Users\\abrar\\Zotero\\storage\\ZHJB6NGW\\Testa and Iraldo - 2010 - Shadows and lights of GSCM (Green Supply Chain Man.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\M2BFAZLR\\S0959652610001058.html:text/html},
}

@misc{noauthor_materials_nodate,
	title = {Materials {Ecology}: {An} {Industrial} {Perspective} {\textbar} {Science}},
	url = {https://www.science.org/doi/10.1126/science.1197478},
	urldate = {2023-09-01},
	file = {Materials Ecology\: An Industrial Perspective | Science:C\:\\Users\\abrar\\Zotero\\storage\\5IN2DE8M\\science.html:text/html},
}

@article{collier_materials_2010,
	title = {Materials {Ecology}: {An} {Industrial} {Perspective}},
	volume = {330},
	shorttitle = {Materials {Ecology}},
	url = {https://www.science.org/doi/10.1126/science.1197478},
	doi = {10.1126/science.1197478},
	number = {6006},
	urldate = {2023-09-01},
	journal = {Science},
	author = {Collier, Paul and Alles, Carina Maria},
	month = nov,
	year = {2010},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {919--920},
}

@article{caldas_materials_2015,
	title = {Materials {Management} {Practices} in the {Construction} {Industry}},
	volume = {20},
	url = {https://ascelibrary.org/doi/10.1061/%28ASCE%29SC.1943-5576.0000238},
	doi = {10.1061/(ASCE)SC.1943-5576.0000238},
	abstract = {AbstractMaterials management is an integrated process that consists of the people, organizations,
technology, and procedures used to effectively identify, quantify, acquire, expedite,
inspect, transport, receive, store, and preserve the materials, ...},
	language = {en},
	number = {3},
	urldate = {2023-09-01},
	journal = {Practice Periodical on Structural Design and Construction},
	author = {Caldas, Carlos H. and Menches, Cindy L. and Reyes, Pedro M. and Navarro, Laure and Vargas, Daniel M.},
	month = aug,
	year = {2015},
	note = {Publisher: American Society of Civil Engineers},
	pages = {04014039},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\CUQCH7MN\\Caldas et al. - 2015 - Materials Management Practices in the Construction.pdf:application/pdf},
}

@article{cai_promoting_2019,
	title = {Promoting sustainability of manufacturing industry through the lean energy-saving and emission-reduction strategy},
	volume = {665},
	issn = {0048-9697},
	url = {https://www.sciencedirect.com/science/article/pii/S0048969719305480},
	doi = {10.1016/j.scitotenv.2019.02.069},
	abstract = {The energy-saving and emission reduction (ESER) strategy is a crucial measure for promoting the sustainability of manufacturing industry in green transition. Analyzing current practices and limitations of the ESER in the manufacturing industry, this paper proposes a new concept entitled lean energy-saving and emission-reduction (LESER) and an approach to effectively improve the energy efficiency and reduce waste emissions. This paper illustrates the definition of the LESER and establishes an implementation framework for LESER to improve the manufacturing process. To quantify and evaluate performance of LESER, the state space model of the carbon footprint for energy consumption and waste discharge is established. A method for implementing the LESER strategy is constructed in the following steps: (i) clarification of the current situation; (ii) analysis of the root cause; (iii) improvement; (iv) evaluation of the carbon emissions; (v) sustaining and standardizing. Finally, the LESER strategy is applied to the Zcrubber Group Co. Ltd., which is characterized with high pollution, high energy consumption, and high emission in green transition. Results demonstrate practicability of the proposed strategy to offer an effective measure for promoting sustainability of manufacturing industry.},
	urldate = {2023-09-01},
	journal = {Science of The Total Environment},
	author = {Cai, Wei and Lai, Kee-hung and Liu, Conghu and Wei, Fangfang and Ma, Minda and Jia, Shun and Jiang, Zhigang and Lv, Li},
	month = may,
	year = {2019},
	keywords = {Sustainability, Carbon emission, Emission reduction, Energy saving, Lean production, Manufacturing industry},
	pages = {23--32},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\8HDDAI92\\S0048969719305480.html:text/html},
}

@article{quan_analysis_2020,
	title = {Analysis on the influencing factors of carbon emission in {China}'s logistics industry based on {LMDI} method},
	volume = {734},
	issn = {0048-9697},
	url = {https://www.sciencedirect.com/science/article/pii/S0048969720319860},
	doi = {10.1016/j.scitotenv.2020.138473},
	abstract = {Logistics industry, as one of the industries with high carbon emissions, has become the focus of all parties while developing rapidly. Based on panel data, the total carbon emissions of logistics industry in China from 2000 to 2016 were calculated by using IPCC method. On this basis, the LMDI decomposition model is used to decompose the influencing factors of carbon emission from five aspects: carbon emission coefficient, energy intensity, energy structure, economic level and population size. Finally, using MATLAB tools to analyze the data. Results show that economic growth is the main factor to promote carbon emissions in logistics industry, followed by the positive impact of population size and energy structure. The carbon factor effect is negligible, energy intensity is the main restraining factor. The effect of various factors on carbon emissions varies from time to time. Therefore, we should speed up the adjustment of energy structure, reduce the dependence on high‑carbon emissions such as coal, optimize transportation system and improve logistics efficiency; at the same time, strengthen the cooperation between the government and enterprises, formulate feasible policies and measures, and do a good job in top-level planning and design of logistics, make our logistics industry embark on the road of low-carbon development.},
	urldate = {2023-09-01},
	journal = {Science of The Total Environment},
	author = {Quan, Chunguang and Cheng, Xiaojuan and Yu, Shasha and Ye, Xin},
	month = sep,
	year = {2020},
	keywords = {Carbon emissions, Decomposition of LMDI factors, IPCC, Logistics industry},
	pages = {138473},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\TWP5LWJG\\S0048969720319860.html:text/html},
}

@article{roy_successful_1992,
	title = {Successful recycling through value-chain collaboration},
	volume = {25},
	issn = {0024-6301},
	url = {https://www.sciencedirect.com/science/article/pii/002463019290009Q},
	doi = {10.1016/0024-6301(92)90009-Q},
	abstract = {Greater responsibility for their products has led manufacturers to a broader concept of ‘product stewardship’. Since most firms are not themselves involved in all phases of the life of a product, co-operation among the various companies in the product's value (supply and disposal) chain becomes essential to develop a strategy for a ‘green’ product. A case study is described of bringing companies as well as Government together to address the issue of management of end-of-life electronic equipment waste. The success of the project provides pointers as to why and how collaboration among firms in management of the environmental impact of products is crucial, and can succeed. It indicates what role company managers can play in the achievement of corporate objectives.},
	number = {4},
	urldate = {2023-09-01},
	journal = {Long Range Planning},
	author = {Roy, R. and Whelan, R. C.},
	month = aug,
	year = {1992},
	pages = {62--71},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\VGZJ6FW5\\002463019290009Q.html:text/html},
}

@article{green_green_2012,
	title = {Green supply chain management practices: impact on performance},
	volume = {17},
	issn = {1359-8546},
	shorttitle = {Green supply chain management practices},
	url = {https://doi.org/10.1108/13598541211227126},
	doi = {10.1108/13598541211227126},
	abstract = {Purpose – The aim is to contribute significantly to the first wave of empirical investigations related to the impact of green supply chain management (GSCM) practices on performance. The paper also aims to theorize and empirically assess a comprehensive GSCM practices and performance model. The model incorporates green supply chain practices that link manufacturers with supply chain partners (both suppliers and customers) to support environmental sustainability throughout the supply chain. Design/methodology/approach – Data collected from 159 manufacturing managers were analyzed using a structural equation modeling methodology. Manufacturing managers provide data reflecting the degree to which their organizations work with suppliers and customers to improve environmental sustainability of the supply chain. Findings – Generally, the adoption of GSCM practices by manufacturing organizations leads to improved environmental performance and economic performance, which, in turn, positively impact operational performance. Operational performance enhances organizational performance. Research limitations/implications – As a first wave empirical investigation of the impact of GSCM practices on performance, the study is by necessity exploratory. Practical implications – Practitioners are provided with a framework for assessing the synergistic impact of GSCM practices on performance. Internal environmental management and green information systems are identified as necessary precursors to the implementation of green purchasing, cooperation with customers, eco‐design, and investment recovery. Originality/value – A comprehensive GSCM practices performance model is proposed and empirically assessed. The results of this investigation support the proposition that GSCM practices are both environmentally necessary and good business. A structured two‐wave approach to the implementation of GSCM practices is recommended.},
	number = {3},
	urldate = {2023-09-01},
	journal = {Supply Chain Management: An International Journal},
	author = {Green, Kenneth W. and Zelbst, Pamela J. and Meacham, Jeramy and Bhadauria, Vikram S.},
	month = jan,
	year = {2012},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Green supply chain management, Environmental performance, Economic performance, Green information systems, Operational performance, Organizational performance},
	pages = {290--305},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\IMM2RQSW\\html.html:text/html},
}

@article{choi_assessing_2017,
	title = {Assessing the impact of green supply chain practices on firm performance in the {Korean} manufacturing industry},
	volume = {20},
	issn = {1367-5567},
	url = {https://doi.org/10.1080/13675567.2016.1160041},
	doi = {10.1080/13675567.2016.1160041},
	abstract = {As a growing number of customers tend to view corporate social responsibility (CSR) as a key purchase decision criterion, demands for CSR including environmental sustainability have accelerated in today's business world. To meet such demands, many firms consider embracing environment-friendly business practices. However, many firms are still hesitant to implement those practices due to sceptical views about their real managerial benefits. Although the previous literature confirms the positive link between a firm's commitment to environmental sustainability and its performance, the varying degree of impact of different kinds of environment-friendly supply chain practices on the firm's operational performance is still unknown. To fill the void left by prior research, this paper aims to classify various types of green supply chain management (GSCM) practices and then assess the impact of each of these distinct types on the firm's operational performances (especially manufacturing and marketing performance). Also, this paper examines how the firm's organisational profiles such as firm size affect the particular firm's choice of GSCM practices. Our experimental results reveal that the chosen type of GSCM practices influences the firm's performance differently.},
	number = {2},
	urldate = {2023-09-01},
	journal = {International Journal of Logistics Research and Applications},
	author = {Choi, Seok-Beom and Min, Hokey and Joo, Hye-Young and Choi, Han-Byul},
	month = mar,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/13675567.2016.1160041},
	keywords = {Green supply chain management, firm performance, Korean manufacturing firms, multivariate analysis, practice types},
	pages = {129--145},
}

@article{ahmed_analyzing_2020,
	title = {Analyzing the impact of environmental collaboration among supply chain stakeholders on a firm’s sustainable performance},
	volume = {13},
	issn = {1936-9743},
	url = {https://doi.org/10.1007/s12063-020-00152-1},
	doi = {10.1007/s12063-020-00152-1},
	abstract = {In the era of industrialization, environmentalists are more concerned with the environment and so are continuously interested in investigating organizational factors that can facilitate the transition towards sustainability. This research systematically investigates the impact of the supply chain partner’s collaborative approach towards green practices on a firm’s sustainability performance. Stakeholder and coordination theories are used to underpin the study. A structural equation modeling technique is adopted to analyze data collected from 126 green supply chain professionals working at various manufacturing firms operating in Pakistan using a survey questionnaire. The results indicate significant and positive impacts of institution pressure and customer monitoring on the adoption of green supply chain management (GSCM) practices by organizations. This study also explains that organizational GSCM practices, external GSCM practices and performance measures have positive and significant relationships. These findings reveal that it is important for managers to address external GSCM pressures by adopting green practices and being a focal firm should undertake GSCM initiatives in collaboration with their suppliers and customers to achieve a holistic impact which ultimately leads to betterment in overall sustainability performance.},
	language = {en},
	number = {1},
	urldate = {2023-09-01},
	journal = {Operations Management Research},
	author = {Ahmed, Waqar and Ashraf, Muhammad Saeed and Khan, Sharfuddin Ahmed and Kusi-Sarpong, Simonov and Arhin, Francis Kow and Kusi-Sarpong, Horsten and Najmi, Arsalan},
	month = jun,
	year = {2020},
	keywords = {Environmental performance, Organizational performance, Coordination theory, Customer collaboration, Green supply chain, Stakeholder theory, Supplier collaboration},
	pages = {4--21},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\CLC63CU6\\Ahmed et al. - 2020 - Analyzing the impact of environmental collaboratio.pdf:application/pdf},
}

@misc{noauthor_inderscience_nodate-1,
	title = {Inderscience {Publishers} - linking academia, business and industry through research},
	url = {https://www.inderscience.com/offers.php?id=10017903},
	urldate = {2023-09-01},
	file = {Inderscience Publishers - linking academia, business and industry through research:C\:\\Users\\abrar\\Zotero\\storage\\HLEAQUPR\\offers.html:text/html},
}

@article{panigrahi_analysis_2018,
	title = {Analysis of interactions among the enablers of green supply chain management using interpretive structural modelling: an {Indian} perspective},
	volume = {1},
	shorttitle = {Analysis of interactions among the enablers of green supply chain management using interpretive structural modelling},
	url = {https://consensus.app/details/this-study-suggests-enablers-adoption-gscm-manufacturing-panigrahi/92829a723a3b5d208908fb7f9129fd95/},
	doi = {10.1504/IJCM.2018.10017903},
	abstract = {The demand of products having minimal environmental impact is soaring high at present. This is because of growing awareness regarding the environmental and global warming concerns. Hence, the industries will now be answerable to their customers about how green their manufacturing processes and supply chains are. It is established that an improved environmental performance leads to financial gains. It is important to analyse the factors that motivates the companies to implement the green way of manufacturing. This study identifies 12 key enablers from the literature that foster the implementation of green supply chain management (GSCM). Further, a quantitative modelling approach, i.e., interpretive structural modelling is applied to analyse the interactions among these enablers. A conceptual framework for the evaluation of the enablers has also been presented. In order to validate the model developed, a case study involving an aluminium manufacturing firm from Eastern India is considered for the study. This study suggests that the major enablers to the adoption of GSCM in manufacturing companies are green methods to reduce GHG emissions, use of eco-friendly raw materials, recycling, recovering end of life products and judicious selection of environmentally responsible or green suppliers.},
	urldate = {2023-09-01},
	journal = {International Journal of Computer Mathematics},
	author = {Panigrahi, S. and Sahu, Bandita},
	year = {2018},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\HH7EXF3Z\\92829a723a3b5d208908fb7f9129fd95.html:text/html},
}

@article{yildiz_cankaya_effects_2018,
	title = {Effects of green supply chain management practices on sustainability performance},
	volume = {30},
	issn = {1741-038X},
	url = {https://doi.org/10.1108/JMTM-03-2018-0099},
	doi = {10.1108/JMTM-03-2018-0099},
	abstract = {Purpose The purpose of this paper is to explore the impact of eight dimensions of green supply chain management (GSCM) on economic, environmental and social performance, which are the three dimensions of corporate sustainability. The eight dimensions covered in this study are: green purchasing, green manufacturing, green distribution, green packaging, green marketing, environmental education, internal environmental management and investment recovery. Design/methodology/approach The relationships between dimensions of GSCM and sustainability performance are tested by using a plant-level survey. A proposed research model and hypotheses are tested by using cross-sectional face-to-face and e-mail survey data collected from manufacturing firms in Turkey. Structural equation modeling is used to test the proposed hypotheses. Findings Except for green purchasing, all GSCM dimensions are found to be related with at least one of the performance dimensions. Practical implications The results are important in highlighting the importance of GSCM in improving sustainability performance. Originality/value This paper enhances the understanding of the relationship between different dimensions of GSCM and the three sustainability performance factors. While there are very few studies examining the relationship between GSCM and corporate sustainability, this study is important in terms of exploring the effects of dimensions of GSCM applications on economic, environmental and social performance one by one, by examining these applications in the form of eight dimensions.},
	number = {1},
	urldate = {2023-09-01},
	journal = {Journal of Manufacturing Technology Management},
	author = {Yildiz Çankaya, Sibel and Sezen, Bulent},
	month = jan,
	year = {2018},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Supply chain management, Green manufacturing, Sustainable production},
	pages = {98--121},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\NM59WNH7\\html.html:text/html},
}

@article{yildiz_cankaya_effects_2018-1,
	title = {Effects of green supply chain management practices on sustainability performance},
	volume = {30},
	issn = {1741-038X},
	url = {https://doi.org/10.1108/JMTM-03-2018-0099},
	doi = {10.1108/JMTM-03-2018-0099},
	abstract = {Purpose The purpose of this paper is to explore the impact of eight dimensions of green supply chain management (GSCM) on economic, environmental and social performance, which are the three dimensions of corporate sustainability. The eight dimensions covered in this study are: green purchasing, green manufacturing, green distribution, green packaging, green marketing, environmental education, internal environmental management and investment recovery. Design/methodology/approach The relationships between dimensions of GSCM and sustainability performance are tested by using a plant-level survey. A proposed research model and hypotheses are tested by using cross-sectional face-to-face and e-mail survey data collected from manufacturing firms in Turkey. Structural equation modeling is used to test the proposed hypotheses. Findings Except for green purchasing, all GSCM dimensions are found to be related with at least one of the performance dimensions. Practical implications The results are important in highlighting the importance of GSCM in improving sustainability performance. Originality/value This paper enhances the understanding of the relationship between different dimensions of GSCM and the three sustainability performance factors. While there are very few studies examining the relationship between GSCM and corporate sustainability, this study is important in terms of exploring the effects of dimensions of GSCM applications on economic, environmental and social performance one by one, by examining these applications in the form of eight dimensions.},
	number = {1},
	urldate = {2023-09-01},
	journal = {Journal of Manufacturing Technology Management},
	author = {Yildiz Çankaya, Sibel and Sezen, Bulent},
	month = jan,
	year = {2018},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Supply chain management, Green manufacturing, Sustainable production},
	pages = {98--121},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\QSMXF9YI\\html.html:text/html},
}

@article{ahmed_analyzing_2020-1,
	title = {Analyzing the impact of environmental collaboration among supply chain stakeholders on a firm’s sustainable performance},
	volume = {13},
	issn = {1936-9743},
	url = {https://doi.org/10.1007/s12063-020-00152-1},
	doi = {10.1007/s12063-020-00152-1},
	abstract = {In the era of industrialization, environmentalists are more concerned with the environment and so are continuously interested in investigating organizational factors that can facilitate the transition towards sustainability. This research systematically investigates the impact of the supply chain partner’s collaborative approach towards green practices on a firm’s sustainability performance. Stakeholder and coordination theories are used to underpin the study. A structural equation modeling technique is adopted to analyze data collected from 126 green supply chain professionals working at various manufacturing firms operating in Pakistan using a survey questionnaire. The results indicate significant and positive impacts of institution pressure and customer monitoring on the adoption of green supply chain management (GSCM) practices by organizations. This study also explains that organizational GSCM practices, external GSCM practices and performance measures have positive and significant relationships. These findings reveal that it is important for managers to address external GSCM pressures by adopting green practices and being a focal firm should undertake GSCM initiatives in collaboration with their suppliers and customers to achieve a holistic impact which ultimately leads to betterment in overall sustainability performance.},
	language = {en},
	number = {1},
	urldate = {2023-09-01},
	journal = {Operations Management Research},
	author = {Ahmed, Waqar and Ashraf, Muhammad Saeed and Khan, Sharfuddin Ahmed and Kusi-Sarpong, Simonov and Arhin, Francis Kow and Kusi-Sarpong, Horsten and Najmi, Arsalan},
	month = jun,
	year = {2020},
	keywords = {Environmental performance, Organizational performance, Coordination theory, Customer collaboration, Green supply chain, Stakeholder theory, Supplier collaboration},
	pages = {4--21},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\2VLKB8AZ\\Ahmed et al. - 2020 - Analyzing the impact of environmental collaboratio.pdf:application/pdf},
}

@article{ali_green_2017,
	title = {Green supply chain management – food for thought?},
	volume = {20},
	issn = {1367-5567},
	url = {https://doi.org/10.1080/13675567.2016.1226788},
	doi = {10.1080/13675567.2016.1226788},
	abstract = {This paper investigates the impact of green supply chain management (GSCM) practices on the performance of UK food retail small and medium-sized enterprises (SMEs). A quantitative approach using a non-probability sampling of 84 participants was employed. Based on the literature review, five hypotheses were developed and tested using the partial least square-structural equation modeling (SEM-Smart PLS 2.03) approach. The reviewed literature revealed that key internal drivers (ID) and external pressures (EP) stimulate organizations to initiate GSCM practices in UK food retail SMEs. Though empirical findings strongly supported the statement that ID influence GSCM practices, they did not show a significant relationship between EP and GSCM practices. Literature also suggests that practicing GSCM can help improve the efficiency, brand image (BI) and profitability, and thus improve the overall firm performance which is also empirically proved. This study helps enrich existing theories on SCM and organizational performance. As to practical impact, this study should facilitate SMEs in GSCM practices and thus help green the economy. While the findings of this study have limited generalisability as the data were collected from UK SMEs only and the sample size was comparatively small, this research establishes a foundation for further study in this domain.},
	number = {1},
	urldate = {2023-09-01},
	journal = {International Journal of Logistics Research and Applications},
	author = {Ali, Abdul and Bentley, Yongmei and Cao, Guangming and Habib, Farooq},
	month = jan,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/13675567.2016.1226788},
	keywords = {performance, Green supply chain management, food retail, small and medium-sized enterprise, sustainable supply chain, UK},
	pages = {22--38},
	file = {Accepted Version:C\:\\Users\\abrar\\Zotero\\storage\\3TF8MZ6J\\Ali et al. - 2017 - Green supply chain management – food for thought.pdf:application/pdf},
}

@article{guerrero_production_2011,
	title = {Production system design to achieve energy savings in an automotive paint shop},
	volume = {49},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2010.535042},
	doi = {10.1080/00207543.2010.535042},
	abstract = {Vehicle painting typically consumes the largest amount of energy in an automotive assembly plant. Effective reduction of energy usage in paint shops will lead to significant savings. Substantial effort has been devoted to reducing energy usage in paint shops through renovating the painting process and equipment. In this paper, we introduce a case study at an automotive paint shop to show that the energy consumption can be reduced significantly through production system design. Specifically, by selecting the appropriate repair capacity, the number of repainted jobs can be reduced, and less material and energy will be consumed. In addition, less atmospheric emissions would be generated during the painting process. Such a technique does not need to invent new chemicals, new painting processes or new control systems in painting booths and ovens. It provides an alternative way for energy and emission reduction to achieve energy-efficient and environmentally friendly manufacturing.},
	number = {22},
	urldate = {2023-09-06},
	journal = {International Journal of Production Research},
	author = {Guerrero, Claudia   Arenas and Wang, Junwen and Li, Jingshan and Arinez, Jorge and Biller, Stephan and Huang, Ningjian and Xiao, Guoxian},
	month = nov,
	year = {2011},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2010.535042},
	keywords = {energy management, environmental management, manufacturing systems, production management},
	pages = {6769--6785},
}

@article{buede_rank_1995,
	title = {Rank disagreement: {A} comparison of multi-criteria methodologies},
	volume = {4},
	copyright = {Copyright © 1995 John Wiley \& Sons, Ltd.},
	issn = {1099-1360},
	shorttitle = {Rank disagreement},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mcda.4020040102},
	doi = {10.1002/mcda.4020040102},
	abstract = {A number of multi-criteria decision support techniques have emerged in recent years that use varying computational approaches to arrive at the most desirable solution and thereby ‘recommend’ a course of action. Decision makers who use the results of this analytic work should be assured that the computational schemes used by their supporting analysts or decision support software produce the appropriate solutions. We conducted a series of simulation experiments that compared the top-ranked options resulting from the computational algorithms that support Multi-Attribute Value Theory (MAVT) and three methods that are reported in the literature that allow rank reversals, the change in rank order of two options when an unrelated option is added or deleted from the analysis: the Analytical Hierarchy Process (AHP), Percentaging and the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS). We also included a Fuzzy algorithm proposed by Yager to gauge its consistency with the other algorithms, even though it is not subject to rank reversals. These experiments demonstrated that the MAVT and AHP techniques, when provided with the same decision outcome data, very often identify the same alternative as ‘best’. The other techniques are noticeably less consistent with MAVT, the Fuzzy algorithm being the least consistent. The situations under which the most frequent and significant differences occurred were dependent upon the method. The results of our experiments indicate that other issues (e.g. the processes used for problem structuring and the elicitation of value weights) are likely to be of greater significance to problem outcome (based on our experience) than the choice between the computational algorithms of MAVT and AHP. The results cause us to be concerned about the use of the other methods.},
	language = {en},
	number = {1},
	urldate = {2023-09-06},
	journal = {Journal of Multi-Criteria Decision Analysis},
	author = {Buede, Dennis M. and Maxwell, Daniel T.},
	year = {1995},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mcda.4020040102},
	keywords = {Decision processes, Multi-criteria decision making, Rank reversal},
	pages = {1--21},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\BV46J3JK\\mcda.html:text/html},
}

@article{keskin_using_2015,
	title = {Using integrated fuzzy {DEMA}℡ and fuzzy {C}: means algorithm for supplier evaluation and selection},
	volume = {53},
	issn = {0020-7543},
	shorttitle = {Using integrated fuzzy {DEMA}℡ and fuzzy {C}},
	url = {https://doi.org/10.1080/00207543.2014.980461},
	doi = {10.1080/00207543.2014.980461},
	abstract = {Decision-making techniques are used to help evaluate the current suppliers’ aim at classifying performance of individual suppliers against desired levels of performance, so as to design suitable plans to increase the performance and capabilities of suppliers. In this study, an integrated model is introduced and proposed for increasing the supplier selection and evaluation quality. The methodology is composed of two steps. The first stage is fuzzy decision-making trial and evaluation laboratory method in which the interactions between the evaluation criteria and the criteria weight have been computed. At the second stage, performances of suppliers are assessed using both the criteria weights obtained at the first stage and fuzzy c-means clustering algorithm by classifying the vendors according to their performances. Obtained results show that the proposed model is very well suited as a decision-making tool for supplier selection decisions.},
	number = {12},
	urldate = {2023-09-06},
	journal = {International Journal of Production Research},
	author = {Keskin, Gülşen Aydın},
	month = jun,
	year = {2015},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2014.980461},
	keywords = {fuzzy c-means clustering, fuzzy DEMATEL, multi-criteria decision-making, supplier evaluation and selection},
	pages = {3586--3602},
}

@article{vanalle_green_2017,
	title = {Green supply chain management: {An} investigation of pressures, practices, and performance within the {Brazilian} automotive supply chain},
	volume = {151},
	issn = {0959-6526},
	shorttitle = {Green supply chain management},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652617305012},
	doi = {10.1016/j.jclepro.2017.03.066},
	abstract = {Over the past few decades, companies have shown growing concerns in relation to the environmental impact of their manufacturing activities. Green supply chain management (GSCM) has been considered by the manufacturers as a feasible option to reduce the environmental impact of operations while simultaneously improving their operational performance. The literature suggests that further research on institutional pressures, performance, and environmental practices are needed, especially in the case of developing countries. The present paper explores the GSCM pressures, practices, and performance observed in suppliers of a Brazilian automotive supply chain. The data were treated using partial least squares structural equation modeling (PLS-SEM) provided by SmartPLS software. The results show that the economic and environmental performance of the studied supply chain is positively related to the adoption of GSCM practices. In addition, the present research also identified the institutional pressures that influence this supply chain to pursue green supply chain management practices. The results of this study provide managerial and theoretical approaches for different industries in Brazil to focus on environmental awareness by adopting GSCM practices. In addition, this study helps increase confidence among managers and policy makers of Brazilian companies in the adoption of GSCM practices to improve firm performance.},
	urldate = {2023-09-06},
	journal = {Journal of Cleaner Production},
	author = {Vanalle, Rosangela Maria and Ganga, Gilberto Miller Devós and Godinho Filho, Moacir and Lucato, Wagner Cezar},
	month = may,
	year = {2017},
	keywords = {Performance, Green supply chain management, Automotive industry, Brazil, Institutional pressures},
	pages = {250--259},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\QHYGM9F2\\S0959652617305012.html:text/html},
}

@article{agarwal_mediation_2018,
	title = {A mediation model of green supply chain management adoption: {The} role of internal impetus},
	volume = {205},
	issn = {0925-5273},
	shorttitle = {A mediation model of green supply chain management adoption},
	url = {https://www.sciencedirect.com/science/article/pii/S0925527318303815},
	doi = {10.1016/j.ijpe.2018.09.011},
	abstract = {Previous research provides evidence that the adoption of Green Supply Chain Management (GSCM) is associated with improved organizational performance, suggesting that GSCM may help companies align environmental and economic goals. Therefore, it becomes important to understand the factors that encourage GSCM adoption. In addition to institutional drivers such as regulations, markets, and suppliers, we suggest that internal impetus, denoting an organization's inner motivation and managerial commitment toward environmental sustainability, is a key driver of GSCM adoption. Combining institutional and self-determination theories, we argue that markets and suppliers as non-coercive institutional drivers stimulate internal impetus while regulations, representing a coercive pressure, do not play this role. This leads us to propose a model of GSCM adoption in which pressures from markets and suppliers are mediated by internal impetus, while regulatory pressures impact adoption directly. We test this model with a sample of 60 manufacturing companies in the U.S. Midwest region using the Partial Least Squares (PLS) technique. Our findings suggest that: (1) suppliers impact GSCM adoption both directly and through the mediating effect of internal impetus; (2) customers and other market pressures on GSCM adoption are fully mediated by internal impetus; (3) regulatory pressures have no impact on GSCM adoption for the companies in our sample. Our results highlight the importance of managerial commitment and the key role of suppliers in successful GSCM adoption. We discuss the implications of these findings and provide recommendations for managers.},
	urldate = {2023-09-06},
	journal = {International Journal of Production Economics},
	author = {Agarwal, Atul and Giraud-Carrier, François C. and Li, Yuan},
	month = nov,
	year = {2018},
	keywords = {Bootstrapping, External drivers, Green supply chain management (GSCM) adoption, Internal drivers, Mediation, Partial least squares (PLS)},
	pages = {342--358},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\YQS3K7GP\\S0925527318303815.html:text/html},
}

@article{agarwal_mediation_2018-1,
	title = {A mediation model of green supply chain management adoption: {The} role of internal impetus},
	volume = {205},
	issn = {0925-5273},
	shorttitle = {A mediation model of green supply chain management adoption},
	url = {https://www.sciencedirect.com/science/article/pii/S0925527318303815},
	doi = {10.1016/j.ijpe.2018.09.011},
	abstract = {Previous research provides evidence that the adoption of Green Supply Chain Management (GSCM) is associated with improved organizational performance, suggesting that GSCM may help companies align environmental and economic goals. Therefore, it becomes important to understand the factors that encourage GSCM adoption. In addition to institutional drivers such as regulations, markets, and suppliers, we suggest that internal impetus, denoting an organization's inner motivation and managerial commitment toward environmental sustainability, is a key driver of GSCM adoption. Combining institutional and self-determination theories, we argue that markets and suppliers as non-coercive institutional drivers stimulate internal impetus while regulations, representing a coercive pressure, do not play this role. This leads us to propose a model of GSCM adoption in which pressures from markets and suppliers are mediated by internal impetus, while regulatory pressures impact adoption directly. We test this model with a sample of 60 manufacturing companies in the U.S. Midwest region using the Partial Least Squares (PLS) technique. Our findings suggest that: (1) suppliers impact GSCM adoption both directly and through the mediating effect of internal impetus; (2) customers and other market pressures on GSCM adoption are fully mediated by internal impetus; (3) regulatory pressures have no impact on GSCM adoption for the companies in our sample. Our results highlight the importance of managerial commitment and the key role of suppliers in successful GSCM adoption. We discuss the implications of these findings and provide recommendations for managers.},
	urldate = {2023-09-06},
	journal = {International Journal of Production Economics},
	author = {Agarwal, Atul and Giraud-Carrier, François C. and Li, Yuan},
	month = nov,
	year = {2018},
	keywords = {Bootstrapping, External drivers, Green supply chain management (GSCM) adoption, Internal drivers, Mediation, Partial least squares (PLS)},
	pages = {342--358},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\MRFHBMRB\\S0925527318303815.html:text/html},
}

@article{li_performance_2016,
	title = {Performance evaluation of eco-industrial thermal power plants by using fuzzy {GRA}-{VIKOR} and combination weighting techniques},
	volume = {135},
	issn = {0959-6526},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652616307909},
	doi = {10.1016/j.jclepro.2016.06.113},
	abstract = {More and more eco-industrial thermal power plants are established in China to promote the clean and sustainable production of coal resources. This paper presents an effective approach for evaluating performance of emerging eco-industrial plants in China. In general, performance evaluation is a complex multi-criteria decision-making problem, in which multiple requirements and fuzzy conditions have to be taken into consideration simultaneously. By combining concepts of the Vlsekriterijumska Optimizacijia I Kompromisno Resenje and grey relational analysis, a new fuzzy multi-criteria decision-making model is proposed to deal with the performance evaluation of eco-industrial thermal power plants. This model is solved by an effective algorithm, which incorporates the decision-maker's attitude on performance ratings of each criterion, and integrates the objective information as well as subjective opinions in criteria weights determination based on fuzzy Analytic Hierarchy Process and Shannon entropy. Finally, the applicability of proposed framework is demonstrated by an empirical study of eco-industrial thermal power plants in Shanxi province. The results show that A3 achieves the best performance, criteria affiliated with waste recycle and pollutant emission obtain much more attentions than that of other criteria. Moreover, the sensitivity analysis indicates the robustness and effectiveness of proposed model and evaluation results. The study innovates the weights determination and aggregating function for conventional fuzzy Vlsekriterijumska Optimizacijia I Kompromisno Resenje, which provides an effective means for performance evaluation of eco-industrial thermal power plants involving subjective assessments of qualitative attributes in a fuzzy environment.},
	urldate = {2023-09-06},
	journal = {Journal of Cleaner Production},
	author = {Li, Nana and Zhao, Huiru},
	month = nov,
	year = {2016},
	keywords = {Sensitivity analysis, Combination weight, Eco-industrial thermal power plant, Fuzzy VIKOR, GRA, Performance evaluation},
	pages = {169--183},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\DS8S6WSG\\S0959652616307909.html:text/html},
}

@misc{noauthor_green_nodate,
	title = {Green supply chain management and financial performance: {The} mediating roles of operational and environmental performance - {Feng} - 2018 - {Business} {Strategy} and the {Environment} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/bse.2033},
	urldate = {2023-09-06},
	file = {Green supply chain management and financial performance\: The mediating roles of operational and environmental performance - Feng - 2018 - Business Strategy and the Environment - Wiley Online Library:C\:\\Users\\abrar\\Zotero\\storage\\KBKNGYL3\\bse.html:text/html},
}

@article{feng_green_2018,
	title = {Green supply chain management and financial performance: {The} mediating roles of operational and environmental performance},
	volume = {27},
	copyright = {Copyright © 2018 John Wiley \& Sons, Ltd and ERP Environment},
	issn = {1099-0836},
	shorttitle = {Green supply chain management and financial performance},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bse.2033},
	doi = {10.1002/bse.2033},
	abstract = {This study investigates the mediating effects of environmental and operational performance on the relationship between green supply chain management (GSCM) and financial performance. The proposed relationships are analyzed using survey data from a sample of 126 automobile manufacturers in China. The results suggest that GSCM as an integral supply chain strategy is significantly and positively associated with both environmental and operational performance, which then indirectly leads to improved financial performance. The results indicate the possible complementarity effects between various internal and external GSCM practices.},
	language = {en},
	number = {7},
	urldate = {2023-09-06},
	journal = {Business Strategy and the Environment},
	author = {Feng, Mengying and Yu, Wantao and Wang, Xingyu and Wong, Chee Yew and Xu, Maozeng and Xiao, Zhi},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bse.2033},
	keywords = {China, environmental performance, financial performance, green supply chain management, operational performance},
	pages = {811--824},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\ZRRN67G5\\Feng et al. - 2018 - Green supply chain management and financial perfor.pdf:application/pdf;Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\N8PNECKE\\bse.html:text/html},
}

@article{green_green_2012-1,
	title = {Green supply chain management practices: impact on performance},
	volume = {17},
	issn = {1359-8546},
	shorttitle = {Green supply chain management practices},
	url = {https://doi.org/10.1108/13598541211227126},
	doi = {10.1108/13598541211227126},
	abstract = {Purpose – The aim is to contribute significantly to the first wave of empirical investigations related to the impact of green supply chain management (GSCM) practices on performance. The paper also aims to theorize and empirically assess a comprehensive GSCM practices and performance model. The model incorporates green supply chain practices that link manufacturers with supply chain partners (both suppliers and customers) to support environmental sustainability throughout the supply chain. Design/methodology/approach – Data collected from 159 manufacturing managers were analyzed using a structural equation modeling methodology. Manufacturing managers provide data reflecting the degree to which their organizations work with suppliers and customers to improve environmental sustainability of the supply chain. Findings – Generally, the adoption of GSCM practices by manufacturing organizations leads to improved environmental performance and economic performance, which, in turn, positively impact operational performance. Operational performance enhances organizational performance. Research limitations/implications – As a first wave empirical investigation of the impact of GSCM practices on performance, the study is by necessity exploratory. Practical implications – Practitioners are provided with a framework for assessing the synergistic impact of GSCM practices on performance. Internal environmental management and green information systems are identified as necessary precursors to the implementation of green purchasing, cooperation with customers, eco‐design, and investment recovery. Originality/value – A comprehensive GSCM practices performance model is proposed and empirically assessed. The results of this investigation support the proposition that GSCM practices are both environmentally necessary and good business. A structured two‐wave approach to the implementation of GSCM practices is recommended.},
	number = {3},
	urldate = {2023-09-06},
	journal = {Supply Chain Management: An International Journal},
	author = {Green, Kenneth W. and Zelbst, Pamela J. and Meacham, Jeramy and Bhadauria, Vikram S.},
	month = jan,
	year = {2012},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Green supply chain management, Environmental performance, Economic performance, Green information systems, Operational performance, Organizational performance},
	pages = {290--305},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\5FL4PRE5\\html.html:text/html},
}

@article{balasubramanian_green_2017,
	title = {Green supply chain management: an empirical investigation on the construction sector},
	volume = {22},
	issn = {1359-8546},
	shorttitle = {Green supply chain management},
	url = {https://doi.org/10.1108/SCM-07-2016-0227},
	doi = {10.1108/SCM-07-2016-0227},
	abstract = {Purpose Curtailing the adverse environmental impacts of the construction sector is one the major challenges of the twenty-first century. However, despite the significance of this problem, the limited efforts so far to tackle the negative impacts associated with this particular sector have been largely fragmented and disjointed. Given that the net green outcome of a construction project is the sum total of the efforts undertaken at the various supply chain stages (from the initial design to the end-of-life demolition) by different stakeholders, the green supply chain management (GSCM) approach is seen as a way forward toward streamlining the fragmented efforts at greening the sector. This forms the motivation of the present work, and this paper aims to develop, validate and apply a multi-dimensional GSCM framework for the construction sector. Design/methodology/approach A comprehensive GSCM assessment framework consisting of nine constructs (external and internal drivers; external and internal barriers; core and facilitating GSCM practices; economic, environmental and organizational performance implications) and their underlying factors was developed through an extensive literature review. Using data collected through a structured questionnaire, the framework was validated, and the relevance/appropriateness of each construct and its underlying factors, along with the hypothesized relationships between the constructs, were assessed separately for each supply chain stakeholder. Findings The findings confirm the validity and reliability of the constructs and their underlying factors as well as the assessment framework. In general, the implementation of green practices has had a positive impact on the environmental, economic and organizational performance for all stakeholders, while the extent of the green practices implemented depends on the relative strength of the drivers and barriers. Research limitations/implications This study fills a gap in the literature about applying/implementing GSCM in the construction sector. Practical implications The findings provide practitioners, policy makers and organizations associated with the UAE construction sector, as well as the construction sector in general, insight into all key aspects of GSCM. Originality/value A comprehensive survey-based assessment of GSCM for the construction sector has not been previously attempted and constitutes the novelty of this work.},
	number = {1},
	urldate = {2023-09-06},
	journal = {Supply Chain Management: An International Journal},
	author = {Balasubramanian, Sreejith and Shukla, Vinaya},
	month = jan,
	year = {2017},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Empirical study, Construction industry, Green supply chains, Structural equation model},
	pages = {58--81},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\TBR3EE26\\Balasubramanian and Shukla - 2017 - Green supply chain management an empirical invest.pdf:application/pdf},
}

@misc{noauthor_impact_nodate,
	title = {Impact of {Green} {Supply} {Chain} {Management} ({GSCM}) on {Business} {Performance} and {Environmental} {Sustainability}: {Case} of a {Developing} {Country} - {Rasheda} {Akter} {Rupa}, {Abu} {Naser} {Mohammad} {Saif}, 2022},
	url = {https://journals.sagepub.com/doi/10.1177/2278533720983089},
	urldate = {2023-09-06},
	file = {Impact of Green Supply Chain Management (GSCM) on Business Performance and Environmental Sustainability\: Case of a Developing Country - Rasheda Akter Rupa, Abu Naser Mohammad Saif, 2022:C\:\\Users\\abrar\\Zotero\\storage\\3UYYMHSF\\2278533720983089.html:text/html},
}

@article{rupa_impact_2022-1,
	title = {Impact of {Green} {Supply} {Chain} {Management} ({GSCM}) on {Business} {Performance} and {Environmental} {Sustainability}: {Case} of a {Developing} {Country}},
	volume = {10},
	issn = {2278-5337},
	shorttitle = {Impact of {Green} {Supply} {Chain} {Management} ({GSCM}) on {Business} {Performance} and {Environmental} {Sustainability}},
	url = {https://doi.org/10.1177/2278533720983089},
	doi = {10.1177/2278533720983089},
	abstract = {In this Fourth Industrial Revolution (4IR), sustainable development for business firms depends on maintaining sustained performance and environmental sustainability to a great extent. The current study discovers the impact of green supply chain management (GSCM) practices on business performance and the environmental sustainability of a developing country, Bangladesh. Cost and profit are the two important indicators of business performance. On the other hand, environmental sustainability is expressed by waste disposal, resource consumption, and greenhouse gas emission. Primary data were collected through the distribution of web links and direct interaction with the participants of different firms practicing GSCM practices in Bangladesh. A structured questionnaire was used for data collection. Hypotheses were formulated and evaluated accordingly. This study found that the impact of implementation of GSCM practices differs with respect to cost, profit, waste disposal, resource consumption, and greenhouse gas emission. GSCM practices have a statistically significant impact on cost, waste disposal, resource consumption, and greenhouse gas emission. The impact of GSCM practices on profit was statistically insignificant. It was found that lack of IT implementation, high cost of waste disposal, uncertainty and competition in the market, resistance to change, and lack of top management support are the major barriers to implement GSCM practices in Bangladesh.},
	language = {en},
	number = {1},
	urldate = {2023-09-06},
	journal = {Business Perspectives and Research},
	author = {Rupa, Rasheda Akter and Saif, Abu Naser Mohammad},
	month = jan,
	year = {2022},
	note = {Publisher: SAGE Publications India},
	pages = {140--163},
	file = {SAGE PDF Full Text:C\:\\Users\\abrar\\Zotero\\storage\\QTESG8RU\\Rupa and Saif - 2022 - Impact of Green Supply Chain Management (GSCM) on .pdf:application/pdf},
}

@article{ahmed_analyzing_2020-2,
	title = {Analyzing the impact of environmental collaboration among supply chain stakeholders on a firm’s sustainable performance},
	volume = {13},
	issn = {1936-9743},
	url = {https://doi.org/10.1007/s12063-020-00152-1},
	doi = {10.1007/s12063-020-00152-1},
	abstract = {In the era of industrialization, environmentalists are more concerned with the environment and so are continuously interested in investigating organizational factors that can facilitate the transition towards sustainability. This research systematically investigates the impact of the supply chain partner’s collaborative approach towards green practices on a firm’s sustainability performance. Stakeholder and coordination theories are used to underpin the study. A structural equation modeling technique is adopted to analyze data collected from 126 green supply chain professionals working at various manufacturing firms operating in Pakistan using a survey questionnaire. The results indicate significant and positive impacts of institution pressure and customer monitoring on the adoption of green supply chain management (GSCM) practices by organizations. This study also explains that organizational GSCM practices, external GSCM practices and performance measures have positive and significant relationships. These findings reveal that it is important for managers to address external GSCM pressures by adopting green practices and being a focal firm should undertake GSCM initiatives in collaboration with their suppliers and customers to achieve a holistic impact which ultimately leads to betterment in overall sustainability performance.},
	language = {en},
	number = {1},
	urldate = {2023-09-06},
	journal = {Operations Management Research},
	author = {Ahmed, Waqar and Ashraf, Muhammad Saeed and Khan, Sharfuddin Ahmed and Kusi-Sarpong, Simonov and Arhin, Francis Kow and Kusi-Sarpong, Horsten and Najmi, Arsalan},
	month = jun,
	year = {2020},
	keywords = {Environmental performance, Organizational performance, Coordination theory, Customer collaboration, Green supply chain, Stakeholder theory, Supplier collaboration},
	pages = {4--21},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\ILRGMGMM\\Ahmed et al. - 2020 - Analyzing the impact of environmental collaboratio.pdf:application/pdf},
}

@article{lim_time-series_2021,
	title = {Time-series forecasting with deep learning: a survey},
	volume = {379},
	shorttitle = {Time-series forecasting with deep learning},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsta.2020.0209},
	doi = {10.1098/rsta.2020.0209},
	abstract = {Numerous deep learning architectures have been developed to accommodate the diversity of time-series datasets across different domains. In this article, we survey common encoder and decoder designs used in both one-step-ahead and multi-horizon time-series forecasting—describing how temporal information is incorporated into predictions by each model. Next, we highlight recent developments in hybrid deep learning models, which combine well-studied statistical models with neural network components to improve pure methods in either category. Lastly, we outline some ways in which deep learning can also facilitate decision support with time-series data.

This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	number = {2194},
	urldate = {2023-09-16},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Lim, Bryan and Zohren, Stefan},
	month = feb,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {counterfactual prediction, deep neural networks, hybrid models, interpretability, time-series forecasting, uncertainty estimation},
	pages = {20200209},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\XM4TSR89\\Lim and Zohren - 2021 - Time-series forecasting with deep learning a surv.pdf:application/pdf},
}

@article{yang_supply_2023-1,
	title = {Supply chain risk management with machine learning technology: {A} literature review and future research directions},
	volume = {175},
	issn = {0360-8352},
	shorttitle = {Supply chain risk management with machine learning technology},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835222008476},
	doi = {10.1016/j.cie.2022.108859},
	abstract = {Coronavirus disease 2019 (COVID-19) has placed tremendous pressure on supply chain risk management (SCRM) worldwide. Recent technological advances, especially machine learning (ML) technology, have shown the possibility to prevent supply chain risk (SCR) by decreasing the need for human labor, increasing response speed, and predicting risk. However, the literature lacks a comprehensive analysis of the relationship between ML and SCRM. This work conducts a comprehensive review of the relatively limited literature in this field. An analysis of 67 shortlisted articles from 9 databases shows that this area is still in the rapid development stage and that researchers have shown extraordinary interest in it. The main purpose of this study is to review the current research status so that researchers have a clear understanding of the research gaps in this area. Moreover, this study provides an opportunity for researchers and practitioners to pay attention to ML algorithms for SCRM during the COVID-19 pandemic.},
	urldate = {2023-09-16},
	journal = {Computers \& Industrial Engineering},
	author = {Yang, Mei and Lim, Ming K. and Qu, Yingchi and Ni, Du and Xiao, Zhi},
	month = jan,
	year = {2023},
	keywords = {Machine learning, COVID-19, Algorithm, Supply chain risk management, Research status},
	pages = {108859},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\N6YZ3ZWV\\Yang et al. - 2023 - Supply chain risk management with machine learning.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\XRZGWN77\\S0360835222008476.html:text/html},
}

@incollection{poole_applications_1989,
	address = {Dordrecht},
	title = {Applications {Engineering}},
	isbn = {978-94-011-7050-5},
	url = {https://doi.org/10.1007/978-94-011-7050-5_13},
	abstract = {Unlike previous chapters, which have concentrated on the system and design issues involved in developing robots, this chapter discusses the application of robot technology to industry. We begin with the steps necessary for planning, selecting and installing robots. That presentation is followed by an examination of those issues which might be faced by a company considering the installation of a seam-welding robot. That example was chosen because it is illustrative of many other types of robot installations. Some special issues involved in work cell systems are covered, and we end with an examination of safety in the plant, including needs, approaches, and available techniques.},
	language = {en},
	urldate = {2023-09-19},
	booktitle = {Fundamentals of {Robotics} {Engineering}},
	publisher = {Springer Netherlands},
	author = {Poole, Harry H.},
	editor = {Poole, Harry H.},
	year = {1989},
	doi = {10.1007/978-94-011-7050-5_13},
	keywords = {Automate Guide Vehicle, Flexible Manufacturing System, Material Handling, Spot Welding, Work Cell},
	pages = {312--333},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\W8ANTS8S\\Poole - 1989 - Applications Engineering.pdf:application/pdf},
}

@book{groover_cadcam_2013,
	title = {{CAD}/{CAM}: {Computer}-{Aided} {Design} and {Manufacturing}},
	isbn = {978-81-7758-416-5},
	shorttitle = {{CAD}/{CAM}},
	abstract = {In this book, the authors examine interactive computer graphics and its use in designing industrial robots, computer control of manufacturing processes, computer-integrated production control, automated inspections, and flexible manufacturing systems. They also discuss the implementation of turnkey CAD/CAM systems.},
	language = {en},
	publisher = {Pearson Education India},
	author = {Groover},
	year = {2013},
}

@book{groover_cadcam_2003,
	edition = {1st edition},
	title = {{CAD}/{CAM}: {Computer}-{Aided} {Design} and {Manufacturing}},
	isbn = {978-81-7490-670-0},
	shorttitle = {{CAD}/{CAM}},
	abstract = {This is a comprehensive survey of the technical topics relating to CAD/CAM including interactive computer graphics, numerical control, computer process control, robotics, group technology, computer integrated production management and flexible manufacturing systems.This successful book has been designed as a textbook for college course and industry continuing education course in CAD/CAM, as well as for engineers, computer specialists and others who wish to learn about the technology and applications of CAD/CAM.},
	language = {English},
	publisher = {Pearson Education},
	author = {Groover, M.},
	month = jan,
	year = {2003},
}

@misc{noauthor_tool_nodate,
	title = {Tool {Path} {Planning} for {Avoiding} {Exit} {Burrs} - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S1526612500700193},
	urldate = {2023-09-19},
	file = {Tool Path Planning for Avoiding Exit Burrs - ScienceDirect:C\:\\Users\\abrar\\Zotero\\storage\\X5VSU4SP\\S1526612500700193.html:text/html},
}

@article{chu_tool_2000,
	title = {Tool {Path} {Planning} for {Avoiding} {Exit} {Burrs}},
	volume = {2},
	issn = {1526-6125},
	url = {https://www.sciencedirect.com/science/article/pii/S1526612500700193},
	doi = {10.1016/S1526-6125(00)70019-3},
	abstract = {Milling exit burrs usually form along the edges of a workpiece when the tool leaves the part while removing stock material. One of the most efficient methods for minimizing exit burrs is to prevent the tool from exiting the workpiece during material removal. This paper describes a systematic framework to generate tool paths that always enter a part, which is not a thin structure, in a planar milling operation. Three distinct tool exit conditions are analyzed for polygonal parts. A test criterion is then proposed to examine the occurrence of tool exits. For each condition, a tool path planning scheme is developed to avoid tool exits. These schemes are proved to be effective using the test criterion. This work is integrated into a networked manufacturing environment as a burr agent. Test parts are cut to demonstrate that this framework enhances edge quality by minimizing tool exits.},
	number = {2},
	urldate = {2023-09-19},
	journal = {Journal of Manufacturing Processes},
	author = {Chu, Chih-Hsing and Dornfeld, David},
	month = jan,
	year = {2000},
	keywords = {Burr, CAD, CAM, Edge Quality, Milling, Tool Exit, Tool Path},
	pages = {116--123},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\57QZHMHW\\S1526612500700193.html:text/html},
}

@article{liu_toolpath_2020,
	title = {Toolpath planning for additive manufacturing using sliced model decomposition and metaheuristic algorithms},
	volume = {149},
	issn = {0965-9978},
	url = {https://www.sciencedirect.com/science/article/pii/S0965997820309522},
	doi = {10.1016/j.advengsoft.2020.102906},
	abstract = {Fabrication efficiency has long been a challenge for additive manufacturing. Standard toolpath generation processes usually give rise to a significant number of non-productive motions that undermine production efficiency and degrade part quality due to frequent acceleration and deceleration in wasted motions. In this paper, we introduce an optimized toolpath generation process that comprises of decomposition of sliced model and optimization of fabrication sequences to minimize non-productive toolpaths. Unlike standard toolpaths, optimized toolpaths carry out fabrication of multiple objects in a staggered sequence to maximize manufacturing efficiency. To tackle the problem of interference between a printhead and objects due to changes in the fabrication sequence of layered depositions, an algorithm that adaptively determines collision-free heights is developed. Additionally, sliced model decomposition considerably reduces the number of entities for optimization. The computational cost involved in toolpath optimization is independent of slicing interval; therefore, the effectiveness and applicability of the proposed optimization approach are well maintained for small slicing intervals. Benchmarks are analyzed to demonstrate the effectiveness and robustness of the proposed toolpath planning approach, and two physical experiments are carried out using fused deposition modeling (FDM) and direct metal deposition (DMD) technologies. Non-productive toolpaths are reduced remarkably, and the desired fabrication quality is achieved for both non-metal and metal structures.},
	urldate = {2023-09-19},
	journal = {Advances in Engineering Software},
	author = {Liu, Wenyang and Chen, Ling and Mai, Guangzhen and Song, Lijun},
	month = nov,
	year = {2020},
	keywords = {Additive manufacturing, Collision avoidance, Metaheuristic, Model decomposition, Toolpath},
	pages = {102906},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\S2SE87Z5\\S0965997820309522.html:text/html},
}

@misc{noauthor_fusion_nodate,
	title = {Fusion 360 {Help} {\textbar} {Setup} tab (milling and cutting) reference {\textbar} {Autodesk}},
	url = {https://help.autodesk.com/view/fusion360/ENU/?guid=MFG-REF-SETUP-MILL},
	urldate = {2023-09-19},
	file = {Fusion 360 Help | Setup tab (milling and cutting) reference | Autodesk:C\:\\Users\\abrar\\Zotero\\storage\\X3ABAT23\\ENU.html:text/html},
}

@misc{noauthor_fusion_nodate-1,
	title = {Fusion 360 {Help} {\textbar} {Setup} tab (milling and cutting) reference {\textbar} {Autodesk}},
	url = {https://help.autodesk.com/view/fusion360/ENU/?guid=MFG-REF-SETUP-MILL},
	urldate = {2023-09-19},
	file = {Fusion 360 Help | Setup tab (milling and cutting) reference | Autodesk:C\:\\Users\\abrar\\Zotero\\storage\\W2LD5E8M\\ENU.html:text/html},
}

@misc{noauthor_help_nodate,
	title = {Help {\textbar} {To} {Align} {Parts} {\textbar} {Autodesk}},
	url = {https://help.autodesk.com/view/NETF/2023/ENU/?guid=GUID-49E9EF75-9D9A-465C-B65B-02EBB0672C7D},
	urldate = {2023-09-19},
	file = {Help | To Align Parts | Autodesk:C\:\\Users\\abrar\\Zotero\\storage\\ULNPCYKE\\ENU.html:text/html},
}

@misc{noauthor_role_nodate,
	title = {The {Role} of {Surface} {Finish} in {Machining} {Processes} - {SendCutSend}},
	url = {https://sendcutsend.com/blog/surface-finish/},
	urldate = {2023-09-19},
	file = {The Role of Surface Finish in Machining Processes - SendCutSend:C\:\\Users\\abrar\\Zotero\\storage\\GPHHGA9J\\surface-finish.html:text/html},
}

@misc{latva_role_2023,
	title = {The {Role} of {Surface} {Finish} in {Machining} {Processes}},
	url = {https://sendcutsend.com/blog/surface-finish/},
	abstract = {Surface finish plays a crucial role in ensuring durability and performance. Learn more about what to account for when designing your part.},
	language = {en-US},
	urldate = {2023-09-19},
	journal = {SendCutSend},
	author = {Latva, Nicole},
	month = jul,
	year = {2023},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\T652G694\\surface-finish.html:text/html},
}

@article{xi_tool_2021,
	title = {Tool wear monitoring in roughing and finishing processes based on machine internal data},
	volume = {113},
	issn = {1433-3015},
	url = {https://doi.org/10.1007/s00170-021-06748-6},
	doi = {10.1007/s00170-021-06748-6},
	abstract = {Data analytics plays a significant role in the realization of Industry 4.0. By generating context-related persistent datasets, every manufacturing process in real production becomes an experiment. The vision of Internet of Production (IoP) is to enable real-time diagnosis and prediction in smart productions by acquiring datasets seamlessly from different data silos. This requires interdisciplinary collaboration and domain-specific expertise. In this paper, we present a novel tool wear monitoring system for milling process developed in the context of IoP. This system is based on high-frequency data from the numerical control of the production machine without additional sensors. The novelty of this paper lies in the introduction of virtual workpiece quality and fusion of multiple build-in sensor signals and a force model as decision support. This bridges the time gap between quality inspection and production at the shop floor level, establishes an automated statistical process control system, and provides a more plausible prediction of tool lifetime. The monitoring of two different milling processes in a real production environment is exemplary demonstrated in this paper. The first case is a face roughing process with the aim of rapidly removing large amounts of material. The second case is a face finishing operation that follows roughing and aims to achieve the desired surface quality.},
	language = {en},
	number = {11},
	urldate = {2023-09-19},
	journal = {The International Journal of Advanced Manufacturing Technology},
	author = {Xi, Tiandong and Benincá, Igor Medeiros and Kehne, Sebastian and Fey, Marcel and Brecher, Christian},
	month = apr,
	year = {2021},
	keywords = {Condition monitoring, Data analytics, Digital twin, Quality inspection, Tool wear},
	pages = {3543--3554},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\G99JMRKS\\Xi et al. - 2021 - Tool wear monitoring in roughing and finishing pro.pdf:application/pdf},
}

@book{noauthor_read_nodate,
	title = {Read "{Unit} {Manufacturing} {Processes}: {Issues} and {Opportunities} in {Research}" at {NAP}.edu},
	shorttitle = {Read "{Unit} {Manufacturing} {Processes}},
	url = {https://www.nap.edu/read/4827/chapter/18},
	abstract = {Read chapter 13 Process Precision and Metrology: Manufacturing, reduced to its simplest form, involves the sequencing of product forms through a number of...},
	language = {en},
	urldate = {2023-09-19},
	doi = {10.17226/4827},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\ZRBLKDYG\\18.html:text/html},
}

@misc{noauthor_basic_2022,
	title = {Basic {Guide} {Of} {Tolerances} {In} {CNC} {Machining} - {LEADRP} - {Rapid} {Prototyping} {And} {Manufacturing} {Service}},
	url = {https://leadrp.net/blog/basic-guide-of-tolerances-in-cnc-machining/},
	abstract = {Tolerances in CNC machining represent the level of precision required to manufacture a part. Machining tolerances describe the acceptable variation in a part's final dimensions or measured value.},
	language = {en-US},
	urldate = {2023-09-19},
	month = nov,
	year = {2022},
	note = {Running Time: 483
Section: Engineering},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\WSXM4PPE\\basic-guide-of-tolerances-in-cnc-machining.html:text/html},
}

@misc{noauthor_powder_nodate,
	title = {Powder {Metallurgy}: {What} {Is} {It}? {Processes}, {Parts}, {Metals} {Used}},
	url = {https://www.iqsdirectory.com/articles/powder-metal-parts/powder-metallurgy.html},
	urldate = {2023-09-19},
}

@misc{noauthor_powder_nodate-1,
	title = {Powder {Metallurgy}: {What} {Is} {It}? {Processes}, {Parts}, {Metals} {Used}},
	url = {https://www.iqsdirectory.com/articles/powder-metal-parts/powder-metallurgy.html},
	urldate = {2023-09-19},
}

@misc{noauthor_milling_2023,
	title = {Milling cutter},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Milling_cutter&oldid=1157220936},
	abstract = {Milling cutters are cutting tools typically used in milling machines or machining centres to perform milling operations (and occasionally in other machine tools). They remove material by their movement within the machine (e.g., a ball nose mill) or directly from the cutter's shape (e.g., a form tool such as a hobbing cutter).},
	language = {en},
	urldate = {2023-09-19},
	journal = {Wikipedia},
	month = may,
	year = {2023},
	note = {Page Version ID: 1157220936},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\HVJ8MACE\\Milling_cutter.html:text/html},
}

@article{loewe_classification_1997,
	title = {Classification and mean behavior of magnetic storms},
	volume = {102},
	copyright = {Copyright 1997 by the American Geophysical Union.},
	issn = {2156-2202},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/96JA04020},
	doi = {10.1029/96JA04020},
	abstract = {The Dst index is used to identify more than 1000 storms which occurred in the time interval 1957 to 1993. Using the minimum Dst value as an indicator, we classify the storms as weak (482), moderate (346), strong (206), severe (45), and great (6). For each of these classes the mean time variation is determined. In contrast to the well-known study of Sugiura and Chapman [1960], the Dst minimum is used as a common reference epoch. This leads to much better agreement between the average and the typical storm behavior. We also find that the maximum ap and AE activity precedes the Dst minimum by 1 to 2 hours. Finally, we demonstrate that both sudden commencement and gradual commencement storms are associated with a distinct decrease in the Bz component of the interplanetary magnetic field.},
	language = {en},
	number = {A7},
	urldate = {2023-10-06},
	journal = {Journal of Geophysical Research: Space Physics},
	author = {Loewe, C. A. and Prölss, G. W.},
	year = {1997},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/96JA04020},
	pages = {14209--14213},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\4LM75KQK\\Loewe and Prölss - 1997 - Classification and mean behavior of magnetic storm.pdf:application/pdf},
}

@article{gruet_multiple-hour-ahead_2018,
	title = {Multiple-{Hour}-{Ahead} {Forecast} of the {Dst} {Index} {Using} a {Combination} of {Long} {Short}-{Term} {Memory} {Neural} {Network} and {Gaussian} {Process}},
	volume = {16},
	copyright = {©2018. American Geophysical Union. All Rights Reserved.},
	issn = {1542-7390},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2018SW001898},
	doi = {10.1029/2018SW001898},
	abstract = {In this study, we present a method that combines a Long Short-Term Memory (LSTM) recurrent neural network with a Gaussian process (GP) model to provide up to 6-hr-ahead probabilistic forecasts of the Dst geomagnetic index. The proposed approach brings together the sequence modeling capabilities of a recurrent neural network with the error bars and confidence bounds provided by a GP. Our model is trained using the hourly OMNI and Global Positioning System (GPS) databases, both of which are publicly available. We first develop a LSTM network to get a single-point prediction of Dst. This model yields great accuracy in forecasting the Dst index from 1 to 6 hr ahead, with a correlation coefficient always higher than 0.873 and a root-mean-square error lower than 9.86. However, even if global metrics show excellent performance, it remains poor in predicting intense storms (Dst {\textless} −250 nT) 6 hr in advance. To improve it and to obtain probabilistic forecasts, we combine the LSTM model obtained with a GP and evaluate the hybrid predictor using the receiver operating characteristic curve and the reliability diagram. We conclude that this hybrid methodology provides improvements in the forecast of geomagnetic storms, from 1 to 6 hr ahead.},
	language = {en},
	number = {11},
	urldate = {2023-10-06},
	journal = {Space Weather},
	author = {Gruet, M. A. and Chandorkar, M. and Sicard, A. and Camporeale, E.},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2018SW001898},
	keywords = {neural networks, Gaussian process, geomagnetic index, multiple-hour-ahead forecasts},
	pages = {1882--1896},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\MQVTNPWD\\Gruet et al. - 2018 - Multiple-Hour-Ahead Forecast of the Dst Index Usin.pdf:application/pdf},
}

@article{burton_empirical_1975,
	title = {An empirical relationship between interplanetary conditions and {Dst}},
	volume = {80},
	copyright = {Copyright © 1975 by the American Geophysical Union.},
	issn = {2156-2202},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/JA080i031p04204},
	doi = {10.1029/JA080i031p04204},
	abstract = {An algorithm is presented for predicting the ground-based Dst index solely from a knowledge of the velocity and density of the solar wind and the north-south solar magnetospheric component of the interplanetary magnetic field. The three key elements of this model are an adjustment for solar wind dynamic pressure, an injection rate linearly proportional to the dawn-to-dusk component of the interplanetary electric field which is zero for electric fields below 0.5 mV m−1, and an exponential decay rate of the ring current with an e folding time of 7.7 hours. The algorithm is used to predict the Dst signature of seven geomagnetic storm intervals in 1967 and 1968. In addition to being quite successful, considering the simplicity of the model, the algorithm pinpoints the causes of various types of storm behavior. A main phase is initiated whenever the dawn-to-dusk solar magnetospheric component of the interplanetary electric field becomes large and positive. It is preceded by an initial phase of increased Dst if the solar wind dynamic pressure increases suddenly prior to the main phase. The recovery phase is initiated when the injection rate governed by the interplanetary electric field drops below the ring current decay rate associated with the ring current strength built up during the main phase. Variable recovery rates are generally due to additional injection during the recovery phase. This one algorithm accounts for magnetospheric behavior at quiet and at disturbed times and seems capable of predicting the behavior of Dst during even the largest of storms.},
	language = {en},
	number = {31},
	urldate = {2023-10-06},
	journal = {Journal of Geophysical Research (1896-1977)},
	author = {Burton, R. K. and McPherron, R. L. and Russell, C. T.},
	year = {1975},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/JA080i031p04204},
	pages = {4204--4214},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\6ZPPG9QY\\Burton et al. - 1975 - An empirical relationship between interplanetary c.pdf:application/pdf},
}

@article{gleisner_predicting_1996,
	title = {Predicting geomagnetic storms from solar-wind data using time-delay neural networks},
	volume = {14},
	doi = {10.1007/s00585-996-0679-1},
	abstract = {We have used time-delay feed-forward neural
networks to compute the geomagnetic-activity index Dst one
hour ahead from a temporal sequence of solar-wind data. The input data include solar-wind density n, velocity V and the southward component Bz
of the interplanetary magnetic field. Dst is not included in
the input data. The networks implement an explicit functional relationship between the solar wind and the geomagnetic disturbance, including both direct and time-delayed non-linear relations. In this study we especially consider the influence of varying the temporal size of the input-data sequence. The networks are trained on data covering 6600 h, and tested on data covering 2100 h. It is found that the initial and main phases of geomagnetic storms are well predicted, almost independent of the length of the input-data sequence. However, to predict the recovery phase, we have to use up to 20 h of solar-wind input data. The recovery phase is mainly governed by the ring-current loss processes, and is very much dependent on the ring-current history, and thus also the solar-wind history. With due consideration of the time history when optimizing the networks, we can reproduce 84\% of the Dst variance.},
	journal = {Annales Geophysicae},
	author = {Gleisner, Hans and Lundstedt, Henrik and Wintoft, Peter},
	month = jul,
	year = {1996},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\J8QDGX69\\Gleisner et al. - 1996 - Predicting geomagnetic storms from solar-wind data.pdf:application/pdf},
}

@misc{noauthor_improvements_nodate,
	title = {Improvements in short‐term forecasting of geomagnetic activity - {Bala} - 2012 - {Space} {Weather} - {Wiley} {Online} {Library}},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2012SW000779},
	urldate = {2023-10-06},
}

@article{bala_improvements_2012,
	title = {Improvements in short-term forecasting of geomagnetic activity},
	volume = {10},
	copyright = {Copyright 2012 by the American Geophysical Union},
	issn = {1542-7390},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2012SW000779},
	doi = {10.1029/2012SW000779},
	abstract = {We have improved our space weather forecasting algorithms to now predict Dst and AE in addition to Kp for up to 6 h of forecast times. These predictions can be accessed in real time at http://mms.rice.edu/realtime/forecast.html. In addition, in the event of an ongoing or imminent activity, e-mail “alerts” based on key discriminator levels have been going out to our subscribers since October 2003. The neural network–based algorithms utilize ACE data to generate full 1, 3, and 6 h ahead predictions of these indices from the Boyle index, an empirical approximation that estimates the Earth's polar cap potential using solar wind parameters. Our models yield correlation coefficients of over 0.88, 0.86, and 0.83 for 1 h predictions of Kp, Dst, and AE, respectively, and 0.86, 0.84, and 0.80 when predicting the same but 3 h ahead. Our 6 h ahead predictions, however, have slightly higher uncertainties. Furthermore, the paper also tests other solar wind functions—the Newell driver, the Borovsky control function, and adding solar wind pressure term to the Boyle index—for their ability to predict geomagnetic activity.},
	language = {en},
	number = {6},
	urldate = {2023-10-06},
	journal = {Space Weather},
	author = {Bala, Ramkumar and Reiff, Patricia},
	year = {2012},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2012SW000779},
	keywords = {Boyle, Index},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\283FS9AZ\\Bala and Reiff - 2012 - Improvements in short-term forecasting of geomagne.pdf:application/pdf},
}

@misc{noauthor_forecasting_nodate,
	title = {Forecasting the {Dst} index using a swarm‐optimized neural network - {Lazzús} - 2017 - {Space} {Weather} - {Wiley} {Online} {Library}},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017SW001608},
	urldate = {2023-10-06},
}

@article{lazzus_forecasting_2017,
	title = {Forecasting the {Dst} index using a swarm-optimized neural network},
	volume = {15},
	copyright = {©2017. American Geophysical Union. All Rights Reserved.},
	issn = {1542-7390},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2017SW001608},
	doi = {10.1002/2017SW001608},
	abstract = {A hybrid technique that combines an artificial neural network with a particle swarm optimization (ANN+PSO) was used to forecast the disturbance storm time (Dst) index from 1 to 6 h ahead. Our ANN was optimized by PSO to update ANN weights and to predict the short-term Dst index using past values as input parameters. The database used contains 233,760 hourly data from 1 January 1990 to 31 August 2016, considering storms and quiet period, grouped into three data sets: learning set (with 116,880 hourly data points), validation set (with 58,440 data points), and testing set (with 58,440 data points). Several ANN topologies were studied, and the best architecture was determined by systematically adding neurons and evaluating the root-mean-square error (RMSE) and the correlation coefficient (R) during the training process. These results show that the hybrid algorithm is a powerful technique for forecasting the Dst index a short time in advance like t + 1 to t + 3, with RMSE from 3.5 nT to 7.5 nT, and R from 0.98 to 0.90. However, t + 4 to t + 6 predictions become slightly more uncertain, with RMSE from 8.8 nT to 10.9 nT, and R from 0.86 to 0.79. Additionally, an exhaustive analysis according to geomagnetic storm magnitude was conducted. In general, the results show that our hybrid algorithm can be correctly trained to forecast the Dst index with appropriate precision and that Dst past behavior significantly affects adequate training and predicting capabilities of the implemented ANN.},
	language = {en},
	number = {8},
	urldate = {2023-10-06},
	journal = {Space Weather},
	author = {Lazzús, J. A. and Vega, P. and Rojas, P. and Salfate, I.},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/2017SW001608},
	keywords = {artificial neural network, Dst index, forecasting, geomagnetic storm, particle swarm optimization, space weather},
	pages = {1068--1089},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\G77V29ZS\\Lazzús et al. - 2017 - Forecasting the Dst index using a swarm-optimized .pdf:application/pdf},
}

@misc{drivendata_magnet_nodate,
	title = {{MagNet}: {Model} the {Geomagnetic} {Field}},
	shorttitle = {{MagNet}},
	url = {https://www.drivendata.org/competitions/73/noaa-magnetic-forecasting/leaderboard/},
	abstract = {Help NOAA better forecast changes in Earth’s magnetic field! Improved models can provide more advanced warning of geomagnetic storms and reduce errors in magnetic navigation systems.},
	language = {en},
	urldate = {2023-10-06},
	journal = {DrivenData},
	author = {DrivenData},
	file = {Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\PYLQPI3U\\leaderboard.html:text/html},
}

@misc{noauthor_220502447_nodate,
	title = {[2205.02447] {A} {Deep} {Learning} {Approach} to {Dst} {Index} {Prediction}},
	url = {https://arxiv.org/abs/2205.02447},
	urldate = {2023-10-06},
}

@misc{abduallah_deep_2022,
	title = {A {Deep} {Learning} {Approach} to {Dst} {Index} {Prediction}},
	url = {http://arxiv.org/abs/2205.02447},
	doi = {10.48550/arXiv.2205.02447},
	abstract = {The disturbance storm time (Dst) index is an important and useful measurement in space weather research. It has been used to characterize the size and intensity of a geomagnetic storm. A negative Dst value means that the Earth's magnetic field is weakened, which happens during storms. In this paper, we present a novel deep learning method, called the Dst Transformer, to perform short-term, 1-6 hour ahead, forecasting of the Dst index based on the solar wind parameters provided by the NASA Space Science Data Coordinated Archive. The Dst Transformer combines a multi-head attention layer with Bayesian inference, which is capable of quantifying both aleatoric uncertainty and epistemic uncertainty when making Dst predictions. Experimental results show that the proposed Dst Transformer outperforms related machine learning methods in terms of the root mean square error and R-squared. Furthermore, the Dst Transformer can produce both data and model uncertainty quantification results, which can not be done by the existing methods. To our knowledge, this is the first time that Bayesian deep learning has been used for Dst index forecasting.},
	urldate = {2023-10-06},
	publisher = {arXiv},
	author = {Abduallah, Yasser and Wang, Jason T. L. and Bose, Prianka and Zhang, Genwei and Gerges, Firas and Wang, Haimin},
	month = may,
	year = {2022},
	note = {arXiv:2205.02447 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 7 pages, 4 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\abrar\\Zotero\\storage\\Z3GT2JGI\\Abduallah et al. - 2022 - A Deep Learning Approach to Dst Index Prediction.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\CA6X2DPM\\2205.html:text/html},
}

@article{palacios_defining_2018,
	title = {Defining scale thresholds for geomagnetic storms through statistics},
	url = {https://nhess.copernicus.org/preprints/nhess-2018-92/},
	doi = {10.5194/nhess-2018-92},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} Geomagnetic storms, as part of the Sun-Earth relations, are continuously monitored with different indices and scales. These indices usually have some associated scale thresholds to quantify the severity or risk of geomagnetic disturbances. However, the most usual scale thresholds are arbitrarily chosen. In this work we aim to quantify the range of the thresholds through a new method. These new thresholds are based on statistical distribution fitting. {\textless}br{\textgreater}{\textless}br{\textgreater} We used different geomagnetic indices, as \textit{Dst}, \textit{SYM-H}, and \textit{K$_{\textrm{p}}$}, since they are relevant for space weather purposes. The first two indices have been discriminated between their negative values and the whole dataset. We considered two periods: a short-term one, comprising data from 1997 to 2012; and long-term ones, which are from 1957\&ndash;2012 for \textit{Dst} and 1932\&ndash;2012 for \textit{K$_{\textrm{p}}$}. {\textless}br{\textgreater}{\textless}br{\textgreater} We look for the best fit for different statistical continuous distributions applied to these indices. The best fits and the data distribution functions yield to intersects that can be used to define thresholds. The best fit distribution functions are more coincidental between them when considering determined similar datasets, as non-central \textit{f}-distribution for negative values, meaningful for geomagnetic disturbances; or non-central Student's-\textit{t}, when the whole dataset is taken. The method yields different values for thresholds depending on the index. Thresholds for geomagnetic storms can be chosen by common values of \textit{SYM-H} and \textit{Dst}, as \&minus;75\&thinsp;nT for moderate storms; \&minus;150\&thinsp;nT for intense storms, and \&minus;330\&thinsp;nT for extreme storms. For the case of \textit{K$_{\textrm{p}}$}, the value equal to 5 may mark the departure from quiet time to stormy time. {\textless}br{\textgreater}{\textless}br{\textgreater} The obtained values are close to those usually considered as thresholds for, typically, \textit{Dst} and \textit{K$_{\textrm{p}}$}; therefore the thresholds defined here may provide criteria to assess the vulnerability to geomagnetic activity on design or mitigation purposes.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2023-10-06},
	journal = {Natural Hazards and Earth System Sciences Discussions},
	author = {Palacios, Judith and Guerrero, Antonio and Cid, Consuelo and Saiz, Elena and Cerrato, Yolanda},
	month = apr,
	year = {2018},
	note = {Publisher: Copernicus GmbH},
	pages = {1--17},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\QDML35KM\\Palacios et al. - 2018 - Defining scale thresholds for geomagnetic storms t.pdf:application/pdf},
}

@article{zidan_rapid_2023,
	title = {Rapid solution of logical equivalence problems by quantum computation algorithm},
	volume = {132},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494622008936},
	doi = {10.1016/j.asoc.2022.109844},
	abstract = {We present a quantum computation algorithm that enables solving the problem of logical equivalence verification in exponentially less time than the classical deterministic computation. In this novel quantum algorithm, the oracles of the two evaluated functions are executed in series to yield a common target qubit which then interacts with an ancillary qubit. We found that the degree of entanglement (measured by the concurrence) of the target and ancillary qubits is a reliable witness for the logical equivalence property of the two functions. The steps number of the quantum algorithm is inversely proportional to the square of the standard error ϵ2 of the measured concurrence value, with no dependence on the input size ′n′ of each function. This corresponds to a number of evaluations of the two functions: O(ϵ−2) for the quantum algorithm compared with O(2n) for the classical approach. To assess the algorithm performance, two sets of experiments are conducted using the IBM Q Experience simulator for input sizes: 2 and 12 variables per function. While the former verifies that the results of the experiment are in a good match with the theory, the latter showcases the quantum supremacy of the presented algorithm. In particular, The latter shows that the quantum algorithm requires only 200 oracles queries compared with 213 queries for the classical algorithm.},
	urldate = {2023-10-09},
	journal = {Applied Soft Computing},
	author = {Zidan, Mohammed and Hegazy, Salem F. and Abdel-Aty, Mahmoud and Obayya, Salah S. A.},
	month = jan,
	year = {2023},
	keywords = {Logical equivalence, Quantum algorithms, Quantum computing, Quantum verification},
	pages = {109844},
	file = {ScienceDirect Snapshot:C\:\\Users\\abrar\\Zotero\\storage\\MIS64T3V\\S1568494622008936.html:text/html},
}

@article{zidan_quantum_2021,
	title = {A {Quantum} {Algorithm} for {Evaluating} the {Hamming} {Distance}},
	volume = {71},
	issn = {1546-2218, 1546-2226},
	url = {https://www.techscience.com/cmc/v71n1/45377},
	doi = {10.32604/cmc.2022.020103},
	abstract = {We present a novel quantum algorithm to evaluate the hamming distance between two unknown oracles via measuring the degree of entanglement between two ancillary qubits. In particular, we use the power of the entanglement degree based quantum computing model that preserves at most the locality of interactions within the quantum model structure. This model uses one of two techniques to retrieve the solution of a quantum computing problem at hand. In the first technique, the solution of the problem is obtained based on whether there is an entanglement between the two ancillary qubits or not. In the second, the solution of the quantum computing problem is obtained as a function in the concurrence value, and the number of states that can be generated from the Boolean variables. The proposed algorithm receives two oracles, each oracle represents an unknown Boolean function, then it measures the hamming distance between these two oracles. The hamming distance is evaluated based on the second technique. It is shown that the proposed algorithm provides exponential speedup compared with the classical counterpart for Boolean functions that have large numbers of Boolean variables. The proposed algorithm is explained via a case study. Finally, employing recently developed experimental techniques, the proposed algorithm has been verified using IBM's quantum computer simulator.},
	language = {en},
	number = {1},
	urldate = {2023-10-09},
	journal = {Computers, Materials \& Continua},
	author = {Zidan, Mohammed and Eldin, Manal and Shams, Mahmoud and Tolan, Mohamed and Abd-Elhamed, Ayman and Abdel-Aty, Mahmoud},
	year = {2021},
	note = {Publisher: Tech Science Press},
	pages = {1065--1078},
	file = {Full Text PDF:C\:\\Users\\abrar\\Zotero\\storage\\RCJVQ7P5\\Zidan et al. - 2021 - A Quantum Algorithm for Evaluating the Hamming Dis.pdf:application/pdf},
}

@article{zidan_novel_2018,
	title = {A {Novel} {Algorithm} based on {Entanglement} {Measurement} for {Improving} {Speed} of {Quantum} {Algorithms}},
	volume = {12},
	issn = {1935-0090, 2325-0399},
	url = {http://naturalspublishing.com/Article.asp?ArtcID=13946},
	doi = {10.18576/amis/120127},
	number = {1},
	urldate = {2023-10-09},
	journal = {Applied Mathematics \& Information Sciences},
	author = {Zidan, Mohammed and Abdel-Aty, Abdel-Haleem and Younes, A. and Zanaty, E. A. and El-khayat, I. and Abdel-Aty, Mahmoud},
	month = jan,
	year = {2018},
	pages = {265--269},
}
