@misc{pca_locus,
  doi = {10.48550/ARXIV.1609.03045},
  
  url = {https://arxiv.org/abs/1609.03045},
  
  author = {Nye, Tom M. W. and Tang, Xiaoxian and Weyenberg, Grady and Yoshida, Ruriko},
  
  keywords = {Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences, 60D05 (Primary) 62H25, 92D15 (Secondary)},
  
  title = {Principal component analysis and the locus of the Frechet mean in the space of phylogenetic trees},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc(duchinotes,
author={Duchi, John},
title={Lecture Notes for Statistics 311/Electrical Engineering 377},
year={2016}
}

@article{Frechet1948,
  title={Les {\'e}l{\'e}ments al{\'e}atoires de nature quelconque dans un espace distanci{\'e}},
  author={Maurice R. Fr{\'e}chet},
  journal={Annales de l'institut Henri Poincar{\'e}},
  year={1948}
}

@inproceedings{barz2019hierarchy,
  title={Hierarchy-based image embeddings for semantic image retrieval},
  author={Barz, Bj{\"o}rn and Denzler, Joachim},
  booktitle={2019 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={638--647},
  year={2019},
  organization={IEEE}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{Ciliberto2016,
 author = {Ciliberto, Carlo and Rosasco, Lorenzo and Rudi, Alessandro},
 booktitle = {Advances in Neural Information Processing Systems 30 (NIPS 2016)},
 title = {A Consistent Regularization Approach for Structured Prediction},
 volume = {30},
 year = {2016}
}

@inproceedings{imagenet,  
 author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},  
 booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},   
 title={ImageNet: A large-scale hierarchical image database},
 year={2009},  
 volume={},  
 number={},  
 pages={248-255},  
 doi={10.1109/CVPR.2009.5206848}
}

@inproceedings{Graber19,
 author = {Colin Graber and Alexander Schwing},
 booktitle = {Advances in Neural Information Processing Systems 33 (NeurIPS 2019)},
 title = {Graph Structured Prediction Energy Networks},
 volume = {33},
 year = {2019}
}

@inproceedings{Rudi18,
 author = {Alessandro Rudi and Carlo Ciliberto and GianMaria Marconi and Lorenzo Rosasco},
 booktitle = {Advances in Neural Information Processing Systems 32 (NeurIPS 2018)},
 title = {Manifold Structured Prediction},
 volume = {32},
 year = {2018}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{cifar100,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}


@InProceedings{Lou20,
  title = 	 {Differentiating through the Fr{é}chet Mean},
  author =       {Lou, Aaron and Katsman, Isay and Jiang, Qingxuan and Belongie, Serge and Lim, Ser-Nam and De Sa, Christopher},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {6393--6403},
  year = 	 {2020},
}

@unknown{Chakraborty19,
author = {Chakraborty, Rudrasis and Wang, Jiayun and Yu, Stella},
year = {2019},
month = {06},
booktitle={Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops}
}, 
title = {SurReal: Fr\'echet Mean and Distance Transform for Complex-Valued Deep Learning}
}


@article{pca_phylogenetic,
	abstract = {Evolutionary relationships are represented by phylogenetic trees, and a phylogenetic analysis of gene sequences typically produces a collection of these trees, one for each gene in the analysis. Analysis of samples of trees is difficult due to the multi-dimensionality of the space of possible trees. In Euclidean spaces, principal component analysis is a popular method of reducing high-dimensional data to a low-dimensional representation that preserves much of the sample's structure. However, the space of all phylogenetic trees on a fixed set of species does not form a Euclidean vector space, and methods adapted to tree space are needed. Previous work introduced the notion of a principal geodesic in this space, analogous to the first principal component. Here we propose a geometric object for tree space similar to the [Formula: see text]th principal component in Euclidean space: the locus of the weighted Fr{\'e}chet mean of [Formula: see text] vertex trees when the weights vary over the [Formula: see text]-simplex. We establish some basic properties of these objects, in particular showing that they have dimension [Formula: see text], and propose algorithms for projection onto these surfaces and for finding the principal locus associated with a sample of trees. Simulation studies demonstrate that these algorithms perform well, and analyses of two datasets, containing Apicomplexa and African coelacanth genomes respectively, reveal important structure from the second principal components.},
	address = {School of Mathematics and Statistics, Newcastle University, Newcastle upon Tyne NE1 7RU, U.K.tom.nye@ncl.ac.uk.; Department of Mathematics, Texas A\&M University, College Station, Texas 77843, U.S.A.xiaoxian@math.tamu.edu.; Department of Mathematics, University of Hawaii at Hilo, Hilo, Hawaii 96720, U.S.A.gradysw@hawaii.edu.; Department of Operations Research, Naval Postgraduate School, Monterey, California 93943, U.S.A.ryoshida@nps.edu.},
	author = {Nye, Tom M W and Tang, Xiaoxian and Weyenberg, Grady and Yoshida, Ruriko},
	crdt = {2018/02/10 06:00},
	date = {2017 Dec},
	date-added = {2022-10-14 05:43:52 -0500},
	date-modified = {2022-10-14 05:43:52 -0500},
	dep = {20170927},
	doi = {10.1093/biomet/asx047},
	edat = {2018/02/10 06:00},
	gr = {WT{\_}/Wellcome Trust/United Kingdom},
	issn = {0006-3444 (Print); 1464-3510 (Electronic); 0006-3444 (Linking)},
	jid = {0413661},
	journal = {Biometrika},
	jt = {Biometrika},
	keywords = {Fr{\'e}chet mean; Phylogenetic tree; Principal component analysis; Tree space},
	language = {eng},
	lid = {10.1093/biomet/asx047 {$[$}doi{$]$}},
	lr = {20220221},
	mhda = {2018/02/10 06:01},
	month = {Dec},
	number = {4},
	oto = {NOTNLM},
	own = {NLM},
	pages = {901--922},
	phst = {2016/09/10 00:00 {$[$}received{$]$}; 2018/02/10 06:00 {$[$}entrez{$]$}; 2018/02/10 06:00 {$[$}pubmed{$]$}; 2018/02/10 06:01 {$[$}medline{$]$}},
	pii = {asx047},
	pmc = {PMC5793493},
	pmid = {29422694},
	pst = {ppublish},
	pt = {Journal Article},
	status = {PubMed-not-MEDLINE},
	title = {Principal component analysis and the locus of the Fr{\'e}chet mean in the space of phylogenetic trees.},
	volume = {104},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1093/biomet/asx047}}


@article{BILLERA2001733,
	abstract = {We consider a continuous space which models the set of all phylogenetic trees having a fixed set of leaves. This space has a natural metric of nonpositive curvature, giving a way of measuring distance between phylogenetic trees and providing some procedures for averaging or combining several trees whose leaves are identical. This geometry also shows which trees appear within a fixed distance of a given tree and enables construction of convex hulls of a set of trees. This geometric model of tree space provides a setting in which questions that have been posed by biologists and statisticians over the last decade can be approached in a systematic fashion. For example, it provides a justification for disregarding portions of a collection of trees that agree, thus simplifying the space in which comparisons are to be made.},
	author = {Louis J. Billera and Susan P. Holmes and Karen Vogtmann},
	doi = {https://doi.org/10.1006/aama.2001.0759},
	issn = {0196-8858},
	journal = {Advances in Applied Mathematics},
	keywords = {phylogenetic trees, semi-labeled trees, associahedron, CAT(0) space, consensus, bootstrap},
	number = {4},
	pages = {733-767},
	title = {Geometry of the Space of Phylogenetic Trees},
	url = {https://www.sciencedirect.com/science/article/pii/S0196885801907596},
	volume = {27},
	year = {2001},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0196885801907596},
	Bdsk-Url-2 = {https://doi.org/10.1006/aama.2001.0759}}


@INPROCEEDINGS{8658633,
  author={Barz, Björn and Denzler, Joachim},
  booktitle={2019 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Hierarchy-Based Image Embeddings for Semantic Image Retrieval}, 
  year={2019},
  volume={},
  number={},
  pages={638-647},
  doi={10.1109/WACV.2019.00073}
  }

@inproceedings{rios-kavuluru-2018-shot,
    title = "Few-Shot and Zero-Shot Multi-Label Learning for Structured Label Spaces",
    author = "Rios, Anthony  and
      Kavuluru, Ramakanth",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1352",
    doi = "10.18653/v1/D18-1352",
    pages = "3132--3142"
}

@inproceedings{stewart2017label,
  title={Label-free supervision of neural networks with physics and domain knowledge},
  author={Stewart, Russell and Ermon, Stefano},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}


@inproceedings{zeroshotsurvey,
	author = {Chen, Jiaoyan and Geng, Yuxia and Chen, Zhuo and Horrocks, Ian and Z. Pan, Jeff and Chen, Huajun},
	booktitle = {Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, {IJCAI-21}},
	doi = {10.24963/ijcai.2021/597},
	editor = {Zhi-Hua Zhou},
	month = {8},
	note = {Survey Track},
	pages = {4366--4373},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	title = {Knowledge-aware Zero-Shot Learning: Survey and Perspective},
	url = {https://doi.org/10.24963/ijcai.2021/597},
	year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.24963/ijcai.2021/597}}


@inproceedings{generalized_ZSL,
	abstract = {In generalized zero shot learning (GZSL), the set of classes are split into seen and unseen classes, where training relies on the semantic features of the seen and unseen classes and the visual representations of only the seen classes, while testing uses the visual representations of the seen and unseen classes. Current methods address GZSL by learning a transformation from the visual to the semantic space, exploring the assumption that the distribution of classes in the semantic and visual spaces is relatively similar. Such methods tend to transform unseen testing visual representations into one of the seen classes' semantic features instead of the semantic features of the correct unseen class, resulting in low accuracy GZSL classification. Recently, generative adversarial networks (GAN) have been explored to synthesize visual representations of the unseen classes from their semantic features - the synthesized representations of the seen and unseen classes are then used to train the GZSL classifier. This approach has been shown to boost GZSL classification accuracy, but there is one important missing constraint: there is no guarantee that synthetic visual representations can generate back their semantic feature in a multi-modal cycle-consistent manner. This missing constraint can result in synthetic visual representations that do not represent well their semantic features, which means that the use of this constraint can improve GAN-based approaches. In this paper, we propose the use of such constraint based on a new regularization for the GAN training that forces the generated visual features to reconstruct their original semantic features. Once our model is trained with this multi-modal cycle-consistent semantic compatibility, we can then synthesize more representative visual representations for the seen and, more importantly, for the unseen classes. Our proposed approach shows the best GZSL classification results in the field in several publicly available datasets.},
	address = {Cham},
	author = {Felix, Rafael and Vijay Kumar, B. G. and Reid, Ian and Carneiro, Gustavo},
	booktitle = {Computer Vision -- ECCV 2018},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	isbn = {978-3-030-01231-1},
	pages = {21--37},
	publisher = {Springer International Publishing},
	title = {Multi-modal Cycle-Consistent Generalized Zero-Shot Learning},
	year = {2018}}

@article{GAN_KG_ZSL,
author = {Qin, Pengda and Wang, Xin and Chen, Wenhu and Zhang, Chunyun and Xu, Weiran and Wang, William},
year = {2020},
month = {04},
pages = {8673-8680},
title = {Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs},
volume = {34},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
doi = {10.1609/aaai.v34i05.6392}
}

@inproceedings{text_zsl,
  added-at = {2019-03-29T00:00:00.000+0100},
  author = {Norouzi, Mohammad and Mikolov, Tomas and Bengio, Samy and Singer, Yoram and Shlens, Jonathon and Frome, Andrea and Corrado, Greg and Dean, Jeffrey},
  biburl = {https://www.bibsonomy.org/bibtex/291a9c90900f6c28476d0c3adff1b88e3/dblp},
  booktitle = {ICLR},
  crossref = {conf/iclr/2014},
  editor = {Bengio, Yoshua and LeCun, Yann},
  ee = {http://arxiv.org/abs/1312.5650},
  interhash = {833e63fcdf640d4c0715903aaa79cf33},
  intrahash = {91a9c90900f6c28476d0c3adff1b88e3},
  keywords = {dblp},
  timestamp = {2019-04-05T11:39:45.000+0200},
  title = {Zero-Shot Learning by Convex Combination of Semantic Embeddings.},
  url = {http://dblp.uni-trier.de/db/conf/iclr/iclr2014.html#NorouziMBSSFCD13},
  year = 2014
}


@inproceedings{text_zsl_2,
	author = {Socher, Richard and Ganjoo, Milind and Manning, Christopher D and Ng, Andrew},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
	publisher = {Curran Associates, Inc.},
	title = {Zero-Shot Learning Through Cross-Modal Transfer},
	url = {https://proceedings.neurips.cc/paper/2013/file/2d6cc4b2d139a53512fb8cbb3086ae2e-Paper.pdf},
	volume = {26},
	year = {2013},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2013/file/2d6cc4b2d139a53512fb8cbb3086ae2e-Paper.pdf}}


@inproceedings{text_zsl_3,
	author = {Frome, Andrea and Corrado, Greg S and Shlens, Jon and Bengio, Samy and Dean, Jeff and Ranzato, Marc\textquotesingle Aurelio and Mikolov, Tomas},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
	publisher = {Curran Associates, Inc.},
	title = {DeViSE: A Deep Visual-Semantic Embedding Model},
	url = {https://proceedings.neurips.cc/paper/2013/file/7cce53cf90577442771720a370c3c723-Paper.pdf},
	volume = {26},
	year = {2013},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2013/file/7cce53cf90577442771720a370c3c723-Paper.pdf}}

@INPROCEEDINGS{attr_zsl_1,
  author={Lampert, Christoph H. and Nickisch, Hannes and Harmeling, Stefan},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Learning to detect unseen object classes by between-class attribute transfer}, 
  year={2009},
  volume={},
  number={},
  pages={951-958},
  doi={10.1109/CVPR.2009.5206594}}

@ARTICLE{attr_zsl_2,
  author={Lampert, Christoph H. and Nickisch, Hannes and Harmeling, Stefan},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Attribute-Based Classification for Zero-Shot Visual Object Categorization}, 
  year={2014},
  volume={36},
  number={3},
  pages={453-465},
  doi={10.1109/TPAMI.2013.140}}

@INPROCEEDINGS{attr_zsl_3,
  author={Farhadi, Ali and Endres, Ian and Hoiem, Derek and Forsyth, David},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Describing objects by their attributes}, 
  year={2009},
  volume={},
  number={},
  pages={1778-1785},
  doi={10.1109/CVPR.2009.5206772}}

@INPROCEEDINGS {KG_zsl_1,
author = {X. Wang and Y. Ye and A. Gupta},
booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Zero-Shot Recognition via Semantic Embeddings and Knowledge Graphs},
year = {2018},
volume = {},
issn = {},
pages = {6857-6866},
abstract = {We consider the problem of zero-shot recognition: learning a visual classifier for a category with zero training examples, just using the word embedding of the category and its relationship to other categories, which visual data are provided. The key to dealing with the unfamiliar or novel category is to transfer knowledge obtained from familiar classes to describe the unfamiliar class. In this paper, we build upon the recently introduced Graph Convolutional Network (GCN) and propose an approach that uses both semantic embeddings and the categorical relationships to predict the classifiers. Given a learned knowledge graph (KG), our approach takes as input semantic embeddings for each node (representing visual category). After a series of graph convolutions, we predict the visual classifier for each category. During training, the visual classifiers for a few categories are given to learn the GCN parameters. At test time, these filters are used to predict the visual classifiers of unseen categories. We show that our approach is robust to noise in the KG. More importantly, our approach provides significant improvement in performance compared to the current state-of-the-art results (from 2 ~ 3% on some metrics to whopping 20% on a few).},
keywords = {visualization;semantics;training;animals;task analysis;symmetric matrices;pattern recognition},
doi = {10.1109/CVPR.2018.00717},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2018.00717},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}


@article{KG_zsl_2,
	abstract = {Zero-shot learning --- the problem of training and testing on a completely disjoint set of classes --- relies greatly on its ability to transfer knowledge from train classes to test classes. Traditionally semantic embeddings consisting of human-defined attributes or distributed word embeddings are used to facilitate this transfer by improving the association between visual and semantic embeddings. In this paper, we take advantage of explicit relations between nodes defined in ConceptNet, a commonsense knowledge graph, to generate commonsense embeddings of the class labels by using a graph convolution network-based autoencoder. Our experiments performed on three standard benchmark datasets surpass the strong baselines when we fuse our commonsense embeddings with existing semantic embeddings, i.e., human-defined attributes and distributed word embeddings. This work paves the path to more brain-inspired approaches to zero-short learning.},
	author = {Roy, Abhinaba and Ghosal, Deepanway and Cambria, Erik and Majumder, Navonil and Mihalcea, Rada and Poria, Soujanya},
	doi = {10.1007/s12559-022-10044-0},
	issn = {1866-9964},
	journal = {Cognitive Computation},
	month = nov,
	number = {6},
	pages = {2212--2222},
	title = {Improving {Zero}-{Shot} {Learning} {Baselines} with {Commonsense} {Knowledge}},
	url = {https://doi.org/10.1007/s12559-022-10044-0},
	volume = {14},
	year = {2022},
	Bdsk-Url-1 = {https://doi.org/10.1007/s12559-022-10044-0}}


@article{KG_zsl_3,
	author = {Gao, Junyu and Zhang, Tianzhu and Xu, Changsheng},
	doi = {10.1609/aaai.v33i01.33018303},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	month = jul,
	number = {01},
	pages = {8303--8311},
	title = {I {Know} the {Relationships}: {Zero}-{Shot} {Action} {Recognition} via {Two}-{Stream} {Graph} {Convolutional} {Networks} and {Knowledge} {Graphs}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4843},
	volume = {33},
	year = {2019},
	Bdsk-Url-1 = {https://ojs.aaai.org/index.php/AAAI/article/view/4843},
	Bdsk-Url-2 = {https://doi.org/10.1609/aaai.v33i01.33018303}}

@inproceedings{ont_zsl_1,
    title = "Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification",
    author = "Li, Juan  and
      Wang, Ruoxu  and
      Zhang, Ningyu  and
      Zhang, Wen  and
      Yang, Fan  and
      Chen, Huajun",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.265",
    doi = "10.18653/v1/2020.coling-main.265",
    pages = "2967--2978",
    abstract = "Relation classification aims to extract semantic relations between entity pairs from the sentences. However, most existing methods can only identify seen relation classes that occurred during training. To recognize unseen relations at test time, we explore the problem of zero-shot relation classification. Previous work regards the problem as reading comprehension or textual entailment, which have to rely on artificial descriptive information to improve the understandability of relation types. Thus, rich semantic knowledge of the relation labels is ignored. In this paper, we propose a novel logic-guided semantic representation learning model for zero-shot relation classification. Our approach builds connections between seen and unseen relations via implicit and explicit semantic representations with knowledge graph embeddings and logic rules. Extensive experimental results demonstrate that our method can generalize to unseen relation types and achieve promising improvements.",
}

@inproceedings{ont_zsl_2,
    title = "Injecting Logical Background Knowledge into Embeddings for Relation Extraction",
    author = {Rockt{\"a}schel, Tim  and
      Singh, Sameer  and
      Riedel, Sebastian},
    booktitle = "Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = may # "{--}" # jun,
    year = "2015",
    address = "Denver, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N15-1118",
    doi = "10.3115/v1/N15-1118",
    pages = "1119--1129",
}

@article{Kampffmeyer2018RethinkingKG,
  title={Rethinking Knowledge Graph Propagation for Zero-Shot Learning},
  author={Michael C. Kampffmeyer and Yinbo Chen and Xiaodan Liang and Hao Wang and Yujia Zhang and Eric P. Xing},
  journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018},
  pages={11479-11488}
}

@inproceedings{
kipf2017semisupervised,
title={Semi-Supervised Classification with Graph Convolutional Networks},
author={Thomas N. Kipf and Max Welling},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=SJU4ayYgl}
}

@Misc{Bhatia16,
          author    = {Bhatia, K. and Dahiya, K. and Jain, H. and Kar, P. and Mittal, A. and Prabhu, Y. and Varma, M.},
          title     = {The extreme classification repository: Multi-label datasets and code},
          url       = {http://manikvarma.org/downloads/XC/XMLRepository.html},
          year      = {2016}
        }


@inproceedings{xc_graph_1,
author = {Mittal, Anshul and Sachdeva, Noveen and Agrawal, Sheshansh and Agarwal, Sumeet and Kar, Purushottam and Varma, Manik},
title = {ECLARE: Extreme Classification with Label Graph Correlations},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449815},
doi = {10.1145/3442381.3449815},
abstract = {Deep extreme classification (XC) seeks to train deep architectures that can tag a data point with its most relevant subset of labels from an extremely large label set. The core utility of XC comes from predicting labels that are rarely seen during training. Such rare labels hold the key to personalized recommendations that can delight and surprise a user. However, the large number of rare labels and small amount of training data per rare label offer significant statistical and computational challenges. State-of-the-art deep XC methods attempt to remedy this by incorporating textual descriptions of labels but do not adequately address the problem. This paper presents ECLARE, a scalable deep learning architecture that incorporates not only label text, but also label correlations, to offer accurate real-time predictions within a few milliseconds. Core contributions of ECLARE include a frugal architecture and scalable techniques to train deep models along with label correlation graphs at the scale of millions of labels. In particular, ECLARE offers predictions that are 2–14\% more accurate on both publicly available benchmark datasets as well as proprietary datasets for a related products recommendation task sourced from the Bing search engine. Code for ECLARE is available at https://github.com/Extreme-classification/ECLARE},
booktitle = {Proceedings of the Web Conference 2021},
pages = {3721–3732},
numpages = {12},
keywords = {label metadata, large-scale learning, label features, Extreme multi-label classification, product to product recommendation},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{xc_graph_2,
author = {Saini, Deepak and Jain, Arnav Kumar and Dave, Kushal and Jiao, Jian and Singh, Amit and Zhang, Ruofei and Varma, Manik},
title = {GalaXC: Graph Neural Networks with Labelwise Attention for Extreme Classification},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449937},
doi = {10.1145/3442381.3449937},
abstract = {This paper develops the GalaXC algorithm for Extreme Classification, where the task is to annotate a document with the most relevant subset of labels from an extremely large label set. Extreme classification has been successfully applied to several real world web-scale applications such as web search, product recommendation, query rewriting, etc. GalaXC identifies two critical deficiencies in leading extreme classification algorithms. First, existing approaches generally assume that documents and labels reside in disjoint sets, even though in several applications, labels and documents cohabit the same space. Second, several approaches, albeit scalable, do not utilize various forms of metadata offered by applications, such as label text and label correlations. To remedy these, GalaXC presents a framework that enables collaborative learning over joint document-label graphs at massive scales, in a way that naturally allows various auxiliary sources of information, including label metadata, to be incorporated. GalaXC also introduces a novel label-wise attention mechanism to meld high-capacity extreme classifiers with its framework. An efficient end-to-end implementation of GalaXC is presented that could be trained on a dataset with 50M labels and 97M training documents in less than 100 hours on 4 \texttimes{} V100 GPUs. This allowed GalaXC to not only scale to applications with several millions of labels, but also be up to 18\% more accurate than leading deep extreme classifiers, while being upto 2-50 \texttimes{} faster to train and 10 \texttimes{} faster to predict on benchmark datasets. GalaXC is particularly well-suited to warm-start scenarios where predictions need to be made on data points with partially revealed label sets, and was found to be up to 25\% more accurate than extreme classification algorithms specifically designed for warm start settings. In A/B tests conducted on the Bing search engine, GalaXC could improve the Click Yield (CY) and coverage by 1.52\% and 1.11\% respectively. Code for GalaXC is available at https://github.com/Extreme-classification/GalaXC},
booktitle = {Proceedings of the Web Conference 2021},
pages = {3733–3744},
numpages = {12},
keywords = {web-scale recommendation, large output spaces, sponsored search, warm start, Extreme classification},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}


@book{bakir_predicting_2007,
	abstract = {State-of-the-art algorithms and theory in a novel domain of machine learning, prediction when the output has structure.Machine learning develops intelligent computer systems that are able to generalize from previously seen examples. A new domain of machine learning, in which the prediction must satisfy the additional constraints found in structured data, poses one of machine learning's greatest challenges: learning functional dependencies between arbitrary input and output domains. This volume presents and analyzes the state of the art in machine learning algorithms and theory in this novel field. The contributors discuss applications as diverse as machine translation, document markup, computational biology, and information extraction, among others, providing a timely overview of an exciting field. Contributors Yasemin Altun, G{\"o}khan Bakir, Olivier Bousquet, Sumit Chopra, Corinna Cortes, Hal Daum{\'e} III, Ofer Dekel, Zoubin Ghahramani, Raia Hadsell, Thomas Hofmann, Fu Jie Huang, Yann LeCun, Tobias Mann, Daniel Marcu, David McAllester, Mehryar Mohri, William Stafford Noble, Fernando P{\'e}rez-Cruz, Massimiliano Pontil, Marc'Aurelio Ranzato, Juho Rousu, Craig Saunders, Bernhard Sch{\"o}lkopf, Matthias W. Seeger, Shai Shalev-Shwartz, John Shawe-Taylor, Yoram Singer, Alexander J. Smola, Sandor Szedmak, Ben Taskar, Ioannis Tsochantaridis, S.V.N Vishwanathan, Jason Weston},
	author = {Bakir, G{\"o}khan and Hofmann, Thomas and Sch{\"o}lkopf, Bernhard and Smola, Alexander J. and Taskar, Ben and Vishwanathan, S.V.N},
	doi = {10.7551/mitpress/7443.001.0001},
	isbn = {978-0-262-25569-1},
	month = jul,
	publisher = {The MIT Press},
	title = {Predicting {Structured} {Data}},
	url = {https://doi.org/10.7551/mitpress/7443.001.0001},
	year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.7551/mitpress/7443.001.0001}}


@inproceedings{NIPS2015_52d2752b,
	author = {Kuleshov, Volodymyr and Liang, Percy S},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Calibrated Structured Prediction},
	url = {https://proceedings.neurips.cc/paper/2015/file/52d2752b150f9c35ccb6869cbf074e48-Paper.pdf},
	volume = {28},
	year = {2015},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2015/file/52d2752b150f9c35ccb6869cbf074e48-Paper.pdf}}




@inproceedings{NEURIPS2018_b3dd760e,
	author = {Korba, Anna and Garcia, Alexandre and d\textquotesingle Alch\'{e}-Buc, Florence},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {A Structured Prediction Approach for Label Ranking},
	url = {https://proceedings.neurips.cc/paper/2018/file/b3dd760eb02d2e669c604f6b2f1e803f-Paper.pdf},
	volume = {31},
	year = {2018},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2018/file/b3dd760eb02d2e669c604f6b2f1e803f-Paper.pdf}}

@article{Petersen2016FrchetRF,
  title={Fr{\'e}chet regression for random objects with Euclidean predictors},
  author={Alexander Petersen and Hans-Georg Muller},
  journal={The Annals of Statistics},
  year={2016}
}


@inproceedings{NEURIPS2018_f6185f0e,
	author = {Rudi, Alessandro and Ciliberto, Carlo and Marconi, GianMaria and Rosasco, Lorenzo},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Manifold Structured Prediction},
	url = {https://proceedings.neurips.cc/paper/2018/file/f6185f0ef02dcaec414a3171cd01c697-Paper.pdf},
	volume = {31},
	year = {2018},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2018/file/f6185f0ef02dcaec414a3171cd01c697-Paper.pdf}}


@inproceedings{NEURIPS2019_ea697987,
	author = {Graber, Colin and Schwing, Alexander},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Graph Structured Prediction Energy Networks},
	url = {https://proceedings.neurips.cc/paper/2019/file/ea6979872125d5acbac6068f186a0359-Paper.pdf},
	volume = {32},
	year = {2019},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2019/file/ea6979872125d5acbac6068f186a0359-Paper.pdf}}

@inproceedings{
vishwakarma2022lifting,
title={Lifting Weak Supervision To Structured Prediction},
author={Harit Vishwakarma and Frederic Sala},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=Cntmos_Ndf0}
}

@inproceedings{
shin2022universalizing,
title={Universalizing Weak Supervision},
author={Changho Shin and Winfred Li and Harit Vishwakarma and Nicholas Carl Roberts and Frederic Sala},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=YpPiNigTzMT}
}

@inproceedings{
roberts2022autowsbench,
title={Auto{WS}-Bench-101: Benchmarking Automated Weak Supervision with 100 Labels},
author={Nicholas Roberts and Xintong Li and Tzu-Heng Huang and Dyah Adila and Spencer Schoenberg and Cheng-Yu Liu and Lauren Pick and Haotian Ma and Aws Albarghouthi and Frederic Sala},
booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2022},
url={https://openreview.net/forum?id=nQZHEunntbJ}
}

@misc{altclip,
      title={AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities}, 
      author={Zhongzhi Chen and Guang Liu and Bo-Wen Zhang and Fulong Ye and Qinghong Yang and Ledell Wu},
      year={2022},
      eprint={2211.06679},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@InProceedings{align,
  title = 	 {Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision},
  author =       {Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {4904--4916},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/jia21b/jia21b.pdf},
  url = 	 {https://proceedings.mlr.press/v139/jia21b.html},
  abstract = 	 {Pre-trained representations are becoming crucial for many NLP and perception tasks. While representation learning in NLP has transitioned to training on raw text without human annotations, visual and vision-language representations still rely heavily on curated training datasets that are expensive or require expert knowledge. For vision applications, representations are mostly learned using datasets with explicit class labels such as ImageNet or OpenImages. For vision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all involve a non-trivial data collection (and cleaning) process. This costly curation process limits the size of datasets and hence hinders the scaling of trained models. In this paper, we leverage a noisy dataset of over one billion image alt-text pairs, obtained without expensive filtering or post-processing steps in the Conceptual Captions dataset. A simple dual-encoder architecture learns to align visual and language representations of the image and text pairs using a contrastive loss. We show that the scale of our corpus can make up for its noise and leads to state-of-the-art representations even with such a simple learning scheme. Our visual representation achieves strong performance when transferred to classification tasks such as ImageNet and VTAB. The aligned visual and language representations enables zero-shot image classification and also set new state-of-the-art results on Flickr30K and MSCOCO image-text retrieval benchmarks, even when compared with more sophisticated cross-attention models. The representations also enable cross-modality search with complex text and text + image queries.}
}

@inproceedings{gao2021simcse,
   title={{SimCSE}: Simple Contrastive Learning of Sentence Embeddings},
   author={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
   booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
   year={2021}
}

@article{Partalas2015LSHTCAB,
  title={LSHTC: A Benchmark for Large-Scale Text Classification},
  author={Ioannis Partalas and Aris Kosmopoulos and Nicolas Baskiotis and Thierry Arti{\`e}res and Georgios Paliouras and {\'E}ric Gaussier and Ion Androutsopoulos and Massih-Reza Amini and Patrick Gallinari},
  journal={ArXiv},
  year={2015},
  volume={abs/1503.08581}
}

@INPROCEEDINGS{resnet,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  doi={10.1109/CVPR.2016.90}}

@inproceedings{Goodfellow14,
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
title = {Generative Adversarial Nets},
year = {2014},
booktitle = {Advances in Neural Information Processing Systems},
pages = {2672–2680},
numpages = {9},
location = {Montreal, Canada},
}


@inproceedings{Vershynin2010IntroductionTT,
  title={Introduction to the non-asymptotic analysis of random matrices},
  author={Roman Vershynin},
  booktitle={Compressed Sensing},
  year={2010},
  url={https://api.semanticscholar.org/CorpusID:133440}
}


@InProceedings{pmlr-v70-guo17a,
  title = 	 {On Calibration of Modern Neural Networks},
  author =       {Chuan Guo and Geoff Pleiss and Yu Sun and Kilian Q. Weinberger},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1321--1330},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/guo17a/guo17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/guo17a.html},
  abstract = 	 {Confidence calibration – the problem of predicting probability estimates representative of the true correctness likelihood – is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling – a single-parameter variant of Platt Scaling – is surprisingly effective at calibrating predictions.}
}


@article{10.3150/14-BEJ645,
	author = {Stanislav Minsker},
	doi = {10.3150/14-BEJ645},
	journal = {Bernoulli},
	keywords = {distributed computing, heavy-tailed noise, large deviations, linear models, low-rank matrix estimation, Principal Component Analysis, robust estimation},
	number = {4},
	pages = {2308 -- 2335},
	publisher = {Bernoulli Society for Mathematical Statistics and Probability},
	title = {{Geometric median and robust estimation in Banach spaces}},
	url = {https://doi.org/10.3150/14-BEJ645},
	volume = {21},
	year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.3150/14-BEJ645}}


@InProceedings{pmlr-v99-cherapanamjeri19b,
  title = 	 {Fast Mean Estimation with Sub-Gaussian Rates},
  author =       {Cherapanamjeri, Yeshwanth and Flammarion, Nicolas and Bartlett, Peter L.},
  booktitle = 	 {Proceedings of the Thirty-Second Conference on Learning Theory},
  pages = 	 {786--806},
  year = 	 {2019},
  editor = 	 {Beygelzimer, Alina and Hsu, Daniel},
  volume = 	 {99},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {25--28 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v99/cherapanamjeri19b/cherapanamjeri19b.pdf},
  url = 	 {https://proceedings.mlr.press/v99/cherapanamjeri19b.html},
  abstract = 	 {We propose an estimator for the mean of a random vector in $\mathbb{R}^d$ that can be computed in time $O(n^{3.5}+n^2d)$ for $n$ i.i.d.&nbsp;samples and that has error bounds matching the sub-Gaussian case. The only assumptions we make about the data distribution are that it has finite mean and covariance; in particular, we make no assumptions about higher-order moments. Like the polynomial time estimator introduced by Hopkins (2018), which is based on the sum-of-squares hierarchy, our estimator achieves optimal statistical efficiency in this challenging setting, but it has a significantly faster runtime and a simpler analysis.}
}

@article{JMLR:v17:14-273,
  author  = {Daniel Hsu and Sivan Sabato},
  title   = {Loss Minimization and Parameter Estimation with Heavy Tails},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {18},
  pages   = {1-40},
  url     = {http://jmlr.org/papers/v17/14-273.html}
}

@misc{lerasle2011robust,
      title={Robust empirical mean Estimators}, 
      author={M. Lerasle and R. I. Oliveira},
      year={2011},
      eprint={1112.3914},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}


