{
  "title": "A Stochastic Gradient Tracking Algorithm for Decentralized Optimization With Inexact Communication",
  "authors": [
    "Suhail M. Shah",
    "Raghu Bollapragada"
  ],
  "submission_date": "2023-07-27T15:32:44+00:00",
  "revised_dates": [],
  "abstract": "Decentralized optimization is typically studied under the assumption of noise-free transmission. However, real-world scenarios often involve the presence of noise due to factors such as additive white Gaussian noise channels or probabilistic quantization of transmitted data. These sources of noise have the potential to degrade the performance of decentralized optimization algorithms if not effectively addressed. In this paper, we focus on the noisy communication setting and propose an algorithm that bridges the performance gap caused by communication noise while also mitigating other challenges like data heterogeneity. We establish theoretical results of the proposed algorithm that quantify the effect of communication noise and gradient noise on the performance of the algorithm. Notably, our algorithm achieves the optimal convergence rate for minimizing strongly convex, smooth functions in the context of inexact communication and stochastic gradients. Finally, we illustrate the superior performance of the proposed algorithm compared to its state-of-the-art counterparts on machine learning problems using MNIST and CIFAR-10 datasets.",
  "categories": [
    "math.OC"
  ],
  "primary_category": "math.OC",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14942",
  "pdf_url": "https://arxiv.org/pdf/2307.14942v1",
  "comment": "34 pages, 4 figures",
  "num_versions": null,
  "size_before_bytes": 572403,
  "size_after_bytes": 183261
}