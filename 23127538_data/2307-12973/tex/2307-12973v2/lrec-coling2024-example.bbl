\begin{thebibliography}{51}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Basile et~al.(2019)Basile, Bosco, Fersini, Nozza, Patti,
  Rangel~Pardo, Rosso, and Sanguinetti}]{basile-etal-2019-semeval}
Valerio Basile, Cristina Bosco, Elisabetta Fersini, Debora Nozza, Viviana
  Patti, Francisco~Manuel Rangel~Pardo, Paolo Rosso, and Manuela Sanguinetti.
  2019.
\newblock \href {https://doi.org/10.18653/v1/S19-2007} {{S}em{E}val-2019 task
  5: Multilingual detection of hate speech against immigrants and women in
  {T}witter}.
\newblock In \emph{Proceedings of the 13th International Workshop on Semantic
  Evaluation}, pages 54--63, Minneapolis, Minnesota, USA. Association for
  Computational Linguistics.

\bibitem[{Basile et~al.(2021)Basile, Fell, Fornaciari, Hovy, Paun, Plank,
  Poesio, and Uma}]{basile-etal-2021-need}
Valerio Basile, Michael Fell, Tommaso Fornaciari, Dirk Hovy, Silviu Paun,
  Barbara Plank, Massimo Poesio, and Alexandra Uma. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.bppf-1.3} {We need to
  consider disagreement in evaluation}.
\newblock In \emph{Proceedings of the 1st Workshop on Benchmarking: Past,
  Present and Future}, pages 15--21, Online. Association for Computational
  Linguistics.

\bibitem[{Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei}]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei. 2020.
\newblock \href
  {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}
  {Language models are few-shot learners}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 1877--1901. Curran Associates, Inc.

\bibitem[{Chung et~al.(2022)Chung, Hou, Longpre, Zoph, Tay, Fedus, Li, Wang,
  Dehghani, Brahma, Webson, Gu, Dai, Suzgun, Chen, Chowdhery, Castro-Ros,
  Pellat, Robinson, Valter, Narang, Mishra, Yu, Zhao, Huang, Dai, Yu, Petrov,
  Chi, Dean, Devlin, Roberts, Zhou, Le, and Wei}]{chung2022scaling}
Hyung~Won Chung, Le~Hou, Shayne Longpre, Barret Zoph, Yi~Tay, William Fedus,
  Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson,
  Shixiang~Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha
  Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter,
  Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew
  Dai, Hongkun Yu, Slav Petrov, Ed~H. Chi, Jeff Dean, Jacob Devlin, Adam
  Roberts, Denny Zhou, Quoc~V. Le, and Jason Wei. 2022.
\newblock \href {http://arxiv.org/abs/2210.11416} {Scaling
  instruction-finetuned language models}.
\newblock \emph{arXiv preprint arXiv:2210.11416}.

\bibitem[{Cohen(1960)}]{Cohen1960ACO}
Jacob Cohen. 1960.
\newblock A coefficient of agreement for nominal scales.
\newblock \emph{Educational and Psychological Measurement}, 20:37 -- 46.

\bibitem[{Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova}]{devlin-etal-2019-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.
\newblock \href {https://doi.org/10.18653/v1/N19-1423} {{BERT}: Pre-training of
  deep bidirectional transformers for language understanding}.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186,
  Minneapolis, Minnesota. Association for Computational Linguistics.

\bibitem[{Fleiss(1971)}]{Fleiss1971MeasuringNS}
Joseph~L. Fleiss. 1971.
\newblock Measuring nominal scale agreement among many raters.
\newblock \emph{Psychological Bulletin}, 76:378--382.

\bibitem[{Fort et~al.(2011)Fort, Adda, and Cohen}]{fort-etal-2011-last}
Kar{\"e}n Fort, Gilles Adda, and K.~Bretonnel Cohen. 2011.
\newblock \href {https://doi.org/10.1162/COLI_a_00057} {Last words: {A}mazon
  {M}echanical {T}urk: Gold mine or coal mine?}
\newblock \emph{Computational Linguistics}, 37(2):413--420.

\bibitem[{Gilardi et~al.(2023)Gilardi, Alizadeh, and
  Kubli}]{gilardi2023chatgpt}
Fabrizio Gilardi, Meysam Alizadeh, and Ma{\"e}l Kubli. 2023.
\newblock Chat{GPT} outperforms crowd-workers for text-annotation tasks.
\newblock \emph{arXiv preprint arXiv:2303.15056}.

\bibitem[{He et~al.(2024)He, Huang, Ding, Rohatgi, and Huang}]{he2024if}
Zeyu He, Chieh-Yang Huang, Chien-Kuang~Cornelia Ding, Shaurya Rohatgi, and
  Ting-Hao'Kenneth' Huang. 2024.
\newblock If in a crowdsourced data annotation pipeline, a gpt-4.
\newblock \emph{arXiv preprint arXiv:2402.16795}.

\bibitem[{Hovy(2015)}]{hovy-2015-demographic}
Dirk Hovy. 2015.
\newblock \href {https://doi.org/10.3115/v1/P15-1073} {Demographic factors
  improve classification performance}.
\newblock In \emph{Proceedings of the 53rd Annual Meeting of the Association
  for Computational Linguistics and the 7th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pages 752--762,
  Beijing, China. Association for Computational Linguistics.

\bibitem[{Hovy et~al.(2013)Hovy, Berg-Kirkpatrick, Vaswani, and
  Hovy}]{hovy-etal-2013-learning}
Dirk Hovy, Taylor Berg-Kirkpatrick, Ashish Vaswani, and Eduard Hovy. 2013.
\newblock \href {https://aclanthology.org/N13-1132} {Learning whom to trust
  with {MACE}}.
\newblock In \emph{Proceedings of the 2013 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 1120--1130, Atlanta, Georgia. Association for
  Computational Linguistics.

\bibitem[{Hovy et~al.(2015)Hovy, Johannsen, and S\o{}gaard}]{hovy2015user}
Dirk Hovy, Anders Johannsen, and Anders S\o{}gaard. 2015.
\newblock \href {https://doi.org/10.1145/2736277.2741141} {User review sites as
  a resource for large-scale sociolinguistic studies}.
\newblock In \emph{Proceedings of the 24th International Conference on World
  Wide Web}, WWW '15, page 452–461. International World Wide Web Conferences
  Steering Committee.

\bibitem[{Huang et~al.(2023)Huang, Kwak, and An}]{Huang_2023}
Fan Huang, Haewoon Kwak, and Jisun An. 2023.
\newblock \href {https://doi.org/10.1145/3543873.3587368} {{Is {ChatGPT} better
  than Human Annotators? Potential and Limitations of {ChatGPT} in Explaining
  Implicit Hate Speech}}.
\newblock In \emph{Companion Proceedings of the {ACM} Web Conference 2023}.
  {ACM}.

\bibitem[{Hung et~al.(2023)Hung, Lauscher, Hovy, Ponzetto, and
  Glava{\v{s}}}]{hung-etal-2023-demographic}
Chia-Chien Hung, Anne Lauscher, Dirk Hovy, Simone~Paolo Ponzetto, and Goran
  Glava{\v{s}}. 2023.
\newblock \href {https://aclanthology.org/2023.findings-eacl.116} {Can
  demographic factors improve text classification? revisiting demographic
  adaptation in the age of transformers}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EACL 2023}, pages 1565--1580, Dubrovnik, Croatia. Association for
  Computational Linguistics.

\bibitem[{Klie et~al.(2023)Klie, Lee, Stowe, {\c{S}}ahin, Moosavi, Bates,
  Petrak, Eckart De~Castilho, and Gurevych}]{klie-etal-2023-lessons}
Jan-Christoph Klie, Ji-Ung Lee, Kevin Stowe, G{\"o}zde {\c{S}}ahin,
  Nafise~Sadat Moosavi, Luke Bates, Dominic Petrak, Richard Eckart De~Castilho,
  and Iryna Gurevych. 2023.
\newblock \href {https://aclanthology.org/2023.eacl-main.261} {Lessons learned
  from a citizen science project for natural language processing}.
\newblock In \emph{Proceedings of the 17th Conference of the European Chapter
  of the Association for Computational Linguistics}, pages 3594--3608,
  Dubrovnik, Croatia. Association for Computational Linguistics.

\bibitem[{Krippendorff(2011)}]{krippendorff1computing}
Klaus Krippendorff. 2011.
\newblock Computing krippendorff's alpha-reliability.
\newblock \emph{Computing}, 1:25--2011.

\bibitem[{Kristensen-McLachlan et~al.(2023)Kristensen-McLachlan, Canavan,
  Kardos, Jacobsen, and Aarøe}]{kristensenmclachlan2023chatbots}
Ross~Deans Kristensen-McLachlan, Miceal Canavan, Márton Kardos, Mia Jacobsen,
  and Lene Aarøe. 2023.
\newblock \href {http://arxiv.org/abs/2311.05769} {Chatbots are not reliable
  text annotators}.

\bibitem[{Kuzman et~al.(2023)Kuzman, Mozetič, and
  Ljubešić}]{kuzman2023chatgpt}
Taja Kuzman, Igor Mozetič, and Nikola Ljubešić. 2023.
\newblock \href {http://arxiv.org/abs/2303.03953} {{ChatGPT: Beginning of an
  End of Manual Linguistic Data Annotation? Use Case of Automatic Genre
  Identification}}.
\newblock \emph{arXiv preprint arXiv:2303.03953}.

\bibitem[{Lee et~al.(2023)Lee, An, and Thorne}]{lee2023large}
Noah Lee, Na~Min An, and James Thorne. 2023.
\newblock \href {http://arxiv.org/abs/2305.13788} {Can large language models
  infer and disagree like humans?}
\newblock \emph{arXiv preprint arXiv:2305.13788}.

\bibitem[{Liu et~al.(2023)Liu, Yuan, Fu, Jiang, Hayashi, and
  Neubig}]{liu2023pre}
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and
  Graham Neubig. 2023.
\newblock \href {https://arxiv.org/abs/2107.13586} {{Pre-train, prompt, and
  predict: A systematic survey of prompting methods in natural language
  processing}}.
\newblock \emph{ACM Computing Surveys}, 55(9):1--35.

\bibitem[{Liu et~al.(2022)Liu, Zhang, Feng, and
  Vosoughi}]{liu-etal-2022-aligning}
Ruibo Liu, Ge~Zhang, Xinyu Feng, and Soroush Vosoughi. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.findings-naacl.18} {Aligning
  generative language models with human values}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  NAACL 2022}, pages 241--252, Seattle, United States. Association for
  Computational Linguistics.

\bibitem[{Longpre et~al.(2023)Longpre, Hou, Vu, Webson, Chung, Tay, Zhou, Le,
  Zoph, Wei et~al.}]{longpre2023flan}
Shayne Longpre, Le~Hou, Tu~Vu, Albert Webson, Hyung~Won Chung, Yi~Tay, Denny
  Zhou, Quoc~V Le, Barret Zoph, Jason Wei, et~al. 2023.
\newblock The flan collection: Designing data and methods for effective
  instruction tuning.
\newblock \emph{arXiv preprint arXiv:2301.13688}.

\bibitem[{M{\"o}kander et~al.(2023)M{\"o}kander, Schuett, Kirk, and
  Floridi}]{mokander2023auditing}
Jakob M{\"o}kander, Jonas Schuett, Hannah~Rose Kirk, and Luciano Floridi. 2023.
\newblock \href
  {https://link.springer.com/article/10.1007/s43681-023-00289-2#citeas}
  {Auditing large language models: a three-layered approach}.
\newblock \emph{AI and Ethics}, pages 1--31.

\bibitem[{Muennighoff et~al.(2023)Muennighoff, Tazi, Magne, and
  Reimers}]{muennighoff-etal-2023-mteb}
Niklas Muennighoff, Nouamane Tazi, Loic Magne, and Nils Reimers. 2023.
\newblock \href {https://aclanthology.org/2023.eacl-main.148} {{MTEB}: Massive
  text embedding benchmark}.
\newblock In \emph{Proceedings of the 17th Conference of the European Chapter
  of the Association for Computational Linguistics}, pages 2014--2037,
  Dubrovnik, Croatia. Association for Computational Linguistics.

\bibitem[{Muennighoff et~al.(2022)Muennighoff, Wang, Sutawika, Roberts,
  Biderman, Scao, Bari, Shen, Yong, Schoelkopf, Tang, Radev, Aji, Almubarak,
  Albanie, Alyafeai, Webson, Raff, and Raffel}]{muennighoff2022crosslingual}
Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella
  Biderman, Teven~Le Scao, M~Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey
  Schoelkopf, Xiangru Tang, Dragomir Radev, Alham~Fikri Aji, Khalid Almubarak,
  Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin Raffel.
  2022.
\newblock \href {http://arxiv.org/abs/2211.01786} {Crosslingual generalization
  through multitask finetuning}.
\newblock \emph{arXiv preprint arXiv:2211.01786}.

\bibitem[{Nozza(2021)}]{nozza-2021-exposing}
Debora Nozza. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.acl-short.114} {Exposing the
  limits of zero-shot cross-lingual hate speech detection}.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 2: Short Papers)}, pages 907--914,
  Online. Association for Computational Linguistics.

\bibitem[{Passonneau and Carpenter(2014)}]{passonneau-carpenter-2014-benefits}
Rebecca~J. Passonneau and Bob Carpenter. 2014.
\newblock \href {https://doi.org/10.1162/tacl_a_00185} {The benefits of a model
  of annotation}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  2:311--326.

\bibitem[{Paun et~al.(2018)Paun, Carpenter, Chamberlain, Hovy, Kruschwitz, and
  Poesio}]{paun-etal-2018-comparing}
Silviu Paun, Bob Carpenter, Jon Chamberlain, Dirk Hovy, Udo Kruschwitz, and
  Massimo Poesio. 2018.
\newblock \href {https://doi.org/10.1162/tacl_a_00040} {Comparing {B}ayesian
  models of annotation}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  6:571--585.

\bibitem[{Plank(2022)}]{plank-2022-problem}
Barbara Plank. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.731} {The
  {``}problem{''} of human label variation: On ground truth in data, modeling
  and evaluation}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 10671--10682, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Plank et~al.(2014)Plank, Hovy, and
  S{\o}gaard}]{plank-etal-2014-linguistically}
Barbara Plank, Dirk Hovy, and Anders S{\o}gaard. 2014.
\newblock \href {https://doi.org/10.3115/v1/P14-2083} {Linguistically debatable
  or just plain wrong?}
\newblock In \emph{Proceedings of the 52nd Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, pages 507--511,
  Baltimore, Maryland. Association for Computational Linguistics.

\bibitem[{{{Plaza-del-Arco}} et~al.(2022){{Plaza-del-Arco}},
  Mart{\'\i}n-Valdivia, and
  Klinger}]{plaza-del-arco-etal-2022-natural-emotions}
Flor~Miriam {{Plaza-del-Arco}}, Mar{\'\i}a-Teresa Mart{\'\i}n-Valdivia, and
  Roman Klinger. 2022.
\newblock \href {https://aclanthology.org/2022.coling-1.592} {{{Natural
  Language Inference Prompts for Zero-shot Emotion Classification in Text
  across Corpora}}}.
\newblock In \emph{Proceedings of the 29th International Conference on
  Computational Linguistics}, pages 6805--6817, Gyeongju, Republic of Korea.
  International Committee on Computational Linguistics.

\bibitem[{{{Plaza-del-Arco}} et~al.(2023){{Plaza-del-Arco}}, Nozza, and
  Hovy}]{plaza-del-arco-etal-2023-respectful}
Flor~Miriam {{Plaza-del-Arco}}, Debora Nozza, and Dirk Hovy. 2023.
\newblock \href {https://doi.org/10.18653/v1/2023.woah-1.6} {{{Respectful or
  Toxic? Using Zero-Shot Learning with Language Models to Detect Hate
  Speech}}}.
\newblock In \emph{The 7th Workshop on Online Abuse and Harms (WOAH)}, pages
  60--68, Toronto, Canada. Association for Computational Linguistics.

\bibitem[{Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu}]{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu. 2020.
\newblock \href {https://dl.acm.org/doi/abs/10.5555/3455716.3455856} {Exploring
  the limits of transfer learning with a unified text-to-text transformer}.
\newblock \emph{The Journal of Machine Learning Research}, 21(1).

\bibitem[{Rosenthal et~al.(2021)Rosenthal, Atanasova, Karadzhov, Zampieri, and
  Nakov}]{rosenthal-etal-2021-solid}
Sara Rosenthal, Pepa Atanasova, Georgi Karadzhov, Marcos Zampieri, and Preslav
  Nakov. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.findings-acl.80} {{SOLID}: A
  large-scale semi-supervised dataset for offensive language identification}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL-IJCNLP 2021}, pages 915--928, Online. Association for Computational
  Linguistics.

\bibitem[{Rottger et~al.(2022)Rottger, Vidgen, Hovy, and
  Pierrehumbert}]{rottger-etal-2022-two}
Paul Rottger, Bertie Vidgen, Dirk Hovy, and Janet Pierrehumbert. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.naacl-main.13} {Two
  contrasting data annotation paradigms for subjective {NLP} tasks}.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 175--190, Seattle, United States. Association for
  Computational Linguistics.

\bibitem[{Sanh et~al.(2022)Sanh, Webson, Raffel, Bach, Sutawika, Alyafeai,
  Chaffin, Stiegler, Scao, Raja, Dey, Bari, Xu, Thakker, Sharma, Szczechla,
  Kim, Chhablani, Nayak, Datta, Chang, Jiang, Wang, Manica, Shen, Yong, Pandey,
  Bawden, Wang, Neeraj, Rozen, Sharma, Santilli, Fevry, Fries, Teehan, Bers,
  Biderman, Gao, Wolf, and Rush}]{sanh2022multitask}
Victor Sanh, Albert Webson, Colin Raffel, Stephen~H. Bach, Lintang Sutawika,
  Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven~Le Scao, Arun Raja,
  Manan Dey, M~Saiful Bari, Canwen Xu, Urmish Thakker, Shanya~Sharma Sharma,
  Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta,
  Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,
  Zheng~Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj,
  Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason~Alan
  Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf, and
  Alexander~M. Rush. 2022.
\newblock \href {http://arxiv.org/abs/2110.08207} {Multitask prompted training
  enables zero-shot task generalization}.
\newblock \emph{arXiv preprint arXiv:2110.08207}.

\bibitem[{Shah et~al.(2020)Shah, Schwartz, and
  Hovy}]{shah-etal-2020-predictive}
Deven~Santosh Shah, H.~Andrew Schwartz, and Dirk Hovy. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.468} {Predictive
  biases in natural language processing models: A conceptual framework and
  overview}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 5248--5264, Online. Association for
  Computational Linguistics.

\bibitem[{Smit et~al.(2020)Smit, Jain, Rajpurkar, Pareek, Ng, and
  Lungren}]{smit-etal-2020-combining}
Akshay Smit, Saahil Jain, Pranav Rajpurkar, Anuj Pareek, Andrew Ng, and Matthew
  Lungren. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.117} {Combining
  automatic labelers and expert annotations for accurate radiology report
  labeling using {BERT}}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1500--1519, Online. Association
  for Computational Linguistics.

\bibitem[{Snow et~al.(2008)Snow, O{'}Connor, Jurafsky, and
  Ng}]{snow-etal-2008-cheap}
Rion Snow, Brendan O{'}Connor, Daniel Jurafsky, and Andrew Ng. 2008.
\newblock \href {https://aclanthology.org/D08-1027} {Cheap and fast {--} but is
  it good? evaluating non-expert annotations for natural language tasks}.
\newblock In \emph{Proceedings of the 2008 Conference on Empirical Methods in
  Natural Language Processing}, pages 254--263, Honolulu, Hawaii. Association
  for Computational Linguistics.

\bibitem[{Sottana et~al.(2023)Sottana, Liang, Zou, and
  Yuan}]{sottana-etal-2023-evaluation}
Andrea Sottana, Bin Liang, Kai Zou, and Zheng Yuan. 2023.
\newblock \href {https://doi.org/10.18653/v1/2023.emnlp-main.543} {Evaluation
  metrics in the era of {GPT}-4: Reliably evaluating large language models on
  sequence to sequence tasks}.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing}, pages 8776--8788, Singapore. Association for
  Computational Linguistics.

\bibitem[{{Stanford AI Lab Blog}(2019)}]{stanford-ai-weak-supervision}
{Stanford AI Lab Blog}. 2019.
\newblock Weak supervision.
\newblock \url{http://ai.stanford.edu/blog/weak-supervision/}.

\bibitem[{Su et~al.(2022)Su, Kasai, Wu, Shi, Wang, Xin, Zhang, Ostendorf,
  Zettlemoyer, Smith, and Yu}]{su2022selective}
Hongjin Su, Jungo Kasai, Chen~Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui
  Zhang, Mari Ostendorf, Luke Zettlemoyer, Noah~A Smith, and Tao Yu. 2022.
\newblock \href {https://arxiv.org/pdf/2209.01975.pdf} {Selective annotation
  makes language models better few-shot learners}.
\newblock \emph{arXiv preprint arXiv:2209.01975}.

\bibitem[{Taori et~al.(2023)Taori, Gulrajani, Zhang, Dubois, Li, Guestrin,
  Liang, and Hashimoto}]{alpaca}
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
  Guestrin, Percy Liang, and Tatsunori~B. Hashimoto. 2023.
\newblock {Stanford Alpaca: An Instruction-following LLaMA model}.
\newblock \url{https://github.com/tatsu-lab/stanford_alpaca}.

\bibitem[{Tay et~al.(2023)Tay, Dehghani, Tran, Garcia, Wei, Wang, Chung,
  Shakeri, Bahri, Schuster, Zheng, Zhou, Houlsby, and Metzler}]{tay2023ul2}
Yi~Tay, Mostafa Dehghani, Vinh~Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang,
  Hyung~Won Chung, Siamak Shakeri, Dara Bahri, Tal Schuster, Huaixiu~Steven
  Zheng, Denny Zhou, Neil Houlsby, and Donald Metzler. 2023.
\newblock \href {http://arxiv.org/abs/2205.05131} {Ul2: Unifying language
  learning paradigms}.
\newblock \emph{arXiv preprint arXiv:2205.05131}.

\bibitem[{T{\"o}rnberg(2023)}]{tornberg2023chatgpt}
Petter T{\"o}rnberg. 2023.
\newblock Chat{GPT-4} outperforms experts and crowd workers in annotating
  political twitter messages with zero-shot learning.
\newblock \emph{arXiv preprint arXiv:2304.06588}.

\bibitem[{Triantafillou et~al.(2020)Triantafillou, Zhu, Dumoulin, Lamblin,
  Evci, Xu, Goroshin, Gelada, Swersky, Manzagol, and
  Larochelle}]{triantafillou2020metadataset}
Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku Evci,
  Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine
  Manzagol, and Hugo Larochelle. 2020.
\newblock \href {https://openreview.net/forum?id=rkgAGAVKPr} {Meta-dataset: A
  dataset of datasets for learning to learn from few examples}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Wang et~al.(2022)Wang, Mishra, Alipoormolabashi, Kordi, Mirzaei,
  Naik, Ashok, Dhanasekaran, Arunkumar, Stap, Pathak, Karamanolakis, Lai,
  Purohit, Mondal, Anderson, Kuznia, Doshi, Pal, Patel, Moradshahi, Parmar,
  Purohit, Varshney, Kaza, Verma, Puri, Karia, Doshi, Sampat, Mishra, Reddy~A,
  Patro, Dixit, and Shen}]{wang-etal-2022-super}
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza
  Mirzaei, Atharva Naik, Arjun Ashok, Arut~Selvan Dhanasekaran, Anjana
  Arunkumar, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai,
  Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi,
  Kuntal~Kumar Pal, Maitreya Patel, Mehrad Moradshahi, Mihir Parmar, Mirali
  Purohit, Neeraj Varshney, Phani~Rohitha Kaza, Pulkit Verma, Ravsehaj~Singh
  Puri, Rushang Karia, Savan Doshi, Shailaja~Keyur Sampat, Siddhartha Mishra,
  Sujan Reddy~A, Sumanta Patro, Tanay Dixit, and Xudong Shen. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.340}
  {Super-{N}atural{I}nstructions: Generalization via declarative instructions
  on 1600+ {NLP} tasks}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 5085--5109, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Wei et~al.(2022)Wei, Tay, Bommasani, Raffel, Zoph, Borgeaud,
  Yogatama, Bosma, Zhou, Metzler, Chi, Hashimoto, Vinyals, Liang, Dean, and
  Fedus}]{wei2022emergent}
Jason Wei, Yi~Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian
  Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed~H.
  Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William
  Fedus. 2022.
\newblock \href {http://arxiv.org/abs/2206.07682} {Emergent abilities of large
  language models}.
\newblock \emph{arXiv preprint arXiv:2206.07682}.

\bibitem[{Xue et~al.(2021)Xue, Constant, Roberts, Kale, Al-Rfou, Siddhant,
  Barua, and Raffel}]{xue-etal-2021-mt5}
Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya
  Siddhant, Aditya Barua, and Colin Raffel. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.naacl-main.41} {m{T}5: A
  massively multilingual pre-trained text-to-text transformer}.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 483--498, Online. Association for Computational
  Linguistics.

\bibitem[{Zhao et~al.(2023)Zhao, Zhou, Li, Tang, Wang, Hou, Min, Zhang, Zhang,
  Dong, Du, Yang, Chen, Chen, Jiang, Ren, Li, Tang, Liu, Liu, Nie, and
  Wen}]{zhao2023survey}
Wayne~Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,
  Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang,
  Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang,
  Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023.
\newblock \href {http://arxiv.org/abs/2303.18223} {A survey of large language
  models}.
\newblock \emph{arXiv preprint arXiv:2303.18223}.

\end{thebibliography}
