{
  "title": "Efficient Multiuser AI Downloading via Reusable Knowledge Broadcasting",
  "authors": [
    "Hai Wu",
    "Qunsong Zeng",
    "Kaibin Huang"
  ],
  "submission_date": "2023-07-28T05:30:19+00:00",
  "revised_dates": [],
  "abstract": "For the 6G mobile networks, in-situ model downloading has emerged as an important use case to enable real-time adaptive artificial intelligence on edge devices. However, the simultaneous downloading of diverse and high-dimensional models to multiple devices over wireless links presents a significant communication bottleneck. To overcome the bottleneck, we propose the framework of model broadcasting and assembling (MBA), which represents the first attempt on leveraging reusable knowledge, referring to shared parameters among tasks, to enable parameter broadcasting to reduce communication overhead. The MBA framework comprises two key components. The first, the MBA protocol, defines the system operations including parameter selection from a model library, power control for broadcasting, and model assembling at devices. The second component is the joint design of parameter-selection-and-power-control (PS-PC), which provides guarantees on devices' model performance and minimizes the downloading latency. The corresponding optimization problem is simplified by decomposition into the sequential PS and PC sub-problems without compromising its optimality. The PS sub-problem is solved efficiently by designing two efficient algorithms. On one hand, the low-complexity algorithm of greedy parameter selection features the construction of candidate model sets and a selection metric, both of which are designed under the criterion of maximum reusable knowledge among tasks. On the other hand, the optimal tree-search algorithm gains its efficiency via the proposed construction of a compact binary tree pruned using model architecture constraints and an intelligent branch-and-bound search. Given optimal PS, the optimal PC policy is derived in closed form. Extensive experiments demonstrate the substantial reduction in downloading latency achieved by the proposed MBA compared to traditional model downloading.",
  "categories": [
    "cs.IT",
    "cs.AI"
  ],
  "primary_category": "cs.IT",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15316",
  "pdf_url": "https://arxiv.org/pdf/2307.15316v1",
  "comment": "Submitted to IEEE for possible publication",
  "num_versions": null,
  "size_before_bytes": 708683,
  "size_after_bytes": 105941
}