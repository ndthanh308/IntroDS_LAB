\section{Communication protocol} \label{sec:comm-protocol}

In this section, we give a deterministic communication protocol for a bounded integral matrix $\ms$ when it has the crucial property that any submatrix contains a large monochromatic rectangle.

\begin{lemma}\label{lem:comm-protocol}
Let $0 < \delta < 1$.
Let $\mm \in \{0, 1, \dots, \Delta\}^{A \times B}$ be a bounded integral matrix with rank $r$,
and suppose for any submatrix $\ms \defeq \mm[A', B']$ where $A' \subseteq A$ and $B' \subseteq B$,
there is a monochromatic rectangle in $\ms$ of size $\geq \delta |A'||B'|$.
Then,
\[
	CC^{\det}(\mm) \leq \Theta \left( \log r \cdot \log \left( \frac{r}{\delta} \log(\Delta + 1) \right) \right).
\]
\end{lemma}

We begin by proving two helper lemmas relating to $\mm$ and the rank of its submatrices, which we subsequently use to bound the communication complexity.

\begin{lemma} \label{lem:rank-reduce}
	Let $\ma, \mb, \mc, \mr$ be matrices of the appropriate dimensions,
	and let $\mr$ have rank 0 or 1. Then
	\[
		\rank \begin{pmatrix}
			\mr \\ \mb 
		\end{pmatrix} +
		\rank \begin{pmatrix}
			\mr & \ma
		\end{pmatrix} \leq 
		\rank \begin{pmatrix}
			\mr & \ma \\
			\mb & \mc
		\end{pmatrix} + 3.
	\]
\end{lemma}
\begin{proof}
	We use a sequence of elementary rank properties:
	\begin{align*}
	\rank \begin{pmatrix}
		\mr & \ma \\
		\mb & \mc
	\end{pmatrix} +1 \geq 
	\rank \begin{pmatrix}
		\mzero & \ma \\
		\mb & \mc
		\end{pmatrix} \geq 
	\rank (\ma) + \rank (\mb) \geq 
	\rank \begin{pmatrix}
		\mr & \ma
	\end{pmatrix} +
	\rank \begin{pmatrix}
		\mr \\ \mb 
		\end{pmatrix} - 2.
	\end{align*}
\end{proof}

\begin{lemma} \label{lem:size-reduce}
	Suppose the rank of $\mm \in \{0, 1, \dots, \Delta\}^{A \times B}$ is $r$.
	Then $\mm$ contains at most $(\Delta + 1)^r$ different rows and columns.
\end{lemma}

\begin{proof}
	We show the argument for rows:
	Let $\mmu \in \{0,\dots,\Delta\}^{A \times r}$ denote a submatrix of $\mm$ consisting of $r$ linearly independent columns of $\mm$. 
	Clearly $\mmu$ has at most $(\Delta + 1)^r$ different rows. If row $i$ and row $j$ of $\mmu$ are identical, then row $i$ and $j$ of $\mm$ are also identical, since by definition of rank, the columns of $\mm$ are obtained by taking linear combinations of columns of $\mmu$.
\end{proof}

Now, we can design a communication protocol to compute $\mm$ using standard techniques.
Without loss of generality, we may assume $\mm$ does not contain identical rows or columns.

\begin{proof}[Proof of \cref{lem:comm-protocol}]
	Suppose Alice has input $a \in A$ and Bob has $b \in B$.
	Then Alice and Bob compute $\mm_{a,b}$ by recursively reducing the matrix $\mm$ to a smaller submatrix in one of two ways: 
	they communicate the bit 0 which guarantees a decrease in rank in the resulting submatrix, and the bit 1 which guarantees a decrease in size.
	
	Let $\ms$ denote the submatrix to be considered at a recursive iteration.
	Alice and Bob begin with $\ms \defeq \mm$.
	During a recursive iteration, they first write $\ms$ in the form
		\[
			\ms = \begin{pmatrix}
							\mr & \ma \\
							\mb & \mc \\
			\end{pmatrix},
		\]
		where $\mr$ denote the large monochromatic rectangle in $\ms$ that is guaranteed to exist, with
		$|\mr| \geq \delta |\ms|$.
		By \cref{lem:rank-reduce}, either $\rank \begin{pmatrix} \mr & \ma \end{pmatrix} \leq \frac{1}{2} \rank (\ms) + 1$,
		or $\rank \begin{pmatrix} \mr & \mb \end{pmatrix} \leq \frac{1}{2} \rank (\ms) + 1$.
		
		In the first case, Alice communicates. 
		If her input row $a$ is in the upper submatrix of $\ms$, Alice sends the bit 0, and both Alice and Bob update $\ms =  \begin{pmatrix} \mr & \ma \end{pmatrix}$.
		On the other hand, if row $a$ is in the lower submatrix of $\ms$, Alice sends the bit 1, and they both update
		$\ms = \begin{pmatrix} \mb & \mc \end{pmatrix}$.
		%
		In the second case, Bob communicates. If his input column $b$ is in the left submatrix of $\ms$, Bob sends 0, and they update $\ms = \begin{pmatrix} \mr \\ \mb \end{pmatrix}$.
		Otherwise, Bob sends 1, and they update $\ms = \begin{pmatrix} \ma \\ \mc \end{pmatrix}$.

		The recursive process ends when either $\ms$ has size 1, or $\rank(\ms) = 1$ or 2.
		In the first case, Alice can simply output the entry of $\ms$, which is precisely $\mm_{a,b}$.
		In the second case, suppose $\ms$ has rank 2 and let $\ms = \vu \vv^\top + \vu' \vv'^\top$ be a factorization,
		where $\vu$ and $\vu'$ are two linearly independent columns of $\ms$.
		Then Alice sends $\vu_a$ and $\vu'_a$, which Bob uses to compute $\vu_a \vv^\top_b + \vu'_a \vv^\top_b = \ms_{a,b} = \mm_{a,b}$. Since $\vu$ and $\vu'$ are columns of $\ms$, their entries take values from $\{0,1,\dots, \Delta\}$, so Alice communicates $O(\log \Delta)$ bits in total.
		
		This process describes a protocol tree, where each leaf corresponds to one pair of input $(a,b)$.
		Each time the bit 0 is communicated, the rank of $\ms$ is approximately halved.
		Each time the bit 1 is communicated, the size of $\ms$ is reduced by a factor of $(1-\delta)$,
		and we may assume the size of $\mm$ is at most $(\Delta+1)^{2r}$ by \cref{lem:size-reduce}.
		In one execution of the protocol, there are at most $\log r$-many 0's and at most $O\left(\frac{- \log |\ms|}{\log(1-\delta)}\right) = O(\frac{r}{\delta} \log(\Delta+1))$-many 1's from the recursive process,
		followed by at most $O(\log \Delta)$ bits from the base case.
		So we can bound the total number of leaves by
		 \[
		 L \defeq O{\log r +  \frac{r}{\delta} \log(\Delta + 1) \choose \log r} \cdot O(\log \Delta).
		 \] 
		Standard protocol balancing techniques then allow us to construct a new protocol tree with height $O(\log L)$  (c.f.\cite{rao2020communication}, Chapter 1, Theorem 1.7). As a result, we conclude the communication complexity of $\ms$ is
		\[
			\log L = O\left( \log r \cdot \log \frac{r}{\delta} \log(\Delta + 1) \right).
		\]
		
\end{proof}
