
\section{Self-concordance theory for sampling IPM \label{sec:sc-theory-rules}}

Theorem~\ref{thm:Dikin-annealing} shows that $\gcdw$  running with
a $(\nu,\onu$)-Dikin-amenable metric for exponential distributions
mixes in $\otilde{n\max\Par{n,\nu,\onu}}$ iterations. Since every
log-concave sampling problem can be reduced to an exponential sampling
problem (as shown in (\ref{eq:reduced-problem})), Theorem~\ref{thm:Dikin-annealing}
ensures a poly-time mixing algorithm that utilizes local geometry
if we have a $(\nu,\onu)$-Dikin-amenable metric for the reduced sampling
problem.

This poses a natural question of how to construct such an efficiently
computable Dikin-amenable metric for structured sampling problems.
Suppose that the structured sampling problems assume a Dikin-amenable
metric for each constraint and epigraph of potentials. Motivated by
self-concordance theory of the optimization IPM, we consider the sum
of each barrier (and thus, the sum of metrics) as a candidate for
the metric of the reduced sampling problem. In fact, this choice aligns
seamlessly with the $\dw$. However, obtaining a provable guarantee
of the sampling IPM with the $\dw$ necessitates a comprehensive understanding
not only of self-concordance but also of SSC, SLTSC, SASC, and $\onu$-symmetry
under the addition of barriers (or metrics). 

In this section, we develop a ``calculus'' for combining metrics
for multiple constraints and epigraphs, deriving the resulting theoretical
guarantees (Theorem~\ref{thm:IPM-sampling}). This leads to a consistent
analogy with the work of \cite{nesterov1994interior} for the optimization
IPM.

\subsection{Basic properties: Scaling, addition and closeness}

Self-concordance is a central notion in the theory of interior-point
methods for optimization (we refer interested readers to \cite{nesterov1994interior,nesterov2018lectures}).
We first recall basic properties of self-concordance and then investigate
those of strong self-concordance and lower trace self-concordance,
which are crucial to our analysis.

\paragraph{Self-concordance.}
\begin{lem}
[\cite{nesterov2003introductory}] Let $f_{i}$ be a $\nu_{i}$-self-concordant
function on a convex set $K_{i}\subset\Rn$ for $i\in[2]$, and $\alpha>0$
be a scalar.
\begin{itemize}
\item (Theorem 4.1.1 and 4.2.2) $f_{1}+f_{2}$ is $(\nu_{1}+\nu_{2})$-self-concordant
on $K_{1}\cap K_{2}$.
\item (Corollary 4.1.2) $g=\hess(\alpha f_{1})$ satisfies $\norm{g(x)^{-\half}Dg(x)[h]g(x)^{-\half}}_{2}\leq\frac{2}{\sqrt{\alpha}}\norm h_{g(x)}$
for $x\in\inter(K_{1}\cap K_{2})$ and $h\in\Rn$.
\item If $f_{1}$ is a $\nu$-self-concordant, then $cf_{1}$ is $(c\nu)$-self-concordant
for $c>1$.
\end{itemize}
\end{lem}

We can extend this to self-concordant matrices as well.
\begin{lem}
\label{lem:sc-addition} Let $g_{i}:\inter(K_{i})\to\psd$ be a PSD
matrix function on a convex set $K_{i}\subset\Rn$ for $i\in[2]$,
and $\alpha>0$ be a scalar.
\begin{itemize}
\item $g_{1}+g_{2}$ is $(\nu_{1}+\nu_{2})$-self-concordant on $K_{1}\cap K_{2}$.
\item If $g_{1}$ is self-concordant, then $\alpha g_{1}$ satisfies $D(\alpha g_{1})(x)[h]\preceq\frac{2}{\sqrt{\alpha}}\norm h_{\alpha g_{1}}(\alpha g_{1})$
for $x\in\inter(K_{1}\cap K_{2})$ and $h\in\Rn$.
\item If $g_{1}$ is $\nu$-self-concordant, then $cg_{1}$ is $(c\nu)$-self-concordant
for $c>1$.
\end{itemize}
\end{lem}

\begin{proof}
Let $\phi_{i}$ be a $\nu_{i}$-self-concordant function counterpart
of $g_{i}$ on $K_{i}$ for $i\in[2]$. Then for $x\in\inter(K_{1}\cap K_{2})$
and $h\in\Rn$
\begin{align*}
D(g_{1}+g_{2})(x)[h] & \preceq2\Par{\norm h_{g_{1}}g_{1}+\norm h_{g_{2}}g_{2}}\preceq2\Par{\norm h_{g_{1}+g_{2}}g_{1}+\norm h_{g_{1}+g_{2}}g_{2}}=2\norm h_{g_{1}+g_{2}}(g_{1}+g_{2}).
\end{align*}
Clearly, $\phi_{1}+\phi_{2}$ is a function counterpart of $g_{1}+g_{2}$.
Thus, $g_{1}+g_{2}$ is a $(\nu_{1}+\nu_{2})$-self-concordant matrix
function on $K_{1}\cap K_{2}$.

For $c>1$, if $g_{1}$ is self-concordant, then $D(cg_{1})(x)[h]\preceq\frac{2}{\sqrt{c}}\norm h_{cg_{1}}(cg_{1})\preceq2\norm h_{cg_{1}}(cg_{1})$,
and its function counterpart $c\phi_{1}$ is $(c\nu)$-self-concordant
by Lemma~\ref{lem:sc-addition}. Hence, $cg_{1}$ is $(c\nu)$-self-concordant.
\end{proof}
The following lemma ensures that the $\dw$ stays inside the convex
body. This lemma was proven only for self-concordant function in (\cite{nesterov2018lectures},
Theorem~5.1.5), but it can be straightforwardly extended to self-concordant
matrices as well.
\begin{lem}
\label{lem:dikin-in-body} $\dcal_{g}^{1}(x)\subset K$ for a convex
set $K$ and self-concordant matrix function $g$ on $K$.
\end{lem}

\begin{proof}
Consider a matrix function $g_{\veps}$ from $\intk$ to $\S_{++}^{n}$
defined by $g_{\veps}(x):=g(x)+\veps I$. It is self-concordant with
a function counterpart $\phi(x)+\frac{\veps}{2}\norm x^{2}$, where
$\phi:\intk\to\R$ is a function counterpart of $g$. For fixed $x\in\intk$
and $h\in\Rn$, let us define a function defined by $\psi(t):=\frac{1}{\sqrt{h^{\top}g_{\veps}(x+th)h}}$
for any feasible $t$. Then
\[
\psi'(t)=-\frac{Dg_{\veps}(x+th)[h,h,h]}{2\norm h_{g_{\veps}(x+th)}^{3}},
\]
and the definition of self-concordance leads to $\Abs{\psi'(t)}\leq1$.
This function can be defined on the interval $\Par{-\psi(0),\psi(0)}$
due to $\psi(t)\geq\psi(0)-|t|$ (see Corollary~5.1.4 in \cite{nesterov2018lectures}).
This implies that $K$ contains the set 
\[
\Brace{x+th:|t|\leq\psi(0)=\frac{1}{\norm h_{g_{\veps}(x)}}}=\Brace{x+th:\norm{th}_{g_{\veps}(x)}\leq1}.
\]
By sending $\veps\to0$, the claim follows.
\end{proof}
The following lemma states that self-concordant metrics are similar
for nearby points.
\begin{lem}
[\cite{nesterov2003introductory}, Theorem 4.1.6] \label{lem:scCloseness}
Given any self-concordant matrix function $g$ on $K\subset\Rn$ and
$x,y\in K$ with $\norm{x-y}_{g(x)}<1$, we have 
\[
\Par{1-\norm{x-y}_{g(x)}}^{2}g(x)\preceq g(y)\preceq\frac{1}{\Par{1-\norm{x-y}_{g(x)}}^{2}}g(x).
\]
\end{lem}


\paragraph{Strong self-concordance.}

Strong self-concordance is additive up to a constant scaling. See
Section~\ref{proof:ssc-basic} for the proof.
\begin{lem}
\label{lem:ssc-sum} If $g_{i}$ is a SSC matrix function on $K_{i}$
for $i\in[2]$, then $2(g_{1}+g_{2})$ is strongly self-concordant
on $K_{1}\cap K_{2}$. 
\end{lem}

Note that if we add $k$-many strongly self-concordant metrics, then
we need the scaling of $2^{\log_{2}k}=k$. We remark that the factor
of $2$ above might be redundant. Next, we recall an analogue of Lemma~\ref{lem:scCloseness}
for strong self-concordance.
\begin{lem}
[\cite{laddha2020strong}, Lemma 1.2] \label{lem:strongSC-closeness}Given
a strongly self-concordant matrix function $g$ on $K$, and any $x,y\in K$
with $\norm{x-y}_{g(x)}<1$, 
\[
\norm{g(x)^{-\half}\Par{g(y)-g(x)}g(x)^{-\half}}_{F}\leq\frac{\norm{x-y}_{g(x)}}{\Par{1-\norm{x-y}_{g(x)}}^{2}}.
\]
\end{lem}


\paragraph{Symmetry.}

Recall that $\onu$-symmetry requires two-sided inclusion: the first
part is $\dcal_{g}^{1}(x)\subset K\cap(2x-K)$, and the second part
is $K\cap(2x-K)\subset\dcal_{g}^{\sqrt{\onu}}(x)$. The first part
immediately follows when a metric is induced by a self-concordant
function.
\begin{lem}
\label{lem:symmetricLeftpart} If $\phi$ is a self-concordant function
on $K$, then $\dcal_{g}^{1}(x)\subset K\cap(2x-K)$ for $g=\hess\phi$
and $x\in K$.
\end{lem}

\begin{proof}
Lemma~\ref{lem:dikin-in-body} ensures that $y\in K$ whenever $y\in\dcal_{g}^{1}(x)$.
Then $2x-y\in\dcal_{g}^{1}(x)$ and thus $2x-y\in K$. It implies
that $y\in2x-K$.
\end{proof}
When a metric is induced by a self-concordant barrier with a barrier
parameter $\nu$, it holds that $\onu=O(\nu^{2})$.
\begin{lem}
\label{lem:bound-symmetry} For a self-concordant barrier $\phi$
with a barrier parameter $\nu$ on $K$ and $g=\hess\phi$, it follows
that $\onu=O(\nu^{2})$.
\end{lem}

\begin{proof}
By Theorem 4.2.5 in \cite{nesterov2003introductory}, for any $x,y\in K$
with $\grad\phi(x)\cdot(y-x)\geq0$ it follows that $\norm{y-x}_{g(x)}\leq\nu+2\sqrt{\nu}$.
Now, let $x\in K$ and $y\in K\cap(2x-K)$. The latter implies that
$y-x=x-z$ for some $z\in K$. 

If $\grad\phi(x)\cdot(y-x)\geq0$, then $\norm{y-x}_{g(x)}\leq\nu+2\sqrt{\nu}.$
If $\grad\phi(x)\cdot(y-x)<0$, then $\grad\phi(x)\cdot(z-x)>0$ and
thus $\norm{y-x}_{g(x)}=\norm{z-x}_{g(x)}\leq\nu+2\sqrt{\nu}$. From
these two cases, it holds in general that $\norm{y-x}_{g(x)}\leq\nu+2\sqrt{\nu}$
and thus $K\cap(2x-K)\subset\dcal_{g}^{\nu+2\sqrt{\nu}}(x)$. By Lemma
\ref{lem:symmetricLeftpart}, $\dcal_{g}^{1}(x)\subset K\cap(2x-K)$
and thus $\onu=O(\nu^{2})$.
\end{proof}
For affine constraints $Ax\geq b$, the first inclusion above has
a useful equivalent description as follows:
\begin{lem}
\label{lem:symmforPolytope} Let $x\in K=\{Ax>b\}$. It holds that
$y\in K\cap(2x-K)$ if and only if $\norm{A_{x}(y-x)}_{\infty}\leq1$.
\end{lem}

\begin{proof}
For $y\in K$, we have $Ay>b$ and thus $s_{x}=Ax-b>A(x-y)$ (elementwise
inequality). As $s_{x}>0$, we have $A_{x}(x-y)\leq1$. When $y\in(2x-K)$,
we can write $y=2x-z$ for some $z\in K$. Note that
\[
A(x-y)=A(z-x)>b-Ax=-s_{x},
\]
and thus $A_{x}(x-y)\geq-1$. Therefore, $\norm{A_{x}(y-x)}_{\infty}\leq1$.
\end{proof}
\begin{lem}
\label{lem:symmScaling} For $\alpha\geq1$, if $g$ is $\onu$-symmetric,
then $\alpha g$ is $\alpha\onu$-symmetric.
\end{lem}

Symmetry parameters and self-concordance parameters are additive.
\begin{lem}
\label{lem:symmetry-addition} If a PSD matrix function $g_{i}$ is
$\onu_{i}$-symmetric on $K_{i}$ for $i\in[2]$, then $g_{1}+g_{2}$
is $\Par{\onu_{1}+\onu_{2}}$-symmetric on $K_{1}\cap K_{2}$.
\end{lem}

\begin{proof}
For $g:=g_{1}+g_{2}$, let $y\in\dcal_{g}^{1}(x)$. It implies $y\in\dcal_{g_{1}}^{1}(x)\cap\dcal_{g_{2}}^{1}(x)$
and so $y\in K_{i}\cap(2x-K_{i})$. Due to $\cap_{i}\Par{K_{i}\cap(2x-K_{i})}=K\cap(2x-K)$,
we have $y\in K\cap(2x-K)$ and so $\dcal_{g}^{1}(x)\subset K\cap(2x-K)$.

Now let $y\in K\cap(2x-K)$. It is obvious that $y\in K_{i}\cap(2x-K_{i})$
for $i=1,2$, and thus
\begin{align*}
(y-x)^{\top}g_{1}(x)(y-x) & \leq\nu_{1},\\
(y-x)^{\top}g_{2}(x)(y-x) & \leq\nu_{2}.
\end{align*}
By adding up these two, it follows that $\norm{y-x}_{g(x)}^{2}\leq\nu_{1}+\nu_{2}$.
\end{proof}

\paragraph{Lower trace self-concordance.}

It readily follows that (strongly) LTSC holds under scaling by a scalar
greater than or equal to $1$. 

We provide a useful sufficient condition under which the sum of PSD
matrix functions is LTSC.
\begin{lem}
\label{lem:sltsc-additive} For a PSD matrix function $g_{i}$ on
$K_{i}$, let $g:=\sum_{i}g_{i}$ be PD on $\bigcap_{i}K_{i}$. If
$g_{i}$ is SLTSC on $K_{i}$, then $g$ is LTSC on $\bigcap_{i}K_{i}$.
\end{lem}

We note that $D^{2}g_{i}(x)[h,h]\succeq0$ is a stronger condition
than $\tr\Par{g^{-1}D^{2}g_{i}(x)[h,h]}\geq-\norm h_{g_{i}(x)}^{2}$.
Thus, a special case of the lemma is that if $D^{2}g_{1}[h,h]\succeq0$
and $D^{2}g_{2}[h,h]\succeq0$, then $g_{1}+g_{2}$ is LTSC. Note
that this condition is \emph{additive.}

We also find that highly self-concordance is a handy sufficient condition
by which one can establish strongly lower trace self-concordance,
whose proof is deferred to Section~\ref{proof:ltsc-basic}.
\begin{lem}
\label{lem:hsc-to-sltsc} For $K\subset\Rn$, let $\bar{g}:\intk\to\psd$
be a HSC matrix function, and define another matrix function by $g:=n\bar{g}$
on $K$. Then $g$ is SLTSC.
\end{lem}


\paragraph{Average self-concordance.}

Just as (S)LTSC, (S)ASC still holds under scaling by a scalar greater
than or equal to $1$. Also, the definition of SASC immediately leads
to the following additive condition:
\begin{lem}
\label{lem:sasc-additive} For a PSD matrix function $g_{i}$ on $K_{i}$
for $i\in[m]$, let $m=O(1)$ and $g:=\sum_{i=1}^{m}g_{i}$ be PD
on $\bigcap_{i}K_{i}$. If $g_{i}$ is SASC on $K_{i}$, then $g$
is ASC on $\bigcap_{i}K_{i}$.
\end{lem}

\begin{proof}
Fix $\veps>0$. Each $g_{i}$ invokes $r_{i}(\veps)$ such that if
$r\leq r_{i}\Par{\frac{\veps}{m}}$, then 
\[
\P\Par{\norm{z-x}_{g_{i}(z)}^{2}-\norm{z-x}_{g_{i}(x)}^{2}\leq2\frac{\veps}{m}\frac{r^{2}}{n}}\geq1-\frac{\veps}{m}.
\]
If $r\leq\bar{r}(\veps):=\min_{i}r_{i}(\veps/m)$, then the union
bound leads to ASC of $\sum g_{i}$ on $\bigcap_{i}K_{i}$.
\end{proof}
When does SASC hold? It is implied in \cite{narayanan2016randomized}
that HSC implies SASC. For completeness, we provide the proof in Section~\ref{proof:asc-basic}.
\begin{lem}
[HSC to SASC] \label{lem:hsc-to-sasc} If $\phi:\intk\to\R$ is HSC,
then $n\phi$ is SASC.
\end{lem}


\subsection{Collapse and embedding: Lifting up SSC, SLTSC, and SASC}

SSC, (S)LTSC, (S)ASC of a local metric do not carry over into an extended
space in the reduced sampling problem. For instance, SSC assumes the
invertibility of the local metric, which may become singular in the
extended space. To address this challenge, we introduce the notions
of \emph{collapse} and \emph{embedding}, based on which we can pass
those properties from the original sampling problem to the reduced
problem.
\begin{defn}
\label{def:sc-along-subspace} Let $K$ and $K'$ be convex sets in
$\Rn$ and in $\R^{m}$ with $n\leq m$, respectively. Let $g:\intk\to\psd$
be a PSD matrix function.
\begin{itemize}
\item We say $g$ is \emph{collapsed onto a linear subspace} $W\subset\Rn$
if $\inner{u,v}_{g(x)}=\inner{P_{W}u,P_{W}v}_{g(x)}$ for any $x\in\intk$
and $u,v\in\Rn$ where $P_{W}$ is the orthogonal projection onto
$W$.
\begin{itemize}
\item In other words, for an orthonormal basis $\{u_{1},\dots,u_{k}\}$
of $W$ there exists the PSD matrix function $g_{W}:\intk\to\S_{+}^{k}$
such that $\inner{e_{i},e_{j}}_{g_{W}(x)}=\inner{u_{i},u_{j}}_{g(x)}$
for $i,j\in[k]$ (i.e., $g_{W}(x)=U^{\top}g(x)U$ where the columns
of $U\in\R^{n\times k}$ are $\Brace{u_{1},\dots,u_{k}}$). 
\end{itemize}
\item For $g$ collapsed onto $W$, we say
\begin{itemize}
\item $g$ is PD along $W$ if $g_{W}$ is PD. In other words, $\norm h_{g(x)}=0$
implies $h\perp W$.
\item $g$ is SSC along $W$ if $g$ is a self-concordant matrix function,
and $g_{W}\succ0$ satisfies $\norm{g_{W}(x)^{-\half}Dg_{W}(x)[h]g_{W}(x)^{-\half}}_{F}\leq2\norm h_{g}(=2\norm{P_{W}h}_{g})$
for any $x\in\intk$ and $h\in\Rn$.
\end{itemize}
\item \emph{Embedding} $\bar{g}$ of $g$ into $K'$
\begin{itemize}
\item Let $P:\R^{m}\to\Rn$ be the projection onto the set of coordinates
appearing in the variable $x$ of $g$. The embedding of $g$ onto
$K'$ is a PSD matrix function $\bar{g}(y):\inter(K')\to\S_{+}^{m}$
such that $\inner{u,v}_{\bar{g}(y)}=\inner{Pu,Pv}_{g(P(y))}$.
\end{itemize}
\end{itemize}
\end{defn}

We note that these notions are well-defined notions independently
of the choice of an orthonormal basis of $W$. The proof can be found
in Section~\ref{prop:collapse-well-defined}.
\begin{prop}
\label{prop:collapse-well-defined} Let $K\subset\Rn$ be convex and
$g:\intk\to\psd$ a PSD matrix function collapsed onto a subspace
$W\subset\Rn$. Then PD and SSC along $W$ are well-defined (i.e.,
the condition for each property holds for any orthonormal basis of
$W$).
\end{prop}


\paragraph{Affine transformation.}

Using these notions, we can make it precise that an inverse mapping
of affine transformations preserves SSC. We begin with a barrier version
and subsequently extend it to a matrix-function version. The detailed
proofs are deferred to Section~\ref{proof:collap-affine}.
\begin{lem}
\label{lem:linear-trans} Let $T:\Rn\to\R^{m}$ be a linear operator
defined by $T(x)=Ax+b$ for $A\in\R^{m\times n}$ and $b\in\R^{m}$.
Let $\phi(y):\intk\subset\R^{m}\to\R$ be a self-concordant barrier
for $K$ and define $\psi(x):=\phi(T(x))=\phi(y)$ on $\bar{K}:=T^{-1}K\subset\Rn$.
\begin{itemize}
\item If $\phi$ is a $(\nu,\onu)$-self-concordant barrier for $K$, so
is $\psi$ for $\bar{K}$.
\item If $D^{4}\phi(y)[v,v]\succeq0$ for $y\in\intk$ and $v\in\R^{m}$,
then $D^{4}\psi(x)[u,u]\succeq0$ for $x\in\inter(\bar{K})$ and $u\in\R^{n}$.
\item If $\phi$ is HSC, so is $\psi$.
\end{itemize}
\end{lem}

\begin{lem}
\label{lem:linear-trans-matrix} Let $g:\intk\subset\R^{m}\to\S_{+}^{m}$
be a self-concordant matrix function and $T(x)=Ax+b$ with $A\in\R^{m\times n}$
and $b\in\R^{m}$ be a linear operator. Define a PSD matrix function
$\bar{g}(x):=A^{\top}g(Tx)A$ mapping from $\bar{K}:=T^{-1}K\subset\Rn$
to $\psd$.
\begin{itemize}
\item If $g$ is $(\nu,\onu)$-self-concordant barrier, so is $\bar{g}$
for $\bar{K}$.
\item If $g$ is SSC, then $\bar{g}$ is SSC along $W=\rowspace(A)$.
\item If $D^{2}g(y)[h,h]\succeq0$ for $y\in\intk$ and $h\in\R^{m}$, then
$D^{2}\bar{g}(x)[\bar{h},\bar{h}]\succeq0$ for $x\in\inter(\bar{K})$
and $\bar{h}\in\Rn$.
\item If $A$ is invertible and $g$ is SLTSC, then $\bar{g}$ is SLTSC.
\item If $A$ is invertible and $g$ is SASC, then $\bar{g}$ is SASC.
\end{itemize}
\end{lem}

Intuitively, embedding should not affect self-concordance and symmetry
parameter, which is indeed the case.
\begin{cor}
\label{cor:embedding-scness} Assume $K\subset\Rn$ is embeddable
into $K'\subset\R^{m}$. If $g:\intk\to\psd$ is a $(\nu,\onu)$-self-concordant
matrix function, then its embedding $\bar{g}:\inter(K')\to\S_{+}^{m}$
is a $(\nu,\onu)$-self-concordant matrix function.
\end{cor}

\begin{proof}
Since $K$ can be embedded into $K'$, there exists a projection matrix
$P\in\{0,1\}^{n\times m}$ such that $\bar{g}(y)=P^{\top}g(Py)P$
with $x=Py\in\intk$ and $y\in\inter(K')$. As we can view $\bar{g}$
as a matrix function induced by the inverse of the linear map $x=Py$,
Lemma~\ref{lem:linear-trans-matrix} shows that $\bar{g}$ is a $(\nu,\onu)$-self-concordant
matrix function for $K'=P^{-1}K$. 
\end{proof}

\paragraph{Lifting up SSC, SLTSC, and SASC via embedding.}

In reduction to the exponential sampling problem, passing essential
properties (e.g., SSC, SLTSC, and SASC) of metrics from the original
space to the extended space poses technical issues. We address these
issues in the following two lemmas, whose proofs are deferred to Section~\ref{proof:lifting-ssc}.

As mentioned earlier, SSC in the original space does not automatically
imply SSC for its embedding $\bar{g}$, as SSC assumes invertibility.
However, there is a useful method for extending SSC from the original
space to the extended space.
\begin{lem}
\label{lem:embedding-ssc} For convex $K\subset\Rn$, let $g:\intk\to\psd$
be SSC along a subspace $W\subset\Rn$, and assume $K$ is embeddable
into convex $K'\subset\R^{m}$ with $m\geq n$. For the embedding
$\bar{g}:\inter(K')\to\S_{+}^{m}$ of $g$ into $K'$, it holds that
$\bar{g}+\veps I_{m}$ is SSC on $K'$ for any $\veps>0$.
\end{lem}

When extending SLTSC and SASC to the embedding space, we encounter
a different subtlety. The conditions in SLTSC and SASC of $\bar{g}$
consider every PSD matrix functions $g'$ such that $\bar{g}+g'$
is invertible in the extended space $\bar{K}$. However, the embedding
$\bar{g}$ of $g$ is collapsed onto the subspace corresponding to
the original space $K$. As SLTSC and SASC convolve $\bar{g}$ and
$g'$ by considering $\Par{\bar{g}+g'}^{-1}$ in their formulations,
it is not evident whether SLTSC and SASC can be transferred to the
extended space $\bar{K}$ from the original space $K$. However, by
employing with Schur complements we can show that these properties
can indeed carry over into the extended space.
\begin{lem}
\label{lem:embedding-sltsc} For convex $K\subset\Rn$, let $g:\intk\to\psd$
is SLTSC, and assume $K$ is embeddable into convex $K'\subset\R^{m}$
with $m\geq n$. Then its embedding $\bar{g}:\inter(K')\to\S_{+}^{m}$
is also SLTSC. The same is true for SASC.
\end{lem}


\subsection{Proof of Theorem \ref{thm:IPM-sampling}}

With our understanding of how to combine properties of barriers for
constraints and epigraphs, we are prepared to prove Theorem~\ref{thm:IPM-sampling}.
Let us revisit the reduced sampling problem in (\ref{eq:reduced-problem}):
\begin{align*}
\text{sample } & \frac{d\tilde{\pi}}{dy}(y)\propto e^{-\bigg\langle(\underbrace{0,\dots,0}_{n\text{ times}}\underbrace{1,\dots,1}_{I\text{ times}}),y\bigg\rangle}\\
\text{s.t. } & y\in\bigcap_{i=1}^{I}E_{i}\cap\underbrace{\bigcap_{j=1}^{J}K_{j}}_{=:K}=:K',
\end{align*}
where $E_{i}:=\Brace{y=(x,t_{1},\dots,t_{I})\in\R^{n+I}:f_{i}(x)\leq y_{n+i}}$
for a proper closed convex function $f_{i}$ and $i\in[I]$, and $K_{j}:=\Brace{y=(x,t_{1},\dots,t_{I})\in\R^{n+I}:h_{j}(x)\leq0}$
for a closed convex function $h_{j}$ and $j\in[J]$, and $K$ has
non-empty interior.

We begin with a useful geometric property of $K'$.
\begin{lem}
If the original sampling problem (\ref{eq:problem}) is well-defined,
then the extended convex region $K'$ in the reduced sampling problem
(\ref{eq:reduced-problem}) has non-empty interior and no straight
line.
\end{lem}

\begin{proof}
Since $f_{i}$ and $h_{j}$ are closed and convex, $K'$ is convex
and closed. Since $f_{i}$ is continuous on $\inter(K)$ due to convexity
(see Theorem~10.1 in \cite{rockafellar1997convex}), its epigraph
has non-empty interior. Thus, $K'$ has non-empty interior.

Since $K'$ is closed and convex, it can be written as $K'=\bigcap_{i}H_{i}$
where $H_{i}=\{x:a_{i}^{\top}x\geq b_{i}\}$ is any halfspace containing
$K'$. Suppose $K'$ contains a straight line $\ell:=\{p+th:t\in\R\}$
for some $p,h\in\Rn$. Then $\ell\subset H_{i}$ for any $i$ and
thus $\ell$ must be parallel to any halfspace $H_{i}$ (i.e., $h\perp a_{i}$). 

Fix $y\in\inter(K')$. The translated line $\ell_{y}$ of $\ell$
containing $y$ is still included in $H_{i}$ for all $i$. As $y\in\inter(K')$,
the distance from $y$ to $\del H_{i}$ is bounded lower by $\delta>0$
for all $i$. Hence, $\ell_{y}+B_{\delta}$ is fully contained in
$H_{i}$ and thus in $K'$.

Clearly, integration of the exponential distribution along the fiber
$\ell_{y}$ is infinite. Since $K'$ contains the cylinder $\ell_{y}+B_{\delta}$,
integration of the exponential distribution over $K'$ must be infinite,
leading to contradiction.
\end{proof}
The following is the extension of Theorem~5.1.6 in \cite{nesterov2018lectures}
to self-concordant matrix functions, which implies invertibility of
Dikin-amenable metrics in the reduced problem.
\begin{lem}
\label{lem:nondegenerate-no-straightline} For convex $K\subset\Rn$
containing no straight line, a self-concordant matrix function $g:\intk\to\psd$
is non-degenerate on $K$.
\end{lem}

\begin{proof}
Suppose $\norm h_{g(x)}=0$ for some $0\neq h\in\Rn$ and $x\in\intk$.
Clearly, the line $x+th$ for $t\in\R$ is contained in $\dcal_{g}^{1}(x)$.
As $\dcal_{g}^{1}(x)\subset K$ due to Lemma~\ref{lem:dikin-in-body},
it implies that $K$ contains a straight line $x+th$, which leads
to contradiction. 
\end{proof}
\thmIPMsampling*
\begin{proof}
First of all, $\bar{g}_{i}^{e}$ is $(\nu_{i},\onu_{i})$-self-concordant
(Corollary~\ref{cor:embedding-scness}), and SLTSC and SASC on $K'$
(Lemma~\ref{lem:embedding-sltsc}). For fixed $\veps>0$, $\bar{g}_{i}^{e}+\veps I$
is SSC by Lemma~\ref{lem:embedding-ssc}. We can make similar arguments
for $\bar{g}_{j}^{c}$ regarding self-concordance, symmetry, SLTSC,
SASC, and SSC. Hence, $g+(I+J)\veps I$ is SSC by Lemma~\ref{lem:ssc-sum}.
Since $g$ is self-concordant on $K'$ by Lemma~\ref{lem:sc-addition}
and $K'$ contains no straight line, $g$ is PD by Lemma~\ref{lem:nondegenerate-no-straightline}.
Sending $\veps$ to $0$, we can obtain SSC of $g$. LTSC and ASC
of $g$ follows from Lemma~\ref{lem:sltsc-additive} and \ref{lem:sasc-additive}.
The symmetry parameter of $g$ follows from Lemma~\ref{lem:symmetry-addition}.
\end{proof}

\subsection{Direct product}

For $i=1,\dots,m$ and domain $E_{i}\subset\R^{n_{i}}$, let $g_{i}(x_{i}):\inter(E_{i})\to\S_{++}^{n_{i}}$
be a self-concordant matrix. For $l:=\sum_{i}n_{i}$ and $E:=\prod_{i}E_{i}$,
we define a self-concordant matrix $g$ on $E\subset\R^{l}$ with
block diagonals being $g_{i}$. To be precise, we can write
\begin{align*}
g(x) & =g(x_{1},\dots,x_{m}):=\sum_{i}\bar{g}_{i}(x),
\end{align*}
where $\bar{g}_{i}:\R^{l}\to\S_{+}^{l}$ is a matrix function whose
entry is all zero but the $i^{th}$ block diagonal being $g_{i}$.

When handling the direct product of domains, it is common for each
domain to have an $O(1)$-dimension. In such cases, scaling the barriers
by dimension worsens mixing time at most constant factors while making
the barriers SSC and SLTSC. We defer the proofs to Section~\ref{proof:direct-ssc-sltsc}.
\begin{lem}
[SSC  under direct product] \label{lem:ssc-direct} For open $E_{i}\subset\R^{n_{i}}$,
let $g_{i}:E_{i}\to\S_{++}^{n_{i}}$ be SC. Then $g:=\sum n_{i}\bar{g}_{i}$
defined on $\prod E_{i}$ is SSC.
\end{lem}

\begin{lem}
[SLTSC  under direct product] \label{lem:sltsc-direct} For open
$E_{i}\subset\R^{n_{i}}$, let $g_{i}:E_{i}\to\S_{++}^{n_{i}}$ be
HSC. Then $g:=\sum n_{i}\bar{g_{i}}$ defined on $\prod E_{i}$ is
SLTSC.
\end{lem}


\subsection{Inverse images under non-linear mappings}

\cite{nesterov1994interior} introduced the notion of \emph{compatibility}
with a convex domain while constructing a self-concordant barrier
for a wider class of structured constraints. We generalize this notion
to the fourth order, by which we can easily construct a SSC, SLTSC,
and SASC barrier. For a convex cone $K$, we use $a\leq_{K}b$ to
denote $b-a\in K$.
\begin{defn}
[Compatibility] Let $\beta,\gamma\geq0$. Let $K$ be a convex cone
in $\R^{m}$ and $\Gamma$ be a closed convex domain in $\Rn$. A
mapping $\acal:\inter(\Gamma)\to\R^{m}$ of class $C^{4}$ is called
$(K,\beta,\gamma)$-compatible with the domain $\Gamma$ if 
\begin{itemize}
\item $\acal$ is concave with respect to $K$. That is, $t\acal(x)+(1-t)\acal(y)\leq_{K}\acal(tx+(1-t)y)$
for all $t\in[0,1]$ and $x,y\in\inter(\Gamma)$. Equivalently, $-D^{2}\acal(x)[h,h]\in K$
for any $x\in\inter\Gamma$ and $h\in\R^{m}$.
\item For any $x\in\inter(\Gamma)$, $y\in\Gamma\cap(2x-\Gamma)$, and $h=y-x$,
it holds that 
\begin{align*}
\beta D^{2}\acal(x)[h,h] & \leq_{K}D^{3}\acal(x)[h,h,h]\leq_{K}-\beta D^{2}\acal(x)[h,h],\\
\gamma D^{2}\acal(x)[h,h] & \leq_{K}D^{4}\acal(x)[h,h,h,h]\leq_{K}-\gamma D^{2}\acal(x)[h,h].
\end{align*}
\end{itemize}
\end{defn}

\begin{example}
\label{exa:useful-criteria} An affine mapping is $(\{0\},0,0)$-compatible
with any closed convex domain. We note that a function that is $(\R_{+},\beta,\gamma)$-compatible
with $\R_{+}$ is a $C^{4}$-smooth concave real-valued function $f:(0,\infty)\to\R$
such that for any $t>0$,
\begin{align*}
|f'''(t)| & \leq-\frac{\beta}{t}f''(t)\quad\&\quad|f^{(4)}(t)|\leq-\frac{\gamma}{t^{2}}f''(t).
\end{align*}
\begin{itemize}
\item Let $0<p\leq1$. Then the function of $f(t)=t^{p}$ is $(\R_{+},2-p,(2-p)(3-p))$-compatible
with $\R_{+}$.
\item $f(t)=\log t$ is $(\R_{+},2,6)$-compatible with $\R_{+}$.
\end{itemize}
The following lemma is an extension of Lemma~5.1.3 in \cite{nesterov1994interior}
to our fourth-order compatibility.
\end{example}

\begin{lem}
\label{lem:extension-compatibility} Let $K,K_{1},K_{2}$ be convex
cones in $\R^{m},\R^{m_{1}},\R^{m_{2}}$ respectively.
\begin{itemize}
\item If $\acal:\inter(\Gamma)\to\R^{m}$ is $(K,\beta,\gamma)$-compatible
with $\Gamma$ and $K\subset K'$ is a closed convex cone in $\R^{m}$,
then $\acal$ is $(K',\beta,\gamma)$-compatible with $\Gamma$.
\item If $\acal_{i}:\inter(\Gamma_{i})\to\R^{m_{i}}$ is $(K_{i},\beta_{i},\gamma_{i})$-compatible
with $\Gamma_{i}$ for $i=1,2$, then $\acal:\inter(\Gamma_{1}\times\Gamma_{2})\to\R^{m_{1}}\times\R^{m_{2}}$
mapping $(x,y)\to(\acal_{1}(x),\acal_{2}(y))$ is $(K_{1}\times K_{2},\max(\beta_{1},\beta_{2}),\max(\gamma_{1},\gamma_{2}))$-compatible
with $\Gamma_{1}\times\Gamma_{2}$.
\end{itemize}
\end{lem}

We now introduce a main result in this section (see Section~\ref{proof:inverse-non-linear}).
To begin with, we recall that for a closed convex domain $G\subset\Rn$
the \emph{recessive cone} $R(G)$ of $G$ is $\{h\in\Rn:x+th\in G\ \text{for all }x\in G\text{ and }t>0\}$.
\begin{lem}
\label{lem:compatible} Let $G$ be a closed convex domain in $\R^{m}$,
$F$ be a highly $\theta$-self-concordant barrier for $G$, $\Gamma$
be a closed convex domain in $\Rn$, and $\Pi$ be a highly $\nu$-self-concordant
barrier for $\Gamma$. Let $\acal$ be a $(K,\beta,\gamma)$-compatible
with $\Gamma$, where $K$ is a ray contained in the recessive cone
$R(G)$. Assume that $\acal(\inter(\Gamma))\cap G\neq\emptyset$.
\begin{itemize}
\item The set $G^{+}=\overline{\inter(\Gamma)\cap\acal^{-1}\Par{\inter(G)}}$
is a closed convex domain in $\Rn$.
\item For $\delta=\max\Par{\beta,\gamma,2}$, the function $\Psi(x)=F(\acal(x))+\delta^{2}\Pi(x)$
is a $(\theta+\delta^{2}\nu)$-self-concordant barrier for $G^{+}$.
\item $\Psi$ is highly self-concordant.
\end{itemize}
\end{lem}

Using this result, we can obtain a useful tool in establishing lower
trace self-concordance of a barrier for the direct product of structured
sets.
\begin{lem}
\label{lem:tool-concave} Let $f(t)$ be a $C^{4}$ concave function
on $\{t>0\}$ such that $|f'''(t)|\leq\frac{\beta}{t}|f''(t)|$ and
$|f^{(4)}(t)|\leq\frac{\gamma}{t^{2}}|f''(t)|$ for $t>0$. Then the
function 
\[
F(t,x)=-\log\Par{f(t)-x}-\max(4,\beta^{2},\gamma^{2})\log t
\]
is a highly $(1+\max(4,\beta^{2},\gamma^{2}))$-self-concordant barrier
for the two dimensional convex domain
\[
G_{f}=\overline{\Brace{(t,x)\in\R^{2}:t>0,\,x\leq f(t)}}.
\]
\end{lem}

\begin{proof}
From the discussion in Example~\ref{exa:useful-criteria}, the map
$f(t):(0,\infty)\to\R$ is $(\R_{+},\beta,\gamma)$-compatible with
$\R_{+}$. Clearly, the identity map from $\R$ to $\R$ is $(\{0\},0,0)$-compatible
with $\R$. Hence by Lemma~\ref{lem:extension-compatibility}-(2)
implies that the map $\acal:\R_{+}\times\R\to\R^{2}$ defined by $\acal(t,x)=(f(t),x)$
is $(\underbrace{\{0\}\times\R_{+}}_{=:K},\beta,\gamma)$-compatible
with $\R_{+}\times\R$. 

Now observe that $G_{f}$ can be written as $\acal^{-1}\bigg(\underbrace{\{(t,x):x\leq t\}}_{=:G}\bigg)$
and that $K=\{0\}\times\R_{+}$ is a ray contained in the recessive
cone $R(G)$. By applying Lemma~\ref{lem:compatible} to the highly
$1$-self-concordant barriers $F(t,x)=-\log(t-x)$ for $G$ and $\Phi(t,x)=-\log t$
for $\R_{+}\times\R$, it follows that $F$ is is a highly $(1+\max(4,\beta^{2},\gamma^{2}))$-self-concordant
barrier for $G_{f}$.
\end{proof}
We can prove a similar result for a convex $f$ as follows:
\begin{lem}
\label{lem:tool-convex} Let $f(x)$ be a $C^{4}$ convex function
on $\{x>0\}$ such that $|f'''(x)|\leq\frac{\beta}{x}f''(x)$ and
$|f^{(4)}(x)|\leq\frac{\gamma}{x^{2}}f''(x)$ for $x>0$. Then the
function 
\[
F(t,x)=-\log\Par{t-f(x)}-\max(4,\beta^{2},\gamma^{2})\log x
\]
is a highly $(1+\max(4,\beta^{2},\gamma^{2}))$-self-concordant barrier
for the two dimensional convex domain
\[
G_{f}=\overline{\Brace{(t,x)\in\R^{2}:x>0,\,t\geq f(x)}}.
\]
\end{lem}

The proof of this lemma follows by applying the previous lemma to
the image of $G_{f}$ under the map $(t,x)\to(-x,t)$.
