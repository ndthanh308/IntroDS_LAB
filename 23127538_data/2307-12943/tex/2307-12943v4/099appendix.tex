
\appendix
\addtocontents{toc}{\protect\setcounter{tocdepth}{1}} 

\section{Backgrounds on matrix algebra}

\subsection{Matrix identities}

We collect algebraic identities related to trace, vectorization, Kronecker
and Hadamard product. 
\global\long\def\vec{\textup{\textsf{vec}}}%
 
\begin{lem}
[Kronecker product] \label{lem:Kronecker} For $A,B,C,D\in\Rdd$
and $M$ in Definition~\ref{def:linearOperators},

\begin{multicols}{2}
\begin{enumerate}
\item $(A\otimes B)\,\vec(C)=\tr(BCA^{\T})$.
\item $\vec(A)^{\T}(B\otimes C)\vec(D)=\tr(DB^{\T}A^{\T}C)$.
\item $(A\otimes B)(C\otimes D)=AC\otimes BD$.
\item $(A\otimes B)^{-1}=A^{-1}\otimes B^{-1}$.
\item $(A\otimes B)^{\T}=A^{\T}\otimes B^{\T}$.
\item $\tr(A\otimes B)=\tr(A)\tr(B)$.
\item $\det\bpar{M^{\T}(A\otimes A)M}=2^{\nicefrac{d(d-1)}{2}}(\det A)^{d+1}$.
\item[]
\end{enumerate}
\end{multicols}
\end{lem}

\begin{lem}
[Hadamard product] \label{lem:Hadamard} Let $A,B,C,D\in\Rdd$,
$x,y\in\Rd$, and $D_{1},D_{2}\in\Rdd$ be diagonal matrices.

\begin{multicols}{2}
\begin{enumerate}
\item $(A\circ B)y=\diag(A\,\Diag(y)B^{\T})$.
\item $x^{\T}(A\circ B)y=\tr(\Diag(x)A\,\Diag(y)B^{\T})$.
\item $D_{1}(A\hada B)=(D_{1}A)\hada B=A\hada(D_{1}B)$.
\item $(A\hada B)D_{2}=(AD_{2})\hada B=A\hada(BD_{2})$.
\item $(A\otimes B)\circ(C\otimes D)=(A\circ C)\otimes(B\circ D)$. \item[]
\end{enumerate}
\end{multicols}
\end{lem}


\subsection{Matrix calculus \label{app:matrixCalculus}}

Let $g(x):\Rd\to\Rdd$ be a matrix function. Its gradient at $x$,
denoted by $\Dd g(x)$, is the third-order tensor defined by $(\Dd g(x))_{ijk}=\pderiv{g_{ij}(x)}{x_{k}}$.
Unless specified otherwise, the multiplication between higher-order
tensors and a matrix of size $d\times d$ is running over $(i,j)$-entries.
For instance, for a matrix $M\in\Rdd$ the product $\Dd g(x)\cdot M$
indicates the third-order tensor defined by
\[
(\Dd g(x)\,M)_{\cdot,\cdot,k}=(\Dd g(x))_{\cdot,\cdot,k}M\text{ for each }k\in[d]\,.
\]
In the same way, the trace is applied to a matrix spanned by $(i,j)$-entries,
i.e.,
\[
\bpar{\tr(\Dd g(x))}_{k}=\tr\Bpar{\bpar{\Dd g(x)}_{\cdot,\cdot,k}}\,.
\]

For $\vphi:\Rd\to\R$ with $\vphi(\cdot):=\log\det g(\cdot)$, its
gradient and the directional derivative in $h\in\Rd$ are
\begin{equation}
\grad\vphi(x)=\tr\bpar{g(x)^{-1}\Dd g(x)}\,,\qquad\text{and}\qquad\grad\vphi(x)\cdot h=\tr\bpar{g(x)^{-1}\Dd g(x)[h]}\,.\label{eq:gradLogDet}
\end{equation}
For the Hessian of $\vphi$, using the product rule and 
\begin{equation}
\Dd(g^{-1})(x)=-g(x)^{-1}\Dd g(x)\,g(x)^{-1}\,,\label{eq:diffInverse}
\end{equation}
we obtain
\begin{align}
\hess\vphi(x) & =\Dd\tr\bpar{g(x)^{-1}\Dd g(x)}=-\tr\bpar{g(x)^{-1}\Dd g(x)\,g(x)^{-1}\Dd g(x)}+\tr\bpar{g(x)^{-1}\Dd^{2}g(x)}\nonumber \\
 & =\tr\bpar{g(x)^{-1}\Dd^{2}g(x)}-\snorm{g(x)^{-\half}\Dd g(x)\,g(x)^{-\half}}_{F}^{2}\,,\label{eq:hessLogDet}
\end{align}
where $\Dd^{2}g(x)$ is the fourth-order tensor defined by $(\Dd^{2}g(x))_{ijkl}=\frac{\de[g(x)]_{ij}}{\de x_{k}\de x_{l}}$.

We now present formulas for the Hessian and its inverse of $\phi(\cdot)=-\log\det(\cdot)$
on $\pd$.
\begin{proof}
[Proof of Proposition \ref{prop:metricFormula}] By setting $g(X)=X$
and $\phi(X)=-\vphi(X)$ above, \eqref{eq:hessLogDet} implies that
for a symmetric matrix $H\in\mbb S^{d}$
\begin{align}
\hess\phi(X)[H,H] & =\snorm{X^{-\half}HX^{-\half}}_{F}^{2}=\tr(X^{-1}HX^{-1}H)\label{eq:2ndDiffLogDet}\\
 & =\vec(H)^{\T}(X^{-1}\otimes X^{-1})\vec(H)=\vec(H)^{\T}(X\otimes X)^{-1}\vec(H)\,,\nonumber 
\end{align}
where the last equality follows from Lemma~\ref{lem:Kronecker}.
When representing $X$ and $H$ in $\R^{d_{s}}$ space with notations
$x:=\svec(X)$ and $h:=\svec(H)$, the definition of $M$ (see Definition~\ref{def:linearOperators})
turns \eqref{eq:2ndDiffLogDet} into
\[
\hess\phi(x)[h,h]=h^{\T}M^{\T}(X\otimes X)^{-1}Mh\,,
\]
and thus $g_{X}:=\nabla_{x}^{2}\phi(x)=\nabla_{X}^{2}\phi(X)$ equals
$M^{\T}(X\otimes X)^{-1}M$. The formula for the inverse, $g_{X}^{-1}=M^{\dagger}(X\otimes X)(M^{\dagger})^{\T}$,
is immediate from \citet{magnus1980elimination}, and another part
follows from $M^{\dagger}=LN$ and $N^{\T}=N$ \citet[Lemma 3.6 and Lemma 2.1]{magnus1980elimination}.
\end{proof}

\section{Self-concordant barriers for linear constraints}

We collect details on self-concordant barriers for linear constraints,
$P=\{x\in\Rd:Ax\geq b\}$ with $A\in\R^{m\times d}$ and $b\in\R^{m}$:
the logarithmic, volumetric, and Lewis-weight barrier/metric. Recall
the notations used in the paper: $s_{x}=\diag(Ax-b)\in\R^{m}$, $S_{x}=\Diag(s_{x})\in\R^{m\times m}$,
and $A_{x}=S_{x}^{-1}A\in\R^{m\times d}$. Also, $s_{x,h}=A_{x}h\in\R^{m}$
and $S_{x,h}=\Diag(s_{x,h})\in\R^{m\times m}$. Let $h\in\Rd$.

\subsection{Logarithmic barriers \label{proof:linear-log-barrier}}

 For $x\in P$, the logarithmic barrier (or log-barrier) and the
Hessian metric are given by
\[
\phi_{\log}(x):=-\sum_{i=1}^{m}\log(a_{i}^{\T}x-b)\,,\qquad\text{and}\qquad g(x)=\hess\phi(x)=A_{x}^{T}A_{x}\,.
\]

\begin{claim}
\label{claim:diffLogBarrier} $\Dd S_{x}[h]=\Diag(Ah)$ and $\Dd S_{x}^{-1}[h]=-S_{x}^{-1}S_{x,h}$.
Also, $\Dd g(x)[h]=-2A_{x}^{\T}S_{x,h}A_{x}$ and $\Dd^{2}g(x)[h,h]=6A_{x}^{\T}S_{x,h}^{2}A_{x}\succeq0$.
\end{claim}

\begin{proof}
The first is obvious from differentiation of $S_{x}=\Diag(Ax-b)$
w.r.t. $x$. As for the second,
\begin{align*}
\Dd S_{x}^{-1}[h] & =-S_{x}^{-1}\Dd S_{x}[h]\,S_{x}^{-1}=-S_{x}^{-1}\Diag(Ah)S_{x}^{-1}=-S_{x}^{-1}\Diag(A_{x}h)=-S_{x}^{-1}S_{x,h}\,.
\end{align*}
As for the third and fourth, as $g(x)=A^{\T}S_{x}^{-2}A$,
\begin{align*}
\Dd g(x)[h] & =A^{\T}\Dd S_{x}^{-2}[h]\,A=-2A^{\T}S_{x}^{-3}\Dd S_{x}[h]A=-2A_{x}^{\T}S_{x}^{-1}\Diag(Ah)A_{x}=-2A_{x}^{\T}S_{x,h}A_{x}\,.\\
\Dd^{2}g(x)[h,h] & =-2A^{\T}\Dd S_{x}^{-3}[h]\,\Diag(Ah)A=6A^{\T}S_{x}^{-4}\Dd S_{x}[h]\,\Diag(Ah)A=6A_{x}^{\T}S_{x,h}^{2}A_{x}\,.\qedhere
\end{align*}
\end{proof}

\subsection{Volumetric barriers \label{proof:linear-volumetric}}

\citet{vaidya1996new} introduced the \emph{volumetric barrier} for
$P$, defined by 
\[
\phi_{\vol}(x)=\half\,\log\det\bpar{\hess\phi_{\log}(x)}=\half\,\log\det(A_{x}^{\T}A_{x})\,.
\]

\begin{claim}
$\grad\phi_{\vol}(x)=-A_{x}^{\T}\sigma_{x}$ and $\hess\phi_{\vol}(x)=A_{x}^{\T}(3\Sigma_{x}-2P_{x}^{(2)})A_{x}$.
\end{claim}

\begin{proof}
For $P_{x}:=P(A_{x})$, using \eqref{eq:gradLogDet} with Claim~\ref{claim:diffLogBarrier}
and apply Lemma~\ref{lem:Hadamard} in (i),
\begin{align*}
\grad\phi_{\vol}(x)[h] & =-\tr\bpar{(A_{x}^{\T}A_{x})^{-1}A_{x}^{\T}S_{x,h}A_{x}}=-\tr(P_{x}S_{x,h})\underset{\text{(i)}}{=}-1^{\T}(P_{x}\circ I_{m})s_{x,h}=-h^{\T}A_{x}^{\T}\sigma_{x}\,,
\end{align*}

For the Hessian of $\phi_{\vol}$, let $g(x)=A_{x}^{\T}A_{x}$ and
then by \eqref{eq:hessLogDet}, 
\[
\hess\phi_{\vol}(x)[h,h]=\half\,\bpar{\tr(g^{-1}\Dd^{2}g[h,h])-\tr(g^{-1}\Dd g[h]\,g^{-1}\Dd g[h])}\,.
\]
As for the first term, Claim~\ref{claim:diffLogBarrier} leads to
\begin{align*}
\tr(g^{-1}\Dd^{2}g[h,h]) & =6\tr(g^{-1}A_{x}^{\T}S_{x,h}^{2}A_{x})=6\tr(P_{x}S_{x,h}IS_{x,h})=6h^{\T}A_{x}^{\T}(P_{x}\circ I)A_{x}h=6h^{\T}A_{x}^{\T}\Sigma_{x}A_{x}h\,.
\end{align*}
As for the second term, 
\begin{align*}
\tr(g^{-1}\Dd g[h]\,g^{-1}\Dd g[h]) & =4\tr(P_{x}S_{x,h}P_{x}S_{x,h})=4(A_{x}h)^{\T}(P_{x}\circ P_{x})(A_{x}h)=4h^{\T}A_{x}^{\T}P_{x}^{(2)}A_{x}h\,.
\end{align*}
Hence, $\Dd^{2}\phi_{\vol}(x)[h,h]=h^{\T}A_{x}^{\T}(3\Sigma_{x}-2P_{x}^{(2)})A_{x}h$,
which completes the proof.
\end{proof}
\begin{claim}
\label{claim:schurProjection} $P_{x}^{(2)}\preceq\Sigma_{x}$, so
$A_{x}^{\T}\Sigma_{x}A_{x}\preceq\hess\phi_{\vol}(x)\preceq3A_{x}^{\T}\Sigma_{x}A_{x}$.
\end{claim}

\begin{proof}
Due to $\Sigma_{x}=P_{x}\circ I$, it suffices to show $h^{\T}P_{x}\circ(I-P_{x})\,h\geq0$
for any $h\in\Rd$. Since $P_{x}$ and $I-P_{x}$ are orthogonal projections,
for $H=\Diag(h)$ and $C:=P_{x}H(I-P_{x})$ ,
\begin{align*}
h^{\T}P_{x}\circ(I-P_{x})\,h & =\tr\bpar{HP_{x}H(I-P_{x})}=\tr\bpar{(I-P_{x})HP_{x}P_{x}H(I-P_{x})}=\tr(C^{\T}C)\geq0\,.\qedhere
\end{align*}
\end{proof}

\subsubsection{Derivatives of leverage scores and projection matrices}

 We derive formulas for derivatives of leverage scores, orthogonal
projections, and so on.
\begin{lem}
\label{lem:calculusLeverage} For $x,h\in\Rd$, let $P_{x}=A_{x}(A_{x}^{\T}A_{x})^{-1}A_{x}^{\T}$,
$\Sigma_{x}=\Diag(P_{x})$, and $\Lambda_{x}=\Sigma_{x}-P_{x}^{(2)}$.
Denote $\theta(x):=A_{x}^{\T}\Sigma_{x}A_{x}$.
\begin{itemize}
\item \textup{\citet[Lemma 24]{lee2019solving}} $\Sigma_{x,h}'=-2\Diag(\Lambda_{x}s_{x,h})=2\bpar{\Diag(P_{x}S_{x,h}P_{x})-\Sigma_{x}S_{x,h}}$.
\item \textup{\citet[Lemma 49]{lee2019solving}} $P_{x,h}'=-P_{x}S_{x,h}-S_{x,h}P_{x}+2P_{x}S_{x,h}P_{x}$.
\item $\Lambda_{x,h}'=-2\Diag(\Lambda_{x}s_{x,h})+2P_{x}\circ P_{x}S_{x,h}+2S_{x,h}P_{x}\circ P_{x}-2(P_{x}S_{x,h}P_{x})\circ P_{x}-2P_{x}\circ(P_{x}S_{x,h}P_{x})$.
\item $\Sigma_{x,h}''=6S_{x,h}\Sigma_{x}S_{x,h}+8\Diag(P_{x}S_{x,h}P_{x}S_{x,h}P_{x})-6\Diag(P_{x}S_{x,h}^{2}P_{x})-8\Diag(S_{x,h}P_{x}S_{x,h}P_{x})$.
\item $\Dd\theta(x)[h]=-2A_{x}^{\T}\Sigma_{x}S_{x,h}A_{x}+A_{x}^{\T}\Sigma_{x,h}'A_{x}$.
\item $\Dd^{2}\theta(x)[h,h]=6A_{x}^{\T}S_{x,h}\Sigma_{x}S_{x,h}A_{x}-4A_{x}^{\T}\Sigma_{x,h}'S_{x,h}A_{x}+A_{x}^{\T}\Sigma_{x,h}''A_{x}$.
Equivalently, 
\begin{align*}
\Dd^{2}\theta(x)[h,h] & =20A_{x}^{\T}S_{x,h}\Sigma_{x}S_{x,h}A_{x}-16A_{x}^{\T}\Diag(S_{x,h}P_{x}S_{x,h}P_{x})A_{x}\\
 & \qquad-6A_{x}^{\T}\Diag(P_{x}S_{x,h}^{2}P_{x})A_{x}+8A_{x}^{\T}\Diag(P_{x}S_{x,h}P_{x}S_{x,h}P_{x})A_{x}.
\end{align*}
\end{itemize}
\end{lem}

\begin{proof}
As for the third item,
\begin{align*}
 & \Lambda_{x,h}'=\Sigma_{x,h}'-P_{x,h}'\circ P_{x}-P_{x}\circ P_{x,h}'\\
 & =-2\Diag(\Lambda_{x}s_{x,h})-(-P_{x}S_{x,h}-S_{x,h}P_{x}+2P_{x}S_{x,h}P_{x})\circ P_{x}-P_{x}\circ(-P_{x}S_{x,h}-S_{x,h}P_{x}+2P_{x}S_{x,h}P_{x})\\
 & \underset{\text{(i)}}{=}-2\Diag(\Lambda_{x}s_{x,h})+2P_{x}\circ P_{x}S_{x,h}+2S_{x,h}P_{x}\circ P_{x}-2(P_{x}S_{x,h}P_{x})\circ P_{x}-2P_{x}\circ(P_{x}S_{x,h}P_{x})\,,
\end{align*}
where in (i) we used $D(A\hada B)=(DA)\circ B=A\hada(DB)$ and $(A\hada B)D=(AD)\hada B=A\circ(BD)$\footnote{This property allows us to write $DA\hada B$ without parenthesis.}
for a diagonal matrix $D\in\Rdd$ (Lemma~\ref{lem:Hadamard}). 

As for the fourth item,
\begin{align*}
 & \Sigma_{x,h}''=-2\Dd\bpar{\Diag(\Lambda_{x}s_{x,h})}[h]=-2\Diag(\Lambda_{x,h}'s_{x,h})+2\Diag(\Lambda_{x}S_{x,h}s_{x,h})\\
 & =-2\Diag\bpar{\bbrack{-2\Diag(\Lambda_{x}s_{x,h})+2P_{x}\circ P_{x}S_{x,h}+2S_{x,h}P_{x}\circ P_{x}-2(P_{x}S_{x,h}P_{x})\circ P_{x}-2P_{x}\circ(P_{x}S_{x,h}P_{x})}s_{x,h}}\\
 & \qquad+2\Diag(\Lambda_{x}S_{x,h}s_{x,h})\\
 & =4\Diag(\cred{\Lambda_{x}}s_{x,h})\cblue{S_{x,h}}-4\Diag(P_{x}\circ P_{x}S_{x,h}s_{x,h})-4\Diag(S_{x,h}P_{x}\circ P_{x}s_{x,h})\\
 & \qquad+4\Diag\bpar{(P_{x}S_{x,h}P_{x})\circ P_{x}s_{x,h}}+4\Diag\bpar{P_{x}\circ(P_{x}S_{x,h}P_{x})s_{x,h}}+2\Diag(\cred{\Lambda_{x}}S_{x,h}s_{x,h})\\
 & =4\Diag\bpar{\cblue{S_{x,h}}\cred{(\Sigma_{x}-P_{x}\circ P_{x})}s_{x,h}}-4\Diag(P_{x}\circ P_{x}S_{x,h}s_{x,h})-4\Diag(S_{x,h}P_{x}\circ P_{x}s_{x,h})\\
 & \qquad+4\Diag\bpar{(P_{x}S_{x,h}P_{x})\circ P_{x}s_{x,h}}+4\Diag\bpar{P_{x}\circ(P_{x}S_{x,h}P_{x})s_{x,h}}+2\Diag\bpar{\cred{(\Sigma_{x}-P_{x}\circ P_{x})}S_{x,h}s_{x,h}}\\
 & =\ccyan{4\Diag(S_{x,h}\Sigma_{x}s_{x,h})}-6\Diag(P_{x}\circ P_{x}S_{x,h}s_{x,h})-8\Diag(S_{x,h}P_{x}\circ P_{x}s_{x,h})\\
 & \qquad+4\Diag\bpar{(P_{x}S_{x,h}P_{x})\circ P_{x}s_{x,h}}+4\Diag\bpar{P_{x}\circ(P_{x}S_{x,h}P_{x})s_{x,h}}+\ccyan{2\Diag(\Sigma_{x}S_{x,h}s_{x,h})}\\
 & =\text{\ensuremath{\ccyan{6\Diag(S_{x,h}\Sigma_{x}s_{x,h})}}}-6\Diag(\cblue{P_{x}\circ P_{x}S_{x,h}s_{x,h}})-8\Diag(\cblue{S_{x,h}P_{x}\circ P_{x}s_{x,h}})\\
 & \qquad+4\Diag\bpar{\cblue{(P_{x}S_{x,h}P_{x})\circ P_{x}s_{x,h}}}+4\Diag\bpar{\cblue{P_{x}\circ(P_{x}S_{x,h}P_{x})s_{x,h}}}\\
 & \underset{\text{(i)}}{=}6S_{x,h}\Sigma_{x}\Diag(s_{x,h})-6\Diag\Bpar{\diag\bpar{P_{x}S_{x,h}(P_{x}S_{x,h})^{\T}}}-8\Diag\Bpar{\diag(S_{x,h}P_{x}S_{x,h}P_{x}^{\T})}\\
 & \qquad+4\Diag(P_{x}S_{x,h}P_{x}S_{x,h}P_{x})+4\Diag\bpar{P_{x}S_{x,h}(P_{x}S_{x,h}P_{x})^{\T}}\\
 & =6S_{x,h}\Sigma_{x}S_{x,h}-6\Diag(P_{x}S_{x,h}^{2}P_{x})-8\Diag(S_{x,h}P_{x}S_{x,h}P_{x})+8\Diag(P_{x}S_{x,h}P_{x}S_{x,h}P_{x})\,,
\end{align*}
where in (i) we applied Lemma~\ref{lem:Hadamard}-1 to the terms
with blue. 

Applying the product rule to $\theta(x)=A_{x}^{\T}\Sigma_{x}A_{x}=A^{\T}S_{x}^{-2}\Sigma_{x}A,$
\begin{align*}
\Dd\theta[h] & =-2A^{\T}S_{x}^{-3}\Sigma_{x}\Diag(Ah)A+A^{\T}S_{x}^{-2}\Sigma_{x,h}'A=-2A_{x}^{\T}\Sigma_{x}S_{x,h}A_{x}+A_{x}^{\T}\Sigma_{x,h}'A_{x}\,,\\
\Dd^{2}\theta[h,h] & =6A_{x}^{\T}S_{x,h}\Sigma_{x}S_{x,h}A_{x}-2A_{x}^{\T}\Sigma_{x,h}'S_{x,h}A_{x}-2A_{x}^{\T}S_{x,h}\Sigma_{x,h}'A_{x}+A_{x}^{\T}\Sigma_{x,h}''A_{x}\\
 & =6A_{x}^{\T}S_{x,h}\Sigma_{x}S_{x,h}A_{x}-4A_{x}^{\T}\Sigma_{x,h}'S_{x,h}A_{x}+A_{x}^{\T}\Sigma_{x,h}''A_{x}\,.
\end{align*}
By substituting $\Sigma_{x,h}'$ and $\Sigma_{x,h}''$ with our formulas
above, 
\begin{align*}
 & \Dd^{2}\theta[h,h]=6A_{x}^{\T}S_{x,h}\Sigma_{x}S_{x,h}A_{x}-4A_{x}^{\T}\Sigma_{x,h}'S_{x,h}A_{x}+A_{x}^{\T}\Sigma_{x,h}''A_{x}\\
 & =6A_{x}^{\T}S_{x,h}\Sigma_{x}S_{x,h}A_{x}+8A_{x}^{\T}\bpar{\Sigma_{x}S_{x,h}-\Diag(P_{x}S_{x,h}P_{x})}S_{x,h}A_{x}\\
 & \qquad+A_{x}^{\T}\Bpar{6S_{x,h}\Sigma_{x}S_{x,h}-6\Diag(P_{x}S_{x,h}^{2}P_{x})-8\Diag(S_{x,h}P_{x}S_{x,h}P_{x})+8\Diag(P_{x}S_{x,h}P_{x}S_{x,h}P_{x})}A_{x}\\
 & =20A_{x}^{\T}S_{x,h}\Sigma_{x}S_{x,h}A_{x}-16A_{x}^{\T}\Diag(S_{x,h}P_{x}S_{x,h}P_{x})A_{x}-6A_{x}^{\T}\Diag(P_{x}S_{x,h}^{2}P_{x})A_{x}\\
 & \qquad+8A_{x}^{\T}\Diag(P_{x}S_{x,h}P_{x}S_{x,h}P_{x})A_{x}\,.\qedhere
\end{align*}
\end{proof}

\subsection{Lewis-weight metric \label{proof:linear-LW}}

We recall preliminaries on the Lewis weights. Particularly, the leverage
scores are simply the $\ell_{2}$-Lewis weights.
\begin{lem}
[\citet{lee2019solving}] \label{lem:usefulFactLewis} Let $W_{x}=\Diag(w_{x}(A_{x}))\in\pd$
be the $\ell_{p}$-Lewis weights and $g(x)=A_{x}^{\T}W_{x}A_{x}$
the Lewis-weights metric, and $h\in\Rd$.
\begin{itemize}
\item \textup{(Lemma 26)} $\max_{i\in[m]}\frac{[\sigma(W_{x}^{1/2}A_{x})]_{i}}{(w_{x})_{i}}\leq2m^{\frac{2}{p+2}}$.
\item \textup{(Lemma 33)} $\norm{A_{x}h}_{W_{x}}=\norm h_{g(x)}$ and $\norm{A_{x}h}_{\infty}\leq\sqrt{2}m^{\frac{1}{p+2}}\norm h_{g(x)}$.
\item \textup{(Lemma 34)} $\norm{W_{x}^{-1}w_{x,h}'}_{W_{x}}\leq p\,\norm h_{g(x)}$.
\end{itemize}
\end{lem}

Next is a directional derivative of the $\ell_{p}$-Lewis weight of
$A_{x}$.
\begin{lem}
[\citet{lee2019solving}, Lemma 24] \label{lem:DWh} The directional
derivative of the $\ell_{p}$-Lewis weight $W_{x}$ in direction $h\in\Rd$
is
\[
W_{x,h}':=\Dd W_{x}[h]=-2\,\Diag(\Lambda_{x}G_{x}^{-1}W_{x}s_{x,h})=-\Diag(W_{x}^{\half}N_{x}W_{x}^{\half}s_{x,h})\,,
\]
where $\Lambda_{x}\defeq W_{x}-P_{x}^{(2)}$, $\bar{\Lambda}_{x}\defeq W_{x}^{-\half}\Lambda_{x}W_{x}^{-\half}$,
$G_{x}\defeq W_{x}-\bpar{1-\frac{2}{p}}\Lambda_{x}$, and $N_{x}\defeq2\bar{\Lambda}_{x}(I-c_{p}\bar{\Lambda}_{x})^{-1}$.
\end{lem}

It is known that these matrices satisfy
\begin{align}
P_{x}^{(2)}\preceq W_{x}\preceq I\,,\label{eq:lewisBasic-PWI}\\
\Lambda_{x}\preceq W_{x}\,,\label{eq:lewisBasic-LW}\\
\frac{2}{p}W_{x}\preceq G_{x}\preceq W_{x}\,, & \text{ which implies }W_{x}^{-1}\preceq G_{x}^{-1}\preceq\frac{p}{2}W_{x}^{-1}\text{ and }I\preceq W_{x}^{\half}G_{x}^{-1}W_{x}^{\half}\preceq\frac{p}{2}I\,.\label{eq:lewisBasic-WGW}
\end{align}
We can also compute the second-order directional derivative of $W_{x}$
in direction $h\in\Rd$.
\begin{lem}
[Second-order derivative of $W_x$] \label{lem:second-deriv-Lewis}
Let $w_{x}\in\R^{m}$ be the $\ell_{p}$-Lewis weight, $\Gamma\in\R_{\geq0}^{m\times m}$
a diagonal matrix, and $h\in\Rd$. Then,
\begin{align}
 & W_{x,h}''=-\Diag\bpar{\half W_{x}^{-\half}W_{x,h}'N_{x}W_{x}^{\half}s_{x,h}+W_{x}^{\half}N_{x,h}'W_{x}^{\half}s_{x,h}+\half W_{x}^{\half}N_{x}W_{x}^{-\half}W_{x,h}'s_{x,h}+2\Lambda_{x}G_{x}^{-1}W_{x}s_{x,h}^{2}}\,,\nonumber \\
 & \tr(\Gamma W_{x,h}'')=-\half\,\tr\bpar{\Gamma\,\Diag(\underbrace{W_{x}^{-\half}W_{x,h}'N_{x}W_{x}^{\half}s_{x,h}}_{\textup{\text{I}}})}-\tr\bpar{\Gamma\,\Diag(\underbrace{W_{x}^{\half}N_{x,h}'W_{x}^{\half}s_{x,h}}_{\textup{\text{II}}})}\nonumber \\
 & \qquad\qquad\qquad-\half\,\tr\bpar{\Gamma\,\Diag(\underbrace{W_{x}^{\half}N_{x}W_{x}^{-\half}W_{x,h}'s_{x,h}}_{\textup{\text{III}}})}-2\tr\bpar{\Gamma\,\Diag(\underbrace{\Lambda_{x}G_{x}^{-1}W_{x}S_{x,h}s_{x,h}}_{\textup{\text{IV}}})}\,,\label{eq:trGamma}\\
 & \Dd^{2}(A_{x}^{\T}W_{x}A_{x})[h,h]=6A_{x}^{\T}S_{x,h}W_{x}S_{x,h}A_{x}-4A_{x}^{\T}W_{x,h}'S_{x,h}A_{x}+A_{x}^{\T}W_{x,h}''A_{x}\label{eq:LW-second-derv}
\end{align}
where $\snorm{\textup{I}}_{W_{x}^{-1}}\lesssim p^{3}m^{\frac{1}{p+2}}\norm h_{\theta}^{2}$,
$\norm{\textup{\text{II}}}_{W_{x}^{-1}}\lesssim p^{3.5}\norm h_{\theta}^{2}$,
$\norm{\textup{\text{III}}}_{W_{x}^{-1}}\lesssim p^{3}m^{\frac{1}{p+2}}\,\norm h_{\theta}^{2}$,
and $\norm{\textup{\text{IV}}}_{W_{x}^{-1}}\lesssim pm^{\frac{1}{p+2}}\norm h_{\theta}^{2}$.
Here, $\lesssim$ hides universal constants and poly-logarithmic factors
in $m$.
\end{lem}

\begin{proof}
The formula for $W_{x,h}''$ follows from differentiating the formula
for $W_{x,h}'$ (Lemma~\ref{lem:DWh}). The dual local norms of I\textasciitilde IV
can be bounded as follows:
\begin{align*}
\norm{\text{I}}_{W_{x}^{-1}} & =\norm{W_{x}^{-1}W_{x,h}'N_{x}W_{x}^{\half}s_{x,h}}_{2}\leq\underbrace{\norm{W_{x}^{-1}W_{x,h}'}_{2}}_{\text{Lemma \ref{lem:LS-comp-tool}-2}}\underbrace{\norm{N_{x}}_{2}}_{\text{Lemma \ref{lem:LS-comp-tool}-1}}\norm{W_{x}^{\half}s_{x,h}}_{2}\lesssim p^{3}m^{\frac{1}{p+2}}\norm h_{\theta}^{2}\,,\\
\norm{\text{II}}_{W_{x}^{-1}} & =\norm{N_{x,h}'W_{x}^{\half}s_{x,h}}_{2}\leq\underbrace{\norm{I+N_{x}}_{2}}_{\text{Lemma \ref{lem:LS-comp-tool}-1}}\underbrace{\norm{(I+N_{x})^{-\half}N_{x,h}'(I+N_{x})^{-\half}}_{2}}_{\text{Lemma \ref{lem:LS-comp-tool}-3}}\norm{W_{x}^{\half}s_{x,h}}_{2}\lesssim p^{3.5}\norm h_{\theta}^{2}\,,\\
\norm{\text{III}}_{W_{x}^{-1}} & =\norm{N_{x}W_{x}^{-\half}W_{x,h}'s_{x,h}}_{2}\leq\underbrace{\norm{N_{x}}_{2}}_{\text{Lemma \ref{lem:LS-comp-tool}-1}}\underbrace{\norm{W_{x}^{-1}W_{x,h}'}_{2}}_{\text{Lemma \ref{lem:LS-comp-tool}-2}}\norm{W_{x}s_{x,h}}_{2}\lesssim p^{3}m^{\frac{1}{p+2}}\,\norm h_{\theta}^{2}\,,\\
\norm{\text{IV}}_{W_{x}^{-1}}^{2} & =s_{x,h}^{\T}S_{x,h}W_{x}G_{x}^{-1}\underbrace{\Lambda_{x}W_{x}^{-1}\Lambda_{x}}_{\preceq W_{x}\ \text{\eqref{eq:lewisBasic-LW}}}G_{x}^{-1}W_{x}S_{x,h}s_{x,h}\leq s_{x,h}^{\T}S_{x,h}W_{x}\underbrace{G_{x}^{-1}W_{x}G_{x}^{-1}}_{\preceq\frac{p^{2}}{4}W_{x}^{-1}\ \text{\eqref{eq:lewisBasic-WGW}}}W_{x}S_{x,h}s_{x,h}\\
 & \leq p^{2}s_{x,h}^{\T}W_{x}^{\half}S_{x,h}^{2}W_{x}^{\half}s_{x,h}\leq p^{2}\norm{s_{x,h}}_{\infty}^{2}\norm h_{\theta}^{2}\leq p^{2}m^{\frac{2}{p+2}}\norm h_{\theta}^{4}\,,
\end{align*}
where we used Lemma~\ref{lem:usefulFactLewis}-2 in the last inequality.
\end{proof}
Next, we recall bounds on the derivatives of matrices relevant to
Lewis weights.
\begin{lem}
[\citet{lee2019solving}] \label{lem:LS-comp-tool} Let $Ax\geq b$
and $h\in\Rd$. For $c_{p}=1-2/p$ with $p>2$, let $\bar{\Lambda}_{x}:=W_{x}^{-\half}\Lambda_{x}W_{x}^{-\half}=I-W_{x}^{-\half}P_{x}^{(2)}W_{x}^{-\half}$,
$N_{x}\defeq2\bar{\Lambda}_{x}(I-c_{p}\bar{\Lambda}_{x})^{-1}$ and
$\theta_{x}=A_{x}^{\T}W_{x}A_{x}$.
\begin{itemize}
\item \textup{(Lemma 31)} $N_{x}$ is symmetric and $0\preceq N_{x}\preceq pI$.
\item \textup{(Lemma 34)} $\norm{W_{x}^{-1}w_{x,h}}_{\infty}\leq p(\sqrt{2}m^{\frac{1}{p+2}}+p/2)\,\norm h_{\theta_{x}}$.
\item \textup{(Lemma 37)} $\norm{(I+N_{x})^{-\half}\Dd N_{x}[h]\,(I+N_{x})^{-\half}}_{2}\leq4p^{5/2}\norm h_{\theta_{x}}$.
\end{itemize}
\end{lem}

Lastly, we remind a result about closeness of the Lewis weights at
close-by points.
\begin{lem}
[\citet{lee2019solving}] \label{lem:weight-close} In the same
setting above, let $x_{t}=x+th$, $s_{t}=s_{x_{t}}$, $w_{t}=w_{x_{t}}$,
and $z_{t,\alpha}\in\R^{m}$ be a vector defined by $[z_{t,\alpha}]_{i}:=\frac{\D}{\D t}\log\Bpar{\frac{[w_{t,i}]^{\alpha}}{s_{t,i}}}$.
Then,
\[
\norm{z_{t}}_{\infty}\leq\bpar{\sqrt{2}(1+|\alpha|p)m^{\frac{1}{p+2}}+p\,|\alpha|\,\max(1,p/2)}\,\norm h_{A_{t}^{\T}W_{t}A_{t}}\,.
\]
\end{lem}

Now we present an auxiliary result showing HSC of the Lewis-weight
metric.
\begin{lem}
\label{lem:Lw-hsc} The metric $g(x)=cA_{x}^{\T}W_{x}A_{x}$ is HSC
for $c=c_{1}(\log m)^{c_{2}}d^{1/2}$ with some constants $c_{1},c_{2}>0$, 
\end{lem}

\begin{proof}
Let $\theta(x)=A_{x}^{\T}W_{x}A_{x}$ and $h\in\Rd$. From \eqref{eq:LW-second-derv},
\begin{align}
\Dd^{2}\theta[h,h,h,h] & =6s_{x,h}^{\T}S_{x,h}W_{x}S_{x,h}s_{x,h}-4s_{x,h}^{\T}W_{x,h}'S_{x,h}s_{x,h}+s_{x,h}^{\T}W_{x,h}''s_{x,h}\nonumber \\
 & =\tr(6S_{x,h}^{4}W_{x}-4S_{x,h}^{3}W_{x,h}'+S_{x,h}^{2}W_{x,h}'')\,.\label{eq:LW-fourth-moment}
\end{align}
As for the first term, $|\tr(S_{x,h}^{4}W_{x})|\leq\norm{s_{x,h}}_{\infty}^{2}\norm h_{\theta}^{2}$.
As for the second term,
\begin{align}
|\tr(S_{x,h}^{3}W_{x,h}')| & \leq\norm{s_{x,h}}_{\infty}^{2}\tr\bpar{\sqrt{S_{x,h}W_{x,h}'^{2}S_{x,h}}}=\norm{s_{x,h}}_{\infty}^{2}\tr\bpar{\sqrt{W_{x,h}'W_{x}^{-1}W_{x,h}'}\sqrt{S_{x,h}W_{x}S_{x,h}}}\nonumber \\
 & \underset{\text{(i)}}{\leq}\norm{s_{x,h}}_{\infty}^{2}\sqrt{\tr(W_{x,h}'W_{x}^{-1}W_{x,h}')}\sqrt{\tr(S_{x,h}W_{x}S_{x,h})}=\norm{s_{x,h}}_{\infty}^{2}\norm{W_{x}^{-1}w_{x,h}'}_{W_{x}}\norm h_{\theta}\nonumber \\
 & \underset{\text{(ii)}}{\leq}p\norm{s_{x,h}}_{\infty}^{2}\norm h_{\theta}^{2}\label{eq:trSW}
\end{align}
where we used the Cauchy-Schwarz in (i) and Lemma~\ref{lem:usefulFactLewis}-3
in (ii).  

As for the last term, we first use the formula for $\tr(S_{x,h}^{2}W_{x,h}'')$
with $\Gamma=S_{x,h}^{2}$ in Lemma~\ref{lem:second-deriv-Lewis}.
Each term there is of the form $\tr(S_{x,h}^{2}\Diag(v))$ for $v=\,$I
\textasciitilde{} IV, which can be bounded as follows:
\begin{align}
\big|\tr\bpar{S_{x,h}^{2}\Diag(v)}\big| & =\big|\tr\bpar{S_{x,h}^{2}W_{x}^{\half}W_{x}^{-\half}\Diag(v)}\big|\leq\sqrt{\tr(W_{x}^{\half}S_{x,h}^{4}W_{x}^{\half})}\sqrt{\tr\bpar{\Diag(v)W_{x}^{-1}\Diag(v)}}\label{eq:last-bound}\\
 & \leq\norm{s_{x,h}}_{\infty}\,\norm h_{\theta}\,\norm v_{W_{x}^{-1}}\,.\nonumber 
\end{align}
Using the norm bounds in Lemma~\ref{lem:second-deriv-Lewis},
it follows that $|\tr(S_{x,h}^{2}W_{x,h}'')|\lesssim\norm h_{\theta}^{4}$
for $p=\O(\log m)$. Putting everything together with $\norm{s_{x,h}}_{\infty}\leq\sqrt{2}m^{\frac{1}{p+2}}\norm h_{\theta}\lesssim\norm h_{\theta}$
(Lemma~\ref{lem:usefulFactLewis}-2),
\begin{align*}
|\Dd^{2}\theta[h,h,h,h]| & \lesssim\norm{s_{x,h}}_{\infty}^{2}\norm h_{\theta}^{2}+\norm{s_{x,h}}_{\infty}\norm h_{\theta}^{3}\lesssim\norm h_{\theta}^{4}\,.\qedhere
\end{align*}
\end{proof}

\section{Technical lemmas}
\begin{lem}
\label{lem:matrix-projection} For a matrix $M\in\R^{m\times d}$
and $E\in\Rdd$ such that $E+M^{\T}M\succ0$, it holds that
\[
M(E+M^{\T}M)^{-1}M^{\T}\preceq P(M)=M(M^{\T}M)^{\dagger}M^{\T}\,.
\]
\end{lem}

\begin{proof}
Let us denote the LHS by $P'$ and the RHS by $P$. We show $I-P'\succeq I-P$
instead. First, $(P')^{2}\preceq P'$ and $(I-P')^{2}\preceq I-P'$
follow from
\begin{align*}
P'P' & =M(E+M^{\T}M)^{-1}\underbrace{M^{\T}M}_{\preceq E+M^{\T}M}\,(E+M^{\T}M)^{-1}M^{\T}\preceq M(E+M^{\T}M)^{-1}M^{\T}=P'\,,\\
(I-P')^{2} & =I+P'P'-2P'\preceq I-P'\,.
\end{align*}
It follows from $(I-P')^{2}\preceq I-P'$ that for any $v\in\R^{m}$
\begin{align*}
v^{\T}(I-P')v & \geq\snorm{(I-P')v}^{2}\geq\norm{(I-P)v}_{2}^{2}=v^{\T}(I-P)v\,,
\end{align*}
where the inequality holds due to $P'v,Pv\in\text{range}(M)$ and
$Pv=\arg\min_{w\in\,\text{range}(M)}\norm{v-w}_{2}^{2}$.
\end{proof}
\begin{prop}
\label{prop:stein-comp} Let $v,w,p,q,r,s\in\Rd$ and $h\sim\ncal(0,I_{d})$.
\begin{itemize}
\item $\E[(v\cdot h)(w\cdot h)^{3}]=3\norm w^{2}(v\cdot w)$.
\item $\E[(v\cdot h)^{2}(w\cdot h)^{2}]=\norm v^{2}\norm w^{2}+2(v\cdot w)^{2}$.
\item $\E[(p\cdot h)^{2}(r\cdot h)(s\cdot h)]=\norm p^{2}(r\cdot s)+2(p\cdot s)(p\cdot r)$.
\end{itemize}
\end{prop}

\begin{proof}
Using Stein's lemma (Lemma~\ref{lem:stein}),
\begin{align*}
\E[(v\cdot h)(w\cdot h)^{3}] & \underset{\text{Stein}}{=}\sum_{i}w_{i}\E[h_{i}(v\cdot h)(w\cdot h)^{2}]=\sum_{i}w_{i}\bpar{v_{i}\E[(w\cdot h)^{2}]+2w_{i}\E[(v\cdot h)(w\cdot h)]}\\
 & =(v\cdot w)\norm w^{2}+2\norm w^{2}(v\cdot w)=3\norm w^{2}(v\cdot w)\,,\\
\E[(v\cdot h)^{2}(w\cdot h)^{2}] & =\sum_{i}v_{i}\E[h_{i}(v\cdot h)(w\cdot h)^{2}]\underset{\text{Stein}}{=}\sum_{i}v_{i}\Par{v_{i}\E[(w\cdot h)^{2}]+2w_{i}\E[(v\cdot h)(w\cdot h)]}\\
 & =\norm v^{2}\norm w^{2}+2(v\cdot w)^{2}\,,\\
\E[(p\cdot h)^{2}(r\cdot h)(s\cdot h)] & =\sum_{i}p_{i}\E[h_{i}(p\cdot h)(r\cdot h)(s\cdot h)]\\
 & \underset{\text{Stein}}{=}\sum p_{i}\Par{p_{i}\E[(r\cdot h)(s\cdot h)]+r_{i}\E[(p\cdot h)(s\cdot h)]+s_{i}\E[(p\cdot h)(r\cdot h)]}\\
 & =\norm p^{2}(r\cdot s)+(p\cdot r)(p\cdot s)+(p\cdot s)(p\cdot r)=\norm p^{2}(r\cdot s)+2(p\cdot s)(p\cdot r)\,.\qedhere
\end{align*}
\end{proof}
These estimations result in a useful lemma for establishing SASC of
barriers for linear constraints.
\begin{lem}
\label{lem:variance-1} For $v,w\in\Rd$ and $h\sim\ncal(0,I_{d})$,
$\E[(v\cdot h)^{3}(w\cdot h)^{3}]=9\norm v^{2}\norm w^{2}(v\cdot w)+6(v\cdot w)^{3}$.
\end{lem}

\begin{proof}
Using Stein's lemma,
\begin{align*}
\E[(v\cdot h)^{3}(w\cdot h)^{3}] & =\sum_{i}v_{i}\E[h_{i}(v\cdot h)^{2}(w\cdot h)^{3}]=\sum v_{i}\bpar{2v_{i}\E[(v\cdot h)(w\cdot h)^{3}]+3w_{i}\E[(v\cdot h)^{2}(w\cdot h)^{2}]}\\
 & \underset{\text{(i)}}{=}2\norm v^{2}\cdot3\norm w^{2}(v\cdot w)+3(v\cdot w)\bpar{\norm v^{2}\norm w^{2}+2(v\cdot w)^{2}}=9\norm v^{2}\norm w^{2}+6(v\cdot w)^{3}\,,
\end{align*}
where in (i) we used Proposition~\ref{prop:stein-comp}-1 and 2.
\end{proof}
\begin{lem}
\label{lem:variance-2} For $p,q,r,s\in\Rd$ and $h\sim\ncal(0,I_{d})$,
\begin{align*}
\E[(p\cdot h)^{2}(q\cdot h)(r\cdot h)^{2}(s\cdot h)] & =(q\cdot s)\norm p^{2}\norm r^{2}+4(p\cdot r)(p\cdot q)(r\cdot s)\\
+2\norm p^{2}(r\cdot q)(r\cdot s) & +2\norm r^{2}(p\cdot q)(p\cdot s)+2(p\cdot r)^{2}(q\cdot s)+4(p\cdot s)(p\cdot r)(r\cdot q)\,.
\end{align*}
\end{lem}

\begin{proof}
Using Stein's lemma,
\begin{align*}
 & \E[(p\cdot h)^{2}(q\cdot h)(r\cdot h)^{2}(s\cdot h)]=\sum_{i}q_{i}\E[h_{i}(p\cdot h)^{2}(r\cdot h)^{2}(s\cdot h)]\\
 & =\sum q_{i}\bpar{2p_{i}\E[(p\cdot h)(r\cdot h)^{2}(s\cdot h)]+2r_{i}\E[(p\cdot h)^{2}(r\cdot h)(s\cdot h)]+2s_{i}\E[(p\cdot h)^{2}(r\cdot h)^{2}]}\\
 & \underset{\text{(i)}}{=}2(p\cdot q)\bpar{\norm r^{2}(p\cdot s)+2(p\cdot r)(r\cdot s)}+2(r\cdot q)\bpar{\norm p^{2}(r\cdot s)+2(p\cdot s)(p\cdot r)}\\
 & \qquad+(q\cdot s)\bpar{\norm p^{2}\norm r^{2}+2(p\cdot r)^{2}}\\
 & =(q\cdot s)\norm p^{2}\norm r^{2}+4(p\cdot r)(p\cdot q)(r\cdot s)+2\norm p^{2}(r\cdot q)(r\cdot s)+2\norm r^{2}(p\cdot q)(p\cdot s)\\
 & \qquad+2(p\cdot r)^{2}(q\cdot s)+4(p\cdot s)(p\cdot r)(r\cdot q)\,.
\end{align*}
In (i), we used Proposition~\ref{prop:stein-comp}-3 to the first
two terms and Proposition~\ref{prop:stein-comp}-2 to the third term.
\end{proof}

