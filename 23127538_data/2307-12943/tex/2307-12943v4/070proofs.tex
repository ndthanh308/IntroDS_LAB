\global\long\def\vec{\textup{\textsf{vec}}}%
\global\long\def\svec{\textup{\textsf{svec}}}%


\section{Proofs \label{sec:proofs}}

We collect deferred proofs in this section.

\subsection{Mixing of \texorpdfstring{$\msf{Dikin\ walk}$}{Dikin walk} ($\S$\ref{sec:mixing-Dikin})}

\subsubsection{One-step coupling \label{proof:onestep}}

We start with the one-step coupling of the $\dw$ under the setting
$\alpha\hess\phi\preceq\hess f\preceq\beta\hess\phi$ on $\intk$.
Roughly speaking, if $\snorm{x-y}_{x}\leq r/\sqrt{d}$ with $r\lesssim1\wedge\nicefrac{1}{\sqrt{\beta}}$,
then $\dtv(P_{x},P_{y})\leq0.99$.
\begin{proof}
[Proof of Lemma~\ref{lem:one-step}] For $\pi\propto\exp(-f)\cdot\mathbf{1}_{K}$
and $z\sim\ncal(x,\frac{r^{2}}{d}g(x)^{-1})$, let us denote
\[
p_{x}=\ncal\Bpar{x,\frac{r^{2}}{d}g(x)^{-1}},\qquad R(x,z)=\frac{p_{z}(x)}{p_{x}(z)}\frac{\pi(z)}{\pi(x)},\qquad A(x,z)=\min\bpar{1,R(x,z)\,\mathbf{1}_{K}(z)}\,.
\]
The transition kernel $P(x,\cdot)$ of the $\dw$ started at $x$
can be written as 
\[
P(x,dz)=\underbrace{\bpar{1-\E_{p_{x}}[A(x,\cdot)]}}_{\eqqcolon r_{x}}\,\delta_{x}(\D z)+A(x,z)\,p_{x}(\D z)\,.
\]
Thus, for $x,y\in\intk$,
\begin{align}
\dtv(P_{x},P_{y}) & =\underbrace{\half(r_{x}+r_{y})}_{\msf I}+\underbrace{\half\int|A(x,z)\,p_{x}(z)-A(y,z)\,p_{y}(z)|\,\D z}_{\msf{II}}\,.\tag{\ensuremath{\msf{TV\text{-}decomposition}}}\label{eq:tv-formula}
\end{align}

Let $h\sim\ncal(0,I_{d})$ and denote a bad event $B_{0}=\{z\in\Rd:\snorm{z-x}_{x}\ge cr\}$
with $c$ determined later. Due to $\snorm{z-x}_{x}=\frac{r}{\sqrt{d}}\snorm h$
(in law) and concentration of the standard Gaussian in a thin shell
of radius $\sqrt{d}$ with annulus $\mc O(1)$\footnote{A standard Gaussian $h\sim\ncal(0,I_{d})$ is concentrated around
a thin sell of radius $\sqrt{d}$ with annulus $\mc O(1)$: For $t>0$,
\[
\P_{h}(\norm h_{2}\geq\sqrt{d}+t)\leq\exp(-t^{2}/2)\,.
\]
}, we have $\P_{z}(B_{0})=\P_{h}(\snorm h\geq c\sqrt{d})\leq\exp\bpar{-(c-1)\sqrt{d}/2}$.
Hence, $\P(B_{0})\leq\veps$ for $c\geq1+\sqrt{\frac{2}{d}\,\log\frac{1}{\veps}}$. 

\paragraph{Rejection probability $r_{x}$ and $r_{y}$ (Term $\protect\msf I$).}

Note that
\[
r_{x}=1-\E_{p_{x}}[A(x,z)]=1-\int\min\Bpar{1,\,\underbrace{\mathbf{1}_{K}(z)\frac{\exp f(x)}{\exp f(z)}}_{\eqqcolon\textsf{A}}\underbrace{\frac{p_{z}(x)}{p_{x}(z)}}_{\eqqcolon\textsf{B}}}p_{x}(\D z)\,.
\]

As for $\textsf{A}$, we let $\hess\phi\preceq c_{\phi}g$ for some
$c_{\phi}>0$ and use Taylor's expansion at $x\in K\cap B_{0}^{c}$
to show that for some $x^{*}\in[x,z]$, 
\begin{align*}
f(x)-f(z) & +\nabla f(x)^{\T}(z-x)=-\snorm{z-x}_{\hess f(x^{*})}^{2}\geq-c_{\phi}\beta\,\snorm{z-x}_{g(x^{*})}^{2}\\
 & \underset{\text{(i)}}{\geq}-c_{\phi}\beta\,\snorm{z-x}_{x}^{2}\cdot(1+2\snorm{x-z}_{x})^{2}\geq-c_{\phi}\beta c^{2}r^{2}(1+2cr)^{2}\underset{\text{(ii)}}{\geq}-\veps\,,
\end{align*}
where we used Lemma~\ref{lem:scCloseness} in (i) and took $r\leq r_{1}(\veps)$
in (ii), which is defined so that $\beta c_{\phi}c^{2}r^{2}(1+cr)^{2}\leq\veps$
for any $r\leq r_{1}(\veps)$. It follows from $\dcal_{g}^{1}(x)\subset K$
and symmetry of $\ncal_{g}^{r}(x)$ that there exists a half-ellipsoid
$G\subset\dcal_{g}^{1}(x)$ in which $\inner{\grad f(x),z-x}\leq0$.
Thus, $f(x)-f(z)\geq-\veps$ holds on $z\in G$.

For a bad event $B_{1}:=G^{c}$, it holds that 
\[
\P_{z}(B_{1})\leq\half+\P_{z}\bpar{\dcal_{g}^{1}(x)^{c}}=\half+\P_{z}(\snorm{z-x}_{x}\geq1)=\half+\P_{h}\Bpar{\norm h\geq\frac{\sqrt{d}}{r}}\leq\half+\veps\,,
\]
where the last inequality follows from concentration of $h$ for any
$r\leq r_{2}(\veps):=\bpar{1+\frac{2}{\sqrt{d}}\,\log\frac{1}{\veps}}^{-1}$. 

As for $\textsf{B}$, for $\vphi(x):=\half\log\det g(x)$ we have
\[
\log\text{\textsf{B}}=-\frac{d}{2r^{2}}\bpar{\snorm{z-x}_{z}^{2}-\snorm{z-x}_{x}^{2}}+\bpar{\vphi(z)-\vphi(x)}\,.
\]
Invoking ASC of $\phi$, we can take $r_{3}(\veps)$ so that $\P_{z}\bpar{\snorm{z-x}_{z}^{2}-\snorm{z-x}_{x}^{2}\leq2\veps r^{2}/d}\geq1-\veps$
for any $r\leq r_{3}(\veps)$ and control the first term. Let the
complement of this event be our second bad event $B_{2}$.

For $\vphi(z)-\vphi(x)$, Taylor's expansion of $\vphi$ at $x$ leads
to 
\[
\vphi(z)-\vphi(x)=\underbrace{\inner{\grad\vphi(x),z-x}}_{\eqqcolon\textsf{A'}}+\underbrace{\half\inner{\hess\vphi(x^{*})(z-x),z-x)}}_{\eqqcolon\textsf{B'}}\text{ for some }x^{*}\in[x,z]\,.
\]
As for $\textsf{A}'$, we have $\inner{\grad\vphi(x),z-x}=\frac{r}{\sqrt{d}}\inner{g(x)^{-1/2}\grad\vphi(x),h}$,
and a standard tail bound for $h$ leads to 
\[
\P_{z}\Bpar{\inner{\grad\vphi(x),z-x}\leq-\frac{r}{\sqrt{d}}\,\snorm{g(x)^{-1/2}\nabla\vphi(x)}_{2}\cdot2\log\frac{1}{\veps}}\leq\veps\,.
\]
We call this event $B_{3}$ and bound $\snorm{g(x)^{-1/2}\nabla\vphi(x)}_{2}$
via SSC of $g$ as follows: omitting $x$ for simplicity,
\begin{align*}
\snorm{g^{-\half}\nabla\vphi}_{2} & =\sup_{v:\norm v_{2}=1}\inner{\grad\vphi,g^{-\half}v}\underset{\text{(i)}}{=}\sup_{v}\tr(g^{-1}\Dd g[g^{-\half}v])=\sup_{v}\tr(g^{-\half}\Dd g[g^{-\half}v]\,g^{-\half})\\
 & \underset{\text{(ii)}}{\leq}\sup_{v}\sqrt{d}\,\snorm{g^{-\half}\Dd g[g^{-\half}v]\,g^{-\half}}_{F}\underset{\text{(iii)}}{\leq}\sup_{v}2\sqrt{d}\snorm{g^{-\half}v}_{x}=2\sqrt{d}\,,
\end{align*}
where (i) follows from \eqref{eq:gradLogDet}, (ii) is due to $\tr(A)\leq\sqrt{d}\snorm A_{F}$
for $A\in\Rdd$, and (iii) is due to SSC. Conditioned on $B_{3}^{c}$,
taking $r\leq r_{4}(\veps):=\veps(4\log\frac{1}{\veps})^{-1}$, we
have
\[
\msf{A'}=\inner{\grad\vphi(x),z-x}\geq-4r\,\log\frac{1}{\veps}\geq-\veps\,.
\]

As for $\textsf{B}'$, denoting $u=z-x$ for $z\in B_{0}^{c}$ 
\begin{align}
\Dd^{2}\vphi(x^{*})[u,u] & \underset{\eqref{eq:hessLogDet}}{=}\tr\bpar{g(x^{*})^{-1}\Dd^{2}g(x^{*})[u,u]}-\snorm{g(x^{*})^{-\half}\Dd g(x^{*})[u]\,g(x^{*})^{-\half}}_{F}^{2}\nonumber \\
 & \underset{\text{(i)}}{\geq}-\snorm u_{x^{*}}^{2}-\snorm{g(x^{*})^{-\half}\Dd g(x^{*})[u]\,g(x^{*})^{-\half}}_{F}^{2}\ge-\snorm u_{x^{*}}^{2}-4\snorm u_{x^{*}}^{2}\nonumber \\
 & \underset{\text{(ii)}}{\geq}-5(1-\snorm{x-x^{*}}_{x})^{-2}\snorm u_{x}^{2}\label{eq:so-taylor-logdet}\\
 & \geq-5(1+2cr)^{2}c^{2}r^{2}\,,\nonumber 
\end{align}
where (i) follows from LTSC and (ii) follows from Lemma~\ref{lem:scCloseness}.
Hence, $\msf{B'}\geq-\veps/2$ by taking $r\leq r_{5}(\veps)$ so
that $5(1+2cr_{5})^{2}c^{2}r_{5}^{2}=\veps$. 

In summary, conditioned on $G:=\bigcap_{i=0}^{3}B_{i}^{c}$ with $\P_{z}(G)\geq\half-4\veps$
due to the union bound, we have
\begin{align}
\textsf{A}: & \,\frac{\exp f(x)}{\exp f(z)}\geq\exp(-\veps)\,,\label{eq:fx-ratio}\\
\textsf{B}: & \,\frac{p_{z}(x)}{p_{x}(z)}\geq\exp(-3\veps)\,,\label{eq:prop-ratio}\\
 & \,\vphi(z)-\vphi(x)\geq-2\veps\,.\label{eq:vphi-z-x}
\end{align}
Combining these together,
\begin{align*}
r_{x} & =1-\int\min\Bpar{1,\mathbf{1}_{K}(z)\frac{\exp f(x)}{\exp f(z)}\,\frac{p_{z}(x)}{p_{x}(z)}}p_{x}(\D z)\leq1-\int_{G}(1\wedge e^{-\veps}e^{-3\veps})\,\P_{z}(G)\leq\half+5\veps\,.
\end{align*}
Bounding $r_{y}$ in the same way, we conclude that $\textsf{I}\leq\half+5\veps$
in \eqref{eq:tv-formula}.

\paragraph{Overlapping part (Term $\protect\msf{II}$).}

WLOG, assume $f(y)\geq f(x)$. We denote good events by $G_{x}=\cap_{i=0,2,3}B_{x,i}^{c}$
and $G_{y}=\cap_{i=0,2,3}B_{y,i}^{c}$ such that $\P_{p_{x}}(G_{x}^{c})\leq3\veps$
and $\P_{p_{y}}(G_{y}^{c})\leq3\veps$, where 
\begin{align*}
B_{x,0} & =\{\snorm{z-x}_{x}\geq cr\}\ \text{with }c\geq1+\frac{2}{\sqrt{d}}\,\log\frac{1}{\veps},\ \text{and}\ B_{x,2}=\Bbrace{\snorm{z-x}_{z}^{2}-\snorm{z-x}_{x}^{2}>\frac{2\veps r^{2}}{d}}\\
B_{x,3} & =\Bbrace{\grad\vphi(x)^{\T}(z-x)\leq-\frac{2r\log\frac{1}{\veps}}{\sqrt{d}}\,\snorm{g(x)^{-\half}\nabla\vphi(x)}_{2}}\,.
\end{align*}
Let $G:=G_{x}\cup G_{y}$, and define a partition of $G$ by
\[
G_{x\backslash y}:=G_{x}\backslash G_{y},\qquad G_{x,y}:=G_{x}\cap G_{y},\qquad G_{y\backslash x}:=G_{y}\backslash G_{x}\,.
\]
Now we decompose the term $\textsf{II}$ as follows: for $Q:=|A(x,z)p_{x}(z)-A(y,z)p_{y}(z)|$,
\begin{align*}
\textsf{II} & =\half\int_{K\backslash G}Q\,\D z+\underbrace{\half\int_{G_{x\backslash y}}Q\,\D z}_{\eqqcolon\acal}+\underbrace{\half\int_{G_{y\backslash x}}Q\,\D z}_{\eqqcolon\bcal}+\underbrace{\half\int_{G_{x,y}}Q\,\D z}_{\eqqcolon\ccal}\\
 & \leq\half\bpar{\P_{p_{x}}(K\backslash G)+\P_{p_{y}}(K\backslash G)}+\acal+\bcal+\ccal\leq\half\bpar{\P_{p_{x}}(G_{x}^{c})+\P_{p_{y}}(G_{y}^{c})}+\acal+\bcal+\ccal\\
 & \leq3\veps+\acal+\bcal+\ccal\,.
\end{align*}
The term $\acal$ can be further decomposed by
\begin{align*}
2\mc A & \leq\int_{G_{x\backslash y}}A(x,z)\,|p_{x}(z)-p_{y}(z)|\,\D z+\int_{G_{x\backslash y}}|A(x,z)-A(y,z)|\,p_{y}(\D z)\\
 & \leq\int_{G_{x\backslash y}}|p_{x}(z)-p_{y}(z)|\,\D z+\P_{p_{y}}(G_{x\backslash y})\leq\int_{G_{x\backslash y}}|p_{x}(z)-p_{y}(z)|\,\D z+\underbrace{\P_{p_{y}}(G_{y}^{c})}_{\leq3\veps}\,,
\end{align*}
and in a similar way $\mc B\leq\half\int_{G_{y\backslash x}}|p_{x}(z)-p_{y}(z)|\,\D z+3\veps/2$.
Combining these together,
\begin{align*}
\mc A+\mc B & \leq3\veps+\half\int_{G_{x\backslash y}\cup G_{y\backslash x}}|p_{x}(z)-p_{y}(z)|\,\D z\leq3\veps+\dtv(p_{x},p_{y})\leq4\veps\,,
\end{align*}
where we used $\dtv(p_{x},p_{y})\leq\veps$; to see this, recall Pinsker's
inequality and a formula for the $\KL$ divergences between two Gaussians:
\[
2[\dtv(p_{x},p_{y})]^{2}\leq\KL(p_{y}\mmid p_{x})=\half\,\Bpar{\tr\bpar{g(y)^{-1}g(x)}-d+\log\det\bpar{g(y)g(x)^{-1}}+\frac{d}{r^{2}}\,\snorm{y-x}_{x}^{2}}\,.
\]
Let $\{\lda_{i}\}_{i\in[d]}$ be the eigenvalues of $g(x)^{-\half}g(y)g(x)^{-\half}$
and $\snorm{x-y}_{x}\leq\frac{sr}{\sqrt{d}}$ with $s>0$ to be determined.
Then, $\half\leq\lda_{i}\leq1+8\norm{x-y}_{x}$ by Lemma~\ref{lem:scCloseness}.
Using this and $\log x\leq x-1$ for $x>0$,
\begin{align*}
2\,\KL(p_{y}\mmid p_{x}) & =\sum_{i=1}^{d}\Bpar{\lda_{i}-1+\log\frac{1}{\lda_{i}}}+\frac{d}{r^{2}}\,\snorm{y-x}_{x}^{2}\le\sum_{i=1}^{d}\frac{(\lda_{i}-1)^{2}}{\lda_{i}}+s^{2}\leq s^{2}\,(128r^{2}+1)\,,
\end{align*}
Taking $s\leq s_{1}(\veps):=\veps$ and $r\leq r_{6}(\veps)$ so that
$\sqrt{128r_{6}^{2}+1}\leq2$, we obtain 
\begin{align}
\dtv(p_{x},p_{y})\leq\sqrt{\half\,\KL(p_{y}\mmid p_{x})} & \leq\frac{s}{2}\sqrt{128r^{2}+1}\leq\veps\,,\label{eq:TV-by-KL}
\end{align}

We now bound $\mc C$. Recall $B_{x,1}=\{\inner{\grad f(x),z-x}\ge0\}$
and $\P_{p_{x}}(B_{x,1})\leq\half+\O(\veps)$. Then,
\begin{align*}
2\mc C & =\int_{(G_{x}\cap G_{y})\backslash B_{x,1}^{c}}Q\,\D z+\int_{G_{x}\cap G_{y}\cap B_{x,1}^{c}}Q\,\D z\leq\int_{B_{x,1}}\underbrace{Q}_{\text{The traingle inequality}}\,\D z+\int_{G_{x}\cap G_{y}\cap B_{x,1}^{c}}Q\,\D z\\
 & \leq\int_{B_{x,1}}|A(x,z)-A(y,z)|\,p_{x}(\D z)+\int_{B_{x,1}}A(y,z)\:|p_{x}(z)-p_{y}(z)|\,\D z+\int_{G_{x}\cap G_{y}\cap B_{x,1}^{c}}Q\,\D z\\
 & \le\underbrace{\P_{p_{z}}(B_{x,1})}_{\leq\half+\veps}+2\underbrace{\dtv(p_{x},p_{y})}_{\leq\veps\ (\ref{eq:TV-by-KL})}+\int_{G_{x}\cap G_{y}\cap B_{x,1}^{c}}|A(x,z)\,p_{x}(z)-A(y,z)\,p_{y}(z)|\,\D z\\
 & \leq\half+2\veps+\int_{G_{x}\cap G_{y}\cap B_{x,1}^{c}}|A(x,z)\,p_{x}(z)-A(y,z)\,p_{y}(z)|\,\D z\,.
\end{align*}
One can check that
\[
|A(x,z)\,p_{x}(z)-A(y,z)\,p_{y}(z)|\,\D z=\Big|\min\Bpar{1,\underbrace{\frac{\exp f(x)}{\exp f(z)}\,\frac{p_{z}(x)}{p_{x}(z)}}_{\eqqcolon\msf U}}-\min\Bpar{\underbrace{\frac{p_{y}(z)}{p_{x}(z)}}_{\eqqcolon\msf V},\underbrace{\frac{\exp f(y)}{\exp f(z)}\,\frac{p_{z}(y)}{p_{x}(z)}}_{\eqqcolon\msf W}}\Big|\,p_{x}(\D z)\,.
\]
Here we note that $\msf U\geq e^{-4\veps}$ due to $\frac{\exp f(x)}{\exp f(z)}\geq e^{-\veps}$
and $\frac{p_{z}(x)}{p_{x}(z)}\geq e^{-3\veps}$ from \eqref{eq:fx-ratio}
and \eqref{eq:prop-ratio}. 

We now show that under additional conditioning, $|\log\textsf{V}|\lesssim\veps$
and $\log\textsf{W}\gtrsim-\veps$ on $z\in G_{x}\cap G_{y}\cap B_{x,1}^{c}$.
For $\vphi(\cdot)=\half\log\det g(\cdot)$ and $\msf L:=-\frac{d}{2r^{2}}(\snorm{z-y}_{y}^{2}-\snorm{z-x}_{x}^{2})$,
\begin{align}
\log\msf V & =-\frac{d}{2r^{2}}(\snorm{z-y}_{y}^{2}-\snorm{z-x}_{x}^{2})+\vphi(y)-\vphi(x)\nonumber \\
 & =\textsf{L}+\inner{\grad\vphi(x),y-x}+\underbrace{\half\inner{\hess\vphi(x^{*})(y-x),y-x}}_{\text{Use }\eqref{eq:so-taylor-logdet}}\quad\text{for some }x^{*}\in[x,y]\label{eq:bound-vphi}\\
 & \geq\textsf{L}-\snorm{g(x)^{-1/2}\nabla\vphi(x)}_{2}\snorm{y-x}_{x}-5\underbrace{(1+2\snorm{x-y}_{x})^{2}}_{\leq2}\snorm{y-x}_{x}^{2}\nonumber \\
 & \geq\textsf{L}-2\sqrt{d}\cdot s\frac{r}{\sqrt{d}}-10s^{2}\frac{r^{2}}{d}\geq\textsf{L}-\veps\,,\label{eq:logV-lower}
\end{align}
where the inequality follows from $s\leq\frac{\veps}{10}$ and $r\leq r_{7}(\veps):=1$. 

As for $\textsf{W}$, due to $f(y)\geq f(x)$ and $\exp(f(x)-f(z))\geq\exp(-\veps)$,
\begin{align}
\log\msf W & \geq\log\Bpar{\frac{\exp f(x)}{\exp f(z)}\frac{p_{z}(y)}{p_{x}(z)}}\geq-\veps-\frac{d}{2r^{2}}(\snorm{z-y}_{z}^{2}-\snorm{z-x}_{x}^{2})+\vphi(z)-\vphi(x)\nonumber \\
 & \underset{\text{(i)}}{\geq}-\veps-\frac{d}{2r^{2}}\Bpar{\snorm{z-y}_{y}^{2}+2\veps\frac{r^{2}}{d}-\snorm{z-x}_{x}^{2}}-2\veps=\textsf{L}-4\veps\,,\label{eq:logW-lower}
\end{align}
where (i) follows from $\snorm{z-y}_{z}^{2}-\snorm{z-y}_{y}^{2}\leq2\veps r^{2}/d$
on $z\in B_{y,2}^{c}$, and $\vphi(z)-\vphi(x)\geq-2\veps$ on $z\in B_{x,3}^{c}$
from \eqref{eq:vphi-z-x}.

Lastly, we show that $|\textsf{L}|$ is bounded by $\mc O(\veps)$
with high probability (w.r.t. $p_{x}$). Due to affine invariance
of the algorithm, we may assume that $x=0$ and $g(x)=I_{d}$ (so
$p_{x}=\ncal(0,I_{d})$). Therefore, 
\begin{align*}
\snorm{z-y}_{y}^{2}-\snorm{z-x}_{x}^{2} & =\snorm{z-y}_{y}^{2}-\snorm z^{2}=\snorm z_{g(y)-I_{d}}^{2}-2\inner{z,y}_{y}+\snorm y_{y}^{2}\,.
\end{align*}
The last term is bounded by $2\norm y^{2}$ due to SC of $g$. Using
a tail bound for Gaussians, we have $\P_{p_{x}}\bpar{|\inner{z,y}_{y}|\geq\frac{r}{\sqrt{d}}\,\snorm{g(y)y}_{2}\cdot2\log\frac{1}{\veps}}\leq\veps$
and call this event $C_{1}$. In addition, SC of $g$ leads to $g(y)\preceq2I_{d}$,
so $\snorm{g(y)y}\leq2\snorm y$.

To bound $\snorm z_{g(y)-I_{d}}^{2}$, we note that $\snorm y=\snorm{y-x}_{x}\leq1/\sqrt{2}$
and so
\begin{align*}
\snorm{g(y)-I_{d}}_{F} & \leq(1+2\snorm y)^{2}\snorm y\leq2s\frac{r}{\sqrt{d}}\,,\quad\text{(Lemma \ref{lem:strongSC-closeness})}\\
\E[\snorm z_{g(y)-I_{d}}^{2}] & =\frac{r^{2}}{d}\tr(g(y)-I_{d})\leq\frac{r^{2}}{d}\sqrt{d}\,\snorm{g(y)-I_{d}}_{F}\leq\frac{r^{2}}{d}\cdot2rs\,.
\end{align*}
By the Hanson-Wright inequality\footnote{\begin{lem*}
[Hanson-Wright; Adapted to Gaussian] Let $h\sim\ncal(0,\sigma^{2}I_{d})$
and $M\in\Rdd$. Then there exists universal constants $c,K>0$ such
that for $t\geq0$
\[
\P\bpar{|\norm h_{A}^{2}-\E[\norm h_{A}^{2}]|>t}\leq2\exp\Bpar{-c\min\Bpar{\frac{t^{2}}{K^{4}\sigma^{4}\norm M_{F}^{2}},\frac{t}{K^{2}\sigma^{2}\norm M_{2}}}}\,.
\]
\end{lem*}
}, for universal constants $K_{1},K_{2}>0$ and $t\geq0$ it holds
that
\[
\P_{z\sim\ncal(0,I_{d})}\bpar{|\norm z_{g(y)-I_{d}}^{2}-\E[\norm z_{g(y)-I_{d}}^{2}]|\geq t}\leq2\exp\Bpar{-K_{1}\Bpar{\frac{t^{2}}{K_{2}^{4}\frac{r^{4}}{d^{2}}\snorm{g(y)-I_{d}}_{F}^{2}}\wedge\frac{t}{K_{2}^{2}\frac{r^{2}}{d}\snorm{g(y)}_{2}}}}\,.
\]
By taking $r\leq r_{8}(\veps):=\frac{\sqrt{K_{1}}}{2K_{2}^{2}}$ and
$s\leq s_{2}(\veps):=\veps(1+\sqrt{\log\frac{2}{\veps}})^{-1}$, it
follows that $\norm z_{g(y)-I_{d}}^{2}\leq\frac{2\veps r^{2}}{d}$
with probability at least $1-\veps$. Denote the complement of this
event by $C_{2}$.

Conditioned on $z\in C_{1}^{c}\cap C_{2}^{c}$, we conclude that
\begin{align*}
|\snorm{z-y}_{y}^{2}-\snorm{z-x}_{x}^{2}| & \leq\snorm z_{g(y)-I_{d}}^{2}+2|\inner{z,y}_{y}|+2\snorm y^{2}\leq\frac{2r^{2}\veps}{d}+\frac{8r\norm y}{\sqrt{d}}\,\log\frac{1}{\veps}+2\norm y^{2}\leq\frac{2r^{2}}{d}\cdot3\veps\,,
\end{align*}
where the last inequality follows from $\norm y\leq\frac{sr}{\sqrt{d}}$
when $s\leq s_{3}(\veps):=\veps\,(4\log\frac{1}{\veps})^{-1}$. Hence,
$|\textsf{L}|\leq3\veps$ on $C_{1}^{c}\cap C_{2}^{c}$. Putting this
into \eqref{eq:logV-lower} and \eqref{eq:logW-lower},
\[
\log\msf V\geq\exp(-4\veps)\qquad\text{and}\qquad\log\msf W\geq\exp(-7\veps)\,.
\]

We can also show $\log\textsf{V}\leq5\veps$. Conditioned on $z\in C_{1}^{c}\cap C_{2}^{c}$,
\[
-\log\msf V=-\textsf{L}+\vphi(x)-\vphi(y)\geq-3\veps+\vphi(x)-\vphi(y)\geq-5\veps\,,
\]
since $\vphi(x)-\vphi(y)$ can be lowered bounded by $-2\veps$ as
in \eqref{eq:bound-vphi}. Hence, $\log\textsf{V}\leq5\veps$.

For $F:=G_{x}\cap G_{y}\cap B_{x,1}^{c}$ and $C:=(C_{1}\cup C_{2})^{c}$,
since $e^{-4\veps}\leq\msf V\leq e^{5\veps}$, $e^{-7\veps}\leq\msf W$,
and $\msf U\geq e^{-4\veps}$,
\begin{align*}
 & \int_{F}|A(x,z)\,p_{x}(z)-A(y,z)\,p_{y}(z)|\,\D z\leq\int_{C^{c}}(\cdot)\,\D z+\int_{F\cap C}(\cdot)\,\D z\\
\leq & \underbrace{\P_{p_{x}}(C^{c})}_{\leq2\veps}+2\underbrace{\dtv(p_{x},p_{y})}_{\leq\veps}+\int_{F\cap C}(\cdot)\,\D z\leq4\veps+\int_{F\cap C}|1\wedge\msf U-\msf V\wedge\msf W|\,p_{x}(\D z)\leq4\veps+(e^{5\veps}-e^{-4\veps})\\
\leq & 18\veps\,.
\end{align*}
Using this, we can bound $\ccal$ by
\begin{align*}
\ccal & \leq\frac{1}{4}+\veps+\half\int_{F}|A(x,z)\,p_{x}(z)-A(y,z)\,p_{y}(z)|\,\D z\leq\frac{1}{4}+10\veps\,.
\end{align*}
Therefore, $\textsf{II}\leq3\veps+\acal+\bcal+\ccal\leq3\veps+4\veps+\frac{1}{4}+10\veps\leq\frac{1}{4}+17\veps.$
Along with $\textsf{I}\leq\half+5\veps$, we can conclude that if
$r\leq\min_{i}r_{i}(\veps)$ and $s\leq\min_{i}s_{i}(\veps)$, then
$\dtv(P_{x},P_{y})\leq\frac{3}{4}+23\veps$.
\end{proof}

\subsubsection{Isoperimetric inequality \label{proof:isoperimetry}}

We now prove an isoperimetric inequality arising from the a SC barrier.
Recall the \emph{cross-ratio} \emph{distance} $d_{K}$ defined on
a convex body $K$: for $x,y\in\intk$, suppose that the chord passing
through $x,y$ has endpoints $p$ and $q$ in the boundary $\de K$
(so the order of points is $p,x,y,q$), then the cross-ratio distance
between $x$ and $y$ is defined by
\[
d_{K}(x,y)\defeq\frac{\snorm{x-y}_{2}\snorm{p-q}_{2}}{\snorm{p-x}_{2}\snorm{y-q}_{2}}\,.
\]
The first type of isoperimetric inequalities says $\psi_{\pi}\gtrsim1/\sqrt{\onu}$.
\begin{proof}
[Proof of Lemma~\ref{lem:symmetry-iso}] For a ball $B_{r}(0)$
of radius $r>0$ centered at the origin, we define a convex body $K_{r}:=K\cap B_{r}(0)$
and use $\pi_{r}$ to denote the truncated distribution of $\pi$
over $K_{r}$. Let $\{S_{1},S_{2},S_{3}\}$ be a partition of $K$
and define $S_{i}^{r}:=S_{i}\cap K_{r}$ for $i\in[3]$. By \citet[Theorem 2.5]{lovasz2007geometry},
we have 
\[
\pi_{r}(S_{3}^{r})\geq d_{K_{r}}(S_{1}^{r},S_{2}^{r})\,\pi_{r}(S_{1}^{r})\,\pi_{r}(S_{2}^{r})\,,
\]
where $d_{K_{r}}(S_{1}^{r},S_{2}^{r})=\inf_{x\in S_{1}^{r},y\in S_{2}^{r}}d_{K_{r}}(x,y)$.
Due to $d_{K_{r}}(x,y)\geq\norm{x-y}_{x}/\sqrt{\onu}$ for any $x,y\in K_{r}$
(see \citet[Lemma 2.3]{laddha2020strong}), 
\[
\pi_{r}(S_{3}^{r})\geq\inf_{x\in S_{1}^{r},\,y\in S_{2}^{r}}\frac{\snorm{x-y}_{x}}{\sqrt{\onu}}\,\pi_{r}(S_{1}^{r})\,\pi_{r}(S_{2}^{r})\geq\frac{1}{\sqrt{\onu}}\inf_{x\in S_{1},\,y\in S_{2}}\snorm{x-y}_{x}\,\pi_{r}(S_{1}^{r})\,\pi_{r}(S_{2}^{r})\,.
\]
As $r\to\infty$, the bounded convergence theorem implies $\pi_{r}(S_{i}^{r})\to\pi(S_{i})$
for $i\in[3]$, completing the proof.
\end{proof}
%
We provide the deferred proof for another isoperimetric inequality,
$\psi_{\pi}\gtrsim\sqrt{\alpha}$, originating from $\alpha$-relatively
strong-convexity of the potential with respect to $\hess\phi$.
\begin{proof}
[Proof of Lemma~\ref{lem:sc-iso}] The proof essentially follows
\citet{gopi2023algorithmic}. Their first proof ingredient is a modified
localization lemma \citet[Lemma 8]{gopi2023algorithmic}; let $f_{1},f_{2},f_{3},f_{4}$
be non-negative functions on $\Rd$ such that $f_{1}$ and $f_{2}$
are upper semicontinuous, and $f_{3}$ and $f_{4}$ are lower semicontinuous,
and $\phi:\Rd\to\R$ be convex. Then the following are equivalent:
\begin{itemize}
\item For any density $\pi:\Rd\to\R$ which is $1$-relatively strongly
logconcave in $\phi$,
\[
\int f_{1}\,\D\pi\cdot\int f_{2}\,\D\pi\leq\int f_{3}\,\D\pi\cdot\int f_{4}\,\D\pi\,.
\]
\item Let $\int_{E}h:=\int_{0}^{1}h((1-t)\,a+tb)e^{-\gamma t}\,\D t$. Then
$\int_{E}f_{1}e^{-\phi}\cdot\int_{E}f_{2}e^{-\phi}\leq\int_{E}f_{3}e^{-\phi}\cdot\int_{E}f_{4}e^{-\phi}$
for any $a,b\in\Rd$ and $\gamma\in\R$.
\end{itemize}
First of all, this can be generalized to an extended convex function
$f$ and $\phi$, whose values outside of $\intk$ are set to $\infty$.
Since the density $\pi$ and a needle $\exp\Par{\gamma t-\phi((1-t)a+tb)}$
for $\gamma\in\R$ and $a,b\in\Rd$ (induced by the extended $f$
and $\phi$) vanish outside of $\intk$, integrands above become zero
on $\intk^{c}$, and thus the integrals above remain the same.

As in \citet[Lemma 9]{gopi2023algorithmic}, the proof boils down
to the case of $\alpha=1$, and it suffices to show that there exists
a constant $C>0$ such that
\[
C\cdot d_{\phi}(S_{1},S_{2})\int_{S_{1}}e^{-f}\cdot\int_{S_{2}}e^{-f}\leq\int e^{-f}\int_{S_{3}}e^{-f}\,.
\]
We can replace $S_{i}\gets$ its closure $\bar{S_{i}}$ for $i\in[2]$,
which only increases the LHS. Also, we can replace $S_{3}\gets$ an
open set $\intk\backslash\bar{S_{1}}\backslash\bar{S_{2}}$, which
does not change the RHS since the boundary of a convex set is a null
set \citet[Theorem 1]{lang1986note}. By taking $f_{i}=\mathbf{1}_{S_{i}}$
for $i\in[3]$ and $f_{4}=(C\,d_{\phi}(S_{1},S_{2}))^{-1}$, we only
need to show that for some $0\leq c<d\leq1$,
\begin{align*}
 & C\cdot d_{\phi}(S_{1},S_{2})\int_{c}^{d}e^{\gamma t-\phi((1-t)\,a+tb)}\mathbf{1}_{S_{1}}((1-t)\,a+tb)\,\D t\cdot\int_{c}^{d}e^{\gamma t-\phi((1-t)\,a+tb)}\mathbf{1}_{S_{2}}((1-t)\,a+tb)\,\D t\\
\leq & \int_{c}^{d}e^{\gamma t-\phi((1-t)\,a+tb)}\,\D t\cdot\int_{c}^{d}e^{\gamma t-\phi((1-t)\,a+tb)}\mathbf{1}_{S_{3}}((1-t)\,a+tb)\,\D t\,,
\end{align*}
where $\phi((1-t)\,a+b)<\infty$ for $t\in(c,d)$. The rest of the
proof is similar to \citet[Lemma 9]{gopi2023algorithmic}.
\end{proof}

\subsection{Sampling IPM ($\S$\ref{sec:IPM-framework})}

\subsubsection{Well-definedness of sampling IPM \label{proof:IPM-welldefined}}
\begin{prop}
\label{prop:density-bounded} Let $p:\Rd\to\R$ be a log-concave density
with finite second moment. Then $p$ is bounded on $\Rd$.
\end{prop}

\begin{proof}
Let $X\sim p$ and denote the mean and covariance of the distribution
$p$ by $\mu:=\E[X]$ and $\Sigma:=\E[(X-\mu)(X-\mu)^{\T}]$. Then
the pushforward $T_{\#}p$ of $p$ via the map $T:x\mapsto y:=\Sigma^{-1/2}(x-\mu)$
is an isotropic log-concave, and satisfy $(T_{\#}p)(y)=\frac{p(x)}{|\det T|}$.
Since $T_{\#}p$ is bounded on $\Rd$ \citet[Theorem 5.14 (e)]{lovasz2007geometry},
$p$ is bounded as well.
\end{proof}
Next, we show that every measure appearing within the sampling IPM
is integrable.
\begin{proof}
[Proof of Proposition~\ref{prop:annealing-welldefined}] Recall
that we may assume $\phi\geq0$. Hence, all $\mu_{i}$'s in Phase
3 and 4 are well-defined
\[
\int_{K}\exp\Bpar{-\bpar{f(x)+\frac{\phi(x)}{\sigma_{i}^{2}}}}\,\D x\leq\int_{K}\exp(-f(x))\,\D x<\infty\,.
\]
In particular, $\exp\bpar{-(f+\frac{\phi}{\nu/d})}$ is integrable
with finite second moment. By Proposition~\ref{prop:density-bounded},
$f(x)+\frac{\phi(x)}{\nu/d}$ achieves a global minimum $m$ in $K$.
As $\sigma_{i}^{2}\leq\sigma_{i_{0}}^{2}=\nu/d$ in Phase 2, we have
\begin{align*}
 & \int_{K}\exp\Bpar{-\frac{\sigma_{i_{0}}^{2}f+\phi}{\sigma_{i_{0}}^{2}}}=\int_{K}\exp\Bpar{-\frac{\sigma_{i_{0}}^{2}f+\phi-\min(\sigma_{i_{0}}^{2}f+\phi)}{\sigma_{i_{0}}^{2}}-\frac{\min(\sigma_{i_{0}}^{2}f+\phi)}{\sigma_{i_{0}}^{2}}}\\
 & \geq\int_{K}\exp\Bpar{-\frac{\bar{f}+\phi-\sigma_{i_{0}}^{2}m}{\sigma_{i}^{2}}-m}=\exp\Bpar{m\bpar{\frac{\sigma_{i_{0}}^{2}}{\sigma_{i}^{2}}-1}}\int_{K}\exp\Bpar{-\frac{\bar{f}+\phi}{\sigma_{i}^{2}}}\,,
\end{align*}
where the inequality holds due to $\min(\sigma_{i_{0}}^{2}f+\phi)=\sigma_{i_{0}}^{2}m$
and $\bar{f}=\sigma_{i_{0}}^{2}f$. Therefore, $\mu_{i}$'s in Phase
2 are also well-defined.
\end{proof}

\subsubsection{Closeness of distributions in sampling IPM \label{proof:IPM-closeness}}

We begin with closeness between $\ncal\bpar{x^{*},\frac{\sigma_{0}^{2}}{1+\nu\beta d^{-1}}g(x^{*})^{-1}}\cdot\mathbf{1}_{\dcal_{g}^{3\sigma_{0}\sqrt{d}}(x^{*})}$
and $\exp\bpar{-\frac{\bar{f}+\phi}{\sigma_{0}^{2}}}$ in Phase 1.
\begin{proof}
[Proof of Lemma~\ref{lem:phase1}] Let $\gamma=9$, $r=(\gamma\sigma_{0}^{2}d)^{1/2}<0.01$,
$\psi:=\bar{f}+\phi$, and $S=\{x\in K:\psi(x)\leq\psi(x^{*})+r^{2}/4\}$.
For $\widetilde{\mu}_{0}=\exp(-\psi/\sigma_{0}^{2})\cdot\mathbf{1}_{K}\propto\mu_{0}$
and $x\in S$, we have $\mu_{0}(x)\geq e^{-\gamma d}\mu_{0}(x^{*}).$
Due to $\mu_{0}(S^{c})\leq\exp(-\gamma d/3)$ (Lemma~\ref{lem:mostMass-logconcave}),
it follows that $1=\mu_{0}(S)+\mu_{0}(S^{c})\leq\mu_{0}(S)+\exp(-\gamma d/3)$
and 
\begin{equation}
1\leq\bpar{1+2\exp(-\gamma d/3)}\,\mu_{0}(S)=\bpar{1+2\exp(-\gamma d/3)}\,\widetilde{\mu}_{0}(S)/\widetilde{\mu}_{0}(\Rd)\,.\label{eq:intp-intSp}
\end{equation}

We show $S\subset D=\dcal_{g}^{3\sigma_{0}\sqrt{d}}(x^{*})$. For
$x\in S$, use Taylor's expansion of $\psi$ at $x^{*}$: for some
$\bar{x}\in[x^{*},x]$
\begin{align}
\psi(x)-\psi(x^{*}) & =\half(x-x^{*})^{\T}\hess\psi(\bar{x})(x-x^{*})\geq\half(x-x^{*})^{\T}\hess\phi(\bar{x})(x-x^{*})\,.\label{eq:psi-taylor}
\end{align}
As $\psi(x)-\psi(x^{*})\leq r^{2}/4$ on $x\in S$, we have $\snorm{\bar{x}-x^{*}}_{\bar{x}}^{2}\leq\snorm{x-x^{*}}_{\bar{x}}^{2}\leq2(\psi(x)-\psi(x^{*}))\leq r^{2}/2$.
Thus, by self-concordance of $\phi$ 
\begin{equation}
\exp(-3r)\,\snorm{x-x^{*}}_{x^{*}}^{2}\leq\snorm{x-x^{*}}_{\bar{x}}^{2}\leq\exp(3r)\,\snorm{x-x^{*}}_{x^{*}}^{2}\,,\label{eq:closenss-initial}
\end{equation}
and it follows that $\snorm{x-x^{*}}_{x^{*}}^{2}\leq r^{2}$, showing
$S\subset D$.

Combining \eqref{eq:psi-taylor}, \eqref{eq:closenss-initial}, and
$(1+\nu\alpha d^{-1})\,\hess\phi\preceq\hess\psi\preceq(1+\nu\beta d^{-1})\,\hess\phi$,
we have 
\begin{equation}
\frac{\exp(-3r)}{2}\Bpar{1+\frac{\nu\alpha}{d}}\,\snorm{x-x^{*}}_{x^{*}}^{2}\underset{(*)}{\leq}\psi(x)-\psi(x^{*})\underset{(\#)}{\leq}\frac{\exp(3r)}{2}\Bpar{1+\frac{\nu\beta}{d}}\,\snorm{x-x^{*}}_{x^{*}}^{2}\,,\label{eq:approx-psigap}
\end{equation}
and thus for a constant $c:=1+\nu\beta d^{-1}$ and function $h(x):=-(2\sigma_{0}^{2})^{-1}\snorm{x-x^{*}}_{x^{*}}^{2}$,
\begin{align*}
 & \norm{\mu/\mu_{0}}=\E_{\mu}\bbrack{\deriv{\mu}{\mu_{0}}}=\frac{\int_{D}\exp\Bpar{-\frac{c}{\sigma_{0}^{2}}\snorm{x-x^{*}}_{x^{*}}^{2}+\frac{\psi}{\sigma_{0}^{2}}}\cdot\widetilde{\mu}_{0}(\Rd)}{\Bbrack{\int_{D}\exp\Bpar{-\frac{c}{2\sigma_{0}^{2}}\,\snorm{x-x^{*}}_{x^{*}}^{2}}}^{2}}\\
 & \underset{\text{(\ref{eq:intp-intSp})}}{\leq}\frac{1}{\Bbrack{\int_{D}\exp(c\cdot h)}^{2}}\int_{D}\exp\Bpar{-\frac{c}{\sigma_{0}^{2}}\snorm{x-x^{*}}_{x^{*}}^{2}+\underbrace{\frac{\psi}{\sigma_{0}^{2}}}_{\text{Use }(\#)\text{ in (\ref{eq:approx-psigap})}}}\bpar{1+2\exp(-\gamma n/3)}\underbrace{\widetilde{\mu}_{0}(S)}_{\text{Use }(*)}\\
 & \lesssim\frac{\int_{D}\exp\Bpar{-\frac{1}{2\sigma_{0}^{2}}\bpar{2c-e^{3r}(1+\nu\beta d^{-1})}\,\snorm{x-x^{*}}_{x^{*}}^{2}}\int_{D}\exp\bpar{-\frac{1}{2\sigma_{0}^{2}}e^{-3r}(1+\nu\alpha d^{-1})\,\snorm{x-x^{*}}_{x^{*}}^{2}}}{\Bbrack{\int_{D}\exp(c\cdot h)}^{2}}\\
 & =\underbrace{\frac{\int_{D}\exp\Bpar{\bpar{2c-c\,e^{3r}}\,h(x)}\cdot\int_{D}\exp\bpar{c\,e^{3r}h(x)}}{\Bbrack{\int_{D}\exp(c\cdot h)}^{2}}}_{=:\text{\textsf{A}}}\,\underbrace{\frac{\int_{D}\exp\bpar{e^{-3r}(1+\nu\alpha d^{-1})\,h(x)}}{\int_{D}\exp\bpar{c\,e^{3r}h(x)}}}_{=:\text{\textsf{B}}}\,.
\end{align*}
As for $\textsf{A}$, Lemma~\ref{lem:adam-logconcave} leads to 
\begin{align*}
\textsf{A} & \leq\Bpar{\frac{c^{2}}{(2c-c\,e^{3r})\,ce^{3r}}}^{d}=\Bpar{\frac{1}{(2-e^{3r})e^{3r}}}^{d}=(1+\mc O(r^{2}))^{d}=\mc O(1)\,.
\end{align*}
As for $\textsf{B}$, let $c_{1}=e^{-3r}\,(1+\nu\alpha d^{-1})$ and
$c_{2}=e^{3r}\,(1+\nu\beta d^{-1})$. With the change of variable
$y=\sigma_{0}^{-1}\sqrt{c_{i}}g(x^{*})^{1/2}(x-x^{*})$ for $i\in[2]$,
it follows that for $r_{i}:=r\sigma_{0}^{-1}\sqrt{c_{i}}(\geq3\sqrt{d})$
\begin{align*}
\textsf{B} & =\Bpar{\frac{c_{2}}{c_{1}}}^{d/2}\frac{\int_{B_{r_{1}}}\exp\bpar{-\half\snorm y^{2}}\,\D y}{\int_{B_{r_{2}}}\exp\bpar{-\half\snorm y^{2}}\,\D y}\leq\Bpar{\frac{c_{2}}{c_{1}}}^{d/2}\lesssim\Bpar{\frac{\nu\beta+d}{\nu\alpha+d}}^{d}\,e^{3rd}\lesssim\Bpar{\frac{\nu\beta+d}{\nu\alpha+d}}^{d}\,.\qedhere
\end{align*}
\end{proof}
Now we show closeness of two consecutive distributions in Phase 2,
i.e., $\sigma_{i+1}^{2}=\sigma_{i}^{2}\bpar{1+\frac{1}{\sqrt{d}}}$.
\begin{proof}
[Proof of Lemma~\ref{lem:phase2}] Observe that for $\psi=\bar{f}+\phi=\frac{\nu}{d}f+\phi$
on $K$ and $F(\sigma^{2})=\int_{K}\exp(-\psi/\sigma^{2})$, 
\begin{align*}
\snorm{\mu_{i}/\mu_{i+1}} & =\E_{\mu_{i}}\bbrack{\deriv{\mu_{i}}{\mu_{i+1}}}=\frac{\int_{K}\exp\bpar{-2\frac{\psi}{\sigma_{i}^{2}}+\frac{\psi}{\sigma_{i+1}^{2}}}\cdot\int_{K}\exp\bpar{-\frac{\psi}{\sigma_{i+1}^{2}}}}{\Par{\int_{K}\exp\bpar{-\frac{\psi}{\sigma_{i}^{2}}}}^{2}}=\frac{F\bpar{\bpar{\frac{2}{\sigma_{i}^{2}}-\frac{1}{\sigma_{i+1}^{2}}}^{-1}}\,F(\sigma_{i+1}^{2})}{F(\sigma_{i}^{2})^{2}}\,.
\end{align*}
By Lemma~\ref{lem:adam-logconcave}, the function $a^{d}F\bpar{\frac{\sigma^{2}}{a}}$
is log-concave in $a$. Using the definition with endpoints $\frac{2}{\sigma_{i}^{2}}-\frac{1}{\sigma_{i+1}^{2}}$
and $\frac{1}{\sigma_{i+1}^{2}}$, and the middle point $\frac{1}{\sigma_{i}^{2}}$,
we obtain
\[
\frac{F\bpar{\bpar{\frac{2}{\sigma_{i}^{2}}-\frac{1}{\sigma_{i+1}^{2}}}^{-1}}\,F(\sigma_{i+1}^{2})}{F(\sigma_{i}^{2})^{2}}\le\Biggl(\frac{\bpar{\frac{1}{\sigma_{i}^{2}}}^{2}}{\bpar{\frac{2}{\sigma_{i}^{2}}-\frac{1}{\sigma_{i+1}^{2}}}\,\frac{1}{\sigma_{i+1}^{2}}}\Biggr)^{d}=\Biggl(\frac{\bpar{1+\frac{1}{\sqrt{d}}}^{2}}{1+\frac{2}{\sqrt{d}}}\Biggr)^{d}\leq\Bpar{1+\frac{1}{d}}^{d}\leq e\,.\qedhere
\]
\end{proof}
We now establish closeness in Phase 3, during which we use the update
of $\sigma_{i+1}^{2}=\sigma_{i}^{2}\bpar{1+\frac{\sigma_{i}}{\sqrt{\nu}}}$.
\begin{proof}
[Proof of Lemma~\ref{lem:phase34}] The update is $\sigma_{i+1}^{2}=\sigma_{i}^{2}\Par{1+r}$
for $r=\frac{\sigma_{i}}{\sqrt{\nu}}$. For $s:=\frac{r}{1+r}$, $\sigma:=\sigma_{i}$,
and $F(\sigma^{2})=\int\exp(-f-\phi/\sigma^{2})$, we have
\begin{align*}
\snorm{\mu_{i}/\mu_{i+1}} & =\frac{F\bpar{\bpar{\frac{2}{\sigma_{i}^{2}}-\frac{1}{\sigma_{i+1}^{2}}}^{-1}}\,F(\sigma_{i+1}^{2})}{F(\sigma_{i}^{2})^{2}}=\frac{F\bpar{\frac{\sigma^{2}}{1+s}}\,F\bpar{\frac{\sigma^{2}}{1-s}}}{F(\sigma^{2})^{2}}\,.
\end{align*}
Let $g(t):=\log F\bpar{\frac{\sigma^{2}}{t}}$ for $t>0$. Then,
\begin{align}
\log\snorm{\mu_{i}/\mu_{i+1}} & =g(1+s)+g(1-s)-2g(1)=\int_{0}^{s}\bpar{g'(1+t)-g'(1-t)}\,\D t=\int_{0}^{s}\int_{1-t}^{1+t}g''(q)\,\D q\,\D t\label{eq:L2-bound-phase3}
\end{align}
and for a probability measure $\nu_{q}\propto\exp\bpar{-f-\frac{q\phi}{\sigma^{2}}}$,
\begin{align*}
g''(q) & =\frac{\D^{2}}{\D q^{2}}\Bbrack{\log\int_{K}\exp\Bpar{-f-\frac{q\phi}{\sigma^{2}}}}=-\frac{1}{\sigma^{2}}\,\frac{\D}{\D q}\Bigg[\frac{\int_{K}\phi\cdot\exp\Bpar{-f-\frac{q\phi}{\sigma^{2}}}}{\int_{K}\exp\Bpar{-f-\frac{q\phi}{\sigma^{2}}}}\Biggr]\\
 & =-\frac{1}{\sigma^{2}}\,\Bigg(-\frac{1}{\sigma^{2}}\,\frac{\int_{K}\phi^{2}\cdot\exp\Bpar{-f-\frac{q\phi}{\sigma^{2}}}}{\int_{K}\exp\Bpar{-f-\frac{q\phi}{\sigma^{2}}}}+\frac{1}{\sigma^{2}}\,\frac{\Bbrack{\int_{K}\phi\cdot\exp\Bpar{-f-\frac{q\phi}{\sigma^{2}}}}^{2}}{\Bbrack{\int_{K}\exp\Bpar{-f-\frac{q\phi}{\sigma^{2}}}}^{2}}\Biggr)\\
 & =\frac{1}{\sigma^{4}}\,\Bpar{\E_{\nu_{q}}[\phi^{2}]-(\E_{\nu_{q}}\phi)^{2}}=\frac{1}{\sigma^{4}}\,\var_{\nu_{q}}\phi\,.
\end{align*}
By the Brascamp-Lieb inequality with $V(\cdot):=f(\cdot)+\frac{q\phi(\cdot)}{\sigma^{2}}$,
\begin{align*}
\var_{\nu_{q}}\phi & \leq\E_{\nu_{q}}\bbrack{(\grad\phi)^{\T}\bpar{\hess V}^{-1}\grad\phi}\leq\frac{\sigma^{2}}{q}\,\E_{\nu_{q}}\snorm{\nabla\phi}_{(\hess\phi)^{-1}}^{2}\leq\frac{\sigma^{2}\nu}{q}\,,
\end{align*}
and thus $g''(q)\leq\frac{\nu}{q\sigma^{2}}.$ Putting this back to
\eqref{eq:L2-bound-phase3}, we acquire
\begin{align}
\log\norm{\mu_{i}/\mu_{i+1}} & \leq\frac{\nu}{\sigma^{2}}\int_{0}^{s}\int_{1-t}^{1+t}\frac{1}{q}\,\D q\,\D t=\frac{\nu}{\sigma^{2}}\int_{0}^{s}\bpar{\log(1+t)-\log(1-t)}\,\D t\nonumber \\
 & =\frac{\nu}{\sigma^{2}}\bpar{(1+s)\,\log(1+s)+(1-s)\,\log(1-s)}\lesssim\frac{\nu s^{2}}{\sigma^{2}}\,.\label{eq:bound-ph3}
\end{align}
It follows from $s=\frac{r}{1+r}$ and $r=\frac{\sigma}{\sqrt{\nu}}$
that $\mu_{i}$ is an $\mc O(1)$-warm start for $\mu_{i+1}$.

For Phase 4, observe that for $\mu\propto\exp(-f-\phi/\sigma^{2})$
with $\sigma^{2}=\nu$,
\begin{align*}
\snorm{\mu/\pi} & =\frac{\int_{K}\exp\bpar{-f-\frac{\phi}{\sigma^{2}/2}}\cdot\int_{K}\exp(-f)}{\Bbrack{\int_{K}\exp\Bpar{-f-\frac{\phi}{\sigma^{2}}}}^{2}}\underset{\text{(i)}}{=}\lim_{r\to1}\frac{F\bpar{\frac{\sigma^{2}}{1+r}}\cdot F\bpar{\frac{\sigma^{2}}{1-r}}}{F(\sigma^{2})}\\
 & \underset{\text{(ii)}}{\leq}\lim_{r\to1}\exp\Bpar{\mc O(1)\frac{\nu}{\sigma^{2}}\,\bpar{(1+r)\,\log(1+r)+(1-r)\,\log(1-r)}}=\exp\Bpar{\mc O(1)\frac{\nu}{\sigma^{2}}}=\exp(\mc O(1))\,.
\end{align*}
where (i) holds due to the monotone convergence theorem, and (ii)
follows from \eqref{eq:bound-ph3}. Therefore, $\mu$ serves as an
$\mc O(1)$-warm start for $\pi$.
\end{proof}
\begin{rem}
[Coupling argument] \label{rem:divine-intervention} The total number
of measures involved in Algorithm~\ref{alg:IPM-sampling} is $m:=\mc O(\sqrt{d})$.
Let $(X_{1},\dots,X_{m})$ be a sequence of samples provided by Algorithm~\ref{alg:IPM-sampling},
and $(\bar{X}_{1},\dots,\bar{X}_{m})$ be a sequence of samples where
each sample is drawn from the \emph{actual} target distributions $\{\mu_{\sigma^{2}}\}$.
Conditioned on events $X_{i}=\bar{X}_{i}$, Algorithm~\ref{alg:IPM-sampling}
ensures that there is a coupling such that $\P(X_{i+1}=\bar{X}_{i+1}\mid X_{i}=\bar{X}_{i})\geq1-\frac{\veps}{\sqrt{d}}$
due to $\veps/\sqrt{d}$ TV-distance guarantee. Combining these couplings,
\[
\P\Par{X_{i}=\bar{X_{i}}\ \forall i\in[m]}=\P(X_{1}=\bar{X}_{1})\cdot\prod_{i=2}^{m}\P(X_{i}=\bar{X}_{i}\mid X_{i-1}=\bar{X}_{i-1})\geq1-\veps\,.
\]
Thus, it leads to a coupling between $X_{m}$ and $\bar{X}_{m}$ such
that $\P(X_{m}=\bar{X}_{m})\geq1-\veps$, so $\law(X_{m})$ is within
$\veps$-TV distance to $\pi=\law(\bar{X}_{m})$.
\end{rem}


\subsection{Self-concordance theory ($\S$\ref{sec:sc-theory-rules})}

\subsubsection{Basic properties: strong self-concordance \label{proof:ssc-basic}}

We show that $2(g_{1}+g_{2})$ is SSC if $g_{1}$ and $g_{2}$ are
SSC.
\begin{proof}
[Proof of Lemma~\ref{lem:ssc-sum}] For fixed $x\in K_{1}\cap K_{2}$
and $h\in\Rd$, let $\Dd g_{i}:=\Dd g_{i}(x)[h]$ for $i=1,2$. Note
that 
\begin{align*}
 & \snorm{(g_{1}+g_{2})^{-\half}\Dd(g_{1}+g_{2})\,(g_{1}+g_{2})^{-\half}}_{F}\\
 & \leq\sum_{i=1}^{2}\snorm{(g_{1}+g_{2})^{-\half}\Dd g_{i}\,(g_{1}+g_{2})^{-\half}}_{F}=\sum_{i=1}^{2}\sqrt{\tr\bpar{(g_{1}+g_{2})^{-1}\Dd g_{i}\,(g_{1}+g_{2})^{-1}\Dd g_{i}}}\\
 & =\Bbrack{\tr\Bpar{\bpar{\underbrace{I+g_{1}^{-\half}g_{2}g_{1}^{-\half}}_{=:E_{1}}}^{-1}\underbrace{g_{1}^{-\half}\Dd g_{1}\,g_{1}^{-\half}}_{=:T_{1}}\bpar{I+g_{1}^{-\half}g_{2}g_{1}^{-\half}}^{-1}g_{1}^{-\half}\Dd g_{1}\,g_{1}^{-\half}}}^{1/2}\\
 & \qquad+\Bbrack{\tr\Bpar{\bpar{\underbrace{I+g_{2}^{-\half}g_{1}g_{2}^{-\half}}_{=:E_{2}}}^{-1}\underbrace{g_{2}^{-\half}\Dd g_{2}\,g_{2}^{-\half}}_{=:T_{2}}\bpar{I+g_{2}^{-\half}g_{1}g_{2}^{-\half}}^{-1}g_{2}^{-\half}\Dd g_{2}\,g_{2}^{-\half}\bigg)}}^{1/2}\\
 & =\sum_{i=1}^{2}\sqrt{\tr(E_{i}^{-1}T_{i}E_{i}^{-1}T_{i})}\leq\sum_{i=1}^{2}\sqrt{\tr(T_{i}E_{i}^{-2}T_{i})}\,,
\end{align*}
where we used the Cauchy-Schwarz inequality $\tr(A^{2})\leq\tr(A^{\T}A)$
in the last line. It follows from $I\preceq E_{i}$ that $I\preceq E_{i}^{2}$
and $I\succeq E_{i}^{-2}\succ0$. Therefore, 
\begin{align*}
\sum_{i=1}^{2}\sqrt{\tr(T_{i}E_{i}^{-2}T_{i})} & \leq\sum_{i=1}^{2}\snorm{T_{i}}_{F}\leq2\sum_{i=1}^{2}\snorm h_{g_{i}(x)}^{2}\leq2\sqrt{2}\norm h_{(g_{1}+g_{2})(x)}\,.
\end{align*}
Putting these together completes the proof.
\end{proof}

\subsubsection{Basic properties: lower trace self-concordance \label{proof:ltsc-basic}}

We now show that if $g$ is HSC, then $dg$ is SLTSC.
\begin{proof}
[Proof of Lemma~\ref{lem:hsc-to-sltsc}] We first consider when
$\bar{g}$ is positive definite on $K$. By HSC of $\bar{g}$, it
holds that $-\snorm h_{\bar{g}}^{2}\,\bar{g}\lesssim\Dd^{2}\bar{g}[h,h]$,
and thus
\[
-\frac{1}{d}\,\snorm h_{g}^{2}\,(g'+g)^{-\half}g\,(g'+g)^{-\half}\lesssim(g'+g)^{-\half}\Dd^{2}g[h,h]\,(g'+g)^{-\half}\,.
\]
Hence,
\begin{align*}
\tr\bpar{(g'+g)^{-1}\Dd^{2}g[h,h]} & \gtrsim-\frac{1}{d}\,\snorm h_{g}^{2}\,\tr\Bpar{(g'+g)^{-\half}g\,(g'+g)^{-\half}}=-\frac{1}{d}\,\snorm h_{g}^{2}\,\tr\bpar{g^{\half}(g'+g)^{-1}g^{\half}}\\
 & \geq-\frac{1}{d}\,\snorm h_{g}^{2}\,\tr(g^{\half}g^{-1}g^{\half})=-\snorm h_{g}^{2}\,.
\end{align*}

When $g$ is singular, we consider $\bar{g}_{\veps}=\bar{g}+\frac{\veps}{d}I\in\pd$
for $\veps>0$. Then $\bar{g}_{\veps}$ is HSC, so for $g_{\veps}=d\bar{g}_{\veps}$
\[
\tr\bpar{(g'+g_{\veps})^{-1}\Dd^{2}g[h,h]}\gtrsim-\snorm h_{g_{\veps}}^{2}\,.
\]
From $(g'+g_{\veps})^{-1}=\frac{1}{\det(g'+g_{\veps})}\,\text{adj}(g'+g_{\veps})$,
the LHS is continuous in $\veps$, and the RHS is too clearly. Sending
$\veps\to0$ completes the proof.
\end{proof}

\subsubsection{Basic properties: strongly average self-concordance \label{proof:sasc-basic}}

To prove Lemma \ref{lem:hsc-to-sasc}, we first recall a concentration
bound.
\begin{lem}
[\citet{narayanan2016randomized}, Lemma 4] \label{lem:odd-order-concen}Let
$h$ be drawn from $\mathbb{S}^{d-1}$ uniformly at random. For any
odd $k$, $C^{k}$-smooth $F:\Rd\to\R$, and $\veps>0$,
\[
\P_{h}\Bpar{|\Dd^{k}F(x)[h^{\otimes k}]|>k\veps\cdot\sup_{\snorm v\leq1}\Dd^{k}F(x)[v^{\otimes k}]}\leq\exp\Bpar{-\frac{d\veps^{2}}{2}}\,.
\]
\end{lem}

We show that if $g$ is HSC, then $dg$ is SASC, using this lemma
and following \citet{narayanan2016randomized}.
\begin{proof}
[Proof of Lemma~\ref{lem:hsc-to-sasc}] Let $g=d\,\hess\phi$ and
consider $g':\intk\to\psd$ such that $\bar{g}=g+g'$ is PD. For fixed
$w\in\Rd$, apply Taylor's expansion to $\vphi(z):=\norm w_{g(z)}^{2}$
at $z=x$, so there exists $p_{w}\in[x,z]$ such that $w^{\T}g(z)w=w^{\T}g(x)w+\Dd g(x)[z,w,w]+\half\,\Dd^{2}g(p_{w})[z,z,w,w].$
Putting $z=w$ here,
\[
|\snorm z_{g(z)}^{2}-\snorm z_{g(x)}^{2}|\leq|\Dd^{3}g(x)[z^{\otimes3}]|+\half|\Dd^{2}g(p_{z})[z^{\otimes4}]|\,.
\]

Going forward, we can assume that $x=0$ and $\bar{g}(x)=I$ due to
affine invariance, and then $z$ equals $rh/\sqrt{d}$ for $h\sim\ncal(0,I_{d})$
in law. Using a standard tail bound on the standard Gaussian, we have
$\P_{h}(\norm h\geq-\sqrt{d}\cdot2\log\veps)\leq\veps.$ Call this
event $B_{1}$. In addition, Lemma~\ref{lem:odd-order-concen} implies
that 
\[
\P\Bpar{\Big|\Dd^{3}\phi(x)\Bbrack{\frac{h^{\otimes3}}{\norm h^{3}}}\Big|\geq3\frac{\veps}{\sqrt{d}}\cdot\sup_{\norm v\leq1}\Dd^{3}\phi(x)[v^{\otimes3}]}\leq\veps\,,
\]
and call this event $B_{2}$. Conditioned on $B_{2}^{c}$,
\begin{align*}
\Big|\Dd^{3}\phi(x)\Bbrack{\frac{h^{\otimes3}}{\norm h^{3}}}\Big| & \leq\frac{3\veps}{\sqrt{d}}\,\sup_{\norm v\leq1}\Dd^{3}\phi(x)[v^{\otimes3}]\leq\frac{6\veps}{\sqrt{d}}\,\sup_{\norm v\leq1}\snorm v_{g(x)/d}^{3}\leq\frac{6\veps}{d^{2}}\,\sup_{\norm v\leq1}\snorm v_{g(x)}^{3}\underbrace{\leq}_{g(x)\preceq I_{d}}\frac{6\veps}{d^{2}}\,.
\end{align*}
Hence, conditioned on $z\in B_{1}^{c}\cap B_{2}^{c}$
\begin{align*}
|\Dd^{3}g(x)[z^{\otimes3}]| & =\frac{r^{3}}{\sqrt{d}}\,\Dd^{3}\phi(x)[h^{\otimes3}]\leq\frac{r^{3}}{\sqrt{d}}\,\frac{6\veps}{d^{2}}\,\snorm h^{3}\leq\frac{r^{2}}{d}\cdot48r\veps\Bpar{\log\frac{1}{\veps}}^{3}\,.
\end{align*}
By taking $r_{1}(\veps)$ so that $-48r_{1}\veps\,(\log\veps)^{3}\leq\veps$,
we can ensure $|\Dd^{3}g(x)[z^{\otimes3}]|\leq\veps r^{2}/d$ for
any $r\leq r_{1}(\veps)$.

As for $|\Dd^{2}g(p_{z})[z^{\otimes4}]|$, HSC of $\phi$ and Lemma~\ref{lem:scCloseness}
lead to 
\begin{align*}
\half\,|\Dd^{2}g(p_{z})[z^{\otimes4}]| & \leq3d\,\snorm z_{\hess\phi(p_{z})}^{4}\le\frac{3}{d}\snorm z_{\hess\phi(x)}^{4}\,(1+2\,\snorm z_{\hess\phi(x)}^{2})^{2}=\frac{3}{d}\,\snorm z_{g(x)}^{4}\,\bpar{1+\frac{2}{d}\,\snorm z_{g(x)}^{2}}^{2}\\
 & \underset{g\preceq I_{d}}{\leq}\frac{3}{d}\snorm z^{4}\bpar{1+\frac{2}{d}\,\snorm z^{2}}^{2}=\frac{3}{d}\,\frac{r^{4}}{d^{2}}\,\snorm h^{4}\Bpar{1+\frac{2r^{2}}{d^{2}}\norm h^{2}}^{2}\\
 & \leq\frac{r^{2}}{d}\cdot3r^{2}\,\bpar{2\log\frac{1}{\veps}}^{4}\Bpar{1+2r^{2}\bpar{2\log\frac{1}{\veps}}^{4}}^{2}\,.
\end{align*}
By taking $r_{2}(\veps)$ and $r_{3}(\veps)$ so that $\Bpar{1+2r_{2}^{2}\bpar{2\log\frac{1}{\veps}}^{4}}^{2}\leq2$
and $2^{2}\cdot3r_{3}^{2}\bpar{2\log\frac{1}{\veps}}^{4}\leq\veps$
respectively, it holds that on $B_{1}^{c}\cap B_{2}^{c}$
\[
\half\,|\Dd^{2}g(p_{z})[z^{\otimes4}]|\leq\veps\frac{r^{2}}{d}\ \text{for any }r\leq\min r_{i}(\veps).
\]
Putting all these together, it follows that $|\norm z_{g(z)}^{2}-\norm z_{g(x)}^{2}|\leq2\veps r^{2}/d$
with probability at least $1-2\veps$. By replacing $2\veps\gets\veps$,
the claim follows.
\end{proof}

\subsubsection{Collapse and embedding: well-definedness \label{proof:collapse-embedding-welldefined}}

We start with well-definedness of the notions of collapse and embedding
(Definition~\ref{def:sc-along-subspace}).
\begin{proof}
[Proof of Proposition~\ref{prop:collapse-well-defined}] Let $k:=\dim(W)$,
and $U$ and $V$ be matrices in $\R^{d\times k}$, where the columns
of each matrix form an orthonormal basis of $W$. Let us denote by
$g_{1}:=U^{\T}gU$ and $g_{2}:=V^{\T}gV$ matrices represented with
respect to $U$ and $V$, and define the invertible matrix $M=V^{-1}U\in\R^{k\times k}$.
Since $U$ and $V$ are full-column rank, if $g_{1}$ is PD, so is
$g_{2}$.

Suppose $g$ is SSC along $W$. Then, 
\begin{align*}
4\norm h_{g}^{2} & \geq\tr(g_{1}^{-1}\Dd g_{1}[h]\,g_{1}^{-1}\Dd g_{1})=\tr\bpar{(U^{\T}gU)^{-1}\cdot U^{\T}\Dd g[h]\,U\cdot(U^{\T}gU)^{-1}\cdot U^{\T}\Dd g[h]\,U}\\
 & =\tr\Bpar{(M^{\T}V^{\T}gVM)^{-1}\cdot M^{\T}V^{\T}\Dd g[h]\,VM\cdot(M^{\T}V^{\T}gVM)^{-1}\cdot M^{\T}V^{\T}\Dd g[h]\,VM}\\
 & =\tr\Bpar{(V^{\T}gV)^{-1}V^{\T}\Dd g[h]\,V\,(V^{\T}gV)^{-1}V^{\T}\Dd g[h]\,V}=\norm{g_{2}^{-\half}\Dd g_{2}[h]\,g_{2}^{-\half}}_{F}^{2}\,,
\end{align*}
and thus $g_{2}$ also satisfies the definition.
\end{proof}

\subsubsection{Collapse and embedding: affine transformation \label{proof:collap-affine}}

We begin with a barrier version.
\begin{proof}
[Proof of Lemma~\ref{lem:linear-trans}] For the first part, $\psi$
is a $\nu$-self-concordant barrier for $\bar{K}$ by \citet[Theorem 4.2.3]{nesterov2003introductory},
so $\dcal_{\bar{g}}^{1}(x)\subset\bar{K}\cap(2x-\bar{K})$ for $\bar{g}(\cdot):=\hess\psi(\cdot)$
by Lemma~\ref{lem:symmetricLeftpart}. Now let $z\in\bar{K}\cap(2x-\bar{K})$.
Then $Tz\in K$ and $T(2x-z)\in K$, and the latter implies $2y-Tz\in K$.
Thus $Tz\in K\cap(2y-K)$ and $Tz\in\dcal_{g}^{\sqrt{\onu}}(y)$.
Due to 
\begin{align*}
\Dd^{2}\psi(x)[(z-x)^{\otimes2}] & =\Dd^{2}\phi(y)[\bpar{A(z-x)}^{\otimes2}]=\Dd^{2}\phi(y)[(Tz-y)^{\otimes2}]\leq\onu\,,
\end{align*}
it follows that $\psi$ is also $\onu$-symmetric. 

For the second part, observe that $\Dd^{4}\psi(x)[v,v,h,h]=\Dd^{4}\phi(y)[Av,Av,Ah,Ah]\geq0$
for any $v,h\in\Rd$. The third part can be proven similarly.
\end{proof}
Next is a matrix version.
\begin{proof}
[Proof of Lemma~\ref{lem:linear-trans-matrix}] Let $\phi$ be a
$\nu$-self-concordant function counterpart of $g$. Then $\psi(x):=\phi(Tx)$
defined on $\inter(\bar{K})$ is $\nu$-self-concordant by Lemma~\ref{lem:linear-trans}.
For any $h\in\Rd$ and $y:=Tx$, we have 
\[
\Dd\bar{g}(x)[h]=A^{\T}\Dd g(y)[Ah]\,A\preceq2\norm{Ah}_{g(y)}\,A^{\T}g(y)A=2\norm h_{\bar{g}(x)}\,\bar{g}(x)\,.
\]

Consider a sequence $\{x_{n}\}\subset\bar{K}$ converging to a boundary
point $x\in\de\bar{K}$. If $Tx\notin\de K$, then $Tx\in\inter(K)$,
and the continuity of $T$ implies $x$ is also in $\inter(\bar{K})$.
Thus, $Tx\in\de K$ and $\psi(x_{n})=\phi(Tx_{n})\to\phi(Tx)=\infty$.
Lastly, $\hess\phi\asymp g$ leads to $\hess\psi=A^{\T}\hess\phi\,A\asymp A^{\T}gA=\bar{g}$,
and $\bar{g}$ is $\nu$-self-concordant for $\bar{K}$.

As for symmetry, since $\bar{g}$ is self-concordant, $\mc D_{\bar{g}}^{1}(x)\subset\bar{K}\cap(2x-\bar{K})$
for $x\in\inter(\bar{K})$ by Lemma~\ref{lem:dikin-in-body}. For
$z\in\bar{K}\cap(2x-\bar{K})$, as $Tz\in K\cap(2Tx-K)$ holds, it
follows that 
\[
\onu\geq\norm{Tz-Tx}_{g(y)}^{2}=\norm{z-y}_{A^{\T}g(y)A}^{2}=\norm{z-y}_{\bar{g}(x)}^{2}\,,
\]
and thus $\bar{g}$ is $\onu$-symmetric.

As for the second item, we first show that $\bar{g}$ is collapsed
onto $W=\rowspace(A)$ (i.e., $\bar{g}=P_{W}\bar{g}P_{W}$ for the
orthogonal projection $P_{W}$ onto $W$). To see this, observe that
\begin{align*}
P_{W}\bar{g}P_{W} & =P_{W}A^{\T}gAP_{W}=A^{\T}(AA^{\T})^{\dagger}A\cdot A^{\T}gA\cdot A^{\T}(AA^{\T})^{\dagger}A\,,
\end{align*}
and due to $AA^{\T}(AA^{\T})^{\dagger}A=AA^{\T}(A^{\T})^{\dagger}A^{\dagger}A=AA^{\dagger}A=A$,
we have $P_{W}\bar{g}P_{W}=A^{\T}gA=\bar{g}$. 

We now show that $\bar{g}$ is SSC along $W$. For $k:=\dim(W)$,
take $U\in\R^{d\times k}$ whose columns form an orthonormal basis
of $W$. It suffices to show that $g_{W}:=U^{\T}\bar{g}U=U^{\T}A^{\T}gAU=M^{\T}gM$
for $M:=AU\in\R^{m\times k}$ is SSC. First of all, we can check PDness
of $g_{W}$ as follows: Suppose $g_{W}v=0$ for some $v\in\R^{k}$.
Then $0=\norm v_{g_{W}}=\norm{g^{1/2}Mv}_{2}$ and $AUv=Mv=0$. Since
$Uv\in\rowspace(A)\cap\textsf{ker}(A)$ and $U$ is full-rank, we
have $v=0$. Next, for $h\in\R^{k}$ and $x\in\inter(\bar{K})$
\begin{align*}
 & \tr\bpar{g_{W}(x)^{-1}\Dd g_{W}(x)[h]\,g_{W}(x)^{-1}\Dd g_{W}(x)[h]}=\tr\Bpar{\bpar{g^{\half}M(M^{\T}gM)^{-1}M^{\T}g^{\half}\cdot g^{-\half}\Dd g(Tx)[Ah]\,g^{-\half}}^{2}}\\
\underset{\text{(i)}}{\leq} & \tr\Bpar{\bpar{g^{-\half}\Dd g(Tx)[Ah]\,g^{-\half}}^{2}}\leq\norm{g^{-\half}\Dd g(Tx)[Ah]\,g^{-\half}}_{F}^{2}\leq4\norm{Ah}_{g(Tx)}^{2}=4\norm h_{\bar{g}(x)}^{2}\,,
\end{align*}
where in (i) we used $P(g^{\half}M)=g^{\half}M(M^{\T}gM)^{-1}M^{\T}g^{\half}\preceq I$.
Thus, $\bar{g}$ is SSC along $W=\rowspace(A)$.

The third item immediately follows from $\Dd^{2}\bar{g}(x)[h,h]=A^{\T}\Dd^{2}g(y)[Ah,Ah]\,A\succeq0$
for any $h\in\Rd$. 

As for the fourth item, for any PSD matrix function $g'$ on $\bar{K}$
we have
\begin{align*}
 & \tr\bpar{(g'+\bar{g})^{-1}\Dd^{2}\bar{g}[h,h]}=\tr\Bpar{(g'+A^{\T}gA)^{-1}A^{\T}\Dd^{2}g[Ah,Ah]\,A}\\
= & \tr\Bpar{(A^{-\T}g'A^{-1}+g)^{-1}\Dd^{2}g[Ah,Ah]}\geq-\norm{Ah}_{g}^{2}=-\norm h_{\bar{g}}^{2}\,.
\end{align*}

The last item is straightforward to check by the change of variable.
\end{proof}

\subsubsection{Collapse and embedding: lifting up SSC, SLTSC, and SASC \label{proof:lifting-ssc}}

In passing SSC to an augmented space, the Woodbury matrix identity
is a main technical tool used: for matrices with compatible sizes
\[
(I+UV)^{-1}=I-U\,(I+VU)^{-1}V\,.
\]
Using this, we show that if $g\in\pd$ is SSC, then $\bar{g}+\veps I_{m}$
is SSC.
\begin{proof}
[Proof of Lemma~\ref{lem:embedding-ssc}] Fix $\veps>0,y\in\inter(K')$,
and $h\in\R^{m}$. Take a projection matrix $P\in\{0,1\}^{d\times m}$
such that $PP^{\T}=I_{d}$ and $\bar{g}(y)=P^{\T}g(Py)P$ for $x=Py\in\intk$.
Also for $k:=\dim(W)$, take a matrix $U\in\R^{d\times k}$ whose
columns form an orthonormal basis of $W$. Then $\bar{g}(y)=P^{\T}g(Py)P$
and $g(x)=Ug_{W}(x)U$, so for $M:=U^{\T}P\in\R^{k\times m}$,
\[
\bar{g}(y)=P^{\T}Ug_{W}(Py)U^{\T}P=M^{\T}g_{W}(Py)M\,.
\]
 Note that $MM^{\T}=I_{k}$. Thus,
\begin{align*}
 & \norm{(\bar{g}(y)+\veps I)^{-\half}\Dd(\bar{g}+\veps I)(y)[h]\,(\bar{g}(y)+\veps I)^{-\half}}_{F}^{2}=\tr\Bpar{\bpar{(\bar{g}(y)+\veps I)^{-1}\Dd\bar{g}(y)[h]}^{2}}\\
= & \tr\Bpar{\bpar{M(M^{\T}g_{W}(x)\,M+\veps I)^{-1}M^{\T}\cdot\Dd g_{W}(x)[Ph]}^{2}}\underset{\text{(i)}}{=}\tr\Bpar{\bpar{(g_{W}(x)+\veps I_{k})^{-1}\Dd g_{W}(x)[Ph]}^{2}}\\
\leq & \norm{g_{W}(x)^{-\half}\Dd g_{W}(x)[Ph]\,g_{W}(x)^{-\half}}_{F}^{2}\leq4\norm{Ph}_{g(x)}^{2}=4\norm h_{\bar{g}(y)}^{2}\,,
\end{align*}
where in (i) we used the identity $M\bpar{M^{\T}g_{W}(x)\,M+\veps I}^{-1}M^{\T}=(g_{W}(x)+\veps I_{k})^{-1}$.
To see this, we use the Woodbury matrix identity to get
\[
(\veps I_{m}+M^{\T}g_{W}M)^{-1}=\frac{1}{\veps}I_{m}-\frac{1}{\veps^{2}}M^{\T}g_{W}^{\half}\bpar{I_{k}+\frac{1}{\veps}g_{W}}^{-1}g_{W}^{\half}M\,,
\]
and thus conjugating both sides by $M$ results in 
\begin{align*}
M\bpar{M^{\T}g_{W}M+\veps I_{m}}^{-1}M^{\T} & =\frac{1}{\veps}I_{k}-\frac{1}{\veps}g_{W}^{\half}(g_{W}+\veps I_{k})^{-1}g_{W}^{\half}=\frac{1}{\veps}I_{k}-\frac{1}{\veps}(g_{W}+\veps I_{k})^{-1}g_{W}\,.
\end{align*}
Then, the identity follows from
\begin{align*}
(g_{W}+\veps I_{k})\cdot\bpar{\frac{1}{\veps}I_{k}-\frac{1}{\veps}\,(g_{W}+\veps I_{k})^{-1}g_{W}} & =\frac{1}{\veps}(g_{W}+\veps I_{k})-\frac{1}{\veps}g_{W}=I_{k}\,.\qedhere
\end{align*}
\end{proof}
In extending SLTSC and SASC, we need two technical lemmas: the inverse
of a block matrix and connection between P(S)Dness and Schur complements.
\begin{lem}
\label{lem:block-inverse} If $D$ and its Schur complement $A-BD^{-1}C$
are invertible, then 
\[
\left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right]^{-1}=\left[\begin{array}{cc}
(A-BD^{-1}C)^{-1} & *\\
* & *
\end{array}\right]\,.
\]
\end{lem}

\begin{lem}
[Schur complement] \label{lem:schur} Let $A\in\Rdd,B\in\R^{d\times m},C\in\R^{m\times m}$
and define a matrix $M\in\R^{(m+d)\times(m+d)}$ by 
\[
M=\left[\begin{array}{cc}
A & B\\
B^{\T} & D
\end{array}\right]\,.
\]
Then $M\succ0$ if and only if $A\succ0$ and $C-BA^{-1}B^{\T}\succ0$
if and only $C\succ0$ and $A-B^{\T}C^{-1}B\succ0$.
\end{lem}

Using these, we show that if $g$ is SLTSC and SASC, then $\bar{g}$
is SLTSC and SASC.
\begin{proof}
[Proof of Lemma~\ref{lem:embedding-sltsc}] Take a full row-rank
projection matrix $P\in\{0,1\}^{d\times m}$ such that $\bar{g}(y)=P^{\T}g(Py)P$,
where the rows of $P$ forms a subset of the canonical basis $\{e_{1},\dots,e_{m}\}$.
We can augment the rows of $P$ with the rest of the canonical basis
so that the augmented matrix $\bar{P}\in\R^{m\times m}$ is an orthonormal
matrix. Then we can represent $\bar{g}$ by 
\[
\bar{g}(y)=\bar{P}^{\T}\left[\begin{array}{cc}
g(Py) & 0\\
0 & 0
\end{array}\right]\bar{P}\,.
\]

Consider a PSD matrix function $g':\inter(K')\to\mbb S_{+}^{m}$ such
that $g'+\bar{g}$ is PD on $K'$. Representing them in the block
form with $g_{A}\in\Rdd,g_{B}\in\R^{d\times(m-d)},$ and $g_{C}\in\R^{(m-d)\times(m-d)}$
\[
\bar{g}+g'=\bar{P}^{\T}\Par{\left[\begin{array}{cc}
g & 0\\
0 & 0
\end{array}\right]+\left[\begin{array}{cc}
g_{A} & g_{B}\\
g_{B}^{\T} & g_{C}
\end{array}\right]}\bar{P}=\bar{P}^{\T}\underbrace{\left[\begin{array}{cc}
g+g_{A} & g_{B}\\
g_{B}^{\T} & g_{C}
\end{array}\right]}_{\eqqcolon g^{*}}\bar{P}\,.
\]
Since $g^{*}$ is PD, $g_{C}$ and its Schur complement $(g+g_{A})-g_{B}g_{C}^{-1}g_{B}^{\T}$
are PD. Thus by Lemma~\ref{lem:block-inverse},
\[
\left[\begin{array}{cc}
g+g_{A} & g_{B}\\
g_{B}^{\T} & g_{C}
\end{array}\right]^{-1}=\left[\begin{array}{cc}
(g+g_{A}-g_{B}g_{C}^{-1}g_{B}^{\T})^{-1} & *\\
* & *
\end{array}\right]\,.
\]
Hence,
\begin{align*}
 & \tr\bpar{(\bar{g}+g')^{-1}\Dd^{2}\bar{g}(y)[h,h]}=\tr\Biggl(\bar{P}^{\T}\left[\begin{array}{cc}
g+g_{A} & g_{B}\\
g_{B}^{\T} & g_{C}
\end{array}\right]^{-1}\bar{P}\bar{P}^{\T}\left[\begin{array}{cc}
\Dd^{2}g(Py)[Ph,Ph] & 0\\
0 & 0
\end{array}\right]\bar{P}\Biggr)\\
= & \tr\Biggl(\left[\begin{array}{cc}
g+g_{A} & g_{B}\\
g_{B}^{\T} & g_{C}
\end{array}\right]^{-1}\left[\begin{array}{cc}
\Dd^{2}g(Py)[Ph,Ph] & 0\\
0 & 0
\end{array}\right]\Biggr)=\tr\bpar{(g+\underbrace{g_{A}-g_{B}g_{C}^{-1}g_{B}^{\T}}_{\succeq0})^{-1}\,\Dd^{2}g(Py)[Ph,Ph]}\\
\ge & -\norm{Ph}_{g(Py)}^{2}=-\norm h_{\bar{g}(y)}^{2}\,,
\end{align*}
where in the last inequality we used STLSC of $g$, since $g'\succeq0$
ensures that its Schur complement satisfies $g_{A}-g_{B}g_{C}^{-1}g_{B}^{\T}\succeq0$
by Lemma~\ref{lem:schur}.

For SASC, consider any PSD matrix function $g':\inter(K')\to\mbb S_{+}^{m}$.
For $x=Py$ and $z_{x}=Pz_{y}\in\Rd$ with $z_{y}\sim\ncal\bpar{y,\frac{r^{2}}{m}\,(\bar{g}+g)(y)^{-1}}$,
we have
\[
\norm{z_{y}-y}_{\bar{g}(z_{y})}^{2}-\norm{z_{y}-y}_{\bar{g}(y)}^{2}=\norm{z_{x}-x}_{g(z_{x})}^{2}-\norm{z_{x}-x}_{g(x)}^{2}\,.
\]
Also, $z_{x}-x=P\,(z_{y}-y)$ is a Gaussian with zero mean and covariance
\begin{align*}
 & \frac{r^{2}}{m}\,P\,(\bar{g}+g')(y)^{-1}P^{\T}=\frac{r^{2}}{m}\,P\bar{P}^{\T}\Par{\left[\begin{array}{cc}
g & 0\\
0 & 0
\end{array}\right]+\left[\begin{array}{cc}
g_{A} & g_{B}\\
g_{B}^{\T} & g_{C}
\end{array}\right]}^{-1}\bar{P}\bar{P}^{\T}\\
= & \frac{r^{2}}{m}\,\left[\begin{array}{cc}
I_{d} & 0_{d\times(m-d)}\end{array}\right]\Par{\left[\begin{array}{cc}
g & 0\\
0 & 0
\end{array}\right]+\left[\begin{array}{cc}
g_{A} & g_{B}\\
g_{B}^{\T} & g_{C}
\end{array}\right]}^{-1}\left[\begin{array}{c}
I_{d}\\
0_{d\times(m-d)}
\end{array}\right]=\frac{r^{2}}{m}\,(g+g_{A}-g_{B}g_{C}^{-1}g_{B}^{\T})^{-1}\,.
\end{align*}
Since $g_{A}-g_{B}g_{C}^{-1}g_{B}^{\T}\succeq0$ due to  $g'\succeq0$,
it holds that $g_{0}:=\frac{m-d}{d}g+\frac{m}{d}(g_{A}-g_{B}g_{C}^{-1}g_{B}^{\T})$
on $\intk$ is PSD. Now, it suffices to check that the covariance
matrix above is equal to $\frac{r^{2}}{d}(g+g_{0})^{-1}$:
\[
\frac{d}{r^{2}}\,(g+g_{0})=\frac{d}{r^{2}}\Bpar{g+\frac{m-d}{d}\,g+\frac{m}{d}\,(g_{A}-g_{B}g_{C}^{-1}g_{B}^{\T})}\frac{m}{r^{2}}\,(g+g_{A}-g_{B}g_{C}^{-1}g_{B}^{\T})\,.\qedhere
\]
\end{proof}

\subsubsection{Direct product: SSC and SLTSC \label{proof:direct-ssc-sltsc}}

We show that if $g_{i}\in\mbb S_{++}^{d_{i}}$ is SC, then $g=\sum d_{i}\bar{g}_{i}$
is SSC.
\begin{proof}
[Proof of Lemma~\ref{lem:ssc-direct}] Note that $d_{i}g_{i}$ is
SSC for $i=1,\dots,m$. For $x\in\prod E_{i}$ and $h=(h_{1},\dots,h_{m})\in\R^{l}$
with $h_{i}\in\R^{d_{i}}$, we have 
\begin{align*}
 & \norm{g(x)^{-\half}\Dd g(x)[h]\,g(x)^{-\half}}_{F}^{2}\\
 & =\left\Vert \left[\begin{array}{ccc}
g_{1}(x_{1})^{-\half}\Dd g_{1}(x_{1})[h_{1}]\,g_{1}(x_{1})^{-\half}\\
 & \ddots\\
 &  & g_{m}(x_{m})^{-\half}\Dd g_{m}(x_{m})[h_{m}]\,g_{m}(x_{m})^{-\half}
\end{array}\right]\right\Vert _{F}^{2}\\
 & =\sum_{i}\norm{g_{i}(x_{i})^{-\half}\Dd g_{i}(x_{i})[h_{i}]\,g_{i}(x_{i})^{-\half}}_{F}^{2}\leq4\sum_{i}\norm{h_{i}}_{d_{i}g_{i}(x_{i})}^{2}=4\norm h_{g(x)}^{2}\,.\qedhere
\end{align*}
\end{proof}
Next, we show that if $g_{i}\in\mbb S_{++}^{d_{i}}$ is HSC, then
$g=\sum d_{i}\bar{g}_{i}$ is SLTSC.
\begin{proof}
[Proof of Lemma~\ref{lem:sltsc-direct}] For $h=(h_{1},\dots,h_{m})$
and any PSD matrix function $g'$, we have
\begin{align*}
\tr\bpar{(g'+g)^{-1}\Dd^{2}g[h^{\otimes2}]} & =\sum_{i}\tr\bpar{(g'+(g-d_{i}\bar{g}_{i})+d_{i}\bar{g}_{i})^{-1}\Dd^{2}(d_{i}\bar{g}_{i})[h^{\otimes2}]}\gtrsim-\sum_{i}\norm h_{d_{i}\bar{g}_{i}}^{2}=-\norm h_{g}^{2}\,,
\end{align*}
where we used Lemma~\ref{lem:hsc-to-sltsc} in the inequality.
\end{proof}

\subsubsection{Inverse images under non-linear mappings \label{proof:inverse-non-linear}}
\begin{proof}
[Proof of Lemma~\ref{lem:compatible}] Since $\acal$ is $(R(G),\beta),\gamma)$-compatible
with $\Gamma$, the first two claims immediately follow from \citet[Proposition 5.1.7]{nesterov1994interior}.
Let $x\in G^{+}$ and $h\in\Rd$. Define the following notations:
\begin{align*}
u=\Dd\acal(x)[h], & \quad v=\Dd^{2}\acal(x)[h^{\otimes2}],\quad w=\Dd^{3}\acal(x)[h^{\otimes3}],\quad z=\Dd^{4}\acal(x)[h^{\otimes4}],\\
s=\sqrt{\Dd F(y)[v]}, & \quad\rho=\sqrt{\Dd^{2}\Pi(x)[h^{\otimes2}]},\quad r=\sqrt{\Dd^{2}F(y)[u^{\otimes2}]}\,.
\end{align*}
From direct computations, we have 
\begin{align*}
\Dd^{2}\Psi(x)[h^{\otimes2}] & =\Dd F(y)[v]+\Dd^{2}F(y)[u^{\otimes2}]+\delta^{2}\Dd^{2}\Pi(x)[h^{\otimes2}]=s^{2}+r^{2}+\delta^{2}\rho^{2}\,,\\
\Dd^{3}\Psi(x)[h^{\otimes3}] & =\Dd F(y)[w]+3\Dd^{2}F(y)[u,v]+\Dd^{3}F(y)[u^{\otimes3}]+\delta^{2}\Dd^{3}\Pi(x)[h^{\otimes3}]\,,\\
\Dd^{4}\Psi(x)[h^{\otimes4}] & =\Dd^{2}F(y)[w,u]+\Dd F(y)[z]+3\Dd^{3}F(y)[u,u,v]+3\Dd^{2}F(y)[v^{\otimes2}]\\
 & \qquad+3\Dd^{2}F(y)[u,w]+\Dd^{4}F(y)[u^{\otimes4}]+3\Dd^{3}F(y)[u,u,v]+\delta^{2}\Dd^{4}\Pi(x)[h^{\otimes4}]\\
 & =\Dd F(y)[z]+3\Dd^{2}F(y)[v^{\otimes2}]+4\Dd^{2}F(y)[u,w]\\
 & \qquad+6\Dd^{3}F(y)[u,u,v]+\Dd^{4}F(y)[u^{\otimes4}]+\delta^{2}\Dd^{4}\Pi(x)[h^{\otimes4}]\,.
\end{align*}
HSC of $F$ and $\Pi$ implies that 
\[
|\Dd^{4}\Pi(x)[h^{\otimes4}]|\leq6\rho^{4}\,,\qquad\text{and}\qquad|\Dd^{4}F(y)[u^{\otimes4}]|\leq6r^{4}\,.
\]
Since $\acal$ is $(K,\beta,\gamma)$-compatible and $K\subset R(G)$,
Lemma~\ref{lem:extension-compatibility}-1 implies concavity of $\acal$
with respect to $R(G)$, which means $-v\geq_{R(G)}0$. Then, \citet[Corollary 2.3.1]{nesterov1994interior}
ensures 
\[
\sqrt{\Dd^{2}F(y)[v^{\otimes2}]}\leq\Dd F(y)[v]=s^{2}\,.
\]
Hence, $|3\Dd^{2}F(y)[v,v]|\leq3(\Dd F(y)[v])^{2}=3s^{4}$, and self-concordance
of $F$ results in
\[
|6\Dd^{3}F(y)[u,u,v]|\leq12r^{2}\sqrt{\Dd^{2}F(y)[v,v]}\leq12r^{2}s^{2}\,.
\]
Since $\{h:h^{\T}\Pi(x)h\leq1\}$ is contained in $\Gamma\cap(2x-\Gamma)$,
compatibility of $\acal$ leads to 
\[
\beta\Dd^{2}\acal(x)\Bbrack{\Bpar{\frac{h}{\norm h_{\Pi(x)}}}^{\otimes2}}\leq_{K}\Dd^{3}\acal(x)\Bbrack{\Bpar{\frac{h}{\norm h_{\Pi(x)}}}^{\otimes3}}\leq_{K}-\beta\Dd^{2}\acal(x)\Bbrack{\Bpar{\frac{h}{\norm h_{\Pi(x)}}}^{\otimes2}}\,,
\]
and thus $\beta\rho v\leq_{K}w\leq_{K}-\beta\rho v$. As $K$ is a
ray, $\Dd^{2}F(y)[w,w]\leq\beta^{2}\rho^{2}\Dd^{2}F(y)[v,v]\leq\beta^{2}\rho^{2}s^{4}$.
Thus,
\[
|4\Dd^{2}F(y)[u,w]|\leq4\sqrt{\Dd^{2}F(y)[u,u]}\sqrt{\Dd^{2}F(y)[w,w]}\leq4r\beta\rho s^{2}\,.
\]
Lastly, since $\gamma v\rho^{2}\leq_{K}z\leq_{K}-\gamma v\rho^{2}$
and $K$ is a ray, we have 
\[
|\Dd F(y)[z]|\leq3\gamma\rho^{2}|\Dd F(y)[v]|=3\gamma\rho^{2}s^{2}\,.
\]
Putting these together,
\begin{align*}
 & \Abs{\Dd^{4}\Psi(x)[h^{\otimes4}]}\leq3\gamma\rho^{2}s^{2}+4r\beta\rho s^{2}+12r^{2}s^{2}+3s^{4}+6\delta^{2}\rho^{4}+6r^{4}\\
\leq & 6(\delta^{2}\rho^{4}+r^{4}+s^{4}+r^{2}s^{2}+\delta\rho^{2}s^{2}+\delta r\rho s^{2})\leq6\bpar{(\delta\rho)^{4}+r^{4}+s^{4}+r^{2}s^{2}+(\delta\rho)^{2}s^{2}+r^{2}s^{2}+(\delta\rho)^{2}s^{2}}\\
\leq & 6\bpar{(\delta\rho)^{2}+r^{2}+s^{2}}^{2}=6\bpar{\Dd^{2}\Psi(x)[h,h]}^{2}\,.\qedhere
\end{align*}
\end{proof}

\subsection{Main constraints and epigraphs ($\S$\ref{sec:handbook-barrier})}

\subsubsection{Linear constraints: strong self-concordance and symmetry \label{proof:linear-SSC-symm}}

We relate SSC and symmetry to well-studied terms in the field of optimization,
such as $\max_{i}\frac{[\sigma(\sqrt{D_{x}}A_{x})]_{i}}{[D_{x}]_{ii}}$
and $\norm{D_{x,h}'}_{D_{x}^{-1}}^{2}$.
\begin{proof}
[Proof of Lemma~\ref{lem:helper4Diagonal}] Let us write $g(x)=A_{x}^{\T}D_{x}A_{x}=A^{\T}V_{x}A$
for $V_{x}:=S_{x}^{-1}D_{x}S_{x}^{-1}$. By Claim~\ref{claim:diffLogBarrier},
\begin{align}
\Dd g(x)[h] & =A^{\T}(-2S_{x}^{-1}S_{x,h}S_{x}^{-1}D_{x}+S_{x}^{-1}\Dd D_{x}[h]\,S_{x}^{-1})A=A^{\T}V_{x}^{1/2}\overline{D}_{x}V_{x}^{1/2}A\,,\label{eq:Dgh}
\end{align}
where $\overline{D}_{x}:=-2S_{x,h}+D_{x}^{-1}\Dd D_{x}[h]$. Using
this,
\begin{align*}
\norm{(g'+g)^{-\half}\Dd g[h]\,(g'+g)^{-\half}}_{F}^{2} & =\tr\bpar{(g'+g)^{-1}A^{\T}V_{x}^{1/2}\overline{D}_{x}\underbrace{V_{x}^{1/2}A(g'+g)^{-1}A^{\T}V_{x}^{1/2}}_{=:P_{x}'}\overline{D}_{x}V_{x}^{1/2}A}\\
 & =\tr(P_{x}'\overline{D}_{x}P_{x}'\overline{D}_{x})\,.
\end{align*}
By Lemma~\ref{lem:matrix-projection}, we have $P_{x}'\preceq P_{x}=P(V_{x}^{1/2}A)=P(D_{x}^{1/2}A_{x})$,
and thus 
\begin{align*}
\tr(P_{x}'\overline{D}_{x}P_{x}'\overline{D}_{x}) & \leq\tr(P_{x}\overline{D}_{x}P_{x}\overline{D}_{x})\underset{\text{(i)}}{=}\diag(\overline{D}_{x})^{\T}P_{x}^{(2)}\,\diag(\overline{D}_{x})\underset{\text{(ii)}}{\leq}\diag(\overline{D}_{x})^{\T}\Sigma_{x}\,\diag(\overline{D}_{x})\\
 & \underset{\text{(iii)}}{\leq}4\sum_{i=1}^{m}[\sigma(D_{x}^{1/2}A_{x})]_{i}\,\bpar{(A_{x}h)_{i}^{2}+(D_{x}^{-1}\Dd D_{x}[h])_{i}^{2}}\\
 & \leq4\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}\cdot\sum_{i=1}^{m}[D_{x}]_{ii}\,\bpar{(A_{x}h)_{i}^{2}+(D_{x}^{-1}\Dd D_{x}[h])_{i}^{2}}\\
 & \underset{\text{(iv)}}{=}4\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}\cdot\bpar{\norm h_{g(x)}^{2}+\sum_{i=1}^{m}[D_{x}^{-1}]_{ii}(\Dd D_{x}[h])_{i}^{2}}\,,
\end{align*}
where (i) holds due to $x^{\T}(A\hada B)y=\tr\bpar{\Diag(x)A\Diag(y)B^{\T}}$
(Lemma~\ref{lem:Hadamard}), (ii) follows from $P_{x}^{(2)}\preceq\Sigma_{x}$
(Claim~\ref{claim:schurProjection})\footnote{Even though this lemma is proven for leverage scores, the proof there
can be extended to any orthogonal projection matrices.}, (iii) uses $(a+b)^{2}\leq2\Par{a^{2}+b^{2}}$ for $a,b\in\R$ and
$\Sigma_{x}=\Diag(P_{x})=\sigma(D_{x}^{1/2}A_{x})$, and (iv) holds
due to $\sum_{i=1}^{m}[D_{x}]_{ii}\,(A_{x}h)_{i}^{2}=h^{\T}A_{x}^{\T}D_{x}A_{x}h=h^{\T}g(x)h$.

As for the second claim,
\begin{align*}
 & \max_{h:\norm h_{g(x)}=1}\norm{A_{x}h}_{\infty}=\max_{h}\max_{i\in[m]}\Abs{\frac{a_{i}^{\T}h}{s_{i}}}=\max_{i\in[m]}\max_{u:\norm u_{2}=1}\Abs{\frac{a_{i}^{\T}g(x)^{-1/2}u}{s_{i}}}\\
= & \max_{i\in[m]}\left\Vert g(x)^{-1/2}\frac{a_{i}}{s_{i}}\right\Vert _{2}=\max_{i\in[m]}\sqrt{\frac{1}{s_{i}^{2}}a_{i}^{\T}g(x)^{-1}a_{i}}=\sqrt{\max_{i\in[m]}e_{i}^{\T}A_{x}g(x)^{-1}A_{x}^{\T}e_{i}}=\sqrt{\max_{i\in[m]}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}}\,.
\end{align*}

As for the last claim, for $h\in\Rd$ such that $\norm{A_{x}h}_{\infty}\leq1$
(i.e., $h\in K\cap(2x-K)$ for $K=\{Ax\geq b\}$ due to Lemma~\ref{lem:symmforPolytope})
we have
\begin{align*}
h^{\T}g(x)h & =h^{\T}A_{x}^{\T}D_{x}A_{x}h=\sum_{i=1}^{m}(D_{x})_{ii}(A_{x}h)_{i}^{2}\leq\norm{A_{x}h}_{\infty}^{2}\sum_{i=1}^{m}(D_{x})_{ii}\leq\tr(D_{x})\,.\qedhere
\end{align*}
\end{proof}
Now we establish SSC and compute the symmetry parameters of metrics
of the form $A_{x}^{\T}D_{x}A_{x}$:
\begin{proof}
[Proof of Lemma~\ref{lem:paramsBarrier}] \textbf{Logarithmic barrier}:
To show that $g$ is SSC along $\rowspace(A)$, consider a self-concordant
matrix $g(y)=S_{y}^{-2}=-\nabla_{y}^{2}(\sum_{i=1}^{m}\log y_{i})$
defined on $\{y\in\R^{m}:y\geq0\}$. By putting $D_{x}=I_{m}$ and
$A_{x}=S_{x}^{-1}$ into Lemma~\ref{lem:helper4Diagonal}-1, since
$\sigma(A_{x})\leq1$
\[
\norm{g(x)^{-\half}\Dd g(x)[h]\,g(x)^{-\half}}_{F}\leq2\Bpar{\max_{i\in[m]}\sigma(A_{x})_{i}}^{1/2}\,\norm h_{g(x)}\leq2\norm h_{g(x)}\,.
\]
Through the linear map $Tx=Ax-b=y$, we recover $g(x)=\hess\phi_{\log}(x)=A^{\T}S_{y}^{-2}A=A_{x}^{\T}A_{x}$,
which is SSC along $\rowspace(A)$ by Lemma~\ref{lem:linear-trans-matrix}.
For the $\onu$-symmetry, the first part (i.e., $\dcal_{g}^{1}(x)\subset K\cap(2x-K)$)
follows from Lemma~\ref{lem:symmetricLeftpart}. The second part
is immediate from $\onu=\tr(I_{m})=m$ and Lemma~\ref{lem:helper4Diagonal}-3.

\textbf{Approximate volumetric barrier}: For $D_{x}=\Sigma_{x}=\Sigma(A_{x})$,
by Lemma~\ref{lem:usefulFactLewis}-1 and 3 with $p=2$,
\begin{align*}
\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}} & \leq2\sqrt{m}\,,\quad\text{and}\quad\sum_{i=1}^{m}[D_{x}^{-1}]_{ii}\,(\Dd D_{x}[h])_{i}^{2}=\norm{\Sigma_{x}^{-1}\diag(\Dd\Sigma_{x}[h])}_{\Sigma_{x}}^{2}\leq4\norm h_{g(x)}^{2}\,.
\end{align*}
Using Lemma~\ref{lem:helper4Diagonal}-1,
\begin{align*}
\norm{g(x)^{-\half}\Dd g(x)[h]\,g(x)^{-\half}}_{F}^{2} & \leq4\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}\,\bpar{\norm h_{g(x)}^{2}+\sum_{i=1}^{m}[D_{x}^{-1}]_{ii}(\Dd D_{x}[h])_{i}^{2}}\leq40\sqrt{m}\norm h_{g(x)}^{2}\,.
\end{align*}
For the $\onu$-symmetry, $\norm{A_{x}(y-x)}_{\infty}^{2}\leq\max_{i\in[m]}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}\leq2m^{1/2}$
for $y\in\dcal_{g}^{1}(x)$ by Lemma~\ref{lem:helper4Diagonal}-2.
Also, Lemma~\ref{lem:helper4Diagonal}-3 implies that $y$ with $\norm{A_{x}(y-x)}_{\infty}\leq1$
is contained in $\dcal_{g}^{\sqrt{\tr(D_{x})}}(x)$, where $\tr(D_{x})=\tr(P_{x})\leq d$.
Therefore, $\tilde{g}(x):=40\sqrt{m}g(x)=40\sqrt{m}A_{x}^{\T}\Sigma_{x}A_{x}$
is SSC with the symmetry parameter $\onu=\mc O(\sqrt{m}d)$.

\textbf{Vaidya metric}: Consider the metric without scaling: $g(x):=A_{x}^{\T}D_{x}A_{x}$
with $D_{x}=\Sigma_{x}+\frac{d}{m}I_{m}$. Then, using \citet[(4.5)]{anstreicher1997volumetric}
in (i) below
\begin{align}
\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}} & \underset{\text{Lemma \ref{lem:helper4Diagonal}-2}}{=}\Bpar{\max_{h\in\Rd}\frac{\norm{A_{x}h}_{\infty}}{\norm h_{g(x)}}}^{2}\underset{\text{(i)}}{\leq}\sqrt{\frac{m}{d}}\,,\label{eq:28-1}\\
\sum_{i=1}^{m}[D_{x}^{-1}]_{ii}\,(\Dd D_{x}[h])_{i}^{2} & \underset{\text{(ii)}}{\leq}\sum_{i=1}^{m}[\Sigma_{x}^{-1}]_{ii}(\Dd\Sigma_{x}[h])_{i}^{2}\underset{\text{Lemma \ref{lem:usefulFactLewis}-3}}{\leq}4h^{\T}A_{x}^{\T}\Sigma_{x}A_{x}h\leq4\norm h_{g(x)}^{2}\,.\nonumber 
\end{align}
Putting these back to Lemma~\ref{lem:helper4Diagonal}-1,
\begin{align*}
\norm{g(x)^{-\half}\Dd g(x)[h]\,g(x)^{-\half}}_{F}^{2} & \leq4\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}\,\bpar{\norm h_{g(x)}^{2}+\sum_{i=1}^{m}[D_{x}^{-1}]_{ii}(\Dd D_{x}[h])_{i}^{2}}\leq20\sqrt{\frac{m}{d}}\norm h_{g(x)}^{2}\,.
\end{align*}
Thus, $\tilde{g}(x):=22\sqrt{\frac{m}{d}}g(x)=22\sqrt{\frac{m}{d}}A_{x}^{\T}\bpar{\Sigma_{x}+\frac{d}{m}I_{m}}A_{x}$
is SSC. For the $\onu$-symmetry, Lemma~\ref{lem:helper4Diagonal}-2
implies that for $y\in\dcal_{g}^{1}(x)$,
\[
\norm{A_{x}(y-x)}_{\infty}^{2}\leq\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}\underset{\text{\eqref{eq:28-1}}}{\leq}\sqrt{\frac{m}{d}}\,.
\]
Also, Lemma~\ref{lem:helper4Diagonal}-3 implies that $y$ with $\norm{A_{x}(y-x)}_{\infty}\leq1$
is contained in $\dcal_{g}^{\sqrt{\tr(D_{x})}}(x)$, where
\[
\tr(D_{x})=\tr\bpar{\Sigma_{x}+\frac{d}{m}I_{m}}=\tr(\Sigma_{x})+d\leq2d\,.
\]
Therefore, $\tilde{g}(x)$ satisfies $\dcal_{\tilde{g}}^{1}(x)\subset K\cap(2x-K)\subset\dcal_{\tilde{g}}^{\sqrt{44(md)^{1/2}}}(x)$,
so $\tilde{g}$ is $\mc O(\sqrt{md})$-symmetric.

\textbf{Lewis-weight metric}: Consider the unscaled version first:
$g(x)=A_{x}^{\T}W_{x}A_{x}$. By Lemma~\ref{lem:helper4Diagonal}-1
\begin{align*}
\norm{g(x)^{-\half}\Dd g(x)[h]\,g(x)^{-\half}}_{F}^{2} & \leq4\max_{i}\frac{[\sigma(W_{x}^{1/2}A_{x})]_{i}}{[W_{x}]_{ii}}\,\bpar{\norm h_{g(x)}^{2}+\sum_{i=1}^{m}[W_{x}^{-1}]_{ii}(\Dd W_{x}[h])_{i}^{2}}\\
 & \underset{\text{(i)}}{\leq}8m^{\frac{2}{p+2}}\bpar{\norm h_{g(x)}^{2}+p^{2}\,\norm h_{g(x)}^{2}}\leq\bpar{8m^{\frac{2}{p+2}}(1+p^{2})}\,\norm h_{g(x)}^{2}\,,
\end{align*}
where in (i) we used Lemma~\ref{lem:usefulFactLewis}-1 and 3.

For the first part of the $\onu$-symmetry, Lemma~\ref{lem:helper4Diagonal}-2
implies that
\[
\max_{h:\norm h_{g(x)}=1}\norm{A_{x}h}_{\infty}=\sqrt{\max_{i}\frac{[\sigma(W_{x}^{1/2}A_{x})]_{i}}{[W_{x}]_{ii}}}\leq\sqrt{2m^{\frac{2}{p+2}}}\,,
\]
 and Lemma~\ref{lem:helper4Diagonal}-3 leads to $K\cap(2x-K)\subset\dcal_{g}^{\sqrt{d}}(x)$
due to
\[
\tr(W_{x})=\tr\bpar{W_{x}^{\half-\frac{1}{p}}A_{x}(A_{x}^{\T}W_{x}^{1-\frac{2}{p}}A_{x})^{-1}A_{x}^{\T}W_{x}^{\half-\frac{1}{p}}}=\tr\bpar{A_{x}^{\T}W_{x}^{1-\frac{2}{p}}A_{x}(A_{x}^{\T}W_{x}^{1-\frac{2}{p}}A_{x})^{-1}}=d\,.
\]
Therefore, $16p^{2}m^{\frac{2}{p+2}}A_{x}^{\T}W_{x}A_{x}$ is SSC
with $\mc O\bpar{dm^{\frac{2}{p+2}}}$-symmetry by Lemma~\ref{lem:symmforPolytope}.
By setting $p=\mc O(\log m)$, the claim follows.
\end{proof}

\subsubsection{Linear constraints: strongly lower trace self-concordance of Vaidya
\label{proof:linear-vaidya-SLTSC}}

Let $\theta_{1}(x):=A_{x}^{\T}\Sigma_{x}A_{x}$, $\theta_{2}(x):=A_{x}^{\T}A_{x}$,
and $\Gamma_{x}:=\Diag\bpar{A_{x}g(x)^{-1}A_{x}^{\T}}$. Recall $g=g_{1}+g_{2}$
for a PSD matrix function $g_{1}$ and the Vaidya metric $g_{2}$.
\begin{lem}
\label{lem:HybridGammaNorm} $\norm{\Gamma_{x}}_{\infty}\leq\frac{1}{44}$.
\end{lem}

\begin{proof}
For $\og_{2}:=\theta_{1}+\frac{d}{m}\theta_{2}=\frac{1}{44}\sqrt{\frac{d}{m}}g_{2}$,
it follows from $g^{-1}\preceq g_{2}^{-1}=\frac{1}{44}\sqrt{\frac{d}{m}}\og_{2}^{-1}$
that
\begin{align*}
44\norm{\Gamma_{x}}_{\infty} & \leq4\sqrt{\frac{d}{m}}\norm{\Diag(A_{x}\og_{2}^{-1}A_{x}^{\T})}_{\infty}=\sqrt{\frac{d}{m}}\max_{i\in[m]}\frac{\bbrack{\sigma\bpar{\sqrt{\Sigma_{x}+\frac{d}{m}I_{m}}A_{x}}}_{i}}{\bbrack{\Sigma_{x}+\frac{d}{m}I_{m}}_{ii}}\underset{\text{\eqref{eq:28-1}}}{\leq}1\,.\qedhere
\end{align*}
\end{proof}
Now we show SLTSC of the Vaidya metric:
\begin{proof}
[Proof of Lemma~\ref{lem:vaidya-SLTSC}]  As $\Dd^{2}\theta_{2}(x)[h,h]\succeq0$
by Claim~\ref{claim:diffLogBarrier}, we have 
\[
\tr\bpar{g^{-1}\Dd^{2}\theta_{2}(x)[h,h]}=\tr\bpar{g^{-\half}\Dd^{2}\theta_{2}(x)[h,h]g^{-\half}}\geq0\,.
\]
As for $\theta_{1}$, by Lemma~\ref{lem:calculusLeverage}-6 $\Dd^{2}\theta_{1}[h,h]\succeq-16A_{x}^{\T}\Diag(S_{x,h}P_{x}S_{x,h}P_{x})A_{x}-6A_{x}^{\T}\Diag(P_{x}S_{x,h}^{2}P_{x})A_{x}$,
so
\[
\tr\bpar{g^{-1}\Dd^{2}\theta_{1}(x)[h,h]}\geq-16\tr(\Gamma_{x}S_{x,h}P_{x}S_{x,h}P_{x})-6\tr(\Gamma_{x}P_{x}S_{x,h}^{2}P_{x})\,.
\]
We first note that $\tr(S_{x,h}P_{x}S_{x,h})=s_{x,h}^{\T}(P_{x}\circ I)s_{x,h}=s_{x,h}^{\T}\Sigma_{x}s_{x,h}=\norm h_{\theta_{1}}^{2}$.
Using this,
\begin{align*}
\tr(\Gamma_{x}S_{x,h}P_{x}S_{x,h}P_{x}) & =\tr(\Gamma_{x}^{1/2}S_{x,h}P_{x}\cdot S_{x,h}P_{x}\Gamma_{x}^{1/2})\leq\sqrt{\tr(\Gamma_{x}^{\half}S_{x,h}P_{x}^{2}S_{x,h}\Gamma_{x}^{\half})\,\tr(\Gamma_{x}^{\half}P_{x}S_{x,h}^{2}P_{x}\Gamma_{x}^{\half})}\\
 & =\sqrt{\tr(P_{x}S_{x,h}\Gamma_{x}S_{x,h}P_{x})}\sqrt{\tr(S_{x,h}P_{x}\Gamma_{x}P_{x}S_{x,h})}=\norm{\Gamma_{x}}_{\infty}\norm h_{\theta_{1}}^{2}\,,\\
\tr(\Gamma_{x}P_{x}S_{x,h}^{2}P_{x}) & =\tr(S_{x,h}P_{x}\Gamma_{x}P_{x}S_{x,h})\leq\norm{\Gamma_{x}}_{\infty}\tr(S_{x,h}P_{x}S_{x,h})\underset{\text{(i)}}{=}\norm{\Gamma_{x}}_{\infty}\norm h_{\theta_{1}}^{2}\,.
\end{align*}
Putting these together and using Lemma~\ref{lem:HybridGammaNorm},
\[
\tr\bpar{g^{-1}\Dd^{2}\theta_{1}(x)[h,h]}\geq-22\norm{\Gamma_{x}}_{\infty}\norm h_{\theta_{1}}^{2}\geq-\half\,\norm h_{\theta_{1}}^{2}\,,
\]
and it follows from $g_{2}=44\sqrt{\frac{m}{d}}\Par{\theta_{1}+\frac{d}{m}\theta_{2}}$
that $\tr\bpar{g^{-1}\Dd^{2}g_{2}(x)[h,h]}\geq-\half\,\norm h_{g_{2}}^{2}$.
\end{proof}

\subsubsection{Linear constraints: strongly lower trace self-concordance of Lewis-weight
\label{proof:linear-Lewis-SLTSC}}

For $\theta(x):=A_{x}^{\T}W_{x}A_{x}$ (i.e., the unscaled version
of $g_{2}$), we write $g_{2}=c\cdot\theta$ for a constant $c$,
which will be set to $c_{1}(\log m)^{c_{2}}\sqrt{d}$ for some constants
$c_{1},c_{2}>0$ later. Going forward, $P_{x}$ indicates the projection
matrix of $W_{x}^{\nicefrac{1}{2}-\nicefrac{1}{p}}A_{x}$ (i.e., $P_{x}=P(W_{x}^{\nicefrac{1}{2}-\nicefrac{1}{p}}A_{x})$).
\begin{lem}
\label{lem:GammaNormLSMetric}$\norm{\Gamma_{x}}_{\infty}\leq2c^{-1}m^{\frac{2}{p+2}}$.
\end{lem}

\begin{proof}
Note that $0\preceq\Gamma_{x}=\Diag(A_{x}g^{-1}A_{x}^{\T})\preceq c^{-1}\Diag(A_{x}\theta^{-1}A_{x}^{\T})$.
By Lemma~\ref{lem:usefulFactLewis}-1,
\[
\norm{\Diag(A_{x}\theta^{-1}A_{x}^{\T})}_{\infty}=\max_{i\in[m]}\frac{\bbrack{\sigma\bpar{W_{x}^{1/2}A_{x}}}_{i}}{\bbrack{W_{x}}_{ii}}\leq2m^{\frac{2}{p+2}}\,.\qedhere
\]
\end{proof}
Now we show SLTSC of the Lewis-weight metric:
\begin{proof}
[Proof of Lemma~\ref{lem:Lw-SLTSC}] From \eqref{eq:LW-second-derv},
$\Dd^{2}\theta[h,h]\succeq-4A_{x}^{\T}W_{x,h}'S_{x,h}A_{x}+A_{x}^{\T}W_{x,h}''A_{x}$.
Thus,
\[
\tr(g^{-1}\Dd^{2}\theta[h,h])\geq\tr\bpar{\Gamma_{x}(W_{x,h}''-4W_{x,h}'S_{x,h})}=-4\tr(\Gamma_{x}W_{x,h}'S_{x,h})+\tr(\Gamma_{x}W_{x,h}'')\,.
\]
As for the first term, $\tr(\Gamma_{x}W_{x,h}'S_{x,h})\leq p\,\norm{\Gamma_{x}}_{\infty}\norm h_{\theta}^{2}$
follows from \eqref{eq:trSW} with $\Gamma_{x}$ replacing $s_{x,h}^{2}$.

As for the second term $\tr(\Gamma_{x}W_{x,h}'')$ (i.e., \eqref{eq:trGamma}
with $\Gamma=\Gamma_{x}$), each term there is of the form $\tr(\Gamma_{x}\Diag(v))$
for $v\in\R^{m}$, which can be bounded as follows:
\begin{align*}
\big|\tr\bpar{\Gamma_{x}\Diag(v)}\big| & =|\tr(\Gamma_{x}W_{x}^{\half}W_{x}^{-\half}\Diag(v))|\leq\sqrt{\tr(W_{x}^{\half}\Gamma_{x}^{2}W_{x}^{\half})}\sqrt{\tr\bpar{\Diag(v)W_{x}^{-1}\Diag(v)}}\\
 & \leq\norm{\Gamma_{x}}_{\infty}\sqrt{\tr(W_{x})}\norm v_{W_{x}^{-1}}=\sqrt{d}\norm{\Gamma_{x}}_{\infty}\norm v_{W_{x}^{-1}}\,.
\end{align*}
Then, we obtain $|\tr(\Gamma_{x}W_{x,h}'')|\lesssim\sqrt{d}\norm{\Gamma_{x}}_{\infty}\norm h_{\theta}^{2}$
for $p=\O(\log m)$ by using this inequality together with the norm
bounds in Lemma~\ref{lem:second-deriv-Lewis}. 

Putting things together, we conclude that
\begin{align*}
\tr(g^{-1}\Dd^{2}\theta[h,h]) & \gtrsim-p\norm{\Gamma_{x}}_{\infty}\norm h_{\theta}^{2}-\sqrt{d}\norm{\Gamma_{x}}_{\infty}\norm h_{\theta}^{2}\gtrsim-c^{-1}\sqrt{d}\norm h_{\theta}^{2}\,,
\end{align*}
where the last line follows from Lemma~\ref{lem:GammaNormLSMetric}.
Therefore, there exists positive constants $d_{1}$ and $d_{2}$ such
that $\tr(g^{-1}\Dd^{2}\theta[h,h])\geq-c^{-1}d_{1}(\log m)^{d_{2}}\sqrt{d}\norm h_{\theta}^{2}$,
which implies
\[
\tr(g^{-1}\Dd^{2}g_{2}[h,h])\geq-c^{-1}d_{1}(\log m)^{d_{2}}\sqrt{d}\norm h_{g_{2}}^{2}\,.
\]
By taking $c=d_{1}(\log m)^{d_{2}}\sqrt{d}$, the metric $g_{2}=c\theta=d_{1}(\log m)^{d_{2}}\sqrt{d}A_{x}^{\T}W_{x}A_{x}$
is SLTSC. 
\end{proof}


\subsubsection{Linear constraints: strongly average self-concordance}

We proceed with a general form of the metric $g(x)=A_{x}^{\T}D_{x}A_{x}$
with a diagonal matrix $0\prec D_{x}\in\R^{m}$. Then we provide computational
lemmas used when proving SASC of barriers for the linear constraints.

We pick any $g':\intk\to\psd$ such that $\bar{g}:=g+g'\succ0$. By
affine invariance, we may assume $\bar{g}(x)=I$ and $x=0$. Note
that $g(x)\preceq I_{d}$, and $z$ equals $rh/\sqrt{d}$ for $h\sim\mc N(0,I_{d})$
in law. Applying Taylor's expansion to $\norm{z-x}_{g(z)}^{2}$ at
$z=x$ (as in the proof of Lemma~\ref{lem:hsc-to-sasc}), for some
$p_{z}\in[x,z]$
\begin{align*}
\big|\norm{z-x}_{g(z)}^{2}-\norm{z-x}_{g(x)}^{2}\big| & \leq\frac{r^{2}}{d}\,\Bpar{\frac{r}{\sqrt{d}}\underbrace{|\Dd g(x)[h^{\otimes3}]|}_{\eqqcolon\textsf{A}}+\frac{r^{2}}{2d}\underbrace{|\Dd^{2}g(p_{z})[h^{\otimes4}]|}_{\eqqcolon\textsf{B}}}\,.
\end{align*}
It suffices to show that $|\Dd g(x)[h^{\otimes3}]|=\mc O(d^{1/2})$
and $|\Dd^{2}g(p_{z})[h^{\otimes4}]|=\mc O(d)$ with high probability.

\paragraph{Term $\textsf{A}$.}

By \eqref{eq:Dgh}, we have $\Dd g(x)[h^{\otimes3}]=-2s_{x,h}^{\T}D_{x}S_{x,h}s_{x,h}+s_{x,h}^{\T}D_{x,h}'s_{x,h}$.
Let $a_{i}$ denote the $i$-th row of $A_{x}$ for $i\in[m]$, and
define two polynomials in $h$ as follows:
\begin{equation}
P_{1}(h):=s_{x,h}^{\T}D_{x}S_{x,h}s_{x,h}=\tr(D_{x}S_{x,h}^{3})=\sum_{i=1}^{m}d_{i}\,(a_{i}^{\T}h)^{3}\,,\quad\text{and}\quad P_{2}(h):=s_{x,h}^{\T}D_{x,h}'s_{x,h}\,.\label{eq:P12}
\end{equation}
By Lemma~\ref{lem:matrix-projection}, $D_{x}^{1/2}A_{x}A_{x}^{\T}D_{x}^{1/2}\preceq P(D_{x}^{1/2}A_{x})$
and thus
\begin{equation}
\max_{i\in[m]}\norm{a_{i}}^{2}=\norm{\Diag(A_{x}A_{x}^{\T})}_{\infty}\leq\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}\,.\label{eq:max-ai}
\end{equation}
By Lemma~\ref{lem:variance-1},
\begin{align}
\E[P_{1}(h)^{2}] & =\E\Bbrack{\Bbrace{\sum_{i=1}^{m}d_{i}(a_{i}\cdot h)^{3}}^{2}}=9\sum_{i,j=1}^{m}\norm{d_{i}^{1/3}a_{i}}^{2}\norm{d_{j}^{1/3}a_{j}}^{2}\inner{d_{i}^{1/3}a_{i},d_{j}^{1/3}a_{j}}+6\sum_{i,j}\inner{d_{i}^{1/3}a_{i},d_{j}^{1/3}a_{j}}^{3}\nonumber \\
 & =9\cdot1^{\T}\Diag(A_{x}A_{x}^{\T})\,D_{x}^{1/2}\underbrace{D_{x}^{1/2}A_{x}A_{x}^{\T}D_{x}^{1/2}}_{\preceq P(D_{x}^{1/2}A_{x})\preceq I_{m}}D_{x}^{1/2}\,\Diag(A_{x}A_{x}^{\T})\,1+6\sum_{i,j}d_{i}d_{j}(a_{i}\cdot a_{j})^{3}\nonumber \\
 & \lesssim\norm{\Diag(A_{x}A_{x}^{\T})}_{\infty}\,\tr\bpar{\Diag(A_{x}A_{x}^{\T})\,D_{x}}+\max_{i}\norm{a_{i}}^{2}\cdot\sum_{i,j}d_{i}d_{j}(a_{i}\cdot a_{j})^{2}\nonumber \\
 & =\max_{i}\norm{a_{i}}^{2}\,\tr(A_{x}^{\T}D_{x}A_{x})+\max_{i}\norm{a_{i}}^{2}\cdot\sum_{j}\tr(d_{j}a_{j}^{\T}A_{x}^{\T}D_{x}A_{x}a_{j})\nonumber \\
 & \underset{\text{(i)}}{\leq}2\max_{i}\norm{a_{i}}^{2}\,\tr(A_{x}^{\T}D_{x}A_{x})\leq2d\,\max_{i}\norm{a_{i}}^{2}\,,\label{eq:P1_bound}
\end{align}
where (i) follows from $A_{x}^{\T}D_{x}A_{x}\preceq I_{d}$ and $\sum_{j}\tr(d_{j}a_{j}^{\T}A_{x}^{\T}D_{x}A_{x}a_{j})\leq\sum_{j}\tr(d_{j}a_{j}^{\T}a_{j})=\tr(A_{x}^{\T}D_{x}A_{x})$.

Another polynomial $P_{2}(h)$ requires a different strategy for bounding
$\E[P_{2}(h)^{2}]$ for each barrier. This polynomial vanishes for
the log-barrier, while the Vaidya and Lewis-weight metrics requires
rather involved tasks for bounding $\E[P_{2}(h)^{2}]$.

\paragraph{Term $\textsf{B}$.}

Due to \eqref{eq:LW-fourth-moment} (with $W_{x}$ replaced by $D_{x}$),
$|\Dd^{2}g(p_{z})[h^{\otimes4}]|$ consists of three polynomials:
\begin{equation}
\bar{P}_{3}(h):=\tr(D_{p_{z}}S_{p_{z},h}^{4})\,,\quad\bar{P}_{4}(h)=\tr(D_{p_{z},h}'S_{p_{z},h}^{2})\,,\quad\bar{P}_{5}(h)=\tr(D_{p_{z},h}''S_{p_{z},h}^{2})\,.\label{eq:P345}
\end{equation}
For each $i=3,4,5$, we define $P_{i}(h)$ by $\bar{P}_{i}(h)$ with
$p_{z}$ replaced by $x$. For the log-barrier, $\bar{P}_{3}(h)$
only matters since $D_{(\cdot)}=I_{m}$. For the Vaidya metric, $\bar{P}_{4}(h)$
and $\bar{P}_{5}(h)$ can be bounded by multiples of $\bar{P}_{3}(h)$.
For the Lewis-weight metric, each $\bar{P}_{i}$ requires a different
procedure for bounding $\E[\bar{P}_{i}(h)^{2}]$. Moreover, we can
show $\bar{P}_{i}(h)\lesssim P_{i}(h)$ and
\begin{align}
\E[P_{3}(h)^{2}] & =\sum_{i,j\in[m]}\E[d_{i}d_{j}\,(a_{i}\cdot h)^{4}(a_{j}\cdot h)^{4}]\underset{\textup{CS}}{\leq}\sum_{i,j}d_{i}d_{j}\sqrt{\E[(a_{i}\cdot h)^{8}]}\sqrt{\E[(a_{j}\cdot h)^{8}]}\nonumber \\
 & \underset{\text{(i)}}{\lesssim}\Bpar{\sum_{i}d_{i}\norm{a_{i}}^{4}}^{2}\leq\max_{i}\norm{a_{i}}^{4}\,\Bpar{\sum_{i}d_{i}\norm{a_{i}}^{2}}^{2}\underset{\text{(ii)}}{\leq}d^{2}\max_{i}\norm{a_{i}}^{4}\,,\label{eq:P3_bound}
\end{align}
where we used $a_{i}\cdot h\sim\ncal(0,\norm{a_{i}}^{2})$ in (i),
and $\sum_{i}d_{i}\norm{a_{i}}^{2}=\tr(A_{x}^{\T}D_{x}A_{x})\leq\tr(I_{d})$
in (ii).

We now show SASC of the three barriers for linear constraints, using
this proof outline.

\paragraph{SASC of log-barriers.\label{proof:linear-SASC-log}}
\begin{proof}
[Proof of Lemma~\ref{lem:logBarrier-SASC}] Set $g(x)=A_{x}^{\T}A_{x}$
(with $D_{x}=I_{m}$). By \eqref{eq:max-ai}, 
\[
\max_{i\in[m]}\norm{a_{i}}^{2}\leq\max[\sigma(A_{x}^{1/2})]_{i}\leq1\,.
\]

As for the term $\msf A$, it suffices to bound $P_{1}(h)=\tr(S_{x,h}^{3})$.
Since $\E[P_{1}(h)^{2}]\lesssim d$ by \eqref{eq:P1_bound}, by Lemma~\ref{lem:conc-gaussian-poly}
with $t=(2e)^{3/2}\vee\bpar{\frac{2e}{3}\log\frac{2}{\veps}}^{3/2}$
and $r_{1}(\veps):=\veps(2\sqrt{60}t)^{-1}$, we have that for any
$r\leq r_{1}(\veps)$,
\[
\text{Event }B_{1}:\quad\P_{h}\Bpar{\frac{r}{\sqrt{d}}\,|P_{1}(h)|\geq\veps}\leq\veps\,.
\]

As for the term $\msf B$, recall $\P_{z}\bpar{\norm z\geq-r\cdot2\log\veps}\leq\veps$
and call this event $B_{2}$. We take $r_{2}(\veps)$ so that $1-2r_{2}\log\veps\leq1.1$,
which ensures $\norm z\leq2r$ conditioned on $B_{2}^{c}$ for $r\leq r_{2}$.
Next, we establish coordinate-wise closeness of $s_{x}$ at close-by
points. Let $x_{t}=x+\frac{tr}{\sqrt{d}}h$, and $s_{t}=Ax_{t}-b$.
For $t\in[0,1]$,
\begin{align*}
\left\Vert S_{0}^{-1}\,\frac{\D s_{t}}{\D t}\right\Vert _{\infty} & =\frac{r}{\sqrt{d}}\,\norm{A_{x}h}_{\infty}\leq\frac{r}{\sqrt{d}}\,\norm h_{g(x)}\leq\frac{r}{\sqrt{d}}\,\norm h=\norm z\,,
\end{align*}
and conditioned on $z\in B_{2}^{c}$ we know $\norm z\leq2r\log\frac{1}{\veps}\leq0.1$
for $r\leq r_{2}$. Hence,
\[
\max_{i\in[m]}\Big|\frac{s_{p,i}-s_{x,i}}{s_{x,i}}\Big|\leq\int_{0}^{1}\left\Vert S_{0}^{-1}\,\frac{\D s_{t}}{\D t}\right\Vert _{\infty}\,\D t\leq0.1\,,
\]
and thus $1.2\geq s_{x,i}/s_{p,i}\geq0.9$ for all $i\in[m]$ (i.e.,
$S_{p}^{-1}\preceq1.2S_{x}^{-1}$).

Using this, we bound $\bar{P}_{3}(h)=\tr(S_{p,h}^{4})$ by a multiple
of $P_{3}(h)=\tr(S_{x,h}^{4})$ as follows:
\begin{align*}
\tr(S_{p,h}^{4}) & =\tr(h^{\T}A^{\T}S_{p,h}S_{p}^{-2}S_{p,h}Ah)\leq2\tr(h^{\T}A^{\T}S_{p,h}S_{x}^{-2}S_{p,h}Ah)=2\tr(S_{x,h}^{2}S_{p,h}^{2})\leq4\tr(S_{x,h}^{4})\,.
\end{align*}
Hence, $\E[\bar{P}_{3}(h)^{2}]\lesssim\E[P_{3}(h)^{2}]\lesssim d^{2}$
by \eqref{eq:P3_bound}. Using Lemma~\ref{lem:conc-gaussian-poly}
with $t=(2e)^{2}\vee\bpar{\frac{2e}{4}\log\frac{2}{\veps}}^{3/2}$
and taking $r_{3}(\veps):=(\nicefrac{\veps}{c_{1}t})^{1/2}$, we obtain
\[
\text{Event }B_{3}:\quad\P\Bpar{\frac{r^{2}}{2d}\cdot16\bar{P}_{3}(h)\geq\veps}\geq\veps\,,
\]

Combining bounds on $\msf A$ and $\msf B$ conditioned on $\cap_{i}B_{i}^{c}$,
we have with probability at least $1-3\veps$
\[
\big|\norm{z-x}_{g(z)}^{2}-\norm{z-x}_{g(x)}^{2}\big|\leq2\veps\frac{r^{2}}{d}\quad\text{for any }r\leq\min_{i}r_{i}(\veps)\,.
\]
By replacing $3\veps\gets\veps$, the claim follows.
\end{proof}

\paragraph{SASC of Vaidya metric.\label{proof:linear-SASC-vaidya}}
\begin{proof}
[Proof of Lemma~\ref{lem:vaidya-SASC}] Set $g(x)=A_{x}^{\T}D_{x}A_{x}$
with $D_{x}=\sqrt{\frac{m}{d}}(\Sigma_{x}+\frac{d}{m}I_{m})$. By
\eqref{eq:max-ai} and \eqref{eq:28-1},
\[
\max_{i\in[m]}\norm{a_{i}}^{2}\leq\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}\leq1\,.
\]

\paragraph{Term $\textsf{A}$.}

As $\msf A$ consists of $P_{1}$ and $P_{2}$ (see \eqref{eq:P12}),
we show $\E[P_{i}(h)^{2}]\lesssim d$ for $i\in[2]$, which by Lemma~\ref{lem:conc-gaussian-poly}
implies $|\msf A|\leq\sqrt{d}$ w.h.p. As for $P_{1}(h)=\tr(D_{x}S_{x,h}^{3})$,
we have $\E[P_{1}(h)]^{2}\lesssim d$ from \eqref{eq:P1_bound}.

As for $P_{2}(h)=\tr(D_{x,h}'S_{x,h}^{2})$, our approach is similar
to \citet{chen2018fast}. By Lemma~\ref{lem:calculusLeverage}, 
\begin{align*}
|P_{2}(h)| & =\Big|\sqrt{\frac{m}{d}}\tr\Bpar{\Diag\bpar{(\Sigma_{x}-P_{x}^{(2)})\,s_{x,h}}\,S_{x,h}^{2}}\Big|\leq|P_{1}(h)|+|\tr(S_{x,h}^{3})|+\sqrt{\frac{m}{d}}\,\big|\tr\bpar{\Diag(P_{x}^{(2)}s_{x,h})\,S_{x,h}^{2}}\big|\,.
\end{align*}
Since we already established a high-probability bound for both $|P_{1}(h)|$
and $|\tr(S_{x,h}^{3})|$ (which is $P_{1}(h)$ for the log-barrier),
we focus on the third term in the RHS.

For $\sigma_{x}:=\diag\Par{P_{x}}$ and $\sigma_{x,i,j}:=(P_{x})_{ij}$,
it follows from $P_{x}^{2}=P_{x}$ that $\sigma_{x,i}=\sum_{j}\sigma_{x,i,j}^{2}$.
Hence,
\begin{align*}
\tr(\Sigma_{x}S_{x,h}^{3}) & =1^{\T}\Sigma_{x}s_{x,h}^{3}=\sum_{i}(s_{x,h})_{i}^{3}\sigma_{x,i}=\sum_{i,j=1}^{m}\sigma_{x,i,j}^{2}(s_{x,h})_{i}^{3}\,,\\
\tr\bpar{\Diag(P_{x}^{(2)}s_{x,h})\,S_{x,h}^{2}} & =\sum_{i,j=1}^{m}\sigma_{x,i,j}^{2}(s_{x,h})_{i}^{2}(s_{x,h})_{j}\underset{\text{symmetry}}{=}\sum_{i,j=1}^{m}\sigma_{x,i,j}^{2}(s_{x,h})_{j}^{2}(s_{x,h})_{i}\,.
\end{align*}
Combining these leads to
\begin{align*}
 & 2\,\tr(\Sigma_{x}S_{x,h}^{3})+6\,\tr\bpar{\Diag(P_{x}^{(2)}s_{x,h})S_{x,h}^{2}}\\
 & =\sum_{i,j=1}^{m}\sigma_{x,i,j}^{2}\bpar{(s_{x,h})_{i}^{3}+3(s_{x,h})_{i}^{2}(s_{x,h})_{j}+3(s_{x,h})_{i}(s_{x,h})_{j}^{2}+(s_{x,h})_{j}^{3}}=\sum_{i,j=1}^{m}\sigma_{x,i,j}^{2}\bpar{(s_{x,h})_{i}+(s_{x,h})_{j}}^{3}\,,
\end{align*}
so we handle $\sum_{i,j}\sigma_{x,i,j}^{2}\bpar{(s_{x,h})_{i}+(s_{x,h})_{j}}^{3}$
instead of $\tr\bpar{\Diag(P_{x}^{(2)}s_{x,h})S_{x,h}^{2}}$, as we
already bounded $\sqrt{\frac{m}{d}}\tr(\Sigma_{x}S_{x,h}^{3})=P_{1}(h)-\sqrt{\frac{d}{m}}\tr(S_{x,h}^{3})$.
Due to $(s_{x,h})_{i}+(s_{x,h})_{j}=(a_{i}+a_{j})^{\T}h$, for $c_{ij}:=a_{i}+a_{j}$
\begin{align}
 & \E\Bbrack{\Bbrace{\sum_{i,j\in[m]}\sigma_{x,i,j}^{2}\bpar{(s_{x,h})_{i}+(s_{x,h})_{j}}^{3}}^{2}}=\sum_{i,j,k,l}\sigma_{x,i,j}^{2}\sigma_{x,k,l}^{2}\E[(c_{ij}\cdot h)^{3}(c_{kl}\cdot h)^{3}]\nonumber \\
 & \underset{\text{Lemma \ref{lem:variance-1}}}{=}9\sum_{i,j,k,l}\sigma_{x,i,j}^{2}\sigma_{x,k,l}^{2}\norm{c_{ij}}^{2}\norm{c_{kl}}^{2}(c_{ij}\cdot c_{kl})+6\sum_{i,j,k,l}\sigma_{x,i,j}^{2}\sigma_{x,k,l}^{2}(c_{ij}\cdot c_{kl})^{3}\,.\label{eq:vaidya-cubic-expansion}
\end{align}

As for the first term in \eqref{eq:vaidya-cubic-expansion}, we denote
$z_{i}:=\sum_{j}\sigma_{x,i,j}^{2}\|c_{ij}\|^{2}$ and $Z:=\Diag\bpar{(z_{i})_{i\in[m]}}$.
Then,
\begin{align}
 & \sum_{i,j,k,l}\sigma_{x,i,j}^{2}\sigma_{x,k,l}^{2}\norm{c_{ij}}^{2}\norm{c_{kl}}^{2}(c_{ij}\cdot c_{kl})=\Bnorm{\sum_{ij}\sigma_{x,i,j}^{2}\norm{c_{ij}}^{2}c_{ij}}^{2}\nonumber \\
 & \leq2\Bnorm{\sum_{ij}\sigma_{x,i,j}^{2}\norm{c_{ij}}^{2}a_{i}}^{2}+2\Bnorm{\sum_{ij}\sigma_{x,i,j}^{2}\norm{c_{ij}}^{2}a_{j}}^{2}=4\Bnorm{\sum_{ij}\sigma_{x,i,j}^{2}\norm{c_{ij}}^{2}a_{i}}^{2}=\Bnorm{\sum_{i}z_{i}a_{i}}^{2}\nonumber \\
 & =1^{\T}ZA_{x}A_{x}^{\T}Z\,1\le1^{\T}ZD_{x}^{-1/2}P(D_{x}^{1/2}A_{x})\,D_{x}^{-1/2}Z\,1\le1^{\T}ZD_{x}^{-1}Z\,1\lesssim\sqrt{\frac{d}{m}}\,\tr(Z)\,,\label{eq:trZ-bound}
\end{align}
where the last inequality follows from $Z\precsim\Sigma_{x}\preceq\sqrt{\frac{d}{m}}D_{x}$
due to
\begin{align*}
z_{i} & \leq2\sum_{j}\sigma_{x,i,j}^{2}(\staticnorm{a_{i}}^{2}+\staticnorm{a_{j}}^{2})\lesssim\underbrace{\sigma_{x,i}\staticnorm{a_{i}}^{2}+\sum_{j}\sigma_{x,i,j}^{2}\staticnorm{a_{j}}^{2}}_{\eqqcolon\msf K_{i}}\leq\sigma_{x,i}\|a_{i}\|^{2}+\sigma_{x,i}\lesssim\sigma_{x,i}\,.
\end{align*}
Moreover, using the bound in $\msf K_{i}$ and $\sum_{i,j}\sigma_{x,i,j}^{2}\snorm{a_{j}}^{2}=\sum_{j}\sigma_{x,i}\norm{a_{i}}^{2}$
\[
\tr(Z)\lesssim\sum_{i}(\sigma_{x,i}\staticnorm{a_{i}}^{2}+\sum_{j}\sigma_{x,i,j}^{2}\staticnorm{a_{j}}^{2})=2\tr(A_{x}^{\T}\Sigma_{x}A_{x})\lesssim\sqrt{\frac{d}{m}}\,\tr(A_{x}^{\T}D_{x}A_{x})\leq d\sqrt{\frac{d}{m}}\,.
\]
Putting this into \eqref{eq:trZ-bound}, we obtain $\sum_{i,j,k,l}\sigma_{x,i,j}^{2}\sigma_{x,k,l}^{2}\norm{c_{ij}}^{2}\norm{c_{kl}}^{2}(c_{ij}\cdot c_{kl})\lesssim d^{2}/m$.

As for the second term in \eqref{eq:vaidya-cubic-expansion},
\begin{align*}
 & \sum_{i,j,k,l}\sigma_{x,i,j}^{2}\sigma_{x,k,l}^{2}\,(c_{ij}\cdot c_{kl})^{3}\lesssim\sum_{i,j,k,l}\sigma_{x,i,j}^{2}\sigma_{x,k,l}^{2}\,|c_{ij}\cdot c_{kl}|^{2}\\
 & \leq\sum_{i,j,k,l}\sigma_{x,i,j}^{2}\sigma_{x,k,l}^{2}\,(a_{i}\cdot a_{k}+a_{i}\cdot a_{l}+a_{j}\cdot a_{k}+a_{j}\cdot a_{l})^{2}\lesssim\sum_{i,j,k,l}\sigma_{x,i,j}^{2}\sigma_{x,k,l}^{2}\,(a_{i}\cdot a_{k})^{2}\\
 & =\sum_{ik}\sigma_{i}\sigma_{k}\,(a_{i}\cdot a_{k})^{2}=\sum_{k}\tr(\sigma_{k}a_{k}^{\T}A_{x}^{\T}\Sigma_{x}A_{x}a_{k})\leq\sqrt{\frac{d}{m}}\sum_{k}\tr(\sigma_{k}a_{k}^{\T}a_{k})\\
 & =\sqrt{\frac{d}{m}}\,\tr(A_{x}^{\T}\Sigma_{x}A_{x})\le\frac{d^{2}}{m}\,.
\end{align*}
This establish a high-probability bound of $\O(d^{2}/m)$ on \eqref{eq:vaidya-cubic-expansion},
implying an $\O(\sqrt{d})$-high-probability bound on $\sqrt{\frac{m}{d}}\big|\tr\bpar{\Diag(P_{x}^{(2)}s_{x,h})\,S_{x,h}^{2}}\big|$.

\paragraph{Term $\textsf{B}$.}

We show that $s_{x}$ and $s_{p_{z}}$ are close, and the same holds
for $\sigma_{x}$ and $\sigma_{p_{z}}$. For $s_{x}$, following the
argument for the log-barrier, we let $x_{t}:=x+th\frac{r}{\sqrt{d}}$
and $s_{t}:=Ax_{t}-b$. For $0\leq t\leq1$,
\begin{align*}
\Bnorm{S_{0}^{-1}\deriv{s_{t}}t}_{\infty} & =\frac{r}{\sqrt{d}}\,\norm{A_{x}h}_{\infty}\underset{\eqref{eq:28-1}}{\leq}\frac{r}{\sqrt{d}}\,\norm h_{A_{x}^{\T}D_{x}A_{x}}\leq\frac{r}{\sqrt{d}}\,\norm h=\norm z\,.
\end{align*}
Conditioned on the high-probability bound of $\norm z\leq2r\log\frac{1}{\veps}\leq0.1$
for any $r$ less than some $r(\veps)$,
\[
\max_{i\in[m]}\Big|\frac{s_{p,i}-s_{x,i}}{s_{x,i}}\Big|\leq\int_{0}^{1}\Bnorm{S_{0}^{-1}\deriv{s_{t}}t}_{\infty}\,\D t\leq0.1\,,
\]
and thus $1.2\geq s_{x,i}/s_{p,i}\geq0.9$ for all $i\in[m]$ (i.e.,
$S_{p}^{-1}\preceq1.2S_{x}^{-1}$). For $\sigma_{x}$, as we have
$\Sigma_{x}=\Diag(A_{x}(A_{x}^{\T}A_{x})^{-1}A_{x}^{\T})$, we have
the same closeness between $\sigma_{x,i}$ and $\sigma_{p,i}$ for
each $i\in[m]$.

Using the formulas in Lemma~\ref{lem:calculusLeverage},
\begin{align*}
|\Dd^{2}g(p)[h^{\otimes4}]| & \lesssim\sqrt{\frac{m}{d}}\,\Bigl(\tr\bpar{(\Sigma_{p}+\frac{d}{m}I_{m})S_{p,h}^{4}}+\underbrace{\tr(S_{p,h}^{2}P_{p}S_{p,h}P_{p}S_{p,h})}_{(*)}\\
 & \qquad\qquad\qquad+\tr(S_{p,h}^{2}P_{p}S_{p,h}^{2}P_{p})+\underbrace{\tr(S_{p,h}P_{p}S_{p,h}P_{p}S_{p,h}P_{p}S_{p,h})}_{\leq\tr(S_{p,h}^{2}P_{p}S_{p,h}^{2}P_{p})}\Bigr)\\
 & \underset{\text{(i)}}{\lesssim}\sqrt{\frac{m}{d}}\,\Bpar{\tr\Bpar{(\Sigma_{p}+\frac{d}{m}I_{m})S_{p,h}^{4}}+\tr(S_{p,h}^{2}\Sigma_{p}S_{p,h}^{2})+\underbrace{\tr(S_{p,h}^{2}P_{p}S_{p,h}^{2}P_{p})}_{\text{Use Lemma \ref{lem:Kronecker}}}}\\
 & \underset{\text{(ii)}}{\lesssim}\sqrt{\frac{m}{d}}\,\tr\Bpar{(\Sigma_{p}+\frac{d}{m}I_{m})S_{p,h}^{4}}\underset{\text{(iii)}}{\lesssim}\sqrt{\frac{m}{d}}\,\tr\Bpar{(\Sigma_{x}+\frac{d}{m}I_{m})S_{x,h}^{4}}=P_{3}(h)\,,
\end{align*}
where in (i) we used the Cauchy-Schwarz inequality on $(*)$:
\begin{align*}
 & \tr(S_{p,h}^{2}P_{p}S_{p,h}P_{p}S_{p,h})\leq\sqrt{\tr(S_{p,h}^{2}P_{p}^{2}S_{p,h}^{2})}\sqrt{\tr(S_{p,h}P_{p}S_{p,h}^{2}P_{p}S_{p,h})}\\
 & \underset{\text{AM-GM}}{\leq}\half\bpar{\tr(S_{p,h}^{2}P_{p}^{2}S_{p,h}^{2})+\tr(S_{p,h}P_{p}S_{p,h}^{2}P_{p}S_{p,h})}\leq\half\,\bpar{\tr(S_{p,h}^{2}\Sigma_{p}S_{p,h}^{2})+\tr(S_{p,h}^{2}P_{p}S_{p,h}^{2}P_{p})}\,,
\end{align*}
(ii) follows from $\tr(S_{p,h}^{2}P_{p}S_{p,h}^{2}P_{p})=s_{p,h}^{2}\cdot P_{p}^{(2)}s_{p,h}^{2}\preceq s_{p,h}^{2}\cdot\Sigma_{p}s_{p,h}^{2}\preceq s_{p,h}^{2}\cdot(\Sigma_{p}+\frac{d}{m}I_{m})s_{p,h}^{2}$,
and in (iii) we used coordinate-wise closeness of $s_{x}\leftrightarrow s_{p}$
and $\sigma_{x}\leftrightarrow\sigma_{p}$. By \eqref{eq:P3_bound},
$\E[P_{3}(h)^{2}]\lesssim d^{2}$, and an $\O(d)$-high-probability
bound on $|P_{3}(h)|$ (so on $\msf B$) follows from Lemma~\ref{lem:conc-gaussian-poly}.
\end{proof}

\paragraph{SASC of Lewis-weight. \label{proof:linear-SASC-Lw}}
\begin{proof}
[Proof of Lemma~\ref{lem:Lw-SASC}] Set $g(x)=\sqrt{d}A_{x}^{\T}W_{x}A_{x}$
(with $D_{x}=\sqrt{d}\,W_{x}$). By \eqref{eq:max-ai} and Lemma~\ref{lem:usefulFactLewis}-1,
\[
\max_{i\in[m]}\norm{a_{i}}^{2}\leq\max_{i}\frac{[\sigma(D_{x}^{1/2}A_{x})]_{i}}{[D_{x}]_{ii}}\leq\frac{2m^{\frac{2}{p+2}}}{\sqrt{d}}\lesssim\frac{1}{\sqrt{d}}\,.
\]

\paragraph{Term $\textsf{A}$.}

As done for the Vaidya metric, a high-probability bound on $\msf A$
requires $\E[P_{i}(h)^{2}]\lesssim d$ for $i=1,2$ (see \eqref{eq:P12}).
Note that $\E[P_{1}(h)^{2}]\lesssim\sqrt{d}$ by \eqref{eq:P1_bound}.

As for $P_{2}(h)=\sqrt{d}\,s_{x,h}^{\T}W_{x,h}'s_{x,h}$, we show
$\E[P_{2}(h)^{2}]\lesssim\sqrt{d}$. Due to $W_{x,h}'=-\Diag(W_{x}^{\half}N_{x}W_{x}^{\half}s_{x,h})$
(Lemma~\ref{lem:DWh}), $P_{2}(h)=-\sqrt{d}s_{x,h}^{\T}\Diag(W_{x}^{\half}N_{x}W_{x}^{\half}s_{x,h})s_{x,h}=-\sqrt{d}\tr\bpar{\Diag(W_{x}^{\half}N_{x}W_{x}^{\half}s_{x,h})S_{x,h}^{2}}$.
Thus,
\begin{align*}
P_{2}(h) & =\sqrt{d}\,\tr\bpar{\Diag(N_{x}W_{x}^{\half}s_{x,h})W_{x}^{\half}S_{x,h}^{2}}=\sqrt{d}\sum_{i=1}^{m}w_{i}^{1/2}(a_{i}\cdot h)^{2}(b_{i}\cdot h)\,,
\end{align*}
where $b_{i}$ is the $i$-th row of $B:=N_{x}W_{x}^{\half}A_{x}$
for $i=1,\dots,m$. By Lemma~\ref{lem:variance-2},
\begin{align*}
 & \E\Bbrack{\Bbrace{\sum_{i=1}^{m}w_{i}^{1/2}(a_{i}\cdot h)^{2}(b_{i}\cdot h)}^{2}}\\
 & =\sum_{i,j\in[m]}w_{i}^{1/2}w_{j}^{1/2}\|a_{i}\|^{2}\|a_{j}\|^{2}(b_{i}\cdot b_{j})\\
 & \quad+4\sum_{i,j}w_{i}^{1/2}w_{j}^{1/2}(a_{i}\cdot a_{j})(a_{i}\cdot b_{i})(a_{j}\cdot b_{j})+4\sum_{i,j}w_{i}^{1/2}w_{j}^{1/2}\|a_{i}\|^{2}(b_{i}\cdot a_{j})(a_{j}\cdot b_{j})\\
 & \quad+2\underbrace{\sum_{i,j}w_{i}^{1/2}w_{j}^{1/2}(a_{i}\cdot a_{j})^{2}(b_{i}\cdot b_{j})}_{=:T_{1}}+4\underbrace{\sum_{i,j}w_{i}^{1/2}w_{j}^{1/2}(a_{i}\cdot a_{j})(a_{i}\cdot b_{j})(a_{j}\cdot b_{i})}_{=:T_{2}}\\
 & =\underbrace{1^{\T}\Diag(A_{x}A_{x}^{\T})\,W^{\half}BB^{\T}W^{\half}\,\Diag(A_{x}A_{x}^{\T})\,1}_{\eqqcolon N_{1}}+4\cdot\underbrace{1^{\T}\Diag(A_{x}B^{\T})\,W^{\half}A_{x}A_{x}^{\T}W^{\half}\,\Diag(A_{x}B^{\T})\,1}_{\eqqcolon N_{2}}\\
 & \quad+4\cdot\underbrace{[1^{\T}\Diag(A_{x}A_{x}^{\T})\,W^{\half}B]\cdot[A_{x}^{\T}W^{\half}\,\Diag(A_{x}B^{\T})\,1]}_{\le N_{1}+N_{2}\text{ by Young's inequality}}+2T_{1}+4T_{2}\,.
\end{align*}
As for $N_{1}$, since $B^{\T}B=A_{x}^{\T}W_{x}^{\half}N_{x}^{2}W_{x}^{\half}A_{x}\leq p^{2}A_{x}^{\T}W_{x}A_{x}$
by Lemma~\ref{lem:LS-comp-tool}-1 and thus $B^{\T}B\precsim(d)^{-1/2}I_{d}$,
Lemma~\ref{lem:matrix-projection} ensures $BB^{\T}\precsim\frac{1}{\sqrt{d}}P(B)\preceq\frac{1}{\sqrt{d}}\,I_{m}$.
Hence,
\begin{align*}
N_{1} & \lesssim\frac{1}{\sqrt{d}}\,\tr\bpar{\Diag(A_{x}A_{x}^{\T})\,W\,\Diag(A_{x}A_{x}^{\T})}\leq\frac{1}{\sqrt{d}}\,\tr(A_{x}^{\T}WA_{x})\,\norm{\Diag(A_{x}A_{x}^{\T})}_{\infty}\lesssim\frac{1}{\sqrt{d}}\,.
\end{align*}
As for $N_{2}$, due to $A_{x}^{\T}W_{x}A_{x}\preceq\frac{1}{\sqrt{d}}I_{d}$
we have $W^{\half}A_{x}A_{x}^{\T}W^{\half}\preceq\frac{1}{\sqrt{d}}I_{m}$
by Lemma~\ref{lem:matrix-projection}. Thus,
\begin{align*}
N_{2} & \lesssim\frac{1}{\sqrt{d}}\,\tr\bpar{\{\Diag(A_{x}B^{\T})\}^{2}}=\frac{1}{\sqrt{d}}\sum_{i\in[m]}(a_{i}\cdot b_{i})^{2}\leq\frac{1}{\sqrt{d}}\sum_{i}\|a_{i}\|^{2}\|b_{i}\|^{2}\\
 & \leq\frac{1}{d}\tr(BB^{\T})\lesssim\frac{1}{d^{3/2}}\tr\bpar{P(B)}\le\frac{1}{\sqrt{d}}\,.
\end{align*}
As for $T_{1}$, by Young's inequality (i.e., $2(a\cdot b)\leq\snorm a^{2}+\norm b^{2}$)
\begin{align*}
T_{1} & =\sum_{i,j\in[m]}(a_{i}\cdot a_{j})^{2}\,\bpar{(w_{j}^{1/2}b_{i})\cdot(w_{i}^{1/2}b_{j})}\lesssim\sum_{i,j}(a_{i}\cdot a_{j})^{2}\,(w_{j}\norm{b_{i}}^{2}+w_{i}\norm{b_{j}}^{2})\\
 & =2\sum_{i,j}w_{j}(a_{i}\cdot a_{j})^{2}\norm{b_{i}}^{2}=\sum_{i}\norm{b_{i}}^{2}\cdot\tr\Bpar{a_{i}^{\T}\Bpar{\sum_{j}a_{j}w_{j}a_{j}^{\T}}a_{i}}\\
 & =\sum_{i}\norm{b_{i}}^{2}\tr(a_{i}^{\T}A_{x}^{\T}WA_{x}a_{i})\leq\frac{1}{\sqrt{d}}\sum_{i}\norm{b_{i}}^{2}\norm{a_{i}}^{2}\leq\frac{1}{d}\tr(BB^{\T})\leq\frac{1}{\sqrt{d}}\,.
\end{align*}
As for $T_{2}$, using $(a_{i}\cdot a_{j})\leq\norm{a_{i}}\norm{a_{j}}\lesssim\frac{1}{\sqrt{d}}$
\begin{align*}
T_{2} & =\sum_{i,j\in[m]}w_{i}^{1/2}w_{j}^{1/2}(a_{i}\cdot a_{j})(a_{i}\cdot b_{j})(a_{j}\cdot b_{i})\lesssim\frac{1}{\sqrt{d}}\sum_{i,j\in[m]}w_{i}^{1/2}w_{j}^{1/2}(a_{i}\cdot b_{j})(a_{j}\cdot b_{i})\\
 & =\frac{1}{\sqrt{d}}\sum_{i}w_{i}^{1/2}b_{i}^{\T}\sum_{j}a_{j}w_{j}^{1/2}b_{j}^{\textbackslash T}a_{i}=\frac{1}{\sqrt{d}}\sum_{i}\tr(a_{i}w_{i}^{1/2}b_{i}^{\T}A_{x}^{\T}W^{1/2}B)\\
 & =\frac{1}{\sqrt{d}}\tr\bpar{(A_{x}^{\T}W^{1/2}B)^{2}}\underset{\text{CS}}{\leq}\frac{1}{\sqrt{d}}\tr(B^{\T}W^{1/2}A_{x}A_{x}^{\T}W^{1/2}B)\leq\frac{1}{d}\tr(B^{\T}B)\leq\frac{1}{\sqrt{d}}\,.
\end{align*}
Putting all the bounds together, we have $\E[P_{2}(h)^{2}]\lesssim d\cdot\frac{1}{\sqrt{d}}=\sqrt{d}$.

\paragraph{Term $\textsf{B}$.}

We show that for any given $\alpha=\Theta(1)$, each coordinate of
$w_{x}/s_{x}^{\alpha}$ and $w_{p_{z}}/s_{p_{z}}^{\alpha}$ is close.
For $0\leq t\le1$, we define $x_{t}:=x+\frac{r}{\sqrt{d}}th$, and
$s_{t},$ $w_{t}$ in the same fashion. Then for $p=\O(\log m)$,
\begin{align*}
\max_{i\in[m]}\Big|\log\frac{(w_{p_{z},i})^{\alpha}}{s_{p_{z},i}}-\log\frac{(w_{x,i})^{\alpha}}{s_{x,i}}\Big| & \leq\int_{0}^{1}\Big|\frac{\D}{\D t}\log\frac{[w_{t,i}]^{\alpha}}{s_{t,i}}\Big|\,\D t\lesssim\frac{r}{\sqrt{d}}\,\norm h_{A_{x}^{\T}W_{x}A_{x}}\leq\frac{1}{d^{1/4}}\norm z\,.
\end{align*}
Just as in showing SASC of the Vaidya metric, we can make this bound
arbitrarily small (say $\delta\approx0$) by conditioning on the high-probability
region where $\norm z\leq r\log\frac{1}{\veps}\leq0.01$. Hence,
\begin{equation}
e^{-\delta}\frac{(w_{x,i})^{\alpha}}{s_{x,i}}\leq\frac{(w_{p_{z},i})^{\alpha}}{s_{p_{z},i}}\leq e^{\delta}\frac{(w_{x,i})^{\alpha}}{s_{x,i}}\,.\label{eq:closeness}
\end{equation}
We remark that this $\Theta(1)$-multiplicative closeness is still
valid without the $\sqrt{d}$-scaling of $A_{x}^{\T}W_{x}A_{x}$.

Using the formula for $\Dd^{2}(A_{x}^{\T}W_{x}A_{x})[h^{\otimes4}]$
in \eqref{eq:LW-fourth-moment},
\begin{align*}
 & |\Dd^{2}g(p)[h^{\otimes4}]|\lesssim\bpar{\bar{P}_{3}(h)+|\bar{P}_{4}(h)|+|\bar{P}_{5}(h)|}=\bar{P}_{3}(h)+\sqrt{d}\,\bpar{|\tr(W_{p,h}'S_{p,h}^{3})|+|\tr(W_{p,h}''S_{p,h}^{2})|}\\
 & =\bar{P}_{3}(h)+\sqrt{d}\underbrace{\big|\tr\bpar{S_{p,h}^{3}\Diag(W_{p}^{\half}N_{p}W_{p}^{\half}s_{p,h})}\big|}_{\eqqcolon T_{1}}+\sqrt{d}\underbrace{|\tr(S_{p,h}^{2}W_{p,h}'')|}_{\eqqcolon T_{2}}\,,
\end{align*}
where in the last line we used the formula for $W_{p,h}'$ (Lemma~\ref{lem:DWh}).

Now we show $\E[\bar{P}_{3}(h)^{2}]\lesssim d^{2}$ and $T_{i}\lesssim\sqrt{d}$
w.h.p. for $i=4,5$. As for $\bar{P}_{3}$, we have $\bar{P}_{3}(h)\lesssim P_{3}(h)$
from the closeness \eqref{eq:closeness} of $w_{i}/s_{i}^{4}$ for
each $i\in[m]$, so $\E[P_{3}(h)^{2}]\lesssim d^{2}\cdot d^{-1}=d$
from \eqref{eq:P3_bound}.

As for $T_{1}$, using the Cauchy-Schwarz 
\begin{align*}
T_{1} & =\big|\tr\bpar{S_{p,h}^{3}W_{p}^{\half}\,\Diag(N_{p}W_{p}^{\half}s_{p,h})}\big|\leq\sqrt{\tr(S_{p,h}^{3}W_{p}S_{p,h}^{3})}\sqrt{s_{p,h}^{\T}W_{p}^{1/2}N_{p}^{2}W_{p}^{1/2}s_{p,h}}\\
 & \underset{\text{(i)}}{\lesssim}\sqrt{s_{p,h}^{3}W_{p}s_{p,h}^{3}}\sqrt{s_{p,h}^{\T}W_{p}s_{p,h}}\underset{\text{(ii)}}{\lesssim}\sqrt{s_{x,h}^{3}W_{x}s_{x,h}^{3}}\sqrt{s_{x,h}^{\T}W_{x}s_{x,h}}=\sqrt{s_{x,h}^{3}W_{x}s_{x,h}^{3}}\cdot d^{-1/4}\norm h_{g(x)}\,,
\end{align*}
where in (i) we used $N_{x}\preceq p^{2}I$ (Lemma~\ref{lem:LS-comp-tool}),
and in (ii) the closeness of $w_{i}/s_{i}^{6}$ and $w_{i}/s_{i}^{2}$
established in \eqref{eq:closeness}. As for the first term in the
RHS, 
\begin{align*}
\E[(s_{x,h}^{3}W_{x}s_{x,h}^{3})^{2}] & \underset{\text{CS}}{\lesssim}\sum_{i,j\in[m]}w_{i}w_{j}\sqrt{\E[(a_{i}\cdot h)^{12}]}\sqrt{\E[(a_{j}\cdot h)^{12}]}=\Bpar{\sum_{i}w_{i}\,\bpar{\E[(a_{i}\cdot h)^{12}]}^{2}}^{2}\\
 & \lesssim\Bpar{\sum_{i}w_{i}\norm{a_{i}}^{6}}^{2}\leq\Bpar{\frac{1}{d^{3/2}}\sum_{i}w_{i}}^{2}=\frac{1}{d}\,.
\end{align*}
As for the second term, the concentration of the standard Gaussian
guarantees $\norm h_{g(x)}\leq\norm h\lesssim\sqrt{d}$ w.h.p. Therefore,
$T_{1}\lesssim\sqrt{d}$ w.h.p.

As for $T_{2}$, \eqref{eq:trGamma} with $\Gamma_{p}=S_{p,h}^{2}$
equals $T_{2}$. Following \eqref{eq:last-bound} with I, II, III,
IV defined in \eqref{eq:LW-second-derv},
\begin{align*}
T_{2} & \lesssim\sum_{v=\text{I,II,III,IV}}\sqrt{\tr(W_{p}S_{p,h}^{4})}\norm v_{W_{p}^{-1}}\underset{\text{(i)}}{\lesssim}\sqrt{\tr(W_{p}S_{p,h}^{4})}\,\bpar{\tr(S_{p,h}^{2}W_{p})+\tr(S_{p,h}^{4}W_{p})}\\
 & \underset{\text{(ii)}}{\lesssim}\sqrt{\tr(W_{x}S_{x,h}^{4})}\,\bpar{\tr(S_{x,h}^{2}W_{x})+\tr(S_{x,h}^{4}W_{x})}\,,
\end{align*}
where (i) follows from Lemma~\ref{lem:second-deriv-Lewis} (i.e.,
$\norm v_{W_{p}^{-1}}\lesssim\norm h_{A_{p}^{\T}W_{p}A_{p}}^{2}=\tr(S_{p,h}^{2}W_{p})$
for $v=$ I, II, III, and $\norm{\text{IV}}_{W_{p}^{-1}}\lesssim\tr(S_{p,h}^{4}W_{p})$),
and (ii) follows from the conditioned event where the closeness of
$w_{i}/s_{i}^{2}$ at $x$ and $z$ holds. Since we already established
the high-probability bounds of $d^{-1/2}P_{3}(h)=\tr(S_{x,h}^{4}W_{x})\lesssim1$
and $\tr(S_{x,h}^{2}W_{x})\lesssim\sqrt{d}$, combining these yield
$T_{2}\lesssim\sqrt{d}$ w.h.p.
\end{proof}

\subsubsection{Quadratic constraints \label{proof:quadratic}}

We show that a $\nu$-SC barrier $\psi(\cdot)=-\log f(\cdot)$ satisfies
\[
|\Dd^{4}\psi(x)[h^{\otimes4}]|\lesssim\nu^{2}\norm h_{\hess\psi(x)}^{2}+\Big|\frac{\Dd^{4}f(x)[h^{\otimes4}]}{f(x)}\Big|\,.
\]

\begin{proof}
[Proof of Lemma~\ref{lem:4th-log}] Fix $h\in\Rd$ and $x\in\inter(K)$,
define $\phi(t):=\psi(x+th)$. Then,
\begin{align*}
\phi' & =-\frac{f'}{f}\,,\\
\phi'' & =\Par{\frac{f'}{f}}^{2}-\frac{f''}{f}=(\phi')^{2}-\frac{f''}{f}\,,\\
\phi''' & =2\phi'\phi''-\frac{f'''f-f''f'}{f^{2}}=2\phi'\phi''-\frac{f'''}{f}+\frac{f''f'}{f^{2}}=2\phi'\phi''+\phi'(\phi''-(\phi')^{2})-\frac{f'''}{f}\\
 & =3\phi'\phi''-(\phi')^{3}-\frac{f'''}{f}\,,\\
\phi^{(4)} & =3(\phi'')^{2}+3\phi'\phi'''-3(\phi')^{2}\phi''-\frac{f^{(4)}f-f'''f'}{f^{2}}\\
 & =3(\phi'')^{2}+3\phi'\phi'''-3(\phi')^{2}\phi''+\phi'\Par{\phi'''-3\phi'\phi''+(\phi')^{3}}-\frac{f^{(4)}}{f}\\
 & =3(\phi'')^{2}+4\phi'\phi'''-6(\phi')^{2}\phi''+(\phi')^{4}-\frac{f^{(4)}}{f}\,.
\end{align*}
Since $|\phi'''|\leq2(\phi'')^{3/2}$ (SC of $\phi$) and $\phi''\geq\frac{1}{\nu}(\phi')^{2}$
(the definition of the barrier parameter), which is equivalent to
$|\phi'|\leq\sqrt{\nu}(\phi'')^{1/2}$, we can directly compute as
follows:
\begin{align*}
|\phi^{(4)}| & \leq4\,|\phi'\phi'''|+3\,|(\phi'')^{2}|+6|\,(\phi')^{2}\phi''|+|(\phi')^{4}|+\Big|\frac{f^{(4)}}{f}\Big|\\
 & \leq8\sqrt{\nu}\,|\phi''|^{2}+3\,|\phi''|^{2}+6\nu\,|\phi''|^{2}+\nu^{2}\,|\phi''|^{2}+\Big|\frac{f^{(4)}}{f}\Big|\lesssim\nu^{2}|\phi''|^{2}+\Big|\frac{f^{(4)}}{f}\Big|\,.\qedhere
\end{align*}
\end{proof}
Using this tool, we study Dikin-amenability of barriers for quadratic
constraints.
\begin{proof}
[Proof of Lemma~\ref{lem:quadratic-const}] Let us check the last
claim first. By Lemma~\ref{lem:linear-trans}, we may assume that
\[
\phi(x,y)=-\log(l+q^{\T}y-\half\norm x^{2})\,,
\]
and let $f(x,y)=l+q^{\T}y-\half\,\norm x^{2}$. For $z=(x,y)\in\intk$
and $u=(u_{x},u_{y})\in\Rd$, we have 
\begin{align}
\Dd\phi(z)[u] & =-\frac{1}{f}\,(q\cdot u_{y}-x\cdot u_{x})=\frac{x\cdot u_{x}-q\cdot u_{y}}{f}\,,\nonumber \\
\Dd^{2}\phi(z)[u,u] & =\frac{1}{f^{2}}\,(x\cdot u_{x}-q\cdot u_{y})^{2}+\frac{1}{f}\,\norm{u_{x}}^{2}\,.\label{eq:hessian-quadratic}
\end{align}

As for the first term in the RHS of \eqref{eq:hessian-quadratic},
it holds that for $v=(v_{x},v_{y})\in\Rd$ 
\begin{align*}
\Dd\Bpar{\frac{(x\cdot u_{x}-q\cdot u_{y})^{2}}{f^{2}}}[v] & =\frac{2\,(x\cdot u_{x}-q\cdot u_{y})(v_{x}\cdot u_{x})}{f^{2}}+2\,(x\cdot u_{x}-q\cdot u_{y})^{2}\cdot\frac{x\cdot v_{x}-q\cdot v_{y}}{f^{3}}\,,\\
\Dd^{2}\Bpar{\frac{(x\cdot u_{x}-q\cdot u_{y})^{2}}{f^{2}}}[v,v] & =\frac{2\,(v_{x}\cdot u_{x})^{2}}{f^{2}}+4\frac{(x\cdot u_{x}-q\cdot u_{y})(v_{x}\cdot u_{x})(x\cdot v_{x}-q\cdot v_{y})}{f^{3}}\\
 & \quad+\frac{4\,(x\cdot u_{x}-q\cdot u_{y})(v_{x}\cdot u_{x})(x\cdot v_{x}-q\cdot v_{y})+2\,(x\cdot u_{x}-q\cdot u_{y})^{2}\norm{v_{x}}^{2}}{f^{3}}\\
 & \quad+\frac{6\,(x\cdot u_{x}-q\cdot u_{y})^{2}(x\cdot v_{x}-q\cdot v_{y})^{2}}{f^{4}}\\
 & =\frac{2\,(v_{x}\cdot u_{x})^{2}}{f^{2}}+\frac{4\,(x_{q}\cdot u)(v_{x}\cdot u_{x})(x_{q}\cdot v)}{f^{3}}\\
 & \quad+\frac{4\,(x_{q}\cdot u)(v_{x}\cdot u_{x})(x_{q}\cdot v)+2(x_{q}\cdot u)^{2}\norm{v_{x}}^{2}}{f^{3}}+\frac{6\,(x_{q}\cdot u)^{2}(x_{q}\cdot v)^{2}}{f^{4}}\,,
\end{align*}
where $x_{q}:=(x,-q)\in\Rd$.

As for the second term, direct computations lead to 
\begin{align*}
\Dd\Bpar{\frac{\norm{u_{x}}^{2}}{f}}[v] & =\frac{1}{f^{2}}\,\norm{u_{x}}^{2}(x\cdot v_{x}-q\cdot v_{y})\,,\\
\Dd^{2}\Bpar{\frac{\norm{u_{x}}^{2}}{f}}[v,v] & =\frac{2}{f^{3}}\,\norm{u_{x}}^{2}(x\cdot v_{x}-q\cdot v_{y})^{2}+\frac{1}{f^{2}}\,\norm{u_{x}}^{2}\norm{v_{x}}^{2}\\
 & =\frac{2}{f^{3}}\,\norm{u_{x}}^{2}(x_{q}\cdot v)^{2}+\frac{1}{f^{2}}\,\norm{u_{x}}^{2}\norm{v_{x}}^{2}\,.
\end{align*}
Putting these together, for $u,v\in\Rd$
\begin{align*}
 & \Dd^{4}\phi[u,u,v,v]\\
 & =\frac{1}{f^{2}}\,\norm{u_{x}}^{2}\norm{v_{x}}^{2}+\underbrace{\frac{2}{f^{2}}\,(v_{x}\cdot u_{x})^{2}}_{\geq0}+\frac{4}{f^{3}}\,\Bpar{\half\,\norm{u_{x}}^{2}(x_{q}\cdot v)^{2}+2\,(x_{q}\cdot u)(v_{x}\cdot u_{x})(x_{q}\cdot v)+\frac{(x_{q}\cdot u)^{2}}{2}\,\norm{v_{x}}^{2}}\\
 & \qquad+\frac{6}{f^{4}}\,(x_{q}\cdot u)^{2}(x_{q}\cdot v)^{2}\\
 & \geq\frac{4}{f^{3}}\,\bigg(\underbrace{\half\norm{u_{x}}^{2}(x_{q}\cdot v)^{2}+\frac{1}{2}\norm{v_{x}}^{2}(x_{q}\cdot u)^{2}}_{\text{Use AM-GM}}+2(x_{q}\cdot u)(v_{x}\cdot u_{x})(x_{q}\cdot v)\bigg)\\
 & \qquad+\underbrace{\frac{1}{f^{2}}\,\norm{u_{x}}^{2}\norm{v_{x}}^{2}+\frac{6}{f^{4}}\,(x_{q}\cdot u)^{2}(x_{q}\cdot v)^{2}}_{\text{Use AM-GM}}\\
 & \geq\frac{4}{f^{3}}\,\bpar{\norm{u_{x}}\,\norm{v_{x}}\,|x_{q}\cdot v|\,|x_{q}\cdot u|-2|x_{q}\cdot u|\,|x_{q}\cdot v|\,\norm{u_{x}}\,\norm{v_{x}}}+\frac{2\sqrt{6}}{f^{3}}\,|x_{q}\cdot u|\,|x_{q}\cdot v|\,\norm{u_{x}}\,\norm{v_{x}}\\
 & =\frac{4}{f^{3}}\,\norm{u_{x}}\,\norm{v_{x}}\,|x_{q}\cdot v|\,|x_{q}\cdot u|\,\Bpar{\frac{\sqrt{6}}{2}-1}\geq0\,.\qedhere
\end{align*}
\end{proof}


\subsubsection{PSD: convexity and strongly self-concordance \label{proof:psd-convex-ssc}}

We start with convexity of $\log\det(\hess\phi)$ for $\phi(X)=-\log\det X$.
\begin{proof}
[Proof of Proposition~\ref{prop:convex-logdet}] Using Lemma~\ref{prop:metricFormula}
and $\det\bpar{M^{\T}(A\otimes A)M}=2^{d(d-1)/2}\,(\det A)^{d+1}$
(Lemma~\ref{lem:Kronecker}) in the first and second equality below,
\begin{align*}
\log\det\bpar{\hess\phi(X)} & =\log\det\bpar{M^{\T}(X^{-1}\otimes X^{-1})M}=\frac{d(d-1)}{2}\,\log2-(d+1)\,\log\det X\,.
\end{align*}
Since $-\log\det X$ is convex in $X$ \eqref{eq:2ndDiffLogDet},
the convexity of $\log\det\bpar{\hess\phi(X)}$ also follows.
\end{proof}
Observe from the proof that $\log\det\bpar{\hess\phi(X)}=\text{const.}+(d+1)\,\phi(X)$.
Differentiating both sides in direction $H$, by \eqref{eq:gradLogDet}
$\tr\bpar{[\hess\phi(X)]^{-1}\Dd^{3}\phi(X)[H]}=(d+1)\,\Dd\phi(X)[H]$.
Hence,
\begin{align}
 & \tr\bpar{[\hess\phi(X)]^{-\half}\Dd^{3}\phi(X)[H]\,[\hess\phi(X)]^{-\half}}=-(d+1)\,\tr(X^{-1}H)\,.\label{eq:difflogdet}
\end{align}

We are ready to show SSC of $\phi$.
\begin{proof}
[Proof of Lemma~\ref{lem:logdet-scaling}] For $H\in\mbb S^{d}$
and $t\in\R$, denote $X_{t}:=X+tH$ and $g_{t}:=M^{\T}(X_{t}\otimes X_{t})^{-1}M$.
Note that
\[
\bnorm{[\hess\phi(X)]^{-\half}\Dd^{3}\phi(X)[H]\,[\hess\phi(X)]^{-\half}}_{F}^{2}=\tr(g^{-1}\del_{t}g_{t}\vert_{t=0}\,g^{-1}\del_{t}g_{t}\vert_{t=0})\,,
\]
and
\begin{align}
\del_{t}g_{t}\vert_{t=0} & \underset{\text{(i)}}{=}\del_{t}\bpar{M^{\T}(X_{t}\otimes X_{t})^{-1}M}\Big|_{t=0}\underset{\text{(ii)}}{=}-M^{\T}(X\otimes X)^{-1}\,\del_{t}(X_{t}\otimes X_{t})\vert_{t=0}\,(X\otimes X)^{-1}M\nonumber \\
 & =-M^{\T}(X^{-1}\otimes X^{-1})(H\otimes X+X\otimes H)(X^{-1}\otimes X^{-1})M\nonumber \\
 & \underset{\text{(iii)}}{=}-M^{\T}(X^{-1}HX^{-1}\otimes X^{-1}+X^{-1}\otimes X^{-1}HX^{-1})M\,,\label{eq:18-1}
\end{align}
where (i) follows from Lemma~\ref{prop:metricFormula}, (ii) is due
to \eqref{eq:diffInverse}, and (iii) follows from $(A\otimes B)(C\otimes D)=(AC)\otimes(BD)$
(Lemma~\ref{lem:Kronecker}-3).

Recall that positive semidefinite matrices have unique positive semidefinite
square roots, so $(X\otimes X)^{\half}=X^{\half}\otimes X^{\half}$
(due to $(X^{1/2}\otimes X^{1/2})\cdot(X^{1/2}\otimes X^{1/2})=X\otimes X$).
Since $g_{t}=M^{\T}(X_{t}\otimes X_{t})^{-1/2}(X_{t}\otimes X_{t})^{-1/2}M$,
the corresponding orthogonal projection is 
\[
P_{t}:=P\bpar{(X_{t}\otimes X_{t})^{-\half}M}=(X_{t}\otimes X_{t})^{-\half}Mg_{t}^{-1}M^{\T}(X_{t}\otimes X_{t})^{-\half}\,.
\]
 By substituting $\del_{t}g_{t}\big|_{t=0}$ with \eqref{eq:18-1},
\begin{align*}
 & \tr(g^{-1}\del_{t}g_{t}\vert_{t=0}\,g^{-1}\del_{t}g_{t}\vert_{t=0})\\
 & =\tr\bigl(g^{-1}M^{\T}(X^{-1}HX^{-1}\otimes X^{-1}+X^{-1}\otimes X^{-1}HX^{-1})M\\
 & \qquad\qquad\cdot g^{-1}M^{\T}(X^{-1}HX^{-1}\otimes X^{-1}+X^{-1}\otimes X^{-1}HX^{-1})\cblue M\bigr)\\
 & =\tr\bigl(\cblue Mg^{-1}M^{\T}(X^{-1}HX^{-1}\otimes X^{-1}+X^{-1}\otimes X^{-1}HX^{-1})M\\
 & \qquad\qquad\cdot g^{-1}M^{\T}(X^{-1}HX^{-1}\otimes X^{-1}+X^{-1}\otimes X^{-1}HX^{-1})\bigr)\\
 & =\tr\Bpar{\bbrack{\cred{Mg^{-1}M^{\T}}(X^{-1}HX^{-1}\otimes X^{-1}+X^{-1}\otimes X^{-1}HX^{-1})}^{2}}\\
 & =\tr\Bpar{\bbrack{\cred{(X\otimes X)^{\half}P(X\otimes X)^{\half}}(X^{-1}HX^{-1}\otimes X^{-1}+X^{-1}\otimes X^{-1}HX^{-1})}^{2}}\\
 & =\tr\Bpar{\bbrack{P\underbrace{(X\otimes X)^{\half}(X^{-1}HX^{-1}\otimes X^{-1}+X^{-1}\otimes X^{-1}HX^{-1})(X\otimes X)^{\half}}_{\eqqcolon S}}^{2}}\\
 & =\tr(PSPS)\,.
\end{align*}
Using Lemma~\ref{lem:Kronecker}-3,
\begin{align*}
S & =\underbrace{X^{-\half}HX^{-\half}\otimes I_{d}}_{\eqqcolon A}+\underbrace{I_{d}\otimes X^{-\half}HX^{-\half}}_{\eqqcolon B}\,.
\end{align*}
By the Cauchy-Schwarz inequality along with $P^{\T}P=P^{2}=P$ and
$P\preceq I_{d}$,
\begin{align*}
\tr(PSPS) & \leq\tr((PS)^{\T}PS)\leq\tr(S^{\T}S)=\norm S_{F}^{2}\leq(\norm A_{F}+\norm B_{F})^{2}\,.
\end{align*}
Using Lemma~\ref{lem:Kronecker}-3, 
\begin{align*}
\norm A_{F}^{2} & =\tr\bpar{(X^{-\half}HX^{-\half}\otimes I_{d})\cdot(X^{-\half}HX^{-\half}\otimes I_{d})}\\
 & =\tr(X^{-\half}HX^{-1}HX^{-\half}\otimes I_{d})=\tr(X^{-\half}HX^{-1}HX^{-\half})\,\tr(I_{d})=d\,\norm H_{X}^{2}\,,
\end{align*}
and similarly $\norm B_{F}^{2}=d\,\norm H_{X}^{2}$. Therefore, $\psi_{X}\leq2\sqrt{d}$
follows from
\[
\bnorm{[\hess\phi(X)]^{-\half}\Dd^{3}\phi(X)[H]\,[\hess\phi(X)]^{-\half}}_{F}\leq\sqrt{\tr(PSPS)}\leq2\sqrt{d}\,\norm H_{X}\,.
\]

To see the optimality of $\O(d^{1/2})$, we recall \eqref{eq:difflogdet}:
\[
\tr\bpar{[\hess\phi(X)]^{-\half}\Dd^{3}\phi(X)[H]\,[\hess\phi(X)]^{-\half}}=-(d+1)\,\tr(X^{-1}H)\,.
\]
Taking supremum on both sides,
\begin{align*}
\sup_{H:\norm H_{X}=1}\tr\bpar{[\hess\phi(X)]^{-\half}\Dd^{3}\phi(X)[H]\,[\hess\phi(X)]^{-\half}} & =\sup_{\substack{H\in\mbb S^{d}:\\
\snorm{X^{-1/2}HX^{-1/2}}_{F}=1
}
}-(d+1)\,\tr(X^{-\half}HX^{-\half})\\
 & =\sup_{S\in\mbb S^{d}:\norm S_{F}=1}(d+1)\,\tr(S)\,,
\end{align*}
and this objective achieves the maximum at $H=-d^{-1/2}X$, with the
supremum being $(d+1)\sqrt{d}$. On the other hand, due to $\tr(A)\leq d^{1/2}\,\norm A_{F}$
for $A\in\R^{d\times d}$,
\begin{align*}
 & \tr\bpar{[\hess\phi(X)]^{-\half}\Dd^{3}\phi(X)[H]\,[\hess\phi(X)]^{-\half}}\\
 & \leq\sqrt{\frac{d(d+1)}{2}}\cdot\bnorm{[\hess\phi(X)]^{-\half}\Dd^{3}\phi(X)[H]\,[\hess\phi(X)]^{-\half}}_{F}\leq\sqrt{\frac{d(d+1)}{2}}\cdot\psi_{X}\norm H_{X}\,,
\end{align*}
and thus by taking supremum on both sides over a symmetric matrix
$H$ with $\norm H_{X}=1$, it follows that $(d+1)\sqrt{d}\leq\sqrt{\frac{d(d+1)}{2}}\,\psi_{X}$
and 
\[
\sqrt{2(d+1)}\leq\psi_{X}\,.\qedhere
\]
\end{proof}

\subsubsection{PSD: strongly lower trace self-concordance \label{proof:psd-sltsc}}

Direct computation leads to $\Dd^{2}g(X)[H,H]\succeq0$ (so SLTSC).
\begin{proof}
[Proof of Lemma~\ref{lem:logdet-sltsc}] For $g(X)=-\hess\log\det X$,
recall that $g(X)[H,H]=\tr(X^{-1}HX^{-1}H)$. Thus for any $V\in\mbb S^{d}$,
\begin{align*}
\Dd g(X)[H,H,V] & =-\tr(X^{-1}VX^{-1}\cdot HX^{-1}H)-\tr(X^{-1}H\cdot X^{-1}VX^{-1}\cdot H)\\
 & =-2\,\tr(X^{-1}VX^{-1}HX^{-1}H)\,,
\end{align*}
and differentiating again,
\begin{align}
 & \Dd^{2}g(X)[H,H,V,V]\nonumber \\
 & =4\,\tr(X^{-1}VX^{-1}VX^{-1}HX^{-1}H)+2\,\tr(X^{-1}VX^{-1}HX^{-1}VX^{-1}H)\nonumber \\
 & =4\,\tr(X^{-\half}HX^{-1}VX^{-1}VX^{-1}HX^{-\half})+2\,\tr(X^{-\half}VX^{-1}HX^{-\half}\cdot X^{-\half}VX^{-1}HX^{-\half})\nonumber \\
 & \underset{\text{(i)}}{\geq}4\,\tr(X^{-\half}HX^{-1}VX^{-1}VX^{-1}HX^{-\half})-2\,\tr(X^{-\half}HX^{-1}VX^{-\half}\cdot X^{-\half}VX^{-1}HX^{-\half})\nonumber \\
 & =2\,\tr(X^{-\half}HX^{-1}VX^{-1}VX^{-1}HX^{-\half})\geq0\,,\label{eq:D4ph1}
\end{align}
where in (i) we used the Cauchy-Schwarz inequality. Therefore, $\Dd^{2}g(X)[H,H]\succeq0$.
\end{proof}

\subsubsection{PSD: average self-concordance \label{proof:psd-asc}}

We establish a connection to the Gaussian orthogonal ensemble (GOE):
for $d_{s}=d(d+1)/2$ and $\svec(H)\sim\ncal\bpar{0,\frac{r^{2}}{d_{s}}\,g(X)^{-1}}$,
we have $\frac{\sqrt{d_{s}d}}{r}X^{-\half}HX^{-\half}$ is the GOE.
\begin{proof}
[Proof of Lemma~\ref{lem:conn-to-goe}] Let $h_{X}:=\svec(X^{-1/2}HX^{-1/2})$
and $h:=\svec(H)$. It holds that
\[
h_{X}=L(X\otimes X)^{-\half}Mh
\]
due to $h_{X}=\svec(X^{-\half}HX^{-\half})=L\,\vec(X^{-\half}HX^{-\half})=L(X\otimes X)^{-\half}\vec(H)=L(X\otimes X)^{-\half}Mh$.
As $h\sim\ncal\bpar{0,\frac{r^{2}}{d_{s}}\,g(X)^{-1}}$, $h_{X}$
is a Gaussian with zero mean and covariance
\begin{align*}
 & \frac{r^{2}}{d_{s}}L(X\otimes X)^{-\half}Mg(X)^{-1}M^{\T}(X\otimes X)^{-\half}L^{\T}\\
\underset{\text{(i)}}{=} & \frac{r^{2}}{d_{s}d}L(X\otimes X)^{-\half}MLN(X\otimes X)N^{\T}L^{\T}M^{\T}(X\otimes X)^{-\half}L^{\T}\\
\underset{(*)}{=} & \frac{r^{2}}{d_{s}d}L(X\otimes X)^{-\half}N(X\otimes X)N^{\T}(X\otimes X)^{-\half}L^{\T}\\
\underset{(*)}{=} & \frac{r^{2}}{d_{s}d}L(X\otimes X)^{-\half}(X\otimes X)N(X\otimes X)^{-\half}L^{\T}\underset{\text{(*)}}{=}\frac{r^{2}}{d_{s}d}LNL^{\T}\\
\underset{\text{(ii)}}{=} & \frac{r^{2}}{d_{s}d}\,\left[\begin{array}{cc}
I_{d}\\
 & \half I_{d(d-1)/2}
\end{array}\right]\,,
\end{align*}
where (i) follows from Proposition~\ref{prop:metricFormula}, $(*)$
follows from Lemma~\ref{lem:MNL-properties}, and (ii) follows from
\citet[Page 427]{magnus1980elimination} that $LNL^{\T}$ is a $d_{s}\times d_{s}$
diagonal matrix with $d$ times $1$ and $\half d(d-1)$ times $1/2$.
Precisely, the entries of $h_{X}\in\R^{d_{s}}$ corresponding to the
diagonals of $X^{-1/2}HX^{-1/2}$ are $1$, and its entries corresponding
to off-diagonals is $1/2$. This is exactly the covariance matrix
of a $d_{s}$-dimensional GOE, so $X^{-\half}HX^{-\half}\sim\frac{r}{\sqrt{d_{s}d}}G$
for the GOE $G$.
\end{proof}
Now we show ASC of $d\phi$.
\begin{proof}
[Proof of Lemma~\ref{lem:logdet-asc}] Expand $\norm{Z-X}_{Z}^{2}:=\norm{Z-X}_{g(Z)}^{2}$
at $X$ for $Z=X+H$:
\[
\norm{Z-X}_{Z}^{2}-\norm{Z-X}_{X}^{2}=\sum_{k=1}^{\infty}\frac{1}{k!}\,\Dd^{k}g(X)[H^{\otimes k+2}]\,.
\]
It follows from induction that for $H_{X}:=X^{-\half}HX^{-\half}$
\begin{align*}
\Dd g(X)[H^{\otimes3}] & =-2d\,\tr(X^{-1}HX^{-1}HX^{-1}H)=-2\tr(H_{X}^{3})\,,\\
\Dd^{2}g(X)[H^{\otimes4}] & =3!\,d\,\tr(H_{X}^{4})\,,\\
\Dd^{k}g(X)[H^{\otimes(k+2)}] & =(-1)^{k}(k+1)!\,d\,\tr(H_{X}^{k+2})\,.
\end{align*}
Putting these back into the series expansion, for $H$ the GOE (see
Lemma~\ref{lem:conn-to-goe})
\begin{align*}
 & \norm{Z-X}_{Z}^{2}-\norm{Z-X}_{X}^{2}=\sum_{k=1}^{\infty}(-1)^{k}(k+1)d\,\tr(H_{X}^{k+2})\\
= & \sum_{k=1}^{\infty}(-1)^{k}(k+1)d\cdot\Bpar{\frac{r}{\sqrt{d_{s}d}}}^{k+2}\tr(H^{k+2})=\frac{r^{2}}{d_{s}}\sum_{k=1}^{\infty}(-1)^{k}(k+1)\,\Bpar{\frac{r}{\sqrt{d_{s}d}}}^{k}\tr(H^{k+2})\,.
\end{align*}

As for ASC, it suffices to show that $\sum_{k=1}^{\infty}(-1)^{k}(k+1)\bpar{\frac{r}{\sqrt{d_{s}d}}}^{k}\,\tr(H^{k+2})$
can be made arbitrarily small. We first control $\sum_{k\geq2}$:
\[
\Big|\sum_{k\geq2}(-1)^{k}(k+1)\Bpar{\frac{r}{\sqrt{d_{s}d}}}^{k}\tr(H^{k+2})\Big|\leq\sum_{k\geq2}(k+1)\Bpar{\frac{r}{\sqrt{d_{s}d}}}^{k}d\cdot\norm H_{\text{op}}^{k+2}\,.
\]
By \citet[Corollary 4.4.8]{vershynin2018high}, $\norm H_{\text{op}}\lesssim\sqrt{d}$
holds with high probability, and thus
\begin{align*}
\sum_{k\geq2}(k+1)\Bpar{\frac{r}{\sqrt{d_{s}d}}}^{k}d\cdot\norm H_{\text{op}}^{k+2} & \leq\sum_{k\geq2}(k+1)r^{k}\frac{1}{d^{3k/2}}d\cdot d^{\frac{k+2}{2}}\leq\sum_{k\geq2}(k+1)r^{k}d^{2-k}\,.
\end{align*}
By taking $r=\Omega(1)$ small enough, we can make this series arbitrarily
small.

Now we bound $\frac{r}{d^{3/2}}\tr(H^{3})$ ($k=1$ case). This is
a Gaussian polynomial in $\svec(H)$, so it suffices to show $\E[(\tr(H^{3}))^{2}]=\mc O(d^{3})$;
we then use Lemma~\ref{lem:conc-gaussian-poly} to obtain a high-probability
bound on the Gaussian polynomial $\frac{r}{d^{3/2}}\tr(H^{3})$. For
$H=(H_{ab})\in\mbb S^{d}$, 
\[
\bpar{\tr(H^{3})}^{2}=\sum_{ipq}H_{ip}H_{pq}H_{qi}\cdot\sum_{jrs}H_{jr}H_{rs}H_{sj}=\sum_{ipqjrs}H_{ip}H_{pq}H_{qi}H_{jr}H_{rs}H_{sj}\,,
\]
where each $H_{**}$ in the summand is an independent Gaussian with
zero mean and variance $1$ or $1/2$ (as $H$ is the GOE). We can
classify the indices $\{i,p,q,j,r,s\}$ into the following types:
\begin{align*}
6\text{ distinct indices } & \{a,b,c,d,e,f\}\,,\\
5\text{ distinct indices } & \{a,b,c,d,(e,e)\}\,,\\
4\text{ distinct indices } & \{a,b,c,(d,d,d)\},\{a,b,(c,c),(d,d)\}\,,\\
\text{Others } & \dots\,,
\end{align*}
where for example $\{a,b,c,d,e,f\}$ means all indices are different,
and $\{a,b,c,d,(e,e)\}$ means that there appear 5 different indices
$\{a,b,c,d,e\}$ but exists one pair $(e,e)$ of the same index. Note
that $\E H_{ip}H_{pq}H_{qi}H_{jr}H_{rs}H_{sj}=\mc O(1)$ is at most
the sixth moment of a standard Gaussian. It implies that toward our
goal of showing $\mc O(d^{3})$-bound on $\bpar{\tr(H^{3})}^{2}$,
it suffices to look into only three types of indices above. This is
because the terms from other types contribute at most $\mc O(d^{3})$
to $\bpar{\tr(H^{3})}^{2}$.
% Figure environment removed

For any term with 6 distinct indices, we can always find an `uncoupled'
$H_{**}$ (for example $H_{ab}$) in the summand that is independent
of all the others, so its expectation of the summand is $0$.

For the terms with $5$-distinct indices $\{a,b,c,d,(e,e)\}$, due
to symmetry (see Figure~\ref{fig:ipq-jrs}) we can further classify
the index $(i,p,q,j,r,s)$ into either $(a,b,c,d,e,e)$ or $(a,b,e,c,d,e)$.
In both cases , $H_{ab}$ has no coupled Gaussian, so the expectations
of the summand are also $0$. 

For $4$-distinct indices, let us first consider $\{a,b,c,(d,d,d)\}$-type
indices. In this case $(i,p,q,j,r,s)$ is of the form either $(a,a,a,b,c,d)$
or $(a,a,b,a,c,d)$ due to symmetry. In both cases, $H_{cd}$ has
no coupled Gaussian. Now consider $\{a,b,(c,c),(d,d)\}$-type indices.
Then $(i,p,q,j,r,s)$ is of the form either $(a,b,c,c,d,d)$ or $(a,c,c,b,d,d)$
or $(a,c,d,b,c,d)$. For each case, $H_{ab},H_{cc},H_{ac}$ are uncoupled
ones. Therefore, $\E[H_{ip}H_{pq}H_{qi}H_{jr}H_{rs}H_{sj}]=0$ whenever
there are at least $4$ distinct indices.
\end{proof}
\begin{rem}
\label{rem:challenge-extension-SASC}It seems challenging to show
that $\phi$ is SASC using the same technique. When $g$ is 
\[
g=d\,\hess(-\log\det X)+g'
\]
for other PSD matrix function $g'$, we know that $\svec(H_{X})=\svec(X^{-\half}HX^{-\half})$
follows a Gaussian distribution with zero mean and covariance matrix
$M$ satisfying
\[
M\preceq\left[\begin{array}{cc}
I_{d}\\
 & \half I_{d(d-1)/2}
\end{array}\right]\,.
\]
A main difference in the SASC setting is that the entries of $h=\svec(H_{X})$
might exhibit dependencies, making the previous approach infeasible.
This arises because many fundamental results in the random matrix
theory often presume independence of the entries of a random matrix.
Moreover, our combinatorial argument for the $k=1$ case is not feasible
in the presence of such dependencies.
\end{rem}


\subsection{Examples ($\S$\ref{sec:examples})}

\subsubsection{Algorithms for PSD sampling \label{proof:Algorithms-for-PSD}}
\begin{proof}
[Proof of Proposition~\ref{thm:hybridPSD}] We define $g_{X}=g=2(d^{2}g_{1}+g_{2})$,
where
\[
g_{1}(X)=M^{\T}(X\kro X)^{-1}M\qquad\text{and}\qquad g_{2}(X)=22\sqrt{\frac{m}{d}}\,M^{\T}A_{X}^{\T}\bpar{\Sigma_{X}+\frac{d}{m}I_{m}}A_{X}M\,.
\]
Since $d^{2}g_{1}$ and $g_{2}$ are SSC, $g$ is also SSC due to
Lemma~\ref{lem:ssc-sum} and $\mc O(d^{3}+\sqrt{md^{2}})$-symmetric\footnote{Since the dimension is $d_{s}$ in the PSD setting, we should replace
$d$ by $d_{s}=\O(d^{2})$ when applying Lemma~\ref{lem:paramsBarrier}.} due to Lemma~\ref{lem:symmetry-addition}. As $d^{2}g_{1}$ and
$g_{2}$ is SLTSC and SASC, $g$ is LTSC and ASC. Putting these together,
it follows that $g$ is $\bpar{\mc O(d^{3}+\sqrt{md^{2}}),\mc O(d^{3}+\sqrt{md^{2}})}$-Dikin-amenable.
Therefore, Theorem~\ref{thm:Dikin-annealing} implies that $\gcdw$
incurs $\otilde{d^{2}(d^{3}+\sqrt{md^{2}})}=\otilde{d^{3}(d^{2}+\sqrt{m})}$
total iterations of the $\dw$ with $g$.

Now we bound the per-step complexity of the $\dw$ (Algorithm~\ref{alg:DikinWalk}).
Recall that it requires (1) the update of the leverage scores, (2)
computation of the matrix function induced by the local metric $g$,
(3) the inverse of the matrix function and (4) its determinant. By
\citet[Theorem 46]{lee2019solving} (with $p=2$ and $d\gets d_{s}$
therein), the initialization of the leverage scores at the beginning
takes $\otilde{md^{2\omega}}$ and their updates takes $\otilde{md^{2(\omega-1)}}$
time. Since (1) takes $\otilde{md^{2(\omega-1)}}$, (2) takes $\otilde{d^{4}+md^{2(\omega-1)}}$,
and (3) and (4) take $\mc O\Par{d^{2\omega}}$, each iteration runs
in $\otilde{d^{2\omega}+md^{2(\omega-1)}}$ time. Even though the
initialization of leverage scores takes $\otilde{md^{2\omega}}$ time,
the amortized per-step time complexity becomes $\otilde{d^{2\omega}+md^{2(\omega-1)}}=\otilde{md^{2(\omega-1)}}$
time, as the mixing rate is $\otilde{d^{3}(d^{2}+\sqrt{m})}$.
\end{proof}
%
\begin{proof}
[Proof of Proposition~\ref{thm:LSPSD}] We define $g_{X}=g=2(d^{2}g_{1}+g_{2})$,
where for some constants $c_{1},c_{2}>0$,
\[
g_{1}(X)=M^{\T}(X\kro X)^{-1}M\qquad\text{and}\qquad g_{2}(X)=dc_{1}(\log m)^{c_{2}}M^{\T}A_{X}^{\T}W_{X}A_{X}M\,.
\]
Since $d^{2}g_{1}$ and $g_{2}$ are SSC, $g$ is also SSC due to
Lemma~\ref{lem:ssc-sum} and $\mc O^{*}(d^{3})$-symmetric due to
Lemma~\ref{lem:symmetry-addition}. As $d^{2}g_{1}$ and $g_{2}$
is SLTSC and SASC, $g$ is LTSC and ASC. Putting these together, it
follows that $g$ is $\bpar{\mc O^{*}(d^{3}),\mc O^{*}(d^{3})}$-Dikin-amenable.
Therefore, Theorem~\ref{thm:Dikin-annealing} implies that $\gcdw$
requires $\otilde{d^{5}}$ iterations of the $\dw$ with $g$. Since
the initialization and update of the Lewis weight takes $\otilde{md^{2\omega}}$
and $\otilde{md^{2(\omega-1)}}$ time \citet[Theorem 46]{lee2019solving},
the same implementation with Theorem~\ref{thm:hybridPSD} also has
the time complexity of $\otilde{md^{2(\omega-1)}}$.
\end{proof}

\subsubsection{Efficient implementation \label{proof:eff_implement}}
\begin{proof}
[Proof of Proposition~\ref{prop:oracle}] Let $v\in\R^{d_{s}}$
be a given vector, and denote $\bar{g}_{0}:=g_{1}$ and $\bar{g}_{i}:=\bar{g}_{i-1}+u_{i}u_{i}^{\T}$
for $i\in[m]$. We first prepare the column vectors $u_{i}$'s of
$U=M^{\T}A^{\T}S_{X}^{-1}$ in $\mc O(md^{2})$ time and then initialize
$\bar{g}_{0}^{-1}v$ and $\bar{g}_{0}^{-1}u_{i}$ for $i\in[m]$ in
$\mc O(md^{\omega})$ time. For $u_{i}$'s, note that $S_{X}$ can
be prepared in $\mc O(md^{2})$ time, and thus $A^{\T}S_{X}^{-1}$
takes $\mc O(md^{2})$ time due to $A\in\R^{d^{2}\times m}$. Since
each row of $M^{\T}\in\R^{d_{s}\times d^{2}}$ has at most two non-zero
entries, we can obtain $u_{i}$'s in $\mc O(md^{2})$ time.

For $\bar{g}_{0}^{-1}v$ and $\bar{g}_{0}^{-1}u_{i}$, we recall from
Lemma~\ref{prop:metricFormula} that for a vector $z\in\R^{d_{s}}$
\begin{align*}
g_{1}^{-1}z & =M^{\dagger}(X\kro X)(M^{\dagger})^{\T}z=LN(X\kro X)NL^{\T}z\,.
\end{align*}
Since each row of $L^{\T}\in\R^{d^{2}\times d_{s}}$ has at most two
non-zero entries, $w:=L^{\T}z\in\R^{d^{2}}$ can be computed in $\mc O(d^{2})$
time. From the definition of $N$, it follows that $Nw=\vec\bpar{\half(W+W^{\T})}$
for $W:=\vec^{-1}(w)\in\Rdd$, which also can be computed in $\mc O(d^{2})$
time. For $\overline{W}:=\half(W+W^{\T})$, it follows that
\[
(X\kro X)Nw=(X\kro X)\vec(\overline{W})\underset{\text{Lemma \ref{lem:Kronecker}-1}}{=}\vec(X\overline{W}X)\,,
\]
which can be computed in $\mc O(d^{\omega})$ time by the fast matrix
multiplication, and in a similar way we can compute $LN\,\vec(X\overline{W}X)$
in $\mc O(d^{2})$ time. Putting all these together, $\bar{g}_{0}^{-1}v$
can be computed in $\mc O(d^{\omega})$ time, and repeating this for
$u_{j}$'s yields $\{\bar{g}_{0}^{-1}v,\bar{g}_{0}^{-1}u_{1},\dots,\bar{g}_{0}^{-1}u_{m}\}$
in $\mc O(md^{\omega})$ time.

Starting with these initializations, we recursively use the Sherman--Morrison
formula: for $z\in\R^{d_{s}}$,
\begin{equation}
\bar{g}_{i}^{-1}z=\bar{g}_{i-1}^{-1}z-\frac{\bar{g}_{i-1}^{-1}u_{i}u_{i}^{\T}\bar{g}_{i-1}^{-1}z}{1+u_{i}^{\T}\bar{g}_{i-1}^{-1}u_{i}}\,.\label{eq:sherman-morrison}
\end{equation}
Using $\bar{g}_{i-1}^{-1}u_{j}$ and $\bar{g}_{i-1}^{-1}v$ from a
previous iteration, we can compute each of $\bar{g}_{i}^{-1}u_{j}$
and $\bar{g}_{i}^{-1}v$ in the current iteration in $\mc O(d^{2})$
time, and thus each round for update takes $\mc O(md^{2})$ time in
total. Since we iterate for $m$ rounds, Algorithm~\ref{alg:subroutine}
outputs $\bar{g}_{m}^{-1}v=g(X)^{-1}v$ in $\mc O(md^{\omega}+m^{2}d^{2})$
time.
\end{proof}
%
\begin{proof}
[Proof of Lemma~\ref{lem:perStep-small-m}] Here we provide details
of Algorithm~\ref{alg:perStep-small-m} in two stages -- (1) sampling
from $\ncal\bpar{0,\frac{r^{2}}{d}g(x)^{-1}}$ and (2) computation
of acceptance probability.

\paragraph{(1) Gaussian sampling:}

For simplicity, we ignore $r^{2}/d$ and illustrate how to draw $v\sim\ncal(0,g(X)^{-1})$
without full computation of $g(X)^{-1}$ in $\mc O(md^{\omega}+m^{2}d^{2})$
time.

Our approach is to compute $v:=g(X)^{-1}\left[\begin{array}{cc}
B & U\end{array}\right]w$ for $w\sim\ncal(0,I_{d^{2}+m})$, which follows the Gaussian distribution
with covariance
\begin{align*}
g(X)^{-1}\left[\begin{array}{cc}
B & U\end{array}\right]\Bpar{g(X)^{-1}\left[\begin{array}{cc}
B & U\end{array}\right]}^{\T} & =g(X)^{-1}(BB^{\T}+CC^{\T})g(X)^{-1}g(X)^{-1}\,,
\end{align*}
since $v$ is a linear transformation of the Gaussian random variable
$w$, and $BB^{\T}+CC^{\T}=g(X)$.

Denoting $w=(w_{b},w_{u})$ for $w_{b}\sim\ncal(0,I_{d^{2}})$ and
$w_{u}\sim\ncal(0,I_{m})$, we can show that $\left[\begin{array}{cc}
B & U\end{array}\right]w$ can be computed in $\mc O(d^{\omega}+md^{2})$ time as follows:
\begin{align*}
\left[\begin{array}{cc}
B & U\end{array}\right]w & =Bw_{b}+Uw_{c}=M^{\T}\underbrace{(X\kro X)^{-1/2}w_{b}}_{\text{Use Lemma \ref{eq:sherman-morrison}}}+M^{\T}A^{\T}S_{X}^{-1}w_{c}\\
 & =M^{\T}\Bpar{\vec\bpar{X^{-1/2}\vec^{-1}(w_{b})\,X^{-1/2}}+A^{\T}S_{X}^{-1}w_{c}}\,,
\end{align*}
where $\vec\bpar{X^{-1/2}\,\vec^{-1}(w_{b})\,X^{-1/2}}$ and $A^{\T}S_{X}^{-1}w_{u}$
can be computed in $\mc O(d^{\omega})$ and $\mc O(md^{2})$ time,
respectively. Since each row of $M^{\T}\in\R^{d_{s}\times d^{2}}$
has at most two non-zero entries, $\left[\begin{array}{cc}
B & U\end{array}\right]w$ can be computed in $\mc O(d^{\omega}+md^{2})$ time. Using Algorithm~\ref{alg:subroutine},
we obtain $v=g(X)^{-1}\left[\begin{array}{cc}
B & U\end{array}\right]w$ in $\mc O(md^{\omega}+m^{2}d^{2})$ time.

\paragraph{(2) Computation of acceptance probability. }

We show that this step also takes $\mc O(md^{\omega}+m^{2}d^{2})$
time. To compute $\det g(X)$, we use Algorithm~\ref{alg:subroutine}
to prepare $\{\bar{g}_{i}^{-1}u_{1},\dots,\bar{g}_{i}^{-1}u_{m}\}_{i=0}^{m}$
at $X$ and $Y=\svec^{-1}(y)$ in $\mc O(md^{\omega}+m^{2}d^{2})$
time. Recall the matrix determinant lemma:
\[
\det(A+uu^{\T})=(1+u^{\T}A^{-1}u)\,\det A\,.
\]
 Using the following recursive formula
\begin{align*}
\det(\bar{g}_{i+1}) & =\det(\bar{g}_{i}+u_{i+1}u_{i+1}^{\T})=(1+u_{i+1}^{\T}\bar{g}_{i}^{-1}u_{i+1})\,\det\bar{g}_{i}\,,
\end{align*}
we start with $\det\bar{g}_{0}=\det g_{1}=2^{d(d-1)/2}(\det X)^{-(d+1)}$
(see Lemma~\ref{lem:Kronecker}-7), which can be computed in $\mc O(d^{\omega})$
time, and compute $\det g(X)$ (and $\det g(Y)$ in the same way)
in $\mc O(md^{\omega}+m^{2}d^{2})$ time.
\end{proof}


\subsubsection{Handling approximate Lewis weights \label{proof:Handling-approximate-Lewis}}
\begin{proof}
[Proof of Lemma~\ref{lem:onestep-app-Lewis}] We just reproduce
the proof of Lemma~\ref{lem:one-step}. For $\pi\propto\exp(-f)\cdot\mathbf{1}_{K}$,
we denote 
\[
p_{x}=\ncal\Bpar{x,\frac{r^{2}}{d}g(x)^{-1}},\qquad R_{x}(z)=\frac{p_{z}(x)}{p_{x}(z)}\frac{\pi(z)}{\pi(x)},\qquad A_{x}(z)=\min\bpar{1,R_{x}(z)\,\mathbf{1}_{K}(z)}\,.
\]
Then the transition kernel of the $\dw$ started at $x$ can be written
as 
\begin{align*}
\widetilde{P}(x,dz) & =\underbrace{(1-\E_{p_{x}}[A_{x}(\cdot)])}_{=:r_{x}}\,\delta_{x}(\D z)+A_{x}(z)\,p_{x}(z)\,\D z\,.%\widetilde{P}(x,S)
\end{align*}
Thus, for $x,y\in\intk$ 
\begin{align*}
\dtv(P_{x},P_{y}) & =\underbrace{\frac{r_{x}+r_{y}}{2}}_{\textsf{I}}+\underbrace{\half\int|A_{x}(z)\,p_{x}(z)-A_{y}(z)\,p_{y}(z)|\,\D z}_{\textsf{II}}\,.
\end{align*}
\end{proof}
We note that $(1-\delta)\,\wt g_{2}\preceq g_{2}\preceq(1+\delta)\,\wt g_{2}$
and thus 
\begin{equation}
(1-\delta)\,\wt g\preceq g\preceq(1+\delta)\,\wt g\,,\label{eq:closeness-approx}
\end{equation}
and this implies $(1-\delta)\,I\preceq\wt g^{-1/2}g\wt g^{-1/2}\preceq(1+\delta)\,I$.
Hence, $(1-\delta)^{d^{2}/2}\leq\sqrt{\frac{\det g}{\det\wt g}}\leq(1+\delta)^{d^{2}/2}$
and 
\begin{align}
(1-\delta)^{d^{2}}\sqrt{\frac{\det\wt g(z)}{\det\wt g(x)}} & \leq\sqrt{\frac{\det g(z)}{\det g(x)}}\leq(1+\delta)^{d^{2}}\sqrt{\frac{\det\wt g(z)}{\det\wt g(x)}}\,.\label{eq:similar-ratio-approx}
\end{align}

With this in mind, recall that 
\[
r_{x}=1-\E_{p_{x}}[A_{x}(\cdot)]=1-\int\min\Bpar{1,\,\underbrace{\mathbf{1}_{K}(z)\frac{\exp(-f(z))}{\exp(-f(x))}}_{\eqqcolon\textsf{A}}\underbrace{\frac{p_{z}(x)}{p_{x}(z)}}_{\eqqcolon\textsf{B}}}\,p_{x}(z)\,\D z.
\]
We can bound $\textsf{A}$ in a similar way by using (\ref{eq:closeness-approx}).
As for $\textsf{B}$, 
\[
\log\text{\textsf{B}}=-\frac{d}{2r^{2}}(\snorm{z-x}_{z}^{2}-\snorm{z-x}_{x}^{2})+\half(\log\det\widetilde{g}(z)-\log\det\widetilde{g}(x))\,.
\]
As in Lemma~\ref{lem:one-step}, the second term can be bounded lower
by $\exp\Par{-3\veps}$ using (\ref{eq:similar-ratio-approx}). The
first term can be lower-bounded by invoking ASC of $g$. To see this,
ignoring the normalization constant of $g_{x}$ 
\begin{align*}
(*)= & \int\mathbf{1}\Bpar{\snorm{z-x}_{\widetilde{g}(z)}^{2}-\snorm{z-x}_{\widetilde{g}(x)}^{2}\leq2\veps\frac{r^{2}}{d}}\sqrt{\Abs{\widetilde{g}(x)}}\exp\bpar{-\half\snorm{z-x}_{\widetilde{g}(x)}^{2}}\,\D z\\
= & \int\mathbf{1}\Bpar{\snorm{z-x}_{\widetilde{g}(z)}^{2}-\snorm{z-x}_{\widetilde{g}(x)}^{2}\leq2\veps\frac{r^{2}}{d}}\sqrt{\Abs{g(x)}}\exp\bpar{-\half\snorm{z-x}_{g(x)}^{2}}\\
 & \qquad\cdot\sqrt{\Abs{\frac{\widetilde{g}(x)}{g(x)}}}\exp\bpar{-\half(\snorm{z-x}_{\widetilde{g}(x)}^{2}-\snorm{z-x}_{g(x)}^{2})}\,\D z\\
\leq & \int\mathbf{1}\Bpar{\snorm{z-x}_{\widetilde{g}(z)}^{2}-\snorm{z-x}_{\widetilde{g}(x)}^{2}\leq2\veps\frac{r^{2}}{d}}\sqrt{\Abs{g(x)}}\exp\bpar{-\half\snorm{z-x}_{g(x)}^{2}}\\
 & \qquad\cdot(1+\delta)^{d^{2}/2}\exp\bpar{\frac{\delta}{2}\snorm{z-x}_{g(x)}^{2}}\,\D z\,.
\end{align*}
Due to $\snorm{z-x}_{g(x)}^{2}\lesssim r^{2}$ w.h.p., taking $\delta=\veps/d^{10}$
leads to 
\[
(*)\leq2\int\mathbf{1}\Bpar{\snorm{z-x}_{\widetilde{g}(z)}^{2}-\snorm{z-x}_{\widetilde{g}(x)}^{2}\leq2\veps\frac{r^{2}}{d}}\sqrt{\Abs{g(x)}}\exp\bpar{-\half\snorm{z-x}_{g(x)}^{2}}\,\D z.
\]
Also, due to 
\begin{align*}
\snorm{z-x}_{\widetilde{g}(z)}^{2}-\snorm{z-x}_{\widetilde{g}(x)}^{2} & \geq(1-\delta)\,\snorm{z-x}_{g(z)}^{2}-(1+\delta)\,\snorm{z-x}_{g(x)}^{2}\\
 & =(1-\delta)\,(\snorm{z-x}_{g(z)}^{2}-\snorm{z-x}_{g(x)}^{2})-2\delta\,\snorm{z-x}_{g(x)}^{2}\,,
\end{align*}
we have 
\begin{align*}
(*) & \leq2\int\mathbf{1}\Bpar{\snorm{z-x}_{g(z)}^{2}-\snorm{z-x}_{g(x)}^{2}\leq(2\veps(1-\delta)^{-1}+\veps)\,\frac{r^{2}}{d}}\sqrt{\Abs{g(x)}}e^{-\half\snorm{z-x}_{g(x)}^{2}}\,\D z\leq6\veps
\end{align*}
by invoking ASC of $g$ in the last inequality. Putting these together,
$\msf I\leq\half+\mc O(\veps)$. For $\msf{II}$, we can follow the
proof of Lemma~\ref{lem:one-step} to show $\msf{II}\leq\frac{1}{4}+\mc O(\veps)$,
and every technical issue can be resolved by repeating the same techniques
above.
