% \vspace{-0.05in}
\nsection{Evaluation against Adaptive Attacks} \label{sec:adaptive_attacks}

% In \S\ref{sec:eval} and \S\ref{sec:end_to_end_eval}, we demonstrate the effectiveness of \ld{} at detecting and responding to existing state-of-the-art lateral-direction localization attack. 
In this section, we take a step further to examine \ld{}'s capability under potential adaptive attacks, including (1) an idealized stealthy attack that can evade the detection, and (2) the latest LD-side attack, which is the inherent new attack surface introduced by \ld{} approach (\S\ref{sec:design_challenges}).

% \vspace{-0.05in}
\nsubsection{Stealthy Attack Evaluation} \label{sec:stealthy_attack}
\vspace{0.05in}

% Since the evaluation in the above sections are all based on \fr{}, which does not assume the existence of defenses such as \ld{}. However, \fr{} is a realistic evaluation target since it is by far the only attack that can break the MSF localization on high-level AD systems. Nevertheless, 
In this evaluation, we analyze the maximum lateral deviations that a hypothetical stealthy attack can achieve by assuming stronger and unrealistic attack capabilities.

% assume the attacker can have \textit{precise} and \textit{instant} control over the lateral deviations in the MSF localization outputs, and evaluate the maximum lateral deviations a hypothetical stealthy attack can cause without being detected.

\textbf{Evaluation methodology.}
Based on the CUSUM anomaly detection formulation (\S\ref{sec:design_detection}), the attack should satisfy $S_{i-1} + \lvert D_i^{\text{MSF}} - D_i^{\text{LD}} \rvert - b < \tau$ in order to prevent detection. Assuming the last CUSUM statistic $S_{i-1} = 0$, the maximum MSF lateral deviation without being detected is thus $D_{i, max}^{\text{MSF}} = D_i^{\text{LD}} + \tau + b$, which is also the maximum physical world deviation given the control assumption (\S\ref{sec:background_threat_model}).
% As shown, the deviation that a stealthy attack can cause depends on the CUSUM parameters and the LD lateral deviation.
Since $\tau$ and $b$ are fixed in the defense, the attacker can carefully select a timing where the LD has a large lateral deviation fluctuation to the actual vehicle location due to detection noises, and apply the MSF lateral deviation to the same direction as the LD's fluctuation direction to achieve a large physical world deviation. Therefore, the attacker's capability on capturing a particular LD fluctuation window determines the maximum physical world deviations she can achieve without being detected. Thus, we evaluate the maximum physical world deviations by assuming various levels of LD fluctuations that the attacker can capture.

% that the attacker can capture particular levels of LD fluctuations. 

\textbf{Assumptions on attack capabilities.}
In this evaluation, we assume the attacker has very unrealistic attack capabilities in order to achieve such a stealthy attack. In particular, the attacker should have a \textit{white-box knowledge} on (1) where exactly on the road that the LD will have a large fluctuation and how much it is, and (2) the attack detection method and parameters used in the target AD system. Moreover, the attacker should also have \textit{precise} and \textit{instantaneous} control over the lateral deviations in the MSF localization outputs in order to execute such attack when large fluctuations appear.

\cut{
\begin{table}[tbp]
\centering
\footnotesize
\caption{Maximum physical deviations can be achieved without being detected under various LD fluctuation assumptions. The percentages indicate the probabilities of such fluctuations.}
\vspace{-0.1in}
\label{tbl:stealthy_detection}
% \setlength{\tabcolsep}{5pt}
\begin{tabular}{@{}ccccc@{}}
\toprule
\multirow{2}{*}{Trace} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}LD fluctuation\\ ($\mu, \sigma$)\end{tabular}} & \multicolumn{3}{c}{Max physical world deviation} \\ \cmidrule(l){3-5} 
 &  & 0 (100\%) & $\mu$ (50\%) & $\mu+3\sigma$ (0.3\%) \\ \midrule
\textit{ka-local31} & 0.12m, 0.08m & 0.7m & 0.82m & 1.06m \\
\textit{ka-local33} & 0.14m, 0.10m & 0.7m & 0.84m & 1.14m \\
\textit{ka-highway36} & 0.29m, 0.10m & 0.7m & 0.99m & 1.29m \\
\textit{ka-highway18} & 0.20m, 0.11m & 0.7m & 0.90m & 1.23m \\ \bottomrule
\end{tabular}
\vspace{-0.05in}
\end{table}
}

\textbf{Results.}
Table~\ref{tbl:stealthy_detection} shows the maximum physical world deviations that the stealthy attack can achieve under different LD fluctuation assumptions. Specifically, we calculate LD fluctuation distributions in each trace and assume that the attacker knows where a certain level of fluctuation happens. Without any such assumptions, the attacker can at most inject $\tau+b=0.7$ m lateral deviation, which is just about to touch the lane boundaries. On the other hand, the attacker can \textit{at most} cause 0.99 m and 1.29 m lateral deviations on the 4 traces if she can capture an average and a 3-$\sigma$ LD fluctuation, respectively. Note that the probabilities of such fluctuations to appear are 50\% and 0.3\% according to the normal distribution. In conclusion, even under very unrealistic attack assumptions, the maximum lateral deviations are still less than the local road attack goal (1.3 m) for \fr{}, which shows that \ld{} is quite effective at bounding the lateral deviations. Moreover, it also highlights that LD is indeed a mature technology (\S\ref{sec:opportunity}) suitable for defense given its high stability.
% means that LD is a reliable defense source due to its stability. 

% \begin{table}[tbp]
% \centering
% \footnotesize
% \caption{Maximum deviations that can be achieved without being detected by \ld.}
% \label{tbl:stealthy_detection}
% \setlength{\tabcolsep}{2pt}
% \begin{tabular}{@{}cccc@{}}
% \toprule
% Trace & \begin{tabular}[c]{@{}c@{}}Max Dev w/o\\ Detection\end{tabular} & \begin{tabular}[c]{@{}c@{}}Lane Straddle\\ Dev\end{tabular} & \begin{tabular}[c]{@{}c@{}}Attack Goal\\ Dev\end{tabular} \\ \midrule
% ka-local31 & 1.39 & 0.7 & 1.3 \\
% ka-local33 & 1.06 & 0.7 & 1.3 \\
% ka-highway36 & 1.18 & 0.7 & 1.9 \\
% ka-highway18 & 1.13 & 0.7 & 1.9 \\ \bottomrule
% \end{tabular}
% \end{table}


% risk to build upon consecutive frames, clearly say we assumed the max attack capability, instant influence on physical world deviation, can precisely control timing and deviationr


% To detection: prevent detection, achieve large deviation Table~\ref{tbl:stealthy_detection}.

% highway18 max adaptive deviation:
% 1.13 m = 0.43 (LD max deviation in benign case) + 0.6 (cusum bias) + 0.1 (cusum threshold)
% highway36
% 1.18 m = 0.48 (LD max deviation in benign case) + 0.6 (cusum bias) + 0.1 (cusum threshold)
% local31
% 1.39 m = 0.59 + 0.7 + 0.1
% local33
% 1.06 m = 0.36 + 0.6 + 0.1

% \junjie{Future work: need an evaluation where we attack from LD side to trigger detection, but no adaptive design in AR.}

% Figure environment removed

% \vspace{-0.05in}
\nsubsection{LD-side Adaptive Attack Evaluation} \label{sec:ld_attack}
\vspace{0.05in}

% \newparts{
% Since \ld{} uses lane detection as a defense source, a direct adaptive attack direction is thus LD-side attacks. Therefore, 
% In this section, we evaluate \ld{} against LD-side attacks.}
% , which are direct adaptive attack direction to \ld{}.}

\newparts{
\textbf{Evaluation methodology.}
We explore the defense capability of \ld{} against the latest LD attack in production low-level AD systems, 
named Dirty Road Patch (DRP) attack~\cite{sato2021dirty}, which is designed to affect the detected lane line shapes to mislead the automated lane centering system to drive the vehicle out of the lane boundaries. 
In LD, the lane line shapes are represented as polynomial functions, which are used in \ld{} to calculate the vehicle's lateral deviations  (Appendix~\ref{app:design_impl}). 
% Therefore, in our evaluation, we focus on the attacked lane line polynomials influenced by DRP attack. 
From the 40 attack traces used in the original DRP attack paper, we extract the attacked lane line polynomials in each frame and calculate an averaged LD deviation trace.
In \ld{} design, LD attacks cannot disrupt the driving behaviors before the attack is detected since only MSF outputs are used for navigation at this moment.
To cause vehicle deviations, the LD attack has to trigger the detection in the first place and affect the \textit{fused} localization in the AR period (\S\ref{sec:design_ar}) in order to affect the vehicle control. Therefore, we focus on the AR period in our evaluation. 
To model the DRP attack effect, we apply the deviation trace (start from the detection deviation 0.7 m) to the LD side in the KAIST traces.
Since the MSF side is benign and should generally well-align with the physical positions of the vehicle, we set the MSF outputs in the AR period with the same deviation as the fused localization, but to the opposite direction based on the control assumption (\S\ref{sec:background_threat_model}).}

\newparts{
\textbf{Results.} Fig.~\ref{fig:ld_attack_devs} shows the maximum and stopping deviations in KAIST traces. As shown, none of them is able to even cause lane straddling. On average, the maximum and stopping deviations in the AR period are only 0.08 m ($\delta=0.08$ m) and 0.02 m ($\delta=0.03$ m), respectively. Such a result indicate that \ld{} is quite robust to adaptive attack to the LD side as well. This is because the safety-driven fusion (\S\ref{sec:design_ar}) in \ld{} can effectively penalize the more aggressive source in the driving context, which in this case is the attacked LD outputs, and prevent the fused localization from being influenced by it.}


