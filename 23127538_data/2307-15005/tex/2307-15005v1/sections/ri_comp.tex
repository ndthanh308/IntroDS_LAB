%------------------------------------------------------------------------------
\section{FL\lowercase{i}CR: Range Image Compression}
\label{sec:ricomp}
%------------------------------------------------------------------------------
Following selecting RI as the appropriate IR, the compression also needs to be efficient, low-latency, and lightweight.
In this section, we describe how to achieve the objectives of the compression method.
First, we identify the distortion issue of the current image codecs to LiDAR RIs.
Second, we explore the opportunity of lossy RIs for the downstream compression steps via RI quantization and subsampling.
We argue the lossless bytestream compressions can be hugely enhanced in terms of the compression efficiency and low latency through the lossy representation.
However, it compromises the point cloud quality, and we present the possible issues of FLiCR with lossy RIs.


\begin{table}[htbp]
  \caption{The compression ratios and qualities of H.264 with different QPs for 100 RIs of 4500$\times$64 and 8 bpp.}
  \begin{center}
  \begin{tabular}{ |c|c|c|c|c| }
    \hline
                            & QP 0    & QP 10 & QP 20  & QP 30 \\ \hline
    Compression Ratio       & 12.85   & 13.33 & 16.41  & 35.01 \\ \hline
    PSNR (dB)               & 63.18   & 48.21 & 37.61  & 38.12 \\ \hline
    CD (cm)                 & 2.23    & 16.25 & 126.06 & 107.16\\ \hline
  \end{tabular}
  \end{center}
  \label{tab:qpt}
\end{table}

% Figure environment removed



\subsection{Issues with Current Image Compressions}
\label{sec:issuecodecs}
By representing LiDAR point clouds as images, it becomes possible to leverage the existing image-processing infrastructures and techniques.
With the popularity of video streaming, modern processor platforms and GPUs are equipped with dedicated hardware modules for the standard codecs such as H.264 and HEVC~\cite{intelquicksink, snapd, nvcodec}.
These codecs efficiently encode and decode continuous images with spatial and temporal optimizations~\cite{richardson2004h, sullivan2012overview}, and the pervasive accelerators enable the codecs in a low-latency and efficient way even with commodity mobile devices.

In this context, it seems appropriate to rely on the existing codecs with hardware accelerators at first glance.
However, we argue the existing codecs specialized for human vision are hardly applicable to RI compression.
The lossy image compression algorithms for human vision fully utilize
the characteristics of the human eyes to remove the data with minimal impacts to visual quality as much as possible; one example is to convert an image into the frequency domain via  discrete cosine transform (DCT) or fast Fourier transform (FFT) and the high frequency has more loss than the low-frequency data~\cite{richardson2004h, sullivan2012overview, marcellin2000overview}.
While the techniques that leverage the nature of human vision work well for normal images, the point cloud details are effectively lost as a result of the frequency-domain loss in LiDAR RIs.


Figure~\ref{fig:qp} shows the reconstructed point clouds from the RIs encoded and decoded via H.264 with different quantization parameters (QP).
QP regulates how much spatial detail is retained and is set from 0 for lossless to 51 for the most lossy compression.
As QP increases, the spatial detail is aggregated so that the encoded bit rate drops at the expense of data loss, resulting in lower quality~\cite{richardson2004h}.
The reconstructed point clouds become vague and noisy with high QPs.
Table~\ref{tab:qpt} shows the averaged compression ratio and quality metrics of the reconstructed point cloud with different QPs.
With the visual results of the reconstructed point clouds, the PSNR and CD results become worse drastically while the compression ratio increases moderately.
Considering that the quantization parameter such as QP or CRF of video streaming is usually set around 20 and 30 as a rule of thumb (FFmpeg's H.264 default CRF is 23~\cite{ffmpegh264}), these results show the current human-vision codecs are unsuitable for the RI compression.
For preserving the quality of point clouds, the codec quantization parameter should be set for lossless (QP 0), but it is at the cost of the lower compression efficiency, as Google Draco achieves $\sim$33\% higher compression ratio in Table~\ref{tab:expcc}.



\begin{table}[htbp]
  \caption{The existing quality metrics with sampling error (SE) for the subsampled RIs of 8 bpp.}
  \begin{center}
  \begin{tabular}{ |c|c|c|c|c| }
    \hline
               & 2048$\times$64    & 1024$\times$64 & 512$\times$64  & 256$\times$64 \\ \hline
     PSNR (dB) & 62.4              & 61.41          & 58.61          & 53.71         \\ \hline
     CD (cm)   & 5.37              & 9.23           & 15.22          & 36.17         \\ \hline
     SE        & 21.03\%           & 58.77\%        & 78.95\%        & 89.22\%       \\ \hline
  \end{tabular}
  \label{tab:oldmetrics}
  \end{center}
\end{table}

% Figure environment removed



\subsection{RI Quantization and Subsampling}
RI has been used for losslessly mapping LiDAR point clouds to 2D
frames, and previous work only applies quantization of bit-per-point (bpp)~\cite{tu2019real, tu2019point, tu2016compressing, ahn2014large, feng2020real, houshiar20153d}.
In these prior works, the main objective is to maximize the compression efficiency while maintaining the point cloud quality as high as possible.
However, we argue that there are more optimization opportunities with lossy RI to decrease not only the data size but the downstream compression tasks' complexities.
Specifically, the RI resolution is determined by the sensor's precisions as mentioned in Section~\ref{sec:ir}, and the subsampling of point clouds can be done by adjusting the precision parameters; the 3D points are coarsely mapped to a 2D frame.
Figure~\ref{fig:subsample} shows the visualizations of reconstructed point clouds from the subsampled RIs.
From the raw point cloud of Figure~\ref{fig:rawpcrep}, we reduced the precision parameters to map it to the RIs of four different lower resolutions.
Even with the lowest subsampled RI of 16 KB with 8 bpp, the shapes of scanned objects are recognizable.


While the subsampled and quantized RI has advantages for data reduction and compression with lower latencies, it would affect the performance of the perception tasks.
So, a quality metric for the point clouds from lossy RIs needs to reflect both the quantization and subsampling errors.
The currently used metrics, PSNR and CD, reflect the quantization error well, but the sampling error of lossy RIs is not represented effectively as these metrics are defined with the point-to-point distances between point clouds (see Section~\ref{sec:metric} for more details).

Table~\ref{tab:oldmetrics} shows PSNR, CD, and sampling error (SE) of the point clouds from four RI resolutions.
In the results, the changes of PSNR and CD exhibit different trends from SE because SE is about the number of lost points from the original point cloud (the entropy-wise quality) while PSNR and CD are with the distances of the closest point pairs between two point clouds (the point-wise quality).

The current metricsâ€™ issue is they only count the point-to-point distances, and each point distance is calculated by finding the nearest point in the comparing point cloud. So, when the point clouds have different numbers of points, they are limited to represent this difference in the total number of points in the point clouds.
To address the limitations of the existing metrics, we propose a unified metric for both the point-wise quality and the information amount to measure quantitatively the impacts on the downstream perceptions from lossy RIs in Section~\ref{sec:metric}.

% Figure environment removed



\subsection{Lossless Compression with Lossy RIs}

% Figure environment removed

As shown in Section~\ref{sec:issuecodecs}, the application of lossy
video codecs to RIs results in lower compression efficiency or can distort the point clouds in the 3D space.
The previous RI compression methods apply the image compression algorithm at lower efficiencies or propose effective lossless RI compression algorithms via spatial and temporal optimizations~\cite{ahn2014large, feng2020real, houshiar20153d, tu2016compressing, tu2019point, tu2019real}.
%However, they only leverage the quantization of bit precisions with lossless RI mapping and their complex algorithms have downsides for low-latency and lightweight while showing high compression ratios.
However, they partially leverage the opportunities of lossy RIs only
with  bit quantization, and their complex algorithms have downsides
% low-latency and lightweight
in terms of latency and overheads, while showing high compression ratios.
For satisfying the low-latency, lightweight, and efficiency requirements, we use the existing bytestream compression algorithm, dictionary coding, and enhance its efficiency by fully leveraging the RI quantization and subsampling.

Dictionary coding is a lossless compression algorithm for bytestreams
and deflates the bytestream by replacing the repeating patterns with shorter references.
Dictionary coding algorithms have been extensively studied with corpus
text data, and they are with simple bit/byte operations and lower
computation complexities in terms of the space-time tradeoff~\cite{shanmugasundaram2011comparative}.
So, they provide the benefits of being lightweight and low-latency, with simple operations and do not distort point clouds unexpectedly.
Even with such advantages, the direct application of bytestream compressions to the raw point cloud and unquantized RIs of floating values is inefficient in terms of the compression ratio (RLE and Dict Coding in Table~\ref{tab:expcc} and Figure~\ref{fig:losslesscr}).

To improve the efficiency, we fully utilize both quantization and subsampling.
The underlying assumption of our approach is dictionary coding uses the repeating features in a bytestream and there is a higher probability of recurring patterns when limiting the representation space of quantized RIs.
The compression pipeline is shown in Figure~\ref{fig:rioverview}.
FLiCR with dictionary coding has similarity to previous RI-based works in terms of leveraging local spatial features, but it is more advantageous in meeting the requirements with its simplicity.
Explicitly, compared to the recent RI-based compression (RT-ST~\cite{feng2020real} in Table~\ref{tab:expcc}), FLiCR shows lower encoding and decoding latencies and energy usage, with the higher compression ratio, as shown in Table~\ref{tab:oursvsdraco}.

Among the dictionary coding algorithms, we use LZ77~\cite{ziv1977universal} and compare it with RLE.
We measure the efficiency improvement and quality reduction by the quantization and subsampling with LZ77 and RLE, and Figure~\ref{fig:losslessours} shows the results of different resolutions of RIs quantized by 8 bpp.
While the end-to-end latencies of the whole compression pipeline can
decrease only with subsampling (see Figure~\ref{fig:losslesslat}),
both quantization and subsampling are required to improve the
compression ratios effectively, as shown in Figure~\ref{fig:losslesscr}.
Then, dictionary coding shows  larger growth than RLE, and these results support our assumption about the performance improvement of dictionary coding with lossy RIs.

Although FLiCR achieves compression efficiency and reduced latency, it
is at the cost of degradation of the point cloud quality by the quantization and subsampling errors, as shown in Figures~\ref{fig:losslesspsnr} and~\ref{fig:losslesscd}.
Since the reduced point cloud quality can have an impact on the downstream perceptions, we evaluate FLiCR with the state-of-the-art LiDAR perceptions and analyze the errors' impacts in Section~\ref{sec:eval}.

% Figure environment removed

Figure~\ref{fig:latbreak} shows the latency breakdowns of FLiCR on our testbed.
In the case where Jetson is a mobile client and the desktop is a server, the end-to-end latency is $\sim$39 ms ($\sim$60\% of Google Draco~\cite{draco}) even with the highest RI resolution; it takes 27 ms for client encoding and 12 ms for server decoding.
With the 256$\times$64 resolution, the end-to-end latency is $\sim$10 ms which is $\sim$16\% of Draco.
Since the large portion of the end-to-end latency is the conversion time between the point cloud and RI, the end-to-end latencies can be largely reduced if a device has a dedicated hardware logic for the RI conversion.
As the RI resolution gets lower, the quantization and compression latencies decrease.
These results show FLiCR fully leverages the synergistic effect by quantization and subsampling for the bytestream compressions.
