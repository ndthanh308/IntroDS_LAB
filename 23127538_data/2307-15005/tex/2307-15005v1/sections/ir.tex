%------------------------------------------------------------------------------
\section{Intermediate Representations for FL\lowercase{i}CR}
\label{sec:ir}
%------------------------------------------------------------------------------

For meeting the aforesaid requirements, it is important to select a proper IR because the compression is dependent on each IR.
In this section, we microbenchmark the IR conversions and point out the benefit of range images (RIs) over the others in the context of enabling remote online perceptions.

\begin{table}[htbp]
  \caption{The latencies (ms) of each IR construction.}
  \begin{center}
  \begin{tabular}{ |c|c|c|c|c|c| }
    \hline
             & RI    & Parallel RI   & Octree & K-d tree & Mesh \\ \hline
     Desktop & 11.78 & \textbf{6.72} & 30.67  & 13.21    & 1872 \\ \hline
     Jetson  & 16.34 & \textbf{9.26} & 32.11  & 32.44    & 2755 \\ \hline
  \end{tabular}
  \label{tab:riconv}
  \end{center}
\end{table}

Table~\ref{tab:riconv} shows the conversion latencies of the IRs with the LiDAR point clouds from the KITTI dataset~\cite{geiger2013vision}.
We use PCL~\cite{rusu20113d} implementations for octree and k-d tree,
and mesh conversion is based on the algorithm of Marton \emph{et al.}~\cite{marton2009fast}.
The RI conversion is our implementation, and the parallelized version is with OpenMP~\cite{dagum1998openmp}.
The RIs are generated by converting the raw points in the 3D Cartesian coordinates to the spherical coordinates.
Equation~\ref{eq:1} shows the conversion and $r$, $\theta$, and $\phi$ are the radial distance, polar angle, and azimuthal angle each.
When $\theta$ and $\phi$ are calculated, they are mapped to the frame pixel by the sensor's angular precisions.
For example, Velodyne HDL-64E used in the KITTI dataset has 0.08\textdegree~and 0.35\textdegree~for horizontal and azimuthal precisions with 360\textdegree~of the horizontal field of view (FoV) and 64 vertical lasers~\cite{hdl64}.
Thus, each scan's point cloud would be mapped to a 2D frame of 4500$\times$64.
By adjusting the parameters of precisions and FoV, RI can work on diverse LiDAR sensors.

\begin{equation}\label{eq:1}
\begin{aligned}
  r = \sqrt{x^2+y^2+z^2} \\
  \theta = arccos\left(\frac{z}{r}\right) \\
  \phi = arctan\left(\frac{y}{x}\right)
\end{aligned}
\end{equation}

In our results, the parallelized RI conversion shows the lowest latency on both desktop and Jetson as RI has advantages over other IRs in terms of simplicity and parallelism.
For the octree and k-d tree, there have been many efforts for their parallelized constructions~\cite{shevtsov2007highly, wehr2018parallel, lauterbach2009fast, karras2012maximizing, wu2011sah}.
However, as pointed out in the previous works, their hierarchical structures inherently make the construction processes sequential, and it is challenging to fully parallelize their constructions.
In contrast, the RI conversion can be easily parallelized since each point conversion of RI is completely independent from the others.
For the mesh, its generation from point clouds requires triangulation algorithms and calculating the surface normal for each mesh.
These processes require iterating each point and finding nearest
neighbors to generate a mesh, and the mesh conversion has high
computational complexity and is not suitable for real-time due to its large magnitude of execution time~\cite{marton2009fast, salman2010feature, guan2020voxel}.

Furthermore, these IRs have different theoretical complexities for the conversion.
The time complexities of the IR constructions are $O(n)$ for the RI and $O(n\log{}n)$ for the trees and mesh; the trees require  binary search for each point insertion, and the mesh construction needs nearest neighbor searches for the normal estimation and triangulation.
In addition, there is a side benefit that various image-processing techniques can be used for RIs.
Based on these observations, we adapt RI as the
target IR.

