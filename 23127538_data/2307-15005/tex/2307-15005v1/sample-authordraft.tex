\documentclass[conference, 10pt]{IEEEtran}
\IEEEoverridecommandlockouts

% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{url}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage{enumitem}

\usepackage{romannum}
\usepackage{textcomp}
\usepackage{tabularx}
\usepackage{diagbox}
\usepackage{multirow}
\usepackage{hhline}

\usepackage{bbding}
\usepackage{pifont}
\usepackage{wasysym}

\usepackage{cleveref}
\crefformat{section}{\S#2#1#3}
\crefformat{subsection}{\S#2#1#3}
\crefformat{subsubsection}{\S#2#1#3}

% for source codes
\usepackage{listings}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstset{
  %frame=tb,
  language=C++,
  backgroundcolor=\color{backcolour},
  commentstyle=\color{dkgreen},
  keywordstyle=\color{blue},
  numberstyle=\tiny\color{gray},
  stringstyle=\color{mauve},
  basicstyle={\small\ttfamily},
  breaklines=true,
  breakatwhitespace=false,
  showstringspaces=false,
  aboveskip=2mm,
  belowskip=2mm,
  columns=flexible,
  numbers=left,
  numbersep=5pt,
  captionpos=b,
  tabsize=2,
  escapeinside={(*@}{@*)}
}

% for figures & subfigures
\usepackage{graphics}
\usepackage{caption}
\usepackage{subcaption}
\graphicspath{{./figures/}}

\usepackage{amsmath}
\usepackage{mathrsfs}

\begin{document}

\title{FLiCR: A Fast and Lightweight LiDAR Point Cloud Compression Based on Lossy RI}
\author{}

\author{\IEEEauthorblockN{Jin Heo}
\IEEEauthorblockA{\textit{Georgia Institute of Technology} \\
Atlanta, Georgia, USA \\
jheo33@gatech.edu}
\and
\IEEEauthorblockN{Christopher Phillips}
\IEEEauthorblockA{\textit{Adeia} \\
Hartwell, Georgia, USA \\
chris.phillips@adeia.com}
\and
\IEEEauthorblockN{Ada Gavrilovska}
\IEEEauthorblockA{\textit{Georgia Institute of Technology} \\
Atlanta, Georgia, USA \\
ada@cc.gatech.edu}
}


%\renewcommand\footnotetextcopyrightpermission[1]{}

% Additional packages

\pagenumbering{arabic}
%\thispagestyle{plain}

\newcommand{\jin}[1]{\textcolor{blue}{JH: #1}}
\newcommand{\ada}[1]{\textcolor{red}{AG: #1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\green}[1]{\textcolor{green}{#1}}
\newcommand{\mul}{$\times$}

\newenvironment{tightitemize}%
 {\begin{list}{$\bullet$}{%
 		\setlength{\leftmargin}{10pt}
        \setlength{\itemsep}{0pt}%
        \setlength{\parsep}{0pt}%
        \setlength{\topsep}{0pt}%
        \setlength{\parskip}{0pt}%
        }%
 }%
{\end{list}}

\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}


\maketitle
\thispagestyle{plain}
\pagestyle{plain}

\begin{abstract}
Light detection and ranging (LiDAR) sensors are becoming available on modern mobile devices and provide a 3D sensing capability.
This new capability is beneficial for perceptions in various use cases, but it is challenging for resource-constrained mobile devices to use the perceptions in real-time because of their high computational complexity.
In this context, edge computing can be used to enable LiDAR online perceptions, but offloading the perceptions on the edge server requires a  low-latency, lightweight, and efficient compression due to the large volume of LiDAR point clouds data.

This paper presents FLiCR, a fast and lightweight LiDAR point cloud compression method for enabling edge-assisted online perceptions.
FLiCR is based on range images (RI) as an intermediate representation (IR), and dictionary coding for compressing RIs.
FLiCR achieves its benefits by leveraging lossy RIs, and we show the efficiency of bytestream compression is largely improved with quantization and subsampling.
In addition, we identify the limitation of current quality metrics for presenting the entropy of a point cloud, and introduce a new metric that reflects both point-wise and entropy-wise qualities for lossy IRs.
The evaluation results show FLiCR is more suitable for edge-assisted real-time perceptions than the existing LiDAR compressions, and we demonstrate the effectiveness of our compression and metric with the evaluations on 3D object detection and LiDAR SLAM.
\end{abstract}

{\let\thefootnote\relax\footnote{{Â© 2022 IEEE.  Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.}}}

\begin{IEEEkeywords}
lidar, lidar point cloud, lidar point cloud compression, 3D point cloud compression, remote lidar perceptions, real-time perception service, range image compression, edge computing
\end{IEEEkeywords}

\input{sections/introduction.tex}
\input{sections/background.tex}
\input{sections/motivation.tex}
\input{sections/ir.tex}
\input{sections/ri_comp.tex}
\input{sections/metric.tex}
\input{sections/evaluation.tex}
\input{sections/related.tex}
\input{sections/limitfuture.tex}
\input{sections/conclusion.tex}
\input{sections/acknowledgment.tex}


%\bibliographystyle{ACM-Reference-Format}
\bibliographystyle{IEEEtran}
\bibliography{sample-base}

\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.
