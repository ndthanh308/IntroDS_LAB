\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{arnab2021vivit}
Arnab, A., Dehghani, M., Heigold, G., Sun, C., Lu{\v{c}}i{\'c}, M., Schmid, C.:
  {ViVit: A video vision transformer}. In: Proceedings of the IEEE/CVF
  international conference on computer vision. pp. 6836--6846 (2021)

\bibitem{balestriero2023cookbook}
Balestriero, R., Ibrahim, M., Sobal, V., Morcos, A., Shekhar, S., Goldstein,
  T., Bordes, F., Bardes, A., Mialon, G., Tian, Y., et~al.: A cookbook of
  self-supervised learning. arXiv preprint arXiv:2304.12210  (2023)

\bibitem{carreira2017quo}
Carreira, J., Zisserman, A.: Quo vadis, action recognition? a new model and the
  kinetics dataset. In: proceedings of the IEEE Conference on Computer Vision
  and Pattern Recognition. pp. 6299--6308 (2017)

\bibitem{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., Hinton, G.: A simple framework for
  contrastive learning of visual representations. In: International conference
  on machine learning. pp. 1597--1607. PMLR (2020)

\bibitem{chen2021visformer}
Chen, Z., Xie, L., Niu, J., Liu, X., Wei, L., Tian, Q.: Visformer: The
  vision-friendly transformer. In: Proceedings of the IEEE/CVF international
  conference on computer vision. pp. 589--598 (2021)

\bibitem{das2020b}
Das, V., Prabhakararao, E., Dandapat, S., Bora, P.K.: B-scan attentive cnn for
  the classification of retinal optical coherence tomography volumes. IEEE
  Signal Processing Letters  \textbf{27},  1025--1029 (2020)

\bibitem{emre2022tinc}
Emre, T., Chakravarty, A., Rivail, A., Riedl, S., Schmidt-Erfurth, U.,
  Bogunovi{\'c}, H.: {TINC: Temporally Informed Non-contrastive Learning for
  Disease Progression Modeling in Retinal OCT Volumes}. In: Medical Image
  Computing and Computer Assisted Intervention--MICCAI 2022: 25th International
  Conference, Singapore, September 18--22, 2022, Proceedings, Part II. pp.
  625--634. Springer (2022)

\bibitem{fan2021multiscale}
Fan, H., Xiong, B., Mangalam, K., Li, Y., Yan, Z., Malik, J., Feichtenhofer,
  C.: Multiscale vision transformers. In: Proceedings of the IEEE/CVF
  international conference on computer vision. pp. 6824--6835 (2021)

\bibitem{Farsiu2014}
Farsiu, S., Chiu, S., O'Connell, R., Folgar, F.: {Quantitative classification
  of Eyes with and without intermediate age-related macular degeneration using
  optical coherence tomography}. Ophthalmology  \textbf{121}(1),  162--72
  (2014),
  \url{http://www.sciencedirect.com/science/article/pii/S016164201300612X}

\bibitem{botond2022}
Fazekas, B., Lachinov, D., Aresta, G., Mai, J., Schmidt-Erfurth, U.,
  Bogunović, H.: Segmentation of bruch's membrane in retinal oct with amd
  using anatomical priors and uncertainty quantification. IEEE Journal of
  Biomedical and Health Informatics  \textbf{27}(1),  41--52 (2023).
  \doi{10.1109/JBHI.2022.3217962}

\bibitem{hu2018squeeze}
Hu, J., Shen, L., Sun, G.: Squeeze-and-excitation networks. In: Proceedings of
  the IEEE conference on computer vision and pattern recognition. pp.
  7132--7141 (2018)

\bibitem{kurmann2019fused}
Kurmann, T., M{\'a}rquez-Neila, P., Yu, S., Munk, M., Wolf, S., Sznitman, R.:
  Fused detection of retinal biomarkers in oct volumes. In: Medical Image
  Computing and Computer Assisted Intervention--MICCAI 2019: 22nd International
  Conference, Shenzhen, China, October 13--17, 2019, Proceedings, Part I 22.
  pp. 255--263. Springer (2019)

\bibitem{lee2021vision}
Lee, S.H., Lee, S., Song, B.C.: Vision transformer for small-size datasets.
  arXiv preprint arXiv:2112.13492  (2021)

\bibitem{li2021dt}
Li, H., Yang, F., Zhao, Y., Xing, X., Zhang, J., Gao, M., Huang, J., Wang, L.,
  Yao, J.: Dt-mil: deformable transformer for multi-instance learning on
  histopathological image. In: Medical Image Computing and Computer Assisted
  Intervention--MICCAI 2021: 24th International Conference, Strasbourg, France,
  September 27--October 1, 2021, Proceedings, Part VIII 24. pp. 206--216.
  Springer (2021)

\bibitem{torchvision2016}
maintainers, T., contributors: Torchvision: Pytorch's computer vision library.
  \url{https://github.com/pytorch/vision} (2016)

\bibitem{Neimark_2021_ICCV}
Neimark, D., Bar, O., Zohar, M., Asselmann, D.: Video transformer network. In:
  Proceedings of the IEEE/CVF International Conference on Computer Vision
  (ICCV) Workshops. pp. 3163--3172 (October 2021)

\bibitem{shao2021transmil}
Shao, Z., Bian, H., Chen, Y., Wang, Y., Zhang, J., Ji, X., et~al.: Transmil:
  Transformer based correlated multiple instance learning for whole slide image
  classification. Advances in neural information processing systems
  \textbf{34},  2136--2147 (2021)

\bibitem{sutton2022developing}
Sutton, J., Menten, M.J., Riedl, S., Bogunovi{\'c}, H., Leingang, O., Anders,
  P., Hagag, A.M., Waldstein, S., Wilson, A., Cree, A.J., et~al.: Developing
  and validating a multivariable prediction model which predicts progression of
  intermediate to late age-related macular degeneration—the pinnacle trial
  protocol. Eye pp.~1--9 (2022)

\bibitem{tang2022self}
Tang, Y., Yang, D., Li, W., Roth, H.R., Landman, B., Xu, D., Nath, V.,
  Hatamizadeh, A.: Self-supervised pre-training of swin transformers for 3d
  medical image analysis. In: Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition. pp. 20730--20740 (2022)

\bibitem{touvron2021training}
Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., J{\'e}gou, H.:
  Training data-efficient image transformers \& distillation through attention.
  In: International conference on machine learning. pp. 10347--10357. PMLR
  (2021)

\bibitem{xiao2021early}
Xiao, T., Singh, M., Mintun, E., Darrell, T., Doll{\'a}r, P., Girshick, R.:
  Early convolutions help transformers see better. Advances in Neural
  Information Processing Systems  \textbf{34},  30392--30400 (2021)

\end{thebibliography}
