\section{Randomized stochastic gradient descent ascent (RSGDA)} \label{sec: rsgda}
%\yy{A table summarizing the conditions and results in introduction would help readers quickly get a big picture of your work.}
In this section, 
we first discuss the motivation of RSGDA (Section \ref{sec: 4.1}),
and show that RSGDA converges to the unique Nash equilibrium of $F$ in the SCSC setting (Section \ref{sec: 4.2}).
Since it is impossible to discuss the convergence to Nash equilibriums in the nonconvex-nonconcave setting, we next show that RSGDA converges to a Nash-type stationary point  and a Stackelberg-type stationary point in the NC-P{\L} condition (Section \ref{sec: 4.3}).
Finally, based on the theoretical results, we propose a selection strategy for $p$ (Section \ref{sec: 4.4}).
    
\subsection{Motivation of RSGDA} \label{sec: 4.1}

The intuition of ESGDA is straightforward. 
On the one hand, SGDmax contains a complete theory but is impractical in applications due to the calculation of $y^*$. 
On the other hand, although SGDA is tractable, it lacks theoretical guarantees and often fails in many cases.
ESGDA takes advantage of both SGDmax and RSGDA. 
% ESGDA takes a fixed number of steps in $y$ and one step in $x$ in each iteration. 
In iterations of ESGDA, 
the multiple steps in $y$ not only provide a reasonable estimation of $y^*$ but are also tractable.

Though ESGDA performs better than SGDA in applications, its theoretical properties are still unclear. 
Analyzing its properties is challenging due to the following two technical reasons.
First, the multiple gradient steps in $y$ create several immediate variables, causing the gap between $y_k$ and $y_{k+1}$. 
Second, a theoretical analysis of the best inner update steps seems to be unachievable if it is analyzed by classical techniques.
Therefore, we focus on the randomized version of ESGDA, i.e., RSGDA, as a surrogate. 
% \lizn{Need a further conclusion sentence}

\subsection{Convergence under SCSC condition} \label{sec: 4.2} %\label{subsec: 3.1}
The existing theoretical analysis~\cite{farnia2021train} demonstrates that, 
when $F$ is SCSC and with noiseless gradients, SGDA and ESGDA can successfully strongly converge to the unique Nash equilibrium with linear convergence rate. 
Thus, we first show that, RSGDA enjoys the same convergence property with SGDA and ESGDA in the SCSC setting. 
In other words, the randomized update of $x$ and $y$ will not damage the convergence results. 
Throughout this subsection, we always assume that $\sigma = 0$, i.e., the gradient estimation is exact.
% Before further details about Algorithm \ref{algo: rsgda}, we first consider it in a simple case: $F$ is $\mu$-SCSC. As discussed above, if $F$ is $\mu$-SCSC, it must have the NC-P{\L} condition. However, due to the rich theoretical results for the SCSC function, it is meaningful to consider Algorithm \ref{algo: rsgda} under the SCSC condition separately. 
Note that when $F$ is SCSC, there is a unique Stackelberg equilibrium and a unique Nash equilibrium of $F$, and the Stackelberg equilibrium and Nash equilibrium are equal~\citep{rockafellar_convex_1970}.
For simplicity, we eliminate the random term $z$ due to the noiseless gradients setting, and assume that the step sizes are constant, i.e.,  for any $k \geq 0$, $\alpha_k \equiv \alpha$ and $\eta_k \equiv \eta$ for some given values $\alpha$ and $\eta$.  
The convergence result is concluded in the following theorem, with all the proofs deferred to the appendix. 
% For ease of notation, we define the operator $H_{\text{RSGDA}}$ as follows: 
% \begin{equation*}
%     H_{\text{RGDA}} (x, y) := 
%     \begin{dcases}
%         (x - \alpha \nabla_x F(x, y), y), & \quad \text{w.p.} \quad p, \\ 
%         (x, y + \eta \nabla_y F(x, y)), & \quad \text{w.p.} \quad 1 - p.
%     \end{dcases}
% \end{equation*}

\begin{theorem} \label{thm: rgda is contractive}
Assume that $F$ is $\mu$-SCSC and $\sigma = 0$. Let $\{ (x_k, y_k) \}$ be the sequence generated by Algorithm \ref{algo: rsgda}, $(x^*, y^*)$ be the Nash equilibrium of $F$. 
For sufficiently small $\alpha = \eta$, there exists a constant $\rho < 1$, such that $\forall k \geq 0$, 
\begin{equation*}
    \e_k [\| (x_{k+1}, y_{k+1}) - (x^*, y^*) \|^2] \leq \rho \| (x_k, y_k) - (x^*, y^*) \|^2.
\end{equation*}
\end{theorem}
% \lizn{Conclusion: vs. GDA}

\noindent{\em Remarks}.
Intuitively, Theorem \ref{thm: rgda is contractive} states that RSGDA is a quasi-contractive operator in the expectation viewpoint. 
Consequently, we can prove that RSGDA converges linearly to the minimax point for a $\mu$-SCSC function $F$ in expectation, which shares the same convergence rate as SGDA and ESGDA in the SCSC setting with $\sigma = 0$. 

\begin{corollary}
    
Consider the setting of Theorem \ref{thm: rgda is contractive}, $\{(x_k, y_k)\}$ converges to the minimax point $(x^*, y^*)$ linearly in expectation.

\end{corollary} \label{coro: 1}

% \lizn{Why randomized version? compared with ESGDA?}

\subsection{Convergence under NC-P{\L} condition} \label{sec: 4.3}

%We have proved the convergence of RSGDA for the $\mu$-SCSC function. 
Next, we switch to analyze the property of RSGDA under the NC-P{\L} condition, which is an extension of the result of the $\mu$-SCSC case.  
In general, SGDA and SGDmax can both converge to a Stackelberg-type stationary point in the NC-P{\L} condition. 
However, there is no theoretical analysis ensuring that ESGDA converges in either the NCSC (nonconvex strongly concave) setting or the NC-P{\L} condition~\cite{sebbouh2021randomized}, due to the complicated structure of ESGDA. 
Hence, we analyze the efficiency of RSGDA in the NC-P{\L} condition. 
Our analysis of RSGDA is similar to the analysis of SGDA, which makes the theory simple and transparent.
Specifically, if function $F$ admits the NC-P{\L} condition, we have the following convergence result for Algorithm~\ref{algo: rsgda}.

\begin{theorem} \label{thm: convergence of rsgda}
% Let Assumption \ref{assum: smoothness}, \ref{assum: bounded variance} $\&$ \ref{assum: ncpl condtion} hold. 
Assume that $F$ is $L_1$-smooth and satisfies the NC-P{\L} condition. 
Let $\alpha_k \leq \frac{1}{2L_2}$ and $18\kappa^2 \frac{p}{1-p}  \alpha_k \leq \eta_k \leq \frac{1}{L_1}$ for $k \geq 0$, 
and assume that the stepsizes $\alpha_k$ and $\eta_k$ are square summable but not summable, 
i.e.,
$ \sum_k \alpha_k = + \infty, \sum_k \eta_k = + \infty$, and 
$\sum_k \alpha_k^2 < + \infty, \sum_k \eta_k^2 < + \infty$.
Then for non-increasing $\{ \alpha_k \}$, we have 
\begin{equation}
    \min_{t=0, 1, \dots, k-1} h_t = o \left( \frac{1}{\sum_{j=0}^{k-1} \alpha_j} \right) \to 0, \quad \textrm{almost surely},
\end{equation}
where $h_t = \frac{1}{4} \| \nabla \phi (x_t) \|^2 + \frac{1}{20} \left( \frac{L_1}{\mu} \right)^2 \| \nabla_y F(x_t, y_t) \|^2 + \frac{11}{40} \| \nabla_x F(x_t, y_t) \|^2$.

\end{theorem}

\noindent{\em Remarks.}
% Before we provide a sketch proof of Theorem \ref{thm: convergence of rsgda}, we first discuss what $h_t$ is.
% We claim that 
Here $h_t$ can be viewed as an efficiency measure of the RSGDA.
In fact, we have $\| \nabla F(x_t, y_t) \|^2 \lesssim h_t$ and $\| \nabla \phi (x_t) \|^2 \lesssim h_t$. Thus, we obtain that 
\begin{equation*}
    \min_{t=0, \dots k} \| \nabla F(x_t, y_t) \|^2 + \| \nabla \phi (x_t) \|^2 \lesssim \min_{t=0, \dots, k} h_t,
\end{equation*}
which means that $h_t$ is an upper bound of $\| \nabla F(x_t, y_t) \|^2 + \| \nabla \phi (x_t) \|^2$.
Hence, to obtain a Nash-type stationary point and a Stackelberg-type stationary point simultaneously, it is sufficient to ensure that $\min_{t=0, \dots, k} h_t \to 0$ as $k \to \infty$.
%Hence, roughly speaking, 
In other words, Theorem \ref{thm: convergence of rsgda} essentially states that RSGDA converges to a Nash-type stationary point and a Stackelberg-type stationary point simultaneously under some suitable conditions. 

A detailed proof is provided in Appendix~\ref{app: rsgda}. 
In a nutshell
, to prove Theorem \ref{thm: convergence of rsgda}, inspired by the work \cite{yang2021faster}, we introduce a Lyapunov function 
\begin{equation*} 
V (x, y):= \phi (x) + C (\phi (x) - F (x, y)), 
\end{equation*}
where $C > 0$ is a constant to be determined later. 
Note that for any $(x, y)$, we have $\phi (x) \geq F(x, y)$ according to the definition of $\phi$.
Hence, $V$ is bounded from below.
Now, for any $k \geq 0$, we define
\begin{equation*}
    V_k := V(x_k, y_k) = \phi (x_k) + C(\phi (x_k) - F(x_k, y_k)).
\end{equation*}
Due to the random term $p$ and the stochastic term $z_k$ in the definition of $(x_{k+1}, y_{k+1})$, comparing $V_k$ and $V_{k+1}$ directly is meaningless.
However, from the stochastic process perspective, one can discuss the gap between $\e_k[V_{k+1}]$ and $V_k$, where $\e_k[\cdot]$ is the conditional expectation.
Next, we show that $\{ V_k \}_k$ is similar to a submartingale which means that it is ``non-increasing'' in the conditional expectation meaning.
In particular, we provide an inequality connecting $\e_k[V_{k+1}]$ and $V_k$.
Finally, by applying the Robbins-Siegmund theorem~\cite{robbins1971convergence} to this inequality, we can obtain the almost surely convergence of RSGDA.

% We claim that we can obtain a Stackelberg-type stationary point and a Nash-type stationary point simultaneously from the sequence $\{ x_k, y_k \}_k$ by Theorem \ref{thm: convergence of rsgda}. In fact, on one side, we have $\| \nabla F(x_t, y_t) \|^2 \lesssim h_t$ and $\| \nabla \phi (x_t) \|^2 \lesssim h_t$. Thus, we obtain that 
% \begin{equation*}
%     \min_{t=0, \dots k} \| \nabla F(x_t, y_t) \|^2 + \| \nabla \phi (x_t) \|^2 \lesssim \min_{t=0, \dots, k} h_t.
% \end{equation*}
% On the other side, note that for any given $k$, $\min_{t=0, \dots, k} h_t$ is bounded by $1 / \sum_{j=0}^k \alpha_j$ and $\sum_j \alpha_j = +\infty$. Hence, $\min_{t \geq 0} h_t = 0$ almost surly. Combining the two observations, we get our claim.

Furthermore, we can get the convergence rate of Algorithm \ref{algo: rsgda} from a straightforward observation of Theorem \ref{thm: convergence of rsgda}, which is concluded in the following theorem.

\begin{theorem}[Convergence rate] \label{thm: convergence rate}

Consider the setting of Theorem \ref{thm: convergence of rsgda}, for any $\epsilon > 0$, there are sequences $\{ \alpha_k \}$ and $\{ \eta_k \}$, such that
\begin{equation}
    \min_{t = 0, 1, \dots, k-1} h_t = o \left( k^{- \frac{1}{2} + \epsilon}  \right),
\end{equation}
almost surely.

\end{theorem}

Finally, we analyze two specific versions of RSGDA, i.e., randomized gradient descent ascent (RGDA) and constant step RSGDA.

\noindent\textbf{RGDA}.
We first consider RGDA, where we use the exact gradients in Algorithm \ref{algo: rsgda}.

\begin{corollary} \label{coro: 2}

Let Assumption \ref{assum: smoothness}, \ref{assum: bounded variance} \& \ref{assum: ncpl condtion} hold with $\sigma^2 = 0$. Assume that  $\alpha_k \equiv \alpha$ and $\eta_k \equiv \eta$ for all $k \geq 0$. Moreover, we assume that $\alpha \leq 1 / (2L_2)$ and $18 \frac{p}{1-p} (L_1/\mu)^2 \alpha = \eta \leq 1 / L_1$, where $L_2 = L_1 + \frac{L_1 \kappa}{2}$ and $\kappa = L_1 / \mu$. Then
\begin{equation}
    \min_{t=0,\dots, k} \e [h_t] = O \left( \frac{1}{k} \right).
\end{equation}
    
\end{corollary}

\noindent\textbf{Constant step RSGDA}.
Another variant of RSGDA is choosing constant step sizes for RSGDA. Though RSGDA with constant steps does not converge, we can provide the computation complexity of obtaining an approximate local solution to problem (\ref{problem: stochastic minimax problem}).

\begin{corollary} \label{coro: 3}
    
Let Assumption \ref{assum: smoothness}, \ref{assum: bounded variance} \& \ref{assum: ncpl condtion} hold. Assume that for any $k \geq 0$, we have $\alpha_k \leq 1 / (2L_2)$ and $18 \frac{p}{1-p} (L_1/\mu)^2 \alpha_k = \eta_k \leq 1 / L_1$, where $L_2 = L_1 + \frac{L_1 \kappa}{2}$ and $\kappa = L_1 / \mu$. Moreover, assume that $\alpha_k \equiv \alpha$ and $\eta_k \equiv \eta$ for all $k \geq 0$. Then for any $\epsilon > 0$, if $k = O (\epsilon^2)$, then
\begin{equation}
    \min_{t=0, \dots, k} \e [h_t] \leq \epsilon.
\end{equation}
    
\end{corollary}

%\begin{remark}
\noindent{\em Remarks}.
Corollary \ref{coro: 3} indicates that the computation complexity of RSGDA is the same as SGDA. 
In other words, RSGDA is as fast as SGDA.
In fact, for any $\epsilon > 0$, SGDA (see like \citet{yang2021faster}) provides a point $x$ such that $\| \nabla \phi (x) \|^2 \leq \epsilon$ in $O(1/\epsilon^2)$ steps.
On the other side, note that $h_k \geq\frac{1}{4} \| \phi (x_k) \|^2$ for any $k \geq 0$.
Hence, Corollary \ref{coro: 3} states that RSGDA provides a point $x$ such that $\| \nabla \phi (x) \|^2 \leq \epsilon$ in $O(1/\epsilon^2)$ steps, which coincides with the results of SGDA.
It means that RSGDA shares the same theoretical computation complexity as SGDA.
%\yy{this paragraph seems to be a mismatch to the above clrollary.}

%\end{remark}

%\yy{overall, the above two sections are still messy to me. consider to add a figure showing the logic flow (this might be rare but I guess a figure may help the readers to follow), and a table to summarize the assumptions/results/etc. of existing methods and your method.}

\subsection{Selection of p} \label{sec: 4.4}

In the last part, we discuss about the value $p$ in applications.
To the end of this subsection, we always assume that the stepsizes are constants.
Theoretically, for any $p \in (0, 1)$, RSGDA converges under some suitable choices of stepsizes. 
However, the empirical experiments show that RSGDA performs better in some $p$ than others.
We propose an intuitive idea to determine the value $p$ in this part.

Recall that $h_k$ is introduced to measure the efficiency of RSGDA.
Thus, for any fixed $n$, the smaller value $\sum_{k=1}^n h_k$, the faster RSGDA converges numerically.
Hence, the basic idea of determining $p$ is to minimize the upper bound of $\sum_{k=1}^n h_k$ by choosing suitable parameter $p$.
Specifically, we choose $p$ according to the following rule.

\begin{proposition} \label{prop: 1}

Consider the setting of Corollary \ref{coro: 3}.
For any initial point $(x_0, y_0)$, There are constant $M_1, M_2 > 0$ independent of $\{ z_1, x_1, y_1, \dots \}$ (the explicit form of $M$ is given in the Appendix), such that the optimal $p$ is given as follow.
\begin{equation}
p =
\begin{dcases}
    \min \left\{ \frac{M_1}{\sqrt{n}} - \frac{M_2}{n} ,\frac{L_2}{9 L_1 \kappa^2 + L_2} \right\}, & \quad \sigma > 0; \\
    \frac{L_2}{9 L_1 \kappa^2 + L_2} & \quad \sigma = 0.
\end{dcases}
\end{equation}
where $n$ is the step number.

\end{proposition}

We give a proof sketch here.
Throughout a complicated computation, one can show that 
\begin{equation} \label{equ: 4.11}
    \sum_{k=1}^n h_k \leq \frac{1}{\alpha p} (V_1 - \inf V) + \frac{18^2 p n}{2 (1-p)} \kappa^4 L_1 \alpha \sigma^2 + \mathrm{const},
\end{equation}
where $V_1$ and $\inf V$ are two constants determined by the initial values, and $\mathrm{const}$ is a constant.
We aim to find the minimization of RHS of \eqref{equ: 4.11} with respect to $p$.
The basic theory of calculus shows that the minimization of RHS of \eqref{equ: 4.11} can be obtained at the value offered in Proposition \ref{prop: 1}.

Roughly speaking, Proposition \ref{prop: 1} states that one should choose the probability $p$ obeying the following rules.
In case the estimation of the gradient is exact, i.e., there is no variance, the hyperparameter $p$ should be as large as possible.
In case $\sigma > 0$, $p$ is the smaller one between $O(1 / \sqrt{n})$ and a constant $\frac{L_2}{9 L_1 \kappa^2 + L_2}$.
Hence, if $n$ is small, $p$ should be a constant; if $n$ is sufficiently large, $p$ should decrease in the rate $O(1/ \sqrt{n})$.
In other words, RSGDA prefers a large probability $p$ when the iteration number $n$ is small and a small $p$ with order $O(1/\sqrt{n})$ in the case $n$ is large.
Hence, we propose an intuitive method called Adaptive-RSGDA (AdaRSGDA) to adjust the parameter $p$.
First, we choose an integer $N_1 > 0$, a constant $N_2 > 0$, and initial probability $p_0$.
For the iteration step $n < N_1$, we fix $p = p_0$.
For the case $n \geq N_1$, we choose $p = 1/([(n-N_1) / N_2] +1)$ for each $N_2$ steps, where $[x]$ denotes the largest integer smaller than $x$.
We use this simple notation to estimate the term $O(1/\sqrt{n})$.
A straightforward observation shows that AdaRSGDA performs like SGDA at the starting $N_1$ steps and naturally changes to ESGDA from the $N_1 + 1$ step.


% In summary, an intuitive choice of $p$ is that for the first several iterations, $p$ should be large enough, then $p$ decreases gradually.
% In other words, RSGDA should take more gradient descent steps at the beginning of the iteration and gradually takes more gradient ascent steps.

