\section{Introduction}

Minimax optimization plays an essential role in various areas, from classic game theory to contemporary machine learning problems such as generative adversarial networks (GANs)~\cite{goodfellow2014generative}, adversarial training~\cite{goodfellow2014explaining}, multi-agent reinforcement learn~\cite{dai2018sbeed, zhang2021multi}, and online learning~\cite{cesa2006prediction}. %, to name but a few. 
% mathematics, and economics \cite{bacsar1998dynamic, neumann1928theorie, von2007theory}. 
In this paper, we consider the following standard stochastic minimax optimization problem:
\begin{equation} \label{problem: stochastic minimax problem}
\begin{aligned}
    \min_{x \in \r^m} \max_{y \in \r^n} F(x, y) := \e_z [ f(x, y; z) ],
\end{aligned}
\end{equation}
where $x$ and $y$ refer to two agents with $x$ intending to maximize the payoff function $F(x,y)$ and $y$ aiming to minimize it. 
We introduce a random vector $z$ obeying the given distribution $\mathcal{D}$ to represent the stochastic approximation to the payoff function. %\yy{if z is not necessary in introduction, we may consider to introduce it in the next sections.}
% where $x, y$ are variables and $z$ is a random vector obeying the given distribution $\mathcal{D}$. 
For ease of notation, the primal function of this problem is denoted by $\phi (x) := \max_y F(x, y)$.

Considering the fact that recent minimax problems often involve a large number of variables, 
first-order methods, including stochastic gradient descent ascent (SGDA), stochastic gradient descent of max-oracle (SGDmax), and epoch stochastic gradient descent ascent (ESGDA), 
have become the canonical algorithms to solve problem~\eqref{problem: stochastic minimax problem}.
However, SGDA, SGDmax, and ESGDA all contain different drawbacks.
The SGDA algorithm, which alternates between one stochastic gradient ascent step in $y$ and one stochastic gradient descent step in $x$, 
%is widely used for solving problem~\eqref{problem: stochastic minimax problem}. 
has been well-studied in recent years~\citep{chen2021proximal, heusel2017gans, lei2020sgd, lin2020gradient,mescheder2017numerics, nagarajan2017gradient}. 
However, most analysis of SGDA particularly relies on strong assumptions in $F$
(e.g., the strong concavity in $y$), 
and SGDA often cannot work well in practical problems that do not admit such ideal assumptions (even for some simple cases such as $F(x, y) = xy$). 
SGDmax~\cite{jin2020local,lin2020gradient,nouiehed_solving_2019, sanjabi2018convergence} is another well-analyzed algorithm for solving problem (\ref{problem: stochastic minimax problem}). 
Compared with SGDA, the theoretical result~\citep{jin2020local} guarantees that the SGDmax can converge under much milder assumptions (e.g., $F$ is Lipschitz and smooth). 
However, SGDmax requires a maximization step in $y$ instead of the stochastic gradient ascent step, which 
is computationally difficult to achieve in practice. 

%The convex-concave setting in which $F$ is assumed to be convex in $x$ and concave in $y$ has been well studied in the literature, see, e.g. \citet{sion1958general, korpelevich1976extragradient, nemirovski2004prox, bubeck2014convex, hazan2019introduction}. 
%Despite that tremendous theories are studied under the convex-concave setting, 
%nearly all minimax problems in machine learning 
%virtually do not admit this ideal assumption \cite{dai2018sbeed, goodfellow2014generative, zhang2021multi}.
%% have a simple convex-concave structure. 
%Hence, in recent years, 
%several analyses % of problem (\ref{problem: stochastic minimax problem}) from a theoretical perspective 
%beyond the convex-concave setting are proposed. 
%For example, 
%\citet{dai2018sbeed,  nouiehed_solving_2019, sinha2017certifying} considered problem (\ref{problem: stochastic minimax problem}) that \lizn{$F(x, y)$ is concave in $y$ for any fixed $x$ but not convex in $x$}. 
%% the nonconvex-concave setting where $F(x, \cdot)$ is concave for any $x$. 
%\citet{lin2018solving} considered a special case of the nonconvex-concave setting where the function $F(\cdot, \cdot)$ satisfies a variational inequality. \citet{yang2021faster} analyzed problem (\ref{problem: stochastic minimax problem}) under the general NC-P{\L} setting, namely, $F(x, y)$ is nonconvex in $x$ and satisfies the Polyak-{\L}ojasiewicz (P\L) condition in $y$ \cite{polyak1963gradient}. On the other hand, \citet{jin2020local} proposed a new notion of local optimality--local minimax and established the connection between local minimax and the solution of problem (\ref{problem: stochastic minimax problem}).

Compared with SGDA and SGDmax, ESGDA~\cite{goodfellow2014generative, sinha2017certifying, sebbouh2021randomized} is more popular due to its superior empirical performance. 
Elaborately, ESGDA takes a fixed number of stochastic gradient ascent steps in $y$ followed by a stochastic gradient descent step in $x$ during each iteration, and the goal of the ascent steps is to find a good approximation of $y^* (x) := \mathop{\arg\max} F(x ,y)$. 
Despite its popularity, ESGDA is extremely difficult to analyze, and hence there are few theoretical analyses beyond the convex-concave setting. 
For example, the latest analysis is from \citet{yan2020optimal} who considered ESGDA under the condition that $F$ is weakly convex in $x$ and strongly concave in $y$. 
%To alleviate the difficulty of 

To better analyze ESGDA, a randomized version of ESGDA called RSGDA is proposed~\citep{sebbouh2021randomized} to bridge the theoretical framework and the empirical result. 
Specifically, at each iteration, 
RSGDA takes a stochastic gradient descent step in $x$ with probability $p$ and a stochastic gradient ascent step in $y$ with probability $1-p$. 
Intuitively, RSGDA is consistent with ESGDA in the sense of expectation: during multiple iterations, 
it takes one gradient descent step, followed by $\frac{1-p}{p}$ gradient ascent steps on average.
% Therefore, one may focus on the theoretical analyses of this randomized version RSGDA in the hope of extending them to the deterministic version ESGDA. %\yy{delete this sentence?}

% By introducing the coin toss parameter $p$, theoretical analysis of RSGDA is simple and transparent.
However, the current analysis of RSGDA in \citep{sebbouh2021randomized} is still unsatisfactory.
First, the analysis only provides a partial convergence result that RSGDA can converge to a stationary point of $\phi$, other than the original function $F$. 
In other words, it proves the convergence of RSGDA with respect to $x$, 
but lacks an analysis of $y$ and, more importantly, the joint variable $(x,y)$. 
Second, the provided convergence rate of RSGDA needs to be re-determined. 
Their theoretical result indicates that RSGDA is slower than SGDA, which is inconsistent with numerical experiments showing that RSGDA is at least as fast as SGDA. 
Third, their analysis is limited to the strongly concave setting, which is prohibitively impractical in most cases.

To this end, we propose a new technical framework to analyze RSGDA. 
Elaborately, inspired by \citet{yang2021faster}, we introduce a new Lyapunov function $V$ to bridge the gap between the original function $F(x,y)$ and the primal function $\phi(x)$.
Furthermore, we use $V$ to analyze RSGDA in a relatively more moderate condition, i.e., the NC-P{\L} setting (nonconvex in $x$ and P{\L} condition in $y$), 
and provide more sound convergence results based on our framework. 
In addition, we also analyze the convergence rate with respect to the parameter $p$, which guides a new selection strategy of $p$. %\yy{can RSGDA with you $p$ selection outperform ESGDA? if yes, I think we can have some much stronger statements here.}

% consider RSGDA under the NC-P{\L} setting, i.e., $F(x, y)$ is nonconvex in $x$ and has the P{\L} condition in $y$. 
% which means that $F(x, y)$ is nonconvex in $x$ and has the P{\L} condition in $y$.
% Hence, our work naturally covers the work \citep{sebbouh2021randomized}.


Our contributions can be summarized as follows:

\begin{itemize}
    % \item In Section \ref{sec: rsgda}, we show the convergence results for RSGDA in both the strongly convex strongly concave case (SCSC) and the NC-P{\L} case. Our contributions are threefold. First, we generalize the nonconvex-strongly concave condition considered in \cite{sebbouh2021randomized} to the NC-P{\L} condition. Moreover, different from the convergence analyses in \cite{jin2020local, sebbouh2021randomized}, we prove that we can obtain a pair $(x, y)$ from the sequence generated by RSGDA such that $ \| \nabla F (x, y)\| \leq \epsilon $ and $ \| \nabla \phi (x) \| \leq \epsilon$ simultaneously. Furthermore, we provide convergence results that are better than the ones provided in \cite{sebbouh2021randomized}.
    
    % Compared to aforementioned previous work, our analysis does not assume uniformly strongly concave in $y$, and improves the convergence bound.
    \item We introduce a new framework for the analysis of RSGDA, and prove the almost sure convergence of RSGDA for both $x$ and the joint variable $(x, y)$ in NC-P{\L} setting.
    
    \item We further analyze the convergence rate of RSGDA, and derive a more sound result than previous analysis. Based on this analysis, we also propose a simple but effective method to adjust the parameter $p$ for RSGDA.
    
    \item Empirical experiments show the efficiency of RSGDA and confirm our theoretical results.
\end{itemize}

The rest of this paper is organized as follows. 
Section~\ref{sec:related} briefly overviews related work in the direction of solving stochastic minimax optimization problem. 
Section \ref{sec: preliminaries} is devoted to preliminaries. 
In Section \ref{sec: rsgda}, we analyze RSGDA under the NC-P{\L} assumption. 
Moreover, we propose an intuitive method to determine the parameter $p$.
Section \ref{sec: experiment} contains the numerical experiments. 
