%%%
% \documentclass[sigconf]{acmart}
%%% For arXiv
\documentclass[sigconf,nonacm]{acmart}

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\copyrightyear{2025}
\acmYear{2025}
\setcopyright{acmlicensed}\acmConference[WSDM '25]{Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining}{March 10--14, 2025}{Hannover, Germany}
\acmBooktitle{Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining (WSDM '25), March 10--14, 2025, Hannover, Germany}
\acmDOI{10.1145/3701551.3703497}
\acmISBN{979-8-4007-1329-3/25/03}

%% Submission ID. This information is sent to you
%%\acmSubmissionID{123-A56-BU3}

%% Packages
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{orcidlink}
\usepackage{dsfont}
\usepackage{bbold}

%% Other:
\newtheorem{remark}{Remark}
% \newcommand{\sr}[1]{\textcolor{orange}{#1}}
% \newcommand{\ja}[1]{\textcolor{blue}{#1}}
% \newcommand{\am}[1]{\textcolor{purple}{#1}}
\newcommand{\candidatesset}{\mathcal{C}}
\newcommand{\candidatessubset}{\mathcal{D}}
\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \littletaller % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
  }}
\newcommand{\littletaller}{\mathchoice{\vphantom{\big|}}{}{}{}}
\newcommand{\besttext}{\text{\textit{best}}}
\newcommand{\goodtext}{\text{\textit{good}}}
\newcommand{\addtext}{\text{\textit{add}}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\ci}{\mathrel{{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}

%%
\settopmatter{printacmref=true}
\begin{document}

%%
\title{The Initial Screening Order Problem}

%%
\author{Jose M. Alvarez}
\orcid{0000-0001-9412-9013}
\affiliation{
  \institution{KU Leuven}
  \city{Leuven}
  \country{Belgium}
}
\email{josemanuel.alvarez@kuleuven.be}
\authornote{This work was done while being a Research Fellow at the University of Pisa.}

\author{Antonio Mastropietro}
\orcid{0000-0002-8823-0163}
\affiliation{
  \institution{University of Pisa}
  \city{Pisa}
  \country{Italy}
}
\email{antonio.mastropietro@di.unipi.it}

\author{Salvatore Ruggieri}
\orcid{0000-0002-1917-6087}
\affiliation{
  \institution{University of Pisa}
  \city{Pisa}
  \country{Italy}
}
\email{salvatore.ruggieri@unipi.it}

%%
\renewcommand{\shortauthors}{Jose M. Alvarez, Antonio Mastropietro, and Salvatore Ruggieri}

%%
\begin{abstract}
    We investigate the role of the initial screening order (ISO) in candidate screening. The ISO refers to the order in which the screener searches the candidate pool when selecting $k$ candidates. Today, it is common for the ISO to be the product of an information access system, such as an online platform or a database query. The ISO has been largely overlooked in the literature, despite its impact on the optimality and fairness of the selected $k$ candidates, especially under a human screener. We define two problem formulations describing the search behavior of the screener given an ISO: the best-$k$, where it selects the top $k$ candidates; and the good-$k$, where it selects the first good-enough $k$ candidates. To study the impact of the ISO, we introduce a human-like screener and compare it to its algorithmic counterpart, where the human-like screener is conceived to be inconsistent over time. Our analysis, in particular, shows that the ISO, under a human-like screener solving for the good-$k$ problem, hinders individual fairness despite meeting group fairness, and hampers the optimality of the selected $k$ candidates. This is due to position bias, where a candidate's evaluation is affected by its position within the ISO. We report extensive simulated experiments exploring the parameters of the best-$k$ and good-$k$ problems for both screeners. Our simulation framework is flexible enough to account for multiple candidate screening tasks, being an alternative to running real-world procedures. 
\end{abstract}

%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003123.10011758</concept_id>
       <concept_desc>Human-centered computing~Interaction design theory, concepts and paradigms</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10002951.10003317.10003338</concept_id>
       <concept_desc>Information systems~Retrieval models and ranking</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Retrieval models and ranking}
\ccsdesc[500]{Human-centered computing~Interaction design theory, concepts and paradigms}

%%
\keywords{Fair set selection; position bias; search user behavior}

%%
% \received{}
% \received[revised]{}
% \received[accepted]{}

%%
\maketitle

\section{Introduction}
\input{sections/1_Introduction}

\section{Searching the Pool of Candidates}
\input{sections/2_ProblemFormulation}

\section{The Human-Like Screener}
\input{sections/3_HumanScreener}

\section{An Experimental Framework}
\input{sections/4_Experiments}

\section{Conclusion}
\input{sections/5_Discussion}

\section*{Acknowledgments} 
Work supported by the European Union (EU)â€™s Horizon Europe research and innovation program for the project FINDHR (g.a. 101070212), and under the Horizon 2020 Marie Sklodowska-Curie Actions research and innovation program  for the project NoBIAS (g.a. 860630). Views and opinions expressed are those of the authors only and do not necessarily reflect those of the EU. Neither the EU nor the granting authority can be held responsible for them.

%%
\clearpage

\section*{Ethical Considerations}
We did not face ethical challenges when drafting the paper. Results are based on simulated data intended to illustrate our theoretical analysis. During our collaboration with company G, in particular, which occurred before the drafting of this paper, we followed G's ethical guidelines at all times. We concluded our collaboration with G with an internal report that we presented and discussed with all stakeholders. No sensitive data (or data at all) from company G was used for this work. At no point did we receive monetary compensation from G. The views reflected are entirely our own. Further, we believe that this work shows the importance of considering the human user in the formulation of the candidate screening problem. We stress that our distinction between an algorithmic screener and a human-like screener is to show the importance of considering the latter kind and not to endorse the former kind. We strongly believe that candidate screening is a complex, human-dependent and human-centered process that should not be left as an automated decision-making problem.

%%
\bibliographystyle{ACM-Reference-Format}
\balance
\bibliography{references}

%%
\clearpage

%%% For arXiv
\appendix
\input{sections/Appendix}

%%
\end{document}

%
% EOF
%
