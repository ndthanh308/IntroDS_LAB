%
\label{sec:HumanScreener}

To study the human interaction with an ISO, we distinguish two kinds of screeners based on the proneness to error when evaluating candidates: 
$h$ is an \textit{algorithmic screener}, or $h_a \in \mathcal{H}_a$, if it consistently evaluates $\mathcal{C}$; whereas $h$ is a \textit{human-like screener}, or $h_h \in \mathcal{H}_h$, if its fatigue hinders the consistency of its evaluation of $\mathcal{C}$.

\subsection{Fatigue and Fatigued Scores}
\label{sec:HumanScreener.BiasedScores}

We first introduce a \textit{time component}, with $t$ denoting the discrete unit of time that represents how long $h$ takes to evaluate a candidate $c \in \mathcal{C}$. 
We assume that $t$ is constant (recall G5 Section~\ref{sec:Generali}), implying that time cannot be optimized by $h$.
We track time along $\theta$, meaning $h$ evaluates the first candidate that appears in $\theta$ at time $t=1$ and so on. 
Time $t$ ranges from $0$ to $n$ at maximum.
We then introduce a \textit{fatigue component} $\phi(t)$ specific to $h_h$ as a function of $t$ and model the \textit{accumulated fatigue} $\Phi \colon \{0, \ldots, n\} \to \mathbb{R}$, with $\Phi(0) = 0$. 
The discrete derivative of $\Phi$, i.e., $\phi(t) = \Phi(t) - \Phi(t-1)$, defined for $t \geq 1$, is the effort of $h_h$ to examine the $t$-th candidate. 

How we define $\Phi$ conditions the effect of fatigue on our analysis of $h_h$.
We make the simplest modeling choice for $\phi$ by assuming that \textit{fatigue accumulates linearly over time}, or $\phi(t) = \lambda$ so that $\Phi(t) = \lambda \cdot t$, meaning $h_h$ becomes tired over time at a constant pace.
How does fatigue materialize for $h_h$?
We model the effect of fatigue on $h_h$ through the \textit{fatigued score}:
%
\begin{equation}
\label{eq:BiasedScoresForHh}
    s_{h_h}(\mathbf{X}_c) + \epsilon
\end{equation}
%
where $\epsilon$ is a random variable dependent on $\Phi$ that quantifies the deviation from the \textit{truthful score} $s_h(\mathbf{X}_c)$.

We model $\epsilon$ using \emph{two modeling choices} at a given time $t$.
% %
% \begin{itemize}
%     \item 
    \textit{\textbf{First modeling choice}:}
    $\epsilon_1$ is a centered Gaussian, and the fatigue affects only its variance. 
    Formally, $\epsilon_1 \sim \mathcal{N}(0, \, v(\Phi(t-1)))$, where $v \colon \mathbb{R} \to \mathbb{R}$ defines the variance of $\epsilon_1$ as an increasing function of $\Phi$.
    % %
    % \item 
    \textit{\textbf{Second modeling choice}:}
    $\epsilon_2$ as an uncentered Gaussian, whose mean is a decreasing function of the fatigue.
    % The second choice assumes that a negative bias can affect each applicant's evaluation.
    % Hence, we model $\epsilon_2$ as an uncentered Gaussian, whose mean is a decreasing function of the fatigue.
    Formally, $\epsilon_2 \sim \mathcal{N}(\mu(\Phi(t-1)), \, v(\Phi(t-1))$, where $\mu \colon \mathbb{R} \to \mathbb{R}$ is a decreasing function rather than a constant of $\Phi$.
    % The more fatigue, the more the screener $h_h$ tends to underscore the candidates.
% \end{itemize}
% %
 
Under $\epsilon_1$, $h_h$ tends to overscore or underscore candidates, introducing both negative and positive bias (i.e., fatigue as ``less attention'' when evaluating candidates) over time. 
Under $\epsilon_2$, instead, $h_h$ tends to underscore the candidates (i.e., fatigue as ``less effort'' when evaluating candidates) over time, introducing always a negative bias. 
With $\epsilon_1$ and $\epsilon_2$, we capture two realistic biased settings driven by the ISO.
We assume $h_h$ is unaware of its fatigue, representing an unconscious bias from performing a repetitive task \cite{Kahneman2011Thinking, Kahneman2021Noise}.

%
\begin{remark}
\label{remark:HumanAndIF}
    $\Phi$ implies that $h_h$ evaluates identical candidates $c_1$ and $c_2$ differently under $\theta$ at $t_1$ and $t_2$ as long as $\Phi(t_1) \neq \Phi(t_2)$ and regardless of whether $h_h$ solves for the best-$k$ or good-$k$ problem.
\end{remark}
%

The algorithms~\ref{algo:Examination} and \ref{algo:Cascade} represent $h_a$.
To represent the human-like screener $h_h$, we must track $\Phi$ over time and draw $\epsilon_1$ (or $\epsilon_2$) to compute \eqref{eq:BiasedScoresForHh} of $h_h$ at time $t$. 
The only changes are to line 2 in Algorithm~\ref{algo:Examination} and line 7 in Algorithm~\ref{algo:Cascade}, where the score computed for candidate $c$ is biased by $\epsilon_1$ (or $\epsilon_2$). 
We present the human-like versions of these search procedures as Algorithms 3 and 4 in Appendix;
% ~\cite{DBLP:journals/corr/abs-2307-15398}; 
these algorithms, though, can be observed using Figure~\ref{fig:TheAlgos}.

\subsection{Position Bias Implications}
\label{sec:PositionBias}

We analyze the fairness and optimality implications of the position bias implicit to $\theta$. For concreteness, we make \textit{two assumptions}.
\textit{\textbf{A1}: We assume $\theta$ is independent of the protected attribute}, meaning how candidates appear in $\theta$ contains no information about $W$.
\textit{\textbf{A2}: We assume the individual scoring function evaluates candidates fairly and truthfully}, meaning $s(\mathbf{X}_c)$ captures no information about $W_c$.
Under \textit{A1} and \textit{A2}, we control for other biases, such as measurement error in $s$, and focus on the position bias coming from $\theta$.

We start with the fairness implications for the best-$k$ and good-$k$ problems. 
Given $\theta$, it is important to distinguish between the group fairness constraining $h$ (i.e., the quota $q$) and the individual fairness violation when $h$ fails to evaluate similar candidates similarly.
Regarding group-level fairness, both $h_a$ and $h_h$ are fair in solving for \eqref{eq:fair_objective_all_screener} and \eqref{eq:AlternativeUtility} by satisfying $f\big(S^k\big) \geq q$.
This point is clear for $h_a$ in Algorithms \ref{algo:Examination} and \ref{algo:Cascade} as there is no fatigue involved.
The same holds for $h_h$ in Algorithms~3 and 4 because the error on the score does not affect the evaluation of $q$.
Here, we have that the expected error $\mathbb{E}[\epsilon \mid W_c = 1, \theta] = \mathbb{E}[\epsilon \mid W_c = 0, \theta]$, regardless of $\epsilon_1$ or $\epsilon_2$ for $h_h$. 
The fatigue and, thus, the fatigued scores are, on average, shared across protected and non-protected candidates.

Distinguishing between $h_a$ and $h_h$ becomes important under individual-level fairness because $h_a$ ensures it while $h_h$ violates it.
A candidate's position in $\theta$ influences the amount of error made by $h_h$ when evaluating that candidate. 
Similar candidates will not be evaluated similarly due to the unequal accumulation of fatigue experienced by $h_h$ when searching $\theta$.
% For instance, given two similar candidate $c_i = \theta^{-1}(i), c_j = \theta^{-1}(j)$, with $i < j$, their evaluation could be significantly different in the amount of error depending on the accumulated fatigue $\Phi(i) < \Phi(j)$. 
% In the case of $\epsilon_1$, $i$ has the advantage of being evaluated by a rested screener.
For $\epsilon_2$, e.g., even if $\mathbf{X}_{c} = \mathbf{X}_{c'}$ but $\theta^{-1}(c) > \theta^{-1}(c')$, the score of $c$ is less, on average, than the one of $c'$, and $c'$ has an unfair premium over $c$ from $\theta$.

We now consider the optimality implications for the best-$k$ and good-$k$ problems.
It follows that $h_a$ reaches the optimal solution in both problems as the absence of fatigue enables $h_a$ to consistently judge suitable candidates.
The opposite holds for $h_h$ due to the inconsistent scoring of candidates ascribed by the accumulated fatigue.
The biased scores not only violate individual fairness, but also lead $h_h$ to misjudge candidates, eventually choosing the wrong ones when searching $\theta$.
%
% To summarize, $h_a$ reaches the optimal and fair solution for both best-$k$ and good-$k$ problems, and guarantees individual fairness in both problems. Instead, $h_h$ reaches the fair but sub-optimal solutions for both best-$k$ and good-$k$ problems, and does not guarantee individual fairness in both problems. 
Significantly, under the $h_h$, the position of a candidate in $\theta$ matters.
As no two candidates occupy the same position in $\theta$, it impacts whether a candidate, depending on the search strategy, is evaluated or not (Remark~\ref{remark:ISOandPS}) and, if so, is evaluated fairly or not (Remark~\ref{remark:HumanAndIF}). These results only worsen when relaxing \textit{A1} and \textit{A2}. We explore these insights in Section~\ref{sec:Experiments} by considering multiple hiring settings for $h_a$ and $h_h$.

%
% EOS
%
