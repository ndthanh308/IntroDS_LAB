%
\label{sec:ProblemFormulation}

We formulate the set selection problem, in which a decision-maker selects a set of items from a population, given an ISO.
Here, the candidates for a job represent the items and the screener evaluating their profiles represents the decision-maker.
Let the ISO be the product of an IAS specific to hiring.

\subsection{Setting}
\label{sec:ProblemFormulation.Setting}

Let us consider a \textit{candidate pool} $\mathcal{C}$ of $n$ candidates, where each \textit{candidate} $c$ is described by the \textit{vector of $p$ attributes} $\mathbf{X}_c \in \mathbb{R}^{p}$ and the \textit{protected attribute} $W_c$.
We assume that $W$ is binary, such that $W_c = 1$ if $c$ belongs to the protected group and $W_c = 0$ otherwise; we can relax this assumption if needed.
The candidates are evaluated by a \textit{screener} $h \in \mathcal{H}$, where $\mathcal{H}$ denotes the set of available screeners. 
The following variables refer to a specific $h$. 
The goal of $h$ is to obtain a \textit{set of $k$ selected candidates} $S^k \in [\mathcal{C}]^k$, with $[\mathcal{C}]^k$ denoting the set of $k$-subsets of $\mathcal{C}$, 
% (i.e., subsets with cardinality $k$), 
based on each candidate's application profile as summarized by the tuple $(\mathbf{X}_c, W_c)$.
Candidate evaluation occurs when $h$ uses an \textit{individual scoring function} $s \colon \mathbb{R}^{p} \to [0, 1]$, such that $s(\mathbf{X}_c)$ returns the score of $c$, and $h$ cannot use $W_c$ when scoring $c$. 
The higher the score, the better $c$ fits the job.

The screener $h$ explores the candidate pool $\mathcal{C}$ in a specific order. 
We denote the \textit{set of total orderings of candidates} in $\candidatesset$ by $\Theta$.
An \textit{order} $\sigma \in \Theta$ maps an integer $i \in \{1, \dots n\}$ to a candidate $c \in \candidatesset$, indicating that $c$ occupies the $i$-th position according to $\sigma$, with notation $\sigma(i) = c$ and vice-versa $\sigma^{-1}(c) = i$.
Importantly, the screener explores $\mathcal{C}$ under the ISO $\theta \in \Theta$, which represents the order chosen by or, alternatively, provided to $h$ before searching $\candidatesset$ (recall, G1 in Section~\ref{sec:Generali}) via an IAS. 
The screener is not required to explore the entirety of $\mathcal{C}$, meaning $h$ can either fully or partially explore $\candidatesset$ given $\theta$ (recall, G2 in Section~\ref{sec:Generali}).
We assume that the screener \textit{respects} $\theta$, meaning: 
%
\begin{equation}
\label{eq:order}
    \mbox{$c_1 \in \candidatesset$ is evaluated before $c_2 \in \candidatesset$ only if $\theta^{-1}(c_1) < \theta^{-1}(c_2)$.}
\end{equation}
%

\subsection{Two Problem Formulations}
\label{sec:ProblemFormulation.Objectives}

We formulate two utility-based set selection problems for $h$ with the shared objective of achieving an optimal and fair set $S^k$.
Under the \textit{best-}$k$ formulation, $S^k$ represents \textit{the fair best $k$ candidates} in $\candidatesset$ according to $h$; we denote it as $S^k_{\besttext}$. 
Under the \textit{good-}$k$ formulation, $S^k$ represents \textit{the fair first good-enough $k$ candidates} in $\candidatesset$ according to $h$; we denote it as $S^k_{\goodtext}$.
The key difference between the two is that the best-$k$ requires a full search of $\candidatesset$ while the good-$k$ allows for a partial search of $\candidatesset$ under $\theta$.
% It is the standard formulation in the fair ranking literature.

How we define optimality, as shown in Sections~\ref{sec:best-k} and \ref{sec:good-k}, determines the best-$k$ and good-$k$ problems.
For fairness, we define the \textit{representational quota} $q \in [0, 1]$ as the desired fraction of protected candidates in $S^k$ and use the fraction $f\big( S^k \big) \in [0, 1]$:
%
\begin{equation}
\label{eq:fairness_function}
    f\big( S^k \big) = \frac{\left\vert\{c \in S^k \text{ s.t. } W_c = 1\}\right\vert}{k}
\end{equation}
%
for $h$ to meet $q$ when deriving $S^k$ by satisfying the condition $f\big( S^k \big) \geq q$.
The unconstrained version is achieved by $q=0$.
We view $q$ as a policy enforced by $h$ to achieve a diverse $S^k$ (recall, G4 in Section~\ref{sec:Generali}). 
It is a statement on the composition of $S^k$, not a statement on the ordering of protected candidates within $S^k$.\footnote{For $k=10$ and $q=0.5$, e.g., the fair screener would need to derive $S^k$ with $5$ protected candidates though in no particular order within $S^k$.}

\subsubsection{Best-$k$.}
\label{sec:best-k}

The screener $h$ finds the set of best $k$ candidates in $\candidatesset$ given $q$ while respecting the ISO \eqref{eq:order}.
Here, $h$ needs to evaluate the complete $\candidatesset$ since it must score and rank all candidates according to the individual scoring function $s$ before choosing the ones with the highest scores and that satisfy $q$.

We view the goal in terms of maximizing a utility for $h$. 
We define \textit{utility} as the benefit derived by $h$ from selecting $k$ candidates. 
Formally, utility is a function $U^k \colon [\mathcal{C}]^k \, \times \, \Theta \to \mathbb{R}$. 
The simplest expression for $U^k$ is to add the scores of the selected candidates:
%
\begin{equation}
\label{eq:Utility}
    U^k_{\addtext} \big( S^k, \theta \big) = \sum_{c \in S^{k}} s\big( \mathbf{X}_{c} \big)
\end{equation}
%
rationalizing that $h$ maximizes its utility by selecting the $k$ most suitable candidates given $\theta$. 
Notice that $\theta$ in \eqref{eq:Utility} does not affect the evaluation order of $S^k$ due to the commutative property of addition.
Under \eqref{eq:Utility}, we define  \textbf{the best-\textit{k} problem} as:
%
\begin{equation}
\label{eq:fair_objective_all_screener}
    \begin{aligned}
    \argmax_{S^k \in [\mathcal{C}]^k} & \quad U^k_{\addtext} \big(S^k, \theta\big) \\
    \textrm{s. t.} & \quad f(S^k) \geq q
    \end{aligned}
\end{equation}
%
with its solution as $S^k_{\besttext}$. In the presence of tied scores, $S^k_{\besttext}$ may not be unique. In such a case, we consider any solution.
%
We emphasize that \eqref{eq:Utility} is not the only possible model for the utility of $h$ and alternative models, such as exposure discounting \cite{DBLP:conf/kdd/SinghJ18}, can be considered for \eqref{eq:fair_objective_all_screener}.
We leave this for future work.

%
% Figure environment removed
%

\subsubsection{Good-$k$}
\label{sec:good-k}

The screener $h$ finds $k$ candidates in $\candidatesset$ that meet a set of \textit{minimum basic requirements} $\psi$ (recall, G3 in Section~\ref{sec:Generali}) given $q$ while respecting the ISO \eqref{eq:order}.
We represent $\psi$ as a \textit{minimum score}, such that $h$ deems a candidate $c \in \candidatesset$ as eligible for being selected if $s(\mathbf{X}_c) \geq \psi$.
Unlike the best-$k$ formulation, here $h$ is not required to evaluate the whole $\candidatesset$ as it is enough to find the first $k$ candidates that are good enough according to $\psi$ and that satisfy $q$. 

We still view the goal in terms of maximizing a utility for $h$. We need to, however, define an alternative utility function to \eqref{eq:Utility} that ensures $h$ stops searching $\candidatesset$ after finding the $k$-\textit{th} good-enough candidate according to $\psi$.
We define the following expression:
%
\begin{equation}
\label{eq:AlternativeUtility}
    U^k_{\psi}\big( S^k, \theta \big) = \left\{
    \begin{array}{ll}
        k - \sum_{c \in S^k} p(c, S^k, \theta) & \text{if,} \  \forall c \in S^k, \  s(\mathbf{X}_c) \geq \psi   \\
        0 & \text{otherwise.}
    \end{array} \right.
\end{equation}
%
with the \textit{penalty function} defined as:
%
\begin{equation}
\label{eq:Penalty}
\begin{aligned}
    p(c, S^k, \theta) = & \, \mathbb{1} \big \{ \exists\ c' \in \mathcal{C}\setminus S^k \, \\ & \mbox{s.t.}\ \, \theta^{-1}(c') < \theta^{-1}(c) \wedge s(\mathbf{X}_{c'}) \geq \psi \wedge W_{c'}=W_c \big \}.
\end{aligned}
\end{equation}
%
Under \eqref{eq:AlternativeUtility}, $h$ wants to find as quickly as possible the $k\text{-\textit{th}}$ suitable candidate without wanting to check whether the $(k+1)\text{-\textit{th}}$ candidate is also suitable.
This is because, for a candidate $c$, \eqref{eq:Penalty} looks for another candidate of the same group as $c$ and meeting $\psi$, who occurs before $c$ under $\theta$ but who has not been selected into $S^k$.
It models the ``wasted effort" in choosing a candidate occurring after another one meeting all the same requirements. 
At worst, there are $k$ penalties.
%
Under \eqref{eq:AlternativeUtility}, we define \textbf{the good-\textit{k} problem} as:
%
\begin{equation}
\label{eq:fair_objective_U_psi}
    \begin{aligned}
    \argmax_{S^k \in [\mathcal{C}]^k} & \quad U^k_{\psi} \big(S^k, \theta\big) \\
    \textrm{s. t.} & \quad f(S^k) \geq q
    \end{aligned}
\end{equation}
%
with its solution as $S_{\goodtext}^k(\psi)$ or, if there is no ambiguity on $\psi$, simply as $S_{\goodtext}^k$.
%
When the fairness constraint is strengthened to a fixed quota, $f(S^k) = q$, the solution is unique; in the general case, $f(S^k) \geq q$, there can be two solutions but with different fractions of the protected group.
% See Example~\ref{ex:diff_fractions_prot} in Appendix~\ref{Appendix.NaiveUtilityGoodk} for details.
Similarly to the best-\textit{k} problem, we emphasize that \eqref{eq:AlternativeUtility} is not the only utility model for \eqref{eq:fair_objective_U_psi}; other models are possible as long as they describe the partial search. 
% We leave this for future work.
% For more details, we motivate \eqref{eq:AlternativeUtility} in Appendix~\ref{Appendix.NaiveUtilityGoodk} by presenting a simpler utility model without \eqref{eq:Penalty} and showing its failure to stop $h$.

%
\begin{remark}
\label{remark:ISOandPS}
    $\theta$ influences the screening process under the good-$k$ problem \eqref{eq:fair_objective_U_psi} due to the potential partial search of $\mathcal{C}$ by $h$, affecting which $k$ candidates are selected.
\end{remark}
%
To observe Remark~\ref{remark:ISOandPS}, 
let $k=1$ and assume two candidates such that $s(\mathbf{X}_{c_1}) \geq \psi$ and $s(\mathbf{X}_{c_2}) \geq \psi$. A $\theta$ such that $\theta^{-1}(c_1) = 1$ and $\theta^{-1}(c_2) = 2$ would imply that $c_1$ is considered eligible and is selected before $h$ even evaluates $c_2$. 
Conversely, a reverse $\theta$ such that $\theta^{-1}(c_1) = 2$ and $\theta^{-1}(c_2) = 1$ would imply the opposite.
This remark holds without assuming anything about $h$.

\subsection{Two Search Procedures}
\label{sec:ProblemFormulation.Algorithms}

The \textit{ExaminationSearch} 
% procedure 
(Algorithm~\ref{algo:Examination}) solves the best-$k$ problem, returning $S^k_\besttext$ for given $n$ (candidates) and $\theta$ (ISO), and parameters $k$ (subset size) and $q$ (group fairness constraint).
First, line 2 calculates the minimum number $q^*$ of candidates from the protected group to be selected, and the maximum number of candidates $r^*$ not in that quota. 
Then, candidates are considered by descending scores, using the \texttt{argsortdesc} procedure (lines 2-3). 
The loop in lines 5-13 iterates until $k$ candidates are found. 
The loop adds candidates to the sets $Q$ and $R$: $Q$ are candidates in the quota of the protected group; $R$ are candidates not in that quota that can be non-protected or protected. 
A non-protected candidate can be only added to the $R$ set; thus, line 7 checks if there is still room in $R$ to do this. A protected candidate is added to the quota set $Q$ if there is room (lines 10-11) or to the other set $R$ otherwise (lines 12-13). 
Finally, the procedure returns the candidates in the quota set $Q$ or in the other set $R$. 
The result of the \textit{ExaminationSearch} procedure maximizes (\ref{eq:fair_objective_all_screener}), as candidates are added in decreasing score, while keeping the fairness constraint through the quota management.

The \textit{CascadeSearch} 
% procedure 
(Algorithm~\ref{algo:Cascade}) solves the good-$k$ setting, returning $S^k_\goodtext$ for given $n$ and $\theta$, and parameters $k$, $q$ and $\psi$ (min. basic requirement).
The difference with the \textit{ExaminationSearch} procedure consists in strictly following $\theta$ (line~4) and checking $\psi$ (line~8) before adding a candidate to the quota set $Q$ or to the other set $R$.
The result of the \textit{CascadeSearch} procedure maximizes (\ref{eq:fair_objective_U_psi}), as no penalty is accumulated in the loop. 
This is because, a non-protected candidate ($W_c=0$) is not added only if there is no room in $R$ (and $R$ never gets smaller to allow for more room later on), while a protected candidate ($W_c=1$) is not added only if it does not meet $\psi$ in line 8 and, thus it cannot be counted for the penalty. 

Our aim here is not to provide novel optimal algorithms, but to study the screener's search behavior of $\candidatesset$ under $\theta$.
Hence, we move away from an optimality analysis of the two algorithms (e.g., \cite{fagin2001optimal}), and focus on modeling the search behavior of $h$ when solving the two problems.
Both algorithms are inherently sequential and can be applied online because we aim to model a human-like screener (next section) that operates sequentially.
Yet, in both algorithms, the applicants are disclosed according to $\theta$ and not to the score, differently from past set selection works (e.g., \cite{stoyanovich2018online}).

%
% EOS
%
