%
\label{sec:Experiments}

We introduce a flexible experimental framework in R \cite{Rlang} based on Monte Carlo simulations. 
It can handle different screening scenarios under the algorithmic or human-like screeners given an ISO.
The code is available in a dedicated GitHub repository.\footnote{\url{https://github.com/cc-jalvarez/initial-screening-order-problem}}

%
% Figure environment removed
%

\subsection{Setup}
\label{sec:Experiments.Setup}

\subsubsection{Generating the sample.}
We assume a sample consisting of $n$ triplets $\{ (s(\mathbf{X}_{c_i}), \theta({c_i}), W_{c_i}) \}_{i=1}^n$ drawn from a probability distribution with domain $\mathcal{G}_n \times \mathbb{R}^n \times \{0, 1\}^n$, where $\mathcal{G}_n$ is the set of all permutations of $\{1, \ldots, n\}$. Each sample represents a candidate pool sorted according to an ISO.

For the individual candidate scores, we consider \textit{three distributions} to model scenarios in which top candidates, as in top scores, occur with different probabilities in $\candidatesset$. 
All three distributions use the truncated normal, $tN(\mu, \sigma)$ \cite{Botev2017}, with values bounded in $[0, 1]$. 
These scenarios, shown in Figure~\ref{fig:1} (upper, left), are:
%
\begin{itemize}
    \item \textit{Symmetric distribution of scores} (in red) defined by $\mu = 0.5$ and $\sigma = 0.02$, implying that top candidates occur with a very low probability in $\candidatesset$.
    %
    \item \textit{Asymmetric distribution of scores} (in blue) defined by $\mu = 0.8$ and $\sigma = 0.05$, implying that top candidates occur with a higher probability and median value ($\approx 0.75$) in $\candidatesset$ relative to the previous scenario.
    %
    \item \textit{Increasing distribution of scores} (in green) defined by $\mu = 1$ and $\sigma = 0.05$, implying that top candidates occur with an even higher probability and median value ($\approx 0.85$) in $\candidatesset$ relative to the two previous scenarios.
\end{itemize}
%
These scenarios have implications, in particular, for the good-$k$ problem where we set the minimum score $\psi$ and the screener is not required to explore all of $\candidatesset$ under $\theta$.
A large $\psi$ makes the screening process highly selective in the first scenario, less selective in the second scenario, and not selective at all in the third scenario, representing candidate pools with different candidate quality.

For the ISO, we consider \textit{two settings} in which a $\theta$ relates or not to $s(\mathbf{X}_{c_i})$, allowing to explore $\theta$ as a product of different IAS:
%
\begin{itemize}
    \item \textit{$\theta$ is generated randomly and independently from the individual candidate scores}. Formally, $\theta \ci s$.
    %
    \item \textit{$\theta$ is generated randomly with a correlation $\rho$ with the individual candidate scores}, where $\rho$ is the Spearman's rank correlation of the pairs $\{ (\theta(c_i), s(\mathbf{X}_{c_i})) \}_{i=1}^k$.\footnote{To generate the correlated $\theta$, we rely on copulas \cite[Section 3.4]{EMBRECHTS2003329}.} Formally, $\theta \not\!\perp\!\!\!\perp s$.
\end{itemize}
%
Intuitively, under $\theta \ci s$, $\theta$ carries no information about the candidate quality in $\candidatesset$. It captures settings in which the screener sorts alphabetically or performs a random shuffle of the candidates.
Under $\theta \not\!\perp\!\!\!\perp s$, in particular for $\rho=-1$, $\theta$ sorts candidates by descending scores. It captures settings where the screener obtains a ranked list of candidates from the IAS.

Finally, regarding the protected attribute, we consider a sample of candidates drawn from $Ber(\mathit{pr})$ such that $\mathit{pr}=0.2$ is the fraction of protected candidates, i.e., $W_c=1$, in $\candidatesset$.
The sample is independently drawn both from the scores and ISO, following assumptions \textit{A1} and \textit{A2} in Section~\ref{sec:PositionBias}.
We can increase $\mathit{pr}$ to study a more diverse $\candidatesset$ and its effect on the screener reaching $q$.

For each set of the parameters ($n$, $k$, $q$, $\rho$, $\psi$), we run 10,000 times the experiments by randomly generating $n$ triplets at each run.
We consider $n=120, k=6, q=0.5$ for Sections~\ref{sec:Experiments.Metrics.outFatigue} and \ref{sec:Experiments.Metrics.withFatigue}.
The runs without a solution of the problem are discarded. 
This mainly occurs in the good-$k$ problem when there are not enough $k$ candidates with scores greater or equal than $\psi$.

%
% Figure environment removed
%

\subsubsection{Fatigued scores.}
Beyond the triplet, for the fatigued scores of $h_h$, we fix $\lambda=1$, hence $\Phi(t) = t$, and define:
%
\begin{itemize}
    \item 
    $\epsilon_1 \sim \mathcal{N}(0, \, (0.005 \cdot (t-1))^2)$, i.e., with constant expectation and standard deviation of $0.005 \cdot (t-1)$.
    %
    \item 
    $\epsilon_2 \sim \mathcal{N}(-0.005 \cdot (t-1), \, (0.001 \cdot (t-1))^2)$, i.e., with decreasing expectation and smaller standard deviation than $\epsilon_1$.
\end{itemize}
%
The assumptions \textit{A1} and \textit{A2}, and defining fatigue as a linear term in the final score \eqref{eq:BiasedScoresForHh} make the scoring function trivial in this setup. We purposely take for granted the truthful evaluation of $\candidatesset$ to focus on how $\theta$ and $h_h$'s fatigue affect the selected $k$ candidates.

\subsubsection{Evaluation metrics.} 
We consider the solution $S^k_{\besttext}$ of the best-$k$ problem \eqref{eq:fair_objective_all_screener} for $h_a$ (Algorithm~\ref{algo:Examination}) as \textit{the baseline solution} and compare it to the solutions of the good-$k$ problem \eqref{eq:fair_objective_U_psi} under $h_a$ (Algorithm~\ref{algo:Cascade}) 
and of best-$k$ and good-$k$ problems under $h_h$ (resp., Algorithms 3 and 4 in Appendix)
% ~\cite{DBLP:journals/corr/abs-2307-15398}).
We define two metrics to capture how close is a compared solution to the baseline solution:
%
\begin{itemize}
    \item 
    \textit{Ratio to baseline} (RtB) is the ratio of $U^k_{\addtext}$ between the compared solution and the baseline solution.
    When calculating the utility of $h_h$, we use the truthful scores, not the fatigued scores, to compare to the baseline.
    For the solution $S_{\goodtext}^k$ under $h_a$, e.g., it is $U^k_{\addtext}(S_{\goodtext}^k) / U^k_{\addtext}(S^k_{\besttext})$. 
    %
    \item 
    \textit{Jaccard similarity} (JdS) is the proportion of candidates in both the compared and baseline solutions over those in at least one of the two solutions. 
    For the solution $S_{\goodtext}^k$ under $h_a$, e.g., it is $|S_{\goodtext}^k \cap S^k_{\besttext}|\, / \, |S_{\goodtext}^k \cup S^k_{\besttext}|$. 
\end{itemize}
%
The RtB captures whether the compared solution achieves the same utility as the baseline solution as measured by $U^k_{\addtext}$, while the JdS captures the overlap in candidates between the compared solution and the baseline solution. 
For both metrics, the closer the ratio is to $1$, the better the compared solution approximates the baseline solution in terms of, respectively, utility and composition.
%
The plots report the mean output of these metrics over all the runs.

% \subsubsection{Simulations.}
% For each set of the parameters ($n$, $k$, $q$, $\rho$, $\psi$), we run 10,000 times the experiments by randomly generating $n$ triplets at each run.
% % For the next sections, 
% We consider $\mathbf{n=120, k=6, q=0.5}$ for the next two sections.
% The runs for which a solution of the problem does not exist are discarded. 
% This mainly occurs in the good-$k$ problem when there are not enough $k$ candidates with scores greater or equal than $\psi$.
% \textbf{The plots report the mean output based on the evaluation metrics over all the runs}.

\subsection{Experiments without Fatigue}
\label{sec:Experiments.Metrics.outFatigue}

Let us start with $h_a$ for clarifying the relation between the best-$k$ (Algorithm~\ref{algo:Examination}) and good-$k$ (Algorithm~\ref{algo:Cascade}) solutions,  
and are interested in whether these differ due to $\theta$ since the best-$k$ requires a full search while the good-$k$ allows for a partial search of $\candidatesset$.
%
To do so, we look at the impact of different individual scores distributions at the variation of $\psi$.
We consider the case for $\theta \ci s$ and focus on the good-$k$ as $\psi$ is specific to this problem.
%
Based on Figure~\ref{fig:1} (upper, center and right),
we find that the good-$k$ approximates the best-$k$ solution, especially when there is a low probability of having top candidates in $\candidatesset$, as $\psi$ increases and screening becomes more selective.
In fact, the $k$ first good-enough candidates essentially become the $k$ top candidates as $\psi$ increases.
%
The symmetric distribution of scores (in red) illustrates clearly this point: having few top candidates forces $h_a$ to explore more $\candidatesset$ following $\theta$, especially under an increasing $\psi$.
%
The opposite holds for the other two distributions of scores, asymmetric (in blue) and increasing (in green), which are more resilient to $\psi$ as each represents a higher concentration of top candidates in $\candidatesset$: having many top candidates makes it difficult for $h_a$ to select the $k$ top candidates under a partial search.

As the RtB and JdS metrics show in Figure~\ref{fig:1} (upper, center and right), $h_a$ still achieves significant utilities under the asymmetric and increasing score distributions relative to the symmetric score distribution but is unlikely to derive the same $k$ selected candidates under a partial search w.r.t.~a full search of $\candidatesset$ despite a large $\psi$.
Clearly, as noted in Remark~\ref{remark:ISOandPS}, where the $k$ top candidates fall within $\theta$ determines if they are selected or not by $h_a$ under the partial search.
Further, the position bias becomes more prevalent when $\candidatesset$ has many top candidates as even its best candidate may never be selected by $h_a$ if it lies at the bottom of $\theta$.

We also consider the case for $\theta \not\!\perp\!\!\!\perp s$, which further illustrate the role of $\theta$.
We study the impact $\rho$ where $\rho = -1$ essentially implies a ranked $\theta$.
Figure~\ref{fig:1} (lower, center and right) reports the RtB metric for the symmetric and increasing score distributions for different $\rho$'s and increasing $\psi$.
In short, an ISO that negatively correlates with candidate quality greatly reduces the difference in utility between the good-$k$ and best-$k$ solutions.
We find that the good-$k$ solution approximates well the best-$k$ solution already for $\rho=-0.5$, while for $\rho=-1$ the two solutions are the same.
These results are expected as $\theta$ represents the best-$k$ solution depending on $\rho$'s strength.
For instance, under $\rho=-1$, the $k$ first good-enough candidates are also the $k$ best candidates in $\candidatesset$. 

Further, we study the impact of changing the number of $n$ candidates in $\candidatesset$ and $k$ candidates to be selected.
Figure~\ref{fig:1} (lower, left) show the RtB for the symmetric score distribution under $\theta \ci s$, though the result hold for the other two distribution as well as under $\theta \not\!\perp\!\!\!\perp s$. 
We compare $n=120, k=6$ to $n=400, k=20$ and $n=30, k=6$ (with ratio of selected $k/n$, resp., of $0.05$ and $0.2$). 
The plots show that changes in the ratio $k/n$ affect the metric, in particular, a larger ratio leads good-$k$ to better approximate best-$k$ for a same $\psi$. 
Clearly, the influence of $\theta$ diminishes as $k/n$ increases.
%
Furthermore, we study the impact of changing $q$.
Here, results are expected given our underlying \textit{A1} and \textit{A2} assumptions, finding that under $\theta \ci s$, $q$ does not affect the relative strengths of best-$k$ and good-$k$ solutions. 
See Appendix.
% ~\cite{DBLP:journals/corr/abs-2307-15398}.

\subsection{Experiments with Fatigue}
\label{sec:Experiments.Metrics.withFatigue}

Let us now focus on $h_h$, and start by studying whether the screener's fatigue impacts the utility relative to the baseline solution (namely, Algorithm~\ref{algo:Examination}). 
We compare the best-$k$ and good-$k$ solutions with fatigue (Algorithms 3 and 4 in Appendix)
% ~\cite{DBLP:journals/corr/abs-2307-15398}) 
to such baseline.
%
We consider the case of $\theta \ci s$.
Figure~\ref{fig:4} (upper, left) shows the RtB metric for the three score distributions for the good-$k$ solution with fatigued scores due to $\epsilon_1$. 
Notice that in Figure~\ref{fig:1} (upper, center), for the asymmetric (in blue) and increasing (in green) score distributions, there is no considerable difference w.r.t. the case without fatigue.
%
In Figure~\ref{fig:4} (upper, left), instead, for the symmetric score distribution (in red) there is a considerable decrease under high $\psi$ values, which can be attributed to a low number of top scores on which $\epsilon_1$'s has a large effect.
For the other two score distributions, there are enough top scores such that $\epsilon_1$ does not change the top score distribution.
%
Since the RtB metric captures achieving the utility of the baseline model, $h_h$ is still able to reach high utility solutions under a partial search when $\candidatesset$ has many top candidates.
Note, thought, that as $\psi$ increases and screening becomes more selective, $h_h$ becomes more tired under $\theta$ as it needs to further search $\candidatesset$ to achieve $k$. 
Naturally, having enough top candidates reduces the need for $h_h$ to further search $\candidatesset$ as $\psi$ increases. 
%
Similar to Figure~\ref{fig:4} (upper, left), Figure~\ref{fig:4} (upper, center) considers the fatigued scores due to $\epsilon_2$. 
The effect on the symmetric distribution (in red) is not present here due to the lower standard deviation of $\epsilon_2$. 
The bias of $\epsilon_2$ does not impact screener utility too much under a $\candidatesset$ with low candidate quality.
Overall, under $\theta \ci s$, variance appears more relevant than bias in the case of low probability for top scores.
This result illustrates the importance of how we define fatigue.

Further, Figure~\ref{fig:4} (upper, right) shows the RtB for the best-$k$ solution at the variation of the quota $q$ that constrains the set selection based on group-level fairness goals. 
Here, there is a considerable and constant loss in screener utility under fatigue, which is more consistent for the symmetric score distribution (in red). 
The RtB is lower than in the case of the good-$k$ with fatigue for $\psi \geq 0.5$. 
This result means that, for the symmetric distribution, the good-$k$ solution with fatigue has better utility than the best-$k$ solution with fatigue. 
Such comparison shows the impact on $h_h$ from following for too long $\theta$, and indicate that one search procedure might be preferred over the other one in certain settings involving $h_h$.

We now consider the case for $\theta \not\!\perp\!\!\!\perp s$, looking at the impact of $\rho$ on $\theta$ with again a focus on the good-$k$ solution.  
Figure~\ref{fig:4} (lower, left) considers the symmetric score distribution (in red) where, for the lower half of $\psi$'s, the lines are similar to the analogous case without fatigue shown in Figure~\ref{fig:1} (lower, center). 
For the higher half of $\psi$'s, instead, there is a decrease in the RtB. 
Again, these results are due to the low probability of top scores for which the effects of the bias due to $\epsilon_1$ is not counter-balanced by $\rho$.
Such an effect does not appear for $\epsilon_2$ nor for $\epsilon_1$ under the increasing score distribution. 
In fact, Figure~\ref{fig:4} (lower, center) and (lower, right) closely resemble those in Figure~\ref{fig:1} (lower, center) and (lower, right), respectively.
It means that fatigue does not have an impact on the utility of the good-$k$ solution if there are sufficiently many top scores or a sufficiently small variability of the fatigue.
This last result points at the importance of providing a $\theta$ to the human screener with some information about candidate quality. 
Intuitively, under a partial search procedure and the threat of position bias through $\theta$, we would like to decrease $h_h$'s fatigue by minimizing its need to further search $\candidatesset$, which reinforces the role of IAS in the ISO problem.

%
% EOS
%
