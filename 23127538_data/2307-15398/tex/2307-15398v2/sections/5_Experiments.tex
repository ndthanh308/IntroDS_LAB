%
\label{sec:Experiments}

We explore the implications of the best-$k$ and good-$k$ settings, for both the algorithmic and human-like screeners, through Monte Carlo experiments. Algorithms~\ref{algo:Examination}--\ref{algo:HumanCascade} and the simulation procedures were developed in R \cite{Rlang}. The source code is provided in an anonymous repository: \url{https://anonymous.4open.science/r/initial-screening-order-problem-D078}.
% \footnote{Link: \url{https://anonymous.4open.science/r/initial-screening-order-problem-D078}.}

\subsection{Experimental Setup}
% \label{sect:expsetup}
\label{sec:Experiments.Setup}

Let us start detailing the random generation of inputs to the procedures.  
% Basically, 
We assume a sample consisting of $n$ triplets $(\theta({c_i}), s(\mathbf{X}_{c_i}), W_{c_i})$ for $i = 1, \ldots, n$, drawn from a probability distribution over the domain 
$\mathcal{G}_n \times \mathbb{R}^n \times \{0, 1\}^n$ where $\mathcal{G}_n$ is the set of all permutations of $\{1, \ldots, n\}$. 

Regarding the scores $s(\mathbf{X}_{c_i})$, we consider three possible marginal density distributions based on the \textit{truncated normal distribution family} \cite{Botev2017} $tN(\mu, \sigma)$ with values bounded in the $[0, 1]$ interval. 
The three distribution model scenarios where very good candidates (i.e.,~those with top scores) occur with different probabilities, as shown in Figure~\ref{fig:1} (left):
%
\begin{itemize}
    \item $tN(0.5, 0.02)$, shown in red, is a \textit{symmetric distribution} with mean/median of $0.5$, for which the top scores occur with very low probability. Hence, setting a large minimum basic requirement $\psi$ is higly selective.
%
    \item $tN(0.8, 0.05)$, shown in blue, is an \textit{asymmetric distribution} with a higher probability of top scores and a higher median value ($\approx 0.75$). In this scenario, a large $\psi$ is less selective of top candidates.
%
    \item $tN(1, 0.05)$, shown in green, is an \textit{increasing distribution}, with top scores occurring with high probability, and an even higher median value ($\approx 0.85$). In this scenario, there are many good candidates, and thus $\psi$ is not selective.
\end{itemize}
%

Regarding the initial order $\theta$, we consider the following possible variants:
%
\begin{itemize}
    \item  $\theta$ is randomly generated independently from the scores. This setting models the case where the screener prefers the alphabetical order, or performs a random shuffle of candidates. We denote such a scenario as $\theta \ci s$.
%
    \item $\theta$ is randomly generated with a given Spearman's rank correlation $\rho$ with the scores.\footnote{Formally, $\rho$ is the Spearman's rank correlation of the pairs $(\theta(c_i), s(\mathbf{X}_{c_i})$ for $i=1, \ldots, n$. It assesses how well the initial order $\theta$ monotonically relates to the scores of candidates. To generate correlated initial ordering and scores, we rely on copulas -- see e.g., \cite[Section 3.4]{EMBRECHTS2003329}.} 
    In particular, for $\rho=-1$, it means that $\theta$ ranks candidates by descending scores. %Correlation close to $-1$ models scenarios where the initial order is the result of some pre-evaluation of the candidates, including automatic ranking by ML models or manual ordering based on job-required skills. 
\end{itemize}
%

Regarding the protected attribute $W$, we consider a random sample drawn from $Ber(\mathit{pr})$, where $\mathit{pr}=0.2$ is the fraction of protected group candidates in the population. 
The sample is independently drawn from both the scores and the initial order, according to the assumptions \textit{A1} and \textit{A2} from Section~\ref{sec:HumanScreener.Analysis}. 
%For the former, it means that scores are not unfairly assigned by the screener. 
%For the the latter, it means that the initial order provided by the screener or by a ML ranking model is fair. Clearly, these two cases are also interesting to experiment with, but this is out of the scope of the paper.

Finally, regarding the fatigued scores, we fix $\lambda=1$, hence $\Phi(t) = t$, and then we define:
%
\begin{itemize}
    \item $\epsilon_1 \sim \mathcal{N}(0, \, (0.005 \cdot (t-1))^2)$, hence with constant expectation and with standard deviation of $0.005 \cdot (t-1)$; and
    %
    \item $\epsilon_2 \sim \mathcal{N}(-0.005 \cdot (t-1), \, (0.001 \cdot (t-1))^2)$, hence with a decreasing expectation and with a smaller standard deviation than $\epsilon_1$.
\end{itemize}
%

For each setting of the parameters ($n$, $k$, $q$, $\rho$, $\psi$ or others), we run 10,000 times the experiments by randomly generating $n$ triplets at each run. Runs for which a solution of the problem does not exist are discarded.\footnote{This mainly occurs in the best-$k$ problem when there are not enough candidates with scores greater or equal than $\psi$.} % and also satisfying the quota $q$ for the protected group.} 
Plots report the mean output (see evaluation metrics next) over the runs.

%
%\begin{example}[Junior Data Scientist for Hire]
%\label{RunningExample}
%    As an illustrative example, suppose G wants to hire three junior data scientists. The hiring manager provides a list of qualifications describing the ideal candidate: a good command of English (B1 or above), a technical background (Engineering, Physics, or equivalent), Python programming skills (command at least of the \texttt{numpy}, \texttt{pandas}, and \texttt{scikit-learn} packages), and familiarity with EU banking regulation models (Basel II and III). The hiring manager sets as the minimum basic requirement that candidates meet two of these qualifications.
%\end{example}
%

\subsection{Evaluation Metrics}
\label{sec:Experiments.Metrics}

The solution $S^k_{\besttext}$ of the fair best-$k$ problem (\ref{eq:fair_objective_all_screener}) for the algorithmic screener represents a baseline to compare with in the analysis of the solutions of the fair good-$k$ problem (\ref{eq:fair_objective_U_psi}) for the algorithmic screener, and of the solution of both fair best-$k$ and fair good-$k$ for the human-like screener. 
We introduce two comparison metrics.
%
%\begin{itemize}
    %\item 
    
    The \textit{ratio to baseline} is defined as the ratio of $U^k_{\addtext}$-utility between the compared solution and the baseline solution. E.g.,~for the solution $S_{\goodtext}^k$ of the algorithmic screener, it is $U^k_{\addtext}(S_{\goodtext}^k) / U^k_{\addtext}(S^k_{\besttext})$. 
    The closer the ratio is to $1$, the better the compared solution approximates the best-$k$ solution of the algorithmic screener in terms of $U^k_{\addtext}$ utility. 
    
    %\item 
    
    The \textit{Jaccard similarity} is defined as the proportion of candidates in both the compared and baseline solutions over those in at least one of the two. E.g., for the solution $S_{\goodtext}^k$ of the algorithmic screener, it is $|S_{\goodtext}^k \cap S^k_{\besttext}|/|S_{\goodtext}^k \cup S^k_{\besttext}|$. 
    Such a metric quantifies the share of candidates between the two solutions. 
    %The closer the metric is to $1$, the more equivalent is the set of selected candidates between the problems.
%\end{itemize}
%
% SR
%We will experiment with the values of these two metrics at the variation of $\psi$ and other parameter settings.


%
% Figure environment removed
%\vspace{-3ex}
%
%
% Figure environment removed
%\vspace{-3ex}
%
%
% Figure environment removed
%\vspace{-3ex}
%

\subsection{Experiments without Fatigue}
\label{sec:Experiments.Metrics.outFatigue}

We start exploring the settings without fatigue, which allows for clarifying the relation between good-$k$ and best-$k$ solutions. 
First, we consider the impact of the score distributions on the metrics at the variation of $\psi$. We fix the case of $n=120$ candidates, $k=6$ of which have to be selected, with a quota of $q=0.5$, and impose independence between $\theta$ and the scores. 
Figure~\ref{fig:1} (center, right) show the ratio to baseline and the Jaccard similarity for the three experimental densities. 
The symmetric distribution allows for  good-$k$ to better approximate the baseline for medium-to-high $\psi$'s. 
This result is expected, as having less candidates with high scores, $tN(0.5, 0.02)$ allows for finding the best ones by restricting to higher scores through the $\psi$ parameter. 
For the other two distributions, the opposite holds: having many good candidates makes it difficult to select the best ones only acting on $\psi$. 
In the case of the Jaccard similarity, the set of candidates selected by best-$k$ and 
good-$k$
greatly differ, unless there are few top candidates. 
\textit{In summary, under $\theta \ci s$, good-$k$ is an approximation of best-$k$   where there is a low probability of having good candidates in the pool}.

Second, we consider the impact of the number $n$ candidates in $\candidatesset$ and the number of $k$ candidates to be selected. 
We focus only on the symmetric distribution and the ratio to baseline, but the results are similar for the other two distributions and the Jaccard similarity. 
Figure~\ref{fig:2} (left) compares the case $n=120, k=6$ considered earlier to two other scenarios. 
The first scenario increases $k=20$ but leaves the ratio of selected $k/n = 0.05$ the same by also increasing $n=400$. 
The second scenario, instead, leaves $k=6$ the same, but it increases $k/n = 0.2$ by decreasing $n=30$. 
The plot shows that changes in the ratio $k/n$ affect the metric, in particular a larger ratio ($n=30$, $k=6$) leads good-$k$ to better approximate best-$k$ for a same $\psi$. The more candidates we can select from the pool, the better the chance to include top ones. 
\textit{In summary, under $\theta \ci s$, the ratio $k/n$ is positively correlated with the ability of best-$k$ to approximate good-$k$}.

Third, we now consider the impact of the correlation $\rho$ between the initial order $\theta$ and the scores. 
Recall that $\rho = -1$ means that the candidates are ordered by descending scores. Under such a condition, the good-$k$ and best-$k$ procedures return the same solution. 
This result is apparent in Figure~\ref{fig:2} (center, right) where we report the ratio to baseline for the symmetric (left) and the increasing (right) score distributions. 
The plots show that even a moderate correlation of $\rho = -0.5$ leads the good-$k$ solution to approximate the best-$k$ one quite well. 
For the increasing distribution (right plot), the ratio to baseline is around 95\%. \textit{In summary, initial orders that negatively correlate to the score greatly reduce the difference in utility between the good-$k$ and best-$k$ solutions}.

Let us now consider the quota parameter $q$, thus far set to $q=0.5$ over a population with a fraction of protected candidates set to $\mathit{pr}=0.2$. 
Since we assumed that $W$ is independent from both scores and initial orders, the fraction of protected group in the solutions of best-$k$ and good-$k$ is, on average, $\mathit{min}\{q, \mathit{pr}\}$. 
Figure~\ref{fig:3} (left) shows this result in the solution for good-$k$. 
A less trivial question is whether $q$ is also not affecting the evaluation metrics, e.g., whether the quota $q$ changes the ratio to baseline? 
Figure~\ref{fig:3} (center, right) show that this is not the case in two experimental settings. 
Again, this result is theoretically implied by the independence of $W$ with scores and initial order. \textit{In summary, under $\theta \ci s$, the quota parameter in the best-$k$ and good-$k$ problem does not affect the relative strengths of their solutions.}


\subsection{Experiments with Fatigue}
\label{sec:Experiments.Metrics.withFatigue}

%Let us now consider the setting with fatigue.
First, we consider whether fatigue impacts on utility w.r.t.~the baseline, namely the solution of best-$k$ without fatigue. 
We compare to such a baseline both the good-$k$ with fatigue (Algorithm.~\ref{algo:HumanCascade}) and best-$k$ with fatigue (Algorithm.~\ref{algo:HumanExamination}).
%See Appendix~\ref{Appendix.HumanAlgorithms} for implementation details on both of these algorithms.
%In the latter case, we readily extend the metric of ratio to baseline as the ratio of the utility for the solution of best-$k$ with fatigue over the one of best-$k$ without fatigue. 

Figure~\ref{fig:4} (left) shows the ratio to the baseline for the three score distributions for the good-$k$ solution with fatigue based on error $\epsilon_1$ for the fatigued scores. 
For the asymmetric and increasing distributions, there is not much difference w.r.t.~the case without fatigue (see Figure~\ref{fig:1} (center)). 
For the symmetric distribution, instead, there is a considerable decrease for high $\psi$'s. 
This can be attributed to the low number of top scores, for which the perturbation due the $\epsilon_1$'s has a large effect. For the other two distributions, instead, there are sufficiently many top scores, for which perturbation does not dramatically change the score distribution for top scores.
Figure~\ref{fig:4} (center) is analogous to (left), but considering fatigued scores based on $\epsilon_2$. 
The effect for the symmetric distribution is not present in such a case, due to the lower standard deviation of $\epsilon_2$. 
The bias of $\epsilon_2$ does not impact too much, apart from high values of $\psi$ where it causes the problem not to have a solution (fatigued scores are smaller than scores of an already low number of top candidates). 
\textit{In summary, under $\theta \ci s$, variance appears more relevant than bias in the case of low probability of top scores.}

Figure~\ref{fig:4} (right) shows the ratio to the baseline for the best-$k$ solution with fatigue at the variation of the quota $q$. There is a considerable and constant loss in utility under fatigue, which is more consistent for the symmetric distribution. 
Interestingly enough, the ratio to baseline is lower than in the case of the good-$k$ with fatigue (see left) for $\psi \geq 0.5$. This means that, \textit{for the symmetric distribution, the good-$k$ solution with fatigue has better utility than the best-$k$ solution with fatigue}. 
This noteworthy result can inform the screening practice.

Finally, we consider the impact of the correlation $\rho$ in the initial order $\theta$ for the good-$k$ solution with fatigue.  
Figure~\ref{fig:5} (left) considers the symmetric distribution. 
For the lower half of $\psi$'s, lines are similar to the analogous case without fatigue shown in Figure~\ref{fig:2} (center). 
For the higher half of $\psi$'s, instead, there is a decrease in the metric. This is, again, due to the low probability of top scores, for which the effects of the variability of $\epsilon_1$ is not counter-balanced by correlation of the scores and initial order.
Such an effect does not appear for $\epsilon_2$ nor for $\epsilon_1$ with the increasing distribution. 
In fact, the plots in Figure~\ref{fig:5} (center) and (right) closely resemble those in Figure~\ref{fig:2} (center) and (right) respectively. 
This is an interesting result on its own. 
It means that, \textit{in the presence of correlation, fatigue does not have an impact on utility of the good-$k$ solution if there are sufficiently many top scores or a sufficiently small variability of the fatigue.}

%
% EOS
%


%
% Figure environment removed
%
%
% Figure environment removed
%\vspace{-3ex}
%