%%
% \documentclass[manuscript,screen,review,anonymous]{acmart}
%%% For arXiv
\documentclass[manuscript,nonacm]{acmart}

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information. This information is sent to you
\setcopyright{acmlicensed}
\copyrightyear{2024}
\acmYear{2024}
\acmDOI{XXXXXXX.XXXXXXX}
%
\acmConference[FAccT '24]{2023 ACM Conference on Fairness, Accountability, and Transparency}{June 3--6, 2024}{Rio de Janeiro, Brazil}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
\acmBooktitle{2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '23), June 3--6, 2024, Rio de Janeiro, Brazil}

%% Submission ID. This information is sent to you
%%\acmSubmissionID{123-A56-BU3}

%% Packages
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{orcidlink}
\usepackage{dsfont}
\usepackage{bbold}

%% Other:
\newtheorem{remark}{Remark}
\newcommand{\sr}[1]{\textcolor{orange}{#1}}
\newcommand{\ja}[1]{\textcolor{blue}{#1}}
\newcommand{\am}[1]{\textcolor{purple}{#1}}
\newcommand{\candidatesset}{\mathcal{C}}
\newcommand{\candidatessubset}{\mathcal{D}}
\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \littletaller % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
  }}
\newcommand{\littletaller}{\mathchoice{\vphantom{\big|}}{}{}{}}
\newcommand{\besttext}{\text{\textit{best}}}
\newcommand{\goodtext}{\text{\textit{good}}}
\newcommand{\addtext}{\text{\textit{add}}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\ci}{\mathrel{{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}
%%
\begin{document}

%%
\title{The Initial Screening Order Problem}

%%
\author{Jose M. Alvarez \orcidlink{0000-0001-9412-9013}}
\email{jose.alvarez@sns.it}
% \orcid{0000-0001-9412-9013}
\affiliation{
  \institution{Scuola Normale Superiore, University of Pisa}
  \city{Pisa}
  \country{Italy}
}

\author{Antonio Mastropietro \orcidlink{0000-0002-8823-0163}}
% \orcid{0000-0002-8823-0163}
\affiliation{
  \institution{University of Pisa}
  \city{Pisa}
  \country{Italy}
}

\author{Salvatore Ruggieri \orcidlink{0000-0002-1917-6087}}
\email{salvatore.ruggieri@unipi.it}
% \orcid{0000-0002-1917-6087}
\affiliation{
  \institution{University of Pisa}
  \city{Pisa}
  \country{Italy}
}

%%
\renewcommand{\shortauthors}{Alvarez, Mastropietro, and Ruggieri}

%%
\begin{abstract}
    We investigate the role of the initial screening order (ISO) in candidate screening processes, such as hiring and academic admissions. ISO refers to the order in which the screener sorts the candidate pool before the evaluation. It has been largely overlooked in the literature, despite its potential impact on the optimality and fairness of the chosen set, especially under a human screener. We define two problem formulations: best-$k$, where the screener chooses the $k$ best candidates, and good-$k$, where the screener chooses the first $k$ good-enough candidates. To study the impact of ISO, we introduce a human-like screener and compare to its algorithmic counterpart. The human-like screener is conceived to be inconsistent over time due to fatigue. Our analysis shows that the ISO under a human-like screener hinders individual fairness despite meeting group level fairness. This is due to the position bias, where a candidate's evaluation is affected by its position within ISO. We report extensive simulated experiments exploring the parameters of the problem formulations both for algorithmic and human-like screeners. This work is motivated by a real world candidate screening problem studied in collaboration with a large European company. 
\end{abstract}

%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003123.10011758</concept_id>
       <concept_desc>Human-centered computing~Interaction design theory, concepts and paradigms</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10002951.10003317.10003338</concept_id>
       <concept_desc>Information systems~Retrieval models and ranking</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Retrieval models and ranking}
\ccsdesc[500]{Human-centered computing~Interaction design theory, concepts and paradigms}

%%
\keywords{fair set selection, position bias, candidate screening, human-in-the-loop}

%%% For arXiv
%%
% \received{}
% \received[revised]{}
% \received[accepted]{}

%%
\maketitle

\section{Introduction}
\input{sections/1_Introduction}

\section{Qualitative Background}
\input{sections/2_Generali}

\section{Problem Formulation and Search Procedures}
\input{sections/3_ProblemFormulation}

\section{The Human-Like Screener}
\input{sections/4_HumanScreener}

\section{Experiments}
\input{sections/5_Experiments}

\section{Conclusion}
\input{sections/6_Discussion}

%%% For arXiv
% \newpage
% \section*{Research Ethics and Social Impact}
% % Authors should describe the ethical challenges they faced in their submission, ideally in a dedicated section, and how they addressed such challenges. In particular, submissions that (1) describe experiments with users and/or deployed systems (e.g., websites or apps), or (2) rely on sensitive user data (e.g., social network information), must adhere to precepts of ethical research and community norms. These include compliance with applicable laws and applicable professional ethical codes; respect for privacy; secure storage of sensitive data; voluntary and informed consent when appropriate; avoiding deceptive practices when not essential; beneficence and non-maleficence (maximizing the benefits to an individual or society while minimizing harm to the individual); risk mitigation; and post-hoc disclosure of audits.
% In this section, we describe the ethical challenges faced during this work as well as clarify any potential negative social impact this work might have in the future.

% \paragraph{Ethical considerations}
% % 1) a description of the ethical concerns the authors mitigated while conducting the work (as part of an ethical considerations statement)
% Given the nature of this work, which is mainly theoretical, to the best of our knowledge, we did not face any ethical challenges when drafting the paper. Our experiments are based on simulated data intended to illustrate our theoretical analysis. During our collaboration with company G, in particular, which occurred before the drafting of this paper, we followed G's strict ethical guidelines at all times. We concluded our collaboration with G with an internal report that we presented and discussed with all stakeholders. No sensitive data (or data at all) from company G was used for this work. At no point did we receive monetary compensation from G. Our research has been funded by public institutions. The views reflected in this paper are entirely our own.

% \paragraph{Researcher positionality}
% % 2) reflections on how their background and experiences inform or shape the work (as part of a researcher positionality statement)
% The authors come from a mixed of backgrounds, both personal and academic. To ensure anonymity, we do not disclose here further information about the authors, but we are committed to provide the necessary details if this submission is successful. We will provide a positionality statement per author. 
 
% \paragraph{Adverse impact}
% % 3) reflection on the adverse, unintended impact the work might have once published (as part of an adverse impact statement)
% We believe that this work shows the importance of considering the human user in the formulation of the candidate screening problem. We want to stress that our distinction between an algorithmic screener and a human-like screener was to show the importance of considering the latter kind and not to endorse the former kind. We strongly believe that candidate screening is a complex, human-dependent and human-centered process that should not be left only to ADM systems.

%%
\begin{acks}
    Jose M. Alvarez and Salvatore Ruggieri received funding from the European Union’s Horizon 2020 research and innovation program under Marie Sklodowska-Curie Actions (grant agreement number 860630) for the project "NoBIAS - Artificial Intelligence without Bias". 
    Antonio Mastropietro and Salvatore Ruggieri received funding from the European Union’s Horizon Europe (grant agreement number 101070212) for the FINDHR project.
    This work reflects only the authors' views and the European Research Executive Agency is not responsible for any use that may be made of the information it contains.
    No other funding was received by the authors.
\end{acks}

%%
% \newpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

%%
\newpage
\appendix
\input{sections/Appendix}

%%
\end{document}

%
% EOF
%
