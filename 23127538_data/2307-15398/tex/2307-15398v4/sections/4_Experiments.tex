%
\label{sec:Experiments}

We introduce a flexible experimental framework in R \cite{Rlang}, based on Monte Carlo simulations, to study the implications of the \textit{initial screening order} (ISO) for the best-$k$ and good-$k$ problems. 
It can handle different screening scenarios under the algorithmic $h_a$ or human-like $h_h$ screeners.
% The Algorithms~\ref{algo:Examination}--\ref{algo:HumanCascade} and simulation procedures are developed in R \cite{Rlang}.
% The source code is provided in an anonymous repository: \url{https://anonymous.4open.science/r/initial-screening-order-problem-E3DE/}.
Visit the following GitHub repository for the code: \url{https://github.com/cc-jalvarez/initial-screening-order-problem/tree/main}.

\subsection{Setup}
\label{sec:Experiments.Setup}

%
% Figure environment removed
%

\subsubsection{Generating the sample.}
We assume a sample consisting of $n$ triplets $\{ (s(\mathbf{X}_{c_i}), \theta({c_i}), W_{c_i}) \}_{i=1}^n$ drawn from a probability distribution with domain $\mathcal{G}_n \times \mathbb{R}^n \times \{0, 1\}^n$, where $\mathcal{G}_n$ is the set of all permutations of $\{1, \ldots, n\}$. Each sample represents a candidate pool $\candidatesset$ sorted according to an ISO $\theta$.

For the candidate scores, $s(\mathbf{X}_{c_i})$, we consider \textit{three distributions} to model scenarios in which top candidates, i.e., top scores, occur with different probabilities in $\candidatesset$. All three distributions use the truncated normal, $tN(\mu, \sigma)$ \cite{Botev2017}, with values bounded in $[0, 1]$. These scenarios, illustrated in Figure~\ref{fig:1} (left), are:
%
\begin{itemize}
    \item 
    \textit{Symmetric distribution of scores} (in red) defined by $\mu = 0.5$ and $\sigma = 0.02$,
    % $tN(0.5,0.02)$, with mean/median of $0.5$ 
    implying that top candidates occur with a very low probability in $\candidatesset$. 
    % Hence, setting a large minimum basic requirement $\psi$ is highly selective of top candidates.
    %
    \item 
    \textit{Asymmetric distribution of scores} (in blue) defined by $\mu = 0.8$ and $\sigma = 0.05$,
    % $tN(0.8, 0.05)$ 
    implying that top candidates occur with a higher probability and median value ($\approx 0.75$) in $\candidatesset$ compared to the previous scenario. 
    % Hence, setting a large $\psi$ is less selective of top candidates.
    %
    \item 
    \textit{Increasing distribution of scores} (in green) defined by $\mu = 1$ and $\sigma = 0.05$,
    % $tN(1, 0.05)$ 
    implying that top candidates occur with an even higher probability and median value ($\approx 0.85$) in $\candidatesset$ compared to the previous scenarios. 
    % In this scenario, there are many good candidates, and thus $\psi$ is not selective.
\end{itemize}
%
These thee scenarios have implications, in particular, for the good-$k$ problem where we set the minimum score $\psi$ and the screener is not required to explore all of $\candidatesset$ under $\theta$ (Remark~\ref{remark:ISOandPS}).
Setting a large $\psi$ makes the screening process highly selective in the first scenario, less selective in the second scenario, and not selective at all in the third scenario, representing candidate pools with different candidate quality on average.

For the ISOs, $\theta(c_i)$, we consider \textit{two settings} in which a given $\theta$ relates or not to $s(\mathbf{X}_{c_i})$, allowing us to explore $\theta$ as a product of different information access systems:
%
\begin{itemize}
    \item \textit{$\theta$ is generated randomly and independently from the candidate scores}. Formally, $\theta \ci s$.
    %
    \item \textit{$\theta$ is generated randomly with a correlation $\rho$ with the candidate scores}, where $\rho$ is the Spearman's rank correlation of the pairs $\{ (\theta(c_i), s(\mathbf{X}_{c_i})) \}_{i=1}^k$.\footnote{To generate the correlated $\theta$, we rely on copulas \cite[Section 3.4]{EMBRECHTS2003329}.} Formally, $\theta \not\!\perp\!\!\!\perp s$.
\end{itemize}
%
% It assesses how well $\theta$ monotonically relates to the scores of candidates.
Under $\theta \ci s$, $\theta$ carries no information about the candidate quality in $\candidatesset$. It captures settings where the screener uses the information access system to sort alphabetically or perform a random shuffle of the candidates.
Under $\theta \not\!\perp\!\!\!\perp s$, in particular for $\rho=-1$, $\theta$ sorts candidates by descending scores. It captures settings where the screener obtains a ranked (i.e., informative) list of candidates from the information access system.

Finally, with regard to protected candidates, i.e., $W=1$, 
we initially consider the sample of candidates drawn from $Ber(\mathit{pr})$ such that $\mathit{pr}=0.2$ is the fraction of protected candidates in $\candidatesset$.
The sample is independently drawn from both the scores and the ISO, according to assumptions \textit{A1} and \textit{A2} in Section~\ref{sec:PositionBias}.
We then increase $\mathit{pr}$ to study a more diverse $\candidatesset$ and its effect on the screener reaching the representational quota $q$.

\subsubsection{Fatigued scores.}
Beyond the triplet, for the fatigued scores of $h_h$, we fix $\lambda=1$, hence $\Phi(t) = t$, and define:
%
\begin{itemize}
    \item 
    $\epsilon_1 \sim \mathcal{N}(0, \, (0.005 \cdot (t-1))^2)$, i.e., with constant expectation and standard deviation of $0.005 \cdot (t-1)$; and
    %
    \item 
    $\epsilon_2 \sim \mathcal{N}(-0.005 \cdot (t-1), \, (0.001 \cdot (t-1))^2)$, i.e., with decreasing expectation and smaller standard deviation than $\epsilon_1$.
\end{itemize}
%
Assumptions \textit{A1}, \textit{A2}, and the fact that we define fatigue as a linear term in the final score \eqref{eq:BiasedScoresForHh} make the scoring function trivial in this setup.
We purposely take for granted the truthful evaluation of the candidates in $\candidatesset$ to focus on how $\theta$ and the fatigue of $h_h$ affect the selected set of $k$ candidates.

\subsubsection{Evaluation metrics.} 
We consider the solution $S^k_{\besttext}$ of the best-$k$ problem (\ref{eq:fair_objective_all_screener}) for $h_a$ (Algorithm~\ref{algo:Examination}) as \textit{the baseline solution}. 
We compare it with the the solutions for the good-$k$ problem (\ref{eq:fair_objective_U_psi}) under $h_a$ (Algorithm~\ref{algo:Cascade}), 
and the solutions for both the best-$k$ (\ref{eq:fair_objective_all_screener}) and good-$k$ (\ref{eq:fair_objective_U_psi}) problems under $h_h$ (respectively, Algorithms \ref{algo:HumanExamination} and \ref{algo:HumanCascade}).
We define two metrics to capture how close is the compared solution to the baseline solution:
%
\begin{itemize}
    \item 
    \textit{Ratio to baseline} (RtB) is the ratio of $U^k_{\addtext}$ between the compared solution and the baseline solution.
    When calculating the utility of $h_h$, we use the truthful scores, not the fatigued scores, to compare to the baseline.
    For the solution $S_{\goodtext}^k$ under $h_a$, e.g., it is $U^k_{\addtext}(S_{\goodtext}^k) / U^k_{\addtext}(S^k_{\besttext})$. 
    %
    \item 
    \textit{Jaccard similarity} (JdS) is the proportion of candidates in both the compared and baseline solutions over those in at least one of the two solutions. 
    For the solution $S_{\goodtext}^k$ under $h_a$, e.g., it is $|S_{\goodtext}^k \cap S^k_{\besttext}|\, / \, |S_{\goodtext}^k \cup S^k_{\besttext}|$. 
\end{itemize}
%
The RtB captures whether the compared solution achieves the same utility as the baseline solution as measured by $U^k_{\addtext}$, while the JdS captures the overlap in candidates between the compared solution and the baseline solution. 
For both metrics, the closer the ratio is to $1$, the better the compared solution approximates the baseline solution in terms of, respectively, utility and composition.

\subsubsection{Simulations.}
For each set of the parameters ($n$, $k$, $q$, $\rho$, $\psi$), we run 10,000 times the experiments by randomly generating $n$ triplets at each run. 
The runs for which a solution of the problem does not exist are discarded. 
This mainly occurs in the good-$k$ problem when there are not enough $k$ candidates with scores greater or equal than $\psi$.
\textbf{The plots report the mean output based on the evaluation metrics over all the runs}.

\subsection{Experiments without Fatigue}
\label{sec:Experiments.Metrics.outFatigue}

We start by considering $h_a$ to clarify the relation between the best-$k$ (Algorithm~\ref{algo:Examination}) and good-$k$ (Algorithm~\ref{algo:Cascade}) solutions. 
Here, we are interested if their solutions differ due to $\theta$, since the best-$k$ requires a full search while the good-$k$ allows for a partial search of $\candidatesset$.

Let us study the impact of the score distributions at the variation of $\psi$.
We consider \textbf{the case of} $\mathbf{n=120, k=6, q=0.5}$ \textbf{and} $\mathbf{\theta \ci s}$, with a focus on the good-$k$ as $\psi$ is specific to this problem.
%
We find that, as $\psi$ increases and screening becomes more selective, the good-$k$ approximates the best-$k$ solution, especially when there is a low probability of having top candidates in $\candidatesset$.
%
The symmetric distribution of scores (in red) in Figure~\ref{fig:1} (center, right) illustrates this point. Having few top candidates forces $h_a$ to explore more $\candidatesset$ under $\theta$, especially as $\psi$ increases and the $k$ first good-enough candidates essentially become the $k$ top candidates.
%
The opposite holds for the other two distributions of scores, asymmetric (in blue) and increasing (in green), which are more resilient to $\psi$ as each represents a higher concentration of top candidates in $\candidatesset$.
Having many top candidates makes it difficult for $h_a$ to select the $k$ top candidates under a partial search.
As the RtB and JdS metrics show in Figure~\ref{fig:1} (center, right), $h_a$ still achieves significant utilities under the other two distributions but is unlikely to derive the same selected set of candidates under a partial search w.r.t.~a full search of $\candidatesset$ despite having a highly selective $\psi$.
% These results are also expected, but worth emphasizing. Having many good candidates means that $h_a$ can still partially search $\candidatesset$ despite having a highly selective $\psi$: i.e., $h_a$ finds $k$ good-enough candidates with high-enough scores as the $k$ top candidates but not the same ones.

Figure~\ref{fig:1}, in short, illustrates how the two set selection problems materialize differently due to $\theta$.
Clearly, as noted in Remark~\ref{remark:ISOandPS}, where the $k$ top candidates appear in $\theta$ can determine if they are selected or not by $h_a$ under a partial search.
The position bias in the ISO becomes more prevalent under many top candidates as even the $\candidatesset$'s best candidate may never be selected by $h_a$ under a partial search if it lies at the bottom of $\theta$.

We also study \textbf{the case when} $\mathbf{\theta \not\!\perp\!\!\!\perp s}$, which we present in Appendix~\ref{Appendix:Experiments.Metrics.outFatigue}.
Here, we briefly discuss these results as they further illustrate the role of $\theta$.
We find that the good-$k$ solution approximates quite well the best-$k$ solution already for $\rho=-0.5$, while for $\rho=-1$, the two solutions are the same.
These results are expected as $\theta$ essentially represents the best-$k$ solution (or an approximation of it) depending on $\rho$'s strength. 
Under $\rho=-1$, e.g., the $\theta$ searched by $h_a$ is already sorted by the candidate scores and, in turn, the $k$ first good-enough candidates are also the $k$ best candidates in $\candidatesset$. 
See Figure~\ref{fig:2} (center, right) for details.

Further, for \textbf{both cases} we also study \textbf{the impact of changing the number of candidates $n$ and selected candidates $k$}. 
The plots are shown in Appendix~\ref{Appendix:Experiments.Metrics.outFatigue}
We find that under $\theta \ci s$, the ratio $k/n$ is positively correlated with the ability of the good-$k$ to approximate best-$k$. 
% Intuitively and unsurprisingly, i
It means that the more candidates we can select from $\candidatesset$, the better the chance to include top ones under a partial search.
Clearly, the influence of $\theta$ diminishes as $k/n$ increases.
See Figure~\ref{fig:2} (left).
Similarly, we study \textbf{the impact of changing the representational quota $q$}. 
Here, results are expected given our underlying \textit{A1} and \textit{A2} assumptions, finding that under $\theta \ci s$, $q$ does not affect the relative strengths of best-$k$ and good-$k$ solutions.
See Figure~\ref{fig:3} (all).

%%%
%%% Moved to Appendix
% Second, we consider the impact of the number $n$ candidates in $\candidatesset$ and the number of $k$ candidates to be selected. 
% We focus only on the symmetric distribution and the ratio to baseline, but the results are similar for the other two distributions and the Jaccard similarity. 
% Figure~\ref{fig:2} (left) compares the case $n=120, k=6$ considered earlier to two other scenarios. 
% The first scenario increases $k=20$ but leaves the ratio of selected $k/n = 0.05$ the same by also increasing $n=400$. 
% The second scenario, instead, leaves $k=6$ the same, but it increases $k/n = 0.2$ by decreasing $n=30$. 
% The plot shows that changes in the ratio $k/n$ affect the metric, in particular a larger ratio ($n=30$, $k=6$) leads good-$k$ to better approximate best-$k$ for a same $\psi$. The more candidates we can select from the pool, the better the chance to include top ones. 
% \textit{In summary, under $\theta \ci s$, the ratio $k/n$ is positively correlated with the ability of best-$k$ to approximate good-$k$}.

% Third, we now consider the impact of the correlation $\rho$ between the initial order $\theta$ and the scores. 
% Recall that $\rho = -1$ means that the candidates are ordered by descending scores. Under such a condition, the good-$k$ and best-$k$ procedures return the same solution. 
% This result is apparent in Figure~\ref{fig:2} (center, right) where we report the ratio to baseline for the symmetric (left) and the increasing (right) score distributions. 
% The plots show that even a moderate correlation of $\rho = -0.5$ leads the good-$k$ solution to approximate the best-$k$ one quite well. 
% For the increasing distribution (right plot), the ratio to baseline is around 95\%. \textit{In summary, initial orders that negatively correlate to the score greatly reduce the difference in utility between the good-$k$ and best-$k$ solutions}.

% %
% % Figure environment removed
% %\vspace{-3ex}
% %

% Let us now consider the quota parameter $q$, thus far set to $q=0.5$ over a population with a fraction of protected candidates set to $\mathit{pr}=0.2$. 
% Since we assumed that $W$ is independent from both scores and the ISO, the fraction of protected group in the solutions of best-$k$ and good-$k$ is, on average, $\mathit{min}\{q, \mathit{pr}\}$. 
% Figure~\ref{fig:3} (left) shows this result in the solution for good-$k$. 
% A less trivial question is whether $q$ is also not affecting the evaluation metrics: e.g., whether the quota $q$ changes the ratio to baseline? 
% Figure~\ref{fig:3} (center, right) show that this is not the case in two experimental settings. 
% Again, this result is theoretically implied by the independence of $W$ with scores and initial order. 
% In summary, under $\theta \ci s$, the quota parameter in the best-$k$ and good-$k$ problem does not affect the relative strengths of their solutions.
%%%
%%%

\subsection{Experiments with Fatigue}
\label{sec:Experiments.Metrics.withFatigue}

%
% Figure environment removed
%

We now focus on $h_h$, and start by studying whether fatigue impacts the utility w.r.t.~the baseline solution (namely, Algorithm~\ref{algo:Examination}). 
We compare to such a baseline both the best-$k$ with fatigue (Algorithm.~\ref{algo:HumanExamination}) and good-$k$ with fatigue (Algorithm.~\ref{algo:HumanCascade}) solutions.

We again consider \textbf{the case of} $\mathbf{n=120, k=6, q=0.5}$ \textbf{and} $\mathbf{\theta \ci s}$.
Figure~\ref{fig:4} (left) shows the RtB metric for the three score distributions for the good-$k$ solution with \textbf{fatigued scores due to $\epsilon_1$}. 
Based on Figure~\ref{fig:1} (center), for the asymmetric (in blue) and increasing (in green) score distributions, there is no considerable difference w.r.t.~the case without fatigue.
%
Instead, for the symmetric score distribution (in red), there is a considerable decrease under high $\psi$ values, which can be attributed to the low number of top scores on which $\epsilon_1$'s has a large effect.
%
For the other two score distributions, we have that there are enough top scores such that $\epsilon_1$ does not change the top score distribution.
Since the RtB metric captures achieving the utility of the baseline model, under a partial search $h_h$ is still able to reach high utility solutions when $\candidatesset$ has many top candidates.
As $\psi$ increases and $h_h$ becomes more selective, it also becomes more tired under $\theta$ as it needs to search more and more candidates to achieve $k$. 
Even as $\psi$ increases and $h_h$ becomes more selective, having enough top candidates reduces the need for $h_h$ to continue searching $\candidatesset$ and, in turn, increase its fatigue. 
%
Figure~\ref{fig:4} (center) is analogous to (left), but considers the \textbf{fatigued scores based on $\epsilon_2$}. 
The effect for the symmetric distribution (in red) is not present in such a case, due to the lower standard deviation of $\epsilon_2$. 
% The bias of $\epsilon_2$ does not impact too much, apart from high values of $\psi$ where it causes the problem of not having a solution. 
% as fatigued scores are smaller than scores of an already low number of top candidates. 
Under $\theta \ci s$, variance appears more relevant than bias in the case of low probability for top scores.
This result illustrates the importance of how we define fatigue. 
% It can also inform how the a human screener should behave in practice to diminish the role of position bias within $\theta$. 
% Given these results, e.g., we would be interested in exploring under what settings would the human screener experience $\epsilon_1$ over $\epsilon_2$.

For \textbf{the case when} $\mathbf{\theta \not\!\perp\!\!\!\perp s}$,
Figure~\ref{fig:4} (right) shows the RtB for the \textbf{best-$k$ solution at the variation of the quota $q$}. 
There is a considerable and constant loss in utility under fatigue, which is more consistent for the symmetric score distribution (in red). 
Note that the RtB is lower than in the case of the good-$k$ with fatigue (see left) for $\psi \geq 0.5$. 
This result means that, for the symmetric distribution, the good-$k$ solution with fatigue has better utility than the best-$k$ solution with fatigue. 

Finally, we consider \textbf{the impact of $\mathbf{\rho}$ on $\mathbf{\theta}$ on the good-$k$ solution}.  
Figure~\ref{fig:5} (left) considers the symmetric score distribution (in red) where, for the lower half of $\psi$'s, the lines are similar to the analogous case without fatigue shown in Figure~\ref{fig:2} (center). 
For the higher half of $\psi$'s, instead, there is a decrease in the metric. 
Again, these results are due to the low probability of top scores for which the effects of the bias due to $\epsilon_1$ is not counter-balanced by $\rho$.
Such an effect does not appear for $\epsilon_2$ nor for $\epsilon_1$ under the increasing score distribution. 
In fact, Figure~\ref{fig:5} (center) and (right) closely resemble those in Figure~\ref{fig:2} (center) and (right) respectively.
It means that fatigue does not have an impact on utility of the good-$k$ solution if there are sufficiently many top scores or a sufficiently small variability of the fatigue.
%
Further, this last result points at the importance of providing a $\theta$ to the human screener with some information about candidate quality. 
Intuitively, under a partial search procedure and the threat of position bias materializing through $\theta$, we would like to decrease $h_h$'s fatigue by minimizing its need to search more of $\candidatesset$, reinforcing the role of information access systems.

%
% EOS
%
