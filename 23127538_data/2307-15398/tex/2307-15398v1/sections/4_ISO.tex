%
\label{sec:ISO}

In this section we show that the arrangement of the candidate pool prior to the screening, or the \textit{initial order} (Section~\ref{sec:InitialOrderDef}), matters for obtaining an optimal and fair selection of candidates under the human-like screener (henceforth, screener). The source of bias, as we show, comes from the position bias inherent in the initial order chosen by the screener. Let us explore the initial screening order problem.

\subsection{Two Search Algorithms}
\label{sec:ISO:SearchAlgorithms}

The screener can choose how to search the initial order $\theta$ (or $\mathcal{C}_{\mathbf{s}}$). We present the two search procedures available to the screener based on the HR officers at G. To focus only on the search procedures, we ignore the fairness representation goals here; we come back to this point in Section~\ref{sec:ISO:PositionBias}.

%
\begin{definition}[Cascade Search]
\label{def:Lazy}
    Under this search procedure, the screener $\mathbf{s}$ searches the initial screening order $\theta$ until it reaches $k$ candidates that satisfy the screening threshold $\psi$ based on the candidate scores $Y$ to derive \textit{select}-$k$. It ranges from a partial to a full search of the candidate pool $\mathcal{C}$, depending on how the suitable candidates are distributed in $\theta$. We summarize this search procedure in Algorithm~\ref{alg:Lazy}.
\end{definition}
%

%
\begin{definition}[Examination Search]
\label{def:Exhaustive}
    Under this search procedure, the screener $\mathbf{s}$ searches the initial screening order $\theta$, compute the candidate scores, sorts candidates based on the scores, and  then selects the first $k$ candidates to derive \textit{select}-$k$. It implies always a full search of the candidate pool $\mathcal{C}$. We summarize this search procedure in Algorithm~\ref{alg:Exhaustive}.
\end{definition}
%

The names of the search procedures are based on the clicking models that study position bias \cite{CraswellZTR08_ExperimentsClickPositionBias}. 
The cascade model explains the behavior of a user that stops or clicks on the first recommendation it finds useful, while the examination model explains the behavior of a user that examines multiple useful recommendations before stopping or clicking on the one it finds more useful. 
Definitions \ref{def:Lazy} and \ref{def:Exhaustive} extend these models into the screening setting where the user (i.e., screener) clicks on (i.e. evaluates) multiple recommendations (i.e. candidates). These clicking models, prior to the rise of fairness, were among the first to consider the implications of \textit{position bias} for the user. In the initial screening problem, position within $\theta$ is the source of bias. 
We explore this in detail in Section~\ref{sec:ISO:PositionBias}.

For both algorithms, we assume to have a sufficient number $m$ of eligible candidates within $\mathcal{C}$ under $\psi$. Formally, it occurs that $m = |\{ c \in \mathcal{C}\ |\ Y_c \geq \psi\}| \geq k$. In practice, however, it is possible for the screener to adjust its expectations by relaxing either $k$ or $\psi$ or both.

We also include in both algorithms the notion of fatigue, which accumulates over time into $\Omega$. Note that $\Omega$ is initiated as 0, or $\Omega(t_0)=0$, and increases by $\omega$ for each $c \in \theta$ candidate that is evaluated. If the screener evaluates $n' \leq n$ candidates, then $\Omega = n' \cdot \omega$. Here, $\Omega$ allows us to capture how tired the screener is after selecting the $k$ candidates. 

For illustrative purposes, fatigue appears as an implicit parameter: we can view $\Omega$ as a counter of something undesirable to the screener. In general, we could summarize the role of fatigue based on \eqref{eq:LowerMaxU} as $\underline{U}^* - \Omega(\underline{\tau})$, meaning the screener considers its fatigue after finding \textit{select}-$k$. In Section~\ref{sec:ISO:FatiguedScreener} we present one explicit form for the fatigue to enter into the screener's behaviour. Here, we use this general form to illustrate the overall role of fatigue as an undesirable thing to accumulate for the screener.

%
\begin{remark}[Baseline Model]
    \label{remark:Baseline}
    For illustrative purposes, we consider the scenario where the screener cannot get tired, $\omega = 0 \; \forall t$ in both Algorithms \ref{alg:Lazy} and \ref{alg:Exhaustive}. We refer to this scenario as the baseline model. Such screener still has the option to choose between a cascade or an examination search.
\end{remark}
%

%
\begin{algorithm}
\caption{CascadeSearch}\label{alg:Lazy}
\begin{algorithmic}[1]
%\Procedure{MyProcedure}{$x,y$}
\Require $\theta$, $k$, $\psi$, $\omega$ and $f$
\State $\text{select-}k \gets \text{list()}$
\State $\Omega \gets 0$
%\State $Y \gets \text{list()}$
%\While{$|\text{select-}k| < k$}
    \For{$c$ in $\theta$}
        \State $\mathbf{X}_c \gets \mathcal{C}[c]$
        \State $Y_c \gets f(\mathbf{X}_c)$
        \State $\Omega \; +\!= \; \omega$
        %\State $Y$\texttt{.append($(Y_c, c)$)}
        \If{$Y_c \geq \psi$}
            \State $\text{select-}k$\texttt{.append($c$)}
        \EndIf
        \If{$|\text{select-}k|=k$}
        \State break
    \EndIf
    \EndFor
%\EndWhile
\end{algorithmic}
\end{algorithm}
%

%
\begin{algorithm}
\caption{ExaminationSearch}\label{alg:Exhaustive}
\begin{algorithmic}[1]
%\Procedure{MyProcedure}{$x,y$}
\Require $\theta$, $k$, $\psi$, $\omega$, and $f$
%\State $\text{select-}k \gets \text{list()}$
\State $\text{select-}k \gets \text{list()}$
\State $\Omega \gets 0$
\State $\tau \gets \text{list()}$
\For{$c$ in $\theta$}
    \State $\mathbf{X}_c \gets \mathcal{C}[c]$
    \State $Y_c \gets f(\mathbf{X}_c)$ 
    \State $\Omega \; +\!= \; \omega$
    \State $\tau$\texttt{.append(($Y_c, c$))}
\EndFor
\State $s \gets $ sort $\tau$ w.r.t. second element 
\State $\text{select-}k \gets [ c$ for $Y_c, c$ in $s[0:k] ]$ 
%\State $Y$\texttt{.sort(key=lambda tuple: tuple[0])} 
% \Comment{Sort in decreasing order using the ranking scores}
%\State $\tau \gets$ \texttt{[i for i in $\tau$ if i $\geq \psi$]}
%\State $\tau \gets \tau[:k]$
%\State $\text{select-}k \gets$ \texttt{list(zip($^{*}\tau$))[1]} 
% \Comment{Extract the candidates from the sorted list of tuples}
\end{algorithmic}
\end{algorithm}
%

%
\begin{proposition}[The cascade search is weekly preferred over the examination search]
\label{proposition:CascadeVsExamination}
    Under sufficient $m \geq k$ eligible candidates in $\mathcal{C}$, with $|\mathcal{C}|=n > m$, 
    the human-like screener weakly prefers Algorithm~\ref{alg:Lazy} to Algorithm~\ref{alg:Exhaustive}.
\end{proposition}
%

We prove Proposition~\ref{proposition:CascadeVsExamination} in Appendix~\ref{App:Proofs}. We do so using the fatigue argument. Essentially, Algorithm~\ref{alg:Exhaustive} will always impose an accumulated fatigue of $\Omega=n \cdot \omega$ while Algorithm~\ref{alg:Lazy} will only require that much effort when the $k^{th}$ candidate is at the bottom of $\theta$. Otherwise, under Algorithm~\ref{alg:Lazy}, the screener will reach its goal of selecting $k$ suitable candidates with less fatigue.

\subsection{Fatigued Scores}
\label{sec:ISO:FatiguedScreener}

Now we consider a more explicit form in which fatigue affects the screener. Other functional forms are possible. We consider the specific scenario where the screener's fatigue directly affects its evaluation of each candidate, indirectly affecting its final utility. This formulation allows us to study how the screener's fatigue translates into potential inconsistent decision-making by the screener. Formally:
%
\begin{equation}
\label{eq:FatiguedScores}
    Y_c = f(X_c, \Omega(c))
\end{equation}
%
where $\Omega(c) = \tau^{-1}(c) \cdot \omega$ represents the accumulated fatigue of the screener after having evaluated up to the $\tau^{-1}(c)$-th candidate in $\theta$. It is natural to assume that $f(X_c) \geq f(X_c, \Omega(c))$, namely scores do not increase under fatigue. Also, for candidates $c_1, c_2$ with $\tau^{-1}(c_1) < \tau^{-1}(c_2)$ and $X_{c_1}=X_{c_2}$ we assume that $Y_{c_1} = f(X_{c_1}, \Omega(c_1)) \geq f(X_{c_2}, \Omega(c_2)) = Y_{c_2}$.

Proposition~\ref{proposition:CascadeVsExamination} still holds under the fatigued scores formulation \eqref{eq:FatiguedScores}. 
The fatigued scores allows us to be more precise on how fatigue overall affects the screening problem. Overall, all these formulations presented so far are attempts to characterize the fact that most screeners have no incentive(s) to explore the entire candidate pool for a job. 

\subsection{Position Bias}
\label{sec:ISO:PositionBias}

Position in the initial order $\theta$ matters. The screener, implicitly, sets a premium for the earlier positions in $\theta$ due to the fatigue term $\omega$ and lower-bound utility constraint $\underline{U}^k$. There is a \textit{position bias} in $\theta$. This bias is further intensified by the screener's weak preference for the Cascade Search over the Examination Search (Proposition~\ref{proposition:CascadeVsExamination}). In this section, we explore the optimality and fairness implications of the position bias in $\theta$. We focus on the Cascade Search (Algorithm~\ref{alg:Lazy}), though these results extend to the Examination Search (Algorithm~\ref{alg:Exhaustive}) too.

A clear consequence of this position bias is that the best suited candidate(s) might not be selected by the screener. Suppose we have $m$ suitable candidates in $\mathcal{C}$ where $|m| = k + 1$. Suppose further that the best suited candidate among these $m$ candidates appears at the end of the initial order $\theta$. Without even considering the screener's fatigue, under Algorithm~\ref{alg:Lazy}, such candidate will not be selected as the screener will stop once $k$ is met. The marginal gain of searching the initial order further does not compensate the screener when $\underline{U}^k$ is enough. Including fatigue into this setting makes searching further more costly. 

The position bias in $\theta$ also has fairness implications. Recall the fair representation constraint $\phi \in [0, 1]$ for the protected attribute $A$ that denotes membership ($A=a$) to the protected group. Defining $\phi=0.3$, for instance, would mean that 30\% of \textit{select}-$k$ should belong to $A=a$. While order within \textit{select}-$k$ is not important, the order of appearance in $\theta$ is important due to the position bias. Suppose $A$ contains two categories where $A=a'$ denotes no-membership to the protected group, then $n_{a} + n_{a'}=n$ in $\mathbf{C}$ and, respectively, in $\theta$. The top position of $\theta$ represents the best possible position for any candidate in $\theta$ given how the position bias increases over time for the screener. Therefore, the probability that the screener starts by evaluating a protected individual versus a non protected individual in $\theta$ is $n_{a}/n$ versus $n_{a'}/n$. 

%
\begin{definition}[Standard Fair Initial Order]
\label{def:StandardFairIO}
    We say the initial order $\theta$ is standard fair if it is independent from the protected attribute $A$. In other words, the choice of $\theta$ by the screener carries no information about membership to the protected group to ($A=a$) for all candidates in the candidate pool $\mathcal{C}$. 
\end{definition}
%

We assume Definition~\ref{def:StandardFairIO}. In practice, it means the screener does not use the choice of initial order $\theta$ to favor one group over the other, which is a realistic assumption. There are two consequences from this assumption. One, we cannot talk about any bias from $\theta$ beyond the inherent position bias already discussed. Two, we cannot talk about an unfair screener but instead about an unfair process. 

Regarding the fairness implications, in the initial screening order problem we are interested on how the burden of the position bias inherent to the initial screening order falls upon the groups in $A$. As the constraint $\phi$ translates into a quota for protected individuals in \textit{select}-$k$, let $k_a = \phi \cdot k$ represent the protected group quota and $k_{a'} = k - k_a$ the number of spaces available in \textit{select}-$k$ open to any candidate regardless of $A$. 

We rewrite Algorithm~\ref{alg:Lazy} to include the fairness constraint giving way to the Fair Cascade Search, or Algorithm~\ref{alg:FairLazy}. Besides including the $A$-specific quotas $k_a$ and $k_{a'}$, we incorporate the fatigued scores (Section~\ref{sec:ISO:FatiguedScreener}) as well as $A$-specific thresholds $\psi_{a}$ and $\psi_{a'}$. For now, let $\psi_{a} = \psi_{a'}$, meaning all candidates must meet the same screening threshold. Here, we let the fatigue enter as a linear term that lowers the score of the candidate. It, for instance, represents the inconsistency of the screener as it will fail to evaluate the same two identical candidates along $\theta$. As the fatigue accumulates, the more inconsistent the screener becomes. 

%
\begin{algorithm}
\caption{FairCascadeSearch}\label{alg:FairLazy}
\begin{algorithmic}[1]
%\Procedure{MyProcedure}{$x,y$}
\Require $\theta$, $k$, $\phi$, $\psi$, $\omega$, and $f$
\State $k_a \gets \phi \cdot k$
\State $k_{a'} \gets k - k_a$
\State $\text{count}_a \gets 0$; $\text{count}_{a'} \gets 0$
\State $\text{select-}k \gets \text{list()}$
\State $\Omega \gets 0$
%\State $Y \gets \text{list()}$
%\While{$|\text{select-}k| < k$}
    \For{$c$ in $\theta$}
        \State $\mathbf{X}_c, A_c \gets \mathcal{C}[c]$
        \State $Y_c \gets f(\mathbf{X}_c) - \Omega$
        \State $\Omega \; += \; \omega$
        \If{$A_c == a$}
            \If{$Y_c \geq \psi_a$ and $ \text{count}_{a} \leq k_{a}$}
                \State $\text{select-}k$\texttt{.append($c$)}
                \State $ \text{count}_{a}$ += 1
            \EndIf
        \Else
            \If{$Y_c \geq \psi_{a'}$ and $ \text{count}_{a'} \leq k_{a'}$}
                \State $\text{select-}k$\texttt{.append($c$)}
                \State $ \text{count}_{a'}$ += 1
            \EndIf
        \EndIf
        
        \If{$|\text{select-}k|=k$}
            \State break
        \EndIf
    \EndFor
%\EndWhile
\end{algorithmic}
\end{algorithm}
%

Under a consistent screener (i.e., one that cannot get tired), or the baseline model from Remark~\ref{remark:Baseline}, Algorithm~\ref{alg:FairLazy} meets the fairness goals summarized by the representational constraint $\phi$. In fact, such screener meets both group-level fairness (as prescribed by the composition of the \textit{select}-$k$) as well as individual-level fairness (as prescribed by the how the screener evaluates each candidate)\footnote{Here, in particular, the individual fairness definition often used is still that one by \citet{DBLP:conf/innovations/DworkHPRZ12}, where the same candidate should be treated similarly regardless of its position in $\theta$. \citet{DBLP:conf/chi/EchterhoffYM22}, e.g., phrase the anchoring bias in terms of this kind of individual fairness.}. This last point follows from Def.~\ref{def:StandardFairIO} and is also based on the assumption that there is no implicit bias in $\mathbf{X}$ nor in $f$ affecting the score $Y$ based on $A$. This is not true, however, under the (human-like) screener we consider here.

%
\begin{proposition}[Unfairness Implications of an Unbalanced Data]
\label{proposition:UnfairUnbalancedData}
    Let $\mathcal{C}$ be a candidate pool, and $\theta$  a standard fair initial screening order, such that $\mathcal{C}$ is unbalanced w.r.t. groups in $A$, i.e., $n_{a'} > n_{a}$ (more non-protected than protected individuals to be evaluated by the screener). Then the Cascade Search (Algorithm~\ref{alg:Lazy}) 
    introduces an unequal, cumulative burden of fatigue on the first $h$ examined candidates from the protected group compared to the first $h$ of the non-protected one, where $h \in [1, \min\{n_a, n_{a'}\}]$.  
\end{proposition}
%

We prove Proposition~\ref{proposition:UnfairUnbalancedData} in Appendix~\ref{App:Proofs}. The logic behind it is quite intuitive considering Algorithm~\ref{alg:FairLazy}. Under an unbalanced initial order $\theta$, the screener will come across more often with candidates from the non-protected and over-represented than the protected and under-represented group. If $\theta$ is non-informative of the protected attribute $A$ (Def.~\ref{def:StandardFairIO}), then we expect the non-protected and protected candidates to appear in $\theta$ based on their respective proportions $n_{a'}/n$ and $n_{a}/n$ in $\mathcal{C}$. As the screener accumulates fatigue in the form of $\Omega$ by going over $\theta$, it means that the screener be more tired when evaluating the first protected candidate than when evaluating the first non-protected candidate, and so on. 

An unbalanced $\mathcal{C}$ means that the protected, under-represented candidates have higher chances to face a more tired screener due to the accumulated fatigue from having evaluated mostly non-protected, over-represented candidates. This is the case for Algorithm~\ref{alg:FairLazy} despite the quota $k_a$. The burden of the screener's fatigue is only equally distributed among candidates in $A$ when $n_a = n_{a'}$.

Under an unbalanced candidate pool, the screener's fatigue affects disproportionally the under-represented group, which is in our case the protected group. In principle, this should not affect group-level fairness goals as captured by $\phi$ via the quota $k_a$. It does, however, affect individual fairness across and within the groups in $A$ as the screener becomes increasingly inconsistent over time. This was already the case in Algorithm~\ref{alg:Lazy}, but it can still be an issue for Algorithm~\ref{alg:FairLazy} despite the quotas. It is the (accumulated) fatigue of the screener that hinders fairness as well as optimality goals. Regarding fairness, in particular, the role of $\omega$ in Algorithm~\ref{alg:FairLazy} hinders the screener's capacity to evaluate similar candidates similarly, which violates individual fairness. It is not because the screener, the scoring function, or the provided information itself are unfair; it is the setup of the process. 

%
\begin{definition}[Fair Initial Order]
\label{def:FairIO}
    The initial order $\theta$ is fair for an algorithm $B$, if starting from $\theta$ as an input, $B$ distributes equally the burden of fatigue incurred by the screener over time across the protected and non-protected groups in $\theta$.
\end{definition}
%

With Def.~\ref{def:FairIO}, we shift the focus from considering the composition of the candidate pool $\mathcal{C}$ to how the protected and non-protected individuals are ordered prior to screening in the initial order $\theta$. What can seem as a seemingly uninteresting and fair (under Def.~\ref{def:StandardFairIO}) step, becomes a fairness matter when we factor in the potential inconsistencies. 

We also highlight the role of the $A$-specific screening thresholds in Algorithm~\ref{alg:FairLazy}. Ideally, the screener sets them equal to each other $\psi_{a} = \psi_{a'}$. However, this might not be possible under an unbalanced dataset as the protected and under-represented group might not have enough eligible candidates in $\mathcal{C}$. Moreover, setting a quota alone is not enough for achieving equality of fatigue .

%
\begin{proposition}[Fairness requires dynamically adapting screening thresholds]
\label{proposition:DifferentThresholds}
    Let $\mathcal{C}$ be a candidate pool, and $\theta$  a standard  initial screening order, such that $\mathcal{C}$ is unbalanced w.r.t. groups in $A$, i.e., $n_{a'} > n_{a}$.
    Let $\beta_a$ and $\beta_{a'}$ be the proportion of eligible candidates for the protected group 
    and the
    unprotected one respectively. To achieve equality of fatigue over the two groups in the Fair Cascade Search (Algorithm~\ref{alg:FairLazy}), the screening thresholds $\psi_a$ and $\psi_{a'}$ must be dynamically adapted. 
\end{proposition}
%

We sketch a proof for Proposition~\ref{proposition:DifferentThresholds} in Appendix~\ref{App:Proofs}. Intuitively, we view it as the consequence of the implicit population numbers. If we expect the protected and non-protected candidates to be distributed similarly in terms of aptitude for the job opening (measured by the screening threshold $\psi$), then we should expect similar candidates profiles across $A$ under a balanced candidate pool $\mathcal{C}$. When this does not occur, meaning the protected group is also the under-represented group, then $\mathcal{C}$ and in turn $\theta$ might be unable to provide the same number of eligible candidates across $A$. The screener then faces the choice to relax the the representation goals $\phi$ according to the available $\mathcal{C}$, or dynamically adapting the screening thresholds. In practice, it means the screener as it will come across more suitable non-protected candidates can be more strict with the minimum basic requirements for such candidates and, conversely, it can be less strict with the protected candidates knowing that the suitable candidates are scarce. 

These conclusions lead us to argue that the fairness goals, even under the ideal fair screener, are supply dependent. In other words, in practice, companies like G are from the beginning constraint by the candidate pool they have available for completing a job opening. All parameters considered in Algorithm~\ref{alg:FairLazy} are susceptible to the realities of $\mathcal{C}$. The initial order $\theta$ materializes these concerns through its inherent position bias. 

%
% EOS
%
