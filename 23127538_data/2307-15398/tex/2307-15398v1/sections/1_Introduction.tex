%
\label{sec:Introduction}

Candidate screening is a complex and delicate human-dependent process. Human screeners face the challenge to select the best candidates using limited information under strict time constraints. The screening process, as with other repetitive tasks, is prone to human error and can lead to biased decisions by the screener \cite{Miller2018Bias, Kahneman2016Noise, Kahneman2021Noise}. Unsurprisingly, a booming industry around automating (online) screening processes has emerged in recent years, especially in the field of Artificial Intelligence (see, e.g.,
\cite{DBLP:journals/air/WillKL23}). Also unsurprisingly, probably due to how complex and delicate these processes are in practice, the algorithmic solutions to candidate screening have yet to deliver on their promises of providing a reliable, auditable, and fair pipeline (e.g., \cite{DBLP:conf/fat/WilsonG0MBSTP21,Wehner20,Sonderling22,Raghavan2020AlgortihmicHiring,DBLP:journals/datamine/RheaMDSSSKS22,jintelligence9030046,DBLP:journals/patterns/SloaneMC22}). The future of candidate screening under the normalization of automated decision-making systems, or ADM, remains an open question.

In this paper we explore a new problem within candidate screening: the initial screening order problem. Our work is based on a collaboration with a large European company, which we refer to as company G (the real name will be kept anonymous), where we worked closely with G's Advanced Analytics and Human Resource teams to understand its hiring pipeline. What started as a project to explore potential areas of automation within G's hiring pipeline, ended with formalizing certain parts of G's hiring pipeline that in prior work, to the best of our knowledge, had been examined very abstractly or simply taken for granted. We found a dissonance between the screening processes the ADM literature used as inspiration for its problem formulations, and the screening processes stakeholders like G actually faced and wished to improve with automation. With the exceptions of \citet{SukumarMH18_PeacanPie} and \citet{DBLP:conf/chi/EchterhoffYM22} (both of which explore the case of college admissions), this paper offers important insights on the complexity of candidate screening (in the case of hiring) and provides a detailed formulation that is helpful for future work in, e.g., game theory, algorithmic fairness, and explainable AI research.
%
We recount our experience at company G in Section~\ref{sec:Generali}.

The overall candidate screening problem naturally translates into a ranking problem. We wish to find $k$ candidates from a pool of candidates and, thus, we evaluate (or screen) each candidate; score each of them based on their profile; order them based on the scores; and select the first $k$ candidates. This problem, in principle, is well understood within the (fair) ranking literature \cite{DBLP:journals/vldb/PitouraSK22, Zehlike2023_FairRanking_P1, Zehlike2023_FairRanking_P2}. There are, of course, open questions on, e.g., how to derive a ranking algorithm under implicit bias in the candidates' profiles \cite{Kleinberg2018Selection}, but the overall algorithmic procedure for obtaining the ranking algorithm is clear. What we came across at G was more complex. For instance, each HR officer (the screener) had its own search procedures for going over the candidate pool as well as its own preference in ordering the candidate pool for screening, i.e. \textit{the initial screening order}. Variability among the screeners is standard in such a setting (e.g., \cite{SukumarMH18_PeacanPie}) and in other similar settings also (e.g., like how two researchers choose to go over differently the same list of related work papers). Such an account on these complex processes we aim to model was missing from the current literature.

What stood out through our collaboration with G, above other aspects that we cover in Section~\ref{sec:Generali}, was the objective of the HR officers: the goal was not to find the best $k$ candidates, but instead to find the first $k$ suitable candidates in the candidate pool. Under this goal, factoring in a human-like screener, the choice on the initial screening order has considerable effects on the selected set of $k$ candidates. 
We prove, for instance, that under an unbalanced candidate pool (meaning, e.g., we have more male candidates than female candidates), the human-like screener can make biased decisions over the protected, under-represented group. Such nuances, we argue, are not easily captured by the standard setting of the (fair) algorithmic screener. 
%
We setup the initial screening problem in Section~\ref{sec:ProblemFormulation} and analyze it in Section~\ref{sec:ISO} with a focus on fairness. 

Our main contribution is the formalization of the initial screening order problem, which is a crucial part within the candidate screening process. Under this problem setup, we explore a few  fairness implications. Further, we describe G's hiring process, which might be representative of other similar settings being tackled by ADM researchers.
%
We position our work within the related work in Section~\ref{sec:RelatedWork}. We conclude the paper in Section~\ref{sec:Discussion}.

%
% EOS
%
