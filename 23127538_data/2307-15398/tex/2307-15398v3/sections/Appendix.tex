%
\label{Appendix}

\section{Collaborating with G}
\label{Appendix.MoreOnG}

\paragraph{Overall experience.}
The collaboration lasted for four months.
Due to the COVID-19 pandemic, it was a hybrid collaboration.
During this time, we mostly interviewed the HR officers to understand their tasks, constraints, and methodologies, often shadowing them during screening sessions.
We were also granted access to Taleo by Oracle, the platform used by HR for managing the hiring pipeline.
This allowed us to experience for ourselves the patterns we observed among the HR officers. These patterns resulted in the stylised facts of Section~\ref{sec:Generali}. 

We interacted, in particular, with five HR officers specialized in screening applications for technical roles within G, such as the roles of data scientist and front-end developer.
These HR officers had to process considerable amounts of information within a time constraint. Based on what we observed, most candidate pools (except for very senior profiles like, e.g., director of data science) consisted of hundred of applications. 
These HR officers were involved in screening multiple candidate pools with similar deadlines within the same week.
It became apparent to us, specially for candidate screening, how time-consuming and human-dependent was the hiring process. 

We discussed our observations, often on a bi-weekly basis, to members of both the HR and AA teams.
We emphasize that we simply collaborated with these teams as equals, sharing the goal of understanding G's hiring process and whether it was suitable or not for (fair) automation. 
We specifically use the wording “stylized facts” in Section~\ref{sec:Generali} to emphasize that we draw inspiration from the collaboration with G in formulating the ISO problem rather than ``hard facts'' about G derived from an observational study. In fact, the first draft of this paper occurred about one year after our collaboration with G had concluded.

\paragraph{Deliverables.}
We concluded the collaboration with a report to AA that formalized G's candidate screening process as a ranking problem, evaluated the potential fairness implications, and assessed the risk and benefits of automation.
The report was discussed with a wider audience within G in a series of presentations hosted by the AA and HR teams. 
The report focused mainly on candidate screening.
It is worth mentioning also that throughout the collaboration, we followed G's strict ethical guidelines at all times.
Further, at no point did we receive monetary compensation from G. Our research has been funded by public European institutions. The views reflected in this paper are entirely our own.
No sensitive data (or data at all) from G was used for this work.
This paper is not a deliverable specific to G.
% , though clearly it is influenced by the report.

\paragraph{The hiring pipeline.}
Hiring at G consists mainly of three phases. With respect to the stylized facts, these are concerned with the candidate screening phase or phase two.
These phases are the following:
%
\begin{itemize}
    \item In \textit{phase one}, the HR builds a candidate pool for the job opening. Candidates submit their CVs, complete a multiple-choice questioner, and write a motivation letter. Sensitive information, such as gender, ethnicity, and age, is also provided or it can be inferred. The candidate pool is stored in a database platform.
    %
    \item In \textit{phase two}, the HR officer reduces the candidate pool into a smaller pool of suitable candidates. The HR officer determines candidate suitability based on each candidate's profile using a set of minimum basic requirements.
    %
    \item In \textit{phase three}, the chosen candidates are interviewed by HR and the team offering the job. 
    It is common for the hiring team to also prepare a use case for the candidates.
    The best candidates receive an offer. If no candidates are hired, HR resorts to the runner-up candidates from phase two and repeat phase three.
\end{itemize}
%
We note that the above represent G's hiring pipeline during the collaboration. We do not know if this hiring pipeline is still the case today, though this is not important for the purpose of this paper.

\section{Supplementary Material}
\label{Appendix.SupplementaryMaterial}

\subsection{Section~\ref{sec:good-k}: Additional Discussion on the Utility Model}
% \subsection{A Naive Utility Function for Section~\ref{sec:good-k}}
\label{Appendix.NaiveUtilityGoodk}

First, we present Example~\ref{ex:diff_fractions_prot} below. It shows that for the utility model \eqref{eq:AlternativeUtility} for the good-$k$ problem, in the general case, i.e.,~$f(S^k) \geq q$, there can be two solutions, but with different fractions of the protected group.

%
\begin{example}
\label{ex:diff_fractions_prot}
    % For example, c
    Consider $n=3, k=2, q=0.5$. Assume three eligible candidates and $\theta(1) = c_1, \theta(2) = c_2, \theta(3) = c_3$ with $W_1 = 0$ and $W_2 = W_3 = 1$. Both $S' = \{c_1, c_2\}$ and $S'' = \{c_2, c_3\}$ are solutions of (\ref{eq:fair_objective_U_psi}) with $U^k_{\psi} \big(S', \theta\big) = U^k_{\psi} \big(S'', \theta\big) = 2$. However, $f(S') = 0.5$ and $f(S'') = 1$. Intuitively, $S'$ is obtained by strictly iterating over $\theta$.
    % , which is the approach we take in Section~\ref{sec:ProblemFormulation.Algorithms} \ja{under the algorithmic solution of this problem}.
\end{example}
%

\noindent
We now motivate the alternative utility model \eqref{eq:AlternativeUtility} used in the good-$k$ problem.
As a possible utility function in the good-$k$ setting consider the following utility model:
%
\begin{equation}
\label{eq:AlternativeUtility2}
    \hat{U}^k_{\psi}\big( S^k, \theta \big) = \left\{
    \begin{array}{ll}
        n - \max_{c \in S^k} \theta^{-1}(c) & \text{if} \  \forall c \in S^k \  s(\mathbf{X}_c) \geq \psi   \\
        0 & \text{otherwise.}
    \end{array} \right.
\end{equation}
%
where we use $\hat{U}_\psi^k$ (i.e., the $U$ hat) to differentiate from the utility model $U_\psi^k$ considered in \eqref{eq:AlternativeUtility}.

Intuitively, in the above utility definition the screener wants to find as quickly as possible a set of $k$ eligible candidates.
Therefore, if $S^k$ contains only eligible candidates, the utility of $h$ selecting $S^k$ under $\theta$ is expressed by the number of candidates past the last one who was screened, i.e.,~the ``saved effort" of the screener $h$.
Despite the simplicity of \eqref{eq:AlternativeUtility2}, the above utility model \eqref{eq:AlternativeUtility2} is not suitable to properly account for the intended good-$k$ problem.
To observe this last point, consider Example~\ref{ex:AltU2}.

%
\begin{example}
\label{ex:AltU2}    
    Let $n=3, k=2, q=0.5$. Assume three eligible candidates and $\theta(1) = c_1, \theta(2) = c_2, \theta(3) = c_3$ with $W_1 = W_2 = 0$ and $W_3 = 1$. It turns out that both $S' = \{c_1, c_3\}$ and $S'' = \{c_2, c_3\}$ maximize the utility and satisfy the fairness constraint $q$.
\end{example}
%

Following up on Example~\ref{ex:AltU2}, 
% However, 
why should have been $c_2$ considered, and then returned in $S''$, if $c_1$ already meets the minimum basic requirement? 
A reason for doing that is a variant of our good-$k$ problem in which the screener $h$ keeps evaluating non-protected candidates in $\mathcal{C}$, even if their quota is reached but the one of protected candidates is not yet reached, for the purpose of keeping the best ones found so far. 
We do not consider such a variant in this paper.
For this reason, we introduce the penalty function in \eqref{eq:AlternativeUtility} presented in Section~\ref{sec:good-k}.

% \subsection{Two Search Procedures: Detailed Discussion}
% \label{Appendix.DiscussionAlgorithms}

% Here, we discuss in detail the two search procedures proposed in Section~\ref{sec:ProblemFormulation.Algorithms} for implementing the best-$k$ (Section~\ref{sec:best-k}) and good-$k$ (Section~\ref{sec:good-k}) fair set selection problem formulations.

% The \textbf{\textit{ExaminationSearch}} procedure, shown in Algorithm~\ref{algo:Examination}, solves the best-$k$ setting, returning $S^k_\besttext$ for given $n$ (candidates), ISO $\theta$, and parameters $k$ (subset size) and $q$ (minimum fraction of selected candidates from the protected group). 
% First, line 2 calculates the minimum number $q^*$ of candidates from the protected group to be selected, and the maximum number of candidates $r^*$ not in that quota. 
% Then, candidates are considered by descending scores, using the \texttt{argsortdesc} procedure (lines 2, 3). 
% The loop in lines 5-13 iterates until $k$ candidates are found. The loop adds candidates to the sets $Q$ and $R$: $Q$ are candidates in the quota of the protected group; $R$ are candidates not in that quota (can be non-protected or protected). An non-protected candidate can be only added to the $R$ set, thus line 7 checks if there is still room in $R$ to do this. A protected candidate is added to the quota set $Q$ if there is room (lines 10-11), or to the other set $R$ otherwise (lines 12-13). 
% Finally, the procedure returns the candidates in the quota set $Q$ or in the other set $R$. 
% The result of the \textit{ExaminationSearch} procedure clearly maximize (\ref{eq:fair_objective_all_screener}), as candidates are added in decreasing score, while keeping the fairness constraint through the quota management.

% The \textbf{\textit{CascadeSearch}} procedure, shown in Algorithm~\ref{algo:Cascade}, solves the good-$k$ setting, returning $S^k_\goodtext$ for given $n$, ISO $\theta$, and parameters $k$, $q$ and $\psi$ (minimum basic requirement). 
% The difference with the \textit{ExaminationSearch} procedure consists in strictly following the initial order $\theta$ (line 4), and in checking the minimum basic requirement (line 8) before adding a candidate to the quota set $Q$ or to the other set $R$.
% The result of the \textit{CascadeSearch} procedure maximizes (\ref{eq:fair_objective_U_psi}), as no penalty is accumulated in the loop. 
% In fact, an non-protected candidate ($W_c=0$) is not added only because  there is no room in $R$ -- and $R$ never gets smaller to allow for more room later on. A protected candidate ($W_c=1$) is not added only if not meeting the minimum basic requirement (line 8), hence it cannot be counted for the penalty. Formally, $U^k_{\psi}\big(S^k_\goodtext, \theta\big) = k$ for the solution $S^k_\goodtext$ returned by \textit{CascadeSearch}.

\subsection{Search Procedures under a Human-Like Screener}
\label{Appendix.HumanAlgorithms}

We update the \textit{ExaminationSearch} and \textit{CascadeSearch} and their corresponding Algorithm \ref{algo:Examination} and Algorithm \ref{algo:Cascade} from Section~\ref{sec:ProblemFormulation.Algorithms} under the human-like screener $h_h$ from Section~\ref{sec:HumanScreener}. 
% In particular, 
We incorporate the \textit{fatigued scores} formulation from Section~\ref{sec:HumanScreener.BiasedScores} into both algorithms, resulting in a human-like \textit{HuamnExaminationSearch} (Algorithm~\ref{algo:HumanExamination}) and a human-like \textit{HumanCascadeSearch} (Algorithm~\ref{algo:HumanCascade}).
In comparison to the algorithmic screener $h_a$, the main difference here is that both algorithms compute the fatigued score for candidate $c \in \mathcal{C}$:
%
\begin{equation}
    Y_c = s(\mathbf{X}_c) + \epsilon
\end{equation}
%
where $\epsilon$ is a random variable depending on the accumulated fatigue $\Phi$ of $h_h$.
In both algorithms \ref{algo:HumanExamination} and \ref{algo:HumanCascade}, by requiring the fatigue component $\Phi$, we also require a specific modeling choice for $\epsilon$ which is a probabilistic function of the accumulated fatigue $\Phi$. As discussed in Section~\ref{sec:HumanScreener.BiasedScores}, $\epsilon$ can be modeled as either $\epsilon_1$ or $\epsilon_2$.

We stress once again that other formulations for $\epsilon$ are possible.
These formulations are compatible with Algorithms~\ref{algo:HumanExamination} and \ref{algo:HumanCascade} as long as $\epsilon$ is treated as a random variable that is drawn each time $h_h$ evaluates candidate $c$.
These formulations can be implemented as with $\epsilon_1$ and $\epsilon_2$, meaning by providing the corresponding probability distribution for the intended accumulated fatigue $\Phi$.

%
% Figure environment removed
%

\section{Additional Experiments}
\label{Appendix.MoreExperiments}

\subsection{Experiments without Fatigue}
\label{Appendix:Experiments.Metrics.outFatigue}

In this section, we present the additional figures and corresponding discussions relating to the experimental analysis of the algorithmic screener $h_a$ from Section~\ref{sec:Experiments.Metrics.outFatigue}.

First, we consider the impact of the correlation $\rho$ between $\theta$ and the scores. 
Recall that $\rho = -1$ means that the candidates are ordered by descending scores. 
Under such a condition, the good-$k$ and best-$k$ procedures return the same solution. 
This result is apparent in Figure~\ref{fig:2} (center, right) where we report the ratio to baseline for the symmetric (left) and the increasing (right) score distributions. 
The plots show that even a moderate correlation of $\rho = -0.5$ leads the good-$k$ solution to approximate the best-$k$ one quite well. 
For the increasing distribution (right), the ratio to baseline is around 95\%. 
In summary, initial orders that negatively correlate to the score greatly reduce the difference in utility between the good-$k$ and best-$k$ solutions.

Second, we consider the impact of the number $n$ candidates in $\candidatesset$ and the number of $k$ candidates to be selected. 
We focus only on the symmetric distribution (in red) and the RtB metric, but the results are similar for the other two distributions (in blue and green) and the JdS metric. 
Figure~\ref{fig:2} (left) compares the case $n=120, k=6$ considered earlier to two other scenarios in terms of $n$ and $k$. 
The first scenario increases $k=20$, but leaves the ratio of selected $k/n = 0.05$ the same by also increasing $n=400$. 
The second scenario, instead, leaves $k=6$ the same, but it increases $k/n = 0.2$ by decreasing $n=30$. 
The plot shows that changes in the ratio $k/n$ affect the metric, in particular a larger ratio ($n=30$, $k=6$) leads good-$k$ to better approximate best-$k$ for the same $\psi$. 
In other words, the more candidates we can select from the pool, the better the chance to include top ones. 
In summary, under $\theta \ci s$, the ratio $k/n$ is positively correlated with the ability of best-$k$ to approximate good-$k$.

Finally, let us now consider the quota parameter $q$, thus far set to $q=0.5$ over a population with a fraction of protected candidates set to $\mathit{pr}=0.2$. 
Since we assumed that $W$ is independent from both scores and the ISO, the fraction of protected group in the solutions of best-$k$ and good-$k$ is, on average, $\mathit{min}\{q, \mathit{pr}\}$. 
Figure~\ref{fig:3} (left) shows this result in the solution for good-$k$. 
A less trivial question is whether $q$ is also not affecting the evaluation metrics: e.g., whether the quota $q$ changes the ratio to baseline? 
Figure~\ref{fig:3} (center, right) show that this is not the case in two experimental settings. 
Again, this result is theoretically implied by the independence of $W$ with scores and initial order. 
In summary, under $\theta \ci s$, the $q$ in the best-$k$ and good-$k$ problem does not affect the relative strengths of their solutions.

%
% Figure environment removed
%\vspace{-3ex}
%
%
% Figure environment removed
%\vspace{-3ex}
%

%
% EOS
%






%
% \begin{proof}[Proof of Proposition~\ref{proposition:CascadeVsExamination}]
% We focus on the expected accumulated fatigue $E[\Omega(t_f)]$ incurred by the screener at the time $f$ of the end of the search. For the Examination Search (Algorithm~\ref{alg:Exhaustive}), $t_f = n$ in all runs, and then $E[\Omega(t_f)] = n \cdot \omega$. For the Cascade Search (Algorithm~\ref{alg:Lazy}), $t_f$ is the time at which the $k^{th}$ eligible candidate is found. Clearly $t_f \in [k, n]$, with the case $t_f =n$ occurring when $m=k$ with probability $k/(n!)$. Thus, $k \cdot \omega \leq E[\Omega(t_f)] < n \cdot \omega$.
% %
% %To show an equal preference by the screener between a Cascade Search (Algorithm~\ref{alg:Lazy}) and an Examination Search (Algorithm~\ref{alg:Exhaustive}), consider the case where the number of eligible candidates in the candidate pool $\mathcal{C}$ equals the number of candidates the screener wishes to select: $m=k$. Further, assume that $|\mathcal{C}| = n > k$ and that all $m$ candidates fall in the bottom $m$-positions of the initial order $\theta$. In this scenario the screener will have to cover the entirety of $\theta$ under either search model to meet the goal of selecting $k$ candidates. Therefore, the screener finds \textit{select}-$k$ with the same accumulated fatigue $\Omega= n \cdot \omega$ under either search model. Here, the screener is indifferent between the two search models.
% %
% %To show a strict preference by the screener between a Cascade Search (Algorithm~\ref{alg:Lazy}) and an Examination Search (Algorithm~\ref{alg:Exhaustive}), consider the case where the same $m$ eligible candidates now appear at top $m$-positions of $\theta$. Under a Cascade Search, the screener finds \textit{select}-$k$ with an accumulated fatigue of $\Omega' = m \cdot \omega$ while, under an Examination search, the screener still needs to cover the remaining $n-m$ candidates and finds \textit{select}-$k$ with an accumulated fatigue of $\Omega'' = n \cdot \omega$. It follows that $\Omega' < \Omega''$, which makes the screener prefer the Cascade over the Examination search model. Therefore, the screener weakly prefers a Cascade Search (Algorithm~\ref{alg:Lazy}) from an Examination Search (Algorithm~\ref{alg:Exhaustive}).
% %
% % Note that under the trivial case where $n=m=k$, the screener is indifferent but then there is no selection problem to consider in this case.
% \end{proof}
% %

% %
% \begin{proof}[Proof of Proposition~\ref{proposition:UnfairUnbalancedData}]
% Let us assume for simplicity that $r = n_{a'}/n_a > 1$ is a natural number. Consider a block of $r+1$ candidates, with one protected and $r$ non-protected. The fatique for examining the protected candidate is $(r+2)/2 \cdot \omega$ on average, based on the position of such candidate in the block. The fatique for examining the first non-protected candidate is $2 \cdot \omega$ with probability $1/(r+1)$ (when the protected candidate occurs in the first position) and $\omega$ with probability $r/(r+1)$ (when the protected candidate occurs in a later position), for an average fatigue of $(r+2)/(r+1) \cdot \omega$. This is lower than the one for the protected candidate, since $r>1$. 

% The fatigue for examining the second protected candidate is at least $(v+2) \cdot \omega$, as such a candidate will be in the next block. If $r \geq 2$, the second non-protected candidate will be in the current block, and the fatigue for examining it will be  $3 \cdot \omega$ with probability $2/(r+1)$ (when the protected candidate occurs in the first or in the second position), and $2 \cdot \omega$ with probability $(r-1)/(r+1)$, for a total of $(5+r)/(r+1) \cdot \omega$. Again, the fatigues for the second non-protected candidate is lower  than the fatigue for the second protected candidate. This reasoning extends to all other order positions of protected and non-protected.

% In summary, the burden of fatigue is unequally distributed among the first $h$ non-protected and the first $h$ protected candidates, where $h \in [1, \min\{n_a, n_{a'}\}]$. 
% %
% %Let $t_1$ and $t_2$ be the time of the screen come across the first non-protected and a protected candidate respectively. 
% %    Let $A=a$ denote membership to the protected group and $A=a'$ to the non-protected group such that there are $n_a$ and $n_{a'}$ protected and non-protected individuals in the candidate pool $\mathcal{C}$. Assume $\mathcal{C}$ is unbalanced, meaning $n_{a} < n_{a'}$, and, consequently, so is the initial screening order $\theta$. Further, assume a Cascade Search (Algorithm~\ref{alg:Lazy}), fatigued scores (Section~\ref{sec:ISO:FatiguedScreener}), and a standard fair initial initial order (Def.~\ref{def:StandardFairIO}). Under this setting, it follows that the most valuable position to fall in for any candidate $c \in \theta$ is the first position, or $\theta(1)$. Therefore:
%     %
% %    \begin{equation*}
% %        P(\theta(1) \wedge A=a) = \frac{n_a}{n} <  \frac{n_{a'}}{n} = P(\theta(1) \wedge A=a') 
% %    \end{equation*}
%     %
% %    the probability for the screener to examine first a non-protected over a protected individual is higher. For simplicity, assume $\theta$ has an order that reflects the proportions $n_a/n$ and $n_{a'}/n$: e.g., if $n_a/n = 0.3$ and $n_{a'}/n = 0.7$ then every 10 positions should contain 3 protected and 7 non-protected candidates. Therefore:
%         %
% %    \begin{equation*}
% %        P(\theta(i) \wedge A=a) = \frac{n_a}{n} <  \frac{n_{a'}}{n} = P(\theta(i) \wedge A=a') \; \forall i \in \theta
% %    \end{equation*}
%     %
% %    meaning it is more likely for the screener to come across a non-protected (and over-represented) individual than a protected (and under-represented) individual when going through $\theta$.
%     %
% %    The accumulated fatigue $\Omega$ increases over $\theta$. Consider the first candidate to be evaluated by the screener from each group in $A$. As it is more likely for the screener to come across a non-protected candidate over a protected candidate, the screener will be more tired by the time it evaluates the first protected candidate than the first non-protected candidate. Since $\Omega(t_1) < \Omega(t_2)$ and so on, the burden of fatigue is unequally distributed in $\Theta$: it is more likely for the non-protected, over represented candidate to face a screener with $\Omega(t_1)$ than it is for a protected under-represents candidate. This argument extends to the rest of the initial order.
% \end{proof}
% %

% %
% \begin{proof}[Proof of Proposition~\ref{proposition:DifferentThresholds}]
% Fairness is achieved if the number of candidates examined for $A=a$ and $A=a'$ are the same. Such numbers can be obtained by considering examination as drawing from an hypergeometric distribution. $\textit{HyperG}(n_a, \beta_a \cdot n_a, w_{a})$ (resp., $\textit{HyperG}(n_{a'}, \beta_{a'} \cdot m_{a'}, w_{a'})$) models the probability of finding a certain number of eligible candidates in $w_{a}$ (resp., $w_{a'}$) evaluations of protected (resp., unprotected) candidates from a pool of $n_a$ (resp., $n_{a'}$) candidates including $\beta_a \cdot n_a$ (resp., $\beta_{a'} \cdot m_{a'}$) eligible in total. The expectation of the distribution is $w_{a} \cdot \beta_a$ (resp., $w_{a'} \cdot \beta_{a'}$). The expectation is the mean number of eligible candidates found, i.e.:
% \[w_{a} \cdot \beta_a = k_a \hspace{2cm} w_{a'} \cdot \beta_{a'} = k - k_a \]
% Since we want $w_{a} = w_{a'}$, we have the solution:
% \[ w_{a} = w_{a'} = \frac{k}{\beta_a + \beta_{a'}} \]
% As a consequence, we must stop the search for each group after $w_{a} = w_{a'}$ evaluations of candidates, which may require to dynamically adapt the screening thresholds $\psi_a$ and $\psi_{a'}$  to ensure the quotas $k_a = \phi \cdot k$ and $k_{a'} = k - k_a$.


% %    Suppose the inherent quality of candidates $Y^{*}$ in the population is independent from $A$, meaning that we have the same proportion of, say, bad, average, and good candidates across males ($A=a')$ and females ($A=a$) in our population. 
% %    Assume we build $\mathcal{C}$ at random by drawing from both male and female populations, keeping an uneven gender balanced of $n_a < n_{a'}$. It follows that $Y^{*}$ and, consequently, the score $Y$ under an unbiased and consistent screener should be distributed evenly across $A$ in $\mathcal{C}$, though, by construction, the number of good male candidates ($g_{a'}$) will be higher than the number of good female candidates ($g_a$). 
% %    If $g_{a'} \geq k_{a'}=k_a > g_a$, then we either reduce $k_{a'}$ until we reach $g_{a}$ and, in turn, increase $k_{a'}$ by that same amount, or we let $\psi_{a} < \psi_{a'}$ and proceed to complete the $k_{a}$ quota with average and even bad female candidates.
% \end{proof}
% %
