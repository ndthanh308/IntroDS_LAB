{
  "2304-13972": {
    "title": "Convergence of Adam Under Relaxed Assumptions",
    "authors": [
      "Haochuan Li",
      "A. Jadbabaie",
      "A. Rakhlin"
    ],
    "submission_date": "2023-04-27",
    "semantic_scholar_id": "b7dfa8acfa5776e22e7c8f6cc0c05b060515e6d6"
  },
  "2302-08783": {
    "title": "SGD with AdaGrad Stepsizes: Full Adaptivity with High Probability to Unknown Parameters, Unbounded Gradients and Affine Variance",
    "authors": [
      "Amit Attia",
      "Tomer Koren"
    ],
    "submission_date": "2023-02-17",
    "semantic_scholar_id": "ad08e32076814abb15238ca90d69a0140d3bacf0"
  },
  "2211-01851": {
    "title": "Adaptive Stochastic Variance Reduction for Non-convex Finite-Sum Minimization",
    "authors": [
      "Ali Kavis",
      "Stratis Skoulakis",
      "Kimon Antonakopoulos",
      "L. Dadi",
      "V. Cevher"
    ],
    "submission_date": "2022-11-03",
    "semantic_scholar_id": "cdcd14a135c231e9c7d3a8d3fe500fb950d57106"
  },
  "2210-05607": {
    "title": "Divergence Results and Convergence of a Variance Reduced Version of ADAM",
    "authors": [
      "Ruiqi Wang",
      "D. Klabjan"
    ],
    "submission_date": "2022-10-11",
    "semantic_scholar_id": "09f1433d729017ba8ab67076491d5d58c2dd10f1"
  },
  "2205-02273": {
    "title": "An Adaptive Incremental Gradient Method With Support for Non-Euclidean Norms",
    "authors": [
      "Binghui Xie",
      "Chen Jin",
      "Kaiwen Zhou",
      "James Cheng",
      "Wei Meng"
    ],
    "submission_date": "2022-04-28",
    "semantic_scholar_id": "54049b75a53c6dcffe8ebe12c6928ed7a42a52a1"
  },
  "2204-02833": {
    "title": "High Probability Bounds for a Class of Nonconvex Algorithms with AdaGrad Stepsize",
    "authors": [
      "Ali Kavis",
      "K. Levy",
      "V. Cevher"
    ],
    "submission_date": "2022-04-06",
    "semantic_scholar_id": "f1d2a203a8f4e3f596bee84bae87d5f415eff81e"
  },
  "2202-05791": {
    "title": "The Power of Adaptivity in SGD: Self-Tuning Step Sizes with Unbounded Gradients and Affine Variance",
    "authors": [
      "Matthew Faw",
      "Isidoros Tziotis",
      "C. Caramanis",
      "Aryan Mokhtari",
      "S. Shakkottai",
      "Rachel A. Ward"
    ],
    "submission_date": "2022-02-11",
    "semantic_scholar_id": "824e2a60781d4e1a921ba8f89c5c36931d724634"
  },
  "2201-12302": {
    "title": "Adaptive Accelerated (Extra-)Gradient Methods with Variance Reduction",
    "authors": [
      "Zijian Liu",
      "Ta Duy Nguyen",
      "Alina Ene",
      "Huy L. Nguyen"
    ],
    "submission_date": "2022-01-28",
    "semantic_scholar_id": "2e1241d2f3b72cddd896d36d1b3d69cfe628d8b2"
  },
  "2106-03056": {
    "title": "MURANA: A Generic Framework for Stochastic Variance-Reduced Optimization",
    "authors": [
      "Laurent Condat",
      "Peter Richtárik"
    ],
    "submission_date": "2021-06-06",
    "semantic_scholar_id": "4e2de2e732da34f95683c48bcace94353a34824d"
  },
  "2103-11333": {
    "title": "ANITA: An Optimal Loopless Accelerated Variance-Reduced Gradient Method",
    "authors": [
      "Zhize Li"
    ],
    "submission_date": "2021-03-21",
    "semantic_scholar_id": "4b33d375f5d5431967210d51c36e6500266265ac"
  },
  "2102-09700": {
    "title": "AI-SARAH: Adaptive and Implicit Stochastic Recursive Gradient Methods",
    "authors": [
      "Zheng Shi",
      "Nicolas Loizou",
      "Peter Richtárik",
      "Martin Tak'avc"
    ],
    "submission_date": "2021-02-19",
    "semantic_scholar_id": "ebf1782199646426259bc98538afc4af67575dff"
  },
  "2102-09645": {
    "title": "SVRG meets AdaGrad: painless variance reduction",
    "authors": [
      "Benjamin Dubois-Taine",
      "Sharan Vaswani",
      "Reza Babanezhad",
      "Mark W. Schmidt",
      "Simon Lacoste-Julien"
    ],
    "submission_date": "2021-02-18",
    "semantic_scholar_id": "42b240d5bef1850fabc25e58deff21b970901ce4"
  },
  "2012-13760": {
    "title": "Variance reduction on general adaptive stochastic mirror descent",
    "authors": [
      "Wenjie Li",
      "Zhanyu Wang",
      "Yichen Zhang",
      "Guang Cheng"
    ],
    "submission_date": "2020-12-26",
    "semantic_scholar_id": "de21dfb081ebea3ebe0d3af1e70dca42af748a83"
  },
  "2010-07799": {
    "title": "Adaptive and Universal Algorithms for Variational Inequalities with Optimal Convergence",
    "authors": [
      "Alina Ene",
      "Huy L. Nguyen"
    ],
    "submission_date": "2020-10-15",
    "semantic_scholar_id": "fe556559951d05fd1ebc4e80fc0e2b1eba375f78"
  },
  "2007-08840": {
    "title": "Adaptive Gradient Methods for Constrained Convex Optimization",
    "authors": [
      "Alina Ene",
      "Huy L. Nguyen",
      "Adrian Vladu"
    ],
    "submission_date": "2020-07-17",
    "semantic_scholar_id": "48d522cb09bc7b6ba5d46fecf7439dbc935a9a89"
  },
  "2006-10281": {
    "title": "Stochastic Variance Reduction via Accelerated Dual Averaging for Finite-Sum Optimization",
    "authors": [
      "Chaobing Song",
      "Yong Jiang",
      "Yi Ma"
    ],
    "submission_date": "2020-06-18",
    "semantic_scholar_id": "83ff0f3d617fb08c1f6ab81d4e43e5301ac22d79"
  },
  "2004-08688": {
    "title": "Lipschitz constant estimation of Neural Networks via sparse polynomial optimization",
    "authors": [
      "Fabian Latorre Gómez",
      "Paul Rolland",
      "V. Cevher"
    ],
    "submission_date": "2020-04-18",
    "semantic_scholar_id": "5f80240a91e751565b1a7d28de80700b8126258c"
  },
  "1911-08380": {
    "title": "Adaptive Gradient Descent for Convex and Non-Convex Stochastic Optimization",
    "authors": [
      "Aleksandr Ogaltsov",
      "D. Dvinskikh",
      "P. Dvurechensky",
      "A. Gasnikov",
      "V. Spokoiny"
    ],
    "submission_date": "2019-11-19",
    "semantic_scholar_id": "4aa6de9107c931f26ed8e9a8a97146655d889c2e"
  },
  "1910-13857": {
    "title": "UniXGrad: A Universal, Adaptive Algorithm with Optimal Guarantees for Constrained Optimization",
    "authors": [
      "Ali Kavis",
      "K. Levy",
      "F. Bach",
      "V. Cevher"
    ],
    "submission_date": "2019-10-30",
    "semantic_scholar_id": "8a44ba9519b6429a363af51bd2cff91b6d513065"
  },
  "1910-09529": {
    "title": "Adaptive gradient descent without descent",
    "authors": [
      "Yura Malitsky",
      "Konstantin Mishchenko"
    ],
    "submission_date": "2019-10-21",
    "semantic_scholar_id": "9a66746cfee06ac98c030328b7c860c79966ff09"
  },
  "1910-06532": {
    "title": "Adaptive Step Sizes in Variance Reduction via Regularization",
    "authors": [
      "Bingcong Li",
      "G. Giannakis"
    ],
    "submission_date": "2019-10-15",
    "semantic_scholar_id": "d19126ab364cfadf90d5043858a558853c62ec45"
  },
  "1908-09345": {
    "title": "Almost Tune-Free Variance Reduction",
    "authors": [
      "Bingcong Li",
      "Lingda Wang",
      "G. Giannakis"
    ],
    "submission_date": "2019-08-25",
    "semantic_scholar_id": "a6975e852a810148ea4b839f11ffe55ff46cdb4e"
  },
  "1906-08496": {
    "title": "Accelerating Mini-batch SARAH by Step Size Rules",
    "authors": [
      "Zhuang Yang",
      "Zengping Chen",
      "Cheng Wang"
    ],
    "submission_date": "2019-06-20",
    "semantic_scholar_id": "2cee1724a2e9fccd2c896820c9db87aedaad51ed"
  },
  "1906-02351": {
    "title": "On the Convergence of SARAH and Beyond",
    "authors": [
      "Bingcong Li",
      "Meng Ma",
      "G. Giannakis"
    ],
    "submission_date": "2019-06-01",
    "semantic_scholar_id": "b88294f620f2dd2f86ec5f4b9c3a21df3b9675db"
  },
  "1905-12412": {
    "title": "A unified variance-reduced accelerated gradient method for convex optimization",
    "authors": [
      "Guanghui Lan",
      "Zhize Li",
      "Yi Zhou"
    ],
    "submission_date": "2019-05-29",
    "semantic_scholar_id": "76bffc0859d0232b05b17e1c22aa4d46e64fbf87"
  },
  "1905-11261": {
    "title": "A Unified Theory of SGD: Variance Reduction, Sampling, Quantization and Coordinate Descent",
    "authors": [
      "Eduard A. Gorbunov",
      "Filip Hanzely",
      "Peter Richtárik"
    ],
    "submission_date": "2019-05-27",
    "semantic_scholar_id": "f762ce106b37728df1126375981a02a589e0497c"
  },
  "1905-10018": {
    "title": "Momentum-Based Variance Reduction in Non-Convex SGD",
    "authors": [
      "Ashok Cutkosky",
      "Francesco Orabona"
    ],
    "submission_date": "2019-05-24",
    "semantic_scholar_id": "90afc52bbacf37e6d3ca16ead35499f661222d7d"
  },
  "1905-09997": {
    "title": "Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates",
    "authors": [
      "Sharan Vaswani",
      "Aaron Mishkin",
      "I. Laradji",
      "Mark W. Schmidt",
      "G. Gidel",
      "Simon Lacoste-Julien"
    ],
    "submission_date": "2019-05-24",
    "semantic_scholar_id": "d32aa34a807560c94d5018e875a021813890447d"
  },
  "1809-02864": {
    "title": "Online Adaptive Methods, Universality and Acceleration",
    "authors": [
      "K. Levy",
      "A. Yurtsever",
      "V. Cevher"
    ],
    "submission_date": "2018-07-04",
    "semantic_scholar_id": "ab88a4b8318c386e6ecca394c83603c120ac4812"
  },
  "1807-01695": {
    "title": "SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path Integrated Differential Estimator",
    "authors": [
      "Cong Fang",
      "C. J. Li",
      "Zhouchen Lin",
      "T. Zhang"
    ],
    "submission_date": "2018-07-01",
    "semantic_scholar_id": "0572951adde832f6f84e26b5fb87da8e1d1ebca5"
  },
  "1806-01811": {
    "title": "AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization",
    "authors": [
      "Rachel A. Ward",
      "Xiaoxia Wu",
      "L. Bottou"
    ],
    "submission_date": "2018-06-05",
    "semantic_scholar_id": "33b2e7cb9c3d3cc902a8cd5118862815d406d31a"
  },
  "1805-02632": {
    "title": "Stochastic quasi-gradient methods: variance reduction via Jacobian sketching",
    "authors": [
      "R. Gower",
      "Peter Richtárik",
      "F. Bach"
    ],
    "submission_date": "2018-05-07",
    "semantic_scholar_id": "5f6323e0e04cc1263b3e0a452e94cde8841d5ea9"
  },
  "1803-02865": {
    "title": "WNGrad: Learn the Learning Rate in Gradient Descent",
    "authors": [
      "Xiaoxia Wu",
      "Rachel A. Ward",
      "L. Bottou"
    ],
    "submission_date": "2018-03-07",
    "semantic_scholar_id": "8325ea0dce7471335d32e4278560c8170e6c78f5"
  },
  "1802-05811": {
    "title": "Distributed Stochastic Optimization via Adaptive SGD",
    "authors": [
      "Ashok Cutkosky",
      "R. Busa-Fekete"
    ],
    "submission_date": "2018-02-01",
    "semantic_scholar_id": "d30f35fdf96ccebed9a6be5b5489da2378812a31"
  },
  "1705-10499": {
    "title": "Online to Offline Conversions, Universality and Adaptive Minibatch Sizes",
    "authors": [
      "K. Levy"
    ],
    "submission_date": "2017-05-30",
    "semantic_scholar_id": "9d2b22eb4f12f55f8c46fa226d6f723df1c7c4fb"
  },
  "1703-00102": {
    "title": "SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient",
    "authors": [
      "Lam M. Nguyen",
      "Jie Liu",
      "K. Scheinberg",
      "Martin Takác"
    ],
    "submission_date": "2017-03-01",
    "semantic_scholar_id": "db4d0e45560ceda35b6212036513bd4ab59ce99d"
  },
  "1702-00763": {
    "title": "Natasha: Faster Non-Convex Stochastic Optimization via Strongly Non-Convex Parameter",
    "authors": [
      "Zeyuan Allen-Zhu"
    ],
    "submission_date": "2017-02-02",
    "semantic_scholar_id": "298138e121aa60c15615b565ebf8a785591da3e0"
  },
  "1609-04747": {
    "title": "An overview of gradient descent optimization algorithms",
    "authors": [
      "Sebastian Ruder"
    ],
    "submission_date": "2016-09-15",
    "semantic_scholar_id": "769ef3d5021cd71c37d2c403f231a53d1accf786"
  },
  "1605-04131": {
    "title": "Barzilai-Borwein Step Size for Stochastic Gradient Descent",
    "authors": [
      "Conghui Tan",
      "Shiqian Ma",
      "Yuhong Dai",
      "Yuqiu Qian"
    ],
    "submission_date": "2016-05-13",
    "semantic_scholar_id": "6078f190e5f6f9b4fed7bfbae12cec592ba6effd"
  },
  "1605-08003": {
    "title": "Tight Complexity Bounds for Optimizing Composite Objectives",
    "authors": [
      "Blake E. Woodworth",
      "N. Srebro"
    ],
    "submission_date": "2016-05-01",
    "semantic_scholar_id": "03282fc4d206fde34237bcf85f1765442abbd4c9"
  },
  "1603-09649": {
    "title": "Stochastic Block BFGS: Squeezing More Curvature out of Data",
    "authors": [
      "R. Gower",
      "D. Goldfarb",
      "Peter Richtárik"
    ],
    "submission_date": "2016-03-31",
    "semantic_scholar_id": "58fe834315bc4add8f10d6ad8b6b20225626c5b4"
  },
  "1603-06160": {
    "title": "Stochastic Variance Reduction for Nonconvex Optimization",
    "authors": [
      "Sashank J. Reddi",
      "Ahmed S. Hefny",
      "S. Sra",
      "B. Póczos",
      "Alex Smola"
    ],
    "submission_date": "2016-03-19",
    "semantic_scholar_id": "acffbcb997ce73bf63e2b5a8d928b287357d4f4f"
  },
  "1603-05953": {
    "title": "Katyusha: the first direct acceleration of stochastic gradient methods",
    "authors": [
      "Zeyuan Allen-Zhu"
    ],
    "submission_date": "2016-03-18",
    "semantic_scholar_id": "908dc24b2af88f92939bf7a521d83ff5f45c86c3"
  },
  "1510-02533": {
    "title": "New Optimisation Methods for Machine Learning",
    "authors": [
      "Aaron Defazio"
    ],
    "submission_date": "2015-10-09",
    "semantic_scholar_id": "9b221450a693efc3c18695024cd8f73dd43337ea"
  },
  "1507-02000": {
    "title": "An optimal randomized incremental gradient method",
    "authors": [
      "Guanghui Lan",
      "Yi Zhou"
    ],
    "submission_date": "2015-07-08",
    "semantic_scholar_id": "4f9832490111bee4d4a8e4a5f470f61e1a0e32fb"
  },
  "1506-03662": {
    "title": "Variance Reduced Stochastic Gradient Descent with Neighbors",
    "authors": [
      "T. Hofmann",
      "Aurélien Lucchi",
      "Simon Lacoste-Julien",
      "B. McWilliams"
    ],
    "submission_date": "2015-06-11",
    "semantic_scholar_id": "1291c0b301f77f6f24ac654689a45f2df34ddbfb"
  },
  "1506-02186": {
    "title": "A Universal Catalyst for First-Order Optimization",
    "authors": [
      "Hongzhou Lin",
      "J. Mairal",
      "Zaïd Harchaoui"
    ],
    "submission_date": "2015-06-06",
    "semantic_scholar_id": "de5064b36b1ba71ac7424cdaf280af5bbdf780c1"
  },
  "1506-01972": {
    "title": "Improved SVRG for Non-Strongly-Convex or Sum-of-Non-Convex Objectives",
    "authors": [
      "Zeyuan Allen-Zhu",
      "Yang Yuan"
    ],
    "submission_date": "2015-06-05",
    "semantic_scholar_id": "3d0b96767d7285b7ce8ecca9715aef9b020fafd9"
  },
  "1412-6980": {
    "title": "Adam: A Method for Stochastic Optimization",
    "authors": [
      "Diederik P. Kingma",
      "Jimmy Ba"
    ],
    "submission_date": "2014-12-22",
    "semantic_scholar_id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8"
  },
  "1407-0202": {
    "title": "SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives",
    "authors": [
      "Aaron Defazio",
      "F. Bach",
      "Simon Lacoste-Julien"
    ],
    "submission_date": "2014-07-01",
    "semantic_scholar_id": "4daec165c1f4aa1206b0d91c0b26f0287d1ef52d"
  },
  "1407-2710": {
    "title": "Finito: A faster, permutable incremental gradient method for big data problems",
    "authors": [
      "Aaron Defazio",
      "Justin Domke",
      "T. Caetano"
    ],
    "submission_date": "2014-06-21",
    "semantic_scholar_id": "076ac26625e3fda9aaaf27f0f03426a0423bb188"
  },
  "1312-1666": {
    "title": "Semi-Stochastic Gradient Descent Methods",
    "authors": [
      "Jakub Konecný",
      "Peter Richtárik"
    ],
    "submission_date": "2013-12-05",
    "semantic_scholar_id": "75f854b27e48e3e8fbf9fa40b5f7d9bcd2251030"
  },
  "1309-5547": {
    "title": "Bundle-level type methods uniformly optimal for smooth and nonsmooth convex optimization",
    "authors": [
      "Guanghui Lan"
    ],
    "submission_date": "2013-09-22",
    "semantic_scholar_id": "3a77216ccde38198351586c82244085fe6f25342"
  },
  "1309-2388": {
    "title": "Minimizing finite sums with the stochastic average gradient",
    "authors": [
      "Mark W. Schmidt",
      "Nicolas Le Roux",
      "F. Bach"
    ],
    "submission_date": "2013-09-10",
    "semantic_scholar_id": "73068d3d5dacf987848eadd9af5b5fad8f7cf9c6"
  },
  "1309-2375": {
    "title": "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization",
    "authors": [
      "Shai Shalev-Shwartz",
      "Tong Zhang"
    ],
    "submission_date": "2013-09-09",
    "semantic_scholar_id": "d9bdff5eac0d0d1ebd8d09960f195b838ce16f4e"
  },
  "1209-1873": {
    "title": "Stochastic dual coordinate ascent methods for regularized loss",
    "authors": [
      "Shai Shalev-Shwartz",
      "Tong Zhang"
    ],
    "submission_date": "2012-09-10",
    "semantic_scholar_id": "0c3751db5a24c636c1aa8abfd9d63321b38cfce5"
  },
  "1002-4908": {
    "title": "Adaptive Bound Optimization for Online Convex Optimization",
    "authors": [
      "H. B. McMahan",
      "Matthew J. Streeter"
    ],
    "submission_date": "2010-02-25",
    "semantic_scholar_id": "172a5ffc5a9b5b64c781d85dddc605c8b96b8abd"
  }
}