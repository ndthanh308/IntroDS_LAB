{
  "title": "Is GPT a Computational Model of Emotion? Detailed Analysis",
  "authors": [
    "Ala N. Tak",
    "Jonathan Gratch"
  ],
  "submission_date": "2023-07-25T19:34:44+00:00",
  "revised_dates": [],
  "abstract": "This paper investigates the emotional reasoning abilities of the GPT family of large language models via a component perspective. The paper first examines how the model reasons about autobiographical memories. Second, it systematically varies aspects of situations to impact emotion intensity and coping tendencies. Even without the use of prompt engineering, it is shown that GPT's predictions align significantly with human-provided appraisals and emotional labels. However, GPT faces difficulties predicting emotion intensity and coping responses. GPT-4 showed the highest performance in the initial study but fell short in the second, despite providing superior results after minor prompt engineering. This assessment brings up questions on how to effectively employ the strong points and address the weak areas of these models, particularly concerning response variability. These studies underscore the merits of evaluating models from a componential perspective.",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.CY",
    "cs.HC"
  ],
  "primary_category": "cs.CL",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13779",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 0,
  "size_after_bytes": 0
}