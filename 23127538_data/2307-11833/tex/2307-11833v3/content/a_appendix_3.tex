\section{Appendix C: Additional Results}
\label{sec:appendc}

\textbf{Ablation Study on Activation Functions.} To investigate the effectiveness of the Wavelet activation function in PINNsFormer, we compare the performance differences using Wavelet than ReLU, Sigmoid, and Sin activation functions over convection and 1D-reaction problems. In particular, we study the effects of using the same activation function in both the feed-forward layer and encoder/decoder layer (marked as ReLU, etc.) and changing the activation function of the encoder/decoder layer to LayerNorm (as vanilla Transformer does, marked as ReLU+LN, etc.). The evaluation results are shown in Table~\ref{tbl:ablation}.

{\small
\begin{table}[h]
% \vspace{-0.1in}
\centering
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{ccccccc}
\hline\hline
\multirow{2}{*}{Activation} & \multicolumn{3}{c}{Convection} & \multicolumn{3}{c}{1D-Reaction} \\
& Loss & rMAE & rRMSE & Loss & rMAE & rRMSE \\ \hline
ReLU & 0.5256 & 1.001 & 1.001 & 0.2083 & 0.994 & 0.996 \\
Sigmoid & 0.1618 & 1.112 & 1.223 & 0.1998 & 0.991 & 0.993 \\
Sin & 0.3159 & 1.074 & 1.141 & 4.9e-6 & 0.017 & 0.032 \\
ReLU+LN & 0.7818 & 1.001 & 1.002 & 0.2028 & 0.992 & 0.993 \\
Sigmoid+LN & 0.0549 & 0.941 & 0.967 & 0.2063 & 0.992 & 0.990 \\
Sin+LN & 0.3219 & 1.083 & 1.156 & 4.7e-6 & 0.016 & 0.033 \\
Wavelet & \textbf{3.7e-5} & \textbf{0.023} & \textbf{0.027} & \textbf{3.0e-6} & \textbf{0.015} & \textbf{0.030} \\
Wavelet+LN & NaN & NaN & NaN & 3.9e-6 & 0.018 & 0.037 \\ \hline\hline
\end{tabular}
\caption{Results for solving convection and 1D-reaction equations using Transformer architecture with different activation functions. PINNsFormer (with Wavelet activation) consistently outperforms all other activation functions in terms of training loss, rMAE, and rRMSE}
\label{tbl:ablation}
% \vspace{-0.2in}
\end{table}
}

The ablation study results show two major conclusions: First, using wavelet activation shows constantly better performance than ReLU, Sigmoid, and Sin activations. In particular, Sin activation may show effectiveness in only certain cases, while Wavelet can generalize all cases well. Second, Introducing LayerNorm activation to the encoder/decoder does not significantly contribute to performance improvement. In contrast, LayerNorm activation may cause convergence issues when coupling with the Wavelet activation function for certain situations.

\textbf{Hyperparameter Sensitivity Study.} To investigate the possible difficulties in picking hyperparameters $k$ and $\Delta$, we compared the performance differences with a mesh choice of these two hyperparameters over the 1d-reaction problem. The evaluation results (relative-$\ell_2$ error, with failure modes bolded) are shown in Table~\ref{tbl:hyper}.

{\small
\begin{table}[h]
% \vspace{-0.1in}
\centering
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{ccccc}
\hline \hline
$\Delta t$   & k=3   & k=5   & k=7   & k=10  \\ \hline
1e-1 & 0.044 & \textbf{0.514} & \textbf{0.743} & \textbf{0.731} \\
1e-2 & 0.029 & 0.035 & 0.045 & 0.049 \\
1e-3 & 0.037 & 0.037 & 0.024 & 0.035 \\
1e-4 & \textbf{0.997} & 0.030 & 0.029 & 0.046 \\
1e-5 & \textbf{0.977} & 0.026 & \textbf{0.977} & 0.021 \\ \hline \hline
\end{tabular}
\caption{Results for solving 1D-reaction equation with various combinations of $\Delta t$ and $k$. PINNsFormer shows the flexibility of a wide choice of hyperparameters on certain problems.}
\label{tbl:hyper}
% \vspace{-0.2in}
\end{table}
}

The study on hyperparameter sensitivity of $\Delta t$ and $k$ exhibits three intuitions: First, given a mesh choice of $k$ and $\Delta t$, PINNsFormer is not sensitive to a wide range of the two hyperparameters. For instance, PINNsFormer successfully mitigates the failure modes for any combinations of $k\in[1e-2, 1e-3, 1e-4]$ and $\Delta t\in[3,5,7]$. Second, the choice of $\Delta t$ should not be either too large (i.e., 1e-1) or too small (i.e., 1e-5). Intuitively, either a too-large or a too-small $\Delta t$ degrades the temporal dependencies between discrete time steps. Third, increasing the pseudo-sequence length can help mitigate PINNs failure modes (i.e., $k=3\rightarrow5$ when $\Delta t=1e-4$). However, once PINNs successfully mitigate the failure mode, the benefit of further increasing $k$ is marginal.


\textbf{Result Visualizations.} We here present the plots of ground truth solutions, neural network predictions, and absolute errors for all evaluations included in the experimental section. The plots on convection, 1D-reaction, 1D-wave, and 2D Navier-Stokes equations are shown in Figure separately.

% Figure environment removed


% Figure environment removed


% Figure environment removed


% Figure environment removed