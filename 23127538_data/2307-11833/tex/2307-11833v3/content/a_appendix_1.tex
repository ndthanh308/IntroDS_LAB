\section{Appendix A: Model Hyperparameters}
\label{sec:appenda}


\textbf{Model Hyperparameters.} We provide a detailed set of hyperparameters used to obtain the experiment results, shown in Table \ref{tbl:hyper}.

\begin{table}[h]
\centering
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{cccc}
\hline\hline
Model                         & Hyperparameters & Value      & Model Parameters      \\ \hline\hline
\multirow{2}{*}{PINNs \& FLS} & hidden layer    & 4          & \multirow{2}{*}{527k} \\
                              & hidden size     & 512        &                       \\ \hline
\multirow{2}{*}{QRes}         & hidden layer    & 4          & \multirow{2}{*}{397k} \\
                              & hidden size     & 256        &                       \\ \hline
\multirow{7}{*}{PINNsFormer}       & $k$               & 5          & \multirow{7}{*}{454k} \\
                              & $\Delta t$               & 1e-3, 1e-4 &                       \\
                              & \# of encoder   & 1          &                       \\
                              & \# of decoder   & 1          &                       \\
                              & embedding size  & 32         &                       \\
                              & head            & 2          &                       \\
                              & hidden size     & 512        &                       \\ \hline \hline
\end{tabular}
\caption{Hyperparameters for Main Results}
\label{tbl:hyper}
\end{table}

% \begin{table}[h]
% \centering
% \renewcommand{\arraystretch}{1.5}
% \begin{tabular}{c|cc}
% Model                   & Hyparameter    & Value \\ \hline
% \multirow{2}{*}{MLP}    & hidden layers & 4     \\ 
%                         & hidden size    & 512   \\ \hline
% \multirow{7}{*}{Trans.} & $k$            & 5     \\
%                         & $\Delta t$     & 1e-4  \\
%                         & encoder        & 1    \\
%                         & decoder        & 1    \\
%                         & embedding size & 32    \\
%                         & heads          & 2     \\
%                         & hidden size    & 512  
% \end{tabular}
% \caption{Hyperparameters for Main Results}
% \label{tbl:hyper}
% \end{table}


\textbf{Training Overhead.} We compare the training overhead of PINNsFormer over PINNs, as PINNs are known as an efficient framework while Transformer-based models are known for being computationally costly. The comparison relies on solving the Convection PDEs, which are detailed in Table \ref{tbl:overhead}. Here, we vary the hyperparameter of pseudo-sequence length $k$ for validation purposes. In practice, we set $k=5$ for all the empirical experiments in this paper.

\begin{table}[h]
\centering
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{cccccc}
\hline\hline
\multicolumn{2}{c}{Model}      & \begin{tabular}[c]{@{}c@{}}Training Time\\ (sec/epoch)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Computational\\ Overhead\end{tabular} & \begin{tabular}[c]{@{}c@{}}GPU Memory\\ (MiB)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Memory\\ Overhead\end{tabular} \\ \hline \hline
\multicolumn{2}{c}{PINNs}      & 0.80                                                                & /                                                                & 1311                                                       & /                                                         \\ \hline
\multirow{3}{*}{PINsFormer} & $k$=3  & 2.10                                                                & 2.62x                                                            & 2207                                                       & 1.68x                                                     \\
                        & $k$=5  & 2.34                                                                & 2.92x                                                            & 2827                                                       & 2.15x                                                     \\
                        & $k$=10 & 3.10                                                                & 3.87x                                                            & 4803                                                       & 3.66x                                                     \\ \hline\hline
\end{tabular}
\caption{Overhead of PINNsFormer than PINNs in varying pseudo-sequence length. Both computational and memory overhead are tolerable and grow approximately linearly as $k$ increases}
\label{tbl:overhead}
\end{table}

\textbf{Evaluation Metrics.} We present the detailed formula of rMAE and rRMSE as the following:
\begin{equation}
\begin{gathered}
    \texttt{rMAE} =  \frac{\sum_{n=1}^N |\hat{u}(x_n,t_n)-u(x_n,t_n)|}{\sum_{n=1}^{N_{\textit{res}}}|u(x_n,t_n)|}\\
    \texttt{rRMSE} = \sqrt{\frac{\sum_{n=1}^N |\hat{u}(x_n,t_n)-u(x_n,t_n)|^2}{\sum_{n=1}^N|u(x_n,t_n)|^2}}
\end{gathered}    
\end{equation}
where $N$ is the number of testing points, $\hat{u}$ is the neural network approximation, and $u$ is the ground truth.