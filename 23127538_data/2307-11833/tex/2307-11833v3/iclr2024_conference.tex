
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}

\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{subfigure}
\usepackage{subcaption} 
\usepackage{mdwlist}
\usepackage{xspace}

\newcommand{\ourmethod}{\textrm{PINNsFormer}\xspace}
\newcommand{\aditya}[1]{\textbf{Aditya says: #1 }}
\newcommand{\rev}[1]{\textcolor{red}{\textbf{#1}}}
% \newcommand{\ourmethod}{\texttt{\textit{PINNsFormer}}\xspace}

% \usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{multirow}
% \usepackage{siunitx}
% \usepackage{graphicx}
% \usepackage{mathtools}
% \usepackage{wrapfig}
% \usepackage{subcaption}

% \usepackage{hyperref}       % hyperlinks
% \usepackage{url}            % simple URL typesetting
% \usepackage{booktabs}       % professional-quality tables
% \usepackage{amsfonts}       % blackboard math symbols
% \usepackage{nicefrac}       % compact symbols for 1/2, etc.
% \usepackage{microtype}      % microtypography
% \usepackage{xcolor}         % colors

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}


\title{PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Zhiyuan Zhao\\
  Georgia Institute of Technology\\
  Atlanta, GA 30332 \\
  \texttt{leozhao1997@gatech.edu} \\
  \And
  Xueying Ding \\
  Carnegie Mellon University \\
  Pittsburgh, PA 15213\\
  \texttt{xding2@andrew.cmu.edu} \\
  \AND
  B. Aditya Prakash \\
  Georgia Institute of Technology \\
  Atlanta, GA 30332 \\
  \texttt{badityap@cc.gatech.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Physics-Informed Neural Networks (PINNs) have emerged as a promising deep learning framework for approximating numerical solutions to partial differential equations (PDEs). However, conventional PINNs, relying on multilayer perceptrons (MLP), neglect the crucial temporal dependencies inherent in practical physics systems and thus fail to propagate the initial condition constraints globally and accurately capture the true solutions under various scenarios. In this paper, we introduce a novel Transformer-based framework, termed \ourmethod, designed to address this limitation. \ourmethod can accurately approximate PDE solutions by utilizing multi-head attention mechanisms to capture temporal dependencies. \ourmethod transforms point-wise inputs into pseudo sequences and replaces point-wise PINNs loss with a sequential loss. Additionally, it incorporates a novel activation function, \texttt{Wavelet}, which anticipates Fourier decomposition through deep neural networks. Empirical results demonstrate that \ourmethod achieves superior generalization ability and accuracy across various scenarios, including PINNs failure modes and high-dimensional PDEs. Moreover, \ourmethod offers flexibility in integrating existing learning schemes for PINNs, further enhancing its performance.
\end{abstract}

% \section{Submission of conference papers to ICLR 2024}
\input{content/01_introduction}
\input{content/02_related_work}
\input{content/03_method}
\input{content/04_experiment}
\input{content/05_conclusion}




\bibliography{iclr2024_conference}
\bibliographystyle{iclr2024_conference}

\clearpage
\appendix
% \section{Appendix}

\input{content/a_appendix_1}
\input{content/a_appendix_2}
\input{content/a_appendix_3}

\end{document}
