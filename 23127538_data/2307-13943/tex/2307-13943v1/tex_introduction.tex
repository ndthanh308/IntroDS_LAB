\section{Introduction}

Recent years have witnessed a surge of applying machine learning (ML) in high-stake and safety-critical applications.
Such applications pose an unprecedented {\it out-of-distribution (OOD) generalization challenge}: ML models are constantly exposed to unseen distributions that lie outside their training space. 
Despite well-documented success for {\it interpolation}, modern ML models (\eg, deep neural networks) are notoriously weak for {\it extrapolation}; a highly accurate model on average can fail catastrophically when presented with rare or unseen distributions~\citep{arjovsky2019invariant}.
For example, a flood predictor, trained with data of all 89 major flood events in the U.S. from 2000 to 2020, would erroneously predict on event ``Hurricane Ida'' in 2021. Without addressing this challenge, it is unclear when and where a model can be applied and how much risk is associated with its use.  

A promising solution for out-of-distribution generalization is to conduct {\it distributionally robust optimization} (DRO)~\citep{namkoong2016stochastic,staib2019distributionally,levy2020large}.
% Description of how DRO works.
DRO minimizes the {\it worst-case} expected risk over an {\it uncertainty set} of potential test distributions.
The uncertainty set is typically formulated as a divergence ball surrounding the training distribution endowed with a certain distance metric such as \textit{f}-divergence~\citep{namkoong2016stochastic} and Wasserstein distance~\citep{shafieezadeh2018wasserstein}.
% The {\it uncertainty set} is typically formulated as an \textit{f}-divergence~\citep{namkoong2016stochastic} or Wasserstein~\citep{shafieezadeh2018wasserstein} ball surrounding the training distribution.
Compared to empirical risk minimization (ERM)~\citep{vapnik1998statistical} that minimizes the average loss, DRO is more robust against {\it distributional drifts}  from spurious correlations, adversarial attacks, subpopulations, or naturally-occurring variation~\citep{robey2021model}.

However, it is non-trivial to build a realistic uncertainty set that truly approximates unseen distributions.
On the one hand, to confer robustness against extensive distributional drifts, the uncertainty set has to be sufficiently large, which increases the risks of conferring implausible distributions, {\it e.g.}, outliers, and thus yielding overly pessimistic models with low prediction confidence~\citep{hu2018does,frogner2021incorporating}.
On the other hand, the worst-case distributions are not necessarily the {\it influential} ones that are truly connected to unseen distributions; optimizing over worst-case rather than influential distributions would yield compromised OOD resilience.

As generalizing to arbitrary test distributions is impossible, we hypothesize further structure on the topology of distributions is crucial in constructing a realistic uncertainty set. More specifically, we propose topology-aware robust optimization (TRO) by integrating two optimization objectives:\\
(1) {\bf Topology learning}: We model the data distributions as many discrete groups lying on a common low-dimensional manifold, where we can {\it explore} the distributional topology by either using physical priors or measuring multiscale Earth Mover's Distance (EMD) among distributions.\\
(2) {\bf Learning on topology}: The acquired distributional topology is then {\it exploited} to construct a realistic uncertainty set, where robust optimization is constrained to bound the generalization risk within a topology graph, rather than blindly generalizing to unseen distributions.

Our contributions include:
1. A new principled optimization method that seamlessly integrates topological information to develop strong OOD resilience.
% {\color{blue}
% 2. Topology learning methods that are orders of magnitude faster than Earth Mover's distance to uncover distributional structure from massively collected datasets.
% }
% 2. Topology learning methods that are orders of magnitude faster than previous methods to uncover distributional structure from massively collected datasets.
2. Theoretical analysis that proves our method enjoys fast convergence for both convex and non-convex loss functions while the generalization risk is tightly bounded.
3. Empirical results in a wide range of tasks including classification, regression, and semantic segmentation demonstrate the superior performance of our method over SOTA.
% 4. Explainable distributional topology that is consistent with human knowledge and scientific plausibility. 
4. Data-driven distributional topology that is consistent with domain knowledge and facilitates the explainability of our approach.
