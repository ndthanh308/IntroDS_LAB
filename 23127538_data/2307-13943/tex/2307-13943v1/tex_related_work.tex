\section{Related Work} 


{\bf Distributionally Robust Optimization}.
In the context of distributionally robust optimization (DRO), \cite{duchi2021learning} and \cite{shalev2016minimizing} argued that minimizing the maximal loss over a set of possible distributions can provide better generalization performance than minimizing the average loss. 
% However, to confer robustness against extensive {\it distributional drifts}, the radius of the divergence ball has to be extremely large, which increases the risks of containing implausible distributions, \textit{e.g.,} outliers, and thus yielding overly pessimistic models with low prediction confidence~\citep{zhai2021doro}.
The robustness guarantee of DRO heavily relies on the quality of the uncertainty set which is typically constructed by moment constraints~\citep{delage2010distributionally}, \textit{f}-divergence~\citep{namkoong2016stochastic} or Wasserstein distance~\citep{shafieezadeh2018wasserstein}.
To avoid yielding overly pessimistic models, group DRO~\citep{hu2018does,sagawa2019distributionally} is proposed to leverage pre-defined data groups to formulate the uncertainty set as the mixture of these groups. Although the uncertainty set of Group DRO is of a wider radius while not being too conservative, our preliminary results show that Group DRO recklessly prioritizes the worst-case groups that incur higher losses than others. Such worst-case groups are not necessarily the influential ones that are truly connected to unseen distributions; optimizing over the worst-case rather than influential groups would yield mediocre OOD generalization performance.

% Several works~\citep{sinha2017certifying} define the uncertainty set as a divergence ball around the training distribution, but such uncertainty set can also lead to overly pessimistic models which optimize for implausible worst-case distributions~\citep{duchi2019distributionally}.
% To construct a realistic set of possible test distributions without being overly conservative, \cite{sagawa2019distributionally} proposed to utilize the prior knowledge of spurious correlations to define groups over the training data and then define the uncertainty set in terms of the mixture of these groups.
% One critical problem of DRO is that it is sensitive to outliers~\citep{qian2019robust,zhai2021doro}, resulting in degraded performance and training instability. 
% We incorporate topological priori into distributionally robust optimization, preventing the model from overfitting to outliers and yielding improved generalization capability on unseen distributions.

{\bf Out-of-Distribution Generalization}.
The goal of OOD generalization is to generalize the model from source distributions to unseen target distributions.
There are mainly two branches of methods to tackle OOD generalization: domain-invariant learning~\citep{arjovsky2019invariant,koyama2020out,liu2021heterogeneous} and distributionally robust optimization. The goal of domain-invariant learning is to exploit the causally invariant correlations across multiple distributions. 
Invariant Risk Minimization (IRM) is one of the most representative methods which learns the optimal classifier across source distributions.
However, recent work~\citep{rosenfeld2021risks} shows that IRM methods can fail catastrophically unless the test data are sufficiently similar to the training distribution.


% From another perspective, DRO methods aim to optimize the worst-performance over some uncertainty set (constructed by source domains) to ensure their generalization performances. One critical problem of such methods is that domains with significantly worse performance may dominate the learning procedure~\citep{qian2019robust};
% Domain discrepancy brought by domain or covariance shifts~\citep{storkey2006mixture} severely degrades the model performance on cross-domain recognition.
% Distribution discrepancy between training and test is common in real-world applications.
% Models trained using Empirical Risk Minimization~\citep{koltchinskii2011oracle} usually yield poor performance on unseen domains. 
% % The goal of domain adaptation is to adapt the model learned on the source domain to the target domain with a different distribution. Domain adaptation and domain generalization are proposed to minimize the domain discrepancy.
% Unsupervised Domain Adaptation (UDA)~\citep{murez2018image,shu2018dirt,french2017self} is the mostly widely adopted method to minimize the domain discrepancy by transferring knowledge learned from the labelled source domain to the unlabelled target domain. 
% Domain generalization~\citep{ghifary2015domain,li2017deeper,shankar2018generalizing,carlucci2019jigasaw,dou2019domain} provides another way to minimize the domain discrepancy, which has been intensively studied in recent years.
% Instead of having access to the data of target domains, domain generalization aims to learn from multiple labelled source domains and expect the model to perform well on unseen domains. Most methods either tried to learn a domain-invariant space to align domains~\citep{muandet2013domain,li2017deeper} or aggregate domain-specific modules~\citep{mancini2018robust}.


\begin{comment}
A promising solution for out-of-distribution (OOD) generalization is to conduct distributionally robust optimization (DRO)~\citep{namkoong2016stochastic,staib2019distributionally,levy2020large}.
% Description of how DRO works.
Typically, DRO aims to minimize the {\it worst-case} expected risk over an {\it uncertainty set} of potential test distributions~\citep{namkoong2016stochastic}.
The uncertainty set is usually formulated as a divergence ball surrounding the training distribution endowed with a certain distance metric such as \textit{f}-divergence~\citep{duchi2019variance,duchi2021learning}, and Wasserstein distance~\citep{shafieezadeh2018wasserstein,shafieezadeh2015distributionally}.
Compared to empirical risk minimization (ERM)~\citep{vapnik1998statistical} that minimizes the average loss, DRO is more robust against OOD data. However, to confer robustness against extensive {\it distributional drifts}, the radius of the divergence ball has to be extremely large, which increases the risks of containing implausible distributions, \textit{e.g.,} outliers, and thus yielding overly pessimistic models with low prediction confidence~\citep{zhai2021doro}. 
To construct a realistic uncertainty set without being overly conservative, 
Group DRO~\citep{hu2018does,sagawa2019distributionally} is proposed to leverage the prior knowledge of spurious correlations to define groups over the training data and formulate the uncertainty set as the mixture of groups.
The uncertainty set of Group DRO is of wider radius but with fewer degrees of freedom~\citep{sagawa2019distributionally}. However, Group DRO recklessly prioritizes  worst-case groups that incur higher losses than others. We argue that the worst-case groups are not necessarily the {\it influential} ones that are truly connected to unseen distributions; optimizing over worst-case rather than influential groups would yield mediocre OOD generalization performance.

Our proposed research is most related to two branched of OOD optimization methods.
(1) Distributionally Robust Optimization (DRO)~\citep{namkoong2016stochastic,staib2019distributionally,levy2020large} optimizes the the worst-case error over an uncertainty distribution set in order to develop resilience against the potential distributional shifts within the set.
Existing DRO methods are often constrained by moment~\citep{delage2010distributionally} or support~\citep{bertsimas2018data} conditions, {\it f}-divergence~\citep{namkoong2016stochastic}, and Wasserstein distance~\citep{shafieezadeh2018wasserstein}.
However, such methods are never constrained by data priors that are available in many scientific applications such as geographically distributed datasets. Without leveraging the data prior, there is a high risk to yield overly pessimistic models which optimize for implausible worst-case distributions, \eg, outliers.
(2) Invariant Risk Optimization (IRO)~\citep{arjovsky2019invariant} assumes causally invariant correlations (rather than spurious correlations) inside data and leverages multiple groups to find such invariance for generalizing under distributional shifts. 
IRO can be achieved by maximizing an invariant predictor across training groups to control the worst-case error~\citep{koyama2020invariance}, or jointly learning of the latent heterogeneity among the data to minimize the heterogeneous risk~\citep{liu2021heterogeneous}. 
However, the effectiveness of such methods relies heavily on the quality of training groups, and the intrinsic role of groups in IRO remains vague in theory.
\end{comment}