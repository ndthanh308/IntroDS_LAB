\section{Problem Formulation and Preliminary Works}

The problem of out-of-distribution (OOD) generalization is defined by a pair of random variables $(X, Y)$ over instances $x \in \mathcal{X} \subseteq \mathbb{R}^d$ and corresponding labels $y \in \mathcal{Y}$, following an unknown joint probability distribution $P(X, Y)$. The objective is to learn a predictor $f \in \mathcal{F}$ such that $f(x) \rightarrow y$ for any $(x, y) \sim P(X, Y)$. Here $\mathcal{F}$ is a function class that is model-agnostic for a prediction task. However, unlike typical supervised learning, the OOD generalization is complicated since one cannot sample directly from $P(X, Y)$. Instead, it is assumed that we can only measure $(X, Y)$ under different environmental conditions $e$ so that data is drawn from a set of groups $\mathcal{E}_{\text {all}}$ such that $(x, y) \sim P_e(X, Y)$. For example, in flood prediction, these environmental conditions denote the latent factors (\eg, stressors, precipitation, terrain, etc) that underlie different flood events. Let $\mathcal{E}_{\text {train}} \subsetneq \mathcal{E}_{\text {all}}$ be a finite subset of training groups (distributions), given the loss function $\ell$, an OOD-resilient model $f$ can be learned by solving a minimax optimization:
\begin{equation}\label{eq:ood}
\min _{f \in \mathcal{F}}\left\{\mathcal{R}(f):=\sup _{e \in \mathcal{E}_{\text {all }}} \mathbb{E}_{(x, y) \sim P_e(X, Y)}[\ell(f(x), y)]\right\} .
\end{equation}
Intuitively, Eq.~\ref{eq:ood} aims to learn a model that minimizes the worst-case risk over the entire family $\mathcal{E}_{\text {all}}$. It is nontrivial since we do not have access to data from any unseen distributions $\mathcal{E}_{\text {test }}=\mathcal{E}_{\text {all}} \backslash \mathcal{E}_{\text {train }}$.

{\bf Empirical Risk Minimization} (ERM).
Typically, classic supervised learning employs ERM~\citep{vapnik1998statistical} to find a model $f$ that minimizes the {\it average} risk under the training distribution $P_{tr}$:
\begin{equation*}
\min _{f \in \mathcal{F}}\{\mathcal{R}(f):= \mathbb{E}_{(x, y) \sim P_{tr}}[\ell(f(x), y)]\}.
\end{equation*}
% where $m = |\mathcal{E}_{\text {train}}|$ is the number of training groups. 
Though proved to be effective in \textit{i.i.d.} settings, models trained via ERM heavily rely on spurious correlations that do not always hold under distributional drifts~\citep{arjovsky2019invariant}.
% ERM can fail catastrophically under distributional shifts since it greedily absorb all correlations and may rely on spurious correlations: misleading heuristics that work for most training examples but do not always hold~\citep{sagawa2019distributionally}.

{\bf Distributionally Robust Optimization} (DRO).
%Improving from ERM, DRO~\citep{namkoong2016stochastic} optimizes for the {\it worst-case} error over an uncertainty set $Q \in \mathcal{P}(P_{tr})$:
%Improving from ERM that minimizes the average loss, DRO~\citep{namkoong2016stochastic} is developed to be more robust against OOD data by optimizing:
To develop OOD resilience, DRO~\citep{namkoong2016stochastic} minimizes the {\it worst-case} risk over an uncertainty set $Q$ by solving:  
\begin{equation}\label{eq:dro}
\min _{f \in \mathcal{F}}\{\mathcal{R}(f):=\sup _{Q \in \mathcal{P}(P_{tr})} \mathbb{E}_{(x, y) \sim Q} [\ell(f(x), y)]\}.
\end{equation}
Here the uncertainty set $Q$ approximates potential test distributions.
It is usually formulated as a divergence ball with a radius of $\rho$ surrounding the training distribution $\mathcal{P}\left(P_{tr}\right)=\left\{Q: D\left(Q, P_{tr}\right) \leq \rho\right\}$ endowed with a certain distance metric $D(\cdot,\cdot)$ such as $f$-divergence~\citep{namkoong2016stochastic} or Wasserstein distance~\citep{shafieezadeh2018wasserstein}.
To construct a realistic uncertainty set without being overly conservative, 
Group DRO is further developed to formulate the uncertainty set as the mixture of training groups~\citep{hu2018does,sagawa2019distributionally}.

Despite the well-documented success, existing DRO methods suffer from critical limitations.
(1) To endow robustness against a wide range of potential test distributions, the radius of the divergence ball has to be sufficiently large with high risks of containing implausible distributions; optimizing for implausible distributions would fundamentally damage the OOD resilience by yielding overly-pessimistic models with low prediction confidence.
%(1) To confer robustness against extensive distributional drifts, the radius of the divergence ball has to be sufficiently large, which increases the risks of conferring implausible distributions, {\it e.g.}, outliers, and thus yielding overly pessimistic models with low prediction confidence.
%(1) Without any prior knowledge or structural assumptions, the uncertainty set has to be sufficiently large to cover a wide range of distributional drifts; this increases the risks of conferring implausible distributions, {\it e.g.}, outliers, and thus yielding overly pessimistic models with low prediction confidence.
(2) The worst-case groups are not necessarily the {\it influential} ones that are truly connected to unseen distributions; optimizing over worst-case rather than influential groups would yield compromised OOD resilience.  
%(2) DRO recklessly prioritizes the worst-case groups that incur higher losses than others. However, we empirically find that the worst-case groups are not necessarily the {\it influential} ones that are truly connected to unseen distributions; optimizing over worst-case rather than influential groups would yield compromised OOD resilience.
%In this paper, we propose topology-aware robust optimization to address these limitations.

\begin{comment}
Different DRO methods adopt different constraints to formulate $\mathcal{P}(P_{tr})$.
For example, \textit{f}-divergence DRO~\citep{namkoong2016stochastic} formulates $\mathcal{P}\left(P_{tr}\right)=\left\{Q: D_{f}\left(Q \| P_{tr}\right) \leq \rho\right\}$
, where $\rho>0$ controls the extent of the distributional shift, 
and $D_{f}\left(Q \| P_{tr}\right)$ is the $f$-divergence between $Q$ and $P_{tr}$.
and Wasserstein DRO~\citep{shafieezadeh2018wasserstein} formulates $\mathcal{P}\left(P_{tr}\right)=\left\{Q: W_{c}\left(Q, P_{tr}\right) \leq \rho\right\}$,
where $W_{c}\left(Q, P_{tr}\right)$ is the Wasserstein distance between $Q$ and $P_{tr}$, 
and the subscript $c$ denotes the transportation cost function $c(\cdot, \cdot)$.
\end{comment}
%Here $\mathcal{P}\left(P_{tr}\right)=\left\{Q: D\left(Q, P_{tr}\right) \leq \rho\right\}$ denotes the uncertainty set lying around the training distribution $P_{tr}$ within a radius $\rho$. $D(\cdot)$ is a distributional distance metric such as $f$-divergence~\citep{namkoong2016stochastic} or Wasserstein distance~\citep{shafieezadeh2018wasserstein}.
%However, without any prior knowledge or structural assumptions, the uncertainty set $Q$ has to be sufficiently large to cover a wide range of distributional drifts for OOD resilience; this would yield overly pessimistic models with low prediction confidence~\citep{frogner2021incorporating}. 


\section{Topology-aware robust optimization}\label{sec:tro}

We propose a new principled optimization method (TRO) to develop OOD resilience, which integrates topology and optimization via a two-phase scheme: {\it Topology Learning} and {\it Learning on Topology}.

% The robustness guarantee of DRO heavily relies on the quality of the uncertainty set: the generalization risk is not bounded if the set does not include the true test distribution. Our goal is to construct a realistic uncertainty set that can approximate unseen distributions with bounded generalization risk.
%As generalizing to arbitrary test distributions is impossible, we hypothesize that further structure on the topology of groups and their corresponding distributions is crucial in constructing a realistic uncertainty set.
% that can approximate unseen distributions.
% we hypothesize that further structure on the topology of $\mathcal{E}_{\text {train}}$ and the corresponding distributions $P_e(X, Y)$ 
%To this end, we propose topology-aware distributionally robust optimization (TRO) to {\it uncover the distributional topology} (Sec.~\ref{sec:topology}), and {\it perform distributionally robust optimization over the topology} (Sec.~\ref{sec:optimization}). The overview of TRO is shown in Fig.~\ref{fig:tro}.
% Given the topology, we can perform OOD generalization according to the graph, rather than blindly generalize to unseen distributions.
% We provide theoretical analysis on the convergence rate and generalization bounds of TRO in Sec.~\ref{sec:theory} and include detailed proof in Appendix~B.

\subsection{Topology learning: Explore the distributional topology}\label{sec:topology}

\vspace{-15pt}
\begin{wrapfigure}{r}{0.42\textwidth}
% \vspace{-5pt}
  \begin{center}
    % Figure removed
  \end{center}
  \vspace{-10pt}
  \caption{Overview of topology-aware distributionally robust optimization (TRO).}
  \vspace{-20pt}
  \label{fig:tro}
\end{wrapfigure}\leavevmode

We model the data groups $\mathcal{E}_{\text {all}}$ as many discrete distributions lying on a common low-dimensional manifold in a high-dimensional data measurement space.
In such case their structure, {\it i.e. distributional topology}, can be naturally captured by a graph $\mathcal{G}=(V, E)$, where the entities  $V=\cup_{e \in \mathcal{E}_{\text {all}}} X_e$ symbolize the groups and the edges $E$ represent interactions among groups.
The topology graph is constructed by: 
(1) {\it identifying entity}: we assume the entities are defined by the given group identities;
and (2) {\it uncovering interactions}: we consider two scenarios to measure the connectivity between discrete distributions as illustrated in Fig~\ref{fig:tro}.

\textbf{Physical-based distributional topology}.
% In the case where the adjacency information is available, we will acquire a physical graph $\mathcal{G}_{physic}$ by simply imposing the predefined neighborhood information.
% Adjacency information widely exists in scientific datasets.
In the scenario where the distributional adjacency information is available, we can instantly acquire the topology $\mathcal{G}_{physic}$ by simply imposing the predefined neighborhood information.
For example, to capture the similarity of weather events in the U.S., one can construct a graph where each state realizes an entity, and the physical adjacency between two states results in an edge (see Fig.~\ref{fig:tro}).
In this case, $\mathcal{G}_{physic}$ functions as {\it a physical prior} to constrain the robust optimization introduced in Sec.~\ref{sec:optimization}.
We empirically find $\mathcal{G}_{physic}$ yields an improvement of 9.56\% over the state of the art regarding OOD generalization reported in Sec.~\ref{sec:classification}.

{\bf Data-driven distributional topology}.
In the absence of  $\mathcal{G}_{physic}$, we propose a data-driven approach to learn the topology $\mathcal{G}_{data}$ from training data.
Specifically, we embed the individual groups onto a shared data graph based on an affinity matrix of the combined data.
Inspired by~\cite{leeb2016holder}, such a data graph can be viewed as a discretization of an underlying Riemann closed manifold.
By simulating a time-dependent diffusion process over the graph, we will obtain density estimates at multiple scales for each group, which will be used to calculate $\ell_1$ distances between two groups.
Such multiscale $\ell_1$ distance has been proved to be topologically equivalent to the Earth Mover's Distance (EMD) on the manifold geodesic, but cutting down the computational complexity from $O\left(m^2 n^3\right)$ to $\tilde{O}(mn)$ between $m$ distributions over $n$ data points~\citep{tong2021diffusion}.   

We obtain the data-driven topology through three steps:
(1) {\it Data graph construction}: we construct a data graph through an affinity matrix $\mathbf{K}$  of the combined data. $\mathbf{K}$ can be implemented through kernel functions (\eg, RBF kernel) which capture the similarity of data. Instead of calculating the similarity between raw data, we calculate the similarity between features extracted from an ERM-trained model as it captures spurious correlations which preserve group identity~\citep{creager2021environment}.
Specifically, we define the affinity matrix as: $\mathbf{K}_{i, j}=\exp \left(-{\left\|f(x_i)-f(x_j)\right\|^2}/{\sigma^2}\right)$, where $\sigma^2$ is the kernel scale.
(2) {\it Multiscale diffusion density estimation}: 
to simulate the diffusion process over the graph, we obtain a Markov diffusion operator $\mathbf{P}$ from $\mathbf{K}$.
Following \cite{coifman2006diffusion}, we normalize the affinity matrix: $\mathbf{M}=\mathbf{Q}^{-1} \mathbf{K} \mathbf{Q}^{-1}$, where $\mathbf{Q}$ is a diagonal matrix and $\mathbf{Q}_{i,i}=\sum_j \mathbf{K}_{i, j}$. The diffusion operator is defined as $\mathbf{P}=\mathbf{D}^{-1} \mathbf{M}$, where  $\mathbf{D}$ is a diagonal matrix and $\mathbf{D}_{i, i}=\sum_j\mathbf{M}_{i, j}$.
The operator $\mathbf{P}$ will be used to approximate the multiscale density estimates $\mathbf{\mu}_e$ for each data group $X_e$: $\mathbf{\mu}_e^t=\frac{1}{n_e} \mathbf{P}^t \mathbf{1}_{X_e}$, where $t$ is the diffusion time,
$\mathbf{P}^t$ denotes the $t$-th power of $\mathbf{P}$,
and $\mathbf{1}_{X_e}$ is the indicator function for group $e$.
Intuitively, $\mathbf{P}^t_{i, j}$ sums the probabilities of all possible paths of length $t$ between $x_i$ and $x_j$. 
By taking multiple powers of $\mathbf{P}$, $\mathbf{\mu}_e$ reveals the topological structure of $X_e$ at multiple scales.
(3) {\it Diffusion EMD measurement}: we follow~\cite{tong2021diffusion} to measure the geodesic distance $W_{\alpha, K}\left(X_e, X_{e^\prime}\right)$ between $X_e$ and $X_{e^\prime}$ by aggregating the $\ell_1$ distances between the multiscale density estimates:
\begin{equation}\label{eq:wasserstein}
W_{\alpha, K}\left(X_e, X_{e^\prime}\right)=\sum_{k=0}^K\left\|T_{\alpha, k}\left(X_e\right)-T_{\alpha, k}\left(X_{e^\prime}\right)\right\|_1, 
\end{equation}
where $\alpha$ is used to balance long- and short-range distances, $K$ is the maximum scale, and
\begin{equation*}
T_{\alpha, k}\left(X_e\right) = \begin{cases}2^{-(K-k-1) \alpha}\left(\mathbf{\mu}_e^{\left(2^{k+1}\right)}-\mathbf{\mu}_e^{\left(2^k\right)}\right), & k<K \\ \mathbf{\mu}_e^{\left(2^K\right)}, & k=K\end{cases}
\end{equation*}

Although $\mathcal{G}_{data}$ is computationally more expensive than $\mathcal{G}_{physic}$, our experimental results in Sec.~\ref{sec:regression} indicate that optimizing with $\mathcal{G}_{data}$ can yield improved OOD resilience. Besides, the ablation study in Sec.~\ref{sec:seg} also indicates that $\mathcal{G}_{data}$ is consistent with domain knowledge and enhances the explainability of TRO. Last but not least, the data-driven method is fully differentiable, making it amenable to jointly conducting topology learning and learning on topology in an end-to-end manner. We leave this as future work. 

\subsection{Learning on topology: Exploit topology for robust optimization}\label{sec:optimization}

\vspace{-15pt}
\begin{wrapfigure}{r}{0.48\textwidth}
\vspace{5pt}
\begin{minipage}{0.48\textwidth}
\begin{algorithm}[H] 
	\caption{TRO Algorithm}
% 	\LinesNumbered
	\label{alg:overrall}
	\KwIn {Data of $\mathcal{E}_{\text {train}}$, Step sizes $\eta_\theta$ and $\eta_\mathbf{q}$}
	\KwOut {Learned model $f$}
	\ul{\it Topology Learning}:\\
	\eIf{$\mathcal{G}_{physic}$ exists}{
	$\mathcal{G}$ $\leftarrow$  $\mathcal{G}_{physic}$
	}{
% 	Obtain $\mathcal{G}_{data}$ via diffusion EMD\\
	Obtain the affinity matrix $\mathbf{K}$ from data\\
	$\mathbf{Q} \leftarrow \operatorname{Diag}\left(\sum_j \mathbf{K}_{i j}\right)$\\
    $\mathbf{M} \leftarrow \mathbf{Q}^{-1} \mathbf{K}\mathbf{Q}^{-1}$ \\
    $\mathbf{D} \leftarrow \operatorname{Diag}\left(\sum_j \mathbf{M}_{i j}\right)$ \\
    $\mathbf{P} \leftarrow \mathbf{D}^{-1} \mathbf{M}$\\
    Obtain $\mathcal{G}_{data}$ via Eq.~\ref{eq:wasserstein}\\
	$\mathcal{G}$ $\leftarrow$  $\mathcal{G}_{data}$
	}
    % \midrule
	\ul{\it Learning on Topology}:\\
	Calculate topological prior $\mathbf{p}$ from $\mathcal{G}$\\
	 \While{not converged}{
	     Sample $(x, y) \sim P_e(X, Y)$ $\forall e \in \mathcal{E}_{\text{train}}$  \\
	     Calculate $\mathcal{R}(f, \mathbf{q})$ via Eq.~\ref{eq:dual}\\
	     Update $\theta$ and $\mathbf{q}$ via Eq.~\ref{eq:primal-dual}
   }
\end{algorithm}
\end{minipage}
\vspace{-15pt}
\end{wrapfigure}\leavevmode

Next, we propose a principled method that integrates distributional topology to develop TRO.
The key challenge is how to leverage $\mathcal{G}$ to construct a {\it uncertainty set} which can approximate unseen distributions with bounded generalization risk.
%that strikes a good trade-off between worst-case and average-case performance.
Our main idea is to assess the {\it group centrality} of training distributions. 
{\it Graph centrality} is widely used in social network analysis~\citep{newman2005measure} to measure how much information is propagated through each entity.
Here we introduce {\it group centrality} to identify {\it influential groups} that are truly connected to unseen distributions, which can be calculated using graph measurements~\citep{tian2019rethinking} such as degree, betweenness, and closeness.
% More specifically, we first calculate the centrality of each entity in $\mathcal{G}_{all}$ to compose a \textit{topological prior} $\mathbf{p}$.
% Then, we can construct the {\it uncertainty set} as an arbitrary mixture of training groups $Q := \{\sum_{e \in \mathcal{E}_{\text {train}}} q_e P_e \; | \; \mathbf{q} \in \Delta_m \}$ where $\Delta_m$ is a $(m-1)-$dimensional probability simplex~\citep{rudin1976principles}.
% Finally, we can achieve OOD generalization by solving a constrained minimax optimization:
More specifically, we first calculate the centrality of each entity in $\mathcal{G}$ as a {\it topological prior} $\mathbf{p}$ to identify influential groups. Then, we construct the {\it uncertainty set} as an arbitrary mixture of training groups $Q := \{\sum_{e \in \mathcal{E}_{\text {train}}} q_e P_e \; | \; \mathbf{q} \in \Delta_m \}$ where 
$q_e$ denotes the weight of group $e$, $P_e$ is the distribution of group $e$,
and $\Delta_m$ is a $(m-1)-$dimensional probability simplex. Finally, we use the prior $\mathbf{p}$ to constrain the uncertainty set $Q$ by solving the minimax optimization problem as:
\begin{equation}\label{eq:tro}
\underset{f \in \mathcal{F}}{\min}
\{
\mathcal{R}(f, \mathbf{q}) := \max _{\mathbf{q} \in \Delta_{m}} \; \sum_ {e \in \mathcal{E}_{\text{train}}} q_e \; \mathbb{E}_{(x, y) \sim P_e (X, Y)} [\ell(f(x), y)]
\}, \;\;\;
\text {s.t. } \mathcal{D}(\mathbf{q} \| \mathbf{p}) \leq \tau.
\end{equation}
% Intuitively, we ensure the uncertainty set $Q$ to have a similar structure as the topological prior $\mathbf{p}$ after optimization;
Intuitively, groups with high training loss and centrality will be assigned with large weights;
this can tightly bound the OOD generalization risk within a topological graph.
$\mathcal{D}$ is an arbitrary distributional distance metric.
% \eg, $\ell_2$ distance or KL divergence~\citep{kullback1951information}.
We use $\ell_2$ distance to implement $\mathcal{D}$ due to its strong convexity and simplicity.
% or Wasserstein Distance~\citep{shafieezadeh2018wasserstein}. 
% $\tau$ is a predefined margin to control the intensity of the constraint.
%However, typical parameterizations often lead to nonconvex problems, wherein methods such as SGD cannot guarantee constraint satisfaction.

However, solving Eq.~\ref{eq:tro} often leads to a non-convex problem, wherein methods such as stochastic gradient descent (SGD) cannot guarantee constraint satisfaction~\citep{robey2021model}.
To address this issue, we leverage Karush–Kuhn–Tucker conditions~\citep{boyd2004convex} and introduce a Lagrange multiplier to convert the constrained problem into its unconstrained counterpart:
\begin{equation}\label{eq:dual}
\underset{f \in \mathcal{F}}{\min}
\{
\mathcal{R}(f, \mathbf{q}) := \max _{\mathbf{q} \in \Delta_{m}} \; \sum_ {e \in \mathcal{E}_{\text {train}}} q_e \; \mathbb{E}_{(x, y) \sim P_e (X, Y)} [\ell(f(x), y)]
- \lambda \mathcal{D}(\mathbf{q} \| \mathbf{p})
\},
\end{equation}
where $\lambda$ is the dual variable. 
Let $\theta \in \Theta$ be the model parameters of $f$, we can solve the primal-dual problem effectively by alternatively updating:
\begin{equation}\label{eq:primal-dual}
\theta^{t+1} = \theta^{t} - \eta_\theta^t \nabla_{\theta} \mathcal{R}(f, \mathbf{q}),\;\;
\mathbf{q}^{t+1} = \mathcal{P}_{\Delta_m}( \mathbf{q}^{t} + \eta_\mathbf{q}^t \nabla_{\mathbf{q}} \mathcal{R}(f, \mathbf{q})), 
\end{equation}
where $\eta_\theta^t$ ($\eta_\mathbf{q}^t$) is  gradient descent (ascent) step size. $\mathcal{P}_{\Delta_m}(\mathbf{q})$ projects $\mathbf{q}$ onto  simplex $\Delta_m$ for regularization. The overall algorithm of TRO is shown in Alg.~\ref{alg:overrall}.
In Sec.~\ref{sec:theory}, we show TRO enjoys fast convergence for both convex and non-convex loss functions, while the generalization risk is tightly bounded with topological constraints.
We empirically demonstrate TRO achieves strong OOD resilience by striking a good balance between the worst-case and influential groups (see Sec.~\ref{sec:regression}).

{\bf Calculation of group centrality}. 
We use betweenness centrality to measure the centrality of groups.
Betweenness centrality measures how often an entity is on the shortest path between two other entities in the topology. 
\cite{freeman1977set} reveals that entities with higher betweenness centrality would have more control over the topology as more information will pass through them.
For physical-based topology $\mathcal{G}_{physic}$, 
we define the centrality of group $e$ by computing the fraction of shortest paths that pass through it: $c_e^{physic}=\sum_{s \in \mathcal{E}_{\text{train}}, t \in \mathcal{E}_{\text{test}}} \frac{\sigma(s, t \mid e)}{\sigma(s, t)}$, 
where $\sigma(s, t)$ is the number of shortest paths between groups $s$ and $t$ in the graph $((s, t)$-paths), and $\sigma(s, t \mid e)$ is the number of $(s, t)$-paths that go through group $e$.
Intuitively, $c_e^{physic}$ measures how much information is propagated through $e$ from the start (training) to the end (test).
For data-driven topology $\mathcal{G}_{data}$, the underlying assumption is that training groups with high centrality also exert strong influence on unseen groups.
Instead of sampling group pairs from two separate sets, we sample $(s, t)$ from $\mathcal{E}_{\text{train}}$. The centrality is modified as: $c_e^{data}=\sum_{s, t \in \mathcal{E}_{\text{train}}} \frac{\sigma(s, t \mid e)}{\sigma(s, t)}$.
We use softmax function to normalize $c_e$ and the prior probability for group $e \in \mathcal{E}_{\text{train}}$ is defined as: $p_e = \text{exp}(c_e)/{\sum_{e\in \mathcal{E}_{\text{train}}} \text{exp}(c_e)}$.