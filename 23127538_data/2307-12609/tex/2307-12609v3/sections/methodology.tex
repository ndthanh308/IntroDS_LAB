\section{Dataset Construction Methodology}
\label{sec:methodology}

This section presents our methodology to build \dataset.

% Figure environment removed


\noindent
\textbf{Hypotheses:}
Our hypothesis is that:
\dcircle{1} the majority of Android app developers rely on Android Studio and Gradle to build their apps;
\dcircle{2} that Gradle in turn relies on Maven and Google to retrieve libraries~\cite{gradle_maven, gradle_google}; and
\dcircle{3} open-source Android apps can bring valuable information about the library used in apps, thanks to the availability of configuration files.


Based on these hypotheses, we set up a straightforward approach that can be seen in Figure~\ref{fig:overview}.
Our approach involves two main steps:
\dcircle{1} extracting libraries from the Maven and Google's Android library repositories; and 
\dcircle{2} extracting libraries used in open-source projects.
Maven is a widely used tool for managing dependencies and building Java-based projects, and the Maven repository is a central location where developers can find and share libraries. 
Google's Android library repository is a collection of Android libraries available through the Google Maven repository.
In the following sections, we explain how we proceed to build \dataset.

\subsection{Mining repositories}

This section details how we obtained the first portion of our dataset by leveraging public library repositories.
Our process is divided into two steps:
\dcircle{1} obtaining package names from the repositories.
\dcircle{2} gathering transitive dependencies from the  package names.

\subsubsection{Package Name Collection}

This section explains how we collect package names from Maven and Google repositories.

\noindent
\textbf{Maven.} 
First, we download the Maven index file (updated weekly) and the Maven Indexer Command Line Interface (CLI) tool which are available publicly.
The Maven index is a file created using the Lucene library~\cite{bialecki2012apache} and contains metadata about the artifacts available in the Maven repository. 
The Maven Indexer CLI is a tool used to extract this file. 
Once the Maven index file is extracted, we use a Java program of our own, called SearchLuceneIndex, to extract all the \emph{groupIds} from the index.
At the time of writing, our list from the Maven repository contains a total of \libsFromMaven entries.

\noindent
\textbf{Google.}
We could extract a total of \libsFromGoogle libraries by accessing the Maven Google repository.
Once we have obtained the package names from both the Maven repository and the Maven Google repository, we merge the two lists into a single list, eliminating any duplicate entries. This results in a list of \sumWithGoogle package names.

\subsubsection{Transitive Dependency Extraction}

Libraries often rely on other libraries known as \emph{transitive dependencies}. 
For example, the \texttt{com.android.tools.sdk-common} library in version 22.9.0 has 12 transitive dependencies. 
Figure~\ref{code:tree} shows the dependency tree of this library.
To create a comprehensive and up-to-date set of libraries, it is important to consider these transitive dependencies. 

% Figure environment removed

We used the \emph{mvn} utility (from Maven) to build a given project's dependency tree.
However, since our dataset is made of libraries (i.e., package names) and not actual development projects, getting the dependency trees from the libraries is not trivial. 
We implemented the following strategy.
First, from the maven index, we obtained all artifacts in the form of the artifactIds (e.g., com.example) concatenated with groupIds (e.g., MyLibrary) and versions (e.g., 1.0) to get the real library names, resulting in a list of \num{10069375} unique libraries.
We considered all available versions for each library because transitive dependencies can differ from one version of a library to another. 
Then, for each library, we generated a \texttt{pom.xml} file with a dummy project and the library as a dependency of the project.
We then launched the \texttt{mvn dependency:tree} command to get the list of all transitive dependencies of the library.
Obtaining transitive dependencies for all libraries in our dataset is computationally intensive. 
With a total of \num{10069375} libraries, extracting transitive dependencies for each library would have taken an unreasonable amount of time. 
Therefore, we set a timeout of 30 seconds for each call to the \texttt{mvn dependency:tree} command.
Even with this timeout, \num{9312664} (i.e., 92.5\%) dependency trees were successfully built, and the process still required 21 days of computation using 70 instances in parallel on a Debian server with an AMD EPYC 7552 48-Core Processor CPU with 96 cores and 630GB of RAM.
Then, we parsed the dependency trees generated and built a list of \transitiveDependencies additional libraries with any duplicate removed.
It should be noted that this number (i.e., \transitiveDependencies) was reached long before (after only 10 days) the \num{9312664} dependency trees were built.
Finally, we merged this list with the one generated previously, and we removed any duplicates, resulting in a final list of \sumWithTransitiveDependencies package names.


\subsection{Mining open-source Android projects}

Open-source projects provide valuable information about the libraries, relying on various third-party libraries to provide specific features and functionality. 
In the following, we describe the process for extracting lists of libraries from open-source projects.

We first obtained a list of open-source Android projects by downloading all apps in \az that were collected from the F-Droid repository.
At the time of writing, this represented \num{4464} apps. 
We then used the F-Droid website to crawl the source code links for these apps and attempted to clone the repositories.
Out of the 4464 apps, we could successfully clone 3425 projects (some reasons why some repositories cannot be cloned involve repositories that do not exist anymore, or the "git clone" command cannot work for, e.g., svn repositories, our prototype currently ignores non-git repositories).
Next, we searched the \texttt{build.gradle} files available in these projects and extracted information about the libraries used.
Specifically, we searched for the Gradle commands \texttt{implementation}, \texttt{classpath}, and \texttt{compile}, commonly used to declare dependencies. 
After parsing the \texttt{build.gradle} files and extracting the relevant information, we obtained a list of \libsOpenSourceProjects unique libraries, which brings our total count of libraries to \sumWithLibsOpenSourceProjects after deduplicating.

To obtain a list of libraries as comprehensive as possible, it is not enough to consider libraries explicitly imported in the \texttt{build.gradle} files of the app projects.
It is also necessary to consider library repositories (other than the default Maven and Google) declared in the \texttt{build.gradle} files and use this information to search for additional libraries.
This process led to two additional repositories: jcenter and gradlePluginPortal. 
However, we found jcenter is deprecated and all its libraries are now in the Maven repository~\cite{jcenter},  
which we have already mined. 
The gradlePluginPortal website proved to be a valuable resource. 
We crawled the gradlePluginPortal website, comprising 656 pages at the time of writing, and obtained an additional list of all package names available.
This led to the discovery of \libsOpenSourceProjectsRepositories libraries, which we added to our list after removing potential duplicates and led to a total of \sumWithLibsOpenSourceProjectsRepositories libraries.

\subsection{Refinement}
We have designed a refinement process to remove unnecessary package names from the list of third-party libraries. This process helps ensure that the list is as concise as possible.
For example, if the list contains the package names ``com.example.subpackage" and ``com.example", we would only keep ``com.example" because this would be sufficient for identifying ``com.example.subpackage.My\-Class" as a library in an app.
This is done by iterating over the list of package names and checking whether any element $e_1$ in the list starts with another element $e_2$ in the same list. 
If this is the case, the element $e_1$ is removed from the list. This process is repeated until no more changes are made to the list.
Overall, our refinement process yields a list of \libsAfterRefinement package names by discarding \num{41194} of them (i.e., \sumWithLibsOpenSourceProjectsRepositories $-$ \libsAfterRefinement).
Table~\ref{table:steps} shows the details of all the steps of our methodology with the number of libraries collected.



\begin{table}
    \setlength{\tabcolsep}{1pt}
    \centering
    \caption{\# of libraries after each step (OS = open-source)}
    \begin{adjustbox}{width=.8\columnwidth,center}
        \begin{tabular}{lccccccccc}
            \hline
            Source &  &  \\ \hline
            Maven & \libsFromMaven &  \\ 
            Google & +\libsFromGoogle &$\rightarrow$& \sumWithGoogle \\ 
            Transitive Dep. && &+\transitiveDependencies & $\rightarrow$ & \sumWithTransitiveDependencies && \\ 
            OS imports & &&&&+\libsOpenSourceProjects & $\rightarrow$ & \sumWithLibsOpenSourceProjects &\\ 
            gradlePluginPortal &&& &&&&+\libsOpenSourceProjectsRepositories & $\rightarrow$ &\sumWithLibsOpenSourceProjectsRepositories \\ \hline
            After Refinement &&&&&&&& & \libsAfterRefinement \\ \hline
        \end{tabular}
    \end{adjustbox} 
    \medskip
    \textit{each resulting number is given after removing duplicates}
    \label{table:steps}
\end{table}
