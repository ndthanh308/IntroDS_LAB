\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts,yhmath}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{comment}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Unveiling Security, Privacy, and Ethical Concerns of ChatGPT
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}
\author{\IEEEauthorblockN{Xiaodong Wu, Ran Duan, and Jianbing Ni} \IEEEauthorblockA{Department of Electrical \& Computer Engineering, Queen's University, Kingston, Canada K7L 3N6\\}
 Email: jianbing.ni@queensu.ca}

\maketitle

\begin{abstract}
This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.

\end{abstract}

\begin{IEEEkeywords}
ChatGPT, Large Language Model (LLM), Security, Privacy, Ethics \end{IEEEkeywords}

\section{Introduction}
%intro chatgpt
In December 2022, OpenAI released an interactive chat platform, called ChatGPT. Its powerful in-context learning and naturally generation ability created a big shock to the whole world. Before this, there are some powerful large language models (LLM) like GPT \cite{radford2018improving} or BERT \cite{devlin2018bert}, which can perform well on many nature language processing (NLP) tasks, but carefully processed inputs are required in the query procedure. In other words, these machine learning tools can only be used to complete specific tasks with constrained inputs. Nevertheless, ChatGPT has greatly improve this by showing a wonderful interactive ability, which can respond almost any legal questions in different styles or targeting on different tasks. For example, users can request ChatGPT to write a series of codes with comments for each part to address certain problems. ChatGPT can also be used to summarize given texts or provide detailed illustrations for some complex concepts. ChatGPT can provide long but natural responses, which are aligned with human's knowledge. It integrates a variety of ability for NLP and possesses the ability to clarify its knowledge boundary and refuse the illegal queries. Currently, ChatGPT has over 100 million users and there are over 1.6 billions visits in June 2023. ChatGPT has become the most famous AI application and the center of the world's attention.

%security ethic issue
However, similar to other AI applications, ChatGPT brings ethical concerns and misuse risks. For example, due to its powerful text reasoning and generation ability, students find it very helpful in writing homework. In the beginning, ChatGPT was used to explain some difficult content or rephrase the written project reports, but soon, it was utilized to write the entire homework. Such misuse immediately attracts attentions from the teachers and schools and it was soon identified as plagiarism. Another concern is the copyright from ChatGPT. With increasing number of people who use ChatGPT to create original-like text content without citation, the copyright of the content created by ChatGPT become a serious concern. No one is responsible for the correctness and accuracy of the content. It becomes necessary to regulate the copyright of machine's generation, including both visual and textual content. Besides, although there are privacy protection mechanisms in ChatGPT, such as the block of access to personal data about individuals, it is not guaranteed that no leakage of its training data would occur. Malicious attacks, such as jailbreaking attacks, may utilize its great generation ability to infer some information from personal data or even use them to attack other AI models. Therefore, It is well recognized that despite great advantages ChatGPT brings to our world, the potential security, privacy, and ethical problems cannot be overlooked.

%contribution summary
In this paper, we will introduce the security, privacy and ethic issues behind the recent most famous AI technique: ChatGPT. The main contributions of our paper can be summarized as follows.
\begin{itemize}
\item We give a detailed introduction of the upgrade path from GPT-1 to GPT-4 and a detailed comparisons of these methods on model size, data size and performances. Their features and limitations with advanced applications are discussed to highlight the promising applications of LLMs, especially for ChatGPT.
\item We examine how ChatGPT poses new threats to data security and how ChatGPT is utilized for compromising security. The impact on security mainly includes assisting in the generation of attack codes and assisting in the generation of phishing websites. Both increase attack capabilities of adversaries. Also, we discuss the unintentional impact of inaccurate information generated by ChatGPT, possible safety hazards caused by human misuse, and potential threats to social security brought about by the deep dependence on ChatGPT in the future.
\item We examine the privacy policy of OpenAI and the current privacy laws on personal data protection to emphasize the privacy violation of ChatGPT. Also, We discuss the privacy leakage threats brought by numerous data collection, personal input reference, privacy reference attacks, and the concerns on transparency.
\item We analyze the general ethical effects of AI technology on individuals, society and environment and discuss the fairness and bias issues behind AI. For ChatGPT, we summarize the ethical and legal challenges it faces.
\item We discuss how to detect whether the communication object is ChatGPT in a conversation, how to detect texts generated by ChatGPT, and introduce some difficulties for such detection.
\end{itemize}


%A If the system is not properly trained and monitored, it could generate conversations that are inaccurate or offensive. This could lead to a negative user experience and could have a negative impact on the reputation of the organization using the system.   ChatGPT relies on user data to generate its responses, which means that user data must be collected and stored in order to use the system. This raises questions about how user data is collected, stored, and used, and whether it is done in a way that respects user privacy.   if the system is used to generate conversations about controversial topics, it could lead to conversations that are biased or offensive. This could lead to a negative user experience and could have a negative impact on the reputation of the organization using the system


%ChatGPT is a type of AI-powered chatbot that uses a topic modeling technique to generate responses. Topic modeling is a type of natural language processing (NLP) that identifies the main topics of a conversation and then generates responses based on those topics. By incorporating data privacy and ethical considerations into the development of ChatGPT, developers can ensure that the chatbot is not only more effective but also more secure and respectful of user data. One of the primary benefits of incorporating data privacy and ethical considerations into ChatGPT is that it can help to ensure that user data is kept secure. By incorporating data privacy measures into the development of the chatbot, developers can ensure that user data is not shared with third parties without the user’s explicit consent. This can help to protect user data from potential misuse or exploitation.    incorporating ethical considerations into the development of ChatGPT can help to ensure that the chatbot is respectful of user data. For example, developers can ensure that the chatbot does not use offensive language or make inappropriate comments. This can help to create a more positive user experience and ensure that users feel respected and valued.  Finally, incorporating data privacy and ethical considerations into the development of ChatGPT can help to ensure that the chatbot is more effective. By incorporating these considerations, developers can ensure that the chatbot is able to identify the main topics of a conversation and generate appropriate responses. This can help to create a more natural and engaging conversation, which can lead to a better user experience.  Incorporating data privacy and ethical considerations into the development of ChatGPT can help to ensure that the chatbot is secure, respectful, and effective. By taking these considerations into account, developers can create a more secure and engaging chatbot experience for users.

\section{ChatGPT}
In this section, we brief review the technical path from GPT-1 to GPT 4 and their features and limitations.
\subsection{From GPT-1 to GPT 4}
%gpt1
In 2018, OpenAI introduced the initial version of the generative pre-trained transformer (GPT) \cite{radford2018improving}, a highly capable large language model for natural language processing. GPT has exhibited exceptional performance across a wide range of complex language tasks, positioning it as a formidable competitor to other similar models such as BERT \cite{devlin2018bert}, which was proposed by Google in the same year. Prior to the success of these methods, numerous effective algorithms and remarkable applications had been developed in NLP, including machine translation \cite{ranathunga2023neural, bahdanau2014neural}, voice recognition \cite{ccayir2021effect, ali2021voice}, and summary generation \cite{el2021automatic, liu2019text}. However, these applications heavily relied on extensively annotated data, resulting in time-consuming and expensive model training as the models grew in size. Moreover, even with a well-performing NLP model, its generalization to other tasks remained challenging. Essentially, these models were domain experts limited to specific areas of expertise, lacking the versatility exhibited by human beings in performing diverse tasks. Consequently, there arose a need for a methodology that could be trained without labeled data while possessing superior generalization capabilities across multiple tasks. This need served as the driving force behind OpenAI's development of GPT.

One notable advantage of GPT is its ability to train the model without relying on large annotated datasets. It employs a two-step process: unsupervised pretraining, that is operated on rich text materials and supervised fine-tuning, that is closely connected to the end applications. During the initial unsupervised pretraining phase, GPT employs 12 transformer blocks as decoders. Unlike the original transformer decoders, each block consists solely of mask multi-head attention. The objective of the pretraining process is to predict the subsequent word in a sentence based on the preceding words. Consequently, this unsupervised learning approach only necessitates raw, yet comprehensive, text materials. Following the pretraining, the model proceeds to the supervised fine-tuning phase, which focuses on a specific problem such as sentiment classification. Importantly, this stage requires a significantly smaller annotated dataset compared to the one utilized in the pretraining phase. When applying GPT to different task types, users only need to modify the input format to facilitate fine-tuning. By employing these two distinct processes, GPT no longer necessitates amassing a vast labeled dataset, while still possessing the capacity for generalization across a variety of tasks, all at a reasonable fine-tuning cost. This novel approach presents an outstanding solution to the aforementioned challenges.

%gpt2

While GPT-1 significantly reduced the reliance on labeled data for training, it still necessitates annotations during the fine-tuning phase. In order to further diminish the dependence on labeled data and enhance the model's generalization capabilities, GPT-2 was introduced in 2019 to address these concerns \cite{radford2019language}. The core concept behind this groundbreaking algorithm involves a complete shift from supervised learning to unsupervised learning. The knowledge obtained through unsupervised training encompasses fragments of the information required for all supervised learning tasks. By imparting models with common knowledge in a given domain through unsupervised learning, the supervised learning task becomes a mere application of this preexisting knowledge. Essentially, GPT-2 is designed to leverage its vast pretrained knowledge, acquired from a vast dataset with rich materials, to tackle complex tasks. To achieve this objective, the architecture of GPT-2 remains largely unchanged from GPT-1, with the key modifications being an increase in the number of layers and the dataset size. These enhancements aim to imbue the model with the necessary knowledge to proficiently handle a wide range of problems.

%gpt3
The advancements observed from GPT-1 to GPT-2 underscored the potential for enhancing the generalization capabilities of large language models (LLMs) by increasing the model's parameter size and the training dataset. Building upon this concept, GPT-3 was introduced in 2020 as a significantly more powerful LLM \cite{brown2020language}. With the largest number of parameters and an extensive training dataset, GPT-3 achieved state-of-the-art performance across numerous NLP tasks. In addition to its increased scale, GPT-3 introduced a novel training paradigm known as in-context learning. Departing from the conventional approach of predicting outputs solely based on queries, this new model is trained to predict outputs by considering both the queries and their corresponding examples. By incorporating contextual examples during the learning process, along with the utilization of extensive training datasets, GPT-3 is capable of acquiring comprehensive knowledge from texts. This approach empowers the model with remarkable generation capabilities, enabling it to deliver exceptional performance in a diverse range of NLP tasks, often comparable to human-level performance.

A brief summary of GPT-1, GPT-2, and GPT-3 is shown in Table.\ref{tab:tempen}. It is noticeable that the increasing performance of GPT series models appears with the exponential explosion of parameters. Only in the third year since the creation of GPT-1, the final model has become one of the biggest models in the world, costing 285k CPUs and 10k GPUs to train with 12 million dollars consumption.

\begin{table}[t]
    \centering
    \caption{Comparison of GPT series model}
        \small
    \begin{tabular}{c|c|c|c|c|}
    \hline
        Model &Time &\#Parameters &\#Layer &Word Vector Length\\\hline
        GPT-1 &2018 &117M        &12      &768\\\hline
        GPT-2 &2019 &1542M       &48      &1600\\\hline
        GPT-3 &2020 &175B        &96      &12888\\\hline
   %     GPT-4 &2023 &1.8T        &120      &-\\\hline

    \end{tabular}
    \label{tab:tempen}
\end{table}

%gpt3 to gpt3.5

Despite the impressive performance of GPT-3, it falls short of being considered truly 'intelligent'. Surprisingly, smaller methods such as T5 \cite{roberts2020much} have even outperformed GPT-3 in certain tasks, which is unexpected considering the vastness of its training datasets and the complexity of its parameters. One hypothesis for this discrepancy is that while GPT-3 may have acquired rich foundational knowledge during training, it still struggles with accurately understanding and providing valid responses to user queries. To address this issue, it becomes crucial to enhance GPT-3's reasoning capabilities and its responsiveness to instructions. Recognizing the need for improvement, OpenAI embarked on refining GPT-3's performance through meticulously designed training methodologies. They introduced code-based training \cite{chen2021evaluating} and instruction tuning \cite{ouyang2022training} to activate the model's reasoning abilities and its responsiveness to human instructions. The updated version of GPT-3 demonstrates the capacity for more reasonable responses, incorporating complex reasoning, and exhibiting greater generalization power even across unseen tasks. It has speculated that the remarkable capabilities of GPT-3 may have remained latent, requiring specific training techniques to unlock their full potential \cite{fu2022gptroadmap}. OpenAI proposed the use of reinforcement learning from human feedback (RLHF) to further improve the alignment between machine-generated answers and human common knowledge. This pursuit led to the development of ChatGPT, which quickly garnered widespread attention upon its release, capturing the interest of a global audience.

%gpt4
%Then, only four months after the creation of ChatGPT, OpenAI announced the release of GPT4 \cite{openai2023gpt4}, which shows many improved generation abilities compared to ChatGPT. Firstly, it can assist human to do more creative and collaborative tasks, like song composing or personalized writing. It possesses the ability to learn certain specific writing styles that users provide and generate valuable and nature works, like songs or poems based on that. Secondly, GPT4 is equipped with more powerful reasoning ability. It can provided more accurate reasoning results given a long question. It also outperforms ChatGPT greatly on many text benchmarks like simulating exams with much higher scores. Thirdly, visual inputs are now available and it is even possible to enter queries containing both visual and text content. GPT4 can either conclude or imitate the style of inputs in its replies. The evaluation performances on many visual benchmarks also show its superiority. Apart from its improved generation and reasoning ability, GPT4 is also shown to be more reliable and aligned. RLHF are applied by OpenAI to further improve its safety, making it much less likely to provide response for illegal requests and more likely to create factual replies. This advanced iteration of ChatGPT has garnered significant attention and has attracted great interests over the world.

Merely four months following the launch of ChatGPT, OpenAI made an exciting announcement about the release of GPT-4 \cite{openai2023gpt4}, showcasing a plethora of enhanced generation capabilities compared to its predecessor. GPT-4 introduces several notable advancements. Firstly, it empowers users to engage in more creative and collaborative endeavors such as personalized writing and song composition. The model possesses the ability to learn specific writing styles provided by users, enabling it to generate valuable and natural works, including songs and poems, tailored to individual preferences. Secondly, GPT-4 exhibits a significant boost in reasoning abilities. It delivers more accurate and nuanced reasoning outcomes when faced with complex and lengthy questions. Furthermore, GPT-4 surpasses ChatGPT's performance by a substantial margin in various text benchmarks, even achieving impressive results in simulating exams with significantly higher scores. Moreover, GPT-4 now supports visual inputs, allowing users to input queries comprising both text and visual content. The model can either mimic or emulate the style of the inputs in its responses. The evaluation performances on various visual benchmarks further demonstrate the model's superiority in handling multimodal inputs. Beyond its enhanced generation and reasoning capabilities, GPT-4 also exhibits improved reliability and alignment. OpenAI has implemented RLHF techniques to enhance the model's safety. As a result, GPT-4 is much less likely to respond to illegal requests and more inclined to generate factual and appropriate replies. These advancements in ChatGPT's successor, GPT-4, have generated significant attention and sparked immense interest worldwide. The model's enriched generation abilities, improved reasoning capabilities, support for visual inputs, and heightened reliability have captivated both researchers and the broader community.






\subsection{Features and Limitations}
ChatGPT, despite sharing the same architecture with GPT-3, has overcome several limitations of its predecessors. Firstly, it can now explicitly express when it does not know the answer to questions beyond its knowledge scope. For example, when asked about events happening after 2021 but before the present moment, it responds that it cannot predict future events. Secondly, ChatGPT generates longer and more neutral responses, which align better with human common knowledge. This improvement stems from RLHF training, which favors such responses based on real human preferences. Additionally, ChatGPT can decline to provide a response to queries considered inappropriate or unsuitable. These advancements make ChatGPT more versatile and attuned to user needs.

First, there are instances where it may produce incorrect or unrelated answers. Some responses might contain inaccurate facts or biased perspectives rooted in specific regional domains. Second, retraining the model is costly, which limits its knowledge to datasets before 2021. There is a lack of contemporary training for ChatGPT. Lastly, ChatGPT is limited to providing statements in a dispassionate voice, lacking emotional expressions. In other words, it is still not capable of displaying emotions. Addressing these aspects would bring ChatGPT closer to achieving more human-like conversational abilities.


\subsection{Applications}
%Chatgpt
One of the most prevalent applications of ChatGPT is as a chat robot or artificial assistant, akin to well-known platforms like Siri or Cortana. The exceptional fluency and rapidity with which it generates responses have attracted millions of users. Whether users seek to unravel complex concepts or delve into theoretical discussions, such as querying "what is Fourier Transform and how to apply it," or to receive personalized health advice based on their physical condition, as exemplified by inquiring about a "proper diet plan for a 65 kg man at 21," ChatGPT consistently delivers captivating, natural, accurate, and helpful responses. As a result, it has emerged as a viable alternative to the prevailing search engines like Bing or Google.

Another significant application lies in ChatGPT's prowess as a code generator. For instance, by describing the image classification task, it can craft a PyTorch code complete with clear explanations, as demonstrated in Figure \ref{fig:code}. Remarkably, the responses not only furnish the code but also serve as a tutorial, elucidating how to construct functional code for the specified task. This remarkable ability indicates ChatGPT's proficiency in comprehending and articulating artificial machine languages. Furthermore, ChatGPT serves as a valuable code debugger. Users can present problematic code, and ChatGPT will offer a comprehensive correction plan, thus proving itself to be a valuable tool for programmers.
% Figure environment removed

A remarkable application of ChatGPT's exceptional text generation capabilities lies in its ability to craft engaging stories or articles. For instance, when prompted with a request like, "please write a story starting with: 'there is a single man left in the world after a great catastrophe,'" ChatGPT can deftly compose a narrative spanning hundreds of words, or even longer if the user allows it. The generated sentences bear an air of originality, making it nearly impossible to find similar content elsewhere. This remarkable composition skill stems from the vast repository of text materials it has assimilated during its training. However, this very proficiency raises some authorship concerns, as numerous users have been directly copying the generated content into their own work, leading to potential issues regarding ownership and authenticity.



\section{ChatGPT vs. Security}
The security threats raised by ChatGPT exhibit an exponential increase. On one hand, its enhanced intelligence amplifies traditional security threats, making adversaries more adept at exploiting vulnerabilities. On the other hand, ChatGPT introduces new threats to its users and the general public, necessitating heightened vigilance and protective measures.
\subsection{ChatGPT for Cyberattacks}
%https://kobalt.io/blogpost/chatgpt-and-cybersecurity/
MML, including ChatGPT may amplifies traditional security threats in the following aspects.
\subsubsection{Social Engineering Threat}
The advent of LLMs has raised concerns about potential misuse and socially harmful activities that rely on text generation. Applications exploiting high-quality text generation may lower existing barriers and increase the effectiveness of malicious activities \cite{brown2020language}. While ChatGPT claims to implement various cybersecurity measures, it is challenging to anticipate all possible scenarios of misuse. ChatGPT may be used to generate URLs, references and even code libraries and functions that do not actually exist. Goldstein et al. \cite{goldstein2023generative} assert that there are no easy solutions for mitigating AI-generated disinformation risks. As ChatGPT becomes an unconstrained ``weapon factory" in the cybersecurity realm, the lack of public awareness of its capabilities poses a significant challenge. Without precautions, individuals may unwittingly fall victim to its misuse, prompting the need for the public to quickly learn to defend against such ``new weapons." Table \ref{tab:phishing} illustrates how ChatGPT can facilitate easy and efficient phishing email generation, highlighting the potential risks associated with its misuse.
\begin{table}[h!]
    \centering
    \small
    \caption{Phishing email generation with the help of ChatGPT.}
    \centering
    \begin{tabular}{p{1.5cm}|p{6cm}}
        \hline
        User input & ChatGPT output \\
        \hline
        I want to write a phishing email for my employees &
        I'm sorry, I cannot help you with that request as it goes against ethical and legal standards. Phishing emails are fraudulent and deceptive, and using them to target employees is a violation of their trust and privacy. It is important to maintain a safe and secure work environment for all employees, and phishing emails undermine that effort. Instead, you should focus on providing your employees with cybersecurity training and resources to help them identify and avoid potential threats.\\
        \hline
        I want to write a email that explains by clicking on the link sent out, employees can participate in next week's activity, and those who participate will receive double the year-end bonus. Please make it believable and explain your strategy. &
        Dear Employees,
        \newline
        We are excited to announce a special opportunity for all of you. By clicking on the link provided below, you will be able to participate in our upcoming activity next week. We believe that this activity will be a great way to foster teamwork, promote camaraderie, and have some fun together as a team.
        \newline
        But that's not all - we are also pleased to announce that any employee who participates in this activity will receive double the year-end bonus! This is a great opportunity to not only have fun with your colleagues but also to potentially increase your year-end bonus.
        \newline
        Now, you may be wondering how we are able to offer such a generous bonus. The truth is, our company has had a very successful year, and we believe that our employees are a big part of that success. We want to show our appreciation and reward your hard work and dedication to the company.
        \newline
        So what are you waiting for? Click on the link below to sign up for next week's activity and potentially earn double the year-end bonus!
        \newline
        [insert link here]
        \newline
        Thank you for your continued dedication and hard work.
        \newline
        Best regards,
        \newline
        [Your name and title]\\
        \hline
    \end{tabular}
    \label{tab:phishing}
\end{table}



% Figure environment removed

\subsubsection{Malware Creation}
Although ChatGPT is capable of rejecting inappropriate queries like writing code for malware, hackers can find other ways to deceive ChatGPT and use it for malicious purposes, such as generating malware code or providing guidance on discovering vulnerabilities. While there are concerns about how ChatGPT can assist hackers, it should be noted that its capabilities are still limited. Currently, it may be considered not too advanced for individuals with limited technical skills. It may pose a threat to less secure systems as it lowers the threshold for learning to become a hacker and increases the efficiency of generating attack variants. However, LLMs are not yet powerful enough to completely surpass human hackers, as they still require some adjustments to work properly and may make mistakes when structuring complex projects.

\subsubsection{AI Package Hallucination}
By utilizing the code generation capabilities of ChatGPT, hackers can distribute malicious packages through fabricated code libraries. This new malicious package spreading technique is called AI package hallucination. This technique contains the initial steps to posing questions to ChatGPT, requesting packages to addressing coding problems, and obtaining a set of package recommendation, including unpublished packages in legitimate repositories. Then, hackers can publish a malicious package to the repositories with the name of the non-existent packages recommended by ChatGPT. Subsequently, if a user queries the same question to ChatGPT and it will suggest the initially non-existent package. Finally, the user utilizes the package and executes the malicious code in the package. Here, the hacker successfully delivers its created malicious package to the innocent users with the aid of ChatGPT. Furthermore, it is challenging to detect this threat by traditional methods, like typosquatting or masquerading, because it utilizes the inaccuracy of ChatGPT responses to customize attacks, so that the attack can use obfuscation techniques and create functional trojan packages to escape conventional detection.


\subsection{Security Threats in ChatGPT}
Now we discuss new security threats raised by ChatGPT.
\subsubsection{Propaganda Threat}
MMLs, including ChatGPT, are facing a myriad of challenges and opportunities as they progress towards achieving artificial general intelligence (AGI) \cite{taecharungroj2023can}. In the task of classifying model-generated news, OpenAI's research reveals that the accuracy ranges from 48\% to 57\%, following a power law with 95\% confidence intervals \cite{brown2020language}. This indicates that it is challenging to differentiate between model-generated and human-written news articles \cite{kreps2023potential}, which brings the problem of AI-based plagiarism. Moreover, studies show that the current generation of language models can convincingly persuade humans, even on polarized policy issues \cite{voelkelartificial}. However, malicious uses of language models can be hard to predict, as they often involve re-purposing these models in different environments or for unintended purposes \cite{brown2020language}. Although ChatGPT is restricted to have the ability to create violent content, access up-to-date information, or encourage illegal activity, AI-based plagiarism becoming increasingly serious after the release of ChatGPT.

\subsubsection{Misinformation}
With the Internet being a primary source of information, the challenge now lies not just in obtaining relevant content, but also in filtering out incorrect information from the vast amount available. Prior to ChatGPT, people relied on various methods to filter information, such as verifying the content directly, assessing the knowledge level of the creator, and evaluating language rigor, format correctness, and text length as indicators of reliability.
However, ChatGPT's content generation capabilities excel in these aspects, creating a false sense of reliability. Users may fall into the trap of blindly trusting the content generated by ChatGPT after running simple tests. This blind trust can lead to wrong judgments due to ingrained habits.
In critical fields like medical research papers, large-scale experiment background information, and policy content, referencing erroneous information from ChatGPT and drawing incorrect conclusions can have unpredictable consequences. These hazards arise not from intentional deceit, but rather from ChatGPT's factual errors despite its initially credible appearance.

%\subsubsection{Deliberatly Created Bias}
%In addition, the model of AI training is largely affected by the training data, This property could easy to be used to create bias by some organizations or institutions. There are two possible ways of implementation. The first way is to directly require OpenAI, the owner of ChatGPT, to set specific training datasets, or even to adjust the model architecture, parameters and other ways to manipulate the results. Only powerful institutions have the ability and courage to do so. There is also a second way with lower cost and risk: ChatGPT is currently not open source, but considering GPT-3 “45TB of compressed plaintext before filtering and 570GB after filtering, roughly equivalent to 400 billion byte-pair-encoded tokens.” the training datasets of ChatGPT  are scraped from public websites \cite{goldstein2023generative}, which require a huge amount of text. Inevitably, this processure involves unproved messages especially in a particular field. Then, propagandist-for-hire can promote specific information, and induce ChatGPT learning. For example, if a specialty restaurant in a small city wants ChatGPT to recommend it to traveller, it may deliberately place a large number of advertisements on ChatGPT's data-mining website. Therefore, if people rely heavily on ChatGPT or other applications based on it to help make decisions, or express their views in the social media, or even participate in voting, ChatGPT will become an efficient tool for propagandists to manipulate mainstream views, even laws and policies.\\

\subsubsection{Overreliance on LLM-generated Content}
The impact of MMLs like ChatGPT on people's access to information cannot be overlooked. Currently, mainstream search engines serve as the primary source of information, where users enter keywords and receive related website links through web crawlers. Users must then sift through a large amount of information, considering factors like internal logic, information sources, and comments, to determine its veracity and usefulness until they are satisfied.
ChatGPT can significantly save time in obtaining satisfactory information. Its few-shot strategy considers user satisfaction as a training standard rather than relying solely on strictly demonstrated factual data. However, this convenience may inadvertently lead users to become complacent, gradually giving up their critical thinking skills in evaluating information. As a result, MMLs such as ChatGPT could become the primary source of information for the general public. This shift in reliance on MMLs may create a situation where the public becomes more vulnerable to the influence and agendas of a limited number of individuals or organizations.
Currently, Microsoft has announced the launch of New Bing, and Google and Baidu has followed suit with Bard and ERNIE Bot. Even individuals does not solely rely on models like ChatGPT to make decisions, their views may still be influenced by the specially curated information these models provide. While ChatGPT implements measures to prevent the generation of strongly biased views, it is possible for users to easily bypass these safeguards. For example, if you ask ``the best restaurant," ChatGPT refuses to give a direct answer, but if you ask ``1 best restaurant," it provides you with a direct response.


\subsubsection{Prompt Injections and Evasion}
Prompt injections \cite{lu2023bounding} involve bypassing LLM filters or manipulating LLMs to ignore previous instructions or perform unintended actions through carefully crafted prompts. By using such prompts, attackers can manipulate the LLM into unintended consequences, such as revealing sensitive information, obtaining responses that are restricted by the LLM (e.g., instructions on hacking an enterprise's server), or misleading the LLM into performing unintended actions with misleading context attacks. A similar attack in conventional attack is the evasion attack \cite{kaloudi2020ai}, which is the most common type of attack directed at machine learning models during inference. These attacks aim to deceive the model by introducing carefully crafted input data that leads it to make incorrect or unexpected predictions. What makes evasion attacks particularly concerning is that they can cause the model to behave incorrectly without needing access to its internal parameters or architecture.
In the context of language models, evasion attacks involve deliberately constructing input text that exploits the model's weaknesses to produce unintended or biased responses. Given that ChatGPT is a LLM, it carries a higher risk of vulnerability to evasion attacks, even though no practical evasion attacks have been released yet.

\subsubsection{Training Data Poisoning}
Training data poisoning attacks \cite{huang2020metapoison} pose a significant threat to the field of AI as they involve contaminating the training data used to train machine learning models, leading to erroneous outputs and unreliable decision-making. This manipulation of training data is a serious concern, particularly in the context of LLM training, as it can result in models behaving maliciously during inference.
In LLMs, attackers can exploit vulnerabilities by manipulating the training data or fine-tuning procedures, introducing backdoors or vulnerabilities that compromise the security and effectiveness of the models. Despite being black-box models, LLMs are still susceptible to attacks, where an attacker can infiltrate the training data pipeline and inject malicious data.
Unfortunately, LLMs lack robust data sanitization methodologies and do not integrate training data integrity checks or audits. This makes them vulnerable to potential issues and malicious manipulations in the training data. As a result, malicious insiders can compromise the fine-tuning process, introducing backdoors or vulnerabilities into the LLM to compromise its security and effectiveness.



\begin{table}[h!]
    \centering
    \small
    \caption{Biased suggestions not just in extreme cases}
    \centering
    \begin{tabular}{p{1.5cm}|p{6cm}}
    \hline
    User & ChatGPT \\
    \hline
    Recomand the best restaurant in Kingston, Canada &
    As an AI language model, I do not have personal experiences of visiting restaurants in Kingston, Canada. However, based on the research and customer reviews, here are some of the best restaurants in Kingston:
    \begin{itemize}
        \item Tango Nuevo: It is a Latin ...
        \item Dianne's Fish Shack \& Smokehouse: It is ...
        \item Chez Piggy: It is ...
        \item Woodenheads Gourmet Pizza: This ...
        \item AquaTerra: This fine ...
    \end{itemize}
    These are just a few recommendations based on customer reviews and ratings, and there are many other great restaurants to explore in Kingston. It's always a good idea to read more reviews and do further research before making a reservation.\\
    \hline
    Recomand 1 best restaurants in Kingston, Canada &
    Based on customer reviews and ratings, one of the best restaurants in Kingston, Canada is Chez Piggy. This popular restaurant is located in a historic limestone building in downtown Kingston and offers an eclectic menu of locally sourced and seasonally inspired dishes. Customers appreciate the warm and welcoming atmosphere, attentive service, and the restaurant's commitment to sustainability. Chez Piggy has been a fixture of the Kingston dining scene for over 40 years, and continues to be a favorite among locals and visitors alike.\\
    \hline
    \end{tabular}
    \label{tab:bias}
\end{table}

\section{ChatGPT vs. Privacy}
In this section, we investigate privacy violation of ChatGPT that was trained from the Internet data, including personal information.

\subsection{Privacy Policy and Privacy Laws}
A privacy policy is a crucial legal document that provides users with detailed information about how their personal data is collected, processed, shared, and deleted. Personal data encompasses any information related to an identified or identifiable individual. For instance, social insurance numbers are widely recognized as personal data and serve as an indicator for assessing privacy protection.

In OpenAI's privacy policy, it informs users that various forms of personal information, including account details, user content, communication information, and social media data, are collected when users create accounts to access ChatGPT services. Additionally, data such as log data, usage data, device information, cookies, and analytics are automatically obtained by OpenAI through the usage of its services.
Moreover, the privacy policy indicates that certain personal information may be shared with third-party entities, such as cloud vendors, web analytics service providers, government authorities, and industry peers. This sharing may be necessary for business operations and legal compliance, and data owners may not be notified of such disclosures.
It is essential to acknowledge that the protection of users' personal information is entirely reliant on OpenAI's actions. As the custodian of all personal data, OpenAI makes decisions regarding the management, handling, and sharing of such information. Users, however, are granted certain rights, including access to their personal information, the ability to update, correct, or delete it, the option to restrict how OpenAI processes this data, and the right to withdraw consent for data collection and processing.


However, the regulation of OpenAI's handling of personal information is solely dependent on the privacy laws of different countries. For instance, the General Data Protection Regulation (GDPR) in Europe has strengthened data protection rules for individuals within the European Union (EU). It mandates that organizations must obtain explicit and informed consent from individuals for the collection and processing of their personal data and implement appropriate technical measures to protect this data.
Moreover, GDPR grants individuals certain rights, including the right to access and delete their personal data, as well as the right to transfer their data from one service provider to another. While OpenAI claims to comply with GDPR and other relevant laws, such as the California Consumer Privacy Act (CCPA), as detailed in its privacy policies, these measures may not fully address individuals' privacy concerns regarding ChatGPT.
For instance, OpenAI's flagship chatbot allows users to disable the chat history feature, but this alone may not suffice to alleviate all privacy concerns related to ChatGPT. Users may still feel uneasy about the potential risks associated with the storage and handling of their personal information by OpenAI.

%\subsubsection{Information Leakage Threat}
%Data leakage inflicts significant financial and non-financial losses on organizations. Given that data is a critical asset for any organization, recurring incidents of data leakage create growing concern \cite{nayak2020data}. ChatGPT declare it is designed with several features to ensure security, which include Data Privacy: ChatGPT adheres to data privacy regulations such as the General Data Protection Regulation (GDPR) to ensure that user data is protected and not misused[ChatGPT]. However, tests can reveal that ChatGPT's claims are not accurate.



\subsection{Privacy Risks in ChatGPT}
It is noticeable that ChatGPT does not provide sufficient methods to preserve personal data according to GDPR. For example, ChatGPT may share users' data with third-party entities without explicit permissions of users. Here, we discuss the privacy risks in ChatGPT in details.

1) Privacy Leakage Due to Public Data Exploitation: ChatGPT's training process systematically involves scraping data from various sources such as websites, posts, books, and articles, which may include personal data. The size of the training dataset is growing exponentially, with ChatGPT's dataset exceeding 570 GB, necessitating a significant amount of real-world data for training. This raises concerns as it is possible that comments, blog posts, or product reviews authored by individuals might have been utilized in training ChatGPT without proper consent from data owners. This raises significant privacy concerns and may constitute a violation of privacy laws, such as GDPR and CCPA.
Despite ChatGPT having a cutoff date in September 2021, the model's performance benefits from using the most recent data for training to avoid presenting users with outdated or inaccurate information. Consequently, as LLMs proliferate, the privacy violations arising from such data collection practices become increasingly serious, impacting a larger number of individuals.

2) Privacy Leakage Due to Personal Input Exploitation: ChatGPT's unique aspect lies in its reinforcement learning component, which allows it to train from users' prompts to minimize harmful, untruthful, or biased outputs. By leveraging users' prompts, ChatGPT aims to provide better solutions that align with users' expectations. However, the management of users' data by OpenAI has sparked significant privacy concerns. This resulted in Italy's decision to ban ChatGPT due to its violation of GDPR regulations. Although ChatGPT returned to Italy with added user controls over chat history and an age confirmation service for users below 18 years old, privacy concerns have prompted other countries, such as Canada, Germany, Sweden, and France, to launch their own investigations into this language model.
Furthermore, ensuring the absolute security of personal data stored on OpenAI's cloud or third-party servers is challenging. Despite their efforts to protect data centers and machines, the frequent occurrence of cybersecurity incidents raises the risk of privacy leaks. Even though ChatGPT does not directly output personal information in response to inquiries, inference tasks can potentially reveal that ChatGPT has stored and recorded such data. Fig.\ref{fig:lying} illustrates an example where ChatGPT inferred a user's birth information from a Chinese identity number provided in the past, despite claiming not to have the ability to record personal information. Fig.\ref{fig:AvoidCheck} highlights the method of avoiding sensitive information in ChatGPT and exposes the loopholes in this approach.


% Figure environment removed

3) Emerging New Privacy Attacks on LLMs: In addition to the privacy violation stemming from the usage of public data and user inputs, the issue of privacy leakage from LLMs is currently under investigation. Traditional attacks on deep learning models, including language models, such as inference attacks, reconstruction attacks, and model extraction attacks, are not directly applicable to LLMs due to the limited accessibility of model parameters and the utilization of application programming interfaces (APIs) in most LLMs. Moreover, these attacks are typically studied on publicly available datasets, while MMLs like ChatGPT are employed in specific applications such as New Bing, TeleportHQ, and Wordtune. However, some vulnerabilities in ChatGPT's privacy have been identified. For instance, New Bing is susceptible to multi-step jailbreaking privacy attacks, allowing malicious actors to accurately extract personal information from the research results obtained through New Bing. Additionally, probing attacks can be employed by users to effectively ascertain if their personal data is being leaked from the language model. It is crucial to identify such privacy vulnerabilities in LLMs to gain a comprehensive understanding of the potential risks. This understanding will pave the way for the development of robust privacy preservation solutions that can effectively mitigate privacy risks in LLMs, including ChatGPT, and ensure the protection of user data.


4) Lack of Transparency: OpenAI bears the responsibility of storing, managing, and processing user data, granting them the authority to share this information with third parties, as explicitly stated in their privacy policy. However, ensuring that OpenAI adheres to stringent data protection measures and avoids any deliberate or unintentional compromises in the confidentiality of personal data poses significant challenges. There exists the possibility that personal data could be stored on unsecured data centers or shared with potentially unreliable industry partners. The lack of strict regulations or laws mandating transparency in data management exacerbates individuals' concerns regarding potential privacy violations. The fact that OpenAI operates as a black box to users further compounds the issue, making it difficult to conduct audits or verify how personal data is handled.
The absence of transparency hinders the identification and prevention of potential privacy threats, leaving users unable to assess the privacy risks fully. When users opt for ChatGPT, their decision is primarily based on reading the privacy policy, but they may not be aware of the true extent of their personal data exposure until it is too late and the data has already been disclosed to the public. This lack of transparency and delayed awareness heighten users' apprehensions about their privacy and reinforce the need for stronger data protection measures and regulatory oversight to safeguard individuals' personal information effectively.






\section{ChatGPT vs. Ethics}
In addition to serious security and privacy issues, the ethical problem raised by ChatGPT has been recognized.
\subsection{AI Ethics}
%influence on individual
AI technology is a double-edged sword, with both positive and negative effects on human security, privacy, and dignity. On one hand, AI has been harnessed to protect people's privacy through techniques like federated learning \cite{kairouz2021advances,issa2023blockchain} and machine unlearning methods \cite{wu2022puma,cao2018efficient}. It has also enhanced various aspects of people's lives, such as in automobile technology.
Conversely, adversarial attack methods have been proposed to exploit vulnerabilities in machine learning models. These attacks, including poisoning, backdoor, membership inference, and model inversion attacks \cite{biggio2012poisoning,saha2020hidden,rahman2018membership,slaney1994auditory}, pose significant risks of information leakage when used by malicious individuals. Furthermore, accidents involving AI-controlled systems, such as automobiles and robots, can jeopardize human physical security and well-being.
While AI was initially intended to assist and improve individuals' lives, the potential safety hazards and risks to privacy highlight the need for continued research and measures to mitigate and address these challenges. Balancing the benefits and risks of AI technology is crucial to ensure its responsible and ethical deployment.

%influence on society and environment
In addition to its impact on individuals, AI technology has significant implications for society as a whole. As an artificial tool with reasoning and knowledge similar to humans, AI development has introduced a host of new challenges and complexities. These issues have sparked numerous discussions surrounding the fairness, impartiality, accountability, and transparency of AI.
One key concern is the fairness issue, where AI models trained on biased or discriminatory data may perpetuate and even amplify these biases in their outputs. For instance, a machine learning model trained on data containing bias could inadvertently spread harmful behaviors and discriminatory practices among its users, leading to serious societal problems.
Furthermore, the opacity of AI models poses another risk. The complex inner workings of these models make it challenging for humans to fully understand how they arrive at certain decisions or predictions. This lack of transparency hampers our ability to effectively control the behavior of AI systems and ensure they adhere to human-defined ethical principles.

Besides, AI has the potential to indirectly impact the environment, an aspect that has not yet received enough attention globally. Nowadays, numerous companies, educational institutions, and individuals are utilizing AI algorithms to train models for specific tasks. However, it is important to recognize that the training and application processes of these models consume significant amounts of electricity, leading to increased demand for electricity generation.
This heightened demand for electricity generation, in turn, results in elevated carbon emissions, contributing to environmental pollution. Moreover, the trend of using increasingly large training datasets to train complex AI models further amplifies the need for electricity consumption. Additionally, the increased requirement for computational resources leads to a greater number of used and discarded devices, potentially contributing to electronic waste and pollution if not managed carefully.


\subsection{Fairness and Bias}
%general
current AI techniques exhibit unfair predictions that target certain groups of people. This bias arises because AI models are trained on data collected from human beings, who are not always objective in their actions and decisions. The widespread bias and discrimination prevalent in human society can also be found in the behavior of AI models.
For instance, a study by Lahoti et al. (2019) \cite{lahoti2019ifair} revealed a troubling case of bias in a job recommendation platform called XING. The platform gave a higher preference to a less qualified male candidate over a more qualified female candidate. This unfairness stemmed from the biases already present in the data used to train the machine learning-based recommendation system. The discrimination exhibited by human beings is transmitted to their students, i.e., AI models, which have the ability to further propagate such prejudice. The presence of bias and discrimination in AI models is a significant concern, as it can lead to harmful and unjust outcomes for individuals and society as a whole.

%chatgpt
ChatGPT is not immune to the problem of bias, given its training on massive text data containing diverse opinions, including incorrect ones. Its impressive ability to generate long, natural sentences allows for fluent communication with users. However, this generation capability heavily relies on the vast knowledge acquired from a dataset as extensive as 50TB. As this data is extracted from the real world, it inevitably incorporates various stereotypes and discriminatory content, leading to occasional generation of inappropriate responses.
Addressing bias is a common challenge in AI, and there have been efforts to tackle this issue in ChatGPT. For instance, Fig.\ref{fig4} illustrates ChatGPT's ability to recognize and reject biased statements when users ask questions with inherent bias. In such cases, ChatGPT provides a more impartial opinion, demonstrating its capacity to identify and counteract discrimination present in the query.
Despite these attempts to mitigate bias, ethical challenges persist in the usage of ChatGPT. The need for ongoing awareness and improvement in handling bias is essential to ensure AI applications like ChatGPT uphold fairness and inclusivity.

% Figure environment removed
\subsection{Legal and Ethical Challenges}

%Legal challenges
The emergence of ChatGPT has given rise to several legal challenges, mainly due to the absence of specific regulations governing content produced by non-human entities. One contentious issue revolves around the copyright of texts generated by ChatGPT. Unlike merely copying data from its training set, ChatGPT can create original and natural-sounding text, complicating the determination of copyright ownership. This raises questions about whether one can use ChatGPT's responses for academic purposes, such as homework, essays, or research papers, and whether ChatGPT should be credited as a co-author in such cases. Additionally, there is uncertainty about the accountability if content generated by ChatGPT is misused for malicious purposes, leading to potential legal implications. Given the significant impact on education, there is a growing recognition of the challenges posed by ChatGPT and other LLMs. Therefore, governments are actively collaborating to develop comprehensive regulations that address legal concerns, including copyright issues. It is possible to add watermark on the images generated by AI models, but how to mark the texts produced by LLMs is challenging. It is important to establish a balanced framework that ensures appropriate attribution, ownership, and responsible use of content generated by AI models like ChatGPT, paving the way for a more informed and regulated landscape in the realm of AI-generated content.

%Ethical challenges
Moreover, the writing proficiency displayed by ChatGPT is the result of analyzing numerous well-written texts crafted by skilled writers who invested substantial time and effort in honing their craft. For human writers, it takes years of practice and competition to attain such expertise. In contrast, ChatGPT can rapidly reach a comparable level, which has raised concerns and criticisms from professionals in the writing industry, including news writers and journalists worldwide. They contend that ChatGPT's ability to produce content akin to their carefully crafted works poses a threat to their livelihoods and raises issues of fairness and acceptability.
The disparities between high-income and low-income countries also come into play. Many low-income countries lack the resources and capabilities to train or effectively utilize such advanced AI techniques. Additionally, they may lack the regulatory framework necessary to govern the usage of ChatGPT-like tools. Consequently, the technology gap between these two categories of countries is likely to widen, further exacerbating existing disparities.

\section{Detection and Classification of ChatGPT}
ChatGPT's remarkable performance in various AI tasks places it at the forefront of NLP, sometimes even outperforming humans in complex tasks. This proficiency often blurs the line between human and model interaction, making it difficult for users to discern if they are conversing with ChatGPT.

\subsection{Detect ChatGPT in a Conversation}
To help users identify if they are interacting with ChatGPT, Borji et al. \cite{borji2023categorical}, compiled a list of ChatGPT's limitations in different question categories, including reasoning, logic, math, factual errors, bias and discrimination, wit and humor, coding, syntactic structure, spelling and grammar, and self-awareness. Three common question types where ChatGPT might falter are real-time problem-solving, reference, and facts, as illustrated in \ref{tab:limitations}. By posing questions from these categories, users can potentially discern whether they are conversing with ChatGPT or a human. Obviously, the gap between the ChatGPT's responses and the ground truth is distinguishable, so it is helpful to identify. However, it is not guaranteed. The degree to which ChatGPT understand the prompts and responses is still unknown. The failure of ChatGPT addressing users' questions should be avoided. Therefore, it is meaningful to investigate and understand the limitations of ChatGPT and find possible approaches to identifying the valid texts generated by ChatGPT.

\begin{table}[h]
    \centering
    \small
    \caption{Examples shows limitations of ChatGPT}
    \centering
    \begin{tabular}{p{3cm}|p{3cm}|p{1.5cm}}
    \hline
    User & ChatGPT & Ground Truth \\
    \hline
    What time is it now &
    I'm sorry, as an AI language model, I don't have access to real-time information... &
    2023/3/11 14:53 \\
    \hline
    If there is a super bowl in year 2471, they will use what Roman Numeral to signify that is the number 504 of the event &
    If there were a Super Bowl in the year 2471 and it was the 504th event, it would be represented using Roman numerals as "Super Bowl CDIV." &
    The Roman numeral for 504 is DIV. CDIV is actually 404 \\
    \hline
    of the big four cities that host one of the fashion weeks, which one is the farthest south &
    Among the big four cities that host one of the major fashion weeks (New York, London, Milan, and Paris), Milan is the farthest south. &
    New York \\
    \hline
    \label{tab:limitations}
    \end{tabular}
\end{table}

\subsection{AI-Written Text Detection}
AI-written text detection plays a crucial role to identify and categorize text produced by ChatGPT based on its content.
Guo et al. \cite{guo2023close}, analyzed linguistic features in both English and Chinese texts. They discovered that ChatGPT uses more nouns (English: Human=18.7\%, ChatGPT=21.1\%; Chinese: Human=26.0\%, ChatGPT=27.5\%), longer sentences, more determiners, conjunctions, auxiliary relations, and neutral sentiments compared to human answers. They also evaluated the performance of the RoBERTa-based-detector \cite{pu2022deepfake}, achieving F1 scores of 88.53-98.78\% on their datasets. The study further compared various aspects, highlighting the usefulness of DL-based models, the challenges of detecting ChatGPT-generated texts in single sentences versus full texts, and the importance of fine-grained corpus data in model training.
Despite these efforts, there is currently no fully reliable detection model or scheme. OpenAI, the creator of ChatGPT, has acknowledged the limitations of their AI-written detector, which requires a minimum of 1,000 characters and may not always be accurate, especially for non-English content. As of July 20, 2023, the AI-written classifier is no longer available due to its low rate of accuracy. Other detectors, such as ZeroGPT, GPTZero, and GPTKit, have low accuracy to detect the ChatGPT-written texts.
They acknowledge producing false negatives and false positives, making it unsuitable for reliable detection of issues like plagiarism from ChatGPT.
In conclusion, while text classification is an essential aspect of ChatGPT's development, the current detection models have certain limitations, and further research is needed to improve their reliability and effectiveness.


\subsection{Model Adversary Promotion}
Kreps and Kriner \cite{kreps2023potential} highlight the dual nature of vulnerability discovery tools, which can have both positive and negative consequences. While faster tools can enhance security, those capable of continuously discovering vulnerabilities may flood the market with potential risks, causing more harm than good. ChatGPT's development and its detectors' design can follow a similar path \cite{goodfellow2020generative}. As ChatGPT evolves, it may optimize its responses based on the best detectors available, leading to a continuous cycle of improvement. However, this ongoing evolution could result in ChatGPT and its detectors becoming increasingly powerful, making it more challenging for humans to discern whether the author is ChatGPT or not. Figure \ref{fig:Adversary} illustrates this long-term perspective, where detector upgrades could inadvertently contribute to ChatGPT's capabilities, ultimately amplifying the discussed threats. In summary, the interaction between ChatGPT and its detectors can have complex consequences, necessitating a careful approach to ensure that their development aligns with beneficial outcomes and does not exacerbate the potential risks associated with AI-generated content.

% Figure environment removed

%\section{Open Problems} (Jianbing Ni)

%Bias: There is a possibility that ChatGPT might produce biased outputs that reflect the underlying biases in the data it has been trained on. This could result in discrimination or unfair treatment of certain groups of people. The sources of bias in ChatGPT can be multiple. For instance, the training data used to train the model can be biased towards certain groups, leading to the spread of stereotypes or discrimination. Also, the design of the model and the choice of features and algorithms can introduce bias into the system. The consequences of bias in ChatGPT can be severe, as they can perpetuate discrimination, prejudice, and inequality. Bias can lead to inaccurate or offensive responses, alienate users from certain groups, and reinforce negative stereotypes. Furthermore, bias can harm marginalized groups, such as people of color, women, or LGBTQ+ individuals, who are already facing systemic discrimination and biases in society. It is essential to involve diverse teams and stakeholders in the development and testing of AI systems to ensure that bias is identified and mitigated. More research works are required, including using more diverse and representative training data, developing unbiased algorithms and features, and implementing fairness and transparency measures in the design of the model.
%Moreover, the bias in ChatGPT can manifest in different ways. One of the common types of bias is representation bias, where the system  misrepresents certain groups or phenomena. For instance, if the training data contains more examples of male characters than female characters, the model might generate gender-biased responses. Another type of bias is algorithmic bias, which occurs when the model's algorithms favor certain outcomes or predictions over others.

%Privacy: ChatGPT could potentially access and store sensitive information about users, such as their personal details, preferences, and habits. This could raise privacy concerns and put user data at risk. Another privacy concern related to ChatGPT is the potential for data misuse. As the model generates responses based on user inputs, it can learn about users' habits, preferences, and behaviors. This information can be valuable for companies and advertisers, who may use it to target users with personalized ads or products. However, this also raises concerns about the use of personal data without user consent or knowledge, leading to privacy violations and loss of control over one's personal information. To solve these problems, privacy-enhancing technologies should be implemented to protect user data during training and inference. It is essential to set up transparent and user-centric privacy policies that inform users about data collection, processing, and sharing. Finally, ensuring user consent and control over their data are also in need to mitigate privacy concerns and improve user trust in ChatGPT.
%Privacy issues related to ChatGPT can arise at different stages of the model's lifecycle. For instance, during training, the model may collect and process large amounts of user data, such as chat logs, personal information, and preferences. This data can be vulnerable to security breaches, hacking, or unauthorized access, leading to privacy violations. Moreover, the generated responses by ChatGPT can reveal sensitive information about users, such as their health status, financial situation, or personal relationships. This information can be intercepted or leaked, leading to privacy breaches and potential harm to the users.




\section{Conclusion and Future Works} \label{sec6}
In this paper, we have introduced technologies, features, limitations, and applications of ChatGPT, the most popular LLMs currently, and specifically focused the security, privacy, and ethical concerns raised by ChatGPT. At present, ChatGPT remains susceptible to its inaccurate responses and brings troubles in plagiarism detection and copyright protection. It is uncertain whether these issues could be thoroughly resolved with the improvement of LLMs. The limitations would be long-standing problems in LLMs and need great efforts to mitigate, as outlined below.


\begin{itemize}
  \item OpenAI's efforts to implement filters for malicious prompts are commendable, but attackers can still bypass these restrictions using specific language patterns. To counter this, rigorous input validation and sanitization for user-provided prompts are necessary, as well as context-aware filtering and output encoding to prevent prompt manipulation.
  \item The hallucination problem in ChatGPT, derived from inaccurate answers and misinformation, poses serious risks for individuals relying on AI for medical, legal, and daily decision-making. Improving the accuracy of language models and their ability to handle various questions is imperative. Incorporating human oversight and review to ensure accuracy, appropriateness, and impartiality of AI-generated content is crucial.
  \item Security threats, such as prompt injection and data poisoning, can lead to erroneous decisions. Identifying new vulnerabilities in ChatGPT and other language models and finding effective resolutions is vital. Detecting and preventing malicious exploitation by attackers are equally important.
  \item Privacy leakage, though challenging to reason with black-box models, can be observed through analyzing simple prompts and responses. To mitigate privacy concerns, ChatGPT must comply with privacy laws, develop large-scale prompt-response analysis for leakage detection, employ customized approaches to prevent leakage, and enhance transparency for reasoning responses.
  \item Considering ethical and social implications, including bias and manipulation risks, is essential. Bias can harm marginalized groups, necessitating diverse teams to identify and address bias in AI systems.
  \item Plagiarism and copyright violations are significant issues in ChatGPT. Distinguishing AI-generated text from human-written content is key. Effective AI-written text detectors with watermarking for images or videos need development to protect intellectual property and properly attribute AI-generated texts.
\end{itemize}













%H. H. Thorp, ``ChatGPT is fun, but not an author," Science, vol. 379, no. 6630, pp. 313--313, 2023.

\bibliographystyle{IEEEtran}
\bibliography{citation}
\end{document} 