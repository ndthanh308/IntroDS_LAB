% Figure environment removed

\section{Defining and Estimating Beliefs encoded in LLMs}\label{sec:eval}
In this section, we tackle the statistical challenges that arise when using LLMs as survey respondents. 
We first define the estimands of interests, then discuss how to estimate them from LLMs outputs.

\vspace{-2mm}
\subsection{Action Likelihood}\label{subsec:action_likelihood_estimand}
To quantify the preferences encoded by an LLM, we define the \textit{action likelihood} as the target estimand. 
We have a dataset of survey questions, $\mathcal{D} = \{x_i\}_{i=1}^{n}$, where each question $x_i = \{d_i, A_i\}$ consists of a scenario description $d_i$ and a set of action descriptions $A_i = \{a_{i,k}\}_{k=1}^{K}$. 
The ``survey respondent'' is an LLM parameterized by $\theta_j$, represented as $p_{\theta_j}$. 
The objective is to estimate the probability of an LLM respondent ``preferring'' action $a_{i,k}$ in scenario $x_i$, which we define as the \emph{action likelihood}.
The estimation challenge is when we present an LLM with a description and two possible actions, denoted as $x_i$, it returns a sequence $p(s \mid x_i)$. The goal is to map the sequence $s$ to a corresponding action $a_{i,k}$.

Formally, we define the set of tokens in a language as $\mathcal{T}$, the space of all possible token sequences of length $N$ as $S_N \equiv \mathcal{T}^N$, the space of semantic equivalence classes as $\mathcal{C}$, and the \emph{semantic equivalence relation} as $E(\cdot, \cdot)$.
All token sequences $s$ in a semantic equivalence set $c\in\mathcal{C}$ reflect the same meaning, that is, $\forall s, s' \in c: E(s, s')$ \cite{kuhn2023semantic}.
Let $c(a_{i,k})$ denote the semantic equivalent set for action $a_{i,k}$.
Given a survey question $x_i$ and an LLM $p_{\theta_j}$, we obtain a conditional distribution over token sequences, $p_{\theta_j}(s \g x_i)$. 
To convert this distribution into a distribution over actions, we aggregate the probabilities of all sequences in the semantic equivalence class. \looseness-1

\begin{definition}\label{def:action_likelihood}
(Action Likelihood) The action likelihood of a model $p_{\theta_j}$ on scenario $x_i$ is defined as,
\begin{align}
p_{\theta_j} (a_{i,k} \g x_i) = \sum_{s \in c(a_{i,k})} p_{\theta_j}\big(s \g x_i\big) \qquad \forall a_{i,k} \in A_i,
\label{eq:action_likelihood}
\end{align}
where $c_{i,k} \in \mathcal{C}$ denotes the semantic equivalence set containing all possible token sequences $s$ that encode a preference for action $a_{i,k}$ in the context of scenario $x_i$.
\end{definition}

The probability of an LLM ``choosing" an action given a scenario, as encoded in the LLM's token probabilities, is defined in \Cref{def:action_likelihood}. To measure uncertainty, we utilize entropy \citep{mackay2003information}.
\begin{definition}
(Action Entropy) The action entropy of a model $p_{\theta_j}$ on scenario $x_i$ is defined as,
\begin{align}
H_{\theta_j}[A_{i} \g x_i] = - \sum_{a_{i,k} \in A_i} p_{\theta_j} (a_{i,k} \g x_i) \log\big(p_{\theta_j} (a_{i,k} \g x_i)\big).
\label{eq:action_entropy}
\end{align}
\end{definition}
The quantity defined in \Cref{eq:action_entropy} corresponds to the semantic entropy measure introduced in \citet{melamed1997measuring, kuhn2023semantic}. It quantifies an LLM's confidence in its encoded semantic preference, rather than the confidence in its token outputs.


\subsection{Marginal Action Likelihood}\label{subsec:marginal_action_likelihood}
\Cref{def:action_likelihood} only considers the semantic equivalence in the LLM's response, and overlooks the semantic equivalence of the input questions. 
Prior research has shown that LLMs are sensitive to the syntax of questions \citep{efrat2020turking, webson2021prompt, zhao2021calibrate, jang2022becel}. 
To account for LLMs question-form sensitivity, we introduce the \emph{marginal action likelihood}. It quantifies the likelihood of a model ``choosing" a specific action for a given scenario when presented with a randomly selected question form.
%



Formally, we define a question-form function $z\colon x \to x$ that maps the original survey question $x$ to a syntactically altered survey question $z(x)$, while maintaining semantic equivalence, i.e., $E(x, z(x))$. 
Let $\mathcal{Z}$ represent the set of question forms that leads to semantically equivalent survey questions. \looseness=-1

\begin{definition}
(Marginal Action Likelihood) The marginal action likelihood of a model $p_{\theta_j}$ on scenario $x_i$ and on a set of question forms $\mathcal{Z}$ is defined as,
\begin{align} 
    p_{\theta_j}\big(a_{i,k} \g \mathcal{Z}(x_i)\big) = 
            \sum_{z \in \mathcal{Z}} p_{\theta_j}\big(a_{i,k} \g z(x_i)\big)\;p(z) \qquad \forall a_{i,k} \in A_i.
    \label{eq:marginal_likelihood}
\end{align}

\end{definition}
Here, the probability $p(z)$ represents the density of the question forms.
In practice, it is challenging to establish a natural distribution over the question forms since it requires modelings of how a typical user may ask a question.
Therefore, the responsibility of defining a distribution over the question forms falls on the analyst. Different choices of $p(z)$ can lead to different inferences regarding the marginal action likelihood.
Similar to \Cref{eq:action_entropy}, we quantify the uncertainty associated with the marginal action likelihood using entropy.
\begin{definition}(Marginal Action Entropy) The marginal action entropy  of a model $p_{\theta_j}$ on scenario $x$ and set of question forms $\mathcal{Z}$ is defined as,
\begin{align} 
H_{\theta_j}[A_{i} \g \mathcal{Z}(x_i)] = - \sum_{a_{i,k} \in A_i} p_{\theta_j}\big(a_{i,k} \g \mathcal{Z}(x_i)\big) \log\bigg(p_{\theta_j}\big(a_{i,k} \g \mathcal{Z}(x_i)\big)\bigg).\label{eq:marginal_uncertainty}
\end{align}
\vspace{-3mm}
\end{definition}

The marginal action entropy captures the sensitivity of the model's output distribution to variations in the question forms and the inherent ambiguity of the scenario. 

To assess how consistent a model is to changes in the question forms, we compute \emph{question-form consistency (QF-C)} as an evaluation metric.
Given a set of question forms $\mathcal{Z}$, we quantify the consistency between the action likelihoods conditioned on different question form using the Generalized Jensen-Shannon Divergence (JSD)~\cite{sibson1969information}.\looseness=-1

\begin{definition}(Question-Form Consistency) \label{def:inconsistency}
The question-form consistency (QF-C) of a model $p_{\theta_j}$ on scenario $x_i$ and set of question forms $\mathcal{Z}$ is defined as,
\begin{align}
\Delta(p_{\theta_j}; \mathcal{Z}(x_i)) = 1 - 
    \frac{1}{|\mathcal{Z}|} \sum_{z \in \mathcal{Z}}\mathrm{KL}\bigg(p_{\theta_j}\big(A_i \mid z(x_i)\big) \;\bigg\| \;\Bar{p}\bigg), \quad 
    \text{where} 
    \quad 
    \Bar{p} = \frac{1}{|\mathcal{Z}|} \sum_{z \in \mathcal{Z}} p_{\theta_j}\big(A_i \mid z(x_i)\big).
\label{eq:approximate-consistency}
\end{align}
%\vspace{-3mm}
\end{definition}
Intuitively, question-form consistency (\Cref{eq:approximate-consistency}) quantifies the average similarity between question-form-specific action likelihoods $p_{\theta_j}(A_i \mid z(x_i))$ and the average likelihood of them. 
This probabilistic definition provides a measure of a model's semantic consistency and is related to existing deterministic consistency conditions \citep{ribeiro2019red, elazar2021measuring, jang2022becel}.

Next, to quantify a model's action uncertainty in its outputs independent of their consistency, we compute the \emph{average question-form-specific action entropy}.\looseness=-1

\begin{definition}(Average Question-Form-Specific Action Entropy)\label{def:QF-E}
The average question-form-specific action entropy (QF-E) of a model $\theta_j$ on scenario $x_i$ and a prompt set $\mathcal{Z}$ is defined as, 
\begin{align}
 H_{QF-E(\theta_j)}[A_i \g  x_i] &= \frac{1}{|Z|}\sum_{z \in \mathcal{Z}}   H[ A_i \g z(x_i)] \;.\label{eq:expected_semantic_entropy}
\end{align}  
\end{definition}

The quantity in \Cref{eq:expected_semantic_entropy} provides a measure of a model's average uncertainty in its outputs across different question forms. It complements the question-form consistency metric defined in \Cref{eq:approximate-consistency}. 


We can use the metrics in \Cref{def:inconsistency} and \ref{def:QF-E} to diagnose why a model has a high marginal action entropy. This increased entropy can stem from: (1) the model providing inconsistent responses, (2) the question being inherently ambiguous to the model, or 3) a combination of both.
A low value of QF-C indicates that the model exhibits inconsistency in its responses, while a high value of QF-E suggests that the question is ambiguous to the model.
Interpreting models that display low consistency but high confidence when conditioned on different question forms (i.e., low QF-C and low QF-E) can be challenging. These models appear to encode specific beliefs but are sensitive to variations in question forms, leading to interpretations that lack robustness.


\subsection{Estimation}\label{subsec:estimation}
We now discuss the estimation of the action likelihood and the margianlized action likelihood based on the output of LLMs.
To compute the action likelihood as defined in \Cref{eq:action_likelihood}, we need to establish a mapping from the token space to the action space. One approach is to create a probability table of all possible continuations $s$, assigning each continuation to an action, and then determining the corresponding action likelihood. However, this approach becomes computationally intractable as the token space grows exponentially with longer continuations.
Compounding this issue is the commercialization of LLMs, which restricts access to the LLMs through APIs. Many model APIs, including Anthropic's \texttt{claude-v1.3} and OpenAI's \texttt{gpt-4}, do not provide direct access to token probabilities.

We approximate the action likelihood through sampling. We sample $M$ token sequences $\{s_{1}, ..., s_{m}\}$ from an LLM by $s_i \sim p_{\theta_j}(s \g z(x_i))$. We then map each token sequence $s$ to the set of potential actions $A_i$ using a deterministic mapping function $g\colon (x_i, s) \to A_i$. Finally, we can approximate the action likelihood $p_{\theta_j}(a_{i,k} \g z(x_i))$ in \Cref{eq:action_likelihood} through Monte Carlo,
\begin{align}
\hat{p}_{\theta_j}\big(a_{i,k} \g z(x_i)\big) = \frac{1}{M} \sum^M_{i=1} \mathds{1} \big[ g(s_i) = a_{i,k} \big], \hspace{2em} s_i \sim p_{\theta_j}(\mathbf{s} \g z(x_i)).\label{eq:monte-carlo}
\end{align}
The mapping function $g$ can be operationalized using a rule-based matching technique, an unsupervised clustering method, or using a fine-tuned or prompted LLM.

Estimating the marginal action likelihood requires specifying a distribution over the question forms $p(z)$. As discussed in \Cref{subsec:marginal_action_likelihood}, different specifications of $p(z)$ can result in different interpretations of the marginal action likelihood. Here, we represent the question forms as a set of prompt templates and assign a uniform probability to each prompt format when calculating the marginal action likelihood. For every combination of a survey question $x_i$ and a prompt template $z\in\mathcal{Z}$, we first estimate the action likelihood using \Cref{eq:action_likelihood}, we then average them across prompt formats,
\begin{align}
\hat{p}_{\theta_j}\big(a_{i,k} \g \mathcal{Z}(x_i)\big) = \frac{1}{|Z|} \sum_{z \in \mathcal{Z}} \hat{p}_{\theta_j}\big(a_{i,k} \g z(x_i)\big).\label{eq:estimated_marginal}
\end{align}
We can calculate the remaining metrics by plugging in the estimated action likelihood.

