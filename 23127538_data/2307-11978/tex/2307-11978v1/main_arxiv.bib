
@misc{Authors14,
 author = {Full Author Name},
 title = {The Frobnicatable Foo Filter},
 note = {Face and Gesture  submission ID 324. Supplied as additional material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {Full Author Name},
 title = {Frobnication Tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {Alvin Alpher},
title = {Frobnication},
journal = {Journal of Foo},
volume = 12, 
number = 1, 
pages = {234--778}, 
year = 2002
}

@article{Alpher03,
author = {Alvin Alpher and Ferris P.~N. Fotheringham-Smythe},
title = {Frobnication Revisited},
journal = {Journal of Foo},
volume = 13, 
number = 1, 
pages = {234--778}, 
year = 2003
}

@article{Alpher04,
author = {Alvin Alpher and Ferris P.~N. Fotheringham-Smythe and Gavin Gamow},
title = {Can a Machine Frobnicate?},
journal = {Journal of Foo},
volume = 14, 
number = 1, 
pages = {234--778}, 
year = 2004
}


%prompt tuning 

@inproceedings{lu2022prompt_dist,
  title={Prompt distribution learning},
  author={Lu, Yuning and Liu, Jianzhuang and Zhang, Yonggang and Liu, Yajing and Tian, Xinmei},
  booktitle={CVPR},
  pages={5206--5215},
  year={2022}
}

@inproceedings{shu2022tpt,
  author    = {Manli, Shu and Weili, Nie and De-An, Huang and Zhiding, Yu and Tom, Goldstein and Anima, Anandkumar and Chaowei, Xiao},
  title     = {Test-Time Prompt Tuning for Zero-shot Generalization in Vision-Language Models},
  booktitle = {NeurIPS},
  year      = {2022},
}

@article{rolnick2017dl_noise,
  title={Deep learning is robust to massive label noise},
  author={Rolnick, David and Veit, Andreas and Belongie, Serge and Shavit, Nir},
  journal={arXiv preprint},
  year={2017}
}


@inproceedings{dosovitskiy2020ViT,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2020}
}

@article{petroni2020context,
  title={How context affects language models' factual predictions},
  author={Petroni, Fabio and Lewis, Patrick and Piktus, Aleksandra and Rockt{\"a}schel, Tim and Wu, Yuxiang and Miller, Alexander H and Riedel, Sebastian},
  journal={arXiv preprint},
  year={2020}
}

@article{liu2021gpt_too,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint},
  year={2021}
}


@inproceedings{Radford2021CLIP,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  booktitle={ICML},
  year=2021
}

@article{Zhou2022CoOp,
    title={Learning to Prompt for Vision-Language Models},
    author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
    journal={IJCV},
    year=2022
}

@inproceedings{zhou2022CoCoOp,
  title={Conditional prompt learning for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={CVPR},
  year={2022}
}

@article{Huang2022UPL,
  title={Unsupervised Prompt Learning for Vision-Language Models},
  author={Huang, Tony and Chu, Jack and Wei, Fangyun},
  journal={arXiv preprint},
  year=2022
}

%VL-PTM
@inproceedings{jia2021_align,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={ICML},
  year={2021},
}

@inproceedings{yao2021filip,
  title={FILIP: Fine-grained Interactive Language-Image Pre-Training},
  author={Yao, Lewei and Huang, Runhui and Hou, Lu and Lu, Guansong and Niu, Minzhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Jiang, Xin and Xu, Chunjing},
  booktitle={ICLR},
  year={2021}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint},
  year={2022}
}

%CLIP-PT application
@inproceedings{rao2022denseclip,
  title={Denseclip: Language-guided dense prediction with context-aware prompting},
  author={Rao, Yongming and Zhao, Wenliang and Chen, Guangyi and Tang, Yansong and Zhu, Zheng and Huang, Guan and Zhou, Jie and Lu, Jiwen},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{du2022Detectiong,
  title={Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model},
  author={Du, Yu and Wei, Fangyun and Zhang, Zihe and Shi, Miaojing and Gao, Yue and Li, Guoqi},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{li2022bridge,
  title={Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos},
  author={Li, Muheng and Chen, Lei and Duan, Yueqi and Hu, Zhilan and Feng, Jianjiang and Zhou, Jie and Lu, Jiwen},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{ju2022prompting_video,
  title={Prompting visual-language models for efficient video understanding},
  author={Ju, Chen and Han, Tengda and Zheng, Kunhao and Zhang, Ya and Xie, Weidi},
  booktitle={ECCV},
  year={2022},
}

@article{sun2022dualcoop,
  title={Dualcoop: Fast adaptation to multi-label recognition with limited annotations},
  author={Sun, Ximeng and Hu, Ping and Saenko, Kate},
  journal={arXiv preprint},
  year={2022}
}

@inproceedings{wang2022continual,
  title={Learning to prompt for continual learning},
  author={Wang, Zifeng and Zhang, Zizhao and Lee, Chen-Yu and Zhang, Han and Sun, Ruoxi and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas},
  booktitle={CVPR},
  year={2022}
}

%----------------------------------------------
% Robust losses
@inproceedings{Zhang2017Understanding,
title	= {Understanding deep learning requires rethinking generalization},
author	= {Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
booktitle={ICML},
year	= {2017},
}

@inproceedings{ghosh2017robust_loss,
  title={Robust loss functions under label noise for deep neural networks},
  author={Ghosh, Aritra and Kumar, Himanshu and Sastry, P Shanti},
  booktitle={AAAI},
  year={2017}
}
@inproceedings{GenXEnt,
  title={Generalized cross entropy loss for training deep neural networks with noisy labels},
  author={Zhang, Zhilu and Sabuncu, Mert},
  booktitle={NeurIPS},
  year={2018}
}
@inproceedings{wang2019symmetric,
  title={Symmetric cross entropy for robust learning with noisy labels},
  author={Wang, Yisen and Ma, Xingjun and Chen, Zaiyi and Luo, Yuan and Yi, Jinfeng and Bailey, James},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{ma2020normalized_loss,
  title={Normalized loss functions for deep learning with noisy labels},
  author={Ma, Xingjun and Huang, Hanxun and Wang, Yisen and Romano, Simone and Erfani, Sarah and Bailey, James},
  booktitle={ICML},
  year={2020}
}

@inproceedings{ma2020normalized,
  title={Normalized loss functions for deep learning with noisy labels},
  author={Ma, Xingjun and Huang, Hanxun and Wang, Yisen and Romano, Simone and Erfani, Sarah and Bailey, James},
  booktitle={ICML},
  year={2020},
}


% Loss correction
@inproceedings{patrini2017making,
  title={Making deep neural networks robust to label noise: A loss correction approach},
  author={Patrini, Giorgio and Rozza, Alessandro and Krishna Menon, Aditya and Nock, Richard and Qu, Lizhen},
  booktitle={CVPR},
  year={2017}
}
@inproceedings{hendrycks2018using,
  title={Using trusted data to train deep networks on labels corrupted by severe noise},
  author={Hendrycks, Dan and Mazeika, Mantas and Wilson, Duncan and Gimpel, Kevin},
  booktitle={NeurIPS},
  year={2018}
}
@inproceedings{chang2017active,
  title={Active bias: Training more accurate neural networks by emphasizing high variance samples},
  author={Chang, Haw-Shiuan and Learned-Miller, Erik and McCallum, Andrew},
  booktitle={NeurIPS},
  year={2017}
}

@article{bootstrapping,
  title={Training deep neural networks on noisy labels with bootstrapping},
  author={Reed, Scott and Lee, Honglak and Anguelov, Dragomir and Szegedy, Christian and Erhan, Dumitru and Rabinovich, Andrew},
  journal={arXiv preprint},
  year={2014}
}

@inproceedings{ma2018dimensionality,
  title={Dimensionality-Driven Learning with Noisy Labels},
  author={Ma, Xingjun and Wang, Yisen and Houle, Michael E and Zhou, Shuo and Erfani, Sarah and Xia, Shutao and Wijewickrema, Sudanthi and Bailey, James},
  booktitle={ICML},
  year={2018}
}

@inproceedings{song2019selfie,
  title={Selfie: Refurbishing unclean samples for robust deep learning},
  author={Song, Hwanjun and Kim, Minseok and Lee, Jae-Gil},
  booktitle={ICML},
  year={2019}
}

@inproceedings{arazo2019unsupervised,
  title={Unsupervised Label Noise Modeling and Loss Correction},
  author={Arazo, Eric and Ortego, Diego and Albert, Paul and Oâ€™Connor, Noel and Mcguinness, Kevin},
  booktitle={ICML},
  year={2019}
}

@inproceedings{yi2019probabilistic,
  title={Probabilistic end-to-end noise correction for learning with noisy labels},
  author={Yi, Kun and Wu, Jianxin},
  booktitle={CVPR},
  year={2019}
}

@article{yao2020dual,
  title={Dual t: Reducing estimation error for transition matrix in label-noise learning},
  author={Yao, Yu and Liu, Tongliang and Han, Bo and Gong, Mingming and Deng, Jiankang and Niu, Gang and Sugiyama, Masashi},
  journal={NeurIPS},
  year={2020}
}

% Sample selection
@inproceedings{han2018co,
  title={Co-teaching: Robust training of deep neural networks with extremely noisy labels},
  author={Han, Bo and Yao, Quanming and Yu, Xingrui and Niu, Gang and Xu, Miao and Hu, Weihua and Tsang, Ivor and Sugiyama, Masashi},
  booktitle={NeurIPS},
  year={2018}
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={ICML},
  year={2018}
}

@inproceedings{yu2019does,
  title={How does Disagreement Help Generalization against Label Corruption?},
  author={Yu, Xingrui and Han, Bo and Yao, Jiangchao and Niu, Gang and Tsang, Ivor and Sugiyama, Masashi},
  booktitle={ICML},
  year={2019}
}


% Meta learning
@inproceedings{li2017learning,
  title={Learning from noisy labels with distillation},
  author={Li, Yuncheng and Yang, Jianchao and Song, Yale and Cao, Liangliang and Luo, Jiebo and Li, Li-Jia},
  booktitle={ICCV},
  year={2017}
}

@inproceedings{ren2018learning,
  title={Learning to Reweight Examples for Robust Deep Learning},
  author={Ren, Mengye and Zeng, Wenyuan and Yang, Bin and Urtasun, Raquel},
  booktitle={ICML},
  year={2018}
}

@inproceedings{li2019learning,
  title={Learning to learn from noisy labeled data},
  author={Li, Junnan and Wong, Yongkang and Zhao, Qi and Kankanhalli, Mohan S},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{shu2019meta,
  title={Meta-weight-net: Learning an explicit mapping for sample weighting},
  author={Shu, Jun and Xie, Qi and Yi, Lixuan and Zhao, Qian and Zhou, Sanping and Xu, Zongben and Meng, Deyu},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{zhang2020distilling,
  title={Distilling Effective Supervision from Severe Label Noise},
  author={Zhang, Zizhao and Zhang, Han and Arik, Sercan O and Lee, Honglak and Pfister, Tomas},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{zheng2021meta,
  title={Meta label correction for noisy label learning},
  author={Zheng, Guoqing and Awadallah, Ahmed Hassan and Dumais, Susan},
  booktitle={AAAI},
  year={2021}
}

% Robust Regularization
@article{smoothing,
  title={Regularizing neural networks by penalizing confident output distributions},
  author={Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, {\L}ukasz and Hinton, Geoffrey},
  journal={arXiv preprint},
  year={2017}
}

@inproceedings{mixup,
  title={Mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{hendrycks2019using,
  title={Using pre-training can improve model robustness and uncertainty},
  author={Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas},
  booktitle={ICML},
  year={2019},
}

@inproceedings{xia2020robust,
  title={Robust early-learning: Hindering the memorization of noisy labels},
  author={Xia, Xiaobo and Liu, Tongliang and Han, Bo and Gong, Chen and Wang, Nannan and Ge, Zongyuan and Chang, Yi},
  booktitle={ICLR},
  year={2020}
}

% Surveys
@article{song2020learning,
  title={Learning from noisy labels with deep neural networks: A survey},
  author={Song, Hwanjun and Kim, Minseok and Park, Dongmin and Lee, Jae-Gil},
  journal={arXiv preprint},
  year={2020}
}

@article{frenay2013classification,
  title={Classification in the presence of label noise: a survey},
  author={Fr{\'e}nay, Beno{\^\i}t and Verleysen, Michel},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={25},
  number={5},
  pages={845--869},
  year={2013},
  publisher={IEEE}
}

%dataset
@inproceedings{recht2019imagenet,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={ICML},
  year={2019},
}

@inproceedings{fei2004cal101,
  title={Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories},
  author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  booktitle={CVPR-W},
  year={2004},
}

@inproceedings{krause20133car,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={ICCV-W},
  year={2013}
}

@inproceedings{nilsback2008flower,
  title={Automated flower classification over a large number of classes},
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={ICVGIP},
  year={2008},
}

@article{maji2013aircraft,
  title={Fine-grained visual classification of aircraft},
  author={Maji, Subhransu and Rahtu, Esa and Kannala, Juho and Blaschko, Matthew and Vedaldi, Andrea},
  journal={arXiv preprint},
  year={2013}
}

@inproceedings{cimpoi2014DTD,
  title={Describing textures in the wild},
  author={Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle={CVPR},
  year={2014}
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint},
  year={2012}
}

@inproceedings{parkhi2012pets,
  title={Cats and dogs},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
  booktitle={CVPR},
  year={2012},
}

@inproceedings{bossard2014food,
  title={Food-101--mining discriminative components with random forests},
  author={Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle={ECCV},
  year={2014},
}

%Method
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={NeurIPS},
  year={2017}
}
@inproceedings{he2016resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}