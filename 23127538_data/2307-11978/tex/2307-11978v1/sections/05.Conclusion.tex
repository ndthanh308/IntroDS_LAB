\section{Conclusion}
\label{sec:conclusion}
In this paper, we provide a comprehensive study on the robustness to label noise of prompt tuning large vision-language models (namely, CLIP). Through a series of experiments, we demonstrated that the noise robustness of prompt tuning can be attributed to the structure imposed on class embeddings by CLIP's pre-trained text encoder. We further demonstrate that prompt tuning can ease overfitting to mislabeled samples by reducing the gradients induced by label noise. 
We extensively experimented with different model configurations such as backbones and context length, obtaining consistent results and conclusions. 
Finally, inspired by our findings, we presented a new robust unsupervised prompt tuning approach that favors diversity over correct predictions, to improve the transfer performance.
