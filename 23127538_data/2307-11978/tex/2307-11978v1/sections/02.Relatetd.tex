\section{Related Work}
\label{sec:r_work}


\noindent \textbf{Prompt tuning for Vision-Language models.} Over the past few years, there has been huge progress in Vision-Language Pre-Trained Models (VL-PTMs)~\cite{Radford2021CLIP,jia2021_align,yao2021filip,yu2022coca}. CLIP~\cite{Radford2021CLIP} is considered a representative model of VL-PTMs. Unlike the conventional, finetuning paradigm, CLIP applies prompt engineering to incorporate the category information in the text input such that its pre-trained model can adapt to various image classification tasks without further training. However, the design of a proper prompt is challenging and requires heuristics. CoOp~\cite{Zhou2022CoOp} introduces learnable prompts optimized on target datasets to address this problem. 
To further extend the generalization of CoOp, CoCoOp~\cite{zhou2022CoCoOp} introduces a lightweight network to add additional information from image inputs into learnable prompts. CoOp has also faced criticism for disregarding the diversity of visual representations. In contrast, ProDA~\cite{lu2022prompt_dist} tackles this issue by utilizing diverse prompts to capture the distribution of varying visual representations.

In contrast to the supervised tuning methods above, UPL~\cite{Huang2022UPL} proposes a framework to perform prompt tuning without labeled data. TPT~\cite{shu2022tpt} achieves zero-shot transfer by dynamically adjusting prompts using only a single test sample.

In addition to downstream tasks for image classification,  recent works have applied prompt tuning on CLIP to various computer vision tasks such as object detection~\cite{rao2022denseclip,du2022Detectiong}, video understanding~\cite{li2022bridge,ju2022prompting_video}, and multi-label recognition~\cite{sun2022dualcoop}. These works reveal the further potential of prompt tuning. 
%We expect our study to contribute to a better understanding of prompt tuning for future work.

\noindent \textbf{Label noise-robust learning.} Deep neural networks (DNNs) have been well-studied for classification tasks without label noises. However, if the training data contains label noise, DNNs would easily overfit to the noisy labels~\cite{Zhang2017Understanding}. To overcome this issue, several works have attempted to improve the noise robustness of DNNs by approaches including robust losses that tolerate noisy labels~\cite{ghosh2017robust_loss, GenXEnt,wang2019symmetric,ma2020normalized}, loss correction approaches that estimate a transition matrix to correct the predictions~\cite{patrini2017making,hendrycks2018using,chang2017active,bootstrapping,arazo2019unsupervised,ma2018dimensionality,song2019selfie,yi2019probabilistic,yao2020dual}, meta-learning frameworks that learn to correct the label noise in training examples~\cite{li2017learning,ren2018learning,li2019learning,shu2019meta,zhang2020distilling,zheng2021meta} and regularization techniques that are customized to lower the negative impact of noise~\cite{mixup,smoothing,hendrycks2019using, xia2020robust}. 

In this work, we demonstrate that prompt tuning on CLIP naturally holds powerful noise robustness. We explore the key factors behind such robustness and show its application on unsupervised prompt tuning.