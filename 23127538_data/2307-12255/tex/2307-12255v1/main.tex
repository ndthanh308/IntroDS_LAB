% \documentclass{article}


% % if you need to pass options to natbib, use, e.g.:
% %     \PassOptionsToPackage{numbers, compress}{natbib}
% % before loading neurips_2022


% % ready for submission
% % \usepackage{neurips_2022}


% % to compile a preprint version, e.g., for submission to arXiv, add the
% % [preprint] option:
% \usepackage[preprint]{neurips_2022}


% % to compile a camera-ready version, add the [final] option, e.g.:
% % \usepackage[final]{neurips_2022}


% % to avoid loading the natbib package, add option nonatbib:
% % \usepackage[nonatbib]{neurips_2022}


% \usepackage[utf8]{inputenc} % allow utf-8 input
% \usepackage[T1]{fontenc}    % use 8-bit T1 fonts
% \usepackage{hyperref}       % hyperlinks
% \usepackage{url}            % simple URL typesetting
% \usepackage{booktabs}       % professional-quality tables
% \usepackage{amsfonts}       % blackboard math symbols
% \usepackage{nicefrac}       % compact symbols for 1/2, etc.
% \usepackage{microtype}      % microtypography
% \usepackage{xcolor}         % colors
% \usepackage{graphicx}
% \usepackage{isomath}
% \usepackage{amsmath, bm}


\documentclass{article}
% \usepackage[nonatbib, preprint]{neurips_2021} and removing \usepackage{biblatex}
\usepackage[nonatbib, final]{nips_2017}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{bm}

% \title{Biometric Pattern Image Denoising \\ Using Deep Learning (Category: Application)}

\title{ResWCAE: Biometric Pattern Image Denoising \\ Using Residual Wavelet-Conditioned Autoencoder} 

%\\(Category: Application)

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Youzhi Liang \\
  Department of Computer Science \\
  Stanford University \\
  Stanford, CA 94305 \\
  \texttt{youzhil@stanford.edu} \\
  \And
  Wen Liang \\
  Google Inc. \\
  Mountain View, CA 94043 \\
  \texttt{liangwen@google.com} \\
}


\begin{document}


\maketitle


\begin{abstract}
% We develop a light and robust deep learning model, using wavelet-conditioned Convolutional Autoencoder, dedicated for biometirc pattern image denoising under extreme noisy conditions. 

% We propose a novel deep learning architecture, named the Wavelet-Conditioned Convolutional Autoencoder, designed specifically for denoising biometric pattern images under conditions of high noise levels. Our model is both lightweight and robust, achieving state-of-the-art performance in this challenging task.

% We propose a novel deep learning architecture, based on a wavelet-conditioned Convolutional Autoencoder, designed for effectively denoising severely degraded biometric pattern images in the presence of high levels of noise interference. Our approach is characterized by its lightweight and robust nature, making it well-suited for deployment in practical scenarios including small IoT devices.

% We introduce a novel deep learning architecture, which utilizes a wavelet-conditioned Convolutional Autoencoder, specifically developed for efficiently denoising heavily degraded biometric pattern images in the presence of significantly high levels of noise interference. Our proposed approach exhibits both lightweight and robust features, thus making it a highly suitable candidate for deployment in practical scenarios, including small Internet of Things (IoT) devices.

% The wavelet encoder produces a compressed representation of features in the wavelet-transform domain using approximation and detail subimages, which serves as a conditional layer input to the image encoder. 

The utilization of biometric authentication with pattern images is increasingly popular in compact Internet of Things (IoT) devices. However, the reliability of such systems can be compromised by image quality issues, particularly in the presence of high levels of noise. While state-of-the-art deep learning algorithms designed for generic image denoising have shown promise, their large number of parameters and lack of optimization for unique biometric pattern retrieval make them unsuitable for these devices and scenarios. In response to these challenges, this paper proposes a lightweight and robust deep learning architecture, the Residual Wavelet-Conditioned Convolutional Autoencoder (Res-WCAE) with a Kullback-Leibler divergence (KLD) regularization, designed specifically for fingerprint image denoising. Res-WCAE comprises two encoders – an image encoder and a wavelet encoder - and one decoder. Residual connections between the image encoder and decoder are leveraged to preserve fine-grained spatial features, where the bottleneck layer conditioned on the compressed representation of features obtained from the wavelet encoder using approximation and detail subimages in the wavelet-transform domain. The effectiveness of Res-WCAE is evaluated against several state-of-the-art denoising methods, and the experimental results demonstrate that Res-WCAE outperforms these methods, particularly for heavily degraded fingerprint images in the presence of high levels of noise. Overall, Res-WCAE shows promise as a solution to the challenges faced by biometric authentication systems in compact IoT devices.

%This suggests that Res-WCAE could be a promising solution for improving the reliability of biometric authentication systems in compact IoT devices.


\end{abstract}

\section{Introduction}

% P1
% the application of biometric authentication
% finger print in particular
% finger print recog issues

% p2
% image denoising in general and issues due to noise level and model size and pattern feature
% fingerprint denoising technique
% gap on high level noise and small neural net and dedicated to fingerprint denoising
% https://ai.googleblog.com/2021/03/accelerating-neural-networks-on-mobile.html
% figur of PSNR vs noise level with neural size indicator

Biometric authentication has gained popularity with the recent advances in sensing systems and vision algorithms~\cite{weaver2006biometric}. Biometric traits, including voice, gait, face, and fingerprints, are widely used to unlock devices, including phones, computers, door locks, and other Internet of Things (IoT) devices~\cite{mgaga2019review}. Fingerprint recognition, in particular, is an active research area due to the unique and stable ridge and minutiae features of fingerprints. However, fingerprint images are susceptible to image quality issues induced by various impression conditions, such as humidity, wetness, dirt, as well as user behavior, resulting in low-quality images that require noise reduction or inpainting of adjacent areas~\cite{drahansky2017challenges}.  High levels of noise caused by the failure or degradation of sensors and by the parched or drenched conditions of user fingers, can lead to repeated fingerprint recognition failure, therefore necessitating denoising of fingerprint images as a pre-processing step to facilitate subsequent operations such as fingerprint authentication and verification~\cite{dharavath2013study}.

Desnoising of fingerprint images is considered as a subfield of image denoising, a well-established and actively researched area in low-level vision, as it is a crucial step in numerous practical applications, including medical imaging, surveillance and photography~\cite{fan2019brief, tian2020deep}. The fundamental objective of image denoising is to retrieve a noise-free image from a noisy observation image. Let $\bm{I}(m,n)$ be a matrix of size $M\times N$, representing a noise-free image, where $(m, n)$ are the coordinates of the pixel; let $\bm{J}(m, n)$ be a matrix of the same size as $\bm{I}(m,n)$, representing the corresponding noisy image. The resulting noisy image $J(x,y)$, following an image degradation model, can be expressed as: $\bm{J}(m, n) = \bm{I}(m, n) + \bm{\epsilon}(m, n)$, where $\epsilon(m, n) \sim \mathcal{N}(0, \sigma^2)$. This additive white Gaussian noise (AWGN) model, which adds independent Gaussian noise to each pixel, is a widely used approach in image processing to simulate noise in images and assess the effectiveness of noise reduction algorithms. It is essential to note that the noise added to each pixel is independent of the additive noise added to other pixels in the image.

State-of-the-art deep learning algorithms have achieved remarkable performance on generic image denoising tasks~\cite{zhang2018ffdnet, zhang2017beyond}. Nevertheless, the associated large number of parameters, ranging from millions to billions, renders them unsuitable for deployment on compact Internet of Things (IoT) devices. Furthermore, these algorithms are designed to denoise images acquired using CMOS sensing with low levels of noise, i.e., $\sigma \leq 50$, which may not be appropriate for fingerprint images acquired using capacitive sensing, in particular under the condition of high levels of noise when hands are too dry or wet, i.e., $\sigma \in [100, 200]$. Fingerprint images are characterized by unique features such as ridges and valleys that must be preserved during the denoising process. Thus, specialized algorithms are required for fingerprint image denoising, which are specifically designed to handle these distinct features targeted for high noisy conditions. Such algorithms leverage fingerprint-specific information, such as ridge orientation or minutiae, to guide the denoising process and protect the critical features of the fingerprint. The use of a generic image denoising algorithm for fingerprint images may not be suitable, as it may result in the loss of vital fingerprint information, reducing the accuracy and reliability of fingerprint recognition systems. State-of-the-art fingerprint denoising models are also limited in the noise levels~\cite{bae2020fingerprint, prabhu2019u, adiga2019fpd, reddy2008fingerprint}. 

% As show in Fig~\ref{fig:prior_art_psnr}, state-of-the-art deep learning algorithms for generic image denoising achieves high performance for images in the presence of low noise. Their performance drop drastically as noise level increases, i.e. the decrease of PSNR of noisy images. 

% % Figure environment removed

In this paper, we propose and evaluate a deep learning architecture, a Residual Wavelet-Conditioned Convolutional Autoencoder (Res-WCAE), to retrieve the underlying intricate and unique fingerprint features, dedicately developed for denoising heavily degraded biometric pattern images in the presence of significantly high levels of noise interference for images with capacitive sensing techniques.  We evaluate our model performance using two datasets consisting of AWGN and synthetic images. Our proposed approach exhibits both lightweight, accurate and robust features, thus making it a highly suitable candidate for deployment in practical scenarios, including small Internet of Things (IoT) devices.

%From a Bayesian perspective, the image prior modeling plays a central role in image denoising when the likelihood is known. To date, several models have been employed to model image priors, including nonlocal self-similarity (NSS) models [1]-[5], sparse models [6]-[8], gradient models [9]-[11], and Markov random field (MRF) models [12]-[14]. NSS models, in particular, have become increasingly popular in state-of-the-art methods, such as BM3D [2], LSSC [4], NCSR [7], and WNNM [15].

\section{Methods}
Our research proposes a Residual Wavelet-Conditioned Convolutional Autoencoder (Res-WCAE) architecture for capturing fine-grained features in fingerprint pattern images obtained through capacitive sensing devices such as cell phones and other compact Internet of Things (IoT) devices. The Res-WCAE architecture comprises two encoders - an image encoder and a wavelet encoder - and one decoder. These encoders work in unison to construct condition layer for the decoder by leveraging compressed features in both the spatial domain and frequency domain, as illustrated in Fig.~\ref{fig:rescae_architecture}. Additionally, residual connections between the image encoder and decoder have been incorporated to enhance the spatial details of the fingerprint patterns. The Res-WCAE can handle a wide range of noise levels with a standard deviation of $\sigma_{\epsilon}$ ranging from 0 to 200, and achieves state-of-the-art denoising performance, notably including in noise levels that were not covered in prior research, to the best of our knowledge.

% Figure environment removed

\subsection{Image Encoder}
The image encoder consists of four down-sampling convolutional layers, producing the condensed representation of image information as well as supplementing the decoder with fine-grained spatial details through residual connections. The input to the image encoder is a 2D gray-scale image that is passed through a sequence of down-sampling layers. These layers reduce the spatial dimensions of the input image while simultaneously increasing the number of channels. The first layer applies a 3x3 convolution with 32 filters and a stride of 2, followed by a Rectified Linear Unit (ReLU) activation function. The output of this layer is then passed to the second layer, which applies a similar convolution with 64 filters and a stride of 2, also followed by a ReLU activation function. The same process is repeated in the third and fourth down-sampling layers, which have 128 and 256 filters respectively. The output of each layer in the image decoder can be represented as follows:

$$\bm{y}_{\mathcal{E}, img}^{[l]} =  \mathcal{F}_{\mathcal{E}, img}^{[l]} \left( 
\bm{y}_{\mathcal{E},{img}}^{[l-1]}; \mathbf{\Theta}_{\mathcal{E}, img}^{[l]} \right) , $$

where $\bm{y}_{\mathcal{E}, img}^{[l]}$ denotes the output of the image encoder at layer $l$, $\mathcal{F}_{\mathcal{E}, img}^{[l]}(\cdot; \mathbf{\Theta}_{\mathcal{E}, img}^{[l]})$ denotes the function of the convolutional neural network followed by a ReLU activation function at layer $l$, with trainable parameters $\mathbf{\Theta}_{\mathcal{E}, img}^{[l]}$ of the image encoder. The input to the first layer of the image encoder is the noisy image, i.e. $\bm{y}_{\mathcal{E}, img}^{[0]} = \bm{J}(M, N)$.

The output, $\bm{y}_{\mathcal{E}, img}^{[l]}$, of each down-sampling layer in the image decoder not only serves as input for the next down-sampling layer but also partially serves as input for the corresponding upsampling layers in the decoder. To preserve important spatial details of the image, the ResCAE employs residual connections between the image encoder and decoder blocks. These connections allow the network to propagate information from the image encoder to the decoder, while retaining fine-grained spatial details of the image. Specifically, the output of each down-sampling block is concatenated with the output of the corresponding up-sampling block, enabling the network to preserve the spatial information and recover intricate details, which will be elaborated in the decoder section.

\subsection{Wavelet Encoder}

The wavelet encoder employs wavelet transform to extract features from the input image. The wavelet transform coefficients are subsequently passed through a sequence of convolutional layers, which reduce the number of channels while preserving the spatial dimensions, where three convolutional layers with 16, 32, and 64 filters, respectively, followed by a rectified linear unit (ReLU) activation function.

Wavelet transform is a widely-used technique in signal and image processing due to its capability to capture both time and frequency domain information~\cite{wang2022asymptomatic, dong2020x}. In image processing, wavelet transform can extract both high-frequency details and low-frequency approximations, offering a multi-resolution analysis of the image by decomposing the image into several levels of detail, which is highly beneficial for capturing fine-grained features of an image while reducing noise and redundancy~\cite{fan2022high, you2023research}. The two-dimensional (2D) wavelet decomposition of a discrete image $\bm{J}(M,N)$ into $K$ octaves results in $3K+1$ subimages that represent the image at different scales and orientations:

$$\mathbb{J}_K = \left[ \bm{J}_K, \bigcup_{k=1}^K \{\bm{j}_k^1, \bm{j}_k^2, \bm{j}_k^3 \} \right],$$ 

where $\bm{J}_K$ denotes a low-resolution approximation of the original image $\bm{J}(M, N)$ and $\{\bm{j}_k^1, \bm{j}_k^2, \bm{j}_k^3 \}$ represents the wavelet subimages containing the image details at different scales ($2^k$) and orientations.

Fingerprints exhibit quasi-periodic patterns with dominant frequencies typically located in the middle frequency channels of the wavelet decomposition, as noted in prior research \cite{tico2001wavelet, le2020fingerprint}. By taking into account ridge orientation and spatial frequency across different regions of the image, one can better capture the inherent nature of the fingerprint image~\cite{hu2021procedure, joshi2021discrete}. We employ a three-layer convolutional neural network (CNN) to extract the condensed feature representation in the wavelet-transform domain. The output of each layer in the wavelet encoder can be represented as follows:

$$\bm{y}_{\mathcal{E}, wvl}^{[l]} =  \mathcal{F}_{\mathcal{E}, wvl}^{[l]} \left( 
\bm{y}_{\mathcal{E},{wvl}}^{[l-1]}; \mathbf{\Theta}_{\mathcal{E}, wvl}^{[l]} \right) , $$

where $\bm{y}_{\mathcal{E}, wvl}^{[l]}$ denotes the output of the wavelet encoder at layer $l$, $\mathcal{F}_{\mathcal{E}, wvl}^{[l]}(\cdot; \mathbf{\Theta}_{\mathcal{E}, wvl}^{[l]})$ denotes the function of the convolutional neural network followed by a ReLU activation at layer $l$ with trainable parameters $\mathbf{\Theta}_{\mathcal{E}, wvl}^{[l]}$. The input to the first wavelet encoder layer is the 2D wavelet decomposition subimages $\mathbb{J}_K$ . We leverage the subimages of wavelet coefficients $\mathbb{J}_K$ with a level of three obtained using Symlets wavelet as input to a three-layer CNN, enabling us to extract a condensed representation of the wavelet transform domain features, as demonstrated in previous works~\cite{sridhar2014wavelet, chen2013wavelet}. Our wavelet encoder is designed to construct an adaptive trainable and parametrized thresholding technique, in contrast to the soft and hard thresholding techniques that are widely used in prior literature~\cite{mgaga2019review, golilarz2017image, zhao2015improved}.

\subsection{Decoder}
The decoder of the network consists of a sequence of up-sampling layers that progressively increase the spatial dimensions of the input while decreasing the number of channels. The up-sampling process initiates with a 3x3 transpose convolution that employs 128 filters and a stride of 2, followed by a rectified linear unit (ReLU) activation function. This process is repeated in the next two layers, with 64 and 32 filters respectively. Finally, the last layer applies a 3x3 transpose convolution with a single filter and a sigmoid activation function to produce the gray-scale image.

The condition layer incorporates the compressed representation of the image and concatenates it with the adaptive compressed representation of the wavelet domain features. By integrating the conditional input, the decoder reconstructs data that is specific to the fingerprint scenario. The output of the encoder layer that takes the condition layer as input can be expressed as:

$$\bm{y}_{\mathcal{D}}^{[3]} =  \mathcal{F}_{\mathcal{D}}^{[3]} \left( \left[
\bm{y}_{\mathcal{E},{img}}^{[4]} \parallel \bm{y}_{\mathcal{E},{wvl}}^{[3]} \right]; \mathbf{\Theta}_{\mathcal{D}}^{[3]} \right),$$

where $\bm{y}_{\mathcal{D}}^{[3]}$ denotes the output of the decoder at layer 3, $\mathcal{F}_{\mathcal{D}}^{[3]}(\cdot; \mathbf{\Theta}_{\mathcal{D}}^{[3]})$ denotes the function of the convolutional neural network followed by a ReLU activation at layer 3 with trainable parameters $\mathbf{\Theta}_{\mathcal{D}}^{[3]}$ and $[ \cdot \parallel \cdot ]$ denotes the concatenation operation. The output of the last decoder layer is the denoised image $\hat{\bm{I}}(M,N) = \bm{y}_{\mathcal{D}}^{[L]}$.

% The output of this layer is then concatenated with the output of the fourth down-sampling layer from the encoder. The resulting tensor is then passed through another transpose convolution with 64 filters and a stride of 2, followed by a ReLU activation function. 
% The conditioned layer integrates the extracted spatial images and wavelet-transform domain features. We concatenate the image encoder output and wavelet encoder output serving as input for the decoder. 

In addition, the network utilizes residual connections between the image encoder and decoder blocks to enhance performance on intricate spatial details~\cite{zini2020deep, chatterjee2022improving}. These connections enable the network to transmit information from the image encoder to the decoder, while retaining crucial fingerprint image details. In particular, the output of each down-sampling block is concatenated with the output of the corresponding up-sampling block, which helps maintain spatial information and facilitates the network's ability to recover fine-grained details. The final decoder layer incorporates a bilinear interpolation technique to upsample the feature maps in the decoder blocks, thereby restoring the spatial resolution of the image. The output of each layer in the decoder can be represented as follows:
% The output of the image encoder and feature encoder in wavelet-transform domain are concatenated, serving as input into the decoder. We also use the residual connection based on the image encoder and decoder. 

$$\bm{y}_{\mathcal{D}}^{[l]} =  \mathcal{F}_{\mathcal{D}}^{[l]} \left( \left[
\bm{y}_{\mathcal{D}}^{[l + 1]} \parallel \bm{y}_{\mathcal{E},{wvl}}^{[l+1]} \right] ; \mathbf{\Theta}_{\mathcal{D}}^{[l]} \right) . $$

To enhance the generalizability of our model, we introduce a regularized cost function that incorporates Kullback–Leibler (KL) divergence regularization through the use of a prior distribution~\cite{kingma2015variational, marojevic2018measuring}. The regularized cost function for Res-WCAE is formulated as the expected loss over the training set using the $L^2$-norm, along with the expected loss over the model parameters using KL divergence, expressed as follows:

$$ \mathcal{L} \left( \mathbf{\Theta} \right) = \mathbb{E}_{\bm{I}} \left\| \bm{y}_{\mathcal{D}}^{[L]} - {\bm{I}} \right\|^2 + \lambda \mathbb{E}_{\bm{y}} D_{\text{KL}} \left( \bm{y}_{\mathcal{D}}^{[L]} \parallel \bm{I} \right) $$

where $\mathbf{\Theta}$ denotes all the trainable parameters, $\lambda D_{\text{KL}} \left( \bm{y}_{\mathcal{D}}^{[L]} \parallel \bm{I} \right)$ denotes the KL divergence of $\bm{y}_{\mathcal{D}}^{[L]}$ from prior distribution $\bm{I}$. The inclusion of KL divergence regularization in our model aims to prevent overfitting to a single training instance, analogous to adapting the target distribution performed by conventional backpropagation algorithms~\cite{yu2013kl, phan2020personalized}.

\section{Experiments, Results and Discussion}

% \subsection{Denoising using Dense Neural Network}
% Servings as a baseline denoising model, a dense neural network consists of two parts, an encoder and a decoder, designed to learn a compressed representation of the input data and to reconstruct the representation in the decoder. The encoder is a sequential model that consists of four fully connected layers followed by ReLU activation functions. The input to the encoder is a tensor with 9888 features, based on image size in our dataset, and the output of the encoder is a tensor with 16 features. The decoder is also a sequential model that consists of four fully connected layers followed by three ReLU activation functions and a Sigmoid activation function for the output layer, which is used to scale the output values between 0 and 1. The input to the decoder is a tensor with 16 features, and the output of the decoder is a tensor with 9888 features. 

% As depicted in Figure~\ref{fig:densenet_denoising_sample}(a), the baseline model can only recognize the overall regime of the fingerprint in the presence of high levels of noise, failing to accurately reconstruct the intricate features of the fingerprint pattern. This observation is further evidenced by the distribution of errors presented in Figure~\ref{fig:densenet_denoising_sample}(b). Although this denoising performance can serve as a baseline for comparision, it falls short of the preprocessing quality required for reliable recognition tasks. 

% % Figure environment removed

% \subsection{Denoising using Autoencoder}

% % Figure environment removed

The Sokoto Coventry Fingerprint Dataset (SOCOFing) was selected for the purpose of constructing and evaluating the models in this study. SOCOFing is a biometric fingerprint database that has been specifically designed for academic research purposes, as documented in~\cite{shehu2018sokoto}. The dataset is comprised of a total of 6,000 fingerprint images that were collected from 600 African subjects, as outlined in~\cite{shehu2018sokoto}. Figure~\ref{fig:denoising_comparison}(b) provides representative samples from the dataset. During the preprocessing stage, the images in the dataset were converted into grayscale images with a resolution of 103x96 pixels, as per standard practice. All images were originally stored in the .BMP format.

To ensure a reliable evaluation of our models, we partitioned the dataset into training, holdout validation, and testing sets in a 70:15:15 ratio. We initialized the weights and trained all neural network architectures from scratch using a mini-batch size of 32. The learning rate was set to 0.001 and the models were trained for a maximum of 200 iterations. In total, we trained and evaluated four neural network architectures, including dense neural network, Autoencoder, wavelet feature conditioned Autoencoder, and Res-WCAE. We selected models based on their performance on the validation set. Our findings show that Res-WCAE outperformed all other models and achieved state-of-the-art performance in the presence of all levels of noise. Figure~\ref{fig:denoising_comparison} (a) depicts the loss vs epoch, which showed moderate fluctuations due to the mini-batch training. We also evaluated the improved Peak Signal-to-Noise Ratio ($\Delta \textit{PSNR}$) relative to the PSNR of the noisy image ($\bm{J}(m, n)$). As illustrated in Figure~\ref{fig:denoising_comparison} (a) inset, the averaged improved PSNR was approximately 7.5 dB for a wide range of noise levels.

% Figure environment removed

% % Figure environment removed

Figure~\ref{fig:denoising_comparison}(a) showcases the effectiveness of the ResWCAE denoising model in reconstructing the intricate features of fingerprint patterns. Despite high levels of noise, the denoised samples still exhibit discernible miniatea, which highlights the model's ability to capture fine details. Notably, we varied the noise level $\sigma$ from 100 to 200, which is a wider range than that used in prior studies (0 to 100), thus demonstrating the robustness of our model.

We conduct a more  rigorous assessment of the denoising models using three evaluation metrics, including Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM), and Mean Squared Error (MSE). The models under study were a Res-WCAE, an autoencoder, and an added noise figure, which served as a baseline for comparison. The results of the study are summarized in Table~\ref{tab:performance_evaluation}. 

\begin{table}[ht]
% \begin{minipage}{0.55\linewidth}
\centering
\caption{Evaluation}
    \begin{tabular}{lccc}
    \toprule
    Model & \multicolumn{3}{c}{$\sigma = 100$} \\
     & PSNR & SSIM & MSE\\
    \midrule
    AWGN & 7.92 & 0.45 & 0.17\\
    Dense NN & 10.03 & 0.35 & 0.12\\
    Autoencoder & 12.77 & 0.69 & 0.06\\
    Res-WCAE & 17.88 & 0.79 & 0.02\\
    \toprule
    \end{tabular}
\label{tab:performance_evaluation}

% \caption{Evaluation}
%     \begin{tabular}{lcccc}
%     \toprule
%     Model & \multicolumn{2}{c}{$\sigma = 100$} & \multicolumn{2}{c}{$\sigma = 200$} \\
%      & PSNR & SSIM & PSNR & SSIM\\
%     \midrule
%     AWGN & 7.86 & 0.46 & 7.86 & 0.46\\
%     Model 2 & 18 & 19 & 20 & 21\\
%     Model 3 & 24 & 25 & 26 & 27\\
%     Res-WCAE & 30 & 31 & 32 & 33\\
%     \toprule
%     \end{tabular}
% \label{tab:performance_evaluation}

% \end{minipage}\hfill
% \begin{minipage}{0.4\linewidth}
% \centering
% \caption{Evaluation (Dataset~\cite{1})}
%     \begin{tabular}{ccc}
%     \toprule
%     Model & PSNR & SSIM \\
%     \midrule
%         Noisy & 7.86 & 0.46\\
%         Dense NN & 10.06 & 0.36\\
%         Autoencoder & 12.711 & 0.69\\ 
%         Res-WCAE & 17.06 & 0.75\\
%     \bottomrule
%     \end{tabular}
% \label{tab:performance_evaluation}
% \end{minipage}
\end{table}

The findings revealed that the ResWCAE model demonstrated superior denoising performance, as evidenced by the highest PSNR and SSIM values and the lowest MSE value. The autoencoder neural network model achieved intermediate performance, with higher PSNR and SSIM values than the noisy figure baseline but lower values than the ResWCAE. ResWCAE model also outperforms the state-of-the-art models applied in the field of fingerprint pattern denoising, including U-Finger model~\cite{prabhu2019u} and Fpd-m-net~\cite{adiga2019fpd}.

\section{Conclusion}
% [Placeholder] In this paper, we propose and evaluate a deep learning architecture, a Residual Wavelet-Conditioned Convolutional Autoencoder (Res-WCAE), to retrieve the underlying intricate and unique fingerprint features, dedicately developed for denoising heavily degraded biometric pattern images in the presence of significantly high levels of noise interference for images with capacitive sensing techniques.  We evaluate our model performance using two datasets consisting of AWGN and synthetic images~\cite{}. Our proposed approach exhibits both lightweight, accurate and robust features, thus making it a highly suitable candidate for deployment in practical scenarios, including small Internet of Things (IoT) devices.

In conclusion, the increasing popularity of biometric authentication in compact Internet of Things (IoT) devices has raised concerns about the reliability of such systems due to image quality issues, especially when dealing with high levels of noise. This paper addresses these challenges by introducing a novel and robust deep learning architecture called Residual Wavelet-Conditioned Convolutional Autoencoder (Res-WCAE) with Kullback-Leibler divergence (KLD) regularization, specifically designed for fingerprint image denoising. By leveraging two encoders - an image encoder and a wavelet encoder - along with residual connections and a compressed representation of features from the wavelet domain, Res-WCAE effectively preserves fine-grained spatial features, outperforming several state-of-the-art denoising methods, especially in heavily degraded fingerprint images with significant noise. The proposed Res-WCAE offers promising solutions for enhancing the reliability of biometric authentication systems in compact IoT devices, presenting a potential breakthrough in the field of image denoising and biometric pattern retrieval.

% Previous studies~\cite{bhattacharyya2009biometric, wayman2005introduction} have also highlighted the potential benefits of pattern-based biometric authentication, and we may explore using their results as baselines for our evaluation. 



\bibliographystyle{unsrt}
\bibliography{reference}
\end{document}