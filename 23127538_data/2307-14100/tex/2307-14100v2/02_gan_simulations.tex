\section{GAN simulations}
\label{sec:gan-simulations}

We use the framework presented in \citet{Kummer_2022,Rustige_2022} to improve the quality and authenticity of the simulated radio sources used as training data. The simulation technique is based on a generative model. Such models are able to learn the underlying statistical distribution of the data and can be used for simulations by sampling from this distribution. In our neural network-based setup a Generative Adversarial Network \citep{goodfellow2014generative,salimans2016improved} is trained in a supervised way on observations from the FIRST survey \citep{FIRST_1995}. The data was recorded by the Very Large Array (VLA) in New Mexico with a resolution of $5"$. The training data set of this generative model is presented in \citet{Griese_2023} and publicly available \citep{Griese_zenodo_2022}. The two neural networks in the standard GAN setup are called generator and discriminator. The generator generates fake images from a noise vector and the discriminator discriminates between real and fake images. Both are trained simultaneously in a two-player minimax game. Eventually, the generator learns to generate images, which are hardly distinguishable from the training images. The used setup is shown in \autoref{fig:wgan_schematic}.

Here, we employ an advanced version of the standard GAN setup, namely a Wasserstein GAN (wGAN). The  Wasserstein distance is used in the  main term of the loss function. The discriminator is replaced by a critic which is used to estimate the Wasserstein distance between real and generated images \citep{arjovsky2017wasserstein}. Additionally, both neural networks of our wGAN setup are conditioned on the morphological class label. Hence, the generator can be used to simulate images of specific classes.
For further development of our image reconstruction technique, we employ the generator of the wGAN trained for augmenting classifier training in \citet{Rustige_2022}. This setup can be used to simulate radio sources of four different morphological classes, namely FRI and FRII, which are used for this paper, and \enquote{bent} and \enquote{compact}. As the model was trained on FIRST images, the generated images have similar properties as the training set of the wGAN. For details of the model training we refer to \citet{Rustige_2022}. 

We simulate \num{30000} sources of the class FRI and \num{30000} sources of the class FRII to construct a data set which we split into a \num{5}:\num{1} ratio between training and validation data. Additionally, we simulate \num{10000} extra sources for the creation of a test data set, which are split into \num{5000} of the class FRI and \num{5000} of the class FRII. The morphological classes of the Fanaroff-â€“Riley classification scheme are distinguished based on the peak location and properties of the radio emission and are well-established in radio astronomy \citep{FR_1974}.
Note, for the simulation of each class a different generator model is used. Consequently, we make sure that the model is optimally chosen for the given class. 
The noise in the training data is reduced by setting all pixel values below three times the local root mean square (RMS) noise to the value of this threshold. Subsequently, the pixel values were rescaled to the range between -1 and 1 to represent floating point grayscale images. The generated images reproduce the preprocessed noise level of the training data inherently. The output size of the images is variable, but in the following we set it to $\SI{128}{\pixel} \times \SI{128}{\pixel}$. %The noise level of the generated images resembles the preprocessed noise level of the training data
However, the generated images require some postprocessing: Gaussian smoothing is applied to the images due to the fact that strong variations exist between neighboring pixels around the sources, i.e. we observe low-intensity pixels directly next to high-intensity pixels. The width of the Gaussian has to be chosen such that the peaks of the main sources are not smeared out and substructures in the images are not eradicated. We decided to use a width of $\sigma=\SI{0.75}{\pixel}$, which best fulfills the previously mentioned criteria. A comparison of different $\sigma$ values for the same exemplary, wGAN-generated source is shown in \autoref{fig:gaussian_filter}. 
After that, the sources are scaled between \SI{1}{\milli\jansky} and \SI{300}{\milli\jansky}. Thus, we ensure that the signal-to-noise ratios (SNRs) range between \num{1} and \num{100}.
SNRs are defined with the help of \texttt{WSCLEAN}.
We perform a cleaning until we reach the threshold of \SI{5}{\sigma}, see \texttt{auto-mask} option of \texttt{WSCLEAN}.
Afterward, we compare the maximum of the clean image with the standard deviation of the residual image.
Tests with different simulation options revealed that flux densities between \SI{1}{\milli\jansky} and \SI{300}{\milli\jansky} lead to SNRs between \num{1} and \num{100} in the simulated observations for our chosen setup.
A detailed analysis for data with different SNRs and additional information about the SNR calculation can be found in \autoref{sec:comparison_wsclean}.

% Figure environment removed