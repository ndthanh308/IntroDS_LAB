\FloatBarrier

\section{Future Work}
\label{sec:future-work}

We have demonstrated the potential of radio interferometric imaging using deep learning techniques.
Still some work needs to be done until this technique can be applied to real data. In particular, we will focus on two issues that we will discuss in the following.

\subsection{Uncertainty estimates}

% Figure environment removed

% Figure environment removed

%As with all data reconstruction, it is important to estimate the uncertainty.
%Currently, we are working on a way to quantify the uncertainty of the predicted real and imaginary reconstructions generated by the neural network models.

Our neural network should not only reconstruct images, but also estimate their uncertainty.
The uncertainty can be estimated by using a negative log likelihood $l_{\beta-NLL}$ as loss function, following \cite{loss-unc} and \cite{unc-icecube}:

\begin{align}
    l(x, y) &= \frac{\log \sigma^2(x)}{2} + \frac{\left(\mu(x) - y \right)^2}{2\sigma^2(x)} \\
    l_{\beta-NLL}(x, y) &= \mathrm{stop}\left(\sigma^{2\beta}\right) l(x, y)
\end{align}
Now, a Gaussian distribution is predicted for each pixel.
The neural network model introduced in \autoref{sec:dl_model} serves to predict the mean values, while a second convolutional network is used for the prediction of the variances.
Sampling from these Gaussian distributions quantifies the uncertainties in Fourier and in image space.

Hence, we are able to estimate the reconstruction error of source types, on which the neural network has not been trained.
This can be illustrated with the example of an image of a cat, see \autoref{fig:cat} (right).
First, we simulate the observation of the cat with the mask in Fourier space used above.
Afterwards, the gridded visibilities are evaluated with our model which was trained on the FIRST simulations, as explained in \autoref{sec:gan-simulations} and \autoref{sec:rime}.
Now we are able to create the mean reconstruction as well as the corresponding uncertainty map, see \autoref{fig:cat}.
It appears that the network is able to reconstruct parts of the left eye of the cat, but not much more since it has been trained on images with a completely different shape. Consequently, the uncertainty map highlights exactly those areas that are reconstructed. This means that the network is uncertain with its prediction, which is the expected behavior. This feature could help to detect unknown source shapes. 

Additionally, we tested our uncertainty approach on source distributions from the test data set introduced in \autoref{sec:evaluation}.
\autoref{fig:unc-radionets} visualizes the reconstruction and the corresponding uncertainty map.
Simulated source distribution (upper left) and deep learning reconstruction (upper right) are in good agreement.
By computing the difference map (lower right) between simulation and prediction, two problems become apparent.
The point source below the main part of the radio source is not reconstructed in the prediction of the neural network.
Simultaneously, the prediction shows a feature above the central radio source, which is an artifact in the reconstruction.
Both features are represented in the calculated uncertainty map (lower left).
Especially for the missing point source the intensity inside the uncertainty map is not high enough to cover the difference between simulation and prediction.
For the central source structure the uncertainty map covers the deviation between simulation and prediction as it is significantly lower.
In our future work, we will focus on improving the coverage of the actual difference for the uncertainty maps.

\subsection{Wide-field and survey data}

Modern radio interferometers have wide field-of-views and record multi-frequency data.
In future work, we will focus on enhancing our simulation chain to take these specifications into account.
One approach to improve the simulations to match sky survey data is to choose larger sky sections as input for the RIME formalism.
In addition to the central main source, we will simulate other sources around the pointing center of the simulated observation.
Thus, noise from bright neighboring sources will be taken into account in the visibility data.

In order to improve the deep learning-based imaging, we plan to exploit the spectral data of different frequency channels.
Since data does not vary much between neighboring channels, the reconstruction of the first channel constitutes a good initial guess for the reconstruction of
the second channel.
Processing this information inside the deep learning model has the potential to improve and speed up the reconstruction of data cubes significantly.

Furthermore, there is still potential to improve the reconstruction by enhancing the gridder.
Currently, our gridder creates a simple two-dimensional histogram, as explained in \autoref{sec:rime}.
This approach is different from established gridders that use convolutional gridding to facilitate subsequent imaging.
Especially in connection with the large field-of-views of modern sky surveys, wide-field gridding methods will also be relevant for imaging with deep learning techniques.

% \subsection{Observational data}

%In order to use the trained neural network to evaluate real measurement data, the difference between simulation and reality must be as small as possible.
%Taking into account all noise effects that occur in a radio interferometer measurement inside the simulations is from particular importance.

%If the mismatch between observation and simulation is too large, the neural network will have considerable difficulties in evaluating real measurements, which will lead to large uncertainties in the reconstructed intensity distributions.

% We use the neural network trained on the FIRST simulations to reconstruct a real VLA measurement.
% We have downloaded the \texttt{FITS} data from the VLA archive \footnote?
% For this, we took the observation of Zwcl 0634.1+4750 from  \cite{measurement}.
% Then, we applied the gridder developed in the \texttt{pyvisgen} package \citep{pyvisgen} to prepare the data for the neural network.

% % Figure environment removed

% \autoref{fig:first-obs} shows that, for now, the mismatch between our simulation and the measurement is too large for our network to be able to reconstruct a meaningful image. Especially the scales of the input data for the neural network differ considerably, which renders the reconstruction very difficult for the trained model.

% In follow-up work, we will focus on the reconstruction of real observation data and the influence of gridding on the reconstructed source distribution as well as minimizing the remaining data-simulation mismatches.