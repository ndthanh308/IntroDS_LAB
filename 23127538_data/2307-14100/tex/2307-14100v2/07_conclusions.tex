\section{Conclusions}
\label{sec:conclusions}

In this paper, we have focused on improving the training data for our neural network. To this end, we have produced realistic radio galaxy simulations and modeled the measurement process of a radio interferometer.

Our image simulation is based on the GAN developed in \cite{Kummer_2022,Rustige_2022}. The GAN can produce an arbitrary number of realistic images of radio galaxies that resemble images from the FIRST survey.

These radio sources are then used as input for the RIME formalism presented in \autoref{sec:rime}. We consider the phase delay and the antenna characteristics for the simulation process and also smear the simulated measurement with noise originating from the measurement process. Various parameters for a real measurement are also taken into account, such as the coordinates of the center of the FOV randomly, as shown in \autoref{tab:parameters-vla}.

The GAN-generated radio galaxies are processed through the RIME framework and then used as input for our neural network. The main neural network is the same as in \cite{Schmidt_2022} with small adjustments, such as twice the number of residual blocks. The training process runs smoothly, as shown in \autoref{fig:train_loss} and produces reconstructions that match the corresponding simulated sky simulation very well, as shown in \autoref{fig:compl_reco}.

To generalize the performance of the trained model, we evaluated the sources in image space using three methods that compare area, peak flux density, and integrated flux density. This was supplemented by a method adopted from the field of computer vision, which is called MS-SSIM. Each of these methods was applied to \num{10000} reconstructions from \texttt{radionets} and from \texttt{WSCLEAN}. The results are shown in \autoref{fig:hist-area} to \autoref{fig:hist-msssim}. While for the ratio of integrated flux densities, \texttt{radionets} and \texttt{WSCLEAN} perform equally well, \texttt{WSCLEAN} overestimates and underestimates for the areas and the MS-SSIM, respectively. The results for the peak flux densities for both methods vary widely due to resolution differences as shown in the comparison of the right images in \autoref{fig:image-pred} and \autoref{fig:reco_wsclean}. Overall we find that \texttt{radionets} is able to reconstruct far more complex source structures than in our previous paper, while only needing minor adjustments. Also, it performs at least as well as \texttt{WSCLEAN} for the main source properties. However, due to non-correctable beam-smearing effects and different effective resolutions, the comparison is not entirely fair.
%Also, \texttt{WSCLEAN} is, for the main part at least, not designed to analyze numerous images that differ in source properties.

Then, we divide up the results according to their SNR. The expectation is that for images with a high SNR the mean and standard deviations of our diagnostic methods are closer to their respective optimal values than for images with a lower SNR. This applies to both \texttt{radionets} and \texttt{WSCLEAN}. In \autoref{fig:mean-std-area} to \autoref{fig:mean-std-msssim}, one can see that this expectation holds in almost every case except for the peak flux densities, where the results are very close for every SNR besides 10. Thus, our network is robust and able to reconstruct complex structures despite a rather low SNR.

To summarize, we improved our simulations with two key features: (i) the GAN-generated radio galaxy images and (ii) the simulation of an interferometer measurement using RIME. With these two developments, we are able to train our network with more realistic data. As a result, the network is able to reconstruct the sources with similar accuracy compared to \texttt{WSCLEAN}, despite the increased complexity of the sources. Finally, the evaluation metrics suggest a better performance than the model in \cite{Schmidt_2022}.

Both frameworks, \texttt{pyvisgen} \citep{pyvisgen} for the simulation part and \texttt{radionets} \citep{radionets} for the model training, are available on GitHub. 
%In future work, we will focus on quantifying the uncertainties, as presented in \autoref{sec:future-work} and \autoref{fig:cat}. Uncertainty maps alongside the reconstructions will give an indication of untrained shapes. %Another focus will be to resolve the remaining data-simulation mismatches in order to be able to reconstruct real interferometric data.

Finally, we give an outlook on future features of our deep learning-based approach.
We focus on the estimation of the reconstruction error, as outlined in \autoref{fig:cat}, by extending the neural network such that it computes uncertainties as well as visibility reconstructions.
The second goal is the application of our deep learning-based imaging approach to actual observation data.
% Its application to the VLA observation of Zwcl 0634.1+4750 in \autoref{fig:first-obs} gives a glimpse of what can be done.
In the future, we will focus on the minimization of data-simulation mismatches to train deep learning models suitable to reconstruct survey data of large parts of the sky.
