\section{Introduction}
In modern astronomy, radio interferometry plays a unique role as it acquires the highest resolutions of astrophysical sources.
This resolution comes at the cost of low data coverage, which generates artifacts in the resulting source images.
Therefore, the cleaning of these artifacts is an unavoidable data processing tasks when dealing with radio interferometric data.

State-of-the-art radio interferometers, such as the LOw-Frequency ARray (LOFAR) \citep{lofar}, record terabytes of data per day.
This high data rate is expected to increase substantially for the Square Kilometre Array (SKA) \citep{ska}.
In order to analyze the large amounts of data on reasonable time scales, it is inevitable to adapt existing analysis strategies.
Here, machine learning techniques are a promising way to speed up and simplify existing imaging pipelines.
Especially deep learning, which is known for its fast execution times on image data, can accelerate the analysis of large data volumes.

In recent months, an increasing number of deep learning techniques have been applied to radio interferometer data.
Application examples include source detection techniques for three-dimensional Atacama Large Millimeter/submillimeter Array (ALMA) data \citep{alma_dl} and the resolution improvements of the Event Horizon Telescope's (EHT) image of the black hole in M87 using principal-component interferometric modeling (PRIMO) \citep{primo_m87}.

% Figure environment removed

We have developed a deep learning-based imaging approach for radio interferometric data published as the Python package \texttt{radionets} \citep{radionets}.
Our imaging approach uses convolutional neural networks known from super-resolution applications \citep{superres} to reconstruct missing visibility data from sparse radio interferometer layouts.
Consequently, our deep learning approach is no classical cleaning, as applied in the CLEAN algorithm \citep{clean}. Instead, we perform the data reconstruction directly in Fourier space.
The results presented in this paper build on our previous work \citep{Schmidt_2022}.
Here, we describe a new method to simulate images with generative adversarial networks (GANs), introduce an enhanced radio interferometer simulation chain based on the radio interferometer measurement equation (RIME) and improved diagnostics.

\autoref{fig:analysis-chain} provides an overview of all parts of our analysis chain. The training of deep learning models requires large amounts of training data which we provide by simulating radio galaxies in image space.
We utilize the GAN that was developed and trained by \citet{Kummer_2022,Rustige_2022} to create source distributions based on the Faint Images of the Radio Sky at Twenty-Centimeters (FIRST) survey \citep{FIRST_1995}.
In a second step, we employ the RIME framework to simulate radio interferometric observations of these sources.
The RIME simulation routine is made available in the python package \texttt{pyvisgen} \citep{pyvisgen}.
During this simulation step, the data is converted from image space into Fourier space, as radio interferometers measure complex visibilities.
We create training and validation data sets consisting of incomplete $uv$ planes.
Then, we train our neural network model to reconstruct the missing visibility data.
In the following step, dedicated test data sets are used to evaluate the reconstruction ability of the trained model.
By applying the inverse Fourier transformation to the reconstructed visibility data, we recover the source distribution in image space.
Thus we can compare the computed reconstruction to the simulated source distribution.
Furthermore, we evaluate the source reconstructions with different metrics, such as the area ratio or the intensity ratio between simulation and reconstruction.
A comparison with the established imaging software \texttt{WSCLEAN} \citep{wsclean} is performed to compare application times and reconstruction quality.

In \autoref{sec:gan-simulations}, we introduce the framework created by \citet{Kummer_2022,Rustige_2022} which provides the radio galaxy simulations. 
The additional simulation techniques used for creating visibilities are described in \autoref{sec:rime}.
\autoref{sec:dl_model} lists the changes done to our neural network model in comparison to \cite{Schmidt_2022} and the hyperparameters set for the training process.
In \autoref{sec:evaluation}, we explain our evaluation techniques.
Our upcoming projects and ideas are presented in \autoref{sec:future-work}.
In \autoref{sec:conclusions}, we summarize our results and conclude.