\appendix

\lstset{language=program}
\lstset{tabsize=3}
\newsavebox{\unnestedP}
\begin{lrbox}{\unnestedP}
\begin{lstlisting}[mathescape]
switch {
  case $\phi_{P,1}$: $\mathbf{x}:=F_{P,1}(\mathbf{x})$;$\delta_{P,1}$;
  $\cdots$
  case $\phi_{P,p}$: $\mathbf{x}:=F_{P,p}(\mathbf{x})$;$\delta_{P,p}$;
}
\end{lstlisting}
\end{lrbox}

\lstset{language=program}
\lstset{tabsize=3}
\newsavebox{\unnestedQ}
\begin{lrbox}{\unnestedQ}
\begin{lstlisting}[mathescape]
switch {
  case $\phi_{Q,1}$: $\mathbf{x}:=\mathbf{F}_{Q,1}(\mathbf{x})$;$\delta_{Q,1}$;
  $\cdots$
  case $\phi_{Q,q}$: $\mathbf{x}:=\mathbf{F}_{Q,q}(\mathbf{x})$;$\delta_{Q,q}$;
}
\end{lstlisting}
\end{lrbox}
% % Figure environment removed

\lstset{language=program}
\lstset{tabsize=3}
\newsavebox{\unnestedRsequential}
\begin{lrbox}{\unnestedRsequential}
\begin{lstlisting}[mathescape]
switch {
  $\cdots$
  case $\phi_{P,i}$: 
    $\mathbf{x}:=(\mathbf{F}_{P,i}(\mathbf{x}))$;
    $break$;($\mbox{if }\delta_{P,i}=\textbf{break}$)
  $\cdots$
  case $\phi_{P,i}\wedge \phi_{Q,j}[\mathbf{F}_{P,i}(\mathbf{x})/\mathbf{x}]$: 
    $\mathbf{x}:=\mathbf{F}_{Q,j} (\mathbf{F}_{P,i}(\mathbf{x}))$; 
    $\delta_{Q,j}$;($\mbox{if }\delta_{P,i}=\textbf{skip}$)
  $\cdots$
}
\end{lstlisting}
\end{lrbox}
% % Figure environment removed

\lstset{language=program}
\lstset{tabsize=3}
\newsavebox{\unnestedRconditional}
\begin{lrbox}{\unnestedRconditional}
\begin{lstlisting}[mathescape]
switch {
  $\cdots$
  case $\phi_{P,i}\wedge b$: 
    $\mathbf{x}:=\mathbf{F}_{P,i}(\mathbf{x})$;$\delta_{P,i}$;
  $\cdots$
  case $\phi_{Q,j}\wedge \neg b$: 
    $\mathbf{x}:=\mathbf{F}_{Q,j}(\mathbf{x})$;$\delta_{Q,j}$;
  $\cdots$
}
\end{lstlisting}
\end{lrbox}
\section{Process of transformation to canonical form}
\label{appendix:transform}
Here, we provide a detailed demonstration of how to transform the loop body $P$ of a non-nested affine program into its canonical form:

% Figure environment removed
\begin{itemize}
\item For the base case where the program $P$ is either a single affine assignment $\mathbf{x}:=\mathbf{F}(\mathbf{x})$ or resp. the \textbf{break} statement, the transformed program $\mathsf{C}_P$ is simply $\textbf{switch}~\{\textbf{case}~\mathbf{true}: \mathbf{x}:=\mathbf{F}(\mathbf{x}); 
\textbf{skip};\}$ or resp. $\textbf{switch}~\{\textbf{case}~\mathbf{true}: \mathbf{x}:=\mathbf{x}; \textbf{break};\}$, respectively.
\item For a sequential composition $R=P;Q$, the algorithm recursively computes $\mathsf{C}_P$ and $\mathsf{C}_Q$ as in Figure~\ref{fig:unnestedP} and Figure~\ref{fig:unnestedQ} respectively, and then compute $\mathsf{C}_R$ as in Figure~\ref{fig:unnestedRsequential} for which: 
\begin{itemize}
\item For each $1\le i\le p$ such that $\delta_{P,i}=\textbf{break}$, we have the branch $\mathbf{x}:=\mathbf{F}_{P,i}(\mathbf{x});\textbf{break};$ (i.e., the branch already breaks in the execution of $P$). 
\item For each $1\le i\le p$ and $1\le j\le q$ such that $\delta_{P,i}=\textbf{skip}$, we have the branch $\mathbf{x}:=\mathbf{F}_{Q,j} (\mathbf{F}_{P,i}(\mathbf{x})); \delta_{Q,j}$ under the branch condition $\phi_{P,i}\wedge (\phi_{Q,j}[\mathbf{F}_{P,i}(\mathbf{x})/\mathbf{x}])$ (i.e., the branch continues to the execution of $Q$). 
\end{itemize}
\item For a conditional branch $R=\textbf{if }b\textbf{ then }P\textbf{ else }Q$, the algorithm recursively computes $\mathsf{C}_P$ and $\mathsf{C}_Q$ as in the previous case, and then compute $\mathsf{C}_R$ as in Figure~\ref{fig:unnestedRconditional} for which: 
\begin{itemize}
\item For each $1\le i\le p$, we have the branch $\mathbf{x}=\mathbf{F}_{P,i}(\mathbf{x});\delta_{P,i};$ with branch condition $\phi_{P,i}\wedge b$ (i.e., the branch conditions of $P$ is conjuncted with the extra condition $b$). 
\item  For each $1\le j\le q$, we have the branch $\mathbf{x}=\mathbf{F}_{Q,j}(\mathbf{x});\delta_{Q,j};$ with branch condition $\phi_{Q,j}\wedge \neg b$ (i.e., the branch conditions of $Q$ is conjuncted with the extra condition $\neg b$).  
\end{itemize}
\end{itemize}

\section{Proof of Theorem~\ref{thr:infeasible}}
\label{app:thm_infeasible}
\par 
\textbf{Theorem}~\ref{thr:infeasible}. \textit{Let \(\Gamma\) be an ATS. For any AAM \(\eta\) that fulfills the initial and consecution conditions derived from the ATS \(\Gamma\) with the original constraints for the infeasible implication as in each consecution tabular of Figure~\ref{tab:farkascons} (aimed at \(-1>=0\)) with each $\mu$ in an infeasible implication instantiated as $k$ for some $k>0$, it is equivalent to set all $\mu$'s to $1$ while preserving the constraints of infeasible implication.}

To prove the theorem, for convenience, we denote the consecution tabular with $-1\geq 0$ as constraint consecution tabular and the consecution tabular without $-1\geq 0$ as transition consecution tabular. Then we prove that constraint consecution tabular is equivalent whether $\mu=1$ or $\mu=k,\forall k>0$.
% Figure environment removed

We scale the leftmost coefficient column $k$ to be $1,\lambda'_i$'s by multiplying $\frac{1}{k}$, where $\lambda'_i=\frac{\lambda_i}{k}$. The coefficient of invariants after transformation is the same as the previous tabular.

% Figure environment removed

Consider all the constraint consecution tabular and choose the maximum $k_{max}$ of their $k$'s. Then, we scale $\lambda_i$'s, $c_{l,i}$'s and $d_{\tsLoc}$ by $k_{max}$ and modify $\lambda'_0$ to be $\lambda''_0=\lambda'_0+\frac{k_{max}}{k}-1$. Note that it's necessary to select the fixed $k_{max}$ to scale $c_{l,i}$'s, so that we avoid affecting the solution in the transition consecution tabular as transition consecution tabular is always satisfied if we multiply $c$ with fixed constant $k_{max}$.

% Figure environment removed

Thus we prove there is no accuracy loss as we set $\mu=1$ by means of coefficient scaling.

In the implementation phase, we decompose the polyhedron derived from infeasible implications and subsequently union the resulting polytope and polyhedral cone into the final solution set. The validity of this methodology is further substantiated in Appendix~\ref{sec:appendix_minkowski}.

\section{Proof of correctness of solutions to invariant sets in the implementation part}\label{sec:appendix_minkowski}
\par
In the implementation, we utilize decomposition theorem of polyhedra and decompose the solution set of invariant when $\mu=1$ to be a polytope $P$ and a polyhedral cone $C$. Similarly, we denote $F$ as the solution set of invariants, which contains the coefficient of invariants at any locations and $F'$ as the solution set of invariants when $\mu=1$ in all the consecution tabular. Then the union of the polytope and polyhedral cone is chosen as our solution set of invariants $F^*=P\cup C$, where $F'=P+C$.

\begin{lemma}
    \textbf{Decomposition theorem of polyhedra.} A set $P$ of vectors in Euclidean space is a polyhedron if and only if $P=Q+C$ for some polytope $Q$ and some polyhedral cone $C$.
\end{lemma}

Now, we are going to prove the correctness of $F^*$. I.e., the vectors in polytope and polyhedral cone are both the coefficient of invariants in different locations.

Consider the relation between $F$ and $F'$, we define that $F''=\{k\cdot \boldsymbol{c}\mid \boldsymbol{c}\in F',k>0\}$.

\begin{proposition}
    $F=F''$
\end{proposition}
\begin{proof}
    We first consider $F\subseteq F''$, which equivalent to prove $\forall \boldsymbol{c}\in F, \exists \boldsymbol{c_0} \in F',k\in R$ such that $k\cdot \boldsymbol{c_0}=\boldsymbol{c}$. We consider the transition consecution tabular. Note that, the consecution tabular is always satisfied if we scale the invariant $\mathrm{\eta}(\tsLoc)$ and $\mathrm{\eta}(\tsLoc')$ simultaneously.

    Then consider the constraint consecution tabular. We have proved if we multiply $\boldsymbol{c_0}\in F'$ with $k_{max}$, we can find corresponding $\boldsymbol{c}=k_{max}*\boldsymbol{c_0}$ is the solution to constraint consecution tabular with $\mu=k,\forall k>0$. (the definition of $k_{max}$ and proof is given in Appendix~\ref{app:thm_infeasible})

    Thus, we prove that $\forall \boldsymbol{c}\in F$, there exists $\boldsymbol{c_0}\in F'$ and $k_{max}\in R$ such that $k_{max}*\boldsymbol{c_0}=\boldsymbol{c}$ and have $F\subseteq F''$. 

    Secondly, we prove $F''\subseteq F$. From the definition of $F''$, if $\boldsymbol{c}\in F'$, we multiply $\frac{1}{k}$ to $\mu=1$ in the constraint consecution tabular, and $k\cdot \boldsymbol{c}$ satisfy the transformed tabulars and other transition consecution tabulars. So $k\cdot \boldsymbol{c}\in F$, and we have $F''\subseteq F$.

    So $F=F''$.
\end{proof}

We utilize the decomposition theorem in $F'$ and have $F'=P+C$, where $P$ is a polytope and $C$ is a polyhedral cone. From the properties of polytope and polyhedral cone, a polytope is a convex hull of finitely many vectors and a polyhedral cone is finitely generated by some vectors.

\begin{equation}
    P=\{\boldsymbol{p_1},\boldsymbol{p_2},\ldots,\boldsymbol{p_n}\}
\end{equation}
\begin{equation}
    C=\{\boldsymbol{g_1},\boldsymbol{g_2},\ldots,\boldsymbol{g_m}\}
\end{equation}

Note that the addition in the theorem means Minkowski sum, Thus,
\begin{equation}
    F'=P+C=\{\boldsymbol{p_1},\boldsymbol{p_2},\ldots,\boldsymbol{p_n};\boldsymbol{g_1},\boldsymbol{g_2},\ldots,\boldsymbol{g_m}\}
\end{equation}

Where $\boldsymbol{p_i}$'s represents the vectors finitely generate the polytope $P$ and $g_i$'s represents the vectors finitely generate the polyhedral cone $C$. That means that $\forall v \in F'$, $v=a_1\boldsymbol{p_1}+\cdots+a_n \boldsymbol{p_n}+b_1 \boldsymbol{g_1}+\cdots + b_m \boldsymbol{g_m}$,where $\sum_i a_i=1$ (from the definition of convex hull) and $a_i,b_i\geq 0,\forall i$. Consider $F=F''=\{k\cdot \boldsymbol{c}\mid \exists k>0,k\cdot \boldsymbol{c}\in F,\boldsymbol{c}\in F'\}$, it's concluded that $\forall \boldsymbol{v} \in F, \boldsymbol{v}=a'_1\boldsymbol{p_1}+\cdots+a'_n \boldsymbol{p_n}+b'_1+\boldsymbol{g_1}+\cdots + b'_m \boldsymbol{g_m}$, where $a'_i=ka_i,k>0$ and $b'_i=kb_i,k>0$.

Thus, it's obvious that $\forall \boldsymbol{p}\in P$, we have $\boldsymbol{p}\in F$ as we can set $\boldsymbol{g_i}=0,\forall i$. However, we can not use the similar method to prove $\forall \boldsymbol{c} \in C,\boldsymbol{c}\in F$, as the $\sum_i a_i$ equal to a non-zero number and $a_i\geq 0, \forall i$. So to prove the $P\cup C$ is also the solution set of invariants, we should consider the practical implications of invariant.

We have known that $F=\{\boldsymbol{v}\mid \boldsymbol{v}=a'_1\boldsymbol{p_1}+\cdots+a'_n \boldsymbol{p_n}+b'_1 +_1+\cdots + b'_m \boldsymbol{g_m},a'_i\geq 0,\boldsymbol{g_i}\geq 0 \forall i,\sum_i a'_i>0\}$ corresponding to the solution of $\boldsymbol{v}^T x<=d_{\tsLoc}$.

Destruct $F$ to be 
\begin{equation}
    F=\{p+c\mid p=a'_1\boldsymbol{p_1}+\cdots+a'_n \boldsymbol{p_n},c=\boldsymbol{g_1}+\cdots + b'_m \boldsymbol{g_m},a'_i\geq 0,\boldsymbol{g_i}\geq 0 \forall i,\sum_i a'_i>0\}
\end{equation}

From the above conclusion, $P\subseteq F$, which means $\forall \boldsymbol{p} \in P$, $\boldsymbol{p}^T \boldsymbol{x}<=d_{\tsLoc}$ is satisfied. Also, $\forall \boldsymbol{v}\in F,\boldsymbol{v}=\boldsymbol{p}+\boldsymbol{c},\boldsymbol{p}\in P, \boldsymbol{c}\in C$, and $(\boldsymbol{p}+\boldsymbol{c})^T \boldsymbol{x}<=d_\tsLoc$. 

Consider $\forall \varepsilon>0$, we have $(\varepsilon \boldsymbol{p}+\boldsymbol{c})^T \boldsymbol{x}<=d_{\tsLoc}$. Thus, we finally conclude that $\lim_{\varepsilon \rightarrow 0} (\varepsilon \boldsymbol{p}+\boldsymbol{c})^T \boldsymbol{x}=\boldsymbol{c}^T \boldsymbol{x}<=d_{\tsLoc}$, which means for all $\boldsymbol{c}\in C$, $\boldsymbol{c}$ is also a solution to invariants. Thus we prove $C\in F$, and $P \cup C \in F$.

So it's correct to directly use the union of the polytope and the polyhedral cone to represents the solution set of invariants.