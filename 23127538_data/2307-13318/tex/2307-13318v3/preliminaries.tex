\section{Preliminaries}

We first recall affine transition systems~\cite{DBLP:conf/sas/SankaranarayananSM04} and invariants over them, and then the classical theorem of Farkas' Lemma and some basic knowledge in polyhedra theory. 
%generation over such model via Farkas' Lemma. In our invariant generation algorithm, we use affine transition systems as the abstract model for programs with affine conditions and updates. 
%We first present the necessary definitions for affine transition systems and invariants, and then the application of Farkas' Lemma to affine invariant generation. We relegate a detailed example to the next section.  


%In this section, we consider affine transition systems \LTSs{}~\cite{DBLP:conf/sas/SankaranarayananSM04} as underlying model for obtaining procedure summary via invariant generation. 
%A \LTS{} is composed of locations that corresponds to affine-program counter and affine transitions between locations that corresponds to affine updates and guards, which is suitable for modeling the executions of an affine program.
%We first state some basic definitions and then present the \LTSs{} with other auxiliary notions. 


\subsection{Affine Transition Systems and Invariants}

%To present affine transition systems, we first define several basic concepts related to affine inequalities as follows. 
%\paragraph{Affine (In)equalities and Assertions} 

To introduce affine transition systems, we need several basic concepts. An \emph{affine inequality} 
%(resp. \emph{affine equality}) 
over a set $V=\{x_1,\dots,x_n\}$ of real-valued variables is of the form $a_{1}x_{1} + \dots + a_{n}x_{n} + b \ge 0$, where $a_i$'s and $b$ are real coefficients, 
%and $\Join\ \in \{ \ge \}$.  
%(resp. $\Join\ \in \{ = \}$), respectively. 
An \emph{affine assertion} over $V$ is a conjunction of affine inequalities and equalities over $V$. %Moreover, 
A \emph{propositional affine predicate} (PAP) over $V$ is a propositional formula whose atomic propositions are affine inequalities and equalities over $V$. A PAP is in disjunctive (resp. conjunctive) normal form (DNF) (resp. CNF) if it is a finite disjunction of affine assertions (resp. a finite conjunction of finite disjunctions of affine assertions), respectively. 

%Note that we only consider non-strict no-smaller-than operator $\ge$ for affine inequalities, and the no-greater-than inequalities $\alpha \le \beta$ could be equivalently transformed into $-\alpha \ge -\beta$. Moreover, although an affine equality $\alpha = \beta$ could be equivalently expressed by the conjunction of the two inequalities $\alpha \le \beta$ and $\alpha \ge \beta$, we handle each affine equality directly since one can apply algorithmic optimizations to affine equalities. Below we present the definition of affine transition systems. 

An affine transition system possesses a finite number of locations and variables and specifies transitions between locations with affine guards and affine update on the values of the variables. 

\begin{definition}[Affine Transition Systems~\cite{DBLP:conf/sas/SankaranarayananSM04}]\label{def:lts}
%\paragraph{Affine Transition Systems~\cite{DBLP:conf/sas/SankaranarayananSM04}} 
An \emph{affine transition system} (\LTS) is a tuple $\Gamma=\langle \tsVars, \tsVars', \tsLocs, \tsTrans, \tsLoc^*, \tsInitcond \rangle$ for which:
\begin{itemize}
    \item 
    $\tsVars$ is a finite set of real-valued variables and $\tsVars'=\{\tsVar' \mid \tsVar \in \tsVars\}$ is the set of primed variables. %from $\tsVars$. 
    \item 
    $\tsLocs$ is a finite set of \emph{locations} and $\tsLoc^*\in\tsLocs$ is the initial location.
    \item 
    $\tsTrans$ is a finite set of \emph{transitions} where each transition $\tsTran$ is a triple $\langle \tsLoc, \tsLoc', \tsGuardcond \rangle$ from location $\tsLoc$ to location $\tsLoc'$ with the guard condition $\tsGuardcond$ as a PAP over $\tsVars \cup \tsVars'$.
    \item
    $\tsInitcond$ is a PAP in DNF over the variables $\tsVars$.  
\end{itemize}
The directed graph $\mbox{\sl DG}(\Gamma)$ of the \LTS{} $\Gamma$ is defined as the graph where the vertices are the locations of $\Gamma$ and there is an edge $(\tsLoc,\tsLoc')$ iff there is a transition $\langle \tsLoc, \tsLoc', \tsGuardcond \rangle$ with source location $\tsLoc$ and target location $\tsLoc'$.
\end{definition}

The intuition of an ATS $\Gamma=\langle \tsVars, \tsVars', \tsLocs, \tsTrans, \tsLoc^*, \tsInitcond \rangle$ is as follows. $\Gamma$ possesses locations $\tsLocs$ and variables $\tsVars$. 
Each variable $\tsVar \in \tsVars$ is mostly used to represent the current value of the variable 
%in the current execution step of the system 
and 
%$\tsVars'=\{\tsVar' \mid \tsVar \in \tsVars\}$ is the corresponding set of \emph{primed variables} such that 
each primed variable $\tsVar' \in \tsVars'$ is used to represent the next value of its unprimed variable $\tsVar \in \tsVars$ after one step of transition. Each transition $\langle \tsLoc, \tsLoc', \tsGuardcond \rangle$ specifies the jump from the current location $\tsLoc$ to the next location $\tsLoc'$ with the guard condition $\tsGuardcond$ specifying the condition to enable the transition. The guard condition involves both the current values (represented by $\tsVars$) and the next values (by $\tsVars'$), so that it can specify the relationship between the current and next values.  
Each clause of the PAP $\tsInitcond$ specifies an independent initial condition at the initial location $\tsLoc^*$. %to be processed separately.




%\smallskip
%\noindent{\em Valuations and Configurations.} 
Below we specify the semantics of an ATS. 
A \emph{valuation} over a finite set $V$ of variables 
%$\tsVars$ 
is a function $\tsEval : V \rightarrow \Rset$ that assigns to each variable $\tsVar \in V$ a real value $\tsEval(\tsVar) \in \Rset$. 
In this work, mostly we consider valuations over the variables $\tsVars$ of an \LTS{} and simply abbreviate ``valuation over $\tsVars$'' as ``valuation'' (i.e., omitting $\tsVars$). 
Given an \LTS, a \emph{configuration} is a pair $(\tsLoc, \tsEval)$ with the intuition that $\tsLoc$ is the current location and $\tsEval$ is a valuation that specifies the current values for the variables. 
%For the sake of convenience, we always assume an implicit linear order over the variable set $V$ and treat each valuation $\tsEval$ over $V$ equivalently as a real vector so that its $i$th coordinate $\tsEval[i]$ is the value for the $i$th variable in the linear order. 

%\smallskip
%\noindent{\em The Satisfaction Relation.} 
%We introduce the following satisfaction relations. 
Given an affine assertion $\tsAssertphi$ and a valuation $\tsEval$ over a variable set $V$, we write $\tsEval \models \tsAssertphi$ to mean that $\tsEval$ satisfies $\tsAssertphi$, i.e., $\tsAssertphi$ is true when one substitutes the corresponding values $\tsEval(\tsVar)$ to all the variables $\tsVar$ in $\tsAssertphi$. Given an \LTS{} $\Gamma$, two valuations $\tsEval,\tsEval'$ 
%(over $\tsVars$) 
and an affine assertion $\tsAssertphi$ over $\tsVars \cup \tsVars'$, we write $\tsEval, \tsEval' \models \tsAssertphi$ to mean that $\tsAssertphi$ is true when one substitutes every variable $\tsVar \in \tsVars$ by $\tsEval(\tsVar)$ and every variable $\tsVar' \in \tsVars'$ by $\tsEval'(\tsVar)$ in $\tsAssertphi$. Moreover, given two affine assertions $\tsAssertphi,\tsAssertpsi$ over a variable set $V$, we write $\tsAssertphi \models \tsAssertpsi$ to mean that $\tsAssertphi$ implies $\tsAssertpsi$, i.e., for every valuation $\tsEval$ over $V$ we have that $\tsEval \models \tsAssertphi$ implies $\tsEval \models \tsAssertpsi$.

%Below To describe the semantics of an \LTS{}, we further define the notions of valuations, configurations and their associated satisfaction relation as follows.

%\hongming{The semantics of affine transition systems is as follows.}
%\smallskip
%\noindent{\em The Semantics of affine transition systems.}
%Formally, 
The semantics of an \LTS{} $\Gamma$ is given by its  paths. 
A \emph{path} $\tsPath$ of the \LTS{} $\Gamma$ is a finite sequence of configurations $(\tsLoc_0,\tsEval_0) \dots (\tsLoc_k,\tsEval_k)$ such that 
\begin{itemize}
    \item(\textbf{Initialization}) $\tsLoc_0 = \tsLoc^*$ and $\tsEval_0 \models \tsInitcond$, and 
    \item(\textbf{Consecution}) for every $0 \le j \le k-1$, there exists a transition $\tsTran = \langle \tsLoc, \tsLoc', \tsGuardcond \rangle$ such that $\tsLoc = \tsLoc_{j}$, $\tsLoc' = \tsLoc_{j+1}$ and $\tsEval_{j},\tsEval_{j+1} \models \tsGuardcond$. 
\end{itemize}
We say that a configuration $(\tsLoc, \tsEval)$ is \emph{reachable} if there exists a path  $(\tsLoc_0,\tsEval_0) \dots (\tsLoc_k,\tsEval_k)$ such that $(\tsLoc_k,\tsEval_k)=(\tsLoc, \tsEval)$. Intuitively, a path starts with some legitimate initial configuration (as specified by \textbf{Initialization}) and proceeds by repeatedly applying the transitions to the current configuration (as described in \textbf{Consecution}). 
Thus, any path $\tsPath = (\tsLoc_0,\tsEval_0) \dots (\tsLoc_k,\tsEval_k)$ corresponds to a possible execution of the underlying \LTS{}. 
Informally, an \LTS{} starts at the initial location $\tsLoc^*$ with an arbitrary initial valuation $\tsEval^*$ such that $\tsEval^* \models \tsInitcond$, constituting an initial configuration $(\tsLoc_0,\tsEval_0)$; then at each step $j$ ($j \ge 0$), given the current configuration $(\tsLoc_j,\tsEval_j)$, the \LTS{} determines the next configuration $(\tsLoc_{j+1},\tsEval_{j+1})$ by first selecting a transition $\tsTran = \langle \tsLoc, \tsLoc', \tsGuardcond \rangle$ such that $\tsLoc = \tsLoc_j$ and then choosing $(\tsLoc_{j+1},\tsEval_{j+1})$ to be any configuration that satisfies $\tsLoc_{j+1}=\tsLoc'$ and $\tsEval_j,\tsEval_{j+1} \models \tsGuardcond$. 

In the following, we assume that the guard condition $\tsGuardcond$ of each transition in a \LTS{} is an affine assertion. This follows from the fact that one can always transform the guard condition into a DNF and then split the transition into multiple sub-transitions where the guard condition of each sub-transition is an affine assertion that is a disjunctive clause of the DNF. A small detail here is that to handle strict inequalities such as $\alpha<\beta$ which arise from taking the negation of a non-strict affine inequality, we either have the over-approximation $\alpha\le \beta$ or tighten it as $\alpha\le \beta-1$ in the integer case (i.e., every variable is integer valued, and every coefficient is an integer). 


    

% definition of invariants
We consider invariants over affine transition systems. 
%In this work, we consider algorithms for procedure summary via affine invariant generation that work on \LTSs{}. 
%The formal definition of invariants is as follows. 
%\smallskip
%\noindent{\em Invariants.} 
An \emph{invariant} at a location $\tsLoc$ of an \LTS{} is an assertion $\tsAssertphi$ such that for every path $\tsPath = (\tsLoc_0,\tsEval_0) \dots (\tsLoc_k,\tsEval_k)$ of the \LTS{} and each $0 \le i \le k$, it holds that $\tsLoc_i = \tsLoc$ implies $\tsEval_i \models \tsAssertphi$. An invariant $\tsAssertphi$ is \emph{affine} if $\tsAssertphi$ is an affine assertion over the variable set $\tsVars$, and is \emph{disjunctively affine} if $\tsAssertphi$ is a PAP in DNF. 
%over the variable set $\tsVars$. 
Intuitively, an invariant $\tsAssertphi$ at a location $\tsLoc$ is an assertion that over-approximates the set of reachable configurations at $\tsLoc$; the invariant is affine if it is in the form of an affine assertion, and disjunctively affine if it is a disjunction of affine assertions. 

In invariant generation, one often investigates a strengthened version of invariants called \emph{inductive invariants}. In this work, we present affine inductive invariants in the form of inductive affine assertion maps~\cite{DBLP:conf/cav/ColonSS03,DBLP:conf/sas/SankaranarayananSM04,oopsla22/scalable} as follows. 
%\noindent 
%{\em Inductive affine assertion maps.} 
An \emph{affine assertion map} (AAM) over an \LTS{} is a function $\tsMap$ that maps every location $\tsLoc$ of the \LTS{} to an affine assertion $\tsMap(\tsLoc)$ over the variables $\tsVars$. An AAM $\tsMap$ is called \emph{inductive} if the following holds:
\begin{itemize}
    \item (\textbf{Initialization})  $\tsInitcond \models \tsMap(\tsLoc^*)$;
    \item (\textbf{Consecution}) For every transition $\tsTran = \langle \tsLoc, \tsLoc', \tsGuardcond \rangle$, we have that $\tsMap(\tsLoc) \wedge \tsGuardcond \models \tsMap(\tsLoc')'$, where $\tsMap(\tsLoc')'$ is the affine assertion obtained by replacing every variable $\tsVar \in \tsVars$ in $\tsMap(\tsLoc')$ with its next-value counterpart $\tsVar' \in \tsVars'$.
\end{itemize}
Informally, an AAM is inductive if it is (i) implied by the initial condition given by $\tsInitcond$ at the initial location $\tsLoc^*$ (i.e., \textbf{Initialization}) and (ii) preserved under the application of every transition (i.e., \textbf{Consecution}). By a straightforward induction on the length of a path under an \LTS, one could verify that every affine assertion in an inductive AAM is indeed an invariant. In the rest of the work, we focus on the automated synthesis of inductive AAMs, and the disjunctive affine invariants are obtained by taking a disjunction of relevant affine assertions in an AAM. 

%Sometimes we need to consider the \LTS{} $\Gamma[\tsLoc,K]$ derived from an \LTS{} $\Gamma$, a location $\tsLoc$ of $\Gamma$ and a subset $K$ of valuations. In detail, the \LTS{} $\Gamma[\tsLoc,K]$ is obtained by having the location $\tsLoc$ as the only location, the self-loop transitions at $\tsLoc$ (i.e., transitions $\langle \tsLoc'', \tsLoc', \tsGuardcond \rangle$ in $\Gamma$ such that $\tsLoc''=\tsLoc'=\tsLoc$) as the only transitions, and the initial condition as the subset $K$\label{pg:selfloop}. Here we slightly abuse the type of the initial condition so that the initial condition can also be a subset of valuations. This will not cause any problem as we consider any initial condition equivalently as the set of valuations that satisfy it. 


% definition of the (affine) procedure summary problem
%\smallskip
%\noindent{\em Loop Summaries.}
In this work, we also encounter the notion of loop summary. Loop summary describes 
%is the classical subject to generate logical formulas that over-approximate 
the relationship between the input and output of a while loop. Given an \LTS{}, 
%that describes the execution of a while loop, 
we denote by $\tsVars_{\mathsf{in}}:=\{\tsVar_{\mathsf{in}}\mid \tsVar\in \tsVars\}$ a copy of input variables from $\tsVars$ and $\tsVars_{\mathsf{out}}:=\{\tsVar_{\mathsf{out}}\mid \tsVar\in \tsVars\}$ a copy of output variables. We write $\mathbf{x}_{\mathsf{in}}$ (resp. $\mathbf{x}_{\mathsf{out}}$) for the vector of input (resp. output) variables, respectively. 
With the designated termination location $\tsLoc_e$ at the end of a while loop, a loop summary  $\ProcSmry$\label{pg:loopsmry} is a logical formula $\ProcSmry(\mathbf{x}_{\mathsf{in}}, \mathbf{x}_{\mathsf{out}})$ with free variables $\mathbf{x}_{\mathsf{in}}, \mathbf{x}_{\mathsf{out}}$ 
such that for all paths $\tsPath = (\tsLoc_0,\tsEval_0) \dots (\tsLoc_k,\tsEval_k)$ such that $\tsLoc_k=\tsLoc_{e}$, we have $\ProcSmry(\tsEval_0, \tsEval_k)$. %In other words, a procedure summary for a LTS is a logical formula that over-approximates the input-output relationship w.r.t a given termination location. 
%consider an approach obtaining a procedure summary of a program via invariant generation. Informally, a procedure summary is the input-output relationship in the corresponding procedure. Note that, we only consider the intraprocedure summary which is the classical problem of automatically deriving the input-output relationship for a procedure without recursive calls. Then we present a formal notion for procedure summary.
%\paragraph{(Affine) Procedure Summary}
%A procedure summary denoted as $\ProcSmry$ is of the form $\bigcup_{i} \ProcSmryith$ where $\ProcSmryith := \psPrecond_{i} \wedge \psPostcond_{i}$ such that: 
%\begin{itemize}
%    \item 
%    $\psPrecond_{i}$ is the $i$-th (affine) input assertion over the variables $\tsVars$ at input location before executing the procedure; 
%    \item 
%    $\psPostcond_{i}$ is the $i$-th (affine) output assertion over the primed-variables $\tsVars'$ at output location after executing the procedure when the input corresponds to $\psPrecond_{i}$.
%\end{itemize}

%\begin{example}
%An example states the procedure summary under the Example~\ref{eg:realcode} ... \qed 
%\end{example}


% definition of invariants
%In this work, we consider algorithms for procedure summary via affine invariant generation that work on \LTSs{}. 


\subsection{Farkas' Lemma and Polyhedra}

Farkas' Lemma~\cite{FarkasLemma} is a classical theorem in the theory of affine inequalities and previous results ~\cite{DBLP:conf/cav/ColonSS03,DBLP:conf/sas/SankaranarayananSM04,oopsla22/scalable} have applied the theorem to affine invariant generation. In these results, the form of Farkas' Lemma follows 
%We follow a variant form of Farkas' Lemma
~\cite[Corollary 7.1h]{DBLP:books/daglib/0090562}.

% Farkas' Lemma
%By~\citet{DBLP:conf/cav/ColonSS03,DBLP:conf/sas/SankaranarayananSM04}, a sound and complete constraint-solving framework for affine invariant generation is proposed via Farkas' Lemma~\cite{FarkasLemma}. The use of Farkas' Lemma transforms the inductive condition for affine invariants equivalently into a system of quadratic constraints, by solving which one could obtain concrete affine invariants. We follow the presentation form of Farkas' Lemma by~\citet{DBLP:conf/cav/ColonSS03}.  

\begin{theorem}[Farkas' Lemma]\label{thr:farkas}
Consider an affine assertion $\tsAssertphi$ over a set $V=\{x_1,\dots, x_n\}$ of real-valued variables 
%in the form of a conjunction of the affine inequalities 
as in Figure~\ref{tsAssertphi in Farkas' Lemma}.
\noindent When $\tsAssertphi$ is satisfiable (i.e., there is a valuation over $V$ that satisfies $\tsAssertphi$), it implies an affine inequality $\tsAssertpsi$ as in Figure~\ref{tsAssertpsi in Farkas' Lemma} (i.e., $\tsAssertphi \models \tsAssertpsi$) if and only if there exist non-negative real numbers $\lambda_0, \lambda_1, \dots, \lambda_m$ such that 
(i) $c_j = \sum^{m}_{i=1} \lambda_{i} \cdot a_{ij}$ for all  $1 \le j \le n$, and 
(ii) $d = \lambda_0 + \sum^{m}_{i=1} \lambda_{i} \cdot b_{i}$ as in Figure~\ref{tab:farkas}. 
Moreover, $\tsAssertphi$ is unsatisfiable if and only if the inequality $-1 \geq 0$ (as $\tsAssertpsi$) can be derived from above.
\end{theorem}

% Figure environment removed

One direction of Farkas' Lemma is straightforward, as one easily sees that if we have a non-negative affine combination of the inequalities in $\tsAssertphi$ that can derive $\tsAssertpsi$, then it is guaranteed that $\tsAssertpsi$ holds whenever $\tsAssertphi$ is true. 
Farkas' Lemma further establishes that the other direction is also valid. In general, Farkas' Lemma simplifies the inclusion of a polyhedron inside a halfspace into the satisfiability of a system of affine inequalities. We refer to the case of unsatisfiable $\tsAssertphi$ with $\tsAssertpsi:=-1\ge 0$ in the statement of Theorem~\ref{thr:farkas} as \emph{infeasible implication}. 

%\begin{remark}\label{remark:OriginFarkas}
%In the statement of Farkas' Lemma above, if we strengthen an affine inequality $a_{j1}x_1 + \cdots + a_{jn}x_n + b_j \geq 0$ in $\tsAssertphi$ to equality (i.e., $a_{j1}x_1 + \cdots + a_{jn}x_n + b_j = 0$), then the theorem holds with the relaxation that we do not require $\lambda_j \ge 0$. This could be observed by first replacing the equality equivalent with both $a_{j1} x_1 + \cdots + a_{jn} x_n + b_j \ge 0$ and $a_{j1} x_1 + \cdots + a_{jn} x_n + b_j \le 0$, and then applying Farkas' Lemma. By similar arguments, the theorem statement holds upon changing multiple affine inequalities into equalities with the relaxation of non-negativity for their corresponding $\lambda_j$'s. 
%\end{remark}

The application of Farkas' Lemma can be visualized by the tabular form in Figure~\ref{tab:farkas} (taken from~\citet{DBLP:conf/cav/ColonSS03}), where $\Join_1,\dots,\Join_m \in \{=,\ge\}$ and we multiply $\lambda_0,\lambda_1,\dots,\lambda_m$ with their inequalities in $\tsAssertphi$ and sum up them together to get $\tsAssertpsi$. For $1 \le j \le m$, 
%if $\Join_j$ is $\ge$, 
we require $\lambda_j \ge 0$. 
%otherwise (i.e., $\Join_j$ is $=$) we do not impose restriction on $\lambda_j$. 

%To illustrate the application of Farkas' Lemma to invariant generation, we also recall several concepts from polyhedra theory. 
In the previous results, the infeasible implication is not handled. In this work, we present a way to handle this via a nontrivial manipulation of polyhedra. To this end, we recall basic concepts from polyhedra theory as follows. 

A subset $P$ of $\Rset^n$ is a \emph{polyhedron} if $P=\{\mathbf{x}\in \Rset^n\mid \mathbf{A}\cdot\mathbf{x}\le \mathbf{b}\}$ for some real matrix $A\in \Rset^{m\times n}$ and real vector $\mathbf{b}\in \Rset^m$, where $\mathbf{x}$ is treated as a column vector and the comparison $\mathbf{A}\cdot\mathbf{x}\le \mathbf{b}$ is defined in the coordinate-wise fashion. 
A polyhedron $P$ is a \emph{polyhedral cone} if $P=\{\mathbf{x}\in \Rset^n\mid \mathbf{A}\cdot\mathbf{x}\le \mathbf{0}\}$ for some real matrix $A\in \Rset^{m\times n}$, 
where $\mathbf{0}$ is the $m$-dimensional zero column vector. 
It is well-known from the Farkas-Minkowski-Weyl Theorem~\cite[Corollary 7.1a]{DBLP:books/daglib/0090562} that any polyhedral cone $P$ can be represented as $P=\{\sum_{i=1}^k \lambda_i\cdot \mathbf{g}_i\mid \lambda_i\ge 0 \mbox{ for all }1\le i\le k\}$ for some real vectors $\mathbf{g}_1,\dots,\mathbf{g}_k$, where such vectors $\mathbf{g}_i$'s are called a collection of \emph{generators} for the polyhedral cone $P$. 
%One can remove redundant generators (i.e., generators that can be expressed as a non-negative affine combination of other generators) via standard methods (such as affine programming~\cite[Chapter 10]{DBLP:books/daglib/0090562}) in polynomial time. 

%% The following is the omitted section, which should be reflected in the overview.

% The existing approaches~\cite{DBLP:conf/cav/ColonSS03,DBLP:conf/sas/SankaranarayananSM04,oopsla22/scalable} apply Farkas' Lemma to (conjunctive) affine invariant generation.  
% All these approaches follow the template-based paradigm as follows:

% \begin{itemize}
% \item Establish an affine template with unknown coefficients over the input \LTS{} that represents the inductive AAM to be solved. 
% \item Apply the initiation and consecution conditions to the template to obtain the constraints for an AAM. 
% \item Use Farkas' Lemma to simplify the constraints obtained in the previous step. %by removing one quantifier alternation in each constraint. 
% \item Solve the simplified constraints from the previous step to obtain concrete solutions to the unknown coefficients in the template. Each solution corresponds to one inductive AAM for the input \LTS{}. 
% \end{itemize}

% The technical details of the paradigm above are given as \textbf{Step A1} -- \textbf{Step A4} below. 
% We fix an input \LTS{} with variable set $\tsVars=\{\tsVar_1,\dots,\tsVar_n\}$.

% \smallskip
% \noindent{\textbf{Step A1.}} In the first step, all the existing approaches establish a template for an inductive AAM. A template $\tsMap$ involves an affine inequality $\tsMap(\tsLoc)= \tsCoefc_{\tsLoc,1} \cdot \tsVar_{1} + \dots + \tsCoefc_{\tsLoc,n} \cdot \tsVar_{n} + d \geq 0$ at each location $\tsLoc$ of the \LTS{} with the unknown coefficients $\tsCoefc_{\tsLoc,1},\dots,\tsCoefc_{\tsLoc,n}, d$ to be resolved. Note that, although there is only one template at each location, the approaches can obtain a conjunctive affine invariant where one solution of the unknown coefficients corresponds to one conjunctive affine inequality.
% % of affine inequalities in form of the template (we present an instantiation in Example~\ref{eg:farkasapplication}). 

% \smallskip
% \noindent{\textbf{Step A2.}} In the second step, all the approaches establish constraints from the initialization and the consecution conditions for an inductive invariant. Recall that the initialization condition specifies that the affine inequality $\tsMap(\tsLoc^*)$ at the initial location $\tsLoc^*$ should be implied by the initial condition $\tsInitcond$, i.e., $\tsInitcond \models \tsMap(\tsLoc^*)$, and the consecution condition specifies that every transition preserves the affine assertion map $\tsMap$, i.e., for every transition $\langle \tsLoc, \tsLoc', \tsGuardcond \rangle$ we have that $\tsMap(\tsLoc) \wedge \tsGuardcond \models \tsMap(\tsLoc')'$. 

% \smallskip
% \noindent{\textbf{Step A3.}} In the third step, all the approaches apply Farkas' Lemma to the constraints collected from the initialization condition $\tsInitcond \models \tsMap(\tsLoc^*)$ and the consecution condition $\tsMap(\tsLoc)\wedge \tsGuardcond \models \tsMap(\tsLoc')'$ for every transition $\langle \tsLoc, \tsLoc', \tsGuardcond \rangle$. 
% For initialization, we apply the tabular in Figure~\ref{tab:farkas} to obtain Figure~\ref{tab:farkasinit} which results in an affine assertion over the unknown coefficients $c_{\tsLoc^*,1},\dots,c_{\tsLoc^*,n},d$ and  the fresh variables $\lambda_{0},\lambda_{1},\dots, \lambda_{m}$. Similarly, the tabular applied to the consecution condition of a transition $\langle \tsLoc, \tsLoc', \tsGuardcond \rangle$ gives Figure~\ref{tab:farkascons} where in addition to $\lambda_j,c_{\tsLoc,j},d_{\tsLoc},c_{\tsLoc',j}, d_{\tsLoc'}$ we have a fresh variable $\mu$ as the non-negative multiplier for $\tsMap(\tsLoc)$. 
% Note that for the consecution condition, the constraint obtained is no longer affine since the fresh variable $\mu$ is multiplied to $\tsMap(\tsLoc)$ in the tabular.  
% % Figure environment removed

% \smallskip
% \noindent{\textbf{Step A4.}} In the last step, the (non-affine) constraints from the previous step are solved to obtain the concrete values for the unknown coefficients in $\tsMap$, so that a concrete inductive AAM would be obtained.
% It is from this point on that the existing approaches become diverse:
% \begin{itemize}
% \item By~\citet{DBLP:conf/cav/ColonSS03}, the non-affine constraints were solved through the complete but costly method of quantifier elimination; 
% \item By~\citet{DBLP:conf/sas/SankaranarayananSM04}, the non-affine constraints were solved through (i) several reasonable heuristics to guess possible values for the key parameter $\mu$ in Figure~\ref{tab:farkascons} so as to remove the non-linearity and obtain an affine under-approximation of the original non-affine constraints, and (ii) the generator computation over polyhedral cones to obtain the invariants. A major heuristic there is to guess possible values for $\mu$ through some practical rules such as factorization and setting $\mu$ manually to $0,1$ (where $0$ means an invariant local to the guard of the transition and $1$ means one incremental to the previous execution).   
% \item By~\citet{oopsla22/scalable}, a substantial improvement on the scalability to the approach by~\citet{DBLP:conf/sas/SankaranarayananSM04} is proposed by generating affine invariants one location at time. The main advantage of this approach is that redundant invariants can be detected more efficiently in the solving of the constraints.   
% \end{itemize}


