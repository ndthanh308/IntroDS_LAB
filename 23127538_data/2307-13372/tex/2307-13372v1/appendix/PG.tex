\label{apx: PG}
\restatePG
\begin{proof} The performance measure is given by,
\begin{align*}
   J(\pi_{\theta}) &= \E_{\traj \sim f(\traj ; \pi_{\theta})} [F(\traj)] = \sum_{\traj} f(\traj ; \pi_{\theta}) F(\traj)\\
\shortintertext{thus, the gradient with respect to $\theta$ is given by}
   \nabla_{\theta} J(\pi_{\theta}) &= \sum_{\traj} \nabla_{\theta} f(\traj ; \pi_{\theta}) F(\traj) 
\end{align*}
For any $p_{\theta}(\tau) \neq 0$ using log trick, $\nabla_{\theta} \log p_{\theta}(\tau) = \frac{\nabla_{\theta} p_{\theta}(\tau)}{p_{\theta}(\tau)}$ from standard calculus and the definition of $f(\tau;\pi_\theta)$ in \eq~\ref{eq: trajectory_distribution}, we can compute the gradient of the objective. Let us define $g(\traj; \pi_\theta) = \nabla_{\theta} (\log \prod_{i=0}^{\horizon-1}\pi_{\theta}(a_i|s_i))$ resulting in \cref{prop: score},
\begin{align*}
\nabla_{\theta} J(\pi_{\theta}) &= \sum_{\tau} f(\tau;\pi_\theta) \nabla_{\theta} (\log \prod_{i=0}^{\horizon-1}\pi_{\theta}(a_i|s_i)) F(\traj) = \sum_{\tau} f(\tau;\pi_\theta) g(\traj; \pi_\theta) F(\traj)\\
 &= \E_{\traj \sim f(\traj ; \pi_{\theta})} \left[ \left(\sum_{i=0}^{H-1} \nabla_{\theta} \log \pi_{\theta}(a_i|s_i) \right) F(\traj) \right] \numberthis\\
\end{align*}
Using marginal gain $F(s|\traj_{0:j}) = F(\traj_{0:j}\cup \{s\}) - F(\traj_{0:j})$ and telescopic sum $\sum_{j=0}^{H-1}F(s_{j+1}|\traj_{0:j}) = F(\traj) - F(s_0)$,
\begin{align*}
   \nabla_{\theta} J(\pi_{\theta}) &= \E_{\traj \sim f(\traj ; \pi_{\theta})} \left[ \left(\sum_{i=0}^{H-1} \nabla_{\theta} \log \pi_{\theta}(a_i|s_i) \right) \left(\sum_{j=0}^{H-1}F(s_{j+1}|\traj_{0:j}) + F(s_0)\right) \right] \\
    % \E\limits_{\traj \sim f(\traj ; \pi_{\theta})}  \left[  \left(\sum_{i=0}^{H-1} \nabla_{\theta} \log \pi_{\theta}(a_i|s_i) \right) \left( \sum_{j=0}^{H-1} F(s_{j+1}|\traj_{0:j}) + F(s_0) \right) \right] \\
    &= \E\limits_{\traj \sim f(\traj ; \pi_{\theta})} \left[ \sum\limits_{i=0}^{H-1} \nabla_{\theta} \log \pi_{\theta}(a_i|s_i) \left(\sum\limits_{j=0}^{H-1}F(s_{j+1}|\traj_{0:j}) + F(s_0) \right) \right]\\
    \intertext{For any function of partial trajectory up to $i$, $b'(\traj_{0:i})$, we have, $\sum\limits_{a_i}  \pi_{\theta}(a_i|s_i) \nabla_{\theta} \log \pi_{\theta}(a_i|s_i) b'(\traj_{0:i})$ $=  \sum\limits_{a_i} \nabla_\theta \pi_{\theta}(a_i|s_i) b'(\traj_{0:i}) = 0$. Thus one can subtract any history-dependent baseline without altering the gradient estimator,}
    &= \E\limits_{\traj \sim f(\traj ; \pi_{\theta})} \left[ \sum\limits_{i=0}^{H-1} \nabla_{\theta} \log \pi_{\theta}(a_i|s_i) \left(\sum\limits_{j=0}^{H-1}F(s_{j+1}|\traj_{0:j}) + F(s_0) - b'(\traj_{0:i}) \right) \right] \\
    &= \E_{\traj \sim f(\traj ; \pi_{\theta})} \left[ \sum_{i=0}^{H-1} \nabla_{\theta} \log \pi_{\theta}(a_i|s_i) \left(\sum_{j=i}^{H-1}F(s_{j+1}|\traj_{0:j})\right) \right]\\
    % &= \E_{\traj \sim f(\traj ; \pi_{\theta})} \left[ \sum_{i=0}^{H-1} \nabla_{\theta} \log \pi_{\theta}(a_i|s_i) \left(\sum_{j=i}^{H-1}F(s_{j+1}|\traj_{0:j})\right) \right]  \tag{Use Causality} \label{eqn: causality}\\
    \intertext{Finally, we can subtract a baseline again using a similar trick as above and we get the theorem statement:}
    &= \E_{\traj \sim f(\traj ; \pi_{\theta})} \left[ \sum_{i=0}^{H-1} \nabla_{\theta} \log \pi_{\theta}(a_i|s_i) \left(\sum_{j=i}^{H-1}F(s_{j+1}|\traj_{0:j}) - b(\traj_{0:i}) \right) \right]
\end{align*}
\end{proof}

