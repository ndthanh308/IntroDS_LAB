We introduced submodular reinforcement learning, a new modelling paradigm for sequential decision-making using submodular rewards. We presented an algorithm that exhibits strong empirical performance on this problem. We theoretically analysed the general problem, proving the first inapproximability result for \subrl. Despite the problem's NP-hardness, under simplified assumptions, we achieved a constant-factor approximation for the algorithm. We hope this work will expand the reach of the \RL community to embrace the broad class of submodular objectives and the modelling opportunities they offer.

