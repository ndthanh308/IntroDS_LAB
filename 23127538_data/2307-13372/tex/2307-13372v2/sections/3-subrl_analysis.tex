\looseness -1 We first show that the \subrl problem is hard to approximate in general.  
In particular, we establish a lower bound that implies \subrl cannot be approximated up to any constant factor in polynomial time, even for {\em deterministic} submodular MDPs. 
We prove this by reducing our problem to a known hard-to-approximate problem -- the submodular orienteering problem (\sop) \citep{chekuri_rg}.  
Since we focus on {\em deterministic} \smdp's, according to Proposition~\ref{prop:deterministicmarkov} and Proposition~\ref{prop:restatedetMDP}, it suffices to consider deterministic, Markovian policies. We now formally state the inapproximability result, 
% \vspace{-5mm}
\begin{restatable*}{theorm}{restateinapprox}\label{thm: inappx}
Let \opt be the optimal value and $\gamma>0$. Even for deterministic \smdp's, the \subrl problem is hard to approximate within a factor of $\Omega(\log^{1-\gamma} \opt)$ unless $\NP \subseteq \ZTIME(n^{polylog(n)})$. 
\end{restatable*} %\vspace{-0.5em}
Thus, under common assumptions in complexity theory \citep{chekuri_rg,Halperin2003inapprox}, the \subrl problem cannot be approximated in general to better than logarithmic factors, i.e., no algorithm can guarantee $J(\pi) \geq \frac{\opt}{\log^{1-\gamma}\opt}$ for all input instances of \subrl. The proof is in \cref{apx: inapprox}.
The significance of this result extends beyond submodular RL. As \subrl falls within the broader category of general non-Markovian reward functions, \cref{thm: inappx} implies that problems involving general set functions are similarly inapproximable, limited to logarithmic factors.

Since our inapproximability result is worst-case in nature, it does not rule out that interesting \subrl problems remain practically solvable. In the next section, we introduce a general algorithm that is efficiently implementable, recovers constant factor approximation under assumptions (\cref{sec: theory}) and is empirically effective as shown in an extensive experimental study (\cref{sec: experiments}).

% Our inapproximability result, while worst-case in nature, does not rule out that interesting \subrl problems may be practically solvable. 


% for any \subrl problem. %Under assumptions, the algorithm can recover a constant factor approximation \cref{sec: theory} and later we demonstrate the effectiveness of the algorithm in an extensive experimental study involving submodular rewards \cref{sec: experiments}.

% We demonstrate the effectiveness of the algorithm and its utility in an extensive experimental study involving submodular rewards.

% \remove{Since the inapproximability result we present is worst-case in nature, it does not rule out that interesting \subrl problems remain practically solvable. In the next section, we introduce a general algorithm that can be efficiently implemented for any \subrl problem. In \cref{sec: experiments}, we demonstrate the effectiveness of the algorithm and its utility in an extensive experimental study involving submodular rewards. Additionally, in \cref{sec: theory}, we establish that our algorithm enjoys a constant factor approximation under stronger assumptions on the Markov chain.}




