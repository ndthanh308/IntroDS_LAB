@INPROCEEDINGS{chekuri_rg,
  author={Chandra Chekuri and Pal, M.},
  booktitle={46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05)}, 
  title={A recursive greedy algorithm for walks in directed graphs}, 
  year={2005},
  volume={},
  number={},
  pages={245-253},
  doi={10.1109/SFCS.2005.9}}

@article{near_optimal_safe_cov,
  title={Near-Optimal Multi-Agent Learning for Safe Coverage Control},
  author={Prajapat, Manish and Turchetta, Matteo and Zeilinger, Melanie and Krause, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={14998--15012},
  year={2022}
}

@inproceedings{bian2017guaranteed,
  title={Guaranteed non-convex optimization: Submodular maximization over continuous domains},
  author={Bian, Andrew An and Mirzasoleiman, Baharan and Buhmann, Joachim and Krause, Andreas},
  booktitle={Artificial Intelligence and Statistics},
  pages={111--120},
  year={2017},
  organization={PMLR}
}

@article{karimi2017stochastic,
  title={Stochastic submodular maximization: The case of coverage functions},
  author={Karimi, Mohammad and others},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}


@inproceedings{asadpour2008stochastic,
  title={Stochastic submodular maximization},
  author={Asadpour, Arash and Nazerzadeh, Hamid and Saberi, Amin},
  booktitle={Internet and Network Economics: 4th International Workshop, WINE 2008, Shanghai, China, December 17-20, 2008. Proceedings 4},
  pages={477--489},
  year={2008},
  organization={Springer}
}

@article{bian2017continuous,
  title={Continuous dr-submodular maximization: Structure and algorithms},
  author={Bian, An and Levy, Kfir and Krause, Andreas and Buhmann, Joachim M},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{Chen2017InteractiveSB,
  title={Interactive Submodular Bandit},
  author={Lin Chen and Andreas Krause and Amin Karbasi},
  booktitle={NIPS},
  year={2017}
}

@article{YisongLSB,
  title={Linear submodular bandits and their application to diversified retrieval},
  author={Yue, Yisong and Guestrin, Carlos},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  year={2011}
}

@article{hassani2017gradient,
  title={Gradient methods for submodular maximization},
  author={Hassani, Hamed and Soltanolkotabi, Mahdi and Karbasi, Amin},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{bhandari2021linear,
  title={On the linear convergence of policy gradient methods for finite mdps},
  author={Bhandari, Jalaj and Russo, Daniel},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2386--2394},
  year={2021},
  organization={PMLR}
}

@article{zahavy2021reward,
  title={Reward is enough for convex MDPs},
  author={Zahavy, Tom and O'Donoghue, Brendan and Desjardins, Guillaume and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={25746--25759},
  year={2021}
}

@article{gorilla-kagwene,
author = {Funwi-gabga, Neba and Mateu, Jorge},
year = {2011},
month = {08},
pages = {},
title = {Understanding the nesting spatial behaviour of gorillas in the Kagwene Sanctuary, Cameroon},
volume = {26},
journal = {Stochastic Environmental Research and Risk Assessment},
doi = {10.1007/s00477-011-0541-1}
}

@article{mojmir-cox,
  author    = {Mojm{\'{\i}}r Mutn{\'{y}} and
               Andreas Krause},
  title     = {Sensing Cox Processes via Posterior Sampling and Positive Bases},
  journal   = {CoRR},
  volume    = {abs/2110.11181},
  year      = {2021},
  url       = {https://arxiv.org/abs/2110.11181},
  eprinttype = {arXiv},
  eprint    = {2110.11181},
  timestamp = {Thu, 28 Oct 2021 15:25:31 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2110-11181.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{prajapat2021competitive,
  title={Competitive policy optimization},
  author={Prajapat, Manish and Azizzadenesheli, Kamyar and Liniger, Alexander and Yue, Yisong and Anandkumar, Anima},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={64--74},
  year={2021},
  organization={PMLR}
}

@article{Liniger2017OptimizationBasedAR,
  title={Optimization-Based Autonomous Racing of 1: 43 Scale RC Cars},
  author={Alexander Liniger and Alexander Domahidi and Manfred Morari},
  journal={Optimal Control Applications and Methods},
  volume={36},
  number={5},
  pages={628--647},
  year={2015}
}
@inproceedings{schulman2015highdimensional,
  author    = {John Schulman and Philipp Moritz and
               Sergey Levine and
               Michael I. Jordan and
               Pieter Abbeel},
  title     = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
  booktitle = {4th International Conference on Learning Representations, {ICLR}},
  year      = {2016},
  timestamp = {Thu, 25 Jul 2019 14:25:38 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanMLJA15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{baird1993,
  author    = {Baird, III, Leemon C},
  title     = {Advantage Updating},
  journal   = {WRIGHT LAB WRIGHT-PATTERSON AFB OH},
  year      = {1993},
}

@inproceedings{Halperin2003inapprox,
author = {Halperin, Eran and Krauthgamer, Robert},
title = {Polylogarithmic Inapproximability},
year = {2003},
isbn = {1581136749},
publisher = {Association for Computing Machinery},
doi = {10.1145/780542.780628},
abstract = {We provide the first hardness result of a polylogarithmic approximation ratio for a natural NP-hard optimization problem. We show that for every fixed ε>0, the GROUP-STEINER-TREE problem admits no efficient log2-ε k approximation, where k denotes the number of groups (or, alternatively, the input size), unless NP has quasi polynomial Las-Vegas algorithms. This hardness result holds even for input graphs which are Hierarchically Well-Separated Trees, introduced by Bartal [FOCS, 1996]. For these trees (and also for general trees), our bound is nearly tight with the log-squared approximation currently known. Our results imply that for every fixed ε>0, the DIRECTED-STEINER TREE problem admits no log2-ε n--approximation, where n is the number of vertices in the graph, under the same complexity assumption.},
booktitle = {Proceedings of the Thirty-Fifth Annual ACM Symposium on Theory of Computing},
pages = {585–594},
numpages = {10},
keywords = {Steiner tree, integrality ratio, polylogarithmic approximation, approximation algorithms, hardness of approximation},
location = {San Diego, CA, USA},
series = {STOC '03}
}

@article{krause2014submodular,
  title={Submodular function maximization.},
  author={Krause, Andreas and Golovin, Daniel},
  journal={Tractability},
  volume={3},
  pages={71--104},
  year={2014}
}

@article{bilmes2022submodularity,
  title={Submodularity in machine learning and artificial intelligence},
  author={Bilmes, Jeff},
  journal={arXiv preprint arXiv:2202.00132},
  year={2022}
}

@PhdThesis{Duff2002,
  author = {Duff, Michael O'Gordon},
  school = {University of Massachusetts Amherst},
  title  = {Optimal learning: Computational procedures for Bayes -adaptive Markov decision processes},
  year   = {2002},
}

@inproceedings{Mutny2023,
  title={Active exploration via experiment design in markov chains},
  author={Mutny, Mojmir and Janik, Tadeusz and Krause, Andreas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={7349--7374},
  year={2023},
  organization={PMLR}
}

@InProceedings{Mutny2022,
  author    = {Mojm\'{i}r Mutn\'{y} and Andreas Krause},
  booktitle = {Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  title     = {Sensing Cox Processes via Posterior Sampling and Positive Bases},
  year      = {2022},
  abstract  = {We study adaptive sensing of Cox point processes, a widely used model from spatial statistics. We introduce three tasks: maximization of captured events, search for the maximum of the intensity function and learning level sets of the intensity function. We model the intensity function as a sample from a truncated Gaussian process, represented in a specially constructed positive basis. In this basis, the positivity constraint on the intensity function has a simple form. We show how the \emph{minimal description positive basis} can be adapted to the covariance kernel, to non-stationarity and make connections to common positive bases from prior works. Our adaptive sensing algorithms use Langevin dynamics and are based on posterior sampling (\textsc{Cox-Thompson}) and top-two posterior sampling (\textsc{Top2}) principles. With latter, the difference between samples serves as a surrogate to the uncertainty. We demonstrate the approach using examples from environmental monitoring and crime rate modeling, and compare it to the classical Bayesian experimental design approach.},
  date      = {2020},
  url       = {https://arxiv.org/abs/2110.11181},
}


@InProceedings{Mutny2021a,
  author    = {Mutn\'{y},Mojm\'{i}r and Krause, Andreas},
  booktitle = {Proc. International Conference for Machine Learning (ICML)},
  title     = {No-regret Algorithms for Capturing Events in Poisson Point Processes},
  year      = {2021},
  abstract  = {Inhomogeneous Poisson point processes are widely used  models of event occurrences. We address \emph{adaptive sensing of Poisson Point processes}, namely, maximizing the number of captured events subject to sensing costs. We encode prior assumptions on the rate function by modeling it as a member of a known \emph{reproducing kernel Hilbert space} (RKHS). By partitioning the domain into separate small regions, and using heteroscedastic linear regression, we propose a tractable estimator of Poisson process rates for two feedback models: \emph{count-record}, where exact locations of events are observed, and \emph{histogram} feedback, where only counts of events are observed. We derive provably accurate anytime confidence estimates for our estimators for sequentially acquired Poisson count data. Using these, we formulate algorithms based on optimism that provably incur sublinear count-regret. We demonstrate the practicality of the method on problems from crime modeling, revenue maximization as well as environmental monitoring.},
  url       = {http://proceedings.mlr.press/v139/mutny21a/mutny21a.pdf},
}

@InProceedings{Mutny2022b,
  author    = {Mutn\'y, Mojm\'ir and Andreas Krause},
  booktitle = {Proc. Neural Information Processing Systems (NeurIPS)},
  title     = {Experimental Design of Linear Functionals in Reproducing Kernel Hilbert Spaces},
  year      = {2022},
  month     = nov,
  abstract  = {Optimal experimental design seeks to determine the most informative allocation of experiments  to infer an unknown statistical quantity. In this work, we investigate optimal design of experiments for {\em estimation of linear functionals in reproducing kernel Hilbert spaces (RKHSs)}. This problem has been extensively studied in the linear regression setting
 under an estimability condition, which allows estimating parameters without bias. We generalize this framework to RKHSs, and allow for the linear functional to be only approximately inferred, i.e., with a fixed bias. This scenario captures many important modern applications such as estimation of gradient maps, integrals and solutions to differential equations. We provide algorithms for constructing bias-aware designs for linear functionals. We derive non-asymptotic confidence sets for fixed and adaptive designs under sub-Gaussian noise, enabling us to certify estimation with bounded error with high probability.},
  url       = {https://arxiv.org/abs/2205.13627},
}


@InProceedings{Hazan2019,
  author       = {Hazan, Elad and Kakade, Sham and Singh, Karan and Van Soest, Abby},
  booktitle    = {International Conference on Machine Learning},
  title        = {Provably efficient maximum entropy exploration},
  year         = {2019},
  organization = {PMLR},
  pages        = {2681--2691},
}


@InProceedings{Zahavy2021,
  author    = {Tom Zahavy and Brendan O’Donoghue and Guillaume Desjardins and Satinder Singh},
  booktitle = {35th Conference on Neural Information Processing Systems (NeurIPS 2021)},
  title     = {Reward is enough for convex MDPs},
  year      = {2021},
}


@Article{Belogolovsky2021,
  author  = {Stav Belogolovsky and Philip Korsunsky and Shie Mannor and Chen Tessler and Tom Zahavy},
  journal = {Machine Learning},
  title   = {Inverse reinforcement learning in contextual MDPs},
  year    = {2021},
}

@InProceedings{Tarbouriech2019,
  author    = {Tarbouriech, Jean and Lazaric, Alessandro},
  booktitle = {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  title     = {Active Exploration in Markov Decision Processes},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Sugiyama, Masashi},
  month     = {16--18 Apr},
  pages     = {974--982},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {89},
  abstract  = {We introduce the active exploration problem in Markov decision processes (MDPs). Each state of the MDP is characterized by a random value and the learner should gather samples to estimate the mean value of each state as accurately as possible. Similarly to active exploration in multi-armed bandit (MAB), states may have different levels of noise, so that the higher the noise, the more samples are needed. As the noise level is initially unknown, we need to trade off the exploration of the environment to estimate the noise and the exploitation of these estimates to compute a policy maximizing the accuracy of the mean predictions. We introduce a novel learning algorithm to solve this problem showing that active exploration in MDPs may be significantly more difficult than in MAB. We also derive a heuristic procedure to mitigate the negative effect of slowly mixing policies. Finally, we validate our findings on simple numerical simulations.},
  pdf       = {http://proceedings.mlr.press/v89/tarbouriech19a/tarbouriech19a.pdf},
  url       = {https://proceedings.mlr.press/v89/tarbouriech19a.html},
}


@InProceedings{tarbouriech2020active,
  author       = {Tarbouriech, Jean and Shekhar, Shubhanshu and Pirotta, Matteo and Ghavamzadeh, Mohammad and Lazaric, Alessandro},
  booktitle    = {Conference on Uncertainty in Artificial Intelligence},
  title        = {Active model estimation in markov decision processes},
  year         = {2020},
  organization = {PMLR},
  pages        = {1019--1028},
}


@article{mutti2022challenging,
  title={Challenging common assumptions in convex reinforcement learning},
  author={Mutti, Mirco and De Santi, Riccardo and De Bartolomeis, Piersilvio and Restelli, Marcello},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4489--4502},
  year={2022}
}

@Book{Szepesvari2020,
  author    = {Csaba Szepesvari and Tor Lattimore},
  publisher = {Cambridge University Press},
  title     = {Bandit Algorithms},
  year      = {2020},
}

@Article{Wang2020,
  author        = {Ruosong Wang and Simon S. Du and Lin F. Yang and Ruslan Salakhutdinov},
  journal       = {CoRR},
  title         = {On Reward-Free Reinforcement Learning with Linear Function Approximation},
  year          = {2020},
  volume        = {abs/2006.11274},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2006-11274.bib},
  eprint        = {2006.11274},
  timestamp     = {Tue, 23 Jun 2020 17:57:22 +0200},
  url           = {https://arxiv.org/abs/2006.11274},
}

@Article{chaloner1995bayesian,
  author    = {Chaloner, Kathryn and Verdinelli, Isabella},
  journal   = {Statistical Science},
  title     = {Bayesian experimental design: A review},
  year      = {1995},
  pages     = {273--304},
  publisher = {JSTOR},
}

@Article{Golovin2011,
  author     = {Golovin, Daniel and Krause, Andreas},
  title      = {Adaptive Submodularity: Theory and Applications in Active Learning and Stochastic Optimization},
  journal    = {J. Artif. Int. Res.},
  year       = {2011},
  volume     = {42},
  number     = {1},
  month      = sep,
  pages      = {427--486},
  issn       = {1076-9757},
  url        = {http://dl.acm.org/citation.cfm?id=2208436.2208448},
  acmid      = {2208448},
  address    = {USA},
  issue_date = {September 2011},
  numpages   = {60},
  publisher  = {AI Access Foundation},
}

@inproceedings{greedy-supermodular,
  title={Guarantees for greedy maximization of non-submodular functions with applications},
  author={Bian, Andrew An and Buhmann, Joachim M and Krause, Andreas and Tschiatschek, Sebastian},
  booktitle={International conference on machine learning},
  pages={498--507},
  year={2017},
  organization={PMLR}
}

@article{nemhauser1978analysis,
  title={An analysis of approximations for maximizing submodular set functions—I},
  author={Nemhauser, George L and Wolsey, Laurence A and Fisher, Marshall L},
  journal={Mathematical programming},
  volume={14},
  number={1},
  pages={265--294},
  year={1978},
  publisher={Springer}
}


@InProceedings{Vanchinathan2015,
  author    = {Vanchinathan, Hastagiri P and Marfurt, Andreas and Robelin, Charles-Antoine and Kossmann, Donald and Krause, Andreas},
  booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  title     = {Discovering valuable items from massive data},
  pages     = {1195--1204},
  year      = {2015},
}


@InProceedings{Jaggi13,
  author    = {Jaggi, Martin},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning},
  title     = {Revisiting {Frank-Wolfe}: Projection-Free Sparse Convex Optimization},
  year      = {2013},
  address   = {Atlanta, Georgia, USA},
  editor    = {Dasgupta, Sanjoy and McAllester, David},
  month     = {17--19 Jun},
  number    = {1},
  pages     = {427--435},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {28},
  abstract  = {We provide stronger and more general primal-dual convergence results for Frank-Wolfe-type algorithms (a.k.a. conditional gradient) for constrained convex optimization, enabled by a simple framework of duality gap certificates. Our analysis also holds if the linear subproblems are only solved approximately (as well as if the gradients are inexact), and is proven to be worst-case optimal in the sparsity of the obtained solutions.    On the application side, this allows us to unify a large variety of existing sparse greedy methods, in particular for optimization over convex hulls of an atomic set, even if those sets can only be approximated, including sparse (or structured sparse) vectors or matrices, low-rank matrices, permutation matrices, or max-norm bounded matrices.    We present a new general framework for convex optimization over matrix factorizations, where every Frank-Wolfe iteration will consist of a low-rank update, and discuss the broad application areas of this approach.},
  pdf       = {http://proceedings.mlr.press/v28/jaggi13.pdf},
  url       = {https://proceedings.mlr.press/v28/jaggi13.html},
}

@inproceedings{lindner2021information,
	Author = {Lindner, David and Turchetta, Matteo and Tschiatschek, Sebastian and Ciosek, Kamil and Krause, Andreas},
	Blog = {https://las.inf.ethz.ch/information-directed-reward-learning},
	Booktitle = {Proc. Neural Information Processing Systems (NeurIPS)},
	Month = {December},
	Title = {Information Directed Reward Learning for Reinforcement Learning},
	Video = {https://www.youtube.com/watch?v=1RpiZrxhV90},
	Year = {2021}}


@article{golovin2011adaptive,
  title={Adaptive submodularity: Theory and applications in active learning and stochastic optimization},
  author={Golovin, Daniel and Krause, Andreas},
  journal={Journal of Artificial Intelligence Research},
  volume={42},
  pages={427--486},
  year={2011}
}
@article{dolhansky2016deep,
  title={Deep submodular functions: Definitions and learning},
  author={Dolhansky, Brian W and Bilmes, Jeff A},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@inproceedings{balcan2011learning,
  title={Learning submodular functions},
  author={Balcan, Maria-Florina and Harvey, Nicholas JA},
  booktitle={Proceedings of the forty-third annual ACM symposium on Theory of computing},
  pages={793--802},
  year={2011}
}

@inproceedings{Singh2009,
author = {Singh, Amarjeet and Krause, Andreas and Kaiser, William J.},
title = {Nonmyopic Adaptive Informative Path Planning for Multiple Robots},
year = {2009},
address = {San Francisco, CA, USA},
abstract = {Many robotic path planning applications, such as search and rescue, involve uncertain environments with complex dynamics that can be only partially observed. When selecting the best subset of observation locations subject to constrained resources (such as limited time or battery capacity) it is an important problem to trade off exploration (gathering information about the environment) and exploitation (using the current knowledge about the environment most effectively) for efficiently observing these environments. Even the nonadaptive setting, where paths are planned before observations are made, is NP-hard, and has been subject to much research.In this paper, we present a novel approach to adaptive informative path planning that addresses this exploration-exploitation tradeoff. Our approach is nonmyopic, i.e. it plans ahead for possible observations that can be made in the future. We quantify the benefit of exploration through the "adaptivity gap" between an adaptive and a nonadaptive algorithm in terms of the uncertainty in the environment. Exploiting the submodularity (a diminishing returns property) and locality properties of the objective function, we develop an algorithm that performs provably near-optimally in settings where the adaptivity gap is small. In case of large gap, we use an objective function that simultaneously optimizes paths for exploration and exploitation. We also provide an algorithm to extend any single robot algorithm for adaptive informative path planning to the multi robot setting while approximately preserving the theoretical guarantee of the single robot algorithm. We extensively evaluate our approach on a search and rescue domain and a scientific monitoring problem using a real robotic system.},
booktitle = {Proceedings of the 21st International Joint Conference on Artificial Intelligence},
pages = {1843–1850},
numpages = {8},
location = {Pasadena, California, USA},
series = {IJCAI'09}
}


@book{puterman_MDPbook,
author = {Puterman, Martin L.},
title = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
year = {1994},
isbn = {0471619779},
publisher = {John Wiley \& Sons, Inc.},
address = {USA},
edition = {1st},
abstract = {From the Publisher:The past decade has seen considerable theoretical and applied research on Markov decision processes, as well as the growing use of these models in ecology, economics, communications engineering, and other fields where outcomes are uncertain and sequential decision-making processes are needed. A timely response to this increased activity, Martin L. Puterman's new work provides a uniquely up-to-date, unified, and rigorous treatment of the theoretical, computational, and applied research on Markov decision process models. It discusses all major research directions in the field, highlights many significant applications of Markov decision processes models, and explores numerous important topics that have previously been neglected or given cursory coverage in the literature. Markov Decision Processes focuses primarily on infinite horizon discrete time models and models with discrete time spaces while also examining models with arbitrary state spaces, finite horizon models, and continuous-time discrete state models. The book is organized around optimality criteria, using a common framework centered on the optimality (Bellman) equation for presenting results. The results are presented in a "theorem-proof" format and elaborated on through both discussion and examples, including results that are not available in any other book. A two-state Markov decision process model, presented in Chapter 3, is analyzed repeatedly throughout the book and demonstrates many results and algorithms. Markov Decision Processes covers recent research advances in such areas as countable state space models with average reward criterion, constrained models, and models with risk sensitive optimality criteria. It also explores several topics that have received little or no attention in other books, including modified policy iteration, multichain models with average reward criterion, and sensitive optimality. In addition, a Bibliographic Remarks section in each chapter comments on relevant historic}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{blum2007approximation,
  title={Approximation algorithms for orienteering and discounted-reward TSP},
  author={Blum, Avrim and Chawla, Shuchi and Karger, David R and Lane, Terran and Meyerson, Adam and Minkoff, Maria},
  journal={SIAM Journal on Computing},
  volume={37},
  number={2},
  pages={653--670},
  year={2007},
  publisher={SIAM}
}

@incollection{FU_score,
title = {Chapter 19 Gradient Estimation},
editor = {Shane G. Henderson and Barry L. Nelson},
series = {Handbooks in Operations Research and Management Science},
publisher = {Elsevier},
volume = {13},
pages = {575-616},
year = {2006},
booktitle = {Simulation},
issn = {0927-0507},
doi = {https://doi.org/10.1016/S0927-0507(06)13019-4},
author = {Michael C. Fu},
abstract = {This chapter considers the problem of efficiently estimating gradients from stochastic simulation. Although the primary motivation is their use in simulation optimization, the resulting estimators can also be useful in other ways, e.g., sensitivity analysis. The main approaches described are finite differences (including simultaneous perturbations), perturbation analysis, the likelihood ratio/score function method, and the use of weak derivatives.}
}

@article{greensmith2004variance,
  title={Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning.},
  author={Greensmith, Evan and Bartlett, Peter L and Baxter, Jonathan},
  journal={Journal of Machine Learning Research},
  volume={5},
  number={9},
  year={2004}
}

@article{GUNAWAN2016315,
title = {Orienteering Problem: A survey of recent variants, solution approaches and applications},
journal = {European Journal of Operational Research},
volume = {255},
number = {2},
pages = {315-332},
year = {2016},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2016.04.059},
author = {Aldy Gunawan and Hoong Chuin Lau and Pieter Vansteenwegen},
keywords = {Scheduling, Survey, Orienteering Problem, Practical Applications},
abstract = {The Orienteering Problem (OP) has received a lot of attention in the past few decades. The OP is a routing problem in which the goal is to determine a subset of nodes to visit, and in which order, so that the total collected score is maximized and a given time budget is not exceeded. A number of typical variants has been studied, such as the Team OP, the (Team) OP with Time Windows and the Time Dependent OP. Recently, a number of new variants of the OP was introduced, such as the Stochastic OP, the Generalized OP, the Arc OP, the Multi-agent OP, the Clustered OP and others. This paper focuses on a comprehensive and thorough survey of recent variants of the OP, including the proposed solution approaches. Moreover, the OP has been used as a model in many different practical applications. The most recent applications of the OP, such as the Tourist Trip Design Problem and the mobile-crowdsourcing problem are discussed. Finally, we also present some promising topics for future research.}
}


@article{sensor-placement-andreas,
author = {Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
title = {Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies},
year = {2008},
issue_date = {6/1/2008},
publisher = {JMLR.org},
volume = {9},
issn = {1532-4435},
abstract = {When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task, for example, geometry or disk models, placing sensors at the points of highest entropy (variance) in the GP model, and A-, D-, or E-optimal design. In this paper, we tackle the combinatorial optimization problem of maximizing the mutual information between the chosen locations and the locations which are not selected. We prove that the problem of finding the configuration that maximizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1-1/e) of the optimum by exploiting the submodularity of mutual information. We also show how submodularity can be used to obtain online bounds, and design branch and bound search procedures. We then extend our algorithm to exploit lazy evaluations and local structure in the GP, yielding significant speedups. We also extend our approach to find placements which are robust against node failures and uncertainties in the model. These extensions are again associated with rigorous theoretical approximation guarantees, exploiting the submodularity of the objective function. We demonstrate the advantages of our approach towards optimizing mutual information in a very extensive empirical study on two real-world data sets.},
journal = {J. Mach. Learn. Res.},
month = {jun},
pages = {235–284},
numpages = {50}
}

@article{Swarm-SLAM,
  title={Swarm slam: Challenges and perspectives},
  author={Kegeleirs, Miquel and Grisetti, Giorgio and Birattari, Mauro},
  journal={Frontiers in Robotics and AI},
  volume={8},
  pages={618268},
  year={2021},
  publisher={Frontiers Media SA}
}


@article{streeter2008online,
  title={An online algorithm for maximizing submodular functions},
  author={Streeter, Matthew and Golovin, Daniel},
  journal={Advances in Neural Information Processing Systems},
  volume={21},
  year={2008}
}


@article{streeter2009online,
  title={Online learning of assignments},
  author={Streeter, Matthew and Golovin, Daniel and Krause, Andreas},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}


@ARTICLE{tohidi20,
  author={Tohidi, Ehsan and Amiri, Rouhollah and Coutino, Mario and Gesbert, David and Leus, Geert and Karbasi, Amin},
  journal={IEEE Signal Processing Magazine}, 
  title={Submodularity in Action: From Machine Learning to Signal Processing Applications}, 
  year={2020},
  volume={37},
  number={5},
  pages={120-133},
  doi={10.1109/MSP.2020.3003836}}

@inproceedings{mf,
author="Egbert Bakker and Lars Nyborg and Hans B. Pacejka",
journal="", 
publisher="SAE International",
title="Tyre Modelling for Use in Vehicle Dynamics Studies", 
booktitle="SAE Technical Paper",
year="1987",
month="02",
volume="",
pages="",
abstract="A new way of representing tyre data obtained from measurements in pure cornering and pure braking conditions has been developed in order to further improve the Dynamic Safety of vehicles. The method makes use of a formula with coefficients which describe some of the typifying quantities of a tyre, such as slip stiffnesses at zero slip and force and torque peak values. The formula is capable of describing the characteristics of side force, brake force and self aligning torque with great accuracy. This mathematical representation is limited to steady-state conditions during either pure cornering or pure braking and forms the basis for a model describing tyre behaviour during combined braking and cornering.",
number="",
doi="10.4271/870421"
} 


@article{Feige-no-other-effi-algo,
author = {Feige, Uriel},
title = {A Threshold of Ln n for Approximating Set Cover},
year = {1998},
issue_date = {July 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0004-5411},
doi = {10.1145/285055.285059},
abstract = {Given a collection ℱ of subsets of S = {1,…,n}, set cover is the problem of selecting as few as possible subsets from ℱ such that their union covers S,, and max k-cover is the problem of selecting k subsets from ℱ such that their union has maximum cardinality. Both these problems are NP-hard. We prove that (1 - o(1)) ln n is a threshold below which set cover cannot be approximated efficiently, unless NP has slightly superpolynomial time algorithms. This closes the gap (up to low-order terms) between the ratio of approximation achievable by the greedy alogorithm (which is (1 - o(1)) ln n), and provious results of Lund and Yanakakis, that showed hardness of approximation within a ratio of (log2 n) / 2 ≃0.72 ln n. For max k-cover, we show an approximation threshold of (1 - 1/e)(up to low-order terms), under assumption that P ≠ NP.},
journal = {J. ACM},
month = {jul},
pages = {634–652},
numpages = {19},
keywords = {approximation ratio, set cover}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={ICML},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{stobbe2010efficient,
  title={Efficient minimization of decomposable submodular functions},
  author={Stobbe, Peter and Krause, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  year={2010}
}

@inproceedings{leskovec2007cost,
  title={Cost-effective outbreak detection in networks},
  author={Leskovec, Jure and Krause, Andreas and Guestrin, Carlos and Faloutsos, Christos and VanBriesen, Jeanne and Glance, Natalie},
  booktitle={Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={420--429},
  year={2007}
}


@inproceedings{kempe2003maximizing,
  title={Maximizing the spread of influence through a social network},
  author={Kempe, David and Kleinberg, Jon and Tardos, {\'E}va},
  booktitle={Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={137--146},
  year={2003}
}

@article{bhandari2019global,
  title={Global optimality guarantees for policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={arXiv preprint arXiv:1906.01786},
  year={2019}
}

@inproceedings{iyer2013fast,
  title={Fast semidifferential-based submodular function optimization},
  author={Iyer, Rishabh and Jegelka, Stefanie and Bilmes, Jeff},
  booktitle={International Conference on Machine Learning},
  pages={855--863},
  year={2013},
  organization={PMLR}
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@article{baxter2001infinite,
  title={Infinite-horizon policy-gradient estimation},
  author={Baxter, Jonathan and Bartlett, Peter L},
  journal={journal of artificial intelligence research},
  volume={15},
  pages={319--350},
  year={2001}
}

@article{abel2021expressivity,
  title={On the expressivity of markov reward},
  author={Abel, David and Dabney, Will and Harutyunyan, Anna and Ho, Mark K and Littman, Michael and Precup, Doina and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={7799--7812},
  year={2021}
}

@article{chatterji2021theory,
  title={On the theory of reinforcement learning with once-per-episode feedback},
  author={Chatterji, Niladri and Pacchiano, Aldo and Bartlett, Peter and Jordan, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3401--3412},
  year={2021}
}

@article{wang2020planning,
  title={Planning with Submodular Objective Functions},
  author={Wang, Ruosong and Zhang, Hanrui and Chaplot, Devendra Singh and Garagi{\'c}, Denis and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2010.11863},
  year={2020}
}

@article{CONFORTI1984251,
title = {Submodular set functions, matroids and the greedy algorithm: Tight worst-case bounds and some generalizations of the Rado-Edmonds theorem},
journal = {Discrete Applied Mathematics},
volume = {7},
number = {3},
pages = {251-274},
year = {1984},
issn = {0166-218X},
author = {Michele Conforti and Gérard Cornuéjols},
abstract = {For the problem maxlcub;Z(S): S is an independent set in the matroid Xrcub;, it is well-known that the greedy algorithm finds an optimal solution when Z is an additive set function (Rado-Edmonds theorem). Fisher, Nemhauser and Wolsey have shown that, when Z is a nondecreasing submodular set function satisfying Z(∅)=0, the greedy algorithm finds a solution with value at least half the optimum value. In this paper we show that it finds a solution with value at least 1/(1 + α) times the optimum value, where α is a parameter which represents the ‘total curvature’ of Z. This parameter satisfies 0≤α≤1 and α=0 if and only if the set function Z is additive. Thus the theorems of Rado-Edmonds and Fisher-Nemhauser-Wolsey are both contained in the bound 1/(1 + α). We show that this bound is best possible in terms of α. Another bound which generalizes the Rado-Edmonds theorem is given in terms of a ‘greedy curvature’ of the set function. Unlike the first bound, this bound can prove the optimality of the greedy algorithm even in instances where Z is not additive. A third bound, in terms of the rank and the girth of X, unifies and generalizes the bounds (e−1)/e known for uniform matroids and 12 for general matroids. We also analyze the performance of the greedy algorithm when X is an independence system instead of a matroid. Then we derive two bounds, both tight: The first one is [1−(1−α/K)k]/α where K and k are the sizes of the largest and smallest maximal independent sets in X respectively; the second one is 1/(p+α) where p is the minimum number of matroids that must be intersected to obtain X.}
}

@article{vondrak2010submodularity,
author = {Vondrak, Jan},
year = {2010},
month = {01},
pages = {},
title = {Submodularity and curvature: the optimal algorithm},
journal = {RIMS Kôkyûroku Bessatsu}
}

@article{basu2019blocking,
  title={Blocking bandits},
  author={Basu, Soumya and Sen, Rajat and Sanghavi, Sujay and Shakkottai, Sanjay},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}