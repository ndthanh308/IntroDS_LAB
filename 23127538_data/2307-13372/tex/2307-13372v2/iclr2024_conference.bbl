\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abel et~al.(2021)Abel, Dabney, Harutyunyan, Ho, Littman, Precup, and Singh]{abel2021expressivity}
David Abel, Will Dabney, Anna Harutyunyan, Mark~K Ho, Michael Littman, Doina Precup, and Satinder Singh.
\newblock On the expressivity of markov reward.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 7799--7812, 2021.

\bibitem[Baird(1993)]{baird1993}
Leemon~C Baird, III.
\newblock Advantage updating.
\newblock \emph{WRIGHT LAB WRIGHT-PATTERSON AFB OH}, 1993.

\bibitem[Bakker et~al.(1987)Bakker, Nyborg, and Pacejka]{mf}
Egbert Bakker, Lars Nyborg, and Hans~B. Pacejka.
\newblock Tyre modelling for use in vehicle dynamics studies.
\newblock In \emph{SAE Technical Paper}. SAE International, 02 1987.
\newblock \doi{10.4271/870421}.

\bibitem[Balcan \& Harvey(2011)Balcan and Harvey]{balcan2011learning}
Maria-Florina Balcan and Nicholas~JA Harvey.
\newblock Learning submodular functions.
\newblock In \emph{Proceedings of the forty-third annual ACM symposium on Theory of computing}, pp.\  793--802, 2011.

\bibitem[Basu et~al.(2019)Basu, Sen, Sanghavi, and Shakkottai]{basu2019blocking}
Soumya Basu, Rajat Sen, Sujay Sanghavi, and Sanjay Shakkottai.
\newblock Blocking bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Baxter \& Bartlett(2001)Baxter and Bartlett]{baxter2001infinite}
Jonathan Baxter and Peter~L Bartlett.
\newblock Infinite-horizon policy-gradient estimation.
\newblock \emph{journal of artificial intelligence research}, 15:\penalty0 319--350, 2001.

\bibitem[Belogolovsky et~al.(2021)Belogolovsky, Korsunsky, Mannor, Tessler, and Zahavy]{Belogolovsky2021}
Stav Belogolovsky, Philip Korsunsky, Shie Mannor, Chen Tessler, and Tom Zahavy.
\newblock Inverse reinforcement learning in contextual mdps.
\newblock \emph{Machine Learning}, 2021.

\bibitem[Bhandari \& Russo(2019)Bhandari and Russo]{bhandari2019global}
Jalaj Bhandari and Daniel Russo.
\newblock Global optimality guarantees for policy gradient methods.
\newblock \emph{arXiv preprint arXiv:1906.01786}, 2019.

\bibitem[Bian et~al.(2017{\natexlab{a}})Bian, Levy, Krause, and Buhmann]{bian2017continuous}
An~Bian, Kfir Levy, Andreas Krause, and Joachim~M Buhmann.
\newblock Continuous dr-submodular maximization: Structure and algorithms.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017{\natexlab{a}}.

\bibitem[Bian et~al.(2017{\natexlab{b}})Bian, Buhmann, Krause, and Tschiatschek]{greedy-supermodular}
Andrew~An Bian, Joachim~M Buhmann, Andreas Krause, and Sebastian Tschiatschek.
\newblock Guarantees for greedy maximization of non-submodular functions with applications.
\newblock In \emph{International conference on machine learning}, pp.\  498--507. PMLR, 2017{\natexlab{b}}.

\bibitem[Bian et~al.(2017{\natexlab{c}})Bian, Mirzasoleiman, Buhmann, and Krause]{bian2017guaranteed}
Andrew~An Bian, Baharan Mirzasoleiman, Joachim Buhmann, and Andreas Krause.
\newblock Guaranteed non-convex optimization: Submodular maximization over continuous domains.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  111--120. PMLR, 2017{\natexlab{c}}.

\bibitem[Bilmes(2022)]{bilmes2022submodularity}
Jeff Bilmes.
\newblock Submodularity in machine learning and artificial intelligence.
\newblock \emph{arXiv preprint arXiv:2202.00132}, 2022.

\bibitem[Chatterji et~al.(2021)Chatterji, Pacchiano, Bartlett, and Jordan]{chatterji2021theory}
Niladri Chatterji, Aldo Pacchiano, Peter Bartlett, and Michael Jordan.
\newblock On the theory of reinforcement learning with once-per-episode feedback.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 3401--3412, 2021.

\bibitem[Chekuri \& Pal(2005)Chekuri and Pal]{chekuri_rg}
Chandra Chekuri and M.~Pal.
\newblock A recursive greedy algorithm for walks in directed graphs.
\newblock In \emph{46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05)}, pp.\  245--253, 2005.
\newblock \doi{10.1109/SFCS.2005.9}.

\bibitem[Chen et~al.(2017)Chen, Krause, and Karbasi]{Chen2017InteractiveSB}
Lin Chen, Andreas Krause, and Amin Karbasi.
\newblock Interactive submodular bandit.
\newblock In \emph{NIPS}, 2017.

\bibitem[Conforti \& Cornuéjols(1984)Conforti and Cornuéjols]{CONFORTI1984251}
Michele Conforti and Gérard Cornuéjols.
\newblock Submodular set functions, matroids and the greedy algorithm: Tight worst-case bounds and some generalizations of the rado-edmonds theorem.
\newblock \emph{Discrete Applied Mathematics}, 7\penalty0 (3):\penalty0 251--274, 1984.
\newblock ISSN 0166-218X.

\bibitem[Dolhansky \& Bilmes(2016)Dolhansky and Bilmes]{dolhansky2016deep}
Brian~W Dolhansky and Jeff~A Bilmes.
\newblock Deep submodular functions: Definitions and learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 29, 2016.

\bibitem[Duff(2002)]{Duff2002}
Michael~O'Gordon Duff.
\newblock \emph{Optimal learning: Computational procedures for Bayes -adaptive Markov decision processes}.
\newblock PhD thesis, University of Massachusetts Amherst, 2002.

\bibitem[Feige(1998)]{Feige-no-other-effi-algo}
Uriel Feige.
\newblock A threshold of ln n for approximating set cover.
\newblock \emph{J. ACM}, 45\penalty0 (4):\penalty0 634–652, jul 1998.
\newblock ISSN 0004-5411.
\newblock \doi{10.1145/285055.285059}.

\bibitem[Fu(2006)]{FU_score}
Michael~C. Fu.
\newblock Chapter 19 gradient estimation.
\newblock In Shane~G. Henderson and Barry~L. Nelson (eds.), \emph{Simulation}, volume~13 of \emph{Handbooks in Operations Research and Management Science}, pp.\  575--616. Elsevier, 2006.
\newblock \doi{https://doi.org/10.1016/S0927-0507(06)13019-4}.

\bibitem[Funwi-gabga \& Mateu(2011)Funwi-gabga and Mateu]{gorilla-kagwene}
Neba Funwi-gabga and Jorge Mateu.
\newblock Understanding the nesting spatial behaviour of gorillas in the kagwene sanctuary, cameroon.
\newblock \emph{Stochastic Environmental Research and Risk Assessment}, 26, 08 2011.
\newblock \doi{10.1007/s00477-011-0541-1}.

\bibitem[Golovin \& Krause(2011)Golovin and Krause]{golovin2011adaptive}
Daniel Golovin and Andreas Krause.
\newblock Adaptive submodularity: Theory and applications in active learning and stochastic optimization.
\newblock \emph{Journal of Artificial Intelligence Research}, 42:\penalty0 427--486, 2011.

\bibitem[Greensmith et~al.(2004)Greensmith, Bartlett, and Baxter]{greensmith2004variance}
Evan Greensmith, Peter~L Bartlett, and Jonathan Baxter.
\newblock Variance reduction techniques for gradient estimates in reinforcement learning.
\newblock \emph{Journal of Machine Learning Research}, 5\penalty0 (9), 2004.

\bibitem[Gunawan et~al.(2016)Gunawan, Lau, and Vansteenwegen]{GUNAWAN2016315}
Aldy Gunawan, Hoong~Chuin Lau, and Pieter Vansteenwegen.
\newblock Orienteering problem: A survey of recent variants, solution approaches and applications.
\newblock \emph{European Journal of Operational Research}, 255\penalty0 (2):\penalty0 315--332, 2016.
\newblock ISSN 0377-2217.
\newblock \doi{https://doi.org/10.1016/j.ejor.2016.04.059}.

\bibitem[Halperin \& Krauthgamer(2003)Halperin and Krauthgamer]{Halperin2003inapprox}
Eran Halperin and Robert Krauthgamer.
\newblock Polylogarithmic inapproximability.
\newblock In \emph{Proceedings of the Thirty-Fifth Annual ACM Symposium on Theory of Computing}, STOC '03, pp.\  585–594. Association for Computing Machinery, 2003.
\newblock ISBN 1581136749.
\newblock \doi{10.1145/780542.780628}.

\bibitem[Hassani et~al.(2017)Hassani, Soltanolkotabi, and Karbasi]{hassani2017gradient}
Hamed Hassani, Mahdi Soltanolkotabi, and Amin Karbasi.
\newblock Gradient methods for submodular maximization.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Hazan et~al.(2019)Hazan, Kakade, Singh, and Van~Soest]{Hazan2019}
Elad Hazan, Sham Kakade, Karan Singh, and Abby Van~Soest.
\newblock Provably efficient maximum entropy exploration.
\newblock In \emph{International Conference on Machine Learning}, pp.\  2681--2691. PMLR, 2019.

\bibitem[Kakade(2001)]{kakade2001natural}
Sham~M Kakade.
\newblock A natural policy gradient.
\newblock \emph{Advances in neural information processing systems}, 14, 2001.

\bibitem[Karimi et~al.(2017)]{karimi2017stochastic}
Mohammad Karimi et~al.
\newblock Stochastic submodular maximization: The case of coverage functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Kegeleirs et~al.(2021)Kegeleirs, Grisetti, and Birattari]{Swarm-SLAM}
Miquel Kegeleirs, Giorgio Grisetti, and Mauro Birattari.
\newblock Swarm slam: Challenges and perspectives.
\newblock \emph{Frontiers in Robotics and AI}, 8:\penalty0 618268, 2021.

\bibitem[Krause \& Golovin(2014)Krause and Golovin]{krause2014submodular}
Andreas Krause and Daniel Golovin.
\newblock Submodular function maximization.
\newblock \emph{Tractability}, 3:\penalty0 71--104, 2014.

\bibitem[Krause et~al.(2008)Krause, Singh, and Guestrin]{sensor-placement-andreas}
Andreas Krause, Ajit Singh, and Carlos Guestrin.
\newblock Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies.
\newblock \emph{J. Mach. Learn. Res.}, 9:\penalty0 235–284, jun 2008.
\newblock ISSN 1532-4435.

\bibitem[Lindner et~al.(2021)Lindner, Turchetta, Tschiatschek, Ciosek, and Krause]{lindner2021information}
David Lindner, Matteo Turchetta, Sebastian Tschiatschek, Kamil Ciosek, and Andreas Krause.
\newblock Information directed reward learning for reinforcement learning.
\newblock In \emph{Proc. Neural Information Processing Systems (NeurIPS)}, December 2021.

\bibitem[Liniger et~al.(2015)Liniger, Domahidi, and Morari]{Liniger2017OptimizationBasedAR}
Alexander Liniger, Alexander Domahidi, and Manfred Morari.
\newblock Optimization-based autonomous racing of 1: 43 scale rc cars.
\newblock \emph{Optimal Control Applications and Methods}, 36\penalty0 (5):\penalty0 628--647, 2015.

\bibitem[Mutn{\'{y}} \& Krause(2021)Mutn{\'{y}} and Krause]{mojmir-cox}
Mojm{\'{\i}}r Mutn{\'{y}} and Andreas Krause.
\newblock Sensing cox processes via posterior sampling and positive bases.
\newblock \emph{CoRR}, abs/2110.11181, 2021.
\newblock URL \url{https://arxiv.org/abs/2110.11181}.

\bibitem[Mutny et~al.(2023)Mutny, Janik, and Krause]{Mutny2023}
Mojmir Mutny, Tadeusz Janik, and Andreas Krause.
\newblock Active exploration via experiment design in markov chains.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pp.\  7349--7374. PMLR, 2023.

\bibitem[Mutti et~al.(2022)Mutti, De~Santi, De~Bartolomeis, and Restelli]{mutti2022challenging}
Mirco Mutti, Riccardo De~Santi, Piersilvio De~Bartolomeis, and Marcello Restelli.
\newblock Challenging common assumptions in convex reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 4489--4502, 2022.

\bibitem[Nemhauser et~al.(1978)Nemhauser, Wolsey, and Fisher]{nemhauser1978analysis}
George~L Nemhauser, Laurence~A Wolsey, and Marshall~L Fisher.
\newblock An analysis of approximations for maximizing submodular set functions—i.
\newblock \emph{Mathematical programming}, 14\penalty0 (1):\penalty0 265--294, 1978.

\bibitem[Prajapat et~al.(2021)Prajapat, Azizzadenesheli, Liniger, Yue, and Anandkumar]{prajapat2021competitive}
Manish Prajapat, Kamyar Azizzadenesheli, Alexander Liniger, Yisong Yue, and Anima Anandkumar.
\newblock Competitive policy optimization.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pp.\  64--74. PMLR, 2021.

\bibitem[Prajapat et~al.(2022)Prajapat, Turchetta, Zeilinger, and Krause]{near_optimal_safe_cov}
Manish Prajapat, Matteo Turchetta, Melanie Zeilinger, and Andreas Krause.
\newblock Near-optimal multi-agent learning for safe coverage control.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 14998--15012, 2022.

\bibitem[Puterman(1994)]{puterman_MDPbook}
Martin~L. Puterman.
\newblock \emph{Markov Decision Processes: Discrete Stochastic Dynamic Programming}.
\newblock John Wiley \& Sons, Inc., USA, 1st edition, 1994.
\newblock ISBN 0471619779.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and Moritz]{schulman2015trust}
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz.
\newblock Trust region policy optimization.
\newblock In \emph{ICML}, pp.\  1889--1897. PMLR, 2015.

\bibitem[Schulman et~al.(2016)Schulman, Moritz, Levine, Jordan, and Abbeel]{schulman2015highdimensional}
John Schulman, Philipp Moritz, Sergey Levine, Michael~I. Jordan, and Pieter Abbeel.
\newblock High-dimensional continuous control using generalized advantage estimation.
\newblock In \emph{4th International Conference on Learning Representations, {ICLR}}, 2016.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Singh et~al.(2009)Singh, Krause, and Kaiser]{Singh2009}
Amarjeet Singh, Andreas Krause, and William~J. Kaiser.
\newblock Nonmyopic adaptive informative path planning for multiple robots.
\newblock In \emph{Proceedings of the 21st International Joint Conference on Artificial Intelligence}, IJCAI'09, pp.\  1843–1850, San Francisco, CA, USA, 2009.

\bibitem[Streeter \& Golovin(2008)Streeter and Golovin]{streeter2008online}
Matthew Streeter and Daniel Golovin.
\newblock An online algorithm for maximizing submodular functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 21, 2008.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Sutton et~al.(1999)Sutton, McAllester, Singh, and Mansour]{sutton1999policy}
Richard~S Sutton, David McAllester, Satinder Singh, and Yishay Mansour.
\newblock Policy gradient methods for reinforcement learning with function approximation.
\newblock \emph{Advances in neural information processing systems}, 12, 1999.

\bibitem[Tarbouriech et~al.(2020)Tarbouriech, Shekhar, Pirotta, Ghavamzadeh, and Lazaric]{tarbouriech2020active}
Jean Tarbouriech, Shubhanshu Shekhar, Matteo Pirotta, Mohammad Ghavamzadeh, and Alessandro Lazaric.
\newblock Active model estimation in markov decision processes.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, pp.\  1019--1028. PMLR, 2020.

\bibitem[Tohidi et~al.(2020)Tohidi, Amiri, Coutino, Gesbert, Leus, and Karbasi]{tohidi20}
Ehsan Tohidi, Rouhollah Amiri, Mario Coutino, David Gesbert, Geert Leus, and Amin Karbasi.
\newblock Submodularity in action: From machine learning to signal processing applications.
\newblock \emph{IEEE Signal Processing Magazine}, 37\penalty0 (5):\penalty0 120--133, 2020.
\newblock \doi{10.1109/MSP.2020.3003836}.

\bibitem[Vondrak(2010)]{vondrak2010submodularity}
Jan Vondrak.
\newblock Submodularity and curvature: the optimal algorithm.
\newblock \emph{RIMS Kôkyûroku Bessatsu}, 01 2010.

\bibitem[Wang et~al.(2020)Wang, Zhang, Chaplot, Garagi{\'c}, and Salakhutdinov]{wang2020planning}
Ruosong Wang, Hanrui Zhang, Devendra~Singh Chaplot, Denis Garagi{\'c}, and Ruslan Salakhutdinov.
\newblock Planning with submodular objective functions.
\newblock \emph{arXiv preprint arXiv:2010.11863}, 2020.

\bibitem[Yue \& Guestrin(2011)Yue and Guestrin]{YisongLSB}
Yisong Yue and Carlos Guestrin.
\newblock Linear submodular bandits and their application to diversified retrieval.
\newblock \emph{Advances in Neural Information Processing Systems}, 24, 2011.

\bibitem[Zahavy et~al.(2021)Zahavy, O’Donoghue, Desjardins, and Singh]{Zahavy2021}
Tom Zahavy, Brendan O’Donoghue, Guillaume Desjardins, and Satinder Singh.
\newblock Reward is enough for convex mdps.
\newblock In \emph{35th Conference on Neural Information Processing Systems (NeurIPS 2021)}, 2021.

\end{thebibliography}
