
\documentclass[journal]{IEEEtran}
%
\usepackage{graphicx}                                % some people may need to use [dvips] option
\usepackage{amsmath}
\usepackage{multirow}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{algorithmic}
\usepackage{cite}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{array}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{float}
\usepackage{threeparttable}
\usepackage{caption,subcaption}
\usepackage{hyperref}
\usepackage{diagbox}
\usepackage{amsmath} 
\usepackage{multirow}
\usepackage{pifont}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\usepackage[table,xcdraw]{xcolor}



\hypersetup{hidelinks,
	colorlinks=true,
	allcolors=black,
	pdfstartview=Fit,
	breaklinks=true}


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\captionsetup[table]{ labelsep=newline,justification=centering,textfont=sc}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{ES2Net: An Efficient Spectral-Spatial Network for Hyperspectral Image Change Detection}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%
\author{
        Qingren Yao,
	Yuan Zhou,~\IEEEmembership{Senior Member,~IEEE,}
	and Wei Xiang,~\IEEEmembership{Senior Member,~IEEE}

% <-this % stops a space
% \thanks{This work was supported by the National Key Research and Development Program of China (2020YFC1523204) and National Natural Science Foundation of China (62171320 and U2006211).(\emph{Corresponding author: Qingren Yao.})} 
\thanks{(\emph{Corresponding author: Yuan Zhou.})}

\thanks{Qingren Yao and Yuan Zhou are with the School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China (e-mail: qingren@tju.edu.cn; zhouyuan@tju.edu.cn).}

\thanks{Wei Xiang is with the School of Computing, Engineering and Mathematical Sciences, La Trobe University, Melbourne, VIC 3086, Australia, and also with the College of Science and Engineering, James Cook University, Cairns, QLD 4878, Australia (e-mail: w.xiang@latrobe.edu.au).}
}

% The paper headers
\markboth{IEEE Transactions on Geoscience and Remote Sensing,Vol.XX, No.XX, XXXX (Preprint. Under review)}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}

% make the title area
\maketitle
% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
    Hyperspectral image change detection (HSI-CD) aims to identify the differences in bitemporal HSIs. To mitigate spectral redundancy and improve the discriminativeness of changing features, some methods introduced band selection technology to select bands conducive for CD. However, these methods are limited by the inability to end-to-end training with the deep learning-based feature extractor and lack considering the complex nonlinear relationship among bands. In this paper, we propose an end-to-end efficient spectral-spatial change detection network (ES2Net) to address these issues. Specifically, we devised a learnable band selection module to automatically select bands conducive to CD. It can be jointly optimized with a feature extraction network and capture the complex nonlinear relationships among bands. Moreover, considering the large spatial feature distribution differences among different bands, we design the cluster-wise spatial attention mechanism that assigns a spatial attention factor to each individual band to improve the discriminativeness of changing features. Experiments on three widely used HSI-CD datasets demonstrate the effectiveness and superiority of this method compared with other state-of-the-art methods.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
    Change detection, deep learning, hyperspectral images, band selection, attention mechanism. 
\end{IEEEkeywords}


\IEEEpeerreviewmaketitle


\section{Introduction}

\IEEEPARstart{C}{hange} detection (CD) aims to recognize differences in multitemporal remote sensing images and has found broad applications in areas such as forestry and agricultural monitoring \cite{silva2021multitemporal}, natural disaster detection \cite{wang2023hierarchical}, and land surface dynamic analysis \cite{yan2019time}. Hyperspectral images (HSIs) typically comprise hundreds of continuous spectral bands in the ultraviolet, visible, near-infrared, and mid-infrared regions of the electromagnetic spectrum. Compared to other remote sensing images, such as visible images, multispectral images, and synthetic aperture radar images, HSIs can capture richer spectral information about ground objects. Hyperspectral image changing detection (HSI-CD) has received increasing attention in recent years. 

HSI-CD algorithms can be classified into three categories as follows: algebra-based, traditional machine learning-based and deep learning-based algorithms. The algebra-based methods directly calculate on image pixels and then determine the changed pixels through selecting an appropriate similarity threshold \cite{du2012fusion, zhuang2016strategies}. However, it is difficult to find appropriate thresholds, and requires image preprocessing. These deficiencies limit the prevailing of algebra-based CD methods. Traditional machine learning-based approaches use hand-crafted feature extraction method to convert HSIs into feature space, then contrast the features from bitemporal images \cite{wu2012hyperspectral, celik2009unsupervised}. But it’s difficult to effectively extract discriminative information through hand-crafted extraction process, resulting in an insufficient performance.

In contrast to traditional machine learning, deep learning can extract features more effectively from complex high-level change information. These methods simply utilized the full-dimensional HSI features and tried to tune network architectures to efficiently extract spectral and spatial features \cite{wang2018getnet}. However, HSIs contain redundant spectral bands that are not conducive to CD. Directly extracting features from the full-dimensional HSI can lead to feature confusion, thereby reducing the discriminativeness of changing features. Recent works tried to mitigate spectral redundancy through band selection technology. Liu et al. \cite{liu2017band} proposed applying band selection algorithm to HSI-CD. They used an iterative algorithm to select the most informative band subset, and then perform CD on the dimensionality-reduced hyperspectral image, demonstrating the feasibility of addressing HSI-CD in a low-dimensional feature space. Based on the slow feature analysis theory, Ou et al \cite{ou2022cnn} designed a slow-fast band selection algorithm for HSI-CD, which selects fast bands with sufficiently changing features and slow bands representing unchanging features to form a band subset.

Above methods rely on manual feature engineering and are not learnable, result in the inability to be jointly optimized with the deep learning-based feature extractor. Moreover, these methods treat each band as a separate image and independently evaluate the importance of each band, ignoring the inherent nonlinear relationships among bands. Therefore, it is difficult for these methods to select the most helpful bands for CD from all spectral bands. On the other hand, some methods adopt spatial attention mechanism to highlight important features and suppress irrelevant ones. However, without considering the large spatial feature distribution differences between different bands, they assign the same spatial attention factor to all bands. This uniform spatial attention allocation may excessively emphasize the feature extraction of certain bands while neglecting others, leading to a decrease in the discriminativeness of the changing features.

To tackle these problems, we propose an end-to-end efficient spectral-spatial change detection network (ES2Net) that incorporates a learnable band selection module and cluster-wise spatial attention mechanism. Specifically, we design a learnable band selection module to automatize the process of finding the bands beneficial for change detection. It explicitly models the nonlinear spectral inter-relationships through multiple fully connected layers and can be co-optimized with subsequent spatial feature extraction network. Furthermore, we implement a cluster-wise spatial attention mechanism that generates a spatial attention factor to each band, thereby enhancing the changing feature of each individual band independently.

The main contributions of this paper are summarized as follows:

\begin{enumerate}
        \item We propose a learnable band selection module to automatically select bands conducive to CD. Unlike the existing methods, it fully considers the nonlinear spectral interrelationships and allows end-to-end training of band selection and a feature extracting network for better CD performance.
        
	\item We propose a cluster-wise spatial attention mechanism that assigns a spatial attention factor to each individual band. Compared with assigning the same spatial attention factor to all bands, changing feature of each individual band can be enhanced independently for stronger discriminativeness.
	
	\item Comprehensive experiments are performed on three widely adopted hyperspectral datasets. The experimental results demonstrate the superiority of our proposed ES2Net over other state-of-the-art HSI-CD methods.
\end{enumerate}

\section{Related Work}

Currently, there have been many existing HSI-CD methods. In this paper, we categorized HSI-CD algorithms in terms of three topics as follows: algebra-based, traditional machine learning-based and deep learning-based algorithms. Here, we briefly describe the three sorts of algorithms in the previous works.

\subsection{Algebra-based Method}

Image differencing, image rationing, and image regression are the earliest algebra-based CD algorithms. When these methods are applied to HSI-CD, they are sensitive to radiation and noise, which compromises the CD accuracy. As a typical example of algebra-based methods, the change vector analysis (CVA) generates a differential image by calculating the difference in the Euclidean distance between the pixels of two images \cite{malila1980change}. Subsequently, some improved CVA methods are gradually proposed. Bovolo et al. \cite{bovolo2011framework} proposed a compressed CVA ($\rm{C^2VA}$) which extends CVA to a 2-D representation of change information. Liu et al. \cite{liu2015sequential} proposed sequential spectral change vector analysis ($\rm{S^2CVA}$) and multiscale morphological compressed change vector analysis ($\rm{M^2C^2VA}$) for multiclass CD. Besides, there are several other algebra-based methods \cite{kwan2019methods}, such as absolute average difference (AAD), vector for angle, and normalized Euclidean distance (NED). These methods commonly require threshold to determine changing and unchanging pixels. But it is difficult to decide a threshold manually, so some automatic threshold methods are used in conjunction with algebra-based methods, such as expectation maximization (EM) \cite{bruzzone2000automatic}, Otsu’s method \cite{otsu1979threshold}, support vector machine (SVM) \cite{bovolo2008novel}, and K-means \cite{chen2017spectrally}. Overall, algebra-based methods are easy to implement and valid for easy scene of HSIs , yet the performance is poor for HSIs with complex spatial texture.


\subsection{Traditional machine learning-based Method}

Traditional machine learning-based completes change detection by transforming the image into a new feature space, where the changed features are highlighted and unchanged features are suppressed. The representative methods include principal component analysis (PCA) \cite{ortiz2006change}, slow feature analysis (SFA) \cite{wu2014slow}, multivariate alteration detection (MAD) \cite{nielsen1997multivariate}, subspace learning \cite{chang2022sketched} and sparse learning \cite{zhang2019superpixel}. Moreover, Nielsen \cite{nielsen2007regularized} further extended MAD to an iteratively reweighted MAD (IR-MAD) for further improving CD accuracy. A multilayer cascade screening strategy (MCS4CD) was proposed in \cite{liu2022multilayer}, which selects the highly reliable unchanged pixels as training samples and extracts the change information by iterative SFA. Hou et al. proposed a space-spectral dual-pipeline framework for HSI-CD using multiple morphological profiles \cite{hou2021hyperspectral}. Meantime, object analysis tactics are introduced into tradition machine learning-based methods. For example, Liu et al. \cite{liu2016unsupervised} counted the subpixel categories within a patch and used the most common category as the patch class for HSI-CD. Nemmour and Chibani \cite{nemmour2006multiple} used SVM for bitemporal HSI classification and compared classification results for CD. Ahlqvist \cite{ahlqvist2008extending} used the method based on fuzzy sets for land cover classification and took the obtained categories for semantic comparison to obtain CD results. Although such kind of methods achieve effective dimensionality reduction and noise decline, they need consume an excessive number of computations when deal with vast changing area.

% Figure environment removed

\subsection{Deep Learning-based Method}

The deep learning-based method is currently the most used HSI-CD method, as its strong capability of feature learning. A lot of common neural networks have been applied to this field, such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), graph neural networks (GCN), and transformer. Zhan et al. \cite{zhan2021sscnn} proposed a spectral–spatial convolution neural network with a Siamese architecture (SSCNN-S) for HSI-CD, which employs 1D convolution to extract the spectral features and reduce spectral dimension. Wang et al. \cite{wang2021ssa} proposed SSA-SiamNet that integrates channel and spatial attention in CNN to highlight influential information and suppress less informative channels and pixels in the spectral and spatial domains. Luo et al. \cite{luo2023multiscale} fused spatial features from different scales with attention mechanism to generate a more discriminative change feature. Wang et al. \cite{wang2022rscnet} designed a residual self-calibrated network that can effectively exploit spatial information. Gong et al. \cite{gong2021spectral} proposed a spectral and spatial network, which is capable to suppress CD-irrelevant spectral and spatial information via adaptive spectral and spatial mechanisms. And Gong et al. devised a semisupervised training strategy by augmenting limited labeled data. Qu et al. \cite{qu2021multilevel} integrated the architecture of encoder-decoder and long short-term memory network (LSTM) to simultaneously learn spatial-spectral features and temporal features. Qu et al. \cite{qu2021dual} proposed a dual-branch difference amplification graph convolutional network, which firstly introduced GCN to HSI-CD. Wang et al. \cite{wang2022csdbf} designed a dual-branch framework (CSDBF) that used CNN to extract pixel-level features and graph attention network to process superpixel-level features. Shi et al. \cite{shi2022learning} devised a multipath convolutional LSTM that enables the model can learn multilevel temporal dependencies of bitemporal HSIs. Yang et al. \cite{yang2022deep} proposed a deep multiscale pyramid network enhanced with spatial-spectral residual attention that aggregates low- and high-level features to enrich spatial details and semantic information. Wang et al. \cite{wang2022spectral} designed a dual-branch transformer for HSI-CD that contains a spectral-spatial transformer and a temporal transformer (SST-Former) and evaluated the model is still valid in small training datasets. Wang et al. \cite{wang2023tritf} devised a triplet transformer framework based on parents-temporal and bother-spatial attention for HSI-CD. Although deep learning-based algorithms have achieved good CD results, the methods typically use convolution to fuse bands or apply channel attention to assign weights for bands, which can cause feature confusion or introduce redundant parameters for handling bands that are irrelevant to CD. Thus, it is important to design an efficient network incorporating band selection to handle HSI-CD.

\section{Methodology}

In this section, the proposed ES2Net is presented in detail. As shown in Fig. \ref{fig1}, the ES2Net is carefully designed to efficiently utilize spectral and spatial information. The band selection (BS) module selects a few bands that contribute to CD from the input HSI, reducing spectral redundancy. Then the low dimensional HSI is inputted into a spatial feature extraction network, where the cluster-wise spatial attention (CSA) is applied to improve the discriminativeness of changing features. In the multi-scale fusion classifier, the features with different scales are integrated and fed into two fully connected layers to produce a final CD binary image.

The three main parts of the proposed ES2Net model, i.e., the band selection module, the cluster-wise spatial attention, the muti-scale fusion classifier, and the well-designed loss, are introduced in the following.

\subsection{Band Selection Module}
We adopt the differential HSI image as the model input, which is obtained by directly subtracting bitemporal HSIs $I_{pre}$ and $I_{\textit{later}}$, yielding a tensor $I\in \mathbb{R}^{B\times h\times w}$, where $h$, $w$ represent the height and width of HSI, and $B$ denotes the number of bands. To make full use of the spatial context information, we divide the whole differential HSI $I$ into $s\times s$ patches, comprising a central pixel and its surrounding pixels, denoted as $X\in \mathbb{R}^{B\times s\times s}$. Like the bitemporal HSI, the differential HSI also exhibits significant spectral redundancy. To reduce the spectral redundancy, we propose the learnable band selection module to automatically select bands conducive to CD. The module is composed of band clustering, diffusion, band attention and intra-cluster Softmax operations, as elaborated below.

\textbf{Band Clustering}. We introduce a clustering constraint in the band selection process to ensure that the selected band subset is still informative while the redundancy is reduced. The bands belonging to the same cluster present strong correlation, and bands in different clusters exhibit relatively low similarity. Selecting one band from each cluster allows the reserved information is as comprehensive as possible. To achieve this aim, we first construct a $B\times B$ similarity matrix $A$, which can be defined as follows:

\begin{equation}\label{eq1}
A_{ij}=\begin{cases} \left| I_{i}-I_{j}\right| , &I_{j}\in \mathcal{N}_{k}(I_{i}) \\
0, &\textit{otherwise} \end{cases} 
\end{equation}

\noindent where the similarity between bands is measured through Euclidean distance, and $\mathcal{N}_{k}(I_{i})$ denotes the k-nearest neighbors of the $i$-th band $I_{i}$. Then, we perform spectral clustering using the similarity matrix to partition all bands into $b$ clusters. The clustering result is recorded through an assignment matrix $C\in \mathbb{R}^{b\times B}$, where the row of the assignment matrix represents the indexes of the clusters, and the column represents the indexes of the bands. Formally, the assignment matrix is expressed as follows:

\begin{equation} \label{eq2}
C_{ij}=\begin{cases} 1, \quad I_{j}\in c_{i}\\ 
0, \quad \textit{otherwise}\end{cases}
\end{equation}

\noindent where $I_{j}$ denotes the $j$th band, and $c_{i}$ represent the $i$th cluster.

\textbf{Diffusion}. Influenced by the differences among patches, it’s difficult to learn a consistent band importance weight. To reduce the differences among patches, a diffusion operation is adopted to make the band correlation of each patch to approximate the band correlation of the entire HSI, which can be expressed as follows:

\begin{equation}\label{eq3}
\overline{X}=\hat{A}XW
\end{equation}

\noindent where $\hat{A}$ is normalized similarity matrix from $A$, and $\mathrm{W}$ is the learnable parameter. In this diffusion process, each band absorbs the features from other bands according to the similarity defined by the matrix $\hat{A}$. Thus, the band correlation of the reformed patch feature $\overline{X}$ will approximate the correlation of the whole HSI.

\textbf{Band Attention}. Using the diffused features, we calculate the similarity between one band and other bands and take it as a cue to calculate the band importance weights. Specifically, we take Euclidean distance as the similarity metric and define $s_{i}$ as the sum of the Euclidean distance between one band and other bands. Then we normalize $s_{i}$ over a patch to prevent the biased magnitude of similarity between different samples:

\begin{equation}\label{eq4}
s_{i}={\sum }_{i,j=1}^{B}\left| \overline{X}_{i}-\overline{X}_{j}\right|    
\end{equation}

\begin{equation}\label{eq5}
\widehat{s_{i}}=\frac{s_{i}-\mu _{s}}{\sigma _{s}+\epsilon }*\gamma +\beta  
\end{equation}

\noindent where $\widehat{s_{i}}$ is the normalized similarity between one band and all other bands, $\mu _{s}$ is the expected value, $\sigma _{s}$ is the standard deviation, $\epsilon $ (e.g., 1e-5) is a constant added for numerical stability, and $\gamma $ and $\beta $ are learnable affine transform parameters. Then, the normalized similarity vector $\boldsymbol{S}=\left\{\hat{s}_{i\ldots B}\right\}\in \mathbb{R}^{B}$ is fed into two fully connected layers to guide the learning of band importance weights $\boldsymbol{w}$, which can be defined as follows:

\begin{equation}\label{eq6}
\boldsymbol{w}=\textit{Sigmoid}(W_{1}W_{0}\boldsymbol{S})
\end{equation}

\noindent where $W_{0}$, $\mathrm{W}_{1}$ are the learnable parameters, $\boldsymbol{w} \in \mathbb{R}^{B}$ is the importance weight vector.

\textbf{Intra-cluster SoftMax}. To select one band from each cluster, we multiply the band weight $\boldsymbol{w}$ with the assignment matrix $C$ row by row to obtain a cluster-wise weight matrix $\mathcal{W}\in \mathbb{R}^{b\times B}$. Then we perform Softmax on the non-zero elements of each row to highlight one band in each cluster that contributes most to change detection, resulting in a selection matrix $E\in \mathbb{R}^{b\times B}$, which is defined as:

\begin{equation}\label{eq7}
E_{ij}=\frac{\exp (\mathcal{W}_{ij}/\tau )}{\sum _{k}\exp (\mathcal{W}_{ik}/\tau )}, \mathcal{W}_{ij}\neq 0, \mathcal{W}_{ik}\neq 0
\end{equation}

\noindent where $\tau $ is the temperature parameter that decreases with epoch. With the temperature parameter becoming smaller, the row vector of selection matrix will be closer to the one-hot vector.

Finally, using the selection matrix, we select the bands with the largest weight from all bands, which can be represented as follows:

\begin{equation}\label{eq8}
\chi =E\times X
\end{equation}
\noindent where $\chi \in R^{b\times s\times s}$ is the patch after dimensionality reduction, $\times $ is the matrix multiplication. 

\subsection{Cluster-wise Spatial Attention}

After band selection, each channel of the patch $\chi$ comes from different clusters. To enhance the learning capability of spatial feature and maintain the feature diversity, we first employ a grouped convolution to expand the channel number from $b$ to $b\times n$. Then each cluster has a vector representation at every position, namely $\chi _{i}=\left\{\boldsymbol{x}_{1\ldots m}\right\}, i\in \left[1\colon b\right], \boldsymbol{x}_{j}\in \mathbb{R}^{n}, m=s\times s$.

Considering the large spatial feature distribution differences among different clusters, we apply a cluster-wise spatial attention by scaling the feature map of each individual cluster with an attention factor. Specifically, the overall spatial information of a cluster is utilized to enhance the learning of spatial feature in each cluster. First, we construct a semantic vector that represents the global spatial information of a cluster through spatial average pooling:

\begin{equation}\label{eq9}
\boldsymbol{g}=\frac{1}{m}{\sum }_{i=1}^{m}\boldsymbol{x}_{i}
\end{equation}

Next, we use this global feature to calculate the corresponding importance coefficient of the feature at each position. This is achieved by the dot product, which measures the similarity between the global feature $\boldsymbol{g}$ and the local feature $\boldsymbol{x}_{i}$ to some extent. Thereby for each position, we have:

\begin{equation}\label{eq10}
c_{i}=\boldsymbol{g}\cdot \boldsymbol{x}_{i}
\end{equation}

We then normalize the importance coefficients $c_{i}$ in the way as same as Eq. (\ref{eq5}), to avoid the biased magnitudes between various patches, resulting in the normalized importance coefficient $a_{i}$.
Finally, the original $\boldsymbol{x}_{i}$ is scaled by the generated importance coefficient $a_{i}$ via a sigmoid function $\sigma (\cdot )$ over the space:

% \begin{equation}\label{eq11}
% a_{i}=\frac{c_{i}-\mu _{c}}{\sigma _{c}+\epsilon }*\gamma +\beta 
% \end{equation}

\begin{equation}\label{eq12}
\hat{\boldsymbol{x}}_{i}=\boldsymbol{x}_{i}\cdot \sigma \left(a_{i}\right)
\end{equation}

\noindent and all the enhanced features form the resulted feature of a cluster $\hat{\chi }=\left\{\hat{\boldsymbol{x}}_{1\ldots m}\right\}, \hat{\boldsymbol{x}}_{i}\in \mathbb{R}^{n}, m=s\times s$. 

As the superior performance of ResNet \cite{he2016deep}, we embedded the cluster-wise spatial attention and grouped convolution into a residual block, which we refer to as the CSA Block, as illustrated in Fig. 1. Following each CSABlock, a convolution without padding is applied to increase the receptive field and decrease the output feature map size, which has been widely used in handling patch data with small size \cite{wang2021ssa}.

\subsection{Multi-scale Fusion Classifier}

In change detection or visual recognition, integrating features with different scales have been proved to be an effective solution to improve feature discriminativeness and parameter utilizing efficiency \cite{ou2022cnn, yang2022deep}. Therefore, we aggregate the features from different depths with different scales to form a comprehensive feature. Then the feature is imported to the two fully connected layers to generate the final CD result. Formally, the multi-scale fusion classifier can be expressed as:

\begin{equation}\label{eq13}
\boldsymbol{x}_{a}=\left[avg\left(x_{b1}\right), avg\left(x_{b2}\right),avg\left(x_{b3}\right)\right]
\end{equation}

\begin{equation}\label{eq14}
f\left(\boldsymbol{x}_{a}\right)=\Theta_{2}\left(\Theta_{1}\boldsymbol{x}_{a}+b_{1}\right)+b_{2} 
\end{equation}

\noindent where $x_{b1}$, $x_{b2}$ and $x_{b3}$ are the features from the first, second CSA Block and the final convolution layer respectively, the $avg()$ denotes the spatial average pooling, $[\cdot ]$ represents the concatenation operation, $\boldsymbol{x}_{a}$ is the aggregated feature. $f()$ denote the two fully connected layers, $\Theta $ and $b$ are the learnable parameters of the fully connected layers.

\subsection{Loss Function}

The loss $L$ for optimizing our model consists of two items, a classification loss $L_{C}$ for supervising the change detection results and a selection loss $L_{E}$ used to constrain the selection matrix:

\begin{equation}\label{eq15}
L=L_{C}+\alpha L_{E}
\end{equation}

\noindent where $\alpha $ is a trade-off coefficient that balances the minimization between the classification error and selection constraint item.

We adopt the weighted binary cross entropy loss as the classification loss to handle the imbalance between the number of changed and unchanged samples, which is characterized as:

\begin{equation}\label{eq16}
L_{C}=-\left[\omega _{c}y\log \left(\hat{y}\right)+\omega _{u}\left(1-y\right)\log \left(1-\hat{y}\right)\right]
\end{equation}

\noindent where $\hat{y}$ represent the predicted probability, $y$ is the true label that is 1 for the changed sample and 0 for the unchanged pixel, $\omega _{c}$ and $\omega _{u}$ are the weights of changed sample and unchanged sample, respectively.

The selection loss aims to guide the row vector of selection matrix $E$ approximates the one-hot vector so that the only one band is selected in a cluster. So, we regularize the entropy of the selection matrix by:

\begin{equation}\label{eq17}
L_{E}=\frac{1}{b}{\sum }_{i}^{b}{\sum }_{j}^{B}E_{ij}\log (E_{ij})
\end{equation}
\noindent where $E_{ij}$ is the $i$-th row j-th column of selection matrix $E$.

\section{Experimental}

% Figure environment removed

% Figure environment removed

This section describes the comparative experiments conducted to evaluate the effectiveness of the proposed ES2Net. Firstly, three commonly used public HSI datasets are introduced in Section IV-A. Secondly, we discuss the experimental setup, which involves comparison methods, evaluation metrics, and parameter settings, in Section IV-B. Thirdly, Sections IV-C, D, and E compare the performance of the proposed method with seven representative change detection methods' performance on three hyperspectral datasets. Fourthly, we analyze the influence of hyperparameters on the model's performance. Finally, to further examine how the performance improves by using our method, an ablation study is presented in Section IV-F.

\subsection{Datasets}

Our method was evaluated on three widely used HSI datasets: Farmland, River, and USA. These datasets were collected using the Hyperion sensor onboard the EO-1 satellite. The sensor covers wavelengths ranging from 0.4 to 2.5 ${\mu}$m with 242 spectral bands, providing HSIs with a spatial resolution of approximately 30 m and a spectral resolution of approximately 10 nm. 

\subsubsection{River dataset} The River dataset covers a river region in Jiangsu Province. It includes bitemporal HSIs acquired on May 3, 2013, and December 31, 2013, with a spatial extent of 463 x 241 pixels. After removing noisy bands, 198 bands were selected for change detection. The bitemporal images are shown in Fig. \ref{fig_datasets}(a) and (b) (bands 33, 22, and 11 as RGB). Changes in the dataset are mainly caused by the removal of sediment from the river.

\subsubsection{Farmland dataset} The Farmland dataset consists of bitemporal scenes captured over a farmland in Yancheng, Jiangsu Province, China, on May 3, 2006, and April 23, 2007. The dataset has a spatial size of 450 x 140 pixels, and 155 bands were considered after removing spectral bands with low signal-to-noise ratios. The false-color composites (band 33, 22, and 11 as RGB) of the two images are shown in Fig. \ref{fig_datasets} (c) and (d). Changes in the dataset were mainly caused by crop rotation.

\subsubsection{USA dataset} The USA dataset was obtained from an irrigated agricultural field in Hermiston City, Umatilla County, OR, USA. The dataset includes two hyperspectral images taken in 2004 and 2007, respectively. This dataset has a spatial size of 307 x 241 pixels and contains 154 bands after removing noisy bands. The false-color composites (bands 33, 22, and 11 as RGB) of the bitemporal images are shown in Fig. \ref{fig_datasets}(e) and (f). Changes in the dataset are mainly caused by the regulation of irrigation areas.

\subsection{Experimental Setup}
\subsubsection{Sampling Rate and Compared Methods} This set of experiments follows the same sampling rate as literature \cite{wang2022csdbf, shi2022learning} which involves selecting 3.36\%, 20.95\%, and 9.77\% of samples for training on the River, Farmland, and USA datasets, respectively. Approximately 1\% of these samples are reserved for validation, with the remaining data used for testing. To evaluate the effectiveness of the proposed method, we compare it against other commonly used and advanced approaches, including GETNET \cite{wang2018getnet}, PBCNN \cite{sharma2017patch}, 3D-CNN \cite{li2017spectral}, SSCNN \cite{zhan2021sscnn}, SSA-SiamNet \cite{wang2021ssa}, SFBS-FFGNET \cite{ou2022cnn}, and CSDBF \cite{wang2022csdbf}. 

\subsubsection{Evaluation metrics} To evaluate the performance of different methods, we utilized commonly used quantitative assessment indices, including overall accuracy (OA), Kappa coefficient (Kappa), Precision (Pr), Recall (Re) and F1-score (F1), which are calculated as follows:

\begin{footnotesize}
\begin{equation}\label{eq18}
\begin{aligned}[c]
OA&=\frac{TP+TN}{TP+TN+FP+FN} \\
Pr&=\frac{TP}{TP+FP} \\
Re&=\frac{TP}{TP+FN} \\
F1&=2\times \frac{Pr\times Re}{Pr+Re} \\
\textit{Kappa}&=\frac{OA-Pc}{1-Pc} \\
Pc&=\frac{\left(TP+FP\right)\left(TP+FN\right)+\left(FN+TN\right)\left(FP+TN\right)}{\left(TP+FP+TN+FN\right)^{2}}
\end{aligned}
\end{equation}
\end{footnotesize}

In Eq. (\ref{eq18}), the metrics used to evaluate the performance of the algorithm include four intermediate indices: True Positives (TP), denoting the number of correctly detected changed pixels; True Negatives (TN), representing the number of correctly identified unchanged pixels; False Positives (FP), which accounts for the number of false-alarm pixels; False Negatives (FN), indicating the number of missed changed pixels.

\subsubsection{Parameter Setting} In the proposed method, several hyperparameters, such as the number of selected bands, the number of convolutional kernels, and the trade-off parameter $\alpha $ can affect the model's performance in the final change detection task. Hence, we analyzed the impact of these parameters in our hyperparameter analysis experiments which is shown in IV-F. In comparison experiments, we set the band down sample rate as 16, i.e., selecting 12, 10, and 10 bands from the 198, 155, and 154 spectral bands in the River, Farmland, and USA datasets, respectively. The number of convolutional kernels in feature extraction network is set to three times the number of selected bands, i.e., 36, 30, and 30 for the River, Farmland, and USA datasets, respectively. For the trade-off parameter $\alpha $, we set it as 0.1 empirically. Considering the number of changed samples is much less than that of unchanged sample, we set the weights $\omega _{c}$ and $\omega _{u}$ of changed samples and unchanged sample to 5 and 1, respectively, to increase the penalty for changed samples. Furthermore, the hyperparameter settings of the comparable methods were kept consistent with those described in their respective articles.

\subsection{Experiment on River Dataset}

\begin{table}[t]
\centering
\caption{Change detection results of the river dataset, model parameters and FLOPs.}
\resizebox{\linewidth}{!}{
\begin{tabular}{cccccccc}
\hline
Method        & OA             & Kappa          & F1             & Pr    & Re    & Parameters(k) & FLOPs(k)   \\ \hline
GETNET        & 95.51          & 74.42          & 76.76          & 65.34 & 92.84 & 154179.42   & - \\
PBCNN         & 96.02          & 71.61          & 73.79          & 75.11 & 72.62 & 235.17       & 3416.93   \\
3D-CNN        & 96.71          & 73.76          & 75.39          & \textbf{95.31} & 62.21 & 245.79      & 492.23   \\
SSCNN-S       & 95.54          & 74.08          & 76.51          & 64.95 & \textbf{93.25} & 21.68        & 1082.72   \\
SSA-SiamNet   & 97.35          & 82.01          & 83.36          & 82.26 & 84.50 & 107.18       & 1795.66    \\
SFBS-FFGNET   & 96.70          & 77.10          & 82.09          & 84.33 & 79.86 & 488.71       & 9790.00       \\
CSDBF         & 96.97          & 79.82          & 82.31          & 84.66 & 80.10  & 122.41       & -     \\
Ours & \textbf{97.46} & \textbf{83.15} & \textbf{84.53} & 80.87 & 88.54 & 42.21        & 288.64     \\ \hline
\end{tabular}}
\label{table1}
\end{table}

% Figure environment removed

% % Figure environment removed

% % Figure environment removed

Table \ref{table1} displays the results of testing all methods on the River dataset, where the proposed method achieves the best performance in terms of OA, Kappa and F1 indices. Due to class imbalance in the dataset, the OA values of most methods were similar, but significant differences can be observed in Kappa values. The proposed method demonstrates a clear advantage in the Kappa index and achieved a 1.14\% improvement over the second-best method, SSA-SiamNet. Different from SFBS-FFGNET, which employs an independent band selection method before the HSI is fed to change detection network, our model integrated a band selection module that is trained jointly with the feature extraction network. The learnable band selection module allowed our method to select more discriminative features, resulting in a 4.48\% increase in Kappa index and a 0.76\% increase in OA than SFBS-FFGNET. Furthermore, SFBS-FFGNET utilizes a complex network to extract changing information; however, we construct a lighter network with approximately 1/10 of its parameters, but achieve better performance. According to the last columns of Table \ref{table1}, our proposed method shows fewer parameters and faster inference speed comparing with most patch-based methods. For fairness, we do not compare FLOPs with GETNET and CSDBF, because both methods inference with an entire image, which typically causes higher FLOPs. 

Fig. \ref{fig_rivercdmap} presents the change detection maps obtained by the different methods. For most methods, it can be observed that many small objects are misidentified over the green box and the change detection results in the red box do not match well with the ground truth. However, the change detection map obtained by our model is the closest to the ground-truth map.

The 12 bands selected by band selection module and the entropy of differential HSI are shown in Fig. \ref{fig_rivercombo} (a). We can see the 12 bands are carefully selected, avoiding adjacent bands containing high redundancy. It is attributed to clustering constraint that effectively partitions all bands into several groups with low correlation. The convergence process of band importance weight is illustrated in Fig. \ref{fig_rivercombo} (b). During the training process, those bands helpful to change detection are progressively highlighted, while bands that do not aid in change detection are suppressed. After 400 epochs, the 12 bands that most beneficial to change detection in all bands are identified and the band importance weights become stable.

\subsection{Experiment on Farmland Dataset}

\begin{table}[t]
\centering
\caption{Change detection results of the farmland dataset, model parameters and FLOPs.}
\resizebox{\linewidth}{!}{
\begin{tabular}{cccccccc}
\hline
Method      & OA    & Kappa & F1    & Pr    & Re    & Parameters(k)  & FLOPs(k)   \\ \hline
GETNET      & 97.79 & 94.46 & 95.99 & 94.39 & 97.74 & 93415.26 & - \\
PBCNN      & 97.61 & 94.13 & 95.79 & 95.01 & 96.59 & 210.40   & 2797.73   \\
3D-CNN      & 98.01 & 95.20  & 96.54 & 94.79 & 98.33 & 196.25   & 393.16    \\
SSCNN-S     & 98.45 & 96.13 & 97.19 & 96.69 & 97.44 & 18.07    & 902.12    \\
SSA-SiamNet & 98.12 & 95.81 & 96.34 & 96.24 & 96.44 & 88.60    & 1486.06   \\
SFBS-FFGNET & 97.60  & 94.30  & 95.94 & 93.09 & \textbf{98.66} & 488.71   & 9790         \\
CSDBF       & 98.43 & 96.20  & 97.06 & 97.18 & 96.94 & 105.64   & -      \\
Ours        & \textbf{98.58} & \textbf{96.47}  & \textbf{97.46} & \textbf{97.43} & 97.48 & 30.68    & 213.64     \\ \hline
\end{tabular}}
\label{table2}
\end{table}

% Figure environment removed

% % Figure environment removed

% % Figure environment removed

Table \ref{table2} presents the results of all experimental methods on the Farmland dataset. Our proposed method achieves the highest OA, Kappa, F1, and Pr, with increases of 0.13\%, 0.34\%, 0.27\% and 0.74\% respectively, over the second-best method, SSCNN-S. CSDBF also performs well, achieving the third-best performance with an OA of 98.43\% and a Kappa of 96.20\%. Compared with SSA-SiamNet that utilizes one attention factor to scale all spatial features, our CSA applies one attention factor to each individual bands, avoiding the unbalanced attention allocation over bands. Thus, our proposed method also yielded a significant improvement over SSA-SiamNet, with a 0.46\% increase in OA and a 0.66\% increase in Kappa index.

Additionally, analyzing the data in the last two columns of Table \ref{table2}, our proposed method uses fewer parameters to achieve better performance in change detection and possesses the highest inference speed. This superior performance can be attributed to our proposed band selection module and the cluster-wise spatial mechanism. The former eliminates spectral redundancy, and the latter improves the discriminativeness of spatial features with few extra parameters, leading to an efficient utilization of parameters CD. The distribution of selected 10 bands and the entropy of differential HSI are presented in Fig. \ref{fig_farmlandcombo} (a). As we can see, the selected bands not only distribute uniform but also avoid the most sharply decreasing regions with low entropy. And the convergence process of band importance weights is shown in Fig. \ref{fig_farmlandcombo} (b).

\subsection{Experiment on USA Dataset}

\begin{table}[t]
\centering
\caption{Change detection results of the USA dataset, model parameters and FLOPs.}
\resizebox{\linewidth}{!}{
\begin{tabular}{cccccccc}
\hline
Method      & OA    & Kappa & F1    & Pr    & Re    & Parameters(k)  & FLOPs(k)   \\ \hline
GETNET      & 93.97 & 82.41 & 86.26 & 79.41 & 94.45 & 93415.26 & - \\
PBCNN      & 95.72 & 86.80 & 89.43 & 88.32 & 90.55 & 209.83   & 2783.33   \\
3D-CNN      & 96.31 & 88.25 & 90.59 & 91.54 & 89.77 & 195.10     & 4449.32   \\
SSCNN-S     & 96.30 & 88.64 & 91.03 & 87.48 & \textbf{95.06} & 17.98    & 897.92    \\
SSA-SiamNet & 95.80 & 87.41 & 90.01 & 86.71 & 93.37 & 88.22     & 1478.86   \\
SFBS-FFGNET & 94.64 & 84.34 & 87.86 & 87.22 & 88.50 & 488.71    & 9790       \\
CSDBF       & 96.87 & \textbf{90.93} & 92.70 & \textbf{94.62} & 90.85 & 105.25   & -     \\
Ours        & \textbf{96.95} & 90.81 & \textbf{92.74} & 94.28 & 91.24 & 29.19     & 199.3      \\ \hline
\end{tabular}}
\label{table3}
\end{table}

% Figure environment removed

% % Figure environment removed

% % Figure environment removed

Table \ref{table3} presents the change detection results of the different methods in the experiment on the USA dataset. Our method achieves the highest OA and F1, demonstrating better overall performance than other methods. Although CSDBF gives the highest Pr and Kappa, it is slightly inferior to our method in other metrics and contains five times the number of parameters as us. We also observe that SSCNN-S doesn’t achieve great performance with a lightweight network structure. The reason may be that it directly applies the $1\times1$ convolution layer to fuse the redundant bands to reduce the spectral dimension of HSI, making it difficult to obtain discriminative low-dimensional features in a limited sample range. We suppose that a learnable band selection module is a more sensible option to reduce the spectral dimension of HSI, because it can avoid the interfere from irrelevant bands and select discriminative bands with considering the inherent spectral inter-relationships. The distribution of selected 10 bands and the entropy of differential HSI are shown in Fig \ref{fig_USAcombo} (a). And the convergence process of band importance weights is presented in Fig \ref{fig_USAcombo} (b).

\subsection{Hyperparameter Analysis}

\begin{table}[t]
\centering
\caption{Change detection results of different down sample rates and expansion rates in three datasets.}
\resizebox{\linewidth}{!}{
\begin{tabular}{c|cc|ccccc}
\hline
Dataset                   & Downsample & Expansion & OA             & Kappa          & F1             & Pr             & Re             \\ \hline
\multirow{4}{*}{River}    & 32         & 2         & 97.27          & 82.09          & 83.57          & 79.03          & 88.66          \\
                          & 32         & 3         & 96.89          & 80.73          & 82.41          & 73.95          & \textbf{93.06} \\
                          & 16         & 2         & 97.06          & 81.22          & 82.82          & 76.37          & 90.45          \\
                          & 16         & 3         & \textbf{97.46} & \textbf{83.15} & \textbf{84.53} & \textbf{80.87} & 88.54          \\ \hline
\multirow{4}{*}{Farmland} & 32         & 2         & 98.33          & 95.83          & 96.99          & 97.33          & 96.64          \\
                          & 32         & 3         & 98.53          & 96.35          & 97.37          & 97.30          & 97.44          \\
                          & 16         & 2         & 98.44          & 96.12          & 97.20          & 97.35          & \textbf{97.70} \\
                          & 16         & 3         & \textbf{98.58} & \textbf{96.47} & \textbf{97.46} & \textbf{97.43} & 97.48          \\ \hline
\multirow{4}{*}{USA}      & 32         & 2         & 96.38          & 88.92          & 91.2           & 94.67          & 87.97          \\
                          & 32         & 3         & 96.40          & 89.00          & 91.26          & \textbf{94.68} & 88.08          \\
                          & 16         & 2         & 96.44          & 89.17          & 91.41          & 94.32          & 88.68          \\
                          & 16         & 3         & \textbf{96.95} & \textbf{90.81} & \textbf{92.74} & 94.28          & \textbf{91.24} \\ \hline
\end{tabular}}
\label{table4}
\end{table}

To analyze the influence of the number of selected bands and channels on change detection results, we conducted experiments with varying down-sample rates $r_{d}$ and channel expansion rates $r_{e}$. Specifically, we selected $1/r_{d}$ bands from all bands and set the number of channels in our change detection network to a factor of $r_{e}$ times the number of selected bands. The results are shown in Table \ref{table4}.

As we can see, the model performance suffers a more or less decline when the number of selected bands is less. The decline is obvious in River and USA, which reveals that 1/32 total bands are not enough to provide sufficient changing information to achieve excellent CD. What is more, a smaller expansion rate typically leads a worse performance. This may be because the reduction in parameters caused a decrease in the network's ability to express complex features. We decided to set $r_{d}$ to 16 and $r_{e}$ to 3, because our model achieved the best performance in all datasets with this pair of hyperparameters. While these values may not be optimal, they provide generally good results across three datasets.

\begin{table}[t]
\centering
\caption{Ablation analysis in three datasets.}
\resizebox{\linewidth}{!}{
\begin{tabular}{cccccccc}
\hline
\multicolumn{1}{c|}{Dataset}                   & Band Selection & \multicolumn{1}{c|}{Spatial Attention} & OA                 & Kappa              & F1                 & Pr                & Re                \\ \hline
\multicolumn{1}{c|}{\multirow{5}{*}{River}}    & \ding{55}      & \multicolumn{1}{c|}{\ding{55}}                  & 95.04  & 71.23  & 73.88   & 62.97  & 89.35  \\
\multicolumn{1}{c|}{}                          & $\checkmark$   & \multicolumn{1}{c|}{\ding{55}}                  & 96.28  & 76.91  & 78.93  & 70.96  & 89.20  \\
\multicolumn{1}{c|}{}                          & $\checkmark$   & \multicolumn{1}{c|}{naive}                      & 96.85  & 80.00  & 81.71  & 75.02  & \textbf{89.74} \\
\multicolumn{1}{c|}{}                          & $\checkmark$   & \multicolumn{1}{c|}{cluster-wise}               & \textbf{97.46}  & \textbf{83.15}  & \textbf{84.53}  & \textbf{80.07}  & 88.54  \\ \hline
\multicolumn{1}{c|}{\multirow{5}{*}{Farmland}} & \ding{55}      & \multicolumn{1}{c|}{\ding{55}}                  & 97.97  & 95.43  & 96.96  & 96.73  & 97.19   \\
\multicolumn{1}{c|}{}                          & $\checkmark$   & \multicolumn{1}{c|}{\ding{55}}                  & 98.33  & 95.84  & 97.00  & 97.19  & 96.82 \\
\multicolumn{1}{c|}{}                          & $\checkmark$   & \multicolumn{1}{c|}{naive}                      & 98.40  & 96.03  & 97.14  & 96.85  & 97.43  \\
\multicolumn{1}{c|}{}                          & $\checkmark$   & \multicolumn{1}{c|}{cluster-wise}               & \textbf{98.55}  & \textbf{96.47}   & \textbf{97.46}  & \textbf{97.43}  & \textbf{97.48}  \\ \hline
\multicolumn{1}{c|}{\multirow{5}{*}{USA}}      & \ding{55}      & \multicolumn{1}{c|}{\ding{55}}                  & 96.13  & 88.46  & 90.92  & 91.07  & 90.76  \\
\multicolumn{1}{c|}{}                          & $\checkmark$   & \multicolumn{1}{c|}{\ding{55}}                  & 96.50  & 89.51  & 91.73  & 92.52  & 90.96  \\
\multicolumn{1}{c|}{}                          & $\checkmark$   & \multicolumn{1}{c|}{naive}                      & 96.48  & 89.19  & 91.39  & \textbf{95.54}  & 87.59  \\
\multicolumn{1}{c|}{}                          & $\checkmark$   & \multicolumn{1}{c|}{cluster-wise}               & \textbf{96.95}  & \textbf{90.81}  & \textbf{92.74}  & 94.28  & \textbf{91.24}  \\ \hline
\end{tabular}}
\label{table5}
\end{table}

\subsection{Ablation Experiment}

We conducted an ablation study to evaluate the efficacy of the band selection module and the cluster-wise spatial attention. Table \ref{table5} presents the change detection performance of models with and without these two modules. The baseline is composed of two residual blocks with a channel number of 32 and a multi-scale fusion classifier. The results indicate that adding the band selection module to the baseline leads to better performance in the three datasets, demonstrating that a limited number of discriminative bands are sufficient to train a change detection network. We can observe that the cluster-wise spatial attention module also leads to further improved performance. Furthermore, we compared the performance of cluster-wise spatial attention and naive spatial attention \cite{woo2018cbam}. As we can see, cluster-wise spatial attention is more effective than naive spatial attention when used with the band selection module. After band selection, the feature distribution differences among bands are significant. Naive spatial attention ignores this point and adopts a uniform attention factor to features of all bands, thus overemphasizing the features of some bands and ignoring the features of others. In contrast, cluster-wise spatial attention generates an attention factor to each band, individually enhancing the feature discriminativeness of each band.

\section{Conclusion}

In this study, an efficient spectral-spatial network ES2Net has been proposed for hyperspectral image change detection. The proposed model introduces a learnable band selection module and a cluster-wise spatial attention mechanism to achieve a highly efficient utilization of spectral and spatial information. The learnable band selection module automatically selects the bands that most contribute to change detection, avoiding feature confusion caused by irrelevant spectral information fusion and enabling the end-to-end training by connecting with the change detection network. The cluster-wise spatial attention mechanism assigns different spatial attention to features from different bands, improving the discriminativeness of changing features by fully considering the spatial variance among bands. The comprehensive experiments on three widely used hyperspectral change detection datasets demonstrate the superiority of the proposed ES2Net method over other state-of-the-art hyperspectral change detection methods. Finally, it is worth working that the proposed band selection module can be easily extended to other HSI processing tasks.

\bibliographystyle{IEEEtran}
\bibliography{ref}



% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a
% line do not exceed the text width or a line break will occur.
%
%% Figure environment removed
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively.
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.







% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%





% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)


% biography section
%
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{% Figure removed}]{Michael Shell}
% or if you just want to reserve a space for a photo:


% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}


% that's all folks
\end{document}


