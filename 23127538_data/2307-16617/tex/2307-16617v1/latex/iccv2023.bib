@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}
@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

%--------- 2D & 3D backbone
@InProceedings{Xie_2017_CVPR,
author = {Xie, Saining and Girshick, Ross and Dollar, Piotr and Tu, Zhuowen and He, Kaiming},
title = {Aggregated Residual Transformations for Deep Neural Networks},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
month = {July},
year = {2017}
}
@InProceedings{He_2016_CVPR,
author    = {Kaiming He and
           Xiangyu Zhang and
           Shaoqing Ren and
           Jian Sun},
title     = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognitions},
pages     = {770--778},
year      = {2016},
url       = {https://doi.org/10.1109/CVPR.2016.90},
doi       = {10.1109/CVPR.2016.90},
timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
biburl    = {https://dblp.org/rec/conf/cvpr/HeZRS16.bib},
bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Dai_2017_ICCV,
author = {Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
title = {Deformable Convolutional Networks},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}
@InProceedings{Chen_2019_CVPR,
author = {Chen, Kai and Pang, Jiangmiao and Wang, Jiaqi and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
title = {Hybrid Task Cascade for Instance Segmentation},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
month = {June},
year = {2019}
}
@article{zhou2020cylinder3d,
  title={Cylinder3d: An effective 3d framework for driving-scene lidar semantic segmentation},
  author={Zhou, Hui and Zhu, Xinge and Song, Xiao and Ma, Yuexin and Wang, Zhe and Li, Hongsheng and Lin, Dahua},
  journal={arXiv preprint arXiv:2008.01550},
  year={2020}
}
@inproceedings{yu2018deep,
  title={Deep layer aggregation},
  author={Yu, Fisher and Wang, Dequan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2403--2412},
  year={2018}
}
@inproceedings{zhou2018voxelnet,
  title={Voxelnet: End-to-end learning for point cloud based 3d object detection},
  author={Zhou, Yin and Tuzel, Oncel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4490--4499},
  year={2018}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@article{cheng2021per,
  title={Per-pixel classification is not all you need for semantic segmentation},
  author={Cheng, Bowen and Schwing, Alex and Kirillov, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17864--17875},
  year={2021}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={Proceedings of European Conference on Computer Vision},
  pages={213--229},
  year={2020},
}

@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}

%--------- 2D multi-task multi-modal
@article{lin2019pareto,
  title={Pareto multi-task learning},
  author={Lin, Xi and Zhen, Hui-Ling and Li, Zhenhua and Zhang, Qing-Fu and Kwong, Sam},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{leang2020dynamic,
  title={Dynamic task weighting methods for multi-task networks in autonomous driving systems},
  author={Leang, Isabelle and Sistu, Ganesh and B{\"u}rger, Fabian and Bursuc, Andrei and Yogamani, Senthil},
  booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
  pages={1--8},
  year={2020},
  organization={IEEE}
}

@inproceedings{chennupati2019multinet++,
  title={Multinet++: Multi-stream feature aggregation and geometric loss strategy for multi-task learning},
  author={Chennupati, Sumanth and Sistu, Ganesh and Yogamani, Senthil and A Rawashdeh, Samir},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={0--0},
  year={2019}
}

@article{wu2021yolop,
  title={Yolop: You only look once for panoptic driving perception},
  author={Wu, Dong and Liao, Manwen and Zhang, Weitian and Wang, Xinggang},
  journal={arXiv preprint arXiv:2108.11250},
  year={2021}
}


%--------- Vision-language
%--------- Vision-Audio
@article{goel2022cyclip,
  title={CyCLIP: Cyclic Contrastive Language-Image Pretraining},
  author={Goel, Shashank and Bansal, Hritik and Bhatia, Sumit and Rossi, Ryan A and Vinay, Vishwa and Grover, Aditya},
  journal={arXiv preprint arXiv:2205.14459},
  year={2022}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


@inproceedings{wang20222modality,
  author    = {Xun Wang and
               Bingqing Ke and
               Xuanping Li and
               Fangyu Liu and
               Mingyu Zhang and
               Xiao Liang and
               Qiushi Xiao},

  title     = {Modality-Balanced Embedding for Video Retrieval},
  booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages     = {2578--2582},
  year      = {2022},
}
%-------- 3D task-------
%-------- BEV network -------
@inproceedings{caesar2020nuscenes,
  title={nuscenes: A multimodal dataset for autonomous driving},
  author={Caesar, Holger and Bankiti, Varun and Lang, Alex H and Vora, Sourabh and Liong, Venice Erin and Xu, Qiang and Krishnan, Anush and Pan, Yu and Baldan, Giancarlo and Beijbom, Oscar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11621--11631},
  year={2020}
}

@article{liang2022bevfusion,
  title={{BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework}},
  author={Liang, Tingting and Xie, Hongwei and Yu, Kaicheng and Xia, Zhongyu and Lin, Zhiwei and Wang, Yongtao and Tang, Tao and Wang, Bing and Tang, Zhi},
  journal={arXiv preprint arXiv:2205.13790},
  year={2022}
}

@article{liu2022bevfusion,
  title={BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation},
  author={Liu, Zhijian and Tang, Haotian and Amini, Alexander and Yang, Xinyu and Mao, Huizi and Rus, Daniela and Han, Song},
  journal={arXiv preprint arXiv:2205.13542},
  year={2022}
}

@article{roddick2018orthographic,
  title={Orthographic feature transform for monocular 3d object detection},
  author={Roddick, Thomas and Kendall, Alex and Cipolla, Roberto},
  journal={arXiv preprint arXiv:1811.08188},
  year={2018}
}

@inproceedings{philion2020lift,
  title={Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3d},
  author={Philion, Jonah and Fidler, Sanja},
  booktitle={Proceedings of European Conference on Computer Vision},
  pages={194--210},
  year={2020},
}

@inproceedings{bai2022transfusion,
  title={Transfusion: Robust lidar-camera fusion for 3d object detection with transformers},
  author={Bai, Xuyang and Hu, Zeyu and Zhu, Xinge and Huang, Qingqiu and Chen, Yilun and Fu, Hongbo and Tai, Chiew-Lan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1090--1099},
  year={2022}
}


@inproceedings{kendall2018multi,
  title={Multi-task learning using uncertainty to weigh losses for scene geometry and semantics},
  author={Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7482--7491},
  year={2018}
}

@inproceedings{feng2021simple,
  title={A simple and efficient multi-task network for 3d object detection and road understanding},
  author={Feng, Di and Zhou, Yiyang and Xu, Chenfeng and Tomizuka, Masayoshi and Zhan, Wei},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={7067--7074},
  year={2021},
}


@article{ye2022lidarmultinet,
  title={LidarMultiNet: Towards a Unified Multi-task Network for LiDAR Perception},
  author={Ye, Dongqiangzi and Zhou, Zixiang and Chen, Weijia and Xie, Yufei and Wang, Yu and Wang, Panqu and Foroosh, Hassan},
  journal={arXiv preprint arXiv:2209.09385},
  year={2022}
}


@article{liu2022petr,
  title={Petr: Position embedding transformation for multi-view 3d object detection},
  author={Liu, Yingfei and Wang, Tiancai and Zhang, Xiangyu and Sun, Jian},
  journal={arXiv preprint arXiv:2203.05625},
  year={2022}
}

@article{liu2022petrv2,
  title={PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images},
  author={Liu, Yingfei and Yan, Junjie and Jia, Fan and Li, Shuailin and Gao, Qi and Wang, Tiancai and Zhang, Xiangyu and Sun, Jian},
  journal={arXiv preprint arXiv:2206.01256},
  year={2022}
}


@article{xie2022m,
  title={M\^{} 2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Birds-Eye View Representation},
  author={Xie, Enze and Yu, Zhiding and Zhou, Daquan and Philion, Jonah and Anandkumar, Anima and Fidler, Sanja and Luo, Ping and Alvarez, Jose M},
  journal={arXiv preprint arXiv:2204.05088},
  year={2022}
}


@inproceedings{vora2020pointpainting,
  title={Pointpainting: Sequential fusion for 3d object detection},
  author={Vora, Sourabh and Lang, Alex H and Helou, Bassam and Beijbom, Oscar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4604--4612},
  year={2020}
}

@article{chen2022autoalign,
  title={AutoAlign: Pixel-Instance Feature Aggregation for Multi-Modal 3D Object Detection},
  author={Chen, Zehui and Li, Zhenyu and Zhang, Shiquan and Fang, Liangji and Jiang, Qinghong and Zhao, Feng and Zhou, Bolei and Zhao, Hang},
  journal={arXiv preprint arXiv:2201.06493},
  year={2022}
}

@article{yin2021multimodal,
  title={Multimodal virtual point 3d detection},
  author={Yin, Tianwei and Zhou, Xingyi and Kr{\"a}henb{\"u}hl, Philipp},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16494--16507},
  year={2021}
}

@inproceedings{xu2021fusionpainting,
  title={FusionPainting: Multimodal fusion with adaptive attention for 3d object detection},
  author={Xu, Shaoqing and Zhou, Dingfu and Fang, Jin and Yin, Junbo and Bin, Zhou and Zhang, Liangjun},
  booktitle={2021 IEEE International Intelligent Transportation Systems Conference (ITSC)},
  pages={3047--3054},
  year={2021},
  organization={IEEE}
}

@inproceedings{lang2019pointpillars,
  title={Pointpillars: Fast encoders for object detection from point clouds},
  author={Lang, Alex H and Vora, Sourabh and Caesar, Holger and Zhou, Lubing and Yang, Jiong and Beijbom, Oscar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12697--12705},
  year={2019}
}

@inproceedings{yin2021center,
  title={Center-based 3d object detection and tracking},
  author={Yin, Tianwei and Zhou, Xingyi and Krahenbuhl, Philipp},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11784--11793},
  year={2021}
}

@article{chen2022futr3d,
  title={Futr3d: A unified sensor fusion framework for 3d detection},
  author={Chen, Xuanyao and Zhang, Tianyuan and Wang, Yue and Wang, Yilun and Zhao, Hang},
  journal={arXiv preprint arXiv:2203.10642},
  year={2022}
}

@inproceedings{liang2019multi,
  title={Multi-task multi-sensor fusion for 3d object detection},
  author={Liang, Ming and Yang, Bin and Chen, Yun and Hu, Rui and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7345--7353},
  year={2019}
}

%-------- multi modality -------

@inproceedings{wang2020makes,
  title={What makes training multi-modal classification networks hard?},
  author={Wang, Weiyao and Tran, Du and Feiszli, Matt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12695--12705},
  year={2020}
}

@inproceedings{peng2022balanced,
  title={Balanced Multimodal Learning via On-the-fly Gradient Modulation},
  author={Peng, Xiaokang and Wei, Yake and Deng, Andong and Wang, Dong and Hu, Di},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8238--8247},
  year={2022}
}
ga
@inproceedings{gao2020listen,
  title={Listen to look: Action recognition by previewing audio},
  author={Gao, Ruohan and Oh, Tae-Hyun and Grauman, Kristen and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10457--10467},
  year={2020}
}

@article{ismail2020improving,
  title={Improving multimodal accuracy through modality pre-training and attention},
  author={Ismail, Aya Abdelsalam and Hasan, Mahmudul and Ishtiaq, Faisal},
  journal={arXiv preprint arXiv:2011.06102},
  year={2020}
}

@inproceedings{kazakos2019epic,
  title={Epic-fusion: Audio-visual temporal binding for egocentric action recognition},
  author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5492--5501},
  year={2019}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2425--2433},
  year={2015}
}

@article{ilievski2017multimodal,
  title={Multimodal learning and reasoning for visual question answering},
  author={Ilievski, Ilija and Feng, Jiashi},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  pages={551--562},
  year={2017}
}

@inproceedings{kiela2018efficient,
  title={Efficient large-scale multi-modal classification},
  author={Kiela, Douwe and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages = {5198--5204},
  year={2018}
}

@inproceedings{owens2018audio,
  title={Audio-visual scene analysis with self-supervised multisensory features},
  author={Owens, Andrew and Efros, Alexei A},
  booktitle={Proceedings of the European Conference on Computer Vision},
  pages={631--648},
  year={2018}
}


@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7132--7141},
  year={2018}
}

@article{liang2022mind,
  title={Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning},
  author={Liang, Weixin and Zhang, Yuhui and Kwon, Yongchan and Yeung, Serena and Zou, James},
  journal={arXiv preprint arXiv:2203.02053},
  year={2022}
}
%-------- multi task -------

@article{liang2022effective,
  title={Effective Adaptation in Multi-Task Co-Training for Unified Autonomous Driving},
  author={Liang, Xiwen and Wu, Yangxin and Han, Jianhua and Xu, Hang and Xu, Chunjing and Liang, Xiaodan},
  journal={arXiv preprint arXiv:2209.08953},
  year={2022}
}

@article{ruder2017overview,
  title={An overview of multi-task learning in deep neural networks},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1706.05098},
  year={2017}
}

@article{vandenhende2021multi,
  title={Multi-task learning for dense prediction tasks: A survey},
  author={Vandenhende, Simon and Georgoulis, Stamatios and Van Gansbeke, Wouter and Proesmans, Marc and Dai, Dengxin and Van Gool, Luc},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  pages = {3614--3633},
  year={2021},
}

@inproceedings{chen2018gradnorm,
  title={Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks},
  author={Chen, Zhao and Badrinarayanan, Vijay and Lee, Chen-Yu and Rabinovich, Andrew},
  booktitle={International Conference on Machine Learning},
  pages={794--803},
  year={2018},
}

@inproceedings{liu2019end,
  title={End-to-end multi-task learning with attention},
  author={Liu, Shikun and Johns, Edward and Davison, Andrew J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1871--1880},
  year={2019}
}


@inproceedings{liu2021towards,
  title={Towards impartial multi-task learning},
  author={Liu, Liyang and Li, Yi and Kuang, Zhanghui and Xue, J and Chen, Yimin and Yang, Wenming and Liao, Qingmin and Zhang, Wayne},
  year={2021},
  booktitle = {International Conference on Learning Representations},
}liu2019end,

@inproceedings{misra2016cross,
  title={Cross-stitch networks for multi-task learning},
  author={Misra, Ishan and Shrivastava, Abhinav and Gupta, Abhinav and Hebert, Martial},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3994--4003},
  year={2016}
}
@inproceedings{ruder2019latent,
  title={Latent multi-task architecture learning},
  author={Ruder, Sebastian and Bingel, Joachim and Augenstein, Isabelle and S{\o}gaard, Anders},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={4822--4829},
  year={2019}
}

@inproceedings{guo2020learning,
  title={Learning to branch for multi-task learning},
  author={Guo, Pengsheng and Lee, Chen-Yu and Ulbricht, Daniel},
  booktitle={International Conference on Machine Learning},
  pages={3854--3863},
  year={2020},
}

@inproceedings{xu2018pad,
  title={Pad-net: Multi-tasks guided prediction-and-distillation network for simultaneous depth estimation and scene parsing},
  author={Xu, Dan and Ouyang, Wanli and Wang, Xiaogang and Sebe, Nicu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={675--684},
  year={2018}
}


@article{li2022bevdepth,
  author    = {Yinhao Li and
               Zheng Ge and
               Guanyi Yu and
               Jinrong Yang and
               Zengran Wang and
               Yukang Shi and
               Jianjian Sun and
               Zeming Li},
  title     = {BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection},
  journal={arXiv preprint arXiv:2206.10092},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2206.10092},
  doi       = {10.48550/arXiv.2206.10092},
  eprinttype = {arXiv},
  eprint    = {2206.10092},
  timestamp = {Mon, 27 Jun 2022 16:51:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2206-10092.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zhang2022beverse,
  author    = {Yunpeng Zhang and
               Zheng Zhu and
               Wenzhao Zheng and
               Junjie Huang and
               Guan Huang and
               Jie Zhou and
               Jiwen Lu},
  title     = {BEVerse: Unified Perception and Prediction in Birds-Eye-View for Vision-Centric
               Autonomous Driving},
  journal   = {arXiv preprint arXiv:2205.09743},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2205.09743},
  doi       = {10.48550/arXiv.2205.09743},
  eprinttype = {arXiv},
  eprint    = {2205.09743},
  timestamp = {Mon, 23 May 2022 14:22:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2205-09743.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{li2022hdmapnet,
  author    = {Qi Li and
               Yue Wang and
               Yilun Wang and
               Hang Zhao},
  title     = {HDMapNet: An Online {HD} Map Construction and Evaluation Framework},
  booktitle = {2022 International Conference on Robotics and Automation},
  pages     = {4628--4634},
  year      = {2022},
  url       = {https://doi.org/10.1109/ICRA46639.2022.9812383},
  doi       = {10.1109/ICRA46639.2022.9812383},
  timestamp = {Wed, 20 Jul 2022 18:22:50 +0200},
  biburl    = {https://dblp.org/rec/conf/icra/LiWWZ22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{li2022bevformer,
  author    = {Zhiqi Li and
               Wenhai Wang and
               Hongyang Li and
               Enze Xie and
               Chonghao Sima and
               Tong Lu and
               Yu Qiao and
               Jifeng Dai},
  title     = {BEVFormer: Learning Bird's-Eye-View Representation from Multi-camera Images via Spatiotemporal Transformers},
  booktitle = {Proceedings of the European Conference on Computer Vision},
  pages     = {1--18},
  year      = {2022},
  url       = {https://doi.org/10.1007/978-3-031-20077-9\_1},
  doi       = {10.1007/978-3-031-20077-9\_1},
  timestamp = {Thu, 10 Nov 2022 10:31:49 +0100},
  biburl    = {https://dblp.org/rec/conf/eccv/LiWLXSLQD22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{guo2020nuscenes,
  author    = {Yiluan Guo and
               Holger Caesar and
               Oscar Beijbom and
               Jonah Philion and
               Sanja Fidler},
  title     = {The efficacy of Neural Planning Metrics: {A} meta-analysis of {PKL}
               on nuScenes},
  journal   = {CoRR},
  volume    = {abs/2010.09350},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.09350},
  eprinttype = {arXiv},
  eprint    = {2010.09350},
  timestamp = {Wed, 21 Oct 2020 12:11:48 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-09350.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2980--2988},
  year={2017}
}

@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}

@article{openpcdet,
  author={OpenPCDet},
  year={Access on 2023},
  url={https://github.com/open-mmlab/OpenPCDet#nuscenes-3d-object-detection-baselines},
  title={nuScenes baselines: \url{https://github.com/open-mmlab/OpenPCDet\#nuscenes-3d-object-detection-baselines}}
}

@inproceedings{FIERY,
  author    = {Anthony Hu and
               Zak Murez and
               Nikhil Mohan and
               Sof{\'{\i}}a Dudas and
               Jeffrey Hawke and
               Vijay Badrinarayanan and
               Roberto Cipolla and
               Alex Kendall},
  title     = {{FIERY:} Future Instance Prediction in Bird's-Eye View from Surround
               Monocular Cameras},
  booktitle = {ICCV},
  pages     = {15253--15262},
  publisher = {{IEEE}},
  year      = {2021},
  url       = {https://doi.org/10.1109/ICCV48922.2021.01499},
  doi       = {10.1109/ICCV48922.2021.01499},
  timestamp = {Fri, 11 Mar 2022 10:01:59 +0100},
  biburl    = {https://dblp.org/rec/conf/iccv/HuMMDHBCK21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{planner,
  author    = {Wenyuan Zeng and
               Wenjie Luo and
               Simon Suo and
               Abbas Sadat and
               Bin Yang and
               Sergio Casas and
               Raquel Urtasun},
  title     = {End-To-End Interpretable Neural Motion Planner},
  booktitle = {CVPR},
  pages     = {8660--8669},
  publisher = {IEEE},
  year      = {2019},
  url       = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Zeng\_End-To-End\_Interpretable\_Neural\_Motion\_Planner\_CVPR\_2019\_paper.html},
  doi       = {10.1109/CVPR.2019.00886},
  timestamp = {Mon, 30 Aug 2021 17:01:14 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/ZengLSSYCU19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5824--5836},
  year={2020}
}

@article{mordan2021detecting,
  title={Detecting 32 pedestrian attributes for autonomous vehicles},
  author={Mordan, Taylor and Cord, Matthieu and P{\'e}rez, Patrick and Alahi, Alexandre},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={8},
  pages={11823--11835},
  year={2021},
  publisher={IEEE}
}

@inproceedings{hu2021fiery,
  title={FIERY: future instance prediction in bird's-eye view from surround monocular cameras},
  author={Hu, Anthony and Murez, Zak and Mohan, Nikhil and Dudas, Sof{\'\i}a and Hawke, Jeffrey and Badrinarayanan, Vijay and Cipolla, Roberto and Kendall, Alex},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15273--15282},
  year={2021}
}

@inproceedings{zeng2019end,
  title={End-to-end interpretable neural motion planner},
  author={Zeng, Wenyuan and Luo, Wenjie and Suo, Simon and Sadat, Abbas and Yang, Bin and Casas, Sergio and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8660--8669},
  year={2019}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}