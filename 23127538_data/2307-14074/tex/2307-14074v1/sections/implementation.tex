%-------------------------------------------------------------------------------
\section{Implementation} \label{imple}
%-------------------------------------------------------------------------------

% Figure environment removed

\sys's implementation consists of (\romannumerber{1}) a fully-functional \sys switch prototype which implements the overall in-fabric logic; and (\romannumerber{2}) a set of software APIs exposed to applications. Our prototype is built upon a FPGA-assisted commodity switch while a P4 programmable switch implementation is also provided.

%\sys's implementation consists of (\romannumerber{1}) a FPGA-based fully-functional prototype which implements the self-defined switch logic and (\romannumerber{2}) a set of software APIs exposed to multicast applications. \sys's switch logic can also be implemented on the Tofino P4 switch, as described in $\S$\ref{dis}.

\parab{FPGA-based prototype.} We implement the group registration, data packet duplication, header modification, and feedback aggregation logics on an FPGA board. The board is equipped with a commodity FPGA chip~\cite{ultrascale} and four 100Gbps Ethernet interfaces. The FPGA resource utilization is shown in Table~\ref{tab:overhead}. We build our testbed with the FPGA board, a commodity Ethernet switch, and four servers, as illustrated in Fig.~\ref{fig:fpgaprototype}. Each server is equipped with a commodity RNIC. The FPGA board and four RNICs are connected to the commodity switch through 100Gbps Ethernet interfaces. 

The commodity switch is configured by Access Control List (ACL) to route the servers' multicast traffic to the FPGA board. The FPGA board identifies the multicast data (ACK\footnote{In Fig.~\ref{fig:fpgaprototype}, we use ACK to represent all types of feedback.}) packets through the specific packet header by \textit{Parser} and \textit{Arbiter}. The data (ACK) packets will be duplicated (aggregated) by \textit{Duplicator} (\textit{ACK Aggregator}). The resulting packets will be pushed in \textit{Queue System}, waiting for the \textit{Multiplexer} to schedule in case for queue competition. Finally, the duplicated data (aggregated ACK) packets are sent back to the commodity switch. During processing, the \textit{Multicast Forwarding Table} is accessed when needed. %\todo{describe Fig. 8} Note those resulting packets' destination IP would be unicast IPs, so the switch routes them as normal unicast packets.
%

\parab{P4-based implementation.}
\sys in-fabric logic can be implemented on the P4 switch as well with some special handling. For the one-to-many data forwarding, P4 switch duplicates packets at the Traffic Manager (TM). The extended table states in Fig.~\ref{fig:table} are stored in the egress pipeline, indexed by <GroupID, EgressPort>. Because the lookup key in P4 switch is at most 32bits, we can use the least significant 24bits of GroupIP plus the 8bits port number as the real index. 

For the many-to-one feedback aggregation, there are two challenges due to the limited capability of P4 switch. Commodity P4 switch switch contains many stages, each with minimal computation capability and independent memory. Firstly, a single stage cannot support the \textit{wrapped-around} PSN comparison. To handle it, we simplify the standard PSN comparison to match the stage's capability, resulting in a tighter PSN space reduced from $2^{23}$ to $2^{22}$. Secondly, a single stage cannot iterate the entire table entries and find the minimum PSN. To handle it, we leverage multiple stages, each responsible for partial entries. Thus, the maximum number of entries supported in each multicast group is limited by the total stage number.

Besides, the P4 switch lacks the computation capability to recalculate the Invariant Cyclic Redundancy Checksum (ICRC) for the modified (aggregated) data (ACK) packets. As a result, those packets would violate the ICRC validation and be discarded at the receiver. This is why we choose the FPGA-based prototype to evaluate \sys in this work. However, a recent work shows that some RNICs provide the ability to bypass ICRC validation~\cite{switchML}. 
%Although this can work, it's a compromised method having security risks. 
%So we select the more integrated FPGA-based prototype to evaluate in $\S$\ref{eva}. Other operators can choose their preferred implementation based on their requirements.

%\begin{algorithm}[t]
%	\caption{Update PSN record and find PSN minimum in P4}\label{alg:psncomp}
%	\begin{algorithmic}[1]
%		%\Function{Generation}{}
%		\State $ack.psn, ack.port\gets $ the PSN and port of ACK packet
%		\State $rec.psn, rec.port\gets$ the PSN and port recorded
%		\State $isTrigger\gets$ whether the packet is a trigger packet
%		%\State $last\_ack\_psn\gets$ last aggregated ACK's psn
%		%\State $min\_port\gets$ port with minimum $ack\_psn$ last time
%		\State min.psn = ack.psn;
%		\State \textcolor{purple}{// every stage compare the PSN}
%		\If{$ack.psn > rec.psn$ or $(ack.psn <= 24'b3fffff$ and $rec.psn >= 24'b600000)$}
%			\State min.psn = rec.psn;
%			\If{rec.port == ack.port}
%				\State rec.psn = ack.psn;
%			\EndIf
%		\EndIf
%		\State \textcolor{purple}{// last stage write the min PSN back}
%		\If{isTrigger} 
%			\State ack.psn = min.psn;
%			\State Forward ACK.
%		\EndIf
%	\end{algorithmic}
%\end{algorithm}

\parab{Software APIs.} We provide various communication libraries and middleboxes for \sys multicast support. Take the commonly-used OpenMPI as an example, we modify the OpenMPI (v4.1.1)~\cite{openmpi} and UCX (v2.3)~\cite{ucx} to adapt to \sys's design, as shown in Fig.~\ref{fig:fpgaprototype}. Specifically, we add a new implementation of $MPI\_Bcast$ and modify UCX for multicast QPs creation and data transmission. When the new $MPI\_Bcast$ is called, the MPI process calls the UCX to establish QPs for multicast. Multicast members exchange their QPs information, and the handshake starts, as described in Appendix \ref{apx:regis}. Once the multicast group is successfully established, the UCX finally calls the RDMA primitives defined in the well-known \textit{libibverbs}~\cite{libibverbs} to transmit data. The software modifications at the end-host are transparent to the upper-layer applications and don't require any RNIC or RDMA driver modification.
%\parab{Coalescence of unicast and multicast}
%When we design \sys, there is a question in our mind: \textit{which is better, maintaining unicast and multicast transports separately at end-host, or utilizing the in-network support to enabling them to match the same transport?} Because of the long-standing resource limit in RNICs and the emeging trend of shifting appropriate computation task to programmability network, we believe the latter is the correct selection.

\begin{table}[t]
	\small
    \centering
%	\begin{center}
%    \begin{tabular}{l|c|c|c}
    \begin{tabular}{|p{0.2\linewidth}|p{0.18\linewidth}|p{0.18\linewidth}|p{0.18\linewidth}|}
    \hline
    \textbf{Resource} & \hfil \textbf{LUT} & \hfil \textbf{Register} & \hfil \textbf{BRAM} \\
    \hline
   	\textbf{Usage} & \hfil 53169 & \hfil 15391 & \hfil 188 \\
    \hline
    \end{tabular}
%    \end{center}
    \caption{Resource usage of the \sys in-fabric logic.}
    \label{tab:overhead}
    \vspace{-0.25cm}
\end{table}

%\parab{Resource overhead}  Note that the size of multicast forwarding table is determined by the number of ports of the switch and doesn't scale up with the multicast group size. 2.7MB memory can support upto 1K multicast groups, which is satisfied in datacenter. We provide a detailed calculation of the maxmum group support in Appendix \ref{apx:cal}. 