%--------------------------------------------------------------------------
\section{\sys}\label{design}
%--------------------------------------------------------------------------

We first describe the key ideas and design challenges of \sys ($\S$\ref{key-chalge}). Then we overview the \sys structure ($\S$\ref{design-overview}), briefing its main components and how they work together. After that, we elaborate these design components one by one ($\S$\ref{connection-handle}-$\S$\ref{other-design}). 

\subsection{Key Ideas and Challenges} \label{key-chalge}

\sys focuses on simultaneously achieving (\romannumerber{1})~the optimal multicast forwarding, (\romannumerber{2})~the efficient utilization of the advanced capabilities of RDMA, and (\romannumerber{3})~satisfying the deployment requirements. To this end, the key ideas behind \sys are to (\romannumerber{1})~perform the optimal multicast forwarding in the in-fabric distribution manner~\cite{crowcroft1988multicast, diab2022orca, shahbaz2019elmo}; and (\romannumerber{2})~re-purpose the native RDMA RC logic with careful switch coordination for an efficient multicast transport. 

However, there are critical challenges blocking the way: \textit{how to achieve integration between the optimal multicast forwarding and the existing RDMA RC logic}. Specifically, there are two main compatibility issues.

The first is that the connection-oriented logic~\cite{rocev2} of RC cannot find the associated QPs when receiving the traditional-forwarded multicast packets, illustrated in Fig.~\ref{fig:design:incompt}. During the traditional multicast forwarding, switches won't change the packet's layer-4 header. Switches either copy the entire packet~\cite{crowcroft1988multicast, Infiniband} or only modify the layer-3 (IP) header for layer-3 multicast routing~\cite{diab2022orca, shahbaz2019elmo}. Thus all packets contain an identical layer-4 header, which only matches at most one connection. The non-matched RNIC will discard these packets as it cannot find the associated QP and Queue Pair Context (QPC) based on the non-matched layer-4 header. 

Secondly, even if receivers can accept the packets and find the associated QPs, the second incompatibility impeding the leverage of RC is the existing reliability logic~\cite{zhu2015congestion, guo2016rdma}. The standard reliability logic is designed for single feedback (including ACK, NACK, CNP, \etc) stream from a single receiver. Thus, multiple feedback streams from multiple receivers can confuse RC and disturb its loss detection and retransmission routines. 

\sys is a fabric-supported multicast protocol that substantially differs from the traditional layer-3 in-fabric approaches. \sys systematically integrates its design components to address these two incompatibilities.

%\sys systematically integrates its design components to address these two incompatibilities. \sys is a fabric-supported multicast protocol that substantially differs from the traditional layer-3 in-fabric approaches. \sys extends the legacy table-based routing approach, including the control-plane table registration and the data-plane data (feedback) packets forwarding. \sys combines layer-4 states into its table design. Based on the extended table, \sys performs two operations. Firstly, \sys modifies the connection-related states in the packet header to achieve a virtual one-to-many connection. Then \sys aggregates feedback (including ACK, NACK, CNP, \etc) packets to reuse the existing reliability logic of RDMA RC. 

% Figure environment removed

% Figure environment removed

\subsection{\sys Overview} \label{design-overview}
Fig.~\ref{fig:overview} illustrates the architecture of \sys. The working steps of \sys are composed of three main phases: the control-plane multicast group registration (\circled{1} $\&$ \circled{2}), the data-plane one-to-many data forwarding (\circled{3}), and the data-plane many-to-one feedback aggregation (\circled{4}).

For the control-plane multicast group registration, \sys elaborately extends the legacy multicast forwarding table structure by integrating layer-4 states. We develop an out-of-band UDP-based protocol called \envelope to register forwarding table to switchesâ€”the master node\footnote{For ease of understanding, readers can think master node as the multicast source. Actually, the master node can be any node in the multicast group.} in the multicast group collects the layer-4 states of other nodes, fits these states into the \envelope packet format, and transmits to switches and other nodes for building forwarding table and affirming the multicast membership, respectively (\circled{1}). The involved nodes will answer ACKs to the master node to confirm its participation (\circled{2}). Due to space limitations, we present the extended forwarding table structure in the main body, leaving the remaining control-plane details in Appendix~\ref{apx:regis}.

For the data-plane one-to-many data forwarding ($\S$\ref{connection-handle}), \sys reserves the optimal multicast forwarding and achieves a virtual one-to-many connection. Let's take the multicast communication in Fig.~\ref{fig:overview} for an example. $S$ only transmits data once via the existing RC connection. Then the switches in the multicast tree copy data and forward them to multiple receivers via the optimal paths. In addition, some specific switches replace the connection-related states in the packet header to match different QPs in different receivers (\circled{3}), thus achieving a virtual one-to-many connection. For instance, $L_1$, $S_1$, $C_2$, and $S_3$ copy and forward data packets to specific ports that are identified in the forwarding table. Additionally, $L_2$, $L_3$, and $L_4$ replace some connection-related states in packet header to match QPs in $R_1$, $R_2$, and $R_3$.

After receiving data packets, receivers, $R_1$, $R_2$, and $R_3$, generate normal ACK/NACK/CNP packets following the existing RC logic. Then the fabric aggregates ACK, filters NACK/CNP, and forwards these feedbacks to the sender (\circled{4}) ($\S$\ref{ack-aggregation} $\&$ $\S$\ref{other-design}). We take ACK as an example. As shown in Fig.~\ref{fig:overview}, $L_2$, $L_3$, $L_4$, and $C_2$ only forward ACK packets to next-hop switches, as there is only one ACK stream as input. $S_3$ and $S_1$ perform ACK aggregation, as there are multiple ACK streams as input. $L_1$ changes the connection-related states in the ACK header to match the $S$'s QP before forwarding the aggregated ACK. %When there are NACK packets, the fabric carefully filters NACK packets to enable the sender can correctly detect and retransmit the lost packet. 

The aggregated ACK and NACK packets enable the sender to transmit the subsequent new data packets or retransmit the lost ones. The filtered CNPs are used to adjust the sender's sending rate. Every data packet will go through the above four steps until the multicast communication job is finished.

%\input{sections/data-forwarding}
\input{sections/connection-handle}
\input{sections/ack-aggregation}
\input{other}
