We examine the effectiveness of PTD via quantitative evaluations,
generalization trial, visual analysis, and ablation studies on two
HOI-M prediction datasets: WBHM \cite{Mandery2015a} and Bimanual
Actions \cite{dreher2020learning}. 

\subsection{Preliminaries}

This section describes the datasets, the baselines, and metrics in
used. Further details are in Supp, Sec. 1.

\subsubsection{Datasets}

\paragraph{Whole-Body Human Motion (WBHM) Database \cite{Mandery2015a}}

is a large-scale dataset featuring 3D motion data of both humans and
objects, which is well suited for this paper. From the raw 3D data,
the selected visual features include 3D skeleton poses of 18 joints
for human entities $(x\in\mathbb{R}^{54})$ and 3D bounding boxes
for objects $(x\in\mathbb{R}^{24})$, sampled at 10Hz, consistent
with the compared methods \cite{corona2020context}.

\paragraph{Bimanual Actions Dataset \cite{dreher2020learning} }

contains activities of subjects using both hands to interact with
different objects at the same time. Unlike WBHM with 3D geometrical
features, all features here are in 2D coordinates making the dataset
more challenging for motion prediction. Furthermore, the subjects
in this dataset always use two arms to interact concurrently with
different objects, requiring a new capability of modeling the collaboration
between the arms. PTD naturally support this use case by considering
each arm to be one human entity, each with features of 2D locations
of the arm key points and hand bounding box.

\subsubsection{Compared methods and baselines}

We compare PTD with the \emph{HOI-M forecasting SOTAs}: CRNN-OPM,
CRNN-OPM-LI \cite{corona2020context} and the\emph{ pose forecasting
SOTAs}: STS-GCN \cite{sofianos2021space}, Motion-Mixer \cite{bouazizi2022motionmixer}.
Motion-Mixer and STS-GCN are retrained using the provided codes\footnote{https://github.com/FraLuca/STSGCN

https://github.com/MotionMLP/MotionMixer}. The others are re-implemented with the settings provided in the
original papers. We also use several common baseline methods of Zero
Velocity, Running avg. 2, GRU \cite{martinez2017human}. 

\subsubsection{Evaluation metric}

The prediction errors at each time step are calculated as the Euclidean
distances with the ground-truth for both human poses and object bounding
boxes (mm for WBHM, pixel for Bimanual Action Dataset). The error
for a sequence is then computed as the average errors across $L$
prediction frames. Prediction performances are reported as the mean
and std of the average errors of 5 independent runs for humans and
objects entities. 

\subsection{Motion forecasting on WBHM Dataset \label{subsec:exp_wbhm}}

For WBHM dataset, we follow the common evaluation protocol \cite{corona2020context}:
to observe for 1 second ($T=10$) and predict the next 2 seconds ($L=20$). 

\paragraph{Quantitative evaluation.}

The average errors reported in \ref{tab:quantitative_wbhm} clearly
indicates that PTD consistently outperforms the SoTAs in both human
pose and object box forecasting. Supp, Sec.3 further reports detailed
errors at each time step.

\begin{table}
\begin{centering}
\begin{tabular}{lcc}
\toprule 
\multirow{1}{*}{} & {\footnotesize{}Human} & {\footnotesize{}Obj}\tabularnewline
\midrule
{\footnotesize{}Zero-Velocity} & {\footnotesize{}176.45} & {\footnotesize{}128.6}\tabularnewline
{\footnotesize{}Running avg. 2} & {\footnotesize{}183.95} & {\footnotesize{}133.3}\tabularnewline
{\footnotesize{}GRU \cite{martinez2017human}} & {\footnotesize{}102.86 $\pm$ 1.4} & {\footnotesize{}119.64 $\pm$ 1.6}\tabularnewline
{\footnotesize{}STS-GCN \cite{sofianos2021space}} & {\footnotesize{}101.36 $\pm$ 2.4} & {\footnotesize{}-}\tabularnewline
{\footnotesize{}Motion-Mixer \cite{bouazizi2022motionmixer}} & {\footnotesize{}87.35 $\pm$ 1.2} & {\footnotesize{}-}\tabularnewline
{\footnotesize{}CRNN-OPM \cite{corona2020context}} & {\footnotesize{}99.01 $\pm$ 1.1} & {\footnotesize{}87.52 $\pm$ 1.6}\tabularnewline
{\footnotesize{}CRNN-OPM-LI \cite{corona2020context}} & {\footnotesize{}95.96 $\pm$ 1.7} & {\footnotesize{}74.27 $\pm$ 1.3}\tabularnewline
\midrule 
\textbf{\footnotesize{}PTD (Ours)} & \textbf{\footnotesize{}85.53}{\footnotesize{} $\pm$}\textbf{\footnotesize{}
0.9} & \textbf{\footnotesize{}70.69}{\footnotesize{} $\pm$}\textbf{\footnotesize{}
0.5}\tabularnewline
\bottomrule
\end{tabular}
\par\end{centering}
\caption{The average errors (mm) on WBHM after 5 independent runs. PTD outperforms
other SOTAs in both human and object prediction. The errors at each
time step are given in Supp, Sec. 3.\label{tab:quantitative_wbhm}}
\end{table}


\paragraph{Visual analysis.}

% Figure environment removed

% Figure environment removed

We verify the benefit of our model by visualizing the internal output
predictions and graph structures of PTD compared to CRNN-OPM-LI \cite{corona2020context}.
The upper row of \ref{fig:qualitative_hoi} shows that PTD could learn
to switch the mechanism from Persistent to Transient when the situation
changes from interaction-free (a) to interaction-involved (b). The
Transient graph in \emph{(b)} reflects the interactions correctly
thanks to it being trained on targeted samples.

In contrast, CRNN-OPM-LI \cite{corona2020context} (lower row) holds
on to a single global mechanism and does not evolve adequately for
the swift change in the true relational topology, resulting in inaccurate
and unrealistic interactions.

The operation of the Transient Switch is visualized in \ref{fig:switch_hoi_wbhm}.
When the interaction is about to occur (i), the switch score $\hat{p}_{r}^{t}$
(\ref{eq:switch_score}) increases to reflect the prospective of the
interaction. When the score passes the threshold, it switches on the
Transient channel a few time-steps before the interaction can be observed,
precisely as designed (\ref{eq:groundtruth_switch_label}). After
maintaining high values during interaction (ii), the score falls when
it anticipates the end of the interaction, deactivating the transient
channel (iii).

\paragraph{Generalization analysis.}

% Figure environment removed

With more accurate modeling, PTD promises a greater generalization
in predicting the patterns unseen in training. To evaluate such potential,
we use a generalization test \cite{hupkes2020compositionality} to
set up a series of experiments where PTD and other models compete
on the test sequences of lengths different from the ones used in training:
(1) observation length $T$ varies, (2) prediction length $L$ varies,
and (3) both observation and prediction lengths varies. 

The results are measured as the total average errors (mm) of humans
and objects and are visualized in \ref{fig:generalization_analysis}.
We exclude STS-GCN and MotionMixer due to their dependence on the
sequence length. 

\textbf{1. Varying observation length $T$} (\ref{fig:vary_obs}):
Interestingly, when observing longer sequences in testing ($T>10$),
the baseline models failed to generalize and perform worse. In contrast,
with mechanism switching, PTD is flexible enough to take advantage
of the longer observed data to gain performance without re-training.
Also, with shorter observed sequences ($T<10$), PTD is more resilient
than other models, showing its capacity of modeling the generic pattern
and avoid overfitting. 

\textbf{2. Predicting longer sequences. }With same observation $(T=10)$
and increased prediction length $L$ of the testing data (\ref{fig:vary_pred}),
PTD keeps the superior performance by extrapolating well to farther
future predictions.

\textbf{3. Increasing both lengths. }Finally, when both length changes
(\ref{fig:vary_both}), the result is consistent with case 1. and
2. where PTD shows its superior ability to take advantage of more
data and generalize well to longer predictions.

\paragraph{Ablation studies.\label{subsec:HOI-Ablation}}

\begin{table}
\centering{}%
\begin{tabular*}{1\columnwidth}{@{\extracolsep{\fill}}l>{\raggedright}m{0.4\columnwidth}>{\centering}m{0.15\columnwidth}>{\centering}m{0.15\columnwidth}}
\toprule 
\multirow{1}{*}{} & \multirow{1}{0.4\columnwidth}{\centering{}{\footnotesize{}Ablation}} & {\footnotesize{}Human} & {\footnotesize{}Object}\tabularnewline
\midrule
{\footnotesize{}1} & {\footnotesize{}w/o Transient channel} & {\footnotesize{}89.49} & {\footnotesize{}74.91}\tabularnewline
{\footnotesize{}2} & {\footnotesize{}w/o Persistent channel} & {\footnotesize{}91.41} & {\footnotesize{}78.67}\tabularnewline
{\footnotesize{}3} & {\footnotesize{}w/o egocentric property} & {\footnotesize{}87.90} & {\footnotesize{}72.30}\tabularnewline
{\footnotesize{}4} & {\footnotesize{}w/o heuristic switch} & {\footnotesize{}86.44} & {\footnotesize{}74.85}\tabularnewline
{\footnotesize{}5} & {\footnotesize{}w/o $\gamma$} & {\footnotesize{}86.17} & {\footnotesize{}70.71}\tabularnewline
{\footnotesize{}6} & {\footnotesize{}w/ only $\gamma$} & {\footnotesize{}87.11} & {\footnotesize{}76.95}\tabularnewline
{\footnotesize{}7} & {\footnotesize{}w/o switching transient} & {\footnotesize{}86.00} & {\footnotesize{}71.40}\tabularnewline
{\footnotesize{}8} & {\footnotesize{}w/o switch loss} & {\footnotesize{}89.59} & {\footnotesize{}73.17}\tabularnewline
{\footnotesize{}9} & {\footnotesize{}w/o multistage training} & {\footnotesize{}90.21} & {\footnotesize{}72.22}\tabularnewline
\midrule 
 & \textbf{\footnotesize{}Full PTD model} & \textbf{\footnotesize{}85.53} & \textbf{\footnotesize{}70.69}\tabularnewline
\bottomrule
\end{tabular*}\caption{Ablation studies on WBHM (avg. errors in mm.) \label{tab:ablation-results}}
\end{table}

We examine the roles of PTD's core components by making ablations
from the model and report the performances in \ref{tab:ablation-results}.
They include:

1.\textbf{ Without Transient channel}: Being alone, Persistent Channel
performs significantly worse than when with its Transient partner
in the duality.

2. \textbf{Without Persistent channel: }Transient Channel also struggles
and gives worse performance operating alone. 

3. \textbf{Without Egocentric property}, including egocentric structure
(\ref{eq:ego_graph_structure}) and representation (\ref{eq:egocentric_leaf}),
Transient channels operate on a fully-connected graph with global
features. This ablated model suffers a significant drop in performance,
showing the role of egocentric design.

4.\textbf{ Heuristic switch:} This experiment probe the need for the
\emph{Transient Switch} (\ref{subsec:switch}) by replacing it with
a heuristic rule $\hat{p}_{r}^{t}=d_{r,min}^{t}\leq\beta$. This heuristic
switch can still provide benefit compared to single channels (row
1,2). However, being too stiff, it cannot represent the switching
patterns and fails to reach the duality's full potential. 

5. \textbf{Switch without spatial discount factor: }Without $\gamma_{r}^{t}$
(\ref{eq:switch_score}), the \emph{Switch} could not respond fast
enough to context changes, resulting in slightly weaker performance.

6. \textbf{Switch with only discount factor: }This quick-change factor
could not do the job by itself as it is susceptible to noisy patterns,
performing even worse than row 5. 

7. \textbf{Without switching transient:} The transient channels is
always on and may capture irrelevant patterns outside the HOI-context,
leading to a drop in the performance.

8. \textbf{Without switch loss: }We study the role of the switch's
direct supervision (\ref{subsec:losses}) by setting $\lambda_{switch}$
to 0, taking $\mathcal{L}_{switch}$ out of \ref{eq:losses}. This
unsupervised switch only relies on weak gradient flowing back from
prediction loss and delivers significantly weakened performance. 

9. \textbf{Without multistage training: }Without such a training procedure
(\ref{subsec:losses}), the model suffers from accumulating losses
during early epochs and capture less accurate motion pattern, resulting
in a decrease in the performance.

\subsection{Motion forecasting on Bimanual Action Dataset}

While WBHM is rich in patterns and is well-suited for large scale
analysis, the Bimanual Action is more realistic, as its 2D RGB data
are more available. Due to the increased ambiguity of the 2D data,
we use longer observed (2s/20 steps) and shorter predict lengths (1s/10
steps).

\textbf{Quantitative evaluation:} The average errors measured in pixel
are reported in \ref{tab:quantitative_bimanual}. Consistent with
the results in WBHM dataset, PTD outperforms other SOTAs in both human
and object motion forecasting. The errors at each time steps are also
detailed in Supp, Sec. 3. \textbf{Visual analysis} of PTD's operation
in this dataset (similar to that of WBHM in \ref{fig:qualitative_hoi}
and \ref{fig:switch_hoi_wbhm}) is provided in Supp, Sec 4. 

\begin{table}
\begin{centering}
\begin{tabular}{lccc}
\toprule 
\multirow{1}{*}{} & {\footnotesize{}Arm Keypoints} & {\footnotesize{}Hand} & {\footnotesize{}BoxObj}\tabularnewline
\midrule 
{\footnotesize{}Zero-Velocity} & {\footnotesize{}12.11} & {\footnotesize{}21.52} & {\footnotesize{}7.02}\tabularnewline
{\footnotesize{}Running avg. 2} & {\footnotesize{}12.80} & {\footnotesize{}22.19} & {\footnotesize{}7.30}\tabularnewline
{\footnotesize{}GRU \cite{martinez2017human}} & {\footnotesize{}12.37 $\pm$ 0.4} & {\footnotesize{}20.80 $\pm$ 0.9} & {\footnotesize{}7.04 $\pm$ 0.0}\tabularnewline
{\footnotesize{}STS-GCN \cite{sofianos2021space}} & {\footnotesize{}11.85 $\pm$ 0.5} & {\footnotesize{}-} & {\footnotesize{}-}\tabularnewline
{\footnotesize{}Motion-Mixer \cite{bouazizi2022motionmixer}} & {\footnotesize{}11.68 $\pm$ 0.2} & {\footnotesize{}-} & {\footnotesize{}-}\tabularnewline
{\footnotesize{}CRNN-OPM \cite{corona2020context}} & {\footnotesize{}12.81 $\pm$ 0.1} & {\footnotesize{}21.66 $\pm$ 0.2} & {\footnotesize{}7.16 $\pm$ 0.1}\tabularnewline
{\footnotesize{}CRNN-OPM-LI \cite{corona2020context}} & {\footnotesize{}11.97 $\pm$ 0.3} & {\footnotesize{}20.13 $\pm$ 0.2} & {\footnotesize{}7.05 $\pm$ 0.1}\tabularnewline
\midrule 
\textbf{\footnotesize{}PTD (Ours)} & \textbf{\footnotesize{}10.94}{\footnotesize{} $\pm$ }\textbf{\footnotesize{}0.2} & \textbf{\footnotesize{}18.80}{\footnotesize{} $\pm$ }\textbf{\footnotesize{}0.1} & \textbf{\footnotesize{}6.81}{\footnotesize{} $\pm$ }\textbf{\footnotesize{}0.0}\tabularnewline
\bottomrule
\end{tabular}
\par\end{centering}
\caption{The avg. errors (pixel) on Bimanual Action dataset from five different
runs.\label{tab:quantitative_bimanual}}
\end{table}


\subsection{Empirical Complexity Analysis}

We did an empirical analysis on the model size and observed that \emph{PTD
has a comparable number of parameters to other methods}. Detailed
numeric analysis is shown in Supp, Sec 2. This fact confirms that
the good performance of PTD is caused by the new multi-mechanism scheme
without the negative trade-off in computation cost. 
