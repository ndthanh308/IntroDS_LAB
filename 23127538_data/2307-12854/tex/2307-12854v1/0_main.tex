\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{soul}
\usepackage[table,x11names]{xcolor}
\usepackage{subcaption}

\newcommand{\reuben}[1]{\emph{\textcolor{blue}{reuben: #1}}}
\newcommand*{\modelname}{Multiscale Video Pretraining\xspace}
\newcommand*{\modelabb}{MVP\xspace}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{7057} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Multiscale Video Pretraining for Long-Term Activity Forecasting}

\author{Reuben Tan$^{1}$ \ \ \ \ Matthias De Lange$^{2}$ \ \ \ \ Michael Iuzzolino $^{3}$ \ \ \ \ Bryan A. Plummer$^{1}$ \ \ \ \  \\  Kate Saenko$^{1,3}$ \ \ \ \
Karl Ridgeway$^{3}$ \ \ \ \ Lorenzo Torresani$^{3}$ \\
$^{1}$Boston University, $^{2}$KU Leuven, $^{3}$Meta\\
{\tt \small \{rxtan,bplum, saenko\}@bu.edu}, {\tt \small \{matthias.delange\}@kuleuven.be} \\ {\tt \small \{mliuzzolino, karl.ridgeway, torresani\}@meta.com} \\
} 

%\author{Reuben Tan$^{1}$ \ \ \ \ Matthias De Lange$^{2}$ \ \ \ \ 
%Michael Iuzzolino $^{3}$ \ \ \ \
%Bryan A. Plummer$^{1}$ \ \ \ \ Kate Saenko$^{1,3}$  \\
%  Karl Ridgeway$^{3}$ \ \ \ \
%  Lorenzo Torresani$^{3}$  \ \
%$^{1}$Boston University, $^{2}$KU Leuven, $^{3}$Meta \\
%{\tt \small \{rxtan, bplum, saenko\}@bu.edu}, {\tt \small \%{matthias.delange\}@esat.kuleuven.be}, {\tt \small \{mliuzzolino, karl.ridgeway, torresani\}@meta.com} \\
%} 
\maketitle

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{abstract}
       Long-term activity forecasting is an especially challenging research problem because it requires understanding the temporal relationships between observed actions, as well as the variability and complexity of human activities. Despite relying on strong supervision via expensive human annotations, state-of-the-art forecasting approaches often generalize poorly to unseen data. To alleviate this issue, we propose \modelname (\modelabb), a novel self-supervised pretraining approach that learns robust representations for forecasting by learning to predict contextualized representations of future video clips over multiple timescales. MVP is based on our observation that actions in videos have a multiscale nature, where atomic actions typically occur at a short timescale and more complex actions may span longer timescales. We compare MVP to state-of-the-art self-supervised video learning approaches on downstream long-term forecasting tasks including long-term action anticipation and video summary prediction. Our comprehensive experiments across the Ego4D and Epic-Kitchens-55/100 datasets demonstrate that MVP outperforms state-of-the-art methods by significant margins. Notably, MVP obtains a relative performance gain of over 20\% accuracy in video summary forecasting over existing methods. %We will release our code.
\end{abstract}

\input{1_introduction.tex}
\input{2_related.tex}
\input{3_approach.tex}
\input{4_experiments.tex}
\input{5_conclusion.tex}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\clearpage
\appendix
\input{6_appendix.tex}

\end{document}
