@inproceedings{qian2021spatiotemporal,
  title={Spatiotemporal contrastive video representation learning},
  author={Qian, Rui and Meng, Tianjian and Gong, Boqing and Yang, Ming-Hsuan and Wang, Huisheng and Belongie, Serge and Cui, Yin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6964--6974},
  year={2021}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{han2019video,
  title={Video representation learning by dense predictive coding},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
  }
  
  @inproceedings{yuan2022contextualized,
  title={Contextualized Spatio-Temporal Contrastive Learning with Self-Supervision},
  author={Yuan, Liangzhe and Qian, Rui and Cui, Yin and Gong, Boqing and Schroff, Florian and Yang, Ming-Hsuan and Adam, Hartwig and Liu, Ting},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13977--13986},
  year={2022}
}

@inproceedings{wang2022long,
  title={Long-short temporal contrastive learning of video transformers},
  author={Wang, Jue and Bertasius, Gedas and Tran, Du and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14010--14020},
  year={2022}
}

@inproceedings{feichtenhofer2021large,
  title={A large-scale study on unsupervised spatiotemporal representation learning},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Xiong, Bo and Girshick, Ross and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3299--3309},
  year={2021}
}

@inproceedings{girdhar2021anticipative,
  title={Anticipative video transformer},
  author={Girdhar, Rohit and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={13505--13515},
  year={2021}
}

@article{damen2020rescaling,
  title={Rescaling egocentric vision},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={arXiv preprint arXiv:2006.13256},
  year={2020}
}

@inproceedings{zatsarynna2021multi,
  title={Multi-modal temporal convolutional network for anticipating actions in egocentric videos},
  author={Zatsarynna, Olga and Abu Farha, Yazan and Gall, Juergen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2249--2258},
  year={2021}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@inproceedings{gong2022future,
  title={Future transformer for long-term action anticipation},
  author={Gong, Dayoung and Lee, Joonseok and Kim, Manjin and Ha, Seong Jong and Cho, Minsu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3052--3061},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{ryoo2011human,
  title={Human activity prediction: Early recognition of ongoing activities from streaming videos},
  author={Ryoo, Michael S},
  booktitle={2011 international conference on computer vision},
  pages={1036--1043},
  year={2011},
  organization={IEEE}
}

@article{hoai2014max,
  title={Max-margin early event detectors},
  author={Hoai, Minh and De la Torre, Fernando},
  journal={International Journal of Computer Vision},
  volume={107},
  pages={191--202},
  year={2014},
  publisher={Springer}
}

@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6202--6211},
  year={2019}
}

@inproceedings{han2020memory,
  title={Memory-augmented dense predictive coding for video representation learning},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III 16},
  pages={312--329},
  year={2020},
  organization={Springer}
}

@article{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}

@article{carreira2018short,
  title={A short note about kinetics-600},
  author={Carreira, Joao and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1808.01340},
  year={2018}
}

@article{carreira2019short,
  title={A short note on the kinetics-700 human action dataset},
  author={Carreira, Joao and Noland, Eric and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1907.06987},
  year={2019}
}

@inproceedings{kuehne2011hmdb,
  title={HMDB: a large video database for human motion recognition},
  author={Kuehne, Hildegard and Jhuang, Hueihan and Garrote, Est{\'\i}baliz and Poggio, Tomaso and Serre, Thomas},
  booktitle={2011 International conference on computer vision},
  pages={2556--2563},
  year={2011},
  organization={IEEE}
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@inproceedings{fan2021multiscale,
  title={Multiscale vision transformers},
  author={Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6824--6835},
  year={2021}
}

@inproceedings{shao2020finegym,
  title={Finegym: A hierarchical video dataset for fine-grained action understanding},
  author={Shao, Dian and Zhao, Yue and Dai, Bo and Lin, Dahua},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2616--2625},
  year={2020}
}

@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{chen2021exploring,
  title={Exploring simple siamese representation learning},
  author={Chen, Xinlei and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={15750--15758},
  year={2021}
}

@inproceedings{bertasius2021space,
  title={Is space-time attention all you need for video understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={ICML},
  volume={2},
  number={3},
  pages={4},
  year={2021}
}

@inproceedings{zhou2018towards,
  title={Towards automatic learning of procedures from web instructional videos},
  author={Zhou, Luowei and Xu, Chenliang and Corso, Jason},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@INPROCEEDINGS{Damen2018EPICKITCHENS,
   title={Scaling Egocentric Vision: The EPIC-KITCHENS Dataset},
   author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria  and Fidler, Sanja and 
           Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan 
           and Perrett, Toby and Price, Will and Wray, Michael},
   booktitle={European Conference on Computer Vision (ECCV)},
   year={2018}
} 

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9879--9889},
  year={2020}
}

@article{akbari2021vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24206--24221},
  year={2021}
}

@inproceedings{vondrick2016anticipating,
  title={Anticipating visual representations from unlabeled video},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={98--106},
  year={2016}
}

@article{wu2020learning,
  title={Learning to anticipate egocentric actions by imagination},
  author={Wu, Yu and Zhu, Linchao and Wang, Xiaohan and Yang, Yi and Wu, Fei},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={1143--1152},
  year={2020},
  publisher={IEEE}
}

@article{furnari2020rolling,
  title={Rolling-unrolling lstms for action anticipation from first-person video},
  author={Furnari, Antonino and Farinella, Giovanni Maria},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={11},
  pages={4021--4036},
  year={2020},
  publisher={IEEE}
}

@inproceedings{sener2020temporal,
  title={Temporal aggregate representations for long-range video understanding},
  author={Sener, Fadime and Singhania, Dipika and Yao, Angela},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XVI 16},
  pages={154--171},
  year={2020},
  organization={Springer}
}

@article{jabri2020space,
  title={Space-time correspondence as a contrastive random walk},
  author={Jabri, Allan and Owens, Andrew and Efros, Alexei},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={19545--19560},
  year={2020}
}

@article{tan2021look,
  title={Look at what iâ€™m doing: Self-supervised spatial grounding of narrations in instructional videos},
  author={Tan, Reuben and Plummer, Bryan and Saenko, Kate and Jin, Hailin and Russell, Bryan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14476--14487},
  year={2021}
}

@article{fu2021violet,
  title={Violet: End-to-end video-language transformers with masked visual-token modeling},
  author={Fu, Tsu-Jui and Li, Linjie and Gan, Zhe and Lin, Kevin and Wang, William Yang and Wang, Lijuan and Liu, Zicheng},
  journal={arXiv preprint arXiv:2111.12681},
  year={2021}
}

@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1728--1738},
  year={2021}
}

@inproceedings{recasens2021broaden,
  title={Broaden your views for self-supervised video learning},
  author={Recasens, Adria and Luc, Pauline and Alayrac, Jean-Baptiste and Wang, Luyu and Strub, Florian and Tallec, Corentin and Malinowski, Mateusz and P{\u{a}}tr{\u{a}}ucean, Viorica and Altch{\'e}, Florent and Valko, Michal and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1255--1265},
  year={2021}
}

@article{farha2020long,
  title={Long-term anticipation of activities with cycle consistency},
  author={Farha, Yazan Abu and Ke, Qiuhong and Schiele, Bernt and Gall, Juergen},
  journal={arXiv preprint arXiv:2009.01142},
  year={2020}
}