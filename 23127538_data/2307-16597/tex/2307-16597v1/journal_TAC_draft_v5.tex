% !TeX spellcheck = en_US

%\documentcl=ass[lettersize,conference]{IEEEtran}
\documentclass[journal,12p]{IEEEtran}

%\usepackage{times}
%\usepackage{appendix}
%% numbers option provides compact numerical references in the text. 
%\usepackage[numbers]{natbib}
%\usepackage{multicol}
%\usepackage[bookmarks=true]{hyperref}

%\documentclass[10pt,journal,onecolumn]{IEEEtran}
%\documentclass[10pt,journal]{IEEEtran}
% Some/most Computer Society conferences require the compsoc mode option,
% but others may want the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference,compsoc]{../sty/IEEEtran}

\makeatletter
\def\endthebibliography{%
	\def\@noitemerr{\@latex@warning{Empty `thebibliography' environment}}%
	\endlist
}
\makeatother


% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
% IEEE Computer Society needs nocompress option
% requires cite.sty v4.0 or later (November 2003)
\usepackage[nocompress]{cite}
\else
% normal IEEE
\usepackage{cite}
\fi
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.
%
% Note that some packages require special options to format as the Computer
% Society requires. In particular, Computer Society  papers do not use
% compressed citation ranges as is done in typical IEEE papers
% (e.g., [1]-[4]). Instead, they list every citation separately in order
% (e.g., [1], [2], [3], [4]). To get the latter we need to load the cite
% package with the nocompress option which is supported by cite.sty v4.0
% and later.





% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
\usepackage[pdftex]{graphicx}
% declare the path(s) where your graphic files are
% \graphicspath{{../pdf/}{../jpeg/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
% \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
% or other class option (dvipsone, dvipdf, if not using dvips). graphicx
% will default to the driver specified in the system graphics.cfg if no
% driver is specified.
% \usepackage[dvips]{graphicx}
% declare the path(s) where your graphic files are
% \graphicspath{{../eps/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
% \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at:
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage{cuted}
\usepackage{paralist}
\usepackage{booktabs} 
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{graphicx,hyperref}
\usepackage{subfigure}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{color}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{algpseudocode}
\newtheorem{problem}{Problem}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\renewcommand{\d}[1]{\ensuremath{\operatorname{d}\!{#1}}}
\newcommand{\ad}{\mathrm{ad}}
\newcommand{\adm}{\mathrm{adm}}
\newcommand{\Ad}{\mathrm{Ad}}
\newcommand{\bigzero}{\mbox{\normalfont\Large\bfseries 0}}
\newcommand{\rvline}{\hspace*{-\arraycolsep}\vline\hspace*{-\arraycolsep}}


\newcommand{\Junfeng}[1]{{\color{blue}{\bf\sf [Junfeng: #1]}}}

\newcommand{\expm}{{\mathrm{exp_m}}}
\newcommand{\dexp}{{\mathrm{dexp}}}
\newcommand{\dexpm}{{\mathrm{dexp_m}}}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a sans serif font rather
% than the serif font used in traditional IEEE formatting and thus the need
% to invoke different subfig.sty package options depending on whether
% compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "% Figure environment removed
\setcounter{equation}{23} 
  \begin{proposition}\label{proposition:Lie_log_evolution_SE3}
			Let $\omega_t^\wedge$ be the 
			$\mathfrak{so}(3)$ part of $\xi_t$. Then, in~\eqref{eqn:therem_3}, ${C}_{t,k}$ and the right Jacobian $ \dexpm{(-\xi_{t})}$ are given by
			\begin{equation}\label{eqn:se_n3_equation_1}
				\begin{split}
			&\dexpm(-\xi_t)=I+\sum_{j=1}^{4}\beta_{t,j}\adm^{j}_{\xi_t}\\
					&\beta_{t,1}=\frac{4 \cos\theta_t-4+\theta_t \sin \theta_t}{2 \theta_t^2}\quad\beta_{t,2}=\frac{4 \theta_t-5 \sin \theta_t+\theta_t \cos \theta_t}{2 \theta_t^3}\\
					&\beta_{t,3} = \frac{\theta_t \sin \theta_t+2 \cos \theta_t-2}{2 \theta_t^4}\quad\beta_{t,4}=\frac{2 \theta _t-3 \sin \theta_t+\theta_t \cos \theta_t}{2 \theta_t^5}
				\end{split}
			\end{equation}
		where $\theta_t\triangleq\| \omega_t \|$ and $C_{t,k}$ is evaluated in~\eqref{eqn:ck}.
		\end{proposition}
		\begin{proof}
			For any $\xi^\wedge\in \mathfrak{se}_N(3)$, we have the identity $\ad^5_{\xi^\wedge}+2\theta^2\ad^3_{\xi^\wedge}+\theta^4\ad_{\xi^\wedge}\equiv 0 $, by (7.62) of~\cite{Hall:371445}. Using this identity, we express $\dexpm(-\xi_t)$ as a power sum of $\adm_{\xi_t}$ up to the fourth order term, given by ~\eqref{eqn:se_n3_equation_1}.
			The result of $C_{t,k}$ is obtained by differentiating the right hand side of \eqref{eqn:se_n3_equation_1} using the product rule. By the chain rule,  we obtain $	\sum_{i=1}^{d} \left(\partial_{\xi_{i}}(\adm_{\xi})^j\right)$ and $\partial_{\xi_{j}}\theta$ to evaluate,  where $	\sum_{i=1}^{d} \left(\partial_{\xi_{i}}(\adm_{\xi})^j\right)$ is evaluated in Lemma~\ref{lemma:support_lemma_2}. Next we briefly provide the evaluation of $\partial_{\xi_{i}}\theta$ by using the fact $\theta^2=\omega^\top\omega$. Differentiating both sides with respect to $\xi_{i}$ and re-arranging, we get that $\partial_{\xi_{i}}\theta=\frac{\omega_i}{\theta}$, from which the values of  $C_{t,k}$'s can be solved.
		\end{proof}
		%In this part,  we get back to some common group. We will present $C_i$ and $\gamma_i$ can be computed  in the explicit form of this group.
		%
		%Consider the state  $X\in SO(3)$, where $SO(3)\subset\mathbb{R}^{3\times3}$ is the set of all orthogonal matrix with determinant $+1$.
		%\begin{lemma}[$SO(3)$]
		%	Let $X\in SO(3)$ be in the Lie group and $x$ be the vector corresponding with the Lie algebra. The matrix representation of left Jacobian $\dexpm_{x}$ defined as $\dexpm_{x}\triangleq\sum_{i=0}^{\infty}\frac{1}{i+1!}\ad^{i}_{x}$  for the state $X\in SO(3)$ is that 
		%	\begin{equation*}
			%		content..,
			%	\end{equation*}
		%	and the matrix representation of $C_x\triangleq\partial_{x}\dexpm_{x}$ is defined as 
		%	\begin{equation*}
			%		content...
			%	\end{equation*} 
		%\end{lemma}
		%The special orthogonal matrix generally can be the representation of the rotation group of the rigid body. Hence, in this way, the explicit form of $SO(3)$ can be used into the analysis of the evolution of distribution for the rotation motion.
		% 
		% Now consider another the state $X\in SE_n(3)$,  where $SE_n(3)$ is composed with one element belongs to $SO(3)$ and $n$ elements are in $\mathbb{R}^3$
		% \begin{lemma}
			% 	Now let $X\in SE_n(3)$ be in the Lie group and its Lie logarithm be $x$. The matrix representation of left Jacobian $\dexpm_{x}$ defined as $\dexpm_{x}\triangleq\sum_{i=0}^{\infty}\frac{1}{i+1!}\ad^{i}_{x}$  for the state $X\in SE_n(3)$ is that 
			% \begin{equation*}
				% 	content..,
				% \end{equation*}
			% and the matrix representation of $C_x\triangleq\partial_{x}\dexpm_{\ad_{{x}}}$ is defined as 
			% \begin{equation*}
				% 	content...
				% \end{equation*} 
			% \end{lemma}
		% Special Euclidean group could be the representation of the IMU state and the SLAM~(simutaneously localization and mapping) state currently. 
		%	\subsection{Example: Integral from Continuous-time Dynamics }
		% Dynamics are about the evolution of some quantities over a period of time. Discrete-time dynamics seem to be a snapshot of the system at a sequence of times and can be used in the industrial numerical computation. In some existing literature~\cite{bibid}, they get accustomed to deal with the following discrete-time dynamics:
		%	\begin{equation}
			%	{X}_{{k+1}}=g_{u_{{k+1}}}({X}_{{k}})
			%\end{equation}
			%with $g_{u_{{k+1}}}(\cdot):G\rightarrow G$ being the mapping such that the next state can also lie on the Lie group and $u_{{k+1}}$ is the time-variant input increment including the control input  ${v}_b,{v}_g\in \mathcal{U}$ mentioned in~\eqref{eqn:affine group system specific}. Considering $\mathfrak{g}$-dimensional noise $w_k$ into the discrete-time dynamics,  they use the exponential mapping and the multiplication operation to add the noise.  We write the dynamics in the following:
			%\begin{equation}\label{eqn:discrete_form_noisy_dynamics}
			%	\begin{split}
				%		{{X}}_{{k+1}}&=\exp{\left(w_{k} \right) }g_{{u}_{{k+1}}}({{{X}}}_{k})\quad\text{left multiplication}\\
				%		{{{X}}}_{{k+1}}&=g_{u_{{k+1}}}({X}_{{k}})\exp{\left(w_{{k}} \right) }\quad\text{right multiplication}
				%	\end{split}
			%\end{equation} 
			%
			%	 The dynamical equation~\eqref{eqn:discrete_form_noisy_dynamics} evolving in the Lie group has a multiplication form in a sense that the discrete-time noise is acting at the identity. It is natural to find out the mapping from the noise in the discrete-time form from the continuous-time form. Now we will give our analysis.
			%
			%  	\begin{theorem}[Noise integral in discrete-time form]\label{pro:Noise increment in discrete-time form}
				%  	Consider $\hat{X}$ satisfy the discrete system~\eqref{eqn:Discrete_dynamics}, $X$ satisfy right multiplication of~\eqref{eqn:discrete_form_noisy_dynamics}.  Let  $\tilde{{\Upsilon}}_k:=\exp(w_k)$ denote the exponential mapping of $w_k$. $\tilde{{\Upsilon}}_{k}$ at $t_k$ of equation ~\eqref{eqn:discrete_form_noisy_dynamics} are the solution of the following differential equations:
				%  	\begin{equation}
					%  		\frac{\d{}}{\d{t}}\tilde{{\Upsilon}}_t=\tilde{{\Upsilon}}_t{v}_b-{v}_b\tilde{{\Upsilon}}_{t}+f_0(\tilde{{\Upsilon}}_t)+\tilde{{\Upsilon}}_tw^\wedge
					%  	\end{equation}
				%  	with its initial condition $\tilde{{\Upsilon}}_{0}={I}$. Its Lie logarithm $w_k$ is the solution at $t_k$ of the following dynamics:
				%  	\begin{equation}\label{eqn:noise_linear}
					%  		\d{w} = {A}\d{t}+\sum_{i=1}^{3n+3}{B}_i\d{W}_i
					%  	\end{equation}
				%  	where 
				%  	\begin{align*}
					%  		{A}&=\left( A_t-\ad_{\mathcal{G}_1({v}_b)}\right) w-\frac{1}{2}\sum_{i=1}^{3n+3}{J}(-\ad_{w^\wedge})^{-1}{C}_i\\
					%  		{C}_i&=\sum_{p=0}^{\infty}\sum_{q=0}^{\infty}\frac{1}{(p+q+2)}\frac{(-1)^p}{p!(q+1)!}(\ad_{w^\wedge})^p(\ad_{{B}_i}(\ad_{w^\wedge}^q({B}_i)))\\
					%  		{B}_i&={J}(-\ad_{w^\wedge})^{-1}a_i
					%  	\end{align*}
				%  	with initial condition $w_{0}=0$.
				%  \end{theorem}
			%  \begin{proof}
				%  	See the Appendix.
				%  \end{proof}
			%In the above analysis,  we propose a theorem result on the SDE, which has an explicit but complex form. Although we could do the approximation to solve the evolution of distribution, such as neglecting higher than the first order term, rigorous theoretical results on this class of methods for filtering are complicated and have yet to be obtained. Instead continuing analysis on the theoretical results, we will use numerical analysis or techniques for SDE to estimate the expectation and second moment with specific convergence rates. Furthermore, the numerical method is amenable to parallelization strategies, promising great potential for its use on the generation of supercomputers. 
			
			
			%\section{Simulation}\label{sec:simulation}
			%			We use numerical simulations to compare the evaluation with propagation step of the invariant extended Kalman filter~\cite{Barrau}, which is considered as a first-order approximation with respect to noise.   We customize Theorem~\ref{thm:SDE_of_Lie_logarithm} on $SE_2(3)$ group. We will choose the Kullback--Leibler~(KL) divergence to compare propagated error distribution with the prior error distribution, describing how the probability distribution evolves, as the evaluation.
			
			%			This section presents the numerical simulation setup. The vehicle drives at an angular velocity of $[0.1,0.1,0.1]^\top$ and acceleration of $[0.2,0.2,0.2]^\top$ with high-frequency inertial measurement odometry, and its state, including orientation, position, and velocity, can be represented as $SE_2(3)$. The initial covariance is $\text{diag}\left\lbrace 0.01I_3, 0.1I_3,0.1I_3 \right\rbrace $. We perform a numerical simulation under different initial conditions. The results are presented in the Fig.~\ref{fig:simulation_of_the_results}.
			
			%% Figure environment removed
			
			%The simulation results show that under varying initial conditions, the KL divergence of the InEKF increases as the scale of the initial conditions grows. On the other hand, our numerical method results remain relatively constant, indicating that the simple first-order approximation with respect to the initial condition of the invariant error disregards the impact of the initial errors. Hence, our solution is relatively robust to the effects of the initial value.
			
			%\subsection{Evolution of the First Moment and Second Moment}
			%As we present in the above section, we obtain the It\^o stochastic differential equation with respect to $\xi_t$
			%\begin{equation}\label{eqn:sde_error_propagation}
			%	\d{\xi_t}={A}_t\xi_t\d{t}+{B}_t\d{W}.
			%\end{equation}
			% The error state with the random noise can be characterized by the following density function
			%$
			%	{p}(\xi_t)
			%$ and the transition probability density function can be denoted as $p(\xi_t|\xi_\gamma)$. 
			%\begin{lemma}[Extentions of Kolmogorov's forward equation]
			%Let $\xi_\gamma,\xi_t\in\mathbb{R}^d$ denote the vectors with the dynamics~\eqref{eqn:sde_error_propagation}. Suppose that the continuous partial derivatives $\frac{\partial p}{\partial t}$, $\frac{\partial p {A}}{\partial t}$,$\frac{\partial p{B}^2}{\partial t}$~exist, the evolution of the transition probability density generated by the~\eqref{eqn:sde_error_propagation} satisfies
			%\begin{equation}
			%	\frac{\partial p(\xi_t|\xi_\gamma)}{\partial t}=-\sum_{i=1}^{d}\frac{\partial(p(\xi_t|\xi_\gamma){A}_{i})}{\partial \xi_i}+\frac{1}{2}\sum_{i,j=1}^{d}\frac{\partial\left[p(\xi_t|\xi_\gamma)({B}_tQ{B}_t^\top)\right]}{\partial \xi_i \partial \xi_j}
			%\end{equation} 
			%with the initial  condition 
			%\begin{equation}
			%	\lim_{t\rightarrow\gamma}p(\xi_t|\xi_\gamma)=\delta(\xi_t-\xi_\gamma).
			%\end{equation}
			%\end{lemma}
			%
			%It is well-known that a operation performed in the Kalman Filter is the propagation of a Gaussian random variable through the system dynamics. However the noisy term in the invariant error system is nonlinear, the error state cannot maintain the Gaussian distribution with the assumption of the white noise.  We suppose that this error can be approximated in the Gaussion distribution and want to calculate the expectation and second moment. Hence we are ready to analyze the evolution of the  expectation and the second moment of the dynamics via the above stochastic differential equation. Let $\bar{\xi}, {P}_t$ denote the expectation $\mathbb{E}(\xi)$, and second moment matrix $\mathbb{E}(\xi\xi^\top)$, respectively.
			%\begin{theorem}
			%\begin{equation}
			%	\begin{split}
				%		\frac{\d{\bar{\xi}_t}}{\d{t}}&=\bar{f}(\xi_t)\\
				%		\frac{\d{{P}}}{\d{t}}&={A}_t{P}+{P}{A}_t^\top+ \overline{{B}{Q}{B}^\top}
				%	\end{split}
			%\end{equation}
			%Suppose that the probabilty density is assumed symmetric and ``close to the mean''. These equations can be approximated in the following equation
			%\begin{equation}
			%\frac{\d{\bar{\xi}}}{\d{t}}=f(\xi_t)+({text})
			%\end{equation} 	
			%\end{theorem}
			%\begin{proof}
			%	See the appendix.
			%\end{proof}
			%Invariant EKF is an estimator for state on the Lie group and has been proved to achieve locally stability  in~\cite{Barrau}. In other words, the expectation of errors between estimates and the true states asymptotically converge to $0$ at the neighborhood of true state. Hence,  in this section we suppose that the estimated state satisfies the following distribution 
			%\begin{equation}
			%	\begin{split}
				%			\hat{{X}}_{t}&\triangleq{X}_{t}\exp{\xi_{t}}\quad\xi_t\sim\mathcal{N}(0,P_{t})\\
				%				\hat{{X}}_{t}&\triangleq\exp{\xi_{t}}{X}_{t}\quad\xi_t\sim\mathcal{N}(0,P_{t})
				%	\end{split}
			%\end{equation}
			%which $\xi$ in this form is equivalent to the nonlinear error which we mentioned above. Besides, it is noted that the distribution is assumed to be so concentrated that the tails of the Gaussian distribution are neglected. In this way, we do not need to worry about the problem if there still exists the bijective mapping from random variable in Lie algebra to the Lie group.
			%
			%We will consider the following problem.
			%\begin{problem}
			%	Given a $\hat{{X}}_{t_k}$, a control input $v\in\mathcal{U}$, a random variable $\xi_{t_k}$ with the Gaussian distribution $\xi_{t}\sim\mathcal{N}(0,P_{t_k})$ and a step size $T$. Show the evolution of $\xi_t$ in $t\in[t_k,t_k+T)$ and the parameters if the distribution can be approximated as a Gaussian distribution.
			%\end{problem}
			%This problem is analyzed in the above section. We will directly give our results on this problem.
			%\begin{proposition}[Algorithm in the Invariant EKF]
			%T.B.D
			%\end{proposition}
			%
			%\begin{remark}
			%Note that a operation performed in the Kalman Filter is the propagation of a Gaussian random variable through the system dynamics. However the noisy term in the invariant error system is nonlinear, the logarithm of invariant error cannot maintain the Gaussian distribution assuming that the distribution of process noise is the Gaussian distribution.  We suppose that this error can be approximated in the Gaussion distribution and want to calculate the expectation and second moment. Hence we are ready to analyze the expectation and the second moment of the dynamics via the above stochastic differential equation.
			%\end{remark}
			% We are ready to come back to consider dynamics in~\eqref{eqn:affine group system specific} which is extended from the affine group system. We will give its discrete-time form in the following proposition.
			
			
			
			
			
			%	\begin{theorem}
				%		The dynamic process $w_t$ has the following properties:
				%		\begin{itemize}
					%				\item $w_0=0$
					%				\item $w$ is continuous with respect to $t$.
					%				\item The expectation $m(t)=\mathbb{E}(w)$ and the second moment ${P}(t) = \mathbb{E}(ww^T)$ can be calculated by solving the following ODEs:
					%				\begin{equation*}
						%					\begin{split}
							%					\dot{m}&=\left( A_t-\ad_{\mathcal{G}_1({v}_b)}\right)m\\
							%					\dot{P}&={A}
							%					\end{split}
						%				\end{equation*} 
					%		\end{itemize}
				%	\end{theorem}
			%	\begin{proof}
				%		See the Appendix.
				%	\end{proof}
			%\begin{corollary}
			%By the above theorem, we have the following conclusion:
			%\begin{equation}
			%	\mathbb{E}(\frac{1}{2}\sum_{i=1}^{3n+3}{J}(-\ad_{w^\wedge})^{-1}{C}_i)=0
			%\end{equation}
			%\end{corollary}
			%
			%	\subsection{Example}
			%	The invariant error propagation in different kinds of group will be introduced in this subsection. 
			%	\subsubsection{$SO(2)$}
			%	The group $SO(2)$ is the subgroup of the $SE_n(3)$ group and also called the commutative group~(Abelian group ) which has the property that the group operation is commutative. Consider state ${X}$ lie in the group $SO(2)$ and have the dynamics~\eqref{eqn:affine group system specific}. Let $\xi^\wedge \in \mathfrak{so}(2)$ denote the logarithm of the invariant error. The SDE of error propagation~\eqref{eqn:continous_time_dynamics_sde} can be deduced in the following form:
			%	\begin{equation}
				%		\d{\xi}=(A_t-\ad_{\mathcal{G}({v}_b)})\xi\d{t}+a^\wedge \d{W},
				%	\end{equation}
			%	where $a$ describes the strength of the noise. 	It is noted that this SDE is the linear SDE.
			%	\subsubsection{$SE(2)$}
			%	The group $SE(2)$ is the extension of the group $SO(2)$ with the vector. Consider state ${X}$ lie in the group $SE(2)$ and the dynamics~\eqref{eqn:affine group system specific}. Let $\xi^\wedge \in \mathfrak{se}(2)$ denote the logarithm of the invariant error. The SDE of error propagation~\eqref{eqn:continous_time_dynamics_sde} can be deduced in the following form:
			%	\begin{equation}
				%		\d{\xi}=(A_t-\ad_{\mathcal{G}({v}_b)})\xi\d{t}+a^\wedge \d{W},
				%	\end{equation}
			%	where $a$ describes the strength of the noise. 
			%	
			%	\subsubsection{$SE_N(3)$}
			
			%	\section{Filter Design on the  Isotropic Noise}\label{sec:rela_between_C_and_D}
			%	
			%	In this part, we will apply our invariant error propagation into the filter design. We will use theorem results to derive a general estimator for the group $SE_N(3)$ within the affine group system. The group $SE_N(3)$, has $3(N+1)$ dimensions, corresponding to translation and rotation in the space. Consider the following nonlinear model with orientation and position, which state denoted by ${X}_k$ can be embedded in the matrix Lie group $SE_N(3)$. Its state is defined by the following parameters: the heading $\theta$, the position ${p}^{(1)}$ and the $i$th order of the derivative ${p}^{(i+1)}$, and write as the following matrix at time $t_k$:
			%	\begin{equation*}
				%		{X}_{k} = \begin{pmatrix}
					%			\exp{( \theta_k)}&
					%			\begin{matrix}
						%				{p}^{(1)}_k&\dots&{p}^{(N)}_k
						%			\end{matrix} \\
					%			0&\begin{matrix}\centering
						%				{I}
						%			\end{matrix}
					%		\end{pmatrix}.
				%	\end{equation*}
			%	
			%	The discrete-time kinematics model and the measurement model are considered as follows 
			%	\begin{align}\label{eqn:measurement_model}
				%		{X}_{{k+1}} &= {\Gamma}_{{k+1}}\Phi_{T}({X}_{{k}}){\Upsilon}_{{k+1}}\\
				%		{Y}_k&={X}_k\exp{(\zeta_k^\wedge)}
				%	\end{align}
			%	where ${\Gamma}_{{k+1}}, {\Upsilon}_{{k+1}}$ and the mapping $\Phi_{T}(\cdot)$ have been stated in the Proposition~\ref{pro:solution_of_dynamics} and ${Y}\in SE_N(3)$ denote the measured pose and ${\zeta}:=\begin{pmatrix}
				%		n_\theta^\top&n_{p1}^\top&\cdots&n_{pN}^\top \end{pmatrix} ^\top\in\mathbb{R}^{(3N+3)}
			%	$ denote a white noisy perturbation. We will define the pertubation variable  satisfying zero-mean Gaussian, i.e., $\zeta\sim \mathcal{N}(0,\Sigma)$.  
			%	
			%	\begin{remark}
				%		\Xinghan{revise in this remark} Design a filter on the right multiplication form.
				%	\end{remark}
			%
			%	\begin{remark}
				%		\Xinghan{revise in this remark} The measurement form~\eqref{eqn:measurement_model} can be solved via the optimization-based method. 
				%	\end{remark}
			%	
			%	\subsection{Propagation}
			%	Now consider the dynamic of estimator $\hat{{X}}$ with the discrete-time form of input measurement $\hat{{\Upsilon}}_{k+1}$ 
			%	\begin{equation}
				%		\hat{{X}}_{k+1}={\Gamma}_{{k+1}}\Phi_{T}(\hat{{X}}_{{k}})\hat{{\Upsilon}}_{k+1}.
				%	\end{equation}
			%
			%	Let $\eta_k$ denote the invariant error and the covariance of invariant error propagation is that
			%	\subsection{Update}
			%	Consider the following update step:
			%	\begin{equation}\label{eqn:left_error_kalman_filter}
				%		\begin{split}
					%			\hat{{X}}_k^{+}&=\hat{{X}}_k\exp{\left( \left( K_k\tilde{{y}}_k^\vee\right)^\wedge  \right) }\\
					%			\tilde{{y}}_k&=\log{\left( \hat{{X}}_k^{-1}{Y}_k\right) }
					%		\end{split}
				%	\end{equation}
			%	where $K_k$ is the Kalman gain at the time step $k$. 
			%	By $\xi=\log{({X}^{-1}\hat{{X}})}$ and $\xi^{+}=\log{({X}^{-1}\hat{{X}}^{+})}$, the equation~\eqref{eqn:left_error_kalman_filter}  writes:
			%	\begin{equation}\label{eqn:error_update}
				%		\begin{split}
					%			\xi_k^{+}&=\xi_k+\tilde{{z}}_k +r(\xi_k,\tilde{{z}}_k)\\
					%			\tilde{{z}}_k^\vee&:= K_k\left(- \xi_{k}+\zeta_k+r(-\xi_{k},\zeta_k)\right)^\vee .
					%		\end{split}
				%	\end{equation} 
			%	%{\color{red}
				%	%The output equations associated with the left invariant can write:
				%	%\begin{equation}
				%	%	{y}^1={X}{d}^1+{v}^1,\dots,{y}^n={X}{d}^n+{v}^n
				%	%\end{equation}
				%	%where ${d}^i$ are known vectors and ${v}^i$ are the Guassian noise with $\mathcal{N}(0,Q)$. The Left-Invariant
				%	%Kalman Filter (LIKF) is defined in this setting through the propagation~\eqref{eqn:SE(2) propagation} and following update step:
				%	%\begin{equation}\label{eqn:left_error_kalman_filter_1}
				%	%\hat{{X}}_k^{+}=\hat{{X}}_k\exp{\left( K_k\begin{pmatrix}
						%	%\hat{{X}}_k^{-1}{y}^{1}-{d}^1\\ 
						%	%\vdots\\
						%	%\hat{{X}}_k^{-1}{y}^{n}-{d}^n
						%	%	\end{pmatrix} \right) }
				%	%\end{equation}
				%	%where $K_k$ is the kalman gain at the time step $k$. 
				%	%By $\xi=\log{({X}^{-1}\hat{{X}})}$ and $\xi^{+}=\log{({X}^{-1}\hat{{X}}^{+})}$, the equation~\eqref{eqn:left_error_kalman_filter_1}  writes:
				%	%\begin{equation*}
				%	%	\begin{split}
					%	%		\xi_k^{+}&=\xi_k+{z}  +r(\xi_k,{z})\\
					%	%		{z}&:= K_k
					%	%		\begin{pmatrix}
						%	%		 \left( \exp{(-\xi_k)}-{I}\right){d}^{1}+\hat{{{X}}}^{-1}{v}^{1}\\
						%	%		 \vdots
						%	%		 \\
						%	%		  \left( \exp{(-\xi_k)}-{I}\right){d}^{n}+\hat{{{X}}}^{-1}{v}^{n}
						%	%		\end{pmatrix}.
					%	%	\end{split}
				%	%\end{equation*}
				%	%}
			%	The Kalman gain $K_k$ in ~\eqref{eqn:left_error_kalman_filter} can be computed like the linear Kalman filter via the Ricatti equation:
			%	\begin{equation}\label{eqn:kalman_gain_compute}
				%		\begin{split}
					%			\frac{\d{}}{\d{t}}{P}&={A}{P}+{P}{A}^\top+{Q}\quad {S}_k={P}_k+\Sigma_k\\
					%			K_k&={P}_{k} {S}_{k}^{-1}\quad {P}_k^{+}=({I}-K_k){P}_k.
					%		\end{split}
				%	\end{equation}
			%	
			%	In the following,  we will study the convergence of errors and the condition of the optimal filtering.
			%	\begin{theorem}\label{thm: Convergence of IEKF}
				%		Consider the system~\eqref{eqn:SE(2)_model} and~\eqref{eqn:measurement_model}  and the optimal filter in~\eqref{eqn:left_error_kalman_filter}. If there exists $\alpha_1, \alpha_2, \beta_1, \beta_2, \delta_1, \delta_2,M$ such that
				%		\begin{enumerate}[i.]
					%			\item ${Q}\succeq\delta_1{I}\succeq0$
					%			\item $\Sigma\succeq\delta_2{I}$
					%			\item $\alpha_1{I}\leq\int_{s=t_{n-M}}^{t_n}{Q}dt\leq\alpha_2{I}$
					%			\item $\beta_1{I}\leq\sum_{i=n-M}^{n-1}\Sigma^{-1}\leq\beta_2{I}$
					%		\end{enumerate}
				%		
				%		
				%		
				%	\end{theorem}
			%	\begin{proof}
				%		This proof is technical and has been moved
				%		to Appendix~\ref{apx:proof_of_convergence}. The rationale is that the subgroup $SO(2)$ of $SE(2)$ is a commutative group, which can derive the linear property of the evolution of the logarithm of the invariant error. Moreover, if the subgroup $SO(2)$ satisfies the convergence, then its associated group $SE(2)$ will converge at $t\to \infty$.
				%	\end{proof}
			%	
			%	\begin{theorem}
				%		Consider the Invariant Kalman filter in~\eqref{eqn:left_error_kalman_filter}. Suppose that the logarithm of invariant error on $SO(2)$ satisfies that there exists $T$ such that $\int_{T}^{T_k}\left| \tilde{\theta}_{t}\right|\d{t} \leq\epsilon$ for any $T_k$, the invariant error Kalman filter is optimal.
				%	\end{theorem}
			%	\begin{proof}
				%		This proof is also technical and has been moved to Appendix~.  
				%	\end{proof}
			
			\section{Conclusions}\label{sec:conclusion}
			
			%%+++Introduction+++%%
			In this paper, we introduced the notion of linear group systems in a matrix group and investigated its connection with affine group systems. We also analyzed the diffusion processes in the linear group system and provided an It\^o SDE description  for the projected dynamics evolving in the Lie algebra. Our findings allowed us to analyze the evolution of the invariant error of two trajectories in the presence of disturbances, and we presented descriptions for the error dynamics in both ODE and SDE formulations. Our explicit and accurate derivation of error dynamics
			for a particular matrix group $SE_N(3)$ may have practical applications in robotic engineering, particularly in estimation on $SE_N(3)$.
			Estimation problems often require filtering in affine group systems with stochastic dynamics, where accurate estimation depends on a deep understanding of the evolution of estimation errors.
			
			%Additionally, we compare the numerical results with those from the invariant extended Kalman filtering (InEKF) through simulations.
			
			
			
			\appendices \section{Proof of Proposition~\ref{pro:linear_system_property} }\label{apx:linear_system_property}		%	  In \cite{Barrau},  the definition of $A_t$ using $g_{u_t}(\exp{(\xi)})=(A_t\xi)^\wedge$ is impressive and promising in practice. Now we will not focus more on the computation of $A_t$ but instead explore the set of $A_t$ and give a necessary and sufficient condition on the linear group system with such $A_t$. 
				
				
				We introduce the following supporting lemma for the proof.
				
				%	  \begin{proof}	
					%	  	First we define the following mapping: for $x\in\mathbb R$,
					%	  	\begin{equation*}
						%	  		h(x)=\exp{\left(x{A} \right) }{B}\exp{\left(-x{A} \right) }.
						%	  	\end{equation*}	
					%	  	which admits a Taylor series at $x_{0}=0$ as
					%	  	$h(x)=\sum_{n=0}^{\infty}\frac{1}{n!}h_n x^{n}$,
					%	  	where $h_n$ are matrix Taylor coefficients of appropriate dimensions.  Evaluating the above series at $x=0$,  we have $h_0= B$.
					%	  	
					%	  	
					%	  	Taking derivative of $h(x)$ with respect to $x$, it yields that
					%	  	\begin{align*}
						%	  		\frac{\rm d}{\rm dx}h(x)&=\frac{\rm d e^{x A}}{\rm dx}  B e^{(-x A)}+e^{(x A)} B     \frac{\rm d e^{(-x A)}}{\rm dx} \\
						%	  		&= Ae^{\left(x{A} \right) }{B}e^{\left(-x{A} \right) }-e^{\left(x{A} \right) }{B}e^{\left(-x{A} \right) } A\\
						%	  		&=\left[ A, e^{\left(x{A} \right) }{B}e^{\left(-x{A} \right) }\right]\\
						%	  		&= [ A, h(x)]\\
						%	  		&= \sum_{n=0}^{\infty}\frac{1}{n!}\left[ A,  h_n\right]  x^{n},
						%	  	\end{align*} 
					%	  	where the last equality holds due to the continuity of the Lie bracket. On the other hand, we know that for any $x\in\mathbb R$,
					%	  	\begin{equation*}
						%	  		\sum_{n=0}^{\infty}\frac{1}{n!}h_{n+1} x^{n}=
						%	  		\frac{\rm d}{\rm dx}h(x)=
						%	  		\sum_{n=0}^{\infty}\frac{1}{n!}\left[ A,  h_n\right]  x^{n}. 
						%	  	\end{equation*}
					%	  	Evaluating the above equation at $x=0$, it leads to
					%	  	$h_1=[ A, h_0]=[ A,  B]$. Keeping taking higher-order derivatives of $h(x)$, it leads to that $h_{n+1}=
					%	  	\left[ A,  h_n\right]$ for $n=0,1,\ldots$. Finally, we conclude the proof by setting $x=1$ for 
					%	  	$h(x)$.
					%	  \end{proof}
				
				\begin{lemma}\label{lemma:supporting_lemma_of_proposition_1}
					Consider  a linear dynamical system \begin{equation}\label{eqn:LTV_dynamical_system}
						\dot{y}_t=A_t y_t ,~t\geq 0,
					\end{equation}
					in 
					$\mathfrak g$, where $\mathfrak g$  is the Lie algebra of a connected Lie group $G$, with  $y^\wedge_t\in  \mathfrak g$ and a given initial condition $y_{t_0}= y_0$. The linear mapping $A_t$ satisfies $[(A_t y_1)^\wedge,(A_t y_2)^\wedge]^\vee=A_t([y_1^\wedge,y_2^\wedge])^\vee$ mentioned in Lemma~\ref{lemma:A_t property}. Let $\Phi_{t,t_0}$ be the state transition mapping, i.e., $\Phi_{t,t_0}: y_{t_0}\mapsto y_t$. Then $\Phi_{t,t_0}$
					has the following properties:
					\begin{enumerate}[(i).]
						\item The dynamics of $\Phi_{t,t_0}$, $t>0$, satisfies a differential equation $\dot{\Phi}_{t,t_0}=A_t\Phi_{t,t_0}$ with initial state $\Phi_{t_0,t_0}$ being the identity mapping.
						\item  For any $\Phi_{t,t_0}$, $t>0$ and $ y,y'\in\mathbb{R}^d$,   $\Phi_{t,t_0}$ is a linear map satisfying 
						\begin{equation*}
							\Phi_{t,t_0}[y^\wedge,y'^\wedge]^\vee=[(\Phi_{t,t_0}y)^\wedge,(\Phi_{t,t_0}y')^\wedge]^\vee.
						\end{equation*}
					\end{enumerate}
				\end{lemma}
				\begin{proof}
					The first property follows from Theorem 5.1 of~\cite{hespanha2018linear}. We will prove the second property.
					Given any $y,y'\in \mathfrak{g}$ and consider the following three trajectories:
					\begin{align*}
						y_{0,t}= \Phi_{t,t_0}y_{0,t_0},~
						y_{1,t}= \Phi_{t,t_0}y_{1,t_0},~\hbox{and~}
						y_{2,t}= \Phi_{t,t_0}y_{2,t_0},
					\end{align*}
					where $y^\wedge_{0,t_0}=[y^\wedge,y'^\wedge]$, 
					$y^\wedge_{1,t_0}=y^\wedge$ and $y^\wedge_{2,t_0}=y'^\wedge$, respectively. It is ready to show that the three trajectories all follow the linear dynamical system~\eqref{eqn:LTV_dynamical_system}.
					Let $z^\wedge_t=[y^\wedge_{1,t},y^\wedge_{2,t}]$. Then, for $t\geq 0$,
					\begin{align*}
						\dot{z}_t^\wedge&=[\dot{y}_{1,t}^\wedge,y_{2,t}^\wedge]+[y_{1,t}^\wedge,\dot{y}_{2,t}^\wedge]\\
						&=[(A_t y_{1,t})^\wedge,y^\wedge_{2,t}]+[y^\wedge_{1,t},(A_ty_{2,t})^\wedge]\\
						&=(A_t[y^\wedge_{1,t},y^\wedge_{2,t}]^\vee)^\wedge=(A_tz_t)^\wedge,
					\end{align*}
					where the third equality uses $[(A_t y_1)^\wedge,(A_t y_2)^\wedge]=(A_t([y_1^\wedge,y_2^\wedge])^\vee)^\wedge$. 
					Since $z_{t_0}=[y^\wedge,y'^\wedge]^\vee=y_{0,t_0}$, we have 
					$y_{0,t}=z_t$ for all $t\geq 0$, that is,
					$$
				\Phi_{t,t_0}[y^\wedge,y'^\wedge]^\vee=[(\Phi_{t,t_0}y)^\wedge,(\Phi_{t,t_0}y')^\wedge]^\vee,
					$$
					which completes the proof.		
					%					Consider $X_t\in G$ with $X_{t_0}=I$ and the vector field $x_{t_0}$, which can be denoted as $X_t=\exp_m{(x_{t_0}(t-t_0))}$ and an adjoint mapping $\Ad_X:\mathfrak{g}\rightarrow\mathfrak{g}, x\mapsto XxX^{-1}$ induced by $X$ satisfying $\Ad_X[y_{t_0},y'_{t_0}]=[\Ad_Xy_{t_0},\Ad_Xy'_{t_0}]$. Let $\Ad_{X_t}y_{t_0}$ represent the flow of $y_t$ during $t\in \lim_{\delta\rightarrow0}[t_0,t_0+\delta]$. The derivative of  $\Ad_{X_t}y_{t_0}$ at $t=t_0$ writes
					%					\begin{equation*}
						%						\begin{split}
							%		\dot{y}_t|_{t=t_0}&=\frac{\d{\Ad_{X_t}y_{t_0}}}{\d{t}}|_{t=t_0}=x_{t_0}y_{t_0}-y_{t_0}x_{t_0}=\ad_{x_{t}}y_{t}|_{t=t_0}.
							%						\end{split}
						%					\end{equation*}
					%				The state $y_{t_0+\delta}$ writes 
					%				\begin{equation*}
						%					y_{t_0+\delta}=\Phi_{t_0+\delta,t_0}y_{t_0}=\Ad_{X_t}y_{t_0}
						%				\end{equation*}
					%				 within $t\in \lim_{\delta\rightarrow0}[t_0,t_0+\delta]$. Now consider the flow $y_t$ is divided into $n$ pieces, then there exist $X_1,......X_n$ such that 
					%					\begin{equation}
						%						\Phi_{t,t_{0}}y_{t_0}=\lim_{n\rightarrow\infty}\prod_{i=0}^{n}\Phi_{t_i,t_{i+1}}y_{t_0}=\lim_{n\rightarrow\infty}\prod_{i=0}^{n}\Ad_{X_i}y_{t_0},
						%					\end{equation}
					%					which illustrates that the mapping $\Phi_{t,t_{0}}$ is equivalent to $\lim_{n\rightarrow\infty}\prod_{i=0}^{n}\Ad_{X_i}$, which has the property $\lim_{n\rightarrow\infty}\prod_{i=0}^{n}\Ad_{X_i}[y_{t_0},y'_{t_0}]=[\lim_{n\rightarrow\infty}\prod_{i=0}^{n}\Ad_{X_i}y_{t_0},\lim_{n\rightarrow\infty}\prod_{i=0}^{n}\Ad_{X_i}y'_{t_0}]$. Hence, we have that $\Phi_{t,t_0}$ satisfy $ 				\Phi_{t,t_0}[y_{t_0},y'_{t_0}]=[\Phi_{t,t_0}y_{t_0},\Phi_{t,t_0}y'_{t_0}]$ which completes the proof.			
				\end{proof}
				
				%		\begin{proof}
					%			The matrix $ {J}(\mathrm{ad}_{\xi})=\frac {1-e^{-\mathrm {ad} _{\xi}}}{\mathrm {ad} _{\xi}}$ can be expanded into a Taylor series as 
					%			$ {J}(\mathrm{ad}_{\xi})=\frac {1-e^{-\mathrm {ad} _{\xi}}}{\mathrm {ad} _{\xi}}=\sum_{n=0}^{\infty}
					%			\frac{1}{(n+1)!}{\ad_{\xi}}^n$.
					%			Since $\lambda_{i}$'s are the eigenvalues of $\ad_{\xi}$, i.e., there exists ${x}\neq{0}$ such that $\ad_{\xi}{x}=\lambda_{i}{x}$, we have that 
					%			\begin{equation}\label{eqn:series_eigen}
						%				\sum_{n=0}^{k}
						%				\frac{1}{(n+1)!}{\ad_{\xi}}^n  x =
						%				\sum_{n=0}^{k}
						%				\frac{1}{(n+1)!}{\lambda_i}^n  x.
						%			\end{equation}
					%			Taking limitation by letting $k\to \infty$ for the both sides of~\eqref{eqn:series_eigen}, we have $ {J}(\mathrm{ad}_{\xi}) x=\frac{1 - e^{-\lambda_{i}}}{\lambda_{i}}{x}$, that is, the eigenvalues of $ {J}(\mathrm{ad}_{\xi})$ are $\frac{1 - e^{-\lambda_{i}}}{\lambda_{i}}$'s. When $ \lambda _{i}\neq 2k\pi {i},k=\pm 1,\pm 2,\ldots$, $\frac{1 - e^{-\lambda_{i}}}{\lambda_{i}}\neq 0$, which completes the proof.
					%		\end{proof}
				
				Now we are ready to prove Proposition~\ref{pro:linear_system_property}.
				
				$(i)\Rightarrow (iii)$. 
				%				Let $\gamma(\tau):=\exp{(\xi_t \tau)}\in G$ denote the curve with $\gamma(0)=e$ and $\gamma'(0)=\xi_t$.  By the  definition of differential of the mapping $f_{u_t}(\cdot)$ in differential geometry field, we have that \begin{align*}
					%					\text{d}f_{u_t}|_{\gamma(\tau)}\cdot\gamma'|_{\tau=0}&=(f_{u_t}\circ\gamma)'_{\tau=0}\\
					%					\text{d}f_{u_t}|_{e}\cdot \xi_t& = \text{d}f_{u_t}\circ\exp (\xi_t).
					%				\end{align*}
				Theorem 7 in~\cite{Barrau} shows that if the state $X_t$ of the dynamical system in \eqref{eqn:linear group system} satisfies a linear group system, then its Lie logarithm $x_t$ satisfies a linear system $\dot{x_t}=A_tx_t$, where $A_t$ is calculated using $f_{u_t}(\expm{(x_t)})=(A_t x_t)^\wedge +O(\|x\|^2)$. The sketch of the proof is that the solution $\phi_t(\expm{(x_0)})$ of a linear group system with initial condition $\expm{(x_0)}$ satisfies $\phi_t(\expm{(x_0)})=\expm{(\Phi_tx_0)}$ and Barrau and Bonnabel demonstrate that $\Phi_t$ is also the state transition matrix of a linear system, i.e., $\frac{\text{d}}{\d{t}}\Phi_t=A_t\Phi_t$. See \cite{Barrau} for more details. 
				
				$(iii)\Rightarrow(ii)$. Consider the dynamics of $x_t$ in $(iii)$.
				Let $X_t=\expm{\left( x_t\right) }$. For any $X,Y\in G$, we can find $x_a, x_b\in \mathbb R^d$ such that $\expm(x_a)=X$ and $\expm(x_b)=Y$. Therefore, 
				\begin{align*}
					&\phi_t(X)\phi_t(Y)=\phi_t(\expm(x_a) )\phi_t(\expm( x_b))\\
					&=\expm( \Phi_{t,0}x_a) \expm( \Phi_{t,0}x_b)= \expm\left(\Phi_{t,0}( \text{BCH}(x_a ^\wedge,x_b^\wedge)^\vee\right) \\		
					&=\phi_t\left(\exp\left( \text{BCH}( x_a ^\wedge, x_b^\wedge)\right)\right)= \phi_t(XY),
				\end{align*}
				where  the fourth equality uses  Lemma~\ref{lemma:supporting_lemma_of_proposition_1}, and $\Phi_{t,0}$ is the state transition mapping discussed in Lemma~\ref{lemma:supporting_lemma_of_proposition_1} and $\text{BCH}(x_a^\wedge,x_b^\wedge):=x_a^\wedge+x_b^\wedge+\frac{1}{2}[x_a^\wedge,x_b^\wedge]+\cdots$ is the Baker–Campbell–Hausdorff formula for $x_a^\wedge,x_b^\wedge\in\mathfrak{g}$.
				
				$(ii)\Rightarrow (i)$. 	 For any $X,Y\in G$ and $t>0$, we have 
				\begin{align*}
					f_{u_t}(\phi_t(XY))&=\frac{\d{}}{\d{t}}\phi_t(XY)\\
					&=\frac{\d{}}{\d{t}}\left( \phi_t(X)\phi_t(Y)\right)\\ 
					&=f_{u_t}(\phi_t(X))\phi_t(Y)+\phi_t(X) f_{u_t}(\phi_t(Y)).
				\end{align*}
				Therefore we have $f_{u_t}(XY)=f_{u_t}(X)Y+Xf_{u_t}(Y)$ for $t=0$,
				which completes the proof.
				
				
				
				
				
				\section{Proof of Theorem~\ref{thm:1}}\label{apx:SDE_of_Lie_logarithm}
				We only prove for the LID case; and for the RID case the proof is similar.
				The proof is divided into two parts. The first part uses It\^o's lemma to derive an SDE with undetermined coefficients and the second part involves calculating the coefficients from Proposition~\ref{pro:sde_estimate_state}.
				
				Suppose that the evolution of $x_t\in\mathbb R^d$ follows a formal SDE:
				\begin{equation}\label{eqn:xt}
					\begin{split}
						\d{x_t}&={F}_t\d{t}+{H}_t\d{W_t},
					\end{split}
				\end{equation}
				with undetermined coefficients ${F}_t\in\mathbb{R}^{d}$ and  ${H}_t\in\mathbb{R}^{d\times d}$.
				Since $X_t=\expm{\left(x_t\right)}\triangleq\exp{\left( \sum_{i=1}^{d}x_{t,i}{E}_i \right)}$, where $E_i$ is a standard orthogonal basis of the Lie algebra, the exact expression for $\d{X}_t$ can be given by  It\^o lemma with two terms:
				\begin{equation}\label{eqn:48}			\d{{X}_t}=\sum_{i=1}^{d}\d{x_{t,i}}\partial_{x_{t,i}}X+\frac{1}{2}\sum_{j=1}^{d}\sum_{i=1}^{d}\d{x_{t,j}}\d{x_{t,i}}\partial^2_{x_{t,ji}}X,
				\end{equation} 
				where $\partial_{x_{t,i}}X\triangleq 
				\frac{\partial \expm(x)}{\partial{x_{i}}}|_{x=x_t}$
				and $\partial^2_{x_{t,ji}}X\triangleq \frac{\partial^2 \expm(x)}{\partial x_{j}\partial x_{i}}|_{x=x_t}$.
				We first go into detail about $\d{x_{t,j}}\d{x_{t,i}}$,
				\begin{align*}
					&\d{x_{t,j}}\d{x_{t,i}}\\
					=&( F_{t,j}\d{t}+\sum_{k=1}^{d}H_{t,jk}\d{W}_{t,k}) ( F_{t,i}\d{t}+\sum_{k=1}^{d}H_{t,ik}\d{W}_{t,k}) \\
					=&\sum_{k=1}^{d}H_{t,jk}H_{t,ik}\d{t}.
				\end{align*}
				Substituting this and~\eqref{eqn:xt} into~\eqref{eqn:48}, we obtain that		\begin{equation}\label{eqn:SDE_M_N}
					\d{X}_t={M}_t\d{t}+{N}_t \d{W_t}
				\end{equation}
				with
				\begin{align*}
					{M}_t&\triangleq\sum_{i=1}^{d}F_{t,i}\partial_{x_{t,i}}X+ \frac{1}{2}\sum_{i,j,k=1}^{d}H_{t,jk}H_{t,ik}\partial^2_{x_{t,ji}}X,\\
					{N}_t&\triangleq\sum_{i=1}^{d}\sum_{k=1}^{d}H_{t,ik}\partial_{x_{t,i}}X.
				\end{align*}
				By Theorem 5 of~\cite{Hunacek2008}, we find 
				$
				\partial_{x_{t,i}}X=X_t \dexpm_{-x_t}{E}_i
				$, which further yields
				\begin{equation*}
					\begin{split}
						\sum_{i=1}^{d}F_{t,i}\partial_{x_{t,i}}X&= X_t\dexp_{-x_t}\sum_{i=1}^{d}F_{t,i}{E}_i= X_t\dexp_{-x_t}({F_t}^\wedge),\\
						\sum_{i=1}^{d}\sum_{k=1}^{d}H_{t,{ik}}\partial_{x_{t_i}}X&= X_t\dexp_{-x_t}\sum_{k=1}^{d}\text{col}_k({H})^\wedge.
					\end{split}
				\end{equation*}
				We next calculate $\Delta_{t,k}\triangleq\sum_{j=1}^{d}\sum_{i=1}^{d}H_{t,jk}H_{t,ik}\partial^2_{x_{t,ji}}X$ in the next lemma,
				the proof of which is further presented in the Appendix~\ref{apx:lemma_computation}.
				\begin{lemma}\label{lemma:calculate_support_lemma}
						$$
						\Delta_{t,k}=X_t\left(  \dexp_{-x_t}(\gamma^\wedge_{t,k})\right) ^2+X_t{C}^\wedge_{t,k},
						$$
						where ${C}_{t,k}\triangleq\sum_{i=0}^{\infty}\frac{(-1)^{i+1}}{(i+2)!}\ad_{\gamma^\wedge_{t,k}}(\ad_{x_t^\wedge})^i\gamma_{t,k}$
						with $\gamma_{t,k}\triangleq\text{col}_k({H_t})$.
					\end{lemma}
				
				
				%			We now have obtained the mapping on ${M}$ and ${N}$ with respect to $\xi$, which can be written as
				%			\begin{equation}\label{eqn:eta_relation_equation}
					%				{M}= \eta {J}_{-\xi}({F}^\wedge)+\frac{1}{2}\sum_{k=1}^{n}\Delta_k \quad
					%				{N}=\sum_{k=1}^{n}\eta \dexpm_{-\xi}(\text{col}_k({G})^\wedge).
					%			\end{equation}
				
				On the other hand, from Proposition~\ref{pro:linear_system_property}, we have
				\begin{equation*}
					f_{u_t}(X_t)=X_t\dexp_{-x_t}((A_tx_t)^\wedge).
				\end{equation*}
				Comparing~\eqref{eqn:dynamic_estimate_state_sde} and~\eqref{eqn:SDE_M_N} term by term, it implies that 
					\begin{equation*}
						\begin{split}
					{F}_t&=A_t x_t-\frac{1}{2}\dexpm^{-1}(-x_t)\sum_{k=1}^{d}{C}_{t,k}\\
					\text{col}_k({H}_t)&=\dexpm^{-1}(-x_t)s_k,
						\end{split}
					\end{equation*}
				which completes the proof.
				\hfill $\square$
				
				\section{Proof of Lemma~\ref{lemma:calculate_support_lemma}}\label{apx:lemma_computation}
						\begin{lemma}\label{lemma:support_lemma_2}
					$$			\sum_{j=1}^{d}H_{t,jk} \left(\partial_{x_{j}}(\adm_{x})^n\right)=\sum^{n-1}_{r=0}\adm^{r}_{x}\adm_{\gamma_{t,k}}\adm^{n-1-r}_{x},$$   for any $x\in\mathbb R^d$.
					
				\end{lemma}
				\begin{proof}
					The proof is by induction. Using the definition of $\ad$, for the case $n=1$ and any $y\in\mathfrak g$,
					\begin{align*}
						\sum_{j=1}^{d}H_{t,jk} \partial_{x_j}(\ad_{x^\wedge}y)
						&= \sum_{j=1}^{d}H_{t,jk}\partial_{x_j}[x,y]\\
						&= \sum_{j=1}^{d}H_{t,jk}\left( {E}_jy-y{E}_j\right)=\ad_{\gamma^\wedge_{t,k}}y.
					\end{align*}
					Assume the result holds for the case $n$, we show it holds for the case $n+1$. The $n+1$ case writes
					\begin{align*}
	 \partial_{x_j}(\ad^{n+1}_{x^\wedge}y)&= \partial_{x_j}\left( x^\wedge\ad^{n}_{x^\wedge}y-\ad^{n}_{x^\wedge}yx^\wedge\right)\\
	 &=\ad_{E_j}\ad^{n}_{x^\wedge}y+\ad_{x^\wedge} \partial_{x_j}(\ad^{n}_{x^\wedge}y)\\
	 &=\ad_{E_j}\ad^{n}_{x^\wedge}y+\ad_{x^\wedge}\sum^{n-1}_{r=0}\ad^{r}_{x^\wedge}\ad_{E_j}\ad^{n-1-r}_{x^\wedge}y\\
	 &=\sum^{n}_{r=0}\ad^{r}_{x^\wedge}\ad_{E_j}\ad^{n-r}_{x^\wedge}y,
					\end{align*}
			where the RHS matches the result for the case $n+1$. This completes the proof.
				\end{proof}
				
			\fbox{Proof of Lemma~\ref{lemma:calculate_support_lemma}}
We have that
				\begin{equation*}
					\begin{split}
						&\sum_{j=1}^{d}\sum_{i=1}^{d}H_{t,jk}H_{t,ik}\partial_{x_{t,ji}}^2X_t\\
						=&\sum_{j=1}^{d}H_{t,jk}\partial_{x_{t,j}}( X_t\dexp_{-x_t})(\gamma_{t,k}^\wedge)\\
						=& \sum_{j=1}^{d}H_{j,k}\left( (\partial_{x_j}X_t)\dexp_{-x_t}+X_t (\partial_{x_j}\dexp_{-x_t}) \right)(\gamma^\wedge_{t,k})\\
						=&X_t(\dexp_{-x_t}\gamma_{t,k}^\wedge)^2+\sum_{j=1}^{d}H_{t,jk}X_t (\partial_{x_j}\dexp_{-x_t})(\gamma_{t,k}^\wedge)
					\end{split}
				\end{equation*}
				Let $ {C}^\wedge_k\triangleq\sum_{j=1}^{d}H_{j,k} (\partial_{x_j}\dexp_{-x_t})(\gamma^\wedge_k) $. By Lemma~\ref{lemma:support_lemma_2},  we rewrite ${C}_k$ ,
				\begin{equation*}
					\begin{split}
					{C_k}&=\sum_{j=1}^{d}H_{j,k} (\partial_{x_j}\dexpm({-x_t}))\gamma_{t,k}\\
					&=\sum_{i=1}^{\infty}\frac{(-1)^{i}}{(i+1)!}\sum^{i-1}_{r=0}\adm^{r}_{x}\adm_{\gamma_{t,k}}\adm^{i-1-r}_{x}\gamma_{t,k},
					\end{split}
				\end{equation*}
				which completes the proof.
				\hfill $\square$
				
				
				
				%\appendix[The proof of some examples]
				%In this proof, we will show some typical applications which has been shown being promising in the filtering designs.
				%\begin{lemma}[Corollary~9 in \cite{Barrau2017LinearOS}]\label{pro:solution_of_dynamics}
				%	If $f_0$ satisfies that linear group system, let $\Phi_t: G\rightarrow G$ denote  the flow of $\dot{{X}}_t=f_0({X}_t)$ and the solution ${X}_t$ at arbitrary $t$ of equation~\eqref{eqn:affine group system specific} can be
				%	written as a function of the initial value ${X}_0$ as:
				%	\begin{equation}\label{eqn:Discrete_dynamics}
					%		{X}_t={\Gamma}_t\Phi_t({X}_0){\Upsilon}_t
					%	\end{equation}
				%	where  ${\Gamma}_t,{\Upsilon}_t$ are solutions to matrix differential equations involving only ${v}_b,{v}_g$ and can write:
				%	\begin{align*}
					%		\frac{\d{}}{\d{t}}{\Gamma}_t&=\mathcal{G}_2({v}_g){\Gamma}_t+f_0({\Gamma}_t)\\
					%		\frac{\d{}}{\d{t}}{\Upsilon}_t&={\Upsilon}_t\mathcal{G}_1({v}_b)   +f_0({\Upsilon}_t)
					%	\end{align*}
				%	with initial condition ${\Gamma}_0={\Upsilon}_0={I}$.
				%\end{lemma}
				%Now using Lemma~\ref{pro:solution_of_dynamics}, the general discrete form of \eqref{eqn:affine group system specific} can write:
				%\begin{equation}\label{eqn:dynamics_of_dicrete_time_form}
				%	{X}_{{k+1}} =g_{u_{k+1}}({X}_{{k}})\equiv {\Gamma}_{{k+1}}\Phi_{T}({X}_{{k}}){\Upsilon}_{{k+1}},
				%\end{equation}
				%where $T$ is each time step, and ${\Gamma}_{{k+1}},{\Upsilon}_{{k+1}}$ are obtained by $\frac{\d{}}{\d{t}}{\Gamma}_t=\mathcal{G}_2({v}_g){\Gamma}_t+f_0({\Gamma}_t)$ and $\frac{\d{}}{\d{t}}{\Upsilon}_t={\Upsilon}_t\mathcal{G}_1({v}_b)   +f_0({\Upsilon}_t)$ with the $k$th step ${\Gamma}_{{k}}={I}$ and ${\Upsilon}_{{k}}={I}$ .
				%		\subsection{The proof of Theorem.~\ref{pro:Noise increment in discrete-time form}}
				%		In this theorem, we just show the evolution of the exponential mapping of $w$. We can use Theorem~\ref{thm:SDE_of_Lie_logarithm} to give the SDE. Let ${{\Upsilon}}$ be the solution of 
				%		$        \frac{\d{}}{\d{t}}{\Upsilon}={\Upsilon}\mathcal{G}_1({v}_b)+f_0({\Upsilon}),
				%		$and $\hat{{\Upsilon}}$ be the solution of 
				%		$    \frac{\d{}}{\d{t}}\hat{{\Upsilon}} =\hat{{\Upsilon}}(\mathcal{G}_1({v}_b)+w)+f_0(\hat{{\Upsilon}})
				%		$. Consider an estimator have the right multiplication form 
				%		\begin{equation}\label{eqn:proof_support_1}
					%			\begin{split}
						%	\hat{{{X}}}_{{k+1}}&=g_{\hat{u}_{{k+1}}}(\hat{{{X}}}_{{k}})\exp{\left(w_{{k}} \right) }\\
						%	&={\Gamma}_{{k+1}}\Phi_{T}({X}_{{k}}){\Upsilon}_{{k+1}}\exp(w_{k}).
						%			\end{split}
					%		\end{equation}
				%		When we are considering $\hat{{\gamma}}_k$ as the measured control input, which is used into the estimator, we have that 
				%		\begin{equation}\label{eqn:proof_support_2}
					%	\hat{{{X}}}_{{k+1}}={\Gamma}_{{k+1}}\Phi_{T}({X}_{{k}})\hat{{\Upsilon}}_{{k+1}}.
					%		\end{equation}
				%	In this way,  via~\eqref{eqn:proof_support_1} and~\eqref{eqn:proof_support_2}, we observe that $\tilde{{\Upsilon}}$ has the following equivalent form
				%	\begin{equation}
					%		\tilde{{\Upsilon}}={\Upsilon}^{-1}\hat{{\Upsilon}}.
					%	\end{equation}
				%	Hence we have the following evolution for $\tilde{{\Upsilon}}$
				%		\begin{equation*}
					%		\frac{\d{}}{\d{t}}\tilde{{\Upsilon}}_t=\tilde{{\Upsilon}}_t{v}_b-{v}_b\tilde{{\Upsilon}}_{t}+f_0(\tilde{{\Upsilon}}_t)+\tilde{{\Upsilon}}_tw^\wedge.
					%	\end{equation*}
				%This form is the same with the left invariant error. Hence, using Theorem~\ref{thm:SDE_of_Lie_logarithm} completes the proof.
				%		\subsection{The proof of Theorem.~\ref{thm: Convergence of IEKF}}\label{apx:proof_of_convergence}
				%		Consider the trajectory of the orientation invariant error $\tilde{\theta}$. Since $SO(2)$ is a commutable group, the output of mapping $r$ with respect to the Lie bracket of $SO(2)$ is $0$.  Hence, via the error propagation equation \eqref{eqn:SE(2) propagation} and update equation \eqref{eqn:error_update}, we have the orientation invariant error propagation and update equation:
				%		\begin{equation*}
					%			\begin{split}
						%				\dot{\tilde{\theta}}&=w_\theta\\
						%				\tilde{\theta}^{+}&=\tilde{\theta}+K_\theta\left(\tilde{\theta}+n_\theta \right) .
						%			\end{split}
					%		\end{equation*}
				%		Obviously, the orientation estimate dynamics is a linear system. Hence, we can use the linear Kalman filter theory to show its convergence and optimality.  Let $w:=\int_{T}w \d{t}$ define the noise variable and it satisfies the Guassian distribution~$\mathcal{N}(0,Q)$, the expectation and covariance of $\tilde{\theta}$ dynamics are
				%		\begin{equation*}
					%			\begin{split}
						%				\mathbb{E}({\tilde{\theta}}_{k+1|k})&=\mathbb{E}({\tilde{\theta}}_{k|k}) \quad
						%				\mathbb{E}({\tilde{\theta}}_{k+1|k+1})=(1-K_\theta)\mathbb{E}({\tilde{\theta}}_{k|k})\\
						%				{P}({\tilde{\theta}}_{k+1|k})&={P}({\tilde{\theta}}_{k|k})+Q\quad
						%				{P}({\tilde{\theta}}_{k+1|k+1})=(1-K_\theta){P}({\tilde{\theta}}_{k+1|k})
						%			\end{split}	
					%		\end{equation*}
				%		The Kalman gain $K_\theta$ is computed by equation~\eqref{eqn:kalman_gain_compute} and is a positive number. Therefore, using the above equation, we can conclude that the $\tilde{\theta}$ will achieve stochastic convergence. However, for the position error propagation, it is not the linear equation and not satisfy the Gaussian distribution propagation. Now we first assume that the error distribution maintains the guassian distribution and we need to compute the dynamics during the propagation step and update one. Let $\tilde{p}:=(\tilde{p}_1,\tilde{p}_2)^\top$ In the following,  we will model the invariant error on the Lie algebra space via the stochasitc differential equation to compute the dynamics of expectation and covariance. Now, its propagation writes:
				%		\begin{equation*}
					%			\d{\tilde{p}}=\left( -\begin{pmatrix}
						%				v_2\\v_1
						%			\end{pmatrix}\tilde{\theta}-w^\wedge\tilde{p}\right)\d{t}+{C}\tilde{p}\d{w}+{C}^{-1}\d{w_p}.
					%		\end{equation*}
				%		Let ${C}$ be a step process. Using the Ito stochastic integral, we can compute the expectation of $\xi$:
				%		\begin{equation*}
					%			\begin{split}
						%				\mathbb{E}(\tilde{p}_{k+1|k})=\mathbb{E}(\tilde{p}_{k|k})+\mathbb{E}(\int_{T}\left( -\begin{pmatrix}
							%					v_2\\v_1
							%				\end{pmatrix}\tilde{\theta}-w^\wedge\tilde{p}\right)\d{t}).
						%			\end{split}
					%		\end{equation*}
				%		We assume that the error $\tilde{\theta}$ will achieve the stochastic stable, that is, $\mathbb{E}(\tilde{\theta})=0$ and in this condition, the above equation writes:
				%		\begin{equation*}
					%			\begin{split}
						%				\mathbb{E}(\tilde{p}_{k+1|k})&={F}_{k+1}\mathbb{E}(\tilde{p}_{k|k})\\
						%				\frac{\d{{F}}}{\d{t}}&=w^\wedge{F}\quad with \quad {F}(0)={I}
						%			\end{split}	
					%		\end{equation*}
				%		Now, we will compute the second order moment
				
				%Since we have proved the orientation invariant error can achieve the convergence, we show the limitation of the matrix ${C}-{I}$
				%\begin{equation}
				%	\lim_{\mathbb{E}(\tilde{\theta})\rightarrow0}\left( \frac{1}{\tilde{\theta}}\begin{pmatrix}
					%		\sin{(\tilde{\theta})}&-(1-\cos{(\tilde{\theta})})\\
					%		1-\cos{(\tilde{\theta})}&\sin{\tilde{\theta}}
					%	\end{pmatrix}-{I}\right) ={0}.
				%\end{equation}
				%
				%Hence, if the orientation invariant error have achieved the stability, it shows that the position invariant error will achieve the stability via the following linear dynamics
				%\begin{equation*}
				%\begin{pmatrix}
				%	\dot{\tilde{p}}_1\\
				%	\dot{\tilde{p}}_2
				%\end{pmatrix}=-\begin{pmatrix}
				%0&-w(t)\\
				%w(t) & 0
				%\end{pmatrix}\begin{pmatrix}
				%{\tilde{p}}_1\\
				%  {\tilde{p}}_2
				%\end{pmatrix}+{C}^{-1}\begin{pmatrix}
				%w_{p1}\\
				%w_{p2}
				%\end{pmatrix}.
				%\end{equation*} 
				%}
			%% use section* for acknowledgment
			%\ifCLASSOPTIONcompsoc
			%  % The Computer Society usually uses the plural form
			%  \section*{Acknowledgments}
			%\else
			%  % regular IEEE prefers the singular form
			%  \section*{Acknowledgment}
			%\fi
			%
			%
			%The authors would like to thank...
			
			
			
			
			
			% trigger a \newpage just before the given reference
			% number - used to balance the columns on the last page
			% adjust value as needed - may need to be readjusted if
			% the document is modified later
			%\IEEEtriggeratref{8}
			% The "triggered" command can be changed if desired:
			%\IEEEtriggercmd{\enlargethispage{-5in}}
			
			% references section
			
			% can use a bibliography generated by BibTeX as a .bbl file
			% BibTeX documentation can be easily obtained at:
			% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
			% The IEEEtran BibTeX style support page is at:
			% http://www.michaelshell.org/tex/ieeetran/bibtex/
			%	\bibliographystyle{plain}
			\bibliographystyle{unsrt}
			% argument is your BibTeX string definitions and bibliography database(s)
			\bibliography{ref}
			%
			% <OR> manually copy in the resultant .bbl file
			% set second argument of \begin to the number of references
			% (used to reserve space for the reference number labels box)
			%\begin{thebibliography}{1}
			%
			%\bibitem{IEEEhowto:kopka}
			%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
			%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
			%
			%\end{thebibliography}
			
			
			
			
			% that's all folks
		\end{document}%% bare_conf_compsoc.tex
