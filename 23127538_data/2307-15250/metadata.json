{
  "title": "D2S: Representing sparse descriptors and 3D coordinates for camera relocalization",
  "authors": [
    "Bach-Thuan Bui",
    "Huy-Hoang Bui",
    "Dinh-Tuan Tran",
    "Joo-Ho Lee"
  ],
  "submission_date": "2023-07-28T01:20:12+00:00",
  "revised_dates": [
    "2023-12-07T13:00:57+00:00",
    "2024-07-12T17:10:55+00:00",
    "2024-10-22T19:09:54+00:00"
  ],
  "abstract": "State-of-the-art visual localization methods mostly rely on complex procedures to match local descriptors and 3D point clouds. However, these procedures can incur significant costs in terms of inference, storage, and updates over time. In this study, we propose a direct learning-based approach that utilizes a simple network named D2S to represent complex local descriptors and their scene coordinates. Our method is characterized by its simplicity and cost-effectiveness. It solely leverages a single RGB image for localization during the testing phase and only requires a lightweight model to encode a complex sparse scene. The proposed D2S employs a combination of a simple loss function and graph attention to selectively focus on robust descriptors while disregarding areas such as clouds, trees, and several dynamic objects. This selective attention enables D2S to effectively perform a binary-semantic classification for sparse descriptors. Additionally, we propose a simple outdoor dataset to evaluate the capabilities of visual localization methods in scene-specific generalization and self-updating from unlabeled observations. Our approach outperforms the previous regression-based methods in both indoor and outdoor environments. It demonstrates the ability to generalize beyond training data, including scenarios involving transitions from day to night and adapting to domain shifts. The source code, trained models, dataset, and demo videos are available at the following link: https://thpjp.github.io/d2s.",
  "categories": [
    "cs.CV",
    "cs.RO"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15250",
  "pdf_url": "https://arxiv.org/pdf/2307.15250v4",
  "comment": "Accepted to IEEE Robotics and Automation Letters",
  "num_versions": null,
  "size_before_bytes": 35245864,
  "size_after_bytes": 1449098
}