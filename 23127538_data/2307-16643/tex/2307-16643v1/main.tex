\documentclass{INTERSPEECH2023}



\interspeechcameraready



\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{csquotes}
\usepackage[T1]{fontenc}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{arydshln}

\graphicspath{./figures}

\title{Improving grapheme-to-phoneme conversion by learning pronunciations from speech recordings}

\name{Manuel Sam Ribeiro, Giulia Comini, Jaime Lorenzo-Trueba}

\address{Amazon Alexa, TTS Research}
\email{\{manuerib, gcomini, truebaj\}@amazon.com}

\begin{document}

\maketitle
\begin{abstract}
The Grapheme-to-Phoneme (G2P) task aims to convert orthographic input into a discrete phonetic representation.
G2P conversion is beneficial to various speech processing applications, such as text-to-speech and speech recognition. However, these tend to rely on manually-annotated pronunciation dictionaries, which are often time-consuming and costly to acquire. In this paper, we propose a method to improve the G2P conversion task by learning pronunciation examples from audio recordings. Our approach bootstraps a G2P with a small set of annotated examples. The G2P model is used to train a multilingual phone recognition system, which then decodes speech recordings with a phonetic representation. Given hypothesized phoneme labels, we learn pronunciation dictionaries for out-of-vocabulary words, and we use those to re-train the G2P system. Results indicate that our approach consistently improves the phone error rate of G2P systems across languages and amount of available data.
\end{abstract}
\noindent\textbf{Index Terms}: grapheme-to-phoneme, phone recognition, pronunciation modeling, low resource, text-to-speech

\input{./content/body.tex}


\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
