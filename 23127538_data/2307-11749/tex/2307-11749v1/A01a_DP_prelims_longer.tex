\section{Differential Privacy}\label{appendix:privacy}

In this work, we will consider an algorithm that satisfies two levels of privacy protection appropriate for federated learning; differential privacy in the aggregate model and differential privacy in the local model. For more details on a potential system for achieving these guarantees please see \cite{mcmillan2022private}. In the federated setting where users may have more than one data point, there are two main choices for the granularity of the privacy guarantee: \devicenospace-level DP and event (or data point)-level DP. We will focus on the stronger of these two guarantees, \devicenospace-level DP, which protects against a user changing all of the data points associated to them.
We will introduce these two types of privacy guarantees in this section. Throughout the remainder of this section, when we refer to a user's data point, we are referring to their set of data points. 


\subsection{Aggregate Differential Privacy}

In the aggregate model of differential privacy, we assume the existence of an aggregation protocol that sums the local reports before they are released to the analyst. The analyst still interacts with the clients in a federated manner to perform the algorithm, but the aggregation protocol guarantees that the analyst does not receive anything about the local reports \emph{except their sum}. The aggregate model of DP is a derivative of the more general and more common than aggregate DP shuffle model of differential privacy introduced in \cite{ErlingssonFMRTT19, CheuSUZZ19}. 

\begin{definition}\label{defnaggregateDP1}
A single round algorithm $\A$ is $(\eps, \delta)$-DP in the aggregate model if the output of the aggregation protocol on two datasets that differ on the data of a single individual are close. Formally, an algorithm $\A:\cD^n\to\cZ$ is $(\eps, \delta)$-DP in the aggregate model if the following conditions both hold:
\begin{itemize}
\item it can be written as $\A(d^{(1)}, \cdots, d^{(n)})=\phi(\aggregator(f(d^{(1)}), \cdots, f(d^{n)}))$ where $f:\cD\to\cZ$ is a randomized function that transforms that data, $\aggregator$ is an aggregation protocol, and $\phi:\cY^n\to\cZ$ is some post-processing of the aggregated report
\item for any pair of datasets $D$ and $D'$ that differ on the data of a single individual, and any event $E$ in the output space,
\[
\Pr(\A(D)\in E)\le e^{\eps} \Pr(\A(D')\in E)+\delta.
\]
\end{itemize}
Note that the post-processing function takes the aggregation as its input and does not have access to the individual reports.
\end{definition}
When $\delta>0$, we call this approximate DP.
When each user uses a local randomizer (i.e. the functions $f$ in Definition~\ref{defnaggregateDP1} are local randomizers), the privacy guarantee in the aggregation model can be bounded by a quantity that is a function of both $\eps_0$, the privacy guarantee in the local model, and $n$, the number of users that participate in the aggregation protocol~\cite{ErlingssonFMRTT19, CheuSUZZ19}. As the number of users increases, the privacy guarantee on the output of the aggregation protocol gets stronger; essentially each user gets ``lost in the crowd''. In this work, we will bound aggregate DP guarantee by the numerical bound on privacy amplification by shuffling due to \cite{feldman2023stronger}, who provide bounds for both approximate DP and a related privacy notion called R\'enyi DP. 

A multi-round algorithm $\A$ is $(\eps,\delta)$-DP in the aggregate model if it is the composition of single round algorithms which are DP in the aggregate model, and the total privacy loss of $\A$ is $(\eps,\delta)$-DP.
One can formulate a version of Definition~\ref{defnaggregateDP1} specifically for multi-round algorithms, for a more in-depth discussion see \cite{Jain2021ThePO}. There are a number of standard theorems for analysing the privacy guarantee of composing multiple differentially private algorithms~\cite{DMNS06, DRV}. When the number of iterations is small, the advanced composition theorem~\cite{DRV, Kairouz:2017} provides a tight analysis. When the number of iterations is large, a tighter analysis is obtained by computing the composition bound in terms of R\'enyi differential privacy~\cite{DLDP, mironov2017renyi} then converting this R\'enyi bound into an $(\epsilon, \delta)$-DP bound~\cite{canonne2020discrete}. In our experiments, we compute the composed privacy guarantee using both of these methods, then select the tighter bound.

Given an expected number of users, the number of iterations, and the desired aggregate privacy guarantee, we can use binary search to approximate the largest per iteration local epsilon that will achieve the given aggregate privacy guarantee. This algorithm is given in Algorithm~\ref{alg:privacy} where RenyiShuffleAnalysis computes the R\'enyi privacy guarantee for amplification by shuffling, Composition uses the composition theorem for R\'enyi DP, Conversion converts the R\'enyi DP guarantees to approximate DP guarantees and BinarySearch makes the decision on whether to increase or decrease $\epslocal'$. Since the aggregate privacy guarantee is our primary privacy guarantee, we do not put an upper bound on our local epsilon. Table~\ref{tab:eps} demonstrates how the local epsilon increases with the number of iterations, and the desired aggregate privacy guarantee. Table~\ref{tab:eps} shows different values of $\epslocal$ and $\epsagg$ depending on the number of iterations for $\numusers = 1.6 \times 10^6$ devices (number of users in the Reddit data set used for our experiments). 

\begin{algorithm}
\caption{Privacy Analysis}\label{alg:privacy}
\begin{algorithmic}[1]
\STATE \textbf{Input}: $\epsilon_{agg},\delta$: Aggregate privacy budget, $\numiters:$ number of iterations, $\numusers$: number of \devices, $\alpha$: pre-defined set of Renyi parameter, $E$: binary search error tolerance
\STATE \textbf{Output}: $\epslocal$: local privacy budget of each \device in each iteration
\STATE $\epslocal' \gets \text{Initialization}$
\WHILE {$|\epsilon_{agg}-\epsilon'_{agg}| \le E$}

\STATE $\epsilon'_r \gets \text{RenyiShuffleAnalysis}(\epsilon'_l, \delta, \numiters, \numusers, \alpha)$ \textit{{\color{darkgreen} // Theorem 3.2 of ~\cite{feldman2023stronger}}}
\STATE $\epsilon'_{composition} \gets \text{Composition}(\epsilon'_r, \numiters)$ \textit{{\color{darkgreen} //  $\epsilon'_{composition} = \numiters \times \epsilon'_r$ }}
\STATE $\epsilon'_{agg} \gets \text{Conversion}(\epsilon'_{composition}, \delta, \alpha)$ \textit{{\color{darkgreen} //  Proposition 12 of ~\cite{canonne2020discrete}}}
\STATE $\epsilon'_l \gets \text{BinarySearch}(\epsilon_{agg}, \epsilon'_{agg}, \epslocal')$
\ENDWHILE
\STATE $\epsilon_l \gets \epsilon'_l$
\STATE \textbf{return} $\epsilon_l$
\end{algorithmic}
\end{algorithm}


\begin{table}[h]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|c|cccccc|cccccc|cccccc|}
\hline
$\epsilon_{agg}$    & \multicolumn{6}{c|}{$0.25$}                                                                                                         & \multicolumn{6}{c|}{$0.5$}                                                                                                         & \multicolumn{6}{c|}{$1$}                                                                                                         \\ \hline
\textbf{$\numiters$}      & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{5} & 6 & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{5} & 6 & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{5} & 6 \\ \hline
\textbf{$\epsilon_l$} & \multicolumn{1}{c|}{6.36}  & \multicolumn{1}{c|}{6.05}  & \multicolumn{1}{c|}{5.79}  & \multicolumn{1}{c|}{5.63}  & \multicolumn{1}{c|}{5.35}  & 5.31  & \multicolumn{1}{c|}{7.18}  & \multicolumn{1}{c|}{6.96}  & \multicolumn{1}{c|}{6.73}  & \multicolumn{1}{c|}{6.48}  & \multicolumn{1}{c|}{6.33}  & 6.26  & \multicolumn{1}{c|}{8.03}  & \multicolumn{1}{c|}{7.73}  & \multicolumn{1}{c|}{7.58}  & \multicolumn{1}{c|}{7.39}  & \multicolumn{1}{c|}{7.03}  & 7.018  \\ \hline
\end{tabular}
}
    \caption{Choices of $\eps_{agg}$, $\numiters$ and $\eps_l$ }
    \label{tab:eps}
\end{table}






