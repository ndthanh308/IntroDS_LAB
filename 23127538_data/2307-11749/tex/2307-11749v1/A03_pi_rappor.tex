\section{PI-RAPPOR}\label{appen:pi-rappor}

In this section, we describe the PI-RAPPOR local randomizer that may be used as the local randomizer ($\compressor$) and two algorithms ($\decompressor$) we can use to get the private frequency estimates each element queried (usually the data domain in each round $\prefixlist_{t-1}\times \alphadom^{\seglent}$). We also discuss the computation and communication costs for the device side and both the server side algorithms, provide recommendations for speeding up the algorithms by a factor of $e^\epslocal + 1$, and provide guidelines for practitioners on how to choose one amongst the two frequency estimation algorithms based on the computation costs. 

As defined in \cite{feldman2021lossless}, we define two constants $\alpha_0$ and $\alpha_1$ which we set suitably to satisfy deletion $\epslocal$ - DP ($\alpha_0 = 1 - \alpha_1 = \frac{1}{e^\epslocal + 1}$) and replacement $\epslocal$ - DP ($\alpha_0 = \frac{1}{e^\epslocal + 1}, \alpha_1 = \frac{1}{2}$), respectively. Let $q$ be a prime power so that $\alpha_0 q$ is an integer (the case when $\alpha_0 q$ is not an integer incurs a small additional error as described in Lemma 4.7 of \cite{feldman2021lossless}). We let $\smallfield$ denote the $\alpha_0 q$ smallest elements of the field and let $\bool{z}$ denote the indicator of the event $z \in \smallfield$. Algorithm 3 of \cite{feldman2021lossless} gives the PI-RAPPOR local randomizer algorithm which can be used as $\compressor$ and Algorithms 4 and 5 of \cite{feldman2021lossless} are two frequency estimation algorithms, which use the outputs of $\compressor$ applied to a datapoint from all users and estimate the frequency of elements in the data domain. The frequency estimate output of either of these algorithms of an element $w$ is a random variable $\freqest[w]$ as defined below:
\begin{equation}
    \tilde{f}[w] = \frac{\binomial{f[w]}{\alpha_1} + \binomial{n - f[w]}{\alpha_0} - n\alpha_0}{\alpha_1 - \alpha_0},
\end{equation}
where $f[w]$ is the true frequency of $w$ and $\binomial(k,\alpha)$ denotes a binomial random variable with parameters $k$ (number of experiments) and $\alpha$ (success probability).
 
As shown in Lemma 4.2 of \cite{feldman2021lossless}, $\tilde{f}$ is an unbiased estimator of $f$ with the minimum possible variance for locally private estimators. Algorithms 4 and 5 in \cite{feldman2021lossless} output the same estimate but only differ in terms of their computational complexity. Please See \cite{feldman2021lossless} for a discussion. While both the algorithms find the frequency of all elements in the domain, they can be easily modified to find the frequency of only subset of the elements in the domain and the computational complexity correspondingly depends on this subset size linearly.


\paragraph{Speedups in the decompressor for prefix based algorithms:}

When the data domain is a contiguous set of elements, we can 
% choose the prime power $q$ so that $\bool{v(w)}$ evaluates to 0 for most values of $w$ and 
precisely calculate the values of $w$ for which it evaluates to $\bool{v(w)} = 1$ and use it to speed up computation by a factor of roughly $\frac{1}{\alpha_0}$. For a given segment length $\seglen$, we choose $q$ to be the smallest prime power bigger than $K = \max\{e^\epslocal + 1,2^\seglen\}$. We also let $c = \lfloor \frac{q}{e^\epslocal + 1} \rfloor$ and denote $\{0,1,\dots,c\}$ by $[c]$. The data domain is of the form $\prefixlist \times \field{q}$ (mapped to $\field{q}^d$) where the elements of $\prefixlist$ are mapped to elements in the first $d - 1 = \lceil\log_q|\prefixlist|\rceil$ dimensions and the last dimension is assigned to all possible completions for a given prefix of length $\seglen$. 

Both algorithms 4 and 5 of \cite{feldman2021lossless} calculate $\bool{v^i(w)}$ where $v^i(w)= v^i_0 + \sum_{j \in [d]} v^i_jw_j$ for all $w$ in the data domain, which in our case is $\prefixlist \times \field{q}$. Instead of calculating the product $v^i(w) = v^i_0 + \sum_{j \in [d]} v^i_jw_j$ for all $w \in \prefixlist \times \field{q}$, we calculate  $v^i_{-1}(h) = v^i_0 + \sum_{j \in [d - 1]} v^i_jh_j$ for all prefixes $h \in \prefixlist$. Then for each element (say $g$) in $[c]$, we calculate $(v^i_d)^{-1}(g - v^i_{-1}(h))$ to get back precisely the element $w_d \in \field{q}$ for which $\bool{v^i(w)}$ will evaluate to 1. The inverse operation can be computed using a lookup table that can be calculated ahead of time in $\log(q)$ time. Thus, instead of searching over all elements in the data domain $\prefixlist \times \field{q}$ in constant time, we search over all possible cutoffs and prefixes in $\log(q)$ time each making the effective computational complexity linear in $c|\prefixlist|\log(q)$ instead of linear in $|\prefixlist|q$, which is a speedup of size roughly $\frac{e^\epslocal + 1}{\epslocal}$.

