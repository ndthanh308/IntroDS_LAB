\section{Related Works}\label{sec:related}
Heavy hitters discovery methods have applications in various different domains~\cite{elkordy2023federated}. This problem has been studied in both the local model~\cite{apple, wang2019locally, acharya2019hadamard} and shuffle model~\cite{ghazi2021power} of differential privacy. Furthermore, recently different multi-party-computing~\cite{boneh2021lightweight} methods and combination of multi-party-computing and DP techniques~\cite{bohler2021secure} have been proposed to find the top-k heavy hitters in different domains. In this work we focus on large domains and specifically iterative methods that allows us to satisfy system constraints. 

In~\cite{zhu2020federated}, the authors propose an iterative algorithm to discover heavy hitters in the central model of differential privacy. The general framework of forming a tree-based structure is the same to our Prefix Tree method except in their algorithm, $\triehhg$, samples a subset of \devices($\gamma \sqrt{\numusers}$) in each iteration and uses the data points of these \devices to compute the heavy hitters for the next iteration, without any additional noise and hence does not satisfy local differential privacy. They select the prefix list for the next iteration to be all the prefixes such that more than $\theta$ \devices send the character in that iteration. The parameters $\gamma$ and $\theta$ are chosen to achieve the required privacy guarantee. 

$\triehhp$~\cite{cormode2022sample} is an extension to $\triehhg$. The authors use the same sampling and threshold algorithm as $\triehhg$ to provide the $(\epsilon, \delta)-$aggregated differential privacy. However, they are able to support more general applications such as quantile and range queries. In addition to detecting heavy hitters, their method is able to report the frequency of heavy hitters without using additional privacy budget. To achieve their goal, they take advantage of Poisson sampling instead of fixed-size sampling to hide the exact number of samples. Consequently, releasing heavy hitters and their counts does not violate user privacy. 

Set Union is a critical operation in many data related applications. Differentially Private Set Union (DPSU) methods are~\cite{gopi2020differentially} popular for extracting n-grams, which is a common application in NLP algorithms. These methods attempt to find the largest subset of the union while satisfying DP. Authors in~\cite{wilson2020differentially}, samples a specific number of items per user and generates a histogram. Finally the items whose counts are above a certain threshold will be reported. In~\cite{carvalho2022incorporating}, utility is boosted by privately reporting the frequencies to the server and eliminating the sampling step. They further take advantage of knowledge transfer from public datasets to achieve more accurate frequency estimation. Using public data as prior knowledge for private computation is investigated in various other works~\cite{liu2021leveraging, bassily2020learning}. In this paper, we use this knowledge transfer to explore the effect of using a  deny list on the utility of the algorithm. Authors in~\cite{Kim2021DifferentiallyPN} combined DPSU and tree based method to improve the utility of n-gram extraction model. The empirical results of their work imply that selecting more than one data point per device improved performance in the central DP setting. 
While we focus on data selection mechanisms that select a single data point per user per round, these mechanisms naturally extend to mechanisms that select more than one data point. In order to elaborate the impact of weighted vs. unweighted sampling, we focus on selecting a single data point per device. We leave an exploration of the optimal number of data points per device per iteration in the aggregate DP setting to future work. 
