\section{TrieHH}
\label{appendix:TrieHH}

\begin{table}[htb]
    \centering
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
        $\epsagg$ & \multicolumn{4}{|c|}{$1$} & \multicolumn{4}{|c|}{$0.5$} & \multicolumn{4}{|c|}{$0.25$} \\ \hline
        $T$ & $12$ & $6$  & $4$ & $3$  & $12$ & $6$  & $4$ & $3$& $12$ & $6$  & $4$ & $3$\\ \hline
         Sampling Rate  & $0.0079$ & $0.0153$ & $0.0221$& $0.0283$ & $0.0040$ & $0.0079$ & $0.0117$& $0.0153$   &$0.0020$ & $0.0040$ & $0.0060$& $0.0079$  \\ \hline
    \end{tabular}
    }
    \caption{Number of rounds effect on the sampling rate of $\triehhg$ ($\delta=10^{-6}$, $\numusers = 1.6\times10^6, \theta = 10$)}
    \label{tab:TrieHH}
\end{table}



\subsection{Single Data Point Setting for $\triehhg$}\label{appendix:single}
In this section we discuss the effect of number of iterations on the utility of a single data point setting for $\triehhg$~\cite{zhu2020federated}. In Figure~\ref{fig:triehhfrequency}, we show the effect of different segmentation on the utility of the algorithm for a single data point per \device setting. For these experiments we used $\epsagg = 1$ and sampling rates are set based on table~\ref{tab:TrieHH}. To evaluate the effect of different segmentation in this part we used the $\complimit = 10^7$ on the dimension. The number of heavy hitters detected by $\triehhg$ algorithm, when the number of iterations are 12 (1 char), 6 (2 char), 4 (3 char), 3 (4 char) are $[142, 261, 355, 135]$. Initially having larger segments help with the algorithm since less number of iterations are required and consequently sampling rate becomes larger. However, by increasing the segment size to certain point, the utility drops. The reason is by enlarging the segment length the number of prefixes in each iteration reduces because of the dimension constraint. Hence, for the comparisons with $\ouralgorithm$ we used the best configurations which is having 4 iterations. 

% Figure environment removed

\subsection{Multiple Data Points Setting for $\triehhg$}\label{appendix:multi}
We further analyze the multiple data points setting. To optimize the algorithm we took advantage of a prefix list for each iteration. \Device s send their data only if they find a match with a prefix in the prefix list. We also use an end character symbol to indicate the end of string. If end character symbol is observed in a prefix at the end of an iteration, the corresponding prefix will be excluded from the prefix list. Therefore, users can send other unfinished prefixes. Also, for our evaluation, we used binary encoding which uses $5$ bits to represent each character. 

The total number of heavy hitters detected by $\triehhg$ algorithm, when the number of iterations are 12 (1 char), 6 (2 char), 4 (3 char), 3 (4 char), are $[816, 706, 506, 110]$ respectively. In this setting, 12 iterations shows the best utility. In Figure~\ref{fig:triehhmultitotal1} and ~\ref{fig:triehhmultifreq1} we used weighted sampling described in the original paper.

 % Figure environment removed

To further improve the utility of $\triehhg$, we used unweighted sampling in another set of experiments. This new sampling scheme leads to finding $[816, 529, 422, 85]$ heavy hitters when having 12 (1 char), 6 (2 char), 4 (3 char), 3 (4 char) iterations respectively. Figure ~\ref{fig:triehhmulticounts1} and ~\ref{fig:triehhmultitotalunweighted} shows the loss and marginal discovered counts based on the unweighted sampling scheme. As demonstrated in these figures, unweighted scheme is able to find more heavy hitters and cause less utility degradation. Also using both sampling schemes, 12 iterations shows the highest utility. Thus, for the comparisons with $\ouralgorithm$ we use unweighted sampling, prefix-list and 12 iterations for $\triehh$.  

% Figure environment removed



