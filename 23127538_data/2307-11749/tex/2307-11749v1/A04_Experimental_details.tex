\section{Additional Experimental Results}\label{appen:expts-details}
\paragraph{Effect of Uniform vs Non-uniform Segmentation in Single Data Point Setting}

As explained in~\ref{sec:expts} using our adaptive segmentation algorithm helps discovering more heavy hitters. In Figures~\ref{fig:segmentationcounts} and ~\ref{fig:segmentationtotal} we show the discovered counts and total utility loss comparison of this uniform and non-uniform segmentation. 
% Figure environment removed
\paragraph{Effect of Dimension Limitation in Single Data Point Setting}

In Figures~\ref{fig:PayloadLimitCount} and ~\ref{fig:PayloadLimitTotal} we evaluated the effect of different dimension limitation parameters in the utility of the model. As shown, reducing the dimension limitation below a certain point, causes a significant utility drop. However, allowing the algorithm to have one extra iteration can help recovering top heavy hitters. 
% Figure environment removed

\paragraph{Effect of Data Selection in Multiple Data Points Setting}

There are different ways to measure the frequency of data points. In Section~\ref{sec:alg}, we discuss how averaging the distribution of words overall \devices can be used to define the global frequency of words (weighted metric). Figure~\ref{fig:weighttotalsamp} shows the total utility loss when using this distribution. 


One other way to measure the frequency is the percentage of \devices who has the word in their support (unweighted metric). Figure~\ref{fig:unweightcountsamp} shows the global number of discovered bins based on how many \devices have the word. Figure~\ref{fig:unweighttotalsamp} demonstrates the total utility loss when using the average of users who has the data point as the frequency of words. As depicted using both distributions, unweighted data selection outperforms weighted data selection regardless of the frequency computation technique. Also prefix list benefits both of the data selection schemes. 

% Figure environment removed
 
\paragraph{Effect of adding a \texttt{deny list} in Multiple Data Points Setting}



Figure~\ref{fig:weightotaldeny} shows the total utility loss when using the frequency of the words in \devices for extracting the global distribution. In Figure~\ref{fig:weightcountdeny} and ~\ref{fig:unweightotaldeny} we use the number of \devices with the word to demonstrate the true counts of the discovered words and total utility loss.  
% Figure environment removed
 
\begin{comment}
% Figure environment removed

% Figure environment removed
\end{comment}

\paragraph{Comparison with previous works}
As illustrated in section~\ref{sec:expts} $\ouralgorithm$ outperforms $\triehh$ under the same constraints. In Figure~\ref{fig:compcountmulti} and~\ref{fig:compmulti}, we show a comparison of $\ouralgorithm$ and $\triehh$ for the multiple data points setting.
% Figure environment removed

