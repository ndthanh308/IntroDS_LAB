\documentclass[12pt, final]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry} 
\usepackage{cite}
\usepackage{mauraisStyle}
\usepackage{cleveref}
\usepackage[normalem]{ulem}

\usepackage[textsize=tiny]{todonotes}
\setlength{\marginparwidth}{2.2cm}

\definecolor{darkgreen}{rgb}{.15,.55,0}
\newcommand{\ymm}[1]{\todo[linecolor=darkgreen,backgroundcolor=darkgreen!25]{#1}}
\newcommand{\aem}[1]{\todo[linecolor=violet,backgroundcolor=violet!25]{#1}}

\newcommand{\rmT}{\mathrm{T}}

\newcommand{\Shi}{{S_{\rm hi}}}
\newcommand{\Slo}{{S_{\rm lo}}}

\newcommand{\ghi}{{g_{\rm hi}}}
\newcommand{\glo}{{g_{\rm lo}}}

\renewcommand{\chi}{{c_{\rm hi}}}
\newcommand{\clo}{{c_{\rm lo}}}

\newcommand{\Bhi}{{B_{\rm hi}}}
\newcommand{\Blo}{{B_{\rm lo}}}

\newcommand{\Xhi}{{X_{\rm hi}}}
\newcommand{\Xlo}{{X_{\rm lo}}}
\newcommand{\XloOne}{{X_{\mathrm{lo}, 1}}}
\newcommand{\XloL}{{X_{\mathrm{lo}, L}}}
\newcommand{\Xloell}{{X_{\mathrm{lo}, \ell}}}
\newcommand{\Xmf}{X_{\rm mf}}

\newcommand{\Xhii}{{X_{\rm hi}^{i}}}
\newcommand{\Xloi}{{X_{\rm lo}^{i}}}

\newcommand{\Xhij}{{X_{\rm hi}^{j}}}
\newcommand{\Xloj}{{X_{\rm lo}^{j}}}

\newcommand{\Xhini}{{X_{\rm hi}^{n, i}}}
\newcommand{\Xloni}{{X_{\rm lo}^{n, i}}}

\newcommand{\Sigmahi}{{\Sigma_{\rm hi}}}
\newcommand{\Sigmalo}{{\Sigma_{\rm lo}}}

\newcommand{\sigmahi}{{\sigma_{\rm hi}}}
\newcommand{\sigmalo}{{\sigma_{\rm lo}}}

\newcommand{\Gammahi}{{\Gamma_{\rm hi}}}
\newcommand{\Gammalo}{{\Gamma_{\rm lo}}}

\newcommand{\calShi}{{\calS_{\rm hi}}}
\newcommand{\calSlo}{{\calS_{\rm lo}}}

\newcommand{\ShiMnot}{{S_{\text{hi}}^{M_0}}}
\newcommand{\SloMnot}{{S_{\text{lo}}^{M_0}}}
\newcommand{\SloM}{{S_{\text{lo}}^{M}}}

\newcommand{\Sigmahihat}{{\hat{\Sigma}_{\text{hi}}}}
\newcommand{\Sigmalohat}{{\hat{\Sigma}_{\text{lo}}}}

\newcommand{\SloOne}{{S^1_{\text{lo}}}}
\newcommand{\SloTwo}{{S^2_{\text{lo}}}}

\newcommand{\Slon}{{S^n_{\text{lo}}}}
\newcommand{\Shin}{{S^n_{\text{hi}}}}

\newcommand{\kibitz}[2]{\textcolor{#1}{#2}}
\renewcommand{\aimee}[1]{\kibitz{violet}{[AM: #1]}}

\begin{document}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0.5em}


\section{Paper Outline}

\subsection{Introduction}

Covariance estimation broadly useful (examples of where, including but not limited to DA). Huge range of work, different regimes. Undersampled regime: zoo of regularization methods (shrinkage, sparsity, localization/tapering). 

Need for \textit{multi-fidelity} covariance estimation.

Interesting/unique challenges of this problem. Note previous work: lack of definiteness. Underlying issue: estimator does not respect geometry of the underlying parameter.

This paper---contributions:
\begin{itemize}
    \item Formulate MF covariance estimation as regression on the SPD manifold, according to the intrinsic geometry
    \item Discuss and demonstrate numerical solution of this problem. Good performance, etc.
    \item Show that our framework is an instance of a general approach to MF estimation in different geometries. Yields CV-type estimators, also regression-type estimators. 
\end{itemize}

Outline, briefly.


\subsection{Background} 
\begin{enumerate}
    \item SPD manifold
    \item Intrinsic statistics \aem{Definitions of mean, covariance. cf Pennec 2006.}
    \item Multifidelity estimation: basic idea and related previous work %
    \ymm{Only brief mention in intro, but main review here?} 
    
    \item Previous work on multivariate covariance estimation specifically (see refs from AM thesis)
        \begin{itemize}
        \item ML variance estimation (EQ) + other paper in AM thesis
        \item ML EnKF (Law et al.\ paper)
        \item MF EnKF (covariance of a control variate)
    \end{itemize}
\end{enumerate}

\subsection{Estimator Formulation}
\begin{enumerate}
    \item Bifidelity sampling setup (coupled pairs plus independent set) 
    \item $\bfS$ as a random variable 
    \item Riemannian covariance 
    \item Mahalanobis distance minimization 
    \item Resulting additive model on tangent space \aem{c.f. recent work on ``Exponential-Wrapped Distributions'' in SIMODS, Chevallier et al. 2022}
\end{enumerate}
\subsection{Analysis, Connections, Simplifications, etc.}
\begin{enumerate}
    \item Properties of Mahalanobis Distance 
        \begin{enumerate}
            \item Tangent-space agnostic 
            \item Affine-invariant 
        \end{enumerate}
    \item Fixed-$\Sigmalo$ simplification 
        \begin{enumerate}
            \item Nonlinear equation for $\Sigmahi$ 
            \item Analytical expected Mahalanobis distance 
        \end{enumerate}
    \item Multifidelity estimation in general geometries
    \begin{enumerate}
        \item Interpretation of fixed-$\Sigmalo$ estimator as control variates 
        \item Connection to other multifidelity estimators -- covariance (including our own) and otherwise  
        \item Best linear-in-tangent-space estimators? \aem{Holds in Euclidean setting for sure. Seems that it should in other geometries. Need to follow up}
    \end{enumerate}
\end{enumerate}

\subsection{Computational considerations}
\begin{enumerate}
    \item Square root parametrization (and why not manifold optimization) 
    \item Regularization in the intrinsic metric 
        \begin{enumerate}
            \item Enforces positive definiteness in square root parametrization 
            \item Regularization parameter in the fixed $\Sigmalo$ simplification can be picked by matching the mean objective function to $d(d+1)/2$
        \end{enumerate} 
\end{enumerate}
\subsection{Numerical Results}
\aimee{Whatever results we decide to include. e.g., }
\begin{enumerate}
    \item ``Cooked up'' Gaussian example (can get Euclidean estimator allocations and weight exactly)
    \item Elliptic PDE with various surrogate models for log-GP diffusivity: KL expansion and PCE (from 16.940). \aem{Will play with this in the coming month. This setting provides a sandbox for building low-fidelity models that are not simply coarser discretizations of the high-fidelity model.}
    \item Metric learning 
\end{enumerate}
\subsection{Conclusion} 



\end{document}
