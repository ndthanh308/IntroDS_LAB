\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems},
  33:1877--1901, 2020.

\bibitem{bulmahn2010pathfinder}
Jason Bulmahn.
\newblock {\em Pathfinder Roleplaying Game: Advanced Player's Guide}.
\newblock Paizo, 2010.

\bibitem{callison-burch-etal-2022-dungeons}
Chris Callison-Burch, Gaurav~Singh Tomar, Lara Martin, Daphne Ippolito, Suma
  Bailis, and David Reitter.
\newblock Dungeons and dragons as a dialog challenge for artificial
  intelligence.
\newblock In {\em Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 9379--9393, Abu Dhabi, United Arab
  Emirates, Dec. 2022. Association for Computational Linguistics.

\bibitem{sub_eval2}
Alexandra DeLucia, Aaron Mueller, Xiang~Lisa Li, and Jo{\~a}o Sedoc.
\newblock Decoding methods for neural narrative generation.
\newblock {\em arXiv preprint arXiv:2010.07375}, 2020.

\bibitem{dong2022survey}
Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun,
  Jingjing Xu, and Zhifang Sui.
\newblock A survey for in-context learning.
\newblock {\em arXiv preprint arXiv:2301.00234}, 2022.

\bibitem{gygax1974dungeons}
Gary Gygax and Dave Arneson.
\newblock {\em dungeons \& dragons}, volume~19.
\newblock Tactical Studies Rules Lake Geneva, WI, 1974.

\bibitem{hensley2008savage}
Shane~Lacy Hensley, Clint Black, et~al.
\newblock {\em Savage worlds}.
\newblock Studio 2 Publishing, 2008.

\bibitem{huang2022towards}
Jie Huang and Kevin Chen-Chuan Chang.
\newblock Towards reasoning in large language models: A survey.
\newblock {\em arXiv preprint arXiv:2212.10403}, 2022.

\bibitem{zero-shot-cot}
Takeshi Kojima, Shixiang~Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke
  Iwasawa.
\newblock Large language models are zero-shot reasoners.
\newblock {\em arXiv preprint arXiv:2205.11916}, 2022.

\bibitem{liang2022seeg}
Yuanzhi Liang, Qianyu Feng, Linchao Zhu, Li Hu, Pan Pan, and Yi Yang.
\newblock Seeg: Semantic energized co-speech gesture generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10473--10482, 2022.

\bibitem{llm_survey}
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and
  Graham Neubig.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting
  methods in natural language processing.
\newblock {\em ACM Computing Surveys}, 55(9):1--35, 2023.

\bibitem{liu2023training}
Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew~M Dai, Diyi
  Yang, and Soroush Vosoughi.
\newblock Training socially aligned language models in simulated human society.
\newblock {\em arXiv preprint arXiv:2305.16960}, 2023.

\bibitem{louis2018deep}
Annie Louis and Charles Sutton.
\newblock Deep dungeons and dragons: Learning character-action interactions
  from role-playing game transcripts.
\newblock In {\em Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 2 (Short Papers)}, pages 708--713, 2018.

\bibitem{lovecraft2016call}
Howard~Phillips Lovecraft.
\newblock {\em The call of Cthulhu}.
\newblock Lulu. com, 2016.

\bibitem{martin2018dungeons}
Lara~J Martin, Srijan Sood, and Mark~O Riedl.
\newblock Dungeons and dqns: Toward reinforcement learning agents that play
  tabletop roleplaying games.
\newblock In {\em INT/WICED@ AIIDE}, 2018.

\bibitem{newman-liu-2022-generating}
Pax Newman and Yudong Liu.
\newblock Generating descriptive and rules-adhering spells for dungeons {\&}
  dragons fifth edition.
\newblock In {\em Proceedings of the 9th Workshop on Games and Natural Language
  Processing within the 13th Language Resources and Evaluation Conference},
  pages 54--60, Marseille, France, June 2022. European Language Resources
  Association.

\bibitem{park2023generative}
Joon~Sung Park, Joseph~C O'Brien, Carrie~J Cai, Meredith~Ringel Morris, Percy
  Liang, and Michael~S Bernstein.
\newblock Generative agents: Interactive simulacra of human behavior.
\newblock {\em arXiv preprint arXiv:2304.03442}, 2023.

\bibitem{sub_eval1}
Manasvi Sagarkar, John Wieting, Lifu Tu, and Kevin Gimpel.
\newblock Quality signals in generated stories.
\newblock In {\em Proceedings of the Seventh Joint Conference on Lexical and
  Computational Semantics}, pages 192--202, 2018.

\bibitem{si-etal-2021-telling}
Wai~Man Si, Prithviraj Ammanabrolu, and Mark Riedl.
\newblock Telling stories through multi-user dialogue by modeling character
  relations.
\newblock In {\em Proceedings of the 22nd Annual Meeting of the Special
  Interest Group on Discourse and Dialogue}, pages 269--275, Singapore and
  Online, July 2021. Association for Computational Linguistics.

\bibitem{cot_self_consistency}
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou.
\newblock Self-consistency improves chain of thought reasoning in language
  models.
\newblock {\em arXiv preprint arXiv:2203.11171}, 2022.

\bibitem{wei2022chain}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc~V
  Le, Denny Zhou, et~al.
\newblock Chain-of-thought prompting elicits reasoning in large language
  models.
\newblock {\em Advances in Neural Information Processing Systems},
  35:24824--24837, 2022.

\bibitem{weir2022ontologically}
Nathaniel Weir, Ryan Thomas, Randolph D'Amore, Kellie Hill, Benjamin Van~Durme,
  and Harsh Jhamtani.
\newblock Ontologically faithful generation of non-player character dialogues.
\newblock {\em arXiv preprint arXiv:2212.10618}, 2022.

\bibitem{sub_eval3}
Pieter Wolfert, Nicole Robinson, and Tony Belpaeme.
\newblock A review of evaluation practices of gesture generation in embodied
  conversational agents.
\newblock {\em IEEE Transactions on Human-Machine Systems}, 52(3):379--389,
  2022.

\bibitem{zhao2023survey}
Wayne~Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,
  Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et~al.
\newblock A survey of large language models.
\newblock {\em arXiv preprint arXiv:2303.18223}, 2023.

\bibitem{gandalf}
Pei Zhou, Andrew Zhu, Jennifer Hu, Jay Pujara, Xiang Ren, Chris Callison-Burch,
  Yejin Choi, and Prithviraj Ammanabrolu.
\newblock An ai dungeon master's guide: Learning to converse and guide with
  intents and theory-of-mind in dungeons and dragons.
\newblock {\em arXiv preprint arXiv:2212.10060}, 2022.

\bibitem{zhu2023fireball}
Andrew Zhu, Karmanya Aggarwal, Alexander Feng, Lara~J Martin, and Chris
  Callison-Burch.
\newblock Fireball: A dataset of dungeons and dragons actual-play with
  structured game state information.
\newblock {\em arXiv preprint arXiv:2305.01528}, 2023.

\end{thebibliography}
