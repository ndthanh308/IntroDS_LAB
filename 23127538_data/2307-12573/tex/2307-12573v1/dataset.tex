\section{Multiple character and novel Object based interaction Estimation}


% Figure environment removed

\subsection{Task Overview}
%We propose a novel task called  Complex Contexts based intention Answering (C2A) that specifically challenges the ability of AI Agent to comprehend complex interaction within long contexts. As illustrated in Table~\ref{tab.data_eg1}, the input contexts consist of 11 turns involving intricate interactions among three players and an NPC. C2A requires methods to accurately determine the character who will act in the next turn and the corresponding actions. To be noticed, actions in TRPGs can be simpify and classified as various pre-defined skills. GMs need to guide the players to operate correct skill checks in every games, which leads all intended actions of players are intuitively annotated by GMs and recorded in the game log. This induces the game logs can naturally involve labeled character intentions and C2A can leverage the game logs to construct the intention understanding tasks with accurate intention labels. 

%Complex Interaction based Character Intention estimation (CIE) 

We introduce a novel task, Multiple character and novel Object based interaction Estimation (MOE), which presents a challenge to comprehend complex interactions within long contexts. The input contexts, illustrated in Fig.~\ref{fig:intro_moe}, involve 11 turns encompassing intricate interactions among three players and an NPC. In MOE task, the primary objective is to accurately determine the character who will act in the next turn and identify the corresponding actions. It is important to note that actions in Tabletop Role-Playing Games (TRPGs) can be simplified and classified as various pre-defined skills. Game Masters (GMs) play a crucial role in guiding players to perform correct skill checks during gameplay, resulting in GMs intuitively annotating all intended actions, which are recorded in the game log. As a result, the game logs naturally contain labeled character intentions, enabling MOE to leverage this data to construct intention understanding tasks with accurate intention labels.

Moreover, there are two primary challenges that need to be addressed in MOE. Both challenges requires the methods to provide higher understanding ability to the input interactions. 
The first challenge revolves around comprehending the behaviors and intentions of multiple characters in complex scenarios. As depicted in Fig.~\ref{fig:intro_moe}, the current game scenario involves four characters: the brown bear, Bill, Elvis Zem, and Maurice. While all characters interact with one another, only one player intends to perform an action and needs to undergo a skill check in the upcoming turn. In the first turn, Bill expresses his disinterest in engaging in the fight. Subsequently, Zem combines the electric spell with the sickle. Notably, the spell was cast in Turn 4 and its effects were explained by the GM in Turn 10. Thus, the spell's execution has already taken place and should not be reevaluated after Turn 10.
%The first challenge involves understanding the behaviors and inferring the intentions of multiple characters. As in Tab.~\ref{tab.data_eg1}, four characters are involved in the current game scenario: the brown bear, Bill, Elvis Zem, and Maurice. While all characters have movements and interact with others, only one player intend to operate the action and needs to perform a skill check at the next turn. Bill hinted that he does not want to engaged in the fight as in the first turn. Zem adds the electric spell to the sickle. Zem's spell was cast in Turn 4, and its effects were explained by the GM in Turn 10. The spell has already been executed and should not be checked again after Turn 10.
The second challenge is understanding the game rules and aligning them with the characters' movements. In Fig.~\ref{fig:intro_moe}, Maurice intends to escape from the bear's attack. However, there is no specific `escape' operation in the skill checks defined by the DND rules. Instead, the bear utilizes its strength to grapple Maurice in the game, and Maurice must also check their strength to contest against the bear. To answer this skill check, methods need to comprehend the intentions and movements of characters and, based on the game rules, infer the appropriate check items for the current turn, akin to a real-human.


% Figure environment removed






%We present Character and Skill check Answering (CSA), a new task that particular challenges the understanding ability for complex and grounded semantics in virtual GM generation. For instance, in Tab~\ref{tab.data_eg1}, the input contexts contain 11 turns with complex interactions with three players and a NPC. CSA requires the proposed method to answer who will act in the next turn and what kind of skill should be check for the action. In the given contexts, there are two challenges should be overcomes. 1. Understanding behaviours and inferring intentions of multiple characters. In Tab.~\ref{tab.data_eg1}, there are four characters in current game scenario, which are the brown bear, Bill, Elvis Zem, and Maurice. Though all the characters have movements and interact to others, only one player need to operate a skill check. Some characters are not involved in the fighting. Some others' movement have already operated and described by DM. For example, spell of Zem is performed in Turn4 and its effect has already described by DM in Turn10. Thus, the spell is a movement that already finished and should not be checked again in the next turn. 2. Understanding the game rules and matching to the characters' movements. In Tab.~\ref{tab.data_eg1}, Maurice wants to escape from the attack of the bear. However, there is no an escape operation in skill check of DND rules. In this case, the bear use its strength to grip Maurice in the game and Maurice also need to check strength to make a contest with the bear. To answer this skill check, methods need to understand the intention and movements of characters. Then, according to the rules of the games, inferring corresponding check items for current turn like a real-human DM. 

\subsection{Evaluation}
To provide a comprehensive assessment of context understanding in MOE, we evaluate the predicted character names and overall predictions separately. Specifically, we measure the average Character Precision (CP) and Character Recall (CR) for character names, as well as the average Skill Precision (SP) and Skill Recall (SR) for both character names and associated skills. Additionally, we compute the Character F-scores (CF) for character names and Skill F-score (SF) for both character names with associated skills.
\begin{align}
    \text{CP} & = \frac{1}{K} \sum_{i}^{K} t_c^i / p^i \\ 
    \text{CR} & = \frac{1}{K} \sum_{i}^{K} t_c^i / g^i \\ 
    \text{SP} & = \frac{1}{K} \sum_{i}^{K} t_s^i / p^i \\ 
    \text{SR} & = \frac{1}{K} \sum_{i}^{K} t_s^i / g^i \\ 
    \text{CF} & = 2 * \text{CP} * \text{CR} / (\text{CP} + \text{CR}) \\ 
    \text{SF} & = 2 * \text{SP} * \text{SR} / (\text{SP} + \text{SR}) 
\end{align}
where $i$ indicates the $i$-th sample, $t_c$ represent the number of correctly predicted character names, $t_s$ denote the number of correct predictions for both character names and associated skills, $p$ indicate the total number of predicted tuples, $g$ represent the number of answers in the ground truth, and $K$ represent the total number of evaluation data samples.

The metrics CP and CR are employed to evaluate the understanding of character intentions, focusing on the accuracy of predicting the characters about to take action. The proposed methods are required to provide correct character predictions, thereby achieving higher values for CP and CR. Then, to achieve higher SP and SR, the proposed methods must accurately comprehend both character intentions and the rules of the game. It is worth noting that if the model consistently predicts all characters as outputs, it may increase the recall but reduce the precision. Conversely, if the method tends to predict only one character, it may achieve higher precision but lower recall. To strike a balance between these factors, we employ F-scores as the final evaluation metrics in our experiments. The F-scores consider both precision and recall values, providing a comprehensive measure of the performance.

%CP and CR can reflect the understanding of the characters' intention, in which the proposed methods need to answer correct characters that about to initiate an action. Then, SP and SR further consider the game rule. To achieve a higher SP and SR, the proposed methods need to correctly understand both the intentions of character and the rules of games. Moreover, sometimes, if the model always predicts all characters as outputs, this may increase the value of recall but reduce the precision. Meanwhile, if the method tends to predict only one character, though may with higher precision, this induce lower recall values. To balance the two factors, we use F-scores as the final metrics in our experiments, which consider the values of both precision and recall.

% Figure environment removed

% Figure environment removed

\subsection{Skill Check Annotation}
In Tabletop Role-Playing Games (TRPGs), skill checks can directly indicate the players' intentions in the game, which play a crucial role in determining the success or failure of character actions. When a player wishes to have their character perform an action involving a skill, such as combat, persuasion, or searching for clues, the game models or rules provide a difficulty level or target number for the action. This difficulty level represents the challenge or desired level of success for the action. The Game Master (GM) assumes the responsibility of judging and guiding the player in performing the skill check based on the character's proficiency associated with the action. The GM then rolls a dice to determine the outcome.
In our task, we annotate the skill checks performed by players' characters during the games based on the semantic or recorded results provided by the GM. It is important to note that some skill checks are not predictable based solely on previous interactions. For example, in Call of Cthulhu (COC) games, perception checks may be prompted by the GM when players enter specific locations. These checks are closely tied to the game models and cannot be predicted in advance. Additionally, certain checks require additional calculations based on character attributes or cards, such as determining damage based on hit points or factoring in armor class to reduce damage. These calculations cannot be inferred solely from the game logs and we also remove these check in MOE.
Thus, we have excluded any checks that are unpredictable and included only those check items that can be inferred from the game logs. For example, the COC logs contain 61 check items (including skills and attributes) that can be verified, while the DND logs contain 25 such items. Further details regarding the check items will be provided in the supplementary material.

%In TRPG, skill check is an important mechanic used to determine the success or failure of a character's attempt to perform a specific action that requires a particular skill. If a player wants their character to perform a task that involves a skill, such as begin to fight, persuading an NPC, or find useful clues in current scenarios, there will be a difficulty level or target number for this task according the game models or rules. This difficulty level represents how challenging the action is or how high the odds of success should be. Then, DM is responsible to judge and guide the player to check this skill based on the character's proficiency associated with the action and roll a dice to determine the outcome. In our dataset, we annotate the skill checks for players' characters during the games according the semantic or recorded results by DM. Moreover, some skill check are hard to be inferred by previous interactions. For example, some perception checks in COC games will be offered by DM if the players have enter particular places. These checks are only related to the game models and can not be predicted before the guidance from DM. Moreover, some checks require additional calculation from the character cards (e.g., damage for current hit points, reduced damage due to armor class) and also can not be inferred merely by game logs. In MLG, we do not include any unpredictable checks and remain all check items that can be inferred by logs. In instant, there are 61 and 25 items (including skills and attributes) that can to be checked in COC and DND logs, respectively. Details for the check items will be shown in supplementary. 

\subsection{Context Excerpt}
Following the labeling of check items in the game logs, we proceed to excerpt relevant contexts associated with each check. Our selection of excerpted contexts is guided by three key principles to ensure the inclusion of long and diverse interactions.
First, we ensure that the excerpted contexts encompass complete events within the game, such as the entire process of encountering enemies or the detailed information and clues leading up to the exploration of certain locations. This ensures that the extracted contexts provide a comprehensive understanding of the events.
Second, we require that the excerpted contexts involve at least two characters who are present in the current scenarios of the game. This criterion allows for the examination of interactions between multiple characters, providing a more complex context for analysis.
Lastly, we ensure that at least one character within the excerpted contexts has a skill check that can be predicted. This principle guarantees that the selected contexts contain situations where skill checks can be inferred based on the information available up to the last turn.
By adhering to these principles, we ensure that the contexts support the understanding of the complex interactions and enable the inference of characters' intentions in subsequent turns.

%After labeling check items in the game logs, we excerpt related contexts to the check. To reserve long and diverse interactions, we excerpt contexts follows three principles: 1. The excerpted contexts should involve a complete event (e.g., the complete process of encountering enemies, the detailed information and clues before entering some places). 2. There should be at least two characters in current scenarios of the game. 3. At least one character should have predictable skill check. These principles ensure that the contexts in MLG support the understanding of multi-character interactions and can be used to infer skill check after the last turn. 

\subsection{Statistical Analysis}
We present the statistical results of answers in MOE in Tab.~\ref{tab.dataset_sta}. In total, we have extracted and labeled 1,003 sets of contexts and corresponding skill checks, which serve as the input context and ground truth for our task. The average number of turns in our dataset is 32.12, indicating its complexity compared to previous works that primarily focused on single-turn responses. %To facilitate evaluation with various Large Language Models (LLMs), we have also translated the logs into English, and the details of the translated version can be found in the supplementary material.
Furthermore, we provide the distributions of skill check labels of the Dungeons and Dragons (DND) logs in the MOE task, as illustrated in Fig.~\ref{fig.sc_sta} and Fig.~\ref{fig.sc_cnt_sta}. The number of characters involved in skill checks varies from 1 to 11, with an average of 1.696 characters per skill check. This reflects the complexity of multi-character interactions within our dataset, which close to the real-human communication in the games. Additionally, the items for skill checks exhibit diversity, highlighting the varied interactions between players. Both sets of statistical results underscore the value of our task as a comprehensive testbed for understanding complex interactions in TRPGs.

%We present some statistical results in Tab.~\ref{tab.dataset_sta}. In overall, we excerpt and label 1,003 sets of contexts and corresponding checks, which formulates as the input context and the ground truth of our QA task in the next section. The average turns in our dataset is 32.12, which is more complex than only 1 turn response in previous works. To better evaluate with various LLMs, we also translate the logs to English and the details for translated version is in supplementary.
%Moreover, the distributions of labels in DND logs of CSA are illustrated as in Fig.~\ref{fig.sc_sta} and Fig.~\ref{fig.sc_cnt_sta}. The number of characters for skill checks are variable from 1 to 11. The average number of characters is 1.696. This reflects the property of multi-character interaction in our dataset. Besides, items for skill check are diverse. This reveal the diversity of the interactions between players. Both statistic results can show the value of our dataset as a testbed for understanding multi-character interactions and grounded language. 


\section{Dataset}
To support our MOE task with more grounded and complex data, we have collect a new dataset. It is sourced from a Chinese TRPG forum\footnote{www.goddessfantasy.net}. This forum hosts a wide array of game records uploaded by users, spanning different rule systems e.g., DND, COC, PF, SW, etc. Unlike play-by-post forums~\cite{callison-burch-etal-2022-dungeons}, where players interact by writing and posting responses, the game logs in this forum are compiled and summarized by the Game Masters (GMs) after the game sessions\footnote{Most users whose logs are used in our study have agreed and provided their informed consent. We are trying to contact and communicate all users to be informed and agree with the participation of the research.}. Besides, in play-by-post scenarios, interactions between players are not immediate, and the feedback from the next player may not appear until several days or even weeks later. In contrast, the majority of game logs in our dataset are derived from instant messaging platforms, including voice and text communication. This characteristic allows for the capture of abundant immediate player responses, closely mirroring daily conversations with grounded language interactions. Consequently, our dataset provides more grounded semantics within real-time communication, making it conducive for exploring AI agents.

Statistically, our dataset comprises 95 sets of records from different games with various rule systems. It encompasses a total of 647,480 Chinese words, as indicated in Tab.~\ref{tab.dataset_sta}. In summary, our dataset not only surpasses previous works in terms of data diversity, groundedness, and complexity but also matches or exceeds their scale.

\begin{table}[t]
	\begin{center}
	\resizebox{0.55\columnwidth}{!}
    {
        \begin{tabular}{|l|l|l|}
        \hline
        Dataset    & \#words        & rules         \\ \hline \hline 
        DDD Corpus~\cite{louis2018deep} & $\sim$4,430,000                      & DND           \\ \hline
        PBP~\cite{callison-burch-etal-2022-dungeons}       & 58,187,526                          & DND           \\ \hline
        GANDALF~\cite{gandalf}    & $\sim$47,000                & DND           \\ \hline
        Ours        & 647,480                  & DND,COC,PF,SW \\ \hline
        \end{tabular}
    }
    \end{center}
    \caption{Dataset statistic. Our dataset exhibits a comparable scale to previous works, while also encompassing a higher diversity of game rules. }
    \label{tab.dataset_sta}
\end{table}

%To support our CSA task with more grounded and complex data, we collect a new dataset named Long-context Grounded-language TRPG Logs datase (LGL). LGL is collected from a Chinese TRPG forum (www.goddessfantasy.net)\footnote{Most users whose logs are used in our study have agreed and provided their informed consent. We are trying to contact and communicate all users to be informed and agree with the participation of the research.}. This forum contains various game records uploaded by users, which belongs to various rules, e.g., DND, COC, PF, SW, etc. Rather than play-by-post forums~\cite{callison-burch-etal-2022-dungeons}, these game logs are compiled and rephrased by the DM after the the game finish. In play-by-post, players write and post responses to a post to communicate each other. Though convenient, the interactions between players are not immediate. The feedback of the next players usually appears a few days even weeks later. Comparably, most game logs in LGL are recorded based on instant messages like voice or text communication. This leads logs in LGL contains abundant immediate responses of players and closer to the daily communication with grounded language interactions, which possess more diversity and complexity. In our work, we collect 95 sets of records in different games with various rules, which are more diverse than previous works. The overall contents contains 647,480 Chinese words as in Tab.~\ref{tab.dataset_sta}. Our dataset present more diversity, groundness and complexity than previous works and is also comparable in data scale.  





%We introduce a Multi-character Interactive TRPG game log dataset (MITD), which contains complex interaction of multiple characters within the long contexts. Our dataset is collected from a Chinese TRPG forum (www.goddessfantasy.net). This forum contains various game records uploaded by users, which belongs to various rules, e.g., DND, COC, PF, SW, etc. Rather than play-by-post forums, these game logs are compiled and rephrased by the GM or DM after the the game finish, which leads the data source possess more diversity and complexity for grounded language interactions. In our work, we collect 95 sets of records in different games with various rules. The overall contents contains 647,480 Chinese words as in~\ref{tab.dataset_sta}. In these logs, we find the original check items in every records, label the check items according the semantics, and capture all related context to this checks. 

%Specifically, to capture the related context, we follows two principles: 1. The captured context should involve a complete event (e.g., the complete process of encountering enemies, the detailed information and clues before entering some places). 2. There should be at least two characters in current scenarios of the game. These two principles ensure that the data in MITD possess long context and interactions between multiple characters. In statistic, the average turns in our dataset is 32.12, which is more complex than only 1 turn response in previous works. In overall, we label and select 1,003 sets of contexts and corresponding checks, which formulates as the input context and the ground truth of our QA task. 










