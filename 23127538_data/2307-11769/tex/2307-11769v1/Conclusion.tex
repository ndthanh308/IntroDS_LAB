\section{Conclusion}\label{sec:conclusion}

This paper presents our empirical domain knowledge distillation framework using ChatGPT and discusses our observations from the framework application experiments in the autonomous driving domain. The key finding is that: 1) with proper design of prompt engineering and execution flow, fully automated domain knowledge (in the ontology format) distillation is possible. However, due to the randomness in the response and the butterfly effect, the quality of fully automated distillation results is not guaranteed. To address this, we develop a web-based assistant to enable manual supervision and early intervention at runtime. We hope our findings and tools inspire future research toward revolutionizing the engineering processes of knowledge-based systems across domains.