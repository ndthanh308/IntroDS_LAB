\section{Distillation Framework Overview}\label{sec:methodology}

\subsection{Ontology 101}

The term \textit{Ontology} is defined as the description of domain \textbf{concepts} (often referred as \textbf{classes}, e.g., \textit{Car}, \textit{Lane}, \textit{Road}), the \textbf{properties} of the concepts (e.g., \textit{Color}, \textit{Size}, \textit{Length}), and the \textbf{relationships} (e.g., \textit{subclass\_of}, \textit{consists\_of}, \textit{drive\_on}) between the concepts. \cite{kendallOntologyEngineering}. The manual ontology construction process usually consists of the following steps (adapted from \cite{kendallOntologyEngineering,noy2001ontology}): 1) Define the application domain; 2) Define all the relevant classes; 3) Organize the classes in a superclass-subclass hierarchy; 4) Define the properties associated with each class; and 5) Define the relationships between each pair of classes.

In the next section, we present our empirical ontology distillation framework designed based on the required steps.

\subsection{Framework Overview}

% Figure environment removed

The LLMs such as ChatGPT\cite{chatGPT} work in a question-answer (or instruction-response) mechanism, which enables us to extract and format the knowledge via ``prompt engineering''. To make this empirical study beneficial to most of the public, we limit the model to the browser version of ChatGPT \cite{chatGPT}, with default generation settings (e.g., temperature \cite{openai_APT_temperature}, and numbers of tokens \cite{openai_APT_tokens}) but provides unlimited free-tier usage. Figure~\ref{fig:automation_framework} presents our empirical distillation framework, consisting of three main components, i.e., Task Workflow, Prompt Engineering, and Execution Loop.

\textbf{Prompt Engineering} When ``chatting'' with ChatGPT, the prompt template consists of three parts, i.e., domain context (why), task instruction (what), and response format (how). The domain context part introduces the background context for the subsequent requests, e.g., ``\textit{I have a road driving scenario ontology as shown below ...}''. The task instruction part instructs the LLM on what information is expected, e.g., ``\textit{Add 10 new relevant concepts, terms or entities to the ontology ...}''. Lastly, to facilitate the automated processing of the responses, the response format part specifies the machine-readable format, e.g., ``\textit{Output the new ontology in DOT format.}''. Note that DOT \cite{DOT_wiki_page} (a graph description language, examples can be found in Figure~\ref{fig:concept_hierarchy_extraction_example}) is used in this study to describe the ontology class hierarchy as it is widely supported by major programming languages. 

\textbf{Task Workflow} We start with a seed ontology of the application domain and go through a list of distillation tasks (i.e., concept/hierarchy distillation, concept definition distillation, concept relationship distillation, and concept property distillation), wherein each task we repeatedly request new knowledge from ChatGPT to augment and improve the ontology. The reasons for such a workflow design are as follows: 

1) During our preliminary concept-distillation experiments, ChatGPT returns a wide range of concepts, including highly relevant, irrelevant, and sometimes duplicated ones, during the looped execution. As discussed in \cite{schafer2023adaptive, pearce2022examining}, with more specific context information and good examples come improved semantic accuracy and more focused responses. Thus, we need to provide illustrative examples in the prompt to distil those highly relevant concepts while eliminating the rest. This is essential, especially for the first request, as subsequent responses highly depend on the previous results, i.e., the butterfly effect applies. As a result, we introduce the seed ontology in the first request consisting of only highly abstract concepts but still sufficient to focus the scope and demonstrate the basic ontology structure, e.g., superclass-subclass relationship, in the DOT format.

2) The basis of an ontology is formed by the concepts and the classification hierarchy (organized by the pairwise superclass-subclass relationships between concepts). As we keep updating the ontology hierarchy, the location of individual concepts in the hierarchy also changes, and so do their definitions, non-hierarchical relationships (e.g., the \textit{drive on} relationship in \textit{vehicles drive on roads}) and properties. As a result, the distillation tasks for the hierarchy-dependent knowledge are performed after the ontology hierarchy has been constructed and fixed. 

\textbf{Execution Loop} In each task, there is an execution loop consisting of prompt generation, response processing and ontology updating, which continues until any stopping criterion is met, e.g., ChatGPT stops presenting new information or the ontology graph has reached a pre-defined breadth or depth. If ChatGPT returns irrelevant or erroneous results, the execution loop can be paused, repeated, reverted or resumed manually at any step to ensure satisfactory distillation results. In each step, we start a new conversation with ChatGPT instead of using the existing conversation sessions. Such a looped execution mechanism is proposed for the following reasons: 

1) It is impractical to extract all the information with one request due to the limit on the maximum number of tokens \cite{openai_APT_tokens} and occasional browser connection timeout exceptions (ChatGPT slowly generating a large body of text may encounter timeout error) per request. 

2) As ChatGPT memorizes its previous requests and responses in the same conversation session, it may return similar undesirable responses as in the previous responses. Hence, we design the prompt schema to be self-sufficient and start a new conversation for each request to avoid such scenarios. 

3) The looped execution mechanism improves the distillation quality and lessens the bufferfly effect by enabling manual supervision and early optimization. For example, in each step of the concept/hierarchy distillation task, instead of asking ChatGPT only to append new concepts while preserving the existing hierarchy, we request it to re-design the hierarchy from scratch considering all the concepts, explicitly requesting it to remove irrelevant concepts and merge duplicated ones. Such a step-wise re-design allows ChatGPT to optimize the hierarchy globally.  

In the next section, we will cover the details of each element in the empirical distillation framework by demonstrating the application in the autonomous driving domain and discuss our key observations and challenges.