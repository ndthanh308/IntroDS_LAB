\section{Introduction}

Large language models (LLMs), such as GPT-3 \cite{brown2020language}, Codex \cite{chen2021evaluating}, and ChatGPT \cite{chatGPT} have made remarkable progress. Trained using an enormous amount of indiscriminate data from the entire internet, these LLMs embed knowledge from different domains, which are thus capable of answering questions, writing codes, drawing pictures, or translating languages across application areas \cite{vemprala2023chatgpt, pearce2022examining, schafer2023adaptive}. In this paper, we aim to investigate if and how the knowledge of a specific application domain, e,g., scenario-based testing of autonomous vehicles, can be extracted to facilitate subsequent tasks, e.g. automatic testing scenario generation.

Safety verification and validation (V\&V) of autonomous vehicles (AVs) are challenging due to the complexity of the AVs and their operating environment. Scenario-based testing of AVs \cite{zhong2021survey,tang2022survey} has been a new V\&V paradigm compared to distance-based approaches, where the performance of AVs is evaluated against the types of scenarios they pass instead of the countless miles they travel. 

Many scenario-generation methods have been proposed, e.g., \cite{tang2021route, tang2022automatic, zhou2023flyover, ding2022survey, tang2021collision, tang2021systematic}. However, those methods are mostly ``parameter samplers'' instead of ``scenario explorers'', meaning they are proposed to sample critical parameter values given a fixed list of scenario parameters toward their generation directions. Still, they cannot systematically explore different functional scenarios \cite{menzel2018scenarios}, e.g. different road networks, traffic actors, and their manoeuvres. Our recent work \cite{khastgir2021systems} applies \textit{Systems Theoretic Process Analysis} (STPA) to explore different scenario types at the functional scenario level; however, such a method requires ``domain knowledge'' and ``manual effort'' extensively and hence does not scale.

% Figure environment removed

Recently, to eliminate the ``manual effort'', combinatorial sampling-based methods are proposed to systematically generate different scenarios given a form of domain knowledge, e.g., either \textit{Operational Design Domain} (ODD) \cite{weissensteiner2023operational} or \textit{Ontology} \cite{bagschik2018ontology}.
The scenario ontology (Figure~\ref{fig:asam_openxOntology_example}) is a form of domain knowledge aiming to encapsulate all the relevant physical entities, their relationships, as well as their associated events and activities, which thus has the potential to generate any scenario. 
However, no approaches have been proposed to automatically ``distil'' such ``domain knowledge'' in any form from scratch for subsequent automation tasks, such as scenario generation, until it becomes feasible with the recent progress in Artificial General Intelligence (AGI) \newgeometry{top=0.75in,left=0.75in,right=0.75in,bottom=0.75in} such as ChatGPT \cite{chatGPT}. In this paper, we conduct an empirical study by ``chatting'' with ChatGPT and discuss our findings in constructing a driving scenario domain ontology. Our contributions are as follows: 
\begin{itemize}[leftmargin=*]
    \item We are the first, to the best of our knowledge, to propose an empirical automation and semi-automation framework for domain knowledge distillation with LLMs.
    \item We discuss our key observations and recommendations covering the entire distillation lifecycle in depth. 
    \item We present our web-based domain ontology distillation assistant to facilitate runtime human supervision, addressing the key challenges faced in the automatic ontology distillation experiment.
\end{itemize}

This paper is organized as follows: Section \ref{sec:methodology} presents an overview of our empirical distillation framework, Section \ref{sec:experiment} demonstrates the application of the framework in the autonomous driving domain and discusses our key observations based on the distillation results, Section \ref{sec:ui} presents our web-based distillation assistant and Section \ref{sec:conclusion} concludes the paper.