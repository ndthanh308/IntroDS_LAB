\begin{thebibliography}{57}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Baevski et~al.(2020)Baevski, Zhou, Mohamed, and Auli}]{baevski2020wav2vec}
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech representations.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:12449--12460.

\bibitem[{Chen et~al.(2022{\natexlab{a}})Chen, Zhou, Du, Lee, Chen, Watanabe, Siniscalchi, Scharenborg, Liu, Yin et~al.}]{chen2022first}
Hang Chen, Hengshun Zhou, Jun Du, Chin-Hui Lee, Jingdong Chen, Shinji Watanabe, Sabato~Marco Siniscalchi, Odette Scharenborg, Di-Yuan Liu, Bao-Cai Yin, et~al. 2022{\natexlab{a}}.
\newblock The first multimodal information based speech processing (misp) challenge: Data, tasks, baselines and results.
\newblock In \emph{ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 9266--9270. IEEE.

\bibitem[{Chen et~al.(2020{\natexlab{a}})Chen, Xie, Vedaldi, and Zisserman}]{chen2020vggsound}
Honglie Chen, Weidi Xie, Andrea Vedaldi, and Andrew Zisserman. 2020{\natexlab{a}}.
\newblock Vggsound: A large-scale audio-visual dataset.
\newblock In \emph{ICASSP}, pages 721--725. IEEE.

\bibitem[{Chen et~al.(2020{\natexlab{b}})Chen, Cui, Liu, Li, Kou, Xu, and Xu}]{chen2020talking}
Lele Chen, Guofeng Cui, Celong Liu, Zhong Li, Ziyi Kou, Yi~Xu, and Chenliang Xu. 2020{\natexlab{b}}.
\newblock Talking-head generation with rhythmic head motion.
\newblock In \emph{European Conference on Computer Vision}, pages 35--51. Springer.

\bibitem[{Chen et~al.(2022{\natexlab{b}})Chen, Wang, Chen, Wu, Liu, Chen, Li, Kanda, Yoshioka, Xiao et~al.}]{chen2022wavlm}
Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu~Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, et~al. 2022{\natexlab{b}}.
\newblock Wavlm: Large-scale self-supervised pre-training for full stack speech processing.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing}.

\bibitem[{Chrupa{\l}a(2022)}]{chrupala2022visually}
Grzegorz Chrupa{\l}a. 2022.
\newblock Visually grounded models of spoken language: A survey of datasets, architectures and evaluation techniques.
\newblock \emph{Journal of Artificial Intelligence Research}, 73:673--707.

\bibitem[{Cramer et~al.(2019)Cramer, Wu, Salamon, and Bello}]{cramer2019look}
Jason Cramer, Ho-Hsiang Wu, Justin Salamon, and Juan~Pablo Bello. 2019.
\newblock Look, listen, and learn more: Design choices for deep audio embeddings.
\newblock In \emph{ICASSP}, pages 3852--3856. IEEE.

\bibitem[{Cudeiro et~al.(2019)Cudeiro, Bolkart, Laidlaw, Ranjan, and Black}]{cudeiro2019capture}
Daniel Cudeiro, Timo Bolkart, Cassidy Laidlaw, Anurag Ranjan, and Michael~J Black. 2019.
\newblock Capture, learning, and synthesis of 3d speaking styles.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10101--10111.

\bibitem[{Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova}]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}.

\bibitem[{Drossos et~al.(2020)Drossos, Lipping, and Virtanen}]{Drossos_2020_icassp}
Konstantinos Drossos, Samuel Lipping, and Tuomas Virtanen. 2020.
\newblock \href {https://arxiv.org/abs/1910.09387} {Clotho: {An} audio captioning dataset}.
\newblock In \emph{ICASSP}.

\bibitem[{Fanzeres and Nadeu(2021)}]{s2i}
Leonardo~A Fanzeres and Climent Nadeu. 2021.
\newblock Sound-to-imagination: Unsupervised crossmodal translation using deep dense network architecture.
\newblock \emph{arXiv preprint arXiv:2106.01266}.

\bibitem[{Fei et~al.(2022)Fei, Lu, Gao, Yang, Huo, Wen, Lu, Song, Gao, Xiang et~al.}]{fei2022towards}
Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et~al. 2022.
\newblock Towards artificial general intelligence via a multimodal foundation model.
\newblock \emph{Nature Communications}, 13(1):1--13.

\bibitem[{Gemmeke et~al.(2017)Gemmeke, Ellis, Freedman, Jansen, Lawrence, Moore, Plakal, and Ritter}]{45857}
Jort~F. Gemmeke, Daniel P.~W. Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R.~Channing Moore, Manoj Plakal, and Marvin Ritter. 2017.
\newblock Audio set: An ontology and human-labeled dataset for audio events.
\newblock In \emph{Proc. IEEE ICASSP 2017}, New Orleans, LA.

\bibitem[{Girdhar et~al.(2023)Girdhar, El-Nouby, Liu, Singh, Alwala, Joulin, and Misra}]{girdhar2023imagebind}
Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan~Vasudev Alwala, Armand Joulin, and Ishan Misra. 2023.
\newblock \href {http://arxiv.org/abs/2305.05665} {Imagebind: One embedding space to bind them all}.

\bibitem[{Guzhov et~al.(2021)Guzhov, Raue, Hees, and Dengel}]{guzhov2021audioclip}
Andrey Guzhov, Federico Raue, J{\"o}rn Hees, and Andreas Dengel. 2021.
\newblock Audioclip: Extending clip to image, text and audio.
\newblock \emph{arXiv preprint arXiv:2106.13043}.

\bibitem[{He et~al.(2020)He, Fan, Wu, Xie, and Girshick}]{9157636}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2020.
\newblock \href {https://doi.org/10.1109/CVPR42600.2020.00975} {Momentum contrast for unsupervised visual representation learning}.
\newblock In \emph{2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 9726--9735.

\bibitem[{Hessel et~al.(2021)Hessel, Holtzman, Forbes, Le~Bras, and Choi}]{hessel2021clipscore}
Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le~Bras, and Yejin Choi. 2021.
\newblock Clipscore: A reference-free evaluation metric for image captioning.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing}, pages 7514--7528.

\bibitem[{Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and Mohamed}]{hsu2021hubert}
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung~Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed. 2021.
\newblock Hubert: Self-supervised speech representation learning by masked prediction of hidden units.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 29:3451--3460.

\bibitem[{Ilharco et~al.(2019)Ilharco, Zhang, and Baldridge}]{ilharco-etal-2019-large}
Gabriel Ilharco, Yuan Zhang, and Jason Baldridge. 2019.
\newblock \href {https://doi.org/10.18653/v1/K19-1006} {Large-scale representation learning from visually grounded untranscribed speech}.
\newblock In \emph{Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)}, pages 55--65, Hong Kong, China. Association for Computational Linguistics.

\bibitem[{Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and Duerig}]{jia2021scaling}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig. 2021.
\newblock Scaling up visual and vision-language representation learning with noisy text supervision.
\newblock In \emph{International Conference on Machine Learning}, pages 4904--4916. PMLR.

\bibitem[{Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei}]{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}.

\bibitem[{Karras et~al.(2017)Karras, Aila, Laine, Herva, and Lehtinen}]{karras2017audio}
Tero Karras, Timo Aila, Samuli Laine, Antti Herva, and Jaakko Lehtinen. 2017.
\newblock Audio-driven facial animation by joint end-to-end learning of pose and emotion.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 36(4):1--12.

\bibitem[{Kazakos et~al.(2021)Kazakos, Nagrani, Zisserman, and Damen}]{Kazakos2021SlowFastAuditory}
Evangelos Kazakos, Arsha Nagrani, Andrew Zisserman, and Dima Damen. 2021.
\newblock \href {https://doi.org/10.1109/ICASSP39728.2021.9413376} {Slow-fast auditory streams for audio recognition}.
\newblock In \emph{ICASSP}, pages 855--859.

\bibitem[{Lahiri et~al.(2021)Lahiri, Kwatra, Frueh, Lewis, and Bregler}]{lahiri2021lipsync3d}
Avisek Lahiri, Vivek Kwatra, Christian Frueh, John Lewis, and Chris Bregler. 2021.
\newblock Lipsync3d: Data-efficient learning of personalized 3d talking faces from video using pose and lighting normalization.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 2755--2764.

\bibitem[{Ma and Zhang(2015)}]{ma2015using}
Long Ma and Yanqing Zhang. 2015.
\newblock Using word2vec to process big text data.
\newblock In \emph{2015 IEEE International Conference on Big Data (Big Data)}, pages 2895--2897. IEEE.

\bibitem[{Mildenhall et~al.(2020)Mildenhall, Srinivasan, Tancik, Barron, Ramamoorthi, and Ng}]{mildenhall2020nerf}
Ben Mildenhall, Pratul~P. Srinivasan, Matthew Tancik, Jonathan~T. Barron, Ravi Ramamoorthi, and Ren Ng. 2020.
\newblock Nerf: Representing scenes as neural radiance fields for view synthesis.
\newblock In \emph{ECCV}.

\bibitem[{Oord et~al.(2018)Oord, Li, and Vinyals}]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals. 2018.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}.

\bibitem[{Pan et~al.(2022)Pan, Chen, Gong, Zhou, Wang, and Lin}]{pan-etal-2022-leveraging}
Xichen Pan, Peiyu Chen, Yichen Gong, Helong Zhou, Xinbing Wang, and Zhouhan Lin. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.acl-long.308} {Leveraging unimodal self-supervised learning for multimodal audio-visual speech recognition}.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 4491--4503, Dublin, Ireland. Association for Computational Linguistics.

\bibitem[{Pedersoli et~al.(2022)Pedersoli, Wiebe, Banitalebi, Zhang, and Yi}]{pedersoli2022estimating}
Fabrizio Pedersoli, Dryden Wiebe, Amin Banitalebi, Yong Zhang, and Kwang~Moo Yi. 2022.
\newblock Estimating visual information from audio through manifold learning.
\newblock \emph{arXiv preprint arXiv:2208.02337}.

\bibitem[{Piczak(2015)}]{piczak2015dataset}
Karol~J. Piczak. 2015.
\newblock \href {https://doi.org/10.1145/2733373.2806390} {{ESC}: {Dataset} for {Environmental Sound Classification}}.
\newblock In \emph{ACM Multimedia}, page 1015. {ACM Press}.

\bibitem[{Qiu and Kataoka(2018)}]{qiu2018image}
Yue Qiu and Hirokatsu Kataoka. 2018.
\newblock Image generation associated with music data.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops}, pages 2510--2513.

\bibitem[{Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin et~al.}]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, et~al. 2021.
\newblock Learning transferable visual models from natural language supervision.
\newblock \emph{ICML}.

\bibitem[{Richard et~al.(2021)Richard, Zollh{\"o}fer, Wen, De~la Torre, and Sheikh}]{richard2021meshtalk}
Alexander Richard, Michael Zollh{\"o}fer, Yandong Wen, Fernando De~la Torre, and Yaser Sheikh. 2021.
\newblock Meshtalk: 3d face animation from speech using cross-modality disentanglement.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 1173--1182.

\bibitem[{Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer}]{Rombach_2022_CVPR}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\"orn Ommer. 2022.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 10684--10695.

\bibitem[{Saharia et~al.(2022{\natexlab{a}})Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, Ho, Fleet, and Norouzi}]{NEURIPS2022_ec795aea}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, Jonathan Ho, David~J Fleet, and Mohammad Norouzi. 2022{\natexlab{a}}.
\newblock \href {https://proceedings.neurips.cc/paper_files/paper/2022/file/ec795aeadae0b7d230fa35cbaf04c041-Paper-Conference.pdf} {Photorealistic text-to-image diffusion models with deep language understanding}.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~35, pages 36479--36494. Curran Associates, Inc.

\bibitem[{Saharia et~al.(2022{\natexlab{b}})Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans et~al.}]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al. 2022{\natexlab{b}}.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:36479--36494.

\bibitem[{Salamon et~al.(2014)Salamon, Jacoby, and Bello}]{Salamon:UrbanSound:ACMMM:14}
J.~Salamon, C.~Jacoby, and J.~P. Bello. 2014.
\newblock A dataset and taxonomy for urban sound research.
\newblock In \emph{ACM Multimedia}, pages 1041--1044, Orlando, FL, USA.

\bibitem[{Song et~al.(2022)Song, Wu, Qian, He, and Loy}]{song2022everybody}
Linsen Song, Wayne Wu, Chen Qian, Ran He, and Chen~Change Loy. 2022.
\newblock Everybody’s talkin’: Let me talk as you want.
\newblock \emph{IEEE Transactions on Information Forensics and Security}, 17:585--598.

\bibitem[{Song et~al.(2021)Song, Liu, Yin, Dong, Zhang, and Bai}]{song2021tacr}
Luchuan Song, Bin Liu, Guojun Yin, Xiaoyi Dong, Yufei Zhang, and Jia-Xuan Bai. 2021.
\newblock Tacr-net: Editing on deep video and voice portraits.
\newblock In \emph{Proceedings of the 29th ACM International Conference on Multimedia}, pages 478--486.

\bibitem[{Song et~al.(2023)Song, Dhariwal, Chen, and Sutskever}]{song2023consistency}
Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. 2023.
\newblock \href {http://arxiv.org/abs/2303.01469} {Consistency models}.

\bibitem[{Sung-Bin et~al.(2023)Sung-Bin, Senocak, Ha, Owens, and Oh}]{sungbin2023sound}
Kim Sung-Bin, Arda Senocak, Hyunwoo Ha, Andrew Owens, and Tae-Hyun Oh. 2023.
\newblock \href {http://arxiv.org/abs/2303.17490} {Sound to visual scene generation by audio-to-visual latent alignment}.

\bibitem[{Tan and Le(2019)}]{tan2019efficientnet}
Mingxing Tan and Quoc Le. 2019.
\newblock Efficientnet: Rethinking model scaling for convolutional neural networks.
\newblock In \emph{International conference on machine learning}, pages 6105--6114. PMLR.

\bibitem[{Thies et~al.(2020)Thies, Elgharib, Tewari, Theobalt, and Nie{\ss}ner}]{thies2020neural}
Justus Thies, Mohamed Elgharib, Ayush Tewari, Christian Theobalt, and Matthias Nie{\ss}ner. 2020.
\newblock Neural voice puppetry: Audio-driven facial reenactment.
\newblock In \emph{European conference on computer vision}, pages 716--731. Springer.

\bibitem[{Turpault et~al.(2019)Turpault, Serizel, Parag~Shah, and Salamon}]{Turpault2019_DCASE}
Nicolas Turpault, Romain Serizel, Ankit Parag~Shah, and Justin Salamon. 2019.
\newblock \href {https://hal.inria.fr/hal-02160855} {{Sound event detection in domestic environments with weakly labeled data and soundscape synthesis}}.
\newblock In \emph{{DCASE}}, New York City, United States.

\bibitem[{Wan et~al.(2019)Wan, Chuang, and Lee}]{8682383}
Chia-Hung Wan, Shun-Po Chuang, and Hung-Yi Lee. 2019.
\newblock \href {https://doi.org/10.1109/ICASSP.2019.8682383} {Towards audio to scene image synthesis using generative adversarial network}.
\newblock In \emph{ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 496--500.

\bibitem[{Wang et~al.(2022)Wang, Bao, Dong, Bjorck, Peng, Liu, Aggarwal, Mohammed, Singhal, Som et~al.}]{wang2022image}
Wenhui Wang, Hangbo Bao, Li~Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais~Khan Mohammed, Saksham Singhal, Subhojit Som, et~al. 2022.
\newblock Image as a foreign language: Beit pretraining for all vision and vision-language tasks.
\newblock \emph{arXiv preprint arXiv:2208.10442}.

\bibitem[{Wen et~al.(2020)Wen, Wang, Richardt, Chen, and Hu}]{wen2020photorealistic}
Xin Wen, Miao Wang, Christian Richardt, Ze-Yin Chen, and Shi-Min Hu. 2020.
\newblock Photorealistic audio-driven video portraits.
\newblock \emph{IEEE Transactions on Visualization and Computer Graphics}, 26(12):3457--3466.

\bibitem[{Wu et~al.(2021)Wu, Jia, Wang, Dou, Duan, and Deng}]{wu2021imitating}
Haozhe Wu, Jia Jia, Haoyu Wang, Yishun Dou, Chao Duan, and Qingshan Deng. 2021.
\newblock Imitating arbitrary talking style for realistic audio-driven talking face synthesis.
\newblock In \emph{Proceedings of the 29th ACM International Conference on Multimedia}, pages 1478--1486.

\bibitem[{Wu et~al.(2022)Wu, Seetharaman, Kumar, and Bello}]{wu2022wav2clip}
Ho-Hsiang Wu, Prem Seetharaman, Kundan Kumar, and Juan~Pablo Bello. 2022.
\newblock Wav2clip: Learning robust audio representations from clip.
\newblock In \emph{ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 4563--4567. IEEE.

\bibitem[{Xu et~al.(2018)Xu, Zhang, Huang, Zhang, Gan, Huang, and He}]{xu2018attngan}
Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and Xiaodong He. 2018.
\newblock Attngan: Fine-grained text to image generation with attentional generative adversarial networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 1316--1324.

\bibitem[{Yi et~al.(2020)Yi, Ye, Zhang, Bao, and Liu}]{yi2020audio}
Ran Yi, Zipeng Ye, Juyong Zhang, Hujun Bao, and Yong-Jin Liu. 2020.
\newblock Audio-driven talking face video generation with learning-based personalized head pose.
\newblock \emph{arXiv preprint arXiv:2002.10137}.

\bibitem[{Zhang et~al.(2021{\natexlab{a}})Zhang, Ni, Fan, Li, Zeng, Budagavi, and Guo}]{zhang20213d}
Chenxu Zhang, Saifeng Ni, Zhipeng Fan, Hongbo Li, Ming Zeng, Madhukar Budagavi, and Xiaohu Guo. 2021{\natexlab{a}}.
\newblock 3d talking face with personalized pose dynamics.
\newblock \emph{IEEE Transactions on Visualization and Computer Graphics}.

\bibitem[{Zhang et~al.(2021{\natexlab{b}})Zhang, Zhao, Huang, Zeng, Ni, Budagavi, and Guo}]{zhang2021facial}
Chenxu Zhang, Yifan Zhao, Yifei Huang, Ming Zeng, Saifeng Ni, Madhukar Budagavi, and Xiaohu Guo. 2021{\natexlab{b}}.
\newblock Facial: Synthesizing dynamic talking face with implicit attribute learning.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 3867--3876.

\bibitem[{Zhang et~al.(2021{\natexlab{c}})Zhang, Li, Ding, and Fan}]{zhang2021flow}
Zhimeng Zhang, Lincheng Li, Yu~Ding, and Changjie Fan. 2021{\natexlab{c}}.
\newblock Flow-guided one-shot talking face generation with a high-resolution audio-visual dataset.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3661--3670.

\bibitem[{Zhang et~al.(2023)Zhang, Chen, Zhou, Wu, Ren, Liu, Yao, Gong, Dai, Li, and Wei}]{zhang2023speechlm}
Ziqiang Zhang, Sanyuan Chen, Long Zhou, Yu~Wu, Shuo Ren, Shujie Liu, Zhuoyuan Yao, Xun Gong, Lirong Dai, Jinyu Li, and Furu Wei. 2023.
\newblock \href {http://arxiv.org/abs/2209.15329} {Speechlm: Enhanced speech pre-training with unpaired textual data}.

\bibitem[{Zhou et~al.(2018)Zhou, Wang, Fang, Bui, and Berg}]{vegas}
Yipin Zhou, Zhaowen Wang, Chen Fang, Trung Bui, and Tamara~L Berg. 2018.
\newblock Visual to sound: Generating natural sound for videos in the wild.
\newblock In \emph{CVPR}.

\bibitem[{Zhu et~al.(2021)Zhu, Luo, Wang, Zheng, and He}]{zhu2021deep}
Hao Zhu, Man-Di Luo, Rui Wang, Ai-Hua Zheng, and Ran He. 2021.
\newblock Deep audio-visual learning: A survey.
\newblock \emph{International Journal of Automation and Computing}, 18(3):351--376.

\end{thebibliography}
