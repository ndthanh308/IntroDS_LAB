\section{Introduction}
Digital signal theory is an extension of the analysis of continuous signals.
This extension is provided by discretization and sampling \cite{bracewell2000fourier}.
The sampling of signals can be mathematically described by a series of Dirac impulses \cite{bracewell2000fourier} and is well known.
Properties of the Dirac impulse, such as sampling, are derived in distribution theory \cite{grubb2008distributions} \cite{strichartz2003guide}.
The theory generalizes differential calculus to functions that are not differentiable in the classical sense such as the Heaviside step function.
Therefore, distribution theory allows one to adopt analog analysis concepts to digital signals.

The performance of computing systems is often modeled by automata as presented in the domain of model checking \cite{clarke1997model} or in queuing theory \cite{shortle2018fundamentals} of computer networks. 
Other approaches such as network \cite{le2001network} and real-time calculus \cite{thiele2000real} are working on stepwise, monotone and linear functions. Both models are abstract.
In our opinion, a clear mathematical concept to compute arbitrary event occurrences in real-time analysis is missing.

In this report, we extend the concept of Dirac combs, a series of Dirac impulses as known from signal theory, to performance analysis of computers. 
The goal is to connect methods from electrical engineering or physics to different models of computation such as graphs, and network as well as real-time calculus.

Our goal is to build the mathematical foundation on an extended algebra and calculus of impulses that we call the Shirac (\underline{Shi}fted Di\underline{rac}) algebra. To this end, we develop a linear space of any combination of digital signals, messages or performance requests.
The idea is that it should be possible to compute on any kind of combination of execution traces before they are being analyzed.
This means complicated message patterns as known from networking or real-time system analysis can be mathematically constructed by combinations of simple elements.

Such an approach enables a general performance analysis of computing systems.
The main advantage of this work is that we only need operations already known by every engineer from their mathematics courses known as linear algebra and calculus.

We first give a short introduction to distributions and the concept to compute with them, in Section \ref{section:distributiontheory}. 
Based on this foundation, we prove the linear space of traces or impulses, in Section \ref{section:impulsespace}, and provide a list of symbols in Table \ref{table:listofsymbols}. 
Lastly, we present a calculus of the linear space in Section \ref{section:operations}.
The goal of the report is to build a base of this theory which can be later used by computer science applications.


%\section{Introduction}
%This report presents a linear algebra and calculus of the Dirac impulse distribution \footnote{Despite of being a distribution, we adopt the convention of the literature to call the Dirac impulse a function.}. 
%The Dirac impulse was initially presented by Paul Dirac \cite{dirac1981principles} and its mathematical background is discussed in distribution theory \cite{grubb2008distributions} \cite{strichartz2003guide}.
%The goal is to generalize differential calculus to functions that are not differentiable in the classical sense such as the Heaviside step function.
%More precisely, functions are generalized to so-called distributions. The space of distributions is known to be the dual vector space of the vector space of test functions \cite{grubb2008distributions}.
%Therefore, it may be the case that the subspace of Dirac impulse distributions is a vector subspace of this vector space.
%To the best of our knowledge, there does not exist any literature showing that the subspace of Dirac impulses is a vector space.
%As the Dirac impulse is a fundamental model to describe any digital signal, we prove in this report its vector space properties and solve an extreme value problem with respect to the density of Dirac impulses.
%It is usually applied in digital signal theory \cite{bracewell2000fourier} to describe a sequence of periodic events
%\begin{equation}
%	\Sh_{p}(t) = \sum_{n = -\infty}^{\infty} \diracdelta(t - np)
%\end{equation}
%occurring at $np$ which is known as the Dirac comb. 
%One application of the Dirac comb $\Sh_{p}(t)$ is the representation of sampling in e.g. an analog-to-digital converter where a continuous signal is digitalized with a sampling rate of $1/p$. 
%Those digital signals that are e.g. inputs to computer programs may be described by a combination of Dirac combs. 
%
%For example, consider a sequence of $N$ messages that is periodically sent over a network with period $p \in \positivrealnumbers$ and each message is divided into $M \in \naturalnumbers$ packets that are sent in a burst of period $q$. If the first message is sent at time point $0$, this means a burst of $M$ packets is sent at time points $0, q, 2q, \dots, (M-1)q$. Then, the second message is sent at time point $p$, so that the burst of packets is sent at $p, p + q, p + 2q, \dots, p + (M-1)q$. This means the periodic message generates a burst of packets where the burst is itself a periodic signal, i.e. we have a nested periodic signal. This timing pattern can be described by a convolution of Dirac combs
%\begin{alignat}{1}
%	(\Sh_{p} \ast \Sh_{q})(t) = \sum_{n = 1}^{N}\sum_{m = 1}^{M}  \diracdelta(t - (n-1)p - (m-1)q)
%\end{alignat}
%In this report, we present a model that can describe and compute any combination of Dirac combs.
%The idea is to define a vector space of Dirac impulses, so that any digital signal can be described by a linear combination of Dirac combs, called a Dirac density.
%The advantage of this algebraic approach is the closure of its operations.
%More precisely, closure means that any combination of Dirac densities constructs again a new Dirac density.
%This means a calculus defined on an arbitrary vector of this space is applicable to any Dirac density.
%
%This report is organized in three sections.
%We provide a background on distribution theory in Section \ref{section:distributiontheory}.
%Then, we present the vector space of Dirac combs in Section \ref{section:impulsespace}.
%Lastly, we present a calculus for the vector space in Section \ref{section:operations}.
%A list of symbols for the algebra is given in Table \ref{table:listofsymbols}.
%\renewcommand{\arraystretch}{1.3}
%\renewcommand{\cellalign}{cl}
%\begin{table}
%	\begin{center}
%		\begin{tabular}{l  l } 
%			Symbol & Meaning  \\ [0.5ex] 
%			\hline\hline
%			$\naturalnumbers$, $\naturalnumberswithzero$,$\naturalnumbersuntil{n}$
%			&
%			\makecell{set of natural numbers, natural numbers with zero, \\ natural numbers $\{1,2,\dots n\}$}
%			\\
%			\hline
%			$\realnumbers, \realnumbersvector{n}$
%			&
%			set of real numbers, $n$-dimensional vectors
%			\\
%			\hline
%			\impulseshift 
%			&
%			shift
%			\\
%			\hline
%			$\amplitude $
%			&
%			amplitude
%			\\
%			\hline
%			$\impulsedegree $
%			&
%			degree
%			\\
%			\hline
%			$\shiftedimpulse{\impulseindex}{\impulsevariable}$ 
%			&
%			\makecell{Dirac impulse function $\diracdelta(\impulsevariable - \impulseindex s)$ of variable $\impulsevariable$ \\ shifted by $\impulseindex \cdot s$}
%			\\ 
%			\hline
%			$\shiftedimpulseset{\impulsevariable}$ & set of all shifted Dirac impulse functions of variable $\impulsevariable$  \\
%			\hline
%			$\impulsegroupoperation$ &  addition operator on two impulse functions \\
%			\hline
%			$\impulsegroup{\impulsevariable}  = (\shiftedimpulseset{\impulsevariable}, \impulsegroupoperation)$ &  abelian group of impulse functions $\shiftedimpulseset{\impulsevariable}$ and group operation $\impulsegroupoperation$ \\
%			\hline
%			$\impulsespectralspacemult$ &  multiplication operator on a real number and an impulse function \\
%			\hline
%			$\impulsespectralspace{\impulsevariable} =  (\shiftedimpulseset{\impulsevariable}, \impulsegroupoperation, \impulsespectralspacemult) $& \makecell{\impulsespectralspacename{} with vector addition $\impulsegroupoperation$ \\ and scalar multiplication $\impulsespectralspacemult$ } \\
%			\hline
%			$\impulsespectraltrain{\impulseshift}{\impulsedegree}{\impulsevariable}$
%			&
%			\makecell{		\impulsespectraltrainname{} (\impulsespectraltrainshort): series of impulse functions \\ where each is impulse is multiplied an amplitude $\amplitude$}
%			\\
%			\hline
%			$\impulsespectraldensity{\impulseshift}{\impulsedegree}{\impulsevariable}$ & \impulsespectraldensityname{} (\impulsespectraldensitynameshort): convolution of $\impulseinterferencedegreetwo \in \naturalnumbers$ \impulsespectraltrainshort s
%			\\
%			\hline
%			$\impulseinterference{\impulseshift}{\impulsedegree}{\impulsevariable}$
%			&
%			\impulseinterferencename{} (\impulseinterferencenameshort): series of $\impulseinterferencedegreeone \in \naturalnumbers$ \impulsespectraldensitynameshort s
%			\\
%			\hline
%			$\amplitudematrix$, 
%			$\amplitudematrixentry{\impulseindex}{\impulseinterferenceindexone}{\impulseinterferenceindextwo}$
%			&
%			\amplitudematrixname,
%			\amplitudevectorname{} at matrix entry $(\impulseinterferenceindexone, \impulseinterferenceindextwo)$
%			\\
%			\hline 
%			$\shiftmatrix{\impulseindex}{\impulsevariable}$,
%			$\shiftmatrixentry{\impulseindex}{\impulsevariable}{\impulseinterferenceindexone}{\impulseinterferenceindextwo} $
%			&
%			\shiftmatrixname{}, 
%			\shiftvectorname{} at matrix entry $(\impulseinterferenceindexone, \impulseinterferenceindextwo)$
%			\\
%			\hline
%			$\amplitudematrixentry{\impulseindex}{\impulseinterferenceindexone}{\impulseinterferenceindextwo} \matrixdotproduct 
%			\shiftmatrixentry{\impulseindex}{\impulsevariable}{\impulseinterferenceindexone}{\impulseinterferenceindextwo} $
%			&
%			\dotproductname{} of an \amplitudevectorname{} and an \shiftvectorname{}
%			\\
%			\hline
%			$\amplitudematrix \matrixdotproduct  \shiftmatrix{\impulseindex}{\impulsevariable}$
%			&
%			\matrixdotproductname{} 
%			\\
%			\hline
%			$\impulsespectraldensityeinsteinmono{\amplitude}{\impulseindex}{\impulseshift}{\impulsevariable}$
%			&
%			\impulsespectraltrainshort{} in Einstein notation
%			\\
%			\hline
%			$\impulsespectraldensityeinsteinmulti{\amplitude}{\impulseindex}{\impulseshift}{\impulsevariable}$
%			&
%			\impulsespectraldensitynameshort{} in Einstein notation
%			\\
%			\hline
%			$\innerconvolution{}{}$
%			&
%			\makecell{\innerconvolutionname{} that convolves \\ the  columns of the two input matrices}
%			\\
%			\hline
%			$\innerconvolution{\amplitudematrix}{\shiftmatrix{\degreevector}{\impulsevariable} }$
%			&
%			\makecell{\impulseconvolutionvectorname{} resulting from the \\ \innerconvolutionname{} of the \amplitudematrixname{} \\ and the \shiftmatrixname{}}
%			\\
%			\hline 
%			$\impulsespectralinterferenceeinstein{\amplitudematrix \matrixdotproduct \shiftmatrix{\impulsedegree}{\impulsevariable}}$
%			&
%			\impulseinterferencenameshort{} as a result of the dot product $\innerconvolution{\amplitudematrix}{\shiftmatrix{\degreevector}{\impulsevariable} } \cdot \boldsymbol{1}$
%			\\
%			\hline
%			$	\amplitudevector{\impulseindex_{\impulseinterferenceindexone,1} \dots \impulseindex_{\impulseinterferenceindexone,\multiperiodicimpulsedimension}} \overline{| \langle \phasevectorcomponent{\impulseindex_{\impulseinterferenceindexone,1}} \dots \phasevectorcomponent{\impulseindex_{\impulseinterferenceindexone,\multiperiodicimpulsedimension}} \rangle  |}_{a,b}$
%			&
%			\makecell{	\heavisidedurationname{}: sum of amplitudes of \\ shifted impulse functions in the interval from a to b}
%			\\
%			\hline
%			$\heavisideduration{\Sh}{a,b}{} $
%			&
%			short-form of \heavisidedurationname
%			\\
%			\hline
%			\makecell{$\heavisidedurationupperupper{\Sh}{a, b}{}$, $\heavisidedurationupperlower{\Sh}{a, b}{}$ \\ 				$\heavisidedurationlowerupper{\Sh}{a, b}{}$}
%			&
%			\heavisidedurationname{} of the interval $[a,b]$,$[a,b)$,$(a,b]$
%			\\
%			\hline
%			$\heavisideduration{\Sh}{\intervalduration}{+} $, $\heavisideduration{\Sh}{\intervalduration}{-} $
%			&
%			\maximumheavisidedurationname{} and \minimumheavisidedurationname{}
%			\\
%			\hline
%			\makecell{$\heavisidedurationupperupper{\Sh}{\intervalduration}{+} $, 				$\heavisidedurationupperlower{\Sh}{\intervalduration}{+} $, 	\\			$\heavisidedurationlowerupper{\Sh}{\intervalduration}{+} $}
%			&
%			\makecell{\maximumheavisidedurationname{} of all intervals $[\impulsevariable, \impulsevariable +\intervalduration]$, \\ $[\impulsevariable, \impulsevariable +\intervalduration)$, $(\impulsevariable, \impulsevariable +\intervalduration]$, $\impulsevariable \in \realnumbers$}
%			\\
%			\hline
%			\makecell{$\heavisidedurationupperupper{\Sh}{\intervalduration}{-} $, $\heavisidedurationupperlower{\Sh}{\intervalduration}{-} $, \\ $\heavisidedurationlowerupper{\Sh}{\intervalduration}{-} $}
%			&
%			\makecell{\minimumheavisidedurationname{} of all intervals $[\impulsevariable, \impulsevariable +\intervalduration]$, \\ $[\impulsevariable, \impulsevariable +\intervalduration)$, $(\impulsevariable, \impulsevariable +\intervalduration]$ $\impulsevariable \in \realnumbers$}
%		\end{tabular}
%	\end{center}
%	\caption{List of symbols}
%	\label{table:listofsymbols}
%\end{table}

\section{Distribution theory}\label{section:distributiontheory}
% Figure environment removed
As we use results of distribution theory in our proofs we give a short-hand introduction to distributions. A complete view to the theory can be found in \cite{grubb2008distributions} and  \cite{strichartz2003guide}.
%\begin{definition}[Interior of a set \cite{luenberger1997optimization}]\label{def:interior}
%	Let $\Omega \subseteq \realnumbersvector{n}$ be a set and $\epsilon > 0$. A point $x \in \Omega$ is called an \textbf{interior point} of $\Omega$ if all $y \in \realnumbersvector{n}$ satisfying the inequality $||x - y || < \epsilon$ are also members of $\Omega$ \footnote{The function $|| \cdot ||$ is the euclidian distance in $\realnumbersvector{n}$.}. 
%	The set of all interior points of $\Omega$ is called the \textbf{interior} of $\Omega$ and denoted $\mathring{\Omega}$.
%\end{definition}
%\begin{definition}[Open set \cite{luenberger1997optimization}]\label{def:openset}
%	A set $\Omega$ is said to be open if $\Omega = \mathring{\Omega}$.
%\end{definition}
% \begin{definition}[Closure of a set \cite{luenberger1997optimization}]\label{def:closure}
% 	A point $y \in \realnumbersvector{n}$ is a \textbf{closure point} of $\Omega \subseteq \realnumbersvector{n}$ if for some $\epsilon > 0$, there exists a point $x \in \Omega$ satisfying $|| x - y || < \epsilon$. The set of all closure points of $\Omega$ is the \textbf{closure} of $\Omega$ and denoted by $\overline{\Omega}$.
% \end{definition}
%\begin{definition}[Boundary of a set]\label{def:boundary}
%	The set $\operatorname{Bd}_{\realnumbersvector{n}} \, \Omega = \overline{\Omega} \setminus \mathring{\Omega}$ is the \textbf{boundary} of $\Omega$.
%\end{definition}
%The interior, closure and boundary of an open set are depicted in Figure \ref{fig:openset}.
%% Figure environment removed
\begin{definition}[Notation for function sets \cite{grubb2008distributions}]
	Let $\Omega \subseteq \realnumbers^{n}$ be an open subset of $\realnumbersvector{n}$. 
	The spaces of continuous, continuously differentiable, $n$-times continuously differentiable and infinitely continuous differentiable functions on $\Omega$ are respectively denoted by $C(\Omega)$, $C^{1}(\Omega)$, $C^{n}(\Omega)$ and $C^{\infty}(\Omega)$.
\end{definition}
\begin{definition}[Support of a function \cite{grubb2008distributions}]
	The \textbf{support} of a function $f\colon \Omega \to \realnumbers$ where $\Omega \subseteq \realnumbers$ is the complement of the set of inputs $x \in \Omega$ to $f$ that are mapped to $0$. Formally,
	\begin{equation} 
		\operatorname{supp}(f) = \{x \in \Omega\,| \, f(x) \neq 0 \}
	\end{equation}
	Function $f$ has a \textbf{compact support} if $\operatorname{supp}(f)$ is closed and bounded. $C^{\infty}_{0}(\Omega)$ denotes the set of infinitely continuous differentiable functions on $\Omega$.
\end{definition}

\begin{definition}[Test function \cite{grubb2008distributions}]\label{def:testfunction}
	A \textbf{test function} is an $\infty$-times continuously differentiable function with compact support in $\Omega$ denoted by $\testfunction \in C^{\infty}_{0}(\Omega)$. $\mathcal{D}(\Omega) = C^{\infty}_{0}(\Omega)$ is called the \textbf{space of test functions}.
\end{definition}
A test function can be constructed by a combination of exponential functions.
A well-known test function is \cite{strichartz2003guide}
\begin{alignat}{1}
	\theta(x) &= 
	\left\{
	\begin{array}{ll}
		e^{-1/x^{2}} &~~ x > 0 \\~
		0 & ~~x \leq 0
	\end{array}
	\right.
	\\
	\testfunction_{r,R}(x)  & = \theta(x - r) \cdot \theta(R- x) ~~~~r,R \in \realnumbers
\end{alignat}
whose construction based on exponential functions is depicted in Figure \ref{fig:testfunctionconstruction}.
%% Figure environment removed
We can construct further test functions based on $\testfunction_{r,R}(x)$ by linear combinations of $\testfunction_{r,R}(x)$ with itself since the space of test functions is known to be a vector space \cite{grubb2008distributions} on $\realnumbers$.

Let $f \colon \realnumbers \to \realnumbers$ be a function with a jump discontinuity at $x_0 \in \realnumbers$. 
A goal in distribution theory is to find a derivative of $f$ at $x_0$ by using a test function. The concept of a function is generalized and is called a distribution.
\begin{definition}[Distribution \cite{grubb2008distributions}]
	A \textbf{distribution} $f \colon C^{\infty}_{0}(\Omega) \to \Omega$ is a continuous linear functional. The vector space of distributions on $\Omega$ is denoted $\mathcal{D'}(\Omega)$. When $f \in \mathcal{D'}(\Omega)$, we denote the value of $f$ on $\testfunction \in C^{\infty}_{0}(\Omega)$ by $f(\testfunction)$ or $\langle f, \testfunction \rangle$.
\end{definition}
A subset of the distributions are the locally integrable functions which means that certain functions can be extended to distributions.
\begin{theorem}[Locally integrable functions \cite{strichartz2003guide}]\label{theorem:locallyintegrable}
	If $f\colon \Omega \to \realnumbers$ is a \textbf{locally integrable} function, i.e. $\int_{K} |f(x)|dx < \infty$ holds for compact sets $K \subset \Omega$, then $f \in \mathcal{D'}(\Omega)$. 
\end{theorem}
Let $f$ be locally integrable. To evaluate $f$ as a distribution, we have to apply $f$ to a test function $\testfunction$. $\langle f, \testfunction \rangle$ denotes that $f$ is applied to $\testfunction$. $\langle f, \testfunction \rangle$ is usually computed using partial integration. For example, distribution theory presents an approach to solve $\langle f', \testfunction \rangle$ where $f'$ denotes the derivative of $f$.  
More precisely, let us consider a function $f$ that is locally integrable and that has jump discontinuities. 
In contrast to classical calculus, distribution theory presents a method to compute a derivative for $f$.
To this end, assume there exists a sequence of differentiable and locally integrable functons $f_n$ approaching $f$ for $n \to \infty$. Then, the derivative $f'$ of $f$ can be determined by applying a test function $\testfunction$ to $f'$ as follows \cite{grubb2008distributions} \cite{strichartz2003guide}:
\begin{alignat}{1}
	\langle f', \testfunction \rangle &
	=
	\int_{-\infty}^{\infty} f'(x) \cdot \testfunction(x)\, dx 
	\label{eq:distributionalderivative1}
	\\
	&
	\lim\limits_{n \to \infty} \int_{-\infty}^{\infty} f_{n}'(x) \cdot \testfunction(x)\, dx
	\\
	&
	=
	\lim\limits_{n \to \infty}
	[f_{n}(x) \, \testfunction(x)]_{-\infty}^{\infty} - \int_{-\infty}^{\infty} f_{n}(x) \, \testfunction'(x) \, dx
	\\
	&
	=
	\lim\limits_{n \to \infty}
	[f_{n}(x) \, \testfunction(x)]_{-\infty}^{\infty} - \int_{-\infty}^{\infty} f_{n}(x) \, \testfunction'(x) \, dx
	\\
	&
	=
	\lim\limits_{n \to \infty}
	[\underbrace{f_{n}(\infty)}_{< \, \infty}  \underbrace{\testfunction(\infty)}_{= \, 0} - \underbrace{f_{n}(-\infty)}_{ < \, \infty} \underbrace{\testfunction(-\infty)}_{ = \, 0}] - \int_{-\infty}^{\infty} f_{n}(x) \, \testfunction'(x) \, dx
	\\
	&
	=
	\lim\limits_{n \to \infty}
	- \int_{-\infty}^{\infty} f_{n}(x) \, \testfunction'(x) \, dx
	\\
	&
	=
	- \int_{-\infty}^{\infty} f(x) \, \testfunction'(x) \, dx
	\\
	&
	=
	- \langle f, \testfunction' \rangle
	\label{eq:distributionalderivative2}
\end{alignat}
Equations \eqref{eq:distributionalderivative1} to \eqref{eq:distributionalderivative2} show that the derivative $f'$ of a discontinuous function $f$ is computed by applying $f$ to the derivative $\testfunction'$ of the test function $\testfunction$. Informally, the problem of differentiating $f$ is moved to the differentiation of $\testfunction$. Since $\testfunction$ is infinitely differentiable ($\testfunction$ is e.g. a combination of exponential functions), $\testfunction'$ exists. Thus, $\testfunction'$ can be used to define the derivative of $f$ acording to Equations \eqref{eq:distributionalderivative1} to \eqref{eq:distributionalderivative2} which is called the distributional derivative of $f$ \cite{grubb2008distributions} \cite{strichartz2003guide}. This is a basic approach in distribution theory to describe derivatives of discontinuous functions.

A fundamental discontinuous function is the Heaviside function as it describes a single jump. It is named after Oliver Heaviside who used this function to describe an electric circuit when it is switched on \cite{josephs1950heaviside}. We derive in the following the derivative of the Heaviside function which is known to be the Dirac impulse  as a special case of the equation $\langle f', \testfunction \rangle = - \langle f, \testfunction' \rangle$.

\subsection{Heaviside function and Dirac delta}\label{section:heavisidefunctionanddiracdelta}
The goal of this report is to compute on impulses. 
To this end, a mathematical concept of an impulse is needed.
Such a concept is the Dirac impulse first introduced by Paul Dirac \cite{dirac1981principles}.
There exist a lot of text books introducing the Dirac impulse to signal theory, communication theory and circuit analysis.
However, to support the linear algebraic approach presented in this work, we revise the introduction of the Dirac impulse in the way it was originally given by Paul Dirac in \cite{dirac1981principles}. 
He already applied partial integration as in distribution theory to compute the derivative of a Heaviside function which we also apply in our proofs. 
Therefore, we start with the Heaviside function.
\begin{definition}[Heaviside function \cite{strichartz2003guide}]\label{def:heavisidefunction}
	The \textbf{Heaviside function} $\heaviside$ is defined by
	\begin{alignat}{1}
		\heaviside(x) \coloneqq 
		\left\{ 
		\begin{array}{ll}
			1,& x > 0 \\
			0,& x < 0 \\
			\heaviside(0), & x = 0
		\end{array}
		\right.
	\end{alignat}
	where $\heaviside(0) \in [0,1]$.
\end{definition}
% Figure environment removed
An explanation for defining $\heaviside(0) \in [0,1]$ is provided by the derivative $ \frac{d}{dx} (\heaviside(x)) |_{x=0}$  of the Heaviside function at $x = 0$.
This derivative can be computed by using partial integration and by approximating the Heaviside function for $k \to 0$ with a family of continuously differentiable functions
and the properties
\begin{alignat}{1}\label{eq:heavisideapproxproperties}
	h_{k}(x) &= 1,~~~ x > k \\
	h_{k}(x) &= 0, ~~~ x < -k
\end{alignat}
and $h_{k}(x) \in C^{\infty}$ for all $k \in \naturalnumbers$. An exemplary approximation is the family of functions
\begin{equation}\label{eq:heavisideapprox}
	h_{k}(x) = \left\{\begin{array}{lll}
		\mathlarger{\frac{1}{1 + \operatorname{e}^{\frac{4kx}{x^{2}-k^{2}}}}}   &,|x| &< k 
		\vspace{3pt}
		\\
		0  &,x &< - k 
		\\
		1  &,x &> k
	\end{array}
	\right.
\end{equation}
that is depicted in Figure \ref{fig:heavisideapprox}.
Based on the Heaviside approximation $h_{k}$, we compute the derivative $ \frac{d}{dx} (\heaviside(x)) $ as follows

%This derivative can be computed using partial integration if it is locally integrable in intervals not including 0.
%This is a key idea in distribution theory.
%Since $	\int_{a}^{0} \frac{d}{dx} (\heaviside(x)) \, dx < \infty$ and $	\int_{0}^{b} \frac{d}{dx} (\heaviside(x)) \, dx < \infty$ for $a \in \realnumbers^{-}$ and $b \in \realnumbers^{+}$, it follows that $ \frac{d}{dx} (\heaviside(x))$ is locally integrable in $[a,0]$ and $[0,b]$, so that we can compute its value by partial integration. Let $\testfunction \in \mathcal{D}$ be a test function. Then,


\begin{alignat}{1}
	\langle \heaviside', \testfunction \rangle 
	&
	=
	\lim_{k \to 0} \, \langle h_{k}', \testfunction \rangle
	\\
	&
	=
	\lim_{k \to 0} 
	\int_{-\infty}^{\infty} h_{k}'(x) \, \testfunction(x) \, dx
	\\
	&
	=
	\lim_{k \to 0} 
	[h_{k}(x) \, \testfunction(x)]_{-\infty}^{\infty} - \int_{-\infty}^{\infty} h_{k}(x) \,  \testfunction'(x) \, dx
	\\
	&
	=
	\lim_{k \to 0} 
	(1\cdot 0 - 0 \cdot 0)- \int_{-\infty}^{-k} \underbrace{h_{k}(x)}_{= \, 0}  \testfunction'(x) \, dx - \int_{-k}^{k} h_{k}(x) \, \testfunction'(x) \, dx 
	\nonumber
	\\
	& ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\,
	-   \int_{k}^{\infty}\underbrace{ h_{k}(x)}_{= \, 1}  \testfunction'(x) \, dx
	\label{eq:heavisideintegralzero}
	\\
	&
	=
	 -  \int_{0}^{\infty} \testfunction'(x) \, dx		\label{eq:heavisideintegralzer2}
	\\
	&
	=
	-[\testfunction(x)]_{0}^{\infty}
	\\
	&
	=
	\testfunction(0)
	\\
	&
	\eqqcolon
	\langle \diracdelta, \testfunction \rangle
\end{alignat}
which is defined as the Dirac impulse. Note that Equation \eqref{eq:heavisideintegralzer2} is a special case of $\langle f', \testfunction \rangle = - \langle f, \testfunction' \rangle$ from Equations \eqref{eq:distributionalderivative1} to \eqref{eq:distributionalderivative2} when $f = \heaviside$.
Furthermore, note that we could define $\heaviside(0) = 0$ or $\heaviside(0) = 1$. But neither of these definitions impact the integral in Equation \eqref{eq:heavisideintegralzero}. 
Both definitions lead to the result $\langle \heaviside', \testfunction \rangle = 	\testfunction(0)$. This is a well-known property of distributions \cite{strichartz2003guide}: There may exist multiple functions that are mapped to the same distribution. 
In case of the Heaviside function, both definitions $\heaviside(0) = 0$ and $\heaviside(0) = 1$ yield the same distribution. 
As a result of this partial integration, Paul Dirac derived in \cite{dirac1981principles} the Dirac impulse as the derivative of the Heaviside function.
\begin{definition}[Dirac delta function]\label{def:diracdelta}
	The \textbf{Dirac delta function} $\delta$ is defined
	\begin{alignat}{1}
		\diracdelta(\timepoint) = \frac{d\heaviside(\timepoint)}{d\timepoint} \,.
	\end{alignat}
\end{definition}
Note that Dirac delta distribution, impulse function, Dirac delta, Dirac impulse and Dirac delta impulse are synonyms of the Dirac delta function.
\subsection{Calculus of distributions}\label{section:calculusofdistribution}
Besides of generalizing differential calculus, distribution theory presents concepts to calculate with derivatives of discontinuous functions.
In other words, operations on distributions can be defined.
%The well-known sampling property of the Dirac impulse $\int \diracdelta(t-a)\phi(t)dt = \phi(a)$ is based on such an operation.
%If we change the shift of $\diracdelta(t-a)$, which means we operate on it, then $\phi$ is sampled at a different shift.
%In other words, an operation on a distribution causes an operation on the test function.
The theory presents the extension of operations such as addition and convolution from functions to distributions.
For this reason, they are also called generalized functions \cite{grubb2008distributions}.
In this section, we introduce operations on distributions which later
 allow us to construct a vector space.
 
An operation on a distribution can be defined based on the concept of \textbf{adjoint maps} \cite{grubb2008distributions}, also called \textbf{adjoint identities} \cite{strichartz2003guide}. 
Informally, the idea is to find the result of an operation on a distribution by finding a mathematically equal result of applying a different (adjoint) operation to a test function. 
This equality is called the adjoint map. 
An example of an adjoint map is $\langle f', \testfunction \rangle = \langle f, \testfunction' \rangle$ from Equation \eqref{eq:distributionalderivative1} to \eqref{eq:distributionalderivative2} where differentiation as an operation on a distribution $f$ is defined by differentation of the test function $\testfunction$. 
We present its general definition followed up by a textbook example of an adjoint map known as the sampling property of the Dirac impulse.

An adjoint map is described by two continuous linear transformations $T, T^{\prime} \colon \mathcal{D}(\Omega) \to \mathcal{D}(\Omega)$ on the vector space of test functions.
$T$ and $T^{\prime}$ being linear means for 
$\testfunction_1, \testfunction_2 \in \mathcal{D}(\Omega), \lambda \in \realnumbers$ that
\begin{alignat}{1}
	T(\testfunction_1 + \testfunction_2) &= T(\testfunction_1) + T(\testfunction_2) \\
	T(\lambda \cdot \testfunction_1) &= \lambda \cdot T(\testfunction)
\end{alignat}
hold
and accordingly for $T^{\prime}$ too.
An adjoint map between $T$ and $T^{\prime}$ means that
\begin{equation}\label{eq:adjoinmaptestfunctions}
	\int_{-\infty}^{\infty} T (\testfunction(x)) \, \theta(x) \, dx = \int_{-\infty}^{\infty}  \testfunction(x) \, T^{\prime} (\theta(x)) \, dx
\end{equation}
holds for any $\testfunction, \theta \in \spaceoftestfunctions$ \cite{strichartz2003guide}.
Equation \ref{eq:adjoinmaptestfunctions} states that the integral of $T (\testfunction(x)) \cdot \theta(x)$ is equal to the integral of $\testfunction(x) \cdot T^{\prime} (\theta(x))$.
The operation $T$ on a test function $\testfunction$ can be reformulated to another (adjoint) operation $T^{\prime}$ that is applied to the test function $\theta$.
In this way, the result of the operator $T$ is defined.
$T (\testfunction(x))$ is defined to have an impact on a test function $\theta$. 
If $\testfunction$ were a distribution, then an operation on $\testfunction$ would be defined by finding an operator $T'$ that manipulates the test function $\theta$.
As a result, an operation on a distribution would be defined by finding its impact on a test function.
%Let us assume that Equation \ref{eq:adjoinmaptestfunctions} holds. 
%Furthermore, assume that we do not know how to solve $\int_{-\infty}^{\infty} T (\testfunction(x)) \, \theta(x) \, dx$.
%If we know the solution of $\int_{-\infty}^{\infty}  \testfunction(x) \, T^{\prime} (\theta(x)) \, dx$, then we also know the solution of $\int_{-\infty}^{\infty} T (\testfunction(x)) \, \theta(x) \, dx$ by Equation \ref{eq:adjoinmaptestfunctions}.
%The original problem $\int_{-\infty}^{\infty} T (\testfunction(x)) \, \theta(x) \, dx$ is solved by solving another (adjoint) problem $\int_{-\infty}^{\infty}  \testfunction(x) \, T^{\prime} (\theta(x)) \, dx$.

In fact,  adjoint maps can be extended from test functions to distributions based on the following theorem stating that any distribution can be approximated by a sequence of test functions.
\begin{theorem}[Distribution from test functions \cite{strichartz2003guide}]\label{theorem:distributionfromtestfunctions}
	Given any distribution $f \in \mathcal{D'}(\Omega)$, there exists a sequence $(\testfunction_n)$ of test functions such that $f = \lim_{n \to \infty} (\testfunction_n)$ as distributions.
\end{theorem}
In this way, new operations on distributions can be defined by finding an adjoint map on test functions.
More formally, the idea is to define an operation $T$ on a distribution $f$ as a result of a limit process in which $f$ is approximated by a sequence of test functions $\testfunction_n$:
\begin{equation}\label{eq:operatorintegral}
	\langle T f, \testfunction \rangle = \int_{-\infty}^{\infty} T(f(x)) \, \testfunction(x) \, dx =  \lim_{n \to \infty}  \int_{-\infty}^{\infty} T(\testfunction_{n}(x)) \, \testfunction(x) \, dx
	=
	\lim_{n \to \infty} \langle T \testfunction_{n}, \testfunction\rangle \, .
\end{equation}
Note that a test function is a distribution since it is locally integrable (Theorem \ref{theorem:locallyintegrable}) which implies $\mathcal{D} \subseteq \mathcal{D'}$ and therefore we can write 	$\langle T f, \testfunction \rangle  = 	\lim_{n \to \infty} \langle T \testfunction_{n}, \testfunction\rangle$.
We observe that the problem $T(f)$ is reduced to the problem $T(\testfunction_{n})$ based on Theorem \ref{theorem:distributionfromtestfunctions}. 
The reason is that we know how to solve $T(\testfunction_{n})$ using the well-known algebra of functions.
Therefore, we can derive $T(f)$ by solving $T(\testfunction_{n})$ since $\testfunction_{n}$ approaches $f$ in the limit process.
This means an operation on a distribution can be defined by an operation on a function. 
In other words, Theorem \ref{theorem:distributionfromtestfunctions} enables the extension of operations on functions to distributions.

Let us now see how we can determine the limit in Equation \ref{eq:operatorintegral}.
Assume that there exists an operator $T^{\prime}$ that constitutes an adjoint map with $T$.
Then, by Equation \ref{eq:operatorintegral}, it follows that
\begin{alignat}{1}\label{eq:operatorintegral2}
	\langle T f, \testfunction \rangle = \int_{-\infty}^{\infty} T(f(x)) \, \testfunction(x) \, dx 
	&
	=  \lim_{n \to \infty}  \int_{-\infty}^{\infty} T(\testfunction_{n}(x)) \, \testfunction(x) \, dx 
	\\
	&
	= 
	\lim_{n \to \infty}  \int_{-\infty}^{\infty} \testfunction_{n}(x) \, T^{\prime}(\testfunction(x)) \, dx
	\\
	&
	=
	\lim_{n \to \infty}	\langle  \testfunction_{n}, T^{\prime}\testfunction \rangle 
	\\
	&
	=
	\langle  f, T^{\prime}\testfunction \rangle \, . \label{eq:operatorintegral3}
\end{alignat}
The adjoint map $	\langle T f, \testfunction \rangle = \langle  f, T^{\prime}\testfunction \rangle$ means that appyling $T$ to $f$ will have an effect (described by $T^{\prime})$ on the test function $\testfunction$.
$T^{\prime}$ manipulates the test function $\testfunction$ which is the input to $f$.
By assumption, $T$ and $T^{\prime}$ form an adjoint map for any test function $\testfunction$, so that any outcome $\langle T f, \testfunction \rangle$ can be described by $\langle  f, T^{\prime}\testfunction \rangle$ independent of the choice of $\testfunction$.
For this reason, $T$ is defined as an operation on the distribution $f$ by the adjoint map $	\langle T f, \testfunction \rangle = \langle  f, T^{\prime}\testfunction \rangle$.

The approach from Equation \eqref{eq:operatorintegral2} to \eqref{eq:operatorintegral3} reduces the problem of deriving $T(f)$ to finding the (adjoint) operator $T^{\prime}$ which can be usually computed using partial integration.
We demonstrate this approach and derive the adjoint map for the well-known translation of the Dirac impulse $\diracdelta_{a}(\testfunction) = \testfunction(a) $ where $\diracdelta_{a} = \diracdelta(x-a)$ or in distributional notation $\langle T_{-a} \, \diracdelta, \testfunction \rangle = \langle \diracdelta, T_{a} \, \testfunction \rangle $ where 
%
%sodass man den grenzwert wieder ziehen kann ohne den operator T auswerten zu m체ssen. damit definiert man T 체ber einen anderen Operator.
%
%in solving the integral inside the limit of Equation \ref{eq:operatorintegral} is partial integration. 
%As a result of this rule, we will get another integral 
%
%Let us now see how adjoint maps on test functions help us to define an operation on a distribution.
%To compute the output of an operation $T \colon \spaceoftestfunctions^{\prime} \to \spaceoftestfunctions^{\prime}$ on a distribution $f \in \spaceoftestfunctions^{\prime}$, we have to solve the integral
%\begin{equation}\label{eq:operatorintegral}
%	\langle T f, \testfunction \rangle = \int_{-\infty}^{\infty} T(f(x)) \, \testfunction(x) \, dx \, .
%\end{equation}
%The first step in solving Equation \ref{eq:operatorintegral} is to approximate $f$ by a sequence of test functions $(\testfunction_n)$, $n \in \naturalnumbers$:
%\begin{equation}\label{eq:operatorintegral2}
%	\langle T f, \testfunction \rangle = \int_{-\infty}^{\infty} T(f(x)) \, \testfunction(x) \, dx  = \lim_{n \to \infty}  \int_{-\infty}^{\infty} T(\testfunction_{n}(x)) \, \testfunction(x) \, dx 
%	=
%	\lim_{n \to \infty} \langle T \testfunction_{n}, \testfunction\rangle
%\end{equation}
%Note that a test function is a distribution since it is locally integrable (Theorem \ref{theorem:locallyintegrable}) which implies $\mathcal{D} \subseteq \mathcal{D'}$ and therefore we can write 	$\langle T f, \testfunction \rangle  = 	\lim_{n \to \infty} \langle T \testfunction_{n}, \testfunction\rangle$.
%Such an approximation always exists based on the following theorem.
%\begin{theorem}[Distribution from test functions \cite{strichartz2003guide}]\label{theorem:distributionfromtestfunctions}
%	Given any distribution $f \in \mathcal{D'}(\Omega)$, there exists a sequence $(\testfunction_n)$ of test functions such that $f = \lim_{n \to \infty} (\testfunction_n)$ as distributions.
%\end{theorem}
%Informally, Equation \ref{eq:operatorintegral2} states that an operation on a distribution can be defined by an operation on a test function.
%If an adjoint map for $ \int_{-\infty}^{\infty} T(\testfunction_{n}(x)) \, \testfunction(x) \, dx$ exists, i.e. if there exists $T^{\prime} \colon \spaceoftestfunctions \to \spaceoftestfunctions$, such that
%\begin{equation}\label{eq:operatorintegral3}
%	\lim_{n \to \infty}  \int_{-\infty}^{\infty} T(\testfunction_{n}(x)) \, \testfunction(x) \, dx  = \lim_{n \to \infty}  \int_{-\infty}^{\infty} \testfunction_{n}(x) \, T^{\prime}(\testfunction(x)) \, dx
%\end{equation}
%holds, then we can solve Equation \ref{eq:operatorintegral2} by finding the (adjoint) operator $S$.
%Formally, jetzt alle gleichungen. the operation T on f is derived as follows.
%
%
%Briefly said, an operation on a distribution is defined by an operation on a test function.
%The idea is to define an operation $T$ on a distribution $f \in \spaceoftestfunctions^{\prime}$ by defining a different (adjoint) operation $T^{\prime}$ on a test function $\theta$.
%
%
%A reason is that the T is defined on f by an integral which is easier to solve for a test function 
%it can be easier to solve an integral of a test function than an integral of a distribution. 
%A reason is that the partial integration requires the differentiation of the factors of the integrand which is given in case of test functions and not trivially found in case of a distribution.
%
%
%
%If $T \colon \mathcal{D}(\Omega) \to \mathcal{D}(\Omega)$, then applying $T$ to a distribution $f \in \mathcal{D'}(\Omega)$ is defined by the adjoint identity
%\begin{equation}\label{eq:adjoinmapdistributions}
%	\langle T f, \testfunction \rangle = \langle f, T^{\prime} \testfunction \rangle
%\end{equation}
%for $T^{\prime}\colon \mathcal{D}(\Omega) \to \mathcal{D}(\Omega)$.
%If we cannot solve $T(f)$, we can try to solve $T^{\prime}(\testfunction)$ such that \eqref{eq:adjoinmapdistributions} holds.
%In other words, an operation $T$ on a distribution $f$ is defined by an operation $T^{\prime}$ on a test function $\testfunction$. 
the translations $T_a$ and $T_{-a}$ are defined as the linear transformations
\begin{alignat}{1}
	T_a \colon \mathcal{D} \to \mathcal{D}, \testfunction(x) \mapsto \testfunction(x+a) 
	\\
	T_{-a} \colon \mathcal{D} \to \mathcal{D}, \testfunction(x) \mapsto \testfunction(x-a) 
\end{alignat}
with $a \in \realnumbers$.
We derive the adjoint map $\langle T_{-a} \, \diracdelta, \testfunction \rangle = \langle \diracdelta, T_{a} \, \testfunction \rangle $
%As a part of this problem, we have to find out how to extend the operation $T_a$, that is defined on test functions, to distributions.
%The idea is that we can describe a distribution as the limit of a sequence of test functions, so that an operation on a distribution can be defined by such a limit process.
%Since a locally integrable function is a distribution (Theorem \ref{theorem:locallyintegrable}), it follows that test functions are distributions, as they are locally integrable. This means $\mathcal{D} \subseteq \mathcal{D'}$.
% Figure environment removed
%\begin{theorem}[Distribution from test functions \cite{strichartz2003guide}]\label{theorem:distributionfromtestfunctions}
%	Given any distribution $f \in \mathcal{D'}(\Omega)$, there exists a sequence $(\testfunction_n)$ of test functions such that $f = \lim_{n \to \infty} (\testfunction_n)$ as distributions.
%\end{theorem}
%This means an operation on test functions can be extended to distributions. If $f = \lim_{n \to \infty} (\testfunction_n)$ is a distribution approximated by a sequence of test functions $ (\testfunction_n)$, the adjoint identity can be written as \cite{strichartz2003guide}
%\begin{alignat}{1}
%	\langle T f, \theta \rangle 
%	&
%	=
%	\lim_{n \to \infty} \langle T \testfunction_n, \theta \rangle = \lim_{n \to \infty} \int_{-\infty}^{\infty} T(\testfunction_n(x))  \,  \theta(x) \, dx \\
%	&
%	=
%	\lim_{n \to \infty}\int_{-\infty}^{\infty} \testfunction_n(x)  \, T^{\prime}(\theta(x)) \, dx = \lim_{n \to \infty} \langle \testfunction_n, T^{\prime}(\theta) \rangle = \langle f, T^{\prime}(\theta) \rangle
%\end{alignat}
%where $\theta \in \mathcal{D}$.
using the following family of test functions to approximate the Dirac impulse:
\begin{alignat}{2}\label{eq:diracapprox}
	f_{k}(x) & = \frac{1}{k} f\left(\frac{x}{k}\right) \\
	f(x) &= \left\{\begin{array}{lll} 
		\frac{4(x^{2}+1)\cdot \operatorname{e}^{\frac{4x}{x^2-1}}} {\left((x^{2}-1)\left(1 + \operatorname{e}^{\frac{4x}{x^{2}-1}}\right)\right)^{2} }   &,|x| &< 1 
		\\
		0  &, |x| & \geq 1 
	\end{array}
	\right.
\end{alignat}
for $k \in \naturalnumbers$ that has the properties 
\begin{alignat}{1}\label{eq:diracapprox2}
	\int_{-1/k}^{1/k}f_k(x) \, dx &= 1 \\
	f_k(x) &= 0 ~~~ x \geq |1/k| \label{eq:diracapprox3}
\end{alignat}
and is depicted in Figure \ref{fig:diracapprox}.
Based on the sequence $f_{k}(x)$ and its properties shown in Equation \ref{eq:diracapprox2} and \ref{eq:diracapprox3}, we derive the translation of the Dirac impulse.
\begin{lemma}[Translation of Dirac impulse \cite{strichartz2003guide}]\label{lemma:translationdirac}
	Let $f_{k}(x)$ be a sequence of test functions approximating the Dirac impulse with the properties $	\int_{-1/k}^{1/k}f_k(x) \, dx = 1 $ and $	f_k(x) = 0, x \geq |1/k|$. Then, $\langle T_{-a}  \, \diracdelta, \testfunction \rangle = \langle \diracdelta, T_{a} \, \testfunction \rangle$ is the adjoint identity of translating the Dirac impulse.
\end{lemma}
\begin{proof}
\begin{alignat}{1}
	\langle T_{-a} \, \diracdelta, \testfunction \rangle
	&
	=
	\lim\limits_{k \to \infty} \int_{-\infty}^{\infty} f_{k}(x-a)  \, \testfunction(x) \, dx
	\\
	&
	=
	\lim\limits_{k \to \infty} 
	[F_{k}(x-a)  \, \testfunction(x)]_{-\infty}^{\infty} - \int_{-\infty}^{\infty} F_{k}(x-a) \,  \testfunction'(x) \, dx \label{eq:diractranslation}
	\\
	&
	=
	\lim\limits_{k \to \infty} 
	1 \cdot 0 - 0 \cdot 0 - \int_{-\infty}^{-1/k+a} \underbrace{F_{k}(x-a)}_{= \, 0, \, \mathrm{by} \, \eqref{eq:diracapprox2}} \testfunction'(x) \, dx - \int_{-1/k+a}^{1/k+a} F_{k}(x+a) \,  \testfunction'(x) \, dx \nonumber
	\\
	& ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	- \int_{1/k+a}^{\infty} \underbrace{F_{k}(x-a)}_{= \, 1, \, \mathrm{by} \, \eqref{eq:diracapprox2}} \testfunction'(x) \, dx
	\\
	&
	=
	\lim\limits_{k \to \infty} 
	- \int_{-1/k+a}^{1/k+a} F_{k}(x-a) \,  \testfunction'(x) \, dx - \int_{1/k+a}^{\infty} \testfunction'(x) \, dx
	\\
	&
	=
	- \int_{a}^{\infty} \testfunction'(x) \, dx
	\\
	&
	=
	-[\testfunction(x)]_{a}^{\infty}
	\\
	&
	=
	\testfunction(a)
	\\
	&
	=
	\langle \diracdelta, T_{a} \, \testfunction \rangle
\end{alignat}
\end{proof}
Hence, we get the adjoint map $\langle T_{-a} \, \diracdelta, \testfunction \rangle = \langle \diracdelta, T_{a} \, \testfunction \rangle$ which defines the translation of the Dirac impulse as the negated translation of the test function.
This translation is known as the sampling property $\diracdelta_{a}( \testfunction) = \testfunction(-a)$ of the Dirac impulse.
Informally, an adjoint map defines an operation on a distribution by applying the operation on the test function instead of the distribution. In this way, it is usually easier to find a solution since test functions have useful properties such as differentiability and compact supports.
%wenn translation fertig ist, dann kann man mit impuls gruppe anfangen, weil man da die translation schon braucht. die heaviside maske kann man dann sp채ter herleiten bei caluclus of impulse algebra.
%hier auch noch die methode mit der approximation der distribution durch testfunktion einf체hren.
We apply adjoint maps in the following to derive further operations on Dirac impulses to construct a vector space.

\section{Impulse algebra}\label{section:impulsespace}
% Figure environment removed
The Dirac impulse is well-known in digital signal theory for its sampling property.
A continuous signal of a physical quantity is the input to a digital system using an analog-to-digital converter.
It samples the input with a given period, so that the output is a digital signal \cite{buttazzo2011hard}. 
The digital signal is the input to a processing unit of an embedded real-time system. 
Any change in the digital signal represented by a Dirac impulse may cause a task of the embedded system to be requested for execution. 

In real-time analysis, it is abstractly said that events request the execution of tasks.
More precisely, an event generates a job of a task at the time point of its occurrence, called the request time.
A job has a certain workload to be processed that is modeled by execution time.
Furthermore, a job must be completed before a specified deadline representing e.g. the stability requirement of a controller \cite{buttazzo2011hard}.
%Therefore, a job is characterized by a request time, an execution time and a deadline.

A goal in real-time analysis is to check whether deadlines of jobs sharing a processor with respect to a given scheduling policy  are violated \cite{buttazzo2011hard}. Task models are the basis for analysis. 
%Different models exist dependent on the event pattern or data and control flow of the task \cite{baruah1999generalized}, \cite{baruah2003dynamic}, \cite{stigge2011digraph}, \cite{albers2006hierarchical}.
The models assume that a sequence of jobs, or \textbf{job train}, is generated. 
However, a model of job trains is often not described  \cite{albers2006hierarchical}, \cite{richter2004compositional},\cite{stigge2011digraph}, \cite{thiele2000real} although jobs are the objects to be scheduled.

For example, the request curve $R(t)$ of the real-time calculus \cite{thiele2000real} shown in Figure \ref{fig:requestfunction} describes the cumulative workload of a job train over time. 
A single job is not defined by $R(t)$ but the sum of the workloads of the job train is described.
In contrast to this, the derivative of $R(t)$ shown in Figure \ref{fig:requestfunction} is a series of Dirac impulses describing the jump discontinuities of the request curve at time points $s_n$ with $n \in \{1,2,3,4\}$. 
A change in the request curve describes the workload $c_n$ that is requested at the time point of the jump. 
If the workload $c_n$ is described by a job, then a Dirac impulse represents a job that is requested at $s_n$ with workload $c_n$ equal to the amplitude of the impulse.
This means a job train is represented by a series of Dirac impulses, or, an \textbf{impulse train} $$\sum_{n = 1}^{N} c_n \, \diracdelta(t - s_n)$$ 

%
%the digital signal can be the source of a sequence of events or impulses (that we call an \textbf{impulse train}) in an embedded real-time system that causes the instantiation and execution of tasks. An instance of a task is a job that is described by its request time (the time point of an event), execution time and deadline. For example, a periodic digital signal may induce a periodic impulse train which in turn causes a periodic generation of jobs. We call a sequence of jobs a job train. Periodic task models are well-studied in the field of real-time analysis \cite{buttazzo2011hard}, \cite{liu1973scheduling}.
%However, if we want to analyze a computing system for an arbitrarily given job train, then we need a model of job trains where request times are arbitrary or constitute multiple nested periods and where each job may have a different execution time.

Our approach in modeling any job train is to construct a vector space of Dirac impulses, so that any job train can be described by a linear combination of impulses, i.e. an impulse train.
It is well-known that the space of distributions is a vector space which means that Dirac impulses, which are distributions, can be linearly combined to form new distributions \cite{grubb2008distributions}.
However, to the best of our knowledge, there is no literature on the vector space of Dirac impulses which we could apply to present a performance analysis of computers. 
Therefore, we present the impulse algebra which is a linear algebra based on the Dirac impulse.
Later, we apply the algebra to introduce new operations on the Dirac impulse based on adjoint maps for analysis purposes.
As the algebra requires many symbols we provide a list of them in Table \ref{table:listofsymbols}.
%The basic element of the presented algebra is the Dirac impulse impulse which was introduced by Paul Dirac \cite{dirac1981principles} to describe the derivative of the Heaviside function. 
%It is also applied to describe a single event in a digital signal, so that the whole signal can be described by a linear combination of Dirac impulses.
%To construct any linear combination, we need to define a vector space of Dirac impulses. To this end, we derive the vector space operations based on distribution theory.
%The list of symbols of the algebra is in Table \ref{table:listofsymbols}.
\subsection{Impulse group}\label{section:impulsegroups}
The vector space of Dirac impulses, called the Dirac space or impulse space, is constructed based on an abelian group of Dirac impulses that is endowed by scalar multiplication of real numbers. Hence, the Dirac space is a vector space on the field of the real numbers that is denoted by the triple $(\realnumbers, +_{\realnumbers}, \cdot_{\realnumbers})$ where $\realnumbers$ is the set of real numbers and $+_{\realnumbers}$ and $\cdot_{\realnumbers}$ are addition and multiplication of real numbers.
To construct this abelian group, we defined the shifted impulse.
\begin{definition}[Shifted impulse]\label{def:shiftedimpulse}
	Let $\impulsevariable \in \realnumbers$ be a variable, $\impulseshift \in \realnumbers$ and $\impulseindex \in \naturalnumberswithzeroandinfinity$.
	Then, the function
	\begin{equation}
		\shiftedimpulse{\impulseindex}{\impulsevariable} = \diracdelta(\impulsevariable - \impulseindex \impulseshift)
	\end{equation}
describes a right-shifted Dirac impulse and is called a \textbf{\shiftedimpulsename} and $ \impulseindex \impulseshift$ is called the \textbf{\shiftname} of the \shiftedimpulsename{} $\shiftedimpulse{\impulseindex}{\impulsevariable}$. 
In short-form, we write
\begin{equation}
	\shiftedimpulsesf{\impulseindex}{\impulsevariable} \coloneqq \shiftedimpulse{\impulseindex}{\impulsevariable}
\end{equation}
\end{definition}
As we present in the following a linear space of \shiftedimpulsename{s}, we introduce additional short-form notation for the summation of Dirac impulses in Appendix \ref{appendix:notation}.  
The \shiftedimpulsename{} can be an element of an algebraic structure, called the \impulsegroupname.
\begin{definition}[\impulsegroupnamecapital]\label{def:impulsegroup}
	The pair $\impulsegroup{\impulsevariable}  \coloneqq (\shiftedimpulseset{\impulsevariable}, \impulsegroupoperation)$ is called \textbf{\impulsegroupname} (IG) where
	$\shiftedimpulseset{\impulsevariable} \coloneqq \{ \shiftedimpulse{\impulseindex}{\impulsevariable}, - \shiftedimpulse{\impulseindex}{\impulsevariable} \}$ is the \textbf{\shiftedimpulsesetname} and 
	\begin{alignat}{1}
		\impulsegroupoperation \colon \shiftedimpulseset{\impulsevariable} \times \shiftedimpulseset{\impulsevariable} \to \shiftedimpulseset{\impulsevariable}, (u_{n}^{ \, x}, v_{m}^{ \, x}) \mapsto u_{n}^{ \, x} +_{\realnumbers} v_{m}^{ \, x}
	\end{alignat}
	is called \textbf{impulse addition}.
\end{definition}
In the following, we show that the \impulsegroupname{} satisfies the axioms of an abelian group.
\begin{lemma}[Impulse group]\label{lemma:impulsegroup}
	The impulse group $\impulsegroup{\impulsevariable}$ is an abelian group.
\end{lemma}
\begin{proof}
	Let $\Omega \subseteq \realnumbers$ be an open set and let $K \subseteq \Omega$ be a compact subset of $\Omega$. Let  $\testfunction(\impulsevariable), \varphi(\impulsevariable) \in \spaceoftestfunctions(\Omega)$ be test functions such that $\operatorname{supp} (\testfunction) \in K$ and $\operatorname{supp} (\varphi) \in K$. 
	Let $n,m,o \in \naturalnumbers, v,w,z \in \realnumbers$. 
	Let $(f_{k})_{k=1}^{\infty}$ be the sequence of test functions approximating the Dirac impulse for $k \to \infty$ with the properties $f_{k}(x) = 0, x > |1/k|$ for all $k$ and $\int_{-1/k}^{1/k} f_{k}(x) = 1$ \cite{strichartz2003guide}.
	
	By the sampling property of the Dirac impulse (Lemma \ref{lemma:translationdirac}), the Dirac impulse maps a test function on a function value at the shift of the impulse: $\langle \diracdelta_{\impulseindex \impulseshift}, \testfunction \rangle = \testfunction(\impulseindex \impulseshift) \in \realnumbers$, where $\diracdelta_{\impulseindex \impulseshift} = \diracdelta(\impulsevariable - \impulseindex \impulseshift)$. We use this property to show that an addition of impulses can be realized by an addition of real numbers.
	
	Closure of $\impulsegroupoperation$:
	\begin{alignat}{1}
		v_{n}^{ \, x} \impulsegroupoperation w_{m}^{ \, x}
		&
		=
		\langle \diracdelta_{nv} +_{\realnumbers} \diracdelta_{mw}, \testfunction \rangle
		\label{eq:impulsegroupclosure1}
		\\
		&
		=
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} (f_{k}(\impulsevariable - nv) +_{\realnumbers} f_{k}(\impulsevariable -mw)) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} f_{k}(\impulsevariable - nv) \cdot \testfunction(\impulsevariable) \, d\impulsevariable 
		+_{\realnumbers} 
		\int_{-\infty}^{\infty} f_{k}(\impulsevariable - mw) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\testfunction(nv) + \testfunction(mw)
		\\
		&
		=
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} f_{k}(\impulsevariable) \cdot(\underbrace{\testfunction(x + nv) +_{\realnumbers} \testfunction(\impulsevariable + mw)}_{\in \spaceoftestfunctions}) \, d\impulsevariable
		\\
		&
		=
		\langle \diracdelta, \testfunction_{nv} +_{\realnumbers} \testfunction_{mw} \rangle
		\label{eq:impulsegroupclosure2}
	\end{alignat}
	where $+_{\realnumbers}$ is the addition of real numbers.
	Equations \ref{eq:impulsegroupclosure1} to \ref{eq:impulsegroupclosure2} state that there exists a pair of test functions such that applying the Dirac impulse on their sum is equal to applying the sum of two Dirac impulses to a single test function, so that $\shiftedimpulseset{\impulsevariable}$ is closed under $\impulsegroupoperation$.
%	We know that $\langle \diracdelta_{nv} +_{\realnumbers}, \testfunction \rangle = \testfunction(nv) \in \realnumbers$ and by closure of real addition 
%	\begin{equation}\label{eq:impulsegroup1}
%		\langle \diracdelta_{nv} +_{\realnumbers}, \testfunction \rangle +_{\realnumbers} \langle \diracdelta_{mw}, \testfunction \rangle  = \testfunction(nv) +_{\realnumbers} \testfunction(mw) \in \realnumbers
%	\end{equation}
%	But \eqref{eq:impulsegroup1} can be also written as
%	\begin{alignat}{1}
%		\testfunction(nv) + \testfunction(mw)
%		&
%		\oset[1.5ex]{\mathclap{\eqref{eq:diractranslation}}}{=}
%		\int_{-\infty}^{\infty} \diracdelta(\impulsevariable - nv) \cdot \testfunction(\impulsevariable) \, d\impulsevariable 
%		+_{\realnumbers} 
%		\int_{-\infty}^{\infty} \diracdelta(\impulsevariable - mw) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
%		\\
%		&
%		=
%		\lim_{k \to \infty}
%		\int_{-\infty}^{\infty} f_{k}(\impulsevariable - nv) \cdot \testfunction(\impulsevariable) \, d\impulsevariable 
%		+_{\realnumbers} 
%		\int_{-\infty}^{\infty} f_{k}(\impulsevariable - mw) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
%		\\
%		&
%		=
%		\lim_{k \to \infty}
%		\int_{-\infty}^{\infty} (f_{k}(\impulsevariable - nv) +_{\realnumbers} f_{k}(\impulsevariable -mw)) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
%		\\
%		&
%		=
%		\langle \diracdelta_{nv} +_{\realnumbers} \diracdelta_{mw}, \testfunction \rangle
%		\\
%		&
%		=
%		v_{n}^{ \, x} \impulsegroupoperation w_{m}^{ \, x}
%	\end{alignat}
%	Hence, the evaluation of added impulses is equal to the addition of the evaluated impulses, 

	
	Associativity:
	\begin{alignat}{1}
		(v_{n}^{ \, x} \impulsegroupoperation w_{m}^{ \, x}) \impulsegroupoperation z_{o}^{ \, x} 
		&
		=
		\langle (\diracdelta_{nv} +_{\realnumbers} \diracdelta_{mw}) +_{\realnumbers} \diracdelta_{oz} , \testfunction \rangle
		\\
		&
		=
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} ((f_{k}(\impulsevariable - nv) +_{\realnumbers} f_{k}(\impulsevariable -mw))+_{\realnumbers} f_{k}(\impulsevariable - oz)) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		\oset[1.5ex]{\mathclap{\mathrm{asso. \, in \,}\realnumbers}}{=}
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} (f_{k}(\impulsevariable - nv) +_{\realnumbers} (f_{k}(\impulsevariable -mw)+_{\realnumbers} f_{k}(\impulsevariable - oz))) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\langle \diracdelta_{nv} +_{\realnumbers} (\diracdelta_{mw} +_{\realnumbers} \diracdelta_{oz}) , \testfunction \rangle
		\\
		&
		=
		v_{n}^{ \, x} \impulsegroupoperation (w_{m}^{ \, x} \impulsegroupoperation z_{o}^{ \, x} )
	\end{alignat}

	Commutativity:
	\begin{alignat}{1}
		v_{n}^{ \, x} \impulsegroupoperation w_{m}^{ \, x}
		&
		=
		\langle \diracdelta_{nv} +_{\realnumbers} \diracdelta_{mw} , \testfunction \rangle
		\\
		&
		=
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} (f_{k}(\impulsevariable - nv) +_{\realnumbers} f_{k}(\impulsevariable -mw)) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		\oset[1.5ex]{\mathclap{\mathrm{comm. \, in \,}\realnumbers}}{=}
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} (f_{k}(\impulsevariable - mw) +_{\realnumbers} f_{k}(\impulsevariable -nv)) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\langle \diracdelta_{mw} +_{\realnumbers} \diracdelta_{nv}  , \testfunction \rangle
		\\
		&
		=
		w_{m}^{ \, x} \impulsegroupoperation v_{n}^{ \, x} 
	\end{alignat}

	Neutral element: %Let $mw = \max\{ \operatorname{Bd}_{\realnumbers} \Omega\}$ be the maximum of the boundary of the open set $\Omega$. By definition of the test function, it follows that $\testfunction(mw) = 0$. Thus,
	Let $w_{K} = \max\{ K \}$ be the maximum of the compact set $K$. Let $w_{K}^{\impulsevariable} \coloneqq \diracdelta(\impulsevariable - w_{K})$ denote the Dirac impulse at the shift $w_{K}$. By definition of $\testfunction$ it follows that $\testfunction(w_{K}) = 0$. Thus,
	\begin{alignat}{1}
		v_{n}^{ \, x} \impulsegroupoperation w_{K}^{ \, x}
		&
		=
		\langle \diracdelta_{nv} +_{\realnumbers} \diracdelta_{w_{K}} , \testfunction \rangle
		\\
		&
		=
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} (f_{k}(\impulsevariable - nv) +_{\realnumbers} f_{k}(\impulsevariable -w_{K})) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} f_{k}(\impulsevariable - nv) \cdot \testfunction(\impulsevariable) \, d\impulsevariable 
		+_{\realnumbers} 
		\int_{-\infty}^{\infty} f_{k}(\impulsevariable - w_{K}) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\langle \diracdelta_{nv}, \testfunction \rangle +_{\realnumbers} \langle \diracdelta_{w_{K}}, \testfunction \rangle
		\\
		&
		=
		v_{n}^{ \, x}  +_{\realnumbers} \testfunction(w_{K})
		\\
		&
		=
		v_{n}^{ \, x}  +_{\realnumbers} 0
		\\
		&
		\oset[1.5ex]{\mathclap{\mathrm{neutral. \, in \,}\realnumbers}}{=}
		v_{n}^{ \, x}
	\end{alignat}
	Thus, $w_{K}^{ \, x}$ is the neutral element of $\shiftedimpulseset{\impulsevariable}$.
	
	Inverse element: 	Let $w_{K}^{ \, x}$ with $w_{K} = \max\{ K \}$ be the neutral element. Then,
	\begin{alignat}{1}
		v_{n}^{ \, x} \impulsegroupoperation -v_{n}^{ \, x}
		&
		=
		\langle \diracdelta_{nv} +_{\realnumbers} - \diracdelta_{nv} , \testfunction \rangle
		\\
		&
		=
		\lim_{k \to \infty}
		\int_{-\infty}^{\infty} (f_{k}(\impulsevariable - nv) +_{\realnumbers} - f_{k}(\impulsevariable -nv)) \cdot \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		0
		\\
		&
		=
		w_{K}^{ \, x}
	\end{alignat}
	As $	v_{n}^{ \, x} \impulsegroupoperation -v_{n}^{ \, x}$ results in the neutral element $w_{K}^{ \, x}$ , it follows that $	- v_{n}^{ \, x}$ is the inverse element of $	v_{n}^{ \, x} $.
\end{proof}
We set the neutral element to the Dirac impulse that samples a test function at the maximum of the compact set $K$ since all test functions in $\spaceoftestfunctions(\Omega)$ have their support in $K$. By Definition \ref{def:testfunction}, $\testfunction$ is zero outside its support, so that the Shirac occurring at $mw = \max\{ K \}$ samples $\testfunction(mw) = 0$ which is neutral in $\realnumbers$. 
The impulse group describes any addition of Dirac impulses. In other words, we can construct Dirac combs using the \impulsegroupoperationname.
\begin{example}[Impulse group]\label{example:impulsegroup}
	Let us consider the \shiftedimpulsenameplural{} $\shiftedimpulse{1}{\impulsevariable},\shiftedimpulse{2}{\impulsevariable},\shiftedimpulse{3}{\impulsevariable} \in \shiftedimpulseset{\impulsevariable}$. By closure of \impulsegroupoperationname, we can construct a finite series of  \shiftedimpulsenameplural{}
	\begin{equation}
		\shiftedimpulseset{\impulsevariable} \ni \shiftedimpulse{0}{\impulsevariable} \impulsegroupoperation \shiftedimpulse{1}{\impulsevariable} \impulsegroupoperation \shiftedimpulse{2}{\impulsevariable}  = \sum_{\impulseindex = 0}^{2} \diracdelta(\impulsevariable - \impulseindex s) = \sum_{\impulseindex = 0}^{2} \shiftedimpulse{\impulseindex}{\impulsevariable}
	\end{equation}
	that is an element of $\shiftedimpulseset{\impulsevariable}$. This means we can apply \impulsegroupoperationname{} on $\sum_{\impulseindex = 0}^{2} \shiftedimpulse{\impulseindex}{\impulsevariable}$ and another group element, e.g. $\sum_{\impulseindex = 0}^{1} q_{\impulseindex}(\impulsevariable)$ to construct the series of  \shiftedimpulsenameplural{}
	\begin{alignat}{1}
		\sum_{\impulseindex = 0}^{2} \shiftedimpulse{\impulseindex}{\impulsevariable} \impulsegroupoperation \sum_{\impulseindex = 0}^{1} q_{\impulseindex}(\impulsevariable)
		&
		=
		\shiftedimpulse{0}{\impulsevariable} \impulsegroupoperation \shiftedimpulse{1}{\impulsevariable} \impulsegroupoperation  \shiftedimpulse{2}{\impulsevariable}
		\impulsegroupoperation
		q_{0}(\impulsevariable)\impulsegroupoperation q_{1}(\impulsevariable) \in \shiftedimpulseset{\impulsevariable}
	\end{alignat}
	that is element of the impulse group by closure of \impulsegroupoperationname. Summarizing, it is possible to construct an arbitrary  \shiftedimpulsename{} series.
\end{example}
\subsection{Impulse spectral space}
In this section, we present a vector space of impulses on the field of the real numbers, called the \impulsespectralspacename, by combining the abelian group of impulses with the scalar multiplication of real numbers.
To this end, we show that the \impulsespectralspacename{} satisfies the axioms of a vector space \cite{hefferon2016linear}.
\begin{definition}[Impulse spectral space]\label{def:impulsespectralspace}
	The triple $\impulsespectralspace{\impulsevariable} = (\shiftedimpulseset{\impulsevariable}, \impulsegroupoperation, \impulsespectralspacemult)$ is called \textbf{\impulsespectralspacename}{} where $\shiftedimpulseset{\impulsevariable}$ and $\impulsegroupoperation$ are the impulse set and impulse addition of Definition \ref{def:impulsegroup} and
	\begin{alignat}{1}
		\impulsespectralspacemult \colon \realnumbers \times \shiftedimpulseset{\impulsevariable} \to \shiftedimpulseset{\impulsevariable}, (\lambda, v_{n}^{ \, x}) \mapsto \lambda \cdot_{\realnumbers} v_{n}^{ \, x}
	\end{alignat}
	is called \textbf{\impulsespectralspacemultname} and $\cdot_{\realnumbers}$ is multiplication of real numbers.
\end{definition}
\begin{theorem}[Impulse spectral vector space]\label{theorem:impulsespectralspace}
	The \impulsespectralspacename{} $\impulsespectralspace{\impulsevariable} = (\shiftedimpulseset{\impulsevariable}, \impulsegroupoperation, \impulsespectralspacemult)$ is a vector space on the field of  the real numbers where $\shiftedimpulseset{\impulsevariable}$ is the set of vectors, and $\impulsegroupoperation$ and $\impulsespectralspacemult$ are respectively vector addition and scalar multiplication.
\end{theorem}
\begin{proof}
	By Lemma \ref{lemma:impulsegroup}, we know that the \shiftedimpulsesetname{} $\shiftedimpulseset{\impulsevariable}$ and \impulsegroupoperationname{} $\impulsegroupoperation$ are an abelian group.
	Hence, we prove the vector space axioms of scalar multiplication.
	Let $\lambda,\alpha,v,w \in \realnumbers, n,m \in \naturalnumbers$.
	Let $(f_{k})_{k=1}^{\infty}$ be a sequence of functions approximating the Dirac distribution for $k \to \infty$ with the properties $f_{k}(x) = 0, x > |1/k|$ for all $k$ and $\int_{-1/k}^{1/k} f_{k}(x) = 1$.
	
	Closure of scalar multiplication:
	\begin{alignat}{1}
		\lambda \impulsespectralspacemult v_{n}^{ \, \impulsevariable} 
		&
		= 
		\langle \lambda \cdot_{\realnumbers} \diracdelta_{nv}, \testfunction \rangle
		\\
		&
		=
		\lim_{k \to \infty} \int_{-\infty}^{\infty} \lambda \cdot_{\realnumbers} f_{k}(\impulsevariable - nv) \cdot_{\realnumbers} \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\lim_{k \to \infty} \int_{-\infty}^{\infty} f_{k}(\impulsevariable - nv) \cdot_{\realnumbers} \underbrace{\lambda \cdot_{\realnumbers} \testfunction(\impulsevariable)}_{\in \spaceoftestfunctions} \, d\impulsevariable
		\\
		&
		=
		\langle \diracdelta_{nv}, \lambda \cdot_{\realnumbers} \testfunction \rangle
	\end{alignat}
	where $\cdot_{\realnumbers}$ is the multiplication of real numbers.
	
	Associativity of scalar multiplication:
	\begin{alignat}{1}
		\alpha \impulsespectralspacemult (\lambda \impulsespectralspacemult v_{n}^{ \, \impulsevariable} ) \label{eq:associativityscalarmultiplication1}
		&
		=
		\langle \alpha \cdot_{\realnumbers}(\lambda \cdot_{\realnumbers} \diracdelta_{nv}), \testfunction \rangle
		\\
		&
		=
		\lim_{k \to \infty} \int_{-\infty}^{\infty} \alpha \cdot_{\realnumbers} (\lambda \cdot_{\realnumbers} f_{k}(\impulsevariable - nv)) \cdot_{\realnumbers} \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		\oset[1.5ex]{\mathclap{\mathrm{asso. \, in \,}\realnumbers}}{=}
		\lim_{k \to \infty} \int_{-\infty}^{\infty} (\alpha \cdot_{\realnumbers} \lambda) \cdot_{\realnumbers} f_{k}(\impulsevariable - nv) \cdot_{\realnumbers} \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\langle (\alpha \cdot_{\realnumbers} \lambda) \cdot_{\realnumbers} \diracdelta_{nv}, \testfunction \rangle
		\\
		&
		=
		(\alpha \cdot_{\realnumbers} \lambda ) \impulsespectralspacemult v_{n}^{ \, \impulsevariable} 
	\end{alignat}

	Distributivity of scalar multiplication:
	\begin{alignat}{1}
		\lambda \impulsespectralspacemult (v_{n}^{ \, x} \impulsegroupoperation w_{m}^{ \, x}) 		\label{eq:distributivityscalarmultiplication1}
		&
		=
		\langle \lambda \cdot_{\realnumbers} (\diracdelta_{nv} +_{\realnumbers} \diracdelta_{mw}), \testfunction \rangle
		\\
		&
		=
		\lim_{k \to \infty} \int_{-\infty}^{\infty} \lambda \cdot_{\realnumbers} (f_{k}(\impulsevariable - nv) +_{\realnumbers} f_{k}(\impulsevariable - mw)) \cdot_{\realnumbers} \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		\oset[1.5ex]{\mathclap{\mathrm{distr. \, in \,}\realnumbers}}{=}
		\lim_{k \to \infty} \int_{-\infty}^{\infty}  (\lambda \cdot_{\realnumbers} f_{k}(\impulsevariable - nv) +_{\realnumbers} \lambda \cdot_{\realnumbers} f_{k}(\impulsevariable - mw)) \cdot_{\realnumbers} \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\langle \lambda \cdot_{\realnumbers}  \diracdelta_{nv} +_{\realnumbers} \lambda \cdot_{\realnumbers}  \diracdelta_{mw}, \testfunction \rangle
		\\
		&
		=
		\lambda \impulsespectralspacemult  v_{n}^{ \, x} \impulsegroupoperation  \lambda \impulsespectralspacemult  w_{m}^{ \, x}
	\end{alignat}

	Distributivity of scalar addition:
	\begin{alignat}{1}
		(\lambda +_{\realnumbers} \alpha) \impulsespectralspacemult v_{n}^{ \, x}
		&
		=
		\langle (\lambda +_{\realnumbers} \alpha) \cdot_{\realnumbers} \diracdelta_{nv} , \testfunction \rangle 
		\label{eq:scalaraddition1}
		\\
		&
		=
		\lim_{k \to \infty} \int_{-\infty}^{\infty} (\lambda +_\realnumbers \alpha) \cdot_{\realnumbers} f_{k}(\impulsevariable - nv) \cdot_{\realnumbers} \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		\oset[1.5ex]{\mathclap{\mathrm{distr. \, in \,}\realnumbers}}{=}
		\lim_{k \to \infty} \int_{-\infty}^{\infty} \lambda \cdot_{\realnumbers} f_{k}(\impulsevariable - nv) +_{\realnumbers} \alpha \cdot_{\realnumbers} f_{k}(\impulsevariable - nv)  \cdot_{\realnumbers} \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\langle \lambda \cdot_{\realnumbers} \diracdelta_{nv} +_{\realnumbers} \alpha \cdot_{\realnumbers} \diracdelta_{nv} , \testfunction \rangle 
		\\
		&
		=
		\lambda \impulsespectralspacemult v_{n}^{ \, x} +_{\realnumbers} \alpha \impulsespectralspacemult v_{n}^{ \, x}
		\label{eq:scalaraddition2}
	\end{alignat}
	
	Neutral element of scalar multiplication:
	\begin{alignat}{1}
		1 \impulsespectralspacemult v_{n}^{\, \impulsevariable} 
		&
		= 
		\langle 1 \cdot_{\realnumbers} \diracdelta_{nv}, \testfunction \rangle
		\\
		&
		=
		\lim_{k \to \infty} \int_{-\infty}^{\infty} 1 \cdot_{\realnumbers} f_{k}(\impulsevariable - nv) \cdot_{\realnumbers} \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		\oset[1.5ex]{\mathclap{\mathrm{neutral \, in \,}\realnumbers}}{=}
		\lim_{k \to \infty} \int_{-\infty}^{\infty} f_{k}(\impulsevariable - nv) \cdot_{\realnumbers} \testfunction(\impulsevariable) \, d\impulsevariable
		\\
		&
		=
		\langle \diracdelta_{nv},  \testfunction \rangle
		\\
		&
		=
		v_{n}^{ \, \impulsevariable} 
	\end{alignat}
\end{proof}
The combination of the impulse group with the real numbers as a vector space enables the scaling of Dirac impulses by real numbers to e.g. describe the weight of an impulse which can represent the execution time of a job.
\begin{example}[\impulsespectralspacenamecapital]
	Let $\sum_{\impulseindex = 1}^{3} \shiftedimpulse{\impulseindex}{\impulsevariable}$ be the finite sequence of \shiftedimpulsenameplural{} of Example \ref{example:impulsegroup}. 
	If we want to model that all  \shiftedimpulsenameplural{} are amplified by a factor of $5$, then we can multiply a scalar to the \shiftedimpulsenameplural{} using the distributivity of scalar multiplication:
	\begin{equation}
		5 \impulsespectralspacemult \sum_{\impulseindex = 0}^{2} \shiftedimpulse{\impulseindex}{\impulsevariable} \oset[1.5ex]{\eqref{eq:distributivityscalarmultiplication1}}{=} \sum_{\impulseindex = 0}^{2} 5 \impulsespectralspacemult  \shiftedimpulse{\impulseindex}{\impulsevariable}
	\end{equation}
	which is a vector of the \impulsespectralspacename{}, so that we can further manipulate this vector by using \impulsegroupoperationname{} and \impulsespectralspacemultname{} to describe any combination of different impulses.
\end{example}
%The \impulsespectralspacename{} allows us to model an arbitrary series of Dirac impulses where each of them can have any amplitude, i.e. we can construct any linear combination of impulses.
%We present a vector subspace of the \impulsespectralspacename{} where impulse addition is restricted two the addition of impulses of equal shifts. The result of such an impulse addition is a new impulse of the same shift and with added amplitudes by the distributivity of scalar addition, see \eqref{eq:scalaraddition1} - \eqref{eq:scalaraddition2}.
\subsection{Monovariate impulse spectral space}%todo 채ndere shirac impulse zu shirac
As a special case, the \impulsegroupoperationname{} of two \shiftedimpulsenameplural{} with equal shifts is a new \shiftedimpulsename{} of the same shift and the sum of their amplitudes.
\begin{example}[Addition of equal \shiftedimpulsenameplural{}]
	Let $2 \, \impulsespectralspacemult \, \diracdelta(\impulsevariable - \impulseindex \phase) \in \impulsespectralspace{\impulsevariable}$ and $3 \, \impulsespectralspacemult \, \diracdelta(\impulsevariable - \impulseindex \phase) \in \impulsespectralspace{\impulsevariable}$. Then, the \impulsegroupoperationname
	\begin{equation}
		2 \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex \phase) \impulsegroupoperation 3 \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex \phase) \oset[1.5ex]{\eqref{eq:scalaraddition1}}{=} (2 +_{\realnumbers} 3) \impulsespectralspacemult  \diracdelta(\impulsevariable - \impulseindex \phase) = 5 \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex \phase) 
	\end{equation}
	adds up the amplitudes of the impulses and does not change their shift.
\end{example}
In fact, the set of  \shiftedimpulsenameplural{} $\fixedshiftedimpulseset{\impulsevariable}{
\impulseshift} \coloneqq \{ \shiftedimpulse{\impulseindex}{\impulsevariable}, - \shiftedimpulse{\impulseindex}{\impulsevariable} \}$ that have shifts being multiples of a fixed value $\impulseshift \in \realnumbers$ forms together with the \impulsegroupoperationname{} and \impulsespectralspacemultname{} a vector subspace \cite{hefferon2016linear} of the \impulsespectralspacename{}.
\begin{theorem}[\monovariateimpulsespectralspacenamecapital]\label{corollary:monovariateimpulsespectralspace}
	Let $\impulseshift \in \realnumbers$. Then, the triple $\monovariateimpulsespectralspace{\impulsevariable}{\impulseshift} = (\fixedshiftedimpulseset{\impulsevariable}{
		\impulseshift}, \impulsegroupoperation, \impulsespectralspacemult)$ describes a vector subspace of the \impulsespectralspacename{} and is called the \textbf{\monovariateimpulsespectralspacename}.
\end{theorem}
\begin{proof}
	To show that $\monovariateimpulsespectralspace{\impulsevariable}{\impulseshift} $ is a vector subspace of $ \impulsespectralspace{\impulsevariable}$, we show the closure of \impulsegroupoperationname{} and \impulsespectralspacemultname{} with respect to $\fixedshiftedimpulseset{\impulsevariable}{
		\impulseshift}$ \cite{hefferon2016linear}.
	Let $n,m,N,M \in \naturalnumbers, \impulseshift \in \realnumbers$ and consider the two vectors
	\begin{equation}
		\sum_{i = n}^{n +N} a_{i} \, \diracdelta(x - is) \in \fixedshiftedimpulseset{\impulsevariable}{
			\impulseshift}
	\end{equation}
	and
	\begin{equation}
		\sum_{i = m}^{m +M} b_{i} \, \diracdelta(x - is) \in \fixedshiftedimpulseset{\impulsevariable}{
			\impulseshift}
	\end{equation}
	Let $\{z, z +1, \ldots, z + Z\} =  \{ n, n + 1, \ldots , n + N\} \cap \{ m, m + 1, \ldots, m + M \}$.
	
	Case 1:
	Assume that $n \leq m \leq n + N \leq m + M$. Then, the \impulsegroupoperationname{} of the two vectors is
	\begin{alignat}{1}
		\sum_{i = n}^{m - 1} a_{i} \, \diracdelta(x - is) \impulsegroupoperation \sum_{i = z}^{z + Z} (a_{i} +_{\realnumbers} b_{i}) \cdot \diracdelta(x - is) \impulsegroupoperation \sum_{i = n + N + 1}^{m + M} a_{i} \, \diracdelta(x - is) \in \fixedshiftedimpulseset{\impulsevariable}{
			\impulseshift}
	\end{alignat}

	Case 2: 
	Assume that $n \leq m \leq m + M \leq n + N$. Then, the \impulsegroupoperationname{} of the two vectors is
	\begin{alignat}{1}
		\sum_{i = n}^{m - 1} a_{i} \, \diracdelta(x - is) \impulsegroupoperation \sum_{i = z}^{z + Z} (a_{i} +_{\realnumbers} b_{i}) \cdot \diracdelta(x - is) \impulsegroupoperation \sum_{i = m + M + 1}^{n + N} a_{i} \, \diracdelta(x - is) \in \fixedshiftedimpulseset{\impulsevariable}{
			\impulseshift} 
	\end{alignat}

	Case 3: 
	Assume that $n \leq n + N < m \leq m + M$. Then, the \impulsegroupoperationname{} of the two vectors is
	\begin{alignat}{1}
		\sum_{i = n}^{n + N} a_{i} \, \diracdelta(x - is) \impulsegroupoperation \sum_{i = n + N + 1}^{m - 1} 0 \cdot \diracdelta(x - is) \impulsegroupoperation \sum_{i = m }^{m + M} a_{i} \, \diracdelta(x - is) \in \fixedshiftedimpulseset{\impulsevariable}{
			\impulseshift} 
	\end{alignat}
	Therefore, $\fixedshiftedimpulseset{\impulsevariable}{
	\impulseshift}$ is closed under \impulsegroupoperationname{}.
	To show the closure of \impulsespectralspacemultname{}, consider that for $\lambda \in \realnumbers$, we have
	\begin{alignat}{1}
		\lambda \impulsespectralspacemult \sum_{i = n}^{n +N} a_{i} \, \diracdelta(x - is) 
		\oset[1.5ex]{\eqref{eq:distributivityscalarmultiplication1}}{=}
		\sum_{i = n}^{n +N} \lambda \cdot a_{i} \, \diracdelta(x - is) 
		\in \fixedshiftedimpulseset{\impulsevariable}{\impulseshift}
	\end{alignat}
\end{proof}
The vector space property of the  \shiftedimpulsenameplural{} does not only serve the purpose of knowing that any impulse train can be described by a linear combination of \shiftedimpulsenameplural{}.
The closure of the vector space operations also imply a general specification of impulse trains.
More precisely, we observe that the shift (request time) and the amplitude (execution time) are the parameters required to specify any vector in the \impulsespectralspacename{}.
The reason is that a general vector consists of a series of Dirac impulses described by these two parameters.
One can also define the degree $N$ as the third parameter to describe the number of impulses in case of a periodic impulse train.
Therefore, we derive in the following a method (a matrix operation) constructing any sequence of \shiftedimpulsenameplural{} given a specification of the shifts, amplitudes and degrees of the impulses.
In this way, we can describe any impulse train in the \impulsespectralspacename{} if its specification is known. 


%Intuitively, if we add two Dirac trains $\diracdelta(\impulsevariable - \impulseshift) \impulsegroupoperation \diracdelta(\impulsevariable - 2\impulseshift) \in \fixedshiftedimpulseset{\impulsevariable}{
%	\impulseshift}$ and $\diracdelta(\impulsevariable - 3\impulseshift ) \impulsegroupoperation \diracdelta(\impulsevariable - 4\impulseshift ) \in \fixedshiftedimpulseset{\impulsevariable}{
%	\impulseshift}$ that have shifts being multiples of $\impulseshift \in \realnumbers$, then their \impulsegroupoperationname{} results in another Dirac train of $\fixedshiftedimpulseset{\impulsevariable}{
%	\impulseshift}$:
%\begin{equation}
%	\diracdelta(\impulsevariable - \impulseshift) \impulsegroupoperation \diracdelta(\impulsevariable - 2\impulseshift) \impulsegroupoperation \diracdelta(\impulsevariable - 3\impulseshift ) \impulsegroupoperation \diracdelta(\impulsevariable - 4\impulseshift ) \in \fixedshiftedimpulseset{\impulsevariable}{
%		\impulseshift}
%\end{equation}
%However, if the Dirac trains $\diracdelta(\impulsevariable - r) \impulsegroupoperation \diracdelta(\impulsevariable - 2r) \in \fixedshiftedimpulseset{\impulsevariable}{
%	r}$ and $\diracdelta(\impulsevariable - 3\impulseshift ) \impulsegroupoperation \diracdelta(\impulsevariable - 4\impulseshift ) \in \fixedshiftedimpulseset{\impulsevariable}{
%	\impulseshift}$ respectively have shifts being multiples of $r,\impulseshift \in \realnumbers$ and $r \neq \impulseshift$, then their \impulsegroupoperationname{} results in a Dirac train that is neither in $\fixedshiftedimpulseset{\impulsevariable}{
%	r}$ nor in $\fixedshiftedimpulseset{\impulsevariable}{
%	\impulseshift}$. Instead, their addition is element of the \impulsegroupname{} from Definition \ref{def:impulsegroup}:
%\begin{equation}
%	\diracdelta(\impulsevariable - r) \impulsegroupoperation \diracdelta(\impulsevariable - 2r) \impulsegroupoperation \diracdelta(\impulsevariable - 3\impulseshift ) \impulsegroupoperation \diracdelta(\impulsevariable - 4\impulseshift ) \in \shiftedimpulseset{
%		\impulsevariable}
%\end{equation}
%Therefore, $\fixedshiftedimpulseset{\impulsevariable}{
%	\impulseshift}$ is closed under \impulsegroupoperationname{}, however, adding vectors of two different \monovariateimpulsespectralspacename s $\monovariateimpulsespectralspace{\impulsevariable}{r} $ and $\monovariateimpulsespectralspace{\impulsevariable}{\impulseshift} $  results in a vector of the \impulsespectralspacename{} $\impulsespectralspace{\impulsevariable}$.
%
%addition von 2 mono ergibt multi. proof f체r multi subspace von impulse spectral space. mit closeness

%jetzt brauchen wir einen d dimensionalen vektor um alle phasen zu beschreiben. wenn die phasen aber perioden aufweisen, k철nnen wir mit weniger daten die sequenz beschreiben. wir k철nnen dann z.b. die faltung nutzen um den vektor zu spezifizieren. --> operator. periodische anteile falten, nicht periodische addieren.
%\subsection{\multiperiodicspectralspacenamecapital}
%We present a vector subspace of the \impulsespectralspacename{} where impulse addition is restricted two the addition of impulses of equal shifts. The result of such an impulse addition is a new impulse of the same shift and with added amplitudes by the distributivity of scalar addition, see \eqref{eq:scalaraddition1} - \eqref{eq:scalaraddition2}.
%For example, the addition
%\begin{equation}
%	2 \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex \phase) \impulsegroupoperation 3 \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex \phase) \oset[1.5ex]{\eqref{eq:scalaraddition1}}{=} (2 +_{\realnumbers} 3) \impulsespectralspacemult  \diracdelta(\impulsevariable - \impulseindex \phase) = 5 \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex \phase) 
%\end{equation}
%only adds up the amplitudes of the vectors and does not change their shift. Indeed, the set of vectors of equal shifts form a vector subspace that we call \multiperiodicspectralspacename.
%
%\begin{definition}[\finiteshiftedimpulsenamecapital]\label{def:finiteshiftedimpulsename}
%	Let $\impulsevariable \in \realnumbers$ be a variable, $\multiperiodicimpulsedimension \in \naturalnumbers$, $i \in \{1,2,\dots, \multiperiodicimpulsedimension\}$ an index, $\impulseshift_{i} \in \realnumbers$ and $\impulseindex_{i} \in \naturalnumbers$.
%	Then, 
%	\begin{equation}
%		\shiftedimpulseindexed{\impulseindex}{\multiperiodicimpulsedimension}{\impulsevariable} = \diracdelta(\impulsevariable - \impulseindex_{1} \impulseshift_{1} - \impulseindex_{2} \impulseshift_{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \impulseshift_{\multiperiodicimpulsedimension} )
%	\end{equation}
%	is called \textbf{\finiteshiftedimpulsename}.
%\end{definition}
%\begin{definition}[\impulsespectraldensitynamecapital]\label{def:impulsespectraldensity}
%	Let $\multiperiodicimpulsedimension \in \naturalnumbers, \degreevector \coloneqq [\degreevectorcomponent{1}, \degreevectorcomponent{2}, \dots, \degreevectorcomponent{\multiperiodicimpulsedimension}] \in \naturalnumberswithinfinityvectors{\multiperiodicimpulsedimension}, \phasevector \coloneqq [\phasevectorcomponent{1}, \phasevectorcomponent{2}, \dots, \phasevectorcomponent{\multiperiodicimpulsedimension}] \in \realnumbersvector{\multiperiodicimpulsedimension}$. The vector
%	\begin{alignat}{1}
%		\impulsespectraldensity{\phasevector}{\degreevector}{\impulsevariable} \coloneqq \sum_{\impulseindex_{1} = 1}^{\degreevectorcomponent{1}} \dots \sum_{\impulseindex_{\multiperiodicimpulsedimension} = 1}^{\degreevectorcomponent{\multiperiodicimpulsedimension}}
%		\amplitudevector{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} \cdot \diracdelta(\impulsevariable - \impulseindex_{1} \phasevectorcomponent{1} - \impulseindex_{2} \phasevectorcomponent{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \phasevectorcomponent{\multiperiodicimpulsedimension} ) \eqqcolon \impulsespectraldensityeinstein{\amplitude}{\impulseindex}{\phase}{\multiperiodicimpulsedimension}
%	\end{alignat}
%	with $\amplitudevector{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} \in \realnumbers$.
%\end{definition}

%\begin{definition}[\multiperiodicspectralspacenamecapital]\label{def:multiperiodicspectralspace}
%	The tuple $\multiperiodicimpulsespace{\impulsevariable} = (\multiperiodicimpulseset{\impulsevariable}, \impulsegroupoperation,\impulsespectralspacemult)$ is called \textbf{\multiperiodicspectralspacename} where 
%	\begin{equation}
%		\multiperiodicimpulseset{\impulsevariable} = \{\shiftedimpulseindexed{\impulseindex}{i}{\impulsevariable} , - \shiftedimpulseindexed{\impulseindex}{i}{\impulsevariable} , \{ \shiftedimpulseindexed{\impulseindex}{i}{\impulsevariable} \} \, | \, i \in \{ 1,2,\dots, \multiperiodicimpulsedimension \} \} \subseteq \shiftedimpulseset{\impulsevariable}
%	\end{equation}
%	and $\impulsegroupoperation$ and $\multiperiodicimpulsedimension$ are defined by Definition \ref{def:impulsespectralspace}.
%\end{definition}
%\begin{definition}[\multiperiodicspectralspacenamecapital]\label{def:multiperiodicspectralspace}
%	The tuple $\multiperiodicimpulsespace{\phasevector}{\degreevector}{\impulsevariable}= (\multiperiodicimpulseset{\phasevector}{\degreevector}{\impulsevariable}, \impulsegroupoperation, \impulsespectralspacemult)$ is called \textbf{\multiperiodicspectralspacename} where
%	\begin{equation}
%		\multiperiodicimpulseset{\phasevector}{\degreevector}{\impulsevariable} = \left\{ \sum_{\impulseindex_{1} = 1}^{\degreevectorcomponent{1}} \dots \sum_{\impulseindex_{\multiperiodicimpulsedimension} = 1}^{\degreevectorcomponent{\multiperiodicimpulsedimension}}
%		\amplitudevector{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} \cdot \diracdelta(\impulsevariable - \impulseindex_{1} \phasevectorcomponent{1} - \impulseindex_{2} \phasevectorcomponent{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \phasevectorcomponent{\multiperiodicimpulsedimension} ) \, \bigg| \,  \amplitudevector{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} \in \realnumbers \right\}
%	\end{equation}
%	is the set of \impulsespectraldensitynameplural{}, and $\impulsegroupoperation$ and $\impulsespectralspacemult$ and \impulsegroupoperationname{} and \impulsespectralspacemultname{} of the \impulsespectralspacename{} (Definition \ref{def:impulsespectralspace}). 
%	$\multiperiodicimpulsedimension \in \naturalnumbers$ is the dimension of the \multiperiodicspectralspacename.
%\end{definition}
%\begin{theorem}[\multiperiodicspectralspacenamecapital]\label{theorem:multiperiodicspectralspace}
%	The \multiperiodicspectralspacename{} $\multiperiodicimpulsespace{\phasevector}{\degreevector}{\impulsevariable} $ is a vector subspace of the \impulsespectralspacename{} $\impulsespectralspace{\impulsevariable}$ of \textbf{dimension} $\multiperiodicimpulsedimension \in \naturalnumbers$.
%\end{theorem}
%\begin{proof}
%	The proof shows that any linear combination of vectors in $	\multiperiodicimpulseset{\phasevector}{\degreevector}{\impulsevariable} $ is again in $	\multiperiodicimpulseset{\phasevector}{\degreevector}{\impulsevariable}$ to show the closure of $	\multiperiodicimpulseset{\phasevector}{\degreevector}{\impulsevariable} $ under the vector space operations $\impulsegroupoperation$ and $\impulsespectralspacemult$.
%	To this end, let $\impulsespectraldensityeinstein{a}{\impulseindex}{\phase}{\multiperiodicimpulsedimension}, \impulsespectraldensityeinstein{b}{\impulseindex}{\phase}{\multiperiodicimpulsedimension}, \impulsespectraldensityeinstein{c}{\impulseindex}{\phase}{\multiperiodicimpulsedimension} \in \multiperiodicimpulseset{\phasevector}{\degreevector}{\impulsevariable}$ and $\alpha,\beta \in \realnumbers$.
%	Then,
%	\begin{alignat}{1}
%		&
%		\alpha \impulsespectralspacemult \impulsespectraldensityeinstein{a}{\impulseindex}{\phase}{\multiperiodicimpulsedimension} 
%		\impulsegroupoperation
%		\beta \impulsespectralspacemult \impulsespectraldensityeinstein{b}{\impulseindex}{\phase}{\multiperiodicimpulsedimension} 
%		\\
%		=
%		&
%		\alpha \impulsespectralspacemult
%		\sum_{\impulseindex_{1} = 1}^{\degreevectorcomponent{1}} \dots \sum_{\impulseindex_{\multiperiodicimpulsedimension} = 1}^{\degreevectorcomponent{\multiperiodicimpulsedimension}}
%		\amplitudevector{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex_{1} \phasevectorcomponent{1} - \impulseindex_{2} \phasevectorcomponent{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \phasevectorcomponent{\multiperiodicimpulsedimension} )
%		\nonumber
%		\\
%		\impulsegroupoperation
%		&
%		\beta \impulsespectralspacemult
%		\sum_{\impulseindex_{1} = 1}^{\degreevectorcomponent{1}} \dots \sum_{\impulseindex_{\multiperiodicimpulsedimension} = 1}^{\degreevectorcomponent{\multiperiodicimpulsedimension}}
%		b_{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex_{1} \phasevectorcomponent{1} - \impulseindex_{2} \phasevectorcomponent{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \phasevectorcomponent{\multiperiodicimpulsedimension} )
%		\\
%		\oset[1.5ex]{\mathclap{\eqref{eq:distributivityscalarmultiplication1}}}{=}
%		&
%		\sum_{\impulseindex_{1} = 1}^{\degreevectorcomponent{1}} \dots \sum_{\impulseindex_{\multiperiodicimpulsedimension} = 1}^{\degreevectorcomponent{\multiperiodicimpulsedimension}} \alpha \impulsespectralspacemult
%		(\amplitudevector{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex_{1} \phasevectorcomponent{1} - \impulseindex_{2} \phasevectorcomponent{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \phasevectorcomponent{\multiperiodicimpulsedimension} ))
%		\nonumber
%		\\
%		\impulsegroupoperation
%		&
%		\sum_{\impulseindex_{1} = 1}^{\degreevectorcomponent{1}} \dots \sum_{\impulseindex_{\multiperiodicimpulsedimension} = 1}^{\degreevectorcomponent{\multiperiodicimpulsedimension}} 		\beta \impulsespectralspacemult
%		(b_{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex_{1} \phasevectorcomponent{1} - \impulseindex_{2} \phasevectorcomponent{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \phasevectorcomponent{\multiperiodicimpulsedimension} ))
%		\\
%		\oset[1.5ex]{\mathclap{\eqref{eq:associativityscalarmultiplication1}}}{=}
%		&
%		\sum_{\impulseindex_{1} = 1}^{\degreevectorcomponent{1}} \dots \sum_{\impulseindex_{\multiperiodicimpulsedimension} = 1}^{\degreevectorcomponent{\multiperiodicimpulsedimension}} (\alpha \cdot_{\realnumbers}
%		\amplitudevector{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}}) \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex_{1} \phasevectorcomponent{1} - \impulseindex_{2} \phasevectorcomponent{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \phasevectorcomponent{\multiperiodicimpulsedimension} )
%		\nonumber
%		\\
%		\impulsegroupoperation
%		&
%		\sum_{\impulseindex_{1} = 1}^{\degreevectorcomponent{1}} \dots \sum_{\impulseindex_{\multiperiodicimpulsedimension} = 1}^{\degreevectorcomponent{\multiperiodicimpulsedimension}} 		(\beta \cdot_{\realnumbers}
%		b_{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}}) \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex_{1} \phasevectorcomponent{1} - \impulseindex_{2} \phasevectorcomponent{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \phasevectorcomponent{\multiperiodicimpulsedimension} )
%		\\
%		\oset[1.5ex]{\mathclap{\eqref{eq:scalaraddition1}}}{=}
%		&
%		\sum_{\impulseindex_{1} = 1}^{\degreevectorcomponent{1}} \dots \sum_{\impulseindex_{\multiperiodicimpulsedimension} = 1}^{\degreevectorcomponent{\multiperiodicimpulsedimension}} 		(\alpha \cdot_{\realnumbers}
%		\amplitudevector{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} +_{\realnumbers} \beta \cdot_{\realnumbers}
%		b_{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}}) \impulsespectralspacemult \diracdelta(\impulsevariable - \impulseindex_{1} \phasevectorcomponent{1} - \impulseindex_{2} \phasevectorcomponent{2} - \dots - \impulseindex_{\multiperiodicimpulsedimension} \phasevectorcomponent{\multiperiodicimpulsedimension} )
%		\\
%		\in
%		&
%		 \multiperiodicimpulseset{\phasevector}{\degreevector}{\impulsevariable}
%	\end{alignat}
%	 since $\alpha \cdot_{\realnumbers}
%	 \amplitudevector{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} +_{\realnumbers} \beta \cdot_{\realnumbers}
%	 b_{\impulseindex_{1},\dots,\impulseindex_{\multiperiodicimpulsedimension}} \in \realnumbers$.
%\end{proof}





















%\subsection{Impulse space}
%	\begin{definition}[Impulse space]\label{def:impulsespace}
%	The \textbf{impulse space} $\impulsespace = (\impulsespaceset, \impulsespaceadd, \impulsespacescalarmult)$ is defined by the set
%	\begin{equation}
%		\impulsespaceset = \left\{ \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  a_{\repetitionindex} \cdot \diracdelta(\timepoint - \repetitionindex \period)  \, \bigg| \, a_{\repetitionindex}, \period \in \realnumbers \, \forall \repetitionindex \in \{0,1, \dots \numberofrepetitions-1\}  \right\}
%	\end{equation}
%	and the operations 
%	\begin{alignat}{3}
%		\impulsespaceadd &\colon \impulsespaceset \times \impulsespaceset \to \impulsespaceset,& \left( \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  a_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period), \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  b_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period) \right) \mapsto& \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  (a_{\repetitionindex} + b_{\repetitionindex})  \diracdelta(\timepoint - \repetitionindex \period) \\
%		\impulsespacescalarmult &\colon \realnumbers \times \impulsespaceset \to \impulsespaceset, & \left( \lambda, \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  a_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period) \right) \mapsto& \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  \lambda \cdot a_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period) 
%	\end{alignat}
%	where $\impulsedensity_{\period}^{<\numberofrepetitions} (\timepoint) \coloneqq \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  a_{\repetitionindex} \cdot \diracdelta(\timepoint - \repetitionindex \period)$ is called \textbf{impulse density} with \textbf{weight} $a_{\repetitionindex}$, \textbf{shift} $- \repetitionindex \period$ and \textbf{degree} $\numberofrepetitions$.
%\end{definition}
%
%
%
%\begin{definition}[Infix notation]
%	Let $\impulsespace = (\impulsespaceset, \impulsespaceadd, \impulsespacescalarmult)$ be the impulse space of Definition \ref{def:impulsespace}.
%	Then, the operations $\impulsespaceadd$ and $\impulsespacescalarmult$ can be written in infix notation as follows:
%	\begin{alignat}{1}
%		\sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  a_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period) \impulsespaceadd \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  b_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period) & \coloneqq 
%		\impulsespaceadd \left( \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  a_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period), \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  b_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period) \right) 
%		\\
%		\lambda \impulsespacescalarmult \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  a_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period)
%		& \coloneqq
%		\impulsespacescalarmult  
%		\left( \lambda, \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  a_{\repetitionindex}  \diracdelta(\timepoint - \repetitionindex \period) \right)
%	\end{alignat}
%\end{definition}
%
%Since the impulse space allows to operate impulse vectors of equal shifts and degree, we can formulate the following short-form notation for such vectors.
%\begin{definition}[Short-form impulse vector]
%	Let $\impulsedensity_{\period}^{<\numberofrepetitions} (\timepoint) \in \impulsespaceset$ be an impulse vector. $\impulsedensity_{\period}^{<\numberofrepetitions} (\timepoint)$ is shortly denoted by
%	\begin{equation}
%	a_{n}\delta^{n}	\coloneqq \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  a_{\repetitionindex} \cdot \diracdelta(\timepoint - \repetitionindex \period) = \impulsedensity_{\period}^{<\numberofrepetitions} (\timepoint)
%	\end{equation}
%\end{definition}
%
%\begin{theorem}[Impulse vector space]\label{theorem:impulsespace}
%	The impulse space $\impulsespace = (\impulsespaceset, \impulsespaceadd, \impulsespacescalarmult)$ as defined by Definition \ref{def:impulsespace} is a vector space where the operations $\impulsespaceadd$ and $\impulsespacescalarmult$ are vector addition and scalar multiplication.
%\end{theorem}
%\begin{proof}
%	Let $\boldsymbol{u} = \sum_{n=1}^{N-1} a_{n}\delta(t - (n-1)p), \boldsymbol{v} = \sum_{n=1}^{N-1} b_{n}\delta(t - (n-1)p), \boldsymbol{w} = \sum_{n=1}^{N-1} c_{n}\delta(t - (n-1)p) \in \impulsespaceset$.
%	
%	Closure of $\impulsespaceadd$. Since $c_{n} \in \realnumbers$, we can set $c_{n} = a_{n} + b_{n}, \forall n \in \{ 1, 2, \dots, N-1 \}$.
%	Therefore,
%	\begin{alignat}{1}
%		\boldsymbol{u} \impulsespaceadd \boldsymbol{v} 
%		&
%		=
%		a_{n}\delta^{n}  \impulsespaceadd b_{n}\delta^{n}  = (a_{n}\delta^{n} + b_{n}\delta^{n} ) = c_{n}\delta^{n}  = \boldsymbol{w} \in \impulsespaceset
%	\end{alignat}
%	
%	Closure of scalar multiplication. Let $\lambda \in \realnumbers$. Then, there exist $d_{n} \in \realnumbers, \forall n \in \{1,2,\dots, N-1\}$, such that $d_{n} = \lambda \cdot a_{n}$. 
%	Therefore,
%	\begin{alignat}{1}
%		\lambda \impulsespacescalarmult \boldsymbol{u} 
%		&
%		= 
%		\lambda \impulsespacescalarmult a_{n}\delta^{n}
%		=
%		\sum_{n=1}^{N-1} \lambda \cdot a_{n}\delta(t - (n-1)p)
%		=
%		\sum_{n=1}^{N-1} d_{n}\delta(t - (n-1)p) \in \impulsespaceset
%	\end{alignat}
%	
%	Associativity of $\impulsespaceadd$.
%	\begin{alignat}{1}
%		(\boldsymbol{u} \impulsespaceadd \boldsymbol{v}) \impulsespaceadd \boldsymbol{w}
%		&
%		=
%		(a_{n}\delta^{n} \impulsespaceadd b_{n}\delta^{n}) \impulsespaceadd c_{n}\delta^{n}
%		\\
%		&
%		=
%		(a_{n} + b_{n})\delta^{n} \impulsespaceadd c_{n}\delta^{n} 
%		\\
%		&
%		=
%		((a_{n} + b_{n}) + c_{n})\delta^{n} 
%		\\
%		&
%		\oset[1.5ex]{\mathclap{\mathrm{asso. \, in \,} \realnumbers}}{=}
%		(a_{n} + (b_{n} + c_{n}))\delta^{n} 
%		\\
%		&
%		= a_{n}\delta^{n} \impulsespaceadd (b_{n} + c_{n})\delta^{n}
%		\\
%		&
%		=
%		a_{n}\delta^{n} \impulsespaceadd (b_{n}\delta^{n} \impulsespaceadd c_{n}\delta^{n} ) 
%		\\
%		&
%		= \boldsymbol{u} \impulsespaceadd (\boldsymbol{v} \impulsespaceadd \boldsymbol{w})
%	\end{alignat}
%	
%	Commutativity of $\impulsespaceadd$.
%	\begin{alignat}{1}
%		\boldsymbol{u} \impulsespaceadd \boldsymbol{v}
%		&
%		=
%		a_{n} \delta^{n} \impulsespaceadd b_{n}\delta^{n}
%		\\
%		&
%		=
%		(a_{n} + b_{n})\delta^{n}
%		\\
%		&
%		\oset[1.5ex]{\mathclap{\mathrm{comm. \, in \,} \realnumbers}}{=}
%		(b_{n} + a_{n})\delta^{n}
%		\\
%		&
%		=
%		b_{n} \delta^{n} \impulsespaceadd a_{n}\delta^{n}
%		\\
%		&
%		=
%		\boldsymbol{v} \impulsespaceadd \boldsymbol{u}
%	\end{alignat}
%	
%	Existence of neutral element of $\impulsespaceadd$. 
%	Let $\boldsymbol{0} = \sum_{n=1}^{N-1} 0 \cdot \delta(t- (n-1)p)$.
%	Then,
%	\begin{alignat}{1}
%		\boldsymbol{0} \impulsespaceadd \boldsymbol{u}
%		&
%		=
%		0 \cdot \delta^{n} \impulsespaceadd a_{n} \delta^{n}
%		\\
%		&
%		=
%		(0 + a_{n}) \cdot \delta^{n}
%		\\
%		&
%		\oset[1.5ex]{\mathclap{\mathrm{neutral \, in \,}\realnumbers}}{=}
%		a_{n} \cdot \delta^{n}
%		\\
%		&
%		=
%		\boldsymbol{u}
%	\end{alignat}
%	
%	Existence of inverse element of $\impulsespaceadd$.
%	Let $\boldsymbol{u^\prime} = \sum_{n=1}^{N} (-a_{n}) \delta(t - np)$.
%	Then,
%	\begin{alignat}{1}
%		\boldsymbol{u}\impulsespaceadd \boldsymbol{u^\prime} 
%		&
%		=
%		a_{n}\delta^{n} \impulsespaceadd (- a_{n})\delta^{n}
%		\\
%		&
%		=
%		(a_{n} + (- a_{n})) \delta^{n}
%		\\
%		&
%		\oset[1.5ex]{\mathclap{\mathrm{inverse \, in \, \realnumbers}}}{=}
%		0 \cdot \delta^{n}
%		\\
%		&
%		=
%		\boldsymbol{0}
%	\end{alignat}
%	
%	Distributivity of scalar multiplication. Let $\lambda, \alpha \in \realnumbers$.
%	Then,
%	\begin{alignat}{1}
%		(\lambda + \alpha) \impulsespacescalarmult \boldsymbol{u}
%		&
%		=
%		(\lambda + \alpha) \impulsespacescalarmult a_{n}\delta^{n}
%		\\
%		&
%		=
%		(\lambda + \alpha) \cdot a_{n} \delta^{n}
%		\\
%		&
%		\oset[1.5ex]{\mathclap{\mathrm{distr. \, in \,} \realnumbers}}{=}
%		(\lambda \cdot a_{n} + \alpha \cdot a_{n}) \cdot \delta^{n}
%		\\
%		&
%		=
%		\lambda \cdot a_{n} \cdot \delta^{n} \impulsespaceadd \alpha \cdot a_{n} \cdot \delta^{n}
%		\\
%		&
%		=
%		\lambda \impulsespacescalarmult \boldsymbol{u} \impulsespaceadd \alpha \impulsespacescalarmult \boldsymbol{u}
%	\end{alignat}
%	
%	Distributivity of vector addition. 
%	\begin{alignat}{1}
%		\lambda \impulsespacescalarmult (\boldsymbol{u} \impulsespaceadd \boldsymbol{v})
%		&
%		=
%		\lambda \impulsespacescalarmult (a_{n} \delta^{n} \impulsespaceadd b_{n}\delta^{n})
%		\\
%		&
%		=
%		\lambda \impulsespacescalarmult ((a_{n} + b_{n}) \cdot \delta^{n})
%		\\
%		&
%		=
%		(\lambda \cdot(a_{n} + b_{n}))\cdot \delta^{n}
%		\\
%		&
%		\oset[1.5ex]{\mathclap{\mathrm{distr. \, in \,} \realnumbers}}{=}
%		(\lambda \cdot a_{n} + \lambda \cdot b_{n})\cdot \delta^{n}
%		\\
%		&
%		=
%		\lambda \cdot a_{n}  \delta^{n} \impulsespaceadd  \lambda \cdot b_{n} \delta^{n}
%		\\
%		&
%		=
%		\lambda \impulsespacescalarmult \boldsymbol{u} \impulsespaceadd \lambda \impulsespacescalarmult \boldsymbol{v}
%	\end{alignat}
%	
%	Associativity of scalar multiplication. 
%	\begin{alignat}{1}
%		\alpha \impulsespacescalarmult (\lambda \impulsespacescalarmult \boldsymbol{u})
%		&
%		=
%		\alpha \impulsespacescalarmult (\lambda \impulsespacescalarmult a_{n}\delta^{n})
%		\\
%		&
%		=
%		\alpha \impulsespacescalarmult ((\lambda \cdot a_{n})\delta^{n})
%		\\
%		&
%		=
%		(\alpha \cdot(\lambda \cdot a_{n}))\delta^{n}
%		\\
%		&
%		\oset[1.5ex]{\mathclap{\mathrm{asso. \, in \,} \realnumbers}}{=}
%		((\alpha \cdot\lambda) \cdot a_{n}))\delta^{n}
%		\\
%		&
%		=
%		(\alpha \cdot \lambda) \impulsespacescalarmult a_{n}\delta^{n}
%		\\
%		&
%		=
%		(\alpha \cdot \lambda) \impulsespacescalarmult \boldsymbol{u}
%	\end{alignat}
%	
%	Neutral element of scalar multiplication.
%	\begin{alignat}{1}
%		1 \impulsespacescalarmult \boldsymbol{u}
%		&
%		=
%		1 \impulsespacescalarmult a_{n} \delta^{n}
%		\\
%		&
%		=
%		1 \cdot a_{n}\delta^{n}	
%		\\
%		&
%		\oset[1.5ex]{\mathclap{\mathrm{neutral \, in \,}\realnumbers}}{=}
%		a_{n}\delta^{n}
%		\\
%		&
%		=
%		\boldsymbol{u}
%	\end{alignat}
%\end{proof}
%
%\begin{example}
%	A sequence of events that occurs at time points 0, 5, 10 and 15 is described by a vector of period $\period = 5$ and $\numberofrepetitions = 4$ repetitions:
%	\begin{equation}
%		\impulsedensity(\timepoint) = \sum_{\repetitionindex = 0}^{3} \diracdelta(\timepoint - 5\repetitionindex)
%	\end{equation}
%	If this sequence of events has execution times $\executiontimevector = (2 \, 3 \, 4 \, 5)^{\transposed}$, they can be described by:
%	\begin{alignat}{1}
%		\executiontimevector \cdot \impulsedensity(\timepoint)
%		&
%		=
%		\begin{pmatrix}
%			2 \\ 3 \\ 4 \\ 5
%		\end{pmatrix}
%		\cdot
%		\begin{pmatrix}
%			\diracdelta(\timepoint) \\ \diracdelta(\timepoint - \period) \\ \diracdelta(\timepoint - 2\period) \\ \diracdelta(\timepoint - 3\period) 
%		\end{pmatrix}
%		\\
%		&
%		=
%		2 \diracdelta(\timepoint) + 3 \diracdelta(\timepoint - \period) +4  \diracdelta(\timepoint - 2\period) + 5 \diracdelta(\timepoint - 3\period) 
%		\\
%		&
%		= 
%		\sum_{\repetitionindex = 0}^{3} \executiontimevectorcomponent{\repetitionindex}\diracdelta(\timepoint - 5\repetitionindex)
%	\end{alignat}
%	If we want to delete the event at time point $10$, we can use vector addition to add $\executiontimevector \cdot \impulsedensity(\timepoint)$ by itself using the scalars $\executiontimevector^{\prime} = (0 \, 0 \, -4 \, 0)^{\transposed}$:
%	\begin{alignat}{1}
%		\executiontimevector \cdot \impulsedensity(\timepoint) + \executiontimevector^{\prime} \cdot \impulsedensity(\timepoint)
%		&
%		=
%		(\executiontimevector + \executiontimevector^{\prime}) \cdot \impulsedensity(\timepoint) 
%		\\
%		&
%		=
%		\begin{pmatrix}
%			2 \\ 3 \\ 4 \\ 5
%		\end{pmatrix}
%		+
%		\begin{pmatrix}
%			0 \\ 0 \\ -4 \\ 0
%		\end{pmatrix}
%		\cdot
%		\begin{pmatrix}
%			\diracdelta(\timepoint) \\ \diracdelta(\timepoint - \period) \\ \diracdelta(\timepoint - 2\period) \\ \diracdelta(\timepoint - 3\period) 
%		\end{pmatrix}
%		= 
%		\begin{pmatrix}
%			2 \\ 3 \\ 0 \\ 5
%		\end{pmatrix}
%		\cdot
%		\begin{pmatrix}
%			\diracdelta(\timepoint) \\ \diracdelta(\timepoint - \period) \\ \diracdelta(\timepoint - 2\period) \\ \diracdelta(\timepoint - 3\period) 
%		\end{pmatrix}
%		\\
%		&
%		=
%		2 \diracdelta(\timepoint) + 3 \diracdelta(\timepoint - \period) + 5 \diracdelta(\timepoint - 3\period) 
%	\end{alignat}
%\end{example}
%However, we cannot add two vectors of different periods. Vector addition is only defined for two vectors of equal periods $\period$.
%The addition of two vectors 
%$\impulsedensity(\timepoint) = \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  \executiontimevectorcomponent{\repetitionindex} \cdot \diracdelta(\timepoint - \repetitionindex \period)$ 
%and 
%$\impulsedensity^{\prime}(\timepoint) = \sum_{m = 0}^{M-1}  d_{m} \cdot \diracdelta(\timepoint - m q)$ 
%of different periods $\period$ and $q$ can be realized by the convolution:
%\begin{alignat}{1}
%	\impulsedensity \ast \impulsedensity^{\prime}(\timepoint) 
%	&
%	= 
%	\int_{-\infty}^{\infty} \sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  \executiontimevectorcomponent{\repetitionindex} \cdot \diracdelta(\timepoint - \tau - \repetitionindex \period) \cdot \sum_{m = 0}^{M-1}  d_{m} \cdot \diracdelta(\tau - m q) \,d\tau
%	\\
%	&
%	=
%	\sum_{\repetitionindex = 0}^{\numberofrepetitions-1}  \sum_{m = 0}^{M-1}  \executiontimevectorcomponent{\repetitionindex} \cdot d_{m} \cdot \diracdelta(\tau -\repetitionindex \period - m q) \, .
%\end{alignat}
%The convolution creates a new vector of two different periods. However, the convolution does not span a new vector space. For example, each event of the vector is scaled by the factor $c_n \cdot d_m$. If the vector shall have the weights
%\begin{alignat}{1}
%	c_0 \cdot d_0 &= 1 \label{eq:weights1} \\
%	c_1 \cdot d_0 &= 1 \label{eq:weights2} \\
%	c_0 \cdot d_1 &= 1 \label{eq:weights3} \\
%	c_1 \cdot d_1 &= 0 \label{eq:weights4}
%\end{alignat}
%then there does not exist a solution to this set of equations. This means there do not exist two impulse vectors whose convolution results in a vector having the weights as defined by  \eqref{eq:weights1} - \eqref{eq:weights4}.
%We have to add further variables to the system of equations so that a solution can exist. For example, if we add the variables
%\begin{alignat}{1}
%	c_0 \cdot d_0 + e_0 \cdot f_0  &= 1 \label{eq:weights5} \\
%	c_1 \cdot d_0 + e_1 \cdot f_0 &= 1 \label{eq:weights6} \\
%	c_0 \cdot d_1 + e_0 \cdot f_1 &= 1 \label{eq:weights7} \\
%	c_1 \cdot d_1 + e_1 \cdot f_1 &= 0 \label{eq:weights8}
%\end{alignat}
%then a solution exist, e.g. with the assignment $c_0 = d_0 = c_1 = d_1 = f_1 = 1$, $e_0 = f_0 = 0$ and $e_1 = -1$.
%To realize this approach we can add two further convolved vectors to the already convolved vectors. Generalizing, we describe a new vector space in which we can realize the generation of such impulses. 
%\section{Multivariate impulse space}\label{section:multivariateimpulsespace}
% We present the vector space of multivariate impulses. 
%\begin{definition}[Multivariate impulse space]\label{def:multivariateimpulsevectorspace}
%		The \textbf{multivariate impulse space} $\multivariateimpulsespace = (\multivariateimpulsespaceset, \multivariateimpulsespaceadd, \multivariateimpulsespacescalarmult)$ is defined by the set
%	\begin{alignat}{2}
%		\multivariateimpulsespaceset &= \bigg\{
%		&&
%		\sum_{\repetitionindex_{1} = 0}^{\numberofrepetitionsvectorcomponent{1}-1} \dots \sum_{\repetitionindex_{\numberofcomponents} = 0}^{\numberofrepetitionsvectorcomponent{\numberofcomponents}-1}
%		a_{\repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}} \cdot \diracdelta(\timepoint - \repetitionindex_{1} \period_{1} - \dots - \repetitionindex_{\numberofcomponents} \period_{\numberofcomponents}) \nonumber
%		\\
% 		&&&
%		\bigg| \, 
%		a_{\repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}}, \periodvectorcomponent{\componentindex} \in \realnumbers
%		 \forall 	\componentindex \in  \naturalnumbersfromto{1}{\numberofcomponents},  \repetitionindex_{\componentindex} \in \naturalnumbersfromto{0}{\numberofrepetitionsvectorcomponent{\componentindex} - 1} \bigg\}
%		 \\
%	\end{alignat}
%	with short form $a^{\repetitionindex}\period_{\repetitionindex} \coloneqq \sum_{\repetitionindex_{1} = 0}^{\numberofrepetitionsvectorcomponent{1}-1} \dots \sum_{\repetitionindex_{\numberofcomponents} = 0}^{\numberofrepetitionsvectorcomponent{\numberofcomponents}-1}
%	a_{\repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}} \cdot \diracdelta(\timepoint - \repetitionindex_{1} \period_{1} - \dots - \repetitionindex_{\numberofcomponents} \period_{\numberofcomponents})$
%	and the operations 
%	\begin{alignat}{4}
%		\multivariateimpulsespaceadd  \colon && \multivariateimpulsespaceset \times \multivariateimpulsespaceset 
%		&
%		\to \multivariateimpulsespaceset, &
%		\left(
%		a^{\repetitionindex}\period_{\repetitionindex},
%		b^{\repetitionindex}\period_{\repetitionindex}
%		\right)
%		&
%		 \mapsto 
%		(a^{\repetitionindex} + b^{\repetitionindex})\period_{\repetitionindex}
%		 \\
%		\multivariateimpulsespacescalarmult \colon && \realnumbers \times \multivariateimpulsespaceset 
%		&
%		\to  \multivariateimpulsespaceset,&
%		\left( \lambda, a^{\repetitionindex}\period_{\repetitionindex}, \right) 
%		&
%		\mapsto	(\lambda \cdot 	a^{\repetitionindex} )\period_{\repetitionindex}
%	\end{alignat}
%	where $\multivariateimpulsedensity_{\periodvector}^{\numberofrepetitionsvector} (\timepoint) \coloneqq \sum_{\repetitionindex_{1} = 0}^{\numberofrepetitionsvectorcomponent{1}-1} \dots \sum_{\repetitionindex_{\numberofcomponents} = 0}^{\numberofrepetitionsvectorcomponent{\numberofcomponents}-1}
%	a_{\repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}} \cdot \diracdelta(\timepoint - \repetitionindex_{1} \period_{1} - \dots - \repetitionindex_{\numberofcomponents} \period_{\numberofcomponents}) = 	a_{\repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}} \diracdelta^{ \repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}}_{\period_{1},\dots, \period_{\numberofcomponents}}$ is called \textbf{multivariate impulse density} with \textbf{weight} $	a_{\repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}}$, \textbf{shift} $\repetitionindex_1 \period_1 + \dots + \repetitionindex_{\numberofcomponents} \period_{\numberofcomponents}$ and \textbf{degree} $M \times N$.
%\end{definition}
%\begin{theorem}[Multivariate impulse vector space]\label{theorem:multivariateimpulsevectorspace}
%		The multivariate impulse space $\impulsespace = (\impulsespaceset, \impulsespaceadd, \impulsespacescalarmult)$ as defined by Definition \ref{def:multivariateimpulsevectorspace} is a vector space where the operations $\multivariateimpulsespaceadd$ and $\multivariateimpulsespacescalarmult$ are vector addition and scalar multiplication.
%\end{theorem}
%\begin{proof}
%	The proof is shown in Appendix \ref{appendix:multivariateimpulsespace}.
%\end{proof}
%We describe the time points at which impulses occur by an $\numberofcomponents$-dimensional tensor since we need to access these time points in later theorems.
%\begin{definition}[Impulse time tensor]\label{def:impulsetimetensor}
%	Let $\multivariateimpulsedensity_{\periodvector}^{\numberofrepetitionsvector} (\timepoint) \coloneqq \sum_{\repetitionindex_{1} = 0}^{\numberofrepetitionsvectorcomponent{1}-1} \dots \sum_{\repetitionindex_{\numberofcomponents} = 0}^{\numberofrepetitionsvectorcomponent{\numberofcomponents}-1}
%	a_{\repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}} \cdot \diracdelta(\timepoint - \repetitionindex_{1} \period_{1} - \dots - \repetitionindex_{\numberofcomponents} \period_{\numberofcomponents}) = 	a_{\repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}} \diracdelta^{ \repetitionindex_{1}, \dots, \repetitionindex_{\numberofcomponents}}_{\period_{1},\dots, \period_{\numberofcomponents}}$ be a multivariate impulse density. Then, the time points at which the impulses occur are described by the tensor 
%	\begin{equation}
%		T_{\repetitionindex_{1},\dots,\repetitionindex_{\numberofcomponents}} = \repetitionindex_{1}\periodvectorcomponent{1} + \dots + \repetitionindex_{\numberofcomponents} \periodvectorcomponent{\numberofcomponents}
%	\end{equation}
%	that is called \textbf{impulse time tensor}.
%\end{definition}
