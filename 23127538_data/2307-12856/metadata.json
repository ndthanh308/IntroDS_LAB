{
  "title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
  "authors": [
    "Izzeddin Gur",
    "Hiroki Furuta",
    "Austin Huang",
    "Mustafa Safdari",
    "Yutaka Matsuo",
    "Douglas Eck",
    "Aleksandra Faust"
  ],
  "submission_date": "2023-07-24T14:56:30+00:00",
  "revised_dates": [
    "2023-10-03T00:41:53+00:00",
    "2023-10-04T00:15:10+00:00",
    "2024-02-27T02:09:09+00:00"
  ],
  "abstract": "Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web automation. However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML. We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions. WebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via Python programs generated from those. We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization. We empirically demonstrate that our modular recipe improves the success on real websites by over 50%, and that HTML-T5 is the best model to solve various HTML understanding tasks; achieving 18.7% higher success rate than the prior method on MiniWoB web automation benchmark, and SoTA performance on Mind2Web, an offline task planning evaluation.",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CL"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.12856",
  "pdf_url": null,
  "comment": "Accepted to ICLR 2024 (Oral)",
  "num_versions": null,
  "size_before_bytes": 6547040,
  "size_after_bytes": 1138075
}