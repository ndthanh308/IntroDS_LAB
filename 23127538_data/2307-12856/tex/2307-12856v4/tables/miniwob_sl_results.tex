\begin{table}[t]
\begin{center}
\begin{small}
%\begin{sc}
\scalebox{1.0}{
\begin{tabular}{lrrr}
\toprule
\textbf{Models} & \textbf{Data} & \textbf{Success} & \textbf{Diff.}\\
\midrule
CC-Net~\citep{humphreys2022data} & 2.4M & 32.0\% & -- \\
WebN-T5-XL~\citep{gur2022html} & 12K & 48.4\% & -- \\
\midrule
LongT5-Base & \multirow{3}{*}{12K} & 53.8\% & 0.0 \\
LongT5-Large & & 56.3\% & 0.0 \\
LongT5-XL & & 60.4\% & 0.0 \\
\midrule
Flan-LongT5-Base & \multirow{3}{*}{12K} & 54.1\% & +0.3 \\
Flan-LongT5-Large & & 56.1\% & -0.2 \\
Flan-LongT5-XL & & 61.1\% & +0.7 \\
\midrule
HTML-T5-Base (ours) & \multirow{3}{*}{12K} & 57.0\% & +3.2 \\
HTML-T5-Large (ours) & & 60.8\% & +4.5 \\
HTML-T5-XL (ours) & & \textbf{63.3}\% & +2.9 \\
\midrule
Flan-T5-XL~\citep{furuta2023mmwebnav} & \multirow{2}{*}{347K} & 75.5\% & -- \\
Flan-T5-XXL~\citep{furuta2023mmwebnav} &  & 79.0\% & -- \\
\midrule
HTML-T5-XL (ours) & 347K & \textbf{79.4}\% & -- \\
\bottomrule
\end{tabular}
}
%\end{sc}
\end{small}
\end{center}
% \vskip -0.1in
\caption{
Average success rate of MiniWoB++ with 56 tasks. We use 12K demonstrations~\citep{liu2018wge}, and compare HTML-T5 among supervised-finetuned baselines~\citep{gur2022html,humphreys2022data}.
HTML-T5-XL remarkably outperforms WebN-T5-XL, the prior best method, by 14.9\%, and HTML-denoising improves the success rate better than instruction tuning.
We also finetune HTML-T5 with 347K demonstrations~\citep{furuta2023mmwebnav}, which performs better than Flan-T5-XXL (11B parameters) even with 3B parameters. See \autoref{sec:per_task_miniwob_results} for the detailed results.
}
\label{tab:miniwob_sl_results}
\end{table}

