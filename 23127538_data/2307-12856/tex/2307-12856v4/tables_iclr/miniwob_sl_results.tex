\begin{wraptable}{R}[0pt]{0.45\linewidth}
\vspace{-1cm}
%\begin{table}[tb]
\begin{center}
\begin{small}
%\begin{sc}
\scalebox{0.75}{
\begin{tabular}{lrrr}
\toprule
\textbf{Models} & \textbf{Data} & \textbf{Success} & \textbf{Diff.}\\
\midrule
\update{SoTA}~\citep{zheng2023synapse} & -- & \update{\textbf{99.2}\%} & -- \\
\midrule
CC-Net & 2.4M & 32.0\% & -- \\
WebN-T5-XL & 12K & 48.4\% & -- \\
\midrule
LongT5-Base & \multirow{3}{*}{12K} & 53.8\% & 0.0 \\
LongT5-Large & & 56.3\% & 0.0 \\
LongT5-XL & & 60.4\% & 0.0 \\
\midrule
Flan-LongT5-Base & \multirow{3}{*}{12K} & 54.1\% & \textcolor{cb_green}{+0.3} \\
Flan-LongT5-Large & & 56.1\% & \textcolor{cb_red}{-0.2} \\
Flan-LongT5-XL & & 61.1\% & \textcolor{cb_green}{+0.7} \\
\midrule
HTML-T5-Base (ours) & \multirow{3}{*}{12K} & 57.0\% & \textcolor{cb_green}{+3.2} \\
HTML-T5-Large (ours) & & 60.8\% & \textcolor{cb_green}{+4.5} \\
HTML-T5-XL (ours) & & \textbf{67.1}\% & \textcolor{cb_green}{+6.7} \\
\midrule
Flan-T5-XL & \multirow{2}{*}{347K} & 75.5\% & -- \\
Flan-T5-XXL &  & 79.0\% & -- \\
\midrule
HTML-T5-XL (ours) & 347K & \textbf{85.6}\% & -- \\
\bottomrule
\end{tabular}
}
%\end{sc}
\end{small}
\end{center}
% \vskip -0.125in
\vskip -0.15in
\caption{
Average success rate of MiniWoB++ with 56 tasks. We use 12K demonstrations and compare HTML-T5 among supervised-finetuned methods.
HTML-T5-XL outperforms WebN-T5-XL~\citep{gur2022html}, the prior best method, by 18.7\%. HTML-denoising also yields better the success rate than instruction tuned ones.
Finetuned HTML-T5 with 347K episodes~\citep{furuta2023mmwebnav} outperforms Flan-T5-XXL (11B parameters) even with 3B parameters\update{, which gets closer to SoTA with GPT-3.5}.
See \autoref{sec:per_task_miniwob_results} for the detailed results.
}
\vskip -0.2in
\label{tab:miniwob_sl_results}
%\end{table}
\end{wraptable}