To mitigate the scarce data problem in long-tailed data distribution, small dataset, and few-shot cases, we propose a text-driven visual feature manifold
% space manipulation and
augmentation method, $\TextMani$.
Our method densifies around all the given individual visual features by adding a difference vector stem from the text embedding.
While the mix-based augmentations inflict semantic perturbation in an inter-class way by label mixing, $\TextMani$ perturbs the semantic meaning of the visual features at an intra-class level, \ie, having semantic perturbation while 
% with the
maintaining its class.
% label.
The intra-class semantic perturbation is \moon{achieved}
% done
by transferring the attribute-embedded vectors 
% from text embedding 
to visual feature space.

\moon{To scrutinize the design of our estimated attribute embedding, we conduct visualization-based analyses: t-SNE plot and simple manipulation tests.}
% Our $\TextMani$ is designed on 
% % with the foundation of 
% the hypotheses on the difference attribute vectors.
% % : adding attribute words is reflected in the CLIP text embedding, and the difference before and after addition can be expressed as the difference vector.
% We visualize empirical evidence through 
% % the text embedding and the difference vector by 
% the t-SNE plot and simple manipulation tests, which 
% % and the results 
% empirically support the hypotheses.
\moon{The results empirically demonstrate that $\TextMani$ readily enriches the sparse samples with comprehensible manipulation, since the general language models also reflect some extent of visual information.
The experiment on the long-tail classification validates the effectiveness of our method, especially on the highly skewed class distribution.
% , and also empirically demonstrates some extent of visual information is reflected in the language model.
We additionally show the compatibility of $\TextMani$ with other augmentation methods or other models in scarce data cases and during linear probing.}
% We also validate the effectiveness of our method, especially on the long-tailed distribution and compatibility with the mix-based methods in scarce data cases.
% The experiments with multiple model architectures show that $\TextMani$ is not a model-specific method.
% To mitigate the challenge in FSOD, small dataset, and long-tail class distribution due to the scarce samples, we propose $\TextMani$ exploiting the explainable and manipulatable attributes from the text.
% We transfer the attribute embedded vector by adding a difference in text embeddings in the image feature.
% Our visualization of text embedding and simple image manipulation give evidence that the difference vector contains the residual information, attributes.
% $\TextMani$ can readily enrich the sparse sample with comprehensible zero-shot manipulation, and our experiments demonstrate its effectiveness.
In this work, note that we only use color and size as attributes; thus, there would be room 
\moon{for further investigation of other effective attributes.}
% to investigate other effective
% % various
% attributes further.
% suitable for the classes as future work.

\vspace{2mm}
{\paragraph{Acknowledgment}
This work was supported by Institute of Information \& communications Technology Planning \& Evaluation (IITP) grant funded by the Korea government(MSIT) (No.2021-0-02068, Artificial Intelligence Innovation Hub; No.2022-0-00124, Development of Artificial Intelligence Technology for Self-Improving Competency-Aware Learning Capabilities; No. 2020-0-00004, Development of Previsional Intelligence based on Long-term Visual Memory Network).
\par}
