\section{Introduction} \label{sec:Introduction}

The black-box optimization problem \cite{Audet_2017,Conn_2009, Pardalos_2021} usually arises when we have few information about the objective function. Such problems can appear when the objective function is non-smooth \cite{Gasnikov_2022_ICML} (i.e. no gradient computation is available) or, for instance, when the function is smooth \cite{Akhavan_2022} (may even have a higher order of smoothness \cite{Bach_2016}), but the process of computing the derivatives is too expensive in contrast to computing the value of the objective function. Moreover, this problem is often solved under conditions of privacy, when some data cannot be disseminated due to confidentiality. Then a gradient-free oracle \cite{Rosenbrock_1960} (or in other words zero-order oracle) acts as some ``black box", which returns only objective function value $f(x)$ at requested point $x$ with some bounded adversarial noise $\delta(x) \leq \Delta$ (where $\Delta$ is level noise). Where the latter means that the gradient-free oracle can give an inexact value of the objective function. As practice shows~\cite{Bogolubsky_2016}, the lower the level of adversarial noise, the more expensive it is to call a gradient-free oracle, so it is important to understand how large the level of adversarial noise can be, at which a ``good" convergence rate is still guaranteed (by ``good" convergence rate is meant the convergence of the algorithm when $\Delta = 0$). This concept of a gradient-free oracle is common in the literature and has the interpretation of a adversarial attack on the black-box model \cite{Chen_2017}. The black box problem is currently actively researched in the optimization \cite{Duchi_2015, Shibaev_2022} and machine learning \cite{Papernot_2016, Papernot_2017} community, since this problem has applications in the following areas: federated learning \cite{Lobanov_2022, Patel_2022}, distributed learning \cite{Scaman_2019, Lobanov_2023_SADOM} and deep learning~\cite{Gao_2018}. A particular need for solving such problems arises in the following applications: model hyperparameters tuning \cite{Hazan_2017,Elsken_2019}, reinforcement learning \cite{Choromanski_2018, Mania_2018}, multi-armed bandits \cite{Bartlett_2008, Bubeck_2012, Shamir_2017}, and many others. 
% Задача черного ящика в гладкой настройке + % Машинное обучение в целом

There are various approaches to solving the black-box problem, but the most common in a theoretically proof-of-concept sense is to create gradient-free optimization algorithms based on the state of the art first-order methods and using various randomized gradient approximations \cite{Gasnikov_2022}. The most common first-order optimization methods in machine learning models are momentum SGD, Adam, and others. But note that these algorithms are variants of Stochastic Gradient Descent (SGD) \cite{Robbins_1951, Bottou_2018}, which use stochastic gradient estimates. By adding a procedure for batching stochastic gradient estimates, it is possible to obtain algorithms that are easily parallelized on several computers. It is data distribution (parallelization) that significantly reduces the computational costs that certainly arise in a huge number of modern machine learning models. Also, with the addition of acceleration one can still achieve improvement in terms of estimates on the number of successive iterations. Thus, for many optimization problems, the state of the art first-order algorithms are accelerated batched variants of SGD. 
% SGD алгоритм + ускоренные + батчированные

In this paper, we focus on solving a stochastic convex black-box optimization problem in a smooth setting with an overparameterization condition. Where the latter means that the model has many more parameters than the data available. We can summarize our contributions as follows:
\begin{itemize}
    \item We derive the convergence rate for a biased Accelerated Stochastic Gradient Descent, which covers smooth convex stochastic optimization problems under the overparameterization setup.

    \item We provide a novel Accelerated Zero-Order Stochastic Gradient Descent Method (AZO-SGD) for solving the black-box problem in a smooth setting under the overparameterization condition. We analyze the robustness of AZO-SGD algorithm to adversarial noise, providing an estimate for the maximum admissible level of adversarial noise at which the desired accuracy can still be achieved. We show that our algorithm is optimal on oracle calls in the class of gradient-free algorithms.

    \item We show the convergence of the Accelerated Zero-Order Stochastic Gradient Descent Method proposed in this paper using a model example of finite sums in which the number of summands is less than the number of variables (the overparameterization condition). 
\end{itemize}
% Наш вклад

\subsection{Related works}

\paragraph{Adversarial noise.}

Finding the maximum admissible noise level at which one can still guarantee convergence to the desired accuracy $\varepsilon$ is an important issue for the black-box optimization problem. Special attention to this question was allocated by the works \cite{Lobanov_2022, Dvinskikh_2022, Kornilov_2023, Lobanov_2023_WAIT}. For example, in \cite{Dvinskikh_2022} the authors found the maximum admissible level of \textit{adversarial deterministic noise} for a non-smooth convex black-box optimization problem $ \sim \mathcal{O} \left(\varepsilon^2 d^{-1/2} \right)$, moreover in \cite{Lobanov_2022} it is shown that this estimate will be the same for $l_1$ and $l_2$ randomization. In \cite{Kornilov_2023}, the authors showed that by assuming a strong convexity, the estimate maximum level of \textit{adversarial deterministic noise} can be improved to ~$\sim~\mathcal{O} \left(\mu^{1/2} \varepsilon^{3/2} d^{-1/2} \right)$ in non-smooth setting. And in \cite{Lobanov_2023_WAIT} the authors were able to show that this estimation in a non-smooth one can be also improved to~$\sim~\mathcal{O} \left(\varepsilon d^{-1/2} \right)$ by using \textit{adversarial stochastic noise}, since this concept of \textit{adversarial stochastic noise} does not accumulate in the bias, but accumulates only in the variance. In addition, this paper shows that if the function is smooth, the estimate of the maximum level of adversarial stochastic noise can be improved to~$\sim~\mathcal{O} \left(\varepsilon^{1/2} d^{-1/2} \right)$.  In this paper, we will use a gradient approximation via $l_2$ randomization to create a novel gradient-free algorithm, and we will find the maximum admissible level of deterministic noise in a smooth setting under overparameterization condition.
% Adversarial Noise особое внимание


\paragraph{SGD type algorithms.}

Many works \cite{Lan_2012, Woodworth_2021, Gorbunov_2020, Gasnikov_2016, Ajalloeian_2020, Polyak_1963, Lojasiewicz_1963, Yue_2022, Woodworth_2021_over} study the Stochastic Gradient Descent and its variant in different setups. For example, in \cite{Lan_2012} the authors proposed an accelerated method of stochastic gradient descent, AC-SA. Later in \cite{Woodworth_2021} authors proposed optimal algorithms for federated learning architecture, which is based on AC-SA (Single-Machine Accelerated SGD and Mini-Batch Accelerated SGD) method. In \cite{Gorbunov_2020} proposed an clipped accelerated SGD method for heavy-tailed optimization problems based on the accelerated SGD method: Stochastic Similar Triangle Method (SSTM) \cite{Gasnikov_2016}. In \cite{Ajalloeian_2020}, the authors studied the biased SGD method in the Polak-Lojasiewicz \cite{Polyak_1963, Lojasiewicz_1963} setup. It is worth noting that in \cite{Yue_2022} it was shown that for problems satisfying the Polak-Lojasiewicz condition the non-accelerated SGD algorithm will be optimal. In \cite{Woodworth_2021_over}, the study of the AC-SA (accelerated SGD) algorithm was continued already in the overparameterization setup. We in this paper generalize the analysis of the AC-SA algorithm from \cite{Woodworth_2021_over}, to create a biased accelerated SGD algorithm in the overparameterization setting. A biased first-order algorithm is necessary because using $l_2$ randomization produces a bias in the case when $\delta(x) > 0$. Therefore, based on the biased batched accelerated stochastic gradient descent and using $l_2$ randomization, we create a new gradient-free optimization algorithm to solve a convex stochastic black-box optimization problem under overparameterization setup.
%SGD types algorithms 

\paragraph{Gradient noise assumptions.}

Recently there is a trend in works \cite{Woodworth_2021_over, Rakhlin_2012, Hazan_2014, Bertsekas_1996, Stich_2019, Lobanov_2023, Schmidt_2013, Srebro_2010} of relaxed stochastic gradient variance restriction condition. Very many works (e.g. see \cite{Rakhlin_2012, Hazan_2014}) use the standard assumption: $\expect{\norms{\nabla f(x,\xi)}^2} \leq \sigma^2$. However, already in the works \cite{Bertsekas_1996, Stich_2019, Lobanov_2023, Zhang_2022} used in the analysis of the algorithm a more relaxed assumption of weak growth: $\expect{\norms{\nabla f(x, \xi)}^2} \leq M\norms{\nabla f(x)}^2 + \sigma^2$. The following work \cite{Schmidt_2013} have set the constants so that the strong growth condition assumption is satisfied: $\expect{\norms{\nabla f(x, \xi)}^2} \leq M\norms{\nabla f(x)}^2$. In \cite{Woodworth_2021_over, Srebro_2010} the condition satisfying the overparameterized set: $\expect{\norms{\nabla f(x^*,\xi)}^2} \leq \sigma_*^2$. In this paper, we will also assume uniform smoothness of the function over $\xi$ as well as the overparameterized condition, since our approach to creating gradient-free algorithms is based on the Accelerated Batched Stochastic Gradient Descent (AC-SA) proposed in~\cite{Woodworth_2021_over}.
% Gradient noise assumption много работ


\subsection{Notations}
We use $\dotprod{x}{y}:= \sum_{i=1}^{d} x_i y_i$ to denote standard inner product of $x,y \in \mathbb{R}^d$, where $x_i$ and $y_i$ are the $i$-th component of $x$ and $y$ respectively. We denote Euclidean norm ($l_2$-norm) in~$\mathbb{R}^d$ as $\norms{x} = \| x\|_2 := \sqrt{\dotprod{x}{x}}$. We use the following notation $B_2^d(r):=\left\{ x \in \mathbb{R}^d : \| x \| \leq r \right\}$ to denote Euclidean ball ($l_2$-ball) and  $S_2^d(r):=\left\{ x \in \mathbb{R}^d : \| x \| = r \right\}$ to denote Euclidean sphere. Operator $\mathbb{E}[\cdot]$ denotes full mathematical expectation. We notation $\tilde{O} (\cdot)$ to hide logarithmic factors. 

\setcounter{footnote}{3}
\subsection{Paper Ogranization}
This paper has the following structure. In Section \ref{sec:Introduction} we introduce this paper and also provide related works. In Section \ref{sec:Technical_Preliminaries} we formulate the problem statement. While in Section \ref{sec:biased_gradient} we provide an accelerated SGD algorithm with a biased gradient oracle in the reparameterization setup. Section \ref{sec:Main_Result} presents the main result of this paper. We confirm the theoretical results via a model example in Section \ref{sec:Experiments}. While Section \ref{sec:Conclusion} concludes this paper. Detailed proofs are presented in the supplementary materials (Appendix)\footnote{The full version of this article, which includes the Appendix can be found by the article title in the arXiv at the following link: \url{https://arxiv.org/abs/2307.12725}.}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%% End of Section: Introduction %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Technical Preliminaries} \label{sec:Technical_Preliminaries}
We study a standard stochastic convex optimization problem:
\begin{equation}\label{eq:init_problem}
    f^* = \min_{x \in \mathbb{R}^d}\left\{ f(x) := \expect{f(x, \xi)} \right\},
\end{equation}
where $f: \mathbb{R}^d \rightarrow \mathbb{R}$ is smooth convex function that we want to minimize over $\mathbb{R}^d$. This problem statement is a general smooth convex stochastic optimization problem, so to define the class of the problem considered in this paper we will introduce some assumptions on the objective function and on the gradient oracle. 

\subsection{Assumptions on the Objective Function}
In all proofs we assume convexity and smoothness of the function $f(x,\xi)$.
\begin{assumption} \label{ass:convex}
    For almost every $\xi$, $f(x,\xi)$ is non-negative, convex w.r.t. $x$,~i.e.
    \begin{equation*}
        \forall x, y, \xi \quad f(y, \xi) \geq f(x, \xi) + \dotprod{\nabla f(x, \xi)}{y - x}.
    \end{equation*}
\end{assumption}

\begin{assumption} \label{ass:smooth}
    For almost every $\xi$, $f(x,\xi)$ is non-negative, $L$-smooth w.r.t.~$x$,~i.e.
    \begin{equation*}
        \forall x, y, \xi \quad f(y, \xi) \leq f(x, \xi) + \dotprod{\nabla f(x, \xi)}{y - x} + \frac{L}{2} \norms{y - x}^2.
    \end{equation*}
\end{assumption}
Assumptions \ref{ass:convex} and \ref{ass:smooth} are common in the literature (see, e.g., \cite{Vaswani_2019, Fatkhullin_2022}). However, it is worth noting that these assumptions require uniform convexity and smoothness over $\xi \sim \mathcal{D}$ \cite{Tran_2022}. This is an essential difference from the standard assumptions, which define a narrower class of the objective function.

\begin{assumption} \label{ass:f_star}
    The function $f(x)$ is a convex and has the minimum value $f^* = \min_{x} f(x)$, which is attained at a point $x^*$ with $\norms{x^*} \leq R$.
\end{assumption}
We explicitly introduce the problem solution $f^*$ in Assumption \ref{ass:f_star}, since our approach implies that the convergence rate depends on the solution $f^*$ (see, e.g., \cite{Cotter_2011}), i.e., our analysis will show an improvement in convergence at $f^* \rightarrow 0$. 


\subsection{Assumptions on the Gradient Oracle}
In our analysis we consider the case when we obtain an inexact gradient value when calling the oracle. Therefore we first define a biased gradient oracle.
\begin{definition}[Gradient Oracle] \label{def:biased_oracle}
A map $\gg: \mathbb{R}^d \times \mathcal{D} \rightarrow \mathbb{R}^d$ s.t.
\begin{equation*}
    \gg(x,\xi) = \nabla f(x, \xi) + \bb(x),
\end{equation*}
where $\bb: \mathbb{R}^d \rightarrow \mathbb{R}^d$ such that $\forall x \in \mathbb{R}^d$: $\norms{\bb(x)}^2 \leq \zeta^2$. 
\end{definition} 
Next, we assume that gradient noise is bounded as follows.
\begin{assumption} \label{ass:stoch_noise}
    There exists $\sigma^2_* \geq 0$ such that $\forall x \in \mathbb{R}^d$
    \begin{equation*}
        \expect{\norms{\nabla f(x^*, \xi) - \nabla f(x^*)}^2} \leq \sigma^2_*.
    \end{equation*}
\end{assumption}
Assumption \ref{ass:stoch_noise} is a common assumption for overparameterized optimization problems, since in this setup in many problems \cite{Jacot_2018, Allen_2019, Belkin_2019} $f^*$ can be expected to be small. We introduced Assumptions \ref{ass:convex}--\ref{ass:stoch_noise} because in this paper we based on the results of~\cite{Woodworth_2021_over}, in which it was proved that the convergence rate of the AC-SA method (from \cite{Lan_2012}) has the following form in overparameterization setup~of~problem~\eqref{eq:init_problem}:
\begin{equation} \label{eq:woodworth_ACSA}
    \expect{f(x_{N}^{ag}) - f^*} \leq c \cdot \left( \frac{L R^2}{N^2} + \frac{L R^2}{BN} + \sqrt{\frac{L R^2 f^*}{BN}} \right),
\end{equation}
where $N$ is a iteration number, $B$ is a batch size and $\sigma^2_* \leq 2 Lf^*$ (it's proven~\cite{Woodworth_2021_over}).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% End of Section: Technical Preliminaries %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Accelerated SGD with Biased Gradient} \label{sec:biased_gradient}
Our approach to create a gradient-free algorithm (for a overparameterized setup) implies the use of $l_2$ randomization (see Section \ref{sec:Main_Result}), based on the AC-SA algorithm from \cite{Woodworth_2021_over}. However, the standard concept of a gradient-free oracle implies the presence of adversarial noise, which can accumulate in both variance and bias. Therefore, it is important to investigate the adversarial noise for the question of maximum admissible noise level, when the desired accuracy can be guaranteed. As can be seen, the result \eqref{eq:woodworth_ACSA} obtained in \cite{Woodworth_2021_over} does not account for the bias in the gradient oracle (see Definition \ref{def:biased_oracle} in the case when $\norms{\bb(x)} = 0$). Consequently, in Theorem \ref{th:biased_AC_SA} we provide a novel biased AC-SA algorithm that is robust to the overparameterized setup and accounts for bias in~gradient~oracle.

\begin{theorem}[Convergence of Biased AC-SA] \label{th:biased_AC_SA}
    Let $f$ satisfy Assumptions \ref{ass:convex}--\ref{ass:f_star} and gradient oracle from Definition \ref{def:biased_oracle} satisfy Assumption \ref{ass:stoch_noise}, then Biased AC-SA algorithm guarantees the convergence with a universal constant $c$
    \begin{equation*} 
        \expect{f(x_{N}^{ag}) - f^*} \leq c \cdot \left( \frac{L R^2}{N^2} + \frac{L R^2}{BN} + \frac{\sigma_* R}{\sqrt{BN}} + \zeta R + \frac{\zeta^2}{2 L}N \right).
    \end{equation*}
\end{theorem}
The results of Theorem \ref{th:biased_AC_SA} show the convergence of the AC-SA algorithm, considering the bias $\bb(x)$ in the gradient oracle.  It is not difficult to see that if we consider the case without bias ($\zeta = 0$), the convergence result of Theorem \ref{th:biased_AC_SA} will fully correspond to the result \eqref{eq:woodworth_ACSA}. The last two terms in Theorem \ref{th:biased_AC_SA} are standard for the accelerated algorithm (see, for example, \cite{Dvinskikh_2021, Vasin_2023}). There are several ways to obtain these results: using the ($\delta,L$)-oracle technique \cite{Devolder_2013}, modifying Assumptions \ref{ass:convex}, \ref{ass:smooth}, or performing sequential reasoning with current assumptions. The proof of Theorem \ref{th:biased_AC_SA} can be found in supplementary materials (Appendix~\ref{Appendix:proof_th1}).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% End of Section: Technical Preliminaries %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Main Result} \label{sec:Main_Result}
In this section, we present the main result of this work, namely a gradient-free algorithm for solving a convex smooth stochastic black-box optimization problem in an overparameterized setup. We further narrow the problem class \eqref{eq:init_problem} considered in this section to the black box problem, that is, when the calculation of the gradient oracle is not available for some reason. Unfortunately, we cannot apply the AC-SA algorithm or even the biased AC-SA algorithm to solving this problem class. Therefore, there is a need to create an algorithm that only requires calculations of function values. Such algorithms are usually called \textit{gradient-free}, since the efficiency of this class of algorithms is determined by three criteria: the maximum admissible level of adversarial noise $\Delta$, iterative complexity $N$, and in particular the total number of calls to the \textit{gradient-free oracle} $T$. Our approach in creating gradient-free algorithm based on the biased AC-SA algorithm. Instead of the gradient oracle (see Definition \ref{def:biased_oracle}) we use the gradient~approximation:
\begin{equation} \label{eq:gradient_approximation}
    \gg(x,\xi,e) = \frac{d}{2 \tau}\left( f_\delta(x + \tau e, \xi) - f_\delta(x - \tau e, \al{\xi}) \right) e,
\end{equation}
where $e$ is a vector uniformly distributed on unit sphere $S_2^d(1)$, $\tau$ is a smoothing parameter and $f_\delta(x, \xi) = f(x, \xi) + \delta(x)$ ($|\delta(x)| \leq \Delta$) is a \textit{gradient-free} oracle. Thus Algorithm \ref{alg:AZO_SGD} presents a novel gradient-free method, namely Accelerated Zero-Order Stochastic Gradient Descent (AZO-SGD) Method for solving the black-box optimization problem \eqref{eq:init_problem} under the overparameterization condition.

\begin{algorithm}
        \caption{Accelareted Zero-Order Stochastic Gradient Descent (AZO-SGD)}\label{alg:AZO_SGD}
        \textbf{Input}: Start point $x^{ag}_0 = x_0 \in \mathbb{R}^d$, maximum number of iterations $N \in \mathbb{Z}_+$.\\
        \hspace*{\algorithmicindent} Let stepsize $ \al{\gamma}_k > 0$, parameters $\beta_k, \tau > 0$, batch size $B \in \mathbb{Z}_+$. 
        \begin{algorithmic}[1]
        \For{$k=0,...,N-1$}
        \State $\beta_k = 1 + \frac{k}{6}$ and $\al{\gamma}_k = \al{\gamma} (k+1)$ for $\gamma = \min \left\{ \frac{1}{12 L}, \frac{B}{24 L(N+1)}, \sqrt{\frac{B R^2}{Lf^* N^3}} \right\}$  
        \State $x^{md}_k = \beta^{-1}_k x_k + (1 - \beta^{-1}_k) x_k^{ag}$
        \State Sample $\{ e_1,...,e_{B} \}$ and $ \{ \xi_1,...,\xi_{B} \}$ independently
        \State Define $\gg_k = \frac{1}{B} \sum_{i=1}^{B} \gg(x^{md}_k, \xi_i, e_i)$ using \eqref{eq:gradient_approximation}
        \State $\tilde{x}_{k+1} = x_k - \al{\gamma}_k \gg_k$
        \State $x_{k+1} = \min \left\{ 1, \frac{R}{\norms{\tilde{x}_{k+1}}} \right\} \tilde{x}_{k+1}$
        \State $x_{k+1}^{ag} = \beta^{-1}_k x_{k+1} + (1 - \beta^{-1}_k) x_{k}^{ag}$
        \EndFor
        \end{algorithmic}
        \textbf{Output}: $x_N^{ag}$.
    \end{algorithm}
    Next, we provide Theorem \ref{th:AZO_SGD}, in which we show the convergence results for Accelareted Zero-Order Stochastic Gradient Descent (AZO-SGD) Method.
    \begin{theorem} \label{th:AZO_SGD}
        Let $f$ satisfy Assumptions \ref{ass:convex}--\ref{ass:f_star} and gradient approximation \eqref{eq:gradient_approximation} with parameter $\tau \leq \frac{\varepsilon}{LR}$ satisfy Assumption \ref{ass:stoch_noise}, then Accelareted Zero-Order Stochastic Gradient Descent (AZO-SGD) Method (see Algorithm \ref{alg:AZO_SGD}) achieves $\varepsilon$-accuracy: $\expect{f(x_{N}^{ag}) - f^*} \leq \varepsilon$ after 
        \begin{equation*}
            N = \mathcal{O}\left( \sqrt{\frac{L R^2}{\varepsilon}} \right), \quad T = \max \left\{ \mathcal{O}\left( \frac{LR^2}{\varepsilon} \right), \mathcal{O}\left( \frac{d \sigma_*^2 R^2}{\varepsilon^{2}} \right) \right\}
        \end{equation*}
        number of iterations, total number of gradient-free oracle calls and at
        \begin{equation*}
            \Delta \leq \frac{\varepsilon^2}{d L R^2}
        \end{equation*}
        the maximum admissible level of adversarial noise.
    \end{theorem}
    The result of Theorem \ref{th:AZO_SGD} shows the effective iterative complexity $N$, since an accelerated method was taken as the base (biased AC-SA, see Theorem \ref{th:biased_AC_SA}). It is also worth noting that the batch size $B = \max \left\{ \mathcal{O}\left( \sqrt{\frac{L R^2}{\varepsilon}} \right), \mathcal{O}\left( \frac{d \sigma_*^2 R}{L^{1/2} \varepsilon^{3/2}} \right) \right\}$ can change with time, i.e., it directly depends on $\sigma^2_*$, which leads to an optimal estimate of the number of gradient-free oracle calls $T$. Finally, one of the main results of this paper is the estimation for the maximum admissible noise level $\Delta$. This estimation is inferior to the other estimations $ \sim \mathcal{O} \left(\varepsilon^2 d^{-1/2} \right)$ in the non-smooth setting and $ \sim \mathcal{O} \left(\varepsilon^{3/2} d^{-1/2} \right)$ in smooth setting, but this is expected, since Algorithm \ref{alg:AZO_SGD} is working in a different setup, namely in overparameterization condition. It's also noted that we don't guarantee that this evaluation is unimproved, but only states that at $ \Delta \leq \mathcal{O} \left(\varepsilon^2 d^{-1} \right)$ there will be convergence to $\varepsilon$-accuracy. We present an open question for future research: improving the estimate to the maximum admissible noise level, as well as finding upper bounds on noise level beyond which convergence in the overparameterized setup cannot~be~guaranteed. The proof of Theorem \ref{th:biased_AC_SA} can be found in supplementary~materials~(Appendix~\ref{Appendix:proof_th2}).

    
    \begin{remark}[General case]
        It is worth noting that this paper, and in particular Theorem \ref{th:biased_AC_SA} and Theorem \ref{th:AZO_SGD}, focus on the Euclidean case. However, using the work of \cite{Ilandarideva_2023} (namely, Algorithm 2) as a basis, and similarly generalizing the convergence results (Corollary 1, \cite{Ilandarideva_2023}) to the case with a biased gradient oracle (see Definition \ref{def:biased_oracle}), we can obtain a gradient-free algorithm for a more general class of problems ($L_p$-norm and presence of constraints). In this case, the parameters (number of iterations $N$, the maximum admissible level of adversarial noise $\Delta$, smoothing parameter $\tau$) of the gradient-free algorithm will be the same as in Theorem \ref{th:AZO_SGD}, except for the total number of oracle calls: let given $1/p + 1/q = 1$
        \begin{equation*}
            T = N \cdot B = \max \left\{ \mathcal{O}\left( \frac{LR^2}{\varepsilon} \right), \mathcal{O}\left( \frac{\min\{ q, \ln d \} d^{2 - \frac{2}{p}} \sigma_*^2 R^2}{\varepsilon^{2}} \right) \right\}.
        \end{equation*}
        This generalization allows one to solve problem \eqref{eq:init_problem} in a broader setting, for instance, by imposing a constraint. In particular, by solving the problem on a simplex ($p=1$, $q=\infty$) we can achieve a reduction of the total number of calls to the zero-order oracle $T$ by $\ln(d)$ compared to the Euclidean case.
    \end{remark}
    

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%% End of Section: Main Result  %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiments} \label{sec:Experiments}
In this section, we will use a simple example to verify the theoretical results, namely to show the convergence of the proposed algorithm Accelerated Zero-Order Stochastic Gradient Descent Method (AZO-SGD, see Algorithm \ref{alg:AZO_SGD}). The optimization problem \eqref{eq:init_problem} is as follows:
\begin{equation} \label{eq:experiments_problems}
    \min_{x \in \mathbb{R}^d} f(x) := \frac{1}{m} \sum_{i = 1}^{m} \left( l_{i}(x) \right)^2,
\end{equation}
where $l(x) = Ax - b$ is system of $m$ linear equations under overparameterization ($d>m$), $A \in \mathbb{R}^{m \times d}$ , $x, b \in \mathbb{R}^d$. Problem \eqref{eq:experiments_problems} is a convex stochastic optimization problem \eqref{eq:init_problem}, also known as the Empirical Risk Minimization problem, where $\xi=i$ is one of $m$ linear equations.
\vspace{-0.8cm}
% Figure environment removed
\vspace{-0.8cm}
In Figure \ref{Fig1} we see the convergence of the proposed gradient-free algorithm. We can also conclude that as the batch size increases, the number of iterations required to achieve the desired accuracy decreases. This effect occurs especially in applications with huge-scale machine learning models. We optimize $f(x)$ \eqref{eq:experiments_problems} with parameters: $d = 256$ (dimensional of problem), $m = 128$
(number of linear equations), $\tau = 0.001$
(smoothing parameter), $\al{\gamma} = 0.0001$ (step size),
$B = \left\{ 8, 16, 64 \right\}$ (batch size). We also understand machine inaccuracy by noise level. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%% End of Section: Experiments  %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion} \label{sec:Conclusion}
The optimization problem in the overparameterization setup has not yet been sufficiently studied. In this paper, we proposed a novel gradient-free algorithm: Accelerated Zero-Order Stochastic Gradient Descent Method for solving the smooth convex stochastic black-box optimization problem in the overparameterization setup. Our approach in creating the gradient-free Algorithm \ref{alg:AZO_SGD} was based on accelerated stochastic gradient descent. However, since there is an accumulation of adversarial noise in $l_2$ randomization, the result of \cite{Woodworth_2021_over} was generalized to the case of a biased gradient oracle. We also showed that the proposed gradient-free algorithm (AZO-SGD) is optimal in terms of iteration and oracle complexities. In addition, we obtained the first estimate, as far as we know, of the level of adversarial noise in the overparameterization setup, thereby opening up many potentially interesting future research questions in this setup.

The authors are grateful to Daniil Vostrikov.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%  End of Section: Conclusion  %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



