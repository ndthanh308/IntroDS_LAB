{
  "title": "Multi-objective Deep Reinforcement Learning for Mobile Edge Computing",
  "authors": [
    "Ning Yang",
    "Junrui Wen",
    "Meng Zhang",
    "Ming Tang"
  ],
  "submission_date": "2023-07-05T16:36:42+00:00",
  "revised_dates": [],
  "abstract": "Mobile edge computing (MEC) is essential for next-generation mobile network applications that prioritize various performance metrics, including delays and energy consumption. However, conventional single-objective scheduling solutions cannot be directly applied to practical systems in which the preferences of these applications (i.e., the weights of different objectives) are often unknown or challenging to specify in advance. In this study, we address this issue by formulating a multi-objective offloading problem for MEC with multiple edges to minimize expected long-term energy consumption and transmission delay while considering unknown preferences as parameters. To address the challenge of unknown preferences, we design a multi-objective (deep) reinforcement learning (MORL)-based resource scheduling scheme with proximal policy optimization (PPO). In addition, we introduce a well-designed state encoding method for constructing features for multiple edges in MEC systems, a sophisticated reward function for accurately computing the utilities of delay and energy consumption. Simulation results demonstrate that our proposed MORL scheme enhances the hypervolume of the Pareto front by up to 233.1% compared to benchmarks. Our full framework is available at https://github.com/gracefulning/mec_morl_multipolicy.",
  "categories": [
    "cs.NI",
    "cs.AI",
    "cs.LG"
  ],
  "primary_category": "cs.NI",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14346",
  "pdf_url": null,
  "comment": "Received by IEEE WiOpt 2023",
  "num_versions": null,
  "size_before_bytes": 1437794,
  "size_after_bytes": 810609
}