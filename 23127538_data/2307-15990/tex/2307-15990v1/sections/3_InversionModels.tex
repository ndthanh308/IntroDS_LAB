We target the problem of reconstructing US images from raw data towards improving image quality. 
%dm To obtain a linear model, 
\dm{To model the reconstruction with a linear model,}
we consider the ultrasonic transmission-reception process under the first-order Born approximation.
\ji{We introduce the following notations: $\tau$, $k$, $x$, and $\rv$ respectively denote
the time delay, the time index, the reflectivity function, and the observation position in the field of view.}
%Denoting by $\tau$ the time delay, by $k$ the \yz{time index, by $x$ the reflectivity function, and by $\rv$ the observation position in the field of view.}
When the ultrasonic wave transmitted by the $i^{th}$ element passes through the scattering medium $\Omega$ and is received by the $j^{th}$ element, the received echo signal can be expressed as
\begin{equation}
    y_{i, j}(k) = \int_{\rv \in \Omega}a_i(\rv)a_j(\rv)h(k-\tau_{i,j}(\rv)) x(\rv) \mathrm{d} \rv + n_{j}(k),
\label{Equ: model_continuous}
\end{equation}
where $n_{j}(k)$ represents the noise for the $j^{th}$ receive element, function $h$ \yz{is the convolution of the emitted excitation pulse} and the two-way transducer impulse response, and $a$ represent\dm{s} the weights for apodization according to the transducer's limited directivity.
\begin{comment}
    \ch{I do noto agree. There is no question of computation tractability here, because we don't compute in continuous. The true reason is that we ignore the spatial impulse respone. What we write here as $a$ are not impulse response, if so you should write something like $a\delta$ and convolve. Here $a(r)$ are only weights related to the directivity, as you well said. Writing the model with SIR will complexify the eq. 1, and I think this is not necessary in this article.}
\end{comment}

The discretized linear physical model with $N$ observation points and $K$ time samples for all $L$ receivers can then be 
%dm formulated 
\dm{rewritten}
as $\yv=\Hv\xv + \nv$, \yz{where $\xv\in \R^{N\times 1}$, $\nv\in \R^{KL\times 1}$, and $\Hv\in \R^{KL\times N}$ is filled with the convolving and multiplying factors from $h$ and $a$ at the delays $\tau_{i,j}$}. 
Due to the \yz{Born approximation, the inaccuracy of $h$ and $a$,} and the discretization, the additive noise $\nv$ \yz{does} not only include the white Gaussian electronic noise but also the model error. However, for simplicity, we still assume $\nv$ as white Gaussian with standard deviation $\gamma$, which is reasonable for the plane wave transmission~\cite{iMAP}. 

While iterative methods exist for solving such \yz{linear inverse} problems~\cite{IPB_Ozkan,RED_USIPB}, our goal is to improve the quality of the reconstructed image by relying on recent advances in diffusion models and, notably, on DDRM.
%dm
\begin{comment}
Formally, we conceive a method to transform the pre-beamformed Radio-Frequency (RF) channel data $\yv \in \R^{KL\times 1}$ into a B-mode image $\xv\in \R^{N\times 1}$, where  $K$ stands for the number of time samples, $L$ the number of channels of a one-dimensional transducer array, and $N$ is the number of pixels in the image. We formulate the problem with a direct linear model $\yv=\Hv\xv + \nv$, where $\Hv\in \R^{KL\times N}$ is the model matrix containing the excitation waveform shifted regarding the pixels-transducer times of flight, and weighted (apodization) according to the transducer limited directivity; 
and $\nv\in \R^{KL\times 1}$ is Gaussian noise with standard deviation $\gamma$.
\end{comment}
Given the above linear model, we \yz{can now} rely on DDRM to iteratively guide the reconstruction of the US image from the measurements. However, since DDRM relies on \yz{the} SVD of $\Hv$ to go from a generic inverse problem \yz{to} a denoising/inpainting problem, and \yz{since this} SVD produces huge orthogonal matrices that cannot be implemented as operators, we \yz{propose to} transform the linear inverse problem model to:
\begin{comment}
this naive direct model leads to a huge model matrix $\Hv$. Since DDRM relies on SVD of $\Hv$, the solution becomes computationally impractical.
Instead, we used the beamformed data :    
\end{comment}
\begin{equation}
    \Bv\yv=\Bv\Hv\xv + \Bv\nv,
    \label{Equ: model_HtH}
\end{equation}
where $\Bv \in \R^{N \times KL}$ is a beamforming matrix that \yz{projects channel data to the image domain}. 
\begin{comment}
A classical beamformer in US imaging is Delay-And-Sum (DAS)\cite{Perrot_2021}, mainly based on pixel-to-transducer times of flight. \yz{In the case} we \yz{consider the pulse-echo response} $h$, another common beamformer is the matched filter performed by defining $\Bv=\Hv^\tD$.
\end{comment}
\yz{After this transformation, we then feed the new inverse problem (Eq.~\ref{Equ: model_HtH}) to DDRM to iteratively reconstruct $\xv$ from $\Bv\yv$ observations. In this way, the size of the SVD of $\Bv\Hv$ becomes more tractable.}
\begin{comment}
Considering the inverse problem in DDRM, we feed the 
$\yv_d=\Bv\yv$ as input and the matrix
$\Hv_d=\Bv\Hv$ for the SVD decomposition. 
\end{comment}
We call this first model DRUS for Diffusion Reconstruction in US.

However, the noise of the updated direct model $\Bv\nv$ is no longer white and thus, it does not meet the assumption of DDRM. For this reason, we introduce a whitening operator $\Cv \in \R^{M \times N}$, where $M \leqslant N$, and upgrade the inversion model to its final form:
\begin{equation}
    \Cv\Bv\yv = \Cv\Bv\Hv\xv + \Cv\Bv\nv,
    \label{Equ: model_CHtH}
\end{equation}
where \Cv is such that $\Cv\Bv\nv$ is a white noise sequence. In order to compute $\Cv$, we rely on the eigenvalue decomposition 
$
    \Bv\Bv^\tD = \Vv \Lambdab \Vv^\tD
$
where $\Lambdab \in \R ^{N \times N}$ is a diagonal matrix of the eigenvalues of $\Bv\Bv^\tD$, and $\Vv \in \R^{N \times N}$ is a matrix whose columns are the corresponding right eigenvectors. Then, the covariance matrix of the whitened additive noise $\Cv\Bv\nv$ can be written as
\begin{align*}
 \mathrm{Cov}(\Cv\Bv\nv)&= \ED[\Cv\Bv\nv \nv^\tD \Bv^\tD \Cv^\tD]
% &= \Cv\Bv \ED(\nv\nv^\tD)\Bv^\tD \Cv^\tD\\
 = \gamma^2 \Cv\Bv\Bv^\tD\Cv^\tD
 = \gamma^2 \Cv\Vv \Lambdab \Vv^\tD \Cv^\tD.
\end{align*}
Now, let $\Cv =\Pv\Lambdab^{-\frac{1}{2}} \Vv^\tD$ with $\Pv=[\Iv_M,\zerob_{M\times(N-M+1)}] \in \R^{M \times N}$. It can be easily checked that $\Cv\Vv \Lambdab \Vv^\tD \Cv^\tD=\Iv_M$, \yz{proving the noise $\Cv\Bv\nv$ is white}.

\yz{Besides, discarding the smallest eigenvalues by empirically choosing $M$, rather than strictly limiting ourselves to zero eigenvalues, can compress the size of the observation vector $\Cv\Bv\yv$ from $N \times 1$ to $M \times 1$ and make the size of the SVD of $\Cv\Bv\Hv$ more  tractable.} %which can help save some memory in some cases.}
\begin{comment}
In practice, we discard the smallest eigenvalues by empirically choosing $M$, rather than strictly limiting ourselves to zero eigenvalues. As a consequence, the size of the observation vector $\Cv\Bv\yv$ is compressed from $N \times 1$ to $M \times 1$. 
\end{comment}

In order to adapt DDRM to the final inverse model in Eq.~\ref{Equ: model_CHtH}, we consider $\yv_d=\Cv\Bv\yv$ and $\nv_d=\Cv\Bv\nv$ as input and \yz{compute the SVD of $\Hv_d=\Cv\Bv\Hv$.} We name this whitened version of the approach WDRUS. In summary:
\begin{itemize}
    \item \DM{DRUS model relies on} ~\eqref{Equ: model_HtH} \DM{with} $\yv_d=\Bv\yv$,  $\Hv_d=\Bv\Hv$ and $\nv_d=\Bv\nv$
    \item \DM{WDRUS model relies on}~\eqref{Equ: model_CHtH} \DM{with} $\yv_d=\Cv\Bv\yv$, $\Hv_d=\Cv\Bv\Hv$ and $\nv_d=\Cv\Bv\nv$.
\end{itemize}
\begin{comment}
In the special case where the DAS matrix $\Bv$ is chosen as the \emph{matched filtering} operator $\Bv= \Hv^\tD$, then
\begin{equation}
    \Bv\Hv=\Bv\Bv^\tD = \Vv \Lambdab \Vv^\tD.
    \label{Equ: B=Ht start}
\end{equation}
and
\begin{align}
\Cv\Bv\Hv &= \Cv\Bv\Bv^\tD\\
% &= \Pv\Lambdab^{-\frac{1}{2}} \Vv^\tD \ast  \Vv \Lambdab \Vv^\tD\\
 &= \Pv \Lambdab^{\frac{1}{2}} \Vv^\tD\\
 &= \Iv_M \Sigmab \Vv^\tD,
 \label{Equ: B=Ht end}
\end{align}
where $\Sigmab \in \R ^{M \times N}$ keeps the first M rows of the diagonal matrix $\Lambdab^{\frac{1}{2}}$.
%As a consequence, svd decompositions are simplified.
\end{comment}