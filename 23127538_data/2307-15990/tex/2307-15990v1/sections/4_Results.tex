In our study, we employed an open-source generative diffusion model~\cite{dhariwal_diffusion_2021} at resolution $256 \times 256$ pre-trained on ImageNet~\cite{ILSVRC15}. We evaluated our method \yz{with $\texttt{it}=50$ on both} synthetic data and on the Plane Wave Imaging Challenge in Medical UltraSound (PICMUS)~\cite{PICMUS} dataset. \yz{For the latter, we also experimented with \yz{the same} unconditional diffusion model \yz{but this time} fine-tuned with 800 high-quality \dm{unpaired} ultrasound images acquired with \yz{a} TPAC Pioneer machine on \yz{a CIRS 040GSE phantom}. Image samples and data acquisition parameters for fine-tuning are in the supplementary material}.

\yz{All evaluations in this paper are performed in plane-wave modality. The baseline for synthetic data is %simply 
beamformed by applying matched filtering $\mathbf{B}=\mathbf{H}^t$. %while 
\dm{The} references for the PICMUS dataset apply DAS %dm method 
with 1, 11, and 75 transmissions. Our proposed DRUS and WDRUS are compared %with them 
\dm{against the DAS references}
by taking \dm{measurements of} a single-transmission %measurements 
as input.}

\subsection{Results on synthetic data}\label{sec: synthetic}
We simulate data from two phantoms, \yz{a synthetic \texttt{SynVitro} and Field\,II \texttt{fetus} \cite{FieII_1,FieII_2}}. \CH{The model matrix $\Hv$ includes receive apodization using \CH{Hann} window and \texttt{f-number}\,$=0.5$, and the beamformer $\mathbf{B}=\mathbf{H}^t$.} We simulated channel data $\mathbf{y} = \mathbf{Hx}+\mathbf{n}$ with six levels of additive noise ($\gamma = 0.3, 0.7, 1.0, 1.5, 2.0, 2.5$).

The restoration quality for \texttt{SynVitro} is quantitatively evaluated with both resolution and contrast metrics. For the \texttt{fetus} phantom, we measure the Structural SIMilarity (SSIM)~\cite{SSIM} and the Peak Signal-to-Noise Ratio (PSNR).
Resolution is measured as the -6dB Full Width at Half Maximum (FWHM) in axial and lateral directions separately on the six bright scatterers. For evaluating the contrast, we rely on both the Contrast to Noise Ratio (CNR) and the generalized Contrast to Noise Ratio (gCNR):
%\mathrm{CNR}=20 \log_{10}\bigg(\frac
%{\left|\mu_{\text{in}}-\mu_{\text{out}}\right|}{\sqrt{\left(\sigma_{\text {in }}^2+\sigma_{\text {out}}^2\right) / 2}}\bigg),
\ji{$$\mathrm{CNR}=10 \log_{10}\bigg(\frac
{\left|\mu_{\text{in}}-\mu_{\text{out}}\right|^2}{\left(\sigma_{\text {in }}^2+\sigma_{\text {out}}^2\right) / 2}\bigg),
\quad
\mathrm{gCNR}=1-\int_{-\infty}^{\infty} \min \left\{f_{\text {in}}(v), f_{\text {out}}(v)\right\} dv,
$$}%
\yz{both measured on the four anechoic regions, where the subscripts `in' and `out' indicate inside or outside the target regions, $v$ denotes the pixel values, and $f$ refers to the histograms of pixels in each region. The restored images and metrics are summarized in Fig.~\ref{fig: results_synthetic}. The metrics for \texttt{SynVitro} are averaged over the different noise levels for simplicity.}

\yz{Qualitatively and quantitatively,} both DRUS and WDRUS significantly outperform the matched-filtering baseline $\Hv^t\yv$, and WDRUS is generally superior to DRUS in terms of noise reduction and contrast enhancement. The two proposed approaches even outperform the ground truth for resolution at low-noise conditions (e.g. $\gamma = 0.3, 0.7, 1.0$), while the resolution of images restored by WDRUS under high-noise conditions (e.g. $\gamma = 1.5, 2.0, 2.5$) is worse than that of DRUS.

% Figure environment removed


\subsection{Results on PICMUS dataset}\label{sec: picmus}
There are four phantoms in the PICMUS~\cite{PICMUS} dataset. 
\yz{\texttt{SR} and \texttt{SC} are Field\,II \cite{FieII_1,FieII_2} simulations while \texttt{ER} and \texttt{EC} were acquired on a CIRS 040GSE phantom.}
\begin{comment}
The first two, \texttt{SR} and \texttt{SC}, are simulated phantoms, for which the channel data have been generated using the simulation software Field\,II~\cite{FieII_1,FieII_2}. The last two, \texttt{ER} and \texttt{EC}, are parts of the CIRS model 040GSE phantom. 
\end{comment}
\CH{
We use the PICMUS presets where the beamformer $\Bv$ comprises receive apodization using Tuckey25 window and \texttt{f-number}\,$=1.4$, while $\Hv$ has no apodization.
}

In addition to using FWHM, CNR, and gCNR for evaluating resolution (for \texttt{SR} and \texttt{ER}) and contrast (for \texttt{SC} and \texttt{EC}) introduced in Section~\ref{sec: synthetic}, we also use the Signal to Noise Ratio (SNR) $\mu_\text{ROI} / \sigma_\text{ROI}$ and the Kolmogorovâ€“Smirnov (KS) test at the 5$\%$ significance level, for evaluating the speckle quality preservation (for \texttt{SC} and \texttt{EC}), where ROI is the region of interest. SNR $\approx 1.91$ and passing the KS test under a Rayleigh distribution hypothesis are \yz{indicators of a} good speckle texture preservation. 

Using single plane-wave transmission (1PW), we compare our approaches with DAS (1PW, 11PWs, and 75 PWs) qualitatively and quantitatively in Fig. \ref{fig: picmus images} and in Table \ref{Tab: picmus metrics}, respectively. We also compare with the scores (\yz{taken} from~\cite{RED_USIPB}) of four other approaches in Table \ref{Tab: picmus metrics}, including the Eigenspace-based Minimum Variance (EMV)~\cite{asl_eigenspace-based_2010} which does adaptive beamforming, the traditional Phase Coherence Imaging (PCF)~\cite{PCF}, a model-based approach 
%leveraging 
with
regularization by denoising (RED)~\cite{RED_USIPB}, and \yz{a learning-based approach} using MobileNetV2 (MNV2)~\cite{MNV2}.

% Figure environment removed

\begin{comment}
\begin{table}[h]%[b]
\caption{Comparison of image quality metrics on the PICMUS dataset.}
\label{Tab: picmus metrics}
\resizebox{\textwidth}{!}{%
\begin{tabular}{ccc|ccc|cc|cc|cccc}
\hline
 &  &  & \multicolumn{3}{c|}{DAS} & \multicolumn{2}{c|}{no fine-tuning} & \multicolumn{2}{c|}{after fine-tuning} & \multirow{2}{*}{EMV\cite{asl_eigenspace-based_2010}} & \multirow{2}{*}{PCF\cite{PCF}} & \multirow{2}{*}{RED\cite{RED_USIPB}} & \multirow{2}{*}{MNV2\cite{MNV2}} \\ \cline{7-10}
 &  &  & 1 & 11 & 75 & DRUS & WDRUS & DRUS & WDRUS &  &  &  &  \\ \hline
\multicolumn{1}{c|}{\multirow{2}{*}{SR}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}FWHM\\ {[}mm{]}\end{tabular}} & A$\downarrow$ & 0.38 & 0.38 & 0.38 & 0.30 & 0.32 & 0.34 & 0.31 & 0.40 & 0.30 & 0.37 & 0.42 \\
\multicolumn{1}{c|}{} &  & L$\downarrow$ & 0.81 & 0.53 & 0.56 & 0.47 & 0.31 & 0.39 & 0.28 & 0.10 & 0.38 & 0.46 & 0.27 \\ \hline
\multicolumn{1}{c|}{\multirow{4}{*}{SC}} & \multicolumn{2}{c|}{CNR{[}dB{]}$\uparrow$} & 10.41 & 12.86 & 15.89 & 16.37 & 15.20 & 15.74 & 16.33 & 11.21 & 0.46 & 15.48 & 10.48 \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{gCNR$\uparrow$} & 0.91 & 0.97 & 1.00 & 0.99 & 0.99 & 0.99 & 0.99 & 0.93 & 0.41 & 0.94 & 0.89 \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{SNR} & 1.72 & 1.69 & 1.68 & 2.06 & 1.98 & 2.03 & 1.99 & / & / & / & / \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{KS} & \Checkmark & \Checkmark & \Checkmark & \Checkmark & \Checkmark & \Checkmark & \Checkmark & \Checkmark & \XSolidBrush & \Checkmark & \Checkmark \\ \hline
\multicolumn{1}{c|}{\multirow{2}{*}{ER}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}FWHM\\ {[}mm{]}\end{tabular}} & A$\downarrow$ & 0.56 & 0.54 & 0.54 & 0.34 & 0.34 & 0.27 & 0.22 & 0.59 & 5.64 & 0.48 & 0.53 \\
\multicolumn{1}{c|}{} &  & L$\downarrow$ & 0.87 & 0.54 & 0.56 & 0.63 & 1.05 & 0.55 & 0.69 & 0.42 & 0.76 & 0.76 & 0.77 \\ \hline
\multicolumn{1}{c|}{\multirow{4}{*}{EC}} & \multicolumn{2}{c|}{CNR{[}dB{]}$\uparrow$} & 7.85 & 11.20 & 12.00 & 9.00 & -7.25 & 11.75 & 13.55 & 8.10 & 3.20 & 14.70 & 7.80 \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{gCNR$\uparrow$} & 0.87 & 0.94 & 0.95 & 0.88 & 0.69 & 0.96 & 0.97 & 0.83 & 0.68 & 0.98 & 0.83 \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{SNR} & 1.97 & 1.91 & 1.92 & 1.91 & 1.50 & 2.11 & 1.92 & / & / & / & / \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{KS} & \Checkmark & \Checkmark & \Checkmark & \Checkmark & \XSolidBrush & \Checkmark & \Checkmark & \Checkmark & \XSolidBrush & \Checkmark & \Checkmark \\ \hline
\end{tabular}%
}
\end{table}
\end{comment}
\begin{table}[ht]%[b]
\caption{\dm{Image quality metrics on the PICMUS SR, SC, ER, EC datasets.}}
\label{Tab: picmus metrics}
\resizebox{\textwidth}{!}{%
\begin{tabular}{ccc|ccc|cc|cc|cccc}
\hline
 & \multicolumn{2}{|c|}{Metric}  & \multicolumn{3}{c|}{DAS} & \multicolumn{2}{c|}{no fine-tuning} & \multicolumn{2}{c|}{after fine-tuning} & \multirow{2}{*}{EMV\cite{asl_eigenspace-based_2010}} & \multirow{2}{*}{PCF\cite{PCF}} & \multirow{2}{*}{RED\cite{RED_USIPB}} & \multirow{2}{*}{MNV2\cite{MNV2}} \\ \cline{7-10}
 & \multicolumn{2}{|c|}{}  & 1 & 11 & 75 & DRUS & WDRUS & DRUS & WDRUS &  &  &  &  \\ \hline
\multicolumn{1}{c|}{\multirow{2}{*}{SR}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}FWHM\\ {[}mm{]}\end{tabular}} & A$\downarrow$ & 0.38 & 0.38 & 0.38 & 0.30 & 0.32 & 0.34 & 0.31 & 0.40 & 0.30 & 0.37 & 0.42 \\
\multicolumn{1}{c|}{} &  & L$\downarrow$ & 0.81 & 0.53 & 0.56 & 0.47 & 0.31 & 0.39 & 0.28 & 0.10 & 0.38 & 0.46 & 0.27 \\ \hline
\multicolumn{1}{c|}{\multirow{4}{*}{SC}} & \multicolumn{2}{c|}{CNR{[}dB{]}$\uparrow$} & 10.41 & 12.86 & 15.89 & 16.37 & 15.20 & 15.74 & 16.33 & 11.21 & 0.46 & 15.48 & 10.48 \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{gCNR$\uparrow$} & 0.91 & 0.97 & 1.00 & 0.99 & 0.99 & 0.99 & 0.99 & 0.93 & 0.41 & 0.94 & 0.89 \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{SNR $|$ KS} & 1.72$|$\Checkmark & 1.69$|$\Checkmark & 1.68$|$\Checkmark & 2.06$|$\Checkmark & 1.98$|$\Checkmark & 2.03$|$\Checkmark & 1.99$|$\Checkmark & / $|$ \Checkmark & / $|$ \XSolidBrush & / $|$ \Checkmark & / $|$ \Checkmark \\ \hline
\multicolumn{1}{c|}{\multirow{2}{*}{ER}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}FWHM\\ {[}mm{]}\end{tabular}} & A$\downarrow$ & 0.56 & 0.54 & 0.54 & 0.34 & 0.34 & 0.27 & 0.22 & 0.59 & 5.64 & 0.48 & 0.53 \\
\multicolumn{1}{c|}{} &  & L$\downarrow$ & 0.87 & 0.54 & 0.56 & 0.63 & 1.05 & 0.55 & 0.69 & 0.42 & 0.76 & 0.76 & 0.77 \\ \hline
\multicolumn{1}{c|}{\multirow{4}{*}{EC}} & \multicolumn{2}{c|}{CNR{[}dB{]}$\uparrow$} & 7.85 & 11.20 & 12.00 & 9.00 & -7.25 & 11.75 & 13.55 & 8.10 & 3.20 & 14.70 & 7.80 \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{gCNR$\uparrow$} & 0.87 & 0.94 & 0.95 & 0.88 & 0.69 & 0.96 & 0.97 & 0.83 & 0.68 & 0.98 & 0.83 \\
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{SNR $|$ KS} & 1.97$|$\Checkmark & 1.91$|$\Checkmark & 1.92$|$\Checkmark & 1.91$|$\Checkmark & 1.50$|$\XSolidBrush & 2.11$|$\Checkmark & 1.92$|$\Checkmark & / $|$ \Checkmark & / $|$ \XSolidBrush & / $|$ \Checkmark & / $|$ \Checkmark \\ \hline
\end{tabular}%
}
\end{table}


In terms of resolution and contrast, our method is overall significantly better than DAS with 1 plane-wave transmission and can compete with DAS with 75 plane-wave transmissions, as seen in Table.~\ref{Tab: picmus metrics}. However, when the diffusion model is \yz{not fine-tuned (using the pre-trained weights from ImageNet \cite{dhariwal_diffusion_2021}), %dm there are 
artifacts} on the \texttt{EC} image \dm{are} recovered by WDRUS, which can be explained from two perspectives.
%dm 
\begin{comment}
First, the un-fine-tuned diffusion model was trained on the ImageNet dataset containing only natural images, thus, there is a gap between the prior probability distribution represented and what is required by PICMUS, resulting in an implicit bias.   
\end{comment}
\yz{First, while a pre-trained model is a powerful prior and frees the user from acquiring data and training a huge model, there is still a gap between the distribution of natural vs. ultrasound images.} This point can be confirmed by comparing the performance of DRUS and WDRUS in Fig.\ref{fig: picmus images} before [col(4,5)] and after [col(6,7)] fine-tuning the diffusion model. With the latter, both DRUS and WDRUS reconstruct images with less distortion, particularly for the anechoic regions on \texttt{SC} and \texttt{EC}, and the hyperechoic region on \texttt{ER}.

Second, due to the approximation of the impulse responses, matrix B has a certain degree of error \yz{which is propagated through the eigenvalue decomposition of B and the whitening matrix C. Eventually, such errors may lead to a larger error in WDRUS than in DRUS, as seen when comparing WDRUS [col(5,7)] and DRUS [col(4,6)], despite better contrast and SSIM metrics in Fig.~\ref{fig: metrics_synthetic}. These errors may also explain why WDRUS is weaker than DRUS in terms of lateral resolution (FWHM L in Table.~\ref{Tab: picmus metrics}) of scatterers in the \texttt{ER} phantom.}

\yz{Finally,} although our method can reconstruct high-quality \texttt{SR}, \texttt{SC}, and \texttt{EC} images using the fine-tuned diffusion model, it is still difficult to retain speckle quality for \texttt{ER}, 
%dm and we will leave this issue in our future work.
\dm{which is a current limitation. }



\begin{comment}
\YZ{We compared the results of using DRUS and WDRUS %to process 
\DM{on} 
single plane wave data with the results of using DAS 
%to process 
\DM{with access to}
1, 11, and 75 plane waves. Visually, it is apparent that our method can directly compete with DAS using 75 plane waves, %even better, 
especially for the first three phantoms. For \texttt{EC}, DRUS also performs well, with better brightness than DAS, but WDRUS exhibits unexpected distortions in this task.}

\YZ{Smaller FWHM and larger CNR are desired for better resolution and higher contrast respectively. The optimal two evaluation metrics in each assessment task are bolded in Table \ref{Tab: picmus metrics}. Overall, the comparison of evaluation metrics aligns with Fig.\ref{fig: picmus images}, confirming that DRUS and WDRUS perform much better than DAS in terms of resolution and contrast. Although WDRUS performs well on the first three phantoms and even achieves the best results on the first phantom, it struggles with more complex tasks such as \texttt{EC}.}
\end{comment}
    