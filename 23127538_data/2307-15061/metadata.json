{
  "title": "The RoboDepth Challenge: Methods and Advancements Towards Robust Depth Estimation",
  "authors": [
    "Lingdong Kong",
    "Yaru Niu",
    "Shaoyuan Xie",
    "Hanjiang Hu",
    "Lai Xing Ng",
    "Benoit R. Cottereau",
    "Liangjun Zhang",
    "Hesheng Wang",
    "Wei Tsang Ooi",
    "Ruijie Zhu",
    "Ziyang Song",
    "Li Liu",
    "Tianzhu Zhang",
    "Jun Yu",
    "Mohan Jing",
    "Pengwei Li",
    "Xiaohua Qi",
    "Cheng Jin",
    "Yingfeng Chen",
    "Jie Hou",
    "Jie Zhang",
    "Zhen Kan",
    "Qiang Ling",
    "Liang Peng",
    "Minglei Li",
    "Di Xu",
    "Changpeng Yang",
    "Yuanqi Yao",
    "Gang Wu",
    "Jian Kuai",
    "Xianming Liu",
    "Junjun Jiang",
    "Jiamian Huang",
    "Baojun Li",
    "Jiale Chen",
    "Shuang Zhang",
    "Sun Ao",
    "Zhenyu Li",
    "Runze Chen",
    "Haiyong Luo",
    "Fang Zhao",
    "Jingze Yu"
  ],
  "submission_date": "2023-07-27T17:59:56+00:00",
  "revised_dates": [
    "2024-09-24T23:49:07+00:00"
  ],
  "abstract": "Accurate depth estimation under out-of-distribution (OoD) scenarios, such as adverse weather conditions, sensor failure, and noise contamination, is desirable for safety-critical applications. Existing depth estimation systems, however, suffer inevitably from real-world corruptions and perturbations and are struggled to provide reliable depth predictions under such cases. In this paper, we summarize the winning solutions from the RoboDepth Challenge -- an academic competition designed to facilitate and advance robust OoD depth estimation. This challenge was developed based on the newly established KITTI-C and NYUDepth2-C benchmarks. We hosted two stand-alone tracks, with an emphasis on robust self-supervised and robust fully-supervised depth estimation, respectively. Out of more than two hundred participants, nine unique and top-performing solutions have appeared, with novel designs ranging from the following aspects: spatial- and frequency-domain augmentations, masked image modeling, image restoration and super-resolution, adversarial training, diffusion-based noise suppression, vision-language pre-training, learned model ensembling, and hierarchical feature enhancement. Extensive experimental analyses along with insightful observations are drawn to better understand the rationale behind each design. We hope this challenge could lay a solid foundation for future research on robust and reliable depth estimation and beyond. The datasets, competition toolkit, workshop recordings, and source code from the winning teams are publicly available on the challenge website.",
  "categories": [
    "cs.CV",
    "cs.RO"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15061",
  "pdf_url": "https://arxiv.org/pdf/2307.15061v2",
  "comment": "Technical Report; 65 pages, 34 figures, 24 tables; Code at https://github.com/ldkong1205/RoboDepth",
  "num_versions": null,
  "size_before_bytes": 41489041,
  "size_after_bytes": 602785
}