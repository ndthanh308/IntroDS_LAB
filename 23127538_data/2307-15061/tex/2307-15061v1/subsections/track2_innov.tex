\subsection{The Innovation Prize Solution: AIIA-RDepth}
\noindent\textbf{Authors:} \textcolor{gray}{Sun Ao, Gang Wu, Zhenyu Li, Xianming Liu, and Junjun Jiang.}

\begin{framed}
    \textbf{Summary} - To enhance the resilience of deep depth estimation models, the \texttt{AIIA-RDepth} team introduces a multi-stage methodology that incorporates both spatial and frequency domain operations. Initially, several masks are employed to selectively occlude regions in the input image, followed by spatial domain enhancement techniques. Subsequently, robust attacks are applied to the high-frequency information of the image in the frequency domain. Finally, these two approaches are amalgamated into a unified framework called MRSF: Masking and Recombination in the Spatial and Frequency domains.
\end{framed}

\subsubsection{Overview}
Monocular depth estimation is a vital research area in the field of computer vision and finds wide-ranging applications in industries such as robotics \cite{dong2022survey}, autonomous driving \cite{geiger2012kitti,uhrig2017kitti}, virtual reality, and 3D reconstruction \cite{silberman2012nyu2}. Recently, deep learning has witnessed significant advancements and has gradually become the mainstream approach for addressing monocular depth estimation problems.

Existing models for supervised monocular depth estimation often train and test on datasets within the same distribution, yielding satisfactory performance on the corresponding testing sets. However, when there exists an incomplete distribution match or certain corruptions between the training and testing data, such as variations in weather and lighting conditions, sensor failures and movements, and data processing issues, the performance of these deep learning models tends to be significantly degraded. To address these challenges, the RoboDepth competition introduced novel datasets that include $18$ types of corruptions, aiming to probe the robustness of models against these corruptions. In light of these OoD issues, we propose a robust data augmentation method that enhances images in both spatial and frequency domains.

Among approaches for supervised monocular depth estimation, DepthFormer from Li \textit{et al.} \cite{li2022depthformer} stands out as a significant contribution. This model proposed to leverage the Transformer architecture to effectively capture the global context by integrating an attention mechanism. Furthermore, it employs an additional convolutional branch to preserve local information.

As for data augmentation, the CutOut technique from DeVries and Taylor \cite{devries2017cutout} is widely acknowledged, where square regions of the input are randomly masked out during training. This approach has been proven effective in improving the robustness and overall performance of convolutional neural networks. Additionally, in frequency domain enhancement, Amplitude Phase Reconstruction (APR) from Chen \textit{et al.} \cite{chen2021apr} is an important method. It directs the attention of CNN models toward the phase spectrum, enhancing their ability to extract meaningful information from the frequency domain.

\subsubsection{Technical Approach}
In this section, we will elucidate the motivation behind and introduce the two components of our Masking and Recombination in the Spatial and Frequency domains (MRSF) approach: 1) masking image regions in the spatial domain and 2) reconstructing the image in the frequency domain. Figure~\ref{fig:track2_innov_framework} provides an overview of MRSF.

% Figure environment removed

\noindent\textbf{Motivation}.
While considerable progress has been made in learning-based depth estimation models, their training and testing processes often rely on clean datasets, disregarding the OoD situations. In practical scenarios, common corruptions are more likely to occur, which can have safety-critical implications for applications such as autonomous driving and robot navigation.

Upon thorough examination of various corrupted images in the RoboDepth Challenge, we have observed that the corruption effects introduced in the competition are inclined to contain high-frequency interference, consequently resulting in substantial alterations to the local information.

To rectify the perturbations to local information and address the issue of high-frequency interference, we employ a robust data augmentation technique, MRSF, that encompasses both spatial and frequency domain operations. This approach enabled us to capture the global information of the image while simultaneously addressing the high-frequency disturbances introduced by the attacking images.

\noindent\textbf{SDA: Spatial Domain Augmentation}.
To facilitate the model’s enhanced understanding of global image information and improve its robustness, we employ a masking method to augment the images in the spatial domain. Initially, we randomly select $N$ points within the $640\times480$ images of NYU Depth V2 \cite{silberman2012nyu2}. These points serve as the top-left corners for generating patch masks, each of a fixed size (specifically, we use a square of size $a\times a$ in the practical implementation, where $a$ is the mask length). If a mask extended beyond the boundaries of the original image, the exceeding portion will be discarded to ensure that only parts within the image are retained.

% Figure environment removed

% Figure environment removed

The overall pipeline of SDA is shown in Figure~\ref{fig:track2_innov_sda}. Through this process, we generate $N$ mask images based on the $N$ points. Subsequently, we perform a logical \texttt{OR} operation on these $N$ mask images, merging them into a final image mask. By applying this mask to the original image, we obtain the augmented image in the spatial domain. The SDA method relies on two critical hyperparameters, namely $N$ and $a$, which have a substantial impact on its performance. Figure~\ref{fig:track2_innov_sda_effect} provides examples of setting $N$ to different values. To determine their optimal values, we conducted an extensive series of experiments. Through careful analysis, we discover that setting $N$ to $12$ and $a$ to $120$ resulted in the model achieving its peak performance. This finding highlights the importance of precisely tuning these hyperparameters in order to maximize the effectiveness of the SDA method.

\noindent\textbf{FDA: Frequency Domain Augmentation}.
We apply a rotation of angle $\theta$ to the original input image, resulting in a new image. Subsequently, we perform a two-dimensional Fourier transform to convert both images into the frequency domain, yielding two frequency domain representations. While preserving the phase spectrum of the frequency domain images, we extract the magnitude values from each frequency domain representation.

% Figure environment removed

% Figure environment removed

% Figure environment removed

\begin{table*}[t]
\caption{Quantitative results on the RoboDepth competition leaderboard (Track \# 2). The \textbf{best} and \underline{second best} scores of each metric are highlighted in \textbf{bold} and \underline{underline}, respectively.}
\centering\scalebox{0.78}{
    \begin{tabular}{l|cccc|ccc}
    \toprule
    \textbf{Method} & \cellcolor{blue!10}\textbf{Abs Rel~$\downarrow$} & \cellcolor{blue!10}\textbf{Sq Rel~$\downarrow$} & \cellcolor{blue!10}\textbf{RMSE~$\downarrow$} & \cellcolor{blue!10}\textbf{log RMSE~$\downarrow$} & \cellcolor{red!10}$\delta<1.25$~$\uparrow$ & \cellcolor{red!10}$\delta<1.25^2$~$\uparrow$ & \cellcolor{red!10}$\delta<1.25^3$~$\uparrow$
    \\\midrule\midrule
    USTCxNetEaseFuxi & $\mathbf{0.088}$ & \underline{$0.046$} & \underline{$0.347$} & $\mathbf{0.115}$ & $\mathbf{0.940}$ & \underline{$0.985$} & \underline{$0.996$}
    \\
    OpenSpaceAI & \underline{$0.095$} & $\mathbf{0.045}$ & $\mathbf{0.341}$ & \underline{$0.117$} & \underline{$0.928$} & $\mathbf{0.990}$ & $\mathbf{0.998}$
    \\
    GANCV & $0.104$ & $0.060$ & $0.391$ & $0.131$ & $0.898$ & $0.982$ & $0.995$
    \\\midrule
    \textbf{AIIA-RDepth~(Ours)} & $0.123$ & $0.088$ & $0.480$ & $0.162$ & $0.861$ & $0.975$ & $0.993$
    \\\bottomrule
\end{tabular}
}
\label{tab:track2_innov_leaderboard}
\end{table*}

\begin{table*}[t]
\caption{Quantitative results of different components in the proposed MRSF framework. The \textbf{best} and \underline{second best} scores of each metric are highlighted in \textbf{bold} and \underline{underline}, respectively.}
\centering\scalebox{0.78}{
    \begin{tabular}{l|cccc|ccc}
    \toprule
    \textbf{Method} & \cellcolor{blue!10}\textbf{Abs Rel~$\downarrow$} & \cellcolor{blue!10}\textbf{Sq Rel~$\downarrow$} & \cellcolor{blue!10}\textbf{RMSE~$\downarrow$} & \cellcolor{blue!10}\textbf{log RMSE~$\downarrow$} & \cellcolor{red!10}$\delta<1.25$~$\uparrow$ & \cellcolor{red!10}$\delta<1.25^2$~$\uparrow$ & \cellcolor{red!10}$\delta<1.25^3$~$\uparrow$
    \\\midrule\midrule
    DepthFormer \cite{li2022depthformer} & $0.131$ & $0.095$ & $0.507$ & $0.170$ & $0.827$ & $0.963$ & $0.987$
    \\\midrule
    + SDA & \underline{$0.127$} & $\mathbf{0.088}$ & $\mathbf{0.480}$ & $\mathbf{0.162}$ & \underline{$0.850$} & $0.967$ & $0.988$
    \\
    + FDA & $0.128$ & \underline{$0.087$} & \underline{$0.462$} & \underline{$0.160$} & \underline{$0.850$} & \underline{$0.969$} & \underline{$0.989$}
    \\\midrule
    + \textbf{MRSF} & $\mathbf{0.123}$ & $\mathbf{0.088}$ & $\mathbf{0.480}$ & $\mathbf{0.162}$ & $\mathbf{0.861}$ & $\mathbf{0.975}$ & $\mathbf{0.993}$
    \\\bottomrule
\end{tabular}
}
\label{tab:track2_innov_ablation}
\end{table*}

The overall pipeline of FDA is shown in Figure~\ref{fig:track2_innov_fda}. The first image tends to retain its low-frequency components, with the low-frequency signal defined as the area with a size of $S$ around the center of the frequency domain image; while the remaining portion represented the high-frequency signal. The second image tends to exclusively preserve its high-frequency components. We then reconstruct the low-frequency and high-frequency components of the two frequency domain representations, resulting in a single reconstructed frequency domain image. Subsequently, we apply a mask to the high-frequency portion of this frequency domain image to enhance the model’s robustness to high-frequency information. We obtain the final image by performing an inverse Fourier transform.

In this method, two crucial hyperparameters, \textit{i.e.} $\theta$ and $S$, play significant roles in the success of the FDA. Figure~\ref{fig:track2_innov_fda_effect} provides examples of setting $\theta$ to different values. We conducted extensive experiments on these two parameters and found that the model tends to achieve the optimal performance when $\theta$ is set to $24$ degrees and $S$ is set to $50\times50$.

\noindent\textbf{MRSF: Masking \& Recombination in Spatial \& Frequency Domains}.
After incorporating the SDA and FDA methods, we observe significant performance improvements in the OoD testing set. Therefore, combining these two methods became a natural idea. Our approach involves concatenating the two methods and assigning a certain probability for their usage, denoted as $\rho1$ and $\rho2$, respectively, during a joint data augmentation. Regarding the issue of the order in which the methods are applied, we conducted experiments and found that when SDA is applied first, the masks have already disrupted the model’s frequency domain properties. Consequently, conducting an attack in the frequency domain after the SDA stage results in images with significant discrepancies in both frequency and spatial domains compared to the original image, rendering the data augmentation ineffective. To address this, we adopted the strategy of performing FDA first, followed by a spatial domain enhancement, to achieve our combined data augmentation.

In our MRSF approach, the two mentioned hyperparameters, $\rho1$, and $\rho2$, play a significant role in balancing the augmentation effects brought by SDA and FDA. We conducted extensive experiments on these two parameters and determined that the optimal performance tends to be achieved when $\rho1$ and $\rho2$ are both set to $0.5$.

\subsubsection{Experimental Analysis}
\noindent\textbf{Implementation Details}.
The MRSF framework is built upon DepthFormer \cite{li2022depthformer} -- a state-of-the-art model in the field of monocular depth estimation which incorporates a Swin Transformer backbone to capture the global context of the input image through an effective attention mechanism. It also utilizes a CNN to extract local information and employs a hierarchical aggregation and heterogeneous interaction module to fuse the features obtained from both components. Figure~\ref{fig:track2_innov_depthformer} provides an overview of DepthFormer \cite{li2022depthformer}. We resort to the Monocular-Depth-Estimation-Toolbox \cite{lidepthtoolbox2022} for the implementation of our baseline. The model is trained on the official training split of the NYU Depth V2 dataset \cite{silberman2012nyu2}, which contains $24000$ RGB-depth pairs with a spatial resolution of $640\times480$. 

\noindent\textbf{Comparative Study}.
We summarize the competition results in Table~\ref{tab:track2_innov_leaderboard}. Our approach achieved the fourth position in the second track of the RoboDepth competition and was honored with the innovative prize. Subsequently, we proceed to study the effects brought by SDA, FDA, and MRSF. The results are shown in Table~\ref{tab:track2_innov_ablation}. Specifically, for MRSF, we employed a stochastic approach where we randomly applied the FDA method to attack the model in the frequency domain, particularly targeting the high-frequency components, with a certain probability. Within the already perturbed images, we further applied the SDA model in the spatial domain using a random mask, again with a certain probability. Through this fusion approach, our method exhibited performance improvements beyond those achieved by either individual method alone.

\noindent\textbf{Ablation Study}.
After completing the baseline testing, we proceed to ablate the effects brought by SDA and FDA. When applying masks in the spatial domain, the number of masks ($N$) and the size of individual masks ($a$) are two critical hyperparameters to determine. We conducted numerous experiments regarding these two parameters and show the results in Table~\ref{tab:track2_innov_sda}.

Initially, we made a conjecture that the model’s performance is correlated with the total area of the masks; when the total area remains constant, the impact of $N$ and $a$ on the model’s performance would be limited. This conjecture was validated in the first three experimental groups. Subsequently, while keeping the size of individual masks ($a$) fixed, we varied the number of masks ($N$) and found that the model achieved optimal performance when $N$ was set to $12$ and $a$ was set to $120$. When the mask size is too large or too small, the model’s performance does not reach its optimal level. Our experiments have demonstrated that the model tends to achieve the best possible performance when the total area of the masks is approximately $75\%$ of the original input resolution.

\begin{table*}[t]
\caption{Ablation results of Spatial Domain Augmentation (SDA) with different hyperparameters on the testing set of the second track of the RoboDepth competition. The \textbf{best} and \underline{second best} scores of each metric are highlighted in \textbf{bold} and \underline{underline}, respectively.}
\centering\scalebox{0.78}{
    \begin{tabular}{l|cccc|ccc}
    \toprule
    \textbf{Method} & \cellcolor{blue!10}\textbf{Abs Rel~$\downarrow$} & \cellcolor{blue!10}\textbf{Sq Rel~$\downarrow$} & \cellcolor{blue!10}\textbf{RMSE~$\downarrow$} & \cellcolor{blue!10}\textbf{log RMSE~$\downarrow$} & \cellcolor{red!10}$\delta<1.25$~$\uparrow$ & \cellcolor{red!10}$\delta<1.25^2$~$\uparrow$ & \cellcolor{red!10}$\delta<1.25^3$~$\uparrow$
    \\\midrule\midrule
    DepthFormer \cite{li2022depthformer} & $0.131$ & $0.095$ & $0.507$ & $0.170$ & $0.827$ & $0.963$ & \underline{$0.987$}
    \\\midrule
    + SDA ($N=12, a=60$) & \underline{$0.128$} & $0.091$ & $0.491$ & $0.166$ & $0.839$ & $0.964$ & \underline{$0.987$}
    \\
    + SDA ($N=48, a=30$) & $\mathbf{0.127}$ & $0.091$ & $0.491$ & $0.165$ & $0.840$ & \underline{$0.965$} & \underline{$0.987$}
    \\
    + SDA ($N=3, a=120$) & $\mathbf{0.127}$ & \underline{$0.089$} & $0.489$ & $0.165$ & $0.843$ & \underline{$0.965$} & \underline{$0.987$}
    \\
    + SDA ($N=6, a=120$) & $\mathbf{0.127}$ & \underline{$0.089$} & \underline{$0.484$} & \underline{$0.163$} & \underline{$0.846$} & \underline{$0.965$} & $\mathbf{0.988}$
    \\
    + SDA ($N=12, a=120$) & $\mathbf{0.127}$ & $\mathbf{0.088}$ & $\mathbf{0.480}$ & $\mathbf{0.162}$ & $\mathbf{0.850}$ & $\mathbf{0.967}$ & $\mathbf{0.988}$
    \\\bottomrule
\end{tabular}
}
\label{tab:track2_innov_sda}
\end{table*}

\begin{table*}[t]
\caption{Ablation results of Frequency Domain Augmentation (FDA) with different hyperparameters on the testing set of the second track of the RoboDepth competition. The \textbf{best} and \underline{second best} scores of each metric are highlighted in \textbf{bold} and \underline{underline}, respectively.}
\centering\scalebox{0.78}{
    \begin{tabular}{l|cccc|ccc}
    \toprule
    \textbf{Method} & \cellcolor{blue!10}\textbf{Abs Rel~$\downarrow$} & \cellcolor{blue!10}\textbf{Sq Rel~$\downarrow$} & \cellcolor{blue!10}\textbf{RMSE~$\downarrow$} & \cellcolor{blue!10}\textbf{log RMSE~$\downarrow$} & \cellcolor{red!10}$\delta<1.25$~$\uparrow$ & \cellcolor{red!10}$\delta<1.25^2$~$\uparrow$ & \cellcolor{red!10}$\delta<1.25^3$~$\uparrow$
    \\\midrule\midrule
    DepthFormer \cite{li2022depthformer} & $0.131$ & $0.095$ & $0.507$ & $0.170$ & $0.827$ & $0.963$ & $0.987$
    \\\midrule
    + FDA ($\theta=3$) & \underline{$0.127$} & \underline{$0.089$} & $0.477$ & $0.163$ & $0.846$ & $0.966$ & $0.987$
    \\
    + FDA ($\theta=6$) & \underline{$0.127$} & \underline{$0.089$} & $0.477$ & $0.163$ & \underline{$0.847$} & $0.966$ & $0.987$
    \\
    + FDA ($\theta=12$) & \underline{$0.127$} & $\mathbf{0.087}$ & $0.471$ & \underline{$0.161$} & \underline{$0.847$} & \underline{$0.968$} & \underline{$0.988$}
    \\
    + FDA ($\theta=24$) & $\mathbf{0.128}$ & $\mathbf{0.087}$ & $\mathbf{0.462}$ & $\mathbf{0.160}$ & $\mathbf{0.850}$ & $\mathbf{0.969}$ & $\mathbf{0.989}$
    \\
    + FDA ($\theta=48$) & $0.131$ & $0.090$ & \underline{$0.464$} & \underline{$0.161$} & $\mathbf{0.850}$ & \underline{$0.968$} & $\mathbf{0.989}$
    \\\bottomrule
\end{tabular}
}
\label{tab:track2_innov_fda}
\end{table*}

Furthermore, we conduct extensive experiments in the frequency domain augmentation. Our method primarily focused on testing various rotation angles, as depicted in Table~\ref{tab:track2_innov_fda}. Ultimately, we found that the optimal value for $\theta$ is $24$ degrees. This is because excessively small $\theta$ values would result in minimal changes to the image, while excessively large values may lead to the loss of crucial information. Additionally, the partitioning of high-frequency and low-frequency information is an important parameter that we explored through experiments. Eventually, we discovered that the model would perform well when low-frequency information was preserved within a rectangular region of size $50\times50$ at the center of the frequency domain image.

\subsubsection{Solution Summary}
In this work, to address the challenge of robust monocular depth estimation, we employed a multi-stage approach. Firstly, we utilized a masking technique to selectively occlude regions in the input image to enhance the spatial domain representation learning. Subsequently, we performed frequency domain operations to separate the high-frequency and low-frequency information of the image, followed by a series of robustness-enhancing techniques applied specifically to the high-frequency information. By employing these two augmentations, we significantly improved the model’s robustness on the OoD testing dataset. We evaluated our proposed approach in the second track of the RoboDepth Challenge and achieved the innovative prize.