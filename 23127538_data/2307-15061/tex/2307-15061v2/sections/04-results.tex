\section{Challenge Results}
\label{sec:challenge_results}

\subsection{Evaluation Metrics}
In the RoboDepth Challenge, the two most conventional metrics were adopted: 1) error rate, including \texttt{Abs Rel}, \texttt{Sq Rel}, \texttt{RMSE}, and \texttt{log RMSE}; and 2) accuracy, including $\delta_1$, $\delta_2$, and $\delta_3$.

\noindent\textbf{Error Rate}.
The Relative Absolute Error (\texttt{Abs Rel}) measures the relative difference between the pixel-wise ground-truth (\texttt{gt}) and the prediction values (\texttt{pred}) in a depth prediction map $D$, as calculated by the following equation:
\begin{equation}
\text{Abs Rel} = \frac{1}{|D|}\sum_{pred\in D}\frac{|gt - pred|}{gt}~.
\end{equation}
The Relative Square Error (\texttt{Sq Rel}) measures the relative square difference between \texttt{gt} and \texttt{pred} as follows:
\begin{equation}
\text{Sq Rel} = \frac{1}{|D|}\sum_{pred\in D}\frac{|gt - pred|^2}{gt}~.
\end{equation}
\texttt{RMSE} denotes the Root Mean Square Error (in meters) of a scene (image), which can be calculated as $\sqrt{\sum|gt - pred|^2}$; while \texttt{log RMSE} is the log-normalized version of \texttt{RMSE}, \textit{i.e.}, $\sqrt{\sum|\log(gt) - \log(pred)|^2}$.


\noindent\textbf{Accuracy}.
The $\delta$ metric is the depth estimation accuracy given the threshold:
\begin{equation}
\delta_t = \frac{1}{|D|}|\{\ pred\in D | \max{(\frac{gt}{pred}, \frac{pred}{gt})< 1.25^t}\}| \times 100\%~,
\end{equation}
where $\delta_1 = \delta<1.25, \delta_2 = \delta<1.25^2, \delta_3 = \delta<1.25^3$ are the three conventionally used accuracy scores among prior works \cite{godard2019monodepth2,lidepthtoolbox2022}.

Following the seminar work MonoDepth2 \cite{godard2019monodepth2}, the \texttt{Abs Rel} metric was selected as the major indicator to compare among submissions in the first track of the RoboDepth Challenge.

Based on the Monocular-Depth-Estimation-Toolbox\footnote{\url{https://github.com/zhyever/Monocular-Depth-Estimation-Toolbox}.}, the $\delta_1$ score was used to rank different submissions in the second track of the RoboDepth Challenge.

\subsection{Track \# 1 Results}

In the first track of the RoboDepth Challenge, we received $684$ valid submissions. The top-performing teams in this track include \texttt{OpenSpaceAI}, \texttt{USTC-IAT-United}, and \texttt{YYQ}. The shortlisted submissions are shown in Table~\ref{tab:track1_results}; the complete results can be found on our evaluation server.

Specifically, the team \texttt{OpenSpaceAI} achieved a \texttt{Abs Rel} score of $0.121$, which is $0.100$ higher than the baseline MonoDepth2 \cite{godard2019monodepth2}. They also ranked first on the \texttt{log RMSE}, $\delta_1$, and $\delta_3$ metrics. Other top-ranked submissions are from: the team \texttt{USTC-IAT-United} (\texttt{Abs Rel}$=0.123$, $\delta_1=0.861$), team \texttt{YYQ} (\texttt{Abs Rel}$=0.123$, $\delta_1=0.848$), team \texttt{zs\_dlut} (\texttt{Abs Rel}$=0.124$, $\delta_1=0.852$), and team \texttt{UMCV} (\texttt{Abs Rel}$=0.124$, $\delta_1=0.847$). We refer readers to the solutions presented in Section~\ref{sec:track1} for additional comparative and ablation results and more detailed analyses.

\input{tables/track1_results}

\subsection{Track \# 2 Results}

In the second track of the RoboDepth Challenge, we received $453$ valid submissions. The top-performing teams in this track include \texttt{USTCxNetEaseFuxi}, \texttt{OpenSpaceAI}, and \texttt{GANCV}. The shortlisted submissions are shown in Table~\ref{tab:track2_results}; the complete results can be found on our evaluation server.

Specifically, the team \texttt{USTCxNetEaseFuxi} achieved a $\delta_1$ score of $0.940$, which is $0.285$ higher than the baseline DepthFormer-SwinT \cite{li2022depthformer}. They also ranked first on the \texttt{Abs Rel} and \texttt{log RMSE} metrics. Other top-ranked submissions are from: the team \texttt{OpenSpaceAI} (\texttt{Abs Rel}$=0.095$, $\delta_1=0.928$), team \texttt{GANCV} (\texttt{Abs Rel}$=0.104$, $\delta_1=0.898$), team \texttt{shinonomei} (\texttt{Abs Rel}$=0.123$, $\delta_1=0.861$), and team \texttt{YYQ} (\texttt{Abs Rel}$=0.125$, $\delta_1=0.851$). We refer readers to the solutions presented in Section~\ref{sec:track2} for additional comparative and ablation results and more detailed analyses.
