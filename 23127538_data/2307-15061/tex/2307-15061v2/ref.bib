@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {European Conference on Computer Vision (ECCV)})
@String(NIPS= {Advances in Neural Information Processing System (NeurIPS)})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf. (BMVC)})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI Conference on Artificial Intelligence})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


% Competition
@misc{RVC,
  title={The Robust Vision Challenge},
  author={Oliver Zendel and Angela Dai and Xavier Puig Fernandez and Andreas Geiger and Vladen Koltun and Peter Kontschieder and Adam Kortylewski and Tsung-Yi Lin and Torsten Sattler and Daniel Scharstein and Hendrik Schilling and Jonas Uhrig and Jonas Wulff},
  howpublished = {\url{http://www.robustvision.net}},
  year={2022}
}

@misc{DDAD,
  title={The Dense Depth for Autonomous Driving (DDAD) Challenge},
  author={Adrien Gaidon and Greg Shakhnarovich and Rares Ambrus and Vitor Guizilini and Igor Vasiljevic and Matthew Walter and Sudeep Pillai and Nick Kolkin},
  howpublished = {\url{https://sites.google.com/view/mono3d-workshop}},
  year={2021}
}

@inproceedings{MobileAI,
  title={Fast and Accurate Single-Image Depth Estimation on Mobile Devices, Mobile AI 2021 Challenge: Report},
  author={Andrey Ignatov and Grigory Malivenko and David Plowman and Samarth Shukla and Radu Timofte},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages = {2545--2557},
  year={2021}
}

@inproceedings{MDEC,
  title={The monocular depth estimation challenge},
  author={Jaime Spencer and C. Stella Qian and Chris Russell and Simon Hadfield and Erich Graf and Wendy Adams and Andrew J. Schofield and James H. Elder and Richard Bowden and Heng Cong and Stefano Mattoccia and Matteo Poggi and Zeeshan Khan Suri and Yang Tang and Fabio Tosi and Hao Wang and Youmin Zhang and Yusheng Zhang and Chaoqiang Zhao},
  booktitle = {IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW)},
  pages = {623--632},
  year={2023}
}

@inproceedings{MDEC2,
  title={The second monocular depth estimation challenge},
  author={Jaime Spencer and C. Stella Qian and Michaela Trescakova and Chris Russell and Simon Hadfield and Erich Graf and Wendy Adams and Andrew J. Schofield and James Elder and Richard Bowden and Ali Anwar and Hao Chen and Xiaozhi Chen and Kai Cheng and Yuchao Dai and Huynh Thai Hoa and Sadat Hossain and Jianmian Huang and Mohan Jing and Bo Li and Chao Li and Baojun Li and Zhiwen Liu and Stefano Mattoccia and Siegfried Mercelis and Myungwoo Nam and Matteo Poggi and Xiaohua Qi and Jiahui Ren and Yang Tang and Fabio Tosi and Linh Trinh and S M Nadim Uddin and Khan Muhammad Umair and Kaixuan Wang and Yufei Wang and Yixing Wang and Mochu Xiang and Guangkai Xu and Wei Yin and Jun Yu and Qi Zhang and Chaoqiang Zhao},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages={3063--3075},
  year={2023}
}

@misc{ArgoverseStereo,
  title={The Argoverse Stereo Competition},
  author={Henrik Kretzschmar and Alex Liniger and Jose M. Alvarez and Yan Wang and Vincent Casser and Fisher Yu and Marco Pavone and Bo Li and Andreas Geiger and Peter Ondruska and Li Erran Li and Dragomir Angelov and John Leonard and Luc Van Gool},
  howpublished = {\url{https://cvpr2022.wad.vision}},
  year={2022}
}

@inproceedings{NTIRE,
  title={NTIRE 2023 Challenge on HR Depth from Images of Specular and Transparent Surfaces},
  author={Pierluigi Zama Ramirez and Fabio Tosi and Luigi Di Stefano and Radu Timofte and Alex Costanzino and Matteo Poggi andSamuele Salti and Stefano Mattoccia and Jun Shi and Dafeng Zhang and Yong A and Yixiang Jin and Dingzhe Li and Chao Li and Zhiwen Liu and Qi Zhang and Yixing Wang and Shi Yin},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages={1384--1395},
  year={2023}
}

@misc{kong2023robodepth_benchmark,
  title = {The RoboDepth Benchmark for Robust Out-of-Distribution Depth Estimation under Corruptions},
  author = {Kong, Lingdong and Xie, Shaoyuan and Hu, Hanjiang and Cottereau, Benoit and Ng, Lai Xing and Ooi, Wei Tsang},
  howpublished = {\url{https://github.com/ldkong1205/RoboDepth}}, 
  year = {2023},
}

@inproceedings{caron2021dino,
    author = {Mathilde Caron and Hugo Touvron and Ishan Misra and Hervé Jégou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
    title = {Emerging properties in self-supervised vision transformers},
    booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
    pages = {9650--9660},
    year = {2021}
}

@article{oquab2023dinov2,
  title = {DINOv2: Learning Robust Visual Features without Supervision},
  author = {Maxime Oquab and Timothée Darcet and Théo Moutakanni and Huy Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and Hervé Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
  journal = {arXiv preprint arXiv:2304.07193},
  year = {2023}
}



% Dataset
@inproceedings{geiger2012kitti,
  title = {Are we ready for autonomous driving? the kitti vision benchmark suite},
  author = {Andreas Geiger and Philip Lenz and Raquel Urtasun},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {3354--3361},
  year = 2012
}

@inproceedings{uhrig2017kitti,
  author = {Jonas Uhrig and Nick Schneider and Lukas Schneider and Uwe Franke and Thomas Brox and Andreas Geiger},
  title = {Sparsity Invariant CNNs},
  booktitle = {IEEE International Conference on 3D Vision (3DV)},
  pages = {11--20},
  year = {2017}
}

@inproceedings{silberman2012nyu2,
  author = {Nathan Silberman and Derek Hoiem and Pushmeet Kohli and Rob Fergus},
  title = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages = {746--760},
  year = {2012}
}

@inproceedings{huang2017adain,
    author = {Xun Huang and Serge Belongie},
    title = {Arbitrary style transfer in real-time with adaptive instance normalization},
    booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
    pages = {1501--1510},
    year = 2017
}

@inproceedings{cordts2016cityscapes,
  title = {The cityscapes dataset for semantic urban scene understanding},
  author = {Marius Cordts and Mohamed Omran and Sebastian Ramos and Timo Rehfeld and Markus Enzweiler and Rodrigo Benenson and Uwe Franke and Stefan Roth and Bernt Schiele},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {3213--3223},
  year = 2016
}

@article{sakaridis2018semantic,
  author = {Sakaridis, Christos and Dai, Dengxin and Van Gool, Luc},
  title = {Semantic Foggy Scene Understanding with Synthetic Data},
  journal = {International Journal of Computer Vision},
  volume = {126},
  number = {9},
  pages = {973--992},
  year = {2018}
}

@article{saxena2008make3d,
  title={Make3d: Learning 3d scene structure from a single still image},
  author={Ashutosh Saxena and Min Sun and Andrew Y. Ng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
  volume={31},
  number={5},
  pages={824--840},
  year={2008}
}

@article{VOC,
  author = {Everingham, Mark and Gool, Luc and Williams, Christopher K. and Winn, John and Zisserman, Andrew},
  title = {The Pascal Visual Object Classes (VOC) Challenge},
  year = {2010},
  volume = {88},
  number = {2},
  journal = {International Journal of Computer Vision (IJCV)},
  pages = {303–338},
}

@inproceedings{COCO,
  title = {Microsoft coco: Common objects in context},
  author = {Tsung-Yi Lin and Michael Maire and Serge Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Dollár and C. Lawrence Zitnick},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages = {740--755},
  year = {2014},
}

@inproceedings{behley2019semanticKITTI,
    author = {Jens Behley and Martin Garbade and Andres Milioto and Jan Quenzel and Sven Behnke and Cyrill Stachniss and Juergen Gall},
    title = {SemanticKitti: A dataset for semantic scene understanding of lidar sequences},
    booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
    pages = {9297--9307},
    year = {2019}
}




% Survey
@article{ming2021survey,
  title={Deep learning for monocular depth estimation: A reviews},
  author={Yue Ming and Xuyang Meng and Chunxiao Fan and Hui Yu},
  journal={Neurocomputing},
  volume={438},
  pages={14--33},
  year={2021}
}

@article{zhao2020survey,
  title={Monocular depth estimation based on deep learning: An overview},
  author={Chaoqiang Zhao and Qiyu Sun and Chongzhen Zhang and Yang Tang and Feng Qian},
  journal={Science China Technological Sciences},
  volume={63},
  number={9},
  pages={1612--1627},
  year={2020}
}

@article{laga2020survey,
  title={A survey on deep learning techniques for stereo-based depth estimation},
  author={Hamid Laga and Laurent Valentin Jospin and Farid Boussaid and Mohammed Bennamoun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
  volume={44},
  number={4},
  pages={1738--1764},
  year={2020}
}

@article{dong2022survey,
  title={Towards real-time monocular depth estimation for robotics: A survey},
  author={Xingshuai Dong and Matthew A. Garratt and Sreenatha G. Anavatti and Hussein A. Abbass},
  journal={IEEE Transactions on Intelligent Transportation Systems (TITS)},
  volume={23},
  number={10},
  pages={16940--16961},
  year={2022}
}

@article{wang2023survey_robustness,
  title={The Robustness of Computer Vision Models
against Common Corruptions: A Survey},
  author={Shunxin Wang and Raymond Veldhuis and Nicola Strisciuglio},
  journal={arXiv preprint arXiv:2305.06024},
  year={2023}
}

% Monocular Depth Estimation
@inproceedings{eigen2014depth,
  title={Depth map prediction from a single image using a multi-scale deep network},
  author={David Eigen and Christian Puhrsch and Rob Fergus},
  booktitle={Advances in Neural Information Processing System (NeurIPS)},
  year={2014}
}

@article{liu2015learning,
  title={Learning depth from single monocular images using deep convolutional neural fields},
  author={Fayao Liu and Chunhua Shen and Guosheng Lin and Ian Reid},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
  volume={38},
  number={10},
  pages={2024--2039},
  year={2015}
}

@inproceedings{garg2016unsupervised,
  title = {Unsupervised CNN for single view depth estimation: Geometry to the rescue},
  author = {Garg, Ravi and Kumar, BG Vijay and Carneiro, Gustavo and Reid, Ian},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages = {740--756},
  year = {2016},
}

@inproceedings{zhou2017sfm,
  title = {Unsupervised learning of depth and ego-motion from video},
  author = {Tinghui Zhou and Matthew Brown and Noah Snavely and David G. Lowe},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {1851--1858},
  year = 2017
}

@inproceedings{godard2017unsupervised,
  title = {Unsupervised monocular depth estimation with left-right consistency},
  author = {Clément Godard and Oisin Mac Aodha and Gabriel J. Brostow},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {270--279},
  year = 2017
}

@inproceedings{bian2019scdepth,
  title={Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video},
  author={Bian, Jiawang and Li, Zhichao and Wang, Naiyan and Zhan, Huangying and Shen, Chunhua and Cheng, Ming-Ming and Reid, Ian},
  booktitle={Advances in Neural Information Processing System (NeurIPS)},
  year={2019}
}

@inproceedings{godard2019monodepth2,
    author = {Clément Godard and Oisin Mac Aodha and Michael Firman and Gabriel J. Brostow},
    title = {Digging into Self-Supervised Monocular Depth Prediction},
    booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
    pages = {3828--3838},
    year = 2019
}

@inproceedings{watson2019hints,
    author = {Jamie Watson and Michael Firman and Gabriel J. Brostow and Daniyar Turmukhambetov},
    title = {Self-supervised monocular depth hints},
    booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
    pages = {2162--2171},
    year = 2019
}

@article{schellevis2019maskocc,
    author = {Maarten Schellevis},
    title = {Improving Self-Supervised Single View Depth Estimation by Masking Occlusion},
    journal = {arXiv preprint arXiv:1908.11112},
    year = 2019
}

@article{lee2019big,
  title = {From big to small: Multi-scale local planar guidance for monocular depth estimation},
  author = {Lee, Jin Han and Han, Myung-Kyu and Ko, Dong Wook and Suh, Il Hong},
  journal = {arXiv preprint arXiv:1907.10326},
  year = 2019
}

@inproceedings{bhat2021adabins,
  title = {Adabins: Depth estimation using adaptive bins},
  author = {Bhat, Shariq Farooq and Alhashim, Ibraheem and Wonka, Peter},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {4009--4018},
  year = 2021
}

@inproceedings{ranftl2021dpt,
  title = {Vision transformers for dense prediction},
  author = {Ranftl, Ren{\'e} and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages = {12179--12188},
  year = 2021
}

@inproceedings{xue2020dnet,
    author = {Feng Xue and Guirong Zhuo and Ziyuan Huang and Wufei Fu and Zhuoyue Wu and Marcelo H. Ang},
    title = {Toward hierarchical self-supervised monocular absolute depth estimation for autonomous driving applications},
    booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
    pages = {2330--2337},
    year = 2020
}

@inproceedings{yan2021cadepth,
    author = {Jiaxing Yan and Hong Zhao and Penghui Bu and YuSheng Jin},
    title = {Channel-wise attention-based network for self-supervised monocular depth estimation},
    booktitle = {IEEE International Conference on 3D Vision (3DV)},
    pages = {464--473},
    year = 2021
}

@inproceedings{lyu2021hrdepth,
    author = {Xiaoyang Lyu and Liang Liu and Mengmeng Wang and Xin Kong and Lina Liu and Yong Liu and Xinxin Chen and Yi Yuan},
    title = {Hr-depth: High resolution self-supervised monocular depth estimation},
    booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
    pages = {2294--2301},
    year = 2021
}

@inproceedings{li2022simipu,
  title = {SimIPU: Simple 2D Image and 3D Point Cloud Unsupervised Pre-Training for Spatial-Aware Visual Representations},
  author = {Li, Zhenyu and Chen, Zehui and Li, Ang and Fang, Liangji and Jiang, Qinhong and Liu, Xianming and Jiang, Junjun and Zhou, Bolei and Zhao, Hang},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year = {2022}
}

@article{li2022depthformer,
  title={DepthFormer: Exploiting Long-Range Correlation and Local Information for Accurate Monocular Depth Estimation},
  author={Li, Zhenyu and Chen, Zehui and Liu, Xianming and Jiang, Junjun},
  journal={arXiv preprint arXiv:2203.14211},
  year={2022}
}

@inproceedings{watson2021manydepth,
    author = {Jamie Watson and Oisin Mac Aodha and Victor Prisacariu and Gabriel Brostow and Michael Firman},
    title = {The temporal opportunist: Self-supervised multi-frame monocular depth},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {1164--1174},
    year = 2021
}

@inproceedings{zhou2021diffnet,
    title={Self-Supervised Monocular Depth Estimation with Internal Feature Fusion},
    author={Hang Zhou and David Greenwood and Sarah Taylor},
    booktitle={British Machine Vision Conference (BMVC)},
    year={2021}
}

@inproceedings{jung2021fsre,
    author = {Hyunyoung Jung and Eunhyeok Park and Sungjoo Yoo},
    title = {Fine-grained semantics-aware representation enhancement for self-supervised monocular depth estimation},
    booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
    pages = {12642--12652},
    year = 2021
}

@inproceedings{johnston2020self,
    author = {Adrian Johnston and Gustavo Carneiro},
    title = {Self-supervised monocular trained depth estimation using self-attention and discrete disparity volume},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {4756--4765},
    year = 2020
}

@inproceedings{wang2020sdc,
    author = {Lijun Wang and Jianming Zhang and Oliver Wang and Zhe Lin and Huchuan Lu},
    title = {Sdc-depth: Semantic divide-and-conquer network for monocular depth estimation},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {541--550},
    year = 2020
}

@inproceedings{tosi2019learning,
    author = {Fabio Tosi and Filippo Aleotti and Matteo Poggi and Stefano Mattoccia},
    title = {Learning monocular depth estimation infusing traditional stereo knowledge},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {9799--9809},
    year = 2019
}

@inproceedings{zhao2021monovit,
    author = {Chaoqiang Zhao and Youmin Zhang and Matteo Poggi and Fabio Tosi and Xianda Guo and Zheng Zhu and Guan Huang and Yang Tang and Stefano Mattoccia},
    title = {Monovit: Self-supervised monocular depth estimation with a vision transformer},
    booktitle = {IEEE International Conference on 3D Vision (3DV)},
    pages = {668-678},
    year = 2022
}

@inproceedings{zhang2022dynadepth,
  title = {Towards scale-aware, robust, and generalizable unsupervised monocular depth estimation by integrating IMU motion dynamics},
  author = {Zhang, Sen and Zhang, Jing and Tao, Dacheng},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages = {143--160},
  year = {2022},
}

@inproceedings{he2022radepth,
  title = {RA-Depth: Resolution Adaptive Self-Supervised Monocular Depth Estimation},
  author = {Mu, He and Le, Hui and Yikai, Bian and Jian, Ren and Jin, Xie and Jian, Yang},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages = {565--581},
  year = {2022},
}

@inproceedings{chen2023tridepth,
  title = {Self-Supervised Monocular Depth Estimation: Solving the Edge-Fattening Problem},
  author = {Chen, Xingyu and Zhang, Ruonan and Jiang, Ji and Wang, Yan and Li, Ge and Li, Thomas H},
  booktitle = {IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages = {5776--5786},
  year = {2023}
}

@inproceedings{zhang2023litemono,
    author = {Zhang, Ning and Nex, Francesco and Vosselman, George and Kerle, Norman},
    title = {Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {18537-18546},
    year = {2023}
}

@inproceedings{kuznietsov2017semi,
    author = {Yevhen Kuznietsov and Jorg Stuckler and and Bastian Leibe},
    title = {Semi-supervised deep learning for monocular depth map prediction},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {6647--6655},
    year = 2017
}

@article{ji2019semi,
  title={Semi-supervised adversarial monocular depth estimation},
  author={Rongrong Ji and Ke Li and Yan Wang and Xiaoshuai Sun and Feng Guo and Xiaowei Guo and Yongjian Wu and Feiyue Huang and Jiebo Luo},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
  volume={42},
  number={10},
  pages={2410--2422},
  year={2019}
}




% Robust Depth Estimation
@article{ranftl2022towards,
  title={Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer},
  author={René Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
  volume={44},
  number={3},
  pages={1623--1637},
  year={2022}
}

@inproceedings{kopf2023robust,
    author = {Johannes Kopf and Xuejian Rong and Jia-Bin Huang},
    title = {Robust consistent video depth estimation},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {1611--1621},
    year = 2021
}

@article{sun2022scdepthv3,
  title={SC-DepthV3: Robust Self-supervised Monocular Depth Estimation for Dynamic Scenes},
  author={Libo Sun and Jia-Wang Bian and Huangying Zhan and Wei Yin and Ian Reid and Chunhua Shen},
  journal={arXiv preprint arXiv:2211.03660},
  year={2022}
}

@inproceedings{xian2018monocular,
    author = {Ke Xian and Chunhua Shen and Zhiguo Cao and Hao Lu and Yang Xiao and Ruibo Li and Zhenbo Luo},
    title = {Monocular relative depth perception with web stereo data supervision},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {311--320},
    year = 2018
}

@inproceedings{li2018megadepth,
    author = {Zhengqi Li and Noah Snavely},
    title = {Megadepth: Learning single-view depth prediction from internet photos},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {2041--2050},
    year = 2018
}

@inproceedings{wang2019web,
    author = {Chaoyang Wang and Simon Lucey and Federico Perazzi and Oliver Wang},
    title = {Web stereo video supervision for depth prediction from dynamic scenes},
    booktitle = {IEEE International Conference on 3D Vision (3DV)},
    pages = {348--357},
    year = 2019
}

@inproceedings{chen2019learning,
    author = {Weifeng Chen and Shengyi Qian and Jia Deng},
    title = {Learning single-image depth from videos using quality assessment networks},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {5604--5613},
    year = 2019
}

@inproceedings{hu2022seasondepth,
    author = {Hanjiang Hu and Baoquan Yang and Zhijian Qiao and Shiqi Liu and Ding Zhao and Hesheng Wang},
    title = {Seasondepth: Cross-season monocular depth prediction dataset and benchmark under multiple environments},
    booktitle = {International Conference on Machine Learning Workshops (ICMLW)},
    year = 2022
}

@inproceedings{zhang2022hierarchical,
  title={Hierarchical Normalization for Robust Monocular Depth Estimation},
  author={Chi Zhang and Wei Yin and Billzb Wang and Gang Yu and Bin Fu and Chunhua Shen},
  booktitle={Advances in Neural Information Processing System (NeurIPS)},
  pages={14128--14139},
  year={2022}
}

@inproceedings{li2019deep,
  title={Deep attention-based classification network for robust depth prediction},
  author={Ruibo Li and Ke Xian and Chunhua Shen and Zhiguo Cao and Hao Lu and Lingxiao Hang},
  booktitle={Asian Conf. Comput. Vis. (ACCV)},
  pages={663--678},
  year={2019}
}

@inproceedings{cheng2022physical,
  title = {Physical attack on monocular depth estimation with optimal adversarial patches},
  author = {Zhiyuan Cheng and James Liang and Hongjun Choi and Guanhong Tao and Zhiwen Cao and Dongfang Liu and Xiangyu Zhang},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages = {514--532},
  year = {2022},
}

@article{chawla2022image,
  title={Image Masking for Robust Self-Supervised Monocular Depth Estimation},
  author={Hemang Chawla and Kishaan Jeeveswaran and Elahe Arani and Bahram Zonooz},
  journal={arXiv preprint arXiv:2210.02357},
  year={2022}
}



% Common Corruptions
@inproceedings{ImageNet-C,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Dan Hendrycks and Thomas Dietterich},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@article{michaelis2019dragon,
  title={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},
  author={Michaelis, Claudio and Mitzkus, Benjamin and Geirhos, Robert and Rusak, Evgenia and Bringmann, Oliver and Ecker, Alexander S. and Bethge, Matthias and Brendel, Wieland},
  journal={arXiv preprint arXiv:1907.07484},
  year={2019}
}

@inproceedings{kar20223d,
  title={3D Common Corruptions and Data Augmentation},
  author={Kar, O{\u{g}}uzhan Fatih and Yeo, Teresa and Atanov, Andrei and Zamir, Amir},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={18963--18974},
  year={2022}
}

@inproceedings{geirhos2018imagenet-trained,
  title={ImageNet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A Wichmann and Wieland Brendel},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@inproceedings{Cityscapes-C,
  title={Benchmarking the robustness of semantic segmentation models},
  author={Christoph Kamann and Carsten Rother},
  pages = {8828--8838},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020}
}

@inproceedings{Kinetics-C,
  title={Benchmarking the Robustness of Spatial-Temporal Models Against Corruptions},
  author={Chenyu Yi and Siyuan Yang and Haoliang Li and Yap-peng Tan and Alex Kot},
  booktitle={Advances in Neural Information Processing System (NeurIPS)},
  year={2021}
}

@inproceedings{RobustNav,
  title={RobustNav: Towards benchmarking robustness in embodied navigation},
  author={Prithvijit Chattopadhyay and Judy Hoffman and Roozbeh Mottaghi and Aniruddha Kembhavi},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021},
  pages={15691--15700},
}

@inproceedings{AdvMix,
  title={When human pose estimation meets robustness: Adversarial algorithms and benchmarks},
  author={Jiahang Wang and Sheng Jin and Wentao Liu and Weizhong Liu and Chen Qian and Ping Luo},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021},
  pages={11855--11864},
}

@article{kong2023robo3d,
  title = {Robo3D: Towards Robust and Reliable 3D Perception against Corruptions},
  author = {Kong, Lingdong and Liu, Youquan and Li, Xin and Chen, Runnan and Zhang, Wenwei and Ren, Jiawei and Pan, Liang and Chen, Kai and Liu, Ziwei},
  journal = {arXiv preprint arXiv:2303.17597}, 
  year = {2023},
}

@misc{kong2023robo3d_benchmark,
  title = {The Robo3D Benchmark for Robust and Reliable 3D Perception},
  author = {Kong, Lingdong and Liu, Youquan and Li, Xin and Chen, Runnan and Zhang, Wenwei and Ren, Jiawei and Pan, Liang and Chen, Kai and Liu, Ziwei},
  howpublished = {\url{https://github.com/ldkong1205/Robo3D}},
  year = {2023},
}

@article{xie2023robobev,
    title = {RoboBEV: Towards Robust Bird's Eye View Perception under Corruptions},
    author = {Xie, Shaoyuan and Kong, Lingdong and Zhang, Wenwei and Ren, Jiawei and Pan, Liang and Chen, Kai and Liu, Ziwei},
    journal = {arXiv preprint arXiv:2304.06719}, 
    year = {2023}
}

@misc{xie2023robobev_codebase,
    title = {The RoboBEV Benchmark for Robust Bird's Eye View Detection under Common Corruption and Domain Shift},
    author = {Xie, Shaoyuan and Kong, Lingdong and Zhang, Wenwei and Ren, Jiawei and Pan, Liang and Chen, Kai and Liu, Ziwei},
    howpublished = {\url{https://github.com/Daniel-xsy/RoboBEV}},
    year = {2023}
}

@article{ren2022modelnet-c,
  title={Benchmarking and Analyzing Point Cloud Classification under Corruptions},
  author={Jiawei Ren and Liang Pan and Ziwei Liu},
  journal={International Conference on Machine Learning (ICML)},
  year={2022}
}

@misc{PointCloud-C,
    title = {The PointCloud-C Benchmark for Robust Point Cloud Perception under Corruptions},
    author = {Jiawei Ren and Lingdong Kong and Liang Pan and Ziwei Liu},
    howpublished = {\url{https://github.com/ldkong1205/PointCloud-C}},
    year = {2022}
}




% Related Tasks
@inproceedings{caesar2020nuScenes,
    author = {Holger Caesar and Varun Bankiti and Alex H Lang and Sourabh Vora and Venice Erin Liong and Qiang Xu and Anush Krishnan and Yu Pan and Giancarlo Baldan and Oscar Beijbom},
    title = {nuScenes: A multimodal dataset for autonomous driving},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {11621--11631},
    year = {2020}
}

@article{fong2022panoptic-nuScenes,
    author = {Whye Kit Fong and Rohit Mohan and Juana Valeria Hurtado and Lubing Zhou and Holger Caesar and Oscar Beijbom and Abhinav Valada},
    title = {Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking},
    journal = {IEEE Robotics and Automation Letters (RA-L)},
    pages = {3795--3802},
    volumn = {7},
    year = {2022}
}

@inproceedings{kong2022laserMix,
    author = {Lingdong Kong and Jiawei Ren and Liang Pan and Ziwei Liu},
    title = {Lasermix for semi-supervised lidar semantic segmentation},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {21705--21715},
    year = {2023}
}

@inproceedings{chen2023clip2Scene,
    author = {Runnan Chen and Youquan Liu and Lingdong Kong and Xinge Zhu and Yuexin Ma and Yikang Li and Yuenan Hou and Yu Qiao and Wenping Wang},
    title = {CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages = {7020--7030},
    year = {2023}
}

@article{kong2023rethinking,
  title = {Rethinking Range View Representation for LiDAR Segmentation},
  author = {Kong, Lingdong and Liu, Youquan and Chen, Runnan and Ma, Yuexin and Zhu, Xinge and Li, Yikang and Hou, Yuenan and Qiao, Yu and Liu, Ziwei},
  journal = {arXiv preprint arXiv:2303.05367},
  year = {2023}
}

@inproceedings{kong2023conDA,
  title = {ConDA: Unsupervised domain adaptation for LiDAR segmentation via regularized domain concatenation},
  author = {Lingdong Kong and Niamul Quader and Venice Erin Liong},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  pages = {9338--9345},
  year = {2023}
}

@article{liu2023segment,
  title = {Segment Any Point Cloud Sequences by Distilling Vision Foundation Models},
  author = {Liu, Youquan and Kong, Lingdong and Cen, Jun and Chen, Runnan and Zhang, Wenwei and Pan, Liang and Chen, Kai and Liu, Ziwei},
  journal = {arXiv preprint arXiv:2306.09347}, 
  year = {2023},
}

@misc{liu2023segment_any_point_cloud,
  title = {The Segment Any Point Cloud Codebase},
  author = {Liu, Youquan and Kong, Lingdong and Cen, Jun and Chen, Runnan and Zhang, Wenwei and Pan, Liang and Chen, Kai and Liu, Ziwei},
  howpublished = {\url{https://github.com/youquanl/Segment-Any-Point-Cloud}},
  year = {2023},
}

@article{chen2023towards,
  title={Towards Label-free Scene Understanding by Vision Foundation Models},
  author={Chen, Runnan and Liu, Youquan and Kong, Lingdong and Chen, Nenglun and Zhu, Xinge and Ma, Yuexin and Liu, Tongliang and Wang, Wenping},
  journal={arXiv preprint arXiv:2306.03899},
  year={2023}
}

@inproceedings{lang2019pointpillars,
  title={Pointpillars: Fast encoders for object detection from point clouds},
  author={Lang, Alex H and Vora, Sourabh and Caesar, Holger and Zhou, Lubing and Yang, Jiong and Beijbom, Oscar},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={12697--12705},
  year={2019}
}

@article{second,
  title={Second: Sparsely embedded convolutional detection},
  author={Yan, Yan and Mao, Yuxing and Li, Bo},
  journal={Sensors},
  volume={18},
  number={10},
  pages={3337},
  year={2018},
}

@inproceedings{pvrcnn,
  title={Pv-rcnn: Point-voxel feature set abstraction for 3d object detection},
  author={Shi, Shaoshuai and Guo, Chaoxu and Jiang, Li and Wang, Zhe and Shi, Jianping and Wang, Xiaogang and Li, Hongsheng},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={10529--10538},
  year={2020}
}

@inproceedings{centerpoint,
  title={Center-based 3d object detection and tracking},
  author={Yin, Tianwei and Zhou, Xingyi and Krahenbuhl, Philipp},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={11784--11793},
  year={2021}
}

@inproceedings{wei2022distillation,
  title={LiDAR distillation: bridging the beam-induced domain Gap for 3D object detection},
  author={Yi Wei and Zibu Wei and Yongming Rao and Jiaxin Li and Jie Zhou and Jiwen Lu},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={179--195},
  year={2022}
}

@inproceedings{li2023logonet,
  title={LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion},
  author={Xin Li and Tao Ma and Yuenan Hou and Botian Shi and Yuchen Yang and Youquan Liu and Xingjiao Wu and Qin Chen and Yikang Li and Yu Qiao and Liang He},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {17524--17534},
  year = {2023}
}

@inproceedings{duan2021advdrop,
  title={Advdrop: Adversarial attack to dnns by dropping information},
  author={Ranjie Duan and Yuefeng Chen and Dantong Niu and Yun Yang and A. Kai Qin and Yuan He},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021},
  pages={7506--7515},
}

@article{xie2023adv,
  title={On the Adversarial Robustness of Camera-based 3D Object Detection},
  author={Shaoyuan Xie and Zichao Li and Zeyu Wang and Cihang Xie},
  journal={arXiv preprint arXiv:2301.10766},
  year={2023}
}





% Innovation 1 of Track 1
@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={1501--1510},
  year={2017}
}

@inproceedings{chen2021amplitude,
  title={Amplitude-phase recombination: Rethinking robustness of convolutional neural networks in frequency domain},
  author={Chen, Guangyao and Peng, Peixi and Ma, Li and Li, Jia and Du, Lin and Tian, Yonghong},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={458--467},
  year={2021}
}

@inproceedings{li2022uncertainty,
  title={Uncertainty modeling for out-of-distribution generalization},
  author={Li, Xiaotong and Dai, Yongxing and Ge, Yixiao and Liu, Jun and Shan, Ying and Duan, Ling-Yu},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022}
}



% 1st Solution of Track 1
@inproceedings{woo2018cbam,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={3--19},
  year={2018}
}

@inproceedings{schon2021mgnet,
  title={Mgnet: Monocular geometric scene understanding for autonomous driving},
  author={Markus Schön and Michael Buchholz and Klaus Dietmayer},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={15804--15815},
  year={2021}
}

@inproceedings{li2021panodepth,
  title={Panodepth: A two-stage approach for monocular omnidirectional depth estimation},
  author={Yuyan Li and Zhixin Yan and Ye Duan and Liu Ren},
  booktitle={IEEE International Conference on 3D Vision (3DV)},
  pages={648--658},
  year={2021}
}

@inproceedings{yucel2021real,
  title={Real-time monocular depth estimation with sparse supervision on mobile},
  author={Mehmet Kerim Yucel and Valia Dimaridou and Anastasios Drosou and Albert Saa-Garriga},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2428--2437},
  year={2021}
}

@article{yang2020mobile3d,
  title={Mobile3DRecon: real-time monocular 3D reconstruction on a mobile phone},
  author={Xingbin Yang and Liyang Zhou and Hanqing Jiang and Zhongliang Tang and Yuanbo Wang and Hujun Bao and Guofeng Zhang},
  journal={IEEE Transactions on Visualization and Computer Graphics (TVCG)},
  volume={26},
  number={12},
  pages={3446--3456},
  year={2020},
}

@inproceedings{lee2022mpvit,
  title={Mpvit: Multi-path vision transformer for dense prediction},
  author={Youngwan Lee and Jonghee Kim and Jeffrey Willette and Sung Ju Hwang},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={7287--7296},
  year={2022}
}

@inproceedings{xiang2018posecnn,
    Author={Xiang, Yu and Schmidt, Tanner and Narayanan, Venkatraman and Fox, Dieter},
    Title={PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes},
    booktitle={Robotics: Science and Systems (RSS)},
    Year={2018}
}

@inproceedings{hendrycks2020augmix,
   title={AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty},
   author={Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D. and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
   booktitle={International Conference on Learning Representations (ICLR)},
   year={2020}
}

@article{devries2017cutout,
   title={Improved regularization of convolutional neural networks with cutout},
   author={Terrance DeVries and Graham W. Taylor},
   journal={arXiv preprint arXiv:1708.04552},
   year={2017}
}

@inproceedings{yun2019cutmix,
   title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
   author={Sangdoo Yun and Dongyoon Han and Seong Joon Oh and Sanghyuk Chun and Junsuk Choe and Youngjoon Yoo},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={6023--6032},
   year={2019}
}

@inproceedings{zhang2018mixup,
   title={mixup: Beyond Empirical Risk Minimization},
   author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
   booktitle={International Conference on Learning Representations (ICLR)},
   year={2018},
}

@inproceedings{madry2018adversarial,
   title={Towards Deep Learning Models Resistant to Adversarial Attacks},
   author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
   booktitle={International Conference on Learning Representations (ICLR)},
   year={2018},
}

@inproceedings{cubuk2019autoaugment,
   title={Autoaugment: Learning augmentation strategies from data},
   author={Ekin D. Cubuk and Barret Zoph and Dandelion Mane and Vijay Vasudevan and Quoc V. Le},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={113--123},
   year={2019}
}

@inproceedings{wang2018learning,
   title={Learning depth from monocular videos using direct methods},
   author={Chaoyang Wang and José Miguel Buenaposada and Rui Zhu and Simon Lucey},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={2022--2030},
   year={2018}
}

@article{kannan2018pairing,
   title={Adversarial logit pairing},
   author={Harini Kannan and Alexey Kurakin and Ian Goodfellow},
   journal={arXiv preprint arXiv:1803.06373},
   year={2018}
}

@inproceedings{eigen2015predicting,
  title={Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture},
  author={David Eigen and Rob Fergus},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={2650--2658},
  year={2015}
}

@inproceedings{loshchilov2018adamw,
   title={Decoupled Weight Decay Regularization},
   author={Ilya Loshchilov and Frank Hutter},
   booktitle={International Conference on Learning Representations (ICLR)},
   year={2018},
}



% 2nd Solution of Track 1
@inproceedings{jaderberg2015spatial,
   title={Spatial transformer networks},
   author={Max Jaderberg and Karen Simonyan and Andrew Zisserman},
   booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
   volume={28},
   year={2015},
}

@inproceedings{klodt2018supervising,
  title={Supervising the new with the old: learning sfm from sfm},
  author={Maria Klodt and Andrea Vedaldi},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={698--713},
  year={2018}
}

@inproceedings{poggi2020uncertainty,
   title={On the uncertainty of self-supervised monocular depth estimation},
   author={Matteo Poggi and Filippo Aleotti and Fabio Tosi and Stefano Mattoccia},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={3227--3237},
   year={2020}
}

@inproceedings{yang2020d3vo,
   title={D3vo: Deep depth, deep pose and deep uncertainty for monocular visual odometry},
   author={Nan Yang and Lukas von Stumberg and Rui Wang and Daniel Cremers},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={1281--1292},
   year={2020}
}

@inproceedings{zamir2022restormer,
   title={Restormer: Efficient transformer for high-resolution image restoration},
   author={Syed Waqas Zamir and Aditya Arora and Salman Khan and Munawar Hayat and Fahad Shahbaz Khan and Ming-Hsuan Yang},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={5728--5739},
   year={2022}
}

@inproceedings{casser2019depth,
    author = {Casser Vincent and Soeren Pirk and Reza Mahjourian and Anelia Angelova},
    title = {Depth prediction without the sensors: Leveraging structure for unsupervised learning from monocular videos},
    booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
    pages = {8001--8008},
    year = {2019}
}

@article{luo2019every,
  title={Every pixel counts++: Joint learning of geometry and motion with 3d holistic understanding},
  author={Chenxu Luo and Zhenheng Yang and Peng Wang and Yang Wang and Wei Xu and Ram Nevatia and Alan Yuille},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
  volume={42},
  number={10},
  pages={2624--2641},
  year={2019}
}

@inproceedings{spencer2020general,
   title={Defeat-net: General monocular depth via simultaneous unsupervised representation learning},
   author={Jaime Spencer and Richard Bowden and Simon Hadfield},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={14402--14413},
   year={2020}
}

@inproceedings{pillai2019superdepth,
   title={Superdepth: Self-supervised, super-resolved monocular depth estimation},
   author={Sudeep Pillai and Rareş Ambruş and Adrien Gaidon},
   booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
   pages={9250--9256},
   year={2019}
}

@inproceedings{he2022mae,
   title={Masked autoencoders are scalable vision learners},
   author={Kaiming He and Xinlei Chen and Saining Xie and Yanghao Li and Piotr Dollár and Ross Girshick},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={16000--16009},
   year={2022}
}



% Innov #2 Solution of Track 1
@inproceedings{dosovitskiy2020vit,
   title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
   author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
   booktitle={International Conference on Learning Representations (ICLR)},
   year={2020},
}

@inproceedings{ranjan2019competitive,
   title={Competitive collaboration: Joint unsupervised learning of depth, camera motion, optical flow and motion segmentation},
   author={Anurag Ranjan and Varun Jampani and Lukas Balles and Kihwan Kim and Deqing Sun and Jonas Wulff and Michael J. Black},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={12240--12249},
   year={2019}
}

@article{kirillov2023segment,
   title={Segment anything},
   author={Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Dollár and Ross Girshick},
   journal={arXiv preprint arXiv:2304.02643},
   year={2023}
}

@article{zhao2016loss,
  title={Loss functions for image restoration with neural networks},
  author={Hang Zhao and Orazio Gallo and Iuri Frosio and Jan Kautz},
  journal={IEEE Transactions on Computational Imaging (TCI)},
  volume={3},
  number={1},
  pages={47--57},
  year={2016}
}

@article{Codalab,
  title={Codalab competitions: An open source platform to organize scientific challenges},
  author={Adrien Pavao and Isabelle Guyon and Anne-Catherine Letournel and Xavier Baró and Hugo Escalante and Sergio Escalera and Tyler Thomas and Zhen Xu},
  journal={PhD Dissertation, Université Paris-Saclay, FRA},
  year={2022}
}



% 1st Solution of Track 2
@article{ning2023ait,
   title={All in tokens: Unifying output space of visual tasks via soft token},
   author={Jia Ning and Chen Li and Zheng Zhang and Zigang Geng and Qi Dai and Kun He and Han Hu},
   journal={arXiv preprint arXiv:2301.02229},
   year={2023}
}

@inproceedings{xie2023revealing,
   title={Revealing the dark secrets of masked image modeling},
   author={Zhenda Xie and Zigang Geng and Jingcheng Hu and Zheng Zhang and Han Hu and Yue Cao},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={14475--14485},
   year={2023}
}

@article{zhao2023unleashing,
   title={Unleashing text-to-image diffusion models for visual perception},
   author={Wenliang Zhao and Yongming Rao and Zuyan Liu and Benlin Liu and Jie Zhou and Jiwen Lu},
   journal={arXiv preprint arXiv:2303.02153},
   year={2023}
}

@article{bhat2023zero,
   title={Zoedepth: Zero-shot transfer by combining relative and metric depth},
   author={Shariq Farooq Bhat and Reiner Birkl and Diana Wofk and Peter Wonka and Matthias Müller},
   journal={arXiv preprint arXiv:2302.12288},
   year={2023}
}

@inproceedings{liang2021swin-ir,
  title={Swinir: Image restoration using swin transformer},
  author={Jingyun Liang and Jiezhang Cao and Guolei Sun and Kai Zhang and Luc Van Gool and Radu Timofte},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={1833--1844},
  year={2021}
}

@inproceedings{chen2021ipt,
   title={Pre-trained image processing transformer},
   author={Hanting Chen and Yunhe Wang and Tianyu Guo and Chang Xu and Yiping Deng and Zhenhua Liu and Siwei Ma and Chunjing Xu and Chao Xu and Wen Gao},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={12299--12310},
   year={2021}
}



% 2nd Solution of Track 2
@article{li2022binsformer,
   title={Binsformer: Revisiting adaptive bins for monocular depth estimation},
   author={Zhenyu Li and Xuyang Wang and Xianming Liu and Junjun Jiang},
   journal={arXiv preprint arXiv:2204.00987},
   year={2022}
}

@article{yuan2022newcrfs,
   title={New crfs: Neural window fully-connected crfs for monocular depth estimation},
   author={Weihao Yuan and Xiaodong Gu and Zuozhuo Dai and Siyu Zhu and Ping Tan},
   journal={arXiv preprint arXiv:2203.01502},
   year={2022}
}

@inproceedings{tang2021transdepth,
   title={Transformer-based attention networks for continuous pixel-wise prediction},
   author={Guanglei Yang and Hao Tang and Mingli Ding and Nicu Sebe and Elisa Ricci},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={16269--16279},
   year={2021}
}

@inproceedings{liu2015deep,
   title={Deep convolutional neural fields for depth estimation from a single image},
   author={Fayao Liu and Chunhua Shen and Guosheng Lin},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={5162--5170},
   year={2015}
}

@inproceedings{radford2021clip,
   title={Learning transferable visual models from natural language supervision},
   author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
   booktitle={International Conference on Machine Learning (ICML)},
   pages={8748--8763},
   year={2021}
}

@inproceedings{rombach2022stable,
   title={High-resolution image synthesis with latent diffusion models},
   author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={10684--10695},
   year={2022}
}

@inproceedings{ronneberger2015unet,
   title={U-net: Convolutional networks for biomedical image segmentation},
   author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
   booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
   pages={234-241},
   year={2015}
}

@inproceedings{kirillov2019fpn,
   title={Panoptic feature pyramid networks},
   author={Alexander Kirillov and Ross Girshick and Kaiming He and Piotr Dollár},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={6399--6408},
   year={2019}
}

@inproceedings{esser2021vqgan,
   title={Taming transformers for high-resolution image synthesis},
   author={Patrick Esser and Robin Rombach and Bjorn Ommer},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={12873--12883},
   year={2021}
}



% 3rd Solution of Track 2
@misc{lidepthtoolbox2022,
  title={Monocular Depth Estimation Toolbox},
  author={Zhenyu Li},
  howpublished = {\url{https://github.com/zhyever/Monocular-Depth-Estimation-Toolbox}},
  year={2022}
}

@inproceedings{oord2017vqvae,
  title={Neural discrete representation learning},
  author={Aaron Van Den Oord and Oriol Vinyals},
  booktitle={Advances in Neural Information Processing System (NeurIPS)},
  year={2017}
}

@inproceedings{xie2022simmim,
   title={Simmim: A simple framework for masked image modeling},
   author={Zhenda Xie and Zheng Zhang and Yue Cao and Yutong Lin and Jianmin Bao and Zhuliang Yao and Qi Dai and Han Hu},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={9653--9663},
   year={2022}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={10012--10022},
  year={2021}
}

@inproceedings{liu2022swin-v2,
   title={Swin transformer v2: Scaling up capacity and resolution},
   author={Ze Liu and Han Hu and Yutong Lin and Zhuliang Yao and Zhenda Xie and Yixuan Wei and Jia Ning and Yue Cao and Zheng Zhang and Li Dong and Furu Wei and Baining Guo},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={12009--12019},
   year={2022}
}



% Innov Solution of Track 2
@inproceedings{chen2021apr,
   title={Amplitude-phase recombination: Rethinking robustness of convolutional neural networks in frequency domain},
   author={Guangyao Chen and Peixi Peng and Li Ma and Jia Li and Lin Du and Yonghong Tian},
   booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages={458--467},
   year={2021}
}