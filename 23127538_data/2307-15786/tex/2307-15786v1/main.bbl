% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{zou2023object}
Z.~Zou, K.~Chen, Z.~Shi, Y.~Guo, and J.~Ye, ``Object detection in 20 years: A
  survey,'' \emph{Proceedings of the IEEE}, 2023.

\bibitem{hirschberg2015advances}
J.~Hirschberg and C.~D. Manning, ``Advances in natural language processing,''
  \emph{Science}, vol. 349, no. 6245, pp. 261--266, 2015.

\bibitem{mahmud2018applications}
M.~Mahmud, M.~S. Kaiser, A.~Hussain, and S.~Vassanelli, ``Applications of deep
  learning and reinforcement learning to biological data,'' \emph{TNNLS},
  vol.~29, no.~6, pp. 2063--2079, 2018.

\bibitem{tampuu2020survey}
A.~Tampuu, T.~Matiisen, M.~Semikin, D.~Fishman, and N.~Muhammad, ``A survey of
  end-to-end driving: Architectures and training methods.''

\bibitem{ivanovs2021perturbation}
M.~Ivanovs, R.~Kadikis, and K.~Ozols, ``Perturbation-based methods for
  explaining deep neural networks: A survey,'' \emph{Pattern Recognition
  Letters}, vol. 150, pp. 228--234, 2021.

\bibitem{wachter2017counterfactual}
S.~Wachter, B.~Mittelstadt, and C.~Russell, ``Counterfactual explanations
  without opening the black box: Automated decisions and the gdpr,''
  \emph{Harv. JL \& Tech.}, vol.~31, p. 841, 2017.

\bibitem{yang2021generative}
F.~Yang, N.~Liu, M.~Du, and X.~Hu, ``Generative counterfactuals for neural
  networks via attribute-informed perturbation,'' \emph{ACM SIGKDD Explorations
  Newsletter}, vol.~23, no.~1, pp. 59--68, 2021.

\bibitem{samadi2023counterfactual}
A.~Samadi, K.~Koufos, and M.~Dianati, ``Counterfactual explainer framework for
  deep reinforcement learning models using policy distillation,'' \emph{arXiv
  preprint arXiv:2305.16532}, 2023.

\bibitem{goodfellow2014explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy, ``Explaining and harnessing
  adversarial examples,'' \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{moosavi2016deepfool}
S.-M. Moosavi-Dezfooli, A.~Fawzi, and P.~Frossard, ``Deepfool: a simple and
  accurate method to fool deep neural networks,'' in \emph{Proceedings of the
  IEEE conference on computer vision and pattern recognition}, 2016, pp.
  2574--2582.

\bibitem{goodfellow2020generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio, ``Generative adversarial networks,''
  \emph{Communications of the ACM}, vol.~63, no.~11, pp. 139--144, 2020.

\bibitem{kim2021counterfactual}
H.~Kim, S.~Shin, J.~Jang, K.~Song, W.~Joo, W.~Kang, and I.-C. Moon,
  ``Counterfactual fairness with disentangled causal effect variational
  autoencoder,'' in \emph{AAAI}, vol.~35, no.~9, 2021, pp. 8128--8136.

\bibitem{jeanneret2022diffusion}
G.~Jeanneret, L.~Simon, and F.~Jurie, ``Diffusion models for counterfactual
  explanations,'' in \emph{ACCV}, 2022, pp. 858--876.

\bibitem{chou2022counterfactuals}
Y.-L. Chou, C.~Moreira, P.~Bruza, C.~Ouyang, and J.~Jorge, ``Counterfactuals
  and causability in explainable artificial intelligence: Theory, algorithms,
  and applications,'' \emph{Information Fusion}, vol.~81, pp. 59--83, 2022.

\bibitem{jacob2022steex}
P.~Jacob, {\'E}.~Zablocki, H.~Ben-Younes, M.~Chen, P.~P{\'e}rez, and M.~Cord,
  ``Steex: steering counterfactual explanations with semantics,'' in
  \emph{ECCV}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp.
  387--403.

\bibitem{zemni2022octet}
M.~Zemni, M.~Chen, {\'E}.~Zablocki, H.~Ben-Younes, P.~P{\'e}rez, and M.~Cord,
  ``Octet: Object-aware counterfactual explanations,'' \emph{arXiv preprint
  arXiv:2211.12380}, 2022.

\bibitem{rodriguez2021beyond}
P.~Rodr{\'\i}guez, M.~Caccia, A.~Lacoste, L.~Zamparo, I.~Laradji, L.~Charlin,
  and D.~Vazquez, ``Beyond trivial counterfactual explanations with diverse
  valuable explanations,'' in \emph{ICCV}, 2021, pp. 1056--1065.

\bibitem{selvaraju2017grad}
R.~R. Selvaraju, M.~Cogswell, A.~Das, R.~Vedantam, D.~Parikh, and D.~Batra,
  ``Grad-cam: Visual explanations from deep networks via gradient-based
  localization,'' in \emph{ICCV}, 2017, pp. 618--626.

\bibitem{wang2020score}
H.~Wang, Z.~Wang, M.~Du, F.~Yang, Z.~Zhang, S.~Ding, P.~Mardziel, and X.~Hu,
  ``Score-cam: Score-weighted visual explanations for convolutional neural
  networks,'' in \emph{CVPRW}, 2020, pp. 24--25.

\bibitem{etmann2019connection}
C.~Etmann, S.~Lunz, P.~Maass, and C.-B. Sch{\"o}nlieb, ``On the connection
  between adversarial robustness and saliency map interpretability,''
  \emph{arXiv preprint arXiv:1905.04172}, 2019.

\bibitem{mangla2021saliency}
P.~Mangla, V.~Singh, and V.~N. Balasubramanian, ``On saliency maps and
  adversarial robustness,'' in \emph{ECML PKDD}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2021, pp. 272--288.

\bibitem{samek2016evaluating}
W.~Samek, A.~Binder, G.~Montavon, S.~Lapuschkin, and K.-R. M{\"u}ller,
  ``Evaluating the visualization of what a deep neural network has learned,''
  \emph{NeurIPS}, vol.~28, no.~11, pp. 2660--2673, 2016.

\bibitem{kim2019grounding}
J.~Kim, T.~Misu, Y.-T. Chen, A.~Tawari, and J.~Canny, ``Grounding
  human-to-vehicle advice for self-driving vehicles,'' in \emph{CVPR}, 2019,
  pp. 10\,591--10\,599.

\bibitem{ribeiro2016should}
M.~T. Ribeiro, S.~Singh, and C.~Guestrin, ``" why should i trust you?"
  explaining the predictions of any classifier,'' in \emph{SIGKDD}, 2016, pp.
  1135--1144.

\bibitem{ribeiro2018anchors}
M.~Ribeiro, S.~Singh, and C.~Guestrin, ``Anchors: High-precision model-agnostic
  explanations,'' in \emph{AAAI}, vol.~32, no.~1, 2018.

\bibitem{lundberg2017unified}
S.~M. Lundberg and S.-I. Lee, ``A unified approach to interpreting model
  predictions,'' \emph{NeurIPS}, vol.~30, 2017.

\bibitem{ziegel2003elements}
E.~R. Ziegel, ``The elements of statistical learning,'' 2003.

\bibitem{breiman2001random}
L.~Breiman, ``Random forests,'' \emph{Machine learning}, vol.~45, pp. 5--32,
  2001.

\bibitem{kim2017interpretable}
J.~Kim and J.~Canny, ``Interpretable learning for self-driving cars by
  visualizing causal attention,'' in \emph{ICCV}, 2017, pp. 2942--2950.

\bibitem{guidotti2018local}
R.~Guidotti, A.~Monreale, S.~Ruggieri, D.~Pedreschi, F.~Turini, and
  F.~Giannotti, ``Local rule-based explanations of black box decision
  systems,'' \emph{arXiv preprint arXiv:1805.10820}, 2018.

\bibitem{sharma2019certifai}
S.~Sharma, J.~Henderson, and J.~Ghosh, ``Certifai: Counterfactual explanations
  for robustness, transparency, interpretability, and fairness of artificial
  intelligence models,'' \emph{arXiv preprint arXiv:1905.07857}, 2019.

\bibitem{dandl2020multi}
S.~Dandl, C.~Molnar, M.~Binder, and B.~Bischl, ``Multi-objective counterfactual
  explanations,'' in \emph{International Conference on Parallel Problem Solving
  from Nature}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp.
  448--469.

\bibitem{ramon2020comparison}
Y.~Ramon, D.~Martens, F.~Provost, and T.~Evgeniou, ``A comparison of
  instance-level counterfactual explanation algorithms for behavioral and
  textual data: Sedc, lime-c and shap-c,'' \emph{Advances in Data Analysis and
  Classification}, vol.~14, no.~4, pp. 801--819, 2020.

\bibitem{rathi2019generating}
S.~Rathi, ``Generating counterfactual and contrastive explanations using
  shap,'' \emph{arXiv preprint arXiv:1906.09293}, 2019.

\bibitem{AugustinBC022}
M.~Augustin, V.~Boreiko, F.~Croce, and M.~Hein, ``Diffusion visual
  counterfactual explanations,'' in \emph{NeurIPS}, 2022.

\bibitem{khorram2022cycle}
S.~Khorram and L.~Fuxin, ``Cycle-consistent counterfactuals by latent
  transformations,'' in \emph{CVPR}, 2022, pp. 10\,203--10\,212.

\bibitem{liu2019generative}
S.~Liu, B.~Kailkhura, D.~Loveland, and Y.~Han, ``Generative counterfactual
  introspection for explainable deep learning,'' in \emph{GlobalSIP}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 1--5.

\bibitem{he2019attgan}
Z.~He, W.~Zuo, M.~Kan, S.~Shan, and X.~Chen, ``Attgan: Facial attribute editing
  by only changing what you want,'' \emph{IEEE transactions on image
  processing}, vol.~28, no.~11, pp. 5464--5478, 2019.

\bibitem{huber2023ganterfactual}
T.~Huber, M.~Demmler, S.~Mertes, M.~L. Olson, and E.~Andr{\'e},
  ``Ganterfactual-rl: Understanding reinforcement learning agents' strategies
  through visual counterfactual explanations,'' \emph{arXiv preprint
  arXiv:2302.12689}, 2023.

\bibitem{choi2018stargan}
Y.~Choi, M.~Choi, M.~Kim, J.-W. Ha, S.~Kim, and J.~Choo, ``Stargan: Unified
  generative adversarial networks for multi-domain image-to-image
  translation,'' in \emph{CVPR}, 2018, pp. 8789--8797.

\bibitem{kothiyalutilization}
I.~Kothiyal, A.~Patil, V.~Horta, and A.~Mileo, ``Utilization of gan for
  automatic evaluation of counterfactuals: Challenges and opportunities,''
  \emph{Digital Book of Abstracts}.

\bibitem{tang2019attention}
H.~Tang, D.~Xu, N.~Sebe, and Y.~Yan, ``Attention-guided generative adversarial
  networks for unsupervised image-to-image translation,'' in
  \emph{IJCNN}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 1--8.

\bibitem{GoodfellowPMXWOCB14}
I.~J. Goodfellow, J.~Pouget{-}Abadie, M.~Mirza, B.~Xu, D.~Warde{-}Farley,
  S.~Ozair, A.~C. Courville, and Y.~Bengio, ``Generative adversarial
  networks,'' \emph{CoRR}, vol. abs/1406.2661, 2014.

\bibitem{WangWDYZDMH20}
H.~Wang, Z.~Wang, M.~Du, F.~Yang, Z.~Zhang, S.~Ding, P.~Mardziel, and X.~Hu,
  ``Score-cam: Score-weighted visual explanations for convolutional neural
  networks,'' in \emph{CVPRW}.\hskip 1em plus 0.5em minus 0.4em\relax Computer
  Vision Foundation / {IEEE}, 2020, pp. 111--119.

\bibitem{tang2021attentiongan}
H.~Tang, H.~Liu, D.~Xu, P.~H. Torr, and N.~Sebe, ``Attentiongan: Unpaired
  image-to-image translation using attention-guided generative adversarial
  networks,'' \emph{TNNLS}, 2021.

\bibitem{gulrajani2017improved}
I.~Gulrajani, F.~Ahmed, M.~Arjovsky, V.~Dumoulin, and A.~C. Courville,
  ``Improved training of wasserstein gans,'' \emph{Advances in neural
  information processing systems}, vol.~30, 2017.

\bibitem{yu2020bdd100k}
F.~Yu, H.~Chen, X.~Wang, W.~Xian, Y.~Chen, F.~Liu, V.~Madhavan, and T.~Darrell,
  ``Bdd100k: A diverse driving dataset for heterogeneous multitask learning,''
  in \emph{CVPR}, 2020, pp. 2636--2645.

\bibitem{xu2020explainable}
Y.~Xu, X.~Yang, L.~Gong, H.-C. Lin, T.-Y. Wu, Y.~Li, and N.~Vasconcelos,
  ``Explainable object-induced action decision for autonomous vehicles,'' in
  \emph{CVPR}, 2020, pp. 9523--9532.

\end{thebibliography}
