

In this section, we carry out an analysis of the effectiveness of the SAFE model on the BDD dataset, and compare its performance against  state-of-the-art methods~\cite{jacob2022steex, zemni2022octet,liu2019generative,huber2023ganterfactual,kothiyalutilization}. The implementation details of the SAcleGAN are presented in Section~\ref{sec:ID}. We employ various metrics to measure the quality of the generated CF explanations, which are presented in Section~\ref{sec:  metric}. After that we proceed with the description of the selected dataset in Section~\ref{sec: BDD} and the discussion of the performance evaluation results in Section~\ref{sec:PE}. Finally, we conduct in Section~\ref{sec: Quality} a qualitative study that illustrates how well the generated CFs convey explanations comprehensible to humans.
%Furthermore, to ascertain the human-understandable nature of the generated CF  examples,  After that we present the details of the employed CF metrics 

% We evaluate the proposed method, SAFE, on several benchmark datasets including, MNIST, CelebA and BDD, and compare it against other state-of-the-art counterfactual generation methods. We measure the quality of the generated counterfactual explanations using various CF metrics, such as similarity to the original input in terms of the number of modified pixels and mean values of changed pixels (Proximity), associated with effectiveness in altering the grey-box decision prediction (Validity). Nevertheless, along with the CF metrics, to check if the CF examples are realistic and plausible, we carried out FID, KID, IS and LPIPS metrics as well. Afterward, we conduct a quantitative user study to illustrate how CF examples can deliver a human-understandable explanation. In the following sections, the first induce of metrics, and in the next trinary section we discuss the results for each dataset. 


%These metrics include the similarity of the generated CF  to the original input in terms of the number of modified pixels and the mean values of changed pixels (referred to as 'Proximity'). Additionally, we assess the effectiveness of the generated CFs in altering the grey-box decision prediction (referred to as 'Validity'). In order to ensure the realistic and plausible nature of the CF examples, we utilize additional metrics such as Frechet Inception Distance (FID), Kernel Inception Distance (KID), Inception Score (IS), and Learned Perceptual Image Patch Similarity (LPIPS). These metrics provide further insights into the perceptual quality and realism of the generated CF explanations.


\subsection{Implementation Details}
%\vspace{-1mm}
\label{sec:ID}
All input images are resized to $128 \times 256$ pixel resolution. To ensure the robustness of our findings, we repeat our experiments five times with different seeds and report the mean values of the performance metrics. For all network models we use the Adam optimiser with a learning rate of $10^{-4}$. The network hyper-parameters and loss coefficients are explored heuristically and set to $\lambda_{cls}=1, \lambda_{gp}=10, \lambda_{rec}=10, \lambda_{fuse}=1~\text{and}~\lambda_{fuse}=5$ (see Eq. \ref{eq: L_d} and \ref{eq: L_G}) for all experiments. The SAcleGAN employs the limited modified generator network and the pure discriminator network of attentionGAN~\cite{tang2019attention} models, and for the subject grey-box model we use ResNet50, see Fig.~\ref{fig: method0}. Furthermore, The 'Saliency Generator' component of our approach utilises the Grad-CAM method~\cite{selvaraju2017grad}. To execute our implementation, we employ Pytorch framework on an NVIDIA RTX-3090 GPU. 



\subsection{Performance Metrics}
\label{sec: metric}
%Quality of the CF explanations is defined as images that are similar to the query image but effectively change the decision of the target model. To verify that our explanations fit the criteria, we report our results with two sorts of metrics, generative and CF metrics. The former validates how the CFs are visually valid and the latter checks how the generated explanations are valid following CF criteria. we evaluate them with the following generative metrics:  

In order to assess the quality of the generated CF examples, we measure their adherence to well-known CF criteria namely  \textbf{Proximity}, \textbf{Sparsity}, and \textbf{Validity}. Proximity refers to the similarity or closeness between the query image and its corresponding CF instance, which can be calculated by measuring the mean value of pixels that are modified. Sparsity refers to the extent to which the changes to the generated CFs are minimal and focus only on a small subset of features. %calculating the number of changed images. 
Validity measures the success rate of the method generating CFs as being equal to the percentage of generated CF examples that altered the model's output to the target label.

Apart from the traditional performance metrics, one can find in the literature  {\it{generative}} type of metrics that assess the visual realism of the generated CF explanations, such as the \textbf{FID}, \textbf{LPIPS}, \textbf{KID}, and \textbf{IS}. FID measures the similarity between generated and real images based on the statistical properties of their feature representations. LPIPS quantifies perceptual differences between images using high-level visual features. KID measures the dissimilarity between feature distributions of generated and real images using the Maximum Mean Discrepancy method, and, IS evaluates the quality and diversity of generated images by comparing them to the real-world distribution of images.

% The quality of the counterfactual (CF) explanations is defined as images that are visually similar to the query image while effectively changing the model's decision to the target decision. In order to validate that our explanations meet these criteria, we report our results using two types of metrics: counterfactual and generative.

% The rest of the metrics that measure the counterfactual performance of the generated images are \textbf{Proximity}, \textbf{Sparsity}, and \textbf{Validity}. Proximity refers to the similarity or closeness between the original instance or query and its corresponding counterfactual instance. Sparsity, on the other hand, refers to the extent to which the counterfactual changes made to the original instance are minimal and focused only on a small subset of features or conditions. At last, validity in counterfactual explanations refers to the reliability and trustworthiness of the generated counterfactual instances and the corresponding explanations.


\subsection{Berkeley DeepDrive Dataset (BDD)}
\label{sec: BDD}
The BDD100k dataset consists of 100,000 detailed images depicting diverse driving scenes~\cite{yu2020bdd100k}. 
The grey-box DNN model used in our experiments is trained to predict actions such as "Move Forward" and "Stop/Slow down" on the BDD-OIA dataset~\cite{xu2020explainable}, which consists of 20,000 scenes specifically selected and annotated with high-level actions from the BDD100k dataset. To generate CF examples, both the SAFE and baseline explainer models are fed with the BDD100k dataset.

\subsection{Performance Evaluation}
\label{sec:PE}
Table~\ref{tab: BDD_0} contains the comprehensive performance comparison results between the proposed model, SAFE, and two well-known cycleGAN models, namely starGAN~\cite{choi2018stargan} and attentionGAN~\cite{tang2021attentiongan}. For the SAFE model, we investigate the effectiveness of the newly introduced loss function, $\mathcal{L_\text{fuse}}$, in Eq.~\eqref{eq:lfuse} for two values of the associated coefficient $\lambda_{fuse}=1$ and $\lambda_{fuse}=5$, indicated by SAFE$_1$ and SAFE$_{5}$ respectively. To ensure a fair comparison with previous studies \cite{liu2019generative,huber2023ganterfactual,kothiyalutilization}, the baseline models are fed with the decision model's output instead of the ground-truth labels. This approach allows for improvements in the proximity, sparsity, and validity metrics of the baseline models. By examining the Table~\ref{tab: BDD_0}, we observe that SAFE outperforms the baselines in terms of validity  substantially, while exhibiting negligible differences in the generative metrics that assess the realism of the generated images (FID, LPIPS, KID, IS). Notably, the effect of the term $\mathcal{L_\text{fuse}}$ in the loss function is evident, where for the lower value of $\lambda_{fuse}$,  SAFE applies more modifications to the query image, resulting in higher validity and greater distance from the initial image. Conversely, a higher value of $\lambda_{fuse}$ leads to a different trade-off where modifications are reduced, resulting in lower validity and a closer resemblance to the initial image.



\begin{table}
\centering
\vspace{1mm}
\caption{Performance comparison of SAFE with cycleGAN models. The direction of arrows preceding the metric indicates which values are desirable (low $\downarrow$, or high $\uparrow$). The best model is highlighted in bold, while the second-best model is underlined. Proximity, sparsity, and validity are denoted by prx, sprs, and vld, respectively. Note that \textit{CF-} represents the counterfactual variant of the model.}
\label{tab: BDD_0}
\begin{tblr}{
  row{1} = {m}{l},
  % column{even} = {c},
  column{1} = {l}{2.11cm},
  column{2-8} = {c}{.45cm},
  hline{1-2,6} = {-}{},
}
Method           & $\downarrow$FID  & $\downarrow$LPIPS & $\downarrow$KID & $\uparrow$IS   &$\downarrow$Prx & $\downarrow$Sprs & $\uparrow$Vld \\
CF-StarGAN       & \textbf{19.31}  & \textbf{0.117}    & 0.067           & 3.151           & 0.039             & 0.999         & 0.564 \\
CF-AttentionGAN        & \uline{28.90}   & \uline{0.196}     & 0.072           & \uline{3.120}   & \textbf{0.009}    & 0.574         & 0.551    \\
$\text{SAFE}_1$  & 28.45           & 0.204             & \uline{0.064}   & 3.081           & \uline{0.021}     & \uline{0.413} & \textbf{0.938}    \\
$\text{SAFE}_{5}$ & 29.21           & 0.225             & \textbf{0.059}  & \textbf{3.242}  & 0.026             & \textbf{0.409}& \uline{0.914}      
\end{tblr}
\end{table}

% \renewcommand{\arraystretch}{1.5}
% \begin{table}[t!]
% \centering
% \vspace{-1mm}
% \caption{Performance comparison of SAFE with CF explainers. The direction of the arrow preceding the metric indicates which values are desirable (low $\downarrow$, or high $\uparrow$). The best performing model is indicated in bold. The validity metric is denoted by vld.}
% \label{tab: BDD_1}
% % \begin{adjustbox}{width=0.55\linewidth,center}
% \begin{tabular}{lccc} 
% \hline
% Method       &  $\downarrow$FID & $\downarrow$LPIPS    & $\uparrow$Vld  \\ 
% \hline
% STEEX        & 61.35 & 0.451 & \textbf{0.973}    \\
% OCTET        & 54.95 & 0.422 & 0.961    \\
% $\text{SAFE}_{1}$       & \textbf{28.45} & \textbf{0.204} & 0.938     \\
% \hline
% \end{tabular}
% % \end{adjustbox}
% \end{table}


\begin{table}[t!]
\centering
% \vspace{1mm}
\caption{Performance comparison of SAFE with CF explainers. The direction of the arrow preceding the metric indicates which values are desirable (low $\downarrow$, or high $\uparrow$). The best performing model is indicated in bold. The validity metric is denoted by vld.}
\label{tab: BDD_1}
\begin{tblr}{
  column{even} = {c},
  column{3} = {c},
  hline{1-2,5} = {-}{},
}
Method          & $\downarrow$ FID & $\downarrow$LPIPS & $\uparrow$Vld  \\
STEEX           & 61.35           & 0.451             & \textbf{0.973} \\
OCTET           & 54.95           & 0.422             & 0.961          \\
$\text{SAFE}_1$ & \textbf{28.45}  & \textbf{0.204}    & 0.938          
\end{tblr}
\end{table}


% Figure environment removed


% \clearpage

% Figure environment removed
\subsection{Quality of Counterfactual Explanations}
\label{sec: Quality}


%In addition to comparing SAFE with cycle-GAN models in 
Table \ref{tab: BDD_1} presents the performance comparison between SAFE and  the latest state-of-the-art CF explainers, namely STEEX \cite{jacob2022steex} and OCTET \cite{zemni2022octet} based on the results reported in their respective papers. Upon examining this table, we do not observe any significant difference in terms of the explainer model's validity performance, however, when it comes to the realism metrics, our approach demonstrates notable improvements. Specifically, it achieves a 53~\% improvement in LPIPS and a 55~\% improvement in FID metrics as compared to the state-of-the-art CF explainers STEEX and OCTET. These results highlight the superior quality and realism of the CF examples generated by the SAFE model. It is worth noting that both baseline methods, STEEX and OCTET, modify disentangled latent states using user-selected features. This approach may result in a counterfactual example that is far from the decision boundary of the grey-box DNN model, as discussed in sections \ref{sec:intro} and \ref{section:related}. 

% The higher LPIPS and FID metrics, which serve as measures of perceptual similarity and statistical distance between the real and generated images, provide substantial support for the aforementioned claim.  % compared to the latest state-of-the-art CF explainers.


Fig.~\ref{fig: BDD} illustrates a visual comparison for the quality of the generated CF examples between SAFE and the baseline cycleGAN models. Given an input labelled as 'Stop' by the decision model (Fig.~\ref{fig: BDD}, first column), the SAFE model leverages a saliency map (depicted as an image overlay) and fades the front vehicle completely to change the decision to 'Go' (Fig.~\ref{fig: BDD}, second column). On the contrary, the baseline models encounter difficulties in achieving such clear modifications in the original image and fail to generate CF examples with similar effectiveness. This visual comparison highlights the superior performance of SAFE in generating meaningful, clear and effective CF explanations as compared to the baseline models.




%\subsection{Celebrity-faces Attributes (CelebA) dataset}
%\label{sec: CelebA}
% \textbf{CelebA} includes more than $200$k high-quality face portraits from $10,177$ annotated with 40 binary attributes describing the person's appearance like hair colour, gender, and age. Each image is rescaled to $256 \time 256$. 


% \begin{table}
% \centering
% \caption{CelebA}
% \label{tab: CelebA_0}
% \begin{adjustbox}{width=\linewidth,center}
% \begin{tabular}{lccccccc}
% Method       & FID    & LPIPS & KID (std)     & IS (std)      & Proximity & Sparsity & Validity  \\ 
% \hline
% CF-StarGAN   & 40.369 & 0.164 & 0.166 (0.015) & 3.325 (0.146) & 0.131     & 1        & 0.605     \\
% CF-AttGAN    & 43.976 & 0.114 & 0.169 (0.011) & 3.593 (0.163) & 0.084     & 0.778    & 0.570     \\
% SAFE\_fuse1  & 44.049 & 0.115 & 0.170 (0.011) & 3.609 (0.175) & 0.070     & 0.681    & 0.936     \\
% SAFE\_fuse10 & 44.663 & 0.114 & 0.168 (0.011) & 3.541 (0.173) & 0.045     & 0.589    & 0.887     \\
% \hline
% \end{tabular}
% \end{adjustbox}
% \end{table}


% \begin{table}
% \centering
% \caption{CelebA}
% \label{tab: CelebA_1}
% \begin{tabular}{lccc}
% \multicolumn{4}{c}{CelebA}                    \\ 
% \hline
% Method       & FID    & Proximity & Validity  \\ 
% \hline
% StarGAN      &        &           &           \\
% CF-StarGAN   & 40.369 & 0.131     & 0.605     \\
% CF-AttGAN    & 43.976 & 0.084     & 0.570     \\
% PE           & 53.4   & 3.74      & 0.722     \\
% Dive         & 33.8   & 4.58      & 0.982     \\
% Steex        & 11.8   & 3.44      & 0.975     \\
% SAFE\_fuse1  & 44.049 & 0.070     & 0.936     \\
% SAFE\_fuse10 & 44.663 & 0.045     & 0.887     \\
% \hline
% \end{tabular}
% \end{table}


% \subsection{Modified National Institute of Standards and Technology (MNIST) dataset}
% The well-known \textbf{MNIST} dataset is a large dataset of handwritten digits $(0-9)$ covering $60$k training and $10$k test images.




% \subsection{Quantitative Results}


% In this section, first, we illustrate how CF examples explain the underlying rationale behind a DNN-based decision model, and then, we visually show how the SAFE approach learned to generate such explanations.


% Toward understanding why a certain decision or outcome is reached, CF examples provide hypothetical instances similar to the original input but differ in certain features. By observing these modified features, we can gain insights into the influential factors guiding the decision-making process.


Fig.~\ref{fig: quality} (top row) illustrates another driving scene showcasing the generation of a CF example that alters the original decision from 'STOP' to 'GO'. The visualisation reveals that SAFE has faded both the pedestrian and the yellow participant vehicle, and moreover, it alters the street sign to a green traffic light. Based on these modifications, we can infer that, under these circumstances, the automated vehicle should proceed forward, taking into account factors such as an obstacle-free urban intersection and the presence of a green traffic light signal. 
The bottom row of Fig.~\ref{fig: quality} presents a different scene in a motorway, wherein the grey-box decision model would only stop if there is a leading vehicle nearby. To summarise, these CF examples effectively highlight the necessary modifications required in the input image to change the automated vehicle's decision, thereby indicating that the DNN model has learned to focus on relevant features during training. This is also evident from the distribution of changed pixels in Fig.~\ref{fig: quality}, where one can see that the SAFE model has successfully concentrated on the important features within the input image, which can be attributed to the utilisation of the saliency maps.
%from the underlying model, which guided SAFE towards the relevant pixels and constrained the potential solutions.
For both driving scenarios we have also generated the CF examples and the changed input pixels by the AttentionGAN~\cite{tang2021attentiongan} model. 
%While the SAFE approach provided meaningful modifications, such as fading objects in the first row and augmenting a vehicle in the second row, 
The latter did not succeed in generating plausible CFs as can be also reflected by the scattered distribution of the changed pixels across the image.
% because it does not solely focused on the essential features of the input, as can be infered by the distriburion of the changed pixels, which are scattered across the image. %that were not relevant to the decision-making process.
%scattered changed pixels in AttentionGAN,  On the other hand, AttentionGAN modified scattered pixels, suggesting a broader range of potential solutions without focusing on the essential features.


% We evaluate the proposed method on several benchmark datasets and compare it against other state-of-the-art counterfactual generation methods. We measure the quality of the generated counterfactual explanations using various metrics, such as similarity to the original input, distance to the original input, and effectiveness in changing the prediction of the machine learning model. We also conduct a user study to evaluate the interpretability of the generated counterfactual explanations.

% \subsection{Datasets}
% \noindent The \textbf{BDD100k}~\cite{yu2020bdd100k} dataset contains $100$k detailed images of diverse driving scenes. Each data in this dataset corresponds to either 'Forward' or 'Stop/Slow down' action class.

% \noindent \textbf{CelebA} includes more than $200$k high-quality face portraits from $10,177$ annotated with 40 binary attributes describing the person's appearance like hair colour, gender, and age. Each image is rescaled to $256 \time 256$. 

% \noindent The well-known \textbf{MNIST} dataset is a large dataset of handwritten digits covering $60$k training and $10$k test images.

% \subsection{Quantitative Results}

% \subsection{Quality of the explanations}
% Quality of the explanations Counterfactual explanations are defined as images that are similar to the query image but effectively change the decision of the target model. To verify that our explanations fit the criteria, we report our results with two sorts of metrics, generative and counterfactual metrics. The former validates how the counterfactuals are visually valid and the latter checks how the generated explanations are valid following counterfactual criteria. we evaluate them with the following generative metrics:  

% \textbf{FID}, \textbf{LPIPS}, \textbf{KID}, and \textbf{IS} are metrics used to assess the quality, similarity, and diversity of generated images in various contexts. FID measures the similarity between generated and real images based on statistical properties of their feature representations. LPIPS quantifies perceptual differences between images using high-level visual features. KID measures the dissimilarity between feature distributions of generated and real images using the Maximum Mean Discrepancy (MMD) method. And, IS evaluates the quality and diversity of generated images by comparing them to the real-world distribution of images.

% The rest of the metrics that measure the counterfactual performance of the generated images are \textbf{Proximity}, \textbf{Sparsity}, and \textbf{Validity}. Proximity refers to the similarity or closeness between the original instance or query and its corresponding counterfactual instance. Sparsity on the other hand, refers to the extent to which the counterfactual changes made to the original instance are minimal and focused only on a small subset of features or conditions. At last, validity in counterfactual explanations refers to the reliability and trustworthiness of the generated counterfactual instances and the corresponding explanations.

% % \noindent \textbf{FID} 
% % (Fr√©chet Inception Distance) score is a metric used to assess the similarity between two sets of images \ASh{Cite}. It measures the difference in statistical properties, such as the mean and covariance, of the feature representations extracted from the images using a pre-trained Inception model. A lower FID score indicates a higher similarity between the generated images and the real images, suggesting better quality and realism. 

% % \noindent \textbf{LPIPS} (Learned Perceptual Image Patch Similarity) is a metric used to quantify the similarity between two images based on their perceptual features. Unlike traditional metrics such as MSE (Mean Squared Error) or SSIM (Structural Similarity Index), which focus on pixel-level differences, LPIPS measures perceptual differences by considering high-level visual features. The LPIPS score ranges from 0 to 1, with 0 indicating perfect similarity and 1 indicating maximum dissimilarity. 

% % \noindent \textbf{KID} (Kernel Inception Distance) measures the dissimilarity between the distributions of features extracted from generated and real images. To compute KID, feature embeddings are extracted from the generated images and the real images using a pre-trained Inception model. These feature embeddings capture high-level representations of the images. The KID metric then calculates the distance between the two distributions of feature embeddings using the Maximum Mean Discrepancy (MMD) method. A lower KID score indicates a higher similarity between the generated and real image distributions, suggesting better quality and realism of the generated images.

% % \noindent \textbf{IS} (Inception Score) is a metric used to evaluate the quality and diversity of generated images in generative models, particularly Generative Adversarial Networks (GANs). The Inception Score assesses how well the generated images match the real-world distribution of images.
% % To calculate the Inception Score, a pre-trained Inception model is used to classify the generated images. The score is based on two components: image quality and image diversity.



% % \usepackage{array}
% % \usepackage{multirow}


% \begin{table*}

% \centering
% \caption{Model Comparison}
% \begin{adjustbox}{width=\linewidth,center}
% \begin{tabular}{l|ccc|ccc|ccc|ccc|ccc|ccc|ccc} 
% \hline
% \multirow{2}{*}{Method} & \multicolumn{3}{c|}{$\downarrow$ FID}       & \multicolumn{3}{c|}{$\downarrow$LPIPS}    & \multicolumn{3}{c|}{$\downarrow$KID(std)}          & \multicolumn{3}{c|}{$\uparrow$IS(std)}           & \multicolumn{3}{c|}{$\downarrow$Proximity} & \multicolumn{3}{c|}{$\downarrow$Sparsity} & \multicolumn{3}{c}{$\uparrow$Validity}   \\ 
% \cline{2-22}
%                         & MNIST & CelebA           & BDD & MNIST & CelebA          & BDD & MNIST & CelebA                   & BDD & MNIST & CelebA                   & BDD & MNIST & CelebA          & BDD  & MNIST & CelebA          & BDD & MNIST & CelebA          & BDD  \\ 
% \hline
% StarGAN                 &       &                  &     &       &                 &     &       &                          &     &       &                          &     &       &                 &      &       &                 &     &       &                 &      \\
% CF-StarGAN              &       &                  &     &       &                 &     &       &                          &     &       &                          &     &       &                 &      &       &                 &     &       &                 &      \\
% AttGAN                  &       &                  &     &       &                 &     &       &                          &     &       &                          &     &       &                 &      &       &                 &     &       &                 &      \\
% CF-AttGAN               &       & \textbf{43.9761} &     &       & \textbf{0.1139} &     &       & 0.1692 (0.0105)          &     &       & \uline{3.5931 (0.1633)}  &     &       & 0.0842          &      &       & 0.7777          &     &       & 0.5701          &      \\
% STEEX                   &       &                  &     &       &                 &     &       &                          &     &       &                          &     &       &                 &      &       &                 &     &       &                 &      \\
% OCTET                   &       &                  &     &       &                 &     &       &                          &     &       &                          &     &       &                 &      &       &                 &     &       &                 &      \\
%                         &       &                  &     &       &                 &     &       &                          &     &       &                          &     &       &                 &      &       &                 &     &       &                 &      \\
% SAFE\_fuse1             &       & 44.0498          &     &       & 0.1150          &     &       & 0.1699 (0.0106)          &     &       & \textbf{3.6092 (0.1752)} &     &       & \uline{0.0704}  &      &       & \uline{0.6811}  &     &       & \textbf{0.9364} &      \\
% SAFE\_fuse10            &       & 44.6635          &     &       & \uline{0.11454} &     &       & \textbf{0.1684 (0.0106)} &     &       & 3.54102 (0.1727)         &     &       & \textbf{0.0445} &      &       & \textbf{0.5895} &     &       & \uline{0.8871}  &      \\
% \hline
% \end{tabular}
% \end{adjustbox}
% \end{table*}



% % Please add the following required packages to your document preamble:
% % \usepackage{multirow}
% \begin{table*}[]
% \begin{adjustbox}{width=\linewidth,center}
% \begin{tabular}{l|cccl|cccl|cccl|cccl|cccl|cccl|cccl}
% \hline
% \multirow{2}{*}{Method} & \multicolumn{4}{c|}{FID}              & \multicolumn{4}{c|}{LPIPS}           & \multicolumn{4}{c|}{KID(std)}                                & \multicolumn{4}{c|}{IS(std)}                                  & \multicolumn{4}{c|}{Proximity}     & \multicolumn{4}{c|}{Sparsity}       & \multicolumn{4}{c}{Validity}       \\ \cline{2-29} 
%                         & MNIST & CelebA  & BDDIO     & BDD100k & MNIST & CelebA  & BDDIO    & BDD100k & MNIST & CelebA          & BDDIO            & BDD100k         & MNIST & CelebA           & BDDIO           & BDD100k          & MNIST & CelebA & BDDIO   & BDD100k & MNIST & CelebA & BDDIO    & BDD100k & MNIST & CelebA & BDDIO   & BDD100k \\ \hline
% StarGAN                 &       &         &           &         &       &         &          &         &       &                 &                  &                 &       &                  &                 &                  &       &        &         &         &       &        &          &         &       &        &         &         \\
% CF-StarGAN              &       &         &           &         &       &         &          &         &       &                 &                  &                 &       &                  &                 &                  &       &        &         &         &       &        &          &         &       &        &         &         \\
% AttGAN                  &       &         & 37.9035   &         &       &         & 0.2723   &         &       &                 & 0.08187(0.01306) &                 &       &                  & 2.9318(0.1090)  &                  &       &        & 0.05302 &         &       &        & 0.66214  &         &       &        & 0.16383 &         \\
% CF-AttGAN               &       & 43.9761 & 36.89592  &         &       & 0.1139  & 0.283277 &         &       & 0.1692 (0.0105) & 0.08645(0.01558) &                 &       & 3.5931 (0.1633)  & 2.91128(0.1151) &                  &       & 0.0842 & 0.0460  &         &       & 0.7777 & 0.5068   &         &       & 0.5701 & 0.16964 &         \\
% STEEX                   &       &         &           &         &       &         &          &         &       &                 &                  &                 &       &                  &                 &                  &       &        &         &         &       &        &          &         &       &        &         &         \\
% OCTET                   &       &         &           &         &       &         &          &         &       &                 &                  &                 &       &                  &                 &                  &       &        &         &         &       &        &          &         &       &        &         &         \\
%                         &       &         &           &         &       &         &          &         &       &                 &                  &                 &       &                  &                 &                  &       &        &         &         &       &        &          &         &       &        &         &         \\
% SAFE\_fuse1             &       & 44.0498 & 37.18234  & 31.0041 &       & 0.1150  & 0.31678  & 0.28231 &       & 0.1699 (0.0106) & 0.08977(0.012)   & 0.06576(0.0126) &       & 3.6092 (0.1752)  & 3.0463(0.115)   & 3.11092(0.06467) &       & 0.0704 & 0.08783 & 0.03455 &       & 0.6811 & 0.83559  & 0.51252 &       & 0.9364 & 0.2892  & 0.51893 \\
% SAFE\_fuse10            &       & 44.6635 & 41.190122 &         &       & 0.11454 & 0.28347  &         &       & 0.1684 (0.0106) & 0.09(0.012)      &                 &       & 3.54102 (0.1727) & 3.0562(0.11432) &                  &       & 0.0445 & 0.05737 &         &       & 0.5895 & 0.696872 &         &       & 0.8871 & 0.2871  &         \\ \hline
% \end{tabular}
% \end{adjustbox}
% \end{table*}



% \begin{table}
% \centering
% \caption{Model Comparison}
% \begin{tabular}{|l|l|l|l|l|} 
% \hline
% ~                  & FID & IS & Sparcity & Validity  \\ 
% \hline
% StarGAN            & ~   & ~  & ~        & ~         \\ 
% \hline
% AttGAN             & ~   & ~  & ~        & ~         \\ 
% \hline
% STEEX              & ~   & ~  & ~        & ~         \\ 
% \hline
% Saliency Guided CF & ~   & ~  & ~        & ~         \\
% \hline
% \end{tabular}
% \end{table}




% \begin{table*}[]
% \begin{tabular}{lccccccc}
% \multicolumn{8}{c}{MNIST}                                                                                                                                                                                                            \\ \hline
% \multicolumn{1}{l|}{Method}       & \multicolumn{1}{c|}{FID} & \multicolumn{1}{c|}{LPIPS} & \multicolumn{1}{c|}{KID(std)} & \multicolumn{1}{c|}{IS(std)} & \multicolumn{1}{c|}{Proximity} & \multicolumn{1}{c|}{Sparsity} & Validity \\ \hline
% \multicolumn{1}{l|}{StarGAN}      & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{CF-StarGAN}   & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{AttGAN}       & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{CF-AttGAN}    & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{SAFE\_fuse1}  & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{SAFE\_fuse10} & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\ \hline
% \end{tabular}
% \end{table*}





% \begin{table*}[]
% \begin{tabular}{lccccccc}
% \multicolumn{8}{c}{CelebA}                                                                                                                         \\ \hline
% Method       & FID         & LPIPS                & KID (std)            & IS (std)             & Proximity   & Sparsity             & Validity    \\ \hline
% StarGAN      &             &                      &                      &                      &             &                      &             \\
% CF-StarGAN   &             &                      &                      &                      &             &                      &             \\
% AttGAN       &             &                      &                      &                      &             &                      &             \\
% CF-AttGAN    & 43.976      & 0.114                & 0.169 (0.011)        & 3.593 (0.163)        & 0.084       & 0.778                & 0.570       \\
% PE           & 53.4(young) &                      &                      &                      & 3.74(young) &                      & 72.2(young) \\
% Dive         & 33.8(young) & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & 4.58(young) & \multicolumn{1}{l}{} & 98.2(young) \\
% Steex        & 11.8(young) & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & 3.44(young) & \multicolumn{1}{l}{} & 97.5(young) \\
% SAFE\_fuse1  & 44.049      & 0.115                & 0.170 (0.011)        & 3.609 (0.175)        & 0.070       & 0.681                & 0.936       \\
% SAFE\_fuse10 & 44.663      & 0.114                & 0.168 (0.011)        & 3.541 (0.173)        & 0.045       & 0.589                & 0.887       \\ \hline
% \end{tabular}
% \end{table*}



% % Please add the following required packages to your document preamble:
% % \usepackage{multirow}
% \begin{table*}[]
% \begin{tabular}{lclclclclclclclllclclcllll}
% \cline{1-15}
% \multirow{2}{*}{Method} & \multicolumn{2}{c}{FID}                          & \multicolumn{2}{c}{LPIPS}                           & \multicolumn{2}{c}{KID(std)}           & \multicolumn{2}{c}{IS(std)}             & \multicolumn{2}{c}{Proximity}  & \multicolumn{2}{c}{Sparsity}   & \multicolumn{2}{c}{Validity}   &  &  & \multicolumn{2}{c}{LPIPS}                                   & \multicolumn{2}{c}{FID}                                     & \multicolumn{2}{c}{validity}                                & \multicolumn{2}{c}{} & \multicolumn{1}{c}{} \\ \cline{2-15}
%                         & BDDIO                & BDD100k                   & BDDIO                & \multicolumn{1}{l|}{BDD100k} & BDDIO                & BDD100k         & BDDIO                & BDD100k          & BDDIO                & BDD100k & BDDIO                & BDD100k & BDDIO                & BDD100k &  &  & \multicolumn{1}{l}{BDDIO(stop)} & BDDIO(Forward)            & \multicolumn{1}{l}{BDDIO(stop)} & BDDIO(forward)            & \multicolumn{1}{l}{BDDIO(stop)} & BDDIO(forward)            &           &          &                      \\
% CF-StarGAN              &                      &                           &                      & \multicolumn{1}{l|}{}        &                      &                 &                      &                  &                      &         &                      &         &                      &         &  &  &                                 & \multicolumn{1}{c}{}      &                                 & \multicolumn{1}{c}{}      &                                 & \multicolumn{1}{c}{}      &           &          &                      \\
% AttGAN                  & 37.9035              &                           & 0.2723               & \multicolumn{1}{l|}{}        & 0.08187(0.01306)     &                 & 2.9318(0.1090)       &                  & 0.05302              &         & 0.66214              &         & 0.16383              &         &  &  &                                 & \multicolumn{1}{c}{}      &                                 & \multicolumn{1}{c}{}      &                                 & \multicolumn{1}{c}{}      &           &          &                      \\
% CF-AttGAN               & 36.89592             &                           & 0.283277             & \multicolumn{1}{l|}{}        & 0.08645(0.01558)     &                 & 2.91128(0.1151)      &                  & 0.0460               &         & 0.5068               &         & 0.16964              &         &  &  &                                 & \multicolumn{1}{c}{}      &                                 & \multicolumn{1}{c}{}      &                                 & \multicolumn{1}{c}{}      &           &          &                      \\
% PE                      & \multicolumn{1}{l}{} & \multicolumn{1}{c}{141.6} & \multicolumn{1}{l}{} &                              & \multicolumn{1}{l}{} &                 & \multicolumn{1}{l}{} &                  & \multicolumn{1}{l}{} &         & \multicolumn{1}{l}{} &         & \multicolumn{1}{l}{} &         &  &  & \multicolumn{1}{l}{}            &                           & \multicolumn{1}{l}{}            &                           & \multicolumn{1}{l}{}            &                           &           &          &                      \\
% Dive                    & \multicolumn{1}{l}{} & \multicolumn{1}{c}{-}     & \multicolumn{1}{l}{} &                              & \multicolumn{1}{l}{} &                 & \multicolumn{1}{l}{} &                  & \multicolumn{1}{l}{} &         & \multicolumn{1}{l}{} &         & \multicolumn{1}{l}{} &         &  &  & \multicolumn{1}{l}{}            &                           & \multicolumn{1}{l}{}            &                           & \multicolumn{1}{l}{}            &                           &           &          &                      \\
% STEEX                   &                      & \multicolumn{1}{c}{58.8}  &                      & \multicolumn{1}{l|}{}        &                      &                 &                      &                  &                      &         &                      &         &                      &         &  &  & 0.45                            & \multicolumn{1}{c}{0.45}  & 61.05                           & \multicolumn{1}{c}{61.55} & 97.4                            & \multicolumn{1}{c}{97.34} &           &          &                      \\
% OCTET                   &                      &                           &                      & \multicolumn{1}{l|}{}        &                      &                 &                      &                  &                      &         &                      &         &                      &         &  &  & 0.43                            & \multicolumn{1}{c}{0.415} & 54.8                            & \multicolumn{1}{c}{55}    & 95.14                           & \multicolumn{1}{c}{97.22} &           &          &                      \\
% SAFE\_fuse1             & 37.18234             & 31.0041                   & 0.31678              & \multicolumn{1}{l|}{0.28231} & 0.08977(0.012)       & 0.06576(0.0126) & 3.0463(0.115)        & 3.11092(0.06467) & 0.08783              & 0.03455 & 0.83559              & 0.51252 & 0.2892               & 0.51893 &  &  & \multicolumn{1}{l}{}            &                           & \multicolumn{1}{l}{}            &                           & \multicolumn{1}{l}{}            &                           &           &          &                      \\
% SAFE\_fuse10            & 41.190122            &                           & 0.28347              &                              & 0.09(0.012)          &                 & 3.0562(0.11432)      &                  & 0.05737              &         & 0.696872             &         & 0.2871               &         &  &  & \multicolumn{1}{l}{}            &                           & \multicolumn{1}{l}{}            &                           & \multicolumn{1}{l}{}            &                           &           &          &                      \\ \cline{1-15}
% \end{tabular}
% \end{table*}








% \label{subsection:result_CF}
% Experimental Results:

% In this section, we present the experimental results of our proposed method for generating counterfactual explanations using saliency maps.

% Datasets:

% We evaluate our method on several benchmark datasets, including the MNIST [1], CIFAR-10 [2], and ImageNet [3] datasets. These datasets cover a wide range of image classification tasks and provide a diverse set of input instances for evaluating the performance of our method.

% Baselines:

% We compare our proposed method against several state-of-the-art counterfactual generation methods, including ContraGAN [4], Generative Counterfactuals [5], and SteerEx [6]. We also include a baseline method that generates random counterfactual explanations by randomly perturbing the input instances.

% Evaluation Metrics:

% We measure the quality of the generated counterfactual explanations using several metrics, including the similarity to the original input, the distance to the original input, and the effectiveness in changing the prediction of the machine learning model. We also evaluate the interpretability of the generated counterfactual explanations using a user study, where human evaluators rate the quality and usefulness of the explanations.

% Results:

% Our experimental results show that the proposed method outperforms the baseline methods and achieves state-of-the-art performance on all benchmark datasets. Specifically, our method generates counterfactual explanations that are more similar to the original input and more effective in changing the prediction of the machine learning model, while also being more interpretable and easier to understand by human evaluators. We also show that incorporating additional constraints, such as distance constraints or fairness constraints, can further improve the performance of the proposed method.

% % Figure environment removed


% % Please add the following required packages to your document preamble:
% % \usepackage{multirow}
% \begin{table}[]
% \begin{tabular}{lccccccccccccccccccclclcl}
% \cline{1-15}
% \multirow{2}{*}{Method} & \multicolumn{2}{c}{FID} & \multicolumn{2}{c}{LPIPS}            & \multicolumn{2}{c}{KID(std)} & \multicolumn{2}{c}{IS(std)} & \multicolumn{2}{c}{Proximity} & \multicolumn{2}{c}{Sparsity} & \multicolumn{2}{c}{Validity} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{2}{c}{LPIPS} & \multicolumn{2}{c}{FID}    & \multicolumn{2}{c}{validity} \\ \cline{2-15}
%                         & BDDIO     & BDD100k     & BDDIO & \multicolumn{1}{c|}{BDD100k} & BDDIO     & BDD100k          & BDDIO    & BDD100k          & BDDIO        & BDD100k        & BDDIO        & BDD100k       & BDDIO        & BDD100k       &                      &                      &                      &                      & \multicolumn{2}{c}{BDDIO} & \multicolumn{2}{c}{BDDIO}  & \multicolumn{2}{c}{BDDIO}    \\
% CF-StarGAN              &           &             &       & \multicolumn{1}{c|}{}        &           &                  &          &                  &              &                &              &               &              &               &                      &                      &                      &                      & \multicolumn{2}{c}{}      & \multicolumn{2}{c}{}       & \multicolumn{2}{c}{}         \\
% AttGAN                  &           &             &       & \multicolumn{1}{c|}{}        &           &                  &          &                  &              &                &              &               &              &               &                      &                      &                      &                      & \multicolumn{2}{c}{}      & \multicolumn{2}{c}{}       & \multicolumn{2}{c}{}         \\
% CF-AttGAN               &           & 28.906      &       & \multicolumn{1}{c|}{0.196}   &           & 0.072(0.012)     &          & 3.120(0.092)     &              & 0.009          &              & 0.574         &              & 0.5518        &                      &                      &                      &                      & \multicolumn{2}{c}{0.196} & \multicolumn{2}{c}{28.906} & \multicolumn{2}{c}{0.5518}   \\
% STEEX                   &           &             &       & \multicolumn{1}{c|}{}        &           &                  &          &                  &              &                &              &               &              &               &                      &                      &                      &                      & \multicolumn{2}{c}{0.451} & \multicolumn{2}{c}{61.351} & \multicolumn{2}{c}{97.372}   \\
% OCTET                   &           &             &       & \multicolumn{1}{c|}{}        &           &                  &          &                  &              &                &              &               &              &               &                      &                      &                      &                      & \multicolumn{2}{c}{0.422} & \multicolumn{2}{c}{54.956} & \multicolumn{2}{c}{96.187}   \\
% SAFE\_fuse1             &           & 28.453      &       & \multicolumn{1}{c|}{0.204}   &           & 0.064 (0.011)    &          & 3.081 (0.907)    &              & 0.026          &              & 0.409         &              & 0.938         &                      &                      &                      &                      & \multicolumn{2}{c}{0.204} & \multicolumn{2}{c}{28.453} & \multicolumn{2}{c}{0.938}    \\
% SAFE\_fuse10            &           & 29.215      &       & 0.225                        &           & 0.059 (0.010)    &          & 3.242 (0.096)    &              & 0.021          &              & 0.413         &              & 0.914         &                      &                      &                      &                      & \multicolumn{2}{c}{0.225} & \multicolumn{2}{c}{29.21}  & \multicolumn{2}{c}{0.914}    \\ \cline{1-15}
% \end{tabular}
% \end{table}






% \begin{table*}[]
% \begin{tabular}{lccccccc}
% \multicolumn{8}{c}{CelebA}                                                                                                                                                             \\ \hline
% Method       & FID                     & LPIPS                & KID (std)            & IS (std)             & Proximity               & Sparsity             & Validity                \\ \hline
% StarGAN      &                         &                      &                      &                      &                         &                      &                         \\
% CF-StarGAN   & 40.369                  & 0.164                & 0.166 (0.015)        & 3.325 (0.146)        & 0.131                   & 1                    & 0.605                   \\
% AttGAN       &                         &                      &                      &                      &                         &                      &                         \\
% CF-AttGAN    & 43.976                  & 0.114                & 0.169 (0.011)        & 3.593 (0.163)        & 0.084                   & 0.778                & 0.570                   \\
% PE           & 35.8(smile),53.4(young) &                      &                      &                      & -(smile),3.74(young)    &                      & 85.3(smile),72.2(young) \\
% Dive         & 29.4(smile),33.8(young) & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & -(smile),4.58(young)    & \multicolumn{1}{l}{} & 97.3(smile),98.2(young) \\
% Steex        & 10.2(smile),11.8(young) & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & 4.11(smile),3.44(young) & \multicolumn{1}{l}{} & 96.9(smile),97.5(young) \\
% SAFE\_fuse1  & 44.049                  & 0.115                & 0.170 (0.011)        & 3.609 (0.175)        & 0.070                   & 0.681                & 0.936                   \\
% SAFE\_fuse10 & 44.663                  & 0.114                & 0.168 (0.011)        & 3.541 (0.173)        & 0.045                   & 0.589                & 0.887                   \\ \hline
% \end{tabular}
% \end{table*}











% \begin{table}[]
% \begin{tabular}{lccccccc}
% \multicolumn{8}{c}{MNIST}                                                                                                                                                                                                            \\ \hline
% \multicolumn{1}{l|}{Method}       & \multicolumn{1}{c|}{FID} & \multicolumn{1}{c|}{LPIPS} & \multicolumn{1}{c|}{KID(std)} & \multicolumn{1}{c|}{IS(std)} & \multicolumn{1}{c|}{Proximity} & \multicolumn{1}{c|}{Sparsity} & Validity \\ \hline
% \multicolumn{1}{l|}{StarGAN}      & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{CF-StarGAN}   & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{AttGAN}       & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{CF-AttGAN}    & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{SAFE\_fuse1}  & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\
% \multicolumn{1}{l|}{SAFE\_fuse10} & \multicolumn{1}{c|}{}    & \multicolumn{1}{c|}{}      & \multicolumn{1}{c|}{}         & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{}         &          \\ \hline
% \end{tabular}
% \end{table}