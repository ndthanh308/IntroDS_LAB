\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{adel2018discovering}
Adel, T., Ghahramani, Z., Weller, A.: Discovering interpretable representations
  for both deep generative and discriminative models. In: International
  Conference on Machine Learning. pp. 50--59. PMLR (2018)

\bibitem{arcones1992bootstrap}
Arcones, M.A., Gine, E.: On the bootstrap of u and v statistics. The Annals of
  Statistics pp. 655--674 (1992)

\bibitem{bengio2013representation}
Bengio, Y., Courville, A., Vincent, P.: Representation learning: A review and
  new perspectives. IEEE Transactions on Pattern Analysis and Machine
  Intelligence  \textbf{35}(8),  1798--1828 (2013)

\bibitem{bengio2013estimating}
Bengio, Y., L{\'e}onard, N., Courville, A.: Estimating or propagating gradients
  through stochastic neurons for conditional computation. arXiv:1308.3432
  (2013)

\bibitem{burgess2018understanding}
Burgess, C.P., Higgins, I., Pal, A., Matthey, L., Watters, N., Desjardins, G.,
  Lerchner, A.: Understanding disentangling in $\beta$-vae. arXiv:1804.03599
  (2018)

\bibitem{chen2018isolating}
Chen, R.T., Li, X., Grosse, R.B., Duvenaud, D.K.: Isolating sources of
  disentanglement in variational autoencoders. In: Advances in Neural
  Information Processing Systems. vol.~31, pp. 2615--2625 (2018)

\bibitem{creager2019flexibly}
Creager, E., Madras, D., Jacobsen, J.H., Weis, M., Swersky, K., Pitassi, T.,
  Zemel, R.: Flexibly fair representation learning by disentanglement. In:
  International Conference on Machine Learning. pp. 1436--1445. PMLR (2019)

\bibitem{dupont2018learning}
Dupont, E.: Learning disentangled joint continuous and discrete
  representations. In: Advances in Neural Information Processing Systems.
  vol.~31 (2018)

\bibitem{eastwood2018framework}
Eastwood, C., Williams, C.K.: A framework for the quantitative evaluation of
  disentangled representations. In: International Conference on Learning
  Representations (2018)

\bibitem{friede2021efficient}
Friede, D., Niepert, M.: Efficient learning of discrete-continuous computation
  graphs. In: Advances in Neural Information Processing Systems. vol.~34, pp.
  6720--6732 (2021)

\bibitem{gondal2019transfer}
Gondal, M.W., Wuthrich, M., Miladinovic, D., Locatello, F., Breidt, M.,
  Volchkov, V., Akpo, J., Bachem, O., Sch{\"o}lkopf, B., Bauer, S.: On the
  transfer of inductive bias from simulation to the real world: a new
  disentanglement dataset. In: Advances in Neural Information Processing
  Systems. vol.~32 (2019)

\bibitem{grathwohl2018backpropagation}
Grathwohl, W., Choi, D., Wu, Y., Roeder, G., Duvenaud, D.: Backpropagation
  through the void: Optimizing control variates for black-box gradient
  estimation. In: International Conference on Learning Representations (2018)

\bibitem{hafner2020mastering}
Hafner, D., Lillicrap, T., Norouzi, M., Ba, J.: Mastering atari with discrete
  world models. arXiv:2010.02193  (2020)

\bibitem{hafner2023mastering}
Hafner, D., Pasukonis, J., Ba, J., Lillicrap, T.: Mastering diverse domains
  through world models. arXiv:2301.04104  (2023)

\bibitem{higgins2018towards}
Higgins, I., Amos, D., Pfau, D., Racani{\`{e}}re, S., Matthey, L., Rezende,
  D.J., Lerchner, A.: Towards a definition of disentangled representations.
  arXiv:1812.02230  (2018)

\bibitem{higgins2017beta}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M.,
  Mohamed, S., Lerchner, A.: $\beta$-vae: Learning basic visual concepts with a
  constrained variational framework. In: International Conference on Learning
  Representations (2017)

\bibitem{jang2017categorical}
Jang, E., Gu, S., Poole, B.: Categorical reparameterization with
  gumbel-softmax. In: International Conference on Learning Representations
  (2017)

\bibitem{jeong2019learning}
Jeong, Y., Song, H.O.: Learning discrete and continuous factors of data via
  alternating disentanglement. In: International Conference on Machine
  Learning. pp. 3091--3099. PMLR (2019)

\bibitem{kim2018disentangling}
Kim, H., Mnih, A.: Disentangling by factorising. In: International Conference
  on Machine Learning. pp. 2649--2658. PMLR (2018)

\bibitem{kingma2013auto}
Kingma, D.P., Welling, M.: Auto-encoding variational bayes. In: International
  Conference on Learning Representations (2013)

\bibitem{klindt2021towards}
Klindt, D.A., Schott, L., Sharma, Y., Ustyuzhaninov, I., Brendel, W., Bethge,
  M., Paiton, D.M.: Towards nonlinear disentanglement in natural data with
  temporal sparse coding. In: International Conference on Learning
  Representations (2021)

\bibitem{kumar2017variational}
Kumar, A., Sattigeri, P., Balakrishnan, A.: Variational inference of
  disentangled latent concepts from unlabeled observations. In: International
  Conference on Learning Representations (2017)

\bibitem{lecun2004learning}
LeCun, Y., Huang, F.J., Bottou, L.: Learning methods for generic object
  recognition with invariance to pose and lighting. In: Proceedings of the 2004
  IEEE Computer Society Conference on Computer Vision and Pattern Recognition,
  2004. CVPR 2004. vol.~2, pp. II--104. IEEE (2004)

\bibitem{locatello2019fairness}
Locatello, F., Abbati, G., Rainforth, T., Bauer, S., Sch{\"o}lkopf, B., Bachem,
  O.: On the fairness of disentangled representations. In: Advances in Neural
  Information Processing Systems. vol.~32 (2019)

\bibitem{locatello2019challenging}
Locatello, F., Bauer, S., Lucic, M., Raetsch, G., Gelly, S., Sch{\"o}lkopf, B.,
  Bachem, O.: Challenging common assumptions in the unsupervised learning of
  disentangled representations. In: International Conference on Machine
  Learning. pp. 4114--4124. PMLR (2019)

\bibitem{locatello2020weakly}
Locatello, F., Poole, B., R{\"a}tsch, G., Sch{\"o}lkopf, B., Bachem, O.,
  Tschannen, M.: Weakly-supervised disentanglement without compromises. In:
  International Conference on Machine Learning. pp. 6348--6359. PMLR (2020)

\bibitem{locatello2019disentangling}
Locatello, F., Tschannen, M., Bauer, S., R{\"{a}}tsch, G., Sch{\"{o}}lkopf, B.,
  Bachem, O.: Disentangling factors of variations using few labels. In:
  International Conference on Learning Representations (2020)

\bibitem{maddison2017concrete}
Maddison, C.J., Mnih, A., Teh, Y.W.: The concrete distribution: A continuous
  relaxation of discrete random variables. In: International Conference on
  Learning Representations (2017)

\bibitem{makhzani2015adversarial}
Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., Frey, B.: Adversarial
  autoencoders. arXiv:1511.05644  (2015)

\bibitem{nguyen2010estimating}
Nguyen, X., Wainwright, M.J., Jordan, M.I.: Estimating divergence functionals
  and the likelihood ratio by convex risk minimization. IEEE Transactions on
  Information Theory  \textbf{56}(11),  5847--5861 (2010)

\bibitem{ozair2021vector}
Ozair, S., Li, Y., Razavi, A., Antonoglou, I., Van Den~Oord, A., Vinyals, O.:
  Vector quantized models for planning. In: International Conference on Machine
  Learning. pp. 8302--8313. PMLR (2021)

\bibitem{peters2017elements}
Peters, J., Janzing, D., Sch{\"o}lkopf, B.: Elements of causal inference:
  Foundations and learning algorithms. The MIT Press (2017)

\bibitem{ramesh2021zero}
Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M.,
  Sutskever, I.: Zero-shot text-to-image generation. In: International
  Conference on Machine Learning. pp. 8821--8831. PMLR (2021)

\bibitem{razavi2019generating}
Razavi, A., Van~den Oord, A., Vinyals, O.: Generating diverse high-fidelity
  images with vq-vae-2. In: Advances in Neural Information Processing Systems.
  vol.~32 (2019)

\bibitem{reed2015deep}
Reed, S.E., Zhang, Y., Zhang, Y., Lee, H.: Deep visual analogy-making. In:
  Advances in Neural Information Processing Systems. vol.~28 (2015)

\bibitem{ridgeway2018learning}
Ridgeway, K., Mozer, M.C.: Learning deep disentangled embeddings with the
  f-statistic loss. In: Advances in Neural Information Processing Systems.
  vol.~31 (2018)

\bibitem{rombach2022high}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution
  image synthesis with latent diffusion models. 2022 ieee. In: CVF Conference
  on Computer Vision and Pattern Recognition (CVPR). pp. 10674--10685 (2022)

\bibitem{scholkopf2012causal}
Sch{\"{o}}lkopf, B., Janzing, D., Peters, J., Sgouritsa, E., Zhang, K., Mooij,
  J.M.: On causal and anticausal learning. In: International Conference on
  Machine Learning (2012)

\bibitem{shayer2018learning}
Shayer, O., Levi, D., Fetaya, E.: Learning discrete weights using the local
  reparameterization trick. In: International Conference on Learning
  Representations (2018)

\bibitem{shu2019weakly}
Shu, R., Chen, Y., Kumar, A., Ermon, S., Poole, B.: Weakly supervised
  disentanglement with guarantees. In: International Conference on Learning
  Representations (2020)

\bibitem{sugiyama2012density}
Sugiyama, M., Suzuki, T., Kanamori, T.: Density-ratio matching under the
  bregman divergence: a unified framework of density-ratio estimation. Annals
  of the Institute of Statistical Mathematics  \textbf{64}(5),  1009--1044
  (2012)

\bibitem{trauble2021disentangled}
Tr{\"a}uble, F., Creager, E., Kilbertus, N., Locatello, F., Dittadi, A., Goyal,
  A., Sch{\"o}lkopf, B., Bauer, S.: On disentangled representations learned
  from correlated data. In: International Conference on Machine Learning. pp.
  10401--10412. PMLR (2021)

\bibitem{tschannen2018recent}
Tschannen, M., Bachem, O., Lucic, M.: Recent advances in autoencoder-based
  representation learning. arXiv:1812.05069  (2018)

\bibitem{tucker2017rebar}
Tucker, G., Mnih, A., Maddison, C.J., Lawson, J., Sohl-Dickstein, J.: Rebar:
  Low-variance, unbiased gradient estimates for discrete latent variable
  models. In: Advances in Neural Information Processing Systems. vol.~30 (2017)

\bibitem{van2017neural}
Van Den~Oord, A., Vinyals, O., et~al.: Neural discrete representation learning.
  In: Advances in Neural Information Processing Systems. vol.~30 (2017)

\bibitem{van2019disentangled}
Van~Steenkiste, S., Locatello, F., Schmidhuber, J., Bachem, O.: Are
  disentangled representations helpful for abstract visual reasoning? In:
  Advances in Neural Information Processing Systems. vol.~32 (2019)

\bibitem{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,
  Kaiser, {\L}., Polosukhin, I.: Attention is all you need. In: Advances in
  Neural Information Processing Systems. vol.~30 (2017)

\bibitem{watanabe1960information}
Watanabe, S.: Information theoretical analysis of multivariate correlation. IBM
  Journal of Research and Development  \textbf{4}(1),  66--82 (1960)

\bibitem{watters2019spriteworld}
Watters, N., Matthey, L., Borgeaud, S., Kabra, R., Lerchner, A.: Spriteworld: A
  flexible, configurable reinforcement learning environment (2019)

\bibitem{watters2019spatial}
Watters, N., Matthey, L., Burgess, C.P., Lerchner, A.: Spatial broadcast
  decoder: {A} simple architecture for learning disentangled representations in
  vaes. arXiv:1901.07017  (2019)

\bibitem{williams1992simple}
Williams, R.J.: Simple statistical gradient-following algorithms for
  connectionist reinforcement learning. Reinforcement learning pp. 5--32 (1992)

\end{thebibliography}
