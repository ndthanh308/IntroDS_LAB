\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
%
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{bbm}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage[title]{appendix}
\usepackage[hidelinks]{hyperref}
\renewcommand\UrlFont{\color{blue}\rmfamily}
\usetikzlibrary{calc,fit,positioning,shapes}
\usepackage[misc]{ifsym}
% 
\newcommand{\kl}[2]{D_{\operatorname{KL}}\bigl(#1\;\|\;#2\bigr)}
\newcommand{\E}[2]{\mathbb{E}_{#1}\left[#2\right]}
\graphicspath{{figures/}}
% 
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
%
\renewcommand\UrlFont{\color{blue}\rmfamily}
% 
%
%
%
% \includeonly{paper}
%
%
% 
% 
\begin{document}
%
\title{Learning Disentangled Discrete Representations}
%
%\titlerunning{Learning Disentangled Discrete Representations}
%
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{
   David~Friede\inst{1} (\Letter) \and %\orcidID{0000-1111-2222-3333} \and
   Christian~Reimers\inst{2} \and %\orcidID{1111-2222-3333-4444} \and
   Heiner~Stuckenschmidt\inst{1} \and %\orcidID{2222--3333-4444-5555} %\and
   Mathias~Niepert\inst{3,4} %\orcidID{3333-4444-5555-6666}
}
%
\authorrunning{D. Friede et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{
   University of Mannheim, Mannheim, Germany\\
   \email{\{david,heiner\}@informatik.uni-mannheim.de} \and
   Max Planck Institute for Biogeochemistry, Jena, Germany\\ 
   \email{creimers@bgc-jena.mpg.de} \and
   University of Stuttgart, Stuttgart, Germany\\
   \email{mathias.niepert@simtech.uni-stuttgart.de} \and
    NEC Laboratories Europe, Heidelberg, Germany \\
}
%
\toctitle{Learning Disentangled Discrete Representations}
\tocauthor{Friede,~D., Reimers,~C., Stuckenschmidt,~H., Niepert,~M.}
%
\maketitle              % typeset the header of the contribution
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract & Keywords
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{abstract}
Recent successes in image generation, model-based reinforcement learning, and text-to-image generation have demonstrated the empirical advantages of discrete latent representations, although the reasons behind their benefits remain unclear. We explore the relationship between discrete latent spaces and disentangled representations
by replacing the standard Gaussian variational autoencoder (VAE) with a tailored categorical variational autoencoder.
We show that the underlying grid structure of categorical distributions mitigates the problem of rotational invariance associated with multivariate Gaussian distributions, acting as an efficient inductive prior for disentangled representations.
We provide both analytical and empirical findings that demonstrate the advantages of discrete VAEs for learning disentangled representations.
Furthermore, we introduce the first unsupervised model selection strategy that favors disentangled representations.
\keywords{Categorical VAE \and Disentanglement.}
\end{abstract}
%
%
%
%
\input{paper}
%
%
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\clearpage
%
\bibliographystyle{splncs04}
\bibliography{bibliography}
%
%
%
\include{appendix}
% 
% 
% 
% 
%
%
%
%
\end{document}