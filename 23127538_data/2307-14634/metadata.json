{
  "title": "Fact-Checking of AI-Generated Reports",
  "authors": [
    "Razi Mahmood",
    "Diego Machado Reyes",
    "Ge Wang",
    "Mannudeep Kalra",
    "Pingkun Yan"
  ],
  "submission_date": "2023-07-27T05:49:24+00:00",
  "revised_dates": [
    "2025-06-02T00:45:38+00:00"
  ],
  "abstract": "With advances in generative artificial intelligence (AI), it is now possible to produce realistic-looking automated reports for preliminary reads of radiology images. This can expedite clinical workflows, improve accuracy and reduce overall costs. However, it is also well-known that such models often hallucinate, leading to false findings in the generated reports. In this paper, we propose a new method of fact-checking of AI-generated reports using their associated images. Specifically, the developed examiner differentiates real and fake sentences in reports by learning the association between an image and sentences describing real or potentially fake findings. To train such an examiner, we first created a new dataset of fake reports by perturbing the findings in the original ground truth radiology reports associated with images. Text encodings of real and fake sentences drawn from these reports are then paired with image encodings to learn the mapping to real/fake labels. The utility of such an examiner is demonstrated for verifying automatically generated reports by detecting and removing fake sentences. Future generative AI approaches can use the resulting tool to validate their reports leading to a more responsible use of AI in expediting clinical workflows.",
  "categories": [
    "cs.AI",
    "cs.CR",
    "cs.CV",
    "cs.LG",
    "eess.IV"
  ],
  "primary_category": "cs.AI",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14634",
  "pdf_url": "https://arxiv.org/pdf/2307.14634v2",
  "comment": "10 pages, 3 figures, 3 tables",
  "num_versions": null,
  "size_before_bytes": 7910251,
  "size_after_bytes": 339281
}