\noindent Nonuniformity correction is an ongoing area of research. Different approaches are described in \cref{sec:prior:calib,sec:prior:singleimage}.

\subsection{Calibration-based methods}\label{sec:prior:calib}
\noindent The process of calibration requires collecting data of a known heat source under different environmental conditions. This process is usually conducted with a scientifically calibrated blackbody in an environmental chamber. The data are used to find coefficients that solve an equation for the calibration. 

The baseline for the calibration methods is a one-point correction. These methods usually assume a known and constant gain across ambient temperatures, and only solve for the offset (e.g.,~\cite{Schulz1995}). The natural extension is the two-point correction where no assumption is made for the gain (e.g.,~\cite{Riou2004}). These early methods solved for the coefficients using a simple linear regression model.

Contemporary methods formulate the nonuniformity correction (NUC) as an inverse problem. 
Nugent et al.~\cite{Nugent2013} solved it as a least-squares problem, with the offset and gain modeled as polynomials of the object's temperature. 
In ref.~\cite{Nugent2014}, they used the internal shutter of the camera to periodically update the results of the calibration. 
Liang et al.~\cite{Liang2017} based the solution on interpolation of a predefined offset table for each ambient temperature, and the offset values for this table were found using a two-point correction.
Chang and Li~\cite{Chang2019Intergration} solved for both the ambient temperature and integration time of the camera.

Calibration-based methods produce good results but relay on the collection of extensive data. The data must be accurate and contain both varying object temperatures and ambient temperatures, requiring the use of scientific-grade equipment. Moreover, these methods are valid only for the camera used to collect the data, meaning that the data-collection process must be performed for every camera to be calibrated. Any attempt to apply the calibration data on another camera will be noisy and have noticeable FPN because the coefficients of the calibration will not be suitable between cameras.

\subsection{Scene-based methods}
\noindent Scene-based methods exploit redundant data in and between frames, rendering calibration unnecessary. 
The redundant data can be movement between frames, camera jitter between images, or a constraint on the dataset itself.

Most of these methods assume that the change in ambient temperature is slow, thus the gain and offset changes slowly, and both can be regarded as constant between frames. 
This assumption holds true, but only for a limited time and ambient temperature span.

Averbuch et al.~\cite{Averbuch2007} used the motion between frames. Consecutive frames were registered to add data on each pixel, and an inverse problem was solved to find the offset. The solution was updated using a Kalman filter.
Papini et al.~\cite{Papini2018} used pairs of blurred and sharp images to approximate the gain and offset.
Saragadam et al.~\cite{Saragadam2021} used a neural network as prior information for solving an optimization problem. The input to the network was jittered frames of the same object. The physical constraint shown in \cref{eq:stefanBoltzmannTaylor} was imposed as part of the optimization problem.

These approaches offer good approximations for the temperatures but are expensive to calculate and require redundancy between frames.

\subsection{Single image-based methods}\label{sec:prior:singleimage}
\noindent The idea of this approach is to use only information that is already embedded in the frame itself.
Scribner et al.~\cite{nnOld} used a neural network to find offset and gain. The neural network acted as a locally adaptive filter on a small neighborhood.
Tendero and Gilles~\cite{admire} equalized the frame using the cumulative histogram of all of the columns in the frame, and then used the discrete cosine transform to denoise the results.

Recently, methods that utilize neural networks in general, and convolutional neural networks (CNN) in particular, have been suggested.
He et al.~\cite{He2018} suggested using a U-Net-type CNN trained end-to-end.
Jian et al.~\cite{Jian2018} filtered the frame with a bilateral filter to allow the network to concentrate only on the high-frequency information.
Chang et al.~\cite{Chang2019} shared multiscale information between layers of the network to improve the NUC results.
Guan et al.~\cite{snrwdnn} used the wavelet transform to decompose the frame into different scales and then used the scales as input to the network. The network output was the wavelets coefficients of the corrected frame.

Estimating scene temperature accurately using only a single frame at different ambient temperatures, without the need to calibrate for each camera, has yet to be achieved.

\input{content/main/prior/fig_cmp_method_scheme.tex}
\cref{fig:prior:cmpOtherMethodsScheme} illustrates the difference between our method and previous methods for estimating the temperature of an object from a thermal image.
Previous methods consisted of two steps: first, applying a nonuniformity correction (NUC) to the thermal image to remove the effects of sensor fixed-pattern noise (FPN); second, calibrating the image using a known heat source to map the gray levels to temperature values.
This process required a specific calibration procedure for each individual camera, and a reliable heat source with a known temperature and emissivity.
Our method, on the other hand, performs both NUC and calibration in a single step.
Our method does not require any calibration for different cameras, and can estimate the temperature of an object from a single thermal image, without any prior knowledge of the object (e.g., the object's emissivity).

This work aims to both estimate the scene temperature and correct the nonuniformity in frames captured by low-cost uncooled microbolometer-based cameras.
We introduce a model for the nonuniformity in IR cameras based on the physical acquisition model, which accounts for the ambient temperature of the camera.
The model utilizes prior knowledge on the physics of the domain, namely radial spatial dependence, which is incorporated into the mathematical modeling of the nonuniformity. The nonuniformity model is general and represents different cameras, unlike previous calibration methods.
The model is used to train a neural network to correct the nonuniformity and produce accurate scene temperatures based only on a single frame and the ambient temperature of the camera.
We also compare a neural network with a physical constraint based on \cref{eq:finalWithFPA} to an end-to-end temperature-estimation network and show that the physical constraint improves performance.
Finally, we demonstrate our method on real data collected with a low-cost uncooled microbolometer camera and compare it to measurements taken with an uncooled scientific-grade accurate radiometric camera to show that the method indeed works and can provide generalizations.
To summarize the findings of this work:
\begin{enumerate}
    \item Estimating scene temperature accurately from a low-cost camera with only a single gray-level frame and ambient temperature as input.
    \item Elimination of the need to calibrate each camera separately by developing a nonuniformity simulator that uses physical prior knowledge of radial pixel dependence.
    The simulator is general and can faithfully represent multiple cameras and situations for a wide range of ambient temperatures.
    \item Investigation of the effect of the physical constraint introduced in \cref{eq:stefanBoltzmannTaylor} on the scene temperature estimation.
    \item Published a \href{https://drive.google.com/drive/folders/1tu_hMJR1SPunttWM65EyuCs7DJs2K6ah?usp=drive_link}{dataset} of thermal images with ground-truth temperature measurements.
\end{enumerate}