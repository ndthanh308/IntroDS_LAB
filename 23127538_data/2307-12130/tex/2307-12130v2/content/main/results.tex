\noindent The methods described in \cref{sec:method} were used to estimate temperature maps and correct nonuniformity in microbolometer-based thermal cameras. The presented experiments are organized as follows: 
\begin{enumerate}
    \item The data and equipment used to develop the proposed method.
    \item The results for characterization of the nonuniformity as presented in \cref{sec:method:characterize}.
    \item The results of the NUC performed by the network, including the effect of the physical constraint.
    \item The results of the NUC performed by the network on real data.
\end{enumerate}

\subsection{Data}\label{sec:materials:data}
\noindent The data for the environmental chamber were measured at ambient temperatures $\Tamb$= \{27, 31, 37.2, 38.9, 40.4, 41.5, 43.6, 44.7, 46.2, 46.8, 48, 50.8\}$^\circ C$. The \blackbody temperatures at each \opPoint were $\Tobj$= \{20, 25, 30, 35, 40, 45, 50, 55, 60\}$^\circ C$.

Noise variance was determined from the environmental chamber measurements:
\begin{equation}\label{eq:varNoise}
    \sigma^2[\tamb,\tobj] = \frac{1}{h\cdot w}\sum_{i=0}^h\sum_{j=0}^w\text{Var}(R[\tamb,\tobj][i,j])_N
\end{equation}
As seen in \cref{eq:varNoise}, the noise variance  used as input to train the network in \cref{eq:netInput} was the average over the spatial dimension of the variance map obtained from $N$ images. The effects of $\tamb,\tobj$ on $\sigma^2$ were found to be negligible, so the average of all $\sigma^2$ was $\sigma^2=5$ gray levels.

As for the training of the network, the datasets were temperature maps collected using a FLIR \scientificCamera camera, which is a scientific-level bolometer-based radiometric camera. The \scientificCamera accuracy is only $2\%$ of the temperature range in each frame.

The training dataset was $12,897$ frames. The validation set was comprised of $4,723$ frames. All frames were of different agricultural fields in Israel, taken from an unmanned aerial vehicle (UAV) flying $70_m-100_m$ above the ground.
Only sharp frames were used, hand-picked by a human user.

The validation sets were captured at the same locations as the training sets, but on different days. This validation procedure was chosen to eliminate data leakage between the training and validation sets, so that the metrics represent the ability of the network to generalize to different data. 
The training and validation dataset split remained the same for all training schemes, to allow a fair comparison between different experiments.

\subsection{Equipment}\label{sec:materials:equipment}
% Figure environment removed
\noindent The environmental chamber used for the characterization process (\cref{sec:method:characterize}) was designed and built at the Agricultural Research Organization, Volcani Institute. A cooking oven was adapted by controlling the heating element with a \campbellCtrl controller. A PID control loop was implemented on the \campbellCtrl to achieve a stable ambient temperature for the camera inside the oven. A schematic of the environmental chamber is presented in \cref{fig:envChamber}.

The \campbellCtrl, \taucamera and \blackbody were all controlled via Python3.8 from a Linux Ubuntu 20.04 computer.

The camera was calibrated using FLIR ThermalResearch v2.1. The configuration of the camera can be seen in \cref{tab:cameraParams} at the supplementary material and information on the various functions can be found in Tau2 Quark Software IDD.

\subsection{Camera characterization}
The number of coefficients for the radial fit (\cref{eq:spatialRadiiFit}) was set to $\mRadial=8$. The number of coefficients for the FPA fit of the radial coefficients (\cref{eq:fitRadiiFPA}) was set to $\mFPA=3$. These values were chosen empirically.

The results of the nonuniformity characterization process described in \cref{sec:method:characterize} as summarized by \cref{alg:estimateNonUniformity} are shown in \cref{fig:fitRes}. 
Four examples from different \opPoints are shown. These results illustrate that the fitting is both valid and corrects the skew in the measurements.

% Figure environment removed

\subsection{Nonuniformity correction}\label{sec:results:nuc}
% Figure environment removed
% Figure environment removed
\newcommand{\heightFigCmpMethodsReal}{25ex}
\newcommand{\colorRealMethodCmpCaptions}{white}
% Figure environment removed

A visual comparison of NUC between the proposed method and other methods is presented in \cref{fig:results:zoomin}. The left-most figure is the input to the network. The patch in the red square is zoomed-in and presented for GxPD, ADMIRE~\cite{admire}, He et al.~\cite{He2018} and SNRWDNN~\cite{snrwdnn}. 

Observing the results, both He et al.~\cite{He2018} and SNRWDNN~\cite{snrwdnn} does not thoroughly removes the NUC, and ADMIRE~\cite{admire} increases noise and adds surplus edges and details thus limiting the fidelity of its estimation. GxPD appears similar to the ground truth data.
More visual results are in \cref{fig:supp:patch:1,fig:supp:patch:2,fig:supp:patch:3,fig:supp:patch:4,fig:supp:patch:5,fig:supp:patch:6,fig:supp:patch:7,fig:supp:patch:8,fig:supp:patch:9,fig:supp:patch:10,fig:supp:patch:11,fig:supp:patch:12} in the \emph{supplementary material}.

A side-view of the results of the temperature estimation can be seen in \cref{fig:results:plots}. These figures contain the real temperature, and the estimations made by the results of the E2E network and the physically constrained network GxPD\@. As can be seen, both estimations are accurate and both network configurations are similar. The input to the network cannot be displayed with the plots, because it is in gray levels, whereas the network output temperatures are in $^\circ C$.

\cref{tab:resultsWithWithoutAmb} compares the metrics of the estimations between the different configurations and compares them to He et al~\cite{He2018} and to SNRWDNN~\cite{snrwdnn}. The latter results were retrained on the same data using the training scheme suggested by those authors. For a fair comparison, we constrained our network to the same depth and number of filters as He et al~\cite{He2018}.
The results of the E2E network without the ambient temperature are also compared. The metrics in the table are an average of the metrics from all validation sets.
Although ADMIRE~\cite{admire} is compared visually in \cref{fig:results:zoomin}, its metrics cannot be compared in the table because the method does not estimate the temperature, only corrects nonuniformity.

The physical constraint on the network (GxPD) improves the results by $12\%$ in MAE compared to the E2E network. This improvement is significant, and shows that the physical constraint is beneficial for the network.
GxPD achieved a $12\%$ improvements in MAE over E2E.
Although GxPD is superior, E2E still offers a significant improvement over other SOTA methods.
This improvement can be explained by the expressive power of the neural network. The network in E2E can intrinsically represent the GxPD network~\cite{nn_alg_book}.
Still, the $12\%$ decrease in MAE between E2E and GxPD means that the physical constraint still has a measurable effect on the results.

Another result in \cref{tab:resultsWithWithoutAmb} is that incorporating the ambient temperature into the network significantly improves the performance of the network, reducing the MAE by $13\%$.

\begin{table}[ht]
    \centering
    \caption{Estimation results for the different configurations (end-to-end (E2E), with and without (w/o) $\tamb$; and physically constrained (GxPD)).}
    \begin{tabular}{|c|c|c|c|}
    \hline
    Network & MAE [$^\circ C$] & PSNR [dB] & SSIM \\
    \hline
    He et al.~\cite{He2018} & 0.93 & 37.21 & 0.95 \\
    \hline
    SNRWDNN~\cite{snrwdnn} & 0.77 & 37.68 & 0.97 \\
    \hline 
    E2E w/o $\tamb$ &  0.48 & 43.25 & 0.99 \\
    \hline
    E2E with $\tamb$ &  0.42 & 44.50 & 0.99 \\
    \hline
    GxPD & 0.37 & 45.43 & 0.99 \\
    \hline
    \end{tabular}
    \label{tab:resultsWithWithoutAmb}
\end{table}

\subsection{Real data}\label{sec:experiments:realdata}
% Figure environment removed%
\noindent We captured the same scene with an accurate \scientificCamera scientific-level radiometric camera and with the \taucamera camera. The \scientificCamera outputs a temperature map and the \taucamera outputs gray levels corresponding to the radiation flux. The camera used for capturing these images was different from the one used for the calibration process.

The ambient temperature and emissivity of the \scientificCamera were tuned using an accurate temperature sensor placed in the scene. The scenes were registered by hand-picking correspondence points and performing a homography with OpenCV V4.5.4.

Six results are presented in \cref{fig:results:realData} and six more are presented in \cref{jeep,shed,building,shed2,building_sunlight,warehouse} in the supplementary material. The gray scales are the temperatures taken using the \scientificCamera. The blue patches in the frames are the per-pixel differences between the temperatures and the results of GxPD\@.
The numbers in white are the MAE between GxPD and the temperature map. We used the GxPD method because its MAE results were significantly better.
The two uppermost figures are cars taken at the morning. The hot areas with high errors stem from direct sunlight hitting the metal and glass surfaces of the cars\. the next two figures are buildings captured from a great distance. The last figure is a tree from a distance. 
Part of the error stems from registration errors between the two cameras, or from moving objects during acquisition (e.g, leaves in the lowest figure).

The range of the MAE is $0.15^\circ C-0.93^\circ C$.
This small error in temperature estimation is of the same order as the accuracy of the scientific \scientificCamera. 
This accurate result was achieved without any thermographic corrections or NUC from the \taucamera, only the radiation flux as gray levels. The exact configuration can be seen in \cref{tab:cameraParams} at the supplementary materiel.
These results are also on-par with the results on the validation set (\cref{tab:resultsWithWithoutAmb}) and with the visual results (\cref{fig:results:zoomin}).

\cref{fig:results:realDataCmp} compared between GxPD to SNRWDNN~\cite{snrwdnn} and to He et al.~\cite{He2018}.
Two registered frames were captured from a UAV simultaneously: a ground truth temperature map using \scientificCamera, and a gray-level frame using the \taucamera camera. The \taucamera used for capturing these images was \emph{different} from the one used in the calibration process.
Each subfigure in \cref{fig:results:realDataCmp} is the error between the estimation of a method to the ground truth temperature map in \cref{fig:results:realDataCmp:gt}. The number in white is the MAE in $\circ C$ between the temperature map and the estimation of the method.
The estimations from left to right - \cref{fig:results:realDataCmp:gxpd} GxPD (ours), \cref{fig:results:realDataCmp:he} He et al.~\cite{He2018} and \cref{fig:results:realDataCmp:snrwdnn} SNRWDNN~\cite{snrwdnn}.
The figure illustrates the generalization capabilities of our method.
While the other methods are trained on the same dataset as our method, they suffer significant degradation in performance when ran on frames acquired by other cameras.
Specifically, the temperature map estimated by SNRWDNN~\cite{snrwdnn} in \cref{fig:results:realDataCmp:snrwdnn} is full of artifacts, and suffer a significant increase in error as compared to the results on the synthetic dataset in \cref{fig:results:zoomin,tab:resultsWithWithoutAmb}.

% 
% \subsection{Roughness}
% Roughness is a widely used reference-free metric for evaluating FPN-correction methods \cite{roughness}. The roughness index $\rho$ measures the high-pass content of an image and is defined by:
% \begin{equation}\label{eq:roughness}
%     \rho = \frac{\norm{h_1*P}_1+\norm{h_2*P}_1}{\norm{P}_1}
% \end{equation}
% where P is the restored image, $h_1=[-1,1]$, $h_2=h^T_1$ and $*$ is the convolution operator.
% \cref{tab:roughness} compares different NUC methods applied to the datasets mentioned in \cref{sec:materials:data}. Note that lower roughness is preferred.
% The ADMIRE \cite{admire} \href{https://www.ipol.im/pub/art/2012/glmt-mire/?utm_source=doi}{\textit{published C++ code}} was used.
% The results of the proposed method are superior, but the difference between the E2E and GxPD are negligible. A qualitative comparison to ADMIRE is seen in \cref{fig:results:zoomin}.
% \begin{table}
%     \centering
%     \caption{Roughness results for different methods used on the validation dataset. A is Neve Yaar, B is Gilat, C is Mevo Bytar, D is Nir Eliyho, and E is Tzora.}
%     \begin{tabular}{|c|c|c|c|c|c|c|}
%         \hline
%         & A & B & C & D & E \\
%         \hline
%         ADMIRE~\cite{admire} & 0.33 & 0.31 & 0.18 &  0.22 & 0.37\\
%         \hline
%         E2E & 0.092 & 0.033 & 0.049 & 0.037 & 0.12\\
%         \hline
%         GxPD & 0.091 & 0.033 & 0.049 & 0.036 & 0.12\\
%         \hline
%     \end{tabular}
%     \label{tab:roughness}
% \end{table}