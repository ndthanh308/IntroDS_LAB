\section{Introduction}\label{sec:intro}
Federated learning is a popular approach for training machine learning models on decentralized data, where data privacy concerns or other constraints prevent centralized data aggregation~\citep{mcmahan2017communication,kairouz2019federated}. In federated learning, model updates are computed locally on each device (the \emph{client}) and then aggregated to train a global model at the center (the \emph{server}). This approach has gained traction due to its ability to leverage data from multiple sources while preserving privacy, security, and autonomy, and has the potential to make machine learning more participatory in a range of interesting problem domains~\citep{paml2020,jones2020nonrivalry,pentland2021building}.


\vspace{0.05in}
Federated learning is naturally most attractive when the participating clients have access to different data, leading to data heterogeneity~\citep{du2022flamby}. 
This heterogeneity can lead to significant fairness issues, where the performance of the global model can be biased towards the data distribution of some clients over others~\citep{dwork2012fairness,li2019fair,abay2020mitigating}. Heterogeneity can also hurt the generalization of the global model~\citep{quinonero2008dataset,mohri2019agnostic}. Specifically, if some clients have a disproportionate influence on the global model, the resulting model is neither fair nor will it generalize well to new clients. Such disparities are especially prevalent and detrimental in medical research, and have resulted in misdiagnosis and suboptimal treatment~\citep{graham2015disparities,albain2009racial,nana2021health}.

\vspace{0.05in}
To address these challenges, distributionally robust objectives (DRO) explicitly account for the heterogeneity across clients and seek to optimize performance under the worst-case data distribution across clients, rather than just the average performance~\citep{rahimian2019distributionally}. This approach can lead to more robust models that are less biased towards specific clients and more likely to generalize to new clients~\citep{mohri2019agnostic,duchi2023distributionally}. However, such robust objectives are significantly harder to optimize. Current algorithms have very slow convergence, potentially to the point of being impractical~\citep{ro2021communication}. This leads to the central question of our work:
\begin{center}
\parbox{0.9\textwidth}{\emph{Can we design federated optimization techniques for the DRO problem with convergence rates that match their average objective counterparts?}}
\vspace{-0.1in}
\end{center}



% Figure environment removed

\subsection{Our Contributions}
We summarize our contributions below.
\vspace{-0.1in}
\paragraph{Framework.} We present a general formulation for the cross-silo federated DRO problem:
\begin{equation}\label{eq:dro-def}
    \min_{\bx} \max_{\blambda \in \Lambda} \left\{ F(\bx, \blambda) := \sum_{i=1}^N\lambda_i\cdot f_{i}(\bx) - \psi(\blambda)\right\},
\end{equation}
where $f_i(\bx)$ is the loss suffered by client $i$. Instead of minimizing a simple average of the client losses, equation \eqref{eq:dro-def} incorporates weights using $\blambda \in \R^N$. The choice of $\blambda$ is made in a \emph{worst-case} manner, while being subject to the constraint set $\Lambda$ and regularized with $\psi(\blambda)$. As we will show, this formulation is a generalization of several specific fair objectives that have been proposed in the federated learning literature~\citep{mohri2019agnostic,li2019fair,li2020tilted,zhang2022proportional,pillutla2021federated}.

\vspace{-0.1in}
\paragraph{Algorithm.} The objective defined in equation \eqref{eq:dro-def} is a min-max problem and can be directly optimized using well-established algorithms such as gradient descent ascent (GDA). However, such approaches ignore the unique structure of our formulation, particularly the linearity of the interaction term between $\blambda$ and $\bx$. We leverage this to design an accelerated primal-dual (APD) algorithm~\citep{hamedani2021primal}. Additionally, we propose to use control variates (\`a~la {\sc Scaffold}) to correct the bias caused by local steps, making optimal use of local client computation \citep{karimireddy2020scaffold}. Our proposed method, {\algname}, combines these ideas to provide an efficient and practical algorithm, compatible with secure aggregation.

\vspace{-0.1in}
\paragraph{Convergence.} We provide strong convergence guarantees for {\algname} when ${f_i}$ are strongly convex. If $\psi(\blambda)$ is a generic convex function, we achieve an {accelerated} $O\left( {1}/{T^2} \right)$ rate of convergence. Furthermore, if $\psi$ is strongly convex, {\algname} converges linearly at a rate of $\exp\left(-O(T)\right)$. This represents the first federated approach for the DRO problem that achieves \emph{linear} convergence, let alone an \emph{accelerated} rate.
Finally, we extend our analysis to the stochastic setting, where we obtain an optimal rate of $O\left( {1}/{T} \right)$, and improve over the previous $O(1/\sqrt{T})$ rate. Thus, we show that the sample complexity as well as the communication complexity for the DRO problem matches that of the easier average objective.


\paragraph{Practical Evaluation.} We conducted comprehensive simulations and demonstrate accelerated convergence, robustness to data heterogeneity, and the ability to leverage local computations.

For deep learning models, we avail ourselves of a two-stage Train-Convexify-Train method~\citep{yu2022tct}. First, we train a deep learning model using conventional federated learning methods, such as FedAvg. Then, we apply {\algname} to fine tune a convex approximation. To evaluate our algorithms, we use several real-world datasets with various distributionally robust objectives, and we study the trade-off between the mean and tail accuracy of these methods.











