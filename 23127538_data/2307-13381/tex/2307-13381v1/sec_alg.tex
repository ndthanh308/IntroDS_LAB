\section{{\algname}: Accelerated Primal-Dual Federated Algorithm with Bias Corrected Local Steps }\label{sec:alg}

In this section, we describe our proposed algorithm {\algname} (Stochastic Controlled Averaging with Primal-Dual updates) for solving the 
federated DRO problem \eqref{eq:dro-def}. 
We present the pseudo-code for {\algname} in Algorithm~\ref{Algorithm:ScaffoldAPD} and algorithm used  for local updates in Algorithm~\ref{Algorithm:local-ScaffoldAPD}.

\vspace{-0.1in}
\begin{algorithm}[ht]
\caption{{\algname}($\bx^{0}, \blambda^{0}$)}\label{Algorithm:ScaffoldAPD}
\begin{algorithmic}
% \STATE \textbf{Input:} ${\bx}^{0}, \blambda^{0}$.
\FOR{$r = 1, 2, \ldots, R$}
    \STATE { \texttt{\# (1).\,Collect gradient and loss vector}}
    \STATE Set parameters $\{\tau_{r}, \sigma_{r},  \gamma_{r}, \theta_{r}\}$
    \FOR{$i = 1, 2, \ldots, N$}
    \STATE $L_i^{r} = f_i(\bx^r)$, \,\,$\bc_i^{r} = g_i(\bx^r)$, \,\,\text{Communicate $(L_i^{r}, \bc_i^{r})$ to center}
    \ENDFOR
    \STATE { \texttt{\# (2).\,Update dual $\blambda$}}
    \STATE {
    {
    \begin{small}
    \begin{equation}\label{eq:alg-update-dual}
    \begin{aligned}
    \bs^r &= (1+\theta_{r}) \nabla_{\blambda}\Phi(\bx^{r}, \blambda^{r})  - \theta_{r}\nabla_{\blambda}\Phi(\bx^{r-1}, \blambda^{r-1})\\
    \blambda^{r+1} &= \text{argmin}_{\blambda \in \Lambda}\left\{\psi(\blambda)-\langle\bs^{r}, \blambda\rangle + \frac{1}{\sigma_r}{\rD}(\blambda, \blambda^{r})\right\}
    \end{aligned}
    \end{equation}
    \end{small}
    }
    }
    \STATE {\texttt{\# (3).\,Update primal $\bx$}}
    \STATE $\bc^r = \sum_{i=1}^{N}{\lambda_i^{r+1}}\bc_i^{r}$, \,\, \text{Communicate $\bc^r$ to each client}
    \FOR{$i = 1, 2, \ldots, N$}
    \STATE {$\Delta\bu_i^r \leftarrow$ {\sc Local-update}($\bx^{r}, \bc_i^{r}, \bc^{r}$)}, \,\, \text{Communicate $\Delta\bu_{i}^{r}$ to the center}
    \ENDFOR
    \STATE {Aggregate updates from different client via the weight vector $\blambda^{r+1}$}
    \begin{small}
    \begin{equation}\label{eq:alg-update-primal}
    \begin{aligned}
    \bx^{r+1} = \text{argmin}_{\bx}\Bigg\{\big\langle \sum_{i=1}^{N}\lambda_i^{r+1}\Delta\bu^{r}_i, \bx\big\rangle + \frac{1}{\tau_r}\mathrm{D}(\bx, \bx^{r})\Bigg\}
    \end{aligned}
    \end{equation}
    \end{small}
\ENDFOR
\STATE \textbf{Return:} $(\bx^{R+1}$, $\blambda^{R+1})$
\end{algorithmic}
\end{algorithm}

\vspace{0.1in}
As described in Algorithm~\ref{Algorithm:ScaffoldAPD}, {\algname} comprises three main steps that are executed at each communication round $r$: 
(1). Collecting  loss vector $[L_1^{r}, \dots, L_N^{r}]^{\top}$ and gradients $\{g_i(\bx^{r})\}_{i=1}^{N}$ (for bias correction); 
(2). Update to the dual variable  by Eq.~\eqref{eq:alg-update-dual}; 
(3). Local updates to each client model, and aggregating the updates by using the updated dual variable, i.e., Eq.~\eqref{eq:alg-update-dual}. We provide the pseudo-code for local updates in Algorithm~\ref{Algorithm:local-ScaffoldAPD}.



\begin{algorithm}[ht]
\caption{{\sc Local-update}$(\bx, \bc_i, \bc)$}\label{Algorithm:local-ScaffoldAPD}
\begin{algorithmic}
\STATE \textbf{Input:} optimization parameters $(\eta_\ell, J)$, model parameters $(\bc_i, \bc$, $\bx)$
    \STATE $\bu_{i, 0} = {\bx}$
    \FOR{$j = 1, 2, \ldots, J$}
    \STATE ${\bu_{i, j} = \bu_{i, j-1} -  \eta_{\ell}\cdot\left(g_i(\bu_{i, j-1})   - \bc_i + \bc \right)} $
    \ENDFOR
    \STATE $\Delta\bu_{i} = (\bx - \bu_{i, J})/(\eta_{\ell}J)$
\STATE \textbf{Return:} $\Delta\bu_{i}$
\end{algorithmic}
\end{algorithm}

\vspace{0.05in}
\textbf{Extrapolated Dual Update.}
Based on the computed loss vector $\nabla_{\blambda}\Phi(\bx^{r}, \blambda^{r}) = [L_1^{r}, \dots, L_N^{r}]^{\top}$ in the first step, we update the weight vector $\blambda$. Importantly, when $\theta_r > 0$, we use both the dual gradient from the current 
round ($\nabla_{\blambda}\Phi(\bx^{r}, \blambda^{r})$) as well as the past round ($\nabla_{\blambda}\Phi(\bx^{r-1}, \blambda^{r-1})$) to obtain the extrapolated gradient $\bs^{r}$. The gradient extrapolation step is widely used in  primal-dual hybrid gradient (PDHG) methods~\citep{chambolle2016ergodic} for solving convex-concave saddle-point problems, and it provides the key component in our algorithm for achieving acceleration. 
The extrapolation step used in Eq.~\eqref{eq:alg-update-dual} is to Nesterovâ€™s acceleration~\citep{nesterov2003introductory}, which can lead to faster convergence rate and has been widely utilized for achieving acceleration in solving various optimization problems.~\citep{chambolle2011first, chambolle2016ergodic, zhang2015stochastic, hamedani2021primal}. 

\vspace{0.05in}
\textbf{Local Steps and Control Variates $\bc_i$.} 
Supposing that communication is not a limiting factor, each client can compute its local gradient and transmit it to the server without any local steps. In this case, the update to the primal variable $\bx$ becomes
\vspace{-0.1in}
\begin{equation}\label{eq:update-x-central-case}
    \Delta \bu_i^{r} = g_i(\bx^{r}), \quad \text{argmin}_{\bx}\Big\{\langle \sum_{i=1}^{N}\lambda_i^{r+1}g_i(\bx^{r}), \bx\rangle + \frac{1}{\tau_r}\mathrm{D}(\bx, \bx^{r})\Big\}.
\end{equation}
This update performs the primal update with the unbiased gradient $\nabla_{\bx}F(\bx^{r}, \blambda^{r+1})$, which is equivalent to the standard primal update in primal-dual-based algorithms~\citep{chambolle2016ergodic,hamedani2021primal,zhang2022sapd}. 
However, such an update does not effectively utilize the local computational resources available on each client. Hence, we would like to perform multiple local update steps. The catch is that performing multiple local steps is known to lead to biased updates and ``client-drift''~\citep{karimireddy2020scaffold,woodworth2020minibatch,wang2020tackling}. We explicitly correct for this bias using control variates $\{\bc_{i}\}_{i\in [N]}$ similar to {\sc Scaffold}. 
As we will demonstrate in the subsequent theoretical analysis, this correction allows {\algname} to converge to the saddle-point solution of the DRO problem regardless of the data heterogeneity.


\vspace{0.05in}
While we use local updates on the primal variable, we do not perform any on the dual variable. This is unlike general federated min-max optimization algorithms~\citep{hou2021efficient, beznosikov2022decentralized}.
This design aligns well with the federated DRO formulation  since it is impractical for each client to update the weight vector at each local step due to their lack of knowledge regarding the loss values of other clients. 
The aggregation of {\algname} on the server resembles federated algorithms used for solving minimization problems, with the key difference being the utilization of the updated weight vector for primal aggregation.






