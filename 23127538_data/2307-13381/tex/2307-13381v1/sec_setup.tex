\vspace{-0.05in}
\section{Problem Setup}
We consider the min-max optimization problem  in the context of federated learning, where the objective function, defined in Eq.~\eqref{eq:dro-def}, is distributed among $N$ clients. Each $f_i: \R^{d}\rightarrow\R$ is the local function on the $i$-th client, where $f_i(\bx) = \E_{\xi \sim \mathcal{D}_i}[f(\bx, \xi)]$ and $\mathcal{D}_i$ is the data distribution of the $i$-th client. For example, we can define $\mathcal{D}_i$ as the uniform distribution over the training dataset present on the $i$-th client.

\vspace{0.05in}
\textbf{Notation.} We use the notation $\bx^{r} \in \R^{d}$ to denote the global iterate at the $r$-th round, and use $\bu_{i,j}^{r} \in \R^{d}$ to denote the local iterate at the $j$-th step on the $i$-th client (at the $r$-th round).
We apply $\blambda = [\lambda_1, \dots, \lambda_N]^{\top} \in \R^{N}$ to denote the weight vector, where $\lambda_i$ is the weight for client $i$. 
We let $[N]$ denote the set $\{1, \dots, N\}$. 
To facilitate clarity and presentation, we let 
\begin{equation}
\Phi(\bx, \blambda)=\sum_{i=1}^N\lambda_i\cdot f_{i}(\bx).
\end{equation} 
iFor local gradients, we let $g_i(\bu_{i,j-1})$ denote the stochastic gradient of $f_i$ at iterate $\bu_{i,j-1}$:
\begin{equation}\label{eq:local-gradient-def}
    g_i(\bu^{r}_{i,j-1}) = \nabla f_i (\bu^{r}_{i,j-1}, \xi^{r}_{i, j-1}).
\end{equation}

% \vspace{-0.1in}
\textbf{Choosing $\psi$ and $\Lambda$.}
We let $\psi: \R^{N} \rightarrow \R$ denote the regularization on the weight vector $\blambda$. 
The $\chi^{2}$ penalty~\citep{levy2020large} involves setting 
\begin{equation}\label{eq:psi-function-def}
    \psi(\blambda) = \mathrm{D}_{\chi^{2}}(\blambda) = \frac{\rho}{2N}\sum_{i=1}^{N}(N\lambda_i - 1)^{2}\text{, and } \Lambda = \Delta^N\,.
\end{equation}
When regularization is set to zero with $\rho =0$, the DRO formulation \eqref{eq:dro-def} recovers the agnostic federated learning (AFL) of~\citet{mohri2019agnostic}. A non-zero value of $\rho$ can be used to trade off the worst-case loss against the average loss. In particular, setting $\rho \rightarrow \infty$ recovers the standard average FL objective. While we will primarily focus on~\eqref{eq:psi-function-def} in this work, other choices are also possible. The DRO objective becomes the $\alpha$-Conditional Value at Risk (CVaR) loss~\citep{duchi2021learning}, also known as super-quantile loss~\citep{pillutla2021federated} by setting
\[
\psi(\blambda) =0\text{, and } \Lambda = \{\blambda \in \Delta, \lambda_i \leq 1/(\alpha N)\}\,.
\]
Finally, we can recover the Q-FL loss of~\citet{li2019fair} by setting 
\[
\psi(\blambda) = \|\blambda\|^{1 + \tfrac{1}{q}}\text{, and } \Lambda = \R^N \,.
\]




\vspace{-0.1in}
\textbf{Definitions and assumptions.} 
In the convergence analysis of our proposed algorithms, we rely on the following definitions and assumptions regarding the local functions and the regularization term $\psi$:
% \vspace{-0.2in}
\begin{definition}[Smoothness]\label{definition:f-smooth}
    $f(\cdot)$ is convex and differentiable, and there exists $L \geq 0$ such that for any $\bx_1, \bx_2$ in the domain of $f_i(\cdot)$, 
    \begin{equation}
        \|\nabla f_i(\bx_1) - \nabla f_i(\bx_2)\| \leq L\|\bx_1 - \bx_2\|.
    \end{equation}
\end{definition}

\vspace{-0.1in}
\begin{definition}[Strong convexity]\label{definition:f-strong-convex}
    $f(\cdot)$ is $\mu$-strongly convex, i.e., 
    \begin{equation}
        f(\bx_2) \geq f(\bx_1) + \langle \nabla f(\bx_1), \bx_2 - \bx_1 \rangle + \frac{\mu}{2}\|\bx_2 - \bx_1\|^{2}.
    \end{equation}
\end{definition}


\begin{assumption}[Smoothness w.r.t. $\Phi$]\label{assumption:L_yx-smooth}
    $\Phi(\bx, \cdot)$ is concave and differentiable, and there exists $L_{\blambda\bx} \geq 0$ such that for any $\bx_1, \bx_2$ in the domain of $\Phi(\cdot, \blambda)$ and $\blambda_1, \blambda_2$ in the domain of $\Phi(\bx, \cdot)$, 
    \begin{equation}
        \|\nabla_{\blambda}\Phi(\bx_1, \blambda_1) - \nabla_{\blambda}\Phi(\bx_2, \blambda_2)\| \leq L_{\blambda\bx}\|\bx_1 - \bx_2\|.
    \end{equation}
\end{assumption}


\begin{assumption}[Bounded noise]\label{assumption:local-noise}
There exist $\zeta \geq 0$ such that for all $i\in[N]$, the local gradient $g_i(\bx)$ defined in Eq.~\eqref{eq:local-gradient-def} satisfies 
    \begin{equation}
        \E\left[\|g_i(\bx) - \nabla f_i(\bx)\|^{2}\right] \leq \zeta^{2}, \quad \E\left[g_i(\bx)\right] = \nabla f_i(\bx).
    \end{equation}
\end{assumption}