
\title{Supplementary Material for ``An Explainable Geometric-Weighted Graph Attention Network for Identifying Functional Networks Associated with Gait Impairment"}
 \titlerunning{Supplementary Material for xGW-GAT}
\author{}
\institute{}
\maketitle    
\vspace{-10ex}
\section*{Riemmanian Metrics}
The Riemannian metric is a geometric structure that assigns a positive-definite inner product to each tangent space of a smooth manifold. This allows us to define notions of length, angle, and curvature on the manifold. Let $\mathcal{M}$ be a smooth manifold, the Riemannian metric on $\mathcal{M}$ is a smoothly varying family of inner products $g_p$ on the tangent spaces $\mathbf{T}_p\mathcal{M}$, for each point $p \in \mathcal{M}$.
\\
\noindent \textbf{Affine Invariant Riemannian Metric (AIRM)}: AIRM\footnote{Pennec, X., Fillard, P. and Ayache, N.: A Riemannian framework for tensor computing. International Journal of computer vision, 66, pp.41-66. (2006)} is an intrinsic Riemannian metric that characterizes the geometry of a symmetric positive definite (SPD) space by returning a number signifying the geodesic distance between two elements in tangent space. Given two SPD matrices $\mathbf{P}$ and $\mathbf{Q}$, the AIRM distance is defined as:
\begin{equation*}
    d_{\text{AIRM}}(\mathbf{P}, \mathbf{Q}) = \sqrt{\sum_{i=1}^{n} \log^2 \lambda_i}
\end{equation*}
where $\lambda_i$ are the eigenvalues of $\mathbf{P}^{-1}\mathbf{Q}$. AIRM is invariant to affine transformations, which makes it robust in many applications, and is strictly bound by innate geometric conditions.
\\
\noindent \textbf{Log-Euclidean Riemannian Metric (LERM)}: LERM\footnote{Arsigny, V., Fillard, P., Pennec, X., Ayache, N.: Geometric means in a novel vector space structure on symmetric positive-definite matrices. SIAM journal on matrix analysis and applications 29(1), 328â€“347 (2007)} is an extrinsic, closed-form formula for the Riemannian mean and is used to measure the geometric difference between matrices in a Riemannian manifold. Given two SPD matrices $\mathbf{P}$ and $\mathbf{Q}$, the LERM distance is defined as:
\begin{equation*}
  d_{\text{LERM}}(\mathbf{P}, \mathbf{Q} = \|log(\mathbf{P}) - log(\mathbf{Q})\|^{2}_F
\end{equation*}
where $|\cdot|^{2}_F$ denotes the Frobenius norm. While not affine-invariant, LERM is particularly advantageous because it embeds points in SPD matrices into a Euclidean space, making them amenable to standard Euclidean distance computations while preserving geometric information and thus is more computationally efficient than affine-invariant metrics like AIRM. 
\\
\noindent \textbf{\emph{symmetrized} Kullback-Leibler Divergence Metric (sKLDM)}: sKLDM\footnote{Kullback, S. and Leibler, R.A.: On information and sufficiency. The annals of mathematical statistics, 22(1), pp.79-86. (1951)} is an extension of the asymmetric KL divergence metric (KLDM), which quantifies the dissimilarity between probability distributions on a Riemannian manifold while taking into account the symmetrical nature of their comparison. It is also known as Jeffreys divergence. Given two SPD matrices $\mathbf{P}$ and $\mathbf{Q}$, the KLDM geodesic distance is defined as:
\begin{equation*}
    d_{\text{KLDM}}(\mathbf{P}, \mathbf{Q}) = Tr(\mathbf{P}(log(\mathbf{P})- log(\mathbf{Q}))
\end{equation*}
where $Tr(\cdot)$ denotes the trace operator. The symmetrized function is as follows:
\begin{equation*}
  d_{\text{sKLDM}}(\mathbf{P}, \mathbf{Q}) = \frac{1}{2} \left( d_{\text{KLDM}}(\mathbf{P}, M) + d_{\text{KLDM}}(\mathbf{Q}, M) \right)
\end{equation*}
where $M$ is the average of the two distributions, i.e. $M = \frac{1}{2}(\mathbf{P}+\mathbf{Q})$.

\begin{table}[t]
\caption{Ablation study for Riemannian metrics: *Note that the LERM results are the same as our best, reported results in the main paper.}
\label{app_dmetrics}
 \begin{tabular}{ lcccc } 
        \toprule
        \textbf{Method} & \textbf{Pre} & \textbf{Rec} & $\mathbf{F_{1}}$ & \textbf{AUC} \\
        \midrule
        \textbf{xGW-GAT} (AIRM) & 0.70 & 0.67 & 0.61 & 0.67 \\
        \textbf{xGW-GAT} (sKLDM) & 0.55 & 0.45 & 0.49 & 0.51 \\
        \midrule 
        \rowcolor{Gray}
        \textbf{xGW-GAT} (LERM)* & \textbf{0.75} & \textbf{0.77} & \textbf{0.76} & \textbf{0.83}\\
        \bottomrule
    \end{tabular}
\end{table}

\section*{Sample Selection Node Centrality Measures}
For each training sample, we derive the following node features that encode node centrality measures, i.e., a node's importance or influence within the network, based on criteria such as the number, quality, and proximity of its connections.
\begin{itemize}
     \item \emph{Degree Centrality}: Degree centrality of a node $j$, denoted $C_D(j)$, is the count of its direct connections or edges, defined as: 
     \begin{equation*}C_D(j) = \text{deg}(j)
     \end{equation*}
     where $\text{deg}(j)$ is the degree of node $d$.
    \item \emph{Eigenvector Centrality}: Eigenvector centrality of a node $j$, denoted $C_E(j)$, measures its influence based on the quality of its connections, defined as:
    \begin{equation*}
        C_E(j) = \frac{1}{\lambda} \sum_{i \in N(j)} A_{ij} C_E(i)
    \end{equation*}
    where $A_{ij}$ is the adjacency matrix, $N(j)$ is the set of neighbors of $i$, and $\lambda$ is the largest eigenvalue.
    \item \emph{Closeness Centrality}: Closeness centrality of a node $v$, denoted $C_C(j)$, measures the inverse average shortest path length to all other nodes, defined as:
    \begin{equation*}
        C_C(j) = \frac{1}{\sum_{u \neq v} d(j,i)}
    \end{equation*}
    where $d(j,i)$ is the shortest path length from $j$ to $i$.
\end{itemize}
