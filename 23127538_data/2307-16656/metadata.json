{
  "title": "Differentially Private and Communication-Efficient Distributed Nonconvex Optimization Algorithms",
  "authors": [
    "Antai Xie",
    "Xinlei Yi",
    "Xiaofan Wang",
    "Ming Cao",
    "Xiaoqiang Ren"
  ],
  "submission_date": "2023-07-31T13:38:52+00:00",
  "revised_dates": [
    "2024-05-01T04:31:13+00:00"
  ],
  "abstract": "This paper studies the privacy-preserving distributed optimization problem under limited communication, where each agent aims to keep its cost function private while minimizing the sum of all agents' cost functions. To this end, we propose two differentially private distributed algorithms under compressed communication. We show that the proposed algorithms achieve sublinear convergence for smooth (possibly nonconvex) cost functions and linear convergence when the global cost function additionally satisfies the Polyak-Łojasiewicz condition, even for a general class of compressors with bounded relative compression error. Furthermore, we rigorously prove that the proposed algorithms ensure $ε$-differential privacy. Unlike methods in the literature, the analysis of privacy under the proposed algorithms do not rely on the specific forms of compressors. Simulations are presented to demonstrate the effectiveness of our proposed approach.",
  "categories": [
    "math.OC"
  ],
  "primary_category": "math.OC",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16656",
  "pdf_url": "https://arxiv.org/pdf/2307.16656v2",
  "comment": "51 pages",
  "num_versions": null,
  "size_before_bytes": 6894104,
  "size_after_bytes": 892231
}