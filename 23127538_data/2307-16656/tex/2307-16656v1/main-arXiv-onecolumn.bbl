% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{xu2017distributed}
Y.~Xu, T.~Han, K.~Cai, Z.~Lin, G.~Yan, and M.~Fu, ``A distributed algorithm for
  resource allocation over dynamic digraphs,'' \emph{IEEE Transactions on
  Signal Processing}, vol.~65, no.~10, pp. 2600--2612, 2017.

\bibitem{nedic2018distributed}
A.~Nedi{\'c} and J.~Liu, ``Distributed optimization for control,'' \emph{Annual
  Review of Control, Robotics, and Autonomous Systems}, vol.~1, pp. 77--103,
  2018.

\bibitem{li2020distributed}
X.~Li, X.~Yi, and L.~Xie, ``Distributed online optimization for multi-agent
  networks with coupled inequality constraints,'' \emph{IEEE Transactions on
  Automatic Control}, vol.~66, no.~8, pp. 3575--3591, 2020.

\bibitem{cattivelli2009diffusion}
F.~S. Cattivelli and A.~H. Sayed, ``Diffusion lms strategies for distributed
  estimation,'' \emph{IEEE transactions on signal processing}, vol.~58, no.~3,
  pp. 1035--1048, 2009.

\bibitem{nedic2009distributed}
A.~Nedic and A.~Ozdaglar, ``Distributed subgradient methods for multi-agent
  optimization,'' \emph{IEEE Transactions on Automatic Control}, vol.~54,
  no.~1, pp. 48--61, 2009.

\bibitem{xu2017convergence}
J.~Xu, S.~Zhu, Y.~C. Soh, and L.~Xie, ``Convergence of asynchronous distributed
  gradient methods over stochastic networks,'' \emph{IEEE Transactions on
  Automatic Control}, vol.~63, no.~2, pp. 434--448, 2017.

\bibitem{yuan2016convergence}
K.~Yuan, Q.~Ling, and W.~Yin, ``On the convergence of decentralized gradient
  descent,'' \emph{SIAM Journal on Optimization}, vol.~26, no.~3, pp.
  1835--1854, 2016.

\bibitem{qu2017harnessing}
G.~Qu and N.~Li, ``Harnessing smoothness to accelerate distributed
  optimization,'' \emph{IEEE Transactions on Control of Network Systems},
  vol.~5, no.~3, pp. 1245--1260, 2017.

\bibitem{shi2015extra}
W.~Shi, Q.~Ling, G.~Wu, and W.~Yin, ``{EXTRA}: An exact first-order algorithm
  for decentralized consensus optimization,'' \emph{SIAM Journal on
  Optimization}, vol.~25, no.~2, pp. 944--966, 2015.

\bibitem{varagnolo2015newton}
D.~Varagnolo, F.~Zanella, A.~Cenedese, G.~Pillonetto, and L.~Schenato,
  ``Newton-raphson consensus for distributed convex optimization,'' \emph{IEEE
  Transactions on Automatic Control}, vol.~61, no.~4, pp. 994--1009, 2015.

\bibitem{wei2013distributed}
E.~Wei, A.~Ozdaglar, and A.~Jadbabaie, ``A distributed newton method for
  network utility maximization--i: Algorithm,'' \emph{IEEE Transactions on
  Automatic Control}, vol.~58, no.~9, pp. 2162--2175, 2013.

\bibitem{bottou2018optimization}
L.~Bottou, F.~E. Curtis, and J.~Nocedal, ``Optimization methods for large-scale
  machine learning,'' \emph{SIAM review}, vol.~60, no.~2, pp. 223--311, 2018.

\bibitem{tychogiorgos2013non}
G.~Tychogiorgos, A.~Gkelias, and K.~K. Leung, ``A non-convex distributed
  optimization framework and its application to wireless ad-hoc networks,''
  \emph{IEEE Transactions on Wireless Communications}, vol.~12, no.~9, pp.
  4286--4296, 2013.

\bibitem{zeng2018nonconvex}
J.~Zeng and W.~Yin, ``On nonconvex decentralized gradient descent,'' \emph{IEEE
  Transactions on signal processing}, vol.~66, no.~11, pp. 2834--2848, 2018.

\bibitem{necoara2019linear}
I.~Necoara, Y.~Nesterov, and F.~Glineur, ``Linear convergence of first order
  methods for non-strongly convex optimization,'' \emph{Mathematical
  Programming}, vol. 175, pp. 69--107, 2019.

\bibitem{wai2017decentralized}
H.-T. Wai, J.~Lafond, A.~Scaglione, and E.~Moulines, ``Decentralized
  frank--wolfe algorithm for convex and nonconvex problems,'' \emph{IEEE
  Transactions on Automatic Control}, vol.~62, no.~11, pp. 5522--5537, 2017.

\bibitem{zhang2018admm}
C.~Zhang, M.~Ahmad, and Y.~Wang, ``Admm based privacy-preserving decentralized
  optimization,'' \emph{IEEE Transactions on Information Forensics and
  Security}, vol.~14, no.~3, pp. 565--580, 2018.

\bibitem{zhu2019deep}
L.~Zhu, Z.~Liu, and S.~Han, ``Deep leakage from gradients,'' in \emph{Advances
  in Neural Information Processing Systems}, 2019, pp. 14\,774--14\,784.

\bibitem{huang2015differentially}
Z.~Huang, S.~Mitra, and N.~Vaidya, ``Differentially private distributed
  optimization,'' in \emph{Proceedings of International Conference on
  Distributed Computing and Networking}, 2015, pp. 1--10.

\bibitem{zhu2018differentially}
J.~Zhu, C.~Xu, J.~Guan, and D.~O. Wu, ``Differentially private distributed
  online algorithms over time-varying directed networks,'' \emph{IEEE
  Transactions on Signal and Information Processing over Networks}, vol.~4,
  no.~1, pp. 4--17, 2018.

\bibitem{ding2021differentially}
T.~Ding, S.~Zhu, J.~He, C.~Chen, and X.~Guan, ``Differentially private
  distributed optimization via state and direction perturbation in multiagent
  systems,'' \emph{IEEE Transactions on Automatic Control}, vol.~67, no.~2, pp.
  722--737, 2021.

\bibitem{chen2023differentially}
X.~Chen, L.~Huang, L.~He, S.~Dey, and L.~Shi, ``A differentially private method
  for distributed optimization in directed networks via state decomposition,''
  \emph{IEEE Transactions on Control of Network Systems}, 2023.

\bibitem{dwork2008differential}
C.~Dwork, ``Differential privacy: A survey of results,'' in \emph{International
  Conference on Theory and Applications of Models of Computation}, 2008, pp.
  1--19.

\bibitem{mo2016privacy}
Y.~Mo and R.~M. Murray, ``Privacy preserving average consensus,'' \emph{IEEE
  Transactions on Automatic Control}, vol.~62, no.~2, pp. 753--765, 2016.

\bibitem{wang2019privacy}
Y.~Wang, ``Privacy-preserving average consensus via state decomposition,''
  \emph{IEEE Transactions on Automatic Control}, vol.~64, no.~11, pp.
  4711--4716, 2019.

\bibitem{he2018preserving}
J.~He, L.~Cai, and X.~Guan, ``Preserving data-privacy with added noises:
  Optimal estimation and privacy analysis,'' \emph{IEEE Transactions on
  Information Theory}, vol.~64, no.~8, pp. 5677--5690, 2018.

\bibitem{altafini2020system}
C.~Altafini, ``A system-theoretic framework for privacy preservation in
  continuous-time multiagent dynamics,'' \emph{Automatica}, vol. 122, p.
  109253, 2020.

\bibitem{lu2018privacy}
Y.~Lu and M.~Zhu, ``Privacy preserving distributed optimization using
  homomorphic encryption,'' \emph{Automatica}, vol.~96, pp. 314--325, 2018.

\bibitem{alistarh2017qsgd}
D.~Alistarh, D.~Grubic, J.~Li, R.~Tomioka, and M.~Vojnovic, ``{QSGD}:
  Communication-efficient {SGD} via gradient quantization and encoding,'' in
  \emph{Advances in Neural Information Processing Systems}, 2017, pp.
  1707--1718.

\bibitem{koloskova2019decentralized}
A.~Koloskova, T.~Lin, S.~U. Stich, and M.~Jaggi, ``Decentralized deep learning
  with arbitrary communication compression,'' in \emph{International Conference
  on Learning Representations}, 2020.

\bibitem{liao2022compressed}
Y.~Liao, Z.~Li, K.~Huang, and S.~Pu, ``A compressed gradient tracking method
  for decentralized optimization with linear convergence,'' \emph{IEEE
  Transactions on Automatic Control}, vol.~67, no.~10, pp. 1254--1261, 2022.

\bibitem{kajiyama2020linear}
Y.~Kajiyama, N.~Hayashi, and S.~Takai, ``Linear convergence of consensus-based
  quantized optimization for smooth and strongly convex cost functions,''
  \emph{IEEE Transactions on Automatic Control}, vol.~66, no.~3, pp.
  1254--1261, 2020.

\bibitem{xiong2021quantized}
Y.~Xiong, L.~Wu, K.~You, and L.~Xie, ``Quantized distributed gradient tracking
  algorithm with linear convergence in directed networks,'' \emph{arXiv
  preprint arXiv:2104.03649}, 2021.

\bibitem{reisizadeh2019robust}
A.~Reisizadeh, H.~Taheri, A.~Mokhtari, H.~Hassani, and R.~Pedarsani, ``Robust
  and communication-efficient collaborative learning,'' in \emph{Advances in
  Neural Information Processing Systems}, 2019, pp. 8386--â€“8397.

\bibitem{taheri2020quantized}
H.~Taheri, A.~Mokhtari, H.~Hassani, and R.~Pedarsani, ``Quantized decentralized
  stochastic learning over directed graphs,'' in \emph{International Conference
  on Machine Learning}, 2020, pp. 9324--9333.

\bibitem{yi2022communication}
X.~Yi, S.~Zhang, T.~Yang, T.~Chai, and K.~H. Johansson, ``Communication
  compression for distributed nonconvex optimization,'' \emph{IEEE Transactions
  on Automatic Control}, 2022.

\bibitem{agarwal2018cpsgd}
N.~Agarwal, A.~T. Suresh, F.~X.~X. Yu, S.~Kumar, and B.~McMahan, ``{cpSGD}:
  Communication-efficient and differentially-private distributed {SGD},'' in
  \emph{Advances in Neural Information Processing Systems}, vol.~31, 2018.

\bibitem{wang2022quantization}
Y.~Wang and T.~Ba{\c{s}}ar, ``Quantization enabled privacy protection in
  decentralized stochastic optimization,'' \emph{IEEE Transactions on Automatic
  Control}, 2022.

\bibitem{yang2019survey}
T.~Yang, X.~Yi, J.~Wu, Y.~Yuan, D.~Wu, Z.~Meng, Y.~Hong, H.~Wang, Z.~Lin, and
  K.~H. Johansson, ``A survey of distributed optimization,'' \emph{Annual
  Reviews in Control}, vol.~47, pp. 278--305, 2019.

\bibitem{liu2021linear}
X.~Liu and Y.~Li, ``Linear convergent decentralized optimization with
  compression,'' in \emph{International Conference on Learning
  Representations}, 2021.

\bibitem{reisizadeh2019exact}
A.~Reisizadeh, A.~Mokhtari, H.~Hassani, and R.~Pedarsani, ``An exact quantized
  decentralized gradient descent algorithm,'' \emph{IEEE Transactions on Signal
  Processing}, vol.~67, no.~19, pp. 4934--4947, 2019.

\bibitem{zhao2022beer}
H.~Zhao, B.~Li, Z.~Li, P.~Richt{\'a}rik, and Y.~Chi, ``Beer: Fast $ \mathcal{O}
  (1/t) $ rate for decentralized nonconvex optimization with communication
  compression,'' \emph{arXiv preprint arXiv:2201.13320}, 2022.

\bibitem{xie2023compressed}
A.~Xie, X.~Yi, X.~Wang, M.~Cao, and X.~Ren, ``Compressed differentially private
  distributed optimization with linear convergence,'' \emph{arXiv preprint
  arXiv:2304.01779}, 2023.

\bibitem{yi2021linear}
X.~Yi, S.~Zhang, T.~Yang, T.~Chai, and K.~H. Johansson, ``Linear convergence of
  first-and zeroth-order primal--dual algorithms for distributed nonconvex
  optimization,'' \emph{IEEE Transactions on Automatic Control}, vol.~67,
  no.~8, pp. 4194--4201, 2021.

\bibitem{beznosikov2020biased}
A.~Beznosikov, S.~Horv{\'a}th, P.~Richt{\'a}rik, and M.~Safaryan, ``On biased
  compression for distributed learning,'' \emph{arXiv preprint
  arXiv:2002.12410}, 2020.

\bibitem{antoniadis2011penalized}
A.~Antoniadis, I.~Gijbels, and M.~Nikolova, ``Penalized likelihood regression
  for generalized linear models with non-quadratic penalties.'' \emph{Annals of
  the Institute of Statistical Mathematics}, vol.~63, no.~3, 2011.

\bibitem{sun2019distributed}
H.~Sun and M.~Hong, ``Distributed non-convex first-order optimization and
  information processing: Lower complexity bounds and rate optimal
  algorithms,'' \emph{IEEE Transactions on Signal processing}, vol.~67, no.~22,
  pp. 5912--5928, 2019.

\bibitem{karimi2016linear}
H.~Karimi, J.~Nutini, and M.~Schmidt, ``Linear convergence of gradient and
  proximal-gradient methods under the polyak-{\l}ojasiewicz condition,'' in
  \emph{Joint European Conference on Machine Learning and Knowledge Discovery
  in Databases}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2016, pp.
  795--811.

\end{thebibliography}
