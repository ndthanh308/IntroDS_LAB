
\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate]{lipics-v2021}

\usepackage{mathtools}
\usepackage{tikz}
\usepackage{tipa}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}

%This is a template for producing LIPIcs articles. 
%See lipics-v2021-authors-guidelines.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"
%for enabling a two-column layout for the author/affilation part (only applicable for > 6 authors), use "authorcolumns"
%for producing a PDF according the PDF/A standard, add "pdfa"

% \pdfoutput=1 %uncomment to ensure pdflatex processing (mandatatory e.g. to submit to arXiv)
\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

% \EventEditors{Meena Mahajan and Friedrich Slivovsky}
% \EventNoEds{2}
% \EventLongTitle{26th International Conference on Theory and Applications of Satisfiability Testing (SAT 2023)}
% \EventShortTitle{SAT 2023}
% \EventAcronym{SAT}
% \EventYear{2023}
% \EventDate{July 4--8, 2023}
% \EventLocation{Alghero, Italy}
% \EventLogo{}
% \SeriesVolume{271}
% \ArticleNo{21}

\title{Even shorter proofs without new variables} %TODO Please add
\author{Adri\'an Rebola-Pardo}{Vienna University of Technology, Austria \and Johannes Kepler Universit\"at Linz, Austria}{adrian.rebola_pardo@jku.at}{https://orcid.org/0000-0001-9234-4377}{}
\authorrunning{A. Rebola-Pardo}
\Copyright{Adri\'an Rebola-Pardo}
\keywords{Interference, SAT solving, Unsatisfiability proofs, Unsatisfiable cores}
\ccsdesc{Hardware~Theorem proving and SAT solving}
\bibliographystyle{plainurl}

\funding{This work has been supported by the LIT AI Lab funded by the State of Upper Austria,
the LogiCS doctoral program W1255-N23 of the Austrian Science Fund (FWF),
the Vienna Science and Technology Fund (WWTF) through grants VRG11-005 and ICT15-103, and
Microsoft Research through its PhD Scholarship Programme.}
\acknowledgements{I would like to thank Georg Weissenbacher for the discussions on WSR,
as well as the anonymous reviewers who provided very useful comments.}
\nolinenumbers

%\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...
%\supplementdetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93, subcategory={Description, Subcategory}, swhid={Software Heritage Identifier}]{General Classification (e.g. Software, Dataset, Model, ...)}{URL to related version} %linktext, cite, and subcategory are optional

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

% \acknowledgements{I want to thank \dots}%optional

%\nolinenumbers %uncomment to disable line numbering



% %Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \EventEditors{John Q. Open and Joan R. Access}
% \EventNoEds{2}
% \EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
% \EventShortTitle{CVIT 2016}
% \EventAcronym{CVIT}
% \EventYear{2016}
% \EventDate{December 24--27, 2016}
% \EventLocation{Little Whinging, United Kingdom}
% \EventLogo{}
% \SeriesVolume{42}
% \ArticleNo{23}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\restr}[2]{{\left.\kern-\nulldelimiterspace#1\vphantom{\big|}\right|_{#2}}}
\newcommand{\Set}[1]{\left\{#1\right\}}
\newcommand{\Cla}[1]{\left[#1\right]}
\newcommand{\Cub}[1]{\left\langle#1\right\rangle}
\newcommand{\smodels}{\mathrel{\models_{\textrm{sat}}}}
\newcommand{\sequiv}{\mathrel{\equiv_{\textrm{sat}}}}
\newcommand{\comp}{\overline}
\newcommand{\mut}[2]{\nabla{#1}.\,{#2}}

\begin{document}

\maketitle

\begin{abstract}
Proof formats for SAT solvers have diversified over the last decade, enabling new features such as extended resolution-like capabilities,
very general extension-free rules, inclusion of proof hints, and pseudo-boolean reasoning. Interference-based methods
have been proven effective, and some theoretical work has been undertaken to better explain their limits and semantics. In this work,
we combine the subsumption redundancy notion from~\cite{BussT19} and the overwrite logic framework from~\cite{Rebola-PardoS18}.
Natural generalizations then become apparent, enabling even shorter proofs of the pigeonhole principle (compared to those from~\cite{HeuleKB17})
and smaller unsatisfiable core generation.
\end{abstract}

\section{Introduction}
\label{sec:intro}

The impressive recent improvements in SAT solving have come coupled with the need to ascertain their results.
While satisfiability results are straightforward to check, unsatisfiability results require massive
proofs, sometimes petabytes in size~\cite{HeuleKM16,Heule18}.
The search for proof systems that enable both easy proof generation and smaller proofs has yield many
achievements~\cite{GoldbergN03,Gelder12,WetzlerHH14,HeuleKB17,Rebola-PardoC18,AltmanningerP20,BussT19,GochtN21,BaekCH21}.

Modern proof systems rely on redundancy properties presenting a phenomenon
known as \emph{interference}~\cite{JarvisaloHB12, HeuleK17B, Rebola-PardoS18}.
Whereas traditional proof systems derive clauses that are implied by the premises,
interference-based proof systems merely require introduced clauses to be consistent with them.
Interference proofs preserve the existence of a model throughout the proof, rather than models themselves.
A somewhat counterintuitive semantics thus arises: introducing a clause
in an interference-based proof system does not only depend on the presence of some clauses,
but also on the absence of some other clauses~\cite{PhilippR17,Rebola-PardoS18}.

The most general interference-based proof system in the literature is known as DSR~\cite{BussT19}.
While its predecesor DPR had success in generating short proofs of the pigeonhole formula
without introducing new variables~\cite{HeuleKB17}, DSR did not seem to succeeded in improving this result,
despite being intuitively well-suited for it.

In this work, we analyze the semantics of DSR proofs extending previous work on DPR proofs~\cite{Rebola-PardoS18}.
We find similar results to that article; in particular, satisfiability-preserving DSR proofs
can be reinterpreted as more traditional, DAG-shaped, model-preserving proofs over
an extension of propositional logic with a \emph{mutation} operator.
Crucially, these DAG-shaped proofs remove the whole-formula dependence interference is characterized by,
enabling an easier analysis of the necessary conditions for
satisfiability-preservation.

This analysis hints at a generalization we call
\emph{weak substition redundancy} (WSR \textipa{[\textprimstress w\textsci z\textschwa\textrhoticity]}),
which allows shorter, more understandable, easier to generate, faster to check proofs.
We demonstrate this by giving an even shorter proof of the pigeonhole formula.
We also provide a couple of examples where smaller unsatisfiable cores can be generated during proof checking,
and fewer lemmas are required during proof generation.

\paragraph*{Interference-based proofs}

Much of proof generation and checking is still done in the same way as a couple decades ago, by
logging the sequence of \emph{learnt clauses} in CDCL checkers, sometimes together with antecedents, and checking those
clauses for simple entailment criteria such as \emph{reverse unit propagation}~(RUP)~\cite{GoldbergN03,ZhangM03}.
Other parts of the proof are generated using more advanced deduction techniques;
even their infrequent use can dramatically decrease the size of
generated proofs~\cite{HeuleHW13a,WetzlerHH14,KieslRH18,HeuleB18},
overcoming not only technical limitations in proof generation,
but also theoretical bounds~\cite{Haken85,Urquhart87,Urquhart99}.
Clause deletion information is also recorded in the proof, which is needed to reduce memory
footprint in checking~\cite{HeuleHW14}.

Much research has been invested on finding ever more powerful proof rules~\cite{JarvisaloHB12,HeuleKB17,BussT19}
that allow to succintly express inprocessing techniques such as
Gaussian elimination~\cite{SoosNC09,Soos10,PhilippR16,ChewH20,GochtN21} or
symmetry breaking~\cite{AloulRMS03,AloulSM06,HeuleHW15}.
These proof rules are collectively called \emph{interference-based rules},
since their derivation depends on the whole formula
rather than just on the presence of some specific clauses~\cite{JarvisaloHB12,HeuleK17B,PhilippR17,Rebola-PardoS18}.
One of the most general interference techniques is \emph{substitution redundancy} (SR), which allows a version of
reasoning without loss of generality~\cite{BussT19}; this technique has been recently lifted to
pseudo-Boolean reasoning with impressive results~\cite{GochtN21}.

\paragraph*{Substitution redundancy and the pigeonhole problem}

A previous version of SR, called \emph{propagation redundancy}~(PR)~\cite{HeuleKB17}, was successful
in achieving short proofs of the pigeonhole problem, known for having exponential proofs in resolution~\cite{Haken85}
and polynomial yet cumbersome proofs in extended resolution~\cite{Cook76}.
The proof from~\cite{HeuleKB17} can be understood in terms of reasoning without loss of
generality~\cite{Rebola-PardoS18}: it assumes that a given pigeon is in a given pigeonhole,
for otherwise we could swap pigeons around.

PR does not have a method to swap the values of variables;
rather, it can only conditionally set them to true or false.
Hence, linearly many reasoning steps are needed to just to achieve the swap.
SR, on the other hand, allows variable swaps, so one could expect that the clause expressing the result
of this swap would satisfy the SR property. Surprisingly, it does not;
in fact, the clause fails to satisfy a requirement that
in its PR version was almost trivial.

\paragraph*{Interference and logical dependency}

Interference-based proofs do not have a ``dependence'' or ``procedence'' structure:
since the ability to introduce a clause is contingent on the whole formula,
no notion of ``antecedents'' exists for SR and its predecessors.
This becomes a problem when computing unsatisfiable cores and trimmed proofs~\cite{NadelRS13};
it also has the potential
to harm the performance of proof checkers, since some techniques that allow skipping unnecessary steps
during proof checking are based on logical dependence~\cite{HeuleHW13}.

This also relates to an issue arising when generating proof fragments for inprocessing techniques.
Sometimes, a clause $C$ cannot be introduced as SR because some lemmas are needed;
the proof generator might know these lemmas and how to derive them.
However, because interference depends on the whole formula,
introducing the lemmas before $C$ can further constrain the requirements
for $C$ to be introduced, demanding yet more lemmas.

\paragraph*{Contributions}

Previous work showed that the semantics of PR can be expressed in terms of \emph{overwrite logic}~\cite{Rebola-PardoS18}.
Overwrite logic extends propositional logic with an \emph{overwrite operator}.
Within overwrite logic, DPR proofs can be regarded as DAG-shaped, model-preserving proofs;
PR introduction can then be shown to behave as reasoning without loss of generality.

In Section~\ref{sec:mutation} we provide an extension to the overwrite logic framework, called \emph{mutation logic},
which elucidates the semantics of DSR proofs. In particular,
model-preserving proofs within mutation logic mimicking satisfiability-preserving DSR proofs
can be extracted, as shown in Section~\ref{ssc:entailment}. This allows a clearer understanding of the SR redundancy rule,
which in turn makes some improvements over SR apparent.

By introducing minor modifications to the definition of SR, in Section~\ref{sec:extensions} we obtain a new,
more powerful redundancy rule called \emph{weak substitution redundancy}~(WSR).
WSR proofs are more succint than DSR proofs, which we demonstrate
by providing a shorter proof of the pigeonhole problem using only $O(n^2)$ clause introductions in Section~\ref{ssc:php}.

Furthermore, WSR enables finer-grained ways to reason about dependency in interference-based proofs.
This can yield shorter proof checking runtimes and smaller trimmed proofs and unsatisfiability cores
when SR clauses are used (Section~\ref{ssc:cores}), as well as easier proof generation techniques by providing
clearer separation for interference lemmas (Section~\ref{ssc:lemmas}).

\section{Preliminaries}
\label{sec:prelim}

Given a \emph{literal} $l$, we denote its \emph{complement} as $\overline l$.
We denote \emph{clauses} by juxtaposing its literals within square brackets,
i.e.\ we denote the clause $l_1 \vee l_2 \vee l_3$ as $\Cla{l_1 l_2 l_3}$.
We similarly denote conjunctions of literals, called \emph{cubes}, as juxtaposed
literals within angle brackets, e.g.\ $\Cub{l_1 l_2 l_3}$.
Crucially, we only consider clauses and cubes that do not contain complementary
literals, as most SAT solvers and proof checkers already make that assumption.
Equivalently, we disallow tautological clauses and unsatisfiable cubes.
We also define complementation for clauses and cubes, i.e.
$\comp{\Cla{l_1 \dots l_n}} = \Cub{\comp{l_1}\dots\comp{l_n}}$ and
$\comp{\Cub{l_1 \dots l_n}} = \Cla{\comp{l_1}\dots\comp{l_n}}$.
SAT solving typically operates over formulas in \emph{conjunctive normal form} (CNF),
which are conjunctions of clauses. Here we regard CNF formulas as finite sets of clauses.

An \emph{atom} is either a literal, or one of the symbols $\top$ or $\bot$ representing
the propositional constants true and false. Complementation is extended to atoms with
$\overline{\top} = \bot$ and $\overline{\bot} = \top$. We can then define the usual propositional
semantics as follows. A \emph{model} $I$ is a total map
from atoms to $\Set{\top, \bot}$ such that $I(\top) = \top$ and $\overline{I(l)} = I(\overline l)$ for all atoms $l$.

We say that $I$ \emph{satisfies} a literal $l$ (written $I \models l$) whenever
$I(l) = \top$. This definition is recursively extended in the usual way to clauses
(disjunctively), cubes and CNF formulas (conjunctively). Similarly, we use the
typical notions of \emph{entailment} (denoted ${\models}$), logical \emph{equivalence}
($\equiv$) and \emph{satisfiability}. We also say that a logical expression $\varphi$
\emph{satisfiability-entails} another expression $\psi$ (denoted $\varphi \smodels \psi$)
whenever, if $\varphi$ is satisfiable, then $\psi$ is satisfiable too. Similarly, $\varphi$
is \emph{satisfiability-equivalent} to $\psi$ (denoted $\varphi \sequiv \psi$) whenever
$\varphi$ and $\psi$ are either both satisfiable or both unsatisfiable (i.e.\ $\varphi \smodels \psi$ and $\psi \smodels \varphi$).

An \emph{atomic substitution} $\sigma$ is a total map from atoms to atoms
satisfying the following constraints:
\begin{romanenumerate}
    \item $\sigma(\top) = \top$.
    \item $\overline{\sigma(l)}$ = $\sigma(\overline l)$ for all atoms $l$.
    \item $\sigma(l) \neq l$ only for finitely many atoms $l$.
\end{romanenumerate}
This definition is essentially equivalent to the substitutions from \cite{BussT19}.
The form presented here makes it easier to compose atomic substitutions with other atomic
substitutions, i.e.\ $(\sigma \circ \tau)(l) = \sigma(\tau(l))$,
and with models, i.e.\ $(I \circ \sigma)(l) = I(\sigma(l))$; the latter is a model
that satisfies a given logical expression $\varphi$ iff $I$ satisfies the expression
resulting from applying the substitution $\sigma$ to $\varphi$.

Note that atomic substitutions have a finite representation: only finitely
many literals are mapped to atoms other than themselves, and
giving the mapping for one polarity fixes the mapping for the other polarity.
Hence, one can represent a substitution as a set of mappings
$\Set{x_1 \mapsto l_1,\dots,x_n \mapsto l_n}$ where the $x_i$ are pairwise distinct
variables, the $l_i$ are atoms, and any variable other than the $x_i$ is mapped to itself.

Our restriction that clauses must be non-tautological is somewhat at odds
with the concept of substitutions. An atomic substitution $\sigma$ \emph{trivializes}
a clause $C$ if either:
\begin{alphaenumerate}
    \item there is a literal $l \in C$ with $\sigma(l) = \top$.
    \item there are two literals $l, k \in C$ with $\sigma(l) = \overline{\sigma(k)}$.
\end{alphaenumerate}
Applying $\sigma$ to $C$ yields a tautology whenever $\sigma$ trivializes $C$, and a
(non-tautological) clause otherwise.
Then we can define the \emph{reduct} of a clause $C$ or a CNF formula $F$ by an atomic
substitution $\sigma$ as:
\begin{align*}
    \restr{C}{\sigma} = {} & \Cla{\sigma(l) \mid l \in C \text{ and } \sigma(l) \neq \bot} \text{, \quad if $\sigma$ does not trivialize $C$} \\
    \restr{F}{\sigma} = {} & \Set{\restr{C}{\sigma} \mid C \in F \text{ and $\sigma$ does not trivialize C}}
\end{align*}

\begin{lemma}
\label{lem:reduct}
    Let $C$ be a clause, $F$ be a CNF formula, and $\sigma$ be an atomic substitution.
    The following then hold:
    \begin{romanenumerate}
        \item \label{itm:reduct:trivial}
        $\sigma$ trivializes $C$ if and only if $I \circ \sigma \models C$
        for all models $I$.
        \item \label{itm:reduct:clause}
        If $\sigma$ does not trivialize $C$, then
        $I \circ \sigma \models C$ if and only if $I \models \restr{C}{\sigma}$
        for all models $I$.
        \item \label{itm:reduct:cnf}
        $I \circ \sigma \models F$ if and only if
        $I \models \restr{F}{\sigma}$ for all models $I$.
    \end{romanenumerate}
\end{lemma}
\begin{proof}
    Let us first show~(\ref{itm:reduct:clause}). First, observe that $I$ satisfies
    $\restr{C}{\sigma}$ if and only if $I$ satisfies $\sigma(l)$ for some literal $l \in C$.
    But this is equivalent to $(I \circ \sigma)(l) = \top$
    for some $l \in C$, which is precisely $I \circ \sigma \models C$.

    We now show~(\ref{itm:reduct:trivial}). The ``only if'' implication is straightforward
    from the definition of a trivializing substitution. For the ``if'' implication,
    we show that if $\sigma$ does not trivialize $C$, then $I \circ \sigma$ falsifies $C$
    for some model $I$. Claim~(\ref{itm:reduct:clause}) gives out that any model $I$ falsifying
    $\restr{C}{\sigma}$, which exists because it is a (non-tautological) clause, has this property.

    Claim~(\ref{itm:reduct:cnf}) then follows easily from claims~(\ref{itm:reduct:trivial})
    and~(\ref{itm:reduct:clause}).
\end{proof}

Note that, for atomic substitutions that only map variables to the constants $\top$ or $\bot$,
there exists a correspondence with cubes. In particular, given variables $x_1,\dots,x_n,y_1,\dots,y_m$,
the cube $Q$ is bijectively associated to the atomic substitution $Q^\star$ where:
\begin{align*}
    Q = {} & \Cub{x_1 \dots x_n \, \comp{y_1} \dots \comp{y_m}} &
    Q^\star = {} & \Set{x_1 \mapsto \top, \dots, x_n \mapsto \top, y_1 \mapsto \bot, \dots, y_m \mapsto \bot}
\end{align*}

\subsection{Interference-based redundancy notions}
\label{ssc:interference}

Throughout the last decade, several redundancy notions collectively called
\emph{interference-based rules} have appeared in the literature~\cite{JarvisaloHB12,HeuleKB17,HeuleK17B,BussT19}.
Originating from clause elimination techniques~\cite{JarvisaloBH10,JarvisaloBH12,KieslSTB18}, interference can be also used to introduce
clauses in the formula; unlike more classical techniques, though, these clauses
do not need to be implied by the formula, but rather \emph{consistent} with it.
Specifically, given a CNF formula $F$, introducing a clause $C$ through interference
requires that $F \sequiv F \cup \Set{C}$.

Many interference-based rules are based on a criterion for entailment called
\emph{reverse unit propagation} (RUP)~\cite{GoldbergN03}. A clause $C$ is called a \emph{RUP clause} over
a CNF formula $F$ whenever unit propagation applied to $F$ using the assumption literals
$\comp C$ yields a conflict; under these circumstances, it can be shown that $F \models C$.

RUP clauses can be characterized in terms of resolution proofs. In particular,
a clause $C$ is a RUP clause over $F$ if and only if $C$ can be derived from $F$ through a
derivation of a particular form, called a \emph{subsumption-merge chain}~\cite{PhilippR17}.
These are derivations as shown in Figure~\ref{fig:smchain}, starting with a subsumption inference
and followed by a number of \emph{resolution merges}, also known as \emph{self-subsuming resolutions}~\cite{EenB05}.
The specifics of subsumption-merge chains in relation to RUPs are not quite relevant for
our discussion; we direct the interested reader to~\cite{PhilippR17,Rebola-PardoW20}.
For us, it suffices to know that checking whether $C$ is a RUP clause over $F$ is essentially
the same as finding the subsumption-merge chain that derives $C$ from $F$~\cite{ZhangM03}.

% Figure environment removed

Building on RUP clauses, many redundancy notions can be defined. The most relevant for our discussion
are, in increasing generality order, \emph{resolution-asymmetric tautologies} (RATs),
\emph{propagation redundancies} (PRs) and \emph{substitution-redundancies} (SRs):

\begin{definition}
\label{def:redundancy}
    Let $C$ be a clause and $F$ be a CNF formula.
    \begin{romanenumerate}
        \item We say $C$ is a RAT clause~\cite{JarvisaloHB12} over $F$ upon a literal $l$
        whenever $l \in C$ and, for every clause $D \in F$ with $\comp l \in D$, the
        expression $C \vee D \setminus \Set{\vphantom{l}\smash{\comp l}}$ is either a tautology or a RUP
        clause over $F$.
        \item We say $C$ is a PR clause~\cite{HeuleKB17} over $F$ upon a cube $Q$ whenever
        $Q \models C$ (i.e.\ $Q \cap C \neq \emptyset$) and each clause in $\restr{F}{Q^\star}$ is a RUP clause over
        $\restr{F}{{\comp C}^\star}$.
        \item We say $C$ is a SR clause~\cite{BussT19} over $F$ upon an atomic substitution
        $\sigma$ whenever $\sigma$ trivializes $C$ and each clause in $\restr{F}{\sigma}$
        is a RUP clause over $\restr{F}{{\comp C}^\star}$.
    \end{romanenumerate}
\end{definition}

For a given \emph{witness} (i.e.\ the literal $l$, the cube $Q$ or the substitution $\sigma$),
checking whether a clause $C$ is a RAT/PR/SR clause over $F$ upon the corresponding witness
is polynomial over the size of $F$. In particular, this check takes at most one RUP check for each
clause~\cite{BussT19}; and RUP checking is quadratic on the size of $F$~\cite{Gelder12}.
Finding the right witness is nevertheless NP-complete~\cite{HeuleKB17}.
These redundancy notions satisfy the general condition for interference:

\begin{theorem}
    Let $C$ be a clause and $F$ be a CNF formula, and assume either of the following:
    \begin{alphaenumerate}
        \item $C$ is a RAT clause over $F$ upon a literal $l$ \cite{JarvisaloHB12}.
        \item $C$ is a PR clause over $F$ upon some cube $Q$ \cite{HeuleKB17}.
        \item $C$ is an SR clause over $F$ upon some atomic substitution $\sigma$ \cite{BussT19}.
    \end{alphaenumerate}
    Then, $F \sequiv F \cup \Set{C}$.
\end{theorem}

In this paper we will mostly focus on substitution redundancy, which is the most general of them.
However, we will use an equivalent definition, as per~\cite[Lemma 5]{BussT19}: instead of the
condition that each clause in $\restr{F}{\sigma}$ is a RUP clause over $\restr{F}{{\comp C}^\star}$,
we require that, for each clause $D \in F$, either $\sigma$ trivializes $D$,
or $\comp C \models \restr{D}{\sigma}$, or the clause $C \vee \restr{D}{\sigma}$ is a RUP clause
over $F$.

\subsection{Proof systems for SAT solving}

RUP clauses provided the first effective solution to the problem of certifying an unsatisfiability
result from a SAT solver. In particular, learnt clauses in a CDCL SAT solver~\cite{SilvaS96} are
RUP clauses~\cite{GoldbergN03, Gelder12}, so checking that each clause in the list of learnt clauses
is a RUP clause over the previously derived formula amounts to certifying that the last
clause in the list is entailed by the solved formula. If that clause is the empty clause,
the list constitutes a refutation.

However, the proof complexity of RUP proofs is rather poor:
there exist many simple problems whose refutations in resolution-based proof systems, such as RUP,
are exponential on the size of the refuted formula~\cite{Haken85,Urquhart87,Urquhart99}.
In fact, this problem extends to (purely) CDCL SAT solvers, on which these results impose
a performance upper bound~\cite{PipatsrisawatD11,BeameKS04}.

To alleviate the impact of these results, some inprocessing techniques were developed,
including reencoding of cardinality constraints~\cite{BiereBLM14,MantheyHB12}, Gaussian
elimination over $\mathbb{Z}_2$~\cite{SoosNC09,Soos10} and symmetry
breaking~\cite{AloulRMS03,AloulSM06}. Unfortunately, the aforementioned limitations
still apply to the generated refutation, so emitting a RUP proof would still
take exponential time.

Allowing interference-based reasoning in the proof led
to a vast number of proof formats~\cite{HeuleHW13a,WetzlerHH14,HeuleKB17,Cruz-FilipeMS17,Cruz-FilipeHHKS17,Lammich17,TanHM21,BussT19,BaekCH21}
and proof generation techniques~\cite{SinzB06,MantheyP14,HeuleHW15,PhilippR16,ChewH20,BryantH21,GochtN21,BryantBH22}.
The proof complexity of these systems is equivalent to that of
extended resolution~\cite{Tseitin1983,reckhow75_phd,KieslRH18,HeuleB18}, for which no
exponential lower bounds are known.

Unlike more traditional, DAG-shaped proofs, interference-based proofs take the
form of a list of \emph{clause introductions} and \emph{deletions}.
Starting with the input CNF formula $F$, clause introductions of the form $\textbf{i: }C$
add a clause $C$ to $F$, whereas clause deletions of the form $\textbf{d: }C$ remove
$C$ from $F$. At each point in the proof there is an \emph{accumulated formula}
where all the previous instructions in the proof have been applied.

Just as DAG-shaped proofs like resolution maintain a soundness invariant (i.e.\ each
model satisfying the premises of the proof also satisfies the conclusion),
interference-based proofs are \emph{satisfiability-preserving}~\cite{PhilippR17}:
at any point in an interference-based proof of $F$, the accumulated formula $G$
satisfies $F \smodels G$. This is guaranteed by imposing some conditions on
clause introductions; clause deletions do not have any requirements, because
deleting a clause is always satisfiability-preserving.

Different proof systems then arise from different conditions on clause introductions.
\emph{Delete Resolution Asymmetric Tautology} (DRAT) requires them to be either RUP clauses
or RAT clauses over the accumulated formula~\cite{HeuleHW13a, WetzlerHH14},
and similarly for \emph{Delete Propagation Redundancy}~(DPR)~\cite{HeuleKB17}
and \emph{Delete Substitution Redundancy}~(DSR)~\cite{BussT19}.
Note that, in the case of introducing a RAT/PR/SR clause (as opposed to a RUP clause),
the witness $\omega$ must be specified; in this case we denote it as $\textbf{i: }C,\,\omega$.

\subsection{Overwrite logic}
\label{ssc:overwrite}

Interference-based proofs represent a structural and semantic departure from traditional
proof systems. This is due to the \emph{non-monotonic} properties of SR: an SR clause
over $F$ upon~$\sigma$ is not necessarily an SR clause over a formula containing $F$.~\cite{JarvisaloHB12,PhilippR17}.

The consequences of non-monotonicity are far-reaching.
Interference-based proofs cannot be freely composed as, for example,
resolution proofs can~\cite{HeuleB15b}: the correctness of a clause introduction depends,
in principle, on the whole formula, which motivated the name ``interference'' as opposed
to ``inference''~\cite{HeuleK17B}.

DPR proofs can be seen as model-preserving, tree-shaped, monotonic proofs over a more general logic, known
as overwrite logic~\cite{Rebola-PardoS18}. There, a model $I$ can be \emph{conditionally overwritten}
with an \emph{overwrite rule} of the form $(Q \coloneq T)$, where $Q$ and $T$ are cubes.
Then, the model $I \circ (Q \coloneq T)$ is defined as $I \circ Q^\star$ if $I \models T$,
or as $I$ otherwise. That is, if $T$ is satisfied, then the minimal assignment satisfying $Q$
is overwritten on $I$.
Instead of clauses, overwrite logic deals with
\emph{overwrite clauses}, represented as $\mut{\varepsilon_1 \dots \varepsilon_n}{C}$,
where $C$ is a clause and the $\varepsilon_i = (Q_i \coloneq T_i)$ are overwrite rules.
Such an overwrite clause is satisfied by a model $I$ whenever
$I \circ \varepsilon_1 \circ \dots \circ \varepsilon_n \models C$.

This framework accurately expresses the reasoning performed by PR
introduction~\cite{Rebola-PardoS18}:
\begin{theorem}
    Let $C$ be a PR clause over a CNF formula $F$ upon a cube $Q$. Then, the implication
    $F \models \mut{(Q \coloneq \comp C)}{(F \cup \Set{C})}$ holds.
\end{theorem}
This result means that non-monotonic, satisfiability-preserving reasoning using PR clauses
can be turned into monotonic, model-preserving reasoning in overwrite logic.
\cite{Rebola-PardoS18} further introduces a traditional, DAG-shaped proof system over
overwrite clauses that mimics PR proofs, hence suggesting that the whole-formula dependence
featured by interference-based proof systems can, to some extent, be curbed.

\section{Mutation semantics for DSR proofs}
\label{sec:mutation}

The overwrite logic presented in Section~\ref{ssc:overwrite} was designed to formalize
the semantics of DPR proofs. In particular, models are overwritten with cubes, which act as
witnesses for PR clause introductions.
In order to extend this framework to DSR proofs, the role of cubes must now be fulfilled
by atomic substitutions. Here we introduce \emph{mutation logic},
which is a straightforward extension of overwrite logic.

In its most general form, a \emph{mutation rule} is an expression $(\sigma \coloneq \tau)$,
where $\sigma$ is an atomic substitution and $\tau$ is any logical expression that can be
evaluated under a model. We call $\tau$ the \emph{trigger} of the rule, and $\sigma$ its
\emph{effect}. Mutation rules themselves are not logical expressions and they cannot be
satisfied or falsified. They are instead intended to codify the idea ``if the trigger
$\tau$ is satisfied, then apply the effect substitution $\sigma$''.
We thus define the \emph{application} of a mutation rule $(\sigma \coloneq \tau)$ to a model
$I$ as:
\begin{equation*}
    I \circ (\sigma \coloneq \tau) = {}
    \begin{cases}
        I \circ \sigma & \text{if }I \models \tau \\
        I & \text{if }I \not\models \tau
    \end{cases}
\end{equation*}

As with overwrite logic, the main difference with propositional logic is the inclusion
of a mutation operator $\nabla$. As in~\cite{Rebola-PardoS18}, one can recursively
define mutation formulas as either propositional formulas, or expressions of the
form $\mut{(\sigma \coloneq \tau)}{\varphi}$ where $\sigma$ is an atomic substitution
and $\varphi$, $\tau$ are mutation formulas. The semantics of the mutation operator are
given by $I \models \mut{(\sigma \coloneq \tau)}{\varphi}$ whenever
$I \circ (\sigma \coloneq \tau) \models \varphi$. In other words: evaluating
$\mut{(\sigma \coloneq \tau)}{\varphi}$ corresponds to evaluating a formula $\varphi^\prime$
obtained from $\varphi$ by applying the effect $\sigma$ to $\varphi$
only if the trigger $\tau$ is satisfied.

This framework is very general, but just as discussed in~\cite{Rebola-PardoS18},
nothing meaningful is lost by introducing some strong restrictions. For the purpose of this paper,
we will only consider \emph{cubic} mutation rules of the form $(\sigma \coloneq Q)$ where $Q$ is a
propositional cube. The logical expressions we will use are of three kinds, where we use
$\mut{\vec{\varepsilon}}{\varphi}$ to denote a nested mutation
$\mut{\varepsilon_1}{{} \dots \mut{\varepsilon_n} \varphi}$ with cubic mutations $\varepsilon_i$:
\begin{itemize}
\item \emph{Mutation clauses} of the form $\mut{\vec{\varepsilon}}{C}$
where $C$ is a propositional clause.
\item \emph{Mutation CNF formulas} (MCNF), which are finite sets of mutation clauses.
The semantics of MCNF formulas are conjunctive, i.e.\ they are satisfied if every mutation
clause in them is satisfied.
\item \emph{Uniformly mutation CNF formulas} (UMCNF) of the form $\mut{\vec{\varepsilon}}{F}$
where $F$ is a propositional CNF formula. $\nabla$ distributes over the propositional
connectives, e.g.\ 
$\mut{\vec{\varepsilon}}{(\varphi_1 \wedge \varphi_2)} \equiv (\mut{\vec{\varepsilon}}{\varphi_1}) \wedge (\mut{\vec{\varepsilon}}{\varphi_2})$.
Hence, UMCNF can be embedded in the fragment of the MCNF formulas that contain clauses
with the same mutation prefix.
\end{itemize}

Similarly to how overwrite logic allows the expression of PR clauses as model-preserving
inferences under an overwrite~\cite{Rebola-PardoS18}, SR clauses become consequences
under a mutation.

\begin{theorem}
\label{thm:srsemantics}
    Let $F$ be a CNF formula and $C$ be an SR clause over $F$ upon an atomic
    mutation $\sigma$. Then, $F \models \mut{(\sigma \coloneq \comp C)}{(F \cup \Set{C})}$.
\end{theorem}
\begin{proof}
    Let $I$ be any model with $I \models F$. Our goal is to show that the model
    $I^\prime = I \circ (\sigma \coloneq \comp C)$ satisfies $F \cup \Set{C}$.
    If $I \models C$ holds, then $I^\prime = I$, which satisfies both $F$ and $C$.
    
    Let us now show the case with $I \not\models C$, where we have $I^\prime = I \circ \sigma$.
    First observe that, since $C$ is an SR clause upon $\sigma$, the clause $C$ is
    trivialized by $\sigma$. Lemma~\ref{lem:reduct} then shows $I^\prime \models C$.
    Now, consider any clause $D \in F$. By the definition of SR clauses, either $\sigma$
    trivializes $D$, or $\comp C \models \restr{D}{\sigma}$,
    or the clause $C \vee \restr{D}{\sigma}$ is a RUP clause over $F$.

    As above, the first case implies $I^\prime \models D$.
    For the second and third cases, it suffices to show $I \models \restr{D}{\sigma}$,
    since Lemma~\ref{lem:reduct} then proves $I^\prime \models D$.
    For the second case, this follows from $I \models \comp C$.
    For the third case, it follows from $I \models F$ and $I \not\models C$.
    We have thus shown that $I^\prime \models F \cup \Set{C}$ as we wanted.
\end{proof}

As for PR clauses in~\cite{Rebola-PardoS18}, one can read Theorem~\ref{thm:srsemantics} as
claiming that SR clause introduction (and in general, interference-based reasoning)
performs reasoning \emph{without loss of generality}. In particular:
$C$ can be assumed in $F$ because, were it not to hold in a given model of $F$,
a transformation, namely the one given by $\sigma$, could be applied to the variables
such that $F$ is still satisfied after the transformation, and $C$ becomes satisfied too.

\subsection{DSR proofs as model-preserving proofs}
\label{ssc:entailment}

The entailment in Theorem~\ref{thm:srsemantics} raises the question whether SR proofs
can be equivalently expressed as model-preserving, DAG-shaped proofs over the corresponding
mutated clauses. Following~\cite{Rebola-PardoS18}, we can define a proof system as shown in
Figure~\ref{fig:inferences}.

% Figure environment removed

\begin{theorem}
    The inference rules in Figure~\ref{fig:inferences} are sound, i.e.\ any model satisfying the premises of each
    rule satisfies its conclusion as well.
\end{theorem}
\begin{proof}
    The proofs for $\textsc{res}$ and $\textsc{sub}$ are straightforward, since the $\nabla$ operator
    preserves implications.

    For $\nabla\textsc{taut}$, consider any model $I$, and let $I^\prime = I \circ \vec{\varepsilon} \circ (\sigma \coloneq \comp C)$.
    If $I \circ \vec{\varepsilon} \models C$, then $I^\prime = I \circ \vec{\varepsilon}$, which satisfies $C$.
    Otherwise, $I^\prime = I \circ \vec{\varepsilon} \circ \sigma$, and since $\sigma$ trivializes $C$ we have $I^\prime \models C$.

    Let us now show $\nabla\textsc{elim}$ correct. Consider any model $I$ satisfying the premises, and call
    $I^\prime = I \circ \vec{\varepsilon} \circ (\sigma \coloneq \comp C)$, so that $I^\prime \models C$ and $I^\prime \models \restr{C}{\sigma}$.
    If $I \circ \vec{\varepsilon} \models Q$, then $I^\prime = I \circ \vec{\varepsilon} \circ \sigma$ satisfies $C$;
    then $I \circ \vec{\varepsilon}$ satisfies $\restr{C}{\sigma}$ by Lemma~\ref{lem:reduct}.
    Otherwise, $I^\prime = I \circ \vec{\varepsilon}$ satisfies $\restr{C}{\sigma}$.

    Finally, for $\nabla\textsc{intro}$, let $I$ be any model satisfying the premises, and $I^\prime = I \circ \vec{\varepsilon} \circ (\sigma \coloneq Q)$.
    If $I \circ \vec{\varepsilon}$ satisfies $Q$ then either it also satisfies $\comp Q \vee \restr{C}{\sigma}$ or $Q \models \restr{C}{\sigma}$.
    Either way, we can conclude $I \circ \vec{\varepsilon} \models \restr{C}{\sigma}$, and since in this case we have $I^\prime = I \circ \vec{\varepsilon} \circ \sigma$,
    Lemma~\ref{lem:reduct} implies that $I^\prime \models C$.
    The other case is $I \circ \vec{\varepsilon} \not\models Q$, and in this case $I^\prime = I \circ \vec{\varepsilon}$, which satisfies $C$.
\end{proof}

Upon closer inspection of the proof of Theorem~\ref{thm:srsemantics},
the relation between the SR property and satisfiability-preservation becomes clearer.
When each clause $D \in F$ is required that either $\sigma$ trivializes $D$, or
$\comp C \models \restr{D}{\sigma}$, or the clause $C \vee \restr{D}{\sigma}$ is a RUP
clause over $F$, these conditions enable deriving
$\mut{(\sigma \coloneq \comp C)}{D}$ through rules $\nabla\textsc{taut}$
or $\nabla\textsc{intro}$ hold: the left-hand premise in $\nabla\textsc{intro}$
just means that $C$ has been derived earlier in the SR proof, while the
right-hand premise ensures that $C \vee \restr{D}{\sigma}$ can be derived (e.g.\ as a RUP clause).

On the other hand, $\nabla\textsc{taut}$ guarantees that $\mut{(\sigma \coloneq \comp C)}{C}$
can be derived, since the definition of SR clauses \emph{forces} $C$ to be trivialized
by $\sigma$. Given that $\nabla$ distributes over $\wedge$, these conditions are proving
$F \models \mut{(\sigma \coloneq \comp C)}{F}$.

Similar to~\cite{Rebola-PardoS18}, a translation of a DSR proof into a mutation logic proof then works as follows.
At each step in the DSR proof, we consider the list of rules $(\sigma_i \coloneq \comp C_i)$
corresponding to each SR clause $C_i$ introduced upon $\sigma_i$ earlier in the proof;
this list is potentially empty, e.g.\ at the start of the proof.
Let us denote this list by $\vec{\varepsilon}$. Then, at that point, all clauses
$D$ in the accumulated CNF formula have been derived as mutation clauses
$\mut{\vec{\varepsilon}}{D}$ in the translation.
The translation then proceeds as follows:
\begin{enumerate}
\item Deletions in the DSR proof are not translated.
\item A RUP clause $C$ can be derived through a subsumption-merge chain~\cite{PhilippR17}; rules $\textsc{res}$
and $\textsc{sub}$ can express a similar derivation of the mutation version of $C$.
\item For an SR clause $C$ over a CNF formula $F$ upon an atomic substitution $\sigma$,
we must derive mutation clauses $D_\nabla = \mut{\vec{\varepsilon}}{\mut{(\sigma \coloneq \comp C)}{D}}$ for
each clause $D \in F \cup \Set{C}$.
\begin{enumerate}
    \item When $\sigma$ trivializes $D$, the mutation clause $D_\nabla$ can be derived
    as an axiom through $\nabla\textsc{taut}$. Note that this case includes the case
    $D = C$ as well; this detail will become relevant in Section~\ref{ssc:wsr}.
    \item When $\comp C \models \restr{D}{\sigma}$, the mutation clause $D_\nabla$ can be
    infered from $\mut{\vec{\varepsilon}}{D}$ through $\nabla\textsc{intro}$. We know this premise has been
    previously derived because $D \in F$.
    \item When $C \vee \restr{D}{\sigma}$ is a RUP clause over $F$, a subsumption-merge chain
    deriving that clause with premises in $F$ exists~\cite{Gelder12, PhilippR17}.
    Replacing clauses $D^\prime$ with mutation clauses $\mut{\vec{\varepsilon}}{{D^\prime}}$,
    resolution inferences with $\nabla\textsc{res}$ and subsumption inferences with
    $\nabla\textsc{sub}$ in that proof then yields a derivation of
    $\mut{\vec{\varepsilon}}{C \vee \restr{D}{\sigma}}$ from previously derived mutation clauses.
    Finally, the rule $\nabla\textsc{intro}$ derives $D_\nabla$.
\end{enumerate}
\item At the end of the proof, the empty clause $\Cla{\,}$ is derived in the SR clause, and
the translation has derived the mutated clause $\mut{\varepsilon}{\Cla{\,}}$. The identity
$\Cla{\,} = \restr{\Cla{\,}}{\sigma}$ for all substitutions $\sigma$ ensures that
$\nabla\textsc{elim}$ can be iteratively applied to eliminate all mutation operators,
so that $\Cla{\,}$ is derived in the translation as well.
\end{enumerate}

\section{Extending DSR proofs}
\label{sec:extensions}

Understanding DSR proofs as mutation logic proofs opens the door to finer-grained
reasoning about interference-based proofs. Crucially, one of the main issues with
interference-based proofs is that deriving a clause involves reasoning over the whole
currently derived formula. In particular, interference-based proofs can be highly
\emph{non-monotonic}: deleting a clause in the current formula can enable new SR
introductions; and conversely, introducing a clause can disable previously available
SR introductions.

This is, at first sight, at odds with the translation described in Section~\ref{ssc:entailment}:
the proofs we obtain there are model-preserving, DAG-shaped proofs with clear
dependencies with other derived clauses. What can be derived in a subproof is never
affected by independent proof sub-DAGs, so clause introduction never disables SR
introductions. Deletions are even more intriguing, since they do not even exist in
the mutation logic framework (just as there is no notion of deletion in a resolution
proof DAG).

Another noticeable feature is how differently an SR clause $C$ over $F$ is treated in
the definition compared to the clauses $D \in F$. Even if at first sight it might
look reasonable to consider different conditions on the premises and on the conclusion,
the translation from Section~\ref{ssc:entailment} uses the same set of inference rules
to derive both $C_\nabla$ and $D_\nabla$.

\subsection{Weak substitution redundancy}
\label{ssc:wsr}

In the translation, the conditions of the definition are used to guarantee that
$C_\nabla$ can be derived through a $\nabla\textsc{taut}$ inference.
However, we have \emph{three} rules that can derive this
mutated clause, and the three are involved in deriving $D_\nabla$ for each $D \in F$.
We can thus relax the conditions over $C$ by demanding just the same as for each $D$:
either $\sigma$ must trivialize $C$, or $\comp C \models \restr{C}{\sigma}$,
or the clause $C \vee \restr{C}{\sigma}$ must be a RUP clause over $F$.

Furthermore, there is nothing in the translation forcing us to derive
$D_\nabla$ for \emph{each and all} clauses $D \in F$.
Rather, we must only do so for those clauses that the proof uses later on.
However, even if we do not need $D$ after the SR introduction, we still can 
use $D$ for the RUP checks of \emph{other} clauses in $F$. Note that this is not
quite the same as deleting $D$ before the SR introduction: doing so could make
the RUP checks of other clauses in $F$ fail.

These two details suggest an extension of substitution redundancy, which we call
\emph{weak substitution redundancy} (WSR).

\begin{definition}
A clause $C$ is a WSR clause over a CNF
formula $F$ upon an atomic substitution $\sigma$ modulo a subformula $\Delta \subseteq F$
whenever, for each clause $D \in (F \setminus \Delta) \cup \Set{C}$, either of the following holds:
\begin{alphaenumerate}
    \item $\sigma$ trivializes $D$.
    \item $\comp C \models \restr{D}{\sigma}$.
    \item $C \vee \restr{D}{\sigma}$ is a RUP clause over $F$.
\end{alphaenumerate}
\end{definition}

\begin{theorem}
Let $C$ be a WSR clause over a CNF formula $F$ upon an atomic substitution $\sigma$ modulo
a subformula $\Delta \subseteq F$. Then, $F \models \mut{(\sigma \coloneq \comp C)}{((F \setminus \Delta) \cup \Set{C})}$ holds.
In particular, if $F$ is satisfiable, then so is $(F \setminus \Delta) \cup \Set{C}$.
\end{theorem}
\begin{proof}
    Similar to the proof of Theorem~\ref{thm:srsemantics}. The main difference is that
    $F \models \mut{(\sigma \coloneq \comp C)}{C}$ must now be shown using the same reasoning
    as $F \models \mut{(\sigma \coloneq \comp C)}{D}$ for $D \in F$.
\end{proof}

The complexity of checking a WSR clause introduction is similar to that of a PR/SR check.
On the one hand, one extra RUP check might be needed if $C \vee \restr{C}{\sigma}$ is not
a tautology; on the other hand, one RUP check is spared for each clause in $\Delta$.

A minor benefit of WSR clauses is that, while not every RUP is a RAT, PR or SR clause,
every RUP clause is a WSR clause upon the identity atomic substitution.
The reason for this is that the condition that
the atomic substitution $\sigma$ must trivialize $\Cla{\,}$ always fails.
This allows reasoning about WSR proofs without the need for case discussion.
\begin{corollary}
    Let $C$ be clause and $F$ be a CNF formula. Then, $C$ is a RUP clause over $F$ if and only if
    $C$ is a WSR clause over $F$ upon the identity atomic substitution modulo $\emptyset$.
\end{corollary}

This, together with the embedded notion of deletions as $\Delta$, enables the definition of a proof
system with only one rule $\textbf{w: }C,\,\sigma \setminus \Delta$. This rule introduces clause $C$ and
deletes clauses in $\Delta$, and is correct whenever $C$ is a WSR clause over $F$ upon $\sigma$ modulo
$\Delta$. We call this proof system the \emph{WSR proof system}.

Note that the relaxations that derive the WSR proof system from DSR already exist in the literature,
albeit in different frameworks. In~\cite{GochtN21}, the first relaxation appears in a proof system
that derives pseudo-Boolean constraints rather than clauses. This work is extended later in~\cite{0001GMN22}
by explicitly maintaining two different accumulated \emph{core} and \emph{derived} formulas,
much in the vein of~\cite{JarvisaloHB12}. A \emph{transfer rule} allows moving core constraints to
the derived constraints, whereas a \emph{dominance-based strengthening rule} allows deriving redundant core constraints while only checking
SR-like conditions on other core constraints, hence treating derived constraints somewhat similarly to the ``modulo'' clauses in WSR.
However, the framework from~\cite{0001GMN22} targets optimization solving approaches; correspondingly,
dominance-based strengthening also includes side conditions on the objective function.
It is not immediately clear what these side conditions morph into when considered over a non-optimization framework,
nor whether the separation between core and derived constraints is fluid enough to fully simulate our second relaxation.

\section{Applications of WSR proofs}
\label{sec:applications}

So far, we have not yet shown any benefit of WSR over SR (or that they are not equivalent,
for that matter). In this section, we demonstrate techniques using WSR proofs that are unavailable
in previously existing interference-based proof systems.

\subsection{A shorter proof of the pigeonhole problem}
\label{ssc:php}

One of the first propositional problems that was found to only have exponential
resolution proofs was the pigeonhole problem~\cite{Haken85}. While polynomial proofs
in the extended resolution system had already been known for a decade~\cite{Cook76},
these proofs needed to introduce fresh variables to support definitions.
However, the seminal work on PR clauses presented a shorter DPR proof that did not
use extra variables, using $O(n^3)$ instructions~\cite{HeuleKB17}.

In~\cite{Rebola-PardoS18} an analysis of this proof from the overwrite logic perspective
was presented; let us briefly reproduce it here. The pigeonhole problem encodes the unsatisfiable
problem ``find an assignment of $n$ pigeons to $n-1$ pigeonholes such that no two pigeons share
the same hole''.
We consider variables $p_{ij}$ encoding ``pigeon $i$ is in hole $j$''. Let us define the following clauses:
\begin{align*}
    H_{in} = {} & \Cla{p_{ij} \mid 1 \leq j < n} \quad \text{for $n > 0$ and $1 \leq i \leq n$} \\
    P_{ijk} = {} & \Cla{\comp{p_{ik}}\,\comp{p_{jk}}} \quad \text{for $1 \leq i < j$ and $1 \leq k$} \\
    L_{ijn} = {} & \Cla{\comp{p_{i (n - 1)}}\,\comp{p_{nj}}} \quad \text{for $n > 1$, $1 \leq i < n$ and $1 \leq j < n - 1$} \\
    R_{in} = {} & \Cla{\comp{p_{i (n - 1)}}} \quad \text{for $n > 1$ and $i < n$}
\end{align*}
Briefly, $H_{in}$ says that pigeon $i$ stays in some hole $1 \leq j < n$; $P_{ijk}$ prevents that pigeons $i$
and $j$ both occupy hole $k$; $L_{ijn}$ can be read as ``if the pigeon $i$ is in the last hole, then hole $j$ does not contain the last pigeon'';
and finally $R_{in}$ prevents that pigeon $i$ is in the last hole.
The pigeonhole problem for $n$ pigeons is then encoded by
\begin{equation*}
\Pi_n = \Set{H_{in} \mid 1 \leq i \leq n} \cup \Set{P_{ijk} \mid 1 \leq i < j \leq n \text{ and }1 \leq k < n}
\end{equation*}
Intuitively, a refutation of $\Pi_n$ proceeds by noting that, without loss of generality, each pigeon $i < n$ is not in hole $n - 1$;
were this not the case, one can swap pigeon $i$ with pigeon $n$ (which is not in hole $n$ because that would violate $P_{in(n-1)}$).
Then, pigeons $1, \dots, (n - 1)$ and holes $1, \dots, (n - 2)$ are in the conditions of the pigeonhole problem $\Pi_{n - 1}$.
This process can be iterated until $\Pi_1$ is reached, which is trivially unsatisfiable.

The proof from \cite{HeuleKB17} follows this reasoning, but a single PR clause is not expressive enough to encode
swaps: the only mutations that it can handle are setting variables to true or false.
Thus, the proof first derives clauses $L_{ijn}$ for $1 \leq i < n$ and $1 \leq j < n - 1$ as PR clauses with
the cube $Q_{ijn} = \Cub{\comp{p_{i (n - 1)}}\,\comp{p_{nj}}p_{ij}p_{n (n - 1)}}$. This encodes the following reasoning:
without loss of generality, if the pigeon $i$ is in the last hole, then hole $j$ does not contain the last pigeon;
were this not the case, ensure that pigeon $i$ is not in the last hole but in the hole $j$ instead, and that
the last pigeon is not in hole $j$ but in the last hole instead. Once the clauses $L_{ijn}$ have been derived for
each $1 \leq i < n$, the clause $R_{in}$ ensuring that pigeon $i$ is not in the last hole can be derived as a RUP clause.

When considered together, the mutations $Q_{ijn}^\star$ for $1 \leq j < n - 1$ express the atomic substitution that swaps
pigeons $i$ and $n$, that is:
\begin{equation*}
    \sigma_{in} = \Set{p_{ij} \mapsto p_{nj}, p_{nj} \mapsto p_{ij} \mid 1 \leq j < n} \quad \text{for $1 \leq i < n$}
\end{equation*}
DSR can handle this kind of mutation. Let us write a DSR derivation of $\Pi_{n - 1}$ from $\Pi_{n}$
(where we are omitting some trailing deletions for simplicity):
\begin{equation*}
    (\textbf{i: }R_{1n},\,\sigma_{1n}),\dots,(\textbf{i: }R_{(n-1)n},\,\sigma_{(n-1)n}),(\textbf{i: }H_{1(n-1)}),\dots,(\textbf{i: }H_{(n-1)(n-1)})
\end{equation*}
Clauses $H_{i(n-1)}$ can be introduced as RUP clauses, since they result from resolution on $H_{in}$ and $R_{in}$.
Furthermore, one would hope for the $R_{in}$ clauses to be SR clauses over the preceding formula upon $\sigma_{in}$.
Let us check this. For each clause $D$ in the preceding formula $F$, we need to check that either of the following holds:
\begin{alphaenumerate}
    \item $D$ is trivialized by $\sigma_{in}$
    \item $\Cub{p_{i (n - 1)}} \models \restr{D}{\sigma_{in}}$
    \item the clause $D_\nabla = \Cla{\comp {p_{i (n - 1)}}} \vee \restr{D}{\sigma_{in}}$ is a RUP clause over $F$.
\end{alphaenumerate}    
Checking case by case one can see that the reduct $\restr{D}{\sigma_{in}}$ is always another clause in $F$,
so $D_\nabla$ is either a tautology or can be derived by subsumption from $F$ (which implies it is a RUP clause).

The clause $R_{in}$, nevertheless, is not an SR clause over $F$ upon $\sigma_{in}$, because it is not trivialized by $\sigma_{in}$.
Observe, however, that
\begin{equation*}
    C_\nabla = C \vee \restr{C}{\sigma_{in}} = \Cla{\comp {p_{i(n - 1)}}\,\comp {p_{n(n - 1)}}} = P_{in(n - 1)} \in F
\end{equation*}
In particular, $C_\nabla$ it is a RUP clause over $F$. Hence, $R_{in}$ is in fact a WSR clause over $F$ upon $\sigma_{in}$ modulo $\emptyset$.
Hence, we can define the WSR derivation $\pi_n$ of $\Pi_1$ from $\Pi_n$ given in Figure~\ref{fig:php} for $n > 1$.
The derivation $\pi_n$ has $O(n^2)$ instructions, and is in fact a refutation, since $\Cla{} \in \Pi_1$.

% Figure environment removed

\subsection{Smaller cores and shorter checking runtime}
\label{ssc:cores}
SAT solvers generate proofs which often introduce clauses uninvolved in the derivation of a contradiction.
This is practically unavoidable because of how solvers generate proofs:
solvers mostly just log every learnt clause~\cite{GoldbergN03},
and at that point the solver does not know what learnt clauses will be useful.

State-of-the-art proof checkers thus validate the proof
backwards~\cite{HeuleHW13,WetzlerHH14}. Starting from the empty clause at the end of the proof,
the checker finds out what clauses are needed to derive each clause as a RUP clause.
Required clauses are then \emph{marked}; as the checker proceeds backwards, unmarked clauses
are skipped. If one were to visualize a RUP proof as a DAG, this amounts to only
checking the connected component that actually derives the empty clause while disregarding
all other connected components in the DAG.

Backwards checking has three interesting consequences. First, it vastly improves checking runtime:
not only are checks for unmarked clauses skipped, but also their premises are skipped as well
(unless they are used to derive another marked clause). Second, a shorter, \emph{trimmed} proof
can be extracted as a by-product of checking. Finally, by the time the checker reaches the start
of the proof, the marked clauses in the input formula form a (not necessarily minimal) unsatisfiable core.

\paragraph{Backwards checking in interference-based proofs}

Interference-based proofs do not have DAG-like dependencies as RUP proofs have.
Let us formalize the problem of backwards checking in this situation.
We assume that the checker keeps track of a CNF formula $F$ and
marked clauses $M \subseteq F$ as it proceeds backwards through the proof. When a
RAT/PR/SR introduction $\textbf{i: }C,\,\omega$ is reached with $C \in M$, the checker removes
$C$ from both the formula $F$ and the marked clauses $M$ and validates the
corresponding RAT/PR/SR introduction. The goal then is to find some (preferably small) subformula $M^\prime$
with $M \subseteq M^\prime \subseteq F$ such that $C$ is a RAT/PR/SR clause upon $\omega$ over $M^\prime$;
this will be the new set of marked clauses.

In the best case scenario, $C$ satisfies the corresponding redundancy property over $M$,
so the checker can move on with $M^\prime = M$.
There is only one way the redundancy property might not hold over $M$:
when one of the RUP checks from Definition~\ref{def:redundancy} fails over $M$
(but still succeeds over $F$), the premises of the induced subsumption-merge
chain must become marked; let us (conspicuously) call this set of \emph{newly} marked clauses $\Delta$.
The problem we are tackling is whether clauses in $\Delta$ \emph{really} need their own RUP check as
mandated by Definition~\ref{def:redundancy}.

For RAT, it turns out, they do not: one can show that, for a witness literal $l$ in a RAT check,
the clauses in $\Delta$ never contain $\comp l$, so they never trigger further RUP checks.
Such a convenient coincidence does not hold for PR or SR, though. In order to establish
that $C$ is a PR/SR clause upon some $M^\prime$, the clauses in $\Delta$ must undergo their own
RUP check, which might add new clauses to $\Delta$, and so on until fixpoint.

This is nevertheless wasteful. By the time the first $\Delta$ has been computed,
introducing $C$ can already be claimed to be satisfiability-preserving, \emph{just not as a PR/SR}:
the conditions above prove that $C$ is a WSR clause upon $\omega$ over $M \cup \Delta$ modulo $\Delta$.
This means that a proof checker (even one that only checks PR/SR) can simply set $M^\prime = M \cup \Delta$
and continue checking the rest of the proof.

To the best of our knowledge, existing checkers do not deal with this situation in
an optimal way, e.g.\ 
the reference DPR checker \texttt{dpr-trim} resorts instead to the fixpoint method%
\footnote{See \url{https://github.com/marijnheule/dpr-trim/blob/83eb40b9028100aca63a419eb6d08b45acf517ad/dpr-trim.c}, line 660.}.
Note that the fixpoint method always produces a larger $M^\prime$ than the WSR-based
method, with associated longer runtimes, larger unsatisfiability cores and longer
trimmed proofs.

Even if for (uncertified) checking WSR only seems relevant at a theoretical level,
state-of-the-art proof checkers emit trimmed, annotated proofs that can be further checked
with a verified tool~\cite{Cruz-FilipeHHKS17, TanHM21}. The formats these annotated proofs use,
such as LRAT or LPR, are based on RAT/PR, and so the fixpoint method is needed
if an annotated proof must be emitted in one of these formats.
Either way, the need for the fixpoint method could be removed by emitting WSR-based annotated proofs.

\begin{example}
    Let us define three CNF formulas. The formula $M$ contains clauses:
    \begin{align*}
        \Cla{a\,\comp c\,x} \qquad \Cla{\comp a\,\comp u\,\comp v\,\comp x} \qquad \Cla{c\,\comp u\,\comp v\,x} & \qquad \Cla{a\,\comp x\,\comp y\,\comp z} \qquad \Cla{a\,\comp c\,\comp x\,y} \qquad \Cla{\comp a\,b\,u}\\
        \Cla{c\,u} \qquad \Cla{\comp u\,y\,z} \qquad \Cla{\comp a\,\comp b\,\comp c} \qquad &\Cla{c\,\comp x\,\comp z}^{\bullet} \qquad \Cla{\comp c\,\comp x z}^{\bullet} \qquad \Cla{c\,\comp x\,\comp y}^{\bullet} \qquad \Cla{\comp a\,b\,\comp u\,v\,\comp x}^{\bullet}
    \end{align*}
    The formula $\Delta$ contains:
    \begin{equation*}
        \Cla{b\,\comp u\,x} \qquad \Cla{\comp b\,\comp t\,v\,x\,\comp y} \qquad \Cla{\comp b\,t\,v\,x\,\comp z} \qquad \Cla{t\,v\,\comp y\,z} \qquad \Cla{\comp t\,v\,y\,\comp z}
    \end{equation*}
    Finally, $\Gamma = \Set{\Cla{\comp b\,x\,\comp u\,y\,\comp z}}$. Let us assume that a proof checker is
    checking a DSR refutation of the unsafistiable formula $F = M \cup \Delta \cup \Gamma$ backwards. It eventually reaches the first instruction, an SR clause introduction
    for $C = \Cla{x\,\comp u}$ upon the atomic substitution $\sigma = \Set{x \mapsto \top, a \mapsto \top, v \mapsto \bot, t \mapsto \top}$. At this point, the clauses in $M$
    (in addition to $C$) have been marked for checking; since this is the first instruction, the marked clauses after checking $C$ for SR are an unsatisfiable core of $F$.
    One can check that $\sigma$ trivializes $C$, and that all clauses in $M$ except for the ones highlighted with~$\bullet$ satisfy the conditions in Definition~\ref{def:redundancy}
    using propagation clauses exclusively from $M$.
    For the highlighted clauses, propagating with clauses from $M \cup \Delta$ does suffice to satisfy Definition~\ref{def:redundancy}.

    As we learnt in Section~\ref{sec:extensions}, we can now stop checking: $C$ is a WSR clause over the formula $M \cup \Delta$ modulo $\Delta$;
    the newly marked clauses (which form the generated unsatisfiable core) are thus $M \cup \Delta$.
    Current checkers will nevertheless not stop here, since SR is more restrictive than WSR. In particular, they check the newly marked clauses $\Delta$
    for the conditions in Definition~\ref{def:redundancy} as well. As it turns out, $C$ is not even an SR clause over $M \cup \Delta$, but only over $F$:
    for the RUP check for $C \vee \restr{\Cla{\comp t\,v\,y\,\comp z}}{\sigma}$ to succeed, the clause in $\Gamma$ is needed too.
    That clause becomes subsequently marked, and a further check is performed for it. This check finally succeeds, reaching a fixpoint.

    This example shows that SR marks strictly more clauses than WSR, which translates into larger generated unsatisfiable cores and trimmed proofs, as well
    as a longer checking runtime since the extra marked clauses will be themselves checked.
\end{example}

\subsection{Interference-free interference lemmas}
\label{ssc:lemmas}

The differences between SR and WSR presented in Section~\ref{ssc:cores} can too be exploited
during proof generation. While the largest share of a proof generated by a state-of-the-art SAT solver
consists of learnt clauses introduced as RUP clauses as well as clause deletions, inprocessing techniques
also contribute to the proof. Typically, an inprocessing technique performs some reasoning
and then a (to some extent) hardcoded proof fragment of the results is generated.
No proof search is performed; rather, the specialized reasoning performed by the inprocessing technique
is translated into the target proof system by a method that has previously been proven correct (on paper, not \emph{in silico}).

Interference-based proof systems are notable for their ability to generate succint proof fragments
for many inprocessing techniques and non-CDCL methods, including parity reasoning~\cite{PhilippR16,GochtN21},
symmetry breaking~\cite{HeuleHW15} and BDD-based reasoning~\cite{BryantBH22}. Devising these proofs
is complex for several reasons; among them is that, in an interference-based proof system, introduced lemmas
may need further lemmas for satisfy Definition~\ref{def:redundancy}.

Let us assume we want to generate a proof fragment deriving a clause
$C$ as an SR clause from $F$ upon some atomic substitution $\sigma$.
The clause $C$ has been obtained through some inprocessing technique,
and we know that all the clauses $D_\nabla = C \vee \restr{D}{\sigma}$ for $D \in F$ are implied by $C$
because of some property of the inprocessing technique.
However, we might find that some of the $D_\nabla$ are not RUPs over $F$;
after all, RUP is just a criterion for entailment.
We can derive some additional clauses (i.e.\ lemmas) $L^1,\dots,L^n$ from $F$ such that
$D_\nabla$ is a RUP over $F \cup L^1,\dots,L^n$, but now the definition of SR clauses demands that
the $L^i_\nabla$ are RUP clauses as well, which might need additional clauses and so on.

This is, in essence, the proof generation version of the proof checking situation from Section~\ref{ssc:cores}.
Just as we did there, with WSR we can completely bypass the need to prove that the $L^i_\nabla$ are RUP clauses:
$C$ is already a WSR clause over $F \cup \Set{L^1,\dots,L^n}$ upon $\sigma$ modulo $\Set{L^1,\dots, L^n}$.
In other words, WSR allows introducing interference lemmas that need not be taken into account for RUP checks.

\begin{example}
\label{exp:lemmas}
Let us consider the CNF formula $F$ containing clauses:
\begin{align*}
    \Cla{a\,b\,\comp x\,y} \qquad \Cla{a\,b\,x\,y\,\comp z} \qquad \Cla{a\,b\,x\,z} \qquad &\Cla{\comp a\,u\,v} \qquad \Cla{\comp c\,u\,v} \qquad \Cla{a\,c\,\comp b\,y} \qquad \Cla{a\,c\,b\,\comp y}\\
    \Cla{c\,\comp b\,\comp y\,\comp z} \qquad \Cla{c\,\comp b\,x\,\comp y\,z} \qquad &\Cla{c\,\comp b\,\comp x\,z} \qquad \Cla{\comp u\,v} \qquad \Cla{u\,\comp v} \qquad \Cla{\comp u\,\comp v}
\end{align*}
We want to derive the clause $C = \Cla{x}$. Unfortunately, $C$ is not a RUP clause over $F$, so we try to introduce it
as an SR clause upon the atomic substitution $\sigma = \Set{x \mapsto \top, y \mapsto z, z \mapsto y}$. This \emph{almost} works:
all the conditions in Definition~\ref{def:redundancy} hold,
except for $C \vee \restr{\Cla{\comp b\,c\,\comp x\,z}}{\sigma} = \Cla{\comp b\,c\,x\,y}$ not being a RUP clause over $F$.
We can derive some RUP lemmas from $F$, for example $L_1 = \Cla{\comp a\,y\,v}$ and then $L_2 = \Cla{\comp a\,y}$;
the clause $\Cla{\comp b\,c\,x\,y}$ is indeed a RUP clause over $F \cup \Set{L_1, L_2}$.

Here is where WSR and SR show their differences again. Under WSR, we can already introduce $C$ in $F$,
because the paragraph above implies that $C$ is a WSR clause over $F \cup \Set{L_1, L_2}$ upon $\sigma$ modulo $\Set{L_1, L_2}$.
This is not the case for SR, though: because the clause $C \vee \restr{L_2}{\sigma} = \Cla{\comp a\,x\,z}$ is not a RUP clause
over $F \cup \Set{L_1, L_2}$, the clause $C$ is not SR over $F$ upon $\sigma$.
We would need to find additional lemmas to make it so, which might then need further lemmas themselves.
\end{example}

\section{Conclusion}
\label{sec:conclusion}

We have presented a generalization of the SR redundancy notion, called weak substitution redundancy (WSR).
This extension is straightforward once the semantics of interference have been understood,
which we achieve by extending the overwrite logic framework from~\cite{Rebola-PardoS18} into
mutation logic, which is able to handle atomic substitutions.

The main differences between SR and WSR are the weakening of one unnecessarily strong condition in the definition,
and the specification of a set of clauses that can be used for ensuring the interference conditions
but will not participate in interference themselves.

These minor differences have an impact on the versatility of the proof system. Shorter proofs can be obtained,
lemmas can be used in a less obstrusive way, the efficiency of the backwards checking algorithm is enhanced,
and smaller unsatisfiable cores and trimmed proofs can be generated.

\bibliography{main}

\end{document}
