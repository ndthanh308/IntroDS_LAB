\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anil et~al.(2021)Anil, Gupta, Koren, Regan, and
  Singer]{second_order_optimization}
Anil, R., Gupta, V., Koren, T., Regan, K., and Singer, Y.
\newblock Scalable second order optimization for deep learning.
\newblock Technical Report arXiv:2002.09018 [cs.LG], ArXiV, 2021.
\newblock URL \url{https://doi.org/10.48550/arXiv.2002.09018}.

\bibitem[Anonymous(2022)]{silk_2022_anon}
Anonymous, A.
\newblock Anonymous implementation, 6 2022.

\bibitem[Barrett \& Dherin(2022)Barrett and Dherin]{barrett2022implicit}
Barrett, D. G.~T. and Dherin, B.
\newblock Implicit gradient regularization, 2022.

\bibitem[Byrd et~al.(1995)Byrd, Lu, Nocedal, and Zhu]{doi:10.1137/0916069}
Byrd, R.~H., Lu, P., Nocedal, J., and Zhu, C.
\newblock A limited memory algorithm for bound constrained optimization.
\newblock \emph{SIAM Journal on Scientific Computing}, 16\penalty0
  (5):\penalty0 1190--1208, 1995.
\newblock \doi{10.1137/0916069}.
\newblock URL \url{https://doi.org/10.1137/0916069}.

\bibitem[Byrd et~al.(2016)Byrd, Hansen, Nocedal, and
  Singer]{byrd_stochastic_lbfgs}
Byrd, R.~H., Hansen, S.~L., Nocedal, J., and Singer, Y.
\newblock A stochastic quasi-newton method for large-scale optimization.
\newblock \emph{SIAM Journal on Optimization}, 26\penalty0 (2):\penalty0
  1008--1031, 2016.
\newblock \doi{10.1137/140954362}.
\newblock URL \url{https://doi.org/10.1137/140954362}.

\bibitem[{DeltaIV}()]{stackexchange-soo-a}
{DeltaIV}.
\newblock Why second order {SGD} convergence methods are unpopular for deep
  learning?
\newblock Cross Validated.
\newblock URL \url{https://stats.stackexchange.com/q/394108}.
\newblock (version: 2019-02-26).

\bibitem[Deng(2012)]{deng2012mnist}
Deng, L.
\newblock The {MNIST} database of handwritten digit images for machine learning
  research.
\newblock \emph{IEEE Signal Processing Magazine}, 29\penalty0 (6):\penalty0
  141--142, 2012.
\newblock \doi{10.1109/MSP.2012.2211477}.

\bibitem[Fletcher \& Reeves(1964)Fletcher and Reeves]{fletcher_reeves}
Fletcher, R. and Reeves, C.~M.
\newblock {Function minimization by conjugate gradients}.
\newblock \emph{The Computer Journal}, 7\penalty0 (2):\penalty0 149--154, 01
  1964.
\newblock ISSN 0010-4620.
\newblock \doi{10.1093/comjnl/7.2.149}.
\newblock URL \url{https://doi.org/10.1093/comjnl/7.2.149}.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{Goodfellow-et-al-2016}
Goodfellow, I., Bengio, Y., and Courville, A.
\newblock \emph{Deep Learning}.
\newblock MIT Press, Cambridge, MA, USA, 2016.
\newblock URL \url{http://www.deeplearningbook.org}.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock Technical Report arXiv:1512.03385 [cs.CV], ArXiV, 2015.
\newblock URL \url{https://arxiv.org/abs/1512.03385}.

\bibitem[{jwimberley}()]{stackexchange-soo-b}
{jwimberley}.
\newblock Why is {Newton's} method not widely used in machine learning?
\newblock Cross Validated.
\newblock URL \url{https://stats.stackexchange.com/q/253636}.
\newblock (version: 2016-12-29).

\bibitem[Kingma \& Ba(2017)Kingma and Ba]{kingma2017adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock Technical Report arXiv:1412.6980 [cs.LG], ArXiV, 2017.

\bibitem[Krizhevsky(2009)]{cifar10}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, Toronto, ON, CA, 2009.

\bibitem[Larson(2008)]{anova_larson2008analysis}
Larson, M.~G.
\newblock Analysis of variance.
\newblock \emph{Circulation}, 117\penalty0 (1):\penalty0 115--121, 2008.
\newblock \doi{CIRCULATIONAHA.107.654335}.
\newblock URL \url{https://doi.org/10.1161/CIRCULATIONAHA.107.654335}.

\bibitem[Le et~al.(2011)Le, Ngiam, Coates, Lahiri, Prochnow, and
  Ng]{le2011optimization}
Le, Q.~V., Ngiam, J., Coates, A., Lahiri, A., Prochnow, B., and Ng, A.~Y.
\newblock On optimization methods for deep learning.
\newblock In \emph{Proceedings of the 28th International Conference on
  International Conference on Machine Learning}, ICML'11, pp.\  265â€“--272,
  Madison, WI, USA, 2011. Omnipress.
\newblock ISBN 9781450306195.
\newblock URL \url{http://www.icml-2011.org/papers/210_icmlpaper.pdf}.

\bibitem[LeCun et~al.(1998{\natexlab{a}})LeCun, Bottou, Bengio, and
  Haffner]{lecun_gradient_based_learning}
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998{\natexlab{a}}.
\newblock \doi{10.1109/5.726791}.
\newblock URL \url{https://doi.org/10.1109/5.726791}.

\bibitem[LeCun et~al.(1998{\natexlab{b}})LeCun, Bottou, Orr, and
  M{\"u}ller]{lecun2012efficient}
LeCun, Y., Bottou, L., Orr, G.~B., and M{\"u}ller, K.~R.
\newblock \emph{Efficient BackProp}, pp.\  9--50.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 1998{\natexlab{b}}.
\newblock ISBN 978-3-540-49430-0.
\newblock \doi{10.1007/3-540-49430-8_2}.
\newblock URL \url{https://doi.org/10.1007/3-540-49430-8_2}.

\bibitem[Liu \& Nocedal(1989)Liu and Nocedal]{lbfgs}
Liu, D.~C. and Nocedal, J.
\newblock On the limited memory bfgs method for large scale optimization.
\newblock \emph{Mathematical Programming}, 45\penalty0 (1):\penalty0 503--528,
  8 1989.
\newblock ISSN 1436-4646.
\newblock \doi{10.1007/BF01589116}.
\newblock URL \url{https://doi.org/10.1007/BF01589116}.

\bibitem[{Nick Alger}()]{stackexchange-soo-positive}
{Nick Alger}.
\newblock Why is {Newton's} method not widely used in machine learning?
\newblock Cross Validated.
\newblock URL \url{https://stats.stackexchange.com/q/253830}.
\newblock (version: 2017-04-13).

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, K\"{o}pf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., K\"{o}pf, A., Yang,
  E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang,
  L., Bai, J., and Chintala, S.
\newblock \emph{PyTorch: An Imperative Style, High-Performance Deep Learning
  Library}.
\newblock Curran Associates Inc., Red Hook, NY, USA, 2019.

\bibitem[Pauloski et~al.(2021)Pauloski, Huang, Huang, Venkataraman, Chard,
  Foster, and Zhang]{kaisa_2021}
Pauloski, J.~G., Huang, Q., Huang, L., Venkataraman, S., Chard, K., Foster, I.,
  and Zhang, Z.
\newblock Kaisa: An adaptive second-order optimizer framework for deep neural
  networks.
\newblock In \emph{Proceedings of the International Conference for High
  Performance Computing, Networking, Storage and Analysis}, SC '21, New York,
  NY, USA, 2021. Association for Computing Machinery.
\newblock ISBN 9781450384421.
\newblock \doi{10.1145/3458817.3476152}.
\newblock URL \url{https://doi.org/10.1145/3458817.3476152}.

\bibitem[Scheffe(1999)]{anova_scheffe1999analysis}
Scheffe, H.
\newblock \emph{The Analysis of Variance}, volume~72.
\newblock John Wiley \& Sons, 1999.

\bibitem[Smith et~al.(2021)Smith, Dherin, Barrett, and De]{smith2021origin}
Smith, S.~L., Dherin, B., Barrett, D. G.~T., and De, S.
\newblock On the origin of implicit regularization in stochastic gradient
  descent.
\newblock Technical Report arXiv:2101.12176 [cs.LG], ArXiV, 2021.

\bibitem[Thiele et~al.(2020)Thiele, Araya-Polo, and
  Hohl]{Quasi_Gauss_Newton_2020}
Thiele, C., Araya-Polo, M., and Hohl, D.
\newblock Deep neural network learning with second-order optimizers -- a
  practical study with a stochastic quasi-{Gauss}-newton method.
\newblock Technical Report arXiv:2004.03040 [cs.LG], ArXiV, 2020.
\newblock URL \url{https://doi.org/10.48550/arXiv.2004.03040}.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy,
  Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett,
  Wilson, Millman, Mayorov, Nelson, Jones, Kern, Larson, Carey, Polat, Feng,
  Moore, {VanderPlas}, Laxalde, Perktold, Cimrman, Henriksen, Quintero, Harris,
  Archibald, Ribeiro, Pedregosa, {van Mulbregt}, and {SciPy 1.0
  Contributors}]{scipy}
Virtanen, P., Gommers, R., Oliphant, T.~E., Haberland, M., Reddy, T.,
  Cournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., {van
  der Walt}, S.~J., Brett, M., Wilson, J., Millman, K.~J., Mayorov, N., Nelson,
  A. R.~J., Jones, E., Kern, R., Larson, E., Carey, C.~J., Polat, {\.I}., Feng,
  Y., Moore, E.~W., {VanderPlas}, J., Laxalde, D., Perktold, J., Cimrman, R.,
  Henriksen, I., Quintero, E.~A., Harris, C.~R., Archibald, A.~M., Ribeiro,
  A.~H., Pedregosa, F., {van Mulbregt}, P., and {SciPy 1.0 Contributors}.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.
\newblock \doi{10.1038/s41592-019-0686-2}.

\bibitem[Yao et~al.(2021)Yao, Gholami, Shen, Mustafa, Keutzer, and
  Mahoney]{adahessian_2021}
Yao, Z., Gholami, A., Shen, S., Mustafa, M., Keutzer, K., and Mahoney, M.
\newblock {ADAHESSIAN}: {An} {Adaptive} {Second} {Order} {Optimizer} for
  {Machine} {Learning}.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  35\penalty0 (12):\penalty0 10665--10673, May 2021.
\newblock ISSN 2374-3468.
\newblock \doi{10.1609/aaai.v35i12.17275}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/17275}.
\newblock Number: 12.

\end{thebibliography}
