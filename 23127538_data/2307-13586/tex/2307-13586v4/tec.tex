

In this section, we point out the key technical hurdles the previous approach encounters when mitigating the burn-in cost, 
and put forward a new strategy to overcome such hurdles. 
For ease of presentation, let us introduce a set of augmented notation to indicate several running iterates in Algorithm~\ref{alg:main}, 
which makes clear the dependency on the episode number $k$ and will be used throughout all of our analysis. 
%
\begin{itemize}

	%\item  $\pi^k$: the policy employed at the beginning of the $k$-th episode.  

	\item  $\widehat{P}^k_{s,a,h}\in \mathbb{R}^{S}$: the latest update of the empirical transition probability vector $\widehat{P}_{s,a,h}$ before the $k$-th episode. 
	
	\item  $\widehat{r}_h^k(s,a)\in [0,H]$: the latest update of the empirical reward $\widehat{r}_h(s,a)$ before the $k$-th episode. 

	\item  $\widehat{\sigma}_h^k(s,a) \in [0,H^2] $: the latest update of the empirical squared reward $\widehat{\sigma}_h(s,a)$ before the $k$-th episode.

	\item  $b_h^k(s,a) \geq 0 $: the latest update of the bonus term $b_h(s,a)$ before the $k$-th episode.


	\item  $N^{k,\mathsf{all}}_{h}(s,a)$: the total visitation count of the $(s,a,h)$-tuple before the beginning of the $k$-th episode. 

	
	\item  $N_h^k(s,a)$: the visitation count $N_h(s,a)$ of the $(s,a,h)$-tuple of the latest doubling batch used to compute $\widehat{P}_{s,a,h}$ before the $k$-th episode.  
		When $N^{k,\mathsf{all}}_{h}(s,a)=0$, we define $N_h^k(s,a)=1$ for ease of presentation.  

	\item  $V_h^k\in \mathbb{R}^{S}$: the value function estimate $V_h$ before the beginning of the $k$-th episode. 
	\item  $Q_h^k\in \mathbb{R}^{SA}$: the Q-function estimate $Q_h$ before the beginning of the $k$-th episode. 
	
\end{itemize}
%
Another notation for the empirical transition probability vector is also introduced below: 
 %
\begin{itemize}
	\item For any $j\geq 2$ (resp.~$j=1$), let  $\widehat{P}^{(j)}_{s,a,h}$ be the empirical transition probability vector for $(s,a,h)$ computed using the $j$-th batch of data, i.e., the $\{2^{j-2}+i\}_{i=1}^{2^{j-2}}$-th samples (resp.~the 1st sample) for $(s,a,h)$.  
	For completeness, we take $\widehat{P}^{(0)}_{s,a,h} = \frac{1}{S} 1$ for the $0$-th batch. 
	
	\item Similarly, let $\widehat{r}^{(j)}_h(s,a)$ (resp.~$\widehat{\sigma}^{(j)}_h(s,a)$) denote the empirical reward (resp.~empirical squared reward) w.r.t.~$(s,a,h)$ based on the $j$-th batch of data. 

\end{itemize}
%



\subsection{Technical barriers in prior theory for $\mathtt{UCBVI}$} 
%
\label{sec:technical-barrier-prior}



%\paragraph{A closer inspection on prior analysis for UCB-based algorithms.} 
%
%Next, let us take a closer inspection on the regret analysis for UCB-based model-based algorithms, 
% in order to better illuminate the part that calls for novel analysis. 



Let us take a close inspection on prior regret analysis for UCB-based model-based algorithms, in order to illuminate the part that calls for novel analysis. 
To simplify presentation, this subsection assumes deterministic rewards so that each empirical reward is replaced by its mean.   



 
%In each episode $k = 1,\ldots, K$, we update our estimates for the Q-function and the value function as follows:
% working backward (i.e., $h=H,H-1,\ldots, 1$), we set 
% \begin{subequations}
% \begin{align}
%	 Q^k_{h}(s,a) &= \min\Big\{ \widehat{r}^k_h(s,a) +  \big\langle \widehat{P}_{s,a,h}^k, V_{h+1}^{k} \big\rangle + b_h^k(s,a),\, H \Big\} ,
%  &&\forall (s,a)\in \mathcal{S}\times \mathcal{A}; \label{eq:updateqq}
% \\  V^k_h(s)&=\max_{a}Q_h^k(s,a), &&\forall s\in \mathcal{S}.\label{eq:updatevv}\end{align}
% \end{subequations}
%%
%Here, $\widehat{r}^k_h(s,a)$  and $\widehat{P}_{s,a,h}^k$ represent respectively the empirical reward 
%and the empirical transition kernel for the $k$-th episode, and $b_h^k(s,a)$ stands for a bonus function 
%properly chosen to ensure that $Q_h^k(s,a)\geq Q^{\star}_{h}(s,a)$ with high probability. 
%These are computed from the collected data. 
% We will specify $\widehat{P}_{s,a,h}^k$ and $\widehat{r}_h^k(s,a)$  
%later in Section~\ref{sec:tec1}, and $b_h^k(s,a)\geq 0$ has been described in Section~\ref{sec:alg}. 


Let us look at the original $\mathtt{UCBVI}$ algorithm proposed by \citet{azar2017minimax}. 
Standard decomposition arguments employed in the literature (e.g., \citet{jaksch2010near,azar2017minimax,zhang2020reinforcement}) decompose the regret as follows:  
%
\begin{align}
\mathsf{Regret}(K)\leq & \sum_{k,h}\Big(\widehat{P}_{s_{h}^{k},a_{h}^{k},h}^{k,\mathsf{all}}-P_{s_{h}^{k},a_{h}^{k},h}\Big)V_{h+1}^{k}+\sum_{k,h}b_{h}^{k}\big(s_{h}^{k},a_{h}^{k}\big)\nonumber\\& +\sum_{k,h}\Big(P_{s_{h}^{k},a_{h}^{k},h}-e_{s_{h+1}^{k}}\Big)\Big(V_{h+1}^{k}-V_{h+1}^{\pi^{k}}\Big);
	%+\sum_{k,h}\Big(\widehat{r}_{h}^{k,\mathsf{all}}\big(s_{h}^{k},a_{h}^{k}\big)-r_{h}\big(s_{h}^{k},a_{h}^{k}\big)\Big);
	\label{eq:key}
\end{align}
%
see also the derivation in Section~\ref{app:thmmain}. 
Here, we abuse the notation by letting $V_{h+1}^k$ (resp.~$b_h^k$) be the value function estimate (resp.~bonus term) of $\mathtt{UCBVI}$ before the $k$-th episode, 
and in the meantime, we let  $\widehat{P}^{k,\mathsf{all}}_{s,a,h}$ 
%(resp.~$\widehat{r}_h^{k,\mathsf{all}}(s,a)$) 
represent the empirical transition probability 
%(resp.~empirical reward) 
for the ($s,a,h$)-tuple computed using {\em all} samples before the $k$-th episode (note that we add the superscript $\mathsf{all}$ to differentiate it from its counterpart in our algorithm).  
%
In order to achieve full-range optimal regret, 
one needs to bound the three terms on the right-hand side of \eqref{eq:key} carefully, among which two are easy to handle.    
%
\begin{itemize}
	\item It is known that the second term (i.e., the aggregate bonus) on the right-hand side of \eqref{eq:key} can be controlled in a rate-optimal manner if we adopt suitably chosen Bernstein-style bonus; see, e.g., \citet{zhang2020reinforcement}, which will also be made clear shortly in Section~\ref{app:thmmain}. 

	\item In the meantime, the third term on the right-hand side of \eqref{eq:key} can be easily coped with by means of standard martingale concentration bounds (e.g., the Freedman inequality). 

\end{itemize}


%For the first term, i.e., the sum of the bonuses, we hope there are no explicit terms with high-order dependence on $(S,A,H)$ when designing the bonus function. 
% If we can adopt the bonus construction in MVP, which has the simple form of $\widetilde{O} \big(\sqrt{ \mathbb{V}(\widehat{P}_{s_h^k,a_h^k,h},V_{h+1}^k) /N} +H/N \big)$ (we omit the bonus for reward for simplicity), which will have no lower order term. 
% On the other hand, the third term could be dealt with via standard Bernstein-style concentration inequalities.

%\paragraph{The analysis used in prior works.} 
%\footnote{Note that this challenge does not arise in the simulator or offline RL setting for inhomogeneous MDPs \citep{li2020breaking,li2022settling}, since $\widehat{P}^k_{s_h^k,a_h^k,h}$ and $V_{h+1}^k$ are (or can be made) independent therein.} 

%%the estimation of $\widehat{P}^{k-1}_{s_h^k,a_h^k,h}$ determines the policy $\pi^{k}$ for the $k$-th round, which in turns affects $\{\widehat{P}^{k}_{s,a,h}\}_{(s,a,h)}$ and $V_{h+1}^k$. On the other hand, $\widehat{P}_{s_h^k,a_h^k,h}^k$ is highly correlated with  $\widehat{P}^{k-1}_{s_h^k,a_h^k,h}$ for most $(s,a,h,k)$-tuples, thus implying that $V_{h+1}^k$ is not independent of $\widehat{P}^k_{s_h^k,a_h^k,h}$.


It then comes down to controlling the first term on the right-hand side of \eqref{eq:key}.  
This turns out to be the most challenging part, owing to the complicated statistical dependency between $\widehat{P}^{k,\mathsf{all}}_{s_h^k,a_h^k,h}$ and $V_{h+1}^k$. 
To see this, note that $\widehat{P}^{k,\mathsf{all}}_{s,a,h}$ is constructed based on {\em all} previous samples of $(s,a,h)$, which has non-negligible influences upon $V_{h+1}^k$ as $V_{h+1}^k$ is computed based on previous samples. 
At least two strategies have been proposed to circumvent this technical difficulty, which we take a moment to discuss. 
%
\begin{itemize}
	\item {\em Strategy 1: replacing $V_{h+1}^k$ with $V_{h+1}^{\star}$ for large $k$.} 
Most prior analysis for model-based algorithms \citep{azar2017minimax,dann2017unifying,zanette2019tighter,zhang2020reinforcement} decomposes  
%
\begin{align}
	&\sum_{k,h} \Big(\widehat{P}^{k,\mathsf{all}}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\Big)V_{h+1}^k 
	\nonumber\\
	&\qquad \qquad 
	=\sum_{k,h} \Big(\widehat{P}^{k,\mathsf{all}}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\Big)V_{h+1}^{\star}+ \sum_{k,h} \Big(\widehat{P}^{k,\mathsf{all}}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\Big)\big(V_{h+1}^k-V_{h+1}^{\star}\big).
	\label{eq:decompose-past-work}
\end{align}
%
The rationale behind this decomposition is as follows: 
%
\begin{itemize}
	\item [(i)] given that $V_{h+1}^{\star}$ is fixed and independent from the data, the first term on the right-hand side of \eqref{eq:decompose-past-work} can be bounded easily using Freedman's inequality; 
	\item [(ii)] the second term on the right-hand side of \eqref{eq:decompose-past-work} would vanish as $V_{h+1}^{k}$ and $V_{h+1}^{\star}$ become exceedingly close (which would happen as $k$ becomes large enough). 
\end{itemize}
%
Such arguments, however, fall short of tightness when analyzing the initial stage of the learning process: given that $V_{h+1}^k-V_{h+1}^{\star}$ cannot be sufficiently small at the beginning, this approach necessarily results in a huge burn-in cost.


	\item {\em Strategy 2: a covering-based argument.} Let us discuss informally another potential strategy that motivates our analysis.  
		We first take a closer look at the relationship between $\widehat{P}^{k,\mathsf{all}}_{s,a,h}$ 
		and $V_{h+1}^k$.  
		Abusing notation by letting $N^{k,\mathsf{all}}_{h}(s,a)$ be the total number of visits to a $(s,a,h)$-tuple before the $k$-th episode in $\mathtt{UCBVI}$, 
		we can easily observe that $\widehat{P}^{k,\mathsf{all}}_{s,a,h}$ and $V_{h+1}^k$ are statistically independent conditioned on the set 
		$\big\{ N^{k,\mathsf{all}}_{h}(s,a)\big\}_{(s,a,k)\in \mathcal{S}\times \mathcal{A}\times [K]}$. 
		Consequently, if we ``pretend'' that $\{N^{k,\mathsf{all}}_{h}(s,a)\}$ are pre-fixed and independent of $\{\widehat{P}^{k,\mathsf{all}}_{s,a,h}\}$, 
		then one can invoke standard concentration inequalities to obtain a high-probability bound on $\sum_{k,h} \big(\widehat{P}^{k,\mathsf{all}}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\big)V_{h+1}^k$ in a desired manner. 
		The next step would then be to invoke a union bound over all possible configurations of $\{N^{k,\mathsf{all}}_{h}(s,a)\}$, 
		so as to eliminate the above independence assumption. 
		The main drawback of this approach, however, is that there are exponentially many (e.g., in $K$) possible choices of $\{N^{k,\mathsf{all}}_{h}(s,a)\}$,  
		inevitably loosening the regret bound. 



		
%Note that $V_{h+1}^k$ is determined by the samples after the $h$-th step up to the $k$-th episode.
%% Then we wonder how these samples is related to $\widehat{P}_{s_h^k,a_h^k,h}$.  
% We can find that, $\widehat{P}^k_{s_h^k,a_h^k,h}$ \emph{at most decides the count} after the $h$-th step. Therefore, if we pretend that the visitation counts $\{N^k_{h}(s,a)\}_{s,a,h,k}$ are fixed independent of $\widehat{P}^k_{s_h^k,a_h^k,h}$, then we can obtain a  desired high-probability upper bound $\widetilde{O}\big( \sqrt{\mathbb{V}(P_{s_h^k,a_h^k,h}, V_{h+1}^k)/N_{h}^k(s_h^k,a_h^k)} \big)$ on the quantity of interest $(\widehat{P}^k_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h})V_{h+1}^k$.  One natural strategy is then to first develop such bounds for $\{N_{h}^k(s,a)\}_{s,a,h,k}$, and  then invoke a covering argument that applies a union bound over  all possible choices of $\{N_{h}^k(s,a)\}_{s,a,h,k}$. 

% To address the above-mentioned issue, the key lies in decoupling the statistical dependence between $\widehat{P}^k_{s_h^k,a_h^k,h}$ and $V_{h+1}^k$.


%Unfortunately, there are exponentially many choices for $\{N_{h}^k(s,a)\}_{s,a,h,k}$,  thus preventing one from invoking the uniform convergence argument. 

 
\end{itemize}


%\paragraph{A high-level diagnosis of the technical obstacles.} 
%%
%Let us first single out a technical challenge on a high level. 
%In the regret analysis, one central step is to control the error term $(\widehat{P}-P)V$,  where $\widehat{P}$ represents a certain empirical transition kernel (constructed based on collected data), 
%$P$ stands for the true transition kernel, and $V$ is a certain value function estimate. 
%The analytical difficulty arises in that $V$ could often be dependent on $\widehat{P}$ in a statistically complicated manner. 
%%
%One strategy that has been previously used for model-based algorithms \citep{azar2017minimax,dann2017unifying,zhang2020reinforcement} decomposes
%%
%$$
%	(\widehat{P}-P)V =(\widehat{P}-P)V^{\star} +(\widehat{P}-P)(V-V^{\star}).
%$$
%%
%Given that $V^{\star}$ is independent of $\widehat{P}$, one can apply Bernstein-style concentration inequalities to control the first term $(\widehat{P}-P)V^{\star}$. As for the second term $(\widehat{P}-P)(V-V^{\star})$, note that $V-V^{\star}$ might become exceedingly small when $K$ is large enough;  
%if this were the case, then one could simply bound this term via $\|\widehat{P}-P\|_1  \|V-V^{\star}\|_{\infty}$, which would become a negligible lower-order term. This approach, however, becomes problematic when $K$ is not large enough, 
%as this crude bound 
%could lead to an extra $\widetilde{O}(\sqrt{S})$ factor in the lower-order term  due to the use of $\|\widehat{P}-P\|_1$. 
%


%\begin{comment}
%
%A couple of strategies have been adopted in prior works to address this issue. 
%%
%\begin{itemize}
%	\item The first strategy, which has been commonly used for model-based algorithms \citep{azar2017minimax,dann2017unifying,zhang2020reinforcement}, decomposes the error term as  
%	%
%	$$
%		(\widehat{P}-P)V =(\widehat{P}-P)V^{\star} +(\widehat{P}-P)(V-V^{\star}).
%	$$
%	%
%Given that $V^{\star}$ is independent of $\widehat{P}$, one can apply Bernstein-style concentration inequalities to control the first term $(\widehat{P}-P)V^{\star}$. As for the second term $(\widehat{P}-P)(V-V^{\star})$, note that $V-V^{\star}$ might become exceedingly small when $K$ is large enough;  
%if this were the case, then one could simply bound this term via $\|\widehat{P}-P\|_1  \|V-V^{\star}\|_{\infty}$, which would become a negligible lower-order term. This approach, however, becomes problematic when $K$ is not large enough, 
%as this crude bound 
%could lead to an extra $\widetilde{O}(\sqrt{S})$ factor in the lower-order term  due to the use of $\|\widehat{P}-P\|_1$. 
%
%	
%	\item We now turn to the analysis of model-free algorithms \citep{jin2018q,zhang2020almost,li2021breaking,menard2021ucb}. 
%		One way that has been used in earlier analyses (e.g.,  \citet{jin2018q}) can be described as follows: 
%		the learner first computes a value estimate $V$, and then employs news samples to construct $\widehat{P}$, 
%		which facilitates the analysis of $(\widehat{P}-P)V$ owing to certain independence between $(\widehat{P}-P)$ and $V$. 
%		Nevertheless, this strategy falls short of sample efficiency (even in an asymptotic large-sample sense), since only very few samples collected after computation of $V$ are utilized to construct $\widehat{P}$.  
%		To enable asymptotic sample optimality, \citet{zhang2020reinforcement} proposed a solution called reference-advantage decomposition (or variance reduction). This strategy maintains a reference value estimate $V^{\mathrm{ref}}$ (computed using a previous batch of data in a way that obeys $V \approx V^{\mathrm{ref}}$) and decomposes $$(\widehat{P}-P)V = (\widehat{P}-P)V^{\mathrm{ref}}+(\widehat{P}-P)(V-V^{\mathrm{ref}}),$$
%where the first term can be easily controlled if $\widehat{P}$ is based on data collected after $V^{\mathrm{ref}}$ is determined, and the second term vanishes if $V\approx V^{\mathrm{ref}}$.  
%%		
%Unfortunately, this strategy also fails to enable all-regime optimality, 
%since even computing the first version of $V^{\mathrm{ref}}$ at the initial stage already requires a large sample size.
%
%
%\end{itemize}
%
%
%
%\end{comment}

%
%%
%To address the above-mentioned issue, the key lies in decoupling the statistical dependence between $\widehat{P}^k_{s_h^k,a_h^k,h}$ and $V_{h+1}^k$. 
%Let us first look at the relationship between $\widehat{P}^k_{s_h^k,a_h^k,h}$ 
% and $V_{h+1}^k$.  Let $\{N^k_h(s,a)\}_{(s,a,h)}$ be the number of visits to a state-action-step tuple $(s,a,h)$ before the $k$-th episode. 
%Note that $V_{h+1}^k$ is determined by the samples after the $h$-th step up to the $k$-th episode.
% % Then we wonder how these samples is related to $\widehat{P}_{s_h^k,a_h^k,h}$.  
%We can find that, $\widehat{P}^k_{s_h^k,a_h^k,h}$ \emph{at most decides the count} after the $h$-th step.
%Therefore, if we pretend that the visitation counts $\{N^k_{h}(s,a)\}_{s,a,h,k}$ are fixed independent of $\widehat{P}^k_{s_h^k,a_h^k,h}$, then we can obtain a  desired high-probability upper bound $\widetilde{O}\big( \sqrt{\mathbb{V}(P_{s_h^k,a_h^k,h}, V_{h+1}^k)/N_{h}^k(s_h^k,a_h^k)} \big)$ on the quantity of interest $(\widehat{P}^k_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h})V_{h+1}^k$. 
%One natural strategy is then to first develop such bounds for $\{N_{h}^k(s,a)\}_{s,a,h,k}$, and 
%then invoke a covering argument that applies a union bound over  all possible choices of $\{N_{h}^k(s,a)\}_{s,a,h,k}$. 
%
%Unfortunately, there are exponentially many choices for $\{N_{h}^k(s,a)\}_{s,a,h,k}$, 
%thus preventing one from invoking the uniform convergence argument. 
%In order to perform proper compression of the set of all possible choices of $\{N_{h}^k(s,a)\}_{(s,a,h,k)}$, 
%we introduce doubling batches (as described in Section~\ref{sec:alg})  
%during estimation of the value functions and Q-functions. 
% To facilitate analysis, we have the following definitions.
%



\subsection{Our approach}\label{sec:tec1}


%
In light of the covering-based argument in Section~\ref{sec:technical-barrier-prior}, 
one can only hope this analysis strategy to work if substantial compression (i.e., a significantly reduced covering number) 
of the visitation counts  is plausible. 
This motivates our introduction of the doubling batches as described in Section~\ref{sec:alg}, 
so that for each $(s,a,h)$-tuple, the empirical model $\widehat{P}_{s,a,h}$  and its associated visitation count $N_{h}(s,a)$ (for the associated batch) are updated at most $\log_2K$ times (see line~\ref{line:trigger-set} of Algorithm~\ref{alg:main}). 
Compared to the original $\mathtt{UCBVI}$ that recomputes the transition model in every episode, 
our algorithm allows for significant reduction of the covering number of the visitation counts,  
thanks to its much less frequent updates.

%, as we shall elucidate below. 



%
%\begin{definition}[Doubling batch and estimations of transitions, rewards, and squared rewards]\label{def:batch} For any $(s,a,h)$, the $i$-th batch for $(s,a,h)$ is the collection of $2^{i-2}+j$-th sample for $j=1,2,\ldots,2^{i-2}$ for $i\geq 2$, and the first sample for $i=1$.\footnote{ It is possible that the total count of $(s,a,h)$ is less than $K$ after $K$ episodes. In this case, we add some virtual samples to fill the $\log_2(K)+1$ batches.} We define $\widehat{P}^{(j)}_{s,a,h}$,  $\widehat{r}^{(j)}_h(s,a)$ and $\widehat{\sigma}^{(j)}_h(s,a)$ to be the empirical transition probability, the empirical reward, and the empirical squared reward of the $j$-th batch for $(s,a,h)$,  respectively. For completeness, we define the $0$-th batch for each $(s,a,h)$ as an empty set, and set $\widehat{P}^{(0)}_{s,a,h} = \frac{1}{S}\mathbf{1}$, $\widehat{r}^{(0)}_h(s,a)= 0$ and $\widehat{\sigma}^{(0)}_h(s,a)=0$ for the $0$-th batch.  
%\end{definition}


%\begin{definition}[Doubling batch and estimations of transitions, rewards, and squared rewards]\label{def:batch} For any $(s,a,h)$, the $i$-th batch for $(s,a,h)$ is the collection of $2^{i-2}+j$-th sample for $j=1,2,\ldots,2^{i-2}$ for $i\geq 2$, and the first sample for $i=1$.\footnote{ It is possible that the total count of $(s,a,h)$ is less than $K$ after $K$ episodes. In this case, we add some virtual samples to fill the $\log_2(K)+1$ batches.} We define $\widehat{P}^{(j)}_{s,a,h}$,  $\widehat{r}^{(j)}_h(s,a)$ and $\widehat{\sigma}^{(j)}_h(s,a)$ to be the empirical transition probability, the empirical reward, and the empirical squared reward of the $j$-th batch for $(s,a,h)$,  respectively. For completeness, we define the $0$-th batch for each $(s,a,h)$ as an empty set, and set $\widehat{P}^{(0)}_{s,a,h} = \frac{1}{S}\mathbf{1}$, $\widehat{r}^{(0)}_h(s,a)= 0$ and $\widehat{\sigma}^{(0)}_h(s,a)=0$ for the $0$-th batch.  
%\end{definition}
%

Similar to \eqref{eq:key}, we are in need of bounding the following term when analyzing Algorithm~\ref{alg:main}: 
%
\begin{equation}
	\sum_{k,h} \Big(\widehat{P}^{k}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\Big)V_{h+1}^k .
\end{equation}
%
In what follows, we present our key ideas that enable tight analysis of this quantity, which constitute our main technical innovations.  
The complete regret analysis for Algorithm~\ref{alg:main} is postponed to Section~\ref{app:thmmain}. 



\subsubsection{Key concept: profiles}  
\label{eq:sec-profile}
 %
%To facilitate analysis, let us first introduce the following convenient notation. 
%
One of the most important concepts underlying our analysis for Algorithm~\ref{alg:main} is the so-called ``profile'', defined below. 
%
\begin{definition}[Profile]
	\label{defn:profile}
%	
Consider any combination $\{N_{h}^{k,\mathsf{all}}(s,a)\}_{(s,a,h,k)\in \mathcal{S}\times \mathcal{A}\times [H]\times [K]}$. 
For any $k\in [K]$, define
%
\begin{subequations}
%
\begin{align}
	\forall (s,a,h)\in \mathcal{S}\times \mathcal{A}\times [H]: \quad 
	I^k_{s,a,h} \coloneqq \begin{cases} \max\big\{ j\in \mathbb{N}: 2^{j-1} \leq N_{h}^{k,\mathsf{all}}(s,a) \big\} , & \text{if }N_{h}^{k,\mathsf{all}}(s,a)>0; \\
	0, & \text{if }N_{h}^{k,\mathsf{all}}(s,a)=0. \end{cases}
\end{align}
%
The profile for the $k$-th episode $(1\leq k\leq K)$ and the total profile are then defined respectively as 
%
\begin{align}
	\mathcal{I}^k &\coloneqq \big\{I^k_{s,a,h} \big\}_{(s,a,h)\in \mathcal{S}\times \mathcal{A}\times [H]} \\
	\text{and}\qquad \mathcal{I} &\coloneqq \{\mathcal{I}^k\}_{k=1}^K.
	\label{eq:defn-profile-Ik}
\end{align}
%
\end{subequations}
%
%We further let $\mathcal{I} \coloneqq \{\mathcal{I}^k\}_{k=1}^K$ be the total profile.
%  
\end{definition}
%
Clearly, once a total profile $\mathcal{I}$ w.r.t.~$\{N_h^{k,\mathsf{all}}(s,a)\}$ is given, one can write
%
\begin{equation}
	\widehat{P}^{k}_{s,a,h} = \widehat{P}^{(I^k_{s,a,h})}_{s,a,h},\qquad \forall (s,a,h,k)\in \mathcal{S}\times \mathcal{A}\times [H]\times [K].
	\label{eq:relation-profile-k}
\end{equation}
%
In other words, a total profile specifies all the time instances and locations when the empirical model is updated. 
Given that each $N_h^k(s,a)$ is recomputed only when the associated empirical model is updated (see line~\ref{line:Nh-update} of Algorithm~\ref{alg:main}), 
the total profile also provides a succinct representation of the set $\{N_h^k(s,a)\}$. 




In order to quantify the degree of compression Definition~\ref{defn:profile} offers when representing the update times and locations, 
we provide an upper bound on the number of possible total profiles in the lemma below. 
%
\begin{lemma}\label{lemma:key2} 
	Suppose that $K\geq SAH\log_2K$. Then the number of all possible total profiles w.r.t.~Algorithm~\ref{alg:main} is at most $$(4SAHK)^{SAH\log_2K +1}.$$ 
\end{lemma}
%
\begin{proof}
	Define the following set (which will be useful in subsequent analysis as well)
%
\begin{equation}\mathcal{C} \coloneqq 
	\Big\{ \mathcal{I}=\{\mathcal{I}^1,\ldots,\mathcal{I}^K\} \,\Big|\, \mathcal{I}^1\leq \mathcal{I}^2\leq \cdots \leq \mathcal{I}^K, 
	\mathcal{I}^{k}\in \big\{0, 1,\cdots,\log_2K\big\}^{SAH} \text{ for all } 1\leq k\leq K \Big\}.
	\label{eq:defn-C-choice}
\end{equation}
%
Due to the monotonicity constraints, it is easily seen that the total profile of any set $\{N_h^k(s,a)\}$ must lie within $\mathcal{C}$. 
It then boils down to proving that  
$|\mathcal{C}|\leq (4SAHK)^{SAH\log_2K +1}$, which can be accomplished via elementary combinatorial calculations. 
The complete proof is deferred to Appendix~\ref{app:pfkey2}. 
\end{proof}
%
%\begin{remark}
In comparison to using $\{N_h^{k,\mathsf{all}}(s,a)\}$ to encode all update times and locations ---  which might have exponentially many (in $K$) possibilities --- 
the use of doubling batches in Algorithm~\ref{alg:main} allows for remarkable compression (as the exponent of the number of possibilities only scales logarithmically in $K$).  


%\end{remark}



\subsubsection{Decoupling the statistical dependency}
\label{sec:decoupling-all}

\paragraph{An expanded view of randomness w.r.t.~state transitions.} 


%With regards to the online RL, we can define a natural filtration induced by the sequential learning process. The formal definition is as follows. 


%%
%  \begin{definition}[Online filtration]\label{filt1}
%	  For any $(h,k)\in [H+1]\times [K]$, let $\mathcal{F}_h^k$ be the $\sigma$-algebra induced by events happening before the $h$-th step in the $k$-th episode. Then $\{\mathcal{F}_h^k\}_{(h,k)\in [H]\times [K]}$ --- with proper ordering in accordance with the sequential learning process --- constructs a filtration $\mathcal{F}_{\mathrm{online}}$, which we shall refer to as ``online filtration'' throughout. 
%  \end{definition}
%



To facilitate analysis, we find it helpful to look at a different yet closely related way to generate independent samples from a generative model.   
%
\begin{definition}[An expanded sample set from a generative model]\label{def:filt2}
	Let $\mathcal{D}^{\mathsf{expand}}$ be a set of $SAHK$ independent samples generated as follows: 
	for each $(s,a,h)\in \mathcal{S}\times \mathcal{A}\times [H]$, draw $K$ independent samples $(s,a,h,s'^{,(i)})$ obeying 
	$s'^{,(i)} \overset{\mathrm{ind.}}{\sim} P_{s,a,h}$ ($1\leq i\leq K$).
\end{definition}
%
Crucially, $\mathcal{D}^{\mathsf{expand}}$ can be viewed as an expansion of the original dataset --- denoted by $\mathcal{D}^{\mathsf{original}}$ --- collected in online learning,  
as we can couple the data collection processes of $\mathcal{D}^{\mathsf{original}}$ and $\mathcal{D}^{\mathsf{expand}}$ as follows: 
%
\begin{itemize}
	\item[(i)] generate $\mathcal{D}^{\mathsf{expand}}$ before the beginning of the online process;
	\item[(ii)] during the online learning process, whenever a sample needs to be drawn from $(s,a,h)$, 
		one can take an unused sample of $(s,a,h)$ from $\mathcal{D}^{\mathsf{expand}}$ without replacement. 
\end{itemize}
%
\noindent 
This allows one to conduct analysis alternatively based on the expanded sample set $\mathcal{D}^{\mathsf{expand}}$, 
which is sometimes more convenient (as we shall detail momentarily). 
Unless otherwise noted, all analyses in our proof assume that $\mathcal{D}^{\mathsf{original}}$ and $\mathcal{D}^{\mathsf{expand}}$ are {\em coupled} through the above simulation process. 



In the sequel, we let $\widehat{P}^{(j)}_{s,a,h}$ (cf.~the beginning of Section~\ref{sec:tec})  denote the empirical probability vector based on the $j$-th batch of data from $\mathcal{D}^{\mathsf{original}}$ and $\mathcal{D}^{\mathsf{expand}}$ interchangeably, as long as it is clear from the context. 






\paragraph{A starting point: a basic decomposition.} 
%
We now describe our approach to tackling the complicated statistical dependency between $\widehat{P}_{s,a,h}^k$ and $V_{h+1}^k$. 
To begin with, from relation~\eqref{eq:relation-profile-k} we can write
%
\begin{align}
 & \sum_{k=1}^{K}\sum_{h=1}^{H}\Big\langle\widehat{P}_{s_{h}^{k},a_{h}^{k},h}^{k}-P_{s_{h}^{k},a_{h}^{k},h},V_{h+1}^{k}\Big\rangle=\sum_{k=1}^{K}\sum_{h=1}^{H}\Big\langle\widehat{P}_{s_{h}^{k},a_{h}^{k},h}^{(I_{s_{h}^{k},a_{h}^{k},h}^{k,\mathsf{true}})}-P_{s_{h}^{k},a_{h}^{k},h},V_{h+1}^{k}\Big\rangle\nonumber\nonumber\\
 & =\sum_{l=0}^{\log_{2}K}\sum_{s,a,h}\bigg\langle\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h},\,\sum_{k=1}^{K}\mathds1\left\{ (s_{h}^{k},a_{h}^{k})=(s,a),I_{s,a,h}^{k,\mathsf{true}}=l\right\} V_{h+1}^{k}\bigg\rangle\nonumber\nonumber\\
 & \leq\sum_{l=1}^{\log_{2}K}\sum_{s,a,h}\bigg\langle\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h},\,\sum_{k=1}^{K}\mathds1\left\{ (s_{h}^{k},a_{h}^{k})=(s,a),I_{s,a,h}^{k,\mathsf{true}}=l\right\} V_{h+1}^{k}\bigg\rangle+ SAH^{2}\nonumber\nonumber\\
 & =\sum_{l=1}^{\log_{2}K}\sum_{j=1}^{2^{l-1}}\bigg\{\sum_{s,a,h}\Big\langle\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h},V_{h+1}^{k_{l,j,s,a,h}}\Big\rangle\bigg\}+SAH^{2},
	\label{eq:PV-sum-decompose}
\end{align}
%
where $\mathcal{I}^{\mathsf{true}}=\{\mathcal{I}^{1,\mathsf{true}},\cdots,\mathcal{I}^{K,\mathsf{true}}\}$
with $\mathcal{I}^{k,\mathsf{true}}=\{I_{s,a,h}^{k,\mathsf{true}}\}$  
denotes the total profile w.r.t.~the true visitation counts in the online learning process, 
$k_{l,j,s,a,h}$ denotes the episode index of the sample that visits $(s,a,h)$ for the $(2^{l-1}+j)$-th time in the online learning process, 
and we take $V_{h+1}^k=0$ for any $k>K$. Here, the third line makes use of the fact that $0\leq V_{h+1}^{k} (s) \leq H$ for all $s\in \mathcal{S}$. 
The decomposition \eqref{eq:PV-sum-decompose} motivates us to first control the term $\sum_{s,a,h}\big\langle\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h},V_{h+1}^{k_{l,j,s,a,h}}\big\rangle$, 
leading to the following 3-step analysis strategy.  
%
\begin{itemize}
	\item[1)] For any given total profile $\mathcal{I} \in \mathcal{C} $ and any fixed $1\leq l\leq \log_2K$, 
		develop a high-probability bound on a weighted sum taking the following form
		%
		\begin{equation}
			\sum_{s,a,h} \Big(\widehat{P}^{(l)}_{s,a,h}-P_{s,a,h} \Big) X_{h+1,s,a},
			\label{eq:P-X-term}
		\end{equation}
		%
		where each vector $X_{h+1,s,a}$ is any deterministic function of $\mathcal{I}$ and the samples collected for steps $h'\geq h+1$. 
		Given the statistical independence between $\widehat{P}^{(l)}_{s,a,h}$ and those samples for steps $h'\geq h+1$ (in the view of $\mathcal{D}^{\mathsf{expand}}$), 
		we can bound \eqref{eq:P-X-term} using standard martingale concentration inequalities. 
		
		
	\item[2)] Take the union bound over all possible $\mathcal{I}\in \mathcal{C}$  
		--- with the aid of Lemma~\ref{lemma:key2} --- to obtain a uniform control of the term \eqref{eq:P-X-term}, 
		simultaneously accounting for all $\mathcal{I} \in \mathcal{C} $ and all associated sequences $\{X_{h+1,s,a}\}$. 



	\item[3)] We then demonstrate that the above uniform bounds can be applied to the decomposition \eqref{eq:PV-sum-decompose} to obtain a desired bound. 
			%
		%\begin{equation}
		%	\sum_{k=1}^K \sum_{h=1}^H \Big(\widehat{P}^{(j_{k,h})}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h} \Big) V_{h+1}^k,
		%	\label{eq:P-V-final-term}
		%\end{equation}
		%
		%where we abbreviate $j_{k,h}=J_{s_h^k,a_h^k,h}^k$. 
		%In light of Properties~(a) and (b) of Algorithm~\ref{alg:main-fixed-profile}, 
		%our proof is based on proper decomposition of \eqref{eq:P-V-final-term} into superposition of terms taking the form of \eqref{eq:P-X-term}. 

		
\end{itemize}
%




\paragraph{Main steps.} 
We now carry out the above three steps. 

\medskip \noindent
 {\em \underline{Steps 1) and 2).}} Let us first specify the types of vectors $\{X_{h,s,a}\}$ mentioned above in \eqref{eq:P-X-term}. 
 For each total profile $\mathcal{I} \in \mathcal{C}$ (cf.~\eqref{eq:defn-C-choice}), 
 consider any set $\big\{ \mathcal{X}_{h,\mathcal{I}} \big\}_{1\leq h\leq H}$ obeying: for each $1\leq h\leq H$,  
%
\begin{itemize}

	\item  $\mathcal{X}_{h+1,\mathcal{I}}$ is given by a {\em deterministic} function of $\mathcal{I}$ and 
		\[
			\Big\{\widehat{P}^{(I^k_{s,a,h'})}_{s,a,h'},\widehat{r}^{(I^k_{s,a,h'})}_{h'}(s,a),\widehat{\sigma}^{(I^k_{s,a,h'})}_{h'}(s,a) \Big\}_{ h< h' \leq H, (s,a,k)\in \mathcal{S}\times \mathcal{A} \times [K]};
		\]

	\item $\|X\|_{\infty}\leq H$ for each vector $X\in \mathcal{X}_{h,\mathcal{I}}$;
%\item $|\mathcal{X}_{h+1}|\leq W$ for any $1\leq h \leq H$ and some $W\in \mathbb{N}$; 

	\item $\mathcal{X}_{h,\mathcal{I}}$  is a set of no more than $K+1$ non-negative vectors in $\mathbb{R}^S$, and contains the all-zero vector $0$.

\end{itemize}
%
Given such a construction of $\big\{ \mathcal{X}_{h,\mathcal{I}} \big\}$, 
we can readily conduct  Steps 1) and 2), with a uniform concentration bound stated below.  
%
\begin{lemma}\label{lemma:uniform}
	Suppose that $K\geq SAH\log_2K$, and construct a set $\big\{ \mathcal{X}_{h,\mathcal{I}} \big\}_{1\leq h\leq H}$ for each $\mathcal{I} \in \mathcal{C}$ 
	satisfying the above properties. 
	%For every total profile $\mathcal{I} \in \mathcal{C}$ (cf.~\eqref{eq:defn-C-choice}), 
	%consider a set $\big\{ \mathcal{X}_{h,\mathcal{I}} \big\}_{1\leq h\leq H}$ such that:  
	 %
Then with probability at least $1- \delta'$, 
%
%
\begin{align}
	&\sum_{s,a,h\in \mathcal{S}\times \mathcal{A}\times [H]}\big\langle \widehat{P}_{s,a,h}^{(l)}-P_{s,a,h}, X_{h+1,s,a} \big\rangle 
	\leq \sum_{s,a,h\in \mathcal{S}\times \mathcal{A}\times [H]} \max\Big\{ \big\langle \widehat{P}_{s,a,h}^{(l)}-P_{s,a,h}, X_{h+1,s,a} \big\rangle, 0 \Big\}
	\nonumber\\
	&\qquad\quad \leq \sqrt{\frac{8}{2^{l-2}}\sum_{s,a,h}\mathbb{V}\big(P_{s,a,h},X_{h+1,s,a}\big)\left(6SAH\log_{2}^{2}K+\log\frac{1}{\delta'}\right)} \notag\\
	&\qquad\qquad\qquad\qquad+\frac{4H}{2^{l-2}}\left(6SAH\log_{2}^{2}K+\log\frac{1}{\delta'}\right)\label{eq:xx1-aux-1}
\end{align}
%
holds simultaneously for all $\mathcal{I} \in \mathcal{C}$, all $2\leq l\leq\log_{2}K+1$, and all sequences $\{X_{h,s,a}\}_{(s,a,h)\in\mathcal{S}\times\mathcal{A}\times[H]}$
obeying $X_{h,s,a}\in\mathcal{X}_{h+1,\mathcal{I}},$ $\forall (s,a,h)\in \mathcal{S}\times\mathcal{A}\times[H]$.  Here, we recall that $\delta'=\frac{\delta}{200SAH^2K^2}$. 
\end{lemma}
%
\begin{proof} 
	We first invoke the Freedman inequality to bound the target quantity for any fixed $\mathcal{I}\in \mathcal{C}$, any fixed integer $l$, and 
	any fixed feasible sequence $\{X_{h,s,a}\}$, 
	before applying the union bound to establish uniform control. 
See Appendix~\ref{app:pfuniform} for details. \end{proof}



\medskip \noindent
 {\em \underline{Step 3).}} 
%
Next, we turn to Step 3), which is accomplished via the following lemma. 
Note that we also provide upper bounds for two additional quantities: $\sum_{k,h}\max\big\{\big\langle\widehat{P}_{s_{h}^{k},a_{h}^{k},h}^{k}-P_{s_{h}^{k},a_{h}^{k},h},V_{h+1}^{k}\big\rangle,0\big\}$ 
and $\sum_{k,h}\big\langle\widehat{P}_{s_{h}^{k},a_{h}^{k},h}^{k}-P_{s_{h}^{k},a_{h}^{k},h},\big(V_{h+1}^{k}\big)^{2}\big\rangle$, 
which will be useful in subsequent analysis. 
%
\begin{lemma}\label{lemma:decouple}
Suppose that $K\geq SAH\log_2K$. With probability exceeding $1-\delta'$, we have
%
\begin{align*} 
	& \sum_{k=1}^{K}\sum_{h=1}^{H}\Big\langle\widehat{P}_{s_{h}^{k},a_{h}^{k},h}^{k}-P_{s_{h}^{k},a_{h}^{k},h},V_{h+1}^{k}\Big\rangle
	\leq \sum_{k=1}^{K}\sum_{h=1}^{H}\max\Big\{\Big\langle\widehat{P}_{s_{h}^{k},a_{h}^{k},h}^{k}-P_{s_{h}^{k},a_{h}^{k},h},V_{h+1}^{k}\Big\rangle,0\Big\} \\
	& \qquad\leq \sqrt{16(\log_{2}K)\sum_{k=1}^{K}\sum_{h=1}^{H}\mathbb{V}\big(P_{s_{h}^{k},a_{h}^{k},h},V_{h+1}^{k}\big)\left(6SAH\log_{2}^{2}K+\log\frac{1}{\delta'}\right)} \\
	&\qquad\qquad\qquad\qquad +49SAH^{2}\log_{2}^{3}K+8H(\log_{2}K)\log\frac{1}{\delta'}
\end{align*}
%
and
%
\begin{align*} 
	& \sum_{k=1}^{K}\sum_{h=1}^{H}\Big\langle\widehat{P}_{s_{h}^{k},a_{h}^{k},h}^{k}-P_{s_{h}^{k},a_{h}^{k},h},\big(V_{h+1}^{k}\big)^{2}\Big\rangle\\
 & \qquad\leq8H\sqrt{(\log_{2}K)\sum_{k=1}^{K}\sum_{h=1}^{H}\mathbb{V}\big(P_{s_{h}^{k},a_{h}^{k},h},V_{h+1}^{k}\big)\left(6SAH\log_{2}^{2}K+\log\frac{1}{\delta'}\right)}\\
	&\qquad\qquad\qquad+49SAH^{3}\log_{2}^{3}K+8H^2(\log_{2}K)\log\frac{1}{\delta'}.
\end{align*}
% 
\end{lemma}
%
\begin{proof} This result is proved by combining the uniform bound in Lemma~\ref{lemma:uniform} with the decomposition~\eqref{eq:PV-sum-decompose}. 
See Appendix~\ref{app:pfdecouple}. \end{proof}


Thus far, we have obtained high-probability bounds on the most challenging terms. The complete proof of Theorem~\ref{thm1} will be presented next in Section~\ref{app:thmmain}. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%% old proof %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{comment}

\paragraph{An auxiliary algorithm for a fixed total profile.} 
%
In order to decouple the statistical dependency between $\widehat{P}_{s,a,h}^k$ and $V_{h+1}^k$, 
we find it helpful to introduce an auxiliary algorithm tailored to a fixed total profile. 
For any given total profile $\mathcal{I} \in \mathcal{C}$ (cf.~\eqref{eq:defn-C-choice}), consider the following updates operating upon the expanded sample set $\mathcal{D}^{\mathsf{expand}}$, 
where $\widehat{r}^{(j)}_h(s,a)$ (resp.~$\widehat{\sigma}^{(j)}_h(s,a)$) denotes the empirical reward (resp.~squared reward) w.r.t.~$(s,a,h)$ based on the $j$-th batch of data. 
%

\begin{algorithm}[H]
	\DontPrintSemicolon
\caption{An auxiliary algorithm for a fixed total profile $\mathcal{I}\in \mathcal{C}$ \label{alg:main-fixed-profile}}
	\For{$k=1,2,\ldots,K$} {
			\For{$h=H,H-1,...,1$} {
				%
				\For{$(s,a)\in \mathcal{S}\times \mathcal{A}$} {

					\vspace{-3ex}
					\begin{align*} 
						\vspace{-3ex}
						j & \leftarrow J_{s,a,h}^k,~~ N_h^{k}(s,a) \leftarrow 2^{j-2}, \\
						b_h(s,a) &\leftarrow c_1 \sqrt{\frac{   \mathbb{ V}\big(\widehat{P}^{(j)}_{s,a,h} ,V_{h+1}\big) \log \frac{1}{\delta'}  }{ \max\{N_h^k(s,a),1 \} }}+c_2 \sqrt{\frac{\big(\widehat{\sigma}^{(j)}_h(s,a)- (\widehat{r}^{(j)}_h(s,a))^2 \big)\log \frac{1}{\delta'}}{\max\{N_h^k(s,a),1\}}} \qquad\qquad\qquad\qquad\qquad\qquad\nonumber\\
						&\qquad\qquad\qquad +c_3\frac{H\log \frac{1}{\delta'}}{ \max\{N_h^k(s,a) ,1\}  },  
						%\label{eq:update1-aux}  
						\\
						Q_h^{k+1}(s,a) &\leftarrow \min\Big\{    \widehat{r}^{(j)}_h(s,a)+\langle \widehat{P}^{(j)}_{s,a,h}, V_{h+1} \rangle +b_h(s,a)    ,H\Big\},\,
						V^{k+1}_{h}(s) \leftarrow \max_{a}Q^{k+1}_h(s,a).
						%\label{eq:updateq-aux}
					\end{align*}
					\vspace{-3ex}
				}
			}
			%
	}
%\end{algorithmic}
\end{algorithm}
%
A few properties about Algorithm~\ref{alg:main-fixed-profile} are in order. To ease presentation,  our discussions in this subsection are conditioned on the randomness of the rewards (i.e., we focus only on the randomness underlying the empirical transition kernels).
%
\begin{itemize}
	\item[(a)] Given any fixed total profile $\mathcal{I} \in \mathcal{C} $, each estimate $V^{k}_{h}$ computed by Algorithm~\ref{alg:main-fixed-profile} is a {\em deterministic} mapping of $\big\{ \widehat{P}_{h'}^{(j)} \mid h'>h, j\leq \log_2K \big\}$  (when conditioned on the randomness of the rewards); as a result,  $V^{k}_{h}$ is statistically independent of  $\big\{ \widehat{P}_{h_0}^{(j)} \mid h_0\leq h, j\leq \log_2K \big\}$. 

	\item[(b)] Once the total profile $\mathcal{I}^{\mathsf{true}}$ of the visitation counts of Algorithm~\ref{alg:main} is revealed, 
		then the value estimates of Algorithm~\ref{alg:main} are equivalent to those of Algorithm~\ref{alg:main-fixed-profile} with $\mathcal{I}=\mathcal{I}^{\mathsf{true}}$. 
\end{itemize}
%


\end{comment}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%% old proof %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







%%%%%%%%%%%%%%%%%%%%%%%%%%%%% old proof %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
\begin{comment}


%
\begin{lemma}\label{lemma:key1}
	Consider any fixed $\mathcal{J} \in \mathcal{C}$ (cf.~\eqref{eq:defn-C-choice}). 
	For each $1\leq h \leq H$, let $\mathcal{X}_{h+1}$ be a set of $N$ vectors obeying 
\begin{itemize}

\item $\|X\|_{\infty}\leq H$ for each vector $X\in \mathcal{X}_{h+1}$; 
\item  $\mathcal{X}_{h+1}$ is fully determined by $\mathcal{J}$ and 
	$\big\{\widehat{P}^{(J^k_{s,a,h'})}_{s,a,h'},\widehat{r}^{(J^k_{s,a,h'})}_{h'}(s,a),\widehat{\sigma}^{(J^k_{s,a,h'})}_{h'}(s,a) \big\}_{ h< h' \leq H, (s,a,k)\in \mathcal{S}\times \mathcal{A} \times [K]}$; 
%\item $|\mathcal{X}_{h+1}|\leq W$ for any $1\leq h \leq H$ and some $W\in \mathbb{N}$; 
\item the all-zero vector $0\in \mathcal{X}_{h+1}$.

\end{itemize}
%
Then with probability at least $1-\delta$, 
%
\begin{align}
& \Bigg| \sum_{k=1}^K \sum_{h=1}^H \Big(\widehat{P}^{(J^k_{s_h^k,a_h^k,h})}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h} \Big) X^k_{h+1} \Bigg| \nonumber
	\\ & \leq  \sqrt{L\sum_{k=1}^K \sum_{h=1}^H \mathbb{V}\big(P_{s_h^k,a_h^k,h},X^k_{h+1}\big)\bigg(SAH\log W + \log\frac{1}{\delta}\bigg)  } 
	+ LH\bigg(SAH\log W + \log\frac{1}{\delta}\bigg)
\end{align}
%
holds simultaneously for all sequences $\{X^k_{h+1}\}_{(h,k)}$ obeying $X^k_{h+1} \in \mathcal{X}_{h+1},\forall (h,k)\in [H]\times [K]$, 
where $L = 200(\log_2(K)+1)^2$.
\end{lemma}

The proof of Lemma~\ref{lemma:key1} is based on a martingale concentration inequality in the view of $\mathcal{F}_{\mathrm{gen}}$. We first fix the choice of $X_{h+1}^k\in \mathcal{X}_{h+1}$ for each $(h,k)$, and then verify that $\sum_{s,a}\sum_{h=1}^H 2^{l-2}(\widehat{P}^{(l)}_{s,a,h}-P_{s,a,h}) Y_{s,a,h}$ is a martingale difference for any $l\geq 2$ and $\{Y_{s,a,h}\}_{(s,a,h)}$ as long as  $Y_{s,a,h}$ is selected from $\{X_{h+1}^k\}_{k=1}^K$ according to some specific rule for any $(s,a,h)$. 
See Appendix~\ref{app:pfseckey1} for the proof of Lemma~\ref{lemma:key1}. 


\end{comment}






% For convenience, we assume that the initial states of all $K$ episodes are independently generated from $\mu$ before the online learning process starts. 





%Then  $\widetilde{F}(SAHK)$ could be viewed as an expansion of $\mathcal{F}_{H+1}^k$, since one could simulate the whole online learning process using the $SAHK$ independent samples in the generative filtration. In other words, for each event in the online filtration $\mathcal{F}_{\mathrm{online}}$, it is measurable w.r.t.~the generative filtration $\mathcal{F}_{\mathrm{gen}}$.  This allows one to conduct analysis based on the generative filtration (as we shall detail momentarily). 
% % In particular, in Lemma~\ref{lemma:key1}, we will prove a concentration inequality under the generative filtration. 
% We also remark that we will only use the generative filtration $\mathcal{F}_{\mathrm{gen}}$ when necessary,  given that the analysis under the online filtration $\mathcal{F}_{\mathrm{online}}$ is more natural for an online learning problem. 





%%%%%%%%%%%%%%%%%%%%%%%%%%%%% old proof %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{comment}

  \begin{definition}[Generative filtration]\label{def:filt2}
    Consider an order over all state-action pairs in $\mathcal{S}\times \mathcal{A}$ such that  
 $\mathcal{S}\times \mathcal{A} = \{ (s^{(i)},a^{(i)})\}_{i=1}^{SA}$. 
 %The samples  are draw in an increasing order from the $H$-th step to the first step, where each $(s,a,h)$ is sampled for $K$ times.  
  Let us employ the following sampling order of the state-action-step tuples: 
 %
 \begin{align}
	 \begin{array}{cccc}
(s^{(1)},a^{(1)},H) & (s^{(2)},a^{(2)},H) & \cdots & (s^{(SA)},a^{(SA)},H)\\
(s^{(1)},a^{(1)},H-1) & (s^{(2)},a^{(2)},H-1) & \cdots & (s^{(SA)},a^{(SA)},H-1)\\
 & \cdots\\
(s^{(1)},a^{(1)},1) & (s^{(2)},a^{(2)},1) & \cdots & (s^{(SA)},a^{(SA)},1)
\end{array}
 \end{align}
 %
where for each $(s,a,h)$ we draw $K$ independent sample transitions from the generative model.  
	  For any $1\leq t\leq K$, define $\overline{\mathcal{F}}_{s,a,h}(t)$ to be the $\sigma$-algebra induced by events happening after the $t$-th sample of $(s,a,h)$ is collected. For any $1\leq z\leq SAHK$,  define $\widetilde{\mathcal{F}}(z) \coloneqq \overline{\mathcal{F}}_{s^{(i)},a^{(i)},h}(t)$, where $(i,h,t)$ is chosen be such that $z = (H-h)\cdot SA\cdot K+ (i-1)\cdot K  + t $. Then (a proper ordering of) $\{\widetilde{F}(z)\}_{z=1}^{SAKH}$ constructs a
 filtration $\mathcal{F}_{\mathrm{gen}}$, which we shall refer to as ``generative filtration'' throughout.
  \end{definition}



%In words, there are a total number of  $SAHK$ samples to be collected ($K$ i.i.d.~samples for each $(s,a,h)$),  and we introduce a sequential ordering of them, with $\widetilde{F}(z)$ denoting the $\sigma$-algebra after the $z$-th sample.  For convenience, we assume that all initial states have been generated from $\mu$ before the online learning process starts. Then  $\widetilde{F}(SAHK)$ could be viewed as an expansion of $\mathcal{F}_{H+1}^k$, since one could simulate the whole online learning process using the $SAHK$ independent samples in the generative filtration. In other words, for each event in the online filtration $\mathcal{F}_{\mathrm{online}}$, it is measurable w.r.t.~the generative filtration $\mathcal{F}_{\mathrm{gen}}$.  This allows one to conduct analysis based on the generative filtration (as we shall detail momentarily). 
% % In particular, in Lemma~\ref{lemma:key1}, we will prove a concentration inequality under the generative filtration. 
% We also remark that we will only use the generative filtration $\mathcal{F}_{\mathrm{gen}}$ when necessary, given that the analysis under the online filtration $\mathcal{F}_{\mathrm{online}}$ is more natural for an online learning problem. 



\iffalse
\paragraph{Decoupling $V$ from $\widehat{P}$ with generative filtration} Below we present the high-level idea to use generative filtration to decouple $V$ from $\widehat{P}$.  Fix $\{n_h(s,a)\}_{(s,a,h)}\in [K]^{SAH}$. Define $\widehat{P}_{s,a,h}$ be the empirical transition model of the first $n_{h}(s,a)$ samples of $(s,a,h)$ under the generative filtration. Now we consider the value function $V$ defined as:
\begin{align}
& V_{H+1}(s) = 0,  \forall s\in \mathcal{S};\nonumber
\\ & V_{h}(s) = \min\{\max_{a} r_h(s,a) + \widehat{P}_{s,a,h}V_{h+1}+b(\widehat{P}_{s,a,h},V_{h+1},n_h(s,a)) ,H\},\forall s\in \mathcal{S}, h = H,H-1,\ldots,1,\label{eq:ls1}
\end{align}
where $b(\cdot,\cdot,\cdot)$ is some proper bonus function. 
Conditioned on  $\widetilde{\mathcal{F}}(SAK(H-h))$, $V_{h+1}$ is fixed, and $\{n_h(s,a)\widehat{P}_{s,a,h}\}_{s,a,h}$ are  mutually independent  multinomial random variables. As a result,  the term
\begin{align}
\sum_{h=1}^H \sum_{s,a}n_h(s,a) (\widehat{P}_{s,a,h} - P_{s,a,h})V_{h+1}
\end{align}
could be viewed as a martingale difference. With concentration inequality (Lemma~\ref{lemma:self-norm}), we can bound this term as 
\begin{align}
\sum_{h=1}^H \sum_{s,a}n_h(s,a) (\widehat{P}_{s,a,h} - P_{s,a,h})V_{h+1} \leq O\left(  \sqrt{\sum_{h=1}^H \sum_{s,a} n_h(s,a)\mathrm{Var}(P_{s,a,h},V_{h+1})\log(\frac{SAH}{\delta})  } + H \log(\frac{SAH}{\delta})\right)\label{eq:cpx1}
\end{align}
with probability $1-\delta$. In comparison, if we bound each $(\widehat{P}_{s,a,h}-P_{s,a,h})V_{h+1}$ by $O\left( \sqrt{\frac{\mathbb{V}(P_{s,a,h},V_{h+1})\log(\frac{SAH}{\delta})}{n_h(s,a)}} + \frac{H\log(\frac{SAH}{\delta})}{n_h(s,a)} \right)$, 
 the total bound would be: with probability $1-\delta$
 \begin{align}
\sum_{h=1}^H \sum_{s,a}n_h(s,a)(\widehat{P}_{s,a,h}-P_{s,a,h})V_{h+1}\leq O\left(  \sqrt{SAH\sum_{h=1}^H \sum_{s,a} n_h(s,a)\mathrm{Var}(P_{s,a,h},V_{h+1})\log(\frac{SAH}{\delta})  } + SAH^2 \log(\frac{SAH}{\delta})\right)\label{eq:cpx21}.
 \end{align}

However,   \eqref{eq:cpx1} only holds for fixed $\{n_h(s,a)\}_{(s,a,h)}$, while \eqref{eq:cpx21} holds for any $\{n_h(s,a)\}_{(s,a,h)}$
\fi 



%\paragraph{Doubling batch updates.}
%%
%We  update the value function and Q-function with the doubling batches.
%Namely, in the $k$-th episode, 
% we choose $\widehat{P}^k_{s,a,h}= \widehat{P}^{(I^k_{s,a,h})}_{s,a,h}$, $\widehat{r}^k_h(s,a) = \widehat{r}^{(I^k_{s,a,h})}_h(s,a)$ and $\widehat{\sigma}^k_h(s,a) = \widehat{\sigma}^{(I^k_{s,a,h})}_h(s,a)$ for any $(s,a,h,k)$. Our update rule is a slightly different from previous doubling update rules \citep{jaksch2010near}, where the algorithm keeps running a policy until the visitation count of some $(s,a,h)$ doubles and then uses the whole dataset to compute the empirical transition model. In contrast, we divide the whole dataset into disjoint batches following Definition~\ref{def:batch}, and only use the latest batch to compute the empirical transition model. We design this update rule because the samples in different batches are not correlated, which could help us decouple the value function and empirical transition model.
%Crucially, our update rule preserves sample efficiency, since the latest batch always contains at least half of the samples. 
%
% 
  




\subsection{Key lemmas}
\label{sec:key-lemmas-tec}
 
As discussed above, under the generative filtration  $\mathcal{F}_{\mathrm{gen}}$, 
the random vector $\widehat{P}^k_{s_h^k,a_h^k,h}$ is conditionally independent of $V_{h+1}^k$ for any $(k,h)\in [K]\times [H]$ if we fix $\mathcal{I}$.
Then we can view the error term $$T_{\mathrm{err}}=\sum_{k=1}^K \sum_{h=1}^H \Big(\widehat{P}^k_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h} \Big) V_{h+1}^k$$  as a martingale difference and obtain a desired  bound. 
Following this intuition, we introduce our key lemma to bound the error term $T_{\mathrm{err}}$ with the doubling batch updates mentioned above.  





%  Let $\mathcal{C}$ be a set which contains all possible values of the total profiles $\mathcal{I}$. One key novelty is to obtain a tight bound on $|\mathcal{C}|$, which we will discuss later.


 Now,  fix any $\mathcal{J}\in \mathcal{C}$, and consider the event $\mathcal{E}(\mathcal{J},\delta)$ defined as follows:
 %
  \begin{align}
	  \mathcal{E}(\mathcal{J},\delta) \coloneqq \left\{\mathcal{I}=\mathcal{J}, \, T_{\mathrm{err}} \leq \sqrt{L\sum_{k=1}^K \sum_{h=1}^H\mathbb{V} \big(P_{s_h^k,a_h^k,h},V_{h+1}^k \big)\bigg(SAH+\log \frac{1}{\delta} \bigg) } + L H \bigg(SAH+\log \frac{1}{\delta} \bigg) \right\}, 
  \end{align}
  %
  where $L$ is a logarithmic term in $(S,A,H,K)$ to be defined shortly. We claim that 
  %
  \begin{equation}
	  \mathrm{Pr}\big(\mathcal{E}(\mathcal{J},\delta)\big)\geq 1- \delta 
	  \label{eq:Pr-E-delta-bound}
  \end{equation}
  %
  for any $\mathcal{J}\in \mathcal{C}$ and $\delta \in (0,1)$.  
Then by applying the union bound over $\mathcal{J} \in \mathcal{C}$ and rescaling $\delta$ as $\delta/|\mathcal{C}|$, we obtain that with probability at least $1-\delta$, 
%
\begin{align}
	T_{\mathrm{err}}\leq  L\sqrt{\sum_{k=1}^K \sum_{h=1}^H\mathbb{V} \big( P_{s_h^k,a_h^k,h},V^k_{h+1} \big)\bigg(SAH+\log\frac{|C|}{\delta}\bigg) } + LH\bigg(SAH+\log\frac{|C|}{\delta}\bigg).\nonumber
\end{align}
%


Consequently, we are left with accomplishing the following two steps:
%
\begin{enumerate}
    \item  Prove that $\mathrm{Pr}(\mathcal{E}(\mathcal{J},\delta))\geq 1-\delta$ (i.e., \eqref{eq:Pr-E-delta-bound}).
    \item Determine $\mathcal{C}$ and  bound $|\mathcal{C}|$ properly.
\end{enumerate}
% (\romannumeral1); (\romannumeral2) 


\end{comment}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%% old proof %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%% old proof %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{comment}

%\paragraph{Proof of inequality~\eqref{eq:Pr-E-delta-bound}.}
%



%\paragraph{Bounding the size of possible profiles $\left|\mathcal{C}\right|$.}
%%
%Next, we turn to the second problem concerning $\left|\mathcal{C}\right|$. 
%
%
%
%In proving Lemma~\ref{lemma:key2}, we use the increasing property that  $J^{\tau}\leq J^{\tau+1},\forall 1\leq\tau \leq K-1$  for $ \mathcal{J} = \{J^1,J^2,\ldots,J^{K}\}\in \mathcal{C}$. The naive bound for the size of  $\mathcal{C}$ is $(\log_2(K)+1)^{SAHK}$, which is too large for our purpose. By virtue of the increasing property, we are actually counting the number of increasing paths in the $SAH$-dimensional grid $ \left\{[\log_2(K)]\cup {0}\right\}^{SAH}$. For each  increasing path, there are at most $SAH(\log_2(K)+1)$ steps and at most $SAH$ directions for each step. Then the proof can be completed with some primitive combinatorial  computations. 
%The detailed proof can be found in Appendix~\ref{app:pfkey2}. 



With Lemma~\ref{lemma:key1} and Lemma~\ref{lemma:key2} in mind, we can invoke a uniform convergence argument to reach the lemma below; 
the proof of this lemma is postponed to Appendix~\ref{app:pfkey3}. 
%
\begin{lemma}\label{lemma:key3} Recall that $\mathcal{I}=\{\mathcal{I}^k\}_{k=1}^K$ is the total profile and the fact that $\widehat{P}^{k}_{s,a,h}=\widehat{P}^{(I^k_{s,a,h})}_{s,a,h}, \widehat{r}^k_{h}(s,a) = \widehat{r}^{(I^k_{s,a,h})}_h(s,a), \widehat{\sigma}_h^k(s,a)=\widehat{\sigma}_h^{(I_{s,a,h}^k)}(s,a)$ for any proper $(s,a,k,h)$. 
 For each $h \times [H]$, let $\mathcal{X}_{h+1}$ be a set of vectors be such that: (1) $\|X\|_{\infty}\leq H$, $\forall X\in \mathcal{X}_{h+1}$ ; (2)  $\mathcal{X}_{h+1}$ is determined by $\{\widehat{P}^{k}_{s,a,h'}, \widehat{r}^k_{h'}(s,a),\widehat{\sigma}^k_{h'}(s,a)\}_{ h+1\leq h'\leq H, 1\leq k\leq K, (s,a)}$ and $\{I^k\}_{k=1}^K$; (3) $|\mathcal{X}_{h+1}|\leq W$ for any $1\leq h \leq H$ and some $W\in \mathbb{N}$; (4) the zero vector $\textbf{0}\in \mathcal{X}_{h+1}$ for each $h\in [H]$. Then with probability at least $1-\delta$, it holds that
\begin{align}
& \Bigg| \sum_{k=1}^K \sum_{h=1}^H \Big(\widehat{P}^{k}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\Big) X^k_{h+1}  \Bigg| \nonumber
\\ & \leq  \sqrt{L_1\sum_{k=1}^K \sum_{h=1}^H \mathbb{V}(P_{s_h^k,a_h^k,h},X^k_{h+1})\bigg( SAH\log W + \log \frac{1}{\delta} \bigg)  } 
	+ L_1H \bigg( SAH\log W + \log \frac{1}{\delta} \bigg) \label{eq:star} 
\end{align}
for any sequence $\{X^k_{h+1}\}_{h,k}$ such that $X^k_{h+1} \in \mathcal{X}_{h+1},\forall (h,k)\in [H]\times [K]$, 
where $L_1 = 4000\log^2_2(K)\log(SAHK)$.
\end{lemma}
%
 



%The full proofs of Lemma~\ref{lemma:key1}, Lemma~\ref{lemma:key2} and Lemma~\ref{lemma:key3} can be found in Appendix~\ref{app:mfsectec}.


In Algorithm~\ref{alg:main}, we compute $V_{h+1}^k$  by the following rule.
\begin{align}
& V^k_{H+1}(s) = 0 ;\forall s\in \mathcal{S}; \nonumber
\\ & V_{h'}^k(s) = \min\left\{ \max_{a} \left( \widehat{r}^k_{h'}(s,a)+ \widehat{P}^k_{s,a,h'}V_{h'+1}^k + b(\widehat{P}^k_{s,a,h'},\widehat{r}^k_{h'}(s,a),\widehat{\sigma}_{h'}^k(s,a), n_h^k(s,a) \right)  ,H\right\}
	%\nonumber\\
%&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\forall s\in \mathcal{S}, h'=H,H-1,\ldots, h+1.\nonumber
\end{align}
%
for all $s\in \mathcal{S}$ and $h'=H,H-1,\ldots, h+1$. 
Here $b(\cdot,\cdot,\cdot,\cdot)$ is some proper bonus function and $n_h^k(s,a)$ is the size of the $I^k_{s,a,h}$-th batch of $(s,a,h)$. 
Then $V_{h+1}^k$ is determined by $\{\widehat{P}^{k}_{s,a,h'}, \widehat{r}^{k}_{h'}(s,a),\widehat{\sigma}^{k}_{h'}(s,a)\}_{ h+1\leq h'\leq H, 1\leq k'\leq k, (s,a)}$ and $\{I^k\}_{k=1}^K$, 
thus allowing us to apply Lemma~\ref{lemma:key3} to bound $T_{\mathrm{err}}$ by choosing $\mathcal{X}_{h+1} = \{V_{h+1}^k\}_{k=1}^K$.
In addition, 
it is worth noting that Lemma~\ref{lemma:key3} is more general compared to our original target to bound $T_{\mathrm{err}}$, since  $\mathcal{X}_{h+1}$ can be chosen as arbitrary functions. 


\end{comment}
