
\section{Technical lemmas}

\begin{lemma}\label{lemma:self-norm}
Let $(M_n)_{n\geq 0}$ be a martingale such that $M_0=0$ and $|M_n-M_{n-1}|\leq c$ for some $c>0$ and any $n\geq 1$. Let $\mathrm{Var}_{n} = \sum_{k=1}^n \mathbb{E}\left[  (M_{k}-M_{k-1})^2 |\mathcal{F}_{k-1}\right]$ for $n\geq 0$, where $\mathcal{F}_k = \sigma(M_1,...,M_{k})$. Then for any positive integer $n$, and any $\epsilon,\delta>0$, one has 
%
\begin{align}
	\mathbb{P} \left[       |M_n|\geq 2\sqrt{2}\sqrt{\mathrm{Var}_n \ln\frac{1}{\delta} } +2\sqrt{\epsilon \ln\frac{1}{\delta} } +2c\ln\frac{1}{\delta} \right]\leq 2\left(\log_2\left(\frac{nc^2}{\epsilon}\right) +1 \right)\delta.\nonumber
\end{align}
%
\end{lemma}
%
\begin{lemma}[Lemma 30 in \cite{chen2021implicit}]\label{lemma:sqv}
Let $X$ be a random variable and $\|X\|_{\infty}$ denotes the largest possible value of $X$. Let $\mathrm{Var}(X)$ denote the variance of $X$. Then $\mathrm{Var}(X^2)\leq 4 \|X\|_{\infty}^2 \mathrm{Var}(X)$.
\end{lemma}

\begin{lemma}[Lemma 10 in \cite{zhang2022horizon}]\label{lemma:con}
Let $X_1,X_2,\ldots$ be a sequence of random variables taking value in $[0,l]$. Define $\mathcal{F}_k =\sigma(X_1,X_2,\ldots,X_{k-1})$ and $Y_k = \mathbb{E}[X_k|\mathcal{F}_k]$ for $k\geq 1$. For any $\delta>0$, we have 
%
\begin{align}
& \mathbb{P}\left[ \exists n, \sum_{k=1}^n X_k \geq  3\sum_{k=1}^n Y_k+ l\ln\frac{1}{\delta}\right]\leq \delta\nonumber
\\  & \mathbb{P}\left[  \exists n,  \sum_{k=1}^n Y_k \geq 3\sum_{k=1}^n X_k + l\ln\frac{1}{\delta}  \right]    \leq \delta .\nonumber 
\end{align}
%
\end{lemma}

\begin{lemma}[Bennet's inequality]\label{bennet}
Let $Z,Z_1,...,Z_n$  be i.i.d.~random variables with values in $[0,1]$ and let $\delta>0$. Define $\mathbb{V}Z = \mathbb{E}\left[(Z-\mathbb{E}Z)^2 \right]$. Then one has
%
\begin{align}
\mathbb{P}\left[ \left|\mathbb{E}\left[Z\right]-\frac{1}{n}\sum_{i=1}^n Z_i  \right| > \sqrt{\frac{  2\mathbb{V}Z \ln(2/\delta)}{n}} +\frac{\ln(2/\delta)}{n} \right]\leq \delta.\nonumber
\end{align}
%
\end{lemma}

\begin{lemma}[Theorem 4 in  \cite{maurer2009empirical}  ]\label{empirical bernstein}
Let $Z,Z_1,...,Z_n$ ($n\geq 2$) be i.i.d.~random variables with values in $[0,1]$ and let $\delta>0$. Define $\overline{Z} = \frac{1}{n}\sum_{i=1}^n Z_{i}$ and $\widehat{V}_n  = \frac{1}{n}\sum_{i=1}^n (Z_i- \overline{Z})^2$. Then we have
%
\begin{align}
\mathbb{P}\left[ \left|\mathbb{E}\left[Z\right]-\frac{1}{n}\sum_{i=1}^n Z_i  \right| > \sqrt{\frac{  2\widehat{V}_n \ln(2/\delta)}{n-1}} +\frac{7\ln(2/\delta)}{3(n-1)} \right] \leq \delta.\nonumber
\end{align}
%
\end{lemma}


\begin{lemma}\label{lemma:doubling}
%
Recall the definition of $N_h^k(s_h^k,a_h^k)$ in Algorithm~\ref{alg:main}. It holds that
%
\begin{align}
\sum_{k=1}^K \sum_{h=1}^H \frac{1}{\max\{ N_h^k(s_h^k,a_h^k),1\}}\leq 2SAH\log_2 K
\end{align}
%
\end{lemma}
\begin{proof}
%
By definition, for any fixed $(s,a,h)$ we have
%
\begin{align}
\sum_{k=1}^K \frac{1}{ N_h^k(s_h^k,a_h^k)}  \mathbb{I}\Big[(s,a)=\big(s_h^k,a_h^k \big) \Big] \leq \log_2 K+1.
\end{align}
%
Summing over all $(s,a,h)$ completes the proof.
\end{proof}


%\section{Discussion for the Discounted MDP}
%In the discounted case, the random variables are more complicated. Using leave-one-out method, we can ensure $(\widehat{P}_{s,a}-P_{s,a})$ is independent of $V^{(s,a)}$, but the sum of error $\sum_{s,a}(\widehat{P}_{s,a}-P_{s,a}) V^{(s,a)}$ is not a martingale (actually it is hard to find a group of $\sigma$-field to make it a martingale), since $V^{(s,a)}$ also depends on $\{ \widehat{P}_{s',a'} \}_{(s',a')\neq (s,a)}$. Deeper analysis shows that to control the error term, we need to find concentration inequalities for a group of coupling random variables, e.g., to prove that $X+XY+Y\leq O(\sqrt{(\mathrm{Var}(X)+\mathrm{Var}(XY)+\mathrm{Var}(Y))\iota})$ with probability $1-\delta$. The example above seems easy, but we are not aware of efficient concentration when the number of random variables is large.


\section{Missing proofs in Section~\ref{sec:tec}}\label{app:mfsectec}


\subsection{Proof of Lemma~\ref{lemma:key1}}\label{app:pfseckey1}


 
 Since $\mathcal{X}_{h+1}$ has at most $W$ elements, we can write $\mathcal{X}_{h+1} = \{x_{h+1}(w)  \}_{w=1}^W$, where each $x_{h+1}(w)$ could be regarded as a function of $\{\widehat{P}^{(J^{k}_{s,a,h})}_{s,a,h'}, \widehat{r}^{(J^k_{s,a,h'})_{h'}(s,a)}, \widehat{\sigma}^{(J^k_{s,a,h'})}_{h'}(s,a)\}_{ h+1\leq h'\leq H, 1\leq k\leq K,(s,a)}$  and $\{J^k\}_{k=1}^K$. Now we fix a group of indices $\{w_{s,a,h}\}_{(s,a,h)}$ where $1\leq w_{s,a,h}\leq W$ for each $(s,a,h)$.

Fix $2\leq l \leq \log_2(K)+1$. We consider to bound the term
%
\begin{align}
T(l,\{w_{s,a,h}\}_{(s,a,h)}) \coloneqq 2^{l-2}\sum_{s,a,h}(\widehat{P}^{(l)}_{s,a,h} - P_{s,a,h}) x_{h+1}(w_{s,a,h}).\nonumber 
\end{align}
%
Recall that $\widehat{P}^{(l)}_{s,a,h}$ is the empirical transition of 
the $l$-th batch of $(s,a,h)$, i.e., the empirical transition of the $2^{l-2}+1$-th to $2^{l-1}$-th samples of $(s,a,h)$. Also recall the definition of $\mathcal{F}_{\mathrm{gen}} = \{\widetilde{F}(z)\}_{z=1}^{SAHK}$ in Definition~\ref{def:filt2}. 
 Conditioned on $\widetilde{\mathcal{F}}((H-h)\cdot SAK)$, $\{x_{h+1}(w_{s,a,h})\}_{(s,a)}$ is fixed, and $\{2^{l-2}\widehat{P}^{(l)}_{s,a,h}\}_{(s,a)}$ are mutually independent multinomial random variables.   Let $v_{s,a,h}(t,l)$ be the next state of the $t$-th sample of  the $ l$-th batch of $(s,a,h)$.   
By writing 
%
\begin{align}
T(l,\{w_{s,a,h}\}_{(s,a,h)}) = \sum_{s,a,h}\sum_{\tau=1}^{2^{l-2}}  ( \textbf{1}_{v_{s,a,h}(\tau,l)} -P_{s,a,h}) \cdot x_{h+1}(w_{s,a,h}),
\end{align}
%
using Lemma~\ref{lemma:self-norm}, with probability at least $1-10SAH^2K^2\delta'$,
%
\begin{align}
T(l,\{w_{s,a,h}\}_{(s,a,h)})  \leq 2\sqrt{2}\cdot \sqrt{ 2^{l-2}\sum_{s,a,h} \mathbb{V}(P_{s,a,h},x_{h+1}(w_{s,a,h}))   \log \frac{1}{\delta'}  } + 3H \log \frac{1}{\delta'}.\label{eq:xx1}
\end{align}


%With $(z,s,a,h,t)$ satisfying $z = (H-h)\cdot SA\cdot 2^{l-2}+ (i-1)\cdot 2^{l-2} + t $, we define $M^{l}(z):= 2^{l-1}\sum_{\alpha=1}^{SA}\sum_{h'\geq h+1}(\widehat{P}^{(l)}_{s^{(\alpha)},a^{(\alpha)},h'}-P_{s^{(\alpha)},a^{(\alpha)},h'} )x^k_{h'+1}(w_{s,a,h'})  + \sum_{\alpha=1}^{i-1}(\widehat{P}^{(l)}_{s^{(\alpha)},a^{(\alpha)},h}-P_{s^{(\alpha)},a^{(\alpha)},h} )x^k_{h'+1}(w_{s,a,h'}) +\sum_{\tau=1}^t ( \textbf{1}_{s'_{s,a,h}(\tau)} x^{k}_{h+1}(w_{s,a,h})-P_{s,a,h} x^{k}_{h+1}(w_{s,a,h})$. 


%Note that $Y_{s^{(i)},a^{(i)},h}$ is measurable with respect to $\mathcal{F}^{l}(z-1)$ for $z = (H-h)\cdot SA\cdot 2^l + (i-1)\cdot 2^l + t $. We then obtain that $\{M^l(z)\}_{z=1}^{SAH\cdot 2^l}$ is a martingale with respect to $\{\mathcal{F}^{l}(z)\}_{z=1}^{SAH\cdot 2^l}$.






Note that $\{w_{s,a,h}\}_{(s,a,h)}$ has at most $(W)^{SAH}$ choices.
 Applying the union bound and rescaling $\delta'$ to $\frac{\delta'}{|W|^{SAH}}$, we see that: with probability at least $1-10SAH^2K^2\delta'$, 
 %
\begin{align}
 & T(l,\{w_{s,a,h}\}_{(s,a,h)})\nonumber\\ &= 2^{l-2}\sum_{s,a,h} (\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h} )x_{h+1}(w_{s,a,h}) \nonumber
 \\ & \leq 2\sqrt{2}\cdot \sqrt{ 2^{l-2}\sum_{s,a,h} \mathbb{V}(P_{s,a,h},x_{h+1}(w_{s,a,h}))   \bigg(2SAH\log W+\log\frac{1}{\delta'}\bigg)  } + 6H\bigg(SAH\log K+\log\frac{1}{\delta'}\bigg) \label{eq:xx2}
\end{align}
%
holds for any $\{w_{s,a,h}\}_{(s,a,h)}$ such that $1\leq w_{s,a,h}\leq W,\forall (s,a,h)$. 



For $l=1$, we have that $\sum_{s,a,h} (\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h} )x_{h+1}(w_{s,a,h}) \leq SAH^2$ trivially.



Now we rewrite 
%
\begin{align}
 & \sum_{k=1}^K \sum_{h=1}^H \left( \widehat{P}^{(J^k_{s_h^k,a_h^k,h})}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h} \right) X_{h+1}^k  \nonumber
 \\ & = \sum_{l=0}^{\log_2(K)} \sum_{s,a,h} (\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h}) \sum_{k=1}^K \mathbb{I}[(s_h^k,a_h^k)=(s,a), I^k_{s,a,h}=l] X_{h+1}^k\nonumber
 \\ & \leq   \sum_{l=1}^{\log_2(K)} \sum_{o = 1}^{2^{l-1}}  \sum_{s,a,h} (\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h}) \sum_{k=1}^K \mathbb{I}[(s_h^k,a_h^k)=(s,a), I^k_{s,a,h}=l,\overline{N}_{s_h^k,a_h^k,h}^k = 2^{l-1}+o] X_{h+1}^k + SAH^2\nonumber
 \\ & = \sum_{l=1}^{\log_2(K)} \sum_{o = 1}^{2^{l-1}}  \sum_{s,a,h} (\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h}) X_{h+1}^{k_{l,o,s,a,h}} + SAH^2,
	\label{eq:f2}
\end{align}
%
where $k_{l,o,s,a,h}$ denotes the index of the $(2^{l-1}+o)$-th sample of $(s,a,h)$ in the online learning process. Recall that $\overline{N}^{K+1}_h(s,a)$ is the total visit count of $(s,a,h)$ in  $K$ episodes. 
If $\overline{N}^{K+1}_{h}(s,a)< 2^{l-1}+o$, we set $k_{l,o,s,a,h}=\infty$ and $X_{h+1}^{\infty}=0$.
% Note that there exists $\mathcal{J}\in \mathcal{C}$ such that $\mathcal{I}\subset \mathcal{J}$. 
Fix $2\leq l \leq \log_2(K)+1$ and $1\leq o \leq 2^{l-1}$, we can find $\{w^{(l,o)}_{s,a,h}\}_{(s,a,h)}$ be such that $x_{h+1}(w^{(l,o)}_{s,a,h})=X_{h+1}^{k_{l,o,s,a,h}}$ for any proper $(s,a,h)$. 
Using \eqref{eq:xx2}  for $(l,o)$ such that  $2\leq l \leq \log_2(K)+1$ and  $1\leq o \leq 2^{l-1}$ , with probability exceeding $1-2K\cdot 10SAH^2K^2\delta'$,
\begin{align}
&  \sum_{l=1}^{\log_2(K)} \sum_{o = 1}^{2^{l-1}}  \sum_{s,a,h} (\widehat{P}_{s,a,h}^{(l)}-P_{s,a,h}) X_{h+1}^{k_{l,o,s,a,h}}  \nonumber
\\ & \leq \sum_{l=1}^{\log_2(K)} \sum_{o = 1}^{2^{l-1}}\frac{1}{2^{l-2}}\Bigg( \sqrt{16 \cdot 2^{l-2} \sum_{s,a,h}\mathbb{V}(P_{s,a,h},X_{h+1}^{k_{l,o,s,a,h}})\cdot \bigg(SAH\log W+\log\frac{1}{\delta'}\bigg) } \nonumber
\\ & \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad + 6H\bigg(SAH\log W+\log\frac{1}{\delta'}\bigg) \Bigg) \nonumber
\\ & \leq \sum_{l=1}^{\log_2(K)}\sqrt{32 \cdot \sum_{s,a,h}\sum_{o=1}^{2^{l-1}} \mathbb{V}(P_{s,a,h},X^{k_{l,o,s,a,h}}_{h+1}) \cdot \bigg(SAH\log W+\log\frac{1}{\delta'}\bigg) } \nonumber
\\ & \qquad\qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad  + \sum_{l=1}^{\log_2(K)} 12H\bigg(SAH\log W+\log\frac{1}{\delta'}\bigg)\nonumber
\\ & \leq \sqrt{64\log_2(K) \sum_{k=1}^K \sum_{h=1}^H \mathbb{V}(P_{s_h^k,a_h^k,h},X_{h+1}^k) \cdot (SAH\log(W)+\log(\frac{1}{\delta'})) } \nonumber
	\\ &\qquad\qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad + 12(\log_2K)H \bigg(SAH\log W+\log\frac{1}{\delta'}\bigg).\label{eq:f} 
\end{align}
In the last inequality, we have applied Cauchy's inequality and the fact that 
\begin{align}
& \sum_{k=1}^K\sum_{h=1}^H \mathbb{V}(P_{s_h^k,a_h^k,h},X_{h+1}^k) \nonumber
\\ & =
\sum_{l=1}^{\log_2(K)}\sum_{s,a,h}\sum_{o=1}^{2^{l-1}}\mathbb{V}(P_{s,a,h},X^{k_{l,o,s,a,h}}_{h+1})
 + \sum_{s,a,h}\sum_{k=1}^K \mathbb{I}\Big[(s_h^k,a_h^k)=(s,a), \overline{N}^k_{h}(s_h^k,a_h^k) = 0\Big]\mathbb{V}(P_{s,a,h},X_{h+1}^k)  .\nonumber
\end{align}


Using \eqref{eq:f2} and \eqref{eq:f}, and replacing $\delta$ with $\delta/(20SAH^2K^3)$, we finish the proof.


\subsection{Proof of Lemma~\ref{lemma:key2}}\label{app:pfkey2}
Let $M = \log_2(K)$ and $N = SAH$. 
Let $\check{\mathcal{C}}(l):= \{ \mathcal{J} = \{J^1,J^2,\ldots,J^l\}| J^{\tau}<J^{\tau+1},\forall 1\leq \tau \leq l-1  , J^{\tau}\in \{0\cup [M]\}^N, \forall \tau
 \}$ and $\check{\mathcal{C}} = \cup_{l\geq 1}\check{\mathcal{C}}(l)$. In words, $\check{\mathcal{C}}(l)$ is the set of \emph{strict} increasing path in $\{0\cup [M]\}^N$ with length $l$ and $\check{\mathcal{C}}$ is the set of all \emph{strict} increasing path.

We define $\mathrm{Proj}:\mathcal{C}\to \check{\mathcal{C}}$ by mapping $\mathcal{J}\in \mathcal{C}$ to $\check{\mathcal{J}}\in \check{\mathcal{C}}$, where $\check{\mathcal{J}}$ is the set of all different elements in $\mathcal{J}$. Let $\mathcal{F}(\check{J}):=\{ \mathcal{J}\in \mathcal{C}| \mathrm{Proj}(\mathcal{J})=\check{\mathcal{J}}\}$  for each $\check{\mathcal{J}}\in \check{\mathcal{C}}$. Because $\check{\mathcal{J}}$ is a \emph{strict} increasing path, there are at most $MN+1$ elements in $\check{\mathcal{J}}$. As a result, the size of $\mathcal{F}(\mathcal{J})$ is at most the solution of the equation below
\begin{align}
\sum_{i=1}^{MN+1} x_i = K, x_i\in \mathbb{N}, \forall 1\leq i \leq MN+1\nonumber
\end{align}
which is $\left( \begin{array}{c} K+MN \\ MN
\end{array}\right) = \frac{(K+MN)!}{(MN)! K!}\leq (K+MN)^{MN}\leq (2K)^{MN}$. It then holds that $|\mathcal{C}|\leq |\check{\mathcal{C}}|\cdot (2K)^{MN}$.

We further consider the set $\check{\mathcal{C}}(MN+1)$. For $\check{\mathcal{J}} = \{J^1,J^2,\ldots, J^{MN+1}\}\in \check{\mathcal{C}}(MN+1)$, with pigeonhole principle, we have that $J^1 = [0,0,\ldots,0]^{\top}$ and $J^{MN+1}=[M,M,\ldots, M]^{\top}$. Moreover, for each $1\leq \tau \leq MN$, $J^{\tau}$ and $J^{\tau+1}$ differ only at one dimension with distance $1$. In this way, we can view $\check{\mathcal{J}}$ as an $MN$-step increasing path from  $ [0,0,\ldots,0]^{\top}$ to $[M,M,\ldots, M]^{\top}$. In each step, we have at most $N$ directions. As a result, there are at most $N^{MN}$ such paths, which implies that $|\check{\mathcal{C}}(MN+1)|\leq N^{MN}$. Finally, noting that for any $\check{\mathcal{J}}\in \check{\mathcal{C}}$, there exists some $\check{\mathcal{J}}'\in \check{\mathcal{C}}(MN+1)$ such that $\check{\mathcal{J}}\subset \check{\mathcal{J}}'$, we conclude that $|\mathcal{C}|\leq (2K)^{MN}|\check{\mathcal{C}}|\leq (2K)^{MN} 2^{MN+1}|\check{\mathcal{C}}(MN+1)|\leq (4KN)^{MN+1}$. 


\subsection{Proof of Lemma~\ref{lemma:key3}}\label{app:pfkey3}


Without loss of generality, we write $\widehat{P}^{(I^k)}=\widehat{P}^k = \{\widehat{P}^k_{s,a,h}\}_{(s,a,h)} = \{\widehat{P}_{s,a,h}^{(I^k_{s,a,h})}\}_{(s,a,h)}$. Then we can regard $\mathcal{X}_{h+1}$ as a function of $\{\widehat{P}^{(I^k)}\}_{k=1}^K$, i.e., 
$\mathcal{X}_{h+1}=  \mathcal{X}_{h+1}^k(\{\widehat{P}^{(I^k)}\}_{k=1}^K, \{I^k\}_{k=1}^K  )$.
Let $\widetilde{\mathcal{E}}$ be the event where there exists $X^k_{h+1} \in \mathcal{X}_{h+1}(\{\widehat{P}^{(I^k)}\}_{k=1}^K, \{I^k\}_{k=1}^K),\forall (h,k)\in [H]\times [K]$ such that \eqref{eq:star} 
does not hold. So it suffices to prove that $\mathrm{Pr}(\widetilde{\mathcal{E}})\leq \delta$.
Fix $\mathcal{J} =\{J^k\}_{k=1}^K\in \mathcal{C}$.
We consider the event $\mathcal{E}(\mathcal{J})$ where there exists a sequence $X^k_{h+1} \in \mathcal{X}_{h+1}(\{\widehat{P}^{(J^k)}\}_{k=1}^K, \{J^k\}_{k=1}^K),\forall (h,k)\in [H]\times [K]$ such that
\begin{align}
& \sum_{k=1}^K \sum_{h=1}^H (\widehat{P}^{(J^k_{s,a,h})}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}) X^k_{h+1} \nonumber
\\ & \leq  \sqrt{L\sum_{k=1}^K \sum_{h=1}^H \mathbb{V}(P_{s_h^k,a_h^k,h},X^k_{h+1})\left(SAH\log(W) + \log(|\mathcal{C}|)+\log(1/\delta)\right)  }\nonumber
\\ & \qquad\qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad + LH(SAH\log(W) + \log(|\mathcal{C}|)+\log(1/\delta))\label{eq:star2},
\end{align}
does not hold, where $L= 200 (\log_2(K)+1)^2$. 
 Let $\widetilde{\mathcal{E}}(\mathcal{J})$ be the event where there exists a sequence $X^k_{h+1} \in \mathcal{X}_{h+1}(\{\widehat{P}^{(J^k)}\}_{k=1}^K),\forall (h,k)\in [H]\times [K]$ such that \eqref{eq:star} 
does not holds and $\mathcal{I}=\mathcal{J}$. Because $|\mathcal{C}|\leq (4SAHK))^{SAH\log_2(K)+1}$, we have $\widetilde{\mathcal{E}}(\mathcal{J})\subset \mathcal{E}(\mathcal{J})$.
With Lemma~\ref{lemma:key1}, we learn that $\mathrm{Pr}(\widetilde{\mathcal{E}}(\mathcal{J}))\leq \mathrm{Pr}(\mathcal{E}(\mathcal{J})) \leq \frac{\delta}{|\mathcal{C}|}$. As a result, we have  $\mathrm{Pr}(\cup_{\mathcal{J}\in \mathcal{C}}\widetilde{\mathcal{E}}(\mathcal{J}))\leq \delta$. By noting that $\widetilde{\mathcal{E}}\subset \cup_{\mathcal{J}\in \mathcal{C}}\widetilde{\mathcal{E}}(\mathcal{J})$, we obtain that $\mathrm{Pr}(\widetilde{\mathcal{E}})\leq \delta$. The proof is completed.


\section{Regret analysis (proof of Theorem~\ref{thm1})}\label{app:thmmain}
\input{proof1}



\section{Proof of the value-based regret bound (proof of Theorem~\ref{thm:first})}\label{sec:appfirst}
\input{first}

\section{Proof of Corollary~\ref{thm:cost}}\label{app:cost}
\input{cost}

\section{Proof of the variance-dependent regret bounds}\label{app:var}

\subsection{Proof of Theorem~\ref{thm:var}}
In this section, we will present the proof of Theorem~\ref{thm:var}. The proof contains two parts, where we respectively prove regret bounds of $\widetilde{O}\left(\min\{\sqrt{SAHK\mathrm{var}_1} +SAH^2,KH\}  \right)$ and $\widetilde{O}\left(\min\{\sqrt{SAHK\mathrm{var}_2} +SAH^2,KH\}  \right)$ . 
Formally we have the following lemmas.

\begin{lemma}\label{lemma:var1}
 With probability exceeding $1-\delta$, the regret of Algorithm~\ref{alg:main} is at most $\widetilde{O}(\min\{\sqrt{SAHK\mathrm{var}_1}+SAH^2,KH\})$
\end{lemma}
\begin{lemma}\label{lemma:var2}
 With probability at least $1-\delta$, the regret of Algorithm~\ref{alg:main} is at most $\widetilde{O}(\min\{\sqrt{SAHK\mathrm{var}_2}+SAH^2,KH\})$
\end{lemma}

Putting the two regret bounds together and rescaling $\delta$ to $\delta/2$, we conclude the proof.

\subsection{Proof of Lemma~\ref{lemma:var1}}
\input{proof_var1}
\subsection{Proof of Lemma~\ref{lemma:var2}}
\input{proof_var2}


\section{Minimax lower bounds}\label{app:lb}

\input{lowerbound}
