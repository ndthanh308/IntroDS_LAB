

In this section, we point out the technical hurdles the previous approach encounters when mitigating the burn-in cost, 
and put forward a new strategy to overcome such hurdles. 




\subsection{Technical barriers in prior theory} 
%


\paragraph{A high-level diagnosis of the technical obstacles.} 
%
Let us first single out a technical challenge on a high level. 
In the regret analysis, one central step is to control the error term $(\widehat{P}-P)V$,  where $\widehat{P}$ represents a certain empirical transition kernel (constructed based on collected data), 
$P$ stands for the true transition kernel, and $V$ is a certain value function estimate. 
The analytical difficult arises in that $V$ is often statistically dependent on $\widehat{P}$. 
A couple of strategies have been adopted in prior works to address this issue. 
%
\begin{itemize}
	\item The first strategy, which has been commonly used for model-based algorithms, 
decomposes the error term as \citep{azar2017minimax,dann2017unifying,zhang2020reinforcement} $$(\widehat{P}-P)V =(\widehat{P}-P)V^* +(\widehat{P}-P)(V-V^*).$$ 
Given $V^*$ is independent of $\widehat{P}$, one can apply Bernstein-style concentration inequalities to control the first term $(\widehat{P}-P)V^*$. As for the second term $(\widehat{P}-P)(V-V^*)$, note that $V-V^*$ might become exceedingly small when $K$ is large enough;  
if this were the case, then one could simply bound this term via $\|\widehat{P}-P\|_1  \|V-V^*\|_{\infty}$, which would become a negligible lower-order term. This approach, however, becomes problematic when $K$ is not large enough, 
as this crude bound 
leads to an extra $\widetilde{O}(\sqrt{S})$ factor in the lower-order term  due to the use of $\|\widehat{P}-P\|_1$. 

	\item We now turn to the analysis of model-free algorithms \citep{jin2018q,zhang2020almost,li2021breaking,menard2021ucb}. 
		One way that has been used in earlier analyses (e.g.,  \citet{jin2018q}) can be described as follows: 
		the learner first computes a value estimate $V$, and then employs news samples to construct $\widehat{P}$, 
		which facilitates the analysis of $(\widehat{P}-P)V$ owing to certain independence between $(\widehat{P}-P)$ and $V$. 
		Nevertheless, this strategy falls short of sample efficiency (even in an asymptotic large-sample sense), given that only the samples collected after computation of $V$ are utilized. 
		To enable asymptotic sample optimality, \citet{zhang2020reinforcement} proposed a solution called reference-advantage decomposition (or variance reduction). This strategy maintains a reference value estimate $V^{\mathrm{ref}}$ (computed using a previous batch of data in a way that obeys $V \approx V^{\mathrm{ref}}$) and decomposes $$(\widehat{P}-P)V = (\widehat{P}-P)V^{\mathrm{ref}}+(\widehat{P}-P)(V-V^{\mathrm{ref}}),$$
where the first term can be easily controlled if $\widehat{P}$ is based on data collected after $V^{\mathrm{ref}}$ is determined, and the second term vanishes if $V\approx V^{\mathrm{ref}}$.  
%		
Unfortunately, this strategy also fails to enable all-regime optimality, 
since even computing the first version of $V^{\mathrm{ref}}$ at the initial stage already requires a large sample size. 

\end{itemize}





\paragraph{A closer inspection on prior analysis for UCB-based algorithms.} 
%
Next, let us take a closer inspection on the regret analysis for UCB-based model-based algorithms, 
in order to better illuminate the part that calls for novel analysis. 

 

In each episode $k = 1,\ldots, K$, we update our estimates for the Q-function and the value function as follows:
%
%\begin{align}
% & V^k_{H+1}(s)=0, \qquad Q^k_{H+1}(s,a)=0, \qquad \forall (s,a)\in \mathcal{S}\times \mathcal{A} .\nonumber
% \end{align}
 working backward (i.e., $h=H,H-1,\ldots, 1$), we set 
 \begin{subequations}
 \begin{align}
	 Q^k_{h}(s,a) &= \min\Big\{ \widehat{r}^k_h(s,a) +  \big\langle \widehat{P}_{s,a,h}^k, V_{h+1}^{k} \big\rangle + b_h^k(s,a),\, H \Big\} ,
  &&\forall (s,a)\in \mathcal{S}\times \mathcal{A}\label{eq:updateqq}
 \\  V^k_h(s)&=\max_{a}Q_h^k(s,a), &&\forall s\in \mathcal{S}.\label{eq:updatevv}\end{align}
 \end{subequations}
%
Here, $\widehat{r}^k_h(s,a)$  
%$\widehat{\sigma}_h^k(s,a)$ 
and $\widehat{P}_{s,a,h}^k$ represent respectively the empirical reward 
%reward square 
and the empirical transition model for the $k$-th episode, and $b_h^k(s,a)$ stands for a bonus function 
%computed based on $(\widehat{P}_{s,a,h}^k,V^k_{h+1},\widehat{r}_h^k(s,a),\widehat{\sigma}_h^k(s,a))$
properly chosen to ensure that $Q_h^k(s,a)\geq Q^*_{h}(s,a)$ with high probability. 
These are computed from the collected data.
%\yxc{TODO} 
 We will specify $\widehat{P}_{s,a,h}^k$ and $\widehat{r}_h^k(s,a)$ 
%and $\widehat{\sigma}_h^k(s,a)$ 
later in Section~\ref{sec:tec1}, and $b_h^k(s,a)\geq 0$ has been described in Section~\ref{sec:alg}. 
It has been shown using standard decomposition arguments that~\citep{jaksch2010near,azar2017minimax,zhang2020reinforcement} 
%
\begin{align}
\mathsf{Regret}(K) \lesssim  \sum_{k,h} b_h^k\big(s_h^k,a_h^k\big) + 
	\underset{\eqqcolon\, T_{\mathrm{err}}}{\underbrace{ \bigg| \sum_{k,h} \Big(\widehat{P}^k_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h} \Big)V_{h+1}^k  \bigg| }}
	+ \bigg| \sum_{k,h} \Big(\widehat{r}_h^k\big(s_h^k,a_h^k\big)-r_h\big(s_h^k,a_h^k \big)\Big) \bigg|.
	\label{eq:key}
\end{align}
%
In order to achieve full-range optimal regret, 
one needs to bound the three terms on the right-hand side of \eqref{eq:key} carefully.  
The first term can be bounded in a rate-optimal manner 
(i.e., $\widetilde{O} \big(\sqrt{ \mathbb{V}(P_{s_h^k,a_h^k,h},V_{h+1}^k) /N} +H/N \big)$)  
if we adopt the bonus construction in \citet{zhang2020reinforcement} for the original MVP  (here, we omit the bonus tailored to stochastic rewards for simplicity). In the meantime, the third term on the right-hand side of \eqref{eq:key} 
can be be easily coped with via standard Bernstein-style concentration inequalities. 


%For the first term, i.e., the sum of the bonuses, we hope there are no explicit terms with high-order dependence on $(S,A,H)$ when designing the bonus function. 
% If we can adopt the bonus construction in MVP, which has the simple form of $\widetilde{O} \big(\sqrt{ \mathbb{V}(\widehat{P}_{s_h^k,a_h^k,h},V_{h+1}^k) /N} +H/N \big)$ (we omit the bonus for reward for simplicity), which will have no lower order term. 
% On the other hand, the third term could be dealt with via standard Bernstein-style concentration inequalities.

%\paragraph{The analysis used in prior works.} 

The term that is the most challenging to control is the second error term $T_{\mathrm{err}}$ on the right-hand side of \eqref{eq:key}. 
Given the statistical dependency between $\widehat{P}^k_{s_h^k,a_h^k,h}$ and $V_{h+1}^k$, 
it is often difficult to directly apply concentration inequalities.\footnote{This is different from the simulator and offline RL setting for inhomogeneous MDPs \citep{li2020breaking,li2022settling}, as $\widehat{P}^k_{s_h^k,a_h^k,h}$ and $V_{h+1}^k$ are (or can be made) independent therein.}
To see this, note that the estimation of $\widehat{P}^{k-1}_{s_h^k,a_h^k,h}$ determines the policy $\pi^{k}$ for the $k$-th round, which in turns affects $\{\widehat{P}^{k}_{s,a,h}\}_{(s,a,h)}$ and $V_{h+1}^k$. On the other hand, $\widehat{P}_{s_h^k,a_h^k,h}^k$ is highly correlated with  $\widehat{P}^{k-1}_{s_h^k,a_h^k,h}$ for most $(s,a,h,k)$-tuples, thus implying that $V_{h+1}^k$ is not independent of $\widehat{P}^k_{s_h^k,a_h^k,h}$.
%
In most prior analysis for model-based algorithms \citep{azar2017minimax,dann2017unifying,zanette2019tighter,zhang2020reinforcement}, this term $T_{\mathrm{err}}$ is decomposed as 
%
\begin{align*}
	&\sum_{k,h} \Big(\widehat{P}^k_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\Big)V_{h+1}^k 
	%\nonumber\\
	%&\qquad \qquad 
	=\sum_{k,h} \Big(\widehat{P}^k_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\Big)V_{h+1}^*+ \sum_{k,h} \Big(\widehat{P}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\Big)\big(V_{h+1}^k-V_{h+1}^*\big).
\end{align*}
%
The first term above can be bounded easily since $V_{h+1}^*$ is fixed and independent of $\widehat{P}^k_{s_{h}^k,a_{h}^k,h}$. 
In comparison, the second term on the right-hand side of the above equation is a lower-order term, which would vanish as $V_{h+1}^*$ converges to $V_{h+1}^*$ (which would happen as $K$ becomes large enough). Such arguments, however, are loose when analyzing the initial stage of the learning process --- given that $V_{h+1}^k-V_{h+1}^*$ is not sufficiently small --- resulting in a potentially large lower-order term and hence large burn-in cost.




\subsection{A novel approach to decouple $V$ from $\widehat{P}$}\label{sec:tec1}
%
To address the above-mentioned issue, the key lies in decoupling the statistical dependence between $\widehat{P}^k_{s_h^k,a_h^k,h}$ and $V_{h+1}^k$. 
Let us first look at the relationship between $\widehat{P}^k_{s_h^k,a_h^k,h}$ 
 and $V_{h+1}^k$.  Let $\{N^k_h(s,a)\}_{(s,a,h)}$ be the number of visits to a state-action-step tuple $(s,a,h)$ before the $k$-th episode. 
Note that $V_{h+1}^k$ is determined by the samples after the $h$-th step up to the $k$-th episode.
 % Then we wonder how these samples is related to $\widehat{P}_{s_h^k,a_h^k,h}$.  
We can find that, $\widehat{P}^k_{s_h^k,a_h^k,h}$ \emph{at most decides the count} after the $h$-th step.
Therefore, if we pretend that the visitation counts $\{N^k_{h}(s,a)\}_{s,a,h,k}$ are fixed independent of $\widehat{P}^k_{s_h^k,a_h^k,h}$, then we can obtain a  desired high-probability upper bound $\widetilde{O}\big( \sqrt{\mathbb{V}(P_{s_h^k,a_h^k,h}, V_{h+1}^k)/N_{h}^k(s_h^k,a_h^k)} \big)$ on the quantity of interest $(\widehat{P}^k_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h})V_{h+1}^k$. 
One natural strategy is then to first develop such bounds for $\{N_{h}^k(s,a)\}_{s,a,h,k}$, and 
then invoke a covering argument that applies a union bound over  all possible choices of $\{N_{h}^k(s,a)\}_{s,a,h,k}$. 

Unfortunately, there are exponentially many choices for $\{N_{h}^k(s,a)\}_{s,a,h,k}$, 
thus preventing one from invoking the uniform convergence argument. 
In order to perform proper compression of the set of all possible choices of $\{N_{h}^k(s,a)\}_{(s,a,h,k)}$, 
we introduce doubling batches (as described in Section~\ref{sec:alg})  
during estimation of the value functions and Q-functions. 
 To facilitate analysis, we have the following definitions.
 
\begin{definition}[Doubling batch and estimations of transitions, rewards, and squared rewards]\label{def:batch} For any $(s,a,h)$, the $i$-th batch for $(s,a,h)$ is the collection of $2^{i-2}+j$-th sample for $j=1,2,\ldots,2^{i-2}$ for $i\geq 2$, and the first sample for $i=1$.\footnote{ It is possible that the total count of $(s,a,h)$ is less than $K$ after $K$ episodes. In this case, we add some virtual samples to fill the $\log_2(K)+1$ batches.} We define $\widehat{P}^{(j)}_{s,a,h}$,  $\widehat{r}^{(j)}_h(s,a)$ and $\widehat{\sigma}^{(j)}_h(s,a)$ to be the empirical transition probability, the empirical reward, and the empirical squared reward of the $j$-th batch for $(s,a,h)$,  respectively. For completeness, we define the $0$-th batch for each $(s,a,h)$ as an empty set, and set $\widehat{P}^{(0)}_{s,a,h} = \frac{1}{S}\mathbf{1}$, $\widehat{r}^{(0)}_h(s,a)= 0$ and $\widehat{\sigma}^{(0)}_h(s,a)=0$ for the $0$-th batch.  
\end{definition}

 
  \begin{definition}[Profile]
Fix $k\in [K]$. Let $I^k_{s,a,h}$ be the largest integer obeying $2^{I^k_{s,a,h}-1}\leq N_{h}^k(s,a)$ for each $(s,a,h)$. In particular, when $N_h^k(s,a)=0$, we set $I^k_{s,a,h}=0$.  
	The profile for the $k$-th episode is defined as 
%
\begin{equation}
	\mathcal{I}^k \coloneqq \big\{I^k_{s,a,h} \big\}_{(s,a,h)\in \mathcal{S}\times \mathcal{A}\times [H]}.
	\label{eq:defn-profile-Ik}
\end{equation}
%
We further let $\mathcal{I} \coloneqq \{\mathcal{I}^k\}_{k=1}^K$ be the total profile.
  \end{definition}


With regards to the online RL, we can define a natural filtration induced by the sequential learning process. The formal definition is as follows. 
%
  \begin{definition}[Online filtration]\label{filt1}
	  For any $(h,k)\in [H+1]\times [K]$, let $\mathcal{F}_h^k$ be the $\sigma$-algebra induced by events happening before the $h$-th step in the $k$-th episode. Then $\{\mathcal{F}_h^k\}_{(h,k)\in [H]\times [K]}$ --- with proper ordering in accordance with the sequential learning process --- constructs a filtration $\mathcal{F}_{\mathrm{online}}$, which we shall refer to as ``online filtration'' throughout. 
  \end{definition}


In order to facilitate analysis, we find it helpful to introduce another filtration below tailored to a generative model (which can be defined in a more flexible way than the online counterpart).  
%
  \begin{definition}[Generative filtration]\label{def:filt2}
    Consider an order over all state-action pairs in $\mathcal{S}\times \mathcal{A}$ such that  
 $\mathcal{S}\times \mathcal{A} = \{ (s^{(i)},a^{(i)})\}_{i=1}^{SA}$. 
 %The samples  are draw in an increasing order from the $H$-th step to the first step, where each $(s,a,h)$ is sampled for $K$ times.  
  Let us employ the following sampling order of the state-action-step tuples: 
 %
 \begin{align}
	 \begin{array}{cccc}
(s^{(1)},a^{(1)},H) & (s^{(2)},a^{(2)},H) & \cdots & (s^{(SA)},a^{(SA)},H)\\
(s^{(1)},a^{(1)},H-1) & (s^{(2)},a^{(2)},H-1) & \cdots & (s^{(SA)},a^{(SA)},H-1)\\
 & \cdots\\
(s^{(1)},a^{(1)},1) & (s^{(2)},a^{(2)},1) & \cdots & (s^{(SA)},a^{(SA)},1)
\end{array}
 \end{align}
 %
where for each $(s,a,h)$ we draw $K$ independent sample transitions from the generative model.  
	  For any $1\leq t\leq K$, define $\overline{\mathcal{F}}_{s,a,h}(t)$ to be the $\sigma$-algebra induced by events happening after the $t$-th sample of $(s,a,h)$ is collected. For any $1\leq z\leq SAHK$,  define $\widetilde{\mathcal{F}}(z) \coloneqq \overline{\mathcal{F}}_{s^{(i)},a^{(i)},h}(t)$, where $(i,h,t)$ is chosen be such that $z = (H-h)\cdot SA\cdot K+ (i-1)\cdot K  + t $. Then (a proper ordering of) $\{\widetilde{F}(z)\}_{z=1}^{SAKH}$ constructs a
 filtration $\mathcal{F}_{\mathrm{gen}}$, which we shall refer to as ``generative filtration'' throughout.
  \end{definition}

In words, there are a total number of  $SAHK$ samples to be collected ($K$ i.i.d.~samples for each $(s,a,h)$), 
and we introduce a sequential ordering of them, with $\widetilde{F}(z)$ denoting the $\sigma$-algebra after the $z$-th sample. 
For convenience, we assume that all initial states have been generated from $\mu$ before the online learning process starts. Then  $\widetilde{F}(SAHK)$ could be viewed as an expansion of $\mathcal{F}_{H+1}^k$, since one could simulate the whole online learning process using the $SAHK$ independent samples in the generative filtration. In other words, for each event in the online filtration $\mathcal{F}_{\mathrm{online}}$, it is measurable w.r.t.~the generative filtration $\mathcal{F}_{\mathrm{gen}}$. 
This allows one to conduct analysis based on the generative filtration (as we shall detail momentarily). 
% In particular, in Lemma~\ref{lemma:key1}, we will prove a concentration inequality under the generative filtration. 
We also remark that we will only use the generative filtration $\mathcal{F}_{\mathrm{gen}}$ when necessary, 
given that the analysis under the online filtration $\mathcal{F}_{\mathrm{online}}$ is more natural for an online learning problem. 



\iffalse
\paragraph{Decoupling $V$ from $\widehat{P}$ with generative filtration} Below we present the high-level idea to use generative filtration to decouple $V$ from $\widehat{P}$.  Fix $\{n_h(s,a)\}_{(s,a,h)}\in [K]^{SAH}$. Define $\widehat{P}_{s,a,h}$ be the empirical transition model of the first $n_{h}(s,a)$ samples of $(s,a,h)$ under the generative filtration. Now we consider the value function $V$ defined as:
\begin{align}
& V_{H+1}(s) = 0,  \forall s\in \mathcal{S};\nonumber
\\ & V_{h}(s) = \min\{\max_{a} r_h(s,a) + \widehat{P}_{s,a,h}V_{h+1}+b(\widehat{P}_{s,a,h},V_{h+1},n_h(s,a)) ,H\},\forall s\in \mathcal{S}, h = H,H-1,\ldots,1,\label{eq:ls1}
\end{align}
where $b(\cdot,\cdot,\cdot)$ is some proper bonus function. 
Conditioned on  $\widetilde{\mathcal{F}}(SAK(H-h))$, $V_{h+1}$ is fixed, and $\{n_h(s,a)\widehat{P}_{s,a,h}\}_{s,a,h}$ are  mutually independent  multinomial random variables. As a result,  the term
\begin{align}
\sum_{h=1}^H \sum_{s,a}n_h(s,a) (\widehat{P}_{s,a,h} - P_{s,a,h})V_{h+1}
\end{align}
could be viewed as a martingale difference. With concentration inequality (Lemma~\ref{lemma:self-norm}), we can bound this term as 
\begin{align}
\sum_{h=1}^H \sum_{s,a}n_h(s,a) (\widehat{P}_{s,a,h} - P_{s,a,h})V_{h+1} \leq O\left(  \sqrt{\sum_{h=1}^H \sum_{s,a} n_h(s,a)\mathrm{Var}(P_{s,a,h},V_{h+1})\log(\frac{SAH}{\delta})  } + H \log(\frac{SAH}{\delta})\right)\label{eq:cpx1}
\end{align}
with probability $1-\delta$. In comparison, if we bound each $(\widehat{P}_{s,a,h}-P_{s,a,h})V_{h+1}$ by $O\left( \sqrt{\frac{\mathbb{V}(P_{s,a,h},V_{h+1})\log(\frac{SAH}{\delta})}{n_h(s,a)}} + \frac{H\log(\frac{SAH}{\delta})}{n_h(s,a)} \right)$, 
 the total bound would be: with probability $1-\delta$
 \begin{align}
\sum_{h=1}^H \sum_{s,a}n_h(s,a)(\widehat{P}_{s,a,h}-P_{s,a,h})V_{h+1}\leq O\left(  \sqrt{SAH\sum_{h=1}^H \sum_{s,a} n_h(s,a)\mathrm{Var}(P_{s,a,h},V_{h+1})\log(\frac{SAH}{\delta})  } + SAH^2 \log(\frac{SAH}{\delta})\right)\label{eq:cpx21}.
 \end{align}

However,   \eqref{eq:cpx1} only holds for fixed $\{n_h(s,a)\}_{(s,a,h)}$, while \eqref{eq:cpx21} holds for any $\{n_h(s,a)\}_{(s,a,h)}$
\fi 



\paragraph{Doubling batch updates.}
%
We  update the value function and Q-function with the doubling batches.
Namely, in the $k$-th episode, 
 we choose $\widehat{P}^k_{s,a,h}= \widehat{P}^{(I^k_{s,a,h})}_{s,a,h}$, $\widehat{r}^k_h(s,a) = \widehat{r}^{(I^k_{s,a,h})}_h(s,a)$ and $\widehat{\sigma}^k_h(s,a) = \widehat{\sigma}^{(I^k_{s,a,h})}_h(s,a)$ for any $(s,a,h,k)$. Our update rule is a slightly different from previous doubling update rules \citep{jaksch2010near}, where the algorithm keeps running a policy until the visitation count of some $(s,a,h)$ doubles and then uses the whole dataset to compute the empirical transition model. In contrast, we divide the whole dataset into disjoint batches following Definition~\ref{def:batch}, and only use the latest batch to compute the empirical transition model. We design this update rule because the samples in different batches are not correlated, which could help us decouple the value function and empirical transition model.
Crucially, our update rule preserves sample efficiency, since the latest batch always contains at least half of the samples. 

 
  


\subsection{Key lemmas}
\label{sec:key-lemmas-tec}
 
As discussed above, under the generative filtration  $\mathcal{F}_{\mathrm{gen}}$, 
the random vector $\widehat{P}^k_{s_h^k,a_h^k,h}$ is conditionally independent of $V_{h+1}^k$ for any $(k,h)\in [K]\times [H]$ if we fix $\mathcal{I}$.
Then we can view the error term $$T_{\mathrm{err}}=\sum_{k=1}^K \sum_{h=1}^H \Big(\widehat{P}^k_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h} \Big) V_{h+1}^k$$  as a martingale difference and obtain a desired  bound. 
Following this intuition, we introduce our key lemma to bound the error term $T_{\mathrm{err}}$ with the doubling batch updates mentioned above.  





  Let $\mathcal{C}$ be a set which contains all possible values of the total profiles $\mathcal{I}$.
One key novelty is to obtain a tight bound on $|\mathcal{C}|$, which we will discuss later.


 Now,  fix any $\mathcal{J}\in \mathcal{C}$, and consider the event $\mathcal{E}(\mathcal{J},\delta)$ defined as follows:
 %
  \begin{align}
	  \mathcal{E}(\mathcal{J},\delta) \coloneqq \left\{\mathcal{I}=\mathcal{J}, \, T_{\mathrm{err}} \leq \sqrt{L\sum_{k=1}^K \sum_{h=1}^H\mathbb{V} \big(P_{s_h^k,a_h^k,h},V_{h+1}^k \big)\bigg(SAH+\log \frac{1}{\delta} \bigg) } + L H \bigg(SAH+\log \frac{1}{\delta} \bigg) \right\}, 
  \end{align}
  %
  where $L$ is a logarithmic term in $(S,A,H,K)$ to be defined shortly. We claim that 
  %
  \begin{equation}
	  \mathrm{Pr}\big(\mathcal{E}(\mathcal{J},\delta)\big)\geq 1- \delta 
	  \label{eq:Pr-E-delta-bound}
  \end{equation}
  %
  for any $\mathcal{J}\in \mathcal{C}$ and $\delta \in (0,1)$.  
Then by applying the union bound over $\mathcal{J} \in \mathcal{C}$ and rescaling $\delta$ as $\delta/|\mathcal{C}|$, we obtain that with probability at least $1-\delta$, 
%
\begin{align}
	T_{\mathrm{err}}\leq  L\sqrt{\sum_{k=1}^K \sum_{h=1}^H\mathbb{V} \big( P_{s_h^k,a_h^k,h},V^k_{h+1} \big)\bigg(SAH+\log\frac{|C|}{\delta}\bigg) } + LH\bigg(SAH+\log\frac{|C|}{\delta}\bigg).\nonumber
\end{align}
%


Consequently, we are left with accomplishing the following two steps:
%
\begin{enumerate}
    \item  Prove that $\mathrm{Pr}(\mathcal{E}(\mathcal{J},\delta))\geq 1-\delta$ (i.e., \eqref{eq:Pr-E-delta-bound}).
    \item Determine $\mathcal{C}$ and  bound $|\mathcal{C}|$ properly.
\end{enumerate}
% (\romannumeral1); (\romannumeral2) 

\paragraph{Proof of inequality~\eqref{eq:Pr-E-delta-bound}.}
%
Towards this end, we need the lemma below. 
%
\begin{lemma}\label{lemma:key1}
Fix any $\mathcal{J} = \{J^k\}_{k=1}^K$. For each $h \times [H]$, let $\mathcal{X}_{h+1}$ be a set of vectors obeying 
\begin{itemize}

\item $\|X\|_{\infty}\leq H$, $\forall X\in \mathcal{X}_{h+1}$; 
\item  $\mathcal{X}_{h+1}$ is determined by $\{\widehat{P}^{(J^k_{s,a,h'})}_{s,a,h'},\widehat{r}^{(J^k_{s,a,h'})}_{h'}(s,a),\widehat{\sigma}^{(J^k_{s,a,h'})}_{h'}(s,a)\}_{ h'\in [h+1, H], k\in [K], (s,a)}$ and $\{J^k\}_{k=1}^K$; 
\item $|\mathcal{X}_{h+1}|\leq W$ for any $1\leq h \leq H$ and some $W\in \mathbb{N}$; 
\item the all-zero vector $\textbf{0}\in \mathcal{X}_{h+1}$ for each $h\in [H]$.

\end{itemize}
%
Then with probability at least $1-\delta$, it holds that
%
\begin{align}
& \Bigg| \sum_{k=1}^K \sum_{h=1}^H \Big(\widehat{P}^{(J^k_{s_h^k,a_h^k,h})}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h} \Big) X^k_{h+1} \Bigg| \nonumber
	\\ & \leq  \sqrt{L\sum_{k=1}^K \sum_{h=1}^H \mathbb{V}\big(P_{s_h^k,a_h^k,h},X^k_{h+1}\big)\bigg(SAH\log W + \log\frac{1}{\delta}\bigg)  } 
	+ LH\bigg(SAH\log W + \log\frac{1}{\delta}\bigg)
\end{align}
%
for any sequence $\{X^k_{h+1}\}_{(h,k)}$ such that $X^k_{h+1} \in \mathcal{X}_{h+1},\forall (h,k)\in [H]\times [K]$, 
where $L = 200(\log_2(K)+1)^2$.
\end{lemma}

The proof of Lemma~\ref{lemma:key1} is based on a martingale concentration inequality in the view of $\mathcal{F}_{\mathrm{gen}}$. We first fix the choice of $X_{h+1}^k\in \mathcal{X}_{h+1}$ for each $(h,k)$, and then verify that $\sum_{s,a}\sum_{h=1}^H 2^{l-2}(\widehat{P}^{(l)}_{s,a,h}-P_{s,a,h}) Y_{s,a,h}$ is a martingale difference for any $l\geq 2$ and $\{Y_{s,a,h}\}_{(s,a,h)}$ as long as  $Y_{s,a,h}$ is selected from $\{X_{h+1}^k\}_{k=1}^K$ according to some specific rule for any $(s,a,h)$. 
See Appendix~\ref{app:pfseckey1} for the proof of Lemma~\ref{lemma:key1}. 



\paragraph{Bounding the size of possible profiles $\left|\mathcal{C}\right|$.}
%
Next, we turn to the second problem concerning $\left|\mathcal{C}\right|$. 
%
Let us choose 
%
\begin{equation}\mathcal{C} \coloneqq 
	\Big\{ \mathcal{J}=\{J^1,J^2,\ldots,J^K\} \,\Big|\, J^{\tau}\leq J^{\tau+1}, \forall 1\leq \tau \leq K-1,  J^{\tau}\in \big\{0\cup[\log_2K]\big\}^{SAH},\forall \tau \Big\}.
	\label{eq:defn-C-choice}
\end{equation}
%
Given that $i^k\leq i^{k+1}$ for $1\leq k\leq K-1$, it is easily seen that $\mathcal{I}\in \mathcal{C}$. The lemma below serves to upper bound the size of $\mathcal{C}$.
%
\begin{lemma}\label{lemma:key2} 
	The choice \eqref{eq:defn-C-choice} obeys 
$|\mathcal{C}|\leq (4SAHK)^{SAH(\log_2K +1)}$.
\end{lemma}

In proving Lemma~\ref{lemma:key2}, we use the increasing property that  $J^{\tau}\leq J^{\tau+1},\forall 1\leq\tau \leq K-1$  for $ \mathcal{J} = \{J^1,J^2,\ldots,J^{K}\}\in \mathcal{C}$. The naive bound for the size of  $\mathcal{C}$ is $(\log_2(K)+1)^{SAHK}$, which is too large for our purpose. By virtue of the increasing property, we are actually counting the number of increasing paths in the $SAH$-dimensional grid $ \left\{[\log_2(K)]\cup {0}\right\}^{SAH}$. For each  increasing path, there are at most $SAH(\log_2(K)+1)$ steps and at most $SAH$ directions for each step. Then the proof can be completed with some primitive combinatorial  computations. 
The detailed proof can be found in Appendix~\ref{app:pfkey2}. 



With Lemma~\ref{lemma:key1} and Lemma~\ref{lemma:key2} in mind, we can invoke a uniform convergence argument to reach the lemma below; 
the proof of this lemma is postponed to Appendix~\ref{app:pfkey3}. 
%
\begin{lemma}\label{lemma:key3} Recall that $\mathcal{I}=\{I^k\}_{k=1}^K$ is the total profile and the fact that $\widehat{P}^{k}_{s,a,h}=\widehat{P}^{(I^k_{s,a,h})}_{s,a,h}, \widehat{r}^k_{h}(s,a) = \widehat{r}^{(I^k_{s,a,h})}_h(s,a), \widehat{\sigma}_h^k(s,a)=\widehat{\sigma}_h^{(I_{s,a,h}^k)}(s,a)$ for any proper $(s,a,k,h)$. 
 For each $h \times [H]$, let $\mathcal{X}_{h+1}$ be a set of vectors be such that: (1) $\|X\|_{\infty}\leq H$, $\forall X\in \mathcal{X}_{h+1}$ ; (2)  $\mathcal{X}_{h+1}$ is determined by $\{\widehat{P}^{k}_{s,a,h'}, \widehat{r}^k_{h'}(s,a),\widehat{\sigma}^k_{h'}(s,a)\}_{ h+1\leq h'\leq H, 1\leq k\leq K, (s,a)}$ and $\{I^k\}_{k=1}^K$; (3) $|\mathcal{X}_{h+1}|\leq W$ for any $1\leq h \leq H$ and some $W\in \mathbb{N}$; (4) the zero vector $\textbf{0}\in \mathcal{X}_{h+1}$ for each $h\in [H]$. Then with probability at least $1-\delta$, it holds that
\begin{align}
& \Bigg| \sum_{k=1}^K \sum_{h=1}^H \Big(\widehat{P}^{k}_{s_h^k,a_h^k,h}-P_{s_h^k,a_h^k,h}\Big) X^k_{h+1}  \Bigg| \nonumber
\\ & \leq  \sqrt{L_1\sum_{k=1}^K \sum_{h=1}^H \mathbb{V}(P_{s_h^k,a_h^k,h},X^k_{h+1})\bigg( SAH\log W + \log \frac{1}{\delta} \bigg)  } 
	+ L_1H \bigg( SAH\log W + \log \frac{1}{\delta} \bigg) \label{eq:star} 
\end{align}
for any sequence $\{X^k_{h+1}\}_{h,k}$ such that $X^k_{h+1} \in \mathcal{X}_{h+1},\forall (h,k)\in [H]\times [K]$, 
where $L_1 = 4000\log^2_2(K)\log(SAHK)$.
\end{lemma}
%
 



%The full proofs of Lemma~\ref{lemma:key1}, Lemma~\ref{lemma:key2} and Lemma~\ref{lemma:key3} can be found in Appendix~\ref{app:mfsectec}.


In Algorithm~\ref{alg:main}, we compute $V_{h+1}^k$  by the following rule.
\begin{align}
& V^k_{H+1}(s) = 0 ;\forall s\in \mathcal{S}; \nonumber
\\ & V_{h'}^k(s) = \min\left\{ \max_{a} \left( \widehat{r}^k_{h'}(s,a)+ \widehat{P}^k_{s,a,h'}V_{h'+1}^k + b(\widehat{P}^k_{s,a,h'},\widehat{r}^k_{h'}(s,a),\widehat{\sigma}_{h'}^k(s,a), n_h^k(s,a) \right)  ,H\right\}
	%\nonumber\\
%&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\forall s\in \mathcal{S}, h'=H,H-1,\ldots, h+1.\nonumber
\end{align}
%
for all $s\in \mathcal{S}$ and $h'=H,H-1,\ldots, h+1$. 
Here $b(\cdot,\cdot,\cdot,\cdot)$ is some proper bonus function and $n_h^k(s,a)$ is the size of the $I^k_{s,a,h}$-th batch of $(s,a,h)$. 
Then $V_{h+1}^k$ is determined by $\{\widehat{P}^{k}_{s,a,h'}, \widehat{r}^{k}_{h'}(s,a),\widehat{\sigma}^{k}_{h'}(s,a)\}_{ h+1\leq h'\leq H, 1\leq k'\leq k, (s,a)}$ and $\{I^k\}_{k=1}^K$, 
thus allowing us to apply Lemma~\ref{lemma:key3} to bound $T_{\mathrm{err}}$ by choosing $\mathcal{X}_{h+1} = \{V_{h+1}^k\}_{k=1}^K$.
In addition, 
it is worth noting that Lemma~\ref{lemma:key3} is more general compared to our original target to bound $T_{\mathrm{err}}$, since  $\mathcal{X}_{h+1}$ can be chosen as arbitrary functions. 

